{"cell_type":{"56d20cbd":"code","a6efd2d9":"code","8e912447":"code","62f86f54":"code","0dd230d4":"code","99f84c60":"code","0a0cc9aa":"code","ed8991f9":"code","67efb7ec":"code","b441f797":"code","b03a088b":"code","1a597252":"code","810fcfb5":"code","fef0a9a0":"code","b3ec5a40":"code","0092f13e":"code","878e32a2":"code","56a002a9":"code","ccfdb279":"code","9b03ae5b":"code","cb22ca40":"code","3cb55dd8":"code","ed030356":"code","233df138":"code","d856e604":"code","23d0e87b":"code","d53e7b15":"code","2613fa02":"code","575fe313":"code","f3bab236":"code","16e2f6b4":"code","c95ba7d4":"code","69095678":"code","4f552cb8":"code","5bb6666f":"code","ae11bd1a":"code","a7cf9d11":"code","7b042ef1":"code","abaa1016":"code","db4bdf26":"code","2ad09afe":"code","fee30779":"code","723caaae":"code","56f7a61e":"code","b9e76526":"code","7c2c3626":"code","e26449a1":"code","dbef2dff":"code","af7e6672":"code","5299526e":"code","f6a13bd3":"code","1d525cc3":"code","70da5fc1":"code","232e5aab":"code","da227edb":"code","dde17c74":"code","e53f25fe":"code","c9ee0fa7":"code","0c15ad0f":"code","1a676332":"code","d38f224c":"code","d67a3051":"code","851b8b4d":"code","ef0cb1f8":"code","e54f3b8c":"code","38ee84c0":"code","4b93dc3d":"code","932369a3":"code","4cf4b95d":"code","543d8087":"code","5d200fa3":"code","38362405":"code","842194b0":"code","c4dab18c":"code","28dbaf85":"code","f8dc4c5b":"markdown","f7cb08da":"markdown","598b3057":"markdown","c2087ad3":"markdown","a27133ce":"markdown","5d0d4600":"markdown","e84860d4":"markdown","a95ea8ab":"markdown","ecd89348":"markdown","97570a5f":"markdown","ce8af2f8":"markdown","da5298a2":"markdown","e033d66c":"markdown","6d5cf1cf":"markdown","95a86a60":"markdown","192437c9":"markdown","e0d1a64c":"markdown","9735b38d":"markdown"},"source":{"56d20cbd":"!pip install stylecloud\n!pip install xlrd==1.2.0","a6efd2d9":"\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8e912447":"# !pip install ipython==7.10.0","62f86f54":"# \u5bfc\u5165\u76f8\u5173\u5305\nimport pandas as pd\nimport os\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport gensim\nfrom gensim.utils import simple_preprocess\nimport gensim.corpora as corpora\nfrom gensim.models.tfidfmodel import TfidfModel\nfrom gensim.models.ldamodel import LdaModel\nfrom gensim.models.coherencemodel import CoherenceModel\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport re\nimport string\n\nimport seaborn as sns\n\nfrom pprint import pprint\n\nfrom wordcloud import WordCloud\n\nfrom PIL import Image\n\nimport pyLDAvis.gensim\n\nimport stylecloud\n\nfrom tqdm import tqdm\n\nprint(os.getcwd())","0dd230d4":"# \u6e05\u7a7a\u6240\u6709\u8f93\u51fa\u6587\u4ef6\n\n# import shutil\n# if os.listdir('\/kaggle\/working') != []:\n#     shutil.rmtree('\/kaggle\/working')","99f84c60":"# \u5168\u5c40\u9009\u53d6\u5173\u952e\u8bcdTop N\nGLOBAL_TOP_N = 20\n\n# \u9010\u6708\u9009\u53d6\u5173\u952e\u8bcdTop N\nPER_MONTH_TOP_N = 10\n\n# \u4e3b\u9898\u6570\u9009\u53d6\nNUM_TOPICS = 4\n\n# \u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570\nITERATIONS = 50","0a0cc9aa":"# \u6307\u5b9a\u5f53\u524d\u5de5\u4f5c\u8def\u5f84\nos.chdir('\/kaggle')\nprint(os.getcwd())\n\n# \u4ececsv\u6587\u4ef6\u4e2d\u8bfb\u5165\u6570\u636e\nTwitter_data = pd.read_excel('.\/input\/twitter-dm-dataset\/twitter_covid.xlsx')\n\n# \u521d\u59cb\u6570\u636e\u90e8\u5206\u5c55\u793a\nTwitter_data.head()","ed8991f9":"# \u89c4\u8303\u5316\u6570\u636e \u5217\u540d\u79f0\nTwitter_data.rename(\n    columns={'m_content': 'content', 'g_publish_time': 'publish_time', 'm_content_id': 'content_id'},\n    inplace=True\n)","67efb7ec":"# \u722c\u53d6\u521d\u59cb\u6570\u636e\u5b58\u5728\u7a7a\u884c\uff0c\u9700\u8981\u8fdb\u884c\u5904\u7406\n# \u53ef\u4ee5\u770b\u5230\u670911744\u6761\u975e\u7a7a\u63a8\u6587\uff0c\u5374\u670911841\u6761\u53d1\u5e03\u65e5\u671f\uff0c\u6240\u4ee5\u6570\u636e\u80af\u5b9a\u5b58\u5728\u90e8\u5206\u7f3a\u5931\nTwitter_data.info()","b441f797":"# \u6e05\u9664\u7f3a\u5931\u63a8\u6587\u6216\u7f3a\u5931\u53d1\u5e03\u65f6\u95f4\u7684\u6570\u636e\nTwitter_data.dropna(axis=0, how='any', inplace=True)","b03a088b":"# \u6e05\u9664\u4e86\u63a8\u6587\u4e3a\u7a7a\u7684\u6570\u636e\u9879\nTwitter_data.info()","1a597252":"# \u5c06\u53d1\u5e03\u65f6\u95f4\u8f6c\u6362\u6210python\u4e2d\u7684datetime\u683c\u5f0f,\u4fbf\u4e8e\u540e\u7eed\u64cd\u4f5c,\u5e76\u5c06\u53d1\u5e03\u65f6\u95f4\u7edf\u4e00\u4e3a year-month-date \u7684\u683c\u5f0f\n\n# PS:\u4e0d\u4f7f\u7528pd.to_datetime\u662f\u56e0\u4e3a\u5bf9\u4e8e\u67d0\u4e00\u6761\u6570\u636e\uff0c\u6211\u4eec\u53ea\u5173\u5fc3\u5176\u53d1\u5e03\u7684\u65e5\u671f\uff0c\u5728\u4e00\u5929\u4e2d\u7684\u5177\u4f53\u65f6\u95f4\u5e76\u4e0d\u5173\u5fc3\uff0c\n# \u800cpd.datetime\u4f1a\u5e26\u4e0a hour-min-sec \uff0c\u4e0d\u5229\u4e8e\u540e\u7eed\u64cd\u4f5c\nTwitter_data['publish_time'] = Twitter_data['publish_time'].map \\\n(lambda x: datetime.date((int)(x.split('-')[0]), (int)(x.split('-')[1]), (int)(x.split('-')[2].split(' ')[0])))\n","810fcfb5":"# \u6240\u6709\u6570\u636e\u6309\u7167\u53d1\u5e03\u65f6\u95f4\u6392\u5e8f\nTwitter_data = Twitter_data.sort_values(by='publish_time')\nTwitter_data.reset_index(inplace=True)\ndel Twitter_data['index']","fef0a9a0":"# \u89c2\u5bdf\u5230\u4e0d\u5728\u9884\u671f\u65f6\u95f4\u8303\u56f4\u5185\u7684\u6570\u636e\uff0c\u8fdb\u884c\u6e05\u9664\nTwitter_data.head()","b3ec5a40":"#\u8bbe\u5b9a\u8d77\u59cb\u3001\u622a\u6b62\u65e5\u671f\nstart_date = datetime.date(2020, 3, 12)\nend_date = datetime.date(2021, 1, 12)\n\n\nfor index, date in enumerate(Twitter_data['publish_time']):\n    # \u5728\u8d77\u59cb\u65e5\u671f\u524d\u6216\u622a\u6b62\u65e5\u671f\u540e,\u4e3a\u4e0d\u7b26\u5408\u8981\u6c42\u7684\u6570\u636e\n    if date.__sub__(start_date).days<0 or date.__sub__(end_date).days>0:\n        Twitter_data.drop(index=index, inplace=True)\n        \nTwitter_data = Twitter_data.reset_index()\ndel Twitter_data['index']","0092f13e":"# \u53ef\u4ee5\u89c2\u5bdf\u5230\u6570\u636e\u5f00\u59cb\u548c\u7ed3\u675f\u90fd\u5df2\u7ecf\u7b26\u5408\u9884\u671f\nTwitter_data.head()","878e32a2":"Twitter_data.tail()","56a002a9":"def format_month_or_day(month_or_day):\n    if int(month_or_day)>0 and int(month_or_day)<10:\n        return '0' + str(month_or_day)\n    else:\n        return month_or_day","ccfdb279":"# \u5c06publish_time\u8fdb\u884c\u62c6\u5206\u4fbf\u4e8e\u540e\u7eed\u7edf\u8ba1\nTwitter_data['year'] = Twitter_data['publish_time'].map(lambda x: x.year)\nTwitter_data['month'] = Twitter_data['publish_time'].map(lambda x: x.month)\nTwitter_data['date'] = Twitter_data['publish_time'].map(lambda x: format_month_or_day(x.day))\nTwitter_data['year_month'] = Twitter_data['publish_time'].map(lambda x: str(x.year) + '-' + str(format_month_or_day(x.month)))\nTwitter_data['times'] = Twitter_data['publish_time'].map(lambda x: 1)","9b03ae5b":"Twitter_data.head()","cb22ca40":"# \u5bf9\u4e8e\u67d0\u4e00\u5929\u7684\u6570\u636e\u9891\u6b21\u7edf\u8ba1\u5982\u4e0b,times\u4e3a\u9891\u6b21\nday_data = Twitter_data.groupby(['publish_time'], as_index=False).agg({'times': 'sum'})","3cb55dd8":"day_data","ed030356":"# \u5bf9\u4e8e\u67d0\u4e2a\u6708\u7684\u6570\u636e\u9891\u6b21\u7edf\u8ba1\u5982\u4e0b\uff0ctimes\u4e3a\u9891\u6b21\nmonth_data = Twitter_data.groupby(['year_month', 'year', 'month'], as_index=False).agg({'times': 'sum'})\nmonth_data['day'] = 1\nmonth_data['publish_time'] = pd.to_datetime(month_data[['year', 'month', 'day']]) ","233df138":"month_data[['year_month', 'times']]","d856e604":"# \u6570\u636e\u91cf\u968f\u65e5\u671f\u5206\u5e03\u7684\u6298\u7ebf\u56fe\uff0c\u53ef\u4ee5\u770b\u5230\u67d0\u4e9b\u65e5\u671f\u7684\u6570\u636e\u91cf\u8f83\u5c11\uff0c\u603b\u4f53\u6765\u8bf4\u76f8\u5bf9\u5747\u5300\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nfig.set_size_inches(16,5)\n\nplt.plot(day_data['publish_time'], day_data['times'], linewidth=1.3, label='Daily', color='orange')\nax.set(xlabel='count',title='Distribution of tweets by date')\nplt.legend()\nplt.show()","23d0e87b":"# \u6570\u636e\u91cf\u968f\u6708\u4efd\u5206\u5e03\u7684\u67f1\u72b6\u56fe\uff0c\u53ef\u4ee5\u770b\u52302020-3\u548c2021-1\u7684\u6570\u636e\u91cf\u8f83\u5c11\uff0c\u5176\u4ed6\u6708\u4efd\u6570\u636e\u91cf\u90fd\u8f83\u5747\u5300\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nfig.set_size_inches(16,5)\nrects = plt.bar \\\n(range(len(month_data['month'])), month_data['times'], tick_label=month_data['year_month'], color='rgb')\n\n# \u6253\u6570\u636e\u6807\u6ce8\nfor rect in rects:  #rects \u662f\u4e09\u6839\u67f1\u5b50\u7684\u96c6\u5408\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width() \/ 2, height, str(height), size=13, ha='center', va='bottom')\n\nplt.title('Distribution of tweets by year-month')\nplt.show()","d53e7b15":"# plt.figure(figsize=(10,10))\n# plt.hist(Twitter_data['publish_time'], density=True, bins='auto',align='left')","2613fa02":"# \u6570\u636e\u91cf\u968f\u6708\u4efd\u5206\u5e03\u7684\u997c\u56fe\nfig = plt.figure()\nfig.set_size_inches(8,8)\n\nplt.pie(month_data['times'],labels=month_data['year_month'],autopct='%1.1f%%',shadow=False,startangle=150)\nplt.title('Distribution of tweets by year-month')\nplt.show()","575fe313":"# print(string.punctuation)\n\ndef text_preprocess(data):\n    # \u53bb\u9664@user\n    processed_data = data.map(lambda x: re.sub(r'@[\\w]*', '', x))\n\n    # \u53bb\u9664\u7f51\u5740\n    processed_data = processed_data.map(lambda x: re.sub(r'http.*\\..* ', '', x))\n\n    # \u53bb\u9664\u6807\u70b9\u7b26\u53f7\n    processed_data = processed_data.map(lambda x: re.sub(r'[^a-zA-Z ]', '', x))\n\n    # \u5220\u9664\u957f\u5ea6\u592a\u77ed\u7684\u8bcd\uff08\u901a\u5e38\u65e0\u610f\u4e49\uff09\n    processed_data = processed_data.map(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n\n    # \u5206\u8bcd\n    processed_data = processed_data.map(lambda x: nltk.WordPunctTokenizer().tokenize(x))\n\n    return processed_data","f3bab236":"# \u53bb\u9664\u6807\u70b9\u3001@\u3001\u77ed\u8bcd\uff0c\u8fdb\u884c\u5206\u8bcd\nProcessed_data = text_preprocess(Twitter_data['content'])","16e2f6b4":"# \u7ecf\u8fc7\u9884\u5904\u7406\u540e\u7684\u5355\u8bcd\u77e9\u9635\nProcessed_data.head()","c95ba7d4":"nltk.download('wordnet')\nnltk.download('stopwords')","69095678":"# \u67e5\u770b\u505c\u7528\u8bcd\u8bcd\u5178\nstopwords.words('english')","4f552cb8":"# \u53bb\u9664\u505c\u7528\u8bcd\nstop_words = stopwords.words('english')\nstop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n\ndef sent_to_words(sentences):\n    for sentence in sentences:\n        # deacc=True removes punctuations\n        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n\ndef remove_stopwords(texts):\n    return [[word for word in simple_preprocess(str(doc)) \n             if word not in stop_words] for doc in texts]\n\n\n# \u53bb\u9664\u505c\u7528\u8bcd\ndata_words = remove_stopwords(Processed_data)\n","5bb6666f":"# \u53bb\u9664\u505c\u7528\u8bcd\u540e\u7684\u5355\u8bcd\u77e9\u9635\ndata_words","ae11bd1a":"# \u53bb\u9664\u641c\u7d22\u5173\u952e\u8bcd\n\n","a7cf9d11":"# \u5bfc\u5165\u4e0b\u9762\u4e09\u79cd\u8bcd\u5e72\u63d0\u53d6\u5668\u8fdb\u884c\u5bf9\u6bd4\nimport nltk.stem.porter as pt\nimport nltk.stem.lancaster as lc\nimport nltk.stem.snowball as sb\n\n# \u5bfc\u5165nltk.stem\u7528\u6765\u8bcd\u578b\u8fd8\u539f\nimport nltk.stem as ns\n\ndef word_stem(text_matrix):\n\n    print(\"----------\u8bcd\u5e72\u63d0\u53d6-------------\")\n    # \u5728\u540d\u8bcd\u548c\u52a8\u8bcd\u4e2d\uff0c\u9664\u4e86\u4e0e\u6570\u548c\u65f6\u6001\u6709\u5173\u7684\u6210\u5206\u4ee5\u5916\u7684\u6838\u5fc3\u6210\u5206\u3002\n    # \u8bcd\u5e72\u5e76\u4e0d\u4e00\u5b9a\u662f\u5408\u6cd5\u7684\u5355\u8bcd\n\n    pt_stemmer = pt.PorterStemmer()  # \u6ce2\u7279\u8bcd\u5e72\u63d0\u53d6\u5668\n    lc_stemmer = lc.LancasterStemmer()   # \u5170\u5361\u65af\u8bcd\u5e72\u63d0\u53d6\u5668\n    sb_stemmer = sb.SnowballStemmer(\"english\")# \u601d\u8bfa\u535a\u8bcd\u5e72\u63d0\u53d6\u5668\n    \n    \n\n    print(\"%8s %8s %8s %8s\" % ('word','pt_stem','lc_stem','sb_stem'))\n    for index_txt, text in enumerate(tqdm(text_matrix)):\n        for index_word, word in enumerate(text):\n            pt_stem = pt_stemmer.stem(word)\n            lc_stem = lc_stemmer.stem(word)\n            sb_stem = sb_stemmer.stem(word)\n            if index_txt==1 and index_word<10:\n                print(\"%8s %8s %8s %8s\" % (word,pt_stem,lc_stem,sb_stem))\n            \n\n\n","7b042ef1":"# \u5c55\u793a\u4e00\u4e0b\u8bcd\u5e72\u63d0\u53d6\u7684\u7ed3\u679c\uff0c\u4f46\u5b9e\u9645\u5e76\u6ca1\u6709\u4f7f\u7528\u8bcd\u5e72\u63d0\u53d6\uff0c\u56e0\u4e3a\u7c92\u5ea6\u8fc7\u7c97\nword_stem(data_words)","abaa1016":"# \u8bcd\u578b\u8fd8\u539f\uff1a\u590d\u6570\u540d\u8bcd->\u5355\u6570\u540d\u8bcd \uff1b\u5206\u8bcd->\u52a8\u8bcd\u539f\u578b\n# \u5355\u8bcd\u539f\u578b\u4e00\u5b9a\u662f\u5408\u6cd5\u7684\u5355\u8bcd\n\ndef word_lemma(text_matrix): \n    print(\"----------\u8bcd\u578b\u8fd8\u539f\u5668---------------\")\n    \n    print(\"%8s %8s %8s\" % ('word','n_lemma','v_lemma'))\n    lemmatizer = ns.WordNetLemmatizer()\n    for index_txt, text in enumerate(tqdm(text_matrix)):\n        for index_word, word in enumerate(text):\n            # \u5c06\u540d\u8bcd\u8fd8\u539f\u4e3a\u5355\u6570\u5f62\u5f0f\n            n_lemma = lemmatizer.lemmatize(word, pos='n')\n            # \u5c06\u52a8\u8bcd\u8fd8\u539f\u4e3a\u539f\u578b\u5f62\u5f0f\n            v_lemma = lemmatizer.lemmatize(word, pos='v')\n            if index_txt == 1 and index_word < 10:\n                print('%8s %8s %8s' % (word, n_lemma, v_lemma))\n            \n            if(len(n_lemma)<len(v_lemma)):\n                text_matrix[index_txt][index_word] = n_lemma\n            else:\n                text_matrix[index_txt][index_word] = v_lemma\n                \n    return text_matrix\n            ","db4bdf26":"# \u5b9e\u9645\u4f7f\u7528\u4e86\u7c92\u5ea6\u66f4\u7ec6\u7684\u8bcd\u5f62\u8fd8\u539f\ndata_words = word_lemma(data_words)","2ad09afe":"# \u7ecf\u8fc7\u8bcd\u5f62\u8fd8\u539f\u540e\u7684\u5355\u8bcd\u77e9\u9635\ndata_words","fee30779":"# \u53bb\u9664\u641c\u7d22\u5173\u952e\u8bcd\u76f8\u5173\u7684\u5355\u8bcd\nban_words_list = []\nwith open('.\/input\/twitter-dm-dataset\/ban_words_list.txt') as f:\n    for line in f.readlines():\n        ban_words_list.append(line.strip('\\n'))","723caaae":"ban_words_list","56f7a61e":"def remove_search_words(words_matrix, ban_words_list):\n    words_processed = []\n    for text in words_matrix:\n        words_text = []\n        for word in text:\n            if word not in ban_words_list:\n                words_text.append(word)\n                \n        words_processed.append(words_text)\n        \n    return words_processed\n    ","b9e76526":"data_words = remove_search_words(data_words, ban_words_list)","7c2c3626":"data_words","e26449a1":"# \u6784\u9020\u8bcd\u5178\uff08\u5c06\u5355\u8bcd\u8bcd\u5178\u5316\uff0c\u7f16\u53f7\u548c\u5355\u8bcd\u5177\u6709\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff09\ndictionary = corpora.Dictionary(data_words)\n\ntexts = data_words\n\n# \u7edf\u8ba1\u8bcd\u9891\uff0c\u6784\u9020\u8bcd\u9891\u77e9\u9635\uff08\u8bcd\u888b\uff09\ncorpus = [dictionary.doc2bow(text) for text in texts]\n","dbef2dff":"# \u6784\u9020TF-IDF\u6a21\u578b\ntf_idf_model = TfidfModel(corpus, normalize=True)\nword_tf_idf = list(tf_idf_model[corpus])","af7e6672":"# \u8bcd\u5178\ndictionary.token2id","5299526e":"# \u8bcd\u9891\uff08\u6bcf\u4e00\u884c\u4ee3\u8868\u4e00\u7bc7\u63a8\u6587\uff0c\u67d0\u4e00\u884c\u4e2d\u7684\u67d0\u4e2a\u5143\u7ec4\u5bf9\uff08x,y\uff09\u4ee3\u8868\u7f16\u53f7\u4e3ax\u7684\u5355\u8bcd\u5728\u8be5\u63a8\u6587\u4e2d\u51fa\u73b0\u4e86y\u6b21\uff09\ncorpus","f6a13bd3":"# \u6bcf\u4e2a\u53e5\u5b50\u5bf9\u5e94\u7684\u8bcd\u888b (\u524d\u9762\u662f\u5355\u8bcd\uff0c\u540e\u9762\u662f\u8bcd\u9891)\n# \u8bcd\u9891\u77e9\u9635\u53cd\u5411\u5316\uff08id->\u5355\u8bcd\uff09\n\nid_words = [[(dictionary[id], count) for id, count in line] for line in corpus]\nprint(data_words[1])\nprint(id_words[1])","1d525cc3":"# TF-IDF\u5f97\u5206\uff0c\u6bcf\u7bc7\u63a8\u6587\u4e2d\u6bcf\u4e2a\u5355\u8bcd\u90fd\u6709\u5bf9\u5e94\u7684TF_IDF\u5f97\u5206\uff0c\u8be5\u5f97\u5206\u5df2\u7ecf\u8fdb\u884c\u4e86\u6807\u51c6\u5316\uff0c\u53ef\u4ee5\u89c6\u4f5c\u4e00\u4e2a\u5355\u8bcd\u7684\u6743\u91cd\nword_tf_idf","70da5fc1":"# \u57fa\u4e8eTF-IDF\u7b97\u6cd5\u63d0\u53d6\u5173\u952e\u8bcd\ndef TF_IDF_get_keywords(words_matrix, top_n=3):\n    # \u6784\u5efa\u8bcd\u888b\u6a21\u578b\n\n    # \u6784\u9020\u8bcd\u5178\uff08\u5c06\u5355\u8bcd\u8bcd\u5178\u5316\uff0c\u7f16\u53f7\u548c\u5355\u8bcd\u5177\u6709\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff09\n    dictionary = corpora.Dictionary(words_matrix)\n\n    texts = words_matrix\n\n    # \u7edf\u8ba1\u8bcd\u9891\uff0c\u6784\u9020\u8bcd\u9891\u77e9\u9635\uff08\u8bcd\u888b\uff09\n    corpus = [dictionary.doc2bow(text) for text in texts]\n    \n    tf_idf_model = TfidfModel(corpus, normalize=True)\n    word_tf_idf = list(tf_idf_model[corpus])\n    \n    key_words_matrix = []\n    \n    for index_txt, text in enumerate(tqdm(word_tf_idf)):\n        text.sort(key=lambda x: x[1], reverse=True)\n        key_words_code = [word[0] for word in text[:top_n+3]]\n        key_words = []\n#         print(key_words_code)\n        for code in key_words_code:\n            if dictionary[code] not in ban_words_list:\n                key_words.append(dictionary[code])\n            if len(key_words)>=3:\n                break\n        \n        if index_txt<5:\n            print('tweet %d \\'s keywords: ' % index_txt)\n            print(key_words)\n            print()\n            \n        key_words_matrix.append(key_words)\n    \n    return key_words_matrix\n        \n    \n    ","232e5aab":"# \u63d0\u53d6\u6bcf\u7bc7\u63a8\u6587Top3\u7684TF-IDF\u5f97\u5206\u7684\u5173\u952e\u8bcd\nkey_words_global = TF_IDF_get_keywords(data_words)","da227edb":"key_words_global","dde17c74":"# \u63d0\u53d6\u9ad8\u9891\u5173\u952e\u8bcd\ndef get_highest_frequency_words(words, top_n=10):\n    frequency = {}\n    for word in words:\n        if word in frequency:\n            frequency[word] += 1\n        else:\n            frequency[word] = 1\n    \n#     print(frequency)\n    top_words = sorted(frequency.items(), key=lambda x: x[1],reverse=True)[:top_n]\n    \n#     print(top_words)\n    top_words_dict = {}\n    for word in top_words:\n        top_words_dict[word[0]] = word[1]\n        \n        \n    return top_words_dict","e53f25fe":"# \u63d0\u53d6\u6bcf\u4e2a\u6708\u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u5173\u952e\u8bcd\nkey_words_global_general = {}\n\nkey_words = []\nfor text in key_words_global:\n    for word in text:\n        key_words.append(word)\n    \n# print(key_words)\n\nkey_words_global_general = get_highest_frequency_words(key_words, top_n=GLOBAL_TOP_N)\n\n# \u5c06Top20\u5173\u952e\u8bcd\u8f93\u51fa\u81f3.\/keywords\/global\/Top20_keywords_global.txt\u6587\u4ef6\u4e2d\nif not os.path.exists('.\/working\/key_words\/global'):\n    os.makedirs('.\/working\/key_words\/global')\nif not os.path.exists('.\/working\/key_words\/global\/Top20_keywords_global.txt'):\n\n    with open('.\/working\/key_words\/global\/Top20_keywords_global.txt', 'w') as f:\n        for key_word in key_words_global_general:\n            f.write(key_word+' '+str(key_words_global_general[key_word])+'\\n')\n    ","c9ee0fa7":"key_words_global_general","0c15ad0f":"# \u751f\u6210\u5168\u5c40\u8bcd\u4e91\n\n# \u8fde\u63a5\u5168\u5c40\u5173\u952e\u8bcd\u77e9\u9635\u4e2d\u6240\u6709\u5355\u8bcd\nglobal_string =  ' '.join([' '.join(word) for word in key_words_global])\n\n# # Create a WordCloud object\n# wordcloud = WordCloud \\\n# (height=400, width=800, background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\n\n# \n# wordcloud.generate(global_string)\n# wordcloud.to_image()\n# if not os.path.exists('.\/word_cloud\/global\/wordcloud_global.png'):\n#     wordcloud.to_file('.\/word_cloud\/global\/wordcloud_global.png')\n\n\nif not os.path.exists('.\/working\/word_cloud\/global'):\n    os.makedirs('.\/working\/word_cloud\/global')\n\n# \u751f\u6210\u8bcd\u4e91    \n    \nif not os.path.exists('.\/working\/word_cloud\/global\/wordcloud_global.png'):\n    \n    stylecloud.gen_stylecloud( \n        text=global_string, \n        icon_name=\"fab fa-twitter\", # \u4f7f\u7528\u63a8\u7279\u56fe\u6807\u8499\u7248\n        gradient='horizontal', # \u6e10\u53d8\u8272\u65b9\u5411\u9009\u4e86\u5782\u76f4\u65b9\u5411\n        max_words=200,\n        output_name='.\/working\/word_cloud\/global\/wordcloud_global.png',\n    )\n\n# \u8bcd\u4e91\u53ef\u89c6\u5316\n\nimg = Image.open('.\/working\/word_cloud\/global\/wordcloud_global.png')\n    \nfig = plt.figure(figsize=(12,8))\nplt.imshow(img)\nplt.axis('off')\nplt.title('global wordcloud', fontsize='xx-large',fontweight='heavy')\nplt.show()","1a676332":"month_data['times']","d38f224c":"# \u9010\u6708\u5206\u5272\u5173\u952e\u8bcd\u77e9\u9635\n'''\ninput: \u5355\u8bcd\u77e9\u9635\uff08\u5206\u8bcd\u540e\u7684\u5355\u8bcd \/ \u63d0\u53d6\u540e\u7684\u5173\u952e\u8bcd\u77e9\u9635\uff09, shape:\n       \u9010\u6708\u6570\u636e\u6761\u6570\uff08\u6bcf\u4e2a\u6708\u6709\u591a\u5c11\u6761\u6570\u636e\uff0c\u524d\u9762\u5df2\u7ecf\u7edf\u8ba1\u8fc7\u4e86\uff09, \n       \u5177\u4f53\u6708\u4efd\uff08\u8fd9\u91cc\u4f7f\u7528year-month\uff09\n       \noutput: \u9010\u6708\u5206\u5272\u540e\u7684\u5355\u8bcd\u77e9\u9635\uff08\u589e\u52a0\u4e86\u4e00\u4e2a\u7ef4\u5ea6\uff09 \n'''\n\ndef words_separate_by_month(words_matrix, times_by_month, year_month):\n    '''\n    @description: \n    @param \n    @return: \n    '''\n    \n    key_words_by_month = {}\n    \n    global_index = 0\n    \n    for index, times in enumerate(times_by_month):\n        key_words_per_month = []\n        for i in range(times):\n            key_words_per_month.append(words_matrix[global_index])\n            global_index += 1\n            \n        key_words_by_month[year_month[index]] = key_words_per_month\n    \n    \n    return key_words_by_month","d67a3051":"# \u751f\u6210\u9010\u6708\u8bcd\u4e91\nkey_words_by_month = words_separate_by_month(key_words_global, month_data['times'], month_data['year_month'])","851b8b4d":"# 2020\u5e7411\u6708\u7684\u524d5\u6761\u6570\u636e\nkey_words_by_month['2020-11'][:5]","ef0cb1f8":"# \u63d0\u53d6\u6bcf\u4e2a\u6708\u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u5173\u952e\u8bcd\nkey_words_by_month_general = {}\n\nfor year_month in key_words_by_month.keys():\n    key_words_per_month = []\n    for text in key_words_by_month[year_month]:\n        for word in text:\n            key_words_per_month.append(word)\n    \n#     print(key_words_per_month)\n    \n    key_words_by_month_general[year_month] = get_highest_frequency_words \\\n    (key_words_per_month, top_n=PER_MONTH_TOP_N)\n    \n    if not os.path.exists('.\/working\/key_words\/per_month'):\n        os.makedirs('.\/working\/key_words\/per_month')\n    if not os.path.exists('.\/working\/key_words\/per_month\/Top10_keywords_'+year_month+'.txt'):\n\n        with open('.\/working\/key_words\/per_month\/Top10_keywords_'+year_month+'.txt', 'w') as f:\n            for key_word in key_words_by_month_general[year_month]:\n                f.write(key_word+' '+str(key_words_by_month_general[year_month][key_word])+'\\n')\n    ","e54f3b8c":"# \u6bcf\u4e2a\u6708\u7684top10\u5173\u952e\u8bcd\npprint(key_words_by_month_general)","38ee84c0":"# \u751f\u6210\u9010\u6708\u8bcd\u4e91\n\nfor year_month in key_words_by_month.keys():\n    \n    # \u8fde\u63a5\u9010\u6708\u5173\u952e\u8bcd\u77e9\u9635\u4e2d\u6240\u6709\u5355\u8bcd\n    per_month_string = ' '.join([' '.join(x) for x in key_words_by_month[year_month]])\n\n#     print(len(per_month_string))\n    # Create a WordCloud object\n    wordcloud = WordCloud \\\n    (height=400, width=800, background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\n\n    # \u751f\u6210\u8bcd\u4e91\n    wordcloud.generate(per_month_string)\n\n    if not os.path.exists('.\/working\/word_cloud\/per_month'):\n        os.makedirs('.\/working\/word_cloud\/per_month')\n    \n    if not os.path.exists('.\/working\/word_cloud\/per_month\/wordcloud_'+year_month+'.png'):\n        wordcloud.to_file('.\/working\/word_cloud\/per_month\/wordcloud_'+year_month+'.png')\n    \n    \n    img = Image.open('.\/working\/word_cloud\/per_month\/wordcloud_'+year_month+'.png')\n    \n    fig = plt.figure(figsize=(12,8))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title('word cloud of %s' % year_month, fontsize='xx-large',fontweight='heavy',color='white')\n    plt.show()","4b93dc3d":"# \u8bfb\u53d6\u6216\u521b\u5efalda\u6a21\u578b\nif not os.path.exists('.\/working\/lda_model'):\n    os.makedirs('.\/working\/lda_model')\n\nif os.path.exists('.\/input\/lda.model'):\n    lda_model = LdaModel.load('.\/input\/lda.model')\nelse:\n\n    # \u8bbe\u5b9a\u7684\u4e3b\u9898\u6570\u76ee\n    num_topics = NUM_TOPICS\n    iterations = ITERATIONS\n\n    # \u6784\u5efaLDA\u6a21\u578b\n    lda_model = gensim.models.LdaMulticore(\n        corpus=corpus,\n        id2word=dictionary,\n        num_topics=num_topics\n    )\n\n    lda_model.save('.\/working\/lda_model\/lda.model')\n\n    \ntopic_list = lda_model.print_topics(num_words=10)\n","932369a3":"# \u4e3b\u9898\u5206\u5e03\ntopic_list","4cf4b95d":"# \u6a21\u578b\u56f0\u60d1\u5ea6\u5f97\u5206\n# \u5f97\u5206\u8d8a\u4f4e\u8bf4\u660e\u6a21\u578b\u5bf9\u6587\u672c\u8d8a\u4e0d\u56f0\u60d1\nprint('Perplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\n# \u6a21\u578b\u4e00\u81f4\u6027\u5f97\u5206\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('Coherence Score: ', coherence_lda)","543d8087":"# \u683c\u5f0f\u5316\u8f93\u51fa\u6240\u6709\u4e3b\u9898\u6784\u6210\uff08\u6982\u7387\u5206\u5e03\uff09\nif not os.path.exists('.\/working\/lda_topics'):\n    os.makedirs('.\/working\/lda_topics')\n    \nif not os.path.exists('.\/working\/lda_topics\/topics.txt'):\n    with open('.\/working\/lda_topics\/topics.txt', 'w') as f:\n        for topic in topic_list:\n            f.write('topic %d:\\n' % topic[0])\n            for word in topic[1].split('+'):\n#                 print(word)\n                f.write('  {}  {}\\n'.format(word.split('*')[1], word.split('*')[0]))\n                \n            f.write('\\n')\n    \n    ","5d200fa3":"# \u6bcf\u4e2a\u6587\u6863\u90fd\u5305\u542b\u591a\u4e2a\u4e3b\u9898\u3002\u4f46\u662f\uff0c\u901a\u5e38\u53ea\u6709\u4e00\u4e2a\u4e3b\u9898\u662f\u4e3b\u5bfc\u7684\u3002\n# \u4e0b\u9762\u7684\u4ee3\u7801\u4e3a\u6bcf\u4e2a\u53e5\u5b50\u63d0\u53d6\u8be5\u4e3b\u8981\u4e3b\u9898\uff0c\u5e76\u5728\u683c\u5f0f\u6b63\u786e\u7684\u8f93\u51fa\u4e2d\u663e\u793a\u8be5\u4e3b\u9898\u548c\u5173\u952e\u5b57\u7684\u6743\u91cd\u3002\ndef format_topics_sentences(ldamodel, corpus, texts):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n    # Get main topic in each document\n    for i, row in enumerate(ldamodel[corpus]):\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0: # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append\\\n                (pd.Series([int(topic_num),round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    contents = pd.Series(texts)\n    # print(contents)\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    # print(sent_topics_df)\n    return(sent_topics_df)\n\ndf_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words)\n\n# Format\ndf_dominant_topic = df_topic_sents_keywords.reset_index()\ndf_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Topic_Keywords', 'Text']\n\n\n\ndf_dominant_topic.to_csv('.\/working\/lda_topics\/dominant_topics.csv',index=False)","38362405":"# \u4f7f\u7528LDA\u5bf9\u6bcf\u7bc7\u63a8\u6587\u7684\u4e3b\u8981\u4e3b\u9898\u7b5b\u9009\ndf_dominant_topic","842194b0":"# LDA\u6a21\u578b\u53ef\u89c6\u5316\n\nvis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\npyLDAvis.display(vis_data)","c4dab18c":"SentiWordNet = pd.read_csv('.\/input\/twitter-dm-dataset\/SentiWordNet3.0.0.csv')","28dbaf85":"# \u60c5\u611f\u8bcd\u8bcd\u5178\u5206\u5e03\nSentiWordNet['attr'].value_counts()","f8dc4c5b":"# \u57fa\u4e8eLDA\u4e3b\u9898\u6a21\u578b\u548c\u60c5\u611f\u8bcd\u5178\u7684Twitter\u63a8\u6587\u4e3b\u9898\u63d0\u53d6\u53ca\u60c5\u611f\u5206\u6790","f7cb08da":"##### \u5c40\u9650\u6027\uff1a\n- \u60c5\u611f\u8bcd\u5178\u65b9\u9762\uff0c\u5355\u8bcd\u5f97\u5206\u76f4\u63a5\u7531\u76f8\u5173\u5355\u8bcd\u5f97\u51fa\uff0c\u5e76\u672a\u8003\u8651\u7a0b\u5ea6\u526f\u8bcd\u7684\u5f71\u54cd\n\n- ","598b3057":"## \u4e8c\u3001\u6587\u672c\u9884\u5904\u7406","c2087ad3":"### \u8bcd\u888b\u6a21\u578b(bag of words)\n- \u5c06\u6bcf\u4e00\u7bc7\u6587\u6863\u89c6\u4e3a\u4e00\u4e2a\u8bcd\u9891\u5411\u91cf\uff0c\u4ece\u800c\u5c06\u6587\u672c\u4fe1\u606f\u8f6c\u5316\u4e3a\u4e86\u6613\u4e8e\u5efa\u6a21\u7684\u6570\u5b57\u4fe1\u606f\n- \u8bcd\u888b\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u8bcd\u4e0e\u8bcd\u4e4b\u95f4\u7684\u987a\u5e8f\uff0c\u8fd9\u7b80\u5316\u4e86\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u4e5f\u4e3a\u6a21\u578b\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u5951\u673a","a27133ce":"## \u5de5\u4f5c\u73af\u5883\uff1a(jupyter notebook)\n\n\npython 3.7.5\n\npandas 1.0.1 (\u5904\u7406\u8868\u683c\u6570\u636e)\n\nwordcloud 1.8.1 (\u8bcd\u4e91)\n\nstylecloud 0.5.1 (\u8bcd\u4e91)\n\nnltk 3.5 (\u5185\u542b\u5404\u79cd\u505c\u7528\u8bcd\uff0c\u4ee5\u53ca\u8bcd\u5e72\u63d0\u53d6\uff0c\u8bcd\u5f62\u8fd8\u539f\u548c\u5206\u8bcd\u7684\u65b9\u6cd5)\n\ngensim 3.8.3 (\u5185\u542bLDA\u6a21\u578b)\n\npyLDAvis 3.2.2 (LDA\u6a21\u578b\u53ef\u89c6\u5316\u5de5\u5177)\n\nnumpy 1.17.4 (\u6570\u5b66\u5de5\u5177)\n\nmatplotlib 3.1.1 (\u6570\u636e\u53ef\u89c6\u5316\u7ed8\u56fe\u5de5\u5177)\n\nseaborn 0.11.0\n\nPillow 7.1.2\n\ntqdm 4.46.0\n","5d0d4600":"## \u4ec0\u4e48\u662fLDA\u4e3b\u9898\u6a21\u578b?\n\n\u5728LDA\u4e2d\uff0c\u6240\u6709\u7684\u6587\u6863\u5171\u6709\u540c\u6837\u7684\u8bdd\u9898\u96c6\uff0c\u4f46\u662f\u6bcf\u4e2a\u6587\u6863\u4ee5\u4e0d\u540c\u7684\u6bd4\u4f8b\u5c55\u793a\u5bf9\u5e94\u7684\u8bdd\u9898\u3002LDA\u7684\u4e3b\u8981\u76ee\u6807\u662f\u81ea\u52a8\u53d1\u73b0\u4e00\u4e2a\u6587\u6863\u96c6\u5408\u4e2d\u7684\u8bdd\u9898\u3002\u8fd9\u4e9b\u6587\u6863\u672c\u8eab\u662f\u53ef\u4ee5\u89c2\u6d4b\u5230\u7684\uff0c\u800c\u8bdd\u9898\u7684\u7ed3\u6784\u2014\u2014\u8bdd\u9898\u3001\u6bcf\u4e2a\u6587\u6863\u7684\u8bdd\u9898\u5206\u5e03\u548c\u6bcf\u4e2a\u6587\u6863\u7684\u6bcf\u4e2a\u8bcd\u7684\u8bdd\u9898\u8d4b\u503c\u2014\u2014\u662f\u9690\u85cf\u7684\uff08\u53ef\u79f0\u4e3ahidden structure\uff09\u3002\u8bdd\u9898\u5efa\u6a21\u7684\u6838\u5fc3\u8ba1\u7b97\u95ee\u9898\u5c31\u662f\u4f7f\u7528\u89c2\u6d4b\u5230\u7684\u6587\u6863\u6765\u63a8\u65ad\u9690\u85cf\u8bdd\u9898\u7ed3\u6784\u3002\u8fd9\u4e5f\u53ef\u4ee5\u770b\u4f5c\u662f\u751f\u6210\uff08generative\uff09\u8fc7\u7a0b\u7684\u9006\u8fc7\u7a0b\u2014\u2014\u4ec0\u4e48\u6837\u7684\u9690\u85cf\u7ed3\u6784\u53ef\u4ee5\u4ea7\u751f\u89c2\u6d4b\u5230\u7684\u6587\u6863\u96c6\u5408\uff1f\n\n\n### LDA\u6a21\u578b\u8bad\u7ec3\n\n\u9ed8\u8ba4\u8bbe\u7f6e\u67095\u4e2atopic\n\n\u671f\u671btopic\u5728\u56db\u4e2a\u8c61\u9650\u5206\u5e03\u8d8a\u5747\u5300\u8d8a\u597d\uff0c\u4ee3\u8868\u8986\u76d6\u5f97\u8d8a\u5168\u9762\n\n\u82e5topic\u4e4b\u95f4\u9694\u7684\u592a\u8fdc\uff0c\u5219\u589e\u5927topic\u7684\u6570\u91cf\n\n\u82e5\u4e0d\u540ctopic\u4e4b\u95f4\u6709\u8f83\u5927\u7684\u91cd\u53e0\uff0c\u5219\u51cf\u5c11topic\u7684\u6570\u91cf\n","e84860d4":"##### \u4f18\u70b9\uff1a\n- \u76f8\u6bd4\u4e8e\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u60c5\u611f\u8bcd\u5178\u8ba1\u7b97\u6587\u672c\u5f97\u5206\uff0c\u65e0\u9700\u7ecf\u8fc7\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u8c03\u53c2\uff0c\u8fc7\u7a0b\u66f4\u4e3a\u76f4\u89c2\uff0c\u4e5f\u66f4\u9002\u5408\u4e8e\u50cftwitter\u63a8\u6587\u8fd9\u79cd\u77ed\u6587\u672c\u7684\u5206\u6790\uff08\u77ed\u6587\u672c\u901a\u5e38\u6709\u5f88\u591a\u903b\u8f91\u4e0d\u5b8c\u6574\u4e14\u4e0d\u7b26\u5408\u8bed\u6cd5\u89c4\u5219\u7684\u53e5\u5b50\uff09\n\n- \n\n","a95ea8ab":"## LDA\u53ef\u89c6\u5316\n- \u6bcf\u4e2a\u4e3b\u9898\u7684\u610f\u4e49\uff08\u53f3\u8fb9\u7684\u5355\u8bcd\u4e3a\u67d0\u4e2a\u4e3b\u9898\u4e0b\u5e38\u51fa\u73b0\u7684\u5355\u8bcd\uff09\n- \u6bcf\u4e2a\u4e3b\u9898\u5728\u603b\u8bed\u6599\u5e93\u4e2d\u7684\u6bd4\u91cd\n- \u4e3b\u9898\u4e4b\u95f4\u7684\u5173\u8054\n","ecd89348":"#### \u6570\u636e\u5206\u5e03\u60c5\u51b5\uff1a2020-3\u548c2021-1\u7684\u6570\u636e\u91cf\u8f83\u5c11\uff0c\u5176\u4ed6\u6708\u4efd\u6570\u636e\u91cf\u90fd\u8f83\u5747\u5300","97570a5f":"## \u8bcd\u4e91\u5206\u6790","ce8af2f8":"### \u60c5\u611f\u8bcd\u5178\u6cd5\u8ba1\u7b97\u6587\u672c\u60c5\u611f\u5f97\u5206\n\n1. \u786e\u5b9a\u5426\u5b9a\u8bcd\u8bcd\u5178\u3001\u7a0b\u5ea6\u526f\u8bcd\u8bcd\u5178\n\n2. \u5224\u65ad\u6bcf\u4e2a\u60c5\u611f\u8bcd\u524d\u662f\u5426\u6709\u5426\u5b9a\u8bcd\u6216\u7a0b\u5ea6\u526f\u8bcd\uff0c\u5c06\u5b83\u4e4b\u524d\u7684\u5426\u5b9a\u8bcd\u548c\u7a0b\u5ea6\u526f\u8bcd\u5212\u5206\u4e3a\u4e00\u4e2a\u7ec4\uff0c\u5982\u679c\u6709\u5426\u5b9a\u8bcd\u5c06\u60c5\u611f\u8bcd\u7684\u60c5\u611f\u6743\u503c\u4e58\u4ee5-1\uff0c\u5982\u679c\u6709\u7a0b\u5ea6\u526f\u8bcd\u5c31\u4e58\u4ee5\u7a0b\u5ea6\u526f\u8bcd\u7684\u7a0b\u5ea6\u503c\uff0c\u6700\u540e\u6240\u6709\u7ec4\u7684\u5f97\u5206\u52a0\u8d77\u6765\uff0c\u5927\u4e8e0\u7684\u5f52\u4e8e\u6b63\u5411\uff0c\u5c0f\u4e8e0\u7684\u5f52\u4e8e\u8d1f\u5411\n\n3. \u6570\u636e\u7edf\u8ba1\u7ed3\u679c\u5206\u6790 \n\n","da5298a2":"## \u6d41\u7a0b\n1. \u6570\u636e\u83b7\u53d6:\n\n\u4f7f\u7528python\u722c\u866b\u722c\u53d6twitter\u6570\u636e,\u65f6\u95f4\u7ebf(2020.3.12-2021.1.12)\n\n2. \u6570\u636e\u6e05\u6d17:\n\n    \u2460 \u6e05\u9664\u5b58\u5728\u63a8\u6587\u6216\u53d1\u5e03\u65f6\u95f4\u7f3a\u5931\u7684\u6570\u636e\u6761\u76ee\n    \n    \u2461 \u5c06\u6570\u636e\u6309\u7167\u53d1\u5e03\u65f6\u95f4\u524d\u540e\u987a\u5e8f\u6392\u5e8f\n    \n    \u2462 \u6570\u636e\u5206\u5e03\u521d\u6b65\u5206\u6790\uff08\u968f\u53d1\u5e03\u65f6\u95f4\uff09\n\n3. \u6587\u672c\u9884\u5904\u7406:\n\n    \u2460 Twitter_data['content'] \u521d\u59cb\u6570\u636e(matrix size:)\n    \n    \u2461 Processed_data \u53bb\u9664\u4e86\u6807\u70b9\u3001@\u3001\u77ed\u8bcd(matrix size:)\n    \n    \u2462 data_words \u53bb\u9664\u4e86nltk\u505c\u7528\u8bcd\u8bcd\u5178\u4e2d\u7684\u505c\u7528\u8bcd\u3001\u81ea\u5b9a\u4e49\u7684\u7981\u7528\u8bcd\u5217\u8868\uff08\u5982\u641c\u7d22\u5173\u952e\u8bcd\uff09(matrix size:)\n\n\n4. **\u60c5\u611f\u5206\u6790:**\n\n    \u2460 \u6839\u636eTF-IDF\u7b97\u6cd5\u5bf9\u63a8\u6587\u8fdb\u884c\u5173\u952e\u8bcd\u63d0\u53d6\uff0c\u8fdb\u884c\u8bcd\u4e91\u5c55\u793a\uff08\u603b\u4f53\u3001\u9010\u6708\uff09\n    \n        1. \u63d0\u53d6\u5168\u5c40Top20\u5173\u952e\u8bcd\uff0c\u751f\u6210\u8bcd\u4e91\u5c55\u793a\n        \n        2. \u9010\u6708\u5206\u5272\u5168\u5c40\u5173\u952e\u8bcd\u77e9\u9635\n        \n        3. \u9010\u6708\u63d0\u53d6Top10\u5173\u952e\u8bcd\uff0c\u751f\u6210\u8bcd\u4e91\u5c55\u793a\n    \n    \u2461 \u4f7f\u7528LDA\u4e3b\u9898\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u63d0\u53d6\u4e3b\u9898\u5206\u5e03\n    \n        1. \u6784\u5efaLDA\u6a21\u578b\uff0c\u8fdb\u884c\u8bad\u7ec3\n\n        2. \u8ba1\u7b97\u6a21\u578b\u56f0\u60d1\u5ea6(Perplexity)\u548c\u6a21\u578b\u4e00\u81f4\u6027\u5f97\u5206(Coherence Score)\uff0c\u5176\u4e2d\u56f0\u60d1\u5ea6\u8d8a\u4f4e\u8d8a\u597d\uff0c\u4e00\u81f4\u6027\u5f97\u5206\u8d8a\u9ad8\u8d8a\u597d\n\n        3. \u4e3a\u6bcf\u7bc7\u63a8\u6587\u5206\u914d\u5bf9\u5e94\u5360\u4e3b\u5bfc\u5730\u4f4d\u7684\u4e3b\u9898\uff08\u6982\u7387\u8f83\u9ad8\u7684\uff09\n\n        4. \u8c03\u6574\u4e3b\u9898\u9009\u53d6\u6570\u6216\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570\u7b49\u5176\u4ed6\u53c2\u6570\uff0c\u8fed\u4ee3\u8c03\u4f18\n        \n    \u2462 \u4f7f\u7528\u60c5\u611f\u8bcd\u5178\u6cd5\u5bf9\u6587\u672c\u8fdb\u884c\u5206\u6790\uff0c \u8ba1\u7b97\u6587\u672c\u60c5\u611f\u5f97\u5206\n    \n        1. \u60c5\u611f\u8bcd\u8bcd\u5178\u4f7f\u7528SentiWordNet3.0\uff0c\u5426\u5b9a\u8bcd\u8bcd\u5178\u4f7f\u7528 \uff0c\u7a0b\u5ea6\u526f\u8bcd\u8bcd\u5178\u4f7f\u7528 \n        \n        2. \u5224\u65ad\u6bcf\u4e2a\u60c5\u611f\u8bcd\u524d\u662f\u5426\u6709\u5426\u5b9a\u8bcd\u6216\u7a0b\u5ea6\u526f\u8bcd\uff0c\u5c06\u5b83\u4e4b\u524d\u7684\u5426\u5b9a\u8bcd\u548c\u7a0b\u5ea6\u526f\u8bcd\u5212\u5206\u4e3a\u4e00\u4e2a\u7ec4\uff0c\u5982\u679c\u6709\u5426\u5b9a\u8bcd\u5c06\u60c5\u611f\u8bcd\u7684\u60c5\u611f\u6743\u503c\u4e58\u4ee5-1\uff0c\u5982\u679c\u6709\u7a0b\u5ea6\u526f\u8bcd\u5c31\u4e58\u4ee5\u7a0b\u5ea6\u526f\u8bcd\u7684\u7a0b\u5ea6\u503c\uff0c\u6700\u540e\u6240\u6709\u7ec4\u7684\u5f97\u5206\u52a0\u8d77\u6765\uff0c\u5927\u4e8e0\u7684\u5f52\u4e8e\u6b63\u5411\uff0c\u5c0f\u4e8e0\u7684\u5f52\u4e8e\u8d1f\u5411\n        \n        3. \u6839\u636e\u60c5\u611f\u8bcd\u5178\u8fdb\u884c\u6587\u672c\u5f97\u5206\u8ba1\u7b97\uff0c\u6bcf\u7bc7\u63a8\u6587\u4f1a\u8ba1\u7b97\u51fa\u4e00\u4e2a\u5f97\u5206\u3002\u5176\u60c5\u611f\u8d8a\u79ef\u6781\uff0c\u5219\u5f97\u5206\u8d8a\u9ad8\uff1b\u53cd\u4e4b\u60c5\u611f\u8d8a\u6d88\u6781\uff0c\u5219\u5f97\u5206\u8d8a\u4f4e\n        \n        4. \u6570\u636e\u7edf\u8ba1\u7ed3\u679c\u5206\u6790\n\n5. \u7ed3\u679c\u5206\u6790\n\n","e033d66c":"## \u4e00\u3001\u6570\u636e\u6e05\u6d17","6d5cf1cf":"## \u521d\u59cb\u5316\u53c2\u6570\u8bbe\u7f6e\n- \u5168\u5c40\u9009\u53d6\u5173\u952e\u8bcdTop N\n- \u9010\u6708\u9009\u53d6\u5173\u952e\u8bcdTop N\n- \u4e3b\u9898\u6570\u9009\u53d6\n- \u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570","95a86a60":"### \u89c2\u5bdf\u539f\u6570\u636e\u57282020.3.12-2021.1.12\u7684\u5206\u5e03\u60c5\u51b5","192437c9":"## \u6982\u5ff5\u8bf4\u660e\n \n \n#### \u4ec0\u4e48\u662fLDA\uff1f\n\n> LDA\uff08\u9690\u542b\u72c4\u5229\u514b\u96f7\u5206\u5e03\uff09**\u5c06\u6587\u6863\u96c6\u4e2d\u7684\u6bcf\u7bc7\u6587\u6863\u7684\u4e3b\u9898\u4ee5\u6982\u7387\u5206\u5e03\u7684\u5f62\u5f0f\u7ed9\u51fa**\n\n\n\n#### \u4ec0\u4e48\u662fTF-IDF\uff1f\n\n> TF: \u8bcd\u9891(term frequency) \uff08\u5bf9\u4e8e\u67d0\u4e2a\u6587\u672c\uff0c\u5355\u8bcd\u5728\u67d0\u4e2a\u6587\u672c\u4e2d\u51fa\u73b0\u8d8a\u591a\u6b21\u8d8a\u91cd\u8981\uff09\n\n> IDF: \u9006\u6587\u6863\u9891\u7387(inverse document frequency) \uff08\u5355\u8bcd\u5728\u8bed\u6599\u5e93\uff08\u6240\u6709\u6587\u672c\uff09\u4e2d\u51fa\u73b0\u8d8a\u5c11\u6b21\u8d8a\u91cd\u8981\uff09\n\n> TF-IDF\u662f\u4e00\u79cd\u8861\u91cf\u67d0\u4e00\u7bc7\u6587\u6863\u4e2d\u67d0\u4e2a\u8bcd\u5bf9\u8be5\u7bc7\u6587\u6863\u91cd\u8981\u7a0b\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002\u901a\u8fc7TF-IDF\u516c\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u8ba1\u7b97\u51fa\u8fd9\u4e2a\u8bcd\u5bf9\u4e8e\u8868\u73b0\u8fd9\u7bc7\u6587\u6863\u4e3b\u9898\u800c\u8a00\u8d21\u732e\u5982\u4f55\u3002TFIDF\u7684\u4e3b\u8981\u601d\u60f3\u662f\uff1a\u5982\u679c\u67d0\u4e2a\u8bcd\u6216\u77ed\u8bed\u5728\u4e00\u7bc7\u6587\u7ae0\u4e2d\u51fa\u73b0\u7684\u9891\u7387TF\u9ad8\uff0c\u5e76\u4e14\u5728\u5176\u4ed6\u6587\u7ae0\u4e2d\u5f88\u5c11\u51fa\u73b0\uff0c\u5219\u8ba4\u4e3a\u6b64\u8bcd\u6216\u8005\u77ed\u8bed\u5177\u6709\u5f88\u597d\u7684\u7c7b\u522b\u533a\u5206\u80fd\u529b\uff0c\u9002\u5408\u7528\u6765\u5206\u7c7b\u6216\u63d0\u53d6\u5173\u952e\u8bcd\u3002\n\n\n\n\n#### \u4ec0\u4e48\u662f\u60c5\u611f\u8bcd\u5178\uff1f\n\n\n","e0d1a64c":"## TF-IDF\uff08\u5173\u952e\u8bcd\u6743\u91cd\uff09\u4e0eLDA\uff08\u8bcd\u5206\u5e03\uff09\u7684\u533a\u522b\n\n> \u4f7f\u7528TF-IDF\u8fdb\u884c\u5173\u952e\u8bcd\u63d0\u53d6\u7684\u5c40\u9650\u6027\u5728\u4e8e: \u5728\u67d0\u4e9b\u573a\u666f\uff0c\u57fa\u4e8e\u6587\u6863\u672c\u8eab\u7684\u5173\u952e\u8bcd\u63d0\u53d6\u8fd8\u4e0d\u662f\u975e\u5e38\u8db3\u591f\uff0c\u6709\u4e9b\u5173\u952e\u8bcd\u5e76\u4e0d\u4e00\u5b9a\u4f1a\u663e\u793a\u5730\u51fa\u73b0\u5728\u6587\u6863\u5f53\u4e2d\uff0c\u5982\u4e00\u7bc7\u8bb2\u52a8\u7269\u751f\u5b58\u73af\u5883\u7684\u79d1\u666e\u6587\uff0c\u901a\u7bc7\u4ecb\u7ecd\u72ee\u5b50\u8001\u864e\u7b49\uff0c\u4f46\u662f\u6587\u4e2d\u5e76\u6ca1\u6709\u663e\u793a\u5730\u51fa\u73b0\u52a8\u7269\u4e8c\u5b57\u3002\n\n> \u800cLDA\u4e3b\u9898\u6a21\u578b\u8ba4\u4e3a\u5728\u8bcd\u4e0e\u6587\u6863\u4e4b\u95f4\u6ca1\u6709\u76f4\u63a5\u7684\u8054\u7cfb\uff0c\u5b83\u4eec\u5e94\u5f53\u8fd8\u6709\u4e00\u4e2a\u7ef4\u5ea6\u5c06\u5b83\u4eec\u4e32\u8054\u8d77\u6765\uff0c\u4e3b\u9898\u6a21\u578b\u5c06\u8fd9\u4e2a\u7ef4\u5ea6\u79f0\u4e3a\u4e3b\u9898\u3002\u6bcf\u4e2a\u6587\u6863\u90fd\u5e94\u8be5\u5bf9\u5e94\u7740\u4e00\u4e2a\u6216\u591a\u4e2a\u7684\u4e3b\u9898\uff0c\u800c\u6bcf\u4e2a\u4e3b\u9898\u90fd\u4f1a\u6709\u5bf9\u5e94\u7684\u8bcd\u5206\u5e03\uff0c\u901a\u8fc7\u4e3b\u9898\uff0c\u5c31\u53ef\u4ee5\u5f97\u5230\u6bcf\u4e2a\u6587\u6863\u7684\u8bcd\u5206\u5e03\u3002","9735b38d":"\u57fa\u4e8eTF-IDF\u7b97\u6cd5\u751f\u6210\u8bcd\u4e91\n"}}