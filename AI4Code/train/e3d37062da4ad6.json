{"cell_type":{"b21e0000":"code","c3c89da7":"code","9ed3c830":"code","57895a11":"code","3e82edb4":"code","7a1544ae":"code","cce9dcde":"code","646333e9":"code","3203c5cd":"code","172a941a":"code","5b7a51ae":"code","d0623fab":"code","6d43bd17":"code","f9877a41":"code","845602a8":"code","ce4a565f":"code","2994713b":"code","ebf96541":"code","ee221869":"code","c443d485":"code","edd9b69c":"code","4b27a524":"code","3678e41e":"code","d27b405d":"code","e433cc0b":"code","51b48a06":"code","753c1130":"code","f6191143":"code","71409cd4":"code","7dc549ed":"code","5dbaede3":"code","560dc87a":"code","9e9d692e":"code","f91d94e5":"code","9c957a4d":"code","96ce8eff":"code","b2d8c4f8":"code","e32adde8":"code","f66f65da":"code","dc491b07":"code","fcee39a7":"code","a5682794":"code","edee5608":"code","d55a4204":"code","7b3ec55d":"code","99e20e64":"code","3305d1b2":"code","a48daac5":"code","5e624a1e":"code","b2fe0cf9":"code","ca89d67b":"code","776231e4":"code","a4a42f88":"code","fc314458":"code","72dd9e0c":"code","2854442b":"markdown"},"source":{"b21e0000":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c3c89da7":"train=pd.read_csv(r'\/kaggle\/input\/bike-sharing-demand\/train.csv')\ntest=pd.read_csv(r'\/kaggle\/input\/bike-sharing-demand\/test.csv')\nsub=pd.read_csv(r'\/kaggle\/input\/bike-sharing-demand\/sampleSubmission.csv')","9ed3c830":"sub.head()","57895a11":"test.head()","3e82edb4":"train.head()","7a1544ae":"dt = test[\"datetime\"]","cce9dcde":"train['datetime'] = pd.to_datetime(train['datetime'])\ntrain['Hour'] = train['datetime'].apply(lambda x:x.hour)\ntrain['Month'] = train['datetime'].apply(lambda x:x.month)\ntrain['Day of Week'] = train['datetime'].apply(lambda x:x.dayofweek)\ntrain['year'] = [t.year for t in pd.DatetimeIndex(train.datetime)]\ntrain['year'] = train['year'].map({2011:0, 2012:1})","646333e9":"test['datetime'] = pd.to_datetime(test['datetime'])\ntest['Hour'] = test['datetime'].apply(lambda x:x.hour)\ntest['Month'] = test['datetime'].apply(lambda x:x.month)\ntest['Day of Week'] = test['datetime'].apply(lambda x:x.dayofweek)\ntest['year'] = [t.year for t in pd.DatetimeIndex(test.datetime)]\ntest['year'] = test['year'].map({2011:0, 2012:1})","3203c5cd":"train.head()","172a941a":"test.head()","5b7a51ae":"train=train.drop('datetime',axis=1)","d0623fab":"train.head()","6d43bd17":"sns.countplot(x=\"year\", data=train)\nplt.show()","f9877a41":"train[\"year\"]=train['year'].replace(0,2011)\ntrain[\"year\"]=train['year'].replace(1,2012)","845602a8":"sns.countplot(x=\"year\", data=train)\nplt.show()","ce4a565f":"sns.barplot(x='Month',y='count',data=train)","2994713b":"sns.barplot(x='Hour',y='count',data=train)","ebf96541":"sns.barplot(x='Day of Week',y='count',data=train)","ee221869":"plt.figure(figsize=(15,15))\nsns.heatmap(train.corr(),annot=True)","c443d485":"sns.scatterplot(x=\"temp\", y=\"atemp\", data=train, hue=\"count\")\nplt.show()","edd9b69c":"sns.scatterplot(x=\"temp\", y=\"count\", data=train)\nplt.show()","4b27a524":"new_df=train.copy()\nnew_df.temp.describe()\nnew_df['temp_bin']=np.floor(new_df['temp'])\/\/5\nnew_df['temp_bin'].unique()\n# now we can visualize as follows\nsns.factorplot(x=\"temp_bin\",y=\"count\",data=new_df,kind='bar')","3678e41e":"train.head()","d27b405d":" # seperating season as per values. this is bcoz this will enhance features.\nseason=pd.get_dummies(train['season'],prefix='season')\ntrain=pd.concat([train,season],axis=1)\ntrain.head()","e433cc0b":" # seperating season as per values. this is bcoz this will enhance features.\nweather=pd.get_dummies(train['weather'],prefix='weather')\ntrain=pd.concat([train,weather],axis=1)\ntrain.head()","51b48a06":"train.head()","753c1130":"train.drop(['casual','registered'],inplace=True,axis=1)\ntrain.head()","f6191143":"train.drop(['season','weather'],inplace=True,axis=1)","71409cd4":"\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\n\n#model selection\nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score","7dc549ed":"x_train,x_test,y_train,y_test=train_test_split(train.drop('count',axis=1),train['count'],test_size=0.25,random_state=42)","5dbaede3":"train.head()","560dc87a":"train.shape","9e9d692e":"test.head()","f91d94e5":"from sklearn.ensemble import RandomForestRegressor \n  \n # create regressor object \nregressor = RandomForestRegressor(n_estimators = 100, random_state = 0) \n  \n# fit the regressor with x and y data \nregressor.fit(x_train,y_train)  ","9c957a4d":"y_pred=regressor.predict(x_test)","96ce8eff":"y_pred","b2d8c4f8":"r2=metrics.r2_score(y_test,y_pred)","e32adde8":"print(r2)","f66f65da":"params = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}","dc491b07":"from sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor(**params)\nreg.fit(x_train, y_train)\n\nmse =  reg.predict(x_test)\nprint(mse)","fcee39a7":"test.head()","a5682794":"test=test.drop('datetime',axis=1)","edee5608":"test.head()","d55a4204":"season=pd.get_dummies(test['season'],prefix='season')\ntest=pd.concat([test,season],axis=1)\n\n # seperating season as per values. this is bcoz this will enhance features.\nweather=pd.get_dummies(test['weather'],prefix='weather')\ntest=pd.concat([test,weather],axis=1)\ntrain.head()","7b3ec55d":"test.drop(['season','weather'],inplace=True,axis=1)\ntest.head()","99e20e64":"test.shape","3305d1b2":"X_test1=test.iloc[:,:].values\nX_test1.shape","a48daac5":"pred=regressor.predict(X_test1)","5e624a1e":"pred=pred.reshape(-1,1)","b2fe0cf9":"pred","ca89d67b":"pred = pd.DataFrame(pred, columns=['count'])","776231e4":"df = pd.concat([dt, pred],axis=1)","a4a42f88":"df.head()","fc314458":"df['count'] = df['count'].astype('int')","72dd9e0c":"df.to_csv('submission1.csv' , index=False)","2854442b":"train[\"datetime\"] = pd.to_datetime(train[\"datetime\"])"}}