{"cell_type":{"649bd944":"code","75b489e2":"code","a19e05a2":"code","9b00279e":"code","2d36e740":"code","02af40b6":"code","d0641d79":"code","c287a824":"code","07157260":"code","b091b3b0":"code","a547f697":"code","7359388f":"code","7f0a3ac0":"code","4bf52a7d":"code","168e6c76":"code","a8101228":"code","4e72d8b7":"code","cb541558":"code","bd31aef6":"code","0f65fd7b":"code","9d17e08d":"code","fc8fe06f":"code","62aded5e":"code","12696675":"code","da5be4ae":"code","5bb2f5d8":"code","e366a10f":"code","bd2cad7c":"code","6f6920b8":"code","9fc81fb8":"code","cab6205c":"code","47ae93e9":"code","ef44064a":"code","06eabc79":"code","4fcb56b4":"code","16fb3247":"code","9de0c56e":"code","e85f73ce":"code","41879d6c":"code","a4f737c1":"code","7d13ab44":"code","f03bbc2a":"code","46dfab8e":"code","11a5b311":"code","3aa353d2":"code","4bc4c1db":"code","3c39495a":"code","86bb2be6":"code","b1c5ce9c":"code","e6df04db":"code","371b48ca":"markdown","5a83be7a":"markdown","81fdea6c":"markdown","f3f6bc10":"markdown","fdb51bd5":"markdown","540cc026":"markdown","a0f8498a":"markdown","6c6639ab":"markdown","e6bd18fe":"markdown","8129d7f1":"markdown","2fa80498":"markdown","238d5d10":"markdown","590c4ef9":"markdown","ca41f132":"markdown","34595325":"markdown","a3989b9b":"markdown","04fe22d3":"markdown","5ca9ed10":"markdown","0cef6678":"markdown","9963c250":"markdown","f9dd983c":"markdown","8b4a87a4":"markdown"},"source":{"649bd944":"\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","75b489e2":"ha =pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","a19e05a2":"ha.head()","9b00279e":"ha.shape","2d36e740":"ha.info()","02af40b6":"ha.isna().sum()","d0641d79":"ha.drop_duplicates(inplace=True)\nha.reset_index(drop=True, inplace=True)\nha.shape","c287a824":"ha['output'].value_counts().plot(kind='bar',grid=True,rot=0)","07157260":"labels= ha['sex'].astype('category').cat.categories.tolist()\ncounts= ha['sex'].value_counts()\nsizes= [counts[var_cat] for var_cat in labels]\nfigx1,ax1 = plt.subplots()\nax1.pie(sizes,labels=labels,autopct='%1.1f%%',shadow=True)\n#autopct helps in showing the percentage on the pie chart\nax1.axis('equal')\nplt.show()","b091b3b0":"ha.boxplot('age','sex',rot = 0,figsize=(5,6),grid=True)","a547f697":"fig, ax = plt.subplots(2,3, figsize=(20,18))\nsns.countplot(x='fbs', data=ha, palette='magma', ax=ax[0][0]).set(title='Fasting Blood Sugar')\nsns.countplot(x='exng', data=ha, palette='magma', ax=ax[0][1]).set(title='Exercise Induced Angina')\nsns.countplot(x='restecg', data=ha, palette='magma', ax=ax[1][0]).set(title='Rest ECG')\nsns.countplot(x='cp', data=ha, palette='magma', ax=ax[0][2]).set(title='Chest Pain Type')\nsns.countplot(x='caa', data=ha, palette='magma', ax=ax[1][1]).set(title='Number of major vessels')\nsns.countplot(x='thall', data=ha, palette='magma', ax=ax[1][2]).set(title='Thallium Stress Test')","7359388f":"fig, ax = plt.subplots(2,2, figsize=(20,18))\nsns.histplot(x=ha[\"age\"], ax=ax[0][0], color=\"red\", kde=True).set(title='Age')\nsns.histplot(x=ha[\"trtbps\"], ax=ax[0][1], color=\"blue\", kde=True).set(title='Resting Blood Pressure')\nsns.histplot(x=ha[\"chol\"], ax=ax[1][0], color=\"orange\", kde=True).set(title='Cholestrol Levels')\nsns.histplot(x=ha[\"thalachh\"], ax=ax[1][1], color=\"green\", kde=True).set(title='Maximum Heart Rate Achieved')","7f0a3ac0":"def bi_ana(df,feature,target):\n    sns.set(rc={'figure.figsize':(6,6)})\n    \n    ax=sns.countplot(x=feature,hue=target,data=df)\n    \n    for n in ax.patches:\n        patch_height=n.get_height()\n        if np.isnan(patch_height):\n            patch_height=0\n        ax.annotate('{}'.format(int(patch_height)), (n.get_x()+0.05, patch_height+10))\n    plt.show()","4bf52a7d":"bi_ana(ha,\"sex\",'output')\nbi_ana(ha,\"cp\",'output')\nbi_ana(ha,\"fbs\",'output')\nbi_ana(ha,\"restecg\",'output')\nbi_ana(ha,\"exng\",'output')\nbi_ana(ha,\"slp\",'output')\nbi_ana(ha,\"caa\",'output')\nbi_ana(ha,\"thall\",'output')","168e6c76":"\nf, ax = plt.subplots(figsize=(15, 8))\ncorr = ha.corr()\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","a8101228":"h_num_cols =['age', 'trtbps', 'chol', 'thalach', 'oldpeak']\nh_cat_cols= ['sex', 'cp', 'caa', 'fbs', 'restecg', 'exng', 'slp', 'thall']\n","4e72d8b7":"#importing the model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\nfrom sklearn.metrics import accuracy_score","cb541558":"#intializing the model \nLR= LogisticRegression(max_iter=1000)","bd31aef6":"#Preparing the data\nx = ha.drop('output', axis=1)\ny = ha['output']\n","0f65fd7b":"x_train,x_test,y_train,y_test=train_test_split(x,y, test_size=0.2, random_state=42)","9d17e08d":"print(\"shape of trainig set:\",x_train.shape)\nprint(\"shape of testing set:\",x_test.shape)","fc8fe06f":"#fitting the model \nLR.fit(x_train,y_train)","62aded5e":"#predicting \nypred=LR.predict(x_test)","12696675":"print(classification_report(y_test, ypred))","da5be4ae":"#feature importance\nimportance = list(zip(ha.columns ,LR.coef_.ravel()))\nimportance = list(sorted(importance, key=lambda x: x[1], reverse=True))\nprint(importance[0:2])","5bb2f5d8":"LR_acc_score= accuracy_score(y_test,ypred )\nprint(\"Accuracy of LogisticRegression:\",LR_acc_score*100)","e366a10f":"# plot feature importance top 5\ntop_columns, top_score = zip(*importance[:5])\nplt.xticks(rotation=45)\nplt.bar(top_columns, top_score)\nplt.show()","bd2cad7c":"#importing model\nfrom sklearn.ensemble import RandomForestClassifier\n","6f6920b8":"#intializing the model\nrfc= RandomForestClassifier(n_estimators=100)","9fc81fb8":"#fitting the model\nrfc.fit(x_train, y_train)","cab6205c":"# predicting\ny_pred=rfc.predict(x_test)","47ae93e9":"print(classification_report(y_test, y_pred))","ef44064a":"rfc_acc_score = accuracy_score(y_test, y_pred)\nprint(\"Accuracy of Random Forests Model is: \", rfc_acc_score)","06eabc79":"#feature importnace\nimp_feature = pd.DataFrame({'Feature': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'], 'Importance': rfc.feature_importances_})\nplt.figure(figsize=(10,4))\nplt.title(\"barplot Represent feature importance \")\nplt.xlabel(\"importance \")\nplt.ylabel(\"features\")\nplt.barh(imp_feature['Feature'],imp_feature['Importance'])\nplt.show()","4fcb56b4":"from sklearn.tree import DecisionTreeClassifier","16fb3247":"dt = DecisionTreeClassifier(criterion = 'entropy',random_state=0,max_depth = 6)","9de0c56e":"print(\"Shape of training set:\", x_train.shape)\nprint(\"Shape of test set:\", x_test.shape)","e85f73ce":"dt.fit(x_train,y_train)","41879d6c":"Y_pred= dt.predict(x_test)","a4f737c1":"\nprint(classification_report(y_test, Y_pred))","7d13ab44":"dt_acc_score= accuracy_score(y_test,Y_pred )\nprint(\"Accuracy of decision tree:\",dt_acc_score*100)","f03bbc2a":"imp_feature = pd.DataFrame({'Feature': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'], 'Importance': dt.feature_importances_})\nplt.figure(figsize=(10,4))\nplt.title(\"Decision tree feature importance\")\nplt.xlabel(\"importance \")\nplt.ylabel(\"features\")\nplt.barh(imp_feature['Feature'],imp_feature['Importance'])\nplt.show()","46dfab8e":"from xgboost import XGBClassifier","11a5b311":"xgb= XGBClassifier(random_state=123 )","3aa353d2":"xgb.fit(x_train,y_train)","4bc4c1db":"y1pred=xgb.predict(x_test)","3c39495a":"\nprint(classification_report(y_test, y1pred))","86bb2be6":"xgb_acc_score= accuracy_score(y_test,y1pred )\nprint(\"Accuracy of Gradient Boost:\",xgb_acc_score*100)","b1c5ce9c":"imp_feature = pd.DataFrame({'Feature': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'], 'Importance': xgb.feature_importances_})\nplt.figure(figsize=(10,4))\nplt.title(\"feature importance o \")\nplt.xlabel(\"importance \")\nplt.ylabel(\"features\")\nplt.barh(imp_feature['Feature'],imp_feature['Importance'])\nplt.show()","e6df04db":"model=pd.DataFrame({'Model':[\"Logistic Regression\",'Random Forest','Decision Tree',\"Gradient Boost\"],\n                    'Accuracy':[LR_acc_score*100,rfc_acc_score*100,dt_acc_score*100,xgb_acc_score*100]})\nmodel","371b48ca":"**1. Logistic Regression**","5a83be7a":"**Categorical**","81fdea6c":"**Heart Attack Analysis**\n\nHeart attacks happen when the heart doesn't get enough blood, or more accurately, oxygen, because blood contains oxygen. If your heart doesn't get enough oxygen, you're more likely to have a heart attack. This is due to a blood clot, a lack of blood supply, and a lack of oxygen. Chest pain, high blood pressure, and high cholesterol levels are all signs of a heart attack.","f3f6bc10":"**3.Decision Tree**","fdb51bd5":"This shows that 68.3% of the pateints belongs to the sex which is represented by 1 , it can be male or female . ","540cc026":"**Conclusion**\n\nIf there are pateints with the following symptoms than the possibility of them getting heart attack is high and should be given immediate attention . Following are the factors to look for :\n\n1.number of major vessels - if type 0\n\n2.Chest Pain type         -  type= non-anginal pain\n\n3.Age of the patient\n\n4.maximum heart rate achieved\n\n5.Sex of the pateint - and especially the male sex as said before males are more likely to get heart attack compared to the females\n","a0f8498a":"Our target value here is the 'output' feature which helps in determing if the patient is likely to have the heart attack or not. We can perform bivariate on categorical features. ","6c6639ab":"**Output**","e6bd18fe":"**Model comparision**","8129d7f1":"**Bivariate analysis**","2fa80498":"**Using Machine learning Algorithms**","238d5d10":"*Few important features which can determine about the output*","590c4ef9":"**2. Random Forest**","ca41f132":"**insights from the above bivariate countplots**\n\n1. From the above univariate analysis, we found that than 68 percent of patients are of one gender (male or female), while the remaining patients are of the other gender (31.7 percent ). All we have to do now is figure out which one is which. For this, we can look at the Hravard studies, which demonstrate that men are more than twice as likely as women to have a heart attack.We can basically find out this by seeing which has more possibility of getting the heart attack that are more likely to be men and rest our women. By sampling using the value count above we can say that Sex =0 is female as it had less risk of heart attack and Sex=1 is male as it had more possibility of getting heart attack.  ","34595325":"**Summary**\n\nThere are 14 columns and 303 rows in the dataset. Only a few of the 14 columns are numerical variables, while the rest are categorical variables. 'age', 'trtbps', 'chol', 'thalach', 'oldpeak' are numerical columns, while'sex', 'cp', 'caa', 'fbs','restecg', 'exng','slp', 'thall' are categorical columns.Because the \u2018output' characteristic takes value 1 in the case of a higher risk of heart attack and 0 in the case of a lower risk of heart attack, this is the responsible variable.\nThere were no null values in this dataset, but it did have one duplicated value, which was eliminated.\n","a3989b9b":"**Feature importance**\n\nBy comparing the feature importance of all the models , we can say the features which are highly correlated to our target values are 'thal','ca','cp','thalach' and 'age'.","04fe22d3":"**4.Extreme Gradient Boost**","5ca9ed10":"**Univariate Analysis**","0cef6678":"random forest and gradient boost worked the best as the machine leraning models ,giving the highest accuracy.\n","9963c250":"**Multivariate analysis**\n\nCorrelation matrix","f9dd983c":"**SEX**","8b4a87a4":"**Numerical**"}}