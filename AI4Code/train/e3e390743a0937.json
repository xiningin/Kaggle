{"cell_type":{"f0053fbf":"code","d36a0340":"code","cf288047":"code","d17451de":"code","bcfac74d":"code","46c0463a":"code","7c66450a":"code","bc424c68":"code","cebc887e":"code","90de6d9e":"code","bdc84992":"code","09750abe":"code","69acb7bb":"code","a94435c8":"code","ee810865":"code","a9a3583b":"code","49c6be99":"code","a51b2649":"code","d29652f2":"code","5b9b264a":"code","f93b4539":"code","376f8dd5":"code","acb5612c":"code","ffdcc524":"code","feff2b80":"code","50c9a459":"code","95915e6e":"code","eb9e8bc6":"code","8a8cb6e3":"code","4bc11fb5":"code","4a3cdf0b":"code","6590d44c":"code","0464bb5a":"code","60b7f202":"code","d02c01cb":"code","3233cdfa":"code","ac51898a":"code","a4cb7797":"code","2d4efee3":"code","e46984ea":"code","fff9a294":"code","fb7a67d4":"code","6574cbeb":"code","8f8590d5":"code","9dedcec7":"code","9ebbf399":"code","b504ed5d":"code","2249fced":"code","951e308b":"code","a7c2cc78":"code","0e885b45":"code","c791483a":"code","dfeaef5c":"markdown","fc7e6bcc":"markdown","7f0a1ab8":"markdown","ad40c536":"markdown","70ae7f05":"markdown","731b4531":"markdown","2693bff3":"markdown","6754e80f":"markdown","71efa596":"markdown","5849a5b3":"markdown","7a180094":"markdown","626cf608":"markdown","cc2fc324":"markdown","5ede57f3":"markdown","8cb2b42e":"markdown","354a86cb":"markdown","2b476ef7":"markdown","b1f4668b":"markdown","103be56e":"markdown","c35c4c56":"markdown","79231da0":"markdown","0b10aeee":"markdown","818bd5a6":"markdown","37784a83":"markdown","a427fc91":"markdown","8f42ba56":"markdown","52adadf5":"markdown","86533d04":"markdown","e930fd46":"markdown","b92dde1b":"markdown","178a00e3":"markdown","c2d51264":"markdown","4f929a93":"markdown","d3ddb12c":"markdown","2223285f":"markdown","c92d276f":"markdown","b1d02eec":"markdown","76eef7d2":"markdown","ec0a610d":"markdown","4e8c8fc2":"markdown","0d037565":"markdown","764021e3":"markdown","1362243c":"markdown","0b751a5e":"markdown","a1abc575":"markdown","4cac5645":"markdown","0ce23145":"markdown","7e00d117":"markdown","e25d0ec0":"markdown","94bf613e":"markdown","8ada88f6":"markdown","2bb36696":"markdown","004c7b71":"markdown","de71aa1f":"markdown","f03f386f":"markdown","da7e96f6":"markdown","e8fe8055":"markdown","4875b701":"markdown","5c073248":"markdown","24df1a15":"markdown","0d1a95fd":"markdown","59ee06d0":"markdown","d65d9303":"markdown","0bc31bde":"markdown","ab0ee928":"markdown","704bd4e5":"markdown","6fbea85f":"markdown","d0c08a11":"markdown","f5363fd4":"markdown","db0b688c":"markdown","08da271c":"markdown","0c06572e":"markdown","9ac3ad0b":"markdown","780c7d1b":"markdown","fdae45c7":"markdown","fea9d6de":"markdown","0a612582":"markdown","d74c4757":"markdown"},"source":{"f0053fbf":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d36a0340":"book_dataset=pd.read_csv('..\/input\/book-recommendation-dataset\/Books.csv')\nrating_dataset=pd.read_csv('..\/input\/book-recommendation-dataset\/Ratings.csv')","cf288047":"book_dataset.shape","d17451de":"rating_dataset.shape","bcfac74d":"rating_dataset.head()","46c0463a":"rating_dataset = rating_dataset.rename(columns={'Book-Rating': 'rating','User-ID':'user_id'})","7c66450a":"book_dataset = book_dataset[:10000]\nrating_dataset=rating_dataset[:5000]","bc424c68":"# rating_dataset = rating_dataset.drop(rating_dataset[rating_dataset.rating == 0].index)","cebc887e":"rating_dataset.head()","90de6d9e":"book_dataset.head()","bdc84992":"book_dataset = book_dataset.rename(columns={'Book-Title': 'book_title','Book-Author':'book_author','Year-Of-Publication':'year_of_publication','Image-URL-S':'Image_URL_S','Image-URL-M':'Image_URL_M','Image-URL-L':'Image_URL_L'})","09750abe":"rating_dataset[rating_dataset.rating == max(rating_dataset.rating)]\nbest_booksId = rating_dataset.ISBN[rating_dataset.rating == max(rating_dataset.rating)]\nbest_booksId = list(dict.fromkeys(best_booksId))","69acb7bb":"best_books = []\nfor i in best_booksId:\n    books_name = book_dataset.book_title[book_dataset.ISBN == i]\n    best_books.append(books_name)","a94435c8":"best_books","ee810865":"len(best_books)","a9a3583b":"count = rating_dataset[\"rating\"].value_counts()\ncount.plot(kind='bar', title=\"Rating\");\n \nplt.show()","49c6be99":"count = book_dataset[\"year_of_publication\"].value_counts()\ncount.plot(kind='bar', title=\"Year of Publication\");\n \nplt.show()","a51b2649":"import seaborn as sns\nsns.pairplot(rating_dataset, diag_kind = 'kde')","d29652f2":"book_dataset = book_dataset.dropna()\nrating_dataset = rating_dataset.dropna()","5b9b264a":"rating_dataset = rating_dataset.drop_duplicates()\nbook_dataset = book_dataset.drop_duplicates()","f93b4539":"book_dataset.shape","376f8dd5":"rating_dataset.shape","acb5612c":"book_dataset.head()","ffdcc524":"book_ISBN = book_dataset['ISBN'].tolist()\n\nbook_title = book_dataset['book_title'].tolist()\n\nbook_author = book_dataset['book_author'].tolist()\n\nbook_year_of_publication = book_dataset['year_of_publication'].tolist()","feff2b80":"book = pd.DataFrame({\n    'book_ISBN': book_ISBN,\n    'book_title': book_title,\n    'book_author': book_author,\n    'book_year_of_publication': book_year_of_publication\n})\nbook","50c9a459":"from sklearn.feature_extraction.text import TfidfVectorizer\n \ntf = TfidfVectorizer()\n \ntf.fit(book['book_author']) \n \ntf.get_feature_names() ","95915e6e":"tfidf_matrix = tf.fit_transform(book['book_author']) \n \ntfidf_matrix.shape ","eb9e8bc6":"tfidf_matrix.todense()","8a8cb6e3":"pd.DataFrame(\n    tfidf_matrix.todense(), \n    columns=tf.get_feature_names(),\n    index=book.book_title\n).sample(10, axis=1,replace=True).sample(10, axis=0)","4bc11fb5":"from sklearn.metrics.pairwise import cosine_similarity\n \ncosine_sim = cosine_similarity(tfidf_matrix) \ncosine_sim","4a3cdf0b":"cosine_sim_df = pd.DataFrame(cosine_sim, index=book['book_title'], columns=book['book_title'])","6590d44c":"def author_recommendations(i, M, items, k=5):\n    ix = M.loc[:,i].to_numpy().argpartition(range(-1,-k,-1))\n    closest = M.columns[ix[-1:-(k+2):-1]]\n    closest = closest.drop(i, errors='ignore')\n    return pd.DataFrame(closest).merge(items).head(k)","0464bb5a":"books_that_have_been_read = \"The Diaries of Adam and Eve\"\nbook[book.book_title.eq(books_that_have_been_read)]","60b7f202":"recommendations = author_recommendations(books_that_have_been_read, cosine_sim_df, book[['book_title', 'book_author']])","d02c01cb":"recommendations = recommendations.drop_duplicates()","3233cdfa":"recommendations","ac51898a":"books_that_have_been_read_row = book_dataset[book_dataset.book_title == books_that_have_been_read]\nbooks_that_have_been_read_author = books_that_have_been_read_row.iloc[0][\"book_author\"]","a4cb7797":"books_with_the_same_author = book_dataset[book_dataset.book_author == books_that_have_been_read_author].shape[0]\nprint(books_with_the_same_author)","2d4efee3":"Accuracy = (recommendations.shape[0]\/books_with_the_same_author)*100\nprint(\"Accuracy of the model is {}%\".format(Accuracy))","e46984ea":"user_ids = rating_dataset['user_id'].unique().tolist()\n\nuser_to_user_encoded = {x: i for i, x in enumerate(user_ids)}\n\nuser_encoded_to_user = {i: x for i, x in enumerate(user_ids)}","fff9a294":"book_ids = rating_dataset['ISBN'].unique().tolist()\nbook_to_book_encoded = {x: i for i, x in enumerate(book_ids)}\nbook_encoded_to_book = {i: x for i, x in enumerate(book_ids)}\n\nrating_dataset['user'] = rating_dataset['user_id'].map(user_to_user_encoded)\nrating_dataset['book'] = rating_dataset['ISBN'].map(book_to_book_encoded)","fb7a67d4":"num_users = len(user_encoded_to_user)\nprint(num_users)\nnum_book = len(book_encoded_to_book)\nprint(num_book)\nrating_dataset['rating'] = rating_dataset['rating'].values.astype(np.float32)\n\nmin_rating = min(rating_dataset['rating'])\nmax_rating = max(rating_dataset['rating'])\n \nprint('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(\n    num_users, num_book, min_rating, max_rating\n))","6574cbeb":"rating_dataset = rating_dataset.sample(frac=1, random_state=42)\nrating_dataset","8f8590d5":"x = rating_dataset[['user', 'book']].values\n \ny = rating_dataset['rating'].apply(lambda x: (x - min_rating) \/ (max_rating - min_rating)).values\n \ntrain_indices = int(0.70 * rating_dataset.shape[0])\nx_train, x_val, y_train, y_val = (\n    x[:train_indices],\n    x[train_indices:],\n    y[:train_indices],\n    y[train_indices:]\n)\n \nprint(x, y)","9dedcec7":"from tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf","9ebbf399":"class RecommenderNet(tf.keras.Model):\n \n  def __init__(self, num_users, num_resto, embedding_size, **kwargs):\n    super(RecommenderNet, self).__init__(**kwargs)\n    self.num_users = num_users\n    self.num_resto = num_resto\n    self.embedding_size = embedding_size\n    self.user_embedding = layers.Embedding(\n        num_users,\n        embedding_size,\n        embeddings_initializer = 'he_normal',\n        embeddings_regularizer = keras.regularizers.l2(1e-6)\n    )\n    self.user_bias = layers.Embedding(num_users, 1)\n    self.resto_embedding = layers.Embedding( \n        num_resto,\n        embedding_size,\n        embeddings_initializer = 'he_normal',\n        embeddings_regularizer = keras.regularizers.l2(1e-6)\n    )\n    self.resto_bias = layers.Embedding(num_resto, 1) \n \n  def call(self, inputs):\n    user_vector = self.user_embedding(inputs[:,0])\n    user_bias = self.user_bias(inputs[:, 0])\n    resto_vector = self.resto_embedding(inputs[:, 1])\n    resto_bias = self.resto_bias(inputs[:, 1]) \n \n    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2) \n \n    x = dot_user_resto + user_bias + resto_bias\n    \n    return tf.nn.sigmoid(x) ","b504ed5d":"model = RecommenderNet(num_users, num_book, 50)\n\nmodel.compile(\n    loss = tf.keras.losses.BinaryCrossentropy(),\n    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n)","2249fced":"history = model.fit(\n    x = x_train,\n    y = y_train,\n    batch_size = 5,\n    epochs = 20,\n    validation_data = (x_val, y_val)\n)","951e308b":"plt.plot(history.history['root_mean_squared_error'])\nplt.plot(history.history['val_root_mean_squared_error'])\nplt.title('model_metrics')\nplt.ylabel('root_mean_squared_error')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","a7c2cc78":"book_dataset =  book\nrating_dataset = rating_dataset","0e885b45":"user_id = rating_dataset.user_id.sample(1).iloc[0]\nbooks_have_been_read_by_user = rating_dataset[rating_dataset.user_id == user_id]\n \nbooks_have_not_been_read_by_user = book_dataset[book_dataset['book_ISBN'].isin(books_have_been_read_by_user.ISBN.values)]['book_ISBN'] \nbooks_have_not_been_read_by_user = list(\n    set(books_have_not_been_read_by_user)\n    .intersection(set(book_to_book_encoded.keys()))\n)\n \nbooks_have_not_been_read_by_user = [[book_to_book_encoded.get(x)] for x in books_have_not_been_read_by_user]\nuser_encoder = user_to_user_encoded.get(user_id)\nuser_book_array = np.hstack(\n    ([[user_encoder]] * len(books_have_not_been_read_by_user), books_have_not_been_read_by_user)\n)","c791483a":"ratings = model.predict(user_book_array).flatten()\n \ntop_ratings_indices = ratings.argsort()[-10:][::-1]\nrecommended_book_ids = [\n    book_encoded_to_book.get(books_have_not_been_read_by_user[x][0]) for x in top_ratings_indices\n]\n \ntop_books_recommended = (\n    books_have_been_read_by_user.sort_values(\n        by = 'rating',\n        ascending=False\n    )\n    .head(5)\n    .ISBN.values\n)\n \nbooks_row = book_dataset[book_dataset['book_ISBN'].isin(top_books_recommended)]\nfor row in books_row.itertuples():\n    print(row.book_title, ':', row.book_author)\n \nprint('----' * 8)\nprint('Top 10 Book Recommendation for user: {}'.format(user_id))\nprint('----' * 8)\n \nrecommended_books = book_dataset[book_dataset['book_ISBN'].isin(recommended_book_ids)]\nfor row in recommended_books.itertuples():\n    print(row.book_title, ':', row.book_author)","dfeaef5c":"Memberi nama header baru pada kolom Book-Rating dan User-ID pada rating_dataset","fc7e6bcc":"Melihat pentingnya dampak buku bagi kehidupan kita, kita perlu banyak membaca buku. Ketika kita membaca buku, kita pasti memiliki ketertarikan kepada satu atau beberapa bidang. Dikarenakan banyaknya buku yang telah dan akan terbit, kita membutuhkan sistem rekomendasi yang akan menyaring buku - buku sesuai dengan selera dan ketertarikan kita. Dengan adanya sistem rekomendasi ini, kita tidak perlu lama - lama dalam mencari buku sesuai ketertarikan kita.\n\nPada latihan kali ini kita akan menggunakan kedua metode yaitu content dan collaborative based filter.\n - Pada **Content Based Flter**, kita akan menggunakan penulis buku menjadi pusat sebagai pusat dari sistem rekomendasi\n - Pada **Collaborative Based Flter**, kita akan menggunakan penilaian dari berbagai pengguna sebagai pusat dari sistem rekomendasi","7f0a1ab8":"## Importing Dataset","ad40c536":"Dataframe di bawah ini digunakan untuk melihat matriks dari judul buku dengan penulis - penulis buku","70ae7f05":"Berikut adalah sistem rekomendasi dari content dan collaborative based system. Keduanya unik dan memiliki kelebihan dan kekurangannya masing - masing.","731b4531":"___\n# Importing Libraries and Dataset","2693bff3":"Pada cell code di bawah ini kita akan mengambil kata - kata penting dalam kolom book_author","6754e80f":"Meneliti ukuran dari dataframe rating","71efa596":"Pada cell code di bawah ini, kita akan mengambil user_id secara acak dari rating_dataset. Dari user_id ini kita perlu mengetahui buku - buku apa saja yang pernah dibaca dan yang belum pernah dibaca, sehingga kita hanya dapat merekomendasikan buku - buku yang belum dibaca.","5849a5b3":"Berdasarkan salah satu artikel dari Universitas Hasanuddin [tautan](https:\/\/journal.unhas.ac.id\/index.php\/jupiter\/article\/view\/1672), membaca buku merupakan hal yang penting untuk dilakukan. Orang - orang yang memilih untuk sering membaca buku memiliki wawasan yang luas. Lewat membaca, kita juga dapat mengetahui, mengenal banyak hal yang sebelumnya belum dikenal dan kita pelajari dan pahami lewat membaca buku.","7a180094":"Kita akan memakai metrik evaluasi akurasi di mana akurasi adalah:\n\nJumlah buku yang direkomendasikan sesuai penulis \/ Jumlah buku yang ditulis oleh penulis yang sama","626cf608":"Model yang akan kita pakai dalam sistem rekomendasi berbasis pendapat pengguna adalah RecommenderNet","cc2fc324":"Kelebihan pada Collaborative Based Filtering bila dibandingkan dengan Content Based Filtering adalah pengguna dapat mengeksplorasi item atau konten di luar preferensi pengguna. Pengguna pun juga dapat mendapat rekomendasi sesuai dengan kecenderungan publik yang dianalisa lewat penilaian pengguna - pengguna lainnya.\n\nKekurangan pada Collaborative Based Filtering adalah pengguna kurang mendapatkan rekomendasi sesuai preferensi pribadi. Konten - konten yang diberikan oleh sistem rekomendasi lebih banyak berasal dari preferensi publik dan bukan preferensi pribadi.\n\nPada Collaborative Based Filtering, saya menggunakan penilaian dari pengguna - pengguna untuk mendapatkan rekomendasi buku - buku.","5ede57f3":"## Visualisasi Metrik","8cb2b42e":"Selanjutnya kita akan melatih model dengan batch_size 5 dan 20 epochs","354a86cb":"Pada code cell di bawah ini, kita akan mencari rekomendasi dari buku yang sudah dibaca, dalam kasus ini, buku yang sudah dibaca adalah \"The Diaries of Adam and Eve\" yang ditulis oleh Mark Twain dan terbit pada tahun 1998","2b476ef7":"Memberi nama header baru pada kolom Book-Title, Book-Author, Image-URL-S, Image-URL-S,Image-URL-M,Image-URL-L pada book_dataset","b1f4668b":"Untuk selanjutnya, kita perlu mengubah dataframe dari buku menjadi sebuah list","103be56e":"Dalam sistem rekomendasi, kita perlu mencari cara supaya item yang kita rekomendasikan tidak terlalu jauh dari data pusat, oleh karena itu kita butuh derajat kesamaan pada item, dalam proyek ini, buku dengan derajat kesamaan antar buku dengan cosine similarity","c35c4c56":"Pada code di bawah ini kita akan membuat dataframe cosine_sim_df dengan baris dan kolomnya adalah judul dari buku","79231da0":"Sebelum kita membagi dataset menjadi data latih dan data validasi, kita terlebih dahulu harus mengacak dataset","0b10aeee":"Meneliti 5 data teratas dari dataset buku","818bd5a6":"Pada cell code di bawah ini, saya membagi dataset yang ada menjadi 70% untuk latihan dan 30% untuk validasi","37784a83":"Content Based Filtering adalah sistem rekomendasi yang merekomendasikan item sesuai dengan item yang disukai oleh pengguna di masa lampau.\n\nContent Based mempelajari profil dan perilaku dari pengguna yang kemudian dari informasi tersebut dianalisa dan diproses sehingga menghasilkan sistem rekomendasi yang baik. Semakin banyak informasi yang diberikan ke sistem ini, maka sistem rekomendasi berbasis content based akan memiliki akurasi yang lebih baik.","a427fc91":"## Evaluation","8f42ba56":"___\n# Data Preprocessing","52adadf5":"Meneliti 5 data teratas dari dataframe rating","86533d04":"Setelah kita membuat list, kita perlu membuat dictionary yang digunakan untuk memnentukan pasangan key-value pada book_ISBN, book_title, book_author, dan book_year_of_publication.","e930fd46":"Meneliti ukuran dari dataset book ","b92dde1b":"Selanjutnya kita melakukan proses compile pada model dengan binary crossentropy sebagai loss function, adam sebagai optimizer, dan RMSE sebagai metrik dari model","178a00e3":"## Multivariate Analysis","c2d51264":"Meneliti jumlah buku - buku bagus","4f929a93":"Berikut adalah 5 buku rekomendasi yang ditulis oleh Mark Twain","d3ddb12c":"Variabel books_that_have_been_read_row di bawah ini akan mengambil satu row dari buku yang pernah dibaca sebelumnya, dan variabel books_that_have_been_read_author adalah penulis buku dari buku yang pernah dibaca sebelumnya","2223285f":"Collaborative Based Filtering adalah sistem rekomendasi berdasarkan pendapat suatu komunitas.","c92d276f":"___\n# Collaborative Filtered Recommendation System","b1d02eec":"Meneliti deskripsi dari dataset rating","76eef7d2":"Meneliti id buku - buku apa saja yang di-rate 10 oleh pengguna","ec0a610d":"Meneliti 5 data teratas dari dataset rating","4e8c8fc2":"Meneliti distribusi rating dari rating dataframe dengan Barplot","0d037565":"## Model Development","764021e3":"Melihat 5 row pertama dari dataset book","1362243c":"Melihat pairplot yang ada pada rating dataset","0b751a5e":"Pada cell code di bawah ini, saya melakukan drop atau pembuangan pada row - row yang merupakan duplikasi dari row - row yang lain, sehingga dataset kita tetap memiliki integritas dan tidak berulang","a1abc575":"## Data Preparation","4cac5645":"Sebelumnya, kita perlu mendefinisikan ulang book_datase dan rating_dataset","0ce23145":"Pada cell code di bawah ini, saya akan meyandikan user_id menjadi integer","7e00d117":"<img src= \"https:\/\/edgecappartners.com\/wp-content\/uploads\/2018\/09\/boook-e1536947008937.jpg\" alt =\"Movie\" style='width: 400px;'>","e25d0ec0":"Pada content Based Filtering, kita akan menggunakan TF-IDF Vectorizer untuk membangun sistem rekomendasi berdasarkan penulis buku.\n\nTF-IDF yang merupakan kepanjangan dari Term Frequency-Inverse Document Frequency memiliki fungsi untuk mengukur seberapa pentingnya suatu kata terhadap kata - kata lain dalam dokumen.\nKita umumnya menghitung skor untuk setiap kata untuk menandakan pentingnya dalam dokumen dan corpus. Metode sering digunakan dalam Information Retrieval dan Text Mining.","94bf613e":"## Membagi Dataset","8ada88f6":"## Modeling","2bb36696":"## Mendapatkan Rekomendasi","004c7b71":"Di bawah ini adalah fungsi untuk mendapatkan rekomendasi berbasis penulis buku dengan k sebagai jumlah rekomendasi yang diingkan, dalam fungsi ini, kita akan mendapatkan 5 rekomendasi","de71aa1f":"Berikut adalah hasil latihan dari data yang ada, evaluasi metrik yang digunakan adalah RMSE","f03f386f":"Melihat dari dataframe dari rating dan books terbilang banyak, di sini saya hanya mengambil 10000 row dari book dataset dan 5000 row untuk rating dataset","da7e96f6":"\n## Data Preparation","e8fe8055":"Pada beberapa kasus, rekomendasi akan memberikan rekomendasi yang terduplikat, sehingga perlu dibuang rekomendasi yang terduplikat","4875b701":"Variabel books_with_the_same_author menunjukkan jumlah buku yang sudah ditulis oleh penulis buku yang berasal dari buku yang pernah dibaca sebelumnya","5c073248":"Pada notebook ini saya melakukan import pada beberapa libraries, seperti pandas, numpy, tenserflow, dll.","24df1a15":"Di code bawah ini saya men-drop seluruh row yang memiliki nilai NaN","0d1a95fd":".todense(), atribut ini dipakai untuk mengubah tfidf_matrix yang awalnya vektor menjadi matriks","59ee06d0":"___\n# Content Filtered Recommendation System","d65d9303":"## Univariate Data Analys","0bc31bde":"Pada cell code di bawah ini, kita akan mendapatkan 5 rekomendasi dari buku \"The Diaries of Adam and Eve\"","ab0ee928":"# Collaborative & Content Filtered Book Recommendation\nName: Farel Arden","704bd4e5":"Ternyata buku yang telah ditulis oleh Mark Twain berjumlah 16 buku, oleh karena itu","6fbea85f":"Atribut argpartition berguna untuk mengambil sejumlah nilai k, dalam fungsi ini 5 tertinggi dari tingkat kesamaan yang berasal dari dataframe cosine_sim_df.","d0c08a11":"Cell code di bawah ini dapat dijadikan pertimbangan dalam memproses data, dikarenakan banyak data rating yang bernilai 0, maka ada 2 pilihan, yaitu:\n- Membuang semua row yang memiliki nilai 0 pada kolom rating pada rating dataset\n- Tetap menggunakan nilai 0 karena 0 bukanlah nilai NaN\n\nPada notebook kali ini, saya memilih pilihan kedua di mana nilai 0 bukanlah nilai NaN dan tidak membuang row dengan nilai rating 0","f5363fd4":"Pada code cell terakhir di bawah ini, kita akan merekomendasikan 10 buku dari user","db0b688c":"Meneliti deskripsi dari dataset book","08da271c":"## Importing Libraries","0c06572e":"Pada notebook ini, kita hanya akan menggunakan dataframe book dan rating untuk content dan collaborative filtered recommendation kita","9ac3ad0b":"Pada tfidf_matrix terdapat 10000 ukuran data dan 5575 nama penulis buku\n","780c7d1b":"Meneliti distribusi tahun terbitnya buku dari book dataframe dengan Barplot","fdae45c7":"Terakhir, kita akan cek jumlah pengguna dan jumlah buku, serta mengubah tipe data rating menjadi float","fea9d6de":"Pada cell code di bawah ini, saya akan meyandikan book_id menjadi integer","0a612582":"Kemudian kita akan lakukan fit dan transformasi ke dalam matriks, pada code di bawah ini, matriks tersebut adalah tfidf_matrix","d74c4757":"Meneliti buku - buku apa saja yang di-rate 10 oleh pengguna"}}