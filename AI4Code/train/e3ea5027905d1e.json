{"cell_type":{"45a52cae":"code","03d3d93c":"code","55d24f5f":"code","8e37c190":"code","2bd1af3e":"code","355a4363":"code","c81ac454":"code","2d448324":"code","32d6d660":"code","d7eae8d8":"code","91264fe3":"code","d4b3798c":"code","4c346f49":"code","0d4f6c4c":"code","9c445ce9":"code","85c0e1bc":"code","b4c39816":"code","f39ee06c":"code","bae4e04e":"code","ac6be0c7":"code","04b3425c":"code","82cada84":"code","67f6f34f":"code","eaa3f5eb":"code","949df206":"code","ee66efa5":"code","53cf4348":"code","c7f700e7":"code","4d144ce0":"code","1addd066":"code","7c37df70":"code","fa272e21":"code","de2d7e82":"code","14ce10d5":"code","4b9f437f":"code","c2aebcd0":"code","4b4d2f8e":"code","7eecddce":"code","5e07c305":"code","2a9446a3":"code","bb96363e":"code","04b6b65a":"code","60519b82":"code","3d1c637e":"code","a4206994":"code","1b8e059c":"code","a8dc3a6d":"code","c5f750d7":"code","a661d916":"code","7633f727":"code","1a5b57f6":"code","2a7fb2c9":"code","56ab3d94":"markdown","ed33da19":"markdown","ebd83bf6":"markdown","d595f4cf":"markdown","f4db96a9":"markdown","5840405d":"markdown","766962fe":"markdown","6f47a258":"markdown","2bda05ab":"markdown"},"source":{"45a52cae":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","03d3d93c":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ncombine = [train_df, test_df]","55d24f5f":"print(train_df.columns.values)","8e37c190":"# preview the data\ntrain_df.head()","2bd1af3e":"train_df.tail()","355a4363":"train_df.info()\nprint('_'*40)\ntest_df.info()\n","c81ac454":"train_df.isnull().sum()","2d448324":"print('_'*40)\ntest_df.isnull().sum()","32d6d660":"train_df.describe()","d7eae8d8":"train_df.describe(include=['O'])","91264fe3":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived',\n                                                                                        ascending=False)","d4b3798c":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived',\n                                                                                  ascending=False)","4c346f49":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived',\n                                                                                      ascending=False)","0d4f6c4c":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', \n                                                                                      ascending=False)","9c445ce9":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","85c0e1bc":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","b4c39816":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","f39ee06c":"train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\nprint(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","bae4e04e":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","ac6be0c7":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","04b3425c":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()","82cada84":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name', 'PassengerId'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","67f6f34f":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","eaa3f5eb":"guess_ages = np.zeros((2,3))\nguess_ages","949df206":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n            age_guess = guess_df.median()\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","ee66efa5":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","53cf4348":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\ntrain_df.head()","c7f700e7":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","4d144ce0":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","1addd066":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","7c37df70":"train_df = train_df.drop(['Parch', 'SibSp'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","fa272e21":"freq_port = train_df.Embarked.dropna().mode()[0]\nprint(freq_port)","de2d7e82":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","14ce10d5":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","4b9f437f":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)","c2aebcd0":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","4b4d2f8e":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","7eecddce":"test_df.head(10)","5e07c305":"X_train = train_df.drop(\"Survived\", axis=1)\ny_train = train_df[\"Survived\"]\nprint(\"X_train.shape\" ,X_train.shape)\nprint(\"y_train.shape\" ,y_train.shape)\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=111)","2a9446a3":"print(\"X_train.shape\" ,X_train.shape)\nprint(\"y_train.shape\" ,y_train.shape)\nprint(\"X_test.shape\" ,X_test.shape)\nprint(\"y_test.shape\" ,y_test.shape)","bb96363e":"# Logistic Regression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nY_pred_lr = logreg.predict(X_test)\nScore_lr = accuracy_score(y_test,Y_pred_lr)\nprint(Score_lr)","04b6b65a":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\nY_pred_svc = svc.predict(X_test)\nScore_svc = accuracy_score(y_test,Y_pred_svc)\nprint(Score_svc)","60519b82":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)\nY_pred_knn = knn.predict(X_test)\nScore_knn = accuracy_score(y_test,Y_pred_knn)\nprint(Score_knn)","3d1c637e":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\nY_pred_gnb = gaussian.predict(X_test)\nScore_gnb = accuracy_score(y_test,Y_pred_gnb)\nprint(Score_gnb)","a4206994":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, y_train)\nY_pred_per = perceptron.predict(X_test)\nScore_per = accuracy_score(y_test,Y_pred_per)\nprint(Score_per)","1b8e059c":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, y_train)\nY_pred_lsvc = linear_svc.predict(X_test)\nScore_lsvc = accuracy_score(y_test,Y_pred_lsvc)\nprint(Score_lsvc)","a8dc3a6d":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nY_pred_sgd = sgd.predict(X_test)\nScore_sgd = accuracy_score(y_test,Y_pred_sgd)\nprint(Score_sgd)","c5f750d7":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred_dtr = decision_tree.predict(X_test)\nScore_dtr = accuracy_score(y_test,Y_pred_dtr)\nprint(Score_dtr)","a661d916":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_pred_rf = random_forest.predict(X_test)\nScore_rf = accuracy_score(y_test,Y_pred_rf)\nprint(Score_rf)","7633f727":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [Score_svc, Score_knn, Score_lr, \n              Score_rf, Score_gnb, Score_per, \n              Score_sgd, Score_lsvc, Score_dtr]})\nmodels.sort_values(by='Score', ascending=False)","1a5b57f6":"Y_pred = linear_svc.predict(test_df)","2a7fb2c9":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = Y_pred\nsubmission.to_csv('submission.csv', index=False)","56ab3d94":"# 5-Cleaning Data","ed33da19":"# 2-Read In and Explore the Data","ebd83bf6":"# **# Titanic Predictions\u00b6******\n**(This is a good and simple code for you)\n\n**Please consider upvoting if this is useful to you**\n\n**Contents :****\n\n* 1-Import Necessary Libraries\n\n* 2-Read In and Explore the Data\n\n* 3-Data Analysis\n\n* 4-Data Visualization\n\n* 5-Cleaning Data\n\n* 6-Train Test Split\n\n* 7-Building a Logistic Regression model\n\n* 8-Evaluation","d595f4cf":"# 6-Train Test Split","f4db96a9":"# 7-Building a models","5840405d":"# 3-Data Analysis","766962fe":"# 4-Data Visualization","6f47a258":"# 1-Import Necessary Libraries","2bda05ab":"# 8-Evaluation"}}