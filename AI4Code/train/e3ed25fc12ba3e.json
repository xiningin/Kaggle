{"cell_type":{"484bae54":"code","557dfcf3":"code","913799ab":"code","d7ff92d5":"code","baf176a8":"code","26c09b40":"code","a32a9998":"code","5d929483":"code","2d92d617":"markdown","e7e1fdeb":"markdown","f777963e":"markdown","10c0a2a1":"markdown"},"source":{"484bae54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","557dfcf3":"from sklearn.model_selection import train_test_split\n\n#load the train and test data\ntrain_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\ntest_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')\n\n#select the target column\n#train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = train_data.SalePrice\nX = train_data.drop('SalePrice',axis=1)\n\n#split the train data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n\n#numerical columns\nnumerical_cols = [col for col in X_train_full.columns if X_train_full[col].dtype in ['int64', 'float64']]\n\n#categorical columns\ncateg_cols = [col for col in X_train_full.columns if X_train_full[col].nunique() < 10 and \n              X_train_full[col].dtype == 'object']\n\nmy_cols = numerical_cols + categ_cols\n\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = test_data[my_cols].copy()","913799ab":"#X_train.shape","d7ff92d5":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n#preprocessing numerical data\n\nnumerical_transformer = SimpleImputer(strategy = 'mean')\n\n#preprocessing categorical data\n\ncateg_transformer = Pipeline(steps = [('imputer' , SimpleImputer(strategy = 'constant')) , \n                                      ('onehot' , OneHotEncoder(handle_unknown='ignore'))\n                                     ])\n\n\n#combine both preprocessing of both numerical and categorical\npreprocessor = ColumnTransformer( \n                   transformers = [('num', numerical_transformer , numerical_cols),\n                                   ('cat',categ_transformer, categ_cols )\n                                  ])\n\n# define the model\n\nmodel = RandomForestRegressor(n_estimators = 550 , random_state = 0)\n\n#bundle preprocessor and model in pipeline\n\nmlc = Pipeline(\n    steps = [('preprocessor', preprocessor), \n             ('model', model)\n            ])\n\n\n#fit the model\n\nmlc.fit(X_train, y_train)\n\n#predict\npreds = mlc.predict(X_valid)\n\n                                  ","baf176a8":"#mean absolute error\n\nprint('MAE:', mean_absolute_error(y_valid, preds))","26c09b40":"#data to be used are X and y which is already defined and the columns are my_cols\n\nX_train_dat = X[my_cols].copy()\ny_train_dat = y.copy()","a32a9998":"numerical_transformer = SimpleImputer(strategy = 'mean')\n\n#preprocessing categorical data\n\ncateg_transformer = Pipeline(steps = [('imputer' , SimpleImputer(strategy = 'constant')) , \n                                      ('onehot' , OneHotEncoder(handle_unknown='ignore'))\n                                     ])\n\n\n#combine both preprocessing of both numerical and categorical\npreprocessor = ColumnTransformer( \n                   transformers = [('num', numerical_transformer , numerical_cols),\n                                   ('cat',categ_transformer, categ_cols )\n                                  ])\n\n# define the model\n\nmodel = RandomForestRegressor(n_estimators = 550 , random_state = 0)\n\n#bundle preprocessor and model in pipeline\n\nmlc = Pipeline(\n    steps = [('preprocessor', preprocessor), \n             ('model', model)\n            ])\n\n\n#fit the model\n\nmlc.fit(X_train_dat, y_train_dat)\n\n#predict\npreds_test = mlc.predict(X_test)","5d929483":"#submission file\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","2d92d617":"#### Define pipeline and other required components to preprocess the data","e7e1fdeb":"## An ML model to predict the housing prices using Pipelines.","f777963e":"### 2. Now lets train the data without splitting","10c0a2a1":"#### Validation"}}