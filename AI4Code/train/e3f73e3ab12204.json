{"cell_type":{"2ab9cc67":"code","85f13008":"code","30befddf":"code","c87dd953":"code","ed3d6742":"code","064e4f1d":"code","8d195f45":"code","bff37403":"code","cea614ef":"code","ff7331cd":"code","bddb4414":"code","d8d3b154":"code","723b1732":"code","438066da":"code","7dadc57f":"code","4b2793f9":"code","4dc414f1":"code","3782ed3e":"code","97c633d0":"code","a242921d":"code","a6890d47":"code","0a03f294":"code","12d02496":"code","0fa47952":"code","9a2b217d":"code","daa79856":"code","774147a0":"code","64db0967":"code","a4c3113a":"code","36832bc6":"code","deb08071":"code","1ef807a2":"code","3eb8a4ce":"markdown","7ce43663":"markdown","2022fa33":"markdown","81c91bdf":"markdown","990fd041":"markdown","a531c847":"markdown","407b41a8":"markdown","a71eadc8":"markdown","838f6f51":"markdown","5734752f":"markdown","5c6a3fc2":"markdown","1f201009":"markdown","73e1da85":"markdown","466fff87":"markdown","eccb7a27":"markdown","4879e84b":"markdown","f5e437e3":"markdown","43b1a275":"markdown"},"source":{"2ab9cc67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","85f13008":"# import the dataset\ndf = pd.read_csv('..\/input\/daily-total-female-births-in-california-1959\/daily-total-female-births-CA.csv')\ndf","30befddf":"df.dtypes","c87dd953":"df['date'] = pd.to_datetime(df['date'])\ndf_birth","ed3d6742":"df.set_index('date', inplace=True)","064e4f1d":"df","8d195f45":"df.plot()","bff37403":"df_birth_smooth = df.rolling(window=20).mean()\ndf_birth_smooth","cea614ef":"# we will visualise the data\ndf.plot()\ndf_birth_smooth.plot()","ff7331cd":"# we will perform the shifting on the data.\ndf['First Level Shifting'] = df['births'].shift(1)\ndf","bddb4414":"df.shape","d8d3b154":"# Mean Sqaured Error\nfrom sklearn.metrics import mean_squared_error","723b1732":"df_birth = df.dropna()\ndf_birth.shape","438066da":"df.shape","7dadc57f":"error = mean_squared_error(df_birth['births'],df_birth['First Level Shifting'])\nerror","4b2793f9":"np.sqrt(error)","4dc414f1":"# import library\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf","3782ed3e":"df","97c633d0":"df.drop('First Level Shifting', axis = 1, inplace=True)","a242921d":"# plot_acf is to identify the parameter Q.\n# ARIMA(p,d,q)\n\nplot_acf(df)","a6890d47":"# plot_acf is to identify the parameter P.\n# ARIMA(p,d,q)\n\nplot_pacf(df)","0a03f294":"# p = 2 or 3\n# q = 3 or 4\n# d = 1","12d02496":"df.shape","0fa47952":"# we will now create a training and testing data for our model.\ndf_train = df[:330]\ndf_test = df[330:]\ndf_train.shape,df_test.shape","9a2b217d":"# import ARIMA\nfrom statsmodels.tsa.arima_model import ARIMA","daa79856":"birth_model = ARIMA(df_train,order = (2,1,3))","774147a0":"birth_model_fit = birth_model.fit()","64db0967":"birth_model_fit.aic","a4c3113a":"# Forecasting \nbirth_forecast = birth_model_fit.forecast(steps=35)[0]","36832bc6":"birth_forecast","deb08071":"# Now we will again checked the mean square error \n# mean_squared_error?\nerror = mean_squared_error(df_test,birth_forecast)\nerror","1ef807a2":"np.sqrt(error)","3eb8a4ce":"We will remove 'First Level Shifting' column in order to perform acf and pacf.","7ce43663":"Now we can see that the our data is not stationary.","2022fa33":"birth_model_fit.aic its ACOG information criteria ,its just for reference, keep changing the value of p,q,d and the values for which we get .aic the lowest that model will be said to be the best model.","81c91bdf":"Now we will perform 1 level shifting on the data to find the mean squared error of the dataframe.","990fd041":"We can see that the date column is of the object datatype. so we will convert it first to datetime datatype.\nAlso we will make the date column as the index.","a531c847":"Now we will use the mean squared error to find the error ","407b41a8":"Here the first value has the correlation of 1, so we after that we will count each values which are not getting in the blue zone. we can see there are 3 or 4 points outside the blue zone. so we can experiment the q values as 3 or 4.","a71eadc8":"We can see that the error of our model is less than the error of naive model earlier.","838f6f51":"In the above dataframe we just shifted the values by one row each. The first row value will be NaN as there is no previous value to shift.","5734752f":"Here we performed rolling on the births columns, here we take the mean of the first 20 observation and put it into 20th row, the same follows for the next following rows. However the data in the first 19 rows will be NaN, as the data is not in adequate quantity.","5c6a3fc2":"From the visualization we can make out that our data is not stationary, but not fully varied.\n\nLet us understand the same by a smoothing process.","1f201009":"We will build arima model now.","73e1da85":"As the mean squared error does not take the input of NaN. so will drop the NaN values.","466fff87":"Here we have the error of around of 9. Now when we create a model, our model can only be considered good if the error value of our model is less than 9.","eccb7a27":"Here the first value has the correlation of 1, so we after that we will count each values which are not getting in the blue zone. we can see there are 2 or 3 points outside the blue zone. so we can experiment the p values as 2 or 3.","4879e84b":"Now we can see that we have converted the date time column to datetime datatype, and have set it as the index.","f5e437e3":"ARIMA(Autoregressive Integrated Moving Average)\n\nAR = p value\nIntegrated = d value\nMoving Average = q value\n\n* Here the d value is the no of differential we used to make time series from non stationary to stationary.\n* P value is autocorrelation value which we can get by observing acf.\n* q value is the partial autocorrelation value which we can get by observing pacf.","43b1a275":"Let us visualise the data now."}}