{"cell_type":{"10cb4276":"code","f88a12cb":"code","f1b79b0c":"code","a6a362e2":"code","de20af46":"code","76d2dea5":"code","0a50f952":"code","37f1b3cc":"code","012c5a50":"code","bd369be4":"code","b32b141f":"code","12306a17":"code","f9c1fa62":"code","15457bc0":"code","909e8c44":"code","8d2038ce":"code","817a3d24":"code","e23a10b6":"code","eff98521":"code","64d6dafe":"code","9a720a74":"code","51523f82":"markdown","f650d715":"markdown","4217fd37":"markdown","8df97243":"markdown"},"source":{"10cb4276":"import pandas as pd\nimport numpy as np\nimport tqdm\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# from statsmodels.tsa.statespace import sarimax\n# import statsmodels as sm\n\n# from sklearn.preprocessing import MinMaxScaler\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import mean_squared_error\n# import keras\n\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.max_rows\", 500)","f88a12cb":"train = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")\ncalendar = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")\nsell = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\n# sample = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sample_submission.csv\")\n\n# data type\ntrain.iloc[:, 6:] = train.iloc[:, 6:].astype(\"int16\")\ncalendar.iloc[:, 11:] = calendar.iloc[:, 11:].astype(\"int8\")\nsell.sell_price = sell.sell_price.astype(\"float16\")","f1b79b0c":"train.id.replace(regex=\"_validation\", value=\"\", inplace=True)\nsell[\"id\"] = sell.item_id+\"_\"+sell.store_id\nsell.drop(columns=[\"store_id\", \"item_id\"], inplace=True)","a6a362e2":"# train dataset\n# setting columns which we use\ntrain_col = ['id', 'date', \n             'FOODS_1', 'FOODS_2', 'FOODS_3', \n             'HOBBIES_1', \"HOBBIES_2\", \n             'HOUSEHOLD_1', 'HOUSEHOLD_2', \n             'FOODS', 'HOBBIES', \n             'CA_1', 'CA_2', 'CA_3', 'CA_4', \n             'TX_1', 'TX_2', 'TX_3', \n             'WI_1', 'WI_2', 'WI_3', \n             'CA', 'TX', \n             \"snap_CA\", \"snap_TX\", \"snap_WI\", \n             'Cultural', 'National', 'Religious', 'Sporting', \n             \"release\", \n             'sell_price', 'sales']\n\n# event one-hot encoding\ntrain_event = calendar.loc[:, [\"d\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]]\ntrain_event = train_event.melt(id_vars=\"d\")\ntrain_event = train_event[~train_event.value.isnull()].reset_index(drop=True)\ntrain_event.variable.replace(to_replace={\"event_name_1\":\"event_name\", \"event_name_2\":\"event_name\", \n                                   \"event_type_1\":\"event_type\", \"event_type_2\":\"event_type\"}, \n                             inplace=True)\n\ntrain_event_type = train_event.query(\"variable=='event_type'\").loc[:, [\"d\"]].merge(pd.get_dummies(train_event.query(\"variable=='event_type'\").value), \n                                                                                   left_index=True, right_index=True, how=\"left\")\ntrain_event_name = train_event.query(\"variable=='event_name'\").loc[:, [\"d\"]].merge(pd.get_dummies(train_event.query(\"variable=='event_name'\").value), \n                                                                                   left_index=True, right_index=True, how=\"left\")\ntrain_event_type = train_event_type.groupby(\"d\").sum()\ntrain_event_name = train_event_name.groupby(\"d\").sum()\ntrain_event_type.reset_index(inplace=True)\ntrain_event_name.reset_index(inplace=True)\n\n# train one-hot encoding\ntrain_dept_id = pd.get_dummies(train.dept_id)\ntrain_cat_id = pd.get_dummies(train.cat_id)\ntrain_store_id = pd.get_dummies(train.store_id)\ntrain_state_id = pd.get_dummies(train.state_id)\n\n# merge all data\ndf_dummies = pd.concat([train[[\"id\"]], train_dept_id, train_cat_id, train_store_id, train_state_id], axis=1)\ntrain_df = df_dummies.merge(train.iloc[:, 6:], left_index=True, right_index=True, how=\"left\")\n\ndel train, train_dept_id, train_cat_id, train_store_id, train_state_id\ngc.collect()\n\ntrain_df = train_df.melt(id_vars=list(df_dummies.columns), \n                         var_name=\"d\", value_name=\"sales\")\n\ntrain_df = train_df.merge(calendar.loc[:, [\"date\", \"d\", \"wm_yr_wk\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]], \n                          left_on=\"d\", right_on=\"d\", how=\"left\")\n\ndel calendar\ngc.collect()\n\ntrain_df = train_df.merge(train_event_type, on=\"d\", how=\"left\")\ntrain_df = train_df.merge(sell.loc[:, [\"id\", \"wm_yr_wk\", \"sell_price\"]], \n                          on=[\"id\", \"wm_yr_wk\"], how=\"left\")\n# df = df.loc[:, col]\ntrain_df.fillna(0, inplace=True)\ntrain_df.loc[:, ['snap_CA', 'snap_TX', 'snap_WI', \n                 'Cultural', 'National', 'Religious', 'Sporting']] = train_df.loc[:, ['snap_CA', 'snap_TX', 'snap_WI', \n                                                                                      'Cultural', 'National', 'Religious', 'Sporting']].astype(\"uint8\")\ntrain_df.date = pd.to_datetime(train_df.date)\n# train_df.set_index([\"id\", \"date\"], inplace=True)\n\ndel sell\ngc.collect()\n\ntrain_df[\"release\"] = 1\ntrain_df.loc[train_df.sell_price==0, \"release\"] = 0\ntrain_df.release = train_df.release.astype(\"uint8\")\n\n# reordering columns\ntrain_df = train_df.loc[:, train_col]","de20af46":"train_df.tail()","76d2dea5":"train = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")\ncalendar = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")\nsell = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\n# sample = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sample_submission.csv\")\n\n# data type\ntrain.iloc[:, 6:] = train.iloc[:, 6:].astype(\"int16\")\ncalendar.iloc[:, 11:] = calendar.iloc[:, 11:].astype(\"int8\")\nsell.sell_price = sell.sell_price.astype(\"float16\")","0a50f952":"train.id.replace(regex=\"_validation\", value=\"\", inplace=True)\nsell[\"id\"] = sell.item_id+\"_\"+sell.store_id\nsell.drop(columns=[\"store_id\", \"item_id\"], inplace=True)","37f1b3cc":"# test dataset\n# setting columns which we use\ntest_col = ['id', 'date', \n            'FOODS_1', 'FOODS_2', 'FOODS_3', \n            'HOBBIES_1', \"HOBBIES_2\", \n            'HOUSEHOLD_1', 'HOUSEHOLD_2', \n            'FOODS', 'HOBBIES', \n            'CA_1', 'CA_2', 'CA_3', 'CA_4', \n            'TX_1', 'TX_2', 'TX_3', \n            'WI_1', 'WI_2', 'WI_3', \n            'CA', 'TX', \n            \"snap_CA\", \"snap_TX\", \"snap_WI\", \n            'Cultural', 'National', 'Religious', 'Sporting', \n            \"release\", \n            'sell_price', 'sales']\n\n# event one-hot encoding\ntest_event = calendar.query(\"date>'2016-04-24'\").loc[:, [\"d\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]]\ntest_event = test_event.melt(id_vars=\"d\")\ntest_event = test_event[~test_event.value.isnull()].reset_index(drop=True)\ntest_event.variable.replace(to_replace={\"event_name_1\":\"event_name\", \"event_name_2\":\"event_name\", \n                                        \"event_type_1\":\"event_type\", \"event_type_2\":\"event_type\"}, \n                            inplace=True)\n\ntest_event_type = test_event.query(\"variable=='event_type'\").loc[:, [\"d\"]].merge(pd.get_dummies(test_event.query(\"variable=='event_type'\").value), \n                                                                       left_index=True, right_index=True, how=\"left\")\ntest_event_name = test_event.query(\"variable=='event_name'\").loc[:, [\"d\"]].merge(pd.get_dummies(test_event.query(\"variable=='event_name'\").value), \n                                                                       left_index=True, right_index=True, how=\"left\")\ntest_event_type = test_event_type.groupby(\"d\").sum()\ntest_event_name = test_event_name.groupby(\"d\").sum()\ntest_event_type.reset_index(inplace=True)\ntest_event_name.reset_index(inplace=True)\ntest_event_type = calendar.query(\"date>'2016-04-24'\").loc[:, [\"d\", \"date\"]].merge(test_event_type, how=\"left\")\ntest_event_name = calendar.query(\"date>'2016-04-24'\").loc[:, [\"d\", \"date\"]].merge(test_event_name, how=\"left\")\ntest_event_type.date = pd.to_datetime(test_event_type.date)\ntest_event_name.date = pd.to_datetime(test_event_name.date)\ntest_event_type.fillna(0, inplace=True)\ntest_event_name.fillna(0, inplace=True)\ntest_event_type.iloc[:, 2:] = test_event_type.iloc[:, 2:].astype(\"uint8\")\ntest_event_name.iloc[:, 2:] = test_event_name.iloc[:, 2:].astype(\"uint8\")\n\n\nsample = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sample_submission.csv\")\n\nvalidation = sample[sample.id.str.contains(\"validation\")].add_prefix(\"val_\")\nevaluation = sample[sample.id.str.contains(\"evaluation\")].add_prefix(\"evl_\")\nvalidation.rename(columns={\"val_id\":\"id\"}, inplace=True)\nevaluation.rename(columns={\"evl_id\":\"id\"}, inplace=True)\nvalidation.id.replace(regex=\"_validation\", value=\"\", inplace=True)\nevaluation.id.replace(regex=\"_evaluation\", value=\"\", inplace=True)\n\nvalidation = validation.melt(id_vars=\"id\", var_name=\"F\", value_name=\"sales\")\nevaluation = evaluation.melt(id_vars=\"id\", var_name=\"F\", value_name=\"sales\")\n\nval = ['val_F1', 'val_F2', 'val_F3', 'val_F4', 'val_F5', 'val_F6', \n       'val_F7', 'val_F8', 'val_F9', 'val_F10', 'val_F11', 'val_F12', \n       'val_F13', 'val_F14', 'val_F15', 'val_F16', 'val_F17', 'val_F18', \n       'val_F19', 'val_F20', 'val_F21', 'val_F22', 'val_F23', 'val_F24', \n       'val_F25', 'val_F26', 'val_F27', 'val_F28']\nevl = ['evl_F1', 'evl_F2', 'evl_F3', 'evl_F4', 'evl_F5', 'evl_F6', \n       'evl_F7', 'evl_F8', 'evl_F9', 'evl_F10', 'evl_F11', 'evl_F12', \n       'evl_F13', 'evl_F14', 'evl_F15', 'evl_F16', 'evl_F17', 'evl_F18', \n       'evl_F19', 'evl_F20', 'evl_F21', 'evl_F22', 'evl_F23', 'evl_F24', \n       'evl_F25', 'evl_F26', 'evl_F27', 'evl_F28']\nval = pd.DataFrame(data={\"F\":val, \"date\":pd.date_range(\"2016-04-25\", \"2016-05-22\")})\nevl = pd.DataFrame(data={\"F\":evl, \"date\":pd.date_range(\"2016-05-23\", \"2016-06-19\")})\n\nvalidation = validation.merge(val).drop(columns=[\"F\"])\nevaluation = evaluation.merge(evl).drop(columns=[\"F\"])\n\nfor i in ['FOODS_1', 'FOODS_2', 'FOODS_3', 'HOBBIES_1', 'HOBBIES_2',\n          'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS', 'HOBBIES', 'HOUSEHOLD', \n          'CA_1', 'CA_2', 'CA_3', 'CA_4', \n          'TX_1', 'TX_2', 'TX_3', \n          'WI_1', 'WI_2', 'WI_3',\n          'CA', 'TX', 'WI']:\n    validation[i] = 0\n    validation.loc[validation.id.str.contains(i), i] = 1\n\nfor i in ['FOODS_1', 'FOODS_2', 'FOODS_3', 'HOBBIES_1', 'HOBBIES_2',\n          'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS', 'HOBBIES', 'HOUSEHOLD', \n          'CA_1', 'CA_2', 'CA_3', 'CA_4', \n          'TX_1', 'TX_2', 'TX_3', \n          'WI_1', 'WI_2', 'WI_3',\n          'CA', 'TX', 'WI']:\n    evaluation[i] = 0\n    evaluation.loc[evaluation.id.str.contains(i), i] = 1\n\ncalendar.date = pd.to_datetime(calendar.date)\nvalidation = validation.merge(calendar.loc[:, [\"date\", \"wm_yr_wk\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]], \n                              left_on=\"date\", right_on=\"date\", how=\"left\")\nevaluation = evaluation.merge(calendar.loc[:, [\"date\", \"wm_yr_wk\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]], \n                              left_on=\"date\", right_on=\"date\", how=\"left\")\nvalidation = validation.merge(sell.loc[:, [\"id\", \"wm_yr_wk\", \"sell_price\"]], \n                              on=[\"id\", \"wm_yr_wk\"], how=\"left\")\nevaluation = evaluation.merge(sell.loc[:, [\"id\", \"wm_yr_wk\", \"sell_price\"]], \n                              on=[\"id\", \"wm_yr_wk\"], how=\"left\")\n\nvalidation[\"release\"] = 1\nvalidation.loc[validation.sell_price==0, \"release\"] = 0\nvalidation.release = validation.release.astype(\"uint8\")\nevaluation[\"release\"] = 1\nevaluation.loc[evaluation.sell_price==0, \"release\"] = 0\nevaluation.release = evaluation.release.astype(\"uint8\")\n\nvalidation = validation.merge(test_event_type, on=\"date\", how=\"left\")\nevaluation = evaluation.merge(test_event_type, on=\"date\", how=\"left\")\n\n# reordering columns\nvalidation = validation.loc[:, test_col]\nevaluation = evaluation.loc[:, test_col]","012c5a50":"%%time\ntrain_df.query(\"FOODS_1==1\").reset_index(drop=True).to_csv(\"..\/working\/df_FOODS_1.csv\", index=False)\ntrain_df.query(\"FOODS_2==1\").reset_index(drop=True).to_csv(\"..\/working\/df_FOODS_2.csv\", index=False)\ntrain_df.query(\"FOODS_3==1\").reset_index(drop=True).to_csv(\"..\/working\/df_FOODS_3.csv\", index=False)\n\n# train_df.query(\"HOBBIES_1==1\").reset_index(drop=True).to_csv(\"..\/working\/df_HOBBIES_1.csv\", index=False)\n# train_df.query(\"HOBBIES_2==1\").reset_index(drop=True).to_csv(\"..\/working\/df_HOBBIES_2.csv\", index=False)\n\n# train_df.query(\"HOUSEHOLD_1==1\").reset_index(drop=True).to_csv(\"..\/working\/df_HOUSEHOLD_1.csv\", index=False)\n# train_df.query(\"HOUSEHOLD_2==1\").reset_index(drop=True).to_csv(\"..\/working\/df_HOUSEHOLD_2.csv\", index=False)","bd369be4":"%%time\nvalidation.reset_index(drop=True).to_csv(\"..\/working\/validation.csv\", index=False)\nevaluation.reset_index(drop=True).to_csv(\"..\/working\/evaluation.csv\", index=False)","b32b141f":"df = train_df\ndf[\"item_id\"] = df.id.apply(func=lambda x:x[:-5])","12306a17":"# _ = df.query(\"FOODS_1==1 and CA==1 and release==1\").groupby([\"item_id\", \"snap_CA\"]).sales.mean()\n# _ = _.reset_index()","f9c1fa62":"_ = df.query(\"FOODS_1==1 and CA==1 and release==1\").loc[:, [\"item_id\", \"snap_CA\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/44+1\n\nplt.figure(figsize=(30, 30))\nplt.suptitle(\"FOODS_1 and CA\")\nfor idx, val in enumerate(range(44, count*44+1, 44)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_CA\")\n    plt.xticks(rotation=45)\nplt.show()","15457bc0":"_ = df.query(\"FOODS_1==1 and TX==1 and release==1\").loc[:, [\"item_id\", \"snap_TX\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/44+1\n\nplt.figure(figsize=(30, 30))\nplt.suptitle(\"FOODS_1 and TX\")\nfor idx, val in enumerate(range(44, count*44+1, 44)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_TX\")\n    plt.xticks(rotation=45)\nplt.show()","909e8c44":"_ = df.query(\"FOODS_1==1 and CA==0 and TX==0 and release==1\").loc[:, [\"item_id\", \"snap_WI\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/44+1\n\nplt.figure(figsize=(30, 30))\nplt.suptitle(\"FOODS_1 and WI\")\nfor idx, val in enumerate(range(44, count*44+1, 44)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_WI\")\n    plt.xticks(rotation=45)\n\nplt.show()","8d2038ce":"_ = df.query(\"FOODS_2==1 and CA==1 and release==1\").loc[:, [\"item_id\", \"snap_CA\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_2 and CA\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_CA\")\n    plt.xticks(rotation=45)\nplt.show()","817a3d24":"_ = df.query(\"FOODS_2==1 and TX==1 and release==1\").loc[:, [\"item_id\", \"snap_TX\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_2 and TX\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_TX\")\n    plt.xticks(rotation=45)\nplt.show()","e23a10b6":"_ = df.query(\"FOODS_2==1 and CA==0 and TX==0 and release==1\").loc[:, [\"item_id\", \"snap_WI\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_2 and WI\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_WI\")\n    plt.xticks(rotation=45)\n\nplt.show()","eff98521":"_ = df.query(\"FOODS_3==1 and CA==1 and release==1\").loc[:, [\"item_id\", \"snap_CA\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_3 and CA\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_CA\")\n    plt.xticks(rotation=45)\nplt.show()","64d6dafe":"_ = df.query(\"FOODS_3==1 and TX==1 and release==1\").loc[:, [\"item_id\", \"snap_TX\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_3 and TX\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_TX\")\n    plt.xticks(rotation=45)\nplt.show()","9a720a74":"_ = df.query(\"FOODS_3==1 and CA==0 and TX==0 and release==1\").loc[:, [\"item_id\", \"snap_WI\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)\/\/50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_3 and WI\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_WI\")\n    plt.xticks(rotation=45)\n\nplt.show()","51523f82":"---\nThe end of notebook","f650d715":"---","4217fd37":"# M5 Data Preprocessing\n## FOODS\nDamien Park  \n2020-04-12","8df97243":"---"}}