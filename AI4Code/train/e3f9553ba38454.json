{"cell_type":{"5fcb6905":"code","a94263d3":"code","a412f6c3":"code","5c9f5c1e":"code","2ed831e8":"code","f2d17663":"code","9b6fd28e":"code","f3807da9":"code","ea9d4b8e":"code","929a4200":"code","f97008a0":"code","3d6715f8":"code","9ee2013d":"code","9b3f5913":"code","ecb5e7e4":"code","f2286203":"code","afd8bca7":"code","76422f58":"code","2793c1e1":"code","df821ed6":"code","17bbf782":"code","5a9cbc67":"code","ec0c27da":"code","f488fd9c":"code","0755f25e":"code","02847f59":"code","6493a52e":"code","05254f83":"code","52b9ecdc":"code","c67bec79":"code","1e5ceebc":"code","80badb50":"code","7d36b60c":"code","959ee610":"code","e5cd03f0":"code","35fd4247":"code","5311efca":"code","5ef0dc54":"code","d19ebdba":"code","d5e658a3":"code","10774b54":"code","c0e70e73":"code","9e013134":"code","fe482503":"code","02dbb815":"code","0b50dd5e":"code","dc25e26c":"code","b50b4c28":"code","9f44bfde":"code","acc5219b":"code","9c04356e":"code","930051a6":"code","5bd6bab1":"code","f2a2c39e":"code","dc983983":"code","05a19f1e":"code","0a1ac48f":"code","272d16b0":"code","5e8794df":"code","b62bf41e":"code","72dc9cfb":"code","bdcbf649":"code","f314decf":"code","c73edf6d":"code","fc9cb5be":"code","d5009707":"code","1b412bde":"code","c7049d48":"code","8f1dd58d":"code","884c79df":"code","47302723":"code","abbeeec0":"code","f6440ea0":"code","dbc8a8ee":"code","9c301272":"code","d1c72927":"code","a87d56d5":"code","745c15fb":"code","52e1817d":"code","a46d063c":"code","1295ad7a":"code","4d631f18":"code","eb4873bf":"code","685325f9":"code","d568de30":"code","ddd674d1":"code","3db1fd45":"code","079c109a":"code","bd2136f8":"code","be48f95d":"code","ff0d796c":"code","fcaee460":"code","78dd36a9":"code","12229833":"code","05d422d7":"code","4403392e":"code","f1168ade":"code","19f150f8":"code","5ac5f00a":"code","55adbb62":"code","65696e0a":"code","3aef4b56":"code","718b6507":"code","0385b736":"code","2c5a63b1":"code","75f05a08":"code","1f3d8f71":"code","d0fdace5":"code","93e92e33":"code","2c74bf21":"code","651b9229":"code","d08482b8":"code","9fddd87a":"code","76094e80":"code","823b4f0e":"code","f3cd0029":"code","81667f0d":"markdown","6d97e7cd":"markdown","6da51180":"markdown","085946f3":"markdown","420a46f9":"markdown","fb165d8b":"markdown","26e9efac":"markdown","92170e26":"markdown","06e92d9f":"markdown","edee1f41":"markdown","3112545c":"markdown","4e43311f":"markdown","93c5ae9e":"markdown","8c32cf46":"markdown","2ce541ee":"markdown","b5361659":"markdown","d9f38779":"markdown","4542e1b2":"markdown","db37ce3d":"markdown","46258358":"markdown","c702dc3c":"markdown","c142d306":"markdown","bbe9d30a":"markdown","c573d470":"markdown","932d2109":"markdown","cf14b2de":"markdown","e20094df":"markdown","0f651c08":"markdown","7e959fcd":"markdown","2c6fb6ad":"markdown","a7742e7a":"markdown","4920379e":"markdown","cd427e07":"markdown","919b5675":"markdown","057e73bf":"markdown","737213dc":"markdown","3982da54":"markdown","900565d3":"markdown","286fd259":"markdown","f988353d":"markdown","2dc42398":"markdown"},"source":{"5fcb6905":"import pandas as pd\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a94263d3":"raw_csv_data = pd.read_csv('\/kaggle\/input\/employee-absenteeism-prediction\/Absenteeism-data.csv')\nraw_csv_data.head()","a412f6c3":"df = raw_csv_data.copy()\ndf.head()","5c9f5c1e":"pd.options.display.max_columns=None\npd.options.display.max_rows=None","2ed831e8":"display(df)","f2d17663":"df.info()","9b6fd28e":"df = df.drop(['ID'], axis=1)","f3807da9":"df.head()","ea9d4b8e":"# Maximum value in 'Reason for Absence' column\ndf['Reason for Absence'].max()","929a4200":"# Minimum value in 'Reason for Absence' column\ndf['Reason for Absence'].min()","f97008a0":"# Unique values in 'Reason for Absence' column\ndf['Reason for Absence'].unique()","3d6715f8":"# length of unique values in 'Reason for Absence' column\nlen(df['Reason for Absence'].unique())","9ee2013d":"sorted(df['Reason for Absence'].unique())","9b3f5913":"# Create dummy for 'Reason for Absence' column\nreason_columns = pd.get_dummies(df['Reason for Absence'], drop_first=True)\nreason_columns","ecb5e7e4":"# Check whether any missing value is there or not\nreason_columns['check'] = reason_columns.sum(axis=1)\nreason_columns","f2286203":"reason_columns['check'].sum(axis=0)","afd8bca7":"# So, we'll be dropping the check column from reason_columns\nreason_columns = reason_columns.drop(['check'], axis=1)\nreason_columns","76422f58":"df.columns.values","2793c1e1":"reason_columns.columns.values","df821ed6":"# Drop 'Reason for Absence' column to avoid multi-collinearity\ndf = df.drop(['Reason for Absence'], axis=1)\ndf.head()","17bbf782":"# Group the variables from 'Reason for Absence' column\nreason_type_1 = reason_columns.iloc[:, 1:14].max(axis=1)\nreason_type_2 = reason_columns.iloc[:, 15:17].max(axis=1)\nreason_type_3 = reason_columns.iloc[:, 18:21].max(axis=1)\nreason_type_4 = reason_columns.iloc[:, 22:].max(axis=1)","5a9cbc67":"df = pd.concat([df, reason_type_1, reason_type_2, reason_type_3, reason_type_4], axis=1)\ndf.head()","ec0c27da":"df.columns.values","f488fd9c":"column_names = ['Date', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours', 'Reason_1', 'Reason_2', 'Reason_3', 'Reason_4']","0755f25e":"df.columns = column_names","02847f59":"df.head()","6493a52e":"column_names_reordered = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours']","05254f83":"df = df[column_names_reordered]","52b9ecdc":"df.head()","c67bec79":"df_reason_mod = df.copy()\ndf_reason_mod.head()","1e5ceebc":"type(df_reason_mod['Date'][0])","80badb50":"# Converting the Date column to timestamp format\ndf_reason_mod['Date'] = pd.to_datetime(df_reason_mod['Date'], format='%d\/%m\/%Y')\ndf_reason_mod['Date'].head()","7d36b60c":"df_reason_mod['Date'][0]","959ee610":"df_reason_mod['Date'][0].month","e5cd03f0":"list_months = []\nlist_months","35fd4247":"len(df_reason_mod)","5311efca":"df_reason_mod.loc[:, 'Date'][0].month","5ef0dc54":"for i in range (len(df_reason_mod)):\n    list_months.append(df_reason_mod.loc[:, 'Date'][i].month)","d19ebdba":"list_months","d5e658a3":"len(list_months)","10774b54":"df_reason_mod['Month Value'] = list_months\ndf_reason_mod.head(20)","c0e70e73":"df_reason_mod.loc[:, 'Date'][0].weekday()","9e013134":"list_days = []","fe482503":"def date_to_weekday(date_value):\n    return (date_value.weekday())","02dbb815":"df_reason_mod['Day of the Week'] = df_reason_mod['Date'].apply(date_to_weekday)\ndf_reason_mod.head(20)","0b50dd5e":"# Dropping Date column from dataframe to avoid multicollinearity\ndf_reason_mod = df_reason_mod.drop(['Date'], axis=1)\ndf_reason_mod.head()","dc25e26c":"df_reason_mod.columns.values","b50b4c28":"column_names_reordered = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4',\n                          'Month Value', 'Day of the Week',\n                           'Transportation Expense', 'Distance to Work', 'Age',\n                           'Daily Work Load Average', 'Body Mass Index', 'Education',\n                           'Children', 'Pets', 'Absenteeism Time in Hours']","9f44bfde":"df_reason_mod = df_reason_mod[column_names_reordered]","acc5219b":"df_reason_mod.head(20)","9c04356e":"df_reason_date_mod = df_reason_mod.copy()","930051a6":"df_reason_date_mod.head()","5bd6bab1":"type(df_reason_date_mod['Transportation Expense'][0])","f2a2c39e":"type(df_reason_date_mod['Distance to Work'][0])","dc983983":"type(df_reason_date_mod['Age'][0])","05a19f1e":"type(df_reason_date_mod['Daily Work Load Average'][0])","0a1ac48f":"type(df_reason_date_mod['Body Mass Index'][0])","272d16b0":"df_reason_date_mod['Education'].unique()","5e8794df":"df_reason_date_mod['Education'].value_counts()","b62bf41e":"df_reason_date_mod['Education'] = df_reason_date_mod['Education'].map({1:0, 2:1, 3:1, 4:1})","72dc9cfb":"df_reason_date_mod['Education'].unique()","bdcbf649":"df_reason_date_mod['Education'].value_counts()","f314decf":"df_preprocessed = df_reason_date_mod.copy()\ndf_preprocessed.head()","c73edf6d":"# Saving the preprocessed CSV file\ndf_preprocessed.to_csv('Absenteeism_preprocessed.csv', index=False)","fc9cb5be":"data_preprocessed = pd.read_csv('Absenteeism_preprocessed.csv')","d5009707":"data_preprocessed.head()","1b412bde":"data_preprocessed['Absenteeism Time in Hours'].median()","c7049d48":"targets = np.where(data_preprocessed['Absenteeism Time in Hours'] > \n                   data_preprocessed['Absenteeism Time in Hours'].median(),\n                   1, 0)","8f1dd58d":"targets","884c79df":"data_preprocessed['Excessive Absenteeism'] = targets","47302723":"data_preprocessed.head()","abbeeec0":"targets.sum() \/ targets.shape[0]","f6440ea0":"# Drop 'Absenteeism Time in Hours' column\ndata_with_targets = data_preprocessed.drop(['Absenteeism Time in Hours', \n                                            'Daily Work Load Average', \n                                            'Education', \n                                            'Reason_4', \n                                            'Distance to Work'], \n                                             axis=1)\ndata_with_targets.head()","dbc8a8ee":"# Checking whether the following two dataframes are same or different\ndata_with_targets is data_preprocessed","9c301272":"data_with_targets.shape","d1c72927":"data_with_targets.iloc[:, :14]","a87d56d5":"data_with_targets.iloc[:, :-1]","745c15fb":"unscaled_inputs = data_with_targets.iloc[:, :-1]","52e1817d":"# from sklearn.preprocessing import StandardScaler\n# absenteeism_scaler = StandardScaler()","a46d063c":"# import the libraries needed to create the Custom Scaler\n# note that all of them are a part of the sklearn package\n# moreover, one of them is actually the StandardScaler module, \n# so you can imagine that the Custom Scaler is build on it\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\n\n# create the Custom Scaler class\n\nclass CustomScaler(BaseEstimator,TransformerMixin): \n    \n    # init or what information we need to declare a CustomScaler object\n    # and what is calculated\/declared as we do\n    \n    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n        \n        # scaler is nothing but a Standard Scaler object\n        self.scaler = StandardScaler(copy,with_mean,with_std)\n        # with some columns 'twist'\n        self.columns = columns\n        self.mean_ = None\n        self.var_ = None\n        \n    \n    # the fit method, which, again based on StandardScale\n    \n    def fit(self, X, y=None):\n        self.scaler.fit(X[self.columns], y)\n        self.mean_ = np.mean(X[self.columns])\n        self.var_ = np.var(X[self.columns])\n        return self\n    \n    # the transform method which does the actual scaling\n\n    def transform(self, X, y=None, copy=None):\n        \n        # record the initial order of the columns\n        init_col_order = X.columns\n        \n        # scale all features that you chose when creating the instance of the class\n        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n        \n        # declare a variable containing all information that was not scaled\n        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n        \n        # return a data frame which contains all scaled features and all 'not scaled' features\n        # use the original order (that you recorded in the beginning)\n        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]","1295ad7a":"unscaled_inputs.columns.values","4d631f18":"# columns_to_scale = ['Month Value','Day of the Week', 'Transportation Expense', \n#                     'Distance to Work','Age', 'Daily Work Load Average', 'Body Mass Index', \n#                     'Children', 'Pets']\n\ncolumns_to_omit = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Education']","eb4873bf":"columns_to_scale = [x for x in unscaled_inputs.columns.values if x not in columns_to_omit]","685325f9":"absenteeism_scaler = CustomScaler(columns_to_scale)","d568de30":"absenteeism_scaler.fit(unscaled_inputs)","ddd674d1":"scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)","3db1fd45":"scaled_inputs","079c109a":"scaled_inputs.shape","bd2136f8":"from sklearn.model_selection import train_test_split","be48f95d":"# Split\nx_train, x_test, y_train, y_test = train_test_split(scaled_inputs, targets, train_size=0.8, random_state=20)","ff0d796c":"print(x_train.shape, y_train.shape)","fcaee460":"print(x_test.shape, y_test.shape)","78dd36a9":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","12229833":"reg = LogisticRegression()","05d422d7":"reg.fit(x_train, y_train)","4403392e":"reg.score(x_train, y_train)","f1168ade":"model_outputs = reg.predict(x_train)","19f150f8":"model_outputs","5ac5f00a":"targets","55adbb62":"np.sum(model_outputs == y_train)","65696e0a":"model_outputs.shape[0]","3aef4b56":"np.sum(model_outputs == y_train) \/ model_outputs.shape[0]","718b6507":"# Finding the intercept\nreg.intercept_","0385b736":"# Finding the coefficient\nreg.coef_","2c5a63b1":"# Finding the column names in unscaled dataframe\nunscaled_inputs.columns.values","75f05a08":"feature_name = unscaled_inputs.columns.values","1f3d8f71":"# Creating summary table to store different attributes and their corresponding values\nsummary_table = pd.DataFrame(columns=['Feature Name'], data=feature_name)\nsummary_table['Coefficients'] = np.transpose(reg.coef_)\nsummary_table","d0fdace5":"# Inserting the value of intercept in the summary table\nsummary_table.index = summary_table.index + 1\nsummary_table.loc[0] = ['Intercept', reg.intercept_[0]]\nsummary_table = summary_table.sort_index()\nsummary_table","93e92e33":"summary_table['Odds_Ratio'] = np.exp(summary_table['Coefficients'])\nsummary_table","2c74bf21":"summary_table.sort_values('Odds_Ratio', ascending=False)","651b9229":"reg.score(x_test, y_test)","d08482b8":"predicted_proba = reg.predict_proba(x_test)\npredicted_proba","9fddd87a":"predicted_proba[:, 1]","76094e80":"import pickle","823b4f0e":"# pickle the model file\nwith open('model', 'wb') as file:\n    pickle.dump(reg, file)","f3cd0029":"# pickle the scaler file\nwith open('scaler', 'wb') as file:\n    pickle.dump(absenteeism_scaler, file)","81667f0d":"Exploration of 'Date' column","6d97e7cd":"Extract the Month value","6da51180":"#### Interpreting the coefficients","085946f3":"Following code is for displaying all the rows and columns in the dataframe, despite of how large they are","420a46f9":"#### Testing the model","fb165d8b":"Final Checkpoint","26e9efac":"### Load the CSV data","92170e26":"Create a Checkpoint","06e92d9f":"Select the inputs for the regression","edee1f41":"Exploring other variables","3112545c":"Manually check the accuracy","4e43311f":"Converting to dummies","93c5ae9e":"Extract the Day of the Week","8c32cf46":"But wait which are the twenty eight reasons we have substituted with numbers. In other words reason one stands for a certain reason for absence as much as reason to stands for another. You may know from statistics that these variables are categorical nominal nominal because instead of using the numbers from 0 to 28 we could have had names disease dentist pregnancy etc..However using numbers is the convention for working with categorical nominal data ","2ce541ee":"#### Save the model","b5361659":"Group the Reason for Absence column","d9f38779":"#### Create a logistic regression model to predict Absenteeism","4542e1b2":"Create a Checkpoint (Creating checkpoint refers to storing the current version of once code)\n\n(Create a copy of the current state of your dataframe)","db37ce3d":"Which is the length of dataframe, so there is no missing values in 'Reason for Absence' column\n\nAnd thus, the validity of reason columns has been checked and we are satisfied with its state.","46258358":"Concatenate column values from reason_columns to df","c702dc3c":"However wait didn't we already find out that minimum value contained in this column is zero while the\nlargest one is 28. This makes up to 29 different values while using the len function instead we just obtained twenty eight.This has to say one thing and one thing only a number between 0 and 28 is missing.","c142d306":"Split the data into train and test and shuffle","bbe9d30a":"Reorder the columns","c573d470":"Create the targets","932d2109":"#### Finding the intercept and coefficients","cf14b2de":"Logistic Regression with Sklearn","e20094df":"You can spot that the value we lack is number 20.","0f651c08":"Rename the above four concatenated columns","7e959fcd":"Load the preprocessed data","2c6fb6ad":"Standardize the data","a7742e7a":"### Importing the relevant libraries","4920379e":"Drop ID column from the dataframe as it is of no use for prediction","cd427e07":"Displaying the head of the dataframe","919b5675":"Reorder columns","057e73bf":"A comment on the targets","737213dc":"Exploring 'Education', 'Children', 'Pets' columns","3982da54":"Training model","900565d3":"### Data Preprocessing","286fd259":"Exploration of Reason for Absence column","f988353d":"Copying the content of initial dataframe to a new one","2dc42398":"Getting the information about the dataframe"}}