{"cell_type":{"7636cc28":"code","11979fc7":"code","9cfd8bde":"code","50c403e0":"code","d0383574":"code","4fe566d7":"code","55ea3544":"code","e95380ef":"code","b44b10db":"code","75278342":"code","d69eaf85":"code","01bb55ef":"code","afb4ef7f":"code","400d62fe":"code","27efe7be":"code","407a2242":"code","d946533a":"code","f9cfedf2":"code","fce67206":"code","11186ab4":"code","bfccd9ed":"code","6df512cb":"code","e1155eb3":"markdown","30df204f":"markdown","a6f5c4f1":"markdown","203784d2":"markdown","2f1bf38d":"markdown","94bf08ae":"markdown","d99caf3d":"markdown","c555381f":"markdown","4ff795da":"markdown","a7dfe2af":"markdown","688c0722":"markdown","e0bac0d8":"markdown","b6f70301":"markdown"},"source":{"7636cc28":"# import libraries \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport PIL\n\n# set global property for figure size\nplt.rcParams['figure.figsize'] = [10, 8]","11979fc7":"# image converter to tensor \ndef image_reader(img_path):\n    # read image in grayscale\n    image = PIL.Image.open(img_path).convert('RGB').convert('L')\n    # return nparray converted image\n    return np.array(image)\n\n# function to show image \ndef plot_image(image, title):\n    plt.title(title)\n    plt.imshow(image, cmap='gray')\n    plt.show()","9cfd8bde":"# get image. If you want to try a mug, try it! \npath_mug = '..\/input\/imagerecogsample\/8012801_R_Z001A_UC1268924.jpg'\npath_river = '..\/input\/imagerecogsample\/download.jpg'\nimage = image_reader(path_river)","50c403e0":"# check image shape \nimage.shape","d0383574":"# show original image\nplot_image(image, 'Original image')","4fe566d7":"# image preprocessing\ndef image_preprocess(image):\n    left = np.array([[0]] * image.shape[0])\n    right = left.copy()\n    upper = np.expand_dims(np.zeros(image.shape[1] + 2), axis=0)\n    lower = upper.copy()\n    \n    image = np.append(image, right, axis=1)\n    image = np.append(left, image, axis=1)\n    image = np.append(image, lower, axis=0)\n    image = np.append(upper, image, axis=0)\n    \n    return image","55ea3544":"'''\nAverage filtering\n'''\n\n# create filter for average filtering\ndef average_filter(size):\n    return np.ones((size, size)) \/ (size**2)\n\n# simple filters in image\ndef simple_filter_image(image, filter_size):\n    # create result numpy array with zeros \n    filtered = np.zeros(image.shape)\n    \n    # add padding to image data  \n    image = image_preprocess(image)\n    \n    # get filter from function defined \n    filter_ = average_filter(filter_size)\n    \n    # update filter_size from width of kernel to number of pixels from center to edge of kernel\n    filter_size = int((filter_size - 1) \/ 2)\n    \n    # filter image for every pixels \n    for i in range(1, image.shape[0]-1):\n        for j in range(1, image.shape[1]-1):\n            # initiate result value and get all indices of all edges \n            res = 0\n            left, right = j - filter_size, j + filter_size + 1\n            upper, lower = i - filter_size, i + filter_size + 1\n            \n            # \n            for p, f in zip(range(upper, lower), range(filter_.shape[0])):\n                res += np.dot(filter_[f], image[p][left:right])\n            \n            filtered[i-1][j-1] = res\n    \n    return filtered","e95380ef":"# average filtered image\nave_img = simple_filter_image(image, 3)\nplot_image(ave_img, 'Average filtering')","b44b10db":"'''\nGaussian blur \n'''\n\n# Create Gaussian filter \ndef gaussian_filter(filter_size, sigma):\n    # get numpy array with identical values in both directions (axis)\n    y, x = np.ogrid[-filter_size:filter_size+1, -filter_size:filter_size+1]\n    \n    # get 3 x 3 matrix based on x and y, then use equation shown to compute filter\n    filter_ = np.exp(-(x**2 + y**2) \/ (2 * sigma**2)) \/ (2 * np.pi * sigma**2)\n    \n    # comment out if you want to see what is going on.\n#     print(f'x looks: {x}\\n y looks: \\n{y}\\n')\n#     print('x**2 looks: {0}\\n y**2 looks: \\n{1}\\n'.format(x**2, y**2))\n#     print('By the property of numpy array, x**2 + y**2 is: \\n{}'.format(x**2 + y**2))\n        \n    return filter_\n\n# gaussian blur function \ndef gaussian_blur(image, filter_size, sigma):\n    filtered = np.zeros(image.shape)\n    \n    # add padding to image \n    image = image_preprocess(image)\n    \n    filter_size = int((filter_size - 1) \/ 2)\n    \n    filter_ = gaussian_filter(filter_size, sigma)\n\n    for i in range(1, image.shape[0]-1):\n        for j in range(1, image.shape[1]-1):\n            res = 0\n            left, right = j - filter_size, j + filter_size + 1\n            upper, lower = i - filter_size, i + filter_size + 1\n            \n            for p, f in zip(range(upper, lower), range(filter_.shape[0])):\n                res += np.dot(filter_[f], image[p][left:right])\n                \n            filtered[i-1][j-1] = res\n    \n    return filtered","75278342":"# gaussian filtered image\ngauss_img = gaussian_blur(image, 3, 3)\nplot_image(gauss_img, 'Gaussian filtering')","d69eaf85":"'''\nbilateral filter\n'''\n\ndef bilateral_filtering(image, sigma_d, sigma_r, rc=1e-8):\n    # add padding to image \n    image = image_preprocess(image)\n    \n    # mini function to compute gaussian of datapoint \n    gaussian = lambda val, sigma: (np.exp(-0.5 * val \/ sigma**2))\n    \n    # calculate filter size with sigma_d\n    filter_size = int(3*sigma_d+1)\n    \n    # sum up all things\n    wht_sum = np.ones(image.shape) * rc\n    res = image * rc\n    \n    for i in range(-filter_size, filter_size+1):\n        for j in range(-filter_size, filter_size+1):\n            # weights calculated for distance\n            spatial_wght = gaussian(i**2 + j**2, sigma_d)\n            \n            off = np.roll(image, [i, j], axis=[0, 1])\n            tw = spatial_wght * gaussian((off - image)**2, sigma_r)\n            res += off*tw\n            wht_sum += tw\n    \n    return res \/ wht_sum","01bb55ef":"# bilateral filtered image\nbilateral_img = bilateral_filtering(image, 3, 1)\nplot_image(bilateral_img, 'Bilateral filtering')","afb4ef7f":"# check with same config in opencv\nimport cv2\nplt.imshow(cv2.bilateralFilter(image, 10, 3, 1), 'gray')","400d62fe":"# Generate edge detection kernels \ndef single_edge_filter(kind='normal'):\n    # normal filter\n    if kind == 'normal':\n        F_x = np.array([[0, 0, 0], \n                        [-1, 0, 1], \n                        [0, 0, 0]]) * 0.5\n        \n    # prewitt filter \n    elif kind == 'prewitt':\n        F_x = np.array([[-1, 0, 1], \n                        [-1, 0, 1], \n                        [-1, 0, 1]])\n    \n    # sobel filter\n    elif kind == 'sobel':\n        F_x = np.array([[-1, 0, 1], \n                        [-2, 0, 2], \n                        [-1, 0, 1]])\n    \n    # return filter and transpose of it\n    return (F_x, F_x.T)\n\n# edge detection for image\ndef single_edge_detection(image, kind='normal', thresh=75):\n    # create result numpy array\n    filtered = np.zeros(image.shape)\n    \n    # preprocess the image\n    image = image_preprocess(image)\n    \n    # condition for canny or other process\n    if kind == 'canny':\n        gauss = gaussian_filter(1, 3)\n        sobel_x, sobel_y = single_edge_filter('sobel')\n        filter_x, filter_y = sobel_x * gauss, sobel_y * gauss\n    \n    else:\n        filter_x, filter_y = single_edge_filter(kind)\n        \n    # loop through every pixels \n    for i in range(1, image.shape[0]-1):\n        for j in range(1, image.shape[1]-1):\n            temp_arr = np.array([])\n            left, right = j - 1, j + 2\n            upper, lower = i - 1, i + 2\n            \n            # get 3x3 matrix from image segment\n            for r in range(upper, lower):\n                temp_arr = np.append(temp_arr, image[r][left:right])\n            \n            temp_arr = temp_arr.reshape(3, 3)\n            \n            # get derivative of x and y dirction\n            I_x = np.sum(filter_x * temp_arr)\n            I_y = np.sum(filter_y * temp_arr)\n            \n            # get gradient \n            grad = np.sqrt(I_x**2 + I_y**2)\n            \n            # check for threshold\n            if grad > thresh:\n                filtered[i-1][j-1] = 255\n            else:\n                filtered[i-1][j-1] = 0\n                \n    return filtered","27efe7be":"# normal edge detection\nimage_mug = image_reader(path_mug)\nnormal_img = single_edge_detection(image_mug, 'normal', 15)\nplot_image(normal_img, 'Normal edge detection')","407a2242":"# prewitt edge detection \nprewitt_img = single_edge_detection(image_mug, 'prewitt')\nplot_image(prewitt_img, 'Prewitt edge detection')","d946533a":"# sobel edge detection\nsobel_img = single_edge_detection(image_mug, 'sobel', 100)\nplot_image(sobel_img, 'Sobel edge detection')","f9cfedf2":"# canny edge detection\ncanny_img = single_edge_detection(image_mug, 'canny', 2)\nplot_image(canny_img, 'Canny edge detection')","fce67206":"# double derivative kernels \ndef laplacian_filter(kind='laplacian'):\n    if kind == 'laplacian':\n        filter_ = np.array([[0, 1, 0], \n                        [1, -4, 1], \n                        [0, 1, 0]])\n    elif kind == 'diag_laplacian':\n        filter_ = np.array([[1, 1, 1], \n                [1, -8, 1], \n                [1, 1, 1]])\n        \n    return filter_\n\ndef laplacian_edge_detection(image, kind='laplacian', thresh=20):\n    # get filter\n    filter_ = laplacian_filter(kind)\n    \n    # get result array\n    filtered = np.zeros(image.shape)\n    \n    # preprocess image\n    image = image_preprocess(image)\n    \n    # loop through every pixel \n    for i in range(1, image.shape[0]-1):\n        for j in range(1, image.shape[1]-1):\n            temp_arr = np.array([])\n            left, right = j - 1, j + 2\n            upper, lower = i - 1, i + 2\n            \n            # get matrix for small segment of image\n            for r in range(upper, lower):\n                temp_arr = np.append(temp_arr, image[r][left:right])\n            \n            temp_arr = temp_arr.reshape(3, 3)\n            \n            # calculate gradient\n            grad = np.sum(filter_ * temp_arr)\n            \n            if grad > thresh:\n                filtered[i-1][j-1] = 255\n            else:\n                filtered[i-1][j-1] = 0\n                \n    return filtered","11186ab4":"laplacian_img = laplacian_edge_detection(image_mug, 'laplacian', 20)\nplot_image(laplacian_img, 'Laplacian edged image')","bfccd9ed":"diag_laplacian_img = laplacian_edge_detection(image_mug, 'diag_laplacian', 20)\nplot_image(diag_laplacian_img, 'Diagonal laplacian edged image')","6df512cb":"# LoG filter\nlog_img = laplacian_edge_detection(gaussian_blur(image_mug, 1, 3), 'diag_laplacian', 1)\nplot_image(log_img, 'LoG edged image')","e1155eb3":"Laplacian filters will work, although it is weak with noises. To avoid this, we will smooth the image to remove noises then apply the laplacian filters. Interestingly, this process can be compiled and given a new name, Laplacian of Gaussian filter (LoG filter). \n\n$$(\\nabla^2G(x, y, \\sigma)) * I(x, y)$$\n\n$$\u2193$$\n\n$$LoG(x, y, \\sigma) = -\\frac{1}{\\pi\\sigma^4}(1-\\frac{x^2 + y^2}{2\\sigma^2})exp(-\\frac{x^2 + y^2}{2\\sigma^2})$$\n\nIn implementation, I will not going to use this formula (I will update this notebook afterwards). So I will simply use gaussain blurred image, then apply laplacian filter. ","30df204f":"## 4. Detector\nNow, with several fitlering techniques, we get the data-reduced version of image. What we would like to do now is to touch with detectors. Detectors can be described as \"feature extraction algorithm\". Detectors can usually detects the edge, corner, and blob. I will only focus with edge detector in this notebook since other topics are little bit complicated and will be long if I explain. Specifically, I will focus on first and second derivative edge detection. ","a6f5c4f1":"# <center>Image Recognition from scratch ~ Spatial filtering and edge detection ~<\/center>\n\n![Image%20recognition%20from%20scratch.jpg](attachment:Image%20recognition%20from%20scratch.jpg)\n\nIn some discussion, I found that one keggler mentioned about some competition participants whom lacks the basic knowledge of ML.  This is what I felt about myself recently. I tried to work on some image recognition competition without clear and solid understanding of fundamental knowledge. Thus, I couldn't end up with a good standing. From this frustration and failure, I started to study about it, along implementing it from scratch. The series of notebooks are going to be the records of my output, and also for sharing fundamentals of image recognition with other kagglers. \n \n In this notebook, we will go over the part of local feature extraction, the spatial filtering and edge detectors. Since a lot of information will be included, I will work on uncovered topics in other notebooks. \n \n Note: This notebook is only for learning \/ educational purposes and cannot be used for competitions or other technical use (since it is not intended to be used in practical ways). Most of them can be done by using openCV or other libraries in much clean and faster way. Also, I violated DRY to make it easy-to-read and show the process.","203784d2":"### 4.2. Edge detectors with second derivative\nAlso, we can accomplish edge detection using second derivative. Mathematically, second derivative of image can be derived by:\n\n$$I_{xx}(x, y) = {I(x+1, y) - I(x, y)} - {I(x, y) - I(x-1, y)}$$\n$$= I(x+1, y) + I(x-1, y) - 2I(x, y)$$\n\n$$I_{yy}(x, y) = {I(x, y+1) - I(x, y)} - {I(x, y) - I(x, y-1)}$$\n$$= I(x, y+1) + I(x, y-1) - 2I(x, y)$$\n\nThen add both values to get **Laplacian**: $$\\nabla^2 = \\frac{\\partial}{\\partial x^2} + \\frac{\\partial}{\\partial y^2}$$\n\nThus the $\\nabla^2$ will be: $$\\nabla^2 = I(x+1, y) + I(x-1, y) + I(x, y+1) + I(x, y-1) - 4I(x, y)$$\n\nFrom this, we will get the filter (we will call this a Laplacian filter): \n\n$$F = \\begin{bmatrix}\n0 & 1 & 0 \\\\\n1 & -4 & 1 \\\\\n0 & 1 & 0\n\\end{bmatrix}$$\n\nAlso, we can get filter considering diagonal direction: \n\n$$F = \\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}$$","2f1bf38d":"### 3.7. Bilateral filter\nNow we have better filter, a gaussian filter. Although this filter reduce noises, it scrapes some significant features from data, like the edge. To prevent this, we would like to create some algorithm that obtains better outputs. Therefore, we need to look out beyond the linear filtering, the non-linear filtering. Non-linear filtering is filtering technique that transforms filter based on data. One of them is called **bilateral filter**. Bilateral filter coputes its weights by considering distance from origin as did in gaussian, and the difference of luminosity between origin pixel and neighboring pixels.\n\n**Math for bilateral filter** \n\n$$\\hat{I}(x, y) = \\frac{\\sum\\limits_{i=-N}^{N} {\\sum\\limits_{j=-N}^{N} {W(x, y, i, j) I(x+j, y+i)}}}{\\sum\\limits_{i=-N}^{N} {\\sum\\limits_{j=-N}^{N} {W(x, y, i, j)}}}$$\n\nwhere W(x, y, i, j) as;\n$$W(x, y, i, j) = exp(-\\frac{(x-j)^2 + (y-i)^2}{2\\sigma_{d}^2} - \\frac{||I(x, y) - I(j, i)||^2}{2\\sigma_{r}^2})$$\n\n$\\sigma_{d}^2$ is the varaince of domain (pixel index) kernel, and $\\sigma_{r}^2$ is the variance of range (intensity value) kernel. As I explained, in filter W, we consider both distance and luminosity difference. Also with usual operation of filter * value, it normalizes with sum of elements in filter. \n\n**Coding issue and solution**\n\nNow, I will not recommend you to reuse previous solution to construct algorithm for bilateral filter, since it will contain four loops (algorithmically, O(N^4) calculation cost for maximum). Thus, we would like to come out something different to avoid this massive calculation cost. With only two loops nested, we will do: \n\n1. compute gaussian for distance between origin and neighboring pixels\n2. shift image pixels with roll method in direction of (i, j)\n3. compute gaussian for difference of instensity by taking difference between shifted and original image \n4. multiply two gaussian weights (call this as tw)\n5. multiply shifted image with tw, and add to result matrix\n6. add tw to weight sum \n7. after all loops are done, return result matrix \/ weighted sum","94bf08ae":"### 4.1. Edge detectors with first derivative \nIntuitively, we define edge as a point where intensity changes a lot. In grayscale, point with black on right and white on left can be seen as an edge. From this intuition, we can compute the difference of intensity with respect to horizontal and vertical direction. \n\n**Math**\n\nWe will use a concept of first derivative. Since pixels are discrete values, we will take difference of one pixel in both directions: \n\n$$f'(x) = f(x+1) - f(x)$$\n$$f'(x) = f(x) - f(x-1)$$\n\nWe can take average of both derivatives, so:\n\n$$f'(x) = \\frac{f(x+1) - f(x-1)}{2}$$\n\nSince image has horizontal and vertical directions, we would like to have partial derivative with respect to both directions.\nLet I be an image, and $I_{x}, I_{y}$ are the derivatives. \n\n$$I_{x} = \\frac{I(x+1, y) - I(x-1, y)}{2}$$\n\n$$I_{y} = \\frac{I(x, y+1) - I(x, y-1)}{2}$$\n\nNow we compute the value of derivative, and if this value is greater than arbitrary threshold, target pixel will be determined as an edge. Value of derivative can be derived by; \n\n$$|\\nabla I| = \\sqrt{I_{x}^2 + I_{y}^2}$$\n\n$$\\hat{I}(x, y) = \n    \\left\\{\n    \\begin{array}{ll}\n        255 & \\mbox{if } |\\nabla I| > t \\\\\n        0 & \\mbox{else}\n    \\end{array}\n\\right.$$\n\n**Convert idea to filter**\n\nNow we can create several filters which are based on an idea we just discussed.\n\n1. **Normal filter**: straightforward filter based on idea above. \n\n$$F_{x} = \\frac{1}{2} \n\\begin{bmatrix}\n0 & 0 & 0 \\\\\n-1 & 0 & 1 \\\\\n0 & 0 & 0\n\\end{bmatrix}$$\n\n$$F_{y} = \\frac{1}{2} \n\\begin{bmatrix}\n0 & -1 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}$$\n\n2. **Prewitt filter**: Since normal filter is weak to the irregular noises, we take derivative of neighboring pixels and take average of it. \n\n$$F_{x} = \n\\begin{bmatrix}\n-1 & 0 & 1 \\\\\n-1 & 0 & 1 \\\\\n-1 & 0 & 1\n\\end{bmatrix}$$\n\n$$F_{y} =  \n\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n0 & 0 & 0 \\\\\n1 & 1 & 1\n\\end{bmatrix}$$\n\n3. **Sobel filter**: Prewitt filter is strong to irregular noises, but does not pay special attention to target pixel. Thus, Sobel filter gives more weights on target pixel. \n\n$$F_{x} = \n\\begin{bmatrix}\n-1 & 0 & 1 \\\\\n-2 & 0 & 2 \\\\\n-1 & 0 & 1\n\\end{bmatrix}$$\n\n$$F_{y} =  \n\\begin{bmatrix}\n-1 & -2 & -1 \\\\\n0 & 0 & 0 \\\\\n1 & 2 & 1\n\\end{bmatrix}$$\n\n**Canny edge detector**\n\nUsing sobel filter on gaussian (smoothed) image allows us to detect appropriate edge on image. We will also implement this. ","d99caf3d":"### 3.5. Averaging filter \nAs you saw in previous section, filtering is all about \"taking weighted average of small segment of image, where segment places target pixel on middle of them\". Thus, in this context, filter is just a matrix containing the weights. If we treat all pixels in segment we are focusing equally, this is where average fltering comes in. (Sometimes it's called mean filtering, but whichever should work.) \n\nSince we are treating all pixels in segment equally, weights in filter should be equal. To achieve this, we simply divide (N x N) matrix of ones by the number of pixel in segmet $N^2$. Mathematically, we can express this as: \n\n$$\\frac{1}{N^2} \n\\begin{bmatrix}\n1 & 1 & ... & 1 \\\\\n1 & 1 & ... & 1 \\\\\n... & ... & ... & ... \\\\\n1 & 1 & ... & 1\n\\end{bmatrix}$$\n\nWe will fix N as 3 for easy this time.\n\n*Algorithm*: \n1. load filter \n2. nested loop through every pixels (row for outer loop and column for inner loop) \n3. get edge pixel index based on current target pixel index and kernel size\n4. manipulate matrix for segment of image which has equal shape with kernel size \n5. multiply filter and segment matrices and get sum of all elements \n6. replace corresponded pixel in numpy array of zeros with result","c555381f":"### 3.4. Add padding\n\nThe problem of filtering is that you cannot cover the side edges of image since filter has its own size and cannot allocate their center to edge pixel of image. The solution to this is to add a **padding** to image. Padding here means to surround image with pixels of value 0. Doing this allows us to allocate filter to original edge of image, and does not affect the result of computation since all values on padding is 0.  ","4ff795da":"## 2. Fundamental works\n\nBefore we go into theories and implementations, we define image loader function and image plot function. Also, we check the image which we are going to use repeatedly.","a7dfe2af":"# Hope this helps. Upvotes and feedbacks are appreciative. ","688c0722":"## 1. Libraries","e0bac0d8":"## 3. Spatial filtering (filtering)\n\n### 3.1. What's spatial filtering? \nWithout major loss of data from image, we would like to extract the data from image. Spatial filtering allows us to reduce amount of data from image without a fatal loss of data. Usually a preprocessing of image before edge,corner, blob detection.\n\n### 3.2. How are we going to achieve this? \nCompile data from target pixel and its peripheral pixels into a single pixel for new data. This allows us to create new image with less amout of data without major loss. There are linear and non-linear spatial filtering. We are going to cover linear one.\n\n### 3.3. Important concepts: Kernel \/ Filter and how it works in process\nAs you can see from name of \"spatial filtering\", we would like to \"filter out\" the image to reduce amount of data. Thus, we will need actual \"filter(kernel)\" to achieve that. \"Filter(kernel)\" is the (2N+1, 2N+1) array of values which covers target pixel and its neighbor pixels. By multiplying corresponding values of filter and pixels, then adding everything up, we will get a value of one pixel for new (filtered) data. \n\n![spatial%20filtering.jpg](attachment:spatial%20filtering.jpg)\n\nMathematically, we can express this process like: \n\n$$\\hat{I}(x, y) = \\sum\\limits_{i=-N}^{N} {\\sum\\limits_{j=-N}^{N} {F(j, i) I(x+j, y+i)}}$$\n\nwhere: \n* i for row index\n* j for column index\n* N for number of pixel from center of filter to the edge\n* F for filter matrix\n* I for matrix from image \n\nAs you can see, what linear image filtering is doing is that it goes over the small segment of image which fits with filter size. Then for each corresponding pixels, they multiply luminance of image and weights in filter. Finally, they add all of multiplied values to get new pixel's luminance. This idea goes along with any linear image filtering, and the usual difference between algorithms is only a difference of filter (kernel) they are using.\n\nAs a short summary, spatial filtering is a **recursive process that takes weighted sum of small segment of image, where segment places target pixel as a center**. ","b6f70301":"### 3.6.Gaussian filtering (blur)\n\nAlthough the averaging filter is a good filtering method, it does not reflects the significance of target pixel since it treats every pixels in the segment equally. To express the significance of target pixel, we can use a **gaussian filter**. A gaussian filter is a filter that is created based on gaussian distribution. Due to the property of gaussian distribution, **weights in filter and distance from center pixel are in proportional relationship**. This means that target pixel will gain a maximum weight (attention) and others will get less weights (attentions). \n\nMathematically, we can express the filter by:\n\n$$G(x, y, \\sigma) = \\frac{1}{2\\pi\\sigma^2} exp( -\\frac{x^2 + y^2}{2\\sigma^2} )$$\n\nwhere x, y as the distance from origin (center) in horizontal \/ vertical direction, and sigma as a scale, which is a scaling factor that decides the area of smoothing.\n\n*Algorithm*: \n\nAs I mentioned, basic algorithm is almost same from what we have used from previous section. In aspect of coding, I just changed a filter and added parameter to generate a filter."}}