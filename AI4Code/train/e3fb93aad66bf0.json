{"cell_type":{"9e8ac77d":"code","6077d8cc":"code","2a094840":"code","0ca624c6":"code","4f411a97":"code","4dc081ce":"code","5ba988c7":"code","281783fa":"code","de7b219e":"code","53fa0c72":"code","413171cf":"code","fda9cf68":"code","c565e0d7":"code","ca5df8e4":"code","1f16e687":"code","ff5dcac9":"code","dfc1536a":"code","24219fec":"code","5726bfed":"code","328acebc":"code","0921859d":"code","0a71cc76":"code","974cf69d":"code","11fcb548":"code","71128ec7":"code","406d3f00":"code","be29f7fb":"code","1385cac9":"code","2f529271":"code","755801fc":"code","e27a285e":"code","71bacf8a":"code","3af8241e":"code","781c58c9":"code","12340521":"code","b17814ed":"code","d59e28e7":"code","ae997cea":"code","4b9a5471":"code","264e9364":"code","537df6a1":"code","62374cb7":"code","582317e3":"code","0439fb52":"code","8cf2a1d8":"code","54f63e34":"code","11b31fc7":"code","8ec24398":"code","f9589f5d":"code","305d11a1":"code","08c45956":"code","d797bc35":"code","4e4d0a2b":"code","0fae18d7":"code","e9f509a2":"code","198c4599":"code","d1b8c71a":"code","aeba746c":"code","c0e1898b":"code","7158293a":"code","5a2d1f1a":"code","8bb8e62e":"code","5fe39790":"code","9f10ddd1":"code","6538f1cd":"code","0315ea65":"code","ecc9d2e9":"code","61038b3d":"code","5dcf5989":"code","846616fe":"markdown","4d0247b4":"markdown","8c3152f7":"markdown","3ae8f168":"markdown","cb5fcbf3":"markdown","bd2762f5":"markdown","51075973":"markdown","80ab7ab2":"markdown","34a499c3":"markdown","b3665417":"markdown","216a242c":"markdown","f9e91ca2":"markdown","c3c653e1":"markdown","34a69e42":"markdown","c574c08a":"markdown","5f1696bb":"markdown","5c96ec10":"markdown","0223184e":"markdown","d567033e":"markdown","29cfcceb":"markdown","7b30e8fc":"markdown","aa9f2c59":"markdown","a758019f":"markdown","927a05e2":"markdown","65329ae1":"markdown"},"source":{"9e8ac77d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","6077d8cc":"test = pd.read_csv('..\/input\/carpredict\/q1-mys-auto.csv')","2a094840":"print(test.head())","0ca624c6":"#missing data\ntotal_test = test.isnull().sum().sort_values(ascending=False)\npercent_test = (test.isnull().sum()\/test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total_test, percent_test], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)\n","4f411a97":"#dealing with missing data\ntest = test.drop((missing_data[missing_data['Total'] > 400]).index,1)\n\ntest.isnull().sum().sort_values(ascending=False).head(10)","4dc081ce":"# Categorical boolean mask\ncategorical_feature_mask = test.dtypes==object\n# filter categorical columns using mask and turn it into alist\ncategorical_cols = test.columns[categorical_feature_mask].tolist()\n","5ba988c7":"categorical_cols","281783fa":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ntest[categorical_cols] = test[categorical_cols].apply(lambda col: labelencoder.fit_transform(col.astype(str)))\n","de7b219e":"test.head()","53fa0c72":"test.isnull().sum().sort_values(ascending=False).head(10)","413171cf":"test1 = pd.read_csv('..\/input\/carpredict\/q1-mys-auto.csv')\ntest1 = test1.dropna()\ntest1 = test1.reset_index(drop=True)\n","fda9cf68":"sns.distplot(test1['CAR_SALE_PRICE'], fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(test1['CAR_SALE_PRICE'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(test1['CAR_SALE_PRICE'], plot=plt)\nplt.show() ","c565e0d7":"corr = test1.corr()","ca5df8e4":"plt.figure(figsize=(30,8))\nsns.heatmap(test1.corr(),cmap='coolwarm',annot = True)\nplt.show()","1f16e687":"corr[corr['CAR_SALE_PRICE']>0.3].index\n","ff5dcac9":"test1.info()","dfc1536a":"\ntest1=test1[[ 'CAR_SALE_PRICE','CAR_LENGTH', 'CAR_WIDTH', 'CAR_ENGINE_SIZE', 'CAR_ENGINE_BORE',\n       'CAR_ENGINE_POWER', 'CAR_WHEEL_BASE', 'CAR_CURB_WEIGHT','CAR_BRAND','CAR_BODY_STYLE', 'CAR_DRIVE_WHEELS','CAR_ENGINE_LOC','CAR_FUEL_TYPE','CAR_FUEL_SYSTEM'\n      ]]","24219fec":"sns.lmplot(x='CAR_WIDTH',y='CAR_SALE_PRICE',data=test1) # CAR_WIDTH seems very corelated with CAR_SALE_PRICE.","5726bfed":"sns.lmplot(x='CAR_LENGTH',y='CAR_SALE_PRICE',data=test1) # CAR_LENGTH ALSO very corelated with CAR_SALE_PRICE.","328acebc":"plt.scatter(x= 'CAR_ENGINE_SIZE', y='CAR_SALE_PRICE', data = test1)","0921859d":"plt.scatter(x='CAR_ENGINE_BORE',y='CAR_SALE_PRICE',data=test1)","0a71cc76":"plt.figure(figsize=(25,8))\nsns.boxplot(x='CAR_ENGINE_POWER',y='CAR_SALE_PRICE',data=test1)\nplt.show()","974cf69d":"sns.lmplot(x='CAR_CURB_WEIGHT',y='CAR_SALE_PRICE',data=test1)\n","11fcb548":"sns.lmplot(x='CAR_WHEEL_BASE',y='CAR_SALE_PRICE',data=test1)","71128ec7":"plt.figure(figsize=(25,8))\nsns.barplot(x='CAR_BRAND',y='CAR_SALE_PRICE',data=test1)\nplt.show()","406d3f00":"plt.figure(figsize=(10,5))\nsns.barplot(x='CAR_BODY_STYLE',y='CAR_SALE_PRICE',data=test1)\nplt.show()","be29f7fb":"plt.figure(figsize=(8,5))\nsns.barplot(x='CAR_DRIVE_WHEELS',y='CAR_SALE_PRICE',data=test1)\nplt.show()","1385cac9":"plt.figure(figsize=(4,4))\nsns.barplot(x='CAR_ENGINE_LOC',y='CAR_SALE_PRICE',data=test1)\nplt.show()","2f529271":"plt.figure(figsize=(5,4))\nsns.barplot(x='CAR_FUEL_TYPE',y='CAR_SALE_PRICE',data=test1)\nplt.show()","755801fc":"plt.figure(figsize=(15,5))\nsns.barplot(x='CAR_FUEL_SYSTEM',y='CAR_SALE_PRICE',data=test1)\nplt.show()","e27a285e":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\nplt.figure(figsize=(16,8))\ncorrmat = test1.corr()\n# picking the top 7 correlated features\ncols = corrmat.nlargest(k, 'CAR_SALE_PRICE')['CAR_SALE_PRICE'].index\ncm = np.corrcoef(test1[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","71bacf8a":"test2 = test1[cols]","3af8241e":"cols","781c58c9":"test2.head()","12340521":"#test['CAR_ENGINE_SIZE'] = test['CAR_ENGINE_SIZE'].fillna(test['CAR_ENGINE_SIZE'].mean())\n","b17814ed":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(test2.drop('CAR_SALE_PRICE', axis=1), test2['CAR_SALE_PRICE'], test_size=0.3, random_state=101)","d59e28e7":"# we are going to scale to data\n\ny_train= y_train.values.reshape(-1,1)\ny_test= y_test.values.reshape(-1,1)\n\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_y = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.fit_transform(X_test)\ny_train = sc_X.fit_transform(y_train)\ny_test = sc_y.fit_transform(y_test)","ae997cea":"X_test","4b9a5471":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()","264e9364":"lm.fit(X_train,y_train)\nprint(lm)\n","537df6a1":"# print the intercept\nprint(lm.intercept_)","62374cb7":"print(lm.coef_)","582317e3":"predictions = lm.predict(X_test)\npredictions= predictions.reshape(-1,1)","0439fb52":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,predictions)\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","8cf2a1d8":"from sklearn import metrics","54f63e34":"print('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","11b31fc7":"from sklearn import ensemble\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import mean_squared_error, r2_score","8ec24398":"params = {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2,\n          'learning_rate': 0.05, 'loss': 'ls'}\nclf = ensemble.GradientBoostingRegressor(**params)\n\nclf.fit(X_train, y_train)","f9589f5d":"clf_pred=clf.predict(X_test)\nclf_pred= clf_pred.reshape(-1,1)","305d11a1":"print('MAE:', metrics.mean_absolute_error(y_test, clf_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, clf_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, clf_pred)))","08c45956":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,clf_pred, c= 'brown')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","d797bc35":"from sklearn.tree import DecisionTreeRegressor\ndtreg = DecisionTreeRegressor(random_state = 100)\ndtreg.fit(X_train, y_train)\n","4e4d0a2b":"dtr_pred = dtreg.predict(X_test)\ndtr_pred= dtr_pred.reshape(-1,1)","0fae18d7":"print('MAE:', metrics.mean_absolute_error(y_test, dtr_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, dtr_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, dtr_pred)))","e9f509a2":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,dtr_pred,c='green')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","198c4599":"from sklearn.svm import SVR\nsvr = SVR(kernel = 'rbf')\nsvr.fit(X_train, y_train)\n","d1b8c71a":"svr_pred = svr.predict(X_test)\nsvr_pred= svr_pred.reshape(-1,1)","aeba746c":"print('MAE:', metrics.mean_absolute_error(y_test, svr_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, svr_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, svr_pred)))","c0e1898b":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,svr_pred, c='red')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","7158293a":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators = 100, random_state = 0)\nrfr.fit(X_train, y_train)\n","5a2d1f1a":"rfr_pred= rfr.predict(X_test)\nrfr_pred = rfr_pred.reshape(-1,1)","8bb8e62e":"print('MAE:', metrics.mean_absolute_error(y_test, rfr_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, rfr_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rfr_pred)))","5fe39790":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,rfr_pred, c='orange')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","9f10ddd1":"import lightgbm as lgb","6538f1cd":"model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.1, n_estimators=500,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","0315ea65":"model_lgb.fit(X_train,y_train)","ecc9d2e9":"lgb_pred = model_lgb.predict(X_test)\nlgb_pred = lgb_pred.reshape(-1,1)","61038b3d":"print('MAE:', metrics.mean_absolute_error(y_test, lgb_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, lgb_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, lgb_pred)))","5dcf5989":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,lgb_pred, c='orange')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","846616fe":"The values of 'CAR_LENGTH', 'CAR_WIDTH', 'CAR_ENGINE_SIZE', 'CAR_ENGINE_BORE','CAR_ENGINE_POWER', 'CAR_WHEEL_BASE', 'CAR_CURB_WEIGHT' are propotional to CAR_SALE_PRICE","4d0247b4":"we can see the most corelated parameters in numerical values above plotting. And we can pick these as features for our macine learning model.","8c3152f7":"Read files and analyses the info","3ae8f168":"* # Data Visualization\n## b) statistical analysis","cb5fcbf3":"<a id=\"1\"><\/a> <br>\n# **Decision Tree Regression **","bd2762f5":"> ![](http:\/\/)The car sale price value is left skewed. We need to make this normal distributed.","51075973":"## c) Regression Models\n<a id=\"1\"><\/a> <br>\n# **Linear Regression **\n\nLet's now begin to train out regression model! We will need to first split up our data into an X array that contains the features to train on, and a y array with the target variable, in this case the Price column. We will toss out the Address column because it only has text info that the linear regression model can't use.","80ab7ab2":"We droped some columns that less than 0.3 of correlation of Sale Prices.","34a499c3":"<a id=\"1\"><\/a> <br>\n# **Random Forest Regression **","b3665417":"<a id=\"1\"><\/a> <br>\n# **Gradient Boosting Regression **\n","216a242c":"<a id=\"1\"><\/a> <br>\n### **Creating and Training the Model **","f9e91ca2":"# LightGBM","c3c653e1":"RWD car drive wheel in highest CAR_SALE_PRICE","34a69e42":"MPFI AND IDI CAR_FUEL_SYSTEM in higher CAR_SALE_PRICE\n\n## Feature Engineering\nNow we are going to pick some features for the model. For this we are going to use correlation matrix and we are going to pick most correlated with car sale price.","c574c08a":"* Convertible and Hardtop car lead to higher CAR_SALE_PRICE","5f1696bb":"Jeep, BMW, Renault and Mercedes-Benz are the car brand in higher price","5c96ec10":"<a id=\"1\"><\/a> <br>\n### **Predictions from our Model **\nLet's grab predictions off our test set and see how well it did!","0223184e":"the car sale price of rear car engine is plenty much higher than Front car engine","d567033e":"Let's look at the point of visualization","29cfcceb":"We'll be trying to predict car price with regression models. \n### Question 1: Data Analysis\n**Let's get started!**\n### a)\tClean and format the dataset\nWe've been able to get data.let's get our environment ready with the libraries we'll need and then import the data!\n### Import Libraries","7b30e8fc":"<a id=\"1\"><\/a> <br>\n### **Model Evaluation **\nLet's evaluate the model by checking out it's coefficients and how we can interpret them.","aa9f2c59":"<a id=\"1\"><\/a> <br>\n### **Train Test Split **\nNow let's split the data into a training set and a testing set. We will train out model on the training set and then use the test set to evaluate the model.","a758019f":"\nThe decision tree is a simple machine learning model for getting started with regression tasks.\n\n**Background**\nA decision tree is a flow-chart-like structure, where each internal (non-leaf) node denotes a test on an attribute, each branch represents the outcome of a test, and each leaf (or terminal) node holds a class label. The topmost node in a tree is the root node. (see here for more details).\n\n","927a05e2":"<a id=\"1\"><\/a> <br>\n# **Support Vector Machine Regression **","65329ae1":"We are going to convert test data. Before this we clean the colunm of missing value"}}