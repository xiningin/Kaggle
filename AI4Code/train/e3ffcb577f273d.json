{"cell_type":{"1177851f":"code","22eabc3b":"code","4cf9e546":"code","955fe3a9":"code","040b7d84":"code","14de7679":"code","e34fe783":"code","a8037653":"code","61322bf2":"code","15349e05":"code","16af8e67":"code","9fdcd22b":"code","01451ff3":"code","cabc10d9":"code","341580d9":"code","1c3e0fa4":"code","52893135":"code","d7ba5767":"code","54a6e723":"code","11ad6e74":"code","7b55b022":"code","6dc4eb80":"code","b5db30d7":"code","4b9c9014":"code","5c1c6549":"code","36f494a4":"code","a3bf88c7":"code","518e893b":"code","791314be":"code","a179649c":"code","1a56947d":"code","23b3af7f":"code","54f94513":"code","b0cbc3b9":"code","6965a628":"code","2992d1e9":"code","7c3a29f9":"code","bf3cb788":"code","f4da05e5":"code","f44fb484":"code","dd8361a7":"code","aa26f91f":"code","5cafe129":"code","293f8c35":"code","8cce7a2f":"markdown","c1b6cc1a":"markdown","53507b52":"markdown","bae65a32":"markdown","8dc09165":"markdown","787a299c":"markdown","97dcd2a6":"markdown","61593284":"markdown","91cc366b":"markdown","802c395d":"markdown","0724c52b":"markdown","c6e09ad1":"markdown","e9871422":"markdown","4f5452fe":"markdown","bdcdf002":"markdown","19c49172":"markdown","80b2e256":"markdown","d4e2edf0":"markdown","c05c56f0":"markdown","d7b730ad":"markdown","13f9485a":"markdown","205eaa08":"markdown","4f015e15":"markdown"},"source":{"1177851f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport os\n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input di\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22eabc3b":"import cv2\npath='\/kaggle\/input\/butterfly-dataset\/leedsbutterfly\/images\/'\nfile=os.listdir('\/kaggle\/input\/butterfly-dataset\/leedsbutterfly\/images\/')\nfeatures=[] #to store images\nlabels=[] #to store labels\nfor img in file:\n    label=int(img[:3]) #extracting labels from the image\n    labels.append(label)\n    img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_COLOR)\n    img_array=cv2.resize(img_array,(220,220))\n    features.append(img_array)\n\n       ","4cf9e546":"dict_1={'001': 'Danaus_plexippus', '002': 'Heliconius_charitonius', '003': 'Heliconius_erato', '004': 'Junonia_coenia', '005': 'Lycaena_phlaeas', '006': 'Nymphalis_antiopa', '007': 'Papilio_cresphontes', '008': 'Pieris_rapae', '009': 'Vanessa_atalanta', '0010': 'Vanessa_cardui'} ","955fe3a9":"print(set(labels))","040b7d84":"list_labels=[]\nfor i in labels:\n    new_label=dict_1['00'+str(i)]\n    list_labels.append(new_label)\nprint(list_labels[:10])    ","14de7679":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=np.random.randint(0,len(labels))\n        ax[i,j].imshow(features[l])\n        ax[i,j].set_title( \"Butterfly: \" +str(list_labels[l]))\nplt.axis('off')        \nplt.tight_layout()\n","e34fe783":"sns.set_style('whitegrid')\nplt.figure(figsize=(20,12))\nfig=sns.countplot(list_labels,linewidth=5)\nplt.xlabel('BUTTERFLY SPECIES')\nplt.show()","a8037653":"features=np.array(features)\nfeatures=features\/255.0","61322bf2":"features=features.reshape(-1,220,220,3)\n","15349e05":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nle=LabelEncoder()\ny=le.fit_transform(list_labels)\n\n","16af8e67":"from tensorflow.keras.utils import to_categorical\ny=to_categorical(y)","9fdcd22b":"y.shape","01451ff3":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(features,y,random_state=11,test_size=0.2)","cabc10d9":"from tensorflow.keras.layers import Dense,MaxPooling2D,Conv2D,Dropout,Flatten\nfrom tensorflow.keras.models import Sequential\nfrom keras.optimizers import Adam\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (5,5), activation = 'relu', input_shape=(220,220,3)))\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu')) \nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu')) \nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu')) \nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu')) \nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(256, activation='relu'))\n\nmodel.add(Dense(10, activation='softmax'))","341580d9":"model.compile(optimizer='adam'\n              ,metrics=['accuracy'],loss='categorical_crossentropy')","1c3e0fa4":"model.summary()","52893135":"history=model.fit(x_train,y_train,batch_size=12,epochs=100,validation_split=0.2)","d7ba5767":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy score')\nplt.title('Model Accuracy')\nplt.legend(['Train','Test'])\nplt.show()","54a6e723":"sns.set_style('darkgrid')\nplt.figure(figsize=(12,8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\nplt.legend(['Train','Test'])\nplt.show()","11ad6e74":"loss,accuracy=model.evaluate(x_test,y_test)","7b55b022":"preds=model.predict(x_test)\n","6dc4eb80":"predictions=np.argmax(preds,axis=1)","b5db30d7":"correct_labels=[] # for storing the correct predictions\nincorrect_labels=[] # for storing the incorrect predictions\n\n\n#for testing which predictions went wrong\n\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])!=predictions[i]):\n        incorrect_labels.append(i)\n    if len(incorrect_labels)==10:\n        break","4b9c9014":"# for testing which predictions are accurate\n\nfor i in range(len(y_test)):\n    if (np.argmax(y_test[i])==predictions[i]):\n        correct_labels.append(i)\n    if len(correct_labels)==10:\n        break","5c1c6549":"\n\ncount=0\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range (5):\n    for j in range (2):\n        ax[i,j].imshow(x_test[correct_labels[count]])\n        ax[i,j].set_title(\"Predicted butterfly : \"+ list_labels[predictions[correct_labels[count]]] +\"\\n\"+\"Actual butterfly : \"+ list_labels[np.argmax(y_test[correct_labels[count]])])\n        plt.tight_layout()\n        count+=1","36f494a4":"count=0\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range(2):\n        ax[i,j].imshow(x_test[incorrect_labels[count]])\n        ax[i,j].set_title(\"Predicted butterfly : \" + list_labels[predictions[incorrect_labels[count]]] + \"\\n\"+\"Actual butterfly : \" +list_labels[np.argmax(y_test[incorrect_labels[count]])])\n        plt.tight_layout()\n        count+=1","a3bf88c7":"import tensorflow\nmnet = tensorflow.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, \n                                                      input_shape=(220, 220, 3),#same as of custom model\n                                                      pooling='avg',\n                                                      weights='imagenet')\n\nmnet.summary()","518e893b":"model2=Sequential([\n    mnet,\n    Dropout(0.25),\n    Dense(10,activation='softmax') # here we use 10 layers because we have to predict bewtween 10 classes\n])","791314be":"model2.layers[0].trainable = False\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])","a179649c":"history2=model2.fit(x_train,y_train,batch_size=12, epochs=100,validation_split=0.3)","1a56947d":"loss,accuracy=model2.evaluate(x_test,y_test)","23b3af7f":"sns.set_style('darkgrid')\nplt.figure(figsize=(12,8))\nplt.plot(history2.history['acc'])\nplt.plot(history2.history['val_acc'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy score')\nplt.title('Model Accuracy')\nplt.legend(['Train','Test'])\nplt.show()","54f94513":"sns.set_style('darkgrid')\nplt.figure(figsize=(12,8))\nplt.plot(history2.history['loss'])\nplt.plot(history2.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\nplt.legend(['Train','Test'])\nplt.show()","b0cbc3b9":"preds2=model2.predict(x_test)","6965a628":"predictions2=np.argmax(preds2,axis=1)","2992d1e9":"correct_preds=[] #to store correct predictions\nincorrect_preds=[] # to store incorrect predictions\n\n# for testing incorrect predictions\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])!=predictions2[i]):\n        incorrect_preds.append(i)\n    if len(incorrect_preds)==10:\n        break","7c3a29f9":"print(len(incorrect_preds))","bf3cb788":"\n#for correct predictions\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])==predictions2[i]):\n        correct_preds.append(i)\n    if len(correct_preds)==10:\n        break","f4da05e5":"count=0\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range (5):\n    for j in range (2):\n        ax[i,j].imshow(x_test[correct_preds[count]])\n        ax[i,j].set_title(\"Predicted butterfly : \"+ list_labels[predictions2[correct_preds[count]]] +\"\\n\"+\"Actual butterfly : \"+ list_labels[np.argmax(y_test[correct_preds[count]])])\n        plt.tight_layout()\n        count+=1","f44fb484":"count=0\nfig,ax=plt.subplots(2,2)\nfig.set_size_inches(10,10)\nfor i in range(2):\n    for j in range(2):\n        ax[i,j].imshow(x_test[incorrect_preds[count]])\n        ax[i,j].set_title(\"Predicted butterfly : \" + list_labels[predictions2[incorrect_preds[count]]] + \"\\n\"+\"Actual butterfly : \" +list_labels[np.argmax(y_test[incorrect_preds[count]])])\n        plt.tight_layout()\n        count+=1","dd8361a7":"import requests # for generating http requests\nfrom PIL import Image\nfrom io import BytesIO\n\ndef process_image(url):\n    response=requests.get(url)\n    img=Image.open(BytesIO(response.content))\n    fix,ax=plt.subplots(1,3,figsize=(15,20))\n    ax[0].imshow(img)\n    ax[0].set_title('image')\n    \n    #grayscale and normalization\n    img=np.array(img)\n    img=cv2.cvtColor(img,cv2.IMREAD_COLOR)\n    print(img.shape)\n    img=img\/255.0\n    ax[1].imshow(img)\n    ax[1].set_title('color image')\n    \n    #resizing\n    img=cv2.resize(img,(220,220))\n    print(img.shape)\n    ax[2].imshow(img)\n    ax[2].set_title('predicted image')\n    plt.tight_layout()\n    img=np.expand_dims(img,axis=0)\n    #making it model ready\n    print(img.shape)\n    return img","aa26f91f":"#predictions\ndef predict(url):\n    img=process_image(url)\n    label=model.predict(img)\n    final_1=np.argmax(label,axis=1)[0]\n    plt.xlabel(list_labels[final_1])\n    return list_labels[final_1]","5cafe129":"predict('https:\/\/media1.picsearch.com\/is?qxlz1LhMfQh73j377t9Yu40tRz2PO0Zm_KZ08yMEnLY&height=248')","293f8c35":"predict('https:\/\/media5.picsearch.com\/is?pljEx0l_3lB284vBBE4XXxioAfoTjCDQWfUqy5wnMWY&height=272')","8cce7a2f":"### lets first begin with importing the data from directories and converting images to array and labels","c1b6cc1a":"#### mapping the labels with their species","53507b52":"### visualizing the incorrect predictions , here one thing we can observe that our model predicts 'Papilo cresphontes' in three cases ,which leads to conclude that our model is little prone to overfitting because 'Papilo cresphontes' is the class with second largest frequency count","bae65a32":"### visualizing the distribution of classes, here we can observe that class Nymphalis_antiopa has highest frequency and Pieris_rapae has lowest","8dc09165":"### after preprocessing the data we can visualize our dataset ,here we selected 10 random images from the dataset and plotted with their appropriate labels","787a299c":"### lets analyse the predictions generated by our custom model, here we are testing our model on 10 images","97dcd2a6":"## Model Building:here we are going to two models -custom model and pre trained model.\n### Lets begin with the custom model","61593284":"### visualizing the incorrect predictions of model2 ","91cc366b":"Well this is for experiment and have fun with the model you have built.You can load images from the internet and predict using the code written below\n\n","802c395d":"### now we have to convert images into numpy array format,and then normalize it","0724c52b":"### visualizing the correct predictions of model2","c6e09ad1":"### OneHotEncoding:To deal with categorical values we need to preprocess it using onehot ecnoding","e9871422":"### below you can see that the no of incorrect predictions in only just 5 ,shows the model is performing quite well","4f5452fe":"#### we can observe that our custom model gives a very good accuracy of 87 % on both train and test data,but if we want to increase the accuracy we can also use the pre trained models","bdcdf002":"### so we are done with all the preprocessing ,now we have to split our data into train and test set  ","19c49172":"### To avoid overfitting and increasing the model performance we are using the technique known as transfer learning, where we can use the pre trained models for predictions,in our case we are using mobilenet","80b2e256":"### here are actual labels with their coresponding species of butterflies ","d4e2edf0":"### here we can observe our new model is performing quite well as compare to our custom model","c05c56f0":"### visualizing the correct predictions","d7b730ad":"### we have to reshape our image array in oreder to meet keras expectations for fitting into model for training","13f9485a":"### Thats all kagglers .I hope that you liked this notebook , if you want to ask anything or want to give any suggestion feel free to write in the comment section.\n## Thank You","205eaa08":"## Experiment and fun","4f015e15":"The image we want to predict is also needed to be preprocessed according to the requirements of the model.You need to take care of resizing like we did below to resize it in (220,220) dimensions"}}