{"cell_type":{"a68b399e":"code","ad2e2467":"code","4deae4b3":"code","55ec5ffd":"code","768cbef3":"code","596c49c7":"code","f601b6a6":"code","19b26078":"code","4746efa7":"code","1fb3c381":"code","df0937e0":"code","63d97adc":"code","7a7abbdf":"code","e0a3acd8":"code","7cf1230b":"code","fdf513cf":"code","c2d652a9":"code","bf2ca12a":"code","9e463e72":"code","fda3bd69":"code","c984114c":"code","816668c4":"code","5e90cdcd":"code","9ae3b9c8":"markdown","0a23bf97":"markdown","b57dd02b":"markdown","8c621401":"markdown","fd54c25d":"markdown","07c4e9fa":"markdown","a317c177":"markdown","3c722713":"markdown","b1878474":"markdown","6d1cac1a":"markdown","9986c310":"markdown","3b553947":"markdown","e21b23b8":"markdown"},"source":{"a68b399e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad2e2467":"import tensorflow as tf\nfrom tensorflow import keras\nimport kerastuner\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, Activation\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\nimport keras.backend as k\nimport numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nfrom sklearn.metrics import classification_report, confusion_matrix","4deae4b3":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","55ec5ffd":"k.image_data_format()","768cbef3":"Data_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/'\nTrain_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/'\nTest_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/'\nValid_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/'","596c49c7":"Train_generator = ImageDataGenerator(width_shift_range=0.2, \n                                     height_shift_range=0.2, \n                                     shear_range=0.2, \n                                     zoom_range=0.4,\n                                     rotation_range= 30,\n                                     horizontal_flip=True,\n                                    fill_mode = 'nearest',\n                                    rescale = 1\/255)\n\nValid_generator = ImageDataGenerator(rescale = 1\/255 )\n\nTest_generator = ImageDataGenerator(rescale= 1\/255)","f601b6a6":"x = load_img('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/NORMAL\/NORMAL2-IM-0490-0001.jpeg')\nx = img_to_array(x)\nx = x.reshape((1,) + x.shape)\ni = 0\nfor batch in Train_generator.flow(x, batch_size=1,\n                                  save_to_dir='\/kaggle\/working\/',\n                        save_prefix='cat', save_format='jpeg'):\n    i += 1\n    if i > 20:\n        break ","19b26078":"Train_data = Train_generator.flow_from_directory(Train_dir, \n                                                 batch_size=32,\n                                                 target_size=(160,160), \n                                                 classes=['NORMAL','PNEUMONIA'],\n                                                 class_mode='binary')\n\nValid_data = Valid_generator.flow_from_directory(Valid_dir,\n                                                 batch_size=32,\n                                                target_size=(160,160), \n                                                classes=['NORMAL','PNEUMONIA'],\n                                                class_mode='binary')\nTest_data = Test_generator.flow_from_directory(Test_dir,\n                                               batch_size=39,shuffle = False,\n                                              target_size=(160,160), \n                                              classes=['NORMAL','PNEUMONIA'],\n                                              class_mode='binary')","4746efa7":"Train_data.class_indices","1fb3c381":"data, label = next(Test_data)","df0937e0":"plt.figure(figsize=(10,10))\nfor i in range(0,9):\n    plt.subplot(330+1+i)\n    plt.imshow(data[i])\n    plt.grid(False)\nplt.show()","63d97adc":"label","7a7abbdf":"batch_size = 32\nprint('\\n---\\tbatch size is\\t\\t{}'.format(batch_size))\nEpochs = 30\nprint('\\n---\\tEpoch number is \\t{}'.format(Epochs))\nnum_of_train_samples = len(Train_data)*32\nprint('\\n---\\tNum of train sample\\t{}'.format(num_of_train_samples))\nnum_of_valid_samples = len(Valid_data)*32\nprint('\\n---\\tNum of valid samples\\t{}'.format(num_of_valid_samples))\nnum_of_test_samples = len(Test_data)*32\nprint('\\n---\\tNum of test samples\\t{}'.format(num_of_test_samples))","e0a3acd8":"print('Number of images in Normal Category is {}'.format(len(os.listdir(Train_dir+'NORMAL'))))\nprint('\\n************\\n')\nprint('percentages of Normal Category is {}'. format(len(os.listdir(Train_dir+'NORMAL'))\/(len(os.listdir(Train_dir+'NORMAL'))+len(os.listdir(Train_dir+'PNEUMONIA')))* 100))\nprint('\\n-------------\\n')\nprint('Number of images in Pneumonia Category is {}'.format(len(os.listdir(Train_dir+'PNEUMONIA'))))\nprint('\\n************\\n')\nprint('percentages of Pneumonia Category is {}'. format(len(os.listdir(Train_dir+'PNEUMONIA'))\/(len(os.listdir(Train_dir+'NORMAL'))+len(os.listdir(Train_dir+'PNEUMONIA')))* 100))","7cf1230b":"print('Number of images in Normal Category is {}'.format(len(os.listdir(Valid_dir+'NORMAL'))))\nprint('\\n************\\n')\nprint('percentages of Normal Category is {}'. format(len(os.listdir(Valid_dir+'NORMAL'))\/(len(os.listdir(Valid_dir+'NORMAL'))+len(os.listdir(Valid_dir+'PNEUMONIA')))* 100))\nprint('\\n-------------\\n')\nprint('Number of images in Pneumonia Category is {}'.format(len(os.listdir(Valid_dir+'PNEUMONIA'))))\nprint('\\n************\\n')\nprint('percentages of Pneumonia Category is {}'. format(len(os.listdir(Valid_dir+'PNEUMONIA'))\/(len(os.listdir(Valid_dir+'NORMAL'))+len(os.listdir(Valid_dir+'PNEUMONIA')))* 100))","fdf513cf":"print('Number of images in Normal Category is {}'.format(len(os.listdir(Test_dir+'NORMAL'))))\nprint('\\n************\\n')\nprint('percentages of Normal Category is {}'. format(len(os.listdir(Test_dir+'NORMAL'))\/(len(os.listdir(Test_dir+'NORMAL'))+len(os.listdir(Test_dir+'PNEUMONIA')))* 100))\nprint('\\n-------------\\n')\nprint('Number of images in Pneumonia Category is {}'.format(len(os.listdir(Test_dir+'PNEUMONIA'))))\nprint('\\n************\\n')\nprint('percentages of Pneumonia Category is {}'. format(len(os.listdir(Test_dir+'PNEUMONIA'))\/(len(os.listdir(Test_dir+'NORMAL'))+len(os.listdir(Test_dir+'PNEUMONIA')))* 100))","c2d652a9":"\ndef build_model(img_rows, img_cols):\n    model = Sequential()\n    model.add(Conv2D(32,(3,3),input_shape=(img_rows,img_cols,3),activation = 'relu'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Conv2D(32,(3,3),activation = 'relu'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Flatten())\n    model.add(Dense(units=128,activation='relu'))\n    model.add(Dense(units=128,activation='relu'))\n    model.add(Dense(units=1, activation='sigmoid'))\n\n    \n    model.compile(loss='binary_crossentropy',\n                  optimizer='Adam',\n                  metrics=['accuracy'])\n    return model","bf2ca12a":"history = build_model(160,160)","9e463e72":"history.fit_generator(Train_data,\n                    steps_per_epoch=num_of_train_samples \/\/ batch_size,\n                    epochs=12, initial_epoch=10,\n                    validation_data=Test_data,\n                    validation_steps=num_of_test_samples \/\/ batch_size)","fda3bd69":"history.evaluate_generator(Test_data,workers = -1)[1]*100","c984114c":"Y_pred = history.predict_generator(Valid_data)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(Valid_data.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['NORMAL','PNEUMONIA']\nprint(classification_report(Valid_data.classes, y_pred, target_names=target_names))","816668c4":"history.save('chest-xray')","5e90cdcd":"# list all data in history\n#print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history.history['accuracy'])\nplt.plot(history.history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history.history['loss'])\nplt.plot(history.history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","9ae3b9c8":"# To save model for reuse in future without re-training.","0a23bf97":"# To plot model performance in training and validation data","b57dd02b":"## Data Augmentation on single image and storing it desire physical location","8c621401":"## Number of images in each category in Validation Data","fd54c25d":"## No. of training images","07c4e9fa":"## Class Label","a317c177":"## Number of images in each category in Testing Data","3c722713":"## Different Directory for data stored in.","b1878474":"In case want to use TPU resources, run the below cell it will initiate in tensorflow ","6d1cac1a":"## Current channel","9986c310":"## label for one batch of 32 images becoz we took batch size of 32 in flow_from_directory","3b553947":"## Test Dataset Visualization","e21b23b8":"## Number of images in each category in Training Data"}}