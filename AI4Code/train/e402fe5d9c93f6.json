{"cell_type":{"e477353a":"code","67bf866e":"code","16346802":"code","18c81c47":"code","ebca8f15":"code","ad47f98a":"code","e04cc0f8":"code","d5364636":"code","84c2de88":"code","89dfb450":"code","ed154d76":"code","78368784":"code","50bb1b27":"code","c42ae6ef":"code","4def1550":"code","8a682610":"code","8c0df86f":"markdown","7dbbaee4":"markdown"},"source":{"e477353a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","67bf866e":"# load libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom tqdm import tqdm_notebook\nfrom datetime import datetime","16346802":"# Load customer feedback data from kaggle dataset\ntweets = pd.read_csv('\/kaggle\/input\/customer-support-on-twitter\/twcs\/twcs.csv')\ntweets.shape","18c81c47":"tweets.columns","ebca8f15":"# We'll focus on what customers said to us, so let's get only customer messages\ncustomer_msg = tweets[tweets.inbound]\ncustomer_msg.shape","ad47f98a":"# Original dataset includes support data from multiple companies. Here we choose one company with similar business as ours.\n# for example Sprint.\ncustomer_msg = customer_msg[customer_msg['text'].str.contains(\"sprintcare\")]\ncustomer_msg.shape","e04cc0f8":"# Let's take a look at the data\ncustomer_msg.head()","d5364636":"# Reduce data size for better performance purpose in testing\ncustomer_msg_sample = customer_msg.head(1000)\ncustomer_msg_sample.shape","84c2de88":"tqdm_notebook().pandas()","89dfb450":"# Change data type to be datetime for column \"created_at\" and\n# sort by the ascending order so we can analize the messages based on the time when they are created \ncustomer_msg_sample['created_at'] = pd.to_datetime(customer_msg_sample.created_at)\ncustomer_msg_sample = customer_msg_sample.sort_values(by='created_at')","ed154d76":"# Instantiate sentiment analyzer from NLTK, make \"sentiment_analyze\" function\nsentiment_analyzer = SentimentIntensityAnalyzer()\n\ndef sentiment_analyze(text: str) -> float:\n    return sentiment_analyzer.polarity_scores(text)['compound']\n","78368784":"# Analyze customer sentiment based on their messages\ncustomer_msg_sample['sentiment'] = \\\n    customer_msg_sample.text.progress_apply(sentiment_analyze)","50bb1b27":"customer_msg_sample.head()","c42ae6ef":"# Group by author_id so we can deal with messages from different customers(author_id)\ncustomer_grouped = customer_msg_sample.groupby('author_id')","4def1550":"# Case 1, we can calculate average sentiment values for each customer over this data chunk\n# and compare to predefined alert threshold. \n# If the average sentiment value is lower than the threshold we'll list all the customers(author_id) \n# and suggest to reach to them for further discussion to find the reason and resolve the issues proactively\nauthor_sentiment_avg = customer_grouped.sentiment.mean().sort_values()\nauthor_sentiment_avg_df = pd.DataFrame({'author_id':author_sentiment_avg.index, 'sentiment':author_sentiment_avg.values})\nalert_threshold_avg = -0.7\nauthor_sentiment_avg_df[author_sentiment_avg_df.sentiment <= alert_threshold_avg]","8a682610":"# Case 2, we can find the minimum sentiment values for each customer over this data chunk\n# and compare to predefined alert threshold. \n# If the minimum sentiment value is lower than the threshold we'll list all the customers(author_id) \n# and suggest to reach to them for further discussion to find the reason and resolve the issues proactively\nauthor_sentiment_lowest = customer_grouped.sentiment.min().sort_values()\nauthor_sentiment_lowest_df = pd.DataFrame({'author_id':author_sentiment_lowest.index, 'sentiment':author_sentiment_lowest.values})\nalert_threshold_min = -0.8\nauthor_sentiment_lowest_df[author_sentiment_lowest_df.sentiment <= alert_threshold_min]","8c0df86f":"## Customer Sentiment Analysis\nFeng Li, fengl2, 2019\/10\/08\n\nI\u2019m working for an IT company in technical support team. We\u2019re dealing with different issues\nfrom various customer in a daily basis. We\u2019re using ticketing system and live chat to\ncommunicate with customers. Customer feedback is very import to us \u2013 When we see positive\nfeedbacks, we know our service is good and we may be able to expand our business with them.\nWhen we see negative feedbacks, we need to take action to understand the reason and\naddress customer\u2019s concerns timely.\n\nSo, we need to carefully monitor customer\u2019s sentiment in all communications between our\nsupport engineers and customers. Basically, we want to do at least two things 1) track\ncustomer\u2019s satisfaction level over times and give action suggestions; 2) real time monitor\nongoing communications and raise alarms when necessary.\n\nHowever, our company\u2019s data cannot be shared in public. So, this project will be using similar\ndata - \u201cCustomer Support on Twitter\u201d dataset from Kaggle. And according to the effort and\nlimited time of this course, this project will focus on the first task \u201ctrack customer\u2019s satisfaction\nlevel over times and give action suggestions\u201d.\n\nThis notebook includes code and document.\n\nThis notebook is being developed as Kaggle kernel using dataset https:\/\/www.kaggle.com\/thoughtvector\/customer-support-on-twitter and usig this kernel https:\/\/www.kaggle.com\/soaxelbrooke\/customer-sentiment-by-brand as reference.","7dbbaee4":"Columns Meaning\n- tweet_id\n\nThe unique ID for this tweet\n- author_id\n\nThe unqiue ID for this tweet author (anonymized for non-company users)\n- inbound\n\nWhether or not the tweet was sent (inbound) to a company\n- created_at\n\nWhen the tweet was created\n- text\n\nThe text content of the tweet"}}