{"cell_type":{"db518431":"code","f5fb8227":"code","bad4a7a9":"code","93cb7123":"code","a1aeeb9f":"code","d0e7bec5":"code","e68cfc6c":"code","1f1b774e":"code","f1f2798c":"code","04fb7c91":"code","bac8b2dd":"code","1a1135bd":"code","60de4ae5":"code","af27004a":"code","2a6205c2":"code","a7cd00b9":"code","9b1237e3":"code","ac4411ed":"code","e5032b0c":"code","65661ce6":"code","beb8f89a":"code","f6067a39":"code","bdef85e1":"code","6e59cc36":"code","30c0d67e":"code","7b65d594":"code","820b98a8":"code","dd6c24bf":"code","a5127141":"code","120265dd":"code","98007155":"code","594d6f1b":"code","279e4ede":"code","28418aef":"code","a6541c06":"code","f89608ec":"code","5169da07":"code","62ca5923":"code","fc304625":"code","65eaf339":"code","38527f23":"code","17df36dd":"code","d84c0677":"code","9945072f":"code","cef59386":"markdown","b234aa55":"markdown","9caf54ab":"markdown","5d337237":"markdown","2c949f60":"markdown","86382a42":"markdown","0fa5c6c6":"markdown","10f7833f":"markdown","fef4d9dc":"markdown","2995cf96":"markdown","d5d9b8c1":"markdown","c04fe591":"markdown"},"source":{"db518431":"%matplotlib inline\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nfrom matplotlib import pyplot as plt\nimport numpy as np # linear algebra\nimport category_encoders as ce\nfrom sklearn.metrics import median_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.utils import shuffle\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import BaggingRegressor\nimport seaborn as sns\nfrom scipy import stats\nimport numpy as np\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f5fb8227":"#run these \n\"\"\"run1-outlier section and check the loss and tune the threshold value if it effect the loss\"\"\"\n\"\"\"run2-plot vs cc_acc(target is the leftmost column)\"\"\"\n\"\"\"run3-grid search on random forest\"\"\"#plz write the code of grid search for xgb work better till now and set hyperparameters\n\"\"\"there are three plz do->1,2,3 \"\"\"","bad4a7a9":"\ndf=pd.read_csv('..\/input\/train.csv')\nprint('df.shape :->'+str(df.shape))\ndf.describe()","93cb7123":"df_test=pd.read_csv('..\/input\/test.csv')\ndf_test.head()","a1aeeb9f":"df_sample=pd.read_csv('..\/input\/sample.csv')\ndf_sample.head()","d0e7bec5":"df.head()","e68cfc6c":"df.info()","1f1b774e":"import seaborn as sns\nfor i in range(3,44):\n    x=df.iloc[:,i]\n    y=df['cc_cons']\n    sns.boxplot(x=x)\n    plt.show()","f1f2798c":"\"\"\"plz do 1- remove outlier and then check acc is it giving some benifits or change threshold if require\"\"\"\nfrom scipy import stats\nimport numpy as np\nz = np.abs(stats.zscore(df.iloc[:,1:]))\nthreshold = 3\ndf_rm = df_train[(z < threshold).all(axis=1)]\nprint('df_train_rm shape :'+str(df_rm.shape))\nprint('df_train shape :'+str(df.shape))","04fb7c91":"\"\"\"plz do 2- iam not getting any know form data no relation so i think this is of now use plz see this ones\"\"\"\nfeatures=df.iloc[:,3:40].columns\nfor i in features:\n    sns.lmplot(x=i, y='cc_cons', data=df,line_kws={'color': 'red'})\n    text=\"Relation between Points and \" + i \n    plt.title(text)\n    plt.show()","bac8b2dd":"df_rem=df.iloc[:,1:]#remove id\ndf_test_rem=df_test.iloc[:,1:]\ndf_test_rem.shape","1a1135bd":"df_rem.head()\nfor i in df_rem.columns:\n    if(i!='account_type' and i!='gender' and i!='loan_enq'):\n         df_rem[i]=df_rem[i].fillna(df_rem[i].median())","60de4ae5":"df_test_rem.head()\nfor i in df_test_rem.columns:\n    if(i!='account_type' and i!='gender' and i!='loan_enq'):\n         df_test_rem[i]=df_test_rem[i].fillna(df_test_rem[i].median())","af27004a":"df_rem_no_null_now=df_rem","2a6205c2":"df_rem","a7cd00b9":"df_1=df_rem\ndf_1.iloc[:,40]=df_1.iloc[:,40].fillna('N')\ndf_1=df_1.iloc[:,:].values","9b1237e3":"df_1_test=df_test_rem\ndf_1_test.iloc[:,40]=df_1_test.iloc[:,40].fillna('N')\ndf_1_test=df_1_test.iloc[:,:].values","ac4411ed":"df_1[:,40]","e5032b0c":"le = LabelEncoder()\n#df_1=df_1.iloc[:,:].values\ndf_1[:, 0] = le.fit_transform(df_1[:, 0])\ndf_1[:, 1] = le.fit_transform(df_1[:, 1])\ndf_1[:, 40] = le.fit_transform(df_1[:, 40])","65661ce6":"ohe = OneHotEncoder(categorical_features = [0])\nX = ohe.fit_transform(df_1).toarray()\nohe = OneHotEncoder(categorical_features = [1+1])\nX = ohe.fit_transform(X).toarray()\nohe = OneHotEncoder(categorical_features = [40+1+1])\nX = ohe.fit_transform(X).toarray()","beb8f89a":"df_1_test.shape","f6067a39":"le = LabelEncoder()\n#df_1=df_1.iloc[:,:].values\ndf_1_test[:, 0] = le.fit_transform(df_1_test[:, 0])\ndf_1_test[:, 1] = le.fit_transform(df_1_test[:, 1])\ndf_1_test[:, 40] = le.fit_transform(df_1_test[:, 40])##column 40 is of loan_enq\nohe_1 = OneHotEncoder(categorical_features = [0])\nX_test = ohe_1.fit_transform(df_1_test).toarray()\nohe_1 = OneHotEncoder(categorical_features = [1+1])\nX_test= ohe_1.fit_transform(X_test).toarray()\nohe_1= OneHotEncoder(categorical_features = [40+1+1])\nX_test = ohe_1.fit_transform(X_test).toarray()","bdef85e1":"X_test=pd.DataFrame(X_test)\nX_test.head()","6e59cc36":"X.shape","30c0d67e":"X_new = pd.DataFrame(X)\n\"\"\"X_new is ready to feed now\"\"\"\nX_new","7b65d594":"X_new1=shuffle(X_new)","820b98a8":"X_load=X_new1.iloc[:,:45]\ny_load=X_new1.iloc[:,45]","dd6c24bf":"X_load.head()","a5127141":"y_load.head()","120265dd":"#next task divide test and cv and apply bagging , xgboost regression and test it\nX_train, X_cv, y_train, y_cv = train_test_split(X_load, y_load, test_size=0.25, random_state=42)","98007155":"print('X_train.shape:'+str(X_train.shape))\nprint('X_cv.shape:'+str(X_cv.shape))","594d6f1b":"from sklearn.preprocessing import MinMaxScaler\nmin_max_scaler =MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X_train)\ndf_normov = pd.DataFrame(np_scaled)\nnp_scaled2 = min_max_scaler.fit_transform(X_cv)\ndf_cv=pd.DataFrame(np_scaled2)\ndf_normov.head()","279e4ede":"\"\"\"plz do -3 please apply grid search so we get better acc and suggest so we can get better acc pipline? kfold?\"\"\"","28418aef":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators=300,max_depth=30)\nrfr.fit(df_normov,y_train)\ny_pred_rfr=rfr.predict(df_cv)\nrfr_pred=mean_squared_error(y_cv, y_pred_rfr)\nprint(rfr_pred)\nprint('r2_score of linear regression model:->'+str(r2_score(y_cv, y_pred_rfr)))","a6541c06":"xgb_pred=mean_absolute_error(np.array(y_cv), y_pred_rfr)\nxgb_pred","f89608ec":"model = BaggingRegressor(DecisionTreeRegressor(max_depth=20),n_estimators=100)\nmodel.fit(df_normov, y_train)\ny_pred_bg=model.predict(np.array(df_cv))\nbg_pred=mean_squared_error(np.array(y_cv),y_pred_bg)\nprint(bg_pred)\nprint('r2_score of linear regression model:->'+str(r2_score(np.array(y_cv), y_pred_bg)))","5169da07":"from sklearn.metrics import median_absolute_error\nbg_pred=median_absolute_error(np.array(y_cv),y_pred_bg)\nprint(bg_pred)","62ca5923":"xgb=XGBRegressor(n_estimators=200, learning_rate=0.01, gamma=0.001, subsample=0.75,  colsample_bytree=1, max_depth=30\nxgb.fit(df_normov,y_train)\ny_pred_xgb=xgb.predict(df_cv)\nxgb_pred=mean_squared_error(np.array(y_cv), y_pred_xgb)\nprint(xgb_pred)\nprint('r2_score of linear regression model:->'+str(r2_score(np.array(y_cv), y_pred_xgb))) ","fc304625":"print('r2_score of linear regression model:->'+str(r2_score(np.array(y_cv), y_pred_xgb))) \nxgb_pred=mean_squared_error(np.array(y_cv), y_pred_rfr)\nprint(xgb_pred)\nxgb_pred2=median_absolute_error(np.array(y_cv),y_pred_xgb)\nprint(xgb_pred2)","65eaf339":"#next task apply grid search on xgb and bagging at night from 11 pm to 1 am","38527f23":"y_pred_final=xgb.predict(X_test)\n","17df36dd":"res=pd.DataFrame(y_pred_final)\ndf_sample.iloc[:,1]=res.iloc[:,0]","d84c0677":"df_sample","9945072f":"from IPython.display import HTML\n\ndf_sample.to_csv('submission.csv')\n\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='submission.csv')","cef59386":"same fot test","b234aa55":"Test Data","9caf54ab":"Sample","5d337237":" **Data plots **","2c949f60":"encodeing for test","86382a42":"Training Data","0fa5c6c6":"**Data Cleaning**","10f7833f":"Fill the missing value of test data","fef4d9dc":"Encoding for gender,account and loan_enq","2995cf96":"**Outlier**","d5d9b8c1":"Fill loan_enq with missing values with N","c04fe591":"Fill the missing value of training data\n"}}