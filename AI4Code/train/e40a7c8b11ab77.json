{"cell_type":{"26307e4a":"code","31be0760":"code","a6c1b6f8":"code","22f69f7c":"code","a61c55bf":"code","c29dc799":"code","6245eeb2":"code","0e0a53f4":"code","4ff9d7ec":"code","8fc313c6":"code","69d25351":"code","351223d3":"code","842f35bd":"code","dfd58c32":"code","baca738e":"code","fe415b38":"code","947118b9":"code","4597c522":"code","f5be6b3c":"code","80bf820e":"code","8ab4628f":"code","544dc091":"code","b420e0a0":"code","c4a0bc4f":"code","16684aea":"code","83646299":"code","48f6c26d":"code","e937f959":"code","f791b1ca":"markdown","30dbd444":"markdown","e5602096":"markdown","5ca41430":"markdown","368aaa5e":"markdown","267ba71b":"markdown","66dc1b44":"markdown","557101be":"markdown","c0f3671d":"markdown","26d6aeb8":"markdown","4b173ee7":"markdown","e50a675d":"markdown","9c4f202f":"markdown","9b1cf8c6":"markdown","6bc95b50":"markdown","d5c1746d":"markdown","2a103ae0":"markdown","bad5fd6a":"markdown"},"source":{"26307e4a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","31be0760":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntrain.sample(3)","a6c1b6f8":"test = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\ntest.sample(3)","22f69f7c":"train.info()","a61c55bf":"describeTable = train.describe().drop(index=['25%', '50%', '75%'])\ndescribeTable","c29dc799":"train.isna().sum().plot(kind='line',color='black', figsize=(27,5));","6245eeb2":"if sum(train.isna().sum()) == 0:\n    print('No Missing Values Found in data frame')","0e0a53f4":"train.drop(columns=['id']).hist(figsize=(27,15), bins=60, grid=False, color='black');","4ff9d7ec":"features_means = describeTable.drop(columns = ['id', 'target']).T['mean']\nplt.xticks(np.arange(0,len(train.columns)-2, step=2))\nplt.xlabel('Feature')\nplt.ylabel('mean')\nfeatures_means.plot(color='black', figsize=(27,5));","8fc313c6":"features_means = train.describe().drop(columns = ['id', 'target', 'f2', 'f35']).T['mean']\nplt.xticks(np.arange(0,len(train.columns)-2, step=2))\nplt.xlabel('Feature')\nplt.ylabel('Mean')\nfeatures_means.plot(color='black', figsize=(27,5));","69d25351":"HI_means = features_means[features_means.values >= 0.5].index.to_list()\nLOW_means = features_means[features_means.values < 0.5].index.to_list()\nprint('There are',len(HI_means), 'features with a mean >= 0.5 and', len(LOW_means) , 'features with a mean < 0.5')","351223d3":"import plotly.io as pio\npio.templates.default = \"plotly_white\"\n\n\ncorr_df = train.drop(columns=['id']).corr()\nmask = np.triu(np.ones_like(corr_df, dtype=bool))\n\ncorrelogramMap = go.Heatmap(z=corr_df.mask(mask),\n                            x=corr_df.columns,\n                            y=corr_df.columns,\n                            colorscale = 'RdBu',\n                            xgap=0.5, ygap=0.5,\n                            colorbar_thickness=20,\n                            colorbar_ticklen=3)\n\ncorrelogramLayout = go.Layout(title_text='Correlation Matrix',\n                   title_x=0.5,\n                   width=1750, height=1000,\n                   xaxis_showgrid=False,\n                   yaxis_showgrid=False,\n                   yaxis_autorange='reversed')\n\ncorrelogram_fig = go.Figure(data=[correlogramMap], layout=correlogramLayout)\n\ncorrelogram_fig.show() ","842f35bd":"TargetCorrel = corr_df[['target']].drop(index=['target'])\n\nTargetCorrel_fig = go.Figure(data=go.Line(x=TargetCorrel.index, y=TargetCorrel['target'], mode='lines+markers', line_color='orange'))\nTargetCorrel_fig.update_traces(marker_color = 'black')\nTargetCorrel_fig.update_layout(plot_bgcolor=\"white\")\n\nTargetCorrel_fig.show()","dfd58c32":"all_in_percent = train.drop(columns = ['id', 'target']).shape[0] * train.drop(columns = ['id', 'target']).shape[1]\ntrainNegative = train.drop(columns = ['id', 'target'])[(train < 0.0)]\ntrainPositive = train.drop(columns = ['id', 'target'])[(train > 0.0)]\ntrainZero =  train.drop(columns = ['id', 'target'])[(train == 0.0)]\n\nprint('There are\\n',round(trainNegative.count().sum()* 100\/all_in_percent,4), '% negative records,\\n' ,\n      round(trainPositive.count().sum()* 100\/all_in_percent,4), '% positive records,\\n',\n      round(trainZero.count().sum()* 100\/all_in_percent,4), '% zero-values records')","baca738e":"negVSposFig = go.Figure()\nnegVSposFig.add_trace(go.Bar(x=trainNegative.columns, y=trainNegative.count().values,\n                    name='Negative Values'))\nnegVSposFig.add_trace(go.Bar(x=trainPositive.columns, y=trainPositive.count().values,\n                    name='Positive Values'))\n\nnegVSposFig.show()","fe415b38":"features = train.drop(columns=['id','target']).columns.to_list()\n\nfrom sklearn.preprocessing import StandardScaler\n                   \nscaling = StandardScaler().fit_transform(train[features])\nscaled_train = train.copy()\nscaled_train[features] = scaling\nscaled_train.head(3)","947118b9":"from sklearn.feature_selection import VarianceThreshold\n\nfeatures = train.drop(columns=['id','target']).columns.to_list()\nselector = VarianceThreshold(threshold  = 0.25)\nselector.fit(X=train[features])\nselected_features = train[features].columns[selector.get_support()].to_list()\n\nprint(len(selected_features) ,\n      'out of',\n      len(train.columns)-2,\n      'features were seleced')","4597c522":"X = train[selected_features]\ny = train['target']","f5be6b3c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.25,\n                                                    random_state=12)","80bf820e":"from time import time\nfrom sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix, ConfusionMatrixDisplay","8ab4628f":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nNNClassifier = Sequential([\n    Dense(units = 4, activation = 'relu'),\n    Dense(units = 16, activation = 'relu'),\n    Dense(units = 32, activation = 'relu'),\n    Dense(units = 16, activation = 'relu'),\n    Dense(units = 1, activation = 'sigmoid')])\nNNClassifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nNNClassifier.fit(X_train, y_train, epochs=15, batch_size=15,verbose=1)","544dc091":"NNClassifier.summary()","b420e0a0":"\n_ , accuracy = NNClassifier.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))\n\ny_pred = np.round((NNClassifier.predict(X_test)))","c4a0bc4f":"cm = confusion_matrix(y_test, y_pred)\nlabels = ['Mail','Spam']\nConfusionMatrixDisplay(cm, display_labels=labels).plot(cmap='Reds');","16684aea":"test['target'] = np.rint(NNClassifier.predict(test.drop(columns='id')[selected_features])).astype('int')","83646299":"test.head()","48f6c26d":"test['target'].value_counts()","e937f959":"subFile = test[['id', 'target']].to_csv('submission.csv' , index=False)","f791b1ca":"#### Look for correlation between features","30dbd444":"Train-Test Split","e5602096":"#### Look for missing values","5ca41430":"### Negative vs. Positive values","368aaa5e":"#### Train DataFrame information","267ba71b":"##### Comparing to all 100 features - it seems thath feature number 2 and feature number 35 contain unusual distribution of values.\n##### What it will look like if I'll ignore them?","66dc1b44":"# Models ","557101be":"Features reduction","c0f3671d":"#### DataFrame statistics","26d6aeb8":"def ModelResults_df(model, X_train = X_train, X_test = X_test, y_train = y_train, y_test = y_test):\n    \"\"\"\n    A simple workflow for model training and it's results.\n    The function return pandas DataFrame containing results as a report for the model.\n    \"\"\"\n    \n    startTime = time()\n    ReportDict = {}\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    endTime = time()\n    \n    modelAccuracy = round(accuracy_score(y_test, y_pred),5)\n    modelROC_AUC = round(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]),5)\n    modelRecall = round(recall_score(y_test, y_pred),5)\n    \n    ReportDict['Training Time (sec)'] = np.round(endTime-startTime, 4)\n    ReportDict['Accuracy Score'] = modelAccuracy\n    ReportDict['ROC AUC score'] = modelROC_AUC\n    ReportDict['Recall score'] = modelRecall\n    \n    return pd.DataFrame(ReportDict, index=[0])","4b173ee7":"Zoom to correlation with target column","e50a675d":"Feature scaling - is it necessery ?","9c4f202f":"#### Observe the distributions of all features (and target)","9b1cf8c6":"#### Observe the means of all features ","6bc95b50":"# Data Preprocessing","d5c1746d":"## Data Exploration","2a103ae0":"from xgboost import XGBClassifier\n\nxbgClassifierReport = ModelResults_df(model = XGBClassifier(n_estimators=1000,\n                                                           max_depth=10))\nxbgClassifierReport","bad5fd6a":"# Submission File"}}