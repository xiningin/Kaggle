{"cell_type":{"24c7db99":"code","4b55ac97":"code","b2e895a8":"code","23771327":"code","291be32f":"code","4f1f7bba":"code","e1023da0":"code","9bb5438f":"code","3d32906d":"code","c5acc19c":"code","884578ee":"code","fd4e0600":"code","3feb363a":"code","01506cfd":"code","43909a07":"code","401c273a":"markdown","8429619b":"markdown","b551bc7e":"markdown","d74a2e99":"markdown","4c48b7c0":"markdown","9b7bb0f9":"markdown","7ee810fb":"markdown","74a117e3":"markdown","1137d9e9":"markdown","e193b377":"markdown","fd56332b":"markdown","3a9b64d9":"markdown","b56d2b49":"markdown"},"source":{"24c7db99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.datasets import imdb\nfrom keras import models\nfrom keras import layers\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b55ac97":"(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n# num_words parametresi ile en s\u0131k tekrar eden 10000 \u00f6rne\u011fi saklay\u0131p nadir \u00f6rnekler g\u00f6z ard\u0131 edilir.","b2e895a8":"train_data[0]","23771327":"train_labels[0] # 0 = olumsuz, 1 = olumlu kriter","291be32f":"def vectorize_sequences(sequences, dimension=10000):\n    # (len(sequences), dimension) \u015feklinde t\u00fcm elemanlar\u0131 0 olan matris olu\u015fturur.\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1 # result[i]'nin istenen indekslerini 1 yapar.\n    return results\n\nX_train = vectorize_sequences(train_data) # e\u011fitim vekt\u00f6r verisi\nX_test = vectorize_sequences(test_data) # test vekt\u00f6r verisi\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')","4f1f7bba":"model = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","e1023da0":"model.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Elle Ayarlama: \n# from keras import losses\n# from keras import metrics\n\n# model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n#               loss=losses.binary_crossentropy,\n#               metrics=[metrics.binary_accuracy])\n# ","9bb5438f":"X_val = X_train[:10000]\npartial_X_train = X_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]","3d32906d":"history = model.fit(partial_X_train, partial_y_train,\n                    epochs=20, batch_size=512,\n                    validation_data=(X_val, y_val))","c5acc19c":"history_dict = history.history\nhistory_dict.keys()","884578ee":"# E\u011fitim ve do\u011fruluk kay\u0131plar\u0131n\u0131 \u00c7izdirmek\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(loss_values) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label='E\u011fitim Kayb\u0131') # bo mavi nokta i\u00e7in\nplt.plot(epochs, val_loss_values, 'b', label='Do\u011fruluk Kayb\u0131')\nplt.title('E\u011fitim ve Do\u011fruluk Kayb\u0131')\nplt.xlabel('Epoklar')\nplt.ylabel('Kay\u0131p')\nplt.legend()\nplt.show()\n\n# E\u011fitim ve Do\u011frulama ba\u015far\u0131m\u0131n\u0131 \u00e7izdirmek\n\nplt.clf() # \u015eekli temizler\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nplt.plot(epochs, acc, 'bo', label='E\u011fitim Ba\u015far\u0131m\u0131')\nplt.plot(epochs, val_acc, 'b', label='Do\u011fruluk Ba\u015far\u0131m\u0131')\nplt.title('E\u011fitim ve Do\u011fruluk ba\u015far\u0131m\u0131')\nplt.xlabel(\"Epoklar\")\nplt.ylabel('Ba\u015far\u0131m')\nplt.show()","fd4e0600":"# Modeli en ba\u015ftan e\u011fitmek \nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=4, batch_size=512)\nresults = model.evaluate(X_test, y_test)","3feb363a":"results","01506cfd":"model.predict(X_test)","43909a07":"model = models.Sequential()\nmodel.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\nmodel.add(layers.Dense(32, activation='tanh'))\nmodel.add(layers.Dense(64, activation='tanh'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',\n              loss='mse',\n              metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=4, batch_size=512)\nresults = model.evaluate(X_test, y_test)\nprint(results)","401c273a":"# ileri G\u00f6zlemler","8429619b":"G\u00f6r\u00fclece\u011fi \u00fczere e\u011fitim kayb\u0131 her epokta d\u00fc\u015ferken e\u011fitim ba\u015far\u0131m\u0131 her epokta artmaktad\u0131r. Bu gradyan ini\u015fi kulland\u0131\u011f\u0131n\u0131zda g\u00f6rmeniz gereken enk\u00fc\u00e7\u00fcltmek istedi\u011finiz de\u011ferin her epokta biraz d\u00fc\u015fmesidir. Ama e\u011fitim ve do\u011fruluk ba\u015far\u0131m\u0131nda bunun olmas\u0131 beklenmez, d\u00f6rd\u00fcnc\u00fc epokta tepe de\u011ferine ula\u015f\u0131yorlar. E\u011fitim esnas\u0131nda \u00e7ok iyi performans g\u00f6steren modelin, daha \u00f6nce hi\u00e7 g\u00f6rmedi\u011fi \u00f6rnekler i\u00e7in de ayn\u0131 performans\u0131 g\u00f6stermesi beklenilmemelidir. Daha kesin ifade ile g\u00f6rd\u00fc\u011f\u00fcm\u00fcz \u015fey 'A\u015f\u0131r\u0131 uydurma'd\u0131r yani Overfitting: \u0130kinci epoktan sonra e\u011fitim veri seti \u00fczerinde a\u015f\u0131r\u0131 e\u011fitti\u011finiz i\u00e7in model e\u011fitim veri setine \u00f6zel g\u00f6sterimleri \u00f6\u011freniyor ama bunu e\u011fitim veri seti d\u0131\u015f\u0131nda genelle\u015ftiremiyor. ","b551bc7e":"# \u00d6zet\n* \u0130kili s\u0131n\u0131fland\u0131rma probleminde a\u011f\u0131n\u0131z bir birimli ve 'sigmoid' aktivasyon fonksiyonlu bir 'Dense' ile bitmeli. A\u011f\u0131n\u0131z\u0131n \u00e7\u0131kt\u0131s\u0131, olas\u0131l\u0131\u011f\u0131 g\u00f6steren 0 ile 1 aras\u0131nda skaler bir de\u011fer olmal\u0131d\u0131r.\n\n* Skaler sigmoid \u00e7\u0131kt\u0131s\u0131 olan ikili s\u0131n\u0131fland\u0131rma problemlerinde kay\u0131p fonksiyonu olarak 'binary_crossentropy' kullan\u0131lmal\u0131. \n\n* Problem ne olursa olsun 'rmsprop' eniyileme algoritmas\u0131 genellikle yeterince iyidir.\n\n* E\u011fitim veri seti \u00fczerinde giderek daha iyi performans g\u00f6steren sinir a\u011flar\u0131 daha \u00f6nce hi\u00e7 g\u00f6rmedi\u011fi veriler \u00fczerinde giderek daha k\u00f6t\u00fc performans g\u00f6stererek overfittinge sebep olur. Bu y\u00fczden e\u011fitim veri seti hari\u00e7 ba\u015fka bir veri seti \u00fczerinde performans\u0131n\u0131 g\u00f6zlemlemeyi unutmay\u0131n.","d74a2e99":"Bu basit yakla\u015f\u0131mla %88 ba\u015far\u0131m elde edilebiliyor. \u015euanda bilinen en iyi yakla\u015f\u0131mlarla %95 ba\u015far\u0131ma ula\u015f\u0131labilmektedir.","4c48b7c0":"# NOT: \nBu kendime not olarak haz\u0131rlad\u0131\u011f\u0131m, bilgileri Fran\u00e7ois Chollet'in Python ile Derin \u00d6\u011frenme kitab\u0131ndan ald\u0131\u011f\u0131m bir notebook'tur. T\u00fcrk\u00e7e Derin \u00d6\u011frenme kayna\u011f\u0131 olabilsin diye public olarak payla\u015f\u0131yorum. ","9b7bb0f9":"## Verileri haz\u0131rlamak\n\nListemizi one-hot-encoding yapaca\u011f\u0131z","7ee810fb":"* Sonunda bir loss function ve optimizasyon algoritmas\u0131 se\u00e7me a\u015famas\u0131na geldiniz. Kar\u015f\u0131n\u0131zda ikili s\u0131n\u0131fland\u0131rma problemi oldu\u011fu i\u00e7in ve a\u011f\u0131n\u0131z\u0131n \u00e7\u0131kt\u0131s\u0131 bir olas\u0131l\u0131k de\u011feri oldu\u011fu i\u00e7in 'binary_crossentropy' loss function'\u0131n\u0131 kullanmak en iyisidir. Yerine 'mean_squared_error' de kullan\u0131labilir. Ama crossentropy \u00e7\u0131kt\u0131s\u0131 olas\u0131l\u0131k de\u011ferleri olan modeller i\u00e7in genellikle en iyi \u00e7\u00f6z\u00fcmd\u00fcr. 'crossentropy' Bilgi Kuram\u0131ndan gelir ve olas\u0131l\u0131k da\u011f\u0131l\u0131mlar\u0131 aras\u0131ndaki uzakl\u0131\u011f\u0131 \u00f6l\u00e7er. \n* A\u015fa\u011f\u0131da 'rmspop' eniyileme algoritmas\u0131 ile 'binary_crossentropy' kay\u0131p fonksiyonunu kullanarak modelinizi nas\u0131l kullanaca\u011f\u0131n\u0131z\u0131 g\u00f6rebilirsiniz. Unutmay\u0131n e\u011fitim esnas\u0131nda model ba\u015far\u0131m\u0131n\u0131 da g\u00f6zlemleyece\u011fiz. ","74a117e3":"Bu s\u00f6zl\u00fc\u011f\u00fcn e\u011fitim ve do\u011frulama esnas\u0131nda kaydedilen 4 girdisi bulunmaktad\u0131r. ","1137d9e9":"# A\u011f\u0131n\u0131z\u0131 in\u015fa etmek\n\n* Girdiler vekt\u00f6r ve etiketler(labels) skaler (1'ler ve 0'lar): Bu kar\u015f\u0131n\u0131za \u00e7\u0131kacak en kolay problem olacak. Bu tip bir problem i\u00e7in kullan\u0131lacak en iyi a\u011f tipi stack s\u0131k\u0131 ba\u011fl\u0131 katmanlardan (Dense) olu\u015fan ve aktivasyon fonksiyonu olarak relu kullan\u0131lan bir a\u011fd\u0131r: Dense(16, activation='relu')\n\n* Dense fonksiyonuna g\u00f6nderilen (16) parametresi bu katmanda olmas\u0131n\u0131 istedi\u011fimiz hidden unit say\u0131s\u0131d\u0131r. Hidden unit katman\u0131n g\u00f6sterim uzay\u0131n\u0131n boyutudur.\n\n* relu aktivasyon fonksiyonu kullanan Dense katman\u0131 a\u015fa\u011f\u0131daki tens\u00f6r i\u015flemini yerine getirmektedir.\n* output = relu(dot(W, input) + b)\n* 16 gizli birim bulunmas\u0131 W a\u011f\u0131rl\u0131k matrisinin (input_dimension, 16) \u015feklinde olmas\u0131 anlam\u0131na gelir: W a\u011f\u0131rl\u0131k matrisi ile i\u00e7 \u00e7arp\u0131m i\u015flemi (dot) girdi verilerini 16 boyutlu bir g\u00f6sterim uzay\u0131na d\u00f6n\u00fc\u015ft\u00fcr\u00fcr.\n* Daha fazla gizli birim bulunmas\u0131 a\u011f\u0131n\u0131z\u0131n daha karma\u015f\u0131k g\u00f6sterimler \u00f6\u011frenebilmesini sa\u011flayacak ama daha fazla hesaplama karma\u015f\u0131kl\u0131\u011f\u0131na sahip olmas\u0131n\u0131 da sa\u011flayacak ve istemedi\u011fimiz \u00f6r\u00fcnt\u00fcleri (bu \u00f6r\u00fcnt\u00fcler e\u011fitim verisi \u00fczerinde ba\u015far\u0131y\u0131 y\u00fckseltecek ancak test verileri \u00fczerinde ba\u015far\u0131ya katk\u0131 sa\u011flamayacakt\u0131r) de \u00f6\u011frenmesine neden olabilecektir. \n\n* Sonu\u00e7 olarak, Her katmanda 16 hidden layer olacak, \u00dc\u00e7\u00fcnc\u00fc katman film kriti\u011finin duygu analizini yaparak skaler \u00e7\u0131kt\u0131 \u00fcretecek.\n* Ara katmanda aktivasyon fonksiyonu olarak relu kullan\u0131lacak ve son katmanda sigmoid aktivasyon fonksiyonu kullanarak \u00e7\u0131kt\u0131lar\u0131 olas\u0131l\u0131k de\u011ferlerine d\u00f6n\u00fc\u015ft\u00fcrecek. \n* relu: Girdilerin negatif de\u011ferleri i\u00e7in s\u0131f\u0131r\u0131 \u00e7\u0131kt\u0131 verir. Daha sonra do\u011frusal artar.\n* Sigmoid : girdileri 0, 1 aral\u0131\u011f\u0131na bast\u0131r\u0131r ve \u00e7\u0131kt\u0131lar\u0131 ise olas\u0131l\u0131k olarak adland\u0131r\u0131labilir.","e193b377":"\u015eimdi modelimizi 20 epokta (20 iterasyonda X_train ve y_train tens\u00f6rlerinde bulunan t\u00fcm \u00f6rnekler) 512'lik mini-y\u0131\u011f\u0131nlar(batch_size) kullanarak e\u011fitece\u011fiz. Ayn\u0131 zamanda kay\u0131p de\u011ferini ve a\u011f ba\u015far\u0131m\u0131n\u0131 ay\u0131rd\u0131\u011f\u0131n\u0131z do\u011frulama veri setinde g\u00f6zlemleyece\u011fiz. Bunu do\u011frulama veri setini 'validation_data' parametresine g\u00f6ndererek yapaca\u011f\u0131z.","fd56332b":"# \u00d6ne\u011fitimli a\u011f\u0131 modeller \u00fczerinde tahmin etmek i\u00e7in kullanmak\n\nA\u011f\u0131 e\u011fittikten sonra onu pratik olarak kullanmak isteriz. 'predict' metodunu kullanarak olumlu kriterlerin olas\u0131l\u0131klar\u0131n\u0131 olu\u015fturabilirsiniz.","3a9b64d9":"model.fit() metodu History nesnesini geri d\u00f6nd\u00fcrmektedir. Bu nesnenin, e\u011fitim boyunca neler oldu\u011fu bilgisini bulunduran history isimli bir eleman\u0131 bulunmaktad\u0131r. \u015eimdi onu inceleyelim.","b56d2b49":"# Yakla\u015f\u0131m\u0131z\u0131 Do\u011frulamak\n* E\u011fitim ba\u015far\u0131m\u0131n\u0131 \u00f6l\u00e7mek i\u00e7in a\u011f\u0131n daha \u00f6nce hi\u00e7 g\u00f6rmedi\u011fi \u00f6zg\u00fcn veri setinden 10000 \u00f6rnekten olu\u015fan do\u011frulama(validation) seti olu\u015fturulur."}}