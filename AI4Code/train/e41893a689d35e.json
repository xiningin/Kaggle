{"cell_type":{"76af4eb2":"code","7bf65b83":"code","ca3adc4c":"code","38999c08":"code","9f808e2e":"code","9fbd3695":"code","c1be2b31":"code","2fe86d63":"code","e0d3b93d":"code","f9f6e7fb":"code","7299da9c":"code","36ba8a09":"code","cca1f930":"code","9a0c4e1e":"code","80d1f7ed":"code","a17ea92e":"code","29769880":"code","164fa25c":"code","df88c8d7":"code","36339b4b":"code","f8a1dbc6":"code","4d697fa3":"code","bd0fd5cf":"code","ae6ad588":"code","8547d20e":"code","f095d952":"markdown","915a0f34":"markdown","e39a8e4e":"markdown","cd4e0f38":"markdown","a6818825":"markdown","0a1a19d3":"markdown","4a724ed9":"markdown","9afd1c87":"markdown","397522c2":"markdown","9895b0dd":"markdown","e9875fd2":"markdown","213bdde1":"markdown","7bb426dd":"markdown","49ebb0ca":"markdown","f2447086":"markdown","45e5f6f8":"markdown","bfad4ea4":"markdown","0f140e4e":"markdown","a33f4eb7":"markdown","15c8cada":"markdown","7483e69f":"markdown","df23bcaf":"markdown","0f7c4d3b":"markdown","3ee97653":"markdown","ddf37b48":"markdown","32df641a":"markdown","17738b8b":"markdown","e1c0fa37":"markdown","6bd8b9da":"markdown","2313f941":"markdown","73663be5":"markdown","75f55ddb":"markdown","8e1fc77d":"markdown","59b7b757":"markdown","3511e516":"markdown"},"source":{"76af4eb2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7bf65b83":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nfrom collections import defaultdict\nfrom collections import Counter\n\n\n\nfrom sklearn.metrics import (\n    precision_score, \n    recall_score, \n    f1_score, \n    classification_report,\n    accuracy_score\n)\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nimport transformers\nfrom tqdm.notebook import tqdm\nfrom tokenizers import BertWordPieceTokenizer\n\nfrom transformers import BertTokenizer","ca3adc4c":"import warnings\nwarnings.filterwarnings(\"ignore\")","38999c08":"df = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', encoding='latin-1')\n\ndf.head()","9f808e2e":"df = df.dropna(how='any', axis=1)\ndf.columns = ['target', 'text']\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(df['target'])\n\ndf['target_encoded'] = le.transform(df['target'])\ndel df['target']\ndf.columns = ['text', 'target']\ndf.head()","9fbd3695":"from collections import Counter\nimport string\n\nchars = Counter()\nfor i, row in df.iterrows():\n    for char in row['text']:\n        chars[char] += 1\nprint('\u0421\u0438\u043c\u0432\u043e\u043b    \u0427\u0430\u0441\u0442\u043e\u0442\u0430')\nfor i in chars:\n    if not re.match(r'[a-z]|[A-Z]|[0-9]|[{} ]'.format(string.punctuation), i):\n        print(i, '        ', chars[i])","c1be2b31":"len(df)","2fe86d63":"target_count = df.groupby('target')['target'].agg('count').values\ntarget_count","e0d3b93d":"sms_lengths = df['text'].apply(lambda x: len(x.split(' ')))\nax = sms_lengths.plot.hist(bins=100, alpha=0.5, title='\u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u043b\u0438\u043d \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439')\nax.set_xlabel('\u0414\u043b\u0438\u043d\u0430 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f')\nax.set_ylabel('\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439')","f9f6e7fb":"stop_words = stopwords.words('english')\nstemmer = nltk.SnowballStemmer('english')\n\ndef preprocess_text(text):\n    \n    text = str(text).lower()\n    text = re.sub('((http|https)\\:\\\/\\\/)?[a-zA-Z0-9\\.\\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\\/\\?\\:@\\-_=#])*', 'url', text)\n    text = re.sub('[.,;-]', '', text)\n    \n    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n\n    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n    \n    return text","7299da9c":"df['text_clean'] = df['text'].apply(preprocess_text)\ndf.head()","36ba8a09":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ndef tf_idf(corpus):\n    \n    vectorizer = TfidfVectorizer(analyzer='word',\n                         ngram_range=(1, 2),\n                         min_df=0,\n                         max_df=0.5,\n                         max_features=5000)\n    \n    tfidf_matrix = vectorizer.fit_transform(corpus)\n    \n    return tfidf_matrix","cca1f930":"word2vec = dict()\n\nwith open('\/kaggle\/input\/glovedata\/glove.6B.200d.txt') as fp:\n    for line in fp.readlines():\n        records = line.split()\n        word = records[0]\n        vector_dimensions = np.asarray(records[1:], dtype='float32')\n        word2vec[word] = vector_dimensions","9a0c4e1e":"def doc2vec(corpus):\n    \n    vectorizer = TfidfVectorizer(analyzer='word',\n                         ngram_range=(1, 2),\n                         min_df=0,\n                         max_df=0.5,\n                         max_features=5000)\n    \n    tfidf_matrix = vectorizer.fit_transform(corpus)\n    tfidf_feature_names = vectorizer.get_feature_names()\n    \n    d2v = []\n    mask = [name in word2vec for name in tfidf_feature_names]\n    mask = np.array(mask)\n    tfidf_matrix_2 = tfidf_matrix[:, mask]\n    vs = []\n    for i in tfidf_feature_names:\n        if i in word2vec:\n            vs.append(word2vec[i])\n    vs = np.array(vs)\n    d2v = tfidf_matrix_2.dot(vs)\n    return d2v","80d1f7ed":"import seaborn as sn\nfrom sklearn.metrics import confusion_matrix\n\ndef conf_matrix(y_true, y_pred):\n    columns = ['HAM', 'SPAM']\n    confm = confusion_matrix(y_true, y_pred)\n    df_cm = pd.DataFrame(confm, index=columns, columns=columns, dtype=np.int32)\n\n    ax = sn.heatmap(df_cm, cmap='Blues', annot=True, fmt=\"d\")","a17ea92e":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom sklearn.metrics import plot_confusion_matrix\n\ndef full_pipeline(model, params, doc2vec_vectorizer=False, print_conf_matrix=False, print_false_classifications=False):\n    \n    if doc2vec_vectorizer:\n        X = doc2vec(df['text_clean'])\n    else:\n        X = tf_idf(df['text_clean'])\n    y = df['target'].to_numpy()\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=239)\n\n    clf = GridSearchCV(model, params)\n    clf.fit(X_train, y_train)\n\n    print(f'Best classifier params: {clf.best_params_}')\n    print(f'TRAIN accuracy: {round(clf.best_score_,3)}, TRAIN ROC AUC: \\\n    {round(roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1]), 3)}')\n    \n    y_pred = clf.predict(X_test)\n    print(f'TEST accuracy: {round(accuracy_score(y_test, y_pred),3)}, TEST ROC AUC: \\\n    {round(roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]), 3)}')\n    \n    if print_conf_matrix:\n        conf_matrix(y_test, y_pred)\n    \n    if print_false_classifications:\n        classes = ['ham', 'spam']\n        false_classification0 = []\n        false_classification1 = []\n        y_pred = clf.predict(X)\n        for i in range(len(y)):\n            if y[i] != y_pred[i]:\n                if y[i] == 0:\n                    false_classification0.append({'text': df.iloc[i]['text'], 'y_true': classes[y[i]], \\\n                                                  'y_pred': classes[y_pred[i]]})\n                else:\n                    false_classification1.append({'text': df.iloc[i]['text'], 'y_true': classes[y[i]], \\\n                                                  'y_pred': classes[y_pred[i]]})\n        random.seed(241)\n        miscl0 = random.sample(false_classification0, min(5, len(false_classification0)))\n        miscl1 = random.sample(false_classification1, min(5, len(false_classification1)))\n    \n        print('\\nExamples, when the model missclassify HAM:\\n')\n        for i in miscl0:\n            print(f\"Text: {i['text']}\\nY_true: {i['y_true']}, Y_pred: {i['y_pred']}\\n\")\n    \n        print('\\nExamples, when the model missclassify SPAM:\\n')\n        for i in miscl1:\n            print(f\"Text: {i['text']}\\nY_true: {i['y_true']}, Y_pred: {i['y_pred']}\\n\")\n        ","29769880":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nmodels = [LogisticRegression(), SVC(), MultinomialNB(), RandomForestClassifier(), KNeighborsClassifier()]\nparams = [{'penalty':['l2'], 'C':[0.1, 1, 10, 20], 'solver': ['liblinear']},\\\n          {'C':[0.5, 1, 2], 'kernel':['linear', 'rbf'], 'probability': [True]},\\\n          {},\\\n          {'max_depth':[5, 7, 12, 20], 'n_estimators':[20, 50, 100]},\\\n          {'n_neighbors':[2, 3, 5, 7, 10, 20]}]\n\nprint()\nfor model, param in zip(models, params):\n    \n    print('Model:', str(model), '\\n')\n    print('Training on tf-idf')\n    full_pipeline(model, param)\n    \n    if str(model) == 'MultinomialNB()':\n        print('\\n')\n        continue\n    print('\\nTraining on GloVe with tf-idf weights')\n    full_pipeline(model, param, doc2vec_vectorizer=True)\n    print('\\n')","164fa25c":"full_pipeline(SVC(), {'C':[2], 'kernel':['linear'], 'probability': [True]}, print_conf_matrix=True, print_false_classifications=True)","df88c8d7":"tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n\ndef bert_encode(data, maximum_length) :\n    input_ids = []\n    attention_masks = []\n\n    for text in data:\n        encoded = tokenizer.encode_plus(\n            text, \n            add_special_tokens=True,\n            max_length=maximum_length,\n            pad_to_max_length=True,\n\n            return_attention_mask=True,\n        )\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n        \n    return np.array(input_ids),np.array(attention_masks)","36339b4b":"X = df['text_clean']\ny = df['target'].to_numpy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=239)\n\ntarget_text_len = 70\n\ntrain_input_ids, train_attention_masks = bert_encode(X_train,target_text_len)","f8a1dbc6":"def create_model(bert_model):\n    \n    input_ids = tf.keras.Input(shape=(target_text_len,),dtype='int32')\n    attention_masks = tf.keras.Input(shape=(target_text_len,),dtype='int32')\n\n    output = bert_model([input_ids,attention_masks])\n    output = output[1]\n    output = tf.keras.layers.Dense(32,activation='relu')(output)\n    output = tf.keras.layers.Dropout(0.2)(output)\n    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n    \n    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    return model","4d697fa3":"from transformers import TFBertModel\nbert_model = TFBertModel.from_pretrained('bert-base-uncased')","bd0fd5cf":"model = create_model(bert_model)\n\nhistory = model.fit(\n    [train_input_ids, train_attention_masks],\n    y_train,\n    validation_split=0.2, \n    epochs=4,\n    batch_size=10\n)","ae6ad588":"def plot_learning_curves(history, arr):\n    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n    for idx in range(2):\n        ax[idx].plot(history.history[arr[idx][0]])\n        ax[idx].plot(history.history[arr[idx][1]])\n        ax[idx].legend([arr[idx][0], arr[idx][1]],fontsize=18)\n        ax[idx].set_xlabel('A ',fontsize=16)\n        ax[idx].set_ylabel('B',fontsize=16)\n        ax[idx].set_title(arr[idx][0] + ' X ' + arr[idx][1],fontsize=16)\n\nplot_learning_curves(history, [['loss', 'val_loss'],['accuracy', 'val_accuracy']])","8547d20e":"test_input_ids, test_attention_masks = bert_encode(X_test,target_text_len)\n\ny_pred_proba = model.predict([test_input_ids, test_attention_masks])\ny_pred_proba = y_pred_proba.reshape((-1))\ny_pred_proba\n\ny_pred = np.zeros_like(y_pred_proba)\n\nfor i in range(len(y_pred)):\n    y_pred[i] = 1 if y_pred_proba[i] > 0.5 else 0\n\nprint(f'\\nTEST accuracy: {round(accuracy_score(y_test, y_pred),3)}, TEST ROC AUC: \\\n{round(roc_auc_score(y_test, y_pred_proba), 3)}\\n')\n\nconf_matrix(y_test, y_pred)\n\n# eval on full dataset\ntest_input_ids, test_attention_masks = bert_encode(X,target_text_len)\n\ny_pred_proba = model.predict([test_input_ids, test_attention_masks])\ny_pred_proba = y_pred_proba.reshape((-1))\ny_pred_proba\n\ny_pred = np.zeros_like(y_pred_proba, dtype=np.int32)\n\nfor i in range(len(y_pred)):\n    y_pred[i] = 1 if y_pred_proba[i] > 0.5 else 0\n\n\nclasses = ['ham', 'spam']\nfalse_classification0 = []\nfalse_classification1 = []\nfor i in range(len(y)):\n    if y[i] != y_pred[i]:\n        if y[i] == 0:\n            false_classification0.append({'text': df.iloc[i]['text'], 'y_true': classes[y[i]], \\\n                                          'y_pred': classes[y_pred[i]]})\n        else:\n            try:\n                false_classification1.append({'text': df.iloc[i]['text'], 'y_true': classes[y[i]], \\\n                                              'y_pred': classes[y_pred[i]]})\n            except Exception as e:\n                print(df.iloc[i]['text'], y[i], y_pred[i])\n                raise e\n\nmiscl0 = random.sample(false_classification0, min(5, len(false_classification0)))\nmiscl1 = random.sample(false_classification1, min(5, len(false_classification1)))\n\nprint('\\nExamples, when the model missclassify HAM:\\n')\nfor i in miscl0:\n    print(f\"Text: {i['text']}\\nY_true: {i['y_true']}, Y_pred: {i['y_pred']}\\n\")\n\nprint('\\nExamples, when the model missclassify SPAM:\\n')\nfor i in miscl1:\n    print(f\"Text: {i['text']}\\nY_true: {i['y_true']}, Y_pred: {i['y_pred']}\\n\")\n","f095d952":"\u0414\u0430,\u00a0\u0441\u0438\u043c\u0432\u043e\u043b\u044b \u043d\u0435 \u043f\u0440\u0435\u0434\u043d\u0430\u0434\u043b\u0435\u0436\u0430\u0449\u0438\u0435 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c\u0443 \u0430\u043b\u0444\u0430\u0432\u0438\u0442\u0443 \u0435\u0441\u0442\u044c, \u043d\u043e \u0438\u0445 \u043e\u0447\u0435\u043d\u044c \u043c\u0430\u043b\u043e, \u0438 \u043f\u043e\u0447\u0442\u0438 \u0432\u0441\u0435 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0442 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f\u043c \u0432\u0430\u043b\u044e\u0442, \u0442\u0430\u043a \u0447\u0442\u043e \u0431\u0443\u0434\u0435\u043c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0447\u0442\u043e \u0432\u0441\u0435 \u0442\u0435\u043a\u0441\u0442\u044b \u043d\u0430 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c.","915a0f34":"\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043f\u043e\u043d\u044f\u0442\u044c \u043d\u0430 \u043a\u0430\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f, \u0434\u043b\u044f \u043f\u0440\u043e\u0441\u0442\u043e\u0442\u044b \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0445 \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u043f\u043e\u043f\u0430\u043b\u0438 \u0432 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u0438\u0439 \u0430\u043b\u0444\u0430\u0432\u0438\u0442, \u0446\u0438\u0444\u0440\u044b \u0438 \u043f\u0443\u043d\u043a\u0442\u0443\u0430\u0446\u0438\u044e.","e39a8e4e":"# \u0421\u0434\u0435\u043b\u0430\u0435\u043c \u043f\u0435\u0440\u0432\u0438\u0447\u043d\u044b\u0439 \u0430\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","cd4e0f38":"\u0412\u044b\u0432\u043e\u0434 confusion_matrix:","a6818825":"\u041d\u0435\u043c\u043d\u043e\u0433\u043e \u043f\u043e\u0447\u0438\u0441\u0442\u0438\u043c \u0442\u0435\u043a\u0441\u0442, \u0443\u0434\u0430\u043b\u0438\u043c \u0441\u0442\u043e\u043f-\u0441\u043b\u043e\u0432\u0430 \u0438 \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u0441\u0442\u0435\u043c\u043c\u0438\u043d\u0433.","0a1a19d3":"\u041d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u0432 6 \u0440\u0430\u0437 \u0431\u043e\u043b\u044c\u0448\u0435 \u0447\u0435\u043c \u0441\u043f\u0430\u043c\u0430. \u042d\u0442\u043e \u0434\u0438\u0441\u0431\u0430\u043b\u0430\u043d\u0441 \u043a\u043b\u0430\u0441\u0441\u043e\u0432, \u0431\u0443\u0434\u0435\u043c \u044d\u0442\u043e \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0442\u044c \u043f\u0440\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0438 \u043c\u043e\u0434\u0435\u043b\u0438. \u0414\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0441\u0442\u0440\u0430\u0442\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 train-test split, \u0430 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c ROC AUC.","4a724ed9":"# \u0421\u0434\u0435\u043b\u0430\u0435\u043c \u0431\u0430\u0437\u043e\u0432\u0443\u044e \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0443 \u0442\u0435\u043a\u0441\u0442\u043e\u0432","9afd1c87":"\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0439 BERT","397522c2":"### \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u0438 \u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u043e\u0441\u0442\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","9895b0dd":"# \u0421\u043a\u0430\u0447\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","e9875fd2":"\u042f \u0445\u043e\u0447\u0443 \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043f\u0440\u043e\u0441\u0442\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u044e\u0442 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0441\u043b\u043e\u0432 \u0432 \u0442\u0435\u043a\u0441\u0442\u0435. \u0422\u043e \u0435\u0441\u0442\u044c \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043d\u0430\u0434\u043e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u0432\u0435\u043a\u0442\u043e\u0440\u043d\u043e\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430, \u0430 \u043f\u043e\u0442\u043e\u043c \u043f\u0435\u0440\u0435\u0434\u0430\u0442\u044c \u0435\u0433\u043e \u043c\u043e\u0434\u0435\u043b\u0438. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0434\u0432\u0430 \u0432\u0435\u043a\u0442\u043e\u0440\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0442\u0435\u043a\u0441\u0442\u0430:\n- TF-IDF\n- \u0421\u0443\u043c\u043c\u0430 GloVe \u044d\u043c\u0431\u0435\u0434\u0434\u0438\u043d\u0433\u043e\u0432 \u0441\u043b\u043e\u0432 \u0441 \u0432\u0435\u0441\u0430\u043c\u0438 TF-IDF","213bdde1":"\u041f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435, \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c accuracy, ROC AUC \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435.\n\u0412\u044b\u0432\u0435\u0434\u0435\u043c \u0441\u044d\u043c\u043f\u043b\u044b \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0448\u0438\u0431\u0430\u0435\u0442\u0441\u044f (\u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443).\n\u0412\u044b\u0432\u044b\u0434\u0435\u043c confusion_matrix.","7bb426dd":"# \u0412\u044b\u0432\u043e\u0434\u044b\n\n\u0422\u0430\u043a \u043a\u0430\u043a \u0432 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f\u0445 \u0441\u043e \u0441\u043f\u0430\u043c\u043e\u043c \u0447\u0430\u0441\u0442\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442\u0441\u044f \u043e\u0441\u043e\u0431\u044b\u0435 \u0441\u043b\u043e\u0432\u0430 \u043f\u043e \u0442\u0438\u043f\u0443 url-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0438 \u0442\u0435\u043b\u0435\u0444\u043e\u043d\u043d\u044b\u0445 \u043d\u043e\u043c\u0435\u0440\u043e\u0432, \u043f\u0440\u043e\u0441\u0442\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0438\u043a\u0430\u043a \u043d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u044e\u0442 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0441\u043b\u043e\u0432 \u0432 \u0442\u0435\u043a\u0441\u0442\u0435, \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0445\u043e\u0440\u043e\u0448\u043e. \u041d\u043e \u043b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043a\u043e\u043d\u0435\u0447\u043d\u043e \u0436\u0435 \u0434\u0430\u0435\u0442 \u0442\u044f\u0436\u0435\u043b\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c, \u0442\u0430\u043a\u0430\u044f \u043a\u0430\u043a BERT, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0441\u043b\u043e\u0432 \u0438 \u043b\u0443\u0447\u0448\u0435 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442 \u0432 \u0441\u043b\u043e\u0436\u043d\u044b\u0445 \u0441\u043b\u0443\u0447\u0430\u044f\u0445.","49ebb0ca":"\u041f\u0440\u043e\u0433\u043e\u043d\u0438\u043c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0447\u0435\u0440\u0435\u0437 \u044d\u0442\u043e\u0442 \u043f\u0430\u0439\u043f\u043b\u0430\u0439\u043d, \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u0447\u0442\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435\u0433\u043e.","f2447086":"\u041f\u043e\u0447\u0442\u0438 \u0432\u0441\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u0438\u043c\u0435\u044e\u0442 \u0434\u043b\u0438\u043d\u0443 \u0434\u043e 50 \u0441\u043b\u043e\u0432, \u0430 \u0441\u0430\u043c\u043e\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0435 175. \u041e\u0434\u043d\u0430 \u0438\u0437 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u0445\u043e\u0447\u0435\u0442\u0441\u044f \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c -  BERT, \u0434\u043b\u044f \u043d\u0435\u0435 \u043c\u043e\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u0438\u0432\u0435\u0441\u0442\u0438 \u0432\u0441\u0435 \u0442\u0435\u043a\u0441\u0442\u044b \u043a \u0434\u043b\u0438\u043d\u0435 50, \u043c\u0435\u043d\u044c\u0448\u0438\u0435 \u0442\u0435\u043a\u0441\u0442\u044b \u0437\u0430\u043f\u0430\u0434\u0438\u0442\u044c, \u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u043e\u0431\u0440\u0435\u0437\u0430\u0442\u044c.","45e5f6f8":"\u0422\u0443\u0442 \u0443\u0436\u0435 \u0432\u0438\u0434\u043d\u043e \u0447\u0442\u043e \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0448\u0438\u0431\u0430\u0435\u0442\u0441\u044f \u043d\u0435 \u0441\u0442\u043e\u043b\u044c \u0442\u0440\u0438\u0432\u0438\u0430\u043b\u044c\u043d\u044b \u0434\u0430\u0436\u0435 \u0434\u043b\u044f \u0447\u0435\u043b\u043e\u0432\u0435\u043a\u0430. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \"Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?\" - \u044d\u0442\u043e \u043e\u0442\u043d\u0435\u0441\u0435\u043d\u043e \u043a \u0441\u043f\u0430\u043c\u0443, \u0445\u043e\u0442\u044f \u043f\u043e\u043d\u044f\u0442\u043d\u043e \u0447\u0442\u043e \u044d\u0442\u043e \u043c\u043e\u0433 \u043d\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u0438 \u0442\u0432\u043e\u0439 \u0437\u043d\u0430\u043a\u043e\u043c\u044b\u0439. \u0412 \u043e\u0431\u0449\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0448\u0438\u0431\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u0440\u0435\u0430\u043b\u044c\u043d\u043e \u0441\u043b\u043e\u0436\u043d\u044b\u0445 \u043f\u043e \u0441\u043c\u044b\u0441\u043b\u0443 \u043a\u0435\u0439\u0441\u0430\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0430\u0445\u043e\u0434\u044f\u0442\u0441\u044f \u0431\u043b\u0438\u0437\u043a\u043e \u043a \u0433\u0440\u0430\u043d\u0438\u0446\u0435 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u043a\u043b\u0430\u0441\u0441\u044b. \u041e\u0441\u043e\u0431\u043e\u0433\u043e \u043f\u0440\u043e\u0441\u0442\u0440\u0430\u043d\u0442\u0441\u0432\u0430 \u0434\u043b\u044f \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0443\u0436\u0435 \u043d\u0435\u0442.","bfad4ea4":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u0438\u043c\u0435\u0435\u0442 \u043b\u0438 \u043c\u0435\u0441\u0442\u043e \u0434\u0438\u0441\u0431\u0430\u043b\u0430\u043d\u0441 \u043a\u043b\u0430\u0441\u0441\u043e\u0432.","0f140e4e":"\u041c\u044b \u0432\u0438\u0434\u0438\u043c \u0447\u0442\u043e \u043b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435\u0433\u043e \u0441\u0435\u0431\u044f \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u0430 SVM \u043d\u0430 tf-idf. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0432\u044b\u0445\u043e\u0434\u043e\u0432 \u044d\u0442\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u0438, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u044b\u043c \u043e\u043d\u0430 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u0438 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u0441\u043f\u0430\u043c\u043e\u043c \u0438\u043b\u0438 \u043d\u0435\u0442.\n\n\n\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u0430 confusion_matrix \u0438 \u0441\u044d\u043c\u043f\u043b\u044b \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0448\u0438\u0431\u0430\u0435\u0442\u0441\u044f. \u0421\u044d\u043c\u043f\u043b\u044b \u0432\u043e\u0437\u044c\u043c\u0435\u043c \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0438\u0437 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438, \u043d\u043e \u0438 \u0438\u0437 \u0442\u0440\u044d\u0439\u043d\u0430, \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u043e\u0448\u0438\u0431\u043e\u043a \u043e\u0431\u043e\u0438\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0431\u044b\u043b\u043e \u0431\u043e\u043b\u044c\u0448\u0435.","a33f4eb7":"# \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043f\u0440\u043e\u0441\u0442\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","15c8cada":"\u0421\u043a\u0430\u0447\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 GloVe \u044d\u043c\u0431\u0435\u0434\u0434\u0435\u043d\u0433\u0438.","7483e69f":"\u0414\u043b\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u0435\u0434\u0438\u043d\u044b\u0439 \u043f\u0430\u0439\u043f\u043b\u0430\u0439\u043d, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u0431\u0443\u0434\u0435\u0442 \u0441\u0440\u0430\u0437\u0443 \u0432\u0441\u0435:\n- \u0412\u044b\u0431\u043e\u0440 \u0441\u043f\u043e\u0441\u043e\u0431\u0430 \u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u043e\u0432\u0430\u0442\u044c \u0442\u0435\u043a\u0441\u0442: \u0447\u0435\u0440\u0435\u0437 tf-idf, \u043b\u0438\u0431\u043e \u0447\u0435\u0440\u0435\u0437 GloVe \u0441 \u0432\u0435\u0441\u0430\u043c\u0438 tf-idf\n- \u041e\u0442\u0441\u043b\u0435\u0436\u0438\u0432\u0430\u043d\u0438\u0435 accuracy \u043d\u0430 Train \u0438 Test\n- \u041f\u0435\u0440\u0435\u0431\u043e\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 CV \u0440\u0435\u0448\u0435\u0442\u043a\u0435\n- \u0412\u044b\u0432\u043e\u0434 confusion matrix\n- \u0412\u044b\u0432\u043e\u0434 \u0441\u044d\u043c\u043f\u043b\u043e\u0432 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0448\u0438\u0431\u0430\u0435\u0442\u0441\u044f","df23bcaf":"\u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043a\u043e\u0440\u043f\u0443\u0441\u0430 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u0432 tf-idf \u043c\u0430\u0442\u0440\u0438\u0446\u0443:","0f7c4d3b":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0432\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438.","3ee97653":"# BERT","ddf37b48":"\u041f\u0440\u0438\u043a\u0440\u0443\u0442\u0438\u043c \u043a BERT-\u0443 2 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0445 \u0441\u043b\u043e\u044f \u0441 \u0434\u0440\u043e\u043f\u0430\u0443\u0442\u043e\u043c \u0438 \u0441\u0438\u0433\u043c\u043e\u0438\u0434\u0443 \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435, \u0447\u0442\u043e\u0431\u044b \u043c\u043e\u0434\u0435\u043b\u044c \u0432\u044b\u0434\u0430\u0432\u0430\u043b\u0430 \u043d\u0430\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c 1-\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430","32df641a":"\u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043a\u043e\u0440\u043f\u0443\u0441\u0430 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u0432 \u043c\u0430\u0442\u0440\u0438\u0446\u0443 \u0441 \u0441\u0443\u043c\u043c\u0430\u043c\u0438 GloVe \u0432\u0435\u043a\u0442\u043e\u0440\u043e\u0432 \u0442\u0435\u043a\u0441\u0442\u0430 \u0441 \u0432\u0435\u0441\u0430\u043c\u0438 tf-idf:","17738b8b":"\u041d\u0430 \u0447\u0442\u043e \u0445\u043e\u0447\u0435\u0442\u0441\u044f \u043e\u0431\u0440\u0430\u0442\u0438\u0442\u044c \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u0432 \u043f\u0435\u0440\u0432\u0443\u044e \u043e\u0447\u0435\u0440\u0435\u0434\u044c:\n- \u0422\u043e\u0447\u043d\u043e \u043b\u0438 \u0432\u0441\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u043d\u0430 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435? \u042f \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u043b \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430,\u00a0\u0442\u0430\u043c \u0435\u0441\u0442\u044c \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0435 \u0436\u0438\u0442\u0435\u043b\u044f\u043c\u0438 \u0421\u0438\u043d\u0433\u0430\u043f\u0443\u0440\u0430, \u0430 \u0435\u0449\u0435 \u0447\u0430\u0441\u0442\u044c \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439 \u0432\u0437\u044f\u0442\u0430 \u0441 \u043a\u0430\u043a\u043e\u0433\u043e-\u0442\u043e \u0438\u0441\u043f\u0430\u043d\u0441\u043a\u043e\u0433\u043e \u0441\u0430\u0439\u0442\u0430\n- \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435\n- \u0415\u0441\u0442\u044c \u043b\u0438 \u0434\u0438\u0441\u0431\u0430\u043b\u0430\u043d\u0441 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n- \u041a\u0430\u043a\u0438\u0435 \u0431\u044b\u0432\u0430\u044e\u0442 \u0434\u043b\u0438\u043d\u044b \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439","e1c0fa37":"\u041f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0432 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432.","6bd8b9da":"\u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u043c \u043f\u0435\u0440\u0435\u0432\u043e\u0434 \u0441\u044b\u0440\u044b\u0445 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u0432 \u0437\u0430\u043f\u0430\u0436\u0435\u043d\u043d\u044b\u0435\/\u043e\u0431\u0440\u0435\u0437\u0430\u043d\u043d\u044b\u0435 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 id \u0442\u043e\u043a\u0435\u043d\u043e\u0432 \u0444\u0438\u043a\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0439 \u0434\u043b\u0438\u043d\u044b,\u00a0\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0436\u043d\u043e \u0431\u0443\u0434\u0435\u0442 \u043f\u043e\u0434\u0430\u0442\u044c \u043d\u0430 \u0432\u0445\u043e\u0434 \u0432 BERT","2313f941":"\u041c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c 2 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u044f:\n- \u041c\u043e\u0434\u0435\u043b\u044c \u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u0437\u0430\u0442\u043e\u0447\u0435\u043d\u0430 \u043f\u043e\u0434 \u0434\u0435\u0442\u0435\u043a\u0446\u0438\u044e \u0446\u0438\u0444\u0440 \u0438 \u0447\u0438\u0441\u0435\u043b, \u0445\u043e\u0442\u044f \u043e\u043d\u0438 \u043e\u0447\u0435\u043d\u044c \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0435\u043d\u043d\u044b \u0434\u043b\u044f \u0441\u043f\u0430\u043c\u0430\n- \u041c\u043e\u0434\u0435\u043b\u044c \u0441\u043a\u043b\u043e\u043d\u043d\u0430 \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0447\u0430\u0441\u0442\u043e \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u044c \u0432 \u0441\u043f\u0430\u043c \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u0433\u0434\u0435 \u043c\u043d\u043e\u0433\u043e \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u044e\u0442\u0441\u044f \u043a\u043b\u044e\u0447\u0435\u0432\u044b\u0435 \u0441\u043b\u043e\u0432\u0430 \u0442\u0438\u043f\u0430 new, msg, \u0445\u043e\u0442\u044f \u0438 \u043e\u0431\u044b\u0447\u043d\u044b\u0435 \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u044f \u043f\u043e\u0440\u043e\u0439 \u0438\u0445 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\n\n\u0411\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u044f \u044d\u0442\u0438\u043c \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u044f\u043c \u043c\u044b \u043f\u043e\u043d\u0438\u043c\u0430\u0435\u043c \u043a\u0430\u043a \u0435\u0449\u0435 \u043c\u043e\u0436\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c, \u043f\u0440\u0438 \u0436\u0435\u043b\u0430\u043d\u0438\u0438.\n\n\u0414\u0432\u0438\u043d\u0435\u043c\u0441\u044f \u0434\u0430\u043b\u044c\u0448\u0435. \u041c\u044b \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u043b\u0438 \u043d\u0430 \u0440\u0430\u0431\u043e\u0442\u0443 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0438\u043a\u0430\u043a \u043d\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u044e\u0442 \u043f\u043e\u0440\u044f\u0434\u043e\u043a \u0441\u043b\u043e\u0432 \u0432 \u0442\u0435\u043a\u0441\u0442\u0435. \u0422\u0435\u043f\u0435\u0440\u044c \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0431\u043e\u043b\u0435\u0435 \u0441\u043b\u043e\u0436\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0443\u0436\u0435 \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u0442 \u043f\u043e\u0440\u044f\u0434\u043e\u043a. \u042f \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u044e BERT.","73663be5":"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438.","75f55ddb":"\u0423\u0434\u0430\u043b\u0438\u043c \u043b\u0438\u0448\u043d\u0438\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u044b, \u0430\u0434\u0435\u043a\u0432\u0430\u0442\u043d\u043e \u043d\u0430\u0437\u043e\u0432\u0435\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0438 \u0438 \u0437\u0430\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c \u0442\u0430\u0440\u0433\u0435\u0442\u044b.","8e1fc77d":"### \u0415\u0434\u0438\u043d\u044b\u0439 \u043f\u0430\u0439\u043f\u043b\u0430\u0439\u043d \u0434\u043b\u044f \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439","59b7b757":"\u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c","3511e516":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c, \u043a\u0430\u043a\u0438\u0435 \u0431\u044b\u0432\u0430\u044e\u0442 \u0434\u043b\u0438\u043d\u044b \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0439."}}