{"cell_type":{"566ded5e":"code","17212cff":"code","8a5fd3b3":"code","2e0eff18":"code","88162402":"code","7678a0a4":"code","88ae7fcc":"code","637a32b5":"code","8a560156":"code","4f334ff0":"code","a00d9c9c":"code","693cd624":"code","4281d495":"code","b7caa67d":"code","ea0ba313":"code","bb7c956f":"code","90a048a8":"code","d9575ce3":"code","1e37c9d2":"code","4e616374":"code","f60dd45e":"code","1ef1fe2a":"code","7252e466":"code","fcf6d773":"code","fcbe3c21":"code","fc6a2cbc":"code","2bd8d5f6":"markdown","f3a876e6":"markdown","f0fed5ac":"markdown","a03f055f":"markdown","7d7f5ef7":"markdown","2ba3cc57":"markdown","a822cefb":"markdown","dad64d11":"markdown","46fd2496":"markdown","850d6f95":"markdown","25849e22":"markdown","21afd7f1":"markdown"},"source":{"566ded5e":"library(tidyverse)\nlibrary(miscset)\nlibrary(dplyr)\ndataset<-read.csv(\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndim_desc(dataset)\n\n","17212cff":"glimpse(dataset)","8a5fd3b3":"names(dataset)","2e0eff18":"ggplot(dataset) +\n  geom_bar(aes(x = SeniorCitizen, fill = Churn), position = \"dodge\") + scale_fill_manual(values=c(\"#999999\", \"#FFB6C1\"))\ndataset %>%\n  group_by(SeniorCitizen) %>%\n  summarise(n = n()) %>%\n  mutate(freq = n \/ sum(n))\ndataset %>%\n  group_by(SeniorCitizen, Churn) %>%\n  summarise(n = n()) %>%\n  mutate(freq = n \/ sum(n))","88162402":"ggplot(dataset) +\n  geom_bar(aes(x = gender, fill = Churn), position = \"dodge\") + scale_fill_manual(values=c(\"#999999\", \"#FFB6C1\"))\ndataset %>%\n  group_by(gender,Churn) %>%\n  summarise(n=n())","7678a0a4":"ggplot(dataset) +\n  geom_bar(aes(x=Partner, fill = Churn), position = \"dodge\") + scale_fill_manual(values=c(\"#999999\", \"#FFB6C1\"))\ndataset %>%\n  group_by(Partner) %>%\n  summarise(n = n()) %>%\n  mutate(freq = n \/ sum(n))\ndataset %>%\n  group_by(Partner, Churn) %>%\n  summarise(n = n()) %>%\n  mutate(freq = n \/ sum(n))","88ae7fcc":"ggplot(dataset) +\n  geom_bar(aes_string(x=\"Dependents\", fill=\"Churn\"), position = \"dodge\") + scale_fill_manual(values=c(\"#999999\", \"#FFB6C1\"))\ndataset %>% group_by(Dependents, Churn) %>%\n  summarise(n=n()) %>%\n  mutate(freq = n \/ sum(n))\ndataset %>% group_by(Dependents) %>%\n  summarise(n = n()) %>%\n  mutate(freq = n \/ sum(n))","637a32b5":"ggplot(dataset, aes(x = SeniorCitizen, y = TotalCharges)) +\n  geom_boxplot() + scale_fill_manual(values=c(\"#2980B9\", \"#FF3333\"))","8a560156":"ggplot(dataset, aes(x = Partner, y = TotalCharges)) +\n  geom_boxplot()","4f334ff0":"ggplot(dataset, aes(x = Dependents, y = TotalCharges)) +\n  geom_boxplot()","a00d9c9c":"dataset %>%\n  select(SeniorCitizen, Churn, TotalCharges, tenure) %>%\n  filter(SeniorCitizen == 1, Churn == \"Yes\") %>%\n  summarize(n = n(),\n            total = sum(TotalCharges),\n            avg_tenure = sum(tenure)\/n)","693cd624":"dataset %>%\n  select(Partner, Churn, TotalCharges, tenure) %>%\n  filter(Partner == \"No\", Churn == \"Yes\") %>%\n  summarise(n = n(),\n            total = sum(TotalCharges),\n            avg_tenure = sum(tenure)\/n)","4281d495":"dataset %>%\n  select(Dependents, Churn, TotalCharges, tenure) %>%\n  filter(Dependents == \"No\", Churn == \"Yes\") %>%\n  summarise(n = n(),\n            total = sum(TotalCharges),\n            avg_tenure = sum(tenure)\/n)","b7caa67d":"dataset$customerID<-NULL\ndataset$gender=factor(dataset$gender,levels=c('Male','Female'),labels=c(0,1))\ndataset$Partner=factor(dataset$Partner,levels=c('Yes','No'),labels=c(1,0))\ndataset$Dependents=factor(dataset$Dependents,levels=c('Yes','No'),labels=c(1,0))\ndataset$PhoneService=factor(dataset$PhoneService,levels=c('Yes','No'),labels=c(1,0))\ndataset$MultipleLines=factor(dataset$MultipleLines,levels=c('Yes','No','No phone service'),labels=c(1,0,2))\ndataset$OnlineBackup=factor(dataset$OnlineBackup,levels=c('Yes','No','No internet service'),labels=c(1,0,2))\ndataset$InternetService=factor(dataset$InternetService,levels=c('DSL','Fiber optic','No'),labels=c(1,2,0))\ndataset$OnlineSecurity=factor(dataset$OnlineSecurity,levels=c('Yes','No','No internet service'),labels=c(1,0,2))\ndataset$DeviceProtection=factor(dataset$DeviceProtection,levels=c('Yes','No','No internet service'),labels=c(1,0,2))\ndataset$TechSupport=factor(dataset$TechSupport,levels=c('Yes','No','No internet service'),labels=c(1,0,2))\ndataset$StreamingTV=factor(dataset$StreamingTV,levels=c('Yes','No','No internet service'),labels=c(1,0,2))\ndataset$StreamingMovies=factor(dataset$StreamingMovies,levels=c('Yes','No','No internet service'),labels=c(1,0,2))\ndataset$Contract=factor(dataset$Contract,levels=c('Month-to-month','One year','Two year'),labels=c(0,1,2))\ndataset$PaperlessBilling=factor(dataset$PaperlessBilling,levels=c('Yes','No'),labels=c(1,0))\ndataset$PaymentMethod=factor(dataset$PaymentMethod,levels=c('Electronic check','Mailed check','Bank transfer (automatic)','Credit card (automatic)'),labels=c(0,1,2,3))\ndataset$Churn=factor(dataset$Churn,levels=c('No','Yes'),labels=c(0,1))\nhead(dataset)","ea0ba313":"write.csv(dataset,'cat_to_num_1.csv',row.names=F)\ndataset<-read.csv('cat_to_num_1.csv')","bb7c956f":"sum(is.na(dataset))\nsum(is.na(dataset$gender))\nsum(is.na(dataset$SeniorCitizen))\nsum(is.na(dataset$Partner))\nsum(is.na(dataset$Dependents))\nsum(is.na(dataset$tenure))\nsum(is.na(dataset$PhoneService))\nsum(is.na(dataset$MultipleLines))\nsum(is.na(dataset$InternetService))\nsum(is.na(dataset$OnlineSecurity))\nsum(is.na(dataset$OnlineBackup))\nsum(is.na(dataset$DeviceProtection))\nsum(is.na(dataset$TechSupport))\nsum(is.na(dataset$StreamingTV))\nsum(is.na(dataset$StreamingMovies))\nsum(is.na(dataset$Contract))\nsum(is.na(dataset$PaymentMethod))\nsum(is.na(dataset$MonthlyCharges))\nsum(is.na(dataset$TotalCharges))\nsum(is.na(dataset$Churn))","90a048a8":"dataset<-na.omit(dataset)\nsum(is.na(dataset))","d9575ce3":"dataset$tenure=scale(dataset$tenure)\nhead(dataset$tenure)","1e37c9d2":"dataset$MonthlyCharges=scale(dataset$MonthlyCharges)\nhead(dataset$MonthlyCharges)","4e616374":"dataset$TotalCharges=scale(dataset$TotalCharges)\nhead(dataset$TotalCharges)","f60dd45e":"plot_tc <- density(dataset$TotalCharge)\nplot(plot_tc)","1ef1fe2a":"plot_mc <- density(dataset$MonthlyCharges)\nplot(plot_mc)","7252e466":"plot_tn <- density(dataset$tenure)\nplot(plot_tn)","fcf6d773":"cormat<-signif(cor(dataset),2)\ncormat","fcbe3c21":"heatmap(cormat,col=heat.colors(256),symm=TRUE)","fc6a2cbc":"import csv\nimport math\nimport pandas as pd\nimport random\n\ndef loadCsv(filename):\n\tlines = csv.reader(open(filename))\n\tdataset = list(lines)\n\tfor i in range(len(dataset)):\n\t\tdataset[i] = [float(x) for x in dataset[i]]\n\treturn dataset\n\ndef splitDataset(dataset, splitRatio):\n\ttrainSize = int(len(dataset) * splitRatio)\n\ttrainSet = []\n\tcopy = list(dataset)\n\twhile len(trainSet) < trainSize:\n\t\tindex = random.randrange(len(copy))\n\t\ttrainSet.append(copy.pop(index))\n\treturn [trainSet, copy]\n\ndef separateByClass(dataset):\n\tseparated = {}\n\tfor i in range(len(dataset)):\n\t\tvector = dataset[i]\n\t\tif (vector[-1] not in separated):\n\t\t\tseparated[vector[-1]] = []\n\t\tseparated[vector[-1]].append(vector)\n\treturn separated\n\ndef mean(numbers):\n\treturn sum(numbers)\/float(len(numbers))\n\ndef stdev(numbers):\n\tavg = mean(numbers)\n\tvariance = sum([pow(x-avg,2) for x in numbers])\/float(len(numbers)-1)\n\treturn math.sqrt(variance)\n\ndef summarize(dataset):\n\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n\tdel summaries[-1]\n\treturn summaries\n\n\ndef summarizeByClass(dataset):\n\tseparated = separateByClass(dataset)\n\tsummaries = {}\n\tfor classValue, instances in separated.items():\n\t\tsummaries[classValue] = summarize(instances)\n\treturn summaries\n\n\n\n\ndef calculateProbability(x, mean, stdev):\n\texponent = math.exp(-(math.pow(x-mean,2)\/(2*math.pow(stdev,2))))\n\treturn (1 \/ (math.sqrt(2*math.pi) * stdev)) * exponent\n\n\ndef calculateClassProbabilities(summaries, inputVector):\n\tprobabilities = {}\n\tfor classValue, classSummaries in summaries.items():\n\t\tprobabilities[classValue] = 1\n\t\tfor i in range(len(classSummaries)):\n\t\t\tmean, stdev = classSummaries[i]\n\t\t\tx = inputVector[i]\n\t\t\tprobabilities[classValue] *= calculateProbability(x, mean, stdev)\n\treturn probabilities\n\n\ndef predict(summaries, inputVector):\n\tprobabilities = calculateClassProbabilities(summaries, inputVector)\n\tbestLabel, bestProb = None, -1\n\tfor classValue, probability in probabilities.items():\n\t\tif bestLabel is None or probability > bestProb:\n\t\t\tbestProb = probability\n\t\t\tbestLabel = classValue\n\treturn bestLabel\n\n\n\ndef getPredictions(summaries, testSet):\n\tpredictions = []\n\tfor i in range(len(testSet)):\n\t\tresult = predict(summaries, testSet[i])\n\t\tpredictions.append(result)\n\treturn predictions\n\n\ndef getAccuracy(testSet, predictions):\n\tcorrect = 0\n\tfor x in range(len(testSet)):\n\t\tif testSet[x][-1] == predictions[x]:\n\t\t\tcorrect += 1\n\treturn (correct\/float(len(testSet))) * 100.0\n\n\ndef main():\n    filename = '..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n    splitRatio = 0.67\n    dataset = loadCsv(filename)\n    trainingSet, testSet = splitDataset(dataset, splitRatio)\n    \n   \n    #dataset = loadCsv(filename)\n    trainingSet =loadCsv(trainingSet)\n    testSet =loadCsv(testSet)\n    print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingSet), len(testSet)))\n    summaries = summarizeByClass(trainingSet)\n    predictions = getPredictions(summaries, testSet)\n    accuracy = getAccuracy(testSet, predictions)\n    print('Accuracy: {0}%'.format(accuracy))    \nmain()","2bd8d5f6":"Naive bayesian classifier","f3a876e6":"Next, we compute the correlation Matrix to assess the relationship between attributes","f0fed5ac":"**Churn prediction**\n\nCustomer Churn, also known as attrition, refers to a condition where the customers stop doing business with a company, This leads to unprecedented and a costly loss. Hence it is a crucial part of the customer-company relationship. The main reason is that the cost of acquiring a new customer is relatively priced higher than\nretaining the old customer. After the advent of enterprise size humongous firms, the need to retain existing customers is essential.In most instances, customers leave the company unexpectedly, without giving any feedback or expressing their issues with the company. Hence it becomes very difficult for the company to know the actual reason. By bringing in a classification model in this place reduces the risk of attrition as the company would be able to predict the churn rate of a customer and if found high, the company could take measures to retain the customer.The major losses incurred by the companies are very high as it impacts sales. So,reducing customer churn is the need of the hour. Thus, the ability to precisely predict the future churn rates is highly demanding. It also helps businesses gain a better understanding about their customers and forecast their reviews.\n\n**Conversion of categorical dataset into numerical dataset**\n\nThe categorical variables can also be never fit directly into a regression model. Hence, they must be converted into numerical attributes.","a03f055f":"Null values check\n\nHere, we check for the presence of null values in each column","7d7f5ef7":"Desity plots\n\nDensity plots are also known as known as Kernel Density Plots or Density Trace Graphs. Distribution of data over a continuous interval or time period can be visualized using the density plots.\n\nHere, we compute the density plots for tenure, total charges and monthly charges.","2ba3cc57":"Conversion of categorical dataset into numerical dataset\n\nThe categorical variables can also be never fit directly into a regression model. Hence, they must be converted into numerical attributes.","a822cefb":"Computing the average of the numerical variables in the dataset","dad64d11":"1. We scale the dataset inorder to bring it into the same range. We carry out scaling for the three attributes, namely tenure,total charges and monthly charges.","46fd2496":"We remove all the rows containing null values","850d6f95":"* Let us begin this process by taking a glimpse of data.  with data wrangling or preprocessing\n\n","25849e22":"Correlation heatmap","21afd7f1":"Again, we check for the presence of null values"}}