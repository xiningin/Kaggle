{"cell_type":{"0d88c31b":"code","8cf2ba49":"code","0c8ea522":"code","aec4799a":"code","cda69f70":"code","d1322d6b":"code","96bfb548":"code","1cd7c89b":"code","2c0a4e4b":"code","1a5be7bc":"code","b2df6afa":"code","0e9a9914":"code","90ee9487":"code","dcbc598e":"code","b26552e3":"code","5154bfe4":"code","4fcc6859":"code","f0526635":"code","28a1b1af":"code","a1cc5d60":"code","6409516a":"code","4135f22e":"code","bac762d0":"code","b03ecf0c":"code","389f20c9":"markdown","aeb91081":"markdown","95ac938b":"markdown","6c696790":"markdown","508bbbf6":"markdown","3a202f35":"markdown","15ab6383":"markdown","6d6f801e":"markdown"},"source":{"0d88c31b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, GlobalAveragePooling2D, UpSampling2D, Input\nfrom tensorflow.keras.layers import MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nimport scipy as sp","8cf2ba49":"(train_data, train_labels),(test_data, test_labels) = tf.keras.datasets.cifar10.load_data()","0c8ea522":"train_data.shape, train_labels.shape, train_data.dtype, test_data.dtype","aec4799a":"class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck']\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_data[i])\n    # The CIFAR labels happen to be arrays, \n    # which is why you need the extra index\n    plt.xlabel(class_names[train_labels[i][0]])\nplt.show()","cda69f70":"train_data = train_data.astype(np.float32)\ntest_data = test_data.astype(np.float32)\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\ntrain_data \/= 255.\ntest_data \/= 255.","d1322d6b":"inp = Input(shape=(32,32,3))\n\nx = Conv2D(filters=32, kernel_size=(3,3),activation='relu', padding='same')(inp)\nx = Conv2D(filters=32, kernel_size=(3,3),activation='relu', padding='same')(x)\nx = MaxPooling2D(pool_size=2, strides=2,padding='valid')(x)\n\nx = Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same')(x)\nx = Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same')(x)\nx = MaxPooling2D(pool_size=2, strides=2, padding='valid')(x)\n\nx = Flatten()(x)\nx = Dropout(0.4)(x)\nx = Dense(units=64, activation='relu')(x)\n\nx = Dense(units=10, activation='softmax')(x)\n\nmodel_costume_cnn = Model(inp, x)\nmodel_costume_cnn.summary()","96bfb548":"model_costume_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory_costume_cnn = model_costume_cnn.fit(train_data,train_labels, batch_size=8, epochs=10, validation_split=0.15)","1cd7c89b":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\n#Assigning the first subplot to graph training loss and validation loss\nax[0].plot(history_costume_cnn.history['loss'],label='Training Loss')\nax[0].plot(history_costume_cnn.history['val_loss'],label='Validation Loss')\n\n#Plotting the training accuracy and validation accuracy\nax[1].plot(history_costume_cnn.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_costume_cnn.history['val_accuracy'],label='Validation Accuracy')\n\nplt.legend()","2c0a4e4b":"(train_data, train_labels),(test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\ntrain_data = tf.keras.applications.resnet50.preprocess_input(train_data)\ntest_data = tf.keras.applications.resnet50.preprocess_input(test_data)","1a5be7bc":"resnet = tf.keras.applications.ResNet50(input_shape=(224,224,3), include_top=False, weights='imagenet', classes=10)\nresnet.trainable = False\n\ninputs = Input((32,32,3))\n\nx = UpSampling2D((7,7))(inputs)\n\nx = resnet(x)\n\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.3)(x)\n\nx = Dense(units=128, activation='relu')(x)\nx = BatchNormalization()(x)\n\noutput = Dense(units=10,activation = 'softmax')(x)\nmodel_resnet = Model(inputs, output)\nmodel_resnet.summary()","b2df6afa":"resnet_learning_rate = 0.0001\nmodel_resnet.compile(optimizer=Adam(learning_rate=resnet_learning_rate),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nsavebest = tf.keras.callbacks.ModelCheckpoint('resnet_beforefinetuning.h5', save_best_only=True);\nhistory_resnet = model_resnet.fit(train_data, train_labels, batch_size=64, epochs=15, validation_split=0.15, callbacks=[savebest])","0e9a9914":"model_resnet = tf.keras.models.load_model('resnet_beforefinetuning.h5')\nmodel_resnet.trainable = True\nmodel_resnet.compile(optimizer=RMSprop(learning_rate=resnet_learning_rate\/10),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nhistory_resnet = model_resnet.fit(train_data, train_labels, batch_size=32, epochs=3, validation_split=0.15)","90ee9487":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\n#Assigning the first subplot to graph training loss and validation loss\nax[0].plot(history_resnet.history['loss'],label='Training Loss')\nax[0].plot(history_resnet.history['val_loss'],label='Validation Loss')\n\n#Plotting the training accuracy and validation accuracy\nax[1].plot(history_resnet.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_resnet.history['val_accuracy'],label='Validation Accuracy')\n\nplt.legend()","dcbc598e":"model_resnet.evaluate(test_data,test_labels)","b26552e3":"(train_data, train_labels),(test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\ntrain_data = tf.keras.applications.mobilenet_v3.preprocess_input(train_data)\ntest_data = tf.keras.applications.mobilenet_v3.preprocess_input(test_data)\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)","5154bfe4":"mobilenet = tf.keras.applications.MobileNetV3Small(input_shape=(96,96,3), include_top=False, weights='imagenet', classes=10)\nmobilenet.trainable = False\n\ninputs = Input((32,32,3))\n\nx = UpSampling2D((3,3))(inputs)\n\nx = mobilenet(x)\n\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.4)(x)\n\nx = Dense(units=128, activation='relu')(x)\nx = BatchNormalization()(x)\n\n\noutput = Dense(units=10,activation = 'softmax')(x)\nmodel_mobilenet = Model(inputs, output)\nmodel_mobilenet.summary()","4fcc6859":"model_mobilenet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nsavebest = tf.keras.callbacks.ModelCheckpoint('mobile_beforefinetuning.h5', save_best_only=True)\nhistory_mobilenet_1 = model_mobilenet.fit(train_data, train_labels, batch_size=64, epochs=5, validation_split=0.15, callbacks=[savebest])","f0526635":"model_mobilenet = tf.keras.models.load_model('mobile_beforefinetuning.h5')\nmodel_mobilenet.trainable = True\nmodel_mobilenet.compile(optimizer=RMSprop(0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory_mobilenet = model_mobilenet.fit(train_data, train_labels, batch_size=32, epochs=20, validation_split=0.15)","28a1b1af":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\n#Assigning the first subplot to graph training loss and validation loss\nax[0].plot(history_mobilenet.history['loss'],label='Training Loss')\nax[0].plot(history_mobilenet.history['val_loss'],label='Validation Loss')\n\n#Plotting the training accuracy and validation accuracy\nax[1].plot(history_mobilenet.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_mobilenet.history['val_accuracy'],label='Validation Accuracy')\n\nplt.legend()","a1cc5d60":"(train_data, train_labels),(test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\ntrain_data = tf.keras.applications.vgg19.preprocess_input(train_data)\ntest_data = tf.keras.applications.vgg19.preprocess_input(test_data)\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)","6409516a":"vgg19 = tf.keras.applications.VGG19(input_shape=(224,224,3), include_top=False, weights='imagenet', classes=10)\nvgg19.trainable = False\n\ninputs = Input((32,32,3))\n\nx = UpSampling2D((7,7))(inputs)\n\nx = vgg19(x)\n\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\n\nx = Dense(units=128, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\n\noutput = Dense(units=10,activation = 'softmax')(x)\nmodel_vgg19 = Model(inputs, output)\nmodel_vgg19.summary()","4135f22e":"initial_epochs = 17\nmodel_vgg19.compile(optimizer=Adam(0.001),loss='categorical_crossentropy',metrics=['accuracy'])\nsavebest = tf.keras.callbacks.ModelCheckpoint('vgg19_beforefinetuning.h5', save_best_only=True)\nhistory_vgg19_1 = model_vgg19.fit(train_data, train_labels, batch_size=64, epochs=initial_epochs, validation_split=0.15, callbacks=[savebest])","bac762d0":"model_vgg19 = tf.keras.models.load_model('vgg19_beforefinetuning.h5')\nmodel_vgg19.trainable = True\nmodel_vgg19.compile(optimizer=RMSprop(0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory_vgg19 = model_vgg19.fit(train_data, train_labels, batch_size=32, epochs=5, validation_split=0.15)","b03ecf0c":"f,ax=plt.subplots(2,1,figsize=(10,10)) \n\n#Assigning the first subplot to graph training loss and validation loss\nax[0].plot(history_vgg19.history['loss'],label='Training Loss')\nax[0].plot(history_vgg19.history['val_loss'],label='Validation Loss')\n\n#Plotting the training accuracy and validation accuracy\nax[1].plot(history_vgg19.history['accuracy'],label='Training Accuracy')\nax[1].plot(history_vgg19.history['val_accuracy'],label='Validation Accuracy')\n\nplt.legend()","389f20c9":"# VGG-19","aeb91081":"As we can see in the plots, our model is overfitted at epoch=10. we can use earlystop in order to prevent this issue but let's use some pretrained model and compare our model to them.","95ac938b":"# ResNet50 with fine tuning\nwe will use resnet50 model without its top and we will freeze the layers wieghts. After training and fitting data our weights would be something reasonable, then we will unfreeze all the weight and fit the data again.","6c696790":"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\nWe are going to build a CNN model to classify these images and then we will use transfer learning to find out which one worked better.\nLet's start with out dataset and take look at it.\n* Costume CNN\n* ResNet50 with fine tuning\n* MobileNet with fine tuning\n* VGG-19 with fune tuning","508bbbf6":"So MobileNetV3 with fine tuning did actually a pretty good job. According to the plot the model is obviously not overfitting and we have solid accuracy of 87%. Let's see if VGG-19 can do a better job!","3a202f35":"Before changing our data let's see some examples of it to have better sight of our dataset.","15ab6383":"As we can see in the cell below out data type is unit8 and we need to change change it to float32. Besides nomalizing our data would be helpfull. That would wrap up out preprocessing for images. We'll see more when we are using transfer learning.","6d6f801e":"# MobileNetV2 "}}