{"cell_type":{"c617960c":"code","1d4cb9b8":"code","38cd9696":"code","2e110678":"code","00de46a9":"code","76d9c906":"markdown"},"source":{"c617960c":"import torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)\n\ntrain = pd.read_csv('..\/input\/ai-tomato\/training_set.csv', header=None, skiprows=1)\n\ntrain","1d4cb9b8":"train[0] = train[0] % 10000 \/100\nxtrain = train.loc[:,[i for i in train.keys()[:-1]]]\nytrain = train[train.keys()[-1]]\n\nxtrain = np.array(xtrain)\nxtrain = torch.FloatTensor(xtrain).to(device)\n\nytrain = np.array(ytrain)\nytrain = torch.FloatTensor(ytrain).view(-1,1).to(device)\n\nytrain","38cd9696":"dataset = TensorDataset(xtrain, ytrain)\ndataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n\ntorch.manual_seed(1)\n\nmodel = nn.Linear(7,1)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.8)\nloss = nn.MSELoss().to(device)\n\nnb_epochs = 500\nfor epoch in range(nb_epochs + 1):\n  for batch_idx, samples in enumerate(dataloader):\n    x, y = samples\n\n    H = model(x)\n    cost = loss(H, y)\n\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n\n  if epoch%50 == 0:\n      print('Epoch {}  Cost {}'.format(epoch, cost.item()))\n\nprint('Learning Finished')","2e110678":"test = pd.read_csv('..\/input\/ai-tomato\/test_set.csv')\ntest=test.dropna(axis=1)","00de46a9":"test['date'] = test['date'] % 10000 \/100\nxtest = test.loc[:,[i for i in test.keys()[:]]]\nxtest = np.array(xtest)\nxtest = torch.from_numpy(xtest).float().to(device)\n\nH = model(xtest)\n\nH = H.cpu().detach().numpy().reshape(-1,1)\n\nsubmit = pd.read_csv('..\/input\/ai-tomato\/submit_sample.csv')\n\nfor i in range(len(submit)):\n  submit['expected'][i] = H[i]\n\nsubmit.to_csv('sub.csv', index = None, header=True)\n\nsubmit","76d9c906":"baseline\uacfc \ub2e4\ub978 \uc810\n\n-\ubbf8\ub2c8\ubc30\uce58\ud559\uc2b5\n-test\uc758 nan \uc5f4 \uc81c\uac70"}}