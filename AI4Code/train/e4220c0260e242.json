{"cell_type":{"33d2a6fa":"code","1a1559fd":"code","48d027d3":"code","0282a7ea":"code","cacdbfef":"code","693ad9c3":"code","89eaa052":"code","582049b2":"code","d58bba08":"code","2ada97e4":"code","a49ada97":"code","3322574d":"code","472757ad":"code","a8f4b597":"code","927a514e":"code","4d1d9de7":"code","0425c7fb":"code","f03b1596":"code","a795ea2f":"code","f7cee7e9":"code","7e3f724d":"code","67d7db34":"code","55932c20":"code","e5bde048":"code","f6174b93":"code","4c0e5a13":"code","68db2245":"code","09817d46":"code","64e990e4":"code","65a3704e":"code","5222c34b":"code","f73f6263":"code","50ee89b6":"code","faf9bd06":"code","79861444":"markdown","a4125f29":"markdown","fa6adb8c":"markdown","b4fc4c74":"markdown","cb8253f8":"markdown","5f3dc9f0":"markdown","f8ea260a":"markdown","c1a1b4f3":"markdown","1956a134":"markdown","5ceb4ad9":"markdown","f67936f8":"markdown","0b9ff106":"markdown","7c4fb490":"markdown","0418675c":"markdown","bcdbf5e3":"markdown"},"source":{"33d2a6fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder \nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1a1559fd":"data= pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","48d027d3":"print(\"data shape: \" ,data.shape)\nprint(\"data columns: \" ,list(data.columns))","0282a7ea":"data.info()","cacdbfef":"data.describe()\n","693ad9c3":"data['Survived'].value_counts().plot.pie(figsize=(6,6))","89eaa052":"def plot_by(data,feature):\n    groupedData = data[feature].groupby(data[\"Survived\"])\n    groupedData = pd.DataFrame({\n        'Survived' : groupedData.get_group(1),\n        'Dead': groupedData.get_group(0)\n    })\n    histogram = groupedData.plot.hist(bins=40,alpha=0.4)\n    histogram.set_xlabel(feature)\n    histogram.plot()","582049b2":"data['Sex'] = data['Sex'].map({'female': 0, 'male': 1})\ndata['Sex'].values.reshape(-1,1)\nenc = OneHotEncoder()\nss = pd.DataFrame(enc.fit_transform(data['Sex'].values.reshape(-1,1)).toarray(),columns=['male','female'])\n","d58bba08":"plot_by(data,'Parch')","2ada97e4":"plot_by(data,'SibSp')","a49ada97":"data['Familly'] = data['SibSp'] + data['Parch']\nplot_by(data,'Familly')","3322574d":"#new features male and female using one hot encoders \ndata['Male'] = ss['male']\ndata['female'] = ss['female']\ndata = data.loc[:, data.columns != 'Sex']\ndata['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\ndata.head()","472757ad":"#new feature (title)\ntitle_names = (data['Title'].value_counts() < 10)\ndata['Title'] = data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\nl = LabelEncoder()\ndata['Title'] = l.fit_transform(data['Title'])","a8f4b597":"Embarked = set(data.loc[data[\"Embarked\"].notnull()][\"Embarked\"])\nEmbarked_to_number = {ni: indi for indi, ni in enumerate(set(Embarked))}\nprint(Embarked)\nprint(Embarked_to_number)\ndata['Embarked'] = data['Embarked'].map(Embarked_to_number)","927a514e":"data['alone'] = (data['Familly'] == 0).astype('int')","4d1d9de7":"data['Embarked'].hist()","0425c7fb":"data.isnull().sum()","f03b1596":"data = data.loc[:, data.columns != 'PassengerId']\ndata = data.loc[:, data.columns != 'Cabin']","a795ea2f":"print(data.shape)\n#complete missing age with median\ndata['Age'].fillna(data['Age'].median(), inplace = True)\n\n#complete embarked with mode\ndata['Embarked'].fillna(data['Embarked'].median(), inplace = True)\n\n#complete missing fare with median\ndata['Fare'].fillna(data['Fare'].median(), inplace = True)\ndata = data.dropna(how='any')\n\n#####################\ndata.isnull().sum()\n","f7cee7e9":"data = data.loc[:, data.columns != 'Ticket']\ndata = data.loc[:, data.columns != 'Name']\ndata.info()\n","7e3f724d":"import seaborn as sns #the librery we'll use for the job xD\n\ncorrmat = data.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, cbar=True, annot=True, square=True, vmax=.8);","67d7db34":"data.head()","55932c20":"data.columns","e5bde048":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score, make_scorer,f1_score, precision_score, recall_score, confusion_matrix","f6174b93":"#preparing the data\nX_cols = list(data.columns)\nX_cols.remove('Survived')\nY=data['Survived']\nrescaledX = StandardScaler().fit_transform(data[X_cols])\nX=pd.DataFrame(data = rescaledX, columns= X_cols)\n# X=data[X_cols]\nX_train,Y_train = X,Y","4c0e5a13":"%%time\nsvm1 = svm.SVC(kernel='linear',random_state = 42)\nsvm2 = svm.SVC(kernel='rbf',random_state = 42) \nlr = LogisticRegression(random_state = 42)\ngb = GaussianNB()\nrf = RandomForestClassifier(random_state = 42)\nknn = KNeighborsClassifier(n_neighbors=15)\ntree = tree.DecisionTreeClassifier()\nmodels = {\"Logistic Regression\": lr, 'DecisionTreeClassifier' : tree, \"Random Forest\": rf, \"svm linear\": svm1 , \"svm rbf\": svm2,\"KNeighborsClassifier\": knn ,'GaussianNB': gb}\nl=[]\nfor model in models:\n    l.append(make_pipeline(Imputer(),  models[model]))\n\n        \ni=0\nfor Classifier in l:    \n    accuracy = cross_val_score(Classifier,X_train,Y_train,scoring='accuracy',cv=5)\n    print(\"===\", [*models][i] , \"===\")\n    print(\"accuracy = \",accuracy)\n    print(\"accuracy.mean = \", accuracy.mean())\n    print(\"accuracy.variance = \", accuracy.var())\n    i=i+1\n    print(\"\")\n    ","68db2245":"k_number = [i for i  in range(1,100,2)]\nacc = []\nks = []\nfor i in range(len(k_number)):\n    knn = KNeighborsClassifier(n_neighbors=k_number[i])\n    accuracy = cross_val_score(knn,X_train,Y_train,scoring='accuracy',cv=5)\n    acc.append(accuracy.mean())\n    ks.append(k_number[i])\nplt.plot(ks,acc)","09817d46":"print(\"best knn score: \", max(acc))\nprint(\"best k is:\", ks[acc.index(max(acc))] )","64e990e4":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'bootstrap': [True,False],\n    'max_depth': [130,140,150,160, None],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 2],\n    'min_samples_split': [12, 14, 16],\n    'n_estimators': [100, 110, 120, 130,140]\n}\n# Create a based model\nrf = RandomForestClassifier(random_state = 42)\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\ngrid_search.fit(X_train, Y_train)\n","65a3704e":"print(grid_search.best_score_)\nprint(grid_search.best_estimator_)\nrf = grid_search.best_estimator_","5222c34b":"svm2 = svm.SVC(kernel='rbf',random_state = 42) \nsvm2.fit(X_train, Y_train)","f73f6263":"data= pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest = data.copy()\ndata['Sex'] = data['Sex'].map({'female': 0, 'male': 1})\ndata['Sex'].values.reshape(-1,1)\nenc = OneHotEncoder()\nss = pd.DataFrame(enc.fit_transform(data['Sex'].values.reshape(-1,1)).toarray(),columns=['male','female'])\ndata['Familly'] = data['SibSp'] + data['Parch']\ndata['Male'] = ss['male']\ndata['female'] = ss['female']\ndata = data.loc[:, data.columns != 'Sex']\ndata['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\ntitle_names = (data['Title'].value_counts() < 10)\ndata['Title'] = data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\nl = LabelEncoder()\ndata['Title'] = l.fit_transform(data['Title'])\nEmbarked = set(data.loc[data[\"Embarked\"].notnull()][\"Embarked\"])\nEmbarked_to_number = {ni: indi for indi, ni in enumerate(set(Embarked))}\ndata['Embarked'] = data['Embarked'].map(Embarked_to_number)\ndata['alone'] = (data['Familly'] == 0).astype('int')\ndata = data.loc[:, data.columns != 'PassengerId']\ndata = data.loc[:, data.columns != 'Cabin']\ndata['Age'].fillna(data['Age'].median(), inplace = True)\ndata['Embarked'].fillna(data['Embarked'].median(), inplace = True)\ndata['Fare'].fillna(data['Fare'].median(), inplace = True)\ndata = data.dropna(how='any')\ndata.isnull().sum()\ndata = data.loc[:, data.columns != 'Ticket']\ndata = data.loc[:, data.columns != 'Name']\nX_cols = list(data.columns)\nrescaledX = StandardScaler().fit_transform(data[X_cols])\nX=pd.DataFrame(data = rescaledX, columns= X_cols)\nX_test = X","50ee89b6":"predictions = svm2.predict(X_test)\nsubmission = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})","faf9bd06":"filename = 'Titanic Predictions 1.csv'\nsubmission.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","79861444":"# Now let's train!","a4125f29":"**Great**, now let's move to Random forest, I would like to run few **grid search** iteration to find the best paramters\/estimator, let's see :","fa6adb8c":"# moving on to the test set\ndon't try to read too much haha, I will just apply what I have done to the train data on the test data so I can run through the estimator.","b4fc4c74":"Hello, Today I am going to give the titanic problem a try ! hopefully i archive good score","cb8253f8":"Cabin has to many null values, so i think the best option is to delete it\nand PassengerId will not give us any information ","5f3dc9f0":"Okay let's pick the top four models \n* svm rbf\n* KNeighborsClassifier\n* GaussianNB \n* Random Forest \n\nlet's start with knn ","f8ea260a":"now let's try on diffrent models","c1a1b4f3":"Okay!\n# Now some visualization","1956a134":"getting the basic information from it","5ceb4ad9":"First thing first is reading the data","f67936f8":"As we you saw random forest did a good job, but not as much as SVM with the rbf kernel, so it will be out official estimator.","0b9ff106":"let's see the best score we got","7c4fb490":"Let's check ths null values now !","0418675c":"tweaks on the data !","bcdbf5e3":"importing the needed libraries!"}}