{"cell_type":{"ca5bb20f":"code","2baf9df8":"code","0f55ef85":"code","9233beff":"code","6ca1d827":"code","ed92b072":"code","891242ce":"code","03acb8a8":"code","4660ac76":"code","53678e7e":"code","58271e97":"code","bc87ffde":"code","83a82b9c":"code","49d8853e":"code","82692abb":"markdown","fb022ed3":"markdown","67ae8be8":"markdown","661cd2e4":"markdown","fa5a0939":"markdown","6888eabd":"markdown","70b79c87":"markdown","b695bacf":"markdown","2d02a19a":"markdown","8e0876dc":"markdown","3e7eec31":"markdown","cfdc31cf":"markdown","6aeec815":"markdown","a7d5451a":"markdown","dff29428":"markdown"},"source":{"ca5bb20f":"import numpy as np # linear algebra\nimport os\nfrom time import time\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, image\nfrom keras.utils import np_utils\nimport json\nfrom PIL import Image\nimport os\nimport tensorflow as tf","2baf9df8":"data_dir = \"..\/input\/coin-images\/coins\/data\"\n\ndata_train_path =  data_dir + '\/train'\ndata_valid_path = data_dir + '\/validation'\ndata_test_path =  data_dir + '\/test'\n\nprint(os.listdir(\"..\/input\/coin-images\/coins\/data\"))","0f55ef85":"with open('..\/input\/coin-images\/cat_to_name.json', 'r') as json_file:\n    cat_2_name = json.load(json_file)\n\nprint(cat_2_name['200'])","9233beff":"batch_size=120\n\n# Transforms\ndatagen_train = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.1,  # randomly shift images horizontally \n    height_shift_range=0.1,  # randomly shift images vertically\n    horizontal_flip=True,\n    featurewise_std_normalization=True, # Normalize images\n    samplewise_std_normalization=True)\n\ndatagen_valid = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.1,  # randomly shift images horizontally\n    height_shift_range=0.1,  # randomly shift images vertically\n    horizontal_flip=True,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True)\n\ndatagen_test = ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_std_normalization=True,\n    samplewise_std_normalization=True)","6ca1d827":"\ntrain_generator = datagen_train.flow_from_directory(\n        data_train_path,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalid_generator = datagen_valid.flow_from_directory(\n        data_valid_path,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')\n\ntest_generator = datagen_test.flow_from_directory(\n        data_test_path,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')","ed92b072":"import matplotlib.pyplot as plt\n\n\n# Lets have a look at some of our images\nimages, labels = train_generator.next()\n\nfig = plt.figure(figsize=(20,10))\nfig.subplots_adjust(wspace=0.2, hspace=0.4)\n\n# Lets show the first 32 images of a batch\nfor i, img in enumerate(images[:32]):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(img)\n    image_idx = np.argmax(labels[i])","891242ce":"int_to_dir = {v: k for k, v in train_generator.class_indices.items()}","03acb8a8":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D\nfrom keras.applications import ResNet50\nfrom keras.models import Model\n\n\n\nbase_model = ResNet50(\n    include_top=False,\n    weights=\"imagenet\"\n)\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='elu')(x)\nx = Dropout(0.95)(x)\n# and a logistic layer\npredictions = Dense(211, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = True","4660ac76":"from keras.optimizers import Adam\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n             metrics=['accuracy'])","53678e7e":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nnum_train = len(train_generator.filenames)\nnum_valid = len(valid_generator.filenames)\nnum_test = len(train_generator.filenames)\n\n\n# When to save the model\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n                               save_best_only=True)\n\n# Reduce learning rate when loss doesn't improve after n epochs\nscheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=5, min_lr=1e-8, verbose=1)\n\n# Stop early if model doesn't improve after n epochs\nearly_stopper = EarlyStopping(monitor='val_loss', patience=10,\n                              verbose=0, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch=num_train\/\/batch_size,\n                    epochs=40,\n                    verbose=1,\n                    callbacks=[checkpointer, scheduler, early_stopper],\n                    validation_data=valid_generator,\n                    validation_steps=num_valid\/\/batch_size)","58271e97":"model.save('model.h5')","bc87ffde":"model.load_weights('..\/input\/weightskerascoincnn\/model.weights.best.hdf5')","83a82b9c":"score = model.evaluate_generator(test_generator, steps=num_test\/\/1, verbose=1)\nprint('\\n', 'Test accuracy:', score[1])","49d8853e":"def get_prediction(img, real_label):\n    img = image.img_to_array(img)\/255\n    \n    #normalise image\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    img = (img - mean)\/std\n    \n    img_expand = np.expand_dims(img, axis=0)\n\n    prediction = model.predict(img_expand)\n    prediction_int = np.argmax(prediction)\n\n    dir_int = int_to_dir[prediction_int]\n    label_name = cat_2_name[str(dir_int)]\n    \n    print(\"Predicted: {}\\nReal:      {}\".format(label_name, cat_2_name[str(real_label)]))\n    print()\n\n\nfor i in range(10):\n    random_index = np.random.randint(0, len(test_generator.filenames))\n    \n    img = test_generator.filenames[random_index]\n    img = image.load_img(\"..\/input\/coin-images\/coins\/data\/test\/\"+img, target_size=(224,224))\n    real_label = test_generator.filenames[random_index].split(\"\/\")[0]\n\n    get_prediction(img, real_label)","82692abb":"**Plot some coins to see the transformations**","fb022ed3":"**Load libraries**","67ae8be8":"**Specify the optimizer**","661cd2e4":"**Load the json that maps the folder number to the coin name**","fa5a0939":"**Specify how I want to train the model and train the model. How to save the model, when to stop training etc.**","6888eabd":"**Save the model. That way we can load it elsewhere**","70b79c87":"**Keras maps each folder (class) to a number. Create a dictionary that maps the number assigned by keras to our folder real number**","b695bacf":"**Create the model using a pre-trained ResNet50. I add only the fully connected layers at the end.**","2d02a19a":"**Load the data using the generators**","8e0876dc":"**The end**","3e7eec31":"**Evaluate our model**","cfdc31cf":"**Sanity check to make sure nothing crazy is happening**","6aeec815":"**Create generators to apply transformations to the images during training**","a7d5451a":"**Load the best saved weights into the model with the best scores**","dff29428":"**Specify location of our data**"}}