{"cell_type":{"2534db0b":"code","caf75a82":"code","b032c10e":"code","0defdd81":"code","cb63ca6c":"code","8c69686c":"code","b0c846ce":"code","6ec4399d":"code","3764b89c":"code","290a975a":"code","30472316":"code","8abc4767":"code","88fa361f":"code","ab8a4faa":"code","b2990ca9":"code","b5044683":"code","911d89d8":"code","0f5f9085":"code","4d261731":"code","0f6f0018":"code","763a4c44":"code","1f456bc4":"code","62fe9019":"code","fcd23529":"code","bb30df89":"code","18dfe16b":"code","c5c68061":"code","17e4c86f":"code","4eb97695":"code","6a7460ea":"markdown","08ce5f93":"markdown","1eb908ce":"markdown","71b90d42":"markdown","75235bd8":"markdown","bcdb8659":"markdown","8255540e":"markdown","903e8a2e":"markdown","65aa53f2":"markdown","e2cf03b9":"markdown","8b7c3260":"markdown","d5b8c1b5":"markdown","99651b8f":"markdown","3082078d":"markdown","0caa592a":"markdown","62423e3f":"markdown"},"source":{"2534db0b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # seaborn package for visualising\nimport plotly.express as px # plotly visualisation\nimport time\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","caf75a82":"'''\nList of files present\n\/kaggle\/input\/novel-corona-virus-2019-dataset\/2019_nCoV_data.csv\n\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_2019_ncov_recovered.csv\n\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_2019_ncov_deaths.csv\n\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_2019_ncov_confirmed.csv\n'''\n#whole_data_path='..\/input\/novel-corona-virus-2019-dataset\/2019_nCoV_data.csv'\nwhole_data_path='..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv'\n\n#recovered_data_path='..\/input\/novel-corona-virus-2019-dataset\/time_series_2019_ncov_recovered.csv'\n#deaths_data_path='..\/input\/novel-corona-virus-2019-dataset\/time_series_2019_ncov_deaths.csv'\n#confirmed_data_path='..\/input\/novel-corona-virus-2019-dataset\/time_series_2019_ncov_confirmed.csv'\n\ncorona_data= pd.read_csv(whole_data_path)\n#recovered_data=pd.read_csv(recovered_data_path)\n#deaths_data=pd.read_csv(recovered_data_path)\n#confirmed_data=pd.read_csv(recovered_data_path)\n\n","b032c10e":"corona_data.shape\n#Total no. of rows","0defdd81":"corona_data.info()","cb63ca6c":"if 'Last Update' in corona_data.columns :\n    corona_data=corona_data.drop('Last Update',axis=1)\nelif  'SNo' in corona_data.columns:\n    corona_data=corona_data.drop('SNo',axis=1)\n    \n#corona_data[\"Date\"] = corona_data['ObservationDate'].astype('datetime64')\ncorona_data[\"ObservationDate\"] = corona_data['ObservationDate'].astype('datetime64')\n\ncorona_data[\"Confirmed\"] = corona_data['Confirmed'].astype('int64')\ncorona_data[\"Deaths\"] = corona_data['Deaths'].astype('int64')\ncorona_data[\"Recovered\"] = corona_data['Recovered'].astype('int64')\n\nprint('Minimum date collected - ',min(corona_data[\"ObservationDate\"]))\nprint('Maximum date collected(Latest data can be retrieved now) - ',max(corona_data[\"ObservationDate\"]))\n\ncorona_data=corona_data.rename(columns={\"ObservationDate\": \"Date\",\"Country\/Region\":\"Country\"})","8c69686c":"corona_data_date=pd.DataFrame(corona_data.groupby(by='Date').sum())\nif 'SNo' in corona_data_date.columns:\n    corona_data_date=corona_data_date.drop('SNo',axis=1)\ncorona_data_date['Date']=corona_data_date.index\ncorona_data_date.Date=corona_data_date.Date.apply(lambda x:x.date())","b0c846ce":"melted_data=pd.melt(corona_data_date,id_vars=['Date'])","6ec4399d":"def bar_plot(column_name):\n    plt.figure(figsize=(10,15))\n    plt.xticks(rotation=90)\n    plt.xlabel('Date', fontsize=18)\n    plot_1=sns.barplot(x='Date',y=column_name,data=corona_data_date)\n    plot_1","3764b89c":"bar_plot('Recovered')","290a975a":"bar_plot('Deaths')","30472316":"bar_plot('Confirmed')","8abc4767":"hm=sns.catplot(x='Date', y='value', hue='variable', data=melted_data, kind='bar',height=10,aspect =1.6,legend=True)\nhm.set_xticklabels( rotation=90)\n","88fa361f":"import plotly.express as px\nfig = px.line(melted_data, x=\"Date\",y='value', color='variable')\nfig.show()","ab8a4faa":"#Since this is a cumulative dataset we can take the maximum of the dataset and then perform our analysis\nlatest_data_corona=corona_data[(corona_data.Date==max(corona_data[\"Date\"]))]","b2990ca9":"corona_data_country=pd.DataFrame(latest_data_corona.groupby(by='Country').sum())\nif 'SNo' in corona_data_country:\n    corona_data_country=corona_data_country.drop('SNo',axis=1)\ncorona_data_country['country']=corona_data_country.index","b5044683":"print('Total no. of confirmed cases over these days',sum(latest_data_corona['Confirmed']))\nprint('Total no. of deaths over these days',sum(latest_data_corona['Deaths']))\nprint('Total no. of recovered cases over these days',sum(latest_data_corona['Recovered']))","911d89d8":"corona_data_country.sort_values(['Confirmed','Deaths','Recovered'],ascending=[False,False,False])","0f5f9085":"corona_data_country[\"country\"].replace({\"Ivory Coast\": \"Cote d'Ivoire\", \n                                        \"Mainland China\": \"China\",\n                                        \"Hong Kong\":\"Hong Kong, China\",\n                                       \"South Korea\":\"Korea, Rep.\",\n                                        \"UK\":\"United Kingdom\",\n                                        \"US\":\"United States\",\n                                        \"Macau\" :\"China\"\n                                       }, inplace=True)\n","4d261731":"df = px.data.gapminder().query(\"year == 2007\")\ncorona_data_country_geo_cd=pd.merge(corona_data_country,df,how='left',on='country')","0f6f0018":"#Removing NaN based rows \ncorona_data_country_geo_cd=corona_data_country_geo_cd.dropna(how='any')\ncorona_data_country_geo_cd=corona_data_country_geo_cd.drop(['year','lifeExp','pop','gdpPercap'],axis=1)","763a4c44":"fig = px.scatter_geo(corona_data_country_geo_cd[corona_data_country_geo_cd['country']!='China'], locations=\"iso_alpha\",\n                     size=\"Confirmed\", # size of markers, \"pop\" is one of the columns of gapminder)\n                    )\nfig.show()","1f456bc4":"fig = px.choropleth(corona_data_country_geo_cd[corona_data_country_geo_cd['country']!='China'], locations=\"iso_alpha\",\n                    color=\"Confirmed\", # lifeExp is a column of gapminder\n                    hover_name=\"country\", # column to add to hover information\n                    color_continuous_scale=px.colors.sequential.Electric)\nfig.show()","62fe9019":"fig = px.choropleth(corona_data_country_geo_cd[corona_data_country_geo_cd['country']!='China'], locations=\"iso_alpha\",\n                    color=\"Deaths\", # lifeExp is a column of gapminder\n                    hover_name=\"country\", # column to add to hover information\n                    color_continuous_scale=px.colors.sequential.Oranges_r)\nfig.show()","fcd23529":"fig = px.choropleth(corona_data_country_geo_cd[corona_data_country_geo_cd['country']!='China'], locations=\"iso_alpha\",\n                    color=\"Recovered\", # lifeExp is a column of gapminder\n                    hover_name=\"country\", # column to add to hover information\n                    color_continuous_scale=px.colors.sequential.Oranges_r)\nfig.show()","bb30df89":"#Analysis of China Region\n#corona_data.head()\ncorona_data[\"Country\"].replace({\"Ivory Coast\": \"Cote d'Ivoire\", \n                                        \"Mainland China\": \"China\",\n                                        \"Hong Kong\":\"Hong Kong, China\",\n                                       \"South Korea\":\"Korea, Rep.\",\n                                        \"UK\":\"United Kingdom\",\n                                        \"US\":\"United States\",\n                                        \"Macau\" :\"China\"\n                                       }, inplace=True)\ncorona_data.Date=corona_data.Date.apply(lambda x:x.date())","18dfe16b":"#Selecting data for only China regions including their province\nChina_data=corona_data[corona_data['Country']=='China']\nprint(China_data.columns)","c5c68061":"sns.catplot(y=\"Province\/State\", x=\"Confirmed\", data=China_data,kind='boxen',height=9,aspect=1.4);\n","17e4c86f":"sns.catplot(y=\"Province\/State\", x=\"Deaths\", data=China_data,kind='boxen',height=9,aspect=1.4);\n","4eb97695":"sns.catplot(y=\"Province\/State\", x=\"Recovered\", data=China_data,kind='boxen',height=9,aspect=1.4);\n","6a7460ea":"The Death toll rate reached an all time high in Hubei region while others getting aware of the issue decided to make this issue a critical one.We can confirm this by checking the Recovered no. of patients.","08ce5f93":" 1. Current details of column and their data types\n\n        | Column_Name         |Data_type|\n        |:-------------------:|:-------:|\n        |  Sno                | int64   |\n        |   ObservationDate   | object  |\n        |   Province\/State    | object  |\n        |   Country           | object  |\n        |   Last Update       | object  |\n        |   Confirmed         | float64 |\n        |   Deaths            | float64 |\n        |   Recovered         | float64 |\nRemoving the Last Update column as it is not currently needed.","1eb908ce":"### Important Docs\n\n1. [Time series](https:\/\/plot.ly\/python\/time-series\/)","71b90d42":"It is quite clear from the above graph is **Hubei** is the epicentre of the disease.It then spread onto other areas like **Anhui,Guangdong,Hunan,Henan**. We can confirm this when we look at those maps and then understand the flow of the virus.","75235bd8":"Initial graphs show that the recovery rate over these days has increased quite good. China especially created a hospital to treat and control the Corona virus within **10 Days** which is pretty amazing !!!","bcdb8659":"I think the above graph sums up all the analysis one needs to do.The virus has grown **EXPONENTIALLY** . This is because it spreads so quickly when people are talking or even sneezing. ","8255540e":"## Initial Dataset Description\n\nReading data from the datasets.Here is the description I have got from the dataset \nDataset Link : [Corona Virus Dataset](https:\/\/www.kaggle.com\/sudalairajkumar\/novel-corona-virus-2019-dataset)\n\n    corona_data    --> Daily level information on the number of 2019-nCoV affected cases across the globe\n    confirmed_data  --> Time series data of confirmed cases\n    deaths_data    --> Time series data of death cases\n    recovered_data --> Time series data of recovered cases\n\nI thank John Hopkins University and SRK for providing the dataset.I hope to learn a lot from it .\n\n### Part 1 : Corona Data\n\nI have started with the corona data which I think is the main dataset from which other datasets have been created from. ","903e8a2e":"I haven't worked on scattergeo of plotly and I couldn't find proper documents on how I can use plotly easily.I therefore did a workaround in which I found a work around to plot the values on to the maps.","65aa53f2":"I love Plotly but never used it properly until now. It is quite interactive and presentable in nature. I need to learn a lot about plotly but initally I think plotly is quite easy to build\n\n## Analysis based on Country \n\nI then concentrated on how the analysis worked based on the country. Clearly China is the epicentre of the virus.But it is also quite interesting to see how the virus spread to other countries as well !!!","e2cf03b9":"Amazingly enough the regions which were getting the highest no. of Confirmed cases do have a higher rate of Recovery cases as well.","8b7c3260":"    Confirmed - Cumulative number of confirmed cases till that date\n    Deaths - Cumulative number of of deaths till that date\n    Recovered - Cumulative number of recovered cases till that date","d5b8c1b5":"As I was talking before, although the confirmed cases is large the virus has a higher recovery rate than the deaths but we can't be quite sure unless one does a statistical inference to prove this hypotheses.","99651b8f":"We have converted the date from object format. The data is present from minimum of 22 Jan to 13 Feb 2020.This dataset is interesting because this dataset is for span of approx. 21 days and the virus unless contained is spreading like a wildfire (This is from the news as the analysis is yet to be done :D ).\n\nI am also getting the total count of Confirmed patients,Patients who died and the recovered patients over the days.","3082078d":"Based on 3 columns i.e. confirmed,deaths and recovered cases we need to do comprehensive EDA with respect to -\n    \n    1. Date (Transition of date and the no. of cases )\n    2. Province\/State,Country (No. of cases based on country )\n\nFor this, if we create functions we can call all the three variables one by one and evaluate the results.\n\n## Analysis based on Date\n\nThe approach I am planning is to first analyse the data based on date and how it has affected over a short span.I then plan to analyse it based on country .Cleaning up of data is needed as it is necessity to understand a little better.","0caa592a":"I plan to do further analysis based on China Region and then on how it is going to go further based on the regions over the time.\n\nPlease let me know If I need to make any changes. I am happy to learn. :)","62423e3f":"As compared to Recovery , I checked on the no. of deaths and over these days it has a fair share of deaths.One thing one can do is check the no. of deaths to the no. of recovery since using that we can analyse how severity the virus actually is."}}