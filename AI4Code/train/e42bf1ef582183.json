{"cell_type":{"27b9f2f4":"code","92601d61":"code","3ad3c54e":"code","6242a3a9":"code","a434c09d":"code","7f142455":"code","8b8b7f42":"code","4171fe24":"code","47d85212":"code","92269c31":"code","801e7edf":"code","a29e0e30":"code","05e62a1f":"code","a94868eb":"code","51fff543":"code","b1eea588":"code","bb0ad4e4":"code","26846299":"code","a481ae60":"markdown","0db9390b":"markdown","b6292d3d":"markdown","e211dc9b":"markdown","f6af79e0":"markdown","8f8a8654":"markdown","a8575204":"markdown"},"source":{"27b9f2f4":"# Data Manipulation libraries\nimport pandas as pd\nimport numpy as np\n\n# Data visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# for supporting sklearn-deap\n!pip install scikit-learn==0.23.2\n# for data preprocessing\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import cross_val_score, train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# for model evaluation\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score\n\n# for hyperparameter tuning using genetic algorithm\n!cp -r ..\/input\/sklearndeap024\/* .\/\n!python setup.py install\nimport evolutionary_search\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# calc time\nimport timeit\n# Seed for random state\nSEED = 42","92601d61":"df = pd.read_csv(\"..\/input\/network-intrusion-detection\/Train_data.csv\")","3ad3c54e":"# Let's view the data.\nprint(\"Training data has {} rows & {} columns\".format(df.shape[0],df.shape[1]))\ndf.head()","6242a3a9":"df.info()","a434c09d":"target_col = \"class\"\ncate_cols = df.drop(\"class\",1).select_dtypes(\"object\").columns\nnum_cols = df.select_dtypes(\"number\").columns","7f142455":"# Impute numerical features\ndf[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n\n# Impute categorical features\ndf[cate_cols] = df[cate_cols].apply(lambda x: x.fillna(x.value_counts().index[0]))\n\n# Encode target column\ndf[target_col] = df[target_col].apply(lambda x: 1 if x==\"anomaly\" else 0)\n\n# Filter missing values\ndf = df.dropna()","8b8b7f42":"# encode categorical columns\nencoder = OneHotEncoder(sparse=False)\nencoded = encoder.fit_transform(df[cate_cols])\nfeat_names = encoder.get_feature_names(cate_cols)\nencoded_df = pd.DataFrame(data = encoded, columns=feat_names)\n\n# scale numerical columns\nscaler = StandardScaler()\nscaled = scaler.fit_transform(df[num_cols])\nscaled_df = pd.DataFrame(scaled, columns = num_cols)\n\n# concat encoded and scaled data\ndf_processed = pd.concat([encoded_df,scaled_df,df[\"class\"]],axis=1)","4171fe24":"df_processed.info()","47d85212":"# Correlation Heatmap\nplt.figure(figsize=(14,10))\nsns.heatmap(df_processed.corr().apply(abs))","92269c31":"X_train, X_test, y_train, y_test = train_test_split(df_processed.drop(\"class\", axis=1), df_processed[\"class\"], test_size=0.25, random_state=SEED)","801e7edf":"y_train.value_counts()","a29e0e30":"# Random Forest Model\nrf = RandomForestClassifier()","05e62a1f":"grid = {'max_depth':[None,3,5,7,9], 'n_estimators': [50,100,200], 'min_samples_split': [3,5,7,9], 'max_features' : ['auto', 'sqrt', 'log2']}\neascv = evolutionary_search.EvolutionaryAlgorithmSearchCV(rf, grid, verbose=1)\neascv.fit(X_train, y_train)","a94868eb":"bestParams = eascv.best_params_","51fff543":"rf.set_params(**bestParams)","b1eea588":"start_time = timeit.timeit()\nrf.fit(X_train,y_train)\nprint(\"Training complete.\")\nprint(\"Time taken =\",abs(timeit.timeit()-start_time))","bb0ad4e4":"train_preds = rf.predict(X_train)\nprint(classification_report(y_train, train_preds))","26846299":"test_preds = rf.predict(X_test)\nprint(classification_report(y_test, test_preds))","a481ae60":"### Load the dataset","0db9390b":"#### Encoding Categorical Data","b6292d3d":"**We are `encoding` the target class to 0s and 1s, so that it can be used for further analysis and training.**","e211dc9b":"### Import Relevant Libraries","f6af79e0":"### Model Selection","8f8a8654":"#### Normalizing the numerical data.","a8575204":"### Data Analysis and Preprocessing"}}