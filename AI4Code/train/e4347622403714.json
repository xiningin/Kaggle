{"cell_type":{"a6cbc9a9":"code","0df227ae":"code","d0b26c51":"code","05077f4f":"code","67f03d9e":"code","896ea13d":"code","bb821261":"code","d84e5a3c":"code","c40f81fa":"code","1a2c97d9":"code","f246ab8a":"code","4cff961a":"code","79dadd1d":"code","7c25c682":"code","86ddc914":"code","17612c4b":"code","8eec15dd":"code","974395b3":"code","a8e7672d":"code","00190b5d":"code","d0e385d1":"code","7353555a":"code","c4c8f309":"code","023c5cf4":"code","cd87da81":"code","ac15c020":"code","d58be6b1":"code","222b8eca":"code","2af2a5d8":"code","a08c5043":"code","85e4f396":"code","0f635fd2":"code","d0246385":"code","2cf74528":"markdown","384adbc4":"markdown","2603bb93":"markdown","4f26c845":"markdown","2b98b454":"markdown","7cecf42e":"markdown","7c773933":"markdown","b3ed3ec8":"markdown","2af01566":"markdown","ea192c98":"markdown","54f34adf":"markdown"},"source":{"a6cbc9a9":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","0df227ae":"import fastai\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nimport cv2\n\nimport pandas as pd\nimport matplotlib.pyplot as plt","d0b26c51":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/tmp\/.cache\/torch\/checkpoints\/'):\n        os.makedirs('\/tmp\/.cache\/torch\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'\n!cp '..\/input\/resnet152\/resnet152.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet152-b121ed2d.pth'\n#!cp '..\/input\/densenet161\/densenet161-8d451a50.pth' '\/tmp\/.cache\/torch\/checkpoints\/densenet161-8d451a50.pth'","05077f4f":"import os\nos.listdir('..\/input')","67f03d9e":"print('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","896ea13d":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 1667\nseed_everything(SEED)","bb821261":"base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\ntrain_dir = os.path.join(base_image_dir,'train_images\/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['id_code'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head(10)","d84e5a3c":"len_df = len(df)\nprint(f\"There are {len_df} images\")","c40f81fa":"df['diagnosis'].hist(figsize = (10, 5))","1a2c97d9":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","f246ab8a":"   \nsrc = (ImageList.from_df(df=df,path='.\/',cols='path') #get dataset from dataset\n        .split_by_rand_pct(0.2, seed=42) #Splitting the dataset\n        .label_from_df(cols='diagnosis',label_cls=FloatList) #obtain labels from the level column\n      )\nsrc","4cff961a":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0, max_lighting=0.2)\ndata = (\n    src.transform(tfms,size=224)\n    .databunch()\n    .normalize(imagenet_stats)\n)\ndata","79dadd1d":"from sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')","7c25c682":"#update - kappa from fastai\nkappa = KappaScore()\nkappa.weights = \"quadratic\"\n#learn = cnn_learner(data, arch, metrics=kappa)","86ddc914":"learn = cnn_learner(data, base_arch=models.resnet152 ,\n                    metrics=[quadratic_kappa],model_dir='\/kaggle',\n                    pretrained=True,\n                    callback_fns=[partial(EarlyStoppingCallback, monitor='quadratic_kappa', \n                                          min_delta=0.01, patience=3)])","17612c4b":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","8eec15dd":"learn.fit_one_cycle(6, 3e-2)\n","974395b3":"learn.save('stage1')","a8e7672d":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","00190b5d":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","d0e385d1":"learn.fit_one_cycle(10, max_lr=slice(1e-6,1e-3))","7353555a":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","c4c8f309":"learn.export()\nlearn.save('stage2')\n","023c5cf4":"learn.show_results(ds_type=DatasetType.Train, rows=4, figsize=(8,10))","cd87da81":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\n#len(data.valid_ds)==len(losses)==len(idxs)\n#interp.plot_confusion_matrix(figsize=(8,8), dpi=60)","ac15c020":"valid_preds = learn.get_preds(ds_type=DatasetType.Valid)","d58be6b1":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","222b8eca":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","2af2a5d8":"optR = OptimizedRounder()\noptR.fit(valid_preds[0],valid_preds[1])","a08c5043":"coefficients = optR.coefficients()\nprint(coefficients)","85e4f396":"from fastai.core import *\nfrom fastai.basic_data import *\nfrom fastai.basic_train import *\nfrom fastai.torch_core import *\ndef _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset\n    old = ds.tfms\n    aug_tfms = [o for o in learn.data.train_ds.tfms]\n    try:\n        pbar = master_bar(range(num_pred))\n        for i in pbar:\n            ds.tfms = aug_tfms\n            yield get_preds(learn.model, dl, pbar=pbar)[0]\n    finally: ds.tfms = old\n\nLearner.tta_only = _tta_only\n\ndef _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10, with_loss:bool=False) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"\n    preds,y = learn.get_preds(ds_type)\n    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n    avg_preds = torch.stack(all_preds).mean(0)\n    if beta is None: return preds,avg_preds,y\n    else:            \n        final_preds = preds*beta + avg_preds*(1-beta)\n        if with_loss: \n            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n            return final_preds, y, loss\n        return final_preds, y\n\nLearner.TTA = _TTA","0f635fd2":"sample_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\nsample_df.head()","d0246385":"learn.data.add_test(ImageList.from_df(sample_df,'..\/input\/aptos2019-blindness-detection',folder='test_images',suffix='.png'))\npreds,y = learn.get_preds(ds_type=DatasetType.Test)\ntest_predictions = optR.predict(preds, coefficients)\nsample_df.diagnosis = test_predictions.astype(int)\nsample_df.head()\nsample_df.to_csv('submission.csv',index=False)","2cf74528":"we will be using a variable learning rate for the various layers. Using 'slice'  takes a start value and a stop value and train the very first layers at a learning rate of 1e-6, and the very last layers at a rate of 1e-4, and distribute all the other layers across that (i.e. between those two values equally).","384adbc4":"## Training (Transfer learning)","2603bb93":"## Submission\nLet's now create a submission","4f26c845":"## EDA","2b98b454":"## TTA\n\nTest-time augmentation, or TTA, is a commonly-used technique to provide a boost in your score, and is very simple to implement. Fastai already has TTA implemented, but it is not the best for all purposes, so I am redefining the fastai function and using my custom version.","7cecf42e":"## Optimize the Metric\n\nOptimizing the quadratic kappa metric was an important part of the top solutions in the previous competition. Thankfully, @abhishek has already provided code to do this for us. We will use this to improve the score.","7c773933":"## Fine Tune","b3ed3ec8":"The Kaggle competition used the Cohen's quadratically weighted kappa so I have that here to compare. This is a better metric when dealing with imbalanced datasets like this one, and for measuring inter-rater agreement for categorical classification (the raters being the human-labeled dataset and the neural network predictions). Here is an implementation based on the scikit-learn's implementation, but converted to a pytorch tensor, as that is what fastai uses.","2af01566":"Checking the distribution of labels and basic EDA..\n\nTodo: Training with old competition data","ea192c98":"**Training:**\n\nWe use transfer learning, where we retrain the last layers of a pretrained neural network. I use the ResNet and Densenet architectures trained on the ImageNet dataset, which has been commonly used for pre-training applications in computer vision. Fastai makes it quite simple to create a model and train.\n* Pretrained Weights have to be from publicly available datasets from Kaggle and not from internet.","54f34adf":"##References\n\nhttps:\/\/course.fast.ai\n\n\nhttps:\/\/www.kaggle.com\/harendrap\/fastai-densenet"}}