{"cell_type":{"4e948ea5":"code","d92de076":"code","fca75e56":"code","6afd001d":"code","9db54b69":"code","1a40d0c3":"code","f4cf1fa4":"code","581e88af":"code","2fe403a6":"code","a02ee14a":"code","74b78000":"code","0b6211c1":"code","5b8dee87":"code","3931bcd4":"code","5f29a141":"code","8ba706d4":"code","6685dd9f":"code","a17bf9d2":"code","65554dbc":"code","4d56a4a6":"code","6d4bced5":"code","d19e07f9":"code","035e3f4e":"code","16a0774d":"code","e7f51997":"code","9bb14b71":"code","eb456c90":"code","50436b6b":"code","04475173":"code","fbdc89cd":"code","3d7d35d2":"code","de410a88":"code","4837562d":"code","3f03e640":"code","6ae5180d":"code","6076cee8":"code","55d79e77":"markdown","d45ac58d":"markdown","46cab978":"markdown","2c46c90f":"markdown","d711bdae":"markdown","94207568":"markdown","5eb1ce77":"markdown"},"source":{"4e948ea5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d92de076":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","fca75e56":"# Loading Data\ntrain_data = pd.read_csv(\"\/kaggle\/input\/big-mart-sales-prediction\/Train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/big-mart-sales-prediction\/Test.csv\")","6afd001d":"train_data.head()","9db54b69":"test_data.head()","1a40d0c3":"train_data.describe()","f4cf1fa4":"train_data.info()","581e88af":"train_data.shape\n","2fe403a6":"test_data.shape","a02ee14a":"train_data.isnull().sum()","74b78000":"test_data.isnull().sum()","0b6211c1":"train_data.apply(lambda x: len(x.unique()))","5b8dee87":"# Handling Missing Values \ntrain_data['Item_Weight'].fillna(train_data['Item_Weight'].mean(),inplace=True)\ntest_data['Item_Weight'].fillna(test_data['Item_Weight'].mean(),inplace=True)\n\ntrain_data['Outlet_Size'].fillna(train_data['Outlet_Size'].mode()[0],inplace=True)\ntest_data['Outlet_Size'].fillna(test_data['Outlet_Size'].mode()[0],inplace=True)","3931bcd4":"train_data.dtypes","5f29a141":"train_data[\"Item_Fat_Content\"].value_counts()","8ba706d4":"# Here we an see that Low Fat and LF are same thing and reg and regilar is same thing \n# Replacing LF and low fat  with Low Fat\ntrain_data.Item_Fat_Content.replace('LF','Low Fat',inplace=True)\ntrain_data.Item_Fat_Content.replace('low fat','Low Fat',inplace=True)\ntest_data.Item_Fat_Content.replace('LF','Low Fat',inplace=True)\ntest_data.Item_Fat_Content.replace('low fat','Low Fat',inplace=True)\n# Replacing reg with Regular \ntrain_data.Item_Fat_Content.replace('reg','Regular',inplace=True)\ntest_data.Item_Fat_Content.replace('reg','Regular',inplace=True)","6685dd9f":"train_data[\"Item_Fat_Content\"].value_counts()","a17bf9d2":"train_data.Item_Type.value_counts().plot.bar(color='Red',figsize=(12,8))","65554dbc":"sns.heatmap(train_data.corr(),vmin=-1,vmax=3,square=True,annot=True,cmap='RdYlGn')","4d56a4a6":"train_data.dtypes","6d4bced5":"train_data.Outlet_Identifier.value_counts()","d19e07f9":"train_data.Item_Fat_Content.value_counts()","035e3f4e":"train_data.Outlet_Size.value_counts()","16a0774d":"train_data.Outlet_Location_Type.value_counts()","e7f51997":"train_data.Outlet_Type.value_counts()","9bb14b71":"train_data.Item_Type.value_counts()","eb456c90":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\n# For Train Data\ntrain_data['Outlet_Identifier']=le.fit_transform (train_data['Outlet_Identifier'])\ntrain_data['Item_Fat_Content']=le.fit_transform (train_data['Item_Fat_Content'])\ntrain_data['Outlet_Size']=le.fit_transform (train_data['Outlet_Size'])\ntrain_data['Outlet_Location_Type']=le.fit_transform (train_data['Outlet_Location_Type'])\ntrain_data['Outlet_Type']=le.fit_transform (train_data['Outlet_Type'])\ntrain_data['Item_Type']=le.fit_transform (train_data['Item_Type'])\n\n# For Test Data\ntest_data['Outlet_Identifier']=le.fit_transform (test_data['Outlet_Identifier'])\ntest_data['Item_Fat_Content']=le.fit_transform (test_data['Item_Fat_Content'])\ntest_data['Outlet_Size']=le.fit_transform (test_data['Outlet_Size'])\ntest_data['Outlet_Location_Type']=le.fit_transform (test_data['Outlet_Location_Type'])\ntest_data['Outlet_Type']=le.fit_transform (test_data['Outlet_Type'])\ntest_data['Item_Type']=le.fit_transform (test_data['Item_Type'])\n","50436b6b":"train_data.head()","04475173":"train_data.info()","fbdc89cd":"test_data.info()","3d7d35d2":"train = train_data.drop(['Item_Identifier','Item_Visibility'], axis=1)\ntest = test_data.drop(['Item_Identifier','Item_Visibility'], axis=1)\n\n","de410a88":"train.head()","4837562d":"y = train['Item_Outlet_Sales']\nx = train.drop('Item_Outlet_Sales', axis = 1)\n","3f03e640":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nX_train, X_test, Y_train, Y_test = train_test_split(x,y, random_state = 0, test_size = 0.25)\nmodel = RandomForestRegressor(random_state=40)\nmodel.fit(X_train, Y_train)\npred_y = model.predict(X_test)\n\n","6ae5180d":"model.score(X_train,Y_train)","6076cee8":"sns.distplot(pred_y,hist=False)\nsns.distplot(Y_test,hist=False,color='r')","55d79e77":"## Lets see what is there in the Data","d45ac58d":"**Now let's handle categorical values **","46cab978":"**There Two Columns with Missing values Item_Weight and Outlet_Type**\n** So Let's remove Missing values**","2c46c90f":"* **Lets Work with categorical data **","d711bdae":"## Model","94207568":"## Data Preprocessing","5eb1ce77":"## Importing Necessary Libraries"}}