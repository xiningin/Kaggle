{"cell_type":{"d5ef16f0":"code","cbefbccc":"code","2dc7dd29":"code","197558f8":"code","2040dad8":"code","ccdac9d2":"code","88c6c041":"code","b11608c3":"code","7900f6e8":"code","1071a798":"code","9d4b6453":"code","180b018e":"code","d09b43b5":"code","0c478fb5":"code","7a04939a":"code","baac2eb9":"code","a1e2fe6d":"code","1003b3f7":"markdown","a0a8f1cb":"markdown","6fd740d5":"markdown","37403c57":"markdown","2fccc73d":"markdown","6e0b6fa3":"markdown","0f39beb9":"markdown","493b154e":"markdown","1fdfa332":"markdown","76412cd1":"markdown","37b30fc5":"markdown","7d8e6e36":"markdown","024eec37":"markdown"},"source":{"d5ef16f0":"import pandas as pd\n\ndf = pd.read_table('..\/input\/criticas-peliculas-filmaffinity-en-espaniol\/reviews_filmaffinity.csv', sep='\\|\\|', header=0, engine='python')\ndf.sample(5)","cbefbccc":"# 1.- Nueva columna con la polaridad de los votos\ndf['polaridad'] = df['review_rate'].apply(lambda  x: 'positivo' if x > 6\n                                          else ('negativo' if x < 4\n                                                else 'neutro'))\ndf.sample(5)","2dc7dd29":"# 2.-  Distribuci\u00f3n num\u00e9rica de los votos de las cr\u00edticas.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nsns.catplot(x='review_rate', kind='count', color='b', data=df)\nplt.title('Distribuci\u00f3n Votos')\nplt.xlabel('Notas')\nplt.ylabel('N\u00ba Votos')","197558f8":"# 3.-  Distribuci\u00f3n de votos por polaridad\n\nsns.catplot(x='polaridad', kind='count', data=df,  order=['negativo', 'neutro', 'positivo'])\nplt.title('Distribuci\u00f3n Polaridad')\nplt.xlabel('Polaridad')\nplt.ylabel('N\u00ba Votos')","2040dad8":"# 4.- Distribuci\u00f3n de los votos por pel\u00edcula.\n\nsns.catplot(x=\"review_rate\", col=\"film_name\", data=df, kind='count', col_wrap=3)","ccdac9d2":"# 1.- Concatenaci\u00f3n de t\u00edtulo y cr\u00edtica\n\ndf['texto'] = df['review_title'] + ' ' + df['review_text']\ndf.head(5)","88c6c041":"# 2.- Pasamos a array de numpy el texto (X) y el target-polaridad (y)\n\nX = df['texto'].values\ny =  df['polaridad'].values\n","b11608c3":"# 3.- Importamos el modelo de spacy en espa\u00f1ol\n\nimport spacy\n\n# Este comando se ejecuta en consola\n!python -m spacy download es","7900f6e8":"import re\n\nfrom tqdm import tqdm\n\n# Importamos el modelo en espa\u00f1ol de spacy\nnlp = spacy.load('es')\n\n\ndef normalize(corpus):\n    \"\"\"Funci\u00f3n que dada una lista de textos, devuelve esa misma lista de textos\n       con los textos normalizados, realizando las siguientes tareas:\n       1.- Pasamos la palabra a min\u00fasculas\n       2.- Elimina signos de puntuaci\u00f3n\n       3.- Elimina las palabras con menos de 3 caracteres (palabras que seguramente no aporten significado)\n       4.- Elimina las palabras con m\u00e1s de 11 caracteres (palabras \"raras\" que seguramente no aporten significado)\n       5.- Elimina las stop words (palabras que no aportan significado como preposiciones, determinantes, etc.)\n       6.- Elimina los saltos de l\u00ednea (en caso de haberlos)\n       7.- Eliminamos todas las palabras que no sean Nombres, adjetivos, verbos o advervios\n    \"\"\"\n    for index, doc in enumerate(tqdm(corpus)):\n        doc = nlp(doc.lower())\n        corpus[index] = \" \".join([word.lemma_ for word in doc if (not word.is_punct)\n                                  and (len(word.text) > 3) \n                                  and (len(word.text) < 11) \n                                  and (not word.is_stop)\n                                  and re.sub('\\s+', ' ', word.text)\n                                  and (word.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV'])])\n        \n        \n    return corpus\n\n# Normalizaci\u00f3n\nX_norm = normalize(X)","1071a798":"# 1.- Particionamos los textos en entrenamiento y test (80% entrenamiento, 20% test)\n\nfrom sklearn.model_selection import train_test_split  \n\nX_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=0)\n\nprint('Textos de entrenamiento: {}'.format(len(X_train)))\nprint('Textos de test: {}'.format(len(X_test)))","9d4b6453":"import numpy as np\n\nkeys_train, counts_train = np.unique(y_train, return_counts=True)\nkeys_test, counts_test = np.unique(y_test, return_counts=True)\nperct_train = counts_train \/ np.sum(counts_train)\nperct_test = counts_test \/ np.sum(counts_test)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(1, 2, 1)\nplt.pie(perct_train, labels=keys_train, autopct='%1.1f%%')\nplt.title('Distribuci\u00f3n Target Train')\nplt.subplot(1, 2, 2)\nplt.pie(perct_test, labels=keys_test, autopct='%1.1f%%')\nplt.title('Distribuci\u00f3n Target Test')\nplt.plot()\n","180b018e":"from sklearn.feature_extraction.text import CountVectorizer\n\nbow = CountVectorizer(max_features=2000, min_df=3)\n\n# Creamos el modelo de bolsa de palabras con los textos de entrenamiento y aplicamos el modelo\nX_bow_train = bow.fit_transform(X_train)\n\n# A modo de ejemplo mostramos las 20 primeras palabras de la bolsa de palabras\nbow.get_feature_names()[0:21]","d09b43b5":"X_bow_test = bow.transform(X_test)","0c478fb5":"\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nmnb = MultinomialNB()\nbnb = BernoulliNB()\nlr = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\nsvm_lin = SVC(kernel='linear')\nsvm_rbf = SVC(kernel='rbf')\nrf_20 = RandomForestClassifier(n_estimators=500, bootstrap=True, criterion='gini', max_depth=20, random_state=0)\nrf_50 = RandomForestClassifier(n_estimators=500, bootstrap=True, criterion='gini', max_depth=50, random_state=0)\n\nclasificadores = {'Multinomial NB': mnb,\n                  'Bernoulli NB': bnb,\n                  'Regresion Logistica': lr,\n                  'SVM lineal': svm_lin,\n                  'SVM Kernel rbf': svm_rbf,\n                  'Random Forest d_20': rf_20,\n                  'Random Forest d_50': rf_50}\n\n\n# Ajustamos los modelos y calculamos el accuracy para los datos de entrenamiento\nfor k, v in clasificadores.items():\n    print ('CREANDO MODELO: {clas}'.format(clas=k))\n    v.fit(X_bow_train, y_train)","7a04939a":"\nfrom sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n\ndef evaluation(model, name, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Funci\u00f3n de devuelve en un diccionario las m\u00e9tricas de evaluaci\u00f3n de \n    Accuracy, Precision, Recall y F1 para los conjuntos de datos de entrenamiento y test\n        model: modelo a evaluar\n        name: nombre del modelo\n        X_train: Variables de entrada del conjunto de datos de entrenamiento\n        y_train: Variable de salida del conjunto de datos de entrenamiento\n        X_test: Variables de entrada del conjunto de datos de test\n        y_test: Variable de salida del conjunto de datos de test\n        return: diccionario con el nombre del modelo y el valor de las m\u00e9tricas\n    \"\"\"\n    model_dict = {}\n    model_dict['name'] = name\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n    model_dict['accuracy_train'] = accuracy_score(y_true=y_train, y_pred=y_pred_train)\n    model_dict['accuracy_tests'] = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n    model_dict['precision_train'] = precision_score(y_true=y_train, y_pred=y_pred_train, average='weighted')\n    model_dict['precision_tests'] = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted')\n    model_dict['recall_train'] = recall_score(y_true=y_train, y_pred=y_pred_train, average='weighted')\n    model_dict['recall_tests'] = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted')\n    model_dict['f1_train'] = f1_score(y_true=y_train, y_pred=y_pred_train, average='weighted')\n    model_dict['f1_tests'] = f1_score(y_true=y_test, y_pred=y_pred_test, average='weighted')\n    \n    return model_dict\n\n\n# Calculamos las m\u00e9tricas de los modelos por separado\nevaluacion = list()\nfor key, model in clasificadores.items():\n    evaluacion.append(evaluation(model=model, name=key, \n                                 X_train=X_bow_train, y_train=y_train,\n                                 X_test=X_bow_test, y_test=y_test))\n\n# Pasamos los resultados a un DataFrame para visualizarlos mejor\ndf = pd.DataFrame.from_dict(evaluacion)\ndf.set_index(\"name\", inplace=True)\ndf","baac2eb9":"# M\u00e9tricas a pintar\nMETRICS = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n\n# Transformamos el dataframe para pintar las gr\u00e1ficas con seaborn\ndf_plot = df.reset_index().melt(id_vars='name').rename(columns=str.title)\n\nplt.figure(figsize=(25, 12))\npos = 1\nfor metric in METRICS:\n    # Filtramos la m\u00e9trica a pintar\n    df_aux = df_plot[df_plot['Variable'].str.contains(metric)]\n    \n    # Pintamos la gr\u00e1fica en su posici\u00f3n 2x2\n    plt.subplot(2, 2, pos)\n    sns.barplot(x='Name', y='Value', hue='Variable', data=df_aux)\n    plt.title(metric.upper())\n    plt.grid()\n    plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n    plt.xticks(rotation=20)\n    pos += 1\nplt.show()","a1e2fe6d":"import itertools\n\nfrom sklearn.metrics import confusion_matrix\n\npolaridad = ['positivo', 'neutro', 'negativo']\n\n# Obtenemos las Matrices de confusi\u00f3n\nmsc = list()\nfor k, v in clasificadores.items():\n    print ('Obteniendo Matriz de Confusi\u00f3n de: {model}'.format(model=k))\n    model = {}\n    model['name'] = k\n    y_pred_train = v.predict(X_bow_train)\n    y_pred_test = v.predict(X_bow_test)\n    model['confusion_matrix_train'] = confusion_matrix(y_true=y_train, y_pred=y_pred_train, labels=polaridad)\n    model['confusion_matrix_test'] = confusion_matrix(y_true=y_test, y_pred=y_pred_test, labels=polaridad)\n    msc.append(model)\n\n    \n# Definimos el heatmap de la matriz de confusi\u00f3n\ndef plot_confusion_matrix(cm, classes, title, cmap=plt.cm.Greens):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n\n# Pintamos las matrices de confusi\u00f3n\nplt.figure(figsize=(20, 35))\npos = 0\nfor mc in msc:\n    pos += 1\n    plt.subplot(len(msc), 2, pos)\n    plot_confusion_matrix(mc['confusion_matrix_train'], classes=polaridad, \n                          title='{}\\nMatriz de Confusi\u00f3n Textos Entrenamiento'.format(mc['name']))\n    pos += 1\n    plt.subplot(len(msc), 2, pos)\n    plot_confusion_matrix(mc['confusion_matrix_test'], classes=polaridad, \n                          title='{}\\nMatriz de Confusi\u00f3n Textos Tests'.format(mc['name'] ))\nplt.show()","1003b3f7":"## 6.- Evaluaci\u00f3n de los modelos\n\n* Para cada uno de los modelos vamos a calcular las siguientes m\u00e9tricas de evaluaci\u00f3n:\n\n1. Accuracy\n1. Precision\n1. Recall\n1. F1","a0a8f1cb":"## 3.- Normalizaci\u00f3n de textos \n\n* Vamos a definir como texto a clasificar t\u00edtulo y la cr\u00edtica, ya que el t\u00edtulo aporta significado al texto.\n\n\n* En este punto realizaremos los siguientes pasos:\n\n1. Concatenaci\u00f3n de t\u00edtulo y cr\u00edtica\n1. Pasamos a array de numpy el texto y el target (polaridad)\n1. Importamos el modelo de spacy en espa\u00f1ol\n1. Normalizaci\u00f3n de los textos: La normalizaci\u00f3n es una tarea que tiene como objetivo poner todo el texto en igualdad de condiciones; como por ejemplo:\n        \n    * Pasar todo el texto a min\u00fasculas (o may\u00fasculas)\n    * Eliminar signos de puntuaci\u00f3n (puntos, comas, comillas, etc)\n    * Quitar las stop-words: pal\u00e1bras que no aportan significado a los textos\n    * Convertir n\u00fameros a su equivalente a palabras\n    * Transformar la palabra a su lema\n    * Pasar emoticonos a textos\n    * etc.","6fd740d5":"## 1.- Carga de datos","37403c57":"## 2.- Distribuci\u00f3n de votos (Positivo {>6} - Neutro {4-6} - Negativo {4>})\n\n1.- Creamos una nueva columna con la polaridad del voto: Positivo \\[10, 6), Neutro [6, 4], Negativo (4, 0\\].\n\n2.- Distribuci\u00f3n num\u00e9rica de los votos de las cr\u00edticas.\n\n3.- Distribuci\u00f3n categ\u00f3rica de la polaridad de los votos.\n\n4.- Distribuci\u00f3n de los votos por pel\u00edcula.","2fccc73d":"* Representamos las m\u00e9tricas para los diferentes modelos en un gr\u00e1fico de barras:","6e0b6fa3":"**NOTA:** *Si ejecutais este notebook en local, es posible que os de un error a la hora de importar el modelo de NLP en espa\u00f1ol. Si da ese error deb\u00e9is de cambiar el nombre del modelo de 'es' a 'es_core_news_sm' o como se indique en el proceso de importaci\u00f3n del modelo de Spacy.*","0f39beb9":"* Mostramos la distribuci\u00f3n del target de los datos de entrenamiento y test para ver si siguen una distribuci\u00f3n similar.","493b154e":"## 4.- Bolsa de Palabras (BoW) - Particionado de datos","1fdfa332":"### Creamos una bolsa de palabras de frecuencias con los textos de entrenamiento.\n\n* Creamos un modelo de bolsa de palabras con las 2000 palabras m\u00e1s frecuentes de los textos de entrenamiento que aparezcan por lo menos en 3 documentos distintos.","76412cd1":"* Con el modelo de bolsa de palabras creado con los textos de entrenamiento, aplicamos el modelo a los textos de test.","37b30fc5":"# An\u00e1lisis de sentimientos - Clasificaci\u00f3n de cr\u00edticas de pel\u00edculas filmaffinity\n\n* Notebook introductorio sobre clasificaci\u00f3n de textos, aplicando algoritmos de aprendizaje sencillos.\n\n\n* Este notebook tiene como objetivo mostrar todo el proceso de clasificaci\u00f3n de textos (an\u00e1lisis de sentimientos) sobre cr\u00edticas de pel\u00edculas.\n\n\n* El proceso realizado es el siguiente:\n\n1. Carga de datos\n2. Definici\u00f3n del target en funci\u00f3n de la nota de la cr\u00edtica {Negativo, Neutro, Positivo}\n3. Normalizaci\u00f3n de textos\n4. Particionado de datos en entrenamiento y test\n5. Creacci\u00f3n del modelos de bolsa de palabras y su apliaci\u00f3n a los textos\n6. Creacci\u00f3n de modelos de clasificaci\u00f3n con algoritmos de aprendizaje sencillos de clasificaci\u00f3n\n7. Evaluaci\u00f3n de los modelos\n","7d8e6e36":"* Dibujamos las matrices de confusi\u00f3n de cada uno de los modelos creados para los textos de entrenamiento y test","024eec37":"## 5.- Creacci\u00f3n de modelos (clasificaci\u00f3n)\n\nUtilizamos los siguientes algoritmos (o metaalgoritmos) de aprendizaje de clasificaci\u00f3n para crear modelos predictivos capaces de clasificar una cr\u00edtica de pelicula en alguna de las siguientes clases: {Negativa, Neutra, Positiva}\n\n* Multinomial Naive Bayes\n* Bernoulli Naive Bayes\n* Regresion Logistica\n* Support Vector Machine\n* Random Forest (ensemble)"}}