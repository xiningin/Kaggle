{"cell_type":{"9cadfc24":"code","ab2fba0a":"code","424963b3":"code","acf83540":"code","fcfc1684":"code","5462809e":"code","7249c1bd":"code","6093e506":"code","d9531b25":"code","6ec246fb":"code","c667636a":"code","082673a3":"code","b69d35d2":"code","9397deb3":"code","49f8cbad":"code","57f95286":"code","aa4d55e7":"code","5264aba2":"code","f995afda":"code","b72b0825":"code","86f70df3":"code","c877f6c8":"code","215a4c98":"markdown","bbaf13f8":"markdown","d13bcbe8":"markdown","7d68ccdc":"markdown","8c8c448f":"markdown","60ab60b4":"markdown","1c6a6a3f":"markdown","95651423":"markdown","29bdc7d8":"markdown","2c1d49a0":"markdown","87ab8841":"markdown","2585cd2b":"markdown","1b446659":"markdown","fd580350":"markdown","6ac534c7":"markdown","03083777":"markdown","da743c75":"markdown","7b9618d9":"markdown","b3569744":"markdown","700c8766":"markdown","2611e7d8":"markdown","368968aa":"markdown","1155671a":"markdown","34934719":"markdown","cf1cc0a4":"markdown","5fe307f6":"markdown","c50e016d":"markdown","0660e533":"markdown"},"source":{"9cadfc24":"import matplotlib.pyplot as matplotlib\nimport seaborn\nimport pandas\nimport numpy\n%matplotlib inline\n\n# Fun\u00e7\u00e3o para fazer reshape de listas 1D\ndef reshape(list1D):\n     return numpy.array(list1D).reshape(-1,1)\n    \n# Fun\u00e7\u00e3o para imprimir nosso modelo de Regress\u00e3o Logistica\ndef plot_ours(model):\n    x = numpy.linspace(0,1,50)\n    y = model.predict(reshape(x))\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Our Logistic model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n    \n# Fun\u00e7\u00e3o para imprimir o modelo \"padr\u00e3o\" de Regress\u00e3o Logistica \ndef plot_lr():\n    logistical = lambda x: numpy.exp(x)\/(1+numpy.exp(x))   \n    x = numpy.linspace(-10,10,50)\n    y = logistical(x)\n    matplotlib.figure(figsize=(4,4))\n    matplotlib.plot(x, y, color=\"red\")\n    matplotlib.suptitle('Logisitc Regression model')\n    matplotlib.xlabel('x')\n    matplotlib.ylabel('y')\n    matplotlib.show()\n\nplot_lr()\n# Apresentar o que \u00e9 um notebook a = 1, ...","ab2fba0a":"from sklearn.metrics import accuracy_score, confusion_matrix\nimport random\n\n# Uma fun\u00e7\u00e3o para criar um dataset com 10.000 n\u00fameros entre 0 e 1 classificados como 0 ou 1 (as vezes errado)\ndef create_dataset():\n    x = [random.random() for i in range(10000)]\n    classify = lambda i: int(i > 0.5) if random.random() > 0.1 else int(not i > 0.5)\n    dataset = pandas.DataFrame(x,columns=['x'])\n    dataset['y'] = dataset['x'].apply(classify)\n    return dataset \n    \ndataset = create_dataset()\ndataset","424963b3":"seaborn.scatterplot(data=dataset,x='x',y='y', alpha=0.01)","acf83540":"import tree\n# Aqui mapeia os dois tipos de diagn\u00f3sticos no espa\u00e7o\ndef plot_cancer_sizes(df):\n    matplotlib.figure(figsize=(12,12))\n    seaborn.kdeplot(df[df['diagnosis']=='M'].perimeter_worst, df[df['diagnosis']=='M'].area_worst, cmap=\"Reds\",  shade=True, alpha=0.3, shade_lowest=False)\n    seaborn.kdeplot(df[df['diagnosis']=='B'].perimeter_worst, df[df['diagnosis']=='B'].area_worst, cmap=\"Greens\", shade=True, alpha=0.3, shade_lowest=False)\n    matplotlib.show()\n\n# Faz um plot do perimeter_worst para os dois diagn\u00f3sticos\ndef plot_cancer_perimeter(df):\n    fig = seaborn.FacetGrid(df, hue=\"diagnosis\", aspect=3)\n    fig.map(seaborn.kdeplot, \"perimeter_worst\", shade=True)\n    fig.add_legend()\n    matplotlib.show()\n\n# Faz um plot da \u00e1rvore de decis\u00f5es\ndef plot_tree(model,x_train):\n    matplotlib.figure(figsize=(15,15))\n    tree.plot_tree(model, feature_names=x_train.columns, class_names=['benigno','maligno'], fontsize=14, filled=True)\n    matplotlib.show()\n\n# Faz um plot das import\u00e2ncias para um Random Forest\ndef plot_importances(model,df):\n    importances = model.feature_importances_\n    indices = numpy.argsort(importances)\n    matplotlib.figure(figsize=(12,8))\n    matplotlib.barh(range(len(indices)), importances[indices], color='b', align='center')\n    matplotlib.yticks(range(len(indices)), df.columns[indices])\n    matplotlib.suptitle('Import\u00e2ncia das caracter\u00edsticas')\n    matplotlib.show()\n\ncancer = pandas.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ncancer","fcfc1684":"plot_cancer_sizes(cancer)","5462809e":"nosso_cancer = list({\n 'radius_mean': 17.99,\n 'texture_mean': 10.38,\n 'perimeter_mean': 122.8,\n 'area_mean': 1001.0,\n 'smoothness_mean': 0.1184,\n 'compactness_mean': 0.2776,\n 'concavity_mean': 0.3001,\n 'concave points_mean': 0.1471,\n 'symmetry_mean': 0.2419,\n 'fractal_dimension_mean': 0.07871,\n 'radius_se': 1.095,\n 'texture_se': 0.9053,\n 'perimeter_se': 8.589,\n 'area_se': 153.4,\n 'smoothness_se': 0.006399,\n 'compactness_se': 0.04904,\n 'concavity_se': 0.05372999999999999,\n 'concave points_se': 0.01587,\n 'symmetry_se': 0.03003,\n 'fractal_dimension_se': 0.006193,\n 'radius_worst': 25.38,\n 'texture_worst': 17.33,\n 'perimeter_worst': 184.6,\n 'area_worst': 2019.0,\n 'smoothness_worst': 0.1622,\n 'compactness_worst': 0.6656,\n 'concavity_worst': 0.7119,\n 'concave points_worst': 0.2654,\n 'symmetry_worst': 0.4601,\n 'fractal_dimension_worst': 0.1189\n}.values())\n\nmodel.predict(reshape(nosso_cancer).transpose())","7249c1bd":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n","6093e506":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, result))","d9531b25":"def plot_iris(df):\n    seaborn.pairplot(df, hue=\"Species\")\n    matplotlib.show()\n\niris = pandas.read_csv('..\/input\/iris\/Iris.csv')\niris","6ec246fb":"plot_iris(iris)","c667636a":"titanic_train = pandas.read_csv(\"..\/input\/titanic\/train.csv\")\ntitanic_test = pandas.read_csv(\"..\/input\/titanic\/test.csv\")\ntitanic_train","082673a3":"import string\nimport time\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\ndef clear_sentence(sentence):\n    sentence = sentence.replace('<br \/>', ' ')\n    sentence = sentence.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n    sentence = sentence.lower()\n    return sentence\n\nimdb = pandas.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")\nimdb","b69d35d2":"diabetes = pandas.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndiabetes","9397deb3":"def plt_digit_from_row(row):\n    label, image = mnist_train.values[row,0], mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='hot')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n\nmnist_train = pandas.read_csv(\"..\/input\/mnist-in-csv\/mnist_train.csv\")\nmnist_test = pandas.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")\nmnist_train.head()","49f8cbad":"plt_digit_from_row(0)","57f95286":"mnist_train_labels, mnist_train_values = mnist_train.values[:,0], mnist_train.values[:,1:]\nmnist_test_labels, mnist_test_values = mnist_test.values[:,0], mnist_test.values[:,1:]","aa4d55e7":"model = LogisticRegression()\n\nmodel.fit(mnist_train_values, mnist_train_labels)\n\n\nprediction = model.predict(mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","5264aba2":"def plt_clothes_from_row(row):\n    label, image = fashion_mnist_train.values[row,0], fashion_mnist_train.values[row,1:]\n    matplotlib.imshow(image.reshape(28,28), cmap='gray')\n    matplotlib.title(\"Label: %s\"%label)\n    matplotlib.show()\n    \nfashion_mnist_train, fashion_mnist_test = pandas.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\"), pandas.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nfashion_mnist_train.head()","f995afda":"plt_clothes_from_row(0)","b72b0825":"fashion_mnist_train_labels, fashion_mnist_train_values = fashion_mnist_train.values[:,0], fashion_mnist_train.values[:,1:]\nfashion_mnist_test_labels, fashion_mnist_test_values = fashion_mnist_test.values[:,0], fashion_mnist_test.values[:,1:]","86f70df3":"model = LogisticRegression()\n\nmodel.fit(fashion_mnist_train_values, fashion_mnist_train_labels)\n\nprediction = model.predict(fashion_mnist_test_values)\n\nprint(classification_report(prediction, mnist_test_labels))","c877f6c8":"from mpl_toolkits.basemap import Basemap\n\n# Precisa ter as colunas 'lat' e 'long'. Retorna o mesmo dataframe com apenas os tweets na regi\u00e3o da austr\u00e1lia.\ndef pegar_tweets_na_australia(dataframe):\n    bot_lat, top_lat, left_lon, right_lon = -44,-10,109,156\n    top = dataframe.lat <= top_lat\n    bot = dataframe.lat >= bot_lat\n    left = dataframe.long >= left_lon\n    right = dataframe.long <= right_lon\n    index = top&bot&left&right \n    return dataframe[index]\n\n# Passe seu dataframe com os dados que voc\u00ea quer plotar e uma legenda (como string).\ndef plotar_mapa(dataframe,legenda):\n    Australia_map = Basemap(llcrnrlat=-44,urcrnrlat=-10,llcrnrlon=109,urcrnrlon=156)\n    matplotlib.figure(figsize=(12,10))\n    Australia_map.bluemarble(alpha=0.9)\n    seaborn.scatterplot(x='long', y='lat', data=dataframe, alpha=1, s=200, label=legenda)\n    matplotlib.show()","215a4c98":"Ok, cansamos de usar Logistic Regression. Queremos modelos diferentes para fazer aprendizado de m\u00e1quina! Vamos tentar utilizar uma \u00e1rvore de decis\u00f5es, \u00e9 o mesmo \"modelo\" que o Akinator funcionava!","bbaf13f8":"Ok, o seu desafio agora \u00e9 utilizar Machine Learning para fazer uma An\u00e1lise de Sentimentos nas reviews de filmes do IMDB. Neste dataset voc\u00ea possui 50.000 reviews de filmes classificadas como \"positiva\" e \"negativa\". Neste dataset, seu modelo pode demorar bastante (coisa de 5 minutos para cima). O qu\u00ea voc\u00ea precisa fazer:\n\n- Limpar as reviews (use a fun\u00e7\u00e3o clear_sentence para cada string do dataset)\n- Separe o treinamento e teste.\n- Vetorizar as palavras (pode usar o HashingVectorizer()). Procure no google como aplicar isso.\n- Coloque em um Machine Learning.\n\n**Objetivos**\n- Qual \u00e9 o melhor tipo de modelo de ML para esse NLP? (Dica: pense em modelos que trabalham com vetores)\n- Ultrapasse 90% de precis\u00e3o neste dataset demorando menos de 1 minuto para rodar (utilize time.time() para pegar os tempos.\n\n\n","d13bcbe8":"Ok, fa\u00e7a x com todas as colunas menos o diagn\u00f3stico, e y como diagn\u00f3stico! Lembre de separar os dados e aplicar a Regress\u00e3o Log\u00edstica","7d68ccdc":"Agora, vamos visualizar como o tamanho do per\u00edmetro e tamanho da \u00e1rea se comportam para o tipo maligno e benigno","8c8c448f":"Voc\u00ea vai precisar fazer o escalamento das imagens para poder ","60ab60b4":"# Aprendendo a usar o Kaggle\n\nOl\u00e1, seja bem vindo ao notebbok de classificadores de ML do Iris Data Science. N\u00f3s preparamos esse notebook para que voc\u00ea possa aprender do 0 at\u00e9 o conhecimento b\u00e1sico de uso de ML. Esse material \u00e9 baseado em dados de competi\u00e7\u00f5es e nas aulas do Prof. Pascal Yim (E.C. Lille).\n\nSe voc\u00ea nunca utilizou o Kaggle, crie sua conta e clique em \"Copy and Edit\" neste notebook e come\u00e7e a programar!\n\nSe voc\u00ea \u00e9 iniciante, comece aqui pelo come\u00e7o e siga as instru\u00e7\u00f5es. Se voc\u00ea j\u00e1 possui experi\u00eancia, pode seguir a frente e tentar os desafios!","1c6a6a3f":"Lembre-se sempre da aplica\u00e7\u00e3o de IA: classificar coisas! Imagine que eu sou um m\u00e9dico com um paciente com essas condi\u00e7\u00f5es. O c\u00e2ncer \u00e9 maligno ou benigno?","95651423":"Ok, s\u00f3 que voc\u00ea nunca encontrar\u00e1 na sua vida os dados dessa forma. Eles normalmente est\u00e3o armazenados em datasets que podem ser acessados por dataframes. A forma mais comum de acessar um dataset \u00e9 utilizando a biblioteca pandas. Vamos ver esse dataset de dataset de \\[0,1\\]  que possui mais 10.000 n\u00fameros. (Aten\u00e7\u00e3o, por volta de 10% das respostas est\u00e3o erradas!)","29bdc7d8":"# Desafio Final: Predizer elei\u00e7\u00f5es com Tweets\n\nDessa vez nem preparamos o dataset para voc\u00ea. Utilizando o dataset das elei\u00e7\u00f5es australianas, voc\u00ea consegue predizer que regi\u00f5es da Austr\u00e1lia apoiam qual partido? Tente treinar seu modelo em algum dataset classificado com positivo e negativo e ent\u00e3o fa\u00e7a o .fit() no dataset das elei\u00e7\u00f5es. Voc\u00ea pode utilizar a fun\u00e7\u00e3o a seguir para plotar seus dados.","2c1d49a0":"# Desafio 4: MNIST - Digit Recognizer\nDataset com d\u00edgitos escritos \u00e0 m\u00e3o e seus respectivos valores. Cada linha dos datasets (tanto de treino quanto de teste) est\u00e1 estruturada da seguinte forma:\n\n| Digito representado | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores bin\u00e1rios:","87ab8841":"Vamos aplicar novamente o que j\u00e1 sabemos.","2585cd2b":"# IRIS\n\nIris, o desafio que deu nome ao nome do nosso grupo, \u00e9 um dataset do tipo de flor Iris (e n\u00e3o o olho!). Nele, h\u00e1 tr\u00eas tipos de esp\u00e9cies, com as informa\u00e7\u00f5es sobre s\u00e9palas e p\u00e9talas.","1b446659":"Vamos aplicar nossa regress\u00e3o log\u00edstica.","fd580350":"Veja s\u00f3 como os dados se parecem:","6ac534c7":"Vamos predizer cancer! O dataset a seguir \u00e9 sobre canc\u00ear de mama no estado de Wisconsin. Na coluna do 'diagnosis' podemos ver os dois diagn\u00f3sticos para cancer de mama: Maligno e Benigno. Vamos tentar adivinhar o diagn\u00f3stico baseado apenas nas informa\u00e7\u00f5es m\u00e9dicas que temos.","03083777":"Vamos ver como cada informa\u00e7\u00e3o se comporta para cada esp\u00e9cie.","da743c75":"Conseguimos ver como \u00e9 a imagem redimensionando o a matriz `1x784` para uma `28x28`:","7b9618d9":"# Desafio 3: Diabetes\nO dataset a seguir possui dados sobre a incid\u00eancia de diabetes na popula\u00e7\u00e3o do povo Pima. Seu desafio \u00e9 descobrir a coluna outcome baseado nos outros dados. Seu desafio \u00e9 ultrapassar 82% de precis\u00e3o.","b3569744":"Ok, agora vamos ver outro tipo de modelo chamado RandomForestClassifier. Veja que o modelo de aplica\u00e7\u00e3o no c\u00f3digo \u00e9 o mesmo!","700c8766":"E agora vamos aprender um pouco sobre classifica\u00e7\u00e3o, como precis\u00e3o, recall, f1-score, e **LOSS**","2611e7d8":"Agora que sabemos como fazer o _fit_ do nosso modelo, vamos ver como ele se parece graficamente. E vamos colocar alguns n\u00fameros de entrada para ele tentar adivinhar!","368968aa":"# Desafio 5: Fashion MNIST\nDataset com desenhos de tipos de roupa classificadas com labels\nCada linha dos datasets (tanto de treino quanto de teste) est\u00e1 estruturada da seguinte forma:\n\n\n| Label de cada roupa | pixel 1x1 | ... | pixel 28x28 |\n|:-----------------:|:---------:|:---:|:----------:|\n|5|0|...|0|\n\nComo temos uma imagem 28x28 temos 784 valores de pixel por coluna, todos valores bin\u00e1rios:","1155671a":"Primeiro passo: Tire a coluna in\u00fatil no final!","34934719":"# Desafio 1: Titanic\n\nO seu objetivo \u00e9 descobrir, dado as informa\u00e7\u00f5es de um passageiro no navio Titanic, se ele sobreviveu ou n\u00e3o o acidente (coluna survived). Neste caso, voc\u00ea perceber\u00e1 que algumas colunas podem deixar seu aprendizado pior. Outro ponto importante \u00e9 que h\u00e1 varias informa\u00e7\u00f5es faltantes (NaN).\n\n**Objetivos**\n- Voc\u00ea consegue preencher as informa\u00e7\u00f5es faltantes de alguma forma? Como?\n- Tente ultrapassar 80% de precis\u00e3o.\n\n\n","cf1cc0a4":"A acur\u00e1cia foi ruim, como voc\u00ea pode ver. O que aconteceu? Ser\u00e1 que tem alguma coluna que est\u00e1 fazendo nossos dados tendenciosos? (dica: tem sim)","5fe307f6":"# Desafio 2: IMDB","c50e016d":"Ok, neste come\u00e7o iremos apresentar o que \u00e9 um modelo, o que \u00e9 x, y, labels\/test, fit e predict. Lembre-se que toda Intelig\u00eancia Artificial \u00e9 um modelo matem\u00e1tico para y = f(x), onde x ser\u00e3o os dados de entrada, y os dados de resposta, e f a nossa fun\u00e7\u00e3o. No caso estamos estudando uma fun\u00e7\u00e3o da forma ```f(x) = exp(x)\/(1+numpy.exp(x))```. N\u00f3s n\u00e3o iremos entrar na matem\u00e1tica por tr\u00e1s disso mas basta entender que ele \u00e9 uma curva.\n\nO que faremos a seguir \u00e9 um \"arredondador\", ou um classificador de 0's e 1's. Queremos que ele fa\u00e7a 0.00231 -> 0 e 0.7987 -> 1, e assim em diante.","0660e533":"# Mexendo com dados reais (Cancer de Mama)\n\n\n"}}