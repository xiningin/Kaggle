{"cell_type":{"eb5aa8b0":"code","99057f01":"code","055fe4ed":"code","980fa982":"code","d5cfa38c":"code","4d36cb57":"code","3869b1be":"code","56ee2ee6":"code","0be28f3d":"code","ae0cf0ff":"code","c60b691c":"code","2535183b":"code","698b6b2b":"code","e2ad85d9":"markdown"},"source":{"eb5aa8b0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","99057f01":"dtr = pd.read_csv('..\/input\/gender-voice-detection\/train.csv')\n# dtr.drop(labels = ['mindom', 'median'], axis = 1, inplace= True)\ndtr.info()","055fe4ed":"X = dtr.iloc[:,1:21].values\nY = dtr.iloc[:,21].values","980fa982":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.95, random_state = 0)\n\nX_train = X\nY_train = Y","d5cfa38c":"from sklearn.preprocessing import StandardScaler\nFS = StandardScaler()\nX_train = FS.fit_transform(X_train)\nX_test = FS.fit_transform(X_test)","4d36cb57":"# #Created a function with many Machine Learning Models\n# def models(X_train,Y_train):\n  \n#   #Using Logistic Regression Algorithm to the Training Set\n#   from sklearn.linear_model import LogisticRegression\n#   log = LogisticRegression(random_state = 0)\n#   log.fit(X_train, Y_train)\n  \n#   #Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n#   from sklearn.neighbors import KNeighborsClassifier\n#   knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n#   knn.fit(X_train, Y_train)\n\n#   #Using SVC method of svm class to use Support Vector Machine Algorithm\n#   from sklearn.svm import SVC\n#   svc_lin = SVC(kernel = 'linear', random_state = 0)\n#   svc_lin.fit(X_train, Y_train)\n\n#   #Using SVC method of svm class to use Kernel SVM Algorithm\n#   from sklearn.svm import SVC\n#   svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n#   svc_rbf.fit(X_train, Y_train)\n\n#   #Using GaussianNB method of na\u00efve_bayes class to use Na\u00efve Bayes Algorithm\n#   from sklearn.naive_bayes import GaussianNB\n#   gauss = GaussianNB()\n#   gauss.fit(X_train, Y_train)\n\n#   #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n#   from sklearn.tree import DecisionTreeClassifier\n#   tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n#   tree.fit(X_train, Y_train)\n\n#   #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n#   from sklearn.ensemble import RandomForestClassifier\n#   forest = RandomForestClassifier(n_estimators=100,random_state = 0)\n#   forest.fit(X_train, Y_train)\n  \n#   #printing model accuracy on the training data.\n#   print('Logistic Regression Training Accuracy: ', log.score(X_train, Y_train))\n#   print('K Nearest Neighbor Training Accuracy: ', knn.score(X_train, Y_train))\n#   print('Support Vector Machine (Linear Classifier) Training Accuracy: ', svc_lin.score(X_train, Y_train))\n#   print('Support Vector Machine (RBF Classifier) Training Accuracy: ', svc_rbf.score(X_train, Y_train))\n#   print('Gaussian Naive Bayes Training Accuracy: ', gauss.score(X_train, Y_train))\n#   print('Decision Tree Classifier Training Accuracy: ', tree.score(X_train, Y_train))\n#   print('Random Forest Classifier Training Accuracy: ', forest.score(X_train, Y_train))\n  \n#   return log, knn, svc_lin, svc_rbf, gauss, tree, forest\n# # Executing the above function\n# model = models(X_train,Y_train)","3869b1be":"# from sklearn.metrics import confusion_matrix \n# for i in range(len(model)):\n#   cm = confusion_matrix(Y_test, model[i].predict(X_test))   #extracting TN, FP, FN, TP\n#   TN, FP, FN, TP = confusion_matrix(Y_test, model[i].predict(X_test)).ravel()\n#   print(cm)\n#   print('Model[{}] Testing Accuracy = \"{} !\"'.format(i,  (TP + TN) \/ (TP + TN + FN + FP)))  # Calculating testing accuracy\n#   print()  # Print a new line since its a by default feature of print function","56ee2ee6":"#Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=100,random_state = 0)\nclassifier.fit(X_train, Y_train)","0be28f3d":"#Get the importance of the features\nforest = classifier[6]\nimportances = pd.DataFrame({'feature':dtr.iloc[:, 1:21].columns,'importance':np.round(forest.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances","ae0cf0ff":"Y_pred = classifier.predict(X_test)   # Prediction was made from test data which we got due to splitting","c60b691c":"dte = pd.read_csv(\"..\/input\/gender-voice-detection\/test.csv\")   # Read the test dataset provided to us\n# dte.drop(labels = ['mindom', 'median'], axis = 1, inplace= True)\ndte","2535183b":"X_TEST = dte.iloc[:,1:].values           # Same procedure is to be followed as it was followed in case of training dataset\nFST = StandardScaler()\nX_TEST = FST.fit_transform(X_TEST)\nY_PRED = classifier.predict(X_TEST)   # Final Data was predicted","698b6b2b":"Predicted = pd.DataFrame(Y_PRED)   # New Dataframe was created\nss = pd.read_csv(\"..\/input\/gender-voice-detection\/sample-submission.csv\")\ndataset = pd.concat([ss['Id'], Predicted], axis=1)     # Concatenation (Merging) with sample-submission dataset and creating a new dataset\ndataset.columns = ['Id', 'label']      # Column names were assigned for new dataset formed\ndataset.to_csv('sample_submission-rf.csv', index = False)   # Exported the new dataset with name","e2ad85d9":"**Cross - Validation**"}}