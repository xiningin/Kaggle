{"cell_type":{"8110b0d6":"code","aa3e1f97":"code","159f693f":"code","e9fa99b4":"code","77a95765":"code","96433ee4":"code","c2bc6f8e":"code","922b49d8":"code","da8f5506":"code","91f4f116":"code","eb580215":"code","9b67749c":"code","39531378":"code","23ac01aa":"code","d5130f93":"code","4975afe7":"code","67a0cf53":"code","5ca2ec15":"code","e73bf45a":"code","b4b29167":"code","1e1ac168":"markdown","4d18a205":"markdown"},"source":{"8110b0d6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aa3e1f97":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression","159f693f":"main_data=pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\n\nmain_data.head()","e9fa99b4":"data=main_data.iloc[:,:-1]\ndata.head()","77a95765":"target=main_data.iloc[:,-1]\ntarget.head()","96433ee4":"from sklearn.model_selection import KFold\n\nk=KFold(n_splits=10)\n\ndata=np.array(data)\ntarget=np.array(target)\n\nfor train_index,test_index in k.split(data):\n    x_train,x_test=data[train_index],data[test_index]\n    y_train,y_test=target[train_index],target[test_index]","c2bc6f8e":"from sklearn.metrics import accuracy_score,recall_score,precision_score","922b49d8":"model1=SVC(kernel='linear')\nmodel1.fit(x_train,y_train)\npred1=model1.predict(x_test)\nprint(accuracy_score(y_test,pred1)*100)","da8f5506":"model2=LogisticRegression()\nmodel2.fit(x_train,y_train)\npred1=model2.predict(x_test)\nprint(accuracy_score(y_test,pred1)*100)","91f4f116":"model3=KNeighborsClassifier(n_neighbors=2)\nmodel3.fit(x_train,y_train)\npred1=model3.predict(x_test)\nprint(accuracy_score(y_test,pred1)*100)","eb580215":"from sklearn.model_selection import StratifiedKFold\n\ns=StratifiedKFold(n_splits=10)\n\nfor train_index,test_index in s.split(data,target):\n    x_train,x_test=data[train_index],data[test_index]\n    y_train,y_test=target[train_index],target[test_index]","9b67749c":"li=[]\n\nmodel1=SVC(kernel='linear')\nmodel1.fit(x_train,y_train)\npred1=model1.predict(x_test)\nprint(accuracy_score(y_test,pred1)*100)\nli.append(accuracy_score(y_test,pred1)*100)","39531378":"model2=LogisticRegression()\nmodel2.fit(x_train,y_train)\npred2=model2.predict(x_test)\nprint(accuracy_score(y_test,pred2)*100)\nli.append(accuracy_score(y_test,pred2)*100)","23ac01aa":"model3=KNeighborsClassifier(n_neighbors=2)\nmodel3.fit(x_train,y_train)\npred3=model3.predict(x_test)\nprint(accuracy_score(y_test,pred3)*100)\nli.append(accuracy_score(y_test,pred3)*100)","d5130f93":"li","4975afe7":"import matplotlib.pyplot as plt\n\nx=np.arange(len(li))\ny=np.array(li)\n\nplt.bar(x,y)\nplt.show()","67a0cf53":"from sklearn.model_selection import cross_val_score","5ca2ec15":"cross_val_score(SVC(kernel='linear'),data,target,cv=5)","e73bf45a":"cross_val_score(LogisticRegression(),data,target,cv=5)","b4b29167":"cross_val_score(KNeighborsClassifier(n_neighbors=5),data,target,cv=5)","1e1ac168":"K-fold is a procedure which has lot of variations among itself, but broadly speaking it's a process of data splitting for train and test where we split the data into numerous fold, in this case being split into 10 folds as mentioned using the n_splits parameter. Among the folds one is taken as test fold and rest become train folds. Iteratively doing this gives us the best results we can get out from the data.","4d18a205":"## Importing All Dependencies"}}