{"cell_type":{"587d9281":"code","f97c5938":"code","39ddf052":"code","63bb3e8b":"code","ae35f7b4":"code","d210c783":"code","d5dcd25e":"code","14a49190":"code","41ac697a":"code","bef9cd24":"code","f581a2ed":"code","29f665cb":"code","78907248":"code","b3d4c6e0":"code","2cf5dc90":"code","d4ca4013":"code","98af5722":"code","9fea2ed7":"code","ef388c2e":"code","2b82bdd1":"code","c70c371b":"code","5e5cb669":"code","00b602d8":"code","19418872":"code","1c7c597d":"code","e9b77b0e":"code","634efded":"code","8026b34c":"code","b7fb90db":"code","781fbf04":"code","f33d81da":"code","d8a95c43":"code","e9f3b46e":"code","d945e235":"code","b275ff87":"code","8f490707":"code","45f3cefe":"code","284fcdca":"code","e54c7467":"code","bcc6c15e":"code","9d7c2362":"code","514dbb6c":"code","1256bb23":"code","85e3a831":"markdown","db8077ad":"markdown","fcf32ed2":"markdown","d464dcef":"markdown","c1a0d746":"markdown","09f5b839":"markdown","39b647af":"markdown","7d174236":"markdown","3ab7688b":"markdown","c9f2a1ac":"markdown","5a435451":"markdown","4d51f4ef":"markdown","179b3899":"markdown","9aaaa259":"markdown","ebe79beb":"markdown","647b2157":"markdown","88070d2b":"markdown","22d05ca3":"markdown","905f215b":"markdown","c8659f40":"markdown","a0b822fe":"markdown","fd9ac31c":"markdown","d3209c20":"markdown"},"source":{"587d9281":"import os # operating system interfaces, to manipulate paths\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n%matplotlib inline","f97c5938":"train = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('..\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsubmission = pd.read_csv('..\/input\/stanford-covid-vaccine\/sample_submission.csv')","39ddf052":"train.head()","63bb3e8b":"test.head()","ae35f7b4":"submission.head()","d210c783":"train.info()","d5dcd25e":"test.info()","14a49190":"print(train['sequence'].apply(lambda x: len(x)).value_counts())  # all the sequences have 107 bases\nprint(train['structure'].apply(lambda x: len(x)).value_counts())  # all the structures have 107 bases\nprint(train['predicted_loop_type'].apply(lambda x: len(x)).value_counts())  # all the structures have 107 bases","41ac697a":"3005 * 130 + 629 * 107","bef9cd24":"train['seq_counts'] = train['sequence'].apply(lambda x: Counter(x.upper()))\ntrain['seq_counts']","f581a2ed":"# doing a bit of feature engieering by taking up the contribution of each code\npercentage = []\nfor i in range(len(train)):\n  count = train.iloc[i]['seq_counts']\n  percentage.append((count['A']\/train.iloc[i]['seq_length'],\n                     count['G']\/train.iloc[i]['seq_length'],\n                     count['C']\/train.iloc[i]['seq_length'],\n                     count['U']\/train.iloc[i]['seq_length']))\n  \npercentage = pd.DataFrame(percentage, columns=['A_p', 'G_p', 'C_p', 'U_p'])\npercentage","29f665cb":"# Calculate the probality of each type of paired bases\npairs = []\nall_partners = []\nfor j in range(len(train)):\n    partners = [-1 for i in range(130)]\n    pairs_dict = {}\n    queue = []\n    for i in range(0, len(train.iloc[j]['structure'])):\n        if train.iloc[j]['structure'][i] == '(':\n            queue.append(i)\n        if train.iloc[j]['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] += 1\n            except:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] = 1\n                \n            partners[first] = i\n            partners[i] = first\n    \n    all_partners.append(partners)\n    \n    pairs_num = 0\n    pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n    for item in pairs_dict:\n        pairs_num += pairs_dict[item]\n    add_tuple = list()\n    for item in pairs_unique:\n        try:\n            add_tuple.append(pairs_dict[item]\/pairs_num)\n        except:\n            add_tuple.append(0)\n    pairs.append(add_tuple)\n    \npairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\npairs","78907248":"# Calculate total paired bases in each RNA sequence\npairs_rate = []\n\nfor j in range(len(train)):\n    res = dict(Counter(train.iloc[j]['structure']))\n    pairs_rate.append(res['('] \/ 53.5)  # 2 * res['(']\/107\n    \npairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\npairs_rate","b3d4c6e0":"# calculate the rate of every Predicted Loop Type in each sequence\nloops = []\nfor j in range(len(train)):\n    counts = dict(Counter(train.iloc[j]['predicted_loop_type']))\n    available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n    row = []\n    for item in available:\n        try:\n            row.append(counts[item] \/ 107)\n        except:\n            row.append(0)\n    loops.append(row)\n    \nloops = pd.DataFrame(loops, columns=available)\nloops","2cf5dc90":"bpps_dir = '..\/input\/stanford-covid-vaccine\/bpps'\n\nbpps_fns = os.listdir(bpps_dir)\nlen(train) + len(test) == len(bpps_fns)","d4ca4013":"def get_bppm(id_):\n    return np.load(os.path.join(bpps_dir, bpps_fns[id_]))\n\n\ndef draw_structure(structure: str):\n    pm = np.zeros((len(structure), len(structure)))\n    start_token_indices = []\n    for i, token in enumerate(structure):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pm[i, j] = 1.0\n            pm[j, i] = 1.0\n    return pm\n\n\ndef plot_structures(bppm: np.ndarray, pm: np.ndarray):\n    fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n    axes[0].imshow(bppm)\n    axes[0].set_title(\"BPPM\")\n    axes[1].imshow(pm)\n    axes[1].set_title(\"structure\")\n    plt.show()","98af5722":"for _ in range(3):\n  idx = np.random.randint(len(bpps_fns))\n  fn = bpps_fns[idx]\n  df_id = fn.split('.')[0]\n\n  print(fn)\n  bpps_ff = get_bppm(idx)\n  struct = train[train['id']==df_id]['structure'].values[0] if df_id in train['id'].to_list() else test[test['id']==df_id]['structure'].values[0]\n  plot_struct = draw_structure(struct)\n  plot_structures(bpps_ff, plot_struct)","9fea2ed7":"# Our target columns\ntarget_cols = submission.columns.to_list()[1:]\nfor col in target_cols:\n  print(train[col].apply(lambda x: len(x)).sum()\/len(train))\n\n# prediction sequence length is 68","ef388c2e":"import tensorflow as tf # tensorflow Library\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import layers as L #import layers into model\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold","2b82bdd1":"#numbering features\ndef tokentoInt(bases):\n  return {x:i for i, x in enumerate(bases)}\n  pass\nprint(tokentoInt('AGCU'))\nprint(tokentoInt('(.)'))\nprint(tokentoInt(\"\".join([x for x in loops.columns])))","c70c371b":"# GRU layer, wrapped by a Bidirectional RNN layer\n# kernel_initializer: Initializer for the kernel weights matrix\ndef gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))\n# LSTM layer, wrapped by a Bidirectional RNN layer\ndef lstm_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.LSTM(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))","5e5cb669":"# source : https:\/\/www.kaggle.com\/c\/stanford-covid-vaccine\/discussion\/183211\ndef MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","00b602d8":"# encode feature to import to model\ndef encoding(df, col):\n  \"\"\"\n  df: dataframe containing sequences and the features\n  col: column to apply encoding\n      : valid values are: 'sequence', 'structure' and 'predicted_loop_type'\n  \"\"\"\n  try:\n    if col == 'sequence':\n      seq_encoding = tokentoInt('AGCU')\n      \n    elif col == 'structure':\n      seq_encoding = tokentoInt('(.)')\n\n    elif col == 'predicted_loop_type':\n      seq_encoding = tokentoInt(\"\".join([x for x in loops.columns]))\n\n    return np.array(df[col].apply(lambda seq: [seq_encoding[x] for x in seq]).values.tolist())\n\n  except KeyError:\n    print('Invalid arguments as col')","19418872":"from tqdm import tqdm","1c7c597d":"private_test = test.query(\"seq_length==130\").copy()\npublic_test = test.query(\"seq_length==107\").copy()\n\n# this split on train set is applied if none of the cv folding aren't applied\ntrain_data = train.query('SN_filter==0')\nval_data = train.query('SN_filter==1')","e9b77b0e":"def get_features(df):\n  seq_inp = encoding(df, 'sequence')\n  struc_inp = encoding(df, 'structure')\n  plt_inp = encoding(df, 'predicted_loop_type')\n  '''\n  bpps_arr = []\n  for i in tqdm(range(len(df))):\n    idx = df.loc[i]['id']\n    bpps_arr.append(np.expand_dims(np.load(os.path.join(bpps_dir, str(idx)+'.npy')), axis=-1))\n\n  cnn_inp = np.array(bpps_arr) # cnn data input\n  '''\n  return seq_inp, struc_inp, plt_inp #, cnn_inp","634efded":"train_labels = np.array(train[target_cols].values.tolist()).transpose(0, 2, 1)\ntrain_labels[0, 0, :]","8026b34c":"# setup seq_model include Input, embedding and LSTM layers.\ndef seq_model(encoding_dict,\n              seq_len=107,\n              pred_len=68,\n              dropout=0.4,\n              sp_dropout=0.2,\n              embed_size=128,\n              hidden_dim=256,\n              layers=2,\n              gru=False):\n  \n  # one sequence at a time of len 107 (if training specified)\n  input = L.Input(shape=(seq_len, ))\n\n  # apply embedding layer \n  embed = L.Embedding(input_dim=len(encoding_dict),\n                      output_dim=embed_size)(input)\n\n  '''reshaped = tf.reshape(embed,\n                        shape=(-1, embed.shape[1], embed.shape[2] * embed.shape[3]))'''\n  hidden = tf.keras.layers.SpatialDropout1D(sp_dropout)(embed)\n  # apply bidirectional lstm\/gru layers * layers count\n  if gru:\n    for _ in range(layers):\n      hidden = gru_layer(hidden_dim, dropout)(hidden)\n  else:\n    for _ in range(layers):\n      hidden = lstm_layer(hidden_dim, dropout)(hidden)\n  \n  return tf.keras.Model(input, hidden)\n  pass","b7fb90db":"'''\ndef cnn_model(input_shape=(107, 107), flag=False):\n  \"\"\"\n  can be of shape 107*107(train and public set) and 130*130(private set) \n  \"\"\"\n  input = L.Input(shape=(*input_shape, 1))  # images are of 2-D\n\n  # let's just go with 3 layers of CNN\n  x = L.Conv2D(kernel_size=(5, 5),\n               filters=64,\n               strides=(2, 2))(input)\n  x = L.MaxPool2D(pool_size=(2, 2))(x) # To get max value of feature and reduce parameter while training\n  x = L.Activation('relu')(x) # I use activation function ReLu here\n\n  x = L.Conv2D(kernel_size=(3, 3),\n               filters=256)(x)\n  x = L.MaxPool2D(pool_size=(2, 2))(x)\n  x = L.Activation('relu')(x)\n  \n  x = L.Conv2D(kernel_size=(1, 4), filters=512)(x)\n  x = L.Activation('relu')(x)\n    \n  # if there is flag, then add more layer\n  if flag:\n    x = L.Conv2D(kernel_size=(2, 2), filters=512)(x)\n    x = L.Activation('relu')(x)\n    x = tf.reshape(x, shape=(-1, x.shape[1]*x.shape[2], x.shape[-1], 1))\n    return tf.keras.Model(input, x)\n\n  x = tf.reshape(x, shape=(-1, x.shape[1]*x.shape[2], x.shape[-1], 1))\n  x = L.Conv2D(kernel_size=(2, 1), filters=1)(x)\n  x = L.Activation('relu')(x)\n\n\n\n\n  return tf.keras.Model(input, x)\n  pass\n'''  ","781fbf04":"# create model from 3 submodel seq_model\ndef main_model(seq_len=107, pred_len=68, cnn_input_shape=(107, 107), flag=False):\n  \"\"\"\n  Consists of four models, one seq_model each for sequence, structure and predicted_loop\n  and one CNN for BPPS files.\n  \"\"\"\n  # extract from sequences\n  Seq_model = seq_model(tokentoInt('AGCU'), seq_len=seq_len, pred_len=pred_len, dropout=0.0)\n  Seq_op = Seq_model.output  # for train,  seq_len = 107\n\n  Struct_model = seq_model(tokentoInt('(.)'), seq_len=seq_len, pred_len=pred_len, dropout=0.0)\n  Struct_op = Struct_model.output\n\n  PLT_model = seq_model(tokentoInt(\"\".join([x for x in loops.columns])), seq_len=seq_len, pred_len=pred_len, dropout=0.0)\n  PLT_op = PLT_model.output\n  '''\n  # add cnn layer output\n  CNN_model = cnn_model(cnn_input_shape, flag=flag)\n  CNN_op = CNN_model.output\n  CNN_op = tf.reshape(CNN_op, shape=(-1, CNN_op.shape[1], CNN_op.shape[2] * CNN_op.shape[3]))\n  \n  print(Seq_op.shape, Struct_op.shape, PLT_op.shape, CNN_op.shape)\n  '''\n  # now we got 3 tensors of shape (BS, 107, 512)\n  ip = tf.add_n([Seq_op, Struct_op, PLT_op])\/3\n  print(ip.shape)\n  ip = ip[:, :pred_len]\n  # Use core layer Dense\n  ip = L.Dense(5, activation='linear')(ip)\n  print(ip.shape)\n  return tf.keras.Model(inputs=[Seq_model.input, Struct_model.input, PLT_model.input], outputs=ip)\n  pass","f33d81da":"model = main_model()\nmodel.summary()","d8a95c43":"# Compile model with one of the most used optimizer Adam\nmodel.compile(loss=MCRMSE,\n           optimizer=tf.keras.optimizers.Adam(lr=0.005))","e9f3b46e":"lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=5)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint(f'lstm.h5')","d945e235":"model.fit(get_features(train), train_labels,\n       epochs=75, batch_size=64,\n       callbacks=[lr_callback, sv_lstm])","b275ff87":"model_long = main_model(seq_len=130, pred_len=130, cnn_input_shape=(130, 130), flag=True)\nmodel_long.summary()","8f490707":"model_long.load_weights('.\/lstm.h5')","45f3cefe":"pred_long = model_long.predict(get_features(private_test), verbose=1)\npred_long.shape","284fcdca":"model_short = main_model(seq_len=107, pred_len=107, cnn_input_shape=(107, 107), flag=True)\nmodel_short.summary()","e54c7467":"model_short.load_weights('.\/lstm.h5')\npred_short = model_short.predict(get_features(public_test), verbose=1)\npred_short.shape","bcc6c15e":"#create predict output data\ndef format_predictions(public_preds, private_preds):\n    preds = []\n    \n    for df, preds_ in [(public_test, public_preds), (private_test, private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds_[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds.append(single_df)\n\n    return pd.concat(preds).groupby('id_seqpos')","9d7c2362":"df = format_predictions(pred_short, pred_long)\ndf.first()","514dbb6c":"submission = df.sum().reset_index()\nsubmission","1256bb23":"#extract result to submission.csv\nsubmission.to_csv('submission.csv', index=False)","85e3a831":"### Features","db8077ad":"## Preparing Data to fit into our Model\n- Sequence Model\n- Structure Model\n- Predicted Loop Type\n- CNN model for BPPS files","fcf32ed2":"So I plan to split the data like following:\n- train: `train_data` and `valid_data` by filtering on SN_filer == 1\n- test: `private_test` and `public_test` filtered on seq_length","d464dcef":"# Analyze RNA Sequences","c1a0d746":"**Preview dataset**","09f5b839":"### Labels","39b647af":"Each  ```.npy``` file corresponds to each sample in our train and test dataset IDs.","7d174236":"## For Predicted Loop Type","3ab7688b":"And reactivity_error,\tdeg_error_Mg_pH10,\tdeg_error_pH10,\tdeg_error_Mg_50C,\tdeg_error_50C,\treactivity,\tdeg_Mg_pH10,\tdeg_pH10,\tdeg_Mg_50C,\tdeg_50C; these columns have length 68 as its measured on first 68 bases.","c9f2a1ac":"Submissions are scored using MCRMSE, mean columnwise root mean squared error:\n\n![MSE (1).png](attachment:11f8cc5d-6858-4b69-83e7-f7a7875519eb.png)\n\nwhere is the number of scored ground truth target columns, and  and  are the actual and predicted values, respectively.\n\nFrom the Data page: There are multiple ground truth values provided in the training data. While the submission format requires all 5 to be predicted, only the following are scored: reactivity, deg_Mg_pH10, and deg_Mg_50C.","5a435451":"In RNA, its sequence that matters. As we can see, the probality of each base is totally different from others. Now let's have a look on the paired-sequence. ","4d51f4ef":"## 1. Loading the competition data","179b3899":"This is what is the lenght of our submission file. So, we gotta predict the five measurements for each base of each sequence, or say it in terms of Sequence models, we gotta predict sequences of length x from sequences of length x, where the values of x can be 107 -> 107 and 130 -> 130 for test cases and 107 -> 68 for train cases.","9aaaa259":"### Compare between Structure and BPPS files","ebe79beb":"Some Measure clues that you might miss:\n- Test set has two types of sequences one of length 107 and another of length 130. \n- As mentioned earlier, the 107 base sequences are filtered out from the 3029 samples of the previous dataset, and these consists of public leader board.\n- Rest 3005 samples are of length 130.","647b2157":"## BPPS features (base-pairing probability)\nThis is a great insight found by [Hidehisa Arai](https:\/\/https:\/\/www.kaggle.com\/hidehisaarai1213\/openvaccine-checkout-bpps). Let's cultivate on it.","88070d2b":"# Understading our Train\/Test set","22d05ca3":"From here, I will go for a very simple model by stacking 3 seq-models for our created features. Let's move ahead.","905f215b":"\n\n*   There were 3029 RNA sequeces.\n*   Experiments were done using first 68 values of the 107-length sequence.\n-   These 3069 (107-base) were split into 2400 train + 629 test with filters being applied to choose the 629 samples. The filters are as follows:\n\n\n\n---\n\n1. Minimum value across all 5 conditions must be greater than -0.5.\n2. Mean signal\/noise across all 5 conditions must be greater than 1.0. [Signal\/noise is defined as mean( measurement value over 68 nts )\/mean( statistical error in measurement value over 68 nts)]\n3. To help ensure sequence diversity, the resulting sequences were clustered into clusters with less than 50% sequence similarity, and the 629 test set sequences were chosen from clusters with 3 or fewer members. That is, any sequence in the test set should be sequence similar to at most 2 other sequences.\n\n---\nAnd as per the instructions, Private LB scoring will be made on 130-base 3005 sequences where the measurement is done on the basis of first 91 bases.\n\n> Note that, the above filters won't be applied to these 3005 samples.","c8659f40":"## For Structures","a0b822fe":"And interestingly, our result will be measured or evalulated on 'reactivity', 'deg_Mg_pH10', 'deg_Mg_50C'. However, we gotta predict for all the 5 values.","fd9ac31c":"## For Sequences\n\n- The possible values are A, G, C and U.","d3209c20":"# Model\nSo my plan is to use the sequences, structures and predicted loops features along with bpps features (via CNN layers) with separate custom embedding for each sequential input and then concatenating them all together to get our desired output sequence of measures."}}