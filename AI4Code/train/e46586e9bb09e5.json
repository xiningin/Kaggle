{"cell_type":{"86f59e14":"code","5cc6893c":"code","ca4a8009":"code","ecc87507":"code","fb19814c":"code","0bfb35e4":"code","012afc97":"code","d08cebe2":"code","28b4f40e":"code","55f06b74":"code","93fe668d":"code","2f5cc28d":"code","d806e284":"code","152a3e36":"code","a07ab6cf":"code","ced9c521":"code","828ec082":"code","e41dd159":"markdown","25d6fc9c":"markdown","f7fb4cc0":"markdown","5b4575f4":"markdown","c92c3919":"markdown","60b15e18":"markdown","271f9a9f":"markdown","73ff2329":"markdown","2f030d03":"markdown","dcc78afe":"markdown","e831854d":"markdown","6e078d5c":"markdown","f376281c":"markdown","4ddea263":"markdown","74621841":"markdown","b262fe7e":"markdown","dd250fd0":"markdown","63c378c5":"markdown","849800d2":"markdown","442b5831":"markdown","41a01cb0":"markdown","b1a523fd":"markdown","fb0165a0":"markdown","82a82c7a":"markdown","4c87d5e2":"markdown","13cc6c25":"markdown","c2f0be2d":"markdown","471b8173":"markdown","3a4525e6":"markdown","15992b48":"markdown"},"source":{"86f59e14":"import numpy as np # for linear algebra\nimport pandas as pd # for data processing\nimport seaborn as sns # for data vis\nimport matplotlib.pyplot as plt# for data vis\n%matplotlib inline","5cc6893c":"df = pd.read_csv('\/kaggle\/input\/superstore-sales\/SampleSuperstore - SampleSuperstore.csv')","ca4a8009":"# to display top 5 rows\ndf.head(5)","ecc87507":"# To display the bottom 5 rows\ndf.tail(5)","fb19814c":"# Checking the data type\ndf.dtypes","0bfb35e4":"#summary statistics of the data\ndf.describe()","012afc97":"df.shape","d08cebe2":"# checking duplicated rows\nduplicate_rows_df = df[df.duplicated()]\nprint(\"number of duplicate rows: \", duplicate_rows_df.shape)","28b4f40e":"# dropping duplicate rows\ndf = df.drop_duplicates()\n","55f06b74":"# check the number of rows to make sure that duplicated rows were deleted \ndf.shape","93fe668d":"# Finding the null values.\nprint(df.isnull().sum())\nprint(df.isna().sum())\n","2f5cc28d":"# sorting the data and displaying the 5 top and 5 bottom rows\ndf.sort_values(\"Profit\")\n","d806e284":"df.groupby('Region').sum( ['Profit']).sort_values(\"Profit\")\n","152a3e36":"df.groupby('Category').sum( ['Profit']).sort_values(\"Profit\")\n","a07ab6cf":"df.groupby(['Region','Category']).sum( ['Profit']).sort_values(\"Profit\")\n","ced9c521":"df.groupby('Region').sum( ['Sales']).sort_values(\"Sales\")\n","828ec082":"df.groupby('Segment').sum( ['Profit']).sort_values(\"Profit\")\n","e41dd159":"# Which Category generates more money to the company ?","25d6fc9c":"# **1. setting the environment and importing required libararies**","f7fb4cc0":"**1. The company needs to do more analysis to figure out why they loosing in the following states:**\n\n**Ohio, North Carolina, Texas, Colorado and Illinois.**\n\n**2. The company needs to enhance its  marketing strategy towards corporate segment** \n\n**3. The tech products are the most sailed and the most profitable products**","5b4575f4":"# **4. Data cleaning**","c92c3919":"# What is the performance of categories in each region?","60b15e18":"# **6. Conclusion**","271f9a9f":"**link to dashboard**[https:\/\/drive.google.com\/file\/d\/11Oku4nj-7Z1YAhIFfHZ7OGCbTu5z0mA7\/view?usp=sharing]","73ff2329":"**# the company is loosing money in :**\n\n **Ohio, North Carolina, Texas, Colorado and Illinois.**","2f030d03":"# Hi there,\n# I hope this notebook be helpful to you\n# !![welcome....jpg](attachment:6475bec1-3373-4ea5-9e0e-a52203094127.jpg)","dcc78afe":"# **The Business task**\n# !![business-tasks-2932687_960_720.png](attachment:bb9c6dae-fc20-4a73-b800-d03852be09c4.png) \n","e831854d":"**The company is mmaking more profits in west region and  less profits in central region**","6e078d5c":"**The company is making more profits from consumers than corporate and home office**","f376281c":"****our data has no Null values nor Na values\n**\nwe are ok, let us go ahead**","4ddea263":"**to find out weak arears where the company can work to make more profit.**","74621841":"# Which segment is making more profits?","b262fe7e":"# **3. inspecting the data**","dd250fd0":"# **2.  loading and reading  the data set**","63c378c5":"**** the data has 9994 rows and 13 columns****","849800d2":"# What are the best and worse states based on profits ?","442b5831":"**In this notebook I am going to do some Exploratory Data Analysis and visualization on the superstore sales dataset.**     **this task is  part of my internship at The Sparks Foundation**","41a01cb0":"# **0. Introduction**","b1a523fd":"**The company is making more profits from  tech products** ","fb0165a0":"**There are 17 duplicated rows**\n\n\n**let us delete these rows because they are few and will not affect the overall analysis.**","82a82c7a":"# **5. Analysis and visualization**","4c87d5e2":"# **THE END**![thanks.jpg](attachment:5b564dd7-78f1-4426-9fa1-855d5ea053b8.jpg)","13cc6c25":"# What is the top performing region and less performing region?","c2f0be2d":"now our data has no duplicated rows\n\nlet us move on","471b8173":"**# The company is making more profits in :**\n\n**Lafayette, Seattle, Newark, Detroit and Minneapolis.**","3a4525e6":"# What is the best region by sale?","15992b48":"# **Table of content**\n\n**0. Intoduction**\n\n\n**1. setting the environment and importing required libararies**\n\n\n**2. loading and reading the data set**\n\n\n**3. Inspecting the dataset**\n\n\n**4. Data cleaning**\n\n\n**5. Analysis and Visualization**\n\n\n**6. Cnoclusion**\n"}}