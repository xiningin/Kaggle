{"cell_type":{"1da921aa":"code","ae348d79":"code","f3f23b35":"code","8a739523":"code","37b236ed":"code","c1b30d68":"code","f943ce82":"code","595e8e5e":"code","8338d2c9":"code","95da2784":"code","f32d7b41":"code","621cf72f":"code","6e007547":"code","62bb076a":"code","447b9c47":"code","f37b5681":"code","5a26f361":"code","bcee1f82":"code","492b5909":"code","65a3075b":"code","18b857eb":"code","c9802bdb":"code","a33242d6":"code","f4ff14f5":"code","9e54d3af":"code","5f493cd4":"code","6946e012":"code","4352b6a0":"code","15d1c10d":"code","2dd84d3b":"code","1f8e840d":"markdown","bfa0df4c":"markdown","7d9ba577":"markdown","1bef42a2":"markdown","76ed9871":"markdown","bc7687aa":"markdown","9b18d584":"markdown","e61529fa":"markdown","fd77d65d":"markdown","2b062b61":"markdown","612cfb35":"markdown","2ce46351":"markdown","08bfce38":"markdown","b6e9ee6e":"markdown","e02553c0":"markdown","c56548b2":"markdown","8f516194":"markdown"},"source":{"1da921aa":"# file system\nimport os\n\n# data manipulation\nimport pandas as pd\nimport numpy as np\n\n# dataviz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import set_config\nset_config(display='diagram')\n\n# pipeline preprocessing\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\n\n# supervised learning\nfrom sklearn.linear_model import RidgeClassifier\n\n# tuning model\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n\n# evaluation\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, accuracy_score","ae348d79":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f3f23b35":"# train dataset\ntrain_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\n\n# test dataset where we need to predict result\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\n# example of submission format\nsubmission_df = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","8a739523":"# create copy for train dataset eda\neda_train_df = train_df.copy()\n\n# replace survived values and get legend color\ndict_survived = {0: \"Drowned\", 1: \"Survived\"}\nsurvived_hue = [\"#e33d00\", \"#00a6e3\"]\n\n# map new values of survived\neda_train_df[\"Survived\"] = eda_train_df[\"Survived\"].map(dict_survived)","37b236ed":"# define two grids\nfig, (ax1, ax2 )= plt.subplots(1, 2, figsize=(26,10))\nfig.suptitle('Missing Data')\n\n# first chart\nsns.heatmap(train_df.isna(), ax=ax1, cbar=True) # you could use train_df.isnull() same results\nax1.set_title('Train dataset')\n\n# second chart\nsns.heatmap(test_df.isna(), ax=ax2, cbar=True)\nax2.set_title('Test dataset')","c1b30d68":"# create empty DataFrame\nx = ['column','missing_data', '%missing_data']\nmissing_data = pd.DataFrame(columns=x)   \n    \n# iterate over columns\nfor col in train_df.columns:\n    icolumn_name = col\n    imissing_data = train_df[col].isna().sum()\n    imissing_in_percentage = round(((train_df[col].isna().sum()\/train_df[col].shape[0])*100), 2)\n    missing_data.loc[len(missing_data)] = [icolumn_name, imissing_data, imissing_in_percentage]\n\n# print results\nprint(missing_data)","f943ce82":"# create empty DataFrame\nx = ['column','missing_data', '%missing_data']\nmissing_data = pd.DataFrame(columns=x)   \n    \n# iterate over columns\nfor col in test_df.columns:\n    icolumn_name = col\n    imissing_data = test_df[col].isna().sum()\n    imissing_in_percentage = round(((test_df[col].isna().sum()\/test_df[col].shape[0])*100), 2)\n    missing_data.loc[len(missing_data)] = [icolumn_name, imissing_data, imissing_in_percentage]\n\n# print results\nprint(missing_data)","595e8e5e":"# define chart\nplt.figure(figsize = (15,8))\nax = sns.countplot(x = 'Survived', data = eda_train_df, palette = survived_hue)\n\n# set titles\nplt.title('Number of passengers by Survived\/Drowned')\nplt.ylabel('Number of passengers')\nplt.xlabel('Modalities')\n\n# add values into seaborn chart\nlabels = (eda_train_df['Survived'].value_counts())\nfor i, v in enumerate(labels):\n    ax.text(i, v+10, str(v), horizontalalignment = 'center', size = 10, color = 'black')\n    \n# define dataframe with occurences by values\nsurvived_values = pd.DataFrame({\n    'counts': eda_train_df['Survived'].value_counts(), \n    'percents': eda_train_df['Survived'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'\n})\n\n# print repartition into dataframe\nprint(survived_values)","8338d2c9":"# define chart\nplt.figure(figsize = (14,8))\nsns.countplot(x = 'Pclass', data = eda_train_df, hue = 'Survived', palette = survived_hue)\n\nplt.title('Number of Survived\/Drowned passengers by class')\nplt.ylabel('Number of passengers')\nplt.legend(loc=(1.02,.5))","95da2784":"# define chart\nplt.figure(figsize=(14, 6))\nsns.boxplot(y = 'Survived', x = 'Age', data = eda_train_df, palette = survived_hue, fliersize = 0, orient = 'h')\nsns.stripplot(y = 'Survived', x = 'Age', data = eda_train_df, linewidth = .8, palette = survived_hue, orient = 'h')\n\nplt.yticks(np.arange(2), ['Drowned', 'Survived'])\nplt.title('Age distribution grouped by surviving status (train data)',fontsize= 14)\nplt.ylabel('Passenger status after the tragedy')\nplt.tight_layout()","f32d7b41":"# define chart\nplt.figure(figsize = (14,8))\nsns.countplot(x = 'Sex', data = eda_train_df, hue = 'Survived', palette = survived_hue)\n\nplt.title('Number of Survived\/Drowned passengers by Gender')\nplt.ylabel('Number of passengers')\nplt.legend(loc=(1.02,.5))","621cf72f":"# define chart\neda_train_df.groupby('Embarked')['Survived'].value_counts(normalize = True).unstack().sort_index().plot(kind='bar', stacked='True', color=survived_hue)\nplt.title('Proportion of Survived\/Drowned passengers by Embarked')\n\nplt.legend(loc=(1.04,0.45))\n_ = plt.xticks(rotation=False)","6e007547":"# define chart\nsns.catplot(\n    y=\"Fare\", x=\"Survived\", kind=\"boxen\", \n    data=eda_train_df, palette=survived_hue, \n    orient=\"v\", height=8 \n)\nplt.tight_layout()","62bb076a":"# extract title from name and normalise it\neda_train_df['Title'] = eda_train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\neda_train_df['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\neda_train_df['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n\n# define chart\nplt.figure(figsize = (14,8))\nsns.countplot(x = 'Title', data = eda_train_df, hue = 'Survived', palette = survived_hue)\n\nplt.title('Number of Survived\/Drowned passengers by Title')\nplt.ylabel('Number of passengers')\nplt.legend(loc=(1.02,.5))","447b9c47":"# get name length\neda_train_df['NameLength'] = eda_train_df['Name'].apply(lambda x: len(x))\n\n# define chart\nplt.figure(figsize=(14, 6))\nsns.boxplot(y = 'Survived', x = 'NameLength', data = eda_train_df, palette=survived_hue, fliersize = 0, orient = 'h')\nsns.stripplot(y = 'Survived', x = 'NameLength', data = eda_train_df, linewidth = .8, palette=survived_hue, orient = 'h')\n\nplt.yticks(np.arange(2), ['Drowned', 'Survived'])\nplt.title('NameLength distribution grouped by surviving status (train data)',fontsize= 14)\nplt.ylabel('Passenger status after the tragedy')\nplt.tight_layout()","f37b5681":"# get family size\neda_train_df['FamilySize'] = (\n    eda_train_df[\"SibSp\"] + # siblings\/spouses\n    eda_train_df[\"Parch\"] # parents\/children \n)\n\n# define chart\nplt.figure(figsize=(14, 6))\nsns.boxplot(y = 'Survived', x = 'FamilySize', data = eda_train_df, palette = survived_hue, fliersize = 0, orient = 'h')\nsns.stripplot(y = 'Survived', x = 'FamilySize', data = eda_train_df, linewidth = 0.8, palette=survived_hue, orient = 'h')\n\nplt.yticks(np.arange(2), ['Drowned', 'Survived'])\nplt.title('Family Size distribution grouped by surviving status (train data)',fontsize= 14)\nplt.ylabel('Passenger status after the tragedy')\nplt.tight_layout()","5a26f361":"# get ticket length\neda_train_df['Ticket'] = eda_train_df['Ticket'].apply(lambda x: x.strip())\neda_train_df['TicketLength'] = eda_train_df['Ticket'].apply(lambda x: len(x))\n\n# define chart\nplt.figure(figsize=(14, 6))\nsns.boxplot(y = 'Survived', x = 'TicketLength', data = eda_train_df, palette = survived_hue, fliersize = 0, orient = 'h')\nsns.stripplot(y = 'Survived', x = 'TicketLength', data = eda_train_df, linewidth = 0.8, palette=survived_hue, orient = 'h')\n\nplt.yticks(np.arange(2), ['Drowned', 'Survived'])\nplt.title('Ticket Length distribution grouped by surviving status (train data)',fontsize= 14)\nplt.ylabel('Passenger status after the tragedy')\nplt.tight_layout()","bcee1f82":"# check if ticket contains digits\neda_train_df['TicketContainsDigits'] = eda_train_df['Ticket'].str.contains(r'\\d+', case=True, regex=True)\n\n# define chart\nplt.figure(figsize = (14,8))\nsns.countplot(x = 'TicketContainsDigits', data = eda_train_df, hue = 'Survived', palette = survived_hue)\n\nplt.title('Number of Survived\/Drowned passengers by Tickets which contains digits')\nplt.ylabel('Number of passengers')\nplt.legend(loc=(1.02,.5))","492b5909":"# check if ticket contains letters\neda_train_df['TicketContainsLetters'] = eda_train_df['Ticket'].str.contains(r'\\D+', case=True, regex=True)\n\n# define chart\nplt.figure(figsize = (14,8))\nsns.countplot(x = 'TicketContainsLetters', data = eda_train_df, hue = 'Survived', palette = survived_hue)\n\nplt.title('Number of Survived\/Drowned passengers by Tickets which contains letters')\nplt.ylabel('Number of passengers')\nplt.legend(loc=(1.02,.5))","65a3075b":"# get correlation matrix\ncorr = eda_train_df.corr()\n\n# define chart\nplt.figure(figsize=(10, 10))\nsns.heatmap(\n    corr, vmax=.8, linewidths=0.01,\n    square=True, annot=True,\n    cmap='YlGnBu', linecolor=\"white\"\n)\n\nplt.title('Correlation between features');","18b857eb":"def lowercase_str(df: pd.DataFrame) -> pd.DataFrame:\n    return df.applymap(lambda x: x.lower() if type(x) == str else x)\n\ndef strip_str(df: pd.DataFrame) -> pd.DataFrame:\n    return df.applymap(lambda x: x.strip() if type(x) == str else x)\n\ndef get_name_features(df: pd.DataFrame) -> pd.DataFrame:\n    df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n    df['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n    df['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n    df['NameLength'] = df['Name'].apply(lambda x: len(x))   \n    return df\n\ndef get_ticket_features(df: pd.DataFrame) -> pd.DataFrame:\n    df['Ticket'] = df['Ticket'].apply(lambda x: x.strip())\n    df['TicketLength'] = df['Ticket'].apply(lambda x: len(x))\n    df['TicketContainsDigits'] = df['Ticket'].str.contains(r'\\d+', case=True, regex=True)\n    df['TicketContainsLetters'] = df['Ticket'].str.contains(r'\\D+', case=True, regex=True)\n    return df\n\ndef get_family_features(df: pd.DataFrame) -> pd.DataFrame:\n    df['FamilySize'] = (\n        df[\"SibSp\"] + # siblings\/spouses\n        df[\"Parch\"] # parents\/children \n    )\n    return df\n\ndef get_phare_features(df: pd.DataFrame) -> pd.DataFrame:\n    df['FarePerPerson']=df['Fare']\/(df['FamilySize']+1)\n    return df\n\ndef drop_duplicates_rows(df: pd.DataFrame) -> pd.DataFrame:\n    return df.drop_duplicates().reset_index(drop=True)\n\ndef drop_columns(df: pd.DataFrame, lst_columns: list) -> pd.DataFrame:\n    return df.drop(columns=lst_columns, axis=1)","c9802bdb":"df_modeling = train_df.copy()\n\ndf_modeling = (\n    df_modeling\n    .pipe(lowercase_str)\n    .pipe(strip_str)\n    .pipe(get_name_features)\n    .pipe(get_ticket_features)\n    .pipe(get_family_features)\n    .pipe(get_phare_features)\n    .pipe(drop_duplicates_rows)\n    .pipe(drop_columns, ['PassengerId', 'Cabin'])\n)","a33242d6":"X = df_modeling.drop(['Survived'], axis = 1)\ny = df_modeling['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=.2, random_state=42, stratify=y\n)","f4ff14f5":"numerical_columns = list(X_train.select_dtypes(include=[np.number]))\ncategorical_columns = list(X_train.select_dtypes(include=[object, bool]))","9e54d3af":"# pipeline categorical \ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\n\n# pipeline numerical\nnum_transformer = Pipeline(steps=[\n    ('imputer', KNNImputer()),\n    ('scaler', StandardScaler()),\n    ('pca', PCA())\n])\n\n# pipeline preprocessing\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, numerical_columns),\n        ('cat', cat_transformer, categorical_columns)\n])\n\n# pipeline steps\nsteps = [('preprocessor', preprocessor), ('clf', RidgeClassifier())]\npipe = Pipeline(steps)","5f493cd4":"# define parameters\nparams = {\n   'clf__alpha':[1.0, 1.5, 2.0, 2.5, 3],\n   'clf__max_iter': [None, 250, 500, 750, 1000, 1250]\n}\n  \n# grid search\ngrid = GridSearchCV(pipe, param_grid=params, cv=RepeatedStratifiedKFold(), verbose=1, n_jobs=-1)\ngrid.fit(X_train, y_train)","6946e012":"y_pred = grid.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_pred))","4352b6a0":"df_to_predict = test_df.copy()\n\ndf_to_predict = (\n    test_df\n    .pipe(lowercase_str)\n    .pipe(strip_str)\n    .pipe(get_name_features)\n    .pipe(get_ticket_features)\n    .pipe(get_family_features)\n    .pipe(get_phare_features)\n    .pipe(drop_duplicates_rows)\n    .pipe(drop_columns, ['PassengerId', 'Cabin'])\n)","15d1c10d":"pred_class = grid.best_estimator_.predict(df_to_predict) # calculate prediction probabilities\npredictions = pd.DataFrame(pred_class, columns=['Survived'])\ndf_submission = pd.concat([test_df, predictions], axis =1)","2dd84d3b":"df_submission_formating = df_submission[[\"PassengerId\", \"Survived\"]]\ndf_submission_formating.to_csv('.\/submission.csv', index=False)","1f8e840d":"#### Evaluate Pipelines","bfa0df4c":"### Inference\n\n#### Data Cleaning","7d9ba577":"#### Init ML Pipelines","1bef42a2":"#### Train Pipeline","76ed9871":"#### Format to submit results","bc7687aa":"## Conclusion\n\n- Try other Sklearn Pipelines Implementation \/ Combinaison (example : selectkbest features...)\n- Create new features and measures their relevance\n- Remove unrelevant features","9b18d584":"#### Split Train dataset into train\/validation sets","e61529fa":"---\n\n### PART C - Feature Engineering\n\n#### Preprocessing functions","fd77d65d":"#### Pandas Pipeline Preprocessing","2b062b61":"#### Train \/ Test datasets contains missing data ? ","612cfb35":"#### Prediction","2ce46351":"#### Display files path","08bfce38":"### PART 2 - Exploratory Data Analysis (EDA)","b6e9ee6e":"---\n\n### PART 4 - Modeling\n\n#### Get Numerical \/ Categorical Columns","e02553c0":"#### Fetch datasets","c56548b2":"**Conclusion :**\n\n- Train dataset missing data: \n    - Age (177 - 19.87%)\n    - Cabin (687 - 77.10%)\n    - Embarked (2 - 0.22%)\n- Test dataset missing Data: \n    - Age (86 - 20.57%)\n    - Fare (1 - 0.24%)\n    - Cabin (327 - 78.23%)\n    \n**Suggestion :**\n- Replace Age by average\/median age\n- Discard Fare \/ Embarked empty rows \n- Discard Cabin column\n\n#### What about relationship Survived \/ Other Features on Train Dataset ?","8f516194":"# Binary Classification Projet\n\n## Kaggle Presentation\n\n### Titanic - Machine Learning from Disaster\nThe sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew. While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n- [Kaggle-Competition-Link](https:\/\/www.kaggle.com\/c\/titanic\/overview)\n\n### Challenge\nIn this challenge, we ask you to build a predictive model that answers the question: <br>\n**\u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).**\n\n---\n\n## Data Description \n\n### Overview\nThe data has been split into two groups:\n- training set (train.csv)\n- test set (test.csv)\n\n**The training set** should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\n\n**The test set** should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\n### Data Dictionary\n\n| Variable \t| Definition                                 \t| Key                                            \t|\n|----------\t|--------------------------------------------\t|------------------------------------------------\t|\n| survival \t| Survival                                   \t| 0 = No, 1 = Yes                                \t|\n| pclass   \t| Ticket class                               \t| 1 = 1st, 2 = 2nd, 3 = 3rd                      \t|\n| sex      \t| Sex                                        \t|                                                \t|\n| Age      \t| Age in years                               \t|                                                \t|\n| sibsp    \t| # of siblings \/ spouses aboard the Titanic \t|                                                \t|\n| parch    \t| # of parents \/ children aboard the Titanic \t|                                                \t|\n| ticket   \t| Ticket number                              \t|                                                \t|\n| fare     \t| Passenger fare                             \t|                                                \t|\n| cabin    \t| Cabin number                               \t|                                                \t|\n| embarked \t| Port of Embarkation                        \t| C = Cherbourg, Q = Queenstown, S = Southampton \t|\n\n---\n\n## Code\n\n### PART 1 - Data Gathering\n\n#### Import Libraries "}}