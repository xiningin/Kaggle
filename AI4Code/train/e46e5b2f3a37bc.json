{"cell_type":{"ad18e836":"code","c11d9441":"code","c3578725":"code","5d55175c":"code","994688b4":"code","aa996cc5":"code","26079d47":"code","8a15d04f":"code","4e7d0c35":"code","63847a6f":"code","5cc00d61":"code","c6bac072":"code","6aca3ad2":"code","57294da3":"code","3bd0d533":"code","ebe525db":"code","a989934e":"code","bd952060":"code","38d18ed5":"code","080d7f5d":"code","0aaa70fe":"code","a324c144":"code","2a9fc21b":"code","b36a2649":"code","3156329f":"code","2e456dfa":"code","4e21c225":"code","977768be":"code","b1b714bb":"code","9fdba726":"code","ad50121e":"code","5302eee9":"code","b5cf7c3a":"code","691342a4":"code","c3f0e766":"code","498682dc":"code","7fba8672":"code","cb32afcb":"code","1cbae54d":"code","aee14e96":"code","95e0aba5":"code","ea1c636c":"code","5abb884d":"code","6d260cd7":"code","caf7c2f7":"code","ed5f8bb0":"code","a68f3290":"code","673bad60":"code","96eabdd4":"code","9ab5de90":"code","359911bf":"code","815ea835":"code","27604d44":"code","d8d99da6":"code","69e172ee":"code","1ec22a66":"code","6f015456":"code","1fa24435":"code","a85aaa74":"code","baaa7f51":"code","888431be":"code","5bc2d409":"code","adda9370":"code","398db47e":"code","441ebd5b":"code","e9350e2f":"code","b09dafbe":"code","f57a1ead":"code","9f7be555":"code","a39fa78d":"code","67b7f293":"markdown","3111a35c":"markdown","26e2f4db":"markdown","adecd785":"markdown","ba9914d7":"markdown","be4ecb9b":"markdown","6c95a6ad":"markdown","1c49d95c":"markdown","8e8f27c8":"markdown","54ed76ed":"markdown","5ad11633":"markdown","f7ee0abd":"markdown","0b7eb890":"markdown","5a3d663d":"markdown","96c6c09c":"markdown","fdb4c174":"markdown","e0fd08c9":"markdown","9d0322ed":"markdown","b524a620":"markdown","32f3911e":"markdown","a9d759d2":"markdown","30b016bc":"markdown","9e5e12c2":"markdown","b761d433":"markdown","2aca4236":"markdown","a371d665":"markdown","29be3949":"markdown","0932f5e8":"markdown","2d37b338":"markdown","9a1f5c45":"markdown","30cd97bb":"markdown","ca3e748d":"markdown","f8e6e775":"markdown"},"source":{"ad18e836":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import cross_validate","c11d9441":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c3578725":"df_sales = pd.read_csv('\/kaggle\/input\/retaildataset\/sales data-set.csv', parse_dates=[\"Date\"])\ndf_stores = pd.read_csv('\/kaggle\/input\/retaildataset\/stores data-set.csv')\ndf_features = pd.read_csv('\/kaggle\/input\/retaildataset\/Features data set.csv', parse_dates=[\"Date\"])","5d55175c":"df_sales.head()","994688b4":"df_stores.head()","aa996cc5":"df_features.tail()","26079d47":"df = df_sales.merge(df_stores).merge(df_features)\ndf.tail()","8a15d04f":"train_data = df.sample(frac=0.8, random_state=123)\ntrain_data","4e7d0c35":"test_data = df[~df.index.isin(train_data.index)]\ntest_data","63847a6f":"train_data.describe()","5cc00d61":"train_data[\"Month\"] = train_data.Date.dt.month\ntrain_data[\"Year\"] = train_data.Date.dt.year\ntrain_data[\"Week\"] = train_data.Date.dt.weekofyear\ntrain_data[\"Day\"] = train_data.Date.dt.dayofyear\ntrain_data.drop(['Date'],axis=1,inplace=True)","c6bac072":"train_data.describe()","6aca3ad2":"train_data.info()","57294da3":"train_data.isnull().sum()","3bd0d533":"lst = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\nfor column in lst:\n    train_data[column].fillna((train_data[column].mean()), inplace=True)\ntrain_data.head()","ebe525db":"m = pd.get_dummies(train_data[\"Type\"])\nm = m.rename(columns={\"A\": \"TypeA\", \"B\": \"TypeB\", \"C\": \"TypeC\"})\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Type\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"IsHoliday\"])\nm = m.rename(columns={False: \"Not Holiday\", True: \"Holiday\"})\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"IsHoliday\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"Store\"])\nm = m.rename(columns=lambda x: 'Store' + str(x))\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Store\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"Dept\"])\nm = m.rename(columns=lambda x: 'Dept' + str(x))\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Dept\", axis = 1, inplace = True)\n\nm = pd.get_dummies(train_data[\"Week\"])\nm = m.rename(columns=lambda x: 'Week' + str(x))\n\ntrain_data = pd.concat([train_data, m], axis = 1)\ntrain_data.drop(\"Week\", axis = 1, inplace = True)","a989934e":"train_data","bd952060":"test_data[\"Month\"] = test_data.Date.dt.month\ntest_data[\"Year\"] = test_data.Date.dt.year\ntest_data[\"Week\"] = test_data.Date.dt.weekofyear\ntest_data[\"Day\"] = test_data.Date.dt.dayofyear\ntest_data.drop(['Date'],axis=1,inplace=True)\n\nlst = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\nfor column in lst:\n    test_data[column].fillna(0, inplace=True)\n\ns = pd.get_dummies(test_data[\"Type\"])\ns = s.rename(columns={\"A\": \"TypeA\", \"B\": \"TypeB\", \"C\": \"TypeC\"})\n\ntest_data = pd.concat([test_data, s], axis = 1)\ntest_data.drop(\"Type\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"IsHoliday\"])\nm = m.rename(columns={False: \"Not Holiday\", True: \"Holiday\"})\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"IsHoliday\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"Store\"])\nm = m.rename(columns=lambda x: 'Store' + str(x))\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"Store\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"Dept\"])\nm = m.rename(columns=lambda x: 'Dept' + str(x))\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"Dept\", axis = 1, inplace = True)\n\nm = pd.get_dummies(test_data[\"Week\"])\nm = m.rename(columns=lambda x: 'Week' + str(x))\n\ntest_data = pd.concat([test_data, m], axis = 1)\ntest_data.drop(\"Week\", axis = 1, inplace = True)","38d18ed5":"test_data","080d7f5d":"df_weekly_sales = train_data['Weekly_Sales']\ntrain_data = train_data \/ train_data.max()\ntrain_data['Weekly_Sales'] = df_weekly_sales","0aaa70fe":"train_data","a324c144":"test_weekly_sales = test_data['Weekly_Sales']\ntest_data = test_data \/ test_data.max()\ntest_data['Weekly_Sales'] = test_weekly_sales","2a9fc21b":"test_data","b36a2649":"X = train_data.drop('Weekly_Sales', axis=1)\ny = train_data['Weekly_Sales']","3156329f":"X_test = test_data.drop('Weekly_Sales', axis=1)\ny_test = test_data['Weekly_Sales']","2e456dfa":"# from sklearn.decomposition import PCA\n\n# train_data_drop = train_data.drop('Weekly_Sales', axis=1)\n\n# pca = PCA(100)\n# pca_train_data = pca.fit_transform(train_data_drop)\n\n# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n# plt.xlabel('number of components')\n# plt.ylabel('cumulative explained variance')","4e21c225":"# sns.set(rc={'figure.figsize':(20,18)})\n# sns.heatmap(df.corr(), center = 0, annot = True)","977768be":"# from sklearn import preprocessing\n# scaler = preprocessing.StandardScaler()\n\n# scaler_list = ['Weekly_Sales', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Month', 'Year', 'Day']\n\n# scaler_data = train_data[scaler_list]\n# scaler_data = pd.DataFrame(scaler.fit_transform(scaler_data))\n\n# train_data.drop(scaler_list, axis=1, inplace=True).reset_index(inplace=True)\n\n# # train_data = pd.concat([scaler_data, train_data], ignore_index=True, axis=1)\n\n# # train_data = pd.DataFrame(scaler.fit_transform(X))\n# # train_data['Weekly_Sales'] = df_weekly_sales","b1b714bb":"# from sklearn import linear_model\n# from sklearn.model_selection import cross_validate\n# from sklearn.metrics import make_scorer\n# from sklearn.metrics import confusion_matrix\n# import lightgbm as lgb","9fdba726":"# X = np.array(train_data.drop('Weekly_Sales', axis=1))\n# y = np.array(train_data[\"Weekly_Sales\"])\n# my_model = lgb.LGBMRegressor(objective='regression', num_leaves=150, max_depth = 14, learning_rate=0.5, n_estimators=2000, reg_alpha=0.5)\n# cv_results = cross_validate(my_model, X, y, scoring = \"r2\", cv = 10)\n# sorted(cv_results.keys())\n# cv_results['test_score']","ad50121e":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","5302eee9":"reg_ols = sm.OLS(y, X)\nest = reg_ols.fit()\nest.summary()  ","b5cf7c3a":"y_pred = est.predict(X)\n\nr_2 = r2_score(y, y_pred)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","691342a4":"y_test_pred = est.predict(X_test)\n\nr_2 = r2_score(y_test, y_test_pred)\nrmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","c3f0e766":"from sklearn.linear_model import Lasso","498682dc":"reg_lasso = Lasso().fit(X,y)\n\ny_pred = reg_lasso.predict(X)\n\nr_2 = reg_lasso.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","7fba8672":"y_test_pred = reg_lasso.predict(X_test)\n\nr2_test = reg_lasso.score(X_test, y_test)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","cb32afcb":"from sklearn.linear_model import Ridge","1cbae54d":"reg_ridge = Ridge().fit(X,y)\n\ny_pred = reg_ridge.predict(X)\n\nr_2 = reg_ridge.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","aee14e96":"y_test_pred = reg_ridge.predict(X_test)\n\nr_2 = reg_ridge.score(X_test, y_test)\nrmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","95e0aba5":"# from sklearn.preprocessing import PolynomialFeatures\n# from sklearn import linear_model","ea1c636c":"# poly = PolynomialFeatures(degree=2)\n# X = poly.fit_transform(X)\n\n# clf = linear_model.LinearRegression().fit(X, y)\n# clf.score(X, y)","5abb884d":"from sklearn.ensemble import GradientBoostingRegressor","6d260cd7":"reg_gbdt = GradientBoostingRegressor().fit(X,y)\n\ny_pred = reg_gbdt.predict(X)\n\nr_2 = reg_gbdt.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","caf7c2f7":"y_test_pred = reg_gbdt.predict(X_test)\n\nr_2 = reg_gbdt.score(X_test, y_test)\nrmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","ed5f8bb0":"from xgboost import XGBRegressor","a68f3290":"reg_xgb = XGBRegressor(objective='reg:squarederror', n_estimators=2000)\nreg_xgb = reg_xgb.fit(X,y)\n\ny_pred = reg_xgb.predict(X)\n\nr2 = reg_xgb.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","673bad60":"y_test_pred = reg_xgb.predict(X_test)\n\nr2_test = reg_xgb.score(X_test, y_test)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","96eabdd4":"import lightgbm as lgb","9ab5de90":"reg_lgb = lgb.LGBMRegressor(objective='regression', num_leaves=60, max_depth = 9, learning_rate=0.5, n_estimators=2000, reg_alpha=0.6, subsample=0.6, colsample_bytree = 0.8, scale_pos_weight = 5)\nreg_lgb.fit(X, y, verbose=False)","359911bf":"y_pred = reg_lgb.predict(X)\n\nr_2 = reg_lgb.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","815ea835":"y_test_pred = reg_lgb.predict(X_test)\n\nr2_test = reg_lgb.score(X_test, y_test)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","27604d44":"def build_model():\n  model = keras.Sequential([\n    layers.Dense(256, activation='relu', input_shape=[len(X.keys())]),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\nmodel = build_model()","d8d99da6":"model.summary()","69e172ee":"train_stats = train_data.describe()\ntrain_stats.pop(\"Weekly_Sales\")\ntrain_stats = train_stats.transpose()\ntrain_stats","1ec22a66":"def norm(x):\n  return (x - train_stats['mean']) \/ train_stats['std']\n  \nnorm_X = norm(X)\nnorm_X_test = norm(X_test)","6f015456":"class PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 200\n\nhistory = model.fit(\n  norm_X, y,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[PrintDot()])","1fa24435":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","a85aaa74":"def plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [Weekly_Sales]')\n  plt.plot(hist['epoch'], hist['mae'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mae'],\n           label = 'Val Error')\n  plt.ylim([0,3000])\n  plt.legend()\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error [Weekly_Sales]')\n  plt.plot(hist['epoch'], hist['mse'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mse'],\n           label = 'Val Error')\n#   plt.ylim([0,3000])\n  plt.legend()\n  plt.show()\n\n\nplot_history(history)","baaa7f51":"y_pred = model.predict(norm_X)\n\nr_2 = r2_score(y, y_pred)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","888431be":"y_test_pred = model.predict(norm_X_test)\n\nr2_test = r2_score(y_test, y_test_pred)\nrmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\nmae_test = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","5bc2d409":"outliers_data = train_data[train_data[\"Weekly_Sales\"] >= 40000]\nnormal_data = train_data[train_data[\"Weekly_Sales\"] < 40000]","adda9370":"X = outliers_data.drop('Weekly_Sales', axis=1)\ny = outliers_data['Weekly_Sales']\nmodel_outliers = lgb.LGBMRegressor(objective='regression', num_leaves=140, max_depth = 15, learning_rate=0.5, n_estimators=2000, reg_alpha=0.6)\nmodel_outliers.fit(X, y, verbose=False)","398db47e":"y_pred = model_outliers.predict(X)\n\nr_2 = model_outliers.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","441ebd5b":"X = normal_data.drop('Weekly_Sales', axis=1)\ny = normal_data['Weekly_Sales']\nmodel_normal = lgb.LGBMRegressor(objective='regression', num_leaves=140, max_depth = 15, learning_rate=0.5, n_estimators=2000, reg_alpha=0.6)\nmodel_normal.fit(X, y, verbose=False)","e9350e2f":"y_pred = model_normal.predict(X)\n\nr_2 = model_normal.score(X, y)\nrmse = mean_squared_error(y, y_pred, squared=False)\nmae = mean_absolute_error(y, y_pred)\n\nprint(\"R squared:\", r_2)\nprint(\"RMSE:\", rmse)\nprint(\"MAE:\", mae)","b09dafbe":"from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n\nmodel = NearestNeighbors(algorithm = \"brute\", n_neighbors = 5)\nmodel.fit(train_data.drop('Weekly_Sales', axis=1))\n\nX_test = X_test.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\n\nindices = model.kneighbors(X_test, 3, return_distance=False)\n\ny_test = pd.DataFrame(y_test)\nX_test['label'] = [0]*len(X_test)\ny_test['label'] = [0]*len(y_test)\nfor i,index_list in enumerate(indices):\n    count = 0\n    for index in index_list:\n        if train_data['Weekly_Sales'].iloc[index] >= 40000:\n            count += 1\n    if count > 1:\n        X_test['label'].iloc[i] = 1\n        y_test['label'].iloc[i] = 1\n\nX_test_normal = X_test[X_test['label'] == 0]\nX_test_outlier = X_test[X_test['label'] == 1]\ny_test_normal = y_test[y_test['label'] == 0]\ny_test_outlier = y_test[y_test['label'] == 1]\n\ny_test_normal = y_test_normal.drop('label', axis = 1)\ny_test_outlier = y_test_outlier.drop('label', axis = 1)","f57a1ead":"y_test_normal_pred = model_normal.predict(X_test_normal.drop('label', axis=1))\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom math import sqrt\nr2_test = r2_score(y_test_normal, y_test_normal_pred)\nrmse_test = sqrt(mean_squared_error(y_test_normal, y_test_normal_pred))\nmae_test = mean_absolute_error(y_test_normal, y_test_normal_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","9f7be555":"y_test_outlier_pred = model_outliers.predict(X_test_outlier.drop('label', axis=1))\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom math import sqrt\nr2_test = r2_score(y_test_outlier, y_test_outlier_pred)\nrmse_test = sqrt(mean_squared_error(y_test_outlier, y_test_outlier_pred))\nmae_test = mean_absolute_error(y_test_outlier, y_test_outlier_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","a39fa78d":"overall_y_test_pred = y_test_normal_pred.tolist() + y_test_outlier_pred.tolist()\noverall_y_test = y_test_normal['Weekly_Sales'].tolist() + y_test_outlier['Weekly_Sales'].tolist()\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom math import sqrt\nr2_test = r2_score(overall_y_test, overall_y_test_pred)\nrmse_test = sqrt(mean_squared_error(overall_y_test, overall_y_test_pred))\nmae_test = mean_absolute_error(overall_y_test, overall_y_test_pred)\n\nprint(\"R squared:\", r2_test)\nprint(\"RMSE:\", rmse_test)\nprint(\"MAE:\", mae_test)","67b7f293":"# Preprocessing","3111a35c":"## Split X and y","26e2f4db":"## Polynomial regression","adecd785":"## LightGBM","ba9914d7":"## KNN to split test data","be4ecb9b":"# Submission 4: Split train dataset and train two models (using LightGBM)","6c95a6ad":"## Lasso regression","1c49d95c":"## Cross Validation","8e8f27c8":"## Number of Nulls for each Feature","54ed76ed":"## Normalization","5ad11633":"## Ridge regression","f7ee0abd":"## Predict on two test dataset using two models","0b7eb890":"## Replace all missing value with zero","5a3d663d":"## Import needed packages","96c6c09c":"## Merge data","fdb4c174":"# Retail Sales Forescast Project by Shizheng Hou, Chuke Xu and Lei","e0fd08c9":"## Read and Import data","9d0322ed":"## Gradient Boosting Decision Tree","b524a620":"## XGBoost","32f3911e":"## Overall performance in whole test dataset","a9d759d2":"# Submission 0: Linear regression","30b016bc":"## Normal data","9e5e12c2":"## Data frame information","b761d433":"# Submission 3: Neural Network","2aca4236":"## Outliers data","a371d665":"## Heat Map","29be3949":"## Encoding","0932f5e8":"## OLS Regression","2d37b338":"## Tranform date to 3 columns","9a1f5c45":"## (PCA)","30cd97bb":"## (Standardization)","ca3e748d":"# Submission 2: GBDT, XGBoost and LightBGM","f8e6e775":"# Submission 1: Lasso, Ridge and Polynomial regression"}}