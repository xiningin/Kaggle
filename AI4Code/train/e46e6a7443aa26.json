{"cell_type":{"cf38aea3":"code","50ee4258":"code","3a0859c0":"code","089ae7d3":"code","ced782d8":"code","ab97083c":"code","7c2c87e8":"code","12add9d9":"code","bdcd5d2d":"code","11e2dd4f":"code","73bdf97d":"code","72984048":"code","74244fcc":"code","5674bd89":"code","d4639f88":"code","7051a77a":"markdown","644fecbd":"markdown","1016b279":"markdown","85309031":"markdown","f215fcbc":"markdown"},"source":{"cf38aea3":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","50ee4258":"dim = 1024 #1024, 256, 'original'\ntest_dir = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test'\n# yolov5x Fold 4 finetune768\nweights_dir = '\/kaggle\/input\/vinbigdata-final-models\/yolov5x_fold4_finetune768_best.pt'","3a0859c0":"test_df = pd.read_csv(f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/test.csv')\ntest_df.head()","089ae7d3":"shutil.copytree('\/kaggle\/input\/yolov5-official-v40\/multilabel-YOLOv5-v4.0\/YOLOv5-v4.0', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5') # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","ced782d8":"!pip install -U -r \/kaggle\/working\/yolov5\/requirements.txt # install dependencies","ab97083c":"!pip install pycocotools\n!pip install thop","7c2c87e8":"!pip install torchvision==0.8.1","12add9d9":"!pip install --upgrade seaborn\n!pip install --upgrade matplotlib","bdcd5d2d":"!python detect.py --weights $weights_dir\\\n--img 768\\\n--conf 0.01\\\n--iou 0.5\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok --augment","11e2dd4f":"!pip install pandas==1.1.5","73bdf97d":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]\/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes","72984048":"image_ids = []\nPredictionStrings = []\n\nfor file_path in tqdm(glob('runs\/detect\/exp\/labels\/*txt')):\n    image_id = file_path.split('\/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.image_id==image_id,['width', 'height']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n#     bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 3).astype(str))\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))","74244fcc":"pred_df = pd.DataFrame({'image_id':image_ids,\n                        'PredictionString':PredictionStrings})\nsub_df = pd.merge(test_df, pred_df, on = 'image_id', how = 'left').fillna(\"14 1 0 0 1 1\")\nsub_df = sub_df[['image_id', 'PredictionString']]\nsub_df.to_csv('\/kaggle\/working\/yolov5x_fold4_finetune768_submission.csv',index = False)\nsub_df.tail()","5674bd89":"len(sub_df)","d4639f88":"shutil.rmtree('\/kaggle\/working\/yolov5')","7051a77a":"# YOLOv5 Stuff","644fecbd":"# Process Submission","1016b279":"# Version\n\n* `v7`: yolov5x_fold4_finetune768 tta768 conf_thr=0.01\n* `v6`: yolov5x_fold3_finetune768 tta768 conf_thr=0.01\n* `v5`: yolov5x_fold2_finetune768 tta768 conf_thr=0.01\n* `v4`: yolov5x_fold1_finetune768 tta768 conf_thr=0.01\n* `v3`: yolov5x_fold0_finetune768 tta768 conf_thr=0.01","85309031":"# [Training Notebook](https:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class)\n* Select `GPU` as the **Accelerator**","f215fcbc":"# Inference"}}