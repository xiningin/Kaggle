{"cell_type":{"e7a8d4e7":"code","3a1b9f7c":"code","2209fe0c":"code","17ba34ea":"code","537fcfb7":"code","9a1e894c":"code","a9e22c7a":"code","3f5cefab":"code","bb942813":"code","8d09536a":"code","96fd1afd":"code","db6dfe7f":"code","843b6f55":"markdown","0332c384":"markdown","93aba564":"markdown","21541abb":"markdown","d979e979":"markdown","081365c7":"markdown","7e38e9a2":"markdown","79c65bff":"markdown","2a437f38":"markdown","9916035e":"markdown","0a1e69db":"markdown","5a21ae67":"markdown","ff1d5763":"markdown"},"source":{"e7a8d4e7":"from keras.models import Sequential\nfrom keras.layers import Activation, Dense\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.models import load_model\nimport keras.callbacks as kcall\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3a1b9f7c":"train_NORMAL    = !find ..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/NORMAL\/ -type f  -exec file {} \\+ | grep -c -i 'image'\ntrain_PNEUMONIA = !find ..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/PNEUMONIA\/ -type f  -exec file {} \\+ | grep -c -i 'image'\nval_NORMAL      = !find ..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/NORMAL\/ -type f  -exec file {} \\+ | grep -c -i 'image'\nval_PNEUMONIA   = !find ..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/PNEUMONIA\/ -type f  -exec file {} \\+ | grep -c -i 'image'\ntest_NORMAL     = !find ..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/NORMAL\/ -type f  -exec file {} \\+ | grep -c -i 'image'\ntest_PNEUMONIA  = !find ..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/PNEUMONIA\/ -type f  -exec file {} \\+ | grep -c -i 'image'\n\n\ntrain_data = np.array([int(train_NORMAL[0]),int(train_PNEUMONIA[0])])\ntest_data = np.array([int(test_NORMAL[0]),int(test_PNEUMONIA[0])])\nval_data = np.array([int(val_NORMAL[0]),int(val_PNEUMONIA[0])])","2209fe0c":"index = np.arange(2)\nbar_width = 0.25\nopacity = 0.7\n\nrects1 = plt.bar(index, train_data, bar_width,\n                alpha=opacity, color='b',\n                label='Train')\nrects2 = plt.bar(index + bar_width, val_data, bar_width,\n                alpha=opacity, color='r', tick_label = ('Normal', 'Pneumonia'),\n                label='Val')\nrects3 = plt.bar(index + 2*bar_width, test_data, bar_width,\n                alpha=opacity, color='g', tick_label = ('Normal', 'Pneumonia'),\n                label='test')\n\nplt.xlabel('Class')\nplt.ylabel('Number of examples')\nplt.title('Total examples per set')\nplt.xticks(index + bar_width)\nplt.legend()\n\nplt.show()","17ba34ea":"## Intilizing variables\noutput_classes = 2\nlearning_rate = 0.0001\nimg_width, img_height,channel = 299, 299, 3\ntraining_examples = 5216 \nbatch_size = 30 \nepochs = 5\nresume_model = False\ntraining_data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train'\nval_data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val'\ntest_data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test'\ntrained_model_dir = '..\/input\/keras-pretrained-models\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'","537fcfb7":"if resume_model == False:\n  ## Model Defination\n  model = Sequential()\n  model.add(Xception(weights=trained_model_dir , include_top=False,pooling = 'avg'))\n  #model.add(Dense(units = 100 , activation = 'relu'))\n  model.add(Dense(units=output_classes, activation='softmax'))\n\n  model.layers[0].trainable = True\n\n  model.compile(loss='categorical_crossentropy',\n                optimizer=Adam(lr=learning_rate),\n                metrics=['accuracy'])\n\n  ## model.load_weights('xception_weights_tf_dim_ordering_tf_kernels_notop.h5', by_name=True)\n\n  ## Image generator function for training and validation\n  img_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n  train_img_generator = img_generator.flow_from_directory(\n        training_data_dir,\n        target_size = (img_width,img_height),\n        batch_size = batch_size,\n        class_mode = 'categorical')\n\n  val_img_generator = img_generator.flow_from_directory(\n                          val_data_dir,\n                          target_size = (img_width,img_height),\n                          class_mode = 'categorical')\n\n  for i, layer in enumerate(model.layers):\n     print('Layer: ',i+1,' Name: ', layer.name)\n","9a1e894c":"## Callbacks for model training\nearly_stop = kcall.EarlyStopping(monitor = 'acc', min_delta=0.0001)\ntensorboard =kcall.TensorBoard(log_dir='.\/tensorboard-logs',write_grads=1,batch_size = batch_size)\n\nclass LossHistory(kcall.Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.acc = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        self.acc.append(logs.get('acc'))\n\nhistory = LossHistory()","a9e22c7a":"## Training only the newly added layer\nif resume_model:\n\tmodel = load_model('chest_xray.h5')\nelse: \n\tmodel.fit_generator(train_img_generator,\n        steps_per_epoch = training_examples \/\/ batch_size,\n        epochs = epochs,\n        validation_data = val_img_generator,\n\t\tvalidation_steps = 1,\n\t\tcallbacks=[early_stop,history])\n\n\t## saving model\n\t#model.save('chest_xray.h5')\n","3f5cefab":"## Image generator function for testing\ntest_img_generator = img_generator.flow_from_directory(\n                        test_data_dir,\n                        target_size = (img_width,img_height),\n                        class_mode = 'categorical',\n                        batch_size= batch_size,\n\t\t\t                  shuffle = False)","bb942813":"test_accu = model.evaluate_generator(test_img_generator,steps=624 \/\/ batch_size)","8d09536a":"print('Accuracy on test data is:', test_accu[1])\nprint('Loss on test data is:', test_accu[0])","96fd1afd":"plt.plot(history.losses,'b--',label='Training')\nplt.plot(len(history.losses)-1,test_accu[0],'go',label = 'Test')\n\nplt.xlabel('# of batches trained')\nplt.ylabel('Training loss')\n\nplt.title('Training loss vs batches trained')\n\nplt.legend()\n\nplt.ylim(0,1.2)\nplt.show()","db6dfe7f":"plt.plot(history.acc,'--',label= 'Training')\nplt.plot(len(history.acc)-1,test_accu[1],'go',label='Test')\n\nplt.xlabel('# of batches trained')\nplt.ylabel('Training accuracy')\n\nplt.title('Training accuracy vs batches trained')\n\nplt.legend(loc=4)\nplt.ylim(0,1.1)\nplt.show()","843b6f55":"# Prediciting Pneumonia with the help of transfer Learning\nThis dataset is avilable on Kaggle [here](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia). The motivation for me here was to implement transfer learning. I was doing a tutorial on it, and thought of using a dataset from kaggle and hence this kernal. \n\nI have tried to explain the model and so, if someone thinks of an improvemnt I can try that. I have used Xception model trained on Imagenet as the base model, and implemented transfer learning in Keras with Tensorflow backend. So, lets start with the dataset and then I will move on to the code:\n\nIts a binary classification dataset. The two classes are **Normal** and **Pneumonia**.  \n![Dataset](https:\/\/i.imgur.com\/jZqpV51.png)\n Below are some cool things about the dataset (after some necessary imports)\n\n","0332c384":"## Plotting the values\nThe data from above, was used in bar graph below. The plot conveys that we have more example of Pneumonia than that of normal scans, which for me was a bit unexpected. I thought it would be reversed.  ","93aba564":"## Import statments\nNot much magic here, just routine libraries","21541abb":"## Evaluating the model\nThis step is used to evaluate the model. It takes the image \"generator\" to provide images in batch and if you have question on steps then dont worry its mentioned in Keras documentation.","d979e979":"## Parameters\n- Learning rate was choosen after training the model couple of time. So, no doubts here\n- image width and height was specified as for the base model. \n- batch size, I tried a couple but then stick to 30 as either increasing\/decreasing it, wasn't helping in reducing accuracy\n- epochs was choosen  because training accuracy reached saturation of around 99.8% and validation accuracy to 100%\n- `resume_model` is used when you want to resume from the **compeletly** trained model, i.e. including the last layers inserted by us. ","081365c7":"## Model Training\nI have used generators to provide the images in batches for training, apart from that if you want you can save the model by un-commenting the last line in this block. ","7e38e9a2":"# ------   End of Kernal   ------\n\n","79c65bff":"## CallBacks for model training\nThis was interesting part, and the only requirment for me was the `LossHistory` class. But, I thought why not extend it and use a couple of more callbacks. Now a word of caution, some callbacks increase the training time because they have their own computation, such as tensorboard. I used in on my mac but not here, because it drastically slowed the training and so i was experimenting here with this data and so its clear not to include tensorboard.","2a437f38":"## Model Defination\nUsing Xception as the base model, and the reason being, it had the best accuracy on imagenet both Top-1 and Top-5 accuracy. The only thing I tried here was using another layer apart from the final layer. The result was not good and so dropped it in the final model. This code will only be executed is `resume_model` is `False`, and its obivious as well. ","9916035e":"## Declaring results\n- Loss on Test data  \n- Accuracy on Test data","0a1e69db":"## Reading the dataset direcotry\nThis is used to understand the dataset distribution. I have also distributed the type of data i.e. training, validation and test for plotting based on class labels. The bash command was taken from [this](https:\/\/serverfault.com\/a\/398682) answer. I tried looping as well but i just couldn't make the code to run. There was some issue with double quotes used in terminal and python returning strings in single quotes.\n\nSo for below code, yes I understand its naive but I had to finish this kernal in time and hence couldn't \"invest\" more time in this small section.","5a21ae67":"## Test image generator\nNow if you have read, genrative models, then its not actually generating images, rather this function here acts as a pipeline to provide the images as batches for the model evaluation step. \n- Shuffle here is `False` because I read it somewhere to set it so when evaluating the model\n- `Batch_size` is same as that used in training the model","ff1d5763":"## Data Visualisation\nBelow are 2 plots, namely Training loss vs batches trained and the other one is trainng accuracy vs batches trained. I am new to platform and to machine learning as well, so these are only two plots which came to my mind."}}