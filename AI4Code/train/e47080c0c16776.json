{"cell_type":{"32f20c73":"code","67775c10":"code","974362db":"code","1f5a97d3":"code","6ae25296":"code","55acb896":"code","02d684a1":"code","c823e9cf":"code","72317921":"code","b49b95dd":"markdown"},"source":{"32f20c73":"import gensim\nimport nltk","67775c10":"from nltk.data import find\nword2vec_sample = str(find('models\/word2vec_sample\/pruned.word2vec.txt'))\nmodel = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)","974362db":"model.most_similar(positive=['medium'], topn = 3)","1f5a97d3":"from nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer","6ae25296":"lemmatizer = WordNetLemmatizer()","55acb896":"def similar_questions(qus):\n    dict1 = {}\n    pos_tag = nltk.pos_tag(word_tokenize(qus))\n    for i in pos_tag:\n        if(i[1] in ['JJ', 'JJR','JJS']):\n            try:\n                dict1.update({i[0]:[k for k in [j[0] for j in model.most_similar_cosmul(positive=[i[0]], topn = 10)] if(k!=lemmatizer.lemmatize(i[0], \"v\") and k[:3].lower()!=i[0][:3].lower() and k.lower()!=i[0].lower())][:2]})\n            except:\n                print(\"Not trained on this word\")\n        elif(i[1] in ['VB', 'VBD','VBG','VBN','VBP']):\n            try:\n                dict1.update({i[0]:[k for k in [j[0] for j in model.most_similar_cosmul(positive=[i[0]], topn = 10)] if(k!=lemmatizer.lemmatize(i[0], \"v\") and k[:3].lower()!=i[0][:3].lower() and k.lower()!=i[0].lower())][:2]})\n            except:\n                print(\"Not trained on this word\")\n        elif(i[1] in ['NN', 'NNS','NNP','NNPS']):\n            try:\n                dict1.update({i[0]:[k for k in [j[0] for j in model.most_similar_cosmul(positive=[i[0]], topn = 10)] if(k!=lemmatizer.lemmatize(i[0], \"v\") and k[:3].lower()!=i[0][:3].lower() and k.lower()!=i[0].lower())][:2]})\n            except:\n                print(\"Not trained on this word\")\n    list1=[]\n    for i in range(2):\n        for k in dict1:\n            list1.append(qus.replace(k,dict1[k][i]))\n    return list1","02d684a1":"qus1 = \"Where is the official home of Santa Claus?\"\nprint(\"=\"*20, \"Similar Questions\", \"=\"*20)\nsimilar_questions(qus1)","c823e9cf":"qus2 = \"What is the largest country in the world in terms of land area?\"\nprint(\"=\"*20, \"Similar Questions\", \"=\"*20)\nsimilar_questions(qus2)","72317921":"qus3 = \"At which place in the world, Narendra Modi wax statue was unveiled in a museum?\"\nprint(\"=\"*20, \"Similar Questions\", \"=\"*20)\nsimilar_questions(qus3)","b49b95dd":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python\/"}}