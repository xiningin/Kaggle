{"cell_type":{"80d96509":"code","a12ccb96":"code","8ea8c967":"code","ba690add":"code","d0167337":"code","b48a20f6":"code","fbc6dc39":"code","0007891d":"code","abb6fc63":"code","2689e4b4":"code","bcb7a9be":"code","9d871f55":"code","72c37af2":"code","93d8b799":"code","ecfbfa7b":"code","e5ba9950":"code","cf69ae1c":"code","e50c0cf0":"code","39594e67":"code","343f6130":"code","d19689bc":"code","a9f31e19":"code","6f700833":"code","98ff9cde":"code","c1ef0009":"code","8d3ef5b3":"code","1884e801":"code","595c6506":"code","e2f601a1":"code","cd437e4d":"code","1c2e3528":"code","ee0c9dcf":"code","03368b49":"code","6abcb9db":"code","c4893dc0":"code","b55e386b":"code","88a39d9b":"code","891315c9":"code","81ffa189":"code","ca688ee7":"code","756d3445":"code","55c34872":"code","8124ae4b":"code","2ef00025":"code","ec8be8e6":"code","a7d6dd46":"code","23ec42c6":"code","f0aa969f":"code","37a523b3":"code","7ba97efa":"markdown","632e90d5":"markdown","26d29b06":"markdown","e626ce9b":"markdown","4324780f":"markdown","cdd0b1ad":"markdown","e8756821":"markdown","dc15ae0f":"markdown","7f6fde91":"markdown","9deb2302":"markdown","e167b7c5":"markdown","9d8ef4bc":"markdown"},"source":{"80d96509":"# Importing the Required Libraries\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import *\nfrom IPython.core.display import display, HTML\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport warnings; warnings.simplefilter('ignore')\ndisplay(HTML(\"<style>.container { width:75% !important; }<\/style>\"))","a12ccb96":"# Importing the Data Set\ndf_adult_eda = pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\")\ndf_adult_eda.head()","8ea8c967":"df_adult_eda.info()","ba690add":"# Removing any space in the names of the columns\ndf_adult_eda.columns = df_adult_eda.columns.str.replace(' ', '')\ndf_adult_eda.columns","d0167337":"df_adult_eda['income'].value_counts()","b48a20f6":"print(\"Initial shape of the dataset : \", df_adult_eda.shape)\n\n# Dropping the duplicate Rows\ndf_adult_eda = df_adult_eda.drop_duplicates(keep = 'first')\nprint (\"Shape of the dataset after dropping the duplicate rows : \", df_adult_eda.shape)","fbc6dc39":"df_adult_eda.head()","0007891d":"df_adult_eda['age'].nunique()","abb6fc63":"df_adult_eda['workclass'].unique()","2689e4b4":"# Checking the null values in the columns\ndf_adult_eda.isnull().sum(axis = 0)","bcb7a9be":"df_adult_eda[df_adult_eda['native.country'] == '?'].shape","9d871f55":"# This Code will Count the occuring of the '?' in all the columns\nfor i in df_adult_eda.columns:\n    t = df_adult_eda[i].value_counts()\n    index = list(t.index)\n    print (\"The Value Counts of ? in\", i)\n    for i in index:\n        temp = 0\n        if i == '?':\n            print (t['?'])\n            temp = 1\n            break\n    if temp == 0:\n        print (\"0\")","72c37af2":"# Dropping the rows whose occupation is '?' \ndf_adult_eda = df_adult_eda[df_adult_eda.occupation != '?']\n\ndf_adult_eda['occupation'].value_counts()","93d8b799":"# The minimum age of the person\ndf_adult_eda.at[df_adult_eda['age'].idxmin(),'age']","ecfbfa7b":"# This distribution plot shows the distribution of Age of people across the Data Set\nplt.rcParams['figure.figsize'] = [12, 8]\nsns.set(style = 'whitegrid')\n\nsns.distplot(df_adult_eda['age'], bins = 90, color = 'mediumslateblue')\nplt.ylabel(\"Distribution\", fontsize = 15)\nplt.xlabel(\"Age\", fontsize = 15)\nplt.margins(x = 0)\n\nprint (\"The maximum age is\", df_adult_eda['age'].max())\nprint (\"The minimum age is\", df_adult_eda['age'].min())","e5ba9950":"# Distribution of Different Features of the Dataset\ndistribution = df_adult_eda.hist(edgecolor = 'black', linewidth = 1.2, color = 'c')\nfig = plt.gcf()\nfig.set_size_inches(12,12)\nplt.show()","cf69ae1c":"# Checking the Difference between the values of the mean and median to get an idea about the amount of outliers\nprint (df_adult_eda['hours.per.week'].median())\nprint (df_adult_eda['hours.per.week'].mean())","e50c0cf0":"# This heatmap shows the Correlation between the different variables\nplt.rcParams['figure.figsize'] = [10,7]\nsns.heatmap(df_adult_eda.corr(), annot = True, color = 'blue', cmap = 'YlGn');","39594e67":"# This shows the hours per week according to the education of the person\nsns.set(rc={'figure.figsize':(12,8)})\nsns_grad = sns.barplot(x = df_adult_eda['education'], y = df_adult_eda['hours.per.week'], data = df_adult_eda)\nplt.setp(sns_grad.get_xticklabels(), rotation=90);","343f6130":"# This bar graph shows the difference of hours per week between male and female \nsns.set(style = 'whitegrid', rc={'figure.figsize':(8,6)})\nsns.barplot(x = df_adult_eda['sex'], y = df_adult_eda['hours.per.week'], data = df_adult_eda,\n            estimator = mean, hue = 'sex', palette = 'winter');","d19689bc":"# Creating Pandas Series for the workclasses whose income is higher than 50K \ndf_ = df_adult_eda.loc[df_adult_eda['income'] == '>50K',['workclass']]\nworkclass_types = df_['workclass'].value_counts()\nlabels = list(workclass_types.index)\naggregate = list(workclass_types)\n\n# This Pie chat shows the Percentage of different workclass who earns more than 50K\nplt.pie(aggregate, labels = labels, autopct='%1.2f%%', shadow=True)\nplt.legend(labels, loc = 'best')\nplt.axis('equal')\nplt.tight_layout()\nplt.show()","a9f31e19":"# Grouping people by their education\neducation_size = df_adult_eda.groupby('education').size()\n\n# Grouping people who earns more than 50K by their education\nmore_income = df_adult_eda.loc[df_adult_eda['income'] == '>50K', ['education']].groupby('education').size()\n\nsns.set(style = 'dark')\nplt.rcParams['figure.figsize'] = [15, 9]\nfig, ax = plt.subplots(1,2)\n\n# Setting axes Labels and Titles\nax[0].set_ylabel(\"Education\")\nax[0].set_xlabel(\"No. of People\")\nax[1].set_xlabel(\"No. of People\")\nax[0].title.set_text(\"People grouped by their Education\")\nax[1].title.set_text(\"People who're earning more than 50K\")\n\n# Barplot for the people grouped by their education\nsns_ed_1 = sns.barplot(x = list(education_size), y = list(education_size.index), palette = 'winter',\n                       order = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'Bachelors', 'Doctorate',\n                                'Assoc-acdm', 'Assoc-voc', 'HS-grad', 'Masters', 'Prof-school', 'Some-college'], ax = ax[0])\n\n# Barplot for the people who earns more than 50K grouped by their education\nsns_ed_2 = sns.barplot(x = list(more_income), y = list(more_income.index), palette = 'winter',\n                       order = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'Bachelors', 'Doctorate',\n                                'Assoc-acdm', 'Assoc-voc', 'HS-grad', 'Masters', 'Prof-school', 'Some-college'], ax = ax[1])\n\n#plt.setp(sns_ed_1.get_xticklabels(), rotation = 90);\n#plt.setp(sns_ed_2.get_xticklabels(), rotation = 90);","6f700833":"df_adult_eda['occupation'].unique()","98ff9cde":"# Grouping people according to their country and their income\ndf_adult_eda_ = df_adult_eda[df_adult_eda['native.country'] != '?']\nnative_more = df_adult_eda_.loc[df_adult_eda_['income'] == '>50K',['native.country']].groupby('native.country').size()\nnative_less = df_adult_eda_.loc[df_adult_eda_['income'] == '<=50K',['native.country']].groupby('native.country').size()\n\nindex_more = list(native_more.index)\nindex_less = list(native_less.index)\n\n# Checking if the Countries in both aspects are same or not\nprint(index_more)\nprint(len(index_more))\nprint(index_less)\nprint(len(index_less))","c1ef0009":"# Checking which Countries are not in the list\n[country for country in index_less if country not in index_more]","8d3ef5b3":"# Making DataFrames of the Data\ndf_more = pd.DataFrame({'Countries' : index_more, '>50K' : list(native_more) })\ndf_less = pd.DataFrame({'Countries' : index_less, '<=50K' : list(native_less) })\n\n# Adding the entries of the missing countries\ndf_more.loc[40] = 'Holand-Netherlands', 0\ndf_more.loc[41] = 'Outlying-US(Guam-USVI-etc)', 0\n\ndf_more","1884e801":"# Merging both the Data Frames to be used for plotting\ndf_fin = pd.merge(df_less, df_more, on = 'Countries')\n\ndf_fin","595c6506":"sns.set(style = 'whitegrid')\nplt.rcParams['figure.figsize'] = [20,10]\n# Dropping the United States Row as there's a disparity between US and other Countries\ndf_fin = df_fin.drop([38])\n\n# This Bar plot shows which country's people after US make more than 50K a year\n\nsns_ = sns.barplot(x = df_fin['Countries'], y = df_fin['>50K'], data = df_fin, palette = 'winter')\nsns_.title.set_text(\"People who're earning more than 50K\")\n\nplt.setp(sns_.get_xticklabels(), rotation = 90);","e2f601a1":"# This Bar plot shows which country's people after US make less than 50K a year\n\nsns__ = sns.barplot(x = df_fin['Countries'], y = df_fin['<=50K'], data = df_fin, palette = 'winter')\nsns__.title.set_text(\"People who're earning less than 50K\")\n\nplt.setp(sns__.get_xticklabels(), rotation = 90);","cd437e4d":"# Setting Parameters\nplt.rcParams['figure.figsize'] = [15,15]\nsns.set(style = 'darkgrid')\n\n# This Violin plot show how capital gain, loss, hours per week and education vary with the race of the people\nplt.subplot(2,2,1)\nsns.violinplot(x = df_adult_eda['race'], y = df_adult_eda['capital.gain'], data = df_adult_eda);\nplt.subplot(2,2,2)\nsns.violinplot(x = df_adult_eda['race'], y = df_adult_eda['capital.loss'], data = df_adult_eda);\nplt.subplot(2,2,3)\nsns.violinplot(x = df_adult_eda['race'], y = df_adult_eda['hours.per.week'], data = df_adult_eda);\nplt.subplot(2,2,4)\nsns.violinplot(x = df_adult_eda['race'], y = df_adult_eda['education.num'], data = df_adult_eda);","1c2e3528":"# Setting Parameters\nplt.rcParams['figure.figsize'] = [15,8]\nfig, ax = plt.subplots(1,2)\n\n# Setting axes Labels and Titles\nax[0].set_ylabel(\"No. of People\")\nax[0].set_xlabel(\"Relationship Status\")\nax[1].set_xlabel(\"Relationship Status\")\nax[0].title.set_text(\"People who're earning less than 50K\")\nax[1].title.set_text(\"People who're earning more than 50K\")\n\n# Grouping people according to their Income and Relationship Status \nrel_less = df_adult_eda.loc[df_adult_eda['income'] == '<=50K',['relationship']].groupby('relationship').size()\nrel_more = df_adult_eda.loc[df_adult_eda['income'] == '>50K',['relationship']].groupby('relationship').size()\n\n# This barplot shows the No.of people earning more or less than 50K according to their Relationship Status\nsns_rel_1 = sns.barplot(x = list(rel_less.index), y = list(rel_less), ax = ax[0])\nsns_rel_2= sns.barplot(x = list(rel_more.index), y = list(rel_more), ax = ax[1])\n\nplt.setp(sns_rel_1.get_xticklabels(), rotation = 60);\nplt.setp(sns_rel_2.get_xticklabels(), rotation = 60);","ee0c9dcf":"# Setting axes Labels and Titles \nfig, ax = plt.subplots(1,2)\nax[0].set_xlabel('Race')\nax[1].set_xlabel('Race')\nax[0].set_ylabel('No. of People')\nax[0].title.set_text(\"People who're earning less than 50K\")\nax[1].title.set_text(\"People who're earning more than 50K\")\n\n# Grouping People according to their race and income\nrace_less = df_adult_eda.loc[df_adult_eda['income'] == '<=50K'].groupby('race').size()\nrace_more = df_adult_eda.loc[df_adult_eda['income'] == '>50K'].groupby('race').size()\n\n# This barplot shows the no.of people earning more or less than 50K according to their races\nsns_race_1 = sns.barplot(x = list(race_less.index), y = list(race_less), ax = ax[0],\n                         order = ['White', 'Black','Asian-Pac-Islander', 'Amer-Indian-Eskimo','Other'])\nsns_race_2 = sns.barplot(x = list(race_more.index), y = list(race_more), ax = ax[1],\n                        order = ['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo','Other'])\n\nplt.setp(sns_race_1.get_xticklabels(), rotation = 90);\nplt.setp(sns_race_2.get_xticklabels(), rotation = 90);","03368b49":"# Copying the eda adult dataFrame and reseting the index\ndf_adult = df_adult_eda.copy()\n\ndf_adult = df_adult.reset_index(drop = True)\ndf_adult.head()","6abcb9db":"df_adult.describe()","c4893dc0":"# Removing the unkown occupations\ndf_adult = df_adult[df_adult.occupation != '?']\n\nprint (df_adult['occupation'].value_counts())","b55e386b":"df_adult.head()","88a39d9b":"# Changing the income column into Numerical Value\ndf_adult['income'] = df_adult['income'].map({'<=50K':0, '>50K':1})","891315c9":"df_adult['income'].value_counts()","81ffa189":"# Changing the Categorical Values to Numerical values using the sklearns Label Encoder\nfrom sklearn.preprocessing import LabelEncoder\n\ncategorical_features = list(df_adult.select_dtypes(include=['object']).columns)\nlabel_encoder_feat = {}\nfor i, feature in enumerate(categorical_features):\n    label_encoder_feat[feature] = LabelEncoder()\n    df_adult[feature] = label_encoder_feat[feature].fit_transform(df_adult[feature])\n\ndf_adult.head()","ca688ee7":"# Shuffling the Data Set\nfrom sklearn.utils import shuffle\ndf_adult = shuffle(df_adult)\n\n# Splitting the data set into train and test set\nfrom sklearn.model_selection import train_test_split\n\nfeatures_ = df_adult.drop(columns = ['income', 'education.num'])\ntarget = df_adult['income']\nX_train, X_test, y_train, y_test = train_test_split(features_, target, test_size = 0.3,random_state = 0)\n\nprint (\"Train data set size : \", X_train.shape)\nprint (\"Test data set size : \", X_test.shape)","756d3445":"# Plotting the feature importances using the Boosted Gradient Descent\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\n# Training the model\nmodel = XGBClassifier()\nmodel_importance = model.fit(X_train, y_train)\n\n# Plotting the Feature importance bar graph\nplt.rcParams['figure.figsize'] = [14,12]\nsns.set(style = 'darkgrid')\nplot_importance(model_importance);","55c34872":"# Training the model_1\nlogistic = LogisticRegression(C = 0.5, max_iter = 500)\nmodel_1 = logistic.fit(X_train, y_train)\n\n# Predictions\npred_1 = model_1.predict(X_test)\n\nprint (\"The accuracy of model 1 : \",accuracy_score(y_test, pred_1))\nprint (\"The f1 score of model 1 : \", f1_score(y_test, pred_1, average = 'binary'))","8124ae4b":"# Training the model_2\nR_forest = RandomForestClassifier(n_estimators = 200)\nmodel_2 = R_forest.fit(X_train, y_train)\n\n# Predictions\npred_2 = model_2.predict(X_test)\n\nprint (\"The accuracy of model 2 : \",accuracy_score(y_test, pred_2))\nprint (\"The f1 score of model 2 : \", f1_score(y_test, pred_2, average = 'binary'))","2ef00025":"# Training the model 3\nboosted_gd = XGBClassifier(learning_rate = 0.35, n_estimator = 500)\nmodel_3 = boosted_gd.fit(X_train, y_train)\n\n# Predictions\npred_3 = model_3.predict(X_test)\n\nprint (\"The accuracy of model 3 : \",accuracy_score(y_test, pred_3))\nprint (\"The f1 score of model 3 : \", f1_score(y_test, pred_3, average = 'binary'))","ec8be8e6":"# Training the model 4\nNB = BernoulliNB(alpha = 0.3)\nmodel_4 = NB.fit(X_train, y_train)\n\n# Predictions\npred_4 = model_4.predict(X_test)\n\nprint (\"The accuracy of model 4 : \",accuracy_score(y_test, pred_4))\nprint (\"The f1 score of model 4 : \", f1_score(y_test, pred_4, average = 'binary'))","a7d6dd46":"# Training the model 5\nsvc = SVC(kernel = 'rbf', max_iter = 1000, probability = True)\nmodel_5 = svc.fit(X_train, y_train)\n\n# Predictions\npred_5 = model_5.predict(X_test)\n\nprint (\"The accuracy of model 5 : \",accuracy_score(y_test, pred_5))\nprint (\"The f1 score of model 5 : \", f1_score(y_test, pred_5, average = 'binary'))","23ec42c6":"list_pred = [pred_1, pred_2, pred_3, pred_4, pred_5]\nmodel_names = [\"Logistic Regression\", \"Random Forest Classifier\", \"Boosted Gradient Descent\", \"Bernoulli NB\", \"SVC\"]\n\nfor i, predictions in enumerate(list_pred) :\n    print (\"Classification Report of \", model_names[i])\n    print ()\n    print (classification_report(y_test, predictions, target_names = [\"<=50K\", \">50K\"]))","f0aa969f":"for i, pred in enumerate(list_pred) :\n    print (\"The Confusion Matrix of : \", model_names[i])\n    print (pd.DataFrame(confusion_matrix(y_test, pred)))\n    print ()","37a523b3":"# ROC Curve for the classification models\n\nmodels = [model_1, model_2, model_3, model_4, model_5]\n\n# Setting the parameters for the ROC Curve\nplt.rcParams['figure.figsize'] = [10,8]\nplt.style.use(\"bmh\")\n\ncolor = ['red', 'blue', 'green', 'fuchsia', 'cyan']\nplt.title(\"ROC CURVE\", fontsize = 15)\nplt.xlabel(\"Specificity\", fontsize = 15)\nplt.ylabel(\"Sensitivity\", fontsize = 15)\ni = 1\n\nfor i, model in enumerate(models) :\n    prob = model.predict_proba(X_test)\n    prob_positive = prob[:,1]\n    fpr, tpr, threshold = roc_curve(y_test, prob_positive)\n    plt.plot(fpr, tpr, color = color[i])\n    plt.gca().legend(model_names, loc = 'lower right', frameon = True)\n\nplt.plot([0,1],[0,1], linestyle = '--', color = 'black')\nplt.show()","7ba97efa":"Model-5 Support Vector Classifier","632e90d5":"## Preprocessing","26d29b06":"Model-1 Logistic Regression","e626ce9b":"Model-3 Boosted Gradient Descent","4324780f":"Model-2 Random Forest Classifier","cdd0b1ad":"#### Consfusion Matrix for the Classifier","e8756821":"#### Classification Reports","dc15ae0f":"## Exploratory Data Analysis","7f6fde91":"## Machine Learning Models","9deb2302":"Model-4 Bernoulli NB","e167b7c5":"## Analysis of the model performances","9d8ef4bc":"The label encoders are saved for each of the feature converted so that they can be decoded at the end. <br>\n -- for feature, encoder in label_encoder_feat.items(): <br>\n    -- df_adult[feature] = encoder.inverse_transform(df_adult[feature])"}}