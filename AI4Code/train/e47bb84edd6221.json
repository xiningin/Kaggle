{"cell_type":{"01387c50":"code","81789528":"code","024603fd":"code","65d3a31f":"code","c85cbfd3":"code","de372125":"code","af3d23f5":"code","cafb6374":"code","8c71b20c":"code","f806d309":"code","570c9fc8":"code","adf97ab1":"code","ef360e4b":"code","18f7ad91":"code","c1763c27":"code","7bb9c4a7":"code","c01e7eb1":"code","b7889dbc":"code","6b85d89a":"code","c786d6ec":"markdown","e1557550":"markdown","b1fb7006":"markdown","682ceb9d":"markdown","8d5b237c":"markdown"},"source":{"01387c50":"from nltk.tokenize import RegexpTokenizer, word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","81789528":"df = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', encoding='ISO-8859-1')\ndf.head()","024603fd":"le = LabelEncoder()","65d3a31f":"data = df.to_numpy() # same as data.values\ndata[0]","c85cbfd3":"X = data[:, 1] # only second col\ny = data[:, 0] # only first col","de372125":"tokenizer = RegexpTokenizer('\\w+') # all the words\nsw = set(stopwords.words('english'))\nps = PorterStemmer()","af3d23f5":"def getStem(review):\n    review = review.lower() # lowercase\n    \n    tokens = tokenizer.tokenize(review) # breaking into small words\n    \n    removed_stopwords = [w for w in tokens if w not in sw]\n    stemmed_words = [ps.stem(token) for token in removed_stopwords]\n    clean_review = ' '.join(stemmed_words)\n    \n    return clean_review","cafb6374":"# get a clean document\ndef getDoc(document):\n    d = []\n    for doc in document:\n        d.append(getStem(doc))\n    return d","8c71b20c":"stemmed_doc = getDoc(X)\nstemmed_doc[:3]","f806d309":"cv = CountVectorizer()","570c9fc8":"# create my vocab\nvc = cv.fit_transform(stemmed_doc)","adf97ab1":"X = vc.todense() # same as to array\nX","ef360e4b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","18f7ad91":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB","c1763c27":"model = MultinomialNB()\nmodel.fit(X_train, y_train)\nans = model.score(X_test, y_test)\nans","7bb9c4a7":"model1 = GaussianNB()\nmodel1.fit(X_train, y_train)\nans1 = model1.score(X_test, y_test)\nans1","c01e7eb1":"model2 = BernoulliNB()\nmodel2.fit(X_train, y_train)\nans2 = model2.score(X_test, y_test)\nans2","b7889dbc":"left = [1,2,3]\nx = ['MultinomialNB','GaussianNB','BernoulliNB']\ny = [ans,ans1,ans2]\nplt.ylim(0.7,1.005)\nplt.title('Comparing Naive Bayes')\nplt.bar(left, y, tick_label = x, width = 0.4, color = ['red', 'green','blue'])","6b85d89a":"print('The best model is MultinomialNB with the accuracy : ',ans * 100)","c786d6ec":"# Processing Data","e1557550":"### Count Vectorizer","b1fb7006":"# Comparing Naive Bayes\n* **Gaussian Naive Bayes classifier**: used when features are not discreet.\n\n* **Multinomial Naive Bayes Classifier**: used when features follow a multinomial distribution.\n\n* **Bernoulli Naive Bayes classifier**: used when features are of the boolean type.","682ceb9d":"#### As we see, Multinomial NB performs the best among the 3 followed closely by Bernoulli NB ","8d5b237c":"### Tokenize and Stemming"}}