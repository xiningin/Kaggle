{"cell_type":{"9db1ec5e":"code","d64693bd":"code","88aec8b3":"code","ccccbd26":"code","fcc48e31":"code","3eae5b2b":"code","2bc91b22":"code","65a380fd":"code","d031043c":"code","7b9e5f43":"code","92968fb3":"code","e25248c6":"code","9cc5ccce":"code","29f43d6a":"code","830bd60a":"code","deb34cfe":"code","cd761ec4":"code","dd5ea7c5":"code","0c80eb32":"code","bb1bca5b":"code","ef2c7bb1":"code","ac66fe01":"code","28bd1ac4":"code","30290cc6":"code","0d7bea5c":"code","fcd0ecf6":"markdown","351d6807":"markdown","aa724146":"markdown","64cf765f":"markdown","9861301c":"markdown","b6c71f18":"markdown","0f9fdcf9":"markdown","327b5b6e":"markdown","6eaefe0f":"markdown","b51d320f":"markdown","8695f71b":"markdown","c4846fd0":"markdown","9cbb20ff":"markdown","1d793a65":"markdown","b7f5b9ba":"markdown"},"source":{"9db1ec5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d64693bd":"pip install TurkishStemmer","88aec8b3":"import pandas as pd\nimport numpy as np\nimport numpy as np\nimport pandas as pd\nimport re  # library for regular expression operations\nimport string  # for string operations\nimport os\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nimport sys\nimport numpy\nfrom nltk.stem import LancasterStemmer\nfrom TurkishStemmer import TurkishStemmer\n\ndef punctiationErasure(doc):\n    return re.sub(r'[^\\w\\s]',' ',doc)\n\ndef nCharfilter(doc,n):\n    rx = r\"\\b\\w{1,%d}\\b\" % (n)\n    return re.sub(rx, '', doc)\n\ndef upperNCharfilter(doc,n):\n    rx=r\"\\b\\w{%d,50}\\b\" % (n)\n    return re.sub(rx, '', doc)\n\ndef removeNumbers(doc):\n    return re.sub(r'[0-9]+', '', doc)\n\ndef removeStopwords(doc,sws):\n    querywords = doc.split()\n    resultwords  = [word for word in querywords if word not in sws]\n    result = ' '.join(resultwords)\n    return result\n\ndef snowballStemmer(doc,language):\n    stemmer = SnowballStemmer(language)\n    querywords = doc.split()\n    resultwords  = [stemmer.stem(word) for word in querywords]\n    return  ' '.join(resultwords)\n\ndef lancaster_Stemmer(doc):\n    stemmer = LancasterStemmer()\n    querywords = doc.split()\n    resultwords  = [stemmer.stem(word) for word in querywords]\n    return  ' '.join(resultwords)\n\ndef turkish_Stemmer(doc):\n    stemmer = TurkishStemmer()\n    querywords = doc.split()\n    resultwords  = [stemmer.stem(word) for word in querywords]\n    return  ' '.join(resultwords)\n","ccccbd26":"df_aday=pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/data_aday_log.csv')\ndf_aday.head()","fcc48e31":"df_aday.jobId.value_counts().describe()","3eae5b2b":"df_aday.jobId.value_counts().hist(bins=100)","2bc91b22":"df_aday.jobseekerId.value_counts()","65a380fd":"df_aday.jobseekerId.value_counts().hist(bins=100)","d031043c":"pd.DataFrame(df_aday.jobId.value_counts()).head(10)","7b9e5f43":"df_cv_det=pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/data_cv_details.csv')\ndf_cv_det.head()","92968fb3":"df_cv_det.jobseekerCity.value_counts()","e25248c6":"df_cv_det.jobseekerLastPosition.value_counts()","9cc5ccce":"df_cv_det.departmentName.value_counts()","29f43d6a":"df_cv_det.totalExperienceYear.describe()","830bd60a":"df_cv_det.totalExperienceYear.hist(bins=25)","deb34cfe":"df_job_det=pd.read_csv('\/kaggle\/input\/datathon-guess-the-last-one\/data_job_details.csv')\ndf_job_det.drop('Unnamed: 0',inplace=True,axis=1)\ndf_job_det.set_index('jobId',inplace=True)\nprint(df_job_det.shape)\ndf_job_det.head()","cd761ec4":"df_job_det.jobPosition.value_counts()","dd5ea7c5":"df_job_det.jobCity.value_counts()","0c80eb32":"df_job_det['Pre1']=df_job_det['jobDescription'].apply(punctiationErasure)\ndf_job_det['Pre2']=df_job_det['Pre1'].apply(nCharfilter,n=2)\ndf_job_det['Pre3']=df_job_det['Pre2'].apply(upperNCharfilter,n=15)\ndf_job_det['Pre4']=df_job_det['Pre3'].apply(removeNumbers)\ndf_job_det['Pre5']=df_job_det['Pre4'].apply(str.lower)\n\nstop_words=set(stopwords.words('turkish'))\nfor stop in ['nbsp','span','span','class','span','span','class','strong','x_msonormal','span','strong','nbsp','lang','strong','class','font','color',\n            'type', 'disc', 'dir', 'ltr' ,'size', 'face' ,'times' ,'new', 'roman']:\n    stop_words.add(stop)\n\ndf_job_det['Pre6']=df_job_det['Pre5'].apply(removeStopwords,sws=stop_words)\ndf_job_det['Pre7']=df_job_det['Pre6'].apply(turkish_Stemmer)\ndf_job_det.head()","bb1bca5b":"from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nTfidf=TfidfVectorizer(min_df = 0.001, max_df = 0.95, #token_pattern = TOKENS_ALPHANUMERIC, \n                ngram_range = (1,1))\n\ndnm=Tfidf.fit(df_job_det['Pre7'])\nvocabulary=dnm.vocabulary_\nidf = dnm.idf_\nvocabulary = sorted(vocabulary.items(), key = lambda x: x[1])\ndictionary = {vocabulary[i][0] : (vocabulary[i][1],idf[i]) for i in range(len(vocabulary))}\n\ndictionary","ef2c7bb1":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndf_job_det['word_list'] = [text.split(' ') for text in df_job_det['Pre7']]\n\nvocabulary = [item for sublist in df_job_det['word_list'] for item in sublist]\ntext = ' '.join(review for review in vocabulary)\n\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stop_words, \n    width=1500, height=750, max_words=500, background_color=\"white\").generate(text)\n\n# generate_from_frequencies generate yerine dene\n\n# Display the generated image:\n# the matplotlib way:\nplt.figure(figsize=[80,40])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\n\nwordcloud.to_file(\"wordcloud.png\")\n\nplt.show()","ac66fe01":"df_word_cloud = pd.Series(wordcloud.words_)\ndf_word_cloud = pd.DataFrame(df_word_cloud)\n\ndf_word_cloud.reset_index(drop = False, inplace =True)\ndf_word_cloud.columns = ['word', 'frequency']\n\ndf_word_cloud.head(20)","28bd1ac4":"tv=TfidfVectorizer(binary=True,norm='l1',\n                  use_idf=False,smooth_idf=False,\n                  min_df=1,max_df=1.0,max_features=500,\n                  ngram_range=(1,1))","30290cc6":"vector_pivot=pd.DataFrame(tv.fit_transform(df_job_det.Pre7).toarray(),columns=tv.get_feature_names())\nvector_pivot","0d7bea5c":"def cos_similarity(textlist):\n    tfidf = tv.fit_transform(textlist)\n    return (tfidf * tfidf.T).toarray()\n\n\ncos_similarity(df_job_det.Pre7[:5])","fcd0ecf6":"Turkish stemmer pek istedi\u011fimizi vermedi. \n'belirleme' 'belirlemek' 'belirlen': 'belirlenen', 'belirlenerek', 'belirlenme', 'belirleyecek' ... Bu kelimelerin k\u00f6klerini bulamam\u0131\u015f\u0131z. Porter stemmer vb farkl\u0131 k\u00f6k bulma y\u00f6ntemleri daha iyi sonu\u00e7 verebilir.","351d6807":"\u0130lan \u015fehirlerin veri \u00f6ni\u015fleme ihtiyac\u0131 bulunuyor. \u0130lan cv benzerli\u011fi gibi metrikler hesaplanacaksa a\u015fa\u011f\u0131daki verileri detayl\u0131 incelemek gerekir","aa724146":"Her ilana Ortalama 50 ki\u015fi ba\u015fvurmu\u015f, 2 bin \u00fczeri ba\u015fvuru alan pop\u00fcler ilanlarda var.","64cf765f":"### Burada farkl\u0131 Doc2vec yakla\u015f\u0131mlar\u0131 uygulanabilir. A\u015fa\u011f\u0131da Cosine sim. uygulamaya \u00e7al\u0131\u015ft\u0131m. Verinin ilk 5 sat\u0131r\u0131 i\u00e7in benzerlik de\u011ferleri a\u015fa\u011f\u0131dad\u0131r","9861301c":"Tf idf vectorizer ile kelime uzay\u0131n\u0131 g\u00f6rselle\u015ftirelim.","b6c71f18":"Adaylara bakt\u0131\u011f\u0131m\u0131z zaman 250 ilana ba\u015fvuran umutsuz arkada\u015flar var :( , \u00c7ok az say\u0131da ba\u015fvuru yapan kullan\u0131c\u0131lar da var.\nBu tarz ki\u015filerin tahminlerinde farkl\u0131 \u015feyler d\u00fc\u015f\u00fcnmek gerekebilir.","0f9fdcf9":"### Free text alan \u00fczerinde yap\u0131lan i\u015flemler;\n### 1. Noktalama i\u015faretlerini temizle\n### 2. karakterden k\u00fc\u00e7\u00fck kelimeleri temizle\n### 3. 15 karakterden b\u00fcy\u00fck kelimeleri temizle\n### 4. N\u00fcmerik de\u011ferleri temizle\n### 5. T\u00fcm kelimeleri k\u00fc\u00e7\u00fck harf'e \u00e7evir\n### 6. Anlam ifade etmeyen kelimeleri \u00e7\u0131kart\n### 7. Kelimelerin k\u00f6klerine inmeye \u00e7al\u0131\u015f","327b5b6e":"Frekans bazl\u0131 inceledi\u011fimizde ilanda ge\u00e7en b\u00f6l\u00fcm bilgisinin parse edilmesi bize fayda sa\u011flayabilir. ","6eaefe0f":"## Text alandan ilanlar\u0131n birbiri ile benzerli\u011fini hesaplayabilmek i\u00e7in bir matris olu\u015ftural\u0131m\n### De\u011fi\u015fken say\u0131s\u0131 artt\u0131r\u0131l\u0131p azalt\u0131labilir.","b51d320f":"# Eda","8695f71b":"Herkese faydas\u0131 olmas\u0131 a\u00e7\u0131s\u0131ndan h\u0131zl\u0131 bir NLP s\u00fcreci i\u015fletmeye \u00e7al\u0131\u015ft\u0131m. Verimsiz yaz\u0131lm\u0131\u015f k\u0131s\u0131mlar olabilir :) \u00d6nerisi olan olursa d\u00fczenleyebiliriz. Vakit bulabilirsem ","c4846fd0":"Beklenildi\u011fi \u00fczere kullan\u0131c\u0131lar\u0131n neredeyse 4\/1 i 1 y\u0131ll\u0131k tecr\u00fcbeye sahip","9cbb20ff":"\u0130lan a\u00e7\u0131klamalar\u0131na bakt\u0131\u011f\u0131m\u0131z zaman ingilizce olan ilanlar\u0131nda oldu\u011funu g\u00f6r\u00fcyoruz. \u0130lgili dili anlay\u0131p ona farkl\u0131 bir yap\u0131 kurgulanabilir. Her i\u015flem a\u015fama a\u015fama farkl\u0131 sahalarda tutup,incelemeye \u00e7al\u0131\u015ft\u0131m. Ara a\u015famalar\u0131n asl\u0131nda bir \u00f6nemi yok.","1d793a65":"Pop\u00fcler top10 ilan. Tahminlerimize g\u00fcvenedi\u011fimiz durumlar i\u00e7in bu liste submit edilebilir.","b7f5b9ba":"9600 farkl\u0131 pozisyon :) E\u011fer filtreleme yap\u0131lacak ise bu pozisyon t\u00fcrlerinin gruplanmas\u0131 i\u015fe yarayabilir. "}}