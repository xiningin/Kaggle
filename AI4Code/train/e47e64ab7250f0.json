{"cell_type":{"22ff096d":"code","78da611a":"code","f39aa105":"code","29a6ee39":"code","5452a506":"code","0895b205":"code","11c0528f":"code","cc539a5a":"code","b42ed074":"code","e2944dfa":"code","2853dd5e":"code","e233ebd3":"code","811aad56":"code","11fd6292":"code","b956d89a":"code","8359e1c2":"code","b41b2710":"code","bc4b78c8":"code","7e1b020d":"code","ed8adbbe":"code","bff93197":"markdown","d3042145":"markdown","2fe01f12":"markdown","7c8d9b2d":"markdown","af5cfd29":"markdown","b800dc50":"markdown","be2b44bf":"markdown","12056fb5":"markdown","e1a017b9":"markdown","1c28ca6e":"markdown","820fdf1b":"markdown"},"source":{"22ff096d":"# loading the necessary libraries\nimport numpy as np\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nimport os\nprint(os.listdir(\"..\/input\"))","78da611a":"# Training\nbs = 64 \/\/2\npath_anno = '..\/input\/aptos2019-blindness-detection\/train.csv'\npath_img = '..\/input\/aptos2019-blindness-detection\/train_images'\n\n# Test dataset\ntpath_anno = '..\/input\/aptos2019-blindness-detection\/test.csv'\ntpath_img = '..\/input\/aptos2019-blindness-detection\/test_images'","f39aa105":"# creating directories and copying the models to those directories\n!mkdir -p \/tmp\/.cache\/torch\/checkpoints\n!cp ..\/input\/resnet50\/resnet50.pth \/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth\n!cp ..\/input\/resnet152\/resnet152.pth \/tmp\/.cache\/torch\/checkpoints\/resnet152-b121ed2d.pth","29a6ee39":"# File names\nfnames = get_image_files(path_img)\nfnames[:5]","5452a506":"# Training images and their labels\ndf = pd.read_csv(path_anno)\ndf.head()","0895b205":"# Test images \ntdf = pd.read_csv(tpath_anno)\ntdf.head()","11c0528f":"test = ImageList.from_df(df = tdf, path = tpath_img, suffix = '.png')\nlen(test)","cc539a5a":"# Since these are microscopic images, I'll turn on random flipping of the images (since there's no really \n# up or down for the images) so the model generalizes well\n\ntfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1, max_warp=0.)","b42ed074":"np.random.seed(42)\nsrc = (ImageList.from_df(path = path_img, df = df, suffix = '.png')\n        .split_by_rand_pct(0.2)\n        .label_from_df(label_delim=None)\n      .add_test(test))","e2944dfa":"data = (src.transform(tfms, size=126)\n        .databunch().normalize(imagenet_stats))","2853dd5e":"data.classes","e233ebd3":"data.show_batch(rows=3, figsize=(7,6))","811aad56":"kappa = KappaScore()\nkappa.weights = \"quadratic\"\n\nlearn = cnn_learner(data, models.resnet50, metrics=[error_rate, kappa], model_dir = Path('..\/kaggle\/working'),\n                   path = Path(\".\"))\n\n# Let's fit a couple of cycles\nlearn.fit_one_cycle(2)\n\n# Now let's find a more accurate learning rate\nlearn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","11fd6292":"# Let's fit some more with a more accurate learning rate\nlearn.fit_one_cycle(8, max_lr=slice(0.01))","b956d89a":"# let's save the model in case, we want to return to this point\nlearn.save('train-1-rn50', return_path = True)","8359e1c2":"# let's see if we can get even a better learning rate from this point on\nlearn.load('train-1-rn50')\n\n# Let's freeze up to last layer group. That is to sets every layer group except the last to untrainable \nlearn.freeze()\n\n# I'll try a smaller learning rate\nlearn.fit_one_cycle(8, max_lr=slice(1e-03))","b41b2710":"data2 = (src.transform(tfms, size= 256)\n        .databunch().normalize(imagenet_stats))","bc4b78c8":"# Replacing data \nlearn.data = data2\n\n# train some more by building on the previous model\nlearn.fit_one_cycle(10)\n\n# Learning rate\nlearn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","7e1b020d":"# choosing a learning rate based on the data \nlearn.fit_one_cycle(10, max_lr = slice(1e-4))","ed8adbbe":"preds, _ = learn.get_preds(ds_type=DatasetType.Test)\npred_prob, pred_class = preds.max(1)\nlen(pred_class)\n\nmy_submission = pd.DataFrame({'id_code': tdf['id_code'] , 'diagnosis': pred_class})\nmy_submission.to_csv('submission.csv', index=False)","bff93197":"## Transformations","d3042145":"## Visualize data","2fe01f12":"Later, I use resnet as the base architecture. However, since we can't use the internet for this kernel in this competition I will set these directories which will contain the models. This is because, `cnn_learner` will check those directories first before attempting to download. When internet for the kernel is turned off and these models don't exist, an error will be raised. To add the models, click on add dataset at the top right corner of this kernel and search for resnet. Make sure to choose resnet for `PyTorch`","7c8d9b2d":"## Loading libraries","af5cfd29":"## Dataset","b800dc50":"Let's replace the data with even a higher size and see ","be2b44bf":"## Fine tuning","12056fb5":"This kernel uses fastai to predict the 5 classes of diabetic retinopathy","e1a017b9":"### Resnet50","1c28ca6e":"## Prediction of test set and submission","820fdf1b":"## Model Training"}}