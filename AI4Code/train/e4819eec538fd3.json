{"cell_type":{"f120e2ba":"code","22c80f7a":"code","f68ef787":"code","93b1cb29":"code","d73dece8":"code","cad2659d":"code","a247b4de":"code","2f2d69e5":"code","ffe02616":"code","e9d8908b":"code","8fb6547a":"code","44397dbf":"code","4e7d9a64":"code","d4e8abde":"code","03807e77":"code","c16b5eef":"code","321d0cdc":"markdown","926d5fd8":"markdown","3f1a2254":"markdown","537611cc":"markdown","ae4ec6ad":"markdown","1b727966":"markdown","7924dc0d":"markdown","a940c916":"markdown","2a4c33c1":"markdown"},"source":{"f120e2ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22c80f7a":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","f68ef787":"!pip install \"torch==1.4\" \"torchvision==0.5.0\"","93b1cb29":"from fastai.vision import *\nfrom fastai.metrics import error_rate","d73dece8":"bs = 64\n# bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart","cad2659d":"path = Path(\"..\/input\/the-simpsons-characters-dataset\/simpsons_dataset\")\npath","a247b4de":"path.ls()","2f2d69e5":"data = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(do_flip=False),size=224,bs=64,train='simpsons_dataset',valid_pct=0.2).normalize(imagenet_stats)","ffe02616":"data.show_batch(rows = 3, figsize=(8,8))","e9d8908b":"print(data.classes)\nlen(data.classes),data.c","8fb6547a":"learn = cnn_learner(data, models.resnet34, metrics=error_rate)","44397dbf":"learn.model","4e7d9a64":"learn.fit_one_cycle(4)","d4e8abde":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","03807e77":"interp.plot_top_losses(9, figsize=(15,11))","c16b5eef":"interp.plot_confusion_matrix(figsize=(15,15), dpi=60)","321d0cdc":"In this particular dataset, labels are stored in the folders names.\n\n* 42 folders, each representing one of the characters.\n* The most popular characters (ie: The Simpson family) each have ~1,000 images, while lesser known characters have ~20\u201330 images.\nTo classify the images into the correct categories, I needed to first extract the labels from the folders names. To do so, I used the factory method [ImageDataBunch.from_folder()](https:\/\/docs.fast.ai\/vision.data.html#ImageDataBunch.from_folder).","926d5fd8":"Downgrading to Torch 1.4 due to compatibility issues","3f1a2254":"We get an accuracy of around 96%","537611cc":"The following lines ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook.","ae4ec6ad":"Checking if the labels were correctly extracted","1b727966":"*The text above each images denotes: the prediction \/ the actual \/ the loss \/ the probability.*\n\nSome of the images were mislabeled due to which this error occured. Plotting the confusion matrix.","7924dc0d":"The confusion matrix traced a diagonal, meaning the model correctly recognized most of the characters, even those of the least popular ones (unbalanced classes), with only 20\u201340 images. This was made possible thanks to a technique called transfer learning.\n\nIndeed, I fitted a model that was pre-trained, meaning it already knew how to recognize images.\n\nWhen I called create_cnn(data, models.resnet34, metrics=error_rate), it loaded a pre-trained resnet34 model which had already been trained to classify 1.5mn pictures across 1,000 different categories of objects (ie: plants, animals, people\u2026)","a940c916":"We will use fast.ai methodology and train our model. We will use a [convolutional neural network](http:\/\/http:\/\/cs231n.github.io\/convolutional-networks\/) backbone and a fully connected head with a single hidden layer as a classifier.\n\nWe will train for 4 epochs (4 cycles through all our data).","2a4c33c1":"Let's see what results we have got.\n\nWe will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly.\n\nFurthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour."}}