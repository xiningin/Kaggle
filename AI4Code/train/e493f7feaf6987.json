{"cell_type":{"97ddf853":"code","43f4df0d":"code","e586f92a":"code","ae668088":"code","94ac965a":"code","46616477":"code","8c3981b9":"code","19650751":"code","50a31615":"code","8fb53690":"markdown","c2c986a4":"markdown","f7347f7f":"markdown","5b7e0981":"markdown","3f354b9e":"markdown","67d38901":"markdown"},"source":{"97ddf853":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","43f4df0d":"def n_deg_poly(data,degree_poly):\n  x=data[['x']]\n  X = np.c_[np.ones((len(x),1)),x]\n  for i in range(2,degree_poly+1):\n    X=np.c_[X,x**i]\n  return X","e586f92a":" def predict(X,theta):\n   return np.dot(X,theta)","ae668088":"def mse(y_predicted,y):\n  return ((y_predicted-y)**2).mean()","94ac965a":"def closed_form(X,y):\n  return np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)","46616477":"def stochastic_gradient(X,y,learning_rate,num_iterations,mini_batch_size):\n  theta = np.random.rand(np.size(X,axis=1),1)\n  data1=np.c_[X,y]\n  theta_vec=pd.DataFrame()\n  for iteration in range(num_iterations):\n    sample = np.random.default_rng().choice(data1,replace=False ,size = mini_batch_size)\n    sample_X = pd.DataFrame(sample[:,:-1])\n    sample_y = pd.DataFrame(sample[:,-1])\n    theta = theta - learning_rate*np.dot(sample_X.T,((np.dot(sample_X,theta))-sample_y))\n    theta_vec=theta_vec.append(theta.tolist())\n  return theta, theta_vec","8c3981b9":"train_data =pd.read_csv('..\/input\/test-and-train-data\/train_data.csv')\ntest_data=pd.read_csv('..\/input\/test-and-train-data\/test_data.csv')\nX_train=n_deg_poly(train_data,1)\nX_test=n_deg_poly(test_data,1)\ny_train=train_data[['y']]\ny_test=test_data[['y']]\ntheta=closed_form(X_train,y_train)\nprint(theta)\ny_predicted=predict(X_test,theta)\ny_predicted_train=predict(X_train,theta)\nerror=mse(y_predicted,y_test) # test-error #1C implementation\ntrain_error= mse(y_predicted_train,y_train)#train-error #1C implementation\nerror=mse(y_predicted,y_test)\nprint(\"Error For Closed-Form, test: \",error,\"\\n train:\",train_error)","19650751":"plt.scatter(train_data[['x']],train_data[['y']],s=20,color=\"black\")\nplt.plot(test_data[['x']],y_predicted)\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.title(\"Linear Regression Plot\")","50a31615":"theta, theta_vec=stochastic_gradient(X_train,y_train,0.0001,100,10)\ny_predicted=predict(X_test,theta)\ny_predicted_train=predict(X_train,theta)\nerror=mse(y_predicted,y_test) # test-error #1C implementation\ntrain_error= mse(y_predicted_train,y_train)#train-error #1C implementation\nprint(\"Error for Stochastic-Gradient, Test: \",error, \"\\n Train:\",train_error)","8fb53690":"Linear Regression through Mini Batch Stochastic Gradient Descent","c2c986a4":" STOCHASTIC GRADIENT DESCENT","f7347f7f":"PREDICT FUNCTION","5b7e0981":" CLOSED FORM SOLUTION","3f354b9e":"MEAN SQUARE ERROR\/COST","67d38901":"Linear Regression through Closed Form Solution"}}