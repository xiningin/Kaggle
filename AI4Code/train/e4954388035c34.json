{"cell_type":{"ca1120f3":"code","f06c0f16":"code","f2d3c08e":"code","69c7d926":"code","1f986310":"code","f6d97685":"code","e9ab2d4d":"code","c9332424":"code","8339672e":"code","3bd9e4f9":"code","e5158f28":"code","6619b625":"code","db3e261a":"code","1a9e2cb8":"code","ee510b43":"code","6271f48a":"code","f6bba447":"code","619d3ff2":"code","ca2b59a0":"code","a40dafe6":"code","a924093e":"code","5339fd5b":"code","17f2ae2d":"code","6cbaef1e":"code","32d80b70":"code","a200eadb":"code","5fd59650":"code","22b53064":"code","c2528ba4":"code","8590ab9d":"code","1e270eda":"code","79376347":"code","12d287f0":"code","ad66d6ac":"code","cf0d4e69":"code","f6d363a3":"code","90d7b91e":"code","cf620500":"code","563695fa":"code","fa31d6bd":"code","d7d2164e":"code","c3149e67":"code","95210d76":"code","56cc4735":"code","167308e8":"code","9138d17e":"code","c1209775":"code","292a5393":"code","508057e9":"code","cb8885e1":"code","58f023ac":"code","c59e965b":"code","1edaf019":"code","ee7fdacd":"code","6df20a01":"code","f1c70e84":"code","5ae400c6":"code","069f3a06":"code","5e94fe06":"code","8952796e":"markdown","761018f1":"markdown","6e01d8ef":"markdown","888c97f0":"markdown","32ceb923":"markdown","09e91b1d":"markdown","bf4dbda5":"markdown","db8f76c4":"markdown"},"source":{"ca1120f3":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n%matplotlib inline  \nfrom sklearn.model_selection import StratifiedKFold\nfrom joblib import load, dump\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom torchvision import models as md\nfrom torch import nn\nfrom torch.nn import functional as F\nimport re\nimport math\nimport collections\nfrom functools import partial\nfrom torch.utils import model_zoo\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","f06c0f16":"package_path = '..\/input\/efficientnet\/efficientnet-pytorch\/EfficientNet-PyTorch\/'\nsys.path.append(package_path)\n\nfrom efficientnet_pytorch import EfficientNet","f2d3c08e":"#making model\n# md_ef = EfficientNet.from_pretrained('efficientnet-b5', num_classes=1)\n\nnum_classes = 1\n\nmd_ef = EfficientNet.from_name('efficientnet-b5')\nmd_ef.load_state_dict(torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b5-586e6cc6.pth'))\nin_features = md_ef._fc.in_features\nmd_ef._fc = nn.Linear(in_features, num_classes)\nmd_ef.cuda()","69c7d926":"#copying weighst to the local directory \n!mkdir models\n!cp '..\/input\/kaggle-public\/abcdef.pth' 'models'","1f986310":"def get_df():\n    base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\n    train_dir = os.path.join(base_image_dir,'train_images\/')\n    df = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\n    df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n    df = df.drop(columns=['id_code'])\n    df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    test_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\n    return df, test_df\n\ndf, test_df = get_df()","f6d97685":"#you can play around with tfms and image sizes\nbs = 64\nsz = 224\ntfms = get_transforms(do_flip=True,flip_vert=True)","e9ab2d4d":"data = (ImageList.from_df(df=df,path='.\/',cols='path') \n        .split_by_rand_pct(0.2) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(tfms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=bs,num_workers=4) \n        .normalize(imagenet_stats)  \n       )","c9332424":"def qk(y_pred, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_pred), y, weights='quadratic'), device='cuda:0')","8339672e":"learn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '..\/input\/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\n\n","3bd9e4f9":"learn.load('abcdef');","e5158f28":"#https:\/\/www.kaggle.com\/abhishek\/optimizer-for-quadratic-weighted-kappa\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","6619b625":"def run_subm(learn=learn, coefficients=[0.5, 1.5, 2.5, 3.5]):\n    opt = OptimizedRounder()\n    preds,y = learn.get_preds(DatasetType.Test)\n    tst_pred = opt.predict(preds, coefficients)\n    tst_pred = tst_pred.astype(int)\n    return tst_pred","db3e261a":"preds1 = run_subm()","1a9e2cb8":"import sys\npackage_dir = \"..\/input\/pretrained-models\/pretrained-models\/pretrained-models.pytorch-master\/\"\nsys.path.insert(0, package_dir)\nimport numpy as np\nimport pandas as pd\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nfrom torchvision import transforms\nimport os\nimport pretrainedmodels\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","ee510b43":"class RetinopathyDatasetTest(Dataset):\n    def __init__(self, csv_file, transform):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join('..\/input\/aptos2019-blindness-detection\/test_images', self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n        image = self.transform(image)\n        return {'image': image}","6271f48a":"model = pretrainedmodels.__dict__['resnet101'](pretrained=None)\n\nmodel.avg_pool = nn.AdaptiveAvgPool2d(1)\nmodel.last_linear = nn.Sequential(\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.25),\n                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n                          nn.ReLU(),\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(in_features=2048, out_features=1, bias=True),\n                         )\nmodel.load_state_dict(torch.load(\"..\/input\/mmmodel\/model.bin\"))\nmodel = model.to(device)","f6bba447":"for param in model.parameters():\n    param.requires_grad = False\n\nmodel.eval()","619d3ff2":"test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_dataset = RetinopathyDatasetTest(csv_file='..\/input\/aptos2019-blindness-detection\/sample_submission.csv',\n                                      transform=test_transform)","ca2b59a0":"def tta(test_dataset, batch_size=32, shuffle=False, num_workers=4):\n    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n    test_preds = np.zeros((len(test_dataset), 1))\n    tk = tqdm(test_data_loader)\n    \n    for i, x_batch in enumerate(tk):\n        x_batch = x_batch['image']\n        pred = model(x_batch.to(device))\n        test_preds[i*32:(i+1)*32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n    \n    return test_preds","a40dafe6":"for i in range(1, 6):\n    locals()['test_preds{}'.format(i)] = tta(test_dataset) ","a924093e":"preds2 = (test_preds1 + test_preds2 + test_preds3 + test_preds4 + test_preds5) \/ 5.0","5339fd5b":"coef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(preds2):\n    if pred < coef[0]:\n        preds2[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        preds2[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        preds2[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        preds2[i] = 3\n    else:\n        preds2[i] = 4","17f2ae2d":"import cv2\nimport matplotlib.pyplot as plt\nfrom os.path import isfile\n# import torch.nn.init as init\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd \nimport os\nfrom PIL import Image\n# from PIL import ImageFilter\n# print(os.listdir(\"..\/input\"))\n# from sklearn.model_selection import train_test_split, StratifiedKFold\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n# from torch.optim import Adam, SGD, RMSprop\nimport time\n# from torch.autograd import Variable\n# import torch.functional as F\nfrom tqdm import tqdm\n# from sklearn import metrics\n# import urllib\n# import pickle\n# from torchvision import models\n# import seaborn as sns\nimport random\nimport sys","6cbaef1e":"package_path = '..\/input\/efficientnet\/efficientnet-pytorch\/EfficientNet-PyTorch\/'\nsys.path.append(package_path)","32d80b70":"## EfficientNet\u662f\u8c37\u6b4c\u5f00\u6e90\u7684\u65b0\u6a21\u578b\u3002\nfrom efficientnet_pytorch import EfficientNet","a200eadb":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","5fd59650":"seed_everything(1234)\nTTA         = 5\nnum_classes = 1\nIMG_SIZE    = 384","22b53064":"test = '..\/input\/aptos2019-blindness-detection\/test_images\/'","c2528ba4":"def expand_path(p):\n    p = str(p)\n    if isfile(test + p + \".png\"):\n        return test + (p + \".png\")\n    return p","8590ab9d":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img","1e270eda":"class MyDataset(Dataset):\n    \n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        label = self.df.diagnosis.values[idx]\n        label = np.expand_dims(label, -1)\n        \n        p = self.df.id_code.values[idx]\n        p_path = expand_path(p)\n        image = cv2.imread(p_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = crop_image_from_gray(image)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 30) ,-4 ,128)\n        image = transforms.ToPILImage()(image)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","79376347":"test_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation((-120, 120)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ntestset        = MyDataset(pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv'), \n                 transform=test_transform)\ntest_loader    = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False)","12d287f0":"model = EfficientNet.from_name('efficientnet-b0')\nin_features = model._fc.in_features\nmodel._fc = nn.Linear(in_features, num_classes)\nmodel.load_state_dict(torch.load('..\/input\/enet0802\/weight_best_0802.pt'))\nmodel.cuda()","ad66d6ac":"for param in model.parameters():\n    param.requires_grad = False","cf0d4e69":"sample = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')","f6d363a3":"%%time\ntest_pred = np.zeros((len(sample), 1))\nmodel.eval()\n\nfor _ in range(TTA):\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(test_loader)):\n            images, _ = data\n            images = images.cuda()\n            pred = model(images)\n            test_pred[i * 16:(i + 1) * 16] += pred.detach().cpu().squeeze().numpy().reshape(-1, 1)\n        \noutput = test_pred \/ TTA","90d7b91e":"coef = [0.57, 1.37, 2.57, 3.57]\n\nfor i, pred in enumerate(output):\n    if pred < coef[0]:\n        output[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        output[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        output[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        output[i] = 3\n    else:\n        output[i] = 4\n        \npreds3 = output","cf620500":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate)\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nfrom keras.models import load_model\nimport keras\nfrom keras.models import Model\n\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\n#from keras.applications.resnet50 import preprocess_input\nfrom keras.applications.densenet import DenseNet121,DenseNet169\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\nfrom keras.utils import Sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport imgaug as ia\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 300\nNUM_CLASSES = 5","563695fa":"df_test = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')","fa31d6bd":"def create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = DenseNet121(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    base_model.load_weights(\"..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5\")\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n    model = Model(input_tensor, final_output) \n    return model","d7d2164e":"submit = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\n\nmodel = load_model('..\/input\/densenet_v2_0817_2\/densenet_v2_0817_2.h5')\npreds4 = []","c3149e67":"# reference:https:\/\/www.kaggle.com\/CVxTz\/cnn-starter-nasnet-mobile-0-9709-lb \nfor i, name in tqdm(enumerate(submit['id_code']), total=len(submit)):\n    path = os.path.join('..\/input\/aptos2019-blindness-detection\/test_images\/', name+'.png')\n    image = cv2.imread(path)\n    image = cv2.resize(image, (SIZE, SIZE))\n    X = np.array((image[np.newaxis])\/255)\n    score_predict=((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n    label_predict = np.argmax(score_predict)\n    preds4.append(label_predict)\n\npreds4 = np.array(preds4) ","95210d76":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","56cc4735":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport scipy as sp\n\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nfrom fastai.callbacks import *\n\nimport PIL\nimport cv2","167308e8":"# Set seed for all\ndef seed_everything(seed=1358):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()","9138d17e":"PATH = Path('..\/input\/aptos2019-blindness-detection')\n\ndf = pd.read_csv(PATH\/'train.csv')","c1209775":"!ls ..\/input\/resnet50\/","292a5393":"# copy pretrained weights for resnet50 to the folder fastai will search by default\nPath('\/tmp\/.cache\/torch\/checkpoints\/').mkdir(exist_ok=True, parents=True)\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'\n\n#copying weighst to the local directory \n!mkdir kaggle\n!cp '..\/input\/resnet50-0823\/resnet50_0823.pth' '\/kaggle\/'","508057e9":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","cb8885e1":"IMG_SIZE = 512\n\ndef _load_format(path, convert_mode, after_open)->Image:\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), 10) ,-4 ,128)\n                    \n    return Image(pil2tensor(image, np.float32).div_(255)) #return fastai Image format\n\nvision.data.open_image = _load_format\n    \nsrc = (\n    ImageList.from_df(df,PATH,folder='train_images',suffix='.png')\n        .split_by_rand_pct(0.2, seed=42)\n        .label_from_df(cols='diagnosis',label_cls=FloatList)    \n    )","58f023ac":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0, max_lighting=0.2)","c59e965b":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","1edaf019":"sample_df = pd.read_csv(PATH\/'sample_submission.csv')\nsample_df.head()","ee7fdacd":"# Definition of Quadratic Kappa\nfrom sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')\n\ndata = (\n    src.transform(tfms,size=224)\n    .databunch()\n    .normalize(imagenet_stats)\n)\n\nlearn = cnn_learner(data, base_arch=models.resnet50 ,metrics=[quadratic_kappa],model_dir='\/kaggle',pretrained=True)\nlearn.data.add_test(ImageList.from_df(sample_df,PATH,folder='test_images',suffix='.png'))\nlearn.load('resnet50_0823')","6df20a01":"preds,y = learn.get_preds(DatasetType.Test)","f1c70e84":"optR = OptimizedRounder()\n\ncoefficients = [0.563203, 1.400153, 2.43412,  3.439786]\ntest_predictions = optR.predict(preds, coefficients)","5ae400c6":"preds5 = test_predictions.astype(int)","069f3a06":"preds1 = preds1.flatten()\npreds2 = preds2.flatten()\npreds3 = preds3.flatten()\npreds4 = preds4.flatten()\npreds5 = preds5.flatten()","5e94fe06":"score = [0.783, 0.750, 0.783, 0.741, 0.738]\nweight = [0.23, 0.195, 0.23, 0.175, 0.170]\npredsData = weight[0]*preds1 + weight[1]*preds2 + weight[2]*preds3 + weight[3]*preds4 + weight[4]*preds5\n\ncoef = [0.5, 1.5, 2.5, 3.5]\nfor i, pred in enumerate(predsData):\n    if pred < coef[0]:\n        predsData[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        predsData[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        predsData[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        predsData[i] = 3\n    else:\n        predsData[i] = 4\nsubmission = pd.read_csv(\"..\/input\/aptos2019-blindness-detection\/sample_submission.csv\")\nsubmission.diagnosis = predsData.astype(int)\nsubmission.to_csv('submission.csv', index=False)","8952796e":"# ResNet50","761018f1":"# Resnet101","6e01d8ef":"Try to fit model here:\n> learn.fit_one_cycle(10, 1e-3)","888c97f0":"# Ensemble","32ceb923":"Just vote from these models below:\n- **EfficientNet v1 by pytorch:**  \n  Eye -- EfficientNet Pytorch[LB 0.777] written by Chanhu  \n  https:\/\/www.kaggle.com\/chanhu\/eye-efficientnet-pytorch-lb-0-777\n    \n- **EfficientNet v2 by fastai: **   \n  Starter kernel for > 0.79  \n  https:\/\/www.kaggle.com\/drhabib\/starter-kernel-for-0-79\n\n- **Resnet101 by pytorch:**  \n  very simple pytorch training [0.59+] written by Abhishek Thakur  \n  https:\/\/www.kaggle.com\/abhishek\/very-simple-pytorch-training-0-59\n\n- **DenseNet by keras: **   \n  APTOS 2019: DenseNet Keras Starter  \n  https:\/\/www.kaggle.com\/xhlulu\/aptos-2019-densenet-keras-starter\n    \n- **Resnet50 by fastai:  **  \n  fast.ai starter with ResNet 50 written by Anna Novikova  \n  https:\/\/www.kaggle.com\/demonplus\/fast-ai-starter-with-resnet-50\n\n\nAnd about the voting code, I learned it from here and did some changes:  \n- **aptos_Vote**    \nhttps:\/\/www.kaggle.com\/ahoukang\/aptos-vote","09e91b1d":"# EfficientNet_v2","bf4dbda5":"# DesNet v2","db8f76c4":"# EfficientNet v1"}}