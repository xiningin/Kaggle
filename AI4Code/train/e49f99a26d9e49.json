{"cell_type":{"f9004b3a":"code","55407fff":"code","c960f0c4":"code","6bccf79f":"code","3d40f165":"code","b17ea4c7":"code","7b32d1a3":"code","a590d196":"code","fb0151fe":"code","c519266f":"code","9f6c5a23":"code","af5ee521":"code","80d3e518":"code","7cb06d8a":"code","832a1c2e":"code","5f575d40":"code","66ba6875":"code","4a17fa17":"code","13476a27":"code","867bd238":"code","b8088736":"code","6fb10382":"code","799372ba":"code","2276cdda":"code","5bf9ebae":"code","916110d9":"code","f552595a":"code","576c47e7":"code","85009a73":"code","e2c315a5":"code","ee9b39ff":"code","c1a53403":"code","50df8215":"code","39b0e893":"code","7da7d32d":"code","747f0907":"code","3b72423a":"code","51187313":"code","d8b58c26":"code","6bbe2f65":"code","2e0d2414":"code","8cb96006":"code","4cc4218a":"code","dd27df0e":"code","29f53ae3":"code","f9a16e54":"code","b333b799":"code","e11e96ba":"code","e66948d8":"code","79b4bd74":"code","a0738977":"code","0f9d6849":"code","f3180ba6":"code","d2564a64":"code","232393d6":"code","42596119":"code","fe4b506c":"code","37fa839f":"code","758bb260":"code","6489a1d4":"code","ca1b6d4d":"code","e4c1b440":"code","215c575c":"markdown","f5baf1db":"markdown","f1444f83":"markdown","dbfe9fba":"markdown","d9a1af4a":"markdown","a7ff9f0e":"markdown","3c9ac41c":"markdown","55c842e1":"markdown","15c22c16":"markdown","f0a55c9f":"markdown","c4eb024f":"markdown","7066f901":"markdown","f72ba140":"markdown","d3c51124":"markdown","8372775f":"markdown","748681ef":"markdown","8323ba97":"markdown","fc2686c5":"markdown","4bd53346":"markdown","5d49d3e6":"markdown","ff2cae7d":"markdown","7c8d6271":"markdown","f6665e8d":"markdown","3ea22b55":"markdown","6e240947":"markdown","aa5514de":"markdown","e97b8622":"markdown","1948a5d9":"markdown","614000dd":"markdown","3d2cbdd5":"markdown","52f42913":"markdown","456fa2bb":"markdown","ffcafa7a":"markdown","464e9fb9":"markdown","692e7195":"markdown","669e357a":"markdown","d10386a2":"markdown"},"source":{"f9004b3a":"import keras\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use(style='ggplot')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nimport seaborn as sns","55407fff":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","c960f0c4":"print (\"Train data shape:\", train.shape)\nprint (\"Test data shape:\", test.shape)","6bccf79f":"pd.set_option('display.max_columns', None)\ntrain.head(5)","3d40f165":"# know more about our prices range\ntrain.SalePrice.describe()","b17ea4c7":"print (\"Skew is:\", train.SalePrice.skew())\nsns.displot(train.SalePrice, kde=True)\nplt.show()","7b32d1a3":"target = np.log1p(train.SalePrice)\nprint (\"Skew is:\", target.skew())\nsns.displot(target, kde=True)\nplt.show()","a590d196":"train_numeric = train._get_numeric_data()\ntest_numeric = test._get_numeric_data()","fb0151fe":"train_numeric","c519266f":"train['LotFrontage'].hist()","9f6c5a23":"train['GarageYrBlt'].hist()","af5ee521":"train['MasVnrArea'].hist()","80d3e518":"train_numeric_cols = train_numeric.columns\ntest_numeric_cols = test_numeric.columns","7cb06d8a":"train[train_numeric_cols] = train[train_numeric_cols].fillna(train_numeric.median())\ntest[test_numeric_cols] = test[test_numeric_cols].fillna(train_numeric.median())","832a1c2e":"# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler()\n# train[train_numeric_cols] = scaler.fit_transform(train[train_numeric_cols])\n\n# test[test_numeric_cols] = scaler.fit_transform(test[test_numeric_cols])","5f575d40":"train_ID = train_numeric['Id']\ntest_ID = test_numeric['Id']","66ba6875":"train_target = train.SalePrice","4a17fa17":"train.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)","13476a27":"y = np.log1p(train.SalePrice)\nX = train.drop(['SalePrice'], axis=1)","867bd238":"ntrain = train.shape[0]\nntest = test.shape[0]\nall_data = pd.concat((X, test)).reset_index(drop=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","b8088736":"all_data_nulls = (all_data.isnull().sum() \/ len(all_data)) * 100\nall_data_nulls = all_data_nulls.drop(all_data_nulls[all_data_nulls == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_nulls})\nmissing_data.head(20)","6fb10382":"all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")","799372ba":"for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')","2276cdda":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)","5bf9ebae":"all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))","916110d9":"for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')","f552595a":"all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)","576c47e7":"# fill with most frequent data\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])","85009a73":"all_data = all_data.drop(['Utilities'], axis=1)","e2c315a5":"# NA means Typ\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")","ee9b39ff":"all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])","c1a53403":"#Check remaining missing values if any \nall_data_na = (all_data.isnull().sum() \/ len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","50df8215":"#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","39b0e893":"from sklearn.preprocessing import LabelEncoder\n\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n","7da7d32d":"# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))","747f0907":"all_data = pd.get_dummies(all_data)\nprint(all_data.shape)","3b72423a":"train = all_data[:ntrain]\ntest = all_data[ntrain:]","51187313":"# X.shape\n# y.shape","d8b58c26":"# mean = train.mean(axis=0)\n# train -= mean\n# std = train.std(axis=0)\n# train \/= std\n\n# test -= mean\n# test \/= std","6bbe2f65":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.20, random_state=42)","2e0d2414":"from keras import models\nfrom keras import layers\nfrom keras import metrics\n\ndef build_model():\n    # Because we will need to instantiate\n    # the same model multiple times,\n    # we use a function to construct it.\n    model = models.Sequential()\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='adam', loss='mse', metrics=[keras.metrics.RootMeanSquaredError()])\n    return model","8cb96006":"# Get a fresh, compiled model.\nnn_model = build_model()\n# Train it on the entirety of the data.\nnn_model.fit(X_train, y_train,\n          epochs=200, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = nn_model.evaluate(X_test, y_test)","4cc4218a":"test_mae_score","dd27df0e":"from sklearn import linear_model\nlr = linear_model.LinearRegression()\nlr_model = lr.fit(X_train, y_train)","29f53ae3":"from sklearn.metrics import mean_squared_error\nprediction = lr_model.predict(X_test)\n\nprint (\"R^2 is:\", lr_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","f9a16e54":"sgd_reg = linear_model.SGDRegressor(penalty=None, alpha=1, max_iter=50, \n                                    early_stopping=False, learning_rate='invscaling', \n                                    eta0=0.01)\nsgd_reg_model = sgd_reg.fit(X_train, y_train)","b333b799":"prediction = sgd_reg_model.predict(X_test)\n\nprint (\"R^2 is:\", sgd_reg_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","e11e96ba":"sgd_reg.intercept_, sgd_reg.coef_","e66948d8":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\nlasso = make_pipeline(RobustScaler(), linear_model.Lasso(alpha =0.0005, random_state=42))","79b4bd74":"lasso_model = lasso.fit(X_train, y_train)\nprediction = lasso_model.predict(X_test)\nprint (\"R^2 is:\", lasso_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","a0738977":"ridge = linear_model.Ridge(alpha=1.0)","0f9d6849":"ridge_model = ridge.fit(X_train, y_train)\nprediction = ridge_model.predict(X_test)\nprint (\"R^2 is:\", ridge_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","f3180ba6":"elastic = linear_model.ElasticNet(l1_ratio=0.001)","d2564a64":"elastic_model = elastic.fit(X_train, y_train)\nprediction = elastic_model.predict(X_test)\nprint (\"R^2 is:\", elastic_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","232393d6":"from sklearn import svm\n\nsvr = svm.SVR()","42596119":"svm_model = svr.fit(X_train, y_train)\nprediction = svm_model.predict(X_test)\nprint (\"R^2 is:\", svm_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","fe4b506c":"poly_svm = svm.SVR(kernel='poly')","37fa839f":"poly_svm_model = poly_svm.fit(X_train, y_train)\nprediction = poly_svm_model.predict(X_test)\nprint (\"R^2 is:\", poly_svm_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","758bb260":"rbf_svm = svm.SVR(kernel='rbf')","6489a1d4":"rbf_svm_model = rbf_svm.fit(X_train, y_train)\nprediction = rbf_svm_model.predict(X_test)\nprint (\"R^2 is:\", rbf_svm_model.score(X_test, y_test))\nprint ('RMSE is:', mean_squared_error(y_test, prediction))","ca1b6d4d":"submission = pd.DataFrame()\nsubmission['Id'] = test_ID\n\nprediction = lasso_model.predict(test)\nfinal_predictions = np.exp(prediction)","e4c1b440":"submission['SalePrice'] = final_predictions\nsubmission.to_csv('submission1.csv', index=False)","215c575c":"## Elastic Regression","f5baf1db":"Split train and data test again","f1444f83":"Prices are right skewed","dbfe9fba":"## Kernel SVM","d9a1af4a":"Label encode the other categorical variables","a7ff9f0e":"## Lasso Regression","3c9ac41c":"Impute missing and no basement values in dataset.","55c842e1":"## Linear SVM ","15c22c16":"Check remaining missing data","f0a55c9f":"### rbf","c4eb024f":"Utilities has only one value for all rows so it wont help in the model.","7066f901":"After preparing data, we will try some models on it and choose the one with most minimum error.","f72ba140":"## NN with Keras","d3c51124":"## Model Preparation\n","8372775f":"Fill LotFrontage with median as houses in same area have similar frontages. ","748681ef":"## Linear Regression ","8323ba97":"### Check for Skewness ","fc2686c5":"For garage data, replace missing with none","4bd53346":"* So, PoolQC has the majority of nulls which makes sense. \n    Most of houses have no swimming pool. \n* Na in fields like PoolQC, MiscFeature, Alley, Fence and FireplaceQu means that house has none of them. \n","5d49d3e6":"and for the cars data, 0 means no cars in garage","ff2cae7d":"# Handling Missing Data","7c8d6271":"#### Check Missing Categorical Data","f6665e8d":"# Encoding","3ea22b55":"Transform ordinal features to numerical","6e240947":"Apply one hot encoding for all values","aa5514de":"### Check for null values ","e97b8622":"## SGD Regressor","1948a5d9":"MasVnrArea and MasVnrType : NA most likely means no masonry veneer for these houses. We can fill 0 for the area and None for the type.\n","614000dd":"# Submission","3d2cbdd5":"# Data Exploration","52f42913":"# Modeling","456fa2bb":"Fill all other values with the mode","ffcafa7a":"#### Drop id and target Columns","464e9fb9":"#### Apply minMaxScalar to numerical columns","692e7195":"Combine both train and test dataset to see all missing ","669e357a":"### Poly","d10386a2":"## Ridge Regression"}}