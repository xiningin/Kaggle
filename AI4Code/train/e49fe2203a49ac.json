{"cell_type":{"0d9a77d2":"code","37f53a79":"code","2b0f25d2":"code","bd35e359":"code","ea9a00e3":"code","59beae42":"code","16ac9fbb":"code","36cd0738":"code","6301da4e":"code","17020a25":"code","2763cffc":"code","af8c15a3":"code","31c45d62":"code","79d34a39":"code","24c53cc2":"code","696b175f":"code","46a4eccf":"code","73c7c794":"code","4fb44c6a":"code","4c3f8e1e":"code","fab43136":"code","7518ca78":"code","0aa84a3a":"code","0406894e":"code","87e9701f":"code","5c79d30a":"code","f6a7d1be":"code","22e69ea2":"code","b6339010":"code","3c35f608":"code","c975a988":"code","a8348a04":"code","7fef7e69":"code","f56d9162":"code","4fc48f01":"code","9d63b351":"code","7d130675":"code","c4734b01":"code","48b432be":"code","b4eb63e6":"code","5f1346ba":"code","87c2437d":"code","e71281fd":"code","4f8bb06e":"code","8aca0879":"code","3f9b19ec":"code","ba4317eb":"code","efe8e514":"code","1e45d6ea":"code","ee3be133":"code","fcf7a72f":"code","55a6ff9a":"code","9813b180":"code","4fcefc45":"code","6a059e07":"code","b5afe464":"code","07c40a82":"markdown","f488f0cd":"markdown","826aaaf2":"markdown","6085c83f":"markdown","3a7373c0":"markdown","98c35fc4":"markdown","43f9e21e":"markdown","1e5dc06b":"markdown","70dcfd47":"markdown","be6cfe48":"markdown","c899dd56":"markdown","7cd2d599":"markdown","7b321ac0":"markdown","9747bf40":"markdown","5442d07b":"markdown","8875d417":"markdown","c892d3d1":"markdown","fed5098e":"markdown","dc5b87e8":"markdown","a752d7e9":"markdown","20503aa9":"markdown","f531b3b6":"markdown","a1bb0de6":"markdown","a7170266":"markdown","5abb47eb":"markdown","3d35eb0e":"markdown","f8516729":"markdown","997d0ccc":"markdown","4be8418c":"markdown","a4fd909d":"markdown","8953a460":"markdown","094494cd":"markdown","7f09ef8d":"markdown","e4eda834":"markdown","f9ddd33a":"markdown","e56e9b11":"markdown"},"source":{"0d9a77d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# plotly library\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","37f53a79":"data=pd.read_csv(\"..\/input\/xAPI-Edu-Data.csv\")","2b0f25d2":"data.head()","bd35e359":"data.info()","ea9a00e3":"data.describe()","59beae42":"#heatmap\nf,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(data.corr(),annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".1f\",ax=ax)\nplt.show()","16ac9fbb":"data.head()","36cd0738":"# Line Plot\ndata.raisedhands.plot(kind=\"line\",color=\"g\",label = 'raisedhands',linewidth=1,alpha = 0.5,grid = True,linestyle = ':',figsize=(10,10))\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.legend(loc=\"upper right\")\nplt.title('Line Plot')            # title = title of plot\nplt.show()","6301da4e":"plt.subplots(figsize=(10,10))\nplt.plot(data.raisedhands[:100],linestyle=\"-.\")\nplt.plot(data.VisITedResources[:100],linestyle=\"-\")\nplt.xlabel(\"x axis\")\nplt.ylabel(\"y axis\")\nplt.title(\"Raidehands and VisITedResources Line Plot\")\nplt.legend(loc=\"upper right\")\nplt.show()","17020a25":"#subplots\nraisedhands=data.raisedhands\nVisITedResources=data.VisITedResources\n\nplt.subplots(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.title(\"raisedhands-VisITedResources subplot\")\nplt.plot(raisedhands[:100],color=\"r\",label=\"raisedhands\")\nplt.legend()\nplt.grid()\n\nplt.subplot(2,1,2)\nplt.plot(VisITedResources[:100],color=\"b\",label=\"VisITedResources\")\nplt.legend()\nplt.grid()\n\nplt.show()","2763cffc":"# discussion and raisedhands line plot in plotly\n# import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n# Creating trace1\ntrace1 = go.Scatter(\n                    x = np.arange(0,82),\n                    y = data.Discussion,\n                    mode = \"lines\",\n                    name = \"discussion\",\n                    marker = dict(color = 'rgba(16, 112, 2, 0.8)'),\n                    )\n# Creating trace2\ntrace2 = go.Scatter(\n                    x =np.arange(0,82) ,\n                    y = data.raisedhands,\n                    mode = \"lines\",\n                    name = \"raisedhands\",\n                    marker = dict(color = 'rgba(80, 26, 80, 0.8)'),\n                   )\ndf = [trace1, trace2]\nlayout = dict(title = 'Discussion and Raisedhands of Students',\n              xaxis= dict(title= 'raisedhands',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = df, layout = layout)\niplot(fig)","af8c15a3":"#histogram of raisedhands\ndata.raisedhands.plot(kind=\"hist\",bins=10,figsize=(10,10),color=\"b\",grid=\"True\")\nplt.xlabel(\"raisedhands\")\nplt.legend(loc=\"upper right\")\nplt.title(\"raisedhands Histogram\")\nplt.show()","31c45d62":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata.plot(kind=\"hist\",y=\"raisedhands\",bins = 50,range= (0,50),normed = True,ax = axes[0])\ndata.plot(kind = \"hist\",y = \"raisedhands\",bins = 50,range= (0,50),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt.show()","79d34a39":"#raidehands vs Discussion scatter plot\nplt.subplots(figsize=(10,10))\nplt.scatter(data.raisedhands,data.Discussion,color=\"green\")\nplt.xlabel(\"raisedhands\")\nplt.ylabel(\"Discussion\")\nplt.grid()\nplt.title(\"Raidehands vs Discussion Scatter Plot\",color=\"red\")\nplt.show()","24c53cc2":"#raidehands vs AnnouncementsView scatter plot\ncolor_list1 = ['red' if i=='M' else 'blue' for i in data.gender]\nplt.subplots(figsize=(10,10))\nplt.scatter(data.raisedhands,data.AnnouncementsView,color=color_list1, alpha=0.8)\nplt.xlabel(\"raisedhands\")\nplt.ylabel(\"AnnouncementsView\")\nplt.grid()\nplt.title(\"Raidehands vs Announcements View Scatter Plot\",color=\"black\",fontsize=15)\nplt.show()","696b175f":"len(data.raisedhands.unique())","46a4eccf":"# raisedhands  in terms of gender\n\n# import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n# creating trace1\ntrace1 =go.Scatter(\n                    x = np.arange(0,82),\n                    y = data[data.gender=='M'].raisedhands,\n                    mode = \"markers\",\n                    name = \"male\",\n                    marker = dict(color = 'rgba(0, 100, 255, 0.8)'),\n                    )\n# creating trace2\ntrace2 =go.Scatter(\n                    x = np.arange(0,82),\n                    y = data[data.gender==\"F\"].raisedhands,\n                    mode = \"markers\",\n                    name = \"female\",\n                    marker = dict(color = 'rgba(255, 128, 255, 0.8)'),\n                    )\n\ndf = [trace1, trace2]\nlayout = dict(title = 'raisedhands',\n              xaxis= dict(title= 'index',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Values',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = df, layout = layout)\niplot(fig)","73c7c794":"# Discussion  in terms of gender\n\n# import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n# creating trace1\ntrace1 =go.Scatter(\n                    x = np.arange(0,82),\n                    y = data[data.gender=='M'].Discussion,\n                    mode = \"markers\",\n                    name = \"male\",\n                    marker = dict(color = 'rgba(0, 100, 255, 0.8)'),\n                    text= data[data.gender==\"M\"].gender)\n# creating trace2\ntrace2 =go.Scatter(\n                    x = np.arange(0,82),\n                    y = data[data.gender==\"F\"].Discussion,\n                    mode = \"markers\",\n                    name = \"female\",\n                    marker = dict(color = 'rgba(200, 50, 150, 0.8)'),\n                    text= data[data.gender==\"F\"].gender)\n\ndf = [trace1, trace2]\nlayout = dict(title = 'Discussion',\n              xaxis= dict(title= 'index',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Values',ticklen= 5,zeroline= False)\n             )\nfig = dict(data = df, layout = layout)\niplot(fig)","4fb44c6a":"# Plotting Scatter Matrix\ncolor_list = ['red' if i=='M' else 'green' for i in data.gender]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'gender'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.8,\n                                       s = 200,\n                                       marker = '.',\n                                       edgecolor= \"black\")\n\nplt.show()","4c3f8e1e":"# Raisehands Average in terms of Topic\n\n# we will create a data containing averages of the numerical values of our data.\ntopic_list=list(data.Topic.unique())\nrh_av=[]\nd_av=[]\naview_av=[]\nvr_av=[]\nfor i in topic_list:\n    rh_av.append(sum(data[data[\"Topic\"]==i].raisedhands)\/len(data[data[\"Topic\"]==i].raisedhands))\n    d_av.append(sum(data[data[\"Topic\"]==i].Discussion)\/len(data[data[\"Topic\"]==i].Discussion))\n    aview_av.append(sum(data[data[\"Topic\"]==i].AnnouncementsView)\/len(data[data[\"Topic\"]==i].AnnouncementsView))\n    vr_av.append(sum(data[data[\"Topic\"]==i].VisITedResources)\/len(data[data[\"Topic\"]==i].VisITedResources))\ndata2=pd.DataFrame({\"topic\":topic_list,\"raisedhands_avg\":rh_av,\"discussion_avg\":d_av,\"AnnouncementsView_avg\":aview_av, \"VisITedResources_avg\":vr_av})\n\n# we will sort data2 interms of index of raisedhands_avg in ascending order\nnew_index2 = (data2['raisedhands_avg'].sort_values(ascending=True)).index.values \nsorted_data2 = data2.reindex(new_index2)\nsorted_data2.head()\n\n# visualization\nplt.figure(figsize=(15,10))\nsns.barplot(x=sorted_data2['topic'], y=sorted_data2['raisedhands_avg'])\nplt.xticks(rotation= 90)\nplt.xlabel('Topics')\nplt.ylabel('Raisehands Average')\nplt.title(\"Raisehands Average in terms of Topic\")","fab43136":"# horizontal bar plot\n# Raised hands, Discussion and Announcements View averages acording to topics\n\nf,ax = plt.subplots(figsize = (9,15)) #create a figure of 9x15 .\nsns.barplot(x=rh_av,y=topic_list,color='cyan',alpha = 0.5,label='Raised hands' )\nsns.barplot(x=d_av,y=topic_list,color='blue',alpha = 0.7,label='Discussion')\nsns.barplot(x=aview_av,y=topic_list,color='red',alpha = 0.6,label='Announcements View')\n\nax.legend(loc='upper right',frameon = True)\nax.set(xlabel='Average ', ylabel='Topics',title = \"Average of Numerical Values of Data According to Topics \")","7518ca78":"# raisehands and discussion average acording to topic\n\n# we will sort data2 interms of index of raisedhands_avg in descending order\nnew_index3 = (data2['raisedhands_avg'].sort_values(ascending=False)).index.values \nsorted_data3 = data2.reindex(new_index3)\n\n# create trace1 \ntrace1 = go.Bar(\n                x = sorted_data3.topic,\n                y = sorted_data3.raisedhands_avg,\n                name = \"raisedhands average\",\n                marker = dict(color = 'rgba(255, 174, 155, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = sorted_data3.topic)\n# create trace2 \ntrace2 = go.Bar(\n                x = sorted_data3.topic,\n                y = sorted_data3.discussion_avg,\n                name = \"discussion average\",\n                marker = dict(color = 'rgba(255, 255, 128, 0.5)',\n                              line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = sorted_data3.topic)\ndf= [trace1, trace2]\nlayout = go.Layout(barmode = \"group\",title= \"Discussion and Raisedhands Average of Each Topic\")\nfig = go.Figure(data = df, layout = layout)\niplot(fig)","0aa84a3a":"# raisehands and discussion average acording to PlaceofBirth\n\n#prepare data\nplace_list=list(data.PlaceofBirth.unique())\nrh_av=[]\nd_av=[]\naview_av=[]\nvr_av=[]\nfor i in place_list:\n    rh_av.append(sum(data[data[\"PlaceofBirth\"]==i].raisedhands)\/len(data[data[\"PlaceofBirth\"]==i].raisedhands))\n    d_av.append(sum(data[data[\"PlaceofBirth\"]==i].Discussion)\/len(data[data[\"PlaceofBirth\"]==i].Discussion))\n    aview_av.append(sum(data[data[\"PlaceofBirth\"]==i].AnnouncementsView)\/len(data[data[\"PlaceofBirth\"]==i].AnnouncementsView))\n    vr_av.append(sum(data[data[\"PlaceofBirth\"]==i].VisITedResources)\/len(data[data[\"PlaceofBirth\"]==i].VisITedResources))\ndata4=pd.DataFrame({\"PlaceofBirth\":place_list,\"raisedhands_avg\":rh_av,\"discussion_avg\":d_av,\"AnnouncementsView_avg\":aview_av, \"VisITedResources_avg\":vr_av})\n\nnew_index4=data4[\"raisedhands_avg\"].sort_values(ascending=False).index.values\nsorted_data4=data4.reindex(new_index4)\n\n# create trace1 \ntrace1 = go.Bar(\n                x = sorted_data4.PlaceofBirth,\n                y = sorted_data4.raisedhands_avg,\n                name = \"raisedhands average\",\n                marker = dict(color = 'rgba(200, 125, 200, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = sorted_data4.PlaceofBirth)\n# create trace2 \ntrace2 = go.Bar(\n                x = sorted_data4.PlaceofBirth,\n                y = sorted_data4.discussion_avg,\n                name = \"discussion average\",\n                marker = dict(color = 'rgba(128, 255, 128, 0.5)',\n                              line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = sorted_data4.PlaceofBirth)\ndf= [trace1, trace2]\nlayout = go.Layout(barmode = \"group\",title= \"Discussion and Raisedhands Average acording to PlaceofBirth\")\nfig = go.Figure(data = df, layout = layout)\niplot(fig)","0406894e":"trace1 = {\n  'x': sorted_data4.PlaceofBirth,\n  'y': sorted_data4.raisedhands_avg,\n  'name': 'raisedhands average',\n  'type': 'bar'\n};\ntrace2 = {\n  'x': sorted_data4.PlaceofBirth,\n  'y': sorted_data4.discussion_avg,\n  'name': 'discussion average',\n  'type': 'bar'\n};\ndf = [trace1, trace2];\nlayout = {\n  'xaxis': {'title': 'PlaceofBirth'},\n  'barmode': 'relative',\n  'title': 'Raisedhands and Discussion Average Acording to Place of Birth'\n};\nfig = go.Figure(data = df, layout = layout)\niplot(fig)","87e9701f":"# Raisedhands vs  Discussion Rate point plot\n#normalize the values of discussion_avg and raisedhands_avg\ndata3=sorted_data2.copy()\ndata3[\"raisedhands_avg\"]=data3['raisedhands_avg']\/max( data3['raisedhands_avg'])\ndata3[\"discussion_avg\"]=data3['discussion_avg']\/max( data3['discussion_avg'])\n\n# visualize\nf,ax1 = plt.subplots(figsize =(12,10))\nsns.pointplot(x='topic',y='raisedhands_avg',data=data3,color='lime',alpha=0.8)\nsns.pointplot(x='topic',y='discussion_avg',data=data3,color='red',alpha=0.8)\nplt.text(5,0.50,'Raised hands Average',color='red',fontsize = 17,style = 'italic')\nplt.text(5,0.46,'Discussion Average',color='lime',fontsize = 18,style = 'italic')\nplt.xlabel('Topics',fontsize = 15,color='blue')\nplt.ylabel('Values',fontsize = 15,color='blue')\nplt.title('Raisedhands vs  Discussion Rate',fontsize = 20,color='blue')\nplt.grid()\n\n\n","5c79d30a":"# Raisedhands vs  Discussion Rate point plot acording to place of birth\n#normalize the values of discussion_avg and raisedhands_avg\ndata5=sorted_data4.copy()\ndata5[\"raisedhands_avg\"]=data5['raisedhands_avg']\/max( data5['raisedhands_avg'])\ndata5[\"discussion_avg\"]=data5['discussion_avg']\/max( data5['discussion_avg'])\n\n# visualize\nf,ax1 = plt.subplots(figsize =(12,10))\nsns.pointplot(x='PlaceofBirth',y='raisedhands_avg',data=data5,color='red',alpha=0.8)\nsns.pointplot(x='PlaceofBirth',y='discussion_avg',data=data5,color='blue',alpha=0.8)\nplt.text(3,0.30,'Raised hands Average',color='red',fontsize = 17,style = 'italic')\nplt.text(3,0.36,'Discussion Average',color='blue',fontsize = 18,style = 'italic')\nplt.xlabel('PlaceofBirth',fontsize = 15,color='purple')\nplt.ylabel('Values',fontsize = 15,color='purple')\nplt.title('Raisedhands vs  Discussion Rate',fontsize = 20,color='purple')\nplt.grid()","f6a7d1be":"data.gender.value_counts()","22e69ea2":"plt.subplots(figsize=(8,5))\nsns.countplot(data.gender)\nplt.xlabel(\"gender\",fontsize=\"15\")\nplt.ylabel(\"numbers\",fontsize=\"15\")\nplt.title(\"Number of Genders in Data\", color=\"red\",fontsize=\"18\")\nplt.show()","b6339010":"#StageID unique values\ndata.StageID.value_counts()","3c35f608":"sns.countplot(data.StageID)\nplt.xlabel(\"StageID\")\nplt.ylabel(\"numbers\")\nplt.title(\"Number of StageID in Data\", color=\"red\",fontsize=\"18\")\nplt.show()","c975a988":"labels=data.StageID.value_counts()\ncolors=[\"grey\",\"blue\",\"green\"]\nexplode=[0,0,0]\nsizes=data.StageID.value_counts().values\n\nplt.figure(figsize = (7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%')\nplt.title(\"StageID in Data\",color = 'blue',fontsize = 15)\nplt.show()","a8348a04":"# StageID piechart in plotly\npie1_list=data[\"StageID\"].value_counts().values\nlabels = data[\"StageID\"].value_counts().index\n# figure\nfig = {\n  \"data\": [\n    {\n      \"values\": pie1_list,\n      \"labels\": labels,\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"StageID\",\n      \"hoverinfo\":\"label+percent\",\n      \"hole\": .3,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"StageID Type\",\n        \"annotations\": [\n            { \"font\": { \"size\": 20},\n              \"showarrow\": False,\n              \"text\": \"StageID\",\n                \"x\": 0.20,\n                \"y\": 1\n            },\n        ]\n    }\n}\niplot(fig)","7fef7e69":"data.head()","f56d9162":"# raisedhands and VisITedResources pair plot\nsns.pairplot(data.loc[:,[\"raisedhands\",\"VisITedResources\",\"Discussion\"]])\nplt.show()","4fc48f01":"data.head()","9d63b351":"data_new=data.loc[:,[\"gender\",\"raisedhands\",\"VisITedResources\",\"AnnouncementsView\",\"Discussion\"]]","7d130675":"data_new.gender=[1 if i==\"M\" else 0 for i in data_new.gender]","c4734b01":"data_new.head()","48b432be":"y=data_new.gender.values\nx_data=data_new.drop(\"gender\",axis=1)","b4eb63e6":"# normalize the values in x_data\nx=(x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data))","5f1346ba":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=52)","87c2437d":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n#fit\nlr=LogisticRegression()\nlr.fit(x_train,y_train)\n\n#accuracy\nprint(\"test accuracy is {}\".format(lr.score(x_test,y_test)))\n","e71281fd":"#split data\nfrom sklearn.neighbors import KNeighborsClassifier\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n\nknn=KNeighborsClassifier(n_neighbors=3)\n\n#fit\nknn.fit(x_train,y_train)\n\n#prediction\nprediction=knn.predict(x_test)","4f8bb06e":"#prediction score (accuracy)\nprint('KNN (K=3) accuracy is: ',knn.score(x_test,y_test)) ","8aca0879":"# find the convenient k value for range (1,31)\nscore_list=[]\ntrain_accuracy=[]\nfor i in range(1,31):\n    knn2=KNeighborsClassifier(n_neighbors=i)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    train_accuracy.append(knn2.score(x_train,y_train))\nplt.figure(figsize=(15,10))   \nplt.plot(range(1,31),score_list,label=\"testing accuracy\",color=\"blue\",linewidth=3)\nplt.plot(range(1,31),train_accuracy,label=\"training accuracy\",color=\"orange\",linewidth=3)\nplt.xlabel(\"k values in KNN\")\nplt.ylabel(\"accuracy\")\nplt.title(\"Accuracy results with respect to k values\")\nplt.legend()\nplt.grid()\nplt.show()\n\nprint(\"Maximum value of testing accuracy is {} when k= {}.\".format(np.max(score_list),1+score_list.index(np.max(score_list))))","3f9b19ec":"from sklearn.svm import SVC\n\nsvm=SVC(random_state=1)\nsvm.fit(x_train,y_train)\n#accuracy\nprint(\"accuracy of svm algorithm: \",svm.score(x_test,y_test))\n","ba4317eb":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\n\n# test accuracy\nprint(\"Accuracy of naive bayees algorithm: \",nb.score(x_test,y_test))\n","efe8e514":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\n\nprint(\"Accuracy score for Decision Tree Classification: \" ,dt.score(x_test,y_test))\n","1e45d6ea":"from sklearn.ensemble import RandomForestClassifier\n\nrf=RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train,y_train)\n\nprint(\"random forest algorithm accuracy: \",rf.score(x_test,y_test))\n","ee3be133":"score_list1=[]\nfor i in range(100,501,100):\n    rf2=RandomForestClassifier(n_estimators=i,random_state=1)\n    rf2.fit(x_train,y_train)\n    score_list1.append(rf2.score(x_test,y_test))\nplt.figure(figsize=(10,10))\nplt.plot(range(100,501,100),score_list1)\nplt.xlabel(\"number of estimators\")\nplt.ylabel(\"accuracy\")\nplt.grid()\nplt.show()\n\nprint(\"Maximum value of accuracy is {} \\nwhen n_estimators= {}.\".format(max(score_list1),(1+score_list1.index(max(score_list1)))*100))","fcf7a72f":"score_list2=[]\nfor i in range(100,131):\n    rf3=RandomForestClassifier(n_estimators=i,random_state=1)\n    rf3.fit(x_train,y_train)\n    score_list2.append(rf3.score(x_test,y_test))\nplt.figure(figsize=(10,10))\nplt.plot(range(100,131),score_list2)\nplt.xlabel(\"number of estimators\")\nplt.ylabel(\"accuracy\")\nplt.grid()\nplt.show()\n\nprint(\"Maximum value of accuracy is {} when number of estimators between 100 and 131 \".format(max(score_list2)))","55a6ff9a":"#Confusion matrix of Random Forest Classf.\ny_pred=rf.predict(x_test)\ny_true=y_test\n\n#cm\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_true,y_pred)\n\n#cm visualization\nf,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"predicted value\")\nplt.ylabel(\"real value\")\nplt.show()","9813b180":"#Confusion matrix of KNN Classf.\ny_pred1=knn.predict(x_test)\ny_true=y_test\n#cm\ncm1=confusion_matrix(y_true,y_pred1)\n\n#cm visualization\nf,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(cm1,annot=True,linewidths=0.5,linecolor=\"blue\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"predicted value\")\nplt.ylabel(\"real value\")\nplt.show()","4fcefc45":"#Confusion matrix of Decision Tree Classf.\ny_pred2=dt.predict(x_test)\ny_true=y_test\n#cm\ncm2=confusion_matrix(y_true,y_pred2)\n\n#cm visualization\nf,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(cm2,annot=True,linewidths=0.5,linecolor=\"green\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"predicted value\")\nplt.ylabel(\"real value\")\nplt.show()","6a059e07":"dictionary={\"model\":[\"LR\",\"KNN\",\"SVM\",\"NB\",\"DT\",\"RF\"],\"score\":[lr.score(x_test,y_test),knn.score(x_test,y_test),svm.score(x_test,y_test),nb.score(x_test,y_test),dt.score(x_test,y_test),rf.score(x_test,y_test)]}\ndf1=pd.DataFrame(dictionary)","b5afe464":"#sort the values of data \nnew_index5=df1.score.sort_values(ascending=False).index.values\nsorted_data5=df1.reindex(new_index5)\n\n# create trace1 \ntrace1 = go.Bar(\n                x = sorted_data5.model,\n                y = sorted_data5.score,\n                name = \"score\",\n                marker = dict(color = 'rgba(200, 125, 200, 0.5)',\n                             line=dict(color='rgb(0,0,0)',width=1.5)),\n                text = sorted_data5.model)\ndat = [trace1]\nlayout = go.Layout(barmode = \"group\",title= 'Scores of Classifications')\nfig = go.Figure(data = dat, layout = layout)\niplot(fig)","07c40a82":"<a id=\"12\"><\/a> \n# Logistic Regression Classification\n\n* When we talk about binary classification( 0 and 1 outputs) what comes to mind first is logistic regression.\n* Logistic regression is actually a very simple neural network. ","f488f0cd":"<a id=\"14\"><\/a> \n# Support Vector Machine (SVM) Classification","826aaaf2":"In this part, we will use Machine Learning algoithms in our data. Machine Learning Classification algorithms have the following steps:\n* Split data\n* Fit data\n* Predict Data\n* Find Accuracy","6085c83f":"As it seen in the graph, it is convenient to choose n_estimators=100 for the best accuracy result.\nLet's look at between 100 and 130. ","3a7373c0":"We know that our accuracy is 0.645 when k=3 .  We predicted;\n* 15 true for label 0=TN\n* 47 true for label 1=TP\n* 8 wrong for the label 1 =FN ( I predicted 8 label 0 but they are label 1)\n* 26 wrong for label 0= FP ( I predicted 26 label  1 but they are label 0)","98c35fc4":"<a id=\"9\"><\/a> \n# Pair Plot","43f9e21e":"We need only numerical features. So create new data containing only numerical values.","1e5dc06b":"# Introduction \n\n1. [EDA (Exploratory Data Analysis)](#1)\n    1. [Line Plot](#2)\n    1. [Histogram](#3)\n    1. [Scatter Plot](#4)\n    1. [Bar Plot](#5)\n    1. [Point Plot](#6)\n    1. [Count Plot](#7)\n    1. [Pie Chart](#8)\n    1. [Pair Plot](#9)\n   \n1. [MACHINE LEARNING](#11)\n    1. [Logistic Regression Classification](#12)\n    1. [KNN (K-Nearest Neighbour) Classification](#13)\n    1. [Support Vector Machine( SVM) Classification](#14)\n    1. [Naive Bayes Classification](#15)\n    1. [Decision Tree Classification](#16)\n    1. [Random Forest Classification](#17)\n    1. [Confusion Matrix](#18)\n    \n1. [Conclusion](#19)  \n","70dcfd47":"We will classify these points by using 3 splits.\n\n<a href=\"https:\/\/ibb.co\/y4n4rRk\"><img src=\"https:\/\/i.ibb.co\/FHbHFWY\/d22-690x569.jpg\" alt=\"d22-690x569\" border=\"0\"><\/a>","be6cfe48":"<a id=\"2\"><\/a> \n# Line Plot","c899dd56":"If you have any questions and suggestions, please comment. Your suggestions are very valuable to me.\nI hope you like it.","7cd2d599":"# Bar Plot in Plotly\n\n* Import graph_objs as *go*\n* Creating traces\n    * x = x axis\n    * y = y axis\n    * mode = type of plot like marker, line or line + markers\n    * name = name of the plots\n    * marker = marker is used with dictionary. \n        * color = color of lines. It takes RGB (red, green, blue) and opacity (alpha)\n        * line = It is dictionary. line between bars\n            * color = line color around bars\n    * text = The hover text (hover is curser)\n* data = is a list that we add traces into it\n* layout = it is dictionary.\n    * barmode = bar mode of bars like grouped\n* fig = it includes data and layout\n* iplot() = plots the figure(fig) that is created by data and layout","7b321ac0":"\n* First split data\n* Fit data\n* Predict Data\n* Find Accuracy\n* Find the convenient k value for the highest accuracy.","9747bf40":"<a id=\"1\"><\/a> \n# EDA (Exploratory Data Analysis)","5442d07b":"We know that our accuracy is 0.7291, which is the best result, when number of estimators is 100 .  But here we predicted \n* 21 true for label 0=TN\n* 49 true for label 1=TP\n* 6 wrong for the label 1 =FN ( I predicted 6 label 0 but they are label 1)\n* 20 wrong for label 0= FP ( I predicted 20 label  1 but they are label 0)\n","8875d417":"<a id=\"13\"><\/a> \n# KNN (K-Nearest Neighbour) Classification\n1. Choose K value.\n1. Find the K nearest data points.\n1. Find the number of data points for each class between K nearest neighbour.\n1. Identify the class of data or point we tested.","c892d3d1":"It is clear from above plot that Random Forest Classification is more effective.","fed5098e":"<a id=\"17\"><\/a> \n# Random Forest Classification\n\nRandom Forest divides the train data into n samples, and for each n sample applies Decision Tree algorithm. At he end of n Decision Tree algorithm, it takes the answer which is more.","dc5b87e8":"* create x_train, y_train, x_test and  y_test arrays with train_test_split method.","a752d7e9":"<a id=\"8\"><\/a> \n# Pie Chart\n\n* fig: create figures\n    * data: plot type\n        * values: values of plot\n        * labels: labels of plot\n        * name: name of plots\n        * hoverinfo: information in hover\n        * hole: hole width\n        * type: plot type like pie\n    * layout: layout of plot\n        * title: title of layout\n        * annotations: font, showarrow, text, x, y","20503aa9":"We need to prepare our data for classificaiton.\n* We will determine x and y values.\n    * y: binary output (0 and 1)\n    * x_data: rest of the data (i.e. features of data except gender)","f531b3b6":"<a id=\"5\"><\/a> \n# Bar Plot","a1bb0de6":"<a id=\"16\"><\/a> \n# Decision Tree Classification\n\nWe have points as seen in the figure and we want to classify these points.\n\n<a href=\"https:\/\/ibb.co\/n8CYzwN\"><img src=\"https:\/\/i.ibb.co\/G3T8cd4\/d11-640x538.jpg\" alt=\"d11-640x538\" border=\"0\"><\/a>\n\n","a7170266":"<a id=\"15\"><\/a> \n# Naive Bayes Classification","5abb47eb":"# Scatter Plot in Plotly\n\n* Import graph_objs as *go*\n* Creating traces\n    * x = x axis\n    * y = y axis\n    * mode = type of plot like marker, line or line + markers\n    * name = name of the plots\n    * marker = marker is used with dictionary. \n        * color = color of lines. It takes RGB (red, green, blue) and opacity (alpha)\n    * text = The hover text (hover is curser)\n* data = is a list that we add traces into it\n* layout = it is dictionary.\n    * title = title of layout\n    * x axis = it is dictionary\n        * title = label of x axis\n        * ticklen = length of x axis ticks\n        * zeroline = showing zero line or not\n    * y axis = it is dictionary and same with x axis\n* fig = it includes data and layout\n* iplot() = plots the figure(fig) that is created by data and layout","3d35eb0e":"Actually, this graph says that, if n_estimators is between 100 and 122, then the value of accuracy is not changing.","f8516729":"<a id=\"7\"><\/a> \n# Count Plot","997d0ccc":"<a id=\"4\"><\/a> \n# Scatter Plot","4be8418c":"<a id=\"6\"><\/a> \n# Point Plot","a4fd909d":"<a id=\"11\"><\/a> \n# MACHINE LEARNING\n\n<a href=\"https:\/\/ibb.co\/hgB9j10\"><img src=\"https:\/\/i.ibb.co\/YNcQMTg\/ml1.jpg\" alt=\"ml1\" border=\"0\">","8953a460":"<a id=\"19\"><\/a> \n# Conclusion\n\nAs it seen from confusion matrices, the number of wrong predictions are:\n* KNN Classif: 8, 26\n* Decision Tree Classif:  16, 16\n* Random Forest Classif: 6, 20\n\nIt seems that Random Forest Classification is more effective which can also be seen from accuracy scores. Now lets check this by visualizing the scores.","094494cd":"We will write 1 for male and 0 for female for classification.","7f09ef8d":"<a id=\"3\"><\/a> \n# Histogram Plot","e4eda834":"<a id=\"18\"><\/a> \n# Confusion Matrix","f9ddd33a":"Assume that we have a graph  and we want to determine the class of black points(i.e. they are in class green or red. )\n<a href=\"https:\/\/ibb.co\/NmzLJF6\"><img src=\"https:\/\/i.ibb.co\/MGLRtgD\/2.png\" alt=\"2\" border=\"0\">\n    \n \n \n","e56e9b11":"Confusion matrix gives the number of true and false predicitons in our classificaiton. It is more reliable than accuracy. \n<br> Here,\n* y_pred:  results that we predict.\n* y_test: our real values."}}