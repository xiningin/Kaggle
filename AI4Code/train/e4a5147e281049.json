{"cell_type":{"01f676a1":"code","36b66256":"code","8cfc6ac9":"code","8bdf5545":"code","e158fab3":"code","d78f7b12":"code","46278307":"code","54a9f7fd":"code","749279dc":"code","ee5ca61b":"code","e062e593":"code","2b683644":"code","5bf227b7":"code","cc6961d2":"code","8c55300f":"code","2beb524e":"code","fd591e51":"code","693628a2":"code","7a7159de":"code","dbfc0424":"code","6379bbc3":"code","43d32d38":"code","5f55da62":"code","e4c7138d":"code","7b1a6865":"code","d31bbbee":"code","8344c7be":"code","e11182ea":"code","419325cc":"code","fcb34624":"code","78fc27ce":"code","6a7a9efa":"code","e229afe3":"code","60cf2449":"code","b5b9af5b":"code","6b4ba355":"code","34114004":"code","d246c27f":"code","92cf3f35":"code","a0e5ffd1":"code","1512a387":"code","08932eb6":"code","d29cd764":"code","d31c9789":"code","bb84cbbc":"code","8317a2dd":"code","4cb2a49f":"markdown","2a00e455":"markdown","5a373855":"markdown","3d3ef323":"markdown","9885ee61":"markdown","490e0d8a":"markdown","f4a8bd31":"markdown"},"source":{"01f676a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36b66256":"import numpy as np, pandas as pd, os\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n\n","8cfc6ac9":"\ntrain = pd.read_csv('..\/input\/instant-gratification\/train.csv')\ntest = pd.read_csv('..\/input\/instant-gratification\/test.csv')\n\ntrain.head()","8bdf5545":"train.shape","e158fab3":"train.columns","d78f7b12":"#cols =columns for c in train.columns if c not in ['id', 'target']]\ncols = ['muggy-smalt-axolotl-pembus', 'dorky-peach-sheepdog-ordinal',\n       'slimy-seashell-cassowary-goose']\noof = np.zeros(len(train))\nskf = StratifiedKFold(n_splits=5, random_state=42)\n   \nfor train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):\n    clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)\n    clf.fit(train.loc[train_index][cols],train.loc[train_index]['target'])\n    oof[test_index] = clf.predict_proba(train.loc[test_index][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","46278307":"clf.get_params()","54a9f7fd":"clf.coef_","749279dc":"train['muggy-smalt-axolotl-pembus_100'] = train['muggy-smalt-axolotl-pembus']*100 ","ee5ca61b":"cols = ['muggy-smalt-axolotl-pembus_100', 'dorky-peach-sheepdog-ordinal',\n       'slimy-seashell-cassowary-goose']\n\nfor train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):\n    clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)\n    clf.fit(train.loc[train_index][cols],train.loc[train_index]['target'])\n    oof[test_index] = clf.predict_proba(train.loc[test_index][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","e062e593":"clf.coef_","2b683644":"train['muggy-smalt-axolotl-pembus_s100'] = train['muggy-smalt-axolotl-pembus']\/100 ","5bf227b7":"cols = ['muggy-smalt-axolotl-pembus_s100', 'dorky-peach-sheepdog-ordinal',\n       'slimy-seashell-cassowary-goose']\n\nfor train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):\n    clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)\n    clf.fit(train.loc[train_index][cols],train.loc[train_index]['target'])\n    oof[test_index] = clf.predict_proba(train.loc[test_index][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","cc6961d2":"clf.coef_","8c55300f":"train['muggy-smalt-axolotl-pembus'].hist();","2beb524e":"for i in range(10000):\n    train.loc[i, 'muggy-smalt-axolotl-pembus'] = train.loc[i, 'muggy-smalt-axolotl-pembus']*100","fd591e51":"train['muggy-smalt-axolotl-pembus'].hist();","693628a2":"cols = ['muggy-smalt-axolotl-pembus', 'dorky-peach-sheepdog-ordinal',\n       'slimy-seashell-cassowary-goose']\n\nfor train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):\n    clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)\n    clf.fit(train.loc[train_index][cols],train.loc[train_index]['target'])\n    oof[test_index] = clf.predict_proba(train.loc[test_index][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","7a7159de":"train = pd.read_csv('..\/input\/instant-gratification\/train.csv')\ncols = ['muggy-smalt-axolotl-pembus', 'dorky-peach-sheepdog-ordinal',\n       'slimy-seashell-cassowary-goose']\n\nfor train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):\n    clf = LogisticRegression(solver='liblinear',penalty='l1')\n    clf.fit(train.loc[train_index][cols],train.loc[train_index]['target'])\n    oof[test_index] = clf.predict_proba(train.loc[test_index][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","dbfc0424":"train = pd.read_csv('..\/input\/instant-gratification\/train.csv')\ncols = ['muggy-smalt-axolotl-pembus', 'dorky-peach-sheepdog-ordinal',\n       'slimy-seashell-cassowary-goose']\n\nfor train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):\n    clf = LogisticRegression(solver='liblinear',penalty='l2')\n    clf.fit(train.loc[train_index][cols],train.loc[train_index]['target'])\n    oof[test_index] = clf.predict_proba(train.loc[test_index][cols])[:,1]\n    \nauc = roc_auc_score(train['target'],oof)\nprint('LR without interactions scores CV =',round(auc,5))","6379bbc3":"from sklearn.model_selection import GridSearchCV","43d32d38":"param_grid = {'C': np.arange(1e-5, 3, 0.1)}\nscoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log loss': 'neg_log_loss'}\ngs = GridSearchCV(LogisticRegression(), return_train_score=False,param_grid = param_grid, scoring=scoring, cv = 5, refit='AUC')\ngs.fit(train[cols], train['target'])","5f55da62":"print('='*20)\nprint(\"best params: \" + str(gs.best_estimator_))\nprint(\"best params: \" + str(gs.best_params_))\nprint('best score:', gs.best_score_)\nprint('='*20)\n","e4c7138d":"df_train = pd.read_csv('..\/input\/random-linear-regression\/train.csv')\ndf_test = pd.read_csv('..\/input\/random-linear-regression\/test.csv')","7b1a6865":"df_test.head()","d31bbbee":"df_train.fillna(49.94, inplace=True)","8344c7be":"df_test.isna().sum()","e11182ea":"df_train.describe()","419325cc":"X_train = df_train['x'].values.reshape(-1,1)\ny_train = df_train['y'].values\nX_test = df_test['x'].values.reshape(-1,1)\ny_test = df_test['y'].values","fcb34624":"from mlxtend.evaluate import bias_variance_decomp\nfrom sklearn.linear_model import LinearRegression\n","78fc27ce":"lr = LinearRegression()\navg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n    lr, X_train, y_train, X_test, y_test, loss='mse',\n    random_seed=123)","6a7a9efa":"avg_bias, avg_var","e229afe3":"df_train_new = pd.concat([df_train, df_train], axis=0)","60cf2449":"df_train_new.shape","b5b9af5b":"df_train.shape","6b4ba355":"X_train = df_train_new['x'].values.reshape(-1,1)\ny_train = df_train_new['y'].values\nX_test = df_test['x'].values.reshape(-1,1)\ny_test = df_test['y'].values","34114004":"avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n    lr, X_train, y_train, X_test, y_test, loss='mse',\n    random_seed=123)","d246c27f":"avg_bias, avg_var","92cf3f35":"from sklearn.metrics import mean_squared_error","a0e5ffd1":"md1 = lr.fit(df_train['x'].values.reshape(-1,1),df_train['y'].values)","1512a387":"pred1 = md1.predict(df_train['x'].values.reshape(-1,1))","08932eb6":"err1 = pred1- df_train['y'].values","d29cd764":"np.mean(err1), np.var(err1), np.sum(err1)","d31c9789":"mean_squared_error(pred1, df_train['y'].values)","bb84cbbc":"md2 = lr.fit(df_train_new['x'].values.reshape(-1,1), df_train_new['y'].values)\npred2 = md2.predict(df_train_new['x'].values.reshape(-1,1))\nmean_squared_error(pred2, df_train_new['y'].values)","8317a2dd":"err2 = pred2 - df_train_new['y'].values\nnp.mean(err2), np.var(err2), np.sum(err2)","4cb2a49f":"#### Question: duplicate 500 obs to result in 1000 obs, how do training error and variances change? \n\n* Training error: mean squared error does not change\n* Variance of error: same as mean squared error, does not change\n* Variances of the model: decrease by 2 in magnitude since the ability to generalize increase","2a00e455":"<a id='tag1'><\/a>\n## Q1: What if we shrink\/ expand one of the variable by 100 times? What will happen to the coefficients?","5a373855":"## Linear regression diag","3d3ef323":"<a id='tag2'><\/a>\n## Q2 What if you change the distribution of the data?\n\nWe can see that the CV score has a slight decrease because of the change of the distribution","9885ee61":"<a id='tag3'><\/a>\n## Regularization","490e0d8a":"# Logistic regression diagnostics\n\n[Credit to this notebook](https:\/\/www.kaggle.com\/cdeotte\/logistic-regression-0-800)\n\n[Also credit to this](https:\/\/www.kaggle.com\/mnassrib\/titanic-logistic-regression-with-python)\n\n## Table of Contents\n\n[Q1](#tag1)\n\n[Q2](#tag2)\n\n[Regularization and grid search](#tag3)","f4a8bd31":"* Expand variable by 100 times: coefficient shrink by 100 times, other coefficients doesn't change\n* vice versa"}}