{"cell_type":{"63fb7ad5":"code","5832915d":"code","457255f6":"code","5bef8660":"code","56a48ee2":"code","bd310cbd":"code","fd5e5dcd":"code","2bcf0a79":"code","ff4b43a0":"code","157e3538":"code","28c6de35":"code","ef3ce207":"code","7bb006ac":"code","f871518c":"code","b1be2a64":"code","49e2b196":"code","7ac7ad39":"code","aa355794":"code","aa85138d":"code","2ec41497":"code","33b56f66":"code","f297dedc":"code","61ec4fa9":"code","abdc6a21":"code","e87be680":"code","8b724409":"code","ef7befe5":"code","309a2f1d":"code","5b2fe96e":"code","9ded1ef6":"code","4d2b3020":"code","9d01ff62":"code","99a71658":"code","cf38b639":"code","8c562d0e":"code","2979df22":"code","1d0e69d7":"code","662ecb63":"code","63462084":"code","666e19a6":"code","034b4d3f":"code","4ace421b":"code","933fe923":"code","514b9904":"code","f532b788":"code","fe00fddb":"code","94d3d430":"code","372f8ff8":"code","41ebcb01":"code","9d3f8ee3":"code","8deb3910":"code","9bc09431":"code","693972a3":"code","29e6d50e":"code","ce43a066":"code","3defcccf":"code","f0db84a7":"code","7f5afe79":"code","a5fdde03":"code","0cbb63a6":"code","82d9b5b8":"code","161115c6":"markdown","138a4a28":"markdown","0f47cda6":"markdown","50df7118":"markdown","f914ab70":"markdown","398d3e0a":"markdown","cff689a2":"markdown","88643786":"markdown","ae55a400":"markdown","2526b2ba":"markdown","2dea4f3d":"markdown","9f250a54":"markdown","7b6aec8a":"markdown","cbd77911":"markdown","15b7212e":"markdown"},"source":{"63fb7ad5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')","5832915d":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","457255f6":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","5bef8660":"round(train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean(), 2)","56a48ee2":"round(train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean(), 2)","bd310cbd":"round(train_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean(), 2)","fd5e5dcd":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nsns.factorplot(x='Pclass', y='Survived', hue='Sex', col='Embarked', data=train_data)","2bcf0a79":"# Parch means \"number of parents \/ children aboard the Titanic\"\n\nround(train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean(), 2)","ff4b43a0":"# SibSp means \"number of siblings \/ spouses aboard the Titanic\"\n\nround(train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean(), 2)","157e3538":"def concat_df(train_data, test_data):\n    # Returns a concatenated df of training and test set\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)","28c6de35":"train_test_data = concat_df(train_data, test_data)","ef3ce207":"# Extract titles from names\ntrain_test_data['Title'] = train_test_data.Name.str.extract('([A-Za-z]+)\\.')","7bb006ac":"pd.crosstab(train_test_data['Title'], train_test_data['Sex'])","f871518c":"train_test_data['Title'] = train_test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')","b1be2a64":"train_test_data['Title'] = train_test_data['Title'].replace('Mlle', 'Miss')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Ms', 'Miss')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Mme', 'Mrs')","49e2b196":"round(train_test_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean(), 2)","7ac7ad39":"train_test_data['Title'] = train_test_data['Title'].map({'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4}).astype(int)","aa355794":"train_test_data.head()","aa85138d":"train_test_data['Sex'] = train_test_data['Sex'].map({'female': 1, 'male': 0}).astype(int)","2ec41497":"train_test_data.isnull().sum()","33b56f66":"train_test_data.Embarked.value_counts()","f297dedc":"# Fill two empty values in the 'Embarked' column with S as most passengers embarked in this port\ntrain_test_data['Embarked'] = train_test_data['Embarked'].fillna('S')","61ec4fa9":"train_test_data['Embarked'] = train_test_data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})","abdc6a21":"train_test_data.head()","e87be680":"age_by_pclass_sex = train_test_data.groupby(['Sex', 'Pclass']).median()['Age']\n\nage_by_pclass_sex","8b724409":"train_test_data['Age'] = train_test_data.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\ntrain_test_data['Age'] = train_test_data['Age'].astype(int)","ef7befe5":"med_fare = train_test_data.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\ntrain_test_data['Fare'] = train_test_data['Fare'].fillna(med_fare)","309a2f1d":"train_test_data['AgeBand'] = pd.qcut(train_test_data['Age'], 7)","5b2fe96e":"print (round(train_test_data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean(), 2))","9ded1ef6":"train_test_data.loc[train_test_data['Age'] <= 18, 'Age_Band'] = 0\ntrain_test_data.loc[(train_test_data['Age'] > 18) & (train_test_data['Age'] <= 22), 'Age_Band'] = 1\ntrain_test_data.loc[(train_test_data['Age'] > 22) & (train_test_data['Age'] <= 25), 'Age_Band'] = 2\ntrain_test_data.loc[(train_test_data['Age'] > 25) & (train_test_data['Age'] <= 43), 'Age_Band'] = 3\ntrain_test_data.loc[train_test_data['Age'] > 43, 'Age_Band'] = 4","4d2b3020":"train_test_data['Age_Band'] = train_test_data['Age_Band'].astype(int)","9d01ff62":"train_test_data['FareBand'] = pd.qcut(train_test_data['Fare'], 8)","99a71658":"print (round(train_test_data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean(), 2))","cf38b639":"train_test_data['Fare'].median()","8c562d0e":"train_test_data.loc[train_test_data['Fare'] <= 9.844, 'Fare_Band'] = 0\ntrain_test_data.loc[(train_test_data['Fare'] > 9.844) & (train_test_data['Fare'] <= 69.55), 'Fare_Band'] = 1\ntrain_test_data.loc[train_test_data['Fare'] > 69.55, 'Fare_Band'] = 2\ntrain_test_data['Fare_Band'] = train_test_data['Fare_Band'].astype(int)","2979df22":"train_test_data['FamilySize'] = train_test_data['SibSp'] +  train_test_data['Parch'] + 1\ntrain_test_data['FamilySize'] = train_test_data['FamilySize'].astype(int)\nprint (round(train_test_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean(), 2))","1d0e69d7":"train_test_data.loc[train_test_data['FamilySize'] == 1, 'IsAlone'] = 1\ntrain_test_data.loc[train_test_data['FamilySize'] > 1, 'IsAlone'] = 0\ntrain_test_data['IsAlone'] = train_test_data['IsAlone'].astype(int)","662ecb63":"print (round(train_test_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean(), 2))","63462084":"train_test_data.head()","666e19a6":"# Drop features (columns) we don't need anymore\ndrop_cols = ['Age', 'Cabin', 'Fare', 'Name', 'Parch', 'SibSp', 'Ticket', 'AgeBand',\n             'FareBand', 'FamilySize']\n\ntrain_test_data.drop(columns=drop_cols, inplace=True)","034b4d3f":"train_test_data.head()","4ace421b":"train_data = train_test_data[train_test_data['Survived'].notna()]","933fe923":"train_data['Survived'] = train_data['Survived'].astype(int)","514b9904":"train_data.head()","f532b788":"train_data.describe()","fe00fddb":"test_data = train_test_data.drop(train_test_data[train_test_data.Survived >= 0].index)","94d3d430":"test_data.head()","372f8ff8":"test_data.describe()","41ebcb01":"# Importing Classifier Modules\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier","9d3f8ee3":"y = train_data[\"Survived\"]\n\nfeatures = [\"Embarked\", \"Pclass\", \"Sex\", \"Title\", \"Age_Band\", \"Fare_Band\", \"IsAlone\"]\nX = train_data[features]\nX_test = test_data[features]\n\nmodel1 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel1.fit(X, y)\npredictions = model1.predict(X_test)","8deb3910":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('model_default.csv', index=False)\nprint(\"Your submission was successfully saved!\")","9bc09431":"# Calculate feature importances in different models\nimportances = pd.DataFrame({'feature':X.columns,'importance':np.round(model1.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nprint(importances)","693972a3":"# Calculate permutation importance in different models\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model1, random_state=1).fit(X, y)\neli5.show_weights(perm, feature_names = X.columns.tolist())","29e6d50e":"from pdpbox import pdp, get_dataset, info_plots\n\nfor feat_name in features:\n    pdp_dist = pdp.pdp_isolate(model=model1, dataset=train_data, model_features=features, feature=feat_name)\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","ce43a066":"features_to_plot = ['Sex', 'Pclass']\ninter  =  pdp.pdp_interact(model=model1, dataset=train_data, model_features=features, features=features_to_plot)\n\npdp.pdp_interact_plot(pdp_interact_out=inter, feature_names=features_to_plot, plot_type='contour')\nplt.show()","3defcccf":"y = train_data[\"Survived\"]\n\nfeatures = [\"Embarked\", \"Pclass\", \"Sex\", \"Title\", \"Age_Band\", \"Fare_Band\", \"IsAlone\"]\nX = train_data[features]\nX_test = test_data[features]\n\nmodel2 = DecisionTreeClassifier(random_state=1)\nmodel2.fit(X, y)\npredictions = model2.predict(X_test)","f0db84a7":"perm = PermutationImportance(model2, random_state=1).fit(X, y)\neli5.show_weights(perm, feature_names = X.columns.tolist())","7f5afe79":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission_dec_tree.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a5fdde03":"y = train_data[\"Survived\"]\n\nfeatures = [\"Embarked\", \"Pclass\", \"Sex\", \"Title\", \"Age_Band\", \"Fare_Band\", \"IsAlone\"]\nX = train_data[features]\nX_test = test_data[features]\n\nmodel3 = SVC(random_state=1)\nmodel3.fit(X, y)\npredictions = model3.predict(X_test)","0cbb63a6":"perm = PermutationImportance(model3, random_state=1).fit(X, y)\neli5.show_weights(perm, feature_names = X.columns.tolist())","82d9b5b8":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission_SVC.csv', index=False)\nprint(\"Your submission was successfully saved!\")","161115c6":"![](https:\/\/images.unsplash.com\/photo-1558431571-4a9f128e135f?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1189&q=80)","138a4a28":"Based on **SibSp** and **Parch** values we categorize all passengers into two groups: **travelling alone** or not.","0f47cda6":"# 1. Chances to survive","50df7118":"Our aim is to categorize **titles** into bigger groups.","f914ab70":"Passengers who embarked in **Cherbourg** (these were mostly rich people) had better chances to survive.","398d3e0a":"\nIn two tables below we can see that a **gender** and a **ticket class** have a huge influence on whether a passenger survived.","cff689a2":"The most successful model is **RandomForestClassifier** with features \"Embarked\", \"Pclass\", \"Sex\", \"Title\", \"Age_Band\", \"Fare_Band\", \"IsAlone\". It scored 0.79425 points which is 0.03 points better than a default submission based on gender values only.","88643786":"# 2. Data preparation and categorization of values","ae55a400":"We categorize **fare values** into groups too.","2526b2ba":"# 3. Prepare tables for machine learning algorithms","2dea4f3d":"Our next aim is to categorize **age values** into several big groups.","9f250a54":"We know if passengers **travelled with a family**. Let's check whether it influenced their chances to survive.","7b6aec8a":"This work is based on two notebooks:\n\n[Titanic - Advanced Feature Engineering Tutorial](https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial)\n\n[Titanic Solution: A Beginner's Guide](https:\/\/www.kaggle.com\/chapagain\/titanic-solution-a-beginner-s-guide)","cbd77911":"# 4. Getting model insights and saving results","15b7212e":"We have two datasets: one to train the machine learning algorithm and another one to test it."}}