{"cell_type":{"b9667c84":"code","a2017944":"code","6914c3db":"code","c54bea26":"code","2a7e7e1f":"code","50f4fd17":"code","0f0ab023":"code","25bed875":"code","f382b9d5":"code","0fcf620a":"code","e571f4c3":"code","e0fb1db8":"code","e4112349":"code","07095439":"code","bcf9f4a4":"code","d3bb1500":"code","02d0e618":"code","bc38f081":"code","df938547":"code","ab7c2986":"code","457f4c23":"code","aed15449":"code","ada532ee":"code","f5fab061":"code","25c016a8":"code","dcd08086":"code","0cf606c1":"code","c9bdf8ef":"code","496e660e":"code","280d2a67":"code","442b47a3":"code","f7d62bfe":"code","9302bbcf":"code","11420648":"code","0e265009":"code","cbd20a4a":"markdown","c1d22675":"markdown","9ff4dae8":"markdown","b558883c":"markdown","bd4c909d":"markdown","2821eb3b":"markdown","872fcb21":"markdown","88e666b8":"markdown","38a62496":"markdown","46bfb489":"markdown","125e4a8f":"markdown","2290dd4b":"markdown","a363f430":"markdown","29f8a9c3":"markdown","09979400":"markdown","4f65ba3d":"markdown","f1a5bae5":"markdown","b87e106e":"markdown","70fedc36":"markdown","f726a06f":"markdown","a4608c52":"markdown","5405b5d4":"markdown","f5d4d69c":"markdown"},"source":{"b9667c84":"pip install bs4","a2017944":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport numpy as np","6914c3db":"response = requests.get(\"https:\/\/www.espncricinfo.com\/rankings\/content\/page\/211271.html\")\nresponse.ok","c54bea26":"response.headers['Content-Type']","2a7e7e1f":"content = response.content","50f4fd17":"read = BeautifulSoup(content, \"html.parser\")","0f0ab023":"response","25bed875":"read.div","f382b9d5":"div = read.find_all(\"div\", class_= \"ciPhotoContainer\")","0fcf620a":"len(div)","e571f4c3":"div[0].h3.text","e0fb1db8":"div[0].find_all(\"h3\")","e4112349":"cric_formats = div[0].find_all(\"h3\")\ncric_formats","07095439":"for i in cric_formats:\n    print(i.text)","bcf9f4a4":"test_tables = read.table\ntest_tables","d3bb1500":"all_tables = read.find_all(\"table\" ,  class_=\"StoryengineTable\")","02d0e618":"len(all_tables)","bc38f081":"odis = all_tables[1]","df938547":"col = []\nfor i in odis.find_all(\"th\"):\n    col.append(i.text)","ab7c2986":"col","457f4c23":"table_data = odis.find_all(\"td\")\ntable_data","aed15449":"table_list = []\nstart = 0\nend = 5\n\nfor i in range(20):\n    Pos,Team, Matches,Points,Rating = table_data[start:end]\n    table_list.append([Pos.text,Team.text, Matches.text,Points.text,Rating.text])\n    start += 5\n    end +=5\n    \n    ","ada532ee":"table_list","f5fab061":"date = odis.caption.text\ndate","25c016a8":"odi_ranking = pd.DataFrame(table_list , columns=col)\nodi_ranking.name = '04 April 2021'","dcd08086":"print(odi_ranking.name)\nodi_ranking.head()","0cf606c1":"t20 = all_tables[2]\nt20","c9bdf8ef":"col = []\nfor i in t20.find_all(\"th\"):\n    col.append(i.text)","496e660e":"col","280d2a67":"table_data1 = t20.find_all(\"td\")\ntable_data1","442b47a3":"table_list1 = []\nstart = 0\nend = 5\n\nfor i in range(85):\n    Pos,Team, Matches,Points,Rating = table_data1[start:end]\n    table_list1.append([Pos.text,Team.text, Matches.text,Points.text,Rating.text])\n    start += 5\n    end +=5","f7d62bfe":"table_list1","9302bbcf":"updated_date = t20.caption.text\nupdated_date","11420648":"t20_ranking = pd.DataFrame(table_list1 , columns=col)","0e265009":"print(updated_date)\nt20_ranking.head(10)","cbd20a4a":"###  ICC ODI Championship Ranking.","c1d22675":"### All five tables of ranking are save in the variable.","9ff4dae8":"### save test table to give attribute table.","b558883c":"* And here comes the link, first we copy and paste the url and assigned it to the variable link, then we send a request to the web page to reture the information.\n\n*  After requesting, we will check it.it will connected or not.i did here print(response.ok) it gives the output of \"<Response [200]>\" or \"200\" and \"True\" which means you are allowed to do web scraping on such websites.\n","bd4c909d":"#### we use **Beatiful Soup** to Convert the HTML page in to readable form by passing \"html.parser\".","2821eb3b":"### Find Column Name from \"th\" tag.","872fcb21":"![image.png](attachment:image.png)","88e666b8":"1. * click on **ICC Test Championship** on the webpage of Ranking Section **Right Clicking** on the mouse then go to **Inspect Element* see ICC Test Championship is in h3 tag. ","38a62496":"* We can find all h3 tags through **find_all** function.","46bfb489":"##### In this kaggle kernel, I'm going to do web scraping of Website \"https:\/\/www.espncricinfo.com\/\" Page.ESPNcricinfo is a sports news website exclusively for the game of cricket. The site features news, articles, live coverage of cricket matches, and StatsGuru, a database of historical matches and players from the 18th century to the present.I'm going to scrap \"ICC ODI Championship\" Table and \"ICC Twenty20 Rankings\" From Ranking Section.\n","125e4a8f":"* Load in the necessary libraries","2290dd4b":"## Now see data is in list of list foam. Now we can put into Data Frame So that it looks good .","a363f430":" * Find all tables with the help of **find_all** attribute and give class which is mandatory.","29f8a9c3":"**text** function only gives original text remove tags.","09979400":"* There is only one divider in the ranking section.You can check through **Right Clicking** on the mouse then go to **Inspect Element** The great part of Inspect Element is that only highlite that line where you click your cursor.","4f65ba3d":"###  ","f1a5bae5":"### ICC Twenty20 Rankings","b87e106e":"#### Without mentioning table **class** we cannot find the table we want.","70fedc36":"### If your like my notebook.\n### Plz upvoted.","f726a06f":"#### First we find the divider class beacuse can't work without mentioning the class name.**","a4608c52":"#### First we Import all the Important Packages that are required to do Web Scraping.\n\n **Numpy** and **Pandas** are standard and I always import it, who knows when it come handy.\n\n**Request**: It is a Python module that you can use to send all kinds of HTTP requests. It is an easy-to-use library with a lot of features ranging from passing parameters in URLs to sending custom headers and SSL Verification.\n\n**BeautifulSoup** : It is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It saves hours or days of work.","5405b5d4":"* td tag -> stand for table data.\n* th tag -> stand for table header.\n* tr tag -> stand for table row.","f5d4d69c":"### The ODI table is at index 1."}}