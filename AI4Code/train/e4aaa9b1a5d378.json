{"cell_type":{"9bcdb9d4":"code","02d5799c":"code","23402794":"code","a691f3f5":"code","2e8c9364":"code","4842954a":"code","92afdc1e":"code","f7dd6b30":"code","c8590435":"code","8015168e":"code","3714595b":"code","62bbb3e3":"code","5a7ef407":"code","b903d3ba":"code","b8f152cc":"code","f83e0c99":"code","0f291d0f":"code","83bcd858":"code","93f6cc6e":"code","87ca012a":"code","f632124b":"code","7826ae36":"code","0115d3d6":"code","d33644f5":"code","69196ad6":"code","1636d9b9":"markdown","a399f804":"markdown","b2641060":"markdown","c13e7d40":"markdown","61ce3692":"markdown","0841817b":"markdown","873a893b":"markdown","e8767228":"markdown","459576cf":"markdown","b9a2c700":"markdown","61abf1f0":"markdown","bc17004b":"markdown","a4419765":"markdown","b9a1f41d":"markdown"},"source":{"9bcdb9d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02d5799c":"from sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport math\nfrom scipy.stats import norm\n","23402794":"iris = pd.read_csv('..\/input\/iris\/Iris.csv')\n","a691f3f5":"iris.head()","2e8c9364":"iris.shape","4842954a":"iris.describe()","92afdc1e":"iris.info()","f7dd6b30":"target_category = iris[\"Species\"].unique()\ntarget_category=list(map(str,target_category))\nprint(target_category)","c8590435":"iris.groupby(\"Species\").Species.count().plot.bar(ylim=0)","8015168e":"species = iris.Species\ndata = iris.drop(columns=['Species','Id'])  ","3714595b":"data.head()","62bbb3e3":"iris['Category'] = iris['Species'].factorize()[0]\ncategory = iris['Category']\niris.head()","5a7ef407":"#split dataset into test set(20%) and train set(80%) using stratify to split into equal size\ndata_train,data_test,species_train,species_test = train_test_split(data,category, test_size = 0.2, stratify = category,random_state=1)\nprint(np.bincount(species_train))\n","b903d3ba":"newIris = pd.DataFrame(np.column_stack([data_train,species_train]))\n","b8f152cc":"\nsetosa = newIris[newIris[4] == 0]\nversicolor = newIris[newIris[4]==1]       \nvirginica  = newIris[newIris[4]==2] \nnewIris = pd.concat([setosa,versicolor,virginica])\n","f83e0c99":"setosa_data=newIris[0:40] \nversicolor_data=newIris[40:80]\nvirginica_data=newIris[80:120]\n","0f291d0f":"setosa_mean = setosa_data.mean()\nversicolor_mean = versicolor_data.mean()\nvirginica_mean= virginica_data.mean()\n","83bcd858":"    \nsetosa_std = setosa_data.std()\nversicolor_std = versicolor_data.std()\nvirginica_std = virginica_data.std()\n","93f6cc6e":"x =[]\nlikelihood = []\n   \nfor j in range(len(newIris)):\n    distribution = 1\n    if(j<40):\n        mean=setosa_mean\n        std = setosa_std\n    if(j>=40 and j<80):\n        mean=versicolor_mean\n        std = versicolor_std\n    if(j>=80 and j<120):\n        mean=virginica_mean\n        std = virginica_std    \n    \n    for i in range(4):\n        x = newIris.iloc[j] \n        a= ((x[i]- mean[i])**2)\/(2*std[i]**2)\n        b= math.sqrt(2*math.pi*(std[i]**2))\n        y = math.exp(-a)\/b\n        distribution= distribution*y  \n    likelihood.append(distribution)\n    x=[]  \nprint(likelihood)              \n","87ca012a":"setosa_priori = len(setosa_data)\/len(newIris)\nversicolor_priori = len(versicolor_data)\/len(newIris)\nvirginica_priori = len(virginica_data)\/len(newIris)\n\nprint(setosa_priori)\nprint(versicolor_priori)\nprint(virginica_priori) \n","f632124b":"newTest = pd.DataFrame(np.column_stack([data_test,species_test]))\n","7826ae36":"setosa = newTest[newTest[4] == 0]\nversicolor = newTest[newTest[4]==1]       \nvirginica  = newTest[newTest[4]==2] \nnewTest = pd.concat([setosa,versicolor,virginica])\n","0115d3d6":"testLikelihood =[]\nx=[]\ntestPosterior=[]\nposteriorSpecies =[]\n\n\nfor j in range(len(newTest)):\n    for c in range(3): \n        if (c==0):\n            mean = setosa_mean\n            std = setosa_std\n            priori = setosa_priori\n        if (c == 1):\n            mean= versicolor_mean\n            std = versicolor_std\n            priori = versicolor_priori\n        if(c == 2):\n            mean= virginica_mean\n            std = virginica_std\n            priori = virginica_priori\n        distribution = 1       \n        for i in range(4):\n            x = newTest.iloc[j] \n            a= ((x[i]- mean[i])**2)\/(2*std[i]**2)\n            b= math.sqrt(2*math.pi*(std[i]**2))\n            y = math.exp(-a)\/b \n            distribution= distribution*y\n        x=[]    \n        testLikelihood.append(distribution)\n        posterior = testLikelihood[c]* priori    #Calculate poterior values\n        testPosterior.append(posterior)\n        maxPosterior = testPosterior.index(max(testPosterior))   #finds the maximum value\n    posteriorSpecies.append(maxPosterior)\n   \n\n    testLikelihood =[]    \n    testPosterior=[] \n","d33644f5":"\nprint(\"Species of original test data\") \nspecies_test = list(map(int,newTest[4]))\nprint(species_test)\n\nprint(\"Species of Maximum Posterior values\")    \nprint(posteriorSpecies)\n","69196ad6":"similar=0\nfor i in range(len(posteriorSpecies)):\n    if(species_test[i] == posteriorSpecies[i]):\n        similar +=1\naccuracy = similar\/(i+1)*100\n\nprint(accuracy)\n","1636d9b9":"# Rearrange the data into groups based on the species","a399f804":"# find standard diviation","b2641060":"# Sort and rearrange the data based on the species","c13e7d40":"# Find Priori probability","61ce3692":"# Read Dataset","0841817b":"# Data Visualization","873a893b":"# Information about Dataset","e8767228":"# Splits data based on species","459576cf":"# Accuarcy","b9a2c700":"# Split dataset into train\/test","61abf1f0":"# find likelihood for test data","bc17004b":"# Lets check the Differences","a4419765":"# Finding Likelihood ","b9a1f41d":"# find mean"}}