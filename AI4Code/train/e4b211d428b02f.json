{"cell_type":{"0296e85d":"code","51bf2093":"code","5a54fa23":"code","efadaad9":"code","31763d45":"code","e0cccfc6":"code","6b63c04d":"code","23958658":"code","21daccba":"code","3172673a":"code","12a5b87c":"code","9ae5fac3":"code","0ee74677":"markdown","e9a65bbd":"markdown","c8807e6b":"markdown"},"source":{"0296e85d":"# some basic understanding of the data and pre-processing for later functions consumption\nimport os\nprint(os.listdir(\"..\/input\"))","51bf2093":"# image helper functions\ndef get_image_file_path(image_file_name):\n    \"\"\"returns the path of image file\"\"\"\n    return '..\/input\/test\/' + image_file_name\n\ndef get_images(n):\n    \"\"\"reads all the files from `..\/input\/test` directory and returns paths for n files from top\"\"\"\n    all_image_files = os.listdir(\"..\/input\/test\/\")\n    # let's save all these image paths for later\n    image_paths = list(map(get_image_file_path, all_image_files))\n    # rather than using all, we will use a subset of these image paths for working on our model\n    image_paths = image_paths[:n]\n    return image_paths\n\ndef get_image_id_from_path(image_path):\n    \"\"\"returns image id from image path\"\"\"\n    return image_path.split('..\/input\/test\/')[1].split('.jpg')[0]","5a54fa23":"# quick sanity check\nprint(get_images(10))\nprint(get_image_id_from_path(get_images(1)[0]))","efadaad9":"# submission helper functions\ndef get_prediction_string(result):\n    with tf.device('\/device:GPU:0'):\n        \"\"\"from each result, generates the complete prediction string in the format {Label Confidence XMin YMin XMax YMax},{...} based on submission file.\"\"\"\n        prediction_strings = []\n        for index, score in enumerate(result['detection_scores']):\n            index = int(index)\n            single_prediction_string = \"\"\n            single_prediction_string += result['detection_class_names'][index].decode(\"utf-8\") + \" \"  + str(score) + \" \"\n            single_prediction_string += \" \".join(str(x) for x in result['detection_boxes'][index])\n            prediction_strings.append(single_prediction_string)\n\n        prediction_string = \" \".join(str(x) for x in prediction_strings)\n        return prediction_string\n\ndef get_prediction_entry(filepath, result):\n    return {\n        \"ImageID\": get_image_id_from_path(filepath),\n        \"PredictionString\": get_prediction_string(result)\n    }","31763d45":"# For running inference on the TF-Hub module.\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# For downloading the image.\nimport matplotlib.pyplot as plt\nfrom six import BytesIO\n\n# For drawing onto the image.\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n\n# For measuring the inference time.\nimport time\n\n# Check available GPU devices.\nprint(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())","e0cccfc6":"def display_image(image):\n    fig = plt.figure(figsize=(20, 15))\n    plt.grid(False)\n    plt.imshow(image)\n\n\ndef draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color,\n                               font,\n                               thickness=4,\n                               display_str_list=()):\n    \"\"\"Adds a bounding box to an image.\"\"\"\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                  ymin * im_height, ymax * im_height)\n    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n               (left, top)],\n              width=thickness,\n              fill=color)\n\n    # If the total height of the display strings added to the top of the bounding\n    # box exceeds the top of the image, stack the strings below the bounding box\n    # instead of above.\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n    # Each display_str has a top and bottom margin of 0.05x.\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = bottom + total_display_str_height\n    # Reverse list and print from bottom to top.\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n                        (left + text_width, text_bottom)],\n                       fill=color)\n        draw.text((left + margin, text_bottom - text_height - margin),\n                  display_str,\n                  fill=\"black\",\n                  font=font)\n        text_bottom -= text_height - 2 * margin\n\n\ndef draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n    colors = list(ImageColor.colormap.values())\n\n    try:\n        font = ImageFont.truetype(\n            \"\/usr\/share\/fonts\/truetype\/liberation\/LiberationSansNarrow-Regular.ttf\",\n            25)\n    except IOError:\n        print(\"Font not found, using default font.\")\n        font = ImageFont.load_default()\n\n    for i in range(min(boxes.shape[0], max_boxes)):\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                           int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n            draw_bounding_box_on_image(\n                image_pil,\n                ymin,\n                xmin,\n                ymax,\n                xmax,\n                color,\n                font,\n                display_str_list=[display_str])\n            np.copyto(image, np.array(image_pil))\n    return image","6b63c04d":"module_handle = \"https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1\"\nimage_path = \"..\/input\/test\/00000b4dcff7f799.jpg\"\n\nwith tf.device('\/device:GPU:0'):\n    with tf.Graph().as_default():\n        detector = hub.Module(module_handle)\n        image_string_placeholder = tf.placeholder(tf.string)\n        decoded_image = tf.image.decode_jpeg(image_string_placeholder)\n        # Module accepts as input tensors of shape [1, height, width, 3], i.e. batch\n        # of size 1 and type tf.float32.\n        decoded_image_float = tf.image.convert_image_dtype(\n            image=decoded_image, dtype=tf.float32)\n        module_input = tf.expand_dims(decoded_image_float, 0)\n        result = detector(module_input, as_dict=True)\n        init_ops = [tf.global_variables_initializer(), tf.tables_initializer()]\n\n        session = tf.Session()\n        session.run(init_ops)\n\n        # Load the downloaded and resized image and feed into the graph.\n        with tf.gfile.Open(image_path, \"rb\") as binfile:\n            image_string = binfile.read()\n\n        result_out, image_out = session.run(\n            [result, decoded_image],\n            feed_dict={image_string_placeholder: image_string})\n        print(\"Found %d objects.\" % len(result_out[\"detection_scores\"]))","23958658":"# see the sample image with bounding boxes\nimage_with_boxes = draw_boxes(\n    np.array(image_out), result_out[\"detection_boxes\"],\n    result_out[\"detection_class_entities\"], result_out[\"detection_scores\"])\ndisplay_image(image_with_boxes)","21daccba":"image_paths = get_images(10)\npredictions = []\n\nwith tf.device('\/device:GPU:0'):\n    for image_path in image_paths:\n        with tf.gfile.Open(image_path, \"rb\") as binfile:\n            image_string = binfile.read()\n\n        inference_start_time = time.clock()\n        result_out, image_out = session.run(\n            [result, decoded_image],\n            feed_dict={image_string_placeholder: image_string})\n        predictions.append(get_prediction_entry(image_path, result_out))\n        print(f'For {image_path} found objects in {time.clock() - inference_start_time} seconds')","3172673a":"predictions_df = pd.DataFrame(predictions)\npredictions_df","12a5b87c":"submission_df = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission_df.update(predictions_df)","9ae5fac3":"# NOTE: this is only on a subset of data\nsubmission_df.to_csv('.\/10_values_submission.csv', index=False)","0ee74677":"**Helper functions**","e9a65bbd":"**More Helper functions for visualization of results**\n\nVisualization code adapted from TF object detection API for the simplest required functionality.","c8807e6b":"Baseline predictions using [TFHub](https:\/\/tfhub.dev\/google\/faster_rcnn\/openimages_v4\/inception_resnet_v2\/1)"}}