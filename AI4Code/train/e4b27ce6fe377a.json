{"cell_type":{"95b0597a":"code","5bfa4cab":"code","38a951c0":"code","b5cb9be8":"code","68d57d98":"code","f270a139":"code","06ffa80b":"code","f3ced078":"code","7b63f0d0":"code","e46d3560":"code","7e0dc012":"code","710b21e1":"code","d13cfed0":"code","8c0be841":"code","422ccef5":"code","7fd9560b":"code","749f37f5":"code","73bb8f16":"code","2796c40c":"code","d022c93a":"code","a97e6da8":"code","3c8b4b1f":"code","d0bd5faf":"code","db27073c":"code","9a404be1":"code","d3ccd01b":"code","355d59d4":"markdown","e8aba012":"markdown","783e2ac7":"markdown","ceefdf4e":"markdown","70d9c8b3":"markdown","b92f5708":"markdown","7d18b500":"markdown","d6e472fd":"markdown","0b73d997":"markdown","b1fa5976":"markdown","c5632ad4":"markdown","bc4a8028":"markdown","1d4ef6d9":"markdown","9ab9e25a":"markdown","5bd2ecb2":"markdown","792ff090":"markdown","d64629ad":"markdown","c1138223":"markdown","a6c31830":"markdown"},"source":{"95b0597a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom scipy.integrate import solve_ivp\nimport numpy\nimport datetime\nfrom datetime import timedelta\n\n%matplotlib inline","5bfa4cab":"# Function code refernece from https:\/\/www.kaggle.com\/anjum48\/seir-model-with-intervention\n\n# Susceptible equation\ndef dS_dt(S, I, R_t, T_inf):\n    return -(R_t \/ T_inf) * I * S\n\n# Exposed equation\ndef dE_dt(S, E, I, R_t, T_inf, T_inc):\n    return (R_t \/ T_inf) * I * S - (T_inc**-1) * E\n\n# Infected equation\ndef dI_dt(I, E, T_inc, T_inf):\n    return (T_inc**-1) * E - (T_inf**-1) * I\n\n# Recovered\/Remove\/deceased equation\ndef dR_dt(I, T_inf):\n    return (T_inf**-1) * I\n\ndef SEIR_model(t, y, R_t, T_inf, T_inc):\n    \n    if callable(R_t):\n        reproduction = R_t(t)\n    else:\n        reproduction = R_t\n        \n    S, E, I, R = y\n    \n    S_out = dS_dt(S, I, reproduction, T_inf)\n    E_out = dE_dt(S, E, I, reproduction, T_inf, T_inc)\n    I_out = dI_dt(I, E, T_inc, T_inf)\n    R_out = dR_dt(I, T_inf)\n    \n    return [S_out, E_out, I_out, R_out]","38a951c0":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/train.csv')\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/test.csv')\ntrain['Date_datetime'] = train['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))","b5cb9be8":"pop_info = pd.read_csv('\/kaggle\/input\/covid19-population-data\/population_data.csv')\ncountry_pop = pop_info.query('Type == \"Country\/Region\"')\nprovince_pop = pop_info.query('Type == \"Province\/State\"')\ncountry_lookup = dict(zip(country_pop['Name'], country_pop['Population']))\nprovince_lookup = dict(zip(province_pop['Name'], province_pop['Population']))","68d57d98":"def plot_model_and_predict(data, pop, solution, title='SEIR model'):\n    sus, exp, inf, rec = solution.y\n    \n    f = plt.figure(figsize=(16,5))\n    ax = f.add_subplot(1,2,1)\n    #ax.plot(sus, 'b', label='Susceptible');\n    ax.plot(exp, 'y', label='Exposed');\n    ax.plot(inf, 'r', label='Infected');\n    ax.plot(rec, 'c', label='Recovered\/deceased');\n    plt.title(title)\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.ylabel(\"Fraction of population\", fontsize=10);\n    plt.legend(loc='best');\n    \n    ax2 = f.add_subplot(1,2,2)\n    preds = np.clip((inf + rec) * pop ,0,np.inf)\n    ax2.plot(range(len(data)),preds[:len(data)],label = 'Predict ConfirmedCases')\n    ax2.plot(range(len(data)),data['ConfirmedCases'])\n    plt.title('Model predict and data')\n    plt.ylabel(\"Population\", fontsize=10);\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.legend(loc='best');","f270a139":"Country = 'Hubei'\nN = pop_info[pop_info['Name']==Country]['Population'].tolist()[0] # Hubei Population \n\n# Load dataset of Hubei\ntrain_loc = train[train['Country_Region']==Country].query('ConfirmedCases > 0')\nif len(train_loc)==0:\n    train_loc = train[train['Province_State']==Country].query('ConfirmedCases > 0')\n\nn_infected = train_loc['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\nmax_days = len(train_loc)# how many days want to predict\n\n# Initial stat for SEIR model\ns = (N - n_infected)\/ N\ne = 0.\ni = n_infected \/ N\nr = 0.\n\n# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9 # average infectious period\nR_0 = 3.954 # reproduction number\n\n## Solve the SEIR model \nsol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(R_0, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\n## Plot result\nplot_model_and_predict(train_loc, N, sol, title = 'SEIR Model (without intervention)')","06ffa80b":"# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9  # average infectious period\n\n# Define the intervention parameters (fit result, latter will show how to fit)\nR_0, cfr, k, L=[ 3.95469597 , 0.04593316 , 3.      ,   15.32328881]\n\ndef time_varying_reproduction(t): \n    return R_0 \/ (1 + (t\/L)**k)\n\nsol2 = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\nplot_model_and_predict(train_loc, N, sol2, title = 'SEIR Model (with intervention)')","f3ced078":"from scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error","7b63f0d0":"def cumsum_signal(vec):\n    temp_val = 0\n    vec_new = []\n    for i in vec:\n        if i > temp_val:\n            vec_new.append(i)\n            temp_val = i\n        else:\n            vec_new.append(temp_val)\n    return vec_new","e46d3560":"# Use a constant reproduction number\ndef eval_model_const(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # R0 become half after intervention days\n    def time_varying_reproduction(t):\n        if t > 80: # we set intervention days = 80\n            return R_0 * 0.5\n        else:\n            return R_0\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","7e0dc012":"# Use a Hill decayed reproduction number\ndef eval_model_decay(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr, k, L = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions   \n    # Hill decay. Initial values: R_0=2.2, k=2, L=50\n    def time_varying_reproduction(t): \n        return R_0 \/ (1 + (t\/L)**k)\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","710b21e1":"from matplotlib import dates\nimport plotly.graph_objects as go\n\ndef fit_model_new(data, area_name, initial_guess=[2.2, 0.02, 2, 50], \n              bounds=((1, 20), (0, 0.15), (1, 3), (1, 100)), make_plot=True, decay_mode = None):\n    \n    if area_name in ['France']:# France last data looks weird, remove it\n        train_data = data.query('ConfirmedCases > 0').copy()[:-1]\n    else:\n        train_data = data.query('ConfirmedCases > 0').copy()\n        \n    ####### If this country have no ConfirmedCase, return 0 #######\n    if len(train_data) == 0:\n        result_zero = np.zeros((43))\n        return pd.DataFrame({'ConfirmedCases':result_zero,'Fatalities':result_zero}), 0 \n    \n    ####### Load the population of area #######\n    try:\n        #population = province_lookup[area_name]\n        population = pop_info[pop_info['Name']==area_name]['Population'].tolist()[0]\n    except IndexError:\n        print ('country not in population set, '+str(area_name))\n        population = 1000000 \n    \n    \n    if area_name == 'US':\n        population = 327200000\n        \n    cases_per_million = train_data['ConfirmedCases'].max() * 10**6 \/ population\n    n_infected = train_data['ConfirmedCases'].iloc[0]\n    \n    ####### Total case\/popuplation below 1, reduce country population #######\n    if cases_per_million < 1:\n        #print ('reduce pop divide by 100')\n        population = population\/100\n        \n    ####### Fit the real data by minimize the MSLE #######\n    res_const = minimize(eval_model_const, [2.2, 0.02], bounds=((1, 20), (0, 0.15)),\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n\n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    ####### Align the date information #######\n    test_end = datetime.datetime.strptime('2020-04-30','%Y-%m-%d')\n    test_start = datetime.datetime.strptime('2020-03-12','%Y-%m-%d')\n    train_max = train_data.Date_datetime.max()\n    train_min = train_data.Date_datetime.min()\n    add_date = 0\n    delta_days =(test_end - train_max).days\n    train_add_time=[]\n\n    if train_min > test_start:\n        add_date = (train_min-test_start).days\n        last = train_min-timedelta(add_date)\n        train_add_time = np.arange(last, train_min, dtype='datetime64[D]').tolist()\n        train_add_time = pd.to_datetime(train_add_time)\n        dates_all = train_add_time.append(pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]')))\n    else:\n        dates_all = pd.to_datetime(np.arange(train_min, test_end+timedelta(1), dtype='datetime64[D]'))\n\n\n    ####### Auto find the best decay function ####### \n    if decay_mode is None:\n        if res_const.fun < res_decay.fun :\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n    else:\n        if decay_mode =='day_decay':\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n\n    ####### Predict the result by using best fit paramater of SEIR model ####### \n    sus, exp, inf, rec = sol.y\n    \n    y_pred = pd.DataFrame({\n        'ConfirmedCases': cumsum_signal((np.clip((inf + rec) * population,0,np.inf)).tolist()),\n       # 'ConfirmedCases': [inf[0]*population for i in range(add_date)]+(np.clip((inf + rec) * population,0,np.inf)).tolist(),\n       # 'Fatalities': [rec[0]*population for i in range(add_date)]+(np.clip(rec, 0, np.inf) * population * res.x[1]).tolist()\n        'Fatalities': cumsum_signal((np.clip(rec * population * res.x[1], 0, np.inf)).tolist())\n    })\n\n    y_pred_valid = y_pred.iloc[:len(train_data)]\n    y_pred_test = y_pred.iloc[-43:]\n    y_true_valid = train_data[['ConfirmedCases', 'Fatalities']]\n    \n    ####### Calculate MSLE ####### \n    valid_msle_cases = mean_squared_log_error(y_true_valid['ConfirmedCases'], y_pred_valid['ConfirmedCases'])\n    valid_msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid['Fatalities'])\n    valid_msle = np.mean([valid_msle_cases, valid_msle_fat])\n    \n    ####### Plot the fit result of train data and forecast after 300 days ####### \n    if make_plot:\n        if len(res.x)<=2:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using intervention days decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}')\n        else:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using Hill decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}, K : {res.x[2]:0.5f}, L: {res.x[3]:0.5f}')\n        \n        ####### Plot the fit result of train data dna SEIR model trends #######\n\n        f = plt.figure(figsize=(16,5))\n        ax = f.add_subplot(1,2,1)\n        ax.plot(exp, 'y', label='Exposed');\n        ax.plot(inf, 'r', label='Infected');\n        ax.plot(rec, 'c', label='Recovered\/deceased');\n        plt.title('SEIR Model Trends')\n        plt.xlabel(\"Days\", fontsize=10);\n        plt.ylabel(\"Fraction of population\", fontsize=10);\n        plt.legend(loc='best');\n        \n        #train_date_remove_year = train_data['Date_datetime'].apply(lambda date:'{:%m-%d}'.format(date))\n        ax2 = f.add_subplot(1,2,2)\n        xaxis = train_data['Date_datetime'].tolist()\n        xaxis = dates.date2num(xaxis)\n        hfmt = dates.DateFormatter('%m\\n%d')\n        ax2.xaxis.set_major_formatter(hfmt)\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'),train_data['ConfirmedCases'],label='Confirmed Cases (train)', c='g')\n        ax2.plot(np.array(train_data['Date_datetime'], dtype='datetime64[D]'), y_pred['ConfirmedCases'][:len(train_data)],label='Cumulative modeled infections', c='r')\n        plt.title('Real ConfirmedCase and Predict ConfirmedCase')\n        plt.legend(loc='best');\n        plt.show()\n            \n        ####### Forecast 300 days after by using the best paramater of train data #######\n        if len(res.x)>2:\n            msle, sol = eval_model_decay(res.x, train_data, population, True, 300)\n        else:\n            msle, sol = eval_model_const(res.x, train_data, population, True, 300)\n        \n        sus, exp, inf, rec = sol.y\n        \n        y_pred = pd.DataFrame({\n            'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n            'Fatalities': cumsum_signal(np.clip(rec, 0, np.inf) * population * res.x[1])\n        })\n        \n        ####### Plot 300 days after of each country #######\n        start = train_min\n        end = start + timedelta(len(y_pred))\n        time_array = np.arange(start, end, dtype='datetime64[D]')\n\n        max_day = numpy.where(inf == numpy.amax(inf))[0][0]\n        where_time = time_array[max_day]\n        pred_max_day = y_pred['ConfirmedCases'][max_day]\n        xy_show_max_estimation = (where_time, max_day)\n        \n        con = y_pred['ConfirmedCases']\n        max_day_con = numpy.where(con == numpy.amax(con))[0][0] # Find the max confimed case of each country\n        max_con = numpy.amax(con)\n        where_time_con = time_array[len(time_array)-50]\n        xy_show_max_estimation_confirmed = (where_time_con, max_con)\n        \n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['ConfirmedCases'].astype(int),\n                            mode='lines',\n                            line = dict(color='red'),\n                            name='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        fig.add_trace(go.Scatter(x=time_array[:len(train_data)], y=train_data['ConfirmedCases'],\n                            mode='lines',\n                            name='Confirmed case until '+ str(train_max.date()),line = dict(color='green', width=4)))\n        fig.add_annotation(\n            x=where_time_con,\n            y=max_con-(max_con\/30),\n            showarrow=False,\n            text=\"Estimate Max Case around:\" +str(int(max_con)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=time_array[len(train_data)-1],\n            y=train_data['ConfirmedCases'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max ConfirmedCase: \" +str(int(train_data['ConfirmedCases'].tolist()[-1]))) \n        \n        fig.add_annotation(\n            x=where_time,\n            y=pred_max_day,\n            text='Infect start decrease from: ' + str(where_time))   \n        fig.update_layout(title='Estimate Confirmed Case ,'+area_name+' Total population ='+ str(int(population)), legend_orientation=\"h\")\n        fig.show()\n        \n        #df = pd.DataFrame({'Values': train_data['ConfirmedCases'].tolist()+y_pred['ConfirmedCases'].tolist(),'Date_datatime':time_array[:len(train_data)].tolist()+time_array.tolist(),\n        #           'Real\/Predict': ['ConfirmedCase' for i in range(len(train_data))]+['PredictCase' for i in range(len(y_pred))]})\n        #fig = px.line(df, x=\"Date_datatime\", y=\"Values\",color = 'Real\/Predict')\n        #fig.show()\n        #plt.figure(figsize = (16,7))\n        #plt.plot(time_array[:len(train_data)],train_data['ConfirmedCases'],label='Confirmed case until '+ str(train_max.date()),color='g', linewidth=3.0)\n        #plt.plot(time_array,y_pred['ConfirmedCases'],label='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date()),color='r', linewidth=1.0)\n        #plt.annotate('Infect start decrease from: ' + str(where_time), xy=xy_show_max_estimation, size=15, color=\"black\")\n        #plt.annotate('max Confirmedcase: ' + str(int(max_con)), xy=xy_show_max_estimation_confirmed, size=15, color=\"black\")\n        #plt.title('Estimate Confirmed Case '+area_name+' Total population ='+ str(int(population)))\n        #plt.legend(loc='lower right')\n        #plt.show()\n\n\n    return y_pred_test, valid_msle","d13cfed0":"country = 'Taiwan*'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","8c0be841":"country = 'Korea, South'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","422ccef5":"country = 'Japan'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","7fd9560b":"country = 'Italy'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","749f37f5":"country = 'New York'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","73bb8f16":"country = 'US'\ncountry_pd_train = train[train['Country_Region']==country]\ncountry_pd_train2 = country_pd_train.groupby(['Date']).sum().reset_index()\ncountry_pd_train2['Date_datetime'] = country_pd_train2['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\na,b = fit_model_new(country_pd_train2,country,make_plot=True)","2796c40c":"import numpy\nvalidation_scores = []\nvalidation_county = []\nvalidation_country = []\nfor country in tqdm(train['Country_Region'].unique()):\n    country_pd_train = train[train['Country_Region']==country]\n    #if country_pd_train['Province_State'].isna().unique()==True:\n    if len(country_pd_train['Province_State'].unique())<2:\n        predict_test, score = fit_model_new(country_pd_train,country,make_plot=False)\n        if score ==0:\n            print(f'{country} no case')\n        validation_scores.append(score)\n        validation_county.append(country)\n        validation_country.append(country)\n        test.loc[test['Country_Region']==country,'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n        test.loc[test['Country_Region']==country,'Fatalities'] = predict_test['Fatalities'].tolist()\n    else:\n        for state in country_pd_train['Province_State'].unique():\n            if state != state: # check nan\n                state_pd = country_pd_train[country_pd_train['Province_State'].isna()]\n                predict_test, score = fit_model_new(state_pd,state,make_plot=False)\n                if score ==0:\n                    print(f'{country} \/ {state} no case')\n                validation_scores.append(score)\n                validation_county.append(state)\n                validation_country.append(country)\n                test.loc[(test['Country_Region']==country)&(test['Province_State'].isna()),'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n                test.loc[(test['Country_Region']==country)&(test['Province_State'].isna()),'Fatalities'] = predict_test['Fatalities'].tolist()\n            else:\n                state_pd = country_pd_train[country_pd_train['Province_State']==state]\n                predict_test, score = fit_model_new(state_pd,state,make_plot=False)\n                if score ==0:\n                    print(f'{country} \/ {state} no case')\n                validation_scores.append(score)\n                validation_county.append(state)\n                validation_country.append(country)\n                test.loc[(test['Country_Region']==country)&(test['Province_State']==state),'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n                test.loc[(test['Country_Region']==country)&(test['Province_State']==state),'Fatalities'] = predict_test['Fatalities'].tolist()\n         #   print(f'{country} {state} {score:0.5f}')\n            \nprint(f'Mean validation score: {np.average(validation_scores):0.5f}')","d022c93a":"validation_scores = pd.DataFrame({'country\/state':validation_country,'country':validation_county,'MSLE':validation_scores})\nvalidation_scores.sort_values(by=['MSLE'], ascending=False).head(20)","a97e6da8":"large_msle = validation_scores[validation_scores['MSLE']>1]","3c8b4b1f":"from sklearn import linear_model\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\n\nfor country in large_msle['country'].unique():\n    if (country!= country)==False: # check None\n        #print ('training model for country ==>'+country)\n        country_pd_train = train[train['Country_Region']==country]\n        country_pd_test = test[test['Country_Region']==country]\n        if len(country_pd_train)==0:\n            country_pd_train = train[train['Province_State']==country]\n            country_pd_test = test[test['Province_State']==country]\n\n            x = np.array(range(len(country_pd_train))).reshape((-1,1))\n            y = country_pd_train['ConfirmedCases']\n            y_fat = country_pd_train['ConfirmedCases']\n\n            model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model = model.fit(x, y)\n\n            model_fat = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model_fat = model_fat.fit(x, y_fat)\n\n            predict_y = model.predict(x)\n            predict_yfat = model_fat.predict(x)\n            score = mean_squared_log_error(np.clip(y,0,np.inf), np.clip(predict_y,0,np.inf))\n            score_fat = mean_squared_log_error(np.clip(y_fat,0,np.inf), np.clip(predict_yfat,0,np.inf))\n            score = (score+score_fat)\/2\n\n            print(f'{country} {score:0.5f}')\n            if score < large_msle[large_msle['country']==country]['MSLE'].tolist()[0]:\n                validation_scores.loc[validation_scores['country']==country,'MSLE'] = score\n                predict_x = (np.array(range(len(country_pd_test)))+50).reshape((-1,1))\n                test.loc[test['Province_State']==country,'ConfirmedCases'] = model.predict(predict_x)\n        else:\n            x = np.array(range(len(country_pd_train))).reshape((-1,1))\n            y = country_pd_train['ConfirmedCases']\n            y_fat = country_pd_train['ConfirmedCases']\n\n            model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model = model.fit(x, y)\n\n            model_fat = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model_fat = model_fat.fit(x, y_fat)\n\n            predict_y = model.predict(x)\n            predict_yfat = model_fat.predict(x)\n            score = mean_squared_log_error(np.clip(y,0,np.inf), np.clip(predict_y,0,np.inf))\n            score_fat = mean_squared_log_error(np.clip(y_fat,0,np.inf), np.clip(predict_yfat,0,np.inf))\n            score = (score+score_fat)\/2\n\n            print(f'{country} {score:0.5f}')\n            if score < large_msle[large_msle['country']==country]['MSLE'].tolist()[0]:\n                validation_scores.loc[validation_scores['country']==country,'MSLE'] = score\n                predict_x = (np.array(range(len(country_pd_test)))+50).reshape((-1,1))\n                test.loc[test['Country_Region']==country,'ConfirmedCases'] = model.predict(predict_x)","d0bd5faf":"submit = pd.read_csv('..\/input\/covid19-global-forecasting-week-2\/submission.csv')\nsubmit['Fatalities'] = test['Fatalities'].astype('float')\nsubmit['ConfirmedCases'] = test['ConfirmedCases'].astype('float')\n#submit.to_csv('submission.csv',index=False)","db27073c":"submit.head()","9a404be1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom scipy.optimize import curve_fit\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n\n%matplotlib inline\ndpi = 96\nplt.rcParams['figure.figsize'] = (1600\/dpi, 600\/dpi)\nplt.style.use('ggplot')\n\n# grabbing prepared dataset from https:\/\/www.kaggle.com\/jorijnsmit\/population-and-sub-continent-for-every-entity\ncovid = pd.read_csv('..\/input\/covid19\/covid.csv', parse_dates=['date'])\n\n# perform same manipulations from the prepared dataset to the test set\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-2\/test.csv', parse_dates=['Date'])\ntest.columns = ['id', 'province_state', 'country_region', 'date']\ntest['country_region'].update(test['country_region'].str.replace('Georgia', 'Sakartvelo'))\ntest['entity'] = test['province_state'].where(~test['province_state'].isna(), test['country_region'])\ntest = test.set_index('id')[['date', 'entity']]\n\ndef logistic(t, k, r, a):\n    \"\"\"k > 0: final epidemic size\n    r > 0: infection rate\n    a = (k - c_0) \/ c_0\n    \"\"\"\n    \n    return k \/ (1 + a * np.exp(-r * t))\n\ndef solve(c):\n    \"\"\"port from https:\/\/mathworks.com\/matlabcentral\/fileexchange\/74411-fitvirus\"\"\"\n    \n    n = len(c)\n    nmax = max(1, n \/\/ 2)\n\n    for i in np.arange(1, nmax+1):\n        k1 = i\n        k3 = n - 1\n        if (n - i) % 2 == 0:\n            k3 -= 1\n\n        k2 = (k1 + k3) \/\/ 2\n        m = k2 - k1 - 1\n\n        if k1 < 1 or k2 < 1 or k3 < 1 or m < 1:\n            return None\n\n        k1 -= 1\n        k2 -= 1\n        k3 -= 1\n\n        # calculate k\n        v = c[k1] * c[k2] - 2 * c[k1] * c[k3] + c[k2] * c[k3]\n        if v <= 0:\n            continue\n        w = c[k2]**2 - c[k3] * c[k1]\n        if w <= 0:\n            continue\n        k = c[k2] * v \/ w\n        if k <= 0:\n            continue\n\n        # calculate r\n        x = c[k3] * (c[k2] - c[k1])\n        if x <= 0:\n            continue\n        y = c[k1] * (c[k3] - c[k2])\n        if y <= 0:\n            continue\n        r = (1 \/ m) * np.log(x \/ y)\n        if r <= 0:\n            continue\n\n        # calculate a\n        z = ((c[k3] - c[k2]) * (c[k2] - c[k1])) \/ w\n        if z <= 0:\n            continue\n        a = z * (x \/ y) ** ((k3 + 1 - m) \/ m)\n        if a <= 0:\n            continue\n        \n        return k, r, a\n\ndef plot_fit(x_train, y_train, x_predict, y_predict, r2):\n    fig, ax = plt.subplots()\n    ax.set_title(f'{subject} {r2}')\n    color = 'green' if r2 > 0.99 else 'red'\n    pd.Series(y_train, x_train).plot(subplots=True, style='.', color='black', legend=True, label='train')\n    pd.Series(y_predict, x_predict).plot(subplots=True, style=':', color=color, legend=True, label='predict')\n    plt.show()\n\nherd_immunity = 0.7\ntest_ratio = 0.2\n\nfor target in ['confirmed', 'fatal']:\n    for subject in tqdm(covid['entity'].unique()):\n        population = covid[covid['entity'] == subject]['population'].max()\n\n        x_train = covid[covid['entity'] == subject]['date'].dt.dayofyear.values\n        y_train = covid[covid['entity'] == subject][target].values\n\n        mask = y_train > 0\n        x_train_m = x_train[mask]\n        y_train_m = y_train[mask]\n        \n        # no point in modelling a single point or no ints at all\n        if x_train_m.size < 2 or x_train_m.sum() == 0:\n            continue\n\n        x_predict = test[test['entity'] == subject]['date'].dt.dayofyear.values\n        submission_size = x_predict.size\n        # start calculating sigmoid at same point x_train_m starts\n        x_predict = np.arange(start=x_train_m[0], stop=x_predict[-1]+1)\n\n        params = solve(y_train_m)\n\n        if params != None:\n        #try:\n            params = (max(params[0], max(y_train_m)), params[1], params[2])\n            lower_bounds = (max(y_train_m), 0, 0)\n            upper_bounds = (max(population * herd_immunity * test_ratio, params[0]), np.inf, np.inf)\n\n            params, _ = curve_fit(\n                logistic,\n                np.arange(x_train_m.size),\n                y_train_m,\n                p0=params,\n                bounds=(lower_bounds, upper_bounds),\n                maxfev=100000\n            )\n\n            y_eval = logistic(np.arange(x_train_m.size), params[0], params[1], params[2])\n            y_predict = logistic(np.arange(x_predict.size), params[0], params[1], params[2])\n\n            r2 = r2_score(y_train_m, y_eval)\n            covid.loc[covid['entity'] == subject, f'log_{target}'] = r2\n\n        else:\n            # we fit a polynomial instead\n            # while forcing cumulative behaviour, i.e. never lower numbers\n            # it's ugly\n            # i know\n\n            model = linear_model.LinearRegression()\n#             model = Pipeline([\n#                 (\"polynomial_features\", PolynomialFeatures(degree=2)), \n#                 (\"linear_regression\", linear_model.Ridge())\n#             ])\n            if target == 'fatal':\n                # pass more features; including confirmed!\n                pass\n            model.fit(x_train_m.reshape(-1, 1), y_train_m)\n\n            y_eval = model.predict(x_train_m.reshape(-1, 1))\n            y_predict = model.predict(x_predict.reshape(-1, 1))\n            y_predict = np.maximum.accumulate(y_predict)\n\n            r2 = r2_score(y_train_m, y_eval)\n            covid.loc[covid['entity'] == subject, f'poly_{target}'] = r2\n\n        if target == 'confirmed' and subject in ['Hubei', 'Italy', 'New York']:\n            plot_fit(x_train, y_train, x_predict, y_predict, r2)\n\n        # assign the prediction to the test dataframe\n        delta = submission_size - y_predict.size\n        if delta > 0:\n            filler = [100] * delta if target == 'confirmed' else [1] * delta\n            y_predict = filler + y_predict.tolist()\n        test.loc[test['entity'] == subject, target] = y_predict[-submission_size:]\n\n# resulting R2 scores for logistic approach\nfor target in ['confirmed', 'fatal']:\n    r2s = covid.groupby('entity')[f'log_{target}'].max()\n    print(r2s.describe())\n    print(r2s[r2s.isna()].index)\n\n# any doubtful maxima due to regression?\nfor target in ['confirmed', 'fatal']:\n    df = []\n    for subject in covid.loc[covid[f'poly_{target}'].isna()]['entity'].unique():\n        df.append(test[test['entity'] == subject][['entity', target]].max().to_dict())\n    df = pd.DataFrame(df).set_index('entity')\n    print(df[target].sort_values(ascending=False).fillna(0).astype('int').head(10))\n    \n# @TODO\n# some are way too high; this is a problem!\n# what are the parameters they are fitted on?\n\n# sanity check before submitting\nsubmission = test[['entity', 'date']].copy()\nsubmission[['confirmed', 'fatal']] = test[['confirmed', 'fatal']].fillna(0).astype('int')\nsubmission[submission['entity'] == 'Netherlands']\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom scipy.optimize import curve_fit\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n\n%matplotlib inline\ndpi = 96\nplt.rcParams['figure.figsize'] = (1600\/dpi, 600\/dpi)\nplt.style.use('ggplot')\n\n# grabbing prepared dataset from https:\/\/www.kaggle.com\/jorijnsmit\/population-and-sub-continent-for-every-entity\ncovid = pd.read_csv('..\/input\/covid19\/covid.csv', parse_dates=['date'])\n\n# perform same manipulations from the prepared dataset to the test set\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-2\/test.csv', parse_dates=['Date'])\ntest.columns = ['id', 'province_state', 'country_region', 'date']\ntest['country_region'].update(test['country_region'].str.replace('Georgia', 'Sakartvelo'))\ntest['entity'] = test['province_state'].where(~test['province_state'].isna(), test['country_region'])\ntest = test.set_index('id')[['date', 'entity']]\n\ndef logistic(t, k, r, a):\n    \"\"\"k > 0: final epidemic size\n    r > 0: infection rate\n    a = (k - c_0) \/ c_0\n    \"\"\"\n    \n    return k \/ (1 + a * np.exp(-r * t))\n\ndef solve(c):\n    \"\"\"port from https:\/\/mathworks.com\/matlabcentral\/fileexchange\/74411-fitvirus\"\"\"\n    \n    n = len(c)\n    nmax = max(1, n \/\/ 2)\n\n    for i in np.arange(1, nmax+1):\n        k1 = i\n        k3 = n - 1\n        if (n - i) % 2 == 0:\n            k3 -= 1\n\n        k2 = (k1 + k3) \/\/ 2\n        m = k2 - k1 - 1\n\n        if k1 < 1 or k2 < 1 or k3 < 1 or m < 1:\n            return None\n\n        k1 -= 1\n        k2 -= 1\n        k3 -= 1\n\n        # calculate k\n        v = c[k1] * c[k2] - 2 * c[k1] * c[k3] + c[k2] * c[k3]\n        if v <= 0:\n            continue\n        w = c[k2]**2 - c[k3] * c[k1]\n        if w <= 0:\n            continue\n        k = c[k2] * v \/ w\n        if k <= 0:\n            continue\n\n        # calculate r\n        x = c[k3] * (c[k2] - c[k1])\n        if x <= 0:\n            continue\n        y = c[k1] * (c[k3] - c[k2])\n        if y <= 0:\n            continue\n        r = (1 \/ m) * np.log(x \/ y)\n        if r <= 0:\n            continue\n\n        # calculate a\n        z = ((c[k3] - c[k2]) * (c[k2] - c[k1])) \/ w\n        if z <= 0:\n            continue\n        a = z * (x \/ y) ** ((k3 + 1 - m) \/ m)\n        if a <= 0:\n            continue\n        \n        return k, r, a\n\ndef plot_fit(x_train, y_train, x_predict, y_predict, r2):\n    fig, ax = plt.subplots()\n    ax.set_title(f'{subject} {r2}')\n    color = 'green' if r2 > 0.99 else 'red'\n    pd.Series(y_train, x_train).plot(subplots=True, style='.', color='black', legend=True, label='train')\n    pd.Series(y_predict, x_predict).plot(subplots=True, style=':', color=color, legend=True, label='predict')\n    plt.show()\n\nherd_immunity = 0.7\ntest_ratio = 0.2\n\nfor target in ['confirmed', 'fatal']:\n    for subject in tqdm(covid['entity'].unique()):\n        population = covid[covid['entity'] == subject]['population'].max()\n\n        x_train = covid[covid['entity'] == subject]['date'].dt.dayofyear.values\n        y_train = covid[covid['entity'] == subject][target].values\n\n        mask = y_train > 0\n        x_train_m = x_train[mask]\n        y_train_m = y_train[mask]\n        \n        # no point in modelling a single point or no ints at all\n        if x_train_m.size < 2 or x_train_m.sum() == 0:\n            continue\n\n        x_predict = test[test['entity'] == subject]['date'].dt.dayofyear.values\n        submission_size = x_predict.size\n        # start calculating sigmoid at same point x_train_m starts\n        x_predict = np.arange(start=x_train_m[0], stop=x_predict[-1]+1)\n\n        params = solve(y_train_m)\n\n        if params != None:\n        #try:\n            params = (max(params[0], max(y_train_m)), params[1], params[2])\n            lower_bounds = (max(y_train_m), 0, 0)\n            upper_bounds = (max(population * herd_immunity * test_ratio, params[0]), np.inf, np.inf)\n\n            params, _ = curve_fit(\n                logistic,\n                np.arange(x_train_m.size),\n                y_train_m,\n                p0=params,\n                bounds=(lower_bounds, upper_bounds),\n                maxfev=100000\n            )\n\n            y_eval = logistic(np.arange(x_train_m.size), params[0], params[1], params[2])\n            y_predict = logistic(np.arange(x_predict.size), params[0], params[1], params[2])\n\n            r2 = r2_score(y_train_m, y_eval)\n            covid.loc[covid['entity'] == subject, f'log_{target}'] = r2\n\n        else:\n            # we fit a polynomial instead\n            # while forcing cumulative behaviour, i.e. never lower numbers\n            # it's ugly\n            # i know\n\n            model = linear_model.LinearRegression()\n#             model = Pipeline([\n#                 (\"polynomial_features\", PolynomialFeatures(degree=2)), \n#                 (\"linear_regression\", linear_model.Ridge())\n#             ])\n            if target == 'fatal':\n                # pass more features; including confirmed!\n                pass\n            model.fit(x_train_m.reshape(-1, 1), y_train_m)\n\n            y_eval = model.predict(x_train_m.reshape(-1, 1))\n            y_predict = model.predict(x_predict.reshape(-1, 1))\n            y_predict = np.maximum.accumulate(y_predict)\n\n            r2 = r2_score(y_train_m, y_eval)\n            covid.loc[covid['entity'] == subject, f'poly_{target}'] = r2\n\n        if target == 'confirmed' and subject in ['Hubei', 'Italy', 'New York']:\n            plot_fit(x_train, y_train, x_predict, y_predict, r2)\n\n        # assign the prediction to the test dataframe\n        delta = submission_size - y_predict.size\n        if delta > 0:\n            filler = [100] * delta if target == 'confirmed' else [1] * delta\n            y_predict = filler + y_predict.tolist()\n        test.loc[test['entity'] == subject, target] = y_predict[-submission_size:]\n\n# resulting R2 scores for logistic approach\nfor target in ['confirmed', 'fatal']:\n    r2s = covid.groupby('entity')[f'log_{target}'].max()\n    print(r2s.describe())\n    print(r2s[r2s.isna()].index)\n\n# any doubtful maxima due to regression?\nfor target in ['confirmed', 'fatal']:\n    df = []\n    for subject in covid.loc[covid[f'poly_{target}'].isna()]['entity'].unique():\n        df.append(test[test['entity'] == subject][['entity', target]].max().to_dict())\n    df = pd.DataFrame(df).set_index('entity')\n    print(df[target].sort_values(ascending=False).fillna(0).astype('int').head(10))\n    \n# @TODO\n# some are way too high; this is a problem!\n# what are the parameters they are fitted on?\n\n# sanity check before submitting\nsubmission = test[['entity', 'date']].copy()\nsubmission[['confirmed', 'fatal']] = test[['confirmed', 'fatal']].fillna(0).astype('int')\nsubmission[submission['entity'] == 'Netherlands']","d3ccd01b":"submission = submission[['confirmed', 'fatal']]\nsubmission.index.name = 'ForecastId'\nsubmission.columns = ['ConfirmedCases', 'Fatalities']\n\nsubmission['ConfirmedCases'] = ((submit['ConfirmedCases'].values + submission['ConfirmedCases'].values)\/2)\nsubmission['Fatalities'] = ((submit['Fatalities'].values + submission['Fatalities'].values)\/2)\n\nsubmission.to_csv('submission.csv')","355d59d4":"## Submit result","e8aba012":"### Model with intervention\n* There are different way to reduce R_t, [Differnt decay function](https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions) as below, we are using hill function\n![image](https:\/\/raw.githubusercontent.com\/wiki\/SwissTPH\/openmalaria\/img\/graphs\/decay-functions.png)\nThis could be modified to take any function of `R_t(t)` values to model the reproduction number as a time varying variable\n* Result shows the predict value greate fit the current comfirmedcases\n* You can also using different decay function as above to reduce \"R_t\"","783e2ac7":"### Intervention by Hill function for SEIR model\n* https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions","ceefdf4e":"### Load dataset (Global ComfirmedCase of each country)","70d9c8b3":"### Function of Fit the SEIR model to real data\n* Auto choose the best decay function of R_t (intervention days decay or Hill decay)\n* Total case\/country population is below 1, reduce country population\n* If datset still no case, return 0 \n* Plot the fit result and forecast trends (Infect smooth decrease by what date)\n* Function being hide, there are describe in code.","b92f5708":"## Retrain PR model for MSLE>1 countries\n* If MSLE of PR model lower than SEIR model, than use PR model as predict result","7d18b500":"### Cumsum signal\n* to prevent fluctuation","d6e472fd":"### Model without intervention\n* We can see the without intervention, Hubei comfirmedcase will keep increase... this is very terrifying.","0b73d997":"# SEIR & PR Model for COVID19 Global forecast\n\nSEIR MODEL Reference:\n* Many thanks for @datasaurus great Kernel : https:\/\/www.kaggle.com\/anjum48\/seir-model-with-intervention\n* [Compartmental models in epidemiology - SEIR](https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology#The_SEIR_model)\n* [SEIR Great APP](http:\/\/gabgoh.github.io\/COVID\/index.html)\n\nPR model Reference:\n* [My previous kernel](https:\/\/www.kaggle.com\/super13579\/covid19-global-forcast-simple-eda-pr-model)\n","b1fa5976":"### Intervention by after days for SEIR model\n* after days, start interverntion, R0 = R0 * 0.5","c5632ad4":"# Conclusion\n* This SEIR model is for idea Compartmental models in epidemiology, it's rough\n* R0 reduce can be cause by many things (government, Medical system, calture(habit to wear mask), people behavior)\n* We can using real data of recover for each country to define \"T_inf\"\n\n# Hope COVID-19 will be under control soon","bc4a8028":"## Predict all Country\/Region and Province\/States\n* Counting all Country\/Region MSLE & predict\n* If MSLE is lower than 1 , using PR model to retrain and check the performance","1d4ef6d9":"## Fit the SEIR model to real data\nFind the best variables of SEIR model to fit the real data\n* T_inf ==> Using average value 2.9 \n* T_inc ==> Using average value 5.2\n* **R_t** ==> find the best reproduction number by fitting the real data (if have decay function, find the paramater of decay function)\n* **cfr** ==> find the best Case fatality rate, this parater is for predict Fatalities","9ab9e25a":"### Load populations of each country","5bd2ecb2":"## SEIR Model function\n* Function From [SEIR Great APP](http:\/\/gabgoh.github.io\/COVID\/index.html)\n![image.png](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/3\/3d\/SEIR.PNG)\n* S ==> Susceptible : number of susceptible\n* E ==> Expose : number of expose\n* I ==> Infectious : number of infectious\n* R ==> Recovered or Removed : number recovered (or immune) individuals. \n* We have S + E + I + R = N, this is only constant because of the (degenerate) assumption that birth and death rates are equal, N is country population.\n\nSusceptible \u2192 Exposed \u2192 Infected \u2192 Removed, Differential Function as below (from [SEIR Great APP](http:\/\/gabgoh.github.io\/COVID\/index.html)): \n![image.png](attachment:image.png)\nWe need to solve the Differential equation to find the S,E,I,R, but what is **\"R_t\"**, **\"T_inf\"**, **\"T_inc\"** and how can we define those variable?\n* R_0 & R_t ==> [Reproduction number](https:\/\/en.wikipedia.org\/wiki\/Basic_reproduction_number), The definition describes the state where no other individuals are infected or immunized (naturally or through vaccination)\n* T_inf ==> Average duration of the infection, 1\/T_inf can be treat as individual experiences one recovery in D units of time.\n* T_inc ==> Average incubation period, Many paper and article define as 5.1 ([reference](https:\/\/www.ncbi.nlm.nih.gov\/pubmed\/32150748), [reference2](https:\/\/www.worldometers.info\/coronavirus\/coronavirus-incubation-period\/))\n\n### Assume there are some intervention will cause reproduction number (R_0) reduce (such as bed nets and vaccines,government, isolation ....), have an effectiveness which decays over time ","792ff090":"## Let's fit SEIR model on country\n* Check Taiwan(My country!!), South Korean, Japan, Italy, New York\n* Hope these are not ture... Italy and New York are very terrifying....","d64629ad":"### Check the total US trend","c1138223":"## Let's try simple SEIR model on Hubei\n* Already defined R0, T_inf, T_inc. \n* Compare invention and non-invention condition on SEIR model.","a6c31830":"### Plot SEIR model and predict"}}