{"cell_type":{"2369ddac":"code","f6e8dbcb":"code","74b49a93":"code","ff75588c":"code","9483fa90":"code","e8c321ec":"code","cc8083ad":"code","a024c1df":"code","604e63b0":"code","f42a0e30":"code","01c2bc24":"code","fc209164":"code","743996be":"code","c07cd810":"code","b1b03532":"code","365c138f":"code","05fc9de4":"code","2ec4cc91":"code","849e034a":"code","10e0a0c6":"code","ead736f7":"code","94f2d76a":"code","ad9a0821":"code","65cc6be9":"code","9b4b79f9":"code","94089772":"code","d4d120c1":"code","b28aa7b1":"code","5a00382e":"code","34e9e704":"code","3942712c":"code","a29592ab":"code","bf64c4b6":"code","1d0a09fd":"code","376fcbdc":"code","94abe08f":"code","8cfaa8f8":"code","e34839ad":"code","b8b501db":"code","5f9993ad":"code","dd390079":"code","954740ae":"code","1a8e4905":"code","82da0165":"code","7481dff7":"code","536feece":"code","5c6949ff":"code","1c8828f1":"code","c1f35d5e":"code","98438f7e":"code","21ee9f49":"code","c416c89d":"code","97232afe":"code","385b6366":"code","7d0ca479":"code","4e9a42b2":"code","b7b3bfff":"code","efb50a84":"code","3b5da513":"code","66d013e7":"code","5b60738d":"code","b2fff44d":"code","90c6d0a1":"code","d6777c75":"code","f5d54a36":"code","b618e8fa":"code","b772631c":"code","15a4227a":"markdown","76a35b09":"markdown","ea3c2770":"markdown","72e9128d":"markdown","3ae61f0f":"markdown","b133eb18":"markdown","1b2720c4":"markdown","d7b0bc73":"markdown","81dd6be7":"markdown","324634f4":"markdown","443065d0":"markdown","d322dc7c":"markdown","35d6d807":"markdown","3f4398a6":"markdown","b6da7640":"markdown","4769722e":"markdown","daf63944":"markdown","ab8e5f13":"markdown","79274484":"markdown","5ac23db9":"markdown","699c8141":"markdown","393e92da":"markdown","7b872c26":"markdown","017c4f9a":"markdown","237b5cc4":"markdown","9c101a2b":"markdown","2f7959c6":"markdown","bf70abe6":"markdown","2c3af137":"markdown","4be61320":"markdown","02aaeade":"markdown"},"source":{"2369ddac":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","f6e8dbcb":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ndf = [train_df, test_df]","74b49a93":"print('train_shape:',train_df.shape)\ntrain_df.head()","ff75588c":"print('test_shape:', test_df.shape)\ntest_df.head()","9483fa90":"train_df.info()","e8c321ec":"train_df.isnull().sum()","cc8083ad":"test_df.isnull().sum()","a024c1df":"sns.heatmap(train_df.isnull(), cbar=False, yticklabels=False)","604e63b0":"train_df.Embarked.value_counts()","f42a0e30":"train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\ndf = [train_df, test_df]","01c2bc24":"train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()","fc209164":"grid = sns.FacetGrid(train_df, col='Survived')\ngrid.map(plt.hist, 'Embarked')","743996be":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Pclass', 'Survived', 'Sex', ci=None, palette='deep')\ngrid.add_legend()","c07cd810":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', ci=None, palette='deep')\ngrid.add_legend()","b1b03532":"for dataset in df:\n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ntrain_df.head()","365c138f":"train_df.Parch.value_counts()","05fc9de4":"grid = sns.FacetGrid(train_df, col='Survived')\ngrid.map(plt.hist, 'Parch')\ngrid.add_legend()","2ec4cc91":"train_df.SibSp.value_counts()","849e034a":"grid = sns.FacetGrid(train_df, col='Survived')\ngrid.map(plt.hist, 'SibSp')\ngrid.add_legend()","10e0a0c6":"train_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ead736f7":"train_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","94f2d76a":"for dataset in df:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","ad9a0821":"for dataset in df:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean().sort_values(by='Survived', ascending=False)","65cc6be9":"train_df.head()","9b4b79f9":"train_df.Sex.value_counts()","94089772":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()","d4d120c1":"for dataset in df:\n    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)","b28aa7b1":"def func(a):\n    try:\n        return a.split(' ')[-1]\n    except:\n        return a","5a00382e":"for dataset in df:\n    dataset['Ticket_num'] = dataset['Ticket'].apply(lambda x: func(x))\n    dataset['Ticket_num'] = dataset['Ticket_num'].replace('LINE', 0)","34e9e704":"train_df.head()","3942712c":"train_df.Ticket_num.unique().shape","a29592ab":"for dataset in df:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\npd.crosstab(train_df['Title'], train_df['Sex'])","bf64c4b6":"train_df[['Title', 'Age']].groupby(['Title'], as_index=False).mean()","1d0a09fd":"for dataset in df:\n    dataset['Age_fill'] = 0\n    dataset.loc[dataset['Title'] == 'Capt', 'Age_fill'] = 70\n    dataset.loc[dataset['Title'] == 'Col', 'Age_fill'] = 58\n    dataset.loc[dataset['Title'] == 'Countess', 'Age_fill'] = 33   \n    dataset.loc[dataset['Title'] == 'Don', 'Age_fill'] = 40    \n    dataset.loc[dataset['Title'] == 'Dr', 'Age_fill'] = 42   \n    dataset.loc[dataset['Title'] == 'jonkheer', 'Age_fill'] = 38    \n    dataset.loc[dataset['Title'] == 'Lady', 'Age_fill'] = 48    \n    dataset.loc[dataset['Title'] == 'Major', 'Age_fill'] = 48.5    \n    dataset.loc[dataset['Title'] == 'Master', 'Age_fill'] = 4.6    \n    dataset.loc[dataset['Title'] == 'Miss', 'Age_fill'] = 21.8\n    dataset.loc[dataset['Title'] == 'Mlle', 'Age_fill'] = 24\n    dataset.loc[dataset['Title'] == 'Mme', 'Age_fill'] = 24\n    dataset.loc[dataset['Title'] == 'Mr', 'Age_fill'] = 32.4\n    dataset.loc[dataset['Title'] == 'Mrs', 'Age_fill'] = 35.9\n    dataset.loc[dataset['Title'] == 'Ms', 'Age_fill'] = 28\n    dataset.loc[dataset['Title'] == 'Rev', 'Age_fill'] = 43.2\n    dataset.loc[dataset['Title'] == 'Sir', 'Age_fill'] = 49","376fcbdc":"train_df.head()","94abe08f":"for dataset in df:\n    dataset['Age'] = dataset['Age'].fillna(dataset['Age_fill'])","8cfaa8f8":"train_df.isnull().sum()","e34839ad":"test_df.isnull().sum()","b8b501db":"for dataset in df:\n    dataset.drop(['Age_fill', 'Cabin', 'Ticket_num', 'Ticket', 'FamilySize', 'SibSp', 'Parch', 'Name'], axis=1, inplace=True)","5f9993ad":"train_df.head()","dd390079":"print('Before conversion')\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)","954740ae":"for dataset in df:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\nprint('After conversion')\ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)","1a8e4905":"mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\nfor dataset in df:\n    dataset['Title'] = dataset['Title'].map(mapping)\ntrain_df.head()","82da0165":"print('Introducing statistical parameters for all of the features:-')\ntrain_df.describe()","7481dff7":"train_df.info()","536feece":"for dataset in df:\n    dataset['Age'] = dataset['Age'].astype(int)","5c6949ff":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","1c8828f1":"for dataset in df:\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\ntrain_df.head()","c1f35d5e":"test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].mode()[0])","98438f7e":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","21ee9f49":"for dataset in df:\n    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ndf = [train_df, test_df]\ntrain_df.head()","c416c89d":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()","97232afe":"for dataset in df:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head()","385b6366":"train_df.head()","7d0ca479":"train_df.drop(['PassengerId', 'AgeBand', 'FareBand'], axis=1, inplace=True)","4e9a42b2":"X_train = train_df.drop(['Survived'], axis=1)\ny_train = train_df['Survived']\nX_test = test_df.drop(['PassengerId'], axis=1)","b7b3bfff":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n","efb50a84":"classifier = LogisticRegression()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","3b5da513":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(classifier.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","66d013e7":"acc_Logistic = cross_val_score(classifier, X_train, y_train, cv=10, scoring='accuracy').mean()\nacc_Logistic","5b60738d":"classifier = KNeighborsClassifier(n_neighbors=5)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","b2fff44d":"acc_KNN = cross_val_score(classifier, X_train, y_train, cv=10, scoring='accuracy').mean()\nacc_KNN","90c6d0a1":"classifier = SVC()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","d6777c75":"acc_SVC = cross_val_score(classifier, X_train, y_train, cv=10, scoring='accuracy').mean()\nacc_SVC","f5d54a36":"classifier = DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)","b618e8fa":"acc_Tree = cross_val_score(classifier, X_train, y_train, cv=10, scoring='accuracy').mean()\nacc_Tree","b772631c":"datasets = pd.DataFrame({\n    'PassengerId': test_df['PassengerId'],\n    'Survived': y_pred\n})\ndatasets.to_csv('gender_submission3.csv', index=False)","15a4227a":"#### Try to extract only integral values from Ticket feature","76a35b09":"oh! I forgot to work on Pclass feature...","ea3c2770":"#### Survival percentage for female passenger is more then male.","72e9128d":"accuracy of svm is highest upto here","3ae61f0f":"creating an artificial feature combining Pclass and Age","b133eb18":"# Model Training","1b2720c4":"accuracy of knn is more then logistic regression","d7b0bc73":"#### Number of male survived is more then female only when Embarked is equal to C.","81dd6be7":"#### Most of the passengers were not aboard with their siblings\/ spouses.","324634f4":"### And its done \ud83e\udd20 but wait other features are still remaning to check...\nlet us now move onto other features","443065d0":"#### Most of the passengers were not aboard on titanic with their parents\/ children.","d322dc7c":"##### Similarily, based on parameters Fare is grouped into 4 parts and then different values is assigned to each group and then mapped accordingly to Fare feature","35d6d807":"So our Embarked feature has 3 values S, C and Q with S has highest number of count then comes C and at last is Q.\n\nThis signifies that most of the passengers boarded through port S and the number of passenger boarded through Q is very less as compared to S.","3f4398a6":"And here comes our best model which has such a great accuracy","b6da7640":"#### Before we start our problem's solution lets talk little bit about the \"Titanic\" incident:-\n\nIn the early morning hours of 15 April 1912, after striking an iceberg during her maiden voyage from Southampton to New York City Titanic sank in the North Atlantic Ocean.\n\nThere are total of 2222 passengers and crew on that ship out of which around 1517 people died but we have given a data with total of 1309 people (891 in train part and 418 in test part) and based on our training data we have to predict which one survived or not survived for test data.\n\nOther main reason of high death toll was that the ship had only 20 lifeboats and as they pulled away from the sinking ship, many were only half-full or even less.\n\n##### Without wasting more time let's jump right into it","4769722e":"#### oh! if number of members in a family is more then 7 then the entire family didn't survived.\ud83d\ude25\ud83d\ude25\nBut still this feature also have certain values which has null correlation, I have to create another feature based on this feature which has less number of categories in it and basically cover all the values of this feature into some other categories.\n\nSuch a feature I can create over here is IsAlone which represents that particular passenger was alone or with someone aboard on titanic. 0 -- Not Alone, 1 -- Alone.","daf63944":"Importing libraries","ab8e5f13":"In the code above I extract Title of each person using regular expression. The RegEx pattern (\\w+\\\\.) matches the first word which ends with a dot character within Name feature. The expand=False flag returns a DataFrame.\n\nBut it(Title) has lots of different values which can be usefull to fill Nan values of Age feature As particular title is used to represent particular range of age and i took the mean of that range then map according to title and thus fill it up with corresponding value.\n\nPreviously I just do fill the Nan's values with any of suitable parameters(mean, median, mode) but in terms to achieve good accuracy I have to do this. I also saw some of people fill this by random numbers between mean plus minus 2 standard deviation.","79274484":"This way Age*Class is a good artificial feature to model as it has third highest negative correlation with Survived.\n\nInversely as Pclass increases, probability of Survived=1 decreases the most.","5ac23db9":"55 percent passengers of C survived.\n\n38 percent passengers of Q survived.\n\n33 percent passengers of S survived.\n\nThe passengers from C has highest survival percentage and S has lowest survival percentage but still the number of survived passenges of S is more then C because of the difference of total count of passengers of S and C.\n\nThis would be more clear through the graph below:-","699c8141":"I am currently a beginner to this amazing world of data science and I feel great to be a part of such community. If you have any suggestions for me please let me know about the code or how can I excel into this huge world of data science, I like to gain more knowledge from you all experts...\n\nSome other notebooks which helped me a lot and I recommend you to please check them out, Simply these are good for beginners.\n* [www.kaggle.com\/mdmahmudferdous\/titanic-survivor-prediction-0-804-top-8](http:\/\/)\n* [www.kaggle.com\/startupsci\/titanic-data-science-solutions\/log](http:\/\/)","393e92da":"## let's go feature by feature","7b872c26":"#### Both the features Parch and SibSp has some values which have very less or even null correlation,\nIt would be better to make another feature derived from these two like we can create a feature named as FamilySize which indicates total number of family members aboard on titanic.\n","017c4f9a":"#### Why did I wasted my time on Ticket feature?\nOut of 891 total values Ticket_num has only 679 unique ones, i.e there is a lot of duplicate values in this feature and this might not happen actually think of it every one has a unique ticket number and Id's so why this feature has that much duplicate values and also this(Ticket) feature has a lot of mixed values in it. This feature doesn't provide much information to our data probably.\n\n#### Now let's jump into Name feature\nIt has lots of error and typos in it only thing i can extract from it is title of each person plus it has all of unique values and thus I am not going to perform any type of encoding on it that makes our model's accuracy very bad.","237b5cc4":"### drop! drop! drop!","9c101a2b":"#### Passengers who paid more was more likely to survive","2f7959c6":"Now it makes sense isn't it...\n\nHere I am trying to see how my Embarked feature affect other features.","bf70abe6":"### More work to do in features\n\nReducing categories in Title feature and keeping just known or important categories.","2c3af137":"There are almost 77 percent Nan values in Cabin feature of training part and about 78 percent Nan's in test part which doesn't provide much information to our data.\n\nSome of Nan values also present in Age and Embarked feature of training and one missing value in Fare of test part I'll fill it up by appropriate value later on.\n\n\n### Conclusion upto here:-\n    1. I have to drop PassengerId from the data as it doesn't contribute to provide any information about the data.\n    2. I have to check how the feature Pclass affect the target variable.\n    3. There is lots of error or typos in Name as it has many ways to describe name of any person like parenthesis, quotes etc. I decided to drop it but I can extract the title of each name, so as to fill Nan's of Age feature. I'll do this later.\n    4. Sex feature has two categories female and male. I have to convert this into numerical feature so that any ML model works properly.\n    5. Age feature has Nan values I'll fill them by mapping the title, you will see that in some time.\n    6. Ticket is mixture of more then one category so I decided to keep only integer value of every ticket.\n    7. Cabin has lots of Nan values so I have to remove that feature.\n    8. I also have to convert categories of Embarked feature into numerical.","4be61320":"### Converting values of Age feature into odinal values based on different age groups","02aaeade":"### Categorical Variables:-\n    Numeric:-\n        Pclass\n        Survived\n    Non Numerical:-\n        Name\n        Sex\n        Embarked\n### Numerical Variables:-\n    Discrete:-\n        SibSp\n        Parch\n    Continous:-\n        Fare\n        Age\n#### Cabin-alphanumeric\n#### Ticket-mixture of numeric and alphanumeric"}}