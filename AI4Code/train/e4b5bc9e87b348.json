{"cell_type":{"fa27b7d3":"code","7e6f77db":"code","fcf48fae":"code","7e77c1d5":"code","54fc332e":"code","7b8e7b1c":"code","baa7134a":"code","0cb19cc3":"code","9995cc63":"code","30fa2630":"code","59559ca7":"code","5bd23faa":"markdown","af40e27c":"markdown","0efede63":"markdown","5ed3ad86":"markdown","f1cb6cc9":"markdown","18ab5a5f":"markdown","bf89190c":"markdown","cbbdf279":"markdown","7a9f7afa":"markdown"},"source":{"fa27b7d3":"import matplotlib.pyplot as plt\nimport numpy as np\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n!pip install torchsummary\nfrom torchsummary import summary\n\nimport torch.nn as nn\nimport torch.nn.functional as F","7e6f77db":"transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n])\n\n# STL10 :\ntrainset = torchvision.datasets.STL10(root='.\/data',split='train',download=True,transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)\n\ntestset = torchvision.datasets.STL10(root='.\/data',split='test',download=True,transform=transform)\ntestloader = torch.utils.data.DataLoader(testset,batch_size=64,shuffle=False)\n\nwith open('.\/data\/stl10_binary\/class_names.txt','r') as f:\n    classes = []\n    lines = f.readlines()\n    for i in lines:\n        classes.append(i.strip())\n        \n# dataset info\nprint('Dataset type : ',type(trainset))\nprint('[ original data ]','='*10)\nprint('Train set shape : ',trainset.data[0].shape)\nprint('Test set shape : ',testset.data[0].shape)\n\nprint('[ transformed data ]','='*10)\ntrain_dataiter = iter(trainloader)\ntrain_images,labels = train_dataiter.next()\ntest_dataiter = iter(testloader)\ntest_images,labels = test_dataiter.next()\nprint('Train set shape : ',train_images[0].shape)\nprint('Test set shape : ',test_images[0].shape)\n\nprint('classes : ',classes)","fcf48fae":"def imshow(img):\n    img = img\/2+0.5 # un normalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg,(1,2,0)))\n    \ndataiter = iter(trainloader)\nimages,labels = dataiter.next()\nprint('image shape : ',images[0].shape)\nimshow(torchvision.utils.make_grid(images))\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","7e77c1d5":"class VGG19(nn.Module):\n    def __init__(self):\n        super(VGG19,self).__init__()\n        \n        self.conv = nn.Sequential(\n            # (3,224,224)  (3,128,128)\n            nn.Conv2d(3,64,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(64,64,3,padding=1),nn.LeakyReLU(0.2),\n            nn.MaxPool2d(2,2),\n            # (64,112,112)  (64,64,64)\n            nn.Conv2d(64,128,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(128,128,3,padding=1),nn.LeakyReLU(0.2),\n            nn.MaxPool2d(2,2),\n            # (128,56,56)   (128,32,32)\n            nn.Conv2d(128,256,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(256,256,3,padding=1),nn.LeakyReLU(0.2),\n            nn.MaxPool2d(2,2),\n            # (256,28,28)   (256,16,16)\n            nn.Conv2d(256,512,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(512,512,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(512,512,3,padding=1),nn.LeakyReLU(0.2),\n            nn.MaxPool2d(2,2),\n            # (512,14,14)   (512,8,8)\n            nn.Conv2d(512,512,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(512,512,3,padding=1),nn.LeakyReLU(0.2),\n            nn.Conv2d(512,512,3,padding=1),nn.LeakyReLU(0.2),\n            nn.MaxPool2d(2,2)\n            # (512,7,7)     (512,4,4)\n        )\n        \n        self.avg_pool = nn.AvgPool2d(7)\n        # (512,1,1)\n        self.classifier = nn.Linear(512,10)\n        '''\n        self.fc1 = nn.Linear(512*2*2,4096)\n        self.fc2 = nn.Linear(4096,4096)\n        self.fc3 = nn.Linear(4096,10)\n        '''\n    \n    def forward(self,x):\n        # print(x.size())\n        features = self.conv(x)\n        # print(features.size())\n        x = self.avg_pool(features)\n        # print(avg_pool.size())\n        x = x.view(features.size(0),-1)\n        # print(flatten.size())\n        x = self.classifier(x)\n        # x = self.softmax(x)\n        return x, features\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n\nnet = VGG19()\nnet = net.to(device)\n\nsummary(net,(3,224,224))\n\n# check the torch size\n# param = list(net.parameters())\n# print(len(param))\n# for i in param:\n#     print(i.shape)\n# print(param[0].shape)","54fc332e":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss().cuda()\noptimizer = optim.Adam(net.parameters(),lr=0.00001)","7b8e7b1c":"from tqdm.notebook import tqdm as tqdm_nb\n\nfor epoch in tqdm_nb(range(100)):\n    running_loss = 0.0\n    for i,data in enumerate(trainloader,0):\n        # get the inputs\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # print(inputs.shape)\n        # print(inputs.shape)\n        # forward + backward + optimize\n        outputs, f = net(inputs)\n        # print(outputs.shape)\n        # print(labels.shape)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        if(loss.item() > 1000):\n            print(loss.item())\n            for param in net.parameters():\n                print(param.data)\n        # print statistics\n        running_loss += loss.item()\n        if i % 50 == 49:\n            print('[%d, %5d] loss: %.3f' % (epoch+1,i+1,running_loss\/50))\n        runnint_loss = 0.0\n        \nprint('Training Completed')\n","baa7134a":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nwith torch.no_grad():\n    for data in testloader:\n        images,labels = data\n        images = images.cuda()\n        labels = labels.cuda()\n        outputs,_ = net(images)\n        _, predicted = torch.max(outputs,1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nfor i in range(10):\n    print('Accuracy of %5s: %2d %%' % (classes[i], 100*class_correct[i]\/class_total[i]))","0cb19cc3":"torch.save(net,'vgg19.pt')\nnet2 = torch.load('vgg19.pt')\nnet2 = net2.to(device)","9995cc63":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        images = images.cuda()\n        labels = labels.cuda()\n        outputs, f = net2(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))\n    \nparams = list(net.parameters())","30fa2630":"import skimage.transform\nclasses =  ('airplance', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck')\nparams = list(net.parameters())\nn = 5\n\nfig, ax = plt.subplots(2,n,figsize=(10,5))\n\nfor num in range(n):\n    print(\"Real Y :\",classes[int(predicted[num])],\" Pred :\",classes[int(labels[num])],num)\n\n    #print(outputs[0])\n\n    overlay = params[-2][int(predicted[num])].matmul(f[num].reshape(512,49)).reshape(7,7).cpu().data.numpy()\n\n    overlay = overlay - np.min(overlay)\n    overlay = overlay \/ np.max(overlay)\n    \n    # origin show\n    ax[0,num].set_title('Y : %s' % (classes[int(predicted[num])]))\n    ax[0,num].imshow(np.transpose(images[num].cpu(),(1,2,0)))\n    # pred show\n    ax[1,num].set_title('Pred : %s' % (classes[int(labels[num])]))\n    ax[1,num].imshow(np.transpose(images[num].cpu(),(1,2,0)))\n    ax[1,num].imshow(skimage.transform.resize(overlay, [224,224]), alpha=0.4,cmap='jet')\n    \n#     imshow(images[num].cpu())\n#     skimage.transform.resize(overlay, [224,224])\n#     plt.imshow(skimage.transform.resize(overlay, [224,224]), alpha=0.4,cmap='jet')\n#     plt.show()\n#     imshow(images[num].cpu())\n#     plt.show()\n\n#plt.imshow(params[-2][int(predicted[num])].matmul(f[num].reshape(512,49)).reshape(7,7).cpu().data.numpy(), alpha=0.5,cmap='jet');","59559ca7":"# !rm -r .\/data","5bd23faa":"# Contents \n > Updated ('21. 6. 17)\n - [0. Description](#0.-Description)\n - [1. Import Packages](#1.-Import-Packages) \n - [2. Load Datasets](#2.-Load-Datasets)\n - [3. Base Model Train(VGG19)](#3.-Base-Model-Train(VGG19))\n - [4. Model Load](#4.-)\n\n- reference : https:\/\/poddeeplearning.readthedocs.io\/ko\/latest\/CNN\/VGG19%20+%20GAP%20+%20CAM\/","af40e27c":"> ---\n> ### 4-1. Load Model & Predict Result","0efede63":"> ---\n> ### 3-2. Criterion(Loss) & Optimizer  ","5ed3ad86":"---\n# 1. Import Packages","f1cb6cc9":"---\n# 2. Load Datasets","18ab5a5f":"---\n# 0. Description\n- Dataset : 3x96x96 ->(resize) 3x224x224\n- Simple Classifier : VGG19\n- Basic Idea : After Conv filter output (14x14 grid 512 channels\n","bf89190c":"---\n# 3. Base Model Train(VGG19)","cbbdf279":"---\n# 4. Generate CAM(Class Activation Map)  ","7a9f7afa":"> ---\n> ### 3-1. Define Model Structure"}}