{"cell_type":{"34f4c568":"code","a2fba366":"code","2d8bf0c5":"code","9450c98e":"code","be792a7a":"code","9e14d9c3":"code","5c709925":"code","eda9d552":"code","2041eed3":"code","45f5d65b":"code","efd172aa":"code","c8329651":"code","f3e6b7cf":"code","98769f56":"code","c1f48501":"code","203fb7aa":"code","77dde820":"code","a679a0fb":"code","1bebde8e":"code","09d03183":"code","fda58d62":"code","3aa2479f":"markdown","08f7f05d":"markdown","25fea31f":"markdown","3f888342":"markdown","ed17796f":"markdown","678c6735":"markdown","accda264":"markdown","fa3e3f24":"markdown","4a1a364b":"markdown","870f625c":"markdown","556c71e3":"markdown","0239d0e7":"markdown","3e5e2196":"markdown","4d977df0":"markdown","75b18cbe":"markdown","cb8f0e31":"markdown","e0451bcf":"markdown","a4a344c2":"markdown","34d36565":"markdown","1bcf5f19":"markdown","50482751":"markdown","67e95050":"markdown"},"source":{"34f4c568":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom IPython.display import Image\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a2fba366":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport plotly.offline as ply\nimport plotly.graph_objs as gob","2d8bf0c5":"mushrooms = pd.read_excel(\"..\/input\/mushroomdata\/mushroom.xlsx\")\nmushrooms","9450c98e":"mushrooms.describe().T # Let's take a rapid glance at count, frequencies, uniqueness, etc. of the dataset.","be792a7a":"#Arranging attributes and classes.\n\nx = mushrooms.drop(columns='class')\ny = mushrooms['class']\n\n# Renaming classes\ny=y.replace('p','poisonous')\ny=y.replace('e','edible')\n\n# Creating a pie chart to see frequency of classes. Frequency of classes is important, because if our dataset is imbalanced dataset then we need to analyze the dataset in a different way.\n\npie_values = pd.Series(y).value_counts()\ntrace = gob.Pie(labels=['edible','poisonous'],values=pie_values)\nply.iplot([trace])","9e14d9c3":"mushrooms.isnull().any() # This code shows that there is a column contains a null value or not, as you can see below the dataset has a columns contains \"nan\" value.\n# So, this code returns true for stalk-root column. ","5c709925":"# Also, we can write a simple for loop to see column(s) which contains(s) non-sense or null value(s).\n\nfor i in mushrooms.columns:\n    print(i,mushrooms[i].unique())","eda9d552":"# Let's use second step to fill non-sense data with more reasonable one.\nx['stalk-root'].value_counts()","2041eed3":"x['stalk-root'] = x['stalk-root'].fillna('b') # '?' in stalk-root attribute filled with 'b' has most frequency.\n# Let's see whether non-sense data exists, or not.\nx['stalk-root'].value_counts()","45f5d65b":"from sklearn.preprocessing import LabelEncoder\nle_encoder = LabelEncoder()\n\ny = le_encoder.fit_transform(y) # Label Encoding for class.\n\nx = pd.get_dummies(x) # One-Hot Encoding for attributes. There are columns has more than two unique values. So, for encoding I use One-Hot Encoding.\n\n# Let's see new looking of our attributes\nx","efd172aa":"# Maybe, K-Means is one of the simpliest algorithms in ML, but there is some challenging situtations like determining the optimal K value which is diretly related to clustering quality.\n\nfrom sklearn.cluster import KMeans\n\nWCSS=[] # I created a free list to append WCSS values.\n\nfor K in range(1,11):\n    KM = KMeans(n_clusters=K, init='k-means++', max_iter=300, n_init=10)\n    KM.fit(x.values)\n    WCSS.append(KM.inertia_)\n\n# Choosing the right K value for a propoer KMeans model may be a challenging situation. In this point, The Elbow Method helps us. This method is based on interpretation. As WCSS value \n# decreases, we can say that clustering process is getting better because similarity of values in a cluster increases and similarity between clusters decreases. This is what we need to do.\n# But some can say that if the number of cluster value is selected too much, the clustering will be so good. This is COMPLETELY WRONG! As Number of Cluster value converges to n (number \n# of data of a dataset) the model may be overfitted. Briefly, choosing the highest value of K does not mean a proper clustering model. Just think about it, if you choose K = n, this is \n# not clustering, this is assigning each data point as a cluster. So, we need to choose optimal K value. We can use The Elbow Method for this.\n\nfigure(figsize=(6,5))\nplt.plot(range(1,11),WCSS)\nplt.title('Elbow Method for Mushroom Dataset')\nplt.xlabel('Number of Cluster')\nplt.ylabel('WCSS')\nplt.show()","c8329651":"# The function coded below shows that differences between WCSS values. We should choose the optimal K value which returns more smoother slope. In this dataset we can choose K=2.\nnp.diff(WCSS)","f3e6b7cf":"# Since we will work with many models, let us keep the names of these models in a list to ease coding.\nmodel_predicted = ['y_KM','y_KNN','y_DT','y_NB','y_LR','y_SVM']\n\nKM = KMeans(n_clusters=2, init='k-means++',max_iter = 300, n_init = 10)\nmodel_predicted[0] = KM.fit_predict(x)","98769f56":"# \u0130mporting libraries for k-cross validation\nfrom sklearn.model_selection import KFold,cross_val_score,cross_val_predict\n\nKFCV = KFold(n_splits = 10, random_state = 42) # Here, random_state value is an important parameter. If the random_state parameter is defined with a fix value like 42, \n# then no matter how many times your code is run,same data will be filled into the train and test test. That means the output will be the same. Otherwise, if random_state parameter is not\n# defined with a fix value, the output will change every time the code is run.","c1f48501":"# Loading KNN classifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Like KMeans, KNN has the same problem with choosing the best K value to perform a proper classifier.\n# Let' s choose the best K value.\n\nvalues =[]\n\nfor K in range(1,20):  \n    KNN=KNeighborsClassifier(n_neighbors=K,metric='euclidean')\n    accuracies=cross_val_score(estimator=KNN,X=x,y=y,cv=KFCV,scoring='accuracy').mean()\n    values.append(accuracies)\n    \nplt.plot(range(1,20),values)\nplt.ylabel('Accuracy')\nplt.xlabel('K Value')\n\nprint('The K value which is the most accuracy', values.index(max(values)),',','Accuracy:', max(values))","203fb7aa":"# KNN is performed with the best K found above.\nKNN = KNeighborsClassifier(n_neighbors=values.index(max(values)),metric='euclidean') # It can be choosen minkowski or manhattan as metric.","77dde820":"# Loading decision tree library\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Performing the model with criterion = 'entropy'. Branching criteria can be chosen as gini. Branching selection depends on your model.\n\nDT = DecisionTreeClassifier(criterion = 'entropy')","a679a0fb":"# Loading Naive Bayes library\n\nfrom sklearn.naive_bayes import GaussianNB\n\nNB = GaussianNB()","1bebde8e":"# Loading Logistic Regression library\n\nfrom sklearn.linear_model import LogisticRegression\n\nLogR = LogisticRegression(solver = 'saga')    # The solver component is important. If you work on a large dataset, it would be better to assign solver = 'saga'. \n# This selection is directly related to model performance. In addition mushroom dataset has only two different class, we don't have to use multi_class component of LogisticRegression.","09d03183":"# Loading SVM Library\n\nfrom sklearn import svm\nL_SVM = svm.LinearSVC()  # In this work, I use linear SVM.","fda58d62":"# Loading Libraries\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\nfrom sklearn.metrics import cohen_kappa_score,confusion_matrix\n\n# A list has been created to store some performance metrics.\n\nscoring = ['accuracy' ,'precision','recall','f1']\n\n# accuracy : Contrary to the popular belief, accuracy does not make sense alone. To obtain better result It should be evaluated with other metrics.\n\n# precision and recall: In a machine learning model with a high accuracy, precision or recall may be dramatically low. This is the critical point! In a imbalanced dataset accuracy can be \n# satisfied value like 80 percent or 90, but precision and recall may be dramatically low. Let's consider the classic example, cancer disease. Consider that the data contains 1000 people, \n# 100 of them are truly cancer, rest of all is not. So, this is an imbalanced data set. Let's consider a model correctly predict 880 of 900 truly not cancer people. On the other hand,\n# the model correctly predict 10 of 100 truly cancer people. So, the model accuracy is 89 percent. This is a huge, but deceptive. Predicting wrong the people with cancer is not acceptable!\n# Although the model accuracy is 89 percent, the percent of corretly predicting of the truly cancer people is 10 percent. This is unacceptable! So, precision and recall help us to determine\n# these situations.\n\n# F-Score: Harmonic mean of recall and precision. It shows tradeoff of recall and precision.\n\nmodel_estimator_list=[KNN,DT,NB,LogR,L_SVM]\nmodel_name_list=['K-Nearest Neighbors','Decision Tree','Naive Bayes','Logistic Regression','SVM']\n\n\n# Confusion matrix of the models.\n\nprint('K-Means Confusion Matrix: \\n' ,confusion_matrix(y,model_predicted[0]))\n\nfor i in range(1,6):\n  model_predicted[i]=cross_val_predict(model_estimator_list[i-1],x,y,cv=KFCV)\n  print(model_name_list[i-1],'Confusion Matrix: \\n',confusion_matrix(y,model_predicted[i]))\n \n\n# Let's see the performance metrics scores resulting from classification.\n\n# Cross-validation was not applied on KMeans, because it is an unsupervised method. Thats why, I calculate performance metrics of K-Means seperately.\n\nprint('K-Means accuracy', accuracy_score(y,model_predicted[0]))\nprint('K-Means precision', precision_score(y,model_predicted[0]))\nprint('K-Means recall', recall_score(y,model_predicted[0]))\nprint('K-Means f1', f1_score(y,model_predicted[0]))\n\n\nfor i in range(0,5):\n    for j in range(0,4):\n      metrics_scores=cross_val_score(estimator=model_estimator_list[i],X=x,y=y,cv=KFCV,scoring=scoring[j])\n      print(model_name_list[i],'model',scoring[j],'on each fold',metrics_scores)\n      print(model_name_list[i],'model',scoring[j],'on each fold',metrics_scores.mean())\n\n        \n# Let's calculate Cohen Kappa Score.\n\nprint('K-Means model kappa',cohen_kappa_score(y,model_predicted[0]))\nfor i in range(0,5):\n   print(model_name_list[i],'kappa',cohen_kappa_score(y,model_predicted[i]))\n","3aa2479f":"<font size='5'>3. Data Preprocessing <\/font>\n<\/br>\n<font size='3'> Before building a proper model, data preprocessing is a vital step. To built  a more accurate model, we need to apply following data preprocessing steps.\n<\/br>\n1. Missing Data \/ Data Cleaning\n2. Data Transformation\n3. Data Reduction *(Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), ...)*\n4. Data Scaling","08f7f05d":"<font size='5'>The Goal<\/font> <br>\n<br>\nThe goal in this working is to briefly show and express how some machine learning algorithms are applied to the Mushroom dataset taken from UCI Machine Learning Repository. Processes mentioned below are expressing sketchy in a simple way for newbie. ","25fea31f":"<font size='4'>4.6. Logistic Regression <\/font>","3f888342":"Would be better to rapid glance at your dataset. ","ed17796f":"<font size='5'> 5. Performance Evaluation of the Models <\/font>","678c6735":"<font size='4'>4.5. Naive Bayes <\/font>","accda264":"Our dataset is full of categorical data. We need to convert these categorical values into numerical representatives. There are two ways to do this.\n* **Label Encoding:** This method can be perform on columns with binary values. We can't apply this method on a columns has more than two different values, because this method may cause a hierarchy between values in a column. So, this may cause incorrect classification.<br>\n<br>\n* **One-Hot Encoding:** This method can also be called \"Dummy Variable\" by some. In this method, each distinct values in a column transform into a column. Unlike label encoding, there is no trouble in terms of hierarchy. As dataset grows dimensionally, this method may cause low running performance.","fa3e3f24":"<font size='4'> 4.2. k-fold Cross Validation <\/font><br>\n<br>\nSince we work with supervised algorithms like KNN, Naive Bayes, Decision Tree, Logistic Regression and Support Vector Machines, we need to split dataset into training and test. There are several ways to split a dataset. These following validation methods can be expressed briefly.<br>\n<br>\n* **k-fold Cross Validation:** *Dataset is splitted into a training and test data, and divided into k-fold. In this method, each fold can be considered as a model. Also each fold has its own performance metrics like accuracy, precision, recall, f-score, ... This method is the best to avoid overfitting and underfitting problems.*\n* **Hold-Out Method:** *Dataset is splitted into a training and test data <u>randomly.<\/u> This splitting is performed just one. So, building a model with this method may cause overfitting and underfitting problems.*\n* **Leave One Out Cross Validation:** This method is a special case of k-fold cross validation. With this method (n-1) data is used for training and the remaining data is used for test. \n* **Re-Substitution Method:** In this method, all data is used for training, also the same data is used for test. <br>\n<br>\nIn this work, I use k-fold cross-validation which is the best to run away overfitting and underfitting situations.","4a1a364b":"<font size = '4'> 3.2. Data Transformation <\/font>","870f625c":"<font size='3'> Because there are no data needed to be scaled and there are no any outlier, we don't apply data scaling step *(If you confused, please ask).* Data Reduction is not applied too, because I planned this article as simple as possible *(In the next post, these steps will be examined in detail) for newbie.* <\/font>","556c71e3":"<font size='4'>4.3. KNN <font>","0239d0e7":"<font size=\"5\"> Reading Data<\/font>\n<br>\n<font size=\"3\"> You can read your dataset as a .csv, or .xls file, or etc. from where your dataset locate in your system. I read the dataset as a .xlsx file shown below. ","3e5e2196":"<font size='3'> as you can see 'stalk-root' contains 'nan' value which is non-sense. We need to fill it with reasonable value instead of 'nan'. There are several ways to fill missing or non-sense data. \n* This method is very dummy, but sometimes it may be working well suprisingly. The column(s) contain(s) missing or non-sense value(s) can be wiped out.\n    <\/br>\n* If the column contains missing or non-sense value is categorical, then we can fill the missing or non-sense values with value has most frequency in that column. If the column is numerical, then we can fill the missing or non-sense values with average or median value of that column.\n    <\/br>\n* We can built decision tree or regression model for missing or non-sense value(s).","4d977df0":"<font size=\"5\">1. Recognizing the data<\/font> <br>\n<br>\n<font size=\"3\"> The Mushroom Data Set includes hypothetical samples corresponding to 23 species the fungal order Agaricales, also known as gilled mushrooms. The dataset has 8124 instances and 22 attributes. In this dataset, each species is identified as <font color='blue'>strictly edible<\/font>, or <font color='orange'>strictly poisonous.<\/font> <\/font> <br>\n<br>\n<font size=\"5\">1.1. Attributes Information<\/font><br>\n<br>\n   <font size=\"3\">The dataset contains missing values in its *stalk-root* attribute. To more accurate result we need to handle these missing values. <br>\n   All attributes is of categorical variables. Some are binary, some are multiple.<\/font><br>\n\n1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n4. bruises?: bruises=t,no=f\n5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n6. gill-attachment: attached=a,descending=d,free=f,notched=n\n7. gill-spacing: close=c,crowded=w,distant=d\n8. gill-size: broad=b,narrow=n\n9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n10. stalk-shape: enlarging=e,tapering=t\n11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n16. veil-type: partial=p,universal=u\n17. veil-color: brown=n,orange=o,white=w,yellow=y\n18. ring-number: none=n,one=o,two=t\n19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d","75b18cbe":"<font size = '4'> 4.1. K-Means <\/font>","cb8f0e31":"<font size='5'> 4. Machine Learning Algorithms <\/font>","e0451bcf":"<font size='3'> These results clearly show that SVM and Logistic regression have better model performace than the others. Also, it can be said that this dataset is not an imbalanced dataset because there is no important difference between accuracy and Kappa score. Also, you can specify overfitting and underfitting situations by seeing cross validation scores of each folds.  <\/font> ","a4a344c2":"<center><font size=\"6\">How dare you eat a poisonous mushroom?<\/font><\/center>\n<center><font size=\"4\"> <font color=orange>*poisonous<\/font>, <font color=blue>or not?*<\/font><\/font><\/center><br>\n<br>\n<center><a href=\"https:\/\/ibb.co\/3rSzWLY\"><img src=\"https:\/\/i.ibb.co\/3rSzWLY\/mushroom-image.jpg\" alt=\"mushroom-image\" border=\"0\"><\/a><\/center>","34d36565":"<font size=\"5\">2. Loading Libraries<\/font>","1bcf5f19":"<font size='4'>3.1. Missing Data \/ Data Cleaning","50482751":"<font size='4'> 4.4. Decision Tree <\/font>","67e95050":"<font size='4'> 4.7. Support Vector Machines <\/font>"}}