{"cell_type":{"53f104d5":"code","2417280b":"code","9967348a":"code","f64273ca":"code","dba0cd97":"code","be252c89":"code","ede2f32f":"code","386db16d":"code","cc4d0cb0":"code","4c35a56e":"code","e76497ad":"code","dc1fe820":"code","c398e4a5":"code","016f8535":"code","8f53d12a":"code","5fb3dc09":"markdown"},"source":{"53f104d5":"import numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nfrom torchvision import transforms as T\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nimport xml.etree.ElementTree as ET\nimport torch\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor","2417280b":"datadir = os.path.join(\"..\", \"input\", \"face-mask-detection\")\ntransform = T.Compose([\n    T.ToTensor()\n])","9967348a":"class mask_data():\n    \n    def __init__(self, datadir, transform=None):\n        self.img_dir = os.path.join(datadir, 'images')\n        self.ann_dir = os.path.join(datadir, 'annotations')\n        self.imgs = list(sorted(os.listdir(self.img_dir)))\n        self.anns = list(sorted(os.listdir(self.ann_dir)))\n        self.transform = transform\n    \n    def __get_target__(self, x):\n        file_path = os.path.join(self.ann_dir, self.anns[x])\n        tree = ET.parse(file_path)\n        root = tree.getroot()\n        target = []\n        \n        for boxes in root.iter('object'):\n            ymin, xmin, ymax, xmax = None, None, None, None\n            \n            ymin = int(boxes.find(\"bndbox\/ymin\").text)\n            xmin = int(boxes.find(\"bndbox\/xmin\").text)\n            ymax = int(boxes.find(\"bndbox\/ymax\").text)\n            xmax = int(boxes.find(\"bndbox\/xmax\").text)\n            label = boxes.find('name').text\n            if label == 'with_mask':\n                label = 1\n            elif label == 'without_mask':\n                label = 2\n            else:\n                label = 3\n                \n            target.append([xmin, ymin, xmax, ymax, label])\n        return np.array(target)\n    \n    def __len__(self):\n        return len(self.imgs)\n        \n    def __getitem__(self, x):\n        img_path = os.path.join(self.img_dir, self.imgs[x])\n        img = Image.open(img_path).convert('RGB')\n        target = self.__get_target__(x)\n        boxes = target[:,:-1]\n        label = target[:,-1]\n        \n        target = dict()\n        target['boxes'] = torch.as_tensor(boxes)\n        target['labels'] = torch.tensor(label)\n        target['image_id'] = torch.tensor([x])\n        target['is_crowd'] = torch.zeros((len(self.imgs)), dtype=torch.int64)\n        target['area'] = torch.tensor((boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0]))\n        if self.transform is not None:\n            img = self.transform(img)\n            \n        return img, target","f64273ca":"dataset = mask_data(datadir, transform)","dba0cd97":"fig, ax = plt.subplots(figsize=(10,10))\nimg,targets = dataset[625]\nimg = img.numpy()\nboxes = targets['boxes']\nlabels = targets['labels']\nimg = np.moveaxis(img, 0, -1)\nfig = plt.imshow(img)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\ni = 0\nfor box in boxes:\n    clr = ''\n    if labels[i] == 1:\n        clr = 'g'\n    elif labels[i] == 2:\n        clr = 'r'\n    else:\n        clr = 'o'\n    i += 1\n    rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n                             linewidth=2, edgecolor=clr, facecolor='none')\n    ax.add_patch(rect)","be252c89":"rows = list()\nfor i in range(len(dataset)):\n    data = dataset[i]\n    target = data[1]\n    face_count = len(target['labels'])\n    with_mask = (target['labels'] == 1).sum().item()\n    without_mask = (target['labels'] == 3).sum().item()\n    improper_mask = (target['labels'] == 2).sum().item()\n    rows.append([face_count, with_mask, without_mask,improper_mask])\n\ndf = pd.DataFrame(rows, columns=['Face Count', 'With Mask', 'Without Mask', 'Improper Mask'])\ndf.sample(3)","ede2f32f":"print(\"======================== Data Summary ========================\")\nprint(f\"Total Images: {len(df)}\")\nprint('--------------------------------------------------------------')\nprint(f\"Total Annoted Faces: {df['Face Count'].sum()}\")\nprint(f\"Total Faces with Masks: {df['With Mask'].sum()}\/{np.round(df['With Mask'].sum()\/df['Face Count'].sum(),2)*100}%\")\nprint(f\"Total Faces without Masks: {df['Without Mask'].sum()}\/{np.round(df['Without Mask'].sum()\/df['Face Count'].sum(),2)*100}%\")\nprint(f\"Total Faces with Improper Masks: {df['Impropoer Mask'].sum()}\/{np.round(df['Impropoer Mask'].sum()\/df['Face Count'].sum(),2)*100}%\")\nprint('--------------------------------------------------------------')\nprint(f\"Average Face Count Per Image: {np.round(df['Face Count'].mean(),1)}\")\nprint(f\"Median Face Count Per Image: {df['Face Count'].median()}\")\nprint(f\"Median Face Count with mask Per Image: {df['With Mask'].median()}\")\nprint(f\"Median Face Count without\/improper mask Per Image: {(df['Without Mask'] + df['Impropoer Mask']).median()}\")\nprint(\"===============================================================\")","386db16d":"train_set, val_set = torch.utils.data.random_split(dataset, (800, 53))\ntrain_dataloader = torch.utils.data.DataLoader(train_set, batch_size=8, shuffle=True,\n                                              collate_fn=lambda x: tuple(zip(*x)))\n\nval_dataloader = torch.utils.data.DataLoader(val_set, batch_size=8, shuffle=True,\n                                              collate_fn=lambda x: tuple(zip(*x)))","cc4d0cb0":"def get_frcnn_model(num_classes):\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n    # get number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes+1)\n    return model","4c35a56e":"# Let make a single forward pass to make sure everything is working fine.\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = get_frcnn_model(3).to(device)\nprint(device)","e76497ad":"params = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.00001, weight_decay=0.0005)\nnum_epochs = 5\nloss_hist = list()","dc1fe820":"model.train()\nfor i in range(num_epochs):\n    j = -1\n    print(f\"Epoch: {i+1}\/{num_epochs}\")\n    print(\"Training\")\n    for images, targets in train_dataloader:\n        j += 1\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        loss = np.round(losses.item(),4)\n        loss_hist.append(loss)\n        if j%10 == 0:\n            print(f\"Loss[{j}\/{len(train_dataloader)}]: {loss}\")\n        \n        del images, targets, losses\n        torch.cuda.empty_cache()\n    \n    total_loss = 0\n    for images, targets in val_dataloader:\n        j += 1\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        with torch.no_grad():\n            loss_dict = model(images, targets)\n        losses = sum(loss for loss in loss_dict.values())\n        total_loss += losses.item()\n        del images, targets, losses\n        torch.cuda.empty_cache()\n    print(\"Validation\")\n    print(f\"Mean Validation Loss: {total_loss\/len(val_dataloader)}\")\n    print('-------------------------------------------------------')","c398e4a5":"fig, ax = plt.subplots(figsize=(10,6))\ny = [np.mean(loss_hist[i-5:i]) for i in range(5,len(loss_hist))]\nx = list(range(len(y)))\nfig = ax.plot(x, y)\n","016f8535":"img, targets = dataset[625]\nmodel.eval()\nwith torch.no_grad():\n    results = model([img.to(device)])\n\nboxes = list()\nlabels = list()\nfor i in range(len(results[0]['scores'])):\n    if results[0]['scores'][i] > 0.3:\n        boxes.append(results[0]['boxes'][i].to('cpu').numpy())\n        labels.append(results[0]['labels'][i].to('cpu').numpy())\n\nfig, ax = plt.subplots(figsize=(10,10))\nimg = np.moveaxis(img.numpy(), 0, -1)\nfig = plt.imshow(img)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\ni = 0\nfor box in boxes:\n    clr = ''\n    if labels[i] == 1:\n        clr = 'g'\n    elif labels[i] == 2:\n        clr = 'r'\n    else:\n        clr = 'o'\n    i += 1\n    rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n                             linewidth=2, edgecolor=clr, facecolor='none')\n    ax.add_patch(rect)","8f53d12a":"torch.save(model.state_dict(), '.\/Mask_Detection_Model_v1.pth')","5fb3dc09":"# Train Face Mask Detection Model using PyTorch"}}