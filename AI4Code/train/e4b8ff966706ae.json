{"cell_type":{"5a5a68d2":"code","9d07b437":"code","57cc75f2":"code","c1266598":"code","cd8620ec":"code","7928e198":"code","b59d42f7":"code","2c37a94d":"code","6cd3fc46":"code","2a0bbaa6":"code","6ffd6cd9":"code","fb242638":"code","d7444d1d":"code","f8abd5b2":"code","dc26992e":"code","001cc8ed":"code","25644a46":"code","6bfdce88":"code","11b21a71":"markdown","1d91dcab":"markdown","2b6c5f1b":"markdown","96c4154b":"markdown","c1cf93a5":"markdown","600c9acd":"markdown","264ae6f5":"markdown","c113b6f5":"markdown","97691ee7":"markdown","697e9148":"markdown","ed50320d":"markdown","345d9a01":"markdown","9fb80bcc":"markdown","2bc1b35c":"markdown","edb26041":"markdown","7180199f":"markdown","76092296":"markdown"},"source":{"5a5a68d2":"!pip install git+https:\/\/github.com\/fastai\/fastai@2e1ccb58121dc648751e2109fc0fbf6925aa8887 2>\/dev\/null 1>\/dev\/null","9d07b437":"from fastai.structured import rf_feat_importance\nfrom fastai.structured import train_cats,proc_df","57cc75f2":"import pandas as pd\nimport numpy as np \nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","c1266598":"import eli5\nfrom sklearn import linear_model\nimport lightgbm as lgb","cd8620ec":"train = pd.read_csv(\"..\/input\/train.csv\")","7928e198":"train_cats(train)","b59d42f7":"train.drop(\"id\",axis=1,inplace=True)","2c37a94d":"df, y, nas,_ = proc_df(train, 'target',do_scale=True)","6cd3fc46":"df.head()","2a0bbaa6":"m = RandomForestRegressor(n_estimators=100)\nm.fit(df, y)","6ffd6cd9":"fi = rf_feat_importance(m,df)","fb242638":"def plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","d7444d1d":"plot_fi(fi[fi.imp>0.005])","f8abd5b2":"model = lgb.LGBMRegressor(n_estimators = 100)\nmodel.fit(df, y)","dc26992e":"fi = pd.DataFrame()\nfi[\"feature\"] = df.columns\nfi[\"importance\"] = model.feature_importances_","001cc8ed":"top_imp_f = fi[fi.importance>5]\ntop_imp_f = top_imp_f.sort_values(by=\"importance\", ascending=False)\n        \n","25644a46":"top_imp_f.plot('feature', 'importance', 'barh', figsize=(12,7), legend=False)","6bfdce88":"eli5.show_weights(model, top=40)","11b21a71":"<h3><a href=\"https:\/\/datawhatnow.com\/feature-importance\/ \" target=\"_blank\">Feature importance and why it\u2019s important<\/a><\/h3>","1d91dcab":"<h3 style=\"color:#e60000\">Warning: For more accurate feature importance is better to use <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.KFold.html\" target=\"_blank\">k forld cross validation<\/a> and perform some <a href=\"https:\/\/www.kaggle.com\/willkoehrsen\/automated-model-tuning\" target=\"_blank\">parameter tuning<\/a> to the model <\/h3>","2b6c5f1b":"<h4><b>Data loading and quick preprocessing<\/b><h4>","96c4154b":"#### the data used in this kernel is from  <a href=\"https:\/\/www.kaggle.com\/c\/dont-overfit-ii\/data\" target=\"_blank\">don't overfit competition<\/a>","c1cf93a5":"<h3><b> What is Feature importance ? <\/b><\/h3>","600c9acd":"<h3><b>RandomForest<\/b><\/h3>","264ae6f5":"<h3>If you found this helpful a upvote would be very much appreciated :-)<\/h3>\n","c113b6f5":"## Thank you for reading ( \u0361\u1d54 \u035c\u0296 \u0361\u1d54 )","97691ee7":"<h4> <b>Import libraries<\/b>  <\/h4>","697e9148":"<h3><b>Eli5<\/b><\/h3> ","ed50320d":"<h3 style=\"color:#800000\"><b>To learn more about fast Ai library check the <a href=\"https:\/\/github.com\/fastai\/fastai\" target=\"_blank\" >Fastai repo<\/a> or this <a href=\"https:\/\/www.kaggle.com\/ishivinal\/a-quick-way-to-make-your-first-submission-fast-ai\" target=\"_blank\">kernel<\/a><\/b><\/h3>","345d9a01":"<h3 style=\"color:#b30000\"><b>This not the best way to perform feature importance techniques it's just a quick way how to use them <\/b><\/h3>","9fb80bcc":"<h3><b>Lighgbm <\/b><\/h3>","2bc1b35c":"<h3> In this kernel I will be showing 2 techniques to perfome feature importance (tree based models Feature importance and eli5 weights ) <\/h3>","edb26041":"<h2>Tree based feature importance using <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html\" target=\"_blank\">RandomForest<\/a> and <a href=\"https:\/\/lightgbm.readthedocs.io\/en\/latest\/\" target=\"_blank\">lighgbm<\/a> <\/h2>","7180199f":"<h4>Feature selection, the process of finding and selecting the most useful features in a dataset, is a crucial step of the machine learning pipeline. Unnecessary features decrease training speed, decrease model interpretability, and, most importantly, decrease generalization performance on the test set.<\/h4>","76092296":"<h3>eli5 is a way to compute feature importances on any model (logisticRegression,svm ...). <a href=\"https:\/\/eli5.readthedocs.io\/en\/latest\/blackbox\/permutation_importance.html\" target=\"_blank\">eli5 documentation<\/a>  + <a href=\"https:\/\/www.kaggle.com\/lopuhin\/eli5-for-mercari\">kernel: eli5 in action<\/a> <\/h3>"}}