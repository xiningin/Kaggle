{"cell_type":{"15d8a552":"code","cbdd78e9":"code","46e50cda":"code","270e6ef7":"code","4af32c93":"code","48d21333":"code","0f0285fd":"code","e8edcb41":"code","0518d7c8":"code","af7a4fc9":"code","d752b284":"code","f4c6bb87":"code","98100eaf":"code","8a2cdf8c":"code","70f82f22":"markdown"},"source":{"15d8a552":"from IPython.display import Image\nImage(\"..\/input\/amer_sign3.png\")","cbdd78e9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, SpatialDropout2D, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\n\nimport matplotlib.pyplot as plt","46e50cda":"# set up training data and labels\ndim_x = 28\ndim_y = 28\nbatch_size=32\n\n# read in data\/labels\nx_train = pd.read_csv('..\/input\/sign_mnist_train.csv')\nx_train.head()\nx_train.shape\ny_train = np.array(x_train['label'])\nx_train.drop('label', axis = 1, inplace = True)\nx_train = np.array(x_train.values)\n\nprint(\"data shapes\", x_train.shape, y_train.shape, \"classes: \",len(np.unique(y_train)))\n\nclasses = len(np.unique(y_train))\nx_train = x_train.reshape((-1, dim_x,dim_y,1))\n# convert labels to one-hot\nprint(np.unique(y_train))\ny = np.zeros((np.shape(y_train)[0],len(np.unique(y_train))))\n\n# skip over 'j'\ny_train[y_train>8] = y_train[y_train>8] - 1\n\n# convert index labels to one-hot\nfor ii in range(len(y_train)):\n    #print(y_train[ii])\n    y[ii,y_train[ii]] = 1\ny_train = y","270e6ef7":"# split into training\/validation\nno_validation = int(0.1 * (x_train.shape[0]))\n\nx_val = x_train[0:no_validation,...]\ny_val = y_train[0:no_validation,...]\n\nx_train = x_train[no_validation:,...]\ny_train = y_train[no_validation:,...]\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n\n# define image generators with mild augmentation\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\\\n                                   rotation_range=10,\\\n                                   width_shift_range=0.05,\\\n                                   height_shift_range=0.05,\\\n                                   shear_range=0.1,\\\n                                   zoom_range=0.075)\n\ntrain_generator = train_datagen.flow(x=x_train,\\\n                                     y=y_train,\\\n                                     batch_size=batch_size,\\\n                                     shuffle=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\nval_generator = test_datagen.flow(x=x_val,\\\n                                    y=y_val,\\\n                                    batch_size=batch_size,\\\n                                    shuffle=True)\n","4af32c93":"# define model Le-Net5\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=6, kernel_size=(5,5), strides=1,input_shape=(dim_x,dim_y,1), activation=tf.nn.tanh))\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), strides=1, activation=tf.nn.tanh))\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(120,activation=tf.nn.tanh))\nmodel.add(Dense(84,activation=tf.nn.tanh))\nmodel.add(Dense(classes, activation=tf.nn.softmax))\n\nmodel.summary()","48d21333":"model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])","0f0285fd":"steps_per_epoch = int(len(y_train)\/batch_size)\nmax_epochs = 64\nhistory = model.fit_generator(generator=train_generator,\\\n                                steps_per_epoch=steps_per_epoch,\\\n                                validation_data=val_generator,\\\n                                validation_steps=50,\\\n                                epochs=max_epochs,\\\n                                verbose=2)","e8edcb41":"plt.figure(figsize=(15,8))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title(\"Accuracy\",fontsize=28)\nplt.xlabel('epoch',fontsize=18)\nplt.ylabel('accuracy',fontsize=18)\nplt.legend(['Train','Val'],fontsize=18)\nplt.show()","0518d7c8":"x_test = pd.read_csv('..\/input\/sign_mnist_test.csv')\ny_test = x_test['label']\nx_test.head()","af7a4fc9":"\nx_test.drop('label', axis = 1, inplace = True)\nx_test = np.array(x_test.values)\nx_test = x_test \/ 255.\n\nprint(\"data shape\", x_test.shape)\n\nx_test = x_test.reshape((-1, dim_x,dim_y,1))","d752b284":"\n# convert labels to one-hot\nprint(np.unique(y_test))\n\ny_temp = np.zeros((np.shape(y_test)[0],len(np.unique(y_test))))\n\ny_test[y_test>8] = y_test[y_test>8] - 1\n\nfor ii in range(len(y_test)):\n    #print(y_train[ii])\n    y_temp[ii,y_test[ii]] = 1\ny_test = y_temp","f4c6bb87":"y_pred = model.predict(x_test)","98100eaf":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred.round())","8a2cdf8c":"# see how we did\n\ndef imshow_w_labels(img, target, pred):\n    plt.figure(figsize=(6,6))\n    plt.imshow(img, cmap=\"gray\")\n    plt.title(\"Prediction: %s, Target: %s\"%(target,pred), fontsize=24)\n    plt.show()\n\nletters = {}\ncounter = 0\nfor letter in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']:\n    letters[counter] = letter\n    counter += 1\n    \nfor kk in range(50,60):\n    imshow_w_labels(x_test[kk,:,:,0],letters[y_test[kk].argmax()], letters[y_pred[kk].argmax()])","70f82f22":"# Learning ASL with LeNet\nWhen people say that deep learning is nothing new, and that the concepts of were described in the 1980s and 1990s, <a href=\"https:\/\/en.wikipedia.org\/wiki\/LeNet\">LeNet<\/a> is one of the foundational networks they are talking about. This notebook uses the high-level keras API from Tensorflow to recreate LeNet and classify the letters of the alphabet in American Sign Language, excepting 'j' and 'z' (which rely on dynamic gestures). \n"}}