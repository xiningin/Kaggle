{"cell_type":{"6f3f5b1a":"code","ab122b9b":"code","70b5dede":"code","9bed2da2":"code","984ba94c":"code","3a4b7050":"code","f866af12":"code","92b5629f":"code","0d5fcf44":"code","49d8eb76":"code","d97a2b70":"code","8e66d78d":"code","dcc48621":"code","783ea9b0":"code","66afec43":"code","aabb0ba9":"code","214f6c64":"code","79e7538f":"code","b9f4617f":"code","d23f904b":"code","7fb51d4a":"code","eadd3208":"code","6eacf29b":"code","3a5326e1":"code","d1e08f49":"code","38777ab7":"code","cca30665":"code","1a4f72bc":"code","afbb8989":"markdown","042ebae3":"markdown","443550eb":"markdown","49bc08af":"markdown","2d9a4eb5":"markdown","8bdd52fb":"markdown","b7731d81":"markdown","a30e7a43":"markdown","714a77b4":"markdown","ef70cbce":"markdown","8d02b3ff":"markdown","5027ea2b":"markdown","4324c3b9":"markdown"},"source":{"6f3f5b1a":"# Import Keras with tensorflow backend\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import optimizers\nfrom keras.applications import VGG16\n\n# Import OpenCV\nimport cv2\n\n# Utility\nimport os\nimport numpy as np\nimport itertools\nimport random\nfrom collections import Counter\nfrom glob import iglob\n\n# Ignore warning\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Confusion Matrix & classification report\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Plot\nimport matplotlib.pyplot as plt\n%matplotlib inline ","ab122b9b":"# Set dataset folder path\nBASE_DATASET_FOLDER = os.path.join(\"..\",\"input\",\"derma_disease_dataset\",\"dataset\")\nTRAIN_FOLDER = \"train\"\nVALIDATION_FOLDER = \"validation\"\nTEST_FOLDER = \"test\"\n\n# ResNet50 image size\nIMAGE_SIZE = (224, 224)\nINPUT_SHAPE = (224, 224, 3)\n\n# Keras settings\nTRAIN_BATCH_SIZE = 64\nVAL_BATCH_SIZE = 8\nEPOCHS = 50\nLEARNING_RATE = 0.0001\nMODEL_PATH = os.path.join(\"derma_diseases_detection.h5\")","70b5dede":"def percentage_value(pct, allvals):\n    absolute = int(pct\/100.*np.sum(allvals))\n    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n\ndef plot_dataset_description(path, title):\n    classes = []\n    for filename in iglob(os.path.join(path, \"**\",\"*.jpg\")):\n        classes.append(os.path.split(os.path.split(filename)[0])[-1])\n\n    classes_cnt = Counter(classes)\n    values = list(classes_cnt.values())\n    labels = list(classes_cnt.keys())\n\n    plt.figure(figsize=(8,8))\n    plt.pie(values, labels=labels, autopct=lambda pct: percentage_value(pct, values), \n            shadow=True, startangle=140)\n\n    plt.title(title)    \n    plt.show()","9bed2da2":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(\n        os.path.join(BASE_DATASET_FOLDER, TRAIN_FOLDER),\n        target_size=IMAGE_SIZE,\n        batch_size=TRAIN_BATCH_SIZE,\n        class_mode='categorical', \n        shuffle=True)","984ba94c":"plot_dataset_description(os.path.join(BASE_DATASET_FOLDER, TRAIN_FOLDER), \"Train folder description\")","3a4b7050":"val_datagen = ImageDataGenerator(rescale=1.\/255)\nval_generator = val_datagen.flow_from_directory(\n        os.path.join(BASE_DATASET_FOLDER, VALIDATION_FOLDER),\n        target_size=IMAGE_SIZE,\n        class_mode='categorical', \n        shuffle=False)","f866af12":"plot_dataset_description(os.path.join(BASE_DATASET_FOLDER, VALIDATION_FOLDER), \"Validation folder description\")","92b5629f":"test_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_directory(\n        os.path.join(BASE_DATASET_FOLDER, TEST_FOLDER),\n        target_size=IMAGE_SIZE,\n        batch_size=VAL_BATCH_SIZE,\n        class_mode='categorical', \n        shuffle=False)","0d5fcf44":"plot_dataset_description(os.path.join(BASE_DATASET_FOLDER, TEST_FOLDER), \"Test folder description\")","49d8eb76":"classes = {v: k for k, v in train_generator.class_indices.items()}\nprint(classes)","d97a2b70":"vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)","8e66d78d":"for layer in vgg_model.layers[:-4]:\n    layer.trainable = False","dcc48621":"# Create the model\nmodel = Sequential()\n \n# Add the vgg convolutional base model\nmodel.add(vgg_model)\n \n# Add new layers\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(classes), activation='softmax'))","783ea9b0":"# Show a summary of the model. Check the number of trainable parameters\nmodel.summary()","66afec43":"# Compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n              metrics=['acc'])","aabb0ba9":"%%time\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n        epochs=EPOCHS,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples\/\/val_generator.batch_size)","214f6c64":"model.save(MODEL_PATH)","79e7538f":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","b9f4617f":"%%time\nloss, accuracy = model.evaluate_generator(test_generator,steps=test_generator.samples\/\/test_generator.batch_size)","d23f904b":"print(\"Accuracy: %f\\nLoss: %f\" % (accuracy,loss))","7fb51d4a":"%%time\nY_pred = model.predict_generator(test_generator,verbose=1, steps=test_generator.samples\/\/test_generator.batch_size)","eadd3208":"y_pred = np.argmax(Y_pred, axis=1)","6eacf29b":"cnf_matrix = confusion_matrix(test_generator.classes, y_pred)","3a5326e1":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    \n    plt.figure(figsize=(12,12))\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=18)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, fontsize=8)\n    plt.yticks(tick_marks, classes, fontsize=12)\n\n    fmt = '.2f'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontsize=16)\n    plt.xlabel('Predicted label', fontsize=16)","d1e08f49":"plot_confusion_matrix(cnf_matrix, list(classes.values()))","38777ab7":"print(classification_report(test_generator.classes, y_pred, target_names=list(classes.values())))","cca30665":"def load_image(filename):\n    img = cv2.imread(os.path.join(BASE_DATASET_FOLDER, TEST_FOLDER, filename))\n    img = cv2.resize(img, (IMAGE_SIZE[0], IMAGE_SIZE[1]) )\n    img = img \/255\n    \n    return img\n\n\ndef predict(image):\n    probabilities = model.predict(np.asarray([img]))[0]\n    class_idx = np.argmax(probabilities)\n    \n    return {classes[class_idx]: probabilities[class_idx]}","1a4f72bc":"for idx, filename in enumerate(random.sample(test_generator.filenames, 10)):\n    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n    \n    img = load_image(filename)\n    prediction = predict(img)\n    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n    plt.imshow(img)\n    plt.figure(idx)    \n    plt.show()","afbb8989":"### Test model\nEvauate model using test dataset","042ebae3":"### Confusion Matrix\nBuild and plot confusion matrix","443550eb":"### Compile model\nCompile model specifying the optimizer learning rate","49bc08af":"### Create model","2d9a4eb5":"### Load VGG16 model\nLoad the pre-trained VGG16 model without the top layer","8bdd52fb":"### Train model\ntrain model using validation dataset for validate each steps","b7731d81":"### Classification Report\nPrint classification report","a30e7a43":"### Random test\nRandom sample images from test dataset and predict ","714a77b4":"### Check Performance\nPlot training and validation accuracy and loss","ef70cbce":"### Data agumentation\nRead images in batches directly from folders and perform data augmentation","8d02b3ff":"### Settings\nDefine all settings usefull for next steps","5027ea2b":"### Freeze the layers except the last 4 layers","4324c3b9":"# Derma Diseases Detection\n- Performs fine tuning on Keras VGG16 in order to detect derma diseases such as: nevus, melanoma and seborrheic_keratosis"}}