{"cell_type":{"fe3f6916":"code","05edf83b":"code","56f0fee9":"code","30eab20d":"code","bfe5e972":"code","8f343966":"code","26f311e8":"code","106e5d12":"code","41c7ad6c":"code","d1ae50a2":"code","63d62f4d":"code","effdf9ed":"code","3477cc6b":"code","37378dc7":"code","fd38415e":"code","ede22de8":"code","e77abe5c":"code","03cfca50":"code","6bafb3ca":"code","66b7aba0":"code","f237bf5d":"code","baa436cf":"code","ce808628":"code","a8654afa":"code","debc27f6":"code","ca9d5b39":"code","79e18168":"markdown","c5206ecc":"markdown","019cf692":"markdown","650af3c5":"markdown","6ea420e9":"markdown","e07a1bbf":"markdown","45cc0056":"markdown","2cd4064c":"markdown","471834ae":"markdown","25d6d5a4":"markdown"},"source":{"fe3f6916":"import pandas as pd\nimport numpy as np\n\n\ndata = pd.read_csv('\/kaggle\/input\/sentimental-analysis-for-tweets\/sentiment_tweets3.csv')","05edf83b":"# checking null vallues present \ndata.isna().sum()","56f0fee9":"print(f'{data.shape} is the shape of the data')\nprint(f'Description: \\n{data.describe()}')","30eab20d":"print(f'Information: {data.info()}')","bfe5e972":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(data, title='Pandas Profiling Report', explorative=True)\n","8f343966":"profile.to_notebook_iframe()\n","26f311e8":"print(data[data['label (depression result)'] == 1].shape[0]\/data.shape[0] *100, \"% of the data is of label 1 \")\nprint(data[data['label (depression result)'] == 0].shape[0]\/data.shape[0] *100, \"% of the data is of label 0 \")","106e5d12":"# it is imbalanced. though I am here trying build a model without making it balanced. \n","41c7ad6c":"#Importing the required libraries  \n\n\nimport nltk\nfrom nltk.corpus import stopwords \nimport string \nnltk.download('stopwords')\nnltk.download('punkt')\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport spacy\nnlp = spacy.load('en')\nlmtzr = WordNetLemmatizer()\ndef text_preprocess(text):\n    lm = []\n    text = nlp(text)\n    for token in text:\n        lm.append(token.lemma_)\n        \n    text = \" \".join(lm)\n    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n   \n\n    \n    return \" \".join(text)","d1ae50a2":"# changing the column names\n\ndata.columns = data.columns.str.replace(\" \", \"_\")","63d62f4d":"# checking the preprocessor\ntext_preprocess('helloo my name is rushi')","effdf9ed":"data['processed'] = data['message_to_examine'].apply(text_preprocess)","3477cc6b":"data.shape","37378dc7":"data['processed'][:10]","fd38415e":"data['processed1'] = data.processed.str.replace(r\"[0-9]\",\"\")","ede22de8":"data['processed1'][:10]","e77abe5c":"from sklearn.feature_extraction.text import TfidfVectorizer \nvectorizer = TfidfVectorizer(\"english\")","03cfca50":"processed  = vectorizer.fit_transform(data['processed1'] ) \n","6bafb3ca":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train,y_test = train_test_split(processed, data['label_(depression_result)'], test_size=0.2)","66b7aba0":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","f237bf5d":"# improting models\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB","baa436cf":"# creating the instance of the models\nlr = LogisticRegression(solver='liblinear', penalty='l1')\nmnb = MultinomialNB()","ce808628":"# fitting the model\nprint(lr.fit(X_train, y_train))\nprint(mnb.fit(X_train, y_train))","a8654afa":"from sklearn.metrics import confusion_matrix, accuracy_score\n\ndef conf_matrix_acc(y_true, y_pred):\n    print(f'Confusion matrix\\n:{confusion_matrix(y_true, y_pred)}\\n')\n    print(f'Accuracy score is : {accuracy_score(y_true, y_pred)}')","debc27f6":"y_pred_lr = lr.predict(X_test)\ny_pred_mnb = mnb.predict(X_test)\n","ca9d5b39":"conf_matrix_acc(y_test,y_pred_lr )\nconf_matrix_acc(y_test, y_pred_mnb)","79e18168":"# Do Upvote ","c5206ecc":"# Evaluating ","019cf692":"#### MultinomailNB and Logistic Regression classifier","650af3c5":"# Sentiment Analysis Using ML model \n- Task to classify the person is depressed or not\n- I am here using logistic regression and Naive bayes classification \n\n## What is depression? \n- A mental health disorder characterised by persistently depressed mood or loss of interest in activities, causing significant impairment in daily life.\n- Possible causes include a combination of biological, psychological and social sources of distress. Increasingly, research suggests that these factors may cause changes in brain function, including altered activity of certain neural circuits in the brain.\n- The persistent feeling of sadness or loss of interest that characterises major depression can lead to a range of behavioural and physical symptoms. These may include changes in sleep, appetite, energy level, concentration, daily behaviour or self-esteem. Depression can also be associated with thoughts of suicide.\n- The mainstay of treatment is usually medication, talk therapy or a combination of the two. Increasingly, research suggests that these treatments may normalise brain changes associated with depression.\n\n\n                                               ","6ea420e9":"# Training","e07a1bbf":"![It has to end](https:\/\/images.pexels.com\/photos\/3958470\/pexels-photo-3958470.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)\nsource : https:\/\/images.pexels.com\/photos\/3958470\/pexels-photo-3958470.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940\n\ncredits: https:\/\/www.pexels.com\/@polina-zimmerman","45cc0056":"![gif](https:\/\/media1.tenor.com\/images\/ea245f1e9eca7421d75e635fc7ae4120\/tenor.gif?itemid=12451028)","2cd4064c":"# Let's talk about data now\n- data has three columns [index, Message_to_examine, Labels(target)]\n- Over 10k rows. \n- message is in text format \n- label is of 0 or 1. \n\n## Steps to create sentiment classifier using LR and NB \n1. See the data\n2. Preprocessing : \n        1.Remove punctuation \n        2. Remove stopwords \n        3. Lemmatization( Normalizing the words to its real form) \n        4. Remove the non-textual data from the dataset \n3. Create vectors for the words (using TfidfVectorizer)\n4. Initialize the model\n5. Fit the model\n6. Do the predictions\n\n        ","471834ae":"## Let's End the Depression !\n\n\n### \u2764\ufe0f Following are some ways to cure. \u2764\ufe0f \n* Try to talk.\n* Do something new.\n* Keep yourself busy.\n\n#  Call your buddy. \n\n* Get Routine\n* Run\/Exercise(personal experience: it works)\n* Try to think less.\n\n\n","25d6d5a4":"- Logistic Regression is Performing better than NB \n- Neural Network will Perform better than these two since these are the basic algorithms yet they are performing great here \n- LSTM .. coming soon"}}