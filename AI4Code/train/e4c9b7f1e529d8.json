{"cell_type":{"3cbf942f":"code","54eb5a81":"code","8afa726e":"code","0dfecaff":"code","0b2ef180":"code","0e1e8b69":"code","21d36457":"code","3dae3da0":"code","bf5b784d":"code","5298b9be":"code","34b22c91":"code","8cfa41fd":"code","6362b7a7":"code","47cc3b02":"markdown","37a62093":"markdown","c6d4113e":"markdown"},"source":{"3cbf942f":"import numpy as np \nimport pandas as pd\nfrom sklearn import *\nimport lightgbm as lgb\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm","54eb5a81":"train = pd.read_csv(\"\/kaggle\/input\/ionswitchingkl\/datasets\/trainK.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/ionswitchingkl\/datasets\/testK.csv\")","8afa726e":"def features(df):\n    df = df.sort_values(by=['time']).reset_index(drop=True)\n    df.index = ((df.time * 10_000) - 1).values\n    df['batch'] = df.index \/\/ 50_000\n    df['batch_index'] = df.index  - (df.batch * 50_000)\n    df['batch_slices'] = df['batch_index']  \/\/ 5_000\n    df['batch_slices2'] = df.apply(lambda r: '_'.join([str(r['batch']).zfill(3), str(r['batch_slices']).zfill(3)]), axis=1)\n    \n    for c in ['batch','batch_slices2']:\n        d = {}\n        d['mean'+c] = df.groupby([c])['signal'].mean()\n        d['median'+c] = df.groupby([c])['signal'].median()\n        d['max'+c] = df.groupby([c])['signal'].max()\n        d['min'+c] = df.groupby([c])['signal'].min()\n        d['std'+c] = df.groupby([c])['signal'].std()\n        d['mean_abs_chg'+c] = df.groupby([c])['signal'].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        d['abs_max'+c] = df.groupby([c])['signal'].apply(lambda x: np.max(np.abs(x)))\n        d['abs_min'+c] = df.groupby([c])['signal'].apply(lambda x: np.min(np.abs(x)))\n        for v in d:\n            df[v] = df[c].map(d[v].to_dict())\n        df['range'+c] = df['max'+c] - df['min'+c]\n        df['maxtomin'+c] = df['max'+c] \/ df['min'+c]\n        df['abs_avg'+c] = (df['abs_min'+c] + df['abs_max'+c]) \/ 2\n    \n    #add shifts\n    df['signal_shift_+1'] = [0,] + list(df['signal'].values[:-1])\n    df['signal_shift_-1'] = list(df['signal'].values[1:]) + [0]\n    df['signal_shift_+2'] = [0,0,] + list(df['signal'].values[:-2])\n    df['signal_shift_-2'] = list(df['signal'].values[2:]) + [0,0]\n    df['signal_shift_+3'] = [0,0,0,] + list(df['signal'].values[:-3])\n    df['signal_shift_-3'] = list(df['signal'].values[3:]) + [0,0,0]\n    for i in df[df['batch_index']==0].index:\n        df['signal_shift_+1'][i] = np.nan\n        df['signal_shift_+2'][i] = np.nan\n        df['signal_shift_+3'][i] = np.nan\n    for i in df[df['batch_index']==49999].index:\n        df['signal_shift_-1'][i] = np.nan\n        df['signal_shift_-2'][i] = np.nan\n        df['signal_shift_-3'][i] = np.nan\n\n    for c in [c1 for c1 in df.columns if c1 not in ['time', 'signal', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]:\n        df[c+'_msignal'] = df[c] - df['signal']\n        \n    return df\n\ntrain = features(train)\ntest = features(test)","0dfecaff":"WINDOWS=[10,50,100,500]\ndef create_rolling_features(df):\n    for window in WINDOWS:\n        df[\"rolling_mean_\" + str(window)] = df['signal'].rolling(window=window).mean()\n        df[\"rolling_std_\" + str(window)] = df['signal'].rolling(window=window).std()\n        df[\"rolling_var_\" + str(window)] = df['signal'].rolling(window=window).var()\n        df[\"rolling_min_\" + str(window)] = df['signal'].rolling(window=window).min()\n        df[\"rolling_max_\" + str(window)] = df['signal'].rolling(window=window).max()\n        df[\"rolling_min_max_ratio_\" + str(window)] = df[\"rolling_min_\" + str(window)] \/ df[\"rolling_max_\" + str(window)]\n        df[\"rolling_min_max_diff_\" + str(window)] = df[\"rolling_max_\" + str(window)] - df[\"rolling_min_\" + str(window)]\n\n    df = df.replace([np.inf, -np.inf], np.nan)    \n    df.fillna(0, inplace=True)\n    return df\n\ntrain = create_rolling_features(train)\ntest = create_rolling_features(test)","0b2ef180":"#================Model building ===============================","0e1e8b69":"col = [c for c in train.columns if c not in ['time', 'open_channels', 'batch', 'batch_index', 'batch_slices', 'batch_slices2']]\n#x1, x2, y1, y2 = model_selection.train_test_split(train[col], train['open_channels'], test_size=0.1, random_state=7)\n","21d36457":"def f1_score_calc(y_true, y_pred):\n    return f1_score(y_true, y_pred, average=\"macro\")\n\ndef lgb_Metric(preds, dtrain):\n    labels = dtrain.get_label()\n    preds = np.round(np.clip(preds, 0, 10)).astype(int)\n    score = f1_score(labels, preds, average=\"macro\")\n    return ('KaggleMetric', score, True)","3dae3da0":"params = { 'n_estimators':1500,\n          'boosting_type': 'gbdt',\n          'max_depth' : 12,\n          'nthread': 3, # Updated from nthread\n          'num_leaves': 207,\n          'learning_rate': 0.08,\n          'max_bin': 200,\n          'subsample_freq': 1,\n           'lambda_l2': 0.10,\n          'lambda_l1': 0.30,\n          'min_split_gain': 0.06,\n          'min_child_weight': 27,\n          'scale_pos_weight': 1,\n          'feature_fraction':0.93,\n          'bagging_fraction':0.93,\n          'min_data_in_leaf':21,\n          'metric' : 'rmse'}","bf5b784d":"#=================prediction=============","5298b9be":"X = train[col].values\nY = train['open_channels'].values\nd_train = lgb.Dataset(X,Y)\nmodel = lgb.train(params, d_train, 1500)","34b22c91":"#Submission dataset\ny_test = model.predict(test[col])\n\ny_test = np.round(np.clip(y_test, 0, 10)).astype(int)","8cfa41fd":"test[\"open_channels\"] = y_test","6362b7a7":"test[['time','open_channels']].to_csv('submission_rollingM.csv', index=False, float_format='%.4f')","47cc3b02":"model = lgb.train(params, lgb.Dataset(x1, y1),1500,  lgb.Dataset(x2, y2),\n                              verbose_eval=50, early_stopping_rounds=100, feval=lgb_Metric)","37a62093":"from pykalman import KalmanFilter\ndef Kalman1D(observations,damping=1):\n    # To return the smoothed time series data\n    observation_covariance = damping\n    initial_value_guess = observations[0]\n    transition_matrix = 1\n    transition_covariance = 0.1\n    initial_value_guess\n    kf = KalmanFilter(\n            initial_state_mean=initial_value_guess,\n            initial_state_covariance=observation_covariance,\n            observation_covariance=observation_covariance,\n            transition_covariance=transition_covariance,\n            transition_matrices=transition_matrix\n        )\n    pred_state, state_cov = kf.smooth(observations)\n    return pred_state\n\n# Kalman Filter\nobservation_covariance = .0015\ntrain['signal'] = Kalman1D(train.signal.values,observation_covariance)\ntest['signal'] = Kalman1D(test.signal.values,observation_covariance)\n","c6d4113e":"#load the datasets\ntrain = pd.read_csv(\"datasets\/train.csv\")\ntest = pd.read_csv(\"datasets\/test.csv\")\nsample = pd.read_csv(\"datasets\/sample_submission.csv\")"}}