{"cell_type":{"b5e65e50":"code","60b9b535":"code","ef7d25ca":"code","c1afa3f9":"code","4d6be73a":"code","20abf46f":"code","a6658763":"code","e2d61275":"code","155e6c66":"code","d5ac65fd":"code","f3ea1235":"code","0c4e3abd":"code","ab3d0e5e":"code","3ee4be38":"code","9e943d1b":"code","933e5160":"code","1532aead":"code","f6a03746":"code","c553f185":"code","52b40f99":"code","171f3e76":"code","45817bf6":"code","6b5dacf2":"code","bc065eae":"code","a5b9f729":"code","ef99fb4a":"code","596dd9e6":"code","cf2f8cd3":"code","b2505d32":"code","fb95d41a":"code","31c534a8":"code","58652498":"markdown","c2fc3604":"markdown","86017e4a":"markdown","c7ebb752":"markdown","a4eec8c3":"markdown","12921b56":"markdown","28a45276":"markdown"},"source":{"b5e65e50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n'#'\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","60b9b535":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom ml_metrics import rmse\n\n","ef7d25ca":"trainData = pd.read_csv('\/kaggle\/input\/neolen-house-price-prediction\/train.csv', index_col='Id')\ntestData = pd.read_csv('\/kaggle\/input\/neolen-house-price-prediction\/test.csv', index_col='Id')\n","c1afa3f9":"trainData.head()","4d6be73a":"trainData.describe()","20abf46f":"#Dataset Shape\nprint(\"shape of train Data :\",trainData.shape)\nprint(\"shape of test Data :\",testData.shape)\n","a6658763":"#select columns with most nan values\nmost_nan_colums=[]\nfor cols in trainData.columns:\n    if trainData[cols].isnull().sum()>1000:\n        most_nan_colums.append(cols)\n#These columns have nans but this doesnot mean they none values , na means 0 not existed in apertment\nprint(\"columns that is mostly nan : \",most_nan_colums)","e2d61275":"for cols in trainData.columns:\n    print(cols, trainData[cols].dtype)","155e6c66":"# Min , Max House prices\n#\nprint(\"The cheapest house sold for ${:,.0f} and the most expensive house sold for ${:,.0f}\".format(trainData.SalePrice.min(),trainData.SalePrice.max()))\nprint(\"The Average Sales Price is ${:,.0f}, while median is ${:,.0f}\".format(trainData.SalePrice.mean(),trainData.SalePrice.median()))\n","d5ac65fd":"# Histogram of house prices to detect outliers based on prices\ntrainData.SalePrice.hist(bins=100,rwidth = 0.9,figsize=(20,7))\nplt.title('House Prices')\nplt.show()","f3ea1235":"#Analysing the Year of Built\nprint('Oldest house built in the Year {} and Newest house built in the Year {}'.format(trainData.YearBuilt.min(),trainData.YearBuilt.max()))","0c4e3abd":"# Histogram of yearBuilt to detect outliers \ntrainData.YearBuilt.hist(bins=30,rwidth=.9,figsize=(20,7))\nplt.title('When the Houses is built')\nplt.show()\n\n","ab3d0e5e":"#draw a seaborn correlation heatmap to detect correlation between features for feature selection process\nfig, ax = plt.subplots(figsize=(30,30))         # Sample figsize in inches\nsns.heatmap(trainData.corr(), annot = True,ax=ax)","3ee4be38":"trainData.info()","9e943d1b":"sns.pairplot(trainData[['MSSubClass','MSZoning','LotFrontage','LotArea','Street','BsmtExposure','SaleType','SaleCondition','SalePrice']])","933e5160":"#first drop columns with most nan values from train and test data set\ntrainData.drop(most_nan_colums, axis=1, inplace=True)\ntestData.drop(most_nan_colums, axis=1, inplace=True)\n#show the shape of train and test data\nprint(\"shape of train Data :\",trainData.shape)\nprint(\"shape of test Data :\",testData.shape)\n","1532aead":"# i tried to select high correlated features from the heat map manually but it's hard to do this way\ntrainData_trial=trainData[['OverallQual','GarageCars','GarageArea','GrLivArea','SalePrice']]\ntrainData_trial.head()","f6a03746":"# this line of code select columns that highly correlated with the house prices column.\nmostCorrelated=abs(trainData.corr()['SalePrice']) >= 0.5\ntrainData=trainData[mostCorrelated.index[mostCorrelated]]","c553f185":"#if column correlation value with saleprice is >=0.5 it's value is True else it's False\nmostCorrelated","52b40f99":"trainData.head()","171f3e76":"#check if rows that contain null values \nnumOfNan=trainData.isnull().sum()\nprint(\"total number of nan in each column is :\",numOfNan)","45817bf6":"#split train data into features annd target\nY = trainData.SalePrice              \ntrainData.drop(['SalePrice'], axis=1, inplace=True)","6b5dacf2":"#split data for train and validation\nX_train, X_valid, y_train, y_valid = train_test_split(trainData, Y, train_size=0.8, test_size=0.2,\n                                                                random_state=42)","bc065eae":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train,y_train)\npreds_valid = model.predict(X_valid)\nprint(\"Score is : \",rmse(y_valid,preds_valid))","a5b9f729":"# Define  model as an object of XGBRegressor\nmodel = XGBRegressor(n_estimators=350,max_depth=15,learning_rate=.1,random_state=1,\n                     n_jobs=10, subsample=1,min_child_weight=0.6) # Your code here\n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Get validation predictions and MAE\npredictedPrices = model.predict(X_valid)\n\n\nprint(\"RMSE Score on validation data\")\nprint(rmse(y_valid, predictedPrices))","ef99fb4a":"# Define  model as an object of XGBRegressor\nmodel = XGBRegressor(n_estimators=400,max_depth=25,learning_rate=.01,random_state=1,\n                     n_jobs=20, subsample=1,min_child_weight=0.6) \n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Get validation predictions and MAE\npredictedPrices = model.predict(X_valid)\n\n\nprint(\"RMSE Score on validation data\")\nprint(rmse(y_valid, predictedPrices))","596dd9e6":"#selected the most correlated columns that is decided based on the train data\nmostCorrelated.drop(['SalePrice'], inplace=True)\ntestData=testData[mostCorrelated.index[mostCorrelated]]","cf2f8cd3":"#check if test rows contain null values \nnumOfNan=testData.isnull().sum()\nprint(\"total number of nan in each column is :\",numOfNan)","b2505d32":"testData.head()","fb95d41a":"#prediction of prices for testData\nprices_Test=model.predict(testData)","31c534a8":"# Save test predictions to CSV\noutput = pd.DataFrame({'Id': testData.index,\n                       'SalePrice': prices_Test})\noutput.to_csv('msubmission.csv', index=False)\nprint('done')","58652498":"# Data Preprocessing","c2fc3604":"# Reading Data","86017e4a":"**Building model using XGBRegressor**","c7ebb752":"### preprocess and prepare Test Data\n","a4eec8c3":"# Exploratory DataAnalysis","12921b56":"# Imports","28a45276":"**Trying Same model but with different hyper parameters**"}}