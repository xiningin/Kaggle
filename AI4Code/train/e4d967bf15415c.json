{"cell_type":{"bb653cc1":"code","3fbdcf80":"code","3096b049":"code","09110952":"code","d01dcf4f":"code","40b4d02a":"code","d0754612":"code","2714771a":"code","9f7b9681":"code","0b08d26d":"code","e59573bb":"code","ffaa98ea":"code","382ec8fc":"code","77ab34e3":"code","0ef29a16":"code","06d813d9":"code","4f347006":"code","16491b86":"code","87eaab02":"code","2b293340":"code","071bc9bc":"code","2cc4c352":"code","5ef362ff":"code","67b2dc11":"code","a8021241":"code","ada6aef2":"code","d23aeae6":"code","42c6bc53":"code","508f2562":"code","5e7a6985":"code","a3d27d30":"code","456bfc79":"code","0d403163":"code","9eda42cb":"code","b4040472":"code","a4d5259c":"code","eb5a5f17":"markdown","ebf3096d":"markdown","e4f6f828":"markdown","96950170":"markdown","4bc0abea":"markdown","433d867d":"markdown","5cd4cfb0":"markdown","31ad593d":"markdown","9e84ef9e":"markdown","a16956fe":"markdown","a6b809c4":"markdown","41fb8b43":"markdown","f4d2ad09":"markdown","434d41ca":"markdown"},"source":{"bb653cc1":"#!pip install timm \nimport sys \nsys.path.append('..\/input\/pytorch-images-seresnet')\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n","3fbdcf80":"import os \nfrom tqdm.notebook import tqdm  \n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\nfrom sklearn import model_selection \nfrom sklearn import preprocessing \nfrom sklearn import metrics \nimport torch \nfrom torch.utils.data import Dataset, DataLoader \nfrom torch.nn.parameter import Parameter \nimport torch.nn as nn \nimport torchvision\nfrom torchvision import models\nimport albumentations \nfrom albumentations import * \nfrom albumentations.pytorch import ToTensorV2 \n\nimport timm \nfrom torch.cuda.amp import autocast, GradScaler \n\nfrom PIL import Image, ImageFile\nimport cv2\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","3096b049":"Resnet_model_path = '..\/input\/resnet200d-public\/resnet200d_320_CV9632.pth'\nSeresnet_model_path = '..\/input\/seresnet152d-cv9615\/seresnet152d_320_CV96.15.pth'\nResnet50_32_4D_path = '..\/input\/pretrained-resnext50-32x4d\/resnext50_32x4d-7cdf4587.pth'\nEffnet_B5 = '..\/input\/efficientnet-pytorch\/efficientnet-b5-586e6cc6.pth'\nTEST_PATH = '..\/input\/ranzcr-clip-catheter-line-classification\/test\/'","09110952":"os.listdir('..\/input\/ranzcr-clip-catheter-line-classification\/train_tfrecords\/\/')[:10]","d01dcf4f":"DIR = '..\/input\/ranzcr-clip-catheter-line-classification'\ntrain_dir = os.path.join(DIR,'train.csv')\ntest_dir = os.path.join(DIR, 'sample_submission.csv')","40b4d02a":"train_df = pd.read_csv(train_dir)\ntest_df = pd.read_csv(test_dir)\ntrain_df.head()","d0754612":"train_df[(train_df['ETT - Normal'] == 1) & (train_df['NGT - Normal'] == 1) & (train_df['CVC - Normal'] == 1)].sum()","2714771a":"train_df.isnull().sum()","9f7b9681":"target_columns = []\n[target_columns.append(x) for x in test_df.columns if x not in ['StudyInstanceUID','PatientID']]\ntarget_columns","0b08d26d":"for c in range(len(target_columns)):\n    plt.figure()\n    train_df[target_columns[c]].hist()\n    plt.title(target_columns[c])","e59573bb":"train_df['PatientID'].unique().shape[0]","ffaa98ea":"df_annotate = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/train_annotations.csv')","382ec8fc":"df_annotate.head()","77ab34e3":"df_annotate.label.value_counts()","0ef29a16":"if (\"1.2.826.0.1.3680043.8.498.10003659706701445041816900371598078663\" in test_df.StudyInstanceUID.values) : \n    print (\"True\")\nelse : \n    print('False')","06d813d9":"output_dir = '.\/'\nif not os.path.exists(output_dir): \n    os.makedirs(output_dir)\n    ","4f347006":"IMAGE_SIZE = 640 \nBATCH_SIZE = 32 ","16491b86":"class TestDataset(Dataset): \n    def __init__(self,df,resize=None,transform=None): \n        self.df = df \n        self.file_name = df['StudyInstanceUID'].values \n        self.transform = transform\n        self.resize = resize \n        \n    def __len__(self): \n        return len(self.df)\n    \n    def __getitem__(self,idx): \n        file_name = self.file_name[idx] \n        file_path = f'{TEST_PATH}\/{file_name}.jpg' \n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.resize is not None : \n            image.resize = [\n                self.resize[1],\n                self.resize[0]\n            ]\n        \n        if self.transform is not None: \n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image \n        ","87eaab02":"def get_transforms():\n        return Compose([\n            Resize(IMAGE_SIZE, IMAGE_SIZE),\n            Normalize(\n            mean = [0.485, 0.456, 0.406], \n            std = [0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","2b293340":"test_aug = Compose([\n        Resize(IMAGE_SIZE,IMAGE_SIZE),\n        Normalize (\n            mean = [0.485, 0.456, 0.406], \n            std = [0.229, 0.224, 0.225],\n        ), \n        ToTensorV2(),\n    ])\n    \n","071bc9bc":"#m1 = timm.create_model(model_name='resnet200d_320',pretrained=False)\n#timm.list_models()","2cc4c352":"class Resnet200D(nn.Module) : \n    def __init__(self, model_name='resnet200d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","5ef362ff":"#m2 = timm.create_model('seresnet152d')\n#m2","67b2dc11":"class SeResnet152D(nn.Module): \n    def __init__(self, model_name='seresnet152d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output\n        ","a8021241":"#m3 = timm.create_model('resnext50_32x4d')\n#m3","ada6aef2":"class Resnet5032(nn.Module): \n    def __init__(self,model_name = 'resnext50_32x4d'): \n        super().__init__()\n        self.model = timm.create_model(model_name,pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features,11)\n    def forward(self,x): \n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs,-1)\n        output = self.fc(pooled_features)\n        return output ","d23aeae6":"class EffB5(nn.Module): \n    def __init__(self,model_name = 'efficientnet_b5'): \n        super().__init__()\n        self.model = timm.create_model(model_name,pretrained=False)\n        n_features = self.model.classifier.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.classifier = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features,11)\n    def forward(self,x): \n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs,-1)\n        output = self.fc(pooled_features)\n        return output ","42c6bc53":"#EfficientNet = EffB5()\n#EfficientNet.load_state_dict(torch.load(Effnet_B5))","508f2562":"seresnet_model = SeResnet152D()\nseresnet_model.load_state_dict(torch.load(Seresnet_model_path)['model'])\nseresnet_model.eval()\nseresnet_model.to(device)","5e7a6985":"resnet_model = Resnet200D()\nresnet_model.load_state_dict(torch.load(Resnet_model_path)['model'])\nresnet_model.eval() \nresnet_model.to(device)\n","a3d27d30":"\n#resnext5032.load_state_dict(torch.load(Resnet50_32_4D_path))\n#weightss= torch.load(Resnet50_32_4D_path)\n#resnext5032 = Resnet5032() \n#resnext5032.load_state_dict(weightss)","456bfc79":"models = [resnet_model,seresnet_model]","0d403163":"def inference(models, test_loader, device): \n    probs = []\n    for i, (images) in tqdm(enumerate(test_loader),total= len(test_loader)) : \n        images = images.to(device)\n        avg_preds = []\n        for model in models : \n            with torch.no_grad():\n                y_preds1 = model(images)\n                y_preds2 = model(images.flip(-1))\n            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) \/ 2 \n            avg_preds.append(y_preds)\n        avg_preds = np.mean(avg_preds,axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs\n            ","9eda42cb":"resnet_model","b4040472":"test_dataset = TestDataset(test_df, transform=test_aug)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, \n                         num_workers=4 , pin_memory=True)\nmodel200D = []\nmodel200D.append(resnet_model)\nmodel152D = []\nmodel152D.append(seresnet_model)\nprediction200D = inference(model200D, test_loader, device)\nprediction152D = inference(model152D, test_loader, device)\npredictions = (2 * prediction200D + prediction152D) \/ 3.0\n#predictions200d = inference(models200D, test_loader, device)\n#predictions152d = inference(models152D, test_loader, device)\n#predictions = (2 * predictions200d + predictions152d) \/ 3.0","a4d5259c":"target_cols = test_df.iloc[:, 1:12].columns.tolist()\ntest_df[target_cols] = predictions\ntest_df[['StudyInstanceUID'] + target_cols].to_csv('submission.csv', index=False)\ntest_df.head()","eb5a5f17":"# Read files ","ebf3096d":"## This Notebook is inspired by this Kernel : \n\n- https:\/\/www.kaggle.com\/alincijov\/ranzcr-resnet200d-seresnet152d-inference \n\nThe wieghts were imported from : \n- https:\/\/www.kaggle.com\/ammarali32\/resnet200d-public for (Resnet200d) \n- https:\/\/www.kaggle.com\/ammarali32\/seresnet152d-cv9615 for (Seresnet152d) \n\n- https:\/\/www.kaggle.com\/yasufuminakama\/pytorch-image-models (for Timm Libraries )\n\nThanks for all those persons","e4f6f828":"## Define Paths for pretrained models ","96950170":"# Load Pretrained models weights ","4bc0abea":"### We see that the data is skewed ****","433d867d":"# Just checking if the first image is on test or on sample_submission csv ","5cd4cfb0":"## Simple EDA ","31ad593d":"### Quick EDA","9e84ef9e":"## Import the libraries ","a16956fe":"## Resnet Model ","a6b809c4":"# Merge Models into list ","41fb8b43":"# Inference function ","f4d2ad09":"# Create target columns ****","434d41ca":"## Path for Models "}}