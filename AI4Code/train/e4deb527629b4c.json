{"cell_type":{"8fad71a5":"code","86f536e3":"code","c35358da":"code","b50f0a54":"code","7f8153a8":"code","9f4a2284":"code","ca2cce54":"code","99a79017":"code","7aa8ab84":"code","ebd71cff":"code","a46d84dd":"code","06af6a87":"code","2575474d":"code","4f2a45a1":"code","8e9ccd11":"code","3cf98f36":"code","9994a6b8":"code","bac0fc11":"code","a8ce17b6":"code","e3cac82a":"code","8b99b4e3":"code","bc67a820":"code","00236fb6":"markdown","42ac7dfb":"markdown","f50c70d8":"markdown","76f9eec3":"markdown","ea050acb":"markdown","7a00e73e":"markdown","3eae4af3":"markdown","ae067c9a":"markdown","cceba659":"markdown","e51b8fb5":"markdown","8f6309b3":"markdown","6e124534":"markdown","31fc677f":"markdown","89e82691":"markdown","d34dcff6":"markdown","026de8f8":"markdown","b433d779":"markdown","44b56e55":"markdown","04df1601":"markdown","aeca8b28":"markdown","f3af8970":"markdown","6998c7ae":"markdown","0e5ca606":"markdown"},"source":{"8fad71a5":"%matplotlib inline\nfrom IPython.core.display import display, HTML, Javascript\n\n# ----- Notebook Theme -----\n\nnotebook_theme = 'carrot'\ncolor_maps = {'turquoise': ['#1abc9c', '#e8f8f5', '#d1f2eb', '#a3e4d7', '#76d7c4', '#48c9b0', '#1abc9c', '#17a589', '#148f77', '#117864', '#0e6251'], 'green': ['#16a085', '#e8f6f3', '#d0ece7', '#a2d9ce', '#73c6b6', '#45b39d', '#16a085', '#138d75', '#117a65', '#0e6655', '#0b5345'], 'emerald': ['#2ecc71', '#eafaf1', '#d5f5e3', '#abebc6', '#82e0aa', '#58d68d', '#2ecc71', '#28b463', '#239b56', '#1d8348', '#186a3b'], 'nephritis': ['#27ae60', '#e9f7ef', '#d4efdf', '#a9dfbf', '#7dcea0', '#52be80', '#27ae60', '#229954', '#1e8449', '#196f3d', '#145a32'], 'peter': ['#3498db', '#ebf5fb', '#d6eaf8', '#aed6f1', '#85c1e9', '#5dade2', '#3498db', '#2e86c1', '#2874a6', '#21618c', '#1b4f72'], 'belize': ['#2980b9', '#eaf2f8', '#d4e6f1', '#a9cce3', '#7fb3d5', '#5499c7', '#2980b9', '#2471a3', '#1f618d', '#1a5276', '#154360'], 'amethyst': ['#9b59b6', '#f5eef8', '#ebdef0', '#d7bde2', '#c39bd3', '#af7ac5', '#9b59b6', '#884ea0', '#76448a', '#633974', '#512e5f'], 'wisteria': ['#8e44ad', '#f4ecf7', '#e8daef', '#d2b4de', '#bb8fce', '#a569bd', '#8e44ad', '#7d3c98', '#6c3483', '#5b2c6f', '#4a235a'], 'wet': ['#34495e', '#ebedef', '#d6dbdf', '#aeb6bf', '#85929e', '#5d6d7e', '#34495e', '#2e4053', '#283747', '#212f3c', '#1b2631'], 'midnight': ['#2c3e50', '#eaecee', '#d5d8dc', '#abb2b9', '#808b96', '#566573', '#2c3e50', '#273746', '#212f3d', '#1c2833', '#17202a'], 'sunflower': ['#f1c40f', '#fef9e7', '#fcf3cf', '#f9e79f', '#f7dc6f', '#f4d03f', '#f1c40f', '#d4ac0d', '#b7950b', '#9a7d0a', '#7d6608'], 'orange': ['#f39c12', '#fef5e7', '#fdebd0', '#fad7a0', '#f8c471', '#f5b041', '#f39c12', '#d68910', '#b9770e', '#9c640c', '#7e5109'], 'carrot': ['#e67e22', '#fdf2e9', '#fae5d3', '#f5cba7', '#f0b27a', '#eb984e', '#e67e22', '#ca6f1e', '#af601a', '#935116', '#784212'], 'pumpkin': ['#d35400', '#fbeee6', '#f6ddcc', '#edbb99', '#e59866', '#dc7633', '#d35400', '#ba4a00', '#a04000', '#873600', '#6e2c00'], 'alizarin': ['#e74c3c', '#fdedec', '#fadbd8', '#f5b7b1', '#f1948a', '#ec7063', '#e74c3c', '#cb4335', '#b03a2e', '#943126', '#78281f'], 'pomegranate': ['#c0392b', '#f9ebea', '#f2d7d5', '#e6b0aa', '#d98880', '#cd6155', '#c0392b', '#a93226', '#922b21', '#7b241c', '#641e16'], 'clouds': ['#ecf0f1', '#fdfefe', '#fbfcfc', '#f7f9f9', '#f4f6f7', '#f0f3f4', '#ecf0f1', '#d0d3d4', '#b3b6b7', '#979a9a', '#7b7d7d'], 'silver': ['#bdc3c7', '#f8f9f9', '#f2f3f4', '#e5e7e9', '#d7dbdd', '#cacfd2', '#bdc3c7', '#a6acaf', '#909497', '#797d7f', '#626567'], 'concrete': ['#95a5a6', '#f4f6f6', '#eaeded', '#d5dbdb', '#bfc9ca', '#aab7b8', '#95a5a6', '#839192', '#717d7e', '#5f6a6a', '#4d5656'], 'asbestos': ['#7f8c8d', '#f2f4f4', '#e5e8e8', '#ccd1d1', '#b2babb', '#99a3a4', '#7f8c8d', '#707b7c', '#616a6b', '#515a5a', '#424949']}\n# color_maps = {'red': ['#f44336', '#ffebee', '#ffcdd2', '#ef9a9a', '#e57373', '#ef5350', '#f44336', '#e53935', '#d32f2f', '#c62828', '#b71c1c', '#ff8a80', '#ff5252', '#ff1744', '#d50000'], 'pink': ['#e91e63', '#fce4ec', '#f8bbd0', '#f48fb1', '#f06292', '#ec407a', '#e91e63', '#d81b60', '#c2185b', '#ad1457', '#880e4f', '#ff80ab', '#ff4081', '#f50057', '#c51162'], 'purple': ['#9c27b0', '#f3e5f5', '#e1bee7', '#ce93d8', '#ba68c8', '#ab47bc', '#9c27b0', '#8e24aa', '#7b1fa2', '#6a1b9a', '#4a148c', '#ea80fc', '#e040fb', '#d500f9', '#aa00ff'], 'deep': ['#673ab7', '#ede7f6', '#d1c4e9', '#b39ddb', '#9575cd', '#7e57c2', '#673ab7', '#5e35b1', '#512da8', '#4527a0', '#311b92', '#b388ff', '#7c4dff', '#651fff', '#6200ea', '#ff5722', '#fbe9e7', '#ffccbc', '#ffab91', '#ff8a65', '#ff7043', '#ff5722', '#f4511e', '#e64a19', '#d84315', '#bf360c', '#ff9e80', '#ff6e40', '#ff3d00', '#dd2c00'], 'indigo': ['#3f51b5', '#e8eaf6', '#c5cae9', '#9fa8da', '#7986cb', '#5c6bc0', '#3f51b5', '#3949ab', '#303f9f', '#283593', '#1a237e', '#8c9eff', '#536dfe', '#3d5afe', '#304ffe'], 'blue': ['#2196f3', '#e3f2fd', '#bbdefb', '#90caf9', '#64b5f6', '#42a5f5', '#2196f3', '#1e88e5', '#1976d2', '#1565c0', '#0d47a1', '#82b1ff', '#448aff', '#2979ff', '#2962ff', '#607d8b', '#eceff1', '#cfd8dc', '#b0bec5', '#90a4ae', '#78909c', '#607d8b', '#546e7a', '#455a64', '#37474f', '#263238'], 'light': ['#03a9f4', '#e1f5fe', '#b3e5fc', '#81d4fa', '#4fc3f7', '#29b6f6', '#03a9f4', '#039be5', '#0288d1', '#0277bd', '#01579b', '#80d8ff', '#40c4ff', '#00b0ff', '#0091ea', '#8bc34a', '#f1f8e9', '#dcedc8', '#c5e1a5', '#aed581', '#9ccc65', '#8bc34a', '#7cb342', '#689f38', '#558b2f', '#33691e', '#ccff90', '#b2ff59', '#76ff03', '#64dd17'], 'cyan': ['#00bcd4', '#e0f7fa', '#b2ebf2', '#80deea', '#4dd0e1', '#26c6da', '#00bcd4', '#00acc1', '#0097a7', '#00838f', '#006064', '#84ffff', '#18ffff', '#00e5ff', '#00b8d4'], 'teal': ['#009688', '#e0f2f1', '#b2dfdb', '#80cbc4', '#4db6ac', '#26a69a', '#009688', '#00897b', '#00796b', '#00695c', '#004d40', '#a7ffeb', '#64ffda', '#1de9b6', '#00bfa5'], 'green': ['#4caf50', '#e8f5e9', '#c8e6c9', '#a5d6a7', '#81c784', '#66bb6a', '#4caf50', '#43a047', '#388e3c', '#2e7d32', '#1b5e20', '#b9f6ca', '#69f0ae', '#00e676', '#00c853'], 'lime': ['#cddc39', '#f9fbe7', '#f0f4c3', '#e6ee9c', '#dce775', '#d4e157', '#cddc39', '#c0ca33', '#afb42b', '#9e9d24', '#827717', '#f4ff81', '#eeff41', '#c6ff00', '#aeea00'], 'yellow': ['#ffeb3b', '#fffde7', '#fff9c4', '#fff59d', '#fff176', '#ffee58', '#ffeb3b', '#fdd835', '#fbc02d', '#f9a825', '#f57f17', '#ffff8d', '#ffff00', '#ffea00', '#ffd600'], 'amber': ['#ffc107', '#fff8e1', '#ffecb3', '#ffe082', '#ffd54f', '#ffca28', '#ffc107', '#ffb300', '#ffa000', '#ff8f00', '#ff6f00', '#ffe57f', '#ffd740', '#ffc400', '#ffab00'], 'orange': ['#ff9800', '#fff3e0', '#ffe0b2', '#ffcc80', '#ffb74d', '#ffa726', '#ff9800', '#fb8c00', '#f57c00', '#ef6c00', '#e65100', '#ffd180', '#ffab40', '#ff9100', '#ff6d00'], 'brown': ['#795548', '#efebe9', '#d7ccc8', '#bcaaa4', '#a1887f', '#8d6e63', '#795548', '#6d4c41', '#5d4037', '#4e342e', '#3e2723'], 'grey': ['#9e9e9e', '#fafafa', '#f5f5f5', '#eeeeee', '#e0e0e0', '#bdbdbd', '#9e9e9e', '#757575', '#616161', '#424242', '#212121'], 'white': ['#ffffff'], 'black': ['#000000']}\n\ncolor_maps = {i: color_maps[i] for i in color_maps if i not in ['clouds', 'silver', 'concrete', 'asbestos', 'wet asphalt', 'midnight blue', 'wet']}\n\nCMAP = 'Oranges'\nprompt = '#1DBCCD'\nmain_color = '#E58F65' # color_maps[notebook_theme]\nstrong_main_color = '#EB9514' # = color_maps[notebook_theme] \ncustom_colors = [strong_main_color, main_color]\n\n# ----- Notebook Theme -----\n\nhtml_contents =\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <link rel=\"stylesheet\" href=\"https:\/\/www.w3schools.com\/w3css\/4\/w3.css\">\n        <link rel=\"stylesheet\" href=\"https:\/\/fonts.googleapis.com\/css?family=Raleway\">\n        <link rel=\"stylesheet\" href=\"https:\/\/fonts.googleapis.com\/css?family=Oswald\">\n        <link rel=\"stylesheet\" href=\"https:\/\/fonts.googleapis.com\/css?family=Open Sans\">\n        <link rel=\"stylesheet\" href=\"https:\/\/cdnjs.cloudflare.com\/ajax\/libs\/font-awesome\/4.7.0\/css\/font-awesome.min.css\">\n        <style>\n        .title-section{\n            font-family: \"Oswald\", Arial, sans-serif;\n            font-weight: bold;\n            color: \"#6A8CAF\";\n            letter-spacing: 6px;\n        }\n        hr { border: 1px solid #E58F65 !important;\n             color: #E58F65 !important;\n             background: #E58F65 !important;\n           }\n        body {\n            font-family: \"Open Sans\", sans-serif;\n            }        \n        <\/style>\n    <\/head>    \n<\/html>\n\"\"\"\n\nHTML(html_contents)","86f536e3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.datasets import cifar10\nimport warnings \nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report,confusion_matrix","c35358da":"\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","b50f0a54":"print('Train data Shape :',x_train.shape)","7f8153a8":"print(x_train[0].shape)\nprint(x_train.max())","9f4a2284":"x_train = x_train\/225\nx_test = x_test\/255","ca2cce54":"class MultiClassification:\n    \n    def keras_model(self,input_shape=(32,32,3),activ='relu',opti='rmsprop'):\n        '''\n        ** Our model bulit with Tensorflow.Keras.\n           -- Main model is Sequential\n           -- Loss function is categorical cross entropy\n           -- Optimizer is rmsprop\n           -- inputShape is changable\n           -- Metric is accuracy\n        \n        '''\n        finder = Sequential()\n#         finder.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation=activ,))\n#         finder.add(MaxPool2D(pool_size=(2, 2)))\n#         finder.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation=activ,))\n#         finder.add(MaxPool2D(pool_size=(2, 2)))\n        finder.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation=activ,))\n        finder.add(MaxPool2D(pool_size=(2, 2)))\n        finder.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation=activ,))\n        finder.add(MaxPool2D(pool_size=(2, 2)))\n        finder.add(Flatten())\n\n        finder.add(Dense(256, activation=activ))\n        finder.add(Dense(10, activation='softmax'))\n        finder.compile(loss='categorical_crossentropy',\n                      optimizer=opti,\n                      metrics=['accuracy'])\n        finder.summary()\n        \n        return finder\n    \n    def train(self,x_train,y_train,x_test,y_test,finder,num=3):\n        '''\n        ** Train Process\n        '''\n        cat_train,cat_test = self.categorical(y_train,y_test)\n        early_stop = EarlyStopping(monitor='val_loss',patience=num)\n        finder.fit(x_train,cat_train,\n                  epochs=20,\n                  validation_data=(x_test,cat_test),\n                  callbacks=[early_stop])\n        losses = pd.DataFrame(finder.history.history)\n        losses[['accuracy','val_accuracy']].plot()\n        losses[['loss','val_loss']].plot()\n        plt.show()\n        return finder,cat_train,cat_test\n    \n    def test(self,model,x_test,y_test):\n        '''\n          ** Test Process\n        '''\n\n        predictions = model.predict(x_test)\n        predictions = np.argmax(predictions,axis=1)\n        self.performance(y_test,predictions)\n        return predictions\n    \n    def categorical(self,y_train,y_test):\n        '''\n        ** Convert Classes to categorical values from 0 to 9\n        '''\n        cat_train = to_categorical(y_train,10)\n        cat_test = to_categorical(y_test,10)\n        return cat_train,cat_test\n    \n    def predict_classes(self,finder,test_img):\n        '''\n         Classes:\n            * airplane  : 1st class\n            * automobile: 2nd class\n            * bird      : 3rd class\n            * cat       : 4th class\n            * deer      : 5th class\n            * dog       : 6th class\n            * frog      : 7th class\n            * horse     : 8th class\n            * ship      : 9th class\n            * truck     : 10th class\n        '''\n        \n        predictions = model.predict(test_img.reshape(1,32,32,3))\n        predictions = np.argmax(predictions,axis=1)\n        true_pred = []\n        for pred in predictions:\n            \n            if pred == 0:\n                true_pred.append('airplane')\n            if pred == 1:\n                true_pred.append('automobile') \n            if pred == 2:\n                true_pred.append('bird')\n            if pred == 3:\n                true_pred.append('cat')  \n            if pred == 4:\n                true_pred.append('deer')\n            if pred == 5:\n                true_pred.append('dog')  \n            if pred == 6:\n                true_pred.append('frog')\n            if pred == 7:\n                true_pred.append('horse')   \n            if pred == 8:\n                true_pred.append('ship')\n            if pred == 9:\n                true_pred.append('truck')  \n                \n        return true_pred\n    \n    def performance(self,pred,y_test):\n        '''\n        ** Measure the performance of test\n        '''\n        \n        print(classification_report(y_test,pred))\n        print(confusion_matrix(y_test,pred))\n        plt.figure(figsize=(10,6))\n        sns.heatmap(confusion_matrix(y_test,pred),annot=True,cmap='viridis')\n        plt.show()","99a79017":"help(MultiClassification)","7aa8ab84":"cs = MultiClassification()","ebd71cff":"model = cs.keras_model()","a46d84dd":"finder,cat_train,cat_test = cs.train(x_train,y_train,x_test,y_test,model,num=3)","06af6a87":"cs.test(finder,x_test,y_test)","2575474d":"test = x_test[120]\nplt.imshow(test)","4f2a45a1":"cs.predict_classes(finder,test)","8e9ccd11":"test = x_test[300]\nplt.imshow(test)","3cf98f36":"cs.predict_classes(finder,test)","9994a6b8":"test = x_test[240]\nplt.imshow(test)","bac0fc11":"cs.predict_classes(finder,test)","a8ce17b6":"test = x_test[26]\nplt.imshow(test)","e3cac82a":"cs.predict_classes(finder,test)","8b99b4e3":"test = x_test[98]\nplt.imshow(test)","bc67a820":"cs.predict_classes(finder,test)","00236fb6":"------","42ac7dfb":"----------\n# Load Data\ud83d\udcdc","f50c70d8":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/symjax.readthedocs.io\/en\/latest\/_images\/sphx_glr_plot_cifar10_001.svg\" alt=\"Heat beating\" style=\"height:500px;margin-top:3rem;\"> <\/div>\n","76f9eec3":"--------","ea050acb":"### Create Class instance","7a00e73e":"----------","3eae4af3":"-----","ae067c9a":"<div style=\"color:white;\n           display:fill;\n           border-radius:0px;\n           background-color:#ee9b00;\n           font-size:150%;\n           font-family:Arial;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 3px;\n              color:white;\"> \nLet's go over another example of using Keras and building out CNNs. This time will use another famous data set, the CIFAR-10 dataset which consists of 10 different image types.\nThe CIFAR-10 small photo classification problem is a standard dataset used in computer vision and deep learning.\n\nAlthough the dataset is effectively solved, it can be used as the basis for learning and practicing how to develop, evaluate, and use convolutional deep learning neural networks for image classification from scratch.\n\nThis includes how to develop a robust test harness for estimating the performance of the model, how to explore improvements to the model, and how to save the model and later load it to make predictions on new data.\n\nIn this tutorial, you will discover how to develop a convolutional neural network model from scratch for object photo classification.\n\nAfter completing this tutorial, you will know:\n\nHow to develop a test harness to develop a robust evaluation of a model and establish a baseline of performance for a classification task. How to explore extensions to a baseline model to improve learning and model capacity. How to develop a finalized model, evaluate the performance of the final model, and use it to make predictions on new images..<\/p>","cceba659":"----------\n# Building the Model \ud83d\udd25","e51b8fb5":"\n# <strong><center>MultiClassification with Keras.<\/center><\/strong>\n\n\n","8f6309b3":"---------","6e124534":"-----","31fc677f":"--------","89e82691":"--------","d34dcff6":"--------","026de8f8":"# CIFAR-10 Photo Classification Dataset\ud83d\udcd1 ","b433d779":"-----","44b56e55":"# Reduce Pixcel \ud83d\udee0","04df1601":"--------","aeca8b28":"\n <div style=\"color:white;\n           display:fill;\n           border-radius:0px;\n           background-color:#ee9b00;\n           font-size:150%;\n           font-family:Arial;\n           letter-spacing:0.5px\">\n<p style=\"padding: 3px;\n              color:white;\"> \n\n\ud83d\udcdcCIFAR is an acronym that stands for the Canadian Institute For Advanced Research and the CIFAR-10 dataset was developed along with the CIFAR-100 dataset by researchers at the CIFAR institute.\n\nThe dataset is comprised of 60,000 32\u00d732 pixel color photographs of objects from 10 classes, such as frogs, birds, cats, ships, etc. The class labels and their standard associated integer values are listed below.\ud83d\udcf0\n* \u2708\ufe0fairplane  : 1st class\n* \ud83d\ude93automobile: 2nd class\n* \ud83d\udc26bird      : 3rd class\n* \ud83d\udc31cat       : 4th class\n* \ud83e\udd8c deer      : 5th class\n* \ud83d\udc15dog       : 6th class\n* \ud83d\udc38frog      : 7th class\n* \ud83d\udc0ehorse     : 8th class\n* \ud83d\udea2 ship      : 9th class\n* \ud83d\ude9atruck     : 10th class\n    \nThese are very small images, much smaller than a typical photograph, and the dataset was intended for computer vision research\ud83d\uddc3.<\/p>","f3af8970":"# Libraries\ud83d\udcda ","6998c7ae":"###  <font color=orange>Thanks for reading. I hope you enjoyed\ud83d\ude0a\n> <img src=\"https:\/\/i.pinimg.com\/originals\/f8\/89\/1e\/f8891ef65e086abc67e5b448acb8bc12.gif\">","0e5ca606":"# Predicting a given image\ud83e\udd14"}}