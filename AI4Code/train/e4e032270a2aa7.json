{"cell_type":{"3bb69db8":"code","bfbb603e":"code","6016f341":"code","f04ab4e2":"code","0c224c65":"code","4e88f179":"code","571476fc":"code","c459095a":"code","33876446":"code","8bef13c8":"code","9a5999c0":"code","0a612252":"code","be00264c":"code","75c052a2":"code","666b1116":"code","4fa90096":"code","2b337881":"code","4264a056":"code","2d3ca9b7":"code","be6cd633":"code","f36b0d82":"code","5a1bfc53":"code","d69c8359":"code","368fc3ae":"code","ecfef774":"code","db06eb7c":"code","5a5dc49a":"code","daae7ad3":"code","459efa67":"code","ac9392c6":"code","ec35282b":"code","ba37b7fc":"code","771ab892":"code","48b6242c":"code","c74c3c85":"code","1a23e689":"code","ce5b21d7":"code","7465e2de":"code","43d27f74":"code","de783843":"code","041a0f32":"code","ba4e5169":"code","ed56ba3a":"code","058f5212":"code","31dbcf71":"code","c509e304":"code","a8f736c5":"code","8d705bd2":"code","03a667ae":"code","7af9d5ea":"code","25bbd45d":"code","3af56c8e":"code","26bdae3c":"code","3a747f07":"code","86be0491":"code","7e2e9b3e":"code","1598dbde":"code","84aad81f":"code","8ed8bc3f":"code","674bad2b":"code","7514b078":"code","74a8336d":"code","961c2295":"code","5d6d1fc5":"code","dfff2462":"code","5ffb0078":"code","114acc91":"code","dfb75746":"code","f33a025a":"code","3bb9c39b":"code","df19653e":"code","9dbcbc3c":"code","9a67929c":"code","9466d943":"code","1e7cc067":"code","b2018d27":"markdown","e630c9a3":"markdown","93af4e29":"markdown","f22eca2d":"markdown","d5039e40":"markdown","ba8cf5d8":"markdown","103549ef":"markdown","6fa06c59":"markdown","e1e880aa":"markdown","2387e9eb":"markdown","c6b27a09":"markdown","43f7e773":"markdown","78b254fa":"markdown","a463956e":"markdown","352eddec":"markdown"},"source":{"3bb69db8":"import pandas as pd\nimport numpy as np\nimport re\nfrom bs4 import BeautifulSoup\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD as TSVD\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS as stopwords","bfbb603e":"data = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","6016f341":"data.head()","f04ab4e2":"data.shape","0c224c65":"train = data.iloc[:25000]\ntest = data.iloc[25000:]","4e88f179":"train.shape, test.shape","571476fc":"train.head()","c459095a":"nlp = spacy.load('en_core_web_lg')","33876446":"# Converting the text to lowercase\n\ntrain['review'] = train['review'].apply(lambda x: str(x).lower())","8bef13c8":"data.head()","9a5999c0":"!pip install contractions","0a612252":"import contractions","be00264c":"contractions_dict = contractions.contractions_dict\ncontractions_dict","75c052a2":"def contraction_expansion(x):\n    \n    if type(x) is str:\n        \n        for key in contractions_dict:\n            \n            value = contractions_dict[key]\n            \n            x = x.replace(key, value)\n            \n        return x\n    \n    else:\n        \n        return x","666b1116":"train['review'] = train['review'].apply(lambda x: contraction_expansion(x))","4fa90096":"train.head()","2b337881":"def remove_emails(x):\n    \n    email_pattern = re.compile(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\")\n    \n    return re.sub(email_pattern, '', x)","4264a056":"train['review'] = train['review'].apply(lambda x:remove_emails(x))","2d3ca9b7":"train.sample(5)","be6cd633":"train['review'] = train['review'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text().strip())","f36b0d82":"train.iloc[6005][0]","5a1bfc53":"train.sample(5)","d69c8359":"def RemoveSpecialChars(x):\n    \n    x = re.sub(r'[^\\w ]+', \"\", x)\n    x = ' '.join(x.split())\n    return x","368fc3ae":"train['review'] = train['review'].apply(lambda x: RemoveSpecialChars(x))","ecfef774":"train.sample(5)","db06eb7c":"train.iloc[6005][0]","5a5dc49a":"def lemme(x):\n    \n    x = str(x)\n    x_list = []\n    doc = nlp(x)\n    \n    for token in doc:\n        lemma = token.lemma_\n        \n        if lemma == '-PRON-' or lemma == 'be':\n            lemma = token.text\n            \n        x_list.append(lemma)\n        \n    return ' '.join(x_list)","daae7ad3":"%%time\ntrain['review'] = train['review'].apply(lambda x: lemme(x))","459efa67":"train.sample(5)","ac9392c6":"stopwords","ec35282b":"len(stopwords)","ba37b7fc":"def RemoveStopWords(x):\n    \n    return ' '.join([word for word in x.split() if word not in stopwords])","771ab892":"x = train.iloc[6005][0]","48b6242c":"# EXAMPLE CODE\n\nprint(x)\nprint()\nprint(\"length of x: \",len(x))","c74c3c85":"x1 = RemoveStopWords(x)\nx1","1a23e689":"len(x1)","ce5b21d7":"%%time\n\ntrain['review'] = train['review'].apply(lambda x: RemoveStopWords(x))","7465e2de":"train.sample(5)","43d27f74":"text = ' '.join(train['review'])","de783843":"#text","041a0f32":"len(text)","ba4e5169":"# Creating Frequency\n\ntext_series = pd.Series(text.split())","ed56ba3a":"freq_comm = text_series.value_counts()","058f5212":"freq_comm","31dbcf71":"rare_words = freq_comm[-82000:-1]\n'rockumentarie' in rare_words","c509e304":"rare_words","a8f736c5":"# Removing 82000 rare occuring words \n\ntrain['review'] = train['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in rare_words]))","8d705bd2":"train['review'].sample(5)","03a667ae":"train['sentiment'].value_counts()","7af9d5ea":"X = train['review']\ny = train['sentiment']","25bbd45d":"tfidf = TfidfVectorizer()","3af56c8e":"X = tfidf.fit_transform(X)","26bdae3c":"X.shape","3a747f07":"X","86be0491":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 4, stratify = y)","7e2e9b3e":"X_train.shape, X_test.shape","1598dbde":"%%time\n\n#tsvd = TSVD(n_components=10000, random_state=4)\n#X_train_tsvd = tsvd.fit_transform(X_train)","84aad81f":"#sum(tsvd.explained_variance_)","8ed8bc3f":"#clf_svc = SVC()","674bad2b":"%%time\n\n#scores = cross_val_score(clf_svc, X_train, y_train, cv=6, n_jobs=-1)","7514b078":"#scores","74a8336d":"from sklearn.linear_model import LogisticRegression","961c2295":"clf_lr = LogisticRegression()","5d6d1fc5":"X_train","dfff2462":"%%time\n\nscores = cross_val_score(clf_lr, X_train, y_train, cv=10, n_jobs=4)","5ffb0078":"scores","114acc91":"scores.mean()","dfb75746":"clf_lr.fit(X_train, y_train)","f33a025a":"y_test_pred = clf_lr.predict(X_test)","3bb9c39b":"print(classification_report(y_test, y_test_pred))","df19653e":"confusion_matrix(y_test, y_test_pred)","9dbcbc3c":"clf_lr.predict(tfidf.transform(['American Psycho deserved an Oscar, they were robbed']))","9a67929c":"y_real_pred = clf_lr.predict(tfidf.transform(test['review']))","9466d943":"print(classification_report(test['sentiment'], y_real_pred))","1e7cc067":"clf_lr.predict(tfidf.transform([\"What hell was that, it's a masterpiece\"]))","b2018d27":"### Dimensionality reduction using Truncated Singular Value Decomposition","e630c9a3":"### Splitting Data into Training and Testing sets","93af4e29":"### Lemmetization","f22eca2d":"### Removing Stop Words","d5039e40":"### Using Logistic Regression","ba8cf5d8":"                                                EXAMPLE END","103549ef":"### Removing Rare Words","6fa06c59":"### Using SVC for Classification","e1e880aa":"### Contractions Expansion","2387e9eb":"### Removing Emails","c6b27a09":"### Converting the Data into Vector","43f7e773":"### Tokenization using Text Blob","78b254fa":"### Removing HTML Tags","a463956e":"### Removing Special Characters","352eddec":"                                                EXAMPLE CODE"}}