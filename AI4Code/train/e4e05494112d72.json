{"cell_type":{"f23a6a93":"code","fe41a274":"code","6dedad78":"code","96f19f13":"code","7921ad65":"code","02e837a3":"code","5d76b787":"code","cd0aa3b6":"code","d73932bc":"code","3dbe8e86":"code","9b5a2be6":"code","06f53cd3":"code","7fdfc548":"code","d557281e":"code","8843c767":"code","3df50147":"code","0e1b4905":"code","d80aaa0e":"code","821f2c40":"code","5ad688a6":"code","7c7a84aa":"code","3101d482":"code","18f6aa45":"code","b2c7e8e4":"code","c4e745d3":"code","3488d08d":"code","8878c358":"code","b01c5f59":"code","d7505831":"code","c999f967":"code","a4824525":"code","9be2c7a7":"code","636f6da9":"code","099af35d":"code","ca6aa22b":"code","6696dec7":"code","09a77567":"code","92e1b9f5":"code","e28af6d3":"code","c6e65c15":"code","19ba8760":"code","98acc3a2":"markdown","0edd2a72":"markdown","cbb7971a":"markdown","4729e3c6":"markdown","a6dfe3f1":"markdown","5198f6bd":"markdown","99ec274d":"markdown","2a0268ac":"markdown","b5730add":"markdown","af5998b7":"markdown","3d113530":"markdown","c3623177":"markdown","4b730908":"markdown","ed759adb":"markdown","41648e45":"markdown","c2107060":"markdown","d545f5c7":"markdown","3f67b3dc":"markdown","975d2e47":"markdown","c011e2bb":"markdown","f73b1c23":"markdown"},"source":{"f23a6a93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe41a274":"import pandas as pd\nimport numpy as np","6dedad78":"train=pd.read_csv(r\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","96f19f13":"train.Survived.value_counts()","7921ad65":"train.shape","02e837a3":"train.isnull().sum()","5d76b787":"train.drop(\"Cabin\",axis=1,inplace=True)","cd0aa3b6":"train.drop('Fare',axis=1,inplace=True)","d73932bc":"train['Age']=train.fillna(train.Age.median())","3dbe8e86":"train.groupby('Sex')['Survived'].value_counts()","9b5a2be6":"import seaborn as sns\nsns.countplot(x=\"Survived\",data=train)","06f53cd3":"sns.countplot(x=\"Survived\",hue=\"Sex\",data=train)","7fdfc548":"sns.countplot(x=\"Survived\",hue=\"Embarked\",data=train)","d557281e":"sns.countplot(x=\"Survived\",hue=\"SibSp\",data=train)","8843c767":"sex=pd.get_dummies(train[\"Sex\"])\nembarked=pd.get_dummies(train[\"Embarked\"])","3df50147":"train=pd.concat([train,sex,embarked],axis=1)\ntrain.drop(['Sex','Embarked','Ticket','Name'],axis=1,inplace=True)\ntrain.head()","0e1b4905":"test=pd.read_csv(r\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","d80aaa0e":"test.isnull().sum()","821f2c40":"test.drop('Cabin',axis=1,inplace=True)","5ad688a6":"test['Age']=test.fillna(test.Age.median())","7c7a84aa":"test.boxplot()","3101d482":"test.boxplot(column=['Fare'])","18f6aa45":"test.drop('Fare',axis=1,inplace=True)","b2c7e8e4":"sex=pd.get_dummies(test[\"Sex\"])\nembarked=pd.get_dummies(test[\"Embarked\"])","c4e745d3":"test=pd.concat([test,sex,embarked],axis=1)\ntest.drop(['Sex','Embarked','Ticket','Name'],axis=1,inplace=True)\ntest.head()","3488d08d":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(train.drop(\"Survived\",axis=1),train['Survived'],test_size=0.2,random_state=0)","8878c358":"train.isnull().sum()","b01c5f59":"from sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression()\nclassifier.fit(x_train,y_train)","d7505831":"predict=classifier.predict(x_test)","c999f967":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\naccuracy=accuracy_score(y_test,predict)\naccuracy","a4824525":"from sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(criterion=\"gini\",max_depth=None,min_samples_leaf=1,random_state=10)\nrf_classifier.fit(x_train,y_train)","9be2c7a7":"pred3 = rf_classifier.predict(x_test)","636f6da9":"accuracy_rf=accuracy_score(y_test,pred3)\naccuracy_rf","099af35d":"from sklearn.tree import DecisionTreeClassifier\ndecision_classifier=DecisionTreeClassifier(criterion=\"gini\",max_depth=None,min_samples_leaf=1,random_state=7)\ndecision_classifier.fit(x_train,y_train)","ca6aa22b":"pred2=decision_classifier.predict(x_test)\n","6696dec7":"accuracy_dt=accuracy_score(y_test,pred2)\naccuracy_dt","09a77567":"test.head()","92e1b9f5":"final=classifier.predict(test)\nfinal","e28af6d3":"test['Survived'] = final\ntest.drop(['Pclass','Age','SibSp','Parch','female','male','C','Q','S'],inplace=True,axis=1)\ntest.head()","c6e65c15":"submission_analysis = pd.DataFrame(test, columns = ['PassengerId', 'Survived'])\nsubmission_analysis.head()","19ba8760":"submission_analysis.to_csv('titanic_data_submission.csv', index=False)","98acc3a2":"# Introducing the train dataset","0edd2a72":"Since, Cabin has most of the values as null, it can be removed from the dataset","cbb7971a":"Since the age column dosent have a lot of null values, they can be replaced with median of the values of the column","4729e3c6":"**In the above three classification models, since Logisitic Regression had the highest accuracy compared to the others, we would be proceeding with the same.**","a6dfe3f1":"Since many values in the Fare column lie utside the interquartile range, it can be ignored as well","5198f6bd":"# **Logistic Regression**","99ec274d":"# Splitting the data into train and test ","2a0268ac":"# Checking for null values and thereby taking appropriate action to avoid them","b5730add":"Since the cabin column has more than 80% null values, it can be dropped","af5998b7":"# **Random Forest**","3d113530":"Quite clearly, more number of females have survived the tragedy.","c3623177":"Observing the null values and taking proper action against them","4b730908":"# **Decision Trees**","ed759adb":"Out of the 891 passengers, we can observe that more than 530 of them have lost their lives.","41648e45":"# Importing Libraries","c2107060":"**One-Hot Encoding** (for converting categorical columns into numerical)","d545f5c7":"# Introducing the test data set","3f67b3dc":"**One-Hot Encoding** (for converting categorical columns into numerical)","975d2e47":"Since the age column dosent have a lot of null values, they can be replaced with median of the values of the column","c011e2bb":"# EDA","f73b1c23":"We can observe that out of the 350 survivors,almost 210 survivors have Embarked in Southampton with Queensland having the least survivors."}}