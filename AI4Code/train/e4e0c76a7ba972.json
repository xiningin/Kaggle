{"cell_type":{"00a9bc81":"code","ac963a37":"code","9ded6794":"code","def3051f":"code","ac71fec3":"code","eec30db2":"code","e9e9e250":"code","48e08a04":"code","b4a98069":"code","eebe46a2":"code","99fb9960":"code","85e2bdd2":"code","0b7f806e":"code","48e209db":"code","05f76728":"code","799275fe":"code","871f6f29":"code","38db9ff2":"code","79444a10":"code","65004484":"code","4195f297":"code","2453b2ca":"markdown","943ad048":"markdown","92826a31":"markdown","2123185a":"markdown","7a36f9cb":"markdown","07257410":"markdown","7c07ac22":"markdown","f4dd0d6d":"markdown","dcac2393":"markdown","0add4e2b":"markdown","124f524a":"markdown","6e8e1f8c":"markdown","d6c5ddf0":"markdown","d7840ae5":"markdown","6d98f7f3":"markdown"},"source":{"00a9bc81":"!pip install -U lightautoml","ac963a37":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error\nimport torch\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\nfrom lightautoml.dataset.roles import CategoryRole","9ded6794":"N_THREADS = 4\nN_FOLDS = 5\nRANDOM_STATE = 42\nTIMEOUT = 36000\nTARGET_NAME = 'pressure'","def3051f":"# for reproducibility\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","ac71fec3":"train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsample_sub = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","eec30db2":"print(train.shape)\ntrain.head()","e9e9e250":"print(test.shape)\ntest.head()","48e08a04":"# LSTM\ntrain_lstm = pd.read_csv('..\/input\/googlebrainlstm\/lstm_train.csv')\ntest_lstm = pd.read_csv('..\/input\/googlebrainlstm\/lstm_test.csv')\ntrain['lstm_pred'] = train_lstm['pressure']\ntest['lstm_pred'] = test_lstm['pressure']\n\n# Bidirectional LSTM\ntrain_bilstm = pd.read_csv('..\/input\/googlebrainbilstm\/bilstm_train.csv')\ntest_bilstm = pd.read_csv('..\/input\/googlebrainbilstm\/bilstm_test.csv')\ntrain['bilstm_pred'] = train_lstm['pressure']\ntest['bilstm_pred'] = test_lstm['pressure']","b4a98069":"# rewritten calculation of lag features from this notebook: https:\/\/www.kaggle.com\/patrick0302\/add-lag-u-in-as-new-feat\n# some of ideas from this notebook: https:\/\/www.kaggle.com\/mst8823\/google-brain-lightgbm-baseline\ntrain['last_value_u_in'] = train.groupby('breath_id')['u_in'].transform('last')\ntrain['u_in_lag1'] = train.groupby('breath_id')['u_in'].shift(1)\ntrain['u_out_lag1'] = train.groupby('breath_id')['u_out'].shift(1)\ntrain['u_in_lag_back1'] = train.groupby('breath_id')['u_in'].shift(-1)\ntrain['u_out_lag_back1'] = train.groupby('breath_id')['u_out'].shift(-1)\ntrain['u_in_lag2'] = train.groupby('breath_id')['u_in'].shift(2)\ntrain['u_out_lag2'] = train.groupby('breath_id')['u_out'].shift(2)\ntrain['u_in_lag_back2'] = train.groupby('breath_id')['u_in'].shift(-2)\ntrain['u_out_lag_back2'] = train.groupby('breath_id')['u_out'].shift(-2)\ntrain = train.fillna(0)\n\ntrain['R__C'] = train[\"R\"].astype(str) + '__' + train[\"C\"].astype(str)\n\n# max value of u_in and u_out for each breath\ntrain['breath_id__u_in__max'] = train.groupby(['breath_id'])['u_in'].transform('max')\ntrain['breath_id__u_out__max'] = train.groupby(['breath_id'])['u_out'].transform('max')\n\n# difference between consequitive values\ntrain['u_in_diff1'] = train['u_in'] - train['u_in_lag1']\ntrain['u_out_diff1'] = train['u_out'] - train['u_out_lag1']\ntrain['u_in_diff2'] = train['u_in'] - train['u_in_lag2']\ntrain['u_out_diff2'] = train['u_out'] - train['u_out_lag2']\n# from here: https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\ntrain.loc[train['time_step'] == 0, 'u_in_diff'] = 0\ntrain.loc[train['time_step'] == 0, 'u_out_diff'] = 0\n\n# difference between the current value of u_in and the max value within the breath\ntrain['breath_id__u_in__diffmax'] = train.groupby(['breath_id'])['u_in'].transform('max') - train['u_in']\ntrain['breath_id__u_in__diffmean'] = train.groupby(['breath_id'])['u_in'].transform('mean') - train['u_in']\n\n# https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/273974\ntrain['u_in_cumsum'] = train.groupby(['breath_id'])['u_in'].cumsum()\ntrain['time_step_cumsum'] = train.groupby(['breath_id'])['time_step'].cumsum()\n# https:\/\/www.kaggle.com\/yasufuminakama\/ventilator-pressure-lstm-starter\ntrain['breath_time'] = train['time_step'] - train.groupby('breath_id')['time_step'].shift(1)","eebe46a2":"# all the same for the test data\ntest['last_value_u_in'] = test.groupby('breath_id')['u_in'].transform('last')\ntest['u_in_lag1'] = test.groupby('breath_id')['u_in'].shift(1)\ntest['u_out_lag1'] = test.groupby('breath_id')['u_out'].shift(1)\ntest['u_in_lag_back1'] = test.groupby('breath_id')['u_in'].shift(-1)\ntest['u_out_lag_back1'] = test.groupby('breath_id')['u_out'].shift(-1)\ntest['u_in_lag2'] = test.groupby('breath_id')['u_in'].shift(2)\ntest['u_out_lag2'] = test.groupby('breath_id')['u_out'].shift(2)\ntest['u_in_lag_back2'] = test.groupby('breath_id')['u_in'].shift(-2)\ntest['u_out_lag_back2'] = test.groupby('breath_id')['u_out'].shift(-2)\ntest = test.fillna(0)\n\ntest['R__C'] = test[\"R\"].astype(str) + '__' + test[\"C\"].astype(str)\n\ntest['breath_id__u_in__max'] = test.groupby(['breath_id'])['u_in'].transform('max')\ntest['breath_id__u_out__max'] = test.groupby(['breath_id'])['u_out'].transform('max')\n\ntest['u_in_diff1'] = test['u_in'] - test['u_in_lag1']\ntest['u_out_diff1'] = test['u_out'] - test['u_out_lag1']\ntest['u_in_diff2'] = test['u_in'] - test['u_in_lag2']\ntest['u_out_diff2'] = test['u_out'] - test['u_out_lag2']\ntest.loc[test['time_step'] == 0, 'u_in_diff'] = 0\ntest.loc[test['time_step'] == 0, 'u_out_diff'] = 0\n\ntest['breath_id__u_in__diffmax'] = test.groupby(['breath_id'])['u_in'].transform('max') - test['u_in']\ntest['breath_id__u_in__diffmean'] = test.groupby(['breath_id'])['u_in'].transform('mean') - test['u_in']\n\ntest['u_in_cumsum'] = test.groupby(['breath_id'])['u_in'].cumsum()\ntest['time_step_cumsum'] = test.groupby(['breath_id'])['time_step'].cumsum()\n\ntest['breath_time'] = test['time_step'] - test.groupby('breath_id')['time_step'].shift(1)","99fb9960":"train['lstm_pred_lag1'] = train.groupby('breath_id')['lstm_pred'].shift(1)\ntrain['lstm_pred_lag_back1'] = train.groupby('breath_id')['lstm_pred'].shift(-1)\ntrain['bilstm_pred_lag1'] = train.groupby('breath_id')['bilstm_pred'].shift(1)\ntrain['bilstm_pred_lag_back1'] = train.groupby('breath_id')['bilstm_pred'].shift(-1)\ntrain['lstm_pred_lag2'] = train.groupby('breath_id')['lstm_pred'].shift(2)\ntrain['lstm_pred_lag_back2'] = train.groupby('breath_id')['lstm_pred'].shift(-2)\ntrain['bilstm_pred_lag2'] = train.groupby('breath_id')['bilstm_pred'].shift(2)\ntrain['bilstm_pred_lag_back2'] = train.groupby('breath_id')['bilstm_pred'].shift(-2)\ntrain = train.fillna(0)","85e2bdd2":"test['lstm_pred_lag1'] = test.groupby('breath_id')['lstm_pred'].shift(1)\ntest['lstm_pred_lag_back1'] = test.groupby('breath_id')['lstm_pred'].shift(-1)\ntest['bilstm_pred_lag1'] = test.groupby('breath_id')['bilstm_pred'].shift(1)\ntest['bilstm_pred_lag_back1'] = test.groupby('breath_id')['bilstm_pred'].shift(-1)\ntest['lstm_pred_lag2'] = test.groupby('breath_id')['lstm_pred'].shift(2)\ntest['lstm_pred_lag_back2'] = test.groupby('breath_id')['lstm_pred'].shift(-2)\ntest['bilstm_pred_lag2'] = test.groupby('breath_id')['bilstm_pred'].shift(2)\ntest['bilstm_pred_lag_back2'] = test.groupby('breath_id')['bilstm_pred'].shift(-2)\ntest = test.fillna(0)","0b7f806e":"train.info()","48e209db":"task = Task('reg', loss='mae', metric='mae')","05f76728":"roles = {\n    'drop': ['id'],\n    'group': 'breath_id', # for group k-fold\n    'target': TARGET_NAME\n}","799275fe":"%%time\n\n# Fitting\nautoml = TabularAutoML(task=task, \n                       timeout=TIMEOUT,\n                       cpu_limit=N_THREADS,\n                       reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                       general_params={'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       tuning_params = {'max_tuning_time': 1800},\n                      )\nautoml.fit_predict(train, roles=roles)","871f6f29":"# Prediction\ntest_pred = automl.predict(test)\nsample_sub[TARGET_NAME] = test_pred.data[:, 0]","38db9ff2":"fi_score = automl.get_feature_scores('fast').sort_values('Importance', ascending=True)","79444a10":"plt.figure(figsize=(10, 30))\nfi_score.set_index('Feature')['Importance'].plot.barh(fontsize=16)\nplt.title('Feature importance', fontsize=18)\nplt.show()","65004484":"sample_sub.head()","4195f297":"sample_sub.to_csv('submission.csv', index=False)","2453b2ca":"## Create submission file","943ad048":"### Task setup\n\nOn the cell below we create Task object - the class to setup what task LightAutoML model should solve with specific loss and metric if necessary (more info can be found [here](https:\/\/lightautoml.readthedocs.io\/en\/latest\/generated\/lightautoml.tasks.base.Task.html#lightautoml.tasks.base.Task) in our documentation):","92826a31":"## LightAutoML model building","2123185a":"## Data loading","7a36f9cb":"Here we setup the constants to use in the kernel:\n\n- `N_THREADS` - number of vCPUs for LightAutoML model creation\n- `N_FOLDS` - number of folds in LightAutoML inner CV\n- `RANDOM_STATE` - random seed for better reproducibility\n- `TIMEOUT` - limit in seconds for model to train\n- `TARGET_NAME` - target column name in dataset","07257410":"## References\n\n- https:\/\/www.kaggle.com\/alexryzhkov\/tps-july-21-lightautoml-baseline\n- https:\/\/lightautoml.readthedocs.io\/en\/latest\/\n- https:\/\/www.kaggle.com\/artgor\/ventilator-pressure-prediction-eda-fe-and-models\n- https:\/\/www.kaggle.com\/junhyeok99\/tensorflow\n- https:\/\/www.kaggle.com\/tolgadincer\/tensorflow-bidirectional-lstm-0-234","7c07ac22":"## Feature engineering (LSTM prediction lags)","f4dd0d6d":"### Feature roles setup\n\nTo solve the task, we need to setup columns roles. The only role you must setup is target role, everything else (drop, numeric, categorical, group, weights etc.) is up to user - LightAutoML models have automatic columns typization inside:","dcac2393":"### LightAutoML model creation - TabularAutoML preset\n\nIn next the cell we are going to create LightAutoML model with `TabularAutoML` class - preset with default model structure like in the image below:\n\n![LightAutoML model](https:\/\/raw.githubusercontent.com\/sberbank-ai-lab\/LightAutoML\/master\/imgs\/tutorial_blackbox_pipeline.png \"LightAutoML model\")\n\nin just several lines. Let's discuss the params we can setup:\n\n- `task` - the type of the ML task (the only must have parameter)\n- `timeout` - time limit in seconds for model to train\n- `cpu_limit` - vCPU count for model to use\n- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc. For example, we setup `n_jobs` threads for typization algo, `cv` folds and `random_state` as inside CV seed.\n- `general_params` - we use `use_algos` key to setup the model structure to work with (Linear and LGBM model on the first level and their weighted composition creation on the second). This setup is only to speedup the kernel, you can remove this `general_params` setup if you want the whole LightAutoML model to run.","0add4e2b":"## Feature importance\n\nFor feature importances calculation we have 2 different methods in LightAutoML:\n\n- Fast (`fast`) - this method uses feature importances from feature selector LGBM model inside LightAutoML. It works extremely fast and almost always (almost because of situations, when feature selection is turned off or selector was removed from the final models with all GBM models). no need to use new labelled data.\n- Accurate (`accurate`) - this method calculate features permutation importances for the whole LightAutoML model based on the new labelled data. It always works but can take a lot of time to finish (depending on the model structure, new labelled dataset size etc.).","124f524a":"## Hello colleagues \ud83d\ude0e\n\n## This notebook is a copy of @tsano430 [notebook](https:\/\/www.kaggle.com\/tsano430\/lightautoml-starter) with the changes based only in LightAutoML part so please upvote it first before reading this notebook - this is really amazing \ud83d\udc4d\n\n## As for the changes, there are 3 changes here, which should be done to receive better score:\n- Fixed loss in `Task` object (it should be MAE as we have MAE as evaluation metric)\n- Fixed roles - if we setup `breath_id` as a group, it is automatically dropped from the feature set (you have no need to send it to drop manually)\n- Changed params for `TabularAutoML` run: increased tuning time limit and removing slow Catboost models to make the model faster\n\n## Please enjoy and do not forget to upvote us on [Github](https:\/\/github.com\/sberbank-ai-lab\/LightAutoML) \u2b50\ufe0f","6e8e1f8c":"## LightAutoML installation","d6c5ddf0":"## Import libraries","d7840ae5":"## Feature engineering\n\nThanks for these feature engineering goes to the notebook [Ventilator Pressure Prediction: EDA, FE and models](https:\/\/www.kaggle.com\/artgor\/ventilator-pressure-prediction-eda-fe-and-models). ","6d98f7f3":"## Add LSTM and bidirectional LSTM results\n\nThanks for these predictions goes to the notebooks [Tensorflow](https:\/\/www.kaggle.com\/junhyeok99\/tensorflow) and [Tensorflow Bidirectional LSTM (0.234)](https:\/\/www.kaggle.com\/tolgadincer\/tensorflow-bidirectional-lstm-0-234)."}}