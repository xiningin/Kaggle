{"cell_type":{"4df58f90":"code","adbaafa8":"code","f2c24000":"code","101d3997":"code","dd3cf8fb":"code","291a0310":"code","1c30bccf":"code","16de89af":"code","f32bf905":"code","1d06d83b":"code","3bf62010":"code","9a802c76":"code","4f5415ed":"code","a243f0ad":"code","c453cf25":"code","6ce956c2":"code","4db57fb1":"code","0c055e1b":"code","93549767":"code","25377771":"code","9f255649":"markdown","30358f6f":"markdown","762768fa":"markdown","888ca0e3":"markdown","b9cda9d0":"markdown","968af714":"markdown","71d4139d":"markdown","eda93a9c":"markdown","1813561a":"markdown","c1715fbd":"markdown"},"source":{"4df58f90":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","adbaafa8":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","f2c24000":"df.tail()","101d3997":"df.isnull().sum()","dd3cf8fb":"df.loc[:, 'Amount'].describe()","291a0310":"plt.figure(figsize=(10, 7))\nsns.distplot(df.loc[:, 'Amount'])","1c30bccf":"plt.figure(figsize=(10, 7))\ndf.loc[:, 'Amount'] = np.log(df.loc[:, 'Amount'] + 1)\nsns.distplot(df.loc[:, 'Amount'])","16de89af":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","f32bf905":"X = df.drop(['Class', 'Time'], axis=1).values\ny = df.loc[:, 'Class'].values","1d06d83b":"X.shape, y.shape","3bf62010":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","9a802c76":"hyperparameters = {\n    'C': np.random.uniform(0, 1000, 30)\n}\n\ngd = RandomizedSearchCV(estimator=LogisticRegression(random_state=2),\n                        param_distributions=hyperparameters,\n                        n_iter=50,\n                        scoring='accuracy',\n                        n_jobs=-1,\n                        cv=5,\n                        verbose=2,\n                        random_state=2)\n\ngd.fit(X_train, y_train)\nprint(gd.best_score_ * 100)\nprint(gd.best_params_)","4f5415ed":"logistic_model = LogisticRegression(random_state=2, C=780.146713913726)\nlogistic_model.fit(X_train, y_train)\nlr_test_prediction = logistic_model.predict(X_test)\n\nlr_test_accuracy = accuracy_score(y_test, lr_test_prediction)\nlr_test_f1_accuracy = f1_score(y_test, lr_test_prediction)\nprint('Accuracy of Logistic Regression is ', lr_test_accuracy * 100)\nprint('F1 Accuracy of Logistic Regression is ', lr_test_f1_accuracy * 100)","a243f0ad":"rf_model = RandomForestClassifier(random_state=2, max_depth=3, n_jobs=-1)\n\nrf_model.fit(X_train, y_train)\nrf_test_prediction = rf_model.predict(X_test)\nrf_test_accuracy = accuracy_score(y_test, rf_test_prediction)\nrf_test_f1_accuracy = f1_score(y_test, rf_test_prediction)\nprint('Accuracy of Random Forest is ', rf_test_accuracy * 100)\nprint('F1 Accuracy of Random Forest is ', rf_test_f1_accuracy * 100)","c453cf25":"gb_model = GradientBoostingClassifier(random_state=2)\n\ngb_model.fit(X_train, y_train)\ngb_test_prediction = gb_model.predict(X_test)\ngb_test_accuracy = accuracy_score(y_test, gb_test_prediction)\ngb_test_f1_accuracy = f1_score(y_test, gb_test_prediction)\nprint('Accuracy of Gradient Boosting is ', gb_test_accuracy * 100)\nprint('F1 Accuracy of Gradient Boosting is ', gb_test_f1_accuracy * 100)","6ce956c2":"xgb_model = XGBClassifier(random_state=2, max_depth=4, eval_metric='logloss')\n\nxgb_model.fit(X_train, y_train)\nxgb_test_prediction = xgb_model.predict(X_test)\nxgb_test_accuracy = accuracy_score(y_test, xgb_test_prediction)\nxgb_test_f1_accuracy = f1_score(y_test, xgb_test_prediction)\nprint('Accuracy of XGBoost is ', xgb_test_accuracy * 100)\nprint('F1 Accuracy of XGBoost is ', xgb_test_f1_accuracy * 100)","4db57fb1":"hyperparameters = {  \n    'learning_rate': (0.01, 0.5),\n    'max_depth': (3, 10),   \n    'subsample': (0.5, 1.0),\n    'colsample_bytree': (0.5, 1.0)\n    # 'reg_lambda': (0, 1000),\n    # 'reg_alpha': (0, 1.0)\n}\n\ngd = GridSearchCV(estimator=LGBMClassifier(random_state=2),\n                        param_grid=hyperparameters,\n                        scoring='accuracy',\n                        n_jobs=-1,\n                        cv=5,\n                        verbose=2)\n\ngd.fit(X_train, y_train)\nprint(gd.best_score_ * 100)\nprint(gd.best_params_)","0c055e1b":"lgbm_model = LGBMClassifier(random_state=2,\n                            learning_rate=0.01,\n                            max_depth=10,\n                            subsample=0.5,\n                            colsample_bytree=1)\n\nlgbm_model.fit(X_train, y_train)\nlgbm_test_prediction = lgbm_model.predict(X_test)\nlgbm_test_accuracy = accuracy_score(y_test, lgbm_test_prediction)\nlgbm_test_f1_accuracy = f1_score(y_test, lgbm_test_prediction)\nprint('Accuracy of LightGBM is ', lgbm_test_accuracy * 100)\nprint('F1 Accuracy of LightGBM is ', lgbm_test_f1_accuracy * 100)","93549767":"from sklearn.ensemble import VotingClassifier\n\nlogistic_model = LogisticRegression(random_state=2, C=780.146713913726)\nrf_model = RandomForestClassifier(random_state=2, max_depth=3, n_jobs=-1)\ngb_model = GradientBoostingClassifier(random_state=2)\nxgb_model = XGBClassifier(random_state=2, max_depth=4, eval_metric='logloss')\nlgbm_model = LGBMClassifier(random_state=2,\n                            learning_rate=0.01,\n                            max_depth=10,\n                            subsample=0.5,\n                            colsample_bytree=1)\n\nhard_voting = VotingClassifier(estimators=[('Logistic Regression', logistic_model),\n                                           ('Random Forest', rf_model),\n                                           ('Gradient Boosting', gb_model),\n                                           ('XGBoost', xgb_model),\n                                           ('LGBM', lgbm_model)], n_jobs=-1, voting='hard')\n\nhard_voting.fit(X_train, y_train)\nhard_voting_prediction = hard_voting.predict(X_test)\nhard_voting_accuracy = accuracy_score(y_test, hard_voting_prediction)\nhard_voting_f1_accuracy = f1_score(y_test, hard_voting_prediction)\nprint('Accuracy of Hard Voting(LR, RF, XGBOOST) is ', hard_voting_accuracy * 100)\nprint('F1 Accuracy of Hard Voting(LR, RF, XGBOOST) is ', hard_voting_f1_accuracy * 100)","25377771":"from sklearn.ensemble import VotingClassifier\n\nlogistic_model = LogisticRegression(random_state=2, C=780.146713913726)\nrf_model = RandomForestClassifier(random_state=2, max_depth=3)\ngb_model = GradientBoostingClassifier(random_state=2)\nxgb_model = XGBClassifier(random_state=2, max_depth=4, eval_metric='logloss')\nlgbm_model = LGBMClassifier(random_state=2,\n                            learning_rate=0.01,\n                            max_depth=10,\n                            subsample=0.5,\n                            colsample_bytree=1)\n\nsoft_voting = VotingClassifier(estimators=[('Logistic Regression', logistic_model),\n                                           ('Random Forest', rf_model),\n                                           ('Gradient Boosting', gb_model),\n                                           ('XGBoost', xgb_model),\n                                           ('LGBM', lgbm_model)], n_jobs=-1, voting='soft')\n\nsoft_voting.fit(X_train, y_train)\nsoft_voting_prediction = soft_voting.predict(X_test)\nsoft_voting_accuracy = accuracy_score(y_test, soft_voting_prediction)\nsoft_voting_f1_accuracy = f1_score(y_test, soft_voting_prediction)\nprint('Accuracy of Soft Voting(LR, RF, XGBOOST) is ', soft_voting_accuracy * 100)\nprint('F1 Accuracy of Hard Voting(LR, RF, XGBOOST) is ', soft_voting_f1_accuracy * 100)","9f255649":"# XGBoost","30358f6f":"## Soft Voting","762768fa":"## Hard Voting","888ca0e3":"# Gradient Boosting","b9cda9d0":"# Random Forest","968af714":"# LightGBM","71d4139d":"# Data load & Understaning","eda93a9c":"# Logistic Regression","1813561a":"# Data Split & Models","c1715fbd":"# Voting"}}