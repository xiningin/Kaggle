{"cell_type":{"7b6adf2b":"code","24a6d1b3":"code","6d5a66f7":"code","ebc571be":"code","2fd348be":"code","afe489f3":"code","f5125380":"code","22236d73":"code","bdaf0c84":"code","30beee65":"code","8ec0ca5a":"code","5bdaa2de":"code","2fe3ce1e":"code","faf7118c":"code","e881f569":"code","feeea2c8":"code","3cbb9cf4":"code","a832b62b":"code","26425fef":"code","6e3e05c3":"code","c14f8c08":"code","2d30380e":"code","2ae47e6c":"markdown","aa028798":"markdown","685cae48":"markdown","63d4e22e":"markdown","02f9e758":"markdown","9017e9cd":"markdown","613e69b8":"markdown","8bd175f7":"markdown","7950f0c5":"markdown","c1040e43":"markdown","ac048432":"markdown","03523b27":"markdown","81b677ae":"markdown","71659030":"markdown"},"source":{"7b6adf2b":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","24a6d1b3":"train = pd.read_csv(\"\/kaggle\/input\/dlp-private-competition-dataset-modificated\/train.csv\")\ntrain = train.drop(['ID'],1)     # train\uc758 ID\ub97c Drop \uc2dc\ucf1c\uc90c\ntrain = train.reset_index(drop=True)     # train\uc758 index\ub97c \ucd08\uae30\ud654 \uc2dc\ucf1c\uc90c\nprint(train.shape)\ntrain.head()","6d5a66f7":"test = pd.read_csv(\"\/kaggle\/input\/dlp-private-competition-dataset-modificated\/test.csv\")\ntest = test.drop(['ID'],1)     # train\uc758 ID\ub97c Drop \uc2dc\ucf1c\uc90c\ntest = test.reset_index(drop=True)     # train\uc758 index\ub97c \ucd08\uae30\ud654 \uc2dc\ucf1c\uc90c\nprint(test.shape)\ntest.head()","ebc571be":"submission = pd.read_csv(\"\/kaggle\/input\/dlp-private-competition-dataset-modificated\/submission.csv\")\nprint(submission.shape)\nsubmission.head()","2fd348be":"test['Y'] = 9999\ntest.head()\n# test\uc14b\uc5d0 Y\uac12\uc5d0 9999\ub97c insert (\ub098\uc911\uc5d0 \ubd84\ud560\ub54c Y\uac12\uc774 9999\uc778 \uac83\ub4e4\ub9cc test\ub85c \ube7c\uc8fc\uba74 \ub428)","afe489f3":"total = pd.concat([train,test],0)     # train\uacfc test\ub97c \ud569\uccd0\uc90c \nprint(train.shape, test.shape, \"--> \",total.shape)     # train\uacfc test\uac00 \ud569\uccd0\uc838\uc11c total\uc774 \ub418\ub294\ub370 shape\ub97c \ud655\uc778\ntotal.head()     # total\uc758 \uc55e\uc5d0 5\uac1c \ud589 \ud655\uc778(\uc798 \ud569\uccd0\uc84c\ub098..)","f5125380":"total.tail()     # total\uc758 \ub9c8\uc9c0\ub9c9 5\uac1c \ud589 \ud655\uc778(\uc798 \ud569\uccd0\uc84c\ub098..)","22236d73":"str_line = []\ncolumn_name = []\nunique_list = []\n\nfor i in total.columns:\n    total_list1 = list(total[i].unique())\n    total_list2 = list((pd.DataFrame(total_list1).dropna())[0])\n    str_data = int(str(type(total_list2[0])) == \"<class 'str'>\")\n    str_line.append(str_data)\n    column_name.append(i)\n\nstr_line = pd.DataFrame(str_line)\ncolumn_name = pd.DataFrame(column_name)\nall_column = pd.concat([column_name, str_line],1)\nall_column.columns = ['column_name', 'strn']\n\nstr_column = pd.DataFrame(all_column[all_column['strn'] == 1])\nstr_column = list(str_column['column_name'])\n\nunique_count = []\nunique_column = []\n\nfor i in str_column:\n    total_unique = list(total[i].unique())\n    total_unique = len(total_unique)\n    unique_count.append(total_unique)\n    unique_column.append(i)\n\nunique_count = pd.DataFrame(unique_count)\nunique_column = pd.DataFrame(unique_column)\n\nif len(unique_count) == 0:\n    print(\"#####  Dataset have no string data  #####\")\nelse:\n    unique_total = pd.concat([unique_column, unique_count],1)\n    unique_total.columns = ['unique_column', 'unique_count']\n    unique_total = unique_total.sort_values([\"unique_count\"], ascending=[False])\n    # unique_total\n    # \uc0c1\uc704 4\uac1c \ud56d\ubaa9\ub4e4\uc740 \ub530\ub85c \uad00\ub9ac\ud574\uc57c \ud560\ub4ef, \ub098\uba38\uc9c0\ub294 OHE\uc9c4\ud589\n    unique_column = unique_total.unique_column.values\n    print(unique_column)     # column\uc5d0 string(\ubb38\uc790) \ub370\uc774\ud130\uac00 \uc788\ub294 column\ub9cc \ucd9c\ub825\ud574\uc90c","bdaf0c84":"from sklearn.preprocessing import LabelEncoder\ncols = ['END_TM', 'A', 'B']     # \uc55e\uc5d0\uc11c \ubb38\uc790\ud615 \ubcc0\uc218\uac00 \uc18d\ud574\uc788\ub294 Column\ub4e4\uc744 Label Encoding\ud568\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(total[c].values)) \n    total[c] = lbl.transform(list(total[c].values))     # unique_column\uc744 \uc804\ubb34 label_encoding\ud568\n\nprint('Shape all_data: {}'.format(total.shape))\n","30beee65":"cate_col = ['END_TM', 'A', 'B']\n\nfor col in cate_col:\n    total[col] = total[col].astype('category')\n    \n# END_TM, A, B\ub294 Label Encoding\uc73c\ub85c \uc22b\uc790\ub85c \ubc14\uafb8\uc5c8\uc9c0\ub9cc \uc6d0\ub798\ub294 category \uac12\uc784,\n# Label Encoding\uc73c\ub85c 1,2,3,4,5,... \uc73c\ub85c \ubc14\ub00c\uc5c8\uae30 \ub54c\ubb38\uc5d0 LightGBM \ubaa8\ub378\uc740 \uadf8\ub0e5 \uc5f0\uc18d\uc801\uc778 \uac12\uc73c\ub85c \uc774\ud574\ud568\n# \uadf8\ub807\uae30 \ub54c\ubb38\uc5d0 \ud574\ub2f9 column\uc744 \uc22b\uc790\uc774\uc9c0\ub9cc Category\ub85c \ubcc0\ud658\uc2dc\ucf1c\uc918\uc57c \ud568","8ec0ca5a":"pd.set_option('display.max_columns', 10000)\n# head() \ucd9c\ub825\uc2dc\uc5d0 \uc804\uccb4\ub85c \ubcf4\uc774\uac8c \ub9cc\ub4e4\uc5b4 \uc90c, \ub113\uc774\ub97c \ub298\ub824\uc90c, \ud654\uba74\n\ntotal.head()     # \ub0a0\uc9dc\uae4c\uc9c0 \uc804\ubd80 Label Encoding \ub418\uc5c8\uc74c..(\ud544\uc694\ud558\ub2e4\uba74 Label Encoding \uc804\uc5d0 \ub530\ub85c Feature Engineering \uc9c4\ud589)","5bdaa2de":"test = total[total['Y'] == 9999]     # total['Y']\uac00 9999\uc778 \uac12\ub9cc test\ub85c \ubf51\uc544\uc90c\ntest.head()     # test\uc5d0\uc11c\ub294 Y\uac12\uc740 \ud544\uc694 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \uc0ad\uc81c\ud574\uc918\uc57c\ud568","2fe3ce1e":"test = test.drop(['Y'],1)\ntest.head() ","faf7118c":"train = total[total['Y'] != 9999]     # total['Y']\uac00 9999\uc774 \uc544\ub2cc \uac12\ub9cc train\uc73c\ub85c \ubf51\uc544\uc90c\ntrain.head()     # \uc798 \ubd84\ub9ac\ub418\uc5c8\uad70..","e881f569":"y = pd.DataFrame(train['Y'])\ny.head()","feeea2c8":"X = train.drop(['Y'],1)\nX.head()","3cbb9cf4":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split (X,y, random_state=0)","a832b62b":"import lightgbm as lgb\nlgbm = lgb.LGBMRegressor (objective = 'regression', num_leaves=144,\n                         learning_rate=0.005,n_estimators=720, max_depth=13,\n                         metric='rmse', is_training_metric=True, max_bin=55,\n                         bagging_fraction=0.8, verbose=-1, bagging_freq=5, feature_fraction=0.9)","26425fef":"lgbm.fit(X_train, y_train)","6e3e05c3":"#=== MSE\ub85c \ud3c9\uac00\ud560 \uacbd\uc6b0 \uc544\ub798\uc640 \uac19\uc774 \uc9c4\ud589===#\nfrom sklearn.metrics import mean_squared_error\n\npred_train = lgbm.predict(X_train)\npred_valid = lgbm.predict(X_valid)\nprint(mean_squared_error(pred_train, y_train))\nprint(mean_squared_error(pred_valid, y_valid))\n\n\n# #=== House Price\uc5d0\uc11c RMSE \uac12\uc744 \uad6c\ud558\ub294 \uacbd\uc6b0 \uc544\ub798\uc640 \uac19\uc774 \uc9c4\ud589===#\n# from sklearn.metrics import mean_squared_error\n\n# pred_train = lgbm.predict(X_train)\n# pred_valid = lgbm.predict(X_valid)\n\n# print(np.sqrt(mean_squared_error(np.log1p(y_train), np.log1p(pred_train))))\n# print(np.sqrt(mean_squared_error(np.log1p(y_valid), np.log1p(pred_valid))))\n\n# # \uc704\uc5d0\ub294 MSE\uc774\uba70, RMSE\ub97c \uad6c\ud560\ub54c\ub294 \ud574\ub2f9\uc73c\ub85c \uc9c4\ud589","c14f8c08":"pred_test = lgbm.predict(test)\npred_test","2d30380e":"submission = submission.drop(\"Y\",1)\npred_test = pd.DataFrame(pred_test)\n\nsubmission_final = pd.concat([submission,pred_test],axis=1)\n\nsubmission_final.columns = ['ID','Y']\nsubmission_final.to_csv(\"submission_fianl.csv\", index=False)\nsubmission_final.tail()","2ae47e6c":"# Find column having a string data\n- Model\uc740 string(\ubb38\uc790) data\ub294 \ubd84\uc11d\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\n- dataset\uc5d0\uc11c string\uc744 \uac00\uc9c0\uace0 \uc788\ub294 column\uc744 \ucc3e\uc544\uc11c \uc22b\uc790\ub85c \ubc14\uafd4\uc8fc\uac70\ub098 \uc9c0\uc6cc\uc57c Model\uc774 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","aa028798":"# Change data from string to numeric(using Label Encoding)\n- \uc55e\uc5d0\uc11c \ucc3e\uc544\uc900 string data\ub97c numerical data(\uc22b\uc790\ud615)\uc73c\ub85c \ubc14\uafd4\uc90d\ub2c8\ub2e4.\n- \uc5ec\uae30\uc11c\ub294 Label Encoding\uc774\ub77c\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. (Label Encoding\uc740 \uc784\uc758\ub85c \uc21c\uc11c\ub300\ub85c 1\ubd80\ud130 \uc9c0\uc815\ud574\uc11c \ubc14\uafd4\uc90d\ub2c8\ub2e4.)","685cae48":"# Import Library\n- \ubd84\uc11d\uc5d0 \ud544\uc694\ud55c Library\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4","63d4e22e":"# Split the dataset(2) (train -> X \/ y)\n- train \ub370\uc774\ud130\ub97c X\ubcc0\uc218\uc640 y\ubcc0\uc218\ub85c \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \ud574\ub2f9\uc740 \ubaa8\ub378\uc744 \ub3cc\ub9ac\uae30\uc804\uc5d0 \uc0ac\uc804 \uacfc\uc815\uc774\ubbc0\ub85c \ud2b9\ubcc4\ud55c \uc774\uc720\uc5c6\uc774 \uc9c4\ud589\ub429\ub2c8\ub2e4.","02f9e758":"# Split the dataset(3) (X, y -> X_train, y_train, X_valid, y_valid)\n- \uc55e\uc5d0\uc11c \ubd84\ub9ac\ud55c X\uc640 y\ub97c train\uacfc valid\ub85c \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \ub370\uc774\ud130 \uc138\ud2b8\ub97c \ubd84\ub9ac\ud558\ub294 \uc774\uc720\ub294 \ubaa8\ub378\uc774 overfitting\uc774 \ub418\uc5c8\ub294\uc9c0 \uac80\uc99d\ud558\uae30 \uc704\ud568\uc785\ub2c8\ub2e4.\n- \uc774\ud574\uac00 \uc5b4\ub824\uc6b8 \uc2dc \uae30\uc874\uc5d0 \ubc30\ud3ec\ud55c Machine Learning Pipeline\uc744 \ucc38\uace0\ud574\uc8fc\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.","9017e9cd":"# Import Dataset\n- \ubd84\uc11d\uc5d0 \ud544\uc694\ud55c Dataset\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4","613e69b8":"# (\u2605\uc704\uc5d0 RMSE \ubcf4\ucda9\uc124\uba85) House Price \ub300\ud68c Scoring \ubc29\uc2dd\n\n- House Price\uc5d0\uc11c\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc2e4\uc81c\uac12\uacfc \uc608\uce21\uac12\uc758 Log\ub97c \uc50c\uc5b4\uc11c RMSE\ub97c \uad6c\ud558\ub77c\uace0 \ud558\uc600\uc74c\n  > Submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n- RMSE\ub294 MSE\uc758 root\ub97c \ucde8\ud574\uc900 \uac12\uc784, \uae30\uc874\uc5d0 MSE\ub97c \uad6c\ud588\ub358 \uc2dd\uc5d0 np.sqrt(Numpy\uc758 square root)\ub97c \uc50c\uc5b4\uc90c\uc73c\ub85c\uc368 \uac12\uc744 \uad6c\ud574\uc8fc\uc5b4\uc57c \ud568\n\n\n\n![](http:\/\/)","8bd175f7":"# Split the dataset (total -> train \/ test)\n- \ubaa8\ub4e0 Feature Engineering\uc744 \uc9c4\ud589\ud588\uae30 \ub54c\ubb38\uc5d0 \ub2e4\uc2dc \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \uae30\uc874\uc5d0 total\ub85c \ud569\uccd0\uc9c4\uac83\uc744 \ub2e4\uc2dc train\uacfc test\ub85c \ubd84\ub9ac\ud569\ub2c8\ub2e4.","7950f0c5":"# Submit the result\n- test dataset\uc744 \uac00\uc9c0\uace0 \uc608\uce21\ud55c \uacb0\uacfc\ub97c submission dataset\uc5d0 import\ud558\uc5ec kaggle\uc5d0 \uc81c\ucd9c!","c1040e43":"# Calculate MSE (Loss function)\n- X_train \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc608\uce21\uac12 Pred_train\uacfc y_train\uac04\uc758 \ucc28\uc774 --- (1)\n- X_valid \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc608\uce21\uac12 Pred_valid\uc640 y_valid\uac04\uc758 \ucc28\uc774 --- (2)\n- (1)\uacfc (2)\uac00 \ucc28\uc774\uac00 \ud06c\ub2e4\uba74 Overfitting\uc774\ubbc0\ub85c \ud5a5\ud6c4 \uc608\uce21\uc5d0 \uc5b4\ub824\uc6b8 \uc218 \uc788\uc74c","ac048432":"# Merge train & test dataset (for Feature Engineering)\n- Feature Engineering\uc744 \ud560\ub54c Train\uacfc Test dataset\uc744 \ub3d9\uc2dc\uc5d0 \uc9c4\ud589\ud574\uc57c \ud568\n- \ud560\ub54c\ub9c8\ub2e4 \ub530\ub85c \uc9c4\ud589\ud558\uba74 \ubd88\ud3b8\ud558\uae30 \ub54c\ubb38\uc5d0 \ud569\uccd0\ub193\uace0 \uc9c4\ud589\ud568(\ucd94\ud6c4 \ub2e4\uc2dc Train\uacfc Test\ub85c \ubd84\ub9ac\ud568)","03523b27":"# Train the model\n- Train data\ub97c \uc0ac\uc6a9\ud558\uc5ec Model\uc744 \ud559\uc2b5\uc2dc\ud0b4","81b677ae":"# Predict wafer thick (with test dataset)\n- \uc55e\uc5d0 \uac80\uc99d\uc744 \ud1b5\ud574 \ubaa8\ub378\uc774 \ud559\uc2b5\uc774 \uc798 \ub418\uc5c8\ub294\uc9c0 \ud655\uc778\uc774 \ub418\uc5c8\ub2e4\uba74 Test dataset\uc744 \uac00\uc9c0\uace0 \uc608\uce21\ud574\ubd04","71659030":"# Import Model (LightGBM)"}}