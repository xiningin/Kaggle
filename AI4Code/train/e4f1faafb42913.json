{"cell_type":{"57e03687":"code","ee3c678e":"code","65ed2d8a":"code","909b7a69":"code","846691c6":"code","540b022f":"code","8253ca31":"code","6b3cabb5":"code","a6b365ef":"code","39373922":"code","223e3343":"code","8988d840":"code","2bcbacb8":"code","5b1b3663":"code","7c8488e7":"code","06d29f8e":"code","925cbed4":"code","98886793":"code","3843d536":"code","2123ef62":"code","ba041507":"code","d8f9d221":"code","286febc3":"markdown","e2a95fff":"markdown","96416275":"markdown","1bafeadc":"markdown","2b81d5bf":"markdown","c7d8b3ff":"markdown","8eeba38f":"markdown","254316f9":"markdown","a30f711a":"markdown","229c3f90":"markdown","ee182e18":"markdown","ce4f410d":"markdown","c9b64166":"markdown"},"source":{"57e03687":"!git clone https:\/\/bitbucket.org\/jadslim\/german-traffic-signs","ee3c678e":"!ls german-traffic-signs","65ed2d8a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.layers import Dense\nfrom keras.layers import Flatten, Dropout\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nimport random\nimport pickle\nimport pandas as pd\nimport cv2","909b7a69":"np.random.seed(0)","846691c6":"with open('german-traffic-signs\/train.p', 'rb') as f:\n    train_data = pickle.load(f)\nwith open('german-traffic-signs\/valid.p', 'rb') as f:\n    val_data = pickle.load(f)\n# TODO: Load test data\nwith open('german-traffic-signs\/test.p', 'rb') as f:\n    test_data = pickle.load(f)\n    \nX_train, y_train = train_data['features'], train_data['labels']\nX_val, y_val = val_data['features'], val_data['labels']\nX_test, y_test = test_data['features'], test_data['labels']\n    \nprint(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)\n ","540b022f":"assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\nassert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\nassert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels.\"\nassert(X_val.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\nassert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels.\"\nassert(X_test.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"","8253ca31":"data = pd.read_csv('german-traffic-signs\/signnames.csv')\nnum_of_samples=[]\n \ncols = 5\nnum_classes = 43\n \nfig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,50))\nfig.tight_layout()\n \nfor i in range(cols):\n    for j, row in data.iterrows():\n      x_selected = X_train[y_train == j]\n      axs[j][i].imshow(x_selected[random.randint(0,(len(x_selected) - 1)), :, :], cmap=plt.get_cmap('gray'))\n      axs[j][i].axis(\"off\")\n      if i == 2:\n        axs[j][i].set_title(str(j) + \" - \" + row[\"SignName\"])\n        num_of_samples.append(len(x_selected))","6b3cabb5":"print(num_of_samples)\nplt.figure(figsize=(12, 4))\nplt.bar(range(0, num_classes), num_of_samples)\nplt.title(\"Distribution of the train dataset\")\nplt.xlabel(\"Class number\")\nplt.ylabel(\"Number of images\")\nplt.show()","a6b365ef":"\nimport cv2\n \nplt.imshow(X_train[1000])\nplt.axis(\"off\")\nprint(X_train[1000].shape)\nprint(y_train[1000])\ndef grayscale(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    return img","39373922":"img = grayscale(X_train[1000])\nplt.imshow(img)\nplt.axis(\"off\")\nprint(img.shape)\ndef equalize(img):\n    img = cv2.equalizeHist(img)\n    return img\nimg = equalize(img)\nplt.imshow(img)\nplt.axis(\"off\")\nprint(img.shape)","223e3343":"def preprocess(img):\n    img = grayscale(img)\n    img = equalize(img)\n    img = img\/255\n    return img","8988d840":"X_train = np.array(list(map(preprocess, X_train)))\nX_test = np.array(list(map(preprocess, X_test)))\nX_val = np.array(list(map(preprocess, X_val)))\n \nplt.imshow(X_train[random.randint(0, len(X_train) - 1)])\nplt.axis('off')\nprint(X_train.shape)","2bcbacb8":"X_train = X_train.reshape(34799, 32, 32, 1)\nX_test = X_test.reshape(12630, 32, 32, 1)\nX_val = X_val.reshape(4410, 32, 32, 1)","5b1b3663":"from keras.preprocessing.image import ImageDataGenerator\n \ndatagen = ImageDataGenerator(width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            zoom_range=0.2,\n                            shear_range=0.1,\n                            rotation_range=10.)\n \ndatagen.fit(X_train)\nbatches = datagen.flow(X_train, y_train, batch_size = 15)\nX_batch, y_batch = next(batches)\n \nfig, axs = plt.subplots(1, 15, figsize=(20, 5))\nfig.tight_layout()\n \nfor i in range(15):\n    axs[i].imshow(X_batch[i].reshape(32, 32))\n    axs[i].axis(\"off\")\n \nprint(X_batch.shape)","7c8488e7":"y_train = to_categorical(y_train, 43)\ny_test = to_categorical(y_test, 43)\ny_val = to_categorical(y_val, 43)","06d29f8e":" def modified_model():\n  model = Sequential()\n  model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))\n  model.add(Conv2D(60, (5, 5), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  \n  model.add(Conv2D(30, (3, 3), activation='relu'))\n  model.add(Conv2D(30, (3, 3), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  \n  model.add(Flatten())\n  model.add(Dense(500, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(43, activation='softmax'))\n  \n  model.compile(Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n  return model","925cbed4":"model = modified_model()\nprint(model.summary())\n \nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size=50),\n                            epochs=10,\n                            validation_data=(X_val, y_val), shuffle = 1)","98886793":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss')\nplt.xlabel('epoch')\n ","3843d536":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['training','test'])\nplt.title('Accuracy')\nplt.xlabel('epoch')\nplt.style.use('ggplot')","2123ef62":"import requests\nfrom PIL import Image\nurl = 'https:\/\/thumbs.dreamstime.com\/t\/road-signs-main-road-sign-blue-background-road-signs-main-road-sign-blue-background-109436823.jpg'\nr = requests.get(url, stream=True)\nimg = Image.open(r.raw)\nplt.imshow(img, cmap=plt.get_cmap('gray'))","ba041507":"img = np.asarray(img)\nimg = cv2.resize(img, (32, 32))\nimg = preprocess(img)\nplt.imshow(img, cmap = plt.get_cmap('gray'))\nprint(img.shape)\nimg = img.reshape(1, 32, 32, 1)","d8f9d221":"print(\"predicted sign: \"+ str(model.predict_classes(img)))\n# the prediction is correct.","286febc3":"### Defining the CNN model. I have taken inspiration from the traditional LeNet architecture as I am curious how this old model performs on such a huge dataset.","e2a95fff":"**I used the traditional LeNet model architecture for classifing road symbols. The model seems to work very well as I achieved validation accuracy of around 99% which is really amazing. Also I tried certain random images from the Internet to classify, the model was accuretly able to classify them. \nI added only a single dropout layer which produced a very good accuracy. The best part of the model is that it has generalize the data very well. Would come back here and try to fine tune the model a little more to achieve 100% valadition accuracy.** \nAnyone who is interested can copy and edit my notebook and let me know the changes. If you like my work then please upvote. ","96416275":"### Downloading the dataset from github. ","1bafeadc":"### Loading the data as train, test & valadition.","2b81d5bf":"### Visualising the data","c7d8b3ff":"### Importing all the libraries","8eeba38f":"### As we can see in graph below that this dataset is a little bit imbalanced.","254316f9":"#### I am curious as to how this model can be deployed as an end node. I already am able to create a UI app for this but if any one have an idea as to how this can be deployed in heroku using flask then please let me know. ","a30f711a":"### Applying the preprocessing function to every image in dataset","229c3f90":"### Taking a random image from Internet to test my model","ee182e18":"### Using OpenCV2 for preprocessing the image. ","ce4f410d":"### This step is just to make sure that I can come to know about any errors easily. One can skip this step if wanted","c9b64166":"### As seen below that the model is accuretly able to classify a random google image. This image belongs to the category 12, one can scroll up and find it in the data visualization part of this notebook"}}