{"cell_type":{"9493867c":"code","2a52cfb4":"code","c0ba936c":"code","68721bfb":"code","3bc67750":"code","c461f7eb":"code","74e838a6":"code","074ad07f":"code","c6ce02cb":"code","d4c2d2ba":"code","22bcaf36":"code","ee7ae810":"code","4f686431":"code","fb4e6cbd":"code","47e52270":"code","ead2a387":"code","84c2a768":"code","5d9a069a":"code","a3dce149":"code","1d48928f":"code","02a5366d":"code","39f32fdd":"code","9222f577":"code","9bb90056":"code","274aaa6a":"code","b0755652":"code","1070b985":"code","6034627a":"code","dd73fead":"code","c028c9ef":"code","23ed7e26":"code","a56f0636":"code","ab5bf640":"code","4228745d":"code","555436d7":"code","d909df80":"code","ca2d648e":"code","7b139f64":"code","37d80151":"code","e60a12d9":"code","cf3cd37a":"code","35e1ae9d":"code","09c8d9be":"code","0339932f":"code","16c254de":"code","60610296":"code","e98ebd23":"code","7456c0c5":"code","6eeb72ee":"code","637093a4":"code","0ba90ad1":"code","ad8aae98":"code","49aeb545":"code","d17492a3":"code","d41a9234":"code","94da1c2e":"code","a0ace0a5":"code","dfe6d915":"code","3eebf4d2":"code","cff26b73":"code","6ad01164":"code","89c38407":"code","ddf44c74":"code","476c88cc":"code","45bd6674":"code","a5dbdc64":"code","ed95ef91":"code","8004b7f8":"code","157469ca":"code","023963e9":"code","dcd3a4bb":"code","15d602d4":"code","a1cc275c":"code","8f3a2e6c":"code","743fc356":"code","782a9de6":"code","95370e8a":"code","2e58841e":"code","7a401dca":"code","05c50afc":"code","556efd98":"code","090788c6":"code","08e07c2e":"code","b10bf2c5":"code","5af0f300":"code","c439db2f":"code","0b242ad6":"code","5797293b":"code","f76cceea":"code","17cd63b9":"code","d29635fc":"code","31cee6f4":"code","5a32ff51":"code","4644e184":"code","06c295d4":"code","629de4d0":"code","13dd7423":"code","80b34e3c":"code","aea6bfd3":"code","f894bf24":"code","1da3f8ca":"code","9a8f8134":"code","68267da3":"code","2f23c16b":"code","8ff0792f":"code","996590f4":"code","0235100d":"code","d5e416a9":"code","7469707a":"code","3cf1130e":"code","2fdc0047":"code","d76146bc":"code","c479598d":"code","9eddfbe7":"code","be91a19f":"code","8f8dbce0":"code","9ac982d7":"code","fe4ce70f":"code","c9addefe":"code","bf799cb4":"code","a4f10ed3":"code","08183955":"markdown","87b950bb":"markdown","76097234":"markdown","73265fb6":"markdown","9db54ab7":"markdown","763e7e3c":"markdown","343924bb":"markdown","45856818":"markdown","6b3e45be":"markdown","0b6e5e80":"markdown","ee6cc5e5":"markdown","6ab76bf5":"markdown","cac22602":"markdown","3e58e0f6":"markdown","a6208dae":"markdown","73b4f9ce":"markdown","dff82c81":"markdown","81e1ece0":"markdown","6abeeb3b":"markdown","9f767a00":"markdown","c0479348":"markdown","44b27c54":"markdown","fc7650cf":"markdown","f35fa78f":"markdown","d291b024":"markdown","adca5b73":"markdown","dee083ae":"markdown","9ab98cad":"markdown","964dc0b7":"markdown","a9cf08ab":"markdown","d3667075":"markdown","6d9612f8":"markdown","ec8ac8d5":"markdown","331de654":"markdown","e2214401":"markdown","4337d720":"markdown","f5de7de8":"markdown","7f4f0830":"markdown","f06f35a7":"markdown","9fde28bc":"markdown","62457954":"markdown","6e9f9b6a":"markdown","f84fdf27":"markdown","870cf11a":"markdown","559523fa":"markdown","41c77244":"markdown","0fcd2be9":"markdown","b694e566":"markdown","4607d2ed":"markdown","16fa5058":"markdown","97f86d28":"markdown","5356061b":"markdown","6b973f25":"markdown","44299fbf":"markdown","01a1a050":"markdown","13ca08f7":"markdown","8dbc1485":"markdown","34891b3e":"markdown","310c1339":"markdown","a4e9bc89":"markdown","1de4b1d7":"markdown","3563c79b":"markdown","5b5a833e":"markdown","26b2f84a":"markdown","1ba812d8":"markdown","b46ff67d":"markdown","f505b8d5":"markdown","e8bc3374":"markdown","67e71bc3":"markdown","16cd0f51":"markdown","ebdbe038":"markdown","43c77db0":"markdown","ae3c6f29":"markdown","87463200":"markdown","82cceda9":"markdown","d80f882b":"markdown","722d6e4a":"markdown","ad400cfb":"markdown","66f9ffba":"markdown","21cc3498":"markdown","8543fce2":"markdown","ebebe8ef":"markdown","4ddc99d2":"markdown","1e546577":"markdown","002fce38":"markdown","53f15c1c":"markdown","d56362ce":"markdown","bd57b6ab":"markdown","c036589e":"markdown","60729033":"markdown","0e6e88d2":"markdown","18501875":"markdown","901efc12":"markdown","6603bc8d":"markdown","efe684bd":"markdown","c6153553":"markdown","67e71e79":"markdown","b4b4460b":"markdown","a57f556c":"markdown","143e2e4c":"markdown","374aa1a3":"markdown","40443b3e":"markdown","f3f73ffb":"markdown","91b57014":"markdown","d86aa2e4":"markdown","bf5ba7fa":"markdown","8e340f58":"markdown","b0b979d5":"markdown","e9e8e4bc":"markdown","b3275660":"markdown"},"source":{"9493867c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nimport gc\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2a52cfb4":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsub_df = pd.read_csv('..\/input\/sample_submission.csv')","c0ba936c":"train_df.head()","68721bfb":"train_df.columns","3bc67750":"train_df.isna().sum()","c461f7eb":"test_df.isna().sum()","74e838a6":"train_df.columns","074ad07f":"f, ax = plt.subplots(3, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(12,8)})\nsns.boxplot(x=train_df.revenue, ax = ax[0])\nax[0].set_title(\"revenue Boxplot\")\nsns.distplot(a=train_df.revenue, kde = False, ax = ax[1])\nax[1].set_title(\"revenue Histogram\")\nsns.distplot(a=np.log1p(train_df.revenue), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed revenue Histogram\")\nf.tight_layout()\n\ntrain_df[\"log_revenue\"] = np.log1p(train_df.revenue)\n\n\n","c6ce02cb":"wordcloud = WordCloud().generate(train_df.title.to_string())\n\nsns.set(rc={'figure.figsize':(12,8)})\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","d4c2d2ba":"train_df[\"title\"] = train_df[\"title\"].fillna(\"\")\ntest_df[\"title\"] = test_df[\"title\"].fillna(\"\")\n\ntrain_df[\"title_len\"] = train_df[\"title\"].apply(len)\ntest_df[\"title_len\"] = test_df[\"title\"].apply(len)\n\nf, ax = plt.subplots(3, figsize=(12,7))\nsns.set(rc={'figure.figsize':(12,8)})\nsns.boxplot(x=train_df.title_len, ax = ax[0])\nax[0].set_title(\"titles' length Boxplot\")\nsns.distplot(a=train_df.title_len, kde = False, ax = ax[1])\nax[1].set_title(\"titles' length Histogram\")\nsns.distplot(a=np.log1p(train_df.title_len), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed titles' length Histogram\")\nf.tight_layout()\n\ntrain_df[\"log_title_len\"] = np.log1p(train_df.title_len)\ntest_df[\"log_title_len\"] = np.log1p(test_df.title_len)","22bcaf36":"wordcloud = WordCloud().generate(train_df.overview.to_string())\n\nsns.set(rc={'figure.figsize':(12,8)})\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","ee7ae810":"train_df[\"overview\"] = train_df[\"overview\"].fillna(\"\")\ntest_df[\"overview\"] = test_df[\"overview\"].fillna(\"\")\n\ntrain_df[\"overview_len\"] = train_df[\"overview\"].apply(len)\ntest_df[\"overview_len\"] = test_df[\"overview\"].apply(len)\n\nf, ax = plt.subplots(3, figsize=(12,7))\nsns.set(rc={'figure.figsize':(12,8)})\nsns.boxplot(x=train_df.overview_len, ax = ax[0])\nax[0].set_title(\"overview' length Boxplot\")\nsns.distplot(a=train_df.overview_len, kde = False, ax = ax[1])\nax[1].set_title(\"overview' length Histogram\")\nsns.distplot(a=np.log1p(train_df.overview_len), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed overview' length Histogram\")\nf.tight_layout()\n\ntrain_df[\"log_overview_len\"] = np.log1p(train_df.overview_len)\ntest_df[\"log_overview_len\"] = np.log1p(test_df.overview_len)","4f686431":"wordcloud = WordCloud().generate(train_df.tagline.to_string())\n\nsns.set(rc={'figure.figsize':(12,8)})\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","fb4e6cbd":"train_df[\"tagline\"] = train_df[\"tagline\"].fillna(\"\")\ntest_df[\"tagline\"] = test_df[\"tagline\"].fillna(\"\")\n\ntrain_df[\"tagline_len\"] = train_df[\"tagline\"].apply(len)\ntest_df[\"tagline_len\"] = test_df[\"tagline\"].apply(len)\n\nf, ax = plt.subplots(3, figsize=(12,7))\nsns.set(rc={'figure.figsize':(12,8)})\nsns.boxplot(x=train_df.tagline_len, ax = ax[0])\nax[0].set_title(\"tagline_len' length Boxplot\")\nsns.distplot(a=train_df.tagline_len, kde = False, ax = ax[1])\nax[1].set_title(\"tagline_len' length Histogram\")\nsns.distplot(a=np.log1p(train_df.tagline_len), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed tagline_len' length Histogram\")\nf.tight_layout()\n\ntrain_df[\"log_tagline_len\"] = np.log1p(train_df.tagline_len)\ntest_df[\"log_tagline_len\"] = np.log1p(test_df.tagline_len)","47e52270":"f, ax = plt.subplots(3, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(12,8)})\nsns.boxplot(x=train_df.budget, ax = ax[0])\nax[0].set_title(\"budget Boxplot\")\nsns.distplot(a=train_df.budget, kde = False, ax = ax[1])\nax[1].set_title(\"budget Histogram\")\nsns.distplot(a=np.log1p(train_df.budget), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed budget Histogram\")\nf.tight_layout()\n\ntrain_df[\"log_budget\"] = np.log1p(train_df.budget)\ntest_df[\"log_budget\"] = np.log1p(test_df.budget)","ead2a387":"def genres_preprocessing(elem):\n    string = str(elem)\n    str1 = string.replace(']','').replace('[','').replace('{','').replace('}','').replace('\\'','').replace(' ','').replace(\"name\", \"\").replace(\"id\", \"\").replace(\":\", \"\")\n    ll = str1.split(\",\")[1::2]\n    return ll\n\ntrain_df[\"genres_processed\"] = train_df.genres.apply(lambda elem: genres_preprocessing(elem))\ntest_df[\"genres_processed\"] = test_df.genres.apply(lambda elem: genres_preprocessing(elem))\n\ngenres_dict = dict()\n\nfor genre in train_df[\"genres_processed\"]:\n    for elem in genre:\n        if elem not in genres_dict:\n            genres_dict[elem] = 1\n        else:\n            genres_dict[elem] += 1\n\n\nsns.set(rc={'figure.figsize':(12,8)})\ngenres_df = pd.DataFrame.from_dict(genres_dict, orient='index')\ngenres_df.columns = [\"number_of_movies\"]\ngenres_df = genres_df.sort_values(by=\"number_of_movies\", ascending=False)\ngenres_df.plot.bar()\nplt.title(\"Number of films per genre\")","84c2a768":"sns.set(rc={'figure.figsize':(9,8)})\ntrain_df['num_genres'] = train_df['genres_processed'].apply(lambda x: len(x) if x != {} else 0)\ntest_df['num_genres'] = test_df['genres_processed'].apply(lambda x: len(x) if x != {} else 0)\n\ntrain_df['num_genres'].value_counts().plot.bar()\nplt.title(\"Number of films with more than 1 genre\")","5d9a069a":"genres_df.index.values\nfor g in genres_df.index.values:\n    train_df['isGenre_' + g] = train_df['genres_processed'].apply(lambda x: 1 if g in x else 0)\n    test_df['isGenre_' + g] = test_df['genres_processed'].apply(lambda x: 1 if g in x else 0)","a3dce149":"train_df.columns","1d48928f":"train_df.original_language.value_counts()[:10].plot.bar()\nplt.title(\"Number of films per language\")","02a5366d":"\ntrain_df[\"is_english_language\"] = train_df.original_language.apply(lambda x: 1 if x == \"en\" else 0)\ntest_df[\"is_english_language\"] = test_df.original_language.apply(lambda x: 1 if x == \"en\" else 0)\n\ntrain_df.is_english_language = train_df.is_english_language.fillna(1)\ntest_df.is_english_language = test_df.is_english_language.fillna(1)\n\nsns.set(rc={'figure.figsize':(12,8)})\nax = sns.countplot(x=\"is_english_language\", data=train_df)","39f32fdd":"def production_companies_preprocessing(elem):\n    string = str(elem)\n    str1 = string.replace(']','').replace('[','').replace('{','').replace('}','').replace(' ','').replace(\"name\", \"\").replace(\"id\", \"\").replace(\":\", \"\").replace(\"\\'\", \"\")\n    ll = str1.split(\",\")[0::2]\n    return ll\n\ntrain_df[\"production_companies\"] = train_df.production_companies.fillna('NoProductionCompany')\ntrain_df[\"production_companies\"] = test_df.production_companies.fillna('NoProductionCompany')\n\ntrain_df[\"production_companies_processed\"] = train_df.production_companies.apply(lambda elem: production_companies_preprocessing(elem))\ntest_df[\"production_companies_processed\"] = test_df.production_companies.apply(lambda elem: production_companies_preprocessing(elem))\n\n\n\nproduction_companies_dict = dict()\n\nfor production_company in train_df[\"production_companies_processed\"]:\n    for elem in production_company:\n        if elem not in production_companies_dict:\n            production_companies_dict[elem] = 1\n        else:\n            production_companies_dict[elem] += 1\n\n\nsns.set(rc={'figure.figsize':(12,8)})\nproduction_companies_df = pd.DataFrame.from_dict(production_companies_dict, orient='index')\nproduction_companies_df.columns = [\"number_of_movies\"]\nproduction_companies_df = production_companies_df.sort_values(by=\"number_of_movies\", ascending=False)\nproduction_companies_df.head(10).plot.bar()\nplt.title(\"Number of films per production company\")","9222f577":"train_df[\"num_of_production_companies\"] = train_df.production_companies_processed.apply(len)\ntest_df[\"num_of_production_companies\"] = test_df.production_companies_processed.apply(len)\n\ntrain_df[\"num_of_production_companies\"].value_counts().plot.bar()\nplt.title(\"Number of multiple production companies per movie\")","9bb90056":"for g in production_companies_df.index.values:\n    train_df['isProductionCompany_' + g] = train_df['production_companies_processed'].apply(lambda x: 1 if g in x else 0)\n    test_df['isProductionCompany_' + g] = test_df['production_companies_processed'].apply(lambda x: 1 if g in x else 0)","274aaa6a":"def production_countries_preprocessing(elem):\n    string = str(elem)\n    str1 = string.replace(']','').replace('[','').replace('{','').replace('}','').replace(' ','').replace(\"name\", \"\").replace(\"iso_3166_1\", \"\").replace(\":\", \"\").replace(\"\\'\", \"\")\n    ll = str1.split(\",\")[0::2]\n    return ll\n\ntrain_df[\"production_countries_processed\"] = train_df.production_countries.fillna(\"NaN\").apply(lambda elem: production_countries_preprocessing(elem))\ntest_df[\"production_countries_processed\"] = test_df.production_countries.fillna(\"NaN\").apply(lambda elem: production_countries_preprocessing(elem))\n\n\nproduction_countries_dict = dict()\n\nfor production_country in train_df[\"production_countries_processed\"]:\n    for elem in production_country:\n        if elem not in production_countries_dict:\n            production_countries_dict[elem] = 1\n        else:\n            production_countries_dict[elem] += 1\n\n\n\nproduction_countries_df = pd.DataFrame.from_dict(production_countries_dict, orient='index')\nproduction_countries_df.columns = [\"number_of_movies\"]\nproduction_countries_df = production_countries_df.sort_values(by=\"number_of_movies\", ascending=False)\nproduction_countries_df.head(10).plot.bar()\nplt.title(\"Number of films per production country\")","b0755652":"for c in production_countries_df.index.values:\n    train_df['isProductionCountry_' + c] = train_df['production_countries_processed'].apply(lambda x: 1 if c in x else 0)\n    test_df['isProductionCountry_' + c] = test_df['production_countries_processed'].apply(lambda x: 1 if c in x else 0)","1070b985":"f, ax = plt.subplots(3, figsize=(12,7))\nsns.boxplot(x=train_df.popularity, ax = ax[0])\nax[0].set_title(\"Popularity Boxplot\")\nsns.distplot(a=train_df.popularity, kde = False, ax = ax[1])\nax[1].set_title(\"Popularity Histogram\")\nsns.distplot(a=np.log1p(train_df.popularity), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed Popularity Histogram\")\nf.tight_layout()\n\ntrain_df[\"log_popularity\"] = np.log1p(train_df.popularity)\ntest_df[\"log_popularity\"] = np.log1p(test_df.popularity)","6034627a":"train_df[\"runtime\"] = train_df[\"runtime\"].fillna(train_df[\"runtime\"].mode()[0])\ntest_df[\"runtime\"] = test_df[\"runtime\"].fillna(test_df[\"runtime\"].mode()[0])\n\nf, ax = plt.subplots(4, figsize=(12,7))\n\ntrain_df.runtime = train_df.runtime.fillna(train_df.runtime.mode())\n\nsns.boxplot(x=train_df.runtime, ax = ax[0])\nax[0].set_title(\"Runtime Boxplot\")\nsns.distplot(a=train_df.runtime, kde = False, ax = ax[1])\nax[1].set_title(\"Runtime Histogram\")\nsns.distplot(a=train_df.runtime\/360, kde = False, ax = ax[2])\nax[2].set_title(\"Runtime in Hours Histogram\")\nsns.distplot(a=np.log1p(train_df.runtime), kde = False, ax = ax[3])\nax[3].set_title(\"Log1p transformed Runtime Histogram\")\nf.tight_layout()\n\ntrain_df[\"runtime_in_hours\"] = train_df.runtime\/360\ntest_df[\"runtime_in_hours\"] = test_df.runtime\/360\n\ntrain_df[\"log_runtime\"] = np.log1p(train_df.runtime)\ntest_df[\"log_runtime\"] = np.log1p(test_df.runtime)","dd73fead":"from datetime import datetime\n\n# fill possible NA values with the statistical mode\ntrain_df[\"release_date\"] = train_df[\"release_date\"].fillna(train_df[\"release_date\"].mode()[0])\ntest_df[\"release_date\"] = test_df[\"release_date\"].fillna(test_df[\"release_date\"].mode()[0])\n\n\ntrain_df['temp'] = train_df.release_date.apply(lambda x: datetime.strptime(x, '%m\/%d\/%y'))\n\ntrain_df[\"month\"] = train_df.temp.apply(lambda x: x.month)\ntrain_df[\"season\"] = train_df[\"month\"]%4\ntrain_df[\"year\"] = train_df.temp.apply(lambda x: x.year)\ntrain_df[\"day_of_week\"] = train_df.temp.apply(lambda x: x.weekday()+1)\ntrain_df[\"week_of_year\"] = train_df.temp.apply(lambda x: x.isocalendar()[1])\n\ntrain_df = train_df.drop(['temp'], axis=1)\n\n\ntest_df['temp'] = test_df.release_date.apply(lambda x: datetime.strptime(x, '%m\/%d\/%y'))\n\ntest_df[\"month\"] = test_df.temp.apply(lambda x: x.month)\ntest_df[\"season\"] = test_df[\"month\"]%4\ntest_df[\"year\"] = test_df.temp.apply(lambda x: x.year)\ntest_df[\"day_of_week\"] = test_df.temp.apply(lambda x: x.weekday()+1)\ntest_df[\"week_of_year\"] = test_df.temp.apply(lambda x: x.isocalendar()[1])\n\ntest_df = test_df.drop(['temp'], axis=1)\n\n\n\ntrain_df[\"day_of_week\"] = train_df[\"day_of_week\"].fillna(train_df[\"day_of_week\"].mode()[0])\ntest_df[\"day_of_week\"] = test_df[\"day_of_week\"].fillna(test_df[\"day_of_week\"].mode()[0])\n\ntrain_df[\"year\"] = train_df[\"year\"].fillna(train_df[\"year\"].mode()[0])\ntest_df[\"year\"] = test_df[\"year\"].fillna(test_df[\"year\"].mode()[0])\n\ntrain_df[\"month\"] = train_df[\"month\"].fillna(train_df[\"month\"].mode()[0])\ntest_df[\"month\"] = test_df[\"month\"].fillna(test_df[\"month\"].mode()[0])\n\ntrain_df[\"week_of_year\"] = train_df[\"week_of_year\"].fillna(train_df[\"week_of_year\"].mode()[0])\ntest_df[\"week_of_year\"] = test_df[\"week_of_year\"].fillna(test_df[\"week_of_year\"].mode()[0])\n\ntrain_df[\"season\"] = train_df[\"season\"].fillna(train_df[\"season\"].mode()[0])\ntest_df[\"season\"] = test_df[\"season\"].fillna(test_df[\"season\"].mode()[0])\n\ntrain_df[[\"release_date\", \"month\", \"year\", \"day_of_week\", \"week_of_year\", \"season\"]].head()","c028c9ef":"sns.set(rc={'figure.figsize':(12,8)})\ntrain_df.month.value_counts().plot.bar()\nplt.title('Number of films per month')","23ed7e26":"sns.set(rc={'figure.figsize':(16,8)})\ntrain_df.week_of_year.value_counts().plot.bar()\nplt.title('Number of films per week_of_year')","a56f0636":"sns.set(rc={'figure.figsize':(16,8)})\ntrain_df.season.value_counts().plot.bar()\nplt.title('Number of films per season')","ab5bf640":"sns.set(rc={'figure.figsize':(12,8)})\ntrain_df.day_of_week.value_counts().plot.bar()\nplt.title('Number of films per day_of_week')","4228745d":"sns.set(rc={'figure.figsize':(20,8)})\ntrain_df.year.value_counts().plot.bar()\nplt.title('Number of films per year')","555436d7":"import re\n\nactors_dict = {}\nsize_of_actors = len(train_df) - train_df.cast.isna().sum()\n\nfor element in train_df[[\"revenue\", \"cast\"]].values:\n    if type(element[1]) == type(str()):\n        \n        result = re.findall('name\\': \\'\\w+\\s*\\w*', element[1])\n        result = [x.replace(\"name\\': \\'\", \"\") for x in result]\n\n        for actor in result:\n            if actor not in actors_dict:\n                actors_dict[actor] = element[0]\n            else:\n                actors_dict[actor] += element[0]\n                \nfor actor in actors_dict:\n    actors_dict[actor] = actors_dict[actor]\/size_of_actors\n    \n\n\nactors_df = pd.DataFrame.from_dict(actors_dict, orient='index', columns=[\"mean_movies_revenue\"])\nactors_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(20).plot.bar()","d909df80":"def find_top_actor_from_cast(top_actor, element):\n    \n    result = []\n    if type(element) == type(str()):\n\n        result = re.findall('name\\': \\'\\w+\\s*\\w*', element)\n        result = [x.replace(\"name\\': \\'\", \"\") for x in result]\n        \n    if top_actor in result:\n        return 1\n    else:\n        return 0\n\nfor top_actor in actors_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).index.values:\n    train_df[\"has_top_actor_\"+ top_actor] = train_df.cast.apply(lambda element: find_top_actor_from_cast(top_actor, element))\n    test_df[\"has_top_actor_\"+ top_actor] = test_df.cast.apply(lambda element: find_top_actor_from_cast(top_actor, element))","ca2d648e":"import re\n\nkeywords_dict = {}\nsize_of_keywords = len(train_df) - train_df.Keywords.isna().sum()\n\nfor element in train_df[[\"revenue\", \"Keywords\"]].values:\n    if type(element[1]) == type(str()):\n        \n        result = re.findall('name\\': \\'\\w+\\s*\\w*', element[1])\n        result = [x.replace(\"name\\': \\'\", \"\") for x in result]\n\n        for key in result:\n            if key not in keywords_dict:\n                keywords_dict[key] = element[0]\n            else:\n                keywords_dict[key] += element[0]\n                \nfor key in keywords_dict:\n    keywords_dict[key] = keywords_dict[key]\/size_of_keywords\n    \nkeywords_df = pd.DataFrame.from_dict(keywords_dict, orient='index', columns=[\"mean_movies_revenue\"])\nkeywords_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).plot.bar()","7b139f64":"def find_top_keywords_from_cast(top_keyword, element):\n    \n    result = []\n    if type(element) == type(str()):\n\n        result = re.findall('name\\': \\'\\w+\\s*\\w*', element)\n        result = [x.replace(\"name\\': \\'\", \"\") for x in result]\n        \n    if top_keyword in result:\n        return 1\n    else:\n        return 0\n\nfor top_keyword in keywords_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).index.values:\n    train_df[\"has_top_keyword_\"+ top_keyword] = train_df.Keywords.apply(lambda element: find_top_keywords_from_cast(top_keyword, element))\n    test_df[\"has_top_keyword_\"+ top_keyword] = test_df.Keywords.apply(lambda element: find_top_keywords_from_cast(top_keyword, element))","37d80151":"train_df[\"num_of_cast\"] = train_df[\"cast\"].str.count(\"name\")\ntest_df[\"num_of_cast\"] = test_df[\"cast\"].str.count(\"name\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_cast = train_df.num_of_cast.fillna(0)\ntest_df.num_of_cast = test_df.num_of_cast.fillna(0)\n\nsns.boxplot(x=train_df.num_of_cast, ax = ax[0])\nax[0].set_title(\"num_of_cast Boxplot\")\nsns.distplot(a=train_df.num_of_cast, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_cast Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_cast), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_cast Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_cast\"] = np.log1p(train_df.num_of_cast)\ntest_df[\"log_num_of_cast\"] = np.log1p(test_df.num_of_cast)","e60a12d9":"train_df[\"num_of_male_cast\"] = train_df[\"cast\"].str.count(\"'gender': 2\")\ntest_df[\"num_of_male_cast\"] = test_df[\"cast\"].str.count(\"'gender': 2\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_male_cast = train_df.num_of_male_cast.fillna(0)\ntest_df.num_of_male_cast = test_df.num_of_male_cast.fillna(0)\n\nsns.boxplot(x=train_df.num_of_male_cast, ax = ax[0])\nax[0].set_title(\"num_of_male_cast Boxplot\")\nsns.distplot(a=train_df.num_of_male_cast, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_male_cast Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_male_cast), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_male_cast Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_male_cast\"] = np.log1p(train_df.num_of_male_cast)\ntest_df[\"log_num_of_male_cast\"] = np.log1p(test_df.num_of_male_cast)","cf3cd37a":"train_df[\"num_of_female_cast\"] = train_df[\"cast\"].str.count(\"'gender': 1\")\ntest_df[\"num_of_female_cast\"] = test_df[\"cast\"].str.count(\"'gender': 1\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_female_cast = train_df.num_of_female_cast.fillna(0)\ntest_df.num_of_female_cast = test_df.num_of_female_cast.fillna(0)\n\nsns.boxplot(x=train_df.num_of_female_cast, ax = ax[0])\nax[0].set_title(\"num_of_female_cast Boxplot\")\nsns.distplot(a=train_df.num_of_female_cast, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_female_cast Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_female_cast), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_female_cast Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_female_cast\"] = np.log1p(train_df.num_of_female_cast)\ntest_df[\"log_num_of_female_cast\"] = np.log1p(test_df.num_of_female_cast)","35e1ae9d":"train_df[\"num_of_crew\"] = train_df[\"crew\"].str.count(\"'job\")\ntest_df[\"num_of_crew\"] = test_df[\"crew\"].str.count(\"'job\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_crew = train_df.num_of_crew.fillna(0)\ntest_df.num_of_crew = test_df.num_of_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_crew, ax = ax[0])\nax[0].set_title(\"num_of_crew Boxplot\")\nsns.distplot(a=train_df.num_of_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_crew\"] = np.log1p(train_df.num_of_crew)\ntest_df[\"log_num_of_crew\"] = np.log1p(test_df.num_of_crew)","09c8d9be":"train_df[\"num_of_male_crew\"] = train_df[\"crew\"].str.count(\"'gender': 2\")\ntest_df[\"num_of_male_crew\"] = test_df[\"crew\"].str.count(\"'gender': 2\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_male_crew = train_df.num_of_male_crew.fillna(0)\ntest_df.num_of_male_crew = test_df.num_of_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_male_crew, ax = ax[0])\nax[0].set_title(\"num_of_male_crew Boxplot\")\nsns.distplot(a=train_df.num_of_male_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_male_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_male_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_male_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_male_crew\"] = np.log1p(train_df.num_of_male_crew)\ntest_df[\"log_num_of_male_crew\"] = np.log1p(test_df.num_of_male_crew)","0339932f":"train_df[\"num_of_female_crew\"] = train_df[\"crew\"].str.count(\"'gender': 1\")\ntest_df[\"num_of_female_crew\"] = test_df[\"crew\"].str.count(\"'gender': 1\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_female_crew = train_df.num_of_female_crew.fillna(0)\ntest_df.num_of_female_crew = test_df.num_of_female_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_female_crew, ax = ax[0])\nax[0].set_title(\"num_of_female_crew Boxplot\")\nsns.distplot(a=train_df.num_of_female_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_female_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_female_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_female_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_female_crew\"] = np.log1p(train_df.num_of_female_crew)\ntest_df[\"log_num_of_female_crew\"] = np.log1p(test_df.num_of_female_crew)","16c254de":"import re\n\ndirectors_dict = {}\nsize_of_crew = len(train_df) - train_df.crew.isna().sum()\n\nfor element in train_df[[\"revenue\", \"crew\"]].values:\n    if type(element[1]) == type(str()):\n        \n        result = re.findall('Director\\', \\'name\\': \\'\\w+\\s*\\w*', element[1])\n        result = [x.replace(\"Director\\', \\'name\\': \\'\", \"\") for x in result]\n\n        for key in result:\n            if key not in directors_dict:\n                directors_dict[key] = element[0]\n            else:\n                directors_dict[key] += element[0]\n                \nfor key in directors_dict:\n    directors_dict[key] = directors_dict[key]\/size_of_crew\n    \ndirectors_df = pd.DataFrame.from_dict(directors_dict, orient='index', columns=[\"mean_movies_revenue\"])\ndirectors_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).plot.bar()","60610296":"def find_top_directors_from_crew(top_director, element):\n    \n    result = []\n    if type(element) == type(str()):\n\n        result = re.findall('Director\\', \\'name\\': \\'\\w+\\s*\\w*', element)\n        result = [x.replace(\"Director\\', \\'name\\': \\'\", \"\") for x in result]\n        \n    if top_director in result:\n        return 1\n    else:\n        return 0\n\nfor top_director in directors_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).index.values:\n    train_df[\"has_top_director_\"+ top_director] = train_df.crew.apply(lambda element: find_top_directors_from_crew(top_director, element))\n    test_df[\"has_top_director_\"+ top_director] = test_df.crew.apply(lambda element: find_top_directors_from_crew(top_director, element))","e98ebd23":"import re\n\nproducers_dict = {}\nsize_of_crew = len(train_df) - train_df.crew.isna().sum()\n\nfor element in train_df[[\"revenue\", \"crew\"]].values:\n    if type(element[1]) == type(str()):\n        \n        result = re.findall('Producer\\', \\'name\\': \\'\\w+\\s*\\w*', element[1])\n        result = [x.replace(\"Producer\\', \\'name\\': \\'\", \"\") for x in result]\n\n        for key in result:\n            if key not in producers_dict:\n                producers_dict[key] = element[0]\n            else:\n                producers_dict[key] += element[0]\n                \nfor key in producers_dict:\n    producers_dict[key] = producers_dict[key]\/size_of_crew\n    \nproducers_df = pd.DataFrame.from_dict(producers_dict, orient='index', columns=[\"mean_movies_revenue\"])\nproducers_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).plot.bar()","7456c0c5":"def find_top_producers_from_crew(top_producer, element):\n    \n    result = []\n    if type(element) == type(str()):\n\n        result = re.findall('Director\\', \\'name\\': \\'\\w+\\s*\\w*', element)\n        result = [x.replace(\"Director\\', \\'name\\': \\'\", \"\") for x in result]\n        \n    if top_producer in result:\n        return 1\n    else:\n        return 0\n\nfor top_producer in producers_df.sort_values(by=\"mean_movies_revenue\", ascending=False).head(10).index.values:\n    train_df[\"has_top_producer_\"+ top_producer] = train_df.crew.apply(lambda element: find_top_producers_from_crew(top_producer, element))\n    test_df[\"has_top_producer_\"+ top_producer] = test_df.crew.apply(lambda element: find_top_producers_from_crew(top_producer, element))","6eeb72ee":"train_df[\"num_of_directors\"] = train_df[\"crew\"].str.count(\"Directing\")\ntest_df[\"num_of_directors\"] = test_df[\"crew\"].str.count(\"Directing\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_directors = train_df.num_of_directors.fillna(0)\ntest_df.num_of_directors = test_df.num_of_directors.fillna(0)\n\nsns.boxplot(x=train_df.num_of_directors, ax = ax[0])\nax[0].set_title(\"num_of_directors Boxplot\")\nsns.distplot(a=train_df.num_of_directors, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_directors Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_directors), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_directors Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_directors\"] = np.log1p(train_df.num_of_directors)\ntest_df[\"log_num_of_directors\"] = np.log1p(test_df.num_of_directors)","637093a4":"train_df[\"num_of_producers\"] = train_df[\"crew\"].str.count(\"Production\")\ntest_df[\"num_of_producers\"] = test_df[\"crew\"].str.count(\"Production\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_producers = train_df.num_of_producers.fillna(0)\ntest_df.num_of_producers = test_df.num_of_producers.fillna(0)\n\nsns.boxplot(x=train_df.num_of_producers, ax = ax[0])\nax[0].set_title(\"num_of_producers Boxplot\")\nsns.distplot(a=train_df.num_of_producers, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_producers Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_producers), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_producers Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_producers\"] = np.log1p(train_df.num_of_producers)\ntest_df[\"log_num_of_producers\"] = np.log1p(test_df.num_of_producers)","0ba90ad1":"train_df[\"num_of_writers\"] = train_df[\"crew\"].str.count(\"Writing\")\ntest_df[\"num_of_writers\"] = test_df[\"crew\"].str.count(\"Writing\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_writers = train_df.num_of_writers.fillna(0)\ntest_df.num_of_writers = test_df.num_of_writers.fillna(0)\n\nsns.boxplot(x=train_df.num_of_writers, ax = ax[0])\nax[0].set_title(\"num_of_writers Boxplot\")\nsns.distplot(a=train_df.num_of_writers, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_writers Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_writers), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_writers Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_writers\"] = np.log1p(train_df.num_of_writers)\ntest_df[\"log_num_of_writers\"] = np.log1p(test_df.num_of_writers)","ad8aae98":"train_df[\"num_of_editors\"] = train_df[\"crew\"].str.count(\"Editing\")\ntest_df[\"num_of_editors\"] = test_df[\"crew\"].str.count(\"Editing\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_editors = train_df.num_of_editors.fillna(0)\ntest_df.num_of_editors = test_df.num_of_editors.fillna(0)\n\nsns.boxplot(x=train_df.num_of_editors, ax = ax[0])\nax[0].set_title(\"num_of_editors Boxplot\")\nsns.distplot(a=train_df.num_of_editors, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_editors Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_editors), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_editors Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_editors\"] = np.log1p(train_df.num_of_editors)\ntest_df[\"log_num_of_editors\"] = np.log1p(test_df.num_of_editors)","49aeb545":"train_df[\"num_of_art_crew\"] = train_df[\"crew\"].str.count(\"Art\")\ntest_df[\"num_of_art_crew\"] = test_df[\"crew\"].str.count(\"Art\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_art_crew = train_df.num_of_art_crew.fillna(0)\ntest_df.num_of_art_crew = test_df.num_of_art_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_art_crew, ax = ax[0])\nax[0].set_title(\"num_of_art_crew Boxplot\")\nsns.distplot(a=train_df.num_of_art_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_art_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_art_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_art_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_art_crew\"] = np.log1p(train_df.num_of_art_crew)\ntest_df[\"log_num_of_art_crew\"] = np.log1p(test_df.num_of_art_crew)","d17492a3":"train_df[\"num_of_sound_crew\"] = train_df[\"crew\"].str.count(\"Sound\")\ntest_df[\"num_of_sound_crew\"] = test_df[\"crew\"].str.count(\"Sound\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_sound_crew = train_df.num_of_sound_crew.fillna(0)\ntest_df.num_of_sound_crew = test_df.num_of_sound_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_sound_crew, ax = ax[0])\nax[0].set_title(\"num_of_sound_crew Boxplot\")\nsns.distplot(a=train_df.num_of_sound_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_sound_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_sound_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_sound_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_sound_crew\"] = np.log1p(train_df.num_of_sound_crew)\ntest_df[\"log_num_of_sound_crew\"] = np.log1p(test_df.num_of_sound_crew)","d41a9234":"train_df[\"num_of_costume_crew\"] = train_df[\"crew\"].str.count(\"Costume & Make-Up\")\ntest_df[\"num_of_costume_crew\"] = test_df[\"crew\"].str.count(\"Costume & Make-Up\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_costume_crew = train_df.num_of_costume_crew.fillna(0)\ntest_df.num_of_costume_crew = test_df.num_of_costume_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_costume_crew, ax = ax[0])\nax[0].set_title(\"num_of_costume_crew Boxplot\")\nsns.distplot(a=train_df.num_of_costume_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_costume_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_costume_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_costume_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_costume_crew\"] = np.log1p(train_df.num_of_costume_crew)\ntest_df[\"log_num_of_costume_crew\"] = np.log1p(test_df.num_of_costume_crew)","94da1c2e":"train_df[\"num_of_camera_crew\"] = train_df[\"crew\"].str.count(\"\\'department\\': \\'Camera\\'\")\ntest_df[\"num_of_camera_crew\"] = test_df[\"crew\"].str.count(\"\\'department\\': \\'Camera\\'\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_camera_crew = train_df.num_of_camera_crew.fillna(0)\ntest_df.num_of_camera_crew = test_df.num_of_camera_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_camera_crew, ax = ax[0])\nax[0].set_title(\"num_of_camera_crew Boxplot\")\nsns.distplot(a=train_df.num_of_camera_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_camera_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_camera_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_camera_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_camera_crew\"] = np.log1p(train_df.num_of_camera_crew)\ntest_df[\"log_num_of_camera_crew\"] = np.log1p(test_df.num_of_camera_crew)","a0ace0a5":"train_df[\"num_of_visual_effects_crew\"] = train_df[\"crew\"].str.count(\"\\'department\\': \\'Visual Effects\\'\")\ntest_df[\"num_of_visual_effects_crew\"] = test_df[\"crew\"].str.count(\"\\'department\\': \\'Visual Effects\\'\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_visual_effects_crew = train_df.num_of_visual_effects_crew.fillna(0)\ntest_df.num_of_visual_effects_crew = test_df.num_of_visual_effects_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_visual_effects_crew, ax = ax[0])\nax[0].set_title(\"num_of_visual_effects_crew Boxplot\")\nsns.distplot(a=train_df.num_of_visual_effects_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_visual_effects_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_visual_effects_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_visual_effects_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_visual_effects_crew\"] = np.log1p(train_df.num_of_visual_effects_crew)\ntest_df[\"log_num_of_visual_effects_crew\"] = np.log1p(test_df.num_of_visual_effects_crew)","dfe6d915":"train_df[\"num_of_lighting_crew\"] = train_df[\"crew\"].str.count(\"\\'department\\': \\'Lighting\\'\")\ntest_df[\"num_of_lighting_crew\"] = test_df[\"crew\"].str.count(\"\\'department\\': \\'Lighting\\'\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_lighting_crew = train_df.num_of_lighting_crew.fillna(0)\ntest_df.num_of_lighting_crew = test_df.num_of_lighting_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_lighting_crew, ax = ax[0])\nax[0].set_title(\"num_of_lighting_crew Boxplot\")\nsns.distplot(a=train_df.num_of_lighting_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_lighting_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_lighting_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_lighting_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_lighting_crew\"] = np.log1p(train_df.num_of_lighting_crew)\ntest_df[\"log_num_of_lighting_crew\"] = np.log1p(test_df.num_of_lighting_crew)","3eebf4d2":"train_df[\"num_of_other_crew\"] = train_df[\"crew\"].str.count(\"\\'department\\': \\'Crew\\'\")\ntest_df[\"num_of_other_crew\"] = test_df[\"crew\"].str.count(\"\\'department\\': \\'Crew\\'\")\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_other_crew = train_df.num_of_other_crew.fillna(0)\ntest_df.num_of_other_crew = test_df.num_of_other_crew.fillna(0)\n\nsns.boxplot(x=train_df.num_of_other_crew, ax = ax[0])\nax[0].set_title(\"num_of_other_crew Boxplot\")\nsns.distplot(a=train_df.num_of_other_crew, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_other_crew Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_other_crew), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_other_crew Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_other_crew\"] = np.log1p(train_df.num_of_other_crew)\ntest_df[\"log_num_of_other_crew\"] = np.log1p(test_df.num_of_other_crew)","cff26b73":"train_df[\"num_of_production_countries\"] = train_df.production_countries_processed.apply(len)\ntest_df[\"num_of_production_countries\"] = test_df.production_countries_processed.apply(len)\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_production_countries = train_df.num_of_production_countries.fillna(0)\ntest_df.num_of_production_countries = test_df.num_of_production_countries.fillna(0)\n\nsns.boxplot(x=train_df.num_of_production_countries, ax = ax[0])\nax[0].set_title(\"num_of_production_countries Boxplot\")\nsns.distplot(a=train_df.num_of_production_countries, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_production_countries Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_production_countries), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_production_countries Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_production_countries\"] = np.log1p(train_df.num_of_production_countries)\ntest_df[\"log_num_of_production_countries\"] = np.log1p(test_df.num_of_production_countries)","6ad01164":"train_df[\"num_of_genres\"] = train_df.genres_processed.apply(len)\ntest_df[\"num_of_genres\"] = test_df.genres_processed.apply(len)\n\nf, ax = plt.subplots(3, figsize=(12,7))\n\ntrain_df.num_of_genres = train_df.num_of_genres.fillna(0)\ntest_df.num_of_genres = test_df.num_of_genres.fillna(0)\n\nsns.boxplot(x=train_df.num_of_genres, ax = ax[0])\nax[0].set_title(\"num_of_genres Boxplot\")\nsns.distplot(a=train_df.num_of_genres, kde = False, ax = ax[1])\nax[1].set_title(\"num_of_genres Histogram\")\nsns.distplot(a=np.log1p(train_df.num_of_genres), kde = False, ax = ax[2])\nax[2].set_title(\"Log1p transformed num_of_genres Histogram\")\nf.tight_layout()\n\n\ntrain_df[\"log_num_of_genres\"] = np.log1p(train_df.num_of_genres)\ntest_df[\"log_num_of_genres\"] = np.log1p(test_df.num_of_genres)","89c38407":"sns.set(rc={'figure.figsize':(20,27)})\n\n# Compute the correlation matrix\ncorr = train_df[[\"revenue\", \"budget\", \"popularity\", \"runtime\", \"num_of_cast\", \"num_of_male_cast\",\n                 \"num_of_female_cast\",\n                 \"num_genres\", \"num_of_production_countries\", \"day_of_week\", \"month\", \"year\", \"week_of_year\", \"season\",\n                 \"title_len\", \"overview_len\", \"tagline_len\",\n                 \"num_of_directors\", \"num_of_producers\", \"num_of_editors\", \"num_of_art_crew\", \"num_of_sound_crew\",\n                 \"num_of_costume_crew\", \"num_of_camera_crew\", \"num_of_visual_effects_crew\", \"num_of_lighting_crew\",\n                 \"num_of_other_crew\"]].corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask=mask, \n            annot=True, \n            fmt=\".2f\", \n            cmap='coolwarm')\n\nplt.title(\"Correlation between numerical features\")","ddf44c74":"sns.set(rc={'figure.figsize':(18,20)})\n\n# Compute the correlation matrix\ncorr = train_df[[\"log_revenue\", \"log_budget\", \"log_popularity\", \"log_runtime\",\n                 \"log_num_of_cast\", \"log_num_of_male_cast\",\n                 \"log_num_of_female_cast\", \"num_genres\", \"num_of_production_countries\",\n                \"day_of_week\", \"month\", \"year\", \"week_of_year\", \"season\",\n                \"log_title_len\", \"log_overview_len\", \"log_tagline_len\",\n                \"log_num_of_directors\", \"log_num_of_producers\", \"log_num_of_editors\", \"log_num_of_art_crew\", \"log_num_of_sound_crew\",\n                       \"log_num_of_costume_crew\", \"log_num_of_camera_crew\", \"log_num_of_visual_effects_crew\", \"log_num_of_lighting_crew\",\n                        \"log_num_of_other_crew\"]].corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask=mask, \n            annot=True, \n            fmt=\".2f\", \n            cmap='coolwarm')\n\nplt.title(\"Correlation between log1p transformed numerical features\")","476c88cc":"train_df['has_collection'] = [0 if pd.isnull(x) else 1 for x in train_df['belongs_to_collection']]\ntest_df['has_collection'] = [0 if pd.isnull(x) else 1 for x in test_df['belongs_to_collection']]\nprint(train_df['has_collection'].value_counts())\n\nsns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='has_collection', y='revenue', data=train_df)\nplt.title('Revenue for film with and without being in a collection')","45bd6674":"train_df['has_homepage'] = [0 if pd.isnull(x) else 1 for x in train_df['homepage']]\ntest_df['has_homepage'] = [0 if pd.isnull(x) else 1 for x in test_df['homepage']]\nprint(train_df['has_homepage'].value_counts())\n\nsns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='has_homepage', y='revenue', data=train_df)\nplt.title('Revenue for film with and without homepage')","a5dbdc64":"train_df['has_tag'] = [0 if len(x) == 0 else 1 for x in train_df['tagline']]\ntest_df['has_tag'] = [0 if len(x) == 0 else 1 for x in test_df['tagline']]\nprint(train_df['has_tag'].value_counts())\n\nsns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='has_tag', y='revenue', data=train_df)\nplt.title('Revenue for film with and without tagline')","ed95ef91":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='num_of_genres', y='revenue', data=train_df)\nplt.title('Revenues for films with multiple genres')","8004b7f8":"for i, g in enumerate(genres_df.index.values):\n    genres_df.loc[g, \"median_salary\"] = train_df[train_df['isGenre_' + g]==1].revenue.median()\n\ngenres_df.sort_values(by=[\"number_of_movies\", \"median_salary\"], ascending=False).head(10)","157469ca":"genres_df.sort_values(by=[\"median_salary\"], ascending=False).median_salary.plot.bar()\nplt.title(\"Sorted movie genres by median revenue\")","023963e9":"for i, p in enumerate(genres_df.sort_values(by=[\"number_of_movies\", \"median_salary\"], ascending=False).head(10).index.values):\n    train_df['isTopGenre_' + p] = train_df['genres_processed'].apply(lambda x: 1 if p in x else 0)\n    train_df['isTopGenre_Other'] = train_df['genres_processed'].apply(lambda x: 1 if p not in x else 0)\n    test_df['isTopGenre_' + p] = test_df['genres_processed'].apply(lambda x: 1 if p in x else 0)\n    test_df['isTopGenre_Other'] = test_df['genres_processed'].apply(lambda x: 1 if p not in x else 0)","dcd3a4bb":"f, ax = plt.subplots(len(genres_df.index.values), 1, figsize=(15,160))\n\nfor i, g in enumerate(genres_df.index.values):\n    sns.boxplot(x=train_df['isGenre_' + g], y='revenue', ax=ax[i], data=train_df)\n    ax[i].set_title('isGenre_' + g +\" and revenue boxplot\")\nf.tight_layout()","15d602d4":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='original_language', y='revenue', data=train_df)\nplt.title('Revenue for a movie and its and original_language')","a1cc275c":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='is_english_language', y='revenue', data=train_df)\nplt.title('Revenue for a movie in contrast with english and non-english language')","8f3a2e6c":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='num_of_production_countries', y='revenue', data=train_df)\nplt.title('number of production countries for a movie and revenue')","743fc356":"f, ax = plt.subplots(len(production_countries_df.index.values), 1, figsize=(15,350))\n\nfor i, c in enumerate(production_countries_df.index.values):\n    sns.boxplot(x=train_df['isProductionCountry_' + c], y='revenue', ax=ax[i], data=train_df)\n    ax[i].set_title('isProductionCountry_' + c +\" and revenue boxplot\")\nf.tight_layout()","782a9de6":"for i, c in enumerate(production_countries_df.index.values):\n    production_countries_df.loc[c, \"median_salary\"] = train_df[train_df['isProductionCountry_' + c]==1].revenue.median()\n\nproduction_countries_df.sort_values(by=[\"number_of_movies\", \"median_salary\"], ascending=False).head(10)","95370e8a":"for i, p in enumerate(production_countries_df.sort_values(by=[\"number_of_movies\", \"median_salary\"], ascending=False).head(10).index.values):\n    train_df['isTopProductionCountry_' + p] = train_df['production_countries_processed'].apply(lambda x: 1 if p in x else 0)\n    test_df['isTopProductionCountry_' + p] = test_df['production_countries_processed'].apply(lambda x: 1 if p in x else 0)","2e58841e":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='day_of_week', y='revenue', data=train_df)\nplt.title('day_of_week when the movie release and revenue')","7a401dca":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='week_of_year', y='revenue', data=train_df)\nplt.title('day_of_week when the movie release and revenue')","05c50afc":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='month', y='revenue', data=train_df)\nplt.title('month when the movie release and revenue')","556efd98":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='season', y='revenue', data=train_df)\nplt.title('season when the movie release and revenue')","090788c6":"sns.set(rc={'figure.figsize':(20, 8)})\ng = sns.boxplot(x='year', y='revenue', data=train_df)\nplt.xticks(rotation=90)\nplt.title('Year when the movie release and revenue')","08e07c2e":"sns.set(rc={'figure.figsize':(12, 8)})\nsns.boxplot(x='num_of_production_companies', y='revenue', data=train_df)\nplt.title('number of production companies for a movie and revenue')","b10bf2c5":"f, ax = plt.subplots(len(production_companies_df.head(5).index.values), 1, figsize=(15,20))\n\nfor i, p in enumerate(production_companies_df.head(5).index.values):\n    sns.boxplot(x=train_df['isProductionCompany_' + p], y='revenue', ax=ax[i], data=train_df)\n    ax[i].set_title('isProductionCompany_' + p +\" and revenue boxplot\")\nf.tight_layout()","5af0f300":"for i, p in enumerate(production_companies_df.index.values):\n    production_companies_df.loc[p, \"median_salary\"] = train_df[train_df['isProductionCompany_' + p]==1].revenue.median()\n\nproduction_companies_df.sort_values(by=[\"number_of_movies\", \"median_salary\"], ascending=False).head(5)","c439db2f":"for i, p in enumerate(production_companies_df.sort_values(by=[\"number_of_movies\", \"median_salary\"], ascending=False).head(10).index.values):\n    train_df['isTopProductionCompany_' + p] = train_df['production_companies_processed'].apply(lambda x: 1 if p in x else 0)\n    #train_df['isTopProductionCompany_Other'] = train_df['production_companies_processed'].apply(lambda x: 1 if p not in x else 0)\n    test_df['isTopProductionCompany_' + p] = test_df['production_companies_processed'].apply(lambda x: 1 if p in x else 0)\n    #test_df['isTopProductionCompany_Other'] = test_df['production_companies_processed'].apply(lambda x: 1 if p not in x else 0)","0b242ad6":"train_df.columns","5797293b":"columns_for_training = [\"log_budget\", \"log_popularity\", \"log_runtime\", \"day_of_week\", \"year\", \"month\", \"week_of_year\", \"season\",\n                        \"num_genres\", \"num_of_production_countries\", \"log_num_of_cast\", \"log_num_of_male_cast\", \"log_num_of_female_cast\", \"has_collection\", \n                        \"has_homepage\", \"has_tag\", \"is_english_language\",\n                       \"log_num_of_crew\", \"log_num_of_male_crew\", \"log_num_of_female_crew\",\n                       \"log_title_len\", \"log_overview_len\", \"log_tagline_len\",\n                       \"log_num_of_directors\", \"log_num_of_producers\", \"log_num_of_editors\", \"log_num_of_art_crew\", \"log_num_of_sound_crew\",\n                       \"log_num_of_costume_crew\", \"log_num_of_camera_crew\", \"log_num_of_visual_effects_crew\", \"log_num_of_lighting_crew\",\n                        \"log_num_of_other_crew\"]\n\n\n# adding isTopGenre_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('isTopGenre_'), axis=1).columns.values)\n\n# adding isTopProductionCompany_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('isTopProductionCompany_'), axis=1).columns.values)\n\n# adding isTopProductionCountry_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('isTopProductionCountry_'), axis=1).columns.values)\n\n# adding has_top_actor_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('has_top_actor_'), axis=1).columns.values)\n\n# adding has_top_keyword_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('has_top_keyword_'), axis=1).columns.values)\n\n# adding has_top_director_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('has_top_director_'), axis=1).columns.values)\n\n# adding has_top_producer_ columns for features before ML modeling\ncolumns_for_training.extend(train_df.select(lambda col: col.startswith('has_top_producer_'), axis=1).columns.values)\n\ncolumns_for_training","f76cceea":"train_df[columns_for_training].head(4)","17cd63b9":"train_df[columns_for_training].isna().sum().sum()","d29635fc":"len(columns_for_training)","31cee6f4":"### a small snippet code for t-test significance between 2 groups, I may use it in the future:\n\n\n#from scipy import stats\n\n#columns_to_test = train_df.select(lambda col: col.startswith('isProductionCompany_'), axis=1).columns.values\n\n#def check_catagorical_to_revenue_statistical_difference(train_df):\n    \n#    for col in columns_to_test:\n\n#        a = train_df[train_df[col]==0].revenue\n#        b = train_df[train_df[col]==1].revenue\n#        t2, p2 = stats.ttest_ind(a,b)\n#        if p2<0.05:\n#            print(col , \" is important for prediction with p-value:\", p2)\n        \n#check_catagorical_to_revenue_statistical_difference(train_df)\n    ","5a32ff51":"y = train_df['log_revenue']\nX = train_df[columns_for_training]\nkfold_splits = 5","4644e184":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport scikitplot as skplt\nimport time\nimport random\n\nimport xgboost as xgb\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\n\npredictions_test_xgb = np.zeros(len(test_df))\nnum_fold = 0\nnum_of_splits = kfold_splits\noof_rmse = 0\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n\n    clf_stra_xgb = xgb.XGBRegressor(n_estimators=10000, seed=42, nthread=-1)\n\n    clf_stra_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                early_stopping_rounds=1000, eval_metric='rmse', verbose=100)\n\n    predictions_valid = clf_stra_xgb.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    \n    print(\"Fold\",num_fold,\"xvalid rmse:\",rmse_valid)\n    num_fold = num_fold + 1\n    \n    oof_rmse += rmse_valid\n\n    predictions_test_xgb += clf_stra_xgb.predict(test_df[xtrain.columns])\/num_of_splits\n\n\npredictions_test_xgb = np.expm1(predictions_test_xgb)\nprint()\nprint(predictions_test_xgb)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\n\nsns.set(rc={'figure.figsize':(9,86)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_xgb, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\nxgb.plot_importance(clf_stra_xgb)","06c295d4":"def bayesian_tuning(xtrain, ytrain):\n    \n    from skopt import BayesSearchCV\n    import xgboost as xgb\n    \n    \n    # Classifier\n    bayes_cv_tuner = BayesSearchCV(\n        estimator = xgb.XGBRegressor(\n            nthread = -1,\n            objective = 'reg:linear',\n            verbosity=1,\n            random_state=42\n        ),\n        search_spaces = {\n            'learning_rate': (0.01, 1.0, 'log-uniform'),\n            'min_child_weight': (0, 10),\n            'n_estimators': (50, 300),\n            'max_depth': (2, 12),\n            'gamma': (1e-3, 1, 'log-uniform'),\n            'subsample': (0.01, 1.0, 'uniform'),\n            'colsample_bytree': (0.01, 1.0, 'uniform'),\n            'colsample_bylevel': (0.01, 1.0, 'uniform'),\n            'reg_lambda': (1e-1, 10, 'log-uniform'),\n            'reg_alpha': (1e-2, 1.0, 'log-uniform')\n        },\n        cv = KFold(\n            n_splits=kfold_splits,\n            shuffle=True,\n            random_state=42\n        ),\n        scoring = 'neg_mean_squared_error',\n        n_jobs = 2,\n        n_iter = 12,\n        verbose=0,\n        refit = True,\n        random_state = 42\n    )\n\n    def status_print(optim_result):\n        \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n\n        # Get all the models tested so far in DataFrame format\n        all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n\n        # Get current parameters and the best parameters    \n        best_params = pd.Series(bayes_cv_tuner.best_params_)\n        print('Model #{}\\nBest score: {}\\nBest params: {}\\n'.format(\n            len(all_models),\n            np.round(bayes_cv_tuner.best_score_, 4),\n            bayes_cv_tuner.best_params_\n        ))\n        \n    result = bayes_cv_tuner.fit(xtrain, ytrain, callback = status_print)\n    return result\n    \n# Fit the model\n#xtrain, ytrain = prepare_for_tuning(X, y, type_of_training=type_of_training)\nresult = bayesian_tuning(xtrain, ytrain)","629de4d0":"result.best_params_","13dd7423":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport xgboost as xgb\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_test_xgb_tuned = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    clf_stra_tuned_xgb = xgb.XGBRegressor(colsample_bytree = result.best_params_[\"colsample_bytree\"],\n                                          colsample_bylevel = result.best_params_[\"colsample_bylevel\"],\n                                    gamma=result.best_params_[\"gamma\"],                 \n                                    learning_rate=result.best_params_[\"learning_rate\"],\n                                    max_depth=result.best_params_[\"max_depth\"],\n                                    min_child_weight=result.best_params_[\"min_child_weight\"],\n                                    n_estimators=10000,\n                                    reg_alpha=result.best_params_[\"reg_alpha\"],\n                                    reg_lambda=result.best_params_[\"reg_lambda\"],\n                                    subsample=result.best_params_[\"subsample\"],\n                                    seed=42,\n                                    nthread = -1)\n\n    clf_stra_tuned_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                early_stopping_rounds=1000, eval_metric='rmse', verbose=100)\n\n    predictions_valid = clf_stra_tuned_xgb.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\",num_fold,\"xvalid rmse:\",rmse_valid)\n    num_fold = num_fold + 1\n    \n    oof_rmse += rmse_valid\n\n    predictions_test_xgb_tuned += clf_stra_tuned_xgb.predict(test_df[xtrain.columns])\/num_of_splits\n    \nprint()\npredictions_test_xgb_tuned = np.expm1(predictions_test_xgb_tuned)\nprint(predictions_test_xgb_tuned)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\n\nsns.set(rc={'figure.figsize':(9,86)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_xgb_tuned, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\nxgb.plot_importance(clf_stra_tuned_xgb)","80b34e3c":"from sklearn.ensemble import ExtraTreesRegressor\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport scikitplot as skplt\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_extra_trees_test = np.zeros(len(test_df))\nnum_fold = 0\nnum_of_splits = kfold_splits\noof_rmse = 0\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n\n    clf_extra_trees = ExtraTreesRegressor(n_estimators=100, random_state=42)\n\n    clf_extra_trees.fit(xtrain_stra, ytrain_stra)\n\n    predictions_valid = clf_extra_trees.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    oof_rmse += rmse_valid\n\n    predictions_extra_trees_test += clf_extra_trees.predict(test_df[xtrain.columns])\/num_of_splits\n\n\npredictions_extra_trees_test = np.expm1(predictions_extra_trees_test)\nprint()\nprint(predictions_extra_trees_test)\nprint()\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_extra_trees_test, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()","aea6bfd3":"def bayesian_tuning_extra_trees(xtrain, ytrain):\n    \n    from skopt import BayesSearchCV\n    from sklearn.ensemble import ExtraTreesRegressor\n    \n    \n    # Classifier\n    bayes_cv_tuner = BayesSearchCV(\n        estimator = ExtraTreesRegressor(\n            random_state=42\n        ),\n        search_spaces = {\n            'n_estimators': (10, 500),\n            'max_depth': (1, 12),\n            'min_samples_split': (2, 20),\n            'min_samples_leaf': (1, 20)\n        },\n        cv = KFold(\n            n_splits=kfold_splits,\n            shuffle=True,\n            random_state=42\n        ),\n        scoring = 'neg_mean_squared_error',\n        n_jobs = 2,\n        n_iter = 12,   \n        verbose = 0,\n        refit = True,\n        random_state = 42\n    )\n\n    def status_print(optim_result):\n        \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n\n        # Get all the models tested so far in DataFrame format\n        all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n\n        # Get current parameters and the best parameters    \n        best_params = pd.Series(bayes_cv_tuner.best_params_)\n        print('Model #{}\\nBest score: {}\\nBest params: {}\\n'.format(\n            len(all_models),\n            np.round(bayes_cv_tuner.best_score_, 4),\n            bayes_cv_tuner.best_params_\n        ))\n        \n    result_extra_trees = bayes_cv_tuner.fit(xtrain, ytrain, callback = status_print)\n    return result_extra_trees\n    \n# Fit the model\n#xtrain, ytrain = prepare_for_tuning(X, y, type_of_training=type_of_training)\nresult_extra_trees = bayesian_tuning_extra_trees(xtrain, ytrain)","f894bf24":"result_extra_trees.best_params_","1da3f8ca":"from sklearn.ensemble import ExtraTreesRegressor\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport scikitplot as skplt\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_extra_trees_tuned_test = np.zeros(len(test_df))\nnum_fold = 0\nnum_of_splits = kfold_splits\noof_rmse = 0\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n\n    clf_extra_trees_tuned = ExtraTreesRegressor(random_state=42, \n                                                max_depth = result_extra_trees.best_params_['max_depth'], \n                                                min_samples_leaf = result_extra_trees.best_params_['min_samples_leaf'], \n                                                min_samples_split = result_extra_trees.best_params_['min_samples_split'], \n                                                n_estimators = result_extra_trees.best_params_['n_estimators'])\n\n    clf_extra_trees_tuned.fit(xtrain_stra, ytrain_stra)\n\n    predictions_valid = clf_extra_trees_tuned.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    oof_rmse += rmse_valid\n\n    predictions_extra_trees_tuned_test += clf_extra_trees_tuned.predict(test_df[xtrain.columns])\/num_of_splits\n\n\npredictions_extra_trees_tuned_test = np.expm1(predictions_extra_trees_tuned_test)\nprint()\nprint(predictions_extra_trees_tuned_test)\nprint()\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_extra_trees_tuned_test, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()","9a8f8134":"from sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport scikitplot as skplt\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_random_forest_test = np.zeros(len(test_df))\nnum_fold = 0\nnum_of_splits = kfold_splits\noof_rmse = 0\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    clf_random_forest = RandomForestRegressor(random_state=42, n_estimators = 100)\n\n    clf_random_forest.fit(xtrain_stra, ytrain_stra)\n\n    predictions_valid = clf_random_forest.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    oof_rmse += rmse_valid\n\n    predictions_random_forest_test += clf_random_forest.predict(test_df[xtrain.columns])\/num_of_splits\n\n\npredictions_random_forest_test = np.expm1(predictions_random_forest_test)\nprint()\nprint(predictions_random_forest_test)\nprint()\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_random_forest_test, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()","68267da3":"def bayesian_tuning_random_forest(xtrain, ytrain):\n    \n    from skopt import BayesSearchCV\n    from sklearn.ensemble import RandomForestRegressor\n    \n    \n    # Classifier\n    bayes_cv_tuner = BayesSearchCV(\n        estimator = RandomForestRegressor(\n            random_state=42\n        ),\n        search_spaces = {\n            'n_estimators': (10, 500),\n            'max_depth': (1, 10),\n            'min_samples_split': (2, 20),\n            'min_samples_leaf': (1, 20)\n        },\n        cv = KFold(\n            n_splits=kfold_splits,\n            shuffle=True,\n            random_state=42\n        ),\n        scoring = 'neg_mean_squared_error',\n        n_jobs = 2,\n        n_iter = 12,   \n        verbose = 0,\n        refit = True,\n        random_state = 42\n    )\n\n    def status_print(optim_result):\n        \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n\n        # Get all the models tested so far in DataFrame format\n        all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n\n        # Get current parameters and the best parameters    \n        best_params = pd.Series(bayes_cv_tuner.best_params_)\n        print('Model #{}\\nBest score: {}\\nBest params: {}\\n'.format(\n            len(all_models),\n            np.round(bayes_cv_tuner.best_score_, 4),\n            bayes_cv_tuner.best_params_\n        ))\n        \n    result_random_forest = bayes_cv_tuner.fit(xtrain, ytrain, callback = status_print)\n    return result_random_forest\n    \n# Fit the model\n#xtrain, ytrain = prepare_for_tuning(X, y, type_of_training=type_of_training)\nresult_random_forest = bayesian_tuning_random_forest(xtrain, ytrain)","2f23c16b":"result_random_forest.best_params_","8ff0792f":"from sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\nimport scikitplot as skplt\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_random_forest_tuned_test = np.zeros(len(test_df))\nnum_fold = 0\nnum_of_splits = kfold_splits\noof_rmse = 0\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    clf_random_forest_tuned = RandomForestRegressor(random_state=42, \n                                              n_estimators = result_random_forest.best_params_['n_estimators'],\n                                              min_samples_leaf = result_random_forest.best_params_['min_samples_leaf'],\n                                              min_samples_split = result_random_forest.best_params_['min_samples_split'])\n\n    clf_random_forest_tuned.fit(xtrain_stra, ytrain_stra)\n\n    predictions_valid = clf_random_forest_tuned.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold xvalid rmse:\", rmse_valid)\n    oof_rmse += rmse_valid\n\n    predictions_random_forest_tuned_test += clf_random_forest_tuned.predict(test_df[xtrain.columns])\/num_of_splits\n\n\npredictions_random_forest_tuned_test = np.expm1(predictions_random_forest_tuned_test)\nprint()\nprint(predictions_random_forest_test)\nprint()\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_random_forest_tuned_test, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()","996590f4":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport lightgbm as lgb\n\nparams = {\n    \"metric\": 'rmse',\n    \"verbosity\": -1\n}\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_test_lgb = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    model_lgb = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n    model_lgb.fit(xtrain_stra, ytrain_stra, \n        eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], eval_metric='rmse',\n        verbose=100, early_stopping_rounds=1000)\n\n    predictions_valid = model_lgb.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    \n    oof_rmse += rmse_valid\n\n    predictions_test_lgb += model_lgb.predict(test_df[xtrain.columns])\/num_of_splits\n    \n\npredictions_test_lgb = np.expm1(predictions_test_lgb)\nprint()\nprint(predictions_test_lgb)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_lgb, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\n#xgb.plot_importance(clf_stra_fs_tuned_xgb)","0235100d":"def bayesian_tuning_lgb(xtrain, ytrain):\n    \n    from skopt import BayesSearchCV    \n    \n    # Classifier\n    bayes_cv_tuner = BayesSearchCV(\n        estimator = lgb.LGBMRegressor(\n            boosting_type='gbdt', n_jobs=2, nthread = 4, verbose=-1\n        ),\n        search_spaces = {\n            'num_leaves': (10, 100),\n            'min_data_in_leaf': (10, 100),\n            'n_estimators': (50, 100),\n            'max_depth': (3, 12),\n            'learning_rate': (0.01, 0.2, 'log-uniform'),\n            \"feature_fraction\": (0.1, 1, 'uniform'),\n            \"bagging_fraction\": (0.1, 1, 'uniform'),\n            'lambda_l1': (0.1, 1, 'log-uniform'),\n            'lambda_l2': (0.1, 1, 'log-uniform')\n        },\n        cv = KFold(\n            n_splits=kfold_splits,\n            shuffle=True,\n            random_state=42\n        ),\n        scoring = 'neg_mean_squared_error',\n        n_jobs = 1,\n        n_iter = 12,   \n        verbose = 0,\n        refit = True,\n        random_state = 42\n    )\n\n    def status_print(optim_result):\n        \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n\n        # Get all the models tested so far in DataFrame format\n        all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n\n        # Get current parameters and the best parameters    \n        best_params = pd.Series(bayes_cv_tuner.best_params_)\n        print('Model #{}\\nBest score: {}\\nBest params: {}\\n'.format(\n            len(all_models),\n            np.round(bayes_cv_tuner.best_score_, 4),\n            bayes_cv_tuner.best_params_\n        ))\n        \n    result_lgbm = bayes_cv_tuner.fit(xtrain, ytrain, callback = status_print)\n    return result_lgbm\n    \n# Fit the model\n#xtrain, ytrain = prepare_for_tuning(X, y, type_of_training=type_of_training)\nresult_lgbm = bayesian_tuning_lgb(xtrain, ytrain)","d5e416a9":"result_lgbm.best_params_","7469707a":"params = {\n    'num_leaves': result_lgbm.best_params_[\"num_leaves\"],\n    'min_data_in_leaf': result_lgbm.best_params_[\"min_data_in_leaf\"],\n    'max_depth': result_lgbm.best_params_[\"max_depth\"],\n    'learning_rate': result_lgbm.best_params_[\"learning_rate\"],\n    \"boosting\": \"gbdt\",\n    \"feature_fraction\": result_lgbm.best_params_[\"feature_fraction\"],\n    \"bagging_freq\": 1,\n    \"bagging_fraction\": result_lgbm.best_params_[\"bagging_fraction\"],\n    \"bagging_seed\": 11,\n    \"metric\": 'rmse',\n    \"lambda_l1\": result_lgbm.best_params_[\"lambda_l1\"],\n    \"lambda_l2\": result_lgbm.best_params_[\"lambda_l2\"],\n    \"verbosity\": -1\n}\n\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport lightgbm as lgb\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=0.3)\n\npredictions_test_lgb_tuned = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    model_lgb_tuned = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n    model_lgb_tuned.fit(xtrain_stra, ytrain_stra, \n        eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], eval_metric='rmse',\n        verbose=100, early_stopping_rounds=1000)\n\n    predictions_valid = model_lgb_tuned.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    oof_rmse += rmse_valid\n\n    predictions_test_lgb_tuned += model_lgb_tuned.predict(test_df[xtrain.columns])\/num_of_splits\n    \n\npredictions_test_lgb_tuned = np.expm1(predictions_test_lgb_tuned)\nprint()\nprint(predictions_test_lgb_tuned)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_lgb_tuned, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\n#xgb.plot_importance(clf_stra_fs_tuned_xgb)","3cf1130e":"from sklearn.feature_selection import SelectFromModel\n\nmax_selected_features = 200\nsel = SelectFromModel(clf_stra_xgb, max_features = max_selected_features, threshold=0.005, prefit=True)\n\nfeature_idx = sel.get_support()\nselected_features_xgb = X.columns[feature_idx]","2fdc0047":"selected_features_xgb","d76146bc":"from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nimport time\nimport random\nfrom sklearn.metrics import mean_squared_error\n\nimport xgboost as xgb\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X[selected_features_xgb], y, random_state=42, test_size=0.3)\n\nimport xgboost as xgb\n\nstart_time = time.time()\n\npredictions_test_xgb_fs = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    \n    clf_stra_fs_xgb = xgb.XGBRegressor(n_estimators=10000, seed=42, nthread = -1)\n\n    clf_stra_fs_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                early_stopping_rounds=1000, eval_metric='rmse', verbose=100)\n\n    predictions_valid = clf_stra_fs_xgb.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    \n    oof_rmse += rmse_valid\n\n    predictions_test_xgb_fs += clf_stra_fs_xgb.predict(test_df[xtrain.columns])\/num_of_splits\n    \n\npredictions_test_xgb_fs = np.expm1(predictions_test_xgb_fs)\nprint(predictions_test_xgb_fs)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_xgb_fs, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\nxgb.plot_importance(clf_stra_fs_xgb)","c479598d":"result = bayesian_tuning(xtrain, ytrain)","9eddfbe7":"from sklearn.model_selection import train_test_split, KFold\nimport time\nimport random\nfrom sklearn.metrics import mean_squared_error\n\nimport xgboost as xgb\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X[selected_features_xgb], y, random_state=42, test_size=0.3)\n\npredictions_test_xgb_fs_tuned = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    \n    clf_stra_fs_tuned_xgb = xgb.XGBRegressor(colsample_bytree = result.best_params_[\"colsample_bytree\"],\n                                    gamma=result.best_params_[\"gamma\"],                 \n                                    learning_rate=result.best_params_[\"learning_rate\"],\n                                    max_depth=result.best_params_[\"max_depth\"],\n                                    min_child_weight=result.best_params_[\"min_child_weight\"],\n                                    n_estimators=10000,\n                                    reg_alpha=result.best_params_[\"reg_alpha\"],\n                                    reg_lambda=result.best_params_[\"reg_lambda\"],\n                                    subsample=result.best_params_[\"subsample\"],\n                                    seed=42,\n                                    nthread = -1)\n\n    clf_stra_fs_tuned_xgb.fit(xtrain_stra, ytrain_stra, eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], \n                early_stopping_rounds=1000, eval_metric='rmse', verbose=100)\n\n    predictions_valid = clf_stra_fs_tuned_xgb.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    \n    oof_rmse += rmse_valid\n\n    predictions_test_xgb_fs_tuned += clf_stra_fs_tuned_xgb.predict(test_df[xtrain.columns])\/num_of_splits\n    \n\npredictions_test_xgb_fs_tuned = np.expm1(predictions_test_xgb_fs_tuned)\nprint(predictions_test_xgb_fs_tuned)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_xgb_fs_tuned, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\nxgb.plot_importance(clf_stra_fs_tuned_xgb)","be91a19f":"from sklearn.feature_selection import SelectFromModel\n\nmax_selected_features = 200\nsel = SelectFromModel(model_lgb, max_features = max_selected_features, threshold=0.005, prefit=True)\n\nfeature_idx = sel.get_support()\nselected_features_lgb = X.columns[feature_idx]","8f8dbce0":"selected_features_lgb","9ac982d7":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport lightgbm as lgb\n\nparams = {\n    \"metric\": 'rmse',\n    \"verbosity\": -1\n}\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X[selected_features_lgb], y, random_state=42, test_size=0.3)\n\npredictions_test_lgb_fs = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    model_lgb_fs = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n    model_lgb_fs.fit(xtrain_stra, ytrain_stra, \n        eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], eval_metric='rmse',\n        verbose=100, early_stopping_rounds=1000)\n\n    predictions_valid = model_lgb_fs.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    \n    oof_rmse += rmse_valid\n\n    predictions_test_lgb_fs += model_lgb_fs.predict(test_df[xtrain.columns])\/num_of_splits\n    \n\npredictions_test_lgb_fs = np.expm1(predictions_test_lgb_fs)\nprint()\nprint(predictions_test_lgb_fs)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_lgb_fs, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\n#xgb.plot_importance(clf_stra_fs_tuned_xgb)","fe4ce70f":"result_lgb = bayesian_tuning_lgb(xtrain, ytrain)","c9addefe":"params = {\n    'num_leaves': result_lgbm.best_params_[\"num_leaves\"],\n    'min_data_in_leaf': result_lgbm.best_params_[\"min_data_in_leaf\"],\n    'max_depth': result_lgbm.best_params_[\"max_depth\"],\n    'learning_rate': result_lgbm.best_params_[\"learning_rate\"],\n    \"boosting\": \"gbdt\",\n    \"feature_fraction\": result_lgbm.best_params_[\"feature_fraction\"],\n    \"bagging_freq\": 1,\n    \"bagging_fraction\": result_lgbm.best_params_[\"bagging_fraction\"],\n    \"bagging_seed\": 11,\n    \"metric\": 'rmse',\n    \"lambda_l1\": result_lgbm.best_params_[\"lambda_l1\"],\n    \"lambda_l2\": result_lgbm.best_params_[\"lambda_l2\"],\n    \"verbosity\": -1\n}\n\n\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport lightgbm as lgb\n\n# create a 70\/30 stratified split of the data \nxtrain, xvalid, ytrain, yvalid = train_test_split(X[selected_features_lgb], y, random_state=42, test_size=0.3)\n\npredictions_test_lgb_fs_tuned = np.zeros(len(test_df))\nnum_fold = 0\noof_rmse = 0\nnum_of_splits = kfold_splits\n\nfolds = KFold(n_splits=num_of_splits, shuffle=False, random_state = 42)\n\nfor train_index, valid_index in folds.split(xtrain, ytrain):\n    xtrain_stra, xvalid_stra = xtrain.iloc[train_index,:], xtrain.iloc[valid_index,:]\n    ytrain_stra, yvalid_stra = ytrain.iloc[train_index], ytrain.iloc[valid_index]\n\n    print()\n    print(\"Fold:\", num_fold)\n    print()\n    \n    model_lgb_fs_tuned = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n    model_lgb_fs_tuned.fit(xtrain_stra, ytrain_stra, \n        eval_set=[(xtrain_stra, ytrain_stra), (xvalid_stra, yvalid_stra)], eval_metric='rmse',\n        verbose=100, early_stopping_rounds=1000)\n\n    predictions_valid = model_lgb_fs_tuned.predict(xvalid)\n    rmse_valid = np.sqrt(mean_squared_error(yvalid, predictions_valid))\n    print(\"Fold\" ,num_fold, \"xvalid rmse:\", rmse_valid)\n    num_fold = num_fold + 1\n    oof_rmse += rmse_valid\n\n    predictions_test_lgb_fs_tuned += model_lgb_fs_tuned.predict(test_df[xtrain.columns])\/num_of_splits\n    \n\npredictions_test_lgb_fs_tuned = np.expm1(predictions_test_lgb_fs_tuned)\nprint()\nprint(predictions_test_lgb_fs_tuned)\nprint(\"OOF Out-of-fold rmse:\", oof_rmse\/num_of_splits)\n\nf, ax = plt.subplots(2, figsize=(12,7))\n\nsns.set(rc={'figure.figsize':(9,14)})\nsns.distplot(train_df.revenue, ax=ax[0])\nax[0].set_title(\"Train Set Revenue Histogram\")\nsns.distplot(predictions_test_lgb_fs_tuned, ax=ax[1])\nax[1].set_title(\"Test Set Revenue Prediction Histogram\")\nf.tight_layout()\n\n#xgb.plot_importance(clf_stra_fs_tuned_xgb)","bf799cb4":"####### xgb with the other models\n\npredictions_test_xgb_extra_trees = (0.5 * predictions_test_xgb) + (0.5 * predictions_extra_trees_test)\npredictions_test_xgb_random_forest = (0.5 * predictions_test_xgb) + (0.5 * predictions_random_forest_test)\npredictions_test_extra_trees_random_forest = (0.5 * predictions_extra_trees_test) + (0.5 * predictions_random_forest_test)\n\npredictions_test_tuned_xgb_extra_trees = (0.5 * predictions_test_xgb_tuned) + (0.5 * predictions_extra_trees_tuned_test)\npredictions_test_tuned_xgb_random_forest = (0.5 * predictions_test_xgb_tuned) + (0.5 * predictions_random_forest_tuned_test)\npredictions_test_tuned_extra_trees_random_forest = (0.5 * predictions_extra_trees_tuned_test) + (0.5 * predictions_random_forest_tuned_test)\n\npredictions_test_xgb_fs_extra_trees =  (0.5 * predictions_test_xgb_fs) + (0.5 * predictions_extra_trees_test)\npredictions_test_xgb_fs_tuned_extra_trees = (0.5 * predictions_test_xgb_fs_tuned) + (0.5 * predictions_extra_trees_test)\n\npredictions_test_baseline_xgb_tuned_extra_trees = (0.5 * predictions_test_xgb) + (0.5 * predictions_extra_trees_tuned_test)\n\n####### lgb with the other models\n\npredictions_test_lgb_xgb = (0.5 * predictions_test_lgb) + (0.5 * predictions_test_xgb)\npredictions_test_tuned_lgb_xgb = (0.5 * predictions_test_lgb_tuned) + (0.5 * predictions_test_xgb_tuned)\n\npredictions_test_lgb_extra_trees = (0.5 * predictions_test_lgb) + (0.5 * predictions_extra_trees_test)\npredictions_test_lgb_random_forest = (0.5 * predictions_test_lgb) + (0.5 * predictions_random_forest_test)\n\npredictions_test_tuned_lgb_extra_trees = (0.5 * predictions_test_lgb_tuned) + (0.5 * predictions_extra_trees_tuned_test)\npredictions_test_tuned_lgb_random_forest = (0.5 * predictions_test_lgb_tuned) + (0.5 * predictions_random_forest_tuned_test)\n\npredictions_test_xgb_fs_lgb =  (0.5 * predictions_test_xgb_fs) + (0.5 * predictions_test_lgb_fs)\npredictions_test_xgb_fs_tuned_lgb = (0.5 * predictions_test_xgb_fs_tuned) + (0.5 * predictions_test_lgb_fs_tuned)\n\n\npredictions_test_baseline_lgb_tuned_extra_trees = (0.5 * predictions_test_lgb) + (0.5 * predictions_extra_trees_tuned_test)","a4f10ed3":"# xgb baseline\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb\nsubmission.to_csv('clf_xgb_baseline.csv', index=False)\n\n# xgb tuning\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_tuned\nsubmission.to_csv('clf_xgb_tuned.csv', index=False)\n\n# lgb baseline\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb\nsubmission.to_csv('clf_lgb_baseline.csv', index=False)\n\n# lgb tuning\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_tuned\nsubmission.to_csv('clf_lgb_tuned.csv', index=False)\n\n# extra trees baseline\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_extra_trees_test\nsubmission.to_csv('clf_extra_trees_baseline.csv', index=False)\n\n# extra trees tuning\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_extra_trees_tuned_test\nsubmission.to_csv('clf_extra_trees_tuned.csv', index=False)\n\n# xgb baseline with feature selection\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_fs\nsubmission.to_csv('clf_xgb_fs_baseline.csv', index=False)\n\n# xgb tuning with feature selection\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_fs_tuned\nsubmission.to_csv('clf_xgb_fs_tuned.csv', index=False)\n\n# lgb baseline with feature selection\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_fs\nsubmission.to_csv('clf_lgb_fs_baseline.csv', index=False)\n\n# lgb tuning with feature selection\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_fs_tuned\nsubmission.to_csv('clf_lgb_fs_tuned.csv', index=False)\n\n# Blend 1\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_extra_trees\nsubmission.to_csv('blend_xgb_extra_trees_baselines.csv', index=False)\n\n# Blend 2\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_random_forest\nsubmission.to_csv('blend_xgb_random_forest_baselines.csv', index=False)\n\n# Blend 3\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_extra_trees_random_forest\nsubmission.to_csv('blend_extra_trees_random_forest_baselines.csv', index=False)\n\n# Blend 4\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_tuned_xgb_extra_trees\nsubmission.to_csv('blend_xgb_extra_trees_tuned.csv', index=False)\n\n# Blend 5\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_tuned_xgb_random_forest\nsubmission.to_csv('blend_xgb_random_forest_tuned.csv', index=False)\n\n# Blend 6\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_tuned_extra_trees_random_forest\nsubmission.to_csv('blend_extra_trees_random_forest_tuned.csv', index=False)\n\n# Blend 7\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_baseline_xgb_tuned_extra_trees\nsubmission.to_csv('blend_baseline_xgb_tuned_extra_trees.csv', index=False)\n\n# Blend 8\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_fs_extra_trees\nsubmission.to_csv('blend_xgb_fs_extra_trees.csv', index=False)\n\n# Blend 9\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_fs_tuned_extra_trees\nsubmission.to_csv('blend_xgb_fs_tuned_extra_trees.csv', index=False)\n\n# Blend 10\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_xgb\nsubmission.to_csv('blend_lgb_xgb.csv', index=False)\n\n# Blend 11\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_tuned_lgb_xgb\nsubmission.to_csv('blend_tuned_lgb_xgb.csv', index=False)\n\n# Blend 12\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_extra_trees\nsubmission.to_csv('blend_tuned_lgb_extra_trees.csv', index=False)\n\n# Blend 13\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_extra_trees\nsubmission.to_csv('blend_tuned_lgb_extra_trees.csv', index=False)\n\n# Blend 14\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_lgb_random_forest\nsubmission.to_csv('blend_tuned_lgb_random_forest.csv', index=False)\n\n# Blend 15\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_tuned_lgb_extra_trees\nsubmission.to_csv('blend_tuned_lgb_extra_trees.csv', index=False)\n\n# Blend 16\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_tuned_lgb_random_forest\nsubmission.to_csv('blend_tuned_lgb_random_forest.csv', index=False)\n\n# Blend 17\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_baseline_lgb_tuned_extra_trees\nsubmission.to_csv('blend_baseline_lgb_tuned_extra_trees.csv', index=False)\n\n# Blend 18\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_fs_lgb\nsubmission.to_csv('blend_xgb_fs_lgb.csv', index=False)\n\n# Blend 19\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['revenue'] = predictions_test_xgb_fs_tuned_lgb\nsubmission.to_csv('blend_xgb_fs_tuned_lgb.csv', index=False)\n","08183955":"#### Bivariate Analysis between each genre and revenue","87b950bb":"#### Number of Genres","76097234":"#### Number of Genres in a movie","73265fb6":"#### Number of Costume and Make-Up crew","9db54ab7":"#### isProductionCompany feature engineering\nFeature Engineering with all the production companies","763e7e3c":"### LGB Tuning with Feature Selection","343924bb":"#### Title\nLets generate a wordcloud","45856818":"#### Number of Genres per movie and revenues","6b3e45be":"#### production_countries","0b6e5e80":"# TMDB Box Office Prediction EDA + ML\n\n![](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*vIR7iO-1GnY2xYxL6NiYkw.png)\n[image-source](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*vIR7iO-1GnY2xYxL6NiYkw.png)\n\nIn a world... where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's \"You had me at 'Hello.'\" For others, the trailer falls short of expectations and you think \"What we have here is a failure to communicate.\"\n\nIn this competition, you're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release.\n\n## *Kernel in progress, is continuously being updated and extended*","ee6cc5e5":"#### Number of Art crew","6ab76bf5":"#### isProduction_country feature engineering","cac22602":"So many columns and features to investigate, lets start by inspecting one by one each feature.","3e58e0f6":"#### Day of the week when the movie released and revenue","a6208dae":"#### Tagline","73b4f9ce":"We have a variaty of data, numerical, categorical and even lists of json formats.","dff82c81":"## Preparations - Prerequisities","81e1ece0":"#### feature engineering, creating the has_top_actor columns","6abeeb3b":"#### Revenue\nOur target variable that must be predicted","9f767a00":"### feature engineering, finding has_top_director in movies","c0479348":"#### English and Non-English movies","44b27c54":"#### Month when the movie released and revenue","fc7650cf":"#### Week of year, which week of the year has most of the releases","f35fa78f":"#### Budget","d291b024":"#### Season when the movie released and revenue","adca5b73":"![](https:\/\/prod-discovery.edx-cdn.org\/media\/course\/image\/2102f79d-9a44-41e9-9d92-884bec46dc65-ff40350cad17.small.jpg)\n[image-source](https:\/\/prod-discovery.edx-cdn.org\/media\/course\/image\/2102f79d-9a44-41e9-9d92-884bec46dc65-ff40350cad17.small.jpg)","dee083ae":"Lets see the length of each movie","9ab98cad":"#### English and non english movies vs revenue","964dc0b7":"#### Number of Visual Effects Crew","a9cf08ab":"#### Cast\nNumber of cast","d3667075":"### Identifying top directors based on average movie revenue","6d9612f8":"### XGBoost training with Feature Selection and tuning","ec8ac8d5":"#### Season of Release, which season has most of the releases","331de654":"![](https:\/\/images-na.ssl-images-amazon.com\/images\/I\/91HTK796%2BML._SX425_.jpg)\n[image-source](https:\/\/images-na.ssl-images-amazon.com\/images\/I\/91HTK796%2BML._SX425_.jpg)","e2214401":"#### Month of Release, which month has most of the releases","4337d720":"### Inspecting the train set","f5de7de8":"### Extra Trees Tuning","7f4f0830":"### Identifying top Producers based on average movie salary","f06f35a7":"#### Week of year when the movie released and revenue","9fde28bc":"### Check for NA values in trainset","62457954":"## Preparing for submission","6e9f9b6a":"### LGBM training after tuning","f84fdf27":"#### Year when the movie released and revenue","870cf11a":"#### original_language and revenue","559523fa":"### Loading Libraries","41c77244":"### Loading the data","0fcd2be9":"#### has_collection and revenue","b694e566":"#### Overview\nLets visualize movies' overview wordcloud","4607d2ed":"### Female Crew\nCounting the number of female crew","16fa5058":"### LightGBM Boosting","97f86d28":"#### Number of Writers","5356061b":"#### isGenre, feature engineering, creating new feature\nisDrama, isComedy etc.","6b973f25":"#### Number of Sound crew","44299fbf":"#### Identifying top actors in movies based on mean movies' revenue","01a1a050":"### LGB Training after Feature Selection and Tuning","13ca08f7":"#### Production Companies","8dbc1485":"#### Day of Release, which day of the week has most of the releases","34891b3e":"#### feature engineering has_top_keyword based on mean movies' revenue","310c1339":"#### Male cast\nnumber of male cast","a4e9bc89":"#### homepage and revenue","1de4b1d7":"#### Genres","3563c79b":"### XGBoost Training after tuning","5b5a833e":"#### Number of Production Companies and revenue","26b2f84a":"#### Number of Other crew","1ba812d8":"### Male Crew\nCounting the number of male crew","b46ff67d":"### Random Forest After tuning","f505b8d5":"### Crew\nCounting the number of crew","e8bc3374":"## Machine Learning","67e71bc3":"#### Original Language","16cd0f51":"### Checking for NA values in feature before training","ebdbe038":"### Feature Selection for LGBM","43c77db0":"## Feature Selection","ae3c6f29":"#### Release Date preprocessing before EDA and ML","87463200":"#### tagline and revenue","82cceda9":"### Baseline LGB Training with Feature Selection","d80f882b":"#### *Thank for your time! Any suggestions are welcomed on how to improve my models performance*","722d6e4a":"### Tuning with feature Selection","ad400cfb":"#### production country and revenue","66f9ffba":"#### Number of Directors in a movie","21cc3498":"Inspecting movies' overview length","8543fce2":"#### Number of Production Companies","ebebe8ef":"## ML Blends","4ddc99d2":"#### Year of Release, which year has most of the releases","1e546577":"#### Female cast\nnumber of female cast","002fce38":"### EDA - Bivariate Analysis","53f15c1c":"### Random Forest Baseline","d56362ce":"### Tuning the LightGBM","bd57b6ab":"#### Bivariate Analysis for log-transformed numerical features","c036589e":"#### Preparations before ML modeling","60729033":"## Exploratory Data Analysis","0e6e88d2":"### feature engineering, finding has_top_producers in movies","18501875":"### Extra Trees Baseline Modeling","901efc12":"#### Number of Producers","6603bc8d":"#### Production Countries","efe684bd":"### Bayesian Tuning","c6153553":"### Bivariate Analysis and Feature Engineering","67e71e79":"#### Runtime","b4b4460b":"#### Number of Editors","a57f556c":"#### popularity","143e2e4c":"### Extra Trees Training after tuning","374aa1a3":"### Baseline XGBoost modeling","40443b3e":"### Baseline XGBoost with Feature Selection","f3f73ffb":"### Feature Selection for xgboost","91b57014":"#### Number of Lighting crew","d86aa2e4":"#### Identifying the top keywords based on mean movie revenue","bf5ba7fa":"### Random Forest Tuning","8e340f58":"### Univariate Analysis","b0b979d5":"#### Number of Camera crew","e9e8e4bc":"![](https:\/\/cmci.colorado.edu\/classes\/INFO-4604\/fa17\/wordcloud.png)\n[image-source](https:\/\/cmci.colorado.edu\/classes\/INFO-4604\/fa17\/wordcloud.png)","b3275660":"#### Bivariate Analysis for numerical features"}}