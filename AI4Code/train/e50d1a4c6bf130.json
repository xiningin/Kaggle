{"cell_type":{"a292c6e5":"code","517c6bb1":"code","6f0a5300":"code","eb0160ab":"code","b0859761":"code","8f1a5361":"code","8b745ba8":"code","963756be":"code","77e13dd8":"code","557a72fc":"code","436a35df":"code","d96e2fc8":"code","e83f3dd1":"code","3bb9c010":"code","e0edec72":"code","26adb9be":"markdown","a8f993df":"markdown","0eb16175":"markdown","ce882296":"markdown","600f579a":"markdown","8a71485c":"markdown","f148ad3d":"markdown","dc75d4ab":"markdown"},"source":{"a292c6e5":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport albumentations as A\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\ntorch.manual_seed(1)\nnp.random.seed(1)","517c6bb1":"data_dir = Path('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset')\nfile_path = list(data_dir.glob(r'**\/*.png'))\nclasses = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],file_path))\n                                \nfile_path = pd.Series(file_path).astype(str)\nclasses = pd.Series(classes)\ndf = pd.concat([file_path, classes], axis=1)\ndf.columns = ['image', 'label']\ndf = df[df['label'].apply(lambda x: x[-2:] != 'GT')]\ndf.head()","6f0a5300":"lb = LabelEncoder()\ndf['encoded_labels'] = lb.fit_transform(df['label'])\ndf","eb0160ab":"plt.figure(figsize=(14, 10))\nfor i in range(20):\n    idx = np.random.randint(0, len(df) - 1)\n    plt.subplot(4, 5, i+1)\n    img = df.iloc[idx, 0]\n    plt.imshow(plt.imread(img))\n    plt.title(df.iloc[idx, 1], size=10, color=\"black\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","b0859761":"train_df, test_df = train_test_split(df, train_size=0.95, random_state=0)\ntrain_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)\nprint(train_df.label.value_counts())\nprint(valid_df.label.value_counts())\nprint(test_df.label.value_counts())","8f1a5361":"class FishDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform=transforms.Compose([transforms.ToTensor()])):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        length = len(self.df)\n        return length\n        \n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx, 0]\n        label = self.df.iloc[idx, 2]\n        label = int(label)\n        label = torch.tensor(label)\n        image = Image.open(img_path)\n        image = self.transform(image)\n        return image, label","8b745ba8":"data_transforms = transforms.Compose([\n    transforms.Resize([224, 224]),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\ndata_transforms_test = transforms.Compose([\n    transforms.Resize([224, 224]),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n","963756be":"train_dataset = FishDataset(df=train_df, transform=data_transforms)\nvalid_dataset = FishDataset(df=valid_df, transform=data_transforms_test)\ntest_dataset = FishDataset(df=test_df, transform=data_transforms_test)","77e13dd8":"batch_size = 64\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))","557a72fc":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","436a35df":"class SimpleCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.LeakyReLU(0.1))\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(0.1),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        self.fc = nn.Sequential(\n            nn.Linear(32 * 112 * 112, 81),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(81),\n            nn.LeakyReLU(81, 9))\n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = x.view(-1, 32 * 112 * 112)\n        x = self.fc(x)\n        return x","d96e2fc8":"#From https:\/\/github.com\/Bjarten\/early-stopping-pytorch\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n    def __init__(self, patience=7, verbose=False):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n#             self.save_checkpoint(val_loss, model)\n        elif score < self.best_score:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n#             self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n#     def save_checkpoint(self, val_loss, model):\n#         '''Saves model when validation loss decrease.'''\n#         if self.verbose:\n#             print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n#         torch.save(model.state_dict(), 'checkpoint.pt')\n#         self.val_loss_min = val_loss","e83f3dd1":"model = SimpleCNN()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ncriterion = nn.CrossEntropyLoss()\n\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, cooldown=2, verbose=True)\n\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","3bb9c010":"epochs = 30\n\ntotal_train_loss = []\ntotal_valid_loss = []\nbest_valid_loss = np.Inf\nearly_stop = EarlyStopping(patience=5, verbose=True)\n\nfor epoch in range(epochs): \n    print('Epoch: ', epoch + 1)\n    train_loss = []\n    valid_loss = []\n    train_correct = 0\n    train_total = 0\n    valid_correct = 0\n    valid_total = 0\n    for image, target in train_loader:\n        model.train()\n        image, target = image.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(image)\n        loss = criterion(output, target)\n        train_loss.append(loss.item())\n        _, predicted = torch.max(output.data, 1)\n        train_total += target.size(0)\n        train_correct += (predicted == target).sum().item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    for image, target in valid_loader:\n        with torch.no_grad():\n            model.eval()\n            image, target = image.to(device), target.to(device)\n            \n            output = model(image)\n            loss = criterion(output, target)\n            valid_loss.append(loss.item())\n            _, predicted = torch.max(output.data, 1)\n            valid_total += target.size(0)\n            valid_correct += (predicted == target).sum().item()\n            \n    epoch_train_loss = np.mean(train_loss)\n    epoch_valid_loss = np.mean(valid_loss)\n    print(f'Epoch {epoch + 1}, train loss: {epoch_train_loss:.4f}, valid loss: {epoch_valid_loss:.4f}, train accuracy: {(100 * train_correct \/ train_total):.4f}%, valid accuracy: {(100 * valid_correct \/ valid_total):.4f}%')\n    if epoch_valid_loss < best_valid_loss:\n        torch.save(model.state_dict(), 'fish_classification_model.pt')\n        print('Model improved. Saving model.')\n        best_valid_loss = epoch_valid_loss\n    \n    early_stop(epoch_valid_loss, model)\n        \n    if early_stop.early_stop:\n        print(\"Early stopping\")\n        break\n        \n    lr_scheduler.step(epoch_valid_loss)\n    total_train_loss.append(epoch_train_loss)\n    total_valid_loss.append(epoch_valid_loss)","e0edec72":"model.load_state_dict(torch.load('fish_classification_model.pt'))\n\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    model.eval()\n    for image, target in test_loader:\n        image, target = image.to(device), target.to(device)\n        \n        output = model(image)\n        \n        _, predicted = torch.max(output.data, 1)\n        total += target.size(0)\n        correct += (predicted == target).sum().item()\n\nprint('Test Accuracy: %d %%' % (\n    100 * correct \/ total))","26adb9be":"# **Model Architecture**","a8f993df":"# **Create Dataframe from Images**","0eb16175":"# **Import Libraries and Set Seed**","ce882296":"# **Visualize Images**","600f579a":"# **Dataset Class**","8a71485c":"# **Predictions on Test Set**","f148ad3d":"# **Split Data into Train, Valid, and Test**","dc75d4ab":"# **Training**"}}