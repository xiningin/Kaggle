{"cell_type":{"10b71c72":"code","55717d6b":"code","6cc55740":"code","b69fc6fa":"code","a3a66b95":"code","e33a36ba":"code","dbc8f6e2":"code","e3182413":"code","7fd77061":"code","462e1fe3":"code","42083405":"code","92e1e13d":"code","58e07521":"code","25928777":"code","5bec82a4":"code","b3c2b36b":"code","85e1db5c":"code","249c7eeb":"code","89b28c2f":"code","687e076d":"code","541a417d":"code","7738bbf7":"code","ac622d5e":"code","a8f5119f":"code","d0ba25bf":"code","d1f7e1a8":"code","9ccaaff8":"code","a7d1b0e5":"code","826bfb78":"code","d1f6bf35":"code","b5471224":"code","4454b7eb":"code","a925fbd3":"code","b1255246":"code","41d47120":"code","79e3d684":"code","3ff8ea6d":"code","2639cc40":"code","0ba6d381":"code","fd38822f":"code","56564bd3":"code","d233a372":"code","40e8576a":"markdown","cff4a094":"markdown","fa198709":"markdown","16492a4c":"markdown","cb06427d":"markdown","6fbb3066":"markdown","5adaf109":"markdown","349858c4":"markdown","f8ddb3db":"markdown","da804819":"markdown","576e0e06":"markdown","fada5ec6":"markdown","b992f3a7":"markdown","83d2a927":"markdown","51824fdf":"markdown","6b406ec4":"markdown","4f06fa86":"markdown","7b6ab3bb":"markdown","f0d81b00":"markdown","629ef3fe":"markdown","3d0d58d0":"markdown"},"source":{"10b71c72":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom fbprophet import Prophet\nplt.style.use('ggplot')","55717d6b":"path = \"..\/input\/train.csv\"\ntrain = pd.read_csv(path)\ntrain.head()","6cc55740":"train.shape","b69fc6fa":"train[\"year\"] = pd.to_datetime(train[\"date\"]).dt.year\ntrain[\"month\"] = pd.to_datetime(train[\"date\"]).dt.month\ntrain[\"month_year\"] = pd.to_datetime(train[\"date\"]).dt.to_period('M')\ntrain.head()","a3a66b95":"# train.count() will give a value only if not nan\ncount_nan = len(train) - train.count()\ncount_nan","e33a36ba":"plt.hist(train[\"sales\"])\nplt.show()","dbc8f6e2":"# R script: MSP <- aggregate(sales ~date, train, mean)\nmean_sales = train.groupby([\"date\"], as_index=False)\nmean_sales = mean_sales[[\"sales\"]].mean()\nmean_sales[\"idx\"] = mean_sales.index","e3182413":"# Could use the follow:\n# plt.scatter(x=mean_sales[\"date\"], y=mean_sales[\"sales\"])\n# plt.show()\n# Seaborn gives us a closer analogue to the work done in R.\ng = sns.relplot(x=\"idx\", y=\"sales\", data=mean_sales, kind=\"line\")","7fd77061":"# Change in rate of sales\n# R script: MSP$rate = c(0, 100*diff(MSP$sales)\/MSP[-nrow(MSP),]$sales)\n# plt.scatter(x=mean_sales.index, y=rt)\n# plt.show()\n# rt is short form for \"Rate\"\nrt = pd.Series(mean_sales[\"sales\"]).pct_change()\nrt = pd.DataFrame(rt)\nrt[\"idx\"] = rt.index\nrt.fillna(0, inplace=True)\ng = sns.relplot(y=\"sales\", x=\"idx\", data=rt, kind=\"line\")","462e1fe3":"# R script: MSP <- aggregate(sales ~<Month, train, mean)\n# plt.scatter(x=mean_sales_monthly.index, y=mean_sales_monthly[\"sales\"])\n# plt.show()\n# Used index instead of month-year values \n# because matplotlib complains otherwise\nmean_sales_monthly = train.groupby([\"month_year\"], as_index=False)\nmean_sales_monthly = mean_sales_monthly[[\"sales\"]].mean()\nmean_sales_monthly[\"idx\"] = mean_sales_monthly.index\ng = sns.relplot(y=\"sales\", x=\"idx\", data=mean_sales_monthly, kind=\"line\")","42083405":"# Change in rate of sales\n# R script: MSP$rate = c(0, 100*diff(MSP$sales)\/MSP[-nrow(MSP),]$sales)\n# rt = pd.Series(mean_sales_monthly[\"sales\"]).pct_change()\nrt = pd.Series(mean_sales_monthly[\"sales\"]).pct_change()\nrt = pd.DataFrame(rt)\nrt[\"idx\"] = rt.index\nrt.fillna(0, inplace=True)\ng = sns.relplot(y=\"sales\", x=\"idx\", data=rt, kind=\"line\")","92e1e13d":"# R script: MSP <- aggregate(sales ~Year, train, mean)\n#plt.scatter(x=mean_sales_yearly.year, y=mean_sales_yearly[\"sales\"])\n#plt.show()\nmean_sales_yearly = train.groupby([\"year\"], as_index=False)\nmean_sales_yearly = mean_sales_yearly[[\"sales\"]].mean()\nmean_sales_yearly[\"idx\"] = mean_sales_yearly.index\ng = sns.relplot(y=\"sales\", x=\"idx\", data=mean_sales_yearly, kind=\"line\")","58e07521":"# Change in rate of sales\n# R script: MSP$rate = c(0, 100*diff(MSP$sales)\/MSP[-nrow(MSP),]$sales)\n#plt.scatter(x=mean_sales_yearly.year, y=rt)\n#plt.show()\nrt = pd.Series(mean_sales_yearly[\"sales\"]).pct_change()\nrt = pd.DataFrame(rt)\nrt[\"idx\"] = rt.index\nrt.fillna(0, inplace=True)\ng = sns.relplot(y=\"sales\", x=\"idx\", data=rt, kind=\"line\")","25928777":"#unique(train$store)\n#Year_state<-aggregate(sales ~store+Year, train,mean)\n#pal<-rep(brewer.pal(10, \"BrBG\"),5)\n#stores = pd.unique(train[\"store\"])\n#years_stores = train.groupby([\"year\", \"store\"], as_index=False)\n#years_stores = years_stores[[\"sales\"]].mean()\n#plt.scatter(x=years_stores[\"sales\"],y=years_stores[\"store\"])\ndata = train.groupby(['store',\"year\"])\nmean = data[[\"sales\"]].mean()\nmean = mean.add_suffix('').reset_index()\ng = sns.relplot(y=\"sales\", x=\"year\", data=mean, kind=\"line\", hue=\"store\")","5bec82a4":"# unique(train$item)\n# Year_state<-aggregate(sales ~item+Year, train,mean)\ndata = train.groupby(['item',\"year\"])\nmean = data[[\"sales\"]].mean()\nmean = mean.add_suffix('').reset_index()\ng = sns.relplot(y=\"sales\", x=\"year\", data=mean, kind=\"line\", hue=\"item\")","b3c2b36b":"import warnings\nwarnings.filterwarnings('ignore')","85e1db5c":"s1i1 = train[(train[\"store\"]==1) & (train[\"item\"])==1]\ns1i1[\"sales\"] = np.log1p(s1i1[\"sales\"])\ns1i1.head()","249c7eeb":"# R script: stats=aggregate(stats$y,by=list(stats$ds),FUN=sum)\n# R script: MSP <- aggregate(sales ~Year, train, mean)\nstats = s1i1[[\"date\", \"sales\"]]\nstats.columns = [\"ds\", \"y\"]\nstats.head()","89b28c2f":"m = Prophet()\nm.fit(stats)\nfuture = m.make_future_dataframe(periods=365)\nfuture.tail()","687e076d":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","541a417d":"fig1 = m.plot(forecast)","7738bbf7":"fig2 = m.plot_components(forecast)","ac622d5e":"playoffs = ['2013-07-12', '2014-07-12', '2014-07-19',\n                 '2014-07-02', '2015-07-11', '2016-07-17',\n                 '2016-07-24', '2016-07-07','2016-07-24']\nsuperbowl = ['2013-01-01', '2013-12-25', '2014-01-01', '2014-12-25','2015-01-01', '2015-12-25','2016-01-01', '2016-12-25',\n                '2017-01-01', '2017-12-25']\n\nplayoffs = pd.DataFrame({\n  'holiday': 'playoff',\n  'ds': pd.to_datetime(playoffs),\n  'lower_window': 0,\n  'upper_window': 1,\n})\nsuperbowls = pd.DataFrame({\n  'holiday': 'superbowl',\n  'ds': pd.to_datetime(superbowl),\n  'lower_window': 0,\n  'upper_window': 1,\n})\nholidays = pd.concat((playoffs, superbowls))","a8f5119f":"s1i1[\"dow\"] = pd.to_datetime(s1i1[\"date\"]).dt.day_name() # day of week\ns1i1.head()","d0ba25bf":"def nfl_sunday(ds):\n    date = pd.to_datetime(ds)\n    if date.weekday() == 6 and (date.month > 8 or date.month < 2):\n        return 1\n    else:\n        return 0","d1f7e1a8":"stats = s1i1[[\"date\", \"sales\"]]\nstats.columns = [\"ds\", \"y\"]\nstats.head()","9ccaaff8":"stats[\"nfl_sunday\"] = stats['ds'].apply(nfl_sunday)\nstats.head()","a7d1b0e5":"# R script below:\n#model_prophet <- prophet()\n#model_prophet <- add_regressor(model_prophet, 'nfl_sunday')\n#model_prophet <- add_seasonality(model_prophet, name='daily', period=60, fourier.order=5)\n#model_prophet <- prophet(stats, holidays = holidays,holidays.prior.scale = 0.5, yearly.seasonality = 4,\n#                         interval.width = 0.95,changepoint.prior.scale = 0.006,daily.seasonality = T)\n#future = make_future_dataframe(model_prophet, periods = 90, freq = 'days')\n#forecast = predict(model_prophet, future)\nm = Prophet(holidays=holidays, holidays_prior_scale=0.5,\n            yearly_seasonality=4,  interval_width=0.95,\n            changepoint_prior_scale=0.006, daily_seasonality=True)\nm.add_regressor('nfl_sunday')\nm.add_seasonality(name='daily', period=60, fourier_order=5)\nm.fit(stats)","826bfb78":"future = m.make_future_dataframe(periods=90, freq=\"D\") # Daily frequency\nfuture['nfl_sunday'] = future['ds'].apply(nfl_sunday)\nfuture.tail()","d1f6bf35":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","b5471224":"fig1 = m.plot(forecast)","4454b7eb":"fig2 = m.plot_components(forecast)","a925fbd3":"# R script: predict_store1_item1=data.frame(date=forecast$ds,forecast=expm1(forecast$yhat))\n# predict_store1_item1$yearmonth=as.yearmon(predict_store1_item1$date)\n# colnames(predict_store1_item1)<-c(\"ds\",\"forecast\",\"yearmonth\")\nps1i1 = forecast[[\"ds\"]]\nps1i1[\"forecast\"] = np.expm1(forecast[\"yhat\"])\nps1i1[\"yearmonth\"] = pd.to_datetime(ps1i1[\"ds\"]).dt.to_period(\"M\")\nps1i1.head()","b1255246":"def smape(outsample, forecast):\n    num = np.abs(outsample-forecast)\n    denom = np.abs(outsample) + np.abs(forecast)\n    return (num\/denom)\/2\n\nstats[\"ds\"] = pd.to_datetime(stats[\"ds\"])","41d47120":"ps1i1[\"ds\"] = pd.to_datetime(ps1i1[\"ds\"])","79e3d684":"# R script: train_predict = merge(stats, ps1i1, by = \"ds\", all.x=T)\ntrain_predict = stats.merge(ps1i1)","3ff8ea6d":"smape_err = smape(train_predict[\"y\"], train_predict[\"forecast\"])\nsmape_err = smape_err[~np.isnan(smape_err)]\nnp.mean(smape_err)","2639cc40":"# Training data from the very beginning\n# Note that I've added some columns\ntrain[\"sales\"] = np.log1p(train[\"sales\"]) ","0ba6d381":"train.columns = [\"ds\", \"store\", \"item\", \"sales\", \"y\", \"m\", \"my\"]\ntrain.head()","fd38822f":"def make_prediction(df):\n    \n    playoffs = ['2013-07-12', '2014-07-12', '2014-07-19',\n                 '2014-07-02', '2015-07-11', '2016-07-17',\n                 '2016-07-24', '2016-07-07','2016-07-24']\n    superbowl = ['2013-01-01', '2013-12-25', '2014-01-01', '2014-12-25','2015-01-01', '2015-12-25','2016-01-01', '2016-12-25',\n                    '2017-01-01', '2017-12-25']\n\n    playoffs = pd.DataFrame({\n      'holiday': 'playoff',\n      'ds': pd.to_datetime(playoffs),\n      'lower_window': 0,\n      'upper_window': 1,\n    })\n    superbowls = pd.DataFrame({\n      'holiday': 'superbowl',\n      'ds': pd.to_datetime(superbowl),\n      'lower_window': 0,\n      'upper_window': 1,\n    })\n    holidays = pd.concat((playoffs, superbowls))\n    \n    m = Prophet(holidays=holidays, holidays_prior_scale=0.5,\n            yearly_seasonality=4,  interval_width=0.95,\n            changepoint_prior_scale=0.006, daily_seasonality=True)\n    m.add_seasonality(name='daily', period=60, fourier_order=5)\n    m.fit(df)\n    future = m.make_future_dataframe(periods=90)\n    forecast = m.predict(future)\n    return forecast","56564bd3":"df = train[(train[\"store\"]==1) & (train[\"item\"] ==2)]\ndf = df[[\"ds\", \"sales\"]]\ndf.columns = [\"ds\", \"y\"]\ndf.head()","d233a372":"prediction = make_prediction(df)\nprediction[[\"ds\", \"yhat\"]].tail()","40e8576a":"# 5.9 Automated forecasting with Prophet: Splitting data by store and item","cff4a094":"Arindam's analysis: We see sales drop from Sunday to Monday so there must be a holiday effect in the sales data. There's a peak in July so this may be due to seasonal sales or summer festivities.\n\nNext step, try excluding change points and include holiday effects. Let's count NFL playoffs as a holiday. And add an extra regressor for NFL sundays.","fa198709":"As mentioned, this value is different than in the kernel I'm reproducing.","16492a4c":"## 4.1 Histogram of sales of an item (daily sales amount)\nHere Arindam writes \"histogram of daily sales price\" but I believe it's actually sales quantity. ","cb06427d":"# 5. Prophet Model\n\n## 5.4 Building the model for store = 1, product = 1","6fbb3066":"Things are a lot smoother now. Note that in the original kernel, I believe that \"NFL Sundays\" wasn't included in the future data- so the results look slightly different. This was raised in a comment and I believe it was confirmed by the author. ","5adaf109":"We can confirm that sales are multipliative with increasing trend and seasonality.","349858c4":"# 3. Missing Values","f8ddb3db":"# 4.3 Sales growth monthly","da804819":"## 4.2 \"Growth\" (?) of sales price by date and change of rate of sales price","576e0e06":"And that's it! I hope I was able to help you out. Please comment below if I made any mistakes, or if there's somewhere I could do better. Thanks!","fada5ec6":"# 4. Individual Feature Visualization","b992f3a7":"# 4.6 Yearly Growth by Item","83d2a927":"# 1. Load Libraries","51824fdf":"# 4.5 Sales growth by store","6b406ec4":"You can see that sales growth is multiplicative with increasing trend and seasonality.","4f06fa86":"Growth of sales increases yearly, but the change in sales is different per year. Rate of change of sales decreased from 2014 to 2015, increased to 2016, then dropped.","7b6ab3bb":"# 5.8 SMAPE Calcuation\n\nI'm not entirely sure if this recreation was done correctly- the results are different than in the original kernel, but that may be because of the error mentioned above.","f0d81b00":"In this kernel I recreate the \"EDA+Prophet+ MLP Neural Network Forecasting\" kernel by Arindam Dutta, found here: https:\/\/www.kaggle.com\/arindamgot\/eda-prophet-mlp-neural-network-forecasting\/notebook. Arindam did a great analysis in R, so I thought I'd recreate his work in Python. Hopefully this is helpful for someone! \n\nPlease note that this is a translation of a kernel from R to Python. The workflow was all devised by Arindam Dutta, who should receive full credit for any and all insight. I will be following their notebook workflow and section numbering.\n\n# 2. Load Data, Summary","629ef3fe":"# 4.4 Growth by Year","3d0d58d0":"Sales is positively skewed."}}