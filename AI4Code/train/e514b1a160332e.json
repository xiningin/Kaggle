{"cell_type":{"42211f43":"code","59cc3d3f":"code","9d3f47d8":"code","05060dfa":"code","020f6b24":"code","dc6afc5c":"code","03464040":"code","a3acf09f":"code","5de3ac05":"code","5dcb4882":"code","5975e2e3":"markdown","850dd250":"markdown","dc3e856f":"markdown","9c5f152d":"markdown","0396286e":"markdown","ab83f6ab":"markdown","d3e06763":"markdown","67955ac9":"markdown","6d9fed16":"markdown"},"source":{"42211f43":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","59cc3d3f":"merchants = pd.read_csv('..\/input\/merchants.csv', index_col='merchant_id')\nmerchants.head()","9d3f47d8":"print(merchants.info())","05060dfa":"print(merchants.memory_usage(deep=True))","020f6b24":"float_cols = merchants.select_dtypes(include=['float'])\n#print(float_cols.dtypes)\n\n\nfor cols in float_cols.columns:\n\tmerchants[cols] = pd.to_numeric(merchants[cols], downcast ='float')\n\nprint(merchants.info())","dc6afc5c":"merchants.head()","03464040":"int_cols = merchants.select_dtypes(include=['int'])\n\n\nfor i in int_cols.columns:\n\tmerchants[i] = pd.to_numeric(merchants[i], downcast ='integer')\n\nprint(merchants.info())","a3acf09f":"merchants.head()","5de3ac05":"for cols in ['category_1', 'category_4', 'most_recent_purchases_range', 'most_recent_sales_range']:\n\tmerchants[cols] = merchants[cols].astype('category')\n\nprint(merchants.info())","5dcb4882":"print(merchants.memory_usage(deep=True))","5975e2e3":"We can see that the DataTypes with object takes up the most memory because Pandas uses pointers to access the string values. \n\nLets first try to reduce float columns by downcasting. ","850dd250":"Lets check out the memory usage of the merchants.csv by pandas dataframeb","dc3e856f":":Tada: Here we can see the reduce of more than 10MB memory usage by just downcasting the float datatype. It can be significant gain seemingly","9c5f152d":"Object takes up the most memory. Below I've identified much more appropriate data types for Object type. Pandas has category type which is much more memory efficient. However keep in mind that you may not be able to apply numeric operations on the category variable.","0396286e":"As you can see from 56.2+ MB we went down to around 19.5MB memory. This should ease the numeric computation for large MB data size most likely","ab83f6ab":"Much better approach might be to encode the categorical variables as integers. That will further reduce the memory usage by the pandas dataframes of merchant.csv. I hope this notebook has been helpful. Let me know your thoughts on comments. ","d3e06763":"In this notebook, I will demonstrate on how to reduce the memory consumption of the Pandas Dataframe which will enable you to carry out the data pre-processing and analysis steps in your less-powerful machine.","67955ac9":"There are 3 data types class; Integer, Float and Object.\n\nLets check out how much each column takes up the memory usage. \n\nThe float64 type represents each floating point value using 64 bits, or 8 bytes. We can save memory by converting within the same type (from float64 to float32 for example), or by converting between types (from float64 to int32) and so on..","6d9fed16":"Lets make use of the Block Manager to see the data types used across the dataframe"}}