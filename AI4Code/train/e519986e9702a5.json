{"cell_type":{"8b8e6a8d":"code","7f25fdad":"code","733ece0d":"code","6cce8706":"code","cc720285":"code","f3c8359c":"code","e1cab966":"code","bce0441c":"code","657d3392":"markdown","1f4942d0":"markdown","3d4d2170":"markdown","bd5803b7":"markdown","f14a3d92":"markdown","dde3ae85":"markdown","4acf61d2":"markdown","9d09a23f":"markdown","108bd5d5":"markdown","0861d025":"markdown"},"source":{"8b8e6a8d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom time import time\n\nprint('loading data file...')\nt0 = time()\ndata = pd.read_csv(\"..\/input\/data.csv\")\nprint(\"loaded in %fs\" % (time() - t0))\ndata.head()\n\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]\nprint('Checking lengths:\\ndata :', len(data), '\\nX :', len(X), '\\ny :', len(y))\n\nclasses_list = np.unique(y)\nclass_to_int = {cur_class: i for i, cur_class in enumerate(classes_list)}\nnb_classes = len(classes_list)\n\nX_flat = X.values.reshape(len(X), -1)\ny_num = [class_to_int[i] for i in y]\n\nprint('Checking pictures range of values:\\nMin :', np.min(X_flat), '\\nMax :', np.max(X_flat))\nprint('Checking target classes:\\n', classes_list)\nprint('Checking numerical targets:\\n', np.unique(y_num))\n\nX_flat = (255 - X_flat) \/ 255\nX_flat = X_flat.astype(np.float32)\ny_num = np.array(y_num).reshape(-1, 1).astype(np.float32)\n\nprint('Checking y_num\\'s shape', y_num.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(X_flat, y_num, test_size=0.2, random_state=0)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n\nimage_border = 32\nimage_shape = (image_border, image_border)\n\n\ndef visualise_samples():\n    X_flat_copy = X_flat.copy()\n    np.random.shuffle(X_flat_copy)\n    for i in range(1, 9):\n        plt.subplot(240 + i)\n        plt.axis('off')\n        image = X_flat_copy[i-1].reshape(image_shape)\n        plt.imshow(image, cmap=plt.cm.gray)\n    plt.show()\n    del X_flat_copy\n\n\nvisualise_samples()","7f25fdad":"mean_images = {}\nfor i, current_class in enumerate(classes_list):\n    print('Computing mean picture for class', current_class)\n    composed_img = np.zeros(image_shape)\n    cnt = 0\n    mask = y_train.reshape(-1) == i\n    for picture in X_train[mask,:]:\n        picture = np.array(picture).reshape(image_shape)\n        composed_img += picture.astype(np.float32)\n        cnt += 1\n    composed_img = composed_img - np.min(composed_img)\n    composed_img = composed_img \/ np.max(composed_img)\n    mean_images[i] = composed_img\n\ndef plot_mean_images(title, images, image_shape, n_col=10, n_row=10):\n    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n    plt.suptitle(title, size=16)\n    for i in images:\n        comp = images[i]\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray)\n        plt.title(i)\n        plt.xticks(())\n        plt.yticks(())\n    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.25, 0.50)\n\nplot_mean_images(\"Mean pictures\", mean_images, (image_border, image_border), 8, 8)","733ece0d":"def mse(imageA, imageB):\n    # the 'Mean Squared Error' between the two images is the\n    # sum of the squared difference between the two images;\n    # NOTE: the two images must have the same dimension\n    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n    err \/= float(imageA.shape[0] * imageA.shape[1])\n    # return the MSE, the lower the error, the more \"similar\"\n    # the two images are\n    return err\n\n\nmodels = np.zeros((len(classes_list), image_border, image_border, 1))\n\nfor i, current_class in enumerate(classes_list):\n    print('Choosing best picture for class', current_class)\n    mean_image = mean_images[i].reshape((image_border, image_border, 1))\n    min_ = 100000000000\n    best_img = None\n    mask = y_train.reshape(-1) == i\n    for picture in X_train[mask, :]:\n        picture = np.array(picture).reshape((1, image_border, image_border, 1))\n        sum_ = mse(mean_image, picture)\n        if sum_ < min_:\n            min_ = sum_\n            best_img = picture\n    models[i, :, :, :] = best_img\n\n\ndef plot_models(title, images, image_shape, n_col=10, n_row=10):\n    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n    plt.suptitle(title, size=16)\n    for i, image in enumerate(images):\n        plt.subplot(n_row, n_col, i + 1)\n        plt.imshow(image.reshape(image_shape), cmap=plt.cm.gray)\n        plt.title(i)\n        plt.xticks(())\n        plt.yticks(())\n    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.25, 0.50)\n\n\nplot_models(\"Models\", models, (image_border, image_border), 8, 8)","6cce8706":"import cv2\n\nX_train_shape = (len(X_train), image_border, image_border, 1)\narr = np.zeros(X_train_shape)\nfor i, y in enumerate(y_train):\n    arr[i, :, :, :] = models[int(y), :, :, :]\nmodels_train = arr\n\nX_valid_shape = (len(X_valid), image_border, image_border, 1)\narr = np.zeros(X_valid_shape)\nfor i, y in enumerate(y_valid):\n    arr[i, :, :, :] = models[int(y), :, :, :]\nmodels_valid = arr\n\nX_test_shape = (len(X_test), image_border, image_border, 1)\narr = np.zeros(X_test_shape)\nfor i, y in enumerate(y_test):\n    arr[i, :, :, :] = models[int(y), :, :, :]\nmodels_test = arr\n\ndel arr\n\nmodels_train = models_train.astype('float32')\nmodels_valid = models_valid.astype('float32')\nmodels_test = models_test.astype('float32')\n\nX_train = X_train.reshape(X_train_shape)\nX_valid = X_valid.reshape(X_valid_shape)\nX_test = X_test.reshape(X_test_shape)\n\nprint('X_train min', np.min(X_train[0]), ' max', np.max(X_train[0]))\nprint('X_valid min', np.min(X_valid[0]), ' max', np.max(X_valid[0]))\nprint('X_test min', np.min(X_test[0]), ' max', np.max(X_test[0]))\nprint('models_train min', np.min(models_train[0]), ' max', np.max(models_train[0]))\nprint('models_valid min', np.min(models_valid[0]), ' max', np.max(models_valid[0]))\nprint('models_test min', np.min(models_test[0]), ' max', np.max(models_test[0]))\n\n\ndef visualize_training_couples(title):\n    n_col = int(np.ceil(np.sqrt(image_border)))\n    n_row = int(np.ceil(np.sqrt(image_border)))\n    plt.figure(figsize=(6. * n_col, 6.26 * n_row))\n    plt.suptitle(title, size=16)\n    for i in range(0, 6 * 4, 6):  # enumerate(X_train[:(n_col * n_row) \/ 3]):\n        plt.subplot(n_row, n_col, i + 1)\n        pic = X_train[i]\n        plt.imshow(pic.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest')\n        plt.subplot(n_row, n_col, i + 2)\n        pic = models_train[i]\n        plt.imshow(pic.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest')\n        plt.subplot(n_row, n_col, i + 3)\n        pic = X_valid[i]\n        plt.imshow(pic.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest')\n        plt.subplot(n_row, n_col, i + 4)\n        pic = models_valid[i]\n        plt.imshow(pic.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest')\n        plt.subplot(n_row, n_col, i + 5)\n        pic = X_test[i]\n        plt.imshow(pic.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest')\n        plt.subplot(n_row, n_col, i + 6)\n        pic = models_test[i]\n        plt.imshow(pic.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest')\n    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)\n\n\nvisualize_training_couples('Training couples')","cc720285":"from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization\nfrom keras.models import Model\n\ndef train_model():\n    input_img = Input(shape=(image_border, image_border, 1))\n    # layer shape 32 x 32\n    x = Conv2D(64, (9, 9), activation='relu', padding='same')(input_img)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, (9, 9), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    # layer shape 16 x 16\n    x = Conv2D(64, (9, 9), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    # layer shape 8 x 8\n    x = Conv2D(64, (7, 7), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    encoded = BatchNormalization(name='encoder')(x)\n    # layer shape 4 x 4\n    # at this point the representation is (4, 4, 64) i.e. 1024-dimensional\n    x = UpSampling2D((2, 2))(encoded)\n    # layer shape 8 x 8\n    x = Conv2D(64, (7, 7), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2, 2))(x)\n    # layer shape 16 x 16\n    x = Conv2D(64, (9, 9), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2, 2))(x)\n    # layer shape 32 x 32\n    x = Conv2D(64, (9, 9), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    decoded = Conv2D(1, (9, 9), activation='sigmoid', padding='same')(x)\n\n    autoencoder = Model(input_img, decoded)\n    autoencoder.summary()\n    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',\n                        metrics=['accuracy'])\n    autoencoder.fit(X_train, models_train,\n                    epochs=10,\n                    batch_size=32,\n                    shuffle=True,\n                    verbose=1,\n                    validation_data=(X_valid, models_valid))\n\n    autoencoder.save('Devanagari_autoencoder.h5')\n    score = autoencoder.evaluate(X_test, models_test)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    return autoencoder\n\n\nautoencoder = train_model()","f3c8359c":"from keras.models import load_model\n\ndef encode_and_save(autoencoder=None):\n    print('Loading model :')\n    t0 = time()\n    # Load previously trained autoencoder\n    if autoencoder is None:\n        autoencoder = load_model('Devanagari_autoencoder.h5')\n    print('Model loaded in: ', time() - t0)\n    \n    encoder = Model(inputs=autoencoder.input,\n                    outputs=autoencoder.get_layer('encoder').output)\n    \n    print('Encoding pictures...')\n    batch_size = 32\n    encoded_train = encoder.predict(X_train, batch_size=batch_size, verbose=1)\n    encoded_valid = encoder.predict(X_valid, batch_size=batch_size, verbose=1)\n    encoded_test = encoder.predict(X_test, batch_size=batch_size, verbose=1)\n    \n    # encoded_train = pd.DataFrame(encoded_train.reshape(X_train.shape[0], -1))\n    # encoded_train.to_csv('Encoded_X_train.csv', header=False, index=False)\n\n    # encoded_valid = pd.DataFrame(encoded_valid.reshape(X_valid.shape[0], -1))\n    # encoded_valid.to_csv('Encoded_X_valid.csv', header=False, index=False)\n\n    # encoded_test = pd.DataFrame(encoded_test.reshape(X_test.shape[0], -1))\n    # encoded_test.to_csv('Encoded_X_test.csv', header=False, index=False)\n\n    return encoded_train, encoded_valid, encoded_test\n\nencoded_train, encoded_valid, encoded_test = encode_and_save(autoencoder)","e1cab966":"from keras.utils import to_categorical\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Sequential\nfrom keras import backend as K\nimport keras\n\n\ndef plot_history(history):\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(loss) + 1)\n    plt.figure()\n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    plt.figure()\n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n\ndef plot_gallery(title, images, image_shape):\n    n_col = int(np.ceil(np.sqrt(images.shape[0])))\n    n_row = int(np.ceil(np.sqrt(images.shape[0])))\n    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n    plt.suptitle(title, size=16)\n    for i, comp in enumerate(images[:(n_col * n_row)]):\n        plt.subplot(n_row, n_col, i + 1)\n        vmax = max(comp.max(), -comp.min())\n        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest',\n                   vmin=-vmax, vmax=vmax)\n        plt.xticks(())\n        plt.yticks(())\n    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)\n\n\nn_row, n_col = 30, 25\n\n\ndef plot_gallery_2(title, images, image_shape, predicted_class=None,\n                   predictions=None, targets=None, n_col=n_col, n_row=n_row):\n    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n    plt.suptitle(title, size=16)\n    for i, comp in enumerate(images[:(n_col * n_row)]):\n        plt.subplot(n_row, n_col, i + 1)\n        vmax = max(comp.max(), -comp.min())\n        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,\n                   interpolation='nearest',\n                   vmin=-vmax, vmax=vmax)\n        idx_sort = np.argsort(predictions[i])[::-1]\n        if predicted_class is not None and predictions is not None and targets is not None:\n            first_guess = idx_sort[0]\n            second_guess = idx_sort[1]\n            third_guess = idx_sort[2]\n            fourth_guess = idx_sort[3]\n            true = targets[i]\n            display = str(true)\n            display += '\/' + str(first_guess)\n            display += '-' + str(second_guess)\n            display += '-' + str(third_guess)\n            display += '-' + str(fourth_guess)\n            plt.title(display)\n        plt.xticks(())\n        plt.yticks(())\n    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.25, 0.50)\n\n\ndef train_dense(encoded_train, encoded_valid, encoded_test ,X_train, X_valid, X_test):\n    y_train_categorical = to_categorical(y_train).astype(np.float32)\n    y_valid_categorical = to_categorical(y_valid).astype(np.float32)\n    y_test_categorical = to_categorical(y_test).astype(np.float32)\n\n    img_rows, img_cols = image_shape\n    nb_channels = 1\n    if K.image_data_format() == 'channels_first':\n        X_train = X_train.reshape(X_train.shape[0], nb_channels, img_rows, img_cols)\n        X_valid = X_valid.reshape(X_valid.shape[0], nb_channels, img_rows, img_cols)\n        X_test = X_test.reshape(X_test.shape[0], nb_channels, img_rows, img_cols)\n        input_shape = (64, 4, 4)\n    else:\n        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, nb_channels)\n        X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, nb_channels)\n        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, nb_channels)\n        input_shape = (4, 4, 64)\n\n    dense_input = Input(shape=input_shape)\n    x = Dense(nb_classes, activation='relu', input_shape=input_shape)(dense_input)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    output = Dense(nb_classes, activation='softmax')(x)\n    dense_model = Model(dense_input, output)\n\n    dense_model.summary()\n\n    dense_model.compile(loss=keras.losses.categorical_crossentropy,\n                        optimizer=keras.optimizers.Adadelta(),\n                        metrics=['accuracy'])\n\n    print('Encoding pictures...')\n    if encoded_train is None:\n        df_encoded_train = pd.read_csv('Encoded_X_train.csv', header=None)\n        encoded_train = np.array(df_encoded_train)\n        encoded_train = encoded_train.reshape((len(df_encoded_train), ) + input_shape)\n        encoded_train = encoded_train.astype(np.float32)\n        del df_encoded_train\n    if encoded_valid is None:\n        df_encoded_valid = pd.read_csv('Encoded_X_valid.csv', header=None)\n        encoded_valid = np.array(df_encoded_valid)\n        encoded_valid = encoded_valid.reshape((len(df_encoded_valid), ) + input_shape)\n        encoded_valid = encoded_valid.astype(np.float32)\n        del df_encoded_valid\n    if encoded_test is None:\n        df_encoded_test = pd.read_csv('Encoded_X_test.csv', header=None)\n        encoded_test = np.array(df_encoded_test)\n        encoded_test = encoded_test.reshape((len(df_encoded_test), ) + input_shape)\n        encoded_test = encoded_test.astype(np.float32)\n        del df_encoded_test\n\n\n    batch_size = 32\n    epochs = 2\n    history = dense_model.fit(encoded_train, y_train_categorical,\n                              batch_size=batch_size,\n                              epochs=epochs,\n                              verbose=1,\n                              validation_data=(encoded_valid, y_valid_categorical))\n\n    plot_history(history)\n\n    dense_model.save('Devanagari_dense.h5')\n\n    predictions = dense_model.predict(encoded_test, batch_size, verbose=1)\n\n    predicted_class = np.argmax(predictions, axis=1)\n\n    mask = predicted_class != np.squeeze(y_test)\n\n    wrong_guesses_images = X_test[mask]\n\n    wrong_guesses_target = encoded_test[mask]\n\n    wrong_guesses_predictions = predictions[mask]\n\n    wrong_guesses_class = predicted_class[mask]\n\n    good_labels = y_test[mask]\n\n    plot_gallery_2(\"Wrong guesses\", wrong_guesses_images, image_shape,\n                   wrong_guesses_class, wrong_guesses_predictions, good_labels,\n                   15, 15)\n\n    plot_gallery_2(\"Wrong guesses target\", wrong_guesses_target, image_shape,\n                   wrong_guesses_class, wrong_guesses_predictions, good_labels,\n                   15, 15)\n\n    score = dense_model.evaluate(encoded_test, y_test_categorical, verbose=1)\n\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    return dense_model\n\ndense = train_dense(encoded_train, encoded_valid, encoded_test, X_train, X_valid, X_test)","bce0441c":"def compile_model(autoencoder=None, dense=None):\n    if autoencoder is None:\n        autoencoder = load_model('Devanagari_autoencoder.h5')\n\n    encoder = Model(inputs=autoencoder.input,\n                    outputs=autoencoder.get_layer('encoder').output)\n    \n    if dense is None:\n        dense = load_model('Devanagari_dense.h5')\n    \n    model = Sequential()\n    model.add(encoder)\n    model.add(dense)\n    model.save('Devanagari_CAE.h5')\n\ncompile_model(autoencoder, dense)","657d3392":"First we'll load our data. Split it between picture pixels and class. And divide it again to have train, valid and test datas. And visualize some samples.","1f4942d0":"All we have to do now, is to compile our autoencoder and dense models into one single model.\nThe size of the final compiled model of the architecture shown in this kernel is 3.5MB","3d4d2170":"We use those encoded representations to train the dense layers classifying the characters.\nAt this point we can already see the accuracy of the model that reaches about 99% of good guesses.\nAt this point, setting the number of kernel to 128 or 256 or choosing higher sizes for kernels actually reduces the accuracy of the model.","bd5803b7":"Now we'll calculate, for each class, an average picture. This will give use a somehow typical representation of each letter\/digit.","f14a3d92":"Now we can pick up, for each class, one sample that represents well the typicaly handwritten character. Those pictures will serve as target models for the autoencoder training.","dde3ae85":"This kernel si designed to demonstrate the use of a convolutional autoencoder to analyse Devanagari's handwritten characters dataset.\nI came to think of this use while I was trying to train a regular convolutional neural network on this dataset and getting stuck at 96% accuracy.\nAt that time, I had read Fran\u00e7ois Chollet's tutorial about autoencoders in keras and I told my-self it could help me get a little bit more accuracy.\nI was first thinking about noise reduction but the lack of precision wasn't a matter of noise.\nSo I thought \"maybe I can match ill written characters to better written characters\".\nI picked up one picture for each character to have them being model characters for their class.\nAfter many experiments, I came to this technique that I'll demonstrate step by step\n","4acf61d2":"Once trained and saved, you can load your model, extract the encoder part, and make it encode the training sets and save them into CSV files (uncomment related lines for personnal use).","9d09a23f":"Once we've prepared our data. We'll make up arrays to feed to our model for training, and check up that couples are correct.","108bd5d5":"Choosing model characters this way might not be the best ever. But from my tryings, it seems to be the most effective way. It's a kind of objective way to analyse the dataset at least.","0861d025":"Now the most important part begins! We'll train our model over 10 epochs to reach good accuracy. Don't expect to see over 90% accuracy on this train. It should be stuck around 66%. But it's ok!\nWhat we want here is to reduce the loss of the model.\nThe design of the autoencoder here is over 4 layers of 64 kernels, reducing the initial dimension expansion over steps to get back to 1024 dimensions. Pictures are 32 x 32 pixels, so 1024 dimensions, the first convolutional layer expands dimensions to a 32 x 32 px picture over 64 channels, which is 65536 dimensions, and the encoded representation is 4 x 4 x 64 = 1024 dimensions as well.\nThis shows good perfomance but you can reduce it to 3 layers (removing the second one and the one before the last convolutional layer), and also reduce dimension gradualy to pass on from 64 kernels to 32, then 16, then 8, which would give you a model of only about 1MB still reaching 97% accuracy.\nOn my computer, with GPU acceleration thanks to Cuda 9.2 Drivers, I can train this autoencoder within two hours."}}