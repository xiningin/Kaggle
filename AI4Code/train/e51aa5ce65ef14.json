{"cell_type":{"a151add7":"code","6e7b30e3":"code","67999ff0":"code","b931bb61":"code","82a58717":"code","db2bb6ce":"code","74067790":"code","e06ee9e4":"code","d4f81476":"code","8923fe68":"code","2eccfc15":"code","1b72695c":"code","b014e8f8":"code","d4cfacdd":"code","9260b9c5":"code","83616a5e":"markdown","7f3965d8":"markdown","7ce5d47e":"markdown","147364b9":"markdown","1aae1a6d":"markdown","77f5d758":"markdown","3fa66638":"markdown","853e0c5b":"markdown","144b8d3c":"markdown","a052cc8b":"markdown","90242c7c":"markdown","e2757377":"markdown","4fa7c2d4":"markdown","9e363d84":"markdown","762eec2d":"markdown"},"source":{"a151add7":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn.functional as F\n\nimport os\nprint(os.listdir(\"..\/input\/cell_images\/cell_images\/\"))","6e7b30e3":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","67999ff0":"train_transforms = transforms.Compose([transforms.Resize((120, 120)),\n                                       transforms.ColorJitter(0.05),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.RandomVerticalFlip(),\n                                       transforms.RandomRotation(20),\n                                       transforms.ToTensor(), \n                                       transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n                                     ])","b931bb61":"image_dir = \"..\/input\/cell_images\/cell_images\/\"\ntrain_set = datasets.ImageFolder(image_dir, transform=train_transforms)","82a58717":"test_size = 0.2\n\nnum_train = len(train_set)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\n\ntest_split = int(np.floor((test_size) * num_train))\ntest_index, train_index = indices[:test_split - 1], indices[test_split - 1:]\n\ntrain_sampler = SubsetRandomSampler(train_index)\ntest_sampler = SubsetRandomSampler(test_index)\n\ntrain_loader = DataLoader(train_set, sampler=train_sampler, batch_size=104)\ntest_loader = DataLoader(train_set, sampler=test_sampler, batch_size=58)\nprint(\"Images in Test set: {}\\nImages in Train set: {}\".format(len(test_index), len(train_index)))","db2bb6ce":"classes=['infected','uninfected']","74067790":"def imshow(img):\n    img = img \/ 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    \nimages, labels = next(iter(train_loader))\n\nfig = plt.figure(figsize=(25, 15))\n\nfor i in range(10):\n    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[], title=classes[labels[i]])\n    imshow(images[i])\nplt.show()","e06ee9e4":"class MosquitoNet(nn.Module):\n    \n    def __init__(self):\n        super(MosquitoNet, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n            \n        self.fc1 = nn.Linear(64*15*15, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 2)\n        self.drop = nn.Dropout2d(0.2)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0), -1)    # flatten out a input for Dense Layer\n        out = self.fc1(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        out = self.fc3(out)\n        \n        return out\n        ","d4f81476":"model = MosquitoNet()\nmodel.to(device)\nerror = nn.CrossEntropyLoss()\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)","8923fe68":"num_epochs = 20\nbatch_size = 100 \n\nfor epoch in range(num_epochs):\n    train_loss = 0.\n    model.train()    # explictily stating the training\n    \n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n        train = images.view(-1, 3, 120, 120)\n        outputs = model(train)\n        \n        optimizer.zero_grad()\n        loss = error(outputs, labels)\n        loss.backward()    #back-propagation\n        optimizer.step()\n        \n        train_loss += loss.item() * batch_size\n     \n    print(\"Epoch: {}, Loss: {:.4f}\".format(epoch + 1, train_loss \/ len(train_loader.dataset)))","2eccfc15":"torch.save(model.state_dict(), \"model.pt\")","1b72695c":"correct = 0\ntotal = 0\nclass_total = [0 for _ in range(2)]\nclass_correct = [0 for _ in range(2)]\nbatch_size = 58\n# Lists used in Confusion Matrix\nactual = []\npredict = []\n\nmodel.eval()    # explicitly stating the testing \nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to (device)\n        \n        actual.append(labels.data.tolist())\n        test = images.view(-1, 3, 120, 120)\n        outputs = model(test)\n        predicted = torch.max(outputs, 1)[1]\n        predict.append(predicted.data.tolist())\n        total += len(labels)\n        correct += (predicted == labels).sum().item()\n        # Calculating classwise accuracy\n        c = (predicted == labels).squeeze()\n        for i in range(batch_size):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n        \nprint(\"Accuracy on the Test set: {:.2f}%\".format(correct * 100 \/ total))\nprint()\nfor i in range(2):\n    print(\"Accuracy of {} :  {:.2f}%   [{} \/ {}]\".format(classes[i], class_correct[i] * 100 \/ class_total[i], \n                                           class_correct[i], class_total[i]))","b014e8f8":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nimport itertools\n\n#flatten out 2D list into 1D\nactual = list(itertools.chain.from_iterable(actual))\npredict = list(itertools.chain.from_iterable(predict))\n","d4cfacdd":"results = confusion_matrix(actual, predict)\nprint(\"Accuracy Score: \")\nprint(\"{:.4f}\".format(accuracy_score(actual, predict)))\nprint()\nprint(\"Report: \")\nprint(classification_report(actual, predict))\nprint()\nprint(\"Confusion Matrix: \")\nprint(pd.DataFrame(results, columns=[\"Predicted No\", \"Predicted Yes\"], index=[\"Actual No\", \"Actual Yes\"]))","9260b9c5":"import seaborn as sns\n\nsns.heatmap(results, cmap=\"magma\", annot=True, fmt=\"d\", cbar=False)","83616a5e":"### CNN class\n* Creating a CNN class as MosquitoNet.\n* It has following layers:\n    * 3 Convolutional layers with MaxPooling (Stride 2)\n    * All 3 convulations are \"Same Convolution with some zero-padding\"\n    * 3 FullyConnected Layers\n* BatchNormalization is used after convulations \n* ReLU is used as a activation function\n* Dropout is used with p = 0.5\n\n* Images are changed from input to output layers in following way:\n    * In Layer 1 : Input: 120 \\* 120 \\* 3, Output: 60 \\* 60 \\* 16\n    * In Layer 2 : Input: 60 \\* 60 \\* 16, Output: 30 \\* 30 \\* 32\n    * In Layer 3 : Input: 30 \\* 30 \\* 32, Output: 15 \\* 15 \\* 64\n    * In FC1 : Input: 14440, Output: 512\n    * In FC2 : Input: 512, Output: 128\n    * In FC3 : Input: 128, Output: 2","7f3965d8":"### Training a Model","7ce5d47e":"### Data Augmentation\n\n* > Using Pytorch transformation function to augment a dataset. I tried different transformations but find these helpful.\n* > All the images are resized to 120 * 120 as an input to custom CNN class.\n* > Applying different transformations like RandomHorizontalFlip( ), RandomRotation( ) etc. There is a 50\/50 chance whether it would change the image or not.\n* > Converting images into Pytorch tensors.\n* > Also normalizing them with mean [0.5, 0.5., 0.5] and standard deviation [0.5, 0.5, 0.5]. All tensors are in range of [-1, 1].\n    > It won't increase size of the dataset as transformation performs one by one on images.","147364b9":"> Displaying it as a plot","1aae1a6d":"> Visualizing some Images...","77f5d758":"### Creating a dataset","3fa66638":"> Making a model and defining error and optimizing algorithm.","853e0c5b":"**Importing libraries**","144b8d3c":"> Calculating a Confusion Matrix","a052cc8b":"**I've achieved a Test Accuracy of more than 96.5 %. That's not bad. Please suggest improvements. Thank you :) **","90242c7c":"> Saving a model in disk","e2757377":"> We have images in 2 classes: Infected and Uninfected","4fa7c2d4":"### Testing a model","9e363d84":"> Loading a images using generic dataloader ImageFolder.","762eec2d":"> Use the GPU if available for computations."}}