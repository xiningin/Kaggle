{"cell_type":{"548f6e01":"code","74240268":"code","62dab855":"code","df53a409":"code","4c1ffb83":"code","817f4ca7":"code","e9257463":"code","73ccbd65":"code","8d7c4bed":"code","d00bf504":"code","b38bba16":"code","9a760a36":"code","7d4bab1f":"code","91df4e16":"code","358e41e5":"code","8bbbb37b":"code","3f53a742":"code","9d71bf64":"code","86a1dc9e":"code","89919cef":"markdown","91539c45":"markdown","d604d9d9":"markdown","29f89f0c":"markdown","4f276fb8":"markdown","a61d3668":"markdown","eb23bd14":"markdown","098d020b":"markdown","5da1694a":"markdown","b434b8ca":"markdown","ea743316":"markdown"},"source":{"548f6e01":"from datetime import datetime\nimport os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.stats import skew\n\nfrom IPython.core.display import display\nfrom tqdm import tqdm\ntqdm.pandas()\n\nprint(os.listdir(\"..\/input\"))","74240268":"# \u5192\u982d\u306epivot_table\u3092\u7528\u3044\u305f\u30d0\u30fc\u30b8\u30e7\u30f3\n# \u6b20\u640d\u5024\u304c\u542b\u307e\u308c\u308b\u3053\u3068\u306b\u6ce8\u610f\u3059\u308b\n\ntick = datetime.now()\ntrain_df = pd.read_csv(\"..\/input\/training_set.csv\", dtype={\"object_id\": np.uint32,\n                                                           \"mjd\": np.float64,\n                                                           \"passband\": np.uint8,\n                                                           \"flux\": np.float32,\n                                                           \"flux_err\": np.float32,\n                                                           \"detected\": np.uint8})\ntrain_meta_df = pd.read_csv('..\/input\/training_set_metadata.csv')\ntock = datetime.now()\nprint(\"load_data: {} ms\".format((tock - tick).seconds * 1000 + ((tock - tick).microseconds \/ 1000)))\n\ntick = datetime.now()\n\n# pivot_table\u306eindex\u3092rank\u3092\u7528\u3044\u3066\u4f5c\u6210\u3059\u308b\ntrain_df[\"rank\"] = train_df.groupby([\"object_id\", \"passband\"])[\"mjd\"].rank()\n\nflux = train_df.pivot_table(columns=[\"object_id\", \"passband\"],\n                            index=\"rank\",\n                            values=\"flux\",\n                            aggfunc=\"mean\")\ndflux = train_df.pivot_table(columns=[\"object_id\", \"passband\"],\n                             index=\"rank\",\n                             values=\"flux_err\",\n                             aggfunc=\"mean\")\n\n# \u5217\u306bNaN\u304c\u542b\u307e\u308c\u308b\u306e\u3067\u6271\u3044\u306b\u6ce8\u610f\u3059\u308b\nflux_mean = np.sum(flux*np.square(flux\/dflux), axis=0)\/np.sum(np.square(flux\/dflux), axis=0)\nflux_std = np.std(flux\/flux_mean, ddof = 1, axis=0)\nflux_amp = (np.max(flux, axis=0) - np.min(flux, axis=0))\/flux_mean\nflux_mad = np.nanmedian(np.abs((flux - np.nanmedian(flux, axis=0))\/flux_mean), axis=0) # array\nflux_beyond = np.sum(np.abs(flux - flux_mean) > np.std(flux, ddof = 1, axis=0), axis=0)\/flux.count()\nflux_skew = skew(flux, nan_policy=\"omit\", axis=0)  # masked_array\n\nresult_df = pd.concat([flux_mean.reset_index(name=\"flux_mean\"),\n                      flux_std.reset_index(name=\"flux_std\").iloc[:, 2:],\n                      flux_amp.reset_index(name=\"flux_amp\").iloc[:, 2:],\n                      flux_beyond.reset_index(name=\"flux_beyond\").iloc[:, 2:]], axis=1)\nresult_df[\"flux_mad\"] = flux_mad\nresult_df[\"flux_skew\"] = flux_skew\ncolnames = [\"flux_mean\", \"flux_std\", \"flux_amp\", \"flux_beyond\", \"flux_mad\", \"flux_skew\"]\n\nfor j in range(6):\n    train_meta_df = train_meta_df.merge(result_df.loc[result_df.passband == j, :]\n                                                 .rename(columns={colname: \"{}_{}\".format(colname, j) for colname in colnames})\n                                                 .drop(\"passband\", axis=1),\n                                        how=\"left\",\n                                        on=[\"object_id\"])\ntock = datetime.now()\nprint(\"processing_time: {} sec\".format((tock - tick).seconds))\n\ntrain_meta_df.head()","62dab855":"# \u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30c7\u30fc\u30bf\u3092\u7528\u610f\u3059\u308b\ndammy_dics = []\nfor i in range(5):\n    for j in range(10):\n        dammy_dics.append({\"time\": i, \"category\": j, \"price\": 10*i + j})\n\ndammy_df = pd.DataFrame(dammy_dics)\ndammy_df.head(10)","df53a409":"# DataFrame.pivot_table()\u3067\u30af\u30ed\u30b9\u96c6\u8a08\u8868\u3092\u4f5c\u308c\u308b\ndammy_piv = dammy_df.pivot_table(index=\"time\",\n                                 columns=\"category\",\n                                 values=\"price\",\n                                 aggfunc=\"sum\")\ndisplay(dammy_piv)","4c1ffb83":"# pivot_table\u306f\u884c\u5217\u3068\u3057\u3066\u8a08\u7b97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\n# \u5404\u6570\u5024\u3092\u4e8c\u4e57\u3059\u308b\nprint(\"piv^2\")\ndisplay(np.square(dammy_piv))\n\n# \u30b9\u30ab\u30e9\u30fc\u3067\u5272\u308b\"\nprint(\"piv \/ 10\")\ndisplay(dammy_piv \/ 10)\n\n# pivot_table\u540c\u58eb\u3092\u8db3\u3059\nprint(\"piv + piv^2\")\ndisplay(dammy_piv + np.square(dammy_piv))","817f4ca7":"# \u5217\u65b9\u5411\u3078\u306e\u96c6\u8a08\n# axis\u3092\u6307\u5b9a\u3057\u306a\u3044\u3068\u81ea\u52d5\u7684\u306b\u5217\u65b9\u5411\u306e\u96c6\u8a08\u306b\u306a\u308a\u3001Series\u304c\u8fd4\u3063\u3066\u304f\u308b\ndisplay(dammy_piv.mean())\n\n# pivot_table\u306b\u5bfe\u3057\u3066Series\u3067\u8a08\u7b97\u3059\u308b\u3068\u3068\u5217\u65b9\u5411\u306bbroadcast\u3055\u308c\u308b\ndisplay(dammy_piv - dammy_piv.mean())","e9257463":"# \"\u884c\u65b9\u5411\u3078\u306e\u96c6\u8a08\u3082\u53ef\u80fd\u3060\u304c\"\ndisplay(dammy_piv.mean(axis=1))\n\n# \u3044\u3044\u611f\u3058\u306bbroadcast\u3057\u3066\u304f\u308c\u306a\u3044\nprint(\"piv - seires\")\ndisplay(dammy_piv - dammy_piv.mean(axis=1))\n\n# \u8ee2\u5024\u3092\u4f7f\u3046\u304f\u3089\u3044\u3057\u304b\u826f\u3044\u65b9\u6cd5\u304c\u601d\u3044\u6d6e\u304b\u3070\u306a\u3044\u306e\u3067\u826f\u3044\u65b9\u6cd5\u304c\u3042\u308c\u3070\u6559\u3048\u3066\u304f\u3060\u3055\u3044\nprint(\"(piv.T - series).T\")\ndisplay((dammy_piv.T - dammy_piv.mean(axis=1)).T)","73ccbd65":"# piv.shift()\u3067\u3072\u3068\u3064\u524d\u306e\u5024\u3092\u3068\u308c\u308b\ndammy_piv.shift(1)","8d7c4bed":"# \u3053\u308c\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u3072\u3068\u3064\u524d\u3068\u306e\u5dee\u5206\u3092\u3068\u308b\u3053\u3068\u304c\u3067\u304d\u308b\ndammy_piv - dammy_piv.shift(1)","d00bf504":"# rolling\u95a2\u6570\u3067\u3001\u79fb\u52d5\u5e73\u5747\u7b49\u3092\u3068\u308b\u3053\u3068\u304c\u3067\u304d\u308b\n# \u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u306f\u81ea\u4fe1\u3092\u542b\u3081\u305f\u4e09\u3064\u306e\u671f\u9593\u5206\u306e\u5e73\u5747\ndammy_piv.rolling(window=3, center=False).mean()","b38bba16":"# shift\u3068\u7d44\u307f\u5408\u308f\u305b\u308b\u3053\u3068\u3067\u3001\u4e00\u3064\u524d\u304b\u3089n\u500b\u524d\u307e\u3067\u306e\u5e73\u5747\u3068\u3044\u3063\u305f\u7279\u5fb4\u91cf\u3092\u4f5c\u308b\u3053\u3068\u304c\u3067\u304d\u308b\ndammy_piv.rolling(window=3, center=False).mean().shift(1)","9a760a36":"# cum\u3007\u3007\u7cfb\u306e\u95a2\u6570\u306f\u305d\u308c\u307e\u3067\u306e\u5408\u8a08\u3092\u8a08\u7b97\u3067\u304d\u308b\n# \u5408\u8a08\ndisplay(dammy_piv.cumsum())","7d4bab1f":"# \u4e0a\u8a18\u307e\u3067\u306e\u30c6\u30af\u30cb\u30c3\u30af\u3092\u99c6\u4f7f\u3059\u308b\u3068\u3001leak\u7121\u3057\u306b\u6642\u7cfb\u5217\u306emean_encoding\u304c\u3067\u304d\u308b\ncum_sum = dammy_df.pivot_table(index=\"time\",\n                               columns=\"category\",\n                               values=\"price\",\n                               aggfunc=\"sum\").cumsum()\ncum_count = dammy_df.pivot_table(index=\"time\",\n                                 columns=\"category\",\n                                 values=\"price\",\n                                 aggfunc=\"count\").cumsum()\ncum_mean = cum_sum \/ cum_count\ncum_mean_without_leakage = cum_mean.shift(1)\ncum_mean_without_leakage","91df4e16":"# \u30c7\u30fc\u30bf\u306e\u30ed\u30fc\u30c9\ntrain_df = pd.read_csv(\"..\/input\/training_set.csv\", dtype={\"object_id\": np.uint32,\n                                                           \"mjd\": np.float64,\n                                                           \"passband\": np.uint8,\n                                                           \"flux\": np.float32,\n                                                           \"flux_err\": np.float32,\n                                                           \"detected\": np.uint8})\ntrain_meta_df = pd.read_csv('..\/input\/training_set_metadata.csv')\ntest_meta_df = pd.read_csv('..\/input\/test_set_metadata.csv')","358e41e5":"# train_df\u3092\u96c6\u8a08\u3057\u3066train_meta\u306b\u7d50\u5408\u3057\u305f\u3044\ndisplay(train_df.head())\ndisplay(train_meta_df.head())","8bbbb37b":"print(\"train_meta: \", train_meta_df.shape)\nprint(\"test_meta: \", test_meta_df.shape)\nprint(\"\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306f\u8a13\u7df4\u30c7\u30fc\u30bf\u306e{:.4}\u500d\".format(test_meta_df.shape[0] \/ train_meta_df.shape[0]))","3f53a742":"# groupby\u7121\u3057\u306b\u6bce\u56de\u53d6\u308a\u51fa\u305d\u3046\u3068\u3059\u308b\u3068\u3068\u3066\u3064\u3082\u306a\u3044\u6642\u9593\u304c\u304b\u304b\u308b\u306e\u30671\/100\u3060\u3051\u8a08\u7b97\nbands = [train_df.passband == b for b in train_df.passband.unique()]\nfor id_ in tqdm(train_df.object_id.unique()[:78]):\n    for band in bands:\n        idx = train_df[(train_df.object_id == id_) & band].index\n        flux, dflux = train_df.loc[idx, \"flux\"], train_df.loc[idx, \"flux_err\"]\n        train_df.loc[idx, \"flux_mean\"] = np.sum(flux*np.square(flux\/dflux))\/np.sum(np.square(flux\/dflux))\n        fluxm = train_df.loc[idx, \"flux_mean\"]\n\n        train_df.loc[idx, \"flux_std\"] = np.std(flux\/fluxm, ddof = 1)\n        train_df.loc[idx, \"flux_amp\"] = (np.max(flux) - np.min(flux))\/fluxm\n        train_df.loc[idx, \"flux_mad\"] = np.median(np.abs((flux - np.median(flux))\/fluxm))\n        train_df.loc[idx, \"flux_beyond\"] = sum(np.abs(flux - fluxm) > np.std(flux, ddof = 1))\/len(flux)\n        train_df.loc[idx, \"flux_skew\"] = skew(flux)","9d71bf64":"# 2. groupby\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3059\u308b\ntick = datetime.now()\ntrain_df = pd.read_csv(\"..\/input\/training_set.csv\", dtype={\"object_id\": np.uint32,\n                                                           \"mjd\": np.float64,\n                                                           \"passband\": np.uint8,\n                                                           \"flux\": np.float32,\n                                                           \"flux_err\": np.float32,\n                                                           \"detected\": np.uint8})\ntrain_meta_df = pd.read_csv('..\/input\/training_set_metadata.csv')\ntock = datetime.now()\nprint(\"load_data: {} ms\".format((tock - tick).seconds * 1000 + ((tock - tick).microseconds \/ 1000)))\n\ntick = datetime.now()\n\ndef agg_func(x):\n    d = {}\n    flux, dflux = x[\"flux\"], x[\"flux_err\"]\n    flux_mean = np.sum(flux*np.square(flux\/dflux))\/np.sum(np.square(flux\/dflux))\n    d[\"flux_mean\"] = flux_mean\n    d[\"flux_std\"] = np.std(flux\/flux_mean, ddof = 1)\n    d[\"flux_amp\"] = (np.max(flux) - np.min(flux))\/flux_mean\n    d[\"flux_beyond\"] = np.sum(np.abs(flux - flux_mean) > np.std(flux, ddof = 1))\/flux.shape[0]\n    d[\"flux_mad\"] = np.median(np.abs((flux - np.median(flux))\/flux_mean))\n    d[\"flux_skew\"] = skew(flux)\n    return pd.Series(d, index = [\"flux_mean\", \"flux_std\", \"flux_amp\", \"flux_mad\", \"flux_beyond\", \"flux_skew\"])\n\nresult_df = train_df.groupby([\"object_id\", \"passband\"]).progress_apply(agg_func).reset_index()\n\ncolnames = [\"flux_mean\", \"flux_std\", \"flux_amp\", \"flux_mad\", \"flux_beyond\", \"flux_skew\"]\nfor j in range(6):\n    train_meta_df = train_meta_df.merge(result_df.loc[result_df.passband == j, :]\n                                                 .rename(columns={colname: \"{}_{}\".format(colname, j) for colname in colnames})\n                                                 .drop(\"passband\", axis=1),\n                                        how=\"left\",\n                                        on=[\"object_id\"])\n\ntock = datetime.now()\ntmp = print(\"total_processing: {} sec\".format((tock - tick).seconds))\ntrain_meta_df.head()","86a1dc9e":"# \u6b20\u640d\u5024\u304c\u542b\u307e\u308c\u308b\u3053\u3068\u306b\u6ce8\u610f\u3059\u308b\n\ntick = datetime.now()\ntrain_df = pd.read_csv(\"..\/input\/training_set.csv\", dtype={\"object_id\": np.uint32,\n                                                           \"mjd\": np.float64,\n                                                           \"passband\": np.uint8,\n                                                           \"flux\": np.float32,\n                                                           \"flux_err\": np.float32,\n                                                           \"detected\": np.uint8})\ntrain_meta_df = pd.read_csv('..\/input\/training_set_metadata.csv')\ntock = datetime.now()\nprint(\"load_data: {} ms\".format((tock - tick).seconds * 1000 + ((tock - tick).microseconds \/ 1000)))\n\ntick = datetime.now()\n\n# pivot_table\u306eindex\u3092rank\u3092\u7528\u3044\u3066\u4f5c\u6210\u3059\u308b\ntrain_df[\"rank\"] = train_df.groupby([\"object_id\", \"passband\"])[\"mjd\"].rank()\n\nflux = train_df.pivot_table(columns=[\"object_id\", \"passband\"],\n                            index=\"rank\",\n                            values=\"flux\",\n                            aggfunc=\"mean\")\ndflux = train_df.pivot_table(columns=[\"object_id\", \"passband\"],\n                             index=\"rank\",\n                             values=\"flux_err\",\n                             aggfunc=\"mean\")\n\n# \u5217\u306bNaN\u304c\u542b\u307e\u308c\u308b\u306e\u3067\u6271\u3044\u306b\u6ce8\u610f\u3059\u308b\nflux_mean = np.sum(flux*np.square(flux\/dflux), axis=0)\/np.sum(np.square(flux\/dflux), axis=0)\nflux_std = np.std(flux\/flux_mean, ddof = 1, axis=0)\nflux_amp = (np.max(flux, axis=0) - np.min(flux, axis=0))\/flux_mean\nflux_mad = np.nanmedian(np.abs((flux - np.nanmedian(flux, axis=0))\/flux_mean), axis=0) # array\nflux_beyond = np.sum(np.abs(flux - flux_mean) > np.std(flux, ddof = 1, axis=0), axis=0)\/flux.count()\nflux_skew = skew(flux, nan_policy=\"omit\", axis=0)  # masked_array\n\nresult_df = pd.concat([flux_mean.reset_index(name=\"flux_mean\"),\n                      flux_std.reset_index(name=\"flux_std\").iloc[:, 2:],\n                      flux_amp.reset_index(name=\"flux_amp\").iloc[:, 2:],\n                      flux_beyond.reset_index(name=\"flux_beyond\").iloc[:, 2:]], axis=1)\nresult_df[\"flux_mad\"] = flux_mad\nresult_df[\"flux_skew\"] = flux_skew\ncolnames = [\"flux_mean\", \"flux_std\", \"flux_amp\", \"flux_beyond\", \"flux_mad\", \"flux_skew\"]\n\nfor j in range(6):\n    train_meta_df = train_meta_df.merge(result_df.loc[result_df.passband == j, :]\n                                                 .rename(columns={colname: \"{}_{}\".format(colname, j) for colname in colnames})\n                                                 .drop(\"passband\", axis=1),\n                                        how=\"left\",\n                                        on=[\"object_id\"])\ntock = datetime.now()\nprint(\"processing_time: {} sec\".format((tock - tick).seconds))\n\ntrain_meta_df.head()","89919cef":"# PLAsTiCC\u306e\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305f\u5b9f\u4f8b","91539c45":"\u3053\u308c\u3060\u3068train_data\u306e\u51e6\u7406\u3067\u3082\u4e00\u6642\u9593\u4ee5\u4e0a\u304b\u304b\u308b\u306e\u3067\u3001\u305d\u306e450\u500d\u3082\u3042\u308btest_data\u3092\u51e6\u7406\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u306a\u3044\n\n## groupby\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3059\u308b","d604d9d9":"\u4e00\u6642\u9593\u4ee5\u4e0a\u304b\u304b\u3063\u305f\u51e6\u7406\u3092\u4e8c\u5206\u534a\u3067\u7d42\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u305f\u304c\u3001test\u30c7\u30fc\u30bf\u3060\u3068900\u5206 = 15\u6642\u9593\u304b\u304b\u308b\u306e\u3067\u307e\u3060\u307e\u3060\u9ad8\u901f\u5316\u3057\u305f\u3044\n\n## pivot_table\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3059\u308b","29f89f0c":"### \u5dee\u5206","4f276fb8":"### \u79fb\u52d5\u5e73\u5747","a61d3668":"groupby\u3067\u4e8c\u5206\u534a\u307b\u3069\u304b\u304b\u3063\u3066\u3044\u305f\u51e6\u7406\u3092\u3001\u308f\u305a\u304b4\u79d2\u3067\u51e6\u7406\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u305f!!\n\ntest\u30c7\u30fc\u30bf\u306f\u5927\u304d\u3059\u304e\u308b\u306e\u3067\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u3088\u3046\u3068\u3059\u308b\u3068\u30e1\u30e2\u30ea\u306b\u4e57\u308a\u5207\u3089\u306a\u3044\u304c\u3001\u79c1\u306e\u74b0\u5883(RAM 32GB)\u3060\u306810\u5206\u5272\u3057\u3066\u8a08\u7b97\u3057\u304a\u304a\u3088\u305d30\u5206\u304f\u3089\u3044\u3067\u51e6\u7406\u304c\u7d42\u308f\u3063\u305f\u3002\n","eb23bd14":"### \u3042\u308b\u6642\u70b9\u307e\u3067\u306e\u5408\u8a08\u3092\u8a08\u7b97\u3059\u308b","098d020b":"## \u30c0\u30df\u30fc\u30c7\u30fc\u30bf\u3067\u306e\u89e3\u8aac\n### \u57fa\u672c\u7684\u306a\u6f14\u7b97","5da1694a":"pivot_table\u3092\u7528\u3044\u305f\u9ad8\u901f\u30c7\u30fc\u30bf\u51e6\u7406\n==========================\n\n# TL;DR\n\u30ab\u30c6\u30b4\u30ea\u3054\u3068\u306e\u96c6\u8a08\u3092\u3057\u305f\u3044\u3068\u304d\u306bpivot_table\u3092\u7528\u3044\u308b\u3068\u76f4\u611f\u7684\u3067\u9ad8\u901f\u306a\u51e6\u7406\u304c\u3067\u304d\u308b","b434b8ca":"[Starter Kit](http:\/\/www.kaggle.com\/michaelapers\/the-plasticc-astronomy-starter-kit)  \u306e3\u7ae0\u306eLightCurve\u5185\u306b\u3042\u308b\u7279\u5fb4\u91cf\u3092\u8a08\u7b97\u3059\u308b\u3002","ea743316":"## \u611a\u76f4\u306b\u8a08\u7b97\u3059\u308b"}}