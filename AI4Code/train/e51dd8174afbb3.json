{"cell_type":{"4898fb53":"code","e8a721de":"code","1d74fd55":"code","cd572294":"code","e6420ede":"code","e72ccca5":"code","38ffc87a":"code","78fb432a":"code","213b7902":"code","cca5a59d":"code","5e3d458c":"code","dfade62c":"code","f832a0fd":"code","82cef332":"code","0320edfb":"code","0fc0ebdc":"code","42e4595c":"code","a31ac83c":"code","df850b92":"code","e8b89fdb":"code","d53eda75":"code","902f4d5d":"code","5dabd664":"code","9004d47c":"code","b300c1bf":"code","b11a2990":"code","44de3de7":"code","05f18586":"code","02ddcb82":"code","a5f31aa8":"code","6cb50259":"code","a88c1612":"code","d7ff7330":"markdown","7147ff27":"markdown","831bc445":"markdown","a516d037":"markdown","71535220":"markdown","a8c724c3":"markdown"},"source":{"4898fb53":"import os\nimport glob\nimport torch\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torchvision.transforms as tt\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.datasets.folder import default_loader\nimport matplotlib.pyplot as plt\n%matplotlib inline","e8a721de":"df = pd.read_csv(\"..\/input\/10-monkey-species\/monkey_labels.txt\")","1d74fd55":"label_dictionary = {\n    \n    \"n0\":\"mantled_howler\",\n    \"n1\":\"patas_monkey\",\n    \"n2\":\"bald_uakari\",\n    \"n3\":\"japanese_macaque\",\n    \"n4\":\"pygmy_marmoset\",\n    \"n5\":\"white_headed_capuchin\",\n    \"n6\":\"silvery_marmoset\",\n    \"n7\":\"common_squirrel_monkey\",\n    \"n8\":\"black_headed_night_monkey\",\t\n    \"n9\":\"nilgiri_langur\"\n}\n\n\ncategories = {\n    \n    \"mantled_howler\":0,\n    \"patas_monkey\":1,\n    \"bald_uakari\":2,\n    \"japanese_macaque\":3,\n    \"pygmy_marmoset\":4,\n    \"white_headed_capuchin\":5,\n    \"silvery_marmoset\":6,\n    \"common_squirrel_monkey\":7,\n    \"black_headed_night_monkey\":8,\n    \"nilgiri_langur\":9\n}","cd572294":"def data_dir(phase):\n    root_dir = \"..\/input\/10-monkey-species\/\"\n    target_path = os.path.join(root_dir + phase + \"\/**\/**\/*.jpg\")\n    path_list = []\n    for path in glob.glob(target_path):\n        path_list.append(path)\n    return path_list\n\ntrain_list = data_dir(phase=\"training\")","e6420ede":"def connect_names(directory):\n    for index in range(len(directory)):\n        split_path = directory[index].split(\"\/\")\n        get_index = split_path[-2]\n        get_name = label_dictionary[get_index]\n        get_name_value = categories[get_name]\n        \nnew_dir = connect_names(train_list)","e72ccca5":"class MyDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.root_dir)\n    \n    def __getitem__(self, index):\n        \n        image_path = self.root_dir[index]\n        image = default_loader(image_path)\n        \n        split = image_path.split(\"\/\")\n        get_index = split[-2]\n        get_label = label_dictionary[get_index]\n        label_value = categories[get_label]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label_value","38ffc87a":"dataset = ds\nfor idx, (data, image) in enumerate(dataset):\n    print(idx)","78fb432a":"transform_ds = tt.Compose([\n    tt.Resize((224,244)),\n    tt.RandomHorizontalFlip(),\n    tt.ToTensor()\n])\n\nds = MyDataset(root_dir=train_list, transform=transform_ds)","213b7902":"val_ds_size = int(len(ds) * 0.1)\ntrain_ds_size = len(ds) - val_ds_size\ntrain_ds, val_ds = random_split(ds, [train_ds_size, val_ds_size])","cca5a59d":"batch_size= 128\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)","5e3d458c":"def show_batch(train_dl):\n    for images, _ in train_dl:\n        fig, ax = plt.subplots(figsize=(12,12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:32], nrow=8).permute(1,2,0))\n        break\n        \nshow_batch(train_dl)","dfade62c":"def accuracy(out, labels):\n    _, preds = torch.max(out, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_loss = [x[\"val_loss\"] for x in outputs]\n        epoch_loss = torch.stack(batch_loss).mean()\n        batch_acc = [x[\"val_acc\"] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()\n        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n    \n    def epoch_end(self, epoch, epochs, result):\n        print(\"Epoch: [{}\/ {}], last_lr: {:.6f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch+1, epochs, result[\"lrs\"][-1], result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))","f832a0fd":"class ResNet(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = models.resnet34(pretrained=True)\n        number_of_features = self.network.fc.in_features\n        self.network.fc = nn.Linear(number_of_features, 10)\n        \n    def forward(self, xb):\n        return self.network(xb)\n    \n    def freeze(self):\n        for param in self.network.parameters():\n            param.requires_grad=False\n        for param in self.network.fc.parameters():\n            param.requires_grad=True\n            \n    def unfreeze(self):\n        for param in self.network.parameters():\n            param.requires_grad=True","82cef332":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n        \ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for x in self.dl:\n            yield to_device(x, self.device)\n            \n    def __len__(self):\n        return len(self.dl)\n    \ndevice = get_device()\ndevice","0320edfb":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","0fc0ebdc":"@torch.no_grad()\ndef evaluate(model, val_dl):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_dl]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\"lr\"]\n    \ndef fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.Adam):\n    \n    history = []\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    \n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n                                               steps_per_epoch=len(train_dl))\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = []\n        lrs = []\n        for batch in tqdm(train_dl):\n            loss = model.training_step(batch)\n            train_loss.append(loss)\n            loss.backward()\n            \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        result = evaluate(model, val_dl)\n        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n        result[\"lrs\"] = lrs\n        model.epoch_end(epoch, epochs, result)\n        history.append(result)\n    return history","42e4595c":"model = to_device(ResNet(), device)","a31ac83c":"history = [evaluate(model, val_dl)]\nhistory","df850b92":"model.freeze()","e8b89fdb":"epochs = 5\nmax_lr = 10e-4\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","d53eda75":"history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n                        weight_decay=weight_decay, grad_clip=grad_clip,\n                        opt_func=opt_func)","902f4d5d":"model.unfreeze()","5dabd664":"epochs = 5\nmax_lr = 10e-5\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","9004d47c":"history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n                        weight_decay=weight_decay, grad_clip=grad_clip,\n                        opt_func=opt_func)","b300c1bf":"def test_dir(phase):\n    root_dir = \"..\/input\/10-monkey-species\/\"\n    test_dir = os.path.join(root_dir+phase+\"\/**\/**\/*.jpg\")\n    path_list = []\n    for path in glob.glob(test_dir):\n        path_list.append(path)\n    return path_list\ntest_directory = test_dir(phase=\"validation\")   ","b11a2990":"transform_test = tt.Compose([\n    tt.Resize((224,224)),\n    tt.ToTensor()\n])\n\ntest_ds = MyDataset(root_dir=test_directory, transform=transform_test)","44de3de7":"test_dl = DataLoader(test_ds, batch_size, num_workers=3, pin_memory=True)\ntest_dl = DeviceDataLoader(test_dl, device)","05f18586":"def prediction(images, model):\n    xb = to_device(images.unsqueeze(0), device)\n    out = model(xb)\n    _, preds = torch.max(out, dim=1)\n    prediction = list(categories)[preds[0].item()]\n    return prediction","02ddcb82":"images, labels = test_ds[10]\nprint(\"Label:\", list(categories)[labels])\nprint(\"Prediction:\", prediction(images, model))\nplt.imshow(images.permute(1,2,0))","a5f31aa8":"images, labels = test_ds[200]\nprint(\"Label:\", list(categories)[labels])\nprint(\"Prediction:\", prediction(images, model))\nplt.imshow(images.permute(1,2,0))","6cb50259":"def plot_loss(history):\n    train_loss = [x.get(\"train_loss\") for x in history]\n    val_loss = [x[\"val_loss\"] for x in history]\n    plt.plot(train_loss, \"-rx\")\n    plt.plot(val_loss, \"-bx\")\n    plt.legend([\"Train loss\", \"Validation loss\"])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss vs number of Epochs\")\n\nplot_loss(history)","a88c1612":"def plot_accuracy(history):\n    accuracy = [x[\"val_acc\"] for x in history]\n    plt.plot(accuracy, \"-bx\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.title(\"Accuracy vs number of Epochs\")\n\nplot_accuracy(history)","d7ff7330":"# Monkeys species","7147ff27":"## Importing the modules","831bc445":"## Predictions","a516d037":"## Model performance","71535220":"## Preparing the data","a8c724c3":"## The model"}}