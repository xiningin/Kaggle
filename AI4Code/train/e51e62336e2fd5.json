{"cell_type":{"8e349bf3":"code","ce386a56":"code","2cc05768":"code","d8918474":"code","38403401":"code","295b8215":"code","94523a5b":"code","17a1cda9":"code","17c6484a":"code","9d8a5c94":"code","0cff7042":"code","ad35ac97":"code","c2f7ba6a":"code","1af3cf25":"code","172b9d1e":"code","1890bef6":"code","68642ff0":"code","904dda16":"code","7c7959f7":"code","0ddea2b0":"code","c99c2baa":"code","00dc14c3":"code","29230fa2":"code","0660eea9":"code","873b4c91":"code","7ccc001a":"code","7f9f4912":"markdown","c7570333":"markdown","e3189d55":"markdown","06716709":"markdown","a4ed02aa":"markdown","233f0c31":"markdown","49105344":"markdown","7a850caa":"markdown","df932018":"markdown","a97591e5":"markdown","476bd00d":"markdown","89e83ba9":"markdown","aae6f222":"markdown","a904d97e":"markdown","b45bd10d":"markdown"},"source":{"8e349bf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pycountry \nimport plotly\nimport plotly.express as px\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom IPython.display import Markdown as md, HTML\n\n%matplotlib inline","ce386a56":"country_region = pd.read_csv('..\/input\/kaggle-surveys\/country_region.csv')\ndf_19 = pd.read_csv('..\/input\/kaggle-surveys\/df_19.csv')\ndf_20 = pd.read_csv('..\/input\/kaggle-surveys\/df_20.csv')\ndf_21 = pd.read_csv('..\/input\/kaggle-surveys\/df_21.csv')","2cc05768":"# numbers of questions in each survey & time taken by gender\n\ndata19 = df_19.loc[:, ['gender', 'age_range','time_in_seconds']]\ndata19['year'] = '2019 (36 Qs)'\n\ndata20 = df_20.loc[:, ['gender', 'age_range','time_in_seconds']]\ndata20['year'] = '2020 (47 Qs)'\n\ndata21 = df_21.loc[:, ['gender', 'age_range','time_in_seconds']]\ndata21['year'] = '2021 (51 Qs)'\n\ndata = pd.concat([data19, data20], ignore_index=True)\ndata = pd.concat([data, data21], ignore_index=True)\n","d8918474":"fig = px.box(data, y=\"age_range\", x=\"time_in_seconds\", color='gender', facet_col=\"year\", log_x=True,\n             height = 1000, width=1200,\n            labels=dict(age_range=\"Age\", time_in_seconds=\"Log(Time) (seconds)\", gender=\"Gender\"))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\nfig.update_yaxes(categoryorder='array', categoryarray= ['18-21', '22-24', '25-29', '30-34', '35-39',\n                                                       '40-44', '45-49', '50-54', '55-59', '60-69', '70'])\nfig.show()","38403401":"highest_index = country_region.sort_values('human development index', ascending=False)['country'].head(1).item()\nhighest_internet = country_region.sort_values('internet users', ascending=False)['country'].head(1).item()\n\nlargest_country = country_region[country_region['world_share'] == max(country_region['world_share'])]['country'].item()\nlargest_share = country_region[country_region['world_share'] == max(country_region['world_share'])]['world_share'].item()*100","295b8215":"md(\"You might think that Kaggle world have the same representation as the real world, meaning, it would make perfect sense if **{}** -who has the highest world share- dominates the survey with same or near its world share **{}%**, but that is not the case here!)\".format(largest_country, largest_share))","94523a5b":"md(\"Okay, then we would assume the country dominating would be the one with the highest *human development index:* **{}** .. if not, it would definitly be the one with the highest *internet users:* **{}**. but no!\".format(highest_index, highest_internet))","17a1cda9":"con19 = df_19['country'].value_counts().reset_index(name='count')\ncon19['perc'] = (con19['count']\/con19['count'].sum())*100\ncon19['year']=2019\ncon20 = df_20['country'].value_counts().reset_index(name='count')\ncon20['perc'] = (con20['count']\/con20['count'].sum())*100\ncon20['year']=2020\ncon21 = df_21['country'].value_counts().reset_index(name='count')\ncon21['perc'] = (con21['count']\/con21['count'].sum())*100\ncon21['year']=2021\n\ndata = pd.concat([con19, con20], ignore_index=True)\ndata = pd.concat([data, con21], ignore_index=True)\n\nfig = px.bar(data[data['perc']>= data['perc'].quantile(0.95)], x=\"year\", y=\"perc\",\n              facet_col=\"index\", facet_col_wrap=7,\n              facet_row_spacing=0.04, # default is 0.07 when facet_col_wrap is used\n              facet_col_spacing=0.09, # default is 0.03\n              height=300, width=800,\n              range_x = [2018,2022],\n              range_y = [0,35],\n              title=\"Countries with volume of at least 5% of Surveys' total records for 2019-2021\",\n            labels=dict(count=\"\", year=\"Year\"))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n\nfig.show()","17c6484a":"subdata = country_region.loc[:, ['country', 'region', 'developing']]\ndata = data.merge(subdata, how='left', left_on='index', right_on='country')\n\ndata['developing'].fillna('NA', inplace=True)\ndata['region'].fillna('NA', inplace=True)","9d8a5c94":"fig = px.bar(data[data['perc']< data['perc'].quantile(0.95)], x=\"year\", y=\"perc\", color = 'developing',\n             facet_col=\"index\", facet_col_wrap=7,\n              facet_row_spacing=0.04, # default is 0.07 when facet_col_wrap is used\n              height=1000, width=800,\n              range_x = [2018,2022],\n              range_y = [0,4],\n              title=\"Survey poputlation percentage of remaining countries (2019-2021)\",\n            labels=dict(count=\"\", year=\"Year\", developing=\"is a developing country?\"))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\nfig.show()","0cff7042":"data19 = data[(data['year']==2019)].groupby('region')['count'].sum().reset_index(name='perc')\ndata19 = data19.sort_values('region')\ndata20 = data[(data['year']==2020)].groupby('region')['count'].sum().reset_index(name='perc')\ndata20 = data20.sort_values('region')\ndata21 = data[(data['year']==2021)].groupby('region')['count'].sum().reset_index(name='perc')\ndata21 = data21.sort_values('region')","ad35ac97":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ncolors = ['orange', 'lightyellow','powderblue', 'violet', 'crimson', 'thistle', 'lightgreen', 'cornflowerblue']\nlabels = data21['region'].tolist()\n\nfig = make_subplots(1, 3, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=['2019', '2020', '2021'])\nfig.add_trace(go.Pie(labels=labels, values=data19['perc'], \n                     name=\"2019\", pull=[0, 0, 0, 0, 0, 0.1]), 1, 1)\nfig.add_trace(go.Pie(labels=labels, values=data20['perc'], \n                     name=\"2020\", pull=[0, 0, 0, 0, 0, 0.1]), 1, 2)\nfig.add_trace(go.Pie(labels=labels, values=data21['perc'], \n                     name=\"2021\", pull=[0, 0, 0, 0, 0, 0.1]), 1, 3)\nfig.update_traces(hoverinfo='label+percent', \n                  marker=dict(colors=colors, line=dict(color='#000000')))\nfig.update(layout_title_text=\"Regions' representation in 2019-2021 surveys\")\nfig.show()","c2f7ba6a":"def count_variable(vars):\n    data19 = df_19.groupby(vars).size().reset_index(name='count').sort_values('count', ascending=False)\n    data19['perc'] = round(data19['count']\/df_19.shape[0]*100, 4)\n    data19['year'] = 2019\n\n    data20 = df_20.groupby(vars).size().reset_index(name='count').sort_values('count', ascending=False)\n    data20['perc'] = round(data20['count']\/df_20.shape[0]*100, 4)\n    data20['year'] = 2020\n\n    data21 = df_21.groupby(vars).size().reset_index(name='count').sort_values('count', ascending=False)\n    data21['perc'] = round(data21['count']\/df_21.shape[0]*100, 4)\n    data21['year'] = 2021\n\n    data = pd.concat([data19, data20], ignore_index=True)\n    data = pd.concat([data, data21], ignore_index=True)\n    \n    return data","1af3cf25":"plot_data = count_variable(['gender','age_range'])\nfig = px.bar(plot_data, x=\"age_range\", y=\"perc\", color=\"gender\",\n  animation_frame=\"year\",animation_group=\"age_range\", range_y=[0,25],\n             title=\"Overall percentage of Age per Gender (2019-2021)\",\n            labels=dict(age_range=\"Age Range\", perc=\"percentage\", gender=\"Gender\"))\nfig.update_xaxes(categoryorder='array', categoryarray= ['18-21', '22-24', '25-29', '30-34', '35-39',\n                                                       '40-44', '45-49', '50-54', '55-59', '60-69', '70'])\n\nfig.show()","172b9d1e":"plot_data = count_variable(['gender','education'])\nfig = px.bar(plot_data, x=\"education\", y=\"perc\", color=\"gender\",\n  animation_frame=\"year\",animation_group=\"education\", range_y=[0,50],\n             title=\"Overall percentage of Education per Gender (2019-2021)\",\n            labels=dict(education=\"Education\", perc=\"percentage\", gender=\"Gender\"))\nfig.update_xaxes(categoryorder='array', categoryarray= ['Some college\/university study without earning a bachelor\u2019s degree',\n                                                        'Bachelor\u2019s degree',\n                                                        'Master\u2019s degree',  \n                                                        'Doctoral degree', \n                                                        'I prefer not to answer',\n                                                        'Professional doctorate'])\n\n\nfig.show()","1890bef6":"plot_data = count_variable(['gender','title'])\nfig = px.bar(plot_data, x=\"title\", y=\"perc\", color=\"gender\",\n  animation_frame=\"year\",animation_group=\"title\", range_y=[0,30],\n             title=\"Overall percentage of Title per Gender (2019-2021)\",\n            labels=dict(title=\"Title\", perc=\"percentage\", gender=\"Gender\"))\nfig.update_xaxes(categoryorder='array', categoryarray= ['Not employed', \n                                                        'Student',\n                                                        'Other', \n                                                        'Product\/Project Manager',\n                                                        'Software Engineer',\n                                                        'Research Scientist',\n                                                        'Data Scientist', \n                                                        'Data Analyst', \n                                                        'Machine Learning Engineer', \n                                                        'Business Analyst', \n                                                        'Data Engineer', \n                                                        'Statistician', \n                                                        'Developer Relations\/Advocacy',\n                                                        'DBA\/Database Engineer'])\n\nfig.show()","68642ff0":"data19 = df_19[['coding_years', 'title', 'gender','yearly_salary_avg']]\ndata19 = data19[~data19['yearly_salary_avg'].isna()]\ndata19['year'] = 2019\n\ndata20 = df_20[['coding_years', 'title', 'gender','yearly_salary_avg']]\ndata20 = data20[~data20['yearly_salary_avg'].isna()]\ndata20['year'] = 2020\n\ndata21 = df_21[['coding_years', 'title', 'gender','yearly_salary_avg']]\ndata21 = data21[~data21['yearly_salary_avg'].isna()]\ndata21['year'] = 2021\n\ndata = pd.concat([data19, data20], ignore_index=True)\ndata = pd.concat([data, data21], ignore_index=True)\n\n# remove outliers\ndata = data[data['yearly_salary_avg']<=600000]\n\nfig = px.box(data, x=\"coding_years\", y=\"yearly_salary_avg\", facet_col=\"year\",\n             color=\"gender\", hover_name=\"gender\", facet_row=\"title\",\n             height=3500, width=2000, facet_row_spacing=0.009,\n             title=\"Average reported salary per years of coding, split by profession per gender (2019-2021)\",\n             labels=dict(coding_years=\"# of Coding Years\", yearly_salary_avg=\"Avergae Salary ($)\", gender=\"Gender\")\n)\nfig.update_xaxes(categoryorder='array', categoryarray= ['-', '1', '1-2', \n                                                        '1-3', '3-5', '5-10',\n                                                        '10-20', '20'])\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\nfig.show()","904dda16":"def get_stats():\n\n    youth_data19 = df_19[df_19['age_range']=='18-21']\n    youth_data19 = youth_data19.drop(columns=['age_range', 'time_in_seconds'])\n\n    youth_data20 = df_20[df_20['age_range']=='18-21']\n    youth_data20 = youth_data20.drop(columns=['age_range', 'time_in_seconds'])\n\n    youth_data21 = df_21[df_21['age_range']=='18-21']\n    youth_data21 = youth_data21.drop(columns=['age_range', 'time_in_seconds'])\n\n    least_data19 = df_19[df_19['age_range'].isin(['40-44', '45-49', '50-54', '55-59', '60-69', '70'])]\n    least_data19 = least_data19.drop(columns=['age_range', 'time_in_seconds'])\n\n    least_data20 = df_20[df_20['age_range'].isin(['40-44', '45-49', '50-54', '55-59', '60-69', '70'])]\n    least_data20 = least_data20.drop(columns=['age_range', 'time_in_seconds'])\n\n    least_data21 = df_21[df_21['age_range'].isin(['40-44', '45-49', '50-54', '55-59', '60-69', '70'])]\n    least_data21 = least_data21.drop(columns=['age_range', 'time_in_seconds'])\n\n    mid_data19 = df_19[df_19['age_range'].isin(['22-24', '25-29', '30-34', '35-39'])]\n    mid_data19 = mid_data19.drop(columns=['age_range', 'time_in_seconds'])\n\n    mid_data20 = df_20[df_20['age_range'].isin(['22-24', '25-29', '30-34', '35-39'])]\n    mid_data20 = mid_data20.drop(columns=['age_range', 'time_in_seconds'])\n\n    mid_data21 = df_21[df_21['age_range'].isin(['22-24', '25-29', '30-34', '35-39'])]\n    mid_data21 = mid_data21.drop(columns=['age_range', 'time_in_seconds'])\n\n    \n    youth_df = pd.DataFrame(columns=['value','count','perc','year', 'variable', 'subgroup'])\n\n    for col in youth_data19:\n        df_tmp = youth_data19.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/youth_data19.shape[0]*100, 2)\n        df_tmp['year'] = 2019\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'youth'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        youth_df = pd.concat([youth_df, df_tmp], ignore_index=True)\n\n    for col in youth_data20:\n        df_tmp = youth_data20.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/youth_data20.shape[0]*100, 2)\n        df_tmp['year'] = 2020\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'youth'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        youth_df = pd.concat([youth_df, df_tmp], ignore_index=True)\n    \n    for col in youth_data21:\n        df_tmp = youth_data21.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/youth_data21.shape[0]*100, 2)\n        df_tmp['year'] = 2021\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'youth'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        youth_df = pd.concat([youth_df, df_tmp], ignore_index=True)\n\n    least_df = pd.DataFrame(columns=['value','count','perc','year', 'variable', 'subgroup'])\n    \n    for col in least_data19:\n        df_tmp = least_data19.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/least_data19.shape[0]*100, 2)\n        df_tmp['year'] = 2019\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'least'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        least_df = pd.concat([least_df, df_tmp], ignore_index=True)\n\n    for col in least_data20:\n        df_tmp = least_data20.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/least_data20.shape[0]*100, 2)\n        df_tmp['year'] = 2020\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'least'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        least_df = pd.concat([least_df, df_tmp], ignore_index=True)\n    \n    for col in least_data21:\n        df_tmp = least_data21.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/least_data21.shape[0]*100, 2)\n        df_tmp['year'] = 2021\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'least'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        least_df = pd.concat([least_df, df_tmp], ignore_index=True)\n    \n    \n    mid_df = pd.DataFrame(columns=['value','count','perc','year', 'variable', 'subgroup'])\n    \n    for col in mid_data19:\n        df_tmp = mid_data19.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/mid_data19.shape[0]*100, 2)\n        df_tmp['year'] = 2019\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'in-between'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        mid_df = pd.concat([mid_df, df_tmp], ignore_index=True)\n\n    for col in mid_data20:\n        df_tmp = mid_data20.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/mid_data20.shape[0]*100, 2)\n        df_tmp['year'] = 2020\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'in-between'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        mid_df = pd.concat([mid_df, df_tmp], ignore_index=True)\n    \n    for col in mid_data21:\n        df_tmp = mid_data21.groupby(col).size().reset_index(name='count').sort_values('count', ascending=False)\n        df_tmp['perc'] = round(df_tmp['count']\/mid_data21.shape[0]*100, 2)\n        df_tmp['year'] = 2021\n        df_tmp['variable'] = col\n        df_tmp['subgroup'] = 'in-between'\n        df_tmp.rename(columns={col:'value'}, inplace=True)\n\n        mid_df = pd.concat([mid_df, df_tmp], ignore_index=True)\n    \n    data = pd.concat([youth_df, mid_df], ignore_index=True)\n    data = pd.concat([data, least_df], ignore_index=True)\n    \n    return data","7c7959f7":"data = get_stats()","0ddea2b0":"data['new_variable'] = data['variable'].apply(lambda x:'Role Activities' if x== 'role_activities_count' or x=='combined_work_activities'\n                                      else 'Media Platforms' if x=='media_plat_count' or x=='combined_media_plat'\n                                      else 'Course Platforms' if x=='course_plat_count' or x=='combined_course_plat'\n                                      else 'Data Primary Tools' if x=='data_primary_tool_count'\n                                      else 'IDEs' if x=='ide_count'or x=='combined_IDE'\n                                      else 'Notebooks' if x=='notebook_count'or x=='combined_notebook'\n                                      else 'Programming Languages' if x=='language_count' or x=='combined_lang'\n                                      else 'Visualization Libs' if x=='viz_lib_count' or x=='combined_libs'\n                                      else 'Hardware' if x=='hardware_count' or x=='combined_HW'\n                                      else 'ML Algorithms' if x=='ml_algo_count' or x=='combined_ml_algo'\n                                      else 'Auto ML' if x=='auto_ml_count' or x=='combined_auto_ml'\n                                      else 'CV methods' if x=='cv_method_count' or x=='combined_cv_method'\n                                      else 'NLP methods' if x=='nlp_method_count' or x=='combined_nlp_method'\n                                      else 'ML frameworks' if x=='ml_framework_count' or x=='combined_ml_framework'\n                                      else 'Cloud Platforms' if x=='cloud_plat_count' or x=='combined_cloud_platform'\n                                      else 'Cloud Products' if x=='cloud_prod_count' or x=='combined_cloud_prod'\n                                      else 'Bigdata Products' if x=='bigdata_prod_count' or x=='combined_bigdata_prod'\n                                      else 'ML Management' if x=='ml_manage_count' or x=='combined_ml_manage'\n                                      else 'Regular autoML' if x=='auto_ml_regular_count' or x=='combined_auto_ml_regular'\n                                      else 'ML Products' if x=='ml_prod_count' or x=='combined_ml_prod'\n                                      else 'BI Products' if x=='bi_prod_count' or x=='combined_bi'\n                                      else 'Deploy Env.' if x=='deploy_count' or x=='combined_deploy'\n                                      else 'Future Cloud Plats ' if x=='f_cloud_plat_count' or x=='combined_f_cloud_plat'\n                                      else 'Future Cloud Prods' if x=='f_cloud_prod_count' or x=='combined_f_cloud_prod'\n                                      else 'Future ML Prods' if x=='f_ml_prod_count' or x=='combined_f_ml_prod'\n                                      else 'Future Bigdata Prods' if x=='f_bigdata_prod_count' or x=='combined_f_bigdata_prod'\n                                      else 'Future BI Prods' if x=='f_bi_prod_count' or x=='combined_f_bi_prod'\n                                      else 'Future autoML' if x=='f_auto_ml_count'\n                                      else 'Future Regular autoML' if x=='f_auto_ml_regular_count'\n                                      else 'Future ML Management' if x=='f_manage_ml_count' or x=='combined_f_manage_ml'\n                                      else 'Storage' if x=='storage_count' or x=='combined_storage'\n                                      else 'Future Storage' if x=='f_storage_count'\n                                      else 'Future autoML Cat.' if x=='f_automl_cat_count'\n                                      else 'Future autoML tools' if x=='f_automl_tool_count'\n                                      else 'Company Size' if x=='company_size'\n                                          else 'Data Scientist #' if x=='data_science_workers'\n                                          else 'Business Using ML?' if x=='business_using_ml'\n                                          else 'Yearly Salary Range' if x=='yearly_salary'\n                                          else 'Yearly ML Spend Range' if x=='ml_spending'\n                                          else 'Data Primary Tool' if x=='data_primary_tool'\n                                          else 'Coding experience (yrs)' if x=='coding_years'\n                                          else 'TPU average usage' if x=='tpu_avg'\n                                          else 'ML experience (yrs)' if x=='ml_years'\n                                          else 'Recommended to learn first' if x=='learn_first_recommendation'\n                                              else 'Bigdata Products Often used' if x=='often_bigdata_products'\n                                              else 'Bigdata Regular Products' if x=='combined_bigdata_prod_regular'\n                                              else 'Regular Computing Platforms' if x=='often_computing_platform'\n                                              else 'Future AutoML Cat.' if x=='combined_f_automl_cat'\n                                              else 'Future AutoML Tools' if x=='combined_f_automl_tool'\n                                              else 'Industry' if x=='industry'\n                                      else x)","c99c2baa":"data['rank'] = (data.groupby(['variable', 'year', 'subgroup'])['perc']\n                      .rank(method='dense', ascending=False)\n                      .astype(int)\n                   )","00dc14c3":"def draw_pivots(values, cells_youth, cells_between, cells_least):\n    html = \"\"\"<style type=\"text\/css\">.tg  {border:none;}<\/style><table>\"\"\"\n    \n    for i in range(len(values)):\n        new_variable = data[data['variable']==values[i]]['new_variable'].unique()\n        html += \"\"\"<thead>\n        <tr> \n            <th colspan=\"3\" style=align: center;> Showing <em><u>\"\"\" +new_variable+ \"\"\"<\/em><\/u> Data for the 3 subgroups .. pivoted on Survey year<\/th>\n        <\/tr>\n        <tr>\n            <td style=\"text-align:center !important\">Youth<\/td>\n            <td style=\"text-align:center !important\">In-Between<\/td>\n            <td style=\"text-align:center !important\">Least<\/td>\n        <\/tr>\n          <tr style=\"text-align:center !important\">\n            <td >\"\"\"+cells_youth[i]+\"\"\"<\/td>\n            <td >\"\"\"+cells_between[i]+\"\"\"<\/td>\n            <td >\"\"\"+cells_least[i]+\"\"\"<\/td>\n          <\/tr>\n        <\/thead>\n        \"\"\"\n    \n    html += \"<tbody><\/tbody><\/table>\"\n    \n    display(HTML(str(html).replace('\\\\n', '').replace(\"['\", '').replace(\"']\", '')))","29230fa2":"def get_top_values(rank, values):\n    subdata = data[(data['rank'].between(1,rank)) & (data['variable'].isin(values))]\n    \n    cells_youth = []\n    for item in values:\n        show_data = subdata[(subdata['variable']==item) & (subdata['subgroup']=='youth')]\n        show_data = show_data.pivot(index=['value'], columns='year', values='perc')\n        show_data = show_data.fillna('')\n        show_data.index.name = None\n\n        print_label = subdata[subdata['variable']==item]['new_variable'].unique().item()\n        \n        cells_youth.append(show_data.to_html())\n        \n    cells_between = []\n    for item in values:\n        show_data = subdata[(subdata['variable']==item) & (subdata['subgroup']=='in-between')]\n        show_data = show_data.pivot(index=['value'], columns='year', values='perc')\n        show_data = show_data.fillna('')\n        show_data.index.name = None\n\n        print_label = subdata[subdata['variable']==item]['new_variable'].unique().item()\n        \n        cells_between.append(show_data.to_html())\n        \n    cells_least = []\n    for item in values:\n        show_data = subdata[(subdata['variable']==item) & (subdata['subgroup']=='least')]\n        show_data = show_data.pivot(index=['value'], columns='year', values='perc')\n        show_data = show_data.fillna('')\n        show_data.index.name = None\n\n        print_label = subdata[subdata['variable']==item]['new_variable'].unique().item()\n        \n        cells_least.append(show_data.to_html())\n    \n    draw_pivots(values, cells_youth, cells_between, cells_least)","0660eea9":"values = ['gender', 'country', 'education', 'title',\n          'learn_first_recommendation',  'company_size','business_using_ml',\n          'data_science_workers', 'yearly_salary', 'ml_spending',\n          'data_primary_tool', 'coding_years', 'tpu_avg', 'ml_years']\n\nget_top_values(5, values)","873b4c91":"subdata = data[data['variable'].isin(['often_bigdata_products', 'role_activities_count', 'media_plat_count', 'course_plat_count',\n 'data_primary_tool_count', 'ide_count', 'notebook_count', 'language_count',\n 'viz_lib_count', 'hardware_count', 'ml_algo_count', 'auto_ml_count', 'cv_method_count', 'nlp_method_count',\n 'ml_framework_count', 'cloud_plat_count', 'cloud_prod_count', 'bigdata_prod_count', 'ml_manage_count',\n 'auto_ml_regular_count',  'ml_prod_count', 'bi_prod_count',\n 'deploy_count', 'f_cloud_plat_count', 'f_cloud_prod_count', 'f_ml_prod_count',\n 'f_bigdata_prod_count', 'f_bi_prod_count', 'f_auto_ml_count', 'f_auto_ml_regular_count',\n 'f_manage_ml_count', 'storage_count', 'f_storage_count', 'f_automl_cat_count', 'f_automl_tool_count'])]\n\nfig = px.bar(subdata, x='value', y=\"perc\", color='year', facet_row='new_variable', facet_col='subgroup',\n             facet_row_spacing=0.002, barmode='group',\n             facet_col_spacing=0.02, # default is 0.07 when facet_col_wrap is used\n              height=4500, width=1100,range_x=[0,10],range_y=[0,100],\n             title=\"Count Percentage of multiple choice Qs per Year\",\n            )\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\nfig.show()","7ccc001a":"values = ['combined_work_activities', 'combined_media_plat',\n       'combined_course_plat', \n       'combined_IDE', 'combined_notebook', 'combined_lang',\n       'combined_libs', 'combined_HW', 'combined_ml_algo',\n       'combined_auto_ml', 'combined_cv_method', 'combined_nlp_method',\n       'combined_ml_framework', 'combined_cloud_platform',\n       'combined_cloud_prod', 'combined_bigdata_prod',\n       'combined_ml_manage', 'combined_auto_ml_regular',\n       'combined_bigdata_prod_regular', \n       'often_computing_platform', \n       'combined_ml_prod', 'combined_bi', 'combined_deploy',\n       'combined_f_cloud_plat', 'combined_f_cloud_prod',\n       'combined_f_ml_prod', 'combined_f_bigdata_prod',\n       'combined_f_bi_prod', 'combined_f_automl_cat',\n       'combined_f_automl_tool', 'combined_f_manage_ml', 'industry',\n        'combined_storage']\n\nget_top_values(3, values)","7f9f4912":"<center><b>India<\/b> -consistently- dominates survey data by more than <span style=\"background-color: #F5F5F5\">20%<\/span> for the past the 3 years.<\/center>\n\n<center>Comes at the second place; <b>USA<\/b> with percentage of dominance equal to <span style=\"background-color: #F5F5F5\">half<\/span> of it's predecessor!<\/center>\n\n<center>And at the third place comes; <b>Other<\/b> with dominance slightly higher\/lower than <span style=\"background-color: #F5F5F5\">5%<\/span> of survey data!<\/center>","c7570333":"#### Here the top 5 values for each subgroup over 2019, 2020 & 2021 .. for the following: \n\n**gender, country, education, title, learn first recommendation, company size, if business is using ML, # of data science workers, yearly salary, ML spending, data primary tool, # of coding years, TPU avg. usage, # of ML years**","e3189d55":"#### How about the number of tools, languages, .. etc these 3 subgroups use?\n\n##### I have counted the number of choices selected for all multiple choice questions, to see if there are any trends comparing 2019, 2020, and 2021 data, and here is what's noticeable:\n- Media\/Course platforms were more popular B.C.!\n- More respondants are using more Visualization Libs, IDEs, programming lang., Notebooks, and HW than previous years\n- Respondants of this year's survey want to learn more & have bigger future plans than their predcessors\n- AutoML, ML management tools & cloud platforms are used more by the least population\n- Older populations know\/use more programming languages than the emerging one\n- Number of role activities is directly propotional to age!\n\nSide note: percentages are calculated per subgroup relative to itself not relative to total sample space","06716709":"#### After knowing about the count, let's know more about the content ..\n\n#### Here the top 3 values for each subgroup over 2019, 2020 & 2021 .. for all MCQs!","a4ed02aa":"# Conclusion\n\n- Splitting our sample space based on age and comparing those subgroups across the 3 years in scope was insightful, it enabled us to see the difference and how this difference changed over time.\n\n- Ofcourse, this is not the sole direction to look at our data, every time our goal changes we might exclude\/include various aspects of data, whether collected by the survey or additional complementry data that will help us take the right decisions.\n\n- I see many opportunities coming from the future MCQs, maybe Kaggle can consider making those questions part of the original survey, or even make a seperate for this type of questions in the future.\n\n*Side note: Further cleaning to data can be done (specifically for the choices of the multiple choice questions)*","233f0c31":"# Survey time\n\nThe first thing I was interested to know about is the time taken to complete the survey specially that the structure changed after 2019.\nThe number of questions has increased from 2019 till 2021, and despite that the change in time taken is not huge, however when we look at how the time is distributed by `gender` & `age`, we find younger respondants have more outliers, where these outliers consume more time.\n\nOne more observation is that for 2021, there are not outliers with low values as the previous surveys, it would be interesting to know if survey mechanism was changed.","49105344":"When we take a look at the remaining countries (whose respondants constitute <5% of the data), we find a pattern of \ndeveloping versus developed countries.\n\n`Developed countries` *(except Japan, UAE, Israel & South Korea)* seem to have a decrease in representation over the past 3 years, on the other hand `developing countries` maintain their presence, for few countries it is even better, they either newly joined or have increased their representation.","7a850caa":"# Closer Look\n\nLet's view the main changes over the past 3 years, I'd start with ***demographics***!\n\nIn 2019, **59** countries were represented in the survey\n> <b><span style=\"color: #FF0000\">8<\/span><\/b> of them dropped out .. <b><span style=\"color: #228B22\">4<\/span><\/b> new countries joined the race\n\nMaking it <b>55<\/b> countries in 2020 survey.\n> <b><span style=\"color: #228B22\">5<\/span><\/b> out of the dropped countries returned .. plus <b><span style=\"color: #228B22\">5<\/span><\/b> brand new countries .. in addition to the new option <span style=\"background-color: #F5F5F5\">not to disclose location<\/span>\n\nMaking 2021 survey has total of **66** countries","df932018":"## Data Preprocessing\n\nYou can find all preprocessing steps in this [notebook](https:\/\/www.kaggle.com\/katokev\/2021-kaggle-machine-learning-data-science-survey\/)","a97591e5":"# General Profiling\n\nAt the first glance you might think you have the characteristics of the sample Kaggle has collected responses from.\nOverall collected data doesn't change much before\/after **B.C.** (Before Covid)\n\nA Typical Profile would be:\n- **Country of origin:** one of the top 3 countries [India, United States, Other]\n- **Age range:** either [18-21, 22-24, 25-29]\n- **Gender:** 79% chance a male\n- **Education:** holding a master's degree or a bachelor\n- **Profession:** if you're not a full-time student, most probably the respondant is a data scientist, whose main activity is *Analyze and understand data to influence product or business decisions*, in the field of Technology\n- **Programming skills:** you use at most 3 languages, which are Python, SQL, and R, with an average 3 years of coding experience, and you favorite IDE(s) are: *Jupyter (JupyterLab, Jupyter Notebooks, etc) , Visual Studio Code (VSCode), PyCharm*\n- **ML skills:**: <2 years experience, utlizing mostly *Linear or Logistic Regression, Decision Trees or Random Forests* and spending less than $1K on ML","476bd00d":"Here is an interesting finding when comparing the data of the past 3 years, for some professions, men are not the highest paid, however, males are not bounded by certain salary like other genders! \n\nCheck out below comparison of average salary Vs. years of coding, split by gender and title.","89e83ba9":"# Closer Look - Cont'd\n\n### What's New after B.C.?\n\nKaggle has attracted different audience after B.C., depicted below how the spectrum changed over the past 3 years, in terms of *age*, *education*, & *title*, split by gender.","aae6f222":"##### And just to see how the world -as regions- is represented on `Kaggle` universe, let's have a look at their percentage over the past 3 years.\n\n##### Shout out to `Africa`, `Latin\/South America`, & `Middle East` for sustaining their presence while `Europe & North America` have decreasing perecntage in the face of `Asia & Pacific` region!\n\n##### Side note: NA here stands for `other` & `undisclosed` countries, it would be very useful to know their details as they hold up nicely in the race!","a904d97e":"##### Most obvious note is `Data Scientist` percentage decreased when `Machine Learning Engineer` was introduced in 2020.","b45bd10d":"# Sub-Grouping\n\nI chose to split our sample space into 3 groups: \n\n- the emerging audience (18-21 yrs)\n- the least represented ages (> 40 yrs)\n- those in-between\n\nLet's dig deeper into their world to know more about their background, tools and plans!"}}