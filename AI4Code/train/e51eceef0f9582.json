{"cell_type":{"b6f373e6":"code","26bee2d4":"code","bf4213d2":"code","c0dc7076":"code","91131b23":"code","c01e2945":"code","57d07bf0":"code","1c56f48d":"code","65a29818":"code","26b5ce64":"code","ae4c72be":"code","703bb8ad":"code","bc69386d":"code","fabf5a29":"code","6fe0a836":"code","be066dd4":"markdown","859921f2":"markdown","0146209b":"markdown","577d2dff":"markdown","6c6e36cb":"markdown","5fdd66ae":"markdown","ec861bed":"markdown","b5655ca1":"markdown","2c5a5ddd":"markdown"},"source":{"b6f373e6":"!pip install torchgan","26bee2d4":"import os\nimport cv2\nimport torch\nimport numpy as np\nfrom torch.optim import Adam\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nfrom torchgan.models import DCGANGenerator, DCGANDiscriminator\nfrom torchgan.losses import MinimaxGeneratorLoss, MinimaxDiscriminatorLoss\nfrom torchgan.trainer import Trainer\nimport matplotlib.pyplot as plt\n%matplotlib inline","bf4213d2":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","c0dc7076":"class FlowerImitationDataset(data.Dataset):\n    \"\"\"Flower Imitation Dataset\"\"\"\n    def __init__(self, path_to_dataset,image_size):\n        self.image_size = image_size\n        self.path_to_dataset = path_to_dataset\n        self.images = []\n        for root, dirs, files in os.walk(os.path.abspath(path_to_dataset), topdown = False):\n            for name in files:\n                self.images.append(os.path.join(root, name))\n        self.transform=transforms.ToTensor()  \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img = cv2.resize(cv2.imread(self.images[idx]),self.image_size)\n        return self.transform(img)","91131b23":"def flower_imitation_data_loader(path_to_dataset, image_size, batch_size):\n    flower_imitation_dataset = FlowerImitationDataset(path_to_dataset, image_size)\n    train_loader = data.DataLoader(flower_imitation_dataset, batch_size=batch_size, shuffle=True)\n    return train_loader","c01e2945":"trainer = Trainer({\"generator\": {\"name\": DCGANGenerator,\n                                 \"args\": {\"out_channels\": 3,\n                                          \"out_size\":256,\n                                          \"step_channels\": 4},\n                                 \"optimizer\": {\"name\": Adam,\n                                               \"args\": {\"lr\": 0.001,\n                                                        \"betas\": (0.5, 0.899)}}},\n                   \"discriminator\": {\"name\": DCGANDiscriminator,\n                                     \"args\": {\"in_channels\": 3,\n                                              \"in_size\":256,\n                                              \"step_channels\": 4},\n                                     \"optimizer\": {\"name\": Adam,\n                                                   \"args\": {\"lr\": 0.001,\n                                                            \"betas\": (0.5, 0.899)}}}},\n                  [MinimaxGeneratorLoss(), MinimaxDiscriminatorLoss()],\n                  sample_size=16, epochs=350, device=device)","57d07bf0":"trainer(flower_imitation_data_loader('\/kaggle\/input\/flowers-imitation\/flowers_imitation\/',\n                                    (256,256),\n                                    64))","1c56f48d":"trainer.complete()","65a29818":"trainer.load_model('.\/model\/gan4.model')\ngenerator = trainer.generator","26b5ce64":"transform=transforms.ToTensor()","ae4c72be":"rx = torch.Tensor([np.random.randn(100)])\nx =  torch.tensor(rx, device=device)","703bb8ad":"y = generator.forward(x)\ny = torch.Tensor.cpu(y)","bc69386d":"y0 = y[0].detach().numpy()\ny0 = y0.transpose()\ny0 = (y0 + 1)\/2","fabf5a29":"y0 = y0*255","6fe0a836":"cv2.imwrite('result.png',y0)","be066dd4":"#### Save the model","859921f2":"# DCGAN for flower imitation\n## Material based on [torchgan example](https:\/\/torchgan.readthedocs.io\/en\/latest\/getting_started\/basic_example.html)","0146209b":"### Net trainer","577d2dff":"### Dataset\nLet's make a dataset class to make model training comfortable. We have two parameters:\n1. *path_to_dataset* - this is a path to folder with images\n2. *image_size*  - final image size before making transforms and passing image to net","6c6e36cb":"#### launch training process","5fdd66ae":"noize generated, pass it to net","ec861bed":"### Data loder\ndefine the data loader to manage batch size","b5655ca1":"#### Save result","2c5a5ddd":"#### Trying trained net\nWe will generate some noize and then pass it to net. Load model from previous cell"}}