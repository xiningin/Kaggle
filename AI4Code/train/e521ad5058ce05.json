{"cell_type":{"836d65eb":"code","82f8f1ee":"code","688d14f6":"code","29cbdb68":"code","12d7e9b6":"code","ef4eb498":"code","1bbd87ab":"code","efa84eca":"code","1dfff1e4":"code","7c5a7b38":"code","30c44a60":"code","dd8f4653":"code","9a946d1b":"code","d4c73dc7":"code","6d9e22ec":"code","e846f7d0":"code","7601d8da":"code","2765104e":"code","1a4d9b32":"code","4451e9c4":"code","2dda4f02":"code","6d235c58":"code","b3966b9a":"code","c1383348":"markdown","fb714e97":"markdown","dd879aa1":"markdown","1a578500":"markdown","121ca066":"markdown"},"source":{"836d65eb":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer, MinMaxScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.sparse import csr_matrix\nfrom sklearn.decomposition import PCA\n\npd.set_option(\"max_colwidth\", None)","82f8f1ee":"anime_data=pd.read_csv('..\/input\/animeplanet-recommendation-database-2020\/anime.csv')\n\nprint(\"anime_data.shape:\", anime_data.shape)\nSynopsis = anime_data[\"Synopsis\"]\ndel anime_data[\"Synopsis\"]\nanime_data.head(1)","688d14f6":"def process_multilabel(series):\n    series = series.split(\",\")\n    if \"Unknown\" in series:\n        series.remove(\"Unknown\")\n    return series\n\nanime_data[\"Tags\"] = anime_data[\"Tags\"].map(process_multilabel)\nanime_data[\"Content Warning\"] = anime_data[\"Content Warning\"].map(process_multilabel)\nanime_data[\"Studios\"] = anime_data[\"Studios\"].map(process_multilabel)\nanime_data[\"Rating Score\"] = anime_data[\"Rating Score\"].replace(\"Unknown\", 0).astype(float)\nanime_data[\"Duration\"] = anime_data[\"Duration\"].replace(\"Unknown\", 0).astype(int)\nanime_data[\"Finished\"] = anime_data[\"Finished\"].replace(\"Unknown\", 0).astype(int)\nanime_data[\"Episodes\"] = anime_data[\"Episodes\"].replace(\"Unknown\", 0).astype(int)\nanime_data[\"Number Votes\"] = anime_data[\"Number Votes\"].replace(\"Unknown\", 0).astype(int)\nanime_data[\"EndYear\"] = anime_data[\"EndYear\"].replace(\"Unknown\", 0).astype(int)\nanime_data[\"StartYear\"] = anime_data[\"StartYear\"].replace(\"Unknown\", 0).astype(int)\n\n\nanime_data.head(1)","29cbdb68":"def preprocessing_category(df, column, is_multilabel=False):\n    # Binarise labels\n    lb = LabelBinarizer()\n    if is_multilabel:\n        lb = MultiLabelBinarizer()\n        \n    expandedLabelData = lb.fit_transform(df[column])\n    labelClasses = lb.classes_\n\n    # Create a pandas.DataFrame from our output\n    category_df = pd.DataFrame(expandedLabelData, columns=labelClasses)\n    del df[column]\n    return pd.concat([df, category_df], axis=1)\n\nanime_metadata = anime_data.copy()\nanime_metadata = preprocessing_category(anime_metadata, \"Type\")\nanime_metadata = preprocessing_category(anime_metadata, \"Season\")\nanime_metadata = preprocessing_category(anime_metadata, \"Studios\", is_multilabel=True)\nanime_metadata = preprocessing_category(anime_metadata, \"Content Warning\", is_multilabel=True)\n#anime_metadata = anime_metadata.replace(\"Unknown\", 0)\n#anime_metadata = anime_metadata.replace(\"an\", 0)\n\nGenders = anime_metadata[\"Tags\"]\nID_NAME = anime_metadata[[\"Anime-PlanetID\", \"Name\", \"Alternative Name\"]]\n\n\ndel anime_metadata[\"Tags\"]\ndel anime_metadata[\"Name\"]\ndel anime_metadata[\"Alternative Name\"]\ndel anime_metadata[\"Anime-PlanetID\"]\ndel anime_metadata[\"Url\"]\n\nnumeric_columns = [\"Rating Score\", \"Number Votes\", \"Episodes\", \"Duration\", \"StartYear\", \"EndYear\"]\nanime_metadata[numeric_columns] = MinMaxScaler().fit_transform(anime_metadata[numeric_columns])\nanime_metadata = anime_metadata.values","12d7e9b6":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\n\n# Filling NaNs with empty string\ngenres_original = anime_data['Tags'].fillna('').astype(str)\ngenres_vector_tf_idf = tfv.fit_transform(genres_original)\n\ngenres_vector_one_hot = preprocessing_category(pd.DataFrame(Genders), \"Tags\", True).values","ef4eb498":"print(\"anime_metadata.shape:\", anime_metadata.shape)\nprint(\"genres_vector_tf_idf.shape:\", genres_vector_tf_idf.shape)\nprint(\"genres_vector_one_hot.shape:\", genres_vector_one_hot.shape)","1bbd87ab":"def get_recommended(vector, query_index, n_neighbors=10):\n    model_knn = NearestNeighbors(metric='cosine', n_neighbors=n_neighbors)\n    model_knn.fit(csr_matrix(vector))\n\n    distances, indices = model_knn.kneighbors(vector[query_index,:].reshape(1, -1), n_neighbors = n_neighbors)\n    result = []\n    for i in range(0, len(distances.flatten())):\n        index = indices.flatten()[i]\n        if index == query_index:\n            continue\n        result.append(anime_data.iloc[index])\n        \n    return pd.DataFrame(result)","efa84eca":"# query_index = np.random.choice(anime_metadata.shape[0])\nquery_index = ID_NAME[ID_NAME[\"Anime-PlanetID\"] == 7639].index[0]\naux = anime_data.iloc[[query_index]].copy()\ndel aux[\"Url\"]\naux","1dfff1e4":"get_recommended(anime_metadata, query_index, 10)","7c5a7b38":"get_recommended(genres_vector_tf_idf, query_index, 10)","30c44a60":"get_recommended(genres_vector_one_hot, query_index, 10)","dd8f4653":"all_data = np.concatenate((anime_metadata, genres_vector_tf_idf.todense(), genres_vector_one_hot), axis=1)\nall_data.shape","9a946d1b":"get_recommended(all_data, query_index, 10)","d4c73dc7":"%%time\n\nreduced_all_data = PCA(n_components=250).fit_transform(all_data)\nget_recommended(reduced_all_data, query_index, 10)","6d9e22ec":"usecols = [\"Anime-PlanetID\", \"Name\", \"Tags\", \"Synopsis\"]\nanime_data_2 = pd.read_csv('..\/input\/animeplanet-recommendation-database-2020\/anime.csv', usecols=usecols)\nanime_data_2.head()","e846f7d0":"query_index_2 = anime_data_2[anime_data_2[\"Anime-PlanetID\"] == 7639].index[0]\nanime_data_2.iloc[[query_index_2]]","7601d8da":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\n\n# Filling NaNs with empty string\n\nsynopsis_original = anime_data_2['Synopsis'].fillna('').astype(str)\nsynopsis_vector_tf_idf = tfv.fit_transform(synopsis_original)\nsynopsis_vector_tf_idf.shape","2765104e":"def get_recommended_another_df(vector, query_index, n_neighbors=10):\n    model_knn = NearestNeighbors(metric='cosine', n_neighbors=n_neighbors)\n    model_knn.fit(csr_matrix(vector))\n\n    distances, indices = model_knn.kneighbors(vector[query_index,:].reshape(1, -1), n_neighbors = n_neighbors)\n    result = []\n    for i in range(0, len(distances.flatten())):\n        index = indices.flatten()[i]\n        if index == query_index:\n            continue\n        result.append(anime_data_2.iloc[index])\n        \n    return pd.DataFrame(result)","1a4d9b32":"get_recommended_another_df(synopsis_vector_tf_idf, query_index_2, 10)","4451e9c4":"%%time\n\nreduced_all_data = PCA(n_components=250).fit_transform(synopsis_vector_tf_idf.todense())\nget_recommended_another_df(reduced_all_data, query_index_2, 10)","2dda4f02":"rating_data = pd.read_csv('..\/input\/animeplanet-recommendation-database-2020\/rating_complete.csv')\n\nprint (\"rating_data.shape:\", rating_data.shape)\nprint (rating_data.info())\nrating_data.head()","6d235c58":"unique_users = {int(x): i for i,x in enumerate(rating_data.user_id.unique())}\nunique_items = {int(x): i for i,x in enumerate(rating_data.anime_id.unique())}\n\nprint(len(unique_items), len(unique_users))\nanime_collabolative_filter = np.zeros((len(unique_items), len(unique_users)))\n\nfor user_id, anime_id, rating in rating_data.values:\n    anime_collabolative_filter[unique_items[int(anime_id)], unique_users[int(user_id)]] = rating","b3966b9a":"get_recommended(anime_collabolative_filter, query_index_2, 10)","c1383348":"## Collaborative Filtering","fb714e97":"### Use Synopsis and TF-IDF","dd879aa1":"# Anime Planet Recommended System - Content Based & Collaborative Filtering\n\nThis notebook use a classic method (KNN) to recommend anime using 2 different approach: \n\n- Content Based\n- Collaborative Filtering\n\nIn Content bases, I explore 7 ways to recommend a list of anime based in 1 given anime:\n\n1. Only Metadata\n2. Using one hot encoding to embedding the tags.\n3. Using TF-IDF to embedding the tags\n4. Concatenate opction 1, 2 and 3.\n5. Apply PCA to generate reduced vector of option 4.\n6. Using TF-IDF to embedding the synopsis\n7. Apply PCA to generate reduced vector of option 6.\n\n\nI was based on the following work https:\/\/www.kaggle.com\/benroshan\/content-collaborative-anime-recommendation","1a578500":"## Content Based","121ca066":"## Recommend with KNN"}}