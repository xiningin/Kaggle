{"cell_type":{"191101a1":"code","96c9321c":"code","c5cad026":"code","35845aa3":"code","67b61b4f":"code","64ece059":"code","26da183e":"code","20fb7b08":"code","cefad6ea":"code","dd970293":"code","f862f1fe":"code","e3d0f3a2":"code","4e006416":"code","5cf5e967":"code","b0614b71":"code","d667bf4d":"code","f35bf1e3":"code","032abbc1":"code","7db6c223":"code","615e3058":"code","665e6bf3":"code","837eae13":"code","0b799f28":"code","dbfe4f91":"code","0d0c20af":"code","ad55d820":"code","367c6986":"code","91a0c185":"code","ed87ea0c":"code","4f1fe6b6":"code","d44e68c3":"code","eb6ff1f5":"code","0bffef44":"code","25683917":"code","05c76a21":"code","a72a08a2":"code","4ef6f259":"code","ae0489a7":"code","76cd3c49":"code","b7c5f5e6":"code","10ddd0cd":"code","9a66eed3":"code","a87ab788":"markdown","821d8ce0":"markdown","718f156a":"markdown","d7cf679d":"markdown","ed74132a":"markdown","390aa1c7":"markdown","1b02841e":"markdown","ea532638":"markdown","bc12e5a6":"markdown","c846622c":"markdown"},"source":{"191101a1":"import numpy as np\nimport pandas as pd","96c9321c":"oof_preds0 = pd.read_csv('..\/input\/cnn-segmentation-cv-with-oof-preds-on-train-set\/oof_preds0.csv')\noof_preds1 = pd.read_csv('..\/input\/cnn-segmentation-cv-with-oof-preds-on-train-set\/oof_preds1.csv')\noof_preds2 = pd.read_csv('..\/input\/cnn-segmentation-cv-with-oof-preds-on-train-set\/oof_preds2.csv')","c5cad026":"oof_preds0.head()","35845aa3":"oof_preds1.head()","67b61b4f":"oof_preds2.head()","64ece059":"df = pd.read_csv('..\/input\/rsna-pneumonia-detection-challenge\/stage_1_train_labels.csv')","26da183e":"df.head(20)","20fb7b08":"df['bbox_target'] = (df['x'].astype(str) +\n                    ' ' + \n                    df['y'].astype(str) +\n                    ' ' +\n                    df['width'].astype(str) +\n                    ' ' +\n                    df['height'].astype(str))","cefad6ea":"df.loc[:, 'bbox_target'] = df.loc[:, 'bbox_target'].map(lambda x: x.split(' '))","dd970293":"df.head(20)","f862f1fe":"df = df.groupby(['patientId'], as_index = False)['bbox_target'].agg('sum')    ","e3d0f3a2":"df.head()","4e006416":"df = df.merge(oof_preds0, on = 'patientId', how = 'left')\ndf = df.merge(oof_preds1, on = 'patientId', how = 'left')\ndf = df.merge(oof_preds2, on = 'patientId', how = 'left')","5cf5e967":"df = df.fillna('')","b0614b71":"df.loc[:, 'bbox_pred'] = (df.loc[:, 'PredictionString'] +\n                         ' ' +\n                         df.loc[:, 'PredictionString_x'] +\n                         ' ' +\n                         df.loc[:, 'PredictionString_y'])","d667bf4d":"df = df.drop(['PredictionString','PredictionString_x', 'PredictionString_y'], axis=1)","f35bf1e3":"df.head(20)","032abbc1":"df.loc[:, 'bbox_pred'] = df.loc[:, 'bbox_pred'].str.strip()","7db6c223":"df.loc[:, 'bbox_pred'] = df.loc[:, 'bbox_pred'].map(lambda x: x.split(' '))","615e3058":"df.head(10)","665e6bf3":"def parse_scores(x):\n    if len(x)!=1:\n        scores = [x[k] for k in range(0,len(x),5)]\n        for score in range(len(scores)):\n            scores[score] = float(scores[score])\n        return np.asarray(scores)","837eae13":"df.loc[:, 'bbox_scores'] = df.loc[:, 'bbox_pred'].map(parse_scores)","0b799f28":"df.head()","dbfe4f91":"def parse_bbox(x):\n    if len(x)!=1:\n        bbox = [int(x[k]) for k in range(0,len(x)) if k%5 != 0]\n        return np.asarray(bbox).reshape(int(len(bbox)\/4),4)","0d0c20af":"df.loc[:, 'bbox_preds'] = df.loc[:, 'bbox_pred'].map(parse_bbox)","ad55d820":"df.head()","367c6986":"df = df.drop(['bbox_pred'], axis=1)","91a0c185":"df.head(20)","ed87ea0c":"df.loc[df['bbox_scores'].isnull(),['bbox_scores']] = df.loc[df['bbox_scores'].isnull(),'bbox_scores'].apply(lambda x: np.asarray([]))","4f1fe6b6":"df.head()","d44e68c3":"df.loc[df['bbox_preds'].isnull(),['bbox_preds']] = df.loc[df['bbox_preds'].isnull(),'bbox_preds'].apply(lambda x: np.asarray([]))","eb6ff1f5":"df.head()","0bffef44":"def parse_target_str(x):\n    if x[0] != 'nan':\n        bbox = np.asarray([int(float(x[k])) for k in range(0,len(x))])\n        return bbox.reshape(int(len(bbox)\/4),4)","25683917":"df.loc[:,'bbox_target'] = df.loc[:,'bbox_target'].map(parse_target_str)","05c76a21":"df.loc[df['bbox_target'].isnull(),['bbox_target']] = df.loc[df['bbox_target'].isnull(),'bbox_target'].apply(lambda x: np.asarray([]))","a72a08a2":"df.head()","4ef6f259":"# helper function to calculate IoU\ndef iou(box1, box2):\n    x11, y11, w1, h1 = box1\n    x21, y21, w2, h2 = box2\n    assert w1 * h1 > 0\n    assert w2 * h2 > 0\n    x12, y12 = x11 + w1, y11 + h1\n    x22, y22 = x21 + w2, y21 + h2\n\n    area1, area2 = w1 * h1, w2 * h2\n    xi1, yi1, xi2, yi2 = max([x11, x21]), max([y11, y21]), min([x12, x22]), min([y12, y22])\n    \n    if xi2 <= xi1 or yi2 <= yi1:\n        return 0\n    else:\n        intersect = (xi2-xi1) * (yi2-yi1)\n        union = area1 + area2 - intersect\n        return intersect \/ union","ae0489a7":"def map_iou(boxes_true, boxes_pred, scores, thresholds = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75]):\n    \"\"\"\n    Mean average precision at differnet intersection over union (IoU) threshold\n    \n    input:\n        boxes_true: Mx4 numpy array of ground true bounding boxes of one image. \n                    bbox format: (x1, y1, w, h)\n        boxes_pred: Nx4 numpy array of predicted bounding boxes of one image. \n                    bbox format: (x1, y1, w, h)\n        scores:     length N numpy array of scores associated with predicted bboxes\n        thresholds: IoU shresholds to evaluate mean average precision on\n    output: \n        map: mean average precision of the image\n    \"\"\"\n    \n    # According to the introduction, images with no ground truth bboxes will not be \n    # included in the map score unless there is a false positive detection (?)\n        \n    # return None if both are empty, don't count the image in final evaluation (?)\n    if len(boxes_true) == 0 and len(boxes_pred) == 0:\n        return None\n    elif len(boxes_true) == 0 and len(boxes_pred) > 0:\n        return 0\n    elif len(boxes_true) > 0 and len(boxes_pred) == 0:\n        return 0\n    elif len(boxes_true) > 0 and len(boxes_pred) > 0:\n        assert boxes_true.shape[1] == 4 or boxes_pred.shape[1] == 4, \"boxes should be 2D arrays with shape[1]=4\"\n        if len(boxes_pred):\n            assert len(scores) == len(boxes_pred), \"boxes_pred and scores should be same length\"\n            # sort boxes_pred by scores in decreasing order\n            boxes_pred = boxes_pred[np.argsort(scores)[::-1], :]\n\n        map_total = 0\n\n        # loop over thresholds\n        for t in thresholds:\n            matched_bt = set()\n            tp, fn = 0, 0\n            for i, bt in enumerate(boxes_true):\n                matched = False\n                for j, bp in enumerate(boxes_pred):\n                    miou = iou(bt, bp)\n                    if miou >= t and not matched and j not in matched_bt:\n                        matched = True\n                        tp += 1 # bt is matched for the first time, count as TP\n                        matched_bt.add(j)\n                if not matched:\n                    fn += 1 # bt has no match, count as FN\n\n            fp = len(boxes_pred) - len(matched_bt) # FP is the bp that not matched to any bt\n            m = tp \/ (tp + fn + fp)\n            map_total += m\n    \n    return map_total \/ len(thresholds)","76cd3c49":"df.head(20)","b7c5f5e6":"for row in range(10):\n    print(map_iou(df['bbox_target'][row], df['bbox_preds'][row], df['bbox_scores'][row]))","10ddd0cd":"map_scores = [x for x in [map_iou(df['bbox_target'][row], df['bbox_preds'][row], df['bbox_scores'][row]) for row in range(len(df))] if x is not None]","9a66eed3":"np.mean(map_scores)","a87ab788":"Edit NaN or None values to empty numpy arrays to fit MAP IoU metric implementation","821d8ce0":"Load oof predictions from CNN segmentation CV kernel https:\/\/www.kaggle.com\/cchadha\/cnn-segmentation-cv-with-oof-preds-on-train-set\/notebook","718f156a":"Read in training labels","d7cf679d":"Merge labels and oof preds","ed74132a":"# Prepare out of fold training predictions for implementation of MAP IoU matching competition evaluation description","390aa1c7":"Parse bounding box labels into correct format for Mean Average Precision IoU metric","1b02841e":"Parse oof preds for MAP IoU","ea532638":"Stripping whitespace from PredictionString column","bc12e5a6":"# Find mean average precision IoU using implementation by chenyc15 https:\/\/www.kaggle.com\/chenyc15\/mean-average-precision-metric and edited herein","c846622c":"# Objective: Obtain out of fold predictions on the entire training set using cross validation and then using a mean average precision IoU metric, that closely resembles the competition metric, to improve validation"}}