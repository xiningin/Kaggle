{"cell_type":{"47595d88":"code","84a9477e":"code","e9f14d71":"code","eb33f143":"code","79089b32":"code","10dbc918":"code","df412850":"code","c718a5f6":"code","7aa9f2e6":"code","990a9bf0":"code","77e3fc89":"code","246893b5":"code","99ab8f07":"code","cf76c4bf":"code","3739f4bb":"code","b9af461a":"code","5241097c":"code","7290c939":"code","55a46480":"code","b4da468f":"markdown","889c9ec2":"markdown","58f30ac3":"markdown","30dde1aa":"markdown","729ee852":"markdown","a3155624":"markdown","6d84b23d":"markdown"},"source":{"47595d88":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport os\nimport pickle","84a9477e":"train = pd.read_csv('..\/input\/train.csv')\n#we will not use test dataset in this exercise\n#test = pd.read_csv('..\/input\/test.csv')","e9f14d71":"train.head()","eb33f143":"train_mini = train[['Name', 'Sex', 'Survived']]","79089b32":"def getTitle(name):\n    titles = ['Dr.', 'Mr.', 'Mrs.', 'Miss.', 'Master.']\n    for title in titles:\n        if title in name:\n            return title\n    #if none of the defined Titles\n    return 'Other'","10dbc918":"train_mini['Title']  = train_mini['Name'].apply(getTitle)","df412850":"train_mini.head()","c718a5f6":"!python --version","7aa9f2e6":"def convert_labels_sklearn_to_vw(y_sklearn):\n    return y_sklearn.map({1:1, 0:-1})\n\ndef convert_labels_vw_to_sklearn(y_vw):\n    return y_vw.map({1:1, -1:0})","990a9bf0":"y = train_mini['Survived']\ny_vw = convert_labels_sklearn_to_vw(y)","77e3fc89":"def to_vw(X, y=None, namespace='Name'):\n    labels = '1' if y is None else y.astype(str)\n    prefix = labels + ' |' + namespace + ' '\n    if isinstance(X, pd.DataFrame):\n        return prefix + X.apply(lambda x: ' '.join(x), axis=1)\n    elif isinstance(X, pd.Series):\n        return prefix + X","246893b5":"train_vw = to_vw(train_mini['Name'], y_vw)\ntrain_title_vw = to_vw(train_mini['Title'], y_vw)","99ab8f07":"train_vw.head()","cf76c4bf":"train_title_vw.head()","3739f4bb":"#test_vw = to_vw(test['Name'])","b9af461a":"#test_vw.head()","5241097c":"from vowpalwabbit.sklearn_vw import VWClassifier\nfrom vowpalwabbit.sklearn_vw import tovw\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.metrics import accuracy_score","7290c939":"thres = 0.5 \n# We will evaluate and compare several VW models as well as simple gender-based models\nmodels = {'VW_passes1': VWClassifier(quiet=False, convert_to_vw=False, \n                                     passes=1, link='logistic', \n                                     pos_threshold=thres,\n                                     random_seed=314),          \n          'VW_passes2': VWClassifier(quiet=False, convert_to_vw=False, \n                                     passes=2, link='logistic', \n                                     pos_threshold=thres,\n                                     random_seed=314), \n          'VW_passes2_l2001': VWClassifier(quiet=False, convert_to_vw=False,\n                                           passes=2, link='logistic', \n                                           pos_threshold=thres,\n                                           random_seed=314, l2=0.01), \n          'VW_passes2_l25em4': VWClassifier(quiet=False, convert_to_vw=False, \n                                            passes=2, link='logistic', \n                                            pos_threshold=thres,\n                                            random_seed=314, l1=5e-4),  \n          'WomenSurvive': None,\n          'MenSurvive': None,\n          'AllSurvive': None,\n          'NooneSurvive': None}\n\ny_females = (train_mini['Sex'] == 'female').astype(int)\ny_males   = (train_mini['Sex'] != 'female').astype(int)\n\n#kfold = StratifiedKFold(n_splits=5, random_state=314, shuffle=True)\nkfold = KFold(n_splits=5, random_state=314, shuffle=True)\n\ndef analyseAccuracy(data_vw):\n    scores = {}\n    for train_idx, valid_idx in kfold.split(data_vw, train_mini['Survived']):\n        train_vw_cv, valid_vw_cv = data_vw[train_idx], data_vw[valid_idx]\n        print(type(train_vw_cv))\n        for clf_name, clf in models.items():\n            # create lists to store kfold results\n            if 'valid_' + clf_name not in scores:\n                scores['valid_' + clf_name] = []\n                scores['train_' + clf_name] = []\n            if clf:\n                # evaluate VW classifiers\n                if isinstance(clf, VWClassifier) and hasattr(clf, 'fit_'):\n                    # reset VW if it has already been trained\n                    clf.get_vw().finish()\n                    clf.vw_ = None \n                # Fit the classifier\n                train_copy = train_vw_cv.copy()\n                clf.fit(train_copy)\n                del train_copy\n                # store VALIDATION accuracy for this fold\n                pred = (clf.decision_function(valid_vw_cv) > clf.pos_threshold).astype(int)\n                acc_valid = accuracy_score(y[valid_idx], pred)\n                scores['valid_' + clf_name].append(acc_valid)\n                #store TRAIN accuracy for this fold\n                pred = (clf.decision_function(train_vw_cv) > clf.pos_threshold).astype(int)\n                acc_train = accuracy_score(y[train_idx], pred)\n                scores['train_' + clf_name].append(acc_train)\n                del pred\n            else:\n                #evaluate also the gender-based dummy models\n                if 'Women' in clf_name:\n                    acc_train = accuracy_score(y[train_idx], y_females[train_idx])\n                    acc_valid = accuracy_score(y[valid_idx], y_females[valid_idx])\n                elif 'Men' in clf_name:\n                    acc_train = accuracy_score(y[train_idx], y_males[train_idx])\n                    acc_valid = accuracy_score(y[valid_idx], y_males[valid_idx])\n                elif 'All' in clf_name:\n                    acc_train = accuracy_score(y[train_idx], np.ones(train_vw_cv.shape))\n                    acc_valid = accuracy_score(y[valid_idx], np.ones(valid_vw_cv.shape))\n                else:\n                    acc_train = accuracy_score(y[train_idx], np.zeros(train_vw_cv.shape))\n                    acc_valid = accuracy_score(y[valid_idx], np.zeros(valid_vw_cv.shape))\n                scores['train_' + clf_name].append(acc_train)            \n                scores['valid_'+ clf_name].append(acc_valid)\n    return scores\n\ndef plotAccuracy(scores_clf, suff=''):\n    # create the pd.DataFrames to store the average stats\n    acc_valid_cv_summary = pd.DataFrame(index=sorted(models.keys()), columns=['raw'], dtype=np.float32)\n    acc_train_cv_summary = pd.DataFrame(index=sorted(models.keys()), columns=['raw'], dtype=np.float32)\n    # fill in the average stats\n    for clf_name in models.keys():\n        acc_valid_cv_summary.loc[clf_name, 'raw'] = np.mean(scores_clf['valid_' + clf_name])\n        acc_train_cv_summary.loc[clf_name, 'raw'] = np.mean(scores_clf['train_' + clf_name])\n\n    #create a figure with 2 subplots\n    fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n    # increase the white space to fil it long Y axis labels\n    fig.subplots_adjust(wspace=1.0)\n    \n    # The comparison of the two tells us about amount of overtraining\n    # performance of the VALIDATION sample \n    sns.heatmap(acc_valid_cv_summary, cmap='Blues', annot=True, vmin=0.75, vmax=0.9, ax=ax[0])\n    ax[0].set_title('Accuracy on VALIDATION sample ' + suff + '(mean from CV)')\n    # performance of the TRAINING sample \n    sns.heatmap(acc_train_cv_summary, cmap='Blues', annot=True, vmin=0.75, vmax=0.9, ax=ax[1])\n    ax[1].set_title('Accuracy on TRAIN sample ' + suff + '(mean from CV)')\n    ","55a46480":"scores_Names = analyseAccuracy(train_vw)\nscores_Titles = analyseAccuracy(train_title_vw)\n\nplotAccuracy(scores_Names, 'using FULL NAME ')\nplotAccuracy(scores_Titles, 'using TITLE ONLY ')","b4da468f":"### Train: Prepare VW-native format (combine X and y)","889c9ec2":"# Vowpal Wabbit","58f30ac3":"The left column in the plots above is more informative, as it shows performance on the validation set, whereas the right column shows performance on the training set, i.e. it includes the bias due to model seeing these exact data in the training.\n\nLet's draw some conclusions:\n1.  Looking on bottom left: VW can effectively learn the gender from the title of the person alone: compare accuracy of *VW_passes1* agains  *WomenSurvive* (which is a dummy, that predicts that all women survive, while all man die)\n2. Comparing top left vs bottom left: VW can extract extra information from the full name text and improve over the dummy *WomenSurvive* prediction. Note, that we did not have to do any text parsing or any kind of encoding- everything was done for us iternally by VW.\n3. Comparing top left vs top right: once we train on the full name, there is room for overtraining. (especcially if we do more than 1 pass over the data, compare behaviour of *VW_pases1* vs *VW_passes2*). L2 regularisation helps to fight it back.","30dde1aa":"# The first running Vowpal Wabbit kernel  using sklearn API\n\nDisclaimer: The purpose of the kernel is to illustrate usage of Vowpal Wabbit. Thus, there will be no exploratory data analysis (EDA) or feature engineering. We will do a basic data cleaning to drop missing values and to impute Age and that is it. You are invited to extend this quick analysis with more data features. One can find many excellent kernels explaining how to do it.\n\n## This is the FIRST running kernal on kaggle that uses vowpal wabbit\n\n**Why to bother about this notebook?** It gives you experience with the sklearn interface of vowpal wabbit instead of the native command-line tool. This allows you to make full use of the sklearn ecosystem and you do not have to convert your data into package-specific format (tools do it themselves under the hood)\n\nThis is the first kernel that will actually run on kaggle, to my knowledge. There are already several others, that contain the full chain of commands and printed outputs, but one was not able to execute those on kaggle up to recent time (and I claim it, because I implemented VW in the kaggle docker repository myself :) )\n\n## The key goal: \n\n**See if VW can learn gender from the Ms\/Mr\/etc title and if there is something extra that it can learn automatically from the rest of the name text**","729ee852":"* ### Test: Prepare VW-native format (only  X)","a3155624":"## Read the original Data in\n\nLet's start by reading in the train and test csv files into a pandas dataframe.\nIf one uses kaggle-api to download datasets, they are available in a standardised location `~\/.kaggle\/competitions\/`","6d84b23d":"### Convert Survived label to follow the VW label convention"}}