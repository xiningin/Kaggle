{"cell_type":{"ab0c4907":"code","bff0c5f0":"code","6322e12b":"code","60c6af8e":"code","6cc83be8":"code","9df2c3fc":"code","47bdf0fa":"code","4929ab86":"code","b58a898d":"code","7d23aa7c":"code","a52894d5":"code","43f07279":"code","3bb90344":"code","40264b7a":"code","dacb06c2":"code","2aabd90b":"markdown","36c12aa9":"markdown","133664c2":"markdown","fe5b4855":"markdown"},"source":{"ab0c4907":"# Importing required modules\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks import LambdaCallback \nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.datasets import mnist, cifar10\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nfrom tqdm import tqdm\n","bff0c5f0":"# Utility functions\ndef print_shapes(x_train, x_test, y_train, y_test):\n  print(f\"x_train: {x_train.shape}\\n\"\\\n      f\"x_test: {x_test.shape}\\n\"\\\n      f\"y_train: {y_train.shape}\\n\"\\\n      f\"y_test: {y_test.shape}\\n\")","6322e12b":"# loading the dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint_shapes(x_train, x_test, y_train, y_test)","60c6af8e":"# Preprocessing images and labels\nheight, width, channels = 32, 32, 3\nnb_classes = 10 \nlabel_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n               'horse', 'ship', 'truck']\n\nx_train = x_train \/ 255\nx_test = x_test \/ 255\n\nx_train = x_train.reshape((-1, height, width, channels))\nx_test = x_test.reshape((-1, height, width, channels))\n\ny_train = tf.keras.utils.to_categorical(y_train, nb_classes)\ny_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n\nprint_shapes(x_train, x_test, y_train, y_test)","6cc83be8":"# Building a simple CNN model\nmodel = Sequential()\n\nmodel.add(L.Conv2D(128, kernel_size=(3, 3),\n                 padding='same', activation='relu', \n                 input_shape=(height, width, channels)))\nmodel.add(L.Dropout(0.3))\n\nmodel.add(L.Conv2D(64, kernel_size=(3, 3),\n                 padding='same', activation='relu', \n                 input_shape=(height, width, channels)))\nmodel.add(L.Dropout(0.3))\n\nmodel.add(L.Conv2D(64, kernel_size=(3, 3),\n                 padding='same', activation='relu'))\nmodel.add(L.Dropout(0.3))\nmodel.add(L.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(L.Conv2D(64, kernel_size=(3, 3),\n                 padding='same', activation='relu'))\nmodel.add(L.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(L.Dropout(0.3))\nmodel.add(L.Flatten())\nmodel.add(L.Dense(32))\nmodel.add(L.Dropout(0.2))\nmodel.add(L.Dense(nb_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n\nmodel.summary()","9df2c3fc":"# Training the model\nhistory = model.fit(x_train, y_train,\n                    batch_size=32,\n                    epochs=8,\n                    validation_data=(x_test, y_test))","47bdf0fa":"# plotting loss\nplt.plot(history.history['loss'], label=\"loss\")\nplt.plot(history.history['val_loss'], label=\"val_loss\")\nplt.legend()\nplt.show()","4929ab86":"# plotting accuracy\nplt.plot(history.history['accuracy'], label=\"accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.legend()\nplt.show()","b58a898d":"# Function to calculate adversary noise\ndef generate_adversary(image, label):\n  image = tf.cast(image, tf.float32)\n\n  with tf.GradientTape() as tape:\n    tape.watch(image)\n    prediction = model(image)\n    loss = tf.keras.losses.MSE(label, prediction)\n  gradient = tape.gradient(loss, image)\n  sign_grad = tf.sign(gradient)\n\n  return sign_grad","7d23aa7c":"# Selecting random image for testing\nrand_idx = randint(0,49999)\nimage = x_train[rand_idx].reshape((1, height, width, channels))\nlabel = y_train[rand_idx]\n\nprint(f'Prediction from CNN: {label_names[np.where(label==1)[0][0]]}')\nplt.figure(figsize=(3,3))\nplt.imshow(image.reshape((height, width, channels)))\nplt.show()","a52894d5":"# Adding the adversary noise to image\nperturbations = generate_adversary(image,label).numpy()\nadversarial = image + (perturbations * 0.05)","43f07279":"# Comparing both images \nfig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\nax1.imshow(image.reshape(height,width, channels))\nax1.set_title(\"Original Image\")\nax2.imshow(adversarial.reshape(height,width, channels))\nax2.set_title(\"Image with Adversary\")\nplt.show()","3bb90344":"# Comparing predictions\nprint(f'Normal Image Prediction: {label_names[model.predict(image).argmax()]}')\nprint(f\"Adversary Prediction: {label_names[model.predict(adversarial).argmax()]}\")","40264b7a":"# Function to generate batch of images with adversary\ndef adversary_generator(batch_size):\n  while True:\n    images = []\n    labels = []\n    for batch in range(batch_size):\n      N = randint(0, 49999)\n      label = y_train[N]\n      image = x_train[N].reshape((1,height, width, channels))\n\n      perturbations = generate_adversary(image, label).numpy()\n      adversarial = image + (perturbations * 0.1)\n\n      images.append(adversarial)\n      labels.append(label)\n\n      if batch%1000 == 0:\n        print(f\"{batch} images generated\")\n\n    images = np.asarray(images).reshape((batch_size, height, width, channels))\n    labels = np.asarray(labels)\n\n    yield images, labels","dacb06c2":"# Testing model accuracy on adversarial examples\nx_adversarial, y_adversarial = next(adversary_generator(10000))\nad_acc = model.evaluate(x_adversarial, y_adversarial, verbose=0)\nprint(f\"Accuracy on Adversarial Examples: {ad_acc[1]*100}\")","2aabd90b":"## Reducing the accuracy of a CNN","36c12aa9":"### Fast Gradient Signed Method (FGSM) attack to generate noise.","133664c2":"## This problem of reduced accuracy, can be solved by augmenting the dataset with adversarial images. There are also other methods to generate adversary noise, will be adding them to this kernel soon.","fe5b4855":"## Do upvote, if you found this helpful."}}