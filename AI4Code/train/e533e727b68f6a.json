{"cell_type":{"c660c489":"code","a2802e61":"code","ddec1b23":"code","a12298cc":"code","70b65b74":"code","58bc22b7":"code","79865f13":"code","ffe99d9d":"code","f6da82a0":"code","98f169b7":"code","96a3bdc7":"code","6e99f44e":"code","c313a7fd":"code","f4a2d9cc":"code","9cb8065f":"code","9d98bdc1":"code","30a7b1d8":"code","3dfb09bf":"code","6b0453f3":"code","f7d50f2d":"markdown","9892aede":"markdown","303bd4c5":"markdown","e4f86585":"markdown","c2d800d6":"markdown","900f13dc":"markdown","63bdee5e":"markdown","4441e7d8":"markdown","777393f3":"markdown","30262b29":"markdown","7c0a6bdd":"markdown","b895aa7a":"markdown","6db32d00":"markdown","658d1136":"markdown","96c64cec":"markdown","f2fa1df2":"markdown","8d72d41c":"markdown"},"source":{"c660c489":"!kaggle competitions download -c tp-n2-aprendizaje-profundo-2021-by-datitos-v2","a2802e61":"!unzip tp-n2-aprendizaje-profundo-2021-by-datitos-v2.zip","ddec1b23":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('fifa2021_training.csv')\ndf_infer = pd.read_csv('fifa2021_test.csv')","a12298cc":"df.iloc[0]","70b65b74":"from sklearn.model_selection import train_test_split\n\ndf_train, df_valid = train_test_split(df, stratify=df.Position, train_size=0.9, random_state=42)","58bc22b7":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\n\nvariables_descartar = [\n    'Position', # variable objetivo\n    'ID',\n    'Name',\n    'Natinality',\n    'BirthDate',\n    'Value',\n    'Wage',\n    'Club',\n    'Club_KitNumber',\n    'Club_JoinedClub',\n    'Club_ContractLength',\n]\n\nvariables_categ\u00f3ricas = df.drop(columns=variables_descartar).select_dtypes(include=np.object).columns\nvariables_num\u00e9ricas   = df.drop(columns=variables_descartar).select_dtypes(include=np.number).columns\n\ntransformador = make_column_transformer(\n    (OneHotEncoder(),  variables_categ\u00f3ricas), # PreferredFoot, PlayerWorkRate, Sex\n    (StandardScaler(), variables_num\u00e9ricas),   # Overal, Potential, Height, etc.\n    remainder='drop' # descarta las columnas no mencionadas en las transformaciones\n)","79865f13":"transformador.fit(df_train)","ffe99d9d":"# el transformador se queja si falta alguna columna de df_train :\/\ndf_infer['Position'] = None\n\n\nX_train = transformador.transform(df_train)\nX_valid = transformador.transform(df_valid)\nX_infer = transformador.transform(df_infer)","f6da82a0":"from sklearn.preprocessing import LabelEncoder\n\ntransformador_etiquetas = LabelEncoder()\n\ntransformador_etiquetas.fit(df_train.Position)\n\ny_train = transformador_etiquetas.transform(df_train.Position)\ny_valid = transformador_etiquetas.transform(df_valid.Position)","98f169b7":"from torch.utils.data import Dataset\n\nclass Tabular(Dataset):\n    def __init__(self, X, y=None):\n        self.X = X.astype(np.float32) # soluciona \"Expected object of scalar type Float but got scalar type Double\"\n        self.y = y \n\n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, item):\n        if self.y is None:\n            return self.X[item]\n        else:\n            return self.X[item], self.y[item]\n\n        \nds_train = Tabular(X_train, y_train)","96a3bdc7":"ds_train[10]","6e99f44e":"from torch.utils.data import DataLoader\n\ndl_train = DataLoader(ds_train, batch_size=32, shuffle=True)","c313a7fd":"X_valid = torch.tensor(X_valid).float()\nX_infer = torch.tensor(X_infer).float()\n\ny_valid = torch.tensor(y_valid)","f4a2d9cc":"import torch\nimport torch.nn as nn","9cb8065f":"IN  = X_trans.shape[1]\nOUT = len(transformador_etiquetas.classes_)\n\nmodelo = nn.Sequential(\n    nn.Linear(IN,  8),\n    nn.Linear( 8, 64), nn.ReLU(),\n    nn.Linear(64, 32), nn.ReLU(),\n    nn.Linear(32, OUT)\n)","9d98bdc1":"criterio = nn.CrossEntropyLoss()\noptimizador = torch.optim.Adam(modelo.parameters(), lr=0.0001)","30a7b1d8":"from sklearn.metrics import balanced_accuracy_score\n\n\u00c9POCAS = 10\n\nfor \u00e9poca in range(\u00c9POCAS):\n    # activa capas Dropout, BatchNorm si las hubiese\n    modelo.train()\n\n    p\u00e9rdidas_train = []\n    \n    for X_lote, y_lote in dl_train:\n        optimizador.zero_grad()\n\n        predicciones = modelo(X_lote)\n        p\u00e9rdida = criterio(predicciones, y_lote)\n\n        p\u00e9rdida.backward()\n        optimizador.step()\n        \n        p\u00e9rdidas_train.append(p\u00e9rdida.item())\n    \n    # desactiva capas Dropout, BatchNorm si las hubiese\n    modelo.eval()\n    \n    with torch.no_grad():\n        predicciones = modelo(X_valid)\n        p\u00e9rdida = criterio(predicciones, y_valid)\n        \n        y_pred = predicciones.argmax(dim=1) # selecciona la clase con mayor probabilidad\n        \n        efectividad = balanced_accuracy_score(y_valid, y_pred)\n    \n    \n    print(f'{\u00e9poca:3d}  |  Train loss: {np.mean(p\u00e9rdidas_train):.3f}    Valid loss: {p\u00e9rdida:.3f}    Valid accuracy: {efectividad:.2f}')","3dfb09bf":"with torch.no_grad():\n    y_infer = modelo(X_infer).argmax(dim=1)\n\ndf_infer['Position'] = transformador_etiquetas.inverse_transform(y_infer)\n\n(\n    df_infer[['ID', 'Position']]\n    .rename(columns={'ID':'Id', 'Position':'Category'})\n    .to_csv('submit.csv', index=False)\n)","6b0453f3":"!kaggle competitions submit -c tp-n2-aprendizaje-profundo-2021-by-datitos-v2 -f submit.csv -m \"Brasil, decime qu\u00e9 se siente\"","f7d50f2d":"# Trabajo pr\u00e1ctico 2","9892aede":"### Transformar variable objetivo\n\nComo la variable objetivo es del tipo string, hay que llevarla a un tipo num\u00e9rico para que PyTorch pueda procesarla.\n\nEste transformador mapea posiciones DEF, FWD, GK, MID a enteros **y viceversa** \u2014 la transformaci\u00f3n inversa ser\u00e1 \u00fatil para convertir las predicciones (enteros) en posiciones otra vez.","303bd4c5":"### Entrenar modelo","e4f86585":"### Obtener datasets","c2d800d6":"### Subir predicciones","900f13dc":"### Breve an\u00e1lisis exploratorio","63bdee5e":"Una de las cosas que `DataLoader` hace es convertir arreglos de NumPy en tensores de PyTorch.\n\nComo no vamos a hacer esto\n\n```python\n# sin shuffle porque validaci\u00f3n e inferencia no requieren barajar sus elementos \ndl_valid = DataLoader(ds_valid, batch_size=32)\ndl_infer = DataLoader(ds_infer, batch_size=32)\n```\n\nvamos a definir tensores a mano.","4441e7d8":"### Cargar datasets","777393f3":"### Instanciar modelo","30262b29":"### Instanciar Datasets de PyTorch\n\nEl aprendizaje profundo es especialmente efectivo para im\u00e1genes y texto; para datos tabulares (como un DataFrame) el aprendizaje de m\u00e1quinas cl\u00e1sico suele funcionar bastante bien, de ah\u00ed que PyTorch no cuente con facilidades para tratar este tipo de problemas.","7c0a6bdd":"Como el dataset es liviano y entra en la memoria, para validaci\u00f3n e inferencia en vez de hacer esto\n\n```python\nds_valid = Tabular(X_valid, y_valid)\nds_infer = Tabular(X_infer)\n```\n\nvamos a usar tensores simplemente para no complicarla.","b895aa7a":"### Particionar datasets","6db32d00":"### Inferir datos de prueba","658d1136":"### Instanciar DataLoaders de PyTorch","96c64cec":"### Entrenar transformador\n\nEsencialmente, calculamos los **promedios** y las **desviaciones est\u00e1ndares** que usaremos para la estandarizaci\u00f3n.\n\n**ESTOS VALORES SOLO DEBEN SER OBTENIDOS DEL DATASET DE ENTRENAMIENTO**.","f2fa1df2":"### Definir transformaciones","8d72d41c":"### Transformar datasets"}}