{"cell_type":{"32e964d4":"code","8b602c59":"code","55b37cca":"code","1b8e9866":"code","02a1b06a":"code","924708bc":"code","fdb806b1":"code","1e37c23f":"code","9f629a1d":"code","8a60a4b6":"code","23b513fe":"code","08826eef":"code","3436ad95":"code","0c0e3b79":"code","cfefcf46":"code","7c92a01a":"code","3929b19b":"code","3ca342ff":"code","3454278c":"code","54db4e34":"code","89ce9a0d":"code","c0b3d019":"code","d777fd64":"code","cb4ae26d":"code","ff3dc932":"code","a982af03":"code","167deb14":"code","e664682b":"code","506afe7b":"code","93d4f769":"code","aacad667":"code","5f88874e":"code","413180a3":"code","92cfd84a":"code","f9f0b52e":"code","f20ffccf":"code","d0fbd3bd":"code","fa029b66":"code","17a9d6a7":"code","7da863bb":"code","1a86a7cb":"code","69fb3706":"code","8182c080":"code","5015094c":"code","141361d8":"code","b5687fb8":"code","97bb2d97":"code","f4b0a80e":"code","530b65bc":"code","cc845699":"code","0b3f89c7":"code","3517195d":"code","407146e5":"code","2a04a51d":"code","abd626a8":"markdown","fb873807":"markdown","249ed226":"markdown","006bcf9e":"markdown","9eb79ec2":"markdown"},"source":{"32e964d4":"import pandas as pd\nimport os\nimport time\nimport seaborn as sns\nimport re\nimport gensim\nfrom nltk.stem import WordNetLemmatizer","8b602c59":"#Load the dataset\ndf = pd.read_csv('\/kaggle\/input\/large-random-tweets-from-pakistan\/Random Tweets from Pakistan- Cleaned- Anonymous.csv',encoding = \"ISO-8859-1\", engine='python')\n","55b37cca":"#Checking the data shape\ndf.shape","1b8e9866":"#checking its columns, i used two columns only as mentioned in Exam Requirements\ndf.columns","02a1b06a":"#checking datatype of columns\ndf.dtypes","924708bc":"#checking first few rows\ndf.head()","fdb806b1":"#checking last few rows\ndf.tail","1e37c23f":"df.isnull().values.any()","9f629a1d":"df.isnull().sum()","8a60a4b6":"#checking the unqiue tweets\ndf['full_text'].unique()","23b513fe":"#checking null values in total\ndf.isnull().sum()","08826eef":"#checking duplicate values in total\ndf.duplicated().sum()","3436ad95":"df.drop_duplicates(inplace=True)\ndf.shape","0c0e3b79":"def creat_corpus (df, Tweet):\n\n    corpus = []\n    \n    for x in df[df['full_text']== Tweet].text.str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","cfefcf46":"# Start with loading all necessary libraries\nimport numpy as np\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","7c92a01a":"print(\"There are {} types of cities in this dataset such as {}... \\n\".format(len(df.location.unique()),\n                                                                           \", \".join(df.location.unique()[0:5])))","3929b19b":"?WordCloud","3ca342ff":"df.columns","3454278c":"type('full_text')","54db4e34":"from PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","89ce9a0d":"text=df.full_text[0]","c0b3d019":"# Create and generate a word cloud image:\nwordcloud = WordCloud().generate(text)","d777fd64":"# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","cb4ae26d":"# lower max_font_size, change the maximum number of word and lighten the background:\nwordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","ff3dc932":"def plot_cloud(worldcloud):\n    plt.figure(fig_size =(40, 30))\n    plt.imshow(worldcloud)\n    plt.axis(\"off\");","a982af03":"text = \" \".join(str(review) for review in df.full_text)","167deb14":"print (\"There are {} words in the combination of all review.\".format(len(text)))","e664682b":"stopwords = set(STOPWORDS)\nstopwords.update([\"Pakistan\", \"PTI\", \"Imran\", \"Islam\", \"Identity\"])\n\n# Generate a word cloud image\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n\n# Display the generated image:\n# the matplotlib way:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","506afe7b":"Create an emoji cloud for most emoji","93d4f769":"from wordcloud import WordCloud\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport emojis","aacad667":"class EmojiCloud:\n    def _init_(self, font_path='Symbola.otf'):\n        self.font_path = font_path\n        self.word_cloud = self.initialize_wordcloud()\n        self.emoji_probability = None","5f88874e":"def initialize_wordcloud(self):\n        return WordCloud(font_path=self.font_path,\n                               width=2000,\n                               height=1000,\n                               background_color='white',\n                               random_state=42,\n                               collocations=False)","413180a3":"def color_func(self, word, font_size, position, orientation, random_state=None,\n                   **kwargs):\n        hue_saturation = '42, 88%'\n\n        current_emoji_probability = self.emoji_probability[word]\n        if current_emoji_probability >= 0.10:\n            opacity = 50\n        else:\n            opacity = 75 - current_emoji_probability\/0.2 * 5\n        return f\"hsl({hue_saturation},{opacity}%)\"","92cfd84a":"def generate(self, text): \n        emoji_frequencies = Counter(emojis.iter(text))\n        total_count = sum(emoji_frequencies.values())  \n        self.emoji_probability = {emoji: count\/total_count for emoji, count in emoji_frequencies.items()}\n        wc = self.word_cloud.generate_from_frequencies(emoji_frequencies)\n        plt.figure(figsize=(20,10))\n        plt.imshow(wc.recolor(color_func=self.color_func, random_state=42))\n        plt.axis(\"off\")","f9f0b52e":"text[0].split()","f20ffccf":"df['full_text'].iloc[0].split()","d0fbd3bd":"df['full_text'].iloc[0].lower().split()\n\n","fa029b66":"# Create a list of lists containing lowercase words for each tweet\nwords_in_tweet = [tweet.lower().split() for tweet in df]\nwords_in_tweet[:2]","17a9d6a7":"# Create a list of lists containing lowercase words for each tweet\nwords_in_tweet = [tweet.lower().split() for tweet in df]\nwords_in_tweet[:2]","7da863bb":"text = \" \".join(str(review) for review in df.full_text)","1a86a7cb":"with open ('positivewords.txt', encoding = 'unicode_escape') as f:\n    p = f.readlines()\n    p=[x.strip() for x in p]\nwith open ('negetivewords.txt', encoding = 'unicode_escape') as f:\n    n=f.readlines()\n    n=[x.strip() for x in n]","69fb3706":"for x in text.split():\n    if x in p:\n        cp+=1\n    if x in n:\n        cn+=1","8182c080":"sns.barplot(y=[cp,cn], x =['Positive Words', 'negetive words'])","5015094c":"location = df.groupby('Location').count()\nlocation.sort_values(by='Tweet', ascending = False).iloc[0]\n#readon of location pakisan is,i filled the missing or vouge locations with pakistan so modt of the locations\n#have been filled with this name","141361d8":" Identify abusive word count frequency","b5687fb8":"abuse =!curl https:\/\/github.com\/LDNOOBW\/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words\/blob\/master\/en","97bb2d97":"count = {}\nfor x in abuse:\n    for y in text.split():\n        if x==y:\n            try:\n                count[x] +=1\n            except:\n                count[x] = 1","f4b0a80e":"import re\ndf['full_text']=df['full_text'].apply(str)\ndef cleantxt(text):\n    text = re.sub(r'@[A-Za-z0-9]+', '',text)\n    text = re.sub(r'#', '',text)\n    text = re.sub(r'RT[\\s]+', '',text)\n    text = re.sub(r'https?:\\\/\\\/\\S+', '',text)\n    \n    return text\n\ndf['full_text'] = df['full_text'].apply(cleantxt)\n\ndf['full_text']","530b65bc":"from textblob import TextBlob\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\n\ndf['Subjectivity'] = df['full_text'].apply(getSubjectivity)\ndf['Polarity'] = df['full_text'].apply(getPolarity)\n\ndf","cc845699":"def getAnalysis(score):\n    if score < 0:\n        return 'Negative'\n    elif score == 0:\n        return 'Neutral'\n    else:\n        return 'Positive'\n    \ndf['Analysis'] = df['Polarity'].apply(getAnalysis)\n\ndf","0b3f89c7":"import matplotlib.pyplot as plt","3517195d":"df['Analysis'].value_counts()\n\nplt.title('Sentiment Analysis')\nplt.xlabel('Sentiment')\nplt.ylabel('Counts')\ndf['Analysis'].value_counts().plot(kind='bar')\nplt.show()","407146e5":"from wordcloud import WordCloud","2a04a51d":"allwords = ''.join(twts for twts in df['full_text'])\nwordCloud = WordCloud(width = 800, height = 500, random_state = 21, max_font_size = 119).generate(allwords)\nplt.imshow(wordCloud, interpolation = \"bilinear\")\nplt.axis('off')\nplt.show()","abd626a8":"Create a word cloud for the most words used","fb873807":"Create a plot between positive and negative word counts","249ed226":" Identify the city that uses twitter most","006bcf9e":"Import Keras Libraries","9eb79ec2":"Topic Modeling"}}