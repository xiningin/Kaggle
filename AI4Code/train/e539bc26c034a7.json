{"cell_type":{"49100bba":"code","9904ec47":"code","044bc270":"code","c1725a8a":"code","2747f89c":"code","e39d7614":"code","94a6a9c8":"code","3ac82ad6":"code","081cf3a9":"code","3a85bd9f":"code","53d96390":"code","8e043618":"code","027325bd":"code","4041d69f":"code","a1f540cb":"code","7bd3e3ab":"code","476ad241":"code","468b7dbb":"code","2271a176":"code","f7b87316":"code","ff683219":"code","0cdafdf6":"markdown","068de368":"markdown","c2071979":"markdown","49314f55":"markdown","47b75b80":"markdown","cfc833dd":"markdown","ef8120d6":"markdown","ecc292e6":"markdown","ae8c8125":"markdown"},"source":{"49100bba":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai.callbacks.tracker import EarlyStoppingCallback\nfrom sklearn.model_selection import train_test_split","9904ec47":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(train.shape)\nprint(test.shape)\nn_train_img = train.shape[0]\nMAX_LR=3e-3\nVALID_PCT=3000\/n_train_img\nVALID_PCT=.1\nVALID_PCT","044bc270":"train.sample(5)","c1725a8a":"test.sample(5)","2747f89c":"class ArrayDataset(Dataset):\n    \"Sample numpy array dataset\"\n    def __init__(self, x, y):\n        self.x, self.y = x, y\n        self.c = 10 # number of labels\n    \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, i):\n        return self.x[i], self.y[i]\n\ndef reshape_and_normalize(arr):\n    return arr.astype(np.float32).reshape([-1, 1, 28, 28])\/255.0\n\ndef conv2(ni,nf): \n    return conv_layer(ni,nf,stride=2)\n\ndef conv_and_res(ni,nf): \n    return nn.Sequential(conv2(ni, nf), res_block(nf))\n\ndef create_nn(n_channel=1):\n    model = nn.Sequential(\n        conv_and_res(n_channel, 8),\n        conv_and_res(8, 16),\n        conv_and_res(16, 32),\n        conv_and_res(32, 16),\n        conv2(16, 10),\n        Flatten()\n    )\n    return model\n\ndef get_preds(learn):\n    pred, _ = learn.get_preds(ds_type=DatasetType.Test)\n    print(len(pred))\n    pred = pd.Series(np.argmax(pred, 1))\n    print(pred.unique())\n    return pred\n\ndef get_callbacks():\n    return [partial(EarlyStoppingCallback, \n                    # monitor='accuracy', \n                    patience=3\n                   )]\n\ndef create_learner(data, model):\n    learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), \n                    metrics=accuracy,\n                    callback_fns=get_callbacks())\n    return learn\n\n\ndef create_submission(learn, file='learn.csv'):\n    pred = get_preds(learn)\n    submission = pd.DataFrame({'ImageId': range(1,1+len(pred)), 'Label': pred})\n    submission.to_csv(file, index=False)\n    return","e39d7614":"%%time\ndata = prepare_dataset(train, test)\nlearn = create_learner(data, create_nn())\nlearn.fit_one_cycle(1, max_lr=MAX_LR)\nlearn.lr_find(end_lr=10)\nlearn.recorder.plot()","94a6a9c8":"# A method to create ImageDataBunch directly from the pandas dataframes.\n# But I don't know how to do data augmentation in this case.\n# So this method is defined but not used.\ndef prepare_dataset(train, test):\n    X = reshape_and_normalize(train.drop('label', axis=1).values)\n    y = train.label.values\n    train_x, valid_x, train_y, valid_y = train_test_split(X, y,test_size=VALID_PCT)\n    test_x = reshape_and_normalize(test.values)\n\n    train_ds, valid_ds = ArrayDataset(train_x, train_y), ArrayDataset(valid_x, valid_y)\n    test_ds = ArrayDataset(test_x, [EmptyLabel()]*len(test_x))\n\n    data = ImageDataBunch.create(train_ds, valid_ds,\n                                 test_ds,\n                                 bs=100, num_workers=1)\n#     data.normalize()\n    print(\"Train\/Valid\/Test sizes:\", len(train_ds), len(valid_ds), len(test_ds))\n    # xb,yb = data.one_batch()\n    # print(xb.shape,yb.shape)\n    # print(xb, yb)\n\n    return data","3ac82ad6":"%%bash\nmkdir -p png\/train\/{0,1,2,3,4,5,6,7,8,9} png\/test","081cf3a9":"%%time\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef save_png(train, test):\n    for cnt, row in train.iterrows():\n        fname = \"png\/train\/{}\/{}.png\".format(row.label, cnt)\n        cv2.imwrite(fname, row.values[1:].reshape([28,28]))\n\n    for cnt, row in test.iterrows():\n        fname = \"png\/test\/{}.png\".format(cnt)\n        cv2.imwrite(fname, row.values.reshape([28,28]))\n    \n    test_fnames = [\"png\/test\/{}.png\".format(cnt) for cnt in range(test.shape[0])]\n    test_df = pd.DataFrame({'fname': test_fnames})\n    return test_df\n    \n\ntest_df = save_png(train, test)","3a85bd9f":"tfms = get_transforms(do_flip=False)\nlen(tfms)\ntfms\n# tfms = (tfms[0],[]) # Don't transform validation sets","53d96390":"%%time\ndata = ImageDataBunch.from_folder('png\/train', \n#                                   test='..\/test',\n                                  bs=100,\n                                  ds_tfms=tfms, \n                                  valid_pct=VALID_PCT\n                                 )\ndata.add_test(ImageList.from_df(test_df, '.'))\ndata.normalize()\ndata","8e043618":"data.show_batch(figsize=(7,6))","027325bd":"%%time\nlearn1 = create_learner(data, create_nn(3))\nlearn1.fit_one_cycle(1, max_lr=MAX_LR)\nlearn1.lr_find(end_lr=10)\nlearn1.recorder.plot()","4041d69f":"# %%time\nlearn1.fit_one_cycle(100, max_lr=MAX_LR)\nlearn1.recorder.plot()","a1f540cb":"learn1.show_results(figsize=(6,9))","7bd3e3ab":"create_submission(learn1, file='learn1.csv')\n!head learn1.csv","476ad241":"%%time\nlearn2 = cnn_learner(data, \n#                     models.resnet18, \n#                     models.resnet34, \n                    models.resnet50, \n                    metrics=[accuracy], callback_fns=get_callbacks())\nlearn2.fit_one_cycle(1, max_lr=MAX_LR)\nlearn2.lr_find(end_lr=10)\nlearn2.recorder.plot()","468b7dbb":"%%time\nlearn2.fit_one_cycle(100, max_lr=MAX_LR)\nlearn2.recorder.plot()","2271a176":"# learn2.interpret().plot_multi_top_losses(5, figsize=(1,1))","f7b87316":"create_submission(learn2, 'learn2.csv')\n!head learn2.csv","ff683219":"!rm -Rf png","0cdafdf6":"# Cleaning\n\nRemove temporarily created PNGs, otherwise the kernel will fail while committing and not able to creat submission CSV files.","068de368":"# Learn MNIST using fast.ai\n\nWe are not using external MNIST data, but will try some pretrained ResNet models.\n","c2071979":"# Network","49314f55":"# Predict and submit","47b75b80":"To use the fast.ai data augmentation facility, I first save the images as PNGs, then call `get_transforms` method.","cfc833dd":"# Transfer Learning from ResNet","ef8120d6":"# Learn","ecc292e6":"# Create an ImageDataBunch\n\n","ae8c8125":"To create an ImageDataBunch using the image transformation `tfms` defined above."}}