{"cell_type":{"aeb55b94":"code","be55e4ed":"code","cc89ac9a":"code","2dbb02a4":"code","eb278698":"code","1cb897ec":"code","086f8b51":"code","2e15112e":"code","239e1656":"code","6b391504":"code","25b7c7a8":"code","79e5f144":"code","9a583915":"code","6c29fe58":"code","5005e72a":"code","80ebf400":"code","30fd6f1f":"code","56c4964b":"code","6e052843":"code","dd6de438":"code","059be90a":"code","98deea5c":"code","db5fcef7":"code","3b752763":"code","50839b96":"code","e4b2a920":"code","e772b6a6":"code","2bbe4c52":"code","da9d45f2":"code","e3b5b17b":"code","314e4c8e":"code","d59634ab":"code","1bf95c9f":"code","9d1f2b24":"code","e23e6e4c":"code","9c6ba716":"markdown","2c290031":"markdown","2af9dfc5":"markdown","1d37f2e8":"markdown","69e77f0f":"markdown","e88f0812":"markdown","78916173":"markdown","67eabb79":"markdown","d3d7e423":"markdown","9d2b2f92":"markdown","1f8cd66b":"markdown","62ebf1de":"markdown","1e1c0a40":"markdown"},"source":{"aeb55b94":"# install TabNet first\n!pip install pytorch-tabnet","be55e4ed":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# TabNet and ML tools\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nfrom sklearn.model_selection import KFold\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","cc89ac9a":"# load training data\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/train.csv')\ndf_train.head()","2dbb02a4":"# histogram of target\ndf_train.target.plot(kind='hist', bins=50)\nplt.title('Target - Histogram')\nplt.grid()\nplt.show()","eb278698":"# KDE plot of target\ndf_train.target.plot(kind='kde')\nplt.title('Target - Kernel Density Estimator')\nplt.grid()\nplt.show()","1cb897ec":"# boxplot of target => looking for outliers\ndf_train.target.plot(kind='box')\nplt.title('Target - Boxplot')\nplt.grid()\nplt.show()","086f8b51":"df_zero = df_train[df_train.target==0]\ndf_zero","2e15112e":"df_train = df_train[df_train.target>0]\ndf_train.target.describe()","239e1656":"features = ['cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n            'cont6', 'cont7', 'cont8', 'cont9', 'cont10',\n            'cont11', 'cont12', 'cont13', 'cont14']","6b391504":"# summary stats\ndf_train[features].describe()","25b7c7a8":"for f in features:\n    plt.figure(figsize=(8,4))\n    plt.hist(df_train[f], bins=100)\n    plt.title(f)\n    plt.grid()\n    plt.show()","79e5f144":"corr_pearson = df_train[features].corr(method='pearson')\ncorr_spearman = df_train[features].corr(method='spearman')","9a583915":"fig = plt.figure(figsize = (12,9))\nsns.heatmap(corr_pearson, annot=True, cmap=\"RdYlGn\")\nplt.title('Pearson Correlation')\nplt.show()","6c29fe58":"fig = plt.figure(figsize = (12,9))\nsns.heatmap(corr_spearman, annot=True, cmap=\"RdYlGn\")\nplt.title('Spearman Correlation')\nplt.show()","5005e72a":"# pairwise scatter plot of features (takes some time to render!)\nsns.pairplot(df_train[features], kind='scatter', plot_kws={'alpha': 0.01})\nplt.show()","80ebf400":"for f in features:\n    c = df_train[f].corr(df_train.target, method='pearson')\n    c = np.round(c,4)\n    plt.figure(figsize=(7,7))\n    plt.scatter(df_train[f], df_train.target, alpha=0.01)\n    plt.title('Target vs ' + f + ' \/ corr = ' + str(c))\n    plt.xlabel(f)\n    plt.ylabel('Target')\n    plt.grid()\n    plt.show()","30fd6f1f":"for f in features:\n    new_var = f + '_bin'\n    df_train[new_var] = pd.cut(df_train[f], bins=10, include_lowest=True)\n    plt.figure(figsize=(7,7))\n    sns.boxplot(data=df_train, x=new_var, y='target')\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.show()","56c4964b":"# load test data\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/test.csv')\ndf_test.head()","6e052843":"# dimensions of test set\ndf_test.shape","dd6de438":"# feature matrices\nX = df_train[features].to_numpy()\nX_test = df_test[features].to_numpy()\n\n# target\ny = df_train.target.to_numpy().reshape(-1, 1)","059be90a":"# random seeds\nrnd_seed_cv = 1234\nrnd_seed_reg = 1234","98deea5c":"# cross validation\nn_cv = 7\nkf = KFold(n_splits=n_cv, random_state=rnd_seed_cv, shuffle=True)","db5fcef7":"# train\n\nCVs = []\npreds_train = []\npreds_test = []\nhists = []\n\nt1 = time.time()\nfor train_index, test_index in kf.split(X):\n    # get current train\/valid set according to CVs\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = y[train_index], y[test_index]\n    \n    # define regression model\n    regressor = TabNetRegressor(\n        n_d = 16, # default: 8\n        n_a = 16, # default: 8\n        n_steps = 4, # default: 3\n        n_independent = 2, # default: 2\n        n_shared = 2, # default: 2\n        lambda_sparse = 0, # default: 1e-3\n        optimizer_params = dict(lr = 1e-2, weight_decay=1e-5), # default: dict(lr=2e-2)\n        mask_type = 'entmax',\n        scheduler_params = dict(mode = 'min',\n                                patience = 5,\n                                min_lr = 1e-4,\n                                factor = 0.8),\n        scheduler_fn = ReduceLROnPlateau,\n        verbose = 1,\n        seed = rnd_seed_reg)\n    \n    # fit model\n    regressor.fit(X_train=X_train, y_train=y_train,\n              eval_set=[(X_valid, y_valid)],\n              max_epochs=100,\n              patience=15,\n              batch_size = 1024,\n              eval_metric=['rmse'])\n    \n    # update stats for cross validation performance, predictions and scoring history\n    CVs.append(regressor.best_cost)\n    preds_train.append(regressor.predict(X))\n    preds_test.append(regressor.predict(X_test))\n    hists.append(regressor.history)\nt2 = time.time()\n\nprint('\\nElapsed time [s]: ', np.round(t2-t1,3))","3b752763":"# plot scoring history\nfor i in range(n_cv):\n    plt.plot(hists[i]['loss'], label=i)\nplt.title('CV loss')\nplt.ylim(0.4,0.6)\nplt.grid()\nplt.legend(loc='lower left')\nplt.show()","50839b96":"# plot scoring history\nfor i in range(n_cv):\n    plt.plot(hists[i]['val_0_rmse'], label=i)\nplt.title('CV RMSE')    \nplt.grid()\nplt.legend(loc='lower left')\nplt.show()","e4b2a920":"# plot learning rates\nfor i in range(n_cv):\n    plt.plot(hists[i]['lr'], label=i)\nplt.title('Learning Rates')\nplt.grid()\nplt.legend(loc='lower left')\nplt.show()","e772b6a6":"# Cross Validation performance\nprint(CVs)\nprint()\nprint('Mean CV performance [RMSE]:  ', np.round(np.mean(CVs, axis=0),8))\nprint('Stdev CV performance [RMSE]: ', np.round(np.std(CVs, axis=0),8))","2bbe4c52":"# show volatility of predictions (on training data)\nn_show = 100 # select subset\nmy_alpha = 0.5\nplt.figure(figsize=(18,5))\nfor i in range(n_cv):\n    plt.scatter(range(0,n_show),preds_train[i][0:n_show], alpha=my_alpha)\nplt.grid()\nplt.show()","da9d45f2":"# show volatility of predictions (on test set)\nn_show = 100 # select subset\nmy_alpha = 0.5\nplt.figure(figsize=(18,5))\nfor i in range(n_cv):\n    plt.scatter(range(0,n_show),preds_test[i][0:n_show], alpha=my_alpha)\nplt.grid()\nplt.show()","e3b5b17b":"# calc predictions on train and test set by averaging\npred_train = np.mean(preds_train, axis=0)\npred_test = np.mean(preds_test, axis=0)","314e4c8e":"# plot distribution of predictions on training data \/ test set\nplt.figure(figsize=(10,4))\n\nplt.subplot(1, 2, 1)\nplt.hist(pred_train, bins=50)\nplt.title('Predictions on Training Data')\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.hist(pred_test, bins=50)\nplt.title('Predictions on Test Set')\nplt.grid()\n\nplt.show()","d59634ab":"# add predictions to training data\ndf_train['prediction'] = pred_train","1bf95c9f":"# plot predictions vs actual on training data\nsns.jointplot(data=df_train, x='target', y='prediction',\n             joint_kws={'alpha' : 0.1})\nplt.show()","9d1f2b24":"# prepare submission\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')\ndf_sub.target = pred_test\ndf_sub.head()","e23e6e4c":"# save to file for submission\ndf_sub.to_csv('submission.csv', index=False)","9c6ba716":"#### Details about model parameters etc. see [https:\/\/pypi.org\/project\/pytorch-tabnet\/](https:\/\/pypi.org\/project\/pytorch-tabnet\/).","2c290031":"<a id='2'><\/a>\n# Exploration of Features","2af9dfc5":"### Feature distributions","1d37f2e8":"#### Check for the zero value","69e77f0f":"<a id='4'><\/a>\n# TabNet model","e88f0812":"<a id='3'><\/a>\n# Target vs Features","78916173":"<a id='1'><\/a>\n# Exploration of Target","67eabb79":"# Table of Contents\n* [Exploration of Target](#1)\n* [Exploration of Features](#2)\n* [Target vs Features](#3)\n* [TabNet Model](#4)","d3d7e423":"### Visualization based on binned features","9d2b2f92":"### Scatter Plot","1f8cd66b":"Thanks to the following notebook for a quick introduction: [https:\/\/www.kaggle.com\/elvinagammed\/tabnet-regression-baseline](https:\/\/www.kaggle.com\/elvinagammed\/tabnet-regression-baseline).","62ebf1de":"#### This is just one of 30'000 rows, let's remove this row...","1e1c0a40":"### Correlations"}}