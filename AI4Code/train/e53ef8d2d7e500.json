{"cell_type":{"54a15809":"code","bde108f4":"code","161190cc":"code","9ffc792e":"code","1af846d0":"code","72285f7e":"code","7e882484":"code","4efd67c7":"code","5f0a2ff4":"code","5a940e6c":"code","c30f6391":"code","f8494098":"code","7020fb21":"code","7d63abb0":"code","83dd3a00":"code","8484525e":"code","3cfedf00":"code","de732962":"code","38fb9109":"code","45e7435b":"code","7c863ef5":"code","c83e95a5":"code","d048dca7":"code","f75d8caf":"code","8f9281e2":"markdown","2c8b64b6":"markdown","55158950":"markdown","2be645fc":"markdown","ad5e2cae":"markdown","e4e98e58":"markdown","b69884be":"markdown","c13e3b4b":"markdown","58753ae4":"markdown","f08bd6b9":"markdown","5b489774":"markdown","052d54bd":"markdown"},"source":{"54a15809":"class CFG:\n    debug=False\n    height=256\n    width=256\n    lr=1e-4\n    batch_size=16\n    epochs=8\n    seed=42\n    target_size=6 #1\n    target_col='isup_grade'\n    n_fold=4","bde108f4":"import os\nimport numpy as np \nimport pandas as pd ","161190cc":"os.listdir('..\/input\/prostate-cancer-grade-assessment')","9ffc792e":"train = pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/train.csv')\ntest = pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/test.csv')\nsample = pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/sample_submission.csv')","1af846d0":"train.head()","72285f7e":"test.head()","7e882484":"sample.head()","4efd67c7":"train['isup_grade'].hist()","5f0a2ff4":"# ====================================================\n# Library\n# ====================================================\n\nimport sys\n\nimport gc\nimport os\nimport random\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\n\nimport skimage.io\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\nimport sklearn.metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom functools import partial\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","5a940e6c":"# ====================================================\n# Utils\n# ====================================================\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n    \ndef init_logger(log_file='train.log'):\n    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n    \n    log_format = '%(asctime)s %(levelname)s %(message)s'\n    \n    stream_handler = StreamHandler()\n    stream_handler.setLevel(DEBUG)\n    stream_handler.setFormatter(Formatter(log_format))\n    \n    file_handler = FileHandler(log_file)\n    file_handler.setFormatter(Formatter(log_format))\n    \n    logger = getLogger('PANDA')\n    logger.setLevel(DEBUG)\n    logger.addHandler(stream_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n\nLOG_FILE = 'train.log'\nLOGGER = init_logger(LOG_FILE)\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=42)","c30f6391":"class TrainDataset(Dataset):\n    def __init__(self, df, labels, transform=None):\n        self.df = df\n        self.labels = labels\n        self.transform = transform\n        self.to_tensor = Compose([ToTensorV2()])\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.df['image_id'].values[idx]\n        file_path = f'..\/input\/prostate-cancer-grade-assessment\/train_images\/{file_name}.tiff'\n        image = skimage.io.MultiImage(file_path)\n        image = cv2.resize(image[-1], (CFG.height, CFG.width))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        original_image = self.to_tensor(image=image)['image']\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            \n        label = self.labels[idx]\n        \n        return image, label, original_image","f8494098":"def get_transforms(*, data):\n    \n    assert data in ('train', 'valid')\n    \n    if data == 'train':\n        return Compose([\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    \n    elif data == 'valid':\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","7020fb21":"# https:\/\/github.com\/Cadene\/pretrained-models.pytorch\/blob\/master\/pretrainedmodels\/models\/senet.py\n\nfrom collections import OrderedDict\nimport math\n\n\nclass SEModule(nn.Module):\n\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, channels \/\/ reduction, kernel_size=1,\n                             padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels \/\/ reduction, channels, kernel_size=1,\n                             padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = self.avg_pool(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n\n\nclass Bottleneck(nn.Module):\n    \"\"\"\n    Base class for bottlenecks that implements `forward()` method.\n    \"\"\"\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SEBottleneck(Bottleneck):\n    \"\"\"\n    Bottleneck for SENet154.\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)\n        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n                               stride=stride, padding=1, groups=groups,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(planes * 4)\n        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNetBottleneck(Bottleneck):\n    \"\"\"\n    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n    (the latter is used in the torchvision implementation of ResNet).\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEResNetBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n                               stride=stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n                               groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNeXtBottleneck(Bottleneck):\n    \"\"\"\n    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None, base_width=4):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width \/ 64)) * groups\n        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n                               stride=1)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n                               padding=1, groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SENet(nn.Module):\n\n    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n                 downsample_padding=1, num_classes=1000):\n        super(SENet, self).__init__()\n        self.inplanes = inplanes\n        if input_3x3:\n            layer0_modules = [\n                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n                                    bias=False)),\n                ('bn1', nn.BatchNorm2d(64)),\n                ('relu1', nn.ReLU(inplace=True)),\n                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n                                    bias=False)),\n                ('bn2', nn.BatchNorm2d(64)),\n                ('relu2', nn.ReLU(inplace=True)),\n                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n                                    bias=False)),\n                ('bn3', nn.BatchNorm2d(inplanes)),\n                ('relu3', nn.ReLU(inplace=True)),\n            ]\n        else:\n            layer0_modules = [\n                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n                                    padding=3, bias=False)),\n                ('bn1', nn.BatchNorm2d(inplanes)),\n                ('relu1', nn.ReLU(inplace=True)),\n            ]\n        # To preserve compatibility with Caffe weights `ceil_mode=True`\n        # is used instead of `padding=1`.\n        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n                                                    ceil_mode=True)))\n        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n        self.layer1 = self._make_layer(\n            block,\n            planes=64,\n            blocks=layers[0],\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=1,\n            downsample_padding=0\n        )\n        self.layer2 = self._make_layer(\n            block,\n            planes=128,\n            blocks=layers[1],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer3 = self._make_layer(\n            block,\n            planes=256,\n            blocks=layers[2],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer4 = self._make_layer(\n            block,\n            planes=512,\n            blocks=layers[3],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.avg_pool = nn.AvgPool2d(7, stride=1)\n        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n                    downsample_kernel_size=1, downsample_padding=0):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=downsample_kernel_size, stride=stride,\n                          padding=downsample_padding, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n                            downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups, reduction))\n\n        return nn.Sequential(*layers)\n\n    def features(self, x):\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def logits(self, x):\n        x = self.avg_pool(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x)\n        return x\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.logits(x)\n        return x\n\n\ndef initialize_pretrained_model(model, num_classes, settings):\n    assert num_classes == settings['num_classes'], \\\n        'num_classes should be {}, but is {}'.format(\n            settings['num_classes'], num_classes)\n    model.load_state_dict(model_zoo.load_url(settings['url']))\n    model.input_space = settings['input_space']\n    model.input_size = settings['input_size']\n    model.input_range = settings['input_range']\n    model.mean = settings['mean']\n    model.std = settings['std']\n\n\ndef se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n\ndef se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model","7d63abb0":"pretrained_path = {'se_resnext50_32x4d': '..\/input\/pytorch-se-resnext\/se_resnext50_32x4d-a260b3a4.pth'}\n\nclass CustomSEResNeXt(nn.Module):\n\n    def __init__(self, model_name='se_resnext50_32x4d'):\n        assert model_name in ('se_resnext50_32x4d')\n        super().__init__()\n        \n        self.model = se_resnext50_32x4d(pretrained=None)\n        weights_path = pretrained_path[model_name]\n        self.model.load_state_dict(torch.load(weights_path))\n        self.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.model.last_linear = nn.Linear(self.model.last_linear.in_features, CFG.target_size)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","83dd3a00":"os.listdir('..\/input\/panda-se-resnext50-classification-baseline')","8484525e":"folds = pd.read_csv('..\/input\/panda-se-resnext50-classification-baseline\/folds.csv')\n\nclass_loaders = []\n\n# we use fold=0 model for Grad-CAM\nfor fold in [0]:\n    \n    # idx\n    val_idx = folds[folds['fold'] == fold].index # check by val data\n    #val_idx = folds[folds['fold'] != fold].index # check by train data\n    \n    # prepare each label loader\n    for i in range(CFG.target_size):\n        valid_dataset = TrainDataset(folds.loc[val_idx][folds[CFG.target_col]==i].reset_index(drop=True), \n                                     folds.loc[val_idx][folds[CFG.target_col]==i].reset_index(drop=True)[CFG.target_col], \n                                     transform=get_transforms(data='valid'))\n        valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n        class_loaders.append(valid_loader)\n        \n    # model\n    model = CustomSEResNeXt(model_name='se_resnext50_32x4d')\n    weights_path = f'..\/input\/panda-se-resnext50-classification-baseline\/fold{fold}_se_resnext50.pth'\n    state = torch.load(weights_path, map_location=device)\n    model.load_state_dict(state)","3cfedf00":"final_conv = model.model.layer4[2]._modules.get('conv3')\nprint(final_conv)\nfc_params = list(model.model._modules.get('last_linear').parameters())","de732962":"import matplotlib.pyplot as plt\nimport torch.nn.functional as F\n\n\nclass SaveFeatures():\n    \"\"\" Extract pretrained activations\"\"\"\n    features = None\n    def __init__(self, m):\n        self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output):\n        self.features = ((output.cpu()).data).numpy()\n    def remove(self):\n        self.hook.remove()\n\n\ndef getCAM(feature_conv, weight_fc, class_idx):\n    _, nc, h, w = feature_conv.shape\n    cam = weight_fc[class_idx].dot(feature_conv[0,:, :, ].reshape((nc, h*w)))\n    cam = cam.reshape(h, w)\n    cam = cam - np.min(cam)\n    cam_img = cam \/ np.max(cam)\n    return cam_img\n\n\ndef plotGradCAM(model, final_conv, fc_params, train_loader, \n                row=1, col=8, img_size=256, device='cpu', original=False):\n    for param in model.parameters():\n        param.requires_grad = False\n    model.to(device)\n    model.eval()\n    # save activated_features from conv\n    activated_features = SaveFeatures(final_conv)\n    # save weight from fc\n    weight = np.squeeze(fc_params[0].cpu().data.numpy())\n    # original images\n    if original:\n        fig = plt.figure(figsize=(20, 15))\n        for i, (img, target, org_img) in enumerate(train_loader):\n            output = model(img.to(device))\n            pred_idx = output.to('cpu').numpy().argmax(1)\n            cur_images = org_img.numpy().transpose((0, 2, 3, 1))\n            ax = fig.add_subplot(row, col, i+1, xticks=[], yticks=[])\n            plt.imshow(cv2.cvtColor(cur_images[0], cv2.COLOR_BGR2RGB))\n            ax.set_title('Label:%d, Predict:%d' % (target, pred_idx), fontsize=14)\n            if i == row*col-1:\n                break\n        plt.show()\n    # heatmap images\n    fig = plt.figure(figsize=(20, 15))\n    for i, (img, target, _) in enumerate(train_loader):\n        output = model(img.to(device))\n        pred_idx = output.to('cpu').numpy().argmax(1)\n        cur_images = img.cpu().numpy().transpose((0, 2, 3, 1))\n        heatmap = getCAM(activated_features.features, weight, pred_idx)\n        ax = fig.add_subplot(row, col, i+1, xticks=[], yticks=[])\n        plt.imshow(cv2.cvtColor(cur_images[0], cv2.COLOR_BGR2RGB))\n        plt.imshow(cv2.resize(heatmap, (img_size, img_size), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n        ax.set_title('Label:%d, Predict:%d' % (target, pred_idx), fontsize=14)\n        if i == row*col-1:\n            break\n    plt.show()","38fb9109":"# plot GradCAM for label=0\nlabel = 0\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=256, device=device, original=True)","45e7435b":"# plot GradCAM for label=1\nlabel = 1\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=256, device=device, original=True)","7c863ef5":"# plot GradCAM for label=2\nlabel = 2\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=256, device=device, original=True)","c83e95a5":"# plot GradCAM for label=3\nlabel = 3\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=256, device=device, original=True)","d048dca7":"# plot GradCAM for label=4\nlabel = 4\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=256, device=device, original=True)","f75d8caf":"# plot GradCAM for label=5\nlabel = 5\nplotGradCAM(model, final_conv, fc_params, class_loaders[label], img_size=256, device=device, original=True)","8f9281e2":"# Transforms","2c8b64b6":"# Dataset","55158950":"# Library","2be645fc":"# Grad-CAM","ad5e2cae":"- PyTorch Grad-CAM\n- Model is taken from [my starter kernel](https:\/\/www.kaggle.com\/yasufuminakama\/panda-se-resnext50-classification-baseline) \n\nIf this notebook is helpful, feel free to upvote :)  ","e4e98e58":"- ref: https:\/\/www.kaggle.com\/bonhart\/inceptionv3-tta-grad-cam-pytorch","b69884be":"# Data Loading","c13e3b4b":"# Library","58753ae4":"# About this notebook","f08bd6b9":"# Model","5b489774":"# Config","052d54bd":"# Utils"}}