{"cell_type":{"653173a9":"code","0400d57d":"code","13bd4240":"code","a8c5fe15":"code","ede7597b":"code","8ef2dbfd":"code","9122aeae":"code","5caea23c":"code","4a4a24b4":"code","33f5ea82":"code","84811899":"markdown"},"source":{"653173a9":"!pip install -q -U albumentations","0400d57d":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom tensorflow.keras.layers import Input,Reshape, Lambda, Conv2D, DepthwiseConv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D,Dropout, Concatenate, Conv2DTranspose, dot, add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras import backend as K\nfrom keras.regularizers import l2\nfrom albumentations import (\n    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n    Rotate,GridDistortion,ElasticTransform\n)","13bd4240":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(9, 9))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image, cmap = 'bone')\n    plt.show()","a8c5fe15":"transforms = Compose([\n        ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        GridDistortion(p=0.5),\n#         OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n#         VerticalFlip(p=0.5),\n        \n])\n","ede7597b":"def load_data(x_path, y_path):\n    images = os.listdir(x_path)\n    masks = os.listdir(y_path)\n    \n    train_x = [os.path.join(x_path, image) for image in images]\n#     train_y = [os.path.join(y_path, mask) for mask in masks]\n    \n    train_y = list(map(lambda x : x.replace('.jpg', '.tiff'), train_x))\n    train_y = list(map(lambda x : x.replace('train_images\/train_images', 'train_masks\/train_masks'), train_y))\n    \n    \n    train_x, valid_x = train_test_split(train_x, test_size=0.15, random_state=42)\n    train_y, valid_y = train_test_split(train_y, test_size=0.15, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y)\n\n\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n    x = x \/ 255.0\n    x = x.astype(np.float32)\n    return x\n\n\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = x.astype(np.int32)\n    return x\n\n\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n    dataset = dataset.shuffle(buffer_size= 5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n    return dataset\n\n\ndef preprocess(x,y):\n    \n    def aug_fn(image, mask):\n        img_data = {\"image\":image}\n        mask_data = {\"mask\":mask}\n        img_data = transforms(**image)\n        mask_data = transforms(**mask)\n        aug_img = img_data[\"image\"]\n        aug_mask = mask_data[\"mask\"]\n        return aug_img, aug_mask\n    \n    def f(x,y):\n        x = x.decode()\n        y = y.decode()\n        \n        image = read_image(x)\n        mask = read_mask(y)\n        augmented = transforms(image=image,mask=mask)\n        aug_img=augmented['image']\n        aug_mask = augmented['mask']\n        \n        return aug_img, aug_mask\n    \n    image, mask = tf.numpy_function(f, [x,y], [tf.float32, tf.int32])\n#     image, mask = tf.numpy_function(aug_fn,[image, mask],[tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 3, dtype = tf.int32)\n    image.set_shape([256,256,3])\n    mask.set_shape([256,256,3])\n    \n    return image, mask","8ef2dbfd":"def res_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\", activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    res = x\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = add([res, x])\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\ndef double_conv_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\", activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n#     x = add([inputs_curr, x])\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\n\n# def conv_block(inputs_prev,inputs_curr, filters, pool=True):\n#     x = Conv2D(filters, 3, padding=\"same\", activation='relu')(inputs_prev)\n#     x = BatchNormalization()(x)\n# #     x = Activation(\"relu\")(x)\n    \n#     x = add([inputs_curr, x])\n# #     x = Conv2D(filters, 3, padding=\"same\")(x)\n# #     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n\n#     if pool == True:\n#         p = MaxPool2D((2, 2))(x)\n#         return x, p\n#     else:\n#         return x\n    \ndef single_conv_block(inputs, filters):\n    x = Conv2D(filters, 3, padding=\"same\", activation='relu')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n    \ndef fsm(inputs):\n    channel_num = inputs.shape[-1]\n\n    res = inputs\n\n    inputs = single_conv_block(inputs, filters=int(channel_num \/\/ 2))\n\n    # x = non_local_block(x, compression=2, mode='dot')\n\n    ip = inputs\n    ip_shape = K.int_shape(ip)\n    batchsize, dim1, dim2, channels = ip_shape\n    intermediate_dim = channels \/\/ 2\n    rank = 4\n    if intermediate_dim < 1:\n        intermediate_dim = 1\n\n    # theta path\n    theta = Conv2D(intermediate_dim, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal',\n                   kernel_regularizer=l2(1e-5))(ip)\n    theta = Reshape((-1, intermediate_dim))(theta)\n\n    # phi path\n    phi = Conv2D(intermediate_dim, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal',\n                   kernel_regularizer=l2(1e-5))(ip)\n    phi = Reshape((-1, intermediate_dim))(phi)\n\n    # dot\n    f = dot([theta, phi], axes=2)\n    size = K.int_shape(f)\n    # scale the values to make it size invariant\n    f = Lambda(lambda z: (1. \/ float(size[-1])) * z)(f)\n\n    # g path\n    g = Conv2D(intermediate_dim, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal',\n                   kernel_regularizer=l2(1e-5))(ip)\n    g = Reshape((-1, intermediate_dim))(g)\n\n    # compute output path\n    y = dot([f, g], axes=[2, 1])\n    y = Reshape((dim1, dim2, intermediate_dim))(y)\n    y = Conv2D(channels, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal',\n               kernel_regularizer=l2(1e-5))(y)\n    y = add([ip, y])\n\n    x = y\n    x = single_conv_block(x, filters=int(channel_num))\n    print(x)\n\n    x = add([x, res])\n    return x\n\ndef build_unet(shape, num_classes):\n    inputs = Input(shape)\n\n    \"\"\" Encoder \"\"\"\n    x1, p1 = res_block(inputs, 16, pool=True)\n    x2, p2 = res_block(p1, 32, pool=True)\n    x3, p3 = res_block(p2, 64, pool=True)\n    #drop3 = Dropout(0.1)(x3)\n    x4, p4 = res_block(p3, 128, pool=True)\n    #drop4 = Dropout(0.1)(x4)\n    x5, p5 = res_block(p4, 256, pool=True) \n    \n    \"\"\" Bridge \"\"\"\n    fsm_out = fsm(p5)\n#     b1 = conv_block(p4, 256, pool=False)\n#     b2 = conv_block(b1, 256, pool=False)\n\n    \"\"\" Decoder \"\"\"\n    #u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n    u0 = Conv2DTranspose(256, (3,3), strides = (2,2), padding=\"same\")(fsm_out)\n    c0 = Concatenate()([u0, x5])\n    x6 = double_conv_block(c0, 256, pool=False)\n\n    u1 = Conv2DTranspose(128, (3,3), strides = (2,2), padding=\"same\")(x6)\n    c1 = Concatenate()([u1, x4])\n    x7 = double_conv_block(c1, 128, pool=False)\n\n#     u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n    u2 = Conv2DTranspose(64, (3,3), strides = (2,2), padding=\"same\")(x7)\n    c2 = Concatenate()([u2, x3])\n    x8 = double_conv_block(c2, 64, pool=False)\n\n#     u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n    u3 = Conv2DTranspose(32, (3,3), strides = (2,2), padding=\"same\")(x8)\n    c3 = Concatenate()([u3, x2])\n    x9 = double_conv_block(c3, 32, pool=False)\n\n#     u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n    u4 = Conv2DTranspose(16, (3,3), strides = (2,2), padding=\"same\")(x9)\n    c4 = Concatenate()([u4, x1])\n    x10 = double_conv_block(c4, 16, pool=False)\n\n    #b2, x5, x6, x7, x8\n                                                     #input size\n    fsm_out_new = double_conv_block(fsm_out, 16, pool=False) #8,8,256 \n    x6_new = double_conv_block(x6, 16, pool=False)           #16,16,256 \n    x7_new = double_conv_block(x7, 16, pool=False)           #32,32,128   \n    x8_new = double_conv_block(x8, 16, pool=False)           #64,64,64 \n    x9_new = double_conv_block(x9, 16, pool=False)           #128,128,32 \n    x10_new = double_conv_block(x10, 16, pool=False)         #256,256,16\n    #all layers except x8_new need to transposed to dimension 256,256,16\n    \n    fsm_out_new_transposed = Conv2DTranspose(16, (3,3), strides = (32,32))(fsm_out_new)\n    x6_transposed = Conv2DTranspose(16, (3,3), strides = (16,16))(x6_new)  \n    x7_transposed = Conv2DTranspose(16, (3,3), strides = (8,8))(x7_new)     \n    x8_transposed = Conv2DTranspose(16, (3,3), strides = (4,4))(x8_new)  \n    x9_transposed = Conv2DTranspose(16, (3,3), strides = (2,2), padding='same')(x9_new)\n    x10_transposed = x10_new\n    \n    concat_output = Concatenate()([fsm_out_new_transposed, x6_transposed, x7_transposed, x8_transposed, x9_transposed, x10_transposed])\n                    #o\/p shape = 256,256,96\n    \n    \n    \"\"\" Output layer \"\"\"\n    #x9 = Conv2D(16, (3,3), padding = \"same\", activation = \"relu\")(x8)  #end result not good enough\n    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(concat_output)\n\n    return Model(inputs, output)\n","9122aeae":"def dice_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    Dice = (2*|X & Y|)\/ (|X|+ |Y|)\n         =  2*sum(|A*B|)\/(sum(A^2)+sum(B^2))\n    ref: https:\/\/arxiv.org\/pdf\/1606.04797v1.pdf\n    \"\"\"\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","5caea23c":"if __name__ == \"__main__\":\n    \n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    i = random.randint(0,49000)\n    \n    \"\"\" Dataset \"\"\"\n    train_frame_path = '..\/input\/lits-256x256\/train_images\/train_images'\n    train_mask_path = '..\/input\/lits-256x256\/train_masks\/train_masks'\n    \n    (train_x, train_y), (valid_x, valid_y) = load_data(train_frame_path, train_mask_path)\n    \n    visualize(image = read_image(train_x[i]), mask = read_mask(train_y[i]))\n    \n    \n    #hyperparameters\n    shape = (256,256,3)\n    classes = 3\n    lr = 1e-4\n    batch_size = 32\n    epochs = 14\n    \n    \"\"\" Model \"\"\"\n    model = build_unet(shape, classes)\n    model.compile(loss=dice_coef_loss , optimizer=tf.keras.optimizers.Adam(lr), metrics = [dice_coef] )\n    model.summary()\n    \n    train_dataset = tf_dataset(train_x, train_y, batch = batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch = batch_size)\n    \n    train_steps = len(train_x)\/\/batch_size\n    valid_steps = len(valid_x)\/\/batch_size\n        \n    callbacks = [\n        ModelCheckpoint(\"best_model.h5\", verbose=1, save_best_model=True),\n        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-6),\n        EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1,min_delta=0.001)\n    ]\n    \n    history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n        callbacks=callbacks,\n        verbose = 1\n    )\n    \n    model.save('.\/final_model.h5')","4a4a24b4":"train_steps","33f5ea82":"import gc\ngc.collect()","84811899":"Multiple Feature Pyramind Network Unet -- MFP unet\n\nhttps:\/\/arxiv.org\/ftp\/arxiv\/papers\/1906\/1906.10486.pdf\n\nImplementation of "}}