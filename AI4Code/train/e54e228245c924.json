{"cell_type":{"efb7f362":"code","db00d113":"code","fb90d1c9":"code","3f0ef193":"code","3ff594fe":"code","b7eddbf5":"code","5d9af2f5":"code","e97b0444":"code","40c1c2a4":"code","99ab9e87":"code","a832ac4a":"code","b236c280":"code","81309f3d":"code","e33eb79b":"code","6734fba6":"code","6bf3f5c0":"markdown","c91cd9c0":"markdown","c7eed5ce":"markdown","07b8155e":"markdown"},"source":{"efb7f362":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport torch\nfrom torchvision import models\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch.nn.functional as F\n\nfrom PIL import Image, ImageDraw\nimport matplotlib.pyplot as plt\n\nimport os\nimport json\nimport re\nimport random\nfrom math import sqrt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","db00d113":"with open('..\/input\/annotations\/Annotation\/n02113799-standard_poodle\/n02113799_489') as f:\n    reader = f.read()","fb90d1c9":"img = Image.open('..\/input\/images\/Images\/n02113799-standard_poodle\/n02113799_489.jpg')\n\nxmin = int(re.findall('(?<=<xmin>)[0-9]+?(?=<\/xmin>)', reader)[0])\nxmax = int(re.findall('(?<=<xmax>)[0-9]+?(?=<\/xmax>)', reader)[0])\nymin = int(re.findall('(?<=<ymin>)[0-9]+?(?=<\/ymin>)', reader)[0])\nymax = int(re.findall('(?<=<ymax>)[0-9]+?(?=<\/ymax>)', reader)[0])\n\norigin_img = img.copy()\ndraw = ImageDraw.Draw(origin_img)\ndraw.rectangle(xy=[(xmin,ymin), (xmax,ymax)])\norigin_img","3f0ef193":"all_img_folder = os.listdir('..\/input\/images\/Images')\n# all_annotation_folder = os.listdir('..\/input\/annotations\/Annotation')\n\nall_img_name = []\nfor img_folder in all_img_folder:\n    img_folder_path = '..\/input\/images\/Images\/' + img_folder\n    all_img_name += list(map(lambda x: img_folder + '\/'+ x, os.listdir(img_folder_path)))\n\n# all_annotation_name = []\n# for annotation_folder in all_annotation_folder:\n#     annotation_folder_path = '..\/input\/annotations\/Annotation\/' + annotation_folder\n#     all_annotation_name += list(map(lambda x: annotation_folder + '\/'+ x, os.listdir(annotation_folder_path)))\n\nlen(all_img_name), all_img_name[0]","3ff594fe":"class MyDateset(Dataset):\n    def __init__(self, file_folder, is_test=False, transform=None):\n        self.img_folder_path = '..\/input\/images\/Images\/'\n        self.annotation_folder_path = '..\/input\/annotations\/Annotation\/'\n        self.file_folder = file_folder\n        self.transform = transform\n        self.is_test = is_test\n        \n    def __getitem__(self, idx):\n        file = self.file_folder[idx]\n        img_path = self.img_folder_path + file\n        img = Image.open(img_path).convert('RGB')\n        \n        if not self.is_test:\n            annotation_path = self.annotation_folder_path + file.split('.')[0]\n            with open(annotation_path) as f:\n                annotation = f.read()\n\n            xy = self.get_xy(annotation)\n            box = torch.FloatTensor(list(xy))\n\n            new_box = self.box_resize(box, img)\n            if self.transform is not None:\n                img = self.transform(img)\n\n            return img, new_box\n        else:\n            if self.transform is not None:\n                img = self.transform(img)\n            return img\n    \n    def __len__(self):\n        return len(self.file_folder)\n        \n    def get_xy(self, annotation):\n        xmin = int(re.findall('(?<=<xmin>)[0-9]+?(?=<\/xmin>)', annotation)[0])\n        xmax = int(re.findall('(?<=<xmax>)[0-9]+?(?=<\/xmax>)', annotation)[0])\n        ymin = int(re.findall('(?<=<ymin>)[0-9]+?(?=<\/ymin>)', annotation)[0])\n        ymax = int(re.findall('(?<=<ymax>)[0-9]+?(?=<\/ymax>)', annotation)[0])\n        \n        return xmin, ymin, xmax, ymax\n    \n    def show_box(self):\n        file = random.choice(self.file_folder)\n        annotation_path = self.annotation_folder_path + file.split('.')[0]\n        \n        img_box = Image.open(self.img_folder_path + file)\n        with open(annotation_path) as f:\n            annotation = f.read()\n            \n        draw = ImageDraw.Draw(img_box)\n        xy = self.get_xy(annotation)\n        print('bbox:', xy)\n        draw.rectangle(xy=[xy[:2], xy[2:]])\n        \n        return img_box\n        \n    def box_resize(self, box, img, dims=(332, 332)):\n        old_dims = torch.FloatTensor([img.width, img.height, img.width, img.height]).unsqueeze(0)\n        new_box = box \/ old_dims\n        new_dims = torch.FloatTensor([dims[1], dims[0], dims[1], dims[0]]).unsqueeze(0)\n        new_box = new_box * new_dims\n        \n        return new_box","b7eddbf5":"tsfm = transforms.Compose([\n    transforms.Resize([332, 332]),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\ntest_tsfm = transforms.Compose([\n    transforms.Resize([332, 332]),\n    transforms.ToTensor(),\n#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])","5d9af2f5":"class Mymodel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.body = nn.Sequential(*list(models.resnet50(pretrained=True).children())[:-2])\n        self.head = nn.Sequential(\n            nn.BatchNorm1d(2048*2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            nn.Dropout(0.25),\n            nn.Linear(in_features=2048*2, out_features=1024, bias=True),\n            nn.ReLU(),\n            nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features=1024, out_features=4, bias=True),\n        )\n        \n    def forward(self, x):\n        x = self.body(x)\n        x1 = nn.AdaptiveAvgPool2d(1)(x)\n        x2 = nn.AdaptiveMaxPool2d(1)(x)\n        x = torch.cat([x1,x2], 1)\n        x = x.view(x.size(0), -1)\n        x = self.head(x)\n        \n        return x","e97b0444":"def loss_fn(preds, targs, class_idxs):\n    return nn.L1Loss()(preds, targs.squeeze())\n\ndef IoU(preds, targs):\n    return intersection(preds, targs.squeeze()) \/ union(preds, targs.squeeze())\n\ndef intersection(preds, targs):\n    # preds and targs are of shape (bs, 4), pascal_voc format\n    if len(targs.shape) == 1:\n        targs = targs.reshape(1, 4)\n#     print(preds.shape, targs.shape)\n    max_xy = torch.min(preds[:, 2:], targs[:, 2:])\n    min_xy = torch.max(preds[:, :2], targs[:, :2])\n    inter = torch.clamp((max_xy - min_xy), min=0)\n    return inter[:, 0] * inter[:, 1]\n\ndef area(boxes):\n    return ((boxes[:, 2]-boxes[:, 0]) * (boxes[:, 3]-boxes[:, 1]))\n\ndef union(preds, targs):\n    if len(targs.shape) == 1:\n        targs = targs.reshape(1, 4)\n    return area(preds) + area(targs) - intersection(preds, targs)","40c1c2a4":"EPOCH = 10\nBS = 64\nLR = 1e-1","99ab9e87":"train_ds = MyDateset(all_img_name[:int(len(all_img_name)*0.8)], transform=tsfm)\ntrain_dl = DataLoader(train_ds, batch_size=BS, shuffle=True)\n\nvalid_ds = MyDateset(all_img_name[int(len(all_img_name)*0.8):int(len(all_img_name)*0.9)], transform=tsfm)\nvalid_dl = DataLoader(valid_ds, batch_size=1)\n\ntest_ds = MyDateset(all_img_name[int(len(all_img_name)*0.9):], is_test=True, transform=test_tsfm)\ntest_dl = DataLoader(test_ds, batch_size=1)","a832ac4a":"train_ds.show_box()","b236c280":"model = Mymodel()\nmodel.cuda();\n\nfor layer in model.body.parameters():\n    layer.requires_grad = False\n    \noptm = torch.optim.Adam(model.head.parameters(), lr=LR)","81309f3d":"from tqdm import tqdm\nmodel.train()\nfor epoch in range(1, EPOCH+1):\n    if epoch == 3:\n        optm = torch.optim.Adam(model.head.parameters(), lr=LR\/2)\n    elif  epoch == 5:\n        optm = torch.optim.Adam(model.head.parameters(), lr=LR\/4)\n    elif epoch == 7:\n        optm = torch.optim.Adam(model.head.parameters(), lr=LR\/8)\n    elif epoch == 9:\n        optm = torch.optim.Adam(model.head.parameters(), lr=LR\/10)\n        \n    train_loss = []\n    train_IoU = []\n    for step, data in enumerate(train_dl):\n        imgs, boxes = data\n        imgs = imgs.cuda()\n        boxes = boxes.cuda()\n        \n        pred = model(imgs)\n        loss = nn.L1Loss()(pred, boxes.squeeze())\n        train_loss.append(loss.item())\n        IOU = IoU(pred, boxes)\n        train_IoU.append(IOU)\n            \n        optm.zero_grad()\n        loss.backward()\n        optm.step()\n        if step % 10 == 0:\n            print('step: ', step, '\/', len(train_dl), '\\tloss:', loss.item(), '\\tIoU:', float(IOU.mean()))\n        \n    model.eval()\n    valid_loss = []\n    valid_IoU = []\n    for step, data in enumerate(tqdm(valid_dl)):\n        imgs, boxes = data\n        imgs = imgs.cuda()\n        boxes = boxes.cuda()\n        \n        pred = model(imgs)\n        loss = nn.L1Loss()(pred, boxes.squeeze())\n        valid_loss.append(loss.item())\n        IOU = IoU(pred, boxes)\n        valid_IoU.append(IOU.item())\n    print('epoch:', epoch, '\/', EPOCH, '\\ttrain_loss:', np.mean(train_loss), '\\tvalid_loss:', np.mean(valid_loss), '\\tIoU:', np.mean(valid_IoU))","e33eb79b":"model.eval()\n\ndraw_img = []\nfor step, img in enumerate(tqdm(test_dl)):\n    img = img.cuda()\n    pred = model(img)\n    \n    origin_img = transforms.ToPILImage()(img.cpu().squeeze())\n    draw = ImageDraw.Draw(origin_img)\n    xmin, ymin, xmax, ymax = tuple(pred.squeeze().tolist())\n    draw.rectangle(xy=[(int(xmin),int(ymin)), (int(xmax),int(ymax))])\n    draw_img.append(origin_img)","6734fba6":"draw_img[14]","6bf3f5c0":"# Train","c91cd9c0":"# show img","c7eed5ce":"# Dataset","07b8155e":"# Model"}}