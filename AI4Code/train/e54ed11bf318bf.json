{"cell_type":{"90075730":"code","96876bb7":"code","923141b4":"code","c6073511":"code","427c7a21":"code","89217251":"code","bf79253c":"code","d53a3f08":"code","85a4d4a3":"code","4e0775b6":"code","3432f6d4":"code","38ffa077":"code","7684d160":"code","eb7e6de1":"code","a5a546b6":"code","15de4d47":"code","61231792":"code","fdab9b67":"code","63c68f5c":"code","b4a7f068":"code","5ca6d58d":"code","23b2b40f":"code","dc3571b1":"code","dd24b6f1":"code","3f84e8d5":"code","56bdc088":"code","3a8be175":"code","e3f14098":"code","958363be":"code","b91d8ea0":"code","a5ee70aa":"code","8da13b84":"code","1df0fd66":"code","d00715a1":"code","9156059c":"code","36a3ad3b":"code","5190fc57":"code","1867b23b":"code","5246a762":"code","0d0eea98":"code","696c0536":"code","173e1d3c":"markdown","229ec5eb":"markdown","92e59c3f":"markdown","36477d92":"markdown","a387cd04":"markdown","7fff3fe5":"markdown","6267a0f6":"markdown","11012dbd":"markdown","58b973c9":"markdown","a6b5ccc2":"markdown","93ad8141":"markdown","0cd689c0":"markdown","f1098b6e":"markdown","2c8e231d":"markdown","a187ff56":"markdown","4578e757":"markdown","4a1e7bef":"markdown","1e7dbdac":"markdown","411c5b32":"markdown","41db233c":"markdown","7b1f22e7":"markdown","1b7e98fc":"markdown","6597a340":"markdown","853a4f73":"markdown"},"source":{"90075730":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error as MAERROR\nfrom sklearn.preprocessing import OneHotEncoder","96876bb7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","923141b4":"hp = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nhppred = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c6073511":"# Have a glimpse of the data\nhp.head()","427c7a21":"hp.head()","89217251":"# what is the shape\nprint(hp.shape)\nprint(hppred.shape)\n# there are 1460 rows and 81 columns in training data\n# (1459,80) in testing data. So one column is missing in test data.","bf79253c":"hp.isna().head() # isnull() also works","d53a3f08":"hp.isnull().sum().sum()","85a4d4a3":"hp.isnull().sum()","4e0775b6":"colnasum_tr = hp.isnull().sum().sort_values(ascending=False) \ncolnasum_pr = hppred.isnull().sum().sort_values(ascending=False) \nprint(colnasum_tr)\nprint(colnasum_pr)\n# We get a Series with index as column names and values are number of NANs or missing values","3432f6d4":"# We can plot the above Series.Pandas has elementary ploting \nhp.isnull().sum().plot() # \n","38ffa077":"# we can plot just a few values of the Series\nhp.isnull().sum().iloc[0:20].plot()","7684d160":"hppred.isnull().sum().plot()","eb7e6de1":"colna = colnasum_tr[colnasum_tr >0]\nprint(colna)\ncolna.shape\n# so there are 19 columns having NANs","a5a546b6":"hp_dna = hp.dropna(axis=1)\nhppred_dna = hppred.dropna(axis=1)\n\nhp_dna","15de4d47":"# check no missing values\nhp_dna.isnull().sum().sum()\n# No NANs or missing values","61231792":"# first list the columns\ncols = hp_dna.columns\n# find out columns with 'Sales' in their names\ncolsale = [col for col in cols if 'Sale' in col]\ncolsale\n# Of ['SaleType', 'SaleCondition', 'SalePrice'] 'SalePrice' is our target variable","fdab9b67":"# first list the columns\ncolspr = hppred_dna.columns\n# find out columns with 'Sales' in their names\ncolsale = [col for col in colspr if 'Sale' in col]\ncolsale\n# oops! prediction data has no 'SalePrice' and 'SaleType' columns\n","63c68f5c":"pd.Series(cols).equals(colspr)\n# Output 'False' implies both have different columns","b4a7f068":"# print columns which match in both\ncolsmatch = [col2 for col1 in cols for col2 in colspr if col1 == col2]\nprint(colsmatch)\nprint('')\nprint('NUmber of matching columns=', len(colsmatch))","5ca6d58d":"hp_dna_X = hp_dna[colsmatch]\nhp_dna_prX = hppred_dna[colsmatch]\nhp_y = hp_dna['SalePrice']","23b2b40f":"# Split into validation and training data\nhptrain_X, hpval_X, hptrain_y, hpval_y = train_test_split(hp_dna_X, hp_y, random_state=2)\nhptrain_X.reset_index(inplace=True) \nhptrain_X.pop('index')\nhpval_X.reset_index(inplace=True)\nhpval_X.pop('index')\nhpval_X.head() \n#train_y= hptrain_y.reset_index()\n#train_y.pop('index')\n#hptrain_y\n\n# above things are done because the output of test-train-split will have random index values. So that index\n# must be removed and a new index is placed","dc3571b1":"# Let us first work with numeric columns only\nXtr_int = hptrain_X.select_dtypes(include = int)\nXval_int = hpval_X.select_dtypes(include = int)\nXpr_int = hp_dna_prX.select_dtypes(include = int)\n","dd24b6f1":"RFmodel = RandomForestRegressor(random_state=100)","3f84e8d5":"RFmodel.fit(Xtr_int,hptrain_y)","56bdc088":"Xtr_int_mae = MAERROR(RFmodel.predict(Xtr_int),hptrain_y)\nprint(Xtr_int_mae)","3a8be175":"pred_valy = RFmodel.predict(Xval_int)\nXval_int_mae = MAERROR(pred_valy,hpval_y)\nprint(Xval_int_mae)","e3f14098":"# Make predictions on test data\n#pred_y = RFmodel.predict(Xpr_int)\n#pred_y.shape","958363be":"hptrain_X.select_dtypes(object).shape","b91d8ea0":"# check which columns have 'object' data types\nobjs = (hptrain_X.dtypes == 'object')\n# print out names of object columns\nprint(objs[objs],'\\n')\n\n# make a list of those columns\nObjCols = list(objs[objs].index)\n#print(ObjCols,'\\n')\n\n# Check that the same list of 'objcols' works for the testing data \nobjs2 = (hp_dna_prX.dtypes == 'object')\nObjCols2 = np.array(list(objs2[objs2].index))\n#print(ObjCols2,'\\n')\nprint(np.array_equal(ObjCols2,ObjCols)) ","a5ee70aa":"print(hpval_X[ObjCols].nunique().sum(),hptrain_X[ObjCols].nunique().sum(),hp_dna_prX[ObjCols].nunique().sum())","8da13b84":"stmt1 = hptrain_X[ObjCols].nunique() == hpval_X[ObjCols].nunique() \nstmt2 = hptrain_X[ObjCols].nunique() == hp_dna_prX[ObjCols].nunique()\nstmt3 = (stmt1) & (stmt2)\nObjColsCmn = list(stmt3[stmt3].index)\nprint('\\n','Object columns that have same nunique() values in \\\n      train,validate and test samples are',ObjColsCmn,'\\n')\n# Now form a dataframe of above object columns for training, validation and test sets \nXtrain = hptrain_X[ObjCols][ObjColsCmn]\nXval = hpval_X[ObjCols][ObjColsCmn]\nXpr = hp_dna_prX[ObjCols][ObjColsCmn]\n\n","1df0fd66":"Ohe = OneHotEncoder(handle_unknown='error',sparse=False)\n\n# Do the OneHotEncoding on training, validation and testing datasets\nOheObjXtrain = pd.DataFrame(Ohe.fit_transform(Xtrain),columns=Ohe.get_feature_names(ObjColsCmn)) # these are the columns corresponding to object columns are OHE\nOheObjXval = pd.DataFrame(Ohe.fit_transform(Xval),columns=Ohe.get_feature_names(ObjColsCmn)) # these are the columns corresponding to object columns are OHE\nOheObjXpr = pd.DataFrame(Ohe.fit_transform(Xpr),columns=Ohe.get_feature_names(ObjColsCmn)) # these are the columns corresponding to object columns are OHE\n\n","d00715a1":"# Check that the number of columns OneHotEncoded(OHE) dataframes are same\nprint('shape of training sample is ',Xtrain.shape,' and shape of its OHE dataframe is ',OheObjXtrain.shape)\nprint('shape of validation sample is ',Xval.shape,' and shape of its OHE dataframe is ',OheObjXval.shape)\nprint('shape of test sample is ',Xpr.shape,' and shape of its OHE dataframe is ',OheObjXpr.shape)\n","9156059c":"#drop the categorical columns\nXtrainObjDrop= hptrain_X.drop(ObjCols,axis=1)\nXvalObjDrop= hpval_X.drop(ObjCols,axis=1)\nXprObjDrop= hp_dna_prX.drop(ObjCols,axis=1)\n\n#concat the dataframes(hereafter call DF) with OneHotEncoded columns\nXtr = pd.concat([XtrainObjDrop,OheObjXtrain],axis =1)\nXval = pd.concat([XvalObjDrop,OheObjXval],axis =1)\nXpr = pd.concat([XprObjDrop,OheObjXpr],axis =1)\n\n#print shape\nprint('Shape of training set is',XtrainObjDrop.shape)\nprint(hpval_X.shape,hptrain_X.shape)\nprint(Xval.shape,Xtr.shape,Xpr.shape)","36a3ad3b":"# instatiate the model class\nRFmodel = RandomForestRegressor(random_state=100)","5190fc57":"# fit\nRFmodel.fit(Xtr.iloc[:,1:],hptrain_y) #id actually doesn't play a role so don't use it","1867b23b":"Xtr_mae = MAERROR(RFmodel.predict(Xtr.iloc[:,1:]),hptrain_y)\nprint(Xtr_mae)","5246a762":"\nXval_mae = MAERROR(RFmodel.predict(Xval.iloc[:,1:]),hpval_y)\nprint(Xval_mae)","0d0eea98":"pred_y = RFmodel.predict(Xpr.iloc[:,1:])\npred_y.shape","696c0536":"output = pd.DataFrame({'Id': Xpr.Id,\n                       'SalePrice': pred_y})\noutput.to_csv('submission.csv', index=False)","173e1d3c":"# Because of the finiteness of the sample data, the number of unique variables per a categorical column are different between the training, validation and test samples as the next cell shows","229ec5eb":"# Compute MAE for Xtr","92e59c3f":"# Split the data into training and testing data","36477d92":"# Compute the MAE for Xval_int","a387cd04":"# So the columns in hptest_dna and hp_dna might be different. So first we got to figure out which columns match and which don't","7fff3fe5":"# Compute the MAE for Xtr_int","6267a0f6":"# Predict 'SalesPrice' for testing data and also get the MAE","11012dbd":"# Therefore, retain only those object columns which have same number of unique values for the categorical variables","58b973c9":"# Above plot shows that predicted distribution has sharply decaying tail.","a6b5ccc2":"# Compute MAE for Xval","93ad8141":"# Number of matching columns in both are 46. So form another training and testing sets with just these matching forms.","0cd689c0":"# Fit the model","f1098b6e":"# Shape","2c8e231d":"## Let us add categorical variables as well into analysis","a187ff56":"# what are the columns with NANs ","4578e757":"# so there NANs. Are there missing values?","4a1e7bef":"# Now let's throw the data into RandomForest and see what comes out!","1e7dbdac":"# Refine the results by exploring the data and refining the model. Let's visualize the data and get some idea about correlations","411c5b32":"# Let's use the OneHotEncoder from scikit-learn","41db233c":"#  Refinement-1 of the model:","7b1f22e7":"# Identify the target column ","1b7e98fc":"# Let us first try to analyze by dropping the columns with NANs","6597a340":"# Now replace the categorical columns in the datasets with the OneHotEncoded columns","853a4f73":"# Let's use the Random Forest regressor "}}