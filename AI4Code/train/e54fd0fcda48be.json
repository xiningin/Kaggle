{"cell_type":{"9b472705":"code","04ddf3fe":"code","dd0af631":"code","cc16732f":"code","25030877":"code","e1492cd8":"code","bccc1fe5":"code","288818aa":"code","a2c5e59f":"code","f94e1fd0":"code","60fa5d5a":"code","ba7b5276":"code","0dcab289":"code","97617dac":"code","c6fa9ea1":"code","e113f346":"code","fab3c543":"code","163e2c00":"code","9d5b3e2f":"code","1e2210a1":"code","5f171956":"code","99727e91":"code","5f1a054b":"code","ba3f3519":"code","e0d63c38":"code","ee6cf7d1":"code","a4ffdb6e":"code","4f759882":"code","bc345559":"code","1967b15a":"code","870cbd3f":"code","a113dae3":"code","2354f698":"code","7e1f7b63":"code","3ec7fe59":"code","d340dd53":"code","5018d6e5":"code","75364cb8":"code","cdcbfc92":"code","99de141f":"code","cfa6bfbb":"code","d0ede91f":"code","3fd5efe9":"code","f2d07f1c":"code","582e7257":"code","61e2e215":"code","752493d5":"code","3ee728a1":"code","c60a728c":"code","3f21d9cc":"code","0f7d7be3":"code","594d54e2":"code","c51963fe":"code","34179be7":"code","91005f75":"code","300e215f":"code","08a6ae0b":"code","8308acd4":"code","e33a0536":"code","cba51880":"code","e5104a24":"code","42713c78":"code","00fbf286":"markdown","2144cc8a":"markdown","51b642bc":"markdown","d0003838":"markdown","ccc7cf5c":"markdown"},"source":{"9b472705":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04ddf3fe":"from matplotlib import pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport warnings \nwarnings.simplefilter(\"ignore\")","dd0af631":"dataset_df = pd.read_csv(\"\/kaggle\/input\/predict-test-scores-of-students\/test_scores.csv\")\ndataset_df.head()","cc16732f":"dataset_df.isnull().sum()","25030877":"dataset_df.duplicated().sum()","e1492cd8":"dataset_df.describe()","bccc1fe5":"dataset_df.info()","288818aa":"dataset_df.columns","a2c5e59f":"categorical_columns = ['school', 'school_setting', 'school_type', 'classroom', 'teaching_method', 'gender', \n                       'lunch', ]\n\nnumerical_columns = ['n_student', 'pretest', 'posttest']","f94e1fd0":"print(dataset_df[categorical_columns[0]].unique())\nprint(dataset_df[categorical_columns[0]].value_counts()\/len(dataset_df))","60fa5d5a":"print(dataset_df[categorical_columns[1]].unique())\nprint(dataset_df[categorical_columns[1]].value_counts()\/len(dataset_df))","ba7b5276":"print(dataset_df[categorical_columns[2]].unique())\nprint(dataset_df[categorical_columns[2]].value_counts()\/len(dataset_df))","0dcab289":"print(dataset_df[categorical_columns[3]].unique())\nprint(dataset_df[categorical_columns[3]].value_counts()\/len(dataset_df))","97617dac":"print(dataset_df[categorical_columns[4]].unique())\nprint(dataset_df[categorical_columns[4]].value_counts()\/len(dataset_df))","c6fa9ea1":"print(dataset_df[categorical_columns[5]].unique())\nprint(dataset_df[categorical_columns[5]].value_counts()\/len(dataset_df))","e113f346":"print(dataset_df[categorical_columns[6]].unique())\nprint(dataset_df[categorical_columns[6]].value_counts()\/len(dataset_df))","fab3c543":"sns.pairplot(dataset_df[numerical_columns+[\"gender\"]], hue=\"gender\")","163e2c00":"gender_df = dataset_df.groupby([\"gender\"])[\"posttest\"].mean().reset_index()\ngender_df.plot.bar(x=\"gender\", y='posttest', title='Dependence of gender on the mean test result')","9d5b3e2f":"school_df = dataset_df.groupby([\"school_type\"])[\"posttest\"].mean().reset_index()\nschool_df.plot.bar(x=\"school_type\", y='posttest', title='Dependence of the type of school on the mean test result')","1e2210a1":"teaching_method_df = dataset_df.groupby([\"teaching_method\"])[\"posttest\"].mean().reset_index()\nteaching_method_df.plot.bar(x=\"teaching_method\", y='posttest', title='Dependence of the teaching method on the mean test result')","5f171956":"dataset_df.groupby(['school_setting'])[\"posttest\"].sum().plot(kind='pie', subplots=True, shadow = True,startangle=90,\nfigsize=(15,10), autopct='%1.1f%%')","99727e91":"teaching_method_df = dataset_df.groupby([\"n_student\"])[\"posttest\"].mean().reset_index()\n\ncolors = np.random.rand(len(teaching_method_df))\nsize = teaching_method_df[\"posttest\"].values\nplt.scatter(teaching_method_df[\"n_student\"], teaching_method_df[\"posttest\"], s=size, c=colors)","5f1a054b":"dataset_df.columns","ba3f3519":"corr_df = dataset_df.drop(['school','student_id','classroom'], axis=1)\n\ncorr_columns = {'school_setting':{'Urban':0, 'Suburban':1, 'Rural':2},\n               'school_type':{'Public':0, 'Non-public':1},\n               'teaching_method':{'Standard':0, 'Experimental':1},\n               'lunch':{'Does not qualify':0, 'Qualifies for reduced\/free lunch':1},\n               'gender':{'Female':0, 'Male':1}}\n\ncorr_df = corr_df.replace(corr_columns)\n\ncorr_df.head()","e0d63c38":"corr = corr_df.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","ee6cf7d1":"dataset_df.head()","a4ffdb6e":"dataset_df = dataset_df.drop([\"student_id\", \"school\", \"classroom\"], axis=1)\ndataset_df.head()","4f759882":"dataset_df.info()","bc345559":"X = dataset_df.iloc[:,0:8].values\ny = dataset_df.iloc[:, -1].values","1967b15a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, shuffle=True)","870cbd3f":"from sklearn.preprocessing import LabelEncoder\n\ncol0_LE = LabelEncoder()\nX_train[:,0] = col0_LE.fit_transform(X_train[:,0])\n\ncol1_LE = LabelEncoder()\nX_train[:,1] = col1_LE.fit_transform(X_train[:,1])\n\ncol2_LE = LabelEncoder()\nX_train[:,2] = col2_LE.fit_transform(X_train[:,2])\n\ncol4_LE = LabelEncoder()\nX_train[:,4] = col4_LE.fit_transform(X_train[:,4])\n\ncol5_LE = LabelEncoder()\nX_train[:,5] = col5_LE.fit_transform(X_train[:,5])","a113dae3":"X_test[:,0] = col0_LE.transform(X_test[:,0])\n\nX_test[:,1] = col1_LE.transform(X_test[:,1])\n\nX_test[:,2] = col2_LE.transform(X_test[:,2])\n\nX_test[:,4] = col4_LE.transform(X_test[:,4])\n\nX_test[:,5] = col5_LE.transform(X_test[:,5])","2354f698":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","7e1f7b63":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","3ec7fe59":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\ny_train = y_train.reshape(-1,1).astype('float32')\ny_test = y_test.reshape(-1,1).astype('float32')","d340dd53":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","5018d6e5":"from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error\n\ndef print_score(y_pred, y_real):\n    print(\"mean_squared_error:\", mean_squared_error(y_pred, y_real))\n    print(\"r2_score:\", r2_score(y_pred, y_real))\n    print(\"explained_variance_score:\", explained_variance_score(y_pred, y_real))   ","75364cb8":"from sklearn.model_selection import GridSearchCV\n\ndef get_trained_grid(model, grid_params, x_train, y_train ,refit=True, cv=10, verbose=1):\n    grid = GridSearchCV(model, grid_params, refit=refit, cv=cv, verbose=verbose)\n    grid.fit(x_train, y_train)\n    return grid","cdcbfc92":"def get_grid_best_params(grid):\n    print(grid.best_params_)\n    print(grid.best_estimator_)","99de141f":"def print_grid_performance(grid, x_test, y_test):\n    y_pred = grid.predict(x_test)\n    print_score(y_pred, y_test)","cfa6bfbb":"from sklearn.linear_model import SGDClassifier\n\n%time\ngrid_params = { \"loss\": [\"hinge\", \"log\", \"modified_huber\"],\n               \"penalty\": [\"l1\", \"l2\", \"elasticnet\"]   \n}\n\ngrid = get_trained_grid(SGDClassifier(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","d0ede91f":"print_grid_performance(grid, X_test, y_test)","3fd5efe9":"from sklearn.neighbors import KNeighborsClassifier\n\n%time\ngrid_params = { \"n_neighbors\": np.arange(1,50)}\n\ngrid = get_trained_grid(KNeighborsClassifier(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","f2d07f1c":"print_grid_performance(grid, X_test, y_test)","582e7257":"from sklearn.naive_bayes import GaussianNB\n\n%time\ngrid_params = { \"var_smoothing\": [1e-09] }\n\ngrid = get_trained_grid(GaussianNB(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","61e2e215":"print_grid_performance(grid, X_test, y_test)","752493d5":"from sklearn.tree import DecisionTreeClassifier\n\n%time\ngrid_params = {'criterion': [\"gini\", \"entropy\"], \n              'splitter': ['best', 'random'], \n              'max_depth': [3,4,None], \n              'min_samples_split':[2, 4, 6],\n              'min_samples_leaf':[1,2,3]}\n\ngrid = get_trained_grid(DecisionTreeClassifier(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","3ee728a1":"print_grid_performance(grid, X_test, y_test)","c60a728c":"from sklearn.ensemble import RandomForestClassifier\n\n%time\ngrid_params = {'n_estimators': [10, 20, 50], \n              'max_features': ['auto', 'sqrt', 'log2'], \n              'bootstrap': [True, False], \n              'criterion':['entropy', 'gini']}\n\ngrid = get_trained_grid(RandomForestClassifier(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","3f21d9cc":"print_grid_performance(grid, X_test, y_test)","0f7d7be3":"from sklearn import svm\n\n%time\ngrid_params = { \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n               \"degree\": [1, 2 ,3, 4, 5, 6] }\n\ngrid = get_trained_grid(svm.SVR(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","594d54e2":"print_grid_performance(grid, X_test, y_test)","c51963fe":"from sklearn.naive_bayes import BernoulliNB\n\n%time\ngrid_params = {'alpha': [0.25, 0.5, 1]}\n\ngrid = get_trained_grid(BernoulliNB(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","34179be7":"print_grid_performance(grid, X_test, y_test)","91005f75":"from xgboost import XGBClassifier\n\n%time\ngrid_params = {'learning_rate': [0.01, 0.05, 0.1], \n              'eval_metric': ['error']}\n\ngrid = get_trained_grid(XGBClassifier(), grid_params, X_train, y_train)\nget_grid_best_params(grid)","300e215f":"print_grid_performance(grid, X_test, y_test)","08a6ae0b":"!pip install livelossplot","8308acd4":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","e33a0536":"from sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Input\n\ndef build_model(optimizer=\"adam\"):\n    model = Sequential()\n    model.add(Dense(32, input_dim=X_train.shape[1], activation=\"sigmoid\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(16, activation=\"sigmoid\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(8, activation=\"sigmoid\"))\n    model.add(Dense(1))\n    model.compile(optimizer=optimizer, loss=\"mean_squared_error\", metrics=[\"mse\"])\n    return model","cba51880":"model = build_model()\nmodel.summary()","e5104a24":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom livelossplot import PlotLossesKerasTF\n\nbatch_size = 16\nepochs = 200\n\ncheckpoint = ModelCheckpoint(\"Best_model_params.h5\", monitor='val_loss')\nes = EarlyStopping(monitor='val_loss', mode='min', patience=10)\ncallbacks = [PlotLossesKerasTF(), es, checkpoint]\n\nhistory = model.fit(X_train, y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    callbacks=callbacks,\n                    validation_data=(X_test, y_test),\n                    verbose=1)","42713c78":"yhat = model.predict(X_test)\nprint_score(yhat, y_test)","00fbf286":"### Read Datase","2144cc8a":"### Preparing Dataset for model","51b642bc":"### Visualizationunique","d0003838":"### Data exploration","ccc7cf5c":"### Building the models"}}