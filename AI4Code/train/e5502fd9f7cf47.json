{"cell_type":{"a0368c4f":"code","a02de12b":"code","b479a9df":"code","ce78e9a0":"code","4d9d5ce1":"code","362d0fb6":"code","9fb03a4c":"code","77e29645":"code","395c0a4f":"code","cf96e1ff":"code","1486fa98":"code","638be128":"code","464dd655":"code","ec542ae2":"code","08a0ed4f":"code","953a850f":"code","720f4e8a":"code","fd151285":"code","f9378565":"code","1a6393c9":"code","7c4eec0b":"code","ac1455c1":"markdown","491b5549":"markdown","5fef5350":"markdown","06e1b7ee":"markdown","f7c16bc4":"markdown","74b43e07":"markdown","df34593a":"markdown","286b78b8":"markdown","b05d9fef":"markdown","140159c9":"markdown","2fe9abb4":"markdown","c532e3fb":"markdown"},"source":{"a0368c4f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport glob\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator","a02de12b":"train_dir = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_dir = '..\/input\/plant-pathology-2021-fgvc8\/test_images'","b479a9df":"def get_files(directory):\n  if not os.path.exists(directory):\n    return 0\n  count = 0 \n  for current_path, dirs, files in os.walk(directory):\n    for dr in dirs:\n      count += len(glob.glob(os.path.join(current_path, dr+\"\/*\")))\n  return count","ce78e9a0":"data_training = get_files(train_dir)\ndata_validation = get_files(val_dir)\ndata_testing = get_files(test_dir)\nnum_classes = len(glob.glob(train_dir + \"\/*\"))\n\nprint('Jumlah data training :', data_training)\nprint('Jumlah data validation :', data_validation)\nprint('Jumlah data testing :', data_testing)\nprint('Jumlah Kelas Dataset :', num_classes)","4d9d5ce1":"train_datagen = ImageDataGenerator(rescale=1\/255,\n                                   horizontal_flip=True,\n                                   zoom_range = 0.3)\n\nval_datagen = ImageDataGenerator(rescale=1\/255,\n                                 horizontal_flip=True,\n                                 zoom_range = 0.3)\n\ntest_datagen = ImageDataGenerator(rescale=1\/255,\n                                  horizontal_flip=False,\n                                  vertical_flip=False)","362d0fb6":"image_width = 400\nimage_height = 400\n\nmode = 'rgb'\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size=(image_width, image_height),\n                                                    batch_size=32,\n                                                    color_mode = mode)\n\nval_generator = val_datagen.flow_from_directory(val_dir,\n                                                target_size = (image_width, image_height),\n                                                batch_size=32,\n                                                color_mode = mode)\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size = (image_width, image_height),\n                                                  batch_size=32,\n                                                  color_mode = mode)","9fb03a4c":"train_generator.class_indices","77e29645":"import keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.utils import plot_model\n\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, BatchNormalization","395c0a4f":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), input_shape=(image_width, image_height, 3), padding='same', strides=1, activation='relu', name='konvolusi_1'))\n#model.add(Conv2D(64, (3,3), strides=1, activation='relu', name='konvolusi_1b'))\nmodel.add(MaxPooling2D(pool_size = (2, 2), name='pool_layer_1'))\n\n\nmodel.add(Conv2D(64, (3,3), padding='same', strides=1, activation='relu', name='konvolusi_2'))\n#model.add(Conv2D(256, (3,3), strides=1, activation='relu', name='konvolusi_2b'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), name='pool_layer_2'))\n\nmodel.add(Conv2D(128, (3,3), padding='same', strides=1, activation='relu', name='konvolusi_3'))\n#model.add(Conv2D(512, (3,3), strides=1, activation='relu', name='konvolusi_3b'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), name='pool_layer_3'))\n\nmodel.add(Conv2D(256, (3,3), padding='same', strides=1, activation='relu', name='konvolusi_4'))\n#model.add(Conv2D(256, (3,3), strides=1, activation='relu', name='konvolusi_4b'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), name='pool_layer_4'))\n\nmodel.add(Conv2D(512, (3,3), padding='same', strides=1, activation='relu', name='konvolusi_5'))\n#model.add(Conv2D(512, (3,3), strides=1, activation='relu', name='konvolusi_5b'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), name='pool_layer_5'))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu', name='ANN_1'))\nmodel.add(Dense(1024, activation='relu', name='ANN_1b'))\nmodel.add(Dense(num_classes, activation='softmax', name='Output'))\n\nmodel.summary()","cf96e1ff":"plot_model(model, show_layer_names=True, show_shapes=True, to_file='ini_model.png')","1486fa98":"from keras.preprocessing import image\nimport numpy as np\n\nimg1 = image.load_img('..\/input\/tomato-disease-ver2\/tomato_disease_ready ver2\/validation\/healthy\/000146ff-92a4-4db6-90ad-8fce2ae4fddd___GH_HL Leaf 259.1 - Copy.JPG')\nplt.imshow(img1)\n\nimg1 = image.load_img('..\/input\/tomato-disease-ver2\/tomato_disease_ready ver2\/validation\/healthy\/000146ff-92a4-4db6-90ad-8fce2ae4fddd___GH_HL Leaf 259.1 - Copy.JPG', target_size=(image_width, image_height, 1), color_mode='rgb')\nimg = image.img_to_array(img1)\nimg = img\/255\nimg = np.expand_dims(img, axis=0)","638be128":"import matplotlib.image as mpig\nfrom keras.models import  Model\n\nconv_output = Model(inputs=model.input, outputs=model.get_layer('konvolusi_3').output)\nconv_features = conv_output.predict(img)\n\nfig = plt.figure(figsize= (28, 14))\ncolumns = 8\nrows = 4\n\nfor i in range (columns*rows):\n  fig.add_subplot(rows, columns, i+1)\n  plt.axis('off')\n  plt.title('filter ke-' + str(i))\n  plt.imshow(conv_features[0, :, :, i])\nplt.show","464dd655":"opt = keras.optimizers.Adam(lr=0.001)\nmodel.compile(optimizer=opt,\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n\nbatch_size = 32\n\ntrain = model.fit_generator(train_generator,\n                            epochs=10,\n                            steps_per_epoch = train_generator.samples \/\/ batch_size,\n                            validation_data = val_generator,\n                            validation_steps = val_generator.samples \/\/ batch_size,\n                            verbose = 1)","ec542ae2":"acc = train.history['accuracy']\nval_acc = train.history['val_accuracy']\nloss = train.history['loss']\nval_loss = train.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# Plot akurasi data taraining dan validation\nplt.plot(epochs, acc, 'b', label='Akurasi training')\nplt.plot(epochs, val_acc, 'r', label='Akurasi validasi')\nplt.title('Akurasi Training dan Validasi')\nplt.legend()\n\nplt.figure()\n\n# Plot loss taraining dan validation\nplt.plot(epochs, loss, 'b', label='Loss training')\nplt.plot(epochs, val_loss, 'r', label='Loss validasi')\nplt.title('Akurasi Training dan Validasi')\nplt.legend()\n\nplt.show()","08a0ed4f":"score, accuracy = model.evaluate(test_generator, verbose=1)\nprint(\"Score Testing adalah {}\".format(score))\nprint(\"Akurasi Testing adalah {}\".format(accuracy))","953a850f":"model.save('.\/model_saya_2.h5')","720f4e8a":"test_generator = test_datagen.flow_from_directory(test_dir,\n                                                  target_size=(image_width,image_height),\n                                                  batch_size=batch_size,\n                                                  color_mode='rgb',\n                                                  shuffle=False)\n\nresolt = model.predict_classes(test_generator, batch_size=None, verbose=1)","fd151285":"resolt","f9378565":"import pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\n\ndata = {'y_Actual':    test_generator.classes,\n        'y_Predicted': resolt\n        }\n\ndf = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\nconfusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n\nsn.heatmap(confusion_matrix, annot=True, fmt='.0f')\nplt.show()","1a6393c9":"# Loading model\nfrom keras.models import load_model\nmodel = load_model('.\/model_saya_2.h5')\n\nClasses = ['bacterial_spot',\n           'early_blight',\n           'healthy',\n           'late_blight',\n           'leaf_mold',\n           'septoria_leaf_spot',\n           'spotted_spider_mite',\n           'target_spot',\n           'yellow_leaf_curl_virus']","7c4eec0b":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# pre-processing test data sama dengan train data\nimg_width = 400\nimg_height = 400\n#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nfrom keras.preprocessing import image\ndef prepare(img_path):\n    img = image.load_img(img_path, target_size=(384,384,3))\n    x = image.img_to_array(img)\n    x = x\/255\n    return np.expand_dims(x, axis=0)\n\ninput_data = '..\/input\/tomato-disease-ver2\/tomato_disease_ready ver2\/test\/yellow_leaf_curl_virus\/a2737028-9b65-4d23-900d-42f9f795f465___YLCV_GCREC 2489.JPG'\nresult = model.predict_classes([prepare(input_data)])\ndisease = image.load_img(input_data)\nplt.imshow(disease)\nprint ('Terdeteksi penyakit : ', Classes[int(result)])\n","ac1455c1":"# Pre-Processing Image","491b5549":"## Pre-Processing data input","5fef5350":"## Menyimpan Model ","06e1b7ee":"## Load data from GDrive","f7c16bc4":"## Test data baru","74b43e07":"## Plot Training Process","df34593a":"## import library","286b78b8":"## Mengatur Ukuran dari image\/citra input","b05d9fef":"## Visualisasi Layer Konvolusi","140159c9":"## Menghitung jumlah dataset","2fe9abb4":"# Build CNN Architecure","c532e3fb":"# Training CNN Architecture"}}