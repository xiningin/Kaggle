{"cell_type":{"d64069df":"code","8cf2257a":"code","10d64426":"code","ca3a7e1f":"code","fe0f9897":"code","6470bfd2":"code","13eb7bb6":"code","8dfcf86e":"code","396c1b44":"code","b8ed2bba":"code","638a5ae1":"code","c5f1216b":"code","59014651":"code","ee733d34":"code","096425b8":"code","7c93f70e":"code","40d4fe3c":"code","16a18332":"code","fd32230f":"code","535ce560":"code","ba6e657e":"code","bfa2d7af":"code","37aea07c":"code","df61a92f":"code","766dee54":"code","2d5864af":"code","56c21a26":"code","e9740c17":"code","b96e5984":"code","ec819176":"code","e540cc04":"code","ddfca86e":"code","b3bd0ae5":"code","22ff7f1c":"markdown"},"source":{"d64069df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cf2257a":"!git clone https:\/\/github.com\/eriklindernoren\/PyTorch-GAN","10d64426":"import os\nos.chdir('.\/PyTorch-GAN')","ca3a7e1f":"#download dataset\n!bash .\/data\/download_cyclegan_dataset.sh vangogh2photo","fe0f9897":"import argparse\nimport os\nimport numpy as np\nimport itertools\nimport datetime\nimport time\nimport matplotlib.pyplot as plt\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image, make_grid\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nimport torch\n\nimport random\nimport sys\nimport glob\nfrom PIL import Image","6470bfd2":"#receive input for model's parameters\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--epoch\", type=int, default=10, help=\"epoch to start training from\")\nparser.add_argument(\"--n_epochs\", type=int, default=11, help=\"number of epochs of training\")\nparser.add_argument(\"--dataset_name\", type=str, default=\"vangogh2photo\", help=\"name of the dataset\")\nparser.add_argument(\"--batch_size\", type=int, default=5, help=\"size of the batches\")\nparser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\nparser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\nparser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\nparser.add_argument(\"--decay_epoch\", type=int, default=0, help=\"epoch from which to start lr decay\")\nparser.add_argument(\"--n_cpu\", type=int, default=2, help=\"number of cpu threads to use during batch generation\")\nparser.add_argument(\"--img_height\", type=int, default=256, help=\"size of image height\")\nparser.add_argument(\"--img_width\", type=int, default=256, help=\"size of image width\")\nparser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\nparser.add_argument(\"--sample_interval\", type=int, default=200, help=\"interval between saving generator outputs\")\nparser.add_argument(\"--checkpoint_interval\", type=int, default=-1, help=\"interval between saving model checkpoints\")\nparser.add_argument(\"--n_residual_blocks\", type=int, default=3, help=\"number of residual blocks in generator\")\nparser.add_argument(\"--lambda_cyc\", type=float, default=10.0, help=\"cycle loss weight\")\nparser.add_argument(\"--lambda_id\", type=float, default=4.0, help=\"identity loss weight\")\nparser.add_argument(\"--color\", type=str, default=\"all\", help=\"filter color dominance\")\nparser.add_argument(\"--cuda\", type=bool, default=torch.cuda.is_available(), help=\"cuda\")\nopt = parser.parse_args('')\nprint(opt)\n\nos.makedirs(\"images\/%s\" % opt.dataset_name, exist_ok=True)\nos.makedirs(\"saved_models\/%s\" % opt.dataset_name, exist_ok=True)","13eb7bb6":"!pip install gdown\nimport gdown\n\nurl = 'https:\/\/drive.google.com\/uc?id=1-MXLfup_MH8Wu7dRMHxjslJhFYdTcDcJ'\n# url = 'https:\/\/drive.google.com\/uc?id=1-VDFU_t1vEDn3BhcZjFMyVt5_YW2bKoW'\n# url = 'https:\/\/drive.google.com\/uc?id=1-fpYYRuQzCn5tPZbhB_1tbzoTFqfvzoo'\n# url = 'https:\/\/drive.google.com\/uc?id=1-gBaYaqe-5YJqOkThP-yUl5bzVUrYUky'\n# url = 'https:\/\/drive.google.com\/uc?id=1-e42gJWJTuUfeFMvE5jkugbDCsEedKRJ'\noutput = '.\/saved.zip'\ngdown.download(url, output, quiet=False)","8dfcf86e":"!unzip '.\/saved.zip' -d '.\/'","396c1b44":"mv .\/content\/checkpoints\/* .\/saved_models\/vangogh2photo\/","b8ed2bba":"class ImageDataset(Dataset):\n    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\", color = \"all\"):\n        self.transform = transforms.Compose(transforms_)\n        self.unaligned = unaligned\n        \n        #type A images are the VanGogh style images and type B images are the real photo\n        #All images are already RGB with the shape of (256,256)\n        self.files_A = sorted(glob.glob(root + \"A\/*.*\"))\n        self.files_B = sorted(glob.glob(root + \"B\/*.*\"))\n        \n        #filter image depending on the color dominance\n        if color != \"all\":\n            A = []\n            B = []\n            \n            #if t == 0, the dataset contains only red domimance images\n            #if t == 1, the dataset contains only green domimance images\n            #if t == 2, the dataset contains only blue domimance images\n            t = 0 if color == \"red\" else 1 if color == \"green\" else 2\n            \n            #filter the type A images\n            for p in self.files_A:\n                img = plt.imread(p)\n                cnt = [0,0,0]\n\n                r = img.shape[0]\n                c = img.shape[1]\n\n                for j in range(r):\n                    for i in range(c):\n                        cnt[np.argmax(img[j][i])] += 1\n                \n                if np.argmax(cnt) == t:\n                    A.append(p)\n\n            #filter the type B images\n            for p in self.files_B:\n                img = plt.imread(p)\n                cnt = [0,0,0]\n\n                r = img.shape[0]\n                c = img.shape[1]\n\n                for j in range(r):\n                    for i in range(c):\n                        cnt[np.argmax(img[j][i])] += 1\n                \n                if np.argmax(cnt) == t:\n                    B.append(p)\n            \n            self.files_A = A\n            self.files_B = B\n                        \n\n\n    def __getitem__(self, index):\n        image_A = Image.open(self.files_A[index % len(self.files_A)])\n        \n        if self.unaligned:\n            #randomize image to be returned\n            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n        else:\n            image_B = Image.open(self.files_B[index % len(self.files_B)])\n\n        #apply transform to the image\n        item_A = self.transform(image_A)\n        item_B = self.transform(image_B)\n        return {\"A\": item_A, \"B\": item_B}\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))","638a5ae1":"#class to update learning rate\nclass LambdaLR:\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n\n    def step(self, epoch):\n        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) \/ (self.n_epochs - self.decay_start_epoch)","c5f1216b":"#function to initialize model's weight and bias\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n        if hasattr(m, \"bias\") and m.bias is not None:\n            torch.nn.init.constant_(m.bias.data, 0.0)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)","59014651":"class ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n\n        self.block = nn.Sequential(\n            nn.ReplicationPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.Dropout2d(p=0.1, inplace=True),\n            nn.InstanceNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReplicationPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)","ee733d34":"#class to generate fake images\nclass Generator(nn.Module):\n    def __init__(self, input_shape, num_residual_blocks):\n        super(Generator, self).__init__()\n        \n        channels = input_shape[0]\n\n        #Initial convolution block\n        out_features = 64\n        model = [\n            nn.ReplicationPad2d(channels),\n            nn.Conv2d(channels, out_features, 7),\n            nn.InstanceNorm2d(out_features),\n            nn.ReLU(inplace=True),\n        ]\n        in_features = out_features\n\n        #Downsampling\n        for _ in range(2):\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                nn.Dropout2d(p=0.1, inplace=True),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True),\n            ]\n            in_features = out_features\n        \n        #Residual blocks\n        for _ in range(num_residual_blocks):\n            model += [ResidualBlock(out_features)]\n\n        #Upsampling\n        for _ in range(2):\n            out_features \/\/= 2\n            model += [\n                nn.Upsample(scale_factor=2),\n                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True),\n            ]\n            in_features = out_features\n\n        #Output layer\n        model += [nn.ReplicationPad2d(channels), nn.Conv2d(out_features, channels, 7), nn.Tanh()]\n        \n        #Unpack the model architecture\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)","096425b8":"#class to consider fake or real images\nclass Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n\n        channels, height, width = input_shape\n        if opt.cuda:\n            self.dev = torch.device('cuda')\n        else:\n            self.dev = torch.device('cpu')\n\n        self.output_shape = (1, height \/\/ 2 ** 4, width \/\/ 2 ** 4)\n        self.loss = torch.nn.MSELoss()\n\n        def discriminator_block(in_filters, out_filters, normalize=True):\n            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *discriminator_block(channels, 64, normalize=False),\n            *discriminator_block(64, 128),\n            *discriminator_block(128, 256),\n            *discriminator_block(256, 512),\n            nn.ZeroPad2d((1, 0, 1, 0)),\n            nn.Conv2d(512, 1, 4, padding=1)\n        )\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=opt.lr,\n                                          betas=(opt.b1, opt.b2))\n\n    def forward(self, img):\n        return self.model(img)\n    \n    #function to train discriminator\n    def feed(self, real_data, fake_data, valid, fake):\n        self.optimizer.zero_grad()\n        \n        #the loss value from the discriminator on determining non generated image (real image)\n        loss_real = self.loss(self.model(real_data), valid)\n        #the loss value from the discriminator on determining generated image\n        loss_fake = self.loss(self.model(fake_data.detach()), fake)\n        loss_value = (loss_real + loss_fake) \/ 2\n\n        loss_value.backward()\n        self.optimizer.step()\n\n        return loss_value","7c93f70e":"class GAN(nn.Module):\n    def __init__(self, opt):\n        super(GAN, self).__init__()\n        self.input_shape = (opt.channels, opt.img_height, opt.img_width)\n        self.G = Generator(self.input_shape, opt.n_residual_blocks)\n        self.D = Discriminator(self.input_shape)\n#         self.loss = torch.nn.BCELoss()\n#         self.opt = opt\n\n        if opt.cuda:\n            self.dev = torch.device('cuda')\n            self.G.cuda()\n            self.D.cuda()\n#             self.loss.cuda()\n            self.Tensor = torch.cuda.FloatTensor\n        else:\n            self.dev = torch.device('cpu')\n            self.Tensor = torch.FloatTensor\n        \n#         self.opt_G = torch.optim.Adam(self.G.parameters(), lr=opt.lr,\n#                                       betas=(opt.b1, opt.b2))\n#         self.opt_D = torch.optim.Adam(self.D.parameters(), lr=opt.lr,\n#                                       betas=(opt.b1, opt.b2))\n        \n    #function to train GAN, but I do not use this function\n#     def train(self, dataloader):\n#         for epoch in range(self.opt.n_epochs):\n#             for i, imgs in enumerate(dataloader):\n#                 valid = torch.ones((imgs.size(0), 1), device=self.dev,\n#                                    requires_grad=False)\n#                 fake  = torch.zeros((imgs.size(0), 1), device=self.dev,\n#                                     requires_grad=False)\n#                 z = torch.randn((imgs.size(0), opt.latent_dim),\n#                                 device=self.dev, requires_grad=True)\n\n#                 real_imgs = imgs.type(dtype=self.Tensor)\n\n#                 gen_imgs = self.G(z)\n\n#                 self.opt_G.zero_grad()\n#                 G_loss = self.loss(self.D(gen_imgs), valid)\n#                 G_loss.backward()\n#                 self.opt_G.step()\n    \n#                 self.opt_D.zero_grad()\n#                 real_loss = self.loss(self.D(real_imgs), valid)\n#                 fake_loss = self.loss(self.D(gen_imgs.detach()), fake)\n#                 D_loss = (real_loss + fake_loss) \/ 2\n#                 D_loss.backward()\n#                 self.opt_D.step()\n                \n#                 done = epoch * len(dataloader) + i\n#                 if done % opt.sample_interval == 0:\n#                     save_image(gen_imgs.data[:25], \n#                                \".\/images\/%d.jpg\" % done,\n#                                nrow = 5, normalize = True)","40d4fe3c":"class CycleGAN(nn.Module):\n    def __init__(self, opt):\n        super(CycleGAN, self).__init__()\n        #model's loss function\n        self.criterion_GAN = torch.nn.MSELoss()\n        self.criterion_cycle = torch.nn.L1Loss()\n        self.criterion_identity = torch.nn.L1Loss()\n\n        self.cuda = opt.cuda\n        self.input_shape = (opt.channels, opt.img_height, opt.img_width)\n        \n        #GAN_AB.D is the discriminator to determine whether an image is generated or real for type B\n        #GAN_AB.G is the generator to generate image type B given type A\n        self.GAN_AB = GAN(opt)\n        \n        #GAN_BA.D is the discriminator to determine whether an image is generated or real for type A\n        #GAN_BA.G is the generator to generate image type A given type B\n        self.GAN_BA = GAN(opt)\n\n        if self.cuda:\n            #using GPU for faster computing\n            self.criterion_GAN.cuda()\n            self.criterion_cycle.cuda()\n            self.criterion_identity.cuda()\n            self.dev = torch.device('cuda')\n            self.Tensor = torch.cuda.FloatTensor\n        else:\n            self.dev = torch.device('cpu')\n            self.Tensor = torch.FloatTensor\n\n        if opt.epoch != 0:\n            #to load model\n            self.GAN_AB.G.load_state_dict(torch.load(\"saved_models\/%s\/G_AB_%d.pth\" % (opt.dataset_name, opt.epoch)))\n            self.GAN_BA.G.load_state_dict(torch.load(\"saved_models\/%s\/G_BA_%d.pth\" % (opt.dataset_name, opt.epoch)))\n            self.GAN_BA.D.load_state_dict(torch.load(\"saved_models\/%s\/D_A_%d.pth\" % (opt.dataset_name, opt.epoch)))\n            self.GAN_AB.D.load_state_dict(torch.load(\"saved_models\/%s\/D_B_%d.pth\" % (opt.dataset_name, opt.epoch)))\n        else:\n            #initialize model's weight and bias\n            self.GAN_AB.G.apply(weights_init_normal)\n            self.GAN_BA.G.apply(weights_init_normal)\n            self.GAN_BA.D.apply(weights_init_normal)\n            self.GAN_AB.D.apply(weights_init_normal)\n    \n        #model's optimizer\n        self.optimizer_G = torch.optim.Adam(\n            itertools.chain(self.GAN_AB.G.parameters(), self.GAN_BA.G.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2)\n        )\n    \n        #model's learning rate updater\n        self.lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n            self.optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n        )\n        self.lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n            self.GAN_BA.D.optimizer, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n        )\n        self.lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n            self.GAN_AB.D.optimizer, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n        )\n        \n        #preprocessor images (transform)\n        self.transforms_ = [\n            transforms.RandomCrop((opt.img_height, opt.img_width)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n        ]\n        \n        #train dataset\n        self.dataloader = DataLoader(\n            ImageDataset(\".\/%s\/train\/\" % opt.dataset_name, transforms_=self.transforms_, unaligned=True, color = opt.color),\n            batch_size=opt.batch_size,\n            shuffle=True,\n            num_workers=opt.n_cpu,\n        )\n        \n        #validation dataset\n        self.val_dataloader = DataLoader(\n            ImageDataset(\".\/%s\/test\/\" % opt.dataset_name, transforms_=self.transforms_, unaligned=True, mode=\"test\", color = opt.color),\n            batch_size=opt.batch_size,\n            shuffle=True,\n            num_workers=1,\n        )\n\n    #function to generate sample images\n    def sample_images(self, batches_done):\n        imgs = next(iter(self.val_dataloader))\n        self.GAN_AB.G.eval()\n        self.GAN_BA.G.eval()\n        \n        #real image of VanGogh Style\n        real_A = self.Tensor(imgs[\"A\"].to(device = self.dev))\n        #generated image from VanGogh Style to real picture\n        fake_B = self.GAN_AB.G(real_A)\n        \n        #real image of real picture\n        real_B = self.Tensor(imgs[\"B\"].to(device = self.dev))\n        #generated image from real picture to VanGogh Style\n        fake_A = self.GAN_BA.G(real_B)\n\n        real_A = make_grid(real_A, nrow=5, normalize=True)\n        real_B = make_grid(real_B, nrow=5, normalize=True)\n        fake_A = make_grid(fake_A, nrow=5, normalize=True)\n        fake_B = make_grid(fake_B, nrow=5, normalize=True)\n        \n        image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n        save_image(image_grid, \"images\/%s\/%s.png\" % (opt.dataset_name, batches_done), normalize=False)\n\n    #function to train cycleGAN\n    def train(self):\n        prev_time = time.time()\n        for epoch in range(opt.epoch, opt.n_epochs):\n            for i, batch in enumerate(self.dataloader):\n                real_A = self.Tensor(batch[\"A\"].to(device = self.dev))\n                real_B = self.Tensor(batch[\"B\"].to(device = self.dev))\n\n                valid = torch.ones((real_A.size(0), *self.GAN_AB.D.output_shape),\n                                   device=self.dev, requires_grad=False)\n                fake  = torch.zeros((real_A.size(0), *self.GAN_AB.D.output_shape),\n                                    device=self.dev, requires_grad=False)\n\n                # ------------------\n                #  Train Generators\n                # ------------------\n\n                self.GAN_AB.G.train()\n                self.GAN_BA.G.train()\n                \n                self.optimizer_G.zero_grad()\n\n                # Identity loss, the loss value is used to train the model so that, the type of the given input and the generated remains the same if the given input is on the target type. \n                # for example, GAN_BA.G is the generator to generate image type A. So, when the input type for the GAN_BA.G is A. The expected output is also type A.\n                loss_id_A = self.criterion_identity(\n                    self.GAN_BA.G(real_A), real_A)\n                loss_id_B = self.criterion_identity(\n                    self.GAN_AB.G(real_B), real_B)\n                loss_identity = (loss_id_A + loss_id_B) \/ 2\n\n                # GAN loss, the loss value is used to train the model so that, the generator can generate the targeted type of image from cross type.\n                # for example, GAN_AB.G is the generator to generate image type B. So, when the input type for the GAN_AB.G is A. The expected output is type B.\n                fake_B = self.GAN_AB.G(real_A)\n                loss_GAN_AB = self.criterion_GAN(self.GAN_AB.D(fake_B), valid)\n                fake_A = self.GAN_BA.G(real_B)\n                loss_GAN_BA = self.criterion_GAN(self.GAN_BA.D(fake_A), valid)\n\n                loss_GAN = (loss_GAN_AB + loss_GAN_BA) \/ 2\n\n                # Cycle loss, the loss value is used to train the model so that, the generator can generate the targeted type of image from the generated image of the other generator.\n                # for example, GAN_AB.G is the generator to generate image type B. So, when the input type for the GAN_AB.G is the generated image of type A from GAN_BA.G. The expected output is type B.\n                recov_A = self.GAN_BA.G(fake_B)\n                loss_cycle_A = self.criterion_cycle(recov_A, real_A)\n                recov_B = self.GAN_AB.G(fake_A)\n                loss_cycle_B = self.criterion_cycle(recov_B, real_B)\n\n                loss_cycle = (loss_cycle_A + loss_cycle_B) \/ 2\n\n                loss_G = loss_GAN + opt.lambda_cyc * loss_cycle + opt.lambda_id * loss_identity\n\n                loss_G.backward()\n                self.optimizer_G.step()\n\n                # ------------------\n                #  Train Discriminator\n                # ------------------\n\n                loss_D = self.GAN_BA.D.feed(real_A, fake_A, valid, fake)\n                loss_D += self.GAN_AB.D.feed(real_B, fake_B, valid, fake)\n                loss_D \/= 2\n\n                # --------------\n                #  Log Progress\n                # --------------\n\n                batches_done = epoch * len(self.dataloader) + i\n                batches_left = opt.n_epochs * len(self.dataloader) - batches_done\n                time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n                prev_time = time.time()\n                \n                #Output running loss, epoch, batch, and estimation time needed\n                sys.stdout.write(\n                    \"\\r[Epoch %d\/%d] [Batch %d\/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n                    % ( epoch,\n                        opt.n_epochs,\n                        i,\n                        len(self.dataloader),\n                        loss_D.item(),\n                        loss_G.item(),\n                        loss_GAN.item(),\n                        loss_cycle.item(),\n                        loss_identity.item(),\n                        time_left,\n                    )\n                )\n\n                if batches_done % opt.sample_interval == 0:\n                    self.sample_images(batches_done)\n            \n            #update learning rate\n            self.lr_scheduler_G.step()\n            self.lr_scheduler_D_A.step()\n            self.lr_scheduler_D_B.step()\n            \n            #save model\n            if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n                torch.save(self.GAN_AB.G.state_dict(), \"saved_models\/%s\/G_AB_%d.pth\" % (opt.dataset_name, epoch))\n                torch.save(self.GAN_BA.G.state_dict(), \"saved_models\/%s\/G_BA_%d.pth\" % (opt.dataset_name, epoch))\n                torch.save(self.GAN_BA.D.state_dict(), \"saved_models\/%s\/D_A_%d.pth\" % (opt.dataset_name, epoch))\n                torch.save(self.GAN_AB.D.state_dict(), \"saved_models\/%s\/D_B_%d.pth\" % (opt.dataset_name, epoch))\n","16a18332":"model = CycleGAN(opt)","fd32230f":"model.train()","535ce560":"print(torch.cuda.memory_summary())","ba6e657e":"torch.save(model.GAN_AB.G.state_dict(), \"saved_models\/%s\/G_AB_%d.pth\" % (opt.dataset_name, opt.n_epochs))\ntorch.save(model.GAN_BA.G.state_dict(), \"saved_models\/%s\/G_BA_%d.pth\" % (opt.dataset_name, opt.n_epochs))\ntorch.save(model.GAN_BA.D.state_dict(), \"saved_models\/%s\/D_A_%d.pth\" % (opt.dataset_name, opt.n_epochs))\ntorch.save(model.GAN_AB.D.state_dict(), \"saved_models\/%s\/D_B_%d.pth\" % (opt.dataset_name, opt.n_epochs))","bfa2d7af":"for i in range(3):\n    model.sample_images(i)","37aea07c":"import matplotlib.pyplot as plt\n\nPATH = '.\/images\/vangogh2photo\/0.png'\n\nfig = plt.figure(figsize=(100,100))\nplt.axis(False)\nplt.imshow(plt.imread(PATH))","df61a92f":"import matplotlib.pyplot as plt\n\nPATH = '.\/images\/vangogh2photo\/1.png'\n\nfig = plt.figure(figsize=(100,100))\nplt.axis(False)\nplt.imshow(plt.imread(PATH))","766dee54":"import matplotlib.pyplot as plt\n\nPATH = '.\/images\/vangogh2photo\/2.png'\n\nfig = plt.figure(figsize=(100,100))\nplt.axis(False)\nplt.imshow(plt.imread(PATH))","2d5864af":"def sample_images(self, name, imgs):\n    self.GAN_AB.G.eval()\n    self.GAN_BA.G.eval()\n    #real image of real picture\n    if name[-1] == 'B':\n        real_B = self.Tensor(imgs)\n    #generated image from real picture to VanGogh Style\n        fake_A = self.GAN_BA.G(real_B)\n    else:\n    #real image of VanGogh Style\n        real_A = self.Tensor(imgs)\n    #generated image from VanGogh Style to real picture\n        fake_B = self.GAN_AB.G(real_A)\n\n\n\n    if name[-1] == 'B':\n        real_B = make_grid(real_B, nrow=5, normalize=True)\n        fake_A = make_grid(fake_A, nrow=5, normalize=True)\n        image_grid = torch.cat((real_B, fake_A), 1)\n    else:\n        real_A = make_grid(real_A, nrow=5, normalize=True)\n        fake_B = make_grid(fake_B, nrow=5, normalize=True)\n        image_grid = torch.cat((real_A, fake_B), 1)\n\n\n\n\n    save_image(image_grid, \"images\/%s\/%s.png\" % (opt.dataset_name, name), normalize=False)\n","56c21a26":"def getitems(root, l):\n    ret = []\n    for p in l:\n        img = Image.open(root + p)\n        item = transforms.Compose(model.transforms_)(img)\n        ret.append(item.tolist())\n    return ret","e9740c17":"root = \".\/%s\/test\/B\/\" % opt.dataset_name\na = ['2014-09-29 14:26:48.jpg',\n     '2014-08-22 05:17:39.jpg',\n     '2014-08-15 21:42:15.jpg',\n     '2014-12-25 23:42:08.jpg',\n     '2014-08-26 17:39:53.jpg',\n    ]\n\nret = model.Tensor(getitems(root, a))\nprint(ret.shape)\nsample_images(model, 'dropout_all_tanH_B', ret)","b96e5984":"fig = plt.figure(figsize=(50,50))\nplt.imshow(plt.imread('.\/images\/vangogh2photo\/dropout_all_tanH_B.png'))","ec819176":"root = \".\/%s\/test\/A\/\" % opt.dataset_name\na = [\n     '00137.jpg',\n     '00162.jpg',\n     '00196.jpg',\n     '00271.jpg',\n     '00044.jpg'\n    ]\n\nret = model.Tensor(getitems(root, a))\nsample_images(model, 'dropout_all_tanH_A', ret)","e540cc04":"fig = plt.figure(figsize=(50,50))\nplt.imshow(plt.imread('.\/images\/vangogh2photo\/dropout_all_tanH_A.png'))","ddfca86e":"os.chdir('..')","b3bd0ae5":"from IPython.display import FileLink\ndisplay(FileLink(\".\/PyTorch-GAN\/saved_models\/%s\/G_AB_%d.pth\" % (opt.dataset_name, opt.n_epochs)))\ndisplay(FileLink(\".\/PyTorch-GAN\/saved_models\/%s\/G_BA_%d.pth\" % (opt.dataset_name, opt.n_epochs)))\ndisplay(FileLink(\".\/PyTorch-GAN\/saved_models\/%s\/D_A_%d.pth\" % (opt.dataset_name, opt.n_epochs)))\ndisplay(FileLink(\".\/PyTorch-GAN\/saved_models\/%s\/D_B_%d.pth\" % (opt.dataset_name, opt.n_epochs)))","22ff7f1c":"**Load Saved Model**"}}