{"cell_type":{"40f44784":"code","76090e6a":"code","ca9cba49":"code","46022e45":"code","3745a87e":"code","b284c557":"code","8d222f6f":"code","ffa7e270":"code","26b5e1fa":"code","44d8786d":"code","1aa6daee":"code","7c8c84e8":"code","5a707dfe":"code","ea047562":"code","da9960db":"code","6b5fd15f":"code","b82dbc83":"code","63e9a747":"code","25c0f7fb":"code","e5f332f1":"code","ffcc8755":"code","67b1ea95":"code","a5444246":"code","4d663223":"code","aa874f1b":"code","60788b76":"code","3a9eeb8b":"code","96d08a03":"code","07985813":"code","5bec9454":"code","97595543":"code","ed103d65":"code","b5ee9281":"code","a60afd2d":"code","8a53cddd":"code","24893fb1":"code","eea701f6":"code","e4ccd2ef":"code","6041c17f":"code","f1d619ee":"code","ec312e37":"code","d02e6f53":"code","c66658f9":"code","89e35079":"code","3c2117d9":"code","7a3faeee":"code","a1fd6183":"code","c984cb73":"code","9430d164":"markdown","f8928530":"markdown","00882d58":"markdown","70367660":"markdown","f270dbe8":"markdown","779ea76f":"markdown","9705acac":"markdown","edf8efc4":"markdown","7f0ae280":"markdown","23b2625f":"markdown","76fa9563":"markdown","172689e1":"markdown","1cf8fb54":"markdown","003bdfa9":"markdown","8efc5c09":"markdown","d3748eb2":"markdown","791d66ff":"markdown","3aefc448":"markdown","accb2470":"markdown","bb2a75ee":"markdown","3741e5bc":"markdown","b18e9de5":"markdown","4b03f4aa":"markdown","a8352a45":"markdown","eff99c1e":"markdown","0c47242e":"markdown","15fc7b09":"markdown","9892f56f":"markdown","890292c2":"markdown","3922b622":"markdown","279577df":"markdown","ca578481":"markdown","a3b19ae5":"markdown","99cea5ff":"markdown","060609d9":"markdown","9bc0c1fc":"markdown","879d91ec":"markdown","385f6c74":"markdown","6c5c4022":"markdown","f6ae2eaa":"markdown","9dfaba4b":"markdown","19129f46":"markdown","b308bc44":"markdown","17ee033b":"markdown","752cd156":"markdown","b62c1290":"markdown","35474e84":"markdown","c43ff8c6":"markdown"},"source":{"40f44784":"# general libraries\n#import time\nimport numpy as np\nimport pandas as pd\n#import math\nfrom IPython.display import display\n\n# graphing librarires\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom plotly import graph_objects as go\nimport plotly.express as px\n\n# sklearn libraries\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import plot_confusion_matrix\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.utils import shuffle\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\n# keras libraries\nfrom tensorflow import keras\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\nfrom keras.layers import Conv2D, MaxPooling2D\n#from keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.resnet import ResNet50\n\n# boosting models\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n# treat warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n        \n# view tables\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', 120)\npd.set_option('display.width', 500)","76090e6a":"df = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","ca9cba49":"# changing all column names to lowercase, for convenience\ndf.columns = df.columns.str.lower()","46022e45":"display(df.info())\ndisplay(df.head())\ndisplay(df.describe().T)\nprint('Nulls',df.isna().sum().sum())\nprint('Duplicates: ',df.duplicated().sum())","3745a87e":"# additional information regarding the customers and the services they get\nprint('There is a total of {} registered customers.'.format(len(df)))\nprint('{} of them get internet services . This is {:.2f}% of the total customers.'.format(\\\n    df[df['internetservice']!='No']['customerid'].count(),df[df['internetservice']!='No']['customerid'].count()*100\/len(df)))\nprint('There are {} customers who have at least one phone line. They are {:.2f}% of the total customers'.format(\\\n    df[df['phoneservice']=='Yes']['customerid'].count(), df[df['phoneservice']=='Yes']['customerid'].count()*100\/len(df)))","b284c557":"df.loc[df['totalcharges'] == ' ', 'totalcharges'].count()","8d222f6f":"df['totalcharges'] = df['totalcharges'].apply(lambda x: 0 if x==' ' else x)\ndf['totalcharges'] = df['totalcharges'].astype('float32')\ndf['totalcharges'].head()","ffa7e270":"# change to 1, 0 values instead pf yes\/no, then convert types\nfor col in ('partner', 'dependents', 'paperlessbilling', 'phoneservice', 'onlinesecurity','onlinebackup', \\\n            'deviceprotection', 'techsupport', 'streamingtv','streamingmovies'):\n    df[col]= df[col].apply(lambda x: 1 if x=='Yes' else 0).astype('int32')\n    \ndf.head(10)","26b5e1fa":"df.info()","44d8786d":"df['monthlycharges'].hist();","1aa6daee":"# the distribution of the monthly charges is not quite normal, \n# so the main number I will refer to will be the median, rather than the mean\ndf.pivot_table(index='churn', values='monthlycharges', aggfunc='median')","7c8c84e8":"# create two separate datasets for two types of customers: churn and those who stayed\nchurn = df.loc[df['churn']=='Yes']\nstayed = df.loc[df['churn']=='No']\n\n# check the values of monthly charges for both types of customers\nchurn['monthlycharges'].hist(color='r', alpha=0.8, label='Left', figsize=(12,6))\nstayed['monthlycharges'].hist(color='g', alpha=0.2, label='Stayed', range=[20, 120],figsize=(12,6))\nplt.legend();","5a707dfe":"fig, ax = plt.subplots(figsize=(12,6))\nax = sns.lineplot(x='tenure', y='totalcharges', hue='churn', data=df)\nax.set(title='Total charges and Lifetime of customers')\nax.set_xlabel('Tenure')\nax.set_ylabel('Total Charges');","ea047562":"# customers who left: internet services\nfig = go.Figure(data=[go.Pie(labels= churn['internetservice'],  title='Internet Services: customers who left')]) \nfig.show();","da9960db":"# customers who stayed: internet service\nfig = go.Figure(data=[go.Pie(labels= stayed['internetservice'],  title='Internet Services: customers who stayed')]) \nfig.show();","6b5fd15f":"# customers who left\nfig = go.Figure(data=[go.Pie(labels= churn['multiplelines'],  title='Phone lines: customers who left')]) \nfig.show();","b82dbc83":"# customers who stayed\nfig = go.Figure(data=[go.Pie(labels= stayed['multiplelines'],  title='Phone lines: customers who stayed')]) \nfig.show();","63e9a747":"fig, ax = plt.subplots(figsize=(12,6))\nax = sns.stripplot(x='contract', y='tenure', hue='churn', data=df)\nax.set(title='Contract Type and Tenure of customers')\nax.set_xlabel('Contract Type')\nax.set_ylabel('Tenure');","25c0f7fb":"churn['tenure'].hist(color='r', alpha=0.8, label='Left', figsize=(12,6))\nstayed['tenure'].hist(color='g', alpha=0.4, label='Stayed',figsize=(12,6))\nplt.legend();","e5f332f1":"df = df.drop('customerid', axis=1)","ffcc8755":"df.hist(edgecolor='black', linewidth=1.2, figsize=(18,12));","67b1ea95":"df['churn'] = df['churn'].apply(lambda x: 0 if x=='No' else 1)\ntarget = df['churn']\n(target.value_counts(normalize=True)*100).round(2)","a5444246":"# OHE on the categorical columns\ndef OHE_encoding(df):\n    ohe_cols = ['internetservice','gender','paymentmethod', 'multiplelines', 'contract']\n    \n    # OHE encoding\n    data_ohe = pd.get_dummies(df[ohe_cols], drop_first=True)\n    \n    # join the columns and drop the relevant columns\n    features = df.join(data_ohe).drop(['internetservice','gender','paymentmethod', 'multiplelines', 'contract'], axis=1)\n    \n    return features","4d663223":"encoded = OHE_encoding(df)\n\nencoded.head()","aa874f1b":"ax = plt.axes()\nplt.gcf().set_size_inches(3,10)\nsns.heatmap(encoded.corr()[['churn']].sort_values('churn', ascending=False), cmap='Blues', annot=True)\nax.set_title('Features Correlations')\n\nplt.show();","60788b76":"features = encoded.drop(['churn'],axis=1)","3a9eeb8b":"features_train, features_test, target_train, target_test = \\\ntrain_test_split(features, target, test_size=0.15, random_state=12345)","96d08a03":"def upsample(features, target, repeat):\n    \n    '''\n    - Takes features_train, target_train and a number for multiplication (repeat).\n    Resamples both sets, features_train and target_train, to include the both:\n    1. the same number of zeros as in the original sets\n    2. the repetition number (repeat) multiplied by the ones in the original sets.\n    - Prints the new shapes of the sets\n    - Returns the new sets: features_upsampled, target_unsampled.\n    '''\n    \n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n\n    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n    \n    print('features_upsampled:',features_upsampled.shape)\n    print('target_upsampled:',target_upsampled.shape)\n    print()\n\n    return features_upsampled, target_upsampled","07985813":"def downsample(features, target, fraction):\n    \n    '''\n    - Takes features_train, target_train and a fraction (float under 1) for multiplication (fraction).\n    Resamples both sets, features_train and target_train, to include both:\n    1. a random sample of zeros in the size of the original zeros in the set multiplied by the given fraction\n    2. the same number of ones as in the original sets.\n    - Prints the new shapes of the sets\n    - Returns the new sets: features_downsampled, target_downsampled.\n    '''\n        \n    features_zeros = features[target == 0]\n    features_ones = features[target == 1]\n    target_zeros = target[target == 0]\n    target_ones = target[target == 1]\n\n    features_downsampled = pd.concat(\n        [features_zeros.sample(frac=fraction, random_state=12345)]\n        + [features_ones])\n    \n    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n\n    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n    \n    print('features_downsampled:',features_downsampled.shape)\n    print('target_downsampled:',target_downsampled.shape)\n    print()\n\n    return features_downsampled, target_downsampled","5bec9454":"# a function that gets parameters and train the model via gridsearch to find the best parameters and best score\ndef train_model(model, params, X, Y, X_test, Y_test, models, names, model_name):\n    \n    '''\n    Takes: \n    - a specific model\n    - a specific dictionary of hyper-parameters for this model\n    - features_train\n    - target_train\n    - features_test\n    - target test\n    - a set of models\n    - a set of names\n    - the specific model's name\n    Creates: \n    - a pipeline to run the model through\n    - a cross-validation model that runs the pipeline\n    Sends parameters to the following functions:\n    - a function that saves the desired scores for the model (model_scores)\n    - a function that displays the most important features for this model (feature_importance)\n    Prints:\n    - best parameters for the models\n    - best roc auc score for the train set\n   '''\n    \n    # defining the pipeline\n    pipeline = Pipeline([('scale', StandardScaler()), ('model', model) ])\n    \n    # use gridsearchCV for cross validation\n    grid = GridSearchCV(pipeline, param_grid=params, cv=5, scoring=['roc_auc','accuracy', 'f1'], refit='roc_auc')\n    grid.fit(X,Y)\n    \n    # display best score on train\n    print('Best roc auc score (on train set):',grid.best_score_)\n    \n    # display scores\n    model_scores(grid, X_test,  models, Y_test, names, model_name)\n    \n    # display features importances\n    feature_importances(X, grid)\n       \n    # display best parameters\n    print('Best parameters:\\n',grid.best_params_)\n    print()","97595543":"# create sets to store information added about the models\nmodels = {'roc auc': [], 'accuracy': [], 'f1': [], 'TP': [], 'TN':[], 'FP':[], 'FN':[]}\nnames = []","ed103d65":"def model_scores(model, X_test, models, Y_test, names, model_name):\n    \n    '''\n    Takes:\n    - a specific model\n    - features_test\n    - a set of models\n    - target_test\n    - a set of names of models\n    - the name of specific model\n    Creates:\n    - predictions usig predict_proba, for the roc auc score\n    - predicition using predict method for the other scores\n    Appends:\n    - the set of models with three scores for the model\n    - the set of models names with the current model's name\n    Sends:\n    - parameters to the function that displays the confusion matrix of the model and it's roc curve (cm_roc_auc_curve)\n    - if the model does not have a cunfusion matrix of a roc curve, the function skips this action    \n    '''\n    \n    # for the roc auc score we need to use predict proba\n    predictions = model.predict_proba(X_test)[:,1]\n    # for accuracy and f1 we will use predict, as usual\n    preds = model.predict(X_test)\n    \n    # collects scores to the dataset\n    models['roc auc'].append(roc_auc_score(Y_test, predictions))\n    models['accuracy'].append(accuracy_score(Y_test, preds))\n    models['f1'].append(f1_score(Y_test, preds))\n    \n    # add the model's name to the above table\n    names.append(model_name)\n    \n    # send to the function that displays confusion matrix and the roc curve\n    try:\n        cm_roc_auc_curve(model, X_test, Y_test, preds, models, names)\n    except:\n        print()","b5ee9281":"# print confusion matix + roc auc curve\ndef cm_roc_auc_curve(model, X_test, y_test, predictions, models, names):\n    \n    '''\n    Takes:\n    - the specific model run by the GrdSearchCV\n    - features_test\n    - target_test\n    - the roc auc predictions\n    - the set of models, updated\n    - the set of models' names, updated\n    Adds to the models set:\n    - the values of the confusion matrix (TP, TN, FP, FN)\n    Displays:\n    - the models set in its current stage (including all the model so far) with their scores and confusion matrix values\n    - a heatmap of the confusion matrix\n    - the roc curve of the current model\n    \n    '''\n    probabilities_one_valid = model.predict_proba(X_test)[:, 1]\n    fpr, tpr, thresholds = roc_curve(y_test, probabilities_one_valid)\n    cm = confusion_matrix(y_test, predictions, labels=[1,0])\n    \n    # add information about tp,tn,fp,fn\n    models['TP'].append(cm[0,0])\n    models['TN'].append(cm[1,1])\n    models['FP'].append(cm[0,1])\n    models['FN'].append(cm[1,0])\n    \n    # sort the table\n    models = pd.DataFrame(models, index=names).sort_values('roc auc', ascending=False)\n    \n    # display the scores of the all the models we have so far\n    display(models)\n    \n    # plot confusion matrix\n    plot_confusion_matrix(model,X_test,y_test)\n    \n    # roc auc curve\n    plt.figure()\n    plt.plot(fpr, tpr)\n    plt.plot([0, 1], [0, 1], linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve for the model')\n    plt.show()","a60afd2d":"def feature_importances(X, model):\n    \n    '''\n    Takes:\n    - features_train\n    - a specific model that was run through GridSearchCV\n    Tries:\n    - to display the 3 most important features of the model\n    - If it's unable to do so, it prints a message telling that the model does not have the method of features importance\n    '''\n    \n    try:\n        feature_importance = pd.DataFrame({'features':X.columns,'importance':model.best_estimator_._final_estimator.feature_importances_})\n        print(feature_importance.sort_values('importance',ascending=False).head(3))\n        print()\n        \n    except:\n        try:\n            feature_importance=pd.DataFrame({'feature':list(X.columns),'importance':[abs(i) for i in model.best_estimator_._final_estimator.coef_[0]]})\n            print(feature_importance.sort_values('importance',ascending=False).head(3))\n            print()\n\n        except:\n            print('This model does not have a feature importance attribute')      ","8a53cddd":"# define hyper parameters for the model\nclf_param = {'model__strategy': ['most_frequent', 'stratified', 'uniform']}\n\n# run the model \nprint('Running Dummy Classifier without balancing the data')\ntrain_model(DummyClassifier(),clf_param,features_train, target_train, features_test, target_test, models, \\\n             names ,'Dummy Model: imbalanced')","24893fb1":"# define hyper parameters for the model\nlr_param = {'model__penalty': ['l2', 'elasticnet'], 'model__solver':['saga'],'model__l1_ratio':[0.05,0.1,0.2]}\n\n# run the model\nprint('Running Logistic Regression without balancing the data')\ntrain_model(LogisticRegression(random_state=12345,), lr_param, features_train, target_train, features_test, target_test,\\\n        models, names ,'Logistic Regression: imbalanced')\n\nprint('Running LR with balancing with class weight parameter')\n# X = features_train[['monthlycharges','lifetime','totalcharges','internetservice_No','internetservice_Fiber optic','type_Two year']]\ntrain_model(LogisticRegression(random_state=12345, class_weight = 'balanced'), lr_param, features_train, target_train,\\\n         features_test, target_test, models, names ,'Logistic Regression: balanced')","eea701f6":"# define hyper parameters for the model\ndt_param = {'model__max_depth' : [4,6,8],'model__min_samples_split' : [100,120,150],\\\n                'model__min_samples_leaf': [6,8,10], 'model__criterion': ['gini', 'entropy']}\n\n# run the model\nprint('Running Decision Tree without balancing the data')\ntrain_model(DecisionTreeClassifier(random_state=12345), dt_param, features_train, target_train, features_test,\\\n         target_test, models,names ,'Decision Tree: imbalanced')\n\nprint('Running DT with balancing with class weight parameter')\ntrain_model(DecisionTreeClassifier(random_state=12345, class_weight='balanced'), dt_param, features_train , target_train, \\\n         features_test, target_test, models, names,'Decision Tree: balanced')","e4ccd2ef":"# define hyper parameters for the model\nrf_param = {'model__max_depth' : [4,5,6], 'model__n_estimators' : [120,135,175], 'model__min_samples_split':[2,4,6]}\n\n# run the model\nprint('Running Random Forest without balancing the data')\ntrain_model(RandomForestClassifier(random_state=12345, criterion='entropy'), rf_param, features_train, target_train, features_test, target_test,\\\n         models, names ,'Random Forest: imbalanced')\n\nprint('Running RF with balancing with class weight parameter')\ntrain_model(RandomForestClassifier(random_state=12345, criterion='entropy', class_weight = 'balanced'), rf_param, features_train, target_train,\\\n             features_test, target_test, models, names ,'Random Forest: balanced')","6041c17f":"# define hyper parameters for the model\ngb_param = {'model__max_depth' : [2,4,6], 'model__n_estimators': [80,150,230] }\n\n# run the model\nprint('Running Gradient Boosting without balancing the data (note that this model has no parameter that deals with imbalance)')\ntrain_model(GradientBoostingClassifier(random_state=42), gb_param, features_train, target_train, features_test, \\\n             target_test,models, names ,'Gradient Boosting: imbalanced')","f1d619ee":"# define hyper parameters for the model\nxgb_param = {'model__max_depth' : [2,4,6],'model__learning_rate': [0.01,0.05,0.1],\\\n                 'model__n_estimators': [150,250,280], 'model__booster':['gbtree', 'gblinear','dart']}\n\n#spq = calculating the value of total negative observations divided by total positive observations\nspw = (lambda x: x[0]\/x[1])(target.value_counts())\n\n# run the model\nprint('Running XGBoost without balancing the data')\ntrain_model(XGBClassifier(random_state=12345, verbosity = 0), xgb_param, features_train, target_train, features_test,\\\n             target_test, models, names ,'XGBoost: imbalanced')\n\nprint('Running XGBoost with scale_pos_weight parameter')\ntrain_model(XGBClassifier(random_state=12345, verbosity = 0, scale_pos_weight= spw), xgb_param, \\\n          features_train, target_train, features_test, target_test, models, names ,'XGBoost: balanced')","ec312e37":"# define hyper parameters for the model\ncb_param = {'model__depth' : [1,2,3], 'model__iterations': [310,320,330], 'model__learning_rate':[0.05,0.08,0.1]\\\n                , 'model__reg_lambda':[0.05, 0.08, 0.1]} \n\n# run the model\nprint('Running CatBoost without balancing the data')\ntrain_model(CatBoostClassifier(random_seed = 42, verbose=0, eval_metric='AUC'), cb_param, features_train, target_train, \\\n             features_test, target_test, models, names ,'CatBoostB: imbalanced')\n\nprint('Running CatBoost with balancing with class weight parameter')\ntrain_model(CatBoostClassifier(random_seed = 42, verbose=0, scale_pos_weight= spw), cb_param, features_train, \\\n         target_train, features_test, target_test, models, names ,'CatBoost: balanced')","d02e6f53":"# scaling the features\nscaler = MinMaxScaler()\nX = scaler.fit_transform(features_train)\nX_test = scaler.transform(features_test)","c66658f9":"# building the neural network\nmodel = Sequential()\nmodel.add(Dense(16, input_dim=(X.shape[1]), activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n# compiling the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n\n# fit model\nmodel.fit(features_train, target_train, validation_data=(X_test, target_test), epochs=100, batch_size = 10, verbose=None)\nmodel.summary()\n\npredictions = model.predict(X_test)","89e35079":"# add scores to the models datarame\nmodels['roc auc'].append(roc_auc_score(target_test, predictions))\nmodels['accuracy'].append('--')\nmodels['f1'].append('--')\nmodels['TP'].append('--')\nmodels['TN'].append('--')\nmodels['FP'].append('--')\nmodels['FN'].append('--')\n\n\nnames.append('Neural Networks: imbalanced')\nmodels = pd.DataFrame(models, index=names).sort_values('roc auc', ascending=False)\ndisplay(models)","3c2117d9":"features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n\nmodel = CatBoostClassifier(random_seed = 42, verbose=0, eval_metric='AUC', depth= 1, iterations= 330, learning_rate= 0.08, reg_lambda= 0.1)\nfit = model.fit(features_upsampled, target_upsampled)\npreds = fit.predict_proba(features_test)[:,1]\nprint('ROC AUC on CatBoost with balancing with upsampling: ',roc_auc_score(target_test,preds))","7a3faeee":"features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)\n\nmodel = CatBoostClassifier(random_seed = 42, verbose=0, eval_metric='AUC', depth= 1, iterations= 330, learning_rate= 0.08, reg_lambda= 0.1)\nfit = model.fit(features_downsampled, target_downsampled)\npreds = fit.predict_proba(features_test)[:,1]\nprint('ROC AUC on CatBoost with balancing with downsampling: ',roc_auc_score(target_test,preds))","a1fd6183":"fig = px.bar(models['roc auc'].sort_values(), orientation='h', title='The ROC AUC Scores of the Models',\\\n             labels={'variable':'ROC AUC Score',  'index': 'Model'})\nfig.show()","c984cb73":"display(models)","9430d164":"#### Downsampling<a class=\"anchor\" id=\"2_1_7_2\"><\/a>","f8928530":"- The only features that have some correlation to the target are internetservice of fiber optic, which makes sense because it's an expensive product.<br>\n- And payment method of electronic check, which seems random, unless it is a complicated paying method that annoys customers.<br>\n- All the other features are not worth mentioning, wrt to their correlation with the target.","00882d58":"## Change columns types<a class=\"anchor\" id=\"1_4\"><\/a>\nColumns that need a type conversion:<br>\n- Totalcharges - it's an object and not numeric. We should check why.<br>\n- All binary columns - other than the target column - will get the values 0,1 for No\/Yes respectively (the columns are: <i>partner, dependents, phoneservice, onlinesecurity, onlinebackup, deviceprotection, techsupport, streamingtv, streamingmovies, paperlessbilling<\/i>).<br>\n- The columns <i>Internetservice<\/i> and <i>gender<\/i> are also binary, but the values are not Yes\/No. Hence, I will add these columns to the list of columns to encode by OHE method. Those columns include: <i>multiplelines, contract, paymentmethod<\/i>.<br>","70367660":"## Training the models<a class=\"anchor\" id=\"2_2\"><\/a>\nIn all the models, other than the neural networks one, I will use GridSearchCV for tuning the hyperparameters. I will use a pipeline, and scale the data from the pipeline to avoid data leakage.<br>\n### Train the Model<a class=\"anchor\" id=\"2_2_1\"><\/a>","f270dbe8":"### How long have they been in the company?<a class=\"anchor\" id=\"1_5_6\"><\/a>","779ea76f":"## Boosting models<a class=\"anchor\" id=\"2_5\"><\/a>\n### Gradient Boosting<a class=\"anchor\" id=\"2_5_1\"><\/a>","9705acac":"### Display correlation between features and the target<a class=\"anchor\" id=\"2_1_5\"><\/a>","edf8efc4":"## Read Files<a class=\"anchor\" id=\"1_2\"><\/a>","7f0ae280":"## Try the best model (CatBoost) with Upsampling and Downsampling<a class=\"anchor\" id=\"2_7\"><\/a>\n### Upsampling<a class=\"anchor\" id=\"2_7_1\"><\/a>","23b2625f":"## Graph Scores<a class=\"anchor\" id=\"2_8\"><\/a>","76fa9563":"# Exploratory Data Analysis<a class=\"anchor\" id=\"1\"><\/a>\n## Import Libraries<a class=\"anchor\" id=\"1_1\"><\/a>","172689e1":"### Phone Lines<a class=\"anchor\" id=\"1_5_4\"><\/a>","1cf8fb54":"### LogisticRegression<a class=\"anchor\" id=\"2_3_2\"><\/a>","003bdfa9":"## Display Data<a class=\"anchor\" id=\"1_3\"><\/a>","8efc5c09":"- 91% of churn customers had a phone service<br>\n- 45% of these customers had multiple lines.<br>\n- 90% of the customers who stayed have a phone service.<br>\n- 49% of these customers had multiple lines.","d3748eb2":"### Binary Columns<a class=\"anchor\" id=\"1_4_2\"><\/a>","791d66ff":"### Downsampling<a class=\"anchor\" id=\"2_7_2\"><\/a>","3aefc448":"## Neural Networks<a class=\"anchor\" id=\"2_6\"><\/a>","accb2470":"- In the bar plot we can see that the main difference between the two groups, is that in the churn group there are less customers with monthly bills of 20-30. This means that more customers in this group have higher monthly bills, relative to the group of customers who stayed in the company. So indeed, it may be the case of high prices that made them leave the company.","bb2a75ee":"### Feature Importance<a class=\"anchor\" id=\"2_2_4\"><\/a>","3741e5bc":"- In this graph we see more significantly how the total charges of the churn customers increase with time. Despite two \"falls\" in the total charges, there are more jumps in the numbers of the churn customers. Their line is more linear.<br>\n- As opposed to them, the customers who stayed show an increase of total charges with time, but the increase is less linear than with the other group.","b18e9de5":"### Contract Type and Tenure<a class=\"anchor\" id=\"1_5_5\"><\/a>","4b03f4aa":"### Monthly charges<a class=\"anchor\" id=\"1_5_1\"><\/a>","a8352a45":"### Display Scores<a class=\"anchor\" id=\"2_2_2\"><\/a>","eff99c1e":"### Total charges and customers' tenure<a class=\"anchor\" id=\"1_5_2\"><\/a>\n- The total charges of the groups of customers who stayed is higher than those of the churn customers. However, the total charges don't tell us much without any indication of the customers lifetime. Therefore, we should check what are the total charges relative to the customers' lifetime.","0c47242e":"### Dealing with imbalanced data<a class=\"anchor\" id=\"2_1_7\"><\/a>\n#### Upsampling<a class=\"anchor\" id=\"2_1_7_1\"><\/a>","15fc7b09":"### Separating the target column<a class=\"anchor\" id=\"2_1_3\"><\/a>","9892f56f":"### CatBoost<a class=\"anchor\" id=\"2_5_3\"><\/a>","890292c2":"## Baseline models<a class=\"anchor\" id=\"2_3\"><\/a>\n### Dummy Model<a class=\"anchor\" id=\"2_3_1\"><\/a>","3922b622":"### Random Forest<a class=\"anchor\" id=\"2_4_2\"><\/a>","279577df":"- Here it is easy to see that the average tenure of churned customers' is much shorter than the tenure of customers who stayed.<br>\n- The range of months is 0-75, and most of the churned customers were in the range of 0-25.<br>\n- This may add the factor of loyalty to the company (actively or passively), which differentiates the two groups. As we saw in the plot of the contract type.","ca578481":"- Upsampling gave a better score than the downsampling. However, the CatBoost model gave a better score without balancing, and even better when balancing with <i>scale_pos_weight<\/i> parameter.","a3b19ae5":"## Analysis of the Data<a class=\"anchor\" id=\"1_5\"><\/a>\nWe will check out the behavior of both types of customers, those who left and those who stayed, regarding the following:\n* What is the their average monthly charges?<br>\n* What is the their average total charges?<br>\n - How  are the total charges related to the customers' tenure?<br>\n* Do they have internet service?<br>\n* Do they have phone service?<br>\n - Do they have multiple lines?<br>\n* What kind of a contract do they have?<br>\n* How long have they been in the company?<br>","99cea5ff":"### Internet Service<a class=\"anchor\" id=\"1_5_3\"><\/a>","060609d9":"### Features Histogram<a class=\"anchor\" id=\"2_1_2\"><\/a>","9bc0c1fc":"- In general, we see more churn customers in the month to month column: more than in other columns, and more than the customers who stayed in the company<br>\n- As to the Tenure, in the one and two year contract columns, there more customers who stayed with longer tenures: relative to churn customer, relative to the month to month column, and relative to the number of customers in these columns who have a shorter lifetime<br>\n- This means again that churn customers were more month to month customers, and with shorter lifetimes in the company<br>\n- Churn customers who happen to be in a one or two year contract have a longer lifetime than those in month to month.","879d91ec":"With the customers who stayed, the division is more equal.<br>\n- 73% of these customers had internet<br>\n- 35% of these customers had fiber optic, and 38% had DSL<br>\n- So more DSL than fiber optic, even though the numbers are close<br>\n- We can assume, carefully, given that the median monthly charges of churn customers is higher than that of the other group, that internet is a relatively exepnsive service. Moreover, since the churn customers have much more fiber optic internet service, we can assume that this specific technology is more expensive than DSL.","385f6c74":"### Splitting the Data<a class=\"anchor\" id=\"2_1_6\"><\/a>","6c5c4022":"## Tree models<a class=\"anchor\" id=\"2_4\"><\/a>\n### Decision Tree<a class=\"anchor\" id=\"2_4_1\"><\/a>","f6ae2eaa":"### Totalcharges<a class=\"anchor\" id=\"1_4_1\"><\/a>","9dfaba4b":"### EDA conclusions:<a class=\"anchor\" id=\"1_5_7\"><\/a>\n- The median monthly charge is 79.65 for churned customers and 64.42 for those who stayed.<Br>\n- Internet service: most of the churned customers had internet service. Only 6% of them did not have this service. 70% of all churned customers had fiber optic.<br>\n- The majority of churned customers had a month to month contract.<br>\n- The majority of churned customers were at the company for less than a year.","19129f46":"# Conclusions<a class=\"anchor\" id=\"3\"><\/a>\n1. When we ran the models, we saw that the most common important features were <i>contract_Two year<\/i>, <i>tenure<\/i>, and <i>internetservice_Fiber optic<\/i> (their order changed between models). This confirms our EDA conclusions: the churned customers paid more, had more internet service, and mostly fiber optic technology. In addition, these customers  were less comitted to the company, as indicated by their preference of a month to month contract.<br>\nHowever, the EDA conclusions, and the features importances, contradict the correlation heatmap, where we saw that none of the features was highly correlated with the target. Also, the contract type was ranked very low.<br>\n\n2. For some models, the balanced data gave better results than the imbalanced data. In other models, like in the CatBoost model that resulted with the highest roc auc score, the imbalanced data gave better results. This can explain why resampling the data didn't result in higher scores than the imbalanced data.<br>\n\n3. Our main metric is ROC AUC. The roc auc curve balances these two measurements:<br>\n$$TPR = TP :  (TP + FN)$$<br>\n$$FPR = FP : (TN + FP)$$\n\nThe goal is to have a high TPR (axis y) and a low FPR (axis x). Hence, we want TP to be as great as possible, for a high TPR, and the FP to be as small as possible, for a low FPR. We want the curve to be as far as possible from the linear line, that begins at the (0,0) point.\n\nWe would expect the CatBoost model with the balanced data, which resulted with the best roc auc score, to have the best TP and FP rates. However, it does not have the best rates in any of the measurements. So maybe the best model for our purpose should actually be the RandomForest one, with the imbalanced data. It has a fairly high roc auc score, and the best FN rate. This means that the model hardly fails to predict which customers are likely to churn.","b308bc44":"### Encoding categorical features using OHE<a class=\"anchor\" id=\"2_1_4\"><\/a>","17ee033b":"#### Adding class_weight \/ scale_pos_weight parameter to models with this parameter<a class=\"anchor\" id=\"2_1_7_3\"><\/a>\n- Parameter <i>class_weight<\/i> exists in most the sklearn models.<br>\n- Parameter <i>scale_pos_weight<\/i> exists in other bossting models.","752cd156":"### Confusion Matrix and ROC Curve<a class=\"anchor\" id=\"2_2_3\"><\/a>","b62c1290":"- 94% of the customers who left had internet.<br>\n- 69% used fiber optic internet<br>\n- 25% of them had DSL<br>\n- Only 6% of them did not have internet services.<br>","35474e84":"# ML Models<a class=\"anchor\" id=\"2\"><\/a>\n- Note that the data is <b>imbalanced (the target column has 73% of customers who stayed, vs. 27% who left)<\/b>.<br>\n- I will deal with the imbalance soon, in order to be able to use the ROC AUC score for the models.<br>\n- I could have taken a deeper care of the outliers, especially in the tenure column. However, I would like to suggest another approach: use data of the last 5 years only. We see that the end dates are only in the last 4 months (relative to February 2020). We don't have data about customers who left before. In addition to that, most of the churn customers enrolled recently (in the last 10 months). Their behavior has nothing to do with what happened a long time ago.<br>\n- I will suggest to limit the data to years 2015 on.\n\n## Preprocessing<a class=\"anchor\" id=\"2_1\"><\/a>\n### Dropping 'customerid' feature<a class=\"anchor\" id=\"2_1_1\"><\/a>","c43ff8c6":"### XGBoost<a class=\"anchor\" id=\"2_5_2\"><\/a>"}}