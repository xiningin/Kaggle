{"cell_type":{"1eff37be":"code","4b5df085":"code","8ef4992f":"code","21a680b6":"code","1cd1199d":"code","a8b8a47e":"code","350ffe3a":"code","505113b6":"code","21ed4e23":"code","100f345e":"code","26382c7f":"code","cb452820":"code","9c5ddc5c":"code","67b86bcd":"code","4521106a":"code","f11c4b79":"code","90e1bc43":"code","7785c0d7":"code","57979cac":"code","187d95cc":"code","649ad11d":"code","b66d99ab":"code","c24d1370":"code","ced002c5":"code","752c891e":"code","f345db6f":"code","2cca9bea":"code","20611bc3":"code","aa6e761d":"code","568816ee":"code","5483a5fd":"code","76ededec":"code","5c546158":"code","a18b52b3":"code","cd4adfe7":"code","4973c14c":"code","17ba47eb":"code","776b8a57":"code","e57aed1c":"code","89fc604b":"code","25b4a98a":"code","ee32fe47":"markdown","cb11b99e":"markdown","c8565fa9":"markdown","51fcd5d1":"markdown"},"source":{"1eff37be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b5df085":"# Importando os dados\ntrain = pd.read_csv('\/kaggle\/input\/big-mart-sales-prediction-datasets\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/big-mart-sales-prediction-datasets\/test.csv')\ntest2 = test.copy()\ntrain.shape, test.shape","8ef4992f":"# Verificando os tipos\ntrain.info()","21a680b6":"# Verificando valores \u00fanicos em cada coluna\ntrain.nunique()","1cd1199d":"# Verificando os valores nulos\ntrain.isna().sum()","a8b8a47e":"test.isna().sum()","350ffe3a":"#Imputando valores das notas a partir da m\u00e9dia\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\nimputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\nimputer.fit(test[['Item_Weight']])\ntest['Item_Weight'] = imputer.transform(test[['Item_Weight']]).ravel()","505113b6":"test.isna().sum()","21ed4e23":"# Analisando a vari\u00e1vel target\ntrain['Item_Outlet_Sales'].describe()","100f345e":"# Item_Fat_Content tem valores em excesso\ntrain['Item_Fat_Content'].unique()","26382c7f":"# Criando um dicion\u00e1rio para mapear todos os registros em 'low' ou 'regular'\nitem_fat = {'Low Fat':'low', 'Regular':'regular', 'LF':'low', 'reg':'regular','low fat':'low'}\n\ntrain['Item_Fat_Content'] = train['Item_Fat_Content'].map(item_fat)\ntest['Item_Fat_Content'] = test['Item_Fat_Content'].map(item_fat)\n\n# Verificando\ntrain['Item_Fat_Content'].unique()","cb452820":"# Verificando Outlet_Size\ntrain['Outlet_Size'].unique()","9c5ddc5c":"# Verificando Outlet_Location_Type\ntrain['Outlet_Location_Type'].unique()","67b86bcd":"# Verificando Outlet_Type\ntrain['Outlet_Type'].unique()","4521106a":"# Verificando Item_Type\ntrain['Item_Type'].unique()","f11c4b79":"# Verificando Outlet_Identifier\ntrain['Outlet_Identifier'].unique()","90e1bc43":"# Quantos valores \u00fanicos de Item_Identifier\ntrain['Item_Identifier'].nunique()","7785c0d7":"# As colunas 'Item_Weight' e 'Outlet_Size' possuem valores nulos\n\n# Vamos usar a m\u00e9dia para imputar valores em Item_Weight\ntrain['Item_Weight'].fillna(train['Item_Weight'].mean(), inplace=True)\n\n# Vamos usar a moda para imputar valores em Outlet_Size\ntrain['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0], inplace=True)","57979cac":"# Precisamos codificar as vari\u00e1veis categ\u00f3ricas\ntrain.dtypes","187d95cc":"test.columns","649ad11d":"test.dtypes","b66d99ab":"# Vamos codificar as colunas categ\u00f3ricas usando one hot encoding\ncat_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n\ntrain = pd.get_dummies(train, columns=cat_cols)\ntest = pd.get_dummies(test, columns=cat_cols)\n\ntrain.shape","c24d1370":"from pandas.plotting import scatter_matrix\nlista_numerico = ['Item_Weight','Item_Visibility','Item_MRP','Item_Outlet_Sales']\nscatter_matrix(train[lista_numerico], figsize=(12,8))","ced002c5":"# Verificando as colunas\ntrain.info()","752c891e":"# Separando o dataframe\nfrom sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(train, random_state=42)\n\ntrain.shape, valid.shape","f345db6f":"# Obtendo as colunas para treinamento\nfeatures = [c for c in train.columns if c not in ['Item_Identifier', 'Item_Outlet_Sales']]\n\nfeatures","2cca9bea":"#MODELO 1 - Random Forest Regressor\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf_padrao = RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)\n\nrf_padrao.fit(train[features], train['Item_Outlet_Sales'])","20611bc3":"# Obtendo os valores de predi\u00e7\u00e3o\npreds_rf = rf_padrao.predict(valid[features])","aa6e761d":"# Calculando a m\u00e9trica\nfrom sklearn.metrics import mean_squared_error\n\nrmse_rf = mean_squared_error(valid['Item_Outlet_Sales'], preds_rf, squared=False)\n\nrmse_rf","568816ee":"#Fazendo previs\u00e3o dos dados de teste\npreds_rf = rf_padrao.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_rf = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_rf['Item_Outlet_Sales'] = preds_rf\ndf_rf = df_rf.set_index('Item_Identifier')\ndf_rf.to_csv('predict_rf.csv')\n\n#Your score for this submission is : 1216.9112751262633.","5483a5fd":"#MODELO 2 GRADIENTE BOOSTING REGRESSOR\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Executando o modelo\ngbr_padrao = GradientBoostingRegressor(n_estimators=200, random_state=42)\n\ngbr_padrao.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_gbr = gbr_padrao.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_gbr = mean_squared_error(valid['Item_Outlet_Sales'], preds_gbr, squared=False)\n\nrmse_gbr","76ededec":"#Fazendo previs\u00e3o dos dados de teste\npreds_gbr = gbr_padrao.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_gbr = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_gbr['Item_Outlet_Sales'] = preds_gbr\ndf_gbr['Item_Outlet_Sales'] = df_gbr['Item_Outlet_Sales'].abs()\ndf_gbr = df_gbr.set_index('Item_Identifier')\ndf_gbr.to_csv('predict_gbr.csv')\n\n#Your score for this submission is : 1159.1857291211495.","5c546158":"#MODELO 3 - ADA BOOST\n\nfrom sklearn.ensemble import AdaBoostRegressor\n\n# Executando o modelo\nada_padrao = AdaBoostRegressor(n_estimators=200, random_state=42)\n\nada_padrao.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_ada = ada_padrao.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_ada = mean_squared_error(valid['Item_Outlet_Sales'], preds_ada, squared=False)\n\nrmse_ada","a18b52b3":"#Fazendo previs\u00e3o dos dados de teste\npreds_ada = ada_padrao.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_ada = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_ada['Item_Outlet_Sales'] = preds_ada\ndf_ada = df_ada.set_index('Item_Identifier')\ndf_ada.to_csv('predict_ada.csv')\n\n#Your score for this submission is : 1274.4715496142203.","cd4adfe7":"#MODELO 4 XGBOOST\n\nfrom xgboost import XGBRegressor\n\nxgb = XGBRegressor(n_estimators=200, learning_rate=0.01, random_state=42, use_label_encoder=True)\nxgb.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_xgb = xgb.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_xgb = mean_squared_error(valid['Item_Outlet_Sales'], preds_xgb, squared=False)\n\nrmse_xgb","4973c14c":"#Fazendo previs\u00e3o dos dados de teste\npreds_xgb = xgb.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_xgb = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_xgb['Item_Outlet_Sales'] = preds_xgb\ndf_xgb = df_xgb.set_index('Item_Identifier')\ndf_xgb.to_csv('predict_xgb.csv')\n\n#Your score for this submission is : 1210.7015987804687.","17ba47eb":"#MODELO 5 CATBOOST\n\nfrom catboost import CatBoostRegressor\n\ncbc = CatBoostRegressor(random_state=42)\ncbc.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_cbc = cbc.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_cbc = mean_squared_error(valid['Item_Outlet_Sales'], preds_cbc, squared=False)\n\nrmse_cbc","776b8a57":"#Fazendo previs\u00e3o dos dados de teste\npreds_cbc = cbc.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_cbc = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_cbc['Item_Outlet_Sales'] = preds_cbc\ndf_cbc['Item_Outlet_Sales'] = df_cbc['Item_Outlet_Sales'].abs()\ndf_cbc = df_cbc.set_index('Item_Identifier')\ndf_cbc.to_csv('predict_cbc.csv')\n\n#Your score for this submission is : 1178.8013859348143.","e57aed1c":"# Usaremos o VotingRegressor\nfrom sklearn.ensemble import VotingRegressor","89fc604b":"# Definindo nossos estimadores\nestimators = [('rf_padrao', rf_padrao),('gbm_padrao',gbm_padrao),('ada_padrao', ada_padrao),('xgb',xgb),('cbc',cbc)]\n\n# Criando o VotingRegressor\nensemble1 = VotingRegressor(estimators=estimators, n_jobs=-1)\n\nensemble1.fit(train[features], train['Item_Outlet_Sales'])\n\n# Obtendo os valores de predi\u00e7\u00e3o\npreds_ens = ensemble1.predict(valid[features])\n\n# Calculando a m\u00e9trica\nrmse_ens = mean_squared_error(valid['Item_Outlet_Sales'], preds_ens, squared=False)\n\nrmse_ens","25b4a98a":"#Fazendo previs\u00e3o dos dados de teste\npreds_ens = ensemble1.predict(test[features])\n\n#Exporta CSV para submiss\u00e3o\ndf_ens = test2[['Item_Identifier','Outlet_Identifier']].copy()\ndf_ens['Item_Outlet_Sales'] = preds_ens\ndf_ens = df_ens.set_index('Item_Identifier')\ndf_ens.to_csv('predict_ens.csv')\n\n#Your score for this submission is : 1165.5169672609384.","ee32fe47":"# Criando nosso pr\u00f3prio Ensemble de M\u00e9todos","cb11b99e":"## Tratamento de Dados","c8565fa9":"# IESB - CIA035 - Aula 07 - Ensemble de Modelos\n\n## Dados\nhttps:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-big-mart-sales-iii\/","51fcd5d1":"## Modelo inicial"}}