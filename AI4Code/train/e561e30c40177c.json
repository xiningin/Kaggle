{"cell_type":{"1793927e":"code","43f3426c":"code","138b8cf7":"code","c1ba77e6":"code","687555a2":"code","1ef3ba51":"code","17cf3de0":"code","e2d71ad9":"code","3cfc6766":"code","09595069":"code","b53f5a19":"code","f2a3a419":"code","ea4914e6":"code","ea7c14a1":"code","f7f2cc96":"code","db6d9452":"code","473a9ad3":"code","b2273f6d":"code","56878779":"code","da314c8d":"code","36129869":"code","e9fdc919":"code","4f1d7fb2":"code","e3b8a9ff":"markdown","d7ddd844":"markdown","07cb11ca":"markdown","fe64182c":"markdown","a55779cc":"markdown","d23b97a9":"markdown","b685984e":"markdown","8a786d20":"markdown","e0dc4cfc":"markdown","2a34a0cc":"markdown","810edc5f":"markdown","4ca19746":"markdown","6a483894":"markdown","788b51eb":"markdown","339b5a26":"markdown","6aad1fc3":"markdown","772ba731":"markdown"},"source":{"1793927e":"import time\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","43f3426c":"SEED = 1234\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","138b8cf7":"df = pd.read_csv('..\/input\/the-bread-basket\/bread basket.csv')\nprint(\"The shape of df: \", df.shape)\ndf.head()","c1ba77e6":"print(\"The number of unique transactions: \", df['Transaction'].nunique())","687555a2":"df['dataset'] = 'train'\ndf.loc[df['Transaction'].isin(df['Transaction'].unique()[-1000:]), 'dataset'] = 'test'\ndf.loc[df['Transaction'].isin(df['Transaction'].unique()[-2000:-1000]), 'dataset'] = 'valid'\n\nprint(\"The number of train transactions: \", df.loc[df['dataset'] == 'train', 'Transaction'].nunique())\nprint(\"The number of validation transactions: \", df.loc[df['dataset'] == 'valid', 'Transaction'].nunique())\nprint(\"The number of test transactions: \", df.loc[df['dataset'] == 'test', 'Transaction'].nunique())","1ef3ba51":"label_encoder = pd.Categorical(df['Item'])\nlabel_encoder = {k: v for v, k in enumerate(label_encoder.categories)}\ndf['Item_encoded'] = df['Item'].apply(lambda x: label_encoder[x])","17cf3de0":"class BasketDataset(Dataset):\n    def __init__(self, df, dim_input, mode):\n        super(BasketDataset, self).__init__()\n        self.df = df\n        self.dim_input = dim_input\n        self.mode = mode\n        self.indices = df['Transaction'].unique()\n        \n    def __len__(self):\n        return len(self.indices)\n        \n    def __getitem__(self, index):\n        transaction_id = self.indices[index]\n        items = df.loc[df['Transaction'] == transaction_id, 'Item_encoded'].values\n        \n        X = torch.zeros(self.dim_input, dtype=torch.float32)\n        y = torch.zeros(self.dim_input, dtype=torch.float32)\n        X[items] = 1\n        y[items] = 1\n        \n        return X, y\n        ","e2d71ad9":"class Encoder(nn.Module):\n    def __init__(self, dim_input, dim_latent, dropout):\n        super(Encoder, self).__init__()\n        self.latent_layer = nn.Linear(dim_input, dim_latent)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        x = self.latent_layer(x)\n        x = torch.sigmoid(x)\n        x = self.dropout(x)\n        return x\n    \nclass Decoder(nn.Module):\n    def __init__(self, dim_output, dim_latent):\n        super(Decoder, self).__init__()\n        self.output_layer = nn.Linear(dim_latent, dim_output)\n        \n    def forward(self, x):\n        x = self.output_layer(x)\n        x = torch.sigmoid(x)\n        return x\n    \nclass AutoEncoder(nn.Module):\n    def __init__(self, dim_input, dim_latent, dropout):\n        super(AutoEncoder, self).__init__()\n        self.encoder = Encoder(dim_input, dim_latent, dropout)\n        self.decoder = Decoder(dim_input, dim_latent)\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n","3cfc6766":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.value = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    \n    def update(self, value, n):\n        self.value = value\n        self.sum += value * n\n        self.count += n\n        self.avg = self.sum \/ self.count","09595069":"class Fitter:\n    def __init__(self, model, lr, n_epochs):\n        self.model = model\n        self.lr = lr\n        self.n_epochs = n_epochs\n        \n        \n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model.to(self.device)\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        self.criterion = torch.nn.BCELoss()\n        \n        self.best_summary_loss = 10 ** 5\n        \n    def fit(self, train_loader, valid_loader):\n        for epoch in range(self.n_epochs):\n            # Train\n            t = time.time()\n            summary_loss = self.train_one_epoch(train_loader)\n            print(\n                f'\\rEpoch:{epoch + 1}\/{self.n_epochs} | ' +\n                f'Train loss: {summary_loss.avg:.7f} | ' +\n                f'Elapsed time: {time.time() - t:.3f} |'\n            )\n            \n            # Evaluation\n            t = time.time()\n            summary_loss = self.evaluate(valid_loader)\n            print(\n                f'\\rEpoch:{epoch + 1}\/{self.n_epochs} | ' +\n                f'Validation loss: {summary_loss.avg:.7f} | ' +\n                f'Elapsed time: {time.time() - t:.3f}'\n            )\n        # End for (n_epochs)\n        \n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = AverageMeter()\n        t = time.time()\n        \n        for step, (X, y) in enumerate(train_loader):\n            print(\n                f'Train step: {step + 1}\/{len(train_loader)} | ' +\n                f'Summary loss: {summary_loss.avg:.7f} | ' +\n                f'Time: {time.time() - t:.3f} |', end='\\r'\n            )\n            X = X.to(self.device)\n            y = y.to(self.device)\n            batch_size = X.shape[0]\n            \n            self.optimizer.zero_grad()\n            output = self.model(X)\n            loss = self.criterion(output, y)\n            loss.backward()\n            summary_loss.update(loss.detach().item(), batch_size)\n            self.optimizer.step()\n        # End for (one epoch)\n        return summary_loss\n        \n    def evaluate(self, valid_loader):\n        self.model.eval()\n        summary_loss = AverageMeter()\n        t = time.time()\n        \n        with torch.no_grad():\n            for step, (X, y) in enumerate(valid_loader):\n                print(\n                    f'Valid step: {step + 1}\/{len(valid_loader)} | ' +\n                    f'Summary loss: {summary_loss.avg:.7f} | ' + \n                    f'Time: {time.time() - t:.3f} |', end='\\r'\n                )\n\n                X = X.to(self.device)\n                y = y.to(self.device)\n                batch_size = X.shape[0]\n\n                self.optimizer.zero_grad()\n                output = self.model(X)\n                loss = self.criterion(output, y)\n                summary_loss.update(loss.detach().item(), batch_size)\n            # End for (One epoch)\n        # End with (validataion)\n        return summary_loss","b53f5a19":"DIM_INPUT = 94 # The number of unique items\nDIM_LATENT = 64 # The number of nodes of the latent layer\nBATCH_SIZE = 16\nDROPOUT = 0.1\nLR = 0.001\nN_EPOCHS = 10","f2a3a419":"train_dataset = BasketDataset(df=df[df['dataset'] == 'train'],\n                              dim_input=DIM_INPUT,\n                              mode='train')\nvalid_dataset = BasketDataset(df=df[df['dataset'] == 'valid'],\n                              dim_input=DIM_INPUT,\n                              mode='train')\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=True,\n                          drop_last=True)\n\nvalid_loader = DataLoader(valid_dataset,\n                          batch_size=BATCH_SIZE,\n                          shuffle=False,\n                          drop_last=False)","ea4914e6":"model = AutoEncoder(DIM_INPUT, DIM_LATENT, DROPOUT)","ea7c14a1":"fitter = Fitter(model, LR, N_EPOCHS)","f7f2cc96":"fitter.fit(train_loader, valid_loader)","db6d9452":"label_decoder = {v: k for k, v in label_encoder.items()}","473a9ad3":"test_dataset = BasketDataset(df=df[df['dataset'] == 'test'],\n                              dim_input=DIM_INPUT,\n                              mode='test')","b2273f6d":"sample_id = 707\n\nX, y = test_dataset[sample_id]\n\nprint([label_decoder[item.item()] for item in torch.where(X == 1)[0]])","56878779":"X_denoised = X.clone()\nX_denoised[torch.where(X == 1)[0][-1]] = 0\n\nbasket = [label_decoder[item.item()] for item in torch.where(X_denoised == 1)[0]]\nprint(basket)","da314c8d":"device = torch.device('cpu')\nmodel.to(device)\nmodel.eval()\n\noutput = model(X_denoised).detach().numpy()\nTopK = np.argsort(-output)[:10]\n\nprint([label_decoder[item] for item in TopK if label_decoder[item] not in basket])","36129869":"sample_id = 700\n\nX, y = test_dataset[sample_id]\nprint([label_decoder[item.item()] for item in torch.where(X == 1)[0]])","e9fdc919":"X_denoised = X.clone()\nX_denoised[torch.where(X == 1)[0][-1]] = 0\n\nbasket = [label_decoder[item.item()] for item in torch.where(X_denoised == 1)[0]]\nprint(basket)","4f1d7fb2":"device = torch.device('cpu')\nmodel.to(device)\nmodel.eval()\n\noutput = model(X_denoised).detach().numpy()\nTopK = np.argsort(-output)[:10]\n\nprint([label_decoder[item] for item in TopK if label_decoder[item] not in basket])","e3b8a9ff":"- Among the model's output, `Spanish Brunch` has the maximum logit value, except for the items tht are already in the basket.\n- That is, our model recommends `Spanish Brunch` to the customer.","d7ddd844":"## Split data into train, validation and test\n- There are 9,465 transactions\n- For this kind of data, we shouldn't split data randomly because we want to predict \"future\" transactions when \"past\" transactions are given.\n- Let's use the last 1,000 transactions as test data and last 1,000 transaction of remaining transactions as validation","07cb11ca":"## Create `torch.nn.Dataset`\n- Honestly, it is not necessary to make `torch.nn.Dataset` for small dataset. (But, I'm sure it is worth using it!)","fe64182c":"- (optional) It is helpful to print `label_encoder` for understanding\n\n~~~python\nprint(label_encoder)\n~~~","a55779cc":"- (optional, but necessary) You will see that our losses are very small. Why? There are many zeros in our target `y`, so that if our model predicts all values as 0 the average of losses go to 0. We can alleviate this problem by providing different weights to 0 and 1. To this end, we should make our own loss function.\n\n~~~python\ndef weighted_binary_cross_entropy(output, target, weights=None):\n    '''\n    code from https:\/\/discuss.pytorch.org\/t\/solved-class-weight-for-bceloss\/3114\/2\n    '''    \n    if weights is not None:\n        assert len(weights) == 2\n        \n        loss = weights[1] * (target * torch.log(output)) + \\\n               weights[0] * ((1 - target) * torch.log(1 - output))\n        \n    else:\n        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n\n    return torch.neg(torch.mean(loss))\n~~~","d23b97a9":"- (optional) Print `X` and `y` generated by BasketDataset\n\n~~~python\ndataset = BasketDataset(df=df[df['dataset'] == 'train'],\n                        dim=94,\n                        mode='train')\n\nX, y = dataset[0]\nprint('X: ', X)\nprint('y: ', y)\n~~~","b685984e":"## Recommend items for given basket\n- I will show you some good results.\n- Note that actually our model is not good because of the following:\n    - Since almost all customers buy only 1~2 items, then our model cannot learn latent space enough.\n    - It tends to recommend popular items such as `bread` or `coffee` (due to data imbalance)","8a786d20":"- (optional) To the best of my knowledge, the original AutoEncoder shares weights of encoder and decoder, which called `Tied AutoEncoder`. Build  `TiedAutoEncoder` and compare it's performance with AutoEncoder (Honestly, I don't know how to implement `TiedAutoEncoder`T_T).","e0dc4cfc":"## To do\n- Visualize the latent space of items. Are they clustered properly? \n- Try the Denoising AutoEncoder that masks some items of an input, but still have to reconsturct the original input. For example, let's assumt an input $X$ has items `['Coffee', 'Drinking chocolate spoons ', 'Juice', 'Mineral water', 'Salad', 'Sandwich']`. The input and output of AutoEncoder are $X$ itself. However, the Denoising AutoEncoder has to reconstruct $X$ for the given denoised input $X_{\\text{denoised}}$ whose some items are masked, for example $X_{\\text{denoised}}$=`['Coffee', 'Juice', 'Salad', 'Sandwich']`. Denoising AutoEncoder provides more robust model.","2a34a0cc":"## AutoEncoder\n- I use a very simple AutoEncoder, that is, it has only one hidden layer.\n- Dropout is used to only Encoder.\n- Activation functions of Encoder and Decoder are sigmoid.\n- It sounds like very poor model, but it is very powerful !","810edc5f":"- Let's take a look the 707th transaction in the test data.","4ca19746":"## Let's train our model\n- Define `BasketDataset` and pass it through `torch.nn.DataLoader`\n- Define our `AutoEncoder` model\n- Combine and train our model and data loader","6a483894":"In this notebook, I will present how a simple AutoEncoder recommends the next item for the given basket. I chose this dataset for this tutorial because the dataset is small enough to implement our recommendation system quickly.\n\n### Before start\n- First of all, I really appreciate [@Aditya Mittal](https:\/\/www.kaggle.com\/mittalvasu95) providing this dataset.\n- I am sorry for my poor English in advance.","788b51eb":"## Apply label encoding to `Item`\n- There are many ways to implement label-encoding. Among them, I use `pandas.Categorical`","339b5a26":"## Fitter\n- Next, we will make a class that trains, evaluates, and predicts for given model and data loaders.\n- Let's make a helper class storing and averaging the losses first.","6aad1fc3":"- Let's assume the customer picks from `Bread` to `Salad` only. Then our model can recommend `Spanish Brunch`?\n- To this end, create `X_denoised` basket that has no `Spanish Brunch`","772ba731":"- The 700th transaction in the test data"}}