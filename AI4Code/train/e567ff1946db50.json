{"cell_type":{"a5d4f9ae":"code","bb75005e":"code","1b560c6b":"code","b6e37951":"code","1726b196":"code","9a645efc":"code","4b39ae69":"code","f133df94":"code","2127368d":"code","2ab69f51":"code","5b686e56":"code","1bdfd5c8":"code","bfce0213":"code","da75f96c":"code","588377dc":"code","20a14b66":"code","46336f59":"code","0003e94d":"code","4c812b5a":"code","d0b7bf7d":"code","a8f50546":"code","d4f149c1":"code","0d8400ea":"code","778af47c":"code","87c8bf88":"code","40b483fb":"code","a423c618":"code","9375e128":"code","95c6a1e4":"code","391e3cc0":"code","60beee44":"code","a2f59915":"markdown","53bb66cf":"markdown"},"source":{"a5d4f9ae":"import pandas as pd\nimport numpy as np\ndata = pd.read_csv(\"..\/input\/musk-dataset\/musk_csv.csv\")\ndata.head()","bb75005e":"data.describe()","1b560c6b":"data.isnull().sum()","b6e37951":"releation = data.corr().abs()","1726b196":"releation","9a645efc":"corr_matrix = data.corr().abs()\n\n# upper triangle of correlation matrix\nupper_traingle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.93\ndrop = [column for column in upper_traingle.columns if any(upper_traingle[column] > 0.92)]","4b39ae69":"df = data.drop(columns = drop)\ndf.shape","f133df94":"def normlize(data):\n    for col in data.columns[3:127]:\n        data[col] = (data[col]\/max(data[col]))\n    return data\n\ndf_norm = normlize(df)\ndf_norm.head()","2127368d":"datax = df_norm[df_norm.columns[3:127]].to_numpy()\ndatay = df_norm[df_norm.columns[-1]].to_numpy()\nprint(datax.shape,datay.shape)","2ab69f51":"from sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt","5b686e56":"X_train, X_test, y_train, y_test = train_test_split(datax,datay,test_size = 0.20)","1bdfd5c8":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","bfce0213":"x_train = np.reshape(X_train,(X_train.shape[0],19,6,1)).astype('float32')\nx_test= np.reshape(X_test,(X_test.shape[0],19,6,1)).astype('float32')","da75f96c":"print(x_train.shape,x_test.shape)","588377dc":"import keras\ny_train = keras.utils.to_categorical(y_train,num_classes = 2)\ny_test = keras.utils.to_categorical(y_test,num_classes = 2)\nprint(y_train.shape,y_test.shape)","20a14b66":"y_train[5000:5005]","46336f59":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D","0003e94d":"model=Sequential()\nmodel.add(Conv2D(64,kernel_size=(2,2),activation='relu',input_shape=(19,6,1)))\nmodel.add(Conv2D(64,(2,2),activation='relu'))\nmodel.add(Conv2D(64,(2,2),activation='relu'))\nmodel.add(Conv2D(32,(2,2),activation='relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.20))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2,activation='sigmoid'))","4c812b5a":"model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\nmodel.summary()","d0b7bf7d":"history = model.fit(x_train,y_train,batch_size=128,epochs=20,validation_data=(x_test,y_test))","a8f50546":"score=model.evaluate(x_test,y_test,verbose=0)\nprint(score)","d4f149c1":"%matplotlib inline\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.savefig('accuracy.png',dpi = 100)\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.savefig('loss.png',dpi = 100)\nplt.show()","0d8400ea":"from sklearn.metrics import f1_score, precision_score, recall_score","778af47c":"model.predict(x_train[0].reshape(1,19,6,1))\n# model is telling 99.9999% musk and 0.0001% is nonMusk","87c8bf88":"x_test.shape","40b483fb":"yp = model.predict(x_test)\nyp.shape\n","a423c618":"def preprocess(m):\n    a = np.zeros((1320))\n    for i in range(1320):\n        if m[i][0]>m[i][1]:\n            a[i] = 1\n        else:\n            a[i] = 0\n    return a\ny_predict = preprocess(yp)","9375e128":"y_test","95c6a1e4":"# our y_test is in 2d shape\ntest = preprocess(y_test)\nprint(test.shape,y_predict.shape)","391e3cc0":"print(\"f1_score:\",f1_score(test,y_predict))\nprint(\"recall:\",recall_score(test,y_predict))\n\nprint(\"Validation Loss:\",score[0])\nprint(\"Validation Accuracy:\",score[1])","60beee44":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","a2f59915":"we can use PCA also for reducing the features which are less  relevant","53bb66cf":"since data has more features we use cnn to capture the most property of the data\nfor balance of data to cnn we have use 114 to 19 by 6"}}