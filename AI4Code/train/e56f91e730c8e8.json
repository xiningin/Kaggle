{"cell_type":{"0f4a9433":"code","4c95b1e4":"code","83653503":"code","2e84cad6":"code","a73c1292":"code","a69256bf":"code","8e56017e":"code","cf1bd81a":"code","bed1bbf5":"code","f66cea0e":"code","05160bff":"code","f81d4d77":"code","4828b1bf":"code","5352886f":"code","861da303":"code","b551ced2":"code","9af77cbb":"code","ebca85cf":"code","686c645b":"code","491d869d":"code","fe509077":"code","221aea14":"code","e0f86df7":"code","fb890d09":"code","c13222bf":"code","d276dfe8":"code","2e6e426c":"code","507e78c6":"code","15aa2aea":"code","c49ed35e":"markdown"},"source":{"0f4a9433":"import tensorflow as tf\n#tf.debugging.set_log_device_placement(True)\nprint(tf.__version__)\n\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Dense, Dropout","4c95b1e4":"import matplotlib.pyplot as plt","83653503":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2e84cad6":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\npd.options.display.float_format = \"{:.4f}\".format","a73c1292":"print(\"shape:\", df.shape)","a69256bf":"print(\"columns: \", df.columns)","8e56017e":"print(\"info: \", df.info())","cf1bd81a":"print(\"describe: \", df.describe())","bed1bbf5":"print(\"head: \")\nprint(df.head(10))","f66cea0e":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","05160bff":"X = df.iloc[:, 1:].values\nX = sc.fit_transform(X)\nprint(X.shape)\nprint(X[0])","f81d4d77":"n_feature = X.shape[1]\nprint(\"n_feature: \", n_feature)","4828b1bf":"adam = tf.keras.optimizers.Adam(learning_rate=0.0005)\n\ni = Input(shape=(n_feature,))\nx = Dense(64, activation=\"relu\")(i)\nx = Dense(32, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\no = Dense(n_feature)(x)\n\nmodel = Model(i,o)\nmodel.compile(loss=\"mse\", metrics=['accuracy'], optimizer=adam)\nmodel.summary()","5352886f":"callback = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=True\n)\nr = model.fit(X, X, epochs=200, batch_size=2064, verbose=1, validation_split=0.1, callbacks=[callback])","861da303":"results = model.evaluate(X, X, batch_size=5, verbose=1)\nprint(\"Loss: %.2f\" % results[0])\nprint(\"Acc: %.2f\" % results[1])","b551ced2":"print(r.history.keys())\nplt.plot(r.history['loss'])\nplt.plot(r.history['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","9af77cbb":"plt.plot(r.history['accuracy'])\nplt.plot(r.history['val_accuracy'])\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","ebca85cf":"X_pred = model.predict(X)\nmse = np.mean(np.power(X - X_pred, 2), axis=1)\nmse","686c645b":"X_def = pd.DataFrame(X)","491d869d":"X_def['Loss_mae'] = mse","fe509077":"#plt.figure()\nfig, ax = plt.subplots()\nimport seaborn as sns\nsns.set(color_codes=True)\ng = sns.distplot(X_def['Loss_mae'],\n             bins = 1, \n             kde= True,\n            color = 'blue')\ng.set(xlim=(0,0.1),ylim=(0,0.2))","221aea14":"X_def['Loss_mae'].describe()","e0f86df7":"mode_loss = X_def['Loss_mae'].mode()[0]\nprint(\"Mode Loss: \", mode_loss)\nmean_loss = X_def['Loss_mae'].mean()\nprint(\"Mean Loss: \", mean_loss)\ndata_plt = g.get_lines()[0].get_data()\nelbow = np.amax(data_plt[1])\nt_loss_index = np.where(data_plt[1] == elbow)\nt_loss = data_plt[0][t_loss_index][0]\nprint(\"Threshold Loss: \", t_loss)","fb890d09":"X_def['Fraud'] = X_def['Loss_mae'] > t_loss\nX_def['Fraud'] = X_def['Fraud'].apply(lambda x: 1 if x else 0)","c13222bf":"X_def['old_class'] = df['Class']","d276dfe8":"X_def[X_def['Fraud'] != X_def['old_class']].head(50)","2e6e426c":"# predizioni errate classe esistente\nX_def[X_def['old_class'] == 1]['Fraud'].value_counts()","507e78c6":"pd.crosstab(X_def['Fraud'], X_def['old_class'])","15aa2aea":"cm = pd.crosstab(X_def['Fraud'], X_def['old_class'])\ntrue_pos = np.sum(np.diag(cm))\nfalse_pos = cm[0][1]\nfalse_neg = cm[1][0]\n#tot = np.sum(np.sum(cm, axis=0))\nprecision = true_pos \/ (true_pos + false_pos) * 100\nrecall = true_pos \/ (true_pos + false_neg) * 100\nf1 = 2 * (precision * recall) \/ (precision + recall)\nprint(\"Precision: %.3f%%\" % (precision))\nprint(\"Recall: %.3f%%\" % (recall))\nprint(\"F1: %.3f%%\" % (f1))","c49ed35e":"Link: https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud"}}