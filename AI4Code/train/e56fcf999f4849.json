{"cell_type":{"9036c186":"code","2d4c5717":"code","1364692d":"code","a9de15df":"code","c2bd9d94":"code","7fbfc26b":"code","b16f496a":"code","c74b2612":"code","09e206af":"code","30c3c69c":"code","1e39bb21":"code","de848e45":"code","8188162d":"code","85ec4865":"code","57425323":"code","f99fe7e9":"code","9838c50a":"code","9a1dd93e":"code","cce7fd50":"code","af020a2c":"code","0d35a2ee":"code","7f74cf10":"code","9256adea":"code","e092ec1a":"code","3971f93a":"code","e02f2572":"code","021bd9b9":"code","7457c74c":"code","e94d845b":"code","11d69ff0":"code","64b527f9":"code","a0de2e77":"code","4cfeb7b4":"code","2aaf1f54":"code","741dd545":"code","aaed5722":"code","28147f62":"code","8dcef849":"code","205a71bd":"code","8a7d0f99":"code","efb968d0":"code","d0b34d72":"markdown","72903f67":"markdown","436d2735":"markdown","988012c2":"markdown","0c63534e":"markdown","5c270a72":"markdown","05f3e349":"markdown","a60a6ccf":"markdown","05e62903":"markdown","513c6ec1":"markdown","c6fc619a":"markdown","2affc2f0":"markdown","af393196":"markdown","d0ecba36":"markdown","dbe35bc3":"markdown","60c6d720":"markdown","b6b7f48a":"markdown","c35a44da":"markdown","414b7ac3":"markdown","7e3fc659":"markdown","5bd89d9d":"markdown","dfbdb180":"markdown","b0f00c84":"markdown","d66d5b43":"markdown","20f7f80b":"markdown","d5995132":"markdown","5010f151":"markdown","f22dd686":"markdown","26be3ab6":"markdown"},"source":{"9036c186":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d4c5717":"import seaborn as sns\nimport numpy as np","1364692d":"data = pd.read_csv(\"..\/input\/loan-predication\/train_u6lujuX_CVtuZ9i (1).csv\")","a9de15df":"data.head()","c2bd9d94":"data.shape","7fbfc26b":"data.isnull().sum()","b16f496a":"Missing_percentage = (data.isnull().sum()\/data.shape[0])*100\nprint(np.round(Missing_percentage, decimals=2))","c74b2612":"import seaborn as sns\nsns.heatmap(data.isnull(), center=True)","09e206af":"# columns with more than 10 null values\nmore_10nulls_columns = data.columns[(data.isna().sum()>10)]\n#filter data\ndata[more_10nulls_columns]","30c3c69c":"# raws with more than 2 null values - method 1\nindexx = []\nfor i in range(0, data.shape[0]):\n    if (data.iloc[i].isna().sum()>2):\n        indexx.append(i)\ndata.iloc[indexx]","1e39bb21":"# raws with more than 2 null values - method 2\ndata[data.isnull().sum(axis=1)>2]","de848e45":"# 3 most largest\ndata.isnull().sum().nlargest(3)","8188162d":"data[data.isnull().sum(axis=1)>0]","85ec4865":"data[(data.Dependents.isna()) & (data.Married=='No')]","57425323":"data.Dependents[(data.Dependents.isna()) & (data.Married=='No')] = \"NA\"","f99fe7e9":"data.Dependents.unique()","9838c50a":"# drop null values:\ndata.dropna()\n#pros: easy, fast\n#cons: loosing some data\n#if you want to change the dataset permanently:\n#data.dropna(inplace=True)","9a1dd93e":"#based on previous value in the column\ndata.fillna(method='backfill')\n# We do not changed the dataset permanently, in case if you want to change the dataset use inplace=True method\n#pros: fast, easy, no previous knowledge about data\n#cons: altering data ","cce7fd50":"#based on next value in the column\ndata.fillna(method='ffill')","af020a2c":"index_Loan_Null = data.Loan_Amount_Term[data.Loan_Amount_Term.isna()].index\ndata.Loan_Amount_Term[data.Loan_Amount_Term.isna()]","0d35a2ee":"# replace the loan amount with 360\nnewdata = data.Loan_Amount_Term.fillna(value=360) \nnewdata.iloc[index_Loan_Null]","7f74cf10":"# replace with avarage value\nnewdata = data.Loan_Amount_Term.fillna(value=data.Loan_Amount_Term.mean()) \nnewdata.iloc[index_Loan_Null]","9256adea":"# replace with mode value\nnewdata = data.Loan_Amount_Term.fillna(value=data.Loan_Amount_Term.mode().max())\nnewdata.iloc[index_Loan_Null]","e092ec1a":"# replace with min or max value\nnewdata = data.Loan_Amount_Term.fillna(value=data.Loan_Amount_Term.min())  #min,   replace min with max for maximum value\nnewdata.iloc[index_Loan_Null]","3971f93a":"# replace with median value\nnewdata = data.Loan_Amount_Term.fillna(data.Loan_Amount_Term.median())\nnewdata.iloc[index_Loan_Null]","e02f2572":"data.Married.unique()","021bd9b9":"import seaborn as sns\nsns.countplot(data.Married, hue=data.Dependents)","7457c74c":"data.Married[(data.Married.isna()) & (data.Dependents !=0)]","e94d845b":"data.Married[(data.Married.isna()) & (data.Dependents !=0)] = 'No'","11d69ff0":"print(\"we have {} percentage of null values for LoanAmount\".format(round(100*data.LoanAmount.isna().sum()\/data.shape[0], 2)))","64b527f9":"data_ML = data.copy()","a0de2e77":"data_with_missed_loan = data_ML[data_ML.LoanAmount.isna()]\ntest_y = data_with_missed_loan.LoanAmount\ntest_x = data_with_missed_loan[['Married','Education','ApplicantIncome','CoapplicantIncome','Loan_Status']]\ntest_y.shape , test_x.shape","4cfeb7b4":"test_x.head()","2aaf1f54":"import numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\ncategorical_columns = ['Married','Education','Loan_Status']\nfor items in categorical_binary:\n    le = OneHotEncoder(drop=\"first\")\n    t = le.fit_transform(test_x[[items]]).toarray()\n    test_x[items+'_binary']=t\ntest_x = test_x[['ApplicantIncome', 'CoapplicantIncome', 'Married_binary', 'Education_binary','Loan_Status_binary']]\ntest_x.head()","741dd545":"data_ML=data_ML.iloc[data_ML.LoanAmount.dropna().index]","aaed5722":"y = data_ML[['Married','Education','ApplicantIncome','CoapplicantIncome','Loan_Status']]\nX = data_ML.LoanAmount\ny.shape, X.shape\nfor items in categorical_binary:\n    le = OneHotEncoder(drop=\"first\")\n    t = le.fit_transform(y[[items]]).toarray()\n    y[items+'_binary']=t\ny = y[['ApplicantIncome', 'CoapplicantIncome', 'Married_binary', 'Education_binary','Loan_Status_binary']]\ny.head()","28147f62":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n","8dcef849":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=200)\nmodel.fit(y_train, X_train)\npredict = model.predict(y_test)\n\nfrom sklearn.metrics import r2_score\nr2_score(predict, X_test)","205a71bd":"missed_values = model.predict(test_x)\nmissed_values","8a7d0f99":"data.LoanAmount[data.LoanAmount.isna()]=missed_values","efb968d0":"data.LoanAmount.isna().any()","d0b34d72":"#### Drop Null Values","72903f67":"The idea is build a ML classifer\/regression to predict the missed values. To implement this, we should build a model (train model) based on non-null values and then predict the null values:","436d2735":"#### Fill based on previous or next values","988012c2":"Lets predict LoanAmount missing values","0c63534e":"We can divide each raw with the sum of the raws to have a percentage of null values in each raw:","5c270a72":"# <a id='5'> 5. Replace with a Constant Value","05f3e349":"### I am working on this notebook ....","a60a6ccf":"# <a id='2'> 2. Filter Null Values","05e62903":"We want to filter the raws and columns with more than 10 null values:","513c6ec1":"# <a id='7'> 7. Prediction of Null Values Using ML Prediction","c6fc619a":"# <a id='4'> 4. Drop Null Values","2affc2f0":"For example if someone does not married, he\/she may not have dependent. So, 'nan' in dependent means no dependent","af393196":"# <a id='6'> 6. Use Other Columns' Information","d0ecba36":"First, we need to check how many null values do we have in each data set:","dbe35bc3":"To keep the original data set unchanged, I am copying the data set in another variable called \"data_ML\"","60c6d720":"You can optimize the model to get a better accuracy, but we are moving as this is just an example :)","b6b7f48a":"We can also visualize the null values. Black lines are showning the null values in each column","c35a44da":"Now remove the missing values of \"LoanAmount\" column from data_ML:","414b7ac3":"# <a id='3'> 3. Check Null Values:","7e3fc659":"## Content:\n> ### <a href='#1'>1. Load Data, Check Data, Null Values<\/a>\n\n \n> ### <a href='#2'>2. Filter Null Values<\/a> \n \n> ### <a href='#3'>3. Check Null Values<\/a> \n \n> ### <a href='#4'>4. Droping <\/a>\n\n> ### <a href=\"#5\">5. Replace with a Constant Value [median, average, mode, next value, previous value, constant value]<\/a>\n> ### <a href=\"#6\">6. Used Other Columns' Info<\/a>\n\n>### <a href=\"#7\">7. Predict Missing Values Using ML Prediction<\/a>\n","5bd89d9d":"## <a id='1'>1.  Load Data, Check Data, Null Values, etc","dfbdb180":"Lets play with \"Married\" column and try to replace the null values","b0f00c84":"Separate the null values in LeanAmount and name it test_x and test_y:\nI am using columns without a null values to predict LoanAmount","d66d5b43":"Purpose: We want to make sure that the values are missed. Sometimes, null values are not really \"missed\" data. For example, imagine you have \"balcony\" column in a house dataset. If you have no balcony in a house, maybe the corresponding value is left as a blank or \"NAN\". In this case, we know the missing value is \"zero\" not a real null value.\nMaybe the data does not exist at all. For example, size of the balcony in a house dataset where house does not have any balcony!\n\nWhat we need to do? CHECK THE NULL VALUES :)","20f7f80b":"As can be seen from the above graph, if someone does not married, it is less likely to have dependents. Hence, we can say: if married section is null value, and dependent value is zero, most probabley married column is 'No'","d5995132":"#### Replace with specific value","5010f151":"#### Columns with largest null values","f22dd686":"Try KNN and other ML methods as well","26be3ab6":"Lets replace NaN with 'NA' or not applicable"}}