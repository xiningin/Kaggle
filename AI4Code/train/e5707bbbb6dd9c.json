{"cell_type":{"c767dd64":"code","4513e739":"code","1e32cd32":"code","f628282e":"code","6c2bb144":"code","328bd3ef":"code","45320c8b":"code","ef24c0da":"code","bb0658c6":"code","f1cfe1e4":"code","33640a31":"code","bcf6fd08":"code","00b2cb19":"code","412a9c5f":"code","e4dfe190":"code","2f7c35a8":"code","bff26de3":"code","a5c11679":"code","4c5f6473":"code","db2ad129":"code","66e6bc8f":"code","bc1a49f7":"code","dc19cbe5":"code","49a4268a":"code","263f91b1":"code","a57e38f9":"code","4e614b1a":"code","dd23b6f7":"code","5c6cb339":"code","f6513dfd":"code","29c6d5ba":"code","083cb7dc":"code","5da1c98f":"code","a2aedfbd":"code","37465c16":"code","d61cef56":"code","23c9f4c8":"code","ef8ca31e":"markdown","0daf1cb5":"markdown","69d8e887":"markdown","33cf381b":"markdown","9cf980da":"markdown","5067d210":"markdown","cb310306":"markdown","c8ee9b10":"markdown","76e58ff2":"markdown","61cf15f2":"markdown","2c9eef1c":"markdown","62ae9e44":"markdown","6acd4c93":"markdown","8e68b700":"markdown","ecf1b063":"markdown"},"source":{"c767dd64":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nimport seaborn as sns \nimport datetime\nfrom scipy.sparse import csr_matrix, hstack\nfrom scipy.stats import probplot\nimport re\nfrom sklearn.preprocessing import LabelEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\ncolor = sns.color_palette()\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\nsns.palplot(color)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4513e739":"train = pd.read_csv('..\/input\/adams-df\/ADAMS_NLPtask_SS20\/Train.csv')\ntest = pd.read_csv('..\/input\/adams-df\/ADAMS_NLPtask_SS20\/Test.csv')","1e32cd32":"train.head()","f628282e":"test.head()","6c2bb144":"train.dtypes","328bd3ef":"test.dtypes","45320c8b":"#uncomment to see, removed for better readability\n#print(train.title[12], \"\/\/\/\", test.Header[4])","ef24c0da":"#uncomment to see, removed for better readability\n#print(train.text[9], \"\/\/\/\", test.Text[4])#","bb0658c6":"#variables with int \/ float dtype are not exponentially big or small, their size can be reduced\nnum_vars = train.select_dtypes(include=np.float64).columns\ntrain[num_vars] = train[num_vars].astype(np.float32)\n\nnum_vars = train.select_dtypes(include=np.int64).columns\ntrain[num_vars] = train[num_vars].astype(np.int32)","f1cfe1e4":"#compare entries for duplicates,\n#uncomment to see, removed for better readability\n\n#train.text[279572]\n#train.text[279573]","33640a31":"#compare entries for duplicates\nprint(\n    train.title[279574],\n    train.title[279575],\n    train.scrappedDate[279572],\n    train.scrappedDate[279576])","bcf6fd08":"#drop duplicates\ntrain = train.drop_duplicates(subset =['postId','title', 'url'], keep='last')\ntrain.reset_index(drop=True, inplace = True)","00b2cb19":"#create year variable for easy comparison\ntrain['createdDate'] = pd.to_datetime(train['createdDate'])\nyear = []\nfor num in train.createdDate:\n    year.append(num.year)\n    \ntrain['year'] = year\n\ntrain.year.value_counts()","412a9c5f":"train.language.value_counts()","e4dfe190":"#drop articles from before 2015, because they don't have enough entries\ntrain = train[train.year >= 2017]\n\n#drop languages except for english\ntrain = train[train.language == 'en']\n\n#reset indexing\ntrain.reset_index(drop=True, inplace = True)","2f7c35a8":"#make a new column for year in test_df, manual one-hot-encoding \nyear_2017 = []\nfor num in test.PublicationDetails:\n    if num.find('2017') >= 0 :\n        year_2017.append(1)\n    else: \n        year_2017.append(0)\n        \nyear_2018 = []\nfor num in test.PublicationDetails:\n    if num.find('2018') >= 0 :\n        year_2018.append(1)\n    else: \n        year_2018.append(0)\n        \n#add column to df\ntest['year_2017'] = year_2017\ntest['year_2018'] = year_2018\n\ndel year_2017\ndel year_2018\ntest.year_2017.value_counts()\ntest.year_2018.value_counts()","bff26de3":"year_2018 = []\nyear_2017 = []\ncounter = 0\n\n#encode train.year to the same format as test.year\nfor i in train['year']:\n    if i == 2018:\n        year_2018.append(1)\n        year_2017.append(0)\n    else:\n        year_2018.append(0)\n        year_2017.append(1)\n    counter += 1\n    \ntrain['year_2017'] = year_2017\ntrain['year_2018'] = year_2018","a5c11679":"int_list = []\ntest['Responses'] = test['Responses'].astype(str)\nfor i in test['Responses']:\n    if i != 'nan':\n        int_list.append(re.findall(r'\\d+', i))\n    else:\n        #int_list.append([np.nan])\n        int_list.append([0])","4c5f6473":"#Thank you to 'Alex Martelli' [2]\nflat_list = []\ndouble = False\nfor sublist in int_list:\n    double = False\n    for item in sublist:\n        if len(sublist)== 1:\n            flat_list.append(item)\n        else:\n            if double == True:\n                flat_list.append(item)\n            else:\n                double = True\n            ","db2ad129":"test['Responses'] = flat_list\ntest['Responses'] = test['Responses'].astype(float)","66e6bc8f":"#html cleaner still doesn't work 100%\n\ndef cleaning_func(text):\n    #remove line breaks\n    text = text.replace('\\n', ' ').replace('\\r', '')\n    \n    #remove urls\n    text = re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE) #[3]#\n\n    #remove html tags\n    cleanr = re.compile('<.*?>')\n    text = re.sub(cleanr, '', text)\n    return text","bc1a49f7":"test['Text'] = test.Text.apply(cleaning_func) ","dc19cbe5":"train['text'] = train.text.apply(cleaning_func) ","49a4268a":"train.totalClapCount.describe()","263f91b1":"train.boxplot(column = 'totalClapCount');\nplt.title('Target variable')","a57e38f9":"sns.distplot(train['totalClapCount'], hist = False, kde = True, rug = True, norm_hist = True,\n             color = 'darkblue', \n             kde_kws={'linewidth': 1},\n             rug_kws={'color': 'black'})","4e614b1a":"#log transformed target variable\nsns.distplot(np.log1p(train['totalClapCount']), hist = False, kde = True, rug = True, norm_hist = True,\n             color = 'darkblue', \n             kde_kws={'linewidth': 2},\n             rug_kws={'color': 'black'}) ","dd23b6f7":"#map target variable to reduce noise \nmyList = [0, 25, 50, 75, 100, 125, 150, 175, 200, 250, 300, 350, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\nclap = []\nfor i in train['totalClapCount']:\n    if i < 2200:\n        clap.append(min(myList, key=lambda x:abs(x-i)))\n    else:\n        clap.append(i)\n        \ntrain['clap'] = clap","5c6cb339":"train['clap_log'] = np.log1p(train['totalClapCount'])\ntrain['recommends_log'] = np.log1p(train['recommends'])\ntrain['wordCount_log'] = np.log1p(train['wordCount'])\n\n","f6513dfd":"clap_len_scatter = sns.scatterplot(x = \"clap_log\", y = \"wordCount_log\",          \n                                      data = train)","29c6d5ba":"clap_reco_scatter = sns.scatterplot(x = \"clap_log\", y = \"recommends_log\",          \n                                      data = train)","083cb7dc":"train.author.value_counts()","5da1c98f":"test.info()","a2aedfbd":"train['author'] = train['author'].astype('category')\ntest.rename(columns={'Author':'author'}, inplace=True)\ntest['author'] = test['author'].astype('category')","37465c16":"#te = TargetEncoder()\n#X_target_encoded = te.fit(train['author'], train['totalClapCount'], handle_missing='return_nan', handle_unknown='return_nan')\n\n#substitute unknown with mean\n#test['author'] = X_target_encoded.transform(test['author'], y=None, override_return_df=False)\n\n#substitute unknown with nAn\n#test['author'] = X_target_encoded.transform(test['author'], y=None, override_return_df=False, )\n\n#test['author'].value_counts()\n\n#te = TargetEncoder()\n#train['author'] = te.fit_transform(train['author'], train['totalClapCount'])","d61cef56":"train.to_csv('train_processed.csv',index=False)","23c9f4c8":"test.to_csv('test_processed.csv',index=False)","ef8ca31e":"The *Author* variable has too many different categories to use One-Hot-Encoding to make it usable for ML-models. We are using Target Encoding to count every author or publishing entity as a category and assign the average *totalClapCount* for every author. Those averages will be applied to known authors in the test data frame, unknown authors will either be set to the average value of 166 or nan, depending on prediction quality. \n\nAfter achieving a MAE of 40, I realised that the fitted Target Encoder has to be applied to the test dataset, thus the function has to be applied after train-test-splitting.\n\nWhile inspecting the *Author* variable in the test dataset closer, I realized, that there are a lot of entries like \"Netflix Technology Blog\" or entries that provide a date. Due to this reason we cannot expect the same prediction accuracy on the *test* dataset as we achieve on the *train* dataset. One option is to extract the author name from *PublicationDetails*, this would however only provide slightly higher accuracy because there are almost as many incorrect entries. ","0daf1cb5":"# Create output","69d8e887":"If we want to use *Responses* from the test dataset for a numeric model, we have to extract the integer value. For extraction we are searching every string for integers, missing values are substituted with zeros. Because we are recieving a list of lists as output, we have to reduce the dimensionality like shown on Stackoverflow [2].","33cf381b":"The log transformed scatter plot shows some correlation between a high number of claps and recommendations. You can mostly see, that articles with a lot of claps don't have a low *wordCount*. This could be implemented using a conditional statement, however the deviation within the data seems too high for it to be used further. ","9cf980da":"Because the test dataset doesn't include year as a variable, we have to extract the year from *PublicationDetails*. Because the *train* dataset now only contains 2017 and 2018, we will only extract these years from the test dataset. They will be encoded in 1 and 0 as One-Hot-Encoding would do. To make the *train* and *test* data as similar as possible, we will do the same for the *train* dataset. ","5067d210":"The scatter plot visualizes the correlation between the log transformed *totalClapCount* and the log transformed *recommends*. A clear linear correlation is visible. Still, the deviation is quite big. This should be the most usefull variable for predicting high values accurately. \n\n\nIn the following, we will check on how the data is distributed in the *test*-df. We have to extract the year from the *PublicationDetails* variable and *responses* as integer data type.","cb310306":"It would make sense to log-transform the target variable to get a more in-depth insight into the contribution. \nThe distribution plot shows that most of the values are between 0 and 5000. The rugplot shows that there might be enough data up to 7000 claps. \n\nThe log transformed distribution plot indicates almost 50% of the values at zero. After a small peak at 4 claps the probability declines rapidly.\n\n\nAs a try to reduce noise in the target variable, we will map \"totalClapCount\" to fixed values.If it will be used in the final model will be decided by the prediction quality. \nBecause we could not detect any improvement in the prediction accuracy, the mapped *totalClapCounts* will not be used for predictions. The MAE increased between 5-10 claps when using the mapped target variable and different small train and test sets.  ","c8ee9b10":"Comparing the *train* and *test* data frames, it becomes clear, that most of the variables in the *train* data frame cannot be used, because they are not available in the *test* df. \n\nFor NLP, the main variable will be the text data provided in the *text* variable. We will also take a look at processing the *title\/Header* text to make predictions. *responsesCreatedCount* in the train-df and responses in the test-df both seem to show how many comments were made for an article. This can be confirmed when taking a look at the actual website. This should be a rally important variable for numeric predictions.\n\nAuthors are given in both data frames and can thus be used as a variable.\n\nThe variable *PublicationDetails* in the test-df can be used to extract the publication data, which is provided in the train-df. It could also be used to extract the publishing entity, which is provided in the *train* data frame as *publicationname*.\n\nAs a final numeric variable, *Length* in the test-df should correlate to *wordCount* in the train-df. \n\n*Test[2]* is listing the *length* as 402 but the article has a reading time of 19min, so we have to assume, that some of the length data is not correct. There is also a lot of text missing for this article [1]. \n\n*Test[47]* and *test[48]* also have text missing. Compared to the original article, we have to assume, that some of the texts are not complete. Because we are going to use a Bert-model for analysing the text and Bert can only use text with a maximum length of 512 (after byte pair encoding), shortened texts should not cause problems. Numeric analysis with the *length* variable can cause problems, though and maybe should not be used, as long as there is no way of detecting a wrong input. We will evaluate this later in correlation to the *totalClapCount*.\n\nLooking at *header* or *keywords* it seems like there are duplicates of some articles. We have to find out how many duplicates there are and have to delete them from the dataset.\n\nLooking at different numeric values one can assume, that 64-bit int and float variables can be scaled down to 32-bit without quality loss.\n\nThe *author* variable in the train-df can likely be combined with numeric data in the same df. For now, this will be seen as an optional task.\n\nFor cleaning and pre-processing we will take a look at how many articles were published per year and what languages are used primarily","76e58ff2":"# Text cleaning\n\nIf we look at some of the texts, we see that there are HTML tags [3], line breaks and some URLs, even though some newer NLP models might be able to work with them, it does always make sense to clean all the data and text as much as possible.","61cf15f2":"Now we will take a look at the numeric variables *recommends* and *wordCount*. *recommends* can be pulled from the *test* dataset. The word count is not available in the *test* dataset. The easiest solution should be counting the words in the test dataset and generating a new variable. But first we should take a look at the correlation between those variables and the target variable.","2c9eef1c":"The average value of the variable is around 169. The boxplot shows that the data is skewed towards low values, this is also shown by the mean (or 50% distribution) with a value of 6. The standard deviation is 1865. All those values indicate, that there are mostly really low values of the varget variable with some few outliners reaching more than 10 to 100 fold the standard deviation.","62ae9e44":"# Bibliography\n\n[1] Daniel Jeffries. Hackernoon (medium.com). The Cryptocurrency Trading Bible. Retrieved 20.8.2020 from https:\/\/medium.com\/hackernoon\/the-cryptocurrency-trading-bible-43d0c57e3fe6\n\n[2]  Alex Martelli. Stackoverflow. How to make a flat list out of list of lists?. Retrieved 20.8.2020 from https:\/\/stackoverflow.com\/questions\/952914\/how-to-make-a-flat-list-out-of-list-of-lists\n\n[3] \"\u2126mega\". Stackoverflow. How to remove any URL within a string in Python. Retrieved 20.8.2020 from https:\/\/stackoverflow.com\/questions\/11331982\/how-to-remove-any-url-within-a-string-in-python","6acd4c93":"# Exploratory data analysis","8e68b700":"# Table of Contents\n\n1. [Data pre-processing](#Data-pre-processing)\n2. [Text cleaning](#Text-cleaning)\n3. [Exploratory data analysis](#Exploratory-data-analysis)\n4. [Create output](#Create-output)\n5. [Bibliography](#Bibliography)\n\nThis notebook will cover pre-processing and EDA to simplify working with the datasets. For a general introduction please take a look at the notebook \"ADAMS_submission\".\n\n\n\n\n\n\n# Data pre-processing\nThe train- and test data is available in CSV-format and will mainly be pre-processed using the *pandas* package. We will take a short look at the datasets to drop most data that is not useful before goint to EDA. ","ecf1b063":"After dropping duplicates, only the years 2018 and 2017 have enough data for training machine learning models, also all languages except for *english* will be dropped, because they will most likely only create noise instead of improving the quality of the ML models. One could assume, that more recent articles have more claps because medium.com might become more popular with time. \n\nBecause the test-data is so small, one could also look through it manually and find out, that out of 514 entries only 2 are non-english. Mainly, for this reason, we will focus on english language models and maybe predict the non-english texts with a different solution like the dataset average. \n\nDepending on the tokenizers, different levels of text cleaning will be required. Bert models do not need much text cleaning, however it will not have a negative impact. "}}