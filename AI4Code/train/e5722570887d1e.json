{"cell_type":{"4def638c":"code","feb652af":"code","f620417a":"code","02bd68a0":"code","5d8c3155":"code","939d285b":"code","aedae872":"code","88db6ee8":"code","c1482356":"code","599340c0":"code","09fab355":"code","91833c62":"code","0dca089a":"code","6ffadcb6":"code","e3ade7b8":"code","93f57b54":"code","42f39526":"code","ea22092e":"markdown","6bce3fdd":"markdown","72dc41cc":"markdown","f44bd19d":"markdown","620e75b8":"markdown","3d8ee670":"markdown","767068d2":"markdown","d31a0d7a":"markdown","7cc305ea":"markdown"},"source":{"4def638c":"import numpy as np\nimport pandas as pd\n\nimport xml.etree.ElementTree as ET\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nimport os\nimport os.path\n\nimport uuid\nimport cv2","feb652af":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models","f620417a":"base_path = '..\/input\/hard-hat-detection\/'\nann_path = base_path + 'annotations\/'\nimg_path = base_path + 'images\/'","02bd68a0":"def get_train_df(ann_path, img_path):\n    def get_file_list(root, file_type):\n        return [os.path.join(directory_path, f) for directory_path, directory_name, \n                files in os.walk(root) for f in files if f.endswith(file_type)]\n    \n    ann_path_list = get_file_list(ann_path, '.xml')\n    ann_list = []\n    \n    for a_path in ann_path_list:\n        root = ET.parse(a_path).getroot()\n        ann = {}\n        \n        ann['uuid']  = uuid.uuid1().int\n        ann['filename'] = Path(str(img_path) + '\/'+ root.find(\".\/filename\").text)\n        \n        # image sizes\n        ann['width'] = root.find(\".\/size\/width\").text\n        ann['height'] = root.find(\".\/size\/height\").text\n        ann['depth'] = root.find(\".\/size\/depth\").text\n        \n        for obj in root.findall('object'):\n            ann['xmin'] = int(obj.find(\"bndbox\").find('xmin').text)\n            ann['ymin'] = int(obj.find(\"bndbox\").find('ymin').text)\n            ann['xmax'] = int(obj.find(\"bndbox\").find('xmax').text)\n            ann['ymax'] = int(obj.find(\"bndbox\").find('ymax').text)\n            \n            ann_list.append(ann)\n        \n    return pd.DataFrame(ann_list)","5d8c3155":"# dataframe train\ndf_train = get_train_df(ann_path, img_path)\nprint(df_train.head())\n\n# uuids from dataframe\nuuids = df_train.uuid.unique()","939d285b":"class Mask_Aide():\n    \n    def bb_to_mask(self, bb, x):\n        row, col, depth = x.shape\n        Y = np.zeros((row, col))\n        bb = bb.astype(np.int)\n        Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n        return Y\n\n    def mask_to_bb(self, Y):\n        col, row = np.nonzero(Y)\n        if len(col) ==  0: return np.zeros(4, dtype=np.float32)\n        top_row, bot_row = np.min(row), np.max(row)\n        left_col, right_col = np.min(col), np.max(col)\n        return np.array([left_col, top_row, right_col, bot_row], dtype=np.float32)\n    \n    def create_corner_rect(self, bb, color='red'):\n        bb = np.array(bb, dtype=np.float32)\n        return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n                             fill=False, lw=3)\n\n    def show_corner_bb(self, im, bb):\n        plt.imshow(im)\n        plt.gca().add_patch(self.create_corner_rect(bb))","aedae872":"mask_aide = Mask_Aide()","88db6ee8":"class Resize():\n    def __init__(self, df, new_path, mask_aide):\n        self.df = df\n        self.train_path_resized = Path(new_path)\n        self.mask_aide = mask_aide\n        self.resize()\n    \n    def read_image(self, path):\n        return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n\n    def create_bb_array(self, x):\n        # [ymin, xmin, ymax, xmax]\n        return np.array([x[6], x[5], x[8], x[7]])\n    \n    def resize_image_bb(self, read_path, write_path, bb, sz):\n        new_size = (int(1.49 * sz), sz)\n        im = self.read_image(read_path)\n\n        im_resized = cv2.resize(im, new_size)\n        Y_resized = cv2.resize(self.mask_aide.bb_to_mask(bb, im), new_size)\n\n        new_path = str(write_path\/read_path.parts[-1])\n        \n        # write only if picture is not resized already\n        file = Path(new_path)\n        if not file.is_file():\n            cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n\n        return new_path, self.mask_aide.mask_to_bb(Y_resized)\n    \n    def resize(self):\n        new_paths = []\n        new_bbs = []\n        \n        for index, row in self.df.iterrows():\n            new_path,new_bb = self.resize_image_bb(row['filename'], self.train_path_resized, self.create_bb_array(row.values),300)\n            new_paths.append(new_path)\n            new_bbs.append(new_bb)\n            \n        self.df['new_path'] = new_paths\n        self.df['new_bb'] = new_bbs","c1482356":"# create temp folder 'images_resized'\n!rm -rf images_resized && mkdir images_resized","599340c0":"resized = Resize(df_train, 'images_resized', mask_aide)\nresized.df.head()","09fab355":"class Augmentation():\n    def __init__(self, mask_aide):\n        self.mask_aide = mask_aide\n    \n    def crop(self, im, r, c, target_r, target_c): \n        return im[r:r+target_r, c:c+target_c]\n\n    def random_crop(self, x, r_pix=8):\n        r, c,*_ = x.shape\n        c_pix = round(r_pix*c\/r)\n        rand_r = random.uniform(0, 1)\n        rand_c = random.uniform(0, 1)\n        start_r = np.floor(2*rand_r*r_pix).astype(int)\n        start_c = np.floor(2*rand_c*c_pix).astype(int)\n        return self.crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n    \n    def center_crop(self, x, r_pix=8):\n        r, c,*_ = x.shape\n        c_pix = round(r_pix*c\/r)\n        return self.crop(x, r_pix, c_pix, r-2*r_pix, c-2*c_pix)\n\n    def random_cropXY(self, x, Y, r_pix=8):\n        r, c,*_ = x.shape\n        c_pix = round(r_pix*c\/r)\n        rand_r = random.uniform(0, 1)\n        rand_c = random.uniform(0, 1)\n        start_r = np.floor(2*rand_r*r_pix).astype(int)\n        start_c = np.floor(2*rand_c*c_pix).astype(int)\n        xx = self.crop(x, start_r, start_c, r-2*r_pix, c-2*c_pix)\n        YY = self.crop(Y, start_r, start_c, r-2*r_pix, c-2*c_pix)\n        return xx, YY\n    \n    def rotate_cv(self, im, deg, y=False, mode=cv2.BORDER_REFLECT, interpolation=cv2.INTER_AREA):\n        r,c,*_ = im.shape\n        M = cv2.getRotationMatrix2D((c\/2,r\/2),deg,1)\n        if y:\n            return cv2.warpAffine(im, M,(c,r), borderMode=cv2.BORDER_CONSTANT)\n        return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n    \n    def transformsXY(self, path, bb, transforms):\n        x = cv2.imread(str(path)).astype(np.float32)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\/255\n        Y = self.mask_aide.bb_to_mask(bb, x)\n        if transforms:\n            rdeg = (np.random.random()-.50)*20\n            x = self.rotate_cv(x, rdeg)\n            Y = self.rotate_cv(Y, rdeg, y=True)\n            if np.random.random() > 0.5: \n                x = np.fliplr(x).copy()\n                Y = np.fliplr(Y).copy()\n            x, Y = self.random_cropXY(x, Y)\n        else:\n            x, Y = self.center_crop(x), self.center_crop(Y)\n        return x, self.mask_aide.mask_to_bb(Y)","91833c62":"augmentations = Augmentation(mask_aide)","0dca089a":"im = cv2.imread(str(df_train.values[100][-2]))\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nmask_aide.show_corner_bb(im, df_train.values[100][-1])","6ffadcb6":"resized.df = resized.df.reset_index()\nfeatures = resized.df[['new_path', 'new_bb']]","e3ade7b8":"X_train, X_test = train_test_split(features, test_size=0.3, random_state=34)","93f57b54":"class SafetyHelmDataset(Dataset):\n    def __init__(self, paths, bb, augmentations, transforms=False):\n        self.transforms = transforms\n        self.paths = paths.values\n        self.bb = bb.values\n        self.augmentations = augmentations\n        \n    def normalize(self, im):\n        imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n        return (im - imagenet_stats[0])\/imagenet_stats[1]\n    \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, idx):\n        path = self.paths[idx]\n        x, y_bb = self.augmentations.transformsXY(path, self.bb[idx], self.transforms)\n        x = self.normalize(x)\n        x = np.rollaxis(x, 2)\n        return x, y_bb","42f39526":"batch_size = 64\n\ntrain_ds = SafetyHelmDataset(X_train['new_path'], X_train['new_bb'], augmentations, transforms=True)\nvalid_ds = SafetyHelmDataset(X_test['new_path'], X_test['new_bb'], augmentations)\n\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)","ea22092e":"# Sample Image","6bce3fdd":"# Safety Helmets Startup Notebook","72dc41cc":"# Mask functions","f44bd19d":"# Safety Helmets Dataset","620e75b8":"# Split DataSet","3d8ee670":"# Resize images & bounding boxes","767068d2":"# Augmentations","d31a0d7a":"# Prepare Data","7cc305ea":"# Summary\n\nWe have the code to :<br>\n- create the helmet pandas Dataset using the XMLs\n- augment the pictures and bounding boxes to have smaller size pictures\/boxes\n- prepare the pytorch Dataset so we can use it to train with different models"}}