{"cell_type":{"401c4faa":"code","d5e1ee07":"code","d4c7a92b":"code","8f6d32e2":"code","e2747b02":"code","f23bcab1":"code","5542f8c2":"code","0a30d4cf":"code","5a5599e5":"code","ab5380f8":"code","b4c3f0e0":"code","8accc58d":"markdown","0f36dbb5":"markdown","dca9c3ee":"markdown","632ff843":"markdown","0556d6c3":"markdown","e7c9f308":"markdown","9ea1d272":"markdown"},"source":{"401c4faa":"import os\nimport pathlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport io\nimport scipy.misc\nimport numpy as np\n\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\nfrom six.moves.urllib.request import urlopen\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub\n\ntf.get_logger().setLevel('ERROR')","d5e1ee07":"def load_image_into_numpy_array(path):\n    \"\"\"Load an image from file into a numpy array.\n    \n      Puts image into numpy array to feed into tensorflow graph.\n      Note that by convention we put it into a numpy array with shape\n      (height, width, channels), where channels=3 for RGB.\n\n      Args:\n        path: the file path to the image\n\n      Returns:\n        uint8 numpy array with shape (img_height, img_width, 3)\n    \"\"\"\n    image = None\n    # if path looks like 'http:abcdefg....'\n    if(path.startswith('http')):\n        response = urlopen(path)\n        image_data = response.read()\n        image_data = BytesIO(image_data)\n        image = Image.open(image_data)\n    # if path doesn't http url...\n    else:\n        image_data = tf.io.gfile.GFile(path, 'rb').read()\n        image = Image.open(BytesIO(image_data))\n        (im_width, im_height) = image.size\n\n    return np.array(image.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)\n\n\nALL_MODELS = {\n'CenterNet HourGlass104 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_512x512\/1',\n'CenterNet HourGlass104 Keypoints 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_512x512_kpts\/1',\n'CenterNet HourGlass104 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_1024x1024\/1',\n'CenterNet HourGlass104 Keypoints 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/hourglass_1024x1024_kpts\/1',\n'CenterNet Resnet50 V1 FPN 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v1_fpn_512x512\/1',\n'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v1_fpn_512x512_kpts\/1',\n'CenterNet Resnet101 V1 FPN 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet101v1_fpn_512x512\/1',\n'CenterNet Resnet50 V2 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v2_512x512\/1',\n'CenterNet Resnet50 V2 Keypoints 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/centernet\/resnet50v2_512x512_kpts\/1',\n'EfficientDet D0 512x512' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d0\/1',\n'EfficientDet D1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d1\/1',\n'EfficientDet D2 768x768' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d2\/1',\n'EfficientDet D3 896x896' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d3\/1',\n'EfficientDet D4 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d4\/1',\n'EfficientDet D5 1280x1280' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d5\/1',\n'EfficientDet D6 1280x1280' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d6\/1',\n'EfficientDet D7 1536x1536' : 'https:\/\/tfhub.dev\/tensorflow\/efficientdet\/d7\/1',\n'SSD MobileNet v2 320x320' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v2\/2',\n'SSD MobileNet V1 FPN 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v1\/fpn_640x640\/1',\n'SSD MobileNet V2 FPNLite 320x320' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v2\/fpnlite_320x320\/1',\n'SSD MobileNet V2 FPNLite 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/ssd_mobilenet_v2\/fpnlite_640x640\/1',\n'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet50_v1_fpn_640x640\/1',\n'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet50_v1_fpn_1024x1024\/1',\n'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet101_v1_fpn_640x640\/1',\n'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet101_v1_fpn_1024x1024\/1',\n'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet152_v1_fpn_640x640\/1',\n'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https:\/\/tfhub.dev\/tensorflow\/retinanet\/resnet152_v1_fpn_1024x1024\/1',\n'Faster R-CNN ResNet50 V1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet50_v1_640x640\/1',\n'Faster R-CNN ResNet50 V1 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet50_v1_1024x1024\/1',\n'Faster R-CNN ResNet50 V1 800x1333' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet50_v1_800x1333\/1',\n'Faster R-CNN ResNet101 V1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet101_v1_640x640\/1',\n'Faster R-CNN ResNet101 V1 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet101_v1_1024x1024\/1',\n'Faster R-CNN ResNet101 V1 800x1333' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet101_v1_800x1333\/1',\n'Faster R-CNN ResNet152 V1 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet152_v1_640x640\/1',\n'Faster R-CNN ResNet152 V1 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet152_v1_1024x1024\/1',\n'Faster R-CNN ResNet152 V1 800x1333' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/resnet152_v1_800x1333\/1',\n'Faster R-CNN Inception ResNet V2 640x640' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/inception_resnet_v2_640x640\/1',\n'Faster R-CNN Inception ResNet V2 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/faster_rcnn\/inception_resnet_v2_1024x1024\/1',\n'Mask R-CNN Inception ResNet V2 1024x1024' : 'https:\/\/tfhub.dev\/tensorflow\/mask_rcnn\/inception_resnet_v2_1024x1024\/1'\n}\n\nIMAGES_FOR_TEST = {\n  'Beach' : 'models\/research\/object_detection\/test_images\/image2.jpg',\n  'Dogs' : 'models\/research\/object_detection\/test_images\/image1.jpg',\n  # By Heiko Gorski, Source: https:\/\/commons.wikimedia.org\/wiki\/File:Naxos_Taverna.jpg\n  'Naxos Taverna' : 'https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/60\/Naxos_Taverna.jpg',\n  # Source: https:\/\/commons.wikimedia.org\/wiki\/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n  'Beatles' : 'https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/1b\/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',\n  # By Am\u00e9rico Toledano, Source: https:\/\/commons.wikimedia.org\/wiki\/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n  'Phones' : 'https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/0d\/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg\/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n  # Source: https:\/\/commons.wikimedia.org\/wiki\/File:The_smaller_British_birds_(8053836633).jpg\n  'Birds' : 'https:\/\/upload.wikimedia.org\/wikipedia\/commons\/0\/09\/The_smaller_British_birds_%288053836633%29.jpg',\n}\n\nCOCO17_HUMAN_POSE_KEYPOINTS = [\n (0, 1),\n (0, 2),\n (1, 3),\n (2, 4),\n (0, 5),\n (0, 6),\n (5, 7),\n (7, 9),\n (6, 8),\n (8, 10),\n (5, 6),\n (5, 11),\n (6, 12),\n (11, 12),\n (11, 13),\n (13, 15),\n (12, 14),\n (14, 16)\n]","d4c7a92b":"!git clone --depth 1 https:\/\/github.com\/tensorflow\/models","8f6d32e2":"%%bash\napt install -y protobuf-compiler\ncd .\/models\/research\nprotoc object_detection\/protos\/*.proto --python_out=.\ncp object_detection\/packages\/tf2\/setup.py .\npython -m pip install .","e2747b02":"from object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.utils import ops as ops_utils\n\nPATH_TO_LABELS = '.\/models\/research\/object_detection\/data\/mscoco_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\nprint(category_index.values())","f23bcab1":"#@title Model Selection { display-mode: \"form\", run: \"auto\" }\nmodel_display_name = 'CenterNet HourGlass104 Keypoints 512x512'\nmodel_handle = ALL_MODELS[model_display_name]\n\nprint('Selected model:'+ model_display_name)\nprint('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n\n# Load model from Tensorflow Hub\nhub_model = hub.load(model_handle)\nif hub_model != None:\n    print('Model loaded with success')","5542f8c2":"selected_image = 'Dogs' # @param ['Beach', 'Dogs', 'Naxos Taverna', 'Beatles', 'Phones', 'Birds']\nflip_image_horizontally = False\nconvert_image_to_grayscale = False\n\nimage_path = IMAGES_FOR_TEST[selected_image]\nprint(image_path)\nimage_np = load_image_into_numpy_array(image_path)\n\n\n## Image preprocessing\nif flip_image_horizontally:\n    image_np[0] = np.fliplr(image_np[0]).copy()\n    \nif convert_image_to_grayscale:\n    image_np[0] = np.tile(np.mean(image_np[0], 2, keepdims=True), (1,1,3)).astype(np.uint8)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np[0])\nplt.show()","0a30d4cf":"print('Doing the inference...')\nresults = hub_model(image_np)\nprint('Complete the inference.')\n\nresult = {key:value.numpy() for key, value in results.items()}\nprint(result.keys())","5a5599e5":"## Dig into result\n\nprint(result['detection_keypoint_scores'])\nprint([category_index[x] for x in result['detection_classes'][0]])","ab5380f8":"label_id_offset = 0\nimage_np_with_detections = image_np.copy()\n\nkeypoints, keypoint_scores = None, None\n\nif 'detection_keypoints' in result:\n    keypoints = result['detection_keypoints'][0]\n    keypoint_scores = result['detection_keypoint_scores'][0]\n\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_detections[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset).astype(int),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.30,\n      agnostic_mode=False,\n      keypoints=keypoints,\n      keypoint_scores=keypoint_scores,\n      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_detections[0])\nplt.show()","b4c3f0e0":"# Handle models with masks:\nimage_np_with_mask = image_np.copy()\n\nif 'detection_masks' in result:\n  # we need to convert np.arrays to tensors\n  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n\n  # Reframe the the bbox mask to the image size.\n  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n            detection_masks, detection_boxes,\n              image_np.shape[1], image_np.shape[2])\n  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n                                      tf.uint8)\n  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_mask[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset).astype(int),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.30,\n      agnostic_mode=False,\n      instance_masks=result.get('detection_masks_reframed', None),\n      line_thickness=8)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_mask[0])\nplt.show()","8accc58d":"# Load utilities","0f36dbb5":"# Build a detection model and load pre-trained model weights","dca9c3ee":"# Install required packages including Visualization Tools","632ff843":"# Loading an image","0556d6c3":"# [Tensorflow Tutorial - Object Detection](https:\/\/github.com\/tensorflow\/hub\/blob\/master\/examples\/colab\/tf2_object_detection.ipynb)","e7c9f308":"# Option","9ea1d272":"# Visualizing the results"}}