{"cell_type":{"82635e68":"code","ff739f7d":"code","2dddb3c3":"code","8b854b7b":"code","c217ab47":"code","5c46a2e4":"code","6a0c8c45":"code","f3c4ab63":"code","debafa60":"code","5ac95c42":"code","4a32be37":"code","5e3bcb22":"code","f5779f3d":"code","0bbf1ae4":"code","3a85ab76":"code","b7979227":"code","3d85364f":"code","fce507a0":"code","40d1c72c":"code","d435282a":"code","40636dc4":"code","f791b79a":"code","12aaff95":"code","690c26fe":"code","71f6bc39":"code","aea4dedc":"code","efd0f5ad":"code","e72298e0":"code","80feccf7":"code","ff9003e3":"code","1926033b":"code","4448736f":"code","5e8c5e96":"code","ff3e4ba8":"code","0a031bdb":"code","2b8ed284":"markdown","2a852281":"markdown","27485b36":"markdown","6f1d8598":"markdown","a27ce5d8":"markdown","03c8d752":"markdown","3a8d5625":"markdown","50177c60":"markdown"},"source":{"82635e68":"import pandas as pd\n# pd.core.common.is_list_like = pd.api.types.is_list_like\nfrom pandas_datareader import data\n#helps in extracting data from included sources.  A very useful tool on pandas\nfrom matplotlib import pyplot as plt\nimport datetime\nimport numpy as np\nprint(f'{np.__version__}: numpy version')\nprint(pd.__version__)\n# print(f'{data.__version__} : pandas_datareader version')","ff739f7d":"# data.DataReader?","2dddb3c3":"#removing SYMC as the data fetched in NAN, look later how to clean the data with SYMC\n\ncompany_dict={\n   'amazon':'AMZN','Apple':'AAPL','Walgreen':'WBA','NOrthrop Grunman':'NOC','Boeing':'BA','Lockhead Martin':'LMT','McDonalds':'MCD',\n    'Intel':'INTC','Navister':'NAV','IBM':'IBM','Texas Instrument':'TXN','Mastercard':'MA','Microsoft':'MSFT','General ELectric':'GE',\n    'Americal express':'AXP','Pepsi':'PEP','Coca Cola':'KO','Jhonson and Jhonson':'JNJ','Toyota':'TM',\n    'Exxon':'XOM','Valero ENgineering':'VLO','Bank of AMerica':'BAC','HOnda':'HMC','Sony':'SNE','Chevren':'CVX','Ford':'F'    \n}\ncompany_dict.items()","8b854b7b":"companies=sorted(company_dict.items(),key=lambda x:x[1])\ncompanies\nprint(len(companies))","c217ab47":"print(list(company_dict.values()),end=\" \")\n# Using print with end=\" \" to get a horizontal list","5c46a2e4":"data_source='yahoo'\nstart_date='2016-01-01'\nend_date='2018-12-31'\n#use pandas_reader.data.DataReader \npanel_data=data.DataReader(list(company_dict.values()),data_source,start_date,end_date)","6a0c8c45":"     #printing axes label \nprint(panel_data.axes)","f3c4ab63":"print(type(panel_data))\npanel_data.info()","debafa60":"panel_data.describe","5ac95c42":"panel_data.columns.to_list()","4a32be37":"#stock open and close data\nstock_close=panel_data['Close']\nstock_open=panel_data['Open']","5e3bcb22":"stock_close.iloc[340]","f5779f3d":"print(stock_close.shape)\nstock_close=np.array(stock_close).T\nprint(stock_close.shape)","0bbf1ae4":"print(stock_open.shape)\nstock_open=np.array(stock_open).T\nprint(stock_open.shape)","3a85ab76":"row,column=stock_open.shape\nrow","b7979227":"print([name for name,id in companies],end=' ')","3d85364f":"print(len(companies))","fce507a0":"#calculating change in price of these stocks during this tenure.\n#defining a placeholder matrix with the dimension of the final matrix \n# movement value will be basically the sum of intraday change for the stock for the tenure considered which is 01-01-2016 till 31-12-2018 in our case\n\nmovements=np.zeros(([row,column]))\nfor i in range (row):\n    movements[i,:]=np.subtract(stock_close[i,:],stock_open[i,:])\nfor i in range(len(companies)):\n    print('company: {}, change:{}'.format(companies[i][0], sum(movements[i][:])))\nprint(movements.shape)\n\nprint(max(movements[4]))","40d1c72c":"#Now since we have the desired data, lets visualize the data  with matplotlib\nplt.clf\nplt.figure(figsize=(18,16))\nax1=plt.subplot(221)\nplt.plot(movements[0][:])\nplt.title(companies[0])\nplt.subplot(222,sharey=ax1)\nplt.plot(movements[1][:])\nplt.title(companies[1])\nplt.show()","d435282a":"from sklearn.preprocessing import Normalizer\nnormalizer=Normalizer()\nnew=normalizer.fit_transform(movements)\nprint(new.max())\nprint(new.min())\nprint(new.mean())","40636dc4":"\nplt.figure(figsize=(18,16))\nax1=plt.subplot(221)\nplt.plot(new[0][:])\nplt.title(companies[0])\nplt.subplot(222,sharey=ax1)\nplt.plot(new[1][:])\nplt.title(companies[1])\nplt.show()","f791b79a":"#Now we are going to make a pipeline and see how it works\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import Normalizer","12aaff95":"normalizer=Normalizer()\n\nkmeans=KMeans(n_clusters=10,max_iter=1000)\n\npipeline=make_pipeline(normalizer,kmeans)\n","690c26fe":"# now lets fit the data to the pipeline\npipeline.fit(movements)\nprint(kmeans.inertia_)\n#Study more about kmeans.inertia_","71f6bc39":"labels=pipeline.predict(movements)\n# print(len(labels))\n# print(len(companies))\ndf=pd.DataFrame({'companies':companies,'labels':labels})\nprint(df.sort_values('labels'))","aea4dedc":"# Now we will apply pca and then apply kmeans on the data with reduced dimension\nfrom sklearn.decomposition import PCA","efd0f5ad":"reduced_data=PCA(n_components=2).fit_transform(new)","e72298e0":"kmeans=KMeans(n_clusters=10)\nmodel=kmeans.fit(reduced_data)\nlabels=model.predict(reduced_data)","80feccf7":"df=pd.DataFrame({'companies':companies,'labels':labels,})\nprint(df.sort_values('labels'))","ff9003e3":"#now we will create a meshgrid using np.mesh \n# step size\nh=0.1\n#plotting the discision boundary\nx_min,x_max=reduced_data[0].min()-1,reduced_data.max()+1\ny_min,y_max=reduced_data[1].min()-1,reduced_data.max()+1\nxx,yy=np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max, h))\n\n","1926033b":"a=np.arange(18).reshape(3,6)\nb=np.arange(0,18,1)\nprint(a)\nprint(b)\nprint(a.ravel(order='A'))","4448736f":"z=kmeans.predict(np.c_[xx.ravel(),yy.ravel()])","5e8c5e96":"print(xx.shape)\nprint(yy.shape)","ff3e4ba8":"#put the result into a color plot\nz=z.reshape(xx.shape)","0a031bdb":"from matplotlib import cm\n\n# define color plot\n\ncmap=plt.cm.Paired\n\n#plotting figure\n\nplt.figure(figsize=(10,10))\nplt.imshow(z,interpolation='nearest',extent=(xx.min(),xx.max(), yy.min(),yy.max()),cmap=cmap, aspect='auto',origin='lower')\nplt.plot(reduced_data[:,0],reduced_data[:,1],'k.',markersize=5)\n\n#plot the centroids of each cluster as  a white x\n\ncentroids=kmeans.cluster_centers_\nplt.scatter(centroids[:,0],centroids[:,1],marker='x',s=169,linewidths=3,color='w',zorder=10)\nplt.title('Kmeans clustering on stock market movements (PCA-reduced data)')\nplt.xlim(x_min,x_max)\nplt.ylim(y_min,y_max)\n\nplt.show()","2b8ed284":"We want to create  **Kmeans ** cluster with 10 clusters.now lets make a pipeline.we are **using make_pipeline** here, only difference with pipeline is that make_pipeline takes the name automatically where in pipeline we need to provide name for the estimator","2a852281":"Lets define some attributes of the data we want to work with and then download it from yahoo.Pandas datareader expects these inputs.For more details pls refer to pandas documentation.","27485b36":"Now we see that the data is comparable. This is very important for our clustering algorithm.","6f1d8598":"We may see the labels changing each time we run the algorithm. But, primarily, we will see that similar companies are mostly grouped together. ","a27ce5d8":"The below graph comparing the stock price movement between apple and amazon is very interesting.\n\n* We see that both the graph varies and have different lavel of stock movements. \n* This is due to the fact that both the prices belong to different lavels. \n* When we normalize the dataset and plot the graph again then we will see that the movements are comparable. \n\n","03c8d752":"This is the most interesting part for me. Plotting a clustered dataset always gives much better graphs. Personally I enoyed plotting this graph and it helped me to sharpen my skills on matplotlib.\n\nI thank to eduonix for some wonderful tutorials","3a8d5625":"# Financial data analysis:(Stock price movement analysis)\n\nIn this notebook, I have tried to demonstrate how we can import financial(stock market) data from an online source and use the data to analyse stock price movement for the included stocks. \n\nWhile learning to do that i came to learn some usefull tools such as pandas_datareader.\n\ndata module from pandas_datareader is a Module that contains tools for collecting data from various remote sources. we are using data.datareader to fetch data from yahoo finance. The Datareader takes the following arguments which can easily be found in the documentation.\n\n* data.DataReader(\n    name,\n    data_source=None,\n    start=None,\n    end=None,\n    retry_count=3,\n    pause=0.1,\n    session=None,\n    api_key=None,\n)\n\n**At the end we will get  the stocks arranged in clusters**\n![index.png](attachment:index.png)(http:\/\/)\n\n","50177c60":"##### Thank you guys for taking time out to go through my notebook. I am at the starting phase of my kaggle journey. Sometimes, there may be mistake and lack of proper explanation.Please pardon me for these. \nThank you again."}}