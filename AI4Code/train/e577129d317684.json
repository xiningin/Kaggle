{"cell_type":{"7f2e0f6a":"code","9c994b16":"code","1cf9fd61":"code","131dc0c9":"code","fc81cd95":"code","e16dd89c":"code","65749f96":"code","c0a38f55":"code","04af097d":"code","15d54747":"code","0751fe1f":"code","bc2832fe":"code","4ab1d14f":"code","212bc84f":"code","4bd1553a":"markdown","80521a32":"markdown","db56235b":"markdown","479d2ca5":"markdown","90e4beab":"markdown","a3b3f12e":"markdown","bf5eb5aa":"markdown","8f12955d":"markdown","8c4a1f07":"markdown","8d93d2b8":"markdown","563cbccc":"markdown","93b00b07":"markdown","65b84588":"markdown","416f567e":"markdown"},"source":{"7f2e0f6a":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_datasets as tfds\n\ndataset, info = tfds.load(\"tf_flowers\", as_supervised = True, with_info = True)\n\n# By setting with_info = True, we get information about our dataset","9c994b16":"info.splits","1cf9fd61":"dataset_size = info.splits[\"train\"].num_examples\nprint(dataset_size)","131dc0c9":"# Let's also checkout number of classes and their names\n\nclass_names = info.features[\"label\"].names\nn_classes = info.features[\"label\"].num_classes\nprint(class_names, n_classes)","fc81cd95":"# We will use TF Datasets API for splitting\n\ntest_set_raw, valid_set_raw, train_set_raw = tfds.load(\n    \"tf_flowers\",\n    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n    as_supervised=True)","e16dd89c":"import matplotlib.pyplot as plt \n\nplt.figure(figsize =(12,10))\nindex = 0\nfor image, label in train_set_raw.take(9):\n    index +=1\n    plt.subplot(3,3, index)\n    plt.imshow(image)\n    plt.title(\"Class: {}\".format(class_names[label]))\n    plt.axis(\"off\")\nplt.show()","65749f96":"def preprocess(image, label):\n    resized_image = tf.image.resize(image,[224,224])\n    final_image = keras.applications.xception.preprocess_input(resized_image)\n    return final_image, label","c0a38f55":"batch_size = 32\ntrain_set = train_set_raw.shuffle(1000)\ntrain_set = train_set.map(preprocess).batch(batch_size).prefetch(1) # Prefetch one batch to make sure that a batch is ready to be served at all time\nvalid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\ntest_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)","04af097d":"base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top = False)\n\n# We will now add our own global average pooling layer followed by a dense output layer with one \n# unit per class using the softmax activation function.\n\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(n_classes, activation = \"softmax\")(avg)\nmodel = keras.Model(inputs = base_model.input, outputs = output)","15d54747":"for index, layer in enumerate(base_model.layers):\n    print(index,layer.name)\n    ","0751fe1f":"for layer in base_model.layers:\n    layer.trainable = False","bc2832fe":"optimizer = keras.optimizers.SGD(lr=0.2, momentum = 0.9, decay = 0.01)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\nhistory = model.fit(train_set, epochs = 10, validation_data = valid_set)","4ab1d14f":"for layer in base_model.layers:\n    layer.trainable = True","212bc84f":"optimizer = keras.optimizers.SGD(lr = 0.01, momentum = 0.9, decay = 0.001)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n              metrics=[\"accuracy\"])\nhistory = model.fit(train_set, epochs = 50, validation_data = valid_set)","4bd1553a":"### We will now apply our preprocess function to all three datasets i.e. train, valid, and test. We'll also shuffle, add batching and prefetch to all datasets.","80521a32":"### Let's first load our flower dataset using Tensorflow Datasets","db56235b":"### Let's visualize some of the images ","479d2ca5":"### As you can see, our model now reached around 92% accuracy on the validation set!!","90e4beab":"### We will now load Xception model, pretrained on ImageNet. By setting include_top = False, we'll exclude the top of the network which includes global average pooling layer and the dense output layer. ","a3b3f12e":"## In this notebook, we will build an image classifier using a pretrained Xception model. We will train our model to classify pictures of flowers","bf5eb5aa":"### Let's also visualize number and type of layers in our Xception CNN","8f12955d":"### Let's now preprocess our images. Xception CNN expects images to be of 224x224 pixels, so we need to resize them.","8c4a1f07":"### As we can see above, we only have training set. Later, we will split it into train, validation and test set but now let's see how many images we have in our dataset","8d93d2b8":"### Time to freeze the weights of the pretrained layers  ","563cbccc":"### After training the model for 10 epochs, the validation accuracy is already about 87%. This does not increase much even if we train for longer epochs. This implies that the top layers of our model are now fully trained. Next, we'll unfreeze all the layers of our base model and continue training. Remember to compile the model !","93b00b07":"### Finally, let's compile and train our model","65b84588":"### Let's now split our training set into 75% for training, 15% for validation and remaining 10% for testing ","416f567e":"#### Ref : https:\/\/github.com\/ageron\/handson-ml2\/blob\/master\/14_deep_computer_vision_with_cnns.ipynb"}}