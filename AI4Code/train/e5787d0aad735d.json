{"cell_type":{"1b7251b5":"code","aaf9c430":"code","eba57f04":"code","2311d867":"code","ee4dd120":"code","62c7aea8":"code","89e0baa1":"code","50b59e9f":"code","d89b5926":"code","b149d10e":"code","d1a71fa9":"code","567fe3ba":"code","9c4b9718":"code","03afb360":"code","46417859":"code","04bc1162":"code","19ab13e0":"code","0dab132b":"code","88ae2edd":"code","0016c2cf":"code","02b36867":"code","79c4315b":"code","3e0554e9":"code","9c9c74cb":"code","8066ed98":"markdown","059ca4b0":"markdown","08052740":"markdown","2b7c446e":"markdown","cf5ccb18":"markdown","fa281b06":"markdown","86922a5b":"markdown","745fecb7":"markdown","f8e74f7d":"markdown","ca2f1b36":"markdown"},"source":{"1b7251b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","aaf9c430":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","eba57f04":"data = pd.read_csv(\"\/kaggle\/input\/california-housing-prices\/housing.csv\", sep=\",\")","2311d867":"data.head()","ee4dd120":"data.info()","62c7aea8":"data.describe()","89e0baa1":"data.isna().sum()","50b59e9f":"sns.pairplot(data)","d89b5926":"ocean = pd.factorize(data.ocean_proximity)","b149d10e":"ocean","d1a71fa9":"data['ocean'] = pd.factorize(data.ocean_proximity)[0]","567fe3ba":"data.head()","9c4b9718":"sns.pairplot(data.iloc[:,3:])","03afb360":"a = pd.Series(data.median_income)\nb = pd.Series(data.households \/ data.population)\nc = pd.Series(data.total_rooms \/ data.households)\nd = pd.Series(data.total_bedrooms \/ data.households)\nplt.scatter(x=c,y=d)","46417859":"e = pd.get_dummies(data.ocean_proximity)","04bc1162":"X = pd.DataFrame()\nX['median_income'] = a\nX['population_density'] = b\nX['housing_density'] = c\nX = pd.concat([X,e],axis=1)\nX.head()","19ab13e0":"y = np.array(data.median_house_value).reshape(-1,1)","0dab132b":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nscaled_X_train = scaler.transform(X_train)\nscaled_X_test = scaler.transform(X_test)\nscaler_out = StandardScaler()\nscaler_out.fit(y_train)\nscaled_y_train = scaler_out.transform(y_train)\nscaled_y_test = scaler_out.transform(y_test)","88ae2edd":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()\nclf.fit(scaled_X_train,scaled_y_train)\nclf.score(scaled_X_test,scaled_y_test)\npred = scaler_out.inverse_transform(clf.predict(scaled_X_test))\nplt.scatter(pred,y_test)","0016c2cf":"err = pred - y_test\nplt.hist(err,bins=50)","02b36867":"((err * err).mean()) ** (0.5)","79c4315b":"from sklearn import tree\nclfTree = tree.DecisionTreeRegressor()\nclfTree.fit(scaled_X_train,scaled_y_train)\npred_tree = scaler_out.inverse_transform(clfTree.predict(scaled_X_test))\nplt.scatter(x=pred_tree,y=y_test)","3e0554e9":"err_tree = pred_tree.reshape(-1,1) - y_test\nplt.hist(err_tree,bins=50)","9c9c74cb":"((err_tree * err_tree).mean()) ** (0.5)","8066ed98":"X axis shows the predicted Median House Value, Y axis shows the target Median House Value.\n\nClearly shows the upper capped values in the target values. Predicted values get a lot higher than the reported Median House Values.","059ca4b0":"total_rooms \/ households (c) and total_bedrooms \/ households (d) are correlated enough that it is probably sufficient to only include one of these, easiest decision is to use total_rooms as this does not have any missing values","08052740":"The histogram of the errors of the model have a larger tail at the negative end showing the skew in the predictions to the higher values, as shown in the previous scatter plot.\n\nRMSE of 69312.60 USD","2b7c446e":"Total rooms, total bedrooms, population, households are very highly correlated with each other.\n\nLongitude. latitude, housing_median_age seems to be no strong correlation with median_house_value\n\nMedian_house_value appears to have a capped upper bound, as seen with the larger values for the top bin in the histogram\n\nAn interesting extra feature might be some indication of the density of the population, e.g. households per population, and type of housing e.g. number of rooms per household\n\nAlso, not included in the pairplot is ocean proximity, so should convert this to a numerical value to check correlation, and convert to one hot values if including in the features.\n\nLikely useful features for predicting median house value:\n- Median_income\n- Households \/ population\n- total_rooms \/ households\n- total_bedrooms \/ households","cf5ccb18":"Can clearly see that in contrast to the linear regression model, the decision tree regressor is also capped as the data is at the upper end of median house values. (One of the disadvantages of decision trees is that they do not generalize beyond the examples that they have seen.)","fa281b06":"Data is looking at blocks of regions in California with information about the housholds in those regions from Census data:\n- Longitude and latitude indicating where in CA the region is located\n- housing_median_age - median age of individuals in the area (though with min at 1, there are likely some incorrect values here)\n- total_rooms - total number of rooms in the region (again with min at 2, likely some incorrect values here)\n- total_bedrooms - total number of bedrooms in the region - likely to be very correlated with total_rooms, possibly only need to keep one of these values\n- population - total population in the region (again with min at 3, likely to be some incorrect values here)\n- median_income - not clear what the scale of this would be\n- median_house_value - from 14,999 to 500,001 (seems that min and max may be truncated)\n\n207 missing data in the total_bedrooms","86922a5b":"California Housing\n\nComparison of Linear Regression and Decision Tree classifier for predicting Median House Value after some feature engineering","745fecb7":"The histogram of the error for the decision tree also is even on both sides, without the long tail for predicting higher median house values.\n\nRMSE of 89878.89 USD","f8e74f7d":"Simple model: see if a linear regression can predict median house price using the features median income, households \/ population, bedrooms \/ households, and whether the region is near the ocean (one hot encoding of classes).","ca2f1b36":"Ocean doesn't look particularly informative for median_house_value except for possibly when it is 4, which is on an island, but will include it as a one-hot encoding."}}