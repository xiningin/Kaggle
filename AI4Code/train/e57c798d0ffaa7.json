{"cell_type":{"95837929":"code","9039f051":"code","9a2c5a58":"code","1e646cce":"code","fb75e8f8":"code","c1c9d8a4":"code","8df11bd9":"code","12d6fa00":"code","defa70b3":"code","c0e6e413":"code","1453fe38":"code","b30ceb5a":"code","9375400e":"code","dd945ec4":"code","fb1cddd8":"code","498d6964":"code","cd29de19":"code","485f64a9":"code","a260f030":"code","8631cddb":"code","382d7b78":"code","4bead670":"code","b8ce83a2":"code","29625836":"code","62e6888a":"code","08baad66":"code","782e3188":"code","fd5dfe37":"code","d545f0b1":"code","d5578dae":"code","cd6b3a7f":"code","82c3704b":"code","b5ed9ef0":"code","7cb27eb2":"code","b66c4cb5":"code","ab415391":"code","f42fae57":"code","b72e507b":"code","468c5e91":"code","97a422c9":"code","02e64320":"code","13e056a7":"code","6242630a":"code","a0d60f9d":"code","7fabe8bd":"code","bbd7437c":"code","42f13491":"code","4b79aee2":"code","c0243d44":"code","6252a3a0":"code","e0de2323":"code","3cb0946e":"code","009ca60c":"code","c70a1d57":"code","62db84cc":"code","49146a3a":"code","f98f20b1":"code","75ad49cb":"code","252dc783":"code","a11e8bc5":"code","c156839e":"code","52529a6e":"code","c21c7ab1":"code","f7f56def":"code","7d9db6b6":"code","31b46e3b":"code","24c90199":"code","1a355cff":"code","89fd47e2":"code","a0c73d34":"code","059ae4bd":"code","83df346e":"code","e0448d15":"code","7e6b8659":"code","c04c2e3f":"code","82baf3c4":"code","33ddbc2e":"code","d2d7b556":"code","8236163b":"code","dbf80b5e":"code","50e74773":"code","06d8eedd":"code","e5978b22":"code","5dfa2289":"markdown","cacda372":"markdown","bafff3ff":"markdown","dbfb5a9f":"markdown","bab0576d":"markdown","e8064d11":"markdown","0e6918b4":"markdown","69bf5455":"markdown","625c0516":"markdown","11840733":"markdown","3eb34b2f":"markdown","349dbf31":"markdown","6fbd3395":"markdown","75935831":"markdown","9131a2a1":"markdown","dca8afed":"markdown"},"source":{"95837929":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndata = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv', delimiter = ',', encoding = 'utf-8')\ndata.head()","9039f051":"df = data.copy()\ndf.dtypes\n","9a2c5a58":"df.dtypes.value_counts()","1e646cce":"df.shape","fb75e8f8":"# Identification des valeurs manquantes :\n\nimport seaborn as sns \nplt.figure(figsize =  (20,10))\nsns.heatmap(df.isna(), cbar = False)\n\n","c1c9d8a4":"df.isna().sum()\/df.shape[0]\n(df.isna().sum()\/df.shape[0]).sort_values(ascending = False)","8df11bd9":"df['stroke'].value_counts(normalize = True)","12d6fa00":"for col in df.select_dtypes('float'):\n    print(col)","defa70b3":"for col in df.select_dtypes('float'):\n    plt.figure()\n    sns.distplot(df[col])","c0e6e413":"for col in df.select_dtypes('object'):\n    plt.figure()\n    df[col].value_counts().plot.pie()\n","1453fe38":"df['hypertension'].value_counts().plot.pie()","b30ceb5a":"df['heart_disease'].value_counts().plot.pie()","9375400e":"# cr\u00e9ation des sous-ensemble \n\nnegative_df = df[df['stroke'] == 0]\n\npositive_df = df[df['stroke'] == 1]\n","dd945ec4":"positive_df.shape","fb1cddd8":"cat_columns = df[['hypertension','heart_disease','gender','ever_married','work_type','Residence_type','smoking_status']].columns.to_list()\n\nnum_columns = df[['age','avg_glucose_level','bmi' ]].columns.to_list()","498d6964":"# Relation cat\u00e9gorie \/ target \n\nfor col in cat_columns : \n    plt.figure()\n    sns.heatmap(pd.crosstab(df['stroke'], df[col]), annot = True, fmt = 'd')\n","cd29de19":"#target \/ age\n\nplt.figure(figsize = (20,8))\nsns.countplot(x = 'age', hue = 'stroke', data = df)","485f64a9":"plt.figure(figsize = (12,8))\nplt.scatter(df['age'], df['bmi'], c = df['stroke'], alpha = 0.4)","a260f030":"#target \/num\u00e9 \n\nfor i in num_columns: \n    plt.figure()\n    sns.distplot(positive_df[i], label= 'positive')\n    sns.distplot(negative_df[i], label= 'negative')\n    plt.legend()\n","8631cddb":"sns.pairplot(df[num_columns])","382d7b78":"sns.heatmap(df[num_columns].corr())","4bead670":"df.corr()['age'\n         ].sort_values()","b8ce83a2":"cat_columns","29625836":"pd.crosstab(df['hypertension'], df['heart_disease'])","62e6888a":"df.columns","08baad66":"df['smoking_status'].value_counts()","782e3188":"df['est malade'] = np.sum(df[['hypertension','heart_disease' ]] == 1, axis = 1) >=1\n\nmalade_df = df[df['est malade'] == True]\nnon_malade_df = df[df['est malade'] == False]","fd5dfe37":"for i in num_columns : \n    plt.figure()\n    sns.distplot(malade_df[i], label= 'malade')\n    sns.distplot(non_malade_df[i], label= 'non malade')\n    plt.legend()\n","d545f0b1":"from scipy.stats import ttest_ind\n\npositive_df.shape","d5578dae":"negative_df.shape","cd6b3a7f":"balanced_neg = negative_df.sample(positive_df.shape[0])","82c3704b":"balanced_neg.shape","b5ed9ef0":"def t_test (col) : \n    alpha = 0.2\n    stat, p = ttest_ind(balanced_neg[col].dropna(), positive_df[col].dropna())\n    if p < alpha : \n        return 'H0 Reject\u00e9e'\n    else : \n        return 0","7cb27eb2":"for col in cat_columns : \n    print(f'{col}{t_test(col)}')","b66c4cb5":"for col in num_columns : \n    print(f'{col}{t_test(col)}')","ab415391":"df = df.drop('id', axis = 1)","f42fae57":"df.columns ","b72e507b":"from sklearn.model_selection import train_test_split","468c5e91":"%matplotlib\nfrom mpl_toolkits.mplot3d import Axes3D\nax = plt.axes(projection = '3d')\nax.scatter(df['hypertension'], df['age'], df['heart_disease'], c=df['stroke'])\n","97a422c9":"# Colonne Gender : \n\ndf.loc[df['gender'] == 'Male','gender'] = 0\ndf.loc[df[\"gender\"] == \"Female\",\"gender\"] = 1","02e64320":"# Colonne Ever Married :\n\ndf.loc[df['ever_married'] == \"Yes\", 'ever_married'] = 1\ndf.loc[df['ever_married'] == \"No\", 'ever_married'] = 0","13e056a7":"#Colonne Residence\n\n\ndf.loc[df['Residence_type'] == \"Urban\", 'Residence_type'] = 1\ndf.loc[df['Residence_type'] == \"Rural\", 'Residence_type'] = 0\n\ndf = df.rename(columns = {'Residence_type': 'Urban_residence'}) ","6242630a":"cat_columns = ['hypertension','heart_disease','gender','ever_married','work_type','Urban_residence','smoking_status']","a0d60f9d":"#Colonne Work Type et Smoking Status\n\ndf2 = pd.get_dummies(df[['work_type', 'smoking_status']], prefix=['work_type', 'smoking_status'])\n\ndf = df.join(df2)","7fabe8bd":"# Suppression des colonnes 'work_type','smoking_status','smoking_status_Unknown','smoking_status_never smoked'\n\ndf = df.drop(['work_type','smoking_status','smoking_status_Unknown','smoking_status_never smoked'], axis = 1)","bbd7437c":"#Suppression de la colonne work type children\n\ndf = df.drop('work_type_children', axis = 1)","42f13491":"df.loc[df['est malade'] == True, 'est malade'] = 1\ndf.loc[df['est malade'] == False, 'est malade'] = 0","4b79aee2":"# On supprime la ligne Gender = Other\nindexNames = df[df['gender'] == 'Other'].index\nindexNames\n","c0243d44":"df = df.drop(index = indexNames)","6252a3a0":"# On remet les bons types aux colonnes\n\ndf[['age', 'avg_glucose_level','bmi']] = df[['age', 'avg_glucose_level','bmi']].astype(float)\ndf[['gender','ever_married','Urban_residence','est malade' ]] = df[['gender','ever_married','Urban_residence','est malade' ]].astype(int)","e0de2323":"df[['work_type_Govt_job', 'work_type_Never_worked','work_type_Private','work_type_Self-employed',\n   'smoking_status_formerly smoked','smoking_status_smokes']] = df[['work_type_Govt_job', 'work_type_Never_worked','work_type_Private','work_type_Self-employed',\n   'smoking_status_formerly smoked','smoking_status_smokes']].astype(int)","3cb0946e":"df.dtypes","009ca60c":"def imputation(df): \n    return df.dropna(axis =0)","c70a1d57":" def feature_engineering (df) : \n        df['est malade'] = np.sum(df[['hypertension','heart_disease' ]] == 1, axis = 1) >=1\n        df = df.drop(['hypertension','heart_disease'], axis = 1)\n        \n        df['a fum\u00e9'] = np.sum(df[['smoking_status_formerly smoked','smoking_status_smokes']] == 1, axis = 1) >=1\n        df = df.drop(['smoking_status_formerly smoked','smoking_status_smokes'], axis = 1)\n        \n        df['vieux'] = df.loc[df['age'] >= 55, 'age']\n        df.loc[df['vieux'] >= 50, 'vieux'] = 1\n        df['vieux'] = df['vieux'].fillna(0)\n        \n        return df\n    ","62db84cc":"def preprocessing (df) : \n    \n    df = imputation(df)\n    df = feature_engineering(df)\n    \n    X = df.drop('stroke', axis = 1)\n    y = df['stroke']\n    \n    print(y.value_counts(normalize = True))\n    \n    return X,y","49146a3a":"trainset, testset = train_test_split(df, test_size = 0.2, random_state = 0)","f98f20b1":"X_train, y_train = preprocessing(trainset)","75ad49cb":"X_test, y_test = preprocessing(testset)","252dc783":"from imblearn.over_sampling import SMOTE \n\nsmote = SMOTE(sampling_strategy = 0.1)\nX_train, y_train = smote.fit_resample(X_train, y_train)","a11e8bc5":"from imblearn.under_sampling import RandomUnderSampler \n\nrUs = RandomUnderSampler(sampling_strategy=0.9)\nX_train, y_train = rUs.fit_resample(X_train, y_train)\n","c156839e":"y_train.value_counts(normalize = True)","52529a6e":"# On entraine un arbre de d\u00e9cision \n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif, chi2\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\n\nmodel = make_pipeline(PolynomialFeatures(2),SelectKBest(score_func=chi2, k=12),\n                      DecisionTreeClassifier(random_state = 0))\n\n#model = make_pipeline(PolynomialFeatures(2),PCA (n_components = 3),\n                      #DecisionTreeClassifier(random_state = 0))\n\n\n\n#model = DecisionTreeClassifier(random_state = 0)","c21c7ab1":"from sklearn.metrics import f1_score,  confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve \n\ndef evaluation(model):\n    model.fit(X_train,y_train)\n    y_pred = model.predict (X_test)\n    \n    print(confusion_matrix(y_test,y_pred))\n    print(classification_report(y_test, y_pred))\n    \n    N, train_score, val_score = learning_curve(model, X_train,y_train, \n                                              cv = 4, scoring = 'f1',\n                                               train_sizes = np.linspace(0.1,1,10))\n    \n    plt.figure(figsize = (12,8))\n    plt.plot(N,train_score.mean(axis = 1), label = 'train score')\n    plt.plot(N,val_score.mean(axis = 1), label = 'validation score')\n    plt.legend()","f7f56def":"evaluation(model)","7d9db6b6":"#pd.DataFrame(model.feature_importances_, index = X_train.columns).plot.bar()","31b46e3b":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.decomposition import PCA","24c90199":"preprocessor = make_pipeline(PolynomialFeatures(2, include_bias = False), SelectKBest(chi2, k=12))","1a355cff":"RandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state = 0))\n\nAdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state = 0))\n\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\nKNN = make_pipeline(preprocessor, StandardScaler(), KNeighborsClassifier())","89fd47e2":"list_of_models = [RandomForest,AdaBoost, SVM, KNN ]\ndict_of_models = {'RandomForest' :RandomForest ,\n                 'Adaboost' : AdaBoost ,\n                 'SVM' :SVM ,\n                 'KNN':KNN }","a0c73d34":"for name,model in dict_of_models.items() : \n    print(name)\n    evaluation(model)","059ae4bd":"from sklearn.model_selection import GridSearchCV","83df346e":"hyper_params = {'svc__gamma' : [1e-3, 1e-4],\n                'svc__C' : [1,10,100,1000]}","e0448d15":"\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\ngrid = GridSearchCV(SVM,hyper_params, scoring = \"recall\", cv =4)\n\ngrid.fit(X_train,y_train)\n\nprint(grid.best_params_)","7e6b8659":"y_pred = grid.predict(X_test)\nprint(classification_report (y_test,y_pred))","c04c2e3f":"evaluation(grid.best_estimator_)","82baf3c4":"hyper_params = {'svc__gamma' : [1e-3, 1e-4],\n                'svc__C' : [1,10,100,1000],\n               'svc__kernel':['rbf', 'linear', 'poly', 'rbf', 'sigmoid'],\n               'pipeline__polynomialfeatures__degree' : [2,3],\n               'pipeline__selectkbest__k' : range(40,80)}","33ddbc2e":"from sklearn.model_selection import RandomizedSearchCV\n\nSVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\ngrid = RandomizedSearchCV(SVM,hyper_params, scoring = \"recall\", cv =4, n_iter = 40)\n\ngrid.fit(X_train,y_train)\n\nprint(grid.best_params_)\n\ny_pred = grid.predict(X_test)\nprint(classification_report (y_test,y_pred))\n\nevaluation(grid.best_estimator_)","d2d7b556":"SVM = make_pipeline(preprocessor, StandardScaler(), SVC(random_state = 0))\n\nevaluation(SVM)","8236163b":"from sklearn.metrics import precision_recall_curve","dbf80b5e":"precision, recall, threshold = precision_recall_curve(y_test, SVM.decision_function(X_test))","50e74773":"plt.plot(threshold, precision[:-1], label = 'precision')\nplt.plot(threshold, recall[:-1], label = 'recall')\nplt.legend()","06d8eedd":"def model_final(model,X, threshold = 0.8) : \n    return model.decision_function(X) > threshold","e5978b22":"y_pred = model_final(SVM, X_test,threshold = 0.1)\n\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test, y_pred))","5dfa2289":"### Modelling","cacda372":"## OPTIMISATION","bafff3ff":"### Sur echantillonnage","dbfb5a9f":"#### ANALYSE DE FOND : \n\n- **Visualisation de la target (Histogramme si c\u2019est une valeur continue \/ Boxplot si c\u2019est une valeur discr\u00e8te** : \n    - Seulement 4% de positifs\n\n- **Signification des diff\u00e9rentes variables** :\n    - Variables continues : non-standardis\u00e9es, asym\u00e9triques\n    - Variables age : age varie de 0 \u00e0 80 ans, on pourra cr\u00e9er une variable pour les cat\u00e9gories d'age plus tard\n    - Variables qualitatives : plus de femmes, plus de mari\u00e9s, plus de personnes travaillant dans le priv\u00e9. Peu de malades hypertension, et maladie du coeur. Une inconnu sur les fumeurs'unknow'\n\n- **Relations features \u2013 target (Histogramme \/ Boxplot)** :\n    - target \/ cat\u00e9gorie : Pour l'instant on ne peut rien tirer de ces graphs \n    - target \/ age : tr\u00e8s peu d'accident vasculaire avant 40 ans, cela augmente avec l'age. La'ge pourrait etre une variable interessante\n    - target \/ viral : l'age et le glucose pourrait \u00eatre des facteurs => \u00e0 tester","bab0576d":"# 2- PRE TRAITEMENT DES DONN\u00c9ES","e8064d11":"## Objectif : \n- Comprendre au maximum les donn\u00e9es dont on dispose pour d\u00e9finir une strat\u00e9gie de mod\u00e9lisation\n\n- D\u00e9volopper une premi\u00e8re strat\u00e9gie de mod\u00e9lisation\n\n#### ANALYSE DE LA FORME : \n\n- **Identification de la target** : stroke\n\n- **Nombre de lignes et de colonnes** : 5110 lignes et 12 colonnes\n\n- **Types de variables** : qualitatives : 9, quantitatives : 3\n\n- **Identification des valeurs manquantes** : peu de NaN, seulement sur la variable bmi (indice de masse corporelle), il y a 4% de valeurs manquantes\n\n","0e6918b4":"## INTRODUCTION","69bf5455":"### Fonctions de preprocessing","625c0516":"### Encodage ","11840733":"### Evaluation","3eb34b2f":"# 3- MODELISATION","349dbf31":"## PRECISION RECALL CURVE","6fbd3395":"### Autres visualisation","75935831":"# 1- EXPLORATORY DATA ANALYSE","9131a2a1":"#### ANALYSE DE LA FORME","dca8afed":"#### ANALYSE DETAILLEE : \n\n- ** Relations variables \/ Variables ** :\n    - Num\u00e9rique \/ Num\u00e9rique : pas de relation lin\u00e9aire\n    - Num\u00e9rique \/ age : Pas de relation lin\u00e9aire\n    - Cat\u00e9gorielles \/ Cat\u00e9gorielles : \n    - Cat\u00e9gorielles \/ Age : \n\n- **Sous-Ensemble** :\n    - est malade (hypertension et maladie cardiaque) : on une IMC plus \u00e9l\u00e9v\u00e9, un age plus \u00e9lev\u00e9 aussi \n\n- **Test hypoth\u00e8ses ** : "}}