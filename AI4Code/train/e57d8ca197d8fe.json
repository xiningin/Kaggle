{"cell_type":{"de33da69":"code","86132071":"code","82505785":"code","25468d03":"code","cf985aea":"code","c6c1cdd0":"code","57d4596a":"code","402be22e":"code","95ad117e":"code","f1a1b855":"code","ba6b6ef2":"code","8b6faa49":"code","1158acea":"code","81899a03":"code","d239ffe2":"code","29562195":"code","085c0927":"code","5f4aa3dc":"code","8b1579e1":"code","ddf71527":"code","9a72ec53":"code","4f29618a":"code","8e64d314":"code","c1cd85b1":"code","7f3d92ae":"code","e86b819b":"code","7f3efcbf":"code","a143b2cf":"code","c82d34d8":"code","b83adf22":"code","b3d27632":"code","2db63342":"code","b43a126b":"code","2e482f05":"markdown","3564c221":"markdown"},"source":{"de33da69":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86132071":"import re\nfrom scipy.stats import iqr, zscore,norm\n\n# to handle datasets\nimport pandas as pd\nimport numpy as np\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\n\n\n# to divide train and test set\nfrom sklearn.model_selection import train_test_split\n\n# feature scaling\nfrom sklearn.preprocessing import StandardScaler\n\n# to build the models\nfrom sklearn.linear_model import LogisticRegression\n\n# to evaluate the models\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import log_loss\n\n# to persist the model and the scaler\nimport joblib\n\n# to visualise al the columns in the dataframe\npd.pandas.set_option('display.max_columns', None)","82505785":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","25468d03":"# Display all dataset samples and info\ndisplay(train_df.head())\ndisplay(test_df.tail())\ndisplay(train_df.info())\ndisplay(test_df.info())","cf985aea":"# Converting Object data type to String for regex expression to be used\ntrain_df['Cabin']= train_df['Cabin'].astype('str')\n# Convert pclass and sibsp into object type since it is not a continuous numerical value\ntrain_df['Pclass']= train_df['Pclass'].astype('object')\ntrain_df['SibSp']= train_df['SibSp'].astype('object')\ntrain_df['Survived']= train_df['Survived'].astype('Int64')\ntrain_df['Parch']= train_df['Parch'].astype('object')\ntrain_df['Survived']= train_df['Survived'].astype('object')","c6c1cdd0":"# Converting Object data type to String for regex expression to be used\ntest_df['Cabin']= test_df['Cabin'].astype('str')\n# Convert pclass and sibsp into object type since it is not a continuous numerical value\ntest_df['Pclass']= test_df['Pclass'].astype('object')\ntest_df['SibSp']= test_df['SibSp'].astype('object')\ntest_df['Parch']= test_df['Parch'].astype('object')","57d4596a":"# replace interrogation marks by NaN values\n\ntrain_df = train_df.replace('?', np.nan)\ntest_df = test_df.replace('?', np.nan)","402be22e":"# retain only the first cabin if more than\n# 1 are available per passenger\n\ndef get_first_cabin(row):\n    try:\n        return row.split()[0]\n    except:\n        return np.nan\n    \ntrain_df['Cabin'] = train_df['Cabin'].apply(get_first_cabin)\ntest_df['Cabin'] = test_df['Cabin'].apply(get_first_cabin)","95ad117e":"# extracts the title (Mr, Ms, etc) from the name variable\n\ndef get_title(passenger):\n    line = passenger\n    if re.search('Mrs', line):\n        return 'Mrs'\n    elif re.search('Mr', line):\n        return 'Mr'\n    elif re.search('Miss', line):\n        return 'Miss'\n    elif re.search('Master', line):\n        return 'Master'\n    else:\n        return 'Other'\n    \ntrain_df['title'] = train_df['Name'].apply(get_title)\ntest_df['title'] = test_df['Name'].apply(get_title)","f1a1b855":"train_df.drop(labels=['Name','Ticket'], axis=1, inplace=True)\ntest_df.drop(labels=['Name','Ticket'], axis=1, inplace=True)","ba6b6ef2":"def varss(data):\n    vars_num = list(data.select_dtypes([np.number]).columns)\n    vars_cat = list(data.select_dtypes(include=['object', 'category']).columns)\n    return [vars_num, vars_cat]\n    \n\nvar = varss(train_df)\nvars_num = (var[0])\nvars_cat = (var[1])\nprint('Number of numerical variables: {}'.format(len(vars_num)))\nprint('Number of categorical variables: {}'.format(len(vars_cat)))","8b6faa49":"vars_cat.remove('Survived')\nvars_num.remove('PassengerId')","1158acea":"train_df['Cabin']= train_df['Cabin'].apply(lambda x: re.split('(\\d)', x)[0])\ntest_df['Cabin']= test_df['Cabin'].apply(lambda x: re.split('(\\d)', x)[0])","81899a03":"# Find missing values in train dataset\n\n#missing data => Find total rows having missing values and calculate the percentage of missing values for each field.\ntotal = train_df.isnull().sum().sort_values(ascending=False)\npercent = (train_df.isnull().sum()\/train_df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","d239ffe2":"# Find missing values in test dataset\n\n#missing data => Find total rows having missing values and calculate the percentage of missing values for each field.\ntotal = test_df.isnull().sum().sort_values(ascending=False)\npercent = (test_df.isnull().sum()\/test_df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","29562195":"for var in vars_cat:\n        plt.figure()\n        g = sns.FacetGrid(train_df, col='Survived')\n        g.map(plt.hist, var)","085c0927":"for var in vars_num:\n        plt.figure()\n        g = sns.FacetGrid(train_df, col='Survived')\n        g.map(plt.hist, var)","5f4aa3dc":"X_train = train_df.drop(\"Survived\",axis=1)","8b1579e1":"# make a list with the numerical variables that contain missing values\nvars_with_na = [\n    var for var in X_train.columns\n    if X_train[var].isnull().sum() > 0 and X_train[var].dtypes != 'O']\n\n# print percentage of missing values per variable\nX_train[vars_with_na].isnull().mean()\n","ddf71527":"# replace engineer missing values as we described above\n\nfor var in vars_with_na:\n\n    # calculate the mode using the train set\n    mode_val = X_train[var].mode()[0]\n\n    # add binary missing indicator (in train and test)\n    #X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n    #X_test[var+'_na'] = np.where(X_test[var].isnull(), 1, 0)\n\n    # replace missing values by the mode\n    # (in train and test)\n    X_train[var] = X_train[var].fillna(mode_val)\n    \n\n# check that we have no more missing values in the engineered variables\nX_train[vars_with_na].isnull().sum()","9a72ec53":"X_test = test_df","4f29618a":"# make a list with the numerical variables that contain missing values\nvars_with_na = [\n    var for var in X_test.columns\n    if X_test[var].isnull().sum() > 0 and X_test[var].dtypes != 'O']\n\n# print percentage of missing values per variable\nX_test[vars_with_na].isnull().mean()","8e64d314":"# replace engineer missing values as we described above\n\nfor var in vars_with_na:\n\n    # calculate the mode using the train set\n    mode_val = X_test[var].mode()[0]\n\n    # add binary missing indicator (in train and test)\n    #X_train[var+'_na'] = np.where(X_train[var].isnull(), 1, 0)\n    #X_test[var+'_na'] = np.where(X_test[var].isnull(), 1, 0)\n\n    # replace missing values by the mode\n    # (in train and test)\n    X_test[var] = X_test[var].fillna(mode_val)\n    \n\n# check that we have no more missing values in the engineered variables\nX_test[vars_with_na].isnull().sum()","c1cd85b1":"scaler = StandardScaler()\nX_train[vars_num] = scaler.fit_transform(X_train[vars_num])\nX_test[vars_num] = scaler.fit_transform(X_test[vars_num])","7f3d92ae":"X_train = pd.get_dummies(X_train, drop_first=True, dummy_na=False,prefix=None,\n    prefix_sep='_',columns=vars_cat)","e86b819b":"X_test = pd.get_dummies(X_test, drop_first=True, dummy_na=False,prefix=None,\n    prefix_sep='_',columns=vars_cat)","7f3efcbf":"y = train_df['Survived']","a143b2cf":"log_reg = LogisticRegression(penalty=\"l2\",max_iter=10000)","c82d34d8":"log_reg.fit(X_train,y.astype(int))","b83adf22":"y_pred = log_reg.predict(X_test)","b3d27632":"from sklearn import model_selection\nprint(model_selection.cross_val_score(log_reg,X_train,y.astype(int),cv=6).mean())","2db63342":"passenger_id = test_df[\"PassengerId\"]\nprint(y_pred.shape)\noutput=pd.DataFrame({\"PassengerId\":passenger_id,\"Survived\":y_pred})\noutput","b43a126b":"\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Submission was successfully saved.\")","2e482f05":"### Replace Missing Value for Numerical Variables in Train dataset","3564c221":"### Replace Missing Value for Numerical Variables in Test dataset"}}