{"cell_type":{"1bcfc412":"code","23d735ca":"code","bb697c37":"code","928fa5b5":"code","71e22b20":"code","03fd2c23":"code","56d2d32e":"code","267a592c":"code","ab67b35c":"code","a615976e":"code","47ca4c9b":"code","3c7f94a6":"code","8424b298":"code","6cf4e8cc":"code","81b3bda0":"code","a7f2b27f":"code","f1de0816":"code","e70badfb":"code","272cd4b0":"code","d96b8774":"code","1e455b7c":"code","72e6d4dd":"code","24f6ef88":"code","4732fca4":"code","1a54a865":"code","9a0db50f":"code","c35927ca":"code","d3ca9124":"code","d978d292":"code","8ea0a8be":"code","cca57d33":"code","aac72438":"code","99f6fc36":"code","9a9e029e":"code","61a775e7":"code","5507b1d3":"code","e6603560":"code","9af76877":"code","f15c7393":"code","9b608271":"code","03fed456":"code","188a1fea":"code","c8512012":"code","ae1b3d69":"code","37cddfcf":"code","8fdb7685":"code","2994c158":"code","12743d55":"code","64f34f0c":"code","c0d3c30c":"code","6f3ece1a":"code","a1854f9a":"code","4c2ae3ba":"code","9d9e1030":"code","745b2b92":"markdown","294c51f8":"markdown","c031daa1":"markdown","eeead409":"markdown","ed03589f":"markdown","a3b5938c":"markdown","e7e1f264":"markdown","9b4e4589":"markdown","570bccda":"markdown","dd6d7e71":"markdown","5f853f69":"markdown","3cdf161a":"markdown","8cf64ae4":"markdown","2c32a8fb":"markdown","6fac6763":"markdown","d58c2241":"markdown","eb168de6":"markdown","5cf083af":"markdown","c484fe4e":"markdown","040695ed":"markdown","8d62710b":"markdown","583d2961":"markdown","4072c169":"markdown"},"source":{"1bcfc412":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23d735ca":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n#Loading libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn.metrics as metrics\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.metrics.pairwise import pairwise_distances\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport re\nimport seaborn as sns","bb697c37":"#Loading data\nbooks = pd.read_csv(\"..\/input\/books-dataset\/books_data\/books.csv\", sep=\";\", \n                    error_bad_lines=False, encoding=\"latin-1\")\nbooks.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication', 'publisher', \n                 'imageUrlS', 'imageUrlM', 'imageUrlL']\nusers = pd.read_csv('..\/input\/books-dataset\/books_data\/users.csv', sep=';', \n                    error_bad_lines=False, encoding=\"latin-1\")\nusers.columns = ['userID', 'Location', 'Age']\nratings = pd.read_csv('..\/input\/books-dataset\/books_data\/ratings.csv', sep=';', \n                      error_bad_lines=False, encoding=\"latin-1\")\nratings.columns = ['userID', 'ISBN', 'bookRating']","928fa5b5":"print(books.shape)\nprint(users.shape)\nprint(ratings.shape)","71e22b20":"books.head()","03fd2c23":"books.drop(['imageUrlS', 'imageUrlM', 'imageUrlL'],axis=1,inplace=True)","56d2d32e":"books.head()","267a592c":"books.yearOfPublication.unique()","ab67b35c":"books.loc[books.yearOfPublication == 'DK Publishing Inc',:]","a615976e":"books.loc[books.yearOfPublication == 'Gallimard',:]","47ca4c9b":"books = books[(books.yearOfPublication != 'DK Publishing Inc')\n              & (books.yearOfPublication != 'Gallimard')]","3c7f94a6":"books.yearOfPublication = books.yearOfPublication.astype('int32')\nbooks.dtypes","8424b298":"#Publisher\n#drop NaNs in publisher column\nbooks = books.dropna(subset=['publisher'])\nbooks.publisher.isnull().sum()","6cf4e8cc":"#Users\nusers.shape\nusers.head()","81b3bda0":"#Age\nprint(sorted(users.Age.unique()))","a7f2b27f":"users.loc[(users.Age > 90) | (users.Age < 5), 'Age'] = np.nan","f1de0816":"#Replace All null values with mean\n#replacing NaNs with mean\nusers.Age = users.Age.fillna(users.Age.mean())","e70badfb":"#Change the datatype into int\n#setting the data type as int\nusers.Age = users.Age.astype(np.int32)","272cd4b0":"print(sorted(users.Age.unique()))","d96b8774":"#check the shape\nratings.shape","1e455b7c":"n_users = users.shape[0]\nn_books = books.shape[0]\nprint(n_users * n_books)","72e6d4dd":"ratings.head(5)","24f6ef88":"ratings_new = ratings[ratings.ISBN.isin(books.ISBN)]","4732fca4":"ratings.shape","1a54a865":"ratings_new.shape","9a0db50f":"ratings.bookRating.unique()","c35927ca":"#Hence segragating implicit and explict ratings datasets\nratings_explicit = ratings_new[ratings_new.bookRating != 0]\nratings_implicit = ratings_new[ratings_new.bookRating == 0]","d3ca9124":"#checking shapes\nprint(ratings_new.shape)\nprint(ratings_explicit.shape)\nprint(ratings_implicit.shape)","d978d292":"#plotting count of bookRating\nsns.countplot(data=ratings_explicit , x='bookRating')\nplt.show();\n","8ea0a8be":"counts1 = ratings_explicit['userID'].value_counts()\n# print(counts1)\nratings_explicit = ratings_explicit[ratings_explicit['userID'].isin(counts1[counts1 >= 100].index)]","cca57d33":"ratings_explicit.head()","aac72438":"ratings_explicit.shape","99f6fc36":"ratings_matrix = ratings_explicit.pivot(index='userID', columns='ISBN', values='bookRating').fillna(0)\nuserID = ratings_matrix.index\nISBN = ratings_matrix.columns\nprint(ratings_matrix.shape)\nratings_matrix.head()","9a9e029e":"from scipy.sparse.linalg import svds\nU, sigma, Vt = svds(ratings_matrix, k = 50)","61a775e7":"sigma = np.diag(sigma)\nall_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \npreds_df = pd.DataFrame(all_user_predicted_ratings, columns = ratings_matrix.columns)","5507b1d3":"preds_df.head()","e6603560":"user_id = 2","9af76877":"userID = ratings_matrix.iloc[user_id-1, :].name\nuserID","f15c7393":"preds_df.shape","9b608271":"sorted_user_predictions = preds_df.iloc[user_id].sort_values(ascending=False)","03fed456":"len(sorted_user_predictions)","188a1fea":"# Get all user interacted books\nuser_data = ratings_explicit[ratings_explicit.userID == (userID)]","c8512012":"user_data.head()","ae1b3d69":"user_data.shape","37cddfcf":"book_data = books[books.ISBN.isin(user_data.ISBN)]","8fdb7685":"book_data.shape","2994c158":"book_data.head()","12743d55":"user_full_info = user_data.merge(book_data)","64f34f0c":"user_full_info.head()","c0d3c30c":"print ('User {0} has already rated {1} books.'.format(userID, user_full_info.shape[0]))","6f3ece1a":"recommendations = (books[~books['ISBN'].isin(user_full_info['ISBN'])].\n                   merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left', left_on = 'ISBN'\n                         ,right_on = 'ISBN')).rename(columns = {user_id: 'Predictions'})","a1854f9a":"recommendations.shape","4c2ae3ba":"recommendations.head()","9d9e1030":"recommendations.sort_values('Predictions', ascending = False).iloc[:10, :]","745b2b92":"### Load Libraries and Data","294c51f8":"### Since we do not have year of publication anywhere in the entire row for DK Publishing Inc and Gallimard, we will drop these rows from the original dataset","c031daa1":"### Take a particular user_id\n* Lets find the recommendations for user with id 2110\n* Get the predicted ratings for userID 2110 and sort them in descending order\n* Create a dataframe with name user_data containing userID 2110 explicitly interacted books\n* Combine the user_data and and corresponding book data(book_data) in a single dataframe with name user_full_info","eeead409":"### Check unique values of year of publication","ed03589f":"![image.png](attachment:image.png)","a3b5938c":"### Check number of records and features given in each dataset\n### Clean the data","e7e1f264":" ### Explore Users dataset\n* Get all unique values in ascending order for column Age \n* Values below 5 and above 90 do not make much sense for our book rating case...hence replace these by NaNs\n* Replace null values in column Age with mean\n* Change the datatype of Age to int","9b4e4589":"### Generate the predicted ratings using SVD with number of singular values to be 50","570bccda":"### Change the datatype of year of publication as integer and drop rows having publisher value as null","dd6d7e71":"### It can be seen that higher ratings are more common amongst users and rating 8 has been rated highest number of times","5f853f69":"### We observe that a lot of records were dropped because the books were not present in our dataset","3cdf161a":"### For analysis purpose we remove ratings of zero as will not help in recommendation","8cf64ae4":"### Collaborative Filtering Based Recommendation Systems\n#### For more accurate results only consider users who have rated atleast 100 books","2c32a8fb":"### Get top 10 recommendation for above given userID","6fac6763":"### Subset ratings data to only those books which are present in our data","d58c2241":"### Generate matrix table from explicit ratings table","eb168de6":"### Ratings dataset will have users * books number of records","5cf083af":"### Since NaNs cannot be handled by training algorithm, replacing these by 0, which indicates absence of ratings","c484fe4e":"### We do not require the image links or URL so dropping them","040695ed":"### Age column has some invalid entries like nan, 0 and very high values like 100 and above\n### Values below 5 and above 90 do not make much sense for our book rating case...hence replacing these by NaNs","8d62710b":"### Setup the environment","583d2961":"### As it can be seen from above that there are some incorrect entries in this field. It looks like Publisher names 'DK Publishing Inc' and 'Gallimard' have been incorrectly loaded as yearOfPublication in dataset due to some errors in csv file.\n\n### Also some of the entries are strings and same years have been entered as numbers in some places, some are future dates like 2030 etc","4072c169":"### Explore Ratings dataset\n* Check the shape\n* Ratings dataset should have books only which exist in our books dataset. Drop the remaining rows\n* Ratings dataset should have ratings from users which exist in users dataset. Drop the remaining rows\n* Consider only ratings from 1-10 and leave 0s in column bookRating\n* Find out which rating has been given highest number of times"}}