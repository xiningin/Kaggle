{"cell_type":{"c7ca3b58":"code","2a06959c":"code","487c8e91":"code","0fc53003":"code","6c56fc7b":"code","4333741e":"code","cd304390":"code","e932f1e0":"code","1e1ff6f4":"code","9fcee1be":"code","80686fa6":"code","fa6308ff":"code","6f4471f8":"code","4ab2fcf7":"code","97c2efa3":"code","cc57982d":"code","94b81f77":"code","de6f5da3":"code","28c75190":"code","76e0018a":"code","b705c9f5":"code","abca8bf9":"code","6cc67ae5":"code","9304e685":"markdown","fbc9ad78":"markdown","a6046d1e":"markdown","6b48f71c":"markdown","e6ffcd4c":"markdown","764d17db":"markdown"},"source":{"c7ca3b58":"## Importing required libraries\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom PIL import Image\nimport warnings\n\nwarnings.filterwarnings('ignore')\nnp.random.seed(0)\ntf.random.set_seed(0)","2a06959c":"cwd = '..\/input\/gtsrb-german-traffic-sign\/'\nos.listdir(cwd)","487c8e91":"meta = os.listdir(cwd+'Meta')\nmeta.remove('.~lock.ClassesInformation.ods#')\nmeta.remove('.~lock.ClassesInformationStrong.ods#')\nmeta","0fc53003":"## Viewing images belonging to each class\n\nplt.figure(figsize=(30,30))\nfor i, file in enumerate(meta):\n    img = Image.open(cwd+'Meta\/'+file)\n    ax = plt.subplot(9,5,i+1)\n    ax.imshow(img)\n    ax.set_title(file, size=20)\n    plt.axis('off')\nplt.tight_layout()","6c56fc7b":"## Creating a dictionary for class labels\n\nclasses = { 0:'Speed limit (20km\/h)',\n            1:'Speed limit (30km\/h)', \n            2:'Speed limit (50km\/h)', \n            3:'Speed limit (60km\/h)', \n            4:'Speed limit (70km\/h)', \n            5:'Speed limit (80km\/h)', \n            6:'End of speed limit (80km\/h)', \n            7:'Speed limit (100km\/h)', \n            8:'Speed limit (120km\/h)', \n            9:'No passing', \n            10:'No passing veh over 3.5 tons', \n            11:'Right-of-way at intersection', \n            12:'Priority road', \n            13:'Yield', \n            14:'Stop', \n            15:'No vehicles', \n            16:'Veh > 3.5 tons prohibited', \n            17:'No entry', \n            18:'General caution', \n            19:'Dangerous curve left', \n            20:'Dangerous curve right', \n            21:'Double curve', \n            22:'Bumpy road', \n            23:'Slippery road', \n            24:'Road narrows on the right', \n            25:'Road work', \n            26:'Traffic signals', \n            27:'Pedestrians', \n            28:'Children crossing', \n            29:'Bicycles crossing', \n            30:'Beware of ice\/snow',\n            31:'Wild animals crossing', \n            32:'End speed + passing limits', \n            33:'Turn right ahead', \n            34:'Turn left ahead', \n            35:'Ahead only', \n            36:'Go straight or right', \n            37:'Go straight or left', \n            38:'Keep right', \n            39:'Keep left', \n            40:'Roundabout mandatory', \n            41:'End of no passing', \n            42:'End no passing veh > 3.5 tons' }","4333741e":"train_df = pd.read_csv(cwd+'Train.csv')\ntrain_df.head()","cd304390":"train_df.describe()","e932f1e0":"print(f'minimum width: {train_df.Width.min()}')\nprint(f'minimum height: {train_df.Height.min()}')\nprint(f'average width: {train_df.Width.mean()}')\nprint(f'average height: {train_df.Height.mean()}')","1e1ff6f4":"train_x =[]\nfor i in train_df.Path:\n    img = Image.open(cwd+i)       # reading image\n    img = img.resize((50,50))     # reasizing image\n    train_x.append(np.array(img)) # saving image as array to train\n\ntrain_y = np.array(train_df.ClassId)\ntrain_x = np.array(train_x)\nprint(train_x.shape)\nprint(train_y.shape)","9fcee1be":"test_df = pd.read_csv(cwd+'Test.csv')\ntest_df.head()","80686fa6":"test_x =[]\nfor i in test_df.Path:\n    img = Image.open(cwd+i)\n    img = img.resize((50,50))\n    test_x.append(np.array(img))\n\ntest_y = np.array(test_df.ClassId)\ntest_x = np.array(test_x)\nprint(test_x.shape)\nprint(test_y.shape)","fa6308ff":"print(classes[train_y[2]])\nplt.imshow(train_x[2])\nplt.axis('off')\nplt.show()","6f4471f8":"## Normalization\n\nxtrain = train_x\/255\nxtest = test_x\/255\n\n\n# One Hot encoding\n\nytrain = keras.utils.to_categorical(train_y)\nytest = keras.utils.to_categorical(test_y)","4ab2fcf7":"## Splitting into train and validation data\n\nfrom sklearn.model_selection import train_test_split\nxtrain, xvalid, ytrain, yvalid = train_test_split(xtrain, ytrain, test_size=0.2, random_state=0)\nprint(xtrain.shape)\nprint(xvalid.shape)\nprint(ytrain.shape)\nprint(yvalid.shape)","97c2efa3":"from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\n\nmodel = keras.models.Sequential()\nmodel.add(Conv2D(filters=32, kernel_size= (5,5), strides=2, activation='relu', padding='same', input_shape=(50,50,3)))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), strides=2, activation='relu', padding='same'))\nmodel.add(MaxPool2D((2,2), padding='valid'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), strides=2, activation='relu', padding='same'))\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), strides=2, activation='relu', padding='same'))\nmodel.add(MaxPool2D((2,2), padding='valid'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(300, activation='relu'))\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\n\nmodel.summary()","cc57982d":"keras.utils.plot_model(model)","94b81f77":"# Compiling the CNN model\nmodel.compile(optimizer='sgd',\n             loss='categorical_crossentropy',\n             metrics = ['accuracy'])","de6f5da3":"## Fitting the model, with early stopping callback\n\nearlystop_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights =True)\n\nmodel_history = model.fit(xtrain,ytrain, epochs=200,\n                         validation_data=(xvalid,yvalid),\n                         callbacks=[earlystop_cb])","28c75190":"# model.save('model1.h5')","76e0018a":"pd.DataFrame(model_history.history).plot()","b705c9f5":"## Evaluating the model\n\nloss, accuracy = model.evaluate(xtest,ytest)\nprint(f'Loss = {loss:.2f}\\naccuracy = {accuracy*100:.2f}%')","abca8bf9":"## Making predictions\n\nprob = model.predict(xtest)\npred = np.argmax(prob, axis=-1)\n","6cc67ae5":"# print(prob[1])\nplt.figure(figsize=(30,30))\nfor i in range(50):\n    ax = plt.subplot(5,10,i+1)\n    ax.imshow(xtest[i])\n    ax.set_title(f'predicted: {classes[pred[i]]}\\nactual:{classes[test_y[i]]}')\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","9304e685":"# Evaluating model performance and making predictions","fbc9ad78":"# Preprocessing\n- The average dimensions of all images is about 50x50 pixels.\n- All images are resized to (50,50) pixels and saved as numpy array\n- The data is normalized and the labels are One Hot encoded","a6046d1e":"# Creating CNN model\n- Data is split into training and validation data\n- The CNN model contains two blocks, each containing two convolutional layers connected to one Max pooling layer\n- This is then connected to a fully connected NN with dropout layers in between.\n- The model is compiled with a SGD optimizer and loss function as categorical crossentropy","6b48f71c":"# Loading the data\n- The data consist of over 50000 images of traffic signs beloging to 43 different classes.\n- The `Meta` folder contains a image from each class\n- The `Train` folder has over 39000 images for training and `Test' folder contains about 12000 images.\n- The csv files contain image dimension, its path and corresponding label.","e6ffcd4c":"# Traffic Sign Recognition","764d17db":"<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRYRi6lFq1cnXbxTuxZOfee1IeA7V4oZyOhlLChG-SDQeec3dPK54VtiF1YzHYP4vjYYnE&usqp=CAU\" width=100%>"}}