{"cell_type":{"d3df47a5":"code","9b979e21":"code","e0eb0927":"code","e5d4f214":"code","4cdd215f":"code","536d7bfa":"code","e2cc1186":"code","eb779c4c":"code","ade45322":"code","5dc6a806":"code","ec558f9e":"code","30faf570":"code","1761a2c4":"code","dfbf4142":"code","e0107794":"code","e01c4d9f":"code","a8fd4c5a":"code","49e8ecfb":"code","bd82fa87":"code","1441d313":"code","a4878ddb":"code","3f966559":"code","e28785a2":"code","fc9504be":"code","7595ccb1":"markdown","140ee6f1":"markdown","1aa1eef1":"markdown","91477ac6":"markdown","d5d6de40":"markdown","ea8505ce":"markdown","a608bcc1":"markdown","72830e49":"markdown","1ca79eac":"markdown","0b046456":"markdown","c455b857":"markdown"},"source":{"d3df47a5":"from IPython.display import Image\n!wget -q https:\/\/m.media-amazon.com\/images\/I\/61sWhGZ5waL.jpg\nImage(\"61sWhGZ5waL.jpg\")","9b979e21":"# importing libraries\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport shutil # to upzip\nfrom tqdm import tqdm # for progress bar\n\n# Libraries for TensorFlow\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, layers\n\n# Library for Transfer Learning\nfrom tensorflow.keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\n# from PIL import Image #image manipulation\n\n# %tensorboard --logdir .\/kaggle\/working\/\nimport tensorflow as tf\nimport datetime\nfrom tensorflow.keras.callbacks import TensorBoard\n\nprint(\"Importing libraries completed.\")","e0eb0927":"# Downloading data\n\n!wget -q https:\/\/storage.googleapis.com\/ibeans\/train.zip\n\n!wget -q https:\/\/storage.googleapis.com\/ibeans\/validation.zip\n\n!wget -q https:\/\/storage.googleapis.com\/ibeans\/test.zip\n    \nprint(\"Data downloading comleted.\")","e5d4f214":"# Unzipping the data\n\n# For Kaggle\nshutil.unpack_archive(\"train.zip\", \"\/kaggle\/working\")\nshutil.unpack_archive(\"validation.zip\", \"\/kaggle\/working\")\nshutil.unpack_archive(\"test.zip\", \"\/kaggle\/working\")\n\n# For Colab\n# shutil.unpack_archive(\"train.zip\", \"\/content\/sample_data\")\n# shutil.unpack_archive(\"validation.zip\", \"\/content\/sample_data\")\n# shutil.unpack_archive(\"test.zip\", \"\/content\/sample_data\")\n\nprint(\"Data unzipped successfully.\")","4cdd215f":"# listing the folders containing images\n\n# Main Dataset\nmain_folder=\"\/kaggle\/working\/train\"\nclass_names=os.listdir(main_folder)\nprint(class_names)\nprint(\"\\n\")\n\n# Function to know the name of element\ndef Get_Element_Name(argument):\n    switcher = {\n        \"bean_rust\": \"Bean Rust\",\n        \"angular_leaf_spot\": \"Angular Leaf Spot\",\n        \"healthy\": \"Healthy\",\n    }\n    return switcher.get(argument, \"Invalid element.\")\n\n# Test Dataset\ntest_folder=\"\/kaggle\/working\/test\"\ntest_class_names=os.listdir(test_folder)\nprint(test_class_names)\nprint(\"\\n\")\n\n# Validation Dataset\nvalidation_folder=\"\/kaggle\/working\/validation\"\nval_class_names=os.listdir(validation_folder)\nprint(val_class_names)\n\nprint(\"\\nSwitcher tested successfully: \"+Get_Element_Name(\"bean_rust\"))\nprint(\"Preparing array for Training, Testing and Validation completed.\")","536d7bfa":"# Preparing Training image data (image array and class name) for processing\n\n# Declaring variables\nx=[] # to store array value of the images\ny=[] # to store the labels of the images\n\n# counts of the images\ntrain_bean_rust_count=0\ntrain_angular_leaf_spot_count=0\ntrain_healthy_count=0\n\nfor folder in tqdm(os.listdir(main_folder)):\n    image_list=os.listdir(main_folder+\"\/\"+folder)\n#     print(image_list)\n    for img_name in image_list:\n        if img_name == \"healthy_train.120tore\":\n            break\n        # Loading images\n        path= main_folder+\"\/\"+folder+\"\/\"+img_name\n        \n        if str(folder)==\"bean_rust\":\n            train_bean_rust_count=train_bean_rust_count+1\n        elif str(folder)==\"angular_leaf_spot\":\n            train_angular_leaf_spot_count=train_angular_leaf_spot_count+1\n        else:\n            train_healthy_count=train_healthy_count+1\n\n        if os.path.isfile(path):\n            img=image.load_img(main_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(224,224))\n\n            # Converting to arrary\n            img=image.img_to_array(img)\n\n            # Transfer Learning: this is to apply preprocess of VGG16 model to our images before passing it to VGG16\n            img=preprocess_input(img) #  Optional step\n\n            # Appending the arrarys\n            x.append(img) # appending image array\n            y.append(class_names.index(folder)) # appending class index to the array\n        \nprint(\"Preparing Training Dataset Completed.\")\nprint(str(train_bean_rust_count) + \", \" + str(train_angular_leaf_spot_count) + \", \" + str(train_healthy_count))","e2cc1186":"# Preparing validation images data (image array and class name) for processing\n\n# Declaring variables\nval_images=[]\nval_images_Original=[]\nval_image_label=[] # to store the labels of the images\n\n# counts of the images\nval_bean_rust_count=0\nval_angular_leaf_spot_count=0\nval_healthy_count=0\n\nfor folder in tqdm(os.listdir(validation_folder)):\n    image_list=os.listdir(validation_folder+\"\/\"+folder)\n    for img_name in image_list:\n        \n        path= validation_folder+\"\/\"+folder+\"\/\"+img_name\n        \n        if str(folder)==\"bean_rust\":\n            val_bean_rust_count=val_bean_rust_count+1\n        elif str(folder)==\"angular_leaf_spot\":\n            val_angular_leaf_spot_count=val_angular_leaf_spot_count+1\n        else:\n            val_healthy_count=val_healthy_count+1\n        \n        if os.path.isfile(path):\n            \n            # Loading images\n            img=image.load_img(validation_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(224,224))\n\n            # Converting to arrarys\n            img=image.img_to_array(img)\n\n            # Saving original images, will be used just for display at the end\n            val_images_Original.append(img.copy())\n\n            # Transfer Learning: this is to apply preprocess of VGG16 to our images before passing it to VGG16\n            img=preprocess_input(img) #  Optional step\n\n            # Appending arrays\n            val_images.append(img) # appending image array\n            val_image_label.append(val_class_names.index(folder))\n        \nprint(\"Preparing Validation Dataset Completed.\")\nprint(str(val_bean_rust_count) + \", \" + str(val_angular_leaf_spot_count) + \", \" + str(val_healthy_count))","eb779c4c":"# Preparing validation images data (image array and class name) for processing\n\n# Declaring variables\ntest_images=[]\ntest_images_Original=[]\ntest_image_label=[] # to store the labels of the images\n\n# counts of the images\ntest_bean_rust_count=0\ntest_angular_leaf_spot_count=0\ntest_healthy_count=0\n\nfor folder in tqdm(os.listdir(test_folder)):\n    image_list=os.listdir(test_folder+\"\/\"+folder)\n    for img_name in image_list:\n        path= test_folder+\"\/\"+folder+\"\/\"+img_name\n        \n        if str(folder)==\"bean_rust\":\n            test_bean_rust_count=test_bean_rust_count+1\n        elif str(folder)==\"angular_leaf_spot\":\n            test_angular_leaf_spot_count=test_angular_leaf_spot_count+1\n        else:\n            test_healthy_count=test_healthy_count+1\n        \n        if os.path.isfile(path):\n            # Loading images\n            img=image.load_img(test_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(224,224))\n\n            # Converting to arrarys\n            img=image.img_to_array(img)\n\n            # Saving original images, will be used just for display at the end\n            test_images_Original.append(img.copy())\n\n            # Transfer Learning: this is to apply preprocess of VGG16 to our images before passing it to VGG16\n            img=preprocess_input(img) #  Optional step\n\n            # Appending arrays\n            test_images.append(img) # appending image array\n            test_image_label.append(test_class_names.index(folder))\n        \nprint(\"Preparing Test Dataset Completed.\")\nprint(str(test_bean_rust_count) + \", \" + str(test_angular_leaf_spot_count) + \", \" + str(test_healthy_count))","ade45322":"# Creating the Second Dataframe using dictionary \n\n\ndf_train = pd.DataFrame({\"Bean Rust Count\":[train_bean_rust_count], \n                         \"Angular Leaf Spot Count\":[train_angular_leaf_spot_count], \n                         \"Healthy Count\":[train_healthy_count]\n                        }) \nprint(\"Train dataset\")\nprint(df_train.head())\n\n\ndf_test = pd.DataFrame({\"Bean Rust Count\":[test_bean_rust_count], \n                         \"Angular Leaf Spot Count\":[test_angular_leaf_spot_count], \n                         \"Healthy Count\":[test_healthy_count]\n                        }) \nprint(\"\\nTest dataset\")\nprint(df_test.head())\n\n\ndf_val = pd.DataFrame({\"Bean Rust Count\":[val_bean_rust_count], \n                         \"Angular Leaf Spot Count\":[val_angular_leaf_spot_count], \n                         \"Healthy Count\":[val_healthy_count]\n                        }) \nprint(\"\\nValidation dataset\")\nprint(df_val.head())","5dc6a806":"# Verifying the output\n\n# Training Dataset\nprint(\"Training Dataset\")\n\nx=np.array(x) # Converting to np arrary to pass to the model\nprint(x.shape)\n\ny=to_categorical(y) # onehot encoding of the labels\n# print(y)\nprint(y.shape)\n\n# Test Dataset\nprint(\"Test Dataset\")\n\ntest_images=np.array(test_images) \nprint(test_images.shape)\n\ntest_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\nprint(test_image_label.shape)\n\n\n# Validation Dataset\nprint(\"Validation Dataset\")\n\nval_images=np.array(val_images) \nprint(val_images.shape)\n\nval_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\nprint(val_image_label.shape)","ec558f9e":"# Check properties of the model that we are going to use for Transfer Learning\n\nprint(\"Printing summary of default VGG16 model.\\n\")\n\n# we are using VGG16 for transfer learnin here. So we have imported it\nfrom tensorflow.keras.applications import VGG16\n\n# initializing model with weights='imagenet'i.e. we are carring its original weights\nmodel_vgg16=VGG16(weights='imagenet')\n\n# display the summary to see the properties of the model\nmodel_vgg16.summary()\n\nprint(\"Printing summary of default VGG16 model is completd!\")","30faf570":"# Modelling WITH Transfer Learning\n\n# Here we will prepare model as per our requirements\n\nprint(\"Summary of Custom VGG16 model.\\n\")\nprint(\"1) We setup input layer and 2) We removed top (last) layer. \\n\")\n\n# let us prepare our input_layer to pass our image size. default is (224,224,3). we will change it to (224,224,3)\ninput_layer=layers.Input(shape=(224,224,3))\n\n# initialize the transfer model VGG16 with appropriate properties per our need.\n# we are passing paramers as following\n# 1) weights='imagenet' - Using this we are carring weights as of original weights.\n# 2) input_tensor to pass the VGG16 using input_tensor\n# 3) we want to change the last layer so we are not including top layer\nmodel_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n\n# See the summary of the model with our properties.\nmodel_vgg16.summary()","1761a2c4":"# access the current last layer of the model and add flatten and dense after it\n\nprint(\"Summary of Custom VGG16 model.\\n\")\nprint(\"1) We flatten the last layer and added 1 Dense layer and 1 output layer.\\n\")\n\nlast_layer=model_vgg16.output # we are taking last layer of the model\n\n# Add flatten layer: we are extending Neural Network by adding flattn layer\nflatten=layers.Flatten()(last_layer) \n\n# Add dense layer\ndense1=layers.Dense(100,activation='relu')(flatten)\ndense1=layers.Dense(100,activation='relu')(flatten)\ndense1=layers.Dense(100,activation='relu')(flatten)\n\n\n# Add dense layer to the final output layer\noutput_layer=layers.Dense(3,activation='softmax')(flatten)\n\n# Creating modle with input and output layer\nmodel=models.Model(inputs=input_layer,outputs=output_layer)\n\n# Summarize the model\nmodel.summary()","dfbf4142":"# we will freez all the layers except the last layer\n\n# we are making all the layers intrainable except the last layer\nprint(\"We are making all the layers intrainable except the last layer. \\n\")\nfor layer in model.layers[:-1]:\n    layer.trainable=False\nmodel.summary()","e0107794":"# Spliting the data into train and test\n\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=5)\n# print(xtrain)\n# print(xtest)\n# print(ytrain)\n# print(ytest)\n\nprint(\"Splitting data for train and test completed.\")","e01c4d9f":"# Compiling Model\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nprint(\"Model compilation completed.\")","a8fd4c5a":"# Tensorboard settings\n\n# Load the extension and start TensorBoard\n# %load_ext tensorboard\n%reload_ext tensorboard\n%tensorboard --logdir logs\n\n# defining log directory\n# log_dir = \".\/kaggle\/working\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlog_dir = \"logs\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ntensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nprint(\"Tensorboard settings completed.\")\nprint(\"\\nThis code will give error as Kaggle does not support Tensorboard at the moment!\")","49e8ecfb":"# Fit the Model\n\nhistory=model.fit(xtrain,ytrain,epochs=20,batch_size=128,verbose=True,\n          validation_data=(xtest,ytest),callbacks=[tensorboard_callback])\n\nprint(\"Fitting the model completed.\")","bd82fa87":"# Functions\n\n# Function 1\n# This function helps to predict individual image supplied to it\n\ndef predict(img_name):\n    img=image.load_img(img_name,target_size=(224,224))\n    img=image.img_to_array(img)\n    plt.imshow(img.astype('int32'))\n    plt.show()\n    img=preprocess_input(img)\n    \n    prediction=model.predict(img.reshape(1,224,224,3))\n    output=np.argmax(prediction)\n    \n    print(class_names[output] + \": \" + Get_Element_Name(class_names[output]))\n\nprint(\"Function 1 defined successfully.\")\n\n\n# Function 2\n# This function plots the image supplied in array\n\ndef plot_image(i, predictions_array, true_label, img): # taking index and 3 arrays viz. prediction array, true label array and image array\n\n    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n    \n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    \n    plt.imshow(img.astype('int32'))\n    \n    predicted_label=np.argmax(predictions_array)\n    true_label=np.argmax(true_label)\n#     print(\"true_label: \" + str(true_label) + \" val_class_names[true_label]: \" + val_class_names[true_label] + \" Get_Element_Name: \" + Get_Element_Name(val_class_names[true_label]))\n#     print(\"predicted_label: \" + str(predicted_label) + \" val_class_names[predicted_label]: \" + val_class_names[predicted_label] + \" Get_Element_Name: \" + Get_Element_Name(val_class_names[predicted_label]))\n\n    if predicted_label == true_label: #setting up label color\n        color='green' # correct then blue colour\n    else:\n        color='red' # wrong then red colour\n    \n    plt.xlabel(\"{} {:2.0f}% \\n ({})\".format(Get_Element_Name(val_class_names[predicted_label]), \n                                            100*np.max(predictions_array), Get_Element_Name(val_class_names[true_label]), \n                                            color=color, horizontalalignment='left'))\n    \n#     plt.xlabel(\"{} {:2.0f}% ({})\".format(val_class_names[predicted_label], \n#                                          100*np.max(predictions_array), val_class_names[true_label]), \n#                                          color=color)\n\nprint(\"Function 2 defined successfully.\")\n\n\n# Function 3\n# This function plots bar chart supplied in the array data\n\ndef plot_value_array(i, predictions_array, true_label): # taking index along with predictions and true label array\n    predictions_array, true_label = predictions_array[i], true_label[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    predicted_label=np.argmax(predictions_array)\n    true_label=np.argmax(true_label)\n\n    if predicted_label == 0:\n        predicted_label=1\n    if true_label == 0:\n        true_label=1\n    \n    thisplot=plt.bar(range(10), predicted_label, color='seashell')\n    plt.ylim([0,1])\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('green')\n\nprint(\"Function 3 defined successfully.\")","1441d313":"# Preparing prediction arrary\n\npredictions=[]\n   \nfor img in tqdm(val_images):\n    img=img.reshape(1,224,224,3)\n    predictions.append(model.predict(img))","a4878ddb":"# Prediction of individual images taken from internet\n\n# # Bean Rust\n# !wget -q https:\/\/media.sciencephoto.com\/image\/c0124704\/800wm\/C0124704-Phaseolus_bean_rust.jpg\n# predict('C0124704-Phaseolus_bean_rust.jpg') \n    \n# # Angular leaf spot\n# !wget -q https:\/\/m.farms.com\/Portals\/0\/angular-leaf-spot-300-1_1_1.png\n# predict('angular-leaf-spot-300-1_1_1.png')\n\n# # Healthy\n# !wget -q https:\/\/m.media-amazon.com\/images\/I\/61sWhGZ5waL.jpg\n# predict('61sWhGZ5waL.jpg')\n\n\n# call the function\n\n# defining parameters to pass to function\ni=random.randrange(1, 133) # image number 12. You may change value of i for play around\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\n# we are passing \"val_images_Original\" just to show original image instead of \"val_images\" \n# which is preprocessed as VGG16 process and used for prediction.\nplot_image(i,predictions, val_image_label, val_images_Original) \nplt.subplot(1,2,2)\nplot_value_array(i, predictions, val_image_label)\nplt.show()","3f966559":"# Declaring variables\nnum_rows=5\nnum_cols=5\nnum_images=num_rows*num_cols\n\nplt.figure(figsize=(2*2*num_cols,2*num_rows))\n\nprint(\"Classification using Transfer Learning (VGG16)\\n\")\nprint(\"Predicted, Percentage, (Original)\\n\")\n\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    ii=random.randrange(1,133)\n    # we are passing \"val_images_Original\" just to show original image instead of \"val_images\" \n    # which is preprocessed as VGG16 process and used for prediction.\n    plot_image(ii,predictions, val_image_label, val_images_Original)\n    \n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n\n    plot_value_array(i, predictions, val_image_label)\nplt.subplots_adjust(hspace=0.5)\nplt.show()","e28785a2":"# plot the loss and accuracy\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\nplt.show()\n\nprint(\"Plotting loss and accuracy completed.\")","fc9504be":"print(\"Notebook completed.\")","7595ccb1":"## **Observations:**\n1. We want to carry weights as it was in original model, so we are carring weights = 'imagenet'\n2. The very first layer is input layer which accept image size = (224, 224, 3). Our image size are different, so we need to change the parameter - image_size in the first layer. Our size will be: (224,224, 3)\n3. We want to change the last layer as we have 10 class classificatoin problem. So, we will not include top layer\n4. Also, we will not train all the layers except the last one as we will have to train that. So, we will set properties for trainable = False excet for the top i.e. last layer.","140ee6f1":"## Visualization of data","1aa1eef1":"**Observation:**\n\n1. The first layer is having image size = (224,224,3) now as we defined.\n1. Also, see the folloiwng 2 top (last) layers which were there in original VGG16 are now not the part of our customized layer because we set include_top=False:\n\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000     ","91477ac6":"# 5. Building a Model: Using Transfer Learning","d5d6de40":"# 4. Verification of Data","ea8505ce":"# 6. Model Evaluation","a608bcc1":"# 7. Predictions","72830e49":"# 1. Importing Libraries","1ca79eac":"# 3. Preparing Data","0b046456":"# 2. Data Gethering","c455b857":" # Image Classification using Transfer Learning - VGG16\n \n**Transfer learning (TL)** is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.\n(Source: https:\/\/en.wikipedia.org\/wiki\/Transfer_learning)\n\nTransfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task which is related to original task.\n\nIt is quite popular in deep learning where pre-trained models are used as the starting point on Computer Vision (CV) and Natural Language Processing (NLP) tasks. This is very helpful approach as it saves lots of time, resoureses. This way one can avail benefit of using complex models developed by others as start point and on top of it develop another.\n\nI have used 10 monkey species dataset (https:\/\/www.kaggle.com\/slothkong\/10-monkey-species) for this experiment. My whole heartedly thanks to Mario (https:\/\/www.kaggle.com\/slothkong).\n\n"}}