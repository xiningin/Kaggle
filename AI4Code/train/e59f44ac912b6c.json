{"cell_type":{"30a64925":"code","d4d318d9":"code","c0627c2b":"code","8c8eb4aa":"code","a34cc343":"code","889c4e04":"code","a8451002":"code","5475dec0":"code","eae41a39":"code","ac686d1f":"code","11d9a6ce":"code","06cb63cc":"code","046fad8f":"code","35f8b1b6":"code","41d3a4c0":"code","a17f38eb":"code","5126f009":"code","8adcf4a0":"code","11793976":"code","fd6753b9":"code","6813db45":"code","4a7bf11b":"code","113c8541":"code","8017cc02":"code","5e086170":"code","d96f7bdd":"code","703b8c7e":"code","d17f8231":"code","d96a49a8":"code","c8c956d5":"code","864e0b49":"code","faae9aab":"markdown","3b4d5fce":"markdown","c7ee4756":"markdown","1666b3a2":"markdown","9ba4b328":"markdown","4157b804":"markdown","22672e1b":"markdown","4b8e802c":"markdown","eb3e533c":"markdown","7ed9c933":"markdown","dddad14f":"markdown","3cdaeb5b":"markdown","ddc4b83c":"markdown","4b483cfd":"markdown","c4326483":"markdown","8447622b":"markdown","4b383ca6":"markdown","56f8dbbe":"markdown","de5a9ba4":"markdown","41fac769":"markdown","96e53a37":"markdown"},"source":{"30a64925":"# Import everything we need\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt, image as mpimg\nfrom tqdm import tqdm\nfrom time import time\nfrom collections import Counter\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers, optimizers, losses, metrics, utils, callbacks, applications\nfrom sklearn.model_selection import train_test_split as tts\nimport cv2 as cv\n\n# Image size: 1024px x 1024px (x 3 color (RGB) channels)\nIMG_SIZE = 1024\n\n# Batch size: 32 images\nBATCH_SIZE = 32\n\n# Paths to directories\n\ntrain_dir = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/ODIR-5K\/Training Images'\ntest_dir = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/ODIR-5K\/Testing Images'\nmain_dir = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/ODIR-5K'\n\nhistory_dir = '\/kaggle\/working\/history'\nif not os.path.isdir(history_dir):\n    os.mkdir(history_dir)\n\n    models_dir = '\/kaggle\/working\/models'\nif not os.path.isdir(models_dir):\n    os.mkdir(models_dir)\n\n\n\n# A function to load and preprocess image (clip out the black background and resize it properly)\n\ndef load_prep_img(image_path, target_shape=(IMG_SIZE, IMG_SIZE)):\n    image = cv.imread(image_path, cv.IMREAD_COLOR) # load from the directory\n    non_0_rows = np.array([row_idx for row_idx, row in enumerate(image) if np.count_nonzero(row)!=0])\n    non_0_cols = np.array([col_idx for col_idx, col in enumerate(image.transpose(1,0,2)) if np.count_nonzero(col)!=0])\n    image = image[non_0_rows.min():non_0_rows.max()+1, non_0_cols.min():non_0_cols.max()+1, :] # clip\n    image = cv.resize(image, target_shape)\n    return image\n    \n\n# Function test:\nimage_path = os.path.join(train_dir, os.listdir(train_dir)[0])\n\nimage = cv.imread(image_path, cv.IMREAD_COLOR)\nprint('Original (raw) image:\\t',image.shape)\nplt.imshow(image)\nplt.show()\n\nimage_prepped = load_prep_img(image_path)\nprint('Preprocessed image:\\t', image_prepped.shape)\nplt.imshow(image_prepped)\nplt.show()","d4d318d9":"data = pd.read_excel(os.path.join(main_dir, 'data.xlsx'))\ndata.head()","c0627c2b":"classes = list(data.columns[7:15])\ndata['Patient Labels'] = data.apply(lambda x:[class_ for class_ in classes if x[class_]==1], axis=1)\ndata.head()","8c8eb4aa":"# Names of columns in the DataFrame\ncol_names = ['Image', 'Keywords', 'Age', 'Sex', 'Patient Labels']\n\n# DataFrame for left-eye images\neyes_L = data[['Left-Fundus', 'Left-Diagnostic Keywords', 'Patient Age', 'Patient Sex', 'Patient Labels']]\neyes_L.columns = col_names\n\n# DataFrame for right-eye images\neyes_R = data[['Right-Fundus', 'Right-Diagnostic Keywords', 'Patient Age', 'Patient Sex', 'Patient Labels']]\neyes_R.columns = col_names\n\n# DataFrame for left-eye and right-eye images combined\neyes_df = pd.concat([eyes_L, eyes_R], axis=0)\n\neyes_df","a34cc343":"# Keywords characteristic for 'O' class:\n\nO_keywords = [\n    'macular epiretinal membrane',\n    'epiretinal membrane',\n    'drusen',\n    #'lens dust',\n    'myelinated nerve fibers',\n    'laser spot',\n    'vitreous degeneration',\n    'refractive media opacity',\n    'spotted membranous change',\n    'tessellated fundus',\n    'maculopathy',\n    'chorioretinal atrophy',\n    'branch retinal vein occlusion',\n    'retinal pigmentation',\n    'white vessel',\n    'post retinal laser surgery',\n    'epiretinal membrane over the macula',\n    'retinitis pigmentosa',\n    'central retinal vein occlusion',\n    'optic disc edema',\n    'post laser photocoagulation',\n    'retinochoroidal coloboma',\n    'atrophic change',\n    'optic nerve atrophy',\n    'old branch retinal vein occlusion',\n    'depigmentation of the retinal pigment epithelium',\n    'chorioretinal atrophy with pigmentation proliferation',\n    'central retinal artery occlusion',\n    'old chorioretinopathy',\n    'pigment epithelium proliferation',\n    'retina fold',\n    'abnormal pigment ',\n    'idiopathic choroidal neovascularization',\n    'branch retinal artery occlusion',\n    'vessel tortuosity',\n    'pigmentation disorder',\n    'rhegmatogenous retinal detachment',\n    'macular hole',\n    'morning glory syndrome',\n    'atrophy',\n    #'low image quality',\n    'arteriosclerosis',\n    'asteroid hyalosis',\n    'congenital choroidal coloboma',\n    'macular coloboma',\n    'optic discitis',\n    'oval yellow-white atrophy',\n    'wedge-shaped change',\n    'wedge white line change',\n    'retinal artery macroaneurysm',\n    'retinal vascular sheathing',\n    'suspected abnormal color of  optic disc',\n    'suspected retinal vascular sheathing',\n    'suspected retinitis pigmentosa',\n    'silicone oil eye',\n    'fundus laser photocoagulation spots',\n    'glial remnants anterior to the optic disc',\n    'intraretinal microvascular abnormality'\n    \n\n]","889c4e04":"def generate_eye_labels(keywords, patient_labels):\n    eye_labels = []\n    \n    if 'normal fundus' in keywords:\n        eye_labels.append('N')\n        if list(set(keywords.replace('\uff0c', ',').split(',')))==['normal fundus']: # there were two images, for which 'normal fundus' keyphrase was duplicated\n            eye_labels.append('N+') # healthy fundus without any caveats (like lens dust or low image quality)\n            return eye_labels # in this case we know that there are no other keywords, so we can already quit the function and return the list\n        else:\n            eye_labels.append('N-') # healthy fundus but with some caveats\n    if 'lens dust' in keywords:\n        eye_labels.append('LD') # lens dust\n    if 'low image quality' in keywords:\n        eye_labels.append('LIQ') # low image quality\n    if 'D' in patient_labels and ('proliferative retinopathy' in keywords or 'diabetic' in keywords):\n        eye_labels.append('D') # diabetes\n    if 'suspected glaucoma' in keywords:\n        eye_labels.append('SG') # suspected glaucoma (it may be real glaucoma or may not)\n    elif 'glaucoma' in keywords:\n        eye_labels.append('G') # glaucoma\n    if 'cataract' in keywords:\n        eye_labels.append('C') # cataract\n    if 'age-related' in keywords:\n        eye_labels.append('A') # AMD\n    if 'hypertensi' in keywords:\n        eye_labels.append('H') # hypertension\n    if 'myopi' in keywords:\n        eye_labels.append('M') # myopia\n    if 'O' in patient_labels and (any(O_keyword in keywords for O_keyword in O_keywords)):\n        eye_labels.append('O') # other (anything else)\n    return eye_labels\n\n\n\n\neyes_df['Eye Labels'] = eyes_df.apply(lambda x: generate_eye_labels(x['Keywords'], x['Patient Labels']), axis=1)\neyes_df","a8451002":"c = Counter()\nfor eye_label in eyes_df['Eye Labels']:\n    c[tuple(eye_label)] +=1 \nc","5475dec0":"def extract_dataframe(criteria=['C'], n_max=0, shuffle=True, df=eyes_df):\n    if type(criteria)!=type(list()):\n        criteria = [criteria]\n    disease_criteria = [criterion for criterion in criteria if criterion!='Male' and criterion!='Female']\n    \n    if disease_criteria==[]:\n        df['extract'] = 1\n    else:\n        df['extract'] = df['Eye Labels'].apply(lambda x: 1 if all(criterion in x for criterion in disease_criteria) else 0)\n    \n    if 'Male' in criteria:\n        df['extract'] = df['extract'] * df['Sex'].apply(lambda x: 1 if x=='Male' else 0 )\n    elif 'Female' in criteria:\n        df['extract'] = df['extract'] * df['Sex'].apply(lambda x: 1 if x=='Female' else 0 )\n        \n    extract_df = df.query(' `extract` == 1 ')\n    extract_df.drop('extract', axis=1, inplace=True)\n    df.drop('extract', axis=1, inplace=True)\n    if shuffle:\n        extract_df = extract_df.sample(frac=1)\n    extract_df.reset_index(drop=True, inplace=True)\n    if n_max!=0:\n        extract_df = extract_df.iloc[:n_max, :]\n    \n    return extract_df\n\n\n","eae41a39":"males_with_cataract_df = extract_dataframe(['C', 'Male'])\nprint(males_with_cataract_df['Eye Labels'].value_counts()) # Distribution of eye labels in males with cataract\nprint(males_with_cataract_df['Patient Labels'].value_counts()) # Distribution of patient labels in males with cataract\nprint(males_with_cataract_df['Sex'].value_counts()) # Distribution of sexes in males with cataract - unsurprisingly boring\nmales_with_cataract_df","ac686d1f":"all_eye_labels = [*classes, 'N-', 'N+','LD','LIQ','SG']\nfor criterion in [*all_eye_labels, 'Male', 'Female']:\n    print(criterion, extract_dataframe(criterion).shape[0])","11d9a6ce":"print(\"There are %i images of perfectly healthy male eyes in the dataset\" % extract_dataframe(['Male','N+']).shape[0])\nprint(\"There are %i images of perfectly healthy female eyes in the dataset\" % extract_dataframe(['Female', 'N+']).shape[0])\nprint(\"There are %i images of perfectly healthy eyes in total in the dataset\" % extract_dataframe(['N+']).shape[0])","06cb63cc":"# Load the extractor - pre-trained ResNet152\nextractor = applications.ResNet152(include_top=False, weights='imagenet', pooling='max', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\ndef extract_features(extract_df, directory=train_dir, verbose=True):\n    if verbose:\n        print(extract_df.shape[0], \"images are being processed...\")\n    extracts = []\n    for i, row in tqdm(extract_df.iterrows()):\n        image_path = os.path.join(directory, row['Image'])\n        image = load_prep_img(image_path, (IMG_SIZE, IMG_SIZE)).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n        extract = extractor.predict(image)\n        extracts.append(extract)\n    \n    return np.array(extracts).reshape(-1,2048)","046fad8f":"n_max = 1024\n\nN_extracts = extract_features(extract_df=extract_dataframe(criteria='N+', n_max=n_max))\nN_labels = np.zeros(shape=(n_max,))\n\nprint(N_extracts.shape, N_labels.shape)","35f8b1b6":"# A function for splitting data into training, validation, and testing sets of given relative sizes\ndef tvt_split(X, y, split_sizes=[8,1,1], stratify=True):\n    split_sizes = np.array(split_sizes)\n    if stratify:\n        train_X, test_X, train_y, test_y = tts(X, y, test_size=split_sizes[2]\/split_sizes.sum(), stratify=y)\n        train_X, val_X, train_y, val_y = tts(train_X, train_y, test_size=split_sizes[1]\/(split_sizes[0]+split_sizes[1]), stratify=train_y)\n    else:\n        train_X, test_X, train_y, test_y = tts(X, y, test_size=split_sizes[2]\/split_sizes.sum())\n        train_X, val_X, train_y, val_y = tts(train_X, train_y, test_size=split_sizes[1]\/(split_sizes[0]+split_sizes[1]))\n    return train_X, val_X, test_X, train_y, val_y, test_y\n\n# A function generating training, validation, and test sets, given the criteria and maximum number of examples per (positive or negative) class\ndef generate_datasets(criteria=['C'], n_max=1024):\n    X_extracts = extract_features(extract_dataframe(criteria, n_max=n_max))\n    X_n = X_extracts.shape[0]\n    X_labels = np.ones(shape=(X_n))\n    \n    extracts = np.concatenate([X_extracts, N_extracts[:X_n, :]], axis=0) # Previously generated extracts of healthy eyes are the negative class\n    labels = np.concatenate([X_labels, N_labels[:X_n]], axis=0)\n    \n    return  tvt_split(extracts, labels) #train_X, val_X, test_X, train_y, val_y, test_y","41d3a4c0":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets(criteria=['D'], n_max=100)","a17f38eb":"for X, y in [[train_X, train_y], [val_X, val_y], [test_X, test_y]]:\n    print(X.shape, y.shape) # Sanity-check for the shape of each set\n    print(np.bincount(y.astype(np.int32))) # Sanity check for equal distribution of classes in each set","5126f009":"# Build a model template, whose copies will be trained to classify all the clinical conditions\n\nmodel_template = models.Sequential(name='model_template', layers=[\n    layers.Input(shape=(2048,)),\n    layers.BatchNormalization(),\n    layers.Dense(256, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(32, kernel_regularizer='l2'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(.5),\n    layers.Dense(2, activation='softmax')\n])\n\n# Callbacks for training models\ndef generate_callbacks(filepath, monitor='val_acc', mode='max'):\n    return [\n        callbacks.EarlyStopping(patience=50), # Stop training after 50 epochs of no improvement\n        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=.1, patience=20, verbose=0), # Reduce learning rate by a factor of 10, if performance hasn't been improving for 20 epochs\n        callbacks.ModelCheckpoint(filepath=filepath, monitor=monitor, mode=mode, save_best_only=True, save_freq='epoch', save_weights_only=True)\n    ]\n\n# Function to evalute the given model on the training, validation, and testing set\ndef evaluate_model(model):\n    print(\"Training set:\\tLoss: %f\\tMetric: %f\"% tuple(model.evaluate(train_X, train_y, verbose=0)))\n    print(\"Validation set:\\tLoss: %f\\tMetric: %f\"% tuple(model.evaluate(val_X, val_y, verbose=0)))\n    print(\"Testing set:\\tLoss: %f\\tMetric: %f\"% tuple(model.evaluate(test_X, test_y, verbose=0)))\n\n\nmodel_template.summary()","8adcf4a0":"def plot_history(history):\n    epochs = np.arange(1, len(history.history['loss'])+1)\n    print(\"epochs:\", len(epochs))\n    \n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    plt.plot(epochs, train_loss, 'r-', label='train_loss')\n    plt.plot(epochs, val_loss, 'g--', label='val_loss')\n    plt.legend()\n    print(\"Training and validation loss:\")\n    plt.show()\n    \n    train_acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    plt.plot(epochs, train_acc, 'r-', label='train_acc')\n    plt.plot(epochs, val_acc, 'g--', label='val_acc')\n    plt.legend()\n    print(\"Training and validation accuracy:\")\n    plt.show()\n    \n    lr = history.history['lr']\n    plt.plot(epochs, lr, 'b--', label='lr')\n    plt.legend()\n    print(\"Learning rate:\")\n    plt.show()","11793976":"# Generate datasets for diabetes\n\ntrain_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('D')","fd6753b9":"D_model = models.clone_model(model_template)\n\nD_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'D_model.h5')\nprint(model_filepath)\n\nD_history = D_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=2\n)","6813db45":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(D_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nD_model.load_weights(model_filepath)# = models.load_model(model_filepath)\nevaluate_model(D_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(D_history.history['val_acc']))","4a7bf11b":"plot_history(D_history)","113c8541":"# Generate datasets for glaucoma\n\ntrain_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('G')","8017cc02":"G_model = models.clone_model(model_template)\n\nG_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'G_model.h5')\n\nG_history = G_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","5e086170":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(G_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nG_model.load_weights(model_filepath)# = models.load_model(model_filepath)\nevaluate_model(G_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(G_history.history['val_acc']))\n\nplot_history(G_history)","d96f7bdd":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('C')","703b8c7e":"C_model = models.clone_model(model_template)\n\nC_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'C_model.h5')\n\nC_history = C_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","d17f8231":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(C_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nC_model.load_weights(model_filepath)# = models.load_model(model_filepath)\nevaluate_model(C_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(C_history.history['val_acc']))\n\nplot_history(C_history)","d96a49a8":"train_X, val_X, test_X, train_y, val_y, test_y = generate_datasets('A')","c8c956d5":"A_model = models.clone_model(model_template)\n\nA_model.compile(\n    optimizer = optimizers.RMSprop(1e-5),\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\nmodel_filepath = os.path.join(models_dir, 'A_model.h5')\n\nA_history = A_model.fit(\n    train_X, train_y,\n    validation_data = (val_X, val_y),\n    epochs = 256, batch_size = BATCH_SIZE,\n    shuffle = True,\n    callbacks = generate_callbacks(filepath=model_filepath),\n    verbose=0\n)","864e0b49":"print(\"\\tEvaluation of the model at the end of training\\n\")\nevaluate_model(A_model)\n\nprint(\"\\n\\tEvaluation of the model instance at the best point in the training (the highest validation accuracy)\\n\")\nA_model.load_weights(model_filepath)\nevaluate_model(A_model)\n\nprint(\"\\nThe highest validation accuracy achieved by this model was\", np.max(A_history.history['val_acc']))\n\nplot_history(A_history)","faae9aab":"How many images with each combination of labels are there?","3b4d5fce":"# Predicting diseases","c7ee4756":"Compress labels given to individual patients into a single column containing just a list of names of labels\/classes as single-character strings","1666b3a2":"## Glaucoma","9ba4b328":"Create a separate DataFrame, where each contains information about a single eye (or, more precisely, about an image of a particular retinal fundus).","4157b804":"Function test","22672e1b":"## Cataract","4b8e802c":"## plot_history\n","eb3e533c":"## Age-related Macular Degeneration (AMD)","7ed9c933":"## generate_datasets (+tvt_split)\n\nA function, which combines the two previous functions and generates training, validation, and testing sets ","dddad14f":"A function for extracting information about the condition of a particular eye from keywords and patient's labels.\n\nI created a few new labels:\n\nN+ for perfectly healthy eyes\nN- for healthy eyes with some caveats (like lens dust or low image quality)\nLD for lens dust\nLIQ for low image quality\nSG for suspected glaucoma, which I decided not to include among other glaucoma cases","3cdaeb5b":"Function tests","ddc4b83c":"## Diabetes","4b483cfd":"How many images can we extract for each defined criterion","c4326483":"We will obtain a set of 1024 extracts of perfectly healthy eyes to be used later as negative examples for all the diseases ","8447622b":"## model_template, generate_callback, evaluate_model\n\nSome things for building, training and evaluating models","4b383ca6":"## extract_dataframe\n\nA function to select those rows of eyes_df, which satisfy given criteria","56f8dbbe":"Read the data table ","de5a9ba4":"# Eye-row DataFrame","41fac769":"# Preparing functions for efficient data generation and model deployment","96e53a37":"## extract_features\n\nA function to load images whose filenames are contained in the DataFrame and immediately extract perform on them feature extraction with pre-trained ResNet152"}}