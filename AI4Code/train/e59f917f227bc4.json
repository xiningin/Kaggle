{"cell_type":{"66d5bbfa":"code","6965f758":"code","be01e891":"code","13952642":"code","3a12701e":"code","a9c84bf7":"code","e30a9855":"code","095d9286":"code","f1f2c6d9":"code","a668388d":"code","8778b1f7":"code","cfb5c31e":"code","10c90b94":"code","2814b065":"code","39e83188":"code","d5b2c1f2":"code","09572c87":"code","857c473b":"code","c2fed0dc":"code","ab867f9f":"code","a1651485":"code","a61d913c":"code","bee308ad":"code","a65d680f":"code","f4289c3e":"markdown","41f722c0":"markdown","919d6e19":"markdown","b67ca525":"markdown","50628d76":"markdown","e62fb8f8":"markdown","c2e404a3":"markdown","8192c43d":"markdown","13bbbd3c":"markdown","0000760b":"markdown","0f37cc12":"markdown","1f94616d":"markdown","15fcb458":"markdown","dd3368b2":"markdown","76e929c2":"markdown","19c0ccd8":"markdown","f960cd36":"markdown"},"source":{"66d5bbfa":"# Dataset handling libraries\nfrom sklearn.datasets import make_regression, load_iris, load_digits\nfrom sklearn.model_selection import train_test_split\n\n# Dataset visualising library\nimport matplotlib.pyplot as plt\n\n# Supervised Learning algorithms\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model evaluation metrics\nfrom sklearn.metrics import r2_score","6965f758":"# First, we will generate the regression dataset\nregression_dataset = make_regression(random_state=0, n_features=1, noise=15, bias=100)","be01e891":"# We will now produce a scatter plot to visualise the relationship between the predictor variable and the target variable.\nplt.scatter(regression_dataset[0], regression_dataset[1])\nplt.xlabel(\"Predictor variable (X)\")\nplt.ylabel(\"Target variable (y)\")\nplt.legend(['all observations'])","13952642":"# We will then store the predictor and target values into the X and y variables respectively (as per convention)\nX = regression_dataset[0]\ny = regression_dataset[1]\n\n# In order to create seperate sets to train and test our model, we will split it into a 70\/30 train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","3a12701e":"# A linear regression model is now initialised and fit to the training set\nlin_regr = LinearRegression()\nlin_regr.fit(X_train, y_train)","a9c84bf7":"# The equation for the line that the linear regression has generated is then printed\nprint(\"Y = {}X + {}\".format(round(lin_regr.coef_[0],2),round(lin_regr.intercept_,2)))","e30a9855":"# The test set values are predicted (the target variable is predicted based on the predictor variable)\ny_pred = lin_regr.predict(X_test)","095d9286":"# The predictions for the test set are visualised against the actual observations\nplt.scatter(X_test, y_test, color=\"black\")\nplt.plot(X_test, y_pred, color=\"blue\", linewidth=3)\nplt.xlabel(\"Predictor variable (X)\")\nplt.ylabel(\"Target variable (y)\")\nplt.legend([\"test set predictions\", \"test set observations\"])","f1f2c6d9":"# R-squared score is a statistical measure of how close the data are to the fitted regression line.\n# R-squared = Explained variation \/ Total variation\n\n#We will now print the R-squared score to evaluate the performance of the model (the closer to 100%, the better)\nprint(\"The R-squared score is {}%\".format(round(r2_score(y_test, y_pred)*100)))\n\n# More information at: https:\/\/blog.minitab.com\/blog\/adventures-in-statistics-2\/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit","a668388d":"#Loading in the iris dataset\niris_dataset = load_iris()\n\n# Printing the types of flower we need to predict\nprint(\"The three types of flower are as follows: \\n\",iris_dataset.target_names)\n# Printing the available predictor variables for each flower\nprint(\"\\nThe predictor variables for each flower are as follows: \\n\",iris_dataset.feature_names)","8778b1f7":"# We will now produce a scatter plot to visualise the first two predictor variables\nplt.scatter(iris_dataset.data[:, 0], iris_dataset.data[:, 1], c=iris_dataset.target)\nplt.xlabel(iris_dataset.feature_names[0])\nplt.ylabel(iris_dataset.feature_names[1])","cfb5c31e":"# We will also visualise the last two predictor variables\nplt.scatter(iris_dataset.data[:, 2], iris_dataset.data[:, 3], c=iris_dataset.target)\nplt.xlabel(iris_dataset.feature_names[2])\nplt.ylabel(iris_dataset.feature_names[3])","10c90b94":"# We will now store the predictor and target values into the X and y variables respectively (as per convention)\nX = iris_dataset.data\ny = iris_dataset.target\n\n# In order to create seperate sets to train and evaluate our model, we will split it into a 70\/30 train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","2814b065":"# A decision tree classifier is now initialised\ndt_clf = DecisionTreeClassifier(random_state=0)\n\n# The decision tree is fit to the data using the training set\ndt_clf.fit(X_train, y_train)","39e83188":"# A random forest classifier is now initialised\nrf_clf = RandomForestClassifier(random_state=0)\n\n# The random forest is fit to the data\nrf_clf.fit(X_train, y_train)","d5b2c1f2":"# The accuracy score of the decision tree is measured\nprint(\"The classification accuracy of the decision tree model is: {}%\".format(round(dt_clf.score(X_test, y_test)*100,2)))","09572c87":"# The accuracy score of the random forest is measured\nprint(\"The classification accuracy of the random forest model is {}%\".format(round(rf_clf.score(X_test, y_test)*100,2)))","857c473b":"# Loading in the digits dataset\ndigits_dataset = load_digits()\n\n# We will now print what the numerical representation of a digit looks like to help us understand the data.\n# Values correspond to how white a pixel is on a scale from 1 to 16.\nfor row in range(8):\n  this_row = digits_dataset.data[1][(row*8):((row+1)*8)-1]\n  print(this_row)\n\n# This is what a sample looks like.\n# You may notice that this looks like a number \"1\"","c2fed0dc":"# Here are some example images from the dataset\nplt.gray()\nfor i in range(1,25):\n  plt.subplot(4, 6, i)\n  plt.imshow(digits_dataset.images[i])","ab867f9f":"# We will now store the predictor and target values into the X and y variables respectively (as per convention)\nX = digits_dataset.data\ny = digits_dataset.target\n\n# In order to create seperate sets to train and evaluate our model, we will split it into a 70\/30 train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","a1651485":"# A decision tree classifier is now initialised\ndt_clf = DecisionTreeClassifier(random_state=0)\n\n# The decision tree is fit to the data\ndt_clf.fit(X_train, y_train)","a61d913c":"# A random forest classified is now initialised\nrf_clf = RandomForestClassifier(random_state=0)\n\n# The random forest is fit to the data\nrf_clf.fit(X_train, y_train)","bee308ad":"# The accuracy score of the decision tree is measured\nprint(\"The classification accuracy of the decision tree model is: {}%\".format(round(dt_clf.score(X_test, y_test)*100,2)))","a65d680f":"# The accuracy score of the random forest is measured\nprint(\"The classification accuracy of the random forest model is {}%\".format(round(rf_clf.score(X_test, y_test)*100,2)))","f4289c3e":"# Dataset #2: Iris flower classification dataset","41f722c0":"## Modelling the dataset","919d6e19":"## Evaluating the models","b67ca525":"# Key Terminology\n\n- Training Set: A randomly sampled majority portion of the dataset (70% in this case) to be used for training the supervised learning algorithm\n- Testing Set: A randomly sampled remaining portion of the dataset (30% in this case) used to evaluate the supervised learning model\n- Predictor variable (X): Data used to predict the target variable\n- Target variable (y): Data that the algorithm is learning how to predict","50628d76":"# Welcome to this hands-on Supervised Learning tutorial\n\nIn this notebook, we will be using a selection of supervised learning algorithms to model a number of sample datasets.","e62fb8f8":"## Evaluating the model","c2e404a3":"## Evaluating the models","8192c43d":"## Understanding the dataset","13bbbd3c":"## Modelling the dataset","0000760b":"# Dataset #3: MNIST digit classification dataset\n","0f37cc12":"# Dataset #1: Generated Regression Dataset\nThis is a procedurally generated regression dataset that we will used to train a linear regression model. ","1f94616d":"## Understanding the dataset","15fcb458":"This is a dataset containing images of digits. We need to make a classifier that can predict which digit the image is resembling.","dd3368b2":"This is a dataset containing various features from three different types of flower. The challange is to create a classifier that can accurately predict the type of flower based on the selection of flower features.","76e929c2":"# Setting up the project\n\nThe first thing we need to do is import the libraries that are going to be used","19c0ccd8":"## Modelling the dataset","f960cd36":"## Understanding the dataset"}}