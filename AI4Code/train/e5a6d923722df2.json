{"cell_type":{"bbef5c4f":"code","08ed5af0":"code","490c7e16":"code","d65fe709":"code","0cecb0c9":"code","969e5fbb":"code","d03ffb3e":"code","5935559f":"code","eeae67ba":"code","cc002e71":"code","d9cabea4":"code","b2ced646":"code","3465a638":"code","32cffb10":"code","9fd3ceb6":"code","eabcc705":"code","9e97e70d":"code","c07a0d57":"markdown","bf571fee":"markdown"},"source":{"bbef5c4f":"captcha_processing_output_folder = \"..\/input\/preprocessing-and-segmenting-letters-from-captcha\/extracted_letter_images\"","08ed5af0":"!pip install imutils\n\nimport cv2\nimport imutils","490c7e16":"def resize_image_to_dimensions(image, desired_width, desired_height):\n    \"\"\"Resizes an image to the desired dimensions.\"\"\"\n    (h, w) = image.shape[:2]\n    if w > h:\n        image = imutils.resize(image, width=desired_width)\n    else:\n        image = imutils.resize(image, height=desired_height)\n    pad_width = int((desired_width - image.shape[1]) \/ 2.0)\n    pad_height = int((desired_height - image.shape[0]) \/ 2.0)\n    image_with_border = cv2.copyMakeBorder(\n        image, pad_height, pad_height, pad_width, pad_width, cv2.BORDER_REPLICATE\n    )\n    image_with_border_resized = cv2.resize(\n        image_with_border, (desired_width, desired_height)\n    )\n    return image_with_border_resized","d65fe709":"def read_image(image_file_path):\n    \"\"\"Read in an image file.\"\"\"\n    img = cv2.imread(image_file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = resize_image_to_dimensions(img, 20, 20)\n    img = np.expand_dims(img, axis=2)\n    return img","0cecb0c9":"!dir ..\/input\/preprocessing-and-segmenting-letters-from-captcha\/extracted_letter_images","969e5fbb":"import numpy as np\nimport os\nfrom imutils import paths\n\nimages = []\nlabels = []\n\nfor image_file_path in imutils.paths.list_images(captcha_processing_output_folder):\n    image_file = read_image(image_file_path)\n    label = image_file_path.split(os.path.sep)[-2]\n    images.append(image_file)\n    labels.append(label)","d03ffb3e":"images = np.array(images, dtype=\"float\") \/ 255.0\nlabels = np.array(labels)","5935559f":"from sklearn.model_selection import train_test_split\n\n(X_train, X_test, y_train, y_test) = train_test_split(\n    images, labels, test_size=0.3, random_state=11\n)","eeae67ba":"\nfrom sklearn.preprocessing import LabelBinarizer\n\nlabel_binarizer = LabelBinarizer().fit(y_train)\ny_train = label_binarizer.transform(y_train)\ny_test = label_binarizer.transform(y_test)\n","cc002e71":"from keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Flatten, Dense\n\nnum_classes = 32\nNN_model = Sequential()\nNN_model.add(\n    Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\")\n)\nNN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nNN_model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\nNN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nNN_model.add(Flatten())\nNN_model.add(Dense(512, activation=\"relu\"))\nNN_model.add(Dense(num_classes, activation=\"softmax\"))\nNN_model.compile(\n    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n)\nNN_model.summary()","d9cabea4":"NN_model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_test, y_test),\n    batch_size=16,\n    epochs=5,\n    verbose=1,\n)","b2ced646":"CAPTCHA = \"..\/input\/captcha-images\/captcha_images\/256Q.png\"","3465a638":"def find_bounding_rectangles_of_contours(contours):\n    \"\"\"Determines the bounding rectangles of the contours of the cropped letters.\"\"\"\n    letter_bounding_rectangles = []\n    for contour in contours:\n        (x, y, w, h) = cv2.boundingRect(contour)\n        if w \/ h > 1.25:\n            half_width = int(w \/ 2)\n            letter_bounding_rectangles.append((x, y, half_width, h))\n            letter_bounding_rectangles.append((x + half_width, y, half_width, h))\n        else:\n            letter_bounding_rectangles.append((x, y, w, h))\n    return letter_bounding_rectangles\n\n\ndef preprocess_CAPTCHA(img):\n    \"\"\"Takes a CAPTCHA image and thresholds it.\"\"\"\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    gray_with_border = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n    preprocessed = cv2.threshold(\n        gray_with_border, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n    )[1]\n    return gray_with_border, preprocessed\n\n\ndef get_CAPTCHA_label(path_to_file):\n    \"\"\"Get the CAPTCHA text from the file name.\"\"\"\n    filename = os.path.basename(path_to_file)\n    label = filename.split(\".\")[0]\n    return label\n\n\ndef CAPTCHA_to_gray_scale_and_bounding_rectangles(captcha_image_file):\n    \"\"\"Take a CAPTCHA and output a grayscale version as well as the bounding rectangles of its cropped letters.\"\"\"\n    image = cv2.imread(captcha_image_file)\n    gray, preprocessed = preprocess_CAPTCHA(image)\n    contours = cv2.findContours(\n        preprocessed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n    )\n    contours = contours[0]\n    letter_bounding_rectangles = find_bounding_rectangles_of_contours(contours)\n    letter_bounding_rectangles = sorted(letter_bounding_rectangles, key=lambda x: x[0])\n    return gray, letter_bounding_rectangles","32cffb10":"captcha_label = get_CAPTCHA_label(CAPTCHA)\ngray, letter_bounding_rectangles = CAPTCHA_to_gray_scale_and_bounding_rectangles(\n    CAPTCHA\n)\npredictions = []\n","9fd3ceb6":"for letter_bounding_rectangle in letter_bounding_rectangles:\n    x, y, w, h = letter_bounding_rectangle\n    letter_image = gray[y - 2 : y + h + 2, x - 2 : x + w + 2]\n    letter_image = resize_image_to_dimensions(letter_image, 20, 20)\n    letter_image = np.expand_dims(letter_image, axis=2)\n    letter_image = np.expand_dims(letter_image, axis=0)\n    prediction = NN_model.predict(letter_image)\n    letter = label_binarizer.inverse_transform(prediction)[0]\n    predictions.append(letter)","eabcc705":"predicted_captcha_text = \"\".join(predictions)\nprint(f\"predicted CAPTCHA text is: {predicted_captcha_text}\")\nprint(f\"captch text is : 256Q\")\n\n\n# it works!","9e97e70d":"import matplotlib.pyplot as plt\n\nplt.imshow(read_image(CAPTCHA))","c07a0d57":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcSOo7kT1RFyx90c6H9P3WnHYeRKOqHp-NlOdA&usqp=CAU)","bf571fee":"This notebook uses inputs from https:\/\/www.kaggle.com\/fanbyprinciple\/preprocessing-and-segmenting-letters-from-captcha\/output"}}