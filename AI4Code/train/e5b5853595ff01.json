{"cell_type":{"85638c66":"code","cdff15fc":"code","29ad0e67":"code","eae00972":"code","c85a89ac":"code","26126d61":"code","0daa71cd":"code","de2c6ac2":"code","ed53ae31":"code","de1aa143":"code","21579135":"markdown","e4601378":"markdown","77e20d32":"markdown","676ccdab":"markdown","473a1c1d":"markdown","094198c7":"markdown"},"source":{"85638c66":"import numpy as np\nimport pandas as pd\nimport cudf\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n%matplotlib inline\nimport plotly.express as px\nimport matplotlib.pyplot as plt","cdff15fc":"%%time\ntrain = cudf.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv', index_col=0)\ntest = cudf.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv', index_col=0)\n\nsample_submission = cudf.read_csv(\"..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\").to_pandas()\n\nmemory_usage = train.memory_usage(deep=True) \/ 1024 ** 2\nstart_mem = memory_usage.sum()","29ad0e67":"feature_cols = test.columns.tolist()\n\ncnt_features =[]\ncat_features =[]\n\nfor col in feature_cols:\n    if train[col].dtype=='float64':\n        cnt_features.append(col)\n    else:\n        cat_features.append(col)\n        \n\ntrain[cnt_features] = train[cnt_features].astype('float32')\ntrain[cat_features] = train[cat_features].astype('uint8')\n\ntest[cnt_features] = test[cnt_features].astype('float32')\ntest[cat_features] = test[cat_features].astype('uint8')\n\nmemory_usage = train.memory_usage(deep=True) \/ 1024 ** 2\nend_mem = memory_usage.sum()\n\ntrain = train.to_pandas()\ntest = test.to_pandas()","eae00972":"# %%time\n# # Here is a sample code for training a simple xgboost model with removing each feature one by one.\n# x_train, x_valid, y_train, y_valid = train_test_split(train[feature_cols], train[\"target\"], test_size=0.2, random_state=42)\n# scores = {}\n# feature_cols.insert(0,\"all\")\n\n# for col in feature_cols:\n#     feat = feature_cols.copy()\n#     feat.remove(col)\n#     if \"all\" in feat:\n#         feat.remove(\"all\")\n#     x_t = x_train[feat]\n#     x_v = x_valid[feat]\n\n#     xgb_params = {\n#         'eval_metric': 'auc',\n#         'objective': 'binary:logistic', \n#         'tree_method': 'gpu_hist', \n#         'predictor': 'gpu_predictor', \n#         'seed': 42, \n#         'use_label_encoder': False,\n#     }\n    \n#     xgb_model = XGBClassifier(**xgb_params)\n#     xgb_model.fit(x_t, y_train, eval_set=[(x_v, y_valid)], verbose=False)\n    \n#     preds_valid = xgb_model.predict_proba(x_v)[:,1]\n#     auc = roc_auc_score(y_valid, preds_valid)\n#     print(f\"{col},{auc}\", end=\"\\t\")\n#     scores.update({col:auc})\n    \n# df = pd.Series(scores, name=\"xgb_scores\")\n# df.to_csv(\"xgboost.csv\", index_label=\"feature\")\n# print(\"AVG AUC:\",np.mean(df.values))","c85a89ac":"fi = pd.read_csv(\"..\/input\/tpsoctclassicfeatureimportance\/xgboost.csv\").set_index(\"feature\")\nfi[\"importance\"] = fi.loc[\"all\",\"xgb_scores\"] - fi[\"xgb_scores\"]\nfi = fi.sort_values(ascending=False, by=\"importance\")\nfi.head(10)","26126d61":"fig = px.bar(fi, y=fi[\"importance\"], x=fi.index)\nfig.update_layout(\n    title=f\"Feature Importance\",\n    xaxis_title=\"Features\",\n    yaxis_title=\"Importance\",\n    yaxis={'categoryorder':'total descending'},\n    colorway=[\"blue\"]\n)\nfig.show()","0daa71cd":"neg_features = fi[fi.importance < 0].index\nprint(neg_features.tolist())","de2c6ac2":"fig = px.bar(fi, y=fi[fi.importance < 0][\"importance\"], x=fi[fi.importance < 0].index)\nfig.update_layout(\n    title=f\"Feature Importance\",\n    xaxis_title=\"Features\",\n    yaxis_title=\"Importance\",\n    yaxis={'categoryorder':'total descending'},\n    colorway=[\"blue\"]\n)\nfig.show()","ed53ae31":"pos_features = fi[fi.importance > 0].index\nprint(pos_features.tolist())","de1aa143":"fig = px.bar(fi, y=fi[fi.importance > 0][\"importance\"], x=fi[fi.importance > 0].index)\nfig.update_layout(\n    title=f\"Feature Importance\",\n    xaxis_title=\"Features\",\n    yaxis_title=\"Importance\",\n    yaxis={'categoryorder':'total descending'},\n    colorway=[\"blue\"]\n)\nfig.show()","21579135":"# Load Data","e4601378":"Note that the order of importance may remain the same with different models, but the magnitude may change. For example with a good model configuration all features with negative effect may have a positive effect, but they will impact less, in comparison with the positive columns. ","77e20d32":"Which features made accuracy worse?","676ccdab":"Which features made accuracy better?","473a1c1d":"# Results\n* We can see some features have **negative effect** on the model and some of them have no effect.  ","094198c7":"# Classic Feature Importance\n\nThe easiest way to **determine the magnitude of importance of each feature**, is to remove each feature, and then train a model to see how much accuracy drops without that feature. A big shortcoming of this solution is that you have to train a model for each feature and this is a resource and time consuming task. \n\nHowever I have provided the results of training for a simple **XGBoost** model (with default parameter values) with removing each feature. You can find the results [here](https:\/\/www.kaggle.com\/kavehshahhosseini\/tpsoctclassicfeatureimportance).\n\nThe results may be different from other ways such as Shapely values, permutation importance, model feature importance and...\n\nI've provided a sample code of how it's been done. You can see it by clicking on \"Show Hidden Cell\"."}}