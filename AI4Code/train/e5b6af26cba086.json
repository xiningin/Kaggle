{"cell_type":{"305b0a03":"code","06c1f2db":"code","c2d9348b":"code","a005bd52":"code","260a42a7":"code","3e8d2ce7":"code","5fed0f90":"code","3209c76d":"code","e0bb14ab":"code","29515e44":"markdown","32a869b4":"markdown","49055e96":"markdown","d9728798":"markdown","45a69977":"markdown","a7a4621b":"markdown","00f7f029":"markdown","726b9315":"markdown"},"source":{"305b0a03":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc\nimport matplotlib.pyplot as plt\nimport xgboost as xgb","06c1f2db":"print('Reading datasets')\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint('Merging test and train')\ntest['target'] = np.nan\ntrain = train.append(test).reset_index() # merge train and test\ndel test\nprint('Done, shape=',np.shape(train))","c2d9348b":"def rank_gauss(x, title=None):\n    #Trying to implement rankGauss in python, here are my steps\n    # 1) Get the index of the series\n    # 2) sort the series\n    # 3) standardize the series between -1 and 1\n    # 4) apply erfinv to the standardized series\n    # 5) create a new series using the index\n    # Am i missing something ??\n    # I subtract mean afterwards. And do not touch 1\/0 (binary columns). \n    # The basic idea of this \"RankGauss\" was to apply rank trafo and them shape them like gaussians. \n    # Thats the basic idea. You can try your own variation of this.\n    \n    if(title!=None):\n        fig, axs = plt.subplots(3, 3)\n        fig.suptitle(title)\n        axs[0][0].hist(x)\n\n    from scipy.special import erfinv\n    N = x.shape[0]\n    temp = x.argsort()\n    if(title!=None):\n        print('1)', max(temp), min(temp))\n        axs[0][1].hist(temp)\n    rank_x = temp.argsort() \/ N\n    if(title!=None):\n        print('2)', max(rank_x), min(rank_x))\n        axs[0][2].hist(rank_x)\n    rank_x -= rank_x.mean()\n    if(title!=None): \n        print('3)', max(rank_x), min(rank_x))\n        axs[1][0].hist(rank_x)\n    rank_x *= 2\n    if(title!=None):\n        print('4)', max(rank_x), min(rank_x))\n        axs[1][1].hist(rank_x)\n    efi_x = erfinv(rank_x)\n    if(title!=None): \n        print('5)', max(efi_x), min(efi_x))\n        axs[1][2].hist(efi_x)\n    efi_x -= efi_x.mean()\n    if(title!=None):\n        print('6)', max(efi_x), min(efi_x))\n        axs[2][0].hist(efi_x)\n        plt.show()\n\n    return efi_x\n","a005bd52":"for i in train.columns:\n    if i.endswith('cat'): # could be train[i].dtype == 'object' + labelencode, or maybe one hot encode...\n        print('Categorical: ',i)\n        train[i] = rank_gauss(train[i].values, i) # display rank gauss tranformation\n    elif i.endswith('bin'):\n        print('Binary: ',i)\n    else:\n        print('Numeric: ',i)","260a42a7":"# TODO, use incremental learning with XGB and execute denoising autoencoder\n\nfrom math import ceil\nclass DAESequence:\n    def __init__(self, df, batch_size=128, random_cols=.15, random_rows=1, use_cache=False, use_lock=False, verbose=True):\n        self.df = df.values.copy()     # ndarray baby\n        self.batch_size = int(batch_size)\n        self.len_data = df.shape[0]\n        self.len_input_columns = df.shape[1]\n        if(random_cols <= 0):\n            self.random_cols = 0\n        elif(random_cols >= 1):\n            self.random_cols = self.len_input_columns\n        else:\n            self.random_cols = int(random_cols*self.len_input_columns)\n        if(self.random_cols > self.len_input_columns):\n            self.random_cols = self.len_input_columns\n        self.random_rows = random_rows\n        self.cache = None\n        self.use_cache = use_cache\n        self.use_lock = use_lock\n        self.verbose = verbose\n        \n        self.lock = ReadWriteLock()\n        self.on_epoch_end()\n\n    def on_epoch_end(self):\n        if(not self.use_cache):\n            return\n        if(self.use_lock):\n            self.lock.acquire_write()\n        if(self.verbose):\n            print(\"Doing Cache\")\n        self.cache = {}\n        for i in range(0, self.__len__()):\n            self.cache[i] = self.__getitem__(i, True)\n        if(self.use_lock):\n            self.lock.release_write()\n        gc.collect()\n        if(self.verbose):\n            print(\"Done\")\n\n    def __len__(self):\n        return int(ceil(self.len_data \/ float(self.batch_size)))\n\n    def __getitem__(self, idx, doing_cache=False):\n        if(not doing_cache and self.cache is not None and not (self.random_cols <=0 or self.random_rows<=0)):\n            if(idx in self.cache.keys()):\n                if(self.use_lock):\n                    self.lock.acquire_read()\n                ret0, ret1 = self.cache[idx][0], self.cache[idx][1]\n                if(self.use_lock):\n                    self.lock.release_read()\n                if (not doing_cache and self.verbose):\n                    print('DAESequence Cache ', idx)\n                return ret0, ret1\n        idx_end = min(idx + self.batch_size, self.len_data)\n        cur_len = idx_end - idx\n        rows_to_sample = int(self.random_rows * cur_len)\n        input_x = self.df[idx: idx_end]\n        if (self.random_cols <= 0 or self.random_rows <= 0 or rows_to_sample<=0):\n            return input_x, input_x # not dae\n        # here start the magic\n        random_rows = np.random.randint(low=0, high=self.len_data-rows_to_sample, size=rows_to_sample)\n        random_rows[random_rows>idx] += cur_len # just to don't select twice the current rows\n        cols_to_shuffle = np.random.randint(low=0, high=self.len_input_columns, size=self.random_cols)\n        noise_x = input_x.copy()\n        noise_x[0:rows_to_sample, cols_to_shuffle] = self.df[random_rows[:,None], cols_to_shuffle]\n        if(not doing_cache and self.verbose):\n            print('DAESequence ', idx)\n        return noise_x, input_x\n","3e8d2ce7":"print(\"Create Model\")\ndae_data = train[train.columns.drop(['id','target'])] # only get \"X\" vector\n\n# reduce data size, we are in kaggle =)\ndae_data = dae_data[0:1000]\ndae_data = dae_data.drop('index', axis=1)\nlen_input_columns, len_data = dae_data.shape[1], dae_data.shape[0]\n\neta = 0.1\nmax_depth = 6\nsubsample = 0.9\ncolsample_bytree = 0.85\nmin_child_weight = 55\nnum_boost_round = 500\n\nparams = {\"objective\": \"reg:linear\",\n          \"booster\": \"gbtree\",\n          \"eta\": eta,\n          \"max_depth\": int(max_depth),\n          \"subsample\": subsample,\n          \"colsample_bytree\": colsample_bytree,\n          \"min_child_weight\": min_child_weight,\n          \"silent\": 1\n          }","5fed0f90":"#FIRST IDEA, AE with stacking use the output (feature_Results) as input to next model\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\ntrain_rows = dae_data.shape[0]\nfeature_results = []\nglobal_min_length, global_max_length = None, None\nfor target_g in dae_data.columns.tolist():\n    features = dae_data.columns.drop(target_g).tolist()\n    target_list = [target_g]\n    train_fea = np.array(dae_data[features])\n    for target in target_list:\n        train_label = dae_data[target]\n        kfold = KFold(n_splits=5, random_state=218, shuffle=True)\n        kf = kfold.split(dae_data)\n        cv_train = np.zeros(shape=(dae_data.shape[0], 1))\n        min_length, max_length = None, None\n        for i, (train_fold, validate) in enumerate(kf):\n            X_train, X_validate, label_train, label_validate = train_fea[train_fold, :], train_fea[validate, :], train_label[train_fold], train_label[validate]\n            dtrain = xgb.DMatrix(X_train, label_train)\n            dvalid = xgb.DMatrix(X_validate, label_validate)\n            watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n            bst = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=50, verbose_eval=False)\n            min_length, max_length = min_length if min_length is not None and min_length<bst.best_ntree_limit else bst.best_ntree_limit, \\\n                                     max_length if max_length is not None and max_length>bst.best_ntree_limit else bst.best_ntree_limit\n            cv_train[validate, 0] += bst.predict(xgb.DMatrix(X_validate), ntree_limit=bst.best_ntree_limit)\n        global_min_length, global_max_length = \\\n            global_min_length if global_min_length is not None and global_min_length<min_length else min_length, \\\n            global_max_length if global_max_length is not None and global_max_length>max_length else max_length\n        print(target, 'mse: ', mean_squared_error(train_label, cv_train), ' min\/max best_ntree_limit: ',min_length, max_length)\n        feature_results.append(cv_train)\n\nfeature_results = np.hstack(feature_results)\nprint(\"AE MSE from train data: \", mean_squared_error(dae_data, feature_results),\n     'min\/max best_ntree_limit: ',global_min_length, global_max_length)\n","3209c76d":"#SECOND IDEA, AE with CV to get highest tree size, and train a regressor with this size \n# and predict 3 'layers', each one with one size (trees\/4 * 1,2,3...)\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nprint(\"CV Part\")\ntree_sizes={}\nfor target_g in dae_data.columns.tolist():\n    features = dae_data.columns.drop(target_g).tolist()\n    dtrain = xgb.DMatrix(dae_data[features].values, dae_data[target_g].values)\n    bst = xgb.cv(params, dtrain, num_boost_round, early_stopping_rounds=50, verbose_eval=False, nfold=5)\n    tree_sizes[target_g] = bst.shape[0]\n    print(target_g, tree_sizes[target_g])\nprint(tree_sizes, min(tree_sizes.values()), max(tree_sizes.values()))\nmax_trees = max(tree_sizes.values())\nprint(\"Tree size: \",max_trees)\n# we could get max size, fit models (overfit obvious), half size and 1\/3 size\nfeature_results2 = []\nfeatures = []\nprint(\"CREATE FEATURE PART \", len(dae_data.columns.tolist()))\nfor target_g in dae_data.columns.tolist():\n    features = dae_data.columns.drop(target_g).tolist()\n    dtrain = xgb.DMatrix(dae_data[features].values, dae_data[target_g].values)\n    size = tree_sizes[target_g] # max_trees\n    bst = xgb.train(params, dtrain, num_boost_round=size)\n    pred = bst.predict(dtrain)\n    feature_results2.append(pred)\n    print('creating features: ',target_g, size, ' error:', mean_squared_error(dae_data[target_g], pred))\n    if(int(size\/4)<=0):\n        features.append(bst.predict(dtrain, ntree_limit =size) )\n    else:\n        features.append(bst.predict(dtrain, ntree_limit =int(size\/4)*1) )\n        features.append(bst.predict(dtrain, ntree_limit =int(size\/4)*2) )\n        features.append(bst.predict(dtrain, ntree_limit =int(size\/4)*3) )\nprint(len(feature_results2))\nfeature_results2 = np.hstack(feature_results2).reshape(-1,dae_data.shape[1])\nfeatures = np.hstack(features)\n\n\n# this error is a bit high, maybe we should do max_tree per feature? or stack too?\nprint(\"AE MSE from train data: \", mean_squared_error(dae_data, feature_results2))\n\nprint(\"Features = \",features.shape)\n","e0bb14ab":"plt.hist(dae_data)\nplt.show()\nplt.hist(feature_results, bins=100)\nplt.show()\nplt.hist(feature_results2, bins=100)\nplt.show()\nplt.hist(features)\nplt.show()\n","29515e44":"Creating Model and Fitting","32a869b4":"Rank Gauss transformation","49055e96":"Fitting model with data","d9728798":"Feature encoding with xgboost https:\/\/github.com\/xiaozhouwang\/kaggle-porto-seguro\/blob\/master\/code\/fea_eng0.py","45a69977":"# TODO IDEAS:\n\n1) DAE with tree (change input each 'epoch')\n\n2) feature extraction with stacking (get features with different n_tree at predict using stacking for loop), this give a better AE RMSE maybe a better feature representation too. must test","a7a4621b":"Categorical to RankGauss, Binary to -1\/1","00f7f029":"DAE Generator for xgb","726b9315":"Reading Dataset"}}