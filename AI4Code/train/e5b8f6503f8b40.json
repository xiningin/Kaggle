{"cell_type":{"4e3d8e54":"code","47c10fdc":"code","e6f04cb1":"code","dab6d06c":"code","28daa76a":"code","bc3c069b":"code","7d8963e2":"markdown","a6009243":"markdown","5e45e098":"markdown","31563ec7":"markdown","44e70b29":"markdown","757788bb":"markdown","0c7d13e2":"markdown","d980e397":"markdown"},"source":{"4e3d8e54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47c10fdc":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OrdinalEncoder","e6f04cb1":"# First let's visualize the dataset:\n\ndf = pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\")\ncols = list(df.columns)\ndf_copy = df\ndf = df.drop(columns = cols[-2:],axis = 1)\ndf.head(30)","dab6d06c":"df['Attrition_Flag'].value_counts('')","28daa76a":"print(f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns\")\nprint(\"\\n\\n\" + \"=\" * 20 + \"\\n\")\ndisplay(df.info())\nprint(\"\\n\" + \"=\" * 10 + \" Unique & missing values\" + \"=\" *10)\ndisplay(pd.DataFrame({\"Uniques\": df.nunique().values, \"Missing\": df.isna().sum(axis = 0).values}, index = df.columns))","bc3c069b":"num = 0\nfig,axs = plt.subplots(7,3,figsize=(50,100),edgecolor='k')\naxs = axs.ravel()\nfor i in cols[2:-2]:\n    sns.set_style('ticks')\n    sns.histplot(df.loc[df['Attrition_Flag']=='Existing Customer' , i], \n                 label = 'Existing', kde = True , \n                 line_kws=dict(linewidth=6), ax = axs[num])\n    sns.histplot(df.loc[df['Attrition_Flag']=='Attrited Customer' , i], \n                 label = 'Attrited', kde = True , \n                 line_kws=dict(linewidth=6), ax = axs[num],color='orange')\n    #sns.histplot(df, x=i,hue=cols[1], kde=True,line_kws=dict(linewidth=6),stat = 'probability', ax = axs[num])\n    \n    plt.setp(axs[num].get_title(), fontsize='25')\n    axs[num].set_xlabel(i,fontsize=40)\n    axs[num].set_ylabel('count',fontsize=30)\n    axs[num].tick_params(axis='both',labelsize = '30')\n    num+=1","7d8963e2":"## Conclusion:\nThe precedent analysis is only for first level dependencies. What I mean by that is that it is possible to have 3rd order dependencies or group ones meaning when you combine different unimportat features they have a effect on the churning ! \nBut my data exploration at least help us to understand first level effect of important features. Better start with approximations and refining the model after.  ","a6009243":"### Basic info","5e45e098":"# Who is gonna churn us ?\n\nA bank offering credit card subscription to their clients is realizing that some customers are releasing their credit card subscription (churn). So they want us to explain how we can predict this in the future, and to discover the type of customer who are sensible to release their subscription. With this information they will be able to approach them before the churn and propose them new services to encourage them staying with the bank. \n\nHow are we gonna do that ? With the data they provide us on the credit card activity for 11027 Customers. Of course the customers identity have been anonymized. \n\nBased on the data and with our analysis we will sort out valuable insights to predict possible future churning customer. \n\nThe work is separated in differents parts:\n\n[Table of contents:](#ToC)\n\n[Importing all the necessary libraries](#0thPart)\n\n[1. Data description and our goal](#1stPart)\n\n[2. Data exploration for first level insights](#2ndPart)\n\n[3. Full features Machine learning model vs Model with first level insights](#3rdPart)\n\n[4. Conclusion](#4thPart)\n\n> Why do we care about churning?\n* `reducing customer churn by 5% can increase profits 25\u2013125%`;\n* it is estimated that `It costs 5 times more to acquire new customers than it does to keep the current ones`;\n\nThese two simple lines underlines that it is crucial for a company to have as many loyal customers as possible and to detect all possible causes of attrition and prone-to-churn clients.\n\nFor this reasons, *interpretability* of the Machine Learning results is the main focus in this notebook. Having an outstanding Machine Learning pipeline is useless, if no business intuition or decision can be based on its results.\n\n**Sources:**\n- [What is Customer Churn & How to Reduce It?](https:\/\/medium.com\/@paldesk\/what-is-customer-churn-how-to-reduce-it-402460e5b569)\n- [Retain more customers by understanding churn](https:\/\/medium.com\/data-science-at-microsoft\/retain-more-customers-by-understanding-churn-ae31d9b2aa2b)\n\n","31563ec7":"## Analysis\n\nWe can see that for the \"Customer_Age\" (fig(1,1)), the class label seems independent of it. there is no apparent useful information from it. WHY ? Because the distribution of customers in the 2 class looks the same(**the modes seem to match in x axes**), except in the vertical counts(**reasoning from logic explained earlier**). But this looks normal because of the initial repartition of labels between \"Existing customer\" and \"Attrided Customer\". The repartition was 84%\/16% respectively. \n\nSo for fig(1,1) to fig(4,3) no feature dependence\n\nBeing in this strategy(looking for modal discrepancy between distributions), we can infer that the most important features that have first level impact on the churn are :\n* Avg_utilization_Ratio\n* Total_Trans_Ct (pretty clear multimode vs unimodal distribution)\n* Total_Trans_Amt\n* Toal_Ct_Chang_Q4_Q1\n* Total_Amt_Chang_Q4_Q1\n* Total_Revolving_Bal","44e70b29":"<a id='1stPart'><\/a>\n# 1. Data description and our goal","757788bb":"<a id='2ndPart'><\/a>\n## First level analysis: let's look which parameter features are directly impacting the churn\n\nInstead of looking for corraletions between features, I wanted to start looking at features who have direct 1st level impact on the churn. \nI used a probabilistic concept to sort out this logic:\n\n\nTake 2 events A and B that are independent, then **P(A inter B) = P(A) * P(B)[1]** resulting in **P(A|B) = P(A)[2]**\n\nSo if we plot the P(A) (for example is the customer Age histogram) the distribution shouldnt vary too much if we plot P(A) for \"existing customer\" or for \"Attrited ones\"(meaning P(A|B) where B here is the label: existing or attrited customer) \n\nSo what I'm gonna do is plot P(A inter B)(histogram) (B is Existing and B- Attrited) and the only difference we will see in distributions **IF THE FEATURES ARE INDEPENDENT** is in the y counts because in the dataset the repartition is P(B) ~= 84% and P(-B) = 16%(see formula [1]) \n\nIn resume what I'm saying is we should have the same population repartition when plotting\nP(A inter B) and P(A inter -B)\n\nFor example with the **A = Gender Male and -A = Female** and **-B = churn , B = Existing** we should have \n(A inter B) and (A inter -B) get the same population repartition of churn and existing customer meaning respectively ~16% of Male customer are churning and ~84% are still existing\n\nLike I said in terms of distribution over possible values of the features the normalized distribution for (Feature inter B) should look the same with (Feature inter -B) \nIf there are differences in the 2 distributions then the churn is **Not independent of the the feature** . Then this feature can be a good predictor to sort out which client will possibly churn. \n\nOne way to measure the difference between the 2 distribution is by doing the **Student's T-test** which allow us to determine if there is a significant difference between the mean of 2 distributions. ","0c7d13e2":"<a id='0thPart'><\/a>\n## Importing all necesaries libraries:\n","d980e397":"## Dataset description:\n<a style=\"font-size:12px;\" href=\"#ToC\">Back to Table of Contents<\/a>\n\n<span style=\"font-size:16px;color:Green\"><b>INTRODUCTION<\/b><\/span>\n\nThe purpose of this section is to become acquainted with the dataset.Two main needs have to be taken into account:\n1. understand what kind of variables are inside the dataset and what is their meaning. Functional knowledge allows to create new variables and get insights from our machine learning output;\n2. get insights that could bring to better output results, such as which variable are related to the target variable or with each other. This is the stepping stone for a good model, since it allows to select the right number of variables (avoiding useless or correlated features) in agreement with Occam's razor principle;  \n\n<span style=\"font-size:16px;color:Green\"><b>RESULTS:<\/b><\/span>\n\nIn the dataset we can find three main classes of features:\n* **anagraphical features:** *Customer_Age, Gender, Education_Level, Marital_Status, Income_Category*. Their meaning is straightforward;\n\n* **customer-bank relationship features:** \n    - Dependent_count: [number of people uses that specific account](https:\/\/www.kaggle.com\/sakshigoyal7\/credit-card-customers\/discussion\/201767);\n    - Card_Category: is this a Premium or a Basic account?\n    - Months_on_book: the duration of the relationship as of now;\n    - Total_Relationship_Count: Total number of products held by the customer. In other words, client could have other products like debit card, loans, and so on;\n    - Contacts_Count_12_mon: the number of contacts between the customer and the bank in the last 12 months. It could be a key indicator of the satisfaction level of the client: the more contacts, the higher the probability that there is something that causes attrition;\n    \n    \n* **Credit Card utilization features:**\n    - Months_Inactive: it determines how many months the client has been inactive. However this variable is not entirely clear to me: official documentation states that this inactivity status is recorded among the last 12 months. However the highest value of this variable is 6 and it is not clear whether this is the number of *consecutive* months of inactivity. In my personal opinion, this variable shows the maximum number of consecutive months of inactivity and a customer is classified as *churned* after 6 or 7 months of inactivity;\n    - Credit_Limit: this is the maximum amount the client is allowed to use;\n    - Total_Revolving_Bal: the debt amount. For example the revolving balance value in february is determined by: $$Debt\\_February=Debt\\_January+CreditUsed\\_February-DebtPaid\\_February$$\n    - Avg_Open_To_Buy: suppose a client has used 500\u00a3, and its credit limit is 2500\u00a3. The custormer is thus *open to buy* 2500-500=2000\u00a3. Avg_Open_To_Buy is the average over the last 12 months of the Open To Buy value;\n    - Total_Trans_Amt: total transactional amount in the last 12 months;\n    - Total_Amt_Chng_Q4_Q1: the ratio between transactional amount of first quarter and the same amount for fourth quarter. Hence, a value smaller tha 1 means that the customer has spent less in this quarter with respect to the last one;\n    - Total_Trans_Ct, Total_Ct_Chng_Q4_Q1: their meaning is analogous to the last two variables. Of course, thee differ on the underlying reference variable, since in this case it is the number of transactions instead of the amount;\n    - Avg_Utilization_Ratio: $$Utilization\\_Ratio=\\frac{Credit\\_Limit-Open\\_To\\_Buy}{Credit\\_Limit}=\\frac{Credit\\_Used}{Credit\\_Limit}$$\n    Avg_Utilization_Ratio is the average proportion of the credit used with respect to the credit liit in the last 12 months.\n    \n\nThere are two more features:\n* **CLIENTNUM:** primary key of the dataset. For the sake of the project, it is not useful;\n* **Attrition_Flag:** whether the customer is an attrited one or not. Attrited customer are referred to *closed* accounts, thus there might be clients *near to churn* in the dataset but classified as normal clients (this will cause some errors, like we will see below).  \nWe can observe that it is an unbalanced distribution (about 84% of the data belong to the class *Existing Customer*, whereas only 16% of clients are in the class of churned ones). This means that any standard machine learning algorithm will struggle to classify correctly the minority class. For more on this, please refer to [3. Full features Machine learning model vs Model with first level insights](#ML);"}}