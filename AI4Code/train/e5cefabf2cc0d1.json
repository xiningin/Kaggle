{"cell_type":{"9756e166":"code","44085796":"code","8c4a0a01":"code","a7b0053c":"code","df9df78e":"code","a1ec7bcb":"code","eb3bcabc":"code","0b424fe3":"code","ac7b54f5":"code","d11fa67a":"code","3444d0cd":"code","227987e0":"code","00df792d":"code","a0d0b00d":"code","dc69b5c8":"code","8e12a0ad":"code","1a95a18d":"code","368da31e":"code","ccc15303":"code","f006a387":"code","23f4040b":"code","4d946858":"code","52e803f0":"code","81399d61":"code","0b653677":"code","df057140":"code","3f635f99":"code","c852d5df":"code","3f07b01b":"code","adee4553":"code","87b9c3e8":"code","1b7d39e7":"code","6343311f":"code","a7f91a02":"code","c5648ec1":"code","06572f8e":"code","a4ca2f42":"code","2215077c":"code","17163ce3":"code","8c31e658":"code","cde30c3b":"code","163033be":"markdown","9014c866":"markdown","67c04d9e":"markdown","5acf13c7":"markdown","2dc7a4c6":"markdown","fd8664ad":"markdown","b576dbf2":"markdown","089ea4a8":"markdown","71542595":"markdown","c9a01b41":"markdown","03089057":"markdown","8c3868a3":"markdown","03910a3a":"markdown","a1b9363d":"markdown"},"source":{"9756e166":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44085796":"df=pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","8c4a0a01":"df.head(5)","a7b0053c":"df.info()","df9df78e":"df.describe().transpose()","a1ec7bcb":"df.isnull().sum()","eb3bcabc":"df.tail(5)","0b424fe3":"print(\"Fraud\")\nprint(df.Time[df.Class==1].describe())","ac7b54f5":"print(\"Not Fraud\")\nprint(df.Time[df.Class==0].describe())","d11fa67a":"import matplotlib.pyplot as plt ","3444d0cd":"f,(ax1,ax2)=plt.subplots(2,1,figsize=(12,6))\nax1.hist(df.Time[df.Class==1],bins=50)\nax1.set_title(\"Fraud\")\nax2.hist(df.Time[df.Class==0],bins=50)\nax2.set_title(\"NOT Fraud\")\nplt.xlabel('Time in secs')\nplt.ylabel('Number of transactions')\nplt.show()","227987e0":"print(\"Fraud\")\nprint(df.Amount[df.Class==1].describe())","00df792d":"print(\"Fraud\")\nprint(df.Amount[df.Class==0].describe())","a0d0b00d":"f,(ax1,ax2)=plt.subplots(2,1,figsize=(12,6))\nax1.hist(df.Amount[df.Class==1],bins=50)\nax1.set_title(\"Fraud\")\nax2.hist(df.Amount[df.Class==0],bins=50)\nax2.set_title(\"NOT Fraud\")\nplt.xlabel('Amount')\nplt.ylabel('Number of transactions')\nplt.show()","dc69b5c8":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,6))\n\nax1.scatter(df.Time[df.Class == 1], df.Amount[df.Class == 1])\nax1.set_title('Fraud')\n\nax2.scatter(df.Time[df.Class == 0], df.Amount[df.Class == 0])\nax2.set_title('Not Fraund')\n\nplt.xlabel('Time in Sec')\nplt.ylabel('Amount')\nplt.show()","8e12a0ad":"X = df.iloc[:, :-1].values\nX","1a95a18d":"import seaborn as sns ","368da31e":"sns.set(style=\"whitegrid\")\nlabels = ['Not Fraud', 'Fraud']\nsizes = df['Class'].value_counts(sort = True)\n\ncolors = [\"lightblue\",\"red\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.title('Frauds in the dataset')\nplt.legend()\nplt.show()","ccc15303":"\nV = df[[col for col in df.columns if 'V' in col]+['Class']]\n\nf, ax = plt.subplots(ncols = 4, nrows = 7, figsize=(15,2*len(V.columns)))\n\nfor i, c in zip(ax.flatten(), V.columns):\n    sns.distplot(V[c][V['Class'] == 0],color='#87bd75', ax = i) #Genuine\n    sns.distplot(V[c][V['Class'] == 1],color='#b94646', ax = i) #Fraud   \nf.tight_layout()","f006a387":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(df[df['Class'] == 0][\"Time\"], color='green') # Genuine - green\nsns.distplot(df[df['Class'] == 1][\"Time\"], color='red') # Fraud - Red\n\nplt.title('Genuine vs Fraud by Time(in sec)', fontsize=15)\nplt.xlim([-10000,180000])\nplt.grid(linewidth = 0.7)\nplt.legend(['Genuine','Fraud'])\nplt.show()","23f4040b":"plt.style.use(\"classic\")\nplt.figure(figsize=(10,10))\n\nsns.distplot(df[df['Class'] == 0][\"Amount\"], color='green') # Genuine - green\nsns.distplot(df[df['Class'] == 1][\"Amount\"], color='red') # Fraud - Red\n\nplt.title('Genuine vs Fraud by Amount', fontsize=15)\nplt.xlim([-10,3700])\nplt.grid(linewidth = 0.7)\nplt.legend(['Genuine','Fraud'])\nplt.show()","4d946858":"X.shape\n","52e803f0":"y=df.iloc[:,-1].values\ny","81399d61":"y.shape","0b653677":"from sklearn.model_selection import train_test_split","df057140":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33)","3f635f99":"from sklearn.preprocessing import MinMaxScaler","c852d5df":"scaler=MinMaxScaler()","3f07b01b":"scaler.fit(X_train)","adee4553":"X_train=scaler.transform(X_train)\nX_test=scaler.transform(X_test)","87b9c3e8":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\n","1b7d39e7":"model= tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(6,  activation='relu'))\nmodel.add(tf.keras.layers.Dense(6,  activation='relu'))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\nmodel.fit(X_train, y_train, epochs=5)","6343311f":"model.evaluate(X_test,y_test)","a7f91a02":"predictions=model.predict(X_test)\npredictions[2829]","c5648ec1":"y_test[2829]","06572f8e":"predictions[2]\ny_test[2]","a4ca2f42":"dataframe=pd.DataFrame(y_test, columns=['prediction']) ","2215077c":"dataframe.nunique()\ndataframe.value_counts()","17163ce3":"from sklearn.metrics import confusion_matrix,accuracy_score","8c31e658":"y_pred = model.predict(X_test)\ny_pred = (y_pred > 0.5) \ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","cde30c3b":"# Visualizing Confusion Matrix\nplt.figure(figsize = (6, 6))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['Genuine', 'Fraud'], xticklabels = ['Predicted Genuine', 'Predicted Fraud'])\nplt.yticks(rotation = 0)\nplt.show()","163033be":" **Dividing the features and classes of the given dataset**","9014c866":"**Visualizing Confusion Matrix**","67c04d9e":"**It seems our dataset is highly imbalance. I'll take care of it later**","5acf13c7":"**since there is no null values hence it has made the further analysis easier . **","2dc7a4c6":"**Genuine vs Fraud by Time**","fd8664ad":"**Making the Confusion Matrix**","b576dbf2":"***Uisng CNN for this classification problem ***","089ea4a8":"** We can see a interesting different distribuition in some of our features**","71542595":"**To prevent the dataset from overfitting the model we just apply the standardscaler to the X  dataset **","c9a01b41":"**Dividing the dataset into training and testing data **","03089057":" ** From the above graph, we can see that most frauds have happened in the early mornings.**\n ","8c3868a3":"**PIE CHART **","03910a3a":"****Distribution Plot****","a1b9363d":"**Genuine vs Fraud by Amount**********"}}