{"cell_type":{"32412a2a":"code","5c3532e1":"code","20ea3c66":"code","57c6538c":"code","d564b54b":"code","8746edb9":"code","3ae91802":"code","8672df42":"code","caff7657":"code","91e31413":"code","d5bd0810":"code","88612343":"code","0105ed00":"code","7a7eeef8":"code","ab86291e":"code","6b1d3310":"code","72cd8895":"code","5ce6953b":"code","e1d968f5":"code","64edc61b":"code","6a47a2f7":"code","010e8284":"code","c107b804":"code","acadb2e0":"code","8924eea5":"code","7cc1ffa5":"code","3aa23819":"code","4617d823":"code","82979be5":"code","e0140b7b":"code","0296bb54":"code","2cc3ee5c":"code","eec036d7":"code","592c581c":"code","b2f35019":"code","28865093":"code","cf4512df":"code","93b95096":"code","90e1c25e":"code","cc45693b":"code","bacac571":"code","7ea409b5":"code","39d89b2d":"code","be55d6cd":"code","ba64da73":"code","a611889f":"code","c6c2c4e8":"code","a5508c69":"code","dac17264":"code","c6f4fb1a":"code","7c9733f4":"code","39a4d619":"code","35dc3473":"code","58397b13":"code","2713076f":"code","872967f8":"code","2bceb7a0":"code","ecbca4fe":"code","69aa5e25":"code","e29df554":"code","c7e28f35":"code","c1e2d0e1":"code","d4985246":"code","ea454f3e":"code","15966179":"code","5d4317d5":"code","bbd05a9e":"code","2f8c9125":"code","61aa655f":"code","6fabf621":"code","c1a5bac8":"code","0c61e3cc":"code","94bd0be7":"code","c6607e9f":"code","ec9f5d17":"code","98698e89":"code","6e865ad5":"code","7594d0bf":"code","c166496d":"code","026385e4":"code","f921c6cc":"code","c50dc474":"code","ed9a3759":"code","3caa6586":"code","1111c3ef":"code","2acad017":"code","d4688ad1":"code","60c2e771":"code","3a66800c":"code","b992b5ee":"code","d1b61aa7":"code","72ebd6f2":"code","7bd23de7":"code","d51bf108":"code","cc2b0d62":"markdown","851dff6a":"markdown","baab0e8f":"markdown","8a0d3d1a":"markdown","3f9fdcad":"markdown","d3217876":"markdown","4c476516":"markdown","402d8a6b":"markdown","d7907edf":"markdown","89eb60fe":"markdown","a8db2794":"markdown","67a9ed7d":"markdown","c73f452d":"markdown","27b0c150":"markdown","1d6845c3":"markdown","d8538f37":"markdown","577b5864":"markdown","2cc04b8f":"markdown","a839e306":"markdown","3ff7d1ec":"markdown","0c0d5cec":"markdown","ed0db4d6":"markdown","3faca584":"markdown","09ca410c":"markdown","d8231a58":"markdown","4610e26f":"markdown","49757e97":"markdown","1cd636fe":"markdown","5b0ed7d2":"markdown","80e2e412":"markdown","ea4bde56":"markdown","d7fbe366":"markdown","ad775805":"markdown","7e1a0347":"markdown","621a43ef":"markdown","448d41e5":"markdown","ae5e37b5":"markdown","f6812aab":"markdown","36aa3330":"markdown","8c1ce7c9":"markdown","8b7fe3a8":"markdown","89be57ba":"markdown","0a412138":"markdown","57d3e4dd":"markdown","379957ec":"markdown","6b3ae2bc":"markdown","95dd7550":"markdown","9f37ec60":"markdown","3fca6d46":"markdown","cbe3eacf":"markdown","539cb964":"markdown","5226c156":"markdown","fd6fd151":"markdown","d0cad67c":"markdown","0513f63d":"markdown","1c668e3b":"markdown","152462d2":"markdown","5fa946ea":"markdown","95136c78":"markdown","edc5173c":"markdown","a9233acd":"markdown","3f0a724e":"markdown","2afcc106":"markdown","b1e6669b":"markdown","c76faa5c":"markdown","9540149e":"markdown","0432cca1":"markdown","c549f65c":"markdown","2df5776c":"markdown","f9e3e2d0":"markdown","ad34b8d2":"markdown","85851f06":"markdown","83342ae6":"markdown","45577dee":"markdown","de9d4836":"markdown","6ab50816":"markdown","5ea107df":"markdown","44b5937d":"markdown","f4ae984b":"markdown","56d4836b":"markdown","350a486d":"markdown","444887fd":"markdown","2ee271d0":"markdown","e3010089":"markdown","ddef80d7":"markdown","27d01f8c":"markdown","c605b63c":"markdown","29453beb":"markdown","8ff2af54":"markdown","304848d8":"markdown"},"source":{"32412a2a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom collections import Counter\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier)\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%cd ..\/input\/titanic\/","5c3532e1":"train = pd.read_csv(\"train.csv\")\ntest  = pd.read_csv(\"test.csv\")\nIDTEST = test[\"PassengerId\"]\n\ndisplay(train.shape, test.shape)\ndisplay(train.head(n=2), test.tail(n=2))\n\ntrain_len = train.shape[0]\ndisplay(\"train_lean : \", train_len)\n\nprint(\"\uae30\uc220\ud1b5\uacc4 : \\n\")\ndisplay(train.info())","20ea3c66":"def load_dataset():\n    \"\"\"\n    \ud559\uc2b5 \ubc0f \ub370\uc774\ud130\uc14b \ub9ac\ud134\n    \uae30\uc220\ud1b5\uacc4 \n    \"\"\"\n    train = pd.read_csv(\"train.csv\")\n    test  = pd.read_csv(\"test.csv\")\n    IDTEST = test[\"PassengerId\"]  # \uacb0\uacfc\ubb3c\uc81c\ucd9c\uc2dc PassengerId\n    \n    # Shape\ubc0f \ub370\uc774\ud130\ubcf4\uae30\n    display(train.shape, test.shape)\n    display(train.head(n=2), display(test.tail(n=2)))\n    \n    train_len = train.shape[0]\n    display(\"train_len : \", train_len)\n    \n    print(\"\uae30\uc220\ud1b5\uacc4 \\n\")\n    display(train.info())\n    return train, test, IDTEST, train_len","57c6538c":"outlier_index = []\nfeature = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n\nfor col in feature:\n    # 25%\n    Q1 = np.percentile(train[col], 25)\n    \n    # 75%\n    Q3 = np.percentile(train[col], 75)\n    \n    #IQR(Interquatile Range)\n    IQR = Q3 - Q1\n    outlier_step = 1.5 * IQR\n    \n    min_outlier = Q1 - outlier_step\n    max_outlier = Q3 + outlier_step\n    \n    \n    outlier_df = train[(train[col] < min_outlier) | (train[col] > max_outlier)]\n    outlier_index.extend(outlier_df.index)\n    \noutlier_index = Counter(outlier_index)    \n#display(outlier_index)\n#display(\"Moset Common\", outlier_index.most_common())\n\n\nmultiple_outliers = [k for k, v in outlier_index.items() if v > 2]","d564b54b":"def detect_outliers(df, features, n):\n    \"\"\"\n    df - DataFrame\n    features - feature\n    n - \uc774\uc0c1\uce58\uac12 \ud544\ud130\ub9c1\uc5d0 \uc0ac\uc6a9\ub418\ub294 \ubcc0\uc218\uac12\n    \n    \ub9ac\ud134\uac12 : \uc774\uc0c1\uce58\uc758 row index\n    \"\"\"\n    outlier_index = []\n    \n    for col in features:\n        # 25%\n        Q1 = np.percentile(df[col], 25)\n        #75%\n        Q3 = np.percentile(df[col], 75)\n        \n        #Interquatile Range(IQR)\n        IQR = Q3 - Q1\n        outlier_step = IQR * 1.5\n        \n        min_cond = Q1 - outlier_step\n        max_cond = Q3 + outlier_step\n        \n        outlier_df = df[(df[col] < min_cond) | (df[col] > max_cond)]\n        display(\"\uc774\uc0c1\uce58 : \\n\", outlier_df, outlier_df.shape)\n        \n        outlier_index.extend(outlier_df.index)\n    \n    outlier_index = Counter(outlier_index)\n    multiple_outliers = [k for k, v in outlier_index.items() if v > n]  \n    return multiple_outliers","8746edb9":"display(\"\uc774\uc0c1\uce58 \uc0ad\uc81c\uc804\", train.shape)\ndisplay(train.iloc[multiple_outliers])\ntrain = train.drop(index = multiple_outliers, axis=0, errors='ignore', inplace=False).reset_index(drop=True)\ndisplay(\"\uc774\uc0c1\uce58 \uc0ad\uc81c \ud6c4 \", train.shape)","3ae91802":"def remove_outliers(df, outlier_pos):\n    \"\"\"\n    \uc774\uc0c1\uce58\uc758 \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0\uc11c \uc778\ub371\uc2a4\ub97c \ub9e4\uac1c\ubcc0\uc218\ub85c \ubc1b\uc544 \n    \ud574\ub2f9 \ub370\uc774\ud130\ub97c \uc0ad\uc81c\n    \"\"\"\n    display(\"\uc774\uc0c1\uce58 \uc0ad\uc81c\uc804\", df.shape)\n    display(df.iloc[outlier_pos])\n    \n    df = df.drop(index = outlier_pos, axis=0, errors='ignore').reset_index(drop=True)\n    display(\"\uc774\uc0c1\uce58 \uc0ad\uc81c \ud6c4 \", df.shape)\n    \n    return df","8672df42":"dataset = pd.concat(objs = [train, test], axis = 0).reset_index(drop=True)\ndisplay(\"\\n \ubcd1\ud569\ub41c \ub370\uc774\ud130\uc14b\", dataset.shape)\ndisplay(\"\\n Dataset Info \", dataset.info())","caff7657":"def get_join_dataset(train, test):\n    \"\"\"\n    \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b\uc744 \ubcd1\ud569\ud55c \ub370\uc774\ud130\uc14b \n    \"\"\"\n    dataset = pd.concat(objs=[train, test], axis = 0).reset_index(drop=True)\n    \n    display(\"\\n \ubcd1\ud569\ub41c \ub370\uc774\ud130\uc14b \", dataset.shape)\n    \n    display(\"\\n Dataset Info \", dataset.info())\n    return dataset\n\n# \uc218\ud589\ndataset = get_join_dataset(train, test)","91e31413":"def check_null_missing_val(df, datasetT=True):\n    \"\"\"\n    \ub110\uac12\uacfc \uacb0\uce21\uce58 \ud655\uc778\n    datasetT \ud30c\ub77c\ubbf8\ud130\ub294 True\uc778 \ud574\ub2f9 \ub370\uc774\ud130\uc14b\uc758 \uacb0\uce21\uce58\ub97c NaN\uac12\uc73c\ub85c \ub300\uce58\n    \"\"\"\n    if datasetT:\n        # Fill empty and NaNs values with NaN\n        df = df.fillna(np.nan)\n    \n    print(\"\ub110\uac12 \uccb4\ud06c : \\n\")\n    display(df.isnull().sum())\n\n    print(\"\ub370\uc774\ud130\ud0c0\uc785 \uccb4\ud06c : \\n\")\n    datatype_df = pd.DataFrame(data = df.dtypes).reset_index()\n    datatype_df = df.rename(columns={\"index\": \"feature\", 0: \"data_type\"}, inplace=False)\n\n    print(\"dataset information : \\n\")\n    display(df.info())\n\n    print(\"dataset descriptive statistics : \\n\")\n    display(df.describe())\n\n    display(df.head(3))\n    return df","d5bd0810":"dataset = check_null_missing_val(dataset)","88612343":"def extract_num_features(df, objType=None):\n    \"\"\"\n    \ub370\uc774\ud130\ud504\ub808\uc784\uc744 \uc785\ub825\ubc1b\uc544 \ub370\uc774\ud130\ud0c0\uc785\uc744 \ud544\ud130\ub9c1\ud558\ub294 \ud574\ub2f9 \n    \ud53c\ucc98\ub9cc \ub9ac\uc2a4\ud2b8\ud0c0\uc785\uc73c\ub85c \ub9ac\ud134\n    \ub9ac\ud134\uac12\uc740 pd.Series\n    \"\"\"\n    int_cols = train.dtypes[train.dtypes != objType]\n    # PassengerId\uc640 Pclass \ud53c\ucc98 \uc0ad\uc81c\n    int_cols.drop(index = [\"PassengerId\", \"Pclass\"], inplace=True)\n    return int_cols  \n\n# \uc218\ud589\nint_cols = extract_num_features(train, 'object')\nint_cols.index","0105ed00":"g = sns.heatmap(train[int_cols.index].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")","7a7eeef8":"g = sns.factorplot(x=\"SibSp\", y=\"Survived\", data = train, kind=\"bar\", size=6, palette=\"muted\")\ng.set_xlabels(\"SibSp\")\ng.despine(left=True)  # \uc88c\uce21\uc758 \ucd95\uc744 \uc5c6\uc570\ng.set_ylabels(\"Survivor Probability\")","ab86291e":"g = sns.factorplot(x=\"Parch\", y=\"Survived\", data = train, palette=\"summer_r\", kind=\"bar\")\ng.despine(left=True)\ng.set_xlabels(\"Parch\")\ng.set_ylabels(\"Survivor Probabilty\")","6b1d3310":"# \ud788\uc2a4\ud1a0\uadf8\ub7a8\uacfc kde plot\uc774 \uac19\uc774.\ng = sns.FacetGrid(train, col=\"Survived\")\ng = g.map(sns.distplot, \"Age\")","72cd8895":"cond_0 = (train[\"Survived\"]== 0) & (train[\"Age\"].notnull())\ncond_1 = (train[\"Survived\"]== 1) & (train[\"Age\"].notnull())\n\ng = sns.kdeplot(train[\"Age\"][cond_0], color=\"red\", shade=True)\ng = sns.kdeplot(train[\"Age\"][cond_1], color=\"blue\", shade=True, ax = g)\n\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng.legend([\"Not Survived\", \"Survived\"])","5ce6953b":"# Fare\ud53c\ucc98\uc758 \ud3b8\ud5a5\ub3c4\ng = sns.distplot(a = dataset[\"Fare\"], color=\"r\", label=\"skewness : {:.2f}\".format(dataset[\"Fare\"].skew()))\ng.set_title(\"Skewnewss for {0}\".format(col))\ng = g.legend(loc=\"best\")","e1d968f5":"def show_dist_plot(df, col:str):\n    \"\"\"\n    \ud574\ub2f9 \ub370\uc774\ud130\ud504\ub808\uc784\uc758 \ud53c\ucc98\uc5d0 \ubd84\ud3ec \ubc0f kde plot\uc744 \uc2dc\uac01\ud654\n    \"\"\"\n    g = sns.distplot(a=df[col], color=\"b\", label=\"skewness : {:.2f}\".format(df[col].skew()))\n    g.set_title(\"Skewnewss for {0}\".format(col))\n    g = g.legend(loc=\"best\")","64edc61b":"num_cols = int_cols[1:].index.values\ndisplay(num_cols)\n\n# \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b \uc870\uc778\ud55c \ub370\uc774\ud130\uc14b\ndataset[num_cols].isnull().sum()","6a47a2f7":"#Fill Fare missing values with the median value\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","010e8284":"# Recheck \ndataset[\"Fare\"].isnull().sum()\ndisplay(dataset[num_cols].isnull().sum())","c107b804":"# before logarithm - display Fare Distribution\nshow_dist_plot(dataset, 'Fare')","acadb2e0":"#dataset[\"Fare\"] = dataset[\"Fare\"].apply(lambda x: np.log1p(x))\n# The following method is also for logarithm\ndataset[\"Fare\"] = dataset[\"Fare\"].apply(lambda x: np.log(x) if x > 0 else 0)","8924eea5":"# After logarithm conversion\nshow_dist_plot(dataset, \"Fare\")","7cc1ffa5":"def show_factor_plot(df, xCol=None, yCol=None, col=None, kind='bar', hue=None):\n    \"\"\"\n    \ud53c\ucc98\ubcc4 \uc0dd\uc874\ub960 \ube44\uad50\n    \"\"\"\n    g = sns.factorplot(x=xCol, y=yCol, hue=hue, col=col, kind=kind, palette=\"muted\", size=6, data = df)\n    sns.despine(left=True)  # \uc67c\ucabd\uc758 \ucd95 \uc81c\uac70\n    g.set_ylabels(yCol)","3aa23819":"g = sns.barplot(x=\"Sex\", y=\"Survived\", data=train)\ng = g.set_ylabel(\"Survivor Probability for Sex\")","4617d823":"train[[\"Sex\", \"Survived\"]].groupby(\"Sex\").mean()","82979be5":"g = sns.factorplot(x = \"Pclass\", y=\"Survived\", kind='bar', palette=\"summer_r\", size=6, data=train)\ng.despine(left=True)\ng = g.set_ylabels(\"Survivor Probability\")","e0140b7b":"g = sns.factorplot(x = \"Pclass\", y=\"Survived\", kind='bar', palette=\"summer_r\", hue=\"Sex\", size=6, data=train)\ng.despine(left=True)\ng = g.set_ylabels(\"Survivor Probability\")","0296bb54":"# Explore Pclass vs Survived by Sex\nshow_factor_plot(train, \"Pclass\",'Survived', hue='Sex')","2cc3ee5c":"# Embarked\ud53c\ucc98\ndataset[\"Embarked\"].isnull().sum()","eec036d7":"# \uc0ac\uc6b0\uc2a4\ud584\ud2bc\uc774 \uac00\uc7a5 \uc2b9\uac1d\uc774 \ub9ce\ub2e4.\ndataset[\"Embarked\"].value_counts()","592c581c":"#Fill Embarked nan values of dataset set with 'S' most frequent value\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","b2f35019":"# Recheck\ndataset[\"Embarked\"].isnull().sum()","28865093":"g = sns.factorplot(x = \"Embarked\", y=\"Survived\", kind=\"bar\", palette=\"muted\", size=6, data=dataset)\ng.despine(left=True)\ng = g.set_ylabels(\"Survival Probability on Embarked\")","cf4512df":"# Explore Embarked vs Survived \nshow_factor_plot(train, xCol='Embarked', yCol='Survived')","93b95096":"# Explore Pclass vs Embarked \nshow_factor_plot(train, xCol='Pclass', col='Embarked', kind='count')","90e1c25e":"g = sns.factorplot(x=\"Pclass\", col=\"Embarked\", kind=\"count\", size=6, palette=\"muted\", data=dataset)\ng = g.set_ylabels(\"Passengers count\")","cc45693b":"# Explore Age vs Sex, Parch , Pclass and SibSP\ng = sns.factorplot(x=\"Sex\", y=\"Age\", data = dataset, kind=\"box\")\ng = sns.factorplot(x=\"Sex\", y=\"Age\", hue=\"Pclass\", data = dataset, kind=\"box\")\ng = sns.factorplot(x=\"Parch\", y=\"Age\", data = dataset, kind=\"box\")\ng = sns.factorplot(x=\"SibSp\", y=\"Age\", data = dataset, kind=\"box\")","bacac571":"# convert Sex into categoricl value 0 for male and 1 for female\ndataset[\"Sex\"] = dataset[\"Sex\"].apply(lambda x: 0 if x ==\"male\" else 1)\n# dataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\":0, \"female\":1})\ndataset.head(n=3)","7ea409b5":"# \uc55e\uc5d0\uc11c \ud55c\ubc88 np.log1p()\ub85c \ub85c\uadf8\ubcc0\ud658 \ud55c \ub370\uc774\ud130\ub97c \ub2e4\uc2dc \ubc11\uc5d0\uac83 np.logp()\ub97c \uc218\ud589\ud558\uba74 \n# \ud788\ud2b8\ub9f5\uc5d0\uc11c \uc774\uc0c1\ud558\uac8c \ubcf4\uc784\ndf = dataset[[\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Pclass\"]]\ng = sns.heatmap(df.corr(), cmap=\"BrBG\", annot=True)","39d89b2d":"# \uc790\uc190\/\ubc30\uc6b0\uc790 \uc218(SibSp), Parch(\ubd80\ubaa8 + \uc544\uc774), Pclass(\uac1d\uc2e4\ub4f1\uae09) = \uc774 \uc138\uac00\uc9c0 \ud53c\ucc98\uc758 \uac12\uc774 \uac19\uc740\uac83\uc758 median()\uac12\uc73c\ub85c \ub300\uce58\n# \ub9de\ub294\uac83\uc774 \uc5c6\uc73c\uba74 \uadf8\ub0e5 Age\ud53c\ucc98\uc758 median()\uac12\uc73c\ub85c \ub300\uce58\ncond_age_null = dataset[\"Age\"].isnull()\ndisplay(cond_age_null.index)\nindex_NaN_age = cond_age_null.index.values\n\nfor i in index_NaN_age:\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((train[\"SibSp\"] == dataset.iloc[i][\"SibSp\"]) & (dataset[\"Parch\"]==dataset.iloc[i][\"Parch\"]) & (dataset[\"Pclass\"]==dataset.iloc[i][\"Pclass\"]))].median()\n    \n    if not np.isnan(age_pred):\n        dataset[\"Age\"].iloc[i] = age_pred\n    else:\n        dataset[\"Age\"].iloc[i] = age_med","be55d6cd":"dataset[\"Age\"].isnull().sum()      ","ba64da73":"def fill_missing_value_age(df, index_NaN_age: list):\n    \"\"\"\n    \uc790\uc190\/\ubc30\uc6b0\uc790 \uc218(SibSp), Parch(\ubd80\ubaa8 + \uc544\uc774), Pclass(\uac1d\uc2e4\ub4f1\uae09) = \uc774 \uc138\uac00\uc9c0 \ud53c\ucc98\uc758 \uac12\uc774 \uac19\uc740\uac83\uc758 median()\uac12\uc73c\ub85c \ub300\uce58\n    \ub9de\ub294\uac83\uc774 \uc5c6\uc73c\uba74 \uadf8\ub0e5 Age\ud53c\ucc98\uc758 median()\uac12\uc73c\ub85c \ub300\uce58\n    \"\"\"\n    for i in index_NaN_age:        \n        age_med = df[\"Age\"].median()\n        age_pred = df[\"Age\"][((df[\"SibSp\"] == df.iloc[i][\"SibSp\"]) & (df[\"Parch\"]==df.iloc[i][\"Parch\"]) & (df[\"Pclass\"]==df.iloc[i][\"Pclass\"]))].median()\n\n        if not np.isnan(age_pred):\n            df[\"Age\"].iloc[i] = age_pred\n        else:\n            df[\"Age\"].iloc[i] = age_med\n    return df","a611889f":"g = sns.factorplot(x=\"Survived\", y=\"Age\", data=dataset, kind = \"box\")\ng.despine(left=True)\ng = sns.factorplot(x=\"Survived\", y=\"Age\", data = dataset, kind = \"violin\")\ng.despine(left=True)","c6c2c4e8":"show_factor_plot(train, xCol='Survived', yCol='Age', kind='box')\nshow_factor_plot(train, xCol='Survived', yCol='Age', kind='violin')","a5508c69":"def feature_engineering(df, titleOpt=False, familyOpt=False, ticketT=False, dropFeature=False ,familyAdd=False):\n    \"\"\"\n    1.Title\uc5d0 \ub300\ud55c \uc815\uc81c\uc791\uc5c5\n    2.FamilySize \ud53c\ucc98 \ucd94\uac00 \ub3c4\ucd9c \n    3.\uc6d0\ud56b\uc778\ucf54\ub529  - Title, Embarked\n    4.Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n    5.\ubd88\ud544\uc694\ud55c \ud53c\ucc98 \uc0ad\uc81c\n    \"\"\"    \n    if titleOpt:\n        # \ube48\ub3c4\ud45c\ub97c \uc774\uc6a9\ud574 \ud574\ub2f9 \ud53c\ucc98\uc758 \ub9ac\uc2a4\ud2b8\ub97c \uad6c\ud558\uae30 \n        titleList = df[\"Title\"].value_counts().index.values.tolist()\n        df[\"Title\"] = df[\"Title\"].replace(titleList, ['Mr', 'Miss', 'Mrs', 'Master', 'Mr', 'Other', 'Other', 'Other', 'Miss', 'Miss', 'Mr', 'Other', 'Mr', 'Miss', 'Other', 'Other', 'Mrs', 'Mr'])\n        df[\"Title\"] = df[\"Title\"].replace(['Mr','Mrs','Miss','Master','Other'], [0, 1, 2, 3, 4])\n        \n        # Name feature remove\n        df.drop(labels=[\"Name\"], axis = 1, inplace=True, errors=\"ignore\")\n        \n    if familyOpt:\n        try:\n            df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n            \n            dataset[\"Single\"] = dataset[\"FamilySize\"].map(lambda x: 1 if x == 1 else 0)\n            dataset[\"SmallF\"] = dataset[\"FamilySize\"].map(lambda x: 1 if x == 2 else 0)\n            dataset[\"MedF\"]   = dataset[\"FamilySize\"].map(lambda x: 1 if 3 <= x <= 4 else 0)\n            dataset[\"LargeF\"] = dataset[\"FamilySize\"].map(lambda x: 1 if x >= 5 else 0)\n        except KeyError:\n            print(\"\uc774\ubbf8 \uc0ad\uc81c \ucc98\ub9ac\ub41c \ud53c\ucc98\")\n        # \ud53c\ucc98 \ucd94\uac00 \ud6c4  \uae30\uc874 \uceec\ub7fc \uc0ad\uc81c \n        df.drop(labels = ['SibSp', 'Parch'], axis = 1, inplace=True, errors='ignore')  \n        \n    if familyAdd: # FamilySize\uc758 \uac12\uc5d0 \ub530\ub77c 4\uac1c\ub85c \ubd84\ub958\n        dataset[\"Single\"] = dataset[\"FamilySize\"].map(lambda x: 1 if x == 1 else 0)\n        dataset[\"SmallF\"] = dataset[\"FamilySize\"].map(lambda x: 1 if x == 2 else 0)\n        dataset[\"MedF\"]   = dataset[\"FamilySize\"].map(lambda x: 1 if 3 <= x <= 4 else 0)\n        dataset[\"LargeF\"] = dataset[\"FamilySize\"].map(lambda x: 1 if x >= 5 else 0)\n        \n    \n    if ticketT:        \n        Ticket = []\n        for i in list(df[\"Ticket\"]):\n            if not i.isdigit():\n                Ticket.append(i.replace(\".\", \"\").replace(\"\/\", \"\").strip().split(' ')[0])  # \uc55e\uc758 \ubb38\uc790\ub9cc \ucd94\ucd9c\n            else:\n                Ticket.append(\"X\")\n        df[\"Ticket\"] = Ticket\n        display(df[\"Ticket\"].head(n=2))\n    \n    #\ubd88\ud544\uc694\ud55c \uceec\ub7fc \uc0ad\uc81c \n    if dropFeature:\n        df.drop(labels=['PassengerId'], axis=1, inplace=True, errors='ignore')    \n    \n    display(df.head(n=2))\n    return df","dac17264":"display(dataset[\"Name\"].head(2))","c6f4fb1a":"# Get Title from Name\nTitle = [i.split(',')[1].split('.')[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(Title)\ndisplay(dataset.head(3))","7c9733f4":"g = sns.countplot(x=\"Title\", data = dataset)\n# g.get_xticklabels() - x\ucd95\uc758 \ub208\uae08\uc5d0 \ub300\ud55c \ub77c\ubca8\uc744 \ubcf4\uc5ec\uc90c\ng = plt.setp(g.get_xticklabels(), rotation=45)","39a4d619":"dataset[\"Title\"].value_counts()","35dc3473":"dataset = feature_engineering(dataset, titleOpt=True)","58397b13":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Mr\",\"Mrs\",\"Miss\", \"Master\", \"Other\"])","2713076f":"g = sns.factorplot(x=\"Title\", y=\"Survived\", data =dataset, kind=\"bar\")\ng = g.set_xticklabels([\"Mr\",\"Mrs\",\"Miss\", \"Master\", \"Other\"])\ng = g.set_ylabels(\"Survival Probability for Title\")","872967f8":"dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset.drop(labels = [\"SibSp\" , \"Parch\"], axis = 1, inplace = True, errors=\"ignore\")","2bceb7a0":"# Create a family size descriptor from SibSp and Parch\ndataset = feature_engineering(dataset, familyOpt=True)","ecbca4fe":"g = sns.factorplot(x=\"FamilySize\", y=\"Survived\", data = dataset)\ng = g.set_ylabels(\"Survival Probability by FamilySize\")","69aa5e25":"dataset[\"FamilySize\"].value_counts()","e29df554":"# FamilySize\uc5d0 \ub530\ub77c \ud53c\ucc98\ub97c 4\uac1c\ub85c \uad6c\ubd84\ndataset = feature_engineering(dataset, familyAdd=True)","c7e28f35":"def show_factorplot(df, cols):\n    \"\"\"\n    \ub370\uc774\ud130\uc14b\uacfc \uceec\ub7fc\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \ubc1b\uc544\uc11c \n    Factotplot\uc73c\ub85c \ud53c\ucc98\ubcc4 \uc0dd\uc874\ub960\uc744 \ubcf4\uc5ec\uc90c\n    \"\"\"\n    for i in range(len(cols)):\n        g = sns.factorplot(x=cols[i], y='Survived', data=dataset, kind='bar')\n        g = g.set_ylabels(\"Survival Probabilit for {0}\".format(cols[i]))   \n    \n# \ud53c\ucc98\ubcc4 \uc0dd\uc874\ub960    \ncols = [\"Single\" ,\"SmallF\", \"MedF\", \"LargeF\"]\nshow_factorplot(dataset, cols)","c1e2d0e1":"#convert to indicator values Title and Embarked \ndataset = pd.get_dummies(dataset, columns=[\"Title\"])\ndataset = pd.get_dummies(dataset, columns=[\"Embarked\"], prefix=\"Em\")","d4985246":"display(dataset.head())\ndisplay(dataset.info())","ea454f3e":"def display_feature_info(df, feature):\n    \"\"\"\n    \ud30c\ub77c\ubbf8\ud130\ub85c \ub4e4\uc5b4\uc624\ub294 \ud53c\ucc98\uc5d0 \ub300\ud574\uc11c \uae30\uc220\ud1b5\uacc4\uc815\ubcf4, \ub110\uac12 \uac2f\uc218, \ub110\uac12\uc774 \uc544\ub2cc \uac2f\uc218\ub97c \n    \ubcf4\uc5ec\uc90c\n    \"\"\"\n    display(df.info())\n    display(df[feature].head())\n    print(\"\\n\")\n    display(df[feature].describe())\n    \n    # \ub110\uac12 \uac2f\uc218\n    display(\"\ub110\uac12 \uac1c\uc218 :\", dataset[feature].isnull().sum())\n    \n    print(\"\\n\")\n    display(dataset[feature][dataset[feature].notnull()].head(2))\n    \ndisplay_feature_info(dataset, 'Cabin')    ","15966179":"dataset[\"Cabin\"] = [i[0] if not pd.isnull(i) else 'X' for i in dataset[\"Cabin\"]]\ncabin_sort = pd.Series(dataset[\"Cabin\"].value_counts().index.values)\n\ndisplay(sorted(cabin_sort))","5d4317d5":"# countplot\uc744 \uadf8\ub9ac\ub418, \uc815\ub82c\uc21c\uc11c\uac00 Cabin\uc758 \uc62c\ub9bc\ucc28\uc21c\uc73c\ub85c \uc815\ub82c\ng = sns.countplot(dataset[\"Cabin\"], order = sorted(cabin_sort))","bbd05a9e":"g = sns.factorplot(x=\"Cabin\", y=\"Survived\", data=dataset, kind=\"bar\", order=sorted(cabin_sort))\ng = g.set_ylabels(\"Survivor Probability for Cabin\")","2f8c9125":"dataset = pd.get_dummies(dataset, columns=[\"Cabin\"], prefix = 'Cabin')","61aa655f":"dataset.head(3)","6fabf621":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \nTicket = []\n\nfor i in list(dataset[\"Ticket\"]):\n    if not i.isdigit():\n        Ticket.append(i.replace(\",\", \"\").replace(\"\/\", \"\").strip().split(\" \")[0])#\uc55e\uc758 \ubb38\uc790\ub9cc \ucd94\ucd9c\n    else:\n        Ticket.append(\"X\")\n                    \ndisplay(Ticket[1: 10])    ","c1a5bac8":"display_feature_info(dataset, 'Ticket')","0c61e3cc":"dataset = pd.get_dummies(dataset, columns=[\"Ticket\"], prefix = \"T\")","94bd0be7":"display(dataset.head())","c6607e9f":"dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset,columns=[\"Pclass\"], prefix=\"Pc\")","ec9f5d17":"# Drop useless variables \nfeature_engineering(dataset, dropFeature=True)","98698e89":"train = dataset[:train.shape[0]]\ntest = dataset[train.shape[0]:]\n\n\ndisplay(train.shape)\ndisplay(test.shape)\n\ndisplay(train.head(n=2))\n\n# remove Survived feature in test datasets\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True, errors=\"ignore\")\n\ndisplay(test.head(n=2))","6e865ad5":"train[\"Survived\"] = train[\"Survived\"].astype(int)\nY_train = train[\"Survived\"]  # label dataset\nX_train = train.drop(labels=[\"Survived\"], axis = 1)\n\ndisplay(X_train.shape, Y_train.shape)","7594d0bf":"# Cross validation model with KFold Stratified cross val\n# parameter : X - train data, y - label data\n# return train index, test index\nkfold = StratifiedKFold(n_splits = 10)","c166496d":"def model_evaluation(classifiers, X, y, kfold):\n    \"\"\"\n    \ubaa8\ub378\uc5d0 \ub300\ud55c \uc608\uce21 \uc815\ud655\ub3c4 \ud3c9\uac00 \n    \"\"\"\n    cv_results = []\n    classifier_name = []\n    \n    for classifier in classifiers:\n        cv_results.append(cross_val_score(classifier, X, y, scoring='accuracy', cv = kfold, n_jobs = 4,verbose=True))\n        classifier_name.append(classifier.__class__.__name__)\n        \n    cv_means = []\n    cv_std = []\n    \n    for cv_result in cv_results:\n        cv_means.append(cv_result.mean())\n        cv_std.append(cv_result.std())\n        \n    # \ub370\uc774\ud130\ud504\ub808\uc784\uc73c\ub85c \ub9ac\ud134\n    cv_res = pd.DataFrame(data = {'CrossValMeans': cv_means, \"CrossValerrors\": cv_std, \"Algorithm\": classifier_name})\n    display(cv_res)\n    \n    return cv_res, cv_std, cv_means","026385e4":"random_state = 2\nsvc = SVC(random_state=random_state)\ndt_clf = DecisionTreeClassifier(random_state = random_state)\nada_clf = AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state), n_estimators=100, learning_rate=0.05,random_state=random_state)\nrf_clf  = RandomForestClassifier(n_estimators = 150, n_jobs = -1, random_state=random_state)\next_clf = ExtraTreesClassifier(random_state=random_state)\ngrd_clf = GradientBoostingClassifier(learning_rate = 0.5, n_estimators = 500, random_state=random_state)\nmlp_clf = MLPClassifier(random_state=random_state)\nknn_clf = KNeighborsClassifier(n_neighbors = 10)\n#lr_clf  = LogisticRegression(random_state = random_state)\nlda_clf = LinearDiscriminantAnalysis()\n\nclassifiers = []\nclassifiers.append(svc)\nclassifiers.append(dt_clf)\nclassifiers.append(ada_clf)\nclassifiers.append(rf_clf)\nclassifiers.append(ext_clf)\nclassifiers.append(grd_clf)\nclassifiers.append(mlp_clf)\nclassifiers.append(knn_clf)\n#classifiers.append(lr_clf)\nclassifiers.append(lda_clf)\n\n# \uc815\ud655\ub3c4 \ud3c9\uac00\ncv_res, cv_std, cv_means = model_evaluation(classifiers, X_train, Y_train, kfold)","f921c6cc":"cv_res, cv_std, cv_means","c50dc474":"g = sns.barplot(x=\"CrossValMeans\", y=\"Algorithm\", data = cv_res, palette=\"Set3\", orient=\"h\", **{\"xerr\": cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross Validation Scores\")","ed9a3759":"a = {'\uad6d\uc5b4': [20, 30, 40],'\uc601\uc5b4':[10, 20, 30], '\uc218\ud559': [20, 56, 90]}\n\npd.DataFrame(data = a)","3caa6586":"def get_best_estimator(models, X_train, Y_train):\n    \"\"\"\n    \uac01 \ubaa8\ub378\uc5d0 \ub300\ud55c \ucd5c\uc801\uc758 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub97c \ud29c\ub2dd\n    \"\"\"\n    best_model = []\n    best_params = []\n    best_score = []\n    \n    for model in models:\n        model.fit(X_train, Y_train)\n        \n        display(\"Best Estimator : \", model.best_estimator_)\n        display(\"Best Params : \", model.best_params_)\n        display(\"Best Score : \", model.best_score_)\n        \n        best_model.append(model.best_estimator_)\n        best_params.append(model.best_params_)\n        best_score.append(model.best_score_)\n        \n    result = pd.DataFrame({\n                    \"Best Model\": best_model,\n                    \"Best Params\": best_params,\n                    \"Best Score\":best_score\n                 })\n    display(\"\ubaa8\ub378\uc758 \uc608\uce21 \uc131\ub2a5 : \\n\", result)\n    return result","1111c3ef":"# AdaBoost\nmodels = []\ndt_clf  = DecisionTreeClassifier()\nadaDTC = AdaBoostClassifier(dt_clf, random_state=7)\n\nada_param_grid = {\n    'n_estimators': [1, 2, 10, 50],\n    'algorithm': ['SAMME', 'SAMME.R'],\n    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]\n}\ngsadaDTC = GridSearchCV(estimator=adaDTC, param_grid=ada_param_grid, scoring='accuracy', n_jobs=-1, verbose=True, cv=kfold)\n\nmodels.append(gsadaDTC)\n# ExtraTrees\nExtc = ExtraTreesClassifier()\n\nex_param_grid = {\n                \"criterion\": [\"gini\", \"entropy\"],\n                \"max_depth\": [None],\n                \"max_features\": [1, 3, 10],\n                \"min_samples_split\": [2, 3, 10],\n                \"min_samples_leaf\": [1, 3, 10],\n                \"bootstrap\": [False],\n                \"n_estimators\" :[100,300]                \n}\n\ngsExtc = GridSearchCV(Extc, param_grid=ex_param_grid, scoring='accuracy', n_jobs=-1, verbose=True, cv=kfold)\nmodels.append(gsExtc)\n\n# RandomForestClassifier\nrf_clf = RandomForestClassifier()\n\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\ngsRfc = GridSearchCV(rf_clf, param_grid=rf_param_grid, scoring='accuracy', n_jobs= -1, verbose=True, cv=kfold)\nmodels.append(gsRfc)\n\n\n# GradientBoostClassifier\ngdb_clf = GradientBoostingClassifier()\n\ngdb_param_grid = {\n                'loss': ['deviance', 'exponential'],\n                'n_estimators' : [100,200,300],\n                'learning_rate': [0.1, 0.05, 0.01],\n                'max_depth': [4, 8],\n                'min_samples_leaf': [100,150],\n                'max_features': [0.3, 0.1]                 \n}\n\ngsGdb = GridSearchCV(gdb_clf, gdb_param_grid, scoring='accuracy', n_jobs = -1, cv=kfold)\nmodels.append(gsGdb)\n\n#SVM\nsvcs = SVC(probability = True)\n\nsvc_param_grid = {\n    'kernel': ['rbf'],\n    'C': [1, 10, 50, 100,200,300, 1000],\n    'gamma': [0.001, 0.01, 0.1, 1]\n}\n\ngsSvc = GridSearchCV(svcs, param_grid = svc_param_grid, scoring='accuracy', n_jobs = -1, cv = kfold)\nmodels.append(gsSvc)","2acad017":"result = get_best_estimator(models, X_train, Y_train)","d4688ad1":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    \n    # train_sizes - number of trainning examples that has been generated the learning curve\n    # train_scores : Scores on training sets.\n    # test_score   : Scores on test sets\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    \n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    \n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","60c2e771":"for best_model in result[\"Best Model\"]:\n    g = plot_learning_curve(best_model, best_model.__class__.__name__ + \" learning curves\", X_train, Y_train, cv=kfold)","3a66800c":"nrows = ncols = 2\nfig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex='all', figsize=(15, 15))\n\nnames_classifiers = [(best_model.__class__.__name__, best_model) for best_model in result[\"Best Model\"]]\n\nnclassifier = 0\nfor row in range(nrows):\n    for col in range(ncols):\n        name = names_classifiers[nclassifier][0]\n        classifier = names_classifiers[nclassifier][1]\n        \n        indices = np.argsort(classifier.feature_importances_[::-1][:40])\n        g = sns.barplot(y = X_train.columns[:40], x = classifier.feature_importances_[:40], orient='h', ax = axes[row, col])\n        g.set_xlabel(\"Relative Importances\", fontsize=12)\n        g.set_ylabel(\"Features\", fontsize=12)\n        g.tick_params(labelsize=9)\n        g.set_title(name + \" feature importances\")     \n        \n        nclassifier += 1","b992b5ee":"predict_series = [pd.Series(best_model.predict(test), name=best_model.__class__.__name__) for best_model in result[\"Best Model\"]] \nensemble_results = pd.concat(predict_series, axis = 1)\n\ng = sns.heatmap(ensemble_results.corr(), annot=True)","d1b61aa7":"votingC = VotingClassifier(estimators = names_classifiers)\nvotingC.fit(X_train, Y_train)","72ebd6f2":"%cd ..\/output\/","7bd23de7":"test_survived = pd.Series(votingC.predict(test), name=\"Survived\")\nresult = pd.concat([IDTEST, test_survived], axis =1)","d51bf108":"result.to_csv(\"titanic_submission_v01.csv\", index=False)","cc2b0d62":"\uc774\uc0c1\uce58(Outlier)\ub294 \ub370\uc774\ud130\uc758 \ud1b5\uacc4\uce58\ub97c \uc65c\uace1\uc2dc\ud0a4\uae30 \ub54c\ubb38\uc5d0 \ub54c\ub860, \uc544\uc6c3\ub77c\uc774\uc5b4\ub97c \ud1b5\uacc4\uce58\uc5d0 \uc81c\uc678\uc2dc\ud0a4\uae30\ub3c4 \ud55c\ub2e4.\n\n1977\ub144\ub3c4 Turjey, JW\uac00 \ubc1c\ud45c\ud55c Turkey Method\uc5d0 \ubc29\ubc95\uc5d0 \uc758\ud574 \uc544\uc6c3\ub77c\uc774\uc5b4\ub97c \ucc3e\uae30\uc704\ud574 IQR\uc5d0 outlier step\ub9cc\ud07c \ub354\ud558\uac70\ub098 \ube80 \uac12\uc774 \uc774\uc0c1\uce58\uc774\ub2e4.","851dff6a":"#### Embarked","baab0e8f":"It seems that passengers having a lot of siblings\/spouseds have less change to survive.\n\nSingle passengers (0 SibSp) or with two others persons(SibSp 1 or 2) have more change to survive.\n\nThis observation is quite interesting, we can consider a new feature decribing these categories\n\n\ub3d9\ubc18\uac00\uc871\uc774 2\uba85\ubcf4\ub2e4 \ub9ce\uc740 \uacbd\uc6b0\ub294 \uc0dd\uc874\ub960\uc774 \ub9ce\uc774 \ub0ae\uc544\uc9d0\uc744 \uc54c\uc218 \uc788\ub2e4.\n\ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1\uc744 \ud1b5\ud574\uc11c \uc0c8\ub85c\uc6b4 \ud53c\ucc98\ub97c \ucd94\uac00\uc801\uc73c\ub85c \ub3c4\ucd9c\uc774 \uac00\ub2a5\ud558\ub2e4.","8a0d3d1a":"* **\ucd5c\uc801\uc758 ML\ubaa8\ub378\uc744 \uac00\uc838\uc624\uae30 \uc704\ud55c \ud568\uc218**","3f9fdcad":"#### Age\n\n* [FacetGrid\ucc38\uc870](https:\/\/seaborn.pydata.org\/generated\/seaborn.FacetGrid.html)\n* [\ucca0\ud559\uacfc \ub370\uc774\ud130\uc0ac\uc774\uc5b8\uc2a4](https:\/\/github.com\/SANGSEOSEO\/philosophy_datascience\/blob\/master\/03.Visualization\/Seaborn_FacetGrid.ipynb)","d3217876":"The family size seems to play an important role, survival probability is worst for large families.\n\nAdditionally, i decided to created 4 categories of family size.","4c476516":"* Logarithm transformation","402d8a6b":"The passenger survival is not the same in the 3 classes. First class passengers have more chance to survive than second class and third class passengers.\n\nThis trend is conserved when we look at both male and female passengers.\n\n1\ub4f1\uae09 \uac1d\uc2e4\uc5d0 \uc788\ub294 \uc2b9\uac1d\uc758 \uc0dd\uc874\ub960\uc774 \ub2e4\ub978 \uc5ec\ud0c0\uc758 \uac1d\uc2e4\uc5d0 \uc788\ub294 \uc2b9\uac1d\ubcf4\ub2e4 \ub192\ub2e4\ub294 \uac83\uc740 \ud0c0\uc774\ud0c0\ub2c9 \ub370\uc774\ud130\ub97c \uacc4\uc18d \ubd84\uc11d\ud558\ub2e4\ubcf4\uba74 \uc77c\uad00\ub41c\uac8c \ub098\uc624\ub294 \ud1b5\ucc30\uc774\ub2e4.","d7907edf":"Age\ubc0f Cabin\ud53c\ucc98\ub294 \uacb0\uce21\uce58 \ucc98\ub9ac\ub97c \uc704\ud574\uc11c \uc911\uc694\ud55c \uc5ed\ud560\uc744 \ud560 \uc218 \uc788\ub2e4.","89eb60fe":"* **\ubaa8\ub4c8\ud654**","a8db2794":"Cabin\ud53c\ucc98\ub294 292\uac1c\ub294 \uac12\uc774 \uc874\uc7ac\ud558\uace0 \ub098\uba38\uc9c0\ub294 1097\uac1c\ub294 \ub110\uac12\uc73c\ub85c \uc874\uc7ac\n\n\uac12\uc774 \uc5c6\ub294 \ud53c\ucc98\uc758 \uac12\uc740 'X'\ub85c \ud558\uace0 \uc788\ub294 \ud53c\ucc98\uc758 \uac12\uc740 \uc55e\uc758 \uccab\uae00\uc790\ub9cc \ucd94\ucd9c\ud574\uc11c \ubcf4\uc5ec\uc900\ub2e4.","67a9ed7d":"### 6.2 \uc559\uc0c1\ube14 \ubaa8\ub378 \n#### 6.2.1 ML\ubaa8\ub378 \uc870\ud569\n\n5\uac1c\uc758 ML\ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574 \uc608\uce21\ud55c \ud3c9\uac00\ub97c \uc559\uc0c1\ube14\ubaa8\ub378\uc744 \uc774\uc6a9\ud574 soft voting\uc608\uce21(\uac01 \ubaa8\ub378\uc758 \uc608\uce21\uc758 \ud3c9\uade0\uce58\ub97c \ud569\uc0b0)","c73f452d":"#### Sex\n* bar plot\uc73c\ub85c \uc131\ubcc4 \uc0dd\uc874\ub960\n* Sex\ub85c Groupby\ud558\uc5ec Survived\uc758 mean()\uac12 ","27b0c150":"#### 6.1.2 \ucd5c\uc801\uc758 \ubaa8\ub378\uc744 \uc704\ud55c \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n\nGradientBoostingClassifier, ExtraTrees, RandomForest, AdaBoost, SVC\ub97c GridSearchCV\ub97c \uc774\uc6a9\ud574 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd","1d6845c3":"Small families have more chance to survive, more than single(Parch 0), medium(Parch 3, 4) and largefamilies(Parch 5, 6)\n\nBe careful there is an important standard deviation in the survival of passengers with 3 parents\/children.\n\n\uc0ac\uc774\uc988\uac00 \uc791\uc740 \uc774\ub3d9\uc774 \uc0dd\uc874\ub960\uc774 \ud6e8\uc52c \uc88b\uc740 \uac83\uc744 \uc54c\uc218\uc788\ub2e4. \n\n\ub3d9\ubc18\uac00\uc871\uc774 3\uc778\uc778 \uacbd\uc6b0, \uc0dd\uc874\uc728\uc758 \ud45c\uc900\ud3b8\ucc28\uac00 \uc2ec\ud55c \uac83\uc744 \uc54c\uc218 \uc788\ub2e4.\n\n\ub3d9\ubc18\uac00\uc871\uc5ec\ubd80, \ud639\uc740 \ucd1d \uac00\uc871\uc218 \uac19\uc740 \ud53c\ucc98 \ub3c4\ucd9c\uc774 \ud544\uc694\ud574\ubcf4\uc784.","d8538f37":"The correlation map confirms the factorplots observations except for Parch.\n\nAge is not correlated with Sex, but is negative correlated with Pclass, Parch and SibSp.\n\nIn the plot of Age in function of Parch, Age is growing with the number of parents\/children.But the general correlation is negative.\n\nSo, I decided to use SibSb, Parch and Pclass in order to impute the missing ages.\n\nThe strategy is to fill Age with the median age of similar rows accorng to Pclass, Parch and SibSp.\n\n\uc0c1\uad00\uad00\uacc4 \ub9f5\uc740 Parch \ud53c\ucc98\ub97c \uc81c\uc678\ud55c factorplot\uad00\uce21\uce58\ub97c \ud655\uc778\ud569\ub2c8\ub2e4. \nAge\ud53c\ucc98\uac00 Sex\ub791\uc740 \uad00\ub828\uc131\uc774 \ub5a8\uc5b4\uc9c0\uace0, Pclass, Parch \uadf8\ub9ac\uace0 SibSp\uc640 \uc74c\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \uac00\uc9c0\uace0\uc788\uc2b5\ub2c8\ub2e4.\n\nAge\ud53c\ucc98\uac00 \ubd80\ubaa8 \ubc0f \uc544\uc774\ub4e4\uc758 \uc218\uc5d0 \ub530\ub77c \uc99d\uac00\ud558\ub294 \uacbd\ud5a5\uc740 \uc788\uc9c0\ub9cc, \uc804\ubc18\uc801\uc73c\ub85c\ub294 \uc74c\uc758 \uc0c1\uad00\uad00\uacc4\uc785\ub2c8\ub2e4.\n\n\uadf8\ub798\uc11c Age \uacb0\uce21\uce58\ub97c \ub300\uce58\ud558\uae30 \uc704\ud574 SibSp, Parch \uadf8\ub9ac\uace0 Pclass\ub97c \uc0ac\uc6a9\ud558\uae30\ub85c \ud569\ub2c8\ub2e4.(\uacb0\uce21\uce58 \ub300\uce58\ub294 median)","577b5864":"GradientBoosting and Adaboost classifiers tends to overfit the training set.\nAccording to the growing cross-validation curves GradientBoosting and Adaboost could perform better with more training examples.\n\nSVC and ExtraTrees classifiers seem to better generalized the prediction since the training and cross-validation curves are close together.\n\nGradientBoosting\ubc0f Adaboost \ubd84\ub958\uae30\uac00 \ud559\uc2b5\uc138\ud2b8\uc5d0 \uacfc\uc801\ud569\uc758 \uacbd\ud5a5\uc774 \ubcf4\uc778\ub2e4.\n\uad50\ucc28\uac80\uc99d\ud69f\uc218\uac00 \uc99d\uac00\ud568\uc5d0 \ub530\ub77c, GradientBoosting\uacfc Adaboost\uac00 \ud559\uc2b5\ub370\uc774\ud130\uc758 \ud06c\uae30\uc5d0 \ub530\ub77c \uc131\ub2a5\uc774 \uc88b\uc544\uc9d0\uc744 \ubcf4\uc778\ub2e4.\n\nSVC\uc640 ExtraTrees\ub294 \ud559\uc2b5\uc810\uc218\uc640 \uad50\ucc28\uac80\uc99d \uc810\uc218\uac00 \uc11c\ub85c \uc218\ub834\ud558\ub294 \uc591\uc0c1\uc744 \ubcf4\uc774\uace0\uc788\ub2e4. ","2cc04b8f":"## 6. MODELING","a839e306":"### 2.2 \uc774\uc0c1\uce58 \uac10\uc9c0","3ff7d1ec":"### 6.1 \ub2e8\uc21c \ubaa8\ub378\ub9c1\n#### 6.1.1 \uad50\ucc28\uac80\uc99d \ubaa8\ub378 \n\n10\uac1c\uc758 \uc778\uae30\uc788\ub294 \ubd84\ub958\uae30\ub97c \ud1b5\ud574 \uac01\uac01 Stratified KFold\uad50\ucc28\uac80\uc99d\uc744 \uc774\uc6a9\ud574 \ud3c9\uade0 \uc815\ud655\ub3c4\ub97c \ud3c9\uac00\ud560 \uac83\uc774\ub2e4.\n\n* SVC\n* Decision Tree\n* AdaBoost \n* Random Forest\n* Extra Trees\n* Gradient Boosting\n* Multiple layer perceprton (neural network)\n* KNN\n* Logistic regression\n* Linear Discriminant Analysis","0c0d5cec":"#### SibSP\n* [seaborn - factorplot](https:\/\/www.kite.com\/python\/docs\/seaborn.factorplot)\n* [seaborn - style \uc0ac\uc6a9\uc790 \uc815\uc758](http:\/\/hleecaster.com\/python-seaborn-set-style-and-context\/)","ed0db4d6":"### 5.3 Cabin","3faca584":"* **\ud53c\ucc98\ub4e4\uac04\uc758 \uc0c1\uad00\uad00\uacc4 \ubcf4\uae30**","09ca410c":"* **Read Evaluate Print Loop**","d8231a58":"10\uac1c\uc758 \uc774\uc0c1\uce58 \ub370\uc774\ud130\uac00 \ubc1c\uacac\ub418\uc5c8\uc73c\uba70 , 28\ubc88, 89\ubc88 \uadf8\ub9ac\uace0 342\ubc88\uc758 \uc2b9\uac1d\uc758 \uc694\uae08\uc774 \ube44\uc815\uc0c1\uc801\uc73c\ub85c \ub192\uc74c.\n\n\ub098\uba38\uc9c0 7\uac1c \ub85c\uc6b0\ub294 \ub9e4\uc6b0 \ub192\uc740 SibSp\uac12\uc744 \uac16\uace0 \uc788\ub2e4.","4610e26f":"#### Parch","49757e97":"**Read Evaluate Print Loop**","1cd636fe":"* **Read Evaluate Print Loop**","5b0ed7d2":"* **Read Evaluate Print Loop**","80e2e412":"### 3.2 \ubc94\uc8fc\ud615 \ud53c\ucc98\uc758 \uac12","ea4bde56":"* One-Hot Encoding","d7fbe366":"It could mean that tickets sharing the same prefixes could be booked for cabins placed together.It could therefore lead to the actual placement of the cabins within the ship.\n\nTickets with sampe prefixes may have a similar class and survival.\n\nSo I decided to replace the Tickets feature column by the ticket prefixe\/\nWhich may be more informative.\n\n\ub3d9\uc77c\ud55c \ud2f0\ucf13\ubc88\ud638\uc758 \uc811\ub450\uc0ac\ub97c \uac16\ub294 \uc2b9\uac1d\uc758 \uacbd\uc6b0\ub294 \ub3d9\uc77c\ud55c \uac1d\uc2e4\uacfc \uadf8\uc5d0 \uc900\ud558\ub294 \uc0dd\uc874\uac00\ub2a5\uc131\uc774 \ub192\uc544\uc9c8 \uac83\uc73c\ub85c \ucd94\ub860\uc774 \uac00\ub2a5","ad775805":"* **\ubaa8\ub4c8\ud654**","7e1a0347":"\ub85c\uadf8\ubcc0\ud658 \ud6c4\uc5d0 \ud3b8\ud5a5\uc815\ub3c4\uac00 \uc0c1\ub2f9\ud788 \uac10\uc18c\ud588\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4","621a43ef":"Not Survived - density line is put on top of Survived density line. We clearly see a peak corresponsing (between 0 and 5) to babies and youd childresn. ","448d41e5":"No difference between median value of age in survived and not survived supopulation.\n\nBut in the violin plot of survived passengers, we still notice that very young passengers have higher survival rate.\n\n\uc0ac\ub9dd\uc790\uc640 \uc0dd\uc874\uc790\uc758 Age\uc758 median\uac12\ub3c4 \ud06c\uac8c \ucc28\uc774\uac00 \uc5c6\ub2e4.\n\nviolin plot\uc744 \ubcf4\uba74 \ub098\uc774\uac00 \uc5b4\ub9b0 \uc601\uc5ed\ub300\uc758 \uc0dd\uc874\ub960\uc774 \uc0c1\ub2f9\ud788 \ub192\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4.","ae5e37b5":"Factorplots of family size categories show that Small and Medium families have more chance to survive than single passengers and large families.\n\n2\uc778, 3\uc778, 4\uc778\uc815\ub3c4\uc758 \uc778\uc6d0\uc73c\ub85c \uac00\uc871\ub07c\ub9ac \ud0d1\uc2b9\ud55c \uacbd\uc6b0 \uc0dd\uc874\ub960\uc774 1\uc778 \ud639\uc740 5\uc778 \uc774\uc0c1\uc758 \uac00\uc871 \ubc0f \uce5c\uc9c0\ub07c\ub9ac \uc2b9\uc120\ud55c \uacbd\uc6b0\ubcf4\ub2e4 \uc0dd\uc874\ub960\uc774 \uc88b\ub2e4\ub294 \uc810\uc740 \uae30\uc5b5\ud558\uc790. \n\n\ud63c\uc790\ubcf4\ub2e4 \ub458\uc774, \ub458\ubcf4\ub2e4\ub294 \uc138\uba85\uc774\uc11c \uc5ec\ud589\uac00\ub77c. \uadf8\ub7ec\uba74 \uc0ac\uace0\ub2f9\ud574\uc11c \ub3cc\uc544\uc624\uc9c0 \ubabb\ud560 \ud655\ub960\uc774 \uc904\uc5b4\ub4e0\ub2e4.","f6812aab":"* **Read Evaluate Print Loop**","36aa3330":"Indeed, the third class is the moset frequent for passenger coming form Southampton (S) and Queenstown(Q),  whereas Cherbourg passengers are mostly in first class which have the highest survival ratio.\n\nAt this point, I can't explain why first class has an higher survival ratio.\nMy hypothesis is thart first class passengers where prioritised during the evacuation due to their influence.\n\nThe difference of survival ratio from passengers between 1st class passengers and 2nd, 3rd class passengers could be ascribed to 1st class passengers's social influence or the Titanic's cabin structure design.\n\n\uc0ac\uc6b0\uc2a4\ud584\ud2bc\uacfc \ud038\uc988\ud0c0\uc6b4\uc758 \uc2b9\uac1d\ub4e4\uc758 \ub300\ubd80\ubd84\uc740 3\ub4f1\uae09 \uac1d\uc2e4\uc5d0 \ubd84\ud3ec\ub418\uc5b4 \uc788\uc73c\uba70, \ucd94\ub860\uc740 \uc774 \uc0ac\ub9dd\uc790\uc758 \ub300\ubd80\ubd84\uc740 \ud038\uc988\ud0c0\uc6b4\uacfc \uc0ac\uc6b0\uc2a4\ud584\ud2bc \ud0d1\uc2b9\uac1d \uc77c \uac83\uc774\ub2e4.\n\n\ubc18\uba74 \uccb4\ub974\ubcf4\ub974\uadf8 \ud0d1\uc2b9\uac1d\ub4e4\uc740  1\ub4f1\uae09\uc774 \uac00\uc7a5 \ub9ce\ub2e4. \n\n1\ub4f1\uae09 \uac1d\uc2e4\uc758 \uc0dd\uc874\ub960\uc774 \ub192\uc740 \uc774\uc720\ub294?\n-> \uc0ac\ud68c\uc801 \uc601\ud5a5\ub3c4 \uc778\uac00, \uc544\ub2c8\uba74 \uad6c\uc870\uac00 \uc6a9\uc774\ud55c \uc5ec\uac1d\uc120\uc758 \uad6c\uc870\uc801 \ubb38\uc81c\uc778\uac00?","8c1ce7c9":"**Age, Sex \uadf8\ub9ac\uace0 FamilySize\uac00 \uc0dd\uc874\ub960 \uc608\uce21\uc5d0 \uc911\uc694 \uc778\uc790**","8b7fe3a8":"**ListComprehensin**","89be57ba":"* **Read Evaluate Print Loop**","0a412138":"### 5.1 Name\/Title","57d3e4dd":"* **Read Evaluate Print Loop**","379957ec":"* **ML\ubaa8\ub378\ubcc4 \ucd5c\uc801\ud654 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815**","6b3ae2bc":"It is clearly obvious that Male have less chance to survive than Female.\n\nSo Sex might play an important role in the prediction of the survival.\n\nFor those who have seen the Titanic movie(1997), I am sure that we all remember this script during the evacuation from shipwreckage.\n\n<span style=\"color:red\">**\"Women and children first\"**<\/span>\n\nComparing to the Titanic ,However What do you think about the Sewol ship in Repubic of South Korea in 15th April , 2015.\nThe only voice from the person in charge was the following.\n\n<span style=\"color:red\">**\"Don't go out of the canbin until we sign.Don't stay out of the cabin.\"**<\/span>","95dd7550":"The Name feature contains information on passenger's title.\n\nSince some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model.","9f37ec60":"Ticket\uc740 \ud53c\ucc98\uc758 \uc131\uaca9\uc0c1, \uac1d\uc2e4\uc758 \ub4f1\uae09\uc774 \ud2f0\uac9f\ubc88\ud638\uc5d0 \uc228\uc5b4\uc788\ub294 \uc758\ubbf8\uac00 \uc788\uae30\ub54c\ubb38\uc5d0, \uc6b0\ub9ac\ub294 \uc5ec\uae30\uc11c \uc880\ub354 \uc788\ub294 \uc758\ubbf8\uc788\ub294 \uacb0\uacfc\ub97c \uc704\ud574 Ticket\ud53c\ucc98\uc758 Prefix\ub97c \ucd94\ucd9c\ud574\uc11c \uad00\ub9ac\ud558\uae30\ub85c \ud568","3fca6d46":"* **Read Evaluate Print Loop**","cbe3eacf":"* [box v.s violin] (https:\/\/junklee.tistory.com\/9)","539cb964":"## 3. \ud53c\ucc98 \ubd84\uc11d\n### 3.1 \uc22b\uc790\ud615 \uac12","5226c156":"Only Fare feature seems to have a significative correlation with the survival probabilty. \n\nIt doesn't mean that the other features are not usefule. Subpopulations in these fatures can be correlated with the survival.\n\nTo determine this, we need to explore in detail these features.\n\nFare\ud53c\ucc98\uac00 \uc0dd\uc874\ub960\uacfc\ub294 \uc758\ubbf8\uc788\ub294 \uc0c1\uad00\uad00\uacc4\ub97c \uac00\uc9c0\uace0\uc788\uc2b5\ub2c8\ub2e4. \n\n\uadf8\ub807\ub2e4\uace0 \ud574\uc11c \ub2e4\ub978 \ud53c\ucc98\ub4e4\uc774 \uc804\ud600 \ud544\uc694\uc5c6\ub2e4\ub294 \uc758\ubbf8\ub294 \uc544\ub2d9\ub2c8\ub2e4. \uae30\uc874 \ud53c\ucc98\ub97c \uc774\uc6a9\ud574 \uc0c8\ub86d\uac8c \ud30c\uc0dd\ubcc0\uc218\ub97c \uc0dd\uc131\ud574\ubcf4\uba74 \uc0c1\uad00\uad00\uacc4\ub97c \uc0c8\ub86d\uac8c \ub3c4\ucd9c\ub418\ub294 \uacbd\uc6b0\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uadf8\ub7f0\uba74\uc5d0\uc11c \ub2e4\ub978 \ud53c\ucc98\ub4e4\uc740 \ub610\ub2e4\ub978 \uc758\ubbf8\ub97c \uac16\uc2b5\ub2c8\ub2e4.\n\n\"\ud638\ub791\uc774\ub294 \uc8fd\uc5b4\uc11c \uac00\uc8fd\uc744 \ub0a8\uae30\uace0 \uc0ac\ub78c\uc740 \uc8fd\uc5b4\uc11c \uc774\ub984\uc744 \ub0a8\uae34\ub2e4.\"\n\ud53c\ucc98\uc758 \uc18c\uba78 \uc790\uccb4\ub3c4 \uc758\ubbf8\uc788\ub2e4\ub294 \ub9d0\uc500\uc774\uc9c0\uc694.","fd6fd151":"#### Fare","d0cad67c":"**Separate train features and label**","0513f63d":"#### 6.1.3 Plot learning curves\n\n\ud559\uc2b5\uace1\uc120\uc740 \uc608\uce21 \uc815\ud655\ub3c4\uc5d0 \ub300\ud55c \ud559\uc2b5\ud06c\uae30\uc758 \ud6a8\uacfc \ubc0f \ud559\uc2b5\uc138\ud2b8\uc5d0 \ub300\ud55c \uacfc\uc801\ud569  \uacb0\uacfc\ub97c \ubcf4\uae30\uc704\ud55c \uc88b\uc740 \ubc29\ubc95\uc785\ub2c8\ub2e4.\n\n* [Learning Curve](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.learning_curve.html)\n* [Data playground](https:\/\/dataplay.tistory.com\/32?category=855225)","1c668e3b":"#### Pclass","152462d2":"### 6.3 \uc608\uce21\n#### 6.3.1 \uc608\uce21 \ubc0f \uacb0\uacfc \uc81c\ucd9c","5fa946ea":"Because of the low number of passengers that have a cabin, survival probabilities have an important standard deviation and we can't distinguish between survival probability of passengers in the different desks.\n\nBut we can see that passengers with a cabin have generally more chance to survive than passengers without (X).\n\nIt is particularly true for cabin B, C, D, E and F.\n\nCabin\ud53c\ucc98\uc758 \uacbd\uc6b0 \ub110\uac12\uc744 \ub300\uccb4\ud558\uae30\uc804 292\uac1c\uc758 \uac12\ub9cc \ub110\uc774 \uc544\ub2c8\uc5c8\uae30 \ub54c\ubb38\uc5d0 \ud06c\uac8c \uc758\ubbf8\uac00 \uc788\ub2e4\uace0 \ud560\uc21c\uc5c6\uc9c0\ub9cc, \uac12\uc774 \uc788\ub294 \ud53c\ucc98\ub4e4\uc758 \uae30\uc900\uc73c\ub85c\ub9cc \ubcf4\uba74 B, C, D, E, F\uac12\uc744 \uac16\ub294 Cabin\uc758 \uacbd\uc6b0\ub294 \uc0dd\uc874\ub960\uc774 \ub192\uc74c\uc5d0 \uc8fc\ubaa9\ud558\ub77c.\n\n\ub300\uccb4\uc801\uc73c\ub85c Cabin\uc758 \uac12\uc774 \ub110\uc774\uc5c8\ub358 'X'\uc758 \uacbd\uc6b0\ub294 \uc0dd\uc874\ub960\uc774 \ub9ce\uc774 \ub0ae\uc74c\uc744 \uc54c\uc218\uc788\ub2e4. ","95136c78":"#### **\uc218\ud589\uacb0\uacfc**","edc5173c":"Age distribution seems to be the sampe in Male and Female subpopulations, so Sex is not informative to predict Age.\n\nHowever, 1st class passengers are older than 2nd class passengers who are also older than 3rd class passengers.\n\nMoreover, the more a passenger has parents\/children the older he is and the more a passenger has sblings\/spouses the younger he is.\n\n\uc131\ubcc4\uc774 \uc5f0\ub839\ub300\ub97c \uc608\uce21\ud560 \uc218 \uc788\ub294 \uacb0\uc815\uc778\uc790\ub294 \uc544\ub2c8\ub2e4.\n\n\uadf8\ub7ec\ub098 1\ub4f1\uae09 \uac1d\uc2e4\uc5d0 \uc788\ub294 \uc2b9\uac1d\uc758 \ub098\uc774\uac00 \ub2e4\ub978 2\ub4f1\uae09 \uac1d\uc2e4, 3\ub4f1\uae09 \uac1d\uc2e4\uc758 \uc2b9\uac1d\ub4e4\ubcf4\ub2e4 \uc5f0\ub839\ub300\uac00 \ub192\ub2e4\ub294 \uc810\uc740 \uc8fc\ubaa9 \ud560 \ub9cc\ud558\ub2e4.\n\n\ubd80\ubaa8 \ubc0f \uc544\uc774\ub4e4\uc744 \ub3d9\ubc18\ud55c \uacbd\uc6b0\uac00 \uc790\uc2dd,\ubc30\uc6b0\uc790\ub97c \ub3d9\ubc18\ud55c \uacbd\uc6b0\ubcf4\ub2e4 \uc5f0\ub839\ub300\uac00 \ub192\ub2e4\ub294 \uac83\uc744 \uc54c \uc218 \uc788\ub2e4.","a9233acd":"### 5.2 Family size\n\uac00\uc871\uc218(FamilySize)\ud53c\ucc98 \ucd94\uac00  - SibSp(\ub3d9\ubc18\uac00\uc871(\uc790\uc190 + \ubc30\uc6b0\uc790)) , Parch(\ubd80\ubaa8\ub2d8 \ub3d9\ubc18\ub41c \uc544\uc774\ub4e4 \ud3ec\ud568)","3f0a724e":"### 2.4 \ub110\uac12\uacfc \uacb0\uce21\uce58 \ud655\uc778","2afcc106":"The first letter of the cabin indicates the Desk, i choosed to keep this information only, since it indicates the probable location of the passenger in the Titanic.","b1e6669b":"## 1. \uc18c\uac1c\n\n\uce90\uae00\uc5d0\uc11c \uc138\ubc88\uc9f8\ub85c \ud0c0\uc774\ud0c0\ub2c9 \uad00\ub828 \ub370\uc774\ud130\uc14b\uc744 \uac00\uc9c0\uace0  \ub2e4\uc74c\uacfc \uac19\uc740 \ubc29\ubc95\uc73c\ub85c \uc9c4\ud589\ud558\ub824\uace0 \ud55c\ub2e4.\n\nNo matter what you're going through, there's a light at the end of the tunnel. \n\nIt may seem hard to get to it, but you can do it.\n\nJust keep working towards to it and you will find the positive side of things.\n  [Demi Lovato]\n\n* **\ud53c\ucc98 \ubd84\uc11d**\n* **\ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1**\n* **\ubaa8\ub378\ub9c1**","c76faa5c":"There is 17 titles in the dataset, most of then are very rare and we can group them into 4 categories.","9540149e":"At this stage, we have 22 features.","0432cca1":"## 2.\ub370\uc774\ud130 \ub85c\ub4dc \ubc0f \ub370\uc774\ud130 \ud655\uc778\n### 2.1 \ub370\uc774\ud130 \ub85c\ub4dc ","c549f65c":"\uc559\uc0c1\ube14 \ubaa8\ub378\ub9c1\uc73c\ub85c GradientBoostingClassifier, ExtraTrees, RandomForest, AdaBoost, SVC\ub97c \uc0ac\uc6a9\ud560 \uac83\uc784.","2df5776c":"* **Read Evaluate Print Loop**","f9e3e2d0":"As we can see, Fare distribution is very skewed.This can lead to overweight veryl high values in the model, even if it is scaled.\n\n\uc704\uc758 \uadf8\ub798\ud504\ucc98\ub7fc , Fare band\uac00 \ub9e4\uc6b0 \ud3b8\ud5a5\ub418\uc5b4\uc788\uc74c\uc744 \uc54c\uc218 \uc788\ub2e4. \uc774\ub7f0 \ub370\uc774\ud130\ub97c \uadf8\ub0e5 \ubaa8\ub378\uc5d0 \ud559\uc2b5\uc2dc\ud0a4\uba74 \uacfc\uc801\ud569\ub418\uae30 \ub54c\ubb38\uc5d0 Min\/Max Scaler\ud639\uc740 Standard Scaler\ub85c \uc815\uaddc\ud654 \uc2a4\ucf00\uc77c\ub9c1 \ud6c4 \ub85c\uadf8\ubcc0\ud658\uc744 \uc801\uc6a9\ud574\uc57c \ud55c\ub2e4.\n\nnp.log1p\ubcc0\ud658\uacfc np.log()\ubcc0\ud658\uc744 \uac19\uc774 \ud55c\ub2e4\uba74 \uc774\ub54c\uc758 \ud3b8\ud5a5\uc815\ub3c4\ub294?\nWhat if we do both np.log1p and np.log ?","ad34b8d2":"### 2.3 \ud559\uc2b5 \ub370\uc774\ud130\uc14b\ud2b8\uc640 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc138\ud2b8 \uc870\uc778","85851f06":"It seems that passengers from Cherbourg(C) have more chance to survive.\n\nMy hypothesis is that the proportion of first class passengers is higher for those who came from Chebourg than Queenstown(Q), Southhamptom(S).\n\nLet's see the Pclass distribution v.s Embarked.\n\n\ud504\ub791\uc2a4 \ub178\ub974\ub9dd\ub514 \ud574\uc548\uc5d0 \uc704\uce58\ud55c \uccb4\ub974\ubcf4\ub974\uadf8\ud56d\uc5d0\uc11c \ud0d1\uc2b9\ud55c \uc2b9\uac1d\ub4e4\uc758 \uc0dd\uc874\ub960\uc774 \ub2e4\ub978 \uc0ac\uc6b0\uc2a4\ud584\ud2bc \ud639\uc740 \ud038\uc988\ud0c0\uc6b4\ubcf4\ub2e4 \ud6e8\uc52c \uc0dd\uc874\ub960\uc774 \uc88b\uc74c\uc744 \uc54c \uc218 \uc788\ub2e4.\n\n\uadf8\ub807\ub2e4\uba74, 1\ub4f1\uae09 \uac1d\uc2e4\uc5d0 \ubb35\uc740 \uc2b9\uac1d\ub4e4\uc758 \ube44\uc728\uc774 \ub2e4\ub978 \uacbd\uc720\uc9c0 \ud56d\uad6c - \uccb4\ub974\ubcf4\ub974\uadf8, \uc0ac\uc6b0\uc2a4\ud584\ud2bc, \ud038\uc988\ud0c0\uc6b4\uc5d0\uc11c \uc628 \uc2b9\uac1d\ub4e4\ubcf4\ub2e4 \ub354 \ub9ce\uc744 \uac83\uc774\ub2e4.\n\n\uacbd\uc720\uc9c0\ud56d\uad6c(Embarked) v.s Pclass(\uac1d\uc2e4\ub4f1\uae09)","83342ae6":"#### **\ubaa8\ub378\ubcc4\ub85c \uc815\ud655\ub3c4 \uc2dc\uac01\ud654**","45577dee":"## 4. \uacb0\uce21\uce58 \ucc44\uc6b0\uae30\n### 4.1 Age\n\nAs we see, Age column contains 256 missing values in the whole dataset.\n\nSince there is subpopulations that have more chance to survive (children for example), It is preferable to keep the age feature and to impute the missing values.\n\nTo address this problem, I looked at the moset correlated features with Age(Sex, Parch, Pclass and SibSp)\n\n\uc55e\uc5d0\uc11c \ubcf4\ub4ef\ud788, Age\ud53c\ucc98\ub294 256\uac1c\uc758 \uacb0\uce21\uce58\ub97c \ud3ec\ud568\ud558\uace0\uc788\ub2e4.\n\nAge\uac00 \uc18d\ud55c \uc5f0\ub839\ub300\uc5d0 \ub530\ub77c \uc0dd\uc874\ub960\uc774 \uadf9\uba85\ud558\uac8c \uac08\ub9ac\ub294 \ubd80\ubd84\uc774 \uc788\uae30 \ub54c\ubb38\uc5d0 \uc911\uc694\ud55c \ud53c\ucc98\ub77c\uace0 \ud560 \uc218 \uc788\uc73c\uba70, \uc774\ub97c \uc704\ud574\uc11c\ub77c\ub3c4 \uacb0\uce21\uce58\ub97c \ub300\uce58\ud560 \ubd80\ubd84\uc774 \ud544\uc694\ud558\ub2e4.\n\n\uc774\ub97c \uc704\ud574\uc11c\ub294 Sex, Parch, Pclass \uadf8\ub9ac\uace0 SibSp\ub97c \uc774\uc6a9\ud574 \uc0c8\ub85c\uc6b4 \ud53c\ucc98\ub97c \uc0dd\uc131\ud558\ub294 \ubb38\uc81c\ub97c \uc0dd\uac01\ud574\ubcf4\uc790","de9d4836":"## 5. \ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1","6ab50816":"* **\ubaa8\ub4c8\ud654**","5ea107df":"#### 6.1.4 Feature importance of tree based classifiers\n\n\uc2b9\uac1d\uc758 \uc0dd\uc874\ub960\uc744 \uc608\uce21\ud558\uae30 \uc704\ud55c \uac00\uc7a5 \uc911\uc694\ud55c \ud53c\ucc98\ub294 \ubb34\uc5c7\uc778\uc9c0 feature_importance\ub97c \ud1b5\ud574 \uc54c\uc544\ubcf8\ub2e4.","44b5937d":"The prediction seems to be quite similar for the 5 classifiers except when Adaboost is compared to the others classifiers.\n\nThe 5 classifiers give more or less the same prediction but there is some differences. Theses differences between the 5 classifier predictions are sufficient to consider an ensembling vote. ","f4ae984b":"# Titanic Top 4% with ensemble modeling\n\n* **1 \uc18c\uac1c**\n* **2 \ub370\uc774\ud130 \ub85c\ub4dc \ubc0f \uccb4\ud06c**\n    * 2.1 \ub370\uc774\ud130 \ub85c\ub4dc \n    * 2.2 \uc774\uc0c1\uce58 \uac10\uc9c0\n    * 2.3 \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc138\ud2b8 \uc870\uc778\n    * 2.4 \ub110 \ubc0f \uacb0\uce21\uce58 \n* **3 \ud53c\ucc98 \ubd84\uc11d**\n    * 3.1 \uc218\uce58\ud615 \uac12\n    * 3.2 \ubc94\uc8fc\ud615 \uac12\n* **4 \uacb0\uce21\uce58 \ucc98\ub9ac**\n    * 4.1 Age\n* **5 \ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1**\n    * 5.1 Name\/Title\n    * 5.2 Family Size\n    * 5.3 Cabin\n    * 5.4 Ticket\n* **6 \ubaa8\ub378\ub9c1**\n    * 6.1 \ub2e8\uc21c ML\ubaa8\ub378\n        * 6.1.1 \uad50\ucc28 \uac80\uc99d \ubaa8\ub378\n        * 6.1.2 \ubca0\uc2a4\ud2b8\ubaa8\ub378\uc5d0 \ub300\ud55c \ud558\uc774\ud130 \ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd\n        * 6.1.3 \ud559\uc2b5\uace1\uc120 \ud3f4\ub86f\n        * 6.1.4 \ud2b8\ub9ac\uae30\ubc18\uc758 \ubd84\ub958\uae30\uc5d0 \ub300\ud55c \ud53c\ucc98 \uc911\uc694\ub3c4\n    * 6.2 \uc559\uc0c1\ube14 \ubaa8\ub378\ub9c1\n        * 6.2.1 \ubaa8\ub378 \uc870\ud569\n    * 6.3 \uc608\uce21\n        * 6.3.1 \uc608\uce21 \ubc0f \uacb0\uacfc \uc608\uce21\n    ","56d4836b":"#### **\ubaa8\ub378 \ud3c9\uac00**","350a486d":"* \ud568\uc218 \ud638\ucd9c","444887fd":"### 5.4 Ticket","2ee271d0":"* Check the skewness of Fare feature","e3010089":" **One-Hot Encoding Title and Embarked**","ddef80d7":"* One-Hot Encoding","27d01f8c":"\uc5f0\ub839\ub300\ub97c \uad6c\ubd84\ud560 \ud544\uc694\uac00 \uc788\uc5b4\ubcf4\uc784.\uc5f0\ub839\uc5d0 \ub300\ud55c \uc0ac\ub9dd\uacfc \uc0dd\uc874\uc758 \ucc28\uc774\ub294 \ud06c\uac8c \ub450\ub4dc\ub7ec\uc9c0\uc9c0\ub294 \uc54a\uc9c0\ub9cc, \uc5f0\ub839\ub300\uac00 \ub4a4\ub85c \uac08\uc218\ub85d \uc0ac\ub9dd\uacfc \uc0dd\uc874\uc758 \uad6c\ubcc4\uc740 \ud655\uc5f0\ud788 \ub4dc\ub7ec\ub0a0\uac83\uc73c\ub85c \ubcf4\uc784","c605b63c":"* **\ubaa8\ub4c8**","29453beb":"#### **\ubaa8\ub378 \ud3c9\uac00 \uc218\ud589**","8ff2af54":"\"Women and children first\"\n\nIt is interesting to note that passengers with other title have more chance to survive.\n\n\"\uc5ec\uc790\uc640 \uc544\uc774\uba3c\uc800 \uad6c\uc870\" \n\n\"Other\" \ud0c0\uc774\ud2c0\uc774 \uc2b9\uc120\uac1d\uc758 Title\uad6c\uc131\uc744 \ubcfc\ub54c \uc0dd\uc874\ub960\uc774 \ub192\ub2e4.","304848d8":"* **Read Evaluate Print Loop**"}}