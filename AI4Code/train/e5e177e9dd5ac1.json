{"cell_type":{"e38b0354":"code","33ba4054":"code","6ae425fd":"code","81f9da12":"code","076ac239":"code","61fdcb3e":"code","613fa9b9":"code","5fd0dc78":"code","ec77504d":"code","1fbb1e50":"code","575acfe1":"code","48f22c44":"code","59b960cf":"code","f0d3e659":"code","c1d2be30":"code","86cfaa74":"code","f9739e3b":"code","78858886":"code","3c0fd99b":"code","7e8ec436":"code","51c0c700":"code","c9ef0ea5":"code","9cfd476e":"code","000ce0cc":"code","f00bcd73":"code","c60d4c18":"code","a62a1c0c":"code","5fd36ef6":"code","870f5c0d":"code","8631c404":"code","3e3d8c14":"code","8fab2e5f":"code","0a3c3f3c":"code","4ea52893":"code","f54709a6":"code","3f15375f":"code","fbbc8473":"code","1b823aa4":"code","987f1a41":"code","b02779ab":"code","68651768":"code","c54945a0":"code","a362d6e0":"code","fccb1093":"code","40b34c60":"code","ace9f5a9":"code","2012e63e":"code","01b8095e":"code","b37d18c2":"code","57dfd08a":"code","dcb0d3b7":"code","6072ced9":"code","d78773ab":"code","3c9cefe0":"code","82f59da2":"code","9f47f69f":"code","cc7169b8":"code","92de679f":"code","4df65ffd":"code","f70658cc":"code","9d7dbae1":"code","39535d22":"code","3c730b85":"code","47556080":"code","6c982d54":"code","75698b3d":"code","94ae8484":"code","3b9a0ab8":"code","17a96463":"code","47c1f251":"code","55561600":"code","d99cd1c3":"code","2769fb59":"code","e25b65f5":"code","22e2cc89":"code","c74b1427":"code","335d3ba9":"code","8406dbf4":"code","22e37fe7":"code","30b36dd3":"code","ffc2cbeb":"code","8a224eb8":"code","92ebf809":"code","ed488ac5":"code","44cf1c4a":"code","fee60182":"code","f905531d":"code","1837e471":"code","67f49dff":"code","93032691":"code","46310605":"code","4d073c92":"code","9e8a0c4f":"code","baa9aec7":"code","26639b41":"code","c726e17b":"code","a6a8063c":"code","53f078c5":"code","9b1d0649":"code","2e95c0d8":"code","2672a09a":"markdown","edb59c3a":"markdown","59c14679":"markdown","24e237b9":"markdown","4fd9f13a":"markdown","b9d9cc04":"markdown","649fceea":"markdown","58b08484":"markdown","b9a5576c":"markdown","0c99175e":"markdown","cc8aa1f6":"markdown","f7a4c2c6":"markdown","dbf1642b":"markdown","97eecb75":"markdown","3c7f0681":"markdown","4f6d5b92":"markdown","3ddd18f6":"markdown","2ae0c56f":"markdown","baad7546":"markdown","7f9a54e7":"markdown","530c4f30":"markdown","5c75574e":"markdown","bb134909":"markdown","786c338e":"markdown","bed51f34":"markdown","d910b1cc":"markdown","b232d615":"markdown","ad31b46e":"markdown","47e91170":"markdown","2a6625b0":"markdown","1d1d348f":"markdown","ba93f1be":"markdown","8dcfb8ca":"markdown","4d062802":"markdown","c30d462c":"markdown","f8f3b933":"markdown","397d1f62":"markdown","a546b63f":"markdown","964bcaf5":"markdown","4cf9e974":"markdown","699e26a0":"markdown","c47843df":"markdown","5bfc9c8e":"markdown","944eff70":"markdown","89c59b0d":"markdown","f8ecfa9b":"markdown","8fb371aa":"markdown","401d90a7":"markdown","26aacde8":"markdown","1e27194f":"markdown","53c27d30":"markdown","401768d9":"markdown","e6505484":"markdown"},"source":{"e38b0354":"# importing libraries\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport itertools\n\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n\nSEED = 0 ","33ba4054":"# titles = pd.read_csv('title.basics.tsv.gz', sep='\\t', low_memory=False)\n# crews = pd.read_csv('title.crew.tsv.gz', sep='\\t')\n# principals = pd.read_csv('title.principals.tsv.gz', sep='\\t')\n# names = pd.read_csv('name.basics.tsv.gz', sep='\\t')\n# ratings = pd.read_csv('title.ratings.tsv.gz', sep='\\t')\n\n# # saving ratings as csv\n# ratings.to_csv('ratings.csv', index=False)\n\nratings = pd.read_csv('..\/input\/imdb-dataset\/ratings.csv')\n### ratings = pd.read_csv('ratings.csv') # use this instead for local machine","6ae425fd":"# # drop originalTitle and endYear column in titles \n# titles.drop(['originalTitle', 'endYear','isAdult'], axis=1, inplace=True)\n\n# # drop rows with null values\n# titles.dropna(inplace=True)\n\n# # drop rows with \\N\n# titles.drop(titles[titles.startYear=='\\\\N'].index, inplace=True) \n# titles.drop(titles[titles.runtimeMinutes=='\\\\N'].index, inplace=True) \n# titles.drop(titles[titles.genres=='\\\\N'].index, inplace=True) \n\n# # drop rows with startYear<1990\n# titles[\"startYear\"] = titles[\"startYear\"].astype(int)\n# titles.drop(titles[titles.startYear<1990].index, inplace=True)\n\n# # drop rows with runtime<30 and runtime>1500\n# titles[\"runtimeMinutes\"] = titles[\"runtimeMinutes\"].astype(int)\n# titles.drop(titles[titles.runtimeMinutes<30].index, inplace=True)\n# titles.drop(titles[titles.runtimeMinutes>1500].index, inplace=True)","81f9da12":"# # saving as csv \n# titles.to_csv('titles_clean.csv', index=False) \n\n# loading cleaned file\ntitles = pd.read_csv('..\/input\/imdb-dataset\/titles_clean.csv')\n### titles = pd.read_csv('titles_clean.csv') # use this instead for local machine\ntitles.head() ","076ac239":"# # merge titles with ratings \n# title_ratings = titles.merge(ratings, how='left', left_on='tconst', right_on='tconst')\n\n# # convert numVotes to int and drop rows with <100 votes\n# title_ratings.dropna(inplace=True)\n# title_ratings[\"numVotes\"] = title_ratings[\"numVotes\"].astype(int)\n# title_ratings.drop(title_ratings[title_ratings.numVotes<100].index, inplace=True)","61fdcb3e":"# # saving as csv\n# title_ratings.to_csv('title_ratings.csv', index=False)\n\n# loading cleaned file\ntitle_ratings = pd.read_csv('..\/input\/imdb-dataset\/title_ratings.csv')\n### title_ratings = pd.read_csv('title_ratings.csv') # use this instead for local machine\ntitle_ratings.head() ","613fa9b9":"# # merge principals with ratings\n# principals.drop(['ordering', 'job', 'characters'], axis=1, inplace=True)\n# principals_ratings = principals.merge(ratings, how='left', left_on='tconst', right_on='tconst')\n\n# # calculate average rating and average numVotes per person \n# principals_avg_ratings = principals_ratings.groupby(['nconst']).mean()","5fd0dc78":"# # drop column\n# names.drop(['knownForTitles'], axis=1, inplace=True)\n\n# # merging names with principals\n# names_ratings = names.merge(principals_avg_ratings, how='left', left_on='nconst', right_on='nconst')\n\n# # drop null values\n# names_ratings = names_ratings.drop(names_ratings[names_ratings.averageRating.isnull() == True].index)","ec77504d":"# # saving as csv\n# names_ratings.to_csv('names_ratings.csv', index=False)\n\n# loading cleaned file\nnames_ratings = pd.read_csv('..\/input\/imdb-dataset\/names_ratings.csv')\n### names_ratings = pd.read_csv('names_ratings.csv') # use this instead for local machine\nnames_ratings.head() ","1fbb1e50":"# listing unique genres\nunique_genres = []\nfor show_genres in title_ratings.genres.str.split(pat=','): \n    for genre in show_genres: \n        if genre not in unique_genres: \n            unique_genres.append(genre) \nprint(unique_genres) \nprint(len(unique_genres))","575acfe1":"# each show can have >1 genre \n# -> creating a list of 0s and 1s to represent genres for that title\ndf = title_ratings[['tconst', 'genres']]\n\nlst = []\nfor i in range(len(df)): \n    sub_lst = []\n    sub_lst.append(df.tconst.iloc[i]) \n    for g in unique_genres: \n        if g in df.genres.iloc[i]: \n            sub_lst.append(1)\n        else: \n            sub_lst.append(0)\n    lst.append(sub_lst) ","48f22c44":"# converting it to a dataframe\ngenre = pd.DataFrame(lst,\n                    columns=['tconst', \n                             'Comedy', 'Fantasy', 'Romance', 'Short', \n                             'Western', 'Drama', 'Thriller', 'Documentary', \n                             'Musical', 'Crime', 'Family', 'Biography', \n                             'History', 'Animation', 'Sci-Fi', 'Horror', \n                             'Action', 'Music', 'Mystery', 'Adventure', \n                             'Sport', 'War', 'Adult', 'Game-Show', \n                             'News', 'Talk-Show', 'Reality-TV'])","59b960cf":"genre.head() ","f0d3e659":"# listing unique title type\nunique_titleType = [] \nfor titleType in title_ratings.titleType: \n    if titleType not in unique_titleType: \n        unique_titleType.append(titleType)\nprint(unique_titleType)\nprint(len(unique_titleType))","c1d2be30":"# this is easier to do one hot because there is only 1 title type for each show\ntitleType = pd.get_dummies(title_ratings.titleType)\ntitleType = pd.concat([title_ratings.tconst,titleType], axis=1)","86cfaa74":"titleType.head() ","f9739e3b":"# merging one hot encoded genre with ratings\ngenre_ratings = genre.merge(ratings, how='left') \ngenre_ratings.head() ","78858886":"# top 10 genres\ntotal_by_genre = genre.drop('tconst', axis=1).sum().sort_values(ascending=False) \ntotal_by_genre.head(10) ","3c0fd99b":"# visualizing top 10 in violin plot\ngenre_type = ['Comedy', 'Fantasy', 'Romance', 'Short', \n              'Western', 'Drama', 'Thriller', 'Documentary', \n              'Musical', 'Crime', 'Family', 'Biography', \n              'History', 'Animation', 'Sci-Fi', 'Horror', \n              'Action', 'Music', 'Mystery', 'Adventure', \n              'Sport', 'War', 'Adult', 'Game-Show', \n              'News', 'Talk-Show', 'Reality-TV']\n\ntop_10_genres = ['Drama', 'Comedy', 'Crime', 'Action',\n                 'Mystery', 'Romance', 'Thriller', 'Adventure',\n                 'Documentary', 'Horror']\n\nunpivot_genre_ratings = pd.melt(genre_ratings, \n                                id_vars=['averageRating'], \n                                value_vars=top_10_genres)\n\nunpivot_genre_ratings = unpivot_genre_ratings.loc[unpivot_genre_ratings.value>0]\nunpivot_genre_ratings.rename(columns={'averageRating': 'ratings', 'variable': 'genres'}, inplace=True)\n\nplt.figure(figsize=(16, 6))\nsns.violinplot(data=unpivot_genre_ratings, \n               x='genres', \n               y='ratings', \n               gridsize=120,\n               width=1.2)\nplt.xlabel('Genres', size=20) \nplt.ylabel('Ratings', size=20)\nplt.title('Genres VS Ratings', size=30)\n# plt.savefig('genres_vs_ratings.png', dpi=300)\nplt.show() ","7e8ec436":"# correlation heatmap\nfig, ax = plt.subplots(figsize=(30,30))  \nsns.heatmap(genre_ratings.corr(), annot=True, annot_kws={\"size\":10}, fmt=\".2%\")","51c0c700":"# data preparation for training and testing\nX_gen = genre_ratings[['Comedy', 'Fantasy', 'Romance', 'Short', \n              'Western', 'Drama', 'Thriller', 'Documentary', \n              'Musical', 'Crime', 'Family', 'Biography', \n              'History', 'Animation', 'Sci-Fi', 'Horror', \n              'Action', 'Music', 'Mystery', 'Adventure', \n              'Sport', 'War', 'Adult', 'Game-Show', \n              'News', 'Talk-Show', 'Reality-TV']]\ny_gen = genre_ratings['averageRating']","c9ef0ea5":"# splitting the data into training and testing sets\nX_gen_train, X_gen_test, y_gen_train, y_gen_test = train_test_split(X_gen, y_gen,\n                                                                    test_size = 0.2, \n                                                                    shuffle=True,\n                                                                    random_state=SEED)","9cfd476e":"# train the model\nLR_gen_regressor = LinearRegression() \nLR_gen_regressor.fit(X_gen_train, y_gen_train) ","000ce0cc":"# test the model\nLR_y_gen_pred = LR_gen_regressor.predict(X_gen_test)\n\nLR_compare_gen_df = pd.DataFrame({'Actual': y_gen_test, \n                                  'Predicted Output': LR_y_gen_pred})\nLR_compare_gen_df.head()","f00bcd73":"# evaluate the model\nLR_gen_r2 = r2_score(y_gen_test, LR_y_gen_pred)\nLR_gen_MAE = mean_absolute_error(y_gen_test, LR_y_gen_pred)\n\nprint(f'Coefficients= {LR_gen_regressor.coef_}')\n\nprint(f'MAE            = {LR_gen_MAE}')\nprint(f'MSE            = {mean_squared_error(y_gen_test, LR_y_gen_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_gen_test, LR_y_gen_pred, squared=False)}')\nprint(f'r2             = {LR_gen_r2}')\n\n\nprint(f'Training score = {LR_gen_regressor.score(X_gen_train, y_gen_train)}')\nprint(f'Test score     = {LR_gen_regressor.score(X_gen_test, y_gen_test)}')","c60d4c18":"# train the model\nKNN_gen_regressor = KNeighborsRegressor() \nKNN_gen_regressor.fit(X_gen_train, y_gen_train) ","a62a1c0c":"%%time \n# occasionally adding this function for cells that takes a longer time to load\n\n# test the model\nKNN_y_gen_pred = KNN_gen_regressor.predict(X_gen_test)\n\nKNN_compare_gen_df = pd.DataFrame({'Actual': y_gen_test, \n                                   'Predicted Output': KNN_y_gen_pred})\nKNN_compare_gen_df.head()","5fd36ef6":"%%time \n\n# evaluate the model\nKNN_gen_r2 = r2_score(y_gen_test, KNN_y_gen_pred)\nKNN_gen_MAE = mean_absolute_error(y_gen_test, KNN_y_gen_pred)\n\nprint(f'MAE            = {KNN_gen_MAE}')\nprint(f'MSE            = {mean_squared_error(y_gen_test, KNN_y_gen_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_gen_test, KNN_y_gen_pred, squared=False)}')\nprint(f'r2             = {KNN_gen_r2}')","870f5c0d":"# train the model \nBR_gen_regressor = BayesianRidge() \nBR_gen_regressor.fit(X_gen_train, y_gen_train) ","8631c404":"# test the model\nBR_y_gen_pred = BR_gen_regressor.predict(X_gen_test)\n\nBR_compare_gen_df = pd.DataFrame({'Actuals': y_gen_test, \n                                  'Predicted Output': BR_y_gen_pred})\nBR_compare_gen_df.head()","3e3d8c14":"# evaluate the model\nBR_gen_r2 = r2_score(y_gen_test, BR_y_gen_pred)\nBR_gen_MAE = mean_absolute_error(y_gen_test, BR_y_gen_pred)\n\n\nprint(f'Coefficients = {BR_gen_regressor.coef_}')\nprint(f'MAE            = {BR_gen_MAE}')\nprint(f'MSE            = {mean_squared_error(y_gen_test, BR_y_gen_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_gen_test, BR_y_gen_pred, squared=False)}')\nprint(f'r2             = {BR_gen_r2}')","8fab2e5f":"# train the model\nRF_gen_regressor = RandomForestRegressor() \nRF_gen_regressor.fit(X_gen_train, y_gen_train) ","0a3c3f3c":"# test the model\nRF_y_gen_pred = RF_gen_regressor.predict(X_gen_test)\n\nRF_compare_gen_df = pd.DataFrame({'Actual': y_gen_test, \n                                  'Predicted Output': RF_y_gen_pred})\nRF_compare_gen_df.head()","4ea52893":"# evaluate the model\nRF_gen_r2 = r2_score(y_gen_test, RF_y_gen_pred)\nRF_gen_MAE = mean_absolute_error(y_gen_test, RF_y_gen_pred)\n\nprint(f'MAE            = {RF_gen_MAE}')\nprint(f'MSE            = {mean_squared_error(y_gen_test, RF_y_gen_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_gen_test, RF_y_gen_pred, squared=False)}')\nprint(f'r2             = {RF_gen_r2}')","f54709a6":"# optimal model search for genre\noptimal_gen_MAE = 100 \noptimal_gen_r2 = 0\noptimal_gen_model = ''\n\n# determined using lowest MAE score\nif LR_gen_MAE < optimal_gen_MAE:\n    optimal_gen_MAE = LR_gen_MAE\n    optimal_gen_r2 = LR_gen_r2\n    optimal_gen_model = 'Linear Regression' \nif KNN_gen_MAE < optimal_gen_MAE:\n    optimal_gen_r2 = KNN_gen_r2\n    optimal_gen_MAE = KNN_gen_MAE\n    optimal_gen_model = 'K Nearest Neighbors' \nif BR_gen_MAE < optimal_gen_MAE:\n    optimal_gen_r2 = BR_gen_r2\n    optimal_gen_MAE = BR_gen_MAE\n    optimal_gen_model = 'Bayesian Ridge' \nif RF_gen_MAE < optimal_gen_MAE:\n    optimal_gen_MAE = RF_gen_MAE\n    optimal_gen_r2 = RF_gen_r2\n    optimal_gen_model = 'Random Forest' \n    \n\nprint(f'Optimal model is \\033[1m{optimal_gen_model}\\033[0m with MAE of \\033[1m{optimal_gen_MAE}\\033[0m and r2 of \\033[1m{optimal_gen_r2}\\033[0m')","3f15375f":"# merging one hot encoded title type with ratings\ntitleType_ratings = titleType.merge(ratings, how='left') \ntitleType_ratings.head() ","fbbc8473":"total_by_tt = titleType.drop('tconst', axis=1).sum().sort_values(ascending=False) \ntotal_by_tt","1b823aa4":"# visualizing with violin plot\ntitle_type = ['movie', 'short', 'tvEpisode', 'tvMiniSeries', \n              'tvMovie', 'tvSeries', 'tvShort', 'tvSpecial', \n              'video', 'videoGame']\n\ntop_tt = ['movie', 'tvEpisode', 'tvSeries', 'tvMovie',\n          'video', 'tvMiniSeries', 'tvSpecial']\n\nunpivot_tt_ratings = pd.melt(titleType_ratings, \n                             id_vars=['averageRating'], \n                             value_vars=top_tt)\n\nunpivot_tt_ratings = unpivot_tt_ratings.loc[unpivot_tt_ratings.value>0]\nunpivot_tt_ratings.rename(columns={'averageRating': 'ratings', 'variable': 'titletypes'}, inplace=True)\n\nplt.figure(figsize=(16, 6))\nsns.violinplot(data=unpivot_tt_ratings, \n               x='titletypes', \n               y='ratings', \n               gridsize=120,\n               width=1.2)\nplt.xlabel('Title Types', size=20) \nplt.ylabel('Ratings', size=20)\nplt.title('Title Types VS Ratings', size=30)\nplt.savefig('titletypes_vs_ratings.png', dpi=300)\nplt.show() ","987f1a41":"# correlation heatmap\nfig, ax = plt.subplots(figsize=(30,30))  \nsns.heatmap(titleType_ratings.corr(), annot=True, annot_kws={\"size\":20}, fmt=\".2%\")","b02779ab":"# data preparation for training and testing\nX_tt = titleType_ratings[['movie', 'short', 'tvEpisode', 'tvMiniSeries',\n                          'tvMovie', 'tvSeries', 'tvShort', 'tvSpecial', \n                          'video', 'videoGame']]\ny_tt = titleType_ratings['averageRating']","68651768":"# splitting the data into training and testing sets\nX_tt_train, X_tt_test, y_tt_train, y_tt_test = train_test_split(X_tt, y_tt,\n                                                                test_size = 0.2, \n                                                                shuffle=True,\n                                                                random_state=SEED)","c54945a0":"# train the model\nLR_tt_regressor = LinearRegression() \nLR_tt_regressor.fit(X_tt_train, y_tt_train) ","a362d6e0":"# test the model\nLR_y_tt_pred = LR_tt_regressor.predict(X_tt_test)\n\nLR_compare_tt_df = pd.DataFrame({'Actual': y_tt_test, \n                                 'Predicted Output': LR_y_tt_pred})\nLR_compare_tt_df.head()","fccb1093":"# evaluate the model\nLR_tt_r2 = r2_score(y_gen_test, LR_y_tt_pred)\nLR_tt_MAE = mean_absolute_error(y_gen_test, LR_y_tt_pred)\n\nprint(f'Coefficients= {LR_tt_regressor.coef_}')\n\nprint(f'MAE            = {LR_tt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_tt_test, LR_y_tt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_tt_test, LR_y_tt_pred, squared=False)}')\n\nprint(f'r2             = {LR_tt_r2}')\n\n\nprint(f'Training score = {LR_tt_regressor.score(X_tt_train, y_tt_train)}')\nprint(f'Test score     = {LR_tt_regressor.score(X_tt_test, y_tt_test)}')","40b34c60":"# train the model\nKNN_tt_regressor = KNeighborsRegressor() \nKNN_tt_regressor.fit(X_tt_train, y_tt_train) ","ace9f5a9":"%%time \n\n# test the model\nKNN_y_tt_pred = KNN_tt_regressor.predict(X_tt_test)\n\nKNN_compare_tt_df = pd.DataFrame({'Actual': y_tt_test, \n                                  'Predicted Output': KNN_y_tt_pred})\nKNN_compare_tt_df.head()","2012e63e":"%%time \n\n# evaluate the model\nKNN_tt_r2 = r2_score(y_gen_test, KNN_y_tt_pred)\nKNN_tt_MAE = mean_absolute_error(y_gen_test, KNN_y_tt_pred)\n\nprint(f'MAE            = {KNN_tt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_tt_test, KNN_y_tt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_tt_test, KNN_y_tt_pred, squared=False)}')\nprint(f'r2             = {KNN_tt_r2}')","01b8095e":"# train the model\nBR_tt_regressor = BayesianRidge() \nBR_tt_regressor.fit(X_tt_train, y_tt_train) ","b37d18c2":"# test the model\nBR_y_tt_pred = BR_tt_regressor.predict(X_tt_test)\n\nBR_compare_tt_df = pd.DataFrame({'Actual': y_tt_test, \n                                 'Predicted Output': BR_y_tt_pred})\nBR_compare_tt_df.head()","57dfd08a":"# evaluate the model\nBR_tt_r2 = r2_score(y_gen_test, BR_y_tt_pred)\nBR_tt_MAE = mean_absolute_error(y_gen_test, BR_y_tt_pred)\n\n\nprint(f'Coefficients = {BR_tt_regressor.coef_}')\nprint(f'MAE            = {BR_tt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_tt_test, BR_y_tt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_tt_test, BR_y_tt_pred, squared=False)}')\nprint(f'r2             = {BR_tt_r2}')","dcb0d3b7":"# train the model\nRF_tt_regressor = RandomForestRegressor() \nRF_tt_regressor.fit(X_tt_train, y_tt_train) ","6072ced9":"# test the model\nRF_y_tt_pred = RF_tt_regressor.predict(X_tt_test)\n\nRF_compare_tt_df = pd.DataFrame({'Actual': y_tt_test, \n                                 'Predicted Output': RF_y_tt_pred})\nRF_compare_tt_df.head()","d78773ab":"# evaluate the model\nRF_tt_r2 = r2_score(y_gen_test, RF_y_tt_pred)\nRF_tt_MAE = mean_absolute_error(y_gen_test, RF_y_tt_pred)\n\nprint(f'MAE            = {RF_tt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_tt_test, RF_y_tt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_tt_test, RF_y_tt_pred, squared=False)}')\nprint(f'r2             = {RF_tt_r2}')","3c9cefe0":"# optimal model search for title type\noptimal_tt_MAE = 100 \noptimal_tt_r2 = 0 \noptimal_tt_model = ''\n\n# determined using lowest MAE score\nif LR_tt_MAE < optimal_tt_MAE:\n    optimal_tt_MAE = LR_tt_MAE\n    optimal_tt_r2 = LR_tt_r2\n    optimal_tt_model = 'Linear Regression' \nif KNN_tt_MAE < optimal_tt_MAE:\n    optimal_tt_MAE = KNN_tt_MAE\n    optimal_tt_r2 = KNN_tt_r2\n    optimal_tt_model = 'K Nearest Neighbors' \nif BR_tt_MAE < optimal_tt_MAE:\n    optimal_tt_MAE = BR_tt_MAE\n    optimal_tt_r2 = BR_tt_r2\n    optimal_tt_model = 'Bayesian Ridge' \nif RF_tt_MAE < optimal_tt_MAE:\n    optimal_tt_r2 = RF_tt_r2\n    optimal_tt_MAE = RF_tt_MAE\n    optimal_tt_model = 'Random Forest' \n    \n    \nprint(f'Optimal model is \\033[1m{optimal_tt_model}\\033[0m with MAE of \\033[1m{optimal_tt_MAE}\\033[0m and r2 of \\033[1m{optimal_tt_r2}\\033[0m.')","82f59da2":"# extract features\nruntime_ratings = title_ratings[['runtimeMinutes', 'averageRating']]\nruntime_ratings.head() ","9f47f69f":"runtime_ratings.info() ","cc7169b8":"# visualizing the data\nplt.figure(figsize=(16, 10))\nplt.scatter(title_ratings.runtimeMinutes, title_ratings.averageRating, c='orange') \nplt.xlabel('Runtime (minutes)', size=20) \nplt.ylabel('Ratings', size=20)\nplt.title('Runtime VS Ratings', size=30)\nplt.savefig('runtime_vs_ratings.png', dpi=300)\nplt.show() ","92de679f":"# data preparation for training and testing\nX_rt = runtime_ratings['runtimeMinutes'].values.reshape(-1,1)\ny_rt = runtime_ratings['averageRating']","4df65ffd":"# splitting the data into training and testing sets\nX_rt_train, X_rt_test, y_rt_train, y_rt_test = train_test_split(X_rt, y_rt,\n                                                                test_size = 0.2, \n                                                                shuffle=True,\n                                                                random_state=SEED)","f70658cc":"# train the model\nLR_rt_regressor = LinearRegression() \nLR_rt_regressor.fit(X_rt_train, y_rt_train) ","9d7dbae1":"# test the model\nLR_y_rt_pred = LR_rt_regressor.predict(X_rt_test)\n\nLR_compare_rt_df = pd.DataFrame({'Actual': y_rt_test, \n                                 'Predicted Output': LR_y_rt_pred})\nLR_compare_rt_df.head()","39535d22":"# evaluate the model\nLR_rt_r2 = r2_score(y_rt_test, LR_y_rt_pred)\nLR_rt_MAE = mean_absolute_error(y_rt_test, LR_y_rt_pred)\n\nprint(f'Coefficients= {LR_rt_regressor.coef_}')\n\nprint(f'MAE            = {LR_rt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_rt_test, LR_y_rt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_rt_test, LR_y_rt_pred, squared=False)}')\n\nprint(f'r2             = {LR_rt_r2}')\n\n\nprint(f'Training score = {LR_rt_regressor.score(X_rt_train, y_rt_train)}')\nprint(f'Test score     = {LR_rt_regressor.score(X_rt_test, y_rt_test)}')","3c730b85":"# train the model\nKNN_rt_regressor = KNeighborsRegressor() \nKNN_rt_regressor.fit(X_rt_train, y_rt_train) ","47556080":"%%time \n\n# test the model\nKNN_y_rt_pred = KNN_rt_regressor.predict(X_rt_test)\n\nKNN_compare_rt_df = pd.DataFrame({'Actual': y_rt_test, \n                                  'Predicted Output': KNN_y_rt_pred})\nKNN_compare_rt_df.head()","6c982d54":"%%time \n\n# evaluate the model\nKNN_rt_r2 = r2_score(y_rt_test, KNN_y_rt_pred)\nKNN_rt_MAE = mean_absolute_error(y_rt_test, KNN_y_rt_pred)\n\n\nprint(f'MAE            = {KNN_rt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_rt_test, KNN_y_rt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_rt_test, KNN_y_rt_pred, squared=False)}')\nprint(f'r2             = {KNN_rt_r2}')","75698b3d":"# train the model\nBR_rt_regressor = BayesianRidge() \nBR_rt_regressor.fit(X_rt_train, y_rt_train) ","94ae8484":"# test the model\nBR_y_rt_pred = BR_rt_regressor.predict(X_rt_test)\n\nBR_compare_rt_df = pd.DataFrame({'Actual': y_rt_test, \n                                 'Predicted Output': BR_y_rt_pred})\nBR_compare_rt_df.head()","3b9a0ab8":"# evaluate the model\nBR_rt_r2 = r2_score(y_rt_test, BR_y_rt_pred)\nBR_rt_MAE = mean_absolute_error(y_rt_test, BR_y_rt_pred)\n\nprint(f'Coefficients = {BR_rt_regressor.coef_}')\nprint(f'MAE            = {BR_rt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_rt_test, BR_y_rt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_rt_test, BR_y_rt_pred, squared=False)}')\nprint(f'r2             = {BR_rt_r2}')","17a96463":"# train the model\nRF_rt_regressor = RandomForestRegressor() \nRF_rt_regressor.fit(X_rt_train, y_rt_train) ","47c1f251":"# test the model\nRF_y_rt_pred = RF_rt_regressor.predict(X_rt_test)\n\nRF_compare_rt_df = pd.DataFrame({'Actual': y_rt_test, \n                                 'Predicted Output': RF_y_rt_pred})\nRF_compare_rt_df.head()","55561600":"# evaluate the model\nRF_rt_r2 = r2_score(y_rt_test, RF_y_rt_pred)\nRF_rt_MAE = mean_absolute_error(y_rt_test, RF_y_rt_pred)\n\n\nprint(f'MAE            = {RF_rt_MAE}')\nprint(f'MSE            = {mean_squared_error(y_rt_test, RF_y_rt_pred)}')\nprint(f'RMSE           = {mean_squared_error(y_rt_test, RF_y_rt_pred, squared=False)}')\nprint(f'r2             = {RF_rt_r2}')","d99cd1c3":"# optimal model search for run time\noptimal_rt_MAE = 100 \noptimal_rt_r2 = 0 \noptimal_rt_model = ''\n\n# determined using lowest MAE score\nif LR_rt_MAE < optimal_rt_MAE:\n    optimal_rt_MAE = LR_rt_MAE\n    optimal_rt_r2 = LR_rt_r2\n    optimal_rt_model = 'Linear Regression' \nif KNN_rt_MAE < optimal_rt_MAE:\n    optimal_rt_MAE = KNN_rt_MAE\n    optimal_rt_r2 = KNN_rt_r2\n    optimal_rt_model = 'K Nearest Neighbors' \nif BR_rt_MAE < optimal_rt_MAE:\n    optimal_rt_MAE = BR_rt_MAE\n    optimal_rt_r2 = BR_rt_r2\n    optimal_rt_model = 'Bayesian Ridge' \nif RF_rt_MAE < optimal_rt_MAE:\n    optimal_rt_MAE = RF_rt_MAE\n    optimal_rt_r2 = RF_rt_r2\n    optimal_rt_model = 'Random Forest' \n    \nprint(f'Optimal model is \\033[1m{optimal_rt_model}\\033[0m with MAE of \\033[1m{optimal_rt_MAE}\\033[0m and r2 of \\033[1m{optimal_rt_r2}\\033[0m.')","2769fb59":"# putting it together\nmodels = ['Linear Regression', 'K nearest neighbors', 'Bayesian Ridge', 'Random Forest']\ngenres_r2 = [LR_gen_r2, KNN_gen_r2, BR_gen_r2, RF_gen_r2]\ngenres_MAE = [LR_gen_MAE, KNN_gen_MAE, BR_gen_MAE, RF_gen_MAE]\ngenre_metrics = pd.DataFrame(zip(models, genres_r2, genres_MAE), \n                            columns=['Genre Model', 'r2', 'MAE'])\ngenre_metrics.sort_values('MAE') ","e25b65f5":"titletypes_r2 = [LR_tt_r2, KNN_tt_r2, BR_tt_r2, RF_tt_r2]\ntitletypes_MAE = [LR_tt_MAE, KNN_tt_MAE, BR_tt_MAE, RF_tt_MAE]\ntitletypes_metrics = pd.DataFrame(zip(models, titletypes_r2, titletypes_MAE), \n                            columns=['Title Types Model', 'r2', 'MAE'])\ntitletypes_metrics.sort_values('MAE') ","22e2cc89":"runtime_r2 = [LR_rt_r2, KNN_rt_r2, BR_rt_r2, RF_rt_r2]\nruntime_MAE = [LR_rt_MAE, KNN_rt_MAE, BR_rt_MAE, RF_rt_MAE]\nruntime_metrics = pd.DataFrame(zip(models, runtime_r2, runtime_MAE), \n                            columns=['Runtime Model', 'r2', 'MAE'])\nruntime_metrics.sort_values('MAE') ","c74b1427":"# calculating weights of each model\ngen_weights = optimal_gen_r2 \/ (optimal_gen_r2+optimal_tt_r2+optimal_rt_r2)\ntt_weights = optimal_tt_r2 \/ (optimal_gen_r2+optimal_tt_r2+optimal_rt_r2)\nrt_weights = optimal_rt_r2 \/ (optimal_gen_r2+optimal_tt_r2+optimal_rt_r2)\n\n# running the best models\nif optimal_gen_model == 'Linear Regression': \n    gen_regressor = LinearRegression().fit(X_gen_train, y_gen_train) \nif optimal_gen_model == 'K Nearest Neighbors' : \n    gen_regressor = KNeighborsRegressor().fit(X_gen_train, y_gen_train) \nif optimal_gen_model == 'Bayesian Ridge': \n    gen_regressor = BayesianRidge().fit(X_gen_train, y_gen_train) \nif optimal_gen_model == 'Random Forest': \n    gen_regressor = RandomForestRegressor().fit(X_gen_train, y_gen_train) \ny_gen_pred = gen_regressor.predict(X_gen_test)\n\nif optimal_tt_model == 'Linear Regression': \n    tt_regressor = LinearRegression().fit(X_tt_train, y_tt_train) \nif optimal_tt_model == 'K Nearest Neighbors' : \n    tt_regressor = KNeighborsRegressor().fit(X_tt_train, y_tt_train) \nif optimal_tt_model == 'Bayesian Ridge': \n    tt_regressor = BayesianRidge().fit(X_tt_train, y_tt_train) \nif optimal_tt_model == 'Random Forest': \n    tt_regressor = RandomForestRegressor().fit(X_tt_train, y_tt_train) \ny_tt_pred = tt_regressor.predict(X_tt_test)\n\nif optimal_rt_model == 'Linear Regression': \n    rt_regressor = LinearRegression().fit(X_rt_train, y_rt_train) \nif optimal_rt_model == 'K Nearest Neighbors' : \n    rt_regressor = KNeighborsRegressor().fit(X_rt_train, y_rt_train) \nif optimal_rt_model == 'Bayesian Ridge': \n    rt_regressor = BayesianRidge().fit(X_rt_train, y_rt_train) \nif optimal_rt_model == 'Random Forest': \n    rt_regressor = RandomForestRegressor().fit(X_rt_train, y_rt_train) \ny_rt_pred = rt_regressor.predict(X_rt_test)","335d3ba9":"# calculating the weighted average of each rating and summing them up. \ncompare_df = pd.DataFrame({'Actuals': y_gen_test, \n                           'Weighted Genre': gen_weights*y_gen_pred,\n                           'Weighted Title Type': tt_weights*y_tt_pred, \n                           'Weighted Run Time': rt_weights*y_rt_pred, \n                           'Overall': gen_weights*y_gen_pred+tt_weights*y_tt_pred+rt_weights*y_rt_pred})\ncompare_df.head() ","8406dbf4":"overall_MAE = sum(abs(compare_df['Actuals']-compare_df['Overall']))\/len(compare_df)\n\nprint('\\033[1mMAE score\\033[0m')\nprint(f'Genres (Random Forest)        : {RF_gen_MAE}')\nprint(f'Title type (Linear Regression): {LR_tt_MAE}') \nprint(f'Run time (Random Forest)      : {RF_rt_MAE}') \nprint(f'Overall                       : {overall_MAE}') ","22e37fe7":"%%time \n\ngen_parameters = {'max_depth': range(1,10),         \n                  'n_estimators': range(1,10),\n                  'max_leaf_nodes': range(2,10)}\n\nRF_gen_gs_classifier = GridSearchCV(RF_gen_regressor,\n                                    gen_parameters,\n                                    scoring='r2', \n                                    cv=5)\nRF_gen_gs_classifier.fit(X_gen_train, y_gen_train)\nprint(f'{RF_gen_gs_classifier.best_params_} gives the best r2 score at: {RF_gen_gs_classifier.best_score_}')","30b36dd3":"RF_optimized_gen_regressor = RandomForestRegressor(max_depth=7, \n                                                   max_leaf_nodes=9, \n                                                   n_estimators=4)\nRF_optimized_gen_regressor.fit(X_gen_train, y_gen_train) \nRF_optimized_y_gen_pred = RF_optimized_gen_regressor.predict(X_gen_test)\n\nRF_optimized_gen_MAE = mean_absolute_error(y_gen_test, RF_optimized_y_gen_pred)\nRF_optimized_gen_r2 = r2_score(y_gen_test, RF_optimized_y_gen_pred)\nprint(f'MAE            = {RF_optimized_gen_MAE}')\nprint(f'r2             = {RF_optimized_gen_r2}')\n\nprint(f'Original model: {optimal_gen_model}, {optimal_gen_MAE}')","ffc2cbeb":"%%time\ntt_parameters = {'n_jobs': range(1,10), \n                 'fit_intercept': [True, False]}\n\nLR_tt_gs_classifier = GridSearchCV(LR_tt_regressor,\n                                    tt_parameters,\n                                    scoring='neg_mean_absolute_error', \n                                    cv=5)\nLR_tt_gs_classifier.fit(X_tt_train, y_tt_train)\nprint(\"'{}' gives the best neg MAE score at: {:.2%}\".format(LR_tt_gs_classifier.best_params_, LR_tt_gs_classifier.best_score_))","8a224eb8":"LR_optimized_tt_regressor = LinearRegression(n_jobs=1, fit_intercept=False)\nLR_optimized_tt_regressor.fit(X_tt_train, y_tt_train) \nLR_optimized_y_tt_pred = LR_optimized_tt_regressor.predict(X_tt_test)\n\nLR_optimized_tt_MAE = mean_absolute_error(y_tt_test, LR_optimized_y_tt_pred)\nLR_optimized_tt_r2 = r2_score(y_tt_test, LR_optimized_y_tt_pred)\nprint(f'MAE            = {LR_optimized_tt_MAE}')\nprint(f'r2             = {LR_optimized_tt_r2}')\n\nprint(f'Original model: {optimal_tt_model}, {optimal_tt_MAE}')","92ebf809":"%%time\nrt_parameters = {'max_depth': range(1,10),         \n                  'n_estimators': range(1,10),\n                  'max_leaf_nodes': range(2,10)}\n\nRF_rt_gs_classifier = GridSearchCV(RF_rt_regressor,\n                                    rt_parameters,\n                                    scoring='neg_mean_absolute_error', \n                                    cv=5)\nRF_rt_gs_classifier.fit(X_rt_train, y_rt_train)\nprint(f'{RF_rt_gs_classifier.best_params_} gives the best neg MAE score at: {RF_rt_gs_classifier.best_score_}')","ed488ac5":"RF_optimized_rt_regressor = RandomForestRegressor(max_depth=6, \n                                                  max_leaf_nodes=9, \n                                                  n_estimators=9)\nRF_optimized_rt_regressor.fit(X_rt_train, y_rt_train) \nRF_optimized_y_rt_pred = RF_optimized_rt_regressor.predict(X_rt_test)\n\nRF_optimized_rt_MAE = mean_absolute_error(y_rt_test, RF_optimized_y_rt_pred)\nRF_optimized_rt_r2 = r2_score(y_rt_test, RF_optimized_y_rt_pred)\nprint(f'MAE            = {RF_optimized_rt_MAE}')\nprint(f'r2             = {RF_optimized_rt_r2}')\n\nprint(f'Original model: {optimal_rt_model}, {optimal_rt_MAE}')","44cf1c4a":"# function to predict movie ratings \n# based on the genre, title type and run time being passed in\ndef rating_prediction(movie_genres, movie_titletype, movie_runtime):\n    movie_genre_binary = []\n    for g in unique_genres: \n        if g in movie_genres: \n            movie_genre_binary.append(1) \n        else: \n            movie_genre_binary.append(0) \n\n    movie_titletype_binary = []\n    for tt in unique_titleType: \n        if tt in movie_titletype: \n            movie_titletype_binary.append(1) \n        else: \n            movie_titletype_binary.append(0) \n\n    movie_gen_pred = RF_gen_regressor.predict([movie_genre_binary])\n    movie_tt_pred = RF_tt_regressor.predict([movie_titletype_binary])\n    movie_rt_pred = RF_rt_regressor.predict([[movie_runtime]])\n    \n    predicted_rating = (gen_weights*movie_gen_pred+tt_weights*movie_tt_pred+rt_weights*movie_rt_pred)[0]\n    return predicted_rating","fee60182":"# these are the different types to choose from\nprint(unique_genres) \nprint(unique_titleType)","f905531d":"# Hitman's Wife's Bodyguard\nmovie_genres = ['Comedy', 'Action']\nmovie_titletype = 'movie' \nmovie_runtime = 100\nrating_prediction(movie_genres, movie_titletype, movie_runtime)","1837e471":"# Black widow\nmovie_genres = ['Adventure', 'Action']\nmovie_titletype = 'movie' \nmovie_runtime = 133\nrating_prediction(movie_genres, movie_titletype, movie_runtime)","67f49dff":"# input your own show here:\nmovie_genres = ['Adventure', 'Comedy']\nmovie_titletype = 'movie' \nmovie_runtime = 133\nrating_prediction(movie_genres, movie_titletype, movie_runtime)","93032691":"# listing down all variables for consideration\nprint(top_10_genres)\nprint(top_tt) \n\nunique_runtime = [100, 120, 140, 160, 180, 200]\nprint(unique_runtime)","46310605":"# listing down all possible combinations \nall_variables = [top_10_genres, top_tt, unique_runtime]\nall_combi = list(itertools.product(*all_variables))\nprint(all_combi[:10])","4d073c92":"# looping through all combinations to find the combination with the best rating \nbest_rating = 0 \nbest_combi = []\nfor combi in all_combi: \n    predicted_rating = rating_prediction(combi[0], combi[1], combi[2]) \n    if predicted_rating > best_rating: \n        best_rating = predicted_rating\n        best_combi = combi \nprint(f'The best combination is a \\033[1m{best_combi[0]}\\033[0m \\033[1m{best_combi[1]}\\033[0m of \\033[1m{best_combi[2]}\\033[0mmins long with a rating of \\033[1m{best_rating}\\033[0m.')","9e8a0c4f":"names_ratings.head() ","baa9aec7":"# names with > 10,000 votes \nnames_ratings_10000votes = names_ratings.drop(names_ratings[names_ratings.numVotes<10000].index)\nnames_ratings_10000votes.head() ","26639b41":"plt.figure(figsize=[15,6])\nplt.scatter(names_ratings_10000votes.numVotes, names_ratings_10000votes.averageRating, c='orange')\nplt.xlabel('Average Votes', size=15) \nplt.ylabel('Ratings', size=15)\nplt.title('Average votes VS Ratings', size=25)\nplt.savefig('averagevotes_vs_ratings.png', dpi=300)\nplt.show() ","c726e17b":"# top names with most number of votes \nnames_ratings_10000votes.sort_values('numVotes', ascending=False).head()","a6a8063c":"# Phyllis Carlyle\nprint(names_ratings[names_ratings.nconst=='nm0138287'])\nprint(titles[titles.tconst=='tt0114369'])","53f078c5":"# Lawrence A. Bonney\nprint(names_ratings[names_ratings.nconst=='nm0095029'])\nprint(titles[titles.tconst=='tt0102926'])","9b1d0649":"# Jonas Rivera\nprint(names_ratings[names_ratings.nconst=='nm0729304'])\n# print(titles[titles.tconst=='tt10484166'])\nprint(titles[titles.tconst=='tt1049413'])\n# print(titles[titles.tconst=='tt10559884 '])\n# print(titles[titles.tconst=='tt1702223'])","2e95c0d8":"# top names with highest ratings \nnames_ratings_10000votes.sort_values('averageRating', ascending=False).head()","2672a09a":"<a id='3.3'><\/a>\n##### [Bayesian Ridge](#100)","edb59c3a":"Gridsearch for Run time analysis **did not** improve the score. ","59c14679":"### Creating one hot encoding for genres ","24e237b9":"<a id='5.1'><\/a>\n##### [Linear Regression](#100)","4fd9f13a":"<a id='4.3'><\/a>\n##### [Bayesian Ridge](#100)","b9d9cc04":"Note: There can be multiple genres but only be 1 title type. ","649fceea":"### Merging titles with ratings","58b08484":"# IMDB ratings prediction ","b9a5576c":"<a id='11'><\/a>\n## [Future opportunities](#100) ","0c99175e":"**End notes** <br> \nThis project has been a really fun one for a start to my journey into ML. I am surpised by the amount of things I can acheive from just 2 months of study. Although there are still a lot more things to study and learn (I believe I have only scratched the tip of the iceberg), but it has altered my mindset towards coding, programming, ML and even AI. It is no longer mysterious and far fetch to me. I look forward to learning and exploring more into this area! ","cc8aa1f6":"<a id='3.4'><\/a>\n##### [Random Forest ](#100)","f7a4c2c6":"There are many more areas of improvements for this model that can be done in the future. I would like to include additional features like crews involved and production cost and see how much these features will affect ratings. I would also like to dwelve into deep learning models as well. Ultimately to further improve prediction and scores. ","dbf1642b":"From the chart, we can see that generally drama, crime, mystery and adventure shows are usually rated higher. Shows like thriller and horror on the other hand has lower ratings. ","97eecb75":"<a id='3'><\/a>\n### [Analysing genres and ratings](#100) ","3c7f0681":"For the analysis, I will be running train, test and evaluation on all 4 models. As this is a regression problem, I will be using Mean Absolute Error(MAE) to evaluate the model's efficiency and select the model with the least MAE. ","4f6d5b92":"From the overall prediction, the overall MAE is 0.826. I will run a gridsearch function on all 3 models to look for the best hyperperameters for each model. Let's see if it will further improve the MAE score. ","3ddd18f6":"Gridsearch for Title Type analysis **did not** improve the score.","2ae0c56f":"##### Runtime (Random Forest) ","baad7546":"### Merging names with ratings","7f9a54e7":"<a id='4.5'><\/a>\n### [Optimal Title Type VS Rating model](#100)","530c4f30":"##### Title Type (Linear Regression) ","5c75574e":"Objective: to predict ratings of new shows <br> \nDatasets: https:\/\/datasets.imdbws.com\/ <br> \nDatasets legend: https:\/\/www.imdb.com\/interfaces\/ <br> \n\n- *Datasets for this project downloaded on 1 June 2021*\n\n","bb134909":"<a id='5.5'><\/a>\n### [Optimal Run Time VS Rating model](#100)","786c338e":"<a id='7'><\/a>\n## [Overall prediction](#100)","bed51f34":"### Cleaning up titles dataframe","d910b1cc":"<a id='3.5'><\/a>\n### [Optimal Genre VS Rating model ](#100)","b232d615":"<a id='2'><\/a>\n# [Data cleaning](#100)  ","ad31b46e":"From the above models, Random Forest performed best for genres and runtime and Linear Regression performed the best for title types. Using the r2 score of these 3 models, I calculated the weights by having the r2 score of that model divided by sum of r2 score. Using the weights, I calculated the weighted average of the predicted ratings based on the 3 different predictions. The result is a better MAE score as compared to the rest of the individual models. This is expected because more features will result in a better score. ","47e91170":"**Conclusion** <br> \nAll 3 gridsearch did not give better results. So I will be using the original optimal model for next steps. ","2a6625b0":"<a id='3.2'><\/a>\n##### [KNN](#100) ","1d1d348f":"<a id='1'><\/a>\n# [Loading data](#100) ","ba93f1be":"<a id='4'><\/a>\n### [Analysing title type and ratings](#100)","8dcfb8ca":"Based on the above optimal models, I have written a function to predict future shows ratings with the 3 features (genres, title type and run time). \n\nI have also included 2 upcoming new release. Let's see how accurate this model is in a few month's time! ","4d062802":"##### Shows ratings prediction","c30d462c":"<a id='3.1'><\/a>\n##### [Linear Regression](#100)","f8f3b933":"**Introduction** \n\nIn this workbook, I have attempted to find the best model (out of the 4 models: Linear Regression, K nearest neighbors(KNN), Bayesian Ridge and Random forest) to predict ratings of new shows.\n\nThe features that are selected are genres, title types and run time. I acknowledge that there are shortfall with using only 3 features. Nevertheless, I am still quite satisfied with the outcome of this project with just 2 months into python and ML learning. I do hope to come back to this and explore more in the future. \n\nCommented out codes are used for data cleaning. Only cleaned datasets are uploaded in this workbook. You can download the entire code, uncomment the codes in your local machine and run the original datasets straight from IMDB. ","397d1f62":"Gridsearch for Genre analysis **did not** improve the score. ","a546b63f":"<a id='4.1'><\/a>\n##### [Linear Regression](#100)","964bcaf5":"<a id='8'><\/a>\n## [Optimization ](#100)","4cf9e974":"##### Genre (Random Forest) ","699e26a0":"<a id='5.4'><\/a>\n##### [Random Forest ](#100)","c47843df":"<a id='6'><\/a>\n# [Overview of models](#100)  ","5bfc9c8e":"<a id='5.2'><\/a>\n##### [KNN ](#100)","944eff70":"<a id='5.3'><\/a>\n##### [Bayesian Ridge](#100)","89c59b0d":"<a id='4.2'><\/a>\n##### [KNN](#100)","f8ecfa9b":"##### Finding the best show combination","8fb371aa":"<a id='5'><\/a>\n### [Analysing Runtime and ratings ](#100)","401d90a7":"<a id='4.4'><\/a>\n##### [Random Forest ](#100)","26aacde8":"### Creating one hot encoding for title type ","1e27194f":"<a id='10'><\/a>\n## [Interesting findings](#100) ","53c27d30":"<a id='9'><\/a>\n## [Predictions](#100) ","401768d9":"From the chart, we can see that most of the shows are in the less than 200 mins range. Shows that are more than 200 mins generally have a rating of more than 5. ","e6505484":"**Table of contents** \n\n<a id='100'><\/a>\n1. [Loading data](#1) \n2. [Data cleaning](#2)\n3. [Analysing genres and ratings](#3)\n    - Model 1: [Linear Regression](#3.1)\n    - Model 2: [K nearest neighbors](#3.2)\n    - Model 3: [Baysian Ridge](#3.3)\n    - Model 4: [Random Forest](#3.4) \n    - [Optimal Genre VS Rating model](#3.5)<br>\n<br>\n4. [Analysing title type and ratings](#4)\n    - Model 1: [Linear Regression](#4.1)\n    - Model 2: [K nearest neighbors](#4.2)\n    - Model 3: [Baysian Ridge](#4.3)\n    - Model 4: [Random Forest](#4.4) \n    - [Optimal Title Type VS Rating model](#4.5)<br>\n<br>\n5. [Analysing Runtime type and ratings](#5)\n    - Model 1: [Linear Regression](#5.1)\n    - Model 2: [K nearest neighbors](#5.2) \n    - Model 3: [Baysian Ridge](#5.3)\n    - Model 4: [Random Forest](#5.4)\n    - [Optimal Runtime VS Rating model](#5.5)<br>\n<br>\n6. [Overview of models](#6)\n6. [Overall Prediction](#7)\n7. [Optimization](#8) \n8. [Predictions](#9) \n9. [Interesting findings](#10) \n10. [Future opportunities](#11) "}}