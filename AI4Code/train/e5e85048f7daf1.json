{"cell_type":{"56ac1973":"code","0f690703":"code","7a69a521":"code","c733be27":"code","09af8020":"code","403febad":"code","8adac1b2":"code","94641f62":"code","81aa0db0":"code","b5f68404":"code","16febb4e":"code","20f254c7":"code","c9695f01":"code","1e1fde82":"code","88ad8f70":"code","3166f910":"code","1e0c18c2":"code","70c4a921":"code","a453c8d9":"code","7069e255":"code","ee170181":"code","dfea789b":"code","01c8ee0e":"code","2047450f":"code","a6524bc6":"code","87b3fc40":"code","ff8e7e88":"code","7ad55214":"code","acc9bb20":"code","c9d3ebe5":"code","fe658c05":"code","3a807ef3":"code","e2ed10e2":"code","0abd61dd":"code","f5b761ec":"code","81bae49e":"code","6bff9205":"code","d9627555":"code","9de888ba":"code","7a930deb":"code","0ecf46e3":"code","526f1f00":"code","cad7165d":"code","783e32d0":"code","16b66734":"code","c339f3e4":"code","1362d6cf":"code","dade09a2":"code","8c6e011b":"code","53381bb7":"code","9f10af24":"code","c3925f2c":"code","0ae3dad8":"markdown","9db02d3c":"markdown","28e76fc1":"markdown","753765a7":"markdown","8827499f":"markdown","001de5b0":"markdown","9d9cefe3":"markdown","3fd8fb6c":"markdown","4b391c28":"markdown","8d6b011f":"markdown","a43a122e":"markdown","3a51b286":"markdown","66cd7989":"markdown","e08897a7":"markdown","3b81068d":"markdown","743da088":"markdown","815227fe":"markdown","b87062b8":"markdown","b569b9df":"markdown","2488d9f3":"markdown","ccc7c72d":"markdown","cb6f497b":"markdown","9a375fc0":"markdown","b96a8a81":"markdown","65d2ea07":"markdown","2e5b91e6":"markdown","179d45c8":"markdown","1fef28ab":"markdown","ada37408":"markdown","ff15ecda":"markdown","42efa95d":"markdown","e82bbf7c":"markdown","bfbab156":"markdown","e6e792bd":"markdown","c08bd663":"markdown","e5d3cce9":"markdown","dbd60ac6":"markdown","b17bade5":"markdown","1092d01b":"markdown","129a9205":"markdown","c072554c":"markdown"},"source":{"56ac1973":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport os\nprint(os.listdir(\"..\/input\"))","0f690703":"class My_Perceptron:\n    \n    def __init__(self, learning_rate, epoch):\n        \"\"\"\n        A\u011f i\u00e7in kullan\u0131lacak parametreler\n        \"\"\"\n        self.learning_rate=None\n        self.epoch=None\n        self.w=None\n        self.bias=None\n        self.errors=None\n        \n        \"\"\"\n        A\u011f parametrelerinin de\u011fer atamas\u0131 yap\u0131l\u0131yor\n        \"\"\"\n        self.set_net_parameters(learning_rate, epoch)\n        \n        \n        \"\"\"\n        S\u0131n\u0131f de\u011ferleri e\u011fitim a\u015famas\u0131nda belirlenecektir\n        \"\"\"\n        self.class1 = None\n        self.class2 = None\n        self.thres  = None\n        \n    \n    def set_net_parameters(self, learning_rate, epoch):\n        self.learning_rate = learning_rate\n        self.epoch         = epoch\n        self.errors        = []\n    \n    def _set_class_values(self, y):\n        classes = np.unique(y)\n        if len(classes) != 2:\n            raise ValueError(\"Number of class should be 2\")\n        else:\n            self.class1 = classes[1]\n            self.class2 = classes[0]\n            self.thres  = sum(classes)\/len(classes)\n            \n            \n    def fit(self, X_train, y_train):\n        \n        self._set_class_values(y_train)\n        #\u00d6zellik vekt\u00f6r\u00fcn\u00fcn uzunlu\u011fu al\u0131n\u0131yor\n        feature_size=X_train.shape[1]\n        \n        self.w = np.random.rand(feature_size)\n        self.bias=np.random.rand()\n        for  i in range(self.epoch):\n            error = 0\n            \n            for xi, yi in zip(X_train, y_train):\n                \"\"\"\n                G\u00fcncelleme katsay\u0131s\u0131 \u00f6\u011frenme oran\u0131na ve yap\u0131lan\n                tahmine g\u00f6re belirleniyor\n                \"\"\"\n                update     = self.learning_rate*(yi-self.predict(xi))\n                self.w = self.w + update*xi\n                self.bias  = self.bias + update\n                \n                error = error + self._get_error(update)\n            \n            self.errors.append(error)\n    \n    def predict(self, X):\n        pred=np.where(self.net_input(X) >= self.thres, self.class1, self.class2)\n        \n        return pred\n    \n    def net_input(self, X):\n        net = np.dot(X, self.w)\n        net = net+self.bias\n        \n        return net\n    \n    def _get_error(self, update):\n        if update == 0.0:\n            return 0\n        return 1","7a69a521":"def performance_metrics(y_true, y_pred,\n            accuracy=True, confusion_matrix=True, classification_report=True):\n    if accuracy:\n        print(\"Ba\u015far\u0131 oran\u0131(%):\",metrics.accuracy_score(y_true, y_pred)*100,end=\"\\n\\n\")\n    if confusion_matrix:\n        print(\"Kar\u0131\u015f\u0131kl\u0131k Matrisi:\\n\",\n              metrics.confusion_matrix(y_true, y_pred),end=\"\\n\\n\")\n   \n    if classification_report:\n        print(\"S\u0131n\u0131fland\u0131rma Raporu:\\n\",\n              metrics.classification_report(y_true, y_pred))","c733be27":"iris_3c=pd.read_csv(\"..\/input\/iris\/Iris.csv\")\nsns.countplot(iris_3c['Species'])","09af8020":"iris_2c=iris_3c[iris_3c['Species']!='Iris-virginica'].copy()\nsns.countplot(iris_2c['Species'])","403febad":"iris_2c.loc[iris_2c['Species']=='Iris-setosa','Species']=-1\niris_2c.loc[iris_2c['Species']=='Iris-versicolor','Species']=1\n\nX=iris_2c.drop(['Id', \"Species\"], axis=1)\ny=iris_2c['Species']\n\nX_train, X_test, y_train, y_test=train_test_split(X.values, \n                                                  y.values, \n                                                  stratify=y, \n                                                  test_size=0.4,\n                                                 random_state=42) \nperceptron=My_Perceptron(learning_rate=0.1, epoch=50)\n\nperceptron.fit(X_train, y_train)\ny_pred=perceptron.predict(X_test)\n\nprint(\"\u0130ki S\u0131n\u0131fl\u0131 Iris Veri Seti \u0130\u00e7in {} \\\nS\u0131n\u0131fland\u0131rma Performans\u0131\\n\".format(perceptron.__class__.__name__))\nperformance_metrics(y_true=y_test, y_pred=y_pred)","8adac1b2":"X_table = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny_and=np.array([0, 0, 0, 1])\ny_or=np.array([0, 1, 1, 1])\ny_xor=np.array([0, 1, 1, 0])\n\nlogic_gate={\"and\":(X_table, y_and),\n           \"or\":(X_table, y_or ),\n           \"xor\":(X_table, y_xor)}","94641f62":"for key, item in logic_gate.items():\n    \n    X_table, y_output= item\n    perceptron=My_Perceptron(learning_rate=0.1, epoch=50)\n    \n    perceptron.fit(X_table, y_output)\n    y_pred=perceptron.predict(X_table)\n\n    print(\"{} \u0130\u00e7in Perceptron S\u0131n\u0131fland\u0131rma Performans\u0131\".format(key.upper()))\n    performance_metrics(y_true=y_output, y_pred=y_pred, \n                        confusion_matrix=False,\n                       classification_report=False)\n","81aa0db0":"class My_ADALINE:\n    \n    def __init__(self, learning_rate, epochs):\n        \"\"\"\n        A\u011f i\u00e7in kullan\u0131lacak parametreler\n        \"\"\"\n        self.learning_rate = None\n        self.epochs = None\n        \n        \"\"\"\n        A\u011f parametrelerinin de\u011fer atamas\u0131 yap\u0131l\u0131yor\n        \"\"\"\n        self._set_net_parameters(learning_rate, epochs)\n        \n        \n        \"\"\"\n        S\u0131n\u0131f etiketleri e\u011fitim a\u015famas\u0131nda belirlenecektir\n        \"\"\"\n        self.class1 = None\n        self.class2 = None\n        self.thres  = None\n        \n        \"\"\"\n        A\u011f de\u011fi\u015fkenleri e\u011fitim a\u015famas\u0131nda belirlenecektir\n        \"\"\"\n        self.w = None\n        self.bias = None\n        self.costs = None\n        \n    def _set_net_parameters(self, learning_rate, epochs):\n        self.learning_rate = learning_rate\n        self.epochs         = epochs\n        \n    \n    def _set_class_values(self, y):\n        classes = np.unique(y)\n        if len(classes) != 2:\n            raise ValueError(\"Number of class should be 2\")\n        else:\n            self.class1 = classes[1]\n            self.class2 = classes[0]\n            self.thres  = sum(classes)\/len(classes)\n\n    \n    def fit(self, X_train, y_train):\n        \n        self._set_class_values(y_train)\n\n        number_of_sample, number_of_feature = X_train.shape[:2]\n        \n        self.w = np.random.rand(number_of_feature)\n        self.bias = np.random.rand()\n        self.costs = []\n        \n        for i in range(self.epochs):\n            net_output = self.net(X_train)\n            errors = y_train-net_output\n            \n            self.w = self.w + self.learning_rate*X_train.T.dot(errors)\n            self.bias = self.bias + self.learning_rate*errors.sum()\n            \n            cost=(errors**2).sum()\/2.0\n            self.costs.append(cost)\n        return self\n    \n    \n    def net(self, X):\n        out = np.dot(X, self.w)\n        out = out + self.bias\n        return out\n    \n    def activation(self, X):\n        return self.net(X)\n    \n    def predict(self, X):\n        return np.where(self.activation(X)>=self.thres, self.class1, self.class2)\n            ","b5f68404":"adaline=My_ADALINE(learning_rate=0.01, epochs=50)\n\nadaline.fit(X_train, y_train)\n\ny_pred=adaline.predict(X_test)\n\nprint(\"\u0130ki S\u0131n\u0131fl\u0131 Iris Veri Seti \u0130\u00e7in \\\n{}  S\u0131n\u0131fland\u0131rma Performans\u0131\\n\".format(adaline.__class__.__name__))\nperformance_metrics(y_true=y_test, y_pred=y_pred,\n                   confusion_matrix=False,\n                   classification_report=False)","16febb4e":"X_scaled=StandardScaler().fit_transform(X)\nprint(\"\u00d6l\u00e7eklendirme ger\u00e7ekle\u015ftirildi...\")","20f254c7":"X_train, X_test, y_train, y_test=train_test_split(X_scaled, \n                                                  y.values, \n                                                  stratify=y, \n                                                  test_size=0.4,\n                                                 random_state=42) ","c9695f01":"adaline=My_ADALINE(learning_rate=0.01, epochs=50)\n\nadaline.fit(X_train, y_train)\n\ny_pred=adaline.predict(X_test)\n\nprint(\"\u0130ki S\u0131n\u0131fl\u0131 Iris Veri Seti \u0130\u00e7in \\\n{} S\u0131n\u0131fland\u0131rma Performans\u0131\\n\".format(adaline.__class__.__name__))\nperformance_metrics(y_true=y_test, y_pred=y_pred)","1e1fde82":"for key, item in logic_gate.items():\n    \n    X_table, y_output= item\n    adaline=My_ADALINE(learning_rate=0.1, epochs=50)\n    \n    adaline.fit(X_table, y_output)\n    y_pred=adaline.predict(X_table)\n\n    print(\"{} \u0130\u00e7in  {} \\\n    S\u0131n\u0131fland\u0131rma Performans\u0131\".format(key.upper(), adaline.__class__.__name__))\n    performance_metrics(y_true=y_output, y_pred=y_pred, \n                        confusion_matrix=False,\n                       classification_report=False)","88ad8f70":"pima=pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\npima.head()","3166f910":"pima.info()","1e0c18c2":"X=pima.drop('Outcome',axis=1).astype(float)\nX=StandardScaler().fit_transform(X)\n\ny=pima['Outcome']","70c4a921":"X_train, X_test, y_train, y_test=train_test_split(X, \n                                                  y, \n                                                  stratify=y, \n                                                  test_size=0.2,\n                                                 random_state=42) ","a453c8d9":"from keras.models import Sequential\nfrom keras.layers import Dense","7069e255":"model=Sequential()\nmodel.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\nmodel.add(Dense(8, kernel_initializer='uniform', activation='relu'))\nmodel.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\nprint(\"A\u011f olu\u015fturuldu...\")","ee170181":"model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\nprint(\"A\u011f derlendi...\")","dfea789b":"model.fit(X_train, y_train,\n          epochs=150, \n          batch_size=10, \n          verbose=0)\nprint(\"A\u011f e\u011fitildi...\")","01c8ee0e":"scores=model.evaluate(X_test,y_test)\nprint(\"A\u011f ba\u015far\u0131 oran:%{:.2f}\".format(scores[1]*100))","2047450f":"from sklearn.model_selection import StratifiedKFold\n\nnumber_of_sample=len(X)\nkfold=StratifiedKFold(n_splits=5, shuffle=True, random_state=24)\ncv_scores=list()\ncounter=1\nfor train, test in kfold.split(X, y):\n    model=Sequential()\n    model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\n    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    print(\"CV{}:A\u011f olu\u015fturuldu...\".format(counter))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    print(\"CV{}:A\u011f derlendi...\".format(counter))\n    model.fit(X[train], y[train],\n              epochs=150, \n              batch_size=10, \n              verbose=0)\n    print(\"CV{}:Model e\u011fitildi..\".format(counter))\n    scores=model.evaluate(X[train],y[train])\n    print(\"CV{}:A\u011f ba\u015far\u0131 oran:%{:.2f}\".format(counter, scores[1]*100))\n    cv_scores.append(scores[1]*100)\n    counter+=1\n    print()","a6524bc6":"print(\"Ortalam ba\u015far\u0131 oran\u0131:%{:.2f} (+\/- {:.2f})\".format(\n    np.mean(cv_scores),\n    np.std(cv_scores))) ","87b3fc40":"from keras.utils.vis_utils import plot_model\n\nplot_model(model, to_file='pima_model_plot.png', \n           show_shapes=True, show_layer_names=True)","ff8e7e88":"pima_model_plot=plt.imread(\"..\/working\/pima_model_plot.png\")\nplt.figure(figsize=(12,10))\nplt.xticks([])\nplt.yticks([])\nplt.imshow(pima_model_plot)\nplt.show()","7ad55214":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn import model_selection  \nfrom sklearn import metrics","acc9bb20":"def create_deep_net_model():\n    model=Sequential()\n    model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\n    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    \n    return model\n    ","c9d3ebe5":"def create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(12, input_dim=8, init= 'uniform' , activation= 'relu' ))\n    model.add(Dense(8, init= 'uniform' , activation= 'relu' ))\n    model.add(Dense(1, init= 'uniform' , activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    return model","fe658c05":"pima=pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\nX=pima.drop('Outcome',axis=1).astype(float)\n#X=StandardScaler().fit_transform(X)\n\ny=pima['Outcome']\nX_train, X_test, y_train, y_test=train_test_split(X, \n                                                  y, \n                                                  stratify=y, \n                                                  test_size=0.3,\n                                                 random_state=42) ","3a807ef3":"model=KerasClassifier(build_fn=create_deep_net_model,nb_epoch=250,batch_size=10,verbose=0)\n\nmodel.fit(X_train, y_train)\ny_pred=model.predict(X_test)\nprint(\"KerasClassifier wrapper e\u011fitildi...\")","e2ed10e2":"print(metrics.accuracy_score(y_test, y_pred))\nprint(metrics.confusion_matrix(y_test, y_pred))","0abd61dd":"house=pd.read_csv(\"..\/input\/housesalesprediction\/kc_house_data.csv\")\nhouse.head()","f5b761ec":"#house_data=house['sqft_living'].copy().reshape(1, -1)\nhouse_data=np.array(house['sqft_living'].astype(np.float64), dtype=pd.Series).reshape(-1,1)\nhouse_target=house['price'].copy()\n#house_data['yr_renovated']=house_data['yr_renovated'].apply(lambda x:1 if x>0 else x)","81bae49e":"from keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# define wider model\ndef wider_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(3, input_dim=1, kernel_initializer= 'normal' , activation= 'relu' ))\n    model.add(Dense(1, kernel_initializer= 'normal' ))\n    # Compile model\n    model.compile(loss= 'mean_squared_error' , optimizer= 'adam' )\n    return model\n# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n# evaluate model with standardized dataset\nestimators = []\nestimators.append(( 'standardize' , StandardScaler()))\nestimators.append(( 'mlp' , KerasRegressor(build_fn=wider_model, nb_epoch=100, batch_size=5,\nverbose=0)))\npipeline = Pipeline(estimators)\nkfold = KFold(n_splits=10, random_state=seed)\nresults = cross_val_score(pipeline, house_data, house_target, cv=kfold)\nprint(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))","6bff9205":"#LeNet i\u00e7in gerekli t\u00fcm k\u00fct\u00fcphaneler ortama dahil ediliyo\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras import backend as K","d9627555":"class LeNet:\n    def __init__(self):\n        print(\"LeNet nesnesi olu\u015fturuldu\")\n    \n    @staticmethod\n    def build(width, height, depth, classes):\n        \"\"\"\n        width  : g\u00f6r\u00fcnt\u00fcn\u00fcn geni\u015fli\u011fi\n        height : g\u00f6r\u00fcnt\u00fcn\u00fcn y\u00fcksekli\u011fi\n        depth  : g\u00f6r\u00fcnt\u00fcn\u00fcn renk kanal\u0131 say\u0131s\u0131\n        classes: s\u0131n\u0131fland\u0131r\u0131lacak etiket say\u0131s\u0131\n        \"\"\"\n        \n        model=Sequential()\n        #shape first s\u0131ras\u0131\n        inputShape=(height, width, depth)\n        \n        if K.image_data_format()==\"channels_first\":\n            inputShape=(depth, height, width)\n        \n        \n        \"\"\"\n        1. Ayar \u0130\u00e7in A\u011f\u0131n olu\u015faca\u011f\u0131 katmanlar:\n        CONV:Conv2D(20, (5,5))\n        ACTIVATION: Relu\n        POOL:MaxPooling2D(pool_size=(2, 2), strides=(2, 2)\n        \"\"\"\n        #CONV katman\u0131 ekleniyor\n        model.add(Conv2D(20, (5,5), padding=\"same\", input_shape=inputShape))\n        \n        #Aktivasyon katman\u0131 ekleniyor\n        model.add(Activation(\"relu\"))\n        \n        #Pool katman\u0131 ekleniyor\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        \n        \"\"\"\n        2. Ayar \u0130\u00e7in A\u011f\u0131n olu\u015faca\u011f\u0131 katmanlar:\n        CONV:Conv2D(50, (5,5))\n        ACTIVATION: Relu\n        POOL:MaxPooling2D(pool_size=(2, 2), strides=(2, 2)\n        \"\"\"\n        #CONV katman\u0131 ekleniyor\n        model.add(Conv2D(50, (5,5), padding=\"same\", input_shape=inputShape))\n        \n        #Aktivasyon katman\u0131 ekleniyor\n        model.add(Activation(\"relu\"))\n        \n        #Pool katman\u0131 ekleniyor\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        \n        \n        model.add(Flatten())\n        model.add(Dense(500))\n        model.add(Activation(\"relu\"))\n        \n        model.add(Dense(classes))\n        model.add(Activation('softmax'))\n        \n        return model\n        ","9de888ba":"print(os.listdir(\"..\/input\"))","7a930deb":"train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(\"Train veri seti y\u00fcklendi\")","0ecf46e3":"print(\"Train veri setindeki \u00f6rnek say\u0131s\u0131:\",train.shape[0])\nprint(\"\u00d6rneklerin \u00f6zellik say\u0131s\u0131        :\",train.shape[1])\ntrain.head()","526f1f00":"train_data=train.drop('label', axis=1).values\ntrain_target=train['label'].values","cad7165d":"del train\nprint(\"train nesnesi silindi\")","783e32d0":"from keras.optimizers import SGD\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","16b66734":"print(K.image_data_format())","c339f3e4":"train_data=train_data.reshape(train_data.shape[0], 28, 28, 1)","1362d6cf":"X_train, X_test, y_train, y_test=train_test_split(train_data\/255.0, \n                                                  train_target,\n                                                 test_size=0.25,\n                                                 random_state=42)\nprint(\"Veri seti e\u011fitim ve test i\u00e7in ayr\u0131\u015ft\u0131r\u0131ld\u0131..\")","dade09a2":"label_binarizer=LabelBinarizer()\ny_train=label_binarizer.fit_transform(y_train)\ny_test=label_binarizer.transform(y_test)\nprint(\"Etiketlerin OneHot kodlama d\u00f6n\u00fc\u015f\u00fcmleri yap\u0131ld\u0131...\")","8c6e011b":"opt=SGD(lr=0.01)\nmodel=LeNet.build(width=28, height=28, depth=1, classes=10 )\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\nprint(\"Model derlendirildi...\")","53381bb7":"H=model.fit(X_train, y_train, \n            validation_data=(X_test, y_test),\n           batch_size=128, \n           epochs=20,\n           verbose=1)\nprint(\"model e\u011fitildi...\")","9f10af24":"y_pred=model.predict(X_test,batch_size=128)\nprint(\"Tahmin yap\u0131ld\u0131...\")","c3925f2c":"print(classification_report(y_test.argmax(axis=1),\n                           y_pred.argmax(axis=1),\n                           target_names=[str(x) for x in label_binarizer.classes_]))","0ae3dad8":"<center><h1>DER\u0130N \u00d6\u011eRENMEN\u0130N TEMELLER\u0130<\/h1><\/center>\n# <a class=\"anchor\" id=0.>\u0130\u00e7indekiler<\/a>\n\n* [0.1. Gerekli K\u00fct\u00fcphaneler Geli\u015ftirme Ortam\u0131na Dahil Ediliyor](#0.1.)\n\n* [1. Tan\u0131t\u0131m](#1.)\n* [2. Yapay Sinir A\u011flar\u0131 Tarih\u00e7esi](#2.)\n* * [2.1. Kurulu\u015f Devri](#2.1.)\n* * [2.2. Duruklama Devri](#2.2.)\n* * [2.3. Geli\u015fme Devri](#2.3.)\n* * [2.4. Y\u00fckseli\u015f Devri(Derin \u00d6\u011frenme)](#2.4.)\n* [3. Perceptron](#3.)\n* * [3.1.  Perceptron Y\u00f6nteminin S\u0131f\u0131rdan Kodlanmas\u0131](#3.1.)\n* * [3.2.  My_Perceptron S\u0131n\u0131f\u0131](#3.2.)\n* * [3.3. Yard\u0131mc\u0131 Fonksiyon: performance_metrics](#3.3.)\n* * [3.4. Iris Veri Seti \u00dczerinden My_Perceptron Test Edilmesi](#3.4.)\n* * [3.5. AND, OR, XOR Mant\u0131ksal Tablolar\u0131 \u00dczerinde My_Perceptron Test Edilmesi](#3.5.)\n* [4. ADALINE:  **ADA**ptive **LIN**ear **E**lements](#4.)\n* * [4.1.  ADALINE Y\u00f6nteminin S\u0131f\u0131rdan Kodlanmas\u0131](#4.1.)\n* * [4.2. My_ADALINE S\u0131n\u0131f](#4.2.)\n* * [4.3.  Iris Veri Seti \u00dczerinde ADALINE Y\u00f6nteminin Test Edilmesi](#4.3.)\n* * [4.4. \u00d6l\u00e7eklendirmenin \u00d6nemi](#4.4.)\n* * [4.5. AND, OR, XOR Mant\u0131ksal Tablolar\u0131 \u00dczerinde My_ADALINE Test Edilmesi](#4.5.)\n* [6. Keras \u0130le Derin A\u011flar Olu\u015fturma](#6.)\n* * [6.1. Derin A\u011flar Olu\u015fturma: S\u0131n\u0131fland\u0131rma](#6.1.)\n* * [6.2. Derin A\u011f Performans\u0131n\u0131n \u00d6l\u00e7\u00fclmesi](#6.2.)\n* * [6.3.A\u011f Yap\u0131s\u0131n\u0131n G\u00f6rselle\u015ftirilmesi](#6.3.)\n* * [6.4. Keras Modelinin sklearn Modeli Gibi Kullan\u0131lmas\u0131: KerasClassifier](#6.4.)\n* [ Evri\u015fimsel Sinir A\u011flar\u0131(Convolutional Neural Networks)](#.)\n* [ LeNet](#5.)\n* * [ LeNet s\u0131n\u0131f\u0131](#5.1.)\n* * [ Veri Setlerinin Y\u00fcklenmesi](#5.2.)\n* * [Veri Setlerinin Keras Modeline Uygun Hale Getirilmesi](#5.3.)\n* * [Derin A\u011flar\u0131n E\u011fitilmesi](#5.4.)\n* * [S\u0131n\u0131fland\u0131rma Sonu\u00e7lar\u0131](#5.5.)\n* [ Modelin Kaydedilmesi](#.)\n","9db02d3c":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=6.4.> <\/a> 6.4. Derin A\u011flar\u0131n Olu\u015fturulmas\u0131: Regresyon","28e76fc1":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=6.4.> <\/a> 6.4. Keras Modelinin sklearn Modeli Gibi Kullan\u0131lmas\u0131: KerasClassifier\n\nKeras k\u00fct\u00fcphanesi derin \u00f6\u011frenme modellerinin olu\u015fturulmas\u0131 i\u00e7in geli\u015ftirilmi\u015f bir k\u00fct\u00fcphane oldu\u011fu i\u00e7in genel makine \u00f6\u011frenmesi modellerinin ihtiya\u00e7 duydu\u011fu baz\u0131 fonksiyonlara sahip de\u011fildir. sklearn, python ile geli\u015ftirilen makine \u00f6\u011fremesi uygulamalar\u0131 i\u00e7in gerekli olan; model se\u00e7imi, \u00f6l\u00e7\u00fcm, parametre optimizasyonu, i\u015f ak\u0131\u015f\u0131n\u0131n otomatikle\u015ftirilmesi ve serile\u015ftirme gibi bir\u00e7ok fonksiyona sahiptir. \n\nKeras k\u00fct\u00fcphanesinden yer alan KerasClassifier  ve KerasRegressor wrapper s\u0131n\u0131flar\u0131yla, olu\u015fturulan derin \u00f6\u011frenme modelleri sklearn modeli gibi kullan\u0131labiliyor. ","753765a7":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=6.><\/a> 6. Keras \u0130le Derin A\u011flar Olu\u015fturma\n\nKeras, arka planda Tensorflow veya Theon k\u00fct\u00fcphanleri kullanarak derin a\u011flar olu\u015ftumay\u0131 kolayla\u015ft\u0131ran derin \u00f6\u011frenme yaz\u0131l\u0131m \u00e7at\u0131s\u0131d\u0131r(framework). Keras ile yapay sinir a\u011flar\u0131n tan\u0131mlanmas\u0131 ve e\u011fitilmesi birka\u00e7 kod sat\u0131rla ger\u00e7ekle\u015ftirilebilir.\n\nPima-Indian veri seti kullan\u0131lacakt\u0131r. Veri seti 768 kad\u0131n hastaya ait 8 \u00f6zellikten ve bir hedef de\u011fi\u015fkenden olu\u015fmaktad\u0131r. Hedef de\u011fi\u015fken ki\u015finin te\u015fhis durumunu 0 ve 1 ile g\u00f6stermektedir. 0 ki\u015finin diabet hastas\u0131 olmad\u0131\u011f\u0131n\u0131, 1 ki\u015finin diabet hastas\u0131 oldu\u011funu belirtmektedir. \n\n* Pregnancies: Ki\u015finin ka\u00e7 kez hamile oldu\u011fu\n* Glucose: Kandanki \u015feker miktar\u0131\n* BloodPressure: Kan bas\u0131nc\u0131\n* SkinThickness: Cilt kal\u0131nl\u0131\u011f\u0131\n* Insulin: Kandaki insulin miktar\u0131\n* BMI: V\u00fccut kitle indeksi\n* DiabetesPedigreeFunction: Diabet soyagac\u0131 fonksiyonu\n* Age: Ya\u015f\n* Outcome: Te\u015fhis","8827499f":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=2.3.><\/a> 2.3. Geli\u015fme Devri\n\nUzun bir aradan sonra, YSA'n\u0131n lineer olmayan s\u0131n\u0131flar \u00fczerinde \u00e7al\u0131\u015fabilece\u011fini g\u00f6steren geri yay\u0131l\u0131ml\u0131(backprobagation) y\u00f6ntemi, YSA \u00e7al\u0131\u015fmalar\u0131n\u0131n tekrar h\u0131z kazanmas\u0131n\u0131 sa\u011flam\u0131\u015ft\u0131r. Geri yay\u0131l\u0131ml\u0131 YSA e\u011fitim y\u00f6ntemi ileri yay\u0131l\u0131ml\u0131(feedforward) y\u00f6ntemlerin geli\u015fmesine imkan vermi\u015ftir. \n\nYSA art\u0131k XOR gibi lineer olarak ay\u0131r\u015ft\u0131rlamayan s\u0131n\u0131flar \u00fczerinde ba\u015far\u0131l\u0131 sonu\u00e7lar vermeye ba\u015flam\u0131\u015ft\u0131r. Daha sonraki \u00e7al\u0131\u015fmalar YSA'n\u0131n makine \u00f6\u011frenmesi modeli i\u00e7in evrensel bir yakla\u015f\u0131m oldu\u011fu fikrinin yerle\u015fmesini sa\u011flam\u0131\u015ft\u0131r. Yani, g\u00f6zetimli \u00f6\u011frenme alt\u0131nda yer alan regresyon ve s\u0131n\u0131fland\u0131rma problemleri ve g\u00f6zetimsi \u00f6\u011frenme alt\u0131nda yer alan k\u00fcmeleme ve boyut azaltma promlemleri YSA modeline uygun hale getirilerek \u00e7\u00f6z\u00fclebilece\u011fi fikri benimsenmi\u015ftir.\n\nGeri yay\u0131ml\u0131 \u00f6\u011frenme y\u00f6ntemi YSA \u00e7al\u0131\u015fmalar\u0131nda bir d\u00f6n\u00fcm noktas\u0131 olmas\u0131na kar\u015f\u0131n hesaplama donan\u0131mlar\u0131n\u0131ndaki yetersizlik YSA'n\u0131n geni\u015f \u00e7apl\u0131 kullan\u0131lmas\u0131na engel oluyordu ve 2000'li y\u0131llardaki Destek Vekt\u00f6r Makineleri(Support Vector Machines) y\u00f6nteminin ba\u015far\u0131s\u0131 YSA'y\u0131 geri plana brakm\u0131\u015ft\u0131.","001de5b0":"# <a class=\"anchor\" id=4.2.><\/a> 4.2.  My_ADALINE S\u0131n\u0131f","9d9cefe3":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=.>4. Evri\u015fimsel Sinir A\u011flar\u0131(Convolutional Neural Network(CNN))<\/a>\n\n...","3fd8fb6c":"Yukadaki sonu\u00e7lar ADALINE modelinin, Perceptron gibi, XOR do\u011fruluk tablosu s\u0131n\u0131fland\u0131rmas\u0131nda ba\u015far\u0131s\u0131z olmu\u015ftur. Bu sonu\u00e7 ADALINE modelinin lineer s\u0131n\u0131fland\u0131r\u0131c\u0131 oldu\u011funu g\u00f6stermektedir. ","4b391c28":"Kanal s\u0131ras\u0131 channels_lat oldu\u011fu i\u00e7in verinin \u015fekil bi\u00e7imi: \u00f6rneksay\u0131s\u0131Xsat\u0131rXs\u00fctunXderinlik olacakt\u0131r","8d6b011f":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=3.5.> <\/a> 3.5. AND, OR, XOR Mant\u0131ksal Tablolar\u0131 \u00dczerinde My_Perceptron Test Edilmesi\n\nSonu\u00e7lar Perceptron algoritmas\u0131n\u0131n kusursuz oldu\u011funu g\u00f6steriyor! Ger\u00e7ekten \u00f6yle mi? Bu sorunun yan\u0131t\u0131n\u0131 bulmaya \u00e7al\u0131\u015fal\u0131m.\n\nPerceptron algoritmas\u0131 linear bir s\u0131n\u0131fland\u0131r\u0131c\u0131d\u0131r. Lineer olarak ayr\u0131labilen veri setleri \u00fczerinde iyi sonu\u00e7lar verir. Lineer olarak ay\u0131rlabilmek nedir? E\u011fer iki s\u0131n\u0131f\u0131 ay\u0131rmak i\u00e7in bir do\u011fru par\u00e7as\u0131 yetiyorsa bu s\u0131n\u0131flar lineer olarak ayr\u0131\u015ft\u0131r\u0131labilir olarak kabul edilir.\n\nLineer s\u0131n\u0131fland\u0131r\u0131c\u0131lar tek bir do\u011fruyla ayr\u0131lamayan veri setleri \u00fczerinde iyi sonu\u00e7lar vermezler. Bunu g\u00f6stermek i\u00e7in en \u00e7ok kullan\u0131lan veri; OR, AND ve XOR do\u011fruluk tablolar\u0131d\u0131r. OR ve AND do\u011fruluk tablolar\u0131ndaki 0 ve 1 s\u0131n\u0131flar\u0131 lineer olarak ayr\u0131labilirken, XOR do\u011fruluk tablosundaki s\u0131n\u0131flar lineer olarak ayr\u0131lamazlar.","a43a122e":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=6.2.><\/a> 6.2. Derin A\u011f Performans\u0131n\u0131n \u00d6l\u00e7\u00fclmesi\n\nKeras ile olu\u015fturulan derin a\u011f modellerinin performans \u00f6l\u00e7\u00fcleri sklearn k\u00fct\u00fcphanesinde yer alan makine \u00f6\u011frenmesi modellerinden biraz farkl\u0131d\u0131r. Derin a\u011f modellerinin performas\u0131n\u0131 \u00f6l\u00e7mek i\u00e7in kullan\u0131labilecek yakla\u015f\u0131mlar:\n\n* Klasik yakla\u015f\u0131mla veri setinin e\u011fitim ve test i\u00e7in ayr\u0131\u015ft\u0131r\u0131lmas\u0131yla performans \u00f6l\u00e7\u00fcm\u00fc\n* Kfold \u00e7a\u011fraz do\u011frulamayla performans \u00f6l\u00e7\u00fcm\u00fc","3a51b286":"Veri setinde eksik bilgiye sahip \u00f6zellik olmad\u0131\u011f\u0131 ve t\u00fcm \u00f6zellikler say\u0131sal de\u011fer i\u00e7erdi\u011fi i\u00e7in \u00f6n i\u015fleme i\u00e7in \u00f6l\u00e7eklendirme yapmak yeterli olacakt\u0131r.","66cd7989":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=5.1.>5.1. LeNet s\u0131n\u0131f\u0131<\/a>\n\n...","e08897a7":"**Not: \u00c7al\u0131\u015fma hen\u00fcz tamamlanmam\u0131\u015ft\u0131r. Ancak yorum ve oylamaya a\u00e7\u0131kt\u0131r. Tamamlanan k\u0131sm\u0131n faydal\u0131 olaca\u011f\u0131n\u0131 d\u00fc\u015f\u00fcnd\u00fc\u011f\u00fcm i\u00e7in yay\u0131mlamaya karar verdim. Yorumlarda yap\u0131lacak isteklere g\u00f6re yeni konular ekleyebilir veya var olan konular\u0131 yeniden d\u00fczenleyebilirim. Yorumlar\u0131n\u0131z merakla bekliyorum. \u00c7al\u0131\u015fmay\u0131 be\u011fenirseniz oylamay\u0131 unutmay\u0131n!**","3b81068d":"<a class=\"anchor\" id=0.1.>0.1. Gerekli K\u00fct\u00fcphaneler Geli\u015ftirme Ortam\u0131na Dahil Ediliyor<\/a>\n\n\u00c7al\u0131\u015fmada t\u00fcm b\u00f6l\u00fcmlerde kullan\u0131lacak k\u00fct\u00fcphanler geli\u015ftirme ortam\u0131na dahil ediliyor. B\u00f6l\u00fcmler  i\u00e7erisinde gerekli k\u00fct\u00fcphanler ihtiya\u00e7 olduk\u00e7a dahil edilecektir. ","743da088":"Yukar\u0131daki sonu\u00e7 beklentilerimizi kar\u015f\u0131lam\u0131yor. Perceptron ile %100 ba\u015far\u0131 oran\u0131 elde etmi\u015fken daha geli\u015fmi\u015f bir y\u00f6ntem olan ADALINE ile %50 ba\u015far\u0131 oran\u0131 elde edilmi\u015ftir. \u0130ki s\u0131n\u0131fl\u0131 veri setleri i\u00e7in %50 ba\u015far\u0131 oran\u0131, modelin hi\u00e7 \u00f6\u011frenmedi\u011fini g\u00f6sterir. Bu ba\u015far\u0131s\u0131zl\u0131\u011f\u0131n nedeni verilern \u00f6l\u00e7eklendirilmemesinden kaynaklanmaktad\u0131r. ","815227fe":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=5.3.>5.3. Veri Setlerinin Keras Modeline Uygun Hale Getirilmesi<\/a>\n\n...","b87062b8":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=1.><\/a> 1. Tan\u0131t\u0131m\n\nBu '\u00c7ekirdek' \u00e7al\u0131\u015fmas\u0131n amac\u0131 derin \u00f6\u011frenme i\u00e7in gerekli teorik ve pratik yetkinliklerini kazand\u0131rmakt\u0131r. \u00c7al\u0131\u015fma kapsam\u0131nda teorik bilgiler \u00e7ok fazla matematiksel notasyonlar kullan\u0131lmadan anlat\u0131lacak ve makine \u00f6\u011frenmesi projelerinde kullan\u0131lacak derin \u00f6\u011frenme teknikleri pratiklerle uygulanacakt\u0131r.\n\n**Derin \u00d6\u011frenme \u0130\u00e7in Do\u011fru Ba\u015flang\u0131\u00e7 Nedir?**\n\nDo\u011fru bir \u00f6\u011frenme plan\u0131yla ba\u015flamak elde edilecek verim a\u00e7\u0131s\u0131ndan \u00e7ok \u00f6nemlidir. Derin \u00f6\u011frenmeye ba\u015flamay\u0131 d\u00fc\u015f\u00fcnenlerin ak\u0131llar\u0131na en \u00e7ok gelen sorular: Derin \u00f6\u011frenme benim i\u00e7in uygun mu? Uygunsa, nas\u0131l bir yol izlemeliyim?\n\n**Derin \u00f6\u011frenme benim i\u00e7in uygun mu?**\n\n**Bu soru i\u00e7in verilen yanl\u0131\u015f cevaplar \u015funlard\u0131r:** Derin \u00f6\u011frenmeye ba\u015flaman i\u00e7in lineer cebir , olas\u0131l\u0131k, istatistik konular\u0131nda ileri derecede yetkinliklere sahip olman gerekir... Temel yapay sinir a\u011flar\u0131 y\u00f6ntemlerini bilmeden derin \u00f6\u011frenmeyi anlayamazs\u0131n... Makine \u00f6\u011frenmesi y\u00f6ntemlerini bilmiyorsan derin \u00f6\u011frenmeye hi\u00e7 ba\u015flama... \u00c7ok iyi derecede proglama bilmiyorsan derin \u00f6\u011frenme sana g\u00f6re de\u011fil...\n\nYukar\u0131daki cevaplara g\u00f6re hareket edilecek olursa, derin \u00f6\u011frenmeye ba\u015flamak i\u00e7in birka\u00e7 y\u0131la ihtiya\u00e7 var demektir. Cevaplarda belirtilen yetkinlikler yeni ba\u015flayan i\u00e7in avantaj sa\u011flasada, ba\u015flamak i\u00e7in olmazsa olmaz de\u011fildir. Derin \u00f6\u011frenmeye ba\u015flamak i\u00e7in temel seviyede matematik ve programlama bilgisi yeterlidir. \n\n**Nas\u0131l bir yol izlemeliyim?**\n\nDerin \u00f6\u011frenme i\u00e7in do\u011fru yol; \u00f6ncelikle basit derin \u00f6\u011frenme modelleri olu\u015fturmak ve bunlar\u0131 pratiklerle uygulamakt\u0131r. E\u011fer be\u011fenirseniz ve daha fazla vakit ay\u0131rma \u015fans\u0131n\u0131z varsa daha zor modeller olu\u015fturmaya ve teorik alt yap\u0131y\u0131 \u00f6\u011frenmeye devam edebilirsiniz. \n\n**Bu '\u00c7ekirdek' \u00e7al\u0131\u015fmas\u0131n\u0131 takip edebilmek i\u00e7in nelere ihtiya\u00e7 var?**\n\nMatris ve vekt\u00f6r i\u015flemlerini bilmek ve bunlar\u0131n python ile nas\u0131l ger\u00e7ekle\u015ftirilece\u011fini bilmek matematik ve programlama a\u00e7\u0131s\u0131ndan yeterli olacakt\u0131r. Ayr\u0131ca basit seviyede Nesne Y\u00f6nelimli Programlama bilmek \u00e7al\u0131\u015fmada yap\u0131lan kodlamalar\u0131 daha kolay anlaman\u0131za yard\u0131mc\u0131 olacakt\u0131r. \n* Lineer Cebir \u0130\u00e7in \"[Makine \u00d6\u011frenmesi \u0130\u00e7in Lineer Cebir](https:\/\/www.kaggle.com\/serkanpeldek\/makine-renmesi-%C4%B0-in-lineer-cebir)\" \u00e7al\u0131\u015fmas\u0131ndan faydalanabilirsiniz.\n* Nesne Y\u00f6nelimli Programlama \u0130\u00e7in \"[Object Oriented Titanics](https:\/\/www.kaggle.com\/serkanpeldek\/object-oriented-titanics)\" \u00e7al\u0131\u015fmas\u0131ndan faydalanabilirsiniz. ","b569b9df":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=4.1.><\/a> 4.1.  ADALINE Y\u00f6nteminin S\u0131f\u0131rdan Kodlanmas\u0131\n\nADALINE y\u00f6nteminin \u00e7al\u0131\u015fma mant\u0131\u011f\u0131 Perceptron y\u00f6ntemine \u00e7ok benzemektedir. ADALINE s\u0131n\u0131f\u0131na ait fit() fonksiyonu Perceptron fit() fonksiyonundan biraz fakl\u0131d\u0131r. ADALINE fit() fonksiyonunda a\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fcn g\u00fcncellenmesi veri setindeki t\u00fcm \u00f6rnekelerin tahminine g\u00f6re belirnenir. Bu a\u00e7\u0131dan e\u011fitim a\u015famas\u0131 daha h\u0131zl\u0131 ger\u00e7ekle\u015ftirilmektedir.  ","2488d9f3":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=2.><\/a> 2. Yapay Sinir A\u011flar\u0131\n\nYapay Sinir A\u011flar\u0131(YSA) insan beyninin \u00e7al\u0131\u015fmas\u0131n\u0131 modellemek i\u00e7in yap\u0131lan \u00e7al\u0131\u015fmalar\u0131n sonucunda ortaya \u00e7\u0131km\u0131\u015f bir \u00f6\u011frenme modelidir. **Derin \u00f6\u011frenme** 1940'lardan bug\u00fcn\u00fc \u00fczerinde \u00e7al\u0131\u015fma yap\u0131lan YSA'n\u0131n geli\u015fmi\u015f \u00e7oklu katmanl\u0131 mimarilerine verilen adland\u0131rmad\u0131r. Asl\u0131nda derin \u00f6\u011frenme YSA'd\u0131r. \n\nYSA'n\u0131n tarih\u00e7esi ayn\u0131 zaman da derin \u00f6\u011frenmenin de tarih\u00e7esidir. \u00dczerinde uzun y\u0131llar \u00e7al\u0131\u015fma yap\u0131lan ve \u015fuan yapay zeka \u00e7al\u0131\u015fmalar\u0131n\u0131 domine eden YSA **imparatorlu\u011funun** tarihi, ironik olarak d\u00f6rt devre ayr\u0131labilir; **Kurulu\u015f, Duruklama, Geli\u015fme ve Y\u00fckseli\u015f(Derin \u00d6\u011frenme)**","ccc7c72d":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=5.2.>5.2. Veri Setlerinin Y\u00fcklenmesi<\/a>\n\n...","cb6f497b":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=2.2.><\/a> 2.2. Duraklama Devri\n\nYSA ilk \u00f6nerildi\u011fi y\u0131ldan 1960'lar\u0131n sonu kadar ara\u015ft\u0131rmac\u0131lar\u0131n yo\u011fun ilgisini \u00e7ekmi\u015ftir. 1969 y\u0131l\u0131nda Minsky ve Papert taraf\u0131nda yay\u0131mlanan makale YSA \u00e7al\u0131\u015fmalar\u0131n\u0131 10 y\u0131l duraklatm\u0131\u015ft\u0131r. Bu a\u00e7\u0131dan \u00e7al\u0131\u015fma \u00f6denem i\u00e7in YSA'n\u0131n laneti olarak adland\u0131r\u0131lm\u0131\u015ft\u0131r. \n\nMinsky ve Papert yazd\u0131klar\u0131 makalede Perceptron y\u00f6nteminin sadece lineer olarak ayr\u0131labilen s\u0131n\u0131flarda kullan\u0131labilece\u011fini, lineer olarak ayr\u0131lamayan s\u0131n\u0131flarda kullan\u0131lamayaca\u011f\u0131n\u0131 g\u00f6stermi\u015flerdir. \u0130leriki konularda da de\u011finece\u011fimiz gibi Perceptron y\u00f6ntemi lineer ayr\u0131labilen s\u0131n\u0131flar\u0131n \u00fczerinde iyi sonu\u00e7 verirken lineer olarak ayr\u0131lamayan s\u0131n\u0131flar \u00fczerinde k\u00f6t\u00fc sonu\u00e7lar vermi\u015ftir. Ayr\u0131ca makalede \u015fimdi \u00e7ok basit olarak g\u00f6r\u00fclen Perceptron y\u00f6nteminin e\u011fitilmesi i\u00e7in yeterli donan\u0131ma sahip olunmad\u0131\u011f\u0131n\u0131 belirtmi\u015flerdir. \n\nMinsky ve Papert makalesinin etkisiyle, 1980'lere kadar YSA y\u00f6ntemlerinde \u00f6nemli geli\u015fmeler ya\u015fanmam\u0131\u015ft\u0131r. ","9a375fc0":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=6.1.><\/a> 6.1. Derin A\u011flar Olu\u015fturma","b96a8a81":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=3.4.> <\/a> 3.4. Iris Veri Seti \u00dczerinden My_Perceptron Test Edilmesi\n\nIris veri setinde \u00fc\u00e7 tane hedef s\u0131n\u0131f vard\u0131r;setosa, versicolor ve virginica. Perceptron algoritmas\u0131 iki s\u0131n\u0131f s\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131 oldu\u011fu i\u00e7in iris veri setindeki sadece iki s\u0131n\u0131f kullan\u0131lacakt\u0131r.\n\n**Uyar\u0131:** Perceptron, SVM, Logistic Regression vb. bir \u00e7ok makine \u00f6\u011frenmesi modeli iki s\u0131n\u0131f s\u0131n\u0131fland\u0131r\u0131c\u0131lard\u0131r. \u0130kili s\u0131n\u0131f s\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131 \u00e7oklu s\u0131n\u0131f s\u0131n\u0131fland\u0131r\u0131c\u0131s\u0131 olarak kullanmak i\u00e7in One vs Rest, One vs One gibi y\u00f6ntemler kullan\u0131l\u0131r. Sklearn k\u00fct\u00fcphanesinden yer alan Perceptron algoritmas\u0131 \u00e7oklu s\u0131n\u0131flar\u0131n s\u0131n\u0131fland\u0131rmada kullan\u0131lmas\u0131 bahsi ge\u00e7en y\u00f6ntemlerle ger\u00e7ekle\u015ftirilir.\n","65d2ea07":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=4.5.><\/a> 4.5. AND, OR, XOR Mant\u0131ksal Tablolar\u0131 \u00dczerinde My_ADALINE Test Edilmesi \n\n\u00d6l\u00e7eklendirme i\u015fleminden sonra ADALINE Iris veri seti \u00fczerinde iyi sonu\u00e7 vermi\u015ftir. Ancak Perceptron modelini gibi ADALINE modeli de lineer olarak ayr\u0131\u015ft\u0131r\u0131labilen s\u0131n\u0131flar \u00fczerinde iyi sonu\u00e7lar verir. ADALINE modelinin lineer olarak ayr\u0131\u015ft\u0131rlamayan veriler \u00fczerinde ba\u015far\u0131s\u0131z oldu\u011funu g\u00f6rmek i\u00e7in AND, OR ve XOR do\u011fruluk tablolar\u0131n\u0131n s\u0131n\u0131fland\u0131rmas\u0131n\u0131 g\u00f6zlemleyerek anlayabiliriz. ","2e5b91e6":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=2.4.><\/a> 2.3. Y\u00fckseli\u015f Devri(Derin \u00d6\u011frenme)\n\n2007'lerde YSA'\u00e7al\u0131\u015fmalar\u0131nda \u00f6nemli bir ilerleme oldu. Bu y\u0131ldan sonra YSA \u00e7al\u0131\u015fmalar\u0131 Derin \u00d6\u011frenme olarak adland\u0131r\u0131lmaya ba\u015flad\u0131. Derin \u00f6\u011frenme algoritmalar\u0131n\u0131n geli\u015fiminde \u00f6nemli d\u00f6rt etken vard\u0131r; \n\n* Derin \u00f6\u011frenme modellerinin e\u011fitilmesi i\u00e7in kullan\u0131lacak verilerin artmas\u0131\n* E\u011fitimin ger\u00e7ekle\u015ftirilmesi i\u00e7in kullan\u0131lacak donan\u0131mlar\u0131n geli\u015fmesi\n* E\u011fitimde kullan\u0131lacak optimizasyon y\u00f6ntemlerinin geli\u015fmesi\n* Paralel hesaplamaya imkan veren GPU teknolojisiyle uyum","179d45c8":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=2.1.><\/a> 2.1. Kurulu\u015f Devri\n\nMcCullock ve Pitts yapay sinir a\u011flar\u0131 \u00fczerine yapt\u0131klar\u0131 ilk \u00e7al\u0131\u015fmada sinir(neuron) kavram\u0131n\u0131 tan\u0131tm\u0131\u015flard\u0131r(McCullock ve Pitts, 1943).\n\nSnirler beyinde, kimyasal ve elektriksel sinyallerin i\u015flenmesi ve iletilmesinde yer alan birbiriyle ba\u011flant\u0131l\u0131 sinir h\u00fccreleridir. McCullock ve Pitts, b\u00f6yle bir sinir h\u00fccresini, ikili \u00e7\u0131kt\u0131larla basit bir mant\u0131k kap\u0131s\u0131 olarak tan\u0131mlad\u0131lar: Birden fazla sinyal dendritlere ula\u015f\u0131r, daha sonra h\u00fccre g\u00f6vdesine entegre edilir ve e\u011fer birikmi\u015f sinyal belirli bir e\u015fi\u011fi a\u015farsa, akson taraf\u0131ndan ge\u00e7irilecek bir \u00e7\u0131k\u0131\u015f sinyali \u00fcretilir(Raschka, 2015).\n\nMcCullock ve Pitts'in \u00f6nerdikleri sinir kavram\u0131n\u0131 temel alan Rosenblatt, perceptron \u00f6\u011frenme kurallar\u0131n\u0131 geli\u015ftirmi\u015ftir(Rosenblatt, 1957). Perceptron kural\u0131 ile Rosenblatt, bir n\u00f6ronun ate\u015f al\u0131p almad\u0131\u011f\u0131na karar vermek i\u00e7in girdi \u00f6zellikleriyle \u00e7arp\u0131lan optimal a\u011f\u0131rl\u0131k katsay\u0131lar\u0131n\u0131 otomatik olarak \u00f6\u011frenecek bir algoritma \u00f6nermi\u015ftir. Denetimli \u00f6\u011frenme ve s\u0131n\u0131fland\u0131rma ba\u011flam\u0131nda, b\u00f6yle bir algoritma, bir \u00f6rne\u011fin bir s\u0131n\u0131fa m\u0131 yoksa di\u011ferine mi ait oldu\u011funu tahmin etmek i\u00e7in kullan\u0131labilir(Raschka, 2015).\n\nBu s\u00fcre zarf\u0131nda sinir a\u011flar\u0131 geli\u015fmeleri h\u0131zla ilerledi ve 1959'da Stanford'da Bernard Widrow ve Marcian Hoff, ger\u00e7ek bir d\u00fcnya sorununa ba\u015far\u0131yla uygulanan ilk sinir a\u011f\u0131n\u0131 geli\u015ftirdi. Bu sistemler, telefon hatlar\u0131ndaki g\u00fcr\u00fclt\u00fcy\u00fc ortadan kald\u0131rmak i\u00e7in \u00f6zel olarak tasarlanm\u0131\u015f ve bug\u00fcn hala kullan\u0131lmakta olan **ADA**ptive **LIN**ear **E**lements ve **M**ultiple **ADA**ptive **LIN**ear **E**lements'\u0131 kullan\u0131ld\u0131. Bu y\u00f6ntemler k\u0131saca ADALINE ve MADALINE olarak adland\u0131r\u0131ld\u0131.\n\nPerceptron e\u011fitimi i\u00e7in geli\u015ftirilen prosed\u00fcrler g\u00fcn\u00fcm\u00fczde **derin a\u011flar\u0131** e\u011fitiminde de kullan\u0131lan Olas\u0131l\u0131ksal Dereceli Azalma (Stochastic Gradient Descent (SGD) y\u00f6nteminin temellerini olu\u015fturmaktad\u0131r. ","1fef28ab":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=5.4.>5.4. Derin A\u011flar\u0131n E\u011fitilmesi<\/a>\n\n...","ada37408":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=6.3.> <\/a> 6.3.A\u011f Yap\u0131s\u0131n\u0131n G\u00f6rselle\u015ftirilmesi\n\nKeras, olu\u015fturulan a\u011flar\u0131n g\u00f6rselle\u015ftirilmesine olanak sunan k\u00fct\u00fcphanelere sahip. Bu k\u00fct\u00fcphaneleri kullanarak olu\u015fturulan a\u011flar\u0131n yap\u0131s\u0131n\u0131 daha kolay kavranabilir. \n","ff15ecda":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=3.3.><\/a> 3.3. Yard\u0131mc\u0131 Fonksiyon: performance_metrics","42efa95d":"Yukar\u0131daki sonu\u00e7larda g\u00f6r\u00fcld\u00fc\u011f\u00fc \u00fczere, Perceptron y\u00f6ntemi OR ve AND verilerini s\u0131n\u0131fland\u0131rmada ba\u015far\u0131l\u0131 olurken XOR verilerinin ayr\u0131\u015ft\u0131r\u0131lmas\u0131nda ba\u015far\u0131s\u0131z olmu\u015ftur. ","e82bbf7c":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=6.>6. Modelin Kaydedilmesi<\/a>\n\n...","bfbab156":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=5.>5. LeNet<\/a>\n\n...","e6e792bd":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=3.1.><\/a> 3.1.  Perceptron Y\u00f6nteminin S\u0131f\u0131rdan Kodlanmas\u0131\n\n\u0130lk \u00f6nerilen YSA \u00f6\u011frenme y\u00f6ntemi olana Perceptron'un kodlanmas\u0131n\u0131 python s\u0131n\u0131f\u0131 kullan\u0131larak ger\u00e7ekle\u015ftirilecektir. Programlamada s\u0131n\u0131flar kullan\u0131larak yaz\u0131lan kodlar Nesne Y\u00f6nelimli Programlama(OOP) olarak adland\u0131r\u0131l\u0131r. OOP yakla\u015f\u0131m\u0131 \u00e7ok detayl\u0131 ve geni\u015f bir konudur. Bu \u00e7ekirdek \u00e7al\u0131\u015fmas\u0131nda yazaca\u011f\u0131m\u0131z kodlar basit seviyede OOP bilgisiyle anla\u015f\u0131labilecek yap\u0131da olacakt\u0131r.\n\n\nPerceptron class kodlamas\u0131 sklearn k\u00fct\u00fcphanesinde yer alan s\u0131n\u0131fland\u0131r\u0131c\u0131lar gibi **fit** ve **predict** fonksiyonlar\u0131na sahip olacakt\u0131r. **fit** fonksiyonu modeli e\u011fitim veri seti \u00fczerinde e\u011fitmek i\u00e7in, **predict** fonksiyonu e\u011fitilen modelde test veri seti \u00fczerinde tahmin yapmak i\u00e7in kullan\u0131lacakt\u0131r.\n\n**net_input()** fonksiyonu \u00f6zellik verk\u00f6t\u00fcyle a\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fcn nokta \u00e7arp\u0131m\u0131n\u0131 hesaplamaktad\u0131r. **get_error()** fonkisyonu tahminin hatal\u0131 olup olmad\u0131\u011f\u0131n\u0131 kontrol etmektedir. ","c08bd663":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=4.><\/a> 4.  ADALINE:  **ADA**ptive **LIN**ear **E**lements\n\n**ADALINE** y\u00f6ntemi Widrow ve Hoff taraf\u0131ndan Perceptron y\u00f6nteminden birka\u00e7 y\u0131l sonra  \u00f6nerildi. ADALINE algoritmas\u0131; lojistik regresyon ve destek vekt\u00f6r makineleri  s\u0131n\u0131fland\u0131r\u0131c\u0131lar\u0131 ve  regresyon modelleri  gibi daha geli\u015fmi\u015f makine \u00f6\u011frenme algoritmalar\u0131n\u0131 anlamak i\u00e7in temel te\u015fkil eden maliyet fonksiyonlar\u0131n\u0131 tan\u0131mlama ve en aza indirme anahtar kavram\u0131n\u0131 g\u00f6stermesi a\u00e7\u0131s\u0131ndan \u00e7ok \u00f6nemli bir yere sahiptir.  \n\nADALINE  ve Perceptron modellerinin temel farkl\u0131 e\u011fitim a\u015famas\u0131nda s\u0131n\u0131flar\u0131 birbirinden ay\u0131ran a\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fcn bulunmas\u0131ndaki yakla\u015f\u0131mlar\u0131d\u0131r. Perceptron y\u00f6nteminde a\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fcn g\u00fcncellenmesi herbir \u00f6rne\u011fin s\u0131n\u0131f tahmini yap\u0131ld\u0131ktan sonra ger\u00e7ekle\u015ftirilirdi. ADALINE y\u00f6nteminde ise a\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fcn g\u00fcncellenmesi veri setindeki t\u00fcm \u00f6rneklerin s\u0131n\u0131f tahmini yap\u0131ld\u0131ktan sonra ger\u00e7ekle\u015ftirilir. ","e5d3cce9":"Veri setinde toplamda 150, her bir s\u0131n\u0131fa ait 50 \u00f6rnek yer almaktadir.  Iris-virginica s\u0131n\u0131f\u0131  veri setinden \u00e7\u0131kart\u0131lacakt\u0131r. ","dbd60ac6":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n<a class=\"anchor\" id=5.5.>5.5. S\u0131n\u0131fland\u0131rma Sonu\u00e7lar\u0131<\/a>\n\n...","b17bade5":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=4.4.><\/a> 4.4.  \u00d6l\u00e7eklendirmenin \u00d6nemi\n\nADALINE modeli iki s\u0131n\u0131fl\u0131 Iris veri setinde %50 ba\u015far\u0131 oran\u0131 vermi\u015ftir. Bu sonu\u00e7 modelin hi\u00e7 \u00f6\u011frenmedi\u011fini g\u00f6stermektedir. \u00c7\u00fcnk\u00fc e\u015fit da\u011f\u0131l\u0131ma sahip iki s\u0131n\u0131fl\u0131 veri setleri i\u00e7in ba\u015far\u0131 oran\u0131 alt s\u0131n\u0131r\u0131 %50'dir. Tahminlerin hepsini s\u0131n\u0131flardan biri olarak belirlemek %50 ba\u015far\u0131 oran\u0131n\u0131 elde etmeye yetecektir.\n\nPeki, Perceptron modelineden daha iyi olan ADALINE neden ba\u015far\u0131s\u0131z oldu? Bunun nedeni; ADALINE modelinin a\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fcn elde edilmesinde kullan\u0131n optimizasyon tekni olan Gradien Desent y\u00f6nteminin \u00f6l\u00e7eklendirmi\u015f verileri \u00fczerinde iyi sonu\u00e7 vermesinden kaynaklanmaktad\u0131r. \n\nVerileri \u00f6l\u00e7ekledirip ADALINE modelini tekrar kullanal\u0131m","1092d01b":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=3.2.><\/a> 3.2.  My_Perceptron S\u0131n\u0131f\u0131","129a9205":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=3.><\/a> 3. Perceptron\n\nMcCullock ve Pitts'in siniri ve Rosenblatt'\u0131n perceptron modelinin ard\u0131ndaki t\u00fcm fikir, beyindeki tek bir n\u00f6ronun nas\u0131l \u00e7al\u0131\u015ft\u0131\u011f\u0131n\u0131 taklit etmek i\u00e7in indirgemeci bir yakla\u015f\u0131m kullanmakt\u0131r: ya ate\u015f eder ya da etmez.\n\nX ve y s\u0131ras\u0131yla veri matrisi ve \u00e7\u0131kt\u0131 vekt\u00f6r\u00fc olsun. Veri matrisi ve \u00e7\u0131kt\u0131 vek\u00f6t\u00fcr\u00fcn\u00fcn bir k\u0131sm\u0131 e\u011fitim, di\u011fer k\u0131sm\u0131 test i\u00e7in kullan\u0131lacakt\u0131r. E\u011fitim ve test k\u00fcmeleri \u015f\u00f6yle ayr\u0131ls\u0131n X_train, X_test, y_train, y_test.\n\nRosenblatt'\u0131n ba\u015flang\u0131\u00e7 perceptron kural\u0131na g\u00f6re perceptron modelinin e\u011fitimi a\u015fa\u011f\u0131daki ad\u0131mlarla \u00f6zetlenebilir:\n\n* A\u011f\u0131rl\u0131k vekt\u00f6r\u00fc W rasgele de\u011ferler ile doldurulur\n* \u00d6\u011frenme oran\u0131n\u0131 belirlenir\n* X_train e\u011fitim k\u00fcmesindeki her bir e\u011fitim \u00f6rne\u011fi xi i\u00e7in a\u015fa\u011f\u0131daki ad\u0131mlar ger\u00e7ekle\u015ftirilir:\n* * \u00c7\u0131kt\u0131 y_pred vekt\u00f6r\u00fcn\u00fc hesapla\n* * A\u011f\u0131rl\u0131k vekt\u00f6r\u00fcn\u00fc y_pred ve y_test vekt\u00f6rlerini dikkate alarak g\u00fcncelle\n\nE\u011fitim a\u015famas\u0131 tamamland\u0131ktan sonra elde edilen a\u011f\u0131rl\u0131k vekt\u00f6r\u00fc test veri k\u00fcmesinin s\u0131n\u0131fland\u0131r\u0131lmas\u0131nda kullan\u0131l\u0131r. S\u0131n\u0131fland\u0131rma i\u015flemi X_test veri setindeki herbir \u00f6rnek i\u00e7in a\u015fa\u011f\u0131da yer alan fonksiyondaki gibi tan\u0131mlana bilir:\n\nf(xi_test)=\n\n* e\u011fer xi_test.W>0 ise ait oldu\u011fu s\u0131n\u0131f 1'dir\n* de\u011fil ise ait oldu\u011fu s\u0131n\u0131f 0'd\u0131r.","c072554c":"[\u0130\u00e7indekiler Men\u00fcs\u00fcne Git](#0.)\n\n# <a class=\"anchor\" id=4.3.><\/a> 4.3.  Iris Veri Seti \u00dczerinde ADALINE Y\u00f6nteminin Test Edilmesi"}}