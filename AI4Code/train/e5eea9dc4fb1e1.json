{"cell_type":{"58775d69":"code","78f7b0e7":"code","9debfe01":"code","97506a8f":"code","8ce68d53":"code","0f9b0267":"code","d7eaa232":"code","2ee66407":"code","4eec18bc":"code","3f781116":"code","e525813a":"code","e4632447":"code","571976fd":"code","abb8242c":"code","19e36fec":"code","a2f0059d":"code","da17f72d":"code","08cb1325":"code","cd16a325":"code","35e8b217":"code","d820343f":"code","798a1513":"code","5b2c69b2":"code","430389bf":"code","f37de747":"code","70491b11":"code","c2cb37bb":"markdown","24c9b8da":"markdown","b8b5ebe4":"markdown","4b306731":"markdown","7114d6ba":"markdown","ec05c85f":"markdown","281d95c5":"markdown","ff0a7d7d":"markdown","649bf097":"markdown","fcbe2f32":"markdown","d7cf78a3":"markdown","7d731758":"markdown","96506185":"markdown","09d23193":"markdown","79e5a6e7":"markdown","d950cbc8":"markdown","3d680b96":"markdown","31024e8c":"markdown","dc587f98":"markdown","aab1de33":"markdown","c2741e1c":"markdown","4d45d82a":"markdown","e28a0c2e":"markdown","97b4f453":"markdown","f12a942b":"markdown"},"source":{"58775d69":"import matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model, load_model\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping\nfrom scipy.io import loadmat\nimport json\nimport numpy as np\nimport time","78f7b0e7":"def plot_loss(history):\n    plt.plot(history['loss'])\n    plt.plot(history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\ndef plot_image(image):\n    plt.imshow(image.reshape((28, 28)))    \n    return\n\ndef plot_images_sample(images):\n    plt.figure(figsize=(8, 5))\n    plt.subplots_adjust(wspace=0, hspace=0)\n    random_indices = random.sample(range(len(images)), 40)\n    for i in range(40):\n        plt.gray()\n        subplot = plt.subplot(5, 8, i + 1)\n        subplot.get_xaxis().set_visible(False)\n        subplot.get_yaxis().set_visible(False)\n\n        plot_image(images[random_indices[i]])\n\ndef plot_comparison(input_images, output_images):\n    plt.figure(figsize=(18, 4))\n    plt.subplots_adjust(wspace=0, hspace=0)\n    random_indices = random.sample(range(len(input_images)), 12)\n    for i in range(12):\n        plt.gray()\n        subplot = plt.subplot(2, 12, i + 1)\n        subplot.get_xaxis().set_visible(False)\n        subplot.get_yaxis().set_visible(False)\n        plot_image(input_images[random_indices[i]])\n        subplot = plt.subplot(2, 12, i + 1 + 12)\n        subplot.get_xaxis().set_visible(False)\n        subplot.get_yaxis().set_visible(False)\n        plot_image(output_images[random_indices[i]])\n\ndef save_to_file(var, filename):\n    js = json.dumps(var)\n    f = open(filename, \"w\")\n    f.write(js)\n    f.close()\n\ndef load_from_file(filename):\n    f = open(filename, \"r\")\n    js = f.read()\n    return json.loads(js)","9debfe01":"training_epochs = 100\ntrain_to_test_ratio = 0.85\ninput_size = 28 * 28\nencoded_size = 7 * 7\nactivation = 'elu'\noptimizer = 'adadelta'\nloss = 'binary_crossentropy'\ncallbacks = [EarlyStopping(monitor='val_loss', patience=3)]\nuse_serialized = False","97506a8f":"# load the dataset\nmnist = loadmat(\"..\/input\/mnist-original\/mnist-original\")\n\n# get the image data from the dataset\nimages = mnist[\"data\"].T\n\n# convert image data into float format\nimages = images \/ 255\n\n# split into training and test images\ntrain_count = round(len(images) * train_to_test_ratio)\ntest_count = len(images) - train_count\ntrain_images = images[:train_count]\ntest_images = images[-test_count:]\n\nprint(\"all images:\", images.shape)\nprint(\"train images:\", train_images.shape)\nprint(\"test images:\", test_images.shape)","8ce68d53":"plot_images_sample(train_images)","0f9b0267":"if (use_serialized):\n    vanilla_autoencoder = load_model('vanilla.h5')\n    vanilla_encoder = load_model('vanilla_encoder.h5')\n    vanilla_decoder = load_model('vanilla_decoder.h5')\n\nelse:\n    input_layer = Input(shape=(input_size,))\n    \n    # encoder\n    encoded_layer = Dense(encoded_size, activation=activation)(input_layer)\n\n    # decoder\n    decoded_layer = Dense(input_size, activation='sigmoid')(encoded_layer)\n\n    # autoencoder\n    vanilla_autoencoder = Model(input_layer, decoded_layer)\n    vanilla_autoencoder.name = \"vanilla autoencoder\"\n\n    # separate encoder and decoder models\n    vanilla_encoder = Model(input_layer, encoded_layer)\n    vanilla_encoder.name = \"vanilla encoder\"\n\n    encoded_input_layer = Input(shape=(encoded_size,))\n    vanilla_decoder = Model(encoded_input_layer, vanilla_autoencoder.layers[-1](encoded_input_layer))\n    vanilla_decoder.name = \"vanilla decoder\"\n\n# print model summaries\nvanilla_autoencoder.summary()\nvanilla_encoder.summary()\nvanilla_decoder.summary()","d7eaa232":"if (use_serialized):\n    history = load_from_file('vanilla_history.json')\n    \nelse:\n    vanilla_autoencoder.compile(optimizer=optimizer, loss=loss)\n    start = time.time()\n    history = vanilla_autoencoder.fit(train_images, train_images, \n                            epochs=training_epochs, \n                            batch_size=256, \n                            shuffle=True, \n                            validation_data=(test_images, test_images),\n                            callbacks=callbacks).history\n    print('training time:', time.time() - start)\n    save_to_file(history, 'vanilla_history.json')\n    vanilla_autoencoder.save('vanilla.h5')\n    vanilla_encoder.save('vanilla_encoder.h5')\n    vanilla_decoder.save('vanilla_decoder.h5')    \n\nplot_loss(history)\nprint(\"loss:\", history[\"loss\"][-1])\nprint(\"val_loss:\", history[\"val_loss\"][-1])\n","2ee66407":"# encode images\nencoded_images = vanilla_encoder.predict(test_images)\nprint(\"encoded images:\", encoded_images.shape)\n\n#decode images\ndecoded_images = vanilla_decoder.predict(encoded_images)\nprint(\"decoded images:\", decoded_images.shape)","4eec18bc":"plot_comparison(test_images, decoded_images)","3f781116":"if (use_serialized):\n    multilayer_autoencoder = load_model('multilayer.h5')\n    multilayer_encoder = load_model('multilayer_encoder.h5')\n    multilayer_decoder = load_model('multilayer_decoder.h5')\n\nelse:\n    input_layer = Input(shape=(input_size,))\n\n    # encoder\n    hidden_encoder_layer = Dense(round((input_size + encoded_size) \/ 4), activation=activation)(input_layer)\n    encoded_layer = Dense(encoded_size, activation=activation)(hidden_encoder_layer)\n\n    # decoder\n    hidden_decoder_layer = Dense(round((input_size + encoded_size) \/ 4), activation=activation)(encoded_layer)\n    decoded_layer = Dense(input_size, activation='sigmoid')(hidden_decoder_layer)\n\n    # autoencoder\n    multilayer_autoencoder = Model(input_layer, decoded_layer)\n    multilayer_autoencoder.name = \"multilayer autoencoder\"\n\n    # separate encoder and decoder models\n    multilayer_encoder = Model(input_layer, encoded_layer)\n    multilayer_encoder.name = \"multilayer encoder\"\n\n    encoded_input_layer = Input(shape=(encoded_size,))\n    multilayer_decoder = Model(encoded_input_layer, multilayer_autoencoder.layers[-1](multilayer_autoencoder.layers[-2](encoded_input_layer)))\n    multilayer_decoder.name = \"multilayer decoder\"\n\n# print model summaries\nmultilayer_autoencoder.summary()\nmultilayer_decoder.summary()\nmultilayer_encoder.summary()\n","e525813a":"if (use_serialized):\n    history = load_from_file('multilayer_history.json')\n    \nelse:\n    multilayer_autoencoder.compile(optimizer=optimizer, loss=loss)\n    start = time.time()\n    history = multilayer_autoencoder.fit(train_images, train_images, \n                            epochs=training_epochs, \n                            batch_size=256, \n                            shuffle=True, \n                            validation_data=(test_images, test_images),\n                            callbacks=callbacks).history\n    print('training time:', time.time() - start)\n    save_to_file(history, 'multilayer_history.json')\n    multilayer_autoencoder.save('multilayer.h5')\n    multilayer_encoder.save('multilayer_encoder.h5')        \n    multilayer_decoder.save('multilayer_decoder.h5') \n    \nplot_loss(history)   \nprint(\"loss:\", history[\"loss\"][-1])\nprint(\"val_loss:\", history[\"val_loss\"][-1])","e4632447":"# encode images\nencoded_images = multilayer_encoder.predict(test_images)\nprint(\"encoded images:\", encoded_images.shape)\n\n#decode images\ndecoded_images = multilayer_decoder.predict(encoded_images)\nprint(\"decoded images:\", decoded_images.shape)","571976fd":"plot_comparison(test_images, decoded_images)","abb8242c":"if (use_serialized):\n    convolutional_autoencoder = load_model('convolutional.h5')\n    convolutional_encoder = load_model('convolutional_encoder.h5')\n    convolutional_decoder = load_model('convolutional_decoder.h5')\n\nelse:\n    input_layer = Input(shape=(28, 28, 1))\n\n    ## encoder\n    # first convolution (outputs 14x14)\n    layer = Conv2D(16, (3, 3), activation=activation, padding='same')(input_layer)\n    layer = MaxPooling2D((2, 2), padding='same')(layer)\n    \n    # second convolution (outputs 7x7)\n    layer = Conv2D(16, (3, 3), activation=activation, padding='same')(layer)\n    encoded_layer = MaxPooling2D((2, 2), padding='same')(layer)\n    \n    ## decoder\n    # first deconvolution (outputs 14x14)\n    layer = Conv2D(16, (3, 3), activation=activation, padding='same')(encoded_layer)\n    layer = UpSampling2D((2, 2))(layer)\n    \n    # second deconvolution (outputs 28x28)\n    layer = Conv2D(16, (3, 3), activation=activation, padding='same')(layer)\n    layer = UpSampling2D((2, 2))(layer)\n\n    # TODO: why is this layer needed?\n    decoded_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(layer)\n\n    # autoencoder\n    convolutional_autoencoder = Model(input_layer, decoded_layer)\n    convolutional_autoencoder.name = \"convolutional autoencoder\"\n\n    # separate encoder and decoder models\n    convolutional_encoder = Model(input_layer, encoded_layer)\n    convolutional_encoder.name = \"convolutional encoder\"\n\n    encoded_input_layer = Input(shape=(7, 7, 16))\n    convolutional_decoder = Model(encoded_input_layer,\n        convolutional_autoencoder.layers[-1](\n            convolutional_autoencoder.layers[-2](\n                convolutional_autoencoder.layers[-3](\n                    convolutional_autoencoder.layers[-4](\n                        convolutional_autoencoder.layers[-5](\n                            encoded_input_layer))))))\n              \n    convolutional_decoder.name = \"convolutional decoder\"\n\n# print model summaries\nconvolutional_autoencoder.summary()\nconvolutional_encoder.summary()\nconvolutional_decoder.summary()\n","19e36fec":"if (use_serialized):\n    history = load_from_file('convolutional_history.json')\n    \nelse:\n    convolutional_autoencoder.compile(optimizer=optimizer, loss=loss)\n    \n    reshaped_train_images = train_images.reshape((len(train_images), 28, 28, 1))\n    reshaped_test_images = test_images.reshape((len(test_images), 28, 28, 1))\n\n    start = time.time()\n    history = convolutional_autoencoder.fit(reshaped_train_images, reshaped_train_images, \n                            epochs=training_epochs, \n                            batch_size=256, \n                            shuffle=True, \n                            validation_data=(reshaped_test_images, reshaped_test_images),\n                            callbacks=callbacks).history\n    print('training time:', time.time() - start)\n    save_to_file(history, 'convolutional_history.json')\n    convolutional_autoencoder.save('convolutional.h5')\n    convolutional_encoder.save('convolutional_encoder.h5')        \n    convolutional_decoder.save('convolutional_decoder.h5')    \n    \nplot_loss(history)\nprint(\"loss:\", history[\"loss\"][-1])\nprint(\"val_loss:\", history[\"val_loss\"][-1])","a2f0059d":"# encode images\nencoded_images = convolutional_encoder.predict(reshaped_test_images)\nprint(\"encoded images:\", encoded_images.shape)\n\n#decode images\ndecoded_images = convolutional_decoder.predict(encoded_images)\nprint(\"decoded images:\", decoded_images.shape)","da17f72d":"plot_comparison(test_images, decoded_images)","08cb1325":"if (use_serialized):\n    sparse_autoencoder = load_model('sparse.h5')\n    sparse_encoder = load_model('sparse_encoder.h5')\n    sparse_decoder = load_model('sparse_decoder.h5')\n\nelse:\n    input_layer = Input(shape=(input_size,))\n    \n    # encoder\n    encoded_layer = Dense(input_size, activation=activation,\n        activity_regularizer=regularizers.l1(10e-7))(input_layer)\n\n    # decoder\n    decoded_layer = Dense(input_size, activation='sigmoid')(encoded_layer)\n\n    # autoencoder\n    sparse_autoencoder = Model(input_layer, decoded_layer)\n    sparse_autoencoder.name = \"sparse autoencoder\"\n\n    # separate encoder and decoder models\n    sparse_encoder = Model(input_layer, encoded_layer)\n    sparse_encoder.name = \"sparse encoder\"\n\n    encoded_input_layer = Input(shape=(input_size,))\n    sparse_decoder = Model(encoded_input_layer, \n       sparse_autoencoder.layers[-1](encoded_input_layer))\n    sparse_decoder.name = \"sparse decoder\"\n\n# print model summaries\nsparse_autoencoder.summary()\nsparse_encoder.summary()\nsparse_decoder.summary()","cd16a325":"if (use_serialized):\n    history = load_from_file('sparse_history.json')\n    \nelse:\n    sparse_autoencoder.compile(optimizer=optimizer, loss=loss)\n    start = time.time()\n    history = sparse_autoencoder.fit(train_images, train_images, \n                            epochs=training_epochs, \n                            batch_size=256, \n                            shuffle=True, \n                            validation_data=(test_images, test_images),\n                            callbacks=callbacks).history\n    print('training time:', time.time() - start)\n    save_to_file(history, 'sparse_history.json')\n    sparse_autoencoder.save('sparse.h5')\n    sparse_encoder.save('sparse_encoder.h5')\n    sparse_decoder.save('sparse_decoder.h5')    \n\nplot_loss(history)\nprint(\"loss:\", history[\"loss\"][-1])\nprint(\"val_loss:\", history[\"val_loss\"][-1])\n","35e8b217":"# encode images\nencoded_images = sparse_encoder.predict(test_images)\nprint(\"encoded images:\", encoded_images.shape)\n\n#decode images\ndecoded_images = sparse_decoder.predict(encoded_images)\nprint(\"decoded images:\", decoded_images.shape)","d820343f":"plot_comparison(test_images, decoded_images)","798a1513":"noise_factor = 0.4\nnoisy_train_images = np.clip(train_images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_images.shape), 0, 1) \nnoisy_test_images = np.clip(test_images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_images.shape), 0, 1)\n\nplot_images_sample(noisy_train_images)","5b2c69b2":"if (use_serialized):\n    denoising_autoencoder = load_model('denoising.h5')\n    denoising_encoder = load_model('denoising_encoder.h5')\n    denoising_decoder = load_model('denoising_decoder.h5')\n\nelse:\n    input_layer = Input(shape=(28, 28, 1))\n\n    ## encoder\n    # first convolution (outputs 14x14)\n    layer = Conv2D(32, (3, 3), activation=activation, padding='same')(input_layer)\n    layer = MaxPooling2D((2, 2), padding='same')(layer)\n    \n    # second convolution (outputs 7x7)\n    layer = Conv2D(32, (3, 3), activation=activation, padding='same')(layer)\n    encoded_layer = MaxPooling2D((2, 2), padding='same')(layer)\n    \n    ## decoder\n    # first deconvolution (outputs 14x14)\n    layer = Conv2D(32, (3, 3), activation=activation, padding='same')(encoded_layer)\n    layer = UpSampling2D((2, 2))(layer)\n    \n    # second deconvolution (outputs 28x28)\n    layer = Conv2D(32, (3, 3), activation=activation, padding='same')(layer)\n    layer = UpSampling2D((2, 2))(layer)\n\n    decoded_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(layer)\n\n    # autoencoder\n    denoising_autoencoder = Model(input_layer, decoded_layer)\n    denoising_autoencoder.name = \"denoising autoencoder\"\n\n    # separate encoder and decoder models\n    denoising_encoder = Model(input_layer, encoded_layer)\n    denoising_encoder.name = \"denoising encoder\"\n\n    encoded_input_layer = Input(shape=(7, 7, 32))\n    denoising_decoder = Model(encoded_input_layer,\n        denoising_autoencoder.layers[-1](\n            denoising_autoencoder.layers[-2](\n                denoising_autoencoder.layers[-3](\n                    denoising_autoencoder.layers[-4](\n                        denoising_autoencoder.layers[-5](\n                            encoded_input_layer))))))\n              \n    denoising_decoder.name = \"denoising decoder\"\n\n# print model summaries\ndenoising_autoencoder.summary()\ndenoising_encoder.summary()\ndenoising_decoder.summary()","430389bf":"if (use_serialized):\n    history = load_from_file('denoising_history.json')\n    \nelse:\n    denoising_autoencoder.compile(optimizer=optimizer, loss=loss)\n   \n    reshaped_noisy_train_images = noisy_train_images.reshape((len(noisy_train_images), 28, 28, 1))\n    reshaped_train_images = train_images.reshape((len(train_images), 28, 28, 1))\n    reshaped_test_images = test_images.reshape((len(test_images), 28, 28, 1))\n    reshaped_noisy_test_images = noisy_test_images.reshape((len(noisy_test_images), 28, 28, 1))\n    \n    start = time.time()\n    history = denoising_autoencoder.fit(reshaped_noisy_train_images, reshaped_train_images, \n                            epochs=training_epochs, \n                            batch_size=256, \n                            shuffle=True, \n                            validation_data=(reshaped_noisy_test_images, reshaped_test_images)).history\n    print('training time:', time.time() - start)\n    save_to_file(history, 'denoising_history.json')\n    denoising_autoencoder.save('denoising.h5')\n    denoising_encoder.save('denoising_encoder.h5')        \n    denoising_decoder.save('denoising_decoder.h5')    \n    \nplot_loss(history)\nprint(\"loss:\", history[\"loss\"][-1])\nprint(\"val_loss:\", history[\"val_loss\"][-1])","f37de747":"# encode images\nencoded_images = denoising_encoder.predict(reshaped_noisy_test_images)\nprint(\"encoded images:\", encoded_images.shape)\n\n#decode images\ndecoded_images = denoising_decoder.predict(encoded_images)\nprint(\"decoded images:\", decoded_images.shape)","70491b11":"plot_comparison(noisy_test_images, decoded_images)","c2cb37bb":"## Architecture\n\n![](https:\/\/i.imgur.com\/byPzKk5.png)","24c9b8da":"## Training","b8b5ebe4":"# Multilayer Autoencoder","4b306731":"## Testing","7114d6ba":"## Libraries","ec05c85f":"# Convolutional Autoencoder","281d95c5":"## Architecture\n\n![](https:\/\/i.imgur.com\/OrWEyXw.png)","ff0a7d7d":"## Architecture\n\n![](https:\/\/i.imgur.com\/veNO3TC.png)","649bf097":"# Vanilla Autoencoder","fcbe2f32":"## Testing","d7cf78a3":"## Training and Testing Dataset","7d731758":"## Training","96506185":"## Testing","09d23193":"## Training","79e5a6e7":"# Sparse Autoencoder","d950cbc8":"##  Training","3d680b96":"## Architecture\n\n![](https:\/\/i.imgur.com\/2qyAqwO.png)","31024e8c":"## Training","dc587f98":"# Denoising Autoencoder","aab1de33":"# Preparations","c2741e1c":"## Data Preparation","4d45d82a":"## Architecture\n\n![](https:\/\/i.imgur.com\/6x2It1E.png)","e28a0c2e":"## Testing","97b4f453":"## Testing","f12a942b":"## Configuration"}}