{"cell_type":{"dcc3bd01":"code","41fe9237":"code","80a605ed":"code","cd995cd1":"code","892a28aa":"code","c1d1a9dd":"code","f686b5f4":"code","69c38a32":"code","341878ab":"code","8eddd101":"code","38cd1ca2":"code","25ad561f":"code","7f57ddd5":"code","7f244ab5":"code","d3563d9d":"code","02c4b952":"code","2e686f8e":"code","6796a832":"code","34e7892b":"code","74dc7111":"code","92beb945":"code","0cac167b":"code","1c469554":"code","a4cf3d3c":"code","8868d8e3":"code","059066d2":"code","65d09a31":"code","e390c69f":"code","cdb45db4":"code","81ffee5e":"code","233339e7":"code","836bd67d":"code","98b7d931":"code","3a69cb51":"code","d0213043":"code","7fef2c31":"code","26810159":"code","1739e864":"code","3b23ffef":"code","dcec2c5a":"code","1a97cf41":"code","25b6fade":"code","b5b634e2":"code","0a64b5de":"code","89f6e276":"code","b622d4d1":"code","4b9035e7":"code","faa1cf35":"code","eb027479":"code","52f5b1b1":"code","96368050":"code","8013c097":"code","0866cae9":"code","304b23b8":"code","7da93cbc":"code","49819792":"code","f6448b0c":"code","ec1a9067":"code","5f7f9d65":"code","f78a543e":"code","def9b140":"code","8f61ebc2":"code","6134d92d":"code","a4ff1ee3":"code","838c9ed9":"code","0e68053c":"code","f66994bc":"code","e79641de":"code","bcab4ef2":"code","7fed1aea":"code","6e7fde68":"markdown","1629eac9":"markdown","0f6462c9":"markdown","ad183301":"markdown","8b5d3eaa":"markdown","8ccda1d4":"markdown","10d6f201":"markdown","4fef555d":"markdown","2e2c7318":"markdown","41b2e414":"markdown","1a64e818":"markdown","4c6a195f":"markdown","7d013039":"markdown","53791808":"markdown","e3910b03":"markdown","7d78e20a":"markdown","0b11f447":"markdown","6748fdcd":"markdown","45836199":"markdown","94db87db":"markdown","0757779d":"markdown","af9ef6b6":"markdown","b8e0cef9":"markdown","00526223":"markdown","ea694a37":"markdown","83da0c03":"markdown","a67dfc22":"markdown","b7f8c12f":"markdown","c7697e5f":"markdown","5e7d55c3":"markdown","deeac498":"markdown","babe38a6":"markdown","da87daa0":"markdown","fcccf5d4":"markdown","8c9a4870":"markdown","7dbcfb1d":"markdown"},"source":{"dcc3bd01":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41fe9237":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px\n\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix,log_loss,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier,StackingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nnp.random.seed(0)\nsns.set_palette('pastel')","80a605ed":"train = pd.read_csv(r'\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv(r'\/kaggle\/input\/titanic\/test.csv')\ntrain.tail()","cd995cd1":"test.head()","892a28aa":"train.head()","c1d1a9dd":"print(train.shape)\nprint(test.shape)","f686b5f4":"train.info()","69c38a32":"test.info()","341878ab":"train.describe()","8eddd101":"test.describe()","38cd1ca2":"train.dtypes","25ad561f":"train.isnull().sum()","7f57ddd5":"test.isnull().sum()","7f244ab5":"avg_age_train = (train.groupby(\"Sex\")['Age']).mean()\nprint(avg_age_train)\navg_age_test = (test.groupby(\"Sex\")['Age']).mean()\nprint(avg_age_test)","d3563d9d":"for i in range(len(train['Age'])):\n    if train['Age'].isnull()[i] == True and train['Sex'][i] == 'male':\n        train['Age'][i] = np.round(avg_age_train['male'],decimals=1)\n    elif train['Age'].isnull()[i] == True and train['Sex'][i] == 'female':\n        train['Age'][i] = np.round(avg_age_train['female'],decimals=1)\n        \nfor i in range(len(test['Age'])):\n    if test['Age'].isnull()[i] == True and test['Sex'][i] == 'male':\n        test['Age'][i] = np.round(avg_age_test['male'],decimals=1)\n    elif test['Age'].isnull()[i] == True and test['Sex'][i] == 'female':\n        test['Age'][i] = np.round(avg_age_test['female'],decimals=1)","02c4b952":"train = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)","2e686f8e":"print(train.shape)\nprint(test.shape)","6796a832":"train.isnull().sum()","34e7892b":"test.isnull().sum()","74dc7111":"Y = train['Survived']\ntrain = train.drop('Survived',axis=1)\ndata = pd.concat([train,test],axis=0)\ndata.head()","92beb945":"avg_fare = data.groupby(\"Sex\")['Fare'].mean()\navg_fare","0cac167b":"print(\"Index of the null value is: \",test[test['Fare'].isnull()].index.tolist())\nprint(test['Sex'][152])","1c469554":"data['Fare'][152] = avg_fare['male']","a4cf3d3c":"data.isnull().sum()","8868d8e3":"print(\"Number of duplicate rows in the train dataset :\",train.duplicated().sum())\nprint(\"Number of duplicate rows in the test dataset :\",test.duplicated().sum())","059066d2":"Name_title_data = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nprint(Name_title_data)\ndata['Name_title'] = Name_title_data\ndata = data.reset_index(drop=True)\ndata.head()","65d09a31":"age_group_data = [None] * len(data['Age'])\nfor i in range(len(data['Age'])):\n    if data['Age'][i] <= 3:\n        age_group_data[i] = 'Baby'\n    elif data['Age'][i] >3 and data['Age'][i] <= 13:\n        age_group_data[i] = 'Child'\n    elif data['Age'][i] >13 and data['Age'][i] <= 19:\n        age_group_data[i] = 'Teenager'\n    elif data['Age'][i] >19 and data['Age'][i] <= 30:\n        age_group_data[i] = 'Young Adult'\n    elif data['Age'][i] >30 and data['Age'][i] <= 45:\n        age_group_data[i] = 'Middle Aged Adult'\n    elif data['Age'][i] >45 and data['Age'][i] <65:\n        age_group_data[i] = 'Adult'\n    else:\n        age_group_data[i] = 'Old'\n\ndata['age_group'] = age_group_data","e390c69f":"np.unique(data['Name_title'])","cdb45db4":"data['Is_Married'] = 0\ndata['Is_Married'].loc[data['Name_title'] == 'Mrs'] = 1\ndata['FamSize'] = data['SibSp'] + data['Parch'] + 1\ndata['Single'] = data['FamSize'].map(lambda s: 1 if s == 1 else 0)","81ffee5e":"data.head()","233339e7":"np.unique(data['Ticket'])\ntic = data.groupby('Ticket',sort=True,group_keys=True)\ngroups = list(tic.groups)\ntogther = [None] * len(data['Ticket'])\nk=0\nfor i in range(len(groups)):\n    for j in range(len(data['Ticket'])):\n        if data['Ticket'][j] == groups[i]:\n            togther[j] = i\ndata['Togther'] = togther","836bd67d":"data.head()","98b7d931":"np.unique(data['Fare'])","3a69cb51":"rates = [None]*len(data['Fare'])\nfor i in range(len(data['Fare'])):\n    if data['Fare'][i]<=10:\n        rates[i] = 1\n    elif data['Fare'][i] >10 and data['Fare'][i]<=30:\n        rates[i] = 2\n    elif data['Fare'][i] >30 and data['Fare'][i]<=70:\n        rates[i] = 3\n    elif data['Fare'][i] >70 and data['Fare'][i]<=100:\n        rates[i] = 4 \n    else:\n        rates[i] = 5\ndata['Rates'] = rates","d0213043":"data['Cabin_present'] = 1\ndata['Cabin_present'].loc[data['Cabin'].isnull()] = 0","7fef2c31":"data.shape","26810159":"data = data.drop('Cabin',axis=1)\ndata = data.drop('Ticket',axis=1)\ndata = data.drop('Name',axis=1)\ndata = data.drop('PassengerId',axis=1)","1739e864":"data_ohe = pd.get_dummies(data,drop_first=True)\ndata_ohe.head()","3b23ffef":"plt.figure(figsize=(20,20))\nsns.heatmap(train.corr(),annot=True,fmt=\"0.3f\",cmap='GnBu',linewidth=1.2,linecolor='black',square=True)\nplt.show()","dcec2c5a":"plt.figure(figsize=(20,20))\nsns.heatmap(test.corr(),annot=True,fmt=\"0.3f\",cmap='YlOrBr',linewidth=1.2,linecolor='black',square=True)\nplt.show()","1a97cf41":"train['Survived'] = Y","25b6fade":"plt.figure(figsize=(20,12))\n\nplt.subplot(2,2,1)\nsns.countplot('Sex',data=train,palette=['darkblue','red'])\nplt.title(\"Train data Sex Count\")\nplt.grid()\n\nplt.subplot(2,2,2)\nsns.countplot('Sex',data=test,palette=['teal','purple'])\nplt.title(\"Test data Sex Count\")\nplt.grid()\n\nplt.show()","b5b634e2":"plt.figure(figsize=(20,12))\nplt.subplot(2,2,1)\nsns.countplot('Survived',data=train,palette=['black','yellow'],hue='Sex')\nplt.grid()\nplt.title(\"Survival Graph\")\n\nplt.subplot(2,2,2)\nsns.countplot('SibSp',data=train,palette=['green','pink'],hue='Sex')\nplt.grid()\nplt.title(\"No of siblings \/ spouses aboard the Titanic\")\n\nplt.subplot(2,2,3)\nsns.countplot('Parch',data=train,palette=['orange','greenyellow'],hue='Sex')\nplt.grid()\nplt.title(\"No of parents \/ children aboard the Titanic\")\nplt.legend(loc='upper right')\n\nplt.subplot(2,2,4)\nsns.countplot('Pclass',data=train,palette=['brown','magenta'],hue='Sex')\nplt.grid()\nplt.title(\"Passenger Class with sex\")\nplt.legend(loc='upper right')\n\nplt.show()","0a64b5de":"plt.figure(figsize=(20,20))\nsns.countplot(y='Age',data=train)\nplt.grid()\nplt.title(\"Train data Age ranges\")\nplt.show()","89f6e276":"plt.figure(figsize=(20,20))\nsns.countplot(y='Age',data=test)\nplt.grid()\nplt.title(\"Test data Age ranges\")\nplt.show()","b622d4d1":"plt.figure(figsize=(20,12))\n\nplt.subplot(2,2,1)\nsns.countplot('Embarked',data=train,hue='Survived',palette=['red','purple'])\nplt.grid()\nplt.title(\"Embarked plotted\")\n\nplt.subplot(2,2,2)\nsns.countplot('Pclass',data=train,hue='Survived',palette=['teal','darkblue'])\nplt.grid()\nplt.title(\"Types of Passenger Classes\")\n\nplt.subplot(2,2,3)\nsns.countplot('Parch',data=train,palette=['orange','greenyellow'],hue='Survived')\nplt.grid()\nplt.title(\"No of parents \/ children aboard the Titanic\")\nplt.legend(loc='upper right')\n\nplt.subplot(2,2,4)\nsns.countplot('SibSp',data=train,palette=['brown','magenta'],hue='Survived')\nplt.grid()\nplt.title(\"No of siblings \/ spouses aboard the Titanic\")\nplt.legend(loc='upper right')\n\nplt.show()","4b9035e7":"fig = px.pie(train,names='Sex',color='Survived')\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","faa1cf35":"fig = px.pie(train,names='Embarked',color='Survived',color_discrete_sequence=px.colors.sequential.RdBu)\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","eb027479":"fig = px.pie(train,names='Pclass',color='Survived',color_discrete_sequence=px.colors.sequential.GnBu)\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","52f5b1b1":"fig = px.pie(train,names='SibSp',color='Survived',template='seaborn')\nfig.update_traces(rotation=140,pull=0.01,marker=dict(line=dict(color='#000000',width=1.2)))\nfig.show()","96368050":"fig = px.violin(train,x='Sex',y='Age',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Sex',y='Pclass',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Sex',y='SibSp',points='all',box=True)\nfig.show()","8013c097":"fig = px.violin(train,x='Survived',y='Age',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Survived',y='Pclass',points='all',box=True,color='Survived')\nfig.show()\n\nfig = px.violin(train,x='Survived',y='SibSp',points='all',box=True)\nfig.show()","0866cae9":"fig = px.scatter(train,x='Age',y='Fare',color='Survived',size='Age')\nfig.show()\n\nfig = px.scatter(train,x='Age',y='Fare',color='Sex',size='Age')\nfig.show()","304b23b8":"train = train.drop('Survived',axis=1)","7da93cbc":"train_ohe = data_ohe[:train.shape[0]]\ntest_ohe = data_ohe[train.shape[0]:]","49819792":"len(data)","f6448b0c":"X_train,X_test,Y_train,Y_test = train_test_split(train_ohe,Y,test_size=0.2)","ec1a9067":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","5f7f9d65":"def plot_conf_matrix(Y_test,Y_pred):\n    conf = confusion_matrix(Y_test,Y_pred)\n    recall =(((conf.T)\/(conf.sum(axis=1))).T)\n    precision =(conf\/conf.sum(axis=0))\n\n    print(\"Confusion Matrix : \")\n    class_labels = [0,1]\n    plt.figure(figsize=(10,8))\n    sns.heatmap(conf,annot=True,fmt=\".3f\",cmap=\"GnBu\",xticklabels=class_labels,yticklabels=class_labels,linecolor='black',linewidth=1.2)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()\n\n    print(\"Precision Matrix ; \")\n    plt.figure(figsize=(10,8))\n    sns.heatmap(precision,annot=True,fmt=\".3f\",cmap=\"YlOrBr\",xticklabels=class_labels,yticklabels=class_labels,linecolor='black',linewidth=1.2)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()\n\n    print(\"Recall Matrix ; \")\n    plt.figure(figsize=(10,8))\n    sns.heatmap(recall,annot=True,fmt=\".3f\",cmap=\"Blues\",xticklabels=class_labels,yticklabels=class_labels,linecolor='black',linewidth=1.2)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()","f78a543e":"# params = dict(\n#     n_estimators = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     criterion = ['gini','entropy'],\n#     max_depth = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n# )\n# rf = RandomForestClassifier()\n# clf = RandomizedSearchCV(rf,params,random_state=0,verbose=0,n_jobs=-1,n_iter=20,cv=10)\n# rsc = clf.fit(X_train,Y_train)\n# rsc.best_params_","def9b140":"rf = RandomForestClassifier(criterion='gini', \n                             n_estimators=700,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1)\nrf.fit(X_train,Y_train)\npred = rf.predict(X_test)\nacc = accuracy_score(Y_test,pred)*100\nprint(acc)\nplot_conf_matrix(Y_test,pred)","8f61ebc2":"# params = dict(\n#     learning_rate = [0.001,0.01,0.1,1,10,100,1000],\n#     n_estimators = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     criterion = ['friedman_mse','mse','mae'],\n#     max_depth = [2,5,10,15,20,25,30,40,50,70,100,125,150,200,300,400,500,700,1000],\n#     min_samples_leaf = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n# )\n# gbdt = GradientBoostingClassifier()\n# clf = RandomizedSearchCV(gbdt,params,random_state=0,verbose=0,n_jobs=-1,n_iter=20,cv=10)\n# gb = clf.fit(X_train,Y_train)\n# gb.best_params_","6134d92d":"gbdt = GradientBoostingClassifier(n_estimators=700,min_samples_leaf=8,max_depth=1000,criterion='mse',learning_rate=0.01)\ngbdt.fit(X_train,Y_train)\npred = gbdt.predict(X_test)\nacc = accuracy_score(Y_test,pred)*100\nprint(acc)\nplot_conf_matrix(Y_test,pred)","a4ff1ee3":"vc = VotingClassifier(estimators=[('rf', rf), ('gbdt', gbdt)],voting='soft')\nvc = vc.fit(X_train,Y_train)\n\npred = vc.predict(X_test)\nacc = accuracy_score(Y_test,pred)*100\nprint(acc)\nplot_conf_matrix(Y_test,pred)","838c9ed9":"X_train.shape","0e68053c":"test['PassengerId']","f66994bc":"predictions = rf.predict(test_ohe)\npredictions.shape","e79641de":"submit = pd.DataFrame(test['PassengerId'],columns=['PassengerId'])\nsubmit['Survived'] = predictions\nsubmit.tail()","bcab4ef2":"submit.to_csv(\"Submissions.csv\",index=False)\nprint(\"Finished saving the file\")","7fed1aea":"pd.read_csv(\".\/Submissions.csv\")","6e7fde68":"**<p style=\"color:green;\">Violin Plots :**","1629eac9":"**<p style=\"color:purple;\">Hence the missing value in the Fare column in the data is handled<\/p>**","0f6462c9":"# **<h1 style=\"color:skyblue;\">GBDT :**","ad183301":"**<p style=\"color:purple;\">I will handle the remaining missing values in the Cabin column after some feature engineering.<\/p>**","8b5d3eaa":"**<p style=\"color:green;\">Pie Charts :**","8ccda1d4":"5. **<p style=\"color:green;\">A feature which categorizes the fare rates of the person.**","10d6f201":"# **<h1 style=\"color:skyblue;\">Data Visualisation :**","4fef555d":"# **<h1 style=\"color:skyblue;\">Predictions :**","2e2c7318":"**<p style=\"color:green;\">Hetamaps :**","41b2e414":"# **<h1 style=\"color:skyblue;\">Random Forest :**","1a64e818":"6. **<p style=\"color:green;\">A feature which tells us the the cabin value is present or not since the cabin feature has so many null values.**","4c6a195f":"# **<h1 style=\"color:skyblue;\">One-Hot Encoding of features :**","7d013039":"**<p style=\"color:purple;\">Now removing the useless columns.**","53791808":"3. **<p style=\"color:green;\">Creating features that the person is married or not,and the family size with SibSp and parch column**","e3910b03":"**<p style=\"color:purple;\">The missing values in the cabin column will be handled after some feature engineering.<\/p>**","7d78e20a":"**<p style=\"color:purple\">There are no duplicate rows present in the dataset .**","0b11f447":"# **<h1 style=\"color:skyblue;\">Loading the dataset :<\/h1>**","6748fdcd":"**<p style=\"color:green;\">Scatter Plots :**","45836199":"**<p style=\"color:purple;\">Bar graphs and CountPlots :**","94db87db":"# **<h1 style=\"color:skyblue;\">Duplicate Values :**","0757779d":"**<p style=\"color:purple;\">The age feature consists of many missing values.<\/p>**","af9ef6b6":"**<p style=\"color:green;\">Combining the dataset :<\/p>**","b8e0cef9":"1. **<p style=\"color:green;\">Creating a feature with the titles of the name.<\/p>**","00526223":"#  **<h1 style=\"color:skyblue;\">Voting Classifier :**","ea694a37":"# **<h1 style=\"color:skyblue;\">ML Models :**","83da0c03":"# **<h1 style=\"color:skyblue;\">Importing Libraries :<\/h1>**","a67dfc22":"# **<h1 style=\"color:skyblue;\">Feature Engineering :**","b7f8c12f":"**<p style=\"color:purple;\">Therefore the missing age values are handled.<\/p>**","c7697e5f":"# **<h1 style=\"color:skyblue;\">Data Modeling :**","5e7d55c3":"# **<h1 style=\"color:skyblue;\">Null Values :<\/h1>**","deeac498":"2. **<p style=\"color:green;\">Creating the category of the age section.**","babe38a6":"# **<h1 style=\"color:green;\">Variable Notes :<\/h1>**\n<p style=\"color:purple;\">pclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n<\/p>\n<p style=\"color:purple;\">\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n<\/p>  \n<p style=\"color:purple;\">\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n<\/p>\n<p style=\"color:purple;\">\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n<\/p>","da87daa0":"**<p style=\"color:purple;\">I am going to replace the missing value in the Fare column by the average fare of according to the Sex<\/p>**","fcccf5d4":"4. **<p style=\"color:green;\">Creating a feature which tells us that the person is travelling with someone or not according to the similar number on the tickets.**","8c9a4870":"**<p style=\"color:purple;\">To handle the missing values in the age column of the dataset I have calculated the average age of the males and the females in the dataset and replaced the missing values accoring to their sex.<\/p>**","7dbcfb1d":"# **<h1 style=\"color:skyblue;\">Train-Test Split :**"}}