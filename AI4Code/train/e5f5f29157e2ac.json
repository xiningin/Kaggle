{"cell_type":{"bbe6a177":"code","9bc8de54":"code","457d2f2c":"code","fe8dc44c":"code","f6069ecc":"code","cc3448d1":"code","cf45f1ab":"code","e040bb2f":"code","836964b4":"code","64b4a2ed":"code","a6f8680c":"code","f5ad85ab":"code","b88c7487":"code","a2b15647":"code","325788cc":"code","63d1b092":"code","37cf801d":"code","ca4fed45":"code","e72c2b59":"code","81420521":"code","f09ad9b5":"code","744ab4fc":"code","b1f23b40":"code","8e231ee1":"markdown"},"source":{"bbe6a177":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9bc8de54":"df=pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndf.head()","457d2f2c":"def show_nan(df):\n    total=len(df)\n    nan_sum=df.isnull().sum()\n    nan_perc=[i\/total for i in nan_sum]\n    df_nan=pd.DataFrame(data=nan_perc,index=df.columns,columns=[\"Nan values\"])\n    return df_nan\n\ndef show_unique(df,th):\n    total=len(df)\n    unique=[(df[col].unique()) for col in df.columns]\n    unique_perc=[len(col) for col in unique ]\n    \n    df_unique=pd.DataFrame(data=unique_perc,index=df.columns,columns=[\"unique vals count\"])\n    \n    cat_col,non_cat,uniques=[],[],[]\n    for index,col in enumerate(unique):\n        if len(col)<th:\n            u_val=col\n            cat_col.append(df.columns[index])\n        else:\n            u_val=\"more than\"+ str(th)\n            non_cat.append(df.columns[index])\n        uniques.append(u_val)\n        \n    df_unique[\"unique vals\"]=uniques\n    return df_unique,cat_col,non_cat\n\ndef get_info(df,unique_val_threshold,only_df=False):\n    df_unique,cat_col,non_cat=show_unique(df,unique_val_threshold)\n    df_nan=show_nan(df)\n    df_info=df_nan.join(df_unique)\n    df_info[\"Dtypes\"]=df.dtypes\n    if only_df:\n        return df_info.style.\\\n            background_gradient(cmap='Greens',axis=0).\\\n            applymap(lambda x: \"color:red\" if x>0 else \"color:black\",subset=[\"Nan values\"]).\\\n            applymap(lambda x: \"background-color:lightgreen\" if x[0]!=\"m\" else \"background-color:pale green\",subset=[\"unique vals\"])\n    return cat_col,non_cat,df_info.style.\\\n            background_gradient(cmap='Greens',axis=0).\\\n            applymap(lambda x: \"color:red\" if x>0 else \"color:black\",subset=[\"Nan values\"]).\\\n            applymap(lambda x: \"background-color:lightgreen\" if x[0]!=\"m\" else \"background-color:pale green\",subset=[\"unique vals\"])\n","fe8dc44c":"cat_col,non_cat,df_info=get_info(df,10)","f6069ecc":"df_info","cc3448d1":"df.describe().style.background_gradient(axis=0)","cf45f1ab":"non_cat","e040bb2f":"cat_col","836964b4":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\ndef count_catcols(df,catcols,width,height):\n    fig,ax=plt.subplots(1,len(catcols),figsize=(width,height))\n    i=0\n    for cols in catcols:\n        x=df[cols]\n        percentage = lambda i: len(i) \/ float(len(x)) \n        sns.barplot(x=x,y=x,ax=ax[i],estimator=percentage).set(ylabel=\"percent\")\n        plt.title(cols)\n        i+=1\n","64b4a2ed":"from matplotlib.pyplot import figure\ndef show_dist(df,target,ax):\n    # Add lines for mean, median and mode:\n    # For Grid (for better mapping of heights)\n    target=target\n    sns.kdeplot(df[target].dropna(),color=\"blue\",ax=ax)\n","a6f8680c":"count_catcols(df,cat_col,25,5)","f5ad85ab":"_,ax_non_cat=plt.subplots(3,2,figsize=(25,12))\n\nshow_dist(df,\"age\",ax_non_cat[0][0])\nshow_dist(df,'creatinine_phosphokinase',ax_non_cat[0][1])\nshow_dist(df,'ejection_fraction',ax_non_cat[1][0])\nshow_dist(df,\"platelets\",ax_non_cat[1][1])\nshow_dist(df,\"serum_creatinine\",ax_non_cat[2][0])\nshow_dist(df,\"time\",ax_non_cat[2][1])","b88c7487":"# countplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\ndef catplot(df,col,target_col):\n    x,t= col, target_col\n\n    df1 = df.groupby(x)[t].value_counts(normalize=True)\n    df1 = df1.rename('percent').reset_index()\n    p=sns.catplot(x=x,y='percent',hue=t,kind='bar',data=df1)\n    return p","a2b15647":"print(cat_col[:-1])","325788cc":"# see relationship with target var\ncat_col=cat_col[:-1]\nfor i,j in enumerate(cat_col):\n    catplot(df,j,\"DEATH_EVENT\")\n    plt.title(j.upper())\n    plt.show()","63d1b092":"sns.pairplot(vars=non_cat,data=df,hue=\"DEATH_EVENT\",kind=\"scatter\")","37cf801d":"df[df[\"DEATH_EVENT\"]==1][non_cat].describe().iloc[:3,:].style.background_gradient()","ca4fed45":"df[df[\"DEATH_EVENT\"]==0][non_cat].describe().iloc[:3,:].style.background_gradient()","e72c2b59":"# observation : seems like platelets is not a good dertimining feature as it doesn't show significant difference in both classes","81420521":"# binarization\ndf=pd.get_dummies(columns=cat_col,data=df)","f09ad9b5":"# raw train( just OHE no outlier removal,feature selection,engineering,tuning,etc)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nX=df.drop([\"DEATH_EVENT\"],axis=1)\ny=df[\"DEATH_EVENT\"]\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\nclf=LogisticRegression()\nclf.fit(X_train,y_train)","744ab4fc":"clf.score(X_train,y_train)","b1f23b40":"print(classification_report(y_test,clf.predict(X_test)))","8e231ee1":"# univariate analysis\n"}}