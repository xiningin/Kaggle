{"cell_type":{"ea37b00f":"code","98931c78":"code","353d8358":"code","83355c32":"code","56187705":"code","f824a91b":"code","c9369ae5":"code","62869e33":"code","3609480f":"code","b2657f7a":"code","ea00b542":"code","9408ac50":"code","2c98b46c":"code","f2c091b0":"code","1e93611a":"code","0bcab90a":"code","cfe6c016":"code","1a40c0c8":"code","5de59883":"code","ec02c1c2":"code","73f37b31":"code","0b91fd8c":"code","c1609318":"code","eccf77b1":"code","32d480f8":"code","e490d1df":"code","60ee3e13":"code","6a1e0ed3":"code","edb12c1a":"code","5a1a2a7d":"code","230acb94":"code","bb4ebf67":"code","f3d94e03":"code","a7de1aaa":"code","c0f5b0c3":"code","35b531de":"code","823f9daf":"code","8e2aab0b":"code","bc1601f6":"code","83b44395":"code","fdf67a7d":"code","94bec088":"markdown","2b797204":"markdown","d95663c3":"markdown","abb97719":"markdown","85bd6459":"markdown","cc350e5f":"markdown","1a5881bb":"markdown","2520ca33":"markdown","410a651b":"markdown","1d28d303":"markdown","5e3a498b":"markdown","21a06529":"markdown","6dfcfa4c":"markdown","99a346f3":"markdown","68c12a8f":"markdown","78dc4b68":"markdown","ca5f7647":"markdown","8a3405f3":"markdown","55b7f57f":"markdown","92bab6bf":"markdown","fea18b2f":"markdown","653c8e42":"markdown","21b16313":"markdown","15fa6642":"markdown","913f328d":"markdown","a563e873":"markdown","8e01e765":"markdown","44133126":"markdown","e6aa6238":"markdown","06d2a31e":"markdown","f55c55d3":"markdown","ed9ddf40":"markdown","04fb1be9":"markdown","33789a3d":"markdown","20b766e7":"markdown","7c9d5533":"markdown","3e504b0c":"markdown","a29b80a0":"markdown","0674e7f2":"markdown","c3dd2680":"markdown","79ab47da":"markdown","0771eaac":"markdown","0d1f8650":"markdown","e3ec1251":"markdown","a9dbc648":"markdown","7dd528d8":"markdown","fbe473e1":"markdown","107463f9":"markdown","721d56b4":"markdown","4b2b3545":"markdown","5ec954ed":"markdown","57c7f9a0":"markdown","18b5bd3a":"markdown","c0a36c32":"markdown","c02d2700":"markdown","70610816":"markdown","e44e1b92":"markdown","a625ce8b":"markdown","71211c7e":"markdown","0b94bf02":"markdown","a817d305":"markdown"},"source":{"ea37b00f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib_venn import venn2, venn3, venn2_circles, venn3_circles #to create intersection graphs\nimport matplotlib.pyplot as plt #to plot show the charts\nimport seaborn as sns\nfrom scipy import stats\n\nfrom nltk import word_tokenize\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nimport os \nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","98931c78":"df_train = pd.read_csv(\"..\/input\/google-quest-challenge\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/google-quest-challenge\/test.csv\")\ndf_sub = pd.read_csv(\"..\/input\/google-quest-challenge\/sample_submission.csv\")","353d8358":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary","83355c32":"resumetable(df_train)[:10]","56187705":"resumetable(df_test)[:10]","f824a91b":"print(f\"Shape of submission: {df_sub.shape}\")\ntarget_cols = df_train[df_train.columns[df_train.columns.isin(df_sub.columns[1:])]].columns","c9369ae5":"df_train.head(3)","62869e33":"## I will use the host column, split and get the first string\nfor i in range(len(df_train)):\n    df_train.loc[i,'host_cat'] = df_train.host.str.split('.')[i][0]\ndf_train.drop('host', axis=1, inplace=True)","3609480f":"host = df_train.groupby(['host_cat'])['url'].nunique().sort_values(ascending=False)\ncategory = df_train.groupby(['category'])['url'].nunique().sort_values(ascending=False)\n\nplt.figure(figsize=(16,12))\nplt.suptitle('Unique URL by Host and Categories', size=22)\n\nplt.subplot(211)\ng0 = sns.barplot(x=category.index, y=category.values, color='blue')\ng0.set_title(\"Unique Answers by category\", fontsize=22)\ng0.set_xlabel(\"Category Name\", fontsize=19)\ng0.set_ylabel(\"Total Count\", fontsize=19)\n#g1.set_xticklabels(g1.get_xticklabels(),rotation=45)\nfor p in g0.patches:\n    height = p.get_height()\n    g0.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.1f}%'.format(height\/category.sum()*100),\n            ha=\"center\",fontsize=11) \n\nplt.subplot(212)\ng1 = sns.barplot(x=host[:20].index, y=host[:20].values, color='blue')\ng1.set_title(\"TOP 20 HOSTS with more UNIQUE questions\", fontsize=22)\ng1.set_xlabel(\"Host Name\", fontsize=19)\ng1.set_ylabel(\"Total Count\", fontsize=19)\ng1.set_xticklabels(g1.get_xticklabels(),rotation=45)\nfor p in g1.patches:\n    height = p.get_height()\n    g1.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.1f}%'.format(height\/host.sum()*100),\n            ha=\"center\",fontsize=11) \n    \nplt.subplots_adjust(hspace = 0.3, top = 0.90)\n\nplt.show()","b2657f7a":"print(f\"Total Unique Users in 'Question User Name': {df_train['question_user_name'].nunique()}\")\nprint(f\"Total Unique Users in 'Answer User Name': {df_train['answer_user_name'].nunique()}\")","ea00b542":"plt.figure(figsize=(12,8))\n\nvenn2([set(df_train['question_user_name'].value_counts(dropna=False).index), \n       set(df_train['answer_user_name'].value_counts(dropna=False).index)],\n      set_labels=('Question Users', 'Answer Users'), alpha=.5)\nplt.title('Comparison of Question and Answer Users Intersection\\n', fontsize=20)\n\nplt.show()","9408ac50":"import matplotlib.gridspec as gridspec # to do the grid of plots\n\ngrid = gridspec.GridSpec(3, 3)\nplt.figure(figsize=(16,3*4))\n\nplt.suptitle('Intersection QA USERS \\nQuestions and Answers by different CATEGORIES', size=20)\n\nfor n, col in enumerate(df_train['category'].value_counts().index):\n    ax = plt.subplot(grid[n])\n    venn2([set(df_train[df_train.category == col]['question_user_name'].value_counts(dropna=False).index), \n           set(df_train[df_train.category == col]['answer_user_name'].value_counts(dropna=False).index)],\n      set_labels=('Question Users', 'Answer Users'), )\n    ax.set_title(str(col), fontsize=15)\n    ax.set_xlabel('')\n    #plt.subplots_adjust(top = 0.98, wspace=.9, hspace=.9)\n    \nplt.subplots_adjust(top = 0.9, hspace=.1)\n\nplt.show()","2c98b46c":"grid = gridspec.GridSpec(5, 3)\nplt.figure(figsize=(16,4.5*4))\n\nplt.suptitle('Intersection QA USERS - TOP 15 \\nQuestions and Answers by different HOSTS', size=20)\ntop_host = df_train['host_cat'].value_counts()[:15].index\nfor n, col in enumerate(top_host):\n    ax = plt.subplot(grid[n])\n    venn2([set(df_train[df_train.host_cat == col]['question_user_name'].value_counts(dropna=False).index), \n           set(df_train[df_train.host_cat == col]['answer_user_name'].value_counts(dropna=False).index)],\n      set_labels=('Question Users', 'Answer Users'), )\n    ax.set_title(str(col), fontsize=15)\n    ax.set_xlabel('')\n    #plt.subplots_adjust(top = 0.98, wspace=.9, hspace=.9)\n    \nplt.subplots_adjust(top = 0.9, hspace=.1)\n\nplt.show()","f2c091b0":"# Tokenize each item in the review column\nword_tokens = [word_tokenize(question) for question in df_train.question_body]\n\n# Create an empty list to store the length of the reviews\nlen_tokens = []\n\n# Iterate over the word_tokens list and determine the length of each item\nfor i in range(len(word_tokens)):\n     len_tokens.append(len(word_tokens[i]))\n\n# Create a new feature for the lengh of each review\ndf_train['question_n_words'] = len_tokens","1e93611a":"grid = gridspec.GridSpec(5, 3)\nplt.figure(figsize=(16,6*4))\n\nplt.suptitle('Title and Question Lenghts by Different Categories \\nThe Mean in RED - Also 5% and 95% lines', size=20)\ncount=0\ntop_cats=df_train['category'].value_counts().index\nfor n, col in enumerate(top_cats):\n    for i, q_t in enumerate(['question_title', 'question_body', 'question_n_words']):\n        ax = plt.subplot(grid[count])\n        if q_t == 'question_n_words':\n            sns.distplot(df_train[df_train['category'] == col][q_t], bins = 50, \n                         color='g', label=\"RED - 50%\") \n            ax.set_title(f\"Distribution of {str(col)} \\nQuestion #Total Words Distribution\", fontsize=15)\n            ax.axvline(df_train[df_train['category'] == col][q_t].quantile(.95))\n            ax.axvline(df_train[df_train['category'] == col][q_t].quantile(.05))\n            mean_val = df_train[df_train['category'] == col][q_t].mean()\n            ax.axvline(mean_val, color='red' )\n            ax.set_xlabel('')            \n        else:\n            sns.distplot(df_train[df_train['category'] == col][q_t].str.len(), bins = 50, \n                         color='g', label=\"RED - 50%\") \n            ax.set_title(f\"Distribution of {str(col)} \\n{str(q_t)}\", fontsize=15)\n            ax.axvline(df_train[df_train['category'] == col][q_t].str.len().quantile(.95))\n            ax.axvline(df_train[df_train['category'] == col][q_t].str.len().quantile(.05))\n            mean_val = df_train[df_train['category'] == col][q_t].str.len().mean()\n            ax.axvline(mean_val, color='red' )\n            #ax.text(x=mean_val*1.1, y=.02, s='Holiday in US', alpha=0.7, color='#334f8d')\n            ax.set_xlabel('')\n        count+=1\n        \nplt.subplots_adjust(top = 0.90, hspace=.4, wspace=.15)\nplt.show()","0bcab90a":"grid = gridspec.GridSpec(10, 3)\n\nplt.figure(figsize=(16,8*4))\ncount=0\nplt.suptitle('Distribution of QA metrics (Target Features)', size=20)\n# top_host = df_train['host_cat'].value_counts()[:15].index\nfor n, col in enumerate(target_cols):\n    #if df_train[target_cols].std()[col] > .15:\n    ax = plt.subplot(grid[count])\n    sns.boxplot(x='category', y=col, data=df_train)\n    ax.set_title(str(col), fontsize=13)\n    ax.set_xlabel('')\n    ax.set_ylabel(' ')\n    count+=1\n    ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n\nplt.subplots_adjust(top = 0.95, hspace=.9, wspace=.2)\n\nplt.show()\n\n","cfe6c016":"pca = PCA(n_components=3, random_state=42)\n\nprincipalComponents = pca.fit_transform(df_train[target_cols])\n\nprincipalDf = pd.DataFrame(principalComponents)\n\n# df.drop(cols, axis=1, inplace=True)\nprefix='Target_PCA'\nprincipalDf.rename(columns=lambda x: str(prefix)+str(x), inplace=True)\n\ndf_train = pd.concat([df_train, principalDf], axis=1)","1a40c0c8":"print(\"TOP 3 PCA Explanability: \")\n[print(str(f\"{i+1} - {round(pca*100,3)}%\")) for i, pca in enumerate(pca.explained_variance_ratio_[:3])]\nprint(f\"Sum of 3 Principal components: {round(pca.explained_variance_ratio_[:3].sum()*100,3)}%\")","5de59883":"plt.figure(figsize=(15,6))\ng = sns.scatterplot(x='Target_PCA0', y='Target_PCA1', data=df_train, hue='category')\ng.set_title(\"PCA Components Distribution by Categories\", fontsize=22)\ng.set_xlabel(\"TARGET PCA 0\", fontsize=16)\ng.set_ylabel(\"TARGET PCA 1\", fontsize=16)\n\nplt.show()","ec02c1c2":"g = sns.FacetGrid(df_train[df_train.host_cat.isin(top_host)], col='host_cat',\n                  col_wrap=3, height=3, aspect=1.5, hue='category')\n\ng.map(sns.scatterplot, \"Target_PCA0\", \"Target_PCA1\", alpha=.5 ).add_legend();\ng.set_titles('{col_name}', fontsize=17)\nplt.show()","73f37b31":"plt.figure(figsize=(16,10))\nsns.heatmap(df_train[target_cols].corr(),vmin=-1,cmap='YlGnBu')","0b91fd8c":"from wordcloud import WordCloud, STOPWORDS\n\nstopwords = set(STOPWORDS)\nnewStopWords = ['amp', 'gt', 'lt', 'div', 'id',\n                'fi', 'will', 'use', 'one', 'nbsp', 'need']\nstopwords.update(newStopWords)","c1609318":"grid = gridspec.GridSpec(5, 2)\n\nplt.figure(figsize=(16,7*4))\n\nplt.suptitle('Word Cloud OF CATEGORY FEATURE', size=20)\n\nfor n, col in enumerate(df_train['category'].value_counts().index):\n    ax = plt.subplot(grid[n])  \n    \n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=250,\n        max_font_size=100, \n        width=400, height=280,\n        random_state=42,\n    ).generate(\" \".join(df_train[df_train['category'] == col]['answer'].astype(str)))\n\n    #print(wordcloud)\n\n    plt.imshow(wordcloud)\n    plt.title(f\"Category: {col}\",fontsize=18)\n    plt.axis('off')\nplt.subplots_adjust(top = 0.95, hspace=.2, wspace=.1 )\n\nplt.show()","eccf77b1":"#newStopWords = ['fruit', \"Drink\", \"black\"]\n\n#stopwords.update(newStopWords)\n\nimport matplotlib.gridspec as gridspec # to do the grid of plots\ngrid = gridspec.GridSpec(5, 2)\n\nplt.figure(figsize=(16,7*4))\n\nplt.suptitle('Answers Word Cloud \\nTOP 10 hosts with more questions', size=20)\n\nfor n, col in enumerate(df_train['host_cat'].value_counts()[:10].index):\n    ax = plt.subplot(grid[n])   \n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=250,\n        max_font_size=100, \n        width=400, height=280,\n        random_state=42,\n    ).generate(\" \".join(df_train[df_train['host_cat'] == col]['answer'].astype(str)))\n\n    #print(wordcloud)\n\n    plt.imshow(wordcloud)\n    plt.title(f\"Host: {col}\",fontsize=18)\n    plt.axis('off')\n    \nplt.subplots_adjust(top = 0.95, hspace=.2, wspace=.1 )\n\nplt.show()","32d480f8":"from textblob import TextBlob\n\npol = lambda x: TextBlob(x).sentiment.polarity\nsub = lambda x: TextBlob(x).sentiment.subjectivity\n\ndf_train['ans_polarity']= df_train['answer'].apply(pol)\ndf_train['ans_subjectivity']= df_train['answer'].apply(sub)\n\ndf_train[['answer', 'category', 'ans_polarity', 'ans_subjectivity']].head()","e490d1df":"plt.figure(figsize=(16,5))\n\ng = sns.scatterplot(x='ans_polarity', y='ans_subjectivity', \n                    data=df_train, hue='category')\ng.set_title(\"Sentiment Analyzis (Polarity x Subjectivity) by 'Category' Feature\", fontsize=21)\ng.set_xlabel(\"Polarity distribution\",fontsize=18)\ng.set_ylabel(\"Subjective \",fontsize=18)\n\nplt.show()","60ee3e13":"polarity_answers = df_train.groupby('category')['ans_polarity', 'ans_subjectivity'].describe().reset_index()\n\npolarity_answers","6a1e0ed3":"stopwords.update(['amp', 'lt', 'gt', 'frac'])","edb12c1a":"import re\ncontraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\",\n                    \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\n                    \"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \n                    \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n                    \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\",\n                    \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \n                    \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n                    \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \n                    \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n                    \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n                    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n                    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n                    \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n                    \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n                    \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n                    \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n                    \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \n                    \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n                    \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n                    \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\",\n                    \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \n                    \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n                    \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n                    \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n                    \"you'll've\": \"you will have\", \"you're\":\"you are\", 'you re':\"you are\",'youre': \"you are\", \"you've\": \"you have\", }\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '\/', '[', ']', '>',\n          '%', '=', '#', '*', '+', '\\\\', '\u2022',  '~', '@', '\u00a3','\u00b7', '_', '{', '}', '\u00a9', '^', '\u00ae', '`', \n          '<', '\u2192', '\u00b0', '\u20ac', '\u2122', '\u203a',  '\u2665', '\u2190', '\u00d7', '\u00a7', '\u2033', '\u2032', '\u00c2', '\u2588', '\u00bd', '\u00e0', '\u2026', \n          '\u201c', '\u2605', '\u201d', '\u2013', '\u25cf', '\u00e2', '\u25ba', '\u2212', '\u00a2', '\u00b2', '\u00ac', '\u2591', '\u00b6', '\u2191', '\u00b1', '\u00bf', '\u25be',\n          '\u2550', '\u00a6', '\u2551', '\u2015', '\u00a5', '\u2593', '\u2014', '\u2039', '\u2500',  '\u2592', '\uff1a', '\u00bc', '\u2295', '\u25bc', '\u25aa', '\u2020', '\u25a0',\n          '\u2019', '\u2580', '\u00a8', '\u2584', '\u266b', '\u2606', '\u00e9', '\u00af', '\u2666', '\u00a4', '\u25b2', '\u00e8', '\u00b8', '\u00be', '\u00c3', '\u22c5', '\u2018', '\u221e', \n          '\u2219', '\uff09', '\u2193', '\u3001', '\u2502', '\uff08', '\u00bb', '\uff0c', '\u266a', '\u2569', '\u255a', '\u00b3', '\u30fb', '\u2566', '\u2563', '\u2554', '\u2557', '\u25ac',\n          '\u2764', '\u00ef', '\u00d8', '\u00b9', '\u2264', '\u2021', '\u221a', #'lt', 'gt', 'amp', 'div', 'ex', 'le', 'http', 'www', 'vo', '\\n'\n         ]\n\ndef clean_text(x):\n    x = str(x)\n    \n    for punct in puncts:\n        if punct in x:\n            x = x.replace(punct, '')\n    return x\n\ndef _get_contractions(contraction_dict):\n    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n    return contraction_dict, contraction_re\n\ncontractions, contractions_re = _get_contractions(contraction_dict)\n\ndef replace_contractions(text):\n    def replace(match):\n        return contractions[match.group(0)]\n    return contractions_re.sub(replace, text)\n","5a1a2a7d":"# Here, the order is important\ndf_train['answer'] = df_train['answer'].apply(replace_contractions)\ndf_train['answer'] = df_train['answer'].apply(clean_text)","230acb94":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\ngrid = gridspec.GridSpec(5, 3)\nplt.figure(figsize=(16,6*4))\n\nfor n, cat in enumerate(top_host[:9]):\n    \n    ax = plt.subplot(grid[n])   \n    # print(f'PRINCIPAL WORDS CATEGORY: {cat}')\n    # vectorizer = CountVectorizer(ngram_range = (3,3)) \n    # X1 = vectorizer.fit_transform(df_train[df_train['host_cat'] == cat]['answer'])  \n \n    min_df_val = round(len(df_train[df_train['host_cat'] == cat]) - len(df_train[df_train['host_cat'] == cat]) * .99)\n    max_df_val = round(len(df_train[df_train['host_cat'] == cat]) - len(df_train[df_train['host_cat'] == cat]) * .3)\n    \n    # Applying TFIDF \n    vectorizer = TfidfVectorizer(ngram_range = (2,2), min_df=5, stop_words='english',\n                                 max_df=.5) \n    X2 = vectorizer.fit_transform(df_train[df_train['host_cat'] == cat]['answer']) \n    features = (vectorizer.get_feature_names()) \n    scores = (X2.toarray()) \n\n    # Getting top ranking features \n    sums = X2.sum(axis = 0) \n    data1 = [] \n    \n    for col, term in enumerate(features): \n        data1.append( (term, sums[0,col] )) \n\n    ranking = pd.DataFrame(data1, columns = ['term','rank']) \n    words = (ranking.sort_values('rank', ascending = False))[:10]\n    \n    sns.barplot(x='term', y='rank', data=words, ax=ax, \n                color='blue', orient='v')\n    ax.set_title(f\"Top rank Trigram of: {cat}\")\n    ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n    ax.set_ylabel(' ')\n    ax.set_xlabel(\" \")\n\nplt.subplots_adjust(top = 0.95, hspace=.9, wspace=.1)\n\nplt.show()","bb4ebf67":"extra_cols = ['host_cat', 'question_n_words', 'Target_PCA0',\n              'Target_PCA1', 'Target_PCA2', 'ans_polarity', 'ans_subjectivity']","f3d94e03":"y_train = df_train[target_cols].copy()\nX_train = df_train.drop(list(extra_cols) + list(target_cols), axis=1)\ndel df_train\n\nX_test = df_test.copy()\ndel df_test","a7de1aaa":"## Shell \n!pip install ..\/input\/sacremoses > \/dev\/null\n\nimport sys\nsys.path.insert(0, \"..\/input\/transformers\/\")\n","c0f5b0c3":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n# import tensorflow_hub as hub\nimport tensorflow as tf\n# import bert_tokenization as tokenization\nimport tensorflow.keras.backend as K\nimport os\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\nfrom transformers import *\n\nfrom transformers import *\n\nnp.set_printoptions(suppress=True)\nprint(tf.__version__)","35b531de":"np.set_printoptions(suppress=True)\n\nfrom transformers import *\n\nBERT_PATH = '..\/input\/bert-base-uncased-huggingface-transformer\/'\ntokenizer = BertTokenizer.from_pretrained(BERT_PATH+'bert-base-uncased-vocab.txt')\n\nMAX_SEQUENCE_LENGTH = 512\n","823f9daf":"## The function to creat the masks using to the title, question and answer\ndef _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n    \n    def return_id(str1, str2, truncation_strategy, length):\n\n        inputs = tokenizer.encode_plus(str1, str2,\n            add_special_tokens=True,\n            max_length=length,\n            truncation_strategy=truncation_strategy)\n        \n        input_ids =  inputs[\"input_ids\"]\n        input_masks = [1] * len(input_ids)\n        input_segments = inputs[\"token_type_ids\"]\n        padding_length = length - len(input_ids)\n        padding_id = tokenizer.pad_token_id\n        input_ids = input_ids + ([padding_id] * padding_length)\n        input_masks = input_masks + ([0] * padding_length)\n        input_segments = input_segments + ([0] * padding_length)\n        \n        return [input_ids, input_masks, input_segments]\n    \n    input_ids_q, input_masks_q, input_segments_q = return_id(\n        title + ' ' + question, None, 'longest_first', max_sequence_length)\n    \n    input_ids_a, input_masks_a, input_segments_a = return_id(\n        answer, None, 'longest_first', max_sequence_length)\n    \n    return [input_ids_q, input_masks_q, input_segments_q,\n            input_ids_a, input_masks_a, input_segments_a]\n\n# Computing the inputs\ndef compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n    \n    input_ids_q, input_masks_q, input_segments_q = [], [], []\n    input_ids_a, input_masks_a, input_segments_a = [], [], []\n    \n    for _, instance in tqdm(df[columns].iterrows()):\n        \n        t, q, a = instance.question_title, instance.question_body, instance.answer\n\n        ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n        \n        input_ids_q.append(ids_q)\n        input_masks_q.append(masks_q)\n        input_segments_q.append(segments_q)\n\n        input_ids_a.append(ids_a)\n        input_masks_a.append(masks_a)\n        input_segments_a.append(segments_a)\n        \n    return [np.asarray(input_ids_q, dtype=np.int32), \n            np.asarray(input_masks_q, dtype=np.int32), \n            np.asarray(input_segments_q, dtype=np.int32),\n            np.asarray(input_ids_a, dtype=np.int32), \n            np.asarray(input_masks_a, dtype=np.int32), \n            np.asarray(input_segments_a, dtype=np.int32)]\n\n\ndef compute_output_arrays(df, columns):\n    return np.asarray(df[columns])","8e2aab0b":"\n## Computing the error metric to the model optimization\ndef compute_spearmanr_ignore_nan(trues, preds):\n    rhos = []\n    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n        rhos.append(spearmanr(tcol, pcol).correlation)\n    return np.nanmean(rhos)\n\ndef create_model():\n    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    \n    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    \n    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    \n    config = BertConfig() # print(config) to see settings\n    config.output_hidden_states = False # Set to True to obtain hidden states\n    # caution: when using e.g. XLNet, XLNetConfig() will automatically use xlnet-large config\n    \n    # normally \".from_pretrained('bert-base-uncased')\", but because of no internet, the \n    # pretrained model has been downloaded manually and uploaded to kaggle. \n    bert_model = TFBertModel.from_pretrained(\n        BERT_PATH+'bert-base-uncased-tf_model.h5', config=config)\n    \n    # if config.output_hidden_states = True, obtain hidden states via bert_model(...)[-1]\n    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\n    a_embedding = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)[0]\n    \n    q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\n    a = tf.keras.layers.GlobalAveragePooling1D()(a_embedding)\n    \n    x = tf.keras.layers.Concatenate()([q, a])\n    \n    x = tf.keras.layers.Dropout(0.2)(x)\n    \n    x = tf.keras.layers.Dense(30, activation='sigmoid')(x)\n\n    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, a_id, a_mask, a_atn,], outputs=x)\n    \n    return model","bc1601f6":"outputs = compute_output_arrays(y_train, y_train.columns)\ninputs = compute_input_arrays(X_train, X_train.columns, tokenizer, MAX_SEQUENCE_LENGTH)\ntest_inputs = compute_input_arrays(X_test, X_test.columns, tokenizer, MAX_SEQUENCE_LENGTH)","83b44395":"## Creating Kfold with 5 splits \ngkf = GroupKFold(n_splits=5).split(X=X_train.question_body, groups=X_train.question_body)\n\n## to receive predictions\nvalid_preds = []\ntest_preds = []\n\n## Looping throught the folds\nfor fold, (train_idx, valid_idx) in enumerate(gkf):\n    \n    # will actually only do 2 folds (out of 5) to manage < 2h\n    if fold in [0 , 2, 4]:\n        \n        ## Train index from Kfold \n        train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n        train_outputs = outputs[train_idx]\n        ## Valid index from Kfold \n        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n        valid_outputs = outputs[valid_idx]\n        \n        K.clear_session()\n        \n        ## Instantiating the Bert Model\n        model = create_model()\n        optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n        \n        ## Fiting the model\n        model.fit(train_inputs, train_outputs, epochs=2, batch_size=6)\n        \n        # model.save_weights(f'bert-{fold}.h5')\n        valid_preds.append(model.predict(valid_inputs))\n        # predicting the test set and appending to test_preds\n        test_preds.append(model.predict(test_inputs))\n        \n        # Calculating the error in the valid set\n        rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n        print('validation score = ', rho_val)","fdf67a7d":"df_sub.iloc[:, 1:] = np.average(test_preds, axis=0) # for weighted average set weights=[...]\n\ndf_sub.to_csv('submission.csv', index=False)","94bec088":"# Start Modellling\n- Preprocessing\n- Implement a simple solution BERT using TfIdf as baseline \n\n> I will implement the amazing pythonic preprocessing of @pavelvpster kernel, you can access <a href=\"https:\/\/www.kaggle.com\/pavelvpster\/google-q-a-labeling-tf-idf-pytorch\">here<\/a>","2b797204":"# Trigrams by TOP 10 HOSTS","d95663c3":"Now, we are ready to start exploring the data to try get a good insight that can help us to build the Algorithm;<br>\nWe can see that we have many different metrics that was included only on training data... It will be useful to we better understand the categories.","abb97719":"It's not so much, but it's a important value that means that we have some different patterns. \n- Let's create some charts to explain","85bd6459":"It's interesting, we can see some difference in the intersection ratio of the USERS in the different categories;<br>\nTake a look on Stackoverflow, it has a big difference between people who ask and people who answer questions; ","cc350e5f":"## Dataframe to CSV \n- Saving the prediction file in csv extension","1a5881bb":"## Principal Component Analyzis - N components","2520ca33":"Cool! I find it very insightful hahah<br>\nIt's interesting to note that programmers host has almost 1:3 ratio between QA Users, and only one in the intersection.<br>\nOnly for curiosity, we can take a look on one some of the intersection users to see what type of questions was done by them","410a651b":"### Creating func to resume the dataset","1d28d303":"## Trainning the model","5e3a498b":"De degree of subjectivity of the Stackoverflow is smaller than the other categories. <br>\nWe can also note a smaller level of polarity in the answer. In opposite of it, Life Arts has the highest polarity and subjectivity what make sense.","21a06529":"# Libraries","6dfcfa4c":"We can't see a clear difference in the answers. But seems that the answers tends to have a more positive value in polarity <br>\nLet's find other way to access this informations in a better and more objective way.","99a346f3":"It's very interesting. <br>\nWe can see that a small part of total users has done both actions on the platform. <br>\nI thought it had a more balanced ratio in users that do questions and who answer it;\n\n","68c12a8f":"Cool! \nThe wordcloud of the hosts are very meaningful of the different communities","78dc4b68":"First chart:\nThe most common category in Stackexchange f\u00f3rums are:<br>\n1 - Technology(41.8%)<br>\n2 - Stackoverflow (21.2%)<br>\n3 - Culture (14.7%)<br>\n4 - Science (11.2)<br>\n5 - Life Arts(10.9)<br>\nIt's not so unbalanced, so it can be useful to train the model. \n\nSecond Chart:\nThe most common category is the Stackoverflow with 20.6% of the total open topics(questions);<br>\nAfter the StackOverflow we can see that only 7 categories have a ratio highest than 2%, we have in total 59;\n\nThe group of Stackoverflow, eletronics, superuser, serverfault, english, math, tex, physics and askubuntu together has **almost 46% of the total** questions. \n","ca5f7647":"## Shape of the Submission","8a3405f3":"## Ploting the Venn Diagram.","55b7f57f":"## Random Example of Questions + Answers","92bab6bf":"# Exploring Target Features\n- Let's explore the target features to find some clear pattern that can be useful.\n- I will apply some techniques of dimensionality reduction and verify the explained variability and f","fea18b2f":"# Questions and Answers Texts\nLet's start ploting some WordClouds by Categories. \n","653c8e42":"# Ploting PCA of Target\n- ploting the first and second principal components","21b16313":"Cool! Now that we got some metrics about the posible sentiment of the answers, let get some quantitative analysis of it.","15fa6642":"## Distribution of all Target Features\n","913f328d":"## Preprocessing","a563e873":"## Setting thePaths to the pre trained models and ","8e01e765":"Cool!!! It shows us that the questions in Technology and Stackoverflow has different pattern than the culture, science, life arts, what make a lot of sense. <br>\n\nBelow, I will take a look in the difference between the hosts. ","44133126":"We have 476 examples in the test dataset.","e6aa6238":"## Ploting the polarity x the subjetictivy","06d2a31e":"# Start Modeling\n- I will start by a simple model to use as baseline. As it's my first time with a QA task, I searched for good solutions. \n- The QA model implementation below, I saw in @hamditarek amazing kernel about LDA and LSA topic modelling. Kernel Link below on the resources links; \n\nVersion 2: <br>\nI'm now testing the solutions of akensert","f55c55d3":"## Getting some statistics of Polarity and Subjectivity by the Category feature","ed9ddf40":"## Test dataset","04fb1be9":"Cool! <br>\nThe quantiles of the distributions are very similar in all categories in both title and question lenghts.\n\n","33789a3d":"## Creating the model","20b766e7":"### Stay tuned and if this kernel was useful for you, please upvote the kernel","7c9d5533":"Nice I can see some interesting words in the different categories, but only stackoverflow seems more clear. Let's explore it in further;","3e504b0c":"# Answers Sentiment analysis ","a29b80a0":"Setting the X and y","0674e7f2":"# NOTE: THIS KERNEL IS NOT FINISHED","c3dd2680":"## QA USERS Intersection by Host feature","79ab47da":"## Importing the needed libraries","0771eaac":"## UNIQUE QUESTIONS\n- Let's start by a more generalist understanding and how the questions are distributed between the different categories and hosts","0d1f8650":"# INITIAL QUESTIONS: \n- What's the intersection between users that do the question and the who don't. \n- In general (mean), how many different topics an user do questions?\n- How many questions and\/or answers an users usually do? \n- We can see clear patterns in different topics? (for instance, well writen in literacture topic...)\n- How many different topics we have?\n- The size of questions and answers are same in all categories?\n- We can detect the sentiment of QA of different categories?\n- What's the most frequent words by categories? \n- How many different topics we can detect in the QA topics? \n- And much more questions that probably will raise when I put my hands-on it! \n\n\n\n## After that we got the answers I will create some features, preprocess the data and model an algorithm that can solve this problem;\n\n# Enjoy and stay tuned to the next updates","e3ec1251":"# Description\n\nComputers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences.\n\nHumans are better at addressing subjective questions that require a deeper, multidimensional understanding of context - something computers aren't trained to do well\u2026yet.. Questions can take many forms - some have multi-sentence elaborations, others may be simple curiosity or a fully developed problem. They can have multiple intents, or seek advice and opinions. Some may be helpful and others interesting. Some are simple right or wrong.\n\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/google-research\/human_computable_dimensions_1.png\" alt=\"QA Google\">\n\nUnfortunately, it\u2019s hard to build better subjective question-answering algorithms because of a lack of data and predictive models. That\u2019s why the CrowdSource team at Google Research, a group dedicated to advancing NLP and other types of ML science via crowdsourcing, has collected data on a number of these quality scoring aspects.\n\nIn this competition, you\u2019re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a \"common-sense\" fashion. Our raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task. By lessening our dependency on complicated and opaque rating guidelines, we hope to increase the re-use value of this data set. What you see is what you get!\n\nDemonstrating these subjective labels can be predicted reliably can shine a new light on this research area. Results from this competition will inform the way future intelligent Q&A systems will get built, hopefully contributing to them becoming more human-like.","a9dbc648":"GREAT! We can clearly note different patterns in the target PCA. \nFor instance, take a look on askubuntu, stackoverflow, tex and culture, English, physics and so on... It's a insightful information.","7dd528d8":"# Finding for Correlation in Target Features","fbe473e1":"It needs a more appropriate text preprocessing but it give us a good first understand about the words in different categories","107463f9":"# PCA of target BY HOSTS\nploting pca to the top 15 hosts with more unique questions","721d56b4":"Cool! It's a good start to meet our data; \nWe have **6079 Answers Unique ID's** of QA Labeled. <br>\nThe resume also shows that **3215 different users did questions** and **4114 different users answered** questions\n\nWe can note that the Entropy of the values are very high and we don't have missing values; \n\n\n","4b2b3545":"## Functions to preprocess the data to BERT archtecture","5ec954ed":"Some of sources\/references that I used in this kernel:<br>\nhttps:\/\/www.kaggle.com\/abhinand05\/bert-for-humans-tutorial-baseline-version-2 <br>\nhttps:\/\/www.kaggle.com\/pavelvpster\/google-q-a-labeling-tf-idf-pytorch <br>\nhttps:\/\/neptune.ai\/blog\/exploratory-data-analysis-natural-language-processing-tools <br>\nhttps:\/\/mlwhiz.com\/blog\/2019\/01\/17\/deeplearning_nlp_preprocess\/ <br>\nhttps:\/\/www.kaggle.com\/hamditarek\/get-started-with-nlp-lda-lsa <br>\nhttps:\/\/www.kaggle.com\/akensert\/bert-base-tf2-0-now-huggingface-transformer<br><br>\nThe books:<br>\n- Natural Language Processing and Computational Linguistics. A practical Guide to Text Analysis with Python, Gensim, spaCy and Keras (Packt-2018) - Bhargav Srinivasa<br>\n- Python Natural Language Processing (Packt-2017) - Jalaj Thanaki","57c7f9a0":"We can note that some features are high correlated.<br>\nFor instance: Critical questions and questions interestingness self seems more well written. ","18b5bd3a":"# Title and Body Lenghts of questions \n- I will start counting the Number of words in each question and set it to a new column\n- After I will plot some distributions about the titles and the bodies of the questions\n- The idea is to see te difference by categories","c0a36c32":"## Processing the inputs and outputs","c02d2700":"# Welcome to my new Kernel to NLP tasks\n\nI'm starting to focus on NLP tasks and I decided to find for good challenges on Kaggle, and for luck, I discovered this competition.\n\nI hope it can be useful to the other fellows I'm sure that I will learn a lot in this amazing world of NLP. \n\nCome with me and let's discover some interesting questions about this data.\n","70610816":"Cool. It's a informative chart where we can get the difference between the categories to each target feature.\n- I think that worth to spent a time to analyze it in depth\nFor instance: \n- \"question body critical\" has an interesting distribution between the different categories. \n- \"question well writen\" shows that Life Arts and Culture has highest quality in the written. \n- And many other distributions that can be meaninful.\n\nAlso, we have some features taht we can't see a clear difference between the categories. \n\nLet's try to extract the PCA of all this features and see what it can shows to us. ","e44e1b92":"##  QA USERS Intersection by CATEGORY feature","a625ce8b":"## Importing the data","71211c7e":"# First look in \"the face\"(haha) of our data","0b94bf02":"## Questions and Answer Unique Users and some values\nAs we saw in the Resume table, \n> Total Unique Users in 'Question User Name': 3215 <br>Total Unique Users in 'Answer User Name': 4114 <br>\n    \nLet's take a first look on the users intersection between who ask something and who try to answer. \n","a817d305":"# WordCloud by HOSTS\n- TOP 10 hosts with more unique questions"}}