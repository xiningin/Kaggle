{"cell_type":{"f70dca75":"code","34ce4f85":"code","2e47e0d2":"code","b65de11f":"code","33dee2fa":"code","c6e9ff1a":"code","0711bbd3":"code","0e3d2606":"code","829a5fb7":"code","f0f693ed":"code","5d67846d":"code","96a155a0":"code","174604f6":"code","da0e7ba0":"code","ab225b3a":"code","b7520a3a":"code","64414afa":"code","8cad90f2":"code","3cbdc0aa":"code","d195d3f3":"code","96b2ccc9":"code","02d7c9b0":"code","1adb8952":"code","16194777":"code","5f91b1ca":"code","c5c8ba85":"code","903e61ea":"code","08c74afb":"code","bd54a588":"code","a6828bdd":"code","cb8441a4":"code","abfa7b37":"code","9b275d33":"code","988d797e":"code","fd613de6":"code","67b83ed1":"code","73698039":"code","01ef7c0c":"code","41ccb380":"code","fbf7ea9d":"code","d9bbc9d4":"code","dc1f5763":"code","f7751142":"code","bbd57935":"code","b239e5b6":"markdown","a25d2ae0":"markdown","933e3e0f":"markdown","8534cf38":"markdown","7135a660":"markdown","2ed2072d":"markdown","e58d3434":"markdown","65b2e8d0":"markdown","4d56851e":"markdown","92b02dd9":"markdown","fb747b0b":"markdown","25e164b7":"markdown"},"source":{"f70dca75":"debug = False\n# debug = True\n\n!ls ..\/input\/","34ce4f85":"import warnings \nwarnings.filterwarnings(\"ignore\")\n\nimport os, gc\nimport sys\nimport random\nimport math\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport pydicom\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm, tqdm_notebook\nimport pandas as pd \nimport glob\n\nsys.path.insert(0, '\/kaggle\/input\/siim-acr-pneumothorax-segmentation')\nfrom mask_functions import rle2mask, mask2rle","2e47e0d2":"DATA_DIR = '\/kaggle\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax'\n\n# Directory to save logs and trained model\nROOT_DIR = '\/kaggle\/working'\n\n!ls {DATA_DIR}","b65de11f":"# !pip install 'keras==2.1.6' --force-reinstall\nSTAGE_DIR = '\/tmp\/Mask_RCNN'\n!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git {STAGE_DIR}\nos.chdir(STAGE_DIR)\n#!python setup.py -q install\n!rm .git samples images assets -rf\n!pwd; ls","33dee2fa":"# Import Mask RCNN\nsys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log","c6e9ff1a":"train_dicom_dir = os.path.join(DATA_DIR, 'dicom-images-train')\ntest_dicom_dir = os.path.join(DATA_DIR, 'dicom-images-test')\n\n# count files\n!ls -m {train_dicom_dir} | wc\n!ls -m {test_dicom_dir} | wc","0711bbd3":"# get model with best validation score: https:\/\/www.kaggle.com\/hmendonca\/mask-rcnn-and-coco-transfer-learning-lb-0-155\/\nWEIGHTS_PATH = \"mask_rcnn_pneumonia.h5\"\n!cp \/kaggle\/input\/mask-rcnn*\/pneumonia*\/*0013.h5 {WEIGHTS_PATH}\n!du -sh *.h5","0e3d2606":"# The following parameters have been selected to reduce running time for demonstration purposes \n# These are not optimal\n\nIMAGE_DIM = 512\n\nclass DetectorConfig(Config):    \n    # Give the configuration a recognizable name  \n    NAME = 'Pneumothorax'\n    \n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 11\n    \n    BACKBONE = 'resnet50'\n    \n    NUM_CLASSES = 2  # background and pneumothorax classes\n    \n    IMAGE_MIN_DIM = IMAGE_DIM\n    IMAGE_MAX_DIM = IMAGE_DIM\n    RPN_ANCHOR_SCALES = (32, 64, 128, 256)\n    TRAIN_ROIS_PER_IMAGE = 32\n    MAX_GT_INSTANCES = 15\n    DETECTION_MAX_INSTANCES = 4\n    DETECTION_MIN_CONFIDENCE = 0.90\n    DETECTION_NMS_THRESHOLD = 0.1\n    WEIGHT_DECAY = 0.0005\n\n    STEPS_PER_EPOCH = 20 if debug else 350\n    VALIDATION_STEPS = 10 if debug else 120\n    \n    ## balance out losses\n    LOSS_WEIGHTS = {\n        \"rpn_class_loss\": 12.0,\n        \"rpn_bbox_loss\": 0.6,\n        \"mrcnn_class_loss\": 6.0,\n        \"mrcnn_bbox_loss\": 1.0,\n        \"mrcnn_mask_loss\": 2.4\n    }\n\nconfig = DetectorConfig()\nconfig.display()","829a5fb7":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import get_cmap\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util import montage\nfrom skimage.morphology import binary_opening, disk, label\nimport gc; gc.enable() # memory is tight\n\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n\ndef multi_rle_encode(img, **kwargs):\n    ''' Encode disconnected regions as separated masks\n    '''\n    labels = label(img)\n    if img.ndim > 2:\n        return [rle2mask(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n    else:\n        return [rle2mask(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n\ndef masks_as_image(rle_list, shape):\n    # Take the individual masks and create a single mask array\n    all_masks = np.zeros(shape, dtype=np.uint8)\n    for mask in rle_list:\n        if isinstance(mask, str) and mask != '-1':\n            all_masks |= rle2mask(mask, shape[0], shape[1]).T.astype(bool)\n    return all_masks\n\ndef masks_as_color(rle_list, shape):\n    # Take the individual masks and create a color mask array\n    all_masks = np.zeros(shape, dtype=np.float)\n    scale = lambda x: (len(rle_list)+x+1) \/ (len(rle_list)*2) ## scale the heatmap image to shift \n    for i,mask in enumerate(rle_list):\n        if isinstance(mask, str) and mask != '-1':\n            all_masks[:,:] += scale(i) * rle2mask(mask, shape[0], shape[1]).T\n    return all_masks","f0f693ed":"from PIL import Image\nfrom sklearn.model_selection import train_test_split\n\ntrain_glob = f'{train_dicom_dir}\/*\/*\/*.dcm'\ntest_glob = f'{test_dicom_dir}\/*\/*\/*.dcm'\n\nexclude_list = []\ntrain_names = [f for f in sorted(glob.glob(train_glob)) if f not in exclude_list]\ntest_names = [f for f in sorted(glob.glob(test_glob)) if f not in exclude_list]\n\nprint(len(train_names), len(test_names))\n# print(train_names[0], test_names[0])\n# !ls -l {os.path.join(train_dicom_dir, train_names[0])}","5d67846d":"# training dataset\nSEGMENTATION = DATA_DIR + '\/train-rle.csv'\nanns = pd.read_csv(SEGMENTATION)\nanns.head()","96a155a0":"# get rid of damn space in column name\nanns.columns = ['ImageId', 'EncodedPixels']","174604f6":"# over-sample pneumothorax\npneumothorax_anns = anns[anns.EncodedPixels != ' -1'].ImageId.unique().tolist()\nprint(f'Positive samples: {len(pneumothorax_anns)}\/{len(anns.ImageId.unique())} {100*len(pneumothorax_anns)\/len(anns.ImageId.unique()):.2f}%')","da0e7ba0":"# ## use only pneumothorax images\n# pneumothorax_fps_train = [fp for fp in train_names if fp.split('\/')[-1][:-4] in pneumothorax_anns]\n\n# image_fps_train, image_fps_val = train_test_split(pneumothorax_fps_train, test_size=0.1, random_state=42)\n\n# test_image_fps = test_names\n\n# if debug:\n#     print('DEBUG subsampling from:', len(image_fps_train), len(image_fps_val), len(test_image_fps))\n#     image_fps_train = image_fps_train[:150] \n#     image_fps_val = image_fps_val[:150]\n# #     test_image_fps = test_names[:150]\n    \n# print(len(image_fps_train), len(image_fps_val), len(test_image_fps))","ab225b3a":"## split and rebalance dataset\ntest_size = config.VALIDATION_STEPS * config.IMAGES_PER_GPU\nimage_fps_train, image_fps_val = train_test_split(train_names, test_size=test_size, random_state=42)\ntest_image_fps = test_names\n\npneumothorax_fps_train = [fp for fp in image_fps_train if fp.split('\/')[-1][:-4] in pneumothorax_anns]\n\nif debug:\n    print('DEBUG subsampling from:', len(image_fps_train), len(image_fps_val), len(test_image_fps))\n    image_fps_train = image_fps_train[:100] + pneumothorax_fps_train[:50] \n    image_fps_val = image_fps_val[:150]\n#     test_image_fps = test_names[:150]\nelse:\n    image_fps_train += pneumothorax_fps_train*3  # oversample positive cases\n    random.shuffle(image_fps_train)\n    \nprint(len(image_fps_train), len(image_fps_val), len(test_image_fps))\npos, total = len([fp for fp in image_fps_train if fp in pneumothorax_fps_train]), len(image_fps_train)\nprint(f'Positive samples in training: {pos}\/{total} {100*pos\/total:.2f}%')","b7520a3a":"class DetectorDataset(utils.Dataset):\n    \"\"\"Dataset class for training our dataset.\n    \"\"\"\n\n    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n        super().__init__(self)\n        \n        # Add classes\n        self.add_class('pneumothorax', 1, 'Pneumothorax')\n        \n        # add images \n        for i, fp in enumerate(image_fps):\n            image_id = fp.split('\/')[-1][:-4]\n            annotations = image_annotations.query(f\"ImageId=='{image_id}'\")['EncodedPixels']\n            self.add_image('pneumothorax', image_id=i, path=fp, \n                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n            \n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path']\n\n    def load_image(self, image_id):\n        info = self.image_info[image_id]\n        fp = info['path']\n        ds = pydicom.read_file(fp)\n        image = ds.pixel_array\n        # If grayscale. Convert to RGB for consistency.\n        if len(image.shape) != 3 or image.shape[2] != 3:\n            image = np.stack((image,) * 3, -1)\n        return image\n\n    def load_mask(self, image_id):\n        info = self.image_info[image_id]\n        annotations = info['annotations']\n#         print(image_id, annotations)\n        count = len(annotations)\n        if count == 0 or (count == 1 and annotations.values[0] == ' -1'): # empty annotation\n            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n            class_ids = np.zeros((1,), dtype=np.int32)\n        else:\n            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n            class_ids = np.zeros((count,), dtype=np.int32)\n            for i, a in enumerate(annotations):\n                mask[:, :, i] = rle2mask(a, info['orig_height'], info['orig_width']).T\n                class_ids[i] = 1\n        return mask.astype(np.bool), class_ids.astype(np.int32)","64414afa":"image_fps, image_annotations = train_names, anns","8cad90f2":"ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath \n# image = ds.pixel_array # get image array\nprint(ds)\ndel ds; gc.collect()","3cbdc0aa":"# Original image size: 1024 x 1024\nORIG_SIZE = 1024","d195d3f3":"%%time\n# prepare the training dataset\ndataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\ndataset_train.prepare()","96b2ccc9":"%%time\n# prepare the validation dataset\ndataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\ndataset_val.prepare()","02d7c9b0":"# Load and display random sample and their bounding boxes\n\nclass_ids = [0]\nwhile class_ids[0] == 0:  ## look for a mask\n    image_id = random.choice(dataset_val.image_ids)\n    image_fp = dataset_val.image_reference(image_id)\n    image = dataset_val.load_image(image_id)\n    mask, class_ids = dataset_val.load_mask(image_id)\n\nprint(image.shape)\n\nplt.figure(figsize=(10, 10))\nplt.subplot(1, 2, 1)\nplt.imshow(image)\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nmasked = np.zeros(image.shape[:2])\nfor i in range(mask.shape[2]):\n    masked += image[:, :, 0] * mask[:, :, i]\nplt.imshow(masked, cmap='gray')\nplt.axis('off')\n\nprint(image_fp)\nprint(class_ids)\n\ndel masked","1adb8952":"# Image augmentation (light but constant)\naugmentation = iaa.Sequential([\n    iaa.OneOf([ ## geometric transform\n        iaa.Affine(\n            scale={\"x\": (0.98, 1.02), \"y\": (0.98, 1.04)},\n            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.04, 0.04)},\n            rotate=(-2, 2),\n            shear=(-1, 1),\n        ),\n        iaa.PiecewiseAffine(scale=(0.001, 0.025)),\n    ]),\n    iaa.OneOf([ ## brightness or contrast\n        iaa.Multiply((0.9, 1.1)),\n        iaa.ContrastNormalization((0.9, 1.1)),\n    ]),\n    iaa.OneOf([ ## blur or sharpen\n        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n        iaa.Sharpen(alpha=(0.0, 0.1)),\n    ]),\n])\n\n# test on the same image as above\nimggrid = augmentation.draw_grid(image[:, :, 0], cols=5, rows=2)\nplt.figure(figsize=(30, 12))\n_ = plt.imshow(imggrid[:, :, 0], cmap='gray')\ndel imggrid; del image","16194777":"%%time\n# get pixel statistics\nimage_stats = []\nfor image_id in dataset_val.image_ids[:4]:\n    image = dataset_val.load_image(image_id)\n    image_stats.append(image.mean(axis=(0,1)))\n\nconfig.MEAN_PIXEL = np.mean(image_stats, axis=0).tolist()\n# VAR_PIXEL = images.var()\ndel image; del image_stats\ngc.collect()\n\nprint(config.MEAN_PIXEL)","5f91b1ca":"model = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n\n# load all weights as number of classes matches the pre-trained model\nmodel.load_weights(WEIGHTS_PATH, by_name=True)\n\n# # Exclude the last layers because they require a matching number of classes\n# model.load_weights(WEIGHTS_PATH, by_name=True,\n#                    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])","c5c8ba85":"# Train the Mask-RCNN Model\nLEARNING_RATE = 0.0006","903e61ea":"%%time\n## train heads with higher lr to speedup the learning\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE*2,\n            epochs=1,\n            layers='heads',\n            augmentation=None)  ## no need to augment yet\n\nhistory = model.keras_model.history.history","08c74afb":"%%time\nmodel.train(dataset_train, dataset_val,\n            learning_rate=LEARNING_RATE,\n            epochs=3 if debug else 13,\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model.keras_model.history.history\nfor k in new_history: history[k] = history[k] + new_history[k]","bd54a588":"# %%time\n# model.train(dataset_train, dataset_val,\n#             learning_rate=LEARNING_RATE\/2,\n#             epochs=4 if debug else 18,\n#             layers='all',\n#             augmentation=augmentation)\n\n# new_history = model.keras_model.history.history\n# for k in new_history: history[k] = history[k] + new_history[k]","a6828bdd":"epochs = range(1, len(history['loss'])+1)\npd.DataFrame(history, index=epochs)","cb8441a4":"plt.figure(figsize=(21,11))\n\nplt.subplot(231)\nplt.plot(epochs, history[\"loss\"], label=\"Train loss\")\nplt.plot(epochs, history[\"val_loss\"], label=\"Valid loss\")\nplt.legend()\nplt.subplot(232)\nplt.plot(epochs, history[\"rpn_class_loss\"], label=\"Train RPN class ce\")\nplt.plot(epochs, history[\"val_rpn_class_loss\"], label=\"Valid RPN class ce\")\nplt.legend()\nplt.subplot(233)\nplt.plot(epochs, history[\"rpn_bbox_loss\"], label=\"Train RPN box loss\")\nplt.plot(epochs, history[\"val_rpn_bbox_loss\"], label=\"Valid RPN box loss\")\nplt.legend()\nplt.subplot(234)\nplt.plot(epochs, history[\"mrcnn_class_loss\"], label=\"Train MRCNN class ce\")\nplt.plot(epochs, history[\"val_mrcnn_class_loss\"], label=\"Valid MRCNN class ce\")\nplt.legend()\nplt.subplot(235)\nplt.plot(epochs, history[\"mrcnn_bbox_loss\"], label=\"Train MRCNN box loss\")\nplt.plot(epochs, history[\"val_mrcnn_bbox_loss\"], label=\"Valid MRCNN box loss\")\nplt.legend()\nplt.subplot(236)\nplt.plot(epochs, history[\"mrcnn_mask_loss\"], label=\"Train Mask loss\")\nplt.plot(epochs, history[\"val_mrcnn_mask_loss\"], label=\"Valid Mask loss\")\nplt.legend()\n\nplt.show()","abfa7b37":"best_epoch = np.argmin(history[\"val_loss\"])\nscore = history[\"val_loss\"][best_epoch]\nprint(f'Best Epoch:{best_epoch+1} val_loss:{score}')","9b275d33":"# select trained model \ndir_names = next(os.walk(model.model_dir))[1]\nkey = config.NAME.lower()\ndir_names = filter(lambda f: f.startswith(key), dir_names)\ndir_names = sorted(dir_names)\n\nif not dir_names:\n    import errno\n    raise FileNotFoundError(\n        errno.ENOENT,\n        \"Could not find model directory under {}\".format(self.model_dir))\n\nfps = []\n# Pick last directory\nfor d in dir_names: \n    dir_name = os.path.join(model.model_dir, d)\n    # Find checkpoints\n    checkpoints = next(os.walk(dir_name))[2]\n    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n    checkpoints = sorted(checkpoints)\n    if not checkpoints:\n        raise Exception(f'No weight files in {dir_name}')\n    if best_epoch < len(checkpoints):\n        checkpoint = checkpoints[best_epoch]\n    else:\n        checkpoint = checkpoints[-1]\n    fps.append(os.path.join(dir_name, checkpoint))\n\nmodel_path = sorted(fps)[-1]\nprint('Found model {}'.format(model_path))","988d797e":"class InferenceConfig(DetectorConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# Recreate the model in inference mode\nmodel = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=ROOT_DIR)\n\n# Load trained weights (fill in path to trained weights here)\nassert model_path != \"\", \"Provide path to trained weights\"\nprint(\"Loading weights from \", model_path)\nmodel.load_weights(model_path, by_name=True)","fd613de6":"# set color for class\ndef get_colors_for_class_ids(class_ids):\n    colors = []\n    for class_id in class_ids:\n        if class_id == 1:\n            colors.append((.941, .204, .204))\n    return colors","67b83ed1":"# Show few example of ground truth vs. predictions on the validation dataset \ndataset = dataset_val\npneumothorax_ids_val = [fp.split('\/')[-1][:-4] for fp in image_fps_val]\npneumothorax_ids_val = [i for i,id in enumerate(pneumothorax_ids_val) if id in pneumothorax_anns]\nfig = plt.figure(figsize=(10, 40))\n\nfor i in range(8):\n    image_id = random.choice(pneumothorax_ids_val)\n    \n    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n        modellib.load_image_gt(dataset_val, inference_config, \n                               image_id, use_mini_mask=False)\n    \n#     print(original_image.shape)\n    plt.subplot(8, 2, 2*i + 1)\n    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n                                dataset.class_names,\n                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n    \n    plt.subplot(8, 2, 2*i + 2)\n    results = model.detect([original_image]) #, verbose=1)\n    r = results[0]\n    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n                                dataset.class_names, r['scores'], \n                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])","73698039":"# Show stats of all trainable weights    \nvisualize.display_weight_stats(model)\n### Click to expand output","01ef7c0c":"# from https:\/\/github.com\/matterport\/Mask_RCNN\/blob\/master\/samples\/coco\/inspect_weights.ipynb\n# Pick layer types to display\nLAYER_TYPES = ['Conv2D', 'Dense', 'Conv2DTranspose']\n# Get layers\nlayers = model.get_trainable_layers()\nlayers = list(filter(lambda l: l.__class__.__name__ in LAYER_TYPES, \n                     layers))\n# Display Histograms\nfig, ax = plt.subplots(len(layers), 2, figsize=(10, 3*len(layers)), gridspec_kw={\"hspace\":1})\nfor l, layer in enumerate(layers):\n    weights = layer.get_weights()\n    for w, weight in enumerate(weights):\n        tensor = layer.weights[w]\n        ax[l, w].set_title(f'Layer:{l}.{w} {tensor.name}')\n        _ = ax[l, w].hist(weight[w].flatten(), 50)","41ccb380":"# Make predictions on test images, write out submission file\ndef predict(image_fps, filepath='submission.csv', min_conf=0.97):\n    # assume square image\n    resize_factor = ORIG_SIZE \/ config.IMAGE_SHAPE[0]\n    with open(filepath, 'w') as file:\n        file.write(\"ImageId,EncodedPixels\\n\")\n\n        for fp in tqdm_notebook(image_fps):\n            image_id = fp.split('\/')[-1][:-4]\n            maks_written = 0\n            \n            ds = pydicom.read_file(fp)\n            image = ds.pixel_array\n            # If grayscale. Convert to RGB for consistency.\n            if len(image.shape) != 3 or image.shape[2] != 3:\n                image = np.stack((image,) * 3, -1)\n            image, window, scale, padding, crop = utils.resize_image(\n                image,\n                min_dim=config.IMAGE_MIN_DIM,\n                min_scale=config.IMAGE_MIN_SCALE,\n                max_dim=config.IMAGE_MAX_DIM,\n                mode=config.IMAGE_RESIZE_MODE)\n\n            results = model.detect([image])\n            r = results[0]\n\n#             assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n            num_instances = len(r['rois'])\n\n            for i in range(num_instances):\n                if r['scores'][i] > min_conf and np.sum(r['masks'][...,i]) > 1:\n                    mask = r['masks'][...,i].T*255\n                    mask, _,_,_,_ = utils.resize_image(\n                        np.stack((mask,) * 3, -1), # requires 3 channels\n                        min_dim=ORIG_SIZE,\n                        min_scale=config.IMAGE_MIN_SCALE,\n                        max_dim=ORIG_SIZE,\n                        mode=config.IMAGE_RESIZE_MODE)\n                    mask = (mask[...,0] > 0)*255\n#                     print(mask.shape)\n#                     plt.imshow(mask, cmap=get_cmap('jet'))\n                    file.write(image_id + \",\" + mask2rle(mask, ORIG_SIZE, ORIG_SIZE) + \"\\n\")\n                    maks_written += 1\n\n            if maks_written == 0:\n                file.write(image_id + \",-1\\n\")  ## no pneumothorax","fbf7ea9d":"submission_fp = os.path.join(ROOT_DIR, 'submission.csv')\npredict(test_image_fps, filepath=submission_fp)\nprint(submission_fp)","d9bbc9d4":"sub = pd.read_csv(submission_fp, dtype={'ImageId':str, 'EncodedPixels':str})\nprint((sub.EncodedPixels != '-1').sum(), sub.ImageId.size, sub.ImageId.nunique())\nprint(sub.EncodedPixels.nunique(), (sub.EncodedPixels != '-1').sum()\/sub.ImageId.nunique())\n\nprint('Unique samples:\\n', sub.EncodedPixels.drop_duplicates()[:6])\nsub.head(10)","dc1f5763":"# show a few test image detection example\ndef visualize_test():\n    ids_with_mask = sub[sub.EncodedPixels != '-1'].ImageId.values\n    fp = random.choice([fp for fp in test_image_fps if fp.split('\/')[-1][:-4] in ids_with_mask])\n#     import pdb; pdb.set_trace()\n    \n    # original image\n    image_id = fp.split('\/')[-1][:-4]\n    ds = pydicom.read_file(fp)\n    image = ds.pixel_array\n    \n    # If grayscale. Convert to RGB for consistency.\n    if len(image.shape) != 3 or image.shape[2] != 3:\n        image = np.stack((image,) * 3, -1)\n    \n    # assume square image \n    resize_factor = 1 ## ORIG_SIZE \/ config.IMAGE_SHAPE[0]\n\n    # Detect on full size test images (without resizing)\n    results = model.detect([image])\n    r = results[0]\n    for bbox in r['rois']: \n#         print(bbox)\n        x1 = int(bbox[1] * resize_factor)\n        y1 = int(bbox[0] * resize_factor)\n        x2 = int(bbox[3] * resize_factor)\n        y2 = int(bbox[2]  * resize_factor)\n        cv2.rectangle(image, (x1,y1), (x2,y2), (77, 255, 9), 3, 1)\n        width = x2 - x1\n        height = y2 - y1\n#         print(\"x {} y {} h {} w {}\".format(x1, y1, width, height))\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n    ax1.set_title(image_id)\n    ax1.imshow(image)\n    ax2.set_title(f\"{len(r['rois'])} masks predicted again\")\n    if len(r['rois']) > 0:\n        ax2.imshow(r['masks'].max(-1))  # get max (overlap) between all masks in this prediction\n    ax3.set_title(f\"{np.count_nonzero(image_id == ids_with_mask)} masks in csv\")\n    ax3.imshow(masks_as_color(sub.query(f\"ImageId=='{image_id}'\")['EncodedPixels'].values, (ORIG_SIZE, ORIG_SIZE)))\n#     print(f\"ImageId=='{image_id}'\", sub.query(f\"ImageId=='{image_id}'\")['EncodedPixels'])\n\nfor i in range(8):\n    visualize_test()","f7751142":"os.chdir(ROOT_DIR)\n!ls *","bbd57935":"# remove files to allow committing (hit files limit otherwise)\n!rm -rf {STAGE_DIR}  \/kaggle\/working\/*\/events*","b239e5b6":"## Display a random image with bounding boxes","a25d2ae0":"## Setup Mask-RCNN\n\n- dicom_fps is a list of the dicom image path and filenames \n- image_annotions is a dictionary of the annotations keyed by the filenames\n- parsing the dataset returns a list of the image filenames and the annotations dictionary","933e3e0f":"## Basic Model Weigths Analysis","8534cf38":"## Training\nNow it's time to train the model. Note that training even a basic model can take a few hours. \n\nNote: the following model is for demonstration purpose only. We have limited the training to a few epochs, and have set nominal values for the Detector Configuration to reduce run-time. \n\n- dataset_train and dataset_val are derived from DetectorDataset \n- DetectorDataset loads images from image filenames and  masks from the annotation data\n- model is Mask-RCNN","7135a660":"## Final steps\nCreate the submission file","2ed2072d":"### Load Pneumonia pre-trained weights","e58d3434":"**Mask-RCNN Starter Model for the SIIM-ACR Pneumothorax Segmentation with transfer learning **\n\nThis kernel uses pre-trained weights from a past medical imaging competition on pneumonia identification: https:\/\/www.kaggle.com\/hmendonca\/mask-rcnn-and-coco-transfer-learning-lb-0-155\n\nBasic ideas included here:\n* dataset distribution balancing\n* image augmentation\n* multi-stage training for transfer learning, and model weights analysis\n* multi-mask prediction for submission\n\nIf you please, upvote and leave questions or constructive feedback below (for me and other kagglers learning).\nCheers!","65b2e8d0":"## Install Matterport's Mask-RCNN\nA very popular model in github.\nSee the [Matterport's implementation of Mask-RCNN](https:\/\/github.com\/matterport\/Mask_RCNN).","4d56851e":"## Image Augmentation\nTry finetuning some variables to custom values","92b02dd9":"## Examine the annotation data\n..., parse the dataset, and view dicom fields","fb747b0b":"## Validation\nHow does the predicted box compared to the expected value? Let's use the validation dataset to check. ","25e164b7":"## Create and prepare the training dataset"}}