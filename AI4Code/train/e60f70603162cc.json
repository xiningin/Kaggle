{"cell_type":{"06efb525":"code","528f675f":"code","27647799":"code","af0bb894":"code","97e83868":"code","987f4253":"code","29c6402b":"code","7641762a":"code","28c05f97":"code","b2ee92ff":"code","e822f330":"code","04a982f3":"code","e9e13432":"code","75cdd09b":"code","f0704ebf":"code","141f17ad":"code","ed64fb4a":"code","a0a7c324":"code","6d0686e5":"code","248b1f37":"code","d5b37936":"code","2bfbb72d":"code","9fe0b368":"code","eaf70e4e":"code","81560145":"code","199ce43c":"code","3301e899":"code","0a1be714":"code","660fae8a":"code","4c7ed1e4":"code","96e3f749":"code","12f58752":"code","ff77214d":"markdown","aa9a3e6f":"markdown","d552904e":"markdown","f57bc271":"markdown","c7611226":"markdown","2f42ab75":"markdown","d99d925b":"markdown","1f26872b":"markdown","6e904220":"markdown","56583f43":"markdown"},"source":{"06efb525":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n### Graphic libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","528f675f":"df_train =pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/train.csv\")","27647799":"df_train.head()","af0bb894":"df_train.info()","97e83868":"df_train.isna().sum()","987f4253":"df_train.describe()","29c6402b":"df_test=pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/test.csv\")","7641762a":"df_test.head()","28c05f97":"df_test.isnull().sum()\n","b2ee92ff":"df_train.shape","e822f330":"df_train[\"target\"].hist(bins=40, edgecolor='y', linewidth=1.0,\n              xlabelsize=8, ylabelsize=8, grid=False, figsize=(6,2), color='green')    \nplt.tight_layout(rect=(0, 0, 1.2, 1.2))   \nplt.suptitle('Target Plot', x=0.65, y=1.25, fontsize=14); ","04a982f3":"sns.boxplot('target', data = df_train)","e9e13432":"sns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(df_train['target'], color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","75cdd09b":"#data = pd.concat([_train['target'], train['OverallQual']], axis=1)\ncorrelation_train=df_train.corr()\nsns.set(font_scale=2)\nplt.figure(figsize = (35,35))\nax = sns.heatmap(correlation_train, annot=True,annot_kws={\"size\": 30},fmt='.1f',cmap='PiYG', linewidths=.5)","f0704ebf":"#plotting correlations\nnum_feat=df_train.columns[df_train.dtypes!=object]\nnum_feat=num_feat[1:-1] \nlabels = []\nvalues = []\nfor col in num_feat:\n    labels.append(col)\n    values.append(np.corrcoef(df_train[col].values, df_train.target.values)[0,1])\n    \nind = np.arange(len(labels))\nwidth = 0.2\nfig, ax = plt.subplots(figsize=(10,10))\nrects = ax.barh(ind, np.array(values), color='green')\nax.set_yticks(ind+((width)\/2.))\nax.set_yticklabels(labels, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation Coefficients w.r.t TArget\");","141f17ad":"df_train.columns","ed64fb4a":"x = df_train.iloc[:, 1:15].values  \nprint(x) \ny = df_train.iloc[:, -1].values ","a0a7c324":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.025, random_state=1)","6d0686e5":"# Feature Scaling\n#from sklearn.preprocessing import StandardScaler\n\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)","248b1f37":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics","d5b37936":"#from xgboost import XGBRegressor\nimport lightgbm as ltb","2bfbb72d":"\n#ltb_r = ltb.LGBMRegressor()\n\nltb_r = ltb.LGBMRegressor(boosting_type= 'gbdt', #'rf', #'goss',#'dart', #\n                         num_leaves=31, \n                         max_depth= 11, #12, #16, #- 1, \n                         learning_rate=0.1, \n                         n_estimators=1000, #500, \n                         subsample_for_bin=200000, \n                         objective=None, \n                         class_weight=None, \n                         min_split_gain=0.0, \n                         min_child_weight=0.001, \n                         min_child_samples=20, \n                         subsample=1.0, \n                         subsample_freq=0, \n                         colsample_bytree=1.0, \n                         reg_alpha=0.0, \n                         reg_lambda=0.0, \n                         random_state=None, \n                         n_jobs=- 1, \n                         silent=True\n                        )\n\nltb_r.fit(X_train,y_train)","9fe0b368":"y_pred= ltb_r.predict(X_train)","eaf70e4e":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_train, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, y_pred)))","81560145":"y_pred = ltb_r.predict(X_test)","199ce43c":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","3301e899":"#X_t = sc.transform(df_test[:,1:])","0a1be714":"# Make prediction for submission using best_estimators from grid search.\npreds = ltb_r.predict(df_test.iloc[:,1:].values)\n#preds=XGB.predict(df_test.iloc[:,1:].values)","660fae8a":"sub=pd.read_csv(\"..\/input\/tabular-playground-series-jan-2021\/sample_submission.csv\")","4c7ed1e4":"sub.head()","96e3f749":"sub.target =preds\nsub.to_csv(\"submission.csv\", index=False)","12f58752":"sub.head()","ff77214d":"## Prepare predictions for submission.csv","aa9a3e6f":"## Split data for training & validation","d552904e":"## Loading train and test data sets","f57bc271":"## EDA\n\n","c7611226":"Correlations","2f42ab75":"Some columns have little negative correlation with target variable.\n\nThese can prove to be important features to predict target.","d99d925b":"Data is clean with continues target variable. let's make split into 70:20 train and validation data. and drop id column. ","1f26872b":"Now let's check test data.","6e904220":"Storing values in numpy array saves memory.","56583f43":"### LGB regressor"}}