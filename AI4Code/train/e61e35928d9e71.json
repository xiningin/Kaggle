{"cell_type":{"7a077969":"code","f19af460":"code","a8dded79":"code","f1bfa298":"code","ab83babf":"code","8b45b7d5":"code","763ef7a8":"code","a42db25c":"code","f15fae31":"code","b940b540":"code","303c6624":"code","917e0215":"code","9725f99f":"code","89858d8b":"code","801d7142":"code","2bb7a3ce":"code","6e2d269b":"code","53b99acf":"code","7f94e88e":"code","709f2570":"code","66d028fe":"code","caed17c0":"code","fcb38c75":"code","ce9ff291":"code","f961ff01":"code","0f51971e":"code","2528cc9c":"code","a83221ce":"code","fb016779":"code","33cf25da":"code","741e011c":"code","f48611ad":"code","10069c3a":"code","1d5fbd05":"code","a0e18491":"markdown","3cd9fe71":"markdown","5c4594b9":"markdown","64125695":"markdown","0a2b6fb7":"markdown","bfb866fd":"markdown","b25970b8":"markdown","c4685fc4":"markdown","6d6df8d9":"markdown","2eb1f325":"markdown","1d6b16da":"markdown","02a6a142":"markdown","3e96368d":"markdown","485d2492":"markdown","7206fb99":"markdown","04635710":"markdown","8bf9e318":"markdown","20a34342":"markdown","10a9215f":"markdown","73e6f680":"markdown","7d5c055a":"markdown","f94b865f":"markdown","26643194":"markdown"},"source":{"7a077969":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f19af460":"train= pd.read_csv('..\/input\/titanic\/train.csv',index_col='PassengerId')\ntest= pd.read_csv('..\/input\/titanic\/test.csv' ,index_col='PassengerId')","a8dded79":"train= pd.concat([train, test])","f1bfa298":"train","ab83babf":"train.isnull().sum()","8b45b7d5":"train['Age'].fillna((train['Age'].mean()), inplace=True) ","763ef7a8":"train.drop('Cabin', inplace=True, axis=1)","a42db25c":"train['Family_name']=train['Name'].str.split(', ').str[0]\ntrain","f15fae31":"train['Title']=train['Name'].str.split(', ').str[1].str.split('.').str[0]\ntrain['Title'].unique()","b940b540":"train['Title'] =train['Title'].replace(['Ms','Mlle'], 'Miss')\ntrain['Title'] = train['Title'].replace(['Mme','Dona','the Countess','Lady'], 'Mrs')\ntrain['Title'] =train['Title'].replace(['Rev','Mlle','Jonkheer','Dr','Capt','Don','Col','Major','Sir'], 'Mr')","303c6624":"cleanup_nums = { \"Title\": {\"Mr\": 0, \"Mrs\": 1, \"Miss\": 2, \"Master\": 3 } }\ntrain.replace(cleanup_nums, inplace=True)","917e0215":"train['FamilySize']= train['SibSp']+train['Parch']+1\ntrain","9725f99f":"bins = [0, 2, 18, 35, 65, np.inf]\nnames = ['<2', '2-18', '18-35', '35-65', '65+']\n\ntrain['AgeRange'] = pd.cut(train['Age'], bins, labels=names)\n\nNumberedAgeCategories = {'<2':0 , '2-18':1, '18-35':2, '35-65':3, '65+':4}\ntrain['AgeRange']=train['AgeRange'].map(NumberedAgeCategories)  \ntrain['AgeRange']=pd.to_numeric(train['AgeRange'])\ntrain","89858d8b":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import ExtraTreesClassifier","801d7142":"train.info()","2bb7a3ce":"def LabelEncoder_(data):\n    label_encoder = LabelEncoder()\n    for col in data.columns[data.dtypes == \"object\"]:\n        data[col] = label_encoder.fit_transform(data[col].astype('str'))\n    return data","6e2d269b":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n\ntrain= LabelEncoder_(train)\n\n# drop rows with null values    \ntrain.dropna(inplace=True)\n\n\n# training data\nX = train.drop('Survived', axis=1)\ny = train['Survived']\n\n\n#splitting dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","53b99acf":"clf = LogisticRegression(max_iter=100000,random_state=0).fit(X_train,y_train)\nclf.score(X_test,y_test)","7f94e88e":"clf = DecisionTreeClassifier(random_state=0, max_depth= 7).fit(X_train,y_train)\nclf.score(X_test,y_test)","709f2570":"clf = RandomForestClassifier(random_state=0,max_depth= 7).fit(X_train,y_train)\nclf.score(X_test,y_test)","66d028fe":"clf =  XGBClassifier(random_state=0,eval_metric='mlogloss', use_label_encoder=False, objective='binary:logistic').fit(X_train,y_train)\nclf.score(X_test,y_test)","caed17c0":"clf =  ExtraTreesClassifier(random_state=0, max_depth= 7).fit(X,y)\nclf.score(X_test,y_test)","fcb38c75":"ExtraTrees_clf= ExtraTreesClassifier(random_state=0, max_depth= 7)","ce9ff291":"from sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.decomposition import PCA","f961ff01":"scaler = preprocessing.StandardScaler().fit(X_train)\nX_train_transformed = scaler.transform(X_train)\nclf =  ExtraTrees_clf.fit(X_train_transformed, y_train)\n\nX_test_transformed = scaler.transform(X_test)\nclf.score(X_test_transformed, y_test)","0f51971e":"data_after_pipeline = make_pipeline(preprocessing.StandardScaler(), ExtraTrees_clf)","2528cc9c":"scores = cross_val_score(data_after_pipeline, X,y, cv=5)\nscores","a83221ce":"scores.mean()","fb016779":"arr= dict(zip(X_train.columns, ExtraTrees_clf.feature_importances_)) ## this is used to write the feature name next to the probability\ndata= pd.DataFrame.from_dict(arr,orient='index', columns=['importance'])\ndata.sort_values(['importance'], ascending=False, inplace=True)","33cf25da":"data.plot.bar(y=\"importance\", rot=70, title=\"Extra Trees Features with their corresponding importance values\")","741e011c":"ExtraTrees_clf_temp =  ExtraTreesClassifier(random_state=0, max_depth= 7).fit(X_train,y_train)\nExtraTrees_clf_temp.score(X_test,y_test)","f48611ad":"ExtraTrees_clf= ExtraTreesClassifier(random_state=0)","10069c3a":"params = {\"max_depth\": [3,7,8], \"n_estimators\": [100,150,200], \"criterion\":['gini', 'entropy'], \"min_samples_split\":[2,3,4,5,6]}\ngrid_clf_acc = GridSearchCV(ExtraTrees_clf, param_grid=params, scoring = None)\ngrid_clf_acc.fit(X, y) \n\nprint('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\nprint('Grid best score: (CV score=%0.3f) ' % grid_clf_acc.best_score_)","1d5fbd05":"pipe = Pipeline(steps=[('StandardScaler', preprocessing.StandardScaler()),('pca', PCA()), ('ExtraTrees', ExtraTrees_clf)])\n\nparam_grid = {'ExtraTrees__max_depth': [3,7],\n              'ExtraTrees__min_samples_leaf': [1,2],\n              'ExtraTrees__criterion': [\"gini\", \"entropy\"],'pca__n_components': [5]}\n\nsearch = GridSearchCV(pipe, param_grid, scoring=None)\nsearch.fit(X, y)\nprint(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\nprint(search.best_params_)","a0e18491":"Manual Label Encoding ","3cd9fe71":"Models to be tested: <br\/>\n1- Logistic Regression <br\/>\n2- Decision Trees","5c4594b9":"Extracting Family Name from 'Name' column","64125695":"# Checking for Null Values","0a2b6fb7":"Minimizing the number of unique values in 'Title' column by grouping similar terms (assigning similar terms to a single category)","bfb866fd":"Binning the age column into categories ","b25970b8":"**Without cross-validation:**","c4685fc4":"This is the accuracy score without applying cv so it is unlikely to be a reliable result. ","6d6df8d9":"**With cross-validation:**","2eb1f325":"# Ensemble Methods","1d6b16da":"Deriving the size of the family based on 'SibSp' and 'Parch' columns","02a6a142":"# Feature Engineering","3e96368d":"# Algorithm Tuning using GridSearchCV","485d2492":"Check this for more feature selection techniques: https:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/feature-selection-techniques-in-machine-learning\/\n","7206fb99":"# Testing Multiple Models","04635710":"PCA is not a good fit in this case, so we might disregard using it for this dataset.","8bf9e318":"# Cross Validation","20a34342":"**GridSearch with pipelining:**","10a9215f":"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.ExtraTreesClassifier.html","73e6f680":"**GridSeachCV**","7d5c055a":"# Feature Selection after model training","f94b865f":"Extracting Title from 'Name' column","26643194":"3- Random Forest <br\/>\n4- XGBoost<br\/>\n5- Extra Trees <br\/>"}}