{"cell_type":{"2d17f198":"code","5bd9b079":"code","e588dd9b":"code","a3441cce":"code","2a96a468":"code","4da90ef9":"code","fbb33e09":"code","26132ce1":"code","b670f89f":"code","f0130587":"code","26fb52bb":"code","fac2da65":"code","5f5dcf90":"code","07b6e35e":"code","aeb8dcc8":"code","b2057a94":"code","6b1a499d":"code","9172e3fa":"code","645056e2":"code","4d62556f":"code","956c9a6d":"code","95f1aad9":"code","ba6fc0ee":"code","9320804a":"code","3dbaaee9":"code","c56e6dc0":"code","b4b2f3a4":"markdown","62128dac":"markdown","307bf903":"markdown","79cc8277":"markdown","146ff1fb":"markdown","ae4ce2ef":"markdown","d18bfa3b":"markdown","f7b59953":"markdown"},"source":{"2d17f198":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport statsmodels.api as sm\nfrom pylab import rcParams\nfrom sklearn.metrics import mean_absolute_error\n\nimport warnings\nwarnings.filterwarnings('ignore')","5bd9b079":"df = pd.read_csv(\"..\/input\/grocery-sales-forecast\/train.csv\")\ndf.head()","e588dd9b":"def get_stats(df):\n    print(\"Info:\")\n    print(df.info())\n    print(\"Describe num:\")\n    print(df.describe())\n    print(\"Describe date:\")\n    print(df.date.describe())\n    print(\"Unique values:\")\n    print([(col, df[col].nunique()) for col in df.columns])","a3441cce":"df.date = df.date.astype('datetime64')","2a96a468":"get_stats(df)","4da90ef9":"df_train  = df.drop(columns=['id'])\ndf_train.sort_values(by='date', ignore_index=True, inplace=True)\ndf_train.head()","fbb33e09":"plt.figure(figsize=(10,5))\nwh0 = df_train.where(df_train.warehouse_id == 0).groupby('date')['quantity'].sum()\nwh0.plot(label='wareh0')\nwh1 = df_train.where(df_train.warehouse_id == 1).groupby('date')['quantity'].sum()\nwh1.plot(label='wareh1')\nplt.legend()\n_ = _","26132ce1":"rcParams['figure.figsize'] = 12, 7\nresult0 = sm.tsa.seasonal_decompose(wh0, model='addictive')\n_ = result0.plot()","b670f89f":"result1 = sm.tsa.seasonal_decompose(wh1, model='addictive')\n_ = result1.plot()","f0130587":"fig = plt.figure(figsize=(20, 5))\nax1 = fig.add_subplot(121)\nax1.set_title(\"wareh0\")\nproducts0 = df_train.where(df_train.warehouse_id == 0).groupby('product_id')['quantity'].median()\nproducts0.plot(label='prd0', ax=ax1)\n\nax2 = fig.add_subplot(122)\nax2.set_title(\"wareh1\")\nproducts1 = df_train.where(df_train.warehouse_id == 1).groupby('product_id')['quantity'].median()\nproducts1.plot(label='prd1', ax=ax2)\n_ = _","26fb52bb":"tmp = df_train.copy()\nfor date in tmp.date.unique():\n    tmp[f'{np.datetime_as_string(date, unit=\"D\")}'] = (tmp.date == date).astype(int) * tmp.quantity\n    \ntrain = tmp.groupby(['warehouse_id', 'product_id'])[[f'{np.datetime_as_string(date, unit=\"D\")}' for date in tmp.date.unique()]].sum()\ntrain","fac2da65":"from sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_absolute_error","5f5dcf90":"n_split = 5\ntest_size = 7 # one week\nkf = TimeSeriesSplit(n_splits=n_split, test_size=test_size)","07b6e35e":"def predict_median(train, test, k):\n    train = train.to_numpy()\n    train = train[-k * test_size:]\n    return pd.Series([np.floor(np.median(train[j::test_size])) for j in range(test_size)], index=test.index)\n\ndef predict_mean(train, test, k):\n    train = train.to_numpy()\n    train = train[-k * test_size:]\n    return pd.Series([np.floor(np.mean(train[j::test_size])) for j in range(test_size)], index=test.index)","aeb8dcc8":"scores = {\n    \"mean\": [],\n    \"median\": [],\n}\npredict = {\n    \"mean\": predict_mean,\n    \"median\": predict_median,\n}\nk_grid = range(1, 19)\n\nfor k in k_grid:\n    k_scores = {key: [] for key in scores}\n    for idx, row in train.iterrows():\n        row_score = {key: [] for key in k_scores}\n        for train_idx, val_idx in kf.split(row.to_numpy()):\n            x_train = row.iloc[train_idx]\n            x_val = row.iloc[val_idx]\n\n            for key in row_score:\n                x_pred = predict[key](x_train, x_val, k)\n                score = mean_absolute_error(x_val, x_pred)\n                row_score[key].append(score)\n\n        for key in k_scores:\n            k_scores[key].append((idx, np.mean(row_score[key]), np.std(row_score[key]), np.max(row_score[key]), np.min(row_score[key])))\n    print(\"With k:\", k)\n    for key in scores:\n        print(key, *[np.mean([score[j] for score in k_scores[key]]) for j in range(1, 5)])\n        scores[key].append(np.mean([score[1] for score in k_scores[key]]))\n\nfor key in scores:\n    print(key, np.min(scores[key]), np.argmin(scores[key]) + 1)","b2057a94":"fig = plt.figure(figsize=(7,7))\nax = fig.add_subplot(111)\n\nfor key in scores:\n    ax.plot(k_grid, scores[key], alpha=0.7, label=key)\nax.legend()\nax.set_title(\"\u0413\u0430\u0434\u0430\u043d\u0438\u0435 \u0441\u043a\u043e\u043b\u044c\u0437\u044f\u0449\u0438\u043c \u0441\u0440\u0435\u0434\u043d\u0438\u043c\/\u043c\u0435\u0434\u0438\u0430\u043d\u043e\u0439\")\nax.set_xticks(k_grid)\n_ = _","6b1a499d":"scores = {\n    \"mean\": [],\n    \"median\": [],\n    \"mix\": [],\n}\npredict = {\n    \"mean\": predict_mean,\n    \"median\": predict_median,\n}\nk_param = {\n    \"mean\": 15,\n    \"median\": 12,\n}\nmix_mask = {}\n\nfor idx, row in train.iterrows():\n    row_score = {key: [] for key in k_param}\n    for train_idx, val_idx in kf.split(row.to_numpy()):\n        x_train = row.iloc[train_idx]\n        x_val = row.iloc[val_idx]\n\n        for key in row_score:\n            x_pred = predict[key](x_train, x_val, k_param[key])\n            score = mean_absolute_error(x_val, x_pred)\n            row_score[key].append(score)\n\n    for key in k_param:\n        scores[key].append((idx, np.mean(row_score[key])))\n    scores[\"mix\"].append(min((scores[\"mean\"][-1], scores[\"median\"][-1]), key=lambda x: x[1]))\n    mix_mask[idx] = scores[\"mean\"][-1] == scores[\"mix\"][-1]\n\npure_score = dict()\nfor key in scores:\n    print(key, np.mean([score[1] for score in scores[key]]))\n    pure_score[key] = [score[1] for score in scores[key]]\nprint(sum(mix_mask.values()), len(mix_mask.values()) - sum(mix_mask.values()))","9172e3fa":"fig = plt.figure(figsize=(7,7))\nax = fig.add_subplot(111)\n\nfor key in scores:\n    ax.plot(pure_score[key], alpha=0.7, label=key)\nax.legend()\nax.set_title(\"\u0413\u0430\u0434\u0430\u043d\u0438\u0435 \u0431\u043b\u0435\u043d\u0434\u0438\u043d\u0433\u043e\u043c \u0441\u043a\u043e\u043b\u044c\u0437\u044f\u0449\u043e\u0433\u043e \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e\/\u043c\u0435\u0434\u0438\u0430\u043d\u044b\")\n_ = _","645056e2":"df_test = pd.read_csv(\"..\/input\/grocery-sales-forecast\/test.csv\")","4d62556f":"df_test.head()","956c9a6d":"get_stats(df_test)","95f1aad9":"tmp = train.copy()\nshifts = [\"2021-04-09\", \"2021-04-10\", \"2021-04-11\", \"2021-04-12\",\"2021-04-13\", \"2021-04-14\", \"2021-04-15\"]\nfor shift in shifts:\n    tmp[shift] = 0\ntmp","ba6fc0ee":"for idx, row in tmp.iterrows():\n    x_train = row.iloc[:-test_size]\n    x_test = row.iloc[-test_size:]\n    x_pred = predict_mean(x_train, x_test, 15) if mix_mask[idx] else predict_median(x_train, x_test, 12)\n    tmp.loc[idx, x_pred.index] = x_pred\ntmp","9320804a":"test = df_test.merge(tmp, how='left', left_on=['warehouse_id', 'product_id'], right_index=True, suffixes=('',''))\ntest['quantity'] = test.apply(lambda x: x[x['date']], axis=1)\ntest.head()","3dbaaee9":"submission = test[['id', 'quantity']]\nsubmission['quantity'] = submission['quantity'].fillna(0).astype('int')\nsubmission.head()","c56e6dc0":"submission.to_csv(\".\/baseline3.csv\", index=False)","b4b2f3a4":"#### \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435","62128dac":"\u041d\u0430\u0447\u043d\u0451\u043c \u0441 \u043f\u0440\u043e\u0441\u0442\u043e\u0433\u043e: \u0431\u0443\u0434\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043d\u0435\u0434\u0435\u043b\u044c. \u0427\u0438\u0441\u043b\u043e \u043d\u0435\u0434\u0435\u043b\u044c \u0431\u0443\u0434\u0435\u043c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u043c. \u0421\u0440\u0430\u0432\u043d\u0438\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0434\u043b\u044f \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0438 \u043c\u0435\u0434\u0438\u0430\u043d\u044b.","307bf903":"## \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u043d\u0430 test","79cc8277":"\u0421\u0440\u0430\u0432\u043d\u0438\u043c \u043b\u0443\u0447\u0448\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0438 \u043c\u0435\u0434\u0438\u0430\u043d\u044b. \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0441\u043c\u0435\u0448\u0430\u0442\u044c \u0438\u0445 \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u0441\u044f \u043b\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e. ","146ff1fb":"## Submit","ae4ce2ef":"## \u0413\u0430\u0434\u0430\u0435\u043c \u043d\u0430 validation","d18bfa3b":"## \u0421\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 train","f7b59953":"\u041d\u0430 \u043f\u0435\u0440\u0432\u044b\u0439 \u0432\u0437\u0433\u043b\u044f\u0434 \u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0432 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435\u0442.\n\n- `id` - \u044d\u0442\u043e \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0441\u0442\u0440\u043e\u043a\u0438.\n\n\u041d\u0435\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0435\u043d\u0438\u0435: \u0441\u0442\u0440\u043e\u043a 78067, \u043d\u043e `id` \u0438\u0437 \u0438\u043d\u0442\u0435\u0440\u0432\u0430\u043b\u0430 [0,83158]. \u0412 \u043b\u044e\u0431\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, \u043a\u0430\u0436\u0435\u0442\u0441\u044f \u043e\u043d \u043d\u0430\u043c \u043d\u0435 \u043d\u0443\u0436\u0435\u043d.\n\n- `warehouse_id` - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u0430.\n- `product_id` - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0442\u043e\u0432\u0430\u0440\u0430.\n\n\u042d\u0442\u0430 \u043f\u0430\u0440\u0430 - \u043e\u0431\u044a\u0435\u043a\u0442 \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c.\n\n- `date` - \u0434\u0430\u0442\u0430.\n\n\u041f\u043e \u044d\u0442\u043e\u043c\u0443 \u043f\u043e\u043b\u044e \u0438 \u0441\u0442\u0440\u043e\u0438\u0442\u0441\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0440\u044f\u0434 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430.\n\n- `quantity` - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0442\u043e\u0432\u0430\u0440\u0430.\n\n\u041d\u0430\u0448 target."}}