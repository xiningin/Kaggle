{"cell_type":{"af1c1d90":"code","bbd920a4":"code","de1aacf8":"code","a7e9247a":"code","9d64bc59":"code","bcec4a44":"code","b6f29f69":"code","fedff6b3":"markdown","a965a4bc":"markdown","252c1c4d":"markdown","167ade9d":"markdown","4ee3464f":"markdown","59944302":"markdown"},"source":{"af1c1d90":"import io\nimport requests\nimport tempfile\nfrom IPython.display import Image as IpythonImage\nimport ipywidgets as wg\nfrom PIL import Image as PillowImage\nfrom PIL import ImageDraw,ImagePath,ImageFont\n\nfrom google.cloud import vision\n\n# Client instance\nclient = vision.ImageAnnotatorClient()","bbd920a4":"# Download a random image in 600x400 size and process with Vision API\nimage_url = \"https:\/\/picsum.photos\/600\/400\"\nwith tempfile.TemporaryFile() as tmpfile:\n    # Download and store image in a temporary file\n    img_data = requests.get(image_url).content\n    tmpfile.write(img_data)\n    tmpfile.seek(0)\n    content = tmpfile.read()\n    print(\"Downloaded random image:\")\n    display(IpythonImage(data=content))\n    image = vision.Image(content=content)\n    %time response = client.web_detection(image=image)\n\n    if response.error.message:\n        raise Exception(\n            '{}\\nFor more info on error messages, check: '\n            'https:\/\/cloud.google.com\/apis\/design\/errors'.format(\n                response.error.message))","de1aacf8":"annotations = response.web_detection\nimage_mathes=[]\n\ndef add_image(image_url):\n    \"\"\"\n    Download and resize image\n    \"\"\"\n    img=IpythonImage(\n            data = requests.get(image_url).content,\n            width = 400,\n            height = 400)\n    image_mathes.append(img)\n\nif annotations.best_guess_labels:\n    for label in annotations.best_guess_labels:\n        print('\\nBest guess label: {}'.format(label.label))\n\nif annotations.pages_with_matching_images:\n    print('\\n{} Pages with matching images found:'.format(\n        len(annotations.pages_with_matching_images)))\n\n    for page in annotations.pages_with_matching_images:\n        print('\\n\\tPage url   : {}'.format(page.url))\n\n        if page.full_matching_images:\n            for image in page.full_matching_images:\n                print('\\tImage url  : {}'.format(image.url))\n                add_image(image.url)\n\n        if page.partial_matching_images:\n            for image in page.partial_matching_images:\n                print('\\tImage url  : {}'.format(image.url))\n                add_image(image.url)\n\nif annotations.web_entities:\n    print('\\n{} Web entities found: '.format(\n        len(annotations.web_entities)))\n\n    for entity in annotations.web_entities:\n        print('\\n\\tScore      : {}'.format(entity.score))\n        print(u'\\tDescription: {}'.format(entity.description))\n\nif annotations.visually_similar_images:\n    print('\\n{} visually similar images found:\\n'.format(\n        len(annotations.visually_similar_images)))\n\n    for image in annotations.visually_similar_images:\n        print('\\tImage url    : {}'.format(image.url))      ","a7e9247a":"# Show mathcing images. Use slider to see similar images found in web search:\nwg.interact((lambda image_index: image_mathes[image_index]), image_index=wg.IntSlider(min=0,max=len(image_mathes)-1,step=1))  ","9d64bc59":"image_url = \"https:\/\/cloud.google.com\/vision\/docs\/images\/bicycle_example.png\"\n\nwith tempfile.TemporaryFile() as tmpfile:\n    # Download and store image in a temporary file\n    img_data = requests.get(image_url).content\n    tmpfile.write(img_data)\n    tmpfile.seek(0)\n    # Read downloaded file.\n    content = tmpfile.read()\n    # Display image\n    display(IpythonImage(data=content, width=400, height=300))\n    # Create a PIL instance for annotation later.\n    pillow_image = PillowImage.open(io.BytesIO(content))\n    # Vision API image\n    image = vision.Image(content=content)\n    %time response = client.object_localization(image=image)\n\n    if response.error.message:\n        raise Exception(\n            '{}\\nFor more info on error messages, check: '\n            'https:\/\/cloud.google.com\/apis\/design\/errors'.format(\n                response.error.message))","bcec4a44":"font = ImageFont.load_default()\nprint('Number of objects found: {}'.format(len(response.localized_object_annotations)))\nfor object_ in response.localized_object_annotations:\n    print('\\n{} (confidence: {})'.format(object_.name, object_.score))\n    polygons=[]\n    for vertex in object_.bounding_poly.normalized_vertices:\n        # Note: vertex.x and .y are in 0..1 range.\n        polygons.append((vertex.x*pillow_image.width, vertex.y*pillow_image.height))\n\n    pdraw = ImageDraw.Draw(pillow_image, mode=\"RGBA\")\n    pdraw.polygon(polygons, fill = (255,64,64,48), outline =\"blue\")\n    pdraw.text((polygons[0][0] + 10, polygons[0][1]),\n              font=font, text=object_.name, \n              fill=(0, 64, 64))\n\ndisplay(pillow_image)","b6f29f69":"image = vision.Image()\nimage.source.image_uri = \"gs:\/\/cloud-samples-data\/vision\/face\/faces.jpeg\"\n\nresponse = client.face_detection(image=image)\nfaces = response.face_annotations\n\n# Names of likelihood from google.cloud.vision.enums\nlikelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n                   'LIKELY', 'VERY_LIKELY')\nprint('Faces:')\n\nfor face in faces:\n    print('      anger: {}'.format(likelihood_name[face.anger_likelihood]))\n    print('        joy: {}'.format(likelihood_name[face.joy_likelihood]))\n    print('   surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n    print('     sorrow: {}'.format(likelihood_name[face.sorrow_likelihood]))\n\n    vertices = (['({},{})'.format(vertex.x, vertex.y)\n                for vertex in face.bounding_poly.vertices])\n    print('face bounds: {}\\n'.format(','.join(vertices)))\n\nif response.error.message:\n    raise Exception(\n        '{}\\nFor more info on error messages, check: '\n        'https:\/\/cloud.google.com\/apis\/design\/errors'.format(\n            response.error.message))","fedff6b3":"### Create API client\nClient library reference: https:\/\/googleapis.dev\/python\/vision\/latest\/index.html","a965a4bc":"## Detect objects in a web image \n\nFor your convenience, the Vision API can perform feature detection directly on an image file located in Google Cloud Storage or on the Web without the need to send the contents of the image file in the body of your request, but in this example we download the image and process as a local temporary file.\n\nImage credit: [Bogdan Dada on Unsplash](https:\/\/unsplash.com\/photos\/J9cBJjlpYKU).","252c1c4d":"# Google Gloud Platform pretrained ML services Notebook series\n\nWelcome to this introduction level series about how to use Google Cloud pretrained ML services Python clients from Kaggle notebooks, without raw HTTP API calls. Four notebooks are prepared as reference guides:\n\n* [Cloud Translation quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-translation-tutorial)\n* [Cloud Natural Language quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-natural-language-tutorial)\n* [Cloud Video Intelligence quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-video-intelligence-tutorial)\n* [Cloud Vision quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-vision-tutorial)\n\n\n## Before start, please read these important notes\n\nFirstly, please note that <mark>Cloud Vision is a paid service<\/mark> and requires a GCP project with billing enabled to use. Please refer to [pricing page](https:\/\/cloud.google.com\/vision\/pricing). Also keep in mind, Vision API apply a [quota limit](https:\/\/cloud.google.com\/vision\/quotas) for requests\/minutes and image file size. When this notebook created, the first 1000 request units within a month were free!\nLuckily, you're eligible for a $300 credit when creating the first GCP project.\n\nBefore you can start using any of these services, you must have a Google Cloud project that has the service API enabled.\n\n1. Select or create a GCP Project\n2. Enable Billing. Remember to understand pricing prior to this step.\n3. [Enable Cloud Vision API](https:\/\/console.cloud.google.com\/apis\/library\/vision.googleapis.com)\n\nIn order to use Google Cloud Services from Kagge notebooks, you need to attach your Google Cloud Platform account to this notebbok. Select 'Add-ons' menu above then 'Google Cloud Services'.\n- If you have already attached Google Cloud account to your Kaggle account, please just attach it to this notebook as well.\n- Otherwise you need to attach your account to your profile (and this notebook) by selecting 'Google Cloud AI Platform' integration and adding an authorized account.\n\n'Cloud Storage' is not needed for this tutorial.\n*Unsuccefull attachment, will cause \"Could not automatically determine credentials.\" error response when you want to instantiate a Python client.* \n\n## Google Cloud Platfrom [Vision](https:\/\/cloud.google.com\/vision) (or Vision AI)\nCloud Vision allows developers to easily integrate vision detection features within applications. Provides functions to process image and PDF files for\n* [Optical Character Recognition](https:\/\/cloud.google.com\/vision\/docs\/ocr)\n* [Image crop hint, image size reduction](https:\/\/cloud.google.com\/vision\/docs\/detecting-crop-hints)\n* [Face detecion](https:\/\/cloud.google.com\/vision\/docs\/detecting-faces)\n* [Dominant picture color detection](https:\/\/cloud.google.com\/vision\/docs\/detecting-properties)\n* [Image labelling](https:\/\/cloud.google.com\/vision\/docs\/labels)\n* [Landmarks](https:\/\/cloud.google.com\/vision\/docs\/detecting-landmarks) and [logo](https:\/\/cloud.google.com\/vision\/docs\/detecting-logos) detection.\n* [Finding adult content or violent content within an image](https:\/\/cloud.google.com\/vision\/docs\/detecting-safe-search)\n* [Searching web contents for an image](https:\/\/cloud.google.com\/vision\/docs\/detecting-web)","167ade9d":"### Analyze the response\n> The result and matches are depend on the image content, you might try with another image by running the previous code cell again.","4ee3464f":"## Face detection with emotional state.\n\nFace Detection detects multiple faces within an image along with the associated key facial attributes such as emotional state or wearing headwear. This code cell shows how simple to process Cloud Storage images directly. Benefit: image content don't need to be upload inside of every API requests.","59944302":"## Detect web entities and pages\n\nThis example based on https:\/\/cloud.google.com\/vision\/docs\/detecting-web#detect_web_entities_with_a_local_image."}}