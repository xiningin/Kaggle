{"cell_type":{"59b415a4":"code","512d1936":"code","e72f6f6f":"code","0c7f99b9":"code","3b43bb08":"markdown","4d41aded":"markdown","a185a85b":"markdown","2b37092a":"markdown","02b27f90":"markdown"},"source":{"59b415a4":"# Setting-up Environment & Importing necessary libraries\n!pip install selenium\n!apt-get update\n!apt install -y chromium-chromedriver\n!cp \/usr\/lib\/chromium-browser\/chromedriver \/usr\/bin\n\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom shutil import make_archive\nimport pandas as pd\n\n# Setting-up web driver\noptions = webdriver.ChromeOptions()\noptions.add_argument('--headless')\noptions.add_argument('--no-sandbox')\noptions.add_argument('--disable-dev-shm-usage')\ndriver = webdriver.Chrome('chromedriver',options=options)","512d1936":"base_url = \"https:\/\/www.amazon.in\"\ndataframe = pd.DataFrame(columns=['product_title', 'customer_reviews_rate', 'offered_price','marked_price', 'is_prime_product', 'product_type', 'product_url'])\n\n# Requesting keyword and Processing for search\nkeyword = input(\"Enter the search keyword: \")\nkeyword = keyword.replace(\" \", \"+\")\n\n# Requesting total page to be extracted for the keyword search\nnumbers_of_pages = 2\ntry:\n  numbers_of_pages = int(input(\"Enter the number of pages to be extracted: \"))\nexcept:\n  print(\"That's not a valid input! Value set to default\")\n  numbers_of_pages = 2","e72f6f6f":"for page in range(1, numbers_of_pages + 1):\n  try:\n    search_url = base_url + \"\/s?k={}&page={}&ref=nb_sb_noss\".format(keyword, page)\n    driver.get(search_url)\n    webpage = driver.execute_script(\"return document.body.outerHTML;\")\n    soup = BeautifulSoup(webpage, \"html.parser\")\n    # Extracting the average customer reviews\n    try:\n      result_div = soup.findAll(\"div\", attrs={\"class\": \"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20\"})\n      for product_detail in result_div:\n        product_title = \"\"\n        product_url = \"\"\n        customer_reviews_rate = \"\"\n        offered_price = \"\"\n        marked_price =\"\"\n        is_prime_product = \"\"\n        product_type = \"\"\n\n        # Fetching Product Title\n        try:\n          product_title = product_detail.find(\"span\", attrs={\"class\": \"a-size-medium a-color-base a-text-normal\"}).text\n        except:\n          # Exception for no product title\n          pass\n\n        # Extracting the product URL\n        try:\n          partial_product_url = product_detail.find(\"a\", attrs={\"class\": \"a-link-normal a-text-normal\"}).attrs[\"href\"]\n          product_url = base_url + partial_product_url\n        except:\n          # Exception for no product url\n          pass\n\n        # Fetching Customer Rating, if available\n        try:\n          customer_reviews_rate = product_detail.find(\"div\", attrs={\"class\": \"a-row a-size-small\"}).text\n        except:\n          # Exception for no previous reviews on the product\n          customer_reviews_rate = \"Not Available\"\n        \n        # Fetching Offer Price\n        try:\n          offered_price = product_detail.find(\"span\", attrs={\"class\": \"a-price\"}).find(\"span\", attrs={\"class\": \"a-offscreen\"}).text\n          if offered_price == '' : offered_price = \"Not Available\"\n        except:\n          # Exception for no offers\n          offered_price = \"Not Available\"\n\n        # Fetching Marked Price\n        try:\n          marked_price = product_detail.find(\"span\", attrs={\"class\": \"a-price a-text-price\"}).find(\"span\", attrs={\"class\": \"a-offscreen\"}).text\n          if marked_price == '' : marked_price = \"Not Available\"\n        except:\n          # Exception for no offers\n          marked_price = \"Not Available\"\n        \n        # Fetching Prime availability\n        try:\n          product_detail.find(\"span\", attrs={\"class\": \"aok-relative s-icon-text-medium s-prime\"})\n          is_prime_product = \"Yes\"\n        except:\n          is_prime_product = \"No\"\n        \n        # Fetching Product Type (sponsered or generic)\n        try:\n          product_detail.find(\"div\", attrs={\"class\": \"a-row a-spacing-micro\"}).text\n          product_type = \"Sponsored\"\n        except:\n          product_type = \"Generic\"\n        \n        \n        # Appending DataFrame with new product entry\n        dataframe = dataframe.append({\n            'product_title': product_title,\n            'customer_reviews_rate': customer_reviews_rate,\n            'offered_price': offered_price,\n            'marked_price': marked_price,\n            'is_prime_product': is_prime_product,\n            'product_type': product_type,\n            'product_url': product_url\n            }, ignore_index = True)\n        \n    except:\n      # Exception for div find failure\n      pass\n\n  except:\n    # Exception for No Results for search or page\n    pass","0c7f99b9":"dataframe.to_csv('amazon_product_details_by_keyword.csv')\ndataframe","3b43bb08":"# **DATA SCRAPING**\n## *Static and run-time variable Definition.*","4d41aded":"## *Assigning URL and fetching the source code for given page numbers.*","a185a85b":"## *Storing DataFrame to CSV*","2b37092a":"# **ENVIRONMENT SET-UP**\n\nImporting python libraries necessary for data crawling, data extraction, data storing.","02b27f90":"# **Web Scarping Amazon Product with Search Keyword**\nBy [Darshan Dhanke](https:\/\/www.kaggle.com\/darshandhanke)\n\n# **INTRODUCTION**\n\nThe notebook consists of an **web scraping data from one of the leading e-commerce platform ([www.amazon.in](http:\/\/www.amazon.in\/))** for online retail shopping services extracted by keyword search.\n\nThe study of the notebook focus on the Data Extraction of different features such as product title, customer reviews rate, offered price, marked price, etc."}}