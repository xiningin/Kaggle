{"cell_type":{"ed3b1d65":"code","ff3ea92f":"code","43d8cdeb":"code","6a4790c5":"code","50b28f9f":"code","0e4faea9":"code","5cf0fdb4":"code","59c19492":"code","335082e9":"code","83a3fd90":"code","0debf974":"code","49c90564":"code","f6fbe5b2":"code","c3bdba5b":"code","063a7976":"code","f82b901b":"code","58dafadc":"code","85a9d316":"code","a717f1e8":"code","b80ab90e":"code","236c249f":"code","3f56233f":"code","6bd6970d":"code","63440864":"code","e54dd5bc":"code","81225baa":"code","74eec358":"code","98c46abe":"code","fd29304a":"code","61f76db2":"code","44515f3d":"code","766b5bff":"code","dccd97fa":"code","28b08145":"code","6d765167":"code","c2d1f176":"code","98f59c2a":"code","d4a850aa":"code","5a9ad976":"code","4c7a6229":"code","41cd5c57":"markdown","e1a7eab7":"markdown","b75babb3":"markdown","88abb59f":"markdown","3973810b":"markdown","d8b8fe9d":"markdown","98b11de2":"markdown","213d4780":"markdown","dae61b80":"markdown","29616b8d":"markdown","b2557c32":"markdown","55c16fdd":"markdown","ce1af116":"markdown","92f74870":"markdown","d37295fe":"markdown","632110e9":"markdown","821260da":"markdown","482978a8":"markdown","04c58724":"markdown","73bfd876":"markdown","7a4647bf":"markdown","7b54034a":"markdown","8f8d0602":"markdown","fe554446":"markdown","eefcf03c":"markdown","b0994673":"markdown","6d9ebc2f":"markdown","47636873":"markdown","72a56eeb":"markdown","393bb6e2":"markdown","be255f4d":"markdown","7d12df6c":"markdown","d700c8e0":"markdown","03964547":"markdown","1840787c":"markdown","4c5615dc":"markdown","93e05f80":"markdown","830d7f2c":"markdown","b21f6439":"markdown","bd59eda8":"markdown","4ea22448":"markdown"},"source":{"ed3b1d65":"import pandas as pd               # for data manipulation\nimport matplotlib.pyplot as plt   # for plotting \nimport seaborn as sns             # an extension of matplotlib for statistical graphics","ff3ea92f":"orders = pd.read_csv('..\/input\/orders.csv' )\nproducts = pd.read_csv('..\/input\/products.csv')\norder_products_prior = pd.read_csv('..\/input\/order_products__prior.csv')\naisles = pd.read_csv('..\/input\/aisles.csv')","43d8cdeb":"orders.head()","6a4790c5":"order_products_prior.head()","50b28f9f":"prd = pd.merge(orders, order_products_prior, on='order_id', how='inner')\nprd.head(10)","0e4faea9":"item = prd.groupby(['product_id', 'user_id'])[['order_id']].count()\nitem.columns = ['total']\nitem.head(10)","5cf0fdb4":"item_one = item[item.total==1]\nitem_one.head()","59c19492":"item_one = item_one.groupby('product_id')[['total']].count()\nitem_one.columns = ['customers_one_shot']\n\nitem_one.head(10)","335082e9":"# Write your answer here\nitem_one= item[item.total==1].groupby('product_id')[['total']].sum()\nitem_one.columns = ['customers_one_shot']\nitem_one.head()","83a3fd90":"#execute command one-time only\nitem=item.reset_index(1)","0debf974":"item.head(10)","49c90564":"item_size = item.groupby('product_id')[['user_id']].count()\nitem_size.columns = ['unique_customers']\nitem_size.head(10)","f6fbe5b2":"item_size['unique_customers']= prd[prd.reordered==0].groupby('product_id')[['user_id']].count()\nitem_size.head(10)","c3bdba5b":"#                                          COMMENT FOR RIGHT JOIN:\n# item_one: may or may not contain observations for each product (may never bought only one time) \n#                         item_size: must have values for every product (bought even once) \n#                                       left or inner joins will lose observations. \n\nresults = pd.merge(item_one, item_size, on='product_id', how='right')\nresults.head()","063a7976":"results.shape","f82b901b":"# Write your answer here\nresults = pd.merge(item_size, item_one, on='product_id', how='left')\nresults.head()","58dafadc":"results.shape","85a9d316":"results['one_shot_ratio'] = results['customers_one_shot']\/results['unique_customers']\nresults.head()","a717f1e8":"results[results.customers_one_shot.isnull()].head(10)","b80ab90e":"results[results.customers_one_shot.isnull()].shape","236c249f":"results = results.fillna(0)\nresults.head()","3f56233f":"results[results.customers_one_shot.isnull()]","6bd6970d":"plt.figure(figsize=(15,5))\n\nplt.hist(results.one_shot_ratio, bins=100)\n\nplt.xlabel('Probability', size=10)\nplt.ylabel('Number of products')\nplt.title('The distribution of one-shot ratio', size=10)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nplt.show()","63440864":"no_reorder = results[results.one_shot_ratio==1]\nno_reorder.head(10)","e54dd5bc":"no_reorder.shape[0]","81225baa":"no_reorder.shape[0]\/results.shape[0]*100","74eec358":"plt.figure(figsize=(15,5))\nplt.hist(no_reorder[no_reorder.one_shot_ratio==1].unique_customers, bins=90)\nplt.show()","98c46abe":"# merge with products, to get the names, aisle, department of the products\nresults_name = pd.merge(results, products[['product_id', 'product_name', 'aisle_id']], on='product_id', how='left')\nresults_name.head()","fd29304a":"results_name = results_name.set_index('product_id')\nresults_name.head()","61f76db2":"# get the products with highest one_time_ratio - we need an estimation for no. unique_customers\nresults_asc = results_name.sort_values('one_shot_ratio', ascending=False)\nresults_asc = results_asc[results_asc.unique_customers > 75]\nresults_asc.head(10)","44515f3d":"# get the products with lowest one_time_ratio\nresults_des = results_name.sort_values('one_shot_ratio', ascending=True)\nresults_des = results_des[results_des.unique_customers > 75]\nresults_des.head(10)","766b5bff":"aisle_ratio = results_asc.groupby('aisle_id')[['one_shot_ratio']].mean()\naisle_ratio.columns = ['mean_one_shot_ratio_of_aisle']\naisle_ratio.head()","dccd97fa":"aisle_ratio = aisle_ratio.sort_values('mean_one_shot_ratio_of_aisle', ascending=False)\naisle_ratio.head()","28b08145":"#get the name of aisles with merge\naisle_ratio_names = pd.merge(aisle_ratio, aisles, on='aisle_id', how='left')\n#set aisle_id as index\naisle_ratio_names = aisle_ratio_names.set_index('aisle_id')\naisle_ratio_names.head(15)","6d765167":"#perform visualization of the products with the lowest one time ratio\nresults_asc_top = results_asc.iloc[0:10]\nresults_asc_top","c2d1f176":"plt.figure(figsize=(12,8))\nsns.barplot(results_asc_top.one_shot_ratio, results_asc_top.product_name)\n# add label to x-axis\nplt.xlabel('Ratio (ordered once\/total orders)', size=15)\n# keep y-axis free of label\nplt.ylabel('  ')\n#put a title\nplt.title('Top 10 products that are ordered only once', size=15)\n\n#make tick locations (titles) more visible\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\n\n#we set the range of y-axis to a bit lower from the lowest probability and a bit higher from the higest probability\nplt.xlim(0.98, 1.001)\nplt.show()","98f59c2a":"aisle_top = aisle_ratio_names.iloc[:10]\naisle_top","d4a850aa":"plt.figure(figsize=(12,8))\n\nsns.barplot(aisle_top.aisle, aisle_top.mean_one_shot_ratio_of_aisle)\n\n# keep x-axis free of label \nplt.xlabel(' ')\nplt.ylabel('Mean one-shot ratio of aisle', size=15)\nplt.title('Top 10 aisles that their products tend to ordered only once', size=15)\n\n#make tick locations (titles) more visible, rotate axis of xticks\nplt.xticks(fontsize=15, rotation=90)\nplt.yticks(fontsize=15)\n\n#we set the range of y-axis to a bit lower from the lowest probability and a bit higher from the higest probability\nplt.ylim(0.8, 0.9)\nplt.show()","5a9ad976":"results_trimmed = results[['one_shot_ratio']]\nresults_trimmed.head()","4c7a6229":"# get the results to the original merged data frame \nprd = pd.merge(prd , results_trimmed, on='product_id', how='left')\nprd.head()","41cd5c57":"As a result we have a DataFrame that keeps both variables for 49677 products:","e1a7eab7":"## Import data into Python\nWe load the required packages:","b75babb3":"With .sort_values( ) we get the aisles with the highest mean of one-shot ratio.","88abb59f":"## 2.2  How many customers bought a product only once\nFrom the **item** DataFrame we can now calculate both numerator (the number of users who bought a product only once) & denominator (the number of unique customers for a product) of the one-shot ratio.\n\nTo get the number of users who bought it only once:\n* We select from **item** DataFrame, only these rows where <b>total purchases are equal to one<\/b>\n","3973810b":"## 2.3 Number of unique customers of a product.\nWe now perform a groupby on **product_id** and count the users that appear in each product. \n\nHowever, **user_id** is passed as index on **item** DataFrame. For this reason, we use the **.reset_index( )** method to convert **user_id** to a column. In our case we use the argument=1 on **.reset_index( )**, as we want only the second index (**user_id**) to be turned into a column.","d8b8fe9d":"And now we get the actual names of the aisles from aisles data frame.\n\nHere we use a left join as we want to keep all the aisles that we have metrics for them, and just join on them the available information of aisles data frame.","98b11de2":"Which means that 90 products have never been bought only once.\nAs NaN values, means absence of an observation for each product, we will use the .fillna(0) method so we can convert all NaN values to zero.","213d4780":"So Indeed, most of the products that are bought only one time tend to have less than 20 unique customers.","dae61b80":"So now, we can perform our desired .groupby( ) on **item** :","29616b8d":"We merge these two DataFrames by their matching column, order_id. The inner join (how='inner') keeps only rows where each order_id can be found on both DataFrames. **orders** DataFrame contains both prior and train orders, while **order_products_prior** contains only prior orders. \n\nAs a result, the new DataFrame contains only prior orders.\n\n![inner](https:\/\/www.w3schools.com\/Sql\/img_innerjoin.gif)","b2557c32":"### 2.2.1 Your Turn \ud83d\udcda\ud83d\udcdd\nWhich other aggregation function will yield the same result?","55c16fdd":"From the results we see that for example product 2 has been bought from 78 individual customers.","ce1af116":"As each row describe a single product, we select product_id to be the main key for each row; with .set_index( ) method we select product_id to be the index for results_name","92f74870":"## 2.4 Merge results\nNow that we have both parts of our final fraction (ratio), we will merge both DataFrames into one. We select a right join as the **item_size** data frame, keeps all the product that they have been purchased, where the **item_one** keeps only the products that they have been purchased only once.\n\n![right](https:\/\/www.w3schools.com\/sql\/img_rightjoin.gif)","d37295fe":"Now that we have a DataFrame that combines both the prior orders and the products purchased on each order, we will get insights for each product.","632110e9":"If you check again on no_reorder DataFrame it seems that products with one-shot ratio = 1  have few unique customers. \n\nTo have a broader view on products with one-shot ratio = 1, we create a histrogram for the number of unique customers","821260da":"## 4.4 Get the name of the products\nNow we will merge the results with the **products** DataFrame. The joining key is the product_id and we select a left join, as we want to keep all these products, that we have created a one-shot ratio for them.\n![left](https:\/\/www.w3schools.com\/sql\/img_leftjoin.gif)","482978a8":"### 2.3.1 Your Turn \ud83d\udcda\ud83d\udcdd\nHow could you create the same variable by using the prd DataFrame & the reorder column?\n> Hint: You will need to filter rows of **prd** DataFrame first.","04c58724":"So for example, product 2 has been bought only one time from 70 individual customers.","73bfd876":"Moreover, we load the .csv files in DataFrames:","7a4647bf":"If we check again for NaN values on results DataFrame we will get no results.","7b54034a":"# 5 Merge the final variables with prd DataFrame\nIn the final chapter, we show how we can merge the final variable created from Section 2 to the initial **prd** DataFrame that holds data for both the orders and products purchased. \n## 5.1 Create a DataFrame from results DataFrame\nHere, we select to keep only the column 'one_shot_ratio'  and store it a new DataFrame called **results_trimmed**\n","8f8d0602":"## 4.3 Analyze the products with One-Shot ratio = 1\nInterestingly many product have one-shot ratio = 1 meaning that these products have never been reordered. In this sub-section we explore these products.","fe554446":"# 1. Create a DataFrame that contains data from multiple sources \nIn this section, we create a new DataFrame that combines the orders, the customers, and the products. Towards this end, we use the following DataFrames:\n\n**orders** which contains the orders made from all customers","eefcf03c":"## 4.5 Get the products with highest and lowest ratio\nIn the coming example we select the products with the highest and lowest one-shot ratio. We select to filter (limit) our results to only these products that have more than 75 unique customers. Products with very few customers cannot provide valid data.\n> We chose to be 75 unique customers, as many products with less than 75 unique customers, had one-shot ratio equal to one.","b0994673":"# 2. Does users frequently reorder a product?  (one-shot ratio)\nIn order to answer this business question we calculate a ratio that consists of the total number of customers who bought a product only once divided by the total number of customers who bought this product.\n\n![](https:\/\/latex.codecogs.com\/gif.latex?one\\&space;-\\&space;shot\\&space;ratio\\&space;of\\&space;a\\&space;product\\&space;=&space;\\frac{customers\\&space;who\\&space;bought\\&space;it\\&space;only\\&space;once}{number\\&space;of\\&space;unique\\&space;customers})\n\nA high one-shot ratio of a product means that customers tend not to reorder this product. \n\nTo calculate this ratio we have to compute:\n* the number of users bought it only once (count)\n* the number of unique customers of a product (count)\n\nThese variables will be calculated through a supportive variable that indicates how many times each customer bought a product. We start by calculating this supportive variable.","6d9ebc2f":"# 4. Further exploration of results DataFrame\nNow that we have both the one-shot ratio & reorder_times_product for each product, we show how we:\n1. Find and fill NaN values\n2. Visualize the one-shot ratio\n3. Analyze the products with one-shot ratio = 1\n4. Get the name of the products\n5. Get the products with highest and lowest one-shot ratio\n6. Find the aisle with highest mean one-shot ratio\n7. Create visualizations for the products and the aisles with the highest ratio\n9. Get the 10 products with the highest reorder_times_product\n\n## 4.1 Find and fill NaN values\nThere may be cases where none customer bought a product only one time. In this case, the corresponding variable after merge will have a NaN value.\n\nLet's check the above scenario. To retrieve the rows with a NaN in a particular column, we can use the following code:\n>df[df['Col1'].isnull()]\n\nSo we modify the previous code for the column customers_bought_once:","47636873":"## 2.6 Create the one-shot ratio\nNow that we have merged the two count variables,  we can create a new column which will keep our desired ratio. \nTo create a new column to an already existing DataFrame you can simply write the name of the DataFrame and the name of the new column in brackets.","72a56eeb":"In the same fashion, we create a plot for the aisles with the highest mean of one-shot ratio. The information for the aisles is stored in the **aisle_ratio_names** DataFrame.","393bb6e2":"## 4.2 Visualize the one-shot ratio\nIn order to visualize the one-shot ratio in a histogram, we use the .hist( ) method of matplotlib package.\nArgument bins=100, creates a histrogram of 100 bins (bin of 0,01 for range 0 to 1) as ratio is a continuous variable.","be255f4d":"## 4.7 Create visualizations for the products and the aisles with the highest ratio\nAt this stage we create two plots; one for the products & one for the aisles with the highest ratio.\n\nFirst we trim **results_asc** (the DataFrame that keeps the one-shot ratio fo each product) to keep only the top 10.","7d12df6c":"Which are actually 8,8% of total products ","d700c8e0":"## 2.1  How many times each customer bought a product.\nTo create this supportive variable, we .groupby( ) the **prd** DataFrame, by the product_id & user_id and we select the column 'order_id' to apply the .count( ) aggregation function. We store the result in a new DataFrame called item.","03964547":"* From the selected rows, we perform a .groupby( ) for each product_id, we select the previously created column 'total' and we use the aggregation function .count( ) to get how many customers bought each product only once.","1840787c":"There are actually 4372 with no reorders.","4c5615dc":"**order_products_prior** which contains the products purchased in each order ","93e05f80":"## 4.6  Aisles with high mean one-shot ratio\nIn this step, we .groupby( ) products by their aisle_id. With aggregation function .mean( ) we get the average of one_shot_ratio for each aisle.\n","830d7f2c":"And now we create a barplot with top products.","b21f6439":"### 2.4.1 Your Turn - Use a left join \ud83d\udcda\ud83d\udcdd\nPropose another way to use a left join to merge the DataFrames **item_one** & **item_size**.  Your new DataFrame should have the same .shape (49677, 2) as the previous DataFrame:","bd59eda8":"### 5.1.2 Merge one_shot_trimmed with prd \nAnd now we join the results_trimmed to the initial prd data frame. We use a left join to keep all the orders and products on the prd data frame.\n![left](https:\/\/www.w3schools.com\/sql\/img_leftjoin.gif)\n\nNote that we would not be able to merge the DataFrames, if we didn't have as index the product_id on results_trimmed.","4ea22448":"# Introduction\nThis kernel has been created by the [Information Systems Lab](http:\/\/islab.uom.gr) at the University of Macedonia, Greece for the needs of the elective course Special Topics of Information Systems I at the [Business Administration](http:\/\/www.uom.gr\/index.php?tmima=2&categorymenu=2) department of the University of Macedonia, Greece.\n\nIn this Instacart Notebook, we answer business questions regarding how consumers behave towards a specific product and thus we calculate variables that describe each product. \n\nTo achieve this, we follow three steps:\n1. Create a new DataFrame, namely **prd**, that contains data from multiple CSV files\n2. Produce supportive variables with aggregated values from the prd DataFrame\n3. Calculate variables that describe products\n\n# Business Insights\nIn this notebook you will explore Instacart data in order to answer the following business questions:\n* Do users frequently reorder a product? i.e. what is the reorder probability of a product? More specific questions incude:\n - What is the number of unique customers of a product?\n - How many customers buy a product only once (one-shot products)? \n - What is the one-shot ratio of a product? (This ratio is related to the reorder probability of a product)\n - What is the mean one-shot ratio of an aisle?\n\n# Python Skills\n* Merge two DataFrame with inner, left, right join\n* Perform a .groupby( ) on data of a DataFrame that meet a condition\n* Create a new column to an already existing DataFrame\n* Convert and index of DataFrame into a column\n* Divide columns element-wise of a data frame\n* Check for NaN (Not a Number) values and modify them\n* Create a histrogram (distribution plot) of a variable\n* Set a column as the index of a DataFrame\n* Filter data frames based on a condition\n* Select rows of a DataFrame, based on a condition\n* Create a new DataFrame, with column(s) of an existing DataFrame\n* Create ratios through supportive variables\n\n# Packages \n* pandas: .merge() , .reset_index( ),  .isnull(), .any(), set_index(), \n* matplotlib.pyplot: .hist()\n* seaborn: .barplot()"}}