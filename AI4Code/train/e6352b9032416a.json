{"cell_type":{"34045853":"code","64b339c4":"code","1e7756e0":"code","bfa8ebda":"code","aa24f8cb":"code","27f4a37b":"code","55d27e64":"code","2b3ccd8e":"code","6e630297":"code","b419c4fd":"code","f2078d5f":"code","5ecb9f44":"code","31596085":"code","c30e55ec":"code","eecca185":"code","df556197":"code","3c1faf0c":"code","350c8355":"code","a266d1af":"code","398ad8f5":"code","5164ea28":"code","5e9e2070":"markdown","bea93820":"markdown","c747dd71":"markdown","e9bcc6cc":"markdown","190a5bf6":"markdown","0e5930ea":"markdown","675dc8d6":"markdown","f15965b8":"markdown","1218783c":"markdown"},"source":{"34045853":"import pandas as pd\nimport string\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport nltk\nimport nltk.data\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.corpus import stopwords\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk import word_tokenize\nnltk.download('vader_lexicon')\nnltk.download('punkt')\nimport warnings\nwarnings.filterwarnings(\"ignore\")","64b339c4":"df_a=pd.read_csv('..\/input\/notebook-cleaned-dataset\/ArianaGrande.csv')\ndf_b=pd.read_csv('..\/input\/notebook-cleaned-dataset\/Beyonce.csv')\ndf_be=pd.read_csv('..\/input\/notebook-cleaned-dataset\/BillieEilish.csv')\ndf_ed=pd.read_csv('..\/input\/notebook-cleaned-dataset\/EdSheeran.csv')\ndf_j=pd.read_csv('..\/input\/notebook-cleaned-dataset\/JustinBieber.csv')\ndf_k=pd.read_csv('..\/input\/notebook-cleaned-dataset\/KatyPerry.csv')\ndf_l=pd.read_csv('..\/input\/notebook-cleaned-dataset\/LadyGaga.csv')\ndf_m5=pd.read_csv('..\/input\/notebook-cleaned-dataset\/Maroon5.csv')\ndf_p=pd.read_csv('..\/input\/notebook-cleaned-dataset\/PostMalone.csv')\ndf_r=pd.read_csv('..\/input\/notebook-cleaned-dataset\/Rihanna.csv')\ndf_s=pd.read_csv('..\/input\/notebook-cleaned-dataset\/SelenaGomez.csv')\ndf_all=[df_a,df_b,df_be,df_ed,df_j,df_k,df_l,df_m5,df_p,df_r,df_s]","1e7756e0":"def lyrics_to_words(document):\n    \"\"\"\n    This function splits the text of lyrics to  single words, removing stopwords and doing the lemmatization to each word\n\n    parameters:\n    document: text to split to single words\n    \"\"\"\n    stop_words = set(stopwords.words('english'))\n    exclude = set(string.punctuation)\n    lemma = WordNetLemmatizer()\n    stopwordremoval = \" \".join([i for i in document.lower().split() if i not in stop_words])\n    punctuationremoval = ''.join(ch for ch in stopwordremoval if ch not in exclude)\n    normalized = \" \".join(lemma.lemmatize(word) for word in punctuationremoval.split())\n    return normalized","bfa8ebda":"def toword(df):\n    def unique(list1):\n       # intilize a null list\n         unique_list = []\n       # traverse for all elements\n         for x in list1:\n             # check if exists in unique_list or not\n             if x not in unique_list:\n                  unique_list.append(x)\n         return unique_list\n    \n    #Stores unique words of each lyrics song into a new column called words\n    #list used to store the words\n    words = []\n    #iterate trought each lyric and split unique words appending the result into the words list\n    df = df.reset_index(drop=True)\n    for word in df['Lyric'].tolist():\n        words.append(unique(lyrics_to_words(word).split()))\n    #create the new column with the information of words lists\n    df['words'] = words\n    return df","aa24f8cb":"def cleaning(df):\n    a=[]\n    i=0\n    df1=df\n    title = df['Title']\n    for t in df['Title']:\n        r=Re=l=Li=c=m=V=ve=D=rs=0\n        r=t.find('remix')\n        Re=t.find('Remix')\n        l=t.find('live')\n        Li=t.find('Live')\n        V=t.find('Version')\n        ve=t.find('version')\n        D=t.find('Demo ')\n        D=t.find('Demo')\n        rs=t.find('Reprise')\n        c=t.find('COPY')\n        m=t.find('Mix')\n        if r != -1:\n            a.append(t)\n        elif Re != -1:\n            a.append(t)\n        elif l != -1:\n            a.append(t)\n        elif Li != -1:\n            a.append(t)\n        elif V != -1:\n            a.append(t)\n        elif ve != -1:\n            a.append(t)\n        elif D != -1:\n            a.append(t)\n        elif rs != -1:\n            a.append(t)\n        elif c != -1:\n            a.append(t)\n        elif m != -1:\n            a.append(t)\n    \n    for t1 in df['Title']:\n        for t2 in a:\n            if t1 == t2:\n                df1=df1.drop(i)\n        i=i+1\n    \n    df1.dropna(subset = [\"Title\"], inplace=True)\n    df1.dropna(subset = [\"Lyric\"], inplace=True)\n    df1.drop_duplicates(subset =\"Title\",keep = False, inplace = True)\n    df1.drop_duplicates(subset =\"Lyric\",keep = False, inplace = True) \n    \n    \n    return df1","27f4a37b":"def countword(df):    \n    \n    c=[]\n    for word in df['words']:\n        for w in word:\n            c.append(w)\n    return c\n","55d27e64":"def words_stats(df,main_df):\n    unique_words = []\n    total_words = []\n    total_news = []\n    name = []\n    \n    for value in df.columns[1:]:\n        unique_words.append(np.count_nonzero(df[value]))\n        total_words.append(sum(df[value]))\n        name.append(str(value))\n        total_news.append(main_df['name'][main_df['name']==value].count())\n        data = pd.DataFrame({'name':name,\n                          'unique words':unique_words,\n                          'total words':total_words,\n                          'total songs':total_news})\n    data['words per songs'] = round(data['total words'] \/ data['total songs'],0)\n    data['words per songs'] = data['words per songs'].astype('int')\n    return data","2b3ccd8e":"df_allc=[]\nfor df in df_all:\n    df_c=cleaning(df)\n    df_w=toword(df_c)\n    df_allc.append(df_w)\n\nframes=df_allc\ndf_main = pd.concat(frames,ignore_index=True)\ndf_main= df_main.drop(df_main[(df_main.Year < 1000) | (df_main.Year > 2021)].index)\ndf_main= df_main.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\ndf_main=df_main.reset_index(drop=True)","6e630297":"before=[]\nafter=[]\nlength=[]\nulength=[]\nwd=[]\n\nfor df in df_all:\n    a,b=df.shape\n    before.append(a)\n    \nfor dfc in df_allc:\n    a,b=dfc.shape\n    after.append(a)  \n    c=countword(dfc)\n    l=len(c)\n    ul=len(np.unique(c))\n    wd.append(c)\n    length.append(l)\n    ulength.append(ul)","b419c4fd":"artists=['ArianaGrande','Beyonce','BillieEilish','EdSheeran','JustinBieber','KatyPerry','LadyGaga','Maroon5','PostMalone','Rihanna','SelenaGomez']\ndf_info =pd.DataFrame({'name':artists,'before':before,'after':after,'words':wd,'unique words':ulength,'word count':length})\ndf_info['diff']=df_info['before']-df_info['after']\ndf_info['words per songs'] = round(df_info['word count'] \/ df_info['after'],0)\ndf_info['words per songs'] = df_info['words per songs'].astype('int')\ndf_info['lexicalrichness']=(df_info['unique words']\/df_info['word count'])*100\ndf_info=df_info[['name','before','after','diff','words','words per songs','unique words','word count','lexicalrichness']]\ndf_info","f2078d5f":"fig = go.Figure(data=[\n    go.Bar(name='Unique Word Count', x=df_info['name'], y=df_info['unique words'].tolist()),\n    go.Bar(name='Total Word Count', x=df_info['name'], y=df_info['word count'].tolist()),\n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group',title={'text': \"Total words vs Unique words\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'})\nfig.show()","5ecb9f44":"print(df_info[df_info.lexicalrichness == max(df_info['lexicalrichness'])].loc[:,'name'])\nprint(max(df_info['lexicalrichness']))\nfig = px.bar(df_info, x='name',y='lexicalrichness')\nfig.update_layout(title={'text': \"Lexicalrichness of all artist\",'y':1,'x':0.5,'xanchor': 'center','yanchor': 'top'})\nfig.show()","31596085":"df_group=df_main.groupby(['Artist','Year']).count().iloc[:,0:2]\n#df_group=df_group.drop(\"Unnamed: 0\",axis=1)\ndf_group =df_group.reset_index()\ndf_group","c30e55ec":"df_temp= df_group.drop('Artist',axis=1)\ndf_temp=df_temp.groupby(['Year']).count()\ndf_temp=df_temp.reset_index()\nfig = px.line(df_temp, x='Year',y='Title')\nfig.update_layout(title={'text': \"No. of Titles by all artist from 2001-2021\",'y':0.95,'x':0.5,'xanchor': 'center','yanchor': 'top'})\nfig.show()","eecca185":"df_temp=[]\nname=df_main['Artist'].unique()\nname=name[0:9]\nnum_plots = 9\ntotal_cols = 3\ntotal_rows = 3\nfig, axs = plt.subplots(nrows=total_rows, ncols=total_cols,\n                        figsize=(7*total_cols, 7*total_rows), constrained_layout=True)\nfor artist in df_main['Artist'].unique():\n    df_temp.append(df_group[df_group['Artist']==artist])\nfor i, var in enumerate(name):\n    row = i\/\/total_cols\n    pos = i % total_cols\n    plot = sns.barplot(data=df_temp[i],x=\"Year\", y=\"Title\",ax=axs[row][pos])\n    axs[row][pos].set_title(name[i])\n\n\nname=df_main['Artist'].unique()\nname=name[9:11]\nfig, axs = plt.subplots(nrows=1, ncols=2,\n                        figsize=(12, 6), constrained_layout=True)\nplot = sns.barplot(data=df_temp[9],x=\"Year\", y=\"Title\",ax=axs[0])\naxs[0].set_title(name[0])\nplot = sns.barplot(data=df_temp[10],x=\"Year\", y=\"Title\",ax=axs[1])\naxs[1].set_title(name[1])","df556197":"\ndef plot_wordcloud(df,row,col):\n    wc = WordCloud(background_color=\"#F2F2F2\",max_font_size=90,random_state=42,\n                      width=500, height=300)\n                      #colormap = \"twilight\")\n    fig = plt.figure(figsize=(30,25))\n     \n    for index, value in enumerate(df.columns[1:]):\n        top_dict = dict(zip(df['words'].tolist(),df[value].tolist()))\n        wc.generate_from_frequencies(top_dict)\n        plt.subplot(row,col,index+1)\n        plt.imshow(wc,interpolation=\"bilinear\")\n        plt.axis(\"off\")\n        plt.title(f\"{value}\",fontsize=15)\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\nvect_words=pd.read_csv('..\/input\/words-dataset\/vectwords.csv')\nplot_wordcloud(vect_words,4,3)","3c1faf0c":"\n#Create lists to store the different scores for each word\ndef setimentanalyzer(df):\n    neg='Negative'\n    neu='Neutral'\n    pos='Positive'\n    negative = []\n    neutral = []\n    positive = []\n    dominant_sentiment=[]\n    dominant_sentiment_score=[]\n    #Initialize the model\n    sid = SentimentIntensityAnalyzer()\n    #Iterate for each row of lyrics and append the scores\n    for i in df.index:\n       \n        scores = sid.polarity_scores(df['Lyric'].iloc[i])\n        negative.append(scores['neg'])\n        neutral.append(scores['neu'])\n        positive.append(scores['pos'])\n        if scores['neg']>scores['pos']:\n            dominant_sentiment_score.append(scores['neg'])\n            dominant_sentiment.append(neg)\n        elif scores['neg']<scores['pos']:\n            dominant_sentiment_score.append(scores['pos'])\n            dominant_sentiment.append(pos)\n        else:\n            dominant_sentiment_score.append(scores['neu'])\n            dominant_sentiment.append(neu)\n    #Create 5 columns to the main data frame  for each score\n    df['negative'] = negative\n    df['neutral'] = neutral\n    df['positive'] = positive\n    df['dominant_sentiment']=dominant_sentiment\n    df['dominant_sentiment_score']=dominant_sentiment_score\n    return df","350c8355":"df_sentiment=setimentanalyzer(df_main)\ndf_sentiment.head(5)","a266d1af":"df_temp=[]\nname=df_sentiment['Artist'].unique()\nname=name[0:9]\nnum_plots = 9\ntotal_cols = 3\ntotal_rows = 3\n#fig, axs = plt.subplots(nrows=total_rows, ncols=total_cols,\nfig, axs = plt.subplots(nrows=total_rows, ncols=total_cols,\n                        figsize=(5*total_cols, 5*total_rows), constrained_layout=True)\nfor artist in df_main['Artist'].unique():\n    df_temp.append(df_sentiment[df_sentiment['Artist']==artist])\nfor i, var in enumerate(name):\n    row = i\/\/total_cols\n    pos = i % total_cols\n    plot = sns.swarmplot(data=df_temp[i], x=\"dominant_sentiment\", y=\"dominant_sentiment_score\",ax=axs[row][pos])\n    axs[row][pos].set_title(name[i])\n    \nname=df_main['Artist'].unique()\nname=name[9:11]\nfig, axs = plt.subplots(nrows=1, ncols=2,\n                        figsize=(10, 5), constrained_layout=True)\nplot = sns.swarmplot(data=df_temp[9], x=\"dominant_sentiment\", y=\"dominant_sentiment_score\",ax=axs[0])\naxs[0].set_title(name[0])\nplot = sns.swarmplot(data=df_temp[10], x=\"dominant_sentiment\", y=\"dominant_sentiment_score\",ax=axs[1])\naxs[1].set_title(name[1])","398ad8f5":"means_df = df_sentiment.groupby(['Artist']).mean()\nmeans_df","5164ea28":"x = np.linspace(0, 10, 1000)\nfor name, group in means_df.groupby('Artist'):\n    plt.scatter(group['positive'],group['negative'],label=name)\n    plt.legend()\nplt.xlim([0,0.3])\nplt.ylim([0,0.3])\nplt.plot(x, x+0, linestyle='solid')\nplt.title(\"Positive Valence vs Negative  Valence\")\nplt.xlabel('Positive Valence')\nplt.ylabel('Negative  Valence')\nplt.show()#positive and negative region","5e9e2070":"# Sentiment Analysis\n>\ud83d\udccc**Note** Now we will analyze the sentiment of each song\n\nAnalysis is done with a function SentimentIntensityAnalyzer ","bea93820":"* Now dividing the mail data frame to visualize how many songs artist sings over a year","c747dd71":"* Now let's look at the above visualization with respect to each artist.","e9bcc6cc":"<div>\n    <center><img src=\"https:\/\/i.imgur.com\/juC10r8.jpg\"\"> <\/center>\n    <center><h1>\u266b Sentiment Analysis of Music Artists \u266b<\/h1> <\/center>\n<\/div>","190a5bf6":"##### *After appling all the function we generate a main dataframe.*\n<br><\/br>\n# **Preparing Data for visualization**\n>\ud83d\udccc**Note**: Now once the data is cleaned we'll divide our main dataframe into sub parts for ease of visualization\n\n* The first visualization we'll look at it how many unique word vs total words these artist uses and lexicalrichness of each artist","0e5930ea":"# **Importing Library**","675dc8d6":"# **Importing all data**\n>\ud83d\udccc**Note**: Importing all singers separately","f15965b8":"# **Cleaning**\n>\ud83d\udccc**Note**: Removing the nan values,unreleased albums and songs sung in any other language than english. \n* Lyrics to words -> To convert all the Lyrics to word \n* To word -> Converts all the words and removes all the repetative words \n*  Count word -> This function can count all the unique and as well non unique words\n*  Word stats -> To give the statistics of words.\n","1218783c":"Now based on the above table we do the follwing analyisis where we find out the dominant sentiment of each artist"}}