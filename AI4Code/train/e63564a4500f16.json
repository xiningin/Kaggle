{"cell_type":{"606c2b43":"code","13a8d528":"code","daa1aab2":"code","7b6b39f2":"code","329708d8":"code","cf2abb30":"code","c540e6d2":"code","9beeae25":"code","c0125c58":"code","2cffbac3":"code","7e022211":"code","2e8ccd6f":"code","81fbcb0d":"code","5cfb760e":"code","26d86076":"code","d1f8f025":"code","b8dfbbb4":"code","a3ef9a87":"code","761978d4":"code","7f47015e":"code","13d4db52":"code","7d4223f8":"code","15ec19c7":"code","a54d9189":"markdown","36b36fc6":"markdown","d64a7014":"markdown"},"source":{"606c2b43":"#importing pandas library for read data from system\nimport pandas as pd","13a8d528":"#reading csv data from system and store into data variable\ndata=pd.read_csv('..\/input\/iris-flower-dataset\/IRIS.csv')","daa1aab2":"#display top 5 rows of data\ndata.head()","7b6b39f2":"data.dtypes","329708d8":"data.describe()","cf2abb30":"from sklearn.preprocessing import scale","c540e6d2":"features=scale(data[['sepal_length','sepal_width','petal_length','petal_width']])","9beeae25":"pd.DataFrame(features).describe()","c0125c58":"#set species column as target column\ntarget=data['species']","2cffbac3":"#checking unique value counts\ntarget.value_counts()","7e022211":"#label encoder from sklearn for label encoding\nfrom sklearn.preprocessing import LabelEncoder","2e8ccd6f":"#coverting text value into numerical value\ntarget=pd.Series(LabelEncoder().fit_transform(target))","81fbcb0d":"#check unique value counts\ntarget.value_counts()","5cfb760e":"#importing train test split from sklearn model selection package for data split 25% for test\nfrom sklearn.model_selection import train_test_split","26d86076":"#split data for train and test\nx_train,x_test,y_train,y_test=train_test_split(features,target,test_size=0.15)","d1f8f025":"#printing data lengths\/number of rows\/data\nprint(len(x_train))\nprint(len(y_train))\nprint(len(x_test))\nprint(len(y_test))","b8dfbbb4":"#import naive bayes classifier from sklearn package\nfrom sklearn.naive_bayes import GaussianNB","a3ef9a87":"#created a object for the classifier\nbc=GaussianNB()","761978d4":"#train usinge train data\nbc.fit(x_train,y_train)","7f47015e":"#predict target data for test feature data and save into pred variable\npred=bc.predict(x_test)","13d4db52":"#importing metrics\nfrom sklearn.metrics import precision_score,recall_score,f1_score,classification_report,accuracy_score","7d4223f8":"print('accuracy:',accuracy_score(pred,y_test))\nprint('precision:',precision_score(pred,y_test,average='micro'))\nprint('recall:',recall_score(pred,y_test,average='micro'))\nprint('f1_score:',f1_score(pred,y_test,average='micro'))","15ec19c7":"print(classification_report(pred,y_test))","a54d9189":"#### Standardize a dataset along any axis.\n\nCenter to the mean and component wise scale to unit variance.","36b36fc6":"### Data Set Information:\n\nThis is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.\n\nPredicted attribute: class of iris plant.\n\nThis is an exceedingly simple domain.\n\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick, spchadwick '@' espeedaz.net ). The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.\n\n#### Attribute Information:\n\n1. sepal length in cm\n2. sepal width in cm\n3. petal length in cm\n4. petal width in cm\n5. class:\n* -- Iris Setosa\n* -- Iris Versicolour\n* -- Iris Virginica\n","d64a7014":"* **binary**: Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n* **micro**: Calculate metrics globally by counting the total true positives, false negatives and false positives.\n* **macro**: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n* **weighted**: Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters \u2018macro\u2019 to account for label imbalance; it can result in an F-score that is not between precision and recall.\n"}}