{"cell_type":{"9061e0f4":"code","aa00c5a8":"code","03d06e65":"code","fdadcdcc":"code","4817ab98":"code","fcf52965":"code","8c5cd79f":"code","59e28c1d":"code","5d8b13f0":"code","6387787c":"code","373c5528":"code","cb6d958b":"code","006357de":"code","b1d59d80":"code","d0ce3e4c":"code","3ce8f520":"code","334e6893":"code","0ee7da5e":"code","7b08b537":"code","b31b0f75":"code","8c0a1c7e":"code","b35c37e2":"code","73e5d852":"code","bd133398":"code","2ce06e19":"code","151c8d2f":"code","065bffb8":"code","a30fc926":"code","3d994936":"code","b88d2a43":"code","aad4d406":"code","5a2d118c":"code","bdd0021d":"code","f160a31e":"code","e07b1b87":"code","7b70a346":"code","00e7c901":"code","7e0a525e":"code","7b6d87c6":"code","464b6566":"code","b190cc64":"code","59440429":"code","f9f06cbf":"code","7d630eb7":"code","c0c6c19f":"code","d8b0e09c":"code","a60c3f67":"code","0b7f50bb":"code","7bf765d1":"code","4cd3e577":"code","3c85d383":"code","2257991e":"code","f75f50fc":"code","269f8063":"code","1584e062":"code","23f95075":"code","417a9bdd":"code","4a21c41e":"code","cc156c45":"code","426981f4":"code","d5df3717":"code","384b4914":"code","8edd4455":"code","296c880e":"code","3eb8270b":"code","f621c3fe":"code","095cf75a":"code","75978d16":"code","ea1bbe11":"code","fbd3ef6a":"code","8c9228f2":"code","76d63df7":"code","1582558f":"code","cc53f582":"code","7a6e8577":"code","b67cc2a9":"code","a425d3f3":"code","9c04695a":"code","ea389997":"code","51b308f2":"code","1ded36a9":"code","72f4c9da":"code","0e4d5835":"code","e1169a82":"code","0f79c797":"code","23cfcd82":"code","70ae9944":"code","6fccf8cb":"code","be6b4960":"code","77ecbe84":"code","b6c56c11":"code","ac0174f7":"code","af237ec7":"code","145a2fda":"code","1eb69857":"code","fb1621ad":"code","c68b09b2":"code","c39ea2a1":"code","36374336":"code","442af0eb":"code","b7ba890b":"code","a6a82a38":"code","2f8738cf":"code","e05d0b45":"code","264454dd":"code","fcb25b9e":"markdown","d4b3bd7c":"markdown","f90b73a4":"markdown","3e82e7f2":"markdown","2f811549":"markdown","7f5d01e7":"markdown","9cd59052":"markdown","01af0fd1":"markdown","5831d768":"markdown","28dbc2e5":"markdown"},"source":{"9061e0f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa00c5a8":"train_data = pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')\ntest_data = pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Test_set.xlsx')","03d06e65":"train_data.head()","fdadcdcc":"test_data.head()","4817ab98":"train_data.info()","fcf52965":"test_data.info()","8c5cd79f":"train_data.describe(include='O')","59e28c1d":"test_data.describe(include='O')","5d8b13f0":"print(\"The shape of the train dataset is :\", train_data.shape)\nprint(\"The shape of the test dataset is :\", test_data.shape)","6387787c":"train_data.isnull().any()","373c5528":"test_data.isnull().any()","cb6d958b":"train_data.isnull().sum()","006357de":"train_data.dropna(inplace=True)","b1d59d80":"train_data.shape","d0ce3e4c":"train_data.head()","3ce8f520":"train_data['Journey_day'] = pd.to_datetime(train_data['Date_of_Journey'], format = '%d\/%m\/%Y').dt.day\ntrain_data['Journey_month'] = pd.to_datetime(train_data['Date_of_Journey'], format = '%d\/%m\/%Y').dt.month","334e6893":"train_data.head()","0ee7da5e":"train_data.drop('Date_of_Journey', axis=1, inplace=True)","7b08b537":"# Similarly we have to extraxt hours and minutes from the Dep_Time feature\n\n# Extracting hour\ntrain_data['Dep_hour'] = pd.to_datetime(train_data['Dep_Time']).dt.hour\n\n# Extracting minutes\ntrain_data['Dep_min'] = pd.to_datetime(train_data['Dep_Time']).dt.minute\n\n# Dropping the old Dep_Time column\n\ntrain_data.drop(['Dep_Time'], axis=1, inplace=True)","b31b0f75":"train_data.head()","8c0a1c7e":"# Prerforming same actions for 'Arrival_Time' column\n\n# Extracting hours\ntrain_data['Arrival_hour'] = pd.to_datetime(train_data['Arrival_Time']).dt.hour\n\n# Extracting minutes\ntrain_data['Arrival_mins'] = pd.to_datetime(train_data['Arrival_Time']).dt.minute\n\n# Dropping the old column\ntrain_data.drop(['Arrival_Time'], axis=1, inplace = True)","b35c37e2":"train_data.head()","73e5d852":"# Time taken by plane to reach destination is called Duration\n# It is the differnce betwwen Departure Time and Arrival time\n\n\n# Assigning and converting Duration column into list\nduration = list(train_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration","bd133398":"# Adding duration_hours and duration_mins list to train_data dataframe\n\ntrain_data[\"Duration_hours\"] = duration_hours\ntrain_data[\"Duration_mins\"] = duration_mins","2ce06e19":"train_data.drop(['Duration'], axis=1, inplace=True)","151c8d2f":"train_data.head()","065bffb8":"train_data.Airline.value_counts()","a30fc926":"plt.figure(figsize=(10,10))\nsns.barplot(x = 'Airline', y = 'Price', data=train_data)\nplt.legend()\nplt.xticks( rotation=90)","3d994936":"sns.distplot(train_data['Price'])","b88d2a43":"train_data.head()","aad4d406":"train_data.Total_Stops.value_counts()","5a2d118c":"train_data.groupby('Airline')['Price'].mean()","bdd0021d":"plt.figure(figsize=(10,10))\nsns.boxplot(x = 'Airline', y = 'Price', data=train_data)\nplt.xticks( rotation=90)","f160a31e":"train_data.groupby('Destination')['Price'].mean()","e07b1b87":"plt.figure(figsize=(10,10))\nsns.boxplot(x = 'Destination', y = 'Price', data=train_data)\nplt.xticks( rotation=45)","7b70a346":"# Hadeling the categorical features\n\ncat_features = [feature for feature in train_data.columns if train_data[feature].dtypes == 'O']\nlist(cat_features)","00e7c901":"train_data.head()","7e0a525e":"train_data.Total_Stops.value_counts()","7b6d87c6":"train_data.replace({'non-stop' : 0, '1 stop' : 1, '2 stops' : 2, '3 stops' : 3, '4 stops' : 4}, inplace = True)\ntrain_data.head()","464b6566":"train_data.drop(['Route', 'Additional_Info'], axis = 1, inplace = True)","b190cc64":"train_data.head()","59440429":"train_data.Airline.value_counts()","f9f06cbf":"train_data.head()","7d630eb7":"Airline = train_data[['Airline']]\n\nAirline = pd.get_dummies(Airline, drop_first = True)","c0c6c19f":"Source = train_data[['Source']]\n\nSource = pd.get_dummies(Source, drop_first = True)","d8b0e09c":"Destination = train_data[['Destination']]\n\nDestination = pd.get_dummies(Destination, drop_first = True)","a60c3f67":"train_data.drop(['Airline', 'Source', 'Destination'], axis = 1, inplace = True)\ntrain_data.head()","0b7f50bb":"df_train =  pd.concat([train_data, Airline, Source, Destination], axis = 1)","7bf765d1":"df_train.head()","4cd3e577":"df_train.isnull().any()","3c85d383":"test_data.head()","2257991e":"# Extracting day and month from 'Date_of_Journey' column.\n\n# Extracting day\ntest_data['Journey_day'] = pd.to_datetime(test_data['Date_of_Journey'], format=\"%d\/%m\/%Y\").dt.day\n\n# Extracting month\ntest_data['Journey_month'] = pd.to_datetime(test_data['Date_of_Journey'], format=\"%d\/%m\/%Y\").dt.month\n\n# Dropping the old column\ntest_data.drop('Date_of_Journey',axis = 1, inplace = True)\ntest_data.head()","f75f50fc":"# Extracting hours and mins from 'Dep_Time' column\n\n# Extracting hours\ntest_data['Dep_hour'] = pd.to_datetime(test_data['Dep_Time']).dt.hour\n\n# Extracting minutes\ntest_data['Dep_mins'] = pd.to_datetime(test_data['Dep_Time']).dt.minute\n\n# Dropping the old column\ntest_data.drop('Dep_Time', axis=1, inplace=True)\ntest_data.head()","269f8063":"# Prerforming same actions for 'Arrival_Time' column\n\n# Extracting hours\ntest_data['Arrival_hour'] = pd.to_datetime(test_data['Arrival_Time']).dt.hour\n\n# Extracting minutes\ntest_data['Arrival_mins'] = pd.to_datetime(test_data['Arrival_Time']).dt.minute\n\n# Dropping the old column\ntest_data.drop(['Arrival_Time'], axis=1, inplace = True)","1584e062":"# Similarly extracting hours and minutes form the 'Arrival_Time' column\n\n\n# It is the differnce betwwen Departure Time and Arrival time\n\n\n# Assigning and converting Duration column into list\nduration = list(test_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hours = []\nduration_mins = []\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration","23f95075":"# Adding duration_hours and duration_mins list to train_data dataframe\n\ntest_data[\"Duration_hours\"] = duration_hours\ntest_data[\"Duration_mins\"] = duration_mins","417a9bdd":"test_data.head()","4a21c41e":"test_data.Total_Stops.value_counts()","cc156c45":"test_data.replace({'non-stop' : 0, '1 stop' : 1, '2 stops' : 2, '3 stops' : 3, '4 stops' : 4}, inplace=True)\ntest_data.head()","426981f4":"test_data.Total_Stops.value_counts()","d5df3717":"Airline = test_data[['Airline']]\n\nAirline = pd.get_dummies(Airline, drop_first=True)","384b4914":"Source = test_data[['Source']]\n\nSource = pd.get_dummies(Airline, drop_first=True)","8edd4455":"Destination = test_data[['Destination']]\n\nDestination = pd.get_dummies(Destination, drop_first=True)","296c880e":"test_data.drop(['Airline', 'Source', 'Destination'], axis = 1, inplace = True)","3eb8270b":"df_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\ndf_test.head()","f621c3fe":"df_test.drop(['Route', 'Additional_Info', 'Duration'], axis = 1, inplace=True)","095cf75a":"df_test.head()","75978d16":"# Plotting a correlation matrix\n\nplt.figure(figsize=(30, 30))\nsns.heatmap(df_train.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","ea1bbe11":"highly_corr_features = df_train[df_train.corr() > 0.7]\n\nlist(highly_corr_features)","fbd3ef6a":"df_train.columns","8c9228f2":"# Splitting the data into Independent and dependent variables\n\nx = df_train[['Total_Stops', 'Journey_day', 'Journey_month', 'Dep_hour',\n       'Dep_min', 'Arrival_hour', 'Arrival_mins', 'Duration_hours',\n       'Duration_mins', 'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n       'Airline_Jet Airways', 'Airline_Jet Airways Business',\n       'Airline_Multiple carriers',\n       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n       'Destination_Kolkata', 'Destination_New Delhi']]\n\ny = df_train['Price']","76d63df7":"# Important feature using ExtraTreesRegressor\n\nfrom sklearn.ensemble import ExtraTreesRegressor\nselection = ExtraTreesRegressor()\nselection.fit(x, y)","1582558f":"print(selection.feature_importances_)","cc53f582":"#plot graph of feature importances for better visualization\n\nplt.figure(figsize = (12,8))\nfeat_importances = pd.Series(selection.feature_importances_, index=x.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","7a6e8577":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)","b67cc2a9":"from sklearn.tree import DecisionTreeRegressor\n\ntree = DecisionTreeRegressor(random_state=42)\ntree.fit(x_train, y_train)\n\n","a425d3f3":"dtree_pred = tree.predict(x_test)","9c04695a":"tree.score(x_train, y_train)","ea389997":"tree.score(x_test, y_test)","51b308f2":"sns.distplot(y_test-dtree_pred)","1ded36a9":"plt.scatter(y_test, dtree_pred, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"dtree prediction\")\nplt.show()","72f4c9da":"from sklearn import metrics","0e4d5835":"print('MAE:', metrics.mean_absolute_error(y_test, dtree_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, dtree_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, dtree_pred)))","e1169a82":"metrics.r2_score(y_test, dtree_pred)","0f79c797":"from sklearn.ensemble import RandomForestRegressor","23cfcd82":"rf = RandomForestRegressor()\nrf.fit(x_train, y_train)","70ae9944":"rf_pred = rf.predict(x_test)","6fccf8cb":"rf.score(x_train, y_train)","be6b4960":"rf.score(x_test, y_test)","77ecbe84":"sns.distplot(y_test-rf_pred)","b6c56c11":"plt.scatter(y_test, rf_pred, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"dtree prediction\")\nplt.show()","ac0174f7":"print('MAE:', metrics.mean_absolute_error(y_test, rf_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, rf_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rf_pred)))","af237ec7":"metrics.r2_score(y_test, rf_pred)","145a2fda":"from sklearn.model_selection import RandomizedSearchCV","1eb69857":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","fb1621ad":"# Create the random grid\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n","c68b09b2":"# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n","c39ea2a1":"rf_random.fit(x_train, y_train)","36374336":"rf_random.best_params_","442af0eb":"rf_prediction = rf_random.predict(x_test)","b7ba890b":"plt.figure(figsize = (8,8))\nsns.distplot(y_test-rf_prediction)\nplt.show()","a6a82a38":"plt.figure(figsize = (8,8))\nplt.scatter(y_test, rf_prediction, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","2f8738cf":"print('MAE:', metrics.mean_absolute_error(y_test, rf_prediction))\nprint('MSE:', metrics.mean_squared_error(y_test, rf_prediction))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rf_prediction)))","e05d0b45":"metrics.r2_score(y_test, rf_prediction)","264454dd":"import pickle\n# open a file, where you ant to store the data\nfile = open('flight_rf.pkl', 'wb')\n\n# dump information to that file\npickle.dump(rf, file)","fcb25b9e":"### Building our machine learning model","d4b3bd7c":"### Performing all the same steps for the test dataset","f90b73a4":"## Feature selection","3e82e7f2":"* From the above observatin we can see that Total_stops feature belongs to a ordinal data category so we need to one hot encode it","2f811549":"\n### Handling Categorical Data\n\nOne can find many ways to handle categorical data. Some of them categorical data are,\n\n  1.  **Nominal data** --> data are not in any order --> **OneHotEncoder** is used in this case\n  2.  **Ordinal data** --> data are in order --> **LabelEncoder** is used in this case\n\n","7f5d01e7":"## Hyperparameter tuning for Random Forest","9cd59052":"### Handeling the categorical features\n\n","01af0fd1":"### Using Random forest regressor","5831d768":"## Using Decision tree regressor\n\n  **Decision tree** : Decision Tree algorithm comes under supervised learning. The Decision tree algorithm can be used for both classification   and regression problem statements. The Decision tree works on if-then statement. The Decision tree tries to solve the problem in a tree representation i.e (nodes and leaf) representation. The input to the decision tree can be both categorical and categorical.\n  \nThis problem statement is basically a regression problem thats why we are using regressor method","28dbc2e5":"## Saving the model"}}