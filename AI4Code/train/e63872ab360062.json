{"cell_type":{"810f0298":"code","793741c0":"code","0e37aace":"code","acde2c87":"code","a9ad991f":"code","9d848efa":"code","56e6e169":"code","d2bd48b6":"code","de301294":"code","0c3a1e1f":"code","775a96da":"code","2a79fea2":"code","80bcd4e9":"code","2e726a8a":"code","0a75b759":"code","ad335830":"code","c7129712":"code","ba515106":"code","a98ca44e":"code","f82d7639":"code","3334c3a9":"code","9db774ac":"code","1a8f24cb":"code","c91b9c99":"code","c8276662":"code","cec6f4fa":"code","2c73ff0a":"code","4484fbd9":"code","60e63aae":"code","bd6f6f66":"code","e22e6941":"code","e858f623":"code","d4a44d7c":"code","7c10c70b":"code","20f38fa2":"code","8f4106d9":"code","3d980a34":"code","61307e58":"code","c8b7a506":"code","2feaed7c":"code","90d4852d":"code","4539071b":"markdown","fad5f586":"markdown","ce6be0fa":"markdown","66152b3b":"markdown","39555f28":"markdown","f9e0af0d":"markdown","df663408":"markdown"},"source":{"810f0298":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","793741c0":"train = pd.read_csv(\"\/kaggle\/input\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/test.csv\")\n\ntest_enrollee_id = test['enrollee_id']\nn_train = train.shape[0]\nn_test = test.shape[0]\n\ndata = pd.concat([train,test])\ndel data['enrollee_id']\n\nprint(data.shape)\nprint(n_train)\nprint(n_test)","0e37aace":"data.head()","acde2c87":"data.info()","a9ad991f":"count_classes = pd.value_counts(train['target'], sort=True)\ncount_classes.plot(kind='bar', rot=0)\nplt.title('Job change class Distribution')\nplt.xticks(range(2))\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.show()","9d848efa":"NoJobChange = len(train[train.target == 0])\nJobChange = len(train[train.target == 1])\nprint(\"No. of Employees not looking for job change: {}\".format(NoJobChange))\nprint(\"No. of Employees looking for job change: {}\".format(JobChange))\nprint(\"Percentage of Employees not looking for job change: {:.2f}%\".format((NoJobChange \/ (len(train.target))*100)))\nprint(\"Percentage of Employees looking for job change: {:.2f}%\".format((JobChange \/ (len(train.target))*100)))","56e6e169":"data.isnull().sum()","d2bd48b6":"percent_missing = data.isnull().sum() * 100 \/ len(data)\nmissing_value_df = pd.DataFrame({'percent_missing': percent_missing})\nmissing_value_df","de301294":"#Ratios in dataset\n\n\n#gender\nprint(\"Gender\\n\")\nmale = len(data[data.gender == \"Male\"])\nfemale = len(data[data.gender == \"Female\"])\nother = len(data[data.gender == \"Other\"])\n\nprint(\"Ratio of Male: {}\".format(male \/ 25894))\nprint(\"Ratio of Female: {}\".format(female \/ 25894))\nprint(\"Ratio of Other: {}\".format(other \/ 25894))\n\nprint(\"-\"*50)\n\n#major_discipline\nprint(\"Major discipline\\n\")\nSTEM = len(data[data.major_discipline == \"STEM\"])\nOther = len(data[data.major_discipline == \"Other\"])\nNo_Major = len(data[data.major_discipline == \"No Major\"])\nBusiness_Degree = len(data[data.major_discipline == \"Business Degree\"])\nArts = len(data[data.major_discipline == \"Arts\"])\nHumanities = len(data[data.major_discipline == \"Humanities\"])\n\n\nprint(\"Ratio of STEM: {}\".format(STEM \/ 28149))\nprint(\"Ratio of Other: {}\".format(Other \/ 28149))\nprint(\"Ratio of No Major: {}\".format(No_Major \/ 28149))\nprint(\"Ratio of Business Degree: {}\".format(Business_Degree \/ 28149))\nprint(\"Ratio of Arts: {}\".format(Arts \/ 28149))\nprint(\"Ratio of Humanities: {}\".format(Humanities \/ 28149))\n\n\nprint(\"-\"*50)\n\n\n#company_size\nprint(\"Company size\\n\")\n_100to500 = len(data[data.company_size == \"100-500\"])\n_less10 = len(data[data.company_size == \"<10\"])\n_50to99 = len(data[data.company_size == \"50-99\"])\n_5000to9999 = len(data[data.company_size == \"5000-9999\"])\n_10000plus = len(data[data.company_size == \"10000+\"])\n_1000to4999 = len(data[data.company_size == \"1000-4999\"])\n_10to49 = len(data[data.company_size == \"10\/49\"])\n_500to999 = len(data[data.company_size == \"500-999\"])\n\nprint(\"Ratio of 100-500: {}\".format(_100to500 \/ 24550))\nprint(\"Ratio of <10: {}\".format(_less10 \/ 24550))\nprint(\"Ratio of 50-99: {}\".format(_50to99 \/ 24550))\nprint(\"Ratio of 5000-9999: {}\".format(_5000to9999 \/ 24550))\nprint(\"Ratio of 10000+: {}\".format(_10000plus \/ 24550))\nprint(\"Ratio of 1000-4999: {}\".format(_1000to4999 \/ 24550))\nprint(\"Ratio of 10\/49: {}\".format(_10to49 \/ 24550))\nprint(\"Ratio of 500-999: {}\".format(_500to999 \/ 24550))\n\n\n\nprint(\"-\"*50)\n\n\n#company_type\nprint(\"Company type\\n\")\nPvt_Ltd = len(data[data.company_type == \"Pvt Ltd\"])\nFunded_Startup = len(data[data.company_type == \"Funded Startup\"])\nPublic_Sector = len(data[data.company_type == \"Public Sector\"])\nEarly_Stage_Startup = len(data[data.company_type == \"Early Stage Startup\"])\nNGO = len(data[data.company_type == \"NGO\"])\nOther = len(data[data.company_type == \"Other\"])\n\n\nprint(\"Ratio of Pvt Ltd: {}\".format(Pvt_Ltd \/ 24011))\nprint(\"Ratio of Funded Startup: {}\".format(Funded_Startup \/ 24011))\nprint(\"Ratio of Public Sector: {}\".format(Public_Sector \/ 24011))\nprint(\"Ratio of Early Stage Startup: {}\".format(Early_Stage_Startup \/ 24011))\nprint(\"Ratio of NGO: {}\".format(NGO \/ 24011))\nprint(\"Ratio of Other: {}\".format(Other \/ 24011))\n\n\nprint(\"-\"*50)","0c3a1e1f":"#Filling null values\n\n# gender\ndata['gender'] = data['gender'].fillna(pd.Series(np.random.choice(['Male', 'Female', 'Other'], \n                                                                    p=[0.90, 0.08, 0.02], size=len(data))))\n\n#enrolled_university\ndata['enrolled_university'] = data['enrolled_university'].fillna((data['enrolled_university'].mode()[0]))\n\n#education_level\ndata['education_level'] = data['education_level'].fillna((data['education_level'].mode()[0]))\n\n\n#major_discipline\ndata['major_discipline'] = data['major_discipline'].fillna(pd.Series(np.random.choice(['STEM', 'Other', 'No Major', \n'Business Degree', 'Arts', 'Humanities'], p=[0.88, 0.02, 0.01, 0.02, 0.02, 0.05], size=len(data))))\n\n\n#experience\ndata['experience'] = data['experience'].fillna((data['experience'].mode()[0]))\n\n\n#company_size\ndata['company_size'] = data['company_size'].fillna(pd.Series(np.random.choice(['100-500', '<10', '50-99',\n'5000-9999', '10000+', '1000-4999', '10\/49', '500-999' ], p=[0.2, 0.1, 0.24, 0.04, 0.15, 0.10, 0.1, 0.07],\n                                                                                size=len(data))))\n#company_type\ndata['company_type'] = data['company_type'].fillna(pd.Series(np.random.choice(['Pvt Ltd', 'Funded Startup',\n'Public Sector', 'Early Stage Startup', 'NGO', 'Other' ], p=[0.76, 0.08, 0.07, 0.04, 0.04, 0.01 ], size=len(data))))\n\n#last_new_job\ndata['last_new_job'] = data['last_new_job'].fillna((data['last_new_job'].mode()[0]))\n","775a96da":"#Label encoding\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\n\ndata['relevent_experience'] = labelencoder.fit_transform(data['relevent_experience'])\n\ndata['enrolled_university'] = labelencoder.fit_transform(data['enrolled_university'])\n\ndata['education_level'] = labelencoder.fit_transform(data['education_level'])\n\ndata['city'] = labelencoder.fit_transform(data['city'])\n","2a79fea2":"print(data.last_new_job.unique())\nprint(data.experience.unique())","80bcd4e9":"data.experience = data.experience.replace(\">20\", 21)\ndata.experience = data.experience.replace(\"<1\", 0)\n\ndata.last_new_job = data.last_new_job.replace(\">4\", 5)\ndata.last_new_job = data.last_new_job.replace(\"never\", 0)\n\ndata['experience'] = data['experience'].astype(str).astype(int)\ndata['last_new_job'] = data['last_new_job'].astype(str).astype(int)\n\ndata['training_hours'] = np.log(data['training_hours'])","2e726a8a":"#Since 'gender', 'major_discipline', 'company_size', 'company_type'  are categorical variables we'll turn them into dummy variables.\n\na = pd.get_dummies(data['gender'], prefix = \"gender\")\nb = pd.get_dummies(data['major_discipline'], prefix = \"major_discipline\")\nc = pd.get_dummies(data['company_size'], prefix = \"company_size\")\nd = pd.get_dummies(data['company_type'], prefix = \"company_type\")\n\n\nframes = [data, a, b, c, d]\ndata = pd.concat(frames, axis = 1)\n\ndata = data.drop(columns = ['gender', 'major_discipline', 'company_size', 'company_type' ])","0a75b759":"cols_data = list(data.columns.values)\ncols_data","ad335830":"#Rearrange column order\n\ndata = data[['city',\n 'city_development_index',\n 'education_level',\n 'enrolled_university',\n 'experience',\n 'last_new_job',\n 'relevent_experience',\n 'training_hours',\n 'gender_Female',\n 'gender_Male',\n 'gender_Other',\n 'major_discipline_Arts',\n 'major_discipline_Business Degree',\n 'major_discipline_Humanities',\n 'major_discipline_No Major',\n 'major_discipline_Other',\n 'major_discipline_STEM',\n 'company_size_10\/49',\n 'company_size_100-500',\n 'company_size_1000-4999',\n 'company_size_10000+',\n 'company_size_50-99',\n 'company_size_500-999',\n 'company_size_5000-9999',\n 'company_size_<10',\n 'company_type_Early Stage Startup',\n 'company_type_Funded Startup',\n 'company_type_NGO',\n 'company_type_Other',\n 'company_type_Public Sector',\n 'company_type_Pvt Ltd',\n 'target'\n]]","c7129712":"data.head()","ba515106":"X_cluster = data.iloc[:, 0:-1].values","a98ca44e":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X_cluster)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","f82d7639":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\ncluster = kmeans.fit_predict(X_cluster)","3334c3a9":"#train\ndata['cluster']= cluster\ndata.head()","9db774ac":"train_data = data.iloc[:n_train]\ntest_data = data.iloc[n_train:]\n\ndel test_data['target']\n\nprint(train_data.shape)\nprint(test_data.shape)","1a8f24cb":"y_train = train_data['target']\ndel train_data['target']\nx_train = train_data\n\nx_test = test_data","c91b9c99":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics.scorer import make_scorer\nfrom sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.feature_selection import SelectKBest, chi2","c8276662":"model = ExtraTreeClassifier()\nmodel.fit(x_train,y_train)\nfeature_imp = pd.DataFrame({'Feature' : x_train.columns, 'Score' : model.feature_importances_})\nfeature_imp.sort_values(by=['Score'], ascending=False)","cec6f4fa":"# Initialise the Scaler \nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler() \nx_train = scaler.fit_transform(x_train)","2c73ff0a":"from sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\nclass_weights_dict = dict(enumerate(class_weights))\nprint(class_weights_dict)","4484fbd9":"dt = DecisionTreeClassifier(class_weight=class_weights_dict)\n\nscores = cross_validate(dt, x_train, y_train, cv=2, scoring=make_scorer(roc_auc_score, average='weighted'))\nprint(scores['test_score'])\nprint(np.mean(scores['test_score']))","60e63aae":"rf = RandomForestClassifier(n_estimators=200, class_weight=class_weights_dict)\n\nscores = cross_validate(rf, x_train, y_train, cv=2, scoring=make_scorer(roc_auc_score, average='weighted'))\nprint(scores['test_score'])\nprint(np.mean(scores['test_score']))","bd6f6f66":"gb = GradientBoostingClassifier(n_estimators=200)\n\nscores = cross_validate(gb, x_train, y_train, cv=2, scoring=make_scorer(roc_auc_score, average='weighted'))\nprint(scores['test_score'])\nprint(np.mean(scores['test_score']))","e22e6941":"lr = LogisticRegression(random_state=0, class_weight=class_weights_dict)\n\nscores = cross_validate(lr, x_train, y_train, cv=2, scoring=make_scorer(roc_auc_score, average='weighted'))\nprint(scores['test_score'])\nprint(np.mean(scores['test_score']))","e858f623":"clf = lr","d4a44d7c":"clf.fit(x_train, y_train)","7c10c70b":"result = pd.DataFrame(data=test['enrollee_id'])\nresult.head()","20f38fa2":"test.head()","8f4106d9":"test = test.drop(['enrollee_id'], axis=1)","3d980a34":"x_test = scaler.transform(x_test)\npred = clf.predict(x_test)\nprint(pred)","61307e58":"test.shape","c8b7a506":"pred.shape","2feaed7c":"#Column addition\n\nresult['target']= pred\nresult.head(25)","90d4852d":"result.to_csv(\"prediction.csv\", index=False)","4539071b":"### column addition (clustering)","fad5f586":"## Algorithms","ce6be0fa":"## Exporting result to csv","66152b3b":"## Data preprocessing","39555f28":"A training institute which conducts training for analytics\/ data science wants to expand their business to manpower recruitment (data science only) as well.\n\nCompany gets large number of signups for their trainings. Now, company wants to connect these enrollees with their clients who are looking to hire employees working in the same domain. Before that, it is important to know which of these candidates are really looking for a new employment. They have student information related to demographics, education, experience and features related to training as well.\n\nTo understand the factors that lead a person to look for a job change, the agency wants you to design a model that uses the current credentials\/demographics\/experience to predict the probability of an enrollee to look for a new job.\n\n","f9e0af0d":"## Predicting final result of test set","df663408":"# HR Analytics Challenge\u00b6\n"}}