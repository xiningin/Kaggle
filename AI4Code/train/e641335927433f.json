{"cell_type":{"79647360":"code","ddcc711c":"code","a7eb8a44":"code","f286e48f":"code","d263d0db":"code","751e1964":"code","eba679ed":"code","c6930118":"code","1aa174cb":"code","9c49da23":"code","4780ac76":"code","721241e1":"code","3e18f005":"code","94151912":"code","2690db5e":"code","02fae228":"code","413a5a83":"markdown","8bf85c32":"markdown","0f59c201":"markdown","a41739b6":"markdown","829515a5":"markdown","d365c9fb":"markdown","23cf2e7a":"markdown","2950beee":"markdown","1f43ef91":"markdown"},"source":{"79647360":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport glob\nimport numpy as np","ddcc711c":"USA=np.load('..\/input\/ntt-data-global-ai-challenge-06-2020\/NTL-dataset\/npy\/USA.npy')\nUSA.shape","a7eb8a44":"plt.figure(figsize=(16,16))\nfor i, image in enumerate(USA[0:15]):\n    plt.subplot(5,3,i+1)\n    plt.imshow(image, 'gray')","f286e48f":"# calculate the total NTL value and add time axis\nUSA_total = []\nfor i, image in enumerate(USA):\n    USA_total.append(image.sum())\n\ndates = pd.date_range(start='1\/1\/2020', periods=len(USA), freq='D')\nUSA_total = pd.Series(USA_total, index=dates)\n\nplt.figure(figsize=(16,4))\nplt.plot(USA_total)\nplt.title(\"total value of NTL\", fontsize=16)","d263d0db":"# simple seasonal decomposition\nimport statsmodels.api as sm\nres = sm.tsa.seasonal_decompose(USA_total, period=30)\n\nplt.figure(figsize=(16, 8)) \n\nplt.subplot(411)\nplt.plot(USA_total)\nplt.ylabel('Original')\n\nplt.subplot(412)\nplt.plot(res.trend)\nplt.ylabel('Trend')\n\nplt.subplot(413) \nplt.plot(res.seasonal)\nplt.ylabel('Seasonality')\n\nplt.subplot(414)\nplt.plot(res.resid)\nplt.ylabel('Residuals')","751e1964":"plt.figure(figsize=(16,16))\nfor i, image in enumerate(USA[-45:-30]):\n    plt.subplot(5,3,i+1)\n    plt.imshow(image, 'gray')","eba679ed":"import cv2\n# external_contours is a black image\nexternal_contours = np.zeros(USA[-39,:,:].shape)\ntemp_image = USA[-39,:,:]\n\n# original\nplt.figure(figsize=(16,16))\nplt.subplot(1,3,1)\nplt.imshow(temp_image, 'gray')\nplt.title('original')\n\n#  If the pixel value is smaller than the maimum value, set it to 0.\nret, thresh = cv2.threshold(temp_image,temp_image.max()-1,temp_image.max(),cv2.THRESH_BINARY)\nplt.subplot(1,3,2)\nplt.imshow(thresh, 'gray')\nplt.title('thresh_binary')\n\n# find countours \ncontours, hierarchy = cv2.findContours(thresh.astype(np.uint8),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n\n# calculate each countour area and draw if it is larger than 500 pixels\nfor i, cnt in enumerate(contours):\n    area = cv2.contourArea(cnt)\n    if area >= 500:\n        cv2.drawContours(external_contours, contours, i, 255, -1)\n\nplt.subplot(1,3,3)\nplt.imshow(external_contours,cmap='gray')\nplt.title('contour area which is larger than 500 pixels') ","c6930118":"USA_nan = np.empty((0,794,1740), int)\nfor i, image in enumerate(USA):\n    image_nan = image.copy()\n\n    ret, thresh = cv2.threshold(image,image.max()-1,image.max(),cv2.THRESH_BINARY)\n    contours, hierarchy = cv2.findContours(thresh.astype(np.uint8),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n\n    for j, cnt in enumerate(contours):\n        area = cv2.contourArea(cnt)\n        if area >= 500:\n            image_nan = cv2.fillConvexPoly(image_nan, contours[j], (np.nan))\n    image_nan = image_nan[np.newaxis,:,:]\n    USA_nan = np.append(USA_nan, image_nan, axis=0)","1aa174cb":"plt.figure(figsize=(16,16))\nfor i, image in enumerate(USA_nan[-45:-30]):\n    plt.subplot(5,3,i+1)\n    plt.imshow(image, 'gray')","9c49da23":"# calculate the average NTL value and add time axis\nUSA_nan_avg = []\nfor i, image in enumerate(USA_nan):\n    USA_nan_avg.append(np.nanmean(image))\n\ndates = pd.date_range(start='1\/1\/2020', periods=len(USA), freq='D')\nUSA_nan_avg = pd.Series(USA_nan_avg, index=dates)\n\nplt.figure(figsize=(16,4))\nplt.plot(USA_nan_avg)\nplt.title(\"average value of NTL\", fontsize=16)","4780ac76":"z,y,x = USA_nan.shape\nUSA_resized = np.empty((0,int(y\/10),int(x\/10)), int)\n\nfor i, image in enumerate(USA_nan):\n    image_resized = cv2.resize(image,None,fx=0.1,fy=0.1,interpolation=cv2.INTER_AREA) \n    image_resized = image_resized[np.newaxis,:,:]\n    USA_resized = np.append(USA_resized, image_resized, axis=0)","721241e1":"plt.figure(figsize=(16,16))\nfor i, image in enumerate(USA_resized[-45:-30]):\n    plt.subplot(5,3,i+1)\n    plt.imshow(image, 'gray')","3e18f005":"z, y, x = USA_resized.shape\n\ndates = pd.date_range(start='1\/1\/2020', periods=z, freq='D')\nUSA_changed = pd.DataFrame()\n\nfor i in range(y):\n    for j in range(x):\n        time_series = pd.Series(USA_resized[:,i,j], index=dates)\n        # Check each pixel in chronological order, and if even one has a value of 0, set all to 0.\n        if (np.nanmin(time_series) == 0):\n            pixel_value = pd.Series(0,index=dates)\n        else:\n            # interpolate NAN value and replace it with the trend value\n            time_series.interpolate(method='index',limit_direction='both',inplace=True)\n            res = sm.tsa.seasonal_decompose(time_series, period=30)\n            pixel_value = res.trend\n        USA_changed = USA_changed.append(pixel_value, ignore_index=True)","94151912":"plt.figure(figsize=(16,16))\nfor i, image in enumerate(range(15)):\n    plt.subplot(5,3,i+1)\n    plt.imshow(USA_changed.iloc[:,i-45].values.reshape(y,x),'gray')","2690db5e":"plt.figure(figsize=(16, 4)) \nplt.plot(USA_changed.dropna(axis=1).sum())","02fae228":"# seems to be good, save the result\npd.to_pickle(USA_changed, \"..\/working\/USA_trend.pkl\")","413a5a83":"### Trend graph seems to be good since covid-19 has spread in the USA since mid-March.\n### The value has been risng since mid-May, Why?\u00b6","8bf85c32":"# Exploratory Data Analysis","0f59c201":"# remove moonlight and cloud from satellite image\n- Check each pixel in chronological order, and if even one has a value of 0, set that pixel to 0 in all chronological order.\n- Interpolate the NAN value with the previous and next values for each pixel\n- Calculate the trend value excluding seasonal fluctuation for each pixel and replace it with the calculated trend value","a41739b6":"### Missing values and clouds affected the total value of NTL","829515a5":"## consume too much memory and time, so resize all images to 1\/100","d365c9fb":"### The value that had been rising since mid-May was adjusted, but NAN value should be interpolated.","23cf2e7a":"## set missing values and cloud to NAN.","2950beee":"# Identify the missing values and cloud using cv2\n- extract maximum value of the image\n- If the pixel value is smaller than the maimum value, it is set to 0, otherwise it is set to a maximum value.\n- Find contours in a image and calculate a contour area.\n- if the calulaterd area is larger then 500 pixels, display the are.","1f43ef91":"### It is brighter in a cycle of about 29-30 days. Expected to be due to moonlight\n- The value seems to be falling as an overall trend, confirm it using simple seasonal decomposition \n- ToDo : The value has been risng since mid-May, analyze it later."}}