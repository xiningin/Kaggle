{"cell_type":{"cabd212d":"code","aa8e1801":"code","22aaa519":"code","d8c15cf0":"code","069b169d":"code","63432e49":"code","4b1ea014":"code","2a752783":"code","ba9c8cfd":"code","1066f2b8":"code","54a79a52":"code","fdc3e703":"code","b9516dd1":"code","0b92058b":"code","fb70f425":"code","672fdf79":"code","8ba3a8fb":"code","97486acf":"code","da8421ed":"code","88d1fe0e":"code","9732a3aa":"code","28ed721d":"code","e5c02a83":"code","f45d84f8":"code","988bd23f":"code","fecc7aa9":"code","79cd46b6":"code","d1509405":"code","e7b26d44":"code","8b52c228":"code","1ce70b86":"code","763f2b3f":"code","f828bc7b":"code","cbee91a1":"code","460f0f4c":"code","8009d272":"code","d2db2d1d":"code","d5da58c8":"code","135c2c38":"code","e315db7d":"code","caceb834":"code","2d3a805d":"markdown"},"source":{"cabd212d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa8e1801":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline","22aaa519":"url='..\/input\/students-performance-in-exams\/StudentsPerformance.csv'","d8c15cf0":"df=pd.read_csv(url)\ndf.head()","069b169d":"df.describe()","63432e49":"sns.pairplot(df)","4b1ea014":"sns.heatmap(df.corr())","2a752783":"data=df.gender.value_counts()\ndata.plot.pie(autopct=\"%.1f%%\")","ba9c8cfd":"data=df['race\/ethnicity'].value_counts()\ndata.plot.pie(autopct=\"%.1f%%\")","1066f2b8":"data=df['parental level of education'].value_counts()\ndata.plot.pie(autopct=\"%.1f%%\")","54a79a52":"data=df['lunch'].value_counts()\ndata.plot.pie(autopct=\"%.1f%%\")","fdc3e703":"data=df['test preparation course'].value_counts()\ndata.plot.pie(autopct=\"%.1f%%\")","b9516dd1":"sns.displot(df['math score'])\nsns.displot(df['reading score'])\nsns.displot(df['writing score'])","0b92058b":"sns.barplot(x=df['math score'],y=df['gender'])","fb70f425":"sns.barplot(x=df['reading score'],y=df['gender'])","672fdf79":"sns.barplot(x=df['writing score'],y=df['gender'])","8ba3a8fb":"sns.countplot(data=df,x='gender',hue='race\/ethnicity')","97486acf":"plt.figure(figsize=(10,10))\nsns.countplot(data=df,x='parental level of education',hue='race\/ethnicity')","da8421ed":"d=pd.get_dummies(df)","88d1fe0e":"d","9732a3aa":"d.drop(columns=['gender_female','race\/ethnicity_group E','parental level of education_some high school','lunch_standard','test preparation course_none'],inplace=True)","28ed721d":"d.head()","e5c02a83":"X=d.drop(columns=['gender_male'])\ny=d.gender_male","f45d84f8":"X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.2)","988bd23f":"model=LogisticRegression()","fecc7aa9":"model.fit(X_train,y_train)","79cd46b6":"y_predicted = model.predict(X_test)","d1509405":"model.score(X_test,y_test)","e7b26d44":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=39)","8b52c228":"knn.fit(X_train,y_train)","1ce70b86":"y_predicted = knn.predict(X_test)","763f2b3f":"from sklearn.metrics import classification_report,confusion_matrix\nprint(confusion_matrix(y_test,y_predicted))","f828bc7b":"print(classification_report(y_test,y_predicted))","cbee91a1":"knn.score(X_test,y_test)","460f0f4c":"error_rate = []\n\n# Will take some time\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","8009d272":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","d2db2d1d":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score","d5da58c8":"svc=SVC()","135c2c38":"svc.fit(X_train,y_train)","e315db7d":"y_predicted=svc.predict(X_test)","caceb834":"svc.score(X_test,y_test)","2d3a805d":"## 89.6% acccuracy with logistic regresion"}}