{"cell_type":{"9dd6a766":"code","9ebb12ef":"code","db106576":"code","0781ab31":"code","c6c9bfd7":"code","8746ad45":"code","83e87d64":"code","6b4ca7d4":"code","9c293f9f":"code","fc8f9842":"code","8bbbe5bb":"code","d7ca7533":"code","f3748345":"code","e0a1b2c1":"code","f256e4ba":"code","e99f350b":"code","cd13e701":"code","dea6890a":"code","407f8698":"code","39db0315":"code","c7cd39a2":"code","a928eaaa":"code","20f04825":"code","8638f72a":"code","cfd09546":"code","29f08c88":"code","323b2c3b":"code","afd6d492":"code","eb6af183":"code","10d3d176":"markdown","9964c535":"markdown","78199cec":"markdown","6ac34fe4":"markdown","d2b517cd":"markdown","2c93e6b0":"markdown","d67e9bbe":"markdown","1fc2a3c3":"markdown","3a79f1b6":"markdown","ba05a040":"markdown","244eae75":"markdown","cca0015a":"markdown","93855477":"markdown","70cec4de":"markdown","a2413123":"markdown","a34afc86":"markdown","0764f069":"markdown","527007d7":"markdown","6ce1ee62":"markdown","c6138f35":"markdown","8cb382c0":"markdown","6e28117e":"markdown","7dcde264":"markdown","b0e0f64f":"markdown","8e5888c1":"markdown","903c0ae1":"markdown","b075d673":"markdown","d2d534fb":"markdown","3dd36c6d":"markdown","914158a1":"markdown","a70de054":"markdown"},"source":{"9dd6a766":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom textblob import TextBlob, Word\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer","9ebb12ef":"cols = ['sentiment','id','date','query_string','user','text']\ndf = pd.read_csv('\/kaggle\/input\/sentiment140\/training.1600000.processed.noemoticon.csv', encoding='latin1', names=cols)","db106576":"df.head()","0781ab31":"df.tail()","c6c9bfd7":"df.sample(10)","8746ad45":"df.info()","83e87d64":"df.drop(columns=['id', 'date', 'query_string'], axis=1, inplace=True)","6b4ca7d4":"df['sentiment'].value_counts(normalize = True)","9c293f9f":"df['sentiment'] = df['sentiment'].replace({4:1})","fc8f9842":"max(df.text.str.len())","8bbbe5bb":"sum(df.text.str.len()>280) # False = 0 & True = 1\n#len(df[(df.text.str.len()>280) == True])","d7ca7533":"df[df.text.str.len()>280]['text']","f3748345":"df = df.drop(df[df.text.str.len()>280].index).reset_index(drop=True)","e0a1b2c1":"df['text'] = df['text'].str.lower()","f256e4ba":"df['text'] = df['text'].apply(lambda t: re.sub('@[^ ]+|#[^ ]+', '', t))","e99f350b":"#string.punctuation\ndf['text'] = df['text'].str.replace('[^A-Za-z0-9 ]', \"\")","cd13e701":"stop = stopwords.words('english')\nstop ","dea6890a":"type(stop)","407f8698":"stop.append('im')","39db0315":"stop","c7cd39a2":"my_stop_words = stop + ['im']","a928eaaa":"df['text'] = df['text'].apply(lambda t: \" \".join(word for word in t.split() if word not in stop))","20f04825":"df['text'][:5]","8638f72a":"st = PorterStemmer()\ndf['text'][:5].apply(lambda t: \" \".join([st.stem(word) for word in t.split()]))","cfd09546":"df['text'] = df['text'].apply(lambda t: \" \".join([Word(word).lemmatize() for word in t.split()]))","29f08c88":"neg_tweets = df.loc[df['sentiment']==0]\npos_tweets = df.loc[df['sentiment']==1]","323b2c3b":"neg_string = neg_tweets['text'].str.cat(sep=' ')\npos_string = pos_tweets['text'].str.cat(sep=' ')","afd6d492":"plt.figure(figsize=(12,10))\nwordcloud_neg = WordCloud(max_font_size=200, background_color=\"white\").generate(neg_string) \nplt.imshow(wordcloud_neg, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title(\"Tweets with Negative sentiment\");","eb6af183":"plt.figure(figsize=(12,10))\nwordcloud_pos = WordCloud(max_font_size=200, background_color=\"white\").generate(pos_string)\nplt.imshow(wordcloud_pos, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title(\"Tweets with Positive sentiment\");","10d3d176":"##### Non useful text removal:\n\nI will remove mentions and hashtags from tweets.","9964c535":"Now your data is cleaned and ready to do machine learning. \nBut wait!!! Computers only understand numbers! \n\nIn the next part, we will transform this text into numbers. See you soon:\")","78199cec":"##### Punctuation removal:","6ac34fe4":"Wordcloud fun's input needs to be a single string.","d2b517cd":"Let's do it on the first 5 rows!","2c93e6b0":"### Content\n\n- Data Exploration\n- Data Pre-Processing\n- Data Visualization","d67e9bbe":"##### What's the maximum length for tweets?\nThis is from twitter:\n***\"The current character limit for a tweet is 280 characters. The length of a tweet was expanded from a 140 character limit on November 7th, 2017.\"***\n\n","1fc2a3c3":"- Lemmatization is quite a similar process to stemming, with the main difference that with lemmatization, the resulting roots are valid words in the language. \n\n    `was --> be`,  \n    `better --> good`\n    \n    `argue, argued, argues, arguing, argus--> 'argue'`","3a79f1b6":"Stop words are words that occur too frequently and not considered informative.","ba05a040":"##### Lowercasing text","244eae75":"##### Lemmatization:","cca0015a":"Negative tweets labeled with 0 and Positive tweets labeled with 4. I will just edit the positive tweets label to be 1 (this is the convention).","93855477":"So you can append your custom stop words. Let's add `im` to our stop words list.","70cec4de":"#### The purpose of this tutorial is to explore text data and give you some sense of how to deal with text data in real-life problems. I will go deeper into modeling in another notebook.\n\n***Note: It's for beginners. It won't add too much if you worked with text data before.***","a2413123":"Let's take a look at these tweets!","a34afc86":"Let's looking at the summary of positive and negative tweets. I will visualize the data using word cloud.","0764f069":"### Preprocessing\n\n\n- Lowercasing text\n- Non useful text removal\n- Punctuation removal\n- Stop words removal\n- Stemming\n- Lemmatization","527007d7":"*How many tweets > maximum length?*","6ce1ee62":"### Data Visualization","c6138f35":"How long is the longest tweet?","8cb382c0":"- English stop words from nltk:","6e28117e":"Let's drop them!","7dcde264":"Stop words are now in **list** called `stop`. \n","b0e0f64f":"##### Stop words removal:","8e5888c1":"### Data Exploration","903c0ae1":"##### Stemming:","b075d673":"- Stemming is the transformation of words to their root forms. \n\n\n    `fishing, fished, fisher, fishes --> 'fish'`\n    \n- The stem need not be a word\n\n    `argue, argued, argues, arguing, argus--> 'argu'`\n\n\n- In general, stemming will tend to chop off affixes.","d2d534fb":"Lets import the necessary libs and load the dataet.","3dd36c6d":"Let's take a look on sentiment. How many positive and negative reviews?","914158a1":"From these info we can already see that the data has no missing values.\n\nThere are some features that won't be relevant in our analysis. Let's focus on text(tweets) and sentiment.\n","a70de054":"The data is balanced (# pos tweets = # neg tweets)"}}