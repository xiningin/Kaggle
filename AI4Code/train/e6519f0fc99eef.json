{"cell_type":{"f8b5ac29":"code","1af0a6f6":"code","ff07c48e":"code","e7753588":"code","f13cad56":"code","9bb0cef3":"code","675545ec":"code","c82a8b2b":"code","fa3566ec":"code","3639dfc9":"code","55123cfb":"code","d00df4ee":"code","f6f4c7ea":"code","58adb8f0":"code","a006b2b3":"code","4b978855":"code","40798b6e":"code","a837afc5":"code","832527c9":"code","716fe497":"code","6043c136":"code","ff16f5bd":"code","acb5f880":"code","691a9708":"code","1845b6be":"code","6b4483d1":"code","ef8fa5b0":"code","17b2472e":"code","cdf8eb3d":"code","b2629a7b":"code","562d496c":"code","3ac8d569":"markdown","70782f08":"markdown","c4ffae47":"markdown","5ceb721e":"markdown","08b8bdbe":"markdown","f1945199":"markdown","6dfefe8f":"markdown","0c711836":"markdown","01dfb97d":"markdown","f49ca30b":"markdown"},"source":{"f8b5ac29":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","1af0a6f6":"import pandas as pd\nimport numpy as np\nimport json\nimport PIL.Image, PIL.ImageFile\n\nPIL.ImageFile.LOAD_TRUNCATED_IMAGES = True\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.utils.mem import *","ff07c48e":"path = Path('\/kaggle\/input\/iwildcam-2020-fgvc7')\n\ndebug =1\nif debug:\n    train_pct=0.04\nelse:\n    train_pct=0.5\nbs=32","e7753588":"!ls \/kaggle\/input\/iwildcam-2020-fgvc7","f13cad56":"with open(path\/'iwildcam2020_train_annotations.json') as f:\n    train_data = json.load(f)\n    \nwith open(path\/'iwildcam2020_test_information.json') as f:\n    test_data = json.load(f)","9bb0cef3":"train_data.keys()","675545ec":"print( '#train_data')\nprint()\nfor key in train_data.keys():\n    print( 'length of', key, ':', len(train_data[key]) )\n    if key != 'info':\n        print( 'example:', train_data[key][0])\n    else:\n        print(train_data[key])\n    print()","c82a8b2b":"print( '#test_data')\nprint()\nfor key in test_data.keys():\n    print( 'length of', key, ':', len(test_data[key]) )\n    if key != 'info':\n        print( 'example:', test_data[key][0])\n    else:\n        print(test_data[key])\n    print()","fa3566ec":"df_train = pd.DataFrame.from_records(train_data['annotations'])\ndf_train","3639dfc9":"df_train = pd.DataFrame.from_records(train_data['annotations'])\ndf_train","55123cfb":"#df_image[df_image['id'] == '896c1198-21bc-11ea-a13a-137349068a90']\n#df_image[df_image['id'] == '8792549a-21bc-11ea-a13a-137349068a90']\n#df_image[df_image['id'] == '87022118-21bc-11ea-a13a-137349068a90']\n\n#df_image[df_image['seq_id'] == '98a295ba-21bc-11ea-a13a-137349068a90']\n#df_image[df_image['location'] == 537]['id'].values","d00df4ee":"df_image = pd.DataFrame.from_records(train_data['images'])\n\nindices = []\n#indices.append( df_train[ df_train['image_id'] == '896c1198-21bc-11ea-a13a-137349068a90' ].index )\n#indices.append( df_train[ df_train['image_id'] == '8792549a-21bc-11ea-a13a-137349068a90' ].index )\nfor _id in df_image[df_image['location'] == 537]['id'].values:\n    indices.append( df_train[ df_train['image_id'] == _id ].index )\n\nfor the_index in indices:\n    df_train = df_train.drop(df_train.index[the_index])","f6f4c7ea":"df_train[df_train['count']>1]","58adb8f0":"df_test = pd.DataFrame.from_records(test_data['images'])\ndf_test","a006b2b3":"df_test['frame_num'].value_counts()","4b978855":"df_test = df_test.rename(columns={\"id\": \"image_id\"})","40798b6e":"train, test = [ImageList.from_df(df, path=path, cols='image_id', folder=folder, suffix='.jpg') \n               for df, folder in zip([df_train, df_test], ['train', 'test'])]\ndata = (train.split_by_rand_pct(0.2, seed=2020)\n        .label_from_df(cols='category_id')\n        .add_test(test)\n        .transform(get_transforms(), size=32)\n        .databunch(path=Path('.'), bs=bs).normalize())","a837afc5":"if debug:\n    src= train.split_subsets(train_size=train_pct, valid_size= train_pct*2)\n#     test=test[:1000]\nelse:\n    src= train.split_subsets(train_size=train_pct, valid_size=0.2, seed=2)\n#     src= train.split_by_rand_pct(0.2, seed=2)\n\nprint(src)\n    \ndef get_data(size, bs, padding_mode='reflection'):\n    return (src.label_from_df(cols='category_id')\n           .add_test(test)\n           .transform(tfms, size=size, padding_mode=padding_mode)\n           .databunch(bs=bs).normalize(imagenet_stats))    ","832527c9":"tfms = get_transforms(max_rotate=20, max_zoom=1.3, max_lighting=0.4, max_warp=0.4,\n                      p_affine=1., p_lighting=1.)\n\ndata = get_data(224, bs, 'zeros')","716fe497":"def _plot(i,j,ax):\n    x,y = data.train_ds[3]\n    x.show(ax, y=y)\n\nplot_multi(_plot, 3, 3, figsize=(12,12))","6043c136":"!ls \/kaggle\/working\/","ff16f5bd":"gc.collect()\nwd=1e-2\n#learn = cnn_learner(data, models.densenet121, metrics=error_rate, bn_final=True, wd=wd )\nlearn = cnn_learner(data, models.resnet34, metrics=error_rate, bn_final=True, wd=wd )\nlearn.model_dir= '\/kaggle\/working\/'","acb5f880":"data = get_data(352,bs)\nlearn.data = data\nlearn.fit_one_cycle(6, max_lr=slice(1e-6,1e-4))\nlearn.save('352')","691a9708":"learn.unfreeze()","1845b6be":"lr = 1e-3\nlearn.fit_one_cycle(4, slice(lr\/100, lr))","6b4483d1":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","ef8fa5b0":"# %%time\n# interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","17b2472e":"test_preds = learn.get_preds(DatasetType.Test)\ndf_test['Category'] = test_preds[0].argmax(dim=1)","cdf8eb3d":"df_test.head()","b2629a7b":"df_test = df_test.rename(columns={\"image_id\": \"Id\"})\ndf_test = df_test.drop(['seq_num_frames', 'location', 'datetime', 'frame_num', 'seq_id', 'width', 'height', 'file_name'], axis=1)","562d496c":"submission = pd.read_csv('\/kaggle\/input\/iwildcam-2020-fgvc7\/sample_submission.csv')\nsubmission = submission.drop(['Category'], axis=1)\nsubmission = submission.merge(df_test, on='Id')\nsubmission.to_csv('submission.csv', index=False)","3ac8d569":"# Data Parsing","70782f08":"# interpretation","c4ffae47":"These images match with same seq_id, '98a295ba-21bc-11ea-a13a-137349068a90', '99136c90-21bc-11ea-a13a-137349068a90'\n\nand location 537\n\nI dropped images from 537 location","5ceb721e":"# Data Load","08b8bdbe":"# Train Model","f1945199":"The code\/model is based on [this kernel](https:\/\/www.kaggle.com\/tanlikesmath\/fastai-starter-iwildcam-2019) and uses a pretrained DenseNet121, along with Mixup as implemented by the fastai library.\n","6dfefe8f":"# Test Predictions","0c711836":"There are some images have more than 1 count","01dfb97d":"Drop the row which has the loading problem with PIL\n\nerror occured with '896c1198-21bc-11ea-a13a-137349068a90', '8792549a-21bc-11ea-a13a-137349068a90', and so on","f49ca30b":"There is no annotations in test_data as we expect"}}