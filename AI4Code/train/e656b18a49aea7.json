{"cell_type":{"57460323":"code","f531cef1":"code","2f5dd2b0":"code","75bebc31":"code","0a969950":"code","3b3d3e21":"code","292f5a7e":"code","5dcf1094":"code","b8551bba":"code","078dd26d":"code","76f7dc95":"code","d0723fc6":"code","ecd37f36":"code","133e6ece":"code","9a5e2f8e":"code","cfe72d53":"markdown"},"source":{"57460323":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f531cef1":"#Gerekli k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd\n#G\u00f6rselle\u015ftirme k\u00fct\u00fcphaneleri\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","2f5dd2b0":"items = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitems_categories = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nsales_train = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nsample_submission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\n\ntest.head() ","75bebc31":"items.columns,items_categories.columns,sales_train.columns,shops.columns","0a969950":"#Fiyat\u0131 10000 s\u0131n\u0131r\u0131n\u0131 a\u015fan \u00fcr\u00fcnler\nfiyat = sales_train[sales_train[\"item_price\"] > 10000]\nfiyat.drop(['shop_id','date','date_block_num','item_cnt_day'],inplace = True, axis = 1)\nfiyat","3b3d3e21":"print ('Dataset b\u00fcy\u00fckl\u00fc\u011f\u00fc:', sales_train.shape)\n#satislar = satislar[satislar['shop_id'].isin(test['shop_id'].unique())]\nsat\u0131\u015f = sales_train[sales_train['item_id'].isin(test['item_id'].unique())]\nprint ('Ayn\u0131 idli \u00fcr\u00fcnleri \u00e7\u0131kar\u0131nca dataset b\u00fcy\u00fckl\u00fc\u011f\u00fc:', sat\u0131\u015f.shape)","292f5a7e":"#ma\u011fazalar\u0131n  toplam sat\u0131\u015f grafi\u011fi\nsns.set_context(\"talk\", font_scale=0.8)\nma\u011faza_sat\u0131\u015f = pd.DataFrame(sales_train.groupby(['shop_id']).sum().item_cnt_day).reset_index()\nma\u011faza_sat\u0131\u015f.columns = ['shop_id', 'sum_sales']\nsns.barplot(x ='shop_id', y='sum_sales', data=ma\u011faza_sat\u0131\u015f, palette='Paired')\ndel ma\u011faza_sat\u0131\u015f\n","5dcf1094":"from datetime import datetime\nsales_train['year'] = pd.to_datetime(sales_train['date']).dt.strftime('%Y')\nsales_train['month'] = sales_train.date.apply(lambda x: datetime.strptime(x,'%d.%m.%Y').strftime('%m')) \n\n%matplotlib inline \n\ngrafik = pd.DataFrame(sales_train.groupby(['year','month'])['item_cnt_day'].sum().reset_index())\nsns.pointplot(x='month', y='item_cnt_day', hue='year', data=grafik)","b8551bba":"#Pivot tablosu\npivot = sales_train.copy()\npivot = pivot.pivot_table(index=['item_id','shop_id'],values='item_cnt_day',columns='date_block_num',fill_value=0,aggfunc='sum').reset_index()\npivot.head(10)","078dd26d":"pivot = pd.merge(test,pivot,on = ['shop_id','item_id'],how = 'left')\npivot.head(10)  #pivot datas\u0131 merge() ile test datas\u0131yla birle\u015ftirildi","76f7dc95":"#NaN de\u011ferler doldurulur\npivot.fillna(0,inplace = True)\npivot.head(10)","d0723fc6":"X_train = np.expand_dims(pivot.values[:,:-1],axis = 2)\ny_train = pivot.values[:,-1:]\nX_test = np.expand_dims(pivot.values[:,1:],axis = 2)\nprint(X_train.shape,y_train.shape,X_test.shape)\n","ecd37f36":"from keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom keras.models import load_model, Model\n\n# Sat\u0131\u015f modeli tan\u0131mlan\u0131r\nsatis_modeli = Sequential()\nsatis_modeli.add(LSTM(units = 64,input_shape = (33,1)))\nsatis_modeli.add(Dropout(0.5))\nsatis_modeli.add(Dense(1))\n\nsatis_modeli.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nsatis_modeli.summary()","133e6ece":"satis_modeli.fit(X_train,y_train,batch_size = 4096,epochs = 5)  #veri seti \u00e7ok b\u00fcy\u00fck oldu\u011fu i\u00e7in batch size 4096 al\u0131nd\u0131","9a5e2f8e":"cikti = satis_modeli.predict(X_test)\norneklem = pd.DataFrame({'ID':test['ID'],'tahmini_aylik_satis':cikti.ravel()})\n\norneklem.to_csv('tahmin.csv',index = False)\norneklem.head(50)","cfe72d53":" **LSTM**\n\nLong short term memory"}}