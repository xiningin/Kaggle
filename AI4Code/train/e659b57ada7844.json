{"cell_type":{"de9fe37c":"code","4db62389":"code","af53ad5c":"code","74ea3343":"code","eda07795":"code","5a918337":"code","547957b9":"code","ae46298f":"code","af4bc602":"code","48bce88a":"code","b3657ecd":"code","8fa3a6e4":"markdown","3492ef68":"markdown","89d73e69":"markdown","382e22b6":"markdown","003114bd":"markdown","9d3dfade":"markdown"},"source":{"de9fe37c":"!pip install iterative-stratification\n!pip install scikit-multilearn","4db62389":"import os\nimport time\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\nfrom skmultilearn.model_selection import IterativeStratification","af53ad5c":"DATASET_PATH = \"\/kaggle\/input\/bengaliai-cv19\/\"\nKEYS = [\"grapheme_root\", \"vowel_diacritic\", \"consonant_diacritic\"]\nTEST_SIZE = 0.1\nSEED = 69","74ea3343":"def get_csv(dataset_path, name):\n    return pd.read_csv(os.path.join(dataset_path, f\"{name}.csv\"))\n\n\ndef count(df):\n    return df.groupby(KEYS).size().reset_index().rename(columns={0: \"size\"})\n\n\ndef split(dataset_path, test_size, stratification):\n    df = get_csv(dataset_path, name=\"train\")\n    img_ids = df[\"image_id\"]\n\n    if stratification == \"sklearn_random\":\n        train_set, valid_set = train_test_split(df[KEYS], test_size=test_size,\n                                                random_state=SEED, shuffle=True)\n    elif stratification == \"sklearn_stratified\":\n        splitter = StratifiedShuffleSplit(n_splits=1,\n                                          test_size=test_size,\n                                          random_state=SEED)\n\n        train_indcs, valid_indcs = next(splitter.split(X=img_ids, y=df[KEYS]))\n        train_set = df.loc[df.index.intersection(train_indcs)].copy()\n        valid_set = df.loc[df.index.intersection(valid_indcs)].copy()\n        \n    elif stratification == \"iterstrat\":\n\n        splitter = MultilabelStratifiedShuffleSplit(n_splits=1,\n                                                    test_size=test_size,\n                                                    random_state=SEED)\n\n        train_indcs, valid_indcs = next(splitter.split(X=img_ids, y=df[KEYS]))\n        train_set = df.loc[df.index.intersection(train_indcs)].copy()\n        valid_set = df.loc[df.index.intersection(valid_indcs)].copy()\n\n    elif stratification == \"skmultilearn\":\n        \n        splitter = IterativeStratification(n_splits=2, order=2, \n                                           sample_distribution_per_fold=[\n                                               test_size, 1.0-test_size])\n        \n        train_indcs, valid_indcs = next(splitter.split(X=img_ids, y=df[KEYS]))\n        train_set = df.loc[df.index.intersection(train_indcs)].copy()\n        valid_set = df.loc[df.index.intersection(valid_indcs)].copy()\n        \n    else:\n        raise ValueError(\"Try something else :)\")\n\n    return train_set, valid_set\n\ndef eval(train, valid):\n    \n    train_count, val_count = count(train), count(valid)\n    \n    total = train_count[\"size\"] + val_count[\"size\"]\n    train_part = train_count[\"size\"] \/ total\n    val_part = val_count[\"size\"] \/ total\n    relative = val_part \/ train_part\n    \n    \n    for k, v in {\"Train\": train_part, \"Valid\": val_part, \n                 \"Valid relative to train\": relative}.items():\n        print(\"-------------------------------------------------------------------\")\n        print(k)\n        print(v)\n        print(\",\".join([f\"{m}: {f(v):.2}\" \n                        for m, f in {\"min\": np.min, \"max\": np.max, \n                                     \"mean\": np.mean, \"std\": np.std}.items()]))\n        print(\"-------------------------------------------------------------------\")","eda07795":"method = \"sklearn_random\"\n\n\nstart = time.time()\n\ntrain, valid = split(dataset_path=DATASET_PATH, \n                     test_size=TEST_SIZE, \n                     stratification=method)\n\nprint(f\"Dataset split done for {time.time() - start} seconds\")","5a918337":"eval(train, valid)","547957b9":"method = \"iterstrat\"\n\nstart = time.time()\n\ntrain, valid = split(dataset_path=DATASET_PATH, \n                     test_size=TEST_SIZE, \n                     stratification=method)\n\nprint(f\"Dataset split done for {time.time() - start} seconds\")","ae46298f":"eval(train, valid)","af4bc602":"# method = \"skmultilearn\"\n\n# start = time.time()\n\n# valid, train = split(dataset_path=DATASET_PATH, \n#                      test_size=TEST_SIZE, \n#                      stratification=method)\n\n# print(f\"Dataset split done for {time.time() - start} seconds\")","48bce88a":"method = \"sklearn_stratified\"\n\nstart = time.time()\n\ntrain, valid = split(dataset_path=DATASET_PATH, \n                     test_size=TEST_SIZE, \n                     stratification=method)\n\nprint(f\"Dataset split done for {time.time() - start} seconds\")","b3657ecd":"eval(train, valid)","8fa3a6e4":"Next method works veeeeery slow and also wrong, that's why I deleted it, but I left the code for you to try.","3492ef68":"As you can see, some validation triplets represent from 3% to 20% of the whole set, which seems to me not very stratified :)\n\nLet's see how other method works.","89d73e69":"As you can see only last method with sklearn.StratifiedShuffleSplit splits train and val in appropriate stratified sizes.","382e22b6":"And last method which stratify dataset which as for me suits much better.","003114bd":"Hello everyone!\n\nToday I'd like to show you that not all of splitting methods are good for our tasks.","9d3dfade":"Let's try the most famous random train_test_split and look what are the partitions for every class triplet."}}