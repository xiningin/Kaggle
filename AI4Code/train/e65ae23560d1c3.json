{"cell_type":{"a2640351":"code","59fd4771":"code","967fbb3e":"code","6126e6c4":"code","b7a7ae2b":"code","187647d7":"code","71d00de1":"code","99cb3d2e":"code","a0f7f6a7":"code","f89b7c7b":"code","d7f40ad6":"code","9435ee5a":"code","0e72c4d8":"code","6694d0c0":"code","31999946":"code","0e114ec7":"code","56c88707":"code","e2ec55c8":"code","95ab4dd9":"code","73abfa4d":"markdown","2ae0c5c4":"markdown","ffeaa333":"markdown","5ef21cde":"markdown","8a256a1b":"markdown","6f1653b9":"markdown","9dfeb0c4":"markdown","39ffc0f3":"markdown","29733a18":"markdown","8b6dd3ce":"markdown"},"source":{"a2640351":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nfrom matplotlib.image import imread\nfrom sklearn.metrics import classification_report\n#tensorflow modules\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping","59fd4771":"data = \"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/\"","967fbb3e":"os.listdir(data)","6126e6c4":"uninfected = len(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\"))\nparasitized = len(os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\"))\nprint(\"Uninfected: \",uninfected)\nprint(\"Parasitized: \", parasitized)","b7a7ae2b":"parasitized_data = os.listdir(\"..\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\")","187647d7":"sh=data+\"\/Parasitized\"+\"\/C99P60ThinF_IMG_20150918_141001_cell_133.png\"\nprint(\"Shape of image: \",imread(sh).shape)","71d00de1":"plt.figure(figsize=(14,14))\nimport random, cv2\nfor i in range(6):\n    plt.subplot(2,6,i+1)\n    type1=\"Uninfected\"\n    imgdir = data+ type1\n    imgfile = np.random.choice(os.listdir(imgdir))\n    img = cv2.imread(imgdir+\"\/\"+imgfile)\n    plt.imshow(img)\n    plt.title(type1)\nplt.show()","99cb3d2e":"plt.figure(figsize=(14,14))\nfor i in range(6):\n    plt.subplot(2,6,i+1)\n    type2=\"Parasitized\"\n    imgdir = data+ type2\n    imgfile = np.random.choice(os.listdir(imgdir))\n    img = cv2.imread(imgdir+\"\/\"+imgfile)\n    plt.imshow(img)\n    plt.title(type2)\nplt.show()","a0f7f6a7":"image_gen = ImageDataGenerator(rotation_range=20,\n                               width_shift_range=0.1,\n                               shear_range=0.1,\n                               fill_mode=\"nearest\")","f89b7c7b":"train = tf.keras.preprocessing.image_dataset_from_directory(data,\n                                                            validation_split=0.2,\n                                                            seed=123,\n                                                            subset=\"training\",\n                                                            image_size=(134,131),\n                                                            batch_size=32)\ntest = tf.keras.preprocessing.image_dataset_from_directory(data,\n                                                           validation_split=0.2,\n                                                           seed=123,\n                                                           subset=\"validation\",\n                                                           image_size=(134,131),\n                                                           batch_size=32)","d7f40ad6":"test.class_names","9435ee5a":"# defining sequential model\nmodel = Sequential()\n\n#adding convo-pool layers\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=(134,131,3),activation='relu',padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=(134,131,3),activation='relu',padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),input_shape=(134,131,3),activation='relu',padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3),input_shape=(134,131,3),activation='relu',padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))\n\n# flattening image\nmodel.add(Flatten())\n\n# adding dense layers\nmodel.add(Dense(128,activation='relu'))\n# adding dropout to minimize overfitting issue\nmodel.add(Dropout(0.2))\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\n\n#compiling the model\nmodel.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=[\"accuracy\"])\n\n#summary of the model\nmodel.summary()","0e72c4d8":"early_stop = EarlyStopping(monitor=\"val_loss\",patience=5, verbose=True)","6694d0c0":"history = model.fit(train,validation_data=test,epochs=20,callbacks=[early_stop],verbose=True)","31999946":"acc = history.history[\"accuracy\"]\nloss = history.history[\"loss\"]\n\nval_acc = history.history[\"val_accuracy\"]\nval_loss = history.history[\"val_loss\"]\n\nplt.figure(figsize=(8,8))\nplt.subplot(2,1,1)\nplt.plot(acc,label=\"Training accuracy\")\nplt.plot(val_acc, label=\"Validation Accuracy\")\nplt.legend()\nplt.ylabel(\"Accuracy\", fontsize=12)\nplt.title(\"Training and Validation Accuracy\", fontsize=12)\nplt.show()","0e114ec7":"plt.figure(figsize=(8,8))\nplt.subplot(2,1,1)\nplt.plot(loss, label=\"Training Loss\")\nplt.plot(val_loss, label = \"Validation Loss\")\nplt.legend()\nplt.ylabel(\"Loss\", fontsize=12)\nplt.title(\"Training and Validation Loss\",fontsize=12)\nplt.show()","56c88707":"model.evaluate(test, verbose=1)","e2ec55c8":"from sklearn.metrics import accuracy_score\npred = model.predict_classes(test)","95ab4dd9":"pred[:10]","73abfa4d":"# CNN Model (Convolutional Neural Network):\n<div class=\"alert alert-box alert-info\">\n* A Convolutional Neural Network (ConvNet\/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects\/objects in the image and be able to differentiate one from the other.\n <\/div>\n \n ![conv2d.png](attachment:a1eb714f-315f-434a-9812-be884a3d0ba1.png)","2ae0c5c4":"# **Malaria Images**\n![malaria.jpeg](attachment:342d976a-3a4a-4c89-88eb-b5934cb8eb87.jpeg)","ffeaa333":"# Image Manipulation","5ef21cde":"## Shape of Images","8a256a1b":"# Importing Modules\n![tensor.png](attachment:221052c1-20bd-4038-bd29-0635c55d2b8f.png)","6f1653b9":"# Images of Paratisitized","9dfeb0c4":"## Count of Images for Uninfected and Parasitized","39ffc0f3":"<div class=\"alert alert-block alert-warning\"> \nPlease UPVOTE if you find this notebook insightful!\n\nThanks in advance.\n<\/div>","29733a18":"# Images of Uninfected","8b6dd3ce":"## Implementing Early stop method"}}