{"cell_type":{"18dad428":"code","7e800264":"code","98f2cf26":"code","0ed9f795":"code","1f61dd56":"code","d7abcef7":"code","aa084a1a":"code","70496164":"code","800805ac":"code","bf7510a7":"code","9d0f1e82":"code","cc2be0ef":"code","49df273c":"markdown","44fb20b2":"markdown","c44709fa":"markdown","387a77e8":"markdown","c3fb2c7e":"markdown","bb47f8ae":"markdown","5100d7f5":"markdown","fadae744":"markdown","4c2ed39f":"markdown","f970e1af":"markdown"},"source":{"18dad428":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4\/ -f .\/ --no-index","7e800264":"import os\nimport cv2\nimport json\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nimport detectron2\nfrom tqdm.auto import tqdm\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.evaluation import inference_on_dataset\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.data import DatasetCatalog, build_detection_test_loader\nimport pycocotools.mask as mask_util\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom fastcore.all import *\nfrom ensemble_boxes import *\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' \nif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\n    print('GPU is available')\nelse:\n    DEVICE = torch.device('cpu')\n    print('CPU is used')\nprint('detectron ver:', detectron2.__version__)","98f2cf26":"best_model=(\n    {'file': '50_FPN_3x_F3_R82_300.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml', 'LB score': 0.300,'ths':[.18, .38, .58]},\n    {'file': '32x8d_FPN_3x_F3_R57_295.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml', 'LB score': 0.295,'ths':[.19, .39, .57]},\n    {'file': '50_FPN_3x_F5_ATTT32_300.pth','config_name':'COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml', 'LB score': 0.300,'ths':[.19, .39, .57]}\n            )","0ed9f795":"#config_name = \"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"\nmdl_path = \"..\/input\/dtectron2-models-5fold\"\nDATA_PATH = \"..\/input\/sartorius-cell-instance-segmentation\"\nMODELS = []\nBEST_MODELS =[]\nTHSS = []\nID_TEST = 0\nSUBM_PATH = f'{DATA_PATH}\/test'\nSINGLE_MODE = False\nNMS = True\nMIN_PIXELS = [75, 150, 75]\nIOU_TH = 0.3\nfor b_m in best_model:\n    model_name=b_m[\"file\"]\n    model_ths=b_m[\"ths\"]\n    config_name=b_m[\"config_name\"]\n    BEST_MODELS.append(model_name)\n    THSS.append(model_ths)\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(config_name))\n    cfg.INPUT.MASK_FORMAT = 'bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n    cfg.MODEL.WEIGHTS = f'{mdl_path}\/{model_name}'  \n    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n    MODELS.append(DefaultPredictor(cfg))\nprint(f'all loaded:\\nthresholds: {THSS}\\nmodels: {BEST_MODELS}')","1f61dd56":"MODELS","d7abcef7":"def rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) \n                       for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    \n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef pred_masks(file_name, path, model, ths, min_pixels):\n    img = cv2.imread(f'{path}\/{file_name}')\n    output = model(img)\n    pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n    pred_class = max(set(pred_classes), key=pred_classes.count)\n    take = output['instances'].scores >= ths[pred_class]\n    pred_masks = output['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    result = []\n    used = np.zeros(img.shape[:2], dtype=int) \n    for i, mask in enumerate(pred_masks):\n        mask = mask * (1 - used)\n        if mask.sum() >= min_pixels[pred_class]:\n            used += mask\n            result.append(rle_encode(mask))\n    return result\n\ndef ensemble_preds(file_name, path, models, ths):\n    img = cv2.imread(f'{path}\/{file_name}')\n    classes = []\n    scores = []\n    bboxes = []\n    masks = []\n    for i, model in enumerate(models):\n        output = model(img)\n        pred_classes = output['instances'].pred_classes.cpu().numpy().tolist()\n        pred_class = max(set(pred_classes), key=pred_classes.count)\n        take = output['instances'].scores >= ths[i][pred_class]\n        classes.extend(output['instances'].pred_classes[take].cpu().numpy().tolist())\n        scores.extend(output['instances'].scores[take].cpu().numpy().tolist())\n        bboxes.extend(output['instances'].pred_boxes[take].tensor.cpu().numpy().tolist())\n        masks.extend(output['instances'].pred_masks[take].cpu().numpy())\n    assert len(classes) == len(masks) , 'ensemble lenght mismatch'\n    #scores, classes, bboxes, masks = zip(*sorted(zip(scores, classes, bboxes, masks),reverse=True))\n    return classes, scores, bboxes, masks\n\ndef nms_predictions(classes, scores, bboxes, masks, \n                    iou_th=0.3, shape=(520, 704)):\n    he, wd = shape[0], shape[1]\n    boxes_list = [[x[0] \/ wd, x[1] \/ he, x[2] \/ wd, x[3] \/ he]\n                  for x in bboxes]\n    scores_list = [x for x in scores]\n    labels_list = [x for x in classes]\n    nms_bboxes, nms_scores, nms_classes = nms(\n        boxes=[boxes_list], \n        scores=[scores_list], \n        labels=[labels_list], \n        weights=None,\n        iou_thr=iou_th\n    )\n    nms_masks = []\n    for s in nms_scores:\n        nms_masks.append(masks[scores.index(s)])\n    nms_scores, nms_classes, nms_masks = zip(*sorted(zip(nms_scores, nms_classes, nms_masks), reverse=True))\n    return nms_classes, nms_scores, nms_masks\n\ndef ensemble_pred_masks(masks, classes, min_pixels, shape=(520, 704)):\n    result = []\n    pred_class = max(set(classes), key=classes.count)\n    used = np.zeros(shape, dtype=int) \n    for i, mask in enumerate(masks):\n        mask = mask * (1 - used)\n        if mask.sum() >= min_pixels[pred_class]:\n            used += mask\n            result.append(rle_encode(mask))\n    return result","aa084a1a":"test_names = os.listdir(SUBM_PATH)\nprint('test images:', len(test_names))","70496164":"encoded_masks_single = pred_masks(\n    test_names[ID_TEST], \n    path=SUBM_PATH, \n    model=MODELS[0],\n    ths=THSS[0],\n    min_pixels=MIN_PIXELS\n)","800805ac":"classes, scores, bboxes, masks = ensemble_preds(\n    file_name=test_names[ID_TEST] , \n    path=SUBM_PATH, \n    models=MODELS, \n    ths=THSS\n)\nif NMS:\n    classes, scores, masks = nms_predictions(\n        classes, \n        scores, \n        bboxes,\n        masks, iou_th=IOU_TH\n    )\nencoded_masks = ensemble_pred_masks(masks, classes, min_pixels=MIN_PIXELS)","bf7510a7":"_, axs = plt.subplots(2, 2, figsize=(14, 8))\naxs[0][0].imshow(cv2.imread(f'{SUBM_PATH}\/{test_names[ID_TEST]}'))\naxs[0][0].axis('off')\naxs[0][0].set_title(test_names[ID_TEST])\nfor en_mask in encoded_masks_single:\n    dec_mask = rle_decode(en_mask)\n    axs[0][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n    axs[0][1].axis('off')\n    axs[0][1].set_title('single model')\naxs[1][0].imshow(cv2.imread(f'{SUBM_PATH}\/{test_names[ID_TEST]}'))\naxs[1][0].axis('off')\naxs[1][0].set_title(test_names[ID_TEST])\nfor en_mask in encoded_masks:\n    dec_mask = rle_decode(en_mask)\n    axs[1][1].imshow(np.ma.masked_where(dec_mask == 0, dec_mask))\n    axs[1][1].axis('off')\n    axs[1][1].set_title('ensemble models')\nplt.show()","9d0f1e82":"subm_ids, subm_masks = [], []\nfor test_name in tqdm(test_names):\n    if SINGLE_MODE:\n        encoded_masks = pred_masks(\n            test_name, \n            path=SUBM_PATH, \n            model=MODELS[0],\n            ths=THSS[0],\n            min_pixels=MIN_PIXELS\n        )\n    else:\n        classes, scores, bboxes, masks = ensemble_preds(\n            file_name=test_name, \n            path=SUBM_PATH, \n            models=MODELS, \n            ths=THSS\n        )\n        if NMS:\n            classes, scores, masks = nms_predictions(\n                classes, \n                scores, \n                bboxes, \n                masks, \n                iou_th=IOU_TH\n            )\n        encoded_masks = ensemble_pred_masks(\n            masks, \n            classes, \n            min_pixels=MIN_PIXELS\n        )\n    for enc_mask in encoded_masks:\n        subm_ids.append(test_name[:test_name.find('.')])\n        subm_masks.append(enc_mask)","cc2be0ef":"pd.DataFrame({\n    'id': subm_ids, \n    'predicted': subm_masks\n}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","49df273c":"## Inference","44fb20b2":"# References\n1. https:\/\/www.kaggle.com\/vgarshin\/detectron2-inference-with-ensemble-and-nms","c44709fa":"## Other notebooks in this competition \n- [Sartorius Segmentation - Keras U-Net[Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-training)\n- [Sartorius Segmentation - Keras U-Net[Inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-inference\/edit)","387a77e8":"## Demo inference","c3fb2c7e":"## Utils","bb47f8ae":"## Install and import libraries","5100d7f5":"# Intro\nEnsembling multiple weaker performing models can help to get the results that you want.","fadae744":"# Ensemble NMS - Detectron2 [Inference]","4c2ed39f":"## My Models","f970e1af":"### Hi kagglers, This is `Ensemble NMS - Detectron2 [Inference]` notebook.\n* [Sartorius Segmentation - Detectron2 [training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-detectron2-training) \n* [Sartorius Segmentation - Detectron2 [Inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-detectron2-inference) \n* [K-fold CrossValidation COCO Dataset Generator](https:\/\/www.kaggle.com\/ammarnassanalhajali\/k-fold-crossvalidation-coco-dataset-generator) \n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>"}}