{"cell_type":{"dd978dd1":"code","dfe7bfa3":"code","f5285a18":"code","49a526ee":"code","fca3306c":"code","ce76f3ef":"code","6571aa1f":"code","f3dd5896":"code","b8b29cfe":"code","06d93a54":"code","b235be48":"code","7b87ddcc":"code","93aeb3de":"code","7c7af25c":"code","4141000a":"code","56678131":"code","6b9016d1":"code","3b9fece9":"code","a75f084d":"markdown","2bf68552":"markdown","b1b13399":"markdown","912b80f1":"markdown"},"source":{"dd978dd1":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\nimport matplotlib.pyplot as plt\n","dfe7bfa3":"# Load the training dataset\ntrain_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain_df.head()","f5285a18":"# Create labels array, Onehot encoding the labels\n\ndata_y = train_df['label'].values\nonehot_y = to_categorical(data_y, num_classes = 10)","49a526ee":"# Create features array, Reshape samples to create images \n\ndata_x = train_df.drop(columns=['label']).values\ndata_x = data_x.reshape(-1, 28, 28, 1)\ndata_x.shape","fca3306c":"# Model expects 32x32x1 we have 28x28x1 so lets get padding\npadded_x = np.zeros(shape=(data_x.shape[0], 32, 32, 1), dtype=np.float32)\npadded_x[:, 2:30, 2:30, :] = data_x\npadded_x \/= 255\npadded_x.shape","ce76f3ef":"X_train, X_test, y_train, y_test = train_test_split(padded_x, onehot_y, test_size=0.2, random_state=42)","6571aa1f":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","f3dd5896":"# Get our model \nmodel = EfficientNetB0(weights=None, input_shape=(32, 32, 1), classes=10)\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","b8b29cfe":"# Define the learning rate reducer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n","06d93a54":"# Define the model checkpoint tool\ncheckpoint = ModelCheckpoint(\"checkpoint_file\",\n                             monitor='val_loss',\n                             verbose=0,\n                             save_best_only=True,                          \n                             save_weights_only=True,\n                             mode='auto',\n                             save_freq='epoch',\n                             options=None)","b235be48":"# Train the model\ntf.config.run_functions_eagerly(True)\n\nhist = model.fit(datagen.flow(X_train,y_train, batch_size=86),\n                 epochs=30,\n                 validation_data=(X_test, y_test),\n                 verbose=1,\n                 steps_per_epoch=X_train.shape[0] \/\/ 86,\n                 callbacks=[checkpoint, learning_rate_reduction])","7b87ddcc":"# Load the best weights\nmodel.load_weights('checkpoint_file')","93aeb3de":"# Test the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(accuracy, loss)","7c7af25c":"# Graph the outputs\nhist_dict = hist.history\nfig, ax = plt.subplots(2)\nax[0].plot(hist_dict['accuracy'], c='blue')\nax[0].plot(hist_dict['val_accuracy'], c='orange')\nax[0].grid()\nax[1].plot(hist_dict['loss'], c='blue')\nax[1].plot(hist_dict['val_loss'], c='orange')\nax[1].grid()","4141000a":"# Do the same processes for test data\ntest_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest_x = test_df.values\ntest_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\n\npadded_test_x = np.zeros(shape=(test_x.shape[0], 32, 32, 1), dtype=np.float32)\npadded_test_x[:, 2:30, 2:30, :] = test_x\npadded_test_x \/= 255\n","56678131":"# Predict for the test data\npredictions = model.predict(padded_test_x, batch_size=32, verbose=1)","6b9016d1":"# Get the most likely answer for each sample\npred = np.argmax(predictions, axis=1)","3b9fece9":"test_df = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\ntest_df['Label'] = pred\ntest_df.to_csv('submission.csv', index=False)","a75f084d":"# Preprocessing","2bf68552":"# Prediction","b1b13399":"# Digit Recognizer using EfficientNet","912b80f1":"# Training"}}