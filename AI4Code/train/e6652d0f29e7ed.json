{"cell_type":{"0865cc6e":"code","bd73b3e7":"code","63a5756b":"code","3956f698":"code","31353bc4":"code","88d367c1":"code","8bcb54e5":"code","cda744d0":"code","1fee673c":"code","aefffd20":"code","112db22e":"code","f9e4ec60":"code","4545fa2c":"code","613c612f":"code","13fdf30a":"code","5c23b47b":"code","0aa20dbb":"code","b036f4e7":"code","2690d3f9":"code","c03dd34d":"code","b39bae2e":"code","451fcf48":"code","61fc0267":"code","e491e03f":"code","5b3be928":"code","ebee18c1":"code","00cccbcb":"code","e89523fc":"code","e8ab8db8":"code","2ee8dc2a":"markdown"},"source":{"0865cc6e":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor","bd73b3e7":"data = pd.read_csv(\"..\/input\/cardataset\/data.csv\")\ndata","63a5756b":"duplicate_rows_df = data[data.duplicated()]\nprint(\"number of dupicate rows:\", duplicate_rows_df.shape)","3956f698":"data.count()","31353bc4":"data = data.drop_duplicates()\ndata.head(5)","88d367c1":"data.count()","8bcb54e5":"data = data.dropna()    # Dropping the missing values.\ndata.count()","cda744d0":"print(data.isnull().sum())  ","1fee673c":"sns.boxplot( x=data['Engine HP'] )","aefffd20":"sns.boxplot( x=data['Engine Cylinders'] )","112db22e":"Q1 = data.quantile(0.25)\nQ3 = data.quantile(0.75)\nIQR = Q3 - Q1  #interquantile range \nprint(IQR)","f9e4ec60":"data = data[~((data< (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\ndata.shape","4545fa2c":"data.Make.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\nplt.title(\"Number of cars by make\")\nplt.ylabel('Number of cars')\nplt.xlabel('Make');","613c612f":"plt.figure(figsize=(10,5))\nc = data.corr()\nsns.heatmap(c,cmap='BrBG', annot= True)\nc","13fdf30a":"fig, ax = plt.subplots(figsize=(10,6))\nax.scatter(data['Engine HP'], data['MSRP'])\nax.set_xlabel('HP')\nax.set_ylabel('Price')\nplt.show()","5c23b47b":"cols_new = ['Engine HP','Engine Cylinders']\nfor column in cols_new:\n   plt.figure(figsize=(8,5))\n   sns.boxplot(x=data[column])\n   plt.title(f'Boxplot for {column}')\n   plt.show()","0aa20dbb":"data.head(5)","b036f4e7":"data.loc[data['city mpg'].sort_values(ascending=True).index].head(10)[['Make','Model','Year','highway MPG','city mpg','MSRP']]","2690d3f9":"data.info()","c03dd34d":"def multihot_encode(df, column):\n    df = df.copy()\n    \n    df[column] = df[column].apply(lambda x: x.split(','))\n    \n    all_categories = np.unique(df[column].sum())\n    \n    for category in all_categories:\n        df[column + '_' + category] = df.apply(lambda x: 1 if category in x[column] else 0, axis=1)\n    \n    df = df.drop(column, axis=1)\n    \n    return df","b39bae2e":"def onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","451fcf48":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Fill multi-hot column missing values\n    df['Market Category'] = df['Market Category'].fillna(\"Missing\")\n    \n    # Multi-hot encoding\n    df = multihot_encode(df, column='Market Category')\n    \n    # One-hot encoding\n    for column in df.select_dtypes('object').columns:\n        df = onehot_encode(df, column=column)\n    \n    # Fill remaining missing values\n    df['Engine HP'] = df['Engine HP'].fillna(df['Engine HP'].mean())\n    for column in ['Engine Cylinders', 'Number of Doors']:\n        df[column] = df[column].fillna(df[column].mode()[0])\n    \n    # Split df into X and y\n    y = df['MSRP']\n    X = df.drop('MSRP', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","61fc0267":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","e491e03f":"X_train","5b3be928":"y_train","ebee18c1":"n_components = 100\n\npca = PCA(n_components=n_components)\npca.fit(X_train)\n\nX_train_reduced = pd.DataFrame(pca.transform(X_train), index=X_train.index, columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])\nX_test_reduced = pd.DataFrame(pca.transform(X_test), index=X_test.index, columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])","00cccbcb":"X_train_reduced","e89523fc":"models = {\n    \"                     Linear Regression\": LinearRegression(),\n    \" Linear Regression (L2 Regularization)\": Ridge(),\n    \" Linear Regression (L1 Regularization)\": Lasso(),\n    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor()\n}\n\nfor name, model in models.items():\n    model.fit(X_train_reduced, y_train)\n    print(name + \" trained.\")","e8ab8db8":"for name, model in models.items():\n    print(name + \" R^2 Score: {:.5f}\".format(model.score(X_test_reduced, y_test)))","2ee8dc2a":"# **Exploratory Data Analysis**"}}