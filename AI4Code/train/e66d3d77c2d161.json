{"cell_type":{"d49eac23":"code","801195f9":"code","9b4c2c5a":"code","20ccce3a":"code","5947c6b7":"code","bd341687":"markdown"},"source":{"d49eac23":"from multiprocessing import Pool\nimport bs4 as bs\nimport random\nimport requests\nimport string","801195f9":"def random_starting_url():\n    starting = ''.join(random.SystemRandom().choice(string.ascii_lowercase) for _ in range(3))\n    url = ''.join(['http:\/\/', starting, '.com'])\n    return url","9b4c2c5a":"def handle_local_links(url,link):\n    if link.startswith('\/'):\n        return ''.join([url,link])\n    else:\n        return link","20ccce3a":"def get_links(url):\n    try:\n        resp = requests.get(url)\n        soup = bs.BeautifulSoup(resp.text, 'lxml')\n        body = soup.body\n        links = [link.get('href') for link in body.find_all('a')]\n        links = [handle_local_links(url,link) for link in links]\n        links = [str(link.encode(\"ascii\")) for link in links]\n        return links\n\n    except TypeError as e:\n        print(e)\n        print('Got a TypeError, probably got a None that we tried to iterate over')\n        return []\n    except IndexError as e:\n        print(e)\n        print('We probably did not find any useful links, returning empty list')\n        return []\n    except AttributeError as e:\n        print(e)\n        print('Likely got None for links, so we are throwing this')\n        return []\n    except Exception as e:\n        print(str(e))\n        # log this error \n        return []","5947c6b7":"def main():\n    how_many = 50\n    p = Pool(processes=how_many)\n    parse_us = [random_starting_url() for _ in range(how_many)]\n    \n    data = p.map(get_links, [link for link in parse_us])\n    data = [url for url_list in data for url in url_list]\n    p.close()\n\n    with open('urls.txt','w') as f:\n        f.write(str(data))\n\nif __name__ == '__main__':\n    main()","bd341687":"This program is basic example of using Multi processing method of python. It is a spider which just randomly visit any website on internet and access it's text using BeautifulSoup library of python."}}