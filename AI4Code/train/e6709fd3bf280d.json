{"cell_type":{"e7510964":"code","adae411d":"code","fa419f70":"code","83b766cd":"code","97ca7cd7":"code","68a169cb":"code","38902cbb":"code","10757fea":"code","11a8e5ca":"code","e3c2002c":"code","b14d1424":"code","ff868254":"code","30528478":"code","82b6e51a":"code","1af32b6e":"code","10ed2cc6":"code","bc1508e2":"code","14f67172":"code","91fc6f6f":"code","9d58f23e":"code","e09b356b":"code","c70fe245":"code","7a2a3db4":"code","af65aeab":"code","51622247":"code","2cf4060f":"code","fbc96811":"code","31db2558":"code","6173258a":"code","950f030e":"code","6b9afb7a":"code","8ca8cd63":"code","b61030d9":"code","0758062b":"code","9faa8a9e":"code","94d106b6":"code","1e0a715e":"code","4c5cf261":"code","6b7b3512":"code","a5580568":"code","79c30bb4":"code","9a5bc7f1":"code","a00fb347":"code","dbc2ea42":"code","59acc00d":"code","f85ed069":"code","0b3523b7":"code","97cabd28":"code","af0cc715":"code","6a4b86c5":"code","2d31e0e9":"code","313953ed":"code","7b46d254":"code","da25632d":"code","db062777":"code","eeaf9565":"code","6ab9a59b":"code","e3615201":"code","f7dee83b":"code","bc1f2704":"code","6e0868e1":"code","0699b2e4":"code","da35ae5a":"code","e56d9871":"code","ba9d0264":"code","13f1b6c9":"code","ca18a29b":"code","c30e5304":"code","767aaef2":"code","19c4e2c7":"code","8525b947":"code","0dbba8f9":"code","88d8f22d":"code","49ff814e":"code","0ce358f4":"code","7fcc0de7":"code","22c329f3":"code","b60cbb80":"markdown","5dc9341b":"markdown","32dd7a0c":"markdown","e76b66ba":"markdown","068504e7":"markdown","50df583f":"markdown","280ea2c9":"markdown","15531056":"markdown","92fff851":"markdown","020866c1":"markdown","c65ee82b":"markdown","8887afa8":"markdown","13a7539a":"markdown","93355b73":"markdown","97a3705f":"markdown","a2140bfd":"markdown","ae9d1e4d":"markdown","b0636a0c":"markdown","74ecb723":"markdown","b414c470":"markdown","fc467a29":"markdown","2e2313f5":"markdown","557eaab2":"markdown","369aaf56":"markdown"},"source":{"e7510964":"import numpy as np\nimport pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_object_dtype\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom xgboost import XGBRegressor\n\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler,RobustScaler,PolynomialFeatures,MinMaxScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import accuracy_score,mean_absolute_error,mean_squared_error,r2_score\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression,ElasticNetCV\nfrom sklearn.ensemble import RandomForestRegressor\n","adae411d":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ncombine = pd.concat([train,test])","fa419f70":"#Droping unnecessary columns for dataframes\ntrain.drop('Id',axis=1,inplace=True)\ntest.drop('Id',axis=1,inplace=True)","83b766cd":"train.head()","97ca7cd7":"test.head()","68a169cb":"test.shape,train.shape","38902cbb":"train.describe().T","10757fea":"train['SalePrice']","11a8e5ca":"#Relation between saleprice and other features\ncorrelation_num = train.corr()\ncorrelation_num.sort_values(['SalePrice'], ascending = True, inplace = True)\ncorrelation_num.SalePrice","e3c2002c":"# Check for Corelation between Features\nplt.figure(figsize=(20, 10))\nsns.heatmap(train.corr(),yticklabels=True,cbar=True,cmap='ocean')","b14d1424":"#Function for printing null_values and related info\ndef descr(train_num):\n    no_rows=train_num.shape[0]\n    types=train_num.dtypes\n    col_null = train_num.columns[train_num.isna().any()].to_list()\n    counts=train_num.apply(lambda x: x.count())\n    uniques=train_num.apply(lambda x: x.unique())\n    nulls=train_num.apply(lambda x: x.isnull().sum())\n    distincts=train_num.apply(lambda x: x.unique().shape[0])\n    nan_percent=(train_num.isnull().sum()\/no_rows)*100\n    cols={'dtypes':types, 'counts':counts, 'distincts':distincts, 'nulls':nulls,  \n          'missing_percent':nan_percent, 'uniques':uniques}\n    table=pd.DataFrame(data=cols)\n    return table\n","ff868254":"#Checking Null Values In Train\ndetails_tr = descr(train)\ndetails_tr.reset_index(level=[0],inplace =True)\ndetails_tr.sort_values(by='missing_percent', ascending=False)","30528478":"#Plot for Missing Values in Train dataset\ndetails_tr.sort_values(by='missing_percent', ascending=False,inplace=True)\ndetails_tr = details_tr[details_tr['missing_percent']>0]\n\nplt.figure(figsize=(10,4), dpi = 100)\nsns.barplot(x=details_tr['index'],y=details_tr['missing_percent'], data=details_tr)\nplt.xticks(rotation=90)\nplt.show()","82b6e51a":"#Checking Null Values In Train\ndetails_test = descr(test)\ndetails_test.reset_index(level=[0],inplace =True)\ndetails_test.sort_values(by='missing_percent', ascending=False)","1af32b6e":"train.isnull().values.any()","10ed2cc6":"test.isnull().values.any()","bc1508e2":"#From above table we know electrical has only 1 missing value so its better to replace nan with mode\ntrain['Electrical'].mode()","14f67172":"#Filling Nan values according to datatype and category in train dataframe\n\nn = []\nc = []\nbsmt_str_cols =  ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nbsmt_num_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\nfor col,col_df in details_tr.iterrows():\n    row = col_df['index']\n    if col_df['dtypes']=='object':\n        c.append(col)\n        if row == 'Electrical':\n            train[row].fillna('SBrkr',inplace=True)\n        elif row =='MasVnrType':\n            train[row].fillna('None',inplace=True)\n        elif row =='GarageType':\n            train[row].fillna('Attchd',inplace=True)\n        elif row =='GarageCond':\n            train[row].fillna('TA',inplace=True)\n        elif row =='GarageFinish':\n            train[row].fillna('Unf',inplace=True)\n        elif row =='GarageQual':\n            train[row].fillna('TA',inplace=True)\n        elif row =='FireplaceQu':\n            train[row].fillna('None',inplace=True)\n        for i in bsmt_str_cols:\n            if row ==i:\n                train[row].fillna('None',inplace=True)\n        else:\n            train[row].fillna(\"NotAvailable\",inplace=True)\n    else:\n        n.append(col)\n        if row =='MasVnrArea':\n            train[row].fillna(0,inplace=True)\n        for i in bsmt_num_cols:\n            if row ==i:\n                train[row].fillna('None',inplace=True)\n        else:\n            train[row].fillna(train[row].median(),inplace=True)\n    \n        \nprint(\"\\nNumerical Features   -->\", len(n))\nprint(\"Categorical Features -->\", len(c))\n        \n","91fc6f6f":"#Filling Nan values according to datatype and category in test dataframe\nnt = []\nct = []\nbsmt_str_cols =  ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\nbsmt_num_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\nfor col,col_df in details_test.iterrows():\n    row = col_df['index']\n    if col_df['dtypes']=='object':\n        ct.append(col)\n        if row == 'Electrical':\n            test[row].fillna('SBrkr',inplace=True)\n        elif row =='MasVnrType':\n            test[row].fillna('None',inplace=True)\n        elif row =='GarageType':\n            test[row].fillna('Attchd',inplace=True)\n        elif row =='GarageCond':\n            test[row].fillna('TA',inplace=True)\n        elif row =='GarageFinish':\n            test[row].fillna('Unf',inplace=True)\n        elif row =='GarageQual':\n            test[row].fillna('TA',inplace=True)\n        elif row =='FireplaceQu':\n            test[row].fillna('None',inplace=True)\n        else:\n            test[row].fillna(\"NotAvailable\",inplace=True)\n        for i in bsmt_str_cols:\n            if row ==i:\n                test[row].fillna('None',inplace=True)\n    \n    else:\n        nt.append(col)\n        if row =='MasVnrArea':\n            test[row].fillna(0,inplace=True)\n        else:\n            test[row].fillna(test[row].median(),inplace=True)\n        for i in bsmt_num_cols:\n            if row ==i:\n                test[row].fillna('None',inplace=True)\n       \n\n            \nprint(\"\\nNumerical Features   -->\", len(nt))\nprint(\"Categorical Features -->\", len(ct))","9d58f23e":"#Checking if there are any remaining Null Values In Train\ndetails_tr = descr(train)\ndetails_tr.sort_values(by='missing_percent', ascending=False).head()","e09b356b":"train.isnull().values.any()","c70fe245":"#Checking if there are any remaining Null Values In Train\ndetails_test = descr(test)\ndetails_test.reset_index(level=[0],inplace =True)\ndetails_test.sort_values(by='dtypes', ascending=True).head()","7a2a3db4":"test.isnull().values.any()","af65aeab":"# Separating Columns with Numerical Value and Character in 2 dataframes of train,test Datasets\ntrain_num = train.select_dtypes(exclude = 'object')\ntrain_cat = train.select_dtypes(include = 'object')\n\ntest_num = test.select_dtypes(exclude = 'object')\ntest_cat = test.select_dtypes(include = 'object')","51622247":"#Plotting numerical features with SalePrice\nfor i in train_num.columns:\n    sns.set_style('whitegrid')\n    plt.figure(figsize= (10,10))\n    x = train_num[i]\n    sns.jointplot(x=x, y=train_num['SalePrice'], data = train_num)","2cf4060f":"#Plotting categorical features with SalePrice\nfor i in train_cat.columns:\n    sns.set_style('whitegrid')\n    plt.figure(figsize= (15,15))\n    x = train_cat[i]\n    sns.jointplot(x=x, y=train_num['SalePrice'], data = train_cat)","fbc96811":"#Prices of Houseprice with years\ntrain.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","31db2558":"train_map = train.copy()\ntest_map = test.copy()","6173258a":"train_map.head()","950f030e":"for feature in train_map.select_dtypes(include = \"object\"):\n    labels_ordered=train_map.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    train_map[feature]=train_map[feature].map(labels_ordered)\n    \nfor feature in test_map.select_dtypes(include = \"object\"):\n    labels_ordered=test_map.groupby([feature])['LotFrontage'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    test_map[feature]=test_map[feature].map(labels_ordered)","6b9afb7a":"test_map.head()","8ca8cd63":"train_map.head()","b61030d9":"\ntest_map = test_map.drop([\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"], axis = 1)\ntrain_map = train_map.drop([\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\"], axis = 1)\nX = train_map.drop([\"SalePrice\"],axis=1).drop(train_map.index[-1])\nY = train_map['SalePrice'].drop(train_map.index[-1])\n\n#Train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=101)\n\n\n# Standard scaling our data\nscaler = StandardScaler()\nscaler.fit(X_train) \nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","0758062b":"X_train.shape , Y_train.shape,X_test.shape,Y_test.shape","9faa8a9e":"from sklearn.linear_model import Ridge,RidgeCV\nrid_reg = Ridge(alpha = 100)\nrid_reg.fit(X_train, Y_train)\n\nY_pred = rid_reg.predict(X_test)\n\n# testing the model\n\nprint(\"MAE : \",mean_absolute_error(Y_test, Y_pred))\nprint('R2 SCORE : ',r2_score(Y_test, Y_pred))\nprint('Score :',rid_reg.score(X_test,Y_test))\nprint('MSE :',mean_squared_error(Y_test,Y_pred))\nprint('RMSE :',np.sqrt(mean_squared_error(Y_test,Y_pred)))","94d106b6":"# let's find best values for alpha by crossvalidating\nridgecv = RidgeCV(alphas = (0.01, 400.0), scoring = 'neg_mean_squared_error', normalize = True)\nridgecv.fit(X_train, Y_train)\nridgecv.alpha_","1e0a715e":"# Create the Ridge model using best alpha value:\nfrom sklearn.linear_model import Ridge,RidgeCV\nrid_reg = Ridge(alpha = 0.01)\nrid_reg.fit(X_train, Y_train)\n\nY_pred_ridge = rid_reg.predict(X_test)\n\n# testing the model\n\nridge_mae = mean_absolute_error(Y_test, Y_pred_ridge)\nridge_r2_score= r2_score(Y_test, Y_pred_ridge)\nridge_rmse = np.sqrt(mean_squared_error(Y_test,Y_pred_ridge))\n\nprint(\"MAE for Ridge : \",ridge_mae)\nprint('R2 SCORE for Ridge: ',ridge_r2_score)\nprint('Score for Ridge:',rid_reg.score(X_test,Y_test))\nprint(\"MSE for Ridge : \",mean_squared_error(Y_test,Y_pred_ridge))\nprint(\"RMSE for Ridge : \",ridge_rmse)","4c5cf261":"Y_pred_ridge.min()","6b7b3512":"plt.figure(figsize=(10,8))\nsns.regplot(x = Y_pred_ridge,y = Y_test,color = 'springgreen');","a5580568":"# Create Lasso model\nfrom sklearn.linear_model import Lasso,LassoCV\nls = Lasso(alpha = 0.8)\nls.fit(X_train, Y_train)\n\nY_pred = ls.predict(X_test)\n\n# testing the model\n\nprint(\"MAE : \",mean_absolute_error(Y_test, Y_pred))\nprint('R2 SCORE : ',r2_score(Y_test, Y_pred))\nprint('Score :',ls.score(X_test,Y_test))\nprint('MSE :',mean_squared_error(Y_test,Y_pred))\nprint('RMSE :',np.sqrt(mean_squared_error(Y_test,Y_pred)))","79c30bb4":"#1. LASSOCV\nlassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\nlassocv.fit(X_train, Y_train)\n\nls.set_params(alpha=lassocv.alpha_)\nls.fit(X_train, Y_train)\nmean_squared_error(Y_test, ls.predict(X_test))","9a5bc7f1":"# Create the Lasso model using best alpha value:\n\nls = Lasso(alpha = 0.0198850177087539)\nls.fit(X_train, Y_train)\n\nY_pred_lasso = ls.predict(X_test)\n\n# testing the model\nlasso_mae = mean_absolute_error(Y_test, Y_pred_lasso)\nlasso_r2_score= r2_score(Y_test, Y_pred_lasso)\nlasso_rmse = np.sqrt(mean_squared_error(Y_test,Y_pred_lasso))\n\nprint(\"MAE for Lasso : \",lasso_mae)\nprint('R2 SCORE for Lasso : ',lasso_r2_score)\nprint('Score for Lasso:',ls.score(X_test,Y_test))\nprint('MSE for Lasso :',mean_squared_error(Y_test,Y_pred_lasso))\nprint('RMSE for Lasso :',lasso_rmse)","a00fb347":"Y_pred_lasso.min()","dbc2ea42":"plt.figure(figsize=(10,8))\nsns.regplot(x = Y_pred_lasso, y = Y_test,color ='darkorchid')","59acc00d":"\n\n#poly converter \npolynomial_converter = PolynomialFeatures(degree=2,include_bias=False)\n\n#convert X data and fit transform\npoly_features_train = polynomial_converter.fit_transform(X_train)\npoly_features_test = polynomial_converter.fit_transform(X_test)","f85ed069":"#fit poly_train in elastic net \nelastic_model = ElasticNetCV(l1_ratio= 1,tol=0.01)\nelastic_model.fit(poly_features_train,Y_train)","0b3523b7":"Y_pred_poly = elastic_model.predict(poly_features_test)","97cabd28":"#Testing the model\npoly_mae = mean_absolute_error(Y_test, Y_pred_poly)\npoly_r2_score = r2_score(Y_test, Y_pred_poly)\npoly_rmse = np.sqrt(mean_squared_error(Y_test,Y_pred_poly))\nprint(\"MAE for Polynomial: \",poly_mae)\nprint('R2 SCORE for Polynomial: ',poly_r2_score)\nprint('MSE for Polynomial :',mean_squared_error(Y_test,Y_pred_poly))\nprint('RMSE for Polynomial :',poly_rmse)","af0cc715":"Y_pred_poly.min()","6a4b86c5":"plt.figure(figsize=(10,8))\nsns.regplot(x = Y_pred_poly,y = Y_test,color= 'coral')","2d31e0e9":"# Create the LinearRegression model\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train,Y_train)","313953ed":"#Testing the model\ntest_pred_lin = lin_reg.predict(X_test)\ntrain_pred_lin = lin_reg.predict(X_train)\n\nlinear_mae = mean_absolute_error(Y_test, test_pred_lin)\nlinear_r2_score= r2_score(Y_test, test_pred_lin)\nlinear_rmse = np.sqrt(mean_squared_error(Y_test,test_pred_lin))\nprint(\"MAE for Linear : \",linear_mae)\nprint('R2 SCORE for Linear : ',linear_r2_score)\nprint('Score for Linear:',lin_reg.score(X_test,Y_test))\nprint('MSE for Linear :',mean_squared_error(Y_test,test_pred_lin))\nprint('RMSE for Linear :',linear_rmse)","7b46d254":"test_pred_lin.min()","da25632d":"plt.figure(figsize=(10,8))\nsns.regplot(x = test_pred_lin, y = Y_test,color ='blue')","db062777":"# Create the RandomForestRegression model\nRF_reg = RandomForestRegressor(n_estimators=1000)\nRF_reg.fit(X_train,Y_train)\n\ntest_pred_RF = RF_reg.predict(X_test)\ntrain_pred_RF= RF_reg.predict(X_train)","eeaf9565":"#Testing the model\nRF_mae = mean_absolute_error(Y_test, test_pred_RF)\nRF_r2_score= r2_score(Y_test, test_pred_RF)\nRF_rmse = np.sqrt(mean_squared_error(Y_test,test_pred_RF))\nprint(\"MAE for RF : \",RF_mae)\nprint('R2 SCORE for RF : ',RF_r2_score)\nprint('Score for RF:',RF_reg.score(X_test,Y_test))\nprint('MSE for RF :',mean_squared_error(Y_test,test_pred_RF))\nprint('RMSE for RF :',RF_rmse)","6ab9a59b":"test_pred_RF.min()","e3615201":"plt.figure(figsize=(10,8))\nsns.regplot(x = test_pred_RF, y = Y_test,color ='olivedrab')","f7dee83b":"# Create the SVM model\nsvm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\nsvm_reg.fit(X_train, Y_train)\n\ntest_pred_svm = svm_reg.predict(X_test)\ntrain_pred_svm = svm_reg.predict(X_train)","bc1f2704":"#Testing the model\nSVM_mae = mean_absolute_error(Y_test, test_pred_svm)\nSVM_r2_score= r2_score(Y_test, test_pred_svm)\nSVM_rmse = np.sqrt(mean_squared_error(Y_test,test_pred_svm))\nprint(\"MAE for RF : \",SVM_mae)\nprint('R2 SCORE for RF : ',SVM_r2_score)\nprint('Score for RF:',svm_reg.score(X_test,Y_test))\nprint('MSE for RF :',mean_squared_error(Y_test,test_pred_svm))\nprint('RMSE for RF :',SVM_rmse)","6e0868e1":"test_pred_svm.min()","0699b2e4":"plt.figure(figsize=(10,8))\nsns.regplot(x = test_pred_svm, y = Y_test,color ='lightseagreen')","da35ae5a":"\nfrom sklearn.linear_model import ElasticNet\n\n# Create the ElasticNet model\nenet_reg = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\nenet_reg.fit(X_train, Y_train)\n\ntest_pred_enet = enet_reg.predict(X_test)\ntrain_pred_enet = enet_reg.predict(X_train)","e56d9871":"#Testing the Model\nENET_mae = mean_absolute_error(Y_test, test_pred_enet)\nENET_r2_score= r2_score(Y_test, test_pred_enet)\nENET_rmse =  np.sqrt(mean_squared_error(Y_test,test_pred_enet))\nprint(\"MAE for RF : \",ENET_mae)\nprint('R2 SCORE for RF : ',ENET_r2_score)\nprint('Score for RF:',enet_reg.score(X_test,Y_test))\nprint('MSE for RF :',mean_squared_error(Y_test,test_pred_enet))\nprint('RMSE for RF :',ENET_rmse)","ba9d0264":"test_pred_enet.min()","13f1b6c9":"plt.figure(figsize=(10,8))\nsns.regplot(x = test_pred_enet, y = Y_test,color ='tomato')","ca18a29b":"from sklearn.linear_model import SGDRegressor\n## Create the SGDRegressor model\nsgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\nsgd_reg.fit(X_train, Y_train)\n\ntest_pred_sgd = sgd_reg.predict(X_test)\ntrain_pred_sgd = sgd_reg.predict(X_train)","c30e5304":"#Testing the Model\nSGD_mae = mean_absolute_error(Y_test, test_pred_sgd)\nSGD_r2_score= r2_score(Y_test, test_pred_sgd)\nSGD_rmse = np.sqrt(mean_squared_error(Y_test,test_pred_sgd))\nprint(\"MAE for RF : \",SGD_mae)\nprint('R2 SCORE for RF : ',SGD_r2_score)\nprint('Score for RF:',sgd_reg.score(X_test,Y_test))\nprint('MSE for RF :',mean_squared_error(Y_test,test_pred_sgd))\nprint('RMSE for RF :',SGD_rmse)","767aaef2":"test_pred_sgd.min()","19c4e2c7":"plt.figure(figsize=(10,8))\nsns.regplot(x = test_pred_sgd, y = Y_test,color ='yellow')","8525b947":"models = pd.DataFrame({\n    'Regression Model': ['Ridge','Lasso','Polynomial','Linear','SVM','RandomForest','ElasticNet','SGD'],\n    'MAE Score': [\n        ridge_mae, \n        lasso_mae,\n        poly_mae,\n        linear_mae,\n        SVM_mae,\n        RF_mae,\n        ENET_mae,\n        SGD_mae],\n    'R2 Score': [\n        ridge_r2_score, \n        lasso_r2_score,\n        poly_r2_score,   \n        linear_r2_score,\n        SVM_r2_score,\n        RF_r2_score,\n        ENET_r2_score,\n        SGD_r2_score\n        ],\n    'RMSE': [\n        ridge_rmse, \n        lasso_rmse,\n        poly_rmse,   \n        linear_rmse,\n        SVM_rmse,\n        RF_rmse,\n        ENET_rmse,\n        SGD_rmse\n        ]\n})\nprint(\"-----------MODEL EVALUATION-----------\")\nmodels.sort_values(by='MAE Score', ascending=True)","0dbba8f9":"models.sort_values(by='RMSE', ascending=True)","88d8f22d":"models.set_index('Regression Model',inplace=True)\nmodels['R2 Score'].plot(kind='barh', figsize=(10, 6))","49ff814e":"Model = RandomForestRegressor()\nModel.fit(X,Y)\nPrediction = Model.predict(test_map)\nPrediction","0ce358f4":"sample = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsample['SalePrice'] = Prediction","7fcc0de7":"sample","22c329f3":"sample.to_csv('Submission.csv',index=False)","b60cbb80":"After checking the correlation of SalePrice with all Features, We can see OverallQual,GrLivArea,GarageCars,GarageArea have the most correlation\n\nWe will confirm it by plotting a correlation heatmap below","5dc9341b":"# Applying Model On Test Data","32dd7a0c":"# Random Forest Regression","e76b66ba":"Plotting numerical features with SalePrice","068504e7":"# Feature Scaling","50df583f":"# Plotting categorical features with SalePrice\n","280ea2c9":"# EDA,Visualization and PreProcessing","15531056":"# Polynomial Regression","92fff851":"Mapping the Numerical Features for Model Processing","020866c1":"So we can deduce from the above bar graph that PoolQc,MiscFeature,Alley,Fence has the maximum number of NAN values","c65ee82b":"# Linear Regression","8887afa8":"Hyper Parameter Tuning For alpha","13a7539a":"We can observe that SalePrice of Houses has been decreasing recently","93355b73":"# SVM Regression","97a3705f":"# Lasso Regression","a2140bfd":"# SGD Regression","ae9d1e4d":"* From Above Data we can infer that RandomForestRegression() is working best so we will consider it for final prediction.","b0636a0c":"**HyperParameterTuning For alpha**","74ecb723":"# Comparing All Regressions","b414c470":"# Computing NAN Values From Train and Test\n","fc467a29":"# **Importing Libraries**","2e2313f5":"# Ridge Regression","557eaab2":"Loading Dataset","369aaf56":"# ElasticNet Regression"}}