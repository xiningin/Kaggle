{"cell_type":{"40eb3548":"code","58cfec2a":"code","0ca6ac1d":"code","b7b2fcb1":"code","69a5592d":"code","13e380de":"code","ded936a9":"code","07838218":"code","9a3bb00d":"code","ba904153":"code","4b54b2dc":"code","ca93ad62":"code","0c7014f9":"code","5c148da6":"code","47e65591":"code","52c26dd4":"code","41a5edee":"code","8f6229fc":"code","464b0de3":"code","1a2e8c69":"code","0f4d9332":"markdown","fe6163b0":"markdown","420820b2":"markdown","5fd4c96e":"markdown","7015b76b":"markdown","74c39d63":"markdown","7c3a630a":"markdown","b639d998":"markdown","7690e244":"markdown","5d863412":"markdown","8e03fe07":"markdown","0427db4e":"markdown","7b6f120b":"markdown","0dec0fc7":"markdown","4de980d1":"markdown","d69d046d":"markdown","187d1437":"markdown","1b2ceb18":"markdown"},"source":{"40eb3548":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n!pip install h2o\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58cfec2a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n\ndf=pd.read_csv(r\"..\/input\/titanic\/train.csv\")\ndf.info()\nprint(df.head())\ndf['Survived'].plot(kind=\"hist\")","0ca6ac1d":"#survival by age\n\nn_bins=10\ndfs=df[df[\"Survived\"]==1]\ndfns=df[df[\"Survived\"]==0]\nx=dfs[\"Age\"], dfns[\"Age\"]\nplt.hist(x, n_bins, histtype=\"bar\", stacked=True)","b7b2fcb1":"#categorical columns (sex and embarked) to numerical\n\ndf[\"Sexn\"]=np.nan\ndf[\"Embarkedn\"]=np.nan\nfor i in df.index:\n    if(df[\"Sex\"][i]==\"male\"):\n        df[\"Sexn\"][i]=1\n    else:\n        df[\"Sexn\"][i]=2\n    if(df[\"Embarked\"][i]==\"C\"):\n        df[\"Embarkedn\"][i]=1\n    elif(df[\"Embarked\"][i]==\"S\"):\n        df[\"Embarkedn\"][i]=2\n    else:\n        df[\"Embarkedn\"][i]=3\n\nprint(df.describe())","69a5592d":"#splitting datasets\n\ndfy=df[[\"Survived\"]]\ny=np.array(dfy)\ndfx=df.drop(columns =['PassengerId', 'Survived','Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'])\nX=np.array(dfx)\n\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.1, random_state=10)","13e380de":"#baseline\/default XGBoost classification\n\nxgbt=xgb.XGBClassifier()\nxgbt.fit(X_train, y_train)\nxgby_pred=xgbt.predict(X_test)\nxgb_score=accuracy_score(y_test, xgby_pred)\nprint(\"Accuracy :\", xgb_score)\nxgb_auc=roc_auc_score(y_test, xgby_pred)\nprint(\"AUC score: \", xgb_auc)","ded936a9":"#GRID SEARCH\npg = {  \n        'eta': [0.1, 0.2, 0.3],\n        'min_child_weight': [1, 3, 5, 7],\n        'gamma': [0, 1, 1.5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.8, 1.0],\n        'max_depth': [5, 6, 7, 8],\n     }\ngs=GridSearchCV(estimator=xgbt, param_grid=pg, scoring='accuracy')\ngs.fit(X_train, y_train.ravel())\nprint(gs.best_estimator_)\nprint(gs.best_params_)\nprint(gs.best_score_)","07838218":"xgbgs=xgb.XGBClassifier(colsample_bytree=1.0, eta=0.1, gamma= 1, max_depth= 8, min_child_weight=5, subsample=1.0)\nxgbgs.fit(X_train, y_train)\nxgbgsy_pred=xgbgs.predict(X_test)\n\nxgbgs_score=accuracy_score(y_test, xgbgsy_pred)\nprint(\"Accuracy: \", xgbgs_score)\nxgbgs_auc=roc_auc_score(y_test, xgbgsy_pred)\nprint(\"ROC-AUC score: \", xgbgs_auc)","9a3bb00d":"xgbgs=xgb.XGBClassifier(colsample_bytree= 1.0, eta= 0.1, gamma= 1.5, max_depth= 5, min_child_weight= 7, n_estimators= 100, subsample= 1.0)\nxgbgs.fit(X_train, y_train)\nxgbgsy_pred=xgbgs.predict(X_test)\nxgbgs_score=accuracy_score(y_test, xgbgsy_pred)\nprint(\"Accuracy: \", xgbgs_score)\nxgbgs_auc=roc_auc_score(y_test, xgbgsy_pred)\nprint(\"ROC-AUC score: \", xgbgs_auc)","ba904153":"#RANDOM SEARCH\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npr = {  'eta': [0.1, 0.2, 0.3, 0.4],\n        'min_child_weight': stats.randint(1,10),\n        'gamma': stats.uniform(0.5,5),\n        'subsample': stats.uniform(0.5,1),\n        'colsample_bytree': stats.uniform(0.5,1),\n        'max_depth': stats.randint(4,15),\n        'n_estimators': [50, 100]  \n        }\n\nrs=RandomizedSearchCV(estimator=xgbt, param_distributions=pr, scoring='accuracy', n_iter=2000)\nrs.fit(X, y)\nprint(rs.best_estimator_)\nprint(rs.best_params_)\nprint(rs.best_score_)\n\n#As we have not used a seed value, results might vary","4b54b2dc":"xgbrs=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.685129917667923, eta=0.3,\n              gamma=1.4825037365560436, gpu_id=-1, importance_type='gain',\n              interaction_constraints='', learning_rate=0.300000012,\n              max_delta_step=0, max_depth=8, min_child_weight=5, missing=np.nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=0,\n              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n              scale_pos_weight=1, subsample=0.6635065109110365,\n              tree_method='exact', validate_parameters=1, verbosity=None)\nxgbrs.fit(X_train, y_train)\nxgbrsy_pred=xgbrs.predict(X_test)\nxgbrs_acc=accuracy_score(y_test, xgbrsy_pred)\nprint(\"Accuracy: \", xgbrs_acc)\nxgbrs_auc=roc_auc_score(y_test, xgbrsy_pred)\nprint(\"ROC-AUC score: \", xgbrs_auc)","ca93ad62":"#BAYES SEARCH\n\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nX_trainsk=np.array(X_train.tolist())\ny_trainsk=np.array(y_train.tolist())\n\nbayes_cv_tuner = BayesSearchCV(\n    estimator = xgb.XGBClassifier(\n        n_jobs = 1,\n        objective = 'binary:logistic',\n        eval_metric = 'auc',\n        tree_method='approx'\n    ),\n    search_spaces = {\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'min_child_weight': (0, 10),\n        'max_depth': (0, 50),\n        'max_delta_step': (0, 20),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n        'gamma': (1e-9, 0.5, 'log-uniform'),\n        'min_child_weight': (0, 5),\n        'n_estimators': (50, 100),\n        'scale_pos_weight': (1e-9, 500, 'log-uniform')\n    },    \n    scoring = 'roc_auc',\n    cv = StratifiedKFold(\n        n_splits=3,\n        shuffle=True,\n        random_state=10\n    ),\n    n_jobs = 3,\n    n_iter = 9,   \n    verbose = 0,\n    refit = True,\n    random_state = 10\n)\n\ndef status_print(optim_result):\n    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n     \n    best_params = pd.Series(bayes_cv_tuner.best_params_)\n    print('Model #{}\\nBest ROC-AUC score: {}\\nBest params: {}\\n'.format(\n        len(all_models),\n        np.round(bayes_cv_tuner.best_score_, 4),\n        bayes_cv_tuner.best_params_\n    ))\n    \nresult = bayes_cv_tuner.fit(X, y, callback=status_print)","0c7014f9":"print(pd.DataFrame(bayes_cv_tuner.cv_results_))","5c148da6":"#H2O AUTOML\n\nimport h2o\nfrom h2o.automl import H2OAutoML\n\nh2o.init(\n    nthreads=-1,     # number of threads when launching a new H2O server\n    max_mem_size=12  # in gigabytes\n)","47e65591":"X_traindf=pd.DataFrame(X_train)\ny_traindf=pd.DataFrame(y_train)\ny_traindf.columns=[\"y\"]\nX_y_train_h = h2o.H2OFrame(pd.concat([X_traindf, y_traindf], axis='columns'))\nX_y_train_h[\"y\"]=X_y_train_h[\"y\"].asfactor()\nprint(X_y_train_h)","52c26dd4":"aml = H2OAutoML(\n    max_runtime_secs=(1800),\n    max_models=None,\n    seed=10,\n    include_algos=[\"XGBoost\", \"GBM\"]\n)\n\naml.train(x = [0, 1, 2, 3, 4, 5, 6, 7], y = \"y\", training_frame = X_y_train_h)\n\nlb = aml.leaderboard\nlb","41a5edee":"xgbh2o = aml.leader\nprint(xgbh2o.params.keys())\nprint()\nparameter_list=['ntrees', 'max_depth', 'min_rows', 'min_child_weight', 'learn_rate', 'eta', 'sample_rate', 'subsample', 'col_sample_rate', 'colsample_bylevel', 'col_sample_rate_per_tree', 'colsample_bytree', 'colsample_bynode', 'max_abs_leafnode_pred', 'max_delta_step', 'monotone_constraints', 'score_tree_interval', 'min_split_improvement', 'gamma', 'nthread', 'save_matrix_directory', 'build_tree_one_node', 'calibrate_model', 'calibration_frame', 'max_bins', 'max_leaves', 'sample_type', 'normalize_type', 'rate_drop', 'one_drop', 'skip_drop', 'tree_method', 'grow_policy', 'booster', 'reg_lambda', 'reg_alpha']\nfor i in parameter_list:\n    if(xgbh2o.params[i][\"default\"]!=xgbh2o.params[i][\"default\"] or xgbh2o.params[i][\"default\"]!=xgbh2o.params[i][\"input\"]):\n        print(i,\" : \", xgbh2o.params[i])","8f6229fc":"X_testh=h2o.H2OFrame(pd.DataFrame(X_test))\n\n#X_testh.columns=X_trainh.columns\nxgbh2o_predh = xgbh2o.predict(X_testh)\nxgbh2o_predh = xgbh2o_predh.as_data_frame().values\nxgbh2o_pred = []\n\nfor i in xgbh2o_predh:\n    xgbh2o_pred.append(i[0])\n    \nxgbh2o_acc=accuracy_score(y_test, xgbh2o_pred)\nprint(\"Accuracy: \", xgbh2o_acc)\nxgbh2o_auc=roc_auc_score(y_test, xgbh2o_pred)\nprint(\"AUC score: \", xgbh2o_auc)","464b0de3":"#PREPROCESSING TEST DATASET\n\ndftest=pd.read_csv(r\"..\/input\/titanic\/test.csv\")\n\ndftest[\"Sexn\"]=np.nan\ndftest[\"Embarkedn\"]=np.nan\nfor i in dftest.index:\n    if(dftest[\"Sex\"][i]==\"male\"):\n        dftest[\"Sexn\"][i]=1\n    else:\n        dftest[\"Sexn\"][i]=2\n    if(dftest[\"Embarked\"][i]==\"C\"):\n        dftest[\"Embarkedn\"][i]=1\n    elif(dftest[\"Embarked\"][i]==\"S\"):\n        dftest[\"Embarkedn\"][i]=2\n    else:\n        dftest[\"Embarkedn\"][i]=3\n\ndfpredx=dftest.drop(columns =['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'])\nXpred=np.array(dfpredx)\nprint(Xpred)","1a2e8c69":"#SUBMITTING THE RESULTS\n\ny_pred = xgbrs.predict(Xpred)\ndfsubmission=dftest\ndfsubmission[\"Survived\"]=y_pred\ndfsubmission=dfsubmission[[\"PassengerId\", \"Survived\"]]\ndfsubmission.set_index(\"PassengerId\", inplace=True)\nprint(dfsubmission.head(20))\n\ndfsubmission.to_csv(\".\/submission2.csv\")","0f4d9332":"Now we create an H2OAutoML object called aml with a max runtime of 1800 secs i.e. 30 minutes, a seed of 10 to ensure reproducibility and the algorithms that it can apply, in this case, XGBoost and GBM (Gradient Boosting Machines). \n\nWe can also include other algorithms like DRF and StackedEnsemble algorithms. Then we train this using the H2OFrame and the columns names of target variable and attributes. Then we print the leaderboard of models that this object creates.","fe6163b0":"**As this is a classification model, we will look at accuracy and roc-auc score as performance metrics. We want a balance between the two with accuracy being slightly more prioritized. We are going to create a model using XGBClassifier() and fit it to the training set and calculate the accuracy and auc scores.**\n\nNow, before splitting the data into train and test files we have dropped all the attributes which are not going to contribute to the survival of the passenger. Following attributes are removed: \u2018PassengerId', 'Survived','Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'. Finally, we use train_test_split to divide our data into train and test datasets.","420820b2":"# Automatic hyperparameter tuning using H2O\n\nNext, we take a look at the fifth approach i.e. automatic hyperparameter tuning using external libraries like h2o. We import and initialize the h2o AutoML model and provide the number of threads and the memory that it can use.\n\nh2o can concurrently process many models (using different threads) and is quite time efficient. It goes through a number of pre-configured models and makes a leaderboard ranking them.","5fd4c96e":"# Bayes Search\n\nTo apply Bayes Search method, we use BayesSearchCV. Bayes search provides the same or better results with every iteration.\n\nThe parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings. In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. \n\nThe number of parameter settings that are tried is given by n_iter. We define the estimator (XGBoost model) and the sample space, provide a cross validation algorithm (StratifiedKFold), enter the scoring metric (auc), set the random state so that our results are reproducible and enter the rest of the arguments.\n","7015b76b":"Now, we can see significant improvements to our baseline model with an **accuracy of 86.667% and an ROC-AUC score of 0.838**. By increaseing the number of hyperparameters that we take into consideration and the number of iterations, we can get even better results.","74c39d63":"After our understanding of the code, here we are plotting another graph with bin size = 10 (where n is the number of counts in each bin of the histogram). \nBefore plotting the graph we have made two sets of arrays one with Survived attribute value = 1 and other with value 0. The graph type used is stacked histogram chart for which we have given the command histtype= \u201cbar\u201d.","7c3a630a":"# Understanding Hyperparamter Tuning (Theory)\n\n**Hyperparameter Tuning**\n\nFor many hyperparameters, like splitter and random state in the decision tree model, tuning is not necessary and default values provide the best output while some do not have considerable effect on the output. Once the hyperparameters that are to be optimized have been identified, there are five widely used approaches for optimization:\n\n**1.\tManually changing the hyperparameters:**\n\nAs the name suggests, in this method we choose initial values based on our best estimation of the optimal values. Then we analyze the evaluation metrics of the model and change the hyperparameters as per our requirements. This method is generally not used as it is inefficient and we can only check one configuration of values at a time (unless we train multiple models).\n\n**2.\tGrid Search:**\n\nIn the grid search method we create a dictionary containing the hyperparameters we want to optimize as keys and an array containing multiple discrete values (of that hyperparameter) as the value (of that key). Then we use the GridSearchCV() from the sklearn.model_selection package to go through all the possible combinations of the discrete values in the dictionary. Some important parameters of the GridSearchCV() function are:\n* estimator - The model being used for fitting.\n* param_grid - The dictionary containing the values of the hyperparameters.\n* scoring - The metric that we use to evaluate the model like accuracy, roc_auc for classification, homogeneity_score for clustering, explained_variance and r2 for regression.\n* n_jobs - Number of jobs that can run in parallel.\n* cv - We can set the K in Kfold cross validation using this parameter.\n* verbose - This can be used to set the verbosity or the number of messages created.\n\n**3.\tRandom Search:**\n\nRandom search creates models with random values of hyperparameters where we can specify the range of values. This method can be more efficient as compared to Grid search as it is less resource intensive and can provide better results in the same number of iterations. This is because the number of models that grid search creates is much larger as it goes through all the possible combinations to find the best fit. Random search is best used when the dataset is large and there are some important and some not so important hyperparameters. Grid search is best used for small datasets and where finding the best performing model is worth the resource tradeoff. For implementation, RandomizedSearchCV() from the sklearn.model_selection package is used. Like Grid Search, we also create a dictionary containing values of hyperparameters. Some important parameters of the GridSearchCV() function are:\n* estimator - The model being used for fitting\n* param_distributions - The dictionary containing the values of the hyperparameters.\n* scoring - The metric that we use to evaluate the model like accuracy, roc_auc for classification, homogeneity_score for clustering, explained_variance and r2 for regression.\n* n_iter - Number of iterations i.e. random combinations that Random Search will go through.\n* cv - We can set the K in Kfold cross validation using this parameter.\n* n_jobs - Number of jobs that can run in parallel.\n* verbose - This can be used to set the verbosity or the number of messages created.\n\n**4.\tBayesian Search and other more efficient algorithms:**\n\nskopt (Scikit-Optimize) and hyperopt are libraries that adopt the latter method i.e. using optimization algorithms for a particular model that we create. Bayesian optimization is more efficient as it changes the values of hyperparameters based on past results (unlike Grid and Random Search which are uniform), thereby coming closer to the optimal configuration with increasing iterations. Bayesian optimization utilizing Gaussian Processes surrogate model can be performed using skopt.gp_minimize. Bayesian optimization utilizing TPE (Tree Parzen Estimator) surrogate model can be implemented by importing and using tpe method from the hyperopt library. Other algorithms like gradient descent, genetic algorithm, hyperband algorithm etc. also offer better performance than grid and random search as they take their previous results into account.\n \n\n**5.\tAutomatic Hyperparameter Tuning:**\n\nHyperparameter tuning can be automated by automating the entire process using libraries like h2o and tpot. h2o is an open source AI and ML platform for python and R. Its AutoML package can generate and rank multiple models with different algorithms and configurations. TPOT is another open source library that can create and evaluate various pipelines that process the raw data and construct models. These libraries can be really convenient to use for relatively simple machine learning use cases.\n\n----------------------------------------------------------------------------------------------------------------------------------------------\n\n**XGBoost hyperparameters**\n\nGenerally, the XGBoost hyperparameters have been divided into 4 categories. They are as follows -\n* General parameters\n* Booster parameters\n* Learning task parameters\n* Command line parameters\n\nBefore running a XGBoost model, we must set three types of parameters - general parameters, booster parameters and task parameters.\nThe fourth type of parameters are command line parameters. They are only used in the console version of XGBoost. So, we will skip these parameters and limit our discussion to the first three type of parameters.\n\nList of hyperparameters that are generally tuned are:\n* **eta** [default=0.3, alias: learning_rate]:\n    Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative. \n    range: [0,1]\n\n* **gamma** [default=0, alias: min_split_loss]:\n    Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n    range: [0,\u221e]\n\n* **max_depth** [default=6]: \n    Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit. 0 is only accepted in lossguided growing policy when tree_method is set as hist or gpu_hist and it indicates no limit on depth. Beware that XGBoost aggressively consumes memory when training a deep tree. \n    range: [0,\u221e]\n\n* **min_child_weight** [default=1]:\n    Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. The larger min_child_weight is, the more conservative the algorithm will be. \n    range: [0,\u221e]\n\n* **max_delta_step** [default=0]:\n    Maximum delta step we allow each leaf output to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative. Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced. Set it to value of 1-10 might help control the update.\n    range: [0,\u221e]\n\n* **subsample** [default=1]: \n    Subsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration. \n    range: (0,1]\n\n* **sampling_method** [default= uniform]: \n\n    The method to use to sample the training instances. \n    options: [uniform, gradient_based] \n\n* **colsample_bytree, colsample_bylevel, colsample_bynode** [default=1]: \n\n    This is a family of parameters for subsampling of columns. All colsample_by* parameters have a range of (0, 1], the default value of 1, and specify the fraction of columns to be subsampled. \n    *  colsample_bytree is the subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed. \n    *  colsample_bylevel is the subsample ratio of columns for each level. Subsampling occurs once for every new depth level reached in a tree. Columns are subsampled from the set of columns chosen for the current tree. \n    *  colsample_bynode is the subsample ratio of columns for each node (split). Subsampling occurs once every time a new split is evaluated. Columns are subsampled from the set of columns chosen for the current level.\n\n\n* **lambda** [default=1, alias: reg_lambda]:\n    L2 regularization term on weights. Increasing this value will make model more conservative.\n\n* **alpha** [default=0, alias: reg_alpha]: \n    L1 regularization term on weights. Increasing this value will make model more conservative.\n\n* **scale_pos_weight** [default=1]: \n    Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider - sum(negative instances) \/ sum(positive instances).\n","b639d998":"Finally, we import the titanic\/test.csv dataset as a dataframe and clean it like we cleaned our train.csv dataset. As this is a  test dataset in which we have to predict and submit for evaluation, we do not have the target variable\u2019s data with us.","7690e244":"Here, we convert the training datasets that we have stored as numpy arrays to pandas dataframes. Then we create a special data structure called H2OFrame by concatenating the X_traindf dataframe (attributes) and y_traindf data (target) and passing it as an argument to the the H2OFrame method of h2o library. We need to do this as h2o only works with this type of data structure.","5d863412":"Next, we deal with categorical attributes. There two categorical attributes that are relevant namely, sex and embarked.\nWe are going to convert these to numerical by encoding them.","8e03fe07":"# Introduction\n\nIn the first step of our model, we are going to import all the required libraries which are needed for this model and import the dataset which we are going to use for this model (Titanic - Machine Learning from Disaster). With this dataset, our target is to identify which passengers on the Titanic will survive based on their attributes.\n\nAfter reading the dataset file, for better understanding of the code we will use the info and head command. Based on the info and head command, we understand what columns (or attributes) are relevant and which ones are not. After that we plotted a histogram of the attribute \u201cSurvived\u201d to understand the distribution of the two classes in our target variable.\n","0427db4e":"# GRID SEARCH\n\nNext, we begin implementing Grid Search algorithm. We create a sample space by creating a dictionary name pg with hyperparameters as keys and an array of their possible values as the values.\n\nNow we have used the Grid Search method to fit the model i.e., on the train set. Every single combination of these possible values is used to create an XGBoost model that is fit to our training dataset and its score is calculated. In our case, **864 models** are created and compared and the best estimator, parameters and score based on the accuracy are printed. Generally, thousands of models are taken into consideration when implementing Grid Search which makes it resource expensive.","7b6f120b":"Subsequently, we have to test the best performing h2o model with our test dataset. Like our train dataset, we manipulate the test dataset to meet h2o\u2019s requirements and we get an array containing predicted values (as well as their probabilities).\n\nWe have obtained an **Accuracy of 85.56% and an AUC score of 0.8392**. This is one of the better performing models of the lot and is comparable to our Random Search model.","0dec0fc7":"We now obtain all the parameters headings of the best performing model (aml.leader) by printing the keys of the params attribute of our model. We then create a list of all the hyperparameters that the model has and then filter out those hyperparameters whose input values or actual values differ from the default values.","4de980d1":"Although Bayes search is slower than Grid or Random Search when it comes to a single iterations but it is much more efficient and requires less number of iterations to provide optimal results. In just 10 iterations, we have our best ROC-AUC score out of all the models. We can further improve on this by including more parameters and increasing iterations. With this approach, we need to find a way to create a balance between accuracy and auc as it prioritizes the scoring method to a fault.\n\nPrinting the final leaderboard of models created by the Bayes Search hyperparameter tuning method and those are as follows:","d69d046d":"# RANDOM SEARCH\n\nNow we move on to Randomized Search algorithm. We create a sample space by creating a sample space named pr with hyperparameters as keys and an array of their possible values as the values. **Unlike Grid Search we generally do not provide specific values, instead we pick a random value from the limits or the array provided.** We try random combinations of these values, thereby covering more search space with less iterations. In the function, we enter the number of models to be created (n_iter) as 2000.\n\nTo ignore warnings we are going to import a library called warnings. Deprecation warnings are warnings that indicate the use of a library or feature is suspended and is no longer considered safe to use. But sometimes, due to compatibility issues between different libraries, we have to use older features. So by setting filterwarnings value to \u201cignore\u201d it will ignore them all.\n","187d1437":"Here we predict whether the passenger survived or not by using our most accurate XGBoost model which has been optimized using **Random Search**. Below you can see the dataset has two values 0 and 1. 1 tell us that the passenger has survived and 0 tell us that the passenger has not survived. We then export this dataset to submission2.csv using the to_csv() method.","1b2ceb18":"We have two sets of parameters which both provide optimal results when fit to the test dataset. The latter provides better roc-auc scores and it is well balanced with accuracy and should be favored. \n\nThe minor change in scores as compared to the baseline model can be attributed to the low number of models created, i.e. only 864 configurations have been tested and the sample space is quite small."}}