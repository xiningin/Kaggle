{"cell_type":{"1307d635":"code","baf859a2":"code","d57acced":"code","e9071296":"code","ec9ee12f":"code","18713054":"code","fd82c663":"code","4daf40cd":"code","524be6a4":"code","3675fe53":"code","d080ca2c":"code","3a569271":"code","f6a01ef1":"code","6da63986":"code","ef215adf":"code","037eecf0":"code","0847b473":"code","4e81022a":"code","6bf4cdcb":"code","f8c3c467":"code","685277e5":"code","6a92dcea":"code","bc145193":"code","8d74d4a1":"code","93dd18ed":"code","640fb5ad":"code","fcb4e35a":"code","7dcde8c2":"code","1628441b":"markdown","cfd166ce":"markdown","da35f99b":"markdown","c67b75e2":"markdown","fb7e6c55":"markdown","b95a7a94":"markdown","d580b167":"markdown","02e25020":"markdown","77a2f907":"markdown","11f96421":"markdown","18dc4029":"markdown"},"source":{"1307d635":"import numpy as np\nimport pandas as pd\nimport warnings\nimport os\nfrom matplotlib import pyplot as plt\nfrom timeit import default_timer as timer\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","baf859a2":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d57acced":"np.random.seed(42)","e9071296":"warnings.simplefilter(action='ignore', category=FutureWarning)","ec9ee12f":"df_train = pd.read_csv('\/kaggle\/input\/bigdata2020classification\/train.csv\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/bigdata2020classification\/test_without_labels.csv\/\/test_without_labels.csv')","18713054":"df_train.head()","fd82c663":"df_train = df_train.drop(['Id'], axis=1)","4daf40cd":"len_start = len(df_train)\ndf_train.info()","524be6a4":"df_train.drop_duplicates(subset='Content', keep='last', inplace=True)","3675fe53":"len_end = len(df_train)","d080ca2c":"# Display number of duplicates in the dataset\n\nprint('{} duplicate articles were removed from the dataset'\n      .format(len_start - len_end))","3a569271":"# Relative frequency of labels\n\nrel_freq = df_train.groupby('Label').Title.count() \/ len(df_train)\nprint(rel_freq)","f6a01ef1":"fig, ax = plt.subplots(figsize=(6,5))\nrel_freq.plot.bar(ax=ax)\nax.set_title('Relative Frequencies of the Class Labels')\nax.set_xlabel('')\nfig.tight_layout()\nplt.show()","6da63986":"# Concatenate the titles and the contents\n\ndf_train['Text'] = df_train['Title'] + ' ' + df_train['Content']\nX = df_train['Text'].to_dense().values\ny = df_train['Label'].to_dense().values","ef215adf":"df_train['Text'][259]","037eecf0":"def get_metrics(y_true, y_pred, metrics):\n    metrics[0] += accuracy_score(y_true, y_pred)\n    metrics[1] += precision_score(y_true, y_pred, average='macro')\n    metrics[2] += recall_score(y_true, y_pred, average='macro')\n    metrics[3] += f1_score(y_true, y_pred, average='macro')\n    return metrics","0847b473":"def evaluate_classifier(clf, kfold, X, y, vectorizer):\n    metrics = np.zeros(4)\n    start = timer()\n    for train, cv in kfold.split(X, y):\n        X_train, X_cv = X[train], X[cv]\n        y_train, y_cv = y[train], y[cv]\n        X_train_gen = [x for x in X_train]\n        vectorizer.fit(X_train_gen)\n        X_train_vec = vectorizer.transform(X_train_gen)\n        clf.fit(X_train_vec, y_train)\n        X_cv_gen = [x for x in X_cv]\n        X_cv_vec = vectorizer.transform(X_cv_gen)\n        y_pred = clf.predict(X_cv_vec)\n        metrics = get_metrics(y_cv, y_pred, metrics)\n    dt = timer() - start\n    metrics = metrics * 100 \/ 5\n    print('Evaluation of classifier finished in {:.2f} s \\n'\n          'Average accuracy: {:.2f} % \\n'\n          'Average precision: {:.2f} % \\n'\n          'Average recall: {:.2f} % \\n'\n          'Average F-Measure: {:.2f} % \\n'\n          .format(dt, metrics[0], metrics[1],\n                  metrics[2], metrics[3]))","4e81022a":"# 5-Fold Cross-Validation\n\nkf = KFold(n_splits=5, shuffle=True, random_state=56)\n\n# Stop Words and TF-IDF Vectorizer\n\nstop_words = ENGLISH_STOP_WORDS\ntfidf = TfidfVectorizer(stop_words=stop_words, min_df=3,\n                        max_df=0.5, ngram_range=(1, 2))\n\n# Classifiers \n\nsvm = LinearSVC(tol=1e-05, max_iter=1500)\nridge = RidgeClassifier(alpha=0.8, tol=1e-05)\nknn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)","6bf4cdcb":"# Divide the dataset into a train\/cross-validation set and a test set\n\nX_train_cv, X_test, y_train_cv, y_test = train_test_split(X, y, test_size=0.2, \n                                                          random_state=56)","f8c3c467":"# SVM classifier\n\nevaluate_classifier(svm, kf, X_train_cv, y_train_cv, tfidf)","685277e5":"# Ridge classifier\n\nevaluate_classifier(ridge, kf, X_train_cv, y_train_cv, tfidf)","6a92dcea":"# kNN classifier\n\nevaluate_classifier(knn, kf, X_train_cv, y_train_cv, tfidf)","bc145193":"# Voting ensemble of 3 classifiers\n\nboost = VotingClassifier(estimators=[\n                        ('svc', svm), ('ridge', ridge), ('knn', knn)],\n                        voting='hard', n_jobs=-1)","8d74d4a1":"# Evaluate the voting classifier on the test set\n\nstart = timer()\nmetrics = np.zeros(4)\nX_train_gen = [x for x in X_train_cv]\ntfidf.fit(X_train_gen)\nX_train_vec = tfidf.transform(X_train_gen)\nboost.fit(X_train_vec, y_train_cv)\nX_test_gen = [x for x in X_test]\nX_test_vec = tfidf.transform(X_test_gen)\ny_pred = boost.predict(X_test_vec)\nmetrics = get_metrics(y_test, y_pred, metrics)\ndt = timer() - start\nmetrics = metrics * 100\nprint('Evaluation of voting classifier on the test set finished in {:.2f} s . \\n'\n      'Average accuracy: {:.2f} % \\n'\n      'Average precision: {:.2f} % \\n'\n      'Average recall: {:.2f} % \\n'\n      'Average F-Measure: {:.2f} % \\n'\n      .format(dt, metrics[0], metrics[1],\n              metrics[2], metrics[3]))","93dd18ed":"# Concatenate the titles and the contents\n\ndf_test['Text'] = df_test['Title'] + ' ' + df_test['Content']\nX_final = df_test['Text'].to_dense().values","640fb5ad":"# Make predictions on the unlabeled data\n\nX_train_gen = [x for x in X]\ntfidf.fit(X_train_gen)\nX_train_vec = tfidf.transform(X_train_gen)\nboost.fit(X_train_vec, y)\nX_test_gen = [x for x in X_final]\nX_test_vec = tfidf.transform(X_test_gen)\ny_pred = boost.predict(X_test_vec)","fcb4e35a":"df_results = pd.DataFrame({'Id':df_test['Id'], 'Predicted':y_pred})","7dcde8c2":"df_results.to_csv('testSet_categories.csv',index=False, header=True)","1628441b":"Let's see a sample (title and content).","cfd166ce":"As we can see, the performance of the voting ensemble classifier is better than that of each one of the individual classifiers that it uses. Moreover, the F-Measure seems very close to -but is actually lower than- the one that our solution scored on the public leaderboard (0.97748).\n\nSince we know have a more trustworthy estimation of the final performance of the voting ensemble, we can train it with the whole dataset and make predictions on the unlabelled test data for the deliverable of the competition.","da35f99b":"In this notebook, we will present the winning solution of the **BigData2020 Classification**, a Kaggle contest created for the **\"Big Data Analytics\"** postgraduate course of the Department of Informatics at the University of Athens. The contest was a very close call, which can be seen from the fact that while our solution was 2nd on the public leaderboard, it eventually came 1st on the private leaderboard (Dimitrios Roussis and Thanasis Polydoros).\n\nI decided to describe our solution in this kernel exactly because I am sure that most teams went to great lengths to win this competition and would probably find it useful. I certainly do not want to spoil the fun for the future students, but I do hope that they will enjoy the challenge as much as we did and actually come up with new and better solutions! Consequently, I will focus only on the parts which are relevant for our approach.\n\nWithout further ado, I will go on to explain what this contest was about, how we tackled the problem and which measure was used. We are given a dataset which contains 111,795 news articles which are labelled as one of the 4 following categories: **Business, Technology, Entertainment** and **Health**. Below, we will first do some minimal preprocessing, extract features with a TF-IDF vectorizer and train a voting classifier.\n\nThe metrics that we measure are the usual ones: Accuracy, Precision, Recall and the F-Measure (also F-Score and also F1 Score). The competition however used only the **F-Measure (Macro)** for the evaluation and the score of our approach was **97.748%** (public leaderborad). So, let us import the necessary libraries and go through the aforementioned steps.","c67b75e2":"Finally, we can move on to the classification of the news articles and for this reason, we will define two functions which will help us evaluate each classifier that we use.","fb7e6c55":"# News Articles Classification (TF-IDF + Voting Ensemble)","b95a7a94":"It is a always a good idea to check the distribution of the classes in a dataset and as we will see, the current dataset is somewhat imbalanced.","d580b167":"In order to use **both the titles and the contents** of each news article, we will concatenate them in a single column from which the features will be extracted.","02e25020":"Below, we define all the necessary tools that will be used to train our final classifier. Note that we do not show the actual process of how we ended up using the hyper-parameters of the TF-IDF Vectorizer or those of the classification algorithms, as that would be very time-consuming (not to mention that it would spoil the fun). \n\nNevertheless, we will make some important remarks:\n- The **TF-IDF Vectorizer** is a feature extraction technique for texts which treats each word and each sequence of two words as tokens for which their term-frequency multiplied by the inverse document-frequency is returned. This essentially means that the TF-IDF vectorizer takes into account not only how many times each word or **bigram** (sequence of two words) appears in a given text, but also how many times it appears overall. We also set upper (max_df=0.5) and lower (min_df=3) thresholds for the document-frequency; this is because a given term (word or bigram) will probably not improve the accuracy of our classifier if it only occurs in a couple samples (note that they are now combinations of the title and the content of each article and it is possible that a given term which is contained only in a single article seems to appear 2 times) nor if it occurs in more than half the articles. This is an easy way to remove reoccuring words and small phrases and has a similar effect with the removal of the stop words.\n- Each classification algorithm is evaluated using **5-fold cross validation** on just 80% of the training data ('X_train_cv' and 'y_train_cv'), while the rest 20% is meant for the final testing ('X_test' and 'y_test'). The evaluation with 5-fold cross validation can give us a very good sense of which algorithms perform better on the specific task, as well as which hyper-parameters of both the classifiers and the TF-IDF vectorizer we should use.\n- The final classification, however, is done by a **voting ensemble classifier** which combines 3 classifiers and gives as an output the predicted label which has the majority vote among the predictions of those classifiers. It is tested on the final test set in order to get a better estimate of its actual performance. This is partially because the hyper-parameters of the classifiers -as well as the choice of which ones to use- are \"fitted\" on the training and cross-validation set and thus, we could not be very confident of how well does our voting ensemble classifier actually generalize on uknown data.","77a2f907":"We can see that the dataset contains a column named \"Id\" which is not useful for our analysis and will be removed.","11f96421":"**PLEASE DO NOT FORGET TO UPVOTE IF YOU LIKED THIS KERNEL!**","18dc4029":"We will also go ahead and remove the duplicate articles, i.e. those articles that have the exact same content. We also want to know how many of them were actually removed."}}