{"cell_type":{"6617c3fb":"code","f4970aaa":"code","cdedcf41":"code","8f915b90":"code","212861b7":"code","abc86069":"code","87f67ebc":"code","924a891a":"code","ad087e2d":"code","751ca55c":"code","5f73cd6e":"code","4198b950":"code","ee1d806c":"code","ef5a087b":"code","ca0e715b":"code","fbfd7fbb":"code","c3cfb7ba":"code","6cd7ab9d":"code","2e126946":"code","893814b7":"code","cf32eaa0":"code","8cfff3ff":"markdown","842fdd11":"markdown","b2a7faa1":"markdown","b6accaea":"markdown","1125ae96":"markdown","d29795a0":"markdown","588ad43e":"markdown","838ffe9f":"markdown","48890b9e":"markdown"},"source":{"6617c3fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nimport sys\n# Any results you write to the current directory are saved as output.\nfrom datetime import datetime\nfrom IPython.core.display import display, HTML\nfrom matplotlib import pyplot    \nimport math\nimport csv\nbln_create_df_all_csv_file = True\nbln_create_words_csv_file = False\nint_df_all_version = 6\nbln_ready_to_commit = True\nbln_create_estimate_files = False\nbln_upload_input_estimates = False\nbln_recode_variables = True\npd.set_option(\"display.max_rows\", 150)\npd.set_option(\"display.max_columns\", 100)\npd.set_option('max_colwidth', 60)\n\ndf_time_check = pd.DataFrame(columns=['Stage','Start','End', 'Seconds', 'Minutes'])\nint_time_check = 0\ndat_start = datetime.now()\ndat_program_start = dat_start\n\nif not bln_ready_to_commit:\n    int_read_csv_rows = 100000\nelse:\n    int_read_csv_rows= None\n    \n# generate crosstabs  {0 = nothing; 1 = screen}\nint_important_crosstab = 1\nint_past_crosstab = 0\nint_current_crosstab = 1\n\nbln_read_train = True\nbln_read_test = True","f4970aaa":"def get_translations_analysis_description(df_input, str_language, str_group, int_code):\n    # created by darryldias 25may2018\n    df_temp = df_input[(df_input['language']==str_language) & (df_input['group']==str_group) & (df_input['code']==int_code)] \\\n                    ['description']\n    return df_temp.iloc[0]\n\n#translations_analysis = pd.read_csv('..\/input\/ulabox-translations-analysis\/translations_analysis.csv')\nstrg_count_column = 'count'   #get_translations_analysis_description(translations_analysis, str_language, 'special', 2)\n\ndef start_time_check():\n    # created by darryldias 21may2018 - updated 8june2018\n    global dat_start \n    dat_start = datetime.now()\n    \ndef end_time_check(dat_start, str_stage):\n    # created by darryldias 21may2018 - updated 8june2018\n    global int_time_check\n    global df_time_check\n    int_time_check += 1\n    dat_end = datetime.now()\n    diff_seconds = (dat_end-dat_start).total_seconds()\n    diff_minutes = diff_seconds \/ 60.0\n    df_time_check.loc[int_time_check] = [str_stage, dat_start, dat_end, diff_seconds, diff_minutes]\n\ndef create_topline(df_input, str_item_column, str_count_column):\n    # created by darryldias 21may2018; updated by darryldias 29may2018\n    str_percent_column = 'percent'   #get_translations_analysis_description(translations_analysis, str_language, 'special', 3)\n    df_temp = df_input.groupby(str_item_column).size().reset_index(name=str_count_column)\n    df_output = pd.DataFrame(columns=[str_item_column, str_count_column, str_percent_column])\n    int_rows = df_temp.shape[0]\n    int_columns = df_temp.shape[1]\n    int_total = df_temp[str_count_column].sum()\n    flt_total = float(int_total)\n    for i in range(int_rows):\n        str_item = df_temp.iloc[i][0]\n        int_count = df_temp.iloc[i][1]\n        flt_percent = round(int_count \/ flt_total * 100, 1)\n        df_output.loc[i] = [str_item, int_count, flt_percent]\n    \n    df_output.loc[int_rows] = ['total', int_total, 100.0]\n    return df_output        \n\ndef get_size_raw(df_input):\n    return sys.getsizeof(df_input)\n\ndef get_size_mb(df_input):\n    int_size_raw = get_size_raw(df_input)\n    flt_size = float(int_size_raw) \/ 1000000 \n    return int(flt_size)\n\ndef get_dataframe_info(df_input, bln_output_csv = False, str_filename = None):\n    # created by darryldias 24may2018 - updated 25jan2019\n    int_rows = df_input.shape[0]\n    int_cols = df_input.shape[1]\n    flt_rows = float(int_rows)\n    int_size_mb = get_size_mb(df_input)\n\n    df_output = pd.DataFrame(columns=[\"Column\", \"Type\", \"Not Null\", 'Null', '% Not Null', '% Null'])\n    df_output.loc[0] = ['Table Row Count', '', int_rows, '', '', '']\n    df_output.loc[1] = ['Table Column Count', '', int_cols, '', '', '']\n    df_output.loc[2] = ['Table Size (MB)', '', int_size_mb, '', '', '']\n    int_table_row = 2\n    for i in range(int_cols):\n        str_column_name = df_input.columns.values[i]\n        str_column_type = df_input.dtypes.values[i]\n        int_not_null = df_input[str_column_name].count()\n        int_null = sum( pd.isnull(df_input[str_column_name]) )\n        flt_percent_not_null = round(int_not_null \/ flt_rows * 100, 1)\n        flt_percent_null = round(100 - flt_percent_not_null, 1)\n        int_table_row += 1\n        df_output.loc[int_table_row] = [str_column_name, str_column_type, int_not_null, int_null, flt_percent_not_null, flt_percent_null]\n\n    if bln_output_csv:\n        df_output.to_csv(str_filename)\n        print ('Dataframe information output created in file: ' + str_filename)\n        return None\n    return df_output\n\ndef check_numeric_var(str_question, int_groups):\n    # created by darryldias 3jul2018  \n    #print(df_output.iloc[3][2])\n    flt_min = application_all[str_question].min()\n    flt_max = application_all[str_question].max()\n    flt_range = flt_max - flt_min \n    flt_interval = flt_range \/ int_groups \n    df_output = pd.DataFrame(columns=['interval', 'value', 'count', 'percent', 'code1', 'code2'])\n\n    int_total = application_all[ (application_all[str_question] <= flt_max) ][str_question].count()\n    for i in range(0, int_groups + 1):\n        flt_curr_interval = i * flt_interval\n        flt_value = flt_min + flt_curr_interval\n        int_count = application_all[ (application_all[str_question] <= flt_value) ][str_question].count()\n        flt_percent = int_count \/  int_total * 100.0\n        str_code_value = \"{0:.6f}\".format(flt_value)\n        str_code1 = \"if row['\" + str_question + \"'] <= \" + str_code_value + \":\"\n        str_code2 = \"return '(x to \" + str_code_value + \"]'\"\n        df_output.loc[i] = [flt_curr_interval, flt_value, int_count, flt_percent, str_code1, str_code2]\n\n    return df_output\n\ndef find_file(str_input_variable):\n    df_file_info = pd.read_csv('..\/input\/dd15-files\/file_information2.csv')\n    int_rows = df_file_info.shape[0]\n    for i in range(int_rows):\n        str_dataset = df_file_info.iloc[i][1]\n        str_file = df_file_info.iloc[i][2]\n        str_column = df_file_info.iloc[i][3]\n        if str_column == str_input_variable:\n            str_file = str_file.replace('train', '')\n            return [str_dataset, str_file]\n\ndef load_variable_data(str_variable):\n    lst_file_info = find_file(str_variable)\n    df_temp = pd.read_csv( '..\/input\/' + lst_file_info[0] + '\/train' + lst_file_info[1] )\n    df_temp2 = pd.read_csv('..\/input\/dd15-files\/train_target.csv')\n    df_temp = pd.merge(df_temp, df_temp2, how='left', on=['KId'])\n    df_temp['train_or_test'] = 1\n    df_temp2 = pd.read_csv( '..\/input\/' + lst_file_info[0] + '\/test' + lst_file_info[1] )\n    df_temp2['train_or_test'] = 2\n    df_temp = pd.concat([df_temp, df_temp2], sort=False)\n    df_temp['overall'] = 1\n    return df_temp\n\ndef show_folder_items(str_folder):\n    # darryldias 8jan2019\n    df_return = pd.DataFrame(columns=['Folder', 'Item'])\n    lst_items = sorted( os.listdir(str_folder) )\n    int_row = 0\n    for str_item in lst_items:\n        int_row += 1\n        df_return.loc[int_row] = [str_folder, str_item]\n    \n    return df_return\n","cdedcf41":"def check_for_new_data():\n    df_return = pd.DataFrame(columns=['new data check'])\n    df_users = pd.read_csv('..\/input\/meta-kaggle\/Users.csv', usecols=['Id'])\n    int_db_rows = df_users.shape[0]\n    df_return.loc[1] = ['database rows: '+ str(int_db_rows)]\n\n    df_stats_01 = pd.read_csv('..\/input\/dd16s-files\/stats_01.csv')\n    df_stats_01 = df_stats_01[ df_stats_01['Variable']=='RegisterDateOverall' ]\n    int_01_rows = df_stats_01.iloc[0][2] \n    #print('01 rows:', int_01_rows)\n    int_stats_rows = int_01_rows\n    df_return.loc[2] = ['stats rows count: ' + str(int_stats_rows)]\n    \n    if int_db_rows == int_stats_rows:\n        df_return.loc[3] = ['no updating required']\n    else:\n        int_diff = int_db_rows - int_stats_rows \n        df_return.loc[3] = ['updating required - there are ' + str(int_diff) + ' missing rows']\n    return df_return\n\ndef get_month_description1 (int_input_month):\n    if int_input_month == 1 :   \n        return 'January'\n    elif int_input_month == 2 :   \n        return 'February'\n    elif int_input_month == 3 :   \n        return 'March'\n    elif int_input_month == 4 :   \n        return 'April'\n    elif int_input_month == 5 :   \n        return 'May'\n    elif int_input_month == 6 :   \n        return 'June'\n    elif int_input_month == 7 :   \n        return 'July'\n    elif int_input_month == 8 :   \n        return 'August'\n    elif int_input_month == 9 :   \n        return 'September'\n    elif int_input_month == 10 :   \n        return 'October'\n    elif int_input_month == 11 :   \n        return 'November'\n    elif int_input_month == 12 :   \n        return 'December'\n    else:\n        return 'Unknown'\n\ndef get_month_description2 (int_input_month):\n    return get_month_description1(int_input_month)[:3]\n\ndef ym_d1 (row, str_input_column):\n    int_ymd = row[str_input_column]\n    str_ymd = str(int_ymd)\n    int_m = int(str_ymd[4:6])\n    int_d = int(str_ymd[6:])\n    str_return = get_month_description2(int_m) + ' ' + str(int_d)\n    return str_return\n\ndef ym_d2 (row, str_input_column):\n    int_ym = row[str_input_column]\n    str_ym = str(int_ym)\n    int_m = int(str_ym[4:6])\n    str_return = get_month_description2(int_m) \n    return str_return\n\ndef show_information(str_message):\n    df_return = pd.DataFrame(columns=['information'])\n    df_return.loc[1] = [ str_message ]\n    display(df_return)   \n\ndef get_y_str_1 (int_ym):\n    str_input = str(int_ym)\n    return str_input[:4]\n\ndef get_stats_count(str_input_variable, int_input_value):\n    df_temp2 = df_stats[ (df_stats['Variable'] == str_input_variable) & (df_stats['Value'] == int_input_value) ]\n    #display( df_temp2.head() )\n    return df_temp2.iloc[0][2]\n","8f915b90":"df_stats = pd.read_csv('..\/input\/dd16s-files\/stats_01.csv')\ndf_info = pd.DataFrame(columns=['information'])\n\n# current month\ndf_temp2 = df_stats[ (df_stats['Variable'] == 'RegisterDateYM_C1') & (df_stats['Value'] > 0) ]\nint_ym_current = df_temp2.iloc[0][1]\nint_ym_current_count = df_temp2.iloc[0][2]\nstr_ym_current = str(df_temp2.iloc[0][1])\nstr_m_current = str_ym_current[4:] \nstr_m_current_desc = get_month_description1 ( int(str_m_current) )\ndf_info.loc[1] = [ 'the count for the current month ' + str_m_current_desc + ' is ' + str(int_ym_current_count) ]\n\n# overall\ndf_temp2 = df_stats[ df_stats['Variable'] == 'RegisterDateOverall' ]\nint_overall_count = df_temp2.iloc[0][2]\ndf_info.loc[2] = [ 'the overall count since 2010 is ' + str(int_overall_count) ]\n\n# last 14 days daily average\ndf_temp3 = df_stats[ (df_stats['Variable'] == 'RegisterDateYMD_C1') & (df_stats['Value'] > 0) ]\nint_value_max = df_temp3['Value'].max()\ndf_temp3 = df_stats[ (df_stats['Variable'] == 'RegisterDateYMD_C1') & (df_stats['Value'] > 0) & (df_stats['Value'] < int_value_max) ]\nint_mean = round( df_temp3['Count'].mean() )\ndf_info.loc[3] = [ 'the daily average for the last 14 days is ' + str(int_mean) ]\n\n# 12 months prior\nstr_variable = 'RegisterDateYM_C2'\ndf_tempf = df_stats[ (df_stats['Variable'] == str_variable) ]\nint_ym_12mprior = df_tempf['Value'].min()\nstr_y_12mprior = get_y_str_1(int_ym_12mprior)\nint_ym_12mprior_count = get_stats_count(str_variable, int_ym_12mprior)\nint_ym_current_count_estimate = get_stats_count(str_variable, int_ym_current)\n\ndf_info.loc[4] = [ 'for ' + str(str_m_current_desc) + ' ' + str(str_y_12mprior) + ' the count is ' + str(int_ym_12mprior_count) ]\ndf_info.loc[5] = [ 'the estimate for the whole current month is ' + str(int_ym_current_count_estimate) ]\n\ndf_info","212861b7":"df_temp2 = pd.read_csv('..\/input\/dd16s-files\/stats_01.csv')\ndf_temp2 = df_temp2[ (df_temp2['Variable'] == 'RegisterDateYM_C5') ]\ndf_temp2['Value_D1'] = df_temp2.apply(ym_d2, axis=1, str_input_column='Value')\ndf_temp2.head(20)","abc86069":"plot_temp = df_temp2.plot(x='Value_D1', y='Count', figsize=(10, 5), legend=None)","87f67ebc":"df_temp3 = pd.read_csv('..\/input\/dd16s-files\/stats_01.csv')\ndf_temp3 = df_temp3[ (df_temp3['Variable'] == 'RegisterDateYMD_C1') & (df_temp3['Value'] > 0) ]\ndf_temp3['Value_D1'] = df_temp3.apply(ym_d1, axis=1, str_input_column='Value')\ndf_temp3.head(20)","924a891a":"plot_temp = df_temp3.plot(x='Value_D1', y='Count', figsize=(10, 5), legend=None)","ad087e2d":"df_temp2 = pd.read_csv('..\/input\/dd16s-files\/stats_01.csv')\ndf_temp2 = df_temp2[ (df_temp2['Variable'] == 'RegisterDateYM_C3') & (df_temp2['Value'] > 0) ]\ndf_temp2['Value_D1'] = df_temp2.apply(ym_d2, axis=1, str_input_column='Value')\ndf_temp2.head(20)","751ca55c":"plot_temp = df_temp2.plot(x='Value_D1', y='Count', figsize=(10, 5), legend=None)","5f73cd6e":"df_temp2 = df_stats[ df_stats['Variable'] == 'RegisterDateYear' ]\ndf_temp2.head(20)","4198b950":"#df_temp2 = df_stats[ (df_stats['Variable'] == 'RegisterDateYear') & (df_stats['Value'] <= 2018) ]\ndf_temp2 = df_stats[ (df_stats['Variable'] == 'RegisterDateYear') ]\nplot_temp = df_temp2.plot(x='Value', y='Count', figsize=(10, 5), legend=None)","ee1d806c":"show_folder_items('..\/input')    ","ef5a087b":"show_folder_items('..\/input\/meta-kaggle')    ","ca0e715b":"show_folder_items('..\/input\/dd16-files')","fbfd7fbb":"show_folder_items('..\/input\/dd16s-files')","c3cfb7ba":"check_for_new_data()","6cd7ab9d":"df_users = pd.read_csv('..\/input\/meta-kaggle\/Users.csv')\nget_dataframe_info(df_users)","2e126946":"df_users.sample(10)","893814b7":"df_stats.sample(10)","cf32eaa0":"end_time_check(dat_program_start, 'overall')\ndf_time_check","8cfff3ff":"### last 15 days counts\n#### the most recent day's count is usually a partial count","842fdd11":"### notes \/ updates\n* this analysis concentrates on the users->registerdate field\n* I only do quick checks, so please use results with caution","b2a7faa1":"## register date counts","b6accaea":"### monthly counts\n#### the current month shows estimate for the whole month","1125ae96":"### other information (can be ignored)","d29795a0":"### rolling 12 month average\n#### uses estimate for the whole current month","588ad43e":"### external stats data (created from the kaggle meta data)","838ffe9f":"### yearly counts","48890b9e":"### source users data"}}