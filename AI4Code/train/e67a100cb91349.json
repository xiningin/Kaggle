{"cell_type":{"47724214":"code","f27ff888":"code","991ddd05":"code","32abaa3b":"code","1456e417":"code","2e4eee65":"code","3acac10a":"code","5604bb0f":"code","16788ecd":"code","145c709a":"code","e0750d3c":"code","5530e9e5":"code","eef2bc9f":"code","4716a802":"code","65db8682":"code","d903829b":"code","f576e477":"code","672d5643":"code","73ec9c16":"code","6378a8b6":"code","090a5e48":"code","a67a94f6":"code","4c2f93ed":"code","75168d2b":"code","6c239b25":"code","a59aa397":"markdown","16289ea0":"markdown","958273e4":"markdown","64eb5cee":"markdown","5f273808":"markdown","ee91301d":"markdown","9eb2f789":"markdown","703782dd":"markdown","11097a23":"markdown","4ddc8c17":"markdown","b9891669":"markdown"},"source":{"47724214":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom functools import partial\nimport optuna\n\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score,accuracy_score,log_loss\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f27ff888":"user_ratings=pd.read_csv('\/kaggle\/input\/board-games-database-from-boardgamegeek\/user_ratings.csv')\nsub_ctg=pd.read_csv('\/kaggle\/input\/board-games-database-from-boardgamegeek\/subcategories.csv')\nartist=pd.read_csv('\/kaggle\/input\/board-games-database-from-boardgamegeek\/artists_reduced.csv')\npublisher=pd.read_csv('\/kaggle\/input\/board-games-database-from-boardgamegeek\/publishers_reduced.csv')\ngame_df=pd.read_csv('\/kaggle\/input\/board-games-database-from-boardgamegeek\/games.csv')","991ddd05":"artist=artist.sort_values(by=['BGGId'])\npublisher=publisher.sort_values(by=['BGGId'])\ngame_df=game_df.sort_values(by=['BGGId'])\nsub_ctg=sub_ctg.sort_values(by=['BGGId'])\n\nsub_ctg=sub_ctg.drop(['BGGId'], axis=1)\npublisher=publisher.drop(['BGGId'], axis=1)\nartist=artist.drop(['BGGId'], axis=1)\ngame_df=game_df.drop(['Name', 'Description', 'GameWeight','NumWeightVotes','AvgRating', 'BayesAvgRating', 'StdDev', 'ComAgeRec', 'LanguageEase', 'BestPlayers', 'GoodPlayers', 'NumOwned', 'NumWant', 'NumWish', 'MfgPlaytime', 'ComMinPlaytime', 'ComMaxPlaytime', 'MfgAgeRec', 'NumUserRatings', 'NumComments', 'NumAlternates', 'NumExpansions', 'NumImplementations', 'IsReimplementation', 'Family', 'Kickstarted', 'ImagePath', 'Rank:boardgame', 'Rank:strategygames', 'Rank:abstracts', 'Rank:familygames', 'Rank:thematic', 'Rank:cgs', 'Rank:wargames', 'Rank:partygames', 'Rank:childrensgames', 'Cat:Thematic', 'Cat:Strategy', 'Cat:War', 'Cat:Family', 'Cat:CGS', 'Cat:Abstract', 'Cat:Party', 'Cat:Childrens'], axis=1)\nprint(\"Columns: {0}\".format(list(game_df.columns)))","32abaa3b":"target=user_ratings.groupby(by=[\"BGGId\"], dropna=False).mean()\ntarget=pd.DataFrame(target.reset_index())\n\ntarget=target.drop(['BGGId'], axis=1)\nfeatures=pd.concat([game_df,publisher,artist,sub_ctg],axis=1)\n\nimport re #column renaming for XGB\nregex = r\"[!\\\"#$%&'()*+,\\-.\\\/:;<=>?@[\\\\\\]^_`{|}~ ]+\"\nfeatures.columns = features.columns.str.replace(regex, '_', regex=True)\ntarget.columns = target.columns.str.replace(regex, '_', regex=True)\nfeatures.head()","1456e417":"#reverse one-hot encoding.\nsub_ctg=pd.DataFrame({\"ctg\":['Exploration', 'Miniatures', 'Territory Building', 'Card Game','Educational', 'Puzzle', 'Collectible Components', 'Word Game','Print & Play', 'Electronic']})\nsub_ctg=pd.concat([sub_ctg,target],axis=1)\nsub_ctg.head()\n\nseries = sub_ctg.groupby(['ctg']).Rating.mean()\nprint(series.to_string())\nsns.barplot(x = series.index, y = series.values)\nplt.title('Rating mean each category')\nplt.xlabel('Categories')\nplt.ylabel('Rating score')\n","2e4eee65":"game_df=pd.concat([game_df,target],axis=1)\nseries = game_df.groupby(['YearPublished']).Rating.mean()\nsns.barplot(x = series.index, y = series.values)\nplt.title('Rating mean each year')\nplt.xlabel('Years')\nplt.ylabel('Rating score')","3acac10a":"#game_df=pd.concat([game_df,target],axis=1)\nseries = game_df.groupby(['MinPlayers']).Rating.mean()\nseries.head()\nsns.barplot(x = series.index, y = series.values)\nplt.title('Rating mean each year')\nplt.xlabel('Minimum player requirements')\nplt.ylabel('Rating score')","5604bb0f":"#game_df=pd.concat([game_df,target],axis=1)\nseries = game_df.groupby(['MaxPlayers']).Rating.mean()\nsns.barplot(x = series.index, y = series.values)\nplt.title('Rating mean each year')\nplt.xlabel('Years')\nplt.ylabel('Rating score')","16788ecd":"corrMatrix = game_df.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","145c709a":"def smape(a, f):\n    return 1\/len(f) * np.sum(2 * np.abs(f-a) \/ (np.abs(a) + np.abs(f))*100)","e0750d3c":"# split data\nX_train,X_val,y_train,y_val = train_test_split(features,target,test_size=0.05,shuffle=False)","5530e9e5":"model1 = LinearRegression()\nmodel1.fit(X_train, y_train)\npredictions = model1.predict(X_val)\nsmape(y_val,predictions)","eef2bc9f":"plt.plot(X_val.index,y_val)\nplt.plot(X_val.index,predictions)","4716a802":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\n\nxgb = xgb.XGBRegressor(n_estimators=1000)\nxgb.fit(X_train, y_train,eval_set=[(X_train,y_train),(X_val, y_val)],early_stopping_rounds=25,verbose=False)","65db8682":"predictions = xgb.predict(X_val)\nplt.plot(X_val.index,predictions)\nplt.plot(X_val.index,y_val)","d903829b":"smape(y_val.values.T,predictions)","f576e477":"from matplotlib import pyplot\n# plot learning curves\nresults = xgb.evals_result()\nplt.figure(figsize=(10, 8))\npyplot.plot(results['validation_0']['rmse'], label='train')\npyplot.plot(results['validation_1']['rmse'], label='test')\n# show the legend\npyplot.legend()\nplt.xlabel('iterations')\nplt.ylabel('rmse')\n# show the plot\npyplot.show()","672d5643":"from catboost import CatBoostRegressor\ncat = CatBoostRegressor()\ncat.fit(X_train,y_train,eval_set=(X_val,y_val),early_stopping_rounds=500,verbose=False)\nsmape(y_val.values.T,cat.predict(X_val))","73ec9c16":"def objective(trial,X,y, name='xgb'):\n    params = param = {\n        'tree_method':'gpu_hist',  \n        'lambda': trial.suggest_loguniform(\n            'lambda', 1e-3, 10.0\n        ),\n        'alpha': trial.suggest_loguniform(\n            'alpha', 1e-3, 10.0\n        ),\n        'eta': trial.suggest_float('eta', 1e-5, 0.1),\n        'colsample_bytree': trial.suggest_categorical(\n            'colsample_bytree', [0.5,0.6,0.7,0.8,0.9,1.0]\n        ),\n        'subsample': trial.suggest_categorical( \n            'subsample', [0.6,0.7,0.8,1.0]\n        ),\n        'learning_rate': trial.suggest_categorical(\n            'learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]\n        ),\n        'n_estimators': trial.suggest_categorical(\n            \"n_estimators\", [150, 200, 300,1000, 1500,2000, 3000]\n        ),\n        'max_depth': trial.suggest_categorical(\n            'max_depth', [4,5,7,9,11,13,15,17]\n        ),\n        'random_state': 42,\n        'min_child_weight': trial.suggest_int(\n            'min_child_weight', 1, 300\n        ),\n        'random_state':10\n    }\n\n    model =  XGBRegressor(**params)\n    model.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=50,verbose=False)\n\n\n    train_score = np.round(np.sqrt(mean_squared_error(y_train, model.predict(X_train))), 5)\n    test_score = np.round(np.sqrt(mean_squared_error(y_val, model.predict(X_val))), 5)\n                  \n    print(f'TRAIN RMSE : {train_score} || TEST RMSE : {test_score}')\n                  \n    return test_score","6378a8b6":"#%%time\n#optimize = partial(objective,X=X_train,y=y_train)\n\n#lgbm = optuna.create_study(direction ='minimize')\n#lgbm.optimize(optimize,n_trials=50)","090a5e48":"params ={'lambda': 0.0029172766068385, 'alpha': 0.011838921441892596, 'eta': 0.0843347405522399, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 4, 'min_child_weight': 2}","a67a94f6":"xgb = XGBRegressor(**params)\nxgb.fit(X_train, y_train,\n        eval_set=[(X_train,y_train),(X_val, y_val)],\n        early_stopping_rounds=60,\n       verbose=False)","4c2f93ed":"predictions = xgb.predict(X_val)\nsmape(y_val.values.T,predictions)","75168d2b":"results = xgb.evals_result()\n\nfrom matplotlib import pyplot\n# plot learning curves\nresults = xgb.evals_result()\nplt.figure(figsize=(10, 8))\npyplot.plot(results['validation_0']['rmse'], label='train')\npyplot.plot(results['validation_1']['rmse'], label='test')\n# show the legend\npyplot.legend()\nplt.xlabel('iterations')\nplt.ylabel('rmse')\n# show the plot\npyplot.show()","6c239b25":"y = predictions\nx = range(len(predictions))\nplt.figure(figsize=(15,6))\nplt.plot(x,y)\nplt.plot(x,y_val,'red')","a59aa397":"**Trial 24 finished with value: 0.7244 and parameters: {'lambda': 0.0029172766068385, 'alpha': 0.011838921441892596, 'eta': 0.0843347405522399, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.016, 'n_estimators': 3000, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 24 with value: 0.7244.**","16289ea0":"# Model Training","958273e4":"> **What is the effect of the minimum player requirements on the score?**","64eb5cee":"# Hyper Paramameter Tuning","5f273808":"> **What is the effect of the published year on the score?**","ee91301d":"# Results","9eb2f789":"**Correlation between all parameters and other parameters.**","703782dd":"# Feature Engineering\n> **We need artists, publishers, game categories and some game features.**\n\n> **In this case we get only published year, minimum player requiremnts and maximum player requirements columns from game features dataset.**\n\n> **We get all featuers other datasets.**\n\n> **In this way we predict game rating.**","11097a23":"# Exploratory Data Analysis\n\n> **What is the effect of the category on the score?**","4ddc8c17":"> **What is the effect of the maximum player requirements on the score?**","b9891669":"> **We create target with user rating dataset and create features merge all feature with concat.**"}}