{"cell_type":{"99cd1646":"code","e130698b":"code","70e20ba3":"code","b7f402d3":"code","a5679a8f":"code","4d431e32":"code","cc77d81c":"code","e4f7a037":"code","6de1030c":"code","56b32fc9":"code","ed00a10a":"code","66e4dcc3":"code","025e4008":"code","66cdada9":"code","dfb84720":"code","fe68114c":"code","7e13b01e":"code","2cf08947":"code","d2a3dcbd":"code","b39ed8a4":"code","3b57e9c8":"code","a672a3f9":"code","f5140aea":"code","519d7ad3":"code","84c539d5":"code","5be581dc":"code","c249c957":"code","8ff04eb8":"markdown","a6402dad":"markdown","cb6fc21b":"markdown","343c4a65":"markdown","1d5b6e40":"markdown","0f7610ca":"markdown","c4ef5f85":"markdown","59f33707":"markdown","90567a1c":"markdown"},"source":{"99cd1646":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e130698b":"df=pd.read_csv('\/kaggle\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","70e20ba3":"df['sentiment'].replace({'positive':1,'negative':0},inplace=True)","b7f402d3":"df.head()","a5679a8f":"import re\ndef clean_html(text):\n    clean=re.compile('<.*?>')\n    return re.sub(clean,'',text)\ndf['review']=df['review'].apply(clean_html)","4d431e32":"def convert_lower(text):\n    return text.lower()\ndf['review']=df['review'].apply(convert_lower)","cc77d81c":"def remove_special(text):\n    x=''\n    \n    for i in text:\n        if i.isalnum():\n            x=x+i\n        else:\n            x=x+' '\n    return x\ndf['review']=df['review'].apply(remove_special)","e4f7a037":"import nltk\nfrom nltk.corpus import stopwords\ndef remove_stopwords(text):\n    x=[]\n    for i in text.split():\n        \n        if i not in stopwords.words('english'):\n            x.append(i)\n    y=x[:]\n    x.clear()\n    return y\ndf['review']=df['review'].apply(remove_stopwords)","6de1030c":"from nltk.stem.porter import PorterStemmer\nps=PorterStemmer()\ny=[]\ndef stem_words(text):\n    for i in text:\n        y.append(ps.stem(i))\n    z=y[:]\n    y.clear()\n    return z\ndf['review']=df['review'].apply(stem_words)","56b32fc9":"def join_back(list_input):\n    return \" \".join(list_input)\ndf['review']=df['review'].apply(join_back)","ed00a10a":"df","66e4dcc3":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features=1000)\nX=cv.fit_transform(df['review']).toarray()","025e4008":"X.shape","66cdada9":"# taking out sentiment column into y \n\ny=df.iloc[:,-1].values","dfb84720":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2)","fe68114c":"X_train.shape","7e13b01e":"X_test.shape","2cf08947":"y_test.shape","d2a3dcbd":"y_train.shape","b39ed8a4":"from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n","3b57e9c8":"clf1=GaussianNB()\nclf2=MultinomialNB()\nclf3=BernoulliNB()","a672a3f9":"clf1.fit(X_train,y_train)\nclf2.fit(X_train,y_train)\nclf3.fit(X_train,y_train)\n","f5140aea":"#testing\ny_pred1=clf1.predict(X_test)\ny_pred2=clf2.predict(X_test)\ny_pred3=clf3.predict(X_test)","519d7ad3":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix","84c539d5":"print(\"Gaussian\",f1_score(y_test,y_pred1))\nprint(\"Multinomial\",f1_score(y_test,y_pred2))\nprint(\"Bernoulli\",f1_score(y_test,y_pred3))\n#f1_score(y_test,y_pred1)","5be581dc":"print(\"Gaussian\",confusion_matrix(y_test,y_pred1))\nprint(\"Multinomial\",confusion_matrix(y_test,y_pred2))\nprint(\"Bernoulli\",confusion_matrix(y_test,y_pred3))","c249c957":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nwc=WordCloud(background_color=\"white\", contour_color=\"steelblue\")\ns=''\nfor i in range(1,50000):\n    s=s+df['review'][i]\nwc.generate(s)\nplt.imshow(wc,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n#WordCloud(df['sentiment'])","8ff04eb8":"> # Removing HTML Tags","a6402dad":"# **2. Count Vectorization**","cb6fc21b":"# **4.Model Evaluation and Confussion Matrix**","343c4a65":"> # Remove the stop words","1d5b6e40":"# **1.Data Preprocessing**","0f7610ca":"# **3.Building and Applying model**","c4ef5f85":"> # Perform **Stemming**","59f33707":"> # Function to remove special characters","90567a1c":"> # Converting everything to lower"}}