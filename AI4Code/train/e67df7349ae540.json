{"cell_type":{"75d90864":"code","d836e6dc":"code","59b45e45":"code","f10592e5":"code","33a40014":"code","e16feb02":"code","cb8e602b":"code","714bf5ce":"code","13fbf09e":"code","29d8492e":"code","a5b34b92":"code","957e3df1":"code","71292028":"code","d6a1f482":"code","8d66b480":"code","c128ecd0":"code","09e732b3":"code","b8d56692":"code","2ffc4bdd":"code","c1e0fbf2":"code","4afc1951":"code","bb6deef9":"code","fda384ed":"code","e1dfff70":"code","b12f390d":"code","a9c10eeb":"code","18369238":"code","db4abeb3":"code","c6f4ca9b":"code","6ffc8383":"code","d0370c36":"code","56196f72":"code","170945ae":"code","be539c52":"code","8220be7d":"code","77b9ee31":"code","a8f54775":"code","7f515cb9":"code","a0d98917":"code","aec5548a":"code","4d631bb2":"code","13c71166":"code","ea4d4db1":"markdown","86a80da5":"markdown","6112f0a7":"markdown","0daddf01":"markdown","a9f4bda7":"markdown","c42e7584":"markdown","6f2b06c1":"markdown","01ed4839":"markdown","185f8f9a":"markdown","dc81308b":"markdown","fb0a036a":"markdown","d29a8926":"markdown","438c37fb":"markdown","9e9905b9":"markdown","831a26dc":"markdown","0d751f2f":"markdown","20e882fd":"markdown"},"source":{"75d90864":"# Import Libraries\n%matplotlib inline\nimport numpy as np                                         ## Numerical Python for data analysis\nimport pandas as pd                                        ## Python Pandas for data analysis\nimport seaborn as sns                                      ## Seaborn for data visualization\nimport matplotlib.pyplot as plt                            ## Matrix plot library for data visualization\nfrom sklearn.model_selection import train_test_split       ## train and test split of data for model training and pred\nfrom sklearn.linear_model import LogisticRegression        ## To perform Logistic Regression\nfrom sklearn.metrics import confusion_matrix               ## Confusion matrix for Model Evaluation\nfrom sklearn.metrics import classification_report          ## To generate the classification report\nfrom sklearn.metrics import accuracy_score                 ## To check accuracy of linear\/polynomial model\nfrom sklearn import metrics                                ## To perform metrix related operation    \nimport warnings                                            ## To avoid Warning\nwarnings.filterwarnings('ignore')\n","d836e6dc":"## Reading Datasets using Pandas\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n","59b45e45":"## Extracting DataSets right below after using concatination\npd.concat([train.head(5),test.head(5)], keys=[\"Train_Data\",\"Test_Data\"])  ## Concated datasets, means 2nd dataframes display right below to first","f10592e5":"pd.concat([train.describe(),test.describe()], keys=[\"Train_Data\",\"Test_Data\"])","33a40014":"## Columns in the Train Data..\ntrain.columns","e16feb02":"## Checking of Null Values in the Train Data_Set\ntrain.isnull().sum().to_frame().T ","cb8e602b":"fig = plt.figure(figsize=(13, 13))                                                                    ## Figure size\nfig.subplots_adjust(hspace=0.4, wspace=1)                                                             ## Define Spaces in Subplot\n\nfor i in range(1, 11):                                                                                ## Apply for Loop for subplotting\n    \n    ax = fig.add_subplot(5, 2, i)\n    \n    if i==1:\n        plt.title('Features',fontsize=20)\n        sns.barplot(x=\"Sex\", y=\"Survived\",data=train)\n    \n    elif i==2:\n        \n        plt.title('Features in Percentage',fontsize=20)\n        Females=train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize=True)[1]*100\n        males=train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize=True)[1]*100\n        values1=[males,Females]\n        plt.pie(values1, labels=('males','Females'),explode=(0.0,0.1),autopct='%1.1f%%')\n    \n    elif i==3:\n        sns.barplot(x=\"Pclass\", y=\"Survived\",data=train)\n    \n    elif i==4:\n        \n        Pclass1=train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize=True)[1]*100\n        Pclass2=train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize=True)[1]*100\n        Pclass3=train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize=True)[1]*100\n        values2=[Pclass1,Pclass2,Pclass3]\n        plt.pie(values2, labels=('Pclass1','Pclass2','Pclass3'),explode=(0.1,0.0,0.0),autopct='%1.1f%%')\n    \n    elif i==5:\n        \n        sns.barplot(x=\"Pclass\", y=\"Survived\", hue = \"Sex\", data=train)\n    \n    elif i==6:\n        \n        PC1 = train[\"Survived\"][train[\"Sex\"] == 'female'][train['Pclass']==1].value_counts(normalize=True)[1]*100\n        PC12 = train[\"Survived\"][train[\"Sex\"] == 'male'][train['Pclass']==1].value_counts(normalize=True)[1]*100\n        PC2 = train[\"Survived\"][train[\"Sex\"] == 'female'][train['Pclass']==2].value_counts(normalize=True)[1]*100\n        PC22 = train[\"Survived\"][train[\"Sex\"] == 'male'][train['Pclass']==2].value_counts(normalize=True)[1]*100\n        PC3 = train[\"Survived\"][train[\"Sex\"] == 'female'][train['Pclass']==3].value_counts(normalize=True)[1]*100\n        PC33 = train[\"Survived\"][train[\"Sex\"] == 'male'][train['Pclass']==3].value_counts(normalize=True)[1]*100\n        values3=[PC1,PC12,PC2,PC22,PC3,PC33]\n        \n        plt.pie(values3, labels=('Class1-Female','Class1-Male','Class2-Female','Class2-Male','Class3-Female','Class3-Male'),autopct='%1.1f%%')\n    \n    elif i ==7:\n        \n        sns.barplot(x=\"SibSp\", y=\"Survived\",data=train)\n    \n    elif i == 8:\n        \n        a = train[\"Survived\"][train['SibSp'] == 0].value_counts(normalize=True)[1]*100\n        b = train[\"Survived\"][train['SibSp'] == 1].value_counts(normalize=True)[1]*100\n        c = train[\"Survived\"][train['SibSp'] == 2].value_counts(normalize=True)[1]*100\n        d = train[\"Survived\"][train['SibSp'] == 3].value_counts(normalize=True)[1]*100\n        e = train[\"Survived\"][train['SibSp'] == 4].value_counts(normalize=True)[1]*100\n        values4=[a,b,c,d,e]\n        plt.pie(values4, labels=('SibSp0','SibSp1','SibSp2','SibSp3','SibSp4'),autopct='%1.1f%%')\n    \n    elif i == 8:\n        \n        sns.barplot(x=\"Parch\", y=\"Survived\",data=train)\n    \n    elif i == 8:\n        P0=train[\"Survived\"][train[\"Parch\"] == 0].value_counts(normalize=True)[1]*100\n        P1=train[\"Survived\"][train[\"Parch\"] == 1].value_counts(normalize=True)[1]*100\n        P2=train[\"Survived\"][train[\"Parch\"] == 2].value_counts(normalize=True)[1]*100\n        P3=train[\"Survived\"][train[\"Parch\"] == 3].value_counts(normalize=True)[1]*100\n        P5=train[\"Survived\"][train[\"Parch\"] == 5].value_counts(normalize=True)[1]*100\n        values5=[P0,P1,P2,P3,P5]\n        plt.pie(values5, labels=('Parch0','Parch1','Parch2','Parch3','Parch5'),explode=(0.0,0.0,0.0,0.1,0.0),autopct='%1.1f%%')\n    \n    elif i==9:\n        \n        sns.barplot(x=\"Parch\", y=\"Survived\",data=train)\n    \n    elif i==10:\n        \n        P0=train[\"Survived\"][train[\"Parch\"] == 0].value_counts(normalize=True)[1]*100\n        P1=train[\"Survived\"][train[\"Parch\"] == 1].value_counts(normalize=True)[1]*100\n        P2=train[\"Survived\"][train[\"Parch\"] == 2].value_counts(normalize=True)[1]*100\n        P3=train[\"Survived\"][train[\"Parch\"] == 3].value_counts(normalize=True)[1]*100\n        P5=train[\"Survived\"][train[\"Parch\"] == 5].value_counts(normalize=True)[1]*100\n        values6=[P0,P1,P2,P3,P5]\n        plt.pie(values6, labels=('Parch0','Parch1','Parch2','Parch3','Parch5'),explode=(0.0,0.0,0.0,0.1,0.0),autopct='%1.1f%%')","714bf5ce":"## Age of People in Passenger Class and distribution plot of Age\nfig = plt.figure(figsize=(13, 8))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nplt.subplot(1,2,1)\nsns.boxplot(x='Pclass',y='Age',data=train)\nplt.subplot(1,2,2)\nsns.distplot(train['Age'].dropna(), kde=False, bins=30, color='Red')","13fbf09e":"## Assumed value of Ages inplace of Nan..\n\ndef Assumed_Age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 45\n        if Pclass == 2:\n            return 37\n        if Pclass == 3:\n            return 25\n    else:\n        return Age\n    ","29d8492e":"train['Age'] = train[['Age','Pclass']].apply(Assumed_Age,axis=1)","a5b34b92":"## Deal with Nan in Embarked column...\ntrain.isnull().sum().to_frame().T ","957e3df1":"train.dropna(subset=['Embarked'],inplace=True)","71292028":"train.drop(['Name','Ticket','Fare','Cabin'], axis=1, inplace=True)","d6a1f482":"train.isnull().sum().to_frame().T  ","8d66b480":"## Check the dtype of all columns\ntrain.info()","c128ecd0":"Sex_Mapping = {\"male\":0,\"female\":1}\ntrain['Sex']=train['Sex'].map(Sex_Mapping)","09e732b3":"train['Sex'].head()","b8d56692":"train['Sex'].isin(['0']).value_counts()","2ffc4bdd":"Embarked_Mapping = {'S':1,'C':2,'Q':3}\ntrain['Embarked']=train['Embarked'].map(Embarked_Mapping)","c1e0fbf2":"train.Embarked.head()","4afc1951":"train['Age']=train['Age'].astype('int64') ## from now on data type of Age column is int64","bb6deef9":"train.info()","fda384ed":"predictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","e1dfff70":"## Lgistic_Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\n\n#Accuracy\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(\"Accuracy:\",acc_logreg)","b12f390d":"print(classification_report(y_val,y_pred))  ##(y_test,predictions)","a9c10eeb":"print(confusion_matrix(y_val, y_pred))  ##y_test, predictions","18369238":"test.head()","db4abeb3":"test.drop(['Name','Ticket','Fare','Cabin'], axis=1, inplace=True) ## Drop down unnecessary columns ","c6f4ca9b":"test.info()","6ffc8383":"Sex_Mapp = {\"male\":0,\"female\":1}\ntest['Sex']=test['Sex'].map(Sex_Mapp)","d0370c36":"EM = {'S':1,'C':2,'Q':3}\ntest['Embarked']=test['Embarked'].map(EM)","56196f72":"test.isnull().sum().to_frame().T","170945ae":"def Age_Assumption(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 45\n        if Pclass == 2:\n            return 37\n        if Pclass == 3:\n            return 25\n    else:\n        return Age","be539c52":"test['Age'] = test[['Age','Pclass']].apply(Age_Assumption, axis=1)","8220be7d":"test['Age']=test['Age'].astype('int64')","77b9ee31":"test.isnull().sum().to_frame().T","a8f54775":"test.head()","7f515cb9":"idss = test['PassengerId']\npredictions = logreg.predict(test.drop(['PassengerId'], axis=1))\noutput = pd.DataFrame({\"PassengerId\":idss,\"Survived\":predictions})","a0d98917":"output.head(10)","aec5548a":"sns.countplot(x=\"Survived\", data=output)","4d631bb2":"output['Survived'].value_counts()","13c71166":"output.to_csv('submission.csv', index=False)","ea4d4db1":"From the above countplot it is predicted that 151 passengers has been survived whereas 267 passenger not survived.","86a80da5":"##### From our confusion matrix we conclude that:\n##### True positive:47 (We predicted a positive result and it was positive)\n#### True negative: 98(We predicted a negative result and it was negative)\n##### False positive: 21(We predicted a positive result and it was negative)\n##### False negative: 30(We predicted a negative result and it was positive)\n##### Accuracy = (TP+TN)\/total\n##### Accuracy = (47+98)\/196 ~ 74%\n##### Error Rate = (FP+FN)\/total\n##### Error rate = (24+28)\/196 ~26.53%\n- From the Confusion Matrix, we have estimated the accuracy which is 73.46% which is quite good at all..","6112f0a7":"- From the above box plot we can see that Age is consist between 27 and 48 in the Pclass-1, from 25 to 37 in Pclass-2 and 25 to 36 in the Pclass-3. \n- From these information ages can be assumed to fill up the null values in the Age column,\n- Let's consider Ages in Pclass-1 = 45, Pclass-2 = 35 and Pclass-3 = 45,  ","0daddf01":"- Dataframe consist of the survival in binary 0:notsurvived, 1:Survived ","a9f4bda7":"We can see that 177 missing values are present in the Age, 687 in Cabin and 2 in Embarked..","c42e7584":"### Apply Logistic Regression on Test Data to Predict Survived \n- To do that need to clean and transform the data \n- Assume age as done with train data\n- convert into binary and all must have same datatype","6f2b06c1":"1) Sex Feature- From the graph we can see that number of females survived more than man, which is about 79.7% and 20.3% respectively.\n\n2) Pclass-It tends for passanger class, Survival rate is more in Pclass1(46.8%) then other two classes (35.2% and 18% respectively). It might be because they have had given more services as Life Boats etc..\n\n- To sum up - from the figure it is observed that number of females survived more in all the passenger classes as compare to number of males. \n\n3) SibSp- Sibling and Spouse, It is noted that those who has 1 sibling has higher rate of survival (It might be husband\/wife, brothers\/sisters etc..). Rate of survival decreses linearly as number of sibling\/Spouse increases. To sum up, those who has more than 4 sibling\/spose has lesser chances of survive.\n\n4) Parch- Parent\/children, It can estimate from the figure that those who are 3 parent\/children are more likely to survive (around 27.3%). Simillarly, those who are 1 parent\/children also good rate of survived (25.1%), Also, number of parent\/children increases have lower rate of survival as it is seen from the above plot.\n\n\n- Now, lets see the age of passenger in each class--","01ed4839":"Now, All data is cleaned ","185f8f9a":"- Predictors and Target variable is required to train the data, \n- Predictors are -Pclass,Sex,SibSp,Parch,Embarked\n- Target variable is Survived column","dc81308b":"## Titanic Survival Predictions (Beginner)\n####  I have attempted to work my way through the Titanic Disaster dataset. Please consider upvoting if this is useful to you! :)\n\n#### Goal\nPrediction of  if a passenger survived the sinking of the Titanic or not. \nFor each in the test set, you must predict a 0 or 1 value for the variable.\n\n","fb0a036a":"Sex and Embarked are object, it need to get convert into binary, here, I used Map function","d29a8926":"##### In order to train the model, null values needs to get filled either dropped...\n\n##### Quetion is what to fill in NaNs = Mean of column, Median, Most Frequent or any specific values ??\n\n##### Before to be made any decision let's have a look at feature of each columns with Survival column","438c37fb":"Again Sex and Age has nan values.. have to replace them..\n\n- Logic for Age column has the same as performed in the train set..\n","9e9905b9":"- Again data needs to be numeric\/Binary.. \n- Need to perform Mapping for sex and Embarked column and Age columns needs to be in Int64 to train the model...","831a26dc":"- Embarked column has two nan Values, Lets drop those\n- It is assume that Name, Ticket, Fare, Cabin are not likely to relavant to train the model therefore, Therefore, we drop those columns..","0d751f2f":"\nThe data has been split into two groups:\n* training set (train.csv) -- The training set has been used to build machine learning models.\n* test set (test.csv) -- The test set will be used to see how well used model performs on unseen data.\n\n\n","20e882fd":"##### Analysis of Each column in Train_set"}}