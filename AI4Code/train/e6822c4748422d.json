{"cell_type":{"c500d06a":"code","91739bb2":"code","b0c926a4":"code","4912d5a5":"code","35e59641":"code","c0383cfc":"code","1388e86d":"code","41c5715c":"code","a47d75dd":"code","cf89a618":"code","4fb45b90":"code","dd84d479":"markdown","1ca0aa59":"markdown","61a7ca2c":"markdown","47ee5dab":"markdown","8abf25a1":"markdown"},"source":{"c500d06a":"from google.colab import drive\ndrive.mount('\/content\/drive')","91739bb2":"# Trying Bounding box\nimport cv2\nimport numpy as np\nfrom google.colab.patches import cv2_imshow\n\nimage = cv2.imread('test.JPG')\noriginal = image.copy()\n#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n\nROI_number = 0\ncnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    x, y, w, h = cv2.boundingRect(c)\n    cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n    ROI = original[y:y+h, x:x+w]\n    #cv2.imwrite('ROI_{}.png'.format(ROI_number), ROI)\n    ROI_number += 1\n\nimgResized = cv2.resize(image, (850, 850))  \ncv2_imshow(imgResized)\n","b0c926a4":"import os, cv2, pandas as pd, numpy as np\n\n# General Path\npath = \"\/content\/drive\/My Drive\/TCC\/resultados\/\"\n\n# List of paths \nfile_list = []\nfile_list.append(os.listdir(f\"{path}grau1\"))\nfile_list.append(os.listdir(f\"{path}grau2\"))\nfile_list.append(os.listdir(f\"{path}grau3\"))\n\n# List of classes\nclass_names=[\"grau1\", \"grau2\", \"grau3\"] \n\nX = []\ny = []\n\n# Count all images\ncontImages = 0\n\n# Feature extraction\nfor classes_files, classe in zip (file_list, range(10)):\n  for i in range(len(classes_files)):\n    name = str(path) + str(class_names[classe]) + str('\/') + str(classes_files[i]) \n    imagem = cv2.imread(name)\n    imagem = cv2.resize(imagem, (299, 299))  # <-- Resize method\n    img = np.asarray(imagem)\n    y.append(classe)      \n    X.append(img)\n    contImages += 1\n\n# Saving the extracted features (deep) in a csv file\nnp.save('X', X)\n\n# Saving the classes in a csv file\ndf_class = pd.DataFrame(y)\ndf_class.to_csv('y.csv', header=False, index=False)\n\nprint(f\"Number of images: {contImages}\")","4912d5a5":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# Model Fine Tuning\n\n# Scale pixels\ndef prep_pixels(train, test):\n\t# Convert from integers to floats\n\ttrain_norm = train.astype('float32')\n\ttest_norm = test.astype('float32')\n\t# Normalize to range 0-1\n\ttrain_norm = train_norm \/ 255.0\n\ttest_norm = test_norm \/ 255.0\n\t# Return normalized images\n\treturn train_norm, test_norm\n\n# Load the images and the corresponding labels\ny = pd.read_csv('y.csv', header=None)\ny = y.to_numpy()\ny = np.ravel(y)\n\nX = np.load('X.npy')\n\n# Holdout -> dividindo a base em treinamento (60%) e teste (40%), estratificada\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42, stratify=y)\n\n# Data normalization\ntrainX, testX = prep_pixels(X_train, X_test)\n\n# Preparing the labels\ntrainY = to_categorical(y_train)\ntestY = to_categorical(y_test)","35e59641":"from keras.applications.inception_v3 import preprocess_input, decode_predictions, InceptionV3\nfrom keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.losses import categorical_crossentropy\n\n# Load without the top FC Layers.\nincepctionv3_conv = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3)) \n\n# Create Model \ndef create_model():\n  # Model Creation\n  model = Sequential()\n  model.add(incepctionv3_conv)\n  model.add(Flatten())\n  model.add(Dense(1024, activation='relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(3, activation='softmax'))\n\n  # Fine Tunning -> Freeze the layers except the last 4 layers\n  for layer in model.layers[:-4]:\n      layer.trainable = False\n\n  # Compile the model\n  model.compile(loss=categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n\n  return model\n\n# Model creation\n#model = create_model()\n\n# Traning the model\n#filepath = os.path.join(path,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\n#history = model.fit(trainX, trainY, batch_size=128, epochs=40, verbose=1, validation_data=(testX, testY), validation_split=0.2, callbacks=[checkpoint])\n\n# Evaluate model\n#_, acc = model.evaluate(testX, testY, verbose=0)\n#print('Final Accuracy: > %.3f' % (acc * 100.0))","c0383cfc":"from keras.preprocessing.image import ImageDataGenerator\n\nmodel = create_model()\n\n# create data generator\ndatagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n\n# apply data generator\ndatagen.fit(trainX)\n\n# prepare iterator\nit_train = datagen.flow(trainX, trainY, batch_size=128)\n# fit model\nsteps = int(trainX.shape[0] \/ 64)\nhistory = model.fit_generator(it_train, epochs=50, verbose=1)\n\n# evaluate model\n_, acc = model.evaluate(testX, testY, verbose=0)\nprint('Test Accuracy: > %.3f' % (acc * 100.0))","1388e86d":"from keras.models import model_from_json\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.inception_v3 import preprocess_input\n\n# Saving the fine tuned model\n\ndef save_model(model):\n  # list of classes\n  class_names=['grau1', 'grau2', 'grau3'] \n\n  # Saving weights\n  model.save_weights('My_model_weights.h5')\n\n  # Save the model architecture\n  with open('My_model_architecture.json', 'w') as f:\n      f.write(model.to_json())\n\n  # Model reconstruction from JSON file\n  with open('My_model_architecture.json', 'r') as f:\n      model = model_from_json(f.read())\n\n  # Load weights into the new model\n  model.load_weights('My_model_weights.h5')","41c5715c":"# Applying the model\n# load an image from file\nimage = load_img(f\"{path}grau2\/1618_5.PNG\", target_size=(299, 299))\n\n# convert the image pixels to a numpy array\nimage = img_to_array(image)\n\n# reshape data for the model\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n\n# prepare the image for the VGG model\nimage = preprocess_input(image)\n\n# predict the probability across all output classes\nyhat = model.predict(image)\nprint(yhat)\n\n# retrieve the most likely result, e.g. highest probability\nlabel = np.argmax(yhat)\n\n# print the classification\nprint(class_names[label])","a47d75dd":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib as plt\nimport seaborn as sns\n\npredY = model.predict(testX)\n\npredY_arg = np.argmax(predY, axis=1)\ntestY_arg = np.argmax(testY, axis=1)\n\n# classification report\ncr = classification_report(testY_arg, predY_arg)\nprint(cr)\n\n# confusion matrix \ncm = confusion_matrix(testY_arg, predY_arg)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True)\n#plt.title('Confusion Matrix', fontsize = 20)","cf89a618":"# GRADE -> worth it\n\nimport cv2\nfrom google.colab.patches import cv2_imshow\n\nsize = 20\n\nimg = cv2.imread('2271-23.png')\n\nfor y in range(0, img.shape[0], size):\n  for x in range(0, img.shape[1], size):\n    #cv2.imwrite(f\"img{r}_{c}.png\",img[r:r+30, c:c+30,:])\n    cv2.rectangle(img, (x, y), (x + size, y + size), (36 ,255 ,12), 2)\n     \ncv2.imwrite('with-grade1.png', img)\ncv2_imshow(img)","4fb45b90":"# BOUNDING BOX -> not worth it\nimport cv2\nimport numpy as np\nfrom google.colab.patches import cv2_imshow\n\nimage = cv2.imread('img.jpg')\noriginal = image.copy()\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n\nROI_number = 0\ncnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if len(cnts) == 2 else cnts[1]\nfor c in cnts:\n    x, y, w, h = cv2.boundingRect(c)\n    cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n    ROI = original[y:y+h, x:x+w]\n    #cv2.imwrite('ROI_{}.png'.format(ROI_number), ROI)\n    ROI_number += 1\n\nimgResized = cv2.resize(image, (850, 850))  \ncv2_imshow(imgResized)\n","dd84d479":"# Analysis","1ca0aa59":"# Differents Techniques to get better performance","61a7ca2c":"# Saving the model","47ee5dab":"# Import database and Feature Extraction","8abf25a1":"# Predicting "}}