{"cell_type":{"b1fe6d2f":"code","142726d1":"code","ed5eb3a2":"code","e0d9c93d":"code","8251db60":"code","a197b879":"code","5bf1ca4e":"code","20395626":"code","83c8d753":"code","43d774d3":"code","8267d0f8":"code","16f85dc9":"code","edd71a49":"code","93bfecb1":"code","02925ade":"code","e1ebd346":"code","89fd1398":"code","25411b51":"code","531d2d05":"code","473d4750":"code","005fdb9e":"code","ec027e25":"code","3d9bc29d":"code","5aafc3bb":"code","76261359":"code","56a65bf9":"code","cb4f5379":"code","51c13fcc":"code","2276456d":"code","4615137a":"code","bbcbb682":"code","8ee835c3":"code","fc31ea25":"code","d8200513":"code","555101cf":"code","05c45a3e":"code","53e60b96":"markdown","6f492c7f":"markdown","725deb3b":"markdown","10ee97ef":"markdown","3a79e752":"markdown","d20b483e":"markdown","12079662":"markdown","eb724808":"markdown","f39c5ae5":"markdown","a5a44550":"markdown","d93ec3fb":"markdown","8f5816c6":"markdown","48ab1f89":"markdown","753b533a":"markdown","13289aeb":"markdown","2e183bf6":"markdown"},"source":{"b1fe6d2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","142726d1":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport nltk\n\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn import neighbors\nfrom scipy.spatial.distance import cosine\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS","ed5eb3a2":"df = pd.read_csv('..\/input\/amazon-fine-food-reviews\/Reviews.csv')","e0d9c93d":"#Basic Information shape and columns\nprint(df.columns)\nprint(df.shape)","8251db60":"#compute the count and mean value as group by the products\ncount = df.groupby(\"ProductId\", as_index=False).count()\nmean = df.groupby(\"ProductId\", as_index=False).mean()\n\n#merge two dataset create df1\ndf1 = pd.merge(df, count, how='right', on=['ProductId'])\n\n#rename column\ndf1[\"Count\"] = df1[\"UserId_y\"]\ndf1[\"Score\"] = df1[\"Score_x\"]\ndf1[\"Summary\"] = df1[\"Summary_x\"]\n\n#Create New datafram with selected variables\ndf1 = df1[['ProductId','Summary','Score',\"Count\"]]\ndf1","a197b879":"#choose only products have over 100 reviews\ndf1 = df1.sort_values(by=['Count'], ascending=False)\ndf2 = df1[df1.Count >= 100]\ndf2","5bf1ca4e":"#create new dataframe as combining all summary with same product Id\ndf4 = df.groupby(\"ProductId\", as_index=False).mean()\ncombine_summary = df2.groupby(\"ProductId\")[\"Summary\"].apply(list)\ncombine_summary = pd.DataFrame(combine_summary)\ncombine_summary.to_csv(\"combine_summary.csv\")\ncombine_summary","20395626":"#create with certain columns\ndf3 = pd.read_csv(\"combine_summary.csv\")\ndf3 = pd.merge(df3, df4, on=\"ProductId\", how='inner')\ndf3 = df3[['ProductId','Summary','Score']]\ndf3","83c8d753":"#function for tokenizing summary\ncleanup_re = re.compile('[^a-z]+')\ndef cleanup(sentence):\n    sentence = sentence.lower()\n    sentence = cleanup_re.sub(' ', sentence).strip()\n    sentence = \" \".join(nltk.word_tokenize(sentence))\n    return sentence","43d774d3":"#reset index and drop duplicate rows\ndf3[\"Summary_Clean\"] = df3[\"Summary\"].apply(cleanup)\ndf3 = df3.drop_duplicates(['Score'], keep='last')\ndf3 = df3.reset_index()\ndf3","8267d0f8":"docs = df3[\"Summary_Clean\"] \nvect = CountVectorizer(max_features = 100, stop_words='english') \nX = vect.fit_transform(docs) \n\ndf5 = pd.DataFrame(X.A, columns=vect.get_feature_names())\ndf5 = df5.astype(int)\ndf5","16f85dc9":"#save \ndf5.to_csv(\"df5.csv\")","edd71a49":"# First let's create a dataset called X\nX = np.array(df5)\n # create train and test\ntpercent = 0.9\ntsize = int(np.floor(tpercent * len(df5)))\ndf5_train = X[:tsize]\ndf5_test = X[tsize:]\n#len of train and test\nlentrain = len(df5_train)\nlentest = len(df5_test)","93bfecb1":"# Next we will instantiate a nearest neighbor object, and call it nbrs. Then we will fit it to dataset X.\nnbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(df5_train)\n\n# Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\ndistances, indices = nbrs.kneighbors(df5_train)","02925ade":"#find most related products\nfor i in range(lentest):\n    a = nbrs.kneighbors([df5_test[i]])\n    related_product_list = a[1]\n    \n    first_related_product = [item[0] for item in related_product_list]\n    first_related_product = str(first_related_product).strip('[]')\n    first_related_product = int(first_related_product)\n    second_related_product = [item[1] for item in related_product_list]\n    second_related_product = str(second_related_product).strip('[]')\n    second_related_product = int(second_related_product)\n    \n    print (\"Based on product reviews, for \", df3[\"ProductId\"][lentrain + i] ,\" and this average Score is \",df3[\"Score\"][lentrain + i])\n    print (\"The first similar product is \", df3[\"ProductId\"][first_related_product] ,\" and this average Score is \",df3[\"Score\"][first_related_product])\n    print (\"The second similar product is \", df3[\"ProductId\"][second_related_product] ,\" and this average Score is \",df3[\"Score\"][second_related_product])\n    print (\"-----------------------------------------------------------\")","e1ebd346":"df5_train_target = df3[\"Score\"][:lentrain]\ndf5_test_target = df3[\"Score\"][lentrain:lentrain+lentest]\ndf5_train_target = df5_train_target.astype(int)\ndf5_test_target = df5_test_target.astype(int)\n\nn_neighbors = 3\nknnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\nknnclf.fit(df5_train, df5_train_target)\nknnpreds_test = knnclf.predict(df5_test)\nprint (knnpreds_test)\n\nprint(classification_report(df5_test_target, knnpreds_test))\nprint (accuracy_score(df5_test_target, knnpreds_test))","89fd1398":"count = df.groupby(\"UserId\", as_index=False).count()\nmean = df.groupby(\"UserId\", as_index=False).mean()\n\n#merge two dataset create df1\ndf1 = pd.merge(df, count, how='right', on=[\"UserId\"])\n#rename column\ndf1[\"Count\"] = df1[\"ProductId_y\"]\ndf1[\"Score\"] = df1[\"Score_x\"]\ndf1[\"Summary\"] = df1[\"Summary_x\"]\n\n#Create New datafram with selected variables\ndf1 = df1[[\"UserId\",'Summary','Score',\"Count\"]]\ndf1","25411b51":"#choose only products have over 100 reviews\ndf1 = df1.sort_values(by=['Count'], ascending=False)\ndf2 = df1[df1.Count >= 100]\ndf2","531d2d05":"df4 = df.groupby(\"UserId\", as_index=False).mean()\ncombine_summary = df2.groupby(\"UserId\")[\"Summary\"].apply(list)\ncombine_summary = pd.DataFrame(combine_summary)\ncombine_summary.to_csv(\"combine_summary.csv\")\ncombine_summary","473d4750":"df3 = pd.read_csv(\"combine_summary.csv\")\ndf3 = pd.merge(df3, df4, on=\"UserId\", how='inner')\ndf3 = df3[['UserId','Summary','Score']]","005fdb9e":"df3[\"Summary_Clean\"] = df3[\"Summary\"].apply(cleanup)","ec027e25":"df3 = df3.drop_duplicates(['Score'], keep='last')\ndf3 = df3.reset_index()","3d9bc29d":"docs = df3[\"Summary_Clean\"] \nvect = CountVectorizer(max_features = 100, stop_words='english') \nX = vect.fit_transform(docs) \ndf5 = pd.DataFrame(X.A, columns=vect.get_feature_names())\ndf5 = df5.astype(int)\ndf5","5aafc3bb":"df5.to_csv(\"df5.csv\")\nkkk  = df.drop_duplicates(['Summary'], keep='last')\nkkk = kkk.reset_index()","76261359":"# First let's create a dataset called X, with 6 records and 2 features each.\nX = np.array(df5)\n\ntpercent = 0.95\ntsize = int(np.floor(tpercent * len(df5)))\ndf5_train = X[:tsize]\ndf5_test = X[tsize:]\n\nlentrain = len(df5_train)\nlentest = len(df5_test)\n\n# Next we will instantiate a nearest neighbor object, and call it nbrs. Then we will fit it to dataset X.\nnbrs = NearestNeighbors(n_neighbors=3, algorithm='ball_tree').fit(df5_train)\n\n# Let's find the k-neighbors of each point in object X. To do that we call the kneighbors() function on object X.\ndistances, indices = nbrs.kneighbors(df5_train)","56a65bf9":"#finding similar user and intereting products\nfor i in range(lentest):\n    a = nbrs.kneighbors([df5_test[i]])\n    related_product_list = a[1]\n    \n    first_related_product = [item[0] for item in related_product_list]\n    first_related_product = str(first_related_product).strip('[]')\n    first_related_product = int(first_related_product)\n    second_related_product = [item[1] for item in related_product_list]\n    second_related_product = str(second_related_product).strip('[]')\n    second_related_product = int(second_related_product)\n    \n    print (\"Based on  reviews, for user is \", df3[\"UserId\"][lentrain + i])\n    print (\"The first similar user is \", df3[\"UserId\"][first_related_product], \".\") \n    print (\"He\/She likes following products\")\n    for i in range(295743):\n        if (kkk[\"UserId\"][i] == df3[\"UserId\"][first_related_product]) & (kkk[\"Score\"][i] == 5):\n            aaa= kkk[\"ProductId\"][i]\n        \n            print (aaa),\n    print (\"--------------------------------------------------------------------\")","cb4f5379":"df5_train_target = df3[\"Score\"][:lentrain]\ndf5_test_target = df3[\"Score\"][lentrain:lentrain+lentest]\ndf5_train_target = df5_train_target.astype(int)\ndf5_test_target = df5_test_target.astype(int)\n\nn_neighbors = 3\nknnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\nknnclf.fit(df5_train, df5_train_target)\nknnpreds_test = knnclf.predict(df5_test)\nprint (\"Predicting review score for testset user are : \", knnpreds_test)\n\nprint(classification_report(df5_test_target, knnpreds_test))","51c13fcc":"cluster = df.groupby(\"Score\")[\"Summary\"].apply(list)","2276456d":"cluster = pd.DataFrame(cluster)\ncluster.to_csv(\"cluster.csv\")\ncluster1 = pd.read_csv(\"cluster.csv\")","4615137a":"cluster1[\"Summary_Clean\"] = cluster1[\"Summary\"].apply(cleanup)","bbcbb682":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=500,\n        max_font_size=30, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n    \n    fig = plt.figure(1, figsize=(8, 8))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","8ee835c3":"show_wordcloud(cluster1[\"Summary_Clean\"][0], title = \"Review Score One\")","fc31ea25":"show_wordcloud(cluster1[\"Summary_Clean\"][1] , title = \"Review Score Two\")","d8200513":"show_wordcloud(cluster1[\"Summary_Clean\"][2], title = \"Review Score Three\")","555101cf":"show_wordcloud(cluster1[\"Summary_Clean\"][3], title = \"Review Score Four\")","05c45a3e":"show_wordcloud(cluster1[\"Summary_Clean\"][4], title = \"Review Score Five\")","53e60b96":"# 1.2 KNN classifier to find similar products","6f492c7f":"# 3.1 World Clouding for Each Score Group","725deb3b":"# 1.1 Text Clean process - Summary column","10ee97ef":"# 1. Product based collaborative filtering","3a79e752":"There are two goals of for the recommender system, first is to be able to effectively predict quantitative reviews based on qualitative reviews; second is to provide each customers with relevant products using textual mining; third is to combine the first and second step to allow for recommendation of similar products, which are likely to be purchased and enjoyed by the customers.","d20b483e":"Recommending a product to the customers based on textual review can result in recommending a product with similar quality but bad reputation.","12079662":"# 2.2 KNN classifier to find similar user and find their interesting products","eb724808":"# 2. User based collaborative filtering","f39c5ae5":"# 3. Word correltation based on cluster","a5a44550":"I found that finding links between the quantitative and qualitative review and using the correlation between two review types are effective in finding a relevant and positive product for the customers.","d93ec3fb":"In order to recommend products to the potential customers, understanding textual review and quantitative review and also undermining the relationship between two distinct review methods is important.","8f5816c6":"# import data","48ab1f89":"Recommending a product to the customers solely on the quantitative review could results in recommendation of an irrelevant product. ","753b533a":"# 1.3 Predicting Review Score","13289aeb":"# Introduction\nIn order to predict a user\u2019s response to a product, it is necessary to understand the tastes of the user and the properties of the product. The taste of the user can be learned from user\u2019s review of various products. The properties of the product can be obtained by mining the reviews given by multiple users. Attainment of the tastes of the user and properties of the product will allow us to estimate whether a user will have positive or negative reactions to the products.\nIn order to do so, the model: \n* Step 1: attempts to find similar products based on qualitative reviews.\n* Step 2, compares quantitative review and qualitative review to create a connection between the two distinctive scales\n* Step 3: analyze each user\u2019s qualitative review and recommend the products using Step 1 and filter out the low ranking products by incorporating Step 2 With these steps, the model is able to create a strong recommendation for the customers by comparing the quantitative and qualitative review of the sample population with the specific customer\u2019s reviews.","2e183bf6":"# 2.3 Predicting Review Score"}}