{"cell_type":{"d6bd4858":"code","8bc5ee7a":"code","fb1df9e6":"code","24be4eeb":"code","c48166b2":"code","afb7dfa5":"code","a9068bda":"code","bebfb4b0":"code","a4072686":"code","a6b83441":"code","a022382c":"code","f25e1ce5":"code","6bc81b88":"code","993bda8d":"code","7cd4c8c7":"code","025ad28b":"code","0267b341":"code","4be69e88":"code","ce7528d6":"code","15f0554e":"code","bcedc95f":"code","7504893d":"code","bdb0fc75":"code","56d56924":"code","d7028744":"code","898d52dc":"code","f137e071":"code","505e6f7b":"code","165236de":"code","1dc18066":"code","ef182777":"code","dd2957cc":"code","a5a48154":"code","50663f63":"code","986b22ac":"code","d43f7679":"code","2fa65f62":"code","950027c8":"code","4cfa8494":"code","fa7b5050":"code","63f76ee0":"code","df7f2002":"code","873ccd3e":"code","cfacb2f3":"code","ddf2fefa":"code","ba70b678":"code","2ee0096d":"code","f09286ba":"code","b0c7cfd6":"code","a28df39d":"code","3b0be61c":"code","b421e8a6":"code","3ae7bf9b":"code","6ba71af6":"code","5593f620":"code","a5748983":"code","0a040815":"markdown","10bba653":"markdown","c8c975b5":"markdown","abd24441":"markdown","0d3df19d":"markdown","bf614ce4":"markdown","35fbdd06":"markdown"},"source":{"d6bd4858":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bc5ee7a":"X_train = pd.DataFrame({'age':[20, 30, 10, np.nan, 10]})\nX_train","fb1df9e6":"from sklearn.impute import SimpleImputer","24be4eeb":"imputer = SimpleImputer(strategy=\"mean\")\nimputer.fit_transform(X_train)","c48166b2":"imputer = SimpleImputer(strategy=\"mean\", add_indicator=True)\nimputer.fit_transform(X_train)","afb7dfa5":"X_test = pd.DataFrame({'age':[np.nan, 1000]})\nX_test","a9068bda":"imputer.transform(X_test)","bebfb4b0":"X_train = pd.DataFrame({'shape':['square', 'square', 'oval', 'circle']})\nX_train","a4072686":"from sklearn.preprocessing import OneHotEncoder","a6b83441":"# left to right the columns are in alphabetical sequence (circle, oval, square)\nohe = OneHotEncoder(sparse=False)\nohe.fit_transform(X_train)","a022382c":"X_test = pd.DataFrame({'shape':['oval']})\nX_test","f25e1ce5":"ohe.transform(X_test)","6bc81b88":"X_test = pd.DataFrame({'shape':['triangle']})\nX_test","993bda8d":"# ohe.transform(X_test)","7cd4c8c7":"ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\nohe.fit_transform(X_train)","025ad28b":"X_test = pd.DataFrame({'shape':['triangle']})\nohe.transform(X_test)","0267b341":"titanic = pd.read_csv(\"\/kaggle\/input\/titanic-complete-hwr-berlin\/titanic_complete.csv\")\ntitanic.head()","4be69e88":"titanic.info()","ce7528d6":"titanic.isna().sum()","15f0554e":"y = titanic['survived']","bcedc95f":"features = ['pclass', 'sex', 'age', 'sibsp', 'parch']","7504893d":"X = titanic[features]","bdb0fc75":"X.head()","56d56924":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","d7028744":"ohe = OneHotEncoder(handle_unknown='ignore')\nimp = SimpleImputer()","898d52dc":"from sklearn.compose import ColumnTransformer","f137e071":"ct = ColumnTransformer(\n    [('ohe', ohe, ['sex']), \n    ('imputer', imp, ['age'])],              \n    remainder='passthrough'\n)","505e6f7b":"X_train","165236de":"ct.fit_transform(X_train)","1dc18066":"features_preprocessing = ['sex_female', 'sex_male', 'age', 'pclass', 'sibsp', 'parch']","ef182777":"from sklearn.tree import DecisionTreeClassifier","dd2957cc":"clf = DecisionTreeClassifier()","a5a48154":"from sklearn.pipeline import Pipeline","50663f63":"pipe = Pipeline([\n    ('preprocessor', ct),\n    ('classifier', clf)]\n)","986b22ac":"pipe","d43f7679":"from sklearn import set_config \nset_config(display='diagram')\npipe","2fa65f62":"pipe.fit(X_train, y_train)","950027c8":"y_pred = pipe.predict(X_test)","4cfa8494":"from sklearn.metrics import classification_report","fa7b5050":"print(classification_report(y_test, y_pred))","63f76ee0":"from sklearn.metrics import plot_confusion_matrix","df7f2002":"plot_confusion_matrix(pipe, X_test, y_test, display_labels=['dead', 'survived'], cmap='Blues', values_format='d');","873ccd3e":"from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(24,12))\nplot_tree(pipe['classifier'], max_depth=3, filled=True, class_names=['dead', 'survived'], feature_names=features_preprocessing)\nplt.show()","cfacb2f3":"params = {'classifier__max_depth':  range(1,10),\n        'preprocessor__imputer__strategy': ['mean', 'median'] \n}","ddf2fefa":"from sklearn.model_selection import GridSearchCV","ba70b678":"grid = GridSearchCV(pipe, params, cv=10, scoring='accuracy', verbose=1, return_train_score=True, n_jobs=-1)\ngrid.fit(X_train, y_train);","2ee0096d":"grid.best_params_","f09286ba":"plot_confusion_matrix(grid, X_test, y_test, display_labels=['dead', 'survived'], cmap='Blues', values_format='d');","b0c7cfd6":"y_pred = grid.predict(X_test)","a28df39d":"print(classification_report(y_test, y_pred))","3b0be61c":"df_cv_results = pd.DataFrame(grid.cv_results_)","b421e8a6":"df_cv_results.head()","3ae7bf9b":"import seaborn as sns","6ba71af6":"sns.lineplot(x='param_classifier__max_depth', y='mean_test_score', hue='param_preprocessor__imputer__strategy', data=df_cv_results);","5593f620":"sns.lineplot(x='param_classifier__max_depth', y='mean_train_score', hue='param_preprocessor__imputer__strategy', data=df_cv_results);","a5748983":"from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,8))\nplot_tree(pipe['classifier'], max_depth=2, filled=True, class_names=['dead', 'survived'], feature_names=features_preprocessing)\nplt.show()","0a040815":"## ","10bba653":"# One-Hot Encoding of categorial Attributes","c8c975b5":"# Titanic Transformer and Pipeline Example (Kata 1)","abd24441":"# Imputing Missing Values","0d3df19d":"# Pipeline","bf614ce4":"# Hyperparamater Tuning with Pipeline (Kata 2)","35fbdd06":"# ColumnTransformer"}}