{"cell_type":{"9091bf6a":"code","ff0d8715":"code","337f5986":"code","d9e6633f":"code","4e77702c":"code","52caab1e":"code","d37a5ac9":"code","961bb5c9":"code","ec16392e":"code","8fb61be4":"code","dbe3e37d":"code","1d61188e":"code","5aa5cc95":"code","59689789":"code","b094b915":"code","fa83f066":"code","7c8926e8":"code","5ea638bf":"code","eaf6d914":"code","142db796":"markdown","39faca24":"markdown","93d5bc65":"markdown","6de78649":"markdown","56ebbf54":"markdown","714b7352":"markdown","d05c423c":"markdown","9f9a6b46":"markdown","323dcc74":"markdown"},"source":{"9091bf6a":"import numpy as np \nimport pandas as pd\nimport os\nimport random\nimport glob\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa","ff0d8715":"EPOCHS=20\nBATCH_SIZE=32\nHEIGHT=256\nWIDTH=256\nCHANNELS=3\nN_CLASSES=13\nAUTO = tf.data.AUTOTUNE","337f5986":"def loadImage(path):\n    img = Image.open(path)\n    img = np.array(img)\n    \n    image = img[:,:256]\n    image = image \/ 255.0\n    mask = img[:,256:]\n    \n    return image, mask\n\ndef bin_image(mask):\n    bins = np.array([20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240])\n    new_mask = np.digitize(mask, bins)\n    return new_mask\n\ndef getSegmentationArr(image, classes, width=WIDTH, height=HEIGHT):\n    seg_labels = np.zeros((height, width, classes))\n    img = image[:, : , 0]\n\n    for c in range(classes):\n        seg_labels[:, :, c] = (img == c ).astype(int)\n    return seg_labels\n\ndef give_color_to_seg_img(seg, n_classes=N_CLASSES):\n    \n    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n    colors = sns.color_palette(\"hls\", n_classes)\n    \n    for c in range(n_classes):\n        segc = (seg == c)\n        seg_img[:,:,0] += (segc*( colors[c][0] ))\n        seg_img[:,:,1] += (segc*( colors[c][1] ))\n        seg_img[:,:,2] += (segc*( colors[c][2] ))\n\n    return(seg_img)","d9e6633f":"train_folder = \"..\/input\/cityscapes-image-pairs\/cityscapes_data\/train\"\nvalid_folder = \"..\/input\/cityscapes-image-pairs\/cityscapes_data\/val\"\ntrain_filenames = glob.glob(os.path.join(train_folder, \"*.jpg\"))\nvalid_filenames = glob.glob(os.path.join(valid_folder, \"*.jpg\"))\n\nnum_of_training_samples = len(train_filenames) \nnum_of_valid_samples = len(valid_filenames)\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, filenames,\n                 batch_size=BATCH_SIZE,\n                 shuffle=True):\n\n        self.filenames = filenames\n        self.batch_size = BATCH_SIZE\n        self.shuffle= shuffle\n        self.n = len(self.filenames)\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n\n    def __get_data(self, batches):\n        imgs=[]\n        segs=[]\n        for file in batches:\n            image, mask = loadImage(file)\n            mask_binned = bin_image(mask)\n            labels = getSegmentationArr(mask_binned, N_CLASSES)\n            labels = np.argmax(labels, axis=-1)\n\n            imgs.append(image)\n            segs.append(labels)\n\n        return np.array(imgs), np.array(segs)\n\n    def __getitem__(self, index):\n\n        batches = self.filenames[index * self.batch_size:(index + 1) * self.batch_size]\n\n        X, y = self.__get_data(batches)\n\n        return (X, y)\n\n    def __len__(self):\n\n        return self.n \/\/ self.batch_size","4e77702c":"train_gen = DataGenerator(train_filenames)\nval_gen = DataGenerator(valid_filenames)","52caab1e":"for imgs, segs in train_gen:\n    break\nimgs.shape, segs.shape","d37a5ac9":"image = imgs[0]\nmask = give_color_to_seg_img(segs[0])\nmasked_image = image * 0.5 + mask * 0.5\n\nfig, axs = plt.subplots(1, 3, figsize=(20,20))\naxs[0].imshow(image)\naxs[0].set_title('Original Image')\naxs[1].imshow(mask)\naxs[1].set_title('Segmentation Mask')\n#predimg = cv2.addWeighted(imgs[i]\/255, 0.6, _p, 0.4, 0)\naxs[2].imshow(masked_image)\naxs[2].set_title('Masked Image')\nplt.show()","961bb5c9":"smooth = 1\n\ndef dice_coef(y_true, y_pred):\n    And = tf.reduce_sum(y_true * y_pred)\n    return (2 * And + smooth) \/ (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = tf.reduce_sum(y_true * y_pred)\n    sum_ = tf.reduce_sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    return 1 - iou(y_true, y_pred)","ec16392e":"def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    p = MaxPooling2D((2, 2))(c)\n    return c, p\n\ndef up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    us = UpSampling2D((2, 2))(x)\n    concat = Concatenate()([us, skip])\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c\n\ndef bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n    return c","8fb61be4":"def UNet():\n    f = [16, 32, 64, 128, 256]\n    inputs = Input((HEIGHT,WIDTH,3))\n    \n    p0 = inputs\n    c1, p1 = down_block(p0, f[0]) #128 -> 64\n    c2, p2 = down_block(p1, f[1]) #64 -> 32\n    c3, p3 = down_block(p2, f[2]) #32 -> 16\n    c4, p4 = down_block(p3, f[3]) #16->8\n    \n    bn = bottleneck(p4, f[4])\n    \n    u1 = up_block(bn, c4, f[3]) #8 -> 16\n    u2 = up_block(u1, c3, f[2]) #16 -> 32\n    u3 = up_block(u2, c2, f[1]) #32 -> 64\n    u4 = up_block(u3, c1, f[0]) #64 -> 128\n    \n    outputs = Conv2D(13, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n    model = Model(inputs, outputs)\n    return model","dbe3e37d":"def unet():\n    main_input = Input(shape=(HEIGHT, WIDTH, CHANNELS), name = 'img_input')\n\n    ''' ~~~~~~~~~~~~~~~~~~~ ENCODING LAYERS ~~~~~~~~~~~~~~~~~~~ '''\n\n    c1 = Conv2D(32, kernel_size=(3,3), padding = 'same')(main_input)\n    c1 = LeakyReLU(0.2)(c1)\n    c1 = BatchNormalization()(c1)\n    c1 = Conv2D(32, kernel_size=(3,3), padding = 'same')(c1)\n    c1 = LeakyReLU(0.2)(c1)\n    c1 = BatchNormalization()(c1)\n\n    p1 = MaxPooling2D((2,2))(c1)\n\n    c2 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(p1)\n    c2 = LeakyReLU(0.2)(c2)\n    c2 = BatchNormalization()(c2)\n    c2 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(c2)\n    c2 = LeakyReLU(0.2)(c2)\n    c2 = BatchNormalization()(c2)\n\n    p2 = MaxPooling2D((2,2))(c2)\n\n    c3 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(p2)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(32*2, kernel_size=(1,1), padding = 'same')(c3)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n    c3 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(c3)\n    c3 = LeakyReLU(0.2)(c3)\n    c3 = BatchNormalization()(c3)\n\n    p3 = MaxPooling2D((2,2))(c3)\n\n    c4 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(p3)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(32*4, kernel_size=(1,1), padding = 'same')(c4)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n    c4 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(c4)\n    c4 = LeakyReLU(0.2)(c4)\n    c4 = BatchNormalization()(c4)\n\n    p4 = MaxPooling2D((2,2))(c4)\n\n    c5 = Conv2D(32*6, kernel_size=(3,3), padding = 'same')(p4)\n    c5 = LeakyReLU(0.2)(c5)\n    c5 = BatchNormalization()(c5)\n\n\n    ''' ~~~~~~~~~~~~~~~~~~~ DECODING LAYERS ~~~~~~~~~~~~~~~~~~~ '''\n\n    u1 = UpSampling2D((2,2))(c5)\n    concat1 = concatenate([c4, u1])\n\n    c6 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(concat1)\n    c6 = LeakyReLU(0.2)(c6)\n    c6 = BatchNormalization()(c6)\n    c6 = Conv2D(32*4, kernel_size=(3,3), padding = 'same')(c6)\n    c6 = LeakyReLU(0.2)(c6)\n    c6 = BatchNormalization()(c6)\n\n\n    u2 = UpSampling2D((2,2))(c6)\n    concat2 = concatenate([c3, u2])\n\n    c7 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(concat2)\n    c7 = LeakyReLU(0.2)(c7)\n    c7 = BatchNormalization()(c7)\n    c7 = Conv2D(32*2, kernel_size=(3,3), padding = 'same')(c7)\n    c7 = LeakyReLU(0.2)(c7)\n    c7 = BatchNormalization()(c7)\n\n    u3 = UpSampling2D((2,2))(c7)\n    concat3 = concatenate([c2, u3])\n\n    c8 = Conv2D(32, kernel_size=(3,3), padding = 'same')(concat3)\n    c8 = LeakyReLU(0.2)(c8)\n    c8 = BatchNormalization()(c8)\n    c8 = Conv2D(32, kernel_size=(3,3), padding = 'same')(c8)\n    c8 = LeakyReLU(0.2)(c8)\n    c8 = BatchNormalization()(c8)\n\n    u4 = UpSampling2D((2,2))(c8)\n    concat4 = concatenate([c1, u4])\n\n    c9 = Conv2D(16, kernel_size = (1,1), padding = 'same')(concat4)\n    c9 = LeakyReLU(0.2)(c9)\n    c9 = BatchNormalization()(c9)\n\n    mask_out = Conv2D(N_CLASSES, (1,1), padding = 'same', activation = 'sigmoid', name = 'mask_out')(c9)\n\n    model = Model(inputs = [main_input], outputs = [mask_out])\n    \n    return model","1d61188e":"model = unet()\nmodel.summary()","5aa5cc95":"checkpoint = ModelCheckpoint('seg_model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)","59689789":"TRAIN_STEPS = len(train_gen)\nVAL_STEPS = len(val_gen)\n\nmodel.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nhistory = model.fit(train_gen, validation_data=val_gen, steps_per_epoch=TRAIN_STEPS, \n          validation_steps=VAL_STEPS, epochs=EPOCHS, callbacks = [checkpoint])","b094b915":"learning_rate = 1e-4\ndecay_rate = (learning_rate - 1e-6) \/ 100\nopt = tf.keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n\ncheckpoint = ModelCheckpoint('seg_model_v2.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nhistory2 = model.fit(train_gen, validation_data=val_gen, steps_per_epoch=TRAIN_STEPS, \n          validation_steps=VAL_STEPS, epochs=10, callbacks = [checkpoint])","fa83f066":"loss = history.history[\"val_loss\"]\nacc = history.history[\"val_accuracy\"]\n\nplt.figure(figsize=(12, 10))\nplt.subplot(211)\nplt.title(\"Val. cce Loss\")\nplt.plot(loss)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\n\nplt.subplot(212)\nplt.title(\"Val. Accuracy\")\nplt.plot(acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\n\nplt.tight_layout()\nplt.show()","7c8926e8":"model.load_weights(\".\/seg_model_v2.h5\")","5ea638bf":"test_gen = DataGenerator(valid_filenames, 1)","eaf6d914":"test_iter = iter(test_gen)\nfor i in range(12):\n    imgs, segs = next(test_iter)\n    pred = model.predict(imgs)\n    _p = give_color_to_seg_img(np.argmax(pred[0], axis=-1))\n    _s = give_color_to_seg_img(segs[0])\n\n    predimg = cv2.addWeighted(imgs[0], 0.5, _p, 0.5, 0)\n    trueimg = cv2.addWeighted(imgs[0], 0.5, _s, 0.5, 0)\n    \n    plt.figure(figsize=(12, 4))\n    plt.subplot(131)\n    plt.title(\"Original\")\n    plt.imshow(imgs[0])\n    plt.axis(\"off\")\n    \n    plt.subplot(132)\n    plt.title(\"Prediction\")\n    plt.imshow(predimg)\n    plt.axis(\"off\")\n    \n    plt.subplot(133)\n    plt.title(\"Ground truth\")\n    plt.imshow(trueimg)\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.savefig(\"pred_\"+str(i)+\".png\", dpi=150)\n    plt.show()","142db796":"# Model","39faca24":"# Loss function","93d5bc65":"## 10 epochs with lr 1e-4","6de78649":"## 20 epochs with Categorical Crossentropy loss","56ebbf54":"# Callbacks","714b7352":"# Train History","d05c423c":"# Utility functions","9f9a6b46":"# Visualize outputs","323dcc74":"# Training"}}