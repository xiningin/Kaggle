{"cell_type":{"fca9a9f2":"code","85f7fcb7":"code","91677372":"code","df87b9d2":"code","88d5eed1":"code","84388371":"code","537e82ce":"code","b20d2a15":"code","e33ab737":"code","af175f1d":"code","fa2e85bb":"code","35aaa6ca":"code","b78e2fea":"code","34f1a19e":"code","ca4be8d7":"code","52a5c341":"code","8e2e083d":"code","3d4a5df2":"code","2a37f4fe":"code","7b29d137":"code","229121e8":"code","d5b6d13e":"code","ae198533":"code","bb6b7531":"code","c448580d":"code","7b10ad2e":"code","adf25895":"code","2465b16e":"code","ca2b059d":"code","9bdf9f70":"code","9eae5390":"code","944fd38d":"code","b778e834":"code","07e46250":"code","1614f2f8":"code","e2e2c49e":"code","c2403546":"code","6c6660ab":"code","9b28533c":"code","25524cd5":"code","f71ec3c3":"markdown","3f0da102":"markdown","ef33ef65":"markdown","396b6eb9":"markdown","2db92fcc":"markdown","4030d80e":"markdown","87fd78de":"markdown","5149d811":"markdown","befeee6e":"markdown","6a60d6d2":"markdown","62a2d843":"markdown","d96f40cb":"markdown","f373f932":"markdown","af5d6aba":"markdown","6b40f3c5":"markdown","08b581a8":"markdown","10db07d9":"markdown","e79019d0":"markdown","46d25a80":"markdown","0602a12f":"markdown","cf70b992":"markdown","a6277ef1":"markdown"},"source":{"fca9a9f2":"!nvidia-smi","85f7fcb7":"!pip uninstall -y lightgbm\n!apt-get install -y libboost-all-dev\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","91677372":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","df87b9d2":"!cd LightGBM\/python-package\/;python setup.py install --precompile","88d5eed1":"!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","84388371":"# Asthetics\nimport warnings\nimport sklearn.exceptions\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=SettingWithCopyWarning)\nwarnings.filterwarnings('ignore', category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nfrom tqdm.auto import tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport random\nimport gc\nimport itertools\ngc.enable()\n\n# Visialisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\n# Machine Learning\n## Utils\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn import preprocessing\n## Classification Models\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\n\n# Metrics\nfrom sklearn.metrics import roc_auc_score\n\n# Deep Learning\nimport torch\n\n# Fixing Seed\nRANDOM_SEED = 42\n\ndef seed_everything(seed=RANDOM_SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()\n\n# Device Optimization\nif torch.cuda.is_available():\n    GPU = True\nelse:\n    GPU = False\n    \nprint(f'GPU Available: {GPU}')","537e82ce":"data_dir = '..\/input\/song-popularity-prediction'\n\ntrain_file_path = '..\/input\/song-popularity-folds\/train_10_folds.csv'\ntest_file_path = os.path.join(data_dir, 'test.csv')\nsample_sub_file_path = os.path.join(data_dir, 'sample_submission.csv')\n\nprint(f'Train file: {train_file_path}')\nprint(f'Test file: {test_file_path}')\nprint(f'Sample Sub file: {sample_sub_file_path}')","b20d2a15":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\nsub_df = pd.read_csv(sample_sub_file_path)","e33ab737":"train_df = train_df.astype({'key': 'category', 'audio_mode': 'category'})\ntest_df = test_df.astype({'key': 'category', 'audio_mode': 'category'})","af175f1d":"train_df.isna().sum()","fa2e85bb":"test_df.isna().sum()","35aaa6ca":"imputer = IterativeImputer(random_state=RANDOM_SEED, max_iter=50, initial_strategy='mean')\n\ntrain_im = pd.DataFrame(imputer.fit_transform(train_df))\ntest_im = pd.DataFrame(imputer.fit_transform(test_df))\n\ntrain_im.columns = train_df.columns\ntest_im.columns = test_df.columns\n\ntrain_df = train_im\ntest_df = test_im\n\ndel train_im, test_im\ngc.collect();","b78e2fea":"train_df.isna().sum()","34f1a19e":"test_df.isna().sum()","ca4be8d7":"target = ['song_popularity']\nnot_features = ['id', 'song_popularity', 'kfold']\ncols = list(train_df.columns)\nfeatures = [feat for feat in cols if feat not in not_features]\nprint(features)","52a5c341":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    valid_ids = valid.id.values.tolist()\n    \n    if GPU:\n        xgb_params = {\n              'learning_rate': 0.019767112972718843,\n              'n_estimators': 10549,\n              'reg_lambda': 11.284062917044315,\n              'reg_alpha': 9.014886258556326e-05,\n              'max_depth': 6,\n              'subsample': 0.808198319392701,\n              'colsample_bytree': 0.3666230760242505,\n              'booster': 'gbtree',\n              'random_state':RANDOM_SEED,\n              'verbosity': 0,\n              'tree_method':'gpu_hist',\n              'gpu_id': 0,\n              'predictor': 'gpu_predictor'\n              }\n    else:\n        xgb_params = {\n              'learning_rate': 0.019767112972718843,\n              'n_estimators': 10549,\n              'reg_lambda': 11.284062917044315,\n              'reg_alpha': 9.014886258556326e-05,\n              'max_depth': 6,\n              'subsample': 0.808198319392701,\n              'colsample_bytree': 0.3666230760242505,\n              'booster': 'gbtree',\n              'random_state': RANDOM_SEED,\n              'verbosity': 0,\n              'n_jobs': 4\n        }\n        \n    clf = XGBClassifier(**xgb_params)  \n    clf.fit(train[features].values, train[target].values,\n            eval_set = [(valid[features].values, valid[target].values)],\n            eval_metric = 'auc',\n            early_stopping_rounds = 300,\n            verbose=False)\n    \n    valid_pred = clf.predict_proba(valid[features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict_proba(test[features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_1']\nvalid_pred_all.to_csv('train_pred_1.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_1'] = test_pred_all\nsub_2.to_csv('test_pred_1.csv', index=False)","8e2e083d":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    valid_ids = valid.id.values.tolist()\n\n    lgb_train = lgb.Dataset(train[features], train[target])\n    lgb_valid = lgb.Dataset(valid[features], valid[target], reference=lgb_train)\n    \n    if GPU:\n        lgbm_params = {\n              'learning_rate': 0.0027109050113455304,\n              'n_estimators': 1348,\n              'reg_lambda': 0.5106388532860763,\n              'reg_alpha': 0.27004521552837574,\n              'max_depth': 130,\n              'num_leaves': 44,\n              'feature_fraction': 0.4263819349686964,\n              'bagging_fraction': 0.49593550461680574,\n              'pos_bagging_fraction': 0.5371623198828565,\n              'neg_bagging_fraction': 0.30616770109746205,\n              'bagging_freq': 6,\n              'min_child_samples': 89,\n              'objective': 'binary',\n              'metric': 'auc',\n              'verbosity': -1,\n              'device': 'gpu',\n              'gpu_platform_id': 0,\n              'gpu_device_id': 0,\n              'random_state':RANDOM_SEED\n              }\n    else:\n        lgbm_params = {\n              'learning_rate': 0.0027109050113455304,\n              'n_estimators': 1348,\n              'reg_lambda': 0.5106388532860763,\n              'reg_alpha': 0.27004521552837574,\n              'max_depth': 130,\n              'num_leaves': 44,\n              'feature_fraction': 0.4263819349686964,\n              'bagging_fraction': 0.49593550461680574,\n              'pos_bagging_fraction': 0.5371623198828565,\n              'neg_bagging_fraction': 0.30616770109746205,\n              'bagging_freq': 6,\n              'min_child_samples': 89,\n              'objective': 'binary',\n              'metric': 'auc',\n              'verbosity': -1,\n              'n_jobs': 4,\n              'random_state':RANDOM_SEED\n              }\n        \n    clf = lgb.train(lgbm_params, lgb_train, valid_sets=[lgb_valid])\n    \n    valid_pred = clf.predict(valid[features].values, num_iteration=clf.best_iteration)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict(test[features].values, num_iteration=clf.best_iteration)\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_2']\nvalid_pred_all.to_csv('train_pred_2.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_2'] = test_pred_all\nsub_2.to_csv('test_pred_2.csv', index=False)","3d4a5df2":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    valid_ids = valid.id.values.tolist()\n    \n    if GPU:\n        cat_params = {\n            'depth' : 4,\n            'grow_policy' : 'Depthwise',\n            'l2_leaf_reg' : 97.2237331816313,\n            'random_strength' : 0.5686428156275426,\n            'learning_rate' : 0.012567270456139758,\n            'iterations' : 9310,\n            'loss_function' : 'Logloss',\n            'bagging_temperature': 0.6051472546289562,\n            'border_count': 202,\n            'eval_metric' : 'AUC',\n            'use_best_model' : True,\n            'early_stopping_rounds' : 300,\n            'task_type' : 'GPU',\n            'verbose' : False\n        }\n    else:\n        cat_params = {\n            'depth' : 4,\n            'grow_policy' : 'Depthwise',\n            'l2_leaf_reg' : 97.2237331816313,\n            'random_strength' : 0.5686428156275426,\n            'learning_rate' : 0.012567270456139758,\n            'iterations' : 1000,\n            'loss_function' : 'Logloss',\n            'bagging_temperature': 0.6051472546289562,\n            'border_count': 202,\n            'eval_metric' : 'AUC',\n            'use_best_model' : True,\n            'early_stopping_rounds' : 100,\n            'task_type' : 'CPU',\n            'thread_count' : 4,\n            'verbose' : False\n        }\n        \n    clf = CatBoostClassifier(**cat_params)  \n    clf.fit(train[features].values, train[target].values,\n            eval_set = [(valid[features].values, valid[target].values)])\n    \n    valid_pred = clf.predict_proba(valid[features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict_proba(test[features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_3']\nvalid_pred_all.to_csv('train_pred_3.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_3'] = test_pred_all\nsub_2.to_csv('test_pred_3.csv', index=False)","2a37f4fe":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    scaler = preprocessing.StandardScaler()\n    train[features] = scaler.fit_transform(train[features])\n    valid[features] = scaler.transform(valid[features])\n    test[features] = scaler.transform(test[features])\n    \n    valid_ids = valid.id.values.tolist()\n    \n    lgb_train = lgb.Dataset(train[features], train[target])\n    lgb_valid = lgb.Dataset(valid[features], valid[target], reference=lgb_train)\n    \n    if GPU:\n        lgbm_params = {\n            'n_estimators': 20000,\n            'learning_rate': 5e-3,\n            'subsample': 0.6,\n            'subsample_freq': 1,\n            'colsample_bytree': 0.4,\n            'reg_alpha': 10.0,\n            'reg_lambda': 1e-1,\n            'min_child_weight': 256,\n            'min_child_samples': 20,\n            'early_stopping_round': 200,\n            'objective': 'binary',\n            'metric': 'auc',\n            'verbosity': -1,\n            'device': 'gpu',\n            'gpu_platform_id': 0,\n            'gpu_device_id': 0,\n            'random_state': RANDOM_SEED\n        }\n    else:\n        lgbm_params = {\n            'n_estimators': 20000,\n            'learning_rate': 5e-3,\n            'subsample': 0.6,\n            'subsample_freq': 1,\n            'colsample_bytree': 0.4,\n            'reg_alpha': 10.0,\n            'reg_lambda': 1e-1,\n            'min_child_weight': 256,\n            'min_child_samples': 20,\n            'early_stopping_round': 200,\n            'objective': 'binary',\n            'metric': 'auc',\n            'verbosity': -1,\n            'n_jobs': 4,\n            'random_state': RANDOM_SEED\n        }\n    \n    clf = lgb.train(lgbm_params, lgb_train, valid_sets=[lgb_valid])\n    \n    valid_pred = clf.predict(valid[features].values, num_iteration=clf.best_iteration)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict(test[features].values, num_iteration=clf.best_iteration)\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_4']\nvalid_pred_all.to_csv('train_pred_4.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_4'] = test_pred_all\nsub_2.to_csv('test_pred_4.csv', index=False)","7b29d137":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    scaler = preprocessing.RobustScaler()\n    train[features] = scaler.fit_transform(train[features])\n    valid[features] = scaler.transform(valid[features])\n    test[features] = scaler.transform(test[features])\n    \n    valid_ids = valid.id.values.tolist()\n    \n    lgb_train = lgb.Dataset(train[features], train[target])\n    lgb_valid = lgb.Dataset(valid[features], valid[target], reference=lgb_train)\n    \n    if GPU:\n        lgbm_params = {\n              'task': 'train',\n              'boosting_type': 'gbdt',\n              'objective': 'binary',\n              'learning_rate': 0.001635,\n              'max_depth': 3,\n              'feature_fraction': 0.2256038826485174,\n              'bagging_fraction': 0.7705303688019942,\n              'min_child_samples': 290,\n              'reg_alpha': 14.68267919457715,\n              'reg_lambda': 66.156,\n              'max_bin': 772,\n              'min_data_per_group': 177,\n              'bagging_freq': 1,\n              'cat_smooth': 96,\n              'cat_l2': 17,\n              'verbosity': -1,\n              'random_state': RANDOM_SEED,\n              'n_estimators': 5000,\n        }\n    else:\n        lgbm_params = {\n              'task': 'train',\n              'boosting_type': 'gbdt',\n              'objective': 'binary',\n              'learning_rate': 0.001635,\n              'max_depth': 3,\n              'feature_fraction': 0.2256038826485174,\n              'bagging_fraction': 0.7705303688019942,\n              'min_child_samples': 290,\n              'reg_alpha': 14.68267919457715,\n              'reg_lambda': 66.156,\n              'max_bin': 772,\n              'min_data_per_group': 177,\n              'bagging_freq': 1,\n              'cat_smooth': 96,\n              'cat_l2': 17,\n              'verbosity': -1,\n              'random_state': RANDOM_SEED,\n              'n_estimators': 5000,\n        }\n    \n    clf = lgb.train(lgbm_params, lgb_train, valid_sets=[lgb_valid])\n    \n    valid_pred = clf.predict(valid[features].values, num_iteration=clf.best_iteration)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict(test[features].values, num_iteration=clf.best_iteration)\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_5']\nvalid_pred_all.to_csv('train_pred_5.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_5'] = test_pred_all\nsub_2.to_csv('test_pred_5.csv', index=False)","229121e8":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    valid_ids = valid.id.values.tolist()\n        \n    clf = LinearRegression()\n    clf.fit(train[features].values, train[target].values)\n    \n    valid_pred = clf.predict(valid[features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict(test[features].values)\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_6']\nvalid_pred_all.to_csv('train_pred_6.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_6'] = test_pred_all\nsub_2.to_csv('test_pred_6.csv', index=False)","d5b6d13e":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i].copy()\n    valid = train_df[train_df['kfold'] == i].copy()\n    test = test_df.copy()\n    \n    valid_ids = valid.id.values.tolist()\n        \n    clf = GaussianNB()\n    clf.fit(train[features].values, train[target].values)\n    \n    valid_pred = clf.predict_proba(valid[features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = clf.predict_proba(test[features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC-AUC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC-AUC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_7']\nvalid_pred_all.to_csv('train_pred_7.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_7'] = test_pred_all\nsub_2.to_csv('test_pred_7.csv', index=False)","ae198533":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\nsub_df = pd.read_csv(sample_sub_file_path)","bb6b7531":"prev_features = list(train_df.columns)","c448580d":"df1 = pd.read_csv('train_pred_1.csv')\ndf2 = pd.read_csv('train_pred_2.csv')\ndf3 = pd.read_csv('train_pred_3.csv')\ndf4 = pd.read_csv('train_pred_4.csv')\ndf5 = pd.read_csv('train_pred_5.csv')\ndf6 = pd.read_csv('train_pred_6.csv')\ndf7 = pd.read_csv('train_pred_7.csv')\n\ndf_test1 = pd.read_csv('test_pred_1.csv')\ndf_test2 = pd.read_csv('test_pred_2.csv')\ndf_test3 = pd.read_csv('test_pred_3.csv')\ndf_test4 = pd.read_csv('test_pred_4.csv')\ndf_test5 = pd.read_csv('test_pred_5.csv')\ndf_test6 = pd.read_csv('test_pred_6.csv')\ndf_test7 = pd.read_csv('test_pred_7.csv')","7b10ad2e":"train_df = train_df.merge(df1, on='id', how='left')\ntrain_df = train_df.merge(df2, on='id', how='left')\ntrain_df = train_df.merge(df3, on='id', how='left')\ntrain_df = train_df.merge(df4, on='id', how='left')\ntrain_df = train_df.merge(df5, on='id', how='left')\ntrain_df = train_df.merge(df6, on='id', how='left')\ntrain_df = train_df.merge(df7, on='id', how='left')\n\ntest_df = test_df.merge(df_test1, on='id', how='left')\ntest_df = test_df.merge(df_test2, on='id', how='left')\ntest_df = test_df.merge(df_test3, on='id', how='left')\ntest_df = test_df.merge(df_test4, on='id', how='left')\ntest_df = test_df.merge(df_test5, on='id', how='left')\ntest_df = test_df.merge(df_test6, on='id', how='left')\ntest_df = test_df.merge(df_test7, on='id', how='left')","adf25895":"cols = list(train_df.columns)\nblend_features = [feat for feat in cols if str(feat).startswith('pred')]\nprint(blend_features)","2465b16e":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = LogisticRegression(solver='liblinear')\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict_proba(valid[blend_features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict_proba(test[blend_features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_1']\nvalid_pred_all.to_csv('L1_train_pred_1.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_1'] = test_pred_all\nsub_2.to_csv('L1_test_pred_1.csv', index=False)","ca2b059d":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = GaussianNB()\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict_proba(valid[blend_features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict_proba(test[blend_features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_2']\nvalid_pred_all.to_csv('L1_train_pred_2.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_2'] = test_pred_all\nsub_2.to_csv('L1_test_pred_2.csv', index=False)","9bdf9f70":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = LinearRegression()\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict(valid[blend_features].values)\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict(test[blend_features].values)\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_3']\nvalid_pred_all.to_csv('L1_train_pred_3.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_3'] = test_pred_all\nsub_2.to_csv('L1_test_pred_3.csv', index=False)","9eae5390":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n\n    model = QuadraticDiscriminantAnalysis()\n    model.fit(train[blend_features].values, train[target].values)\n\n    valid_pred = model.predict_proba(valid[blend_features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict_proba(test[blend_features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_4']\nvalid_pred_all.to_csv('L1_train_pred_4.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_4'] = test_pred_all\nsub_2.to_csv('L1_test_pred_4.csv', index=False)","944fd38d":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n    \n    if GPU:\n        xgb_params = {\n            'n_estimators': 10000,\n            'booster': 'gbtree',\n            'random_state': RANDOM_SEED,\n            'verbosity': 0,\n            'tree_method':'gpu_hist',\n            'gpu_id': 0,\n            'predictor': 'gpu_predictor'\n        }\n    else:\n        xgb_params = {\n            'n_estimators': 1000,\n            'booster': 'gbtree',\n            'random_state': RANDOM_SEED,\n            'verbosity': 0,\n            'n_jobs': 4\n        }\n        \n    model = XGBClassifier(**xgb_params)  \n    model.fit(train[blend_features].values, train[target].values,\n            eval_set = [(valid[blend_features].values, valid[target].values)],\n            eval_metric = 'auc',\n            early_stopping_rounds = 300,\n            verbose=False)\n\n    valid_pred = model.predict_proba(valid[blend_features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict_proba(test[blend_features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_5']\nvalid_pred_all.to_csv('L1_train_pred_5.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_5'] = test_pred_all\nsub_2.to_csv('L1_test_pred_5.csv', index=False)","b778e834":"test_pred_all = None\nvalid_pred_all = {}\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    valid_ids = valid.id.values.tolist()\n        \n    if GPU:\n        cat_params = {\n            'depth' : 3,\n            'grow_policy' : 'SymmetricTree',\n            'learning_rate' : 0.1,\n            'iterations' : 10000,\n            'loss_function' : 'CrossEntropy',\n            'eval_metric' : 'AUC',\n            'use_best_model' : True,\n            'early_stopping_rounds' : 300,\n            'task_type' : 'GPU',\n            'verbose' : False\n        }\n    else:\n        cat_params = {\n            'depth' : 3,\n            'grow_policy' : 'SymmetricTree',\n            'learning_rate' : 0.1,\n            'iterations' : 1000,\n            'loss_function' : 'CrossEntropy',\n            'eval_metric' : 'AUC',\n            'use_best_model' : True,\n            'early_stopping_rounds' : 100,\n            'task_type' : 'CPU',\n            'thread_count' : 4,\n            'verbose' : False\n        }\n        \n    model = CatBoostClassifier(**cat_params)  \n    model.fit(train[blend_features].values, train[target].values,\n            eval_set = [(valid[blend_features].values, valid[target].values)])\n\n    valid_pred = model.predict_proba(valid[blend_features].values)[:, 1]\n    valid_pred_all.update(dict(zip(valid_ids, valid_pred)))\n    test_pred = model.predict_proba(test[blend_features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nvalid_pred_all = pd.DataFrame.from_dict(valid_pred_all, orient='index').reset_index()\nvalid_pred_all.columns = ['id', 'pred_L1_6']\nvalid_pred_all.to_csv('L1_train_pred_6.csv', index=False)\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['pred_L1_6'] = test_pred_all\nsub_2.to_csv('L1_test_pred_6.csv', index=False)","07e46250":"train_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\nsub_df = pd.read_csv(sample_sub_file_path)","1614f2f8":"prev_features = list(train_df.columns)","e2e2c49e":"df1 = pd.read_csv('L1_train_pred_1.csv')\ndf2 = pd.read_csv('L1_train_pred_2.csv')\ndf3 = pd.read_csv('L1_train_pred_3.csv')\ndf4 = pd.read_csv('L1_train_pred_4.csv')\ndf5 = pd.read_csv('L1_train_pred_5.csv')\ndf6 = pd.read_csv('L1_train_pred_6.csv')\n\ndf_test1 = pd.read_csv('L1_test_pred_1.csv')\ndf_test2 = pd.read_csv('L1_test_pred_2.csv')\ndf_test3 = pd.read_csv('L1_test_pred_3.csv')\ndf_test4 = pd.read_csv('L1_test_pred_4.csv')\ndf_test5 = pd.read_csv('L1_test_pred_5.csv')\ndf_test6 = pd.read_csv('L1_test_pred_6.csv')","c2403546":"train_df = train_df.merge(df1, on='id', how='left')\ntrain_df = train_df.merge(df2, on='id', how='left')\ntrain_df = train_df.merge(df3, on='id', how='left')\ntrain_df = train_df.merge(df4, on='id', how='left')\ntrain_df = train_df.merge(df5, on='id', how='left')\ntrain_df = train_df.merge(df6, on='id', how='left')\n\ntest_df = test_df.merge(df_test1, on='id', how='left')\ntest_df = test_df.merge(df_test2, on='id', how='left')\ntest_df = test_df.merge(df_test3, on='id', how='left')\ntest_df = test_df.merge(df_test4, on='id', how='left')\ntest_df = test_df.merge(df_test5, on='id', how='left')\ntest_df = test_df.merge(df_test6, on='id', how='left')","6c6660ab":"cols = list(train_df.columns)\nstack_features = [feat for feat in cols if str(feat).startswith('pred')]\nprint(stack_features)","9b28533c":"test_pred_all = None\nall_roc = []\n\nfor i in tqdm(range(train_df['kfold'].nunique())):\n    train = train_df[train_df['kfold'] != i]\n    valid = train_df[train_df['kfold'] == i]\n    test = test_df.copy()\n\n    model = LogisticRegression(solver='liblinear')\n    model.fit(train[stack_features].values, train[target].values)\n\n    valid_pred = model.predict_proba(valid[stack_features].values)[:, 1]\n    test_pred = model.predict_proba(test[stack_features].values)[:, 1]\n    roc = roc_auc_score(valid[target].values, valid_pred)\n    all_roc.append(roc)\n\n    if test_pred_all is None:\n        test_pred_all = test_pred\n    else:\n        test_pred_all += test_pred\n    \n    print(f'Fold {i+1} ROC: {round(roc, 4)}')\n    \nprint('')\nprint(f'Average ROC: {round(np.mean(all_roc), 4)} Std: {round(np.std(all_roc), 4)}')\ntest_pred_all \/= train_df['kfold'].nunique()\n\nsub_2 = pd.DataFrame()\nsub_2['id'] = test_df['id']\nsub_2['song_popularity'] = test_pred_all\nsub_2.to_csv('Stacked_Submission_1.csv', index=False)","25524cd5":"sub_2.head()","f71ec3c3":"## 3. Linear Regression","3f0da102":"## 6. Linear Regression - 1","ef33ef65":"## 7. Naive Bayes - 1","396b6eb9":"## 5. XGBoost","2db92fcc":"## 1. Logistic Regression","4030d80e":"## 4. QDA","87fd78de":"## 6. Cat Boost","5149d811":"## 1. XGBoost - 1","befeee6e":"## 3. Catboost - 1","6a60d6d2":"## 5. LGBM - 3\n\nFrom https:\/\/www.kaggle.com\/venkatkumar001\/spp2-lgbm","62a2d843":"# Installing Libraries","d96f40cb":"# Stacking (L2 Model)","f373f932":"# Handling NULL Values","af5d6aba":"# Read Data","6b40f3c5":"## 4. LGBM - 2","08b581a8":"# Imports","10db07d9":"# Blending (L1 Models)","e79019d0":"## 2. Naive Bayes","46d25a80":"# Get GPU Info","0602a12f":"## 2. LGBM - 1","cf70b992":"# L0 Models","a6277ef1":"# Feature List"}}