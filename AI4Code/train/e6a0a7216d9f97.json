{"cell_type":{"9e7fc5ee":"code","8c14a2fc":"code","907f991b":"code","5d25528c":"code","d221c10f":"code","937d2111":"code","5714b1c7":"code","03f45808":"code","441e1b79":"code","695ed711":"code","0fd9ab78":"code","b418bd8d":"markdown","38545781":"markdown","f67c09bd":"markdown","38f031d8":"markdown"},"source":{"9e7fc5ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re # Import Regular Expression Library\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8c14a2fc":"data=pd.read_csv(\"..\/input\/Restaurant_Reviews.csv\")","907f991b":"#Exchange the characters not between in \"a-z\" and \"A-Z\" with space character\ncomment=re.sub('[^a-zA-Z]',' ',data['Review'][0])\n#Now data is not DataFrame anymore. It's string!","5d25528c":"comment=comment.lower() #transfom all the characters into lower case","d221c10f":"comment=comment.split() #transform the sentence into word list","937d2111":"#remove the stopwords\nfrom nltk.corpus import stopwords\nstopwords_en = stopwords.words('english')\nprint(stopwords_en)","5714b1c7":"#Stemming and Lemmatization\nfrom nltk.stem.porter import PorterStemmer\nps= PorterStemmer() \ncomment=[ps.stem(kelime) for kelime in comment if not kelime in set(stopwords.words('english'))]\n#If the word is not stopwords, throw it into the list\n#Since we write in square brackets, the values returned from the function will be defined as a list\ncomment= ' '.join(comment) #Merge all words in comment with a space between them and put them in comment. Comment is string now","03f45808":"#repeat all the steps for all the reviews in Dataset\ncomments=[]\nfor i in range(1000):\n    comment=re.sub('[^a-zA-Z]',' ',data['Review'][i])\n    comment=comment.lower() #transfom all the characters into lower case\n    comment=comment.split()\n    comment=[ps.stem(kelime) for kelime in comment if not kelime in set(stopwords.words('english'))]\n    comment= ' '.join(comment) #Merge all words in comment with a space between them and put them in comment. Comment is string now\n    comments.append(comment)\ncomments","441e1b79":"from sklearn.feature_extraction.text import CountVectorizer\ncv= CountVectorizer(max_features=1000) #Take 2000 words most common used\nX = cv.fit_transform(comments).toarray()#independent variable\ny = data.iloc[:,1].values  #dependent variable","695ed711":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20)\ngnb= GaussianNB()\ngnb.fit(X_train,y_train)\ny_pred=gnb.predict(X_test)","0fd9ab78":"from sklearn.metrics import confusion_matrix\ncm= confusion_matrix(y_test,y_pred)\nprint(cm)","b418bd8d":"# Machine Learning","38545781":"That's ALL","f67c09bd":"# Feature Extraction","38f031d8":"# Preprocessing"}}