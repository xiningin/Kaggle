{"cell_type":{"9ba91851":"code","3104f7ae":"code","d25460cd":"code","184726d5":"code","0df51aa7":"code","d5e089f9":"code","bcc50f15":"code","8415fa65":"code","3515d3b9":"code","ad36c38f":"code","d59bb892":"code","b4b40ac5":"code","37c3604a":"markdown","67e292b3":"markdown","4c6d3713":"markdown","6d742b00":"markdown"},"source":{"9ba91851":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense,Flatten,Conv2D,Conv2DTranspose,BatchNormalization,Reshape\nfrom tensorflow.keras import Sequential\n\nfrom IPython import display","3104f7ae":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","d25460cd":"def plot_results(images, n_cols=None):\n    '''visualizes fake images'''\n    display.clear_output(wait=False)  \n\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n\n    plt.figure(figsize=(n_cols, n_rows))\n    \n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","184726d5":"(X_train, _), _ = tf.keras.datasets.fashion_mnist.load_data()\n# normalize pixel values\nX_train = X_train.astype(np.float32) \/ 255\nX_train = X_train.reshape(-1, 28, 28, 1) * 2. - 1.   # values between -1 and +1","0df51aa7":"BATCH_SIZE = 128\ndataset=tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000).batch(BATCH_SIZE,drop_remainder=True).prefetch(1)","d5e089f9":"codings_size = 32\ngenerator=Sequential(\n[\n    Dense(7*7*128,input_shape=[codings_size]),\n    Reshape([7,7,128]),\n    BatchNormalization(),\n    Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",activation=\"selu\"),\n    BatchNormalization(),\n    Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",activation=\"tanh\"),   \n\n])\ngenerator.summary()","bcc50f15":"discriminator=Sequential([\n    Conv2D(64,kernel_size=5, strides=2, padding=\"SAME\",activation=tf.keras.layers.LeakyReLU(0.2),input_shape=[28, 28, 1]),\n    tf.keras.layers.Dropout(0.4),\n    Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.Dropout(0.4),\n    Flatten(),\n    Dense(1, activation=\"sigmoid\")    \n])\ndiscriminator.summary()","8415fa65":"gan = Sequential([generator, discriminator])","3515d3b9":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","ad36c38f":"def train_gan(gan,train_dataset,random_normal_dimensions,n_epochs=50):\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        print(\"Epoch {}\/{}\".format(epoch + 1, n_epochs))\n        for img in dataset:\n            batch_size=img.shape[0]\n            #Phase 1\n            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n            fake_img = generator(noise)\n            mixed_images = tf.concat([fake_img,img], axis=0)\n            discriminator_labels = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(mixed_images, discriminator_labels)\n            #Phase 2\n            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n            generator_labels = tf.constant([[1.]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, generator_labels)\n        plot_results(fake_img, 16)                     \n        plt.show()","d59bb892":"train_gan(gan, dataset, codings_size, 100)","b4b40ac5":"generator.save('mnist model generator.h5')","37c3604a":"**Model**","67e292b3":"**Helping fxn**","4c6d3713":"**Download and Preprocessing**","6d742b00":"**Imports**"}}