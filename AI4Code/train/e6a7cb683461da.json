{"cell_type":{"86547977":"code","7d99120b":"code","2d4d8a68":"code","88d8c9e6":"code","bf624ede":"code","287f426a":"code","70e2554d":"code","3ab302bb":"code","4af3c946":"code","8a020432":"code","36df36a0":"code","6fc18995":"code","afe2fb9e":"code","6fc6310f":"code","5f69f8d4":"code","7dddbb1d":"code","927b00d5":"code","38483199":"code","b6c97663":"code","02445307":"code","683e1b75":"code","c3dabcf7":"code","79a34fb7":"code","15d9785e":"code","648ef056":"code","86e7f633":"code","c8567c97":"code","7fe6e54f":"code","3890044c":"code","7deb45e5":"code","2fd466a5":"code","b7c47121":"code","2b035f25":"code","372aba7e":"code","c6318c92":"code","c8831156":"code","305dc98d":"markdown","053b8d7d":"markdown","17ff68f4":"markdown","3eb0f81d":"markdown","dcf2e6b7":"markdown"},"source":{"86547977":"import pandas as pd","7d99120b":"buildingname = \"Office_Abbey\"","2d4d8a68":"rawdata = pd.read_csv(\"..\/input\/\"+buildingname+\".csv\", parse_dates=True, index_col='timestamp')","88d8c9e6":"rawdata.info()","bf624ede":"rawdata.head()","287f426a":"rawdata.plot(figsize=(20,8))","70e2554d":"meta = pd.read_csv(\"..\/input\/all_buildings_meta_data.csv\",index_col='uid')","3ab302bb":"meta.head()","4af3c946":"meta.loc[buildingname]","8a020432":"meta.loc[buildingname][\"sqm\"]","36df36a0":"rawdata.head()","6fc18995":"rawdata_normalized = rawdata\/meta.loc[buildingname][\"sqm\"]","afe2fb9e":"rawdata_normalized.head()","6fc6310f":"rawdata_normalized_monthly = rawdata_normalized.resample(\"M\").sum()","5f69f8d4":"rawdata_normalized_monthly","7dddbb1d":"rawdata_normalized_monthly.plot(kind=\"bar\", figsize=(10,4))","927b00d5":"rawdata_normalized_monthly.sum().plot(kind=\"bar\", figsize=(5,4))","38483199":"rawdata_normalized_monthly.index = rawdata_normalized_monthly.index.strftime('%b')","b6c97663":"rawdata_normalized_monthly.plot(kind=\"bar\", figsize=(10,4))","02445307":"buildingnamelist = [\"Office_Abbey\",\n\"Office_Pam\",\n\"Office_Penny\",\n\"UnivLab_Allison\",\n\"UnivLab_Audra\",\n\"UnivLab_Ciel\"]","683e1b75":"annual_data_list = []\nannual_data_list_normalized = []","c3dabcf7":"all_data_list = []","79a34fb7":"for buildingname in buildingnamelist:\n    print(\"Get the data from: \"+buildingname)\n    \n    rawdata = pd.read_csv(\"..\/input\/\"+buildingname+\".csv\", parse_dates=True, index_col='timestamp')\n    rawdata = rawdata[~rawdata.index.duplicated(keep='first')]\n    \n    all_data_list.append(rawdata[buildingname])\n","15d9785e":"all_data = pd.concat(all_data_list, axis=1)","648ef056":"all_data.info()","86e7f633":"all_data.head()","c8567c97":"all_data.plot(figsize=(20,15), subplots=True)","7fe6e54f":"all_data.resample(\"D\").sum().plot(figsize=(20,15), subplots=True)","3890044c":"all_data.truncate(before='2015-02-01',after='2015-03-05').plot(figsize=(20,15), subplots=True)","7deb45e5":"all_data.truncate(before='2015-02-01',after='2015-02-05').plot(figsize=(20,15), subplots=True)","2fd466a5":"for buildingname in buildingnamelist:\n    print(\"Getting data from: \"+buildingname)\n    \n    rawdata = pd.read_csv(\"..\/input\/\"+buildingname+\".csv\", parse_dates=True, index_col='timestamp')\n    floor_area = meta.loc[buildingname][\"sqm\"]\n    \n    annual = rawdata.sum()\n\n    normalized_data = rawdata\/floor_area\n    annual_normalized = normalized_data.sum()\n    \n    annual_data_list_normalized.append(annual_normalized)\n    annual_data_list.append(annual) ","b7c47121":"totaldata = pd.concat(annual_data_list)\ntotaldata_normalized = pd.concat(annual_data_list_normalized)","2b035f25":"totaldata","372aba7e":"totaldata_normalized","c6318c92":"totaldata.plot(kind='bar',figsize=(10,5))","c8831156":"totaldata_normalized.plot(kind='bar',figsize=(10,5))","305dc98d":"# now we want to normalize the data using floor area!","053b8d7d":"# Normalizing Data by Floor Area\n\nIn this analysis will understand the difference between consumption and normalized consummption\n\n- Clayton Miller\n- March 14, 2018","17ff68f4":"# Now we want to divide the consumption data by the sqm","3eb0f81d":"# First, let's look at the data from the buildings","dcf2e6b7":"# Now we loop through 6 buildings to extract data and normalized"}}