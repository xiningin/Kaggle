{"cell_type":{"e92808d1":"code","472d4990":"code","e2456907":"code","74fe5638":"code","4cbde634":"code","8bc320a9":"code","cd1b800c":"code","0c749e74":"code","de1e11e5":"code","d059b17e":"code","56c4d998":"code","7f5d4ec6":"code","51947416":"code","039b89aa":"code","4f6061ea":"code","39bf0718":"code","7ab47494":"code","0774f949":"code","cae8e985":"code","7dc6d2d6":"code","99ba382a":"code","acb3774e":"code","9778a7d5":"code","70b34469":"code","6977d067":"code","75d1c9ba":"code","5b204225":"code","213220c7":"code","2f639659":"code","99fe6034":"code","958806d9":"code","bb9a8665":"code","90c73351":"code","96b8783e":"code","94a7971b":"code","13e03a82":"code","40fd64c2":"code","76a4d211":"code","b2e25fb7":"code","0638ccde":"code","92d59669":"code","bb687272":"code","5be298e2":"code","d8aab20a":"code","d6a7e3ec":"code","1c42c711":"code","06d8401f":"code","74a33cb1":"code","f8f46dcb":"code","5f0cc36e":"code","f8e9b6e4":"code","990d0eb3":"code","a817b77a":"code","f132406d":"code","e5a9b78e":"code","76cd06f0":"code","2006ad03":"markdown","36e2ca82":"markdown","e3447866":"markdown","ebe90d31":"markdown","3ae39918":"markdown","b503f72b":"markdown","558c51ea":"markdown","905ab5dd":"markdown","d48f545b":"markdown","846bcbc5":"markdown"},"source":{"e92808d1":"import numpy as np\nimport sys\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing","472d4990":"data_orig = pd.read_csv(\"..\/input\/train.csv\")\ndata = data_orig","e2456907":"data = data.replace({'?':np.nan})","74fe5638":"data.isnull().sum(axis = 0)","4cbde634":"nan_col = ['Worker Class','Fill','Teen','PREV','Live','MOVE','REG','MSA','State','Area','Reason','MLU','MOC','MIC','Enrolled']","8bc320a9":"data = data.drop(nan_col, axis = 1)","cd1b800c":"pd.set_option('display.max_columns', 60)\ndata.head()","0c749e74":"null_columns = data.columns[data.isna().any()]\nnull_columns","de1e11e5":"for c in null_columns:\n    data[c] = data[c].fillna(data[c].mode()[0])","d059b17e":"for col in data.columns:\n    print(col , data[col].unique())\n    print(\" \")","56c4d998":"categorical_col = ['COB SELF','COB MOTHER','COB FATHER','Detailed']\ndata = data.drop(categorical_col, axis = 1)\ndata.head()","7f5d4ec6":" new_data = pd.get_dummies(data, columns=['Married_Life','Cast', 'Hispanic', 'Sex','Full\/Part', 'Tax Status',\n                                         'Summary', 'Citizen','Schooling'])","51947416":"X_train = new_data\nX_train  = X_train.drop(['Class'], axis=1)\ny_train = new_data['Class']","039b89aa":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","4f6061ea":"#Using RandomForestClassifier for feature selection\nplt.figure(figsize=(60,60))\nmodel = AdaBoostClassifier(random_state=42)\nmodel = model.fit(X_train,y_train)\nfeatures = X_train.columns\nimportances = model.feature_importances_\nimpfeatures_index = np.argsort(importances)\n#print([features[i] for i in impfeatures_index])\nsns.barplot(x = [importances[i] for i in impfeatures_index], y = [features[i] for i in impfeatures_index])\nplt.xlabel('value', fontsize=32)\nplt.ylabel('parameter', fontsize=32)\nplt.tick_params(axis='both', which='major', labelsize=25)\nplt.tick_params(axis='both', which='minor', labelsize=25)\nplt.show()","39bf0718":"#Selecting top features based on their importance according to the above graph\nimpfeatures = features[impfeatures_index[-25:]]\nX_train = X_train[[features for features in impfeatures]]","7ab47494":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)","0774f949":"from imblearn.over_sampling import RandomOverSampler","cae8e985":"ros = RandomOverSampler(random_state=0)\nX_resampled1, y_resampled1 = ros.fit_resample(X_train, y_train)","7dc6d2d6":"score_train_RF = []\nscore_test_RF = []\n\nfor i in range(1,18,1):\n    rf = RandomForestClassifier(n_estimators=i, random_state = 42,class_weight='balanced')\n    rf.fit(X_resampled1,y_resampled1)\n    sc_train = rf.score(X_resampled1,y_resampled1)\n    score_train_RF.append(sc_train)\n    sc_test = rf.score(X_val,y_val)\n    score_test_RF.append(sc_test)","99ba382a":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(1,18,1),score_train_RF,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(1,18,1),score_test_RF,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score,test_score],[\"Train Score\",\"Test Score\"])\nplt.title('Fig4. Score vs. No. of Trees')\nplt.xlabel('No. of Trees')\nplt.ylabel('Score')","acb3774e":"rf = RandomForestClassifier(n_estimators=14, random_state = 42,class_weight='balanced')\nrf.fit(X_resampled1,y_resampled1)\nrf.score(X_val,y_val)","9778a7d5":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\ny_pred_RF = rf.predict(X_val)\nconfusion_matrix(y_val, y_pred_RF)","70b34469":"from sklearn.metrics import roc_auc_score","6977d067":"print(roc_auc_score(y_val,y_pred_RF))","75d1c9ba":"print(classification_report(y_val, y_pred_RF))","5b204225":"from sklearn.tree import DecisionTreeClassifier\n","213220c7":"from sklearn.tree import DecisionTreeClassifier\n\ntrain_acc = []\ntest_acc = []\nfor i in range(2,30):\n    dTree = DecisionTreeClassifier(min_samples_split=i, random_state = 42,class_weight='balanced')\n    dTree.fit(X_resampled1,y_resampled1)\n    acc_train = dTree.score(X_resampled1,y_resampled1)\n    train_acc.append(acc_train)\n    acc_test = dTree.score(X_val,y_val)\n    test_acc.append(acc_test)","2f639659":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(2,30),train_acc,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(2,30),test_acc,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score, test_score],[\"Train Accuracy\", \"Validation Accuracy\"])\nplt.title('Accuracy vs min_samples_split')\nplt.xlabel('Max Depth')\nplt.ylabel('Accuracy')","99fe6034":"dTree = DecisionTreeClassifier(class_weight='balanced', random_state = 42)\ndTree.fit(X_resampled1,y_resampled1)\ndTree.score(X_val,y_val)","958806d9":"y_pred_DT = dTree.predict(X_val)\nprint(confusion_matrix(y_val, y_pred_DT))","bb9a8665":"print(roc_auc_score(y_val,y_pred_DT))","90c73351":"print(classification_report(y_val, y_pred_DT))","96b8783e":"from sklearn.ensemble import AdaBoostClassifier","94a7971b":"score_train_AB = []\nscore_test_AB = []\n\nfor i in range(1,20,1):\n    ab = AdaBoostClassifier(n_estimators=i, random_state = 42)\n    ab.fit(X_resampled1,y_resampled1)\n    sc_train = ab.score(X_resampled1,y_resampled1)\n    score_train_AB.append(sc_train)\n    sc_test = ab.score(X_val,y_val)\n    score_test_AB.append(sc_test)","13e03a82":"plt.figure(figsize=(10,6))\ntrain_score,=plt.plot(range(1,20,1),score_train_AB,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='green', markersize=5)\ntest_score,=plt.plot(range(1,20,1),score_test_AB,color='red',linestyle='dashed',  marker='o',\n         markerfacecolor='blue', markersize=5)\nplt.legend( [train_score,test_score],[\"Train Score\",\"Test Score\"])\nplt.title('Fig4. Score vs. No. of Trees')\nplt.xlabel('No. of Trees')\nplt.ylabel('Score')","40fd64c2":"ab = AdaBoostClassifier(n_estimators=500, random_state = 42)\nab.fit(X_resampled1,y_resampled1)\nab.score(X_val,y_val)","76a4d211":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\ny_pred_AB = ab.predict(X_val)\nconfusion_matrix(y_val, y_pred_AB)","b2e25fb7":"print(roc_auc_score(y_val,y_pred_AB))","0638ccde":"print(classification_report(y_val, y_pred_AB))","92d59669":"from sklearn.naive_bayes import GaussianNB as NB","bb687272":"nb = NB()\nnb.fit(X_resampled1,y_resampled1)\nnb.score(X_val,y_val)","5be298e2":"y_pred_NB = nb.predict(X_val)\nprint(confusion_matrix(y_val, y_pred_NB))","d8aab20a":"print(roc_auc_score(y_val,y_pred_AB))","d6a7e3ec":"print(classification_report(y_val, y_pred_NB))","1c42c711":"X_test1 = pd.read_csv('..\/input\/test.csv')\nX_test1 = X_test1.replace({'?':np.nan})","06d8401f":"ID = X_test1['ID']","74a33cb1":"del_col = ['Worker Class','Fill','Teen','PREV','Live','MOVE','REG','MSA',\n           'State','Area','Reason','MLU','MOC','MIC','Enrolled',\n          'COB SELF','COB MOTHER','COB FATHER','Detailed'\n          ]\n\nX_test1 = X_test1.drop(del_col, axis = 1)\n","f8f46dcb":"null_columns_test = X_test1.columns[X_test1.isna().any()]\nnull_columns_test","5f0cc36e":"for c in null_columns_test:\n    X_test1[c] = X_test1[c].fillna(X_test1[c].mode()[0])","f8e9b6e4":" X_test1 = pd.get_dummies(X_test1, columns=['Married_Life','Cast', 'Hispanic', 'Sex','Full\/Part', 'Tax Status',\n                                         'Summary', 'Citizen','Schooling'])","990d0eb3":"X_test1 = X_test1[[features for features in impfeatures]]","a817b77a":"preds = ab.predict(X_test1)","f132406d":"df = pd.DataFrame(columns=['ID', 'Class'])\ndf['ID']=ID\ndf['Class']=preds\ndf.head()","e5a9b78e":"#df.to_csv('2015b3a70395g.csv',index=False)","76cd06f0":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html='<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title} <\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ncreate_download_link(df)","2006ad03":"### Naive Bayes","36e2ca82":"### Adaboost","e3447866":"### Random Forest","ebe90d31":"### Decision Tree","3ae39918":"## Data Preprocessing","b503f72b":"### Feature Selection","558c51ea":"#### oversampling","905ab5dd":"## Applying Classification Algorithms","d48f545b":"# Datamining Assignment 2","846bcbc5":"## Processing Test Dataset"}}