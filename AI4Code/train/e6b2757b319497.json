{"cell_type":{"83eeec12":"code","c0138cad":"code","49257341":"code","5bf69ca6":"code","ae2dea23":"code","2085b793":"code","46a1737d":"code","8e1ae3d8":"code","a1aac4e1":"code","807d90a4":"code","80c66267":"code","b2485e77":"code","7a54f931":"code","960e819a":"code","35cef7ca":"code","bd05557d":"code","1d6bb44e":"code","8e741143":"code","fd70b612":"code","c86a4523":"code","771901ed":"code","771be2d4":"code","bf3a7014":"code","6f0d61b2":"code","03e0e2f2":"markdown","e434639c":"markdown"},"source":{"83eeec12":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c0138cad":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime","49257341":"# loading dataset\n\ndf = pd.read_csv('..\/input\/2008.csv')\ndf.head()","5bf69ca6":"df.shape","ae2dea23":"# mengecek nilai yang hilang (NaN)\n\ndata_nan = df.isnull().sum(axis=0).reset_index()\ndata_nan.columns = ['variable', 'missing values']\ndata_nan","2085b793":"data_nan['filling factor (%)'] = (df.shape[0] - data_nan['missing values'])\/df.shape[0]*100.\ndata_nan","46a1737d":"data_nan.sort_values(by='filling factor (%)').reset_index(drop=True)","8e1ae3d8":"df['Date'] = pd.to_datetime(df['Year'].map(str)+'-'+df['Month'].map(str)+'-'+df['DayofMonth'].map(str))\ndf.head()","a1aac4e1":"def format_tanggal (dataframe):\n    if pd.isnull(dataframe):\n        return np.nan\n    else:\n        if dataframe == 2400: dataframe = 0\n        dataframe = \"{0:04d}\".format(int(dataframe))\n        tanggal = datetime.time(int(dataframe[0:2]), int(dataframe[2:4]))\n        return tanggal\n\ndef combine_date(x):\n    if pd.isnull(x[0]) or pd.isnull(x[1]):\n        return np.nan\n    else:\n        return datetime.datetime.combine(x[0],x[1])\n\ndef create_flight_time(data, col):    \n    liste = []\n    for index, cols in data[['Date', col]].iterrows():    \n        if pd.isnull(cols[1]):\n            liste.append(np.nan)\n        elif float(cols[1]) == 2400:\n            cols[0] += datetime.timedelta(days=1)\n            cols[1] = datetime.time(0,0)\n            liste.append(combine_date(cols))\n        else:\n            cols[1] = format_tanggal(cols[1])\n            liste.append(combine_date(cols))\n    return pd.Series(liste)","807d90a4":"df['CRSDepTime'] = create_flight_time(df, 'CRSDepTime')\ndf['DepTime'] = df['DepTime'].apply(format_tanggal)\ndf['CRSArrTime'] = df['CRSArrTime'].apply(format_tanggal)\ndf['ArrTime'] = df['ArrTime'].apply(format_tanggal)","80c66267":"df.loc[:5, ['CRSDepTime', 'CRSArrTime', 'DepTime',\n             'ArrTime', 'DepDelay', 'ArrDelay']]","b2485e77":"# mengekstrak parameter statistik dari fungsi groupby\ndef get_stats(group):\n    return {'min': group.min(), 'max': group.max(),\n            'count': group.count(), 'mean': group.mean()}\n\n# membuat dataframe dengan info statistik dari setiap pesawat\nglobal_stats = df['DepDelay'].groupby(df['UniqueCarrier']).apply(get_stats).unstack()\nglobal_stats = global_stats.sort_values('count')\nglobal_stats","7a54f931":"# mengelompokkan penerbangan yang mengalami delay\ndelay_type = lambda x:((0,1)[x > 5],2)[x > 45]\ndf['DelayLvl'] = df['DepDelay'].apply(delay_type)\n\nfig = plt.figure(1, figsize=(10,7))\nax = sns.countplot(y=\"UniqueCarrier\", hue='DelayLvl', data=df)\n\n# mengatur label dari plot yang akan dibuat\nplt.setp(ax.get_xticklabels(), fontsize=12, weight = 'normal', rotation = 0);\nplt.setp(ax.get_yticklabels(), fontsize=12, weight = 'bold', rotation = 0);\nax.yaxis.label.set_visible(False)\nplt.xlabel('Flight count', fontsize=16, weight = 'bold', labelpad=10)\n\n# mengatur legenda dari plot yang akan dibuat\nL = plt.legend()\nL.get_texts()[0].set_text('on time (t < 5 min)')\nL.get_texts()[1].set_text('small delay (5 < t < 45 min)')\nL.get_texts()[2].set_text('large delay (t > 45 min)')\nplt.show()","960e819a":"df.columns","35cef7ca":"np.where(df.dtypes.values == np.dtype('float64'))","bd05557d":"new_df = df.iloc[:, np.where(df.dtypes.values == np.dtype('float64'))[0]]\nnew_df.head()","1d6bb44e":"for i in range(len(new_df.columns)):\n    if (new_df.isnull().iloc[:,i].shape[0]>0):\n        print('\\nAttribute-',i,' (before) :',new_df.isnull().iloc[:,i].shape[0])\n        new_df.iloc[:,i].fillna(new_df.iloc[:,i].mean(), inplace=True)\n        print('\\nAttribute-',i,' (after) :',new_df.isnull().iloc[:,i].shape[0])","8e741143":"new_df.head()","fd70b612":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score","c86a4523":"# define the dictionary of models our script can use\n# the key to the dictionary is the name of the model\n# (supplied via command line argument) and the value is the model itself\nmodels = {\n    \"knn\": KNeighborsClassifier(n_neighbors=1),\n    \"naive_bayes\": GaussianNB(),\n    \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n    \"svm\": SVC(kernel=\"linear\", gamma=\"auto\"),\n    \"decision_tree\": DecisionTreeClassifier(),\n    \"random_forest\": RandomForestClassifier(n_estimators=100),\n    'mlp': MLPClassifier()\n}","771901ed":"df.Diverted","771be2d4":"# perform a training testing split, using 75% of the data for\n# training and 25% for evaluation\n(trainX, testX, trainY, testY) = train_test_split(new_df.values, df.Diverted, random_state=3, test_size=0.25)","bf3a7014":"# train the Random Forest model\nprint(\"[INFO] using '{}' model\".format(\"random_forest\"))\nmodel = models[\"random_forest\"]\nmodel.fit(trainX, trainY)\n# make predictions on our data and show a classification report\nprint(\"[INFO] evaluating...\")\npredictions = model.predict(testX)\nprint(classification_report(testY, predictions))","6f0d61b2":"accuracy_score(testY, predictions)","03e0e2f2":"**1. Mengimpor Libraries**","e434639c":"**Analisis Data Penerbangan Amerika Serikat**"}}