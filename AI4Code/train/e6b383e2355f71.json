{"cell_type":{"5b8fb398":"code","36620d39":"code","ad997916":"code","8bed32be":"code","61215413":"code","5931155d":"code","841697ab":"code","5e1e23d4":"code","067b84ec":"code","8fcc57ac":"code","c9fa37d3":"code","d3813b98":"code","2a21488f":"code","8a5b0ed4":"code","bef11c33":"code","87959bcf":"code","2f05f6d5":"code","202a5bf2":"code","9d9ab489":"markdown","ee2d1858":"markdown","e8d53180":"markdown"},"source":{"5b8fb398":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36620d39":"data = pd.read_csv('..\/input\/nips-2015-papers\/Papers.csv')\ndata.columns","ad997916":"paper_text = data['PaperText']\npaper_1 = paper_text.iloc[0]\npaper_1\n# text = paper_1.str.cat(sep=' ')\n# print(text)","8bed32be":"#!pip install -U spacy\n#!pyhon -m spacy download en_core_web_sm","61215413":"import spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom string import punctuation","5931155d":"stopwords = list(STOP_WORDS)\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp(paper_1)","841697ab":"tokens = [token.text for token in doc]\nprint(tokens)","5e1e23d4":"punctuation","067b84ec":"punctuation = punctuation + '\\n' \nword_frequencies = {}\nfor word in doc:\n    if word.text.lower() not in stopwords:\n        if word.text.lower() not in punctuation:\n            if word.text not in word_frequencies.keys():\n                word_frequencies[word.text] = 1\n            else:\n                word_frequencies[word.text] += 1\nmax_frequency = max(word_frequencies.values())\nprint(\"The most frequent word appeared {} times.\".format(max_frequency))\n# from collections import Counter\n# word_frequencies = Counter(doc.text)","8fcc57ac":"for word in word_frequencies.keys():\n    word_frequencies[word] = word_frequencies[word]\/max_frequency","c9fa37d3":"sentence_tokens = [sent for sent in doc.sents]\nprint(sentence_tokens)","d3813b98":"sentence_scores = {}\nfor sent in sentence_tokens:\n    for word in sent:\n        if word.text.lower() in word_frequencies.keys():\n            if sent not in sentence_scores.keys():\n                sentence_scores[sent] = word_frequencies[word.text.lower()]\n            else:\n                sentence_scores[sent] += word_frequencies[word.text.lower()]\nsentence_scores","2a21488f":"from heapq import nlargest","8a5b0ed4":"select_length = int(len(sentence_tokens)*0.2)\nselect_length","bef11c33":"summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\nsummary","87959bcf":"Combine the summary sentences together.","2f05f6d5":"final_summary = [word.text for word in summary]\nsummary = ' '.join(final_summary)\nprint(summary)","202a5bf2":"print(\"Word count of the original paper: \", len(paper_1))\nprint(\"Word count after summerization: \", len(summary))\n","9d9ab489":"* Text cleaning\n* Sentence tokenization\n* Word tokenization\n* Word-frequency table\n* Summarization","ee2d1858":"Normalize the word frequencies.","e8d53180":"Remove the punctuations"}}