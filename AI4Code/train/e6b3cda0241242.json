{"cell_type":{"ff3f363f":"code","3c970a25":"code","320cddaa":"code","78609004":"code","31abc022":"code","b72f4e56":"code","7e96a7c1":"code","80683e34":"code","56d785b9":"code","7b2b696d":"code","6ecd8543":"code","64a75441":"code","69fd0f1b":"code","79b13a53":"code","9554126a":"code","ff2aa1ff":"code","cbb97e62":"code","6a50d750":"code","a2e8bcc2":"code","75a6f66a":"code","c48896fe":"code","367a4ed4":"code","bcbc3f80":"code","d3e38532":"code","098aa43f":"code","232c9c03":"markdown"},"source":{"ff3f363f":"from IPython.display import JSON\nfrom pathlib import PosixPath\nfrom tqdm import tqdm_notebook\n\nimport PIL.ImageDraw\nfrom fastai.vision import *\n\nOCRDCROP = PosixPath(\"..\/input\/ocrdcrop\/\")\nINPUT = OCRDCROP \/ \"0bags-crop-sauvola\"\nIMGS_SCALED = OCRDCROP \/ \"scaled\"\nMASKS_SCALED = OCRDCROP \/ \"masks_scaled\"\nSCALE_FACTOR = 4\n\nPROCESS_SCALING = False  # already scaled\nPROCESS_MASKING = False  # already masked","3c970a25":"INPUT.ls()[:5]","320cddaa":"imgfiles = sorted(f.relative_to(INPUT) for f in INPUT.ls() if re.match(r'[^.]+\\.png$', str(f.relative_to(INPUT))))\nbinfiles = sorted(f.relative_to(INPUT) for f in INPUT.ls() if re.match(r'[^.]+\\.bin\\.png$', str(f.relative_to(INPUT))))\nannfiles = sorted(f.relative_to(INPUT) for f in INPUT.ls() if re.match(r'[^.]+\\.json$', str(f.relative_to(INPUT))))\nassert len(imgfiles) == len(binfiles)\nassert len(imgfiles) == len(annfiles)\npd.set_option('max_colwidth', 80)\ndf = pd.DataFrame({'img': imgfiles, 'bin': binfiles, 'ann': annfiles})\ndf.head()","78609004":"df[\"ann_json\"] = df.ann.apply(lambda f: json.load(open(INPUT \/ f, \"r\")))\ndf.head()","31abc022":"ann_json_example = json.load(open(INPUT \/ annfiles[0], \"r\"))\nann_json_example","b72f4e56":"segtypes = set()\nfor aj in df.ann_json.to_list():\n    for region in aj.get(\"regions\", []):\n        segtypes.add(region[\"type\"])\nsegtypes = dict((v, k) for k, v in enumerate(sorted(segtypes), start=1))\nsegtypes[\"void\"] = 0\nsegtypes","7e96a7c1":"PathLike = Union[str, PosixPath]\n\ndef pathify(p: PathLike) -> PosixPath:\n    return PosixPath(p) if not type(p) is PosixPath else p ","80683e34":"def resize_image_(imgpath: PosixPath, orig_folder: PathLike = INPUT, dest_folder: PathLike = IMGS_SCALED, scale = SCALE_FACTOR):\n    img = open_image(orig_folder \/ imgpath)\n    img.resize((img.shape[0], img.shape[1] \/\/ scale, img.shape[2] \/\/ scale))\n    img.save(dest_folder \/ imgpath)\n","56d785b9":"if PROCESS_SCALING:\n    for f in tqdm_notebook(imgfiles):\n        resize_image_(f)","7b2b696d":"def regions(imgfile: PathLike) -> List[Dict]:\n    imgfile = pathify(imgfile)\n    annfile = INPUT \/ re.sub('\\.png$', '.json', imgfile.name)\n    ann = json.load(open(annfile, \"r\"))\n    return ann.get(\"regions\", [])\n\ndef create_mask_(\n    imgfile: PathLike,\n    classes: Dict[str, int], \n    img_folder: PathLike = INPUT, \n    mask_folder: PathLike = MASKS_SCALED,\n    # border: str = \"ArtificialBorder\", border_width: int = 5,  # XXX(js): no idea about a good border_width\n    downscale: int = SCALE_FACTOR,\n):\n    imgfile = pathify(imgfile)\n    res = PIL.Image.open(img_folder \/ imgfile.name).size\n    img = PIL.Image.new(\n        mode='L',  # only one 8bit channel (we'll encode the segmentation classes each as one byte with a different nr for each class)\n        size=(res[0] \/\/ downscale, res[1] \/\/ downscale), \n        color=0\n    )\n    regs = regions(imgfile)\n    for r in regs:\n        assert \"coords\" in r\n        assert \"type\" in r\n        coords = [(c[0] \/\/ downscale, c[1] \/\/ downscale) for c in r[\"coords\"]]\n        PIL.ImageDraw.Draw(img).polygon(coords, fill=classes[r[\"type\"]])\n        \n    # Also draw artificial borders but after the filled polygon to not get hidden by any overlapping stuff\n    # for r in regs:\n    #    coords = r[\"coords\"]\n    #    coords += [coords[0], coords[1]]  # necessary to close the lining (it's not autoclosed like for polygonals)\n    #    PIL.ImageDraw.Draw(img).line(coords, fill=classes[border], width=border_width)\n    \n    assert np.max(list(img.getdata())) <= np.max(list(classes.values()))\n    img.save(mask_folder \/ imgfile.name)","6ecd8543":"if PROCESS_MASKING:\n    for f in tqdm_notebook(imgfiles):\n        create_mask_(f, segtypes)","64a75441":"RESNET_SIZE = (224, 224)  # that's what resnet is trained for\nprint(\"Normalize all image with resize to\", RESNET_SIZE)\ndef get_y_fn(imgfile: PathLike) -> PosixPath:\n    return MASKS_SCALED \/ imgfile.name\n\ndef valid_by_book(imgfile: PosixPath, split_pct: float = 0.2) -> bool:\n    \"\"\" Returns same result for all pages inside a book (given they are in the same folder)\"\"\"\n    book_name = imgfile.name.split(\"OCR\")[0]  # anything before OCR in \"arent_dichtercharaktere_1885_OCR-D-IMG-CROP2_0002.png\" determines the book the page is from\n    h = int(hashlib.md5(book_name.encode(\"utf-8\")).hexdigest(), 16)  # little trick to calculate a platform independent hash on the name\n    return (h % 1e6) \/ 1e6 < split_pct\n\ndef create_data(\n    tfms: List[Transform] = None, \n    bs: int = 8,\n    sample_p: float = 1.0, split_pct: float = 0.2, split_by_book: bool = False,\n    seed: int = None\n) -> ImageDataBunch:\n    if not tfms: tfms = []\n    data= (SegmentationItemList\n        .from_folder(IMGS_SCALED)\n        .filter_by_rand(sample_p)\n    )\n    data = (\n        data.split_by_valid_func(valid_by_book)\n        if split_by_book\n        else data.split_by_rand_pct(valid_pct=split_pct, seed=seed)\n    )\n    data = (data\n        .label_from_func(get_y_fn, classes=list(segtypes.values()))\n        .transform(tfms, size=RESNET_SIZE, tfm_y=True)\n        .databunch(bs=bs)\n        .normalize(imagenet_stats)\n    )\n    return data\n\ndata = create_data(seed=1)\ndata","69fd0f1b":"data.items","79b13a53":"data.x[0]","9554126a":"data.y[0]","ff2aa1ff":"data.show_batch()","cbb97e62":"void_code = 0  # I fill image with zeros and we don't want to train this void information\ndef acc_page_seg(input, target):\n    target = target.squeeze(1)\n    mask = target != void_code\n    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()","6a50d750":"tfms = []  # no transformations so far\ndata = create_data(tfms=tfms, split_by_book=True, seed=42)  # XXX(js): tried several batch sizes and 8 seems to work good\ndata","a2e8bcc2":"learn = unet_learner(data, models.resnet34, metrics=acc_page_seg)","75a6f66a":"learn.fit_one_cycle(4)","c48896fe":"learn.show_results()","367a4ed4":"learn.fit_one_cycle(20, max_lr=slice(1e-6, 1e-4))","bcbc3f80":"learn.save(\"unet-epochs24\")","d3e38532":"learn.show_results()","098aa43f":"learn.fit_one_cycle(25, max_lr=slice(1e-6, 1e-4))","232c9c03":"## Look to input files"}}