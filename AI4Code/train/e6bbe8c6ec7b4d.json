{"cell_type":{"e8179692":"code","c04c6577":"code","09011f21":"code","76fa56dd":"code","3c43ab96":"code","1a8505c7":"code","8d21fb66":"code","0b46993d":"code","b4ee826c":"code","b866df97":"code","7f333769":"code","1252bb46":"code","b2690808":"code","8c68190b":"code","49cb1712":"code","9cff8cc2":"code","1c1d2675":"code","3abd99e2":"code","c0e5dfd7":"code","58b100f6":"code","bfded548":"code","2496253f":"code","61c8d346":"code","ddc8c5d7":"code","57845cf0":"code","cd9efc77":"code","1c17324e":"markdown","ec7b21ee":"markdown","907980f6":"markdown","317858c3":"markdown","bda3f4c9":"markdown","07f3c406":"markdown","102e27ee":"markdown","3d7712d7":"markdown","09c5fec8":"markdown"},"source":{"e8179692":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore') # filter warnings\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c04c6577":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","09011f21":"train.head()","76fa56dd":"test.head()","3c43ab96":"print(\"train shape:\",train.shape)\nprint(\"test shape:\",test.shape)","1a8505c7":"train['label'].value_counts().plot(kind = 'bar')","8d21fb66":"y_train = train[\"label\"] # y_train label k\u0131sm\u0131 \nx_train = train.drop(labels = [\"label\"], axis = 1) # label d\u0131\u015f\u0131ndaki t\u00fcm k\u0131s\u0131m","0b46993d":"plt.figure(figsize = (15,7)) # x ve y deki sizeleri\nsns.countplot(y_train, palette = \"icefire\") # grafik\nplt.title(\"number of digit classes\")\ny_train.value_counts(ascending = False) # counts yaz\u0131 olarak","b4ee826c":"x_train.head()\nx_train.iloc[0] # alt alta yaz\u0131lm\u0131\u015f bu pixelleri bir matris'e atarak 28*28'lik resim haline getiriyoruz","b866df97":"\nimg = x_train.iloc[0].to_numpy() # xtrain'nin 0'. indexini al img'e y\u00fckle, matrix'e at\u0131yoruz\nimg = img.reshape((28,28)) # 28 28 olarak img yap\nplt.imshow(img, cmap = 'gray') # gray scale olarak g\u00f6ster 28*28 yapt\u0131\u011f\u0131m\u0131z img'i\nplt.title(train.iloc[0,0]) # hangi say\u0131 oldu\u011funu s\u00f6yl\u00fcyor\nplt.axis(\"off\")\nplt.show()","7f333769":"train.head()","1252bb46":"#index 3 'de benim label'im 4 yani 4 say\u0131s\u0131n\u0131 g\u00f6rdmemiz laz\u0131m\n\nimg = x_train.iloc[3].to_numpy()\nimg = img.reshape((28,28))\nplt.imshow(img, cmap = \"gray\")\nplt.title(train.iloc[3,0]) # ilk \u00f6nce index sonra i\u00e7indeki index\nplt.axis(\"off\")\nplt.show()","b2690808":"#reshape\nx_train = x_train.values.reshape(-1, 28, 28, 1) # 28, 28, 1 'lik matris'e \u00e7eviriyorum asl\u0131nda 4 boyutlu oluyor ilk boyut ka\u00e7 tane data var onu g\u00f6steriyor\ntest = test.values.reshape(-1, 28, 28, 1)","8c68190b":"print(x_train.shape)\nprint(test.shape)","49cb1712":"x_train = x_train.astype('float32')\ntest = test.astype('float32')\nx_train = x_train \/ 255 # bu datalar\u0131 255'e b\u00f6lere normalize ediyoruz label d\u0131\u015f\u0131ndaki t\u00fcm datal\ntest = test \/ 255 # test edilecek data\nprint(x_train.shape)\nprint(test.shape)","9cff8cc2":"#label encoding (0,0,1,0,0,0,0,0) = 2 gibi\nnclasses = y_train.max() - y_train.min() + 1 # 10\nprint(\"nclasses\",nclasses)\nfrom keras.utils.np_utils import to_categorical # one hot encoding\ny_train = to_categorical(y_train, num_classes = nclasses)  # ka\u00e7 tane data var 0 1 2 3 4 5 6 7 8 9 \nprint(\"Shape of ytrain after encoding: \", y_train.shape)","1c1d2675":"from sklearn.model_selection import train_test_split\nseed = 1\nnp.random.seed(seed)\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = seed, shuffle = True, stratify=y_train) #%10luk test i\u00e7in ay\u0131r burada test gibi validation var kullan\u0131yoruz\nprint(\"x_train shape:\", X_train.shape)\nprint(\"x_val shape:\", X_val.shape)\nprint(\"y_train shape:\", Y_train.shape)\nprint(\"y_val shape:\", Y_val.shape) ","3abd99e2":"#data augmentation \n# resimleri de\u011fi\u015ftiriyoruz overfitting'i \u00f6nlemek i\u00e7in\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=0.2,  # randomly rotate images in the range 5 degrees # 10\n        zoom_range = 0.2, # Randomly zoom image 5%                           # 0.1\n        width_shift_range=0.2,  # randomly shift images horizontally 5%      # 0.1\n        height_shift_range=0.2,  # randomly shift images vertically 5%       # 0.1\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","c0e5dfd7":"for i in range(10, 15):\n    plt.imshow(X_train[i][:,:,0])\n    plt.show()","58b100f6":"#library\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop, Adam\n\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n","bfded548":"nets = 4\nmodel = [0] * 10 # nets\nfor i in range(10): #nets\n\n    model[i] = Sequential()\n\n    model[i].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(32, kernel_size = 3, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(BatchNormalization())\n    model[i].add(Dropout(0.4))\n    \n# filters feature detect eden filtre input boyutumuz 28*28*1\n# 8 tane 5x5'lik filtrem var \n# same padding kullan\u0131yoruz\n# buna initial input shape belirlememiz laz\u0131m\n    \n    model[i].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(64, kernel_size = 3, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(BatchNormalization())\n    model[i].add(Dropout(0.4))\n\n    model[i].add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model[i].add(BatchNormalization())\n    model[i].add(Flatten())\n    model[i].add(Dropout(0.4))\n    model[i].add(Dense(256, activation = \"relu\")) # hidden layer ekle\n    model[i].add(Dropout(0.4))\n    model[i].add(Dense(10, activation='softmax')) # \u00e7oklu output sebebiyle softmax\n    model[i].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    #binary cross entropy'den fark\u0131 binary'de 1 veya 0 gibi de\u011fer alabiliyordu categorical'de kategorik olarak sana 2den fazla feature varsa bunu kullan\u0131yoruz","2496253f":"# clear comment for use\n\"\"\"#epoch ve batch size \n\n# 10 tane resmin var diyelim, batch size 2 olsun. her seferinde forward-backward propagation yaparken 2 resimle yapacaks\u0131n. bunu 5 kere yapacaks\u0131n batch'i\n# bu i\u015fleme 1 epoch diyoruz , burada epoch 3 dersek bunu 15 kere batch yapaca\u011f\u0131m.\n\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\nmodel_log = [0] * 10 # nets\nepochs = 45 # accuracy artt\u0131rmak i\u00e7in epoch yani num of iteration y\u00fckseltmemiz laz\u0131m ama zaman artar\nfor j in range(10): # nets\n    print(\"CNN \",j+1)\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.1)\n    model_log[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n        epochs = epochs, steps_per_epoch = X_train2.shape[0]\/\/64,  \n        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=1)\n    print(\"CNN: \",j+1,\" \",\"Epochs: \",epochs,\" \",\"Train_accuracy: \",max(model_log[j].history['accuracy']),\" \",\"Validation_accuracy: \",max(model_log[j].history['val_accuracy']))\"\"\"","61c8d346":"plt.plot(model_log[0].history['accuracy'],label = 'ACCURACY')\nplt.plot(model_log[0].history['val_accuracy'],label = 'VALIDATION ACCURACY')\nplt.legend()","ddc8c5d7":"plt.plot(model_log[0].history['loss'],label = 'TRAINING LOSS')\nplt.plot(model_log[0].history['val_loss'],label = 'VALIDATION LOSS')\nplt.legend()","57845cf0":"results = np.zeros( (test.shape[0],10) ) \nfor j in range(10):\n    results = results + model[j].predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","cd9efc77":"\"\"\"#submission\nsample = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\nsample[\"Label\"] = labels\nsubmission = sample\nsubmission.to_csv(\"submission.csv\", index=False)\"\"\"","1c17324e":"## Visualization","ec7b21ee":"An example might make it clearer.\n\nSay you have a dataset of 10 examples (or samples). You have a batch size of 2, and you've specified you want the algorithm to run for 3 epochs.\n\nTherefore, in each epoch, you have 5 batches (10\/2 = 5). Each batch gets passed through the algorithm, therefore you have 5 iterations per epoch. Since you've specified 3 epochs, you have a total of 15 iterations (5*3 = 15) for training.\n","907980f6":"# Splitting the dataset","317858c3":"## x_train and y_train","bda3f4c9":"# Normalization","07f3c406":"# Data Augmentation","102e27ee":"# Read Dataset","3d7712d7":"# One hot encoding","09c5fec8":"# CNN (Convolutional Neural Network)\n### CNN is normally, used for image classsification and object detection\n##### Detecting Edges and convex shapes, kedinin kuyru\u011fu, say\u0131n\u0131n d\u00fcz \u00e7izgileri vb.. # basic shapes, edge detect filter : [0,10,0],[10,-4,10],[0,10,0] gibi..\n\n<a href=\"https:\/\/ibb.co\/kV1j9p\"><img src=\"https:\/\/preview.ibb.co\/nRkBpp\/gec2.jpg\" alt=\"gec2\" border=\"0\"><\/a>\n\n* Convolution = feature detector (relu) kinda filter\n* Pooling = downsampling ( convolution matrix'in boyutunu k\u00fc\u00e7\u00fclt\u00fcyor) overfitting'i engelliyor\n* Flatten = matrix'i d\u00fczle\u015ftiriyor\n* feature map = \u00e7arp\u0131m i\u015flemi mapping gibi\n* stride = matrix \u00fczerinde kayma i\u015flemi bunu yaparken bilgi kaybedebiliyoruz..\n<a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/m4FQC9\/gec.jpg\" alt=\"gec\" border=\"0\"><\/a>\n* After having convolution layer we use ReLU to break up linearity. Increase nonlinearity. Because images are non linear.\n<a href=\"https:\/\/ibb.co\/mVZih9\"><img src=\"https:\/\/preview.ibb.co\/gbcQvU\/RELU.jpg\" alt=\"RELU\" border=\"0\"><\/a>\n* relu = non linearity'i artt\u0131r\u0131yor, pozitif taraf ne girerse o \u00e7\u0131kar, negatif her zaman 0 \u00e7\u0131kar\n* convolution uyguland\u0131\u011f\u0131nda bilgi kaybediyoruz.. bunu kaybetmemek i\u00e7in padding methodu kullan\u0131yoruz buna same padding diyoruz\n* same padding resmimizin etraf\u0131na 0 olan bir layer yap\u0131p data kaybetmeden hepsini kullanmaya \u00e7al\u0131\u015f\u0131yoruz\n* As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n* input size and output size are same.\n <a href=\"https:\/\/ibb.co\/jUPkUp\"><img src=\"https:\/\/preview.ibb.co\/noH5Up\/padding.jpg\" alt=\"padding\" border=\"0\"><\/a>\n* max pooling # over fitting'i engellemek i\u00e7in yap\u0131yoruz. 2x2'lik bir matrisimiz olsun max pooling yapt\u0131\u011f\u0131m\u0131z i\u00e7in maximum de\u011feri buraya yaz\u0131yoruz, pooling layer elde ediyoruz, down sampling yap\u0131yoruz. 6x6'l\u0131k bir matris'i 2x2 ile taray\u0131p max de\u011feri yazarsak 3x3 'l\u00fck matris olu\u015fturuyoruz bir nevi down sampling \n* It makes down-sampling or sub-sampling (Reduces the number of parameters)\n* It makes the detection of features invariant to scale or orientation changes.\n* It reduce the amount of parameters and computation in the network, and hence to also control overfitting. \n<a href=\"https:\/\/ibb.co\/ckTjN9\"><img src=\"https:\/\/preview.ibb.co\/gsNYFU\/maxpool.jpg\" alt=\"maxpool\" border=\"0\"><\/a>\n* flattening\n <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/c7eVvU\/flattenigng.jpg\" alt=\"flattenigng\" border=\"0\"><\/a>\n* full connectted layer\n* Neurons in a fully connected layer have connections to all activations in the previous layer\n* Artificial Neural Network\n<a href=\"https:\/\/ibb.co\/hsS14p\"><img src=\"https:\/\/preview.ibb.co\/evzsAU\/fullyc.jpg\" alt=\"fullyc\" border=\"0\"><\/a>\n* creating model\n* conv => max pool => dropout => conv => max pool => dropout => fully connected (2 layer)\n* Dropout: Dropout is a technique where randomly selected neurons are ignored during training \n* forward propagation yaparken baz\u0131 nodelar\u0131 kapat\u0131yoruz, random yap\u0131yoruz, \u00e7e\u015fitlili\u011fi artt\u0131rmak i\u00e7in kullan\u0131yoruz \n* <a href=\"https:\/\/ibb.co\/jGcvVU\"><img src=\"https:\/\/preview.ibb.co\/e7yPPp\/dropout.jpg\" alt=\"dropout\" border=\"0\"><\/a>"}}