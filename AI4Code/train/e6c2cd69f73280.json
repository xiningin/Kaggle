{"cell_type":{"b6746d44":"code","a7c05233":"code","521e4afa":"code","c08760ad":"code","6929d963":"code","5b3ae645":"code","26798555":"code","a6a5bf0e":"code","d089fdfd":"code","825431df":"code","f7ddeb75":"code","de9cf2a2":"code","ea3239c6":"code","ff6604fa":"code","0ec2a6cb":"code","202b4277":"code","b19afb2e":"code","6d24f672":"code","39d54772":"code","cb52525e":"code","16ea57fa":"code","cfe5c331":"code","1aebfe73":"code","3fc48421":"code","4895b13b":"code","f57cca3e":"code","dd20e5dd":"code","88658e06":"code","75e72963":"code","da463c3a":"code","f0670ebd":"code","1da13394":"code","15130ff3":"code","962c1691":"code","f756ad26":"code","764a3de4":"code","ba904716":"code","f38a15bc":"code","bf636428":"code","751428e1":"code","056e5d7c":"code","36fcc90f":"code","c6706e41":"code","8efbc259":"code","a3414a26":"code","2992c3ca":"code","baccf632":"code","4fd8ef98":"code","bac0857d":"code","a5dceabf":"code","1b587fd7":"code","5164ba4b":"code","28713121":"code","f82d9996":"code","0d95192c":"code","e8f07fc6":"code","47684bfe":"code","4e6fe7a5":"code","3e73f97c":"code","673a13e2":"code","0dfbdc17":"code","96db5825":"code","f710665a":"code","d126dd6a":"code","84eaa4c7":"code","14b14008":"code","bbd8ca23":"code","fb2a82cf":"code","76e97ce1":"code","186be758":"code","cb081928":"code","c6a8f920":"code","900618d1":"code","d4c2b6dd":"code","1c27f779":"code","19372211":"code","98f48cc3":"code","eb8aea80":"code","fe9fd60b":"markdown","6a60bb14":"markdown","13123480":"markdown","310e26cd":"markdown","6a2f5915":"markdown","1031ddab":"markdown","59ac438e":"markdown","848a6372":"markdown","65aff195":"markdown","1f352b4a":"markdown","aca1d33e":"markdown","756c6bde":"markdown","a4fdacf6":"markdown","bc93ff13":"markdown","9ff934da":"markdown","9494c8fe":"markdown","c597afff":"markdown","ef2cc572":"markdown","cb9a1498":"markdown","298b8a49":"markdown","921978e1":"markdown"},"source":{"b6746d44":"pip install --upgrade seaborn","a7c05233":"import seaborn as sns","521e4afa":"sns.__version__","c08760ad":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport osmnx as ox\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\");\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\nimport zipfile\nwith zipfile.ZipFile('..\/input\/two-sigma-connect-rental-listing-inquiries\/test.json.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('\/kaggle\/working\/')\n\nwith zipfile.ZipFile('..\/input\/two-sigma-connect-rental-listing-inquiries\/train.json.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('\/kaggle\/working\/')\n    \n    \nprint('After zip extraction:')\nprint(os.listdir(\"\/kaggle\/working\/\"))","6929d963":"data_root = '\/kaggle\/working'\nprint(os.listdir(data_root))","5b3ae645":"train_df = pd.read_json(\"..\/working\/train.json\")\ntrain_df.head(3)","26798555":"data_df = train_df.copy()","a6a5bf0e":"data_df['interest_level'].value_counts()\/data_df.shape[0]","d089fdfd":"data_df.info()","825431df":"data_df.groupby('interest_level')['price'].mean()","f7ddeb75":"plt.figure(figsize=(15, 7))\n\nsns.boxplot(y='price', data=data_df)\n\nplt.title('Price', fontsize=20)\n#plt.ylabel('Age', fontsize=14)\n#plt.xlabel('Education', fontsize=14)\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14);","de9cf2a2":"q = data_df['price'].quantile(0.99)\ndata_df = data_df[data_df['price'] < q]","ea3239c6":"data_df['price'].describe()","ff6604fa":"sns.displot(\n    data = data_df,\n    x = data_df['price']\/1000,\n    hue='interest_level',\n    kind = \"kde\"   \n    #common_norm=False # \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u0430\u044f \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u0434\u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0430\n)\n\nplt.title('Price', fontsize=20)\nplt.xlabel('Price', fontsize=14)\nplt.ylabel('Dentsity', fontsize=14)\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14);","0ec2a6cb":"data_df.bathrooms.unique()","202b4277":"data_df.building_id.value_counts()","b19afb2e":"data_df.loc[data_df.bathrooms == 2.5].head(4)","6d24f672":"def code_mean (data, cat_feature, real_feature):\n    return (data[cat_feature].map(data.groupby(cat_feature)[real_feature].mean()))","39d54772":"data_df['interest_level_mean'] = code_mean(data_df, 'interest_level', 'price')","cb52525e":"data_df['interest_level_mean'].value_counts()","16ea57fa":"data_df['price'].describe()","cfe5c331":"data_df.plot(kind=\"scatter\", x = \"bedrooms\", y = \"price\")","1aebfe73":"data_df['price'].describe()","3fc48421":"plt.figure(figsize=(8,6))\nsns.distplot(data_df.price.values, bins=50, kde=True)\nplt.xlabel('price', fontsize=12)\nplt.show()","4895b13b":"data_df['created'].sort_values(ascending=False)","f57cca3e":"import datetime\n\norigin = datetime.datetime(2016,1,1)\ndata_df['created_code'] = data_df['created'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S') - origin).days)\ndata_df['created_code'].describe()\n","dd20e5dd":"data_df['num_photos'] = data_df['photos'].apply(len)\ndata_df['num_features'] = data_df['features'].apply(len)\ndata_df['num_description_words'] = data_df['description'].apply(lambda x: len(x.split(' ')))","88658e06":"data_df = data_df.drop(['photos', 'created', 'features', 'description', 'listing_id', 'street_address'], axis=1)","75e72963":"data_df.info()","da463c3a":"data_df.hist(bins=50, figsize=(20,15))","f0670ebd":"corr_matrix = data_df.corr()\n","1da13394":"corr_matrix[\"interest_level_mean\"].sort_values(ascending=False)","15130ff3":"lat_target = data_df.latitude # \u043c\u0430\u0441\u0441\u0438\u0432 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432\nlng_target = data_df.longitude\n#fig, ax = ox.plot_graph(G, figsize=(10,20), close=False, show=False)\n#ax.scatter(lng_target, lat_target) # \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432\n","962c1691":"data_df.loc[data_df['interest_level'] == 'low', ['interest_level_coded']] = 0\ndata_df.loc[data_df['interest_level'] == 'medium', ['interest_level_coded']] = 1\ndata_df.loc[data_df['interest_level'] == 'high', ['interest_level_coded']] = 2","f756ad26":"data_df['interest_level_coded'].head(10)","764a3de4":"#G = ox.graph_from_place('New York, USA', network_type='walk')\n\n#N = data_df['interest_level_coded'].count()","ba904716":"import seaborn as sns\n\n#fig, ax = ox.plot_graph(G, figsize=(10,20), close=False, show=False, bgcolor='grey',)\n#c = data_df['interest_level_coded']\n             \n#scatter = ax.scatter(lng_target, lat_target, c = c)# \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432\n\n# produce a legend with the unique colors from the scatter\n#legend1 = ax.legend(*scatter.legend_elements() ,loc=\"upper right\", title=\"Interests\")\n","f38a15bc":"from wordcloud import WordCloud\n\nplt.figure(figsize = (12, 12))\ntext = ' '.join(train_df['description'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Words in Apartment Description', fontsize=14)\nplt.axis(\"off\")","bf636428":"list_of_features = list(train_df['features'].values)\nplt.figure(figsize = (10, 10))\ntext = ' '.join(['_'.join(i.split(' ')) for j in list_of_features for i in j])\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False, width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Features', fontsize=14)\nplt.axis(\"off\")\nplt.show()","751428e1":"plt.figure(figsize = (12, 12))\ntrain_df['display_address'] = train_df['display_address'].apply(lambda x: x.replace(' ', '_'))\ntext = ' '.join(data_df['display_address'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Display Addresses', fontsize=14)\nplt.axis(\"off\")\nplt.show()","056e5d7c":"temp = pd.DataFrame(data_df.dtypes)\ntemp.columns = [\"DataType\"]","36fcc90f":"temp","c6706e41":"categorical_columns = temp.index[temp[\"DataType\"] == 'object'].values","8efbc259":"for column in categorical_columns:\n    print(column+ \" column has :\", str(len(data_df[column].unique()))+\" distinct values\")","a3414a26":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin","2992c3ca":"test_df = pd.read_json(\"..\/working\/test.json\")\ntest_df.info()","baccf632":"train_df.loc[train_df['interest_level'] == 'low', ['interest_level_coded']] = 0\ntrain_df.loc[train_df['interest_level'] == 'medium', ['interest_level_coded']] = 1\ntrain_df.loc[train_df['interest_level'] == 'high', ['interest_level_coded']] = 2","4fd8ef98":"X_train = train_df.drop(columns=['interest_level', 'interest_level_coded'], axis=1).copy()\ny_train = train_df['interest_level_coded'].copy()\n#y_train = pd.factorize(y_train)[0]\nX_train.shape, y_train.shape","bac0857d":"X_test = test_df.copy()","a5dceabf":"X_test.shape","1b587fd7":"X_test.head()","5164ba4b":"cat_attrs = ['building_id', 'display_address', 'manager_id']","28713121":"import itertools\nfrom collections import Counter\na = list(X_train['features'].values.flatten())\nfeature_list = list(itertools.chain.from_iterable(a))\ntop_25_features = [ x for x, y in Counter(feature_list).most_common(25)]\ntop_25_features","f82d9996":"from sklearn.base import BaseEstimator, TransformerMixin","0d95192c":"class CustomObjectAttrs(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X['building_id'] = pd.factorize(X['building_id'])[0]\n        X['manager_id'] = pd.factorize(X['manager_id'])[0]\n        X['display_address'] = pd.factorize(['display_address'])[0]\n        return X","e8f07fc6":"class CustomNumAttrs(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X['photos'] = X['photos'].apply(len)\n        X['description'] = X['description'].apply(lambda x: len(x.split(' ')))\n        X['building_id_cod'] = X['building_id'].map(X.groupby('building_id').size())\n        X['manager_id_cod'] = X['manager_id'].map(X.groupby('manager_id').size())\n        X['display_address_cod'] = X['display_address'].map(X.groupby('display_address').size())\n        X = X.drop(['building_id'], axis=1)\n        X = X.drop(['manager_id'], axis=1)\n        X = X.drop(['display_address'], axis=1)\n\n        return X","47684bfe":"import datetime\n\nclass CustomDateAttrs(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        #origin = datetime.datetime(2016,1,1)\n        #X['created_code'] = X['created'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S') - origin).days)\n        X[\"created\"] = pd.to_datetime(X[\"created\"])\n        X[\"created_year\"] = X[\"created\"].dt.year\n        X[\"created_month\"] = X[\"created\"].dt.month\n        X[\"created_day\"] = X[\"created\"].dt.day\n        X[\"created_hour\"] = X[\"created\"].dt.hour\n        X = X.drop(['created'], axis=1)\n        return X","4e6fe7a5":"encoded_features = []\n\nclass CustomMultiLabelBinarizer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.mlb_enc = None\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        try:\n            X['features'] = X['features'].apply(lambda x: ['no_feature', ] if len(x)==0 else self.get_features(x))\n            if self.mlb_enc==None:\n                self.mlb_enc = MultiLabelBinarizer()\n                X_enc = pd.DataFrame(self.mlb_enc.fit_transform(X['features']), columns=self.mlb_enc.classes_, \n                                     index=X.index)\n                encoded_features.append(self.mlb_enc.classes_)\n            else:\n                X_enc = pd.DataFrame(self.mlb_enc.transform(X['features']), columns=self.mlb_enc.classes_, \n                                     index=X.index)\n            X = pd.concat([X, X_enc], axis=1)\n            X = X.drop('features', axis=1)\n        except Exception as e:\n            print(\"CustomMultiLabelBinarizer: Exception caught for {}: {}\".format(e))\n        return X\n    \n    @staticmethod\n    def get_features(x):\n        if len(x)==0:\n            return ['no_feature', ]\n        \n        features = [feature for feature in x if feature in top_25_features]\n        if len(features)==0:\n            features.append('other')\n        return features","3e73f97c":"pre_process = ColumnTransformer([('drop_cols', 'drop', ['street_address', 'listing_id']),\n                                 ('num_imputer', SimpleImputer(strategy='median'), ['bathrooms', 'bedrooms', 'price', 'latitude', 'longitude']),\n                                 ('custom_date_attr', CustomDateAttrs(), ['created', ]),\n                                 ('custom_num_attrs', CustomNumAttrs(), ['description', 'photos', 'building_id', 'manager_id', 'display_address']),\n                                 ('list_encoder', CustomMultiLabelBinarizer(), ['features', ])\n                                 ])\n\nX_train_transformed = pre_process.fit_transform(X_train)\nX_test_transformed = pre_process.transform(X_test)\n\nX_train_transformed.shape, X_test_transformed.shape","673a13e2":"feature_columns = ['bathrooms', 'bedrooms', 'price', 'latitude', 'longitude', 'building_id_num', 'manager_id_num', 'display_address_num'] + ['created_year', 'created_month', 'created_day', 'created_hour'] + ['description', 'photos'] + list(encoded_features[0])\nprint(len(feature_columns), feature_columns)","0dfbdc17":"X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_columns)\nX_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_columns)","96db5825":"X_train_transformed.head(5)","f710665a":"from sklearn.model_selection import train_test_split\n\nX_train_transformed, X_val_transformed, Y_train, Y_val = train_test_split(X_train_transformed, y_train, test_size=0.1, random_state=2018)\n\nprint('Shape of x_train:', X_train_transformed.shape)\nprint('Shape of x_val:', X_val_transformed.shape)\nprint('Shape of y_train:', Y_train.shape)\nprint('Shape of y_val:', Y_val.shape)","d126dd6a":"Y_train","84eaa4c7":"Y_val","14b14008":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler = MinMaxScaler()\nscaler.fit(X_train_transformed)\n\nX_train_scaled = scaler.transform(X_train_transformed)\nX_val_scaled = scaler.transform(X_val_transformed)\nX_test_scaled = scaler.transform(X_test_transformed )","bbd8ca23":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras.layers import BatchNormalization","fb2a82cf":"def act(x):\n    return keras.activations.elu(x, alpha=0.3)","76e97ce1":"he_inint = keras.initializers.VarianceScaling(\n    scale=1.0, mode=\"fan_avg\", distribution=\"truncated_normal\", seed=None\n)","186be758":"model = keras.Sequential(\n    [\n        keras.Input(shape=X_train_scaled.shape[1]),\n        layers.Dense(256, kernel_initializer = he_inint, activation=act),\n        layers.BatchNormalization(),\n        layers.Dense(256, kernel_initializer = he_inint, activation=act),\n        layers.Dropout(0.5),\n        layers.Dense(128, kernel_initializer = he_inint, activation=act),\n        layers.Dropout(0.5),\n        #layers.ActivityRegularization(l1=0.0, l2=0.01),\n        layers.Dense(128, kernel_initializer = he_inint, activation=act),\n        layers.Dropout(0.5),\n        # layers.ActivityRegularization(l1=0.0, l2=0.01),\n        layers.Dense(64, kernel_initializer = he_inint, activation=act),\n        layers.Dropout(0.5),\n        layers.Dense(64, kernel_initializer = he_inint, activation=act),\n        layers.Dropout(0.5),\n        layers.Dense(3, activation=\"softmax\"),\n    ]\n)\n\nmodel.summary()","cb081928":"opt = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\")\n\nmodel.compile(optimizer = opt, loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n\nmodel.fit(X_train_scaled, Y_train, validation_data = (X_val_scaled, Y_val), epochs=60, batch_size=64)","c6a8f920":"plt.plot(model.history.history['loss'])\nplt.plot(model.history.history['val_loss'])\nplt.title(\"Model's Training & Validation loss across apochs\")\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()","900618d1":"plt.plot(model.history.history['accuracy'])\nplt.plot(model.history.history['val_accuracy'])\nplt.title(\"Model's Training & Validation accuracy across apochs\")\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()","d4c2b6dd":"#prediction=model.predict(X_val_scaled)","1c27f779":"prediction=model.predict(X_test_scaled)","19372211":"import xgboost as xgb\n\ndef runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.03\n    param['max_depth'] = 6\n    param['silent'] = 1\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest)\n    return pred_test_y, model","98f48cc3":"out_df = pd.DataFrame(prediction)\nout_df.columns = [\"high\", \"medium\", \"low\"]\nout_df[\"listing_id\"] = X_test.listing_id.values\n#new_order = [\"listing_id\", \"high\", \"medium\", \"low\"]\nout_df = out_df.reindex(columns=[\"listing_id\"] + list(out_df.columns[:-1]))\n#out_df = out_df[out_df.columns[new_order]]\nout_df.to_csv(\"cz.csv\", index=False)","eb8aea80":"out_df.head()","fe9fd60b":"\u041f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u0433\u0440\u0430\u0444\u0438\u043a, \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434 \u043e \u0442\u043e\u043c, \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u043f\u0440\u0438\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u0432\u044b\u0431\u0440\u043e\u0441\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u043d\u0435\u0433\u0430\u0442\u0438\u0432\u043d\u043e \u043f\u043e\u0432\u043b\u0438\u044f\u0442\u044c \u043d\u0430 \u0430\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445. \u0418\u0441\u043a\u043b\u044e\u0447\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 'price'.","6a60bb14":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u044b: 'num_photos', 'num_features'","13123480":"\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0430\u0446\u0438 \u0438 \u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","310e26cd":"\u041f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u0433\u0440\u0430\u0444\u0438\u043a, \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434 \u043e \u0442\u043e\u043c, \u0432 \u0434\u0430\u043d\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u043f\u0440\u0438\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u0432\u044b\u0431\u0440\u043e\u0441\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u043d\u0435\u0433\u0430\u0442\u0438\u0432\u043d\u043e \u043f\u043e\u0432\u043b\u0438\u044f\u0442\u044c \u043d\u0430 \u0430\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445. \u0418\u0441\u043a\u043b\u044e\u0447\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 'price'.","6a2f5915":"**\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445**","1031ddab":"\u0423\u0434\u0430\u043b\u0438\u043c \u0441\u0442\u0440\u043e\u043a\u0438 \u0441 \u0432\u044b\u0431\u0440\u043e\u0441\u0430\u043c\u0438 \u043f\u043e \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u0443 'price'","59ac438e":"\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0431\u043e\u043b\u0435\u0435 \u043f\u043e\u0434\u0440\u043e\u0431\u043d\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a 'price'","848a6372":"\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u044b","65aff195":"\u041f\u043e\u0441\u0442\u043e\u0440\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 \u043d\u0435\u0434\u0432\u0438\u0436\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u043a\u043e\u043b-\u0432\u0430 \u043a\u043e\u043c\u043d\u0430\u0442","1f352b4a":"\u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u043d\u0430\u0431\u043e\u0440 Train \u043d\u0430 \u043d\u0430\u0431\u043e\u0440\u044b Train \u0438 Val \u0432 \u0441\u043e\u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0438 90:10","aca1d33e":"\u0418\u0441\u0441\u043b\u0435\u0434\u0443\u0435\u043c \u043a\u043e\u043b\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u043e\u0432","756c6bde":"**\u0413\u0438\u043f\u043e\u0442\u0435\u0437\u044b**\n1. Interest_level \u043c\u043e\u0436\u0435\u0442 \u0437\u0430\u0432\u0438\u0441\u0435\u0442\u044c \u043e\u0442 price\n2. Price \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u043e\u0442 bathrooms \u0438 bedrooms\n3. \u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u043e\u043b-\u0432\u0430 photos \u0438 interest_level\n4. \u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c display_address \u0438 price\n5. \u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c features \u0438 price\n6. \u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c created \u0438 price","a4fdacf6":"\u0422.\u043a. \u043f\u0440\u0438\u0437\u043d\u0430\u043a 'interest_level' \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u043c, \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043c \u0435\u0433\u043e \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0440\u0435\u0434\u043d\u0435\u0439 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\u044e \u043a\u0432\u0430\u0440\u0442\u0438\u0440 \u0432\u043d\u0443\u0442\u0440\u0438 \u0433\u0440\u0443\u043f\u043f\u044b","bc93ff13":"**\u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c**","9ff934da":"\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0431\u043e\u043b\u0435\u0435 \u043f\u043e\u0434\u0440\u043e\u0431\u043d\u043e","9494c8fe":"**Exploratory data analysis**","c597afff":"\u041e\u0442\u043c\u0435\u0442\u0438\u043c, \u0447\u0442\u043e \u0441\u0440\u0435\u0434\u043d\u044f\u044f \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0431\u044c\u044f\u0432\u043b\u0435\u043d\u0438\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 'low' - 4.176,  'medium' - 3.158, 'high' - 2.700. ","ef2cc572":"\u0412\u044b\u0447\u0438\u0441\u043b\u0438\u043c \u0441\u0440\u0435\u0434\u043d\u044e\u044e \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438","cb9a1498":"\u0412\u044b\u044f\u0441\u043d\u0438\u043c \u043a\u0430\u043a\u0438\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u043e\u0431\u044f\u0432\u043b\u0435\u043d\u0438\u0439 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044e\u0442","298b8a49":"\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0430\u0442\u0440\u0438\u0431\u0443\u0442 'cerated'.","921978e1":"\u041e\u0442\u043c\u0435\u0442\u0438\u043c, \u0447\u0442\u043e \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u044b \u043d\u0435 \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e, \u043f\u0440\u0435\u043e\u0431\u043b\u0430\u0434\u0430\u0435\u0442 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u0441 \u043d\u0438\u0437\u043a\u0438\u043c \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u043c, \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u0441 \u0432\u044b\u0441\u043e\u043a\u0438\u043c \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u043c \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u0442 \u043b\u0438\u0448\u044c 7%."}}