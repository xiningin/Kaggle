{"cell_type":{"08dc3245":"code","c287a222":"code","6cb9eb94":"code","3f531c8e":"code","0d633845":"code","3051bde3":"code","aff8dcea":"code","1658d2c6":"code","472acdc3":"code","b3a60f70":"code","57586bc8":"code","afa31564":"code","276c4a57":"code","48988017":"markdown","38744c69":"markdown","b9d2a6e9":"markdown","0cb63ef5":"markdown","46cf4631":"markdown","6caaa261":"markdown","ab2f7603":"markdown","47e28358":"markdown","91be5dbd":"markdown","e6b58884":"markdown","0f8270a8":"markdown","6cd1d94e":"markdown"},"source":{"08dc3245":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport gc\nimport os\nimport logging\nimport datetime\nimport warnings\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.offline as py \nfrom plotly.offline import init_notebook_mode, iplot\npy.init_notebook_mode(connected=True) # this code, allow us to work with offline plotly version\nimport plotly.graph_objs as go # it's like \"plt\" of matplot\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c287a222":"train_df = pd.read_csv('..\/input\/train.csv')\ntrain_df.head()","6cb9eb94":"test_df = pd.read_csv('..\/input\/test.csv')\ntest_df.head()","3f531c8e":"train_df['target'].value_counts()","0d633845":"sns.countplot(train_df['target'])","3051bde3":"train_df.shape","aff8dcea":"train_df.describe()","1658d2c6":"train_df.isnull().any().any()","472acdc3":"train_df.hist(figsize = (20,20), bins = 20)\nplt.subplots_adjust(bottom=1.5, right=1.5, top=3)\nplt.show()","b3a60f70":"label = train_df.target\nfeatures = [c for c in train_df.columns if c not in ['ID_code','target']]\n\nX_train, X_test, y_train, y_test = train_test_split(train_df[features], label, test_size = 0.02, random_state = 7)\nX_train1, y_train1 = X_train, y_train\nX_test1, y_test1 = X_test, y_test\n\nmodel1 = RandomForestClassifier(n_estimators = 50, random_state = 0).fit(X_train1, y_train1)\ny_pred = model1.predict(X_test1)","57586bc8":"from sklearn.metrics import accuracy_score,roc_curve, auc\naccuracy_score(y_test1, y_pred)","afa31564":"feature_importances = pd.DataFrame(model1.feature_importances_, index = X_train.columns, columns = ['importance'])\nfeature_importances = feature_importances.sort_values('importance' , ascending = False)\n#feature_importances.head()\n\ncolors = ['grey'] * 47 + ['green'] * 50\ntrace1 = go.Bar(x = feature_importances.importance[:97][::-1],\n               y = [x.title()+\"  \" for x in feature_importances.index[:97][::-1]],\n               name = 'feature importnace (relative)',\n               marker = dict(color = colors, opacity=0.4), orientation = 'h')\n\ndata = [trace1]\n\nlayout = go.Layout(\n    margin=dict(l=400), width = 1000, height = 1000,\n    xaxis=dict(range=(0.0,0.015)),\n    title='Feature Importance (Which Features are important to make predictions ?)',\n    barmode='group',\n    bargap=0.25\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","276c4a57":"submission = pd.read_csv('..\/input\/sample_submission.csv')\n#submission['target'] = model1.predict_proba(X_test1)[:,1]\n#submission.to_csv('submission_gnb.csv', index=False)","48988017":"## Business Goal:\n### Identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. ","38744c69":"#### Any missing values?","b9d2a6e9":"<img src=\"https:\/\/cached.imagescaler.hbpl.co.uk\/resize\/scaleWidth\/743\/cached.offlinehbpl.hbpl.co.uk\/news\/OMC\/35588D26-DA0A-7761-CEE8D2C3A142E700.JPG\" width=\"400px\"\/>","0cb63ef5":"### checking \/model performance or accuracy score.","46cf4631":"## Feature Enginnering and Prediction\n### Random forest classifier\nA random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.","6caaa261":"### Feature Importance","ab2f7603":"There is major imbalance in target values. ","47e28358":"We can further analys more important features","91be5dbd":"Accuracy score is nearly 90%, which is good. for further investigation we can check relative feature importance","e6b58884":"### variable distribution.","0f8270a8":"Feature enginnering plot reference kernel:  [Shivam Bansal](https:\/\/www.kaggle.com\/shivamb\/an-insightful-story-of-crowdfunding-projects) ","6cd1d94e":"### Data Preprocessing"}}