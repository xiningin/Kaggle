{"cell_type":{"0518d28a":"code","8ca624e1":"code","b8df6e88":"code","6e586982":"code","829ad802":"code","0a0aaef4":"code","9e0bfa51":"code","ee184a56":"code","b6a9d3e6":"code","9cb0ceb1":"code","940980c8":"code","b6d936fd":"code","527f56bb":"code","682cff3a":"code","997c14fa":"code","3372a162":"code","5f356c8d":"code","6ecd9c99":"code","97ae29c8":"code","45700745":"code","48485554":"code","3eef6959":"code","4705d96a":"code","34a68dcb":"code","585f95ce":"code","e1ac2689":"code","08a34cf1":"code","6babbc8a":"code","20028ac3":"code","92141d66":"code","d515c479":"code","e383cfaf":"code","cbe52def":"code","16534a6b":"code","f7cade7f":"code","5c5355f1":"code","0b143e0a":"code","1ebdcfbd":"code","d9fde801":"code","ff69c4a6":"code","e81a00cf":"code","691e6706":"code","7caeaf37":"code","834cbc81":"code","d560cae9":"code","8ed991ff":"code","1da337a9":"code","df348082":"code","ae7e2998":"code","a52531cf":"code","8155a444":"code","eeee9b2d":"markdown","82925771":"markdown","177f3b55":"markdown","2cf45f3a":"markdown","ed331d38":"markdown","a80fe400":"markdown","7656bae1":"markdown","24560795":"markdown","5cc3c41c":"markdown","b3400680":"markdown","b7359d44":"markdown","8bed4f00":"markdown","f4163651":"markdown","8ef57135":"markdown","ca0c8b26":"markdown","6eb4331c":"markdown","94a2ad4d":"markdown","511771c7":"markdown","2cfe6233":"markdown","6aa3e051":"markdown","0aa1ad25":"markdown","ca4d8eec":"markdown","dd022f40":"markdown","e279915b":"markdown","aa08a83e":"markdown","ff2dcf0b":"markdown","06999dad":"markdown","d1e60de1":"markdown","e9baba66":"markdown","e7cbcade":"markdown","b43998c1":"markdown","7ec97c1d":"markdown","eb795f43":"markdown","c296cc4f":"markdown","f96b1bb8":"markdown","9ea5d25a":"markdown","db6f192b":"markdown"},"source":{"0518d28a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom IPython.display import Image\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.getcwd())\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ca624e1":"\nhousehold_data = pd.read_csv('..\/input\/smart-meters-in-london\/informations_households.csv')","b8df6e88":"household_data.head()","6e586982":"Image('..\/input\/acornimage\/Acorn.png')","829ad802":"print(household_data.Acorn_grouped.unique())\nprint(household_data.stdorToU.unique())","0a0aaef4":"homedf = pd.read_csv('\/kaggle\/input\/smart-meters-in-london\/daily_dataset\/daily_dataset\/block_24.csv')\n","9e0bfa51":"print(homedf.shape)\nprint(homedf.describe())\nhomedf.head()\n","ee184a56":"print('First day = {}'.format(homedf.day.min()))\n\nprint('Last day = {}'.format(homedf.day.max()))\nhomedf['day'] = pd.to_datetime(homedf['day'])\nx_dates = homedf['day'].dt.strftime('%Y-%m-%d').sort_values().unique()\n# ax.set_xticklabels(labels=x_dates, rotation=45, ha='right')","b6a9d3e6":"freq = int(100) #change frequency of tick label\nhomedf.iloc[::freq].day.dt.date","9cb0ceb1":"\nfig, ax = plt.subplots(figsize = (12,12))\nsns.lineplot(ax = ax, x = 'day',y = 'energy_median',data = homedf)\nax.set_xticklabels(homedf.iloc[::freq].day.dt.date)\n","940980c8":"n=111 #Look at 10 blocks\nhouseblock = homedf\nfor block in range(n):\n    newblock = pd.read_csv('\/kaggle\/input\/smart-meters-in-london\/daily_dataset\/daily_dataset\/block_'+str(block)+'.csv')\n    houseblock = pd.concat([houseblock, newblock],axis =0)","b6d936fd":"houseblock.LCLid.nunique() #5550 unique homes","527f56bb":"home_joined = pd.merge(houseblock,household_data, on = 'LCLid',how='left')\n\nhome_joined.day = pd.to_datetime(home_joined.day)\nhome_joined.head()\n","682cff3a":"home_joined['stdorToU']","997c14fa":"sns.set(font_scale=1.2)  # crazy big\nsns.set_style('whitegrid')\n\ndef demographic_trends_facet_plot(trend1 = 'energy_mean', trend2 = 'energy_max'):\n    fig, ax = plt.subplots(2,2, figsize = (15,15))\n    fig.subplots_adjust(hspace = .5, wspace=0.2)\n\n    axs = ax.ravel()\n    i=0\n    for aggregate_function in [trend1,trend2]:\n        for energy_plan in ['ToU','Std']:\n            home_energyplan = home_joined[home_joined['stdorToU'] == energy_plan]\n            aggdata = home_energyplan.groupby('Acorn')[aggregate_function].agg('mean')\n            aggdata = aggdata.reset_index()\n            bp = sns.barplot(ax = axs[i],x = 'Acorn',y = aggregate_function,data =aggdata)\n            bp.set_xticklabels(bp.get_xticklabels(), \n                              rotation=45, \n                              horizontalalignment='right')\n            axs[i].set_title(energy_plan)\n            axs[i].set_xlabel('Acorn Group')\n            i+=1\n\n\ndemographic_trends_facet_plot()","3372a162":"aggdata = home_joined.groupby(['Acorn','stdorToU'])['energy_mean'].agg('mean').reset_index()\nfig,ax = plt.subplots(figsize = (12,12))\nsns.set(font_scale=1.5)  # crazy big\n\nbp = sns.barplot(ax = ax,x = 'Acorn',y = 'energy_mean',hue = 'stdorToU',data =aggdata)\nbp.set_xticklabels(bp.get_xticklabels(), \n      rotation=45, \n      horizontalalignment='right')","5f356c8d":"aggdata = aggdata[aggdata['Acorn'] != 'ACORN-']\nStd = aggdata.loc[aggdata['stdorToU'] == 'Std']\nToU = aggdata.loc[aggdata['stdorToU'] == 'ToU']\nprint(aggdata)\ndf = pd.merge(Std,ToU, on = 'Acorn', how = 'outer', suffixes = ('_Std','_ToU'))\ndf['consump_diff'] =  df.energy_mean_ToU - df.energy_mean_Std\nfig,ax =plt.subplots(figsize = (12,12))\nbp = sns.barplot(ax = ax, x = 'Acorn', y = 'consump_diff', data = df)\n                     \nbp.set_xticklabels(bp.get_xticklabels(), \n      rotation=45, \n      horizontalalignment='right')\nax.set_title('Change in Consuption after Change in Subscription from Std to ToU')","6ecd9c99":"Image('..\/input\/acornimage\/Acorn.png',width= 700, height=700)","97ae29c8":"tempforecast = pd.read_csv('..\/input\/smart-meters-in-london\/weather_hourly_darksky.csv')\nprint(tempforecast.shape)\ntempforecast.head()\ntempforecast.time = pd.to_datetime(tempforecast.time)","45700745":"tempforecast.groupby([tempforecast['time'].dt.year]).count()['visibility'].plot(kind=\"bar\")\n","48485554":"years = [2012,2013]\ntempforecast = tempforecast.loc[tempforecast.time.dt.year.isin(years)]","3eef6959":"fig, ax = plt.subplots(1, 2, figsize = (15,8))\ntempforecast.loc[tempforecast.time.dt.year == 2012].groupby([tempforecast['time'].dt.hour])['visibility'].count().plot(ax = ax[0],kind='bar')\ntempforecast.loc[tempforecast.time.dt.year == 2013].groupby([tempforecast['time'].dt.hour])['visibility'].count().plot(ax = ax[1],kind = 'kde')\n\n","4705d96a":"home_joined.head()","34a68dcb":"n_homes =5550  # Number of unique homes in the dataset\n\n(home_joined.groupby([home_joined['day'].dt.year]).count()\/n_homes)['energy_mean'].plot(kind=\"bar\")\n","585f95ce":"tempforecast = tempforecast.loc[tempforecast.time.dt.year == 2013]\nhome_joined = home_joined.loc[home_joined.day.dt.year == 2013]\ntempforecast.head()","e1ac2689":"numerical = tempforecast.columns.drop(['time','icon','precipType','summary'])\ncategorical = ['icon','summary','precipType']\n\nfig,ax = plt.subplots(2,4,figsize = (25,18))\naxs = ax.ravel()\n\nfor i, feature in enumerate(numerical):\n    tempforecast.plot('time',feature, ax=axs[i])\n    axs[i].set_ylabel(feature)","08a34cf1":"fig,ax = plt.subplots(2,4,figsize = (25,18))\naxs = ax.ravel()\n\nfor i, feature in enumerate(numerical):\n    tempforecast.groupby(tempforecast['time'].dt.dayofyear).mean().reset_index().plot('time',feature, ax=axs[i])\n    axs[i].set_ylabel(feature)\n    axs[i].set_xlabel('Day of Year')\nplt.title('Average Hourly Variability of Predicted Variables')","6babbc8a":"fig,ax = plt.subplots(1,3,figsize = (20,9))\nfor i,feature in enumerate(categorical):\n    tempforecast.groupby(tempforecast[feature])[feature].count().plot(kind = 'bar', ax = ax[i])","20028ac3":"fig, ax = plt.subplots(figsize = (12,12))\nsns.heatmap(tempforecast.corr(), annot = True, ax = ax)","92141d66":"tempforecast = tempforecast.drop(['apparentTemperature'],axis=1)","d515c479":"tempforecast_daily_categorical = tempforecast[categorical+['time']].groupby(tempforecast['time'].dt.dayofyear).agg(lambda x:x.value_counts().index[0])\nfig,ax = plt.subplots(1,3,figsize = (20,9))\nfor i,feature in enumerate(categorical):\n    tempforecast_daily_categorical.groupby(tempforecast_daily_categorical[feature])[feature].count().plot(kind = 'bar', ax = ax[i])","e383cfaf":"tempforecast_daily = tempforecast.groupby(tempforecast['time'].dt.dayofyear).mean()\ntempforecast_daily = tempforecast_daily.join(tempforecast_daily_categorical).drop('time',axis=1)\ntempforecast_daily.head()\ntempforecast_daily=tempforecast_daily.reset_index().rename({'time':'dayno'},axis=1)\n","cbe52def":"pd.set_option('display.max_columns', None)\nprint('Shape before Join = {}'.format(home_joined.shape))\nhome_joined['dayno'] = home_joined.day.dt.dayofyear\ndf = home_joined.merge(tempforecast_daily, how = 'left', on = 'dayno')\nprint('Shape after Join = {}'.format(df.shape))\ndf.head()","16534a6b":"fig, ax = plt.subplots(figsize= (12,12))\nbp = df.groupby(['Acorn_grouped','Acorn']).count()['LCLid'].plot(ax=ax,kind = 'bar')\nbp.set_xticklabels(bp.get_xticklabels(), \n      rotation=45, \n      horizontalalignment='right')","f7cade7f":"df = df[~df['Acorn'].isin(['ACORN-','ACORN-U'])]","5c5355f1":"fig,ax = plt.subplots(figsize = (14,14))\nsns.lineplot(x= 'temperature', y = 'energy_mean', hue = 'stdorToU', data = df, ax = ax)","0b143e0a":"fig,ax = plt.subplots(figsize = (14,14))\nsns.lineplot(x= 'temperature', y = 'energy_mean', hue = 'Acorn_grouped', data = df, ax = ax)","1ebdcfbd":"fig,ax = plt.subplots(figsize = (20,20))\nsns.heatmap(df.corr(),ax =ax, annot=True)","d9fde801":"from sklearn.feature_selection import RFE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import set_config\n","ff69c4a6":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","e81a00cf":"df1 = df[df.isna().any(axis=1)]\n(df1['energy_max']-df1['energy_min']).sum()\n","691e6706":"df.loc[df['energy_std'].isna(),'energy_std']=0","7caeaf37":"df= df.dropna()","834cbc81":"df.head()","d560cae9":"y = df.energy_mean\npredictor_cols = ['temperature']\nX = df[predictor_cols]\n","8ed991ff":"X = sm.add_constant(X)\nmodel = sm.OLS(y,X)\nresults = model.fit()\nprint(results.summary())\nprint('Mean Squared Error = {:.2f}'.format(results.mse_model))","1da337a9":"dfsmall = df.sample(frac=0.01)\npredictor_cols = ['dayno','visibility','windBearing','temperature','dewPoint','pressure','windSpeed','humidity','stdorToU','Acorn','summary','precipType']\n\nX = dfsmall[predictor_cols]\ny = dfsmall['energy_mean']\n\n\nnumerical_features = ['dayno','visibility','windBearing','temperature','dewPoint','pressure','windSpeed','humidity']\ncategorical_features = ['stdorToU','summary','precipType']\nordinal_features = ['Acorn'] \n","df348082":"def build_pipeline(numerical_features, categorical_features, ordinal_features):\n    numeric_transformer = Pipeline(steps=[\n        ('scaler', StandardScaler())])\n\n    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n    ordinal_transformer = OrdinalEncoder()\n\n    preprocessor = ColumnTransformer( # Transform respective columns using column transformer\n        transformers=[\n            ('num', numeric_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features),\n            ('ord', ordinal_transformer, ordinal_features)\n        ])\n\n    rfe = RFE(estimator=RandomForestRegressor(), n_features_to_select=4)\n\n\n    regressorpipe = Pipeline(steps=[('preprocessor', preprocessor), ('feature_selection', rfe),\n                          ('regressor', RandomForestRegressor())])\n    return rfe, regressorpipe\n\nrfe, regressor = build_pipeline(numerical_features, categorical_features, ordinal_features)\n\nX_new = regressor.fit(X, y)\n\n","ae7e2998":"def visualization_plot(RFE):\n    columns = numerical_features +list(X['stdorToU'].unique()) +list(X['summary'].unique())+list(X['precipType'].unique()) +['Acorn']\n    fig, ax = plt.subplots(figsize = (12,12))\n    x = np.arange(len(columns))  # the label locations\n    ax.barh(x, RFE.ranking_)\n    ax.set_yticks(x)\n    ax.set_yticklabels(columns)\n#     plt.xticks(rotation=90)\n    ax.set_title('Ranking of Feature Importance (1 = highest, 18 = lowest)')\n\nvisualization_plot(rfe)","a52531cf":"regressor.score(X_test,y_test)","8155a444":"# Reselect features and train model\nnumerical_features = ['dayno','visibility','temperature','pressure']\ncategorical_features = ['stdorToU','precipType']\nordinal_features = ['Acorn'] \nrfe, pipeline = build_pipeline(numerical_features, categorical_features, ordinal_features)\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state=42)\n\npipeline.fit(X_train, y_train)\nprint('Model Score After Feature Removal = {}'.format(pipeline.score(X_test,y_test)))","eeee9b2d":"Now we have to explore the forecast variables and see how best we can aggregrate these variables to predict consumption. The forecast variables are provided hourly, so they have to be aggreagated over a 24 hour period. For some variables, aggregating by the mean daily values loses a significant amount of information and makes the variable useless in analysis","82925771":"Those on the standard subscription always consume more than those on the ToU subscription. And energy consumption levels drop significantly with temperature. There is also a clear cut-off, past which the energy consu,ption tails off.\nHow does this trend vary with Acorn group?\n1. ","177f3b55":"Energy consumption certainly increases for those using the Time of Use plan, there is also a trend of energy consumption increasing with Acorn group. Looking at mean consumption on a single chart\n","2cf45f3a":"What do each of these acorn groups represent in terms of Acorn_i? What is Acorn-U? Can we rmove it?\n","ed331d38":"# Forecasting Model Iteration","a80fe400":"We remove 2011, 2014 and 2012 from our daataset as they have insuffieicnt number of days on average","7656bae1":"Some predictors have more daily variability than seasonal variability such as windbearing and visibility ","24560795":"Primary analysis of consumption vs. temperature\n\n","5cc3c41c":"For which groups does changing the plan have the most and the least effect??","b3400680":"There are clearlt seasonal variations, winter consumption is higher than summer consumption, it is also interesting to note the rapid decrease in consumption at the beginning of the program.\nLets look at variation in energy consumption depending on the income of the house\n","b7359d44":"# Joining data sets and forecasting consumption","8bed4f00":"The energy units are given KWh. We review basic trends:\n","f4163651":"Joining temperature forecast and house data, when aggregating, the categorical variables are lost, to include them in the daily values we will take the most common category in each day","8ef57135":"The Acorn user group classifies the UK demographics into different demographic types ranging from Adversity groups to Affluent. The second column details what type of payment scheme the household was put on, with Std being a flat rate for energy cost, and ToU a Time of Use scheme, where customers are told at what time they will pay what price","ca0c8b26":"All the people in a single block of units where on the standard rate and are from the same acorn group, lets merge a few blocks together to see if we can analyse the variation by joining a few blocks together","6eb4331c":"Data cleaning","94a2ad4d":"# Pipeline & Feature Selection","511771c7":"The RFE selects the temperature, and the ACORN group as the most important features in determining the mean_consumption","2cfe6233":"What other factors may affect the consumption?","6aa3e051":"# Checking distribution of time data","0aa1ad25":"Import sklearn regression models","ca4d8eec":"First analyse the distribution of time data to see how well distributed the time data is. Since our home_joined dataset uses daily data, we want to know how complete the weather distribution is for daily data","dd022f40":"Start with linear regression from statsmodels api, for our benchmark model we will predict energy consumption based solely on temperature","e279915b":"# Analysing trends in forecast variables throughout the year","aa08a83e":"2011 and 2014 are lacking in sufficient daily data, so they will be excluded from this analysis","ff2dcf0b":"This base model doesn't perform very well as can be seen we will need to introduce the other variables and perform categorical encoding on the weather features as well as ordinal encoding on the acorn group","06999dad":"To test how well this aggregate function applied on the categorical data performs, we can compare the barplots with the previous barplots and see if the proportions remain the same","d1e60de1":"They are pretty similar, with the exception of the removal of some categories which never featured as the most common in any day","e9baba66":"For most demographics, the consumption drops when switching subscription, presumably as the user becomes more conscious about there energy consumption, there are noticable outliers however such as those with executive wealth","e7cbcade":"Import useful sklearn modules for feature preprocessing and selection","b43998c1":"We can drop the remaining NaN values of which there are only 7","7ec97c1d":"# Forecasting","eb795f43":"The goal is to select the most important features in related to energy consumption and to build a predictive model. We first use RFE to determine the most important features and reduce our model","c296cc4f":"the std. deviation column gives a lot of NaN values, these occur when the minimum energy = max energy, we can therefore replace these with 0","f96b1bb8":"Begin by taking an overview of the houses dat stored in information_hoseholds","9ea5d25a":"We review different trends in energy consumption depending on whether one uses the Standard plan or the Time of Use plan","db6f192b":"We can get ris of apparentTemperature as it is highly correlated with the temperature and provides no new information"}}