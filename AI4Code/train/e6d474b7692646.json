{"cell_type":{"19c54a5f":"code","b133b4db":"code","81c563a2":"code","f0e393e8":"code","7a5c191d":"code","f2394922":"code","441325d1":"code","b09a97c0":"code","695a62b1":"code","6c47345d":"code","f2ded858":"code","b25e9f3b":"code","752bbd1d":"markdown","56cbced3":"markdown","c8144cb5":"markdown","df77b814":"markdown","a002f9ca":"markdown","59f73bba":"markdown","24ccc51b":"markdown"},"source":{"19c54a5f":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","b133b4db":"df = pd.read_csv(\"..\/input\/heart.csv\")\ndf.info()","81c563a2":"a = pd.get_dummies(df['cp'], prefix = \"cp\")\nb = pd.get_dummies(df['thal'], prefix = \"thal\")\nc = pd.get_dummies(df['restecg'], prefix = 'restecg')\nd = pd.get_dummies(df['slope'], prefix = \"slope\")\nframes = [df, a, b, c, d]\ndf = pd.concat(frames, axis = 1)\ndf = df.drop(columns = ['cp', 'thal','restecg', 'slope'])\ndf.head()","f0e393e8":"y = df.target.values\nX = df.drop(['target'], axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","7a5c191d":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","f2394922":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","441325d1":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu', input_dim = 23))\n# classifier.add(Dropout(p = 0.1))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu'))\n# classifier.add(Dropout(p = 0.1))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100)","b09a97c0":"# # Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","695a62b1":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred.round())\nsns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n#accuracy score\nfrom sklearn.metrics import accuracy_score\nac=accuracy_score(y_test, y_pred.round())\nprint('accuracy of the model: ',ac)","6c47345d":"# Evaluating the ANN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef build_classifier():\n    classifier = Sequential()\n    classifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu', input_dim = 23))\n    classifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\nmean = accuracies.mean()\nvariance = accuracies.std()\nprint('Accuracies are', accuracies,'\\n', 'Mean is', mean, '\\n', 'Variance is', variance)","f2ded858":"# Tuning the ANN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef build_classifier(optimizer):\n    classifier = Sequential()\n    classifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu', input_dim = 23))\n    classifier.add(Dense(units = 11, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier)\nparameters = {'batch_size': [25, 32],\n              'epochs': [100, 200],\n              'optimizer': ['adam', 'rmsprop']}\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10)\ngrid_search = grid_search.fit(X_train, y_train)\nbest_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_","b25e9f3b":"print(best_parameters)\nprint(best_accuracy)","752bbd1d":"#### Improving the ANN","56cbced3":"#### Evaluating, Improving and Tuning the ANN","c8144cb5":"#### ANN","df77b814":"#### Dataset contains 14 columns (1 target) and 303 instances(rows). No missing values. But 'cp', 'thal', 'restecg'and 'slope' are categorical variables need to turn them into dummy variables.\n","a002f9ca":"#### Feature scaling","59f73bba":"#### Set training and testing data","24ccc51b":"#### In this project I'm going to use ANN to do the predication. "}}