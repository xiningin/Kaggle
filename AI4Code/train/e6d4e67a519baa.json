{"cell_type":{"bae0ef36":"code","81aa4ae7":"code","637d613c":"code","57c73546":"code","3d1f30c4":"code","f4830b2a":"code","3bacc40b":"code","f6cb136b":"code","03b50147":"code","6dd08f04":"code","7198089d":"code","dd94cf17":"code","4dbd392f":"code","7584f8d8":"code","f3f0f292":"code","1cbb6e12":"code","20d6ad89":"code","40b0ae69":"markdown","f730a49b":"markdown","fec623c4":"markdown","21e564bd":"markdown","df8a9458":"markdown","da9a7d9b":"markdown"},"source":{"bae0ef36":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81aa4ae7":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport collections \nfrom sklearn.preprocessing import MinMaxScaler\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nimport warnings\nfrom textblob import TextBlob \nfrom sklearn.ensemble import RandomForestClassifier\nimport folium\nwarnings.filterwarnings(\"ignore\")\n\nHotels = pd.read_csv(\"\/kaggle\/input\/515k-hotel-reviews-data-in-europe\/Hotel_Reviews.csv\")\n\nUniq_ = Hotels.sort_values('Hotel_Name', ascending=False)\nUniq_hotels = Uniq_.drop_duplicates(subset='Hotel_Address', keep='first')\nhotels = Uniq_.drop([\"Review_Date\",\"days_since_review\",\"lat\",\"lng\",\"Tags\",\"Total_Number_of_Reviews_Reviewer_Has_Given\",\"Positive_Review\",\"Negative_Review\",\"Reviewer_Score\"], axis=1)\n \nnationality_counter = collections.Counter(Hotels[\"Reviewer_Nationality\"].tolist())\nhotel_counter = collections.Counter(Hotels[\"Hotel_Name\"].tolist())\n\nUniq_hotels.tail()\nuniq_hotels = Uniq_hotels.drop([\"Review_Date\",\"Reviewer_Nationality\",\"Negative_Review\",\"Review_Total_Negative_Word_Counts\",\"Positive_Review\",\"Review_Total_Positive_Word_Counts\",\"Total_Number_of_Reviews_Reviewer_Has_Given\",\"Reviewer_Score\",\"Tags\",\"days_since_review\",\"lat\",\"lng\"],axis=1)\n\nhoteladdress = uniq_hotels[\"Hotel_Address\"]\n\nuniq_hotels_lat = Uniq_hotels[\"lat\"]\nuniq_hotels_lng = Uniq_hotels[\"lng\"]\n\nHotel_num = []\n\nfor c in hoteladdress:\n    if \"United Kingdom\" in c:\n        Hotel_num.append(0)\n    elif \"France\" in c:\n        Hotel_num.append(1)\n    elif \"Italy\" in c:\n        Hotel_num.append(2)\n    elif \"Spain\" in c:\n        Hotel_num.append(3)\n    elif \"Austria\" in c:\n        Hotel_num.append(4)\n    elif \"Netherlands\" in c:\n        Hotel_num.append(5)\n        \nuniq_hotels[\"hotel_loc\"] = Hotel_num\n","637d613c":"hotel_add = hotels[\"Hotel_Address\"].unique()\n\nneg_rev_avg_words = []\npos_rev_avg_words = []\n\nfor i in range(len(hotel_add)):\n    \n    neg_rev_avg_words.append(sum(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Negative_Word_Counts\"])\/len(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Negative_Word_Counts\"]))\n    pos_rev_avg_words.append(sum(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Positive_Word_Counts\"])\/len(hotels[hotels.Hotel_Address == hotel_add[i]][\"Review_Total_Positive_Word_Counts\"]))\n\nuniq_hotels[\"positive_review_average_word_count\"] = pos_rev_avg_words\nuniq_hotels[\"negative_review_average_word_count\"] = neg_rev_avg_words  \n\nuniq_hotels.drop(['Hotel_Address'],axis=1, inplace=True)\n","57c73546":"total_reviews = uniq_hotels['Total_Number_of_Reviews']\nadditional_scoring = uniq_hotels['Additional_Number_of_Scoring']\naverage_score = uniq_hotels['Average_Score']\npos_rev_avg_word_count = uniq_hotels[\"positive_review_average_word_count\"]\nneg_rev_avg_word_count = uniq_hotels[\"negative_review_average_word_count\"]\n\ntotal_reviews = total_reviews.values.astype(float)\nadditional_scoring = additional_scoring.values.astype(float)\naverage_score = average_score.values.astype(float)\npos_rev_avg_word_count = pos_rev_avg_word_count.values.astype(float)\nneg_rev_avg_word_count = neg_rev_avg_word_count.values.astype(float)\n\ntotal_reviews = total_reviews .reshape(-1, 1)\nadditional_scoring = additional_scoring.reshape(-1,1)\naverage_score = average_score.reshape(-1,1)\npos_rev_avg_word_count = pos_rev_avg_word_count.reshape(-1,1)\nneg_rev_avg_word_count = neg_rev_avg_word_count.reshape(-1,1)","3d1f30c4":"min_max_scaler = MinMaxScaler()\n\nuniq_hotels[\"total_reviews\"] = min_max_scaler.fit_transform(total_reviews)\nuniq_hotels[\"additional_scoring\"] = min_max_scaler.fit_transform(additional_scoring)\nuniq_hotels[\"average_score\"] = min_max_scaler.fit_transform(average_score)\nuniq_hotels[\"pos_rev_avg_word_count\"] = min_max_scaler.fit_transform(pos_rev_avg_word_count)\nuniq_hotels[\"neg_rev_avg_word_count\"] = min_max_scaler.fit_transform(neg_rev_avg_word_count)\n\nuniq_hotels.drop(['Additional_Number_of_Scoring','Total_Number_of_Reviews','Average_Score'], axis=1, inplace = True)\nuniq_hotels.tail()\n","f4830b2a":"# Comparing how Additional and Average scoring compares to the number of reviews\nt = uniq_hotels[\"total_reviews\"]\ny = uniq_hotels[\"average_score\"]\n\nplt.scatter(y, t, c='purple')\nplt.xlabel('Scoring')\nplt.ylabel('Number of Reviews')\nplt.show()","3bacc40b":"# Comparing how Additional and Average scoring compares to the number of positive reviews\n\nt = uniq_hotels[\"pos_rev_avg_word_count\"]\ny = uniq_hotels[\"average_score\"]\n\nplt.scatter(t, y, c='purple')\nplt.xlabel('Positive review word count')\nplt.ylabel('Score')\nplt.show()","f6cb136b":"# Comparing how Additional and Average scoring compares to the number of negative reviews\n\nt = uniq_hotels[\"neg_rev_avg_word_count\"]\ny = uniq_hotels[\"average_score\"]\n\nplt.scatter(t, y, c='purple')\nplt.xlabel('Negative review word count')\nplt.ylabel('Score')\nplt.show()","03b50147":"top_hotels = dict(hotel_counter.most_common(5))\n\nobjects_hotels = list(top_hotels.keys())\nperformance_hotels = top_hotels.values()\n\nplt.barh(objects_hotels, performance_hotels, alpha=1)\nplt.xlabel(\"Number of reviews\")\nplt.show()","6dd08f04":"top_nationalities = dict(nationality_counter.most_common(5))\n\nobjects_nationalities = list(top_nationalities.keys())\nperformance_nationalities = top_nationalities.values()\n\nplt.barh(objects_nationalities, performance_nationalities, alpha=1)\nplt.xlabel(\"Number of reviews\")\nplt.show()","7198089d":"\nfrom sklearn.cluster import KMeans\n\n# f1 = Hotels_['neg'].values\n# f2 = Hotels_['pos'].values\n# f3 = Hotels_['Total_revs'].values \n# f4 = Hotels_['Add_sc'].values\n# f5 = Hotels_['Av_sc'].values\n\narray = uniq_hotels.drop([\"Hotel_Name\",\"additional_scoring\", \"pos_rev_avg_word_count\",\"neg_rev_avg_word_count\",\"hotel_loc\"],axis=1)\nX = array.to_numpy()\n\nkmeans = KMeans(n_clusters=3).fit(X)\n\nlabels = kmeans.predict(X)\n\nC = kmeans.cluster_centers_\n\nprint(C)\nprint(array.columns)\n","dd94cf17":"fig = plt.figure()\nax = Axes3D(fig)\nax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y)\nax.scatter(C[:, 0], C[:, 1], C[:, 2],)\n","4dbd392f":"import folium\n\nEurope_coordinates = (54.5260, 15.2551)\n\nUniq_hotels=Uniq_hotels.dropna(subset=['lng'])\nUniq_hotels=Uniq_hotels.dropna(subset=['lat'])\n\n\nlat = list(Uniq_hotels[\"lat\"])\nlong = list(Uniq_hotels[\"lng\"])\nhotel_name = list(Uniq_hotels[\"Hotel_Name\"])\naverage_score = list(Uniq_hotels[\"Average_Score\"])\n    \ndef color(score): \n    for i in average_score:\n        if score >= 9:\n            col = \"green\"\n        elif score < 9 and score > 7:\n            col = \"orange\"\n        elif score < 7 and score > 4.8:\n            col = \"red\"\n        else:\n            col = \"black\"\n    return col\n\n\nhotel_map = folium.Map(location=Europe_coordinates, zoom_start=4)\n\nfor lt, ln, name, score in zip(lat, long, hotel_name, average_score):\n    folium.Marker(location=[lt, ln], popup=str(name), icon= folium.Icon(color=color(score))).add_to(hotel_map)\n\n\n\nhotel_map","7584f8d8":"from sklearn.model_selection import train_test_split\nX = uniq_hotels.drop([\"Hotel_Name\", \"hotel_loc\", 'positive_review_average_word_count', 'negative_review_average_word_count'], axis=1)\ny = uniq_hotels[\"hotel_loc\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","f3f0f292":"# Logistic Regression\n\nlogreg = LogisticRegression()\nparam_grid = {'C':np.arange(0.01,100,10)}\ngrid = GridSearchCV(logreg,param_grid)\ngrid.fit(X_train,y_train)\n\nlogR = grid.best_estimator_\nlogR.fit(X_train,y_train)\n\ny_predicts = logR.predict(X_test)\n\nprint(classification_report(y_test, y_predicts))","1cbb6e12":"df = pd.read_csv(\"Hotel_Reviews.csv\")\n\nreviewer_score = df[\"Reviewer_Score\"]\nnegative_review = df[\"Negative_Review\"]\npositive_review = df[\"Positive_Review\"]\n\nreviewer_score_label = pd.qcut(reviewer_score, 2, labels = False)\nnegative_review_polarity = []\nnegative_review_subjectivity = []\npositive_review_polarity = []\npositive_review_subjectivity = []\n\nfor i in range(len(negative_review)):\n    term_1 = TextBlob(negative_review[i]).sentiment\n    term_2 = TextBlob(positive_review[i]).sentiment\n    \n    negative_review_polarity.append(term_1[0])\n    negative_review_subjectivity.append(term_1[1])\n    positive_review_polarity.append(term_2[0])\n    positive_review_subjectivity.append(term_2[1])\n    \n \nX = df[['Review_Total_Negative_Word_Counts', 'Total_Number_of_Reviews', 'Review_Total_Positive_Word_Counts', 'Total_Number_of_Reviews_Reviewer_Has_Given']]\n\nX['negative_review_polarity'] = negative_review_polarity\nX['negative_review_subjectivity'] = negative_review_subjectivity\nX['positive_review_polarity'] = positive_review_polarity\nX['positive_review_subjectivity'] = positive_review_subjectivity \n\ny = pd.qcut(reviewer_score, 2, labels = False)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\ntree = RandomForestClassifier(random_state=0)\ntree.fit(X_train, y_train)\n\ny_pred = tree.predict(X_test)\nprint(classification_report(y_pred, y_test))\n\nfeature_imp = pd.Series(tree.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(feature_imp)\n","20d6ad89":"\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\ny_pred = tree.predict(X_test)\nprint(classification_report(y_pred, y_test))\n","40b0ae69":"## 3. Analysis","f730a49b":"## 2. Data visualisation","fec623c4":"## 1. Data preprocessing","21e564bd":"# Decoding hotel success","df8a9458":"This is a project to show how you can work with very large datasets and glean business insighta from them in a quick and easy way.","da9a7d9b":"#### There are two datasets. Both are storted by Hotel Name alphabetically. \n#### One is called hotels and it has all of the 515738 entries.\n#### The second is called uniq_hotels and it contains 1493 entries and only has unique Hotel names and corresponding addresses, average score, total reviews and additional score."}}