{"cell_type":{"cc360e66":"code","cb840dc0":"code","76ff9e68":"code","af506da6":"code","a1ea6770":"code","5cf88409":"code","10fc56f5":"code","1ea14249":"code","95ad61c9":"code","a374638e":"code","ceff7209":"code","6521883c":"code","adf787da":"code","0892edcf":"code","ad8c975e":"code","65078200":"code","16ae00f6":"code","f69ad8dc":"code","d682a719":"code","80591388":"code","5d353853":"code","3601883f":"code","48fd6d98":"code","76106f53":"code","70758276":"code","8c73638d":"code","11e94d5f":"code","07c0c4d0":"code","0a19fae7":"code","9f864695":"code","44c6679b":"code","e934ea26":"code","aa9d7980":"code","e6402e2f":"code","7834e7f8":"code","7eac2ecf":"code","130bd347":"code","eb34e54f":"code","78d43e0b":"code","9dcb5f12":"code","f61fc43e":"code","a5fc177b":"code","6096b246":"code","3490ecd4":"code","094f5642":"code","afaa4cb6":"code","7fe1d50c":"code","6fc39adc":"code","f95b7909":"code","17f589ca":"code","6ec784ea":"code","e509837e":"code","dfb8b562":"code","b3f7afb0":"code","ed453a2e":"code","19ce3119":"code","411c2bc8":"code","be4222bd":"code","c8eee1db":"code","2036c4c9":"code","6c472e19":"code","81827ee6":"code","0d115d71":"code","10567249":"code","bd16f759":"code","424b4c22":"code","56068c70":"code","54eb8372":"code","5cb96a43":"code","3b744d9e":"code","1240364e":"code","13d00d57":"code","fae48b0e":"code","0a0ee568":"code","7556f596":"code","7d72561e":"code","fda41e11":"code","d3ca4da5":"code","836776cf":"code","e4f7e60c":"code","892fa3c2":"code","af07af3a":"code","9caa9409":"code","9bbf9ca7":"code","f89b40bc":"code","0ed4b0ff":"code","e1417570":"code","ed68ae19":"code","256f627f":"code","53759979":"code","0134812a":"code","eadfe646":"code","1306804c":"code","94d73cf6":"code","10941130":"code","3d6826e1":"code","990dc9b0":"code","d1f15d34":"code","3560282b":"code","26c1813e":"code","0d66e6e0":"code","38ca95a0":"code","870b5ecc":"code","059b4737":"code","f4ecee33":"code","a1a86f3f":"code","d83efbaf":"code","5f7040d7":"code","3c8e7770":"code","5ff79238":"code","585e9d72":"code","25b8d5e5":"code","848251e2":"code","85d1c32f":"code","4b48504c":"code","d55afa2b":"code","666ef926":"code","ef82336b":"code","90c58db4":"code","f070c9ff":"code","ca1d6374":"code","409971a7":"code","bfd012fb":"code","c228634c":"markdown","e46f7143":"markdown","319c3ca5":"markdown","199b1c95":"markdown","73be03bf":"markdown","bfcd629e":"markdown","786b9067":"markdown","92d7cb1c":"markdown","a703e131":"markdown","e5011293":"markdown","77e780ec":"markdown","c015ea3e":"markdown","4dece358":"markdown"},"source":{"cc360e66":"# Importing Libraries\n\nimport os\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model, ensemble, tree\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,cross_validate\nfrom sklearn.metrics import confusion_matrix, auc,roc_auc_score,roc_curve,recall_score,classification_report\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_rows', 100, 'display.max_columns', 400)","cb840dc0":"# Function to Load the file at specified path\n# Parameters :- 1. path :- path from where file should be I\n\ndef Load_File(path) :\n    if os.path.isfile(path) :\n        data = pd.read_csv(path)\n        data = data.replace('?', np.nan)\n        print(\"\\n\" + \"Number of rows in data are %s\" % len(data))\n        print(\"Number of columns in data are %s\" % len(data.columns) + \"\\n\")\n        print(\"Following are the data types of columns:- \")\n        print(data.dtypes)\n        print(\"Number of missing values in the data are:- \")\n        print(data.isnull().sum())\n        print(\"Data Import is Complete\")\n        \n        return data\n    else:\n        print(path + \" does not exist. Enter the correct path\")\n        \n\n# Generalized Function to plot the counts\n# Parameters\n# 1. rotx  : rotation of ticks on x-axis\n# 2. roty  : rotation of ticks on y-axis\n# 3. fontx : font size of ticks on x-axis\n# 4. fonty : font size of ticks on y-axis\n# 5. column_name : Name of the column for which we need the count\n# 6. data_name   : Dataframe Used for plotting\n# 7. plot_size   : Size of the plot\n# 8. hue : If second column is needed for getting the count, the hue is True else False\n# 9. hue_column_name = Second Column for plotting\n\n\ndef countplot(rotx, roty, fontx, fonty, column_name, data_name, plot_size = (10, 5), hue = False, hue_column_name=None):\n    plt.figure(figsize = plot_size)\n    plt.xticks(rotation=rotx, fontsize=fontx)\n    plt.yticks(rotation=roty, fontsize=fonty)\n    sns.set_style(\"whitegrid\")\n    if not hue:\n        sns.countplot(column_name, data=data_name, palette='husl',\n                      order = data_name[column_name].value_counts().index)\n    else:\n        sns.countplot(column_name, data=data_name, \n                      palette='husl', hue = hue_column_name,\n                      order = data_name[column_name].value_counts().index)\n    sns.despine()\n\n\n# Function to Encode the Categorical Data Columns\n# Parameters 1. df :- Dataframe 2. Column_name :- Feature to encode\n\ndef categorical_encoding(df, column_name_list=[]):\n    \n    for column_name in column_name_list:\n        print(df[column_name].unique())\n        categorical_columns = pd.get_dummies(df[column_name], prefix = column_name, \n                                             prefix_sep = '_', drop_first = False)\n        df = pd.concat([df, categorical_columns], axis = 1)\n        df = df.drop(column_name, axis = 1)\n    return df\n\n\n# Function to Label Encode the data\n# Parameters :- 1. data :- Dataframe 2. columns_list :- List of columns to label encode\n\ndef labelEncoder(data, columns_list):\n    for col in columns_list:\n        encoder = LabelEncoder()\n        data[col]  = encoder.fit_transform(data[col])\n    return data\n\n\n# Function to plot stacked plot\n# Paramteres :- \n# data :- Dataframe used for plotting\n# column_one :- Column One to group by\n# column_two : Column Two to group by\n# agg_column : Column to count numbers\n\ndef stacked_plot(data, column_one, column_two, agg_column, plot_size=(10, 5)):\n    pal     = sns.color_palette(\"colorblind\")\n    grouped = data.groupby([column_one, column_two])[agg_column].count()\n    grouped = grouped.groupby(level=0).apply(lambda x:100 * x \/ float(x.sum()))\n    grouped = grouped.unstack(column_two).fillna(0)\n    print(grouped)\n    unique_list = list(data[column_two].unique())\n    grouped[unique_list].plot(kind='bar', stacked=True, color=pal, figsize=plot_size)","76ff9e68":"\"\"\"LOADING ASSESSMENTS DATA\"\"\"\n\n# code_module          identification code of the module, to which the assessment belongs\n# code_presentation    identification code of the presentation, to which the assessment belongs\n# id_assessment        identification number of the assessment\n# assessment_type      type of assessment\n# date                 days information about the final submission date of the assessment calculated as the number of days \n#                      since the start of the module-presentation. The starting date of the presentation has number 0 (zero)\n# weight               weight of the assessment in %. Typically, Exams are treated separately and have the weight 100%\n#                      the sum of all other assessments is 100%\n\noulad_assessment = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/assessments.csv')","af506da6":"oulad_assessment.head()","a1ea6770":"### Filling in the missing values with the mean of the number of days.\n\noulad_assessment['date'] = oulad_assessment['date'].fillna(int(oulad_assessment['date'].astype(float).mean()))","5cf88409":"### There are 7 types of code_module\n\noulad_assessment['code_module'].unique()","10fc56f5":"### There are 3 types of Assessment\n# TMA :- Tutor Marked Assessment\n# CMA :- Computer Marked Assessment\n# Exam :- Final Exam\n\noulad_assessment['assessment_type'].unique()","1ea14249":"### Below histogram shows us the range of for the number for days for final submission.\n\nplt.hist(oulad_assessment['date'].astype(int), bins=7)","95ad61c9":"\"\"\"Loading Courses Data\"\"\"\n\n# code_module         name of the module, which serves as the identifier\n# code_presentation   name of the presentation. It consists of the year and B for the presentation \n#                     starting in February and J for the presentation starting in October\n# length              length of the module presentation in days\n\noulad_courses = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/courses.csv')","a374638e":"oulad_courses.head()","ceff7209":"\"\"\"Loading Student Assessment Data\"\"\"\n\n# id_assessment            the identification number of the assessment\n# id_student               a unique identification number for the student\n# date_submitted           the date of student submission, measured as the number of days \n#.                         since the start of the module presentation\n# is_banked                a status flag indicating that the assessment result has been transferred from a previous presentation\n# score                    the student\u00eds score in this assessment. The range is from 0 to 100. The score lower than 40 is \n#                          interpreted as Fail. The marks are in the range from 0 to 100\n\noulad_student_assessment = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/studentAssessment.csv')","6521883c":"### As the number of missing values are very less as compared to the total data\n\noulad_student_assessment = oulad_student_assessment.dropna()","adf787da":"oulad_student_assessment.head()","0892edcf":"\"\"\"Loading Student Registration Data\"\"\"\n\n# code_module             an identification code for a module\n# code_presentation       the identification code of the presentation\n# id_student              a unique identification number for the student\n# date_registration       the date of student's registration on the module presentation, this is the number of days measured relative to \n#                         the start of the module-presentation (e.g. the negative value -30 means that the student registered to module\n#                         presentation 30 days before it started)\n# date_unregistration     date of student unregistration from the module presentation, this is the number of days measured relative to \n#                         the start of the module-presentation. Students, who completed the course have this field empty. Students who \n#                         unregistered have Withdrawal as the value of the final_result column in the studentInfo.csv file\n\noulad_student_registration = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/studentRegistration.csv')","ad8c975e":"## From the description it is clear that if value is missing in column date_unregistration then that means student\n## completed the course and if it is null then student withdrawn from the course\n\n## 0 : 'COMPLETED'\n## 1 : 'WITHDRAWN'\n\n## There are very few missing values in the data_registration column. I replaced it with the 0 \n\noulad_student_registration['date_unregistration'] = ['0' if pd.isnull(days) else '1' for days in oulad_student_registration['date_unregistration']]\noulad_student_registration['date_registration']   = oulad_student_registration['date_registration'].fillna(0).astype(float).apply(abs)\n","65078200":"oulad_student_registration.head()","16ae00f6":"\"\"\"Loading Student Information Data\"\"\"\n\n# code_module             an identification code for a module on which the student is registered\n# code_presentation       the identification code of the presentation during which the student is registered on the module\n# id_student              a unique identification number for the student\n# gender                  the student\u00eds gender\n# region                  identifies the geographic region, where the student lived while taking the module-presentation\n# highest_education       highest student education level on entry to the module presentation\n# imd_band                specifies the Index of Multiple Depravation band of the place where the student lived during the module-presentation\n# age_band                band of the student\u00eds age\n# num_of_prev_attempts    the number times the student has attempted this module\n# studied_credits         the total number of credits for the modules the student is currently studying\n# disability              indicates whether the student has declared a disability\n# final_result            student\u00eds final result in the module-presentation\n\noulad_student_info = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/studentInfo.csv')","f69ad8dc":"### There are missing values in the imd_band. As those represent then band in which they are, we can think of them \n### like a category and we can fill missing values with the mode\n\nprint(oulad_student_info['imd_band'].unique())\n\noulad_student_info['imd_band'] = oulad_student_info['imd_band'].fillna(oulad_student_info['imd_band'].mode()[0])","d682a719":"oulad_student_info.head()","80591388":"# code_module           an identification code for a module\n# code_presentation     the identification code of the module presentation\n# id_student            a unique identification number for the student\n# id_site               an identification number for the VLE material\n# date                  the date of student\u00eds interaction with the material measured as the \n#                       number of days since the start of the module-presentation\n# sum_click             the number of times a student interacts with the material in that day \n\noulad_student_vle = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/studentVle.csv')","5d353853":"oulad_student_vle.head()","3601883f":"\"\"\"Loading VLE data\"\"\"\n# id_site              an identification number of the material\n# code_module          an identification code for module\n# code_presentation    the identification code of presentation\n# activity_type        the role associated with the module material\n# week_from            the week from which the material is planned to be used\n# week_to              week until which the material is planned to be used\n\noulad_vle = Load_File('\/kaggle\/input\/student-demographics-online-education-dataoulad\/vle.csv')","48fd6d98":"### As we can see that there are close to 80% values which are missing in the week_from and week_to columns\n### So I will remove those columns\n\noulad_vle = oulad_vle.drop(['week_from', 'week_to'], axis = 1)","76106f53":"oulad_vle.head()","70758276":"### We can see from the plot that activity_type = 'resource' has the most data points in VLE table\n\ncountplot(90, 0, 14, 10, 'activity_type', oulad_vle, plot_size=(15, 6))","8c73638d":"student_vle_merge_vle = oulad_student_vle.merge(oulad_vle, \n                                                on=['id_site', 'code_module', 'code_presentation'],\n                                                how = 'left')","11e94d5f":"## We can see that there are multiple interactions from a single student even before the course started. We can assume\n## that if student is interested in the course then that student will interact with the material of course before the\n## course starts\n\n## Number of clicks before the course can be an importtant factor which can help us determine whether student will\n## perform good or bad in the course. Therefore for each student we will calculate the number of clicks before and\n## after course went live\n\nstudent_vle_merge_vle[(student_vle_merge_vle['id_student']==28400) & (student_vle_merge_vle['date']<0)].head(10)","07c0c4d0":"student_vle_merge_vle['Click_Timing'] = ['Before' if date < 0 else 'After' for date in student_vle_merge_vle['date']]","0a19fae7":"# Creating After clicks and Before Clicks columns based on the data\n\nstudent_vle_merge_vle['After_Clicks'] = np.where(student_vle_merge_vle['Click_Timing'] =='After',\n                                                 student_vle_merge_vle['sum_click'], 0)\n\nstudent_vle_merge_vle['Before_Clicks']= np.where(student_vle_merge_vle['Click_Timing'] =='Before',\n                                                 student_vle_merge_vle['sum_click'], 0)","9f864695":"# Create a new dataframe by Grouping the columns\n\nstudent_vle_merge_vle_group = student_vle_merge_vle.groupby(['code_module', \n                                                             'code_presentation', \n                                                             'id_student']\n                                                            ,as_index=False)['sum_click', 'After_Clicks', 'Before_Clicks'].sum()","44c6679b":"student_vle_merge_vle_group.isnull().sum()","e934ea26":"### Plot describing the way students connect to VLE\n### We can see that most of the rows in the data are on ForumNG (Open University Forum Platform),\n### oucontent (Open University Content), subpage and homepage.\n\ncountplot(90, 0, 15, 12, 'activity_type', student_vle_merge_vle, plot_size=(20, 7))","aa9d7980":"# In this step I am plotting average interaction of student with each activity type. \n# We can see that most of the interactions are with the QUIZ, OUCONTENT, GLOSSARY, OUWIKI which is understandable as \n# student interact mostly with content to learn stuff and then use glossary to understand the study material. Also,\n# interactions with quiz is evident as after learning something, there are quizzes on the platform after completing chapters.\n\nplt.figure(figsize = (15, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_vle_merge_vle.groupby(['activity_type'], as_index=True)['sum_click'].mean().sort_values(ascending=False).plot(kind='bar')\n","e6402e2f":"student_vle_merge_vle.head()","7834e7f8":"student_registration_merge_courses = oulad_student_registration.merge(oulad_courses, \n                                                                      on = ['code_module', 'code_presentation'],\n                                                                      how = 'left')","7eac2ecf":"student_registration_merge_courses['Year'] = student_registration_merge_courses['code_presentation'].str[0:4]\nstudent_registration_merge_courses['Starting_Month'] = ['February' if code[-1] == 'B' else 'October' \n                                                        for code in student_registration_merge_courses['code_presentation']]","130bd347":"student_registration_merge_courses","eb34e54f":"# We can clearly see from the below plot that mMore registrations are in the month of October as compared to the month\n# of February. Also there are more people who drawn in the month of October.\n\ncountplot(90, 0, 14, 10, 'Starting_Month', student_registration_merge_courses, plot_size=(8, 6), hue=True, hue_column_name='date_unregistration')\n","78d43e0b":"### This plot shows us that there are more registrations in 2014 as compared to 2013\n\ncountplot(90, 0, 14, 10, 'Year', student_registration_merge_courses, plot_size=(5, 5))","9dcb5f12":"# This plot shows us the count by year and then by data unregistration count\n\ncountplot(90, 0, 14, 10, 'Year', student_registration_merge_courses, plot_size=(8, 6), hue=True, hue_column_name='date_unregistration')\n\n","f61fc43e":"### From the below table we can see that course length doesn't have much difference for the student who withdrawn\n### and students who completed the course\n\nstudent_registration_merge_courses.groupby('date_unregistration', as_index=False)['module_presentation_length'].mean()","a5fc177b":"student_assessment_merge_assessment = oulad_student_assessment.merge(oulad_assessment,\n                                                                     on = ['id_assessment'], how='left' )","6096b246":"student_assessment_merge_assessment.dtypes","3490ecd4":"# There would have been instances where students submitted their assignments later than the deadline. In this step,\n# using the date_submitted (days after student recieved their assignment) column and date (deadline in days for the assignment)\n# we can check whether their was a late submission or not (0 : Late, 1:OnTime)\n\nstudent_assessment_merge_assessment['Late_submission'] = ['0' if int(student_assessment_merge_assessment['date_submitted'].iloc[i]) \n                                                          > int(student_assessment_merge_assessment['date'].iloc[i]) else '1' \n                                                         for i in range(len(student_assessment_merge_assessment))]\n","094f5642":"print('Percentage of Late Submissions From Students are : ')\nprint((len(student_assessment_merge_assessment[student_assessment_merge_assessment['Late_submission']=='0'])\/len(student_assessment_merge_assessment)*100))\nprint('We can see that approximately 30 percent of students submitted their assigments late')","afaa4cb6":"# There are three types of assessments :- Tutor Marked Assessment (TMA), Computer Marked Assessment (CMA), Exams\n# Following Plot Shows us the Percentage of Late Submission by Assessment_Type\n# We can see that Most of the late submissions are for Final Exam and CMA which is Computer marked exam.\n# Tutor marked exams has the least late submissions\n\nstacked_plot(student_assessment_merge_assessment, 'assessment_type', 'Late_submission', 'id_student', plot_size=(10, 7))\n\n","7fe1d50c":"# There are 7 course modules. 4 are from STEM and 3 from Social Sciences\n# Social Sciences :- AAA, BBB, GGG\n# STEM :- CCC, DDD, EEE, FFF\n# We can see from the plot that most percentage of the late submissions are for Course BBB, CCC and DDD\n\n\nstacked_plot(student_assessment_merge_assessment, 'code_module', 'Late_submission', 'id_student', plot_size=(12, 8))","6fc39adc":"## Creating a column for Social Science and STEM field\n\nstudent_assessment_merge_assessment['Code_Category'] = ['Social_Science' if student_assessment_merge_assessment['code_module'].iloc[i] in ['AAA', 'BBB', 'GGG']\n                                                        else 'STEM' for i in range(len(student_assessment_merge_assessment))]\n","f95b7909":"## Social Science has more percentage of late submissions as compared to STEM\n\n\nstacked_plot(student_assessment_merge_assessment, 'Code_Category', 'Late_submission', 'id_student', plot_size=(8, 7))","17f589ca":"# As from the description of table we know that score less than 40 is considered as Fail and above that is pass\n\n\nstudent_assessment_merge_assessment['Result'] = ['Fail' if int(student_assessment_merge_assessment['score'].iloc[i]) < 40\n                                                        else 'Pass' for i in range(len(student_assessment_merge_assessment))]","6ec784ea":"# Following Plot shows us the Ratio of Pass and Fail students in the form of plot\n# Failure Rate in STEM is more as compared to Social Sciences\n\nstacked_plot(student_assessment_merge_assessment, 'Code_Category', 'Result', 'id_student', plot_size=(10, 7))","e509837e":"# We can see from the following plot that course DDD , CCC and BBB have the most failure rate. Out of the 3\n# courses 2 of them are from STEM.\n\n\nstacked_plot(student_assessment_merge_assessment, 'code_module', 'Result', 'id_student', plot_size=(15, 8))","dfb8b562":"## Weightage of Assignment can have impact on the submissions and Result of students. I categorized the weight into\n## Low, Medium and High Weightage.\n\nprint(student_assessment_merge_assessment['weight'].unique())\n\npercentage_segment = []\n\nfor percent in student_assessment_merge_assessment['weight']:\n    if percent <= 10:\n        percentage_segment.append('Low_Weightage')\n    elif percent > 10 and percent <= 30:\n        percentage_segment.append('Medium_Weightage')\n    else:\n        percentage_segment.append('High_Weightage')\n        \nstudent_assessment_merge_assessment['Weigthage'] = percentage_segment","b3f7afb0":"# We can see that Medium and High Weightage Assessments have high failure rate as compared to low\n\nstacked_plot(student_assessment_merge_assessment, 'Weigthage', 'Result', 'id_student', plot_size=(8, 6))","ed453a2e":"# Following Plot shows the ratio of Pass and Fail in Late_submission.\n# We can clearly see that Late Submissions have more Failure Rate as compared to people who submit on time.\n\nstacked_plot(student_assessment_merge_assessment, 'Late_submission', 'Result', 'id_student', plot_size=(8, 6))","19ce3119":"student_assessment_merge_assessment.head()","411c2bc8":"student_info = oulad_student_info.merge(student_vle_merge_vle_group, \n                                        on = ['code_module', 'code_presentation', 'id_student'],\n                                        how = 'left')\n\nstudent_info['sum_click']     = student_info['sum_click'].fillna(student_info['sum_click'].mean())\nstudent_info['After_Clicks']  = student_info['After_Clicks'].fillna(student_info['After_Clicks'].mean())\nstudent_info['Before_Clicks'] = student_info['Before_Clicks'].fillna(student_info['Before_Clicks'].mean())","be4222bd":"## In this plot I am trying to examine the relationship between number of clicks versus the result\n## We can clearly see from the plot that number of clicks is directly related to the result. Student who passed with\n## Distinction has significantly more clicks as compared to ones with result = PASS and there is a huge difference\n## between the students who failed or withdrawn as compared to the one's who passed with or without distinction\n\nplt.figure(figsize = (10, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_info.groupby(['final_result'])['After_Clicks'].mean().sort_values(ascending = False).plot(kind='bar')","c8eee1db":"## Even from the clicks data before the course even started, we can see that more the clicks more are the chances\n## for student to pass.\n\nplt.figure(figsize = (10, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_info.groupby(['final_result'])['Before_Clicks'].mean().sort_values(ascending = False).plot(kind='bar')","2036c4c9":"## People with less credits have more chances to pass with distinction or pass because they have to study less\n## People who withdrew has more average credits as compared to another. \n\nplt.figure(figsize = (10, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_info.groupby(['final_result'])['studied_credits'].mean().sort_values(ascending = False).plot(kind='bar')","6c472e19":"plt.figure(figsize = (10, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_info.groupby(['age_band'])['Before_Clicks'].mean().sort_values(ascending = False).plot(kind='bar')","81827ee6":"# Number of Clicks by imd_band.\n\nplt.figure(figsize = (10, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_info.groupby(['imd_band'])['sum_click'].sum().sort_values(ascending = False).plot(kind='bar')","0d115d71":"# We can see that Males have higher Click Rate as compared to the females\n\nplt.figure(figsize = (8, 5))\nplt.xticks(rotation=90, fontsize=15)\nplt.yticks(rotation=0, fontsize=12)\nsns.set_style(\"whitegrid\")\nstudent_info.groupby(['gender'])['sum_click'].sum().sort_values(ascending = False).plot(kind='bar')","10567249":"## Following plot shows us the number of students in each result category. Most of the data is in age band 0-55.\n## There are very few data points for age >= 55. \n## We can see that Failure and Withdrawn rate is greater in age_band 0-35\n\nprint(student_info.groupby(['age_band', 'final_result'])['id_student'].count().sort_values(ascending = False))\nstacked_plot(student_info, 'age_band', 'final_result', 'id_student', plot_size=(10, 8))","bd16f759":"# We can see from the plot that Failure Rate and Withdrawal Rate is high in people who have NO FORMAL EDUCATION\n# and who have LOWER THAN A LEVEL EDUCATION\n# Failure Rate is lowest in people who has Post Graduation.\n\n\nstacked_plot(student_info, 'highest_education', 'final_result', 'id_student', plot_size=(10, 8))","424b4c22":"## We can see from the plot that most of the data is for people who have a level or lower level of education.\n## This will cause an imbalance when the feature is used in the model. So I will manipulate the feature and \n## create two categories. One with higher education and one with lower education.\n\ncountplot(90, 0, 12, 10, 'highest_education', student_info)","56068c70":"student_info['highest_education'].unique()","54eb8372":"## Manioulating the feature higher_education\n\nstudent_info['highest_education'] = [0 if education in ['A Level or Equivalent', 'Lower Than A Level', 'No Formal quals']\n                                    else 1 for education in student_info['highest_education']]\n","5cb96a43":"countplot(90, 0, 12, 10, 'highest_education', student_info, plot_size=(7, 6))","3b744d9e":"## We can see from the plot that students with lower education has higher failure rate than the ones who had higher education\n\nstacked_plot(student_info, 'highest_education', 'final_result', 'id_student', plot_size=(10, 8))","1240364e":"## We can see that Failure Rate and Withdrawal rate is similar in all the regions.\n\nstacked_plot(student_info, 'region', 'final_result', 'id_student', plot_size=(15, 8))","13d00d57":"stacked_plot(student_info, 'imd_band', 'final_result', 'id_student', plot_size=(15, 8))","fae48b0e":"# We can see that Males are more in number as compared to females\n\ncountplot(90, 0, 14, 10, 'gender', student_info, plot_size=(5, 5))","0a0ee568":"## We can see that there is no difference between the Withdrawal Rates and Failure Rates for both the gender.\n\nstacked_plot(student_info, 'gender', 'final_result', 'id_student', plot_size=(10, 8))","7556f596":"# Following plot shows us the results by disability.\n# Withdrawn Rate is more in People who are disable.\n\n\nstacked_plot(student_info, 'disability', 'final_result', 'id_student', plot_size=(15, 8))","7d72561e":"student_registration_merge_courses = student_registration_merge_courses.drop('date_unregistration', axis = 1)","fda41e11":"student_info = student_info.merge(student_registration_merge_courses,\n                                 on = ['code_module', 'code_presentation', 'id_student'],\n                                 how = 'left')","d3ca4da5":"## Following Plot shows us the Result by Session. Failure Rate is more in people who took the course in February.\n## Also withdrawn rate is slightly more in course starting in February. \n\nstacked_plot(student_info, 'Starting_Month', 'final_result', 'id_student', plot_size=(15, 8))","836776cf":"## There are less people who registered in February as compared to October. But still the failure and withdrawn rate\n## is more for february. May be the students don't like content or the course in February.\n\ncountplot(90, 0, 12, 10, 'Starting_Month', student_info, plot_size=(7, 6))","e4f7e60c":"## We can clearly see from the plot that we have the least failure and withdrawn rate in the students who did not\n## took the course before or number of previous attempts are zero. \n\nstacked_plot(student_info, 'num_of_prev_attempts', 'final_result', 'id_student', plot_size=(15, 8))\n","892fa3c2":"# Most of the data is for zero attempts which cause imbalance in the feature. We need to collect more data for creating\n# balance in the feature. So instead of using this feature, we will manipulate the feature to create two categories only.\n# 0 and 1 where 0 show no previous attempts and 1 shows previous attempts.\n\ncountplot(90, 0, 12, 10, 'num_of_prev_attempts', student_info, plot_size=(10, 8))","af07af3a":"student_info['num_of_prev_attempts'] = [0 if attempts == 0 else 1 for attempts in student_info['num_of_prev_attempts']]","9caa9409":"## Still there is imbalance in the feature but it's better than the initial.\n\ncountplot(90, 0, 12, 10, 'num_of_prev_attempts', student_info, plot_size=(7, 6))","9bbf9ca7":"# We can clearly see that people with previous attempts have more failure and withdrawn rate.\n\nstacked_plot(student_info, 'num_of_prev_attempts', 'final_result', 'id_student', plot_size=(15, 8))","f89b40bc":"## We can see that \n\nstacked_plot(student_info, 'code_module', 'final_result', 'id_student', plot_size=(15, 8))","0ed4b0ff":"student_info['Code_Category'] = ['Social_Science' if student_info['code_module'].iloc[i] in ['AAA', 'BBB', 'GGG']\n                                 else 'STEM' for i in range(len(student_info))]","e1417570":"## From the following plot we can see that Failure Rate is higher in Social Science and Withdrawn rate is higher in\n## STEM Courses.\n\nstacked_plot(student_info, 'Code_Category', 'final_result', 'id_student', plot_size=(15, 8))","ed68ae19":"# In this step, I will remove code_module, code_presentation, id_student and Year as those won't have impact on the result \n\nstudent_info = student_info.drop(['code_presentation', 'id_student', 'Year'], axis = 1)","256f627f":"student_info['date_registration'] = student_info['date_registration'].astype(float)","53759979":"student_info['date_registration'].describe()","0134812a":"student_info.head()","eadfe646":"# There are two types of categorical variables in the data.\n# 1. NOMINAL :- Here there is no order in the categories\n# 2. ORDINAL :- When there is order in the category\n\nnominal_columns = ['gender', 'region', 'disability', 'Starting_Month', 'code_module', 'Code_Category']\nordinal_columns = ['highest_education', 'imd_band', 'age_band']","1306804c":"data = labelEncoder(student_info, ordinal_columns)\ndata = categorical_encoding(student_info, nominal_columns)","94d73cf6":"countplot(90, 0, 10, 10, 'final_result', data, plot_size=(10, 7))","10941130":"## To built a simplified binary class model, I am labeling Distinction and Pass as 0 and Withdrawn and Failure as 1\n\ndata['Result']  = [0 if result in ['Pass', 'Distinction'] else 1 for result in data['final_result']]","3d6826e1":"## In this steP, I am creating a dropout column where we consider withdrawn as the dropout and everything else as no dropout\n## '0' : Not Withdrawn, '1': 'Withdrawn'\n\ndata['dropout'] = [0 if result in ['Pass', 'Distinction', 'Fail'] else 1 for result in data['final_result']]","990dc9b0":"## Creating Feature and Target Dataframes\n\nfeature = data.drop(['final_result', 'Result'], axis = 1)\ntarget  = data['Result']","d1f15d34":"## We can see that both the classes are close in numbers. So I will treat this as a balanced case of binary classification.\n\ntarget.value_counts()","3560282b":"### Here we will split our data into training and testing. As we have less data, I will keep 80% of the data for \n### training and only 20% for testing. I would like to have more data where I can create three separate datasets\n### for training, validation and testing. As our objective here is to find features which impact the decision whether\n### student will fail or not, I will use most for training only.\n\nX_train, X_test, Y_train, Y_test = train_test_split(feature, target, \n                                                    test_size = 0.2, \n                                                    random_state = 123, \n                                                    stratify=data.final_result)","26c1813e":"# In this step I will create a feature and target set for the dropout vs non-dropout case\n\nfeature_dropout = data.drop(['final_result', 'dropout', 'Result'], axis = 1)\ntarget_dropout  = data['dropout']","0d66e6e0":"target_dropout.value_counts()","38ca95a0":"## Splitting Data into training and test sets\n\nX_train_dropout, X_test_dropout, Y_train_dropout, Y_test_dropout = train_test_split(feature_dropout, target_dropout, \n                                                                                    test_size = 0.2, \n                                                                                    random_state = 123, \n                                                                                    stratify=target_dropout)","870b5ecc":"data.head()","059b4737":"## Initializing the Random Forest Model\n\nrandom_forest_model = RandomForestClassifier(n_estimators=100, \n                                             random_state=123, \n                                             max_depth=25,\n                                             min_samples_split = 100,\n                                             n_jobs=4)","f4ecee33":"## Fitting the model using Training Data\n\nrandom_forest_model.fit(X_train, Y_train)","a1a86f3f":"## Predicting on Test Data using fitted model\n\npredictions_random = random_forest_model.predict(X_test)","d83efbaf":"print(confusion_matrix(Y_test, predictions_random))","5f7040d7":"print(\"Accuracy of the model is \", accuracy_score(Y_test, predictions_random))","3c8e7770":"print(classification_report(Y_test, predictions_random, digits=2))","5ff79238":"predictions_rf = random_forest_model.predict_proba(X_test)\npreds = predictions_rf[:,1]\ny_test = np.array(Y_test)\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","585e9d72":"# n_estimators      = [100, 300, 500, 800, 1200]\n# max_depth         = [5, 8, 15, 25, 30]\n# min_samples_split = [50, 100, 150, 250, 300]\n# min_samples_leaf  = [1, 2, 5, 10] \n\n# hyperF  = {'n_estimators' : n_estimators, \n#            'max_depth' : max_depth,  \n#            'min_samples_split' : min_samples_split, \n#            'min_samples_leaf' : min_samples_leaf}\n\n# gridF   = GridSearchCV(random_forest_model, hyperF, cv = 3, verbose = 1)\n# bestF   = gridF.fit(X_train, Y_train)","25b8d5e5":"# bestF.best_params_\n\n# {'max_depth': 30,\n#  'min_samples_leaf': 1,\n#  'min_samples_split': 50,\n#  'n_estimators': 100}","848251e2":"random_forest_model_best_fit = RandomForestClassifier(n_estimators=100, \n                                                      random_state=123, \n                                                      max_depth=30,\n                                                      min_samples_split = 50,\n                                                      n_jobs=4)","85d1c32f":"random_forest_model_best_fit.fit(X_train, Y_train)","4b48504c":"predict_best_fit = random_forest_model_best_fit.predict(X_test)","d55afa2b":"print(classification_report(predict_best_fit, Y_test))","666ef926":"## We can see that region has close to None impact on the output of the model. So we will remove this feature.\n\nimportance = pd.concat([pd.DataFrame(X_train.columns),\n                          pd.DataFrame(np.transpose(random_forest_model.feature_importances_))], axis = 1)\nimportance.columns = ['Features', 'Coeff']\nimportance = importance.sort_values('Coeff', ascending=False)\nimportance","ef82336b":"## I am using class weight in this case because we have less samples for class = 1 which is dropout\n\nrandom_forest_model_drop = RandomForestClassifier(n_estimators=100, \n                                                  random_state=123, \n                                                  max_depth=25,\n                                                  min_samples_split = 100,\n                                                  class_weight = {0: 1, 1: 2},\n                                                  n_jobs=4)","90c58db4":"random_forest_model_drop.fit(X_train_dropout, Y_train_dropout)","f070c9ff":"predict_dropout = random_forest_model_drop.predict(X_test_dropout)","ca1d6374":"print(classification_report(predict_dropout, Y_test_dropout))","409971a7":"predictions_rf = random_forest_model_drop.predict_proba(X_test_dropout)\npreds = predictions_rf[:,1]\ny_test = np.array(Y_test_dropout)\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","bfd012fb":"importance = pd.concat([pd.DataFrame(X_train_dropout.columns),\n                          pd.DataFrame(np.transpose(random_forest_model_drop.feature_importances_))], axis = 1)\nimportance.columns = ['Features', 'Coeff']\nimportance = importance.sort_values('Coeff', ascending=False)\nimportance","c228634c":"###### MERGING VLE DATA WITH THE STUDENT INFO DATA","e46f7143":"# BUILDING AND EVALUATING MODEL","319c3ca5":"# MERGING DATA\n\n#### In this step we will merge different dataframe which we loaded in the previous steps. Based on the database schema we will \n#### join the different tables\n\nDatabase schema.png![image.png](attachment:image.png)","199b1c95":"#### USING GRID SEARCH FOR HYPERPARAMETER OPTIMIZATION","73be03bf":"#### Building a model to predict whether student will pass or fail","bfcd629e":"# DATA PREPARATION\n#### Feature Selection\n#### Data Encoding\n#### Splitting Data","786b9067":"###### In this step I will merge assessments Table with the studentAssessment Table to understand the relationship between assessment and student performance","92d7cb1c":"###### In the first step I am merging studentVle table with the vle table. This can show us about the interactions of students with VLE.","a703e131":"### In the First case I am assuming Withdrawn Class as Fail and I am building a model whether student will pass or fail.\n### In the Second case I will create a labels for dropout vs non-dropout and build a model using that","e5011293":"###### Combining Student Info with the Student Registration Table","77e780ec":"#### Building a model to predict whether student will dropout or not","c015ea3e":"###### In this step I will merge studentRegistration table with the courses table to understand the related between registrations and length of course","4dece358":"# IMPORTING DATA"}}