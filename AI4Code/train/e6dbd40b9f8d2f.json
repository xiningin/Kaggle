{"cell_type":{"a2b55d95":"code","61df3b1b":"code","8dcf4a45":"code","e3282a11":"code","ac8c003f":"code","46bce8c1":"code","edb335fe":"code","0a36675d":"code","09b027ec":"code","9bd179bf":"code","4e2ac6f3":"code","3bdd3fc0":"code","a68ba5a2":"code","7e5a7102":"code","77749261":"code","18c81d43":"code","c80ff952":"code","be3c6716":"code","75d2d3f0":"code","3ff802e3":"markdown","9601b313":"markdown","9c7db2da":"markdown","34a77fe5":"markdown","9a906d0c":"markdown","d7e6c094":"markdown"},"source":{"a2b55d95":"import fastai\nfrom fastai.vision import *\nfastai.__version__","61df3b1b":"path = Path('..\/input\/imet-2019-fgvc6\/') # iMet data path","8dcf4a45":"# Making pretrained weights work without needing to find the default filename\nfrom torch.utils import model_zoo\nPath('models').mkdir(exist_ok=True)\n!cp '..\/input\/densenet201\/densenet201.pth' 'models\/'\ndef load_url(*args, **kwargs):\n    model_dir = Path('models')\n    filename  = 'densenet201.pth'\n    if not (model_dir\/filename).is_file(): raise FileNotFoundError\n    return torch.load(model_dir\/filename)\nmodel_zoo.load_url = load_url","e3282a11":"# Load train dataframe\ntrain_df = pd.read_csv(path\/'train.csv')\ntrain_df.head()","ac8c003f":"# Load labels dataframe\nlabels_df = pd.read_csv(path\/'labels.csv')\nlabels_df.head()","46bce8c1":"# Load sample submission\ntest_df = pd.read_csv(path\/'sample_submission.csv')\ntest_df.head()","edb335fe":"train, test = [ImageList.from_df(df, path=path, cols='id', folder=folder, suffix='.png') \n               for df, folder in zip([train_df, test_df], ['train', 'test'])]\ndata = (train.split_by_rand_pct(0.2, seed=42)\n        .label_from_df(cols='attribute_ids', label_delim=' ')\n        .add_test(test)\n        .transform(get_transforms(), size=128)\n        .databunch(path=Path('.'), bs=64).normalize())","0a36675d":"data.show_batch()","09b027ec":"# Source: https:\/\/www.kaggle.com\/c\/human-protein-atlas-image-classification\/discussion\/78109\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n\n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n               ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n\n        return loss.sum(dim=1).mean()\n    \nclass FbetaLoss(nn.Module):\n    def __init__(self, beta=1):\n        super(FbetaLoss, self).__init__()\n        self.small_value = 1e-6\n        self.beta = beta\n\n    def forward(self, logits, labels):\n        beta = self.beta\n        batch_size = logits.size()[0]\n        p = F.sigmoid(logits)\n        l = labels\n        num_pos = torch.sum(p, 1) + self.small_value\n        num_pos_hat = torch.sum(l, 1) + self.small_value\n        tp = torch.sum(l * p, 1)\n        precise = tp \/ num_pos\n        recall = tp \/ num_pos_hat\n        fs = (1 + beta * beta) * precise * recall \/ (beta * beta * precise + recall + self.small_value)\n        loss = fs.sum() \/ batch_size\n        return 1 - loss\n\nclass CombineLoss(nn.Module):\n    def __init__(self):\n        super(CombineLoss, self).__init__()\n        self.fbeta_loss = FbetaLoss(beta=2)\n        self.focal_loss = FocalLoss()\n        \n    def forward(self, logits, labels):\n        loss_beta = self.fbeta_loss(logits, labels)\n        loss_focal = self.focal_loss(logits, labels)\n        return 0.5 * loss_beta + 0.5 * loss_focal","9bd179bf":"learn = cnn_learner(data, base_arch=models.densenet201, loss_func=CombineLoss(), metrics=fbeta)","4e2ac6f3":"# Find a good learning rate\nlearn.lr_find()\nlearn.recorder.plot()","3bdd3fc0":"lr = 3e-2\nlearn.fit_one_cycle(3, slice(lr))","a68ba5a2":"learn.unfreeze()","7e5a7102":"learn.lr_find()\nlearn.recorder.plot()","77749261":"lr = 1e-3\nlearn.fit_one_cycle(21, slice(lr\/10, lr))","18c81d43":"def find_best_fixed_threshold(preds, targs, do_plot=True):\n    score = []\n    thrs = np.arange(0, 0.5, 0.01)\n    for thr in progress_bar(thrs):\n        score.append(fbeta(valid_preds[0],valid_preds[1], thresh=thr))\n    score = np.array(score)\n    pm = score.argmax()\n    best_thr, best_score = thrs[pm], score[pm].item()\n    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n    if do_plot:\n        plt.plot(thrs, score)\n        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n        plt.show()\n    return best_thr\n\ni2c = np.array([[i, c] for c, i in learn.data.train_ds.y.c2i.items()]).astype(int) # indices to class number correspondence\n\ndef join_preds(preds, thr):\n    return [' '.join(i2c[np.where(t==1)[0],1].astype(str)) for t in (preds[0].sigmoid()>thr).long()]","c80ff952":"# Validation predictions\nvalid_preds = learn.get_preds(DatasetType.Valid)\nbest_thr = find_best_fixed_threshold(*valid_preds)","be3c6716":"# Test predictions\ntest_preds = learn.get_preds(DatasetType.Test)\ntest_df.attribute_ids = join_preds(test_preds, best_thr)\ntest_df.head()","75d2d3f0":"test_df.to_csv('submission.csv', index=False)","3ff802e3":"# Create data object using datablock API","9601b313":"# Train the model","9c7db2da":"# iMet Collection 2019 - FGVC6\n**Simple baseline for iMet Collection 2019 competition using fastai v1**\n* Model: densenet201\n* Loss: Focal loss\n* Metric: $F_{2}$ score\n\n**What to try next?**\n* Different models\n* Optimize hyperparameter choice\n* Few-shot learning to improve score on classes with very few samples","34a77fe5":"# Get predictions","9a906d0c":"# Initial setup","d7e6c094":"# Create learner with densenet121 and FocalLoss\nFor problems with high class imbalance Focal Loss is usually a better choice than the usual Cross Entropy Loss."}}