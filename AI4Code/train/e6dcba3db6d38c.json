{"cell_type":{"764b4d3b":"code","3cab0677":"code","2f62a0f8":"code","3de3f4a7":"code","3e869981":"code","bc54d23c":"code","33a88373":"code","959c78bd":"code","ecd4b141":"code","ae3aa707":"code","dc02a6d7":"code","9c9c32b5":"code","aaa34e31":"code","303490ce":"code","97f18cdc":"code","0822c266":"code","5bb366d9":"code","d448c57c":"code","8a9ae432":"code","a21b7a05":"code","d540a67f":"code","fb39dffc":"code","dae34755":"code","595ac3e5":"code","b2a65cd9":"code","9e194823":"code","2ca3bd68":"code","f20d6059":"markdown"},"source":{"764b4d3b":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split","3cab0677":"train_dir = '..\/input\/cifar100\/CIFAR100\/TRAIN'\ntest_dir = '..\/input\/cifar100\/CIFAR100\/TEST'","2f62a0f8":"Name=[]\nfor file in os.listdir(train_dir):\n    Name+=[file]\nprint(Name)\nprint(len(Name))","3de3f4a7":"N=[]\nfor i in range(len(Name)):\n    N+=[i]\n    \nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) \n\ndef mapper(value):\n    return reverse_mapping[value]","3e869981":"dataset=[]\ncount=0\nfor name in Name:\n    path=os.path.join(train_dir,name)\n    for im in os.listdir(path):\n        if im[-4:]=='.png':\n            image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(32,32))\n            image=img_to_array(image)\n            image=image\/255.0\n            dataset.append([image,count])\n    count=count+1","bc54d23c":"testset=[]\ncount=0\nfor name in Name:\n    path=os.path.join(train_dir,name)\n    for im in os.listdir(path):\n        if im[-4:]=='.png':\n            image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(32,32))\n            image=img_to_array(image)\n            image=image\/255.0\n            testset.append([image,count])\n    count=count+1","33a88373":"data,labels0=zip(*dataset)\ntest,tlabels0=zip(*testset)","959c78bd":"data=np.array(data)\nlabels1=to_categorical(labels0)\nlabels=np.array(labels1)","ecd4b141":"test=np.array(test)\ntlabels=np.array(tlabels0)","ae3aa707":"print(len(data))\nprint(len(test))","dc02a6d7":"trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=44)","9c9c32b5":"print(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","aaa34e31":"datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,\n                        width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")","303490ce":"pretrained_model3 = tf.keras.applications.DenseNet201(input_shape=(32,32,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model3.trainable = False","97f18cdc":"inputs3 = pretrained_model3.input\nx3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model3.output)\noutputs3 = tf.keras.layers.Dense(100, activation='softmax')(x3)\nmodel = tf.keras.Model(inputs=inputs3, outputs=outputs3)","0822c266":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","5bb366d9":"his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)","d448c57c":"y_pred=model.predict(testx)\npred=np.argmax(y_pred,axis=1)\nground = np.argmax(testy,axis=1)\nprint(classification_report(ground,pred))","8a9ae432":"get_acc = his.history['accuracy']\nvalue_acc = his.history['val_accuracy']\nget_loss = his.history['loss']\nvalidation_loss = his.history['val_loss']\n\nepochs = range(len(get_acc))\nplt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')\nplt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')\nplt.title('Training vs validation accuracy')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","a21b7a05":"epochs = range(len(get_loss))\nplt.plot(epochs, get_loss, 'r', label='Loss of Training data')\nplt.plot(epochs, validation_loss, 'b', label='Loss of Validation data')\nplt.title('Training vs validation loss')\nplt.legend(loc=0)\nplt.figure()\nplt.show()","d540a67f":"load_img(\"..\/input\/cifar100\/CIFAR100\/TEST\/bicycle\/bike_s_001073.png\",target_size=(32,32))","fb39dffc":"image=load_img(\"..\/input\/cifar100\/CIFAR100\/TEST\/bicycle\/bike_s_001073.png\",target_size=(32,32))\n\nimage=img_to_array(image) \nimage=image\/255.0\nprediction_image=np.array(image)\nprediction_image= np.expand_dims(image, axis=0)","dae34755":"prediction=model.predict(prediction_image)\nvalue=np.argmax(prediction)\nname=mapper(value)\nprint(\"Prediction is {}.\".format(name))","595ac3e5":"prediction2=model.predict(test)\nprint(test.shape)\nprint(prediction2.shape)","b2a65cd9":"PRED=[]\nfor item in prediction2:\n    value2=np.argmax(item)\n    PRED+=[value2]\nprint(PRED[0:5])","9e194823":"ANS=list(tlabels0)\nprint(ANS[0:5])","2ca3bd68":"accuracy=accuracy_score(ANS,PRED)\nprint(accuracy)","f20d6059":"##### In case of target_size=(64,64), allocated memory became more than available."}}