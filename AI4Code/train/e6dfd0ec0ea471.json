{"cell_type":{"5c4c96a3":"code","a1241fd3":"code","313e0b4e":"code","514bae47":"code","106118d2":"code","759fd158":"code","d03cec23":"code","e57cd905":"code","4ad828d8":"code","f92d46ce":"code","5f27768f":"code","f989e1e3":"code","db128e5d":"code","7cc37cc1":"code","48c313a4":"code","775c15bd":"code","9e8ac25a":"code","1532c28a":"code","a4c05855":"code","31e8a8de":"code","0e7cddf5":"code","ce3506dc":"code","efc9d902":"code","ff4792e2":"code","fee8b628":"code","347a24f8":"code","e877be61":"code","6bd036ff":"code","9404d4a0":"code","decf5158":"code","79257a26":"code","d17c5e32":"code","5b5217a4":"code","3a26204e":"code","ffc8efef":"code","4b891715":"code","4454a776":"code","ed4595ef":"code","8add53b9":"code","f7ebc3b4":"markdown","3398c95b":"markdown","a3321487":"markdown"},"source":{"5c4c96a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a1241fd3":"import pandas as pd\n\nfull_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\nX_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","313e0b4e":"full_train","514bae47":"full_train.describe()","106118d2":"full_train.info()","759fd158":"corr = full_train.corr()","d03cec23":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(8,7))\nsns.heatmap(corr, cmap='binary', annot=True)\nplt.show()","e57cd905":"validation_size = 0.1\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_validation = train_test_split(full_train, test_size=validation_size, random_state=0)\n\nY_train = X_train.pop('Survived')\nY_validation = X_validation.pop('Survived')","4ad828d8":"PASSENGERID = 'PassengerId'\nPCLASS = 'Pclass'\nNAME = 'Name'\nSEX = 'Sex'\nAGE = 'Age'\nSIBSP = 'SibSp'\nPARCH = 'Parch'\nTICKET = 'Ticket'\nFARE = 'Fare'\nCABIN = 'Cabin'\nEMBARKED = 'Embarked'\n\nHAS_AGE = 'has_age'\nHAS_CABIN = 'has_cabin'\nAGE_CATEGORIES = 'age_category'\nFAMILY_MEMBERS = 'family_members'","f92d46ce":"import numpy as np\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer","5f27768f":"class AgeTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self._age_imputer = SimpleImputer(strategy='mean')\n\n    def fit(self, X, y=None):\n        self._age_imputer.fit(X)\n        return self\n\n    def transform(self, X):\n        has_age_series = (~X.isna() * 1).iloc[:, 0]\n        age_series = self._age_imputer.transform(X).reshape(-1)\n        categories_series = pd.cut(age_series, bins=[0, 12, 19, np.inf], labels=[0, 1, 2])\n        result = pd.DataFrame({'age': age_series, 'has_age': has_age_series, 'age_categories': categories_series})\n        return result.reset_index(drop=True)","f989e1e3":"class SexTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self._sex_encoder = OneHotEncoder(sparse=False, dtype=np.int32, handle_unknown='ignore')\n\n    def fit(self, X, y=None):\n        self._sex_encoder.fit(X, y)\n        return self\n\n    def transform(self, X: pd.Series):\n        transformed = self._sex_encoder.transform(X)\n        sex_df = pd.DataFrame(transformed, columns=self._sex_encoder.categories_[0])\n        return sex_df.reset_index(drop=True)","db128e5d":"class EmbarkedTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self._embarked_transform = Pipeline([\n            ('imputer', SimpleImputer(strategy='constant', fill_value='NA')),\n            ('encoder', OneHotEncoder(sparse=False, dtype=np.int32, handle_unknown='ignore'))])\n\n    def fit(self, X, y=None):\n        self._embarked_transform.fit(X, y)\n        return self\n\n    def transform(self, X: pd.Series):\n        embarked_columns = [f'embarked_{val}' for val in self._embarked_transform[1].categories_[0]]\n        embarked_df = pd.DataFrame(self._embarked_transform.transform(X[[EMBARKED]]),\n                                   columns=embarked_columns)\n        return embarked_df.reset_index(drop=True)","7cc37cc1":"class FareTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self._fare_transform = SimpleImputer(strategy='mean')\n\n    def fit(self, X, y=None):\n        self._fare_transform.fit(X, y)\n        return self\n\n    def transform(self, X: pd.Series):\n        fare_series = self._fare_transform.transform(X).reshape(-1)\n        result = pd.DataFrame({'fare': fare_series})\n        return result.reset_index(drop=True)","48c313a4":"class HasCabinTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X: pd.Series):\n        has_cabin = (~X.isna() * 1).iloc[:, 0]\n        result = pd.DataFrame({'has_cabin': has_cabin})\n        return result.reset_index(drop=True)","775c15bd":"class NameTransformer(BaseEstimator, TransformerMixin):\n    OTHER_TITLE = 'Other'\n\n    def __init__(self):\n        self._ohe = OneHotEncoder(sparse=False, dtype=np.int32, handle_unknown='ignore')\n\n    def _get_title(self, X):\n        titles_series = X.iloc[:, 0].str.split(\", \").str[1].str.split(\". \").str[0]\n        counts = titles_series.value_counts()\n        distinct_titles = set(counts[counts > 1].index)\n        titles_series.loc[~titles_series.isin(distinct_titles)] = NameTransformer.OTHER_TITLE\n        return pd.DataFrame({'title': titles_series})\n\n    def fit(self, X, y=None):\n        titles = self._get_title(X)\n        self._ohe.fit(titles)\n        return self\n\n    def transform(self, X):\n        titles = self._get_title(X)\n        result = self._ohe.transform(titles)\n        result = pd.DataFrame(result, columns=self._ohe.categories_[0])\n        return result","9e8ac25a":"class FamilyMembersTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        family_members = X.sum(axis=1)\n        result = pd.DataFrame({'family_members': family_members})\n        return result.reset_index(drop=True)","1532c28a":"class IdentityTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        result = X.copy()\n        return result.reset_index(drop=True)","a4c05855":"from typing import List, Tuple, Union\n\nclass DataFrameColumnTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, transformers: List[Tuple[TransformerMixin, Union[str, List[str]]]]):\n        self._transformers = transformers\n\n    def _get_x_by_columns(self, x, columns):\n        return x[[columns]] if isinstance(columns, str) else x[columns]\n\n    def fit(self, X, y=None):\n        for transformer, columns in self._transformers:\n            x_context = self._get_x_by_columns(X, columns)\n            transformer.fit(x_context)\n        return self\n\n    def transform(self, X):\n        result = []\n        for transformer, columns in self._transformers:\n            x_context = self._get_x_by_columns(X, columns)\n            transformed_df = transformer.transform(x_context)\n            result.append(transformed_df)\n        result = pd.concat(result, axis=1)\n        return result","31e8a8de":"class PandasTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Returns a pandas DataFrame after applying the transformation instead of\n    numpy array\n    \"\"\"\n    def __init__(self, transformer):\n        self.transformer = transformer\n\n    def fit(self, X, y=None):\n        self.transformer.fit(X, y)\n        return self\n\n    def transform(self, X):\n        result = self.transformer.transform(X.copy())\n        result_df = pd.DataFrame(result, columns=list(X.columns), index=X.index)\n        return result_df","0e7cddf5":"from sklearn.preprocessing import StandardScaler\n\ntitanic_transformer = DataFrameColumnTransformer([\n    (AgeTransformer(), AGE),\n    (SexTransformer(), SEX),\n    (EmbarkedTransformer(), EMBARKED),\n    (HasCabinTransformer(), CABIN),\n    (NameTransformer(), NAME),\n    (FamilyMembersTransformer(), [SIBSP, PARCH]),\n    (IdentityTransformer(), [PCLASS]),\n    (FareTransformer(), [FARE])])\n\ntitanic_pipeline = Pipeline([\n    ('transform', titanic_transformer),\n    ('scale', PandasTransformer(StandardScaler()))])\n\ntrain_transformed = titanic_pipeline.fit_transform(X_train)\nvalidation_transformed = titanic_pipeline.transform(X_validation)\ntest_transformed = titanic_pipeline.transform(X_test)","ce3506dc":"corr = pd.concat([train_transformed, Y_train], axis=1).corr()\nplt.figure(figsize=(22,16))\nsns.heatmap(corr, cmap='binary', annot=True)\nplt.show()","efc9d902":"from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score","ff4792e2":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(train_transformed, Y_train)","fee8b628":"validation_predicted = lr.predict(validation_transformed)","347a24f8":"precision_score(Y_validation, validation_predicted)","e877be61":"recall_score(Y_validation, validation_predicted)","6bd036ff":"f1_score(Y_validation, validation_predicted)","9404d4a0":"accuracy_score(Y_validation, validation_predicted)","decf5158":"from sklearn.model_selection import cross_val_score\nfrom hyperopt import hp, fmin, tpe, Trials, SparkTrials\nfrom hyperopt import space_eval\nfrom hyperopt.pyll.base import scope\n\nimport ray\nfrom ray import tune\nfrom ray.tune.suggest.hyperopt import HyperOptSearch\nfrom ray.tune.suggest import ConcurrencyLimiter\nfrom ray.tune import CLIReporter\n\nray.shutdown()\nray.init(num_cpus=2) # choose as many cpus as your machine supports to get a significant acceleration \n\nreporter = CLIReporter()","79257a26":"def ray_train(predictor):\n    def inner(params):\n        prd = predictor(**params)\n        score = cross_val_score(prd, train_transformed, Y_train, cv=5, scoring='f1')\n        result = np.mean(score)\n        tune.report(f1=result)\n    return inner","d17c5e32":"decision_tree_search_space = {\n    'max_depth': hp.quniform('max_depth', 2, 9, 1),\n    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 9, 1)),\n    'min_samples_leaf': hp.uniform('min_samples_leaf', 0.001, 0.5)\n}","5b5217a4":"from sklearn.tree import DecisionTreeClassifier\n\nalgo = HyperOptSearch(decision_tree_search_space, metric=\"f1\", mode=\"max\")\n\nanalysis = tune.run(ray_train(DecisionTreeClassifier),\n                    num_samples=100,\n                    search_alg=algo,\n                    progress_reporter=reporter)","3a26204e":"best_decision_tree_params = analysis.get_best_config(metric='f1', mode='max')\ndtc = DecisionTreeClassifier(**best_decision_tree_params)\ndtc.fit(train_transformed, Y_train)\nvalidation_predicted_decision_tree = dtc.predict(validation_transformed)\nf1_score(Y_validation, validation_predicted_decision_tree)","ffc8efef":"random_forest_search_space = {\n    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 4000, 100)),\n    'max_depth': hp.quniform('max_depth', 2, 9, 1),\n    'max_features': hp.choice('max_features', ['auto', 'sqrt', 'log2']),\n    'max_samples': hp.uniform('max_samples', 0, 1)\n}","4b891715":"from sklearn.ensemble import RandomForestClassifier\n\nalgo = HyperOptSearch(random_forest_search_space, metric=\"f1\", mode=\"max\")\n\nanalysis = tune.run(ray_train(RandomForestClassifier),\n                    num_samples=200,\n                    search_alg=algo,\n                    progress_reporter=reporter)\n","4454a776":"best_random_forest_params = analysis.get_best_config(metric='f1', mode='max')\nrfc = RandomForestClassifier(**best_random_forest_params)\nrfc.fit(train_transformed, Y_train)\nvalidation_predicted_random_forest = rfc.predict(validation_transformed)\nf1_score(Y_validation, validation_predicted_random_forest)","ed4595ef":"rfc = RandomForestClassifier(**best_random_forest_params)\nrfc.fit(pd.concat([train_transformed, validation_transformed]), pd.concat([Y_train, Y_validation]))\ntest_predicted_random_forest = rfc.predict(test_transformed)","8add53b9":"passenger_id = X_test[PASSENGERID]\nsubmission = pd.DataFrame({PASSENGERID: passenger_id, 'Survived': test_predicted_random_forest})\nsubmission.to_csv('submission.csv', index=False)","f7ebc3b4":"Now we can start training models","3398c95b":"We initialize ray","a3321487":"We create a relevant transformer class for each column"}}