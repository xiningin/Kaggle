{"cell_type":{"6305ed02":"code","5a2f3772":"code","2fd9414c":"code","2f7b1cc5":"code","3c84f42a":"code","aa436dd3":"code","39f800aa":"code","d63ca87d":"code","5c327895":"code","cf33480e":"code","d721cc6f":"code","88685e07":"code","a139d840":"code","56670296":"code","a3adfb95":"code","47f19c30":"code","d1f36b7e":"markdown","af5f0c00":"markdown","b0752a30":"markdown"},"source":{"6305ed02":"!pip install featurewiz","5a2f3772":"import featurewiz as FW","2fd9414c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport janestreet\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nkaggle_yes = True\nimport os\ni = 0\nfiles = []\nif kaggle_yes:\n    datapath = '\/kaggle\/input'\nelse:\n    datapath = '..\/Ram\/data_sets\/Janata_Hack_TS'\nfor dirname, _, filenames in os.walk(datapath):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n        print(files[i])\n        i += 1 ","2f7b1cc5":"train_df = pd.read_csv(files[3],nrows=400000)\nprint(train_df.shape)\ntrain_df.head(1)","3c84f42a":"target = 'resp'\ndate_col = 'date'\nid_col = 'ts_id'\nignore_cols = ['resp_1','resp_2','resp_3','resp_4']","aa436dd3":"train_df = train_df.fillna(-999)\ntrain_df.isnull().sum().sum()","39f800aa":"train_df.drop(ignore_cols,axis=1,inplace=True)","d63ca87d":"preds = [x for x in list(train_df) if x not in [target,'ts_id']]\nlen(preds)","5c327895":"from sklearn.preprocessing import StandardScaler","cf33480e":"env = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","d721cc6f":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.fillna(-999)\n    X_test = test_df[preds]\n    y_preds = FW.simple_XGBoost_model(X_XGB=train_df[preds], Y_XGB=train_df[target], \n                                  X_XGB_test=X_test, \n                     modeltype='Regression', \n                     log_y=False, GPU_flag=True, \n                     scaler=StandardScaler(), enc_method='label', verbose=0)\n    action = ((test_df['weight'].values * y_preds) > 0).astype('int')\n\n    sample_prediction_df.action = action\n    env.predict(sample_prediction_df)","88685e07":"test = pd.read_csv(files[2])\ntest = test.fillna(-999)\nprint(test.shape)\ntest.head()","a139d840":"y_preds1 = FW.simple_XGBoost_model(X_XGB=train_df[preds], Y_XGB=train_df[target], \n                                  X_XGB_test=test[preds], \n                     modeltype='Regression', \n                     log_y=False, GPU_flag=True, \n                     scaler=StandardScaler(), enc_method='label', verbose=0)  \ny_preds1 = ((test['weight'].values * y_preds1) > 0).astype('int')\ny_preds1","56670296":"y_preds1.mean()","a3adfb95":"subm = pd.read_csv(files[0])\nprint(subm.shape)\nsubm['action'] = y_preds1\nsubm.head()","47f19c30":"subm.to_csv('submission.csv',index=False)","d1f36b7e":"# Indebted to Nicholas Jelicic, creator of this notebook for making a Simple LR model to crack this problem\nhttps:\/\/www.kaggle.com\/njelicic\/linear-regression","af5f0c00":"\noutput = FW.featurewiz(orig_train, target, corr_limit=0.70,\n                    verbose=2, sep=',', header=0, test_data=orig_test,\n                    feature_engg='target', category_encoders='')","b0752a30":"# Similarly indebted to Jorijn Jacko Smit, creator of this notebook for using GroupkFold to crack this problem\nhttps:\/\/www.kaggle.com\/jorijnsmit\/found-the-holy-grail-grouptimeseriessplit"}}