{"cell_type":{"b4560273":"code","67358d30":"code","c950eb4e":"code","f12bbea8":"code","7b15e4ad":"code","48da8b2b":"code","3171307d":"code","f26609f9":"code","6b00c246":"code","447997a0":"code","13dec04c":"code","d2b1eeeb":"code","e13b252b":"code","1f67d6d6":"code","5acd094e":"code","df19c67d":"code","d69f5ee9":"code","477d5394":"code","19316d33":"code","4fb082c2":"code","b68410c0":"code","d1e5aa10":"code","ec6d175a":"code","1d60a50c":"code","4a4315e6":"code","4c395cb1":"code","09df5315":"code","d65b5688":"markdown","fa57ef9a":"markdown","42e03308":"markdown","4fb0721c":"markdown","f44fdf4c":"markdown","c77e3d37":"markdown","fdb92b51":"markdown","b03fabf3":"markdown","02610b1c":"markdown","6a34014e":"markdown","ceabd499":"markdown","a17d6049":"markdown","bea61938":"markdown","9a175585":"markdown","2d317ddd":"markdown","cb55c85e":"markdown","eaa86e28":"markdown","733b1527":"markdown"},"source":{"b4560273":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","67358d30":"#https:\/\/www.kaggle.com\/nagarajukuruva\/computer-vision-imageprocessing\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport warnings\nimport os\nimport pickle\n\nimport joblib\nfrom skimage.io import imread, imshow\nfrom tqdm import tqdm\nfrom skimage.transform import resize\n\n\nwarnings.filterwarnings('ignore')\npd.options.display.float_format = '{:,.2f}'.format\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 200)\n\n# import numpy as np\n# np.random.seed(1001)\nimport tensorflow as tf\nimport random\nSEED=26\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\nfrom sklearn.model_selection import train_test_split\n\n\n#from __future__ import print_function\nfrom keras.models import Model, Sequential, load_model\nfrom keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout\nfrom keras.datasets import mnist\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import Callback\n\nfrom imageio import imread\nfrom keras import activations\n#!pip install keras-vis\n#from vis.input_modifiers import Jitter\n#from vis.utils import utils\n#from vis.visualization import visualize_activation, get_num_filters\n\n\n## extra imports to set GPU options\nimport tensorflow as tf\nfrom keras import backend as k\n\n# ###################################\n# # TensorFlow wizardry\n# config = tf.ConfigProto()\n \n# # Don't pre-allocate memory; allocate as-needed\n# config.gpu_options.allow_growth = True\n \n# # Only allow a total of half the GPU memory to be allocated\n# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n \n# # Create a session with the above options specified.\n# k.tensorflow_backend.set_session(tf.Session(config=config))\n# ###################################","c950eb4e":"def reset_random_seeds():\n    import tensorflow as tf\n    import random\n    import random\n    os.environ['PYTHONHASHSEED']=str(26)\n    random.seed(26)\n    np.random.seed(26)\n    tf.random.set_seed(26)\nreset_random_seeds()","f12bbea8":"def smooth_curve(points, factor=0.8):\n    smoothed = []\n    for point in points:\n        if smoothed:\n            previous = smoothed[-1]\n            smoothed.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed.append(point)\n    return smoothed\n\ndef plot_compare(history, steps=-1):\n    if steps < 0:\n        steps = len(history.history['accuracy'])\n    acc = smooth_curve(history.history['accuracy'][:steps])\n    val_acc = smooth_curve(history.history['val_accuracy'][:steps])\n    loss = smooth_curve(history.history['loss'][:steps])\n    val_loss = smooth_curve(history.history['val_loss'][:steps])\n    \n    plt.figure(figsize=(6, 4))\n    plt.plot(loss, c='#0c7cba', label='Train Loss')\n    plt.plot(val_loss, c='#0f9d58', label='Val Loss')\n    plt.xticks(range(0, len(loss), 5))\n    plt.xlim(0, len(loss))\n    plt.title('Train Loss: %.3f, Val Loss: %.3f' % (loss[-1], val_loss[-1]), fontsize=12)\n    plt.legend()\n    \n    plt.figure(figsize=(6, 4))\n    plt.plot(acc, c='#0c7cba', label='Train Acc')\n    plt.plot(val_acc, c='#0f9d58', label='Val Acc')\n    plt.xticks(range(0, len(acc), 5))\n    plt.xlim(0, len(acc))\n    plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (acc[-1], val_acc[-1]), fontsize=12)\n    plt.legend()\n    \ndef deprocess_image(x):\n    # normalize tensor: center on 0., ensure std is 0.1\n    x -= x.mean()\n    x \/= (x.std() + 1e-5)\n    x *= 0.1\n\n    # clip to [0, 1]\n    x += 0.5\n    x = np.clip(x, 0, 1)\n\n    # convert to RGB array\n    x *= 255\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n \ndef save_history(history, fn):\n    with open(fn, 'wb') as fw:\n        pickle.dump(history.history, fw, protocol=2)\n\ndef load_history(fn):\n    class Temp():\n        pass\n    history = Temp()\n    with open(fn, 'rb') as fr:\n        history.history = pickle.load(fr)\n    return history\n\ndef jitter(img, amount=32):\n    ox, oy = np.random.randint(-amount, amount+1, 2)\n    return np.roll(np.roll(img, ox, -1), oy, -2), ox, oy\n\ndef reverse_jitter(img, ox, oy):\n    return np.roll(np.roll(img, -ox, -1), -oy, -2)\n\ndef plot_image(img):\n    plt.figure(figsize=(6, 6))\n    plt.imshow(img)\n    plt.axis('off')\n\ndef Image_reader_from_csv(path_of_image,image_colName,_df):\n    plt.figure(figsize=(15,20))\n    showAxis=430\n    for i in _df[image_colName].head(9):\n        #print(i)\n        ax_pos=1\n        showAxis=showAxis+ax_pos\n        ax1=plt.subplot(showAxis)\n        image = imread(path_of_image+'images\/'+i, as_gray=True)\n        image = imread(path_of_image+'images\/'+i) # as_gray to extend the pixel\n        imshow(image,ax=ax1)\n        ax1.set_title(i+'-shape'+str(image.shape))","7b15e4ad":"def Steps_1fitModel_2saveModel_3saveHistory(model_Version,train_gen,validation_gen,_model_design,ep_sz=3):\n    _model=_model_design\n    # simple early stopping\n    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n    STEP_SIZE_TRAIN=train_gen.n\/\/train_gen.batch_size\n    STEP_SIZE_VALID=validation_gen.n\/\/validation_gen.batch_size\n    _model_history=_model.fit_generator(generator=train_gen,\n                        steps_per_epoch=STEP_SIZE_TRAIN,\n                        validation_data=validation_gen,\n                        validation_steps=STEP_SIZE_VALID,\n                        verbose=1,\n                        epochs=ep_sz,\n                        callbacks=[es]\n    )\n\n    #_model.save()\n    modelFileName='model'+str(model_Version)+'.fit'\n    joblib.dump(_model, modelFileName)\n    save_history(_model_history, 'history'+str(model_Version)+'.bin')\n    del STEP_SIZE_TRAIN,STEP_SIZE_VALID,_model_history,_model\n    #return _model\n\n    \ndef load_andPlotHistoryForModelVersion(model_Version):\n    history = load_history('history'+str(model_Version)+'.bin')\n    plot_compare(history) \n    del history\n\ndef load_modelForModelVersion(model_Version):\n    model = load_model('history'+str(model_Version)+'.fit')\n    return model\n    \ndef make_prediction_generate_csv(modelVersion,test_gen,model):\n    STEP_SIZE_TEST=test_gen.n\/\/test_gen.batch_size\n    test_gen.reset()\n    pred=model.predict_generator(test_gen,steps=STEP_SIZE_TEST,verbose=1)\n\n    #pred.shape\n    def classLabing(x):\n        if x<.5:\n            return 0\n        else:\n            return 1\n    predictions=[classLabing(i) for i in pred]\n#     predicted_class_indices=np.argmax(pred,axis=1)\n#     len(predicted_class_indices)\n\n#     labels = (train_generator.class_indices)\n#     labels = dict((v,k) for k,v in labels.items())\n#     predictions = [labels[k] for k in predicted_class_indices]\n#     len(predictions)\n\n    filenames=test_gen.filenames\n    len(filenames)\n    results=pd.DataFrame({\"image_names\":filenames,\n                           \"emergency_or_not\":predictions})\n    print(results['emergency_or_not'].value_counts())\n    csv_name='results_model'+ str(modelVersion) +'.csv'\n    results.to_csv(csv_name,index=False)\n    print(\"\\n\\n\",csv_name,\" generated \\n\\n\")\n","48da8b2b":"import pandas as pd\nimg_path=\"\/kaggle\/input\/av-dataset\/train_SOaYf6m\/images\"\nsub=pd.read_csv(\"\/kaggle\/input\/av-dataset\/sample_submission_yxjOnvz.csv\")\ntrain=pd.read_csv(\"\/kaggle\/input\/av-dataset\/train_SOaYf6m\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/av-dataset\/test_vc2kHdQ.csv\")\nsub.head()","3171307d":"print(\"count of 0 and 1 in target columns:\\n\",train['emergency_or_not'].value_counts(), \"\\n\\nShape:\",train.shape,\"\\n\\n\")\nprint(train.head())\ntrain.isna().sum()","f26609f9":"trdf=train.copy()\ntrdf['emergency_or_not']=trdf['emergency_or_not'].astype('str')\ntrdf.head()","6b00c246":"print(\"\\n\\nShape:\",test.shape,\"\\n\\n\")\nprint(test.head())\ntest.isna().sum()","447997a0":"def prepareData(validationSplit=1):\n    from keras_preprocessing.image import ImageDataGenerator\n    test_datagen = ImageDataGenerator(rescale = 1.\/255)\n    \n    if validationSplit==1:\n        train_datagen = ImageDataGenerator(rescale = 1.\/255,validation_split=0.25)\n        train_generator=train_datagen.flow_from_dataframe(\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"training\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n\n        validation_generator=train_datagen.flow_from_dataframe(\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"validation\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n    elif validationSplit==0:\n        train_datagen = ImageDataGenerator(rescale = 1.\/255)\n        train_generator=train_datagen.flow_from_dataframe(\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"training\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n        validation_generator=\"\"\n    test_generator=test_datagen.flow_from_dataframe(\n                                    dataframe=test, \n                                    directory=img_path,\n                                    x_col=\"image_names\",\n                                    #subset=\"testing\",\n                                    y_col=None,\n                                    seed=42,\n                                    shuffle=False,\n                                    class_mode=None,\n                                    target_size=(224,224), \n                                    batch_size=2)\n    return train_generator,validation_generator,test_generator\n#train_generator,validation_generator,test_generator=prepareData()\n#del train_generator,validation_generator,test_generator\n#test_generator\n","13dec04c":"def prepareAugmentedData(validation_split=1):\n    from keras_preprocessing.image import ImageDataGenerator\n    test_datagen = ImageDataGenerator(rescale = 1.\/255)\n    if validation_split==1:\n        train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                 validation_split=0.25,\n                                 shear_range = 0.2,\n                                 featurewise_center=False,            ## Set input mean to 0 over the dataset\n                                 samplewise_center=False,             ## Set each sample mean to 0\n                                 featurewise_std_normalization=False, ## Divide inputs by std of the dataset\n                                 samplewise_std_normalization=False,  ## Divide each input by its std\n                                 zca_whitening=False,                 ## Apply ZCA whitening\n                                 rotation_range=10,                   ## Randomly rotate images in the range (degrees, 0 to 180)\n                                 zoom_range = 0.2,                    ## Randomly zoom image \n                                 width_shift_range=0.1,               ## Randomly shift images horizontally (fraction of total width)\n                                 height_shift_range=0.1,              ## Randomly shift images vertically (fraction of total height)\n                                 horizontal_flip=True,               ## Randomly flip images horizontally\n                                 vertical_flip=True)                 ## Randomly flip images vertically\n\n        train_generator=train_datagen.flow_from_dataframe(\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"training\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n        validation_generator=train_datagen.flow_from_dataframe(\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"validation\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n    elif validation_split==0:\n        #train Not splittling into validation dataset\n        train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                 featurewise_center=False,            ## Set input mean to 0 over the dataset\n                                 samplewise_center=False,             ## Set each sample mean to 0\n                                 featurewise_std_normalization=False, ## Divide inputs by std of the dataset\n                                 samplewise_std_normalization=False,  ## Divide each input by its std\n                                 zca_whitening=False,                 ## Apply ZCA whitening\n                                 rotation_range=10,                   ## Randomly rotate images in the range (degrees, 0 to 180)\n                                 zoom_range = 0.1,                    ## Randomly zoom image \n                                 width_shift_range=0.1,               ## Randomly shift images horizontally (fraction of total width)\n                                 height_shift_range=0.1,              ## Randomly shift images vertically (fraction of total height)\n                                 horizontal_flip=False,               ## Randomly flip images horizontally\n                                 vertical_flip=False)                 ## Randomly flip images vertically\n        train_generator=train_datagen.flow_from_dataframe(\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"training\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n        validation_generator = ''\n    test_generator=test_datagen.flow_from_dataframe(\n                                    dataframe=test, \n                                    directory=img_path,\n                                    x_col=\"image_names\",\n                                    y_col=None,\n                                    seed=42,\n                                    shuffle=False,\n                                    class_mode=None,\n                                    target_size=(224,224), \n                                    batch_size=2)\n    return train_generator,validation_generator,test_generator\n#del \n#train_generator,validation_generator,test_generator=prepareData()\n#test_generator","d2b1eeeb":"def generate_data(augment=1,validation_split=1):\n    if augment == 0:\n        return prepareData(validation_split)\n    elif augment == 1:\n        return prepareAugmentedData(validation_split)\ntrain_generator,validation_generator,test_generator=generate_data(augment=0,validation_split=1)\n#del train_generator,validation_generator,test_generator","e13b252b":"def numba():\n    from numba import cuda\n    cuda.select_device(0)\n    cuda.close()\n#numba()\nimport gc\ngc.collect()","1f67d6d6":"def execute_Model_v16():\n    \"\"\"\n    This is different from model_call1 \n    Here train_Generater are prequisite\n    \"\"\"\n    import gc    \n    for lr in [.001]:\n        for i in range(15): gc.collect()\n        SEED=26\n        os.environ['PYTHONHASHSEED']=str(SEED)\n        random.seed(SEED)\n        np.random.seed(SEED)\n        tf.random.set_seed(SEED)\n\n\n        val_losslog_score=[]\n        val_acc_score=[]\n        train_losslog_score=[]\n        train_acc_score=[]\n\n        runs=1\n        print(\"Runs planned = \",runs)\n        for run_iter in range(0,runs):\n            print(\"------- Executing run :\",run_iter+1 )\n            model = Sequential()\n            val_score,train_score=Model_v16(train_generator,validation_generator,test_generator,\"3\",model,lr,0,1)\n            \n            val_losslog_score.append(val_score[0])\n            val_acc_score.append(val_score[1])\n            train_losslog_score.append(train_score[0])\n            train_acc_score.append(train_score[1])\n            print(val_score,train_score)\n            del val_score\n        print(\"Train (loss_log,acc) of \",runs,\"runs:\",np.mean(train_losslog_score),np.mean(train_acc_score))\n        print(\"Valid (loss_log,acc) of \",runs,\"runs:\",np.mean(val_losslog_score),np.mean(val_acc_score))\n\n        del model,train_losslog_score,train_acc_score,val_losslog_score,val_acc_score\n        for i in range(15): gc.collect()\n","5acd094e":"#kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))\ndef Model_v16(train_generator,validation_generator,test_generator,model_Version_text,model,_lr=.03,augment=0,generate_test_csv=1):\n    # Initialising the CNN\n    print(\"----------------------------------------Learning Rate:\",_lr )\n    for i in range(15): gc.collect()    \n    \n    model.add(Conv2D(20, (3,3), activation='relu', padding='same', name='conv_1',input_shape=(224, 224, 3)\n            , kernel_regularizer=l2(0.0001),bias_regularizer=l2(0.05)))\n    \n    model.add(Conv2D(50, (3,3), activation='relu', padding='same', name='conv_12',input_shape=(224, 224, 2)\n           , kernel_regularizer=l2(0.0001),bias_regularizer=l2(0.05) ))\n    model.add(MaxPooling2D((2, 2), name='maxpool_1'))  # DownSampling\n    model.add(Conv2D(50, (3,3), activation='relu', padding='same', name='conv_13',input_shape=(224, 224, 2)\n       , kernel_regularizer=l2(0.0001),bias_regularizer=l2(0.0005) ))\n    #model.add(BatchNormalization(name='batchNormalisation'))\n    #,kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)\n    #model.add(SeparableConv2D(120,(5,5), activation='relu', padding='same', name='Sepconv_1_1'))\n    #model.add(BatchNormalization(name='batchNormalisation1'))\n    #model.add(Dropout(0.5))\n    \n    #model.add(Conv2D(60, (3,3), activation='relu', padding='same', name='conv_13',input_shape=(224, 224, 1)\n     #       ))\n    #model.add(MaxPooling2D((2, 2), name='maxpool_2'))\n    #model.add(Dropout(0.05))\n    #model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='conv_1_1',\n    #                 kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01)))\n    #model.add(Conv2D(16, (3, 3), activation='relu', padding='same', name='conv_1_2'))\n    \n    #model.add(Dropout(0.15))\n    #model.add(MaxPooling2D((2, 2), name='maxpool_2'))  # DownSampling\n    model.add(Dropout(0.1))\n    #model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1_2'))\n    #model.add(Dropout(0.1))\n    #model.add(MaxPooling2D((2, 2), name='maxpool_2'))\n    model.add(Flatten())\n    \n    #  drop outs\n    model.add(Dropout(0.1))\n    \n    #model.add(Dense(30, activation='relu', name='dense1'))\n    #model.add(Dropout(0.8))\n    #model.add(Dense(100, activation='relu', name='dense2'))\n    \n    #model.add(Dropout(0.40))\n    model.add(Dense(1, activation='sigmoid', name='output'))\n\n    \n    optimizer=1\n    # Model compilation\n    def compileModel(Adam_orRMSProp=2):\n        if Adam_orRMSProp ==2:\n            RMSprp=tf.keras.optimizers.RMSprop(\n            learning_rate=0.0001, rho=0.99, momentum=0.4, epsilon=1e-010, centered=True,\n            name='RMSprop'\n            )\n            model.compile(optimizer=RMSprp, loss='binary_crossentropy', metrics=['accuracy'])\n        else:\n            model.compile(optimizer=Adam(lr=.001), loss='binary_crossentropy', metrics=['accuracy'])\n    compileModel(optimizer)\n    # model fit and then save model and save history\n    Steps_1fitModel_2saveModel_3saveHistory(model_Version_text,train_generator,validation_generator,model,7)\n    \n    # plot modelfit history\n    load_andPlotHistoryForModelVersion(model_Version_text)\n    \n    # load model from file\n    \n    loaded_model_fromFile= joblib.load('model' + str(model_Version_text)+ \".fit\")\n    #if Optimiser is RMSprop, we need to recomple the model after loading from file... but not for Adam\n    if optimizer ==2 :\n        loaded_model_fromFile.compile(optimizer=RMSprp, loss='binary_crossentropy', metrics=['accuracy'])\n    # Evaluate validattion data set from the file loaded from saved file\n    # Evaluation matrix logloss, accuracy\n    STEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size\n    val_score=loaded_model_fromFile.evaluate_generator(generator=validation_generator,steps=STEP_SIZE_VALID)\n\n    STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\n    train_score=loaded_model_fromFile.evaluate_generator(generator=train_generator,steps=STEP_SIZE_TRAIN)\n    \n    # making prediction on test data\n    if generate_test_csv==1:\n        make_prediction_generate_csv(1,test_generator,loaded_model_fromFile)\n        \n    model.summary()\n    gc.collect()\n    del model,loaded_model_fromFile,train_generator,validation_generator,test_generator,STEP_SIZE_VALID,model_Version_text\n    gc.collect()\n    return val_score,train_score\n","df19c67d":"import gc\n# from keras.models import Model\n# from keras.layers import Dense\nfrom keras.optimizers import RMSprop\n# from keras.layers import Flatten,Input\n# from keras.layers import Dense, Dropout, Activation\n# from tensorflow.keras import activations\nfrom keras.regularizers import l2\n# from keras.layers import Conv2D, SeparableConv2D, Dense, Flatten, concatenate, multiply, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Input\nexecute_Model_v16()","d69f5ee9":"img_path","477d5394":"label_col=\"emergency_or_not\"\ndef import_vgg16_predict_training_data():\n    # This will load the whole VGG16 network, including the top Dense layers.\n    # Note: by specifying the shape of top layers, input tensor shape is forced\n    # to be (224, 224, 3), therefore you can use it only on 224x224 images.\n    \n    from tensorflow.keras.preprocessing.image import load_img,img_to_array\n    from keras.applications.resnet50 import preprocess_input,decode_predictions\n    from keras.models import Model\n    from keras.layers import Dense\n    from keras.layers import Flatten\n    from keras.layers import Dense, Dropout, Activation\n    from tensorflow.keras import activations\n    from keras.regularizers import l2\n    from keras.layers import Conv2D, SeparableConv2D, Dense, Flatten, concatenate, multiply, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Input\n    # Making predicton on training data with class 1 data using VGA model\n\n    #img_Fullpath=img_path+\"10.jpg\"\n    def ImageShow(imageFull_path,showAxis=111):\n        ax1=plt.subplot(showAxis)\n        ax1.figsize=(17,18)\n        image = imread(imageFull_path)\n        imshow(image,ax=ax1)\n        ax1.set_title('shape'+str(image.shape))\n    #ImageShow(img_Fullpath)\n\n    def predictionTrainingClass1Data(_model):\n        vgg16_pred=[]\n        img_loc=0\n        img_axis=220\n        for img in train[train[label_col]==1].image_names.head(4):\n\n            # Step 2- Image pre-processing\n            #img_path=img_path\n            image = load_img(img_path+\"\/\"+img, target_size=(224, 224))\n            # convert the image pixels to a numpy array\n            image = img_to_array(image)\n            # reshape data for the model\n            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n            # prepare the image for the VGG model\n            image = preprocess_input(image)\n\n            # Step 3- prediction\n            yhat = _model.predict(image)\n            # convert the probabilities to class labels\n            label = decode_predictions(yhat)\n            # retrieve the most likely result, e.g. highest probability\n            label = label[0][0][1]\n            img_loc=img_loc+1\n            print(img,\" is  predicted as \",label)\n            vgg16_pred.append(label)\n            ImageShow(img_path+\"\/\"+img,img_axis+img_loc)\n\n    # example of loading the vgg16 model\n    from keras.applications.vgg16 import VGG16\n    \n    # Step 1- load model\n    model = VGG16(weights='imagenet',input_shape=(224, 224, 3),include_top=True)\n    # summarize the model\n    #model.summary()\n    # Let pridict the first 5 images of training data with class1 \n    import gc \n    \n    predictionTrainingClass1Data(model)\n    gc.collect()\n    del model\n    gc.collect()\n    \n#del model    \nimport_vgg16_predict_training_data()","19316d33":"# create an empty python list\nX = []\n\n# go through all the image locations one by one\nfor img_name in train.image_names:\n    # read the image from location\n    image_path = img_path +\"\/\"+ img_name\n    img = plt.imread(image_path)\n    # pile it one over the other\n    X.append(img)\n    \n# convert this python list to a single numpy array\n#X = np.array(X)\n\n# create an empty python list\nX_test = []\n\n# go through all the image locations one by one\nfor img_name in test.image_names:\n    image_path = img_path +\"\/\"+ img_name\n    # read the image from location\n    img = plt.imread(image_path)\n    # pile it one over the other\n    X_test.append(img)\n    \n# convert this python list to a single numpy array\n#X = np.array(X)","4fb082c2":"\n# convert this python list to a single numpy array\nX = np.array(X)\nX_test = np.array(X_test)        \n\n#getting the labels for images\ny = train.emergency_or_not.values\n\n\n#show maximum and minimum values for the image array\nprint(\"min,max Before Preprocess:\",X.min(), X.max())\n\n#preprocess input images accordiing to requirements of VGG16 model ** Important step\nX = preprocess_input(X, mode='tf')\nX_test = preprocess_input(X_test, mode='tf')\n\n# See the data after preprocessing data\nprint(\"min,max After Preprocess:\",X.min(), X.max())\n\n# splitting the dataset into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n","b68410c0":"def import_vgg16_predict_training_data2():\n        #     # Making predicton on training data with class 1 data using VGA model\n    img_path=\"\/kaggle\/input\/train_SOaYf6m\/images\/\"\n    def makingPrediction(_model):\n        vgg16_pred=[]\n        for img in train[train[label_col]==1].image_names:\n\n            # Step 2- Image pre-processing\n            image = load_img(img_path+img, target_size=(224, 224))\n            # convert the image pixels to a numpy array\n            image = img_to_array(image)\n            # reshape data for the model\n            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n            # prepare the image for the VGG model\n            image = preprocess_input(image)\n\n            # Step 3- makeing prediction\n            yhat = _model.predict(image)\n            # convert the probabilities to class labels\n            label = decode_predictions(yhat)\n            # retrieve the most likely result, e.g. highest probability\n            label = label[0][0][1]\n            print(img,\" is \",label)\n            vgg16_pred.append(label)\n            return vgg16_pred\n    img_Fullpath=img_path+\"10.jpg\"\n    def ImageShow(imageFull_path,showAxis=111):\n        ax1=plt.subplot(showAxis)\n        ax1.figsize=(8,8)\n        image = imread(imageFull_path)\n        imshow(image,ax=ax1)\n        ax1.set_title('shape'+str(image.shape))\n    #ImageShow(img_Fullpath)\n    \n    \n    \n    \n    #----------------------------------------------------MAIN FUNCTION PART -------------------------------------#\n\n    # Step 1------------ Set the Base model as VGG16\n    # Dont inclue Top and the your personal data input size\n    #input_tensor = Input(shape=(224, 224, 3))\n    base_model = VGG16(weights='imagenet',input_shape=(224, 224, 3),include_top=False)\n    print('Model loaded.')\n\n    # Extract the last layer of VGG16\n    vgg16_output = base_model.output\n    base_model.summary()\n    \n    img_name\n    # step 2 -------------Lets chain into new mode\n    flatten = (Dropout(0.5))(vgg16_output)\n    flatten = Flatten(name='flatten')(flatten)\n    flatten = (Dropout(0.5))(flatten)\n    dense = Dense(132, activation='relu', kernel_initializer='he_normal', name='fc1')(flatten)\n    dense = Dense(64, activation='relu', kernel_initializer='he_normal', name='fc2')(dense)\n    pred = Dense(units=1, activation='sigmoid', name='prediction')(dense)\n\n    # Lets build the new bodel#\n    new_model = Model(input=base_model.input, output=pred)\n    new_model.summary()\n\n    # set the first 25 layers (up to the last conv block)\n    # to non-trainable (weights will not be updated)\n    # To \"freeze\" a layer means to exclude it from training\n    for layer in new_model.layers:\n       if layer.name in ['fc1', 'fc2', 'prediction']:\n           continue\n    layer.trainable = False\n\n    # compile the model with a SGD\/momentum optimizer\n    #from keras import optimizers\n    optimizer=Adam(lr=.0001)\n    new_model.compile(optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n    # train model using features generated from VGG16 model\n    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n    new_model.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid),callbacks=[es])\n    #optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n    #,\n    #\n    #new_model.summary()\n    #Steps_1fitModel_2saveModel_3saveHistory(1,new_model,15)\n    return new_model\n    \nnew_model= import_vgg16_predict_training_data2()","d1e5aa10":"def prepareData(validationSplit=1):\n    from keras_preprocessing.image import ImageDataGenerator\n    test_datagen = ImageDataGenerator(rescale = 1.\/255)\n    \n    if validationSplit==1:\n        train_datagen = ImageDataGenerator(rescale = 1.\/255,validation_split=0.25)\n        train_generator=train_datagen.flow_from_dataframe(\n                                        preprocessing_function=preprocess_input,\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"training\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n\n        validation_generator=train_datagen.flow_from_dataframe(\n                                        preprocessing_function=preprocess_input,\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"validation\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n    elif validationSplit==0:\n        train_datagen = ImageDataGenerator(rescale = 1.\/255)\n        train_generator=train_datagen.flow_from_dataframe(\n                                        preprocessing_function=preprocess_input,\n                                        dataframe=trdf, \n                                        directory=img_path, \n                                        x_col=\"image_names\", \n                                        subset=\"training\",\n                                        seed=42,\n                                        shuffle=False,\n                                        y_col=\"emergency_or_not\", \n                                        class_mode=\"binary\", \n                                        target_size=(224,224), \n                                        batch_size=16)\n        validation_generator=\"\"\n    test_generator=test_datagen.flow_from_dataframe(\n                                    preprocessing_function=preprocess_input,\n                                    dataframe=test, \n                                    directory=img_path,\n                                    x_col=\"image_names\",\n                                    #subset=\"testing\",\n                                    y_col=None,\n                                    seed=42,\n                                    shuffle=False,\n                                    class_mode=None,\n                                    target_size=(224,224), \n                                    batch_size=2)\n    return train_generator,validation_generator,test_generator\ntrain_generator,validation_generator,test_generator=prepareData()\n#del train_generator,validation_generator,test_generator\n#test_generator\n","ec6d175a":"def pickFewTopLayers_TransferLearning_VGA16(PoollayerName_toPick=\"block2_pool\",pickLayer=1):\n    # download Vgg16 model\n    vgg_model = VGG16(weights='imagenet',\n                                   include_top=False,\n                                   input_shape=(224, 224, 3))\n    \n    # Creating dictionary that maps layer names to the layers\n    layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n    if pickLayer ==0:\n\n        \n        \n        # Getting output tensor of the last VGG layer that we want to include\n        print(vgg_model.input)\n        #print(vgg_model.layers)\n        print(vgg_model.summary())\n        print(vgg_model.output)\n        \n        print(\"Vgg model layers list.......\\n\")\n        print(list(layer_dict))\n    elif  pickLayer ==1:\n        x = layer_dict[PoollayerName_toPick].output\n        # Stacking a new simple convolutional network on top of it    \n        #x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu',name=\"MyConv_layer\")(x)\n        #x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Flatten()(x)\n        x = Dropout(0.5)(x)\n        x = Dense(32, activation='relu')(x)\n        x = Dropout(0.5)(x)\n        x = Dense(1, activation='softmax')(x)\n\n        # Creating new model. Please note that this is NOT a Sequential() model.\n        from keras.models import Model\n        custom_model = Model(input=vgg_model.input, output=x)\n        # Make sure that the pre-trained bottom layers are not trainable\n        \n        # freezing layers taken from pretrained model ( transfer learning)\n            # Finding the Index\n        layerList=list(layer_dict)\n        for i in range(0,len(layerList)):\n            if layerList[i]==PoollayerName_toPick:\n                layerIndex=i+1\n            # Freeze all layers till the given layer name\n        for layer in custom_model.layers[:layerIndex]:\n            layer.trainable = False\n            \n        #custom_model.trainable = True\n        #custom_model.summary()\n        # Model compilation\n        custom_model.compile(optimizer=Adam(lr=.001), loss='binary_crossentropy', metrics=['accuracy'])\n        Steps_1fitModel_2saveModel_3saveHistory(1,train_generator,validation_generator,custom_model,15)\n        del custom_model,vgg_model\n#pickFewTopLayers_TransferLearning_VGA16('block2_pool',pickLayer=1)","1d60a50c":"def import_vgg16_predict_training_data2_withoutWeight():\n        #     # Making predicton on training data with class 1 data using VGA model\n    img_path=\"\/kaggle\/input\/train_SOaYf6m\/images\/\"\n    def makingPrediction(_model):\n        vgg16_pred=[]\n        for img in train[train[label_col]==1].image_names:\n\n            # Step 2- Image pre-processing\n            image = load_img(img_path+img, target_size=(224, 224))\n            # convert the image pixels to a numpy array\n            image = img_to_array(image)\n            # reshape data for the model\n            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n            # prepare the image for the VGG model\n            image = preprocess_input(image)\n\n            # Step 3- makeing prediction\n            yhat = _model.predict(image)\n            # convert the probabilities to class labels\n            label = decode_predictions(yhat)\n            # retrieve the most likely result, e.g. highest probability\n            label = label[0][0][1]\n            print(img,\" is \",label)\n            vgg16_pred.append(label)\n            return vgg16_pred\n    img_Fullpath=img_path+\"10.jpg\"\n    def ImageShow(imageFull_path,showAxis=111):\n        ax1=plt.subplot(showAxis)\n        ax1.figsize=(8,8)\n        image = imread(imageFull_path)\n        imshow(image,ax=ax1)\n        ax1.set_title('shape'+str(image.shape))\n    #ImageShow(img_Fullpath)\n    \n    \n    #----------------------------------------------------MAIN FUNCTION PART -------------------------------------#\n\n    # Step 1------------ Set the Base model as VGG16\n    # Dont inclue Top and the your personal data input size\n    input_tensor = Input(shape=(224, 224, 3))\n    base_model = VGG16(weights=None,input_shape=(224, 224, 3),include_top=False)\n    print('Model loaded.')\n\n    # Extract the last layer of VGG16\n    vgg16_output = base_model.output\n\n    # step 2 -------------Lets chain into new mode\n    flatten = (Dropout(0.5))(vgg16_output)\n    flatten = Flatten(name='flatten')(flatten)\n    flatten = (Dropout(0.5))(flatten)\n    #dense = Dense(32, activation='relu', kernel_initializer='he_normal', name='fc1')(flatten)\n    #dense = Dense(32, activation='relu', kernel_initializer='he_normal', name='fc2')(dense)\n    pred = Dense(units=1, activation='softmax', kernel_initializer='he_normal', name='prediction')(flatten)\n\n    # Lets build the new bodel\n    new_model = Model(input=base_model.input, output=pred)\n    #new_model.summary()\n\n    # set the first 25 layers (up to the last conv block)\n    # to non-trainable (weights will not be updated)\n    # To \"freeze\" a layer means to exclude it from training\n    for layer in new_model.layers:\n        #if layer.name in ['fc1', 'fc2', 'prediction']:\n        #    continue\n        layer.trainable = True\n\n    # compile the model with a SGD\/momentum optimizer\n    from keras import optimizers\n    new_model.compile(loss='binary_crossentropy',\n    #optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n    optimizer=optimizers.Adam(lr=.001),\n    metrics=['accuracy'])\n    #new_model.summary()\n    Steps_1fitModel_2saveModel_3saveHistory(1,train_generator,validation_generator,new_model,15)\n    \nimport_vgg16_predict_training_data2_withoutWeight()","4a4315e6":"def import_vgg16_predict_training_data2_withoutWeight(PoollayerName_toPick=\"block2_pool\",pickLayer=1):\n        #     # Making predicton on training data with class 1 data using VGA model\n    img_path=\"\/kaggle\/input\/train_SOaYf6m\/images\/\"\n    def makingPrediction(_model):\n        vgg16_pred=[]\n        for img in train[train[label_col]==1].image_names:\n\n            # Step 2- Image pre-processing\n            image = load_img(img_path+img, target_size=(224, 224))\n            # convert the image pixels to a numpy array\n            image = img_to_array(image)\n            # reshape data for the model\n            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n            # prepare the image for the VGG model\n            image = preprocess_input(image)\n\n            # Step 3- makeing prediction\n            yhat = _model.predict(image)\n            # convert the probabilities to class labels\n            label = decode_predictions(yhat)\n            # retrieve the most likely result, e.g. highest probability\n            label = label[0][0][1]\n            print(img,\" is \",label)\n            vgg16_pred.append(label)\n            return vgg16_pred\n    img_Fullpath=img_path+\"10.jpg\"\n    def ImageShow(imageFull_path,showAxis=111):\n        ax1=plt.subplot(showAxis)\n        ax1.figsize=(8,8)\n        image = imread(imageFull_path)\n        imshow(image,ax=ax1)\n        ax1.set_title('shape'+str(image.shape))\n    #ImageShow(img_Fullpath)\n    \n\n#         layerList=list(layer_dict)\n#         for i in range(0,len(layerList)):\n#             if layerList[i]==PoollayerName_toPick:\n#                 layerIndex=i+1\n#             # Freeze all layers till the given layer name\n#         for layer in custom_model.layers[:layerIndex]:\n#             layer.trainable = False\n            \n    \n    \n    \n    #----------------------------------------------------MAIN FUNCTION PART -------------------------------------#\n\n    # Step 1------------ Set the Base model as VGG16\n    # Dont inclue Top and the your personal data input size\n    input_tensor = Input(shape=(224, 224, 3))\n    base_model = VGG16(weights=None,input_shape=(224, 224, 3),include_top=False)\n    print('Model loaded.')\n\n    # Extract the last layer of VGG16\n    layer_dict = dict([(layer.name, layer) for layer in base_model.layers])\n    vgg16_output = layer_dict[PoollayerName_toPick].output\n\n    # step 2 -------------Lets chain into new mode\n    flatten = (Dropout(0.5))(vgg16_output)\n    flatten = Flatten(name='flatten')(flatten)\n    flatten = (Dropout(0.5))(flatten)\n    #dense = Dense(32, activation='relu', kernel_initializer='he_normal', name='fc1')(flatten)\n    #dense = Dense(32, activation='relu', kernel_initializer='he_normal', name='fc2')(dense)\n    pred = Dense(units=1, activation='softmax', kernel_initializer='he_normal', name='prediction')(flatten)\n\n    # Lets build the new bodel\n    new_model = Model(input=base_model.input, output=pred)\n    #new_model.summary()\n\n    # set the first 25 layers (up to the last conv block)\n    # to non-trainable (weights will not be updated)\n    # To \"freeze\" a layer means to exclude it from training\n    for layer in new_model.layers:\n        layer.trainable = True\n\n    # compile the model with a SGD\/momentum optimizer\n    from keras import optimizers\n    new_model.compile(loss='binary_crossentropy',\n    #optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n    optimizer=optimizers.Adam(lr=.0000000001),\n    metrics=['accuracy'])\n    #new_model.summary()\n    Steps_1fitModel_2saveModel_3saveHistory(1,train_generator,validation_generator,new_model,5)\n    \nimport_vgg16_predict_training_data2_withoutWeight()","4c395cb1":"from kerastuner import HyperModel\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    Dense,\n    Dropout,\n    Flatten,\n    MaxPooling2D\n)\n\nclass CNNHyperModel(HyperModel):\n\n    def __init__(self, input_shape, num_classes):\n        \n        self.input_shape = input_shape\n        self.num_classes = num_classes\n\n    def build(self, hp):\n        print(\"\\n\\n---------------------------------------- Architechting Keras Model ------------------------------\\n\\n\")\n        #print(\"step 1.model initialisation \")\n        model = keras.Sequential()\n        \n        #print(\"step 2.  Conv2D layer 1 \")\n        hp_filters=hp.Choice('num_filters',values=[20,24,28,32],default=32)\n        model.add(\n            Conv2D(\n                filters=hp_filters,\n                kernel_size=3,\n                activation='relu',\n                input_shape=self.input_shape\n            )\n        )\n        model.add(\n        Dropout(rate=hp.Float(\n            'dropout_1',\n            min_value=0.0,\n            max_value=0.5,\n            default=0.25,\n            step=0.05,\n        ))\n    )\n        model.add(MaxPooling2D((2, 2), name='maxpool_4'))\n        model.add(\n        Dropout(rate=hp.Float(\n            'dropout_2',\n            min_value=0.0,\n            max_value=0.5,\n            default=0.25,\n            step=0.05,\n        ))\n    )\n#         model.add(layers.Dense(units=hp.Int('units',\n#                                     min_value=32,\n#                                     max_value=512,\n#                                     step=32),\n#                        activation='relu'))\n        \n#         #print(\"step 2.  Conv2D layer 2 \")\n#         model.add(\n#             Conv2D(\n#                 filters=16,\n#                 activation='relu',\n#                 kernel_size=3\n#             )\n#         )\n        \n#         #print(\"step 2.  max Pooling layaer 1 \")\n#         model.add(MaxPooling2D(pool_size=2))\n#         model.add(\n#             Dropout(rate=hp.Float(\n#                 'dropout_1',\n#                 min_value=0.0,\n#                 max_value=0.5,\n#                 default=0.25,\n#                 step=0.05,\n#             ))\n#         )\n        \n#         #print(\"step 3.  Conv2D layer 1 \")\n#         model.add(\n#             Conv2D(\n#                 filters=32,\n#                 kernel_size=3,\n#                 activation='relu'\n#             )\n#         )\n        #print(\"step 3.  Conv2D layer 2 \")\n#         model.add(\n#             Conv2D(\n#                 filters=hp.Choice(\n#                     'num_filters',\n#                     values=[32, 64],\n#                     default=64,\n#                 ),\n#                 activation='relu',\n#                 kernel_size=3\n#             )\n#         )\n#         #print(\"step 3.  MaxPooling2D 2 \")\n#         model.add(MaxPooling2D(pool_size=2))\n        \n        \n#         model.add(\n#             Dropout(rate=hp.Float(\n#                 'dropout_2',\n#                 min_value=0.0,\n#                 max_value=0.5,\n#                 default=0.25,\n#                 step=0.05,\n#             ))\n#         )\n        \n        model.add(Flatten())\n#         model.add(\n#             Dense(\n#                 units=hp.Int(\n#                     'units',\n#                     min_value=32,\n#                     max_value=512,\n#                     step=32,\n#                     default=128\n#                 ),\n#                 activation=hp.Choice(\n#                     'dense_activation',\n#                     values=['relu', 'tanh', 'sigmoid'],\n#                     default='relu'\n#                 )\n#             )\n#         )\n        \n#         model.add(\n#             Dropout(\n#                 rate=hp.Float(\n#                     'dropout_3',\n#                     min_value=0.0,\n#                     max_value=0.5,\n#                     default=0.25,\n#                     step=0.05\n#                 )\n#             )\n#         )\n#         #print(\"drop out\/ Flattening\/drop out setting done\")\n        \n        model.add(Dense(self.num_classes, activation='softmax'))\n\n        model.compile(\n            optimizer=keras.optimizers.Adam(\n                hp.Float(\n                    'learning_rate',\n                    min_value=.0008,\n                    max_value=.001,\n                    #sampling='LOG',\n                    default=.005\n                )\n            ),\n            loss='binary_crossentropy',\n            metrics=['accuracy']\n        )\n        print(\"final dense layer added \")\n        return model\nNUM_CLASSES = 1  # cifar10 number of classes\nimport gc\ngc.collect()\n#del train_generator,validation_generator,test_generator#,best_model,tuner,hypermodel\ngc.collect()\n\nINPUT_SHAPE = (224, 224, 3)  # cifar10 images input shape\nhypermodel1 = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n\nfrom kerastuner.tuners import RandomSearch\n\ntuner = RandomSearch(\n    hypermodel1,\n    objective='val_accuracy',\n    seed=SEED,\n    max_trials=5,\n    executions_per_trial=2,\n    directory='random_search',\n    project_name='cifar10'\n)\n# from kerastuner.tuners import Hyperband\n# tuner = Hyperband(\n#     hypermodel,\n#     max_epochs=10,\n#     objective='val_accuracy',\n#     seed=26,\n#     executions_per_trial=2,\n#     directory='hyperband',\n#     project_name='cifar10'\n# )\n\ntrain_generator,validation_generator,test_generator=prepareAugmentedData()\ntuner.search(train_generator, steps_per_epoch=1, epochs=5, validation_data=validation_generator)\n# Show a summary of the search and evaluating the best model\n#best_model = tuner.get_best_models(num_models=1)[0]\n#best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n#print(best_hps.get('learning_rate'))\n#STEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size\n#print(best_model.evaluate_generator(generator=validation_generator,steps=STEP_SIZE_VALID))\n#best_model.summary()","09df5315":"best_model = tuner.get_best_models(num_models=1)[0]\nbest_model.summary()","d65b5688":"# Method to prepare and generated Augement data","fa57ef9a":"# To kill the processes of kaggle notebook","42e03308":"# Transfer learning using VGA16","4fb0721c":"# Keras Data preparation","f44fdf4c":"## What is loss function?\n\nWe define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications called the \"categorical_crossentropy\".\n\nThe most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n\nI choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.\n\nThe metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).","c77e3d37":"# problem Statment\nEmergency vs Non-Emergency Vehicle Classification\nFatalities due to traffic delays of emergency vehicles such as ambulance & fire brigade is a huge problem. In daily life, we often see that emergency vehicles face difficulty in passing through traffic. So differentiating a vehicle into an emergency and non emergency category can be an important component in traffic monitoring as well as self drive car systems as reaching on time to their destination is critical for these services.\n\n![image.png](attachment:image.png)\n\nIn this problem, you will be working on classifying vehicle images as either belonging to the emergency vehicle or non-emergency vehicle category. For the same, you are provided with the train and the test dataset. Emergency vehicles usually includes police cars, ambulance and fire brigades.\n\n\n\n\nData Description\ntrain.zip: contains 2 csvs and 1 folder containing image data\ntrain.csv \u2013 [\u2018image_names\u2019, \u2018emergency_or_not\u2019] contains the image name and correct class for 1646 (70%) train images\nimages \u2013 contains 2352 images for both train and test sets\ntest.csv: [\u2018image_names\u2019] contains just the image names for the 706 (30%) test images\nsample_submission.csv: [\u2018image_names\u2019,\u2019emergency_or_not\u00ad\u2019] contains the exact format for a valid submission (1 - For Emergency Vehicle, 0 - For Non Emergency Vehicle)","fdb92b51":"Case 2: step1 -> First lets prepare data differently\n\nAs you know CNN can read data 2G and 3G\n","b03fabf3":"## Hyper parameter runing using Random Search or hyperband\n### Search Space definition\nTo perform hyperparameter tuning, we need to define the search space, that is to say which hyperparameters need to be optimized and in what range. Here, for this relatively small model, there are already 6 hyperparameters that can be tuned:\n\n    the dropout rate for the three dropout layers\n\n    the number of filters for the convolutional layers\n\n    the number of units for the dense layer\n\n    its activation function\n\nIn Keras Tuner, hyperparameters have a type (possibilities are Float, Int, Boolean, and Choice) and a unique name. Then, a set of options to help guide the search need to be set:\n\n    a minimal, a maximal and a default value for the Float and the Int types\n\n    a set of possible values for the Choice type\n\n    optionally, a sampling method within linear, log or reversed log. Setting this parameter allows to add prior knowledge you might have about the tuned parameter. We'll see in the next section how it can be used to tune the learning rate for instance\n\n    optionally, a step value, i.e the minimal step between two hyperparameter values\n    \n    # example\n    \n    filters=hp.Choice(\n    'num_filters',\n    values=[32, 64],\n    default=64,\n    ),\n\n    tensorflow.keras.layers.Conv2D(filters, kernel_size, strides=(1, 1),\n      padding='valid', data_format=None, dilation_rate=(1, 1),\n      activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n      bias_initializer='zeros', kernel_regularizer=None,\n          bias_regularizer=None, activity_regularizer=None,\n      kernel_constraint=None, bias_constraint=None)\n  \n  ","02610b1c":"# CASE 5 MERGE (Case 3 and Case 4)\n##### Case 3: Create a new network with bottom layers taken from VGG\nAssume that for some specific task for images with the size (160, 160, 3), you want to use pre-trained bottom layers of VGG, up to layer with the name block2_pool.\n\n##### Case 4: Load VGA without Weight\na VGG-16 model pre-trained on the ImageNet database was used. If a trainable VGG-16 model is desired, \n1.    set the VGG-16 'weights' parameter to 'None' for random initialization and \n2.    set the 'cnn.trainable' attribute to 'True'.\n\nThe number and kind of layers, units, and other parameters should be tweaked as necessary for specific application needs.","6a34014e":"# Learning\n1. How to prepare data for CNN model using KERAS train generator\n2. How to prepare data for CNN model directly without train generator\n3. How to  build CNN from scratch\n4. How to use VGA16 (transfer learning) as its \n5. How to prepare VGA16(transfer learning) with top layer and replace top with custom FC layer\n6. How to pick partial layer from pretrained model and append your own layer and use it for your own data\n7. ","ceabd499":"# 1. Building CNN model from scratch","a17d6049":"# CASE2 : Loading weights from available pre-trained models (VGA) via KERAS and append your own top layer\n\nIf you are only interested in convolution filters. Note that by not specifying the shape of top layers, the input tensor shape is (None, None, 3), so you can use them for any size of images.","bea61938":"# Case 3: Create a new network with bottom layers taken from VGG\nAssume that for some specific task for images with the size (160, 160, 3), you want to use pre-trained bottom layers of VGG, up to layer with the name block2_pool.","9a175585":"# Lets Generate Data","2d317ddd":"# About Computer Vision\nComputer Vision as a field of research is notoriously difficult. Almost no research problem has been satisfactorily solved. One main reason for this difficulty is that the human visual system is simply too good for many tasks (e.g., face recognition), so that computer vision systems suffer by comparison. \n\nA human can recognize faces under all kinds of variations in illumination, viewpoint, expression, etc. In most cases we have no difficulty in recognizing a friend in a photograph taken many years ago. Also, there appears to be no limit on how many faces we can store in our brains for future recognition. There appears no hope in building an autonomous system with such stellar performance.\n\nGiven all this, computer vision has shown a lot of promise and reshaping the future of various industries such as automobile industry, healthcare industry, financial industry and so on\n\nThis weekend we bring to you another hackathon to apply your deep learning skills to solve a computer vision problem. This time you are in for a two week ride so brush up on our computer vision skills and hop on.\n\n","cb55c85e":"# Case 4: Load VGA without Weight\na VGG-16 model pre-trained on the ImageNet database was used. If a trainable VGG-16 model is desired, \n1.    set the VGG-16 'weights' parameter to 'None' for random initialization and \n2.    set the 'cnn.trainable' attribute to 'True'.\n\nThe number and kind of layers, units, and other parameters should be tweaked as necessary for specific application needs.","eaa86e28":"# CASE 1: Use VGA16 as it is, to predict your own images one by one","733b1527":"# Data Augmentation\nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.\n\nThe improvement is important :\n\nWithout data augmentation i have obtained an accuracy of 78%\nWith data augmentation i have achieved 82% of accuracy\n\nFor the data augmentation, i have choosed to :\n\nRandomly rotate some training images by 10 degrees\nRandomly Zoom by 10% some training images\nRandomly shift images horizontally by 10% of the width\nRandomly shift images vertically by 10% of the height\nI did not apply a vertical_flip nor horizontal_flip since model was giving less performence with these two options.\n\nOnce our model is ready, we fit the training dataset .\n\ntrain the model and plot the history\n Plot the loss and accuracy curves for training and validation data\n fig, ax = plt.subplots(2,1)\n ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n legend = ax[0].legend(loc='best', shadow=True)\n\n ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n legend = ax[1].legend(loc='best', shadow=True)"}}