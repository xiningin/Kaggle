{"cell_type":{"cfe6ad46":"code","2550aec1":"code","3de1a253":"code","78215793":"code","75a7b5d6":"code","0a77bb89":"code","8b22af03":"code","ded74d7a":"code","3d2d97a2":"code","d2825182":"code","24ce6af4":"code","cfe56b12":"code","3e8cc52c":"code","837fd845":"code","9915d0ab":"code","23e28eb5":"code","94aa21da":"code","7478f19f":"code","1b0ef0ad":"code","e35a5c51":"code","42d0c3ca":"code","d11fb318":"code","5b761363":"markdown"},"source":{"cfe6ad46":"import os\nimport sys\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFilter\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport seaborn as sns\n\nnp.random.seed(100)\nLEVEL = 'level_3'","2550aec1":"my_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\", \"yellow\", \"green\"])","3de1a253":"class SigmoidNeuron:\n  \n  def __init__(self):\n    self.w = None\n    self.b = None\n    \n  def perceptron(self, x):\n    return np.dot(x, self.w.T) + self.b\n  \n  def sigmoid(self, x):\n    return 1.0\/(1.0 + np.exp(-x))\n  \n  def grad_w_mse(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    return (y_pred - y) * y_pred * (1 - y_pred) * x\n  \n  def grad_b_mse(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    return (y_pred - y) * y_pred * (1 - y_pred)\n  \n  def grad_w_ce(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    if y == 0:\n      return y_pred * x\n    elif y == 1:\n      return -1 * (1 - y_pred) * x\n    else:\n      raise ValueError(\"y should be 0 or 1\")\n    \n  def grad_b_ce(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    if y == 0:\n      return y_pred \n    elif y == 1:\n      return -1 * (1 - y_pred)\n    else:\n      raise ValueError(\"y should be 0 or 1\")\n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n    \n    # initialise w, b\n    if initialise:\n      self.w = np.random.randn(1, X.shape[1])\n      self.b = 0\n      \n    if display_loss:\n      loss = {}\n    \n    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      dw = 0\n      db = 0\n      for x, y in zip(X, Y):\n        if loss_fn == \"mse\":\n          dw += self.grad_w_mse(x, y)\n          db += self.grad_b_mse(x, y) \n        elif loss_fn == \"ce\":\n          dw += self.grad_w_ce(x, y)\n          db += self.grad_b_ce(x, y)\n      self.w -= learning_rate * dw\n      self.b -= learning_rate * db\n      \n      if display_loss:\n        Y_pred = self.sigmoid(self.perceptron(X))\n        if loss_fn == \"mse\":\n          loss[i] = mean_squared_error(Y, Y_pred)\n        elif loss_fn == \"ce\":\n          loss[i] = log_loss(Y, Y_pred)\n    \n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      if loss_fn == \"mse\":\n        plt.ylabel('Mean Squared Error')\n      elif loss_fn == \"ce\":\n        plt.ylabel('Log Loss')\n      plt.show()\n      \n  def predict(self, X):\n    Y_pred = []\n    for x in X:\n      y_pred = self.sigmoid(self.perceptron(x))\n      Y_pred.append(y_pred)\n    return np.array(Y_pred)","78215793":"class SigmoidNeuron_V:\n  \n  def __init__(self):\n    self.W = None\n    self.b = None\n    \n  def perceptron(self, X):\n    return np.dot(X, self.W.T) + self.b\n  \n  def sigmoid(self, X):\n    return 1.0\/(1.0 + np.exp(-X))\n  \n  def grad_w_mse(self, X, y):\n    y_pred = self.sigmoid(self.perceptron(X))\n    return np.matmul(((y_pred - y.reshape(y_pred.shape[0], 1)) * y_pred * (1 - y_pred)).T, X)\n  \n  def grad_b_mse(self, X, y):\n    y_pred = self.sigmoid(self.perceptron(X))\n    return np.sum((y_pred - y.reshape(y_pred.shape[0], 1)) * y_pred * (1 - y_pred))\n  \n  def grad_w_ce(self, X, y):\n    y_pred = self.sigmoid(self.perceptron(X))\n    return np.matmul((y_pred - y.reshape(y_pred.shape[0], 1)).T, X)\n    \n  def grad_b_ce(self, X, y):\n    y_pred = self.sigmoid(self.perceptron(X))\n    return np.sum((y_pred - y.reshape(y_pred.shape[0], 1)))\n  \n  def fit(self, X, y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False, display_weight=False):\n    \n    # initialise w, b\n    if initialise:\n      self.W = np.random.randn(1, X.shape[1])\n      self.b = 0\n      \n    if display_loss:\n      loss = {}\n    \n    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      dw = 0\n      db = 0\n      if loss_fn == \"mse\":\n        dw = self.grad_w_mse(X, y)\n        db = self.grad_b_mse(X, y) \n      elif loss_fn == \"ce\":\n        dw = self.grad_w_ce(X, y)\n        db = self.grad_b_ce(X, y)\n      \n      self.W -= learning_rate * dw\n      self.b -= learning_rate * db\n      \n      if display_loss:\n        Y_pred = self.sigmoid(self.perceptron(X))\n        if loss_fn == \"mse\":\n          loss[i] = mean_squared_error(y, Y_pred)\n        elif loss_fn == \"ce\":\n          loss[i] = log_loss(y, Y_pred)\n        \n      if display_weight:\n        weight_matrix = np.array([[self.b] + list(sn_ce.W[0])[23:38]])\n        weight_matrices.append(weight_matrix)\n    \n    if display_loss:\n      plt.plot(np.array(list(loss.values())).astype(float))\n      plt.xlabel('Epochs')\n      if loss_fn == \"mse\":\n        plt.ylabel('Mean Squared Error')\n      elif loss_fn == \"ce\":\n        plt.ylabel('Log Loss')\n      plt.show()\n      \n  def predict(self, X):\n    Y_pred = []\n    Y_pred.append(self.sigmoid(self.perceptron(X)))\n    return np.array(Y_pred)","75a7b5d6":"def read_all(folder_path, key_prefix=\"\"):\n    '''\n    It returns a dictionary with 'file names' as keys and 'flattened image arrays' as values.\n    '''\n    print(\"Reading:\")\n    images = {}\n    files = os.listdir(folder_path)\n    for i, file_name in tqdm_notebook(enumerate(files), total=len(files)):\n        file_path = os.path.join(folder_path, file_name)\n        image_index = key_prefix + file_name[:-4]\n        image = Image.open(file_path)\n        image = image.convert(\"L\")\n        images[image_index] = np.array(image.copy()).flatten()\n        image.close()\n    return images","0a77bb89":"languages = ['ta', 'hi', 'en']\n\nimages_train = read_all(\"..\/input\/level-3-dataset\/\"+LEVEL+\"_train\/\"+LEVEL+\"\/background\", key_prefix='bgr_') # change the path\nfor language in languages:\n  images_train.update(read_all(\"..\/input\/level-3-dataset\/\"+LEVEL+\"_train\/\"+LEVEL+ \"\/\" +language, key_prefix=language+\"_\" ))\nprint(len(images_train))\n\nimages_test = read_all(\"..\/input\/level-3-dataset\/level_3_test\/kaggle_\"+LEVEL, key_prefix='') # change the path\nprint(len(images_test))","8b22af03":"list(images_test.keys())[:5]","ded74d7a":"image_filter = lambda x: 255 if x <= 10 else 0","3d2d97a2":"def border_filter(img, padding =3):\n    img = img.reshape(64, 64)\n    img[:padding] = 0\n    img[:, :padding] = 0\n    img[-padding:] = 0\n    img[:, -padding:] = 0\n    return img","d2825182":"X_train = []\nY_train = []\nfor key, value in images_train.items():\n    X_train.append(border_filter(np.array([ image_filter(x) for x in value ])).flatten())\n    if key[:4] == \"bgr_\":\n        Y_train.append(0)\n    else:\n        Y_train.append(1)\n\nID_test = []\nX_test = []\nfor key, value in images_test.items():\n  ID_test.append(int(key))\n  X_test.append(border_filter(np.array([ image_filter(x) for x in value ])).flatten())\n  \n        \nX_train = np.array(X_train)\nY_train = np.array(Y_train)\nX_test = np.array(X_test)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","24ce6af4":"def imshow(image):\n    image = image.reshape(64, 64)\n    plt.axis('off')\n    plt.imshow(image)","cfe56b12":"plt.imshow(X_train[7111].reshape(64, 64))","3e8cc52c":"imshow(X_train[8556])","837fd845":"scaler = MinMaxScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_test = scaler.transform(X_test)","9915d0ab":"imshow(X_scaled_train[8556])","23e28eb5":"sn_mse = SigmoidNeuron_V()\nsn_mse.fit(X_scaled_train, Y_train, epochs=1000, learning_rate=0.009, loss_fn=\"mse\", display_loss=True)","94aa21da":"# Epoch - 1000, lr - 0.005\nsn_ce = SigmoidNeuron_V()\nsn_ce.fit(X_scaled_train, Y_train, epochs=1000, learning_rate=0.005, loss_fn=\"ce\", display_loss=True)","7478f19f":"def print_accuracy(sn):\n  Y_pred_train = sn.predict(X_scaled_train)\n  Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n  accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n  print(\"Train Accuracy : \", accuracy_train)\n  print(\"-\"*50)","1b0ef0ad":"print_accuracy(sn_mse)\nprint_accuracy(sn_ce)","e35a5c51":"vals = sn_ce.W.reshape(64, 64)","42d0c3ca":"plt.figure(figsize=[10, 10])\nsns.heatmap(vals, cmap='coolwarm', square=True, vmin=-3, vmax=3)","d11fb318":"Y_pred_test = sn_ce.predict(X_scaled_test)\nY_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n\nsubmission = {}\nsubmission['ImageId'] = ID_test\nsubmission['Class'] = Y_pred_binarised_test\n\nsubmission = pd.DataFrame(submission)\nsubmission = submission[['ImageId', 'Class']]\nsubmission = submission.sort_values(['ImageId'])\nsubmission.to_csv(\"submisision.csv\", index=False)","5b761363":"## Sample Submission"}}