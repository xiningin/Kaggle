{"cell_type":{"b3c3fe8b":"code","e36d6f7d":"code","b5f52c65":"code","8ac3d5e3":"code","63784e0f":"code","97b2dc81":"code","3af4c518":"code","5921c139":"code","8cfb4b8e":"code","ee4f4ef9":"code","d1a1b2fc":"code","b2812950":"code","633c4c00":"code","4c5f63b6":"code","ec0bf5ea":"code","e7fbf797":"code","98e0fe76":"code","cd9b5ccf":"code","8b18e0a2":"code","9e63d16b":"code","4ba06d26":"code","6237ceff":"markdown","98adc434":"markdown","201d2f62":"markdown","56fadb95":"markdown","52128ca9":"markdown"},"source":{"b3c3fe8b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport  glob, cv2, os, random\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e36d6f7d":"submission = pd.read_csv('\/kaggle\/input\/recunoasterea-scris-de-mana\/sampleSubmission.csv')#\nsubmission.head()","b5f52c65":"train = pd.read_csv('\/kaggle\/input\/recunoasterea-scris-de-mana\/train.csv')\ntrain.head()","8ac3d5e3":"train['label'].hist()","63784e0f":"test_imgs = glob.glob('\/kaggle\/input\/recunoasterea-scris-de-mana\/test\/test\/*')\ntrain_imgs = glob.glob('\/kaggle\/input\/recunoasterea-scris-de-mana\/train\/train\/*')\nlen(test_img), len(train_img)","97b2dc81":"img2text = {i:str(j) for i,j in train.to_numpy()}\n#img2text","3af4c518":"from keras import backend as K\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Input, Dense, Activation\nfrom keras.layers import Reshape, Lambda, BatchNormalization\nfrom keras.layers.merge import add, concatenate\nfrom keras.models import Model\nfrom keras.layers.recurrent import LSTM\n\nK.set_learning_phase(0)\n\n#inspirat de la https:\/\/github.com\/qjadud1994\/CRNN-Keras\/\n\n# # Loss and train functions, network architecture\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage:\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n\nimg_w, img_h = 128, 32\nnum_classes = 13\nmax_text_len = 9\n\ndef get_Model(training):\n    input_shape = (img_w, img_h, 1)     # (128, 32, 1)\n\n    # Make Networkw\n    inputs = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 128, 32, 1)\n\n    # Convolution layer (VGG)\n    inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 32, 64)\n    inner = BatchNormalization()(inner)\n    inner = Activation('relu')(inner)\n    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n    \n    inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 16, 64)\n    inner = BatchNormalization()(inner)\n    inner = Activation('relu')(inner)\n    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None,64, 32, 64)\n    \n    inner = Conv2D(64, (2, 2), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 64)\n    inner = BatchNormalization()(inner)\n    inner = Activation('relu')(inner)\n    inner = MaxPooling2D(pool_size=(2, 2), name='max3')(inner)  # (None,64, 32, 64)\n    \n#     inner = Conv2D(64, (2, 2), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 64)\n#     inner = BatchNormalization()(inner)\n#     inner = Activation('relu')(inner)\n#     inner = MaxPooling2D(pool_size=(2, 2), name='max4')(inner)  # (None,64, 32, 64)\n\n    inner = Conv2D(128, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 16, 4, 512)\n    inner = BatchNormalization()(inner)\n    inner = Activation('relu')(inner)\n\n    print(inner)\n    # CNN to RNN\n    inner = Reshape(target_shape=((16, 4*128)), name='reshape')(inner)  # (None, 32, 2048)\n    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n\n    # RNN layer\n    lstm_1 = LSTM(128, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n    lstm_1b = LSTM(128, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n\n    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n    lstm1_merged = BatchNormalization()(lstm1_merged)\n\n    # transforms RNN output to character activations:\n    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm1_merged) #(None, 32, 63)\n    y_pred = Activation('softmax', name='softmax')(inner)\n\n    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)\n    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n\n    # Keras doesn't currently support loss funcs with extra parameters\n    # so CTC loss is implemented in a lambda layer\n    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n\n    if training:\n        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n    else:\n        return Model(inputs=[inputs], outputs=y_pred)\n    \n","5921c139":"from keras import backend as K\nK.clear_session()\nmodel = get_Model(training=True)\nmodel.summary()","8cfb4b8e":"letters = [i for i in '!~0123456789']\n# # Input data generator\ndef labels_to_text(labels):    \n    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n\ndef text_to_labels(text):     \n    text = str(text)\n    while len(text)<8:\n        text = '~'+text\n    return list(map(lambda x: letters.index(x), text))\n\n\nclass TextImageGenerator:\n    def __init__(self, img_dirpath, img_w, img_h,\n                 batch_size, downsample_factor, max_text_len=8, isTesting=False,\n                 validationNr=False, validationNR=1500):\n        self.img_h = img_h\n        self.img_w = img_w\n        self.batch_size = batch_size\n        self.max_text_len = max_text_len\n        self.downsample_factor = downsample_factor\n        self.img_dirpath = img_dirpath                  # image dir path\n        self.img_dir = os.listdir(self.img_dirpath)     # images list\n        if validationNr:\n            self.img_dir = self.img_dir[:validationNR]\n        else:\n            self.img_dir = self.img_dir[validationNR:]\n        self.n = len(self.img_dir)                     # number of images\n        self.indexes = list(range(self.n))\n        self.cur_index = 0\n        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n        self.texts = []\n\n    def build_data(self):\n        print(self.n, \" Image Loading start...\")\n        for i, img_file in enumerate(self.img_dir):\n            img = cv2.imread(self.img_dirpath + img_file, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, (self.img_w, self.img_h))\n            img = img.astype(np.float32)\n            img = (img \/ 255.0) * 2.0 - 1.0\n\n            self.imgs[i, :, :] = img\n            self.texts.append(img2text[img_file.split('\/')[-1]])\n        print(len(self.texts) == self.n)\n        print(self.n, \" Image Loading finish...\")\n\n    def next_sample(self):      ## index max \n        self.cur_index += 1\n        if self.cur_index >= self.n:\n            self.cur_index = 0\n            random.shuffle(self.indexes)\n        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n\n    def next_batch(self):      \n        while True:\n            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])     # (bs, 128, 64, 1)\n            Y_data = np.ones([self.batch_size, self.max_text_len])             # (bs, 9)\n            input_length = np.ones((self.batch_size, 1)) * 14#(self.img_w \/\/ self.downsample_factor - 2)  # (bs, 1)\n            label_length = np.zeros((self.batch_size, 1))           # (bs, 1)\n\n            for i in range(self.batch_size):\n                img, text = self.next_sample()\n                img = img.T\n                img = np.expand_dims(img, -1)\n                X_data[i] = img\n                Y_data[i] = text_to_labels(text)\n                label_length[i] = 8# len(text)\n\n            # dict \ud615\ud0dc\ub85c \ubcf5\uc0ac\n            inputs = {\n                'the_input': X_data,  # (bs, 128, 64, 1)\n                'the_labels': Y_data,  # (bs, 8)\n                'input_length': input_length,  # (bs, 1) -> \ubaa8\ub4e0 \uc6d0\uc18c value = 30\n                'label_length': label_length  # (bs, 1) -> \ubaa8\ub4e0 \uc6d0\uc18c value = 8\n            }\n            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1) -> \ubaa8\ub4e0 \uc6d0\uc18c 0\n            yield (inputs, outputs)","ee4f4ef9":"# model = get_Model(training=True)\n\n\nmg_w, img_h, batch_size, downsample_factor = 128, 32, 10, 4\ntrain_file_path = '\/kaggle\/input\/recunoasterea-scris-de-mana\/train\/train\/'\ntiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor)\ntiger_train.build_data()","d1a1b2fc":"g = tiger_train.next_batch()\ninputs, outputs = next(g)","b2812950":"inputs.keys()","633c4c00":"inputs['input_length']","4c5f63b6":"inputs['the_input'].shape","ec0bf5ea":"plt.imshow(inputs['the_input'][0,:,:,0])","e7fbf797":"outputs","98e0fe76":"from keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\nmodel = get_Model(training=True)\n\nval_batch_size = 10\n\ntrain_file_path = '\/kaggle\/input\/recunoasterea-scris-de-mana\/train\/train\/'\ntiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor, validationNr=True, validationNR=1500)\ntiger_train.build_data()\n\ntiger_val = TextImageGenerator(train_file_path, img_w, img_h, val_batch_size, downsample_factor, validationNr=False, validationNR=1500)\ntiger_val.build_data()\n\nada = Adam()\n\nearly_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=4, mode='min', verbose=1)\ncheckpoint = ModelCheckpoint(filepath='LSTM+BN5--{epoch:02d}--{val_loss:.3f}.hdf5', monitor='loss', verbose=1, mode='min', period=1)\n# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\nmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n\n# captures output of softmax so we can decode the output during visualization\nmodel.fit_generator(generator=tiger_train.next_batch(),\n                    steps_per_epoch=int(tiger_train.n \/ batch_size),\n                    epochs=60,\n#                     callbacks=[checkpoint],\n                    validation_data=tiger_val.next_batch(),\n                    validation_steps=int(tiger_val.n \/ val_batch_size))\n","cd9b5ccf":"model.save_weights('LSTM+BN4--26--0.011.hdf5')","8b18e0a2":"\nfrom keras import backend as K\nK.clear_session()\nmodel = get_Model(training=False)\nmodel.load_weights('LSTM+BN4--26--0.011.hdf5')","9e63d16b":"import itertools, os, time\n\ndef decode_label(out):\n    # out : (1, 32, 42)\n    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index -> len = 32\n    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n    outstr = ''\n    for i in out_best:\n        if i < len(letters) and letters[i] not in ['~','!']:\n            outstr += letters[i]\n    return outstr\nimg2text = {}\nfor i,test_img in enumerate(test_imgs[:]):#train_imgs:\n    if i%100==0:\n        print(i,'of', len(test_imgs))\n    img = cv2.imread(test_img, cv2.IMREAD_GRAYSCALE)\n\n    img_pred = img.astype(np.float32)\n    img_pred = cv2.resize(img_pred, (128, 32))\n    img_pred = (img_pred \/ 255.0) * 2.0 - 1.0\n    img_pred = img_pred.T\n    img_pred = np.expand_dims(img_pred, axis=-1)\n    img_pred = np.expand_dims(img_pred, axis=0)\n\n    net_out_value = model.predict(img_pred)\n\n    pred_texts = decode_label(net_out_value)\n    img2text[test_img.split('\/')[-1]] = 0 if len(pred_texts)==0 else pred_texts#int(pred_texts)\n    if False:\n        print(pred_texts)\n        plt.imshow(img)\n        print(img2text)\n        break","4ba06d26":"#save the prediction\nsubmission['Expected'] = submission['Id'].apply(lambda x: img2text[x])\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","6237ceff":"# Procesem imaginile si etichetele","98adc434":"# Prezicem pe imaginile de testare","201d2f62":"# Antrenam modelul","56fadb95":"# Construim modelul","52128ca9":"# Testam fuctiile de procesare a imaginilor"}}