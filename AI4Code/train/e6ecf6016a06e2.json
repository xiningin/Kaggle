{"cell_type":{"0524dc2c":"code","3cce53f5":"code","cdc7eda4":"code","e959b995":"code","59b95d23":"code","628f69f5":"code","0d1bcc52":"code","d01d3072":"code","3062d7fa":"code","b6f67a66":"code","d308b83c":"code","a3bae0d6":"code","94f611bd":"code","261a2b7a":"code","2d6e4243":"code","43e63ea2":"code","d8816af5":"code","dd7df074":"code","3da68bc1":"code","f00def99":"code","824c8df8":"code","3781663a":"code","4477fb2e":"code","34719d33":"code","13d15327":"code","b46bb6cc":"code","19e1f3a3":"code","cd19a4bf":"code","ca51aff7":"code","a9867ca7":"code","5c434152":"code","f9418c4e":"code","9031d9ab":"code","f9e3ed1a":"code","096fb41d":"code","355db167":"code","84ac90d5":"code","a789d5df":"code","809d190b":"code","e2d17555":"code","a00135fe":"code","d51b8545":"code","8017a504":"code","7551bfea":"code","7d0cc696":"code","48cd760d":"code","48aa81b6":"code","548701d7":"code","b5df3d1f":"code","77a282d8":"code","3effb340":"code","7ab4531d":"code","46d83840":"code","99c78c90":"code","6e557421":"markdown","9642c883":"markdown","e0d1c53b":"markdown","e6188cfc":"markdown","c4c74659":"markdown","cbcb5571":"markdown","6d586b79":"markdown","6de7cfed":"markdown","c594dd7c":"markdown","bff8482c":"markdown","4bb38fcd":"markdown","e946b952":"markdown","4e757964":"markdown"},"source":{"0524dc2c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3cce53f5":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","cdc7eda4":"train.head()","e959b995":"def get_uniques(df,lim=10):\n    for col in df.columns:\n        arr = list(df[col].values)\n        unqs = set(arr)\n        if len(unqs)<lim:\n            print(col, \":\",unqs)\n        else:\n            print(col,\"long : \", len(unqs))\n\nget_uniques(train)","59b95d23":"train.isna().sum()","628f69f5":"from copy import deepcopy\ndf = deepcopy(train)","0d1bcc52":"def data_replacer(df):\n    df['Embarked'] = df['Embarked'].fillna('X')\n    df['Cabin'] = df['Cabin'].fillna('Unknown')\n    df['Age'] = df['Age'].fillna(0)\n    return df\ndf = data_replacer(df)","d01d3072":"df.isna().sum()","3062d7fa":"df.info()","b6f67a66":"df.drop(['PassengerId', 'Name'], axis = 1, inplace = True) ","d308b83c":"def merge_list_to_dict(test_keys,test_values):\n    # using dictionary comprehension\n    # to convert lists to dictionary\n    merged_dict = {test_keys[i]: test_values[i] for i in range(len(test_keys))}\n    return merged_dict\nLABELS_Sex  = {\"male\":0,\"female\":1}\nLists_Embarked = ['Q', 'C', 'S', 'X']\nLABELS_Embarked = merge_list_to_dict(Lists_Embarked,list(range(len(Lists_Embarked))))\ndf['Sex'] = df['Sex'].map(LABELS_Sex)\ndf['Embarked'] = df['Embarked'].map(LABELS_Embarked)","a3bae0d6":"df.drop(['Cabin', 'Ticket'], axis = 1, inplace = True) ","94f611bd":"get_uniques(df)","261a2b7a":"df.to_csv('training_data.csv',index=False)","2d6e4243":"!pip install autoviz\n!pip install xlrd","43e63ea2":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()","d8816af5":"new_df = AV.AutoViz('training_data.csv')","dd7df074":"new_df = AV.AutoViz('training_data.csv',depVar='Survived')","3da68bc1":"def prepare_data(df):\n    df = data_replacer(df)\n    df.drop(['PassengerId', 'Name'], axis = 1, inplace = True) \n    df['Sex'] = df['Sex'].map(LABELS_Sex)\n    df['Embarked'] = df['Embarked'].map(LABELS_Embarked)\n    df.drop(['Cabin', 'Ticket'], axis = 1, inplace = True)\n    return df\ntrain_p = prepare_data(train)\ntest_p = prepare_data(test)","f00def99":"train_p.head()","824c8df8":"target = \"Survived\"\ndef subtract_lists(x,y):\n    \"\"\"Subtract Two Lists (List Difference)\"\"\"\n    return [item for item in x if item not in y]\ndef create_dataset(df,as_df=True):\n    cols_y = [target]\n    cols_x = subtract_lists(list(df.columns),cols_y)\n    X_df = df[cols_x]\n    y_df = df[cols_y]\n    if as_df:\n        return X_df,y_df\n    else:\n        return X_df.values,y_df.values\nX,y = create_dataset(train_p)\nprint(X.shape, y.shape)","3781663a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","4477fb2e":"X_train_df = deepcopy(X_train)\nX_train_df[target] = y_train.values.flatten()\nX_test_df = deepcopy(X_test)\nX_test_df[target] = y_test.values.flatten()","34719d33":"X_full_df = deepcopy(X)\nX_full_df[target] = y.values.flatten()","13d15327":"!pip install h2o","b46bb6cc":"import h2o\nfrom h2o.automl import H2OAutoML","19e1f3a3":"h2o.init(\n    nthreads=-1,     # number of threads when launching a new H2O server\n    max_mem_size=12  # in gigabytes\n\n)","cd19a4bf":"\"\"\"\ntrain_p.to_csv('train_p.csv',index=False)\ntest_p.to_csv('test_p.csv',index=False)\n\n# Import a sample binary outcome train\/test set into H2O\ntrain_h2o = h2o.import_file(\"train_p.csv\")\ntest_h2o = h2o.import_file(\"test_p.csv\")\n\ntrain_h2o = h2o.H2OFrame(X_train_df)\ntest_h2o = h2o.H2OFrame(X_test_df)\n\nX_h2o = train_h2o.columns\ny_h2o = target\nX_h2o.remove(y_h2o)\n\n# For binary classification, response should be a factor\ntrain_h2o[y_h2o] = train_h2o[y_h2o].asfactor()\ntest_h2o[y_h2o] = test_h2o[y_h2o].asfactor()\n\naml = H2OAutoML(max_models=20, seed=1)\naml.train(x=X_h2o, y=y_h2o, training_frame=train_h2o)\n\"\"\"","ca51aff7":"train_h2o = h2o.H2OFrame(X_full_df)","a9867ca7":"X_h2o = train_h2o.columns\ny_h2o = target\nX_h2o.remove(y_h2o)","5c434152":"# For binary classification, response should be a factor\ntrain_h2o[y_h2o] = train_h2o[y_h2o].asfactor()","f9418c4e":"aml = H2OAutoML(max_models=30,seed=1)\naml.train(x=X_h2o, y=y_h2o, training_frame=train_h2o)","9031d9ab":"lb = aml.leaderboard\nlb.head(rows=lb.nrows)","f9e3ed1a":"# To generate predictions on a test set, you can make predictions\n# directly on the `\"H2OAutoML\"` object or on the leader model\n# object directly\n# preds = aml.predict(test)\n\n# or:\n# preds_ML = aml.leader.predict(test_h2o)","096fb41d":"!pip install autokeras","355db167":"import tensorflow as tf\nimport autokeras as ak","84ac90d5":"X,y = create_dataset(train_p,as_df=False)\nprint(X.shape, y.shape)","a789d5df":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","809d190b":"train_set = tf.data.Dataset.from_tensor_slices((X_train.astype(np.unicode), y_train))\ntest_set = tf.data.Dataset.from_tensor_slices((X_test.astype(np.unicode), y_test))","e2d17555":"\"\"\"\nclf = ak.StructuredDataClassifier(overwrite=True, max_trials=3)\n# Feed the tensorflow Dataset to the classifier.\nclf.fit(train_set, epochs=10)\n\n# Predict with the best model.\npredicted_y = clf.predict(test_set)\n# Evaluate the best model with testing data.\nprint(clf.evaluate(test_set))\n\"\"\"","a00135fe":"# It tries 10 different models.\nclf = ak.StructuredDataClassifier(overwrite=True, max_trials=3)\n# Feed the structured data classifier with training data.\nclf.fit(X_train, y_train, epochs=10)","d51b8545":"# Predict with the best model.\npredicted_y = clf.predict(X_test)\n# Evaluate the best model with testing data.\nprint(clf.evaluate(X_test, y_test))","8017a504":"test_p","7551bfea":"preds_full = aml.leader.predict(h2o.H2OFrame(test_p))","7d0cc696":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest","48cd760d":"sub","48aa81b6":"type(preds_full[\"predict\"])","548701d7":"ps = h2o.as_list(preds_full)","b5df3d1f":"ps","77a282d8":"sub[\"Survived\"] = ps[\"predict\"]","3effb340":"sub","7ab4531d":"import shutil\ndef destroy_files(folder):\n    for f in os.listdir(folder):\n        try:\n            os.remove(f)\n        except:\n            shutil.rmtree(f)\ndestroy_files(\".\/\")","46d83840":"os.listdir(\".\/\")","99c78c90":"sub.to_csv(\"submission.csv\",index=False)","6e557421":"### Generic Plot","9642c883":"### Cabin and Ticket\n\n- Probably contains no vital information, and Cabin Values were 77 % empty so we drop them.","e0d1c53b":"### Map Relevant Features \n- Sex : {\"Male\":0,\"Female\":1}\n- Embarked : {\"Male\":0,\"Female\":1}","e6188cfc":"### numpy.ndarray to tf.data.Dataset","c4c74659":"# EDA","cbcb5571":"### Data Prep Pipeline (ETA) for ML","6d586b79":"### Drop Irrelevant Features - PassengerId, Name","6de7cfed":"### ML Models","c594dd7c":"# AutoKeras","bff8482c":"#### Gives a Cross Validated Score on its own, the perfect library!","4bb38fcd":"### Specific Plot","e946b952":"### Data Imputation\n\n- For Embarked we can just replace the NaNs with `X` (only 2)\n- For Age we replace with 0\n- For Cabin we replace with 'Unknown'","4e757964":"### Perform AutoViz EDA"}}