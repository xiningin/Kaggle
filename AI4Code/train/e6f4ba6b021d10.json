{"cell_type":{"90048c9b":"code","d0f238c9":"code","8425bc07":"code","0e00f3b8":"code","3573bdbe":"code","fa497a45":"code","f43ee668":"code","98e37aae":"code","8cebb569":"code","af6a208e":"code","49faaed5":"code","7aea24dc":"code","2e5a5379":"code","1b92ed39":"code","f6fa08c7":"code","5f89bfef":"code","b0d76d48":"code","313d6c81":"code","0b316bd1":"code","86b2cfd9":"code","4edc7cc4":"code","83c9cb64":"code","c361848d":"code","046f27df":"code","bd1e1167":"code","c5d62368":"code","f38cbea1":"code","bd3f040f":"code","b63ead3f":"code","18148930":"code","40cb508d":"code","e810d01a":"code","558efb8a":"code","bc41926b":"code","62d53a69":"code","50bac03a":"code","6087fb4e":"code","1d4a0d2e":"code","cac83993":"code","82e3e886":"code","84408f7e":"code","71f8d269":"code","b441e226":"code","583a2d6a":"code","16606493":"code","f33e325b":"code","dac9a2c4":"code","e6b7ab8c":"code","e56eb972":"code","03358d31":"code","3436c6a6":"code","4fd8fc60":"code","1f680f38":"code","4bc75e61":"code","e331a837":"code","08167fd6":"code","ff677b0e":"code","df084a91":"code","dd746f3b":"code","bca12193":"code","2957b06d":"code","f0f8324e":"code","2c200855":"code","56e0ab4f":"code","2691c74a":"code","75e1f04c":"code","94e67827":"code","18222c29":"code","2502dd01":"code","76c50a9b":"code","5b303e11":"code","b9682c35":"code","8254699d":"code","26a39014":"code","a500be57":"code","8212c61c":"code","7dd3b3d9":"code","7885b645":"code","4cec2002":"markdown","d2caed14":"markdown","13f0dcf5":"markdown","c4269a2b":"markdown","d1181579":"markdown","a0bcca57":"markdown","7af801dc":"markdown","2f0d5021":"markdown","129dc04b":"markdown","b6743d5f":"markdown","a9dcf072":"markdown","a157bca0":"markdown","85f41980":"markdown","38f6cdc5":"markdown","9a6bd3cd":"markdown","bbd6464f":"markdown","9fe8f2ab":"markdown","886d520a":"markdown","7b461745":"markdown","e2d799a1":"markdown","af63166f":"markdown","05882ca6":"markdown","21c3d93d":"markdown","01a92077":"markdown","982096d7":"markdown","cf6bb239":"markdown","5ba5ee2f":"markdown","3d946908":"markdown","43e1a319":"markdown","979c727f":"markdown","e04d6eea":"markdown","0c5a517c":"markdown","87da8dcd":"markdown","10e80556":"markdown","233d61df":"markdown","fd970c94":"markdown","5e365359":"markdown","3a3c77b9":"markdown","57e568cb":"markdown","9e1b805c":"markdown","d16d7e39":"markdown","ad3ab82c":"markdown","5ba73cc7":"markdown","566c419d":"markdown","57fdb35a":"markdown","d02830f6":"markdown","133b7e9a":"markdown","3b51cea8":"markdown","b91f8f94":"markdown","5ba739dd":"markdown","ca9c663e":"markdown","ed00743f":"markdown","93e381c4":"markdown","502812f6":"markdown","e8d21c9a":"markdown","fde2ae2a":"markdown","44944eb4":"markdown","c6c3d2ad":"markdown","b0a2b216":"markdown","47fc036b":"markdown","ae65fcc5":"markdown","9b8034b9":"markdown","5731cd8f":"markdown","d8348007":"markdown","cf2161c3":"markdown","b71e2366":"markdown","c467fe8d":"markdown","bf6d5989":"markdown","f4034916":"markdown","b3893517":"markdown","e8674e07":"markdown","0b21de72":"markdown","d9629c2c":"markdown","53b85f8e":"markdown","59ace3c8":"markdown","ed91e179":"markdown","6539d0b5":"markdown","1dccef6e":"markdown","5d9ab766":"markdown","484f8ab4":"markdown","f2be1e2e":"markdown","91fc2338":"markdown","e84020b7":"markdown","20b24393":"markdown","fd7a5dbb":"markdown","b9a5648a":"markdown","c5afacfa":"markdown","ab18faff":"markdown","7420a94e":"markdown"},"source":{"90048c9b":"# Downloading and importing all the necessary libraries to complete the project.\nimport tweepy\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport requests\nimport json\nimport os\nimport re\nimport warnings\nwarnings.simplefilter('ignore')","d0f238c9":"from PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","8425bc07":"pd.set_option('display.max_colwidth', -1)","0e00f3b8":"archive = pd.read_csv('..\/input\/twitter-archive-enhanced-2.csv')","3573bdbe":"from tweepy import OAuthHandler\nfrom timeit import default_timer as timer","fa497a45":"consumer_key = 'HIDDEN'\nconsumer_secret = 'HIDDEN'\naccess_token = 'HIDDEN'\naccess_secret = 'HIDDEN'\n\nauth = OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_secret)\n\napi = tweepy.API(auth, wait_on_rate_limit=True)\n\ntweet_ids = archive.tweet_id.values\nlen(tweet_ids)","f43ee668":"# set a function for tweet extraction\n# file already created so no need to execute to continue the notebook\ndef tweet_extraction():\n    count = 0\n    fails_dict = {}\n    start = timer()\n    with open('tweet_json.txt', 'w') as outfile:\n        for tweet_id in tweet_ids:\n            count += 1\n            print(str(count) + \": \" + str(tweet_id))\n            try:\n                tweet = api.get_status(tweet_id, tweet_mode='extended')\n                print(\"Success\")\n                json.dump(tweet._json, outfile)\n                outfile.write('\\n')\n            except tweepy.TweepError as e:\n                print(\"Fail\")\n                fails_dict[tweet_id] = e\n                pass\n    end = timer()\n    print(end - start)\n    print(fails_dict)","98e37aae":"df_list = []\nwith open('..\/input\/tweet_json.txt') as file:\n    for line in file:\n        data = json.loads(line)\n        keys = data.keys()\n        user = data.get('user')\n        id_str = data.get('id_str')\n        retweet_count = data.get('retweet_count')\n        favorite_count = data.get('favorite_count')\n        df_list.append({'id_str': id_str,\n                        'retweet_count': retweet_count,\n                        'favorite_count': favorite_count})","8cebb569":"tweet_count = pd.DataFrame(df_list, columns = ['id_str', 'retweet_count', 'favorite_count'])","af6a208e":"# Downloading the image predictions from the internet\nfolder_name = 'image_pred'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)\n\nurl = 'https:\/\/d17h27t6h515a5.cloudfront.net\/topher\/2017\/August\/599fd2ad_image-predictions\/image-predictions.tsv'\nresponse = requests.get(url)","49faaed5":"with open(os.path.join(folder_name, url.split('\/')[-1]), mode='wb') as file:\n    file.write(response.content)","7aea24dc":"image_pred = pd.read_csv('..\/input\/image-predictions.tsv', sep='\\t')","2e5a5379":"archive.head()","1b92ed39":"archive.text.sample(20)","f6fa08c7":"tweet_count.head()","5f89bfef":"image_pred.head()","b0d76d48":"archive.info()","313d6c81":"doggo = archive.doggo.value_counts()\nfloofer = archive.floofer.value_counts()\npupper = archive.pupper.value_counts()\npuppo = archive.puppo.value_counts()\nprint(doggo); \nprint(floofer); \nprint(pupper); \nprint(puppo)","0b316bd1":"archive.name.value_counts().head(20)","86b2cfd9":"archive.source.value_counts()","4edc7cc4":"tweet_count.info()","83c9cb64":"image_pred.info()","c361848d":"# trimmed the names in order to make less wordy when coding\narchive_clean = archive.copy()\nimage_clean = image_pred.copy()\ntweet_clean = tweet_count.copy()","046f27df":"drop_retweet = archive_clean[pd.notnull(archive_clean['retweeted_status_id'])].index\ndrop_reply = archive_clean[pd.notnull(archive_clean['in_reply_to_status_id'])].index","bd1e1167":"archive_clean.drop(index=drop_retweet, inplace=True)\narchive_clean.drop(index=drop_reply, inplace=True)","c5d62368":"archive_clean.info()","f38cbea1":"archive_clean.dropna(axis='columns',how='any', inplace=True)","bd3f040f":"archive_clean.drop(columns='source', inplace=True)","b63ead3f":"archive_clean.head()","18148930":"tweet_clean.rename(index=str, columns={\"id_str\": \"tweet_id\"}, inplace=True)\narchive_clean.rename(columns={\"floofer\": \"floof\", \n                                         \"rating_numerator\": \"rate_num\",\n                                         \"rating_denominator\": \"rate_denom\"}, inplace=True)","40cb508d":"tweet_clean.info()","e810d01a":"archive_clean.info()","558efb8a":"image_clean['tweet_id'] = image_clean['tweet_id'].astype('str')\narchive_clean['timestamp'] = pd.to_datetime(archive_clean['timestamp'])\narchive_clean['tweet_id'] = archive_clean['tweet_id'].astype('str')","bc41926b":"image_clean.info()","62d53a69":"archive_clean.info()","50bac03a":"image_clean['p1'] = image_clean['p1'].str.lower()\nimage_clean['p2'] = image_clean['p2'].str.lower()\nimage_clean['p3'] = image_clean['p3'].str.lower()","6087fb4e":"image_clean.p1.head()","1d4a0d2e":"image_clean.p2.head()","cac83993":"image_clean.p3.head()","82e3e886":"archive_clean['text'] = archive_clean.text.str.replace(\"&amp;\", \"&\")\narchive_clean['text'] = archive_clean.text.str.replace(\"\\n\", \" \")\narchive_clean['text'] = archive_clean.text.str.replace(r\"http\\S+\", \"\")\narchive_clean['text'] = archive_clean.text.str.strip()","84408f7e":"archive_clean.query(\"text == '&amp;'\")","71f8d269":"archive_clean.iloc[[588, 797, 853, 948, 985, 1005, 1136, 1234, 1239, 1278, \n                    1294, 1307, 1426, 1556, 1592, 1649, 1653, 1719, 1759, \n                    1811, 1860, 1922, 1960, 2005, 2014, 2047, 2076], [2,3,4,5]]","b441e226":"archive_clean.reset_index(inplace=True, drop=True)","583a2d6a":"archive_clean[archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\\/\\d+)\")][['text', 'rate_num']]","16606493":"hyphen_table = archive_clean.text.str.extractall(r\"(\\d+\\d*\\\/\\d+)\")\nhyphen_table.head(10)","f33e325b":"match_1 = hyphen_table.query(\"match == 1\")\nmatch_1.head()","dac9a2c4":"match_1.index.labels","e6b7ab8c":"# copied indices from above\narchive_clean.iloc[[588, 797, 853, 948, 985, 1005, 1136, 1234, 1239, 1278, \n                    1294, 1307, 1426, 1556, 1592, 1649, 1653, 1719, 1759, \n                    1811, 1860, 1922, 1960, 2005, 2014, 2047, 2076], [2,3,4,5]]","e56eb972":"#rating confused with 9\/11(September 11th)\narchive_clean.iloc[853, 3] = 14\narchive_clean.iloc[853, 4] = 10\n\n#rating confused with 4\/20(Weed Day)\narchive_clean.iloc[948, 3] = 13\narchive_clean.iloc[948, 4] = 10\n\n#rating confused with phrase 50\/50 split\narchive_clean.iloc[985, 3] = 11\narchive_clean.iloc[985, 4] = 10\n\n#rating confused with 7\/11 which is name of convience store\narchive_clean.iloc[1426, 3] = 10\narchive_clean.iloc[1426, 4] = 10\n\n#rating confused with 1\/2 representing \"half\"\narchive_clean.iloc[2076, 3] = 9\narchive_clean.iloc[2076, 4] = 10","03358d31":"doubles_list = archive_clean.iloc[[588, 797, 1005, 1136, 1234, 1239, 1278, \n                    1294, 1307, 1556, 1592, 1649, 1653, 1719, 1759, \n                    1811, 1860, 1922, 1960, 2005, 2014, 2047]]\ndouble_index = doubles_list.index","3436c6a6":"archive_clean.iloc[[41, 528, 586, 1474], [2,3,4]]","4fd8fc60":"archive_clean.iloc[41, 3] = 13.5\narchive_clean.iloc[528, 3] = 9.75\narchive_clean.iloc[586, 3] = 11.27\narchive_clean.iloc[1474, 3] = 11.26","1f680f38":"archive_clean.iloc[[45, 528, 586, 1474], [2,3,4]]","4bc75e61":"archive_clean.iloc[[853, 948, 985, 1426, 2076], [2,3,4,5]]","e331a837":"doubles_list = archive_clean.iloc[[588, 797, 1005, 1136, 1234, 1239, 1278, \n                    1294, 1307, 1556, 1592, 1649, 1653, 1719, 1759, \n                    1811, 1860, 1922, 1960, 2005, 2014, 2047]]\ndouble_index = doubles_list.index","08167fd6":"archive_clean.drop(axis='index', index=double_index, inplace=True)","ff677b0e":"archive_clean.info()","df084a91":"df_merge1 = archive_clean.join(tweet_clean.set_index('tweet_id'), on='tweet_id')","dd746f3b":"df_merge1.info()","bca12193":"master = df_merge1.join(image_clean.set_index('tweet_id'), on='tweet_id')","2957b06d":"master.info()","f0f8324e":"master_copy = master.copy()","2c200855":"drop_index = master_copy[pd.isnull(master_copy['jpg_url'])].index\ndrop_index2 = master_copy[pd.isnull(master_copy['retweet_count'])].index\ndrop_index, drop_index2","56e0ab4f":"master_copy.drop(index=drop_index, inplace=True)\nmaster_copy.drop(index=drop_index2, inplace=True)","2691c74a":"master_copy.info()","75e1f04c":"master_copy.to_csv(path_or_buf='master.csv', index=False)","94e67827":"master_clean = master_copy[['timestamp','tweet_id', 'rate_num', 'rate_denom', \n                            'name', 'retweet_count', 'favorite_count', 'p1', 'p2', 'p3']]","18222c29":"#setting the DataFrame to index the timestamp column\nmaster_copy = master_copy.set_index('timestamp')","2502dd01":"master_copy.sample(5)","76c50a9b":"# viewing some descriptive statistics with the quantitative measures in our analysis. \n# used round(5) in order to visually see the last two columns without scientific notation involved.\nmaster_copy.describe().round(5)","5b303e11":"# this method helps to see which variables correlate and helpful when doing a hypothesis test or A\/B test. \nmaster_copy.corr()","b9682c35":"sns.pairplot(master_copy, vars=[\"rate_num\", \"rate_denom\", \"retweet_count\", \"favorite_count\", \"p1_conf\", \"p2_conf\", \"p3_conf\"]);","8254699d":"# set these variables so the plotting code would be cleaner.\nretweet_resamp = master_copy['retweet_count'].resample('1w').mean()\nfavorite_resamp = master_copy['favorite_count'].resample('1w').mean()","26a39014":"# plotting the resample of weekling favorite and retweet counts to show a smoother display over time.\nsns.set(rc={'figure.figsize':(13, 6)})\nfig, ax = plt.subplots()\nax.plot(retweet_resamp, marker='*', linestyle='-', linewidth=0.5, label='Retweet Count Resample')\nax.plot(favorite_resamp, marker='*', markersize=3, linestyle='--', label='Favorite Count Resample')\nax.set_ylabel('Counts')\nax.set_xlabel('Time Periods (Monthly Intervals)')\nax.legend();","a500be57":"tweets = np.array(master_copy.text)\nmy_list = []\nfor tweet in tweets:\n    my_list.append(tweet.replace(\"\\n\",\"\"))","8212c61c":"mask = np.array(Image.open(requests.get('https:\/\/clipartix.com\/wp-content\/uploads\/2016\/06\/Dog-bone-pink-print-dog-paw-print-transparent-background-paw-print-pink-clipart.jpg', stream=True).raw))\ntext = my_list","7dd3b3d9":"def gen_wc(text, mask):\n    word_cloud = WordCloud(width = 500, height = 500, background_color='white', mask=mask).generate(str(text))\n    plt.figure(figsize=(10,8),facecolor = 'white', edgecolor='red')\n    plt.imshow(word_cloud)\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    plt.show()","7885b645":"gen_wc(text, mask)","4cec2002":"##### Code","d2caed14":"> #9 **MERGE**","13f0dcf5":"## Gathering the Data","c4269a2b":"##### Code","d1181579":"##### Test","a0bcca57":"* As shown above, each variable initially seems to follow a logical pattern without abnormal outliers sending red flags. For example, the **rate_denom** the minimum is 2 which makes sense because 0 cannot be the lowest since it's part of a ratio and you cannot divide by zero. \n* Even, though some of the numerators in the **rate_num** column are extraordinarily high and above 10 for the denominator, the rating system for the WeRateDogs feed follows an out of the norm rating system. Therefore, this should not draw attention as an issue. \n* Also, for columns **p1_conf**, **p2_conf**, and **p3_conf**, the numbers are in the bounds from 0 to 1, which is good because they are confidence intervals and are bound between 0 and 1. **p1_conf** has a higher average than **p2_conf** and so forth, and their max and min are higher in both categories respectively. \n* This suggests that the neural network developed to identify the breed of dog works effectively because \"p1\", \"p2\" and \"p3\" are the predictions in succession. Indicating the first prediction (p1) has a higher confidence of being correct than the following predictions. ","7af801dc":"##### Test","2f0d5021":"> #10 **Final Merge**","129dc04b":"> **Missing Data**","b6743d5f":"#### Correlation","a9dcf072":"##### Code","a157bca0":"#### Basic Statistics","85f41980":"> * Missing information for the dog stages.","38f6cdc5":"> First we need to create a list with all the words that were tweeted in our DataFrame.","9a6bd3cd":"##### Define","bbd6464f":"> #3 **Fixing Column Names**\n\n* **tweet_clean: unifying column names**\n* **archive_clean: column names**","9fe8f2ab":"### Assessment Summary\n\n#### Quality\n#### `archive` Table\n* Missing values in columns: __in_reply_to_status_id__, __in_reply_to_user_id__, __retweeted_status_id__, __retweeted_status_user_id__, __retweeted_status_timestamp__, and __expanded_urls__.\n* Column name __floofer__ should be spelled __'floof'__\n* **tweet_id** has dtype int64 and should be object\n* **timestamp** should be a datetime64 dtype type as well\n* Missing information for dog stages.\n* Many missing names from the list under __'None'__, and random names like **'a'** and __'an'__ might be parts of strings that got taken out of context.\n* Remove from table retweets and replies keepng only original tweets.\n* Some tweets had **\"\\&amp\"** combined with **\";\"** which is the html code to display just the ampersand, so that needs to be cleaned up.\n\n#### `tweet_count` Table\n* The column **id_str** should be changed to **tweet_id** so merging tables will be smoother.\n\n#### `image_pred` Table\n* The types of dogs in columns **p1**, **p2**, and **p3** had some uppercase and lowercase letters. \n* The **tweet_id** column should be dtype object instead of int64.\n\n\n#### Tidiness\n\n* The `tweet_count` and `archive` table should be merged as this is added data to the other table.\n* The **source** column in `archive` table looks messy and clutters the table.\n* All three tables will eventually be merged into one.","886d520a":"* In the `archive_clean` table, there are some tweets with two dogs being rated, therefore those will be dropped because it violates the rules of tidiness. ","7b461745":"> Second table `tweet_count` downloaded programmatically from twitter's API using tweepy, then saved to a JSON file, stored in a dictionary, then loaded into a pandas DataFrame.","e2d799a1":"## Assessing the Data","af63166f":"##### Test","05882ca6":"* The code used above was modeled from this blog on how to generate a word cloud in python.\nhttps:\/\/blog.goodaudience.com\/how-to-generate-a-word-cloud-of-any-shape-in-python-7bce27a55f6e","21c3d93d":"In the `image_clean` table, the dogbreeds in the **p1**, **p2**, _and_ **p3** are converting all the names to lowercase letters.","01a92077":"Make copies of each table first before cleaning, as to help reduce catastrophe","982096d7":"* A word cloud is a fun tool that lets user take the most frequently used words from a text, in this case, the tweets used in the dataset, and display in a fun image. \n* The outline of a paw print was used for this word cloud in association with the @WeRateDogs twitter account that was used in the process of this project.","cf6bb239":"> #2 **archive: Missing values in columns and unnecessary columns**","5ba5ee2f":"# Data Wrangle Final Project","3d946908":"##### Define","43e1a319":"* The time series code above was modeled after a blog post Tutorial about Time Series Analysis with Pandas. https:\/\/www.dataquest.io\/blog\/tutorial-time-series-analysis-with-pandas\/","979c727f":"* Code template above provided by Udacity. ","e04d6eea":"##### Programmatic","0c5a517c":"Take both the `archive_clean` and `tweet_clean` tables and merge into one table using the `join()` method on the columns **tweet_id**.","87da8dcd":"In the `archive_clean` table, use several methods such as `extractall()`, `query()`, `contains()`, etc to check for misextraction of the ratings.","10e80556":"##### Define","233d61df":"Find the retweets and replies using the **retweeted_status_id** and **in_reply_to_status_id** columns and remove from the DataFrame","fd970c94":"> #5 **image_clean: dog breeds uniformity**","5e365359":"##### Define","3a3c77b9":"#### Trends","57e568cb":"Removing the missing rows from the merged tables using the `drop()` method.","9e1b805c":"##### Code","d16d7e39":"##### Code","ad3ab82c":"* The line graph above, was used by resampling the average counts of data, in weekly intervals, much like a moving average, which helps smooth out the graph and improve visibility of the trends.\n* As mentioned before, with this timeseries chart above, the **favorite_count** and **retweet_count** are positively correlated with one another. This is due to the fact that most people retweet 'tweets' that they like in order for others to see it. It is like 'free advertising' for the 'tweet' itself and shows people on your feed what you're interested in. It's a sharing feature when you want others to see something you've read\/seen. \n* According to the chart, there are 3 spikes at specific times of year, those being, the middle of spring into summer, and then the Christmas\/Holiday time. This is most likely due to the fact that people with dogs are more active in the warmer months, posting cute things their dog is doing outside. Also, during the holidays, they are more likely to share pics\/etc about things they care about during this time i.e. their dogs. \n* The overall trend of the counts shows the popularity of this twitter page slowly growing overtime. If the number of followers were taken into account, it would most likely show a similar trend since the twitter account is getting more \"air time.\" ","5ba73cc7":"> Next, we downloaded an image of a paw print from the internet and used it in the function below to generate a word cloud with the tweets. ","566c419d":"## Cleaning the Data","57fdb35a":"> The **tweet_id** column should be dtype object instead of int64.","d02830f6":"##### Test","133b7e9a":"##### Define","3b51cea8":"> Many missing names from the list under __'None'__, and random names like **'a'** and __'an'__ might be parts of strings that got taken out of context.","b91f8f94":"##### Code","5ba739dd":"> * **tweet_id** has dtype int64 and should be object\n> * **timestamp** should be a datetime64 dtype type as well","ca9c663e":"##### Define","ed00743f":"#### Quality\n#### `archive` Table\n* Missing values in columns: __in_reply_to_status_id__, __in_reply_to_user_id__, __retweeted_status_id__, __retweeted_status_user_id__, __retweeted_status_timestamp__, and __expanded_urls__.\n* Column name __floofer__ should be spelled __'floof'__\n\n#### `image_pred` Table\n* The types of dogs in columns __p1__, __p2__, and __p3__ had some uppercase and lowercase letters. \n\n#### Tidiness\n* The column **text** had multiple variables like a url link, rating, and some tweets represented two dogs. \n* The `tweet_count` and `archive` table should be merged as this is related data.\n","93e381c4":"##### Code","502812f6":"##### Define","e8d21c9a":"##### Code","fde2ae2a":"> #6 **archive_clean: clean up text column**","44944eb4":"##### Introduction\n> The main purpose of this project is to use real world data to wrangle (gather, assess, clean) and then apply analysis with visualizations. The data used was from the Twitter account \u2018WeRateDogs\u2019 (@dog_rates) which \u201crates people's dogs with a humorous comments about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11\/10, 12\/10, 13\/10, etc.\u201d (Project Overview, Udacity). There are three pieces of data that will be gathered, cleaned, and then merged together to make one final DataFrame to analyze. ","c6c3d2ad":"##### Code","b0a2b216":"##### Code","47fc036b":"* In the `image_clean` table, change the dtype of column **tweet_id** from int64 to object using the `astype()` function. \n* In the `archive_clean` table, change the dtype of column **timestamp** from object to datetime using pandas `to_datetime()` function. \n* In the `archive_clean` table, change the dtype of column **tweet_id** from int64 to object using the `astype()` function.","ae65fcc5":"* The correlation chart is useful for finding connections between variables, especially with hypothesis testing or an A\/B test. The numbers range from 0 to 1, and a positive number is a positive correlation and vice versa for a negative number. \n* The correlation coefficient beteen **retweet_count** and **favorite_count** is 0.929604, which is close to 1 and positive demonstrating a strong positive correlation bewteen those two metrics. \n* The only other coefficient worth mentioning is the between **p1_conf** and **p3_conf** which is -0.706755, demonstrating a negative semi-strong relationship. This is probably a result because **p3_conf** confidence score is affected by the results of the first prediction in the neural network. The more confident the result of the first image, the less likely the following images would accurately guess the breed of dog. ","9b8034b9":"> #4 **Fixing Datatypes**\n\n> * **image_clean: tweet_id dtype \"string\"**\n> * **archive_clean: timestamp dtype \"datetime\"**\n> * **archive_clean: tweet_id dtype \"string\"**","5731cd8f":"> #8 **archive_clean: removing. doubles**","d8348007":"##### Test","cf2161c3":"> First table `archive` downloaded from the internet manually and programmatically opened into a pandas DataFrame.","b71e2366":"Take the newly `df_merge1` table and combine with the `image_clean` table using the same `join()` method on the **tweet_id** column.","c467fe8d":"> The column **id_str** should be changed to **tweet_id** so merging tables will be smoother.","bf6d5989":"##### Test","f4034916":"> #7 **archive_clean: fix some of the ratings columns**","b3893517":"> Third table, programmatically downloaded from the Udacity servers and stored in a folder `image_pred`, then written to local computer and loaded into a pandas DataFrame.","e8674e07":"##### Test","0b21de72":"##### Define","d9629c2c":"* In the `tweet_clean` table the column name **id_str** changed to **tweet_id** using the `rename()` function.\n* In the `archive_clean` table, column name **floofer** should be **\"floof\"** to match the dog stage associated with it using the `rename()` function. The columns **rating_numerator** and **rating_denominator** should be shortend to **\"rate_num\"** and **\"rate_denom\"** to make it less wordy.","53b85f8e":"##### Define","59ace3c8":"##### Test","ed91e179":"Remove columns with missing values using `dropna()` method. Also, use the `drop()` method to drop **source** column from table as well","6539d0b5":"* In the `archive_clean` table, change the html ampersand code from **\"&amp ;\"** to **\"&\"** in the **text** column\n* Remove the **\"\/n \"** the newline symbol \n* Remove ending url link.","1dccef6e":"## Analyzing the Data","5d9ab766":"##### Test","484f8ab4":"##### Define","f2be1e2e":"## Word Cloud with Tweets","91fc2338":"##### Test","e84020b7":"##### Code","20b24393":"> #1 **archive: remove from table retweets and replies keeping only original tweets**","fd7a5dbb":"##### Define","b9a5648a":"> Now we wanna take the final DataFrame and set the index to the **timestamp** column in order to gather some time series analysis. Twitter data is very time specific and would be nice visually to see changes over time. ","c5afacfa":"##### Test","ab18faff":"###### Visual","7420a94e":"> The **source** column looks messy and clutters the table"}}