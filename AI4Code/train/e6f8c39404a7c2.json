{"cell_type":{"55253154":"code","93fb6354":"code","e0f844b7":"code","7e0e6871":"code","4358f86c":"code","2ad2c73e":"code","04cc4fc3":"code","774a9c59":"code","31cf1c06":"code","57f42ff0":"code","076a4b4e":"code","b625fcf9":"code","ac1df0f1":"code","87938bd9":"code","c61760b7":"code","bb2841c8":"code","bc8c9fc4":"code","9a01bf40":"code","80a2d548":"code","b1f538e7":"code","c9daffce":"code","b38dea7b":"code","71bf12f5":"code","5a0c4d27":"code","5de8163f":"code","6c19ab20":"code","eeeba934":"code","436fc9f2":"code","3605c56f":"code","8d4a88b4":"code","a6a6acfe":"code","12f11a22":"code","2dda1577":"code","4ab783a4":"code","fa2a1b5e":"code","08142839":"code","83d732ce":"code","14f0f569":"code","59c5f8d7":"code","742ac7b0":"code","951ae71f":"code","a064c9de":"code","17ffe042":"code","a7bf8369":"markdown","7d85ee45":"markdown","33a3fd95":"markdown","c0ebf741":"markdown","de7cea35":"markdown","010eb849":"markdown"},"source":{"55253154":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","93fb6354":"df=pd.read_csv('..\/input\/aqi-project\/AQI_13_16_Banglore.csv')\ndf.shape","e0f844b7":"df.head()","7e0e6871":"## Check for null values\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","4358f86c":"df=df.dropna()","2ad2c73e":"X=df.iloc[:,:-1] ## independent features\ny=df.iloc[:,-1] ## dependent features","04cc4fc3":"X.isnull().sum()","774a9c59":"y.isnull().sum()","31cf1c06":"sns.pairplot(df)","57f42ff0":"df.corr()","076a4b4e":"import seaborn as sns\n#get correlations of each features in dataset\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","b625fcf9":"corrmat.index","ac1df0f1":"from sklearn.ensemble import ExtraTreesRegressor\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesRegressor()\nmodel.fit(X,y)","87938bd9":"X.head()","c61760b7":"print(model.feature_importances_)","bb2841c8":"\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(5).plot(kind='barh')\nplt.show()","bc8c9fc4":"sns.distplot(y)","9a01bf40":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","80a2d548":"from sklearn.ensemble import RandomForestRegressor","b1f538e7":"regressor=RandomForestRegressor()\nregressor.fit(X_train,y_train)","c9daffce":"print(\"Coefficient of determination R^2 <-- on train set: {}\".format(regressor.score(X_train, y_train)))","b38dea7b":"print(\"Coefficient of determination R^2 <-- on train set: {}\".format(regressor.score(X_test, y_test)))","71bf12f5":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(regressor,X,y,cv=5)","5a0c4d27":"score.mean()","5de8163f":"prediction=regressor.predict(X_test)","6c19ab20":"sns.distplot(y_test-prediction)","eeeba934":"plt.scatter(y_test,prediction)","436fc9f2":"RandomForestRegressor()","3605c56f":"from sklearn.model_selection import RandomizedSearchCV","8d4a88b4":"n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\nprint(n_estimators)","a6a6acfe":" #Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n# Method of selecting samples for training each tree\n# bootstrap = [True, False]\n","12f11a22":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","2dda1577":"# Use the random grid to search for best hyperparameters\nrf = RandomForestRegressor()","4ab783a4":"# Random search of parameters, using 3 fold cross validation, \nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 1)","fa2a1b5e":"rf_random.fit(X_train,y_train)","08142839":"rf_random.best_params_","83d732ce":"rf_random.best_score_","14f0f569":"predictions=rf_random.predict(X_test)","59c5f8d7":"sns.distplot(y_test-predictions)","742ac7b0":"plt.scatter(y_test,prediction)","951ae71f":"from sklearn import metrics\nprint('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","a064c9de":"import pickle ","17ffe042":"# open a file, where you ant to store the data\nfile = open('random_forest_regression_model.pkl', 'wb')\n\n# dump information to that file\npickle.dump(rf_random, file)","a7bf8369":"### Train Test split","7d85ee45":"## Hyperparameter Tuning","33a3fd95":"#### Model Evaluation","c0ebf741":"### Correlation Matrix with Heatmap","de7cea35":"## RandomForestRegressor","010eb849":"### Feature Selection"}}