{"cell_type":{"021e210c":"code","1256bcc2":"code","7cabb553":"code","c817494e":"code","2fe9030e":"code","723384b6":"code","f15fd011":"code","714f5079":"code","4fcf2839":"code","1f6bf576":"code","caf75f7d":"code","2053a52a":"code","2a26780f":"code","85543b0f":"code","3727f15c":"code","ba68cc2d":"code","3a2a0b67":"markdown","61b270e3":"markdown","b03618d8":"markdown","dfb5bed6":"markdown","ae19973a":"markdown","ee4d16f9":"markdown","8f52e5c5":"markdown","5eb2979e":"markdown","aa6592e3":"markdown","182138d3":"markdown","081d8128":"markdown","adcbc558":"markdown","8be31db4":"markdown","601ddfab":"markdown","b518da13":"markdown","907062ca":"markdown","32d38ca7":"markdown","0734f0e4":"markdown","e851bfcf":"markdown"},"source":{"021e210c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout ,Flatten, Conv2D, MaxPooling2D, Activation\nfrom keras.optimizers import Adam ,RMSprop\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1256bcc2":"train=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\nprint(train.shape)\nprint(test.shape)\n","7cabb553":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\n\n# free some space\ndel train \n\nprint(X_train.shape)\nprint(Y_train.shape)\n\n# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n\n# reshaping the dataset\n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\nprint(X_train.shape)\nprint(test.shape)","c817494e":"Y_train = to_categorical(Y_train, num_classes = 10)","2fe9030e":"for i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i][:,:,0])","723384b6":"#define the convnet \nclass LeNet:\n\t@staticmethod\n\tdef build(input_shape, classes):\n\t\tmodel = Sequential()\n\t\t# CONV => RELU => POOL\n\t\tmodel.add(Conv2D(20, kernel_size=5, padding=\"same\",\n\t\t\tinput_shape=input_shape))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\t\t# CONV => RELU => POOL\n\t\tmodel.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n\t\tmodel.add(Activation(\"relu\"))\n\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\t\t# Flatten => RELU layers\n\t\tmodel.add(Flatten())\n\t\tmodel.add(Dense(500))\n\t\tmodel.add(Dropout(0.3))\n\t\tmodel.add(Activation(\"relu\"))\n \n\t\t# a softmax classifier\n\t\tmodel.add(Dense(classes))\n\t\tmodel.add(Activation(\"softmax\"))\n\n\t\treturn model\n","f15fd011":"\nNB_EPOCH = 20\nBATCH_SIZE = 128\nVERBOSE = 1\nOPTIMIZER = Adam()\nVALIDATION_SPLIT=0.2 # For validation with 20 percent of the training data.\n\nIMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\nNB_CLASSES = 10  # number of outputs = number of digits\nINPUT_SHAPE = (IMG_ROWS, IMG_COLS, 1)\n","714f5079":"# initialize the optimizer and model\nmodel = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n\tmetrics=[\"accuracy\"])\n","4fcf2839":"history = model.fit(X_train, Y_train, \n\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH, \n\t\tverbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n","1f6bf576":"# Set a learning rate annealer\nlr_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n\n# split the dataset to reserve a validation dataset.\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\n\n# data generator.\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  \n\n\ndatagen.fit(X_train)","caf75f7d":"NB_EPOCH = 30\nBATCH_SIZE = 128\nVERBOSE = 1\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n\tmetrics=[\"accuracy\"])\n\n# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=BATCH_SIZE),\n                              epochs = NB_EPOCH, validation_data = (X_val,Y_val),\n                              verbose = VERBOSE, steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE\n                              , callbacks=[lr_reduction])","2053a52a":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper left')\nplt.show()","2a26780f":"def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","85543b0f":"# Display some error results \n\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    n = 0\n    nrows = 3\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 9 errors \nmost_important_errors = sorted_dela_errors[-9:]\n\n# Show the top 9 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","3727f15c":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n","ba68cc2d":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"LeNet_mnist_datagen.csv\",index=False)\n","3a2a0b67":"And now, let us train the model.\n\n## 5. Train the model without data augmentation","61b270e3":"### Confusion matrix\n\nConfusion matrix can be very helpfull to see your model drawbacks.\nWe plot the confusion matrix of the validation results.\n","b03618d8":"## 9. Submision.","dfb5bed6":"Before making network ready for training we have to make sure to add below things:\n\n1. **A loss function:** to measure how good the network is\n\n2. **An optimizer:** to update network as it sees more data and reduce loss value\n\n3. **Metrics:** to monitor performance of network\n","ae19973a":"### preprocess of data.\n\nTo conserve the spatial structure and relations of each image, we need to reshape image in dataset in 3 dimension (height = 28px, width = 28px , canal = 1). In particular, we transforms a flat vector representing each written digit into the bitmap representation for having the spatial locality of image.","ee4d16f9":"# An application of computer Vision with MNIST digit recognition Challenge. (~99.60% Accuracy)\n\n\n### Table of interest:\n1. Introduction\n2. Import and Preprocess the data\n3. Visualize some examples from the dataset.\n4. Defining the model architecture Using ConVnets\n5. Train the model without data augmentation\n6. Train the model using data augmentation\n7. Evaluate the model\n8. Prediction\n9. Submition","8f52e5c5":"For the data augmentation, we choosed to :\n* Randomly rotate some training images by 10 degrees\n* Randomly Zoom by 10% some training images\n* Randomly shift images horizontally by 10% of the width\n* Randomly shift images vertically by 10% of the height\n\nI did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\n\nNow, lets fit the training data.","5eb2979e":"## 6. Train the model using data augmentation\n   one of the most commun tehnique to avoid overfitting is **data augmentation**. And We know that overfitting is generaly occur when we don't have enought data for training the model. To avoid this overfitting problem, we need to expand artificially our handwritten digit dataset. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit. \n    Also, in order to make the optimizer converge faster and closest to the global minimum of the loss function, we used an annealing method of the learning rate (LR). The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.\n    Its better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.\n\nDifferent data aumentation techniques are as follows:\n1. Cropping\n2. Rotating\n3. Scaling\n4. Translating\n5. Flipping\n6. Adding Gaussian noise to input images etc.\n\n\nOk lets get started with data augmentation review code.","aa6592e3":"## 3. Visualize some examples from the dataset.\n\nLets vizualise some images from dataset. ","182138d3":"## 4. Defining the model architecture Using ConVnets\n\n   Yann le Cun proposed (for more information refer to: ***Convolutional Networks for Images, Speech,\nand Time-Series, by Y. LeCun and Y. Bengio, brain theory neural networks, vol. 3361, 1995***) a family\nof ConvNets named LeNet trained for recognizing MNIST handwritten characters with robustness to\nsimple geometric transformations and to distortion. The key intuition here is to have low-layers\nalternating convolution operations with max-pooling operations. The convolution operations are\nbased on carefully chosen local receptive fields with shared weights for multiple feature maps. Then,\nhigher levels are fully connected layers based on a traditional MLP with hidden layers and softmax as\nthe output layer.\n\n\n   To define LeNet code, we use a convolutional 2D module, which is:\n`keras.layers.convolutional.Conv2D(filters, kernel_size, padding='valid')`\n\n**Here :**\n* `filters` : is the number of convolution kernels to use (for example, the dimensionality of the output);\n* `kernel_size` :  is an integer or tuple\/list of two integers, specifying the width and height of the 2D convolution window (can be a single integer to specify the same value for all spatial dimensions);\n* `padding='same'` means that padding is used. There are two options: `padding='valid'` means that the convolution is only computed where the input and the filter fully overlap, and therefore the output is smaller than the input, while `padding='same'` means that we have an output that is the same size as the input, for which the area around the input is padded with zeros.\n\nIn addition, we use a `MaxPooling2D` module:\n`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))`\n\n**Here :**\n* `pool_size=(2, 2)` is a tuple of two integers representing the factors by which the image is vertically and horizontally downscaled. So (2, 2) will halve the image in each dimension;\n* `strides=(2, 2)` is the stride used for processing.\n\nThen we define the LeNet network:\n\n* We have a first **convolutional** stage with `relu` activations followed by a **max-pooling**. Our net will learn `20` convolutional filters, each one of which has a size of `5 x 5`.The output dimension is the same one of the `input_shape`, so it will be `28 x 28`. Note that since the Convolution2D is the first stage of our pipeline, we are also required to define its `input_shape` . The max-pooling operation implements a sliding window that slides over the layer and takes the maximum of each region with a step of two pixels vertically and horizontally.\n\n* Then a second **convolutional** stage with `relu` activations follows, again by a **max-pooling**. In this case, we increase the number of convolutional filters learned to `50` from the previous `20`. Increasing the number of filters in deeper layers is a common technique used in deep learning.\n\n* Then we have a pretty standard flattening and a **dense network** of `500` neurons, followed by a `Dropout` of `0.3` probabilitie before a `softmax` classifier with `10` classes.\n\nLet's see how it looks visually:\n\n![LeNet.png](attachment:LeNet.png)\n\nAnd now, let us review the code.","081d8128":"### Import of data","adcbc558":"## 8. Prediction","8be31db4":"As we can look with this visualization, our model don't overfit after 30 epochs. We can increse the nomber off epochs without causing overfitting but the performance of our model don't increse significantly. ","601ddfab":"### Miss-labeled data visualization","b518da13":"## 2. Import and Preprocess the data\n\n### Import all required libraries","907062ca":"## 1. Introduction.\n\nThis is my first project on Kaggle and is done mainly for myself, for my personal experimentation of computer vision problem and CNN architectures. I hope that it might be helpful for others.\nI'm trying to Experiment a LeNet architecture of CNN on MNIST digit dataset. For this purpuse, this notebook is inspired of many kaggle Kernel and many others papers which ares availlable on web, especially this one : <a href = \"www.packtpub.com\">Deep Learning with Keras<\/a>.\n\nMNIST is called Hello world of Deep learning.\n\n\nLet's get started.","32d38ca7":"Hope that you find this notebook helpful for you. More to come.\n\nPlease upvote if you find it useful. That will keep me motivated for doing more better.\n\nThanks.","0734f0e4":"The output variable is an integer from 0 to 9. This is a multiclass classification problem. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]). \n","e851bfcf":"## 7. Evaluate the model ( Model with data augmentation)\n\n### Training and validation curves."}}