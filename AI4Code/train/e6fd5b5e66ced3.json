{"cell_type":{"edcead80":"code","d84b204a":"code","8799f13b":"code","0a57a3f0":"code","8207dd39":"code","dfd289d2":"code","d4dd5926":"code","b3b9886b":"code","1eb210d7":"code","f142eeb6":"code","5a2a38c9":"code","27b3aaca":"code","c2b28130":"code","5305f504":"code","8906e802":"code","77069278":"code","15e01ef6":"code","8491c96a":"code","016bbbdd":"code","fd7b7ffd":"code","0a98b6c4":"code","d45e71e6":"code","ca7cb446":"code","bfddf71f":"code","96400dd0":"code","3633d4e9":"code","fadc94a7":"code","a2b8058e":"code","b8884d37":"code","a594882b":"code","9f972f59":"code","2468d256":"code","78f424b9":"code","11b325cb":"code","7907e2c1":"code","498df17e":"code","5d5916df":"code","84dce90e":"code","8a10d40b":"code","cec62b6e":"code","5c755c6f":"code","99df5459":"code","c2711ad5":"code","88be7582":"code","18f8deb4":"code","6103a9cc":"code","a6506ceb":"code","d4a5de69":"code","16f0b091":"code","e51a903d":"code","cfc96ca4":"code","3a1eb481":"code","0344fd46":"code","4dfda45b":"code","0761c3d6":"code","7609d8f9":"code","5c25ec9a":"code","18d5e66a":"code","15084e71":"code","d911430f":"code","7495fc22":"code","3b156c0c":"code","3dfe8203":"code","9f3582ce":"code","18c41f0d":"markdown","6bd4727a":"markdown","627f23f3":"markdown","fce3c875":"markdown","2883b837":"markdown","9ba2b9ed":"markdown","25029b61":"markdown","5561fc58":"markdown","e94d38df":"markdown","4dab2d0e":"markdown","ec823004":"markdown","9d7eecfc":"markdown","236b5469":"markdown","0d174a47":"markdown","d48075b0":"markdown"},"source":{"edcead80":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.transform import resize\nimport time\nimport gc\nimport math\nfrom sklearn.metrics import confusion_matrix\n\nimport os","d84b204a":"import tensorflow as tf\nfrom tensorflow.keras.layers import Activation, Input, Add, Dense, Concatenate, Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization, Flatten, Dropout\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras  import layers","8799f13b":"IM_SIZE = 64\nval_split = 0.2\ntrain_rate = 1 - val_split\nn_file = 4\nn_each_train = 50210\nn2_train = 12000","0a57a3f0":"def conv2d_unit(array, conv, stride, padding = True):\n    #array.shape = (x,y)\n    #conv.shape = (x,y)\n    size = conv.shape[0]\n    pad = int(size\/2)\n    L1 = array.shape[0]\n    L3 = int(math.ceil(L1\/stride))\n\n    if padding == True:\n        L2 = L1 + 2*pad \n        \n        array2 = np.zeros((L2, L2))\n        array3 = np.zeros((L3, L3))\n        array2[pad:L1+pad, pad:L1+pad] = array[:,:]\n        \n        for i in range(L3):\n            for j in range(L3):\n                x2 = stride*i\n                y2 = stride*j\n                a = np.sum(array2[x2:x2+size,y2:y2+size]*conv)\n                \n                array3[i,j] = a\n        \n        return array3\n\ndef conv2d(array, conv, stride = 1, padding = True):\n    #array.shape = (x,y,n)\n    #conv.shape =(x,y,c,n)\n    n1 = array.shape[2]\n    n2 = conv.shape[3]\n    L1 = array.shape[0]\n    L3 = int(math.ceil(L1\/stride))    \n    \n    array3 = np.zeros((L3,L3,n2))\n    for i in range(n2):\n        for j in range(n1):\n            array3[:,:,i] += conv2d_unit(array[:,:,j], conv[:,:,0,i], stride)\n    \n    return array3","8207dd39":"def pooling_unit(array, size, stride):\n    L1 = array.shape[0]\n    L3 = int(math.ceil(L1\/stride))\n    pad = int(size\/2)\n    L2 = size + int(stride*L3*(L3-1)\/2) + 2*pad\n\n    array2 = np.zeros((L2, L2))    \n    array3 = np.zeros((L3, L3))\n    array2[pad:L1+pad,pad:L1+pad] = array[:,:]\n    \n    for i in range(L3):\n        for j in range(L3):\n            array3[i,j] = np.max(array2[stride*i:stride*i+size,stride*j:stride*j+size])\n    \n    return array3\n\ndef pooling(array, size = 2, stride = 2):\n    #array.shape = (x,y,z) \n    N = array.shape[2]\n    L1 = array.shape[0]\n    L3 = int(math.ceil(L1\/stride))\n    array2 = np.zeros((L3,L3,N))\n    for i in range(N):\n        array2[:,:,i] = pooling_unit(array[:,:,i], size, stride)\n    \n    return array2","dfd289d2":"def adding_b(array, b):\n    n = b.shape[0]\n    for i in range(n):\n        array[:,:,i] += b[i]\n    \n    return array","d4dd5926":"#one hot encoding of train label\ndef one_hot_encoder(data):\n    array = np.zeros((data.shape[0], data.max() + 1))\n    \n    for i in range(data.shape[0]):\n        array[i,data[i]] = 1\n        \n    return array","b3b9886b":"def cnn_model(FS, F):\n    Input_X = Input(shape=(IM_SIZE,IM_SIZE,1))\n    #64\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(Input_X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = MaxPooling2D(pool_size=(2, 2), strides=2)(X)    \n    #32\n    F = 2*F\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = MaxPooling2D(pool_size=(2, 2), strides=2)(X)\n    \n    #16\n    F = 2*F\n    FS = 3\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = MaxPooling2D(pool_size=(2, 2), strides=2)(X)  \n    \n    #8    \n    F = 2*F\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)\n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = Conv2D(F,  kernel_size = FS, strides=(1, 1),  padding='same',\n                kernel_initializer = glorot_uniform(seed=1), activation = \"relu\")(X)  \n    X = MaxPooling2D(pool_size=(2, 2), strides=2)(X)\n    F = 2*F\n\n    #4\n    #flatten\n    X = Flatten()(X)\n    X = BatchNormalization()(X)\n    X = Dropout(0.4)(X)\n    X = Dense(F, activation='relu', kernel_initializer= glorot_uniform(seed=1))(X)\n    X = Dropout(0.4)(X)\n    X = Dense(F, activation='relu', kernel_initializer= glorot_uniform(seed=1))(X)\n    X = Dropout(0.35)(X)    \n   \n    Xg = Dense(168, activation='softmax', kernel_initializer='glorot_uniform')(X)    \n    Xv = Dense(11, activation='softmax', kernel_initializer='glorot_uniform')(X)\n    Xc = Dense(7, activation='softmax', kernel_initializer='glorot_uniform')(X)\n        \n    model = Model(inputs = Input_X, outputs = [Xg, Xv, Xc])\n    adam = optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00005, amsgrad=False)\n    model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n    \n    return model    ","1eb210d7":"def train_model(Model, epochs):\n    history = Model.fit(x = train_m, y = [out_g, out_v, out_c], sample_weight = [weight_g*2, weight_v, weight_c], \n          validation_split=val_split, epochs = epochs, batch_size=250)\n    return history","f142eeb6":"def train_model_final(Model, epochs):\n    history = Model.fit(x = train_m, y = [out_g,out_g,out_g, out_v, out_c], sample_weight = [weight_g, weight_g,weight_g, weight_v, weight_c], \n          validation_split=val_split, epochs = epochs, batch_size=250)\n    return history","5a2a38c9":"def train_model_big(Model, epochs):\n    history = Model.fit(x = train_m, y = [out_g,out_g,out_g, out_v, out_c], sample_weight = [weight_g,weight_g,weight_g, weight_v, weight_c], \n          validation_split=val_split, epochs = epochs, batch_size=250)\n    return history","27b3aaca":"def generate_filtered_image(array, model):\n    #array.shape = (x,y,1)\n    conv1 = model.get_weights()[0]\n    b1 = model.get_weights()[1]\n    conv2 = model.get_weights()[2]\n    b2 = model.get_weights()[3]\n    conv3 = model.get_weights()[4]\n    b3 = model.get_weights()[5]\n    conv4 = model.get_weights()[6]\n    b4 = model.get_weights()[7]\n    \n    conv5 = model.get_weights()[8]\n    b5 = model.get_weights()[9]\n    conv6 = model.get_weights()[10]\n    b6 = model.get_weights()[11]\n    conv7 = model.get_weights()[12]\n    b7 = model.get_weights()[13]\n    conv8 = model.get_weights()[14]\n    b8 = model.get_weights()[15]\n    \n    conv9 = model.get_weights()[16]\n    b9 = model.get_weights()[17]\n    conv10 = model.get_weights()[18]\n    b10 = model.get_weights()[19]\n    conv11 = model.get_weights()[20]\n    b11 = model.get_weights()[21]\n    conv12 = model.get_weights()[22]\n    b12 = model.get_weights()[23]\n    \n    conv13 = model.get_weights()[24]\n    b13 = model.get_weights()[25]\n    conv14 = model.get_weights()[26]\n    b14 = model.get_weights()[27]\n    conv15 = model.get_weights()[28]\n    b15 = model.get_weights()[29]    \n    conv16 = model.get_weights()[30]\n    b16 = model.get_weights()[31]       \n    \n    x1 = adding_b(conv2d(array, conv1), b1)\n    x2 = adding_b(conv2d(x1, conv2), b2)\n    x3 = adding_b(conv2d(x2, conv3), b3)\n    x4 = adding_b(conv2d(x3, conv4), b4)\n    xp1 = pooling(x4)\n    \n    x5 = adding_b(conv2d(xp1, conv5), b5)\n    x6 = adding_b(conv2d(x5, conv6), b6)\n    x7 = adding_b(conv2d(x6, conv7), b7)\n    x8 = adding_b(conv2d(x7, conv8), b8)\n    xp2 = pooling(x8)    \n    \n    x9 = adding_b(conv2d(xp2, conv9), b9)\n    x10 = adding_b(conv2d(x9, conv10), b10)\n    x11 = adding_b(conv2d(x10, conv11), b11)\n    x12 = adding_b(conv2d(x11, conv12), b12)\n    xp3 = pooling(x12)       \n    \n    x13 = adding_b(conv2d(xp3, conv13), b13)\n    x14 = adding_b(conv2d(x13, conv14), b14)\n    x15 = adding_b(conv2d(x14, conv15), b15)\n    x16 = adding_b(conv2d(x15, conv16), b16)\n    xp4 = pooling(x16)    \n    \n    return x1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4","c2b28130":"def generate_filtered_image_3(array, model, seq, stride):\n    layer = []\n    n = len(seq)\n    m = len(model.get_weights())\n    for i in range(m):\n        layer.append(model.get_weights()[i])   \n   \n    X = []\n    i = 0\n    k = 0\n    AR = array\n    while k < n:\n        \n        if seq[k] == \"c\":\n            x_tmp = conv2d(AR, layer[i], stride = stride[k])\n            X.append(x_tmp)\n            i += 1\n            X.append(adding_b(x_tmp, layer[i]))\n            i += 1\n        elif seq[k] == \"p\":\n            X.append(pooling(AR, stride = stride[k]))\n        k += 1\n        \n        AR = X[-1]\n        \n    return X\n    ","5305f504":"def show_conv_images(array, name):\n    n = array.shape[2]\n    if n > 10:\n        n=10 + int((n-10)\/3)\n    fig, ax = plt.subplots(1,n, figsize = (18,3))\n    for i in range(n):\n        ax[i].imshow(array[:,:,i], cmap = \"gray\")\n        if i % 10 == 0:\n            ax[i].set_title(name +\" - \"+ str(i+1))\n        ax[i].set_xticks([], [])\n        ax[i].set_yticks([], [])\n    \n    plt.show()","8906e802":"def show_original_image(array):\n    fig, ax = plt.subplots(figsize = (3,3))\n    ax.imshow(array, cmap = \"gray\")\n    ax.set_title(\"original cropped image\")\n    ax.set_xticks([], [])\n    ax.set_yticks([], [])\n    plt.show()","77069278":"class_map = pd.read_csv(\"\/kaggle\/input\/bengaliai-cv19\/class_map.csv\")\ntrain_label = pd.read_csv(\"\/kaggle\/input\/bengaliai-cv19\/train.csv\")\ntest_label = pd.read_csv(\"\/kaggle\/input\/bengaliai-cv19\/test.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv\")","15e01ef6":"train_m = pd.read_parquet(\"\/kaggle\/input\/bengali-create-processed-file\/processed_train.parquet\")","8491c96a":"train_m = np.reshape(train_m.values,(train_m.shape[0],64,64))","016bbbdd":"out_g = one_hot_encoder(train_label[\"grapheme_root\"][0:train_m.shape[0]].values)\nout_v = one_hot_encoder(train_label[\"vowel_diacritic\"][0:train_m.shape[0]].values)\nout_c = one_hot_encoder(train_label[\"consonant_diacritic\"][0:train_m.shape[0]].values)","fd7b7ffd":"count_grapheme = train_label[[\"grapheme_root\"]][0:train_m.shape[0]].groupby(\"grapheme_root\").size()\nmax_graheme = count_grapheme.max()\nweight_grapheme = pd.DataFrame({\"grapheme_root\": range(168), \"W_g\":max_graheme\/(count_grapheme.values)})\n\ncount_vowel = train_label[[\"vowel_diacritic\"]][0:train_m.shape[0]].groupby(\"vowel_diacritic\").size()\nmax_vowel = count_vowel.max()\nweight_vowel = pd.DataFrame({\"vowel_diacritic\": range(11), \"W_v\":max_vowel\/(count_vowel.values)})\n\ncount_consonant = train_label[[\"consonant_diacritic\"]][0:train_m.shape[0]].groupby(\"consonant_diacritic\").size()\nmax_consonant = count_consonant.max()\nweight_consonant = pd.DataFrame({\"consonant_diacritic\": range(7), \"W_c\":max_consonant\/(count_consonant.values)})","0a98b6c4":"weight_cosonant_dic = {}\nfor i in range(weight_consonant.shape[0]):\n    key = weight_consonant.iloc[i,0]\n    val = weight_consonant.iloc[i,1]\n    weight_cosonant_dic[key] = val\n    \nweight_vowel_dic = {}\nfor i in range(weight_vowel.shape[0]):\n    key = weight_vowel.iloc[i,0]\n    val = weight_vowel.iloc[i,1]\n    weight_vowel_dic[key] = val\n\nweight_grapheme_dic = {}\nweight_grapheme_dic2 = {}\nweight_grapheme_dic3 = {}\nfor i in range(weight_grapheme.shape[0]):\n    key = weight_grapheme.iloc[i,0]\n    val = weight_grapheme.iloc[i,1]\n    weight_grapheme_dic[key] = np.sqrt(2*val-1)\n    weight_grapheme_dic2[key] = val\n    weight_grapheme_dic3[key] = np.sqrt(2*val-1)*2","d45e71e6":"train_m = np.reshape(train_m, (train_m.shape[0], train_m.shape[1],train_m.shape[2], 1))","ca7cb446":"model = cnn_model(FS = 2, F = 16)","bfddf71f":"model.summary()","96400dd0":"history_g = model.fit(x = train_m, y = [out_g, out_v, out_c], \n                    class_weight = [weight_grapheme_dic3,  \n                                    weight_vowel_dic, weight_cosonant_dic], \n                    validation_split=val_split, \n          epochs = 10, \n          batch_size= 400, shuffle = True)","3633d4e9":"sample = 978\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","fadc94a7":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","a2b8058e":"sample = 17001\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","b8884d37":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","a594882b":"model = cnn_model(FS = 3, F = 16)","9f972f59":"model.summary()","2468d256":"history_g = model.fit(x = train_m, y = [out_g, out_v, out_c], \n                    class_weight = [weight_grapheme_dic3,  \n                                    weight_vowel_dic, weight_cosonant_dic], \n                    validation_split=val_split, \n          epochs = 10, \n          batch_size= 400, shuffle = True)","78f424b9":"sample = 978\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","11b325cb":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","7907e2c1":"sample = 17001\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","498df17e":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","5d5916df":"model = cnn_model(FS = 4, F = 16)","84dce90e":"model.summary()","8a10d40b":"history_g = model.fit(x = train_m, y = [out_g, out_v, out_c], \n                    class_weight = [weight_grapheme_dic3,  \n                                    weight_vowel_dic, weight_cosonant_dic], \n                    validation_split=val_split, \n          epochs = 10, \n          batch_size= 400, shuffle = True)","cec62b6e":"sample = 978\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","5c755c6f":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","99df5459":"sample = 17001\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","c2711ad5":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","88be7582":"model = cnn_model(FS = 5, F = 16)","18f8deb4":"model.summary()","6103a9cc":"history_g = model.fit(x = train_m, y = [out_g, out_v, out_c], \n                    class_weight = [weight_grapheme_dic3,  \n                                    weight_vowel_dic, weight_cosonant_dic], \n                    validation_split=val_split, \n          epochs = 10, \n          batch_size= 400, shuffle = True)","a6506ceb":"sample = 978\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","d4a5de69":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","16f0b091":"sample = 17001\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","e51a903d":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","cfc96ca4":"model = cnn_model(FS = 6, F = 16)","3a1eb481":"model.summary()","0344fd46":"history_g = model.fit(x = train_m, y = [out_g, out_v, out_c], \n                    class_weight = [weight_grapheme_dic3,  \n                                    weight_vowel_dic, weight_cosonant_dic], \n                    validation_split=val_split, \n          epochs = 10, \n          batch_size= 400, shuffle = True)","4dfda45b":"sample = 978\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","0761c3d6":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","7609d8f9":"sample = 17001\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","5c25ec9a":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","18d5e66a":"model = cnn_model(FS = 7, F = 16)","15084e71":"model.summary()","d911430f":"history_g = model.fit(x = train_m, y = [out_g, out_v, out_c], \n                    class_weight = [weight_grapheme_dic3,  \n                                    weight_vowel_dic, weight_cosonant_dic], \n                    validation_split=val_split, \n          epochs = 10, \n          batch_size= 400, shuffle = True)","7495fc22":"sample = 978\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","3b156c0c":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","3dfe8203":"sample = 17001\nx1,x2,x3,x4,xp1, x5,x6,x7,x8,xp2, x9,x10,x11,x12,xp3, x13,x14,x15,x16,xp4 = generate_filtered_image(train_m[sample,:,:,:], model)","9f3582ce":"show_original_image(train_m[sample,:,:,0])\nshow_conv_images(x1, name = \"conv1\")\nshow_conv_images(x2, name = \"conv2\")\nshow_conv_images(x3, name = \"conv3\")\nshow_conv_images(x4, name = \"conv4\")\nshow_conv_images(xp1, name = \"maxpool\")\n\nshow_conv_images(x5, name = \"conv5\")\nshow_conv_images(x6, name = \"conv6\")\nshow_conv_images(x7, name = \"conv7\")\nshow_conv_images(x8, name = \"conv8\")\nshow_conv_images(xp2, name = \"maxpool\")\n\nshow_conv_images(x9, name = \"conv9\")\nshow_conv_images(x10, name = \"conv10\")\nshow_conv_images(x11, name = \"conv11\")\nshow_conv_images(x12, name = \"conv12\")\nshow_conv_images(xp3, name = \"maxpool\")\n\nshow_conv_images(x13, name = \"conv13\")\nshow_conv_images(x14, name = \"conv14\")\nshow_conv_images(x15, name = \"conv15\")\nshow_conv_images(x16, name = \"conv16\")\nshow_conv_images(xp4, name = \"maxpool\")","18c41f0d":"## Functions\n","6bd4727a":"## Case1. CNN filter size 2 with Max Pooling 2","627f23f3":"### 4. CNN Model","fce3c875":"### 2. MaxPooling","2883b837":"## Case2. CNN filter size 3 with Max Pooling 2","9ba2b9ed":"### 3. Adding constant","25029b61":"### 6. Plot Image","5561fc58":"### 5. Image Generator","e94d38df":"## Read file","4dab2d0e":"### 1. Convolution Layer","ec823004":"## Case3. CNN filter size 4 with Max Pooling 2","9d7eecfc":"## Case5. CNN filter size 6 with Max Pooling 2","236b5469":"## Purpose\n**How the input image looks like after convolution layers? What is the effect of convolution filter size?**\nThose are always mysterious but curious for data science learners. In this kernel, I attemp to visualize images after going through each CNN layers.\nThis work have been achieved by following steps.\n\n* step1. training model for a while.\n* step2. to extract elements of each layers from trained model by Keras\n* step3. to compute image data with extracted elements of CNN layers \n\nFurthermore, convolution and pooling layers are manually defined by functions. It was even good training for me to re-learn CNN logic. Please note that the amount of train data is smaller than the actual competition's data to reduce computation time. Becasue this kernel is for study purpose. \n","0d174a47":"## Case4. CNN filter size 5 with Max Pooling 2","d48075b0":"## Case6. CNN filter size 7 with Max Pooling 2"}}