{"cell_type":{"c0abe8ce":"code","fb7b4630":"code","57903248":"code","0956f69e":"code","c66f3628":"code","0837042f":"code","3d50061d":"code","b814e7e1":"code","a18038e4":"code","87a4c3d0":"code","a3721342":"code","98fa923c":"code","cd3a9462":"code","96bdc069":"code","672888a0":"code","fe1aaf08":"code","b479f792":"code","b94c9a06":"code","8f72540b":"code","77cfc71b":"code","2a9507ce":"code","cd4da210":"code","815c7acc":"code","55d1931d":"code","0ae2e0c2":"code","3c311be5":"code","31505969":"code","2a6a206c":"code","f445fbe7":"code","76a21756":"code","2111335d":"markdown"},"source":{"c0abe8ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import * \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models as visonmodels\n\n# Any results you write to the current directory are saved as output.","fb7b4630":"!ls ..\/input\n!mkdir -p \/tmp\/.torch\/models\/\n!cp ..\/input\/pretrained-pytorch-models\/* \/tmp\/.torch\/models\/\n!cp ..\/input\/resnet-from-fastai\/* \/tmp\/.torch\/models","57903248":"path = Path('..\/input\/digit-recognizer')","0956f69e":"class CustomImageItemList(ImageList):\n    def open(self, fn):\n        img = fn.reshape(28, 28)\n        img = np.stack((img,)*3, axis=-1) # convert to 3 channels\n        return Image(pil2tensor(img, dtype=np.float32))\n\n    @classmethod\n    def from_csv_custom(cls, path:PathOrStr, csv_name:str, imgIdx:int=1, header:str='infer', **kwargs) -> 'ItemList':\n        df = pd.read_csv(Path(path)\/csv_name, header=header)\n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        # convert pixels to an ndarray\n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values \/ 783.0, axis=1).values\n        return res","c66f3628":"test = CustomImageItemList.from_csv_custom(path=path, csv_name='test.csv', imgIdx=0)\ndata = (CustomImageItemList.from_csv_custom(path=path, csv_name='train.csv')\n                       .split_by_rand_pct(.2)\n                       .label_from_df(cols='label')\n                       .add_test(test, label=0)\n                       .databunch(bs=64, num_workers=0)\n                       .normalize(imagenet_stats))","0837042f":"x, y = next(iter(data.train_dl))\nprint(x.shape)\nprint(y.shape)","3d50061d":"data.show_batch(rows=3, figsize=(12,9))","b814e7e1":"arch1 = models.resnet34","a18038e4":"arch1()","87a4c3d0":"class Net1(nn.Module):\n    def __init__(self,pretrained):\n        super(Net1, self).__init__()\n        self.conv1 = nn.Conv2d(3, 20, 5, 1)\n        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n        self.fc1 = nn.Linear(4*4*50, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2, 2)\n        x = x.view(-1, 4*4*50)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","a3721342":"# class Net1(nn.Module):\n#     def __init__(self,pretrained):\n#         super(Net1, self).__init__()\n#         self.body=nn.Sequential(\n#             nn.Conv2d(3, 20, 5, 1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2),\n#             nn.Conv2d(20, 50, 5, 1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(2),\n\n#         )\n#         self.head=nn.Sequential(\n#             nn.Linear(4*4*50, 500),\n#             nn.ReLU(),\n#             nn.Linear(500, 10),\n#             nn.LogSoftmax(dim=1)\n#         )\n\n#     def forward(self, x):\n#         x=self.body(x)\n#         x = x.view(-1, 4*4*50)\n#         return self.head(x)","98fa923c":"arch2 = Net1","cd3a9462":"print(torch.__version__)","96bdc069":"torch.cuda.is_available()","672888a0":"learn = Learner(data, arch2(False),metrics=error_rate,model_dir='\/tmp\/models')","fe1aaf08":"# learn =  cnn_learner(data, arch2,pretrained=False,model_dir='\/tmp\/models')","b479f792":"learn.lr_find()\nlearn.recorder.plot()","b94c9a06":"lr = 0.03","8f72540b":"learn.fit_one_cycle(3, slice(lr))","77cfc71b":"# learn.fit_one_cycle(30, max_lr=slice(3e-5,3e-4),callbacks=[SaveModelCallback(learn,monitor='error_rate',mode='min')])\n#rule of thumb do Lowest error rate.","2a9507ce":"learn.recorder.plot_losses()","cd4da210":"learn.save('stage-1')","815c7acc":"learn.load('stage-1')","55d1931d":"interp = learn.interpret()","0ae2e0c2":"interp.plot_top_losses(9, figsize=(7,7))","3c311be5":"preds, y, losses = learn.get_preds(ds_type=DatasetType.Test, with_loss=True)","31505969":"# Bug in fastai? Why is this needed?\ny = torch.argmax(preds, dim=1)","2a6a206c":"submission_df = pd.DataFrame({'ImageId': range(1, len(y) + 1), 'Label': y}, columns=['ImageId', 'Label'])\nsubmission_df.head()","f445fbe7":"submission_df.to_csv('submission.csv', index=False)","76a21756":"!head submission.csv","2111335d":"Pull in digit reader"}}