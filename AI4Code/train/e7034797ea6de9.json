{"cell_type":{"c0039713":"code","49548347":"code","9501bdea":"code","cf6b5afa":"code","74e42427":"code","6caa48dd":"code","eb44abb8":"code","01d629ad":"code","7a05a89e":"code","56739286":"code","1fa553da":"code","13384f29":"code","82876cef":"code","c103dd15":"code","eac24bd5":"markdown","5698e8d4":"markdown"},"source":{"c0039713":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","49548347":"from pathlib import Path\nfrom fastai import *\nfrom fastai.vision import *\nimport torch","9501bdea":"data_folder = Path(\"..\/input\")","cf6b5afa":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/sample_submission.csv\")","74e42427":"train_df.head()","6caa48dd":"test_df.head()","eb44abb8":"## Reads images from the test folder with the dataframe that contains ids that act as the image name for test\ntest_img = ImageList.from_df(test_df, path=data_folder\/'test', folder='test')\n\n\n## setting the transformations to be applied on the images \ntransformations = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1, max_lighting=0.1, \n                                 max_warp=0.2, p_affine=0.75, p_lighting=0.75)\n\n\n\n##########\n## (ImageList.from_df(train_df, path=data_folder\/'train', folder='train') gives us ImageList object to apply \n\n# split_by_rand_pct(): Split the items randomly by putting valid_pct in the validation set, optional seed can be passed.\n# add_test() : Add test set containing items with an arbitrary label (here arbitrary label is 0.5)\n# label_from_df(): Label self.items from the values in cols in self.inner_df.\n# transform() : to run the transformations decides in the transfomations object above\n# databunch() : to convert to a DataBunch bs is batch size\n\n# torch.device() argument ->\n#----------------------------------------------------------------------------------------------------------------------\n# A torch.device is an object representing the device on which a torch.Tensor is or will be allocated.\n\n# The torch.device contains a device type ('cpu' or 'cuda') and optional device ordinal for the device type. \n# If the device ordinal is not present, this represents the current device for the device type; e.g. a torch.\n# Tensor constructed with device 'cuda' is equivalent to 'cuda:X' where X is the result of torch.cuda.current_device().\n\n# A torch.Tensor\u2019s device can be accessed via the Tensor.device property.\n\n# A torch.device can be constructed via a string or via a string and device ordinal\n\n#----------------------------------------------------------------------------------------------------------------------\n\ntrain_image_list_bunch = (ImageList.from_df(train_df, path=data_folder\/'train', folder='train')\n        .split_by_rand_pct(0.02)\n        .label_from_df()\n        .add_test(test_img)\n        .transform(transformations, size=128)\n        .databunch(path='.', bs=64, device= torch.device('cuda:0'))\n        .normalize(imagenet_stats)\n       )","01d629ad":"train_image_list_bunch.show_batch(rows=4, figsize=(7,6))","7a05a89e":"# The cnn_learner factory method helps you to automatically get a pretrained model from a given architecture \n# with a custom head that is suitable for your data.\n\n# cnn_learner[source][test]\n# cnn_learner(data:DataBunch, base_arch:Callable, cut:Union[int, Callable]=None, pretrained:bool=True, \n#             lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[Module]=None, \n#             split_on:Union[Callable, Collection[ModuleList], NoneType]=None, bn_final:bool=False, \n#             init='kaiming_normal_', concat_pool:bool=True, **kwargs:Any) \u2192 Learner\n\n# Build convnet style learner.\n\n# This method creates a Learner object from the data object and model inferred from it with the backbone given in arch. \n# Specifically, it will cut the model defined by arch (randomly initialized if pretrained is False) at the last \n# convolutional layer by default\n\nlearn = cnn_learner(train_image_list_bunch, models.densenet161, metrics=[error_rate, accuracy])","56739286":"# lr_find(): Explore lr from start_lr to end_lr over num_it iterations in learn. If stop_div, \n# stops when loss diverges.\n\nlearn.lr_find()\nlearn.recorder.plot()","1fa553da":"## fit_one_cycle(): Fits number of cycles\/epochs as per arguments\n\n\n# fit_one_cycle(learn:Learner, cyc_len:int, max_lr:Union[float, Collection[float], slice]=slice(None, 0.003, None), \n#               moms:Point=(0.95, 0.85), div_factor:float=25.0, pct_start:float=0.3, final_div:float=None, \n#               wd:float=None, callbacks:Optional[Collection[Callback]]=None, tot_epochs:int=None, \n#               start_epoch:int=None)\n\n# Fit a model following the 1cycle policy.\n\n\nlr = 1e-01\nlearn.fit_one_cycle(5, slice(lr))","13384f29":"#get pedictions from the model\npreds,_ = learn.get_preds(ds_type=DatasetType.Test)","82876cef":"test_df.has_cactus = preds.numpy()[:, 0]","c103dd15":"test_df.to_csv('submission.csv', index=False)","eac24bd5":"#### Here is a graph of the key module dependencies\n\n![Here is a graph of the key module dependencies](https:\/\/docs.fast.ai\/imgs\/dependencies.svg)","5698e8d4":"# Introduction\n\n\nThanks to https:\/\/www.kaggle.com\/kenseitrg\/simple-fastai-exercise Please upvote!\n\nThe fastai library simplifies training fast and accurate neural nets using modern best practices. \u201cfast.ai\u201d offers a practical way of mastering Deep Learning by straight away going coding and implementing of real Kaggle competitions. Then later slowly it builds a solid understanding about the underlying concepts of \u2018Neural Networks\u2019, how these concepts can be applied to real world scenarios, their(Neural Networks) limitations.\n\nHere is the link to the courses (free and no ads) : https:\/\/www.fast.ai\/\n\n\n### The code has been commented as comprehensively as possible for explanation purpose."}}