{"cell_type":{"2b546e50":"code","cd4fc1f8":"code","a46c6817":"code","37b4aa4f":"code","cd827c2f":"code","be9fce26":"code","123f5d6f":"code","4e031667":"code","af20b6f5":"code","125967e1":"code","7647d749":"code","96fba380":"code","18799854":"code","c8a0f4b6":"code","ab42892d":"code","041cc9e0":"code","7a92f23a":"code","60e768b9":"code","91723f52":"code","587b82c7":"code","d615219a":"code","c013eae7":"code","a5fc8166":"code","ec5b986c":"code","b1c6beba":"code","f1f5a23c":"code","8050140d":"code","40de1c4c":"code","606c1730":"code","e9ddbf3d":"code","559302ea":"code","94f04a1e":"code","6706b862":"code","ffc33a7e":"code","f0b42a4c":"code","0e5912b7":"code","c1e10165":"code","c6b027d6":"code","22de06a6":"code","99944423":"code","865a58d4":"code","74166fe9":"code","b9aba1db":"code","64cf1697":"code","dd3390cb":"code","4c9d8143":"code","3dd11e0c":"code","47c8292c":"code","445ce804":"code","b7c4fe3a":"code","d61f508e":"code","28157ff4":"code","79ad6766":"code","80d2c956":"code","bf530178":"code","78ff4748":"code","13a9df7d":"code","6ad5493e":"code","b4a9c414":"code","cbed9502":"code","6163dfeb":"code","8eaafcae":"code","17f2b9e5":"code","a37c40ec":"code","b8250cc3":"code","d3074211":"code","d54f4494":"code","95710dc3":"code","504fd46f":"code","a75ed383":"code","c58cd3b8":"code","75c09355":"code","97699c5d":"code","157cef2d":"code","df15fff4":"code","ecbe9edd":"code","35a277ed":"code","e3aed1b4":"code","d133db3e":"code","1eccd758":"code","87b68687":"code","e91126c3":"code","f5c9ecd9":"code","a85b1edc":"code","8333dbd2":"code","622fd744":"code","1d44eb1f":"code","1332bdc6":"code","fcd3e38b":"code","0e682c5b":"code","d2b4b313":"code","90849831":"markdown","5c97a556":"markdown","f3b99ee8":"markdown","e6e99859":"markdown","efda4521":"markdown","1f21f2c6":"markdown","43bb2410":"markdown"},"source":{"2b546e50":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","cd4fc1f8":"df=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndf_test=pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","a46c6817":"df.shape,df_test.shape","37b4aa4f":"null_values=df.isnull().sum().to_frame()\nnull_values.columns=['Count of null values']\nnull_values[null_values['Count of null values']>0]","cd827c2f":"null_values_test=df_test.isnull().sum().to_frame()\nnull_values_test.columns=['Count of null values']\nnull_values_test[null_values_test['Count of null values']>0]","be9fce26":"df_combine=pd.concat([df,df_test],axis=0)","123f5d6f":"df_combine.shape","4e031667":"null=df_combine.isnull().sum().to_frame()\nnull.columns=['Count of null values']\nnull[null['Count of null values']>0]","af20b6f5":"df_combine.loc[df_combine['Alley'].isnull(),'Alley']='No alley access'\ndf_combine.loc[df_combine['LotFrontage'].isnull(),'LotFrontage']=df_combine['LotFrontage'].median()\ndf_combine.loc[df_combine['MasVnrType'].isnull(),'MasVnrType']='Other'\ndf_combine.loc[df_combine['MasVnrArea'].isnull(),'MasVnrArea']=0\ndf_combine.loc[df_combine['BsmtQual'].isnull(),'BsmtQual']='No Basement'\ndf_combine.loc[df_combine['BsmtCond'].isnull(),'BsmtCond']='No Basement'\ndf_combine.loc[df_combine['BsmtExposure'].isnull(),'BsmtExposure']='No Basement'\ndf_combine.loc[df_combine['BsmtFinType1'].isnull(),'BsmtFinType1']='No Basement'\ndf_combine.loc[df_combine['BsmtFinType2'].isnull(),'BsmtFinType2']='No Basement'\ndf_combine.loc[df_combine['FireplaceQu'].isnull(),'FireplaceQu']='No Fireplace'\ndf_combine.loc[df_combine['GarageType'].isnull(),'GarageType']='No Garage'\ndf_combine.loc[df_combine['GarageYrBlt'].isnull(),'GarageYrBlt']=0\ndf_combine.loc[df_combine['GarageFinish'].isnull(),'GarageFinish']='No Garage'\ndf_combine.loc[df_combine['GarageQual'].isnull(),'GarageQual']='No Garage'\ndf_combine.loc[df_combine['GarageCond'].isnull(),'GarageCond']='No Garage'\ndf_combine.loc[df_combine['Electrical'].isnull(),'Electrical']='SBrkr'","125967e1":"null=df_combine.isnull().sum().to_frame()\nnull.columns=['Count of null values']\nnull[null['Count of null values']>0]","7647d749":"#A large values are missing for PoolQC hence deleting the column\ndf_combine['PoolQC'].value_counts()\ndf_combine.drop(['Id','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)","96fba380":"null=df_combine.isnull().sum().to_frame()\nnull.columns=['Count of null values']\nnull[null['Count of null values']>0]","18799854":"df_combine=df_combine.reset_index()\ndf_combine.drop('index',axis=1,inplace=True)\ndf_combine","c8a0f4b6":"df_combine.loc[df_combine['BsmtFinSF1'].isnull() | df_combine['BsmtFinSF2'].isnull(),'BsmtFinSF1']=0\ndf_combine.loc[df_combine['BsmtFinSF1'].isnull() | df_combine['BsmtFinSF2'].isnull(),'BsmtFinSF2']=0","ab42892d":"df_combine.loc[df_combine['BsmtFullBath'].isnull(),'BsmtFullBath']=df_combine['BsmtFullBath'].mode()[0]\ndf_combine.loc[df_combine['BsmtHalfBath'].isnull(),'BsmtHalfBath']=df_combine['BsmtHalfBath'].mode()[0]\ndf_combine.loc[df_combine['BsmtUnfSF'].isnull(),'BsmtUnfSF']=df_combine['BsmtUnfSF'].median()\ndf_combine.loc[df_combine['Exterior1st'].isnull(),'Exterior1st']=df_combine['Exterior1st'].mode()[0]\ndf_combine.loc[df_combine['Exterior2nd'].isnull(),'Exterior2nd']=df_combine['Exterior2nd'].mode()[0]\ndf_combine.loc[df_combine['Functional'].isnull(),'Functional']=df_combine['Functional'].mode()[0]\ndf_combine.loc[df_combine['GarageArea'].isnull(),'GarageArea']=0\ndf_combine.loc[df_combine['GarageCars'].isnull(),'GarageCars']=df_combine['GarageCars'].mode()[0]\ndf_combine.loc[df_combine['KitchenQual'].isnull(),'KitchenQual']=df_combine['KitchenQual'].mode()[0]\ndf_combine.loc[df_combine['MSZoning'].isnull(),'MSZoning']=df_combine['MSZoning'].mode()[0]\ndf_combine.loc[df_combine['SaleType'].isnull(),'SaleType']=df_combine['SaleType'].mode()[0]\ndf_combine.loc[df_combine['TotalBsmtSF'].isnull(),'TotalBsmtSF']=0\ndf_combine.loc[df_combine['Utilities'].isnull(),'Utilities']=df_combine['Utilities'].mode()[0]","041cc9e0":"df=df_combine.iloc[0:1460,:].copy(deep=True)\ndf_test=df_combine.iloc[1460:,:].copy(deep=True)","7a92f23a":"df.shape,df_test.shape","60e768b9":"null_values=df.isnull().sum().to_frame()\nnull_values.columns=['Count of null values']\nnull_values[null_values['Count of null values']>0]","91723f52":"null_values_test=df_test.isnull().sum().to_frame()\nnull_values_test.columns=['Count of null values']\nnull_values_test[null_values_test['Count of null values']>0]","587b82c7":"df.head()","d615219a":"numeric=['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd','BsmtFinSF1',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'GarageYrBlt', 'GarageArea',\n        'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal']\n\ncat=['MSSubClass', 'MSZoning','Street', 'Alley','LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath','GarageCars',\n       'BedroomAbvGr', 'KitchenAbvGr','TotRmsAbvGrd',\n       'OverallQual', 'OverallCond', 'RoofStyle','RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n       'CentralAir', 'Electrical', 'KitchenQual','Functional', 'FireplaceQu', 'GarageType',\n       'GarageFinish', 'GarageQual', 'GarageCond', 'MoSold', 'YrSold','Fireplaces',\n       'PavedDrive', 'SaleType','SaleCondition']","c013eae7":"len(numeric),len(cat)","a5fc8166":"for i in cat:\n    plt.figure(figsize=(20,5))\n    plt.subplot(1,2,1)\n    plt.title(i)\n    ((df[i].value_counts()\/df.shape[0])*100).plot(kind='bar')\n    plt.subplot(1,2,2)\n#     df.boxplot(column='SalePrice',by=i)\n    sns.boxplot(df[i],df['SalePrice'])\n    plt.xticks(rotation=90)\n    plt.show()\n","ec5b986c":"for i in numeric:\n    sns.scatterplot(df[i],df['SalePrice'])\n    plt.show()","b1c6beba":"corrdf=pd.DataFrame(df.corr()['SalePrice'])\ncorrdf","f1f5a23c":"sns.boxplot(df['SalePrice'])","8050140d":"df['SalePrice'].plot(kind='kde')","40de1c4c":"# lets apply log transformation as it is right skewed\ndf['SalePrice']=np.log(df['SalePrice'])","606c1730":"sns.boxplot(df['SalePrice'])","e9ddbf3d":"df['SalePrice'].skew()","559302ea":"df['SalePrice'].plot(kind='kde')","94f04a1e":"df_combine=pd.concat([df,df_test],axis=0)\ndf_combine=df_combine.reset_index()\ndf_combine.drop('index',axis=1,inplace=True)\ndf_combine","6706b862":"df_dummies1=pd.DataFrame()\nfor i in cat:\n    df_dummies=pd.DataFrame()\n    df_dummies=pd.get_dummies(df_combine[i],prefix=i,drop_first=True)\n    df_dummies1=pd.concat([df_dummies1,df_dummies],axis=1)\n    \ndf_dummies1.head()","ffc33a7e":"for i in cat:\n    df_combine.drop(i,axis=1,inplace=True)\ndf_combine.columns","f0b42a4c":"df_final=pd.concat([df_dummies1,df_combine],axis=1)\ndf_final","0e5912b7":"df=df_final.iloc[0:1460,:].copy(deep=True)\ndf_test=df_final.iloc[1460:,:].copy(deep=True)\ndf.shape,df_test.shape","c1e10165":"X=df.drop('SalePrice',axis=1)\nY=df['SalePrice']","c6b027d6":"from sklearn.preprocessing import MinMaxScaler\nminmax=MinMaxScaler()\nx1=minmax.fit_transform(X)\ndf_multi_scaled=pd.DataFrame(x1,columns=X.columns)\ndf_multi_scaled.head()","22de06a6":"X_test=df_test.drop('SalePrice',axis=1)\nY_test=df_test['SalePrice']\nx2=minmax.transform(X_test)\ndf_multi_scaled_test=pd.DataFrame(x2,columns=X_test.columns)\n# df_multi_scaled_test.head()","99944423":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(df_multi_scaled)\nlin_reg = sm.OLS(Y,X_constant).fit()\nlin_reg.summary()","865a58d4":"cols = list(df_multi_scaled.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = df_multi_scaled[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(Y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)\n","74166fe9":"len(selected_features_BE)","b9aba1db":"dfnew=df_multi_scaled[selected_features_BE]\ndftestnew=df_multi_scaled_test[selected_features_BE]","64cf1697":"df_combine=pd.concat([dfnew,dftestnew])\ndf_combine=df_combine.reset_index()\ndf_combine.drop('index',axis=1,inplace=True)\ndf_combine","dd3390cb":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n[variance_inflation_factor(df_combine.values, j) for j in range(1, df_combine.shape[1])]","4c9d8143":"def calculate_vif(x):\n    thresh = 5.0\n    output = pd.DataFrame()\n    k = x.shape[1]\n    vif = [variance_inflation_factor(x.values, j) for j in range(x.shape[1])]\n    for i in range(1,k):\n        a = np.argmax(vif)\n        if vif[a] <= thresh :\n            break\n        if i == 1 :          \n            output = x.drop(x.columns[a], axis = 1)\n            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n        elif i > 1 :\n            output = output.drop(output.columns[a],axis = 1)\n            vif = [variance_inflation_factor(output.values, j) for j in range(output.shape[1])]\n    return(output)","3dd11e0c":"Xnew=calculate_vif(df_combine)\nXnew.head()","47c8292c":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n[variance_inflation_factor(Xnew.values, j) for j in range(1, Xnew.shape[1])]","445ce804":"df=Xnew.iloc[0:1460,:].copy(deep=True)\ndf_test=Xnew.iloc[1460:,:].copy(deep=True)","b7c4fe3a":"df.shape,df_test.shape","d61f508e":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(df)\nlin_reg = sm.OLS(Y,X_constant).fit()\nlin_reg.summary()","28157ff4":"cols = list(df.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = df[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(Y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)\n","79ad6766":"df=df[selected_features_BE]\ndf_test=df_test[selected_features_BE]","80d2c956":"\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import model_selection\nfrom sklearn.linear_model import Ridge,ElasticNet,Lasso\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score","bf530178":"variance=[]\nmeans=[]\nfor n in np.arange(0.001,1,0.001):\n    ridge=Ridge(alpha=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=model_selection.cross_val_score(ridge,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    means.append(np.mean(rmse))\n    variance.append(np.std(rmse,ddof=1))\nx_axis=np.arange(0.001,1,0.001)\nplt.plot(x_axis,variance) \n","78ff4748":"np.argmin(variance),means[np.argmin(variance)],variance[np.argmin(variance)]","13a9df7d":"variance_lasso=[]\nmeans_lasso=[]\nfor n in np.arange(0.001,1,0.0001):\n    lasso=Lasso(alpha=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=cross_val_score(lasso,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    means_lasso.append(np.mean(rmse))\n    variance_lasso.append(np.std(rmse,ddof=1))\nx_axis=np.arange(0.001,1,0.0001)\nplt.plot(x_axis,variance_lasso) \n","6ad5493e":"np.argmin(variance_lasso),means_lasso[np.argmin(variance_lasso)],variance_lasso[np.argmin(variance_lasso)]","b4a9c414":"np.argmin(means_lasso),means_lasso[np.argmin(means_lasso)],variance_lasso[np.argmin(means_lasso)]","cbed9502":"from sklearn.linear_model import ElasticNetCV, ElasticNet\ncv_model = ElasticNetCV(l1_ratio=np.arange(0.001,1,0.001),n_jobs=-1, random_state=0)\ncv_model.fit(df,Y)\nprint('Optimal alpha: %.8f'%cv_model.alpha_)\nprint('Optimal l1_ratio: %.3f'%cv_model.l1_ratio_)\nprint('Number of iterations %d'%cv_model.n_iter_)","6163dfeb":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor","8eaafcae":"#3)Decision tree\nDT=DecisionTreeRegressor()\nfrom sklearn.model_selection import RandomizedSearchCV\nparams={'max_depth':np.arange(5,150),\n       'min_samples_leaf':np.arange(5,50),\n       'min_samples_split':np.arange(5,50)\n       }\ngsearch=RandomizedSearchCV(DT,param_distributions=params,cv=3,scoring='neg_mean_squared_error',random_state=0)\ngsearch.fit(df,Y)\ngsearch.best_params_","17f2b9e5":"# 3)tunning k value\nknn=KNeighborsRegressor()\nknn_params={'n_neighbors':np.arange(1,100),'weights':['uniform','distance']}\nrandomsearch=RandomizedSearchCV(knn,knn_params,cv=3,scoring='neg_mean_squared_error',random_state=0)\nrandomsearch.fit(df,Y)\nrandomsearch.best_params_","a37c40ec":"means_knn=[]\nvariance_knn=[]\nfor n in np.arange(1,100):\n    KNN=KNeighborsRegressor(weights='distance',n_neighbors=n)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    value=model_selection.cross_val_score(KNN,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(value))\n    variance_knn.append(np.std(rmse,ddof=1))\n    means_knn.append(np.mean(rmse))\n    \nx_axis=np.arange(len(means_knn))\nplt.plot(x_axis,means_knn)","b8250cc3":"np.argmin(means_knn),means_knn[np.argmin(means_knn)],variance_knn[np.argmin(means_knn)]","d3074211":"np.argmin(variance_knn),means_knn[np.argmin(variance_knn)],variance_knn[np.argmin(variance_knn)]","d54f4494":"\nvariance_rf=[]\nmeans_rf=[]\nfor n in np.arange(1,100):\n    RF=RandomForestRegressor(criterion='mse',n_estimators=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=cross_val_score(RF,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    means_rf.append(np.mean(rmse))\n    variance_rf.append(np.std(rmse,ddof=1))\n    \n\nx_axis=np.arange(len(variance_rf))\nplt.plot(x_axis,variance_rf) ","95710dc3":"np.argmin(variance_rf),means_rf[ np.argmin(variance_rf)],np.min(variance_rf)","504fd46f":"np.argmin(means_rf),means_rf[np.argmin(means_rf)],variance_rf[np.argmin(means_rf)]","a75ed383":"from sklearn.ensemble import BaggingRegressor","c58cd3b8":"means_Bag_DT=[]\nvariance_Bag_DT=[]\nfor n in np.arange(1,200):\n    Bag=BaggingRegressor(n_estimators=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=cross_val_score(Bag,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    means_Bag_DT.append(np.mean(rmse))\n    variance_Bag_DT.append(np.std(rmse,ddof=1))\nx_axis=np.arange(len(variance_Bag_DT))\nplt.plot(x_axis,means_Bag_DT)","75c09355":"np.argmin(variance_Bag_DT),means_Bag_DT[np.argmin(variance_Bag_DT)],variance_Bag_DT[np.argmin(variance_Bag_DT)]","97699c5d":"np.argmin(means_Bag_DT),means_Bag_DT[np.argmin(means_Bag_DT)],variance_Bag_DT[np.argmin(means_Bag_DT)]","157cef2d":"knn_cust=KNeighborsRegressor(weights='uniform',n_neighbors=6,n_jobs=-1)\nmeans_Bag_knngrid=[]\nvariance_Bag_knngrid=[]\nfor n in np.arange(1,50):\n    Bag=BaggingRegressor(base_estimator=knn_cust,n_estimators=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=cross_val_score(Bag,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    means_Bag_knngrid.append(np.mean(rmse))\n    variance_Bag_knngrid.append(np.std(rmse,ddof=1))\nx_axis=np.arange(len(variance_Bag_knngrid))\nplt.plot(x_axis,variance_Bag_knngrid)","df15fff4":"np.argmin(variance_Bag_knngrid),means_Bag_knngrid[np.argmin(variance_Bag_knngrid)],variance_Bag_knngrid[np.argmin(variance_Bag_DT)]","ecbe9edd":"np.argmin(means_Bag_knngrid),means_Bag_knngrid[np.argmin(means_Bag_knngrid)],variance_Bag_knngrid[np.argmin(means_Bag_knngrid)]","35a277ed":"from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,VotingRegressor\n","e3aed1b4":"rmse_ada_DT=[]\nvariance_ada_DT=[]\nfor n in np.arange(1,100):\n    AB=AdaBoostRegressor(n_estimators=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=cross_val_score(AB,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    rmse_ada_DT.append(np.mean(rmse))\n    variance_ada_DT.append((np.std(rmse,ddof=1)))\nx_axis=np.arange(len(rmse_ada_DT))\nplt.plot(x_axis,rmse_ada_DT)","d133db3e":"np.argmin(rmse_ada_DT),rmse_ada_DT[np.argmin(rmse_ada_DT)],variance_ada_DT[np.argmin(rmse_ada_DT)]","1eccd758":"np.argmin(variance_ada_DT),rmse_ada_DT[np.argmin(variance_ada_DT)],variance_ada_DT[np.argmin(variance_ada_DT)]","87b68687":"# RandomForest=RandomForestRegressor(n_estimators=6,random_state=0,n_jobs=-1)\n# rmse_ada_RandomForest=[]\n# variance_ada_RandomForest=[]\n# for n in np.arange(1,100):\n#     AB=AdaBoostRegressor(base_estimator=RandomForest,n_estimators=n,random_state=0)\n#     kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n#     scores=cross_val_score(AB,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n#     rmse=np.sqrt(np.abs(scores))\n#     rmse_ada_RandomForest.append(np.mean(rmse))\n#     variance_ada_RandomForest.append((np.std(rmse,ddof=1)))\n# x_axis=np.arange(len(rmse_ada_RandomForest))\n# plt.plot(x_axis,rmse_ada_RandomForest)\n# np.argmin(rmse_ada_RandomForest),rmse_ada_RandomForest[np.argmin(rmse_ada_RandomForest)],variance_ada_RandomForest[np.argmin(rmse_ada_RandomForest)]\n# np.argmin(variance_ada_RandomForest),rmse_ada_RandomForest[np.argmin(variance_ada_RandomForest)],variance_ada_RandomForest[np.argmin(variance_ada_RandomForest)]\n","e91126c3":"# Best estimator for RandomForest is 98","f5c9ecd9":"LR=LinearRegression()\nrmse_ada_GB=[]\nvariance_ada_GB=[]\nfor n in np.arange(1,260):\n    GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n    kfold = model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    scores=cross_val_score(GB,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    rmse=np.sqrt(np.abs(scores))\n    rmse_ada_GB.append(np.mean(rmse))\n    variance_ada_GB.append((np.std(rmse,ddof=1)))\nx_axis=np.arange(len(rmse_ada_GB))\nplt.plot(x_axis,rmse_ada_GB)","a85b1edc":"np.argmin(rmse_ada_GB),rmse_ada_GB[np.argmin(rmse_ada_GB)],variance_ada_GB[np.argmin(rmse_ada_GB)]","8333dbd2":"np.argmin(variance_ada_GB),rmse_ada_GB[np.argmin(variance_ada_GB)],variance_ada_GB[np.argmin(variance_ada_GB)]","622fd744":"ridge=Ridge(alpha=0.107,random_state=0)\nelasticnet = ElasticNet(l1_ratio=0.059, alpha =0.00178473,  fit_intercept=True)\nFGDT=DecisionTreeRegressor()\nDT=DecisionTreeRegressor(min_samples_split=30,min_samples_leaf=9,max_depth=79,random_state=0)\nRandomForest=RandomForestRegressor(n_estimators=99,random_state=0,n_jobs=-1)\nknn_grid=KNeighborsRegressor(weights='uniform',n_neighbors=7,n_jobs=-1)\nknn_cust=KNeighborsRegressor(weights='distance',n_neighbors=6,n_jobs=-1)\nBag_dt=BaggingRegressor(n_estimators=6,random_state=0)\nboost_dt=AdaBoostRegressor(n_estimators=49,random_state=0)\nboost_randomForest=AdaBoostRegressor(base_estimator=RandomForest,n_estimators=98,random_state=0)\ngradientboost=GradientBoostingRegressor(n_estimators=259,random_state=0)\nstacked_1 = VotingRegressor(estimators = [('Elasticnet', elasticnet),('Gradientboost',gradientboost), ('AdaBoost Default', boost_dt)])\nstacked_2 = VotingRegressor(estimators = [('Elasticnet', elasticnet),('Gradientboost',gradientboost), ('Ridge', ridge)])\n\n\n\nmodels = []\nmodels.append(('Ridge', ridge))\nmodels.append(('ElasticNet',elasticnet))\nmodels.append(('FGDT',FGDT))\nmodels.append(('DT',DT))\nmodels.append(('RandomForest',RandomForest))\nmodels.append(('KNN GRID',knn_grid))\nmodels.append(('KNN cust',knn_cust))\nmodels.append(('Bagged DT',Bag_dt))\nmodels.append(('ADABoost DT',boost_dt))\nmodels.append(('ADABoost RF',boost_randomForest))\nmodels.append(('Gradient Boosting',gradientboost))\nmodels.append(('Stacking-elastic net,gradient boost and AdaBoostDT',stacked_1))\nmodels.append(('Stacking-elastic net,gradient boost and Ridge',stacked_2))\n","1d44eb1f":"# After removing multicollinearity lets perform linear regression and then RIDGE and  LASSO\nmeans=[]\nrmse=[]\nnames=[]\nvariance=[]\ndf_result=pd.DataFrame()\nfor name,model in models:\n    kfold=model_selection.KFold(shuffle=True,n_splits=3,random_state=0)\n    cv_result=model_selection.cross_val_score(model,df,Y,cv=kfold,scoring='neg_mean_squared_error')\n    value=np.sqrt(np.abs(cv_result))\n    print(value)\n    means.append(value)\n    names.append(name)\n    rmse.append(np.mean(value))\n    variance.append(np.std((value),ddof=1))\ndf_result['Names']=names\ndf_result['RMSE']=rmse\ndf_result['Variance']=variance\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(means)\nax.set_xticklabels(names)\nplt.xticks(rotation=90)\nplt.show()","1332bdc6":"df_result","fcd3e38b":"\ndf_result.sort_values(by='RMSE')","0e682c5b":"df_result.sort_values(by='Variance')","d2b4b313":"stacked_2.fit(df,Y)\npredicted_values=stacked_2.predict(df_test)\npred=np.exp(predicted_values)\nresult=pd.DataFrame(pred)\nresult","90849831":"# Performing Log Transformation on target variable as it is right skewed","5c97a556":"The above graph is showing  percentage wise category and second plot is showing distribution as well showing within a category which groups have costlier houses","f3b99ee8":"# Lets convert categorical to numeric","e6e99859":"#  Multicollinearity","efda4521":" categorical values","1f21f2c6":"# EDA","43bb2410":"OverallQual,GrLivArea,GarageCars,GarageArea,TotalBsmtSF,1stFlrSF these are few features having strong positive correlation with SalePrice"}}