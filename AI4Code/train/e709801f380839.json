{"cell_type":{"90aa8e04":"code","cff33c25":"code","2f0f8c34":"code","3daf1408":"code","e58d7694":"code","07912362":"code","35aba4f1":"code","6da8135c":"code","12b374c1":"code","486df5a7":"code","aa27f168":"code","25978198":"code","7bb23c5d":"code","4658b71c":"code","d2cc6097":"code","93a6bcf7":"code","814f161a":"code","782e981a":"code","2b95b738":"code","ad0e3963":"code","92d76729":"code","c1a037f4":"code","8189823d":"code","f1ba4329":"code","7ff8dfa9":"code","919fc77c":"code","fbd16c35":"code","5e7fdfba":"code","47052554":"code","3cb5bce8":"code","48343f21":"code","8a97a5f2":"code","4a0dc862":"code","066be248":"code","b92f5d89":"code","550fe377":"code","e2972bff":"code","1777210e":"code","23f96cd0":"code","a0d2d9bb":"code","600bb58e":"code","a0b9fe46":"code","6e1ebaa2":"code","b6b4565d":"code","66d33440":"markdown","4376b2dd":"markdown","67da278b":"markdown","50e891fc":"markdown","7f4326a1":"markdown","2af0ad00":"markdown","bdadc450":"markdown","846b58fb":"markdown","1669c836":"markdown","c13a9f50":"markdown","d89471f2":"markdown","b5ccdd67":"markdown","0c89ba8d":"markdown","bc26452f":"markdown","750d55c8":"markdown","2dd1da4c":"markdown","474904a4":"markdown","238a8893":"markdown","12dbbfe8":"markdown"},"source":{"90aa8e04":"#import packages\nimport numpy as np \nimport pandas as pd\n\n#import data\nred_cam_viol_org = pd.read_csv('..\/input\/chicago-red-light-and-speed-camera-data\/red-light-camera-violations.csv')\nred_cam_loc_org = pd.read_csv('..\/input\/chicago-red-light-and-speed-camera-data\/red-light-camera-locations.csv')","cff33c25":"# install csvvalidator \nimport sys\n!{sys.executable} -m pip install csvvalidator","2f0f8c34":"# import packages \nfrom csvvalidator import *\n\n# fields for first dataframe\nfield_names_1 = ('INTERSECTION', 'VIOLATION DATE', 'VIOLATIONS')\n\n# create validator object\nvalidator_1 = CSVValidator(field_names_1)\n\n# write checks\nvalidator_1.add_value_check('INTERSECTION', str, 'EX1.1', 'Intersection must be a string')\nvalidator_1.add_value_check('VIOLATION DATE', datetime_string('%Y-%m-%d'), 'EX1.2', 'Invalid date')\nvalidator_1.add_value_check('VIOLATIONS', int, 'EX1.3', 'Number of violations not an integer')\n\n# fields for second dataframe\nfield_names_2 = ('INTERSECTION', 'LONGITUDE', 'LATITUDE')\n\n# create validator object\nvalidator_2 = CSVValidator(field_names_2)\n\n# write checks\nvalidator_2.add_value_check = ('INTERSECTION', str, 'EX2.1', 'Intersection must be a string')\nvalidator_2.add_value_check = ('LONGITUDE', float, 'EX2.2', 'Longitude not a float')\nvalidator_2.add_value_check = ('LATITUDE', float, 'EX2.3', 'Latitude not a float')","3daf1408":"# import libraries \nimport csv\nfrom io import StringIO\n\n# first sample csv\ngood_data_1 = StringIO(\"\"\"INTERSECTION,VIOLATION DATE,VIOLATIONS\nTest1-Test2,2014-08-05, 5\nTest3-Test4,2014-07-11,12\nTest5-Test6,2014-07-04,30\n\"\"\")\n\n# read text in as a csv\ntest_csv_1 = csv.reader(good_data_1)\n\n# validate first good csv\nvalidator_1.validate(test_csv_1)","e58d7694":"# second sample csv\ngood_data_2 = StringIO(\"\"\"INTERSECTION,LONGITUDE,LATITUDE\nTest1-Test2, 41.931791, -87.726979\nTest3-Test4, 41.924237, -87.746302\nTest5-Test6, 41.923676, -87.785441\n\"\"\")\n\n# read text in as a csv\ntest_csv_2 = csv.reader(good_data_2)\n\n# validate first good csv\nvalidator_2.validate(test_csv_2)","07912362":"#examine dataframe\nred_cam_viol_org.head()","35aba4f1":"#remove unnecessary columns\n\nred_cam_viol = red_cam_viol_org[[\"INTERSECTION\", \"CAMERA ID\", \"ADDRESS\", \"VIOLATION DATE\", \"VIOLATIONS\"]].copy()\nred_cam_viol.head()","6da8135c":"# number of red light camera violations \nred_cam_viol[\"VIOLATIONS\"].sum()","12b374c1":"# number of red light camera violations per day\n\n# convert column to \"date time\"\nred_cam_viol[\"VIOLATION DATE\"] = pd.to_datetime(red_cam_viol[\"VIOLATION DATE\"])\n\n# add new column with day of week \nred_cam_viol[\"Day of Week\"] = red_cam_viol[\"VIOLATION DATE\"].dt.day_name()\n\n# create two dictionarys to sort by day of week \ndays = {'Monday' : 1, 'Tuesday' : 2, 'Wednesday' : 3, 'Thursday' : 4, 'Friday' : 5, 'Saturday' : 6, 'Sunday' : 7}\ndays2 = {1: 'Monday', 2: 'Tuesday', 3 : 'Wednesday', 4: 'Thursday', 5 : 'Friday', 6 : 'Saturday', 7 : 'Sunday'}\n\n# group by day of week, sum number of violations, and sort by day of week\nviol_per_day = red_cam_viol.groupby([\"Day of Week\"])[\"VIOLATIONS\"].count()\nviol_per_day = viol_per_day.reset_index()\nviol_per_day[\"Day of Week\"] = viol_per_day[\"Day of Week\"].map(days)\nviol_per_day = viol_per_day.sort_values(by = \"Day of Week\")\nviol_per_day[\"Day of Week\"] = viol_per_day[\"Day of Week\"].map(days2)\nviol_per_day.set_index(\"Day of Week\", drop = True, inplace = True)\n\n# plot data\nax = viol_per_day.plot.bar(color = 'b', ylim=[59000, 73000])\nax.set_ylabel(\"Total Number of Violations\")","486df5a7":"red_cam_loc_org.head()","aa27f168":"#remove unneeded columns\nred_cam_loc = red_cam_loc_org[[\"INTERSECTION\", \"LATITUDE\", \"LONGITUDE\"]].copy()\nred_cam_loc.head()","25978198":"#remove all caps\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.title()\n\n#replace \"and\" with \"-\"\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\" And \",\"-\")\n\nred_cam_viol.head()","7bb23c5d":"#Before merging, I want to learn a bit more about my datasets. \n\nnull_counts_viol = red_cam_viol.isnull().sum()\nprint(null_counts_viol)","4658b71c":"red_cam_viol.info()","d2cc6097":"null_counts_loc = red_cam_loc.isnull().sum()\nprint(null_counts_loc)","93a6bcf7":"red_cam_loc.info()","814f161a":"#create unique lists of intersections within each dataset\n\nloca = np.sort(red_cam_loc['INTERSECTION'].unique())\nviol = np.sort(red_cam_viol['INTERSECTION'].unique())","782e981a":"#find values that do not appear in viol lists\ndef missing(loca, viol): \n    return (list(set(loca) - set(viol)))\n\nmissing = missing(loca, viol)\nmissing.sort()\nprint(missing)","2b95b738":"# find missing values that do not appear in loc list\n\ndef missing2(viol, loca): \n    return (list(set(viol) - set(loca)))\n\nmissing2 = missing2(viol, loca)\nmissing2.sort()\nprint(missing2)","ad0e3963":"red_cam_loc['INTERSECTION'] = red_cam_loc['INTERSECTION'].str.upper()\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.upper()","92d76729":"# replace errors found in spot check of lists\n\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"?\", \" \")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"STONEY\", \"STONY\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"31ST ST-MARTIN LUTHER KING DRIVE\", \"DR MARTIN LUTHER KING DRIVE-31ST\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"4700 WESTERN\", \"47TH-WESTERN\")","c1a037f4":"# resave first list with capitalized letters\nloca = np.sort(red_cam_loc['INTERSECTION'].unique())","8189823d":"# create new column\nred_cam_viol[\"Corrected Intersection\"] = 'Unchecked'\n\n# divides intersections by hyphen and insert in new column\nred_cam_viol[\"First Street\"], red_cam_viol[\"Second Street\"] = red_cam_viol.INTERSECTION.str.split(\"-\", 1).str\nred_cam_viol['New Intersection'] = red_cam_viol[\"Second Street\"] + \"-\" + red_cam_viol[\"First Street\"]\n\ndef match(df, loca): \n    df.loc[df['INTERSECTION'].isin(loca), \"Corrected Intersection\"] = df['INTERSECTION']\n    df.loc[(~df['INTERSECTION'].isin(loca)) & (df[\"New Intersection\"].isin(loca)), \"Corrected Intersection\"] = df['New Intersection'] \n    errors = df.loc[df['Corrected Intersection'] == 'Unchecked']\n    errors_list = np.sort(errors['INTERSECTION'].unique())\n    return df, errors_list\n\n# call function \nred_cam_viol, errors_list = match(red_cam_viol, loca)\nprint(errors_list)","f1ba4329":"red_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"\/\", \"-\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"HIGHWAY\", \"HWY\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"83RD-STONY ISLAND\", \"STONY ISLAND-83RD\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"95TH-STONY ISLAND\", \"STONY ISLAND-95TH\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"ARCHER-NARRAGANSETT-55TH\", \"ARCHER-NARRAGANSETT\")\nred_cam_viol[\"INTERSECTION\"] = red_cam_viol[\"INTERSECTION\"].str.replace(\"LAKE-UPPER WACKER\", \"LAKE-WACKER\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"DR MARTIN LUTHER KING-31ST\", \"DR MARTIN LUTHER KING DRIVE-31ST\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"LAKE SHORE-BELMONT\", \"LAKE SHORE DR-BELMONT\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"PULASKI-ARCHER-50TH\", \"PULASKI-ARCHER\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"KOSTNER-GRAND-NORTH\", \"KOSTNER-GRAND\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"HOMAN-KIMBALL-NORTH\", \"HOMAN-KIMBALL\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"WESTERN-DIVERSEY-ELSTON\", \"WESTERN-DIVERSEY\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"KEDZIE-79TH-COLUMBUS\", \"KEDZIE-79TH\")\nred_cam_loc[\"INTERSECTION\"] = red_cam_loc[\"INTERSECTION\"].str.replace(\"HALSTED-FULLERTON-LINCOLN\", \"HALSTED-FULLERTON\")","7ff8dfa9":"#resave list with corrected intersection names\nloca = np.sort(red_cam_loc['INTERSECTION'].unique())\n\n#rewrite columns with corrected values\nred_cam_viol[\"First Street\"], red_cam_viol[\"Second Street\"] = red_cam_viol.INTERSECTION.str.split(\"-\", 1).str\nred_cam_viol['New Intersection'] = red_cam_viol[\"Second Street\"] + \"-\" + red_cam_viol[\"First Street\"]\n\n# call function again \nred_cam_viol, errors_list = match(red_cam_viol, loca)\nprint(errors_list)","919fc77c":"red_cam_viol.info()","fbd16c35":"red_cam_final_org = pd.merge(red_cam_viol, red_cam_loc, left_on = \"Corrected Intersection\",right_on= \"INTERSECTION\", how = \"left\")\nred_cam_final_org.head()","5e7fdfba":"null_counts_merged = red_cam_final_org.isnull().sum()\nprint(null_counts_merged)","47052554":"red_cam_final_org.info()","3cb5bce8":"red_cam_final_org[\"INTERSECTION_y\"] = np.where(red_cam_final_org[\"INTERSECTION_y\"].isnull(), red_cam_final_org[\"INTERSECTION_x\"], red_cam_final_org[\"INTERSECTION_x\"])","48343f21":"red_cam_final = red_cam_final_org[[\"INTERSECTION_y\", \"CAMERA ID\", \"LATITUDE\", \"LONGITUDE\", \"VIOLATION DATE\", \"VIOLATIONS\"]].copy()\nred_cam_final.rename(columns = {\"INTERSECTION_y\" : \"INTERSECTION\"}, inplace = True)\nred_cam_final.head()","8a97a5f2":"intersection_grouped = red_cam_final.groupby(\"INTERSECTION\")\nintersection_summed = pd.DataFrame(intersection_grouped[\"VIOLATIONS\"].sum())\nintersection_summed.head()","4a0dc862":"red_cam_totals = pd.merge(intersection_summed,red_cam_final,left_on = \"VIOLATIONS\", right_index = True)\nred_cam_totals = red_cam_totals[[\"VIOLATIONS\", \"LATITUDE\", \"LONGITUDE\"]].copy()\n\n# set 100 as scale factor\nred_cam_totals[\"SCALE\"] = red_cam_totals[\"VIOLATIONS\"] \/ 100\nred_cam_totals.head()","066be248":"# import libraries\nfrom shapely.geometry import Point, Polygon \nimport matplotlib.pyplot as plt\nimport geopandas as gpd \nimport descartes","b92f5d89":"#convert to a geo-dataframe\ngeometry = [Point(xy) for xy in zip(red_cam_totals['LONGITUDE'], red_cam_totals['LATITUDE'])]\ncrs = {'init','epsg:4326'}\ngdf = gpd.GeoDataFrame(red_cam_totals, crs=crs, geometry=geometry)","550fe377":"#plot red light cameras onto city map\nstreet_map = gpd.read_file('..\/input\/chicago-streets-shapefiles\/geo_export_75808441-05b9-4a51-a665-cf23dcf0a285.shx')\nfig,ax = plt.subplots(figsize = (15,15))\nstreet_map.plot(ax = ax, alpha = 0.4, color = \"grey\")\ngdf.plot(ax=ax, markersize=red_cam_totals[\"SCALE\"], marker=\"o\", color=\"red\")","e2972bff":"viol_per_day = viol_per_day.reset_index()\nviol_per_day.head()","1777210e":"#install package \n!pip install chart-studio\n\n#import plotly \nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode()","23f96cd0":"data = [\n    go.Scatter(x=viol_per_day['Day of Week'], y=viol_per_day['VIOLATIONS'], marker=dict(color='rgb(158,202,225)', line=dict(color='rgb(8,48,107)', width=1.5,)),\n    opacity=0.6)]\n\nlayout = go.Layout(autosize = True, title=\"Red Light Camera Violations per Day\", xaxis={'title':'Days of Week'}, yaxis={'title':'Total Violations'})\n\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","a0d2d9bb":"# reset index to convert dataframe from geo to plotly\ngdf_2 = gdf.reset_index()\ngdf_2['TEXT'] = gdf_2['INTERSECTION'] + \": \" + gdf_2['VIOLATIONS'].astype(str) + ' total violations'","600bb58e":"#Instead of using scaled data, I will normalize the \"VIOLATIONS\" column.\n\n# normalize data using min-max \ngdf_2[\"NORMALIZED\"] = (gdf_2[\"VIOLATIONS\"] - gdf_2[\"VIOLATIONS\"].min()) \/ (gdf_2[\"VIOLATIONS\"].max() - gdf_2[\"VIOLATIONS\"].min())","a0b9fe46":"mapbox_access_token = 'pk.eyJ1IjoidGdhc2luc2tpIiwiYSI6ImNqcXc3MjhpNzEzMnYzeG9ieDNkb2M5ZmQifQ.m3MsgcBIXdwOT6hxvi007g'\n\ndata = [\n    go.Scattermapbox(\n        lat= gdf_2['LATITUDE'],\n        lon= gdf_2['LONGITUDE'],\n        mode='markers',\n        text = gdf_2['TEXT'],\n        hoverinfo = 'text',\n        marker=dict(\n            size= 8,\n            color = gdf_2['NORMALIZED'],\n            colorscale= 'Jet', \n            showscale=True,\n            cmax=1,\n            cmin=0),),]\n\nlayout = go.Layout(\n    title = \"Number of Total Red Light Violations by Intersection in Chicago\", \n    autosize=True,  \n    hovermode='closest',\n    mapbox=dict(\n        accesstoken=mapbox_access_token,\n        bearing=0,\n        center=dict(\n            lat=41.881832,\n            lon=-87.623177),\n        pitch=0,\n        zoom=10),)\n\nfig = dict(data=data, layout=layout)\niplot(fig)","6e1ebaa2":"print(\"Total Number of Red Camera Violations in Chicago:\")\nred_cam_viol[\"VIOLATIONS\"].sum()","b6b4565d":"mapbox_access_token = 'pk.eyJ1IjoidGdhc2luc2tpIiwiYSI6ImNqcXc3MjhpNzEzMnYzeG9ieDNkb2M5ZmQifQ.m3MsgcBIXdwOT6hxvi007g'\n\ntrace1 = go.Scatter(x=viol_per_day['Day of Week'], y=viol_per_day['VIOLATIONS'], mode='lines+markers+text', xaxis='x1', yaxis='y1')#, subplot = 'plot1')\n\ntrace2 = go.Scattermapbox(\n        lat= gdf_2['LATITUDE'],\n        lon= gdf_2['LONGITUDE'],\n        mode='markers',\n        text = gdf_2['TEXT'],\n        hoverinfo = 'text',\n        marker=dict( \n            size= 8,\n            color = gdf_2['NORMALIZED'],\n            colorscale= 'Jet',\n            showscale=True,\n            colorbar=dict(title = dict(text=\"Violations (Scaled)\", side=\"right\"), x = 1), \n            cmax=1,\n            cmin=0), \n        subplot = 'mapbox')\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(\n    autosize=True,\n    hovermode='closest',\n    xaxis=dict(\n        domain=[0, 0.45]\n    ),\n    yaxis=dict(\n        domain=[0, 1]\n    ),\n    mapbox=dict(\n        accesstoken=mapbox_access_token,\n        domain = {'x' : [.5, 1], 'y' : [0,1]},\n        bearing=0,\n        center=dict(\n            lat=41.8746,\n            lon=-87.6687),\n        pitch=0,\n        zoom=10),)\n\nfig = go.Figure(data=data, layout=layout)\n\nfig['layout']['xaxis1'].update(title='Days per Week')\nfig['layout']['yaxis1'].update(title='Total Number of Violations')\nfig['layout'].update(showlegend=False)\nfig['layout'].update(height=600, width=800, title='Total Red Light Camera Violations in Chicago: By Day and Intersection')\n\niplot(fig) ","66d33440":"Luckily, the second dataset contains information about the Latitude and Longitude of each camera.  Unfortunately, the Camera IDs aren't included in this second dataset. But I noticed that information about the intersection is present in each dataset, so I can merge the datasets on this column and hopefully retrieve information about where the Camera IDs are located. To do this, I will first need to modify the \"Intersection\" column of the first dataset. ","4376b2dd":"I notice right away that there are some problems with capitalization - for example, the intersections in list viol are written with \"st\" or \"th\", while the intersections in list loc are written with \"St\" and \"Th\". To avoid these kinds of capitalization errors, I will make the columns in each dataframe uppercase.","67da278b":"I gained a bit more Latitude and Longitude data (from 241,983 missing to 230,165), but there is still more munging to do! Two other problems I noticed: in the loc list, sometimes \"?\" appear instead of spaces (like in the street \"Stony Island\", which is also misspelled in the viol list). A second problem is the order of the Intersection streets. In the viol list, one intersection is listed as \"California-Irving Park\" but in the loc list, the same intersection appears as \"Irving Park-California.\" ","50e891fc":"The first piece of information I want is the total number of red camera violations. This should be pretty easy, as the \"Violations\" column records the number of violations captured by each camera ID on each day. ","7f4326a1":"For my mapping, I've decided to concentrate on the total number of violations per intersection. This means I will have to manipulate my red_cam_final dataframe to create a new dataframe, which I can then re-merge with the original dataframe to retrieve the location data. I used ideas from: https:\/\/towardsdatascience.com\/geopandas-101-plot-any-data-with-a-latitude-and-longitude-on-a-map-98e01944b972 and https:\/\/towardsdatascience.com\/exploring-and-visualizing-chicago-transit-data-using-pandas-and-bokeh-part-ii-intro-to-bokeh-5dca6c5ced10 for help plotting. ","2af0ad00":"It doesn't look like there's much else left to munge. I am a little confused how these street intersections reported red camera violations if there is no camera located there, but for now I will move on with my merge and mapping EDA. ","bdadc450":"Next, I want to track how many violations, on average, occur on each day of the week. It would also be interesting to track when these violations occur, but unfortunately it looks like there is no time series data available. ","846b58fb":"The first time I merged the two datasets, 241,983 rows contained no \"Latitude\" and Longitude\" data and the Camera ID column went from 552 null values to 630. Because I merged on the \"Intersections\" columns, I wanted to further explore the data in those columns to see if I can figure out why some data disappeared. My assumption is that the Intersections will be the same for both datasets, but that may not be true.","1669c836":"# Identifying Relevant Information for a Dashboard. \n\nAfter looking at the dataset, I think that the following information would be interesting to track in a dashboard: \n\n* Number of red camera violations, \n* Distribution of violations by day of week, \n* Distrbution of violations by location, and \n* Distribution of violations by camera ID","c13a9f50":"This dashboard displays the total number of red camera violations in the city of Chicago, Illinois. It includes a count of total violations, a chart with the number of violations per day, and a map with the locations of the red light cameras and number of violations. This work was completed after viewing the December 2018 Kaggle Dashboard Training. It is hosted online by the Google Cloud Platform service. The page is updated daily at midnight Central Standard Time (CST). The interactive graphs were created through Plotly. \n\nNormally, I would hide my raw code, as well as the work I did to clean and manipulate the data. However, I kept it visible for now, to showcase those skill sets.","d89471f2":"# Final Dashboard","b5ccdd67":"Now I want to visualize the geographical distribution of red light camera violations by projecting the number of violations onto a map of Chicago. To do this, I will need the location of each camera. This information wasn't in my first dataset, but let's see if it's in my second dataset. ","0c89ba8d":"# Data Cleanup and Munging","bc26452f":"My function hasn't removed all the errors, so I will have to munge manually. But it's much easier than before to spot these smaller discrepencies! For example, I now notice that a few intersections list three streets instead of two (like \"Stony Island\/Cornell-67th\"), but uses a \"\/\" instead of \"-\" to divide the streets. ","750d55c8":"# Data Validation\n\nBecause I will be automatically updating this Dashboard, I want to validate my source dataset to check that the format and content remains as it is now (and to flag the dataset if something significant changes that would affect my Dashboard). ","2dd1da4c":"I now only have 45,637 rows without Latitude and Longitude data, as opposed to over 240,000 before munging. Next, I'm going to clean up my final dataset a little.","474904a4":"Uh-oh! I already see that a lot of information regarding the location of the violations is missing. I will quickly remove these columns from my first dataset.","238a8893":"Now I need to convert the Latitude and Longitude into x and y tuples. ","12dbbfe8":"For an actual dashboard, my charts, graphs and maps would be more interactive, to allow other users to modify the data as they see fit. Other tips (from Kaggle's Dasbhoarding tutorial) include: \n\n* Hiding code, \n* Removing text, and \n* Consolidating charts and tables on the same line when possible"}}