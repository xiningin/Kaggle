{"cell_type":{"4cf959d6":"code","bcf9eece":"code","7ef31bad":"code","2eb7d923":"code","0fb3fd9a":"code","2ca0648b":"code","9bd1951d":"code","a339cd70":"code","708c5731":"code","1fac3876":"code","64f58ca9":"code","40fcba12":"code","b1099830":"code","de808b35":"markdown","7f43b608":"markdown","8b643309":"markdown","8ef355e0":"markdown","9d6c97ab":"markdown","82326fb0":"markdown","35d0cb84":"markdown","c31f5714":"markdown"},"source":{"4cf959d6":"# Import necessary packages to read, process and visualize data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt     # Generate plots\nimport seaborn as sns               # Visualization\n%matplotlib inline\n\n# Read the data\nfilename = \"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\ndata = pd.read_csv(filename)\n\n# Let us see the shape of data\nprint(data.shape)   \n# Following output shows there are 7043 rows and 21 columns in our data","bcf9eece":"# Overview and statistical details of the data..\n# Let us see first five rows to understand what type of values exist for each columns\ndata.head()","7ef31bad":"# To view all column names and their respective data types\ndata.columns\ndata.info()\ndata.describe() # Shows statistical summaries for all numeric columns","2eb7d923":"# Plot distribution of dependent\/target variable - Churn column\ndata['Churn'].value_counts().head().plot.bar()   # To generate a bar plot\n\n# To generate a pie chart. Since there are only two classes, a pie chart may look more appealing\nsizes = data['Churn'].value_counts(sort = True)\nlabels = np.unique(data.Churn)\n\n# Visualize the data\nplt.figure(figsize = (6,6))\nplt.subplot(212)\nplt.title(\"Customer churn rate:\")\nplt.pie(sizes, labels = labels, autopct='%1.1f%%')\n\n# Bar & pie plots below show that number of customers churned is less than half of not churned.","0fb3fd9a":"# Convert following object type columns to numeric        \ndata.TotalCharges = pd.to_numeric(data.TotalCharges, errors = 'coerce')","2ca0648b":"# Let us find if there are any missing values in our data.\nprint(\"No. of missing values: \\n\",data.isnull().sum())","9bd1951d":"# Drop CustomerId column as it is not required\ndata.drop(['customerID'], axis = 1, inplace = True)\n\n# Fill the missing values with 0\ndata['TotalCharges'] = data['TotalCharges'].fillna(0.0)\n\n# Check for any existing missing values\nprint(\"Missing values now: \\n\", data.isnull().sum())","a339cd70":"# Now let us work on categorical features. \ndata.gender = [1 if x == \"Male\" else 0 for x in data.gender]\nfor col in ('Partner', 'Dependents', 'PhoneService' , 'OnlineSecurity',\n        'OnlineBackup','DeviceProtection', 'TechSupport','StreamingTV',\n        'StreamingMovies','PaperlessBilling','MultipleLines','Churn'):\n    data[col] = [1 if x == \"Yes\" else 0 for x in data[col]]        \ndata.head(10)   # See how data looks like now","708c5731":"# Print correlation between all features and target variable\ndata.corr()['Churn'].sort_values()","1fac3876":"# Plot heatmap using Seaborn to visualize correlation amongst ftrs.\nsns.heatmap(data.corr(), annot = True)","64f58ca9":"# For following features, let us generate bar plots w.r.t. target variable\nfor col in ('Partner', 'Dependents', 'PhoneService' , 'OnlineSecurity',\n        'OnlineBackup','DeviceProtection', 'TechSupport','StreamingTV',\n        'StreamingMovies','PaperlessBilling','MultipleLines'):\n    sns.barplot(x = col, y = 'Churn', data = data)\n    plt.show()\n# Following plots show Churn rate for each category of these categorical features.    ","40fcba12":"# Generate pairplots for all features.\nhighCorrCols = ['MonthlyCharges','TotalCharges','tenure', 'Churn']\nsns.pairplot(data[highCorrCols], hue = 'Churn')","b1099830":"# Prepare data for model training and testing input.\ny = data.Churn.values     # Target feature\n\n# All features except class (target)\ndata = pd.get_dummies(data)\nX = data.drop([\"Churn\"],axis=1)\n\nfrom sklearn.metrics import accuracy_score, mean_squared_error as mse\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier as RF\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.svm import SVC \nfrom sklearn.neural_network import MLPClassifier\n\n# Split the data into training and testing data\nX_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2, random_state=1)\n\n# Classification using RBF SVM  \nsvc_rbf = SVC(kernel = \"rbf\")\nsvc_rbf = svc_rbf.fit(X_train,y_train)\nprediction = svc_rbf.predict(X_test)\nprint(\"Mean-squared error using SVM RBF:\", mse(y_test, prediction))\nprint(\"Accuracy with SVM RBF:\",accuracy_score(y_test, prediction))\n\n# Classification using Random Forest Classifier\nrfc = RF(max_depth= 5, n_estimators= 10, max_features= 'auto')\nrfc = rfc.fit(X_train,y_train)\nprediction = rfc.predict(X_test)\nprint(\"Mean-squared error using Random Forest Classifier:\", mse(y_test, prediction))\nprint(\"Accuracy with Random Forest Classifier:\",accuracy_score(y_test, prediction))\n\n# Classification using Logistic Regression\nlogreg = LR(C = 1)\nlogreg = logreg.fit(X_train,y_train)\nprediction = logreg.predict(X_test)\nprint(\"Mean-squared error using Logistic Regression:\", mse(y_test, prediction))\nprint(\"Accuracy with Logistic Regression:\",accuracy_score(y_test, prediction))\n\n# Classification using Multi-layer perceptron \nann = MLPClassifier(solver='lbfgs', alpha = 1e-5,\n                    hidden_layer_sizes = (5, 2), random_state = 1)\nann = ann.fit(X_train, y_train)\nprediction = ann.predict(X_test)\nprint(\"Mean-squared error using Neural networks MLP:\", mse(y_test, prediction))\nprint(\"Accuracy with Neural networks MLP:\",accuracy_score(y_test, prediction))","de808b35":"From above we can see there are mostly categorical features in the data. \nHowever, it is better to obtain exact information about each column.","7f43b608":"Output shows that there are 11 total missing values in TotalCharges column.","8b643309":"**Predicting whether a customer will churn by learning models on telecom industry dataset provided by IBM data community-**\n\nThis notebook covers following contents -\n*  Reading the data\n*  Overview of data's structure - how various features and their respective values look  \n    like?\n*  Finding and handling missing values\n*  Dealing with categorical attributes\n*  Identifying higher correlation features (with the target)\n*  Generating relevant insights about values of these high correlation features for churned customers (A Tableau  \n    worksheet is attached for some plots - see the dashboards)\n*  Preparing data for models\n*  Model generation and performance evaluation","8ef355e0":"[Dashboards for More Data Visualization and EDA!](https:\/\/public.tableau.com\/profile\/shubha#!\/vizhome\/ContractInternetService\/Dashboard1)\nInsights from above plots -\n* Each categorical plot shows which of their categories there is a higher customer churn rate.\nFrom Dashboard 1 -\n* Most customers with Month-to-month contract and Fibre optic Internet Service churned.\n* Customers with Two-year contract and No Internet service have least churn rate. \n* Customers who did churn showed a declining trend with increase in tenure period.\n* Customers who did not churn increased when tenure is very less (0-5 months) and more than 66   \n  months (showing a peak towards the ends with dropped curve in the middle).\n* When Monthly Charges are less, less customer churn rate is observed seeing maximum churn rate at nearly \n  75units Monthly charge.\n* Churn rate is higher for customers with Multiple Lines while those with No Phone Service have least churn rate.  \n\n**(Will add and discuss some more dashboards soon..)","9d6c97ab":"This is my first kernel at Kaggle. I will keep on working to improve this and my future kernels. \nPlease feel free to provide any advice or suggestions and I would try to make changes accordingly.\n\nIf you found this work helpful, please do upvote and comment below.\n\n**Happy learning and thank you!**","82326fb0":"Missing values for all columns are now 0. So, no more missing data.","35d0cb84":"Now, let us see which features are most effective in causing customer churn.\n**Correlation -**\nCorrelation between variables shows how dependent variable changes due to an independent variable under consideration. \nA value close to +1 signifies strong positive correlation, while close to -1 shows strong negative effect. Correlation coeff. close to zero signifies weak relation between features. ","c31f5714":"From above output we can observe :\n*  Mean Monthly charges is about 64.76 units and 75% of observations are monthly charged around 89.85\n*  The maximum tenure is 72 months with mean being about 32 months.\n*  About 50% of customers stayed for 55 months tenure and were charged 70.3 per month  \nTo get more relevant information, we will visualize attributes of the data and distribution of target variable(Churn)"}}