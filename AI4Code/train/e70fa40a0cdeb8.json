{"cell_type":{"625a85ce":"code","4896b476":"code","8a813ec9":"code","7792fbb6":"code","818fa457":"code","0e2067d4":"code","2791f62c":"code","9cb63204":"code","8a73d3b3":"code","15193022":"code","687034ac":"code","16fbdb48":"code","1ddef9ef":"code","5749095f":"code","c55a9f9e":"code","513c093e":"code","78a05b2d":"code","3eb9e3e0":"code","2d8cbc2d":"code","5ed05e75":"code","82a63abe":"code","cabcd375":"code","fc25094b":"code","8e217cd1":"code","dc16f4fe":"code","2ed49359":"code","ab88d9b9":"code","e214a841":"code","d254c88f":"code","cf1591d8":"code","9d18829f":"code","c59c8d16":"code","31c89b96":"code","f8c516c8":"code","8e304f25":"code","99d716ee":"markdown","90cabba8":"markdown"},"source":{"625a85ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport wandb\nimport glob\nimport re \nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport tensorflow as tf\nimport imageio\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport collections\nimport json\nfrom tqdm import tqdm\n%matplotlib inline\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4896b476":"wandb.login()","8a813ec9":"CONFIG = {\n    'IMG_SIZE':224,\n    'competition':'rsna-miccai-brain',\n    '_wandb_kernel':'rooneyy'\n}","7792fbb6":"filename = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv'\ntrain_df = pd.read_csv(filename)\ntrain_df.head()","818fa457":"print(f'Number of rows: {len(train_df)}')","0e2067d4":"fig, ax = plt.subplots(figsize=(10,6))\nsns.countplot(y='MGMT_value', data=train_df);\nax.set_title('Distribution of labels', fontsize=15, weight='heavy')","2791f62c":"filenames = glob.glob('\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/*\/*\/*')\nprint(f'Total number of files: {len(filenames)}')","9cb63204":"label_dict = {'FLAIR':[],\n              'T1w':[],\n              'T1wCE':[],\n              'T2w':[]\n             }\n\nfor filename in tqdm(filenames):\n    scan = filename.split('\/')[-2]\n    if scan == 'FLAIR':\n        label_dict['FLAIR'].append(filename)\n    elif scan == \"T1w\":\n        label_dict['T1w'].append(filename)\n    elif scan == 'T1wCE':\n        label_dict['T1wCE'].append(filename)\n    elif scan == 'T2w':\n        label_dict['T2w'].append(filename)\n        \nprint('Size of FLAIR scan: {}\\nT1w scan: {}\\nT1wCE scan: {}\\nT2w scan: {}'.format(len(label_dict['FLAIR']),\n                                                                                 len(label_dict['T1w']),\n                                                                                 len(label_dict['T1wCE']),\n                                                                                 len(label_dict['T2w'])))","8a73d3b3":"run = wandb.init(project='brain-tumor-wizz', config=CONFIG)\ndata = [['FLAIR',74248],['T1w',77627],['T1wCE',96766],['T2w',100000]]\ntable = wandb.Table(data=data, columns=['Scan type','Size of Files'])\nwandb.log({'my_bar_chart_id':wandb.plot.bar(table, 'Scan type', 'Size of Files', title='Scan types vs Number of Dicom Files')})\nrun.finish()","15193022":"def ReadMRI(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    \n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if fix_monochrome and dicom.PhotometricInterpretation == 'MONOCHROME1':\n        data = data - np.min(data)\n        if np.max(data) != 0:\n            data = data \/ np.max(data)\n        data = (data * 255).astype(np.uint8)\n    \n    return data","687034ac":"path = filenames[32346]\ndata = ReadMRI(path)\nplt.imshow(data, cmap='gray')","16fbdb48":"def sorted_nicely(l):\n    \"\"\" Sort the given iterable in the way that humans expect \"\"\"\n    convert = lambda text: int(text) if text.isdigit() else text\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(l, key=alphanum_key)","1ddef9ef":"def get_patient_id(patient_id):\n    if patient_id < 10:\n        return '0000'+str(patient_id)\n    elif patient_id >= 10 and patient_id < 100:\n        return '000'+str(patient_id)\n    elif patient_id >= 100 and patient_id < 1000:\n        return '00'+str(patient_id)\n    else:\n        return '0'+str(patient_id)","5749095f":"train_df_1 = train_df[train_df.MGMT_value == 1].reset_index(drop=True)\nprint(f'Number of patients with brain tumor: {len(train_df_1)}')\n\nIMG_2_log = 20\ntrain_df_1_sampled = train_df_1.sample(n=IMG_2_log).reset_index(drop=True)\nprint(f'Number of sampled patients: {len(train_df_1_sampled)}') \n\nsampled_data_at = wandb.Table(dataframe=train_df_1_sampled)\nrun = wandb.init(project='brain-tumor-viz(Sampled Patients)', config=CONFIG)\nwandb.log({f'Sampled DataFrame': sampled_data_at})\nrun.finish()","c55a9f9e":"for i in tqdm(range(len(train_df_1_sampled))):\n    ID = train_df_1_sampled.BraTS21ID[i]\n    patient_id = get_patient_id(ID)\n    \n    run = wandb.init(project='brain-tumor-viz(Animate MRI)', config=CONFIG, name=f'{patient_id}')\n    \n    for key in label_dict.keys():\n        if os.path.isdir(f'\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{patient_id}\/{key}'):\n            _filenames = os.listdir(f'\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{patient_id}\/{key}')\n            _filenames = sorted_nicely(_filenames)\n            for filename in _filenames:\n                mri_data = ReadMRI(f'\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{patient_id}\/{key}\/{filename}')\n                wandb.log({f'{key}': [wandb.Image(mri_data)]})\n    \n    run.finish()","513c093e":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = data - np.min(data)\n    if np.amax(data) != 0:\n        data = data \/ np.amax(data)\n    data = (data * 255).astype(np.uint8)\n    \n    return data","78a05b2d":"def visualise_sample(brats21id, slice_i, mgmt_value, types=('FLAIR','T1w','T1wCE','T2w')):\n    plt.figure(figsize=(10,6))\n    patient_path = os.path.join('\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/', str(brats21id).zfill(5))\n    \n    for i, t in enumerate(types, 1):\n        t_paths = sorted(glob.glob(os.path.join(patient_path, t, '*')), key = lambda x: int(x[:-4].split('-')[-1]))\n        data = load_dicom(t_paths[int(len(t_paths) * slice_i)])\n        plt.subplot(1, 4, i)\n        plt.imshow(data, cmap='gray');\n        plt.title(f'{t}', fontsize=16)\n        plt.axis('off')\n        \n    plt.suptitle(f'MGMT value: {mgmt_value}', fontsize=14)\n    plt.show()","3eb9e3e0":"for i in np.random.choice(range(len(train_df)), 10):\n    _brats21id = train_df.iloc[i].BraTS21ID\n    _mgmt_value = train_df.iloc[i].MGMT_value\n    visualise_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5)","2d8cbc2d":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\ndef create_animations(ims):\n    fig = plt.figure(figsize=(10,6))\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap='gray')\n    \n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n    \n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval = 1000\/\/20)","5ed05e75":"def load_dicom_line(path):\n    t_paths = sorted(glob.glob(os.path.join(path, '*')), key = lambda x: int(x[:-4].split('-')[-1]))\n    \n    images=[]\n    for filename in t_paths:\n        data = load_dicom(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","82a63abe":"path = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00234\/T2w'","cabcd375":"train_df[train_df.BraTS21ID == 234].MGMT_value.values","fc25094b":"print('MGMT Value of patient:', train_df[train_df.BraTS21ID == 234].MGMT_value.values)\nimages = load_dicom_line(path)\ncreate_animations(images)","8e217cd1":"print('MGMT value of patient:', train_df[train_df.BraTS21ID == 510].MGMT_value.values)\npath = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00510\/T2w'\nimages = load_dicom_line(path)\ncreate_animations(images)","dc16f4fe":"import time \n\nimport torch \nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional \nfrom efficientnet_pytorch import EfficientNet\nimport cv2\n\nfrom sklearn.model_selection import StratifiedKFold\n","2ed49359":"def set_seed(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        \n        \nset_seed(42)        ","ab88d9b9":"df = pd.read_csv('\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')\ndf_train, df_valid = sk_model_selection.train_test_split(df, test_size=0.2, random_state=42, stratify = df['MGMT_value'])","e214a841":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets):\n        self.paths = paths\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.paths)\n        \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f'\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{str(_id).zfill(5)}\/'\n        channels = []\n        for t in ('FLAIR','T1w','T1wCE','T2w'):\n            t_paths = sorted(glob.glob(os.path.join(patient_path, t, '*')), key = lambda x: int(x[:-4].split('-')[-1]))\n            x = len(t_paths)\n            if x < 10:\n                r = range(x)\n            else:\n                d = x \/\/ 10\n                r = range(d, x - d, d)\n            \n            channel = []\n            for i in r:\n                channel.append(cv2.resize(load_dicom(t_paths[i]), (256,256)) \/ 255)\n            channel = np.mean(channel, axis=0)\n            channels.append(channel)\n        \n        y = torch.tensor(self.targets[index], dtype = torch.float)\n        \n        \n        return {'X': torch.tensor(channels).float(), 'y':y}","d254c88f":"train_data_retriever = DataRetriever(df_train['BraTS21ID'].values, df_train['MGMT_value'].values)\n\nvalid_data_retriever = DataRetriever(df_valid['BraTS21ID'].values, df_valid['MGMT_value'].values)","cf1591d8":"plt.figure(figsize=(10,10))\nfor i in range(3):\n    plt.subplot(1, 3, i+1)\n    plt.imshow(train_data_retriever[100]['X'].numpy()[i], cmap='gray')","9d18829f":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","c59c8d16":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet.from_name('efficientnet-b0')\n        checkpoint = torch.load('\/kaggle\/input\/nfnets\/pytorch-image-models-master\/')# to be completed\n        self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias = True)\n        \n    def forward(self, x):\n        out = self.net(x)\n        return(out)","31c89b96":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, val):\n        self.n += 1\n        #incremental update\n        self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n        \n\nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        #incremental update\n        self.avg = true_count \/ self.n + last_n \/ self.n * self.avg","f8c516c8":"class Trainer:\n    def __init__(\n        self,\n        model,\n        device,\n        optimizer,\n        criterion,\n        loss_meter,\n        score_meter):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            'epoch': '[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s',\n            'checkpoint': 'The score improved from {:.5f} to {:.5f}. Save model to {}',\n            'patience': \"\\nValid score didn't improve last {} epochs\"\n        }\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n        for n_epoch in range(1, epochs + 1):\n            self.info_message(f'EPOCH: {n_epoch}')\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(self.messages['epoch'], 'Train', n_epoch, train_loss, train_score, train_time)\n            \n            self.info_message(self.messages['epoch'], 'Valid', n_epoch, valid_loss, valid_score, valid_time)\n            \n            if True:\n#                 if self.best_valid_score < valid_score:\n                self.info_message(self.messages['checkpoint'], self.best_valid_score, valid_score, save_path)\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n                \n            if self.n_patience >= patience:\n                self.info_message(self.messages['patience'], patience)\n                break\n                \n    def train_epoch (self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch['X'].to(self.device)\n            target = batch['y'].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            \n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n            \n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}\/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end='\\r')\n            \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n        \n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch['X'].to(self.device)\n                target = batch['y'].to(self.device)\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n                \n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, end='\\r')\n            \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n        {\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'best_valid_score': self.best_valid_score,\n            'n_epoch': n_epoch\n        },\n        save_path\n        )\n        \n    @staticmethod\n    def info_message(message, *args, end='\\n'):\n        print(message.format(*args), end=end)","8e304f25":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_data_retreiver = DataRetriever(\n    df_train['BraTS21ID'].values,\n    df_train['MGMT_value'].values)\n\nvalid_data_retreiver = DataRetriever(\n    df_valid['BraTS21ID'].values,\n    df_valid['MGMT_value'].values)\n\ntrain_loader = torch_data.DataLoader(\n    train_data_retreiver,\n    batch_size=8,\n    shuffle=True,\n    num_workers=8)\n\nvalid_loader = torch_data.DataLoader(\n    valid_data_retreiver,\n    batch_size=8,\n    shuffle=False,\n    num_workers=8)\n\nmodel = Model()\nmodel.to(device)\n# \noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = torch_functional.binary_cross_entropy_with_logits\n\ntrainer = Trainer(\n    model,\n    device,\n    optimizer,\n    criterion,\n    LossMeter,\n    AccMeter)\n\nhistory = trainer.fit(\n    2,\n    train_loader,\n    valid_loader,\n    f'best_model-0.path',\n    100)","99d716ee":"## **Read Dicom Files**","90cabba8":"# Work in Progress . ."}}