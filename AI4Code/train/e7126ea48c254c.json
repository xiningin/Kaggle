{"cell_type":{"aa2261b0":"code","a2e9e56f":"code","27686c08":"code","c1afb810":"code","18a0d6a6":"code","0a763bf8":"code","9246bdd0":"code","76afd4e8":"code","923d019e":"code","0f773d27":"markdown","e59766ea":"markdown","ac82678b":"markdown","8c404fd9":"markdown"},"source":{"aa2261b0":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls ","a2e9e56f":"import detectron2\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom fastcore.all import *\ndetectron2.__version__","27686c08":"dataDir=Path('..\/input\/sartorius-cell-instance-segmentation')","c1afb810":"# From https:\/\/www.kaggle.com\/stainsby\/fast-tested-rle\ndef rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef get_masks(fn, predictor):\n    im = cv2.imread(str(fn))\n    outputs = predictor(im)\n    pred_masks = outputs['instances'].pred_masks.cpu().numpy()\n    res = []\n    used = np.zeros(im.shape[:2], dtype=int) \n    for mask in pred_masks:\n        mask = mask * (1-used)\n        used += mask\n        res.append(rle_encode(mask))\n    return res","18a0d6a6":"ids, masks=[],[]\ntest_names = (dataDir\/'test').ls()","0a763bf8":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_101_FPN_3x.yaml\"))\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \ncfg.MODEL.WEIGHTS = os.path.join('..\/input\/model-101', \"model_final.pth\")  \n#cfg.MODEL.WEIGHTS = os.path.join('..\/input\/detectron-pth\/output', \"model_final.pth\") \ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\npredictor = DefaultPredictor(cfg)\n","9246bdd0":"encoded_masks = get_masks(test_names[0], predictor)\n\n_, axs = plt.subplots(1,2, figsize=(40,15))\naxs[1].imshow(cv2.imread(str(test_names[0])))\nfor enc in encoded_masks:\n    dec = rle_decode(enc)\n    axs[0].imshow(np.ma.masked_where(dec==0, dec))","76afd4e8":"for fn in test_names:\n    encoded_masks = get_masks(fn, predictor)\n    for enc in encoded_masks:\n        ids.append(fn.stem)\n        masks.append(enc)","923d019e":"pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","0f773d27":"### Look at the outputs on a sample test file to sanity check\nI'm encoding here in the competition format and decoding back to bit mask just to make sure everything is fine","e59766ea":"## Inference and submission\n\n If you find it useful,I hope you will give me a upvote\uff0cI need it\uff0cThanks\n\nThank dragon Zhang for sharing[part three](https:\/\/www.kaggle.com\/dragonzhang\/positive-score-with-detectron-3-3-inference). I want to use a more advanced model to participate in this competition. In this version, I chose maskrcnnr101, which uses the detectron framework, which is very easy to use. I am also trying to use the latest model to improve my scores. \n\nAfter [part one](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-1-3-input-data\/) and [part two](https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-2-3-training) we have a trained model. I'm attaching it to this notebook through a dataset. Now all that's left is to run all the test files through it.\n\nThere are two minor details we need to handle:\n- The submission notebooks don't have access to the internet, in order to install detectron2 I needed to download dependecies with `pip download`, put them into a dataset and attach it to the notebook: https:\/\/www.kaggle.com\/slawekbiel\/detectron-05\n- The masks we submit can't overlap, see [the discussion](https:\/\/www.kaggle.com\/c\/sartorius-cell-instance-segmentation\/discussion\/279790#1550666). So I'm manually clipping the output returned from the model) I'm processing the masks ordereded by score, so in the case of conflict the more confident one remaines whole and the other one gets clipped.","ac82678b":"### Looks good, so lets generate masks for all the files and create a submission","8c404fd9":"### Initiate a Predictor from our trained model"}}