{"cell_type":{"39852cf5":"code","d94174ff":"code","55198578":"code","e168052d":"code","e8a22ebd":"code","bfc017d2":"code","7c8f4e71":"code","0f6efec3":"code","8d4d62bc":"code","2dca890e":"code","dd71fee8":"code","b7206ac0":"code","e3c8e62f":"code","5264034b":"code","87d65baf":"markdown","7f34a045":"markdown","3ad23978":"markdown","27195247":"markdown"},"source":{"39852cf5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d94174ff":"sample_submission = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv')\nsample_submission.head()","55198578":"train_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\ntrain_df.head()","e168052d":"train_df.shape","e8a22ebd":"print(f\"\"\"there are {train_df['grapheme_root'].nunique()} grapheme_root, {train_df['vowel_diacritic'].nunique()} vowel_diacritics and {train_df['consonant_diacritic'].nunique()} consonant_diacritic.\"\"\")","bfc017d2":"print(f\"\"\"Most frequent graphene_root is {train_df['grapheme_root'].value_counts().index[0]}\nMost frequent vowel_diacritic is {train_df['vowel_diacritic'].value_counts().index[0]}\nMost frequent consonant_diacritic is {train_df['consonant_diacritic'].value_counts().index[0]}\"\"\")","7c8f4e71":"plots=train_df[\"grapheme_root\"].value_counts().reset_index()\nplots.columns = ['grapheme_root', 'counts']\nplt.scatter( x=plots.grapheme_root, y=plots.counts, c='g', s= (plots.counts\/20))","0f6efec3":"class_map_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/class_map.csv')\nclass_map_df.tail()","8d4d62bc":"class_map_df.head()","2dca890e":"class_map_df.shape","dd71fee8":"img = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/train_image_data_1.parquet')\nimg.shape","b7206ac0":"img.head()","e3c8e62f":"img_id = img.iloc[:,0]\nimage = img.iloc[:,1:].values.reshape(-1, 137,236)\nimage","5264034b":"plt.figure(figsize=(12,12))\nfor i in range(10):\n plt.subplot(5,5,i+1)\n plt.imshow(image[i])","87d65baf":"**Load Packages-**","7f34a045":"**Exploring Parquet Files-**\nParquet files are best suited for Apache Hadoop system and good for storing files as pixels are arranged in columar pattern.","3ad23978":"**Getting Images from data-**","27195247":"**DATA EXPLORATION-**"}}