{"cell_type":{"141ea043":"code","63f60c60":"code","0e08be6c":"code","19d9fe62":"code","6bf8aa88":"code","a57b4056":"code","647db5ad":"code","07d804b6":"code","ff8bc5cb":"code","b1bd49a0":"code","8ad6cd54":"code","187ab980":"code","e594e00c":"code","8c53230a":"code","037fa70c":"code","8be1c6ba":"code","2dc50f44":"code","2b5a5011":"code","523bff93":"code","18587ff6":"code","c151099d":"code","1de0315d":"code","fa1085ae":"code","df946798":"code","c1c12549":"code","ca061978":"code","f7255e9b":"code","f19c8c03":"code","28285f5c":"code","d76cd5ef":"code","c5ca692c":"code","267c88ae":"code","12550633":"code","e8a99fda":"code","78bc1638":"code","8065a341":"code","3432040e":"code","ae79978c":"code","2e6c69b6":"code","5504bdda":"code","b70b330d":"code","018d9350":"code","ef60be13":"code","cc7e77f1":"code","e40f0d29":"code","507b3b9f":"code","88cea324":"code","90a700de":"code","5a9f73f3":"markdown","881b74ec":"markdown","27a169a9":"markdown","9aed4464":"markdown","0db365c1":"markdown","4b80c991":"markdown","e2419f92":"markdown","01156a88":"markdown","148a7c23":"markdown","c71383cb":"markdown","c6d12a87":"markdown","9a2957ca":"markdown"},"source":{"141ea043":"# importar pacotes necess\u00e1rios\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n# definir par\u00e2metros extras\npd.set_option('precision', 3)\npd.set_option('display.max_columns', 100)\n\n# carregar arquivos de dados de treino\ndata1 = pd.read_csv('..\/input\/zoo-train.csv', index_col='animal_name')\ndata2 = pd.read_csv('..\/input\/zoo-train2.csv', index_col='animal_name')\ndata3 = pd.read_csv('..\/input\/zoo-test.csv', index_col='animal_name')\n\n# quantas linhas e colunas existem?\nprint(\"data1.shape\")\nprint(data1.shape)\nprint(\"data2.shape\")\nprint(data2.shape)\nprint(\"data3.shape\")\nprint(data3.shape)\n# mostrar alguns exemplos de registros\ndata1.head(5)","63f60c60":"\n# Preparando os Dados\nfrom sklearn.preprocessing import StandardScaler\n\n# Normalizando as bases\ndata1['hair'] = np.where(data1['hair'] =='n', 0, 1)\ndata1['feathers'] = np.where(data1['feathers'] =='n', 0, 1)\ndata1['eggs'] = np.where(data1['eggs'] =='n', 0, 1)\ndata1['milk'] = np.where(data1['milk'] =='n', 0, 1)\ndata1['airborne'] = np.where(data1['airborne'] =='n', 0, 1)\ndata1['aquatic'] = np.where(data1['aquatic'] =='n', 0, 1)\ndata1['predator'] = np.where(data1['predator'] =='n', 0, 1)\ndata1['toothed'] = np.where(data1['toothed'] =='n', 0, 1)\ndata1['backbone'] = np.where(data1['backbone'] =='n', 0, 1)\ndata1['breathes'] = np.where(data1['breathes'] =='n', 0, 1)\ndata1['venomous'] = np.where(data1['venomous'] =='n', 0, 1)\ndata1['fins'] = np.where(data1['fins'] =='n', 0, 1)\ndata1['tail'] = np.where(data1['tail'] =='n', 0, 1)\ndata1['domestic'] = np.where(data1['domestic'] =='n', 0, 1)\ndata1['catsize'] = np.where(data1['catsize'] =='n', 0, 1)\n\ndata2['hair'] = np.where(data2['hair'] =='n', 0, 1)\ndata2['feathers'] = np.where(data2['feathers'] =='n', 0, 1)\ndata2['eggs'] = np.where(data2['eggs'] =='n', 0, 1)\ndata2['milk'] = np.where(data2['milk'] =='n', 0, 1)\ndata2['airborne'] = np.where(data2['airborne'] =='n', 0, 1)\ndata2['aquatic'] = np.where(data2['aquatic'] =='n', 0, 1)\ndata2['predator'] = np.where(data2['predator'] =='n', 0, 1)\ndata2['toothed'] = np.where(data2['toothed'] =='n', 0, 1)\ndata2['backbone'] = np.where(data2['backbone'] =='n', 0, 1)\ndata2['breathes'] = np.where(data2['breathes'] =='n', 0, 1)\ndata2['venomous'] = np.where(data2['venomous'] =='n', 0, 1)\ndata2['fins'] = np.where(data2['fins'] =='n', 0, 1)\ndata2['tail'] = np.where(data2['tail'] =='n', 0, 1)\ndata2['domestic'] = np.where(data2['domestic'] =='n', 0, 1)\ndata2['catsize'] = np.where(data2['catsize'] =='n', 0, 1)\n\ndata3['hair'] = np.where(data3['hair'] =='n', 0, 1)\ndata3['feathers'] = np.where(data3['feathers'] =='n', 0, 1)\ndata3['eggs'] = np.where(data3['eggs'] =='n', 0, 1)\ndata3['milk'] = np.where(data3['milk'] =='n', 0, 1)\ndata3['airborne'] = np.where(data3['airborne'] =='n', 0, 1)\ndata3['aquatic'] = np.where(data3['aquatic'] =='n', 0, 1)\ndata3['predator'] = np.where(data3['predator'] =='n', 0, 1)\ndata3['toothed'] = np.where(data3['toothed'] =='n', 0, 1)\ndata3['backbone'] = np.where(data3['backbone'] =='n', 0, 1)\ndata3['breathes'] = np.where(data3['breathes'] =='n', 0, 1)\ndata3['venomous'] = np.where(data3['venomous'] =='n', 0, 1)\ndata3['fins'] = np.where(data3['fins'] =='n', 0, 1)\ndata3['tail'] = np.where(data3['tail'] =='n', 0, 1)\ndata3['domestic'] = np.where(data3['domestic'] =='n', 0, 1)\ndata3['catsize'] = np.where(data3['catsize'] =='n', 0, 1)\n\ndata1.head()","0e08be6c":"# quais s\u00e3o as colunas e respectivos tipos de dados?\ndata1.info()","19d9fe62":"# sum\u00e1rio estat\u00edstico das caracter\u00edsticas num\u00e9ricas\ndata1.describe()","6bf8aa88":"# quantos registros existem de cada classe?\ndata1['class_type'].value_counts()","a57b4056":"# gerar boxplot para cada uma das caracter\u00edsticas por esp\u00e9cie\ndata1.boxplot(by=\"class_type\", figsize=(20, 10))","647db5ad":"# gerar mapa de calor com a correla\u00e7\u00e3o das caracter\u00edsticas\nsns.heatmap(data1.corr(), annot=True, cmap='cubehelix_r')","07d804b6":"# importar pacotes necess\u00e1rios\nimport numpy as np\n\n\n# importar pacotes usados na sele\u00e7\u00e3o do modelo e na medi\u00e7\u00e3o da precis\u00e3o\nfrom sklearn.model_selection import train_test_split\n\n# importar os pacotes necess\u00e1rios para os algoritmos de classifica\u00e7\u00e3o\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n# definir dados de entrada\n\nX = data1.drop(['class_type'], axis=1) # tudo, exceto a coluna alvo\ny = data1['class_type'] # apenas a coluna alvo\n\nprint('Forma dos dados originais:', X.shape, y.shape)","ff8bc5cb":"# separarar dados para fins de treino (70%) e de teste (30%)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Forma dos dados separados:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)","b1bd49a0":"# A) Support Vector Machine (SVM)\n\nmodel = SVC()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')\n","8ad6cd54":"# B) Logistic Regression\n\nmodel = LogisticRegression()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","187ab980":"# C) Decision Tree\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","e594e00c":"# D) K-Nearest Neighbours\n\nmodel = KNeighborsClassifier(n_neighbors=3)\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","8c53230a":"# carregar arquivo de dados de treino\ntrain_data = data1\n\n# carregar arquivo de dados de teste\ntest_data = data3\n\ntest_data.head()\n","037fa70c":"# definir dados de treino\nfrom sklearn import preprocessing\n\nX_train = train_data.drop(['class_type'], axis=1) # tudo, exceto a resposta\ny_train = train_data['class_type'] # apenas a coluna alvo\nX_train_pro=preprocessing.scale(X_train)\n\nprint('Forma dos dados de treino:', X_train.shape, y_train.shape)","8be1c6ba":"# definir dados de teste\n\nX_test = test_data\nX_test_pro=preprocessing.scale(X_test)\n\nprint('Forma dos dados de teste:', X_test.shape)","2dc50f44":"# Usando Decision Tree\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\nprint(model)","2b5a5011":"# executar previs\u00e3o usando o modelo escolhido\ny_pred = model.predict(X_test)\n\nprint('Exemplos de previs\u00f5es:\\n', y_pred[:10])","523bff93":"# gerar dados de envio (submiss\u00e3o)\n\nsubmission = pd.DataFrame({\n  'animal_name': X_test.index,\n  'class_type': y_pred\n})\nsubmission.set_index('animal_name', inplace=True)\n\n# mostrar dados de exemplo\nsubmission.head(10)\n","18587ff6":"# gerar arquivo CSV para o envio\nsubmission.to_csv('.\/zoo-submission-dectree.csv')","c151099d":"# importar pacotes necess\u00e1rios\nimport numpy as np\n\n\n# importar pacotes usados na sele\u00e7\u00e3o do modelo e na medi\u00e7\u00e3o da precis\u00e3o\nfrom sklearn.model_selection import train_test_split\n\n# importar os pacotes necess\u00e1rios para os algoritmos de classifica\u00e7\u00e3o\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n# definir dados de entrada\nT = data1.append(data2, ignore_index=True)\nX = T.drop(['class_type'], axis=1) # tudo, exceto a coluna alvo\ny = T['class_type'] # apenas a coluna alvo\n\nprint('Forma dos dados originais:', X.shape, y.shape)","1de0315d":"# separarar dados para fins de treino (70%) e de teste (30%)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Forma dos dados separados:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)","fa1085ae":"# A) Support Vector Machine (SVM)\n\nmodel = SVC()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')\n","df946798":"# B) Logistic Regression\n\nmodel = LogisticRegression()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","c1c12549":"# C) Decision Tree\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","ca061978":"# D) K-Nearest Neighbours\n\nmodel = KNeighborsClassifier(n_neighbors=3)\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","f7255e9b":"data1.head()","f19c8c03":"data2.head()","28285f5c":"# carregar arquivo de dados de treino\ntrain_data = data1.append(data2, ignore_index=True)","d76cd5ef":"print(train_data.shape)\ntrain_data.head()","c5ca692c":"# carregar arquivo de dados de teste\ntest_data = data3\n\ntest_data.head()\n","267c88ae":"# definir dados de treino\nfrom sklearn import preprocessing\n\nX_train = train_data.drop(['class_type'], axis=1) # tudo, exceto a resposta\ny_train = train_data['class_type'] # apenas a coluna alvo\n\n\nprint('Forma dos dados de treino:', X_train.shape, y_train.shape)","12550633":"# definir dados de teste\n\nX_test = test_data\n\nprint('Forma dos dados de teste:', X_test.shape)","e8a99fda":"# Usando Decision Tree\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\nprint(model)","78bc1638":"# executar previs\u00e3o usando o modelo escolhido\ny_pred = model.predict(X_test)\n\nprint('Exemplos de previs\u00f5es:\\n', y_pred[:10])","8065a341":"# gerar dados de envio (submiss\u00e3o)\n\nsubmission = pd.DataFrame({\n  'animal_name': X_test.index,\n  'class_type': y_pred\n})\nsubmission.set_index('animal_name', inplace=True)\n\n# mostrar dados de exemplo\nsubmission.head(10)","3432040e":"# gerar arquivo CSV para o envio\nsubmission.to_csv('.\/zoo-submission-dectree-full.csv')","ae79978c":"#### Usando Vizinhos mais Pr\u00f3ximos...","2e6c69b6":"# Usando K-Nearest Neighbours\n\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train, y_train)\n\nprint(model)","5504bdda":"# executar previs\u00e3o usando o modelo escolhido\ny_pred = model.predict(X_test)\n\nprint('Exemplos de previs\u00f5es:\\n', y_pred[:10])","b70b330d":"# gerar dados de envio (submiss\u00e3o)\n\nsubmission = pd.DataFrame({\n  'animal_name': X_test.index,\n  'class_type': y_pred\n})\nsubmission.set_index('animal_name', inplace=True)\n\n# mostrar dados de exemplo\nsubmission.head(10)","018d9350":"# gerar arquivo CSV para o envio\nsubmission.to_csv('.\/zoo-submission-KNN-full.csv')","ef60be13":"# importar pacotes necess\u00e1rios\nimport numpy as np\n\n\n# importar pacotes usados na sele\u00e7\u00e3o do modelo e na medi\u00e7\u00e3o da precis\u00e3o\nfrom sklearn.model_selection import train_test_split\n\n# importar os pacotes necess\u00e1rios para os algoritmos de classifica\u00e7\u00e3o\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n# definir dados de entrada\nT = data2\nX = T.drop(['class_type'], axis=1) # tudo, exceto a coluna alvo\ny = T['class_type'] # apenas a coluna alvo\n\nprint('Forma dos dados originais:', X.shape, y.shape)","cc7e77f1":"# separarar dados para fins de treino (70%) e de teste (30%)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint('Forma dos dados separados:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)","e40f0d29":"# A) Support Vector Machine (SVM)\n\nmodel = SVC()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')\n","507b3b9f":"# B) Logistic Regression\n\nmodel = LogisticRegression()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","88cea324":"# C) Decision Tree\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","90a700de":"# D) K-Nearest Neighbours\n\nmodel = KNeighborsClassifier(n_neighbors=3)\n\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test) * 100\n\nprint(model, '\\nScore:', score, '%')","5a9f73f3":"N\u00e3o foram encontradas correla\u00e7\u00f5es siginificativas entre as vari\u00e1veis.","881b74ec":"## Gerando os arquivos para submiss\u00e3o...\n","27a169a9":"##### Todos os scores cairam, utilizando somente o segundo arquivo.\n","9aed4464":"#### Para as t\u00e9cnicas testadas, listo os scores encontrados:\nSVC Score: 80.64516129032258\n\nLogisticRegression Score: 93.54838709677419\n\nDecisionTreeClassifier Score: 100.0\n\nKNeighborsClassifier Score: 93.54838709677419\n\n\nA t\u00e9cnica de \u00e1rvore de decis\u00e3o apresentou o melhor resultado.\n    ","0db365c1":"## Testando Modelos novamente, utilizando somente a segunda base...","4b80c991":"#### Testando Modelos...","e2419f92":"#### Utilizando \u00c1rvore de Decis\u00e3o","01156a88":"## Gerando os arquivos para submiss\u00e3o utilizando as duas bases...","148a7c23":"#### Usando \u00c1rvore de Decis\u00e3o...","c71383cb":"# Explora\u00e7\u00e3o dos Dados\n\nO arquivos .csv foram baixados e explorados visualmente com o uso do excel, por\u00e9m nenhuma caracter\u00edstica classificat\u00f3ria foi observada.\n\nEnt\u00e3o iniciei a leitura e explora\u00e7\u00e3o dos dados atrav\u00e9s do Jupyter.","c6d12a87":"## Testando Modelos novamente, utilizando todos os dados (das duas bases)...","9a2957ca":"#### Para as t\u00e9cnicas testadas com todos os registros, listo os scores encontrados:\nSVC Score: 88.63636363636364 %\n\nLogisticRegression Score: 97.72727272727273 %\n\nDecisionTreeClassifier Score: 97.72727272727273 %\n\nKNeighborsClassifier Score: 97.72727272727273 %\n\n\nA t\u00e9cnica de \u00e1rvore de decis\u00e3o, Regress\u00e3o Log\u00edstica, e KNN apresentaram os melhores resultados, ficando empatados."}}