{"cell_type":{"2848062e":"code","f0bbdd49":"code","d213f3c0":"code","ef2977a0":"code","4efb8a69":"code","456c800b":"code","b251619e":"code","dff6f362":"markdown","95e57d81":"markdown","a5c8ccaa":"markdown","af7e6977":"markdown","c6739c5a":"markdown","a3d0c324":"markdown"},"source":{"2848062e":"import itertools\nimport os\n\nimport matplotlib.pylab as plt\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport keras\n\nprint(\"TF version:\", tf.__version__)\nprint(\"Hub version:\", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")","f0bbdd49":"module_selection = (\"mobilenet_v2_100_224\", 224) #@param [\"(\\\"mobilenet_v2_100_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\nhandle_base, pixels = module_selection\nMODULE_HANDLE =\"https:\/\/tfhub.dev\/google\/imagenet\/{}\/feature_vector\/4\".format(handle_base)\nIMAGE_SIZE = (pixels, pixels)\nprint(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n\nBATCH_SIZE = 32 #@param {type:\"integer\"}","d213f3c0":"data_dir = tf.keras.utils.get_file(\n    'flower_photos',\n    'https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz',\n    untar=True)\n\ndatagen_kwargs = dict(rescale=1.\/255, validation_split=.20)\ndataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n                   interpolation=\"bilinear\")\n\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    **datagen_kwargs)\nvalid_generator = valid_datagen.flow_from_directory(\n    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n\n#O dataset augmentation, selecionado na condicional abaixo, melhora a performance do treino  e generaliza\u00e7\u00e3o do modelo\ndo_data_augmentation = True #@param {type:\"boolean\"}\nif do_data_augmentation:\n  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n      rotation_range=40,\n      horizontal_flip=True,\n      width_shift_range=0.2, height_shift_range=0.2,\n      shear_range=0.2, zoom_range=0.2,\n      **datagen_kwargs)\nelse:\n  train_datagen = valid_datagen\ntrain_generator = train_datagen.flow_from_directory(\n    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)","ef2977a0":"do_fine_tuning = False #@param {type:\"boolean\"}\n\nprint(\"Building model with\", MODULE_HANDLE)\nmodel = tf.keras.Sequential([\n    # Explicitly define the input shape so the model can be properly\n    # loaded by the TFLiteConverter\n    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n    tf.keras.layers.Dropout(rate=0.2),\n    tf.keras.layers.Dense(train_generator.num_classes,\n                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n])\nmodel.build((None,)+IMAGE_SIZE+(3,))\nmodel.summary()","4efb8a69":"model.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0) #Stochastic Gradient Descent\n  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n  metrics=['accuracy'])","456c800b":"steps_per_epoch = train_generator.samples \/\/ train_generator.batch_size\nvalidation_steps = valid_generator.samples \/\/ valid_generator.batch_size\nhist = model.fit(\n    train_generator,\n    epochs=5, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps).history","b251619e":"plt.figure()\nplt.ylabel(\"Loss (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,2])\nplt.plot(hist[\"loss\"])\nplt.plot(hist[\"val_loss\"])\n\nplt.figure()\nplt.ylabel(\"Accuracy (training and validation)\")\nplt.xlabel(\"Training Steps\")\nplt.ylim([0,1])\nplt.plot(hist[\"accuracy\"])\nplt.plot(hist[\"val_accuracy\"])","dff6f362":"**Treino do modelo**","95e57d81":"**Introdu\u00e7\u00e3o**\n\nO objetivo desse notebook \u00e9 a cria\u00e7\u00e3o de um modelo Keras para classifica\u00e7\u00e3o de imagens, utilizando um modelo pr\u00e9-treinado do TensorFlow Hub para etra\u00e7\u00e3o de features de imagens - o pre-training foi feito no dataset ImageNet, maior e mais generalista.\nModelos de classifica\u00e7\u00e3o de imagens podem ter numerosos par\u00e2metros, e seu treino a partir do zero demanda muitos dados j\u00e1 classificados e capacidade computacional. Uma das vantagens do transfer learning \u00e9 justamente essa: a reutiliza\u00e7\u00e3o de um modelo pr\u00e9-treinado em um novo problema.\n\n","a5c8ccaa":"**Importa\u00e7\u00e3o do dataset**\n\n","af7e6977":"**Sele\u00e7\u00e3o de modelo pr\u00e9-salvo**\n\nAqui selecionamos o modelo (\"mobilenet_v2_100_224\", 224) e trabalhamos batch size 32:","c6739c5a":"**Importa\u00e7\u00e3o de pacotes**","a3d0c324":"**Defini\u00e7\u00e3o do modelo**"}}