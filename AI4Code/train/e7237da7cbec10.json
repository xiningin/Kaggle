{"cell_type":{"80aa320e":"code","a4a0b5b3":"code","e035e6fd":"code","8e6983f2":"code","9cef3957":"code","d1ceebdc":"code","ea187d2a":"code","a1d3bb46":"code","be7e24f8":"code","fab83612":"code","66f54e2c":"code","efae061b":"code","824376f6":"code","6cab1b5e":"code","7cd94234":"code","1df1006f":"code","8f6fdab5":"code","abf45bf5":"code","31aaae4e":"code","0e6f18e3":"code","a0ceb7d2":"markdown","c881d3ff":"markdown","a7f154b1":"markdown","1e6f16c7":"markdown","d2e6a009":"markdown","eb9346ff":"markdown"},"source":{"80aa320e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a4a0b5b3":"# \ubd84\uc11d\ub370\uc774\ud130(\uc120\uac70\ud589\ub3d9)  \ub370\uc774\ud130 \ud655\uc778\nimport pandas as pd\ndata=pd.read_csv('..\/input\/big-data-certification-study\/Fvote.csv', encoding='utf-8')\ndata.head()\n","e035e6fd":"data.describe()\n","8e6983f2":"data.hist(figsize=(20,10))\n","9cef3957":"# \ud2b9\uc131 \ubcc0\uc218\uc640 \ub808\uc774\ube14 \ubcc0\uc218 \ub098\ub204\uae30\nX=data.loc[:, 'gender_female':'score_intention']\ny=data[['vote']]","d1ceebdc":"# \ud2b9\uc131 \ubcc0\uc218\uc640 \ub808\uc774\ube14 \ubcc0\uc218 \ud589\uc5f4\ud655\uc778\nprint(X.shape)\nprint(y.shape)","ea187d2a":"# \ud559\uc2b5\uc6a9 \ub370\uc774\ud130(train)\uc640 \ud14c\uc2a4\ud2b8\uc6a9 \ub370\uc774\ud130(test) \uad6c\ubd84\uc744 \uc704\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\n# \ub808\uc774\ube14\uc774 \ubc94\uc8fc\ud615\uc77c \uacbd\uc6b0 straity \uc635\uc158 \ucd94\ucc9c\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X, y, stratify=y, random_state=42)","a1d3bb46":"# \ud559\uc2b5\ub370\uc774\ud130\uc640 \ud14c\uc2a4\ud2b8\ub370\uc774\ud130\uc758 0\/1 \ube44\uc728\uc774 \uc720\uc0ac\ud55c\uc9c0 \ud3c9\uade0\uc73c\ub85c \ud655\uc778(stratity \uc635\uc158 \uc801\uc6a9\uc2dc \uc720\uc0ac)\nprint(y_train.mean())\nprint(y_test.mean())","be7e24f8":"# \ud2b9\uc131\uce58(X)\uc758 \ub2e8\uc704 \uc815\uaddc\ud654\ub97c \uc704\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac \ube14\ub7ec\uc624\uae30(min-max)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler_minmax=MinMaxScaler()","fab83612":"# min-max \ubc29\ubc95\uc73c\ub85c \uc815\uaddc\ud654\n# \uc8fc\uc758!: fit\uc740 \ud559\uc2b5\ub370\uc774\ud130\ub85c \ud574\uc57c, \ub098\uc911\uc5d0 test \ub370\uc774\ud130 \uc815\uaddc\ud654\uc2dc train \ub370\uc774\ud130\uc758 \ucd5c\ub300-\ucd5c\uc18c \uae30\uc900\uc774 \uc801\uc6a9\ub428\nscaler_minmax.fit(X_train)\nX_scaled_minmax_train=scaler_minmax.transform(X_train)\n\n","66f54e2c":"# test \ub370\uc774\ud130\uc5d0\ub3c4 \uc815\uaddc\ud654 \uc801\uc6a9 \ubc0f \ub370\uc774\ud130 \ud655\uc778: min-max \ubc29\ubc95\nX_scaled_minmax_test=scaler_minmax.transform(X_test)\npd.DataFrame(X_scaled_minmax_test).describe()\n","efae061b":"# min-max \ubc29\ubc95\uc73c\ub85c \uc815\uaddc\ud654\ud55c \ub370\uc774\ud130\uc758 \uae30\uc220\ud1b5\uacc4\ub7c9 \ud655\uc778\npd.DataFrame(X_scaled_minmax_train).describe()","824376f6":"# \ud2b9\uc131\uce58(X)\uc758 \ub2e8\uc704 \uc815\uaddc\ud654\ub97c \uc704\ud55c \ub77c\uc774\ube0c\ub7ec\ub9ac \ube14\ub7ec\uc624\uae30(standard)\nfrom sklearn.preprocessing import StandardScaler\nscaler_standard=StandardScaler()\n# standard \ubc29\ubc95\uc73c\ub85c \uc815\uaddc\ud654\n# \uc8fc\uc758!: fit\uc740 \ud559\uc2b5\ub370\uc774\ud130\ub85c \ud574\uc57c, \ub098\uc911\uc5d0 test \ub370\uc774\ud130 \uc815\uaddc\ud654\uc2dc train \ub370\uc774\ud130\uc758 \ud45c\uc900\ud654(\ud3c9\uade0, \ud45c\uc900\ud3b8\ucc28) \uae30\uc900\uc774 \uc801\uc6a9\ub428\nscaler_standard.fit(X_train)\nX_scaled_standard_train=scaler_standard.transform(X_train)","6cab1b5e":"# standard \ubc29\ubc95\uc73c\ub85c \uc815\uaddc\ud654\ud55c \ub370\uc774\ud130\uc758 \uae30\uc220\ud1b5\uacc4\ub7c9 \ud655\uc778\npd.DataFrame(X_scaled_standard_train).describe()","7cd94234":"# test \ub370\uc774\ud130\uc5d0\ub3c4 \uc815\uaddc\ud654 \uc801\uc6a9 \ubc0f \ub370\uc774\ud130 \ud655\uc778: standard \ubc29\ubc95\nX_scaled_standard_test=scaler_standard.transform(X_test)\npd.DataFrame(X_scaled_standard_test).describe()","1df1006f":"# ML \uc54c\uace0\ub9ac\uc998 \ubaa8\ub4c8 \ubd88\ub7ec\uc624\uae30 \ubc0f \ud559\uc2b5\ub370\uc774\ud130\uc5d0 \uc801\uc6a9(LogisticRegression)\nfrom sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()","8f6fdab5":"# \ud6c8\ub828\ub370\uc774\ud130\uc758 \uc815\ud655\ub3c4(accuracy) \ud655\uc778\nmodel.fit(X_scaled_minmax_train, y_train)\npred_train=model.predict(X_scaled_minmax_train)\nmodel.score(X_scaled_minmax_train, y_train)","abf45bf5":"# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uc815\ud655\ub3c4\npred_test=model.predict(X_scaled_minmax_test)\nmodel.score(X_scaled_minmax_test, y_test)","31aaae4e":"# \ud6c8\ub828\ub370\uc774\ud130\uc758 \uc815\ud655\ub3c4(accuracy) \ud655\uc778\nmodel.fit(X_scaled_standard_train, y_train)\npred_train=model.predict(X_scaled_standard_train)\nmodel.score(X_scaled_standard_train, y_train)","0e6f18e3":"# \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uc815\ud655\ub3c4\npred_test=model.predict(X_scaled_standard_test)\nmodel.score(X_scaled_standard_test, y_test)","a0ceb7d2":"5. Model Score Check  \ubaa8\ub378 \ud559\uc2b5","c881d3ff":"4. Standard Scaler \n","a7f154b1":"3.  Min Max Sclaler \n","1e6f16c7":"2. Train Data , test Data Split \n","d2e6a009":"Standardize \uc815\uaddc\ud654 \ub370\uc774\ud130 \uc801\uc6a9\uacb0\uacfc\n","eb9346ff":"1. Data read_csv\n"}}