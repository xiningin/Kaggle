{"cell_type":{"f0c23b17":"code","9d4e63f7":"code","ac437a63":"code","8879fce3":"code","6e274e38":"code","a819a8c7":"code","fc051964":"code","f48c2692":"code","9136a123":"code","6e4bb288":"code","52c34323":"code","7c265e14":"code","2e81d298":"code","2f5f41b7":"code","c11e26f3":"code","7d22fe24":"code","8f9ae94b":"code","36d46fba":"code","367a62b3":"code","47539ac8":"markdown","a724a8af":"markdown","c3491dbb":"markdown","6c62ee8e":"markdown","df8ab4ee":"markdown","d5667bbf":"markdown","1320632b":"markdown","03b81d75":"markdown","d30545b1":"markdown","2ce64656":"markdown"},"source":{"f0c23b17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d4e63f7":"import sklearn\nsklearn.__version__","ac437a63":"import gc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, roc_auc_score","8879fce3":"train_data =  pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntrain_data_0 = pd.read_csv('..\/input\/november21\/train.csv')\ntest_data =  pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\nX = train_data.drop('target',axis=1).set_index('id')\ny = train_data.target\ny0 = train_data_0.target\nX_test = test_data.set_index('id')","6e274e38":"del train_data, train_data_0, test_data\ngc.collect()","a819a8c7":"ss = StandardScaler().fit(X)\nX = pd.DataFrame(ss.transform(X),index=X.index,columns=X.columns)\nX_test = pd.DataFrame(ss.transform(X_test),index=X_test.index,columns=X_test.columns)","fc051964":"clf = LinearSVC(C=1e6, dual=False, tol=1e-6, max_iter=100000,random_state=42).fit(X,y0)\naccuracy_score(y0,clf.predict(X))","f48c2692":"scores = clf.decision_function(X)\npc = 3.0\nlo=np.percentile(scores[scores<0],100-pc\/2)\nhi=np.percentile(scores[scores>=0],pc\/2)\nmask = np.logical_and(scores>lo,scores<hi)\nX_b, y0_b = X[mask], y0[mask]","9136a123":"pip install cvxopt","6e4bb288":"import cvxopt","52c34323":"def hard_margin_svm(X,y):\n    X = X.to_numpy()\n    y = y.to_numpy().astype(np.float64)\n    \n    y = (2*y - 1).reshape(-1,1) # convert to +\/- 1 target representation\n    \n    m,n = X.shape\n    X_1 = y * X\n    H = np.dot(X_1 , X_1.T) \n\n\n    P = cvxopt.matrix(H)\n    q = cvxopt.matrix(-np.ones((m, 1)))\n    G = cvxopt.matrix(-np.eye(m))\n    h = cvxopt.matrix(np.zeros((m,1)))\n    A = cvxopt.matrix(y.reshape(1, -1))\n    b = cvxopt.matrix(np.zeros(1))\n\n    cvxopt.solvers.options['show_progress'] = True\n    cvxopt.solvers.options['abstol'] = 1e-8\n    cvxopt.solvers.options['reltol'] = 1e-8\n    cvxopt.solvers.options['feastol'] = 1e-8\n\n    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n    alpha = np.array(solution['x']) \n    \n    w = ((y * alpha).T @ X).reshape(-1,1)\n    S = (alpha > 1e-4).flatten()\n    b = np.mean(y[S] - np.dot(X[S], w))\n    \n    return alpha, w, b\n    ","7c265e14":"alpha, w, b = hard_margin_svm(X_b,y0_b)","2e81d298":"def decision_function(w,b,X):\n    return (X.to_numpy()@w+b).reshape(-1,) ","2f5f41b7":"min(decision_function(w,b,X)*(2*y0.to_numpy()-1))","c11e26f3":"2\/np.linalg.norm(w)","7d22fe24":"accuracy_score(y0,decision_function(w,b,X)>0)","8f9ae94b":"roc_auc_score(y,decision_function(w,b,X))","36d46fba":"scores = decision_function(w,b,X_test)","367a62b3":"pd.DataFrame({'id': X_test.index, 'target': scores}).to_csv('submission.csv', index=False)\nprint(\"Submission saved!\")","47539ac8":"How does the training AUC score fare on the altered labels?","a724a8af":"Okay, this is practically 1. We have indeed found the hard margin SVM. And the margin width is given by $\\frac{2}{||w||}$.","c3491dbb":"\nFinally, let's make a submission.","6c62ee8e":"Now just run it already!","df8ab4ee":"If we fitted a hard margin SVM with all the samples, there would be too many (600000) constraints for the cvxopt solver. Instead, we build a soft margin SVM first as a first approximation of the decision boundary, and take only 3% of the samples around this approximate boundary.","d5667bbf":"Loading data as usual, special thanks to @criskiev for providing the training labels before the infamous \"flip\".","1320632b":"For perspective, all the features have been normalized to stdev 1. So the two classes can be linearly separated, but barely -- the margin is tiny.\n\nNext, what is the training accuracy on the original, unaltered labels? We know it should be 1 because the hard margin SVM separates the two classes by definition. Let's double check that.","03b81d75":"Convergence sooner than I thought! Now we need to write a little function to emulate the function with the same name in LinearSVC. This is not probability, but for AUC scoring purpose, this would suffice as a ranking function.","d30545b1":"Something we need to check before moving on. We only fitted the classifier with 3% of the data around the approximate decision boundary. How do we know that the hard margin constraints, viz., $$\\tilde{y}_i(x_i\\cdot w+b)\\ge1$$ are satisfied for the rest of the samples? We need to check this manually.","2ce64656":"Now we solve the dual form of the hard margin SVM optimization problem. The following function is heavily based on the implementation of Xavier Bourret Sicotte.\n\n[https:\/\/xavierbourretsicotte.github.io\/SVM_implementation.html](https:\/\/xavierbourretsicotte.github.io\/SVM_implementation.html)"}}