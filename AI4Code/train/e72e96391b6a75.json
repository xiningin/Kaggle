{"cell_type":{"bd25774e":"code","220f84f9":"code","e7f60d96":"code","04ca3a7a":"code","3c69fafe":"code","6dd9b111":"code","e77f6a19":"code","0f32e49a":"code","1014de0f":"code","ce8c7db8":"code","72caa715":"code","cadd147e":"code","34e1abaa":"code","06d4ca43":"code","afa4f9a4":"code","f8246cb6":"code","17a126e3":"code","ebb4eb22":"code","a0ac88ed":"code","239e4462":"code","2770a67c":"code","1a4d9156":"code","0775482f":"code","424b1208":"code","85bcff10":"code","9a58fefb":"code","d8a04712":"code","4385ceb2":"code","6b99100a":"code","9b6c15fb":"code","09d9ce86":"code","ff48fa38":"code","666e9d03":"code","4a54cda3":"code","fe9d99a3":"code","17515a30":"code","4ceb6728":"code","86214ae2":"code","49e096e4":"code","5b439875":"code","767779dd":"code","3e4aa82e":"code","00e63c08":"code","f0d80532":"code","0810ee6d":"code","0584f35a":"code","07d707de":"code","5296dcb1":"code","b3ceeb72":"code","9b7c138c":"code","064d9d35":"code","bbd9876b":"code","d889cab7":"code","2a7d039f":"code","b2da62eb":"code","dd8f52c0":"code","925dd2c7":"markdown","bed81b1d":"markdown","bb0b27c0":"markdown","0bcac4f2":"markdown","6dc51c51":"markdown","eb6148fb":"markdown","95092a68":"markdown","9faf489b":"markdown","343b9c54":"markdown","42679e32":"markdown","0c186f26":"markdown","fb3b3eb2":"markdown","c499e1ae":"markdown","b1a72d99":"markdown","0d395d4c":"markdown","fde8d26a":"markdown"},"source":{"bd25774e":"#Load required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","220f84f9":"#Load the data\ntitan=pd.read_csv(\"..\/input\/titan.csv\")","e7f60d96":"#get an overview of the data\ntitan.head()","04ca3a7a":"titan.sample(10)","3c69fafe":"titan.tail()","6dd9b111":"titan.shape","e77f6a19":"#Identify variables\ntitan.dtypes\ntitan.info()","0f32e49a":"titan.columns","1014de0f":"#Data cleaning\ntitan.drop([\"Unnamed: 0\"], axis=1,inplace=True)\ntitan.head()\n","ce8c7db8":"titan.pclass.unique()","72caa715":"#Understand various summary statistics of the data\n\ninclude =['object', 'float', 'int'] \ntitan.describe(include=include)\n#titan.describe()","cadd147e":"#Get count of missing values in the dataset\ntitan.isnull().sum()","34e1abaa":"#get value counts of unique categorical values in a column - Univariate analysis\ntitan.pclass.value_counts()","06d4ca43":"#get all unique values in a column\ntitan.embark_town.value_counts()","afa4f9a4":"iris=sns.load_dataset(\"iris\")\niris.head()","f8246cb6":"iris.species.value_counts()","17a126e3":"iris.shape","ebb4eb22":"titan.survived.value_counts()\n","a0ac88ed":"titan.sex.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'","239e4462":"ax = sns.countplot(x = 'survived',data = titan) \ntotal = float(len(titan))\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \nplt.show()","2770a67c":"titan.age.hist(figsize=(10,5))","1a4d9156":"plt.figure(figsize=(10,5))\nsns.distplot(titan['age'], hist=False)","0775482f":"plt.figure(figsize=(15,10))\nsns.distplot(titan['fare'])","424b1208":"iris.plot(kind = 'hist', stacked = False, bins = 10)","85bcff10":"import plotly.express as px\nfig = px.box(titan,x='survived',y='age', color='pclass')\nfig.show()","9a58fefb":"sns.relplot(x = 'sepal_length', y = 'petal_length', hue='species',data = iris)","d8a04712":"sns.relplot(x = 'sepal_width', y = 'petal_width',style = 'species' ,data = iris)","4385ceb2":" relplot = sns.catplot(x=\"pclass\", hue=\"who\", col=\"survived\",  \n      data=titan, kind=\"count\",  \n    height=4, aspect=.7);  \nrelplot","6b99100a":"#You can visually analyse the missing data using a library Missingno. \n\nimport missingno as msno\nmsno.bar(titan)","9b6c15fb":"decmiss=titan.deck.isna().sum()\nperdecmiss = decmiss\/len(titan.deck)\nperdecmiss","09d9ce86":"msno.heatmap(titan)","ff48fa38":"titancopy=titan.copy()","666e9d03":"#Deleting the Deck column\ntitancopy.drop('deck',axis=1, inplace=True)","4a54cda3":"np.median(titan['age'])\nnp.mean(titan['age'])","fe9d99a3":"from scipy import stats\nstats.mode(titan['age'])","17515a30":"titancopy['age'].fillna(29,inplace=True)","4ceb6728":"titancopy.embarked.value_counts()","86214ae2":"titancopy['embarked'].fillna(\"S\", inplace=True)","49e096e4":"titancopy.embark_town.value_counts()","5b439875":"titancopy['embark_town'].fillna(\"Southampton \", inplace=True)","767779dd":"titancopy.isna().sum()","3e4aa82e":"px.box(titan, y='age')","00e63c08":"px.box(titan,x='survived',y='fare', color='pclass')","f0d80532":"titancopy.corr()","0810ee6d":"plt.figure(figsize=(10,10))\ncorr = titan.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True, annot=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n)\nax.set_yticklabels(\n    ax.get_yticklabels(),\n    rotation=45,\n\n);","0584f35a":"mask = np.triu(np.ones_like(iris.corr(), dtype=np.bool))\nfig, ax = plt.subplots(figsize=(15, 10)) \nsns.heatmap(iris.corr(), mask=mask, annot=True) \n            ","07d707de":"sns.pairplot(iris)","5296dcb1":"from pandas.plotting import scatter_matrix\nscatter_matrix(iris, figsize= (10,10),  color = 'r',diagonal='kde')\nplt.show()","b3ceeb72":"ax=iris.plot(figsize=(15,10), title=\"Iris\")\nplt.xlabel('X Axis')\nplt.ylabel('Y Axis')","9b7c138c":"titancopy.plot(kind=\"line\",subplots = True, sharex = False, layout = (2,3), figsize = (16,8))\nplt.tight_layout()","064d9d35":"#Adding trendline to the data\nx=iris.sepal_length\ny=iris.petal_width\nplt.scatter(x, y)\n\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),\"y--\")\n\nplt.show()","bbd9876b":"\nx=iris.sepal_length\ny=iris.petal_length\nplt.scatter(x, y)\n\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),\"r\")\n\nplt.show()","d889cab7":"titancopy","2a7d039f":"#variable transformation\ntitancopy['alive'].replace({'no':0,'yes':1}, inplace=True)","b2da62eb":"#Convert boolean to integer\ntitancopy[\"alone\"]=titancopy[\"alone\"].astype(int)","dd8f52c0":"titancopy","925dd2c7":"# Feature Engineering\n\nTwo techniques of feature engineering are:\n* Variable Transformation\n* Variable\/Feature creation\n\nVariable transformation: is replacement of a variable by a function. For example replacing a variable y by the square\/cube root or log of y. Binning also can be used.\n\nFeature\/Variable creation: is a process to generate new variables\/features based on existing variable.","bed81b1d":"**Histogram**\nA normal distribution is an idealized, smooth, bell-shaped histogram with all of the randomness removed. It represents an ideal data set that has lots of numbers concentrated in the middle of the range, with the remaining numbers trailing off symmetrically on both sides.\nSome histograms will show a skewed distribution to the right. A distribution skewed to the right is said to be positively skewed. Some histograms will show a skewed distribution to the left. A distribution skewed to the left is said to be negatively skewed. ","bb0b27c0":"# Visualize patterns in the data\n Identification of patterns in your data, which includes correlation between data attributes or between missing data. It\u2019s time to also explore the data visually.\n \n","0bcac4f2":"If you have a data set with many columns, a good way to quickly check correlations among columns is by visualizing the correlation matrix as a heatmap.","6dc51c51":"For Predicting Survival using simple RandomForest and Decision Tree techniques on the Titanic dataset refer [Simple EDA, Prediction using RForest & DecisionTr](https:\/\/www.kaggle.com\/krrai77\/simple-eda-prediction-using-rforest-decisiontr)","eb6148fb":"Before deleting columns check if the column is significant or has strong correlation with other variables in the dataset using a correlation matrix or heatmap. Make a copy of the original dataset before deleting any data.","95092a68":"Pair plot allows us to see both distribution of single variable and relationships between two variables. They are great method to identify trends for further analysis.","9faf489b":"A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. The line of 1.00s going from the top left to the bottom right is the main diagonal, which shows that each variable always perfectly correlates with itself. This matrix is symmetrical, with the same correlation is shown above the main diagonal being a mirror image of those below the main diagonal.","343b9c54":"24 is the most frequently occurring value in the dataset for age. Therefore, it is the mode of the data set for age.","42679e32":"# Handling Missing values\n\nMissing data while modeling can reduce the power \/ fit of a model or can lead to a biased model. It can lead to wrong prediction or classification. \nMethods for treating missing values are:\n* Deleting the observations. Disadvantage is it reduces the sample size. If more than 70% of the values are missing for a column then that column can be deleted.\n* Mean\/ Mode\/ Median\/ Constant Imputation. Imputation is a method to fill in the missing values with calculated ones or a contant value. This is the most frequently used method. For numerical values you can go with mean, and if there are some outliers try median. For categorical values replace the missing entry with the most frequent one.\n* Prediction model is one of the complex method for handling missing data. Here a predictive model is built to estimate values that will substitute the missing data. \n","0c186f26":"# Data Exploration and Visualization Using Python\n\nData exploration is a key aspect of data analysis. Without spending significant time on data exploration one cannot expect to get good insights about the dataset which is very important to build efficient predictive models. You can get a basic description of the data, visualize it, and identify patterns in it,\n\nBelow are some of the key steps involved in data exploration:\n* Load data \n* Identify variables\n* Variable analysis\n* Handling missing values\n* Outlier detection\n* Visualize data patterns\n* Feature engineering\n\nIn this tutorial each step will be studied with examples.\n\n\n","fb3b3eb2":"# Handling Outliers\n\nBox plot helps in identifying outliers in the data. Outlier is an observation that appears away from an overall pattern in a sample.\n\nMedian (Q2\/50th Percentile): the middle value of the dataset.\nFirst quartile (Q1\/25th Percentile): the middle number between the smallest number (not the \u201cminimum\u201d) and the median of the dataset.\nThird quartile (Q3\/75th Percentile): the middle value between the median and the highest value (not the \u201cmaximum\u201d) of the dataset.\nInterquartile range (IQR): 25th to the 75th percentile.\nWhiskers\nOutliers","c499e1ae":"# Univariate Analysis\nIn case of continuous variables, we need to understand the central tendency and spread of the variable. We can use Box plots and Histogram for this purpose. Categorical variables can be measured using Count and Count% against each category. Bar chart can be used as visualization.","b1a72d99":"# Identify variable types\n\nVariable category - Variable can be **Categorial or Continuos**\nIn the titanic variable **Categorical variables** are:\n* Sex\n* Embarked\n* Class\n* Who\n* Adult_male\n* Deck\n* Embark_town\n* Alive\n* Alone\n* survived\n* pclass\n* parch\n* sibsp\n\nContinuos variables are:\n* age\n* fare\n\nIn this **Target variable is Survived** and other variables are Predictors. \n(sibsp - Number of Siblings\/Spouses Aboard, parch - Number of Parents\/Children Aboard)","0d395d4c":"# Bi-variate Analysis\nBi-variate Analysis finds out the relationship between two variables. We can perform bi-variate analysis for any combination of categorical and continuous variables. \nWhile doing bi-variate analysis between two continuous variables, scatter plot is best to use. Scatter plot indicates the linear or non-linear relationship between the variables. \nBar charts helps to understand relation between 2 categorical variables. \n\n\n","fde8d26a":"Most of the ways to handle outliers are similar to the methods of missing values like deleting observations, transforming them, put them in a separate group, and  imputing values. Outliers can drastically change the outcome of the data analysis and statistical modeling."}}