{"cell_type":{"18b82b0d":"code","8b4a7511":"code","782a5af7":"code","38569b5f":"code","6444de82":"code","f2a5b728":"code","576449be":"code","f430d244":"code","dd7a25ca":"code","b1a9a5b8":"code","b4d7f610":"code","8498ccb7":"code","fac19289":"code","e3588aff":"code","5690dc36":"code","c6257b76":"code","d3880d3b":"code","60caffc1":"code","2384ee31":"code","bfb8a073":"code","04a691fd":"code","353d02a9":"code","6901e6ba":"code","fbf26fbe":"code","624ba72d":"code","c3f17905":"code","a7a35be3":"code","3668f7c7":"code","1988197c":"code","7bc4e0cc":"code","0e8c5215":"code","db7f44ab":"code","db3ff8b5":"code","4ace10e8":"code","e0db37bd":"code","d378dfdf":"code","4b1304b1":"code","7b6a9481":"code","eb82acb5":"code","653e06d3":"code","301c1494":"code","34ed1d58":"markdown","93a28230":"markdown","cf1c42b6":"markdown","a13bb73c":"markdown","94edee3a":"markdown","f3036d9b":"markdown","62f52b2e":"markdown","2f41f171":"markdown","dab51737":"markdown","d4126313":"markdown","fc14cb89":"markdown","1e28fa1e":"markdown","7315065b":"markdown","a41f8ecc":"markdown","47490a3a":"markdown","a2a21763":"markdown","27ca323c":"markdown","45440771":"markdown"},"source":{"18b82b0d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","8b4a7511":"df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","782a5af7":"df.head()","38569b5f":"df.info()","6444de82":"plt.figure(figsize=(8,5))\nsns.countplot(x=df['target'])\nplt.title('Target column count',fontsize=20)\nplt.xlabel('Target',fontsize=15)\nplt.ylabel('Count',fontsize=15);","f2a5b728":"df['text'].isnull().sum()","576449be":"df['text'].str.isspace().sum()","f430d244":"import string","dd7a25ca":"def remove_punctuation(text_str):\n    for x in text_str:\n        if x in string.punctuation:\n            text_str = text_str.replace(x,\"\")\n    return text_str","b1a9a5b8":"df['text']=df['text'].apply(remove_punctuation)","b4d7f610":"df.head()","8498ccb7":"df['text'].isnull().sum()","fac19289":"df['text'].str.isspace().sum()","e3588aff":"df = df.drop(['keyword','location'],axis=1)","5690dc36":"df.head()","c6257b76":"from sklearn.feature_extraction.text import CountVectorizer ","d3880d3b":"cv = CountVectorizer(stop_words='english')","60caffc1":"matrix = cv.fit_transform(df[df['target']==1]['text'])\nfreqs = zip(cv.get_feature_names(), matrix.sum(axis=0).tolist()[0]) \n\nprint(\"Top 15 words used for disaster tweets.\")\nprint(sorted(freqs, key=lambda x: -x[1])[:15])","2384ee31":"matrix = cv.fit_transform(df[df['target']==0]['text'])\nfreqs = zip(cv.get_feature_names(), matrix.sum(axis=0).tolist()[0]) \n\nprint(\"Top 15 words used for non disaster tweets.\")\nprint(sorted(freqs, key=lambda x: -x[1])[:15])","bfb8a073":"X = df['text']","04a691fd":"y = df['target']","353d02a9":"from sklearn.model_selection import train_test_split","6901e6ba":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=101)","fbf26fbe":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text  import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,auc,roc_curve,plot_roc_curve","624ba72d":"tfidf = TfidfVectorizer(stop_words='english')\nsvc = SVC(class_weight='balanced',random_state=30)\nlg_model = LogisticRegression(class_weight='balanced',random_state=30)\nrfc_model = RandomForestClassifier(class_weight='balanced',random_state=30)","c3f17905":"def select_model(model,tfidf=tfidf,X_train=X_train,X_test = X_test,y_test = y_test,y_train=y_train):\n    operation = [('tfidf',tfidf),('model',model)]\n    pipe = Pipeline(operation)\n    pipe.fit(X_train,y_train)\n    prediction = pipe.predict(X_test)\n    print(f'Model Name:{model}')\n    print(accuracy_score(y_test,prediction))\n    plot_roc_curve(pipe,X_test,y_test)","a7a35be3":"select_model(rfc_model)","3668f7c7":"select_model(lg_model)","1988197c":"select_model(svc)","7bc4e0cc":"operation = [('tfidf',tfidf),('svc',svc)]\npipe = Pipeline(operation)","0e8c5215":"pipe.fit(X,y)","db7f44ab":"prediction = pipe.predict(X)","db3ff8b5":"accuracy_score(y,prediction)","4ace10e8":"df_test = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","e0db37bd":"df_test.head()","d378dfdf":"df_test['text'] = df_test['text'].apply(remove_punctuation)","4b1304b1":"df_test['text'].isnull().sum()","7b6a9481":"df_test['text'].str.isspace().sum()","eb82acb5":"df_test['target'] = pipe.predict(df_test['text'])","653e06d3":"df_test.head()","301c1494":"df_test[['id','target']].to_csv('final_submission_tweets_prediction.csv',index=False)","34ed1d58":"<h4><b>Train test split of the training data<\/b><\/h4>","93a28230":"<h4><b>To remove punctuation from the text<\/b><\/h4>","cf1c42b6":"<h4><b> Logistic regression and the support vector classifier AUC is same but accuracy score of the support vector machine classifier is slightly higher than the Logistic regression classifier<\/b><h4>","a13bb73c":"<h4><b>Creating function to check multiple models<\/b><\/h4>","94edee3a":"<h2>Sentiment analysis of the Disaster tweets<\/h2>","f3036d9b":"<h4><b>Making the prediction for the test dataset<\/b><\/h4>","62f52b2e":"<h4><b> Top 15 words related to the non disaster tweets<\/b><\/h4>","2f41f171":"<h4><b>Import required machine learning models and metrics to evalutae the model<\/b><\/h4>","dab51737":"<h4><b>Goal-: To predict the whether twits are disaster tweets or not.<\/b><\/h4> \n<ul>\n    <li>0 - Not Disaster<\/li>\n    <li>1 - Disaster<\/li>\n<\/ul>\n\n<h3>Columns<\/h3>\n<ul>\n<li>id - a unique identifier for each tweet<\/li>\n<li>text - the text of the tweet<\/li>\n<li>location - the location the tweet was sent from (may be blank)<\/li>\n<li>keyword - a particular keyword from the tweet (may be blank)<\/li>\n<li>target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)<\/li>\n<\/ul>","d4126313":"<h4><b> Top 15 words related to the disaster tweets<\/b><\/h4>","fc14cb89":"<h4><b>Drop the keyword and location columns<\/b><\/h4>","1e28fa1e":"<h4><b>Import required library<\/b><\/h4>","7315065b":"<h4><b>Feature extraction from the text<\/b><\/h4>","a41f8ecc":"**Random Forest classifire**","47490a3a":"**Support vector machine classifier**","a2a21763":"**Make the final model using whole training data to predict the test data using support vector machine classifier model**","27ca323c":"<h4><b>Making prediction for the test data set<\/b><\/h4>","45440771":"**Logistic Regression Model**"}}