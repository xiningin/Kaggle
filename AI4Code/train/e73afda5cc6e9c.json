{"cell_type":{"d577a529":"code","e258f7ab":"code","c394b195":"code","ccc73801":"code","ab922632":"code","1ca8913f":"code","84dcd23f":"code","1f5044d4":"code","fbf6c780":"code","99165060":"code","43641264":"code","92ec5aaa":"code","9d0eb84e":"code","1ee68956":"code","122a52e1":"code","325f7fd4":"code","2e86b283":"code","0dee2026":"code","73891699":"code","5e4c4482":"code","0f1976f2":"code","30bb4559":"code","b0d066ae":"code","31206f02":"code","a19b6277":"code","000caab6":"code","a0308a34":"code","f0471c01":"code","8541ce54":"code","c4c96507":"code","85c07554":"code","b1d487f8":"code","bd12b782":"code","ae20fc2a":"code","8a3b2720":"code","70edbaea":"code","10519c66":"code","bcffe088":"code","d131b7d0":"code","b8206fe1":"code","dcc0b9ce":"code","9c547594":"code","d27addd9":"code","b69f4e49":"code","be198b5c":"code","7f30d85b":"markdown","d6aee611":"markdown","f9fc4277":"markdown","b53b9b59":"markdown","19d7cf95":"markdown","720930a4":"markdown","9c690dea":"markdown","db2c30fc":"markdown","d1bf3dac":"markdown","e362b088":"markdown","06bf0206":"markdown","b80ca5df":"markdown","4ce925b7":"markdown","7e4e23ad":"markdown","fb7dc27f":"markdown","e028c09f":"markdown","1577f24a":"markdown","8ef8cea3":"markdown","d3b0846c":"markdown","273f447b":"markdown","2ea6fc5d":"markdown","bc6c08ba":"markdown","2bd93654":"markdown","7e70d39c":"markdown","d23ee836":"markdown","41bb294b":"markdown","68e73864":"markdown","4710a28a":"markdown","d396c225":"markdown","9edb7da9":"markdown","1ed27cb2":"markdown","b6417d69":"markdown","e06ac992":"markdown","92630d56":"markdown"},"source":{"d577a529":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom datetime import timedelta\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier","e258f7ab":"employee_survey_data = pd.read_csv('..\/input\/hr-analytics-case-study\/employee_survey_data.csv')\ngeneral_data = pd.read_csv('..\/input\/hr-analytics-case-study\/general_data.csv')\nstart_time = pd.read_csv('..\/input\/hr-analytics-case-study\/in_time.csv')\nmanager_survey_data = pd.read_csv('..\/input\/hr-analytics-case-study\/manager_survey_data.csv')\nfinish_time = pd.read_csv('..\/input\/hr-analytics-case-study\/out_time.csv')","c394b195":"print(general_data.head())","ccc73801":"print(employee_survey_data.head())","ab922632":"print(manager_survey_data.head())","1ca8913f":"print(start_time.head())","84dcd23f":"print(finish_time.head())","1f5044d4":"print('General data shape:', general_data.shape)\nprint('Employee survey data shape:', employee_survey_data.shape)\nprint('Manager survey data shape:', manager_survey_data.shape)\nprint('Start working time data shape', start_time.shape)\nprint('End working time data shape:', finish_time.shape)","fbf6c780":"# Firstly, change column name Unnamed: 0 to EmployeeID in start and end time datasets.\nstart_time.rename(columns={'Unnamed: 0':'EmployeeID'}, inplace=True)\nfinish_time.rename(columns={'Unnamed: 0':'EmployeeID'}, inplace=True)\nprint('Number of unique values of EmployeeID in start time dataset:', start_time.EmployeeID.nunique())\nprint('Number of unique values of EmployeeID in finish time dataset:', finish_time.EmployeeID.nunique())","99165060":"general_data.set_index('EmployeeID', inplace=True)\nemployee_survey_data.set_index('EmployeeID', inplace=True)\nmanager_survey_data.set_index('EmployeeID', inplace=True)\nstart_time.set_index('EmployeeID', inplace=True)\nfinish_time.set_index('EmployeeID', inplace=True)","43641264":"main_data = pd.concat([general_data, employee_survey_data, manager_survey_data], axis = 1)\nprint(main_data.columns.values)","92ec5aaa":"start_time = start_time.apply(pd.to_datetime)\nfinish_time = finish_time.apply(pd.to_datetime)\nmain_data['WorkingHours'] = (finish_time - start_time).mean(axis=1)\nmain_data['WorkingHours'] = main_data['WorkingHours'] \/ np.timedelta64(1, 's')\nmain_data['Overtime'] = main_data['WorkingHours'] - main_data['StandardHours'] * 3600","9d0eb84e":"print(main_data.info())","1ee68956":"print('\\033[1mNULL VALUES\\033[0m\\n'+ str(main_data.isnull().sum()))","122a52e1":"plt.figure(figsize=(25,8))\n\nplt.subplot(1,5,1)\nmain_data['NumCompaniesWorked'].plot(kind='density', color='teal')\nplt.title('Density Plot Of Number Of \\nCompanies Worked')\n\nplt.subplot(1,5,2)\nmain_data['TotalWorkingYears'].plot(kind='density', color='blue')\nplt.title('Density Plot Of \\nTotal Working Years')\n\nplt.subplot(1,5,3)\nmain_data['EnvironmentSatisfaction'].plot(kind='density', color='teal')\nplt.title('Density Plot Of \\nEnvironment Satisfaction')\n\nplt.subplot(1,5,4)\nmain_data['JobSatisfaction'].plot(kind='density', color='blue')\nplt.title('Density Plot Of \\nJob Satisfaction')\n\nplt.subplot(1,5,5)\nmain_data['WorkLifeBalance'].plot(kind='density', color='green')\nplt.title('Density Plot Of \\nWork Life Balance')\n\nplt.show()","325f7fd4":"null = ['NumCompaniesWorked', 'TotalWorkingYears', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']\nfor i in null:\n    main_data[i] = main_data[i].fillna(main_data[i].median())","2e86b283":"print('\\033[1mNULL VALUES\\033[0m\\n'+ str(main_data.isnull().values.any()))","0dee2026":"for i in main_data:\n    print(\"data[\\'\" + i + \"\\']:\", main_data[i].nunique())","73891699":"main_data.drop(['EmployeeCount', 'StandardHours', 'Over18'], axis=1, inplace=True)","5e4c4482":"total = len(main_data['Attrition'])\nAttrition = pd.DataFrame(main_data['Attrition'].value_counts())\nprint(Attrition.T)\nplt.figure(figsize=(6,4))\nplt.style.use('ggplot')\nax = Attrition.plot(kind='bar', color='pink')\nplt.title('Attrition', fontweight='bold', fontsize=15)\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width()\/2., height + 10 , '{:.0%}'.format(height\/total))\nplt.show()","0f1976f2":"main_data['AgeGroups'] = pd.cut(main_data['Age'], range(10, 70, 10))","30bb4559":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,3,1)\nsns.distplot(main_data['Age'], color='green')\nplt.xlim(10,70)\nplt.title('Age Distribution')\n\nplt.subplot(1,3,2)\nmain_data['MaritalStatus'].value_counts().plot(kind='bar', color='lightblue')\nplt.xticks(rotation=0)\nplt.title('Marital Status Distribution')\n\nplt.subplot(1,3,3)\nmain_data['Gender'].value_counts().plot(kind='bar', color='lightpink')\nplt.xticks(rotation=0)\nplt.title('Gender Distribution')\n\nplt.show()","b0d066ae":"plt.figure(figsize=(16,10))\n\nplt.subplot(2,3,4)\nmain_data['Department'].value_counts().plot(kind='bar', color='lightblue')\nplt.xticks(rotation=0)\nplt.title('Department Distribution')\n\nplt.subplot(2,3,5)\nmain_data['JobRole'].value_counts().plot(kind='bar', color='lightblue')\nplt.title('Job Role Distribution')\n\nplt.subplot(2,3,6)\nmain_data['EducationField'].value_counts().plot(kind='bar', color='lightblue')\nplt.title('Education Field Distribution')\n\nplt.show()","31206f02":"graphs = ['AgeGroups', 'MaritalStatus', 'Gender', 'Department', 'JobRole', 'EducationField']\nplt.figure(figsize=(20,15))\nfor index, item in enumerate(graphs):\n    plt.subplot(2,3,index+1)\n    ax = sns.countplot(x=item, hue='Attrition', data=main_data, palette='husl')\n    if index+1>3: plt.xticks(rotation=90)\n    index = int(len(ax.patches)\/2)\n    for left,right in zip(ax.patches[:index], ax.patches[index:]):\n        left_height = left.get_height()\n        right_height = right.get_height()\n        total = left_height + right_height\n        ax.text(left.get_x() + left.get_width()\/2., left_height + 20, '{:.0%}'.format(left_height\/total), ha=\"center\")\n        ax.text(right.get_x() + right.get_width()\/2., right_height + 20, '{:.0%}'.format(right_height\/total), ha=\"center\")\nplt.show()  ","a19b6277":"main_data = main_data.drop('AgeGroups', axis=1)","000caab6":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot(main_data[main_data['Attrition']=='Yes']['MonthlyIncome'], color='darkblue')\nplt.title('Distribution of Monthly Income for Attrition (YES)', fontsize=12, fontweight='bold')\n\nplt.subplot(1,2,2)\nsns.distplot(main_data[main_data['Attrition']=='No']['MonthlyIncome'], color='darkred')\nplt.title('Distribution of Monthly Income for Attrition (NO)', fontsize=12, fontweight='bold')\n\nplt.show()","a0308a34":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot(main_data[main_data['Attrition']=='Yes']['PercentSalaryHike'], color='darkgreen')\nplt.title('Distribution of Percent Salary Hike for Attrition (YES)', fontsize=12, fontweight='bold')\n\nplt.subplot(1,2,2)\nsns.distplot(main_data[main_data['Attrition']=='No']['PercentSalaryHike'], color='darkorange')\nplt.title('Distribution of Percent Salary Hike for Attrition (NO)', fontsize=12, fontweight='bold')\n\nplt.show()","f0471c01":"plt.figure(figsize=(16,6))\n\nsns.kdeplot(main_data['YearsSinceLastPromotion'][main_data.Attrition=='Yes'], color='blue', shade=True)\nsns.kdeplot(main_data['YearsSinceLastPromotion'][main_data.Attrition=='No'], color='red', shade=True)\nplt.title('Distribution of Years Since Last Promotion', fontsize=15)\nplt.legend(['Attrition (YES)', 'Attrition (NO)'])\nplt.xlabel('Years', fontsize=12)\n\nplt.show()","8541ce54":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.kdeplot(main_data['YearsAtCompany'][main_data.Attrition=='Yes'], shade=True, color='green')\nsns.kdeplot(main_data['YearsAtCompany'][main_data.Attrition=='No'], shade=True, color='red')\nplt.title('Distribution Of Years At Company', fontsize=13)\nplt.ylabel('Distribution')\nplt.legend(['Attrition (YES)','Attrition (NO)'])\n\nplt.subplot(1,2,2)\nsns.kdeplot(main_data['YearsWithCurrManager'][main_data.Attrition=='Yes'], shade=True, color='green')\nsns.kdeplot(main_data['YearsWithCurrManager'][main_data.Attrition=='No'], shade=True, color='red')\nplt.title('Distribution of Years With Current Manager', fontsize=13)\nplt.legend(['Attrition (YES)','Attrition (NO)'])\n\n\nplt.show()","c4c96507":"plt.figure(figsize=(16,6))\n\nplt.subplot(1,3,1)\nsns.violinplot(data=main_data, x='Attrition', y='JobSatisfaction', palette='Blues')\nplt.title('Job Satisfaction')\n\nplt.subplot(1,3,2)\nsns.violinplot(data=main_data, x='Attrition', y='EnvironmentSatisfaction', palette='Blues')\nplt.title('Environment Satisfaction')\n\nplt.subplot(1,3,3)\nsns.violinplot(data=main_data, x='Attrition', y='WorkLifeBalance', palette='Blues')\nplt.title('Work Life Balance')\n\nplt.show()","85c07554":"numerical_columns = main_data.select_dtypes(exclude='object').columns\nnumerical_data = main_data[numerical_columns]\ncategorical_columns = main_data.select_dtypes(include='object').columns\ncategorical_data = main_data[categorical_columns]","b1d487f8":"plt.figure(figsize=(20,15))\nfor index, item in enumerate(numerical_columns, 1):\n    plt.subplot(5, 4, index)\n    sns.boxplot(main_data[item])\nplt.show() ","bd12b782":"columns = ['MonthlyIncome', 'NumCompaniesWorked', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', \n           'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'PerformanceRating', 'WorkingHours']\nmain_data[columns] = (main_data[columns] + 1).transform(np.log)","ae20fc2a":"dummies = pd.get_dummies(main_data[categorical_columns], drop_first = True)\nmain_data = pd.concat([main_data, dummies], axis = 1)\nmain_data.drop(categorical_columns, axis = 1, inplace = True)","8a3b2720":"X = main_data.drop('Attrition_Yes', axis=1)\ny = main_data['Attrition_Yes']","70edbaea":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ncolumns = X.columns\nmain_data[columns] = scaler.fit_transform(main_data[columns])","10519c66":"plt.rcParams['figure.figsize'] = [35,30]\nsns.heatmap(main_data.corr(), cmap='PuBu', annot=True, linewidths=.5, annot_kws={'size':8})\nplt.title('Correlation Matrix', fontweight='bold', fontsize='15')\nplt.show()","bcffe088":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"variables\"] = X.columns\nvif['vif'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nfor index,column in enumerate(X.columns):\n    print(index, column, vif['vif'][index])\n    if vif['vif'][index]>5:\n        vif = vif.drop([index], axis=0)","d131b7d0":"print(vif)","b8206fe1":"columns = list(vif['variables'])\ndata = main_data[columns]\ndata = pd.concat([data, main_data['Attrition_Yes']], axis=1)","dcc0b9ce":"from sklearn.model_selection import train_test_split\nX = data.drop('Attrition_Yes', axis=1)\ny = data ['Attrition_Yes']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)","9c547594":"lr = LogisticRegression(solver='liblinear', random_state=42)\nlr.fit(X_train, y_train)\nlrpred = lr.predict(X_test)","d27addd9":"print('Accuracy score of Logistic Regression:' + str(accuracy_score(y_test,lrpred)))\nprint('Confusion Matrix\\n' + str(confusion_matrix(y_test, lrpred)))","b69f4e49":"plt.figure(figsize=(12,5))\n\nlrprob = lr.predict_proba(X_test)\nlr_pred = lrprob[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, lr_pred)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('Logistic Regression ROC', fontsize=15)\nplt.ylabel('True Positive Rate', fontsize=15)\nplt.xlabel('False Positive Rate', fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 14})\n\nplt.show()","be198b5c":"from sklearn.metrics import classification_report\nprint('Logistic Regression\\n',classification_report(y_test, lrpred))","7f30d85b":"Other values in these columns are not normally distributed. It's better to use median value to fill the null values.","d6aee611":"Let's set the column named EmployeeID in all files. We are getting ready for merging.","f9fc4277":"We don't have any null values left in our dataset.","b53b9b59":"Percent Salary Hike of employees who want to leave the company is lower.","19d7cf95":"### Converting to numerical variables","720930a4":"It seems there are some null values in our dataset. The values under Non_null column are not all 4410.","9c690dea":"Logistic regression is sensitive to outliers. I will check for outliers in the dataset.","db2c30fc":"### Checking Multicollinearity","d1bf3dac":"* Department : There are many people working in R&D department. The number of people works in HR is the lowest.\n* Job Role: There are so many sales executive in the company. Sales department mostly include Sales Executives.\n* Education Field: There are so many people in the company who studied Life Sciences.\n","e362b088":"We need to calculate total working hours as below from workin times. After that, we can calculate overtime as well. Finally, we can merge all files by adding WorkingHours and Overtime columns to our main_data.","06bf0206":"### Outliers","b80ca5df":"I will convert categorical variables to numerical variables. Categorical variables are not ordinal. For this reason, I will apply OneHotEncoder.","4ce925b7":"There are 4410 employee records in all of the datasets. We will combine them to get more accurate results.","7e4e23ad":"There are outliers in the dataset. I will apply log transformation to these variables. Log transformation de-emphasizes outliers and allows us to potentially obtain a bell-shaped distribution.","fb7dc27f":"# 4. Data Preparation","e028c09f":"16% of employess are not satisfied. It's not that small number for the company. ","1577f24a":"Employees who want to quit their jobs are not quite satisfied with their jobs. Work life balance is lower.","8ef8cea3":"The income of employees who want to leave the company is lower.","d3b0846c":"Firstly, it is better to see attriton level in our dataset. The number of people who want to leave the company, and the number of people who are satisfied to work.","273f447b":"Multicollinearity occurs when the model includes multiple factors that are correlated to each other. Logistic regression requires there to be little or no multicollinearity among the independent variables. This means that the independent variables should not be too highly correlated with each other.\n\nI will check the correlation between the variables visually and with the VIF value. I will drop the variables with VIF above 5.","2ea6fc5d":"# **1. Reading And Understanding The Data**","bc6c08ba":"# 5. Building The Model","2bd93654":"* Age : Age group of employees is usually 30 - 40.\n* Marital Status : The number of married people is highest, while the divorced is lowest.\n* Gender : Male population is higher than female.","7e70d39c":"If employees spend more time in the company, attrition rate is lower. People don't want to leave the company after spending long time in the same company.","d23ee836":"# 2. Cleaning The Data","41bb294b":"Firstly, we will combine the files of general_data, employee_survey_data, manager_survey_data. We need to change time files before merging.","68e73864":"# 3. Exploratory Data Analysis","4710a28a":"Logistic Regression predicted 146 False Negative values. 146 people are actually want to quit their jobs, but the model says they want to stay. This is quite important, because we don't want to lose them in the company. Other models can be used on this dataset.","d396c225":"Let's check the number of unique values in our dataset. ","9edb7da9":"We need to handle the null values in our dataset. Firstly, let's visulize them, so that we can decide to fill them either with median or mean etc..","1ed27cb2":"There are columns named  Unnamed: 0  in start_time and finish_time files. We will convert to EmployeeID for clearity, because we will combine the files later.","b6417d69":"The number of unique values in the columns of EmployeeCount, Over18, StandardHours is just 1. All values are same. Let's remove these columns.","e06ac992":"# 6. Evaluating The Model","92630d56":"These graphs show the Attrition level by Age, Marital Status, Gender, Department, Job Role, Education Field.\n\nAge Group : 23% of 20-30 age group wants to leave the company.\n\nMarital Status : 26% od single people wants to leave the company.\n\nGender : 17% of male employess wants to leave the company.\n\nDepartment : 16% of R&D department wants to leave the company.\n\nJob Role: 24% of Research Directors wants to leave the company.\n\nEducation Field : 41% of Human Resources wants to leave the company. This is very high.\n"}}