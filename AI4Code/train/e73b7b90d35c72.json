{"cell_type":{"7ebb9699":"code","cb6603ab":"code","373fae72":"code","cbcc6690":"code","3da73cc2":"code","e24898b7":"code","103997f5":"code","22593142":"code","fa42f2ff":"code","a15c4bd5":"code","00091aba":"code","13d4c617":"code","964d73a7":"code","68b1ae4e":"code","9073090b":"code","03ea7452":"code","d04aaf25":"markdown","038b1a32":"markdown","58432b5c":"markdown","c4d800d9":"markdown","e9b58c2a":"markdown","39329d34":"markdown","1b2c2061":"markdown"},"source":{"7ebb9699":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport re\nfrom sklearn import preprocessing\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","cb6603ab":"train.sample(5)","373fae72":"test.sample(5)","cbcc6690":"print(\"Train\")\nfor col in train:\n    print(col, \"-\", np.sum(train[col].isna()))\n    \nprint(\"\\nTest\")\nfor col in test:\n    print(col, \"-\", np.sum(test[col].isna()))","3da73cc2":"train.Cabin[train.Cabin.notnull()].sample(10)","e24898b7":"# Get first character of cabin\ncCabin = train.Cabin.fillna(\"X\")\nfirstChar = cCabin.astype(str).str[0]\n\n# Determine if cabin is correlated with the number of dead\nsurvival = train.Survived\ncabinSurvived = pd.concat([firstChar, survival], axis=1)\ncabinTypes = cabinSurvived.Cabin.unique()\n\nlabels = []\nsurvived = []\ntotals = []\nfor cabin in cabinTypes:\n    mask = cabinSurvived.Cabin == cabin\n    labels.append(cabin)\n    survived.append(cabinSurvived.Survived[mask].sum())\n    totals.append(cabinSurvived.Survived[mask].count())\n    \n\nplt.bar(labels, totals, zorder=1)\nplt.bar(labels, survived, zorder=2)\nplt.title(\"Survived Over Total People Given Cabin\")\nplt.show()\nplt.figure()\nplt.bar(labels[1:], totals[1:], zorder=1)\nplt.bar(labels[1:], survived[1:], zorder=2)\nplt.show()","103997f5":"# Get first character of cabin\nnnAge = train.Age.notnull()\ncAge = train.Age[nnAge]\n\n# Determine if cabin is correlated with the number of dead\nsurvival = train.Survived[nnAge]\ncAgeSurvived = pd.concat([cAge, survival], axis=1)\nageTypes = cAgeSurvived.Age.unique()\nlabels = []\nsurvived = []\ntotals = []\nfor age in ageTypes:\n    mask = cAgeSurvived.Age == age\n    labels.append(age)\n    survived.append(cAgeSurvived.Survived[mask].sum())\n    totals.append(cAgeSurvived.Survived[mask].count())\n    \n\nplt.bar(labels, totals, zorder=1)\nplt.bar(labels, survived, zorder=2)\nplt.title(\"Survived Over Total People Given Age\")\nplt.show()","22593142":"def convert_titles(data):\n    title = data['Title']\n    if title in ['Don', 'Jonkheer', 'Rev']:\n        return 'Mr'\n    if title in ['Major', 'Capt', 'Col']:\n        return 'Military'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if data['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\n    \ndef get_normalized_col(col):\n    x = col.values\n    scaler = preprocessing.MinMaxScaler()\n    x_scaled = scaler.fit_transform(x)\n    return pd.DataFrame(x_scaled)\n\n# Modify provided data: all NaN are X cabins\ndef modify_data(data):\n    # Create new column 'Title'\n    data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    data['Title'] = data.apply(convert_titles, axis=1)\n    data['Title'] = pd.Categorical(data.Title).codes\n    \n    # Modify Embarked\/Sex to be codes\n    data.Embarked = pd.Categorical(data.Embarked).codes\n    data.Sex = pd.Categorical(data.Sex).codes\n    \n    # Convert SibSp and Parch into Family Parameter\n    data['Family'] = data['SibSp'] + data['Parch']\n\n    # Drop all non useful columns\n    data = data.drop(columns=['Ticket', 'Parch', 'SibSp', 'Name', 'PassengerId', 'Cabin'])\n    \n    # Need to fix Age NaN, using Pclass as age classification.\n    for title in data['Title'].unique():\n        ageAvg = data.Age[data.Age.notnull()][data['Title'] == title].sum() \/ (data['Title'] == title).sum()\n        data.loc[data.Age.isna() & (data['Title'] == title), 'Age'] = ageAvg\n        \n    # Scale integer values       \n    data.loc[data.Fare.isna(), 'Fare'] = np.average(data.loc[data.Fare.notnull(), 'Fare'])\n    \n    # Add new age class column\n    data['AgeClass'] = data['Age'] * data['Pclass']\n    \n    # Normalize larger numbers\n    data['AgeClass'] = (data['AgeClass'] - data['AgeClass'].min()) \/ (data['AgeClass'].max() - data['AgeClass'].min())\n    data['Age'] = (data['Age'] - data['Age'].min()) \/ (data['Age'].max() - data['Age'].min())\n    data['Fare'] = (data['Fare'] - data['Fare'].min()) \/ (data['Fare'].max() - data['Fare'].min())\n    data['Family'] = (data['Family'] - data['Family'].min()) \/ (data['Family'].max() - data['Family'].min())\n    return data\n    \ntrain_set = modify_data(train)\ntest_set = modify_data(test)\n","fa42f2ff":"train_set","a15c4bd5":"# Check for isNaN in trainset\nprint(\"Train Set\")\nfor col in train_set:\n    print(col, \"-\", np.sum(train_set[col].isna()))\n\nprint(\"\\nTest Set\")\nfor col in test_set:\n    print(col, \"-\", np.sum(test_set[col].isna()))","00091aba":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras import optimizers\n\nfrom sklearn import model_selection, linear_model, metrics\n\nkeras.backend.clear_session()\n\nxset = np.array(train_set.values.tolist())[:, 1:]\nyset = np.array(train_set.values.tolist())[:, :1]\nsubmit_x = np.array(test_set)\n\n\nx_train, x_test, y_train, y_test = model_selection.train_test_split(xset, yset)#, random_state=0)\ninput_shape = x_train[0].shape\n\nmodel = Sequential([Dense(8, activation='relu', input_shape=input_shape), BatchNormalization(), Dense(5, activation='relu'), Dense(2, activation='sigmoid')])\nopt = optimizers.Adam()\n\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\nmodel.build()\nmodel.summary()","13d4c617":"model.fit(x_train, to_categorical(y_train), epochs=15)","964d73a7":"y_pred = model.predict(x_test)\nprint(\"Accuracy score:\", metrics.accuracy_score(y_test, np.argmax(y_pred, axis=-1)))","68b1ae4e":"predictions = np.argmax(model.predict(submit_x), axis=-1)\n\npredicted_data = {'PassengerId': test.PassengerId, 'Survived': pd.Series(predictions)}\ndata = pd.DataFrame(predicted_data, columns = ['PassengerId', 'Survived'])","9073090b":"data","03ea7452":"data.to_csv('submission.csv', index=False)","d04aaf25":"# Data Portion","038b1a32":"## Data Notes\n* Name is formatted Last Name, Title. (Firstname Middlename)\n* Age has NaN\n* Cabin has NaN\n* Embarked has NaN\n\nNeed to determine if Cabin, Age and Embarked have significance","58432b5c":"# Submission Portion","c4d800d9":"## Data Modifications\n* Converted all categorical data to be integers.\n* Missing fair (1) is set to average.\n* Create Title which represents the name title.\n* Remove Ticket, Parch, SibSp, Name, Cabin and PassengerId fields.\n* Added interaction term ageclass.\n* Normalized family, age, fare and ageclass.","e9b58c2a":"# Supervised Learning Portion\nModel is a Dense 8 -> ReLU -> Batchnorm -> Dense 5 -> ReLU -> Dense 2 -> Sigmoid\n\nOptimizer is Adam with binary crossentropy loss\n\nEpochs is 15. Setting to 300 was extreme and lead to overfitting. 15 seemed to achieve great results.","39329d34":"There is a higher total of those who survived for different cabins. T has zero survivers, C, A and G appear balanced, and E, B, F, D have a slightly higher survival ratio, NaN has a very low survival rate. I decided to keep the cabin on my first attempt, but after examining the difference without cabin the model has a higher predicted accuracy.","1b2c2061":"Age also has some correlation to the survival rate. Going to use age as well. As embark location has minimal missing data, going to use it as well."}}