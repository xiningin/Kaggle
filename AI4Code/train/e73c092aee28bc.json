{"cell_type":{"05bb0438":"code","f7e96cb6":"code","de456e92":"code","2884cf0a":"code","98252715":"code","a9541eb5":"code","e88aa6cd":"code","feb41fc9":"code","9c08f174":"code","d7f1115f":"code","6ed0d850":"code","3bf98eae":"code","768cb73b":"code","2ee7b055":"code","ad38e915":"code","9fbfcc78":"markdown","0520cc70":"markdown","661be610":"markdown","43fad49b":"markdown","a897ebb3":"markdown"},"source":{"05bb0438":"#import important libraries for our work\nimport requests \nfrom bs4 import BeautifulSoup \nfrom tabulate import tabulate \nimport os \nimport numpy as np \nimport pandas as pd\nimport datetime","f7e96cb6":"today=datetime.date.today().strftime(\"%m-%d-%Y\")\ndata_date=datetime.date.today()-datetime.timedelta(days=1)\nprint(\"Today is {}\".format(today))\ndata_date=data_date.strftime(\"%m-%d-%Y\")\n","de456e92":"url= 'https:\/\/www.worldometers.info\/coronavirus\/'","2884cf0a":"# get web data\nreq = requests.get(url)\nresponse = req.content\n# parse web data\nsoup = BeautifulSoup(response, \"html.parser\")\nsoup","98252715":"# find the table\n#table is in the last of the page\n\nthead= soup.find_all('thead')[-1]\nprint(thead)","a9541eb5":"# get all rows in thead\nhead = thead.find_all('tr')\nhead","e88aa6cd":"# get the table data content\ntbody = soup.find_all('tbody')[0]\ntbody","feb41fc9":"body = tbody.find_all('tr')\nbody","9c08f174":"# get the table contents\n\n# container for  column title\nhead_rows = []\n\n\n# loop through the head and append each row to head\nfor tr in head:\n    td = tr.find_all(['th', 'td'])\n    row = [i.text for i in td]\n    head_rows.append(row)\nprint(head_rows[0])","d7f1115f":"# container for contents\nbody_rows = []\n\n# loop through the body and append each row to body\nfor tr in body:\n    td = tr.find_all(['th', 'td'])\n    row = [i.text for i in td]\n    body_rows.append(row)\nprint(body_rows)","6ed0d850":"df_bs = pd.DataFrame(body_rows[:len(body_rows)-6],columns=head_rows[0]) \ndf_bs.head()","3bf98eae":"# continentdata\ncols=['Continent','TotalCases', 'NewCases', 'TotalDeaths', 'NewDeaths', 'TotalRecovered',\n       'NewRecovered', 'ActiveCases', 'Serious,Critical', ]\n\ncontinent_data = df_bs.iloc[:8, :-3].reset_index(drop=True)\n\n\n# drop unwanted columns\ncontinent_data = continent_data.drop('#', axis=1)\n#rearrange Columns Sequence\ncontinent_data = continent_data[cols]\ncontinent_data['Continent'].loc[6]=\"Not Assigned\"\ncontinent_data['Continent'].loc[7]=\"World\"\n\n\ncontinent_data","768cb73b":"# drop first 8 nrows\nworld_data = df_bs.iloc[8:, :-3].reset_index(drop=True)\n\n# drop unwanted columns\nworld_data = world_data.drop('#', axis=1)\nworld_data.rename(columns={'Country,Other':\"Country\",'Serious,Critical':'Serious','Tests\/\\n1M pop\\n':'Tests\/1M pop'},inplace= True)\n\n# first few rows\nworld_data.head()","2ee7b055":"#save the data\nworld_data.to_csv(str(data_date)+\"world_data.csv\",index = False)\nworld_data.head()","ad38e915":"# check the saved data \ndata=pd.read_csv(str(data_date)+\"world_data.csv\")\ndata","9fbfcc78":"###  Web Scrapping  Covid-19 data ","0520cc70":"### Thanks for going through in this notebook. Your suggestions are requested in comments .If you feel this notebook helpful and useful, please upvote the notebook.","661be610":"### Web Scrapping \nWeb Scraping is a technique employed to extract large amounts of data from websites whereby the data is extracted and saved to a local file in the local machine or to a database in table format or wherever you want.","43fad49b":"## Data Source\n\n\n'https:\/\/www.worldometers.info\/coronavirus\/'","a897ebb3":"## Data Source\n\n'https:\/\/www.worldometers.info\/coronavirus\/'\n\n"}}