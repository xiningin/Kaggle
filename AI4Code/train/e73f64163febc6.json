{"cell_type":{"60a0b4ee":"code","12e10ce6":"code","8c8d432f":"code","aaeedfdc":"code","ba794148":"code","8d6175de":"code","de7dec6e":"code","9d183676":"code","3292a07b":"code","c7a52639":"code","70b4e311":"code","91e6f911":"code","31791ab1":"code","2446ffde":"code","168d537c":"code","fd8ea13d":"code","63e8fc1e":"code","947dbf9c":"code","84ab4c45":"code","cce60f34":"markdown","6cdfcbb4":"markdown","833221a8":"markdown","ef20b172":"markdown","5b242506":"markdown","22d3482a":"markdown","1ee08e37":"markdown","f8cb03fb":"markdown","0a6387cd":"markdown","a619927d":"markdown","5e442893":"markdown","311fb736":"markdown","93000ebf":"markdown","a8f1e23b":"markdown","11cf879a":"markdown","611efd6d":"markdown"},"source":{"60a0b4ee":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = FutureWarning)\n\nimport itertools\nimport math\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_predict, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.multiclass import unique_labels\n\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tnrange","12e10ce6":"# Read training and test files\nX_train = pd.read_csv('..\/input\/learn-together\/train.csv', index_col = 'Id', engine = 'python')\nX_test = pd.read_csv('..\/input\/learn-together\/test.csv', index_col = 'Id', engine = 'python')\n\n# Define the dependent variable \ny_train = X_train['Cover_Type'].copy()\n\n# Define a training set\nX_train = X_train.drop(['Cover_Type'], axis = 'columns')","8c8d432f":"class_names = np.array([None, 'Spruce\/Fir','Lodgepole Pine', 'Ponderosa Pine', 'Cottonwood\/Willow', 'Aspen', 'Douglas-fir', 'Krummholz'])\nclass_names","aaeedfdc":"permutation = list(itertools.permutations(list(range(1,8))))","ba794148":"def get_permuted_class_names(i):\n    permuted_class_names = np.copy(class_names)\n    for j in range(7):\n        permuted_class_names[j + 1] = class_names[permutation[i][j]]\n    return permuted_class_names","8d6175de":"model = RandomForestClassifier(random_state = 1)","de7dec6e":"def get_accuracy(X, y):\n    scores = cross_val_score(model, X, y, scoring = 'accuracy', n_jobs = -1)\n    return np.mean(scores)","9d183676":"def get_prediction(X, y):\n    y_pred = cross_val_predict(model, X, y, n_jobs = -1)\n    return y_pred","3292a07b":"accuracy = get_accuracy(X_train, y_train)\nprint('Accuracy: {:.4f}'.format(accuracy))","c7a52639":"def plot_confusion_matrix(y, y_pred):\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y, y_pred)\n    # Only use the labels that appear in the data\n    classes = class_names[unique_labels(y, y_pred)]\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title='Confusion matrix',\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n\n    np.set_printoptions(precision=2)\n\n    # plt.figure(figsize=(24, 24))\n    plt.show()","70b4e311":"results = pd.DataFrame(columns = ['Permutation', 'Accuracy'])\n\nfor i in tnrange(math.factorial(7)):\n    accuracy = get_accuracy(X_train, y_train.replace(permutation[0], permutation[i]))\n    results = results.append({\n        'Permutation': permutation[i],\n        'Accuracy': accuracy  \n    }, ignore_index = True)\n\nresults.to_csv('results.csv', index = True)\nprint(results.describe())","91e6f911":"print('Difference in accuracy from worst to best permutation: {:.2%}'.format(results['Accuracy'].max() - results['Accuracy'].min()))\nprint('Difference in accuracy from initial to best permutation: {:.2%}'.format(results['Accuracy'].max() - results.iloc[0]['Accuracy']))","31791ab1":"plt.hist(results[\"Accuracy\"], 32, density=True, alpha=0.5)\n\nplt.legend(loc='upper right')\nplt.xlabel('Smarts')\nplt.ylabel('Probability')\nplt.title('Histogram of IQ')\nplt.grid(True)\nplt.show()","2446ffde":"nlargest_accuracy = results.nlargest(10, ['Accuracy'])\nlargest_accuracy = nlargest_accuracy.iloc[0].name\nnlargest_accuracy","168d537c":"nsmallest_accuracy = results.nsmallest(10, ['Accuracy'])\nsmallest_accuracy = nsmallest_accuracy.iloc[0].name\nnsmallest_accuracy","fd8ea13d":"y_pred = get_prediction(X_train, y_train.replace(permutation[0], permutation[largest_accuracy]))\nplot_confusion_matrix(y_train, pd.Series(y_pred).replace(permutation[largest_accuracy], permutation[0]))","63e8fc1e":"y_pred = get_prediction(X_train, y_train.replace(permutation[0], permutation[smallest_accuracy]))\nplot_confusion_matrix(y_train, pd.Series(y_pred).replace(permutation[smallest_accuracy], permutation[0]))","947dbf9c":"# Get model with the permutation with the largest_accuracy\naccuracy = get_accuracy(X_train, y_train.replace(permutation[0], permutation[largest_accuracy]))\nprint(accuracy)\n\n# Predict with test data\nmodel.fit(X_train, y_train.replace(permutation[0], permutation[largest_accuracy]))\ny_test_pred = pd.Series(model.predict(X_test))\n\n# Transform back the forest type\ny_test_pred = y_test_pred.replace(permutation[largest_accuracy], permutation[0])","84ab4c45":"output = pd.DataFrame({'ID': X_test.index,\n                       'Cover_Type': y_test_pred})\n\noutput.to_csv('submission.csv', index=False)","cce60f34":"## Submit","6cdfcbb4":"# Calculate accuracy for all permutations","833221a8":"## Get permuted class names","ef20b172":"## Confusion matrix for the smallest accuracy","5b242506":"## Show the top smallest and largests Accuracy","22d3482a":"# Introduction\n\nIs the order of the cover type categories influencing the model accuracy?\n\nIs relevant this influence?\n\nThis kernel pretends to answer these two questions.\nIn order to do that is to use the Random Forest Classifier\nwith all the variables and with all the default values.","1ee08e37":"## Confusion matrix for the largest accuracy","f8cb03fb":"## Define class names","0a6387cd":"> ## Cross validation function\n","a619927d":"## Get accuracy for the original forest type order","5e442893":"## Create permutations","311fb736":"# Submit","93000ebf":"## Confusion matrix function","a8f1e23b":"## Prepare selected model and predict test","11cf879a":"# Conclusions\n\nThe order of the categorical dependent variable influences a bit the accuracy of the prediction, about 1 %.\n\nPermutation 0 submission (original order) got a public leaderboard score of 0.71571, while the *best* permutation got only 0.70268.\n\nGetting the best accuracy in the train \/ validation data makes the model very good for these subsample of the 2.6 % of the total, but not such good result in the test data. The order that is the best for the train may not even be good for the test. Choosing the best permutation overfits.","611efd6d":"# Prepare data and functions\n## Read data"}}