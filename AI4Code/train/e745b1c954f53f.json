{"cell_type":{"d346f89a":"code","9913e011":"code","eb18354a":"code","97ba6048":"code","5a1d10bc":"code","18f1d41e":"code","2b65665b":"code","c98488e8":"code","594fc6ad":"code","2a2d409f":"code","4774941d":"code","6bf79f55":"code","4e3c0692":"code","179b889e":"code","64b1dd88":"code","1ee7285b":"code","3b111336":"code","89000c06":"code","8b78f3b6":"code","78579a7e":"code","83e3e01e":"code","965cbcb1":"code","9f231da2":"code","bc68235c":"code","b7944721":"code","4fd82f0b":"code","541c60d9":"code","a869fae4":"code","444f0ddc":"code","e1ba376a":"code","04ac40b2":"code","55d39a3f":"code","11a85cd3":"code","8bd0960e":"code","28299c6c":"code","7aba367a":"code","fce90a16":"code","978ddb80":"code","21377203":"code","f188b6ab":"code","21abe8c7":"code","8611c145":"code","bf0bf947":"code","4de20357":"code","320f590b":"code","07465950":"code","532ef996":"code","a15bf443":"markdown","073d5108":"markdown","a4b54e86":"markdown","53c51b90":"markdown","ad9f7f09":"markdown","98071067":"markdown","7447a971":"markdown","5cd3626e":"markdown","7017b802":"markdown","6e5fdc97":"markdown","cedddfbb":"markdown","65a5276d":"markdown","18d85e8a":"markdown","fc3e087c":"markdown","3cc478be":"markdown","8cbb2d63":"markdown","0c174b72":"markdown","568835a6":"markdown","5f74b672":"markdown","cf82e83c":"markdown","3340bf9c":"markdown","099441ae":"markdown","b07e51ab":"markdown","53bca91b":"markdown","5a3efc5e":"markdown","60a3c197":"markdown","327b2aca":"markdown","983831a7":"markdown","88667c8f":"markdown","38acbc45":"markdown","a237855f":"markdown","f8120647":"markdown"},"source":{"d346f89a":"import pandas as pd\npd.set_option('display.float_format', lambda x: '%.2f' % x)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport scipy\n\n#Suppressing all warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","9913e011":"df.head()","eb18354a":"df.describe()","97ba6048":"df.isnull().sum()","5a1d10bc":"import plotly.express as px\nfig = px.pie(df, names='DEATH_EVENT', title='Distribution of Death Events in Patients',width=600, height=400)\nfig.show()","18f1d41e":"plt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\n\nx = df.iloc[:, :-1]\ny = df.iloc[:,-1]\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","2b65665b":"corr = df.corr()\nax, fig = plt.subplots(figsize=(15,15))\nsns.heatmap(corr, vmin=-1, cmap='coolwarm', annot=True)\nplt.show()","c98488e8":"corr[abs(corr['DEATH_EVENT']) > 0.1]['DEATH_EVENT']","594fc6ad":"sns.boxplot(x = df.ejection_fraction, color = 'teal')\nplt.show()","2a2d409f":"df[df.ejection_fraction > 65]","4774941d":"sns.boxplot(x = df.time, color = 'teal')","6bf79f55":"sns.boxplot(x = df.serum_creatinine, color = 'teal')","4e3c0692":"sns.boxplot(x = df.serum_sodium, color='teal')\nplt.show()","179b889e":"df[df.serum_sodium < 125]","64b1dd88":"\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n        x = df.age,\n        xbins = dict(  #Bins used for histogram\n            start=40,\n            end=95,\n            size=2\n        ),\n        marker_color='#e8ab60',\n        opacity=1\n))\n\nfig.update_layout(\n    title_text='AGE DISTRIBUTION',\n    xaxis_title_text='AGE',\n    yaxis_title_text='COUNT', \n    bargap=0.05, # gap between bars of adjacent location coordinates\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\nfig.show()","1ee7285b":"import plotly.express as px\nfig = px.histogram(df, x='age', color='DEATH_EVENT', marginal='violin', hover_data=df.columns,\n                  title='Distrubution of AGE vs DEATH_EVENT',\n                  labels={'age': \"AGE\"},\n                  template='plotly_dark',\n                  color_discrete_map={'0':'RebeccaPurple', '1':'MediumPurple'})\n\nfig.show()\n","3b111336":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df['creatinine_phosphokinase'],\n    xbins=dict( # bins used for histogram\n        start=23,\n        end=582,\n        size=15\n    ),\n    marker_color='#FE6F5E',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='CREATININE PHOSPHOKINASE DISTRIBUTION',\n    xaxis_title_text='CREATININE PHOSPHOKINASE',\n    yaxis_title_text='COUNT', \n    bargap=0.05, # gap between bars of adjacent location coordinates\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\nfig.show()","89000c06":"import plotly.express as px\n\nfig = px.histogram(df, x=\"creatinine_phosphokinase\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df.columns,\n                   title =\"Distribution of CREATININE PHOSPHOKINASE vs DEATH_EVENT\", \n                   labels={\"creatinine_phosphokinase\": \"CREATININE PHOSPHOKINASE\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","8b78f3b6":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df['ejection_fraction'],\n    xbins=dict( # bins used for histogram\n        start=14,\n        end=80,\n        size=2\n    ),\n    marker_color='#A7F432',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='EJECTION FRACTION DISTRIBUTION',\n    xaxis_title_text='EJECTION FRACTION',\n    yaxis_title_text='COUNT', \n    bargap=0.05, # gap between bars of adjacent location coordinates\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\nfig.show()","78579a7e":"import plotly.express as px\n\nfig = px.histogram(df, x=\"ejection_fraction\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df.columns,\n                   title =\"Distribution of EJECTION FRACTION vs DEATH_EVENT\", \n                   labels={\"ejection_fraction\": \"EJECTION FRACTION\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","83e3e01e":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df['platelets'],\n    xbins=dict( # bins used for histogram\n        start=25000,\n        end=300000,\n        size=5000\n    ),\n    marker_color='#50BFE6',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='PLATELETS DISTRIBUTION',\n    xaxis_title_text='PLATELETS',\n    yaxis_title_text='COUNT', \n    bargap=0.05, # gap between bars of adjacent location coordinates\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\nfig.show()","965cbcb1":"import plotly.express as px\nfig = px.histogram(df, x=\"platelets\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=df.columns,\n                   title =\"Distribution of PLATELETS vs DEATH_EVENT\", \n                   labels={\"platelets\": \"PLATELETS\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","9f231da2":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df['serum_creatinine'],\n    xbins=dict( # bins used for histogram\n        start=0.5,\n        end=9.4,\n        size=0.2\n    ),\n    marker_color='#E77200',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='SERUM CREATININE DISTRIBUTION',\n    xaxis_title_text='SERUM CREATININE',\n    yaxis_title_text='COUNT', \n    bargap=0.05, # gap between bars of adjacent location coordinates\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\nfig.show()","bc68235c":"import plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = df['serum_sodium'],\n    xbins=dict( # bins used for histogram\n        start=113,\n        end=148,\n        size=1\n    ),\n    marker_color='#AAF0D1',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='SERUM SODIUM DISTRIBUTION',\n    xaxis_title_text='SERUM SODIUM',\n    yaxis_title_text='COUNT', \n    bargap=0.05, # gap between bars of adjacent location coordinates\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\nfig.show()","b7944721":"import plotly.express as px\n\nfig = px.histogram(df, x=\"serum_sodium\", color=\"DEATH_EVENT\", marginal=\"violin\",hover_data=df.columns,\n                   title =\"Distribution of SERUM SODIUM vs DEATH_EVENT\", \n                   labels={\"serum_sodium\": \"SERUM SODIUM\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","4fd82f0b":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nd1 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"sex\"]==1)]\nd2 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"sex\"]==1)]\nd3 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"sex\"]==0)]\nd4 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"sex\"]==0)]\n\nlabel1 = [\"Male\",\"Female\"]\nlabel2 = ['Male - Survived','Male - Died', \"Female -  Survived\", \"Female - Died\"]\nvalues1 = [(len(d1)+len(d2)), (len(d3)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"GENDER\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"GENDER VS DEATH_EVENT\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\n\nfig.update_layout(\n    title_text=\"GENDER DISTRIBUTION IN THE DATASET  \\\n                   GENDER VS DEATH_EVENT\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='GENDER', x=0.19, y=0.5, font_size=15, showarrow=False),\n                 dict(text='GENDER VS DEATH_EVENT', x=0.95, y=0.5, font_size=15, showarrow=False)],\n     paper_bgcolor=\"white\")\n\nfig.show()\n","541c60d9":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nd1 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"diabetes\"]==0)]\nd2 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"diabetes\"]==1)]\nd3 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"diabetes\"]==0)]\nd4 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"diabetes\"]==1)]\n\nlabel1 = [\"No Diabetes\",\"Diabetes\"]\nlabel2 = ['No Diabetes - Survived','Diabetes - Survived', \"No Diabetes -  Died\", \"Diabetes  - Died\"]\nvalues1 = [(len(d1)+len(d3)), (len(d2)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"DIABETES\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"DIABETES VS DEATH_EVENT\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\n\nfig.update_layout(\n    title_text=\"DIABETES DISTRIBUTION IN THE DATASET \\\n                  DIABETES VS DEATH_EVENT\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='DIABETES', x=0.15, y=0.5, font_size=15, showarrow=False),\n                 dict(text='DIABETES VS DEATH_EVENT', x=0.97, y=0.5, font_size=15, showarrow=False)],\n     paper_bgcolor=\"white\")\nfig.show()\n","a869fae4":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nd1 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"anaemia\"]==0)]\nd2 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"anaemia\"]==0)]\nd3 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"anaemia\"]==1)]\nd4 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"anaemia\"]==1)]\n\nlabel1 = [\"No Anaemia\",\"Anaemia\"]\nlabel2 = ['No Anaemia - Survived','No Anaemia - Died', \"Anaemia -  Survived\", \"Anaemia  - Died\"]\nvalues1 = [(len(d1)+len(d2)), (len(d3)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"ANAEMIA\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"ANAEMIA VS DEATH_EVENT\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\n\nfig.update_layout(\n    title_text=\"ANAEMIA DISTRIBUTION IN THE DATASET \\\n                  ANAEMIA VS DEATH_EVENT\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='ANAEMIA', x=0.17, y=0.5, font_size=12, showarrow=False),\n                 dict(text='ANAEMIA VS DEATH_EVENT', x=0.9, y=0.5, font_size=12, showarrow=False)],\n     paper_bgcolor=\"white\")\nfig.show()\n","444f0ddc":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nd1 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"smoking\"]==0)]\nd2 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"smoking\"]==0)]\nd3 = df[(df[\"DEATH_EVENT\"]==0) & (df[\"smoking\"]==1)]\nd4 = df[(df[\"DEATH_EVENT\"]==1) & (df[\"smoking\"]==1)]\n\nlabel1 = [\"No Smoking\",\"Smoking\"]\nlabel2 = ['No Smoking - Survived','No Smoking - Died', \"Smoking - Survived\", \"Smoking - Died\"]\nvalues1 = [(len(d1)+len(d2)), (len(d3)+len(d4))]\nvalues2 = [len(d1),len(d2),len(d3),len(d4)]\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=label1, values=values1, name=\"SMOKING\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=label2, values=values2, name=\"SMOKING VS DEATH_EVENT\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\n\nfig.update_layout(\n    title_text=\"SMOKING DISTRIBUTION IN THE DATASET \\\n                  SMOKING VS DEATH_EVENT\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='SMOKING', x=0.20, y=0.5, font_size=10, showarrow=False),\n                 dict(text='SMOKING VS DEATH_EVENT', x=0.84, y=0.5, font_size=8, showarrow=False)],\n    autosize=False,width=1200, height=500, paper_bgcolor=\"white\")\nfig.show()\n","e1ba376a":"# \"Distribution of AGE Vs DIABETES\"\nimport plotly.express as px\nfig = px.histogram(df, x=\"age\", color=\"diabetes\", marginal=\"violin\",hover_data=df.columns,\n                   title =\"Distribution of AGE Vs DIABETES\", \n                   labels={\"diabetes\": \"DIABETES\", \"age\": \"AGE\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","04ac40b2":"# \"Distribution of AGE Vs DIABETES\"\nimport plotly.express as px\nfig = px.histogram(df, x=\"age\", color=\"diabetes\", marginal=\"violin\",hover_data=df.columns,\n                   title =\"Distribution of AGE Vs DIABETES\", \n                   labels={\"diabetes\": \"DIABETES\", \"age\": \"AGE\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","55d39a3f":"# \"Distribution of AGE Vs HIGH BLOOD PRESSURE\"\nimport plotly.express as px\nfig = px.histogram(df, x=\"age\", color=\"high_blood_pressure\", marginal=\"violin\",hover_data=df.columns,\n                   title =\"Distribution of AGE Vs HIGH BLOOD PRESSURE\", \n                   labels={\"high_blood_pressure\": \"HIGH BLOOD PRESSURE\", \"age\": \"AGE\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","11a85cd3":"# \"Distribution of AGE Vs SMOKING\"\nimport plotly.express as px\nfig = px.histogram(df, x=\"age\", color=\"smoking\", marginal=\"violin\",hover_data=df.columns,\n                   title =\"Distribution of AGE Vs SMOKING\", \n                   labels={\"smoking\": \"SMOKING\", \"age\": \"AGE\"},\n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"})\nfig.show()","8bd0960e":"from sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import GridSearchCV\ndef compute(Y_pred,Y_test):\n    #Output plot\n    plt.figure(figsize=(12,6))\n    plt.scatter(range(len(Y_pred)),Y_pred,color=\"yellow\",lw=5,label=\"Predictions\")\n    plt.scatter(range(len(Y_test)),Y_test,color=\"red\",label=\"Actual\")\n    plt.title(\"Prediction Values vs Real Values\")\n    plt.legend()\n    plt.show()\n\n    cm=confusion_matrix(Y_test,Y_pred)\n    class_label = [\"High-risk\", \"Low-risk\"]\n    df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n    sns.heatmap(df_cm,annot=True,cmap='Pastel1',linewidths=2,fmt='d')\n    plt.title(\"Confusion Matrix\",fontsize=15)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n    #Calculate Metrics\n    acc=accuracy_score(Y_test,Y_pred)\n    mse=mean_squared_error(Y_test,Y_pred)\n    precision, recall, fscore, train_support = score(Y_test, Y_pred, pos_label=1, average='binary')\n    print('Precision: {} \\nRecall: {} \\nF1-Score: {} \\nAccuracy: {} %\\nMean Square Error: {}'.format(\n        round(precision, 3), round(recall, 3), round(fscore,3), round((acc*100),3), round((mse),3)))\n","28299c6c":"#Data Preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n#Basic Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport time\n\n#Metrics (Computation)\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import GridSearchCV\n\n#Boosting Algorithms\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\n#Neural Network Model\nfrom sklearn.neural_network import MLPClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7aba367a":"# Trial and Error revealed that not considering Age column improves accuracy\n\nx = df[['ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time']]\ny = df['DEATH_EVENT']\n\n#Spliting data into training and testing data\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.2,random_state=65) \n","fce90a16":"import time\n#Build Model\nstart = time.time()\n\nmodel_Log= LogisticRegression(random_state=1)\nmodel_Log.fit(X_train,Y_train)\nY_pred= model_Log.predict(X_test)\n\nend=time.time()\n\nmodel_Log_time=end-start\nmodel_Log_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_Log_time),5)} seconds\\n\")\n#Plot and compute metrics\ncompute(Y_pred,Y_test)","978ddb80":"#Build Model\nstart=time.time()\n\nmodel_GB= GradientBoostingClassifier(random_state=10,n_estimators=20,learning_rate=0.29,loss=\"deviance\")\nmodel_GB.fit(X_train,Y_train)\nY_pred= model_GB.predict(X_test)\n\nend=time.time()\n\nmodel_GB_time=end-start\nmodel_GB_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_GB_time),5)} seconds\")\n#Plot and compute metric\ncompute(Y_pred,Y_test)","21377203":"#Build Model\nstart=time.time()\n\nmodel_RF = RandomForestClassifier(n_estimators=300,criterion=\"gini\",random_state=1,max_depth=100)\nmodel_RF.fit(X_train,Y_train)\nY_pred=model_RF.predict(X_test)\n\nend=time.time()\n\nmodel_RF_time=end-start\nmodel_RF_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_RF_time),5)} seconds\")\n#Plot and compute metric\ncompute(Y_pred,Y_test)","f188b6ab":"#Build Model\nstart=time.time()\n\nmodel_svm=SVC(kernel=\"rbf\")\nmodel_svm.fit(X_train,Y_train)\nY_pred=model_svm.predict(X_test)\n\nend=time.time()\n\nmodel_svm_time=end-start\nmodel_svm_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_svm_time),5)} seconds\")\n#Plot and compute metric\ncompute(Y_pred,Y_test)","21abe8c7":"#Build Model\nstart=time.time()\n\nmodel_KNN = KNeighborsClassifier(n_neighbors=15)\nmodel_KNN.fit(X_train,Y_train)\nY_pred = model_KNN.predict(X_test)\n\nend=time.time()\n\nmodel_KNN_time = end-start\nmodel_KNN_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_KNN_time),5)} seconds\")\n#Plot and compute metric\ncompute(Y_pred,Y_test)","8611c145":"#Build Model\nstart=time.time()\n\nmodel_tree=DecisionTreeClassifier(random_state=10,criterion=\"gini\",max_depth=100)\nmodel_tree.fit(X_train,Y_train)\nY_pred=model_tree.predict(X_test)\n\nend=time.time()\n\nmodel_tree_time=end-start\nmodel_tree_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_tree_time),5)} seconds\")\n#Plot and compute metric\ncompute(Y_pred,Y_test)","bf0bf947":"#Build Model\nstart=time.time()\n\nmodel_xgb = XGBClassifier(objective='binary:logistic',learning_rate=0.1,\n                          max_depth=1,\n                          n_estimators = 50,\n                          colsample_bytree = 0.5)\nmodel_xgb.fit(X_train,Y_train)\nY_pred = model_xgb.predict(X_test)\n\nend=time.time()\n\nmodel_xgb_time=end-start\nmodel_xgb_accuracy=round(accuracy_score(Y_test,Y_pred), 4)*100 # Accuracy\n\nprint(f\"Execution time of model: {round((model_xgb_time),5)} seconds\")\n#Plot and compute metric\ncompute(Y_pred,Y_test)","4de20357":"accuracies={\"Logistic regression\": model_Log_accuracy,\n            \"KNN\": model_KNN_accuracy,\n            \"SVM\": model_svm_accuracy,\n            \"Decision Tree\": model_tree_accuracy,\n            \"Random Forest\": model_RF_accuracy,\n            \"Gradient Boosting\": model_GB_accuracy,\n            \"XG Boost\": model_xgb_accuracy}\n\nacc_list=accuracies.items()\nk,v = zip(*acc_list) \ntemp=pd.DataFrame(index=k,data=v,columns=[\"Accuracy\"])\ntemp.sort_values(by=[\"Accuracy\"],ascending=False,inplace=True)\n\n#Plot accuracy for different models\nplt.figure(figsize=(20,7))\nACC=sns.barplot(y=temp.index,x=temp[\"Accuracy\"],label=\"Accuracy\",edgecolor=\"black\",linewidth=3,orient=\"h\",palette=\"twilight_r\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy Comparison\")\nplt.xlim(80,98)\n\nACC.spines['left'].set_linewidth(3)\nfor w in ['right', 'top', 'bottom']:\n    ACC.spines[w].set_visible(False)\n    \n#Write text on barplots\nk=0\nfor ACC in ACC.patches:\n    width = ACC.get_width()\n    plt.text(width+0.1, (ACC.get_y() + ACC.get_height()-0.3),s=\"{}%\".format(temp[\"Accuracy\"][k]),fontname = 'monospace', fontsize = 14, color = 'black') \n    k+=1\n    \nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.show()","320f590b":"print(f'Gradient Booster Classifier: { model_GB_accuracy}%\\nDecision Tree Classifier: {model_tree_accuracy}%\\nLinear Regression: {model_Log_accuracy}%\\nSupport Vector Machine: {model_svm_accuracy}%\\nRandom Forest Classifier: {model_RF_accuracy}%\\nK Nearest Neighbors: {model_KNN_accuracy}%\\nExtra Gradient Booster Classifier: {model_xgb_accuracy}%')","07465950":"exe_time={\"Logistic regression\": model_Log_time,\n            \"KNN\": model_KNN_time,\n            \"SVM\": model_svm_time,\n            \"Decision Tree\": model_tree_time,\n            \"Random Forest\": model_RF_time,\n            \"Gradient Boosting\": model_GB_time,\n            \"XG Boost\": model_xgb_time,}\n\ntime_list=exe_time.items()\nk,v = zip(*time_list) \ntemp1=pd.DataFrame(index=k,data=v,columns=[\"Time\"])\ntemp1.sort_values(by=[\"Time\"],ascending=False,inplace=True)\n\n#Plot accuracy for different models\nplt.figure(figsize=(20,7))\nET=sns.barplot(y=temp1.index,x=temp1[\"Time\"],label=\"Time\",edgecolor=\"black\",linewidth=3,orient=\"h\",palette=\"twilight_r\")\nplt.ylabel(\"Model\")\nplt.title(\"Execution Time Comparison\")\nET.spines['left'].set_linewidth(3)\nfor w in ['right', 'top', 'bottom']:\n    ET.spines[w].set_visible(False)\n\n#Write text on barplots\nk=0\nfor ET in ET.patches:\n    width = ET.get_width()\n    plt.text(width+0.01, (ET.get_y() + ET.get_height()-0.3),s=\"{}s\".format(round((temp1[\"Time\"][k]),3)),fontname = 'monospace', fontsize = 14, color = 'black') \n    k+=1\n\nplt.legend(loc=\"lower right\")\nplt.tight_layout()\nplt.show()","532ef996":"print(f'Decision Tree Classifier: {round(model_tree_time,3)} sec \\nSupport Vector Machine: {round(model_svm_time,3)} sec \\nK Nearest Neighbors: {round(model_KNN_time,3)} sec \\nExtra Gradient Booster Classifier: {round(model_xgb_time,3)} sec\\nGradient Booster Classifier: { round(model_GB_time,3)} sec \\nLinear Regression: {round(model_Log_time,3)} sec \\nRandom Forest Classifier: {round(model_RF_time,3)} sec \\n ')","a15bf443":"### 5) K Nearest Neighbors","073d5108":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\"><b>A sample from the data<\/b><\/p>","a4b54e86":"<center><img src=\"https:\/\/ac-cdn.azureedge.net\/infusionnewssiteimages\/agingcare\/21e637ea-aa74-4ae2-b278-181d2cded7a3.jpg?fit=scale\"><\/center>","53c51b90":"##  Finding Outliers on Dataset","ad9f7f09":"### 2Gradient Booster Classifier","98071067":"<p style=\"font-size:15px; font-family:verdana;\"><b>Thanks for reading my notebook!\ud83d\ude03<\/b><\/p>","7447a971":"### Death Event Distribution","5cd3626e":"> Insight:From the above subplot we can conclude that in our dataset 65% do not have HIGH BLOOD PRESSURE (out of which 45.8% survived and 19.2% died) and 35% have HIGH BLOOD PRESSURE (out of which 22.2% survived and 12.8% died).","7017b802":"### 6) Decision Tree Classifier","6e5fdc97":"## Insight of Dataset ","cedddfbb":"<h1><center>Heart Failure Prediction with Various Machine Learning Models<\/center><\/h1>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em; text-align: justify\"><span style=\"color:crimson;\">Dilated cardiomyopathy (DCM)<\/span> is the most common type of heart disease, occurring mostly in adults 20 to 60. It affects the heart's ventricles and atria, the lower and upper chambers of the heart, respectively. Frequently the disease starts in the left ventricle, the heart's main pumping chamber. The heart muscle begins to dilate, meaning it stretches and becomes thinner. Consequently, the inside of the chamber enlarges. The problem often spreads to the right ventricle and then to the atria. As the heart chambers dilate, the heart muscle doesn't contract normally and cannot pump blood very well.<\/p>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">Source: <a href=\"https:\/\/www.heart.org\/en\/health-topics\/cardiomyopathy\/what-is-cardiomyopathy-in-adults\/dilated-cardiomyopathy-dcm\" target=\"_blank\">Heart.org<\/a><\/p>\n","65a5276d":"### 4) Support Vector Machine","18d85e8a":"From the above graph we can see that ```time```, ```ejection_fraciton```, ```serum_creatinine```, ```age```, ```serum_sodium``` has the most feature importance on predicting the ```DEATH_EVENT```.","fc3e087c":"The features 'age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', and 'time' have a considerable correlation with ```DEATH_EVENT```","3cc478be":"(Random Forest rate varies on each execution from 88.33% to 91.67%)","8cbb2d63":"### 1) Linear Regression","0c174b72":"### Using Correlation Heatmap","568835a6":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\"><b>Data distribution<\/b><\/p>","5f74b672":"**Display Function to plot and compute the data.**<br>\nWe will use this function for each model separately.","cf82e83c":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\"><b>Aim of this notebook \ud83d\udcda<\/b><\/p>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em; text-align: justify\">In this notebook, I visualize the distribution of the variables in the <a href=\"https:\/\/www.kaggle.com\/andrewmvd\/heart-failure-clinical-data\" target=\"_blank\">Heart Failure Prediction<\/a> dataset and explore their relationship with the target variable <code>DEATH_EVENT<\/code>. Based on the result of this analysis, I define seven machine learning models to compare their performance on this dataset to predict the target variable using the most correlated subset of variables from the dataset.<\/p>\n","3340bf9c":"<p style=\"font-size:15px; font-family:verdana;\">The dataset has observations of 13 variables for 299 patients<\/p>\n<div style=\"font-size:15px; font-family:verdana;\"><b>Variables in this dataset<\/b>\n<ol>\n    <li><span style=\"color:crimson;\">Age<\/span>: Age of the patient in years<\/li>\n    <li><span style=\"color:crimson;\">Anaemia<\/span>: Decrease of red blood cells or hemoglobin (0:Reduced or 1:Normal)<\/li>\n    <li><span style=\"color:crimson;\">creatinine_phosphokinase<\/span>: Level of the CPK enzyme in the blood (mcg\/L)<\/li>\n    <li><span style=\"color:crimson;\">Diabetes<\/span>: If the patient has diabetes (0:No or 1:Yes)<\/li>\n    <li><span style=\"color:crimson;\">ejection_fraction<\/span>: Percentage of blood leaving the heart at each contraction (percentage)<\/li>\n    <li><span style=\"color:crimson;\">high_blood_pressure<\/span>: If the patient has hypertension (0:No or 1:Yes)<\/li>\n    <li><span style=\"color:crimson;\">platelets<\/span>: Platelets in the blood (kiloplatelets\/mL)<\/li>\n    <li><span style=\"color:crimson;\">serum_creatinine<\/span>: Level of serum creatinine in the blood (mg\/dL)<\/li>\n    <li><span style=\"color:crimson;\">serum_sodium<\/span>: Level of serum sodium in the blood (mEq\/L)<\/li>\n    <li><span style=\"color:crimson;\">sex<\/span>: Biological sex of the patient (0:Female or 1:Male)<\/li>\n    <li><span style=\"color:crimson;\">smoking<\/span>: If the patient is a smoker (0:No or 1: Yes)<\/li>\n    <li><span style=\"color:crimson;\">time<\/span>: Follow-up period in days<\/li>\n    <li><span style=\"color:crimson;\">death_event<\/span>: If the patient survived till the end of follow-up period (0:No or 1:Yes )<\/li>\n<\/ol>\n<\/div>","099441ae":"## Feature Selection\n\n### Using ExtraTreesClassifier","b07e51ab":"> Insight: From the above subplot we can conclude that in our dataset 65.3% are MALE (out of which 44.4% survived and 20.9% died) and 34.7% are FEMALE (out of which 23.6% survived and 11.1% died).\n","53bca91b":"Here the columns \"*age - thall*\" are the independent variables and the last column \"*output*\" contains the dependent variable.<br> The meaning of every column is given below (pulled from the original dataset description).","5a3efc5e":"### 3) Random Forest Classifier","60a3c197":"### 7) Extra Gradient Booster Classifier","327b2aca":"**Data Splitting and scaling:**<br>\nWe will split the data into training and testing sets using train_test_split from *sklearn.preprocessing*. After splitting we will scale our data using the MinMax scaler before using it for training our model.","983831a7":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\"><h3>Lets see what our data looks like.<\/h3><\/p>","88667c8f":"## Model Training and Prediction","38acbc45":"## Final Results:","a237855f":"> Insight:From the above subplot we can conclude that in our dataset 67.7% do not SMOKE (out of which 45.8% survived and 21.9% died) and 32.3% do SMOKE (out of which 22.2% survived and 10.1% died).","f8120647":"**Clealy, there are no null values in the dataset as observed above so we don't need to treat any columns for null values.**"}}