{"cell_type":{"f08cfeed":"code","2f9a0d37":"code","23c012e7":"code","bb12990d":"code","bc7c2b51":"code","49bccefe":"code","f0b85ee3":"code","831a8158":"code","6a9ab3b6":"code","20415245":"code","9fd6ff64":"markdown","a78cbecb":"markdown","bdfbfcb0":"markdown","f0486e97":"markdown","ed10a429":"markdown"},"source":{"f08cfeed":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\nfrom datetime import datetime\nfrom pytz import timezone\n\nfrom types import FunctionType, MethodType\ndef refer_args(x):\n    if type(x) is MethodType or type(x) is FunctionType:\n        print(*x.__code__.co_varnames, sep='\\n')\n    else:\n        print(*[x for x in dir(x) if not x.startswith('__')], sep='\\n')\n\ndatetime.now(timezone('Asia\/Tokyo')).strftime('%Y\/%m\/%d %H:%M:%S')","2f9a0d37":"!pip install GetOldTweets3","23c012e7":"import os\nfrom time import sleep\n\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport GetOldTweets3 as got\nfrom GetOldTweets3.manager import TweetManager, TweetCriteria","bb12990d":"df_train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ndf_test = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsr_id_train = df_train['id']\nsr_text_train = df_train['text']\nsr_id_test = df_test['id']\nsr_text_test = df_test['text']","bc7c2b51":"def tweet2dict(id_, tweet):\n    return {\n        'id':id_,\n        'permalink': tweet.permalink,\n        'username': tweet.username,\n        'favorites': tweet.favorites,\n        'retweets': tweet.retweets,\n        'text': tweet.text,\n        'date': tweet.date,\n        'mentions': tweet.mentions,\n        'hashtags': tweet.hashtags,\n        'geo': tweet.geo,\n        'urls': tweet.urls,\n    }\n\ncolumns = [\n    'id',\n    'permalink',\n    'username',\n    'favorites',\n    'retweets',\n    'text',\n    'date',\n    'mentions',\n    'hashtags',\n    'geo',\n    'urls',\n]\ndtype = {\n    'id':'int',\n    'favorites': 'int',\n    'retweets': 'int',\n}","49bccefe":"df_tweet_train = pd.DataFrame(columns=columns)\ndf_tweet_train = df_tweet_train.astype(dtype)\n\nidx = 0\nid_, query = sr_id_train[idx], sr_text_train[idx]\ntweetCriteria = TweetCriteria().setQuerySearch(query).setMaxTweets(10)\ntweets = TweetManager.getTweets(tweetCriteria)\nif tweets:\n    tweet = min((tweet for tweet in tweets), key=lambda tweet:tweet.date)\n    tweet_dict = tweet2dict(id_, tweet)\nelse:\n    tweet_dict = {'id':id_}\ndf_tweet_train = df_tweet_train.append(tweet_dict, ignore_index=True)\n\nid_, query\ntweet_dict","f0b85ee3":"file = 'tmp_file'\nif os.path.isfile(file):\n    df_tweet_train = pd.read_csv(file)\n    idx = len(df_tweet_train)\nelse:\n    df_tweet_train = pd.DataFrame(columns=columns)\n    idx = 0","831a8158":"%%time\nloop = tqdm(\n    enumerate(zip(sr_id_train[idx:], sr_text_train[idx:]), idx+1),\n    total=len(sr_id_train),\n    initial=idx\n)\n\nfor i, (id_, query) in loop:\n    tweetCriteria = TweetCriteria().setQuerySearch(query).setMaxTweets(10)\n    try:\n        tweets = TweetManager.getTweets(tweetCriteria)\n    except SystemExit:\n        tweets = []\n    if tweets:\n        tweet = min((tweet for tweet in tweets), key=lambda tweet:tweet.date)\n        tweet_dict = tweet2dict(id_, tweet)\n    else:\n        tweet_dict = {'id':id_}\n    df_tweet_train = df_tweet_train.append(tweet_dict, ignore_index=True)\n    sleep(2)\n    if i % 500 == 0:\n        df_tweet_train.to_csv(f'data\/train_tweet_{i}.csv', index=False)\ndf_tweet_train = df_tweet_train.astype({'id':int})\ndf_tweet_train.to_csv('train_tweet.csv', index=False)","6a9ab3b6":"file = 'tmp_file'\nif os.path.isfile(file):\n    df_tweet_test = pd.read_csv(file)\n    idx = len(df_tweet_test)\nelse:\n    df_tweet_test = pd.DataFrame(columns=columns)\n    idx = 0","20415245":"%%time\nloop = tqdm(\n    enumerate(zip(sr_id_test[idx:], sr_text_test[idx:]), idx+1),\n    total=len(sr_id_test),\n    initial=idx\n)\n\nfor i, (id_, query) in loop:\n    tweetCriteria = TweetCriteria().setQuerySearch(query).setMaxTweets(10)\n    try:\n        tweets = TweetManager.getTweets(tweetCriteria)\n    except SystemExit:\n        tweets = []\n    if tweets:\n        tweet = min((tweet for tweet in tweets), key=lambda tweet:tweet.date)\n        tweet_dict = tweet2dict(id_, tweet)\n    else:\n        tweet_dict = {'id':id_}\n    df_tweet_test = df_tweet_test.append(tweet_dict, ignore_index=True)\n    sleep(2)\n    if i % 500 == 0:\n        df_tweet_test.to_csv('test_tweet_backup.csv', index=False)\ndf_tweet_test = df_tweet_test.astype({'id':int})\ndf_tweet_test.to_csv('test_tweet.csv', index=False)","9fd6ff64":"# **Japanese Description**\n\n## \u88dc\u52a9\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\n\u5143\u306e\u30c4\u30a4\u30fc\u30c8\u306e\u771f\u304b\u507d\u304b\u3092\u5224\u65ad\u3059\u308b\u3068\u304d\u3001  \n\u6587\u7ae0\u3060\u3051\u3067\u306f\u306a\u304f\u30ea\u30d7\u30e9\u30a4\u6570\u3084\u30ea\u30c4\u30a4\u30fc\u30c8\u6570\u3001\u30e6\u30fc\u30b6\u60c5\u5831\u306a\u3069  \n\u7dcf\u5408\u7684\u306a\u60c5\u5831\u304b\u3089\u5224\u65ad\u3059\u308b\u3067\u3057\u3087\u3046\u3002  \n\n\u79c1\u306f\u30c4\u30a4\u30fc\u30c8\u306e\u6587\u7ae0\u304b\u3089Twitter\u306e\u691c\u7d22\u3092\u4f7f\u3063\u3066\u3001\u6587\u7ae0\u304c\u4e00\u81f4\u3059\u308b\u3082\u306e\u3092\u63a2\u3057\u51fa\u3057  \n\u305d\u306e\u30c4\u30a4\u30fc\u30c8\u95a2\u9023\u60c5\u5831\u3092\u307e\u3068\u3081\u3066\u88dc\u52a9\u30c7\u30fc\u30bf\u3068\u3057\u3066\u6271\u304a\u3046\u3068\u8003\u3048\u307e\u3057\u305f\u3002\n\n\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002  \n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u4f5c\u6210\u3059\u308b\u30bf\u30a4\u30df\u30f3\u30b0\u306b\u3088\u3063\u3066\u3001\u5f97\u3089\u308c\u308b\u51fa\u529b\u304c\u7570\u306a\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002  \n\n\n## \u30c7\u30fc\u30bf\u306e\u53d6\u5f97\n\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u3053\u3061\u3089\u306e[\u30ea\u30f3\u30af](https:\/\/www.kaggle.com\/hinamimi\/nlpwithdisastertweets-searching-real-tweets)\u304b\u3089\u53d6\u5f97\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002","a78cbecb":"## Searching train tweet","bdfbfcb0":"## Sample","f0486e97":"# Making ancillary data\nWhen I judge whether the original tweet is real or fake,  \nI will judge not only from the sentence but also from the comprehensive information  \nsuch as the number of replies, the number of retweets, user information.  \n\nI decided to use the search of Twitter from the text of the tweet to find out the one that  \nthe text matches and collect the information related to the tweet and regarded as auxiliary data.  \n\nYou can create datasets in this notebook.  \nDepending on the timing of creating the dataset, the output obtained may differ.  \n\n# Getting data\nThe dataset can get from [here](https:\/\/www.kaggle.com\/hinamimi\/nlpwithdisastertweets-searching-real-tweets).","ed10a429":"## Searching test tweet"}}