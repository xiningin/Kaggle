{"cell_type":{"50e2fc92":"code","45f0cdb4":"code","88a2886e":"code","95c6c5eb":"code","0453861e":"code","2123e79a":"code","234eb1eb":"code","d968da0f":"code","46d12ccc":"code","391437fb":"code","d1df3e87":"code","ebdde1dd":"code","dab910ca":"code","4ac2b482":"code","f9628a1c":"code","476e31ba":"code","c665b776":"code","2a8c2a92":"code","0fda617b":"code","c80e40af":"code","0bfe471e":"markdown","7f858e0b":"markdown","05fbd38e":"markdown","c3515d8a":"markdown","ad1f7327":"markdown"},"source":{"50e2fc92":"import os, sys, random, warnings, math\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nfrom tqdm.auto import tqdm, trange\nfrom itertools import chain\n\nimport cv2\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import models, Input, layers, callbacks, utils, optimizers, applications","45f0cdb4":"class config:\n    im_width = 128\n    im_height = 128\n    im_chan = 1\n    path_train = 'train\/'\n    path_test = 'test\/'","88a2886e":"! unzip -q ..\/input\/tgs-salt-identification-challenge\/train.zip -d train\/\n! unzip -q ..\/input\/tgs-salt-identification-challenge\/test.zip -d test\/","95c6c5eb":"random.seed(19)\nids = random.choices(os.listdir('train\/images'), k=6)\nfig = plt.figure(figsize=(20,6))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    \n    img = load_img('train\/images\/' + img_name)\n    img_mask = load_img('train\/masks\/' + img_name)\n    \n    plt.subplot(2, 6, q*2-1)\n    plt.imshow(img)\n    plt.subplot(2, 6, q*2)\n    plt.imshow(img_mask)\nfig.suptitle('Sample Images', fontsize=24);","0453861e":"train_ids = next(os.walk(config.path_train+\"images\"))[2]\ntest_ids = next(os.walk(config.path_test+\"images\"))[2]","2123e79a":"X = np.zeros((len(train_ids), config.im_height, config.im_width, config.im_chan), dtype=np.uint8)\nY = np.zeros((len(train_ids), config.im_height, config.im_width, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    x = img_to_array(load_img(config.path_train + '\/images\/' + id_, color_mode=\"grayscale\"))\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X[n] = x\n    mask = img_to_array(load_img(config.path_train + '\/masks\/' + id_, color_mode=\"grayscale\"))\n    Y[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\nprint('Done!')\nprint('X shape:', X.shape)\nprint('Y shape:', Y.shape)","234eb1eb":"X_train = X[:int(0.9*len(X))]\nY_train = Y[:int(0.9*len(X))]\nX_eval  = X[int(0.9*len(X)):]\nY_eval  = Y[int(0.9*len(X)):]\n\nX_train = np.append(X_train, [np.fliplr(x) for x in X], axis=0)\nY_train = np.append(Y_train, [np.fliplr(x) for x in Y], axis=0)\nX_train = np.append(X_train, [np.flipud(x) for x in X], axis=0)\nY_train = np.append(Y_train, [np.flipud(x) for x in Y], axis=0)\n# X_train = np.append(X_train, [np.rot90(x, k=1) for x in X], axis=0)\n# Y_train = np.append(Y_train, [np.rot90(x, k=1) for x in Y], axis=0)\n# X_train = np.append(X_train, [np.rot90(x, k=3) for x in X], axis=0)\n# Y_train = np.append(Y_train, [np.rot90(x, k=3) for x in Y], axis=0)\n\ndel X, Y\n\nprint('X train shape:', X_train.shape, 'X eval shape:', X_eval.shape)\nprint('Y train shape:', Y_train.shape, 'Y eval shape:', Y_eval.shape)","d968da0f":"def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = layers.BatchNormalization()(x)\n    if activation == True:\n        x = layers.LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = layers.LeakyReLU(alpha=0.1)(blockInput)\n    x = layers.BatchNormalization()(x)\n    blockInput = layers.BatchNormalization()(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = layers.Add()([x, blockInput])\n    return x","46d12ccc":"def UXception(input_shape=(None, None, 3)):\n\n    backbone = applications.Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n    input_layer = backbone.input\n    start_neurons = 16\n\n    conv4 = backbone.layers[121].output\n    conv4 = layers.LeakyReLU(alpha=0.1)(conv4)\n    pool4 = layers.MaxPooling2D((2, 2))(conv4)\n    pool4 = layers.Dropout(0.1)(pool4)\n    \n     # Middle\n    convm = layers.Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = residual_block(convm,start_neurons * 32)\n    convm = layers.LeakyReLU(alpha=0.1)(convm)\n    \n    # 10 -> 20\n    deconv4 = layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = layers.concatenate([deconv4, conv4])\n    uconv4 = layers.Dropout(0.1)(uconv4)\n    \n    uconv4 = layers.Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = residual_block(uconv4,start_neurons * 16)\n    uconv4 = layers.LeakyReLU(alpha=0.1)(uconv4)\n    \n    # 10 -> 20\n    deconv3 = layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    conv3 = backbone.layers[31].output\n    uconv3 = layers.concatenate([deconv3, conv3])    \n    uconv3 = layers.Dropout(0.1)(uconv3)\n    \n    uconv3 = layers.Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = residual_block(uconv3,start_neurons * 8)\n    uconv3 = layers.LeakyReLU(alpha=0.1)(uconv3)\n\n    # 20 -> 40\n    deconv2 = layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    conv2 = backbone.layers[21].output\n    conv2 = layers.ZeroPadding2D(((1,0),(1,0)))(conv2)\n    uconv2 = layers.concatenate([deconv2, conv2])\n        \n    uconv2 = layers.Dropout(0.1)(uconv2)\n    uconv2 = layers.Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = residual_block(uconv2,start_neurons * 4)\n    uconv2 = layers.LeakyReLU(alpha=0.1)(uconv2)\n    \n    # 40 -> 80\n    deconv1 = layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    conv1 = backbone.layers[11].output\n    conv1 = layers.ZeroPadding2D(((3,0),(3,0)))(conv1)\n    uconv1 = layers.concatenate([deconv1, conv1])\n    \n    uconv1 = layers.Dropout(0.1)(uconv1)\n    uconv1 = layers.Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = residual_block(uconv1,start_neurons * 2)\n    uconv1 = layers.LeakyReLU(alpha=0.1)(uconv1)\n    \n    \n    # 80 -> 160\n    uconv0 = layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   \n    uconv0 = layers.Dropout(0.1)(uconv0)\n    uconv0 = layers.Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = residual_block(uconv0,start_neurons * 1)\n    uconv0 = layers.LeakyReLU(alpha=0.1)(uconv0)\n    \n    uconv0 = layers.Dropout(0.1\/2)(uconv0)\n    output_layer = layers.Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    \n    \n    model = models.Model(input_layer, output_layer)\n\n    return model","391437fb":"input_layer = Input(shape=(config.im_height, config.im_width, 1))\nscaled = layers.Lambda(lambda x: x \/ 255) (input_layer)\nx = layers.Conv2D(3, 1, activation='relu', padding='same')(scaled)\noutput_layer = UXception(input_shape=(config.im_height, config.im_width, 3))(x)\n\nmodel = models.Model(input_layer, output_layer)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","d1df3e87":"utils.plot_model(model, expand_nested=True, show_shapes=True)","ebdde1dd":"es = callbacks.EarlyStopping(patience=30, verbose=1, restore_best_weights=True)\nrlp = callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-12, verbose=1)\n\nresults = model.fit(\n    X_train, Y_train, validation_data=(X_eval, Y_eval), batch_size=8, epochs=300, callbacks=[es, rlp]\n)","dab910ca":"sns.set_style('darkgrid')\nfig, ax = plt.subplots(2, 1, figsize=(20, 8))\nhistory = pd.DataFrame(results.history)\nhistory[['loss', 'val_loss']].plot(ax=ax[0])\nhistory[['acc', 'val_acc']].plot(ax=ax[1])\nfig.suptitle('Learning Curve', fontsize=24);","4ac2b482":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","f9628a1c":"preds_eval = model.predict(X_eval, verbose=1)\n\nthresholds = np.linspace(0, 1, 50)\nious = np.array([iou_metric_batch(Y_eval, np.int32(preds_eval > threshold)) for threshold in tqdm(thresholds)])\n\nthreshold_best_index = np.argmax(ious[9:-10]) + 9\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend();","476e31ba":"# Get and resize test images\nX_test = np.zeros((len(test_ids), config.im_height, config.im_width, config.im_chan), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    x = img_to_array(load_img(config.path_test + '\/images\/' + id_, color_mode=\"grayscale\"))\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\n\nprint('Done!')","c665b776":"preds_test = model.predict(X_test, verbose=1)\npreds_test_upsampled = []\nfor i in trange(len(preds_test)):\n    preds_test_upsampled.append(resize(\n        np.squeeze(preds_test[i]), (sizes_test[i][0], sizes_test[i][1]),  mode='constant', preserve_range=True\n    ))","2a8c2a92":"!rm -rf train\n!rm -rf test","0fda617b":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {\n    fn[:-4]:RLenc(np.round(preds_test_upsampled[i] > threshold_best)) \n    for i,fn in tqdm(enumerate(test_ids), total=len(test_ids))\n}","c80e40af":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","0bfe471e":"# Scoring","7f858e0b":"# Augmentation and Cross Validation","05fbd38e":"# Model Evaluation","c3515d8a":"# Model Building","ad1f7327":"# Data Exploration"}}