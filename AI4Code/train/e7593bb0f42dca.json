{"cell_type":{"f2781aa6":"code","3de1bd40":"code","6f504d42":"code","3f1cb8fd":"code","dca208e7":"code","5abb41c0":"code","46e74121":"code","25ade9be":"code","08846a3d":"code","2add2e4f":"code","bf4498a5":"code","5ef078a4":"code","cbbffcfa":"code","a93df84f":"code","9d4e5cd6":"code","8caf5a25":"code","3e20dcba":"code","d37f95a4":"code","d69b844b":"markdown","79f5e961":"markdown","1cd6875a":"markdown","83aa19f0":"markdown","8daa7891":"markdown","9892754f":"markdown","1abc562f":"markdown","8456c38b":"markdown"},"source":{"f2781aa6":"import numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf = pd.read_csv('..\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')","3de1bd40":"for col in df.columns:\n    print( col, '{nulls:.2f}%'.format(nulls=(df[col].isna().sum() \/ df.shape[0]) * 100))\n\n# Since EmployeeCount is 1, and Standard Hours is 80 for everyone, lets remove them\ndf = df.drop(['EmployeeCount','StandardHours','EmployeeNumber'],1)","6f504d42":"attr_split = (df['Attrition'].value_counts(normalize=True) * 100)\nfig = px.bar(attr_split, \n             x = 'Attrition',\n            )\nfig.update_layout(\n    template=\"plotly_dark\",\n)\nfig.show()","3f1cb8fd":"Q1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\n\niqr_df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n\nfig = px.box(iqr_df, \n             y=\"MonthlyIncome\",\n            x = 'Attrition',\n            color=\"Gender\")\nfig.update_layout(\n    template=\"plotly_dark\",\n)\nfig.show()","dca208e7":"corr = df.corr()\nfig = px.imshow(corr,\n                color_continuous_scale='Reds')\n\nfig.update_layout(\n    template=\"plotly_dark\",\n)\n\nfig.show()","5abb41c0":"df_one = df.groupby(by=['JobLevel','Attrition'])['MonthlyIncome'].mean().reset_index()\ndf_one\nfig = go.Figure()\n\nfig.add_trace(\n    go.Bar(\n        x = df_one[ df_one['Attrition'] == 'Yes' ]['JobLevel'],\n        y = df_one[ df_one['Attrition'] == 'Yes' ]['MonthlyIncome'],\n        name='Attrition = Yes',\n        marker_color='rgb(255, 153, 153)'\n                )\n)\n\nfig.add_trace(\n    go.Bar(\n        x = df_one[ df_one['Attrition'] == 'No' ]['JobLevel'],\n        y = df_one[ df_one['Attrition'] == 'No' ]['MonthlyIncome'],\n        name='Attrition = No',\n        marker_color='rgb(153, 255, 153)'\n                )\n)\n\nfig.update_layout(\n    title='Attrition by Monthly Income, by Job Level',\n    barmode='group',\n    bargap=0.2,\n    bargroupgap=0.05,\n    template='plotly_dark'\n)\n\nfig.show()","46e74121":"df_two = df.groupby(by=['JobLevel'])['Attrition'].value_counts().rename('Count').reset_index()\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Bar(\n        x = df_two[ df_two['Attrition'] == 'Yes' ]['JobLevel'],\n        y = df_two[ df_two['Attrition'] == 'Yes' ]['Count'],\n        name='Attrition = Yes',\n        marker_color='rgb(255, 153, 153)'\n                )\n)\n\nfig.add_trace(\n    go.Bar(\n        x = df_two[ df_two['Attrition'] == 'No' ]['JobLevel'],\n        y = df_two[ df_two['Attrition'] == 'No' ]['Count'],\n        name='Attrition = No',\n        marker_color='rgb(153, 255, 153)'\n                )\n)\n\nfig.update_layout(\n    title='Attrition by Job Level',\n    barmode='group',\n    bargap=0.2,\n    bargroupgap=0.05,\n    template='plotly_dark'\n)\n\nfig.show()","25ade9be":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","08846a3d":"#split dataset in features and target variable\n\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ntest = df.select_dtypes(include=numerics)\n\nfeature_cols = test\nX = feature_cols\ny = df['Attrition'] # Target variable","2add2e4f":"crit = ['entropy','gini']\nsplitter = ['best','random']\nfor c in crit:\n    for s in splitter:\n        clf = DecisionTreeClassifier(splitter=s,random_state=1,criterion=c)\n        clf = clf.fit(X_train,y_train)\n        y_pred = clf.predict(X_test)\n        print(c,s,\" Accuracy: {score:.2f}%\".format(score= metrics.accuracy_score(y_test, y_pred)*100 ))","bf4498a5":"# Testing importance of each feature, which provide less information in the decision process\nfrom matplotlib import pyplot\nimportance = clf.feature_importances_\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\npyplot.bar([x for x in range(len(importance))], importance)\npyplot.show()","5ef078a4":"cols = [0,1,2,4,6,7,8,12,13,14,17,18,19,20,21,22]\ntest2 = test.drop( test.columns[cols],axis=1)\nprint( test2 )","cbbffcfa":"feature_cols = test2\nX = feature_cols\ny = df['Attrition'] # Target variable\ncrit = ['entropy','gini']\nsplitter = ['best','random']\nfor c in crit:\n    for s in splitter:\n        clf = DecisionTreeClassifier(splitter=s,random_state=1,criterion=c)\n        clf = clf.fit(X_train,y_train)\n        y_pred = clf.predict(X_test)\n        print(c,s,\" Accuracy: {score:.2f}%\".format(score= metrics.accuracy_score(y_test, y_pred)*100 ))","a93df84f":"#!pip install info_gain\nfrom info_gain import info_gain\neach = df.columns\n\nfor e in each:\n    ig  = info_gain.info_gain(df['Attrition'], df[e])\n    print(e,ig)","9d4e5cd6":"feature_cols = df[['DailyRate','Age','DistanceFromHome','HourlyRate','JobLevel','JobRole','MaritalStatus','MonthlyIncome','OverTime','PerformanceRating','YearsWithCurrManager', 'StockOptionLevel', 'YearsAtCompany', 'YearsInCurrentRole', 'TotalWorkingYears']]\njobrole = pd.get_dummies(feature_cols['JobRole'])\njobrole = jobrole[:-1]\nstats = pd.get_dummies(feature_cols['MaritalStatus'])\nstats = stats[:-1]\noTime = pd.get_dummies(feature_cols['OverTime'])\noTime = oTime[:-1]\n\nfeature_cols = pd.concat([feature_cols, jobrole], axis=1, sort=False)\nfeature_cols = pd.concat([feature_cols, stats], axis=1, sort=False)\nfeature_cols = feature_cols.drop(['JobRole','MaritalStatus','OverTime'],1)","8caf5a25":" feature_cols = feature_cols.fillna(0)","3e20dcba":"X = feature_cols\ny = df['Attrition']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n\ncrit = ['entropy','gini']\nsplitter = ['best','random']\nfor c in crit:\n    for s in splitter:\n        clf = DecisionTreeClassifier(splitter=s,random_state=1,criterion=c,max_depth=5)\n        clf = clf.fit(X_train,y_train)\n        y_pred = clf.predict(X_test)\n        print(c,s,\" Accuracy: {score:.2f}%\".format(score= metrics.accuracy_score(y_test, y_pred)*100 ))","d37f95a4":"#!pip install --upgrade scikit-learn==0.20.3\n#!pip install pydotplus\nfrom sklearn.tree import export_graphviz\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nimport pydotplus\n\ndot_data = StringIO()\nexport_graphviz(clf, \n                out_file=dot_data,  \n                filled=True, \n                rounded=True,\n                special_characters=True, \n                #feature_names = X_train,\n                #class_names=['0','1']\n               )\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","d69b844b":"# Correlation Matrix","79f5e961":"# Preprocessing & Cleaning\nIt is my understanding that a row marked \"Yes\" for attrition is an employee that will not be replaced once they're gone from the company.\nThere doesnt appear to be any empty cells. \nThere were a few outliers, removed by inter-quantile range.","1cd6875a":"Since the levels of attrition are fairly close in each group it doesn't appear that their salaries for each level are inappropriate. If there were higher attrition rates for a certain joblevel then maybe monthly income if affecting their stay. ","83aa19f0":"# Predicting Your Own Attrition\n","8daa7891":"To me, this shows that there is more turnover in lower positions but that rate drops as you move up the levels.","9892754f":"There appears to be high correlation between:\n* Job Level and Monthly Income\n* Monthly Income and Years Worked at the company\n* Job Performance and Perc. Salary Hike\nLets look into Different job levels, Monthly Income, and Attrition rates","1abc562f":"From the boxplot it appears that employees who have a higher income are less likely to leave.","8456c38b":"## Job Level & Monthly Income"}}