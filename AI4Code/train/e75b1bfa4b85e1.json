{"cell_type":{"a4d76d48":"code","ffb44c32":"code","b429cf46":"code","f5a3e2a8":"code","fa50933f":"code","6059b309":"code","64d34568":"code","13ada330":"code","dcba9934":"code","02e4e577":"code","2e9fb1cc":"code","5e1fcbf7":"code","cd823ef0":"code","53b916e3":"code","28ef52ab":"code","751aca08":"code","f723ce96":"code","f69f7ff0":"code","c3bc72c1":"code","d11631b8":"code","68313593":"code","001918db":"code","2b21c820":"code","9423efb2":"code","f8b25c42":"code","a89454c7":"code","9dfa58a0":"code","95f43180":"code","1c26a0c9":"code","f121a6be":"code","e2b7be3b":"code","7b0d4ca5":"code","a24bc113":"code","b6b4bd58":"code","13311696":"code","83d4a7dd":"code","8df8c8af":"code","278791c2":"code","cd880afa":"code","e63c9f59":"code","b394ed40":"code","4b53b73e":"markdown","8280d66d":"markdown","a9cb3cd6":"markdown","6fb38079":"markdown","950b6f47":"markdown","574cb237":"markdown","82583ffa":"markdown","09f38d93":"markdown","321ef7a6":"markdown","66983b45":"markdown","a179c10e":"markdown","e6a4f2f1":"markdown"},"source":{"a4d76d48":"# !pip install git+https:\/\/github.com\/keras-team\/keras-applications.git -q\n\n# import keras_applications as ka\n# def set_to_tf(ka):\n#     from tensorflow.keras import backend, layers, models, utils\n#     ka._KERAS_BACKEND = backend\n#     ka._KERAS_LAYERS = layers\n#     ka._KERAS_MODELS = models\n#     ka._KERAS_UTILS = utils\n    \n    \n# set_to_tf(ka)\n\n# !pip install \/kaggle\/input\/keras-pretrained-imagenet-weights\/image_classifiers-1.0.0-py3-none-any.whl\n\n# from classification_models.tfkeras import Classifiers\n# Classifiers.models_names()","ffb44c32":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import Model\n# import tensorflow.keras.applications.efficientnet as efn\nfrom tensorflow.keras.applications import *\nimport os\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","b429cf46":"df = pd.read_csv('..\/input\/nih-dataframe\/NIH_Dataframe.csv')\ndf.img_ind= df.img_ind.apply(lambda x: x.split('.')[0])\ndisplay(df.head(4))\nprint(df.shape)","f5a3e2a8":"target_cols = df.drop(['img_ind'], axis=1).columns.to_list()\nn_classes = len(target_cols)\nimg_size = 256\nn_epochs = 35\nlr= 0.0001\nseed= 11\nval_split= 0.2\nseed= 33\nbatch_size=12\nLabel = 'Cardiomegaly' # replace this with the respective disease label\nn_classes","fa50933f":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\n\n'''\nReference\nhttps:\/\/www.kaggle.com\/xhlulu\/ranzcr-efficientnet-tpu-training\n\n'''\n\ndef build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path) # Reads and outputs the entire contents of the input filename.\n\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3) # Decode a PNG-encoded image to a uint8 or uint16 tensor\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3) # Decode a JPEG-encoded image to a uint8 tensor\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32)# Casts a tensor to the type float32 and divides by 255.\n        img = tf.image.resize(img, target_size) # Resizing to target size\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        #img = tf.image.random_flip_left_right(img)\n        #img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO) # overlaps data preprocessing and model execution while training\n    return dset\n","6059b309":"DATASET_NAME = \"nih-image-600x600-data\"\nstrategy = auto_select_accelerator()\nbatch_size = strategy.num_replicas_in_sync * batch_size\nprint('batch size', batch_size)","64d34568":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(DATASET_NAME)\nGCS_DS_PATH","13ada330":"paths = GCS_DS_PATH + \"\/NIH_Images\/\" + df['img_ind'] + '.jpg'\n\n\n# #Get the multi-labels\n# label_cols = df.columns[:-1]\n# labels = df[label_cols].values\ndef get_label(df , label):\n    labels = df[label].values\n    return labels","dcba9934":"# Train test split\ndef t_t_s(df , paths , label):\n    labels = get_label(df , label)\n    (train_paths, valid_paths, \n      train_labels, valid_labels) = train_test_split(paths, labels, test_size=val_split, random_state=11)\n    return  train_paths, valid_paths, train_labels, valid_labels\n\n# print(train_paths.shape, valid_paths.shape)\n# train_labels.sum(axis=0), valid_labels.sum(axis=0)","02e4e577":"tr_paths , val_paths , tr_labels , val_labels = t_t_s(df , paths , Label)","2e9fb1cc":"# Build the tensorflow datasets\n\ndecoder = build_decoder(with_labels=True, target_size=(img_size, img_size))\n\n# Build the tensorflow datasets\ndtrain = build_dataset(\n    tr_paths, tr_labels, bsize=batch_size, decode_fn=decoder\n)\n\ndvalid = build_dataset(\n    val_paths, val_labels, bsize=batch_size, \n    repeat=False, shuffle=False, augment=False, decode_fn=decoder\n)","5e1fcbf7":"data, _ = dtrain.take(2)\nimages = data[0].numpy()","cd823ef0":"fig, axes = plt.subplots(3, 4, figsize=(20,10))\naxes = axes.flatten()\nfor img, ax in zip(images, axes):\n    img = img \/ 255.\n    ax.imshow(img)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","53b916e3":"pos = np.count_nonzero(tr_labels==0)\nneg = np.count_nonzero(tr_labels==1)\ntotal = len(tr_labels)\nprint('class 0 : ' + str(pos))\nprint('class 1 : ' + str(neg))\nprint('total : ' +str(total))\n\nw_0 = (1\/pos)*(total)\/2\nw_1 = (1\/neg)*(total)\/2\n\nclass_weights = {0:w_0 ,1:w_1}\nprint(f'weight of class 0 : {w_0}')\nprint(f'weight of class 1 : {w_1}')","28ef52ab":"def build_model(name,suff):\n    \n    \"\"\"\n    name : (str) accepted values 'b0' , 'b1' , 'b2' , 'v2'\n    suff : (str) accepted values 'eff' , 'mb'\n    \"\"\"\n    #seresnet152, _ = Classifiers.get('seresnet152')\n    #base = seresnet152(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n    #base  = efficientnet.EfficientNetB0(include_top=False , weights='imagenet')\n    #pre = efficientnet.preprocess_input\n    \n    # for layers in eff_B2.layers:\n    #     print((layers.name , layers))\n    # function to freeze the batch normalization layers\n    def freeze_bn_layers(model):\n        for layers in model.layers:\n            if (layers.name).endswith('_bn'):\n                layers.trainable = False\n\n    # instantiating the preporcessing layers\n    if suff.startswith('eff'):\n        pre = efficientnet.preprocess_input\n    else:\n        pre = mobilenet_v2.preprocess_input\n    \n    # instantiating the base model based on name given\n    if name == 'b0':\n        base = efficientnet.EfficientNetB0(include_top=False , weights= 'imagenet')\n    elif name == 'b1':\n        base = efficientnet.EfficientNetB1(include_top=False , weights= 'imagenet')\n    elif name == 'b2':\n        base = efficientnet.EfficientNetB2(include_top=False , weights= 'imagenet')\n    else:\n        base = mobilenet_v2.MobileNetV2(include_top=False , weights='imagenet')\n        \n    freeze_bn_layers(base)\n    \n    inp = layers.Input(shape = (img_size, img_size, 3))\n    x = pre(inp)\n    x= base(x)\n    x= layers.GlobalAveragePooling2D()(layers.Dropout(0.16)(x))\n    #x = layers.Dense(128, 'relu')(x)\n    x= layers.Dropout(0.3)(x)\n    x= layers.Dense(1, 'sigmoid')(x)\n    return Model(inp, x)\n    ","751aca08":"def train_and_evaluate_model(name , label, model_suffix, class_weights=None):\n    with strategy.scope():\n        METRICS = [\n          tf.keras.metrics.TruePositives(name='tp'),\n          tf.keras.metrics.FalsePositives(name='fp'),\n          tf.keras.metrics.TrueNegatives(name='tn'),\n          tf.keras.metrics.FalseNegatives(name='fn'), \n          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n          tf.keras.metrics.Precision(name='precision'),\n          tf.keras.metrics.Recall(name='recall'),\n          tf.keras.metrics.AUC(name='auc'),\n          tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n        ]\n        model= build_model(name, model_suffix)\n        loss= tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0)\n        model.compile(optimizers.Adam(lr=lr),loss=loss,metrics=METRICS)\n        \n        name= 'NIH_' + label +'_' +model_suffix+'_'+name + '_moodel.h5'\n\n        rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n                                        min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n\n        ckp = ModelCheckpoint(name,monitor = 'val_loss',\n                              verbose = 1, save_best_only = True, mode = 'min')\n\n        es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                            restore_best_weights = True, verbose = 1)\n\n        steps_per_epoch = (tr_paths.shape[0] \/\/ batch_size)\n\n        history = model.fit(dtrain,                      \n                    validation_data=dvalid,                                       \n                    epochs=n_epochs,\n                    callbacks=[rlr,es,ckp],\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1)\n    \n    return model , history , steps_per_epoch","f723ce96":"def plot_loss(history):\n    plt.figure(figsize = (12, 6))\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.plot( history.history[\"loss\"], label = \"Training Loss\", marker='o')\n    plt.plot( history.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\n    plt.grid(True)\n    plt.legend()\n    plt.show()","f69f7ff0":"def plot_auc(history):\n    plt.figure(figsize = (12, 6))\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"AUC\")\n    plt.plot( history.history[\"auc\"], label = \"Training AUC\" , marker='o')\n    plt.plot( history.history[\"val_auc\"], label = \"Validation AUC\", marker='+')\n    plt.grid(True)\n    plt.legend()\n    plt.show()","c3bc72c1":"def extract_metric(history , df , name):\n    index = np.argmin(history.history['val_loss'])\n    \n    data_dict = {'name': name}\n    for m in history.history:\n        data_dict[m] = history.history[m][index]\n        \n    df = df.append(data_dict , ignore_index=True)\n    return df","d11631b8":"B0_model , historyB0 , sppB0 = train_and_evaluate_model('b0', Label , 'eff', class_weights)","68313593":"# plotting loss\nplot_loss(historyB0)","001918db":"# plotting AUC\nplot_auc(historyB0)","2b21c820":"name = Label + '_eff_B0'\nmetric_df = pd.DataFrame(columns=['name'] + [p for p in historyB0.history.keys()])","9423efb2":"metric_df = extract_metric(historyB0 , metric_df , name=name)","f8b25c42":"B1_model , historyB1 , sppB1 = train_and_evaluate_model('b1', Label , 'eff', class_weights)","a89454c7":"# plotting loss\nplot_loss(historyB1)","9dfa58a0":"# plotting AUC\nplot_auc(historyB1)","95f43180":"name = Label + 'eff_B1'\nmetric_df = extract_metric(historyB1 , metric_df , name=name)","1c26a0c9":"B2_model , historyB2 , sppB2 = train_and_evaluate_model('b2', Label , 'eff', class_weights)","f121a6be":"# plotting loss\nplot_loss(historyB2)","e2b7be3b":"# plotting AUC\nplot_auc(historyB2)","7b0d4ca5":"name = Label + 'eff_B2'\nmetric_df = extract_metric(historyB2 , metric_df , name=name)","a24bc113":"mb_model , history_mb , spp_mb = train_and_evaluate_model('v2', Label , 'mb', class_weights)","b6b4bd58":"# plotting loss\nplot_loss(history_mb)","13311696":"# plotting AUC\nplot_auc(history_mb)","83d4a7dd":"name = Label + 'mb_v2'\nmetric_df = extract_metric(history_mb , metric_df , name=name)","8df8c8af":"metric_df.to_csv('performance.csv')","278791c2":"# with strategy.scope():\n#     METRICS = [\n#       tf.keras.metrics.TruePositives(name='tp'),\n#       tf.keras.metrics.FalsePositives(name='fp'),\n#       tf.keras.metrics.TrueNegatives(name='tn'),\n#       tf.keras.metrics.FalseNegatives(name='fn'), \n#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n#       tf.keras.metrics.Precision(name='precision'),\n#       tf.keras.metrics.Recall(name='recall'),\n#       tf.keras.metrics.AUC(name='auc'),\n#       tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n#     ]\n#     model= build_model()\n#     loss= tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0)\n#     model.compile(optimizers.Adam(lr=lr),loss=loss,metrics=METRICS)\n    \n#     name= 'NIH_' + label +'_moodel.h5'\n\n#     rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n#                                     min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n\n#     ckp = ModelCheckpoint(name,monitor = 'val_loss',\n#                           verbose = 1, save_best_only = True, mode = 'min')\n\n#     es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n#                         restore_best_weights = True, verbose = 1)\n    \n","cd880afa":"# name= 'NIH_Cardiomegaly_moodel.h5'\n\n# rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n#                                 min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n        \n# ckp = ModelCheckpoint(name,monitor = 'val_loss',\n#                       verbose = 1, save_best_only = True, mode = 'min')\n        \n# es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n#                     restore_best_weights = True, verbose = 1)","e63c9f59":"# steps_per_epoch = (tr_paths.shape[0] \/\/ batch_size)\n# steps_per_epoch","b394ed40":"# history = model.fit(dtrain,                      \n#                     validation_data=dvalid,                                       \n#                     epochs=n_epochs,\n#                     callbacks=[rlr,es,ckp],\n#                     steps_per_epoch=steps_per_epoch,\n#                     verbose=1)","4b53b73e":"### a single function to compile and train the model","8280d66d":"## 2. EfficientnetB1","a9cb3cd6":"saving the metrics dataframe as csv","6fb38079":"# Data Preparation","950b6f47":"### Using mobileNets","574cb237":"### Calculating class weights for class imablamce","82583ffa":"## 4. MobileNetV2","09f38d93":"## 1. EfficientnetB0","321ef7a6":"# Final Training","66983b45":"### Function to extract the values of all the performance metrics","a179c10e":"# Training Pipeline","e6a4f2f1":"## 3. EfficientnetB2"}}