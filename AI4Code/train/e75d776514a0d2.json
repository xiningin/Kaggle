{"cell_type":{"567a50c5":"code","76f30a48":"code","2b970fab":"code","d6400ff7":"code","7c934f2e":"code","4090cbe6":"code","6e99c780":"code","0e11bbd2":"code","2982735c":"code","b9cf601d":"markdown","bb5a1ce2":"markdown","ffad94db":"markdown","005487a1":"markdown","d6fc67cb":"markdown","dec26e48":"markdown","76ae5468":"markdown","be8a2abc":"markdown"},"source":{"567a50c5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\nwarnings.filterwarnings('ignore')","76f30a48":"df=pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\nprint(df.shape)\ndf.head(10)","2b970fab":"train_df,test_df=train_test_split(df,test_size=0.15)\nprint(train_df.shape)\nprint(test_df.shape)","d6400ff7":"#Outlier Correction,Missing values,Scaling\ncolumns=['age','trestbps','chol','thalach','oldpeak'] #take only numerical columns\nss=StandardScaler() \n\ndef outlier_(X):\n    tmp=[]\n    Q3=train_df[X].quantile(0.75)\n    Q1=train_df[X].quantile(0.25)\n    IQR=Q3-Q1\n    lower=train_df[X][train_df[X]<Q1-1.5*IQR].values\n    upper=train_df[X][train_df[X]>Q3+1.5*IQR].values\n    return lower,upper   \n\noutlier_col=[] #Store column names that have outliers.\nfor i in columns:\n    l,u=outlier_(i)\n    if len(l)>0 or len(u)>0:\n        print('>>Feature {} contain outliers'.format(i))\n        outlier_col.append(i)\n    else:\n        print('Feature {} contain no outliers'.format(i))","7c934f2e":"iqr_values={} #To treat values in test data\ndef outlier_treatment(X):\n    Q3=train_df[X].quantile(0.75)\n    Q1=train_df[X].quantile(0.25)\n    IQR=Q3-Q1\n    lb=Q1-1.5*IQR\n    ub=Q1+1.5*IQR\n    train_df[X][train_df[X]<lb]=lb\n    train_df[X][train_df[X]>ub]=ub\n    iqr_values[X]=[lb,ub]\n\nfor i in outlier_col:\n    outlier_treatment(i)","4090cbe6":"X=train_df.drop('target',axis=1)\n\n#Rescale\nX[columns]=ss.fit_transform(X[columns])\nX=X.values\n\ny=train_df['target'].values","6e99c780":"\nparams={'C':[i for i in range(1,150,5)],\n       'penalty':['l1','l2','elasticnet']}\n\nsplits=5\nkf=StratifiedKFold(n_splits=splits)\n\nmodel_dict={}\nmodel_ix=0\n\nfor train_ix,test_ix in kf.split(X,y):\n    print('Fold: {}\/{}'.format(model_ix+1,splits))\n    train_data_X,train_data_y=X[train_ix],y[train_ix]\n    test_data_X,test_data_y=X[test_ix],y[test_ix]\n    \n    lr=LogisticRegression(class_weight='balanced')\n    gs=GridSearchCV(LogisticRegression(class_weight='balanced'),param_grid=params)\n    gs.fit(train_data_X,train_data_y)\n    best_model=gs.best_estimator_\n    \n    print('Validation Score: {:.3f}'.format(roc_auc_score(test_data_y,best_model.predict(test_data_X))))\n    print('-------------------------------------')\n    \n    #Save Model\n    model_dict['LogReg'+str(model_ix)]=best_model\n    model_ix+=1","0e11bbd2":"test_X=test_df.drop('target',axis=1)\ntest_y=test_df['target']\n\nfor col in outlier_col:\n    test_X[col][test_X[col]>iqr_values[col][1]]=iqr_values[col][1]\n    test_X[col][test_X[col]<iqr_values[col][0]]=iqr_values[col][1]\n    \ntest_X[columns]=ss.transform(test_X[columns])","2982735c":"predictions=np.zeros((len(test_X),5))\nfor ix,k in enumerate(model_dict):\n    p=model_dict[k].predict(test_X)\n    predictions[:,ix]=p\n\npredictions=[1 if p>=0.5 else 0 for p in predictions.mean(axis=1)]\nprint('Test Score: {:.3f}'.format(roc_auc_score(test_y,predictions)))","b9cf601d":"# Load Libraries","bb5a1ce2":"# Stratified_KFold + GridSearch\n* With each fold, we will tune the model and save it\n* Use all saved models from the K folds to make averaging classifier","ffad94db":"# Read Data","005487a1":"# Divide Data","d6fc67cb":"* Nothing Fancy and technical done in this notebook, we just used 3 things:\n  * > Cross Validation\n  * > Grid Search\n  * > Averaging\n\n**Fin**","dec26e48":"# Preprocess Test Data","76ae5468":"# Make Test Predictions","be8a2abc":"# Basic Preprocessing\n\n* Treat Outliers\n* Scale data"}}