{"cell_type":{"61ba55c0":"code","3ee588c1":"code","21162a99":"code","182d0d82":"code","8b30581c":"code","c312d23f":"code","72533d9a":"code","96685a62":"code","4d92e37d":"code","8be3fd15":"code","7c943296":"code","fba1bcf6":"code","3b175292":"code","02151534":"code","58a1a151":"code","0292874d":"code","5b2971aa":"code","7f673d69":"code","57d380c1":"code","e0f52151":"code","b79f9c8c":"code","b1b24235":"code","13fa081f":"code","0234183f":"code","0465ec0f":"code","3ea087d2":"code","af09416b":"code","c0ce9523":"code","f6518a74":"code","c3354118":"code","cef253c8":"code","c0911263":"code","1b9d3e74":"code","331084da":"code","b47ee803":"code","c1cb5cda":"code","def1c875":"code","3deab4fe":"code","99c7c423":"code","3b145c54":"code","5a349021":"markdown","38ab27a8":"markdown","584e67ad":"markdown","d663e4c2":"markdown","4d98aaa9":"markdown","6f18be2f":"markdown","f455394e":"markdown","5a5476a2":"markdown","eee46ac5":"markdown","593ffd7e":"markdown","d15aff12":"markdown","db1cc8ee":"markdown","b4a02877":"markdown","1a2f2713":"markdown","1bd6e080":"markdown","0abeee6f":"markdown","772ea78a":"markdown","3f06a80c":"markdown","5d7105c7":"markdown","d07a5ff3":"markdown","ff185826":"markdown","6a7229af":"markdown","27667e75":"markdown","ff19e616":"markdown","bc30bc01":"markdown","9fe9009b":"markdown","3f015edc":"markdown","9b67f323":"markdown","110d80e5":"markdown","d0a736dc":"markdown","9bc7fe8f":"markdown","8e27c529":"markdown","61d244e7":"markdown","313a934a":"markdown"},"source":{"61ba55c0":"from IPython.display import YouTubeVideo,HTML\nYouTubeVideo(\"IAQp2Zuqevc\", width=700, height=500)","3ee588c1":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns\nimport random\nimport cv2\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as tt\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split, DataLoader\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\nimport os","21162a99":"data_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray'\n\nprint(os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"\/train\")\nprint(classes)","182d0d82":"pneumonia_files = os.listdir(data_dir + \"\/train\/PNEUMONIA\")\nprint('No. of training examples for Pneumonia:', len(pneumonia_files))\nprint(pneumonia_files[:5])","8b30581c":"normal_files = os.listdir(data_dir + \"\/train\/NORMAL\")\nprint('No. of training examples for Normal:', len(normal_files))\nprint(normal_files[:5])","c312d23f":"dataset = ImageFolder(data_dir+'\/train', \n                      transform=tt.Compose([tt.Resize(255),\n                                            tt.CenterCrop(224),\n                                            tt.RandomHorizontalFlip(),\n                                            tt.RandomRotation(10),\n                                            tt.RandomGrayscale(),\n                                            tt.RandomAffine(translate=(0.05,0.05), degrees=0),\n                                            tt.ToTensor()\n                                            #tt.Normalize(mean=[0.485, 0.456, 0.406], \n                                            #std=[0.229, 0.224, 0.225] ,inplace=True)\n                                           ]))\n","72533d9a":"dataset","96685a62":"img, label = dataset[0]\nprint(img.shape, label)\nimg","4d92e37d":"print(dataset.classes)","8be3fd15":"# number of images for each class\n\ntrain_samplesize = pd.DataFrame.from_dict(\n    {'Normal': [len([os.path.join(data_dir+'\/train\/NORMAL', filename) \n                     for filename in os.listdir(data_dir+'\/train\/NORMAL')])], \n     'Pneumonia': [len([os.path.join(data_dir+'\/train\/PNEUMONIA', filename) \n                        for filename in os.listdir(data_dir+'\/train\/PNEUMONIA')])]})\n\n\nsns.barplot(data=train_samplesize).set_title('Training Set Data Inbalance', fontsize=20)\nplt.show()","7c943296":"import matplotlib.pyplot as plt\n%matplotlib inline \n\ndef show_example(img, label):\n    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n    plt.imshow(img.permute(1, 2, 0))\n    \nshow_example(*dataset[4])","fba1bcf6":"\n# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,8))\n    for i in range(len(samples)):\n        image = cv2.cvtColor(imread(samples[i]), cv2.COLOR_BGR2RGB)\n        ax[i\/\/5][i%5].imshow(image)\n        if i<5:\n            ax[i\/\/5][i%5].set_title(\"Normal\", fontsize=20)\n        else:\n            ax[i\/\/5][i%5].set_title(\"Pneumonia\", fontsize=20)\n        ax[i\/\/5][i%5].axis('off')","3b175292":"## Plot training samples\nrand_samples = random.sample([os.path.join(data_dir+'\/train\/NORMAL', filename) \n                              for filename in os.listdir(data_dir+'\/train\/NORMAL')], 5) + \\\n    random.sample([os.path.join(data_dir+'\/train\/PNEUMONIA', filename) \n                   for filename in os.listdir(data_dir+'\/train\/PNEUMONIA')], 5)\n\nplot_samples(rand_samples)\nplt.suptitle('Training Set Samples', fontsize=30)\nplt.show()","02151534":"# set random seed so we get the same sampling every time for reproducibility\n\nrandom_seed = 2020\ntorch.manual_seed(random_seed);","58a1a151":"train_size = round(len(dataset)*0.7) # 70%\nval_size = len(dataset) - train_size # 30%\n\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nlen(train_ds), len(val_ds)","0292874d":"batch_size=128\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)","5b2971aa":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:60], nrow=10).permute(1, 2, 0))\n        break\n        \nshow_batch(train_dl)","7f673d69":"torch.cuda.is_available()","57d380c1":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndevice = get_default_device()\ndevice","e0f52151":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","b79f9c8c":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device) # yield will stop here, perform other steps, and the resumes to the next loop\/batch\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","b1b24235":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds)), preds\n\ndef F1_score(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    \n    # precision, recall, and F1\n    cm  = confusion_matrix(labels, preds)\n    tn, fp, fn, tp = cm.ravel()\n    precision = tp\/(tp+fp)\n    recall = tp\/(tp+fn)\n    f1 = 2*((precision*recall)\/(precision+recall))\n    \n    return precision,recall,f1,preds","13fa081f":"class PneumoniaModelBase(nn.Module):\n    \n    # this is for loading the batch of train image and outputting its loss, accuracy \n    # & predictions\n    def training_step(self, batch, weight):\n        images,labels = batch\n        out = self(images)                                      # generate predictions\n        loss = F.cross_entropy(out, labels, weight=weight)      # weighted compute loss\n        acc,preds = accuracy(out, labels)                       # calculate accuracy\n        \n        return {'train_loss': loss, 'train_acc':acc}\n       \n    # this is for computing the train average loss and acc for each epoch\n    def train_epoch_end(self, outputs):\n        batch_losses = [x['train_loss'] for x in outputs]       # get all the batches loss\n        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n        batch_accs = [x['train_acc'] for x in outputs]          # get all the batches acc\n        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n        \n        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n    \n    # this is for loading the batch of val\/test image and outputting its loss, accuracy, \n    # predictions & labels\n    def validation_step(self, batch):\n        images,labels = batch\n        out = self(images)                                      # generate predictions\n        loss = F.cross_entropy(out, labels)                     # compute loss\n        acc,preds = accuracy(out, labels)                       # calculate acc & get preds\n        \n        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n                'preds':preds.detach(), 'labels':labels.detach()}\n    # detach extracts only the needed number, or other numbers will crowd memory\n    \n    # this is for computing the validation average loss and acc for each epoch\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]         # get all the batches loss\n        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n        batch_accs = [x['val_acc'] for x in outputs]            # get all the batches acc\n        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n        \n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n    # this is for printing out the results after each epoch\n    def epoch_end(self, epoch, train_result, val_result):\n        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.\n              format(epoch+1, train_result['train_loss'], train_result['train_acc'],\n                     val_result['val_loss'], val_result['val_acc']))\n    \n    # this is for using on the test set, it outputs the average loss and acc, \n    # and outputs the predictions\n    def test_prediction(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()           # combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()              # combine accuracies\n        # combine predictions\n        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n        # combine labels\n        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n        \n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n                'test_preds': batch_preds, 'test_labels': batch_labels}      ","0234183f":"resnet50 = models.resnet50(pretrained=True)\n#resnet50","0465ec0f":"class PneumoniaResnet(PneumoniaModelBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet50(pretrained=True)\n        # Freeze training for all layers before classifier\n        for param in self.network.fc.parameters():\n            param.require_grad = False  \n        num_features = self.network.fc.in_features # get number of in features of last layer\n        self.network.fc = nn.Linear(num_features, 2) # replace model classifier\n    \n    def forward(self, xb):\n        return self.network(xb)\n    \n#     def freeze(self):\n#         # To freeze the residual layers\n#         for param in self.network.parameters():\n#             param.require_grad = False\n#         for param in self.network.fc.parameters():\n#             param.require_grad = True\n    \n#     def unfreeze(self):\n#         # Unfreeze all layers\n#         for param in self.network.parameters():\n#             param.require_grad = True","3ea087d2":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit(epochs, lr, model, train_loader, val_loader, weight, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache() # release all the GPU memory cache\n    history = {}\n    \n#    Set up cutom optimizer with weight decay\n#    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n\n#     Set up one-cycle learning rate scheduler\n#     sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n#                                                 steps_per_epoch=len(train_loader))\n#   sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n    \n    optimizer = opt_func(model.parameters(), lr)\n\n    best_loss = 1 # initialize best loss, which will be replaced with lower better loss\n    for epoch in range(epochs):\n        \n        # Training Phase \n        model.train() \n        train_outputs = []      \n        lrs = []\n        \n        for batch in train_loader:\n            outputs = model.training_step(batch, weight)\n            loss = outputs['train_loss']                          # get the loss\n            train_outputs.append(outputs)\n            # get the train average loss and acc for each epoch\n            train_results = model.train_epoch_end(train_outputs)                        \n            loss.backward()                                       # compute gradients\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()                                      # update weights\n            optimizer.zero_grad()                                 # reset gradients  \n            \n#             Record & update learning rate\n#             lrs.append(get_lr(optimizer))\n#             sched.step()\n        \n        # Validation phase\n        val_results = evaluate(model, val_loader)\n        \n        # Save best loss\n        if val_results['val_loss'] < best_loss and epoch + 1 > 15:\n            best_loss = min(best_loss, val_results['val_loss'])\n            best_model_wts = copy.deepcopy(model.state_dict())\n            #torch.save(model.state_dict(), 'best_model.pt')\n        \n        # print results\n        model.epoch_end(epoch, train_results, val_results)\n        \n        # save results to dictionary\n        to_add = {'train_loss': train_results['train_loss'],\n                  'train_acc': train_results['train_acc'],\n                 'val_loss': val_results['val_loss'],\n                  'val_acc': val_results['val_acc'], 'lrs':lrs}\n        \n        # update performance dictionary\n        for key,val in to_add.items():\n            if key in history:\n                history[key].append(val)\n            else:\n                history[key] = [val]\n    \n    model.load_state_dict(best_model_wts)                         # load best model\n    \n    return history, optimizer, best_loss","af09416b":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\n\nmodel = to_device(PneumoniaResnet(), device)","c0ce9523":"epochs = 20\nlr = 0.0001\ngrad_clip = None\nweight_decay = 1e-4\nopt_func = torch.optim.Adam\n# weighted loss for data class imbalance\nweight = torch.FloatTensor([3876\/(1342+3876), 1342\/(1342+3876)]).to(device)\n","f6518a74":"history, optimizer, best_loss = fit(epochs, lr, model, train_dl, val_dl, weight, \n                                    grad_clip=grad_clip, \n                                    weight_decay=weight_decay, \n                                    opt_func=opt_func)","c3354118":"print('Best loss is:', best_loss)","cef253c8":"# Save Model\nbestmodel = {'model': PneumoniaResnet(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(bestmodel, 'PneumoniaResnet.pth')","c0911263":"# this is for loading the model from a previously saved one\n\ndef load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n\n    model.eval()\n    return model\n\n#model = load_checkpoint('.\/PneumoniaResnet.pth')","1b9d3e74":"# Plot Accuracy and Loss \n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,epochs+1))\nax1.plot(epoch_list, history['train_acc'], label='Train Accuracy')\nax1.plot(epoch_list, history['val_acc'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs+1, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, history['train_loss'], label='Train Loss')\nax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, epochs+1, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","331084da":"# number of images for each class\n\ntest_samplesize = pd.DataFrame.from_dict(\n    {'Normal': [len([os.path.join(data_dir+'\/test\/NORMAL', filename) \n                     for filename in os.listdir(data_dir+'\/test\/NORMAL')])], \n     'Pneumonia': [len([os.path.join(data_dir+'\/test\/PNEUMONIA', filename) \n                        for filename in os.listdir(data_dir+'\/test\/PNEUMONIA')])]})\n\nsns.barplot(data=test_samplesize).set_title('Test Set Data Inbalance', fontsize=20)\nplt.show()","b47ee803":"@torch.no_grad()\ndef test_predict(model, test_loader):\n    model.eval()\n    # perform testing for each batch\n    outputs = [model.validation_step(batch) for batch in test_loader] \n    results = model.test_prediction(outputs)                          \n    print('test_loss: {:.4f}, test_acc: {:.4f}'\n          .format(results['test_loss'], results['test_acc']))\n    \n    return results['test_preds'], results['test_labels']","c1cb5cda":"test_dataset = ImageFolder(data_dir+'\/test', \n                           transform=tt.Compose([tt.Resize(255),\n                                                 tt.CenterCrop(224),                                                              \n                                                 tt.ToTensor()\n                                                 #tt.Normalize(mean=[0.485, 0.456, 0.406], \n                                                 #             std=[0.229, 0.224, 0.225],\n                                                 #             inplace=True)\n                                                ]))","def1c875":"# Evaluate test set\n\ntest_dl = DataLoader(test_dataset, batch_size=256)\ntest_dl = DeviceDataLoader(test_dl, device)\npreds,labels = test_predict(model, test_dl)","3deab4fe":"# Plot confusion matrix\ncm  = confusion_matrix(labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.xlabel('Predicted Label',fontsize=18)\nplt.ylabel('True Label',fontsize=18)\nplt.show()","99c7c423":"# Compute Performance Metrics\ntn, fp, fn, tp = cm.ravel()\n\naccuracy = (np.array(preds) == np.array(labels)).sum() \/ len(preds)\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\nf1 = 2*((precision*recall)\/(precision+recall))\n\nprint(\"Accuracy of the model is {:.2f}\".format(accuracy))\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))\nprint(\"F1 Score of the model is {:.2f}\".format(f1))","3b145c54":"# select 5 normal and 5 pneumonia images indices\nidxs = torch.tensor(np.append(np.arange(start=0, stop=5, step=1), \n                             np.arange(start=500, stop=505, step=1))) \n\nfig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,14))\n\nfor c,i in enumerate(idxs):\n    img_tensor, label = test_dataset[i]\n    ax[c\/\/5][c%5].imshow(img_tensor[0,:,:], cmap='gray')\n    ax[c\/\/5][c%5].set_title('Label: {}\\nPrediction: {}'\n                            .format(test_dataset.classes[label], \n                                    test_dataset.classes[preds[i]]),\n                            fontsize=25)\n    ax[c\/\/5][c%5].axis('off')\n    ","5a349021":"We then define some helper functions to select which device to use depending on whether the GPU is available or not, and another to move our data and models to the device.","38ab27a8":"Next, we get a measure of how well our model is performing by evaluating several metrics of the predictions against the actual target_labels. \n\n**Accuracy** is not a good evaluation metric when there is huge **data class imbalance**. Imagine that if we have 100 samples: 99 pneumonia and 1 normal, then a model that predicts everything as pneumonia will get an accuracy of 99%. In this case, its better to look at **precision and recall**, and their harmonic mean, the **F1 score**. \n\nThis can be visualized using a confusion matrix as well.\n\n<img src = 'https:\/\/bk9zeg.bn.files.1drv.com\/y4mZtoVgcWgAYE59g3lpWQ3PaZWMqnDN7gz1ir2LIgyPjR6a26Ij1vDBmjsETpEmvAkebvyLjSVofcRVSjW8Ux62r8_tIyIK6AZJ7GQOz_sWtAj_hdQIA57pbJaEpHJEeY_pG7odhdU1osvM7jHXfFzpVsIOt76oqNe39j4KZIFRDOguHUr5jPtDe0TIzNTLQuehcuQdw-aIjt7FR9D6Ti9-A?width=618&height=419&cropmode=none' width=\"600\">","584e67ad":"<a id='Evaluation_metrics'><\/a>\n# 8. Model Evaluation Metrics","d663e4c2":"Before we begin, let's watch a video to get an idea of what is pneumonia!","4d98aaa9":"# **Pneumonia Detection Using ResNet Transfer Learning (Pytorch)** <br>\nAuthor: TeYang, Lau<br>\nCreated: 13\/7\/2020<br>\nLast update: 14\/7\/2020<br>\n\n<img src = 'https:\/\/cdn.mos.cms.futurecdn.net\/Uv5aXbwKSZMQz8WNviVb3X.jpg' width=\"900\">\n<br>\n\nThis kernel was created after my dive into using **Pytorch**. PyTorch is python native, and integrates easily with other python packages, which makes this a simple choice for researchers. Many researchers use Pytorch because the API is intuitive and easier to learn, and get into experimentation quickly, rather than reading through documentation.\n\nHere, I am using **Residual Network** (ResNet) via **transfer learning**, a popular deep learning neural network model, to classify Pneumonia chest X-ray scans. This dataset consists of around 5,000 and 600 images in the training and testing set respectively. It is quite small by today's big era standard, and it presents some challenges such as data imbalance that I will attempt to mitigate. By leveraging the power of transfer learning, we are able to 'transfer' the weights of low-level features (e.g., lines, shapes, etc) that were detected in a pretrained model. Doing so saves us the need to train a model from scrach, which can be challenging for those who do not have a 'big' enough dataset or computational resources.\n\nThroughout this kernel, I will try to explain the details of the code, so that people who are new can get something away from it!\n\n\nThe process is as follows:\n1. [Data Loading and Structure](#Data_loading_structure)\n2. [Preparing Train, Validation & Test Data](#Preparing_data)\n3. [Set Up GPU](#GPU)\n4. [Creating Model Class](#ModelClass)\n5. [Train and Evaluate Model](#Train_model)    \n6. [Accuracy and Loss Plots](#Accuracy_loss_plots)\n7. [Predicting on Test Set](#Predict_test)\n8. [Model Evaluation Metrics](#Evaluation_metrics)\n9. [Plot Predictions against Actual Labels](#Plot_predictions)\n10. [Conclusion](#Conclusion)<br><br>\n","6f18be2f":"<a id='Train_model'><\/a>\n# 5. Train and Evaluate Model","f455394e":"<img src = 'https:\/\/www.researchgate.net\/publication\/331364877\/figure\/fig3\/AS:741856270901252@1553883726825\/Left-ResNet50-architecture-Blocks-with-dotted-line-represents-modules-that-might-be.png' width=\"600\">\n\n<br>\n\nFrom [Ji et al.(2019)](https:\/\/www.researchgate.net\/publication\/331364877_Optimized_Deep_Convolutional_Neural_Networks_for_Identification_of_Macular_Diseases_from_Optical_Coherence_Tomography_Images)","5a5476a2":"<a id='Predict_test'><\/a>\n# 7. Predicting on Test Set\n\nIt's time to test our model on the test set and see how well it performs on data that **it has not seen before**. This is important, as we want a model that can generalize to other datasets other than what it is trained on. A model that only does well on the training and validation dataset but not on a testing dataset is not a useful one.","eee46ac5":"Let's load the ResNet50 model and inspect it. I did not print it out here because it is very long. It has 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer. Note that the network has an `AdaptiveAvgPool2d` layer. This allows us to input images of any size into the model.","593ffd7e":"Let's look at an example of an image in its tensor form. Note that after being loaded, each image is now [3, 224, 224], with 3 being the RGB channels.","d15aff12":"Let's plot out some images with their labels. Notice the data augmentation being applied. During training, this image might be transformed to this form, but in another epoch, this image will receive another random transformation, and this DIVERSIFIES the dataset, since the model is not receiving each image in the same 'form' every epoch.","db1cc8ee":"<a id='Plot_predictions'><\/a>\n# 9. Plot Predictions against Actual Labels\n\n\nNext, we print out some of the images and their respective predictions.","b4a02877":"Next, I plot out some images according to their labels, from the directory (not from the transformed dataset) as it is easier to separate between the classes. \n\nCan you see any difference between the scans? Personally, I cannot since I am not a trained medical doctor specializing in pneumonia diagnosis. However, some expert practitioners might also encounter problems making correct diagnosis. And this is where deep learning comes in. It can help make the process faster and more efficient for practitioners by first separating scans that have a high and low probability of classification. For those with low probability, expert diagnoses can then be sought from the practitioners. It can even have the potential to identify and inform new ways to diagnosing diseases that were not known before.","1a2f2713":"Next we create the class to setup the model.\n\nInside the __init__ constructor method, we load the **ResNet50** model, setting the `pretrained` parameter to true to load the pretrained weights. We then freeze the starting layers of the network (except the fully connected layer) and replaced the last layer (fc) with our own as our output has only 2 classes, whereas the ResNet50 was trained to output 1000 classes (refer to the model above).\n\nThe forward method is invoked when we pass a batch of inputs to the model.","1bd6e080":"Finally, it's time to train and evaluate our model on the entire train and validation sets.\n\nConfigurations like `batch size`, `learning rate` etc. need to picked in advance while training machine learning models, and are called **hyperparameters**. Picking the right hyperparameters is critical for training an accurate model within a reasonable amount of time, and is an active area of research and experimentation. Feel free to try different learning rates and see how it affects the training process.","0abeee6f":"Here we select a batch size of 128 to perform mini_batch gradient descent\/or other optimizers. This is a hyperparameter that can be tuned. The batch size means that the 3651 train images will be divided into batches of 128 images and gradient descent will be performed on each of this 128 images in one epoch (1 runthrough of the whole data).","772ea78a":"<a id='Data_loading_structure'><\/a>\n# 1. Data Loading and Structure\n\nWe start by loading the dependencies and data, and exploring the dataset to look at its structure. We also print some images to get a hang of it.","3f06a80c":"<a id='Conclusion'><\/a>\n# 10. Conclusion\n\nIn conclusion, our model performed reasonably well, as it manages to predict most of the pneumonia images. This is important as in healthcare diagnosis, accurate prediction of diseases saves lives. However, false positives can also increase the cost of healthcare, as more people with diseases are diagnosed with diseases. It can also lead to panic and affect people's physical and mental well-being. Better performance can be achieved with better tuning of the model hyperparameters. This is an iterative process, with lots of trial and error.\n\nBelow are some of the difficulties that I faced for this dataset:\n\n* **Data class imbalance:** This is quite prevalent in the real world and as data scientists, we should all learn to embrace it and find ways to get around this problem. Usually, one way is to simply collect more data for the undersampled class. However, this is not possible for this dataset and especially for healthcare data, which is very difficult to collect and share. In this kernel, I used weighted loss to give more weights to the loss of the normal images. This weighting can be tuned as well to achieve the optimal performance. Stratified sampling is also important in this case, but pytorch does not yet have any built-in functions.\n\n* **Overfitting:** This dataset is prone to overfitting as seen by the train and validation plots. Therefore, I only selected the model weights that achieved the best\/lowest validation loss. However, sometimes the best validation loss are achieved in the early epochs, and it performs very badly on the test set, probably due to class imbalance when batching or sampling. For that reason, I have chosen to select the best validation loss only after certain epochs. I am not sure if this is a valid method. Please let me know if anyone has any comments on it!\n\nHere are some other methods that I tried but did not improve or even hurt performance:\n\n* **Learning rate scheduling using:** \n   * [**Step learning rate:**](https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/optim\/lr_scheduler.html#StepLR) decays the learning rate of each parameter group by gamma every setp_size epochs.\n   * [**One fit cycle:**](https:\/\/pytorch.org\/docs\/stable\/_modules\/torch\/optim\/lr_scheduler.html#OneCycleLR) The 1cycle policy anneals the learning rate from an initial learning rate to some maximum learning rate and then from that maximum learning rate to some minimum learning rate much lower than the initial learning rate. This policy was initially described in the paper [Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates](https:\/\/arxiv.org\/abs\/1708.07120). Refer to this [post](https:\/\/sgugger.github.io\/the-1cycle-policy.html) to get a better understanding.\n* **Gradient Clipping:**  rescale\/limit the values of gradients to a small range below a threshold to prevent undesirable changes in parameters due to large gradient values (exploding gradients), which makes the model unstable. Refer to this [post](https:\/\/towardsdatascience.com\/what-is-gradient-clipping-b8e815cdfb48) for a better understanding.\n* **Weight Decay:** a regularization technique which prevents the weights from becoming too large by adding an additional term (a tunable constant, aka weight decay multiplied by the sum of squares of our model parameters\/weights) to the loss function. Refer to this [post](https:\/\/towardsdatascience.com\/this-thing-called-weight-decay-a7cd4bcfccab) for a better understanding. `Loss = MSE(y_hat, y) + wd * sum(w^2)`\n\nThat's it for now. If you like the kernel or learned something from it, please upvote it! Feel free to also check out my other kernels below. Good luck in your deep learning!","5d7105c7":"<a id='ModelClass'><\/a>\n# 4. Creating Model Class\n\nFinally it's time to create our model. We start by creating a class to initialize our model.\n\nBut first, we create some functions to calculate the metrics for our model performance.","d07a5ff3":"<a id='GPU'><\/a>\n# 3. Set Up GPU\n\nNow we set up the GPU so that training can be done faster. As the sizes of our models and datasets increase, we need to use GPUs to train our models within a reasonable amount of time. GPUs contain hundreds of cores that are optimized for performing expensive matrix operations on floating point numbers in a short time, which makes them ideal for training deep neural networks with many layers. [Kaggle](https:\/\/www.kaggle.com\/) and [Google Colab](https:\/\/colab.research.google.com\/) provide GPUs for limited free usage while [Google Cloud Platform](https:\/\/cloud.google.com\/) and [Amazon Web Services](https:\/\/aws.amazon.com\/) among others provide GPU-powered machines for rent.\n\nWe can check if a GPU is available and the required NVIDIA CUDA drivers are installed using `torch.cuda.is_available`. ","ff185826":"This dataset is well structured for most deep learning frameworks. It is organized into train, val, and test folders, which contains subfolders of the classes of pneumonia (normal, pneumonia), each containing the respective jpeg images.","6a7229af":"<a id='Accuracy_loss_plots'><\/a>\n# 6. Accuracy and Loss Plots\n\nWe made plots of the accuracy and loss for the training and validation data. This gives us an idea of how our model is performing (e.g., underfitting, overfitting).","27667e75":"Let's visualize a batch of data in a grid using the make_grid function from torchvision. We'll also use the `.permute` method on the tensor to move the channels to the last dimension, as expected by matplotlib.","ff19e616":"We can get the classes by using the `.classes` on the dataset.","bc30bc01":"<font size=\"+3\" color=\"steelblue\"><b>My other works<\/b><\/font><br>\n\n<div class=\"row\">\n  <div class=\"col-sm-4\">\n    <div class=\"card\">\n      <div class=\"card-body\" style=\"width: 20rem;\" style='background:red'>\n        <h5 class=\"card-title\"><u>120 Dog Breeds Classification<\/u><\/h5>\n        <img style='width:250px' src=\"https:\/\/raw.githubusercontent.com\/teyang-lau\/Dog_Breeds_Classification_CNN\/master\/Pictures\/dogbreeds.jpg\" class=\"card-img-top\" alt=\"...\"><br>\n        <p class=\"card-text\">Dog Breeds Classification using Transfer Learning via Inception V3.<\/p>\n        <a href=\"https:\/\/www.kaggle.com\/teyang\/dog-breeds-classification-using-transfer-learning?scriptVersionId=35621180\" class=\"btn btn-primary\" style=\"color:white;\">Go to Post<\/a>\n      <\/div>\n    <\/div>\n  <\/div>\n    \n  <div class=\"col-sm-4\">\n    <div class=\"card\">\n      <div class=\"card-body\" style=\"width: 20rem;\">\n         <h5 class=\"card-title\"><u>Covid-19 & Google Trends<\/u><\/h5>\n         <img style='height:135px' src=\"https:\/\/miro.medium.com\/max\/821\/1*Fi6masemXJT3Q8YWekQCDQ.png\" class=\"card-img-top\" alt=\"...\"><br>\n         <p class=\"card-text\">Covid-19-Google Trend Analysis and Data Vizualization<\/p>\n         <a href=\"https:\/\/www.kaggle.com\/teyang\/covid-19-google-trends-auto-arima-forecasting\" class=\"btn btn-primary\" style=\"color:white;\">Go to Post<\/a>\n      <\/div>\n    <\/div>\n  <\/div>  \n    \n  <div class=\"col-sm-4\">\n    <div class=\"card\">\n      <div class=\"card-body\" style=\"width: 20rem;\">\n         <h5 class=\"card-title\"><u>Neural Net with MNIST Pytorch<\/u><\/h5>\n         <img style='height:170' src=\"https:\/\/www.kaggleusercontent.com\/kf\/38574776\/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..2w3cv3Az2uSvI27xHWQIZQ.9WZNOk05K_N3eAUxuFagLubggjqDTyLqSDNYBu8XZjeCnCEaY_YxBQh58uYs9Ty_IG791GX2fOuYuG_A747PBEjPfqZ9tTbPehQolfUeq7aqKyei4nXcVu_lqtyCb4mpr4JTfwvugwlv2E-Lreba6bw3WpYmVEAb0ug8VbaxnxLX6_mUKVlNAZVyzv7tUHtvaKr-D_2MipZXaS1UGFCAnYoPcHb1156QkYPnYuy5YrT0OGf9Dre3Yk681dwrMYDUwyP8_TT1tN3PrgAUj1zlLoWsSzLaAET2AFiOQTHO6vhHEi41JIuFatx9Bu-67c54RNoJW_TqffKzAmgwJsO4F27xSlz30Q128NUYUex5qGeluHvy1d_ILODFaz3Z9We9jGmmkpT2xx2H1UdlV_wa3SU9rdDh05yTt3aaBFZjUNuvHpKztPO12uvO-wN_d0decitVVr5b4EGZsWs_zPyW-WMsORtb94TKVlIh9M0z5OnWOPkslNc1rxTQ30Zi8DWYiZ-A0rV791N7TznHZ51kNdtu9EfuBdqU9KeCxGf8eaNCEEDAe43UxE_KWUGxv98Xa_DtAn1MjhMx_3ogHGwtoReIU-4Mpcbc4jZrF3vVZpDu9xI4_zuNhmO8RitQ7RdeHVvd9eFYp0O0o-R_TNCdGQikpui_kWSBYXNb1YgwmwI.vUV8oTsXy5Eu6SwO9aM_OA\/__results___files\/__results___14_1.png\" class=\"card-img-top\" alt=\"...\"><br><br>\n         <p class=\"card-text\">MNIST classification with Neural Network using Pytorch<\/p>\n         <a href=\"https:\/\/www.kaggle.com\/teyang\/neural-network-mnist-using-pytorch\" class=\"btn btn-primary\" style=\"color:white;\">Go to Post<\/a>\n      <\/div>\n    <\/div>\n  <\/div>  ","9fe9009b":"<a id='Preparing_data'><\/a>\n# 2. Preparing Train, Validation & Test Data\n\nNow it's time to prepare our training, validation and testing dataset. We do this using the random_split function in torch. Here we split the train dataset into 70% train and 30% validation. Note that Pytorch doesn't have any built-in functions for stratified sampling, meaning that each sample will have the same proportion of classes as the original. There are a few written functions contributed by the community ([stratified sampling](https:\/\/github.com\/jaideep11061982\/Stratified_sampler_fastai\/blob\/master\/batch_sampler.py)), but I have not tried it out yet. \n\n1. **Training set** - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n2. **Validation set** - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n3. **Test set** - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.","3f015edc":"Our model is performing quite well with a F1-score of about 90%. Precision is lower than recall, but this is expected due to the data class imbalance. The weightings can perhaps we tuned to improve the precision. However, recall and precision is balance and one has to be sacrificed for the other.","9b67f323":"Now we define the helper functions to fit and evaluate the model.\n\n* **evaluate**: this simply calls the validation functions we defined in the base model class above and returns the output. This function is called inside the **fit** function.\n\n* **get_lr**: for getting the learning rate of each epoch, so that one can store them if a learning rate scheduler is used, to keep track of the changes.\n\n* **fit**: this is the main function to fit the model. We pass in our model and dataloaders and other hyperparameters. There are some codes that were commented out. These are some other methods that I tried but they did not seem to help with performance, such as weight decay, gradient clipping and one-cycle learning rate scheduler.\n\n* `model.eval()` set specific layers like dropout and batchnorm to evaluation mode (dropout won\u2019t drop activations, batchnorm will use running estimates instead of batch statistics) while `model.train()` will enable them.\n\n* `torch.no_grad()` impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but we won\u2019t be able to backprop (which we don\u2019t want in an evaluation  phase).","110d80e5":"There appears to be **data class imbalance** in our dataset, with pnuemonia images having more samples compared to normal images. This is an issue as it will become harder for the model to generalize well as the model might get overfitted to a dominant class during training and thus perform badly when it sees a new dataset. I will try to compensate for this by weighting the loss of each class\/label. This means that for the normal images, they will be given a higher weighting when evaluating the loss, and pneumonia images will be given a lower weighting.","d0a736dc":"Before we train the model, we need to ensure that the data and the model's parameters (weights and biases) are on the same device (CPU or GPU). We can reuse the to_device function to move the model's parameters to the right device. This is important and is a step that is usually forgotten and will cause error.","9bc7fe8f":"Here, we define a `DeviceDataLoader` class to wrap our existing data loaders and move data to the selected device, as batches are accessed. Interestingly, we don't need to extend an existing class to create a PyTorch dataloader. All we need is an `__iter__` method to retrieve batches of data, and an `__len__` method to get the number of batches.","8e27c529":"### ResNet\n\nA [**Residual Network**](https:\/\/arxiv.org\/abs\/1512.03385) is just like any other CNN network architecture, except that they use a **residual block**. This adds the original input back to the output feature map obtained by passing the input through one or more convolutional layers: \n\n<img src = 'https:\/\/miro.medium.com\/max\/1140\/1*D0F3UitQ2l5Q0Ak-tjEdJg.png' width=\"400\">\n\n<br>\nThis small change produces a drastic improvement in performance. It allows deeper networks to be trained without hurting performance as some layers can be skipped (residual blocks are also called skip-connections). You can refer to this blogpost to get a better understanding of how ResNet works:\n\nhttps:\/\/towardsdatascience.com\/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec \n\n","61d244e7":"Now let us transform the images. Pytorch requires us to transform the images into tensors before loading the images when we need it for training. Doing so means that images are not all loaded at once, consuming most of your memory.\n\nPyTorch datasets also allow us to specify one or more transformation functions which are applied to the images as they are loaded. `torchvision.transforms` contains many such predefined functions. Here we will apply the following: \n\n1. Resize and crop to 224x224 as many images are of different sizes\n2. Data Augmentation: random horizontal flip, random rotation and random grayscale\n3. Convert images into PyTorch tensors\n\n**More about data augmentation:**\n\nData augmentation is a strategy that enables practitioners to significantly increase the **diversity** of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks. Note that it increase diversity by introducing random alterations of the original image, but it **DOES NOT INCREASE** the number of images\/samples of the dataset. \n\nAlso note that it is generally recommended to do **channel-wise data normalization** on the images. This means that for each channel (RGB), we subtract the mean and divide by the standard deviation of each channel of the entire dataset, from each pixel. This serves to prevent any color from having a wider influence\/impact on the weights during training as one of the color can have a wider range in the dataset. When using transfer learning, it is recommended to normalize using the mean and standard deviation of the dataset that the pretrained model is trained on (Imagenet usually). However, for me, I found that normalizing decreases the performance, so I did not do it.","313a934a":"Here we create a base model class with functions that will be called with the main model class.\n\n* **training_step**: for loading the batch of train images and outputting its loss and accuracy. The output is used for computing the gradients and for combining with other batches later on\n* **train_epoch_end**: this is used for combining the accuracies and losses of all the batches in each epoch for printing\n* **validation_step**: same as for `training_step`, but for validation and test images\n* **validation_epoch_end**: same as for `train_epoch_end`, but for validation images\n* **epoch_end**: this takes all the outputs from `train_epoch_end` and `validation_epoch_end` and prints out the epoch performance\n* **test_prediction**: for predictions on test images and returning the performance, labels and predictions"}}