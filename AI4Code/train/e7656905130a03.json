{"cell_type":{"e1c86123":"code","d42e6237":"code","d9a7f27d":"code","05a81f2c":"code","ca764894":"code","c86dce27":"code","3f1fa3f8":"code","acc8a89f":"code","73df6d88":"code","50237fc8":"code","81ebcdd2":"markdown","286ac930":"markdown","4dbb6dc8":"markdown","f130d0ed":"markdown"},"source":{"e1c86123":"import tensorflow as tf\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom glob import glob","d42e6237":"imgs_path = glob('..\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/images\/*.png')\nmasks_path = glob('..\/input\/segmentation-full-body-mads-dataset\/segmentation_full_body_mads_dataset_1192_img\/masks\/*.png')\n\nimgs_path = sorted(imgs_path,key=lambda x:os.path.basename(x).split('_')[1:])\nmasks_path = sorted(masks_path,key=lambda x:os.path.basename(x).split('_')[1:])\nlen(imgs_path)==len(masks_path)\n\n##################################################\ndef load_img(img_path):\n    image = tf.io.read_file(img_path)\n    image = tf.io.decode_png(image,channels=3)\n    image = image[90:450,150:406,:]\n\n    return image\ndef load_mask(mask_path):\n    mask = tf.io.read_file(mask_path)\n    mask = tf.io.decode_image(mask,channels=1,dtype='uint8',expand_animations=False)\n    mask = mask[90:450,150:406,:]\n    mask = tf.where(mask>=140, 1, 0)\n    return mask\n\n@tf.function()\ndef preprocess(img_path,mask_path):\n    image=load_img(img_path)\n    mask =load_mask(mask_path)\n    image=tf.cast(image,'float32')\n    mask=tf.cast(mask,'float32')\n    image \/= 255. \n    #\u968f\u673a\u88c1\u526a\u81f3\u76ee\u6807\u5927\u5c0f,\u6ce8\u610f\u8bbe\u5b9a\u968f\u673aseed\uff0c\u4fdd\u8bc1mask\u548cimg\u88c1\u526a\u65b9\u5f0f\u76f8\u540c\n    image = tf.image.random_crop(image,size=(256,256,3),seed=1234)\n    mask = tf.image.random_crop(mask,size=(256,256,1),seed=1234)\n\n    if tf.random.uniform(()) > 0.5:\n        image=tf.image.flip_left_right(image)#\u968f\u673a\u5de6\u53f3\u7ffb\u8f6c\n        mask=tf.image.flip_left_right(mask)\n    #\u66f4\u591a\u6570\u636e\u589e\u5f3a\u65b9\u5f0f\u5f85\u8865\u5145\u5e94\u7528\n    return image,mask\ntrain_set=tf.data.Dataset.from_tensor_slices((imgs_path[:1000],masks_path[:1000]))\ntrain_set=train_set.map(preprocess,num_parallel_calls=-1).shuffle(1000).batch(16)\ntest_set =tf.data.Dataset.from_tensor_slices((imgs_path[1000:],masks_path[1000:]))\ntest_set=test_set.map(preprocess,num_parallel_calls=-1).batch(16)","d9a7f27d":"img,mask=next(iter(test_set))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow(mask[i][...,0])\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow(img[i])","05a81f2c":"!git clone https:\/\/github.com\/SyangZ007\/Image-Segmentation\n    \nimport sys\nsys.path.append('.\/Image-Segmentation')\nfrom model import U2NET_Mini\nmodel=U2NET_Mini(in_ch=3,out_ch=1)\n#model.summary()","ca764894":"def jacard_iou(y_true, y_pred):\n    '''\u8ba1\u7b97y_true,y_pred\u7684IOU\u6307\u6807'''\n    y_pred=tf.where(y_pred>=0.5,1.,0)#\u9608\u503c\u7b5b\u9009\u540e\u518d\u8ba1\u7b97IOU\n    y_pred=tf.keras.layers.Flatten()(y_pred[0])\n    y_true=tf.keras.layers.Flatten()(y_true)\n    y_true=tf.cast(y_true,'float32')\n    intersection = tf.math.reduce_sum(y_pred*y_true)\n    union = tf.math.reduce_sum(y_true) + tf.math.reduce_sum(y_pred) - intersection\n    return (intersection + 1.0) \/ (union + 1.0)\n\nclass MeanIOU(tf.keras.metrics.MeanIoU):\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        #subclass MeanIOU metrics\uff0c\u6a21\u578b\u67097\u4e2a\u8f93\u51famask,subclass\u5b9e\u73b0IOU\u6307\u6807\u66f4\u65b0\n        y_pred=tf.where(y_pred[0]>=0.5,1,0)#\u6839\u636e\u9608\u503c\u8f93\u51famask\n        return super().update_state(y_true, y_pred, sample_weight)\n    \nclass DisplayCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        #clear_output(wait=True)\n        img_t,mask_t=next(iter(test_set)) \n        pred_mask=model(img_t)#\u8fd4\u56de\u7684\u662f7\u4e2amask\u7ec4\u6210\u7684tuple\n        mask_=pred_mask[0]\n\n        plt.figure(figsize=(10,10))\n        for i in range(16):\n            plt.subplot(4,4,i+1)\n            dst=np.vstack((mask_[i],mask_t[i]))\n            plt.imshow(np.squeeze(dst))\n        plt.show()\n        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n    \nbce_loss = tf.keras.losses.BinaryCrossentropy()\nclass Multi_BCE(tf.keras.losses.Loss):\n    '''subclass keras loss to implement multi output bce loss'''\n    def call(self, y_true, y_pred):\n        #y_pred have 7 mask output,each mask must have to compute bce with y_true\n        loss_tar = bce_loss(y_true,y_pred[0])#\u6a21\u578b\u603b\u7684\u8f93\u51fa\u5c42mask\n        loss1 = bce_loss(y_true,y_pred[1])\n        loss2 = bce_loss(y_true,y_pred[2])\n        loss3 = bce_loss(y_true,y_pred[3])\n        loss4 = bce_loss(y_true,y_pred[4])\n        loss5 = bce_loss(y_true,y_pred[5])\n        loss6 = bce_loss(y_true,y_pred[6])\n        return loss_tar + loss1 + loss2 + loss3 + loss4 + loss5 + loss6","c86dce27":"opt=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_jacard_iou', factor=0.5, patience=5, verbose=1, mode='auto')\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_jacard_iou', min_delta=1e-4, patience=15, verbose=0, mode='auto')\n\nmodel.compile(optimizer=opt, loss = Multi_BCE(),metrics=[jacard_iou,MeanIOU(num_classes=2)])\nhist1=model.fit(train_set,epochs=15,validation_data=test_set,callbacks=[reduce_lr,early_stop,DisplayCallback()])","3f1fa3f8":"#\u5207\u6362SGD\u4f18\u5316\u5668\u7ee7\u7eed\u8bad\u7ec3\nopt=tf.keras.optimizers.SGD(lr=0.0005)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_jacard_iou', factor=0.5, patience=5, verbose=1, mode='auto')\n\nmodel.compile(optimizer=opt, loss = Multi_BCE(),metrics=[jacard_iou,MeanIOU(num_classes=2)])\nhist2=model.fit(train_set,epochs=10,validation_data=test_set,callbacks=[reduce_lr,DisplayCallback()])","acc8a89f":"# summarize history for loss\ntrain_loss=hist1.history['loss']\ntrain_loss.extend(hist2.history['loss'])\nval_loss=hist1.history['val_loss']\nval_loss.extend(hist2.history['val_loss'])\n\nplt.plot(train_loss,label='training loss')\nplt.plot(val_loss,label='val loss')\nplt.legend()\nplt.title('model loss curve')\nplt.show()\n\ntrain_iou=hist1.history['mean_iou']\ntrain_iou.extend(hist2.history['mean_iou_1'])\nval_iou=hist1.history['val_mean_iou']\nval_iou.extend(hist2.history['val_mean_iou_1'])\n\nplt.plot(train_iou,label='training iou')\nplt.plot(val_iou,label='val iou')\nplt.legend()\nplt.title('model IOU accuracy')\n","73df6d88":"for img,mask in test_set.take(1):\n    y_pred=model.predict(img)\n    y_pred=tf.where(y_pred>=0.5,1.,0)#\u6839\u636e\u9608\u503c\u8f93\u51famask\n\niou=tf.keras.metrics.MeanIoU(num_classes=2)\niou.update_state(mask,y_pred[0])\n                 #sample_weight=[0.2,0.8])\nprint(\"Mean IoU =\", iou.result().numpy())","50237fc8":"plt.figure(figsize=(10,10))\ndst=tf.multiply(y_pred[0],img)\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow(dst[i])\nplt.show()","81ebcdd2":"# \u8ba1\u7b97mean IOU\u6307\u6807","286ac930":"# \u8bad\u7ec3\u5206\u4e24\u9636\u6bb5\uff0cAdam\u4f18\u5316\u5668\u8bad\u7ec3\u7b2c\u4e00\u9636\u6bb5\uff0c\u5feb\u901f\u6536\u655b;SGD\u4f18\u5316\u5668\u8bad\u7ec3\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5fae\u8c03","4dbb6dc8":"# \u4f7f\u7528Dice loss.Focal loss\u8fdb\u884c\u8bad\u7ec3,IOU \u4f5c\u4e3ametrics\u6307\u6807","f130d0ed":"# \u6a21\u578b\u6700\u7ec8\u9884\u6d4b\u6548\u679c\u5c55\u793a"}}