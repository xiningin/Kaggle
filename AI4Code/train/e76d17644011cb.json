{"cell_type":{"bef12e56":"code","7c3c7700":"code","da87130a":"code","3fe98165":"code","b255d58c":"code","f92c3910":"code","b61d0d25":"code","2eddf28d":"code","3295dbd2":"code","d2d0ef67":"code","41eeecd2":"code","6234a558":"code","5f79548c":"code","7b5f7e7d":"code","59459b54":"markdown","88e2ce91":"markdown","f34e8ba8":"markdown","400af3b2":"markdown","0bc2b4ec":"markdown","f1043875":"markdown","b3420d72":"markdown","8b677b21":"markdown","79cce19a":"markdown"},"source":{"bef12e56":"!\/opt\/conda\/bin\/python3.7 -m pip install --upgrade pip\n! pip install -q efficientnet","7c3c7700":"##--------------------------\n# Import necessary libraries\n##--------------------------\nimport os\n\nimport pandas as pd\nfrom pandas_profiling import ProfileReport\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport numpy as np\n\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nimport efficientnet.tfkeras as efn\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nfrom kaggle_datasets import KaggleDatasets\n\nimport warnings\nwarnings.filterwarnings('ignore')","da87130a":"AUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","3fe98165":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"petfinder-pawpularity-score\")\nprint(GCS_DS_PATH)\n\nTRAIN_PATH = GCS_DS_PATH + \"\/train\/\"\nTEST_PATH = GCS_DS_PATH + \"\/TEST\/\"\n\nTRAIN_P = \"..\/input\/petfinder-pawpularity-score\/train\"\nTEST_P = \"..\/input\/petfinder-pawpularity-score\/test\"\n\ntrain_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\n\nTRAIN_NS = os.listdir(TRAIN_P) \nTEST_NS = os.listdir(TEST_P)\nTRAIN_PS = [os.path.join(TRAIN_P,f) for f in TRAIN_NS]\nTEST_PS = [os.path.join(TEST_P,f) for f in TEST_NS]\n\nHEIGHT, WIDTH = 512, 512\nCHANNELS = 3\nSEED = 2021\nNUM_CLASSES = 10","b255d58c":"##------------------------------\n# Display Random Training Images\n##------------------------------\n\nrand_ls = np.random.randint(9000, size=(9))\nfig,ax = plt.subplots(nrows=3,ncols=3,figsize=(18,10))\nfor count,i in enumerate(rand_ls):\n    r,c = count\/\/3, count%3\n    ax[r,c].imshow(np.asarray(Image.open(TRAIN_PS[i])))\n    ax[r,c].axis(\"off\")\n    label = train_df[train_df[\"Id\"] == TRAIN_NS[i].split(\".\")[0]][\"Pawpularity\"].values[0]\n    ax[r,c].set_title(f\"Pawpularity Score : {label}\",fontsize=15, fontfamily=\"monospace\", fontweight=\"bold\")","f92c3910":"##--------------------------------\n# Height, Width of Training Images\n##--------------------------------\ntrain_h, train_w = [], []\n\nfor path in TRAIN_PS:\n    im = Image.open(path)\n    w,h = im.size\n    train_h.append(h)\n    train_w.append(w)\n\n'''plt.figure(figsize=(10,10))\nsns.jointplot(x=train_w, y=train_h,kind=\"kde\")\nplt.xlabel(\"Width of Image\")\nplt.ylabel(\"Height of Image\")'''\nprint(f\"Mean Height : {sum(train_h)\/len(train_h)} | Mean Width : {sum(train_w)\/len(train_w)}\")","b61d0d25":"##---------------------------\n# Metadata of Training images\n# Pandas Profiling\n##---------------------------\ntrain_df[\"Width\"] = train_w\ntrain_df[\"Height\"] = train_h\n\ntrain_report = ProfileReport(train_df,title=\"Metadata of Training images\")\n#train_report.to_file(\".\/train_metadata.html\")\ntrain_report","2eddf28d":"##----------------------\n#Preprocessing Functions\n##----------------------\n\ndef process_img(filepath,label):\n    image = tf.io.read_file(filepath)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label\n\n\ndef data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) \n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) \n        \n    \n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    \n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n    \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label\n\ndef get_dataset(filenames,labels, training=True):\n    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))\n    dataset = dataset.map(process_img,num_parallel_calls=AUTO)\n    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)\n    dataset = dataset.cache()\n    dataset = dataset.repeat()\n    if training:\n        dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","3295dbd2":"files_ls = tf.io.gfile.glob(TRAIN_PATH + \"*.jpg\" )\nfiles_df = pd.DataFrame(files_ls, columns = [\"filepath\"])\n\nbin_ranges = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\nbin_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ntrain_df[\"label\"] = pd.cut(np.array(train_df[\"Pawpularity\"]),bins=bin_ranges,labels=bin_names)\n\nreal_labels = np.array(train_df[\"Pawpularity\"])\npaw_values = []\nfor i in bin_names:\n    val = list(train_df[train_df[\"label\"] == i][\"Pawpularity\"])\n    paw_values.append(sum(val)\/len(val))\n\npseudo_labels = np.array(train_df[\"label\"])\n                       \n'''onehot_labels = np.zeros((len(labels), NUM_CLASSES))\nfor i in range(len(pseudo_labels)):\n    onehot_labels[i][pseudo_labels[i]] = 1'''\n    \ntrain_df.head()","d2d0ef67":"def create_model():\n    \n    pretrained = efn.EfficientNetB7(include_top=False, weights='noisy-student',input_shape=[HEIGHT,WIDTH, CHANNELS])\n    '''pretrained = tf.keras.applications.DenseNet121(weights= \"imagenet\",\n                                                   include_top=False,\n                                                   input_shape=(HEIGHT,WIDTH,CHANNELS),pooling=None)'''        \n    x = pretrained.output\n    x = tf.keras.layers.GlobalAveragePooling2D() (x)\n    x = tf.keras.layers.Dense(512, activation = \"relu\") (x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(256, activation=\"relu\") (x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    #outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", dtype='float32')(x)\n    outputs = tf.keras.layers.Dense(1, dtype='float32')(x)\n        \n    model = tf.keras.Model(pretrained.input, outputs)\n    return model","41eeecd2":"import tensorflow_addons as tfa\n\ndef compile_model(model, lr=0.001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    #loss = tf.keras.losses.CategoricalCrossentropy()\n    loss = tf.keras.losses.MeanSquaredError()\n   \n    metrics = [tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n    '''\n    tfa.metrics.F1Score(num_classes = NUM_CLASSES,average = \"macro\", name = \"f1_score\"),\n    tf.keras.metrics.CategoricalAccuracy(name='acc')\n    '''\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","6234a558":"METRIC = \"val_rmse\"\n\ndef create_callbacks(kfold,metric = METRIC):\n    \n    cpk_path = f'.\/best_model_{kfold}.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor= metric,\n        mode='min',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor= metric,\n        mode='min',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor= metric,\n        mode='min',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","5f79548c":"EPOCHS = 10\nVERBOSE = 1\nN_SPLITS = 10\nBATCH_SIZE = 32\n\nkfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\nhistory = {}\n\n\nfor fold,(tID,vID) in enumerate(kfold.split(files_ls,pseudo_labels)):\n    tFiles, tLabels = list(files_df.iloc[tID][\"filepath\"]),real_labels[tID]  #, onehot_labels[tID]\n    vFiles, vLabels = list(files_df.iloc[vID][\"filepath\"]), real_labels[vID]  #, onehot_labels[vID]\n    print(\"Number of Training Images: \",len(tID))\n    print(\"Number of Validation Images: \",len(vID))\n    \n    STEPS_PER_EPOCH  = len(tID)\/\/BATCH_SIZE\n    VALID_STEPS = len(vID)\/\/BATCH_SIZE\n    \n    tf.keras.backend.clear_session()\n    \n    train_ds = get_dataset(tFiles,tLabels, training = True)\n    val_ds = get_dataset(vFiles, vLabels, training = False)\n    \n    with strategy.scope():\n        model = create_model()\n        model = compile_model(model, lr=0.0001)\n        callbacks = create_callbacks(kfold = fold)\n    \n        print(\"------------------Fold - \",fold+1,\" --------------------------\")\n        history[fold] = model.fit(\n                            train_ds,\n                            epochs=EPOCHS,\n                            callbacks=callbacks,\n                            validation_data = val_ds,\n                            verbose=VERBOSE,\n                            steps_per_epoch = STEPS_PER_EPOCH,\n                            validation_steps=VALID_STEPS\n                           )","7b5f7e7d":"plt.figure(figsize=(8*N_SPLITS,24))\n\nfor i in range(N_SPLITS):\n    acc = history[i].history['rmse']\n    val_acc = history[i].history['val_rmse']\n    loss = history[i].history['loss']\n    val_loss = history[i].history['val_loss']\n    epochs_range = range(len(history[i].history['val_loss'])) \n    \n    plt.subplot(N_SPLITS, 2,i*2+1)\n    plt.plot(epochs_range, acc, label='Training RMSE')\n    plt.plot(epochs_range, val_acc, label='Validation  RMSE')\n    plt.legend(loc='lower right')\n    plt.title(f'FOLD:{str(i)} Training and Validation  RMSE')\n    \n    plt.subplot(N_SPLITS, 2, i*2+2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title(f'FOLD:{str(i)} Training and Validation Loss')\n\nplt.show()","59459b54":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Data Preprocessing\ud83e\uddf0<\/h1><\/center>","88e2ce91":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Libraries\ud83d\udcda<\/h1><\/center>","f34e8ba8":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Data Visualization\ud83d\udcca<\/h1><\/center>","400af3b2":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Initializations\ud83c\udfac<\/h1><\/center>","0bc2b4ec":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">How did the Training go\ud83d\udcdc<\/h1><\/center>","f1043875":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Checking TPU access\ud83d\udcbb<\/h1><\/center>","b3420d72":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Setting Up Training Process\ud83c\udf73<\/h1><\/center>","8b677b21":"<center style = \"font-family: 'Lucida Console', 'Courier New', monospace;\">\n    <img src = \"https:\/\/www.bargainmarket.com.au\/images\/banner-pets-dog-cat-boarding.png\" width=600 height = 400>\n    <h1 style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\">PetFinder.my - Pawpularity Contest \ud83d\udc36\ud83d\udc31<\/h1>\n<\/center>\n\n<br>\n<h2 style = \"font-family: Consolas\">What is PetFinder.my\u2753<\/h2>\n<p style = \"font-family : Lucida Sans Typewriter\">\n<a href = \"https:\/\/petfinder.my\/\">PetFinder.my<\/a> is Malaysia\u2019s leading animal welfare platform, featuring over 180,000 animals with 54,000 happily adopted. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n<\/p>\n\n<br>\n<h2 style = \"font-family: Consolas\">What should we do\ud83d\udcdd<\/h2>\n<p style = \"font-family : Lucida Sans Typewriter\">\nIn this competition, you\u2019ll analyze raw images and metadata to predict the \u201cPawpularity\u201d of pet photos. You'll train and test your model on PetFinder.my's thousands of pet profiles.<\/p>\n\n<br>\n<h2 style = \"font-family: Consolas\">Data Information\ud83d\udcbd<\/h2>\n<p style = \"font-family : Lucida Sans Typewriter\">Check <a href = \"https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/data\">competition page<\/a> for details<\/p>\n\n<h2 style = \"font-family : Comic Sans MS\">Let's dive in \u2b07\ufe0f<\/h2>","79cce19a":"<center style = \"background: rgb(238,174,202);\nbackground: radial-gradient(circle, rgba(238,174,202,1) 0%, rgba(81,154,204,1) 0%);\"><h1 style = \"font-family:'Bodoni MT'\">Training\ud83d\udca1<\/h1><\/center>"}}