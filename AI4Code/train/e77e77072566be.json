{"cell_type":{"f5affac5":"code","b7db1855":"code","3d83f267":"code","db2f92d6":"code","1db66426":"code","51b2f2cb":"code","d2fc47ab":"code","0d750dc7":"code","3c8712e6":"code","06bf5698":"code","3ca2bb75":"code","e91cfd56":"code","53bc0caf":"code","15e59d70":"code","95251c5d":"code","45e40af9":"code","96549e6e":"code","ab5d904e":"code","e05c11e1":"code","d38583db":"code","4229121d":"code","9cb80b70":"code","b0ece0e8":"code","c0416b2f":"code","bf209d0a":"code","296d59ea":"code","4bcef09e":"code","bed0d66f":"code","8b4ad7dc":"code","112f5daa":"code","ec1a738a":"code","6978b813":"code","8dcbdb26":"code","0d56afe4":"code","c942d7c6":"code","c98eb57f":"code","09c6988a":"code","9fc61d07":"markdown","8b3d7ee1":"markdown","44d87f85":"markdown","01c87ed9":"markdown","ef8f1481":"markdown","3c52f3bf":"markdown","2ec36181":"markdown","5abde10b":"markdown","480a9ee8":"markdown","c100b652":"markdown","3098ed94":"markdown","f017477a":"markdown","d1347cf1":"markdown","ecb163e9":"markdown","03365725":"markdown","f413a26d":"markdown","b39577c4":"markdown","866f97a9":"markdown","9eb3fb5b":"markdown","f4c94d9a":"markdown","f3a770ba":"markdown","2338daa2":"markdown","7f4da617":"markdown","5e2f9b83":"markdown","72a13d6a":"markdown","0d930f1e":"markdown"},"source":{"f5affac5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nfrom functools import reduce\nfrom sklearn.model_selection import GridSearchCV\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b7db1855":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","3d83f267":"train_df.head()","db2f92d6":"train_df.info()","1db66426":"train_df.describe()","51b2f2cb":"train_df.Embarked.value_counts()","d2fc47ab":"def fix_nas(dataset): \n        dataset[\"Embarked\"].fillna(\"S\",inplace=True)\n        dataset.drop([\"Cabin\"],axis=1,inplace=True)\n        #mean_age = round(train_df.Age.mean())\n        #dataset.Age.fillna(mean_age,inplace=True)    \n        dataset.drop([\"Ticket\"],axis=1,inplace=True)\n        \n        ages_mean= dataset[[\"Pclass\",\"SibSp\",\"Parch\",\"Sex\",\"Age\"]].groupby([\"Pclass\",\"SibSp\",\"Parch\",\"Sex\"]).agg('median').reset_index()\n        \n        for i,data in ages_mean.iterrows():\n                dataset.loc[:,\"Age\"][(dataset[\"Pclass\"]==int(data[\"Pclass\"])) & (dataset[\"SibSp\"]==int(data[\"SibSp\"])) & \n                                     (dataset[\"Parch\"]==int(data[\"Parch\"]))& (dataset[\"Sex\"]==data[\"Sex\"]) & \n                                     (dataset.Age.isnull())] =data[\"Age\"]\n                \n        dataset.loc[:,\"Age\"][(dataset.Age.isnull())] =dataset[\"Age\"].median()\n        dataset.loc[:,\"Age\"]=dataset.loc[:,\"Age\"].astype(int) ","0d750dc7":"def get_title(data):\n    title = data.split(\".\")[0].split(\",\")[1].replace(\" \",\"\")\n    if ([\"Master\",\"Mr\"].count(title)!=0):\n        title = \"Mr\"\n    elif ([\"Major\",\"Col\",\"Mlle\",\"Don\",\"Lady\",\"Mme\",\"Jonkheer\",\"theCountess\",\"Capt\",\"Sir\"].count(title)!=0):\n        title = \"NA\"  \n    elif ([\"Miss\",\"Ms\"].count(title)!=0):\n        title = \"Ms\"    \n    return title","3c8712e6":"def get_family_members(dataset):\n    fam_num = dataset[\"SibSp\"]+dataset[\"Parch\"]+1\n    if fam_num >7:\n        fam_num=8\n    return fam_num","06bf5698":"def is_single(dataset):\n    if (dataset[\"Family\"] >1):\n        return 0\n    else:\n        return 1","3ca2bb75":"def get_age_category(dataset):\n    #[\"Less than 20\",\"20 to 40\",\"40 to 60\",\"More than 60\"]\n    if (dataset[\"Age\"]<=10):\n        return 0\n    elif((dataset[\"Age\"]>10)&(dataset[\"Age\"]<20)):\n        return 1\n    elif((dataset[\"Age\"]>=20)&(dataset[\"Age\"]<40)):\n         return 2\n    elif((dataset[\"Age\"]>=40)&(dataset[\"Age\"]<60)):\n         return 3\n    elif((dataset[\"Age\"]>=60)):\n         return 4     ","e91cfd56":"train_df.drop([\"PassengerId\"],axis=1,inplace=True)\n\n\nfix_nas(train_df)    \nfix_nas(test_df)  \n\ntrain_df[\"Title\"]=train_df.Name.apply(get_title)\ntrain_df[\"Family\"] = train_df.apply(get_family_members,axis=1)\ntrain_df[\"Is_Single\"] = train_df.apply(is_single,axis=1)\n#train_df[\"Ticket\"] = train_df.apply(get_ticket_number,axis=1)\n\ntest_df[\"Title\"]=train_df.Name.apply(get_title)\ntest_df[\"Family\"] = train_df.apply(get_family_members,axis=1)\ntest_df[\"Is_Single\"] = train_df.apply(is_single,axis=1)\n#test_df[\"Ticket\"] = test_df.apply(get_ticket_number,axis=1)\n\ngender_le = LabelEncoder()\ntrain_df.Sex = gender_le.fit_transform(train_df[\"Sex\"])\ntest_df.Sex = gender_le.transform(test_df[\"Sex\"])\ngender_le_classes = gender_le.classes_.tolist()\n\nembarked_le = LabelEncoder()\ntrain_df.Embarked = embarked_le.fit_transform(train_df[\"Embarked\"])\ntest_df.Embarked = embarked_le.transform(test_df[\"Embarked\"])\nembarked_le_classes = embarked_le.classes_.tolist()\n\n\ntitle_le = LabelEncoder()\ntrain_df.Title = title_le.fit_transform(train_df[\"Title\"])\ntest_df.Title = title_le.transform(test_df[\"Title\"])\ntitle_le_classes = title_le.classes_.tolist()\n\ntrain_df[\"Age_Cat\"]= train_df.apply(get_age_category,axis=1)\ntest_df[\"Age_Cat\"]= test_df.apply(get_age_category,axis=1)\ntrain_df[\"Fare_Cat\"]= (pd.cut(train_df.Fare,bins=5,labels=['1','2','3','4','5'])).astype(int)\ntest_df[\"Fare_Cat\"]= (pd.cut(test_df.Fare,bins=5,labels=['1','2','3','4','5']))##\ntrain_df.drop(['Age','Fare','SibSp','Parch'],axis=1,inplace=True)\ntest_df.drop(['Age','Fare','SibSp','Parch'],axis=1,inplace=True)\ntest_df.Fare_Cat.fillna(\"1\",inplace=True,axis=0) \ntrain_df.drop([\"Name\"],axis=1,inplace=True)","53bc0caf":"fig, ax = plt.subplots(figsize=(15,10))\nax = sns.heatmap(train_df[[\"Survived\",\"Pclass\",\"Sex\",\"Age_Cat\",\"Fare_Cat\",\"Embarked\",\"Is_Single\",\"Family\"]].corr(),annot=True)","15e59d70":"survived_df = train_df[train_df.Survived==1]\nnon_survived_df = train_df[train_df.Survived==0]\nplot_features = [\"Pclass\",\"Sex\",\"Age_Cat\",\"Fare_Cat\",\"Embarked\",\"Title\",\"Is_Single\",\"Family\"]","95251c5d":"#### Plot (Survived)\n\nlab = train_df[\"Survived\"].value_counts().keys().tolist()\n#values\nval = train_df[\"Survived\"].value_counts().values.tolist()\ndesc = [\"Survived\" if i==1 else \"Not Survived\" for i in lab]\ntrace = go.Pie(labels = desc ,\n               values = val ,\n               marker = dict(colors =  [ 'red' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Survived \/ Not Survived Passengers\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)\n\n\n#### Plot (Pclass)\npclass_df =pd.DataFrame(train_df[\"Pclass\"].value_counts(sort=False)).reset_index()\npclass_df.columns=['label','val']\n#lab = train_df[\"Pclass\"].value_counts(sort=False).keys().tolist()\nlab=pclass_df.label\n#values\n#val = train_df[\"Pclass\"].value_counts(sort=False).values.tolist()\nval=pclass_df.val\ndesc = [\"Class \"+str(i) for i in lab]\ntrace = go.Pie(labels = desc ,\n               values = val ,\n             \n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Passengers Classes\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)\n\n#### Plot (Age)\nage_df =pd.DataFrame(train_df[\"Age_Cat\"].value_counts(sort=False)).reset_index()\nage_df.index=[\"Less than 10\",\"10 to 20\",\"20 to 40\",\"40 to 60\",\"More than 60\"]\nage_df.reset_index(inplace=True)\nage_df.columns=['desc','label','val']\n#lab = train_df[\"Pclass\"].value_counts(sort=False).keys().tolist()\nlab=age_df.desc\n#values\n#val = train_df[\"Pclass\"].value_counts(sort=False).values.tolist()\nval=age_df.val\ndesc = [str(i) for i in lab]\ntrace = go.Pie(labels = desc ,\n               values = val ,\n             \n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Age Categories\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)","45e40af9":"def histogram(column) :\n    trace1 = go.Histogram(x  = survived_df[column],\n                        #  histnorm= \"percent\",\n                          name = \"Survived\",\n                          marker = dict(line = dict(width = .5,\n                                                    color = \"black\"\n                                                    )\n                                        ),\n                         opacity = .9 ,marker_color='green'\n                         ) \n    \n    trace2 = go.Histogram(x  = non_survived_df[column],\n                        #  histnorm = \"percent\",\n                          name = \"Not Survived\",\n                          marker = dict(line = dict(width = .5,\n                                              color = \"black\"\n                                             )\n                                 ),\n                          opacity = .9,marker_color='red'\n                         )\n    \n    data = [trace1,trace2]\n    layout = go.Layout(dict(title =column + \" distribution in passangers survival \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = column,\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = \"Number of Cases\",\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                           )\n                      )\n   \n    fig  = go.Figure(data=data,layout=layout)\n    if(column=='Sex'):\n        fig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = [0,1],\n        ticktext = ['Female','Male']\n        )\n        )\n    if(column=='Age_Cat'):\n        fig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = [0,1,2,3,4],\n        ticktext = [\"Less than 10\",\"10 to 20\",\"20 to 40\",\"40 to 60\",\"More than 60\"]\n        )\n        ) \n    if(column=='Title'):\n        fig.update_layout(\n        xaxis = dict(\n        tickmode = 'array',\n        tickvals = [0,1,2,3,4,5],\n        ticktext = title_le_classes\n        )\n        )      \n    py.iplot(fig)\n  ","96549e6e":"for idx ,feature in enumerate (plot_features, start=1) :\n    histogram(feature)","ab5d904e":"gender_submission_df = test_df[[\"PassengerId\"]]\ntest_df.drop(\"Name\",axis=1,inplace=True)\ntest_df.drop(\"PassengerId\",axis=1,inplace=True)","e05c11e1":"test_df.Fare_Cat = test_df.Fare_Cat.astype(int)\ntest_df.info()","d38583db":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report , roc_auc_score,roc_curve , recall_score , precision_score ,accuracy_score,f1_score\nX = train_df.iloc[:,1:]\ny = train_df.iloc[:,0]\nX_train, X_valid , y_train, y_valid = train_test_split(X,y,random_state=123,test_size=.3)\nscores_df = pd.DataFrame(columns=[\"model_name\",\"model\",\"precision\",\"accuracy\",\"recall\",\"f1score\",\"rocauc\",\"fpr\",\"tpr\"])\n","4229121d":"def model_scores(model_name,model,y_test,y_pred,fpr,tpr):\n    precision = precision_score(y_test,y_pred)\n    accuracy = accuracy_score(y_test,y_pred)\n    recall = recall_score(y_test,y_pred)\n    f1score = f1_score(y_test,y_pred)\n    roc_auc = roc_auc_score(y_test,y_pred)\n    scores = {\"model_name\":[model_name],\n              \"model\":[model],\n              \"precision\":[precision],\n              \"accuracy\":[accuracy],\n              \"recall\":[recall],\n              \"f1score\":[f1score],\n              \"rocauc\":[roc_auc],\n              \"fpr\":[fpr] ,\n              \"tpr\":[tpr]}\n    scores = (pd.DataFrame(scores))\n    global scores_df\n    scores_df=pd.concat([scores_df,scores],axis=0)","9cb80b70":"from sklearn.neighbors import KNeighborsClassifier as KNN\nknn_params= {\"n_neighbors\":[3,4,5,6]}\nknn_grid = GridSearchCV(estimator=KNN(),param_grid=knn_params,cv=4)\nknn_grid.fit(X_train,y_train)\ny_pred = knn_grid.predict(X_valid)\ny_proba =knn_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"KNN\",knn_grid.best_estimator_ ,y_valid,y_pred,fpr,tpr)","b0ece0e8":"\nprint(classification_report(y_valid,y_pred))","c0416b2f":"from sklearn.linear_model import LogisticRegression\nlogreg_param ={\"C\":[0.01,0.01,1,10]}\nlogreg_grid = GridSearchCV(estimator=LogisticRegression(),param_grid=logreg_param,cv=4)\nlogreg_grid.fit(X_train,y_train)\ny_pred = logreg_grid.predict(X_valid)\ny_proba = logreg_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"LogReg\",logreg_grid.best_estimator_ ,y_valid,y_pred,fpr,tpr)\n\nprint(classification_report(y_valid,y_pred))","bf209d0a":"from sklearn.svm import SVC\nsvm_param ={\"C\":[0.01,0.01,1,2,5,10,50,100],\"gamma\":[.001,.01,1,10],\"kernel\":[\"rbf\"],\"probability\":[True]}\nsvm_grid = GridSearchCV(estimator=SVC(),param_grid=svm_param,cv=4)\nsvm_grid.fit(X_train,y_train)\ny_pred = svm_grid.predict(X_valid)\ny_proba = svm_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"SVM\",svm_grid.best_estimator_ ,y_valid,y_pred,fpr,tpr)\n\nprint(classification_report(y_valid,y_pred))","296d59ea":"from sklearn.svm import SVC\nlin_svm_param ={\"C\":[0.001,0.01,0.01,1],\"kernel\":[\"linear\"],\"probability\":[True]}\nlin_svm_grid = GridSearchCV(estimator=SVC(),param_grid=lin_svm_param,cv=4)\nlin_svm_grid.fit(X_train,y_train)\ny_pred = lin_svm_grid.predict(X_valid)\ny_proba = lin_svm_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"LinSVM\",lin_svm_grid.best_estimator_ ,y_valid,y_pred,fpr,tpr)","4bcef09e":"from sklearn.tree import DecisionTreeClassifier\ndt_param={\"max_depth\":[3,4,5]}\ndt_grid = GridSearchCV(DecisionTreeClassifier(),param_grid=dt_param,cv=4)\ndt_grid.fit(X_train,y_train)\ny_pred = dt_grid.predict(X_valid)\ny_proba = dt_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"DescisionTree\",dt_grid.best_estimator_ ,y_valid,y_pred,fpr,tpr)\nprint(dt_grid.best_estimator_)","bed0d66f":"dtree.feature_importances_","8b4ad7dc":"fig = plt.figure(figsize=(20,10))\ndtree= dt_grid.best_estimator_\ndtree.feature_importances_\nsns.set_context(\"notebook\")\nsns.set_style(\"whitegrid\")\nax=sns.barplot(y=X_train.columns , x=dtree.feature_importances_)\nax.set(Title=\"Decision Tree Features Importance\")\nplt.show()\n","112f5daa":"from sklearn.ensemble import RandomForestClassifier\nrf_param={\"max_depth\":[3,4,5],\"n_estimators\":[100,150,200],\"min_samples_split\":[2,3,4,5]}\nrf_grid = GridSearchCV(RandomForestClassifier(),param_grid=rf_param,cv=4)\nrf_grid.fit(X_train,y_train)\ny_pred = rf_grid.predict(X_valid)\ny_proba = rf_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"RandomForest\",rf_grid.best_estimator_ ,y_valid,y_pred,fpr,tpr)\n","ec1a738a":"import xgboost as xgb\nxg_param={\"objective\":['binary:logistic'],\"n_estimators\":[10,20,50]}\nxg_grid = GridSearchCV(xgb.XGBClassifier(seed=123),param_grid=xg_param,cv=4)\n\n\nxg_grid.fit(X_train,y_train)\ny_pred = xg_grid.predict(X_valid)\ny_proba = xg_grid.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"XGBClassifierGrid\",xg_grid.best_estimator_  ,y_valid,y_pred,fpr,tpr)","6978b813":"def plot_roc_auc(model_name,fpr,tpr):\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=fpr, y=tpr,\n                    mode='lines',\n                    name=model_name))\n    fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n                    mode='lines',\n                    line = dict(color='red', width=4, dash='dash'), showlegend=False))\n\n    fig.show()","8dcbdb26":"scores_df[[\"model_name\",\"precision\",\"accuracy\",\"recall\",\"f1score\",\"rocauc\"]]","0d56afe4":"from sklearn.ensemble import VotingClassifier\nvoting_classifiers_list = [(\"XGBClassifierGrid\",xg_grid.best_estimator_ ),(\"RandomForest\",rf_grid.best_estimator_),(\"SVM\",svm_grid.best_estimator_)]\nvote_clf = VotingClassifier(estimators=voting_classifiers_list,voting=\"soft\")\nvote_clf.fit(X_train,y_train)\ny_pred = vote_clf.predict(X_valid)\ny_proba = vote_clf.predict_proba(X_valid)[:,1]\nfpr,tpr,thr = roc_curve(y_valid,y_proba)\nmodel_scores(\"Voting\",vote_clf  ,y_valid,y_pred,fpr,tpr)","c942d7c6":"#plot_roc_auc(model_name,fpr,tpr)\nfor i,rec in scores_df.iterrows():\n    #print(rec.fpr)\n    plot_roc_auc(rec.model_name,rec.fpr,rec.tpr)","c98eb57f":"gender_submission_df[\"Survived\"] = vote_clf.predict(test_df)\ngender_submission_df.set_index([\"PassengerId\"],inplace=True)\ngender_submission_df.to_csv('\/kaggle\/working\/my_submission.csv')\n","09c6988a":"#gender_submission_df","9fc61d07":"# Create a function to fill the Null values and drop the unneeded columns","8b3d7ee1":"# Get the category of the age as following\n1. Less than 10 years\n2. From 10 to 20 years\n3. From 20 to 40 years\n4. From 40 to 60 years\n5. More than 60 years","44d87f85":"# Exploring the training dataset ","01c87ed9":"# **Modeling using SVM**","ef8f1481":"# **Plotting ROC AUC **","3c52f3bf":"# Conclusion\n* Class 3 surviving chance was too low comparing to Class 1\n* Most of the survivals are females \n* Surviving chance for kids less than 10 years was slightly higher than other age ranges\n* Singles were the biggest portion of the non survivals","2ec36181":"# Preraring Test and Submission Dataframes","5abde10b":"Some featues have NULL values like **Age, Cabin** and **Embarked**\n\nAs **Embarked** missing values are 2 records we will fill them with the most major values","480a9ee8":"# Features Exploration\nExploring some features in a visual way to know more about the distrubution of the key features ","c100b652":"# Import the necessary libraries","3098ed94":"# **Modeling using Random Forest**","f017477a":"# **Modeling using KNN **","d1347cf1":"# Exploration results\n* Unfortunately 62% of the passengers didn't survive.\n* Around 55% of passengers were in Class 3.\n* The passengers majority were between 20 and 40 years old.","ecb163e9":"# **Modeling using LinearSVM**","03365725":"# **Modeling using XGBoost Classifier**","f413a26d":"# Get the number of family members","b39577c4":"# Extracting Features and Target and splitting the data","866f97a9":"# Introduction\n\nThis is my first ever Machine learning model, So I've tried to use some basic and advanced algorithms to get used to them.\n\nThe notebook is trying to analyse the Titanic disaster and predict if the provided passengers in the test dataset are survived or not.","9eb3fb5b":"# Check if the passenger is single or not","f4c94d9a":"# **Modeling using LogReg **","f3a770ba":"# **Voting Classifier**\nPicking the top classifier and use the voting to get the best predictions","2338daa2":"# Data cleaning\nCleaning the data using the created functions and dropping the unneeded columns","7f4da617":"# Get the Titles from the passenger name","5e2f9b83":"# Data correlation\nPlotting the correlation between features in order to take a deeper look to our data and how are the features are correlated to the target value","72a13d6a":"# Results submission","0d930f1e":"# **Modeling using Decision Tree**"}}