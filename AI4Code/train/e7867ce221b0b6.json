{"cell_type":{"3a5bff09":"code","b1973f3f":"code","b747eabe":"code","62483e0b":"code","8d50bee9":"code","e059d468":"code","9190df0c":"code","a3edd0ee":"code","c59d5dab":"code","a5b63c1c":"code","63a1b2e1":"code","2eaa1af1":"code","f13cc73b":"code","abd2f455":"code","baeb4d32":"code","01f31318":"code","9aad717e":"code","4da540fc":"code","2eab3b80":"code","ddac0ec5":"code","94454d73":"code","5038fb01":"code","dd76987e":"code","87e0036c":"code","aa0d3509":"code","75484cd4":"code","b7da941e":"code","29585ee9":"code","eb7494db":"code","a542f196":"markdown","bfd48314":"markdown","d5b0274e":"markdown","dbfa2ce9":"markdown","74a12056":"markdown","c12cdf97":"markdown","ba8f056c":"markdown","b875a16e":"markdown","ebab0b53":"markdown","6b76b3c8":"markdown","bcb4731a":"markdown"},"source":{"3a5bff09":"!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null # no output\npackage_path = '..\/input\/unetmodelscript' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom model import Unet # import Unet model from the script","b1973f3f":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tqdm.notebook import tqdm_notebook as tqdm\nimport seaborn as sns\nimport albumentations  as albu\nfrom albumentations.pytorch import ToTensor\nimport random\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nimport torchvision\nfrom torchvision import models\nfrom torch.autograd import Function","b747eabe":"# \u4e71\u6570\u306e\u30b7\u30fc\u30c9\u3092\u8a2d\u5b9a\nseed = 1234\nrandom.seed(seed)\ntorch.manual_seed(seed)\nnp.random.seed(seed)","62483e0b":"save_dir_weights  = \".\/weights\"\nsave_dir_logs  = \".\/logs\"\n\nif os.path.exists(save_dir_weights) == False:\n    os.makedirs(save_dir_weights)\nif os.path.exists(save_dir_logs) == False:\n    os.makedirs(save_dir_logs)","8d50bee9":"input_dir = \"..\/input\/severstal-steel-defect-detection\/\"\ninput_dir_Train  = os.path.join(input_dir, 'train_images')\ninput_dir_Test  = os.path.join(input_dir, 'test_images')\nfilelist_Train = os.listdir(input_dir_Train)\nfilelist_Test = os.listdir(input_dir_Test)\nprint('train data size : {}'.format(len(filelist_Train)))\nprint('test data size : {}'.format(len(filelist_Test)))","e059d468":"index = 0\npath = os.path.join(input_dir_Train, filelist_Train[0])\nimage = cv2.imread(path)","9190df0c":"plt.imshow(image)","a3edd0ee":"print('image shape : {}'.format(image.shape))","c59d5dab":"df_path = os.path.join(input_dir, 'train.csv')\ndf = pd.read_csv(df_path)\ndf.head()","a5b63c1c":"print('defect num : {}'.format(df['ImageId'].nunique()))\nprint('no defect num : {}'.format(len(filelist_Train) - df['ImageId'].nunique()))","63a1b2e1":"defect_class = np.zeros((4))\nfor i in tqdm(range(len(df))):\n    class_id = df.iloc[i]['ClassId']\n    defect_class[class_id - 1] += 1","2eaa1af1":"fig, ax = plt.subplots()\nsns.barplot(x=np.arange(1, 5), y=defect_class, ax=ax)\nax.set_title(\"the number of images for each class\")\nax.set_xlabel(\"class\")","f13cc73b":"def make_df(df):\n    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n    df['defects'] = df.count(axis=1)\n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=seed)\n    return train_df, val_df","abd2f455":"train_df, val_df = make_df(df)","baeb4d32":"def make_mask(index, df):\n    filename = df.iloc[index].name\n    labels = df.iloc[index, :4]\n    masks = np.zeros((256, 1600, 4), dtype=np.float32)\n    for idx, label in enumerate(labels):\n        if label is not np.nan:\n            mask = np.zeros((256*1600), dtype=np.uint8)\n            pixels = label.split(' ')\n            pixels = [pixels[i:i+2] for i in range(0, len(pixels), 2)]\n            for pixel in pixels:\n                pos, le = pixel\n                pos, le = int(pos), int(le)\n                mask[pos-1:pos+le-1] = 1\n            masks[:,:,idx] = mask.reshape(256, 1600, order = 'F')\n    return filename, masks","01f31318":"f, m = make_mask(0, train_df)\nprint('file name : {}'.format(f))\nplt.imshow(cv2.imread(os.path.join(input_dir_Train, f)))\nplt.show()\nplt.imshow(m[:,:,2])\nplt.show()","9aad717e":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndef get_augmentation(mean, std, phase):\n    \n    if phase == 'train':\n        transform = [\n            albu.HorizontalFlip(p=0.5),\n            albu.VerticalFlip(p=0.5),\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    else:\n        transform = [\n            albu.Resize(256, 256, interpolation=cv2.INTER_NEAREST, p=1),\n            albu.Normalize(mean=mean, std=std, p=1),\n            ToTensor(),\n        ]\n    \n    return albu.Compose(transform)","4da540fc":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self, df, input_dir, phase):\n        self.df = df\n        self.input_dir = input_dir\n        self.transforms = get_augmentation(mean, std, phase) \n        self.phase = phase\n    def __getitem__(self, idx):\n        filename, mask = make_mask(idx, self.df)\n        image = cv2.imread(os.path.join(self.input_dir, filename))\n        augmented = self.transforms(image=image, mask=mask)\n        image, mask = augmented['image'], augmented['mask']\n        mask = mask[0].permute(2, 0, 1)\n        return image, mask\n    def __len__(self):\n        return len(self.df)","2eab3b80":"train_dataset = MyDataset(train_df, input_dir_Train, phase = 'train')\nval_dataset = MyDataset(val_df, input_dir_Train, phase = 'val')\n\n# \u52d5\u4f5c\u78ba\u8a8d\nindex = 0\nimage, mask = train_dataset.__getitem__(index) \nprint(image.size())\nplt.imshow(image.to('cpu').detach().numpy().copy()[0])\nplt.show()\nprint(mask.size())\nplt.imshow(mask.to('cpu').detach().numpy().copy()[2])\nplt.show()","ddac0ec5":"batch_size = 4\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=6)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)\n\ndataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n\n# \u52d5\u4f5c\u78ba\u8a8d\nbatch_iterator = iter(dataloaders_dict[\"train\"])  # \u30a4\u30c6\u30ec\u30fc\u30bf\u306b\u5909\u63db\ninputs, labels = next(batch_iterator)  # 1\u756a\u76ee\u306e\u8981\u7d20\u3092\u53d6\u308a\u51fa\u3059\nprint('inputs size : {}'.format(inputs.size()))\nprint('labels size : {}'.format(labels.size()))","94454d73":"!mkdir -p \/tmp\/.cache\/torch\/checkpoints\/\n!cp ..\/input\/resnet18\/resnet18.pth \/tmp\/.cache\/torch\/checkpoints\/resnet18-5c106cde.pth","5038fb01":"model = Unet(\"resnet18\", encoder_weights=\"imagenet\", classes=4, activation=None)\n\nmodel.train()\n\nprint('\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u5b8c\u4e86\uff1a\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\u3057\u307e\u3057\u305f')","dd76987e":"criterion = nn.BCEWithLogitsLoss()","87e0036c":"optimizer = optim.Adam(\n    model.parameters(), lr=5e-4\n)","aa0d3509":"def dice_coeff(pred, mask):\n    with torch.no_grad():\n        batch_size = len(pred)\n        pred = pred.view(batch_size, -1) # Flatten\n        mask = mask.view(batch_size, -1)  # Flatten\n        pred = (pred>0.5).float()\n        mask = (mask>0.5).float()\n        smooth = 0.0001\n        intersection = (pred * mask).sum()\n        dice_pos = (2. * intersection + smooth) \/ (pred.sum() + mask.sum() + smooth) \n        intersection = ((pred + mask) == 0).sum()\n        dice_neg = (2. * intersection + smooth) \/ ((pred == 0).sum() + (mask == 0).sum() + smooth)\n        dice = (dice_pos + dice_neg) \/ 2.0\n        return dice.item()","75484cd4":"def train_model(model, dataloaders_dict, num_epoch, optimizer, criterion, train_loss, train_acc, val_loss, val_acc):\n    # \u521d\u671f\u8a2d\u5b9a\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    model = model.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b    \n    torch.backends.cudnn.benchmark = True\n    \n    num_train_imgs = len(dataloaders_dict['train'].dataset)\n    num_val_imgs = len(dataloaders_dict['val'].dataset)\n    batch_size = dataloaders_dict['train'].batch_size\n    \n    for epoch in range(num_epoch):\n    \n        print('Epoch {}\/{}'.format(epoch+1, num_epoch))\n        print('-------------')\n    \n        #---- Train section\n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        for img, mask in tqdm(dataloaders_dict['train']):\n        \n            model.train()\n\n            # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b   \n            img = img.to(device) \n            mask = mask.to(device)\n\n            # optimizer\u3092\u521d\u671f\u5316\n            optimizer.zero_grad()\n        \n            output = model(img)\n            loss =  criterion(output, mask)\n        \n            # \u8a13\u7df4\u6642\u306f\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n            loss.backward()\n            optimizer.step()\n        \n            # \u7d50\u679c\u306e\u8a08\u7b97\n            epoch_loss += loss.item() # loss\u306e\u5408\u8a08\u3092\u66f4\u65b0\n\n            prob = torch.sigmoid(output)\n            prob = prob.to('cpu').detach()\n            mask = mask.to('cpu').detach()\n        \n            # \u30c0\u30a4\u30b9\u4fc2\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n            epoch_acc += dice_coeff(prob, mask)\n        \n        train_loss.append(epoch_loss \/ num_train_imgs * batch_size)\n        train_acc.append(epoch_acc \/ num_train_imgs * batch_size)\n        \n        print('Train {} finished'.format(epoch + 1))\n        print('Loss : {}'.format(epoch_loss \/ num_train_imgs * batch_size))\n        print('Accuracy : {}'.format(epoch_acc \/ num_train_imgs * batch_size))\n    \n        #---- Val section\n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        with torch.no_grad():\n            for img, mask in tqdm(dataloaders_dict['val']):\n            \n                model.eval()\n            \n                # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n                img = img.to(device)\n                mask = mask.to(device)\n\n                output = model(img)\n                loss = criterion(output, mask)\n                \n                # \u7d50\u679c\u306e\u8a08\u7b97\n                epoch_loss += loss.item() # loss\u306e\u5408\u8a08\u3092\u66f4\u65b0\n\n                prob = torch.sigmoid(output)\n                prob = prob.to('cpu').detach()\n                mask = mask.to('cpu').detach()\n            \n                # \u30c0\u30a4\u30b9\u4fc2\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                epoch_acc += dice_coeff(prob, mask)\n            \n        val_loss.append(epoch_loss \/ num_val_imgs * batch_size)\n        val_acc.append(epoch_acc \/ num_val_imgs * batch_size)\n        \n        print('Valid {} finished'.format(epoch + 1))\n        print('Loss : {}'.format(epoch_loss \/ num_val_imgs * batch_size))\n        print('Accuracy : {}'.format(epoch_acc \/ num_val_imgs * batch_size))\n        \n        torch.save(model.state_dict(), '{}CP{}.pth'.format('.\/weights\/resnet18_', epoch + 1))\n        print('Checkpoint {} saved'.format(epoch + 1)) \n","b7da941e":"train_loss = []\ntrain_acc = []\nval_loss = []\nval_acc = []\nnum_epoch = 20\ntrain_model(model, dataloaders_dict, num_epoch, optimizer, criterion, train_loss, train_acc, val_loss, val_acc)","29585ee9":"plt.title('Resnet18')\nplt.xlabel(\"Epoch\")\nplt.plot(list(range(num_epoch)), train_acc, val_acc)\nplt.ylabel(\"Acc\")\nplt.legend(['Training Accuracy', 'Validation Accuracy'])\nplt.tight_layout()\nplt.grid(True)\nplt.savefig(\".\/logs\/acc.png\")","eb7494db":"plt.title('Resnet18')\nplt.xlabel(\"Epoch\")\nplt.plot(list(range(num_epoch)), train_loss, val_loss)\nplt.ylabel(\"Loss\")\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.tight_layout()\nplt.grid(True)\nplt.savefig(\".\/logs\/loss.png\")","a542f196":"# \u53ef\u8996\u5316","bfd48314":"# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\u4f5c\u6210","d5b0274e":"# \u30c7\u30fc\u30bf\u78ba\u8a8d","dbfa2ce9":"# \u5b66\u7fd2\u30fb\u691c\u8a3c\u3092\u5b9f\u65bd","74a12056":"# Data Augmentation","c12cdf97":"# \u640d\u5931\u95a2\u6570\u3092\u5b9a\u7fa9","ba8f056c":"# \u6700\u9069\u5316\u624b\u6cd5\u3092\u6c7a\u5b9a","b875a16e":"## csv\u30d5\u30a1\u30a4\u30eb","ebab0b53":"# DataLoader\u4f5c\u6210","6b76b3c8":"# \u30de\u30b9\u30af\u753b\u50cf\u4f5c\u6210","bcb4731a":"## \u753b\u50cf\u30c7\u30fc\u30bf"}}