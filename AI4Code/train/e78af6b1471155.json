{"cell_type":{"216bfc9f":"code","365a8c9f":"code","0c1021a9":"code","d3ede11a":"code","6a3559a9":"code","b6c36983":"code","86230ae2":"code","f7c315c0":"code","2dbed47c":"code","9a924f5b":"code","747415ac":"code","d8869989":"code","131de4dc":"code","7526374d":"code","4faa90dc":"code","6e7c6133":"code","7ce69e8e":"code","68dbee02":"code","75f30688":"code","43793137":"code","754c5f22":"code","1fca97d9":"code","bb03f32b":"code","27a8b109":"code","e1f27863":"code","6ba634ec":"code","8e53224b":"code","4bafbc99":"code","7147d8ba":"code","106d61b2":"code","84f31bde":"code","d46e7a18":"code","cc9920e1":"code","f949db62":"code","1787ab3e":"code","9e641b9b":"code","75f195c4":"code","74f28a00":"code","c0997e71":"code","31dc6a51":"code","7ac12215":"code","0757fcd6":"code","15964532":"markdown","ee719100":"markdown","85f1cf51":"markdown","bc207be1":"markdown","a1c58850":"markdown","d94db743":"markdown","15677933":"markdown","66ad5dd3":"markdown","4d8110a1":"markdown","cf864cd4":"markdown","25a284d8":"markdown","cf2ee42e":"markdown","c2da9392":"markdown","15aefbb9":"markdown","1b3d6f74":"markdown","daec54f6":"markdown","57de6e07":"markdown","454bfc9a":"markdown","5dae5f71":"markdown","3f79f009":"markdown","9803c2bf":"markdown","c687a619":"markdown","bd551974":"markdown","d5bb9a66":"markdown","bc62558d":"markdown"},"source":{"216bfc9f":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os","365a8c9f":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder","0c1021a9":"path_in = '..\/input\/ashrae-energy-prediction\/'\nprint(os.listdir(path_in))","d3ede11a":"train_data = pd.read_csv(path_in+'train.csv', parse_dates=['timestamp'])\ntrain_weather = pd.read_csv(path_in+'weather_train.csv', parse_dates=['timestamp'])\nbuilding_data = pd.read_csv(path_in+'building_metadata.csv')","6a3559a9":"def plot_bar(data, name):\n    fig = plt.figure(figsize=(16, 9))\n    ax = fig.add_subplot(111)\n    data_label = data[name].value_counts()\n    dict_train = dict(zip(data_label.keys(), ((data_label.sort_index())).tolist()))\n    names = list(dict_train.keys())\n    values = list(dict_train.values())\n    plt.bar(names, values)\n    ax.set_xticklabels(names, rotation=45)\n    plt.grid()\n    plt.show()","b6c36983":"print('# samples train_data:', len(train_data))\nprint('# samples train_weather:', len(train_weather))\nprint('# samples building_data:', len(building_data))","86230ae2":"train_data.head()","f7c315c0":"train_weather.head()","2dbed47c":"building_data.head()","9a924f5b":"cols_with_missing_train_data = [col for col in train_data.columns if train_data[col].isnull().any()]\ncols_with_missing_train_weather = [col for col in train_weather.columns if train_weather[col].isnull().any()]\ncols_with_missing_building = [col for col in building_data.columns if building_data[col].isnull().any()]","747415ac":"print(cols_with_missing_train_data)\nprint(cols_with_missing_train_weather)\nprint(cols_with_missing_building)","d8869989":"train_data['month'] = train_data['timestamp'].dt.month\ntrain_data['day'] = train_data['timestamp'].dt.weekday\ntrain_data['hour'] = train_data['timestamp'].dt.hour","131de4dc":"train_data['weekend'] = np.where((train_data['day'] == 5) | (train_data['day'] == 6), 1, 0)","7526374d":"features_cyc = {'month' : 12, 'day' : 7, 'hour' : 24}\nfor feature in features_cyc.keys():\n    train_data[feature+'_sin'] = np.sin((2*np.pi*train_data[feature])\/features_cyc[feature])\n    train_data[feature+'_cos'] = np.cos((2*np.pi*train_data[feature])\/features_cyc[feature])\ntrain_data = train_data.drop(features_cyc.keys(), axis=1)","4faa90dc":"train_data = pd.get_dummies(train_data, columns=['meter'])","6e7c6133":"train_data.head()","7ce69e8e":"imp_most = SimpleImputer(strategy='most_frequent')","68dbee02":"building_data[cols_with_missing_building] = imp_most.fit_transform(building_data[cols_with_missing_building])","75f30688":"plot_bar(building_data, 'primary_use')","43793137":"map_use = dict(zip(building_data['primary_use'].value_counts().sort_index().keys(),\n                     range(1, len(building_data['primary_use'].value_counts())+1)))","754c5f22":"building_data['primary_use'] = building_data['primary_use'].replace(map_use)","1fca97d9":"building_data = pd.get_dummies(building_data, columns=['primary_use'])","bb03f32b":"building_scale = ['square_feet', 'year_built', 'floor_count']","27a8b109":"mean = building_data[building_scale].mean(axis=0)\nbuilding_data[building_scale] = building_data[building_scale].astype('float32')\nbuilding_data[building_scale] -= building_data[building_scale].mean(axis=0)\nstd = building_data[building_scale].std(axis=0)\nbuilding_data[building_scale] \/= building_data[building_scale].std(axis=0)","e1f27863":"building_data.head()","6ba634ec":"weather_int = ['cloud_coverage']\nweather_cyc = ['wind_direction']\nweather_scale = ['air_temperature', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_speed']","8e53224b":"imp_most = SimpleImputer(strategy='most_frequent')\ntrain_weather[cols_with_missing_train_weather] = imp_most.fit_transform(train_weather[cols_with_missing_train_weather])","4bafbc99":"train_weather['wind_direction'+'_sin'] = np.sin((2*np.pi*train_weather['wind_direction'])\/360)\ntrain_weather['wind_direction'+'_cos'] = np.cos((2*np.pi*train_weather['wind_direction'])\/360)\ntrain_weather = train_weather.drop(['wind_direction'], axis=1)","7147d8ba":"mean = train_weather[weather_scale].mean(axis=0)\ntrain_weather[weather_scale] = train_weather[weather_scale].astype('float32')\ntrain_weather[weather_scale] -= train_weather[weather_scale].mean(axis=0)\nstd = train_weather[weather_scale].std(axis=0)\ntrain_weather[weather_scale] \/= train_weather[weather_scale].std(axis=0)","106d61b2":"train_weather.head()","84f31bde":"train_data = pd.merge(train_data, building_data, on='building_id', right_index=True)\ntrain_data = train_data.sort_values(['timestamp'])\ntrain_data = pd.merge_asof(train_data, train_weather, on='timestamp', by='site_id', right_index=True)\ndel building_data\ndel train_weather","d46e7a18":"train_data = train_data.sort_index()","cc9920e1":"no_feature = ['building_id', 'timestamp', 'meter_reading', 'site_id']","f949db62":"X_train = train_data[train_data.columns.difference(no_feature)].copy(deep=False)\ny_train = train_data['meter_reading']","1787ab3e":"del train_data","9e641b9b":"X_train.head()","75f195c4":"y_train_scaled = np.log1p(y_train)","74f28a00":"y_train_scaled.hist(bins=50)","c0997e71":"y_train_scaled[110:115]","31dc6a51":"y_test = np.expm1(y_train_scaled)","7ac12215":"y_test[110:115]","0757fcd6":"def rmse(y_true, y_pred):\n    \"\"\" root_mean_squared_error \"\"\"\n    return K.sqrt(K.mean(K.square(y_pred - y_true)))","15964532":"## Weather data\n","ee719100":"### Encoding\nWe created the features month, day and hour which are cyclic. ","85f1cf51":"## Have a look on the data","bc207be1":"## Building data\n### Handle missing data","a1c58850":"# Evaluation Metric\nThe evaluation metric for this competition is Root Mean Squared Logarithmic Error. <br>\nhttps:\/\/www.kaggle.com\/c\/ashrae-energy-prediction\/overview\/evaluation","d94db743":"# Merge the data","15677933":"# Scale and rescale y_train\nThe target value ist energy consumption in kWh (or equivalent). Note that this is real data with measurement error, which we expect will impose a baseline level of modeling error.\nTo train we recommend to scale y_train and rescale the predicted y_test.","66ad5dd3":"### Encoding\nThe feature primary_use is a categorical feature with 16 categories. For the first we use a simple mapping.","4d8110a1":"### Scale","cf864cd4":"# Feature engineering\nWe handle the missing values, create new features and use encoding techniques based on<br>\nhttps:\/\/www.kaggle.com\/drcapa\/categorical-feature-encoding-challenge-xgb\n","25a284d8":"## Extract missing data\n* train_data: no missing values\n* train_weather: there are some missing values we have to deal with\n* builing_data: there are missing values for the features year_build and floor_count\n\nThe missing data are numerical values.","cf2ee42e":"# Next Steps\n\nFurther the feature enginneering can be extended:\n* Are there any holidays?\n* Is there any realationship between the features?","c2da9392":"### Encoding\nThe feature wind_direction is the compass direction (0-360) and cyclic.","15aefbb9":"# Model\n**Current score: 3.09**\n\nTo create and train a model you can use for example a simple neural network like <br>\nhttps:\/\/www.kaggle.com\/drcapa\/ashrae-datagenerator-neuralnetwork\n\nThere is also used a DataGenerator. Because of the big data we need a lot of time to train end predict. We recommend to download the kernel and calculate local. So you have more than 9 hours and can reach good results. ","1b3d6f74":"# Help functions","daec54f6":"Additionally we create the feature weekend: 5 = saturday and 6 = sunday.","57de6e07":"There are 4 types of meters: <br>\n0 = electricity, 1 = chilledwater, 2 = steam, 3 = hotwater <br>\nWe use the one hot encoding for this 4 feature.","454bfc9a":"## Train data\n### New features\nBased on the timestamp we create new features for the month, the day the hour and the year. These are cyclic features. ","5dae5f71":"### Scale","3f79f009":"# Welcome to the ASHRAE - Great Energy Predictor Competition\nThis notebook is a starter code for all beginners and easy to understand.<br>\nWe focus on\n* a simple analysis of the data,\n* create new features,\n* hanlde missing data,\n* encoding and \n* scale data. <br>\n\nWe use categorical feature encoding techniques, compare<br>\nhttps:\/\/www.kaggle.com\/drcapa\/categorical-feature-encoding-challenge-xgb\n\nIn this kernel we consider the train data. For prediction we must repeate all operations also for the test data. <br>\nFinally we merge the train data with weahter and building date. After that we define X_train and y_train.","9803c2bf":"# Analysis\nFirst we do a simple analysis.","c687a619":"### Handle missing data ","bd551974":"# Load Libraries\nWe need the standard python libraries and some libraries of sklearn.","d5bb9a66":"# Define X_train and y_train","bc62558d":"# Load Data"}}