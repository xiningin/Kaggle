{"cell_type":{"70bb4cd5":"code","007bae60":"code","22aa2692":"code","c7e58572":"code","017a224f":"code","a37dc7cf":"code","20bacdba":"code","4ca22ebd":"code","e5423522":"code","e2bf8fd3":"code","ee7c0241":"code","29284de0":"code","10712a88":"code","e06182fc":"code","7575ecb8":"markdown","415c05a3":"markdown","3f9be1b2":"markdown","4f269e78":"markdown","b150e858":"markdown","9dd7ec92":"markdown"},"source":{"70bb4cd5":"import keras\nfrom keras import regularizers, optimizers\nfrom keras import losses\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Input, Dropout, Embedding, LSTM\nfrom keras.optimizers import RMSprop, Adam, Nadam\nfrom keras.preprocessing import sequence\n\nfrom keras.layers import Conv1D, Flatten, Activation, SpatialDropout1D\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.utils import to_categorical\n\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\n\nimport tensorflow \nimport sys","007bae60":"path = '..\/input\/creditcardfraud\/creditcard.csv'\ndf = pd.read_csv(path, sep=\",\", index_col=None)\ndf.head()","22aa2692":"# Standardize\ndf['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\ndf['Time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))","c7e58572":"anomalies = df[df[\"Class\"] == 1]\nnormal = df[df[\"Class\"] == 0]\n\nanomalies.shape, normal.shape","017a224f":"for f in range(0, 20):\n    normal = normal.iloc[np.random.permutation(len(normal))]\n    \n\ndata_set = pd.concat([normal[:2000], anomalies])\n\nx_train, x_test = train_test_split(data_set, test_size = 0.4, random_state = 42)\n\nx_train = x_train.sort_values(by=['Time'])\nx_test = x_test.sort_values(by=['Time'])\n\ny_train = x_train[\"Class\"]\ny_test = x_test[\"Class\"]\n\nx_train.head(10)","a37dc7cf":"x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\nx_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\ninput_shape = (x_train.shape[1], 1)\n\ny_train = keras.utils.to_categorical(y_train, 2)\ny_test = keras.utils.to_categorical(y_test, 2)\n\nprint(\"Shapes:\\nx_train:%s\\ny_train:%s\\n\" % (x_train.shape, y_train.shape))\nprint(\"x_test:%s\\ny_test:%s\\n\" % (x_test.shape, y_test.shape))\nprint(\"input_shape:{}\\n\".format(input_shape))","20bacdba":"input_layer = Input(shape=(input_shape ))\n\n#Series of temporal convolutional layers with dilations increasing by powers of 2.\nconv_1 = Conv1D(filters=128, kernel_size=2, dilation_rate=1,\n                padding='causal', strides=1,input_shape=input_shape,\n                kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(input_layer)\n\n#Dropout layer after each 1D-convolutional layer\ndrop_1 = SpatialDropout1D(0.05)(conv_1)\n\nconv_2 = Conv1D(filters=128, kernel_size=2, dilation_rate=2,\n                padding='causal',strides=1, kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(drop_1)\n\ndrop_2 = SpatialDropout1D(0.05)(conv_2)\n\nconv_3 = Conv1D(filters=128, kernel_size=2, dilation_rate=4,\n                padding='causal', strides=1,kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(drop_2)\n\ndrop_3 = SpatialDropout1D(0.05)(conv_3)\n\nconv_4 = Conv1D(filters=128, kernel_size=2, dilation_rate=8,\n                padding='causal', strides=1,kernel_regularizer=regularizers.l2(0.05),\n                activation='relu')(drop_3)\n\ndrop_4 = SpatialDropout1D(0.05)(conv_4)\n\n#Flatten layer to feed into the output layer\nflat = Flatten()(drop_4)\n\noutput_layer = Dense(2, activation='softmax')(flat)\n\nTCN = Model(inputs=input_layer, outputs=output_layer)","4ca22ebd":"TCN.compile(loss='mean_squared_error',\n              optimizer=optimizers.Adam(lr=0.002),\n              metrics=['mae', 'accuracy'])\n\ncheckpointer = ModelCheckpoint(filepath=\"model_TCN_creditcard.h5\",\n                               verbose=0,\n                               save_best_only=True)\n\nTCN.summary()","e5423522":"TCN.fit(x_train, y_train,\n          batch_size=128,\n          epochs=10,\n          verbose=1,\n          validation_data=(x_test, y_test))","e2bf8fd3":"score = TCN.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","ee7c0241":"preds = TCN.predict(x_test)\ny_pred = np.round(preds)\nprint(y_pred)\nauc = roc_auc_score( y_pred, y_test)\nprint(\"AUC: {:.2%}\".format (auc))","29284de0":"print(classification_report(y_test, y_pred))","10712a88":"class Visualization:\n    labels = [\"Normal\", \"Anomaly\"]\n\n    def draw_confusion_matrix(self, y, ypred):\n        matrix = confusion_matrix(y, ypred)\n\n        plt.figure(figsize=(10, 8))\n        colors=[ \"orange\",\"green\"]\n        sns.heatmap(matrix, xticklabels=self.labels, yticklabels=self.labels, cmap=colors, annot=True, fmt=\"d\")\n        plt.title(\"Confusion Matrix\")\n        plt.ylabel('Actual')\n        plt.xlabel('Predicted')\n        plt.show()\n\n\n    def draw_anomaly(self, y, error, threshold):\n        groupsDF = pd.DataFrame({'error': error,\n                                 'true': y}).groupby('true')\n\n        figure, axes = plt.subplots(figsize=(12, 8))\n\n        for name, group in groupsDF:\n            axes.plot(group.index, group.error, marker='x' if name == 1 else 'o', linestyle='',\n                    color='r' if name == 1 else 'g', label=\"Anomaly\" if name == 1 else \"Normal\")\n\n        axes.hlines(threshold, axes.get_xlim()[0], axes.get_xlim()[1], colors=\"b\", zorder=100, label='Threshold')\n        axes.legend()\n        \n        plt.title(\"Anomalies\")\n        plt.ylabel(\"Error\")\n        plt.xlabel(\"Data\")\n        plt.show()\n\n    def draw_error(self, error, threshold):\n            plt.plot(error, marker='o', ms=3.5, linestyle='',\n                     label='Point')\n\n            plt.hlines(threshold, xmin=0, xmax=len(error)-1, colors=\"b\", zorder=100, label='Threshold')\n            plt.legend()\n            plt.title(\"Reconstruction error\")\n            plt.ylabel(\"Error\")\n            plt.xlabel(\"Data\")\n            plt.show()","e06182fc":"visualize = Visualization()\ny_pred2 = np.argmax(y_pred, axis=1)\ny_test2 = np.argmax(y_test, axis=1)\nvisualize.draw_confusion_matrix(y_test2, y_pred2)","7575ecb8":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/312305\/633246\/752964d08f6001573444649668b0b011\/dataset-cover.jpg?t=2019-08-22-03-58-44\" class=\"Header_CoverImg-sc-1431b7d ibFJYv\">\n<\/div>","415c05a3":"<h1 id=\"dataset\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","3f9be1b2":"<h1 id=\"visualization\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Visaulization\n        <a class=\"anchor-link\" href=\"#visualization\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","4f269e78":"<h1 id=\"tcn\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Temporal Convolutional Neural Network\n        <a class=\"anchor-link\" href=\"#tcn\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","b150e858":"<h1 id=\"training\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","9dd7ec92":"<h1 id=\"analyze\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Analyze\n        <a class=\"anchor-link\" href=\"#analyze\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}