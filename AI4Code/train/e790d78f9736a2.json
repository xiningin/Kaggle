{"cell_type":{"e28902d1":"code","330f8bf1":"code","b4d61d38":"code","c7c6f117":"code","342cff22":"code","6f2f6a1c":"code","e80e80b1":"code","b01d8770":"markdown"},"source":{"e28902d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","330f8bf1":"import pydicom\nimport os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nfrom matplotlib import pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom tqdm import tqdm\nimport glob2","b4d61d38":"#for training only\ndef show_dcm_info(dataset):\n    print(\"Filename.........:\", file_path)\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    print()\n\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    print(\"View Position.......:\", dataset.ViewPosition)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)","c7c6f117":"def plot_pixel_array(dataset, figsize=(10,10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","342cff22":"for file_path in glob2.glob('..\/input\/siim-train-test\/dicom-images-train\/**\/*.dcm'):\n    dataset = pydicom.dcmread(file_path)\n    show_dcm_info(dataset)\n    plot_pixel_array(dataset)\n    break","6f2f6a1c":"sz = 256\nsz0 = 1024\nPATH_TRAIN0 = '..\/input\/siim-train-test\/dicom-images-train\/'\nPATH_TRAIN1 = '..\/input\/siim-train-test\/dicom-images-test\/'\nPATH_TEST = '..\/input\/siim-acr-pneumothorax-segmentation\/stage_2_images\/'\ntrain_out = 'train.zip'\ntest_out = 'test.zip'\nmask_out = 'masks.zip'\ntrain = glob2.glob(os.path.join(PATH_TRAIN0, '**\/*.dcm'))+glob2.glob(os.path.join(PATH_TRAIN1, '**\/*.dcm'))\ntest = glob2.glob(os.path.join(PATH_TEST, '**\/*.dcm'))","e80e80b1":"len(train)","b01d8770":"# Read IMGs"}}