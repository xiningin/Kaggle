{"cell_type":{"878b68dd":"code","e758f343":"code","30b78bb0":"code","0bd3615c":"code","4e552e29":"code","dc9e5f45":"code","d5c63b23":"code","ca283b10":"code","eccd93c1":"code","ff335f72":"code","09b9e091":"code","6bfbf4d0":"code","23b440ea":"code","3cbc544d":"code","ac9e8ceb":"markdown","4395ea58":"markdown","97f4734a":"markdown","f6cd8489":"markdown","7240ed6a":"markdown","bed7ba2d":"markdown","5dc4d9b1":"markdown","c6cb61ec":"markdown","7afc28e6":"markdown"},"source":{"878b68dd":"ComputeLB = False\n\nimport os, gc, zipfile\nimport numpy as np, pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport librosa \nimport cv2\n\nPATH='..\/input\/hah-data-science-challenge\/'","e758f343":"# change wave data to mel-stft\ndef calculate_melsp(x, n_fft=1024, hop_length=128):\n    stft = np.abs(librosa.stft(x, n_fft=n_fft, hop_length=hop_length))**2\n    log_stft = librosa.power_to_db(stft)\n    melsp = librosa.feature.melspectrogram(S=log_stft,n_mels=128)\n    return melsp","30b78bb0":"train = pd.read_csv(\"..\/input\/hah-data-science-challenge\/train.csv\")\nsmpl_sub = pd.read_csv(\"..\/input\/hah-data-science-challenge\/test.csv\")","0bd3615c":"train = train[train.Target==0]\ntrain['Target']=train['Target'].astype('int64')\ntrain=train.reset_index()","4e552e29":"os.mkdir('..\/tmp')\nos.mkdir('..\/tmp\/images')","dc9e5f45":"# CREATE RANDOMLY CROPPED IMAGES\nfor i in range(len(train)):\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n    #img = img.reshape(512,512)\n    cv2.imwrite('..\/tmp\/images\/'+str(i)+'.png', img)\n    #img.save('..\/tmp\/images\/'+str(i)+'.png','PNG')","d5c63b23":"from keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\nBATCH_SIZE = 64; EPOCHS = 16\ntrain_datagen = ImageDataGenerator()\ntrain_batches = train_datagen.flow_from_directory('..\/tmp\/',\n        target_size=(256,256), shuffle=True, class_mode='input', batch_size=BATCH_SIZE, color_mode='grayscale')","ca283b10":"# ENCODER\ninput_img = Input(shape=(256, 256,1))  \nx = Conv2D(48, (3, 3), activation='relu', padding='same')(input_img)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nencoded = Conv2D(32, (1, 1), activation='relu', padding='same')(x)\n\n# LATENT SPACE\nlatentSize = (32,32,32)\n\n# DECODER\ndirect_input = Input(shape=latentSize)\nx = Conv2D(192, (1, 1), activation='relu', padding='same')(direct_input)\nx = BatchNormalization()(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(48, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n# COMPILE\nencoder = Model(input_img, encoded)\ndecoder = Model(direct_input, decoded)\nautoencoder = Model(input_img, decoder(encoded))\n\nautoencoder.compile(optimizer='Adam', loss='binary_crossentropy')","eccd93c1":"history = autoencoder.fit_generator(train_batches,\n        steps_per_epoch = train_batches.samples \/\/ BATCH_SIZE,\n        epochs = EPOCHS, verbose=2)","ff335f72":"for i in range(10):\n\n    plt.figure(figsize=(15,5))\n    plt.subplot(1,3,1)\n    \n    # ORIGINAL IMAGE\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n    plt.title('Original')\n    plt.imshow(img)\n\n    # LATENT IMAGE\n    latent_img = encoder.predict(img.reshape(1,256,256))\n    #mx = np.max( latent_img[0] )\n    #mn = np.min( latent_img[0] )\n    #latent_flat = ((latent_img[0] - mn) * 255\/(mx - mn)).flatten(order='F')\n    #img = Image.fromarray( latent_flat[:2025].astype('uint8').reshape((45,45)), mode='L') \n    plt.subplot(1,3,2)\n    plt.title('Latent')\n    plt.xlim((-10,55))\n    plt.ylim((-10,55))\n    plt.axis('off')\n    plt.imshow(latent_img[:,:,1][0])\n\n    # RECONSTRUCTED IMAGE\n    decoded_imgs = decoder.predict(latent_img[0].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n    #img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((64,64,3)))\n    plt.subplot(1,3,3)\n    plt.title('Reconstructed')\n    plt.imshow(decoded_imgs[0])\n    \n    plt.show()","09b9e091":"diff_mean=np.zeros([len(train),1])\nfor i in range(len(train)):\n    \n    # ORIGINAL IMAGE\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n\n    # LATENT IMAGE\n    latent_img = encoder.predict(img.reshape(1,256,256))\n\n    # RECONSTRUCTED IMAGE\n    decoded_imgs = decoder.predict(latent_img[0].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n    \n    diff = np.abs(img-decoded_imgs)\n    diff_mean[i]=np.mean(diff)\n\nplt.figure(figsize=(5,5))\nplt.hist(diff_mean)\nplt.show()","6bfbf4d0":"train = pd.read_csv(\"..\/input\/hah-data-science-challenge\/train.csv\")\n\ntrain = train[train.Target==1]\ntrain['Target']=train['Target'].astype('int64')\ntrain=train.reset_index()\n\nfor i in range(2):\n\n    plt.figure(figsize=(15,5))\n    plt.subplot(1,3,1)\n    \n    # ORIGINAL IMAGE\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n    plt.title('Original')\n    plt.imshow(img)\n\n    # LATENT IMAGE\n    latent_img = encoder.predict(img.reshape(1,256,256))\n    #mx = np.max( latent_img[0] )\n    #mn = np.min( latent_img[0] )\n    #latent_flat = ((latent_img[0] - mn) * 255\/(mx - mn)).flatten(order='F')\n    #img = Image.fromarray( latent_flat[:2025].astype('uint8').reshape((45,45)), mode='L') \n    plt.subplot(1,3,2)\n    plt.title('Latent')\n    plt.xlim((-10,55))\n    plt.ylim((-10,55))\n    plt.axis('off')\n    plt.imshow(latent_img[:,:,1][0])\n\n    # RECONSTRUCTED IMAGE\n    decoded_imgs = decoder.predict(latent_img[0].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n    #img = Image.fromarray( (255*decoded_imgs[0]).astype('uint8').reshape((64,64,3)))\n    plt.subplot(1,3,3)\n    plt.title('Reconstructed')\n    plt.imshow(decoded_imgs[0])\n    \n    plt.show()","23b440ea":"diff_mean2=np.zeros([len(train),1])\nfor i in range(len(train)):\n    \n    # ORIGINAL IMAGE\n    y, sr = librosa.core.load(PATH+'\/train\/train\/'+train[\"\u30d5\u30a1\u30a4\u30eb\"].values[i],sr=None)\n    y = librosa.util.normalize(y)\n    melsp = calculate_melsp(y)\n    img = melsp\n    img = cv2.resize(img,(256,256))\n\n    # LATENT IMAGE\n    latent_img = encoder.predict(img.reshape(1,256,256))\n\n    # RECONSTRUCTED IMAGE\n    decoded_imgs = decoder.predict(latent_img[0].reshape((-1,latentSize[0],latentSize[1],latentSize[2])))\n    \n    diff = np.abs(img-decoded_imgs)\n    diff_mean2[i]=np.mean(diff)\n\nplt.figure(figsize=(5,5))\nplt.hist(diff_mean2)\nplt.show()","3cbc544d":"plt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.hist(diff_mean,color = 'red')\nplt.title('Target=0')\nplt.subplot(1,2,2)\nplt.hist(diff_mean2,color = 'blue')\nplt.title('Target=1')\nplt.show()","ac9e8ceb":"\u97f3\u58f0\u30c7\u30fc\u30bf\u3092\u30e1\u30eb\u30b9\u30da\u30af\u30c8\u30b0\u30e9\u30e0\u306b\u5909\u63db\u3057\u307e\u3059\u3002","4395ea58":"\u6b21\u306b\u3001Target=0\u306e\u5143\u753b\u50cf\u3068\u30c7\u30b3\u30fc\u30c0\u30fc\u3067\u51fa\u529b\u3055\u305b\u305f\u753b\u50cf\u3068\u306e\u5dee\u5206\u3092\u53d6\u308a\u3001\n\u3069\u308c\u304f\u3089\u3044\u306e\u983b\u5ea6\u306b\u306a\u308b\u306e\u304b\u3092\u898b\u3066\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002","97f4734a":"\u7d9a\u3044\u3066\u3001Target=1\u3092\u53ef\u8996\u5316\u3057\u3066\u307f\u307e\u3059\u3002","f6cd8489":"\u53ef\u8996\u5316\u3057\u3066\u307f\u307e\u3059\uff01","7240ed6a":"**Auto-Encoder\u3092\u4f7f\u3063\u3066\u691c\u8a0e\u3057\u3066\u307f\u307e\u3057\u305f\u3002**","bed7ba2d":"Target=0\u306e\u307f\u3092\u5b66\u7fd2\u3055\u305b\u307e\u3059\uff01","5dc4d9b1":"\u3046\uff5e\u3093\u3002\u5fae\u5999\u3002\u3002\u3002\n\n\u3053\u306e\u7d50\u679c\u3092\u898b\u308b\u3068AE\u3067Target=0\u3068Target=1\u3092\u533a\u5225\u3059\u308b\u306e\u304c\u96e3\u3057\u305d\u3046\u3067\u3059\u3002\u3002\u3002","c6cb61ec":"# ENCODER\ninput_img = Input(shape=(256, 256,1))  \nx = Conv2D(1, (3, 3), activation='relu', padding='same')(input_img)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nencoded = Conv2D(1, (1, 1), activation='relu', padding='same')(x)\n\n# LATENT SPACE\nlatentSize = (32,32,1)\n\n# DECODER\ndirect_input = Input(shape=latentSize)\nx = Conv2D(1, (1, 1), activation='relu', padding='same')(direct_input)\nx = BatchNormalization()(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n# COMPILE\nencoder = Model(input_img, encoded)\ndecoder = Model(direct_input, decoded)\nautoencoder = Model(input_img, decoder(encoded))\n\nautoencoder.compile(optimizer='Adam', loss='binary_crossentropy')","7afc28e6":"\u6b21\u306b\u3001Target=1\u306e\u5143\u753b\u50cf\u3068\u30c7\u30b3\u30fc\u30c0\u30fc\u3067\u51fa\u529b\u3055\u305b\u305f\u753b\u50cf\u3068\u306e\u5dee\u5206\u3092\u53d6\u308a\u3001\n\u3069\u308c\u304f\u3089\u3044\u306e\u983b\u5ea6\u306b\u306a\u308b\u306e\u304b\u3092\u898b\u3066\u307f\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002"}}