{"cell_type":{"ed5a062a":"code","628ae6e3":"code","33d84d6a":"code","9300fc91":"code","46b00319":"code","be7c4d27":"code","eb4888a8":"code","7542c77f":"code","a8ddecaf":"code","ff19ba58":"code","fffae831":"code","8ae93caa":"code","3b1a8636":"code","1d7e96f5":"code","3ce169dc":"markdown","27e7ed3a":"markdown"},"source":{"ed5a062a":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\ntrain = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.head()","628ae6e3":"book_example = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0')\ntrade_example =  pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/stock_id=0')\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id","33d84d6a":"book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) \/ (\n                                       book_example['bid_size1']+ book_example['ask_size1'])","9300fc91":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"wap\", title='WAP of stock_id_0, time_id_5')\nfig.show()","46b00319":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() ","be7c4d27":"book_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example = book_example[~book_example['log_return'].isnull()]","eb4888a8":"fig = px.line(book_example, x=\"seconds_in_bucket\", y=\"log_return\", title='Log return of stock_id_0, time_id_5')\nfig.show()","7542c77f":"def realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')","a8ddecaf":"import os\nfrom sklearn.metrics import r2_score\nimport glob\n\nlist_order_book_file_train = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')","ff19ba58":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\ntrain['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n\nmodel_dict = {}\n\ndef realized_volatility_per_time_id_linear(file_path, prediction_column_name, train_test = True):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  \/ (\n                                      df_book_data['bid_size1']+ df_book_data[\n                                  'ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    \n    poly = PolynomialFeatures(degree=3)\n    \n    if train_test:\n        \n        df_realized_vol_per_stock_joined = train.merge(df_realized_vol_per_stock[['row_id',prediction_column_name]], on = ['row_id'], how = 'right')\n\n        weights = 1\/np.square(df_realized_vol_per_stock_joined.target)\n\n        X = np.array(df_realized_vol_per_stock_joined[[prediction_column_name]]).reshape(-1, 1)\n        X_ = poly.fit_transform(X)\n        y = df_realized_vol_per_stock_joined.target\n\n\n        reg = LinearRegression().fit(X_, y, sample_weight = weights)\n        df_realized_vol_per_stock[[prediction_column_name]] = reg.predict(X_)\n\n        model_dict[stock_id] = reg\n\n    else: \n        \n        reg = model_dict[stock_id]\n        \n        X = np.array(df_realized_vol_per_stock[[prediction_column_name]]).reshape(-1, 1)\n        X_ = poly.fit_transform(X)\n        df_realized_vol_per_stock[[prediction_column_name]] = reg.predict(X_)\n    \n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]","fffae831":"def past_realized_volatility_per_stock_linear(list_file,prediction_column_name, train_test = True):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id_linear(file,prediction_column_name,train_test)])\n    return df_past_realized\n\ndf_past_realized_train = past_realized_volatility_per_stock_linear(list_file=list_order_book_file_train,prediction_column_name='pred')","8ae93caa":"train = train[['row_id','target']]\ndf_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')","3b1a8636":"from sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\nR2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nRMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","1d7e96f5":"list_order_book_file_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')\ndf_naive_pred_test = df_past_realized_train = past_realized_volatility_per_stock_linear(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target', train_test = False)\ndf_naive_pred_test.to_csv('submission.csv',index = False)","3ce169dc":"# Weighted Regression Baseline\n\nThe idea of this notebook is to show that a simple weight help optimise the RMSPE as discussed here : https:\/\/www.kaggle.com\/c\/optiver-realized-volatility-prediction\/discussion\/250324\n\nI got the idea to work on individual stock regression and the importance of taking the custom evaluation into account in my EDA Notebook here : https:\/\/www.kaggle.com\/lucasmorin\/target-error-exploration-stock-time-clustering\n","27e7ed3a":"Submission"}}