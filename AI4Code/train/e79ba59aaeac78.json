{"cell_type":{"ff65cc6f":"code","9229700a":"code","119027a3":"code","c0ace3c0":"code","c6732605":"code","7bd1a741":"code","b3e899b4":"code","8cca6cec":"code","a53a59c9":"code","1c1e57c1":"code","188d5729":"code","5f8ec77b":"code","5804b4e0":"code","f67c0df2":"code","463570ab":"code","d7a0484a":"code","c225d4a3":"code","ae0c60b2":"code","76b1ecf8":"code","39777c46":"code","fa6c8997":"code","67257f0f":"code","abcdd436":"markdown","72e33bcf":"markdown","e2c752c2":"markdown","94bfa3d4":"markdown","3d33548e":"markdown","a7daad52":"markdown","a241137f":"markdown","af7e99c3":"markdown","102fa7f1":"markdown"},"source":{"ff65cc6f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\ndf_train = pd.read_csv(\"..\/input\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\")\n\nX_train = df_train.drop(\"label\",axis =1).values\ny_train = df_train[\"label\"].values\n\nX_test = df_test.values\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","9229700a":"# \u691c\u8a3c\u7528\u306e\u30c7\u30fc\u30bf\u4f5c\u6210\nrandom_seed = 1\nX_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, random_state=random_seed)","119027a3":"# \u5b9a\u6570\u5b9a\u7fa9\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n\n# \u6559\u5e2b\u30c7\u30fc\u30bf\u306e\u5206\u5e03\u3092\u78ba\u8a8d\nsns.countplot(y_train)\n\n# \u6b20\u640d\u5024\u306e\u78ba\u8a8d\ndf_train.isnull().any().describe() # unique:\u7a2e\u985e, top:\u6700\u983b\u5024, freq:\u6700\u983b\u5024\u306e\u51fa\u73fe\u56de\u6570","c0ace3c0":"# \u6b63\u898f\u5316\nX_train_split = X_train_split\/255\nX_test_split = X_test_split\/255\nX_test = X_test\/255\nX_train_all = X_train\/255\n\n# Reshape\nX_train_split = X_train_split.reshape(-1,img_rows, img_cols, 1)\nX_test_split = X_test_split.reshape(-1,img_rows, img_cols, 1)\nX_test = X_test.reshape(-1,img_rows, img_cols,1)\nX_train_all = X_train_all.reshape(-1, img_rows, img_cols, 1)\n\n# one-hot-encoding\ny_train_split = to_categorical(y_train_split, num_classes)\ny_test_split = to_categorical(y_test_split, num_classes)\ny_train_all = to_categorical(y_train, num_classes)\n\n#np.shape(X_train_split) # (31500, 784)","c6732605":"plt.imshow(X_train_split[0][:,:,0])","7bd1a741":"#Data Augmentation\n# split\u7528\u306eDataAugmentation\u306e\u4f5c\u6210\ndatagen_split = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range=0.1, # \u30e9\u30f3\u30c0\u30e0\u306b\u30ba\u30fc\u30e0\u3059\u308b\u7bc4\u56f2\n    width_shift_range=0.1, # \u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u30b7\u30d5\u30c8\u3059\u308b\u7bc4\u56f2\n    height_shift_range=0.1, # \u30e9\u30f3\u30c0\u30e0\u306b\u5782\u76f4\u30b7\u30d5\u30c8\u3059\u308b\u7bc4\u56f2\n    )\ndatagen_split.fit(X_train_split)\n\n# \u5168\u30c7\u30fc\u30bf\u7528\u306eDataAugmentation\u306e\u4f5c\u6210\ndatagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    )\ndatagen.fit(X_train_all)","b3e899b4":"# Augmentation\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\ntmp = datagen_split.flow(X_train_split, y_train_split)\ntmp_x = tmp.__getitem__(0)[0]\nplt.imshow((tmp_x[0][:,:,0]))","8cca6cec":"# CNN\u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\nclass CNN():\n    def __init__(self):\n        self.X_input = Input((img_rows,img_cols,1))\n        self.X = Conv2D(filters=64, kernel_size=(5,5), padding=\"valid\")(self.X_input)\n        #self.X = Conv2D(filters=64, kernel_size=(5,5), padding=\"valid\")(self.X) ### add\n        self.X = Activation('relu')(self.X)\n        self.X = MaxPooling2D(pool_size = (2,2))(self.X)\n        self.X = Dropout(rate=0.1, seed=random_seed)(self.X) ### add\n        \n        self.X = Conv2D(filters=128, kernel_size=(5,5), padding=\"valid\")(self.X)\n        #self.X = Conv2D(filters=64, kernel_size=(5,5), padding=\"same\")(self.X) ### add\n        self.X = Activation('relu')(self.X)\n        self.X = MaxPooling2D(pool_size = (2,2))(self.X)\n        self.X = Dropout(rate=0.1, seed=random_seed)(self.X) ### add\n        \n        self.X = Flatten()(self.X)\n        self.X = Dense(num_classes, activation=\"softmax\")(self.X)\n        \n    def Make_model(self):\n        # \u30e2\u30c7\u30eb\u306e\u4f5c\u6210\u3002\u5165\u51fa\u529b\u3092\u4e0e\u3048\u308b\u3068\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\u3067\u304d\u308b\u3002\n        model = Model(inputs=self.X_input, outputs=self.X)\n        \n        ### model = Model(inputs=self.X_input, outputs=self.X)\n        return model ","a53a59c9":"# \u30e2\u30c7\u30eb\u69cb\u7bc9\ncnn_object_origData = CNN() # DataAugmentation \u3092\u8ffd\u52a0\u3057\u306a\u3044\u5834\u5408\u306e\u7d50\u679c\u306e\u8a55\u4fa1\u7528\ncnn_model_origData = cnn_object_origData.Make_model()\n\ncnn_object_dataAug = CNN() # DataAugmentation\u3092\u8ffd\u52a0\u3057\u3066\u8a55\u4fa1\u3059\u308b\u7528\ncnn_model_dataAug = cnn_object_dataAug.Make_model()\n\n# compile\ncnn_model_origData.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\", # DataAugmentation \u3092\u8ffd\u52a0\u3057\u306a\u3044\u5834\u5408\u306e\u7d50\u679c\u306e\u8a55\u4fa1\u7528\n                 metrics=[\"accuracy\"])\ncnn_model_dataAug.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\", # DataAugmentation\u3092\u8ffd\u52a0\u3057\u3066\u8a55\u4fa1\u3059\u308b\u7528\n                 metrics=[\"accuracy\"])\n\n# fit\nhistory_origData = cnn_model_origData.fit(X_train_split, y_train_split, epochs=10, validation_data=(X_test_split, y_test_split)) #DataAugmentation\u3092\u8ffd\u52a0\u3057\u306a\u3044\u30e2\u30c7\u30eb\nhistory_dataAug = cnn_model_dataAug.fit_generator(datagen_split.flow(X_train_split, y_train_split), # DataAugmentation\u3092\u8ffd\u52a0\u3057\u305f\u30e2\u30c7\u30eb\n                        steps_per_epoch=X_train_split.shape[0],\n                        epochs=1, validation_data=(X_test_split, y_test_split))","1c1e57c1":"cnn_model_origData.summary()","188d5729":"# evaluate for training data\ncnn_model_origData.evaluate(X_train_split, y_train_split)","5f8ec77b":"cnn_model_dataAug.evaluate(X_train_split, y_train_split)","5804b4e0":"# evaluate for created test data\ncnn_model_origData.evaluate(X_test_split, y_test_split)","f67c0df2":"cnn_model_dataAug.evaluate(X_test_split, y_test_split)","463570ab":"# \ny_test_split_predict_origData = np.argmax(cnn_model_origData.predict(X_test_split, verbose=1),axis=1)\ny_test_split_predict_dataAug = np.argmax(cnn_model_dataAug.predict(X_test_split, verbose=1),axis=1)\ny_test_split_class = np.argmax(y_test_split,axis=1) # shape(10500,)","d7a0484a":"# Confustion Matrix\n# This code is taken from sklearn site(https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \nconfusion_mtx_origData = confusion_matrix(y_test_split_class, y_test_split_predict_origData)\nplot_confusion_matrix(confusion_mtx_origData, range(num_classes))","c225d4a3":"confusion_mtx_dataAug = confusion_matrix(y_test_split_class, y_test_split_predict_dataAug)\nplot_confusion_matrix(confusion_mtx_dataAug, title=\"Confusion matrix(with Data Augmentation)\", classes=range(num_classes))","ae0c60b2":"#help(history_origData)\n#history.__dict__","76b1ecf8":"plt.plot(history_origData.history[\"acc\"])\nplt.plot(history_origData.history[\"val_acc\"])\nplt.title(\"accuracy\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend([\"train_sp\",\"test_sp\"],loc=\"upper left\")\nplt.show()","39777c46":"if __name__ == \"__main__\":\n    # \u5168\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u5b66\u7fd2\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\n    cnn_object = CNN()\n    cnn_model = cnn_object.Make_model()\n    cnn_model.compile(optimizer=tf.train.AdamOptimizer(),loss=\"categorical_crossentropy\",\n                         metrics=[\"accuracy\"])\n\n    #cnn_model.fit(X_train_all, y_train_all, epochs=5)\n    cnn_model.fit_generator(datagen.flow(X_train_all, y_train_all), # DataAugmentation\u3092\u8ffd\u52a0\u3057\u305f\u30e2\u30c7\u30eb\n                                steps_per_epoch=X_train_all.shape[0],\n                                epochs=1)\n\n    y_test = cnn_model.predict(X_test, verbose=1)\n    y_pred_classes = np.argmax(y_test,axis = 1) \n\n    sample = pd.DataFrame(np.arange(28000)+1,columns=['ImageId'])\n    sample[\"Label\"] = np.zeros(28000)\n    submit_sample = sample.copy()\n    submit_sample[\"Label\"] = y_pred_classes","fa6c8997":"cnn_model.evaluate(X_test_split, y_test_split)","67257f0f":"submit_sample.to_csv(\"dnn_submit_cnn_01.csv\", index=False)","abcdd436":"# \u306f\u3058\u3081\u306b  \nkeras\u3092\u7528\u3044\u3066\uff12\u5c64\u306e\u30b7\u30f3\u30d7\u30eb\u306aCNN\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057MNIST\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5206\u985e\u3059\u308b\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3057\u305f\u3002  \nkeras\u306ebackend\u306fTensorFlow(default)\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002  \n\u5206\u985e\u7cbe\u5ea6\u306fepoch\u657020\u306799.442%\u3092\u9054\u6210\u3057\u3066\u3044\u307e\u3059\u3002  \n\u8a08\u7b97\u6642\u9593\u3092\u524a\u6e1b\u3059\u308b\u305f\u3081\u306b\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306fepoch\u6570\u30921\u306b\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u518d\u73fe\u3055\u308c\u308b\u5834\u5408\u306fepoch\u309220\u306b\u5909\u66f4\u3057\u3001\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\u3048\n## \u5168\u4f53\u306e\u6d41\u308c\n\uff11\uff0e\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d  \n\uff12\uff0e\u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406  \n\uff13\uff0eCNN\u30e2\u30c7\u30eb\u306e\u4f5c\u6210  \n\uff14\uff0eCNN\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0  \n\uff15\uff0e\u4e88\u6e2c\u7d50\u679c\u306e\u78ba\u8a8d  \n\uff16\uff0e\u5168\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305fCNN\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210  \n","72e33bcf":"# 3. CNN\u30e2\u30c7\u30eb\u306e\u4f5c\u6210","e2c752c2":"# \uff16\uff0e\u5168\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305fCNN\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3068\u63d0\u51fa\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210  ","94bfa3d4":"## 1.\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d\nReshape  \nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel.  \nFor RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.\n","3d33548e":"# 2. \u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406  ","a7daad52":"# \u4e88\u6e2c\u7d50\u679c\u306e\u5206\u6790","a241137f":"# \u5b66\u7fd2\u7d50\u679c\u306e\u53ef\u8996\u5316","af7e99c3":"# CNN\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0","102fa7f1":"# \uff15\uff0e\u4e88\u6e2c\u7d50\u679c\u306e\u78ba\u8a8d  "}}