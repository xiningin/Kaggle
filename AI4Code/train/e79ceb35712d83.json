{"cell_type":{"2277337a":"code","06848890":"code","f852652f":"code","80c2475c":"code","f9ab05fb":"code","f199af3e":"code","2f69a115":"code","e152ac4f":"code","67926236":"code","db82d826":"code","be0b9b02":"code","66acf154":"code","a5340630":"code","bd6145b0":"code","77a125f1":"code","20523662":"code","27273c0c":"markdown","5cdb9a3b":"markdown","a1b6eff4":"markdown","4ace6bf4":"markdown","1f2d96a1":"markdown","d5bc95b5":"markdown","44ddba8a":"markdown","57e58506":"markdown","658babd6":"markdown","6293720b":"markdown","0d5a411c":"markdown"},"source":{"2277337a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06848890":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nnp.random.seed(123)\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Activation, Dropout, Convolution2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam","f852652f":"train= pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest= pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n","80c2475c":"x_train = train.drop(labels = [\"label\"],axis = 1) \ny_train = train[\"label\"]\ndel train","f9ab05fb":"print(x_train.isnull().sum().sum())\nprint(y_train.isnull().sum().sum())","f199af3e":"x_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","2f69a115":"x_train = x_train.astype('float32')\ntest = test.astype('float32')","e152ac4f":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test= train_test_split(x_train, y_train, test_size=0.1, random_state=2)","67926236":"x_train = x_train \/ 255\nx_test = x_test \/ 255\ny_train = y_train \/ 255\ny_test = y_test \/ 255\ntest = test \/ 255","db82d826":"y_train = to_categorical(y_train, num_classes = 10)","be0b9b02":"eg= plt.imshow(x_train[0][:,:,0])","66acf154":"model = Sequential()\n\nmodel.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1))) \nmodel.add(Convolution2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","a5340630":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1)","bd6145b0":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","77a125f1":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_data.csv\",index=False)","20523662":"submission.head()","27273c0c":"# Data Preparation","5cdb9a3b":"# CNN","a1b6eff4":"**Train Test Split**","4ace6bf4":"**Reshaping**","1f2d96a1":"**Normalization**","d5bc95b5":"**Model Evaluation**","44ddba8a":"# Submission","57e58506":"**label Encoding**","658babd6":"**Checking for missing values**","6293720b":"**Load the Data**","0d5a411c":"# Importing Libraries"}}