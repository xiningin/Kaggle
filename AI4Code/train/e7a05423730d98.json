{"cell_type":{"114f1a75":"code","a29011ea":"code","f0072b36":"code","83e31a1d":"code","cb95278a":"code","42446464":"code","2d7ceff9":"code","40f3d2cd":"code","f8a27b9f":"code","cde76691":"code","55910651":"code","72a344b2":"code","8edbefe6":"code","7d00f3cd":"code","bd528b52":"code","f330b681":"code","7546899c":"code","9a3f2802":"code","9e1248d9":"code","90a10d97":"code","a803526e":"code","5a7da278":"markdown","771673de":"markdown","7780e1a6":"markdown","c44a0029":"markdown","cfd78545":"markdown","77369e0e":"markdown","fc50d8c9":"markdown","5fe87b79":"markdown","776acee5":"markdown","e26bb1a5":"markdown","75e35642":"markdown","15ad68a1":"markdown","c213cf40":"markdown"},"source":{"114f1a75":"import tensorflow as tf","a29011ea":"tf.keras.__version__","f0072b36":"import tensorflow as tf\nimport os\nimport pandas as pd\nimport cv2\nfrom skimage.transform import rescale, resize\nimport keras\nimport numpy as np\nfrom sklearn.utils import class_weight\nimport tensorflow_addons as tfa\nimport pickle\nfrom skimage.io import imread\nfrom sklearn.utils import shuffle\nfrom matplotlib import pyplot as plt","83e31a1d":"keras.__version__","cb95278a":"#To get the filenames for a task\ndef filenames(part,train=True):\n    root='..\/input\/mura-v11\/'\n    if train:\n        csv_path=\"..\/input\/mura-v11\/MURA-v1.1\/train_image_paths.csv\"\n    else:\n        csv_path=\"..\/input\/mura-v11\/MURA-v1.1\/valid_image_paths.csv\"\n    \n    with open(csv_path, 'rb') as F:\n        d = F.readlines()\n        if part == 'all':\n            imgs = [root + str(x, encoding='utf-8').strip() for x in d]  # \u6240\u6709\u56fe\u7247\u7684\u5b58\u50a8\u8def\u5f84, [:-1]\u76ee\u7684\u662f\u629b\u5f03\u6700\u672b\u5c3e\u7684\\n\n        else:\n            imgs = [root + str(x, encoding='utf-8').strip() for x in d if\n                            str(x, encoding='utf-8').strip().split('\/')[2] == part]\n\n    #imgs= [x.replace(\"\/\", \"\\\\\") for x in imgs]\n    labels= [x.split('_')[-1].split('\/')[0] for x in imgs]\n    return imgs,labels\n\n\n#To icrop a image from center\ndef crop_center(img,cropx,cropy):\n    y,x,_ = img.shape\n    startx = x\/\/2-(cropx\/\/2)\n    starty = y\/\/2-(cropy\/\/2)    \n    return img[starty:starty+cropy,startx:startx+cropx]\n","42446464":"from albumentations import (\n    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n    RandomBrightness, RandomContrast, RandomGamma,\n    ToFloat, ShiftScaleRotate\n)\nfrom albumentations.augmentations.transforms import Resize\nAUGMENTATIONS_TRAIN = Compose([\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=0.5),\n    RandomGamma(gamma_limit=(80, 120), p=0.5),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ToFloat(max_value=255)\n])\nAUGMENTATIONS_TEST = Compose([\n    # CLAHE(p=1.0, clip_limit=2.0),\n    ToFloat(max_value=255)\n])","2d7ceff9":"albumentation_list =  [\n    HorizontalFlip(p=0.5),\n    RandomContrast(limit=0.2, p=0.5),\n    RandomGamma(gamma_limit=(80, 120), p=0.5),\n    RandomBrightness(limit=0.2, p=0.5),\n    ShiftScaleRotate(\n        shift_limit=0.0625, scale_limit=0.1, \n        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), \n    ToFloat(max_value=255)\n]\nroot='..\/input\/mura-v11\/'\nchosen_image= imread(root+'MURA-v1.1\/train\/XR_ELBOW\/patient01055\/study1_positive\/image3.png')\nimg_matrix_list = []\nbboxes_list = []\nfor aug_type in albumentation_list:\n    img = aug_type(image = chosen_image)['image']\n    img_matrix_list.append(img)\nimg= resize(chosen_image,(300,300,3))\nimg_matrix_list.append(img)\nimg_matrix_list.append(crop_center(img,224,224))\n\nimg_matrix_list.insert(0,chosen_image)    \n\ntitles_list = [\"Original\",\"Horizontal Flip\",\"Random Contrast\",\"Random Gamma\",\"RandomBrightness\",\n               \"Shift Scale Rotate\",\"Resizing\", \"Cropping\"]\n\ndef plot_multiple_img(img_matrix_list, title_list, ncols, main_title=\"Data Augmentation\"):\n    fig, myaxes = plt.subplots(figsize=(20, 15), nrows=2, ncols=ncols, squeeze=True)\n    fig.suptitle(main_title, fontsize = 30)\n    #fig.subplots_adjust(wspace=0.3)\n    #fig.subplots_adjust(hspace=0.3)\n    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n        myaxes[i \/\/ ncols][i % ncols].imshow(img)\n        myaxes[i \/\/ ncols][i % ncols].set_title(title, fontsize=15)\n    plt.show()\n    \nplot_multiple_img(img_matrix_list, titles_list, ncols = 4)","40f3d2cd":"class My_Custom_Generator(keras.utils.Sequence) :\n  \n  def __init__(self, image_filenames, labels, batch_size,transform) :\n    self.image_filenames = image_filenames\n    self.labels = labels\n    self.batch_size = batch_size\n    self.t= transform\n    \n  def __len__(self) :\n    return (np.ceil(len(self.image_filenames) \/ float(self.batch_size))).astype(np.int)\n  \n  \n  def __getitem__(self, idx) :\n    batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n    x=[]\n    for file in batch_x:\n        img= imread(file)\n        img= self.t(image=img)[\"image\"]\n        img= resize(img,(300,300,3))\n        img= crop_center(img,224,224)\n        x.append(img)\n    x=np.array(x)\/255.0\n    y= np.array(batch_y)\n    return x,y","f8a27b9f":"part='XR_WRIST'\nimgs,labels= filenames(part=part)\nvimgs,vlabels= filenames(part=part,train=False)\nprint(labels.count('positive'),labels.count('negative'))\ntraining_data= labels.count('positive')+labels.count('negative')\nprint(\"Training Data: \", training_data)\ny_data= [0 if x=='positive' else 1 for x in labels]\ny_data= keras.utils.to_categorical(y_data)\nprint(vlabels.count('positive'),vlabels.count('negative'))\nvalidation_data= vlabels.count('positive')+vlabels.count('negative')\nprint(\"Validation Data: \", validation_data)\nvy_data= [0 if x=='positive' else 1 for x in vlabels]\nvy_data= keras.utils.to_categorical(vy_data)","cde76691":"from sklearn.utils.class_weight import compute_class_weight\n\ny_integers = np.argmax(y_data, axis=1)\nclass_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\nd_class_weights = dict(enumerate(class_weights))","55910651":"batch_size = 32\nimgs, y_data = shuffle(imgs, y_data)\n#vimgs, vy_data = shuffle(vimgs, vy_data)\nmy_training_batch_generator = My_Custom_Generator(imgs, y_data, batch_size,AUGMENTATIONS_TRAIN)\nmy_validation_batch_generator = My_Custom_Generator(vimgs, vy_data, batch_size,AUGMENTATIONS_TEST)","72a344b2":"part='XR_WRIST'\ncheckpoint_path = \"WRIST_GPU.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nmy_callbacks = [\n    keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=0, save_best_only=True,\n                                       save_weights_only=False, mode='auto'),\n    keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,patience=3,\n                                         min_delta=0.001, verbose=1, min_lr=0.000000001)]\n","8edbefe6":"Inception=keras.applications.InceptionResNetV2(include_top=False,input_shape=(224,224,3))\n#for layer in Inception.layers[:4]:\n#  layer.trainable=False\ninput_image=keras.layers.Input((224,224,3))\nx=Inception (input_image)\n\n#x=keras.layers.GlobalAveragePooling2D()(x)\nx=keras.layers.Flatten()(x)\n#x=keras.layers.Dense(1024)(x)\n#x=keras.layers.Activation(activation='relu')(x)\n#x= keras.layers.Dropout(0.5)(x)\nx=keras.layers.Dense(256)(x)\nx=keras.layers.Activation(activation='relu')(x)\nx= keras.layers.Dropout(0.5)(x)\nx=keras.layers.Dense(2)(x)\nout=keras.layers.Activation(activation='softmax')(x)\n\nmodel=keras.Model(inputs=input_image,outputs=out)\nmodel.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\nprint(model.summary())","7d00f3cd":"history=model.fit_generator(generator=my_training_batch_generator,\n                   steps_per_epoch = int(training_data \/\/ batch_size),\n                   epochs = 50,\n                   verbose = 1,\n                   class_weight=d_class_weights,\n                   validation_data = my_validation_batch_generator,\n                   validation_steps = int(validation_data \/\/ batch_size),\n                   callbacks=my_callbacks)","bd528b52":"# checkpoint_path","f330b681":"# model.save('abcd.h5')","7546899c":"m = tfa.metrics.CohenKappa(num_classes=2)\nmodel=tf.keras.models.load_model('.\/WRIST_GPU.h5')\ny_pred=  model.predict(my_validation_batch_generator)\n\nyp2 = np.argmax(y_pred,axis = 1)\nya2 = np.argmax(vy_data,axis = 1)\nprint(y_pred.shape,vy_data.shape)\nm.update_state(ya2, yp2)\nprint('Final result: ', m.result().numpy())","9a3f2802":"# from keras.models import Sequential\n# from keras.layers import GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n# from keras.optimizers import RMSprop, Adam\n# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n# from tensorflow.keras.applications import EfficientNetB3","9e1248d9":"!python --version","90a10d97":"import tensorflow","a803526e":"tensorflow.__version__","5a7da278":"* Evaluate the performance by cohen's kappa score","771673de":"Data augmentations","7780e1a6":"* Training callbacks","c44a0029":"Getting data using the utility functions","cfd78545":"Plotting the augmentations","77369e0e":"****Some utility functions****","fc50d8c9":"* Create a model","5fe87b79":"# This notebook is a guide for classification task in MURA dataset. ","776acee5":"* Calculate class-weight to avoid class-imbalance ","e26bb1a5":"*  *Training*","75e35642":"* Create Training and Test daat generator","15ad68a1":"Import the modules","c213cf40":"Creating data generator for training and testiing with augmentation"}}