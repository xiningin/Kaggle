{"cell_type":{"3dbdb7f3":"code","a40f436f":"code","98207383":"code","9598879b":"code","04c50542":"code","baf97868":"code","ea05ba3c":"code","150e4f9e":"code","b8c9eab5":"code","3c72fba5":"code","98b2ce87":"code","47f1d42a":"code","3bcb54f7":"code","2647bc1e":"code","bb2fbff8":"code","a31dc694":"code","549cff69":"code","b31b406a":"markdown"},"source":{"3dbdb7f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('..\/input\/unsw-nb15\/UNSW_NB15_training-set.csv')","a40f436f":"##Data cleaning\n##3 Create a new DataFrame X you will use for cleaning. Store the labels in the dataframe Y.\nX = df.copy()\nY = X.label\n\ncolumnNames= df.columns\nprint('Column names: ')\nprint(columnNames)\n\n#prnt(X.label==1)\n\n","98207383":"##4 remove labels bound to attack as well as the 'id' field to avoid biaised learning\nattack=df.loc[(df.label==1)&(df.attack_cat!='Normal')]\n#del attack['label']\n#attack\n#attack = attack.drop(['id'],axis=1)\n#attack\nX.drop(columns=['attack_cat', 'label', 'id'], inplace=True)","9598879b":"##5 List string fields, and perform one-hot encoding\nstring_fields = X.select_dtypes('object').columns.values\nX = pd.get_dummies(X, columns=string_fields)\n\ndf.columns\nprint(X)","04c50542":"##Machine learning analysis\n##6 Through train_test_split on X and Y, and the XGBClassifier\n##6.1 Extract train and test dataframes for X and Y\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1)\nprint(\"Train size = \"+str(len(X_train))+\" Test_size = \"+str(len(X_test)))","baf97868":"##6.2 train the model\nfrom xgboost import XGBClassifier, plot_importance, plot_tree\nfrom sklearn.metrics import roc_auc_score\n\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nxgb_model.fit(X_train, y_train)","ea05ba3c":"##6.3 Extract the AUPRC\nfrom sklearn.metrics import average_precision_score\nweights = (Y == 0).sum()\/(1.0*(Y==1).sum())\n\nprobabilities = xgb_model.fit(X_train, y_train).predict_proba(X_test)\nprint('AUPRC = {}'.format(average_precision_score(y_test, \\\n                                                  probabilities[:,1])))","150e4f9e":"##6.4 Plot the relative importance of fields through plot_importance, using importance_type 'gain','weight','cover'\nfig = plt.figure(figsize = (10,10))\nax = fig.add_subplot(111)\n\ncolours = plt.cm.Set1(np.linspace(9,1,9))\n\nax = plot_importance(xgb_model,height=1,color=colours,grid=False, \\\n                    show_values=False, importance_type='gain', ax=ax);\nfor axis in ['top','bottom','left','right']:\n    ax.spines[axis].set_linewidth(2)\n    \nax.set_xlabel('importance score',size=10);\nax.set_ylabel('features',size=10);\nax.set_yticklabels(ax.get_yticklabels(),size=12);\nax.set_title('Importance_type gain',size=20)","b8c9eab5":"fig1 = plt.figure(figsize = (10,10))\nax1 = fig1.add_subplot(111)\n\ncolours1 = plt.cm.Set1(np.linspace(0,1,9))\nax1 = plot_importance(xgb_model,height=1,color=colours1,grid=False, \\\n                    show_values=False, importance_type='cover', ax=ax1);\nfor axis in ['top','bottom','left','right']:\n    ax.spines[axis].set_linewidth(2)\n    \nax1.set_xlabel('importance score',size=10);\nax1.set_ylabel('features',size=10);\nax1.set_yticklabels(ax1.get_yticklabels(),size=12);\nax1.set_title('Importance_type cover',size=20)","3c72fba5":"fig2 = plt.figure(figsize = (10,10))\nax2 = fig2.add_subplot(111)\n\ncolours2 = plt.cm.Set1(np.linspace(2,5,9))\nax2 = plot_importance(xgb_model,height=1,color=colours2,grid=False, \\\n                    show_values=False, importance_type='weight', ax=ax2);\nfor axis in ['top','bottom','left','right']:\n    ax.spines[axis].set_linewidth(2)\n    \nax2.set_xlabel('importance score',size=10);\nax2.set_ylabel('features',size=10);\nax2.set_yticklabels(ax2.get_yticklabels(),size=12);\nax2.set_title('Importance_type weight',size=20)","98b2ce87":"##Statistics Analysis\n##7 Apply a Principal Component Analysis (PCA) to the dataset X, to extract independent parameters of the model\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n#import matplotlib.pyplot as plt\n\nx = StandardScaler().fit_transform(X.copy())\npca = PCA(n_components=2)\npca_x = pca.fit_transform(x)\n\nprincipalDf = pd.DataFrame(data = pca_x, columns = ['principal component 1', \\\n                                                    'principal component 2'])\nfinalDf = pd.concat([principalDf, Y], axis = 1)\n\nfig = plt.figure(figsize=(8,8))\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = [0,1]\ncolors = ['r','b']\nfor target, color in zip(targets,colors):\n    indicesToKeep = finalDf.label == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'],\n              finalDf.loc[indicesToKeep, 'principal component 2'],\n              c = color,\n              s = 50)\n    ax.legend(targets)\n    ax.grid()\n    \n    print(\"Independant parameters = \"+str(pca.explained_variance_))","47f1d42a":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(X.copy())\npca = PCA(n_components=2)\npca_x = pca.fit_transform(x)\n\nprincipalDf = pd.DataFrame(data = pca_x, columns = ['principal component 1', \\\n                                                   'principal component 2'])\nfinalDf = pd.concat([principalDf, Y], axis=1)","3bcb54f7":"fig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1, 1, 1)\nax.set_xlabel('Principal component 1', fontsize = 15)\nax.set_ylabel('Principal component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = [0, 1]\ncolors = ['r', 'b']\nfor target, color in zip(targets, colors):\n    indicesToKeep = finalDf.label == target\n    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'],\n              finalDf.loc[indicesToKeep, 'principal component 2'],\n              c = color,\n              s = 50)\n    ax.legend(targets)\n    ax.grid()\n    \n","2647bc1e":"print(\"Independent parameter = \"+str(pca.explained_variance_))","bb2fbff8":"##10.1. Build the Precision-Recall (PRC) curve\n# precision-recall curve and f1 for an imbalanced dataset\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom matplotlib import pyplot\n\n\nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(X_train, y_train)\n\nlr_probs = model.predict_proba(X_test)\nlr_probs = lr_probs[:, 1]\nyhat = model.predict(X_test)\nlr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\nlr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\nprint('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\npyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\npyplot.plot(lr_recall, lr_precision, marker='.', label='Logistic')\npyplot.xlabel('Recall')\npyplot.ylabel('Precision')\npyplot.legend()\npyplot.show()","a31dc694":"##10.2. Build the Receiver Operating Characteristic (ROC) curve\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nimport sklearn.metrics as metrics\nfrom matplotlib import pyplot\nns_probs = [0 for _ in range(len(y_test))]\nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(X_train, y_train)\nlr_probs = model.predict_proba(X_test)\n#lr_probs = probabilities\nlr_probs = lr_probs[:, 1]\n#lr_probs = probabilities[:, 1]\nns_auc = roc_auc_score(y_test, ns_probs)\nlr_auc = roc_auc_score(y_test, lr_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('Logistic: ROC AUC=%.3f' % (lr_auc))\nns_fpr, ns_tpr, _ = metrics.roc_curve(y_test, ns_probs)\nlr_fpr, lr_tpr, _ = metrics.roc_curve(y_test, lr_probs)\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","549cff69":"##Plot the learning curve\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom matplotlib import pyplot\n\nyhat = model.predict(X_test)\nscore = accuracy_score(y_test, yhat)\nprint('Accuracy: %.3f' % score)\nresults = model.evals_result()\npyplot.plot(results['validation_0']['logloss'], label='train')\npyplot.plot(results['validation_1']['logloss'], label='test')\npyplot.legend()\npyplot.show()","b31b406a":"6.5 What do you conclude wrt. the security status of the target system?\n"}}