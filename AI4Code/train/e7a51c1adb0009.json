{"cell_type":{"72a02797":"code","710c32de":"code","729e101c":"code","4c7c3935":"code","387a9657":"code","cb74377e":"markdown","adb55f97":"markdown"},"source":{"72a02797":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","710c32de":"import time\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import TensorBoard\nimport matplotlib.pyplot as plt\n%matplotlib inline","729e101c":"train = '..\/input\/intel-image-classification\/seg_train\/seg_train'\n\ndata = ImageDataGenerator(rescale=1.\/255)\nTrain = data.flow_from_directory(\n    train,\n    target_size = (150,150),\n    class_mode = 'categorical'\n)","4c7c3935":"test = '..\/input\/intel-image-classification\/seg_test\/seg_test'\n\nVal = data.flow_from_directory(\n    test,\n    target_size = (150,150),\n    class_mode = 'categorical'\n)","387a9657":"dense_layers = [256, 512]\nconv_layers = [128, 256]\nfor dense in dense_layers:\n    for conv in conv_layers:\n        model = tf.keras.models.Sequential([\n\n            tf.keras.layers.Conv2D( conv, (3,3), activation = 'relu', input_shape = (150,150,3)),\n            tf.keras.layers.MaxPooling2D(2,2),\n\n            tf.keras.layers.Conv2D( conv, (3,3), activation = 'relu'),\n            tf.keras.layers.MaxPooling2D(2,2),\n\n            tf.keras.layers.Conv2D( 64, (3,3), activation = 'relu'),\n            tf.keras.layers.MaxPooling2D(2,2),\n\n            tf.keras.layers.Conv2D( 32, (3,3), activation = 'relu'),\n            tf.keras.layers.MaxPooling2D(2,2),\n\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dropout(0.5),\n\n            tf.keras.layers.Dense(dense, activation = 'relu'),\n            tf.keras.layers.Dense(6, activation = 'softmax')\n\n        ])\n        \n        Name = 'cnv {}  -  dense {} '.format(conv,dense,int(time.time()))\n        tensorboard = TensorBoard(log_dir = 'logs\/'.format(Name))\n        \n        model.summary()\n\n        model.compile(optimizer= keras.optimizers.Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n\n        history = model.fit_generator(Train, epochs=25, validation_data = Val, verbose = 1, callbacks= [tensorboard])\n        \n        acc = history.history['accuracy']\n        val_acc = history.history['val_accuracy']\n        loss = history.history['loss']\n        val_loss = history.history['val_loss']\n\n        epochs = range(len(acc))\n\n        plt.plot(epochs, acc, 'r', label='Training accuracy')\n        plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n        plt.title('Training and validation accuracy')\n        plt.legend(loc=0)\n        plt.figure()\n        \n        plt.plot(epochs, loss, 'r', label='Trainig Loss')\n        plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n        plt.title('Training and Validation Loss')\n        plt.legend(loc=0)\n        plt.figure()\n\n\n        plt.show()","cb74377e":"## Data Loader ","adb55f97":"# Libraries"}}