{"cell_type":{"5a52c215":"code","57703d17":"code","d07dac62":"code","f55acc26":"code","338e9b33":"code","feda5c32":"code","ebdfa974":"code","5f6de0bb":"code","9a9d4855":"code","9f5e02b6":"code","6e48b7d0":"code","3b80e104":"code","6443a9e3":"code","c6881d18":"code","18abcdf2":"code","5c8a5d1b":"code","6ddaab03":"code","e03e92fa":"markdown","354d23e7":"markdown","0b3c2681":"markdown","9e3df056":"markdown","5c8469af":"markdown","a74f64bf":"markdown","18f973ee":"markdown","fc95bed3":"markdown","f0952356":"markdown","9fdbddf2":"markdown"},"source":{"5a52c215":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-notebook')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","57703d17":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data  = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntrain_data.head(5)\n","d07dac62":"#Retrieve column information, we can see there are several columns having non value to fill - Age, Cabin, Embarked\n#Cabin is too sparse, we will research its correlation and availability later on.\n#For categorical feature like Pclass, Embarked or Cabin, we will onehot or hash them depends on the carbinality.\n\ntrain_data.info()","f55acc26":"train_data.describe()","338e9b33":"#Outlier detection using the Tukey method\nfrom collections import Counter\n\ndef outlier_detection(dataframe,features, critical=1.5):\n    ind = []\n    for column in features:\n        q1 = np.percentile(dataframe[column],25)\n        q3 = np.percentile(dataframe[column],75)\n        res = q3 - q1\n        new = critical * res\n        out = dataframe[(dataframe[column] < q1 - new) | (dataframe[column] > q3 + new)].index\n        ind.extend(out)\n    ind = Counter(ind)\n    val = list(s for s,i in ind.items())\n    return val\n\n#Detecting outliers for the numerical features\nott = outlier_detection(train_data,[\"Fare\"]) #\"SibSp\",\"Parch\",\"Fare\"\n\ntrain_data.iloc[ott]","feda5c32":"pres_data = train_data.copy()\n\npres_data['Is_Cabin'] = pres_data['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1 )\n\nsns.scatterplot(data=pres_data, x='Is_Cabin', y='Fare')\n\npres_data","ebdfa974":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"%.3f of women who survived\" % rate_women)\n\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"%.3f of men who survived\" % rate_men)","5f6de0bb":"default_age = train_data['Age'].mean()\n\ntrain_data['Age'] = train_data['Age'].fillna(default_age)\ntest_data['Age'] = test_data['Age'].fillna(default_age)\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,8))\n\nwomen = train_data[train_data['Sex']=='female']\nmen = train_data[train_data['Sex']=='male']\n\nax = sns.distplot(women[women['Survived']==1].Age, bins=20, label='survived', ax=axes[0], kde=False, color='green')\nax = sns.distplot(women[women['Survived']==0].Age, bins=20, label='not survived', ax=axes[0], kde=False, color='red')\nax.legend()\nax.set_title('Female')\n\nax = sns.distplot(men[men['Survived']==1].Age, bins=20, label='survived', ax=axes[1], kde=False, color='green')\nax = sns.distplot(men[men['Survived']==0].Age, bins=20, label='not survived', ax=axes[1], kde=False, color='red')\nax.legend()\n_ = ax.set_title('Male')\n\n","9a9d4855":"sns.barplot(x='Pclass', y='Survived', data=train_data)\n","9f5e02b6":"sns.catplot('SibSp', 'Survived', data=train_data, kind='point')\nsns.catplot('Parch', 'Survived', data=train_data, kind='point')","6e48b7d0":"#import pandas_profiling\n\n#report = pandas_profiling.ProfileReport(train_data)\n#display(report)","3b80e104":"features = [\"PassengerId\", \"Name\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"]\n\nnum_train, num_test = len(train_data), len(test_data)\nprint(num_train, num_test)\n\n#process the null value\nmerged_data = pd.concat([train_data[features], test_data[features]], axis=0, ignore_index=True)\nmerged_data['Age'] = merged_data['Age'].fillna(merged_data['Age'].mean())\nmerged_data['Fare'] = merged_data['Fare'].fillna(merged_data['Fare'].mean())\nmerged_data[['Cabin','Embarked']] = merged_data[['Cabin','Embarked']].fillna(value='Unknown')\n\nmerged_data","6443a9e3":"y = train_data[\"Survived\"]\nwinsorized_X = pd.get_dummies(merged_data[[\"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Embarked\"]])\n\n#Hashcode the Cabin feature\n\n#mh3 = FeatureHasher(n_features=8, alternate_sign=False, input_type='dict')\n#h_array = mh3.fit_transform(merged_data[['Cabin']].to_dict('records')).toarray()\n#h_df = pd.DataFrame(h_array, columns=['Cabin_' + str(i) for i in range(h_array.shape[1])]).astype('int64')\n#winsorized_X = winsorized_X.merge(h_df, left_index=True, right_index=True)\n\n\nwinsorized_X.info()","c6881d18":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import RandomOverSampler\n\n\nX_train = winsorized_X.iloc[0:num_train]\nX_test = winsorized_X.iloc[num_train:]\n\n#Over sampling\nros = RandomOverSampler(random_state=1)\nX_ros, y_ros = ros.fit_resample(X_train, y)\n\nx_train, x_valid, y_train, y_valid = train_test_split(X_ros, y_ros, test_size=0.2, random_state=1)\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nd_test = xgb.DMatrix(X_test)\n\nparams = {\n        'objective':'binary:hinge',\n        'max_depth':12,\n        'learning_rate':0.02,\n        'eval_metric':'error',\n        'min_child_weight':1,\n        'subsample':1,\n        'colsample_bytree':0.4,\n        'seed':29,\n        'reg_lambda':2.8,\n        'reg_alpha':0,\n        'gamma':0,\n        'nthread':-1\n}\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\nnrounds=5000  \nmodel = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=600, maximize=False, verbose_eval=30)\n\n\n\n","18abcdf2":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,20))\nxgb.plot_importance(model,ax=ax,max_num_features=20,height=0.8,color='g')\n\nplt.show()\n\n","5c8a5d1b":"from sklearn import metrics\ny_pred = model.predict(d_valid)\n\nprint('Accuracy :{0:0.5f}'.format(metrics.accuracy_score(y_valid, y_pred))) \nprint('AUC : {0:0.5f}'.format(metrics.roc_auc_score(y_valid, y_pred)))\nprint('Precision : {0:0.5f}'.format(metrics.precision_score(y_valid, y_pred)))\nprint('Recall : {0:0.5f}'.format(metrics.recall_score(y_valid, y_pred)))\nprint('F1 : {0:0.5f}'.format(metrics.f1_score(y_valid, y_pred)))","6ddaab03":"predictions = model.predict(d_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.astype('int32')})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e03e92fa":"# Winsorization","354d23e7":"# Class","0b3c2681":"# Outlier Detection\nTukey method https:\/\/www.stat.cmu.edu\/~cshalizi\/statcomp\/13\/labs\/05\/lab-05.pdf","9e3df056":"# Gender\nWe can see female has high possiblity to survive","5c8469af":"# Fill the Missing Value","a74f64bf":"# Age","18f973ee":"# Fare Cabin Correction","fc95bed3":"# siblings & spouses","f0952356":"# All Data Profiling","9fdbddf2":"# Overview of Dataset"}}