{"cell_type":{"a1ca302a":"code","250cd398":"code","65d781d7":"code","23aafdec":"code","73cf56fc":"code","22eeee53":"code","59559abb":"code","62f1c621":"code","76dc649f":"code","a7083a8c":"code","1f7dd80a":"code","8530e02f":"code","be70e5b8":"code","5f0ea525":"code","b360cc7b":"code","245aa168":"code","91473f65":"code","ad64d502":"code","84a31d3e":"code","454f337e":"code","f923fdd3":"code","f47914d1":"code","123877b0":"code","22f09094":"code","6b3c68dd":"code","0b286ce7":"code","2070e644":"code","f36be330":"code","b3d62004":"code","25ca59f9":"code","5df6243e":"code","9ce89ec1":"code","fa2c9e77":"code","08016f10":"code","2844a1b8":"code","275f629e":"code","3b764ed0":"code","1de831aa":"code","f08e778f":"code","614193d1":"code","66309b6d":"code","f1cf5ef4":"code","9b6bc394":"code","d0fcf381":"code","c6dd4a81":"code","7c27853c":"code","845902f1":"code","4244493a":"code","8f6aefae":"code","bedb1c76":"code","b061ac9a":"code","d7e87626":"code","207cc7b1":"code","88dc7b89":"code","1b3e99e4":"code","7f51fdc2":"code","75f26938":"code","7884600d":"code","ce9e8a38":"code","483fca41":"code","c4fb60eb":"code","0722961d":"code","2d22395f":"code","6ae61b4b":"code","5a2b7b4b":"code","d0245598":"code","2e7aba49":"code","3d2bd664":"code","5860fd97":"code","14669e98":"code","daf7a1ed":"markdown","bd2fe72e":"markdown","77d78cb5":"markdown","4c609814":"markdown","3769768e":"markdown","1513876c":"markdown","3e013ed3":"markdown","0b88e6ce":"markdown","124839a3":"markdown","8b8d7d9c":"markdown","381fbfe4":"markdown","40d117a9":"markdown","2d4d047f":"markdown","074aab8b":"markdown","94c7b3c9":"markdown","77c9e3be":"markdown"},"source":{"a1ca302a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_columns', 500)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","250cd398":"housing = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\nhousing.head(10)","65d781d7":"housing.info()","23aafdec":"housing.describe()","73cf56fc":"housing.hist(bins=50, figsize=(20,15))\nplt.show()","22eeee53":"from sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","59559abb":"housing1 = train_set.copy()","62f1c621":"housing1.isnull().sum().sort_values(ascending = False).head(30)","76dc649f":"plt.figure(figsize=(12,4))\nsns.heatmap(housing1.isnull(),cbar=False,cmap='viridis',yticklabels=False)\nplt.title('Missing value in the dataset');","a7083a8c":"housing1.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence'], axis=1, inplace=True)","1f7dd80a":"housing1.head()","8530e02f":"corr = housing1.corr()\nsns.heatmap(corr, linewidths=0.5);","be70e5b8":"corr[\"SalePrice\"].sort_values(ascending=False)","5f0ea525":"from pandas.plotting import scatter_matrix\n\nattributes = [\"SalePrice\", \"OverallQual\", \"GrLivArea\",\n             'GarageArea','TotalBsmtSF', '1stFlrSF', 'FullBath',\n              'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd','GarageYrBlt', 'MasVnrArea']\npd.plotting.scatter_matrix(housing1[attributes], figsize=(15, 10))\n","b360cc7b":"attributes = [\"SalePrice\", \"OverallQual\", \"GrLivArea\",\n             'GarageArea']\npd.plotting.scatter_matrix(housing1[attributes], figsize=(15, 10))","245aa168":"housing1 = train_set.drop(\"SalePrice\", axis=1) # drop labels for training set\nhousing_labels = train_set[\"SalePrice\"].copy()","91473f65":"sample_incomplete_rows = housing1[housing1.isnull().any(axis=1)].head()\nsample_incomplete_rows","ad64d502":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy=\"median\")","84a31d3e":"housing_num = housing1.select_dtypes(exclude=['object'])\nhousing_num.head()","454f337e":"imputer.fit(housing_num)","f923fdd3":"imputer.statistics_","f47914d1":"housing_num.median().values","123877b0":"X = imputer.transform(housing_num)","22f09094":"housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing1.index)","6b3c68dd":"housing_tr.loc[sample_incomplete_rows.index.values]","0b286ce7":"imputer.strategy","2070e644":"housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing_num.index)\nhousing_tr.head()","f36be330":"plt.figure(figsize=(12,4))\nsns.heatmap(housing_num.isnull(),cbar=False,cmap='viridis',yticklabels=False)\nplt.title('Missing value in the dataset');","b3d62004":"plt.figure(figsize=(12,4))\nsns.heatmap(housing_tr.isnull(),cbar=False,cmap='viridis',yticklabels=False)\nplt.title('Missing value in the dataset');","25ca59f9":"housing_cat = housing1.select_dtypes('object')\nhousing_cat.head(10)","5df6243e":"imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')","9ce89ec1":"imp.fit(housing_cat)","fa2c9e77":"a = imp.transform(housing_cat)","08016f10":"housing_object = pd.DataFrame(a, columns=housing_cat.columns,\n                          index=housing1.index)","2844a1b8":"housing_object.loc[sample_incomplete_rows.index.values]","275f629e":"imp.strategy","3b764ed0":"housing_object = pd.DataFrame(a, columns=housing_cat.columns,\n                          index=housing_cat.index)\nhousing_object.head()","1de831aa":"from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\nfrom sklearn.preprocessing import OneHotEncoder","f08e778f":"from sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_object)\nhousing_cat_encoded[:5]","614193d1":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('std_scaler', StandardScaler()),\n\n    ])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","66309b6d":"housing_num_tr","f1cf5ef4":"cat_pipeline = Pipeline([\n        ('imp', SimpleImputer(strategy=\"most_frequent\")),\n        ('cat_encoder', OrdinalEncoder()),\n\n    ])\n\nhousing_object_tr = cat_pipeline.fit_transform(housing_object)","9b6bc394":"housing_object_tr","d0fcf381":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(housing_num)\ncat_attribs = list(housing_object)\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing1)","c6dd4a81":"housing_prepared","7c27853c":"housing_prepared.shape","845902f1":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","4244493a":"# let's try the full preprocessing pipeline on a few training instances\nsome_data = housing1.iloc[:5]\nsome_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)\n\nprint(\"Predictions:\", lin_reg.predict(some_data_prepared))","8f6aefae":"print(\"Labels:\", list(some_labels))","bedb1c76":"from sklearn.metrics import mean_squared_error\n\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","b061ac9a":"from sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(housing_labels, housing_predictions)\nlin_mae","d7e87626":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(housing_prepared, housing_labels)","207cc7b1":"housing_predictions = tree_reg.predict(housing_prepared)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","88dc7b89":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","1b3e99e4":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndisplay_scores(tree_rmse_scores)","7f51fdc2":"lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n                             scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","75f26938":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\nforest_reg.fit(housing_prepared, housing_labels)","7884600d":"housing_predictions = forest_reg.predict(housing_prepared)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","ce9e8a38":"\nfrom sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","483fca41":"scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\npd.Series(np.sqrt(-scores)).describe()","c4fb60eb":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\")\nsvm_reg.fit(housing_prepared, housing_labels)\nhousing_predictions = svm_reg.predict(housing_prepared)\nsvm_mse = mean_squared_error(housing_labels, housing_predictions)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse","0722961d":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3\u00d74) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2\u00d73) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search.fit(housing_prepared, housing_labels)","2d22395f":"grid_search.best_params_","6ae61b4b":"grid_search.best_estimator_","5a2b7b4b":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","d0245598":"pd.DataFrame(grid_search.cv_results_)","2e7aba49":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n        'n_estimators': randint(low=1, high=200),\n        'max_features': randint(low=1, high=8),\n    }\n\nforest_reg = RandomForestRegressor(random_state=42)\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\nrnd_search.fit(housing_prepared, housing_labels)","3d2bd664":"cvres = rnd_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","5860fd97":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","14669e98":"cat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","daf7a1ed":"## **Discover and Visualize the Data to Gain Insights**\n\n\n- In this phase, we will copying the training dataset to play with. \n- Check missing values data\n- Looking for correlations\n- Experimenting with Attribute Combinations","bd2fe72e":"The main goal is Predict the House Prices using Regression. \nTherefore, there would be finding the right features that helps the prediction less error.","77d78cb5":"Transform the Training set:","4c609814":"Handling NaN Values ","3769768e":"We will transform 2 pipelines here which are numerical pipeline and categorical pipeline. \nin the function, we have to create all transformation we have done along the way of creating the pipeline","1513876c":"Dropping the Object attributes to perform Imputer Median for missing numerical values","3e013ed3":"Features **PoolQC, MiscFeature, Alley,and Fence** have a lot of missing values.\nWe'll drop these features from the consideration","0b88e6ce":"Checking Correlation from SalePrice attribute. \nThere are several attributes has positive correlation with SalePrice which are: \nOverallQual, GrLivArea, GarageArea,TotalBsmtSF, 1stFlrSF, FullBath,TotRmsAbvGrd, YearBuilt, YearRemodAdd,GarageYrBlt, MasVnrArea","124839a3":"### Select and Train a Model","8b8d7d9c":"## Fine-Tune the Model","381fbfe4":"## **1. Get The Data**\n\nTake a look at the the Data Structure","40d117a9":"## Conclusion\n\nThe prediction could have done better by trying with some combinations with the attributes.","2d4d047f":"We have done replace the NaN in categorical values,\n\nWe have done shifting the object types into numbers categorical \n\nNow, we are missing the part combining all attributes into 1 place, or call Pipeline","074aab8b":" ### Transformation Pipelines","94c7b3c9":"### **Create a Test Set**","77c9e3be":"### Preparing the Data for Machine Learning Algorithms"}}