{"cell_type":{"1ae2c685":"code","a3333558":"code","d618518a":"code","a1a93794":"code","4558ca89":"code","e03d8321":"code","7cebde9b":"code","d1532044":"code","1aefa878":"code","c9a99bd3":"code","e085f70b":"code","08611e4b":"code","9c3806a8":"code","3871fb3d":"code","60efcc13":"code","5a4b6829":"code","fd028c0e":"code","f91e0fe2":"code","07c744b7":"code","a7091529":"code","9fdb282c":"code","ab0f9c91":"code","49b5c8c4":"code","d404ece4":"code","734f3ac2":"code","fb049761":"code","975cfd6d":"code","a646d3e7":"code","1537d5d1":"code","ef0f961d":"code","3eca87b5":"markdown","7ae4a489":"markdown","13504d74":"markdown"},"source":{"1ae2c685":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a3333558":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nsns.set()\nfrom scipy.stats import norm \nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings \nwarnings.filterwarnings('ignore')\n%matplotlib inline","d618518a":"df_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')","a1a93794":"df_train.columns","4558ca89":"df_train.shape","e03d8321":"df_train.describe()","7cebde9b":"df_train.SalePrice.describe()","d1532044":"sns.distplot(df_train['SalePrice'])\n#Deviate from the normal distribution.\n#Have appreciable positive skewness.\n#Show peakedness.","1aefa878":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","c9a99bd3":"var = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x = var, y = 'SalePrice', ylim=(0,800000))\n#Linear Relationship","e085f70b":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000))\n#Strong LInear or Exponential ","08611e4b":"var = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8,6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000)","9c3806a8":"var = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(20, 10))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);\n#SalePrice' is more prone to spend more money in new stuff than in old relics.","3871fb3d":"#saleprice correlation matrix\ncorrmat = df_train.corr()\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()\n","60efcc13":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","5a4b6829":"#Finding NULL data \ntotal = df_train.isnull().sum().sort_values(ascending = False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","fd028c0e":"#dealing with missing data\ndf_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_train.isnull().sum().max() #just checking that there's no missing data missing...","f91e0fe2":"#Standardizing Data \nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis])\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","07c744b7":"#Histogram and normal distribution\nsns.distplot(df_train['SalePrice'], fit = norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot = plt)","a7091529":"#Histogram and normal distribution\nsns.distplot(df_train['SalePrice'], fit = norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot = plt)","9fdb282c":"#Applying log transformations\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","ab0f9c91":"#Transformed Histogram and normal probability plot\nsns.distplot(df_train['SalePrice'], fit = norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot = plt)","49b5c8c4":"#histogram and normal probability plot\nsns.distplot(df_train['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","d404ece4":"#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\n\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","734f3ac2":"#transform data\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","fb049761":"#histogram and normal probability plot\nsns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","975cfd6d":"#scatter plot\nplt.scatter(df_train['GrLivArea'], df_train['SalePrice']);","a646d3e7":"#scatter plot\nplt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]['SalePrice']);","1537d5d1":"#convert categorical variable into dummy\ndf_train = pd.get_dummies(df_train)\ndf_train.head()","ef0f961d":"df_train.to_csv('House_Price_Prediction_Sid.csv')","3eca87b5":"# **Outliers Removal**","7ae4a489":"# Normality Distribution","13504d74":"**TO Test Homoscedasticity**"}}