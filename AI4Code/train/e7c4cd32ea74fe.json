{"cell_type":{"0812ba04":"code","28a0e987":"code","76d61e2e":"code","20bb4401":"code","e910d4d6":"code","1f7a32b5":"code","1920443b":"code","a28426fc":"code","36ba5413":"code","181338e4":"code","ea8ff2dc":"code","cfec9117":"code","493b07b7":"code","b975e9f8":"code","f7142220":"code","bf712de5":"code","d6ca8959":"code","fa893cc7":"code","cdd1d43e":"code","4c510282":"code","e6d55ce0":"code","dc31fe7f":"code","b33c62ce":"markdown","b47a1c4c":"markdown","82000287":"markdown","8bcfc38b":"markdown","6c626bf9":"markdown","2d0af7ae":"markdown","e1ac7cb7":"markdown","9f1a7061":"markdown","6eb0ba35":"markdown","9475a596":"markdown","c4c80a88":"markdown","6943db68":"markdown","b1d4c769":"markdown","3aaae3f4":"markdown","a701c859":"markdown","63fc7d2a":"markdown","0fc2b63f":"markdown","08c3e2ae":"markdown"},"source":{"0812ba04":"# Linear algebra\nimport numpy as np\n\n# Data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\n\n# Deep Learning\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.utils import np_utils\n\n# Visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline","28a0e987":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","76d61e2e":"train_df.head()","20bb4401":"train_df.describe()","e910d4d6":"x_train = train_df.drop('label', axis=1).values\ny_train = train_df['label'].values\n\nx_test = test_df.values","1f7a32b5":"img_height, img_width = 28, 28\nx_train = x_train.reshape(x_train.shape[0], img_height, img_width, 1)\nx_test = x_test.reshape(x_test.shape[0], img_height, img_width, 1)","1920443b":"num_classes = 10\ny_train = np_utils.to_categorical(y_train, num_classes)","a28426fc":"y_train[:5]","36ba5413":"x_test = x_test \/ 255.0\nx_train = x_train \/ 255.0","181338e4":"model = Sequential()\n\nmodel.add(Conv2D(\n    filters=32,\n    kernel_size=(5,5),\n    input_shape=(img_height, img_width, 1), \n    padding=\"Same\",\n    activation=\"relu\"\n))\nmodel.add(Conv2D(\n    filters=32,\n    kernel_size=(5,5),\n    input_shape=(img_height, img_width, 1), \n    padding=\"Same\",\n    activation=\"relu\"\n))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(\n    filters=64,\n    kernel_size=(3,3),\n    input_shape=(img_height, img_width, 1), \n    padding=\"Same\",\n    activation=\"relu\"\n))\nmodel.add(Conv2D(\n    filters=64,\n    kernel_size=(3,3),\n    input_shape=(img_height, img_width, 1), \n    padding=\"Same\",\n    activation=\"relu\"\n))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=\"softmax\"))","ea8ff2dc":"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nprint(model.summary())","cfec9117":"checkpoint = ModelCheckpoint(\n    'best_model.hdf5',\n    monitor='val_acc',\n    save_best_only=True,\n    verbose=1\n)","493b07b7":"lr_reduction = ReduceLROnPlateau(\n    monitor='val_acc',\n    patience=3,\n    factor=0.5,\n    min_lr=0.00001,\n    verbose=1\n)","b975e9f8":"batch_size = 96\nepochs = 40\nvalidation_size = 0.3","f7142220":"history = model.fit(\n    x=x_train, \n    y=y_train, \n    batch_size=batch_size, \n    epochs=epochs,\n    verbose=1,\n    validation_split=validation_size,\n    callbacks=[checkpoint, lr_reduction]\n)","bf712de5":"plt.figure(figsize=(16,9))\nplt.plot(history.history['acc'], label='Train')\nplt.plot(history.history['val_acc'], label='Test')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","d6ca8959":"model.load_weights('best_model.hdf5')","fa893cc7":"probabilities = model.predict(x_test)","cdd1d43e":"predictions = np.argmax(probabilities, axis=1)","4c510282":"submission = pd.DataFrame(data={\n    'ImageId': list(range(1, predictions.shape[0]+1)),\n    'Label': predictions\n})","e6d55ce0":"submission.head()","dc31fe7f":"submission.to_csv('submission.csv', index=False)","b33c62ce":"## Callback for saving best model","b47a1c4c":"## Predict classes\nMethod *predict* returns the probability that the image belongs to one of the classes (0,1,2,...,8,9).  ","82000287":"## Load weights of the best model","8bcfc38b":"## Compile model","6c626bf9":"## Data Normalization\nData Normalization will help increase accuracy of the model  \n*255* - highest value","2d0af7ae":"## Import all neccesary libraries","e1ac7cb7":"## Train\/test plot","9f1a7061":"## Convert data to 2D representation","6eb0ba35":"## Save submission to file","9475a596":"<div style=\"text-align: center\"><h2>Hey, my dear friend!<\/h2><\/div>  \n<div style=\"text-align: center\"><h6>I created this kernel for the people who take first steps in the Deep Learning<\/h6><\/div>  \n<div style=\"text-align: center\"><h6>Don't forget upvote if you like the kernel<\/h6><\/div>  ","c4c80a88":"## Reduce learning rate when a metric has stopped improving\nModels often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","6943db68":"## Create submission","b1d4c769":"# Let's begin","3aaae3f4":"## Convert pandas DataFrame to NumPy array","a701c859":"## Read data","63fc7d2a":"## Create deep learning model","0fc2b63f":"## Convert probabilities to class\nIn the competition we should predict class.  \nHence, we should convert probabilities to classes","08c3e2ae":"![](https:\/\/mathematicaforprediction.files.wordpress.com\/2013\/08\/digitimageswithzenbrush-testset.jpg)"}}