{"cell_type":{"a3956a93":"code","55569050":"code","52f500e0":"code","d869d39a":"code","525570c3":"code","bc77defc":"code","ee6bfb82":"code","ba1b4146":"code","1ec330bf":"code","37213053":"code","1556f564":"code","f121b825":"code","28fa9dc5":"code","64f4a078":"code","7ecd82df":"code","43f0fd24":"code","df8885f2":"code","8882c40c":"code","b1c65640":"code","9d9bf6b3":"code","c032ec7c":"code","99ee7701":"code","365f12df":"code","a40443f2":"code","635335d1":"code","248d51c9":"code","afbd3af5":"code","1c73904d":"code","a24d0c42":"code","7f82494f":"code","9c78ed70":"code","8778682f":"code","81f80a22":"markdown","7ccb23dd":"markdown","f0bf7a7c":"markdown","f1006abe":"markdown"},"source":{"a3956a93":"import os\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nimport torch\nimport torch.nn as nn\nimport cv2\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n%matplotlib inline","55569050":"dir = '..\/input\/cats-faces-64x64-for-generative-models'\nprint(os.listdir(dir))","52f500e0":"##printing first 20 image names\nprint(os.listdir(dir+'\/cats')[:20])","d869d39a":"image_size = 64\nbatch_size = 128\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n\ntrain_ds = ImageFolder(dir, transform=tt.Compose([ tt.Resize(image_size),\n                                                        tt.CenterCrop(image_size),\n                                                        tt.ToTensor(),\n                                                        tt.Normalize(*stats)]))\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)","525570c3":"\ndef denorm(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0]","bc77defc":"def show_images(images, nmax=64):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n\ndef show_batch(dl, nmax=64):\n    for images, _ in dl:\n        show_images(images, nmax)\n        break","ee6bfb82":"show_batch(train_dl)","ba1b4146":"def is_cuda_available():\n    if torch.cuda.is_available():\n        print(\"CUDA available. Training on GPU!\")\n        return torch.device('cuda')\n    else:\n        print(\"CUDA not available. Training on CPU!\")\n        return torch.device('cpu')\n","1ec330bf":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","37213053":"is_cuda_available()","1556f564":"device=is_cuda_available()\ntrain_dl = DeviceDataLoader(train_dl, device)","f121b825":"#basic cnn with convolutional layers and leaky relu as activation fn\ndiscriminator = nn.Sequential(\n    # in: 3 x 64 x 64\n\n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 64 x 32 x 32\n\n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 128 x 16 x 16\n\n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 256 x 8 x 8\n\n    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 512 x 4 x 4\n\n    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    # out: 1 x 1 x 1\n\n    nn.Flatten(),\n    nn.Sigmoid())","28fa9dc5":"discriminator = to_device(discriminator, device)","64f4a078":"latent_size = 128\ngenerator = nn.Sequential(\n    # in: latent_size x 1 x 1\n\n    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    # out: 512 x 4 x 4\n\n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    # out: 256 x 8 x 8\n\n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # out: 128 x 16 x 16\n\n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    # out: 64 x 32 x 32\n\n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Tanh()\n    # out: 3 x 64 x 64\n)","7ecd82df":"xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\nfake_images = generator(xb)\nprint(fake_images.shape)\nshow_images(fake_images)","43f0fd24":"generator = to_device(generator, device)","df8885f2":"def train_discriminator(real_images, opt_d):\n    # Clear discriminator gradients\n    opt_d.zero_grad()\n\n    # Pass real images through discriminator\n    real_preds = discriminator(real_images)\n    real_targets = torch.ones(real_images.size(0), 1, device=device)\n    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n\n    # Pass fake images through discriminator\n    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n    fake_preds = discriminator(fake_images)\n    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n\n    # Update discriminator weights\n    loss = real_loss + fake_loss\n    loss.backward()\n    opt_d.step()\n    return loss.item(), real_score, fake_score","8882c40c":"def train_generator(opt_g):\n    # Clear generator gradients\n    opt_g.zero_grad()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n    \n    # Try to fool the discriminator\n    preds = discriminator(fake_images)\n    targets = torch.ones(batch_size, 1, device=device)\n    loss = F.binary_cross_entropy(preds, targets)\n    \n    # Update generator weights\n    loss.backward()\n    opt_g.step()\n    \n    return loss.item()\n","b1c65640":"\nsample_dir = 'generated'\nos.makedirs(sample_dir, exist_ok=True)","9d9bf6b3":"def save_samples(index, latent_tensors, show=True):\n    fake_images = generator(latent_tensors)\n    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n    print('Saving', fake_fname)\n    if show:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))","c032ec7c":"fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)","99ee7701":"save_samples(0, fixed_latent)","365f12df":"def fit(epochs, lr, start_idx=1):\n    torch.cuda.empty_cache()\n    \n    # Losses & scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n    \n    # Create optimizers\n    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images, _ in tqdm(train_dl):\n            # Train discriminator\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            # Train generator\n            loss_g = train_generator(opt_g)\n            \n        # Record losses & scores\n        losses_g.append(loss_g)\n        losses_d.append(loss_d)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        # Log losses & scores (last batch)\n        print(\"Epoch [{}\/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n    \n        # Save generated images\n        save_samples(epoch+start_idx, fixed_latent, show=False)\n    \n    return losses_g, losses_d, real_scores, fake_scores","a40443f2":"lr = 0.0003\nepochs = 60","635335d1":"history=fit(epochs,lr)","248d51c9":"losses_g, losses_d, real_scores, fake_scores = history","afbd3af5":"from IPython.display import Image","1c73904d":"Image('.\/generated\/generated-images-0033.png')","a24d0c42":"\nvid_fname = 'gans_training.avi'\n\nfiles = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\nfiles.sort()\n\nout = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n[out.write(cv2.imread(fname)) for fname in files]\nout.release()","7f82494f":"plt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","9c78ed70":"\nplt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","8778682f":"save_samples(0, fixed_latent)","81f80a22":"This is a basic implementation of Generative Adversarial Network to generate fake images of cats. I am a complete beginner in GANs so feel free to correct\/suggest topics.\n\n\nCode referred from [this post](https:\/\/towardsdatascience.com\/getting-started-with-gans-using-pytorch-78e7c22a14a5)","7ccb23dd":"One Fake generated image:","f0bf7a7c":"# GANs for Cats","f1006abe":"# What is GAN?\n\n\n* GAN is basically a way of training a generative model using a supervised learning problem.\n* There are 2 basic requirements namely, Generator : Model used to generate plausible or fake samples from already available samples and discriminator : Model used to classify the given samples as real or fake.\n* The two models are trained together in a zero-sum game until the discriminator is fooled about half the time.\n* A single training cycle involves first selecting a batch of real images from the problem domain. A batch of latent points is generated and fed to the generator model to synthesize a batch of images. The discriminator is then updated using the batch of real and generated images, minimizing binary cross-entropy loss used in any binary classification problem.The generator is then updated via the discriminator model. This means that generated images are presented to the discriminator as though they are real (not generated) and the error is propagated back through the generator model. This has the effect of updating the generator model toward generating images that are more likely to fool the discriminator.\n\t\n![](https:\/\/miro.medium.com\/max\/1800\/1*TKr1dtcNgJCA8uYY1OhmSg.png)"}}