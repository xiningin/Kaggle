{"cell_type":{"68b726c7":"code","a45b9711":"code","43018f36":"markdown"},"source":{"68b726c7":"\"\"\" This module generates notes for a midi file using the\n    trained neural network \"\"\"\n!pip install music21\nimport pickle\nimport numpy\nfrom music21 import instrument, note, stream, chord\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.layers import BatchNormalization as BatchNorm\nfrom keras.layers import Activation\n\ndef generate():\n    \"\"\" Generate a piano midi file \"\"\"\n    #load the notes used to train the model\n    with open('..\/input\/lofi-weights\/notes', 'rb') as filepath:\n        notes = pickle.load(filepath)\n\n    # Get all pitch names\n    pitchnames = sorted(set(item for item in notes))\n    # Get all pitch names\n    n_vocab = len(set(notes))\n\n    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n    model = create_network(normalized_input, n_vocab)\n    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n    create_midi(prediction_output)\n\ndef prepare_sequences(notes, pitchnames, n_vocab):\n    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n    # map between notes and integers and back\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    sequence_length = 32\n    network_input = []\n    output = []\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in = notes[i:i + sequence_length]\n        sequence_out = notes[i + sequence_length]\n        network_input.append([note_to_int[char] for char in sequence_in])\n        output.append(note_to_int[sequence_out])\n\n    n_patterns = len(network_input)\n\n    # reshape the input into a format compatible with LSTM layers\n    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    # normalize input\n    normalized_input = normalized_input \/ float(n_vocab)\n\n    return (network_input, normalized_input)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" create the structure of the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(\n        512,\n        input_shape=(network_input.shape[1], network_input.shape[2]),\n        recurrent_dropout=0.3,\n        return_sequences=True\n    ))\n    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n\n    # Load the weights to each node\n    model.load_weights('..\/input\/lofi-weights\/lofi-hip-hop-weights-improvement-100-0.6290.hdf5')\n\n    return model\n\ndef generate_notes(model, network_input, pitchnames, n_vocab):\n    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n    # pick a random sequence from the input as a starting point for the prediction\n    start = numpy.random.randint(0, len(network_input)-1)\n\n    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n\n    pattern = network_input[start]\n    prediction_output = []\n\n    # generate 500 notes\n    for note_index in range(200):\n        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n        prediction_input = prediction_input \/ float(n_vocab)\n\n        prediction = model.predict(prediction_input, verbose=0)\n\n        index = numpy.argmax(prediction)\n        result = int_to_note[index]\n        prediction_output.append(result)\n\n        pattern.append(index)\n        pattern = pattern[1:len(pattern)]\n\n    return prediction_output\n\ndef create_midi(prediction_output):\n    \"\"\" convert the output from the prediction to notes and create a midi file\n        from the notes \"\"\"\n    offset = 0\n    output_notes = []\n\n    # create note and chord objects based on the values generated by the model\n    for pattern in prediction_output:\n        # pattern is a chord\n        if ('.' in pattern) or pattern.isdigit():\n            notes_in_chord = pattern.split('.')\n            notes = []\n            for current_note in notes_in_chord:\n                new_note = note.Note(int(current_note))\n                new_note.storedInstrument = instrument.Piano()\n                notes.append(new_note)\n            new_chord = chord.Chord(notes)\n            new_chord.offset = offset\n            output_notes.append(new_chord)\n        # pattern is a note\n        else:\n            new_note = note.Note(pattern)\n            new_note.offset = offset\n            new_note.storedInstrument = instrument.Piano()\n            output_notes.append(new_note)\n\n        # increase offset each iteration so that notes do not stack\n        offset += 0.5\n\n    midi_stream = stream.Stream(output_notes)\n\n    midi_stream.write('midi', fp='lofi_output.mid')\n\nif __name__ == '__main__':\n    generate()","a45b9711":"#after converting to mp3...\nimport IPython\nIPython.display.Audio(\"..\/input\/lofi-weights\/lofi_test_output2.mp3\")","43018f36":"## Any and all upvotes are very much appreciated :)"}}