{"cell_type":{"b51da31e":"code","f3089f74":"code","d975f8bd":"code","ccde78c6":"code","3aa62ea7":"code","0d4b3f48":"code","34a60d0c":"code","5fbc9d1b":"code","2fe389c8":"code","04dc5f32":"code","3cb8ea80":"code","bd5e556c":"code","70a6385f":"code","ff7cbb1c":"code","ad95ad0c":"code","4752e669":"code","d2cebea1":"code","d914ed46":"code","c33c5a03":"code","a3676389":"code","ff4014b4":"markdown","023aca0a":"markdown","d4b9531b":"markdown","ec549b37":"markdown","e34ffc46":"markdown","1cbdf104":"markdown","a13c9e4d":"markdown","aedfdee8":"markdown","e2d5d405":"markdown","f2267345":"markdown","1bedd26e":"markdown","99bf5bb1":"markdown"},"source":{"b51da31e":"%reset -f","f3089f74":"%%capture\n\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import PoissonRegressor\n\nimport joblib\n\nimport tensorflow as tf\nmae = tf.keras.losses.MeanAbsoluteError()    ## The loss for this task\n_ = mae([1], [2]) \n\nimport os\n\nINPUT_DIR = '\/kaggle\/input\/morebikes2021'\nASSETS_DIR = '\/kaggle\/input\/motorbikes-all-stations-training-comparison'\n\nFEATURE_SET = 'short_full_temp'   ## Change here to use different features","d975f8bd":"def get_peters_features():\n    short = ['bikes_3h_ago', 'short_profile_3h_diff_bikes', 'short_profile_bikes']\n    short_temp = short + ['temperature.C']\n    full = ['bikes_3h_ago', 'full_profile_3h_diff_bikes', 'full_profile_bikes']\n    full_temp = full + ['temperature.C']\n    short_full = ['bikes_3h_ago', 'short_profile_3h_diff_bikes', 'short_profile_bikes', 'full_profile_3h_diff_bikes', 'full_profile_bikes']\n    short_full_temp = short_full + ['temperature.C']\n    \n    if FEATURE_SET=='short':\n        return short\n    elif FEATURE_SET=='short_temp':\n        return short_temp\n    elif FEATURE_SET=='full':\n        return full\n    elif FEATURE_SET=='full_temp':\n        return full_temp\n    elif FEATURE_SET=='short_full':\n        return short_full\n    elif FEATURE_SET=='short_full_temp':\n        return short_full_temp\n    \nfeatures_to_use = get_peters_features()","ccde78c6":"## Test to see what a model on station #15 looks like\n# os.listdir(models_path)\nfilename = INPUT_DIR+'\/Models\/Models\/model_station_15_rlm_'+FEATURE_SET+'.csv'\ndf = pd.read_csv(filename)\ndf","3aa62ea7":"def make_model_path(station_id):\n    return INPUT_DIR+'\/Models\/Models\/model_station_'+str(station_id)+'_rlm_'+FEATURE_SET+'.csv'\n\ndef predict_with_peters_model(model, X):\n    \n    ## Get the weigths in correct order (intercept first)\n    df = model.set_index('feature')\n    new_feats = ['(Intercept)'] + features_to_use\n    df = df.reindex(new_feats)\n    \n    weights = np.array(df['weight'])\n    \n    return weights @ X.T","0d4b3f48":"## Load validation data\nX_val = np.load(ASSETS_DIR+'\/X_val.npy')\ny_val = np.load(ASSETS_DIR+'\/y_val.npy')\n\nX_val.shape","34a60d0c":"## Add intercept before making predictions\nintercept = np.ones((len(X_val)))[:, np.newaxis]\n\nX_val_intercept = np.concatenate([intercept, X_val], axis=1)\nX_val_intercept.shape","5fbc9d1b":"peters_full_preds = np.zeros((len(X_val), 200))\n\nfor model_id in range(1, 201):\n    model = pd.read_csv(make_model_path(model_id))\n    \n    preds = predict_with_peters_model(model, X_val_intercept)\n    peters_full_preds[:, model_id-1] = preds\n    \n# print(peters_full_preds)\npeters_full_preds = np.rint(peters_full_preds)","2fe389c8":"def plot_results(y_pred, title):\n    fig, ax = plt.subplots(1, 1, figsize=(18, 5))\n\n    plt.plot(y_val[:600], \"o\", label=\"True values\")\n    ax.plot(y_pred[:600], \".\", label=\"Predictions\")\n    ax.set_xlabel(\"instances\")\n    ax.set_ylabel(\"# bikes\")\n    ax.legend(loc=\"best\")\n    ax.set_title(\n        title+\"\\nMAE = {:.2f}\".format(\n            mae(y_val, y_pred).numpy()\n        )\n    )\n    \npeters_avg_preds = np.rint(np.mean(peters_full_preds, axis=1))\n\nplot_results(peters_avg_preds, 'Average predictions over 200 models')","04dc5f32":"## Returns the most-voted index in a single 1-dimensional array\ndef vote(pred):\n    uniques = np.unique(pred)\n    counts = np.zeros_like(uniques)\n    \n    for j in range(len(uniques)):\n        counts[j] = (pred==uniques[j]).sum()\n    \n    return uniques[np.argmax(counts)]\n\n## Votes on a batch of data \ndef get_voting_preds(full_preds):\n    voting_preds = np.zeros((len(full_preds)))\n\n    for i in range(len(full_preds)):\n        voting_preds[i] = vote(np.rint(full_preds[i]))\n        \n    return voting_preds\n\npeters_voting_preds = get_voting_preds(peters_full_preds)\n\nplot_results(peters_voting_preds, 'Voting predictions over 200 models')\n# peters_voting_preds","3cb8ea80":"all_stations_model = joblib.load(ASSETS_DIR+'\/all_stations_model.pkl')\n\nall_stations_preds = np.rint(all_stations_model.predict(X_val))\n\nplot_results(all_stations_preds, 'Phase 1 result with one model for all stations')","bd5e556c":"per_station_models = joblib.load(ASSETS_DIR+'\/per_station_models.pkl')\nstations = np.load(ASSETS_DIR+'\/stations_val.npy')\n\nper_station_preds = np.zeros_like(y_val)\nfor i in range(len(y_val)):\n    per_station_preds[i] = np.rint(per_station_models[stations[i]].predict([X_val[i]]))\n\nplot_results(per_station_preds, 'Phase 1 result with one model per-station')","70a6385f":"def combine_with_peters(our_preds, our_weight):\n    dup_count = int(200*our_weight \/ (1-our_weight))\n    weighted_preds = np.tile(our_preds[:, np.newaxis], reps=(1, dup_count))\n\n    return np.concatenate([peters_full_preds, weighted_preds], axis=1)\n\n## Plot evolution of scores with weights\ndef plot_score_evolution(x, y, title):\n    fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n\n    plt.plot(x, y, \"g-\")\n    argmin = np.argmin(y)\n    print(\"Min MAE score:\", x[argmin], y[argmin])\n    plt.plot(x[argmin], y[argmin], \"ro\", label=\"Min score = \"+str(np.round(y[argmin],2)))\n    ax.set_xlabel(\"weight\")\n    ax.set_ylabel(\"MAE score\")\n    ax.legend(loc=\"best\")\n    ax.set_title(title)\n    \n    return x[argmin]","ff7cbb1c":"x = np.linspace(0, 0.98, 100)\ny = np.zeros_like(x)\nfor i in range(len(x)):\n    full_full_preds = combine_with_peters(per_station_preds, x[i])\n    resulting_preds = np.rint(np.mean(full_full_preds, axis=1))\n    y[i] = mae(y_val, resulting_preds)\n\nbest_weigth1 = plot_score_evolution(x, y, title=\"Evolution of the combined MAE score with our predictions' weight when averaging\")","ad95ad0c":"our_weigth = best_weigth1 \nfull_full_preds = combine_with_peters(per_station_preds, our_weigth)\n# print(full_full_preds.shape)\n\nresulting_preds = np.rint(np.mean(full_full_preds, axis=1))\n\nplot_results(resulting_preds, \"Averaging Peter's and our predictions with best weight = \"+str(np.round(our_weigth,2)))","4752e669":"x = np.linspace(0, 0.98, 100)\ny = np.zeros_like(x)\nfor i in range(len(x)):\n    full_full_preds = combine_with_peters(per_station_preds, x[i])\n    resulting_preds = np.rint(get_voting_preds(full_full_preds))\n    y[i] = mae(y_val, resulting_preds)\n\nbest_weigth2 = plot_score_evolution(x, y, title=\"Evolution of the combined MAE score with our predictions' weight when voting\")","d2cebea1":"our_weigth = best_weigth2\n\nfull_full_preds = combine_with_peters(per_station_preds, our_weigth)\n\nresulting_preds = np.rint(get_voting_preds(full_full_preds))\n\nplot_results(resulting_preds, \"Voting Peter's and our predictions with best weight = \"+str(np.round(our_weigth,2)))","d914ed46":"X_test = np.load(ASSETS_DIR+'\/X_test.npy')\nintercept = np.ones((len(X_test)))[:, np.newaxis]\nX_test_intercept = np.concatenate([intercept, X_test], axis=1)\n\nids = np.load(ASSETS_DIR+'\/ids_test.npy')\n\nstation_ids = np.load(ASSETS_DIR+'\/stations_test.npy')","c33c5a03":"## Our predictions\nour_test_preds = np.zeros((len(X_test)))\nfor i in range(len(X_test)):\n    station_id = station_ids[i]\n    our_test_preds[i] = per_station_models[station_id].predict([X_test[i]])\nour_test_preds = np.rint(our_test_preds)\n    \n## Peter's predictions\npeters_full_test_preds = np.zeros((len(X_test), 200))\nfor model_id in range(1, 201):\n    model = pd.read_csv(make_model_path(model_id))\n    preds = predict_with_peters_model(model, X_test_intercept)\n    peters_full_test_preds[:, model_id-1] = preds\npeters_full_test_preds = np.rint(peters_full_test_preds)\n    \n# Combine both\nour_weight = best_weigth1\ndup_count = int(200*our_weight \/ (1-our_weight))\nour_weighted_preds = np.tile(our_test_preds[:, np.newaxis], reps=(1, dup_count))\nfull_full_preds = np.concatenate([peters_full_test_preds, our_weighted_preds], axis=1)\n\n## Get average\/voting prediction\nfinal_test_preds = np.rint(np.mean(full_full_preds, axis=1))\n# final_test_preds = np.rint(get_voting_preds(full_full_preds))\n\n## Replace negative predictions with 0\nfinal_test_preds = np.where(final_test_preds<0, np.zeros_like(final_test_preds), final_test_preds)","a3676389":"results = pd.DataFrame({'Id':ids, 'bikes':final_test_preds})\nresults.to_csv('\/kaggle\/working\/roussel_subin_submission.csv', index=False)\nresults","ff4014b4":"## Peter's predictions with our per-station predictions - **Voting**","023aca0a":"# New predictions for the competition\n\nNow that we know the optimal weights for combining our model with the given models, we can make new predictions for the competition.","d4b9531b":"## All stations together","ec549b37":"# Compare to our results in the previous notebook\n\nHere we load, repeat and diplay the results we obtained in the previous notebook (Phase 1). ","e34ffc46":"## One model per station","1cbdf104":"# Combining all models \n\nHere, we combine our predictions to those from the 200 linear models by means of averaging and voting. For all instances, we find the weight our predictions should be assigned in order to minimize the combined MAE. Once the (optimal) weight is known, we duplicate our predictions by $dupcount = \\frac{200 \\times weight}{ 1 - weight}$ before combining to the others, then averaging or voting just as we've done so far. ","a13c9e4d":"The table below summarizes the improvement in MAE score when combining predictions from the 200 provided models and our custom-built ones. Note that for the table below, our models were restricted to linear regression with Ridge regularization (as illustrated in our very first notebook). Also noticing that our per-station models outperformed our all-station model, we've only considered the former in this comparison. \n\n|       | Our models | Given models  | Combined model  |\n| :---        |    :----:   |          :---: |          :---: |\n| **Averaging**      |   2.47     |2.49| 2.42|\n| **Voting**   |    2.47    |2.47| 2.43|\n","aedfdee8":"# Objective\n\nThis notebook deals with Phases 2 and 3 of the Kaggle competition. It build on the results from the previous notebook (Phase 1) to compare our models with the 200 pre-trained linear models that are provided (hereafter known as Peter's models). After that, we combined those models' predictions with ours, hence reusing the knowledge learned from a whole year's data, and knowledge from appropriate stations.\n\n*In order to change our models and obtain different results in this notebook, one should edit and save the previous notebook `MoreBikes - All-Stations Training & Comparison` before reruning this one.*","e2d5d405":"## Average predictions","f2267345":"## Voting predictions","1bedd26e":"# Load and use Peter's 200 models\n\nOnce we loaded the models and made 200 different predictions for every instance in the validation set, we had two options for settling on a single prediction:\n1. By averaging all the predictions,\n2. By picking the most voted prediction.\n\nWe implemented both strategies. We will see in charts below that these two \"bagging\" approaches returned similar results.","99bf5bb1":"## Peter's predictions with our per-station predictions - **Averaging**"}}