{"cell_type":{"4c5e32ce":"code","a14ab34f":"code","9a056210":"code","6ebdc1c9":"code","e87a8430":"code","e9fb88fe":"code","2868c0b4":"code","a77a6741":"code","c9927f15":"code","5bc1edff":"code","8d847c1d":"code","9037e92c":"code","b243b056":"code","00fb75b9":"code","05baaa9c":"code","2b64793b":"code","d4a3b1c9":"code","b8b9593b":"code","c30a826b":"code","013b6e1d":"code","89af31a2":"markdown"},"source":{"4c5e32ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a14ab34f":"!pip install xlrd","9a056210":"!pip install openpyxl","6ebdc1c9":"df = pd.read_excel('\/kaggle\/input\/scrnaseq-human-embryonic-stem-h1-h9-cell-lines\/GSE85917_Bacher.RSEM.xlsx')\ndf","e87a8430":"df1 = df.copy()","e9fb88fe":"# cells per lane\ndf2 = pd.read_excel('\/kaggle\/input\/scrnaseq-human-embryonic-stem-h1-h9-cell-lines\/GSE85917_Bacher.RSEM.xlsx', sheet_name=1)\ndf2","2868c0b4":"df3 = pd.read_excel('\/kaggle\/input\/scrnaseq-human-embryonic-stem-h1-h9-cell-lines\/GSE85917_Bacher.RSEM.xlsx', sheet_name=2)\ndf3","a77a6741":"df4 = pd.read_excel('\/kaggle\/input\/scrnaseq-human-embryonic-stem-h1-h9-cell-lines\/GSE85917_Bacher.RSEM.xlsx', sheet_name=3)\ndf4","c9927f15":"list_cells = []\nfor df in (df1,df2,df3,df4):\n    list_cells += list(df.columns[1:])\nprint(len(list_cells))\nlist_cells\n\nobs = pd.DataFrame( index = list_cells)\nobs.index.name = 'Cell'\nobs['Cell_type'] = [t.split('_')[1][:2] for t in list_cells]\nobs['Cells per lane'] = [int(t.split('_')[0][1:]) for t in list_cells]\n\nobs","5bc1edff":"X = np.zeros( shape=  (len(df), 0))\nprint(X)\nfor df in (df1,df2,df3,df4):\n    X = np.concatenate( (X,df.iloc[:,1:].values), axis = 1 )\nprint(X.shape)\nX ","8d847c1d":"df_genes = df1.iloc[:,0].to_frame() # .set_index(0)\ndf_genes.columns = ['Gene']\ndf_genes = df_genes.set_index(df_genes.columns[0])\ndf_genes","9037e92c":"df_genes","b243b056":"!pip install scanpy\nimport scanpy as sc\nimport anndata\n\nimport scipy \n\n\nimport time\nt0start = time.time()\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport sys","00fb75b9":"adata = anndata.AnnData(X = X.T, var = df_genes, obs = obs )\nadata","05baaa9c":"f = 'GSE85917_human_H1H9_hESC_Y2016_366Cells_GEO_counts_Bacher_Kendziorski'\nadata.write_h5ad(f+'.h5ad',compression='gzip')","2b64793b":"adata.obs['Cell_type'].unique()","d4a3b1c9":"mask = adata.obs['Cell_type'] == 'H1'\nmask.sum()","b8b9593b":"f = 'GSE85917_human_H1_hESC_Y2016_184Cells_GEO_counts_Bacher_Kendziorski'\nadata[mask].write_h5ad(f+'.h5ad',compression='gzip')","c30a826b":"mask = adata.obs['Cell_type'] == 'H9'\nmask.sum()","013b6e1d":"f = 'GSE85917_human_H9_hESC_Y2016_182Cells_GEO_counts_Bacher_Kendziorski'\nadata[mask].write_h5ad(f+'.h5ad',compression='gzip')","89af31a2":"# What is about ?\n\nExcel file contains 5 sheets, but 5-th sheet - bult data,\nthe first 4 sheets - single cell data , we take them and convert to single h5ad file"}}