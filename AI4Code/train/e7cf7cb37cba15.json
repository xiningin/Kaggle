{"cell_type":{"0eca5bcc":"code","b1d8a9e5":"code","7927837a":"code","d8606fcb":"code","39876baf":"code","de41ba91":"code","12b79909":"code","7f5bed2e":"code","5e7e2083":"code","b8d613c0":"code","26809eb0":"code","82e510b9":"code","fc05b89f":"code","3b41f55f":"code","a828bc75":"code","1d7a16f6":"code","da8dc929":"code","5ea4562d":"code","5d825268":"code","46c272b6":"code","d4f99611":"code","67947519":"code","17ef600f":"code","2b5b3c61":"markdown","2d12c196":"markdown","6d3c4ad0":"markdown","17fee17b":"markdown","80e3f189":"markdown","fb3e9dbd":"markdown","b70f2c8f":"markdown","0a5abed6":"markdown","f0eef548":"markdown","453eb409":"markdown"},"source":{"0eca5bcc":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Embedding, MaxPooling1D, Concatenate\nfrom keras.layers import Input\nfrom keras import backend as K \n\nimport tensorflow as tf\nfrom sklearn.metrics import roc_auc_score","b1d8a9e5":"base_data_dir = '..\/input\/cat-in-the-dat\/'\ndtr = pd.read_csv(base_data_dir + \"train.csv\")\ndts = pd.read_csv(base_data_dir + \"test.csv\")\ndts.target = np.NaN\nd = pd.concat([dtr, dts], sort=False)\ntrain_set = dtr.shape[0]\ndel(dtr, dts)","7927837a":"d.columns","d8606fcb":"cat_features = [i for i in d.columns if not i in (\"id\",\"target\")]\nprint(cat_features)","39876baf":"for c in cat_features:\n    d[c] = d[c].astype(\"category\")","de41ba91":"cat_vectors = [d[c].cat.codes.to_numpy() for c in cat_features]","12b79909":"cat_size = [len(d[c].cat.categories) for c in cat_features]\ncat_offset = np.cumsum([0] + cat_size[:-1])\ncat_vectors2 = [cat_vectors[i] + cat_offset[i] for i in range(len(cat_vectors))]\ncat_matrix = np.concatenate([np.reshape(np.ravel(c),(-1,1)) for c in cat_vectors2], axis=1)","7f5bed2e":"print(cat_matrix.shape)\nprint(cat_matrix[0:2,])","5e7e2083":"from sklearn.model_selection import train_test_split\ntrain_idx, test_idx = train_test_split(range(train_set), test_size=0.2)","b8d613c0":"X_train = cat_matrix[train_idx,:]\nX_test = cat_matrix[test_idx,:]\ny_train = d.target.iloc[train_idx]\ny_test = d.target.iloc[test_idx]\n# X_train, X_test, y_train, y_test = train_test_split(cat_matrix[0:train_set,:], d.target[0:train_set], test_size=0.2)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","26809eb0":"max_features = np.max(cat_matrix)+1\nmaxlen = cat_matrix.shape[1]\nprint(max_features, maxlen)","82e510b9":"# from https:\/\/stackoverflow.com\/questions\/41032551\/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\ndef auc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n\nembedding_size = 10\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, embedding_size, input_length=maxlen))\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])","fc05b89f":"print(model.summary())","3b41f55f":"hist = model.fit(X_train, y_train,validation_data=(X_test, y_test),\n          batch_size=100, epochs=3, shuffle=True)","a828bc75":"import matplotlib.pyplot as plt\nplt.plot(hist.history['auc'])\nplt.plot(hist.history['val_auc'])\nplt.title('model ROC AUC')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1d7a16f6":"y_pred = model.predict(X_test)\nK.clear_session()","da8dc929":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr)\nplt.xlabel('False positive')\nplt.ylabel('True positive')\nplt.title('ROC auc='+str(auc(fpr, tpr)))\nplt.show()","5ea4562d":"# from https:\/\/stackoverflow.com\/questions\/41032551\/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\ndef auc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n\ndef prepare_one_cat_layer(c):\n    inp = Input(shape=(1,))\n    es = int(round(np.log(np.max(c))))+2 # just a guess\n    emb = Embedding(np.max(c)+1, es, input_length=1)(inp)\n    return (inp,emb)\n\ncat_layers = [prepare_one_cat_layer(c) for c in cat_vectors]\n\nx = Concatenate()([c[1] for c in cat_layers])\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = Dense(10, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(10, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nfinal_layer = Dense(1, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=[c[0] for c in cat_layers], outputs=[final_layer])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=[auc])","5d825268":"Xs_train = [c[train_idx] for c in cat_vectors]\nXs_test = [c[test_idx] for c in cat_vectors]","46c272b6":"hist = model.fit(Xs_train, y_train, validation_data=(Xs_test, y_test),\n          batch_size=100, epochs=3, shuffle=True)","d4f99611":"import matplotlib.pyplot as plt\nplt.plot(hist.history['auc'])\nplt.plot(hist.history['val_auc'])\nplt.title('model ROC AUC')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","67947519":"y_pred = model.predict(Xs_test)\nK.clear_session()","17ef600f":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr)\nplt.xlabel('False positive')\nplt.ylabel('True positive')\nplt.title('ROC auc='+str(auc(fpr, tpr)))\nplt.show()","2b5b3c61":"First prepare a list of vectors with numeric representation for each categorical value.\nNote that if there is a NA in the category it is mapped into -1 code by pandas.\nIn this case there are no NAs. \nIf there are NAs we should be using code values + 1.","2d12c196":"Now, make one single merged matrix with all categorical codes.\nEach categorical code must be unique. \nTo achieve that values in each subsequent categorical vector is increased by the number of levels in previous vectors.\nThen all these vectors are merged into a single matrix.","6d3c4ad0":"Look at the ROC graph.","17fee17b":"# What is it\n\nThe idea is to try to compare NN performance with one emedding applied to each categorical feature as \nopposed to one embedding applied to all features at once. \nThe hope is that if there are feature interactions using all features at the same time\nmay provide embeddings that give us better predictions in models.\n\nThe results below show that there is no difference. The ROC AUC values from both models are the same.\nThis result may be specific to this data set, though. \nIn artificial data set there may be no feature interactions at all.\n\nStill, there may be other advantages of using one embedding for all. Simpler model, simpler inputs, for example.\n\n## TODO\n\n* Different models, try adding max pooling for example\n* Different data set, same approach applied to different data set may produce different results. But than again, maybe not. Maybe NN learns all interactions it can learn in both cases.\n","80e3f189":"# Try model with each feature having it's own embedding","fb3e9dbd":"Look at the model convergence graphs.","b70f2c8f":"# Prepare train and test set split","0a5abed6":"# Map categorical feature into vectors and matrix","f0eef548":"# Read data","453eb409":"# Try NN model using emedding across all features"}}