{"cell_type":{"e35e1c8a":"code","ef040f66":"code","3538dd46":"code","dfc2ff0c":"code","f2d4ede7":"code","87792e40":"code","3c98aa12":"code","9ee40370":"code","6b933f7b":"code","9ec149e3":"code","b7bc0a67":"code","49edce61":"code","36fa2554":"code","68595329":"code","960a8f18":"code","d287d0e4":"code","e3c3edb8":"code","3e770621":"code","f41900d2":"code","5108aef8":"code","950050ed":"code","7e430455":"code","0f5644e9":"code","94b62712":"code","1302f758":"code","e261c372":"code","1e8bcf7e":"code","55e97662":"code","e4829361":"code","133194d6":"code","1416f222":"code","3ece9749":"code","e7b813eb":"code","d96d4d4a":"code","a1e34e5f":"code","660fe87b":"code","4e3130de":"markdown","30bd2025":"markdown","4fcf0c1f":"markdown","cb2f69c1":"markdown","e2160241":"markdown","f4547fca":"markdown","e3c122a2":"markdown","4fa2d307":"markdown","10849fe7":"markdown","7e6c5fbf":"markdown","99e31316":"markdown","0df0e536":"markdown","5a7575db":"markdown","7413e442":"markdown","fc247030":"markdown"},"source":{"e35e1c8a":"!pip install -q fastai==2.1.10 fastcore==1.3.13","ef040f66":"from fastai.vision.all import *\n\nSEED = 42 \nset_seed(SEED, reproducible=True)","3538dd46":"path = Path('\/kaggle\/input\/scse-cc-2021')\npath.ls()","dfc2ff0c":"train_df = pd.read_csv(path\/'train.csv')\ntrain_df = train_df[['id', 'num1', 'num2', 'op', 'answer']]\ntrain_df.head()","f2d4ede7":"num1_vocab = train_df['num1'].unique()\nnum2_vocab = train_df['num2'].unique()\nop_vocab = train_df['op'].unique()\n\nblocks = (\n    ImageBlock(cls=PILImageBW),\n    CategoryBlock(vocab=num1_vocab), \n    CategoryBlock(vocab=num2_vocab),\n    CategoryBlock(vocab=op_vocab),\n)","87792e40":"getters = [\n    ColReader('id', pref=path\/'images\/images\/'),\n    ColReader('num1'),\n    ColReader('num2'),\n    ColReader('op'),\n]           ","3c98aa12":"item_tfms = [] # don't need cause all training images are initially of the same size\nbatch_tfms = [*aug_transforms(do_flip=False)]\nbs = 64","9ee40370":"db = DataBlock(\n    blocks=blocks,\n    getters=getters,\n#     splitter=RandomSplitter(seed=SEED), # slow\n    splitter=RandomSubsetSplitter(0.08, 0.02, seed=SEED), # quick training using 10% data, but with a drop in about 0.2 combine_acc\n    item_tfms=item_tfms,\n    batch_tfms=batch_tfms,\n    n_inp=1,\n)","6b933f7b":"dls = db.dataloaders(train_df, bs=bs)\ndls.show_batch(cmap='gray')","9ec149e3":"body = create_body(resnet50, n_in=1, pretrained=True)\n# body = create_body(densenet169, n_in=1, cut=1, pretrained=True)\n# body = create_body(vgg19_bn, n_in=1, pretrained=True)","b7bc0a67":"class MultiModel(Module):\n    \"A multi-head model given an 'encoder' and 'n' output features\"\n    def __init__(self, encoder, n):\n        nf = num_features_model(encoder) * 2\n        self.encoder = encoder\n        self.num1 = create_head(nf, n[0])\n        self.num2 = create_head(nf, n[1])\n        self.op   = create_head(nf, n[2])\n  \n    def forward(self, x):\n        y = self.encoder(x)\n        num1 = self.num1(y)\n        num2 = self.num2(y)\n        op = self.op(y)\n        return [num1, num2, op]","49edce61":"class CombinationLoss(Module):\n    \"Calculate total loss from 3 targets with custom contribution\"\n    def __init__(self, func=F.cross_entropy, weights=[1, 1, 1]):\n        self.func, self.w = func, weights\n\n    def forward(self, xs, *ys, reduction='mean'):\n        loss = 0\n        for i, w, x, y in zip(range(len(xs)), self.w, xs, ys):\n            loss += w * self.func(x, y, reduction=reduction) \n        return loss","36fa2554":"def combine_acc(inp, num1_targ, num2_targ, op_targ, axis=-1):\n    \"Calculate overall accuracy from all 3 targets\"\n    pred1, targ1 = flatten_check(inp[0].argmax(dim=axis), num1_targ)\n    pred2, targ2 = flatten_check(inp[1].argmax(dim=axis), num2_targ)\n    pred3, targ3 = flatten_check(inp[2].argmax(dim=axis), op_targ)\n    acc1 = pred1 == targ1\n    acc2 = pred2 == targ2\n    acc3 = pred3 == targ3\n    acc = acc1 & acc2 & acc3\n    return acc.float().mean()","68595329":"net = MultiModel(body, dls.c)","960a8f18":"model_name = 'resnet50'\n# model_name = 'densenet169'\n# model_name = 'vgg19'","d287d0e4":"# for transfer learning\ndef multimodel_split(m): return L(m.encoder, nn.Sequential(m.num1, m.num2, m.op)).map(params)","e3c3edb8":"learn = Learner(dls, net, \n                loss_func=CombinationLoss(),\n                opt_func=Adam,\n                splitter=multimodel_split,\n                metrics=combine_acc)","3e770621":"# save the best model so far\ncbs = [SaveModelCallback(monitor='combine_acc', fname=model_name+'_best')]","f41900d2":"# quick run with 5 epochs\nlearn.fine_tune(5, 1e-2, cbs=cbs)","5108aef8":"learn.recorder.plot_loss()","950050ed":"learn.load(model_name+'_best')","7e430455":"preds, targs = learn.get_preds()","0f5644e9":"combine_acc(preds, targs[0], targs[1], targs[2])","94b62712":"test_df = pd.read_csv(path\/'test.csv')\ntest_df.head()","1302f758":"test_dl = dls.test_dl(test_df)\ntest_dl.show_batch(cmap='gray')","e261c372":"preds, _ = learn.get_preds(dl=test_dl)","1e8bcf7e":"test_df['num1'] = dls.vocab[0][preds[0].argmax(dim=1)]\ntest_df['num2'] = dls.vocab[1][preds[1].argmax(dim=1)]\ntest_df['op']   = dls.vocab[2][preds[2].argmax(dim=1)]","55e97662":"test_df.head()","e4829361":"def get_answer(row):\n    if row['op'] == 'plus': \n        ans = row['num1'] + row['num2']\n    elif row['op'] == 'minus': \n        ans = row['num1'] - row['num2']\n    elif row['op'] == 'times': \n        ans = row['num1'] * row['num2']\n    elif (row['op'] == 'divide') & (row['num2'] != 0):\n        ans = row['num1'] \/ row['num2']\n    else:\n        ans = 0\n    return f'{ans:.2f}'","133194d6":"submit = pd.read_csv(path\/'submission.csv')\nsubmit['answer'] = test_df.apply(get_answer, axis=1)\nsubmit.head()","1416f222":"# Only run this cell once!!!\n# all_val_preds, all_test_preds = [], []","3ece9749":"# all_val_preds.append(preds)","e7b813eb":"# all_test_preds.append(preds)","d96d4d4a":"# Ensemling on the validation set \n# Go back to the upper part to see the final 'combine_acc'\n# avg_val_preds = []\n# for i in range(3):\n#     new_preds = (all_val_preds[0][i] + all_val_preds[1][i] + all_val_preds[2][i]) \/ 3\n#     avg_val_preds.append(new_preds)\n# preds = avg_val_preds","a1e34e5f":"# Ensemling on the test set \n# avg_test_preds = []\n# for i in range(3):\n#     new_preds = (all_test_preds[0][i] + all_test_preds[1][i] + all_test_preds[2][i]) \/ 3\n#     avg_test_preds.append(new_preds)\n# preds = avg_test_preds","660fe87b":"submit.to_csv('submission.csv', index=False)","4e3130de":"## Make predictions on test data","30bd2025":"- Go back to the upper part, change to a **different encoder body** and train again\n- Only use this code after `all_val_preds` and `all_test_preds` have outputs from resnet, densenet, and vgg","4fcf0c1f":"| Encoder Body    | Max Accuracy (Validation) (using 100% data) |\n|----------|----------|\n| resnet50    | 0.9959   |\n| densenet169 | 0.9956   |\n| vgg19    | 0.9963   |\n| all 3 ensembled    | 0.9972   |","cb2f69c1":"## Design a custom multi-head CNN model\n- Remember to **enable Internet** if using Kaggle notebook to download **pretrained** weights\n- Switch between different bodies when doing **ensembling**\n- `n_in = 1` because all of these pretrained models are trained with `n_in = 3` (i.e coloured instead of b&w)","e2160241":"- Go back to the upper part to get **preds** on the **validation set**","f4547fca":"- Go back to the upper part to get **preds** on the **test set**","e3c122a2":"## Ensembling\n- This part is **supposed to be run multiple times!**\n- Ensembling using **resnet50**, **densenet169**, **vgg19**\n- Remember to set the same the seed value for `splitter` to have the same validation set\n- Uncomment the cells below when you want to use ensembling","4fa2d307":"- If you want to do **ensembling**, append `preds` to `all_test_preds` below\n- If you are doing **ensembling** below, take note that `preds=avg_test_preds` now","10849fe7":"## Evaluate on validation data","7e6c5fbf":"## Submit to Kaggle\n- Download the `submission.csv` file and submit","99e31316":"- If you want to do **ensembling**, append `preds` to `all_val_preds` below\n- If you are doing **ensembling** below, take note that `preds=avg_val_preds` now","0df0e536":"- There should be no **division by zero** errors if training with **100% data**, so don't need to worry about it","5a7575db":"## Process data","7413e442":"## Training\n- Change `model_name` accordingly to the `body` used","fc247030":"## Import libraries & data\n- `fastai` releases updates frequently, so I won't guarantee this notebook will work with versions later than the one specified here\n- In fact, a newer version was released 2 days before the final presentation"}}