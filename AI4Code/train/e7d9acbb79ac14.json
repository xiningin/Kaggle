{"cell_type":{"d0d7ad90":"code","dd2f3a75":"code","2299a513":"code","37973a7f":"code","7b4eb835":"code","c99c5139":"code","073f5544":"code","1cd6d0f1":"code","42c1c290":"code","28549ab4":"code","160d1524":"code","0e4e76c7":"code","7955c7ed":"code","5eb5a8e5":"code","10d84b0d":"code","90fe4cbc":"code","dc7a47df":"code","0439de37":"code","f980e805":"code","1dc9e194":"code","7f3049b3":"code","92c4edae":"code","4e398b8c":"code","998cf8ce":"code","41cc632e":"code","f54760db":"code","ba265874":"code","66d10ea5":"code","949e3398":"code","8d96d50d":"markdown","a9f509a6":"markdown","b89493d7":"markdown","f97345e0":"markdown","83f2d07b":"markdown","604bd7c7":"markdown","0c84d951":"markdown","85c6951d":"markdown","b2db663a":"markdown","a4a34f9f":"markdown","f9f4e916":"markdown","d00e0ee6":"markdown","06eb9787":"markdown","65760802":"markdown","385d216d":"markdown"},"source":{"d0d7ad90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd2f3a75":"## Imports...\n# Math\nfrom random import randint\n\n# For deep learning algo\nfrom keras import layers\nfrom keras import models\nfrom tensorflow.keras.utils import to_categorical\n\n# For machine learning algo\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\n\n# For visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2299a513":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(\"Train_data shape: \", train_data.shape)\nprint(\"Test_data shape:\", test_data.shape)\nprint(\"\\n\")\n\nprint(\"Train data:\")\ntrain_data.head()","37973a7f":"# Visualize the set of single labels. Are all labels represented? If so, ais their distribution rather uniform?\nset(train_data[\"label\"])","7b4eb835":"# Visualize the distribuation of labels\nsns.countplot(x=train_data[\"label\"])","c99c5139":"def plot_digit(pixels, label):\n    digit = pixels.to_numpy().reshape((28,28))\n    plt.title(\"Label: {}\".format(label))  \n    fig = plt.imshow(digit,cmap=\"gist_gray\")","073f5544":"random_num = randint(0, train_data.shape[0] - 1)\npixels = train_data.iloc[random_num,1:]\nlabel = train_data.iloc[random_num,0]\n\nplot_digit(pixels, label)","1cd6d0f1":"d_y = train_data[\"label\"].to_numpy()\nd_x = train_data.drop(columns = \"label\").to_numpy()\nd_x = np.reshape(d_x, (d_x.shape[0], 28, 28, 1))\n\nx_test = test_data.to_numpy()\nx_test = np.reshape(x_test, (x_test.shape[0], 28, 28, 1))\n\nd_x = d_x.astype('float32')\nx_test = x_test.astype('float32')\n\nd_x\/=255\nx_test\/=255\n\n#print(train_data.iloc[0])\nprint(\"Shape of d_x: \", d_x.shape)\nprint(\"Shape of d_y: \", d_y.shape)\n#print(x_train[0].shape)","42c1c290":"# set number of categories\nnum_category = 10\n# convert class vectors to binary class matrices\nd_y = to_categorical(d_y, num_category)\nprint('Shape of y_train: ', d_y.shape)","28549ab4":"x_train, x_val, y_train, y_val = train_test_split(d_x, d_y, test_size=0.2, random_state=0)\n\nprint('Shape of y_train: ', y_train.shape)","160d1524":"cnn_model = models.Sequential()\ncnn_model.add(layers.Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)))\n#model.add(layers.BatchNormalization())\ncnn_model.add(layers.MaxPooling2D((2,2)))\ncnn_model.add(layers.Conv2D(64, (5,5), activation='relu'))\n#model.add(layers.BatchNormalization(-1)) does not work :( we will look at it a later submission\n#cnn_model.add(layers.Dropout(0.25))\ncnn_model.add(layers.MaxPooling2D((2,2)))\n\ncnn_model.add(layers.Flatten())\n\ncnn_model.add(layers.Dense(128, activation='relu'))\ncnn_model.add(layers.BatchNormalization())\n#cnn_model.add(layers.Dropout(0.5))\ncnn_model.add(layers.Dense(num_category, activation='softmax'))\n\ncnn_model.summary()","0e4e76c7":"# Compile the model using categorical_crossentropy because we have more than 2 categories\ncnn_model.compile(loss='categorical_crossentropy', \n             optimizer=\"rmsprop\",\n             metrics=['acc'])","7955c7ed":"history = cnn_model.fit(x_train,\n                    y_train,\n                    epochs=50,\n                    batch_size=1024,\n                    validation_data=(x_val, y_val))","5eb5a8e5":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Traiing loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.legend()\n\nplt.show()","10d84b0d":"# Let's look at the predictions from our CNN model\ncnn_pred = pd.DataFrame(np.argmax(cnn_model.predict(x_val), axis=1), columns=[\"CNN Prediction\"])\n\n# Correct labels from input dataset\nlabels = pd.DataFrame(np.argmax(y_val, axis = 1), columns=[\"Value\"])\nprint('Shape of labels:', labels.shape)\n\n# Let's see where our model was wrong\nwrong_cnn_pred = cnn_pred[cnn_pred[\"CNN Prediction\"] != labels['Value']]\nprint('Shape of wrong_cnn_pred:', wrong_cnn_pred.shape, \"\\n\")\n\njoin = pd.concat([wrong_cnn_pred, labels], axis=1, join=\"inner\")\nprint('Shape of join:', join.shape, \"\\n\")\n\nsns.countplot(x=join[\"Value\"])","90fe4cbc":"# Loop on all categories (labels)\nfor i in range(0, num_category):\n    # Filter the join table on the current category\n    filtered = join[join[\"Value\"] == i]\n    plt.figure()\n    sns.countplot(x=filtered[\"CNN Prediction\"]).set(title=\"Mislabelings of {}\".format(i))","dc7a47df":"fig = plt.figure()\nj = 0\nnum_plots = min(9, wrong_cnn_pred.shape[0])\nfor i in wrong_cnn_pred.index[:num_plots]:\n    plt.subplot(3,3,j+1)\n    plt.tight_layout()\n    digit = x_val[i].reshape((28,28))\n    pred_label = wrong_cnn_pred.loc[i].argmax() # we get the index of the max in the row i\n    correct_label = y_val[i].argmax()\n    plt.title(\"Predicted: {} | was {}\".format(pred_label, correct_label)) \n    plt.imshow(digit, cmap='gray', interpolation='none')\n    plt.xticks([])\n    plt.yticks([])\n    j += 1","0439de37":"# scikit-learn expects 2d num arrays for the training dataset for a fit function.\n# Thefore we need to reshape our arrays\nx_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\nx_val = x_val.reshape(x_val.shape[0], x_val.shape[1]*x_val.shape[2])","f980e805":"y_train = np.argmax(y_train, axis=1)\nprint(y_train.shape)\ny_val = np.argmax(y_val, axis=1)\nprint(y_val.shape)","1dc9e194":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(x_train, y_train)\n\n# Predictions for validation\nrf_pred = rf.predict(x_val)\nprint(rf_pred.shape)","7f3049b3":"# Validation data metrics\nprint(\"Test data metrics:\")\nprint(sklearn.metrics.classification_report(y_true= y_val, y_pred= rf_pred))","92c4edae":"print (\"Confusion Report\")\nprint(sklearn.metrics.confusion_matrix(y_val, rf_pred))","4e398b8c":"svc = LinearSVC(dual=False)\nsvc.fit(x_train, y_train)\n\n# Predictions for validation\nsvc_pred = svc.predict(x_val)\nprint(svc_pred.shape)","998cf8ce":"# Validation data metrics\nprint(\"Test data metrics:\")\nprint(sklearn.metrics.classification_report(y_true= y_val, y_pred= svc_pred))","41cc632e":"print (\"Confusion Report\")\nprint(sklearn.metrics.confusion_matrix(y_val, svc_pred))","f54760db":"rf_pred = pd.DataFrame(rf_pred, columns=[\"RF Prediction\"])\nsvc_pred = pd.DataFrame(svc_pred, columns=[\"SVC Prediction\"])\nall_pred = pd.concat([cnn_pred, rf_pred, svc_pred, labels], axis=1)\nall_pred.head()","ba265874":"# CNN has the best accuracy until now\n# Let's see if we can improve it by using the RF and SVC models\n# We don't want to give to much weight to RF and SVC because they would otherwise decrease the whole accuracy\n# Therefore let's focus on the errors of CNN model and look at the prediction of RF and SVC\npred_dict = dict()\n\npred_dict[\"all wrong\"] = len(all_pred[(all_pred[\"CNN Prediction\"] != all_pred[\"Value\"]) & \n                                      (all_pred[\"RF Prediction\"] != all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] != all_pred[\"Value\"])].index)\n\npred_dict[\"only CNN correct\"] = len(all_pred[(all_pred[\"CNN Prediction\"] == all_pred[\"Value\"]) & \n                                      (all_pred[\"RF Prediction\"] != all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] != all_pred[\"Value\"])].index)\n\npred_dict[\"only CNN correct_RF and SVC wrong with same value\"] = len(all_pred[(all_pred[\"CNN Prediction\"] == all_pred[\"Value\"]) & \n                                      (all_pred[\"RF Prediction\"] != all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] != all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] == all_pred[\"RF Prediction\"])].index)\n\npred_dict[\"only RF correct\"] = len(all_pred[(all_pred[\"CNN Prediction\"] != all_pred[\"Value\"]) & \n                                      (all_pred[\"RF Prediction\"] == all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] != all_pred[\"Value\"])].index)\n\npred_dict[\"only SVC correct\"] = len(all_pred[(all_pred[\"CNN Prediction\"] != all_pred[\"Value\"]) & \n                                      (all_pred[\"RF Prediction\"] != all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] == all_pred[\"Value\"])].index)\n\npred_dict[\"RF SCV correct_CNN wrong\"] = len(all_pred[(all_pred[\"CNN Prediction\"] != all_pred[\"Value\"]) & \n                                      (all_pred[\"RF Prediction\"] == all_pred[\"Value\"]) &\n                                      (all_pred[\"SVC Prediction\"] == all_pred[\"Value\"])].index)\n\nprint(pred_dict)  ","66d10ea5":"final_pred = cnn_model.predict(x_test)\nfinal_pred.shape","949e3398":"y_pred = final_pred.argmax(axis=1)\nImageID = np.arange(len(y_pred))+1\nOut = pd.DataFrame([ImageID,y_pred]).T\nOut.rename(columns = {0:'ImageId', 1:'Label'})\n#Out\nOut.to_csv('submission.csv', header =  ['ImageId', 'Label' ], index = None)","8d96d50d":"We can see that the distribution is rather uniform.\nNow let's visualize one sample...","a9f509a6":"We can see that sometimes either RF or SVC predict the right label while CNN is wrong. However, it happens only rarely that BOTH of them are correct when CNN is wrong. On the other hand, it happens quite frequently that both predict the same WRONG value when CNN is correct. Thus, we cannot configure our model in such a way that the predicted value would be the one predicted by RF and SVC is they are the same. In doing so, we will decrease the accuracy of our model. ","b89493d7":"### Plotting the results ","f97345e0":"### Build and train RF Classifier model","83f2d07b":"# Models\nIn this section we will test and compare several machine learning algorithms, including:\n* Convolutional Neural Network (CNN)\n* Random Forest Classifier\n* Support Vector Machine Classifier\n\nBecause I was reading Deep Learning with Python from Fran\u00e7ois Chollet before diving into Kaggle, I will start with the CNN in order to apply what I have learned in that book :)\n## CNN \n### Data processing ","604bd7c7":"# Import Data and analysis of the data\nLet's import the data first and look at them.","0c84d951":"# Model Ensembling?\nLet's compare our models. For instance let's see when one is wrong and not the others. By combining (ensembling) our models all together one might expect to have a more accurate prediction. However, what choice can we make to ensemble our models? Our CNN model is accurate around 99% of the time while RF and SVC has an accuracy of only approximatively 96% and 91% respectively. We should therefore be careful to not affect negatively our model when combining them. Let's have a look at it...","85c6951d":"It is interesting to see that the number of errors per label is non uniform. Some labels are much less well predicted than others. <br> Let's visualize what are the tendencies of our model in mislabeling the categories. For instance, is a 9 more ofter confused with a 0 or a 4? ","b2db663a":"### Training the model","a4a34f9f":"# Submission of test data\nBased on the conclusions above we will only use the CNN model.","f9f4e916":"The training and validation and accuracy (and loss) are rather constant at the end. Without much improvement. The model does not overfit. There is room for improvement, but at this stage we will leave the model as it is and will improve later.","d00e0ee6":"### Building the network ","06eb9787":"# Introduction\nHere is my very first Kaggle Notebook ! <br>\nI use this Notebook in order to get some practice and we look at 3 different type of models:\n1. Convolutional Neural Network\n1. Random Forest Classifier\n1. Support Vector Classification <br> <br> \nFor this submission I did not try to fine-tune the models. However, I investigate the possiblity to ensemble them in order to improve teh accuracy of my model.","65760802":"## Support Vector Machine Classifier","385d216d":"The current validation accuracy is around 99% percent which is pretty ! <br>\nLooking at the sample of errors illustrated above, I think it is fair to say that even a human could have mislabelled the image as well... <br>\nStill, let's try to improve our model and use other types of algorigthms to classify our images.\n\n## Random Forest Classifier\n### Data Processing"}}