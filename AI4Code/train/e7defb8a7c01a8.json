{"cell_type":{"44b55a81":"code","10d7f8e0":"code","9254cfa1":"code","681c30fa":"code","f5a37c68":"code","7f804887":"code","7ddeed45":"code","e6b5dd1a":"code","5fc90095":"code","5e1ba969":"markdown","a50bfb6b":"markdown","8e43047b":"markdown","ae42da0a":"markdown"},"source":{"44b55a81":"import itertools\nimport jieba\nimport numpy as np\nfrom collections import Counter\nfrom keras.models import Model, Sequential\nfrom keras.layers import InputLayer, Embedding, LSTM, Dense, TimeDistributed, SimpleRNN\nfrom keras.optimizers import SGD, Adam, Adadelta, RMSprop","10d7f8e0":"def build_vocab(text, vocab_lim):\n    # Counter\u5de5\u5177\u53ef\u4ee5\u5bf9\u5217\u8868\u5bf9\u8c61\u8fdb\u884c\u8ba1\u6570\n    word_cnt = Counter(text)\n    # most_common(vocab_lim)\u53ef\u4ee5\u8fd4\u56de\u4e00\u5217(\u5355\u8bcd\uff0c\u6b21\u6570)\u7684\u5143\u7ec4\n    # x[0]\u5c31\u662f\u628a\u5355\u8bcd\u4ece\u5143\u7ec4\u91cc\u53d6\u51fa\u6765\n    vocab_inv = [x[0] for x in word_cnt.most_common(vocab_lim)]\n    # \u6709\u4e86vocab_inv\u4ee5\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u5efa\u7acb\u5b83\u7684\u9006\u6620\u5c04\n    vocab = {x: index for index, x in enumerate(vocab_inv)}\n    return vocab, vocab_inv","9254cfa1":"vocab, vocab_inv = build_vocab(['a', 'a', 'b', 'c', 'a', 'd', 'd', 'e'], 10)\nprint(vocab)\nprint(vocab_inv)","681c30fa":"def process_file(file_name, use_char_based_model):\n    raw_text = []\n    # \u6253\u5f00\u6587\u4ef6\n    with open(file_name, \"r\") as f:\n        # \u904d\u5386\u6587\u4ef6\u4e2d\u7684\u6bcf\u4e00\u884c\n        for line in f:\n            if (use_char_based_model):\n                # \u5206\u5b57\n                raw_text.extend([str(ch) for ch in line])\n            else:\n                # \u5206\u8bcd\n                raw_text.extend([word for word in jieba.cut(line)])\n    return raw_text","f5a37c68":"def build_matrix(text, vocab, length, step):\n    M = []\n    # \u5c06\u5b57\u7b26\u6570\u7ec4text\u8f6c\u5316\u4e3a\u5bf9\u5e94\u7684\u7f16\u53f7\u6570\u7ec4M\n    for word in text:\n        # \u5f97\u5230word\u7684\u7f16\u53f7\n        index = vocab.get(word)\n        if (index is None):\n            # \u5982\u679cword\u4e0d\u5728\u8bcd\u5178\u91cc\uff0c\u7edf\u4e00\u7f16\u53f7\u4e3avocab\u7684\u957f\u5ea6\uff0c\u6bd4\u5982vocab\u539f\u6765\u67094000\u4e2a\u5355\u8bcd\uff0c\u5b83\u4eec\u6807\u53f7\u4e3a0~3999\uff0c4000\u662f\u7ed9\u4e0d\u5728\u8bcd\u5178\u91cc\u7684\u8bcd\u7edf\u4e00\u9884\u7559\u7684\u7f16\u53f7\n            M.append(len(vocab))\n        else:\n            # \u5426\u5219\u5c31\u53d6\u8bcd\u5178\u91cc\u7684\u7f16\u53f7\n            M.append(index)\n    num_sentences = len(M) \/\/ length\n\n    X = []\n    Y = []\n    # \u4ece0\u5f00\u59cb\uff0c\u6bcf\u9694step\u4e2a\u4f4d\u7f6e\u53d6\u4e00\u5bf9\u6570\u636e\n    for i in range(0, len(M) - length, step):\n        # [M_{i}, M_{i+1}, ..., M_{i+length}]\u662f\u8f93\u5165\n        X.append(M[i : i + length])\n        # [M_{i+1}, M_{i+2}, ..., M_{i+length+1}]\u662f\u8f93\u51fa\n        Y.append([[x] for x in M[i + 1 : i + length + 1]])\n    return np.array(X), np.array(Y)","7f804887":"# \u8bbe\u7f6e\u6bcf\u5bf9\u6570\u636e\u7684\u957f\u5ea6\u4e3a11\nseq_length = 11\n# \u5f97\u5230\u6587\u672c\u5206\u5272\u540e\u7684\u5e8f\u5217\uff0c\u6211\u4eec\u91c7\u7528\u5206\u5b57\u6a21\u578b\nraw_text = process_file(\"..\/input\/poetry.txt\", True)\n# \u5efa\u7acb\u8bcd\u5178\uff0c\u8bcd\u9891\u6392\u540d4000\u540d\u4ee5\u540e\u7684\u8bcd\u4e0d\u8ba1\u5165\u8bcd\u5178\nvocab, vocab_inv = build_vocab(raw_text, 4000)\nprint(len(vocab), len(vocab_inv))\n# \u6784\u5efa\u8bad\u7ec3\u6570\u636e\nX, Y = build_matrix(raw_text, vocab, seq_length, seq_length)\nprint(X.shape)\nprint(Y.shape)\nprint(X[0])\nprint(Y[0])","7ddeed45":"# \u642d\u5efa\u6a21\u578b\nmodel = Sequential()\n# \u8f93\u5165\u5c42 \u8bbe\u5b9a\u5f62\u72b6\u4e3a(None\uff0c)\u53ef\u4ee5\u4f7f\u6a21\u578b\u63a5\u53d7\u53d8\u957f\u8f93\u5165\n# \u6ce8\u610f\u5230\u6211\u4eec\u5728\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u7684\u65f6\u5019\u8ba9\u6bcf\u6b21\u8f93\u5165\u7684\u957f\u5ea6\u90fd\u662fseq_length\uff0c\u662f\u56e0\u4e3a\u6211\u4eec\u8981\u7528batch\u8bad\u7ec3\u7684\u65b9\u5f0f\u6765\u63d0\u9ad8\u5e76\u884c\u5ea6\n# \u540c\u6837\u957f\u5ea6\u7684\u6570\u636e\u53ef\u4ee5\u5728\u4e00\u6b21\u8fd0\u7b97\u4e2d\u5b8c\u6210\uff0c\u4e0d\u540c\u957f\u5ea6\u7684\u53ea\u80fd\u9010\u6b21\u8ba1\u7b97\n# \u8fd9\u4e00\u5c42\u8f93\u51fa\u7684\u5f62\u72b6\u662f(seq_length, )\nmodel.add(InputLayer(input_shape=(None, )))\n# \u8bcd\u5d4c\u5165\u5c42\uff0cinput_dim\u8868\u793a\u8bcd\u5178\u7684\u5927\u5c0f\uff0c\u5927\u5c0f4000\u7684\u8bcd\u5178\u4e00\u5171\u67090~4000\u4e2a\u6807\u53f7\u7684\u8bcd\uff0c\u6bcf\u79cd\u6807\u53f7\u5bf9\u5e94\u4e00\u4e2aoutput_dim\u7ef4\u7684\u8bcd\u5411\u91cf\uff0c\u8bbe\u7f6etrainable=True\u4f7f\u5f97\u8bcd\u5411\u91cf\u77e9\u9635\u53ef\u4ee5\u8c03\u6574\n# \u8fd9\u4e00\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\u662f(seq_length, 256, )\nmodel.add(Embedding(input_dim=len(vocab) + 1, output_dim=256, trainable=True))\n# RNN\u5c42\uff0c\u8f93\u51fa\u5f62\u72b6\u662f(seq_length, 256, )\nmodel.add(SimpleRNN(units=256, return_sequences=True))\n# \u6bcf\u4e2a\u65f6\u523b\u8f93\u51fa\u7684256\u7ef4\u5411\u91cf\u9700\u8981\u7ecf\u8fc7\u4e00\u6b21\u7ebf\u6027\u53d8\u6362\uff08\u4e5f\u5c31\u662fDense\u5c42\uff09\u8f6c\u5316\u4e3a4001\u7ef4\u7684\u5411\u91cf\uff0c\u7528softmax\u53d8\u6362\u8f6c\u5316\u4e3a\u4e00\u4e2a4001\u7ef4\u7684\u6982\u7387\u6982\u7387\u5206\u5e03\uff0c\u7b2ci\u7ef4\u8868\u793a\u4e0b\u4e00\u4e2a\u65f6\u523b\u7684\u8bcd\u662fi\u53f7\u5355\u8bcd\u7684\u6982\u7387\n# Dense\u5373\u7ebf\u6027\u53d8\u6362\uff0cTimeDistributed\u8868\u793a\u5bf9\u6bcf\u4e2a\u65f6\u523b\u90fd\u5982\u6b64\u4f5c\u7528\n# \u8fd9\u4e00\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\u662f(seq_length, len(vocab) + 1)\nmodel.add(TimeDistributed(Dense(units=len(vocab) + 1, activation='softmax')))\n\n# \u5b9a\u4e49loss\u51fd\u6570\u4e3a\u4ea4\u53c9\u71b5\uff0c\u4f18\u5316\u5668\u4e3aAdam\uff0c\u5b66\u4e60\u7387\u4e3a0.01\nmodel.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')\nmodel.summary()","e6b5dd1a":"# \u8bad\u7ec3\nmodel.fit(X, Y, batch_size=512, epochs=18, verbose=1, validation_split=0.1)","5fc90095":"st = '\u660e\u6708\u677e\u95f4\u7167'\nprint(st, end='')\n\nvocab_inv.append(' ')\n\nfor i in range(200):\n    X_sample = np.array([[vocab.get(x, len(vocab)) for x in st]])\n    pdt = (-model.predict(X_sample)[:, -1: , :][0][0]).argsort()[:4]\n    if vocab_inv[pdt[0]] == '\\n' or vocab_inv[pdt[0]] == '\uff0c' or vocab_inv[pdt[0]] == '\u3002':\n        ch = vocab_inv[pdt[0]]\n    else:\n        ch = vocab_inv[np.random.choice(pdt)]\n    print(ch, end='')\n    st = st + ch","5e1ba969":"#### process_file\u7684\u4f5c\u7528\u662f\u8bfb\u5165\u8def\u5f84\u4e3afile_name\u7684\u6587\u4ef6\uff0c\u5e76\u6839\u636euse_char_based_model\u6765\u9009\u62e9\u5bf9\u6587\u4ef6\u5185\u5bb9\u7684\u5207\u5272\u65b9\u5f0f\n#### \u5982\u679cuse_char_based_model = True\uff0c\u90a3\u4e48\u8fd4\u56de\u7684\u5217\u8868\u662f\u5c06\u539f\u6587\u4ef6\u5185\u5bb9\u6309\u5b57\u5206\u5f00\n#### \u5982\u679cuse_char_based_model = False, \u90a3\u4e48\u8fd4\u56de\u7684\u5217\u8868\u662f\u5c06\u539f\u6587\u4ef6\u4e2d\u6587\u5206\u8bcd","a50bfb6b":"#### build_matrix\u7528\u4e8e\u6784\u5efa\u8bad\u7ec3\u6570\u636e\uff0c\u8f93\u5165\u6587\u672ctext\u548c\u8bcd\u5178vocab\uff0clength\u662f\u4e00\u5bf9\u6570\u636e\u7684\u957f\u5ea6\uff0cstep\u8868\u793a\u6bcf\u9694step\u4e2a\u4f4d\u7f6e\u53d6\u4e00\u5bf9\u6570\u636e\n#### \u8bad\u7ec3\u6570\u636e\u662f\u4e00\u4e2a\u8f93\u5165\u8f93\u51fa\u5bf9\uff0c\u6839\u636e\u6211\u4eec\u5bf9RNN\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\uff0c\u8f93\u5165\u662f$(w_{i}, w_{i+1}, \\dots, w_{i+length})$\u7684\u8bdd\uff0c\u8f93\u51fa\u662f$(w_{i+1}, w_{i+2}, \\dots, w_{i+length+1})$\n![](https:\/\/cs.stanford.edu\/people\/karpathy\/recurrentjs\/eg.png)","8e43047b":"#### build_vocab\u51fd\u6570\u7684\u4f5c\u7528\u662f\u5bf9\u8f93\u5165\u7684text\u5217\u8868\u5efa\u7acb\u8bcd\u5178vocab\u548cvocab_inv\n#### \u5176\u4e2dvocab\u662f\u5355\u8bcd\u5230\u7f16\u53f7\u7684\u6620\u5c04\n#### vocab_inv\u662f\u7f16\u53f7\u5230\u5355\u8bcd\u7684\u6620\u5c04","ae42da0a":"#### \u5982\u679c\u6ca1\u6709\u5b89\u88c5 keras \u548c tensorflow \u5e93\n#### \u8bf7\u4f7f\u7528 pip install keras tensorflow \u5b89\u88c5\n#### \u5982\u679c\u4f7f\u7528conda\u865a\u62df\u73af\u5883\n#### \u8bf7\u4f7f\u7528conda install -c conda-forge keras\n#### conda install -c conda-forge tensorflow "}}