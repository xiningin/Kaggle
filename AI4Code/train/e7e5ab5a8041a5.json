{"cell_type":{"13fdb083":"code","b8175931":"code","ab72cdf7":"code","6f66459c":"code","245b6451":"code","c8b32437":"code","ebe63124":"code","10c270d6":"code","b82302c2":"code","9984fb95":"code","feac49b8":"markdown","235702d2":"markdown","98da75a0":"markdown","6483b0c0":"markdown","88625a47":"markdown","c9718dc7":"markdown","6fb6f6d7":"markdown","0ca1d9ee":"markdown","309383de":"markdown","11f2894c":"markdown","1769859a":"markdown","cd7259ac":"markdown","a65d2d36":"markdown"},"source":{"13fdb083":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.formula.api as smf\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib.colors import ListedColormap","b8175931":"genre = pd.read_csv('..\/input\/dataset-of-songs-in-spotify\/genres_v2.csv')","ab72cdf7":"# Unify song name\nfor i in range(len(genre)):\n    if genre['song_name'][i] != genre['song_name'][i]:\n        genre['song_name'][i:] = genre['title'][i:]\n        break\ngenre.drop(['Unnamed: 0', 'title'], axis=1, inplace=True)\n# Drop NaN\ngenre.dropna(inplace=True)\n# Produce a numerical version dataset\ngenre_data = genre.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'song_name', 'genre'], axis=1)\n# Standardize \nnum_column = genre_data.columns\ngenre_data = StandardScaler().fit_transform(genre_data)\ngenre_data = pd.DataFrame(genre_data)\ngenre_data.columns = num_column\npca = PCA(n_components=2).fit(genre_data).transform(genre_data)","6f66459c":"sns.pairplot(genre_data)","245b6451":"val_accuracies = []\ntrain_accuracies = []\nKNN_models = []\nX_train, X_test, Y_train, Y_test = train_test_split(genre_data, genre['genre'], test_size=0.2)\nX_train, X_val, Y_train, Y_val = train_test_split(genre_data, genre['genre'], test_size=0.2)\n# We try neighbors from 1 to 11\nfor i in range(1,11):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, Y_train)\n    total = 0\n    for actual,pred in zip(neigh.predict(X_val), Y_val):\n        total += actual == pred\n    val_accuracies.append(total\/len(X_val))\n    total = 0\n    for actual,pred in zip(neigh.predict(X_train), Y_train):\n        total += actual == pred\n    train_accuracies.append(total\/len(X_train))\n    KNN_models.append(neigh)","c8b32437":"plt.plot(np.arange(10) + 1, val_accuracies, c='y')\nplt.plot(np.arange(10) + 1, train_accuracies, c='b')\nplt.legend(['Validation set', 'Train set'])","ebe63124":"for i in range(3):\n    select_model = KNN_models[i]\n    total = 0\n    for actual,pred in zip(select_model.predict(X_test), Y_test):\n        total += actual == pred\n    print('Model {} accuracy:'.format(i+1), total\/len(X_test))\n","10c270d6":"print(PCA(n_components=2).fit(genre_data).explained_variance_ratio_)\ngenre['pc1'] = pca[:, 0]\ngenre['pc2'] = pca[:, 1]\nsns.set(rc={'figure.figsize': (20,15)})\nsns.scatterplot(data=genre, x='pc1', y='pc2', hue='genre', alpha=0.6)","b82302c2":"h = .02  # step size in the mesh\n\n# Create color maps\ncmap_light = ListedColormap(['orange', 'blue', 'red', 'brown', 'yellow', 'green', 'aqua', 'purple', 'pink', 'silver', 'black', 'dimgray', 'darkred', 'linen', 'lawngreen'])\ncmap_bold = ['orange', 'blue', 'red', 'brown', 'yellow', 'green', 'aqua', 'purple', 'pink', 'silver', 'black', 'dimgray', 'darkred', 'linen', 'lawngreen']\n\n# We train the model under pca to plot 2d boundaries\nclf = KNeighborsClassifier(n_neighbors=5).fit(pca, genre['genre'])\n\ncodemap = {}\nfor i,genre_name in enumerate(genre['genre']):\n    codemap[genre_name] = i\n    \n# Plot the decision boundary. For that, we will assign a color to each\n# point in the mesh [x_min, x_max]x[y_min, y_max].\nx_min, x_max = pca[:, 0].min() - 1, pca[:, 0].max() + 1\ny_min, y_max = pca[:, 1].min() - 1, pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = np.array([codemap[genre_name] for genre_name in Z])\n# Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.figure(figsize=(20,16))\nplt.contourf(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\npts = sns.scatterplot(x=pca[:, 0], y=pca[:, 1], hue=genre['genre'],\n                palette=cmap_bold, alpha=0, edgecolor=\"black\", size=1)\npts.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\n\nplt.show()","9984fb95":"count = {}\nfor name in genre['genre']:\n    if name not in count:\n        count[name] = 1\n    else:\n        count[name] += 1\nfor name in count:\n    print(name, count[name])","feac49b8":"## Limitation  \n\n1. Genres are generally not independent of one another. We have names that implies relationships (Dark Trap VS. Trap). This is also shown from the plot of the first two pc.  \n\n2. There are significant differences between number of samples of each genre as shown in the cell below.","235702d2":"# Clean dataset\n1. Notice that some sonngs have names but others do not. The ones that do not have a name actually has a reference of where they are found under the **title** column. We merge those with the name column.\n\n2. For purposes of classification, we separate the text columns (type, id, etc.) and create another dataframe containing only numeric values \n\n3. Standardize and remove NaN values","98da75a0":"# Further questions","6483b0c0":"# View dataset using pairplot","88625a47":"# Genre classification using Spotify dataset","c9718dc7":"# View results and choose which model to use","6fb6f6d7":"# Get data","0ca1d9ee":"# Plot the first two pcs and their explained variances","309383de":"# Analysis","11f2894c":"What is the relationship between these genres? \nPrimary idea: Usign K-Means to generate clusters and analyze the elements of those clusters","1769859a":"## From the plot, we can see that 1-3 neighbors are ideal value to use. Both gives good validation results as well as training results.","cd7259ac":"## We choose the 1-neighbor model and plot decision bounadries","a65d2d36":"# Using K-NN to build model"}}