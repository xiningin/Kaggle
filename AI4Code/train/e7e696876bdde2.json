{"cell_type":{"7349dd2f":"code","72f4920c":"code","0762a5c6":"code","0cf6976f":"code","81ff02b3":"code","0ea39ff0":"code","51fa2f34":"code","2175f477":"code","fc348815":"code","e67553f5":"code","aecd4b3e":"code","b73503f8":"code","f9ad5eeb":"code","099e937d":"code","13d71ffb":"code","7eafcb91":"code","88beca04":"code","081dedb6":"code","6c8778cb":"code","05298b67":"code","a5643ffd":"code","f9f408bc":"code","dbce4452":"code","4ca9d15e":"code","9ea0d146":"code","35653ac7":"code","58032a02":"code","16f7c5a1":"code","269732f5":"code","acf87e7e":"code","f060cd83":"markdown","11246779":"markdown","06b2068a":"markdown","f3e20345":"markdown","4896051c":"markdown","53bf7df4":"markdown","29c221a0":"markdown","6cd22b77":"markdown","e5fd2bdc":"markdown","d389d4b0":"markdown","5ed66ce4":"markdown","6bde3e48":"markdown","95c1b4b5":"markdown","d5e39007":"markdown","7bed9fdd":"markdown","e1590d5b":"markdown","04ed82b2":"markdown","cc8c5cfa":"markdown","f098dbe1":"markdown","ff2c804f":"markdown","8b4285fc":"markdown"},"source":{"7349dd2f":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import log_loss\nfrom sklearn.ensemble import RandomForestClassifier","72f4920c":"pd.set_option(\"max_columns\",110)\nplt.rcParams['figure.figsize'] = 50,50","0762a5c6":"train = pd.read_csv(\"..\/input\/train.csv\",index_col=\"unique_id\")\ntest = pd.read_csv(\"..\/input\/test.csv\",index_col=\"unique_id\")","0cf6976f":"y = train.targets.values\nx = train.drop([\"targets\"],axis=1).values","81ff02b3":"sss = StratifiedShuffleSplit(n_splits=1, test_size=.20, random_state=0)\nfor train_index, test_index in sss.split(x, y):\n    x_train,x_test,y_train,y_test = x[train_index],x[test_index],y[train_index],y[test_index]","0ea39ff0":"lr = LogisticRegression()\nlr.fit(x_train,y_train)\ny_pred = lr.predict_proba(x_test)\nlog_loss(y_test,y_pred)","51fa2f34":"train_df = train.copy()\ntest_df = test.copy()","2175f477":"train_df.head()","fc348815":"train_df.hist()\nplt.show()","e67553f5":"train_df[[\"x_79\"]] = train_df[[\"x_79\"]]+2017\ntrain_df[\"x_6\"] = train_df[\"x_6\"]+101.25\ntrain_df[\"x_6\"] = train_df[\"x_6\"].astype(\"int64\")\ntrain_df[[\"x_51\"]] = train_df[[\"x_51\"]]-123456\ntrain_df[[\"x_61\"]] = train_df[[\"x_61\"]]-2017\ntest_df[[\"x_79\"]] = test_df[[\"x_79\"]]+2017\ntest_df[\"x_6\"] = test_df[\"x_6\"]+101.25\ntest_df[\"x_6\"] = test_df[\"x_6\"].astype(\"int64\")\ntest_df[[\"x_51\"]] = test_df[[\"x_51\"]]-123456\ntest_df[[\"x_61\"]] = test_df[[\"x_61\"]]-2017","aecd4b3e":"train_df.head()","b73503f8":"train_df['x_31'] = np.log(train_df['x_31'])\ntest_df['x_31'] = np.log(test_df['x_31'])\ntrain_df['x_31'] = train_df['x_31'].astype(\"int64\")\ntest_df[\"x_31\"] = test_df[\"x_31\"].astype(\"int64\")\ntrain_df['x_90'] = np.log(train_df['x_90'])\ntest_df['x_90'] = np.log(test_df['x_90'])\ntrain_df['x_90'] = train_df['x_90'].astype(\"int64\")\ntest_df[\"x_90\"] = test_df[\"x_90\"].astype(\"int64\")","f9ad5eeb":"train_df.head()","099e937d":"plt.rcParams.update(plt.rcParamsDefault)","13d71ffb":"sns.kdeplot(train_df.x_94)","7eafcb91":"v = train_df.x_94\nv = np.floor(v)\nsns.kdeplot(v)","88beca04":"train_df.x_94 = train_df.x_94.apply(np.floor).astype(\"int64\")\ntrain_df.x_98 = train_df.x_98.apply(np.floor).astype(\"int64\")\ntrain_df.x_100 = train_df.x_100.apply(np.floor).astype(\"int64\")\ntrain_df.x_11 = train_df.x_11.apply(np.floor).astype(\"int64\")\ntrain_df.x_13 = train_df.x_13.apply(np.floor).astype(\"int64\")\ntrain_df.x_17 = train_df.x_17.apply(np.floor).astype(\"int64\")\ntrain_df.x_21 = train_df.x_21.apply(np.floor).astype(\"int64\")\n\ntest_df.x_94 = test_df.x_94.apply(np.floor).astype(\"int64\")\ntest_df.x_98 = test_df.x_98.apply(np.floor).astype(\"int64\")\ntest_df.x_100 = test_df.x_100.apply(np.floor).astype(\"int64\")\ntest_df.x_11 = test_df.x_11.apply(np.floor).astype(\"int64\")\ntest_df.x_13 = test_df.x_13.apply(np.floor).astype(\"int64\")\ntest_df.x_17 = test_df.x_17.apply(np.floor).astype(\"int64\")\ntest_df.x_21 = test_df.x_21.apply(np.floor).astype(\"int64\")","081dedb6":"train_df.head()","6c8778cb":"sns.kdeplot(train_df['x_13'])","05298b67":"def negpos(a):\n    if(a<0):\n        a=-a\n    else:\n        a=a\n    return a","a5643ffd":"train_df.x_94 = train_df.x_94.apply(negpos)\ntrain_df.x_98 = train_df.x_98.apply(negpos)\ntrain_df.x_100 = train_df.x_100.apply(negpos)\ntrain_df.x_11 = train_df.x_11.apply(negpos)\ntrain_df.x_13 = train_df.x_13.apply(negpos)\ntrain_df.x_17 = train_df.x_17.apply(negpos)\ntrain_df.x_21 = train_df.x_21.apply(negpos)\n\ntest_df.x_94 = test_df.x_94.apply(negpos)\ntest_df.x_98 = test_df.x_98.apply(negpos)\ntest_df.x_100 = test_df.x_100.apply(negpos)\ntest_df.x_11 = test_df.x_11.apply(negpos)\ntest_df.x_13 = test_df.x_13.apply(negpos)\ntest_df.x_17 = test_df.x_17.apply(negpos)\ntest_df.x_21 = test_df.x_21.apply(negpos)","f9f408bc":"train_df.head()","dbce4452":"def log_problem(a):\n    if(a<=1):\n        return 0\n    else:\n        return np.log10(a) \n    \ntrain_df.x_96=train_df.x_96.apply(log_problem)\ntrain_df.x_96=np.ceil(train_df.x_96).astype(\"int64\")\n\ntest_df.x_96=test_df.x_96.apply(log_problem)\ntest_df.x_96=np.ceil(test_df.x_96).astype(\"int64\")","4ca9d15e":"train_df.head()","9ea0d146":"y_new = train_df.targets.values\nx_new = train_df.drop([\"targets\"],axis=1).values","35653ac7":"sss = StratifiedShuffleSplit(n_splits=1, test_size=.20, random_state=0)\nfor train_index, test_index in sss.split(x, y):\n    x_train,x_test,y_train,y_test = x_new[train_index],x_new[test_index],y_new[train_index],y_new[test_index]","58032a02":"lr = LogisticRegression(class_weight='balanced')\nlr.fit(x_train,y_train)\ny_pred = lr.predict_proba(x_test)\nlog_loss(y_test,y_pred)","16f7c5a1":"t = pd.read_csv(\"..\/input\/test.csv\")\ndef filesub(v,y_pred,test):\n    a = pd.DataFrame(y_pred,columns=['proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9'])\n    a[\"unique_id\"] = test[\"unique_id\"]\n    columns=[\"unique_id\",'proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9']\n    a = a[columns]\n    a.to_csv(v+\"_sub.csv\",index=False)","269732f5":"lr.fit(x_new,y_new)\ny_pred = lr.predict_proba(test_df.values)","acf87e7e":"filesub(\"lr_first\",y_pred,t)","f060cd83":"Splitting train set to train and validation set","11246779":"## BaseLine Classifier Training","06b2068a":"## Now we can start modelling as our data is properly cleanded and scaled","f3e20345":"### 1. Logistic Regression","4896051c":"Seperation of data","53bf7df4":"# FigureItOut Complete EDA","29c221a0":"## Things remaning","6cd22b77":"Splitting data for validation","e5fd2bdc":"Setting some options","d389d4b0":"We can also remove outliers for some more accuracy","5ed66ce4":"Reading data files","6bde3e48":"Importing Libraries","95c1b4b5":"There are some remaning columns with decimal values we can convert them to int by taking floor of them this also keep the same density accros the axis","d5e39007":"1. Differet models can be applied\n2. Outliers can be removed\n3. More feature engg can be done","7bed9fdd":"Most of the plots of the columns which contains the negative number are gaussin plots we can use the property of these convert them to positive","e1590d5b":"If we see further we can also convert other colums to int by taking there log","04ed82b2":"Utility function for file submission","cc8c5cfa":"# DataCleaning, EDA and Feature Engg","f098dbe1":"Training and testing the model","ff2c804f":"We can see some columns have very high values but they are more or less same we can subtract those columns with there smallest value to get the best result","8b4285fc":"Finally for column 96 we can take log10 to convert that to its original value"}}