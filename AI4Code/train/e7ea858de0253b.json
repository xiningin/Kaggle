{"cell_type":{"f1a42675":"code","0fb25877":"code","4895ac02":"code","0d47db5e":"code","7c000c52":"code","d16d57b4":"code","e57f9d77":"code","843ef945":"code","8dd11b5c":"code","292bc6ef":"code","eb93aec1":"code","0f1241db":"code","0510d233":"code","9dbcf014":"code","57b484ef":"code","3a884f63":"code","44e35d9e":"code","11ec15c5":"code","d48d9caa":"code","d3ce7cfe":"code","0680be93":"code","7ff86389":"code","7fbdc6cd":"code","2b79417b":"code","6b7f1069":"code","693cb4c0":"code","e9653871":"code","ecf60d7a":"code","612b87ec":"code","123b5fd2":"code","291ad9a9":"code","469ddc84":"code","8d083d39":"code","4a82dbbd":"code","ae69817e":"code","a4c04aec":"code","b9bb2665":"code","8ccde6e0":"markdown"},"source":{"f1a42675":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0fb25877":"import numpy as np\nimport pandas as pd\nimport pickle","4895ac02":"train_df = pd.read_csv('\/kaggle\/input\/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2\/train_sessions.csv',\n                      index_col='session_id')\ntest_df = pd.read_csv('\/kaggle\/input\/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2\/test_sessions.csv',\n                     index_col='session_id')","0d47db5e":"train_df.head()","7c000c52":"# \u041c\u0435\u043d\u044f\u0435\u043c \u0442\u0438\u043f \u0430\u0442\u0440\u0438\u0431\u0443\u0442\u043e\u0432 site1, ..., site10 \u043d\u0430 \u0446\u0435\u043b\u043e\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0439 \u0438 \u0437\u0430\u043c\u0435\u043d\u044f\u0435\u043c \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043d\u0443\u043b\u044f\u043c\u0438\nsites = ['site%s' % i for i in range(1,11)]\ntrain_df[sites] = train_df[sites].fillna(0).astype(int)\ntest_df[sites] = test_df[sites].fillna(0).astype(int)","d16d57b4":"with open(r\"\/kaggle\/input\/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2\/site_dic.pkl\", \"rb\") as input_file:\n    site_dict = pickle.load(input_file)\n\nsites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])","e57f9d77":"sites_dict.head()","843ef945":"sites_dict.shape","8dd11b5c":"train_df.shape, test_df.shape","292bc6ef":"train_df['target'].values","eb93aec1":"y_train = train_df['target'].values","0f1241db":"idx = train_df.shape[0]\ndata_df = pd.concat([train_df, test_df], sort=False)","0510d233":"data_df[sites].to_csv('data_sessions_text.txt', \n                                 sep=' ', index=None, header=None)","9dbcf014":"!head data_sessions_text.txt","57b484ef":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(use_idf=True)\nwith open('data_sessions_text.txt') as inp_file:\n    data = tfidf.fit_transform(inp_file)","3a884f63":"X_train = data[:idx]\nX_test = data[idx:]\nprint(X_train.shape, X_test.shape)","44e35d9e":"X_add = data_df[['time1']]\nX_add['time1'] = X_add['time1'].apply(pd.to_datetime)","11ec15c5":"X_add['start day'] = X_add['time1'].apply(lambda x: x.dayofweek)\nX_add['start hour'] = X_add['time1'].apply(lambda x: x.hour)\nX_add['start month'] = X_add['time1'].apply(lambda x: x.month)\nX_add['weekend'] = X_add['start day'].apply(lambda x: x > 4).astype(np.int8)\n\nX_add['1st half day'] = X_add['start hour'].apply(lambda x: x > 14).astype(np.int8)\nX_add['morning'] = X_add['start hour'].apply(lambda x: (x >= 7) & (x < 12)).astype(np.int8)\nX_add['day'] = X_add['start hour'].apply(lambda x: (x >= 12) & (x < 18)).astype(np.int8)\nX_add['evening'] = X_add['start hour'].apply(lambda x: (x >= 18) & (x < 23)).astype(np.int8)\nX_add['night'] = X_add['start hour'].apply(lambda x: (x >= 23) | (x < 7)).astype(np.int8)","d48d9caa":"X_add.head()","d3ce7cfe":"X_add = X_add.drop(columns=['time1'])","0680be93":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler = StandardScaler()\n\n\nfeatures_to_scale = [\n    'start day',\n    'start hour',\n    'start month'\n]\nX_add[features_to_scale] = scaler.fit_transform(X_add[features_to_scale])","7ff86389":"X_add.head()","7fbdc6cd":"X_add_train = X_add[:idx]\nX_add_test = X_add[idx:]","2b79417b":"X_train, X_test","6b7f1069":"from scipy import sparse\nX_train = sparse.hstack((X_train,X_add_train))\nX_test = sparse.hstack((X_test,X_add_test))","693cb4c0":"X_train, X_test","e9653871":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nlog_reg = LogisticRegression(C=1.0, random_state=42, solver='lbfgs', max_iter=500)\nX_train_log, X_valid_log, y_train_log, y_valid_log = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\nlog_reg.fit(X_train_log, y_train_log)","ecf60d7a":"y_pred = log_reg.predict_proba(X_valid_log)\nscore = roc_auc_score(y_valid_log, y_pred[:,1])\nscore","612b87ec":"log_reg.fit(X_train, y_train)","123b5fd2":"# \u0414\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\ny_test = log_reg.predict_proba(X_test)","291ad9a9":"def write_to_submission_file(predicted_labels, out_file,\n                             target='target', index_label=\"session_id\"):\n    predicted_df = pd.DataFrame(predicted_labels,\n                                index = np.arange(1, predicted_labels.shape[0] + 1),\n                                columns=[target])\n    predicted_df.to_csv(out_file, index_label=index_label)","469ddc84":"write_to_submission_file(y_test[:,1], 'baseline_1.csv')","8d083d39":"param_grid = [\n    {'penalty' : ['l1', 'l2'],\n    'C' : [0.001,0.01,0.1,1,10,100,1000],\n    'solver' : ['liblinear']}]","4a82dbbd":"from sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(log_reg, scoring = 'roc_auc', param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\ngrid_search.fit(X_train, y_train)","ae69817e":"grid_search.best_params_","a4c04aec":"y_test = grid_search.best_estimator_.predict_proba(X_test)","b9bb2665":"write_to_submission_file(y_test[:,1], 'baseline_2.csv')","8ccde6e0":"**Features Engineering**"}}