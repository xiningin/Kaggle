{"cell_type":{"a9bd9860":"code","99be5112":"code","b393c396":"code","b519e3a4":"code","58e79f87":"code","9bc15c25":"code","14250e71":"code","37c24efe":"code","ee6cfbba":"code","26723641":"code","7575535e":"code","487ca57a":"code","64183b94":"code","400c2dca":"code","a38598fb":"code","314c299c":"code","e0dd6278":"code","3254202f":"code","90f0e0a1":"code","0e15447b":"code","b6d88b8f":"code","7358b5dc":"code","f9866976":"code","55443aec":"code","5dd8faa2":"code","9a8e44d1":"code","26becc3a":"code","733f6cfe":"code","bc1c76db":"code","0a82da5c":"code","1a7d9db8":"code","65fe4637":"code","63b5d64d":"code","edb8ec06":"code","a4213700":"code","66c0f967":"code","241d112e":"code","2b2e0980":"code","9e115b72":"markdown","f06ad12a":"markdown","1d3d9dbd":"markdown","e784fb59":"markdown","f206287c":"markdown","f862074a":"markdown","fd36dce9":"markdown","f5b09fb8":"markdown","3de05946":"markdown","d0473b97":"markdown","e760f5ec":"markdown","16542ff0":"markdown","54252aa0":"markdown"},"source":{"a9bd9860":"from sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport matplotlib.pyplot as plt","99be5112":"n_samples, n_features = 10, 1\nrng = np.random.RandomState(0)\n\ny = rng.randn(n_samples)\nX = rng.randn(n_samples, n_features)","b393c396":"X, y","b519e3a4":"X.shape, y.shape","58e79f87":"y = y.reshape(len(y), 1)\n# y = y.reshape(-1, 1)\n\nX.shape, y.shape","9bc15c25":"plt.scatter(X, y, color = 'blue')\nplt.show()","14250e71":"reg_rbf = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2)) # Default kernel='rbf'\nreg_lr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, kernel = 'linear'))\nreg_p = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, kernel = 'poly'))\n","37c24efe":"reg_rbf.fit(X, y)\nreg_lr.fit(X, y)\nreg_p.fit(X, y)","ee6cfbba":"# Pipeline(steps=[('standardscaler', StandardScaler()),('svr', SVR(epsilon=0.2))])\n# Pipeline(steps=[('standardscaler', StandardScaler()),('svr', SVR(epsilon=0.2))])\n# Pipeline(steps=[('standardscaler', StandardScaler()),('svr', SVR(epsilon=0.2))])","26723641":"y_pred_rbf = reg_rbf.predict([[1.49407907]])\ny_pred_lr = reg_lr.predict([[1.49407907]])\ny_pred_p = reg_p.predict([[1.49407907]])\n\ny_pred_rbf, y_pred_lr, y_pred_p","7575535e":"plt.scatter(X, y, color = 'blue', label = 'Data')\n\nplt.plot(X, reg_rbf.predict(X), color = 'r', label = 'SVR with Default RBF Model')\nplt.plot(X, reg_lr.predict(X), color = 'g', label = 'SVR with Linear')\nplt.plot(X, reg_p.predict(X), color = 'c', label = 'SVR with Poly')\n\nplt.title(\"SVR - Randomly Generated Data\")\n\nplt.xlabel('X')\nplt.ylabel('y')\n\nplt.legend()\n\nplt.show()  ","487ca57a":"# Change in C and gamma\nreg_rbf = make_pipeline(StandardScaler(), SVR(C=100, epsilon=0.1, gamma=0.1)) # Default kernel='rbf'\nreg_lr = make_pipeline(StandardScaler(), SVR(C=100, epsilon=0.1, kernel = 'linear', gamma='auto'))\nreg_p = make_pipeline(StandardScaler(), SVR(C=100, epsilon=0.1, kernel = 'poly', gamma='auto', degree=3, coef0=1))\n\nreg_rbf.fit(X, y)\nreg_lr.fit(X, y)\nreg_p.fit(X, y)","64183b94":"plt.scatter(X, y, color = 'blue', label = 'Data')\n\nplt.plot(X, reg_rbf.predict(X), color = 'r', label = 'SVR with Default RBF Model')\nplt.plot(X, reg_lr.predict(X), color = 'g', label = 'SVR with Linear')\nplt.plot(X, reg_p.predict(X), color = 'c', label = 'SVR with Poly')\n\nplt.title(\"SVR - Randomly Generated Data - With C = 100\")\n\nplt.xlabel('X')\nplt.ylabel('y')\n\nplt.legend()\n\nplt.show()","400c2dca":"data = {'Position':['CEO','Sr. Director','Director','Region Manager','Country Manager','Manager','Consultant','Software Engineer','Business ANalyst','Junior Engineer',], \n        'Level': [10,9,8,7,6,5,4,3,1,2],\n        'Salary' : [700,500,300,200,150,110,80,50,60,45] # in Thousands\n       } ","a38598fb":"## Import Library\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt","314c299c":"# Creating DataFrame   \ndf = pd.DataFrame(data)","e0dd6278":"df","3254202f":"X = df.iloc[:, 1:2].values\ny = df.iloc[:, 2].values\n\n# X = df.drop(['Position','Salary'], axis=1)\n# y = df.Salary","90f0e0a1":"X","0e15447b":"y","b6d88b8f":"y.shape","7358b5dc":"# y = y.reshape(len(y), 1)\n# y.shape","f9866976":"y","55443aec":"from sklearn.preprocessing import StandardScaler\n\nxsc = StandardScaler()\nysc = StandardScaler()\n\nX_scaled = xsc.fit_transform(X)\ny_scaled = ysc.fit_transform(y.reshape(-1,1))\n# y_scaled = ysc.fit_transform(y)","5dd8faa2":"y_scaled.shape","9a8e44d1":"y_scaled","26becc3a":"from sklearn.svm import SVR\n\nreg = SVR(kernel = 'rbf')\n\nreg.fit(X_scaled, y_scaled)","733f6cfe":"y_pred = reg.predict([[8.5]])\n\ny_pred = ysc.inverse_transform(y_pred)\ny_pred","bc1c76db":"x_grid = np.arange(min(X_scaled), max(X_scaled), 0.01) # choice of 0.01 instead of 0.1 is as the data is featured scaled.\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(X_scaled, y_scaled, color = 'blue')\nplt.plot(x_grid, reg.predict(x_grid), color = 'red') \nplt.title(\"SVR\")\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()","0a82da5c":"reg_l = SVR(kernel = 'linear')\n\nreg_l.fit(X_scaled, y_scaled)\n\ny_pred = reg_l.predict([[8.5]])\n\ny_pred = ysc.inverse_transform(y_pred)\ny_pred","1a7d9db8":"x_grid = np.arange(min(X_scaled), max(X_scaled), 0.01) # choice of 0.01 instead of 0.1 is as the data is featured scaled.\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(X_scaled, y_scaled, color = 'blue')\nplt.plot(x_grid, reg_l.predict(x_grid), color = 'red')\nplt.title(\"SVR\")\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()","65fe4637":"reg_p = SVR(kernel = 'poly')\n\nreg_p.fit(X_scaled, y_scaled)\n\ny_pred = reg_p.predict([[8.5]])\n\ny_pred = ysc.inverse_transform(y_pred)\ny_pred","63b5d64d":"x_grid = np.arange(min(X_scaled), max(X_scaled), 0.01) # choice of 0.01 instead of 0.1 is as the data is featured scaled.\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(X_scaled, y_scaled, color = 'blue')\nplt.plot(x_grid, reg_p.predict(x_grid), color = 'red')\nplt.title(\"SVR\")\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()  ","edb8ec06":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_scaled, y_scaled)\n\n#predecting the test set results\ny_pred = lr.predict([[8.5]])\ny_pred = ysc.inverse_transform(y_pred)\ny_pred","a4213700":"x_grid = np.arange(min(X_scaled), max(X_scaled), 0.01) # choice of 0.01 instead of 0.1 is as the data is featured scaled.\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(X_scaled, y_scaled, color = 'blue')\nplt.plot(x_grid, lr.predict(x_grid), color = 'red')\nplt.title(\"Linear Regression\")\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()  ","66c0f967":"x_grid = np.arange(min(X_scaled), max(X_scaled), 0.01) # choice of 0.01 instead of 0.1 is as the data is featured scaled.\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(X_scaled, y_scaled, color = 'blue', label = 'data')\nplt.plot(x_grid, reg.predict(x_grid), color = 'red', label = 'RBF Model')\nplt.plot(x_grid, reg_l.predict(x_grid), color = 'c', label = 'Linear Model')\nplt.plot(x_grid, reg_p.predict(x_grid), color = 'navy', label = 'Polynomial Model')\nplt.plot(x_grid, lr.predict(x_grid), color = 'm', label = 'Linear Regression Model')\nplt.title(\"SVR\")\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.legend()\nplt.show()  ","241d112e":"eps = 20\n\nreg_eps = SVR(kernel = 'rbf', epsilon=eps)\n\nreg_eps.fit(X_scaled, y_scaled)\n\ny_pred = reg_eps.predict([[8.5]])\n\ny_pred = ysc.inverse_transform(y_pred)\ny_pred","2b2e0980":"x_grid = np.arange(min(X_scaled), max(X_scaled), 0.01) # choice of 0.01 instead of 0.1 is as the data is featured scaled.\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(X_scaled, y_scaled, color = 'blue')\nplt.plot(x_grid, reg_eps.predict(x_grid), color = 'red')\nplt.plot(x_grid, reg_eps.predict(x_grid)-eps, color='black') # Vector\nplt.plot(x_grid, reg_eps.predict(x_grid)+eps, color='black') # Vector\nplt.title(\"SVR - with Epislon as {}\".format(eps))\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()","9e115b72":"So selecting the appropriate kernel is very important. ","f06ad12a":"This is just a basic explainition om SVR (Support Vector Regression) which is a part of SVM (Support Vector Machine), which is mainly used for Classification but algorithm and the approach which is applied for SVM is also helpful in using it as a regression. \n\nThe main feature how SVM works is by keeping a hyperplane and max margin.\n\nLets consider the below as a Classification Problem, the SVM will makes a hyperplane or the main line for the division, classification the area above the line and area below the line.\n\nNow if that line is considered as a hyperplane and the max margin error we see made with the dotten line is the one which classifies the specific range in which it can be included or excluded.\n\nIf we apply the same for Regression purposes than hyperplane changes according to the points present in the same.\n\nIf i have a linear distribution of data it will be plotted with the according to the hyperplane folowed by the margin that it gives with the regressor.\n\nAnd if i have a non-linear plane then hyperplane will change according to that and will have the classification of the data.\n\n![image.png](attachment:image.png)\n","1d3d9dbd":"## Feature Scaling","e784fb59":"# Example 2 : Simulate the actual data\nTo see the example, lets have our own simple data.\n\nFor this I am createing a sample data of positions in companies, and their level, based on that the Salary is derived.\n\nNow our aim is to predict the salary for a person who joined with a level of 8.5.","f206287c":"Lets change the Kernel Value from `rbf` to `linear`","f862074a":"## SVR","fd36dce9":"## Defining Feature and Target","f5b09fb8":"Plot all the Models","3de05946":"## Model Training","d0473b97":"## Linear Regression for Comparasion","e760f5ec":"So with the Linear it not results the expectation.","16542ff0":"## Working with Epislon","54252aa0":"# Example 1 : Randomly generated data"}}