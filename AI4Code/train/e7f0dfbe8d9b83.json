{"cell_type":{"68d9cb0b":"code","420f457c":"code","d5eff234":"code","180308e6":"code","8aa03dec":"code","b52b953f":"code","2b91cb3d":"code","07e5c8e2":"code","f90fd928":"code","5562e781":"code","d2de21df":"code","60dc7e5e":"code","dfaaf7a0":"code","6e6d365c":"code","fe2df173":"code","2cf0b6da":"code","d13de68d":"code","91effc69":"code","38f2c7eb":"code","9d014bbc":"code","b5bd607a":"code","451e2116":"code","9f79327b":"code","c1824df8":"code","1ac2071c":"code","16678dd1":"code","8b4bc4ed":"code","24262ab6":"code","7d69a18b":"code","7c89568a":"code","f31f6332":"code","454dae54":"code","8af90a13":"code","38813398":"code","4f33feb7":"code","6cc7f3b7":"code","a616e2f2":"code","9def1d8e":"code","9dc72bf6":"code","d1aaa00e":"code","1664255b":"code","e57f1c73":"code","aa0a2c3f":"code","6b400f57":"code","5a6724b2":"markdown","3144731b":"markdown","4d93b9de":"markdown","608c1783":"markdown","fb2cc841":"markdown","a3d3e55e":"markdown","9735b719":"markdown","90b70af3":"markdown","28927108":"markdown","15637d9d":"markdown","185a81a9":"markdown","e67bad80":"markdown","8028497a":"markdown","0ccbaef2":"markdown","d7c1852d":"markdown","9efb6c76":"markdown","f60ca474":"markdown","b455a9bd":"markdown","c49089bd":"markdown","29ea7163":"markdown","f15096ce":"markdown","f3ccb5b2":"markdown","bcb6b5b2":"markdown","bff36470":"markdown","4a1a30d4":"markdown","34e61738":"markdown","a7900abd":"markdown","5c9b6903":"markdown","54d8a124":"markdown","1b1042c7":"markdown","f225c88d":"markdown","8790f88b":"markdown","ef064017":"markdown","d158c536":"markdown","783797ae":"markdown","115a7a8c":"markdown","f782d690":"markdown"},"source":{"68d9cb0b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n","420f457c":"!pip install pyspark","d5eff234":"#PySpark Package Import\n\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nimport time\n\nfrom pyspark.sql.functions import monotonically_increasing_id,broadcast","180308e6":"my_spark = SparkSession.builder.getOrCreate()\nmy_spark","8aa03dec":"print('Version',my_spark.version)","b52b953f":"%%time\nflights = my_spark.read.csv('\/kaggle\/input\/flight-delays\/flights.csv',header=True)\nairports = my_spark.read.csv('\/kaggle\/input\/flight-delays\/airports.csv',header=True)\nairlines = my_spark.read.csv('\/kaggle\/input\/flight-delays\/airlines.csv',header=True)\n","2b91cb3d":"flights.printSchema()","07e5c8e2":"type(flights)","f90fd928":"flights.select('DISTANCE').dtypes","5562e781":"flights = flights.withColumn('DISTANCE',flights['DISTANCE'].cast('integer'))\nflights","d2de21df":"flights.show(5)","60dc7e5e":"airports.show(5)","dfaaf7a0":"airlines.show(5)","6e6d365c":"flights = flights.withColumn('duration_hrs',flights.AIR_TIME\/60)\nflights.show(5)","fe2df173":"dist_flights = flights.filter('DISTANCE>1000')\ndist_flights.show(1)","2cf0b6da":"dist_col = dist_flights.select('YEAR','MONTH','FLIGHT_NUMBER','TAIL_NUMBER','ORIGIN_AIRPORT','DESTINATION_AIRPORT','AIR_TIME',\n                               'DISTANCE')\ndist_col.show(5)","d13de68d":"dist_col.filter(dist_col.DESTINATION_AIRPORT=='PBI').show(5)","91effc69":"dist_col.filter(dist_col.ORIGIN_AIRPORT=='JFK').filter(dist_col.DESTINATION_AIRPORT=='PBI').show(5)","38f2c7eb":"dist_col.selectExpr('YEAR','MONTH','FLIGHT_NUMBER','TAIL_NUMBER','ORIGIN_AIRPORT',\n                    'DESTINATION_AIRPORT','AIR_TIME','DISTANCE','DISTANCE\/(AIR_TIME \/60)as Average_Speed').show(5)","9d014bbc":"dist_col.count()","b5bd607a":"dist_col.filter(dist_col.ORIGIN_AIRPORT=='SEA').groupby('ORIGIN_AIRPORT').count().show()","451e2116":"#Converting Column Type using cast\ndist_col=dist_col.withColumn('AIR_TIME',dist_col['AIR_TIME'].cast('integer'))\ndist_col","9f79327b":"#Minimum value\ndist_col.select('ORIGIN_AIRPORT','DISTANCE','AIR_TIME').groupby().min('DISTANCE').show()","c1824df8":"# Maximum Value\n\ndist_col.select('DISTANCE').groupby().max().show()\n\n","1ac2071c":"dist_col.select('DISTANCE').groupby().avg().show()","16678dd1":"dist_col.groupby().sum('DISTANCE').collect()[0][0]","8b4bc4ed":"dist_col.filter(dist_col.ORIGIN_AIRPORT=='SEA').groupby('DESTINATION_AIRPORT').count().show(5)","24262ab6":"month_df = dist_col.groupBy('MONTH','ORIGIN_AIRPORT')\nmonth_df.avg('DISTANCE').show(5)","7d69a18b":"month_df.agg(F.mean('DISTANCE')).show(5)","7c89568a":"flights.rdd.getNumPartitions()","f31f6332":"airports.select(airports['AIRPORT']).distinct().show(5)","454dae54":"airports.filter('length(AIRPORT)<15').show()","8af90a13":"airports.filter(~F.column('AIRPORT').contains('Airport')).show()","38813398":"airports.withColumn('State Name',F.when(airports.STATE=='TX','Texas')).show(5)","4f33feb7":"airports.withColumn('Flag',F.when(airports.STATE=='TX','Texas').when(airports.STATE=='GA','Georgio')\n                    .otherwise('N\/A')).show(5)","6cc7f3b7":"airports.withColumn('ID',monotonically_increasing_id()).show()","a616e2f2":"start_time = time.time()\n\ndest_cache = flights.select('DESTINATION_AIRPORT').cache()\nprint('First Call to cache',dest_cache,time.time()-start_time)\nsecond_time = time.time()\nprint('Second Call to the dataframe',dest_cache,time.time()-second_time)","9def1d8e":"print('Is the dataframe Cached?',dest_cache.is_cached)\ndest_cache.unpersist()\n\nprint('Is the dataframe Cached?',dest_cache.is_cached)","9dc72bf6":"start_time = time.time()\ndf = airports.join(flights,airports['IATA_CODE']==flights['ORIGIN_AIRPORT'])\nprint('Time to Join the dataframe',time.time()-start_time)\n","d1aaa00e":"df.explain()","1664255b":"start_time = time.time()\ndf_broadcast = airports.join(broadcast(flights),airports['IATA_CODE']==flights['ORIGIN_AIRPORT'])\nprint('Time to execute',start_time-time.time())","e57f1c73":"df_broadcast.explain()","aa0a2c3f":"airports.createOrReplaceTempView('Airports_tbl')\n\nmy_spark.sql('Select * from Airports_tbl').show()","6b400f57":"my_spark.sql('select * from airports_tbl where state=\"PA\"').show()","5a6724b2":"### Printing the Schema","3144731b":"### Filtering Columns with PySpark","4d93b9de":"### Create a Temporary Table in PySpark","608c1783":"### Multiple When Statement in PySpark","fb2cc841":"### Install PySpark","a3d3e55e":"### Show top 5 data in the dataframe","9735b719":"### Monotinically Increasing IDs","90b70af3":"### Type","28927108":"### Top 5 data in Airlines","15637d9d":"### .agg in PySpark.SQL.functions","185a81a9":"### PySpark Version","e67bad80":"### Caching in Spark","8028497a":"### Filtering Data in PySpark\nWe will filter data based on Distance>1000","0ccbaef2":"### Count from Particular Origin to Multiple Destination","d7c1852d":"### Column Information","9efb6c76":"### Checking Number of Paritions for the dataframe","f60ca474":"### Converting String to Integer","b455a9bd":"### Select with Filter based on Multiple Column Values\u00b6","c49089bd":"#### Conditional Statement Execution in PySpark DataFrame","29ea7163":"### Filter based on Length of Airport Name\u00b6","f15096ce":"### Joining two Dataframe","f3ccb5b2":"### Select Specific Column Data","bcb6b5b2":"### Top 5 records in Airport","bff36470":"### Aggregating Columns With\n\n- Minimum\n- Maximum\n- Average\n- Sum","4a1a30d4":"### Reference: \n\nThey have more explanation in the content and information.\n    \n[BigData With PySpark](https:\/\/learn.datacamp.com\/skill-tracks\/big-data-with-pyspark)\n\nStay tuned for more...\n\n    \n            \n            \n","34e61738":"### Creating a new Column","a7900abd":"### Explain Plan on the dataframe","5c9b6903":"### Filter so that AIRPORT name should not contain Airport in its name","54d8a124":"### Groupby on multiple Columns","1b1042c7":"### Clearing the Cache","f225c88d":"### PySpark Package Import","8790f88b":"### Importing Files","ef064017":"### Count on the Entire dataset","d158c536":"### Select Column With Expression","783797ae":"### Select with Filter based on Column Values","115a7a8c":"### Groupby Columns and doing a Count","f782d690":"### Another way to use the aggregation on Column"}}