{"cell_type":{"b63473bf":"code","d4429291":"code","a2f15faa":"code","09bd7378":"code","fa60aa20":"code","b55c8cf3":"code","59644cb2":"code","90f17045":"code","52d62564":"code","ca887f86":"code","bbda08c2":"code","2080c73a":"code","2e58a309":"code","d2a39444":"code","536f8d2f":"code","fbae2d1c":"code","d60a144f":"code","0d8df48d":"code","45e79266":"markdown","0a140798":"markdown","d33d851f":"markdown","7f48174d":"markdown","26a4e4f0":"markdown","0f11a14d":"markdown","43b4310c":"markdown","600a042a":"markdown","b321c0da":"markdown"},"source":{"b63473bf":"import matplotlib.pyplot as plt\nimport numpy as np\nimport time\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.optim as optim","d4429291":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size=32\nepochs=10\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","a2f15faa":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","09bd7378":"# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))","fa60aa20":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(16, 32, 3)\n\n        self.fc1 = nn.Linear(32 * 6 * 6, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        #print(x.shape)\n        x = self.pool(F.relu(self.conv2(x)))\n        #print(x.shape)\n        x = x.view(-1, 32 * 6 * 6)\n        #print(x.shape)\n        x = F.relu(self.fc1(x))\n        #print(x.shape)\n        x = F.relu(self.fc2(x))\n        #print(x.shape)\n        x = self.fc3(x)\n        #print(x.shape)\n        #quebra\n        return x","b55c8cf3":"net = Net()\nnet","59644cb2":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\noptimizer = optim.AdamW(net.parameters(), lr=0.01)","90f17045":"def train(net, criterion, optimizer):\n    since = time.time()\n\n    for epoch in range(epochs):  # loop over the dataset multiple times\n\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            if i % 100 == 99:    # print every 2000 mini-batches\n                print('[%d, %5d] loss: %.3f - time: %.2f' % (epoch + 1, i + 1, running_loss \/ 2000, time.time() - since))\n                running_loss = 0.0\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n\ntrain(net, criterion, optimizer)","52d62564":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))","ca887f86":"outputs = net(images)\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size)))","bbda08c2":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct \/ total))","2080c73a":"def eval_net(net):\n    class_correct = list(0. for i in range(10))\n    class_total = list(0. for i in range(10))\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            outputs = net(images)\n            _, predicted = torch.max(outputs, 1)\n            c = (predicted == labels).squeeze()\n            for i in range(4):\n                label = labels[i]\n                class_correct[label] += c[i].item()\n                class_total[label] += 1\n\n    for i in range(10):\n        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] \/ class_total[i]))\n        \neval_net(net)","2e58a309":"net = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","d2a39444":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","536f8d2f":"def train_gpu(net, criterion, optimizer):\n    since = time.time()\n\n    ###\n    net.to(device)\n\n    for epoch in range(epochs):  # loop over the dataset multiple times\n\n        running_loss = 0.0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            ### inputs, labels = data\n            inputs, labels = data[0].to(device), data[1].to(device)\n\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            if i % 100 == 99:    # print every 2000 mini-batches\n                print('[%d, %5d] loss: %.3f - time: %.2f' % (epoch + 1, i + 1, running_loss \/ 2000, time.time() - since))\n                running_loss = 0.0\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n\ntrain_gpu(net, criterion, optimizer)","fbae2d1c":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data[0].to(device), data[1].to(device)\n\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct \/ total))","d60a144f":"def eval_net_gpu(net):\n    class_correct = list(0. for i in range(10))\n    class_total = list(0. for i in range(10))\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data[0].to(device), data[1].to(device)\n\n            outputs = net(images)\n            _, predicted = torch.max(outputs, 1)\n            c = (predicted == labels).squeeze()\n            for i in range(4):\n                label = labels[i]\n                class_correct[label] += c[i].item()\n                class_total[label] += 1\n\n    for i in range(10):\n        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] \/ class_total[i]))\n        \neval_net_gpu(net)","0d8df48d":"# referencias\n# https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py","45e79266":"# 1. Preparando os Dados","0a140798":"# 3. Definindo uma Fun\u00e7\u00e3o de Custo e um Otimizador","d33d851f":"## 5.1 Qual foi a Performance nos dados de Teste?","7f48174d":"# 4. Treinando a Rede","26a4e4f0":"## 5.2 Qual foi a Performance em Cada Classe?","0f11a14d":"Os passos s\u00e3o:\n* Carregar e normalizar os datasets de treinamento e teste do CIFAR usando o torchvision\n* Definir uma Rede Convolucional\n* Definir uma fun\u00e7\u00e3o de custo (loss)\n* Testar a rede em dados de teste","43b4310c":"# 5. Testando a Rede nos Dados de Teste","600a042a":"# B\u00f4nus: E treinar na GPU faz diferen\u00e7a?","b321c0da":"# 2. Definindo uma Rede Convolucional"}}