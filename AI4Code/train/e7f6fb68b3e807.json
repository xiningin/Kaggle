{"cell_type":{"f3d776ec":"code","4305d564":"code","383e1e6b":"code","e0ef365b":"code","095fb9ab":"code","5234a59c":"code","7ba04f03":"code","9054f2d7":"code","a98165be":"code","2fb3292b":"code","0a39b3be":"code","fb64ab2b":"code","5757d531":"code","aae30732":"code","7b475914":"code","90ca4be4":"code","b27fdcb4":"code","396d1184":"code","d888da1a":"code","0432b425":"code","c572a167":"code","bade2f8a":"code","e845578e":"code","1ad7fd53":"code","ad59a162":"code","24c17a33":"code","b40998ce":"code","6936bf27":"code","30886f12":"code","0293f2bf":"code","072da88c":"code","4ac3e77a":"code","982839a0":"code","66b90b08":"code","0c6aad84":"code","d2c877e5":"code","892f74bd":"markdown","8e6033c1":"markdown"},"source":{"f3d776ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4305d564":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","383e1e6b":"train = pd.read_csv(\"..\/input\/cat-in-the-dat\/train.csv\")\n#train.head(5)\n#train.tail(5)","e0ef365b":"#sns.countplot(train[\"nom_0\"])\n#sns.countplot(train[\"nom_1\"]) -scaling\n#sns.countplot(train[\"nom_2\"]) -scaling\n#sns.countplot(train[\"nom_3\"])\n#sns.countplot(train[\"nom_4\"]) -scaling\n#sns.countplot(train[\"nom_5\"]) -drop\n#sns.countplot(train[\"nom_6\"]) -drop\n#sns.countplot(x = \"nom_7\", data = train) -drop\n#sns.countplot(train[\"nom_8\"]) -drop\n#sns.countplot(train[\"ord_0\"])\n#sns.countplot(train[\"ord_1\"]) -scaling\n#sns.countplot(train[\"ord_2\"]) -scaling\n#sns.countplot(train[\"ord_3\"]) -scaling\n#sns.countplot(train[\"ord_4\"]) -scaling\n#sns.countplot(train[\"ord_5\"]) -drop\n#sns.countplot(train[\"month\"])","095fb9ab":"#train = train.drop([\"ord_5\",\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\"], axis = 1)","5234a59c":"train.tail(5)","7ba04f03":"train.drop(\"id\", axis = 1, inplace = True)","9054f2d7":"train.head(5)","a98165be":"from sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n#bin_3\nl_enc = LabelEncoder()\nX = train[\"bin_3\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"bin_3\":X})\ntrain.drop(\"bin_3\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","2fb3292b":"#bin_4\nX = train[\"bin_4\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"bin_4\":X})\ntrain.drop(\"bin_4\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","0a39b3be":"#nom_0\nscaler = StandardScaler()\nX = train[\"nom_0\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_0\":X})\ntrain.drop(\"nom_0\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","fb64ab2b":"#nom_1\nscaler = StandardScaler()\nX = train[\"nom_1\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_1\":X})\ntrain.drop(\"nom_1\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","5757d531":"#nom_2\nscaler = StandardScaler()\nX = train[\"nom_2\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_2\":X})\ntrain.drop(\"nom_2\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","aae30732":"#nom_3\nscaler = StandardScaler()\nX = train[\"nom_3\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_3\":X})\ntrain.drop(\"nom_3\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","7b475914":"#nom_4\nscaler = StandardScaler()\nX = train[\"nom_4\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_4\":X})\ntrain.drop(\"nom_4\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","90ca4be4":"#nom_5\nscaler = StandardScaler()\nX = train[\"nom_5\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_5\":X})\ntrain.drop(\"nom_5\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","b27fdcb4":"#nom_6\nscaler = StandardScaler()\nX = train[\"nom_6\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_6\":X})\ntrain.drop(\"nom_6\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","396d1184":"#nom_7\nscaler = StandardScaler()\nX = train[\"nom_7\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_7\":X})\ntrain.drop(\"nom_7\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","d888da1a":"#nom_8\nscaler = StandardScaler()\nX = train[\"nom_8\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_8\":X})\ntrain.drop(\"nom_8\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","0432b425":"#nom_9\nscaler = StandardScaler()\nX = train[\"nom_9\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_9\":X})\ntrain.drop(\"nom_9\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","c572a167":"#ord_1\nscaler = StandardScaler()\nX = train[\"ord_1\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_1\":X})\ntrain.drop(\"ord_1\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","bade2f8a":"#ord_2\nscaler = StandardScaler()\nX = train[\"ord_2\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_2\":X})\ntrain.drop(\"ord_2\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","e845578e":"#ord_3\nscaler = StandardScaler()\nX = train[\"ord_3\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_3\":X})\ntrain.drop(\"ord_3\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","1ad7fd53":"#ord_4\nscaler = StandardScaler()\nX = train[\"ord_4\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_4\":X})\ntrain.drop(\"ord_4\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","ad59a162":"#ord_5\nscaler = StandardScaler()\nX = train[\"ord_5\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_5\":X})\ntrain.drop(\"ord_5\", axis = 1, inplace = True)\ntrain = pd.concat([train,X_df], axis = 1)\ntrain.head(5)","24c17a33":"X_t = train.drop(\"target\", axis = 1).values\nX_t = scaler.fit_transform(X_t)\n#print(X_t)\nY_t = train[\"target\"].values\n#print(Y_t)","b40998ce":"from xgboost import XGBClassifier\n\nrs = 2\nX_train, X_dev, Y_train, Y_dev = train_test_split(X_t,Y_t, test_size = 0.2, random_state = rs)","6936bf27":"classifier = XGBClassifier(learning_rate=0.05,n_estimators=50000,seed=2019,reg_alpha=5,eval_metric='auc',tree_method='gpu_hist')\nclassifier.fit(X_train, Y_train, eval_set=[(X_train, Y_train), (X_dev, Y_dev)],early_stopping_rounds=50, verbose=50)","30886f12":"results = classifier.evals_result()\nepochs = len(results['validation_0']['auc'])\nx_axis = range(0, epochs)\n\n# plotting the loss\nplt.figure(figsize=(15, 7))\nplt.plot(x_axis, results['validation_0']['auc'], label='Train')\nplt.plot(x_axis, results['validation_1']['auc'], label='Val')\nplt.legend()\nplt.ylabel('AUC')\nplt.xlabel('# of iterations')\nplt.title('XGBoost AUC')\nplt.show()","0293f2bf":"Y_hat = classifier.predict(X_dev)\nprint(accuracy_score(Y_dev, Y_hat))","072da88c":"test_orig = pd.read_csv(\"..\/input\/cat-in-the-dat\/test.csv\")","4ac3e77a":"test = test_orig.copy()\ntest.drop(\"id\", axis = 1, inplace = True)\n\n#bin_3\nl_enc = LabelEncoder()\nX = test[\"bin_3\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"bin_3\":X})\ntest.drop(\"bin_3\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#bin_4\nl_enc = LabelEncoder()\nX = test[\"bin_4\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"bin_4\":X})\ntest.drop(\"bin_4\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_0\nscaler = StandardScaler()\nX = test[\"nom_0\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_0\":X})\ntest.drop(\"nom_0\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_1\nscaler = StandardScaler()\nX = test[\"nom_1\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_1\":X})\ntest.drop(\"nom_1\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_2\nscaler = StandardScaler()\nX = test[\"nom_2\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_2\":X})\ntest.drop(\"nom_2\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_3\nscaler = StandardScaler()\nX = test[\"nom_3\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_3\":X})\ntest.drop(\"nom_3\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_4\nscaler = StandardScaler()\nX = test[\"nom_4\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_4\":X})\ntest.drop(\"nom_4\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_5\nscaler = StandardScaler()\nX = test[\"nom_5\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_5\":X})\ntest.drop(\"nom_5\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_6\nscaler = StandardScaler()\nX = test[\"nom_6\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_6\":X})\ntest.drop(\"nom_6\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_7\nscaler = StandardScaler()\nX = test[\"nom_7\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_7\":X})\ntest.drop(\"nom_7\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_8\nscaler = StandardScaler()\nX = test[\"nom_8\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_8\":X})\ntest.drop(\"nom_8\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#nom_9\nscaler = StandardScaler()\nX = test[\"nom_9\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"nom_9\":X})\ntest.drop(\"nom_9\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#ord_1\nscaler = StandardScaler()\nX = test[\"ord_1\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_1\":X})\ntest.drop(\"ord_1\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#ord_2\nscaler = StandardScaler()\nX = test[\"ord_2\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_2\":X})\ntest.drop(\"ord_2\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#ord_3\nscaler = StandardScaler()\nX = test[\"ord_3\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_3\":X})\ntest.drop(\"ord_3\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#ord_4\nscaler = StandardScaler()\nX = test[\"ord_4\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_4\":X})\ntest.drop(\"ord_4\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\n#test.head(5)\n\n#ord_5\nscaler = StandardScaler()\nX = test[\"ord_5\"].values\nX = l_enc.fit_transform(X)\nX_df = pd.DataFrame(data = {\"ord_5\":X})\ntest.drop(\"ord_5\", axis = 1, inplace = True)\ntest = pd.concat([test,X_df], axis = 1)\ntest.head(5)","982839a0":"X_test = test.values\n#print(X_test)\nX_test = scaler.fit_transform(X_test)\n#print(X_test)","66b90b08":"Y_test = classifier.predict_proba(X_test, ntree_limit=classifier.best_ntree_limit)[:, 1]\nprint(Y_test)","0c6aad84":"Y_df = pd.DataFrame(data = {'target':Y_test})\nsub = pd.read_csv(\"..\/input\/cat-in-the-dat\/sample_submission.csv\")\nsub.drop(\"target\", axis = 1, inplace = True)\ntest_final = pd.concat([sub, Y_df], axis = 1)\ntest_final.head(5)","d2c877e5":"test_final.to_csv(\"submission.csv\", index = False)","892f74bd":"> **Creating a dataframe and saving the output in a csv file**","8e6033c1":"> **Importing the dataset and exploring it**"}}