{"cell_type":{"2e83a9f7":"code","72333a51":"code","be350942":"code","dafff990":"code","bc9ca597":"code","568e4649":"code","684cec02":"code","af28c124":"code","a2a14a3b":"code","fc6a37e7":"code","819ebef2":"code","ddce86bd":"code","f67a36b7":"code","3371eb35":"code","c55d48e1":"code","ee8c069f":"code","ea049262":"code","2e2844df":"code","944bbc6c":"code","e52aab99":"code","71ecbcdc":"code","69c6c048":"code","62b8b042":"code","ee9894e4":"code","51de2f54":"code","eb71be55":"code","f8c35a17":"code","4020b1c4":"code","4d535868":"code","49b92e23":"code","67cb98e8":"code","dc23e528":"code","4fe1cfc8":"code","1c53a865":"code","fcb0664b":"code","87ae8b55":"code","7e226cf8":"code","4fc3ad4a":"code","e5e54fc3":"code","361343bf":"code","3cea09ec":"code","bef755a6":"code","12e5c728":"code","20c1bb6a":"code","20edeb93":"code","53456869":"code","dc0aacfa":"code","2c060550":"markdown","51813131":"markdown","6e5ee1cb":"markdown","3911e1ec":"markdown","c8d2df17":"markdown","9344530c":"markdown","4d76f9ac":"markdown","4ac4b1e6":"markdown","276a8bc8":"markdown","8dfb7793":"markdown","63558d1b":"markdown","a97be846":"markdown","8a1a1671":"markdown","bcc9301e":"markdown","80b1870c":"markdown"},"source":{"2e83a9f7":"import gc, os, logging, datetime, warnings, pickle, optuna\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import preprocessing\nwarnings.filterwarnings('ignore')","72333a51":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","be350942":"os.listdir('..\/input\/ieee-fraud-detection')","dafff990":"train_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv')\ntrain_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv')\ntest_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv')","bc9ca597":"print(\"train_transaction shape : \", train_transaction.shape)\nprint(\"train_identity shape : \", train_identity.shape)\nprint(\"test_transaction shape : \", test_transaction.shape)\nprint(\"test_identity shape : \", test_identity.shape)","568e4649":"df_train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ndf_test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","684cec02":"for df in [train_transaction, train_identity, test_transaction, test_identity]:\n    del df","af28c124":"drop_col = ['V300','V309','V111','V124','V106','V125','V315','V134','V102','V123','V316','V113',\n            'V136','V305','V110','V299','V289','V286','V318','V103','V304','V116','V29','V284','V293',\n            'V137','V295','V301','V104','V311','V115','V109','V119','V321','V114','V133','V122','V319',\n            'V105','V112','V118','V117','V121','V108','V135','V320','V303','V297','V120',\n            'V1','V14','V41','V65','V88','V107']\nfor df in [df_train, df_test]:\n    df = df.drop(drop_col, axis=1)","a2a14a3b":"print(\"df_train shape :\", df_train.shape)\nprint(\"df_test shape :\", df_test.shape)","fc6a37e7":"from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\ndates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\nus_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())","819ebef2":"def make_time_feature(df):\n    START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')\n    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n    df['DT_M'] = ((df['DT'].dt.year-2017)*12 + df['DT'].dt.month).astype(np.int8)\n    df['DT_W'] = ((df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear).astype(np.int8)\n    df['DT_D'] = ((df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear).astype(np.int16)\n    df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n    df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n    df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n    df['is_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n    return df","ddce86bd":"for df in [df_train, df_test]:\n    df = make_time_feature(df=df)","f67a36b7":"df_deviceinfo = pd.read_csv('..\/input\/ieee-deviceinfo\/DeviceInfo.csv')","3371eb35":"df_train = pd.merge(df_train, df_deviceinfo, on='DeviceInfo', how='left')\ndf_test = pd.merge(df_test, df_deviceinfo, on='DeviceInfo', how='left')","c55d48e1":"del df_deviceinfo","ee8c069f":"for df in [df_train, df_test]:\n    df['OS'] = df['id_30'].apply(lambda x: str(x).split(' ')[0])\n    df['OS_version'] = df['id_30'].apply(lambda x: str(x).split(' ')[-1])\n    df['OS_version'] = df['OS_version'].apply(lambda x: str(x).replace('_', '').replace('.', ''))\n    df['OS_version'] = df['OS_version'].apply(lambda x: int(x) if x.isdigit() else np.nan)","ea049262":"browser_release_date = {'android browser 4.0' : '2011-10-18',\n                        'android webview 4.0' : '2011-10-18',\n                        'chrome 43.0 for android' : '2015-04-15',\n                        'chrome 46.0 for android' : '2015-10-14',\n                        'chrome 49.0' : '2016-03-02',\n                        'chrome 49.0 for android' : '2016-03-09',\n                        'chrome 50.0 for android' : '2016-04-26',\n                        'chrome 51.0' : '2016-05-25',\n                        'chrome 51.0 for android' : '2016-06-01',\n                        'chrome 52.0 for android' : '2016-07-27',\n                        'chrome 53.0 for android' : '2016-09-07',\n                        'chrome 54.0 for android' : '2016-10-19',\n                        'chrome 55.0' : '2016-12-01',\n                        'chrome 55.0 for android' : '2016-12-06',\n                        'chrome 56.0' : '2017-01-25',\n                        'chrome 56.0 for android' : '2017-02-01',\n                        'chrome 57.0' : '2017-03-09',\n                        'chrome 57.0 for android' : '2017-03-16',\n                        'chrome 58.0' : '2017-04-19',\n                        'chrome 58.0 for android' : '2017-04-20',\n                        'chrome 59.0' : '2017-06-05',\n                        'chrome 59.0 for android' : '2017-06-06',\n                        'chrome 60.0' : '2017-07-25',\n                        'chrome 60.0 for android' : '2017-07-31',\n                        'chrome 61.0' : '2017-09-05',\n                        'chrome 61.0 for android' : '2017-09-05',\n                        'chrome 62.0' : '2017-10-17',\n                        'chrome 62.0 for android' : '2017-10-19',\n                        'chrome 62.0 for ios' : '2017-10-18',\n                        'chrome 63.0' : '2017-12-06',\n                        'chrome 63.0 for android' : '2017-12-05',\n                        'chrome 63.0 for ios' : '2017-12-05',\n                        'chrome 64.0' : '2018-01-24',\n                        'chrome 64.0 for android' : '2018-01-23',\n                        'chrome 64.0 for ios' : '2018-01-24',\n                        'chrome 65.0' : '2018-03-06',\n                        'chrome 65.0 for android' : '2018-03-06',\n                        'chrome 65.0 for ios' : '2018-03-06',\n                        'chrome 66.0' : '2018-04-17',\n                        'chrome 66.0 for android' : '2018-04-17',\n                        'chrome 66.0 for ios' : '2018-04-17',\n                        'chrome 67.0' : '2018-05-29',\n                        'chrome 67.0 for android' : '2018-05-31',\n                        'chrome 69.0' : '2018-09-04',\n                        'edge 13.0' : '2015-09-15',\n                        'edge 14.0' : '2016-02-18',\n                        'edge 15.0' : '2016-10-07',\n                        'edge 16.0' : '2017-09-26',\n                        'edge 17.0' : '2018-04-30',\n                        'firefox 47.0' : '2016-06-07',\n                        'firefox 48.0' : '2016-08-02',\n                        'firefox 52.0' : '2017-03-07',\n                        'firefox 55.0' : '2017-08-08',\n                        'firefox 56.0' : '2017-09-28',\n                        'firefox 57.0' : '2017-11-14',\n                        'firefox 58.0' : '2018-01-23',\n                        'firefox 59.0' : '2018-03-13',\n                        'firefox 60.0' : '2018-05-09',\n                        'firefox mobile 61.0' : '2018-06-26',\n                        'google search application 48.0' : '2016-01-20',\n                        'google search application 49.0' : '2016-03-02',\n                        'ie 11.0 for desktop' : '2013-10-17',\n                        'ie 11.0 for tablet' : '2013-10-17',\n                        'mobile safari 10.0' : '2016-09-14',\n                        'mobile safari 11.0' : '2017-09-20',\n                        'mobile safari 8.0' : '2014-09-17',\n                        'mobile safari 9.0' : '2015-09-16',\n                        'opera 49.0' : '2017-11-08',\n                        'opera 51.0' : '2018-02-07',\n                        'opera 52.0' : '2018-03-14',\n                        'opera 53.0' : '2018-05-10',\n                        'safari 10.0' : '2016-09-20',\n                        'safari 11.0' : '2017-09-19',\n                        'safari 9.0' : '2015-09-30',\n                        'samsung browser 3.3' : '2015-08-01',\n                        'samsung browser 4.0' : '2016-03-11',\n                        'samsung browser 4.2' : '2016-08-19',\n                        'samsung browser 5.2' : '2016-11-01',\n                        'samsung browser 5.4' : '2017-05-01',\n                        'samsung browser 6.2' : '2017-08-01',\n                        'samsung browser 6.4' : '2018-02-19',\n                        'samsung browser 7.0' : '2018-03-01',\n                       }","2e2844df":"def time_split(val):\n    try:\n        return datetime.datetime.strptime(str(x), '%Y-%m-%d')\n    except:\n        return pd.NaT","944bbc6c":"for df in [df_train, df_test]:\n    df['browser_elapsed_time'] = df['id_31'].map(browser_release_date)\n    df['browser_elapsed_time'].apply(lambda x: time_split(x))\n    df['browser_elapsed_time'] = df['DT'] - df['browser_elapsed_time'].astype('datetime64[D]')\n    df['browser_elapsed_time'] = df['browser_elapsed_time'].dt.days\n    del df['DT']","e52aab99":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\nus_emails = ['gmail', 'net', 'edu']","71ecbcdc":"def make_email_feature(df):\n    for c in ['P_emaildomain', 'R_emaildomain']:\n        df[c + '_bin'] = df[c].map(emails)\n        df[c + '_suffix'] = df[c].map(lambda x: str(x).split('.')[-1])\n        df[c + '_suffix'] = df[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","69c6c048":"for df in [df_train, df_test]:\n    df = make_email_feature(df=df)","62b8b042":"def siev_card_feature(df_train, df_test, col):\n    valid_card = pd.concat([df_train[[col]], df_test[[col]]])\n    valid_card = valid_card[col].value_counts()\n    valid_card_std = valid_card.values.std()\n    invalid_cards = valid_card[valid_card < 2]\n    print('{0}{1}\\nNumber of Rare card : '.format(col, '*'*10), len(invalid_cards))\n    \n    valid_card = valid_card[valid_card >= 2]\n    valid_card = list(valid_card.index)\n    print('Number of not intersection in Train : ', len(df_train[~df_train[col].isin(df_test[col])]))\n    print('Nmber of intersection in Train : ', len(df_train[df_train[col].isin(df_test[col])]))\n    \n    df_train[col] = np.where(df_train[col].isin(df_test[col]), df_train[col], np.nan)\n    df_test[col]  = np.where(df_test[col].isin(df_train[col]), df_test[col], np.nan)\n\n    df_train[col] = np.where(df_train[col].isin(valid_card), df_train[col], np.nan)\n    df_test[col]  = np.where(df_test[col].isin(valid_card), df_test[col], np.nan)","ee9894e4":"for col in ['card1','card2','card3','card4','card5','card6']:\n    siev_card_feature(df_train, df_test, col)","51de2f54":"def make_composite_id(new_id, id1, id2):\n    df_train[new_id] = df_train[id1].astype(str)+'_' + df_train[id2].astype(str)\n    df_test[new_id] = df_test[id1].astype(str)+'_' + df_test[id2].astype(str)","eb71be55":"make_composite_id('uid1', 'card1', 'card2') #card1 + card2 -> uid1\nmake_composite_id('uid2', 'uid1', 'card3')\nmake_composite_id('uid2', 'uid2', 'card5') #card1 + card3 +card5 -> uid2\nmake_composite_id('uid3', 'uid2', 'addr1')\nmake_composite_id('uid3', 'uid3', 'addr2') #card2 + addr1 + addr2 -> uid3\nmake_composite_id('uid4', 'uid3', 'P_emaildomain') #uid3 + P_emaildomain -> uid4\nmake_composite_id('uid5', 'uid3', 'R_emaildomain') #uid3 + R_emaildomain -> uid5\nmake_composite_id('bank_type', 'card3', 'card5') #card3 + card5 -> bank_type","f8c35a17":"gc.collect()","4020b1c4":"for df in [df_train, df_test]:\n    df = reduce_mem_usage(df=df)","4d535868":"def create_new_columns(key, aggs):\n    return [key + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]","49b92e23":"aggs = {}\nfor col in ['DT_D','DT_W','DT_M']:\n    aggs[col] = ['nunique', 'mean', 'median', 'var', 'skew']\naggs","67cb98e8":"df_temp = pd.concat([df_train, df_test])\nfor key in tqdm_notebook(['card3', 'card5', 'bank_type']):\n    new_columns = create_new_columns(key, aggs)\n    df_grouped = df_temp.groupby(key).agg(aggs)\n    df_grouped.columns = new_columns\n    df_grouped.reset_index(drop=False,inplace=True)\n    df_train = df_train.merge(df_grouped,on=key,how='left')\n    df_test = df_test.merge(df_grouped,on=key,how='left')","dc23e528":"aggs = {}\nfor col in ['TransactionAmt', 'D15']:\n    aggs[col] = ['nunique', 'mean', 'median', 'var', 'skew', 'min', 'max']\naggs","4fe1cfc8":"for key in tqdm_notebook(['card1','card2','card3','card5','uid1','uid2','uid3','uid4','uid5','bank_type']):\n    new_columns = create_new_columns(key, aggs)\n    df_grouped = df_temp.groupby(key).agg(aggs)\n    df_grouped.columns = new_columns\n    df_grouped.reset_index(drop=False,inplace=True)\n    df_train = df_train.merge(df_grouped,on=key,how='left')\n    df_test = df_test.merge(df_grouped,on=key,how='left')","1c53a865":"aggs = {}\nfor col in ['TransactionAmt', 'D15']:\n    aggs[col] = ['mean', 'median', 'min', 'max']\n    \nfor key in tqdm_notebook(['card1','card2','card3','card5','uid1','uid2','uid3','uid4','uid5','bank_type']):\n    columns = create_new_columns(key, aggs)\n    for i in columns:\n        diff_column = 'diff_' + i\n        ratio_column = 'ratio_' + i\n        df_train[diff_column] = df_train['TransactionAmt'] - df_train[i]\n        df_test[diff_column] = df_test['TransactionAmt'] - df_test[i]\n        df_train[ratio_column] = df_train['TransactionAmt'] \/ df_train[i]\n        df_test[ratio_column] = df_test['TransactionAmt'] \/ df_test[i]","fcb0664b":"del df_temp\ndel df_grouped\ngc.collect()","87ae8b55":"df_train['nulls1'] = df_train.isna().sum(axis=1)\ndf_test['nulls1'] = df_test.isna().sum(axis=1)","7e226cf8":"categorical_features = list()\nfor i in df_train.columns:\n    if(df_train[i].dtype == object):\n        categorical_features.append(i)\nprint(categorical_features)","4fc3ad4a":"def label_encoding(df_train, df_test, feature):\n    le = preprocessing.LabelEncoder()\n    le.fit(list(df_train[feature].astype(str).values) + list(df_test[feature].astype(str).values))\n    df_train[feature] = le.transform(list(df_train[feature].astype(str).values))\n    df_test[feature] = le.transform(list(df_test[feature].astype(str).values))","e5e54fc3":"for feature in tqdm_notebook(categorical_features):\n    label_encoding(df_train, df_test, feature)","361343bf":"def frequency_encoding(df_train, df_test, feature, self_encoding=False):\n    df_temp = pd.concat([df_train[[feature]], df_test[[feature]]])\n    fq_encode = df_temp[feature].value_counts(dropna=False).to_dict()\n    if self_encoding:\n        df_train[feature] = df_train[feature].map(fq_encode)\n        df_test[feature] = df_test[feature].map(fq_encode)            \n    else:\n        df_train[feature+'_fq_enc'] = df_train[feature].map(fq_encode)\n        df_test[feature+'_fq_enc'] = df_test[feature].map(fq_encode)","3cea09ec":"for feature in tqdm_notebook(categorical_features):\n    frequency_encoding(df_train, df_test, feature, self_encoding=False)","bef755a6":"for feature in tqdm_notebook(['DT_M','DT_W','DT_D']):\n    frequency_encoding(df_train, df_test, feature, self_encoding=False)","12e5c728":"for feature in tqdm_notebook(['card1','card2','card3','card5','uid1','uid2','uid3','uid4','uid5']):\n    frequency_encoding(df_train, df_test, feature, self_encoding=False)","20c1bb6a":"for feature in tqdm_notebook(['general_vendor','general_platform','general_type']):\n    frequency_encoding(df_train, df_test, feature, self_encoding=False)","20edeb93":"for df in [df_train, df_test]:\n    df = reduce_mem_usage(df=df)","53456869":"gc.collect()","dc0aacfa":"df_train.to_pickle('df_train.pkl')\ndf_test.to_pickle('df_test.pkl')","2c060550":"## Label Encoding","51813131":"## Latest Browser\nCalculate how many days passed from when the used browser had been released.  \n(I couldn't get correct information of release dates of samsung browsers.)","6e5ee1cb":"# Output train & test data after feature engineering","3911e1ec":"## Interpretation of 'P_emaildomain' and 'R_emaildomain'\nBased on public notebook.","c8d2df17":"## null count","9344530c":"# Feature Engineering","4d76f9ac":"# This notebook only contains FE part.","4ac4b1e6":"## Interpretation of 'DeviceInfo'\nAdd information of vendor, os, device type (such as mobile, tablet, or pc) of devices.  \nI manually searhed that information and gather to csv file.","276a8bc8":"## Client Virtual ID","8dfb7793":"## OS Information\nBreak 'id_30' to information of OS and OS version.","63558d1b":"## Card Information","a97be846":"## Aggregation","8a1a1671":"## Reduce Memory","bcc9301e":"## Interpretation of 'TransactionDT'","80b1870c":"## Frequency Encoding"}}