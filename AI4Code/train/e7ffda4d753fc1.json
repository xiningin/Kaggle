{"cell_type":{"10e956bb":"code","bde2281a":"code","df320cdf":"code","0c74c9c8":"code","fd9da0b2":"code","718aa741":"code","ae6a7133":"code","8995e13f":"code","bb2ed897":"code","b65b098d":"code","1f6b94a8":"code","93cece35":"code","fdf7894d":"code","9490f440":"code","560b5b64":"code","465ff8a5":"markdown","c483f9e9":"markdown","971d500b":"markdown","7af4e1cc":"markdown","4ec58c25":"markdown","1edb2174":"markdown","33f62a73":"markdown","29c5b324":"markdown","88578314":"markdown","8c56bb75":"markdown"},"source":{"10e956bb":"import gc\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# \uad50\ucc28\uac80\uc99d lib\nfrom sklearn.model_selection import StratifiedKFold,train_test_split\nfrom tqdm import tqdm_notebook\n\n#\ubaa8\ub378 lib\nfrom keras.datasets import mnist\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, AveragePooling2D\nfrom keras import layers\nfrom keras.optimizers import Adam,RMSprop\n\n#\ubaa8\ub378\nfrom keras.applications import VGG16, VGG19, resnet50\n\n#\uacbd\uace0\uba54\uc138\uc9c0 \ubb34\uc2dc\nimport warnings\nwarnings.filterwarnings(action='ignore')","bde2281a":"import os\nos.listdir('..\/input\/digit-recognizer')\ndatapath = '..\/input\/digit-recognizer'","df320cdf":"train =pd.read_csv(datapath+'\/train.csv')\nprint(train.shape)\ntrain.head()","0c74c9c8":"test =pd.read_csv(datapath+'\/test.csv')\nprint(test.shape)\ntest.head()","fd9da0b2":"train_labels = train['label']\ntrain = (train.iloc[:,1:].values).astype('float32')\ntest = test.values.astype('float32')","718aa741":"#Visualizing the data\nsample = train[10, :].reshape(28,28)\nplt.imshow(sample, cmap='gray')\nplt.show()\nprint('label : ', train_labels[10])","ae6a7133":"train = train.reshape(42000, 28, 28, 1)\ntest= test.reshape(28000, 28, 28, 1)\n# change shape using pad\ntrain = np.pad(train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\ntest = np.pad(test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n\nprint('train shape : ', train.shape)\nprint('test shape : ', test.shape)","8995e13f":"# int64 -> float32 ,  scaling\ntrain = train.astype('float32')\/255\ntest = test.astype('float32')\/255\nX_train, X_val, y_train, y_val = train_test_split(train, train_labels, test_size=0.20, random_state=42)\n\n#One-hot encoding the labels\nprint('X_train shape : ', X_train.shape)\nprint('X_val shape : ', X_val.shape)\nprint('y_train : ', y_train.shape)\nprint('y_val : ', y_val.shape)\ny_train = to_categorical(y_train)\ny_val = to_categorical(y_val)\nprint('y_train_to_categorical : ', y_train.shape)\nprint('y_val_to_categorical : ', y_val.shape)","bb2ed897":"#lenet-5 model\nmodel = Sequential()\n#Conv layer 1\nmodel.add(layers.Conv2D(filters=6, kernel_size=(5, 5),strides=1, activation='relu', input_shape=(32,32,1)))\n#Pooling layer 1\nmodel.add(AveragePooling2D(pool_size = 2, strides = 2))\n#Conv Layer2\nmodel.add(layers.Conv2D(filters=16, kernel_size=(5, 5),strides=1, activation='relu'))\n#Pooling layer 2\nmodel.add(AveragePooling2D(pool_size = 2, strides = 2))\nmodel.add(layers.Flatten())\n#FC Layer 3\nmodel.add(layers.Dense(120, activation='relu'))\n#FC Layer 4\nmodel.add(layers.Dense(84, activation='relu'))\n#FC Layer 5\nmodel.add(layers.Dense(10, activation = 'softmax'))\n\n\n# compile\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()","b65b098d":"datagen = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.10,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)","1f6b94a8":"patient = 4\ncallbacks_list = [\n    ReduceLROnPlateau(\n        monitor = 'val_loss', \n        #Reduces learning rate to half\n        factor = 0.5, \n        #\uc704\uc640 \ub3d9\uc77c\n        patience = patient \/ 2, \n        #min Reduces learning\n        min_lr=0.00001,\n        verbose=1,\n        mode='min'\n    )]","93cece35":"%%time\nepochs =30\nbatch_size = 64\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,y_val),\n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              ,callbacks=callbacks_list,verbose = 1)\n","fdf7894d":"#predict\nsubmission =pd.read_csv(datapath+'\/sample_submission.csv')\npred = model.predict(test)\npred = np.argmax(pred,axis = 1)\nsubmission['Label'] = pred\nsubmission.to_csv('submission.csv',index=False)\nsubmission.head()","9490f440":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.ylim(0.9,1)\nplt.show()","560b5b64":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs, loss, label='Training loss')\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.ylim(0,0.5)\nplt.show()","465ff8a5":"![image.png](attachment:image.png)","c483f9e9":"# Train and predict","971d500b":"# Preprocessing\n- LeNet-1 used 28x28 images\n- In LeNet-5, 28x28 test image of MNIST was placed in the center of 32x32 image and processed. Because of the use of larger-sized images, the consideration of small parts of the image is much more considered than in the down-size image, and as a result, the performance can be obtained more.","7af4e1cc":"## data load","4ec58c25":"# Acc\/Loss plot","1edb2174":"# conclusion","33f62a73":"# Model\n- [32x32x1] INPUT\n- [28x28x6] CONV1: 6 5x5 filters at stride 1, pad 0 \n- [6x14x14] Average POOL1: 2x2 filters at stride 2  \n- [16x10x10] CONV2: 256 5x5 filters at stride 1, pad 0  \n- [16x5x5] Average POOL2: 2x2 filters at stride 2  \n- [120] FC6: 120 neurons\n- [84] FC7: 84 neurons\n- [10] FC8: 10 neurons (class scores)","29c5b324":"- LeNet-5 model ussd Non-overlapping pooling\n![image.png](attachment:image.png)","88578314":"- Renet-5, over 99 percent. Amazing!\n- If you try an ensemble through cross-validation, your score will go up","8c56bb75":"# LeNet-5\n- First successful model in the industry\n![image.png](attachment:image.png)"}}