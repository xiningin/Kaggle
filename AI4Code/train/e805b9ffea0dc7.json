{"cell_type":{"6239cdf3":"code","d065056a":"code","988e570d":"code","cf6f588a":"code","955cb949":"code","a975637b":"code","a768aa0b":"code","952be304":"code","0e1475ee":"code","1e0c442b":"code","fc9443b7":"code","16d70bd9":"code","f3984a21":"code","7e84e93c":"code","b73f7a2b":"markdown","b9e5cf34":"markdown","34b24fb2":"markdown"},"source":{"6239cdf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom xml.dom import minidom\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d065056a":"CD = '..\/input\/englishportuguese-translation\/' ","988e570d":"SL = 'EN' #this is a constant and should not be changed, i.e. Source Language is always English","cf6f588a":"TL = 'PT' #depending on the desired Target Language, this could be set, available abbr. choices are written in the introduction paragraph","955cb949":"pd.read_csv('..\/input\/englishportuguese-translation\/por.txt', sep='\\t', header = None)[[0,1]].rename(columns = {0:SL, 1:TL})","a975637b":"df= pd.read_csv('..\/input\/englishportuguese-translation\/por.txt', sep='\\t', header = None)[[0,1]].rename(columns = {0:SL, 1:TL})\ndf.head()","a768aa0b":"#Code by Mohammad Imran Shaikh https:\/\/www.kaggle.com\/shikhnu\/covid19-tweets-eda-visualization-wordcloud\n\nunique_df = pd.DataFrame()\nunique_df['Features'] = df.columns\nunique=[]\nfor i in df.columns:\n    unique.append(df[i].nunique())\nunique_df['Uniques'] = unique\n\nf, ax = plt.subplots(1,1, figsize=(15,7))\n\nsplot = sns.barplot(x=unique_df['Features'], y=unique_df['Uniques'], alpha=0.8)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center',\n                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\nplt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\nplt.ylabel('#Unique values', size=12, weight='bold')\nplt.xlabel('Features', size=12, weight='bold')\nplt.xticks(rotation=90)\nplt.show()","952be304":"#Code by Savita Nair https:\/\/www.kaggle.com\/savitanair\/hr-analytics\n\nprint(f'Dataset has {len(df.PT.unique())} unique groups')\nprint('*'*20)\nprint(f'And the top 10 counts are :')\nprint(df.PT.value_counts().head(10))\nprint('*'*20)\n\nc = df.PT.value_counts().head(10)\nfig, ax = plt.subplots(1,1,figsize=(12,6))\nax.bar(c.index, c.values, width=0.8, color='g')\nplt.xticks(rotation=45)","0e1475ee":"#Code by Savita Nair https:\/\/www.kaggle.com\/savitanair\/hr-analytics\n\nprint(f'Dataset has {len(df.EN.unique())} unique groups')\nprint('*'*20)\nprint(f'And the top 10 counts are :')\nprint(df.EN.value_counts().head(10))\nprint('*'*20)\n\nc = df.EN.value_counts().head(10)\nfig, ax = plt.subplots(1,1,figsize=(12,6))\nax.bar(c.index, c.values, width=0.8, color='b')\nplt.xticks(rotation=45)","1e0c442b":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.PT)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='summer', background_color=\"green\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","fc9443b7":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.EN)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Blues', background_color=\"red\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","16d70bd9":"def process_tuv(tuv):\n    lang = tuv.getAttribute(\"lang\")\n    if lang == '':\n        lang = tuv.getAttribute(\"xml:lang\")\n    seg = tuv.getElementsByTagName('seg')[0]\n    txt = seg.childNodes[0].data\n    return lang, txt\n\ndef read_tmx_files(path):\n\n    \"\"\"Read function takes in a path to TMX translation file and outputs the metadata and a pandas dataframe.\n\n    Args:\n        param1 (str): The path to the TMX translation file\n\n    Returns:\n        dict: The header of the TMX file, which contains metadata\n        DataFrame: A Pandas Dataframe. Each line item consists of source_language, source_sentence, target_language, target_sentence\n\n    \"\"\"\n    # parse an xml file by name\n    tmx = minidom.parse(path)\n\n    # Get metadata\n    metadata = {}\n    header = tmx.getElementsByTagName('header')[0]\n    for key in header.attributes.keys():\n        metadata[key] = header.attributes[key].value\n        \n    srclang = metadata['srclang']\n\n    # Get translation sentences\n    body = tmx.getElementsByTagName('body')[0]\n    translation_units = body.getElementsByTagName('tu')\n    items = []\n    count_unpaired = 0\n    for tu in translation_units:\n        if len(tu.getElementsByTagName('tuv')) < 2:\n            print(\"Unpaired translation. Ignoring...\")\n            count_unpaired = count_unpaired + 1\n        else:\n            srclang, srcsentence = process_tuv(tu.getElementsByTagName('tuv')[0])\n            targetlang, targetsentence = process_tuv(tu.getElementsByTagName('tuv')[1])\n            item = {\n                'source_language': srclang,\n                'source_sentence': srcsentence,\n                'target_language': targetlang,\n                'target_sentence': targetsentence\n            }\n            items.append(item)\n\n    df = pd.DataFrame(items)\n    if count_unpaired > 0:\n       print(\"The data contained %d unpaired translations which were ignored\" % (count_unpaired))\n    return metadata, df","f3984a21":"#metadata, df = read_tmx_files('..\/input\/paralel-translation-corpus-in-22-languages\/Sample TMX file (EN-GA)\/EN-GA.tmx')\n#df.head()","7e84e93c":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Who is Tom? @mpwolke was Here' )","b73f7a2b":"#Reading the Translation Memory Data","b9e5cf34":"#Codes by Habib G\u00fcltekin https:\/\/www.kaggle.com\/hgultekin\/starter-reading-the-tm-data","34b24fb2":"I saved the next block if (in the future) I have a XML file."}}