{"cell_type":{"34dc18ae":"code","fda4744d":"code","7c4f2ebd":"code","0994c213":"code","e28f605c":"code","cd985d6d":"code","7b447186":"code","10a7cefb":"code","73da592e":"code","35f7d1fe":"code","ef3cf41a":"code","131126e2":"code","1ae40ecb":"code","5b399963":"code","e1d682b1":"code","082b9133":"code","2815a2d1":"code","2b8f5aeb":"code","c99658fa":"code","3367be3e":"code","55b04e1c":"code","d9c6f9ae":"code","01803805":"code","3c5732fe":"code","c0cd319a":"code","a275b3d9":"code","1ff6021d":"code","057b8764":"code","792a757e":"code","af4ad723":"code","4b9f7e5d":"code","c4f6c4a3":"code","7524fb80":"code","2fa82bbe":"code","a27f9f9a":"code","64969814":"code","101a7090":"code","eff284af":"code","8a3850b6":"markdown","4580f82d":"markdown","df1d4bc4":"markdown","6f441395":"markdown","959f9664":"markdown","00233ccf":"markdown","be16afc3":"markdown","64ddcc93":"markdown","7e37847e":"markdown","c9cdc3e1":"markdown","0f349de2":"markdown","f6673a46":"markdown","1cdcc561":"markdown","336c41d9":"markdown","77801f1c":"markdown","5697e501":"markdown","50a6e446":"markdown","9b9d64e4":"markdown","4ab1d268":"markdown","30a12caa":"markdown","8b0ec1b6":"markdown","6065803f":"markdown","4d4f1d5e":"markdown","ad9aff1e":"markdown","f8cf3979":"markdown","0fd3c358":"markdown","b4b524f3":"markdown","a4bd1ef8":"markdown","b37f49d4":"markdown","085f3d2c":"markdown","6106078d":"markdown"},"source":{"34dc18ae":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","fda4744d":"os.getcwd()    #to get current working directory","7c4f2ebd":"dataset = pd.read_csv('..\/input\/dectecting-phishing-website-using-machine-learning\/dataset.csv')    # read dataset\n\ndataset.head(5)    # To display 1st 5 obervations","0994c213":"dataset.info()    # Information of all dataset","e28f605c":"dataset.isnull().sum()    # For count missing values","cd985d6d":"dataset = dataset.drop_duplicates()    # For remove duplicates","7b447186":"dataset = dataset.drop('index',axis = 1)    # For drop index column","10a7cefb":"dataset.head()    # For display top 5 observation","73da592e":"dataset.head(10).T","35f7d1fe":"dataset.columns.to_list()","ef3cf41a":"from sklearn.preprocessing import LabelEncoder\n\n# Create an object of the label encoder class\nlabelencoder = LabelEncoder()\n\n# Apply labelencoder object on columns\ndataset = dataset.apply(labelencoder.fit_transform)","131126e2":"dataset.head()","1ae40ecb":"sns.set(style=\"darkgrid\")    # To set background\nsns.countplot('Result', data = dataset)    # Countplot\nplt.title('Class Distribution Plot')    # Title","5b399963":"from matplotlib.pyplot import show\ntotal = float(len(dataset)) # one person per row \nsns.set(style=\"darkgrid\")\n\nax = sns.countplot(x=\"Result\",hue = 'SSLfinal_State',data=dataset)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\")\nplt.title('Multiple Bar Plot of SSLfinal_State v\/s Result')\nshow()","e1d682b1":"from matplotlib.pyplot import show\ntotal = float(len(dataset)) # one person per row \nsns.set(style=\"darkgrid\")\n\nax = sns.countplot(x=\"Result\",hue = 'Links_in_tags',data=dataset)    # Countplot\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,          # Loop for calculate percentages for each bar\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \n    \nplt.title('Multiple Bar Plot of Links_in_tags v\/s Result')    # Title of plot\nshow()","082b9133":"from matplotlib.pyplot import show\ntotal = float(len(dataset)) # one person per row \nsns.set(style=\"darkgrid\")\n\nax = sns.countplot(x=\"Result\",hue = 'web_traffic',data=dataset)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \nplt.title('Multiple Bar Plot of web_traffic v\/s Result')    # Title of plot\nshow()","2815a2d1":"from matplotlib.pyplot import show\ntotal = float(len(dataset)) # one person per row \nsns.set(style=\"darkgrid\")\n\nax = sns.countplot(x=\"Result\",hue = 'URL_of_Anchor',data=dataset)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \n    \nplt.title('Multiple Bar Plot of URL_of_Anchor v\/s Result')    # Title of plot\nshow()","2b8f5aeb":"from matplotlib.pyplot import show\ntotal = float(len(dataset)) # one person per row \nsns.set(style=\"darkgrid\")\n\nax = sns.countplot(x = \"Result\",hue = 'having_Sub_Domain',data=dataset)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}'.format(height\/total),\n            ha=\"center\") \n    \nplt.title('Multiple Bar Plot of having_Sub_Domain v\/s Result')\nshow()","c99658fa":"plt.figure()\nplt.figure(figsize = (20,40))    # For Figure size\n\nfor i in range(1,31):\n    sns.set(style = 'darkgrid')\n    plt.subplot(11,3,i)    # Create Subplot \n    sns.countplot(dataset.columns[i],data = dataset)   # Create Countplot\n    plt.tight_layout()    # For tight graph layout\n    \n    \nplt.title('Distributions of Features')\nplt.show()","3367be3e":"data_count = dataset.apply(pd.value_counts)    # For count values\n\ndata_count = data_count.T.iloc[:-2, : ]    # For draw last 2 rows\n\ndata_count.fillna(0, inplace = True)    # For fill missing value\n\ndata_count.style.background_gradient(cmap = 'Blues')    # For background style\n","55b04e1c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC","d9c6f9ae":"from sklearn.model_selection import train_test_split    # import train_test_split module\n\nx_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:,:-1], dataset.iloc[:,-1], test_size = .20, random_state = 7)    # Split dataset into train, test\n","01803805":"from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve","3c5732fe":"from sklearn.tree import DecisionTreeClassifier    # import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)    # Accuracy Score\nprint(acc)","c0cd319a":"model = LogisticRegression()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)    # Accuracy Score\nprint(acc)","a275b3d9":"model = KNeighborsClassifier()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)    # Accuracy Score\nprint(acc)","1ff6021d":"model = GaussianNB()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)    # Accuracy Score\nprint(acc)","057b8764":"model = SVC()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)\nprint(acc)","792a757e":"model = MLPClassifier()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)\nprint(acc)","af4ad723":"model = RandomForestClassifier()    # Call model\n\nmodel.fit(x_train, y_train)    # Fit model\n\ny_pred = model.predict(x_test)    # Prediction\n\nacc = accuracy_score(y_test, y_pred)    # Accuracy Score\nprint(acc)","4b9f7e5d":"pd.DataFrame({'Accuracy' : [0.9647, 0.9376, 0.9570, 0.6296, 0.9611, 0.9656, 0.9756]}, index = ['Decision_Tree', 'Logistic regression',\n                                                                                    'K Nearest Neighbour', 'Navie Bayes', 'Support Vector Machine', 'ANN', 'Random Forest']).plot(kind = 'bar')","c4f6c4a3":"cr = classification_report(y_test, y_pred, target_names = ['phishing', 'No phishing'])    # Classification Report\nprint(cr)","7524fb80":"sns.heatmap(confusion_matrix(y_test, y_pred),cmap = 'Blues', annot = True, fmt = '.2f',)","2fa82bbe":"roc = plot_roc_curve(model, x_test, y_test)    # Plot Roc Curve\nplt.title(\"ROC Curve\")","a27f9f9a":"plot_precision_recall_curve(model, x_test, y_test)    # Plot precision recall curve\nplt.title(\"Precision Recall Curve\")","64969814":"feature_importance = model.feature_importances_    # Important Features\n\nindices=np.argsort(feature_importance)[::-1]    # Reature importance in descending order\nnames=[dataset.columns[:-1][i] for i in indices ]     # Rearrange names\n\n\nplt.figure(figsize=(10,4))    # Set Figure Size\nplt.title(\"Features_Importnace\")    # Add title\nplt.bar(range(30), feature_importance[indices])    # Create Barplot\nplt.xticks(range(30),names,rotation=90)    # Xticks for each Bar\nplt.show()","101a7090":"import joblib","eff284af":"joblib.dump(model, 'Random_Forest.pkl')    # save model","8a3850b6":"![phishing_rendered-1024x300.jpg](attachment:phishing_rendered-1024x300.jpg)","4580f82d":"#### Classification Report of Random Forest Classifier","df1d4bc4":"## Import Libraries","6f441395":"## Disadvantages\n1. As it provides fake identity of user, the phishers may find out the fake user by consistently analyzing fake response\n   from user.\n2. Phishers can use CAPTCHA (completely automated public Turing tests to tell computers and humans apart) to intact\n   the response of the legitimate user.","959f9664":"### Decision Tree","00233ccf":"### Random Forest","be16afc3":"The aim of the experiments conducted in this notebook is to give an idea of how modern <b>phishing website attacks<\/b> can be prevented using machine learning. To do this, we are going to use the __['Phishing Websites'](https:\/\/archive.ics.uci.edu\/ml\/datasets\/phishing+websites)__ Dataset. The viewers are requested to take a look at __[this paper](https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00327\/Phishing%20Websites%20Features.docx)__ by the authors of the dataset. The paper discusses the data generation strategy in details and how the authors were able to come up with the most significant set of features for detecting phishing websites.","64ddcc93":"## Conclusion\n1. From Countplot we say that distribution of Phishing Website is maximum.\n2. From all model we say that ANN, SVM, Decision Tree, KNN, Random Forest are good fit but AUc and Precision, Recall for          Random Forest is better than all other Classifiers.\n3. Accuracy of Random Forest Classifier is 0.9774\n4. Area Under Curve of Random Forest Classifier is 1\n5. Average Precision of Random Forest Classifier is 0.99","7e37847e":"### K Nearest Neighbour","c9cdc3e1":"#### Precision Recall Curve of Random Forest Classifier","0f349de2":"## Model Building","f6673a46":"####  Interpretation \n    Count for Phishing website is maximum.","1cdcc561":"### Navie Baye's","336c41d9":"### ANN","77801f1c":"## Data Preprocessing","5697e501":"## Save Model ","50a6e446":"#### ROC Curve of Random Forest Classifier","9b9d64e4":"#### Interpretation\n    Here AUC(Area Under Curve) is 1 that emplies our model is best for given dataset.","4ab1d268":"## Data Cleaning ","30a12caa":"#### Confusion Matrix of Random Forest Classifier","8b0ec1b6":"#### Interpretation\n\n    Random Forect Classifier's Accuracy is better as compare to all other Classifier's Accuracy, So We go with Random Forest Classifier. ","6065803f":"## Table of Content\n1. [Import Libraries](#Import-Libraries)\n1. [Data Preprocessing](#Data-Preprocessings)\n1. [Data Cleaning](#Data-Cleaning)\n1. [Data Visualization](#Data-Visualization)\n1. [Model Building](#Model-Building)\n1. [Save Model ](#Save-Model )\n1. [Conclusion](#Conclusion)","4d4f1d5e":"#### Interpretation\n    Here TP(True Positive and TN(True Negative) count is better that means model predicted classes is almost same.","ad9aff1e":"## Advantages\n1. This technique provides the phishing webpage detection by hiding the users identity from phishers.\n2. The computation time is very less.","f8cf3979":"### Logistic Regression","0fd3c358":"#### Interpretation\n    Here AP(Average Precision) is 0.99 that is nearly equal to 1 that emplies our model is best for given dataset.","b4b524f3":"## Data Visualization","a4bd1ef8":"### Support Vector Machine","b37f49d4":"#### Interpretation\n    From above barplot we can say that first six features are more important as compare to other features.","085f3d2c":"## Classifiers","6106078d":"<h1><center><font color='darkslategrey'>Detecting Phishing Websites Using Machine Learning<\/font> <\/center><\/h1>"}}