{"cell_type":{"f16f2c98":"code","0710383c":"code","b4823aa8":"code","84c5f0c1":"code","9eabc2e8":"code","9c4dcf1a":"code","931e8d5c":"code","ca5872c3":"code","e4d198b0":"code","87e0353c":"code","f6c38658":"code","33b27404":"markdown","1ffa7311":"markdown","27e153bd":"markdown","67dfbf95":"markdown","76f1c466":"markdown","94b2fadb":"markdown"},"source":{"f16f2c98":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nnp.random.seed(123)","0710383c":"# gen data for proprtional sampling\nraw_data = np.array([1,4,2,9,15,50,17])","b4823aa8":"# sort asc. order\ndata = np.array(sorted(raw_data))","84c5f0c1":"sns.barplot(data, data)\n\nplt.title(\"The probabiltiy of selecting each of the values is directlyproportional to it's value.\\nWe can clearly see probabilty of selecting 50 is more \\nthan probability of selecting -9 or 2 because it is greater\\n\\n data\")\nplt.grid()\nplt.show()","9eabc2e8":"# Normalize by divide by  sum (probability of selecting that value)\ndata_probs = data \/ data.sum()","9c4dcf1a":"# plot normalized \/ probabilites\nsns.barplot(data, data_probs) # old-data: label, new-data: (data_scaled) obsvns\n\nplt.grid()\nplt.title(\"Normalized(div. by max): Probabilities\\n Note, now w\/ probabilites we can see what is probability of selecting each\\n\\n data_probs\")\nplt.show()","931e8d5c":"# cumulative sum\n# --------------\n# cumlative sums will be upperlimits of our\n# uniform rvs to select that obsvc\nlabels = sorted(data)\ndata_norm_sorted = sorted(data_probs)\ncum_sums = np.cumsum(data_norm_sorted)\n\ncum_sums","ca5872c3":"pd.DataFrame({\n    'Raw Input: data (sorted)': data,\n    'Pobabilites: data_probs': data_probs,\n    'Cumulative Sum: Upper Limits for uniform rvs': cum_sums\n})","e4d198b0":"plt.figure(figsize=(10,7))\nplt.plot(cum_sums)\nplt.scatter(np.arange(0, len(cum_sums)), cum_sums)\n\n\ny = cum_sums # sorted\nx = data # sorted\n\n\nplt. plot([-2, 0], [0, 0],linestyle=\"--\")\nfor idx in range(0, len(cum_sums)):\n    begx, begy = -2, cum_sums[idx]\n    endx, endy = 6, cum_sums[idx]\n    plt. plot([begx, endx], [begy, endy],linestyle=\"--\")\n\n_labels = [\"Nothing\"] + labels \nleg = [f\"Lower-limit of {data[idx]} AND upper-limit of {_labels[idx]}\" for idx in range(0,len(cum_sums+1))]\n\nplt.legend([\"Cumulative Sums\"]+leg)\n\nplt.title(\"Mapping U.R.V to Cumulative Sum For\\nProportional Sampling\\n\\n\" + \\\n         \"The intervals of uniform r.v is given by dashed lines for proportional sampling of sorted `data`\")\nplt.ylabel(\"CDF\")\nplt.xlabel(\"indices of sorted sorted `data`\")\nplt.show()","87e0353c":"# sampling function (w\/ replacement)\ndef _sample_from_cum_sum(cum_sums, sample_size):\n    proportional_sample_accumulator = []\n    \n    for _ in range(0, sample_size):\n        urv = np.random.uniform(0,1)\n        # sample based on uniform random variablE and upper-limits\n        for idx, cum_sum in enumerate(cum_sums):\n            if urv < cum_sum:\n                porportionally_sampled_obsv = data[idx] # `data` is not raw (sorted above)\n                proportional_sample_accumulator.append(porportionally_sampled_obsv)\n                break # important\n                \n    return proportional_sample_accumulator","f6c38658":"_sample_from_cum_sum(cum_sums, 3)","33b27404":"# Proportional Sampling","1ffa7311":"**Start sampling from CUMULATIVE SUMS w\/ uniform rvs $U(0,1)$**","27e153bd":"## Proportional Sampling Implementation\n\n1. **GENERATE CUMULATIVE SUM**\n\n    - Take sorted `data` (Preferrably all positive)\n    - Divide all by `max(data)` $\\Rightarrow$ `data_probs`\n    - Generate Cumulative Sums `cum_sums` of `data_probs` \n\n\n2. **SAMPLE FROM CUMUMLATIVE SUMS(upper-limits) USING UNIFORM RVs**\n\n   - Genrate a uniform rv [0,1] cz, range of `cum_sum` is [0,1]\n   - Start from lowest idx of cum sums. If `rv < cum_sum`, sample is `data[idx_of_cum_sum]`\n   - Repeat for `sample_size` number of times\n   \n### NOTE\n\n> - If raw data is not all positive, we can *shift* and after proportionally sampling, *unshift* to avoid negative \n> numbers\n> - `data` is sorted. `raw_input_data` might not be sorted.\n>\n> - If squashed (eg. minmax) instaed of division by max, will not work.","67dfbf95":"> - **Normalizing by divide by  sum** is just like finding **probabilities** of items being selected\n>\n> - Note that we are finding probabilites. **Not squashing** in some range like *min-max-scaling or std-normalisation*.\n>  Because, we will use this data for finding intervals for *uniform rvs* (which won't be possible if not probabilities)","76f1c466":"> *The probability of selecting an observation is directly proprtional to it's value*","94b2fadb":"**Proportionally sample 3 samples w\/ replacement**\n\n> *High chance of getting large nums*"}}