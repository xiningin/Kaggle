{"cell_type":{"7c483566":"code","6a5a289e":"code","32023ade":"code","efd53dd0":"code","8d206d7e":"code","8c956300":"code","81ae2810":"code","9f29b34d":"code","e6698edd":"code","1383c4f2":"code","f016e811":"code","e0633f62":"code","b5517e5b":"code","41517ea3":"code","5332a572":"markdown","5a3872ad":"markdown","0648e58e":"markdown","1c5ada3a":"markdown","da57d721":"markdown","7c584031":"markdown","3cf408a9":"markdown","c879e9aa":"markdown","c17d5439":"markdown","c4a63e2b":"markdown","2c499d40":"markdown","09570eba":"markdown"},"source":{"7c483566":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6a5a289e":"from tqdm import tqdm\nfrom xgboost import XGBRegressor","32023ade":"X_train=pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/train.csv' )\nX_test=pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/test.csv' )","efd53dd0":"sample_submission=pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-4\/submission.csv' )","8d206d7e":"X_train['Date'] = pd.to_datetime(X_train['Date'], infer_datetime_format=True)\nX_test['Date'] = pd.to_datetime(X_test['Date'], infer_datetime_format=True)\n\nX_train.loc[:, 'Date'] = X_train.Date.dt.strftime(\"%m%d\")\nX_train[\"Date\"]  = X_train[\"Date\"].astype(int)\n\nX_test.loc[:, 'Date'] = X_test.Date.dt.strftime(\"%m%d\")\nX_test[\"Date\"]  = X_test[\"Date\"].astype(int)\n\nX_train.rename(columns={'Country_Region':'Country'}, inplace=True)\nX_test.rename(columns={'Country_Region':'Country'}, inplace=True)\n\nX_train.rename(columns={'Province_State':'State'}, inplace=True)\nX_test.rename(columns={'Province_State':'State'}, inplace=True)","8c956300":"X_train.loc[X_train['State'].isna(), 'State']=\"nan\"\nX_test.loc[X_test['State'].isna(), 'State']=\"nan\"","81ae2810":"from sklearn.base import BaseEstimator\n\n# Create a regressor that does not give negative results\nclass booster(BaseEstimator):\n    def __init__(self, **params):\n        self.reg=XGBRegressor(**params)\n\n    def fit(self, X, y=None):\n        self.reg.fit(X,y)\n        return self\n\n    def predict(self,X):\n        pred=self.reg.predict(X)\n        pred[pred<0]=0\n        return pred\n    \n    def set_params(self,**params):\n        self.reg.set_params(**params)\n    \n","9f29b34d":"countries = X_train['Country'].unique()\n\nfrom sklearn import preprocessing, clone\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import r2_score\ntscv = TimeSeriesSplit(n_splits=10)\ncv_score=[]\ncs=[]\n\nle = preprocessing.LabelEncoder()\n\nxout = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\ncv_score=[]\n\nfor country in countries:\n    states = X_train.loc[X_train['Country'] == country, :]['State'].unique()\n    #print(country, states)\n    # check whether string is nan or not\n    for state in states:\n        X_train_CS = X_train.loc[(X_train['Country'] == country) & (X_train['State'] == state), ['State', 'Country', 'Date', 'ConfirmedCases', 'Fatalities']]\n\n        y1_train_CS = X_train_CS.loc[:, 'ConfirmedCases']\n        y2_train_CS = X_train_CS.loc[:, 'Fatalities']\n\n\n        X_train_CS = X_train_CS.loc[:, ['State', 'Country', 'Date']]\n\n        X_train_CS['Country'] = le.fit_transform(X_train_CS['Country'])\n        X_train_CS['State'] = le.fit_transform(X_train_CS['State'])\n\n        X_test_CS = X_test.loc[(X_test['Country'] == country) & (X_test['State'] == state), ['State', 'Country', 'Date', 'ForecastId']]\n\n        X_test_CS_Id = X_test_CS.loc[:, 'ForecastId']\n        X_test_CS = X_test_CS.loc[:, ['State', 'Country', 'Date']]\n\n        X_test_CS['Country'] = le.fit_transform(X_test_CS['Country'])\n        X_test_CS['State'] = le.fit_transform(X_test_CS['State'])\n\n        regressor = booster(mad_depth=3,n_estimators=10)\n\n        # cross-validation for confirmed cases\n        cv=[]\n        for train_index, test_index in tscv.split(X_train_CS):\n            xtrain, ytrain = X_train_CS.iloc[train_index], y1_train_CS.iloc[train_index]\n            xtest, ytest = X_train_CS.iloc[test_index], y1_train_CS.iloc[test_index]\n            reg=clone(regressor)\n            reg.fit(xtrain,ytrain)\n            cv+=[np.mean(r2_score(ytest,reg.predict(xtest)))]\n            \n        # cross validation for fatalities\n        cv2=[]\n        for train_index, test_index in tscv.split(X_train_CS):\n            xtrain, ytrain = X_train_CS.iloc[train_index], y2_train_CS.iloc[train_index]\n            xtest, ytest = X_train_CS.iloc[test_index], y2_train_CS.iloc[test_index]\n            reg=clone(regressor)\n            reg.fit(xtrain,ytrain)\n            cv2+=[np.mean(r2_score(ytest,reg.predict(xtest)))]\n            \n        cv_score += [[np.mean(cv), np.mean(cv2)]]\n\n        cs += [(country, state)]\n","e6698edd":"cv_score=np.array(cv_score)\nnp.mean(cv_score, axis=0)","1383c4f2":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.distplot(cv_score[:,0], label='Error for Confirmed Cases')\nsns.distplot(cv_score[:,1], label='Error for Fatalities')\nplt.legend()","f016e811":"country_state= [country+'\/'+state for country,state in cs]\nN=15\nind_sort_cc=np.argsort(cv_score[:,0])\n\nprint(pd.DataFrame({'Coutry\/State':np.array(country_state)[ind_sort_cc[:N]],'error':np.array(cv_score)[ind_sort_cc[:N],0] }))","e0633f62":"ind_sort_f=np.argsort(cv_score[:,1])\n\nprint(pd.DataFrame({'Coutry\/State':np.array(country_state)[ind_sort_f[:N]],'error':np.array(cv_score)[ind_sort_f[:N],1] }))","b5517e5b":"import plotly.graph_objects as go #Plotlygo for plotting\n\n#Plotting a bar graph for error by couple (country,state).\nN=50 # number of country\/state to plot\nindices=ind_sort_cc[:N]\nscores = {'Country\/State' : np.array(country_state)[indices], 'error': np.array(cv_score[:,0])[indices]}\nscores_df = pd.DataFrame(scores)\n\n#Plotting the Graph.\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=scores_df['Country\/State'], y=scores_df['error'], name='States most difficult to predict for ConfirmedCases'))\n\nfig.show()\n","41517ea3":"\nindices=ind_sort_f[:N]\nscores = {'Country\/State' : np.array(country_state)[indices], 'error': np.array(cv_score[:,1])[indices]}\nscores_df = pd.DataFrame(scores)\n\n#Plotting the Graph.\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=scores_df['Country\/State'], y=scores_df['error'], name='States most difficult to predict for Fatalities'))\n\nfig.show()\n","5332a572":"In this kernel I used a very basic xgboost regressor algorithm to predict Covid-19 cases and then I see which states give rise the the largest error. \n\nA big error in predicting 'ConfirmedCases' means that the trend cannot be easily predicted by a simple model, there are several possible explanations : \n\n* not enough test to detect all covid-19 cases\n* Local policies that are difficult to predict\n* environmental factor\n* atypical place (e.g. China, origin of the epidemy)\n\nOn the other hand, a big error in predicting'Fatalities' cannot be explained by the first reason.","5a3872ad":"## Prediction with xgboost and comparison of error on several countries.","0648e58e":"First, we process the data so that the time is given by an integer and we simplify the name of the features.","1c5ada3a":"Rename nan states as the string \"nan\". We will need this later.","da57d721":"We make a model for each country\/state. We use TimeSeriesSplit a cross-validation adapted to time-series to get validation scores. Instead of the mean_squared_log_error used in the leaderboard we use r2 score as it seems less influenced by the total population of a country.","7c584031":"Without surprise, China present a lot of difficult to predict regions because of its place as origin of the epidemy.","3cf408a9":"* We do the same with the number of fatalities","c879e9aa":"## Data processing","c17d5439":"## Description of this kernel","c4a63e2b":"## Results","2c499d40":"## A small vizualization","09570eba":"* See which are the 15 most \"Confirmed cases\" difficult to predict with our model (it can change according to which loss you choose)"}}