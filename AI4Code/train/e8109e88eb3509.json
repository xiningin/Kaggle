{"cell_type":{"47be0f48":"code","d3e8c44d":"code","19822d58":"code","d07a48d5":"code","68eb0a97":"code","9bf5eede":"code","6fcf1e02":"code","969d2442":"code","7b5bbec6":"code","8a0045f0":"code","9cd07671":"code","ab24f535":"code","8fd6a2fd":"code","4af03c41":"code","62d8c667":"code","0e099b70":"code","f0f754bc":"code","cf3c5c23":"markdown","28a1bf29":"markdown","d65bdbf8":"markdown","7257aa56":"markdown","f7184f42":"markdown","fe4e6825":"markdown","60daca62":"markdown","ea65eca7":"markdown"},"source":{"47be0f48":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","d3e8c44d":"target=\"HasDetections\"\nsubmission_id_col=\"MachineIdentifier\"\n\nseed_split=1 \ntest_size=1\/3\nseed_train=100\n","19822d58":"df_kaggle_train = pd.read_hdf(\n         '..\/input\/save-hdf-full\/train.hdf',\n         key=\"train\"\n)","d07a48d5":"df_kaggle_test = pd.read_hdf(\n         '..\/input\/save-hdf-full\/test.hdf',\n         key=\"test\"\n)","68eb0a97":"df_kaggle_train.shape,df_kaggle_test.shape","9bf5eede":"X=df_kaggle_train.sample(10000)","6fcf1e02":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# From other kernels available, frequency based rank encoding\ndef frequency_encoding(X,variable):\n    t = X[variable].value_counts(normalize=True,dropna=False).reset_index()\n    t = t.reset_index()\n    t.loc[t[variable] == 1, 'level_0'] = np.nan\n    t.set_index('index', inplace=True)\n    max_label = t['level_0'].max() + 1\n    t.fillna(max_label, inplace=True)\n    \n    #return t.to_dict()['level_0']\n    return t.to_dict()[variable]\n\n\nclass FitState():\n    def __init__(self):\n        pass\n    \nclass PrepPipeline(BaseEstimator, TransformerMixin):\n    \n    def __init__(self,fillna=None,fix_smartscreen=False,fix_engineversion=False,cat_encode=False,copy=True,notes=None):\n        self.notes=notes\n        self.copy=copy\n        self.fillna=fillna\n        self.fix_smartscreen=fix_smartscreen\n        self.fix_engineversion=fix_engineversion\n        self.cat_encode=cat_encode\n        \n    def fit(self, X, y=None):\n        self.fit_state=FitState()\n        self.prepare(X=X,y=y,fit=True)\n        return self\n\n    def transform(self, X,y=None):\n        assert isinstance(X, pd.DataFrame)\n        return self.prepare(X=X,y=y,fit=False)\n    \n    def show_params(self):\n        print(\"fit_state\",vars(self.fit_state))\n        print(\"params\",self.get_params())\n        \n    # Experiment is reduce class overhead, bring related fit & transform closer, no models without pipelines\n    def prepare(self,X,y=None,fit=False):\n        \n        fit_state=self.fit_state\n        if (self.copy):\n            X=X.copy()\n        \n\n        # SmartScreen fix\n        if (self.fix_smartscreen):\n            X.SmartScreen=X.SmartScreen.str.lower()\n            X.SmartScreen.replace({\"promt\":\"prompt\",\n                                    \"promprt\":\"prompt\",\n                                    \"00000000\":\"0\",\n                                    \"enabled\":\"on\",\n                                    \"of\":\"off\" ,\n                                    \"deny\":\"0\" , # just one\n                                    \"requiredadmin\":\"requireadmin\"\n                                   },inplace=True)\n            X.SmartScreen=X.SmartScreen.astype(\"category\")\n\n        # Numeric missings\n        if self.fillna is not None:        \n            X.select_dtypes(include=[np.number]).fillna(self.fillna,inplace=True)\n    \n        if self.fix_engineversion:\n            X[[\"EngineVersion_1\",\"EngineVersion_2\",\"EngineVersion_3\",\"EngineVersion_4\"]]=X.EngineVersion.str.split(\".\",expand=True).astype(int)\n            X.drop(columns=[\"EngineVersion_1\",\"EngineVersion_2\"],inplace=True)\n            X[\"EngineVersion_34\"]=X.EngineVersion_3*10+X.EngineVersion_4\n        \n        \n        if self.cat_encode:\n            if fit:\n                cat_encode_vars=['Census_OEMModelIdentifier', 'CityIdentifier', 'Census_FirmwareVersionIdentifier',\n                                 'AvSigVersion','AVProductStatesIdentifier','CountryIdentifier','Census_ProcessorModelIdentifier',\n                                 'Census_OSInstallTypeName','Census_FirmwareManufacturerIdentifier',\n                                 'SmartScreen','AppVersion','EngineVersion',\"SMode\",\n                                 'OsVer','OsSuite','OsPlatformSubRelease','SkuEdition',\"Platform\"\n                                ]\n                fit_state.categorical_columns=cat_encode_vars\n        \n                freq_enc_dict_dict = {}\n                for variable in fit_state.categorical_columns:\n                    freq_enc_dict_dict[variable] = frequency_encoding(X,variable)\n                fit_state.freq_enc_dict_dict=freq_enc_dict_dict\n            else:\n                freq_enc_dict_dict = fit_state.freq_enc_dict_dict\n                test_freq_enc_dict_dict={}\n                for variable in fit_state.categorical_columns:\n                    test_freq_enc_dict_dict[variable] = frequency_encoding(X,variable)\n                    X[variable+\"_freq\"] = X[variable].map(lambda x: freq_enc_dict_dict[variable].get(x, np.nan)).astype(\"float64\")\n                    X[variable+\"_freq_test\"] = X[variable].map(lambda x: test_freq_enc_dict_dict[variable].get(x, np.nan)).astype(\"float64\")\n        \n        X.drop(columns=[\"AvSigVersion\",\"EngineVersion\",\"SMode\",\n                        \"AppVersion\",\"Census_OSVersion\"],inplace=True)\n        return X\n\n\n# Test\nPrepPipeline(copy=True,cat_encode=True).fit_transform(X).head().T","969d2442":"TRAIN_ROWS=500000\ndf_train=df_kaggle_train.sample(TRAIN_ROWS,random_state=seed_split)\ndf_train.head()","7b5bbec6":"from sklearn.model_selection import train_test_split\n\n# Split X,y\ny= df_train[target].values\ndf_train.drop(columns=target,inplace=True)","8a0045f0":"df_train.drop(columns=[submission_id_col],inplace=True)","9cd07671":"# Split kaggle train, reserve internal hold out test set\nX_train_all, X_test, y_train_all,y_test = train_test_split(df_train,y, \n                                                   test_size=test_size, random_state=seed_split,stratify =y)","ab24f535":"# Split for eval df\/early stopping\n\ntest_frac=.10\nfrom sklearn.model_selection import train_test_split\nX_train, X_eval, y_train,y_eval = train_test_split(X_train_all,y_train_all, \n                                                   test_size=test_frac, random_state=seed_split,stratify =y_train_all)","8fd6a2fd":"from sklearn.pipeline import Pipeline\nfrom lightgbm import LGBMClassifier\n\nparam_grid={\"clf__boosting_type\": [\"gbdt\",\"dart\",\"goss\",\"rf\"],\n           # \"clf__class_weight\":[None,\"balanced\"],\n            #\"clf__colsample_bytree\": [.1,.2,.3,.4,.5,.6,.8,.9,1],\n            \"clf__subsample\":[.4,.5,.75,.9,1],\n            \"clf__max_bin\":[10,50,100,340,500,170],\n            \"clf__importance_type\":['split'],\n            \"clf__num_leaves\":[10,25,31,53,100,31,None],\n           # \"clf__min_split_gain\":[.05,.025,.01,.1],\n                     }\nn_estimators=2000\n\npipeline=Pipeline([\n    ('prep', PrepPipeline(notes=\"with cat encode\",cat_encode=True)),\n    (\"clf\",LGBMClassifier(random_state=seed_train,\n                          n_jobs=1,\n                          learning_rate=.3,\n                          n_estimators=n_estimators ))])\n         \n","4af03c41":"prep_pipeline=pipeline.named_steps[\"prep\"].fit(X_train,y_train)\neval_set=[(prep_pipeline.transform(X_eval),y_eval), \n          (prep_pipeline.transform(X_train), y_train)]\neval_set[0][0].shape","62d8c667":"from sklearn.model_selection import RandomizedSearchCV,GridSearchCV,train_test_split\n\nif __name__ == \"__main__\":\n    \n    from sklearn.model_selection import cross_val_score,RepeatedStratifiedKFold,RepeatedKFold\n\n    random_state=43\n    rskf = RepeatedKFold(n_splits=5, n_repeats=2,random_state=random_state)\n    \n    # run randomized search\n    n_iter_search = 50\n    search_njobs=-1\n    model_search = RandomizedSearchCV(pipeline, param_distributions=param_grid,n_jobs=search_njobs,n_iter=n_iter_search,\n                                      scoring=\"roc_auc\",error_score=0,cv=rskf,random_state=seed_train,\n                                     verbose=1)\n    \n    # Fit with early stopping\n    early_stopping_round=50\n    print(X_train.shape,y_train.shape) \n    model_search.fit(X_train,y_train,\n           #clf__eval_metric = 'auc',\n           clf__eval_set= eval_set,\n           clf__eval_names=[\"eval\",\"train\"],\n           clf__verbose=False,\n           clf__early_stopping_rounds = early_stopping_round\n            )\n\n    ","0e099b70":"df_cv_results=pd.DataFrame(model_search.cv_results_).sort_values(by='rank_test_score')\ndf_cv_results[\"dif_test_train\"]=df_cv_results.mean_train_score-df_cv_results.mean_test_score\ndf_cv_results.fillna(\"NA\",inplace=True)\n\ndf_cv_results.drop(\"params\",axis=1,inplace=True)\n\ndf_cv_results.sort_values(\"mean_test_score\",ascending=False,inplace=True)\n\ndf_cv_results.to_csv(f\"cv_results_{TRAIN_ROWS}_{n_iter_search}_{seed_train}.csv\")\ndf_cv_results","f0f754bc":"%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display as display, Markdown\n\neval_cv_metric=\"mean_test_score\"\ntrain_cv_metric=\"mean_train_score\"\n\nscore_result=eval_cv_metric\nscore_result2=\"dif_test_train\"\nsplit_col=\"\"\n\ndisplay(Markdown(\"## %s,%s vs parameters (numeric)\"%(score_result,score_result2)))\n\nall=df_cv_results\n\nall[\"all\"]=\"\"\n\nif not split_col in all.keys():\n     split_col=\"all\"\n\naxis=0\nfor col in all.columns:\n    if col.startswith(\"param_\") and len(all[col].unique())>1:\n        plt.figure(figsize=(12,6))\n\n        sns.boxplot(x=col, y=score_result, hue=split_col,data=all)\n        sns.swarmplot(x=col, y=score_result, color=\"red\",data=all)\n        plt.legend()\n        ax2 = plt.twinx()\n        sns.pointplot(x=col, y=score_result2,hue=split_col,ax=ax2, data=all)\n","cf3c5c23":"More on exploring pipelines:\n\nhttps:\/\/github.com\/DevScope\/ai-lab\/","28a1bf29":"# Sample train set","d65bdbf8":"# Test split","7257aa56":"# Prep Pipeline","f7184f42":"# Read Data","fe4e6825":"# Search Results","60daca62":"# Pipeline & Hyper param search","ea65eca7":"# Good luck!\n"}}