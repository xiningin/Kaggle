{"cell_type":{"637035c9":"code","c6147f41":"code","c7e7ad8a":"code","76c6ce52":"code","7bef9d69":"code","103a8709":"code","e6f82d4e":"code","0e00fce4":"code","fae53e57":"code","e360167d":"code","31251721":"code","9a555d70":"code","8b355f51":"code","78f5f156":"code","0fc7511e":"code","d601087a":"code","997ee607":"code","8e268878":"code","73cf2330":"code","b8409e31":"code","c45e215c":"code","95f2fd5f":"code","85602757":"code","a05eee16":"code","f523d034":"code","5e88d766":"code","34362b00":"code","df7f4941":"code","bcfd9dc5":"code","d15204bc":"code","c65b8007":"code","cf8c62ce":"markdown","f11ff7e6":"markdown"},"source":{"637035c9":"#!\/usr\/bin\/env python\n# coding: utf-8\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport os\nfrom time import time\nimport shutil\nimport argparse\nimport configparser\n#from model.ASTGCN_r import make_model\n#from lib.utils import load_graphdata_channel1, get_adjacency_matrix, compute_val_loss_mstgcn, predict_and_save_results_mstgcn\n#from tensorboardX import SummaryWriter\n#from lib.metrics import masked_mape_np,  masked_mae,masked_mse,masked_rmse","c6147f41":"\ndef load_graphdata_channel1(graph_signal_matrix_filename, num_of_hours, num_of_days, num_of_weeks, DEVICE, batch_size, shuffle=True):\n    '''\n    \u8fd9\u4e2a\u662f\u4e3aPEMS\u7684\u6570\u636e\u51c6\u5907\u7684\u51fd\u6570\n    \u5c06x,y\u90fd\u5904\u7406\u6210\u5f52\u4e00\u5316\u5230[-1,1]\u4e4b\u524d\u7684\u6570\u636e;\n    \u6bcf\u4e2a\u6837\u672c\u540c\u65f6\u5305\u542b\u6240\u6709\u76d1\u6d4b\u70b9\u7684\u6570\u636e\uff0c\u6240\u4ee5\u672c\u51fd\u6570\u6784\u9020\u7684\u6570\u636e\u8f93\u5165\u65f6\u7a7a\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff1b\n    \u8be5\u51fd\u6570\u4f1a\u628ahour, day, week\u7684\u65f6\u95f4\u4e32\u8d77\u6765\uff1b\n    \u6ce8\uff1a \u4ece\u6587\u4ef6\u8bfb\u5165\u7684\u6570\u636e\uff0cx\u662f\u6700\u5927\u6700\u5c0f\u5f52\u4e00\u5316\u7684\uff0c\u4f46\u662fy\u662f\u771f\u5b9e\u503c\n    \u8fd9\u4e2a\u51fd\u6570\u8f6c\u4e3amstgcn\uff0castgcn\u8bbe\u8ba1\uff0c\u8fd4\u56de\u7684\u6570\u636ex\u90fd\u662f\u901a\u8fc7\u51cf\u5747\u503c\u9664\u65b9\u5dee\u8fdb\u884c\u5f52\u4e00\u5316\u7684\uff0cy\u90fd\u662f\u771f\u5b9e\u503c\n    :param graph_signal_matrix_filename: str\n    :param num_of_hours: int\n    :param num_of_days: int\n    :param num_of_weeks: int\n    :param DEVICE:\n    :param batch_size: int\n    :return:\n    three DataLoaders, each dataloader contains:\n    test_x_tensor: (B, N_nodes, in_feature, T_input)\n    test_decoder_input_tensor: (B, N_nodes, T_output)\n    test_target_tensor: (B, N_nodes, T_output)\n    '''\n\n    file = os.path.basename(graph_signal_matrix_filename).split('.')[0]\n\n    dirpath = os.path.dirname(graph_signal_matrix_filename)\n\n    filename = os.path.join('..\/input\/prepare-pemsd4-dataset\/',\n                            file + '_r' + str(num_of_hours) + '_d' + str(num_of_days) + '_w' + str(num_of_weeks)) +'_astcgn'\n\n    print('load file:', filename)\n\n    file_data = np.load(filename + '.npz')\n    train_x = file_data['train_x']  # (10181, 307, 3, 12)\n    train_x = train_x[:, :, 0:1, :]\n    train_target = file_data['train_target']  # (10181, 307, 12)\n\n    val_x = file_data['val_x']\n    val_x = val_x[:, :, 0:1, :]\n    val_target = file_data['val_target']\n\n    test_x = file_data['test_x']\n    test_x = test_x[:, :, 0:1, :]\n    test_target = file_data['test_target']\n\n    mean = file_data['mean'][:, :, 0:1, :]  # (1, 1, 3, 1)\n    std = file_data['std'][:, :, 0:1, :]  # (1, 1, 3, 1)\n\n    # ------- train_loader -------\n    train_x_tensor = torch.from_numpy(train_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n    train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n\n    train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n\n    # ------- val_loader -------\n    val_x_tensor = torch.from_numpy(val_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n    val_target_tensor = torch.from_numpy(val_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n\n    val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    # ------- test_loader -------\n    test_x_tensor = torch.from_numpy(test_x).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n    test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n\n    test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    # print\n    print('train:', train_x_tensor.size(), train_target_tensor.size())\n    print('val:', val_x_tensor.size(), val_target_tensor.size())\n    print('test:', test_x_tensor.size(), test_target_tensor.size())\n\n    return train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, mean, std\n","c7e7ad8a":"adj_filename = '..\/input\/pems-dataset\/data\/PEMS04\/PEMS04.csv'\ngraph_signal_matrix_filename = '..\/input\/pems-dataset\/data\/PEMS04\/PEMS04.npz'\nnum_of_vertices = 307\npoints_per_hour = 12\nnum_for_predict = 12\nlen_input = 12\ndataset_name = 'PEMS04'\nid_filename = None\n\n\nctx = 0\nin_channels = 1\nnb_block = 2\nK = 3\nnb_chev_filter = 64\nnb_time_filter = 64\nbatch_size = 32\n\nnum_of_weeks = 0\nnum_of_days = 0\nnum_of_hours = 1\nstart_epoch = 0\nepochs = 3\nlearning_rate = 0.001\nmodel_name = 'astgcn_r'\nloss_function = 'mse'\nmetric_method = 'unmask'\nmissing_value=0.0\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = ctx\nUSE_CUDA = torch.cuda.is_available()\nDEVICE = torch.device('cuda:0')\nprint(\"CUDA:\", USE_CUDA, DEVICE)\ntime_strides = num_of_hours\n\n#folder_dir = '%s_h%dd%dw%d_channel%d_%e' % (model_name, num_of_hours, num_of_days, num_of_weeks, in_channels, learning_rate)\n#print('folder_dir:', folder_dir)\n#params_path = os.path.join('experiments', dataset_name, folder_dir)\n#print('params_path:', params_path)\n\n\n","76c6ce52":"train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(\n    graph_signal_matrix_filename, num_of_hours,\n    num_of_days, num_of_weeks, DEVICE, batch_size)","7bef9d69":"\ndef get_adjacency_matrix(distance_df_filename, num_of_vertices, id_filename=None):\n    '''\n    Parameters\n    ----------\n    distance_df_filename: str, path of the csv file contains edges information\n    num_of_vertices: int, the number of vertices\n    Returns\n    ----------\n    A: np.ndarray, adjacency matrix\n    '''\n    if 'npy' in distance_df_filename:\n\n        adj_mx = np.load(distance_df_filename)\n\n        return adj_mx, None\n\n    else:\n\n        import csv\n\n        A = np.zeros((int(num_of_vertices), int(num_of_vertices)),\n                     dtype=np.float32)\n\n        distaneA = np.zeros((int(num_of_vertices), int(num_of_vertices)),\n                            dtype=np.float32)\n\n        if id_filename:\n\n            with open(id_filename, 'r') as f:\n                id_dict = {int(i): idx for idx, i in enumerate(f.read().strip().split('\\n'))}  # \u628a\u8282\u70b9id\uff08idx\uff09\u6620\u5c04\u6210\u4ece0\u5f00\u59cb\u7684\u7d22\u5f15\n\n            with open(distance_df_filename, 'r') as f:\n                f.readline()\n                reader = csv.reader(f)\n                for row in reader:\n                    if len(row) != 3:\n                        continue\n                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n                    A[id_dict[i], id_dict[j]] = 1\n                    distaneA[id_dict[i], id_dict[j]] = distance\n            return A, distaneA\n\n        else:\n\n            with open(distance_df_filename, 'r') as f:\n                f.readline()\n                reader = csv.reader(f)\n                for row in reader:\n                    if len(row) != 3:\n                        continue\n                    i, j, distance = int(row[0]), int(row[1]), float(row[2])\n                    A[i, j] = 1\n                    distaneA[i, j] = distance\n            return A, distaneA\n\n","103a8709":"adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)","e6f82d4e":"# -*- coding:utf-8 -*-\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n","0e00fce4":"from scipy.sparse.linalg import eigs","fae53e57":"def scaled_Laplacian(W):\n    '''\n    compute \\tilde{L}\n    Parameters\n    ----------\n    W: np.ndarray, shape is (N, N), N is the num of vertices\n    Returns\n    ----------\n    scaled_Laplacian: np.ndarray, shape (N, N)\n    '''\n\n    assert W.shape[0] == W.shape[1]\n\n    D = np.diag(np.sum(W, axis=1))\n\n    L = D - W\n\n    lambda_max = eigs(L, k=1, which='LR')[0].real\n\n    return (2 * L) \/ lambda_max - np.identity(W.shape[0])\n\n\ndef cheb_polynomial(L_tilde, K):\n    '''\n    compute a list of chebyshev polynomials from T_0 to T_{K-1}\n    Parameters\n    ----------\n    L_tilde: scaled Laplacian, np.ndarray, shape (N, N)\n    K: the maximum order of chebyshev polynomials\n    Returns\n    ----------\n    cheb_polynomials: list(np.ndarray), length: K, from T_0 to T_{K-1}\n    '''\n\n    N = L_tilde.shape[0]\n\n    cheb_polynomials = [np.identity(N), L_tilde.copy()]\n\n    for i in range(2, K):\n        cheb_polynomials.append(2 * L_tilde * cheb_polynomials[i - 1] - cheb_polynomials[i - 2])\n\n    return cheb_polynomials\n","e360167d":"class Spatial_Attention_layer(nn.Module):\n    '''\n    compute spatial attention scores\n    '''\n    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n        super(Spatial_Attention_layer, self).__init__()\n        self.W1 = nn.Parameter(torch.FloatTensor(num_of_timesteps).to(DEVICE))\n        self.W2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_timesteps).to(DEVICE))\n        self.W3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n        self.bs = nn.Parameter(torch.FloatTensor(1, num_of_vertices, num_of_vertices).to(DEVICE))\n        self.Vs = nn.Parameter(torch.FloatTensor(num_of_vertices, num_of_vertices).to(DEVICE))\n\n\n    def forward(self, x):\n        '''\n        :param x: (batch_size, N, F_in, T)\n        :return: (B,N,N)\n        '''\n\n        lhs = torch.matmul(torch.matmul(x, self.W1), self.W2)  # (b,N,F,T)(T)->(b,N,F)(F,T)->(b,N,T)\n\n        rhs = torch.matmul(self.W3, x).transpose(-1, -2)  # (F)(b,N,F,T)->(b,N,T)->(b,T,N)\n\n        product = torch.matmul(lhs, rhs)  # (b,N,T)(b,T,N) -> (B, N, N)\n\n        S = torch.matmul(self.Vs, torch.sigmoid(product + self.bs))  # (N,N)(B, N, N)->(B,N,N)\n\n        S_normalized = F.softmax(S, dim=1)\n\n        return S_normalized\n\n\nclass cheb_conv_withSAt(nn.Module):\n    '''\n    K-order chebyshev graph convolution\n    '''\n\n    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n        '''\n        :param K: int\n        :param in_channles: int, num of channels in the input sequence\n        :param out_channels: int, num of channels in the output sequence\n        '''\n        super(cheb_conv_withSAt, self).__init__()\n        self.K = K\n        self.cheb_polynomials = cheb_polynomials\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.DEVICE = cheb_polynomials[0].device\n        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n\n    def forward(self, x, spatial_attention):\n        '''\n        Chebyshev graph convolution operation\n        :param x: (batch_size, N, F_in, T)\n        :return: (batch_size, N, F_out, T)\n        '''\n\n        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n\n        outputs = []\n\n        for time_step in range(num_of_timesteps):\n\n            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n\n            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n\n            for k in range(self.K):\n\n                T_k = self.cheb_polynomials[k]  # (N,N)\n\n                T_k_with_at = T_k.mul(spatial_attention)   # (N,N)*(N,N) = (N,N) \u591a\u884c\u548c\u4e3a1, \u6309\u7740\u5217\u8fdb\u884c\u5f52\u4e00\u5316\n\n                theta_k = self.Theta[k]  # (in_channel, out_channel)\n\n                rhs = T_k_with_at.permute(0, 2, 1).matmul(graph_signal)  # (N, N)(b, N, F_in) = (b, N, F_in) \u56e0\u4e3a\u662f\u5de6\u4e58\uff0c\u6240\u4ee5\u591a\u884c\u548c\u4e3a1\u53d8\u4e3a\u591a\u5217\u548c\u4e3a1\uff0c\u5373\u4e00\u884c\u4e4b\u548c\u4e3a1\uff0c\u8fdb\u884c\u5de6\u4e58\n\n                output = output + rhs.matmul(theta_k)  # (b, N, F_in)(F_in, F_out) = (b, N, F_out)\n\n            outputs.append(output.unsqueeze(-1))  # (b, N, F_out, 1)\n\n        return F.relu(torch.cat(outputs, dim=-1))  # (b, N, F_out, T)\n\n\nclass Temporal_Attention_layer(nn.Module):\n    def __init__(self, DEVICE, in_channels, num_of_vertices, num_of_timesteps):\n        super(Temporal_Attention_layer, self).__init__()\n        self.U1 = nn.Parameter(torch.FloatTensor(num_of_vertices).to(DEVICE))\n        self.U2 = nn.Parameter(torch.FloatTensor(in_channels, num_of_vertices).to(DEVICE))\n        self.U3 = nn.Parameter(torch.FloatTensor(in_channels).to(DEVICE))\n        self.be = nn.Parameter(torch.FloatTensor(1, num_of_timesteps, num_of_timesteps).to(DEVICE))\n        self.Ve = nn.Parameter(torch.FloatTensor(num_of_timesteps, num_of_timesteps).to(DEVICE))\n\n    def forward(self, x):\n        '''\n        :param x: (batch_size, N, F_in, T)\n        :return: (B, T, T)\n        '''\n        _, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n\n        lhs = torch.matmul(torch.matmul(x.permute(0, 3, 2, 1), self.U1), self.U2)\n        # x:(B, N, F_in, T) -> (B, T, F_in, N)\n        # (B, T, F_in, N)(N) -> (B,T,F_in)\n        # (B,T,F_in)(F_in,N)->(B,T,N)\n\n        rhs = torch.matmul(self.U3, x)  # (F)(B,N,F,T)->(B, N, T)\n\n        product = torch.matmul(lhs, rhs)  # (B,T,N)(B,N,T)->(B,T,T)\n\n        E = torch.matmul(self.Ve, torch.sigmoid(product + self.be))  # (B, T, T)\n\n        E_normalized = F.softmax(E, dim=1)\n\n        return E_normalized\n\n\nclass cheb_conv(nn.Module):\n    '''\n    K-order chebyshev graph convolution\n    '''\n\n    def __init__(self, K, cheb_polynomials, in_channels, out_channels):\n        '''\n        :param K: int\n        :param in_channles: int, num of channels in the input sequence\n        :param out_channels: int, num of channels in the output sequence\n        '''\n        super(cheb_conv, self).__init__()\n        self.K = K\n        self.cheb_polynomials = cheb_polynomials\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.DEVICE = cheb_polynomials[0].device\n        self.Theta = nn.ParameterList([nn.Parameter(torch.FloatTensor(in_channels, out_channels).to(self.DEVICE)) for _ in range(K)])\n\n    def forward(self, x):\n        '''\n        Chebyshev graph convolution operation\n        :param x: (batch_size, N, F_in, T)\n        :return: (batch_size, N, F_out, T)\n        '''\n\n        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape\n\n        outputs = []\n\n        for time_step in range(num_of_timesteps):\n\n            graph_signal = x[:, :, :, time_step]  # (b, N, F_in)\n\n            output = torch.zeros(batch_size, num_of_vertices, self.out_channels).to(self.DEVICE)  # (b, N, F_out)\n\n            for k in range(self.K):\n\n                T_k = self.cheb_polynomials[k]  # (N,N)\n\n                theta_k = self.Theta[k]  # (in_channel, out_channel)\n\n                rhs = graph_signal.permute(0, 2, 1).matmul(T_k).permute(0, 2, 1)\n\n                output = output + rhs.matmul(theta_k)\n\n            outputs.append(output.unsqueeze(-1))\n\n        return F.relu(torch.cat(outputs, dim=-1))\n\n\nclass ASTGCN_block(nn.Module):\n\n    def __init__(self, DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, num_of_timesteps):\n        super(ASTGCN_block, self).__init__()\n        self.TAt = Temporal_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n        self.SAt = Spatial_Attention_layer(DEVICE, in_channels, num_of_vertices, num_of_timesteps)\n        self.cheb_conv_SAt = cheb_conv_withSAt(K, cheb_polynomials, in_channels, nb_chev_filter)\n        self.time_conv = nn.Conv2d(nb_chev_filter, nb_time_filter, kernel_size=(1, 3), stride=(1, time_strides), padding=(0, 1))\n        self.residual_conv = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n        self.ln = nn.LayerNorm(nb_time_filter)  #\u9700\u8981\u5c06channel\u653e\u5230\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\n\n    def forward(self, x):\n        '''\n        :param x: (batch_size, N, F_in, T)\n        :return: (batch_size, N, nb_time_filter, T)\n        '''\n        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n\n        # TAt\n        temporal_At = self.TAt(x)  # (b, T, T)\n\n        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n\n        # SAt\n        spatial_At = self.SAt(x_TAt)\n\n        # cheb gcn\n        spatial_gcn = self.cheb_conv_SAt(x, spatial_At)  # (b,N,F,T)\n        # spatial_gcn = self.cheb_conv(x)\n\n        # convolution along the time axis\n        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) \u7528(1,3)\u7684\u5377\u79ef\u6838\u53bb\u505a->(b,F,N,T)\n\n        # residual shortcut\n        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) \u7528(1,1)\u7684\u5377\u79ef\u6838\u53bb\u505a->(b,F,N,T)\n\n        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n\n        return x_residual\n\n\nclass ASTGCN_submodule(nn.Module):\n\n    def __init__(self, DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices):\n        '''\n        :param nb_block:\n        :param in_channels:\n        :param K:\n        :param nb_chev_filter:\n        :param nb_time_filter:\n        :param time_strides:\n        :param cheb_polynomials:\n        :param nb_predict_step:\n        '''\n\n        super(ASTGCN_submodule, self).__init__()\n\n        self.BlockList = nn.ModuleList([ASTGCN_block(DEVICE, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_of_vertices, len_input)])\n\n        self.BlockList.extend([ASTGCN_block(DEVICE, nb_time_filter, K, nb_chev_filter, nb_time_filter, 1, cheb_polynomials, num_of_vertices, len_input\/\/time_strides) for _ in range(nb_block-1)])\n\n        self.final_conv = nn.Conv2d(int(len_input\/time_strides), num_for_predict, kernel_size=(1, nb_time_filter))\n\n        self.DEVICE = DEVICE\n\n        self.to(DEVICE)\n\n    def forward(self, x):\n        '''\n        :param x: (B, N_nodes, F_in, T_in)\n        :return: (B, N_nodes, T_out)\n        '''\n        for block in self.BlockList:\n            x = block(x)\n\n        output = self.final_conv(x.permute(0, 3, 1, 2))[:, :, :, -1].permute(0, 2, 1)\n        # (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T)\n\n        return output\n\n\ndef make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx, num_for_predict, len_input, num_of_vertices):\n    '''\n    :param DEVICE:\n    :param nb_block:\n    :param in_channels:\n    :param K:\n    :param nb_chev_filter:\n    :param nb_time_filter:\n    :param time_strides:\n    :param cheb_polynomials:\n    :param nb_predict_step:\n    :param len_input\n    :return:\n    '''\n    L_tilde = scaled_Laplacian(adj_mx)\n    cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n    model = ASTGCN_submodule(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, cheb_polynomials, num_for_predict, len_input, num_of_vertices)\n\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n        else:\n            nn.init.uniform_(p)\n\n    return model","31251721":"net = make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx,  num_for_predict, len_input, num_of_vertices)\n","9a555d70":"\nprint('param list:')\nprint('CUDA\\t', DEVICE)\nprint('in_channels\\t', in_channels)\nprint('nb_block\\t', nb_block)\nprint('nb_chev_filter\\t', nb_chev_filter)\nprint('nb_time_filter\\t', nb_time_filter)\nprint('time_strides\\t', time_strides)\nprint('batch_size\\t', batch_size)\nprint('graph_signal_matrix_filename\\t', graph_signal_matrix_filename)\nprint('start_epoch\\t', start_epoch)\nprint('epochs\\t', epochs)","8b355f51":"\ndef masked_mae(preds, labels, null_val=np.nan):\n    if np.isnan(null_val):\n        mask = ~torch.isnan(labels)\n    else:\n        mask = (labels != null_val)\n    mask = mask.float()\n    mask \/= torch.mean((mask))\n    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n    loss = torch.abs(preds - labels)\n    loss = loss * mask\n    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n    return torch.mean(loss)\n","78f5f156":"\nmasked_flag=0\ncriterion = nn.L1Loss().to(DEVICE)\ncriterion_masked = masked_mae\n","0fc7511e":"if loss_function=='masked_mse':\n    criterion_masked = masked_mse         #nn.MSELoss().to(DEVICE)\n    masked_flag=1\nelif loss_function=='masked_mae':\n    criterion_masked = masked_mae\n    masked_flag = 1\nelif loss_function == 'mae':\n    criterion = nn.L1Loss().to(DEVICE)\n    masked_flag = 0\nelif loss_function == 'rmse':\n    criterion = nn.MSELoss().to(DEVICE)\n    masked_flag= 0","d601087a":"optimizer = optim.Adam(net.parameters(), lr=learning_rate)","997ee607":"print(net)","8e268878":"print('Net\\'s state_dict:')\ntotal_param = 0\nfor param_tensor in net.state_dict():\n    print(param_tensor, '\\t', net.state_dict()[param_tensor].size())\n    total_param += np.prod(net.state_dict()[param_tensor].size())\nprint('Net\\'s total params:', total_param)","73cf2330":"print('Optimizer\\'s state_dict:')\nfor var_name in optimizer.state_dict():\n    print(var_name, '\\t', optimizer.state_dict()[var_name])\n","b8409e31":"global_step = 0\nbest_epoch = 0\nbest_val_loss = np.inf\n\nstart_time = time()\n","c45e215c":"\ndef compute_val_loss_mstgcn(net, val_loader, criterion,  masked_flag,missing_value,sw, epoch, limit=None):\n    '''\n    for rnn, compute mean loss on validation set\n    :param net: model\n    :param val_loader: torch.utils.data.utils.DataLoader\n    :param criterion: torch.nn.MSELoss\n    :param sw: tensorboardX.SummaryWriter\n    :param global_step: int, current global_step\n    :param limit: int,\n    :return: val_loss\n    '''\n\n    net.train(False)  # ensure dropout layers are in evaluation mode\n\n    with torch.no_grad():\n\n        val_loader_length = len(val_loader)  # nb of batch\n\n        tmp = []  # \u8bb0\u5f55\u4e86\u6240\u6709batch\u7684loss\n\n        for batch_index, batch_data in enumerate(val_loader):\n            encoder_inputs, labels = batch_data\n            outputs = net(encoder_inputs)\n            if masked_flag:\n                loss = criterion(outputs, labels, missing_value)\n            else:\n                loss = criterion(outputs, labels)\n\n            tmp.append(loss.item())\n            if batch_index % 100 == 0:\n                print('validation batch %s \/ %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n            if (limit is not None) and batch_index >= limit:\n                break\n\n        validation_loss = sum(tmp) \/ len(tmp)\n        sw.add_scalar('validation_loss', validation_loss, epoch)\n    return validation_loss\n","95f2fd5f":"from tensorboardX import SummaryWriter\nsw = SummaryWriter(logdir='.', flush_secs=5)","85602757":"# train model\nfor epoch in range(start_epoch, epochs):\n    params_filename = os.path.join('.\/', 'epoch_%s.params' % epoch)\n\n    if masked_flag:\n        val_loss = compute_val_loss_mstgcn(net, val_loader, criterion_masked, masked_flag,missing_value,sw, epoch)\n    else:\n        val_loss = compute_val_loss_mstgcn(net, val_loader, criterion, masked_flag, missing_value, sw, epoch)\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_epoch = epoch\n        torch.save(net.state_dict(), params_filename)\n        print('save parameters to file: %s' % params_filename)\n\n    net.train()  # ensure dropout layers are in train mode\n\n    for batch_index, batch_data in enumerate(train_loader):\n        encoder_inputs, labels = batch_data\n        optimizer.zero_grad()\n        outputs = net(encoder_inputs)\n        if masked_flag:\n            loss = criterion_masked(outputs, labels,missing_value)\n        else :\n            loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        training_loss = loss.item()\n        global_step += 1\n        sw.add_scalar('training_loss', training_loss, global_step)\n\n        if global_step % 1000 == 0:\n            print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step, training_loss, time() - start_time))\n","a05eee16":"print('best epoch:', best_epoch)","f523d034":"params_path = '.\/'","5e88d766":"\ndef re_normalization(x, mean, std):\n    x = x * std + mean\n    return x\n","34362b00":"def masked_mape_np(y_true, y_pred, null_val=np.nan):\n    with np.errstate(divide='ignore', invalid='ignore'):\n        if np.isnan(null_val):\n            mask = ~np.isnan(y_true)\n        else:\n            mask = np.not_equal(y_true, null_val)\n        mask = mask.astype('float32')\n        mask \/= np.mean(mask)\n        mape = np.abs(np.divide(np.subtract(y_pred, y_true).astype('float32'),\n                      y_true))\n        mape = np.nan_to_num(mask * mape)\n        return np.mean(mape)\n","df7f4941":"def predict_and_save_results_mstgcn(net, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type):\n    '''\n    :param net: nn.Module\n    :param data_loader: torch.utils.data.utils.DataLoader\n    :param data_target_tensor: tensor\n    :param epoch: int\n    :param _mean: (1, 1, 3, 1)\n    :param _std: (1, 1, 3, 1)\n    :param params_path: the path for saving the results\n    :return:\n    '''\n    net.train(False)  # ensure dropout layers are in test mode\n\n    with torch.no_grad():\n\n        data_target_tensor = data_target_tensor.cpu().numpy()\n\n        loader_length = len(data_loader)  # nb of batch\n\n        prediction = []  # \u5b58\u50a8\u6240\u6709batch\u7684output\n\n        input = []  # \u5b58\u50a8\u6240\u6709batch\u7684input\n\n        for batch_index, batch_data in enumerate(data_loader):\n\n            encoder_inputs, labels = batch_data\n\n            input.append(encoder_inputs[:, :, 0:1].cpu().numpy())  # (batch, T', 1)\n\n            outputs = net(encoder_inputs)\n\n            prediction.append(outputs.detach().cpu().numpy())\n\n            if batch_index % 100 == 0:\n                print('predicting data set batch %s \/ %s' % (batch_index + 1, loader_length))\n\n        input = np.concatenate(input, 0)\n\n        input = re_normalization(input, _mean, _std)\n\n        prediction = np.concatenate(prediction, 0)  # (batch, T', 1)\n\n        print('input:', input.shape)\n        print('prediction:', prediction.shape)\n        print('data_target_tensor:', data_target_tensor.shape)\n        output_filename = os.path.join(params_path, 'output_epoch_%s_%s' % (global_step, type))\n        np.savez(output_filename, input=input, prediction=prediction, data_target_tensor=data_target_tensor)\n\n        # \u8ba1\u7b97\u8bef\u5dee\n        excel_list = []\n        prediction_length = prediction.shape[2]\n\n        for i in range(prediction_length):\n            assert data_target_tensor.shape[0] == prediction.shape[0]\n            print('current epoch: %s, predict %s points' % (global_step, i))\n            if metric_method == 'mask':\n                mae = masked_mae_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n                rmse = masked_rmse_test(data_target_tensor[:, :, i], prediction[:, :, i],0.0)\n                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n            else :\n                mae = mean_absolute_error(data_target_tensor[:, :, i], prediction[:, :, i])\n                rmse = mean_squared_error(data_target_tensor[:, :, i], prediction[:, :, i]) ** 0.5\n                mape = masked_mape_np(data_target_tensor[:, :, i], prediction[:, :, i], 0)\n            print('MAE: %.2f' % (mae))\n            print('RMSE: %.2f' % (rmse))\n            print('MAPE: %.2f' % (mape))\n            excel_list.extend([mae, rmse, mape])\n\n        # print overall results\n        if metric_method == 'mask':\n            mae = masked_mae_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n            rmse = masked_rmse_test(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0.0)\n            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n        else :\n            mae = mean_absolute_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1))\n            rmse = mean_squared_error(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1)) ** 0.5\n            mape = masked_mape_np(data_target_tensor.reshape(-1, 1), prediction.reshape(-1, 1), 0)\n        print('all MAE: %.2f' % (mae))\n        print('all RMSE: %.2f' % (rmse))\n        print('all MAPE: %.2f' % (mape))\n        excel_list.extend([mae, rmse, mape])\n        print(excel_list)","bcfd9dc5":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error","d15204bc":"def predict_main(global_step, data_loader, data_target_tensor,metric_method, _mean, _std, type):\n    '''\n    :param global_step: int\n    :param data_loader: torch.utils.data.utils.DataLoader\n    :param data_target_tensor: tensor\n    :param mean: (1, 1, 3, 1)\n    :param std: (1, 1, 3, 1)\n    :param type: string\n    :return:\n    '''\n\n    params_filename = os.path.join('.\/', 'epoch_%s.params' % global_step)\n    print('load weight from:', params_filename)\n\n    net.load_state_dict(torch.load(params_filename))\n\n    predict_and_save_results_mstgcn(net, data_loader, data_target_tensor, global_step, metric_method,_mean, _std, params_path, type)","c65b8007":"# apply the best model on the test set\npredict_main(best_epoch, test_loader, test_target_tensor,metric_method ,_mean, _std, 'test')\n\n","cf8c62ce":"# Making the model","f11ff7e6":"<h1>\n<center>Rewriting the code accompanying the paper<\/center>\n<\/h1>\n<h1>\n<center>Attention Based Spatial-Temporal Graph Convolutional Networks\nfor Traffic Flow Forecasting<\/center>\n<\/h1>\n\n<h1>\nIn this notebook we will dive into attentional temporal graph convolution networks where everything new meets Attention + deep learning time series analysis( temporal data) + Graph convolution all in one thing.. I will add more comments to explain the code next week."}}