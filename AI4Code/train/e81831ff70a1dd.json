{"cell_type":{"7337a905":"code","476e5a4b":"code","acedccac":"code","f33afea3":"code","cf66fe79":"code","108f404f":"code","1d44ee91":"code","9b3e8723":"code","5d76b97c":"code","974f6ef6":"code","93053e38":"code","59a8b5e2":"code","e3713165":"code","37586e65":"code","1b4b3678":"code","527181fe":"code","a634bdd5":"code","52f4c70d":"code","e248d5ed":"code","31649e32":"code","1d6ce3b4":"code","f8f98109":"code","6452a886":"code","13e0a304":"code","a8658be0":"code","80e61331":"code","4f267d1d":"markdown","298b73d7":"markdown","08cd681e":"markdown","0fd82b81":"markdown","64f76198":"markdown","45d7faba":"markdown","30b14c99":"markdown","b614359a":"markdown","3f3c9881":"markdown","878566ce":"markdown","08bb4a77":"markdown","246005ab":"markdown","9bc0cebb":"markdown","249daa27":"markdown","ba283f50":"markdown","c7fe7700":"markdown","5e3a3108":"markdown","220575ab":"markdown","38db4aaa":"markdown","c6866349":"markdown","c8ad78bb":"markdown","2727cc27":"markdown","0dcf863f":"markdown","9fec4adf":"markdown","e43019df":"markdown","a8a6fee4":"markdown","6ed4d622":"markdown","35a11960":"markdown"},"source":{"7337a905":"import pandas as pd\n\ndata = pd.read_csv(\"..\/input\/supermarket-sales\/supermarket_sales - Sheet1.csv\")","476e5a4b":"data.isnull().sum()","acedccac":"# Convertinf the Date column into a usable format:\ndata['Date'] = pd.to_datetime(data.Date)","f33afea3":"data['day'] = data['Date'].dt.day.astype('object')\n\ndata['month'] = data['Date'].dt.month.astype('object')\n\ndata['year'] = data['Date'].dt.year.astype('object')","cf66fe79":"data.apply(pd.Series.nunique)","108f404f":"data.drop(['Date', 'year', 'Tax 5%', 'gross margin percentage', 'Branch', 'Invoice ID'], axis=1, inplace=True)","1d44ee91":"data['Time'] = pd.to_datetime(data.Time)\ndata['hour'] = data['Time'].dt.hour.astype('object')","9b3e8723":"data.drop(['Time'], inplace=True, axis=1)","5d76b97c":"data.head()","974f6ef6":"# Making another smaller dataset for later use:\nnewdataset = data[:200]","93053e38":"labels = pd.Series(newdataset['Total'])","59a8b5e2":"cbedata = newdataset.copy()\n\n# Defining the categorical columns: \ncatcols = ['City', 'Customer type', 'Gender', 'Product line', 'day', 'month', 'hour', 'Payment']\n\n# Importing CatBoostEncoder\nfrom category_encoders import CatBoostEncoder\n\nce = CatBoostEncoder()\n\n# Fitting it on the data:\nce.fit(cbedata[catcols], labels)\n\n# Transforming the data:\ncbedata[catcols] = ce.transform(cbedata[catcols])","e3713165":"cbedata.head()","37586e65":"from sklearn.preprocessing import StandardScaler\n\nscale = StandardScaler()\n\nscaleddata = pd.DataFrame(scale.fit_transform(cbedata), columns=cbedata.columns)","1b4b3678":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(30,10))\nsns.set_context('poster', font_scale=0.7)\nsns.heatmap(scaleddata.corr(), annot=True)","527181fe":"plt.figure(figsize=(20,7))\nsns.countplot(data = newdataset, x = 'day')","a634bdd5":"plt.figure(figsize=(15, 7))\nsns.set_palette(['skyblue'])\nsns.scatterplot(data = newdataset, x = 'gross income', y = 'Unit price')","52f4c70d":"from sklearn.cluster import KMeans\n\nkms = KMeans(n_clusters=4, init=\"k-means++\")\n\nkcluster = pd.DataFrame(kms.fit_predict(cbedata), columns=['kcluster'])","e248d5ed":"plt.figure(figsize=(15,7))\nsns.set_context(\"poster\")\nsns.scatterplot(data=clustereddata, x='Unit price',\n                y='gross income', hue='kcluster')","31649e32":"richcustomers = clustereddata.loc[clustereddata['kcluster'] == 0]\nnotrichcustomers = clustereddata.loc[clustereddata['kcluster'] == 2]","1d6ce3b4":"plt.figure(figsize=(15,5))\nsns.set_context(\"poster\", font_scale=.7)\nsns.countplot(richcustomers['City'])","f8f98109":"plt.figure(figsize=(15,5))\nsns.set_context(\"poster\", font_scale=.5)\nsns.countplot(richcustomers['Product line'])","6452a886":"plt.figure(figsize=(15,5))\nsns.set_context(\"poster\", font_scale=.5)\nsns.set_palette(['red'])\nsns.distplot(richcustomers['Total'])","13e0a304":"plt.figure(figsize=(15,5))\nsns.set_context(\"poster\", font_scale=.5)\nsns.distplot(notrichcustomers['Total'])\nplt.xlim(right=1200)","a8658be0":"plt.figure(figsize=(20,7))\nplt\nsns.countplot(richcustomers['day'])","80e61331":"plt.figure(figsize=(20,7))\nsns.countplot(notrichcustomers['day'])","4f267d1d":"What if we used KMeans clustering algorithm, to understand the data better:","298b73d7":"Comparing the total value of items bought by the wealthy and the thrifters:","08cd681e":"Checking the columns for their cardinality:","0fd82b81":"Checking the DataSet for null values:","64f76198":"Lets make the time and date columns usable:","45d7faba":"Here is a plot for the gross income and unit price of the items bought.","30b14c99":"Thank you for going through this notebook. Hit me up in the comments if you feel that I could have improved somewhere. Upvote if you liked it.","b614359a":"Seperating out the wealthy from the thrifters:","3f3c9881":"Clearly the clustering algorithm (KMeans with k-means++ initialisation) is working fine. The wealthy customers pay way more than the thrifters and this can be clearly seen in the distributions.","878566ce":"In this notebook I make sense out of data about the items sold in a supermarket. Its not my first time but yet I fear that I will not be able to find insights, atleast there's no loss in trying tho. ","08bb4a77":"# Heatmap:","246005ab":"Plotting the countplot for the customers from each of the cities:","9bc0cebb":"I would be defining the labels for lets say a very basic regression model. Let the labels be the quantity of good that the customers have purchased.","249daa27":"The heatmap has already shown that there is a correlation of 0.69, which means both are directly related. It is wrong to assume that correlation indicates causation but using common sense it would be arguably evident that the following:\n* The cluster of data points, thins in its density around low gross income and high unit price (instances do exist there though).\n* The cluster of data points, is heavy in its density around the high gross income and high unit price (density is higher as compared to low gross income).\n* People with higher gross incomes seem to be able to afford items of higher unit price.\n","ba283f50":"Checking what exactly do the wealthy customers buy:","c7fe7700":"Redefining the Time column and adding the column 'hour':","5e3a3108":"Standardization is a another reprocessing tool which transforms all the numerical values (assuming that the whole dataset is just numerical values) into values between -1 and 1. This increases the processing speed and makes using algorithms on the data easier.","220575ab":"# Preprocessing the Data:","38db4aaa":"This heatmap looks like a mine for insights. There is a high positive correlation between the gross income and total as well as gross income and quantity but lets not stop working with the data just here. \n\nThere is a decent correlation between the days and total amount earned from a sale which might suggest that on some particular day(s) of the month the sales are higher than usual.","c6866349":"Dropping Time column because well it is now useless:","c8ad78bb":"# Reading the Data:","2727cc27":"Taking a look at this beauty:","0dcf863f":"Lets look at the sales on different days:","9fec4adf":"Clearly, what is clearly visible here is that the supermarket gets more visitors during particular days of the month.\n\nIn the case of the wealthy customers the peak day of all three months is the 28th and 29th day of the respective month.\n\nIn the case of the thrift shoppers, the peak day of each month is the 10th day of the month.","e43019df":"Finally adding the columns for day of the month, month and year:","a8a6fee4":"# Further Data Visualisation:","6ed4d622":"# Clustering the Data:","35a11960":"It looks like the column year has just a single value, thus it has to be removed since it adds no value to our dataset. Also the date, Tax 5% and some other columns in their original format seem useless so lets drop them. Lets make a point to not remove Invoice Id in real life as Invoice Ids would help in identifying valuable customers from thrifters after segmentation."}}