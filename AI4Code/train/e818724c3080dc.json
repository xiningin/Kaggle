{"cell_type":{"799d868f":"code","eb850856":"code","e37b64c5":"code","09159af5":"code","9ad0e20d":"code","e00a379e":"code","727c7151":"code","07e3bf13":"code","6dff6ff9":"code","7fdb82a1":"code","a4e54740":"code","b96e6fd9":"code","ef3ca30c":"code","95ce06b0":"code","c266c5da":"code","d2870c24":"code","01046350":"code","0ff83bb4":"code","16d3130f":"code","80183cf9":"code","85db611e":"code","52cce06e":"code","822a9d0e":"code","22e9b531":"code","8d4c4bd4":"code","ea311adb":"code","d0a28a10":"code","fcb900b8":"code","ac369fa5":"markdown","8f69c713":"markdown","501d5e59":"markdown","8929cf8e":"markdown","8b53e9e4":"markdown","f90fcf7d":"markdown","62e5d5b5":"markdown","7946369d":"markdown"},"source":{"799d868f":"#Importing the packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_absolute_error","eb850856":"dataset = pd.read_csv('..\/input\/irisdataset\/iris.csv')","e37b64c5":"dataset.head() #first five rows","09159af5":"dataset.shape #dimension of dataset","9ad0e20d":"dataset.dtypes #type of every variable","e00a379e":"dataset['variety']=dataset['variety'].astype('category') ","727c7151":"dataset.isnull().sum() #how many misssing values we have","07e3bf13":"dataset.info()","6dff6ff9":"dataset.variety.value_counts() #frequency by category of dependent variable","7fdb82a1":"dataset.describe() #basic statistics","a4e54740":"#Boxplots for each independent variable\ndataset.plot(kind='box')","b96e6fd9":"#Box plots by variety category\ndataset.boxplot(by=\"variety\",figsize=(10,10))","ef3ca30c":"#Histograms for every numerical variable:\ndataset.hist(figsize=(10,5))\nplt.show()","95ce06b0":"#Plots by category\nsns.pairplot(dataset,hue=\"variety\")","c266c5da":"#Preparing data to the split\nX = dataset.iloc[:,:4]\ny = dataset.variety\n\n#Splitting the dataset into the train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 5)\nprint(\"X_train:\",X_train.shape,\n      '\\n',\"X_test:\",X_test.shape,\n      '\\n',\"y_train:\",y_train.shape,\n      '\\n',\"y_test:\",y_test.shape)","d2870c24":"#Decision Tree\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy is:',accuracy_score(y_pred,y_test))\npd.concat([X_test, y_test, pd.Series(y_pred, name='predicted', index=X_test.index)], \n          ignore_index=False, axis=1)\n","01046350":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","0ff83bb4":"#Random Forest\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy is:',accuracy_score(y_pred,y_test))\npd.concat([X_test, y_test, pd.Series(y_pred, name='predicted', index=X_test.index)], \n          ignore_index=False, axis=1)","16d3130f":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","80183cf9":"#K-Nearest Neighbours\nmodel2 = KNeighborsClassifier(n_neighbors=2)\nmodel2.fit(X_train, y_train)\ny_pred = model2.predict(X_test)\nprint('Accuracy is:',accuracy_score(y_pred,y_test))\npd.concat([X_test, y_test, pd.Series(y_pred, name='predicted', index=X_test.index)], \n          ignore_index=False, axis=1)","85db611e":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","52cce06e":"#How many neighbors we need?\nscores = []\nfor n in range(1,15):\n    model = KNeighborsClassifier(n_neighbors=n)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    scores.append(accuracy_score(y_pred,y_test))\n    \nplt.plot(range(1,15), scores)\nplt.xlabel('Number of neighbors')\nplt.ylabel('Accuracy')\nplt.show()","822a9d0e":"#Let's try one more time with 8 neighbors\nmodel3 = KNeighborsClassifier(n_neighbors=8)\nmodel3.fit(X_train, y_train)\ny_pred = model3.predict(X_test)\nprint('Accuracy is:',accuracy_score(y_pred,y_test))\npd.concat([X_test, y_test, pd.Series(y_pred, name='predicted', index=X_test.index)], \n          ignore_index=False, axis=1)","22e9b531":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","8d4c4bd4":"#Support Vector Machine\nfrom sklearn.svm import SVC\nmodel5=SVC()\nmodel5.fit(X_train, y_train)\ny_pred = model5.predict(X_test)\nprint('Accuracy is:',accuracy_score(y_pred,y_test))\npd.concat([X_test, y_test, pd.Series(y_pred, name='predicted', index=X_test.index)], \n          ignore_index=False, axis=1)","ea311adb":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","d0a28a10":"#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nmodel6 = GaussianNB()\nmodel6.fit(X_train, y_train)\ny_pred = model6.predict(X_test)\nprint('Accuracy is:',accuracy_score(y_pred,y_test))\npd.concat([X_test, y_test, pd.Series(y_pred, name='predicted', index=X_test.index)], \n          ignore_index=False, axis=1)\n","fcb900b8":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","ac369fa5":"##**Classification models**\n1. Decision Tree\n2. Random Forest\n3. K-Nearest Neighbours\n4. Support Vector Machine\n5. Naive Bayes","8f69c713":"This dataset has 150 observations and 5 variables.\nWe have here 4 numerical features: sepal length, sepal width, petal length and petal width. Variety is a dependent variable with three categories, each of them have a 50 observations.\nWe don't have to worry about missing data.\n","501d5e59":"Classification models on Iris dataset with Python (first exercise).","8929cf8e":"##**Visualization**","8b53e9e4":"**Getting Data**","f90fcf7d":"##**Understanding a dataset**","62e5d5b5":"Trying a few different models on train and test dataset:","7946369d":"**Introduction**\n\nThe data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n(source: Wikipedia)"}}