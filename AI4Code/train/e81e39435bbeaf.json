{"cell_type":{"c676128f":"code","82bd3ed4":"code","07dcbcb0":"code","a80df61d":"code","703b1c1c":"code","053248ef":"code","dc782356":"code","330bf90d":"code","384483b1":"code","21e978ec":"code","8015333a":"code","961d958a":"code","f7a4c298":"code","22e69640":"code","8fd07f50":"code","d96f59cf":"code","8485811d":"code","e4bc613f":"code","e4064786":"code","e6c8897c":"code","9ad15e16":"code","e874bf4e":"code","2dff12ef":"code","cbf244cb":"code","6de36fd1":"code","a72b0593":"code","e8cc7cda":"code","d4bffd2e":"code","dfd8db9d":"code","de7498f7":"code","08430a43":"code","0fbd9318":"code","7e12bd35":"code","2966382e":"code","0eb7fa95":"code","1dc404df":"code","7d29380a":"code","c3670d5b":"code","42d18cb3":"markdown","33e0cfce":"markdown","445bf45a":"markdown","a31598ad":"markdown","038de044":"markdown","cbfcc119":"markdown","c697716e":"markdown","e58d5fc0":"markdown","1a2d0fb8":"markdown","6c667200":"markdown","d768e424":"markdown","73392597":"markdown","0613e475":"markdown","986ab1e8":"markdown","6ca9e6de":"markdown","a9c23b15":"markdown","b4ba0f45":"markdown","e5e07048":"markdown","cf65f4e1":"markdown"},"source":{"c676128f":"import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport spacy\nfrom sklearn.model_selection import train_test_split","82bd3ed4":"df_train = pd.read_csv(\"\/kaggle\/input\/predict-categories-of-items-using-nlp\/training_data.csv\")\ndf_train.head()","07dcbcb0":"df_test = pd.read_csv(\"\/kaggle\/input\/predict-categories-of-items-using-nlp\/testing_data.csv\")\ndf_test","a80df61d":"df_train.isnull().sum()\n\n# No Null Values","703b1c1c":"df_train.shape","053248ef":"df_train.category.value_counts()","dc782356":"df_train.category.replace(to_replace=['None'], value=np.nan, inplace=True)","330bf90d":"df_train.isnull().sum()","384483b1":"df_train.dropna(inplace=True)","21e978ec":"df_train.shape","8015333a":"blanks = []\n\nfor i,l,r in df_train.itertuples():\n    if type(r) == str:\n        if r.isspace():\n            blanks.append(i)\n            \nprint(blanks)","961d958a":"# feature\nX = df_train['title']\n\n# label\ny = df_train['category']","f7a4c298":"# Train-Test Split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","22e69640":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC","8fd07f50":"model1 = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])","d96f59cf":"model1.fit(X_train, y_train)","8485811d":"prediction1 = model1.predict(X_test)","e4bc613f":"print(confusion_matrix(y_test, prediction1))","e4064786":"print(classification_report(y_test, prediction1))","e6c8897c":"print(accuracy_score(y_test, prediction1))","9ad15e16":"from sklearn.model_selection import GridSearchCV","e874bf4e":"model_grid_search = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC(random_state=42))])\n\nparameters = [{\n    'tfidf__max_df': (0.25, 0.5, 0.75),\n    'tfidf__max_features': (None, 5000, 10000, 50000),\n    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\n},{\n    'clf__C': [0.00001, 0.0001, 0.0005],\n    'clf__dual': (True, False)\n}]\n\ngrid_search = GridSearchCV(estimator=model_grid_search, param_grid=parameters, verbose=1, n_jobs=-1, cv=4)","2dff12ef":"grid_search.fit(X_train, y_train)","cbf244cb":"grid_search.best_estimator_","6de36fd1":"grid_search.best_score_","a72b0593":"grid_search.best_params_","e8cc7cda":"model2 = Pipeline([('tfidf', TfidfVectorizer(max_df=0.25,\n                                               max_features=50000,\n                                              ngram_range=(1,2))),\n                     ('clf', LinearSVC(random_state=42))\n                    ])","d4bffd2e":"model2.fit(X_train, y_train)","dfd8db9d":"prediction2 = model2.predict(X_test)","de7498f7":"print(confusion_matrix(y_test, prediction2))","08430a43":"print(classification_report(y_test, prediction2))","0fbd9318":"print(accuracy_score(y_test, prediction2))","7e12bd35":"print(\"First Prediction:\\n\",classification_report(y_test, prediction1),\"\\n\\nSecond Prediciton:\\n\",classification_report(y_test, prediction2))","2966382e":"# feature\nX_t = df_test['title']\n\n# label\ny_t = df_test['category']","0eb7fa95":"getting_categories = model2.predict(X_t)","1dc404df":"len(getting_categories), len(df_test)","7d29380a":"df_test['category'] = getting_categories","c3670d5b":"df_test.head()","42d18cb3":"### Predictions","33e0cfce":"**Putting the above best params in the pipeline.**","445bf45a":"### Model Creation","a31598ad":"**Comparing 1st predictions with the current predictions.**","038de044":"### Train-Test Split","cbfcc119":"### Getting the categories of the test data using the model 2","c697716e":"The model is having quite a good accuracy and f1 score for most of the categories, let's improve the model.","e58d5fc0":"### Objective\n\nCategorize the items into 5 different categories `Home & Kitchen`, `Tools & Home Improvement`, `Office Products`, `Grocery & Gourmet Food`, `Industrial & Scientific`, `Electronics` using Natural Language Processing for an e-commerce firm.\nGiven is a dataset of training data and need to predict the categories on the test data.","1a2d0fb8":"### Predictions on Model 2","6c667200":"### Reading and understanding the data","d768e424":"### Importing libraries","73392597":"On comparing the `classification reports` of the 2 predictions, we can observe that there are improvements in the `precision`, `recall` and `f1-score` of most of categories, and so, `model 2` is our final model.","0613e475":"### Finding best parameters for the Pipeline","986ab1e8":"**Best Parameters**","6ca9e6de":"# Predict categories of the items using NLP","a9c23b15":"So, now we have predicted the categories of the test data.","b4ba0f45":"There are no empty string values as well.","e5e07048":"### Cleaning the data","cf65f4e1":"We can observe that there are many columns with `None`. Lets remove those rows since they'll hinder our predictions."}}