{"cell_type":{"3aa0ac72":"code","e10b755a":"code","4615f31e":"code","c13851e8":"code","ea082ef7":"code","cb2ea312":"code","aaff7702":"code","92a91c24":"code","e453e357":"code","000a9da7":"code","1ff18c08":"code","896d95a9":"markdown","5759a845":"markdown"},"source":{"3aa0ac72":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e10b755a":"#Get tools\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport time\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc, roc_auc_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report, confusion_matrix","4615f31e":"df=pd.read_csv('..\/input\/creditcard.csv')\nprint(df.head())","c13851e8":"#From previous exercise, unsupporting variables and variables with collinearity were identified\n#Get rid of those for a simpler set of predictors\ndf.drop(['Amount','Time'],axis=1,inplace=True)\ndf.drop(['V8','V13','V23','V26','V27','V28'],axis=1,inplace=True)\ndf.drop(['V2','V3','V5','V7','V9','V11','V15','V19','V20','V21','V22','V24','V25'],axis=1,inplace=True)\nprint(df.head())","ea082ef7":"#As in previous exercise, imbalanced class ratio warrants\n#(1)training set with balanced class representation; and \n#(2)an unseen test set with a similar distribution of minority to majority class (fraud ~ 0.17%)\n\n#Instead of undersampling the majority class, here I use Synthetic Minority Over-sampling Technique (SMOTE)\n\n#First, split into train and test sets to ensure no information leaked to test set\n\nX,y=df.iloc[:,:-1],df.iloc[:,-1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n\n#Check majority vs. minority class distribution in train and test sets\n\nprint('Fraudulent share, train set (before SMOTE): {0:.2%}'.format(sum(y_train==1)\/len(y_train)))\nprint('Fraudulent share, test set: {0:.2%}'.format(sum(y_test==1)\/len(y_test))) ","cb2ea312":"#Apply SMOTE to train set\nsm=SMOTE(random_state=22)\nX_resampled, y_resampled=sm.fit_sample(X_train,y_train)\n\n#Check majority vs. minority class distribution in train set after resampling\n\nprint('Fraudulent share, train set (after SMOTE): {0:.2%}'.format(sum(y_resampled==1)\/len(y_resampled)))","aaff7702":"#Fit Random Forest Classifier used previously to data\n#Predict and evaluate effect of SMOTE\n\nRFC_mod=RandomForestClassifier(max_depth=4,random_state=22)\n\nRFC_mod.fit(X_resampled,y_resampled)","92a91c24":"#Predict and check AUPRC as well as time the prediction\n\nt0=time.time()\ny_pred_RFC=RFC_mod.predict(X_test)\nt1=time.time()\n\nprint('Predicting with Random Forest Classifier model took: {0:.4f} seconds'.format(t1-t0))\n\nlabels=['No Fraud','Fraud']\n#Calculate precision recall curve and area under curve\nprecision_RFC,recall_RFC,threshold_RFC=precision_recall_curve(y_test,y_pred_RFC)\nauprc_RFC=auc(recall_RFC,precision_RFC)\nprint()\nprint('Area under precision recall curve, Random Forest Classifier model: {0:.4f}'.format(auprc_RFC))\nprint()\nprint(classification_report(y_test,y_pred_RFC,target_names=labels))\nprint()\nprint(confusion_matrix(y_test,y_pred_RFC))","e453e357":"#Using SMOTE instead of undersampling the majority the class improved model performance\n#Area under precision recall curve increased to 0.5445 from 0.4824\n#Prediction still took under one second - YAY!\n\n#Let's see if changing hyperparameters of Random Forest Classifier can improve model performance further\n#Here, I choose to tweak the \n#(1)max_depth (maximum depth of each tree), and \n#(2)n_estimators (number of trees).\n\n# Maximum depth of each tree\nmax_depth=[None,5,10]\n\n# Number of trees\nn_estimators=[10,12,14,16]\n\n#create grid\ngrid={\n    'max_depth': max_depth,\n    'n_estimators': n_estimators\n}\n\n#Random search of parameters\nRFC_search=GridSearchCV(estimator=RandomForestClassifier(random_state=22), param_grid=grid,cv=3,scoring='f1',verbose=True)\n\n#Fit model\nRFC_search.fit(X_resampled, y_resampled)\n\n#print results\nprint(RFC_search.best_score_)\nprint(RFC_search.best_params_)\n","000a9da7":"#Wow! That took a long time for hardly an exhaustive search!\n\n#The best max_depth and n_estimators identified are:\n#'None' and '16', respectively.\n#Refit the random forest classifier with these hyperparameters and check performance\n\nRFC_mod=RandomForestClassifier(random_state=22,max_depth=None,n_estimators=16)\nRFC_mod.fit(X_resampled,y_resampled)\n\nt0=time.time()\ny_pred_RFC=RFC_mod.predict(X_test)\nt1=time.time()\n\nprint('Predicting with Random Forest Classifier model took: {0:.4f} seconds'.format(t1-t0))\n\n#Calculate precision recall curve and area under curve\nprecision_RFC,recall_RFC,threshold_RFC=precision_recall_curve(y_test,y_pred_RFC)\nauprc_RFC=auc(recall_RFC,precision_RFC)\nprint()\nprint('Area under precision recall curve, Random Forest Classifier model: {0:.4f}'.format(auprc_RFC))\nprint()\nprint(classification_report(y_test,y_pred_RFC,target_names=labels))\nprint()\nprint(confusion_matrix(y_test,y_pred_RFC))","1ff18c08":"#Great! The area under the precision recall curve rose to 0.8163\n#and the number of false positives and false negatives limited.\n\n#Since the Random Forest Classifier is a 'bagging' algorithm, \n#wouldn't increasing the number of trees improve performance?\n#Right now, the default number of trees is 10; but this will be changed to 100 soon.\n#Let's fit this soon-to-be 'default' model to our training set and compare the performance.\n\nRFC_mod=RandomForestClassifier(random_state=22,max_depth=None,n_estimators=100)\nRFC_mod.fit(X_resampled,y_resampled)\n\nt0=time.time()\ny_pred_RFC=RFC_mod.predict(X_test)\nt1=time.time()\n\nprint('Predicting with Random Forest Classifier model took: {0:.4f} seconds'.format(t1-t0))\n\n#Calculate precision recall curve and area under curve\nprecision_RFC,recall_RFC,threshold_RFC=precision_recall_curve(y_test,y_pred_RFC)\nauprc_RFC=auc(recall_RFC,precision_RFC)\nprint()\nprint('Area under precision recall curve, Random Forest Classifier model: {0:.4f}'.format(auprc_RFC))\nprint()\nprint(classification_report(y_test,y_pred_RFC,target_names=labels))\nprint()\nprint(confusion_matrix(y_test,y_pred_RFC))","896d95a9":"Not as good as the classifier using n_estimators=16 but, still, comparable performance.  It seems more efficient to spend time identifying supportive \/ correlated features before fitting a model than to depend on an exhaustive search for the best hyperparameters.  Even though the Random Forest Classifier was developed to minimize overfitting, it is not immune to it.    ","5759a845":"[Previously](http:\/\/www.kaggle.com\/rowena1\/my-first-kernel), through undersampling the majority class, I was able to get a Random Forest classifier that outperforms a no-skill dummy classifier -- area under precision recall curve was 0.4816 compared to 0.2538 in the no-skill case.  The aim of this exercise is to improve upon the previous classifier.\n\nHere, instead of undersampling the majority class, I used Synthetic Minority Over-sampling Technique. This raised the area under the precision-recall curve from 0.4816 to 0.5445.  Then, by tweaking the hyperparameters improved model performance further, bringing the area under the precision-recall curve to 0.8163.  Also, this was achieved with a test set that preserved the imbalance between the majority and minority classes to better represent reality.  However, since PCA was applied to the original dataset to protect customer privacy, there would have been some information leaked to the test set.\n\nSearching through various combinations of hyperparameters is time consuming.  It is more efficient to first launch an interim model using default hyperparametric settings and an edited set of predictors.  Then, search for an optimized model and release that.  Using a more parsimonious set of predictors also aids interpretability of the decision paths. "}}