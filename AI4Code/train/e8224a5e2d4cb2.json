{"cell_type":{"3be2d8de":"code","534d93a1":"code","938908f1":"code","48825545":"code","b06e352c":"code","5701d3b0":"code","7e7791f3":"code","ab25badb":"code","18b976bb":"code","ba6f689b":"code","0f2d4c1f":"code","cde5a09c":"code","7b28b60d":"code","c3b9a0da":"code","17233a8a":"code","486021f4":"code","daeaea75":"code","9a7d05d2":"code","1281e419":"code","cc4a9033":"code","b50d9267":"code","8365c912":"code","81eada40":"code","f7d1d120":"code","e0d424ba":"code","16c3c8ab":"code","646d5cda":"code","88121b20":"code","1c9e16ef":"code","b4e1c257":"code","72557d59":"code","5d9cf073":"code","3d25ed91":"code","a91ebbf0":"code","f42dda54":"code","7cc5512f":"code","a88fa3c1":"code","8dcdd8fc":"code","7b182b84":"code","ec349f1d":"code","578968cc":"code","215f2f10":"code","eb49e664":"code","a115cbee":"code","1c96d8e6":"code","2e473811":"code","1688aaf1":"code","9a065d22":"code","40369fd6":"code","9954177d":"code","b2d5f7ac":"code","0ee96065":"code","ba51521d":"code","89abf656":"code","03fcf052":"code","1929fcc9":"code","b4d0a874":"code","8c9ff4a9":"code","d4f2b92d":"code","8e6b8a6c":"code","1c898749":"code","bb50dac2":"code","dd39aca0":"code","240ec741":"code","a5d7d3a9":"code","eee14e6a":"code","23ba697d":"markdown","119ec614":"markdown","20b5f71b":"markdown","98e9dfea":"markdown","6cd3e26a":"markdown","49758649":"markdown","f31c037f":"markdown","2498e117":"markdown","797eefe3":"markdown","41019a47":"markdown","52fae75f":"markdown","34edcebf":"markdown","596e9dc4":"markdown","e1597bbd":"markdown","d6c2c25a":"markdown","acbc94d1":"markdown","73d39789":"markdown"},"source":{"3be2d8de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","534d93a1":"# Farkl\u0131 store i\u00e7in 3 ayl\u0131k item-level sales tahmini.\n# 5 y\u0131ll\u0131k bir veri setinde 10 farkl\u0131 ma\u011faza ve 50 farkl\u0131 item var.\n# Buna g\u00f6re ma\u011faza-item k\u0131r\u0131l\u0131m\u0131nda 3 ay sonras\u0131n\u0131n tahminlerini vermemiz gerekiyor.\n\nimport time\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport warnings\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 500)\nwarnings.filterwarnings('ignore')\n\n\ndef check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","938908f1":"train = pd.read_csv(\"..\/input\/demand-forecasting-kernels-only\/train.csv\", parse_dates=['date'])\ntest = pd.read_csv(\"..\/input\/demand-forecasting-kernels-only\/test.csv\", parse_dates=['date'])\nsample_sub = pd.read_csv(\"..\/input\/demand-forecasting-kernels-only\/sample_submission.csv\")\ndf = pd.concat([train, test], sort=False)","48825545":"df.head()","b06e352c":"df[\"date\"].min(), df[\"date\"].max()","5701d3b0":"check_df(train)","7e7791f3":"check_df(test)","ab25badb":"check_df(sample_sub)","18b976bb":"check_df(df)","ba6f689b":"# Sat\u0131\u015f da\u011f\u0131l\u0131m\u0131 nas\u0131l?\ndf[\"sales\"].describe([0.10, 0.30, 0.50, 0.70, 0.80, 0.90, 0.95, 0.99])","0f2d4c1f":"# Ka\u00e7 store var?\ndf[[\"store\"]].nunique()","cde5a09c":"# Ka\u00e7 item var?\ndf[[\"item\"]].nunique()","7b28b60d":"# Her store'da e\u015fit say\u0131da m\u0131 e\u015fsiz item var?\ndf.groupby([\"store\"])[\"item\"].nunique()","c3b9a0da":"# Peki her store'da e\u015fit say\u0131da m\u0131 sales var?\ndf.groupby([\"store\", \"item\"]).agg({\"sales\": [\"sum\"]})","17233a8a":"# ma\u011faza-item k\u0131r\u0131l\u0131m\u0131nda sat\u0131\u015f istatistikleri\ndf.groupby([\"store\", \"item\"]).agg({\"sales\": [\"sum\", \"mean\", \"median\", \"std\"]})","486021f4":"def create_date_features(df):\n    df['month'] = df.date.dt.month\n    df['quarter'] = df.date.dt.quarter\n    df['is_q_end'] = df.date.dt.is_quarter_end.astype(int)\n    df['is_q_start'] = df.date.dt.is_quarter_start.astype(int)\n    df['days_in_month'] = df.date.dt.days_in_month\n    df['day_of_month'] = df.date.dt.day\n    df['day_of_year'] = df.date.dt.dayofyear\n    df['week_of_year'] = df.date.dt.weekofyear\n    df['day_of_week'] = df.date.dt.dayofweek\n    df['year'] = df.date.dt.year\n    df[\"is_wknd\"] = df.date.dt.weekday \/\/ 4\n    df['is_month_start'] = df.date.dt.is_month_start.astype(int)\n    df['is_month_end'] = df.date.dt.is_month_end.astype(int)\n    return df\n","daeaea75":"\ndf = create_date_features(df)\n","9a7d05d2":"# \u015eu an ay bilgisi oldu\u011fu mesela store-item-month k\u0131r\u0131l\u0131m\u0131nda sat\u0131\u015f istatistiklerini g\u00f6rebiliriz.\ndf.groupby([\"store\", \"item\", \"year\",\"month\"]).agg({\"sales\": [\"sum\", \"mean\", \"median\", \"std\"]})","1281e419":"# \u015eu an ay bilgisi oldu\u011fu mesela store-item-quarter k\u0131r\u0131l\u0131m\u0131nda sat\u0131\u015f istatistiklerini g\u00f6rebiliriz.\ndf.groupby([\"store\", \"item\", \"year\",\"quarter\"]).agg({\"sales\": [\"sum\", \"mean\", \"median\", \"std\"]})","cc4a9033":"def random_noise(dataframe):\n    return np.random.normal(scale=1.6, size=(len(dataframe),))","b50d9267":"df.sort_values(by=['store', 'item', 'date'], axis=0, inplace=True)","8365c912":"\ncheck_df(df)","81eada40":"# sat\u0131\u015f\u0131n ilk 10 g\u00f6zlemine bakal\u0131m:\ndf[\"sales\"].head(10)","f7d1d120":"# Birinci gecikme\ndf[\"sales\"].shift(1).values[0:10]\n","e0d424ba":"# \u0130kinci gecikme\ndf[\"sales\"].shift(2).values[0:10]\n","16c3c8ab":"# \u00dc\u00e7\u00fcnc\u00fc gecikme\ndf[\"sales\"].shift(3).values[0:10]","646d5cda":"# Daha anla\u015f\u0131l\u0131r olmas\u0131 i\u00e7in df'te bir arada ele alal\u0131m:\npd.DataFrame({\"sales\": df[\"sales\"].values[0:10],\n              \"lag1\": df[\"sales\"].shift(1).values[0:10],\n              \"lag2\": df[\"sales\"].shift(2).values[0:10],\n              \"lag3\": df[\"sales\"].shift(3).values[0:10],\n              \"lag4\": df[\"sales\"].shift(4).values[0:10]})","88121b20":"df.groupby([\"store\", \"item\"])['sales'].head()","1c9e16ef":"df.groupby([\"store\", \"item\"])['sales'].transform(lambda x: x.shift(1))","b4e1c257":"def lag_features(dataframe, lags):\n    for lag in lags:\n        dataframe['sales_lag_' + str(lag)] = dataframe.groupby([\"store\", \"item\"])['sales'].transform(\n            lambda x: x.shift(lag)) + random_noise(dataframe)\n    return dataframe","72557d59":"df = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 456,546, 728,821])\ncheck_df(df)","5d9cf073":"df[df[\"sales\"].isnull()]","3d25ed91":"df[\"sales\"].head(10)","a91ebbf0":"df[\"sales\"].rolling(window=2).mean().values[0:10]","f42dda54":"df[\"sales\"].rolling(window=3).mean().values[0:10]","7cc5512f":"df[\"sales\"].rolling(window=5).mean().values[0:10]","a88fa3c1":"pd.DataFrame({\"sales\": df[\"sales\"].values[0:10],\n              \"roll2\": df[\"sales\"].rolling(window=2).mean().values[0:10],\n              \"roll3\": df[\"sales\"].rolling(window=3).mean().values[0:10],\n              \"roll5\": df[\"sales\"].rolling(window=5).mean().values[0:10]})","8dcdd8fc":"def roll_mean_features(dataframe, windows):\n    for window in windows:\n        dataframe['sales_roll_mean_' + str(window)] = dataframe.groupby([\"store\", \"item\"])['sales']. \\\n                                                          transform(\n            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n            dataframe)\n    return dataframe","7b182b84":"df = roll_mean_features(df, [365, 456,546])","ec349f1d":"pd.DataFrame({\"sales\": df[\"sales\"].values[0:10],\n              \"roll2\": df[\"sales\"].shift(1).rolling(window=2).mean().values[0:10],\n              \"ewm099\": df[\"sales\"].shift(1).ewm(alpha=0.99).mean().values[0:10],\n              \"ewm095\": df[\"sales\"].shift(1).ewm(alpha=0.95).mean().values[0:10],\n              \"ewm07\": df[\"sales\"].shift(1).ewm(alpha=0.7).mean().values[0:10],\n              \"ewm02\": df[\"sales\"].shift(1).ewm(alpha=0.1).mean().values[0:10]})","578968cc":"def ewm_features(dataframe, alphas, lags):\n    for alpha in alphas:\n        for lag in lags:\n            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n                dataframe.groupby([\"store\", \"item\"])['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n    return dataframe\n","215f2f10":"\nalphas = [0.95, 0.9, 0.8, 0.7, 0.5]\nlags = [91, 98, 105, 112, 180, 270, 365,456,546, 728,821]","eb49e664":"df = ewm_features(df, alphas, lags)\ncheck_df(df)","a115cbee":"df = pd.get_dummies(df, columns=['store', 'item', 'day_of_week', 'month'])","1c96d8e6":"df['sales'] = np.log1p(df[\"sales\"].values)\ncheck_df(df)","2e473811":"\ndef smape(preds, target):\n    n = len(preds)\n    masked_arr = ~((preds == 0) & (target == 0))\n    preds, target = preds[masked_arr], target[masked_arr]\n    num = np.abs(preds - target)\n    denom = np.abs(preds) + np.abs(target)\n    smape_val = (200 * np.sum(num \/ denom)) \/ n\n    return smape_val\n\ndef lgbm_smape(preds, train_data):\n    labels = train_data.get_label()\n    smape_val = smape(np.expm1(preds), np.expm1(labels))\n    return 'SMAPE', smape_val, False\n","1688aaf1":"# 2017'nin ba\u015f\u0131na kadar (2016'n\u0131n sonuna kadar) train seti.\ntrain = df.loc[(df[\"date\"] < \"2017-01-01\"), :]","9a065d22":"# 2017'nin ilk 3'ay\u0131 validasyon seti.\nval = df.loc[(df[\"date\"] >= \"2017-01-01\") & (df[\"date\"] < \"2017-04-01\"), :]","40369fd6":"cols = [col for col in train.columns if col not in ['date', 'id', \"sales\", \"year\"]]","9954177d":"Y_train = train['sales']\nX_train = train[cols]\n\nY_val = val['sales']\nX_val = val[cols]","b2d5f7ac":"# kontrol\nY_train.shape, X_train.shape, Y_val.shape, X_val.shape","0ee96065":"lgb_params =  { 'metric': 'mae',\n                'num_leaves' : 12,\n                'max_depth': 10,\n                'min_child_samples': 5,\n                'learning_rate': 0.03,\n                'colsample_bytree': 0.5,\n                'verbose': 0,\n                'num_boost_round': 2000,\n                'early_stopping_rounds': 200,\n                'min_child_weight' : 0.1,\n                'nthread': -1}","ba51521d":"# metric mae: l1, absolute loss, mean_absolute_error, regression_l1\n# l2, square loss, mean_squared_error, mse, regression_l2, regression\n# rmse, root square loss, root_mean_squared_error, l2_root\n# mape, MAPE loss, mean_absolute_percentage_error\n","89abf656":"\nlgbtrain = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\nlgbval = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain, feature_name=cols)\n\nmodel = lgb.train(lgb_params, lgbtrain,\n                  valid_sets=[lgbtrain, lgbval],\n                  num_boost_round=lgb_params['num_boost_round'],\n                  early_stopping_rounds=lgb_params['early_stopping_rounds'],\n                  feval=lgbm_smape,\n                  verbose_eval=100)\ny_pred_val = model.predict(X_val, num_iteration=model.best_iteration)","03fcf052":"smape(np.expm1(y_pred_val), np.expm1(Y_val))","1929fcc9":"def plot_lgb_importances(model, plot=False, num=10):\n\n    gain = model.feature_importance('gain')\n    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n                             'split': model.feature_importance('split'),\n                             'gain': 100 * gain \/ gain.sum()}).sort_values('gain', ascending=False)\n    if plot:\n        plt.figure(figsize=(10, 10))\n        sns.set(font_scale=1)\n        sns.barplot(x=\"gain\", y=\"feature\", data=feat_imp[0:25])\n        plt.title('feature')\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(feat_imp.head(num))","b4d0a874":"plot_lgb_importances(model, num=30, plot=True)","8c9ff4a9":"lgb.plot_importance(model, max_num_features=20, figsize=(10, 10), importance_type=\"gain\")\nplt.show()","d4f2b92d":"train = df.loc[~df.sales.isna()]\nY_train = train['sales']\nX_train = train[cols]\n\ntest = df.loc[df.sales.isna()]\nX_test = test[cols]","8e6b8a6c":"lgb_params = { 'metric': 'mae',\n                'num_leaves' : 12,\n                'max_depth': 10,\n                'min_child_samples': 5,\n                'learning_rate': 0.03,\n                'colsample_bytree': 0.5,\n                'verbose': 0,\n                'min_child_weight' : 0.1,\n                'nthread': -1,\n              \"num_boost_round\": 2000}\n","1c898749":"lgbtrain_all = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)","bb50dac2":"model = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model.best_iteration)","dd39aca0":"test_preds = model.predict(X_test, num_iteration=model.best_iteration)","240ec741":"smape(np.expm1(y_pred_val), np.expm1(Y_val))","a5d7d3a9":"submission_df = test.loc[:, ['id', 'sales']]\nsubmission_df['sales'] = np.expm1(test_preds)\nsubmission_df['id'] = submission_df.id.astype(int)\nsubmission_df.to_csv('submission.csv', index=False)\n","eee14e6a":"submission_df.head(20)","23ba697d":"# Custom Cost Function","119ec614":"# Rolling Mean Features","20b5f71b":"# Exponentially Weighted Mean Features","98e9dfea":"# Final Model","6cd3e26a":"# Random Noise","49758649":"# LightGBM Model","f31c037f":"# Time-Based Validation Sets","2498e117":"# One-Hot Encoding","797eefe3":"# Lag\/Shifted Features","41019a47":"# De\u011fi\u015fken \u00f6nem d\u00fczeyleri","52fae75f":"# Date Features","34edcebf":"# Model","596e9dc4":"# MAE: mean absolute error\n# MAPE: mean absolute percentage error\n# SMAPE: Symmetric mean absolute percentage error (adjusted MAPE)","e1597bbd":"# FEATURE ENGINEERING","d6c2c25a":"\n# Loading the data\n","acbc94d1":"# EDA\n","73d39789":"# Converting sales to log(1+sales)"}}