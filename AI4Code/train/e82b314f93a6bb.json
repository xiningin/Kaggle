{"cell_type":{"eff68408":"code","f349e6c9":"code","c95dafb0":"code","511b23a7":"code","201fcaa9":"code","cb32eed5":"code","e879386f":"code","aa3814bb":"code","84bd047e":"code","aff1ff17":"code","877de796":"code","fe612d41":"code","230c06cb":"code","0ca3fb31":"code","bd535448":"code","6b8cfae0":"code","f527d8f8":"code","2a18c2b2":"code","fa32bc63":"code","e828950d":"code","a67dd6af":"code","803a98df":"code","9cbdb8cb":"markdown","53530504":"markdown"},"source":{"eff68408":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f349e6c9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n\n#Module for resampling\nfrom sklearn.utils import resample\n\n#for model creation\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n#for decision tree classifcation\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n\n#for randomforest classification\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n\n#for knn classification\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#for svm classification\nfrom sklearn.svm import SVC\nfrom sklearn import svm\n\n#for mlp classification\nfrom sklearn.neural_network import MLPClassifier\n","c95dafb0":"\ndata=pd.read_csv('..\/input\/adult-census-income\/adult.csv')","511b23a7":"data.head(10)","201fcaa9":"data.info()","cb32eed5":"#Removal of missing data specified by question mark(?)\n#New dataframe df\ndf = data[(data != '?').all(axis=1)]","e879386f":"df.head()","aa3814bb":"df.tail()","84bd047e":"# Binary encoding of the target variable\ndf['income'] = df['income'].apply(lambda inc: 0 if inc == \"<=50K\" else 1) ","aff1ff17":"#One-hot encoding of the categorical columns\n#converting categorical data to binary\ndf = pd.get_dummies(df,columns=['workclass','sex', 'marital.status',\n                                    'race','relationship','occupation'],\n               prefix=['workclass', 'is', 'is', 'race_is', 'relation', 'is'], drop_first=True)","877de796":"df.head()","fe612d41":"print(df['income'].value_counts())","230c06cb":"#Balancing data\n# Separate majority and minority classes\ndf_majority = df[df.income==0]\ndf_minority = df[df.income==1]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=22654,    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.income.value_counts()","0ca3fb31":"df_upsampled.info()","bd535448":"plt.figure(figsize=(20,12))\nsns.heatmap(df_upsampled.corr())","6b8cfae0":"#Splitting dataset into training and testing class\narray = df_upsampled.values\nX = array[:,0:8 and 9:44]\nY = array[:,8]\nY=Y.astype('int')\n\nX_train,X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)","f527d8f8":"# Create Decision Tree classifer object\nclf = DecisionTreeClassifier(criterion=\"entropy\",max_depth=3)\n\nclf = clf.fit(X_train,Y_train)\nY_pred = clf.predict(X_validation)\n\ncm = confusion_matrix(Y_pred, Y_validation)\n\nprint(\"Accuracy of Decision tree classification:\",metrics.accuracy_score(Y_validation, Y_pred))\nprint(cm)","2a18c2b2":"#decision tree\nplt.figure(figsize=(10,10))\ntree.plot_tree(clf)","fa32bc63":"#random forest classification\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf = clf.fit(X_train,Y_train)\n\nY_pred = clf.predict(X_validation)\ncm = confusion_matrix(Y_pred, Y_validation)\n\nprint(\"Accuracy random froest classification:\",metrics.accuracy_score(Y_validation, Y_pred))\nprint(cm)","e828950d":"#knn clasification\nknn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\nknn.fit(X_train,Y_train)\n\nY_pred = knn.predict(X_validation)\ncm = confusion_matrix(Y_pred, Y_validation)\n\nprint(\"Accuracy of knn classification:\",metrics.accuracy_score(Y_validation, Y_pred))\nprint(cm)","a67dd6af":"#support vector machine Classification\nclf = svm.SVC(kernel='linear') \n\nclf.fit(X_train, Y_train)\n\n\nY_pred = clf.predict(X_validation)\ncm = confusion_matrix(Y_pred, Y_validation)\n\n\nprint(\"Accuracy of SVM Classifier : \",metrics.accuracy_score(Y_validation, Y_pred))\nprint(cm)\n\n","803a98df":"#MultilayerPercetron classification\n\nclf = MLPClassifier(hidden_layer_sizes=(3,3), max_iter=3000,activation = 'relu',solver='adam',random_state=1)\nclf=clf.fit(X_train, Y_train)\n\ncm = confusion_matrix(Y_pred, Y_validation)\nY_pred = clf.predict(X_validation)\n\nprint(\"Accuracy of MLPClassifier : \",metrics.accuracy_score(Y_validation, Y_pred))\nprint(cm)","9cbdb8cb":"# **Unbalanced data is seen in target class**","53530504":"# One-hot encoding Implementation"}}