{"cell_type":{"bc8ee95e":"code","67d91684":"code","3a42c139":"code","dbf553e7":"code","d8de1354":"code","118f624e":"code","583cb8ff":"code","4cbe5d91":"code","9b08b452":"code","a679ad54":"code","339e271c":"code","c809f19c":"code","77110be9":"markdown","00857e4b":"markdown","0b2972c3":"markdown","24c94bdd":"markdown","ab892ccc":"markdown","0e73f42a":"markdown","d27266dd":"markdown","c35565ce":"markdown","4ee189d0":"markdown","520c3d93":"markdown","71c22ef1":"markdown"},"source":{"bc8ee95e":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\n\nRANDOM_STATE = 2021\n\nimport numpy as np\nimport pandas as pd\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.cluster import DBSCAN","67d91684":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","3a42c139":"# get train row size \ntrain_len = len(train)\n# concat train + test \ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n# empty data => np.nan\ndataset = dataset.fillna(np.nan)","dbf553e7":"# column encoding and create new features\n# 1.Fare\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n# dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n\n# 2.Embarked\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(dataset[\"Fare\"].mode()[0])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\n\n# 3.Sex\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n# dataset = pd.get_dummies(dataset, columns = [\"Sex\"])\n\n# 4.Age\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].mean()\n    dataset['Age'].iloc[i] = age_med\n#     age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n#     if not np.isnan(age_pred) :\n#         dataset['Age'].iloc[i] = age_pred\n#     else :\n#         dataset['Age'].iloc[i] = age_med\n        \n        \n# 5.Name         \n# dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n# dataset[\"Title\"] = pd.Series(dataset_title)\n# dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n# dataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n# dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n# dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)\n# dataset = pd.get_dummies(dataset, columns = [\"Title\"])\n\n# 6.SibSp(Number of Siblings\/Spouses Aboard) + Parch(Number of Parents\/Children Aboard) =>Fsize\ndataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['IsSingle'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n# dataset['IsSmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n# dataset['IsMedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# dataset['IsLargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n# #7.Cabin\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\n\n# #8.Ticket \nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# 9.Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# 10.PassengerId\ndataset.drop(labels = [\"Name\",\"PassengerId\"], axis = 1, inplace = True)","d8de1354":"# devide train test \ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","118f624e":"outlier_cols = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) != str and colvalue.nunique() >= 10:\n        outlier_cols.append(colname)\n        \ndef drop_outliers(df, field_name):\n    iqr = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n    df.drop(df[df[field_name] > (iqr + np.percentile(df[field_name], 75))].index, inplace=True)\n    df.drop(df[df[field_name] < (np.percentile(df[field_name], 25) - iqr)].index, inplace=True)\n\nfor col in outlier_cols:\n    drop_outliers(train,col)","583cb8ff":"def getLabelCount(df,target):\n    return [( labelValue,len(train.loc[df[target] == labelValue]) ) for labelValue in df[target].unique()]\n\nlabelCount = getLabelCount(train,TARGET)\nlabelCount","4cbe5d91":"from sklearn import ensemble","9b08b452":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test\n\nmodel = ensemble.AdaBoostClassifier(random_state=RANDOM_STATE) \nmodel.fit(X,y)","a679ad54":"from sklearn.model_selection import cross_val_score,cross_val_predict,cross_validate\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef showModelEvaluation(y_test,predictions):\n    print(\"precision_score1:\",precision_score(y_test, predictions) )\n    print(\"recall_score1:\",recall_score(y_test, predictions))\n    print(\"f1_score1:\",f1_score(y_test, predictions))\n    print(\"roc_auc score\",roc_auc_score(y_test, predictions) )\n    print(\"\")\n    \n    #condusion metrics\n    cm = confusion_matrix(y_test, predictions)\n    score = np.mean([y_test == predictions])\n    #plot\n    sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=1, square = True,cbar = False);\n    plt.ylabel('Actual label');\n    plt.xlabel('Predicted label');\n    all_sample_title = 'Accuracy Score: {0}'.format(score)\n    plt.title(all_sample_title, size = 15);","339e271c":"pred_test = model.predict(X_test)\npred_test[:5]","c809f19c":"submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsubmission[TARGET] = pred_test.astype(int)\nsubmission.to_csv(SUBMISSION_PATH,index=False)\nsubmission.head()","77110be9":"### 1.4 check label count","00857e4b":"# predict & submission","0b2972c3":"### 1.3 outlier","24c94bdd":"##### 1.2.3. devide data ","ab892ccc":"### 1.1 load data","0e73f42a":"# make model (split data & train data) ","d27266dd":"##### 1.2.2. feature engineering","c35565ce":"# load data & preprocess","4ee189d0":"##### 1.2.1 concat data","520c3d93":"### 1.2. preprocess data","71c22ef1":"# evaluate model"}}