{"cell_type":{"a5e6d281":"code","40cbd757":"code","6583df3b":"code","699773b3":"code","f9842a8d":"code","2dedb248":"code","5b9b21bd":"code","e891ed64":"code","6f01cbdf":"code","e8a305e0":"code","2596a97c":"code","bfe070dc":"code","ec9f1f0d":"code","39499b06":"code","846871a9":"code","1a637a35":"code","7295d0b4":"code","6adce5a6":"code","076f86cd":"code","b8a7fae9":"code","4830890b":"code","6ea59503":"code","2cae44ab":"code","6b67a328":"code","bd513e3a":"code","624576b1":"code","606561b0":"code","aef7a534":"code","c4cf5b71":"code","c55ceeac":"code","32ffc26a":"code","a8a2d181":"code","ca735d6a":"code","7579b7e0":"code","4c2fc733":"code","44525221":"code","5c6d8fea":"code","ecbbcd41":"code","dc3d8e79":"markdown","7c63afe0":"markdown","c8fb4f4a":"markdown","03aa4474":"markdown","b4f9ae17":"markdown","f524d680":"markdown","539c489a":"markdown","cb9e9b8c":"markdown","d92154b4":"markdown","467839e1":"markdown","e4597760":"markdown","49ed4faa":"markdown","91472247":"markdown","92327989":"markdown","07763e75":"markdown","160ace6c":"markdown","b9054e34":"markdown","9244f546":"markdown","aa95e6e8":"markdown","4e0064c4":"markdown","0f5c44ea":"markdown","cc9d3f85":"markdown","706a0787":"markdown","078d1a0a":"markdown","81ff1c56":"markdown","4e7aac59":"markdown","8ab3dad4":"markdown","4773bf93":"markdown","2053fbe4":"markdown","63d94bee":"markdown","b0ad20da":"markdown","1389811d":"markdown","b10ae3ac":"markdown","69eebfee":"markdown","c9882942":"markdown","8582c930":"markdown","62461b31":"markdown","19b6b2cc":"markdown","a9e2e76d":"markdown","e5b97def":"markdown","5fdf89c8":"markdown","b591a3b4":"markdown","0fda57ac":"markdown","39b1fc7c":"markdown","459ef598":"markdown"},"source":{"a5e6d281":"# Essentials\nimport numpy as np\nimport pandas as pd\n\n# Visualisation\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Others\nfrom wordcloud import WordCloud","40cbd757":"# Let's start with the trending French videos\nfr_videos_raw = pd.read_csv('..\/input\/youtube-new\/FRvideos.csv', sep=',')","6583df3b":"fr_videos_raw.head()","699773b3":"fr_category_id = pd.read_json('..\/input\/youtube-new\/FR_category_id.json')","f9842a8d":"fr_category_id.head()","2dedb248":"fr_category_id['items'].iloc[0]","5b9b21bd":"# We retreive category_id and category_title in two lists (with same order) contained in a dict\nfr_category_id_dict = {'category_id':[key for key in fr_category_id['items'].keys()],\n                       'category_title':[y['snippet']['title'] for x,y in fr_category_id['items'].items()]}\nfr_category_id_dict.keys(), fr_category_id_dict.values()","e891ed64":"# Create dataframe from dict\nfr_category_id_df = pd.DataFrame.from_dict(fr_category_id_dict)\n\n# Merge on category_id then drop it\nfr_videos = fr_videos_raw.merge(fr_category_id_df, how='inner', on='category_id').drop(columns='category_id')\nfr_videos.loc[:5, ['title', 'category_title']]","6f01cbdf":"# Dataset dimensions\nfr_videos.shape","e8a305e0":"# Missing values by column\nfr_videos.isna().sum()","2596a97c":"# Renaming columns for cleaner code\nfr_videos = fr_videos.rename(columns={'category_title':'category'})\npx.histogram(fr_videos, x='category', title='Number of videos per category').update_xaxes(categoryorder='total descending')","bfe070dc":"# Trending_date  & publish_time\nfr_videos.loc[:5, ['video_id', 'trending_date', 'publish_time']]","ec9f1f0d":"# Converting series to datetime series\nfr_videos['trending_date'] = pd.to_datetime(fr_videos['trending_date'], format='%y.%d.%m')\nfr_videos['publish_time'] = pd.to_datetime(fr_videos['publish_time'], format='%Y-%m-%d')\n\n# Adding a time to trending_date in order to compare with publish_time\n# Input last minute of day in order to avoid negative differences\nfr_videos['trending_date'] = pd.to_datetime(fr_videos['trending_date'].astype(str) + ' ' + pd.Series(['23:59:59+00:00']*fr_videos.shape[0]),\n                                            format='%Y-%m-%d %H:%M:%S')\n\n# Create new feature trending_time in seconds\nfr_videos['trending_time'] = pd.to_timedelta(fr_videos['trending_date'] - fr_videos['publish_time']).apply(lambda x: int(x.total_seconds()))\n\n# Assert there's no negative time\ntry:\n    if (fr_videos['trending_time'] < 0).any():\n        raise ValueError\nexcept ValueError:\n    print(\"Negative timedelta found ! You should have a look.\")","39499b06":"# I first used px.histogram but the data was so spread again it didn't help\n# Even a boxplot is stretched too much to have a good overview\n# We plot in hours\n(fr_videos['trending_time']\/\/3600).describe()","846871a9":"# More precision\nfor quantile, trd_time in fr_videos['trending_time'].quantile([0.80, 0.85, 0.90, 0.95, 0.97, 0.99]).iteritems():\n    print(\"{}% of videos become trending in less than {} hours\".format(int(quantile*100), int(trd_time\/\/(3600))))","1a637a35":"# Renaming columns for cleaner code\nfr_videos = fr_videos.rename(columns={'comment_count':'comments'})\n\nfig = px.scatter_matrix(fr_videos, dimensions=['views', 'likes', 'dislikes', 'comments'])\n# You can add diagonal_visible=False as argument in update_traces if you want to skip the diagonal\nfig.update_traces(opacity=0.3, showupperhalf=False)\nfig.show()","7295d0b4":"px.histogram(fr_videos, x='comments_disabled', facet_col='video_error_or_removed', color='ratings_disabled')","6adce5a6":"any_disabled = pd.Series([True if any([com, rat, err]) else False for com, rat, err in zip(fr_videos['comments_disabled'],\n                                         fr_videos['ratings_disabled'],\n                                         fr_videos['video_error_or_removed'])])","076f86cd":"# Let's quickly check if any_disabled did the trick:\ntry:\n    assert fr_videos[(fr_videos['comments_disabled'] == False) & \n          (fr_videos['ratings_disabled'] == False) & \n          (fr_videos['video_error_or_removed'] == False)].shape[0] == (any_disabled == False).sum()\n    fr_videos['any_disabled'] = any_disabled\nexcept AssertionError:\n    print(\"any_disabled was not successfully computed !\")","b8a7fae9":"fr_videos['description'].head()","4830890b":"fr_videos['description'].isna().sum()","6ea59503":"# Count length of the description\nfr_videos['description_length'] = fr_videos['description'].str.len()\n\n# Input 0 for missing values and convert series to integer type\nfr_videos['description_length'] = fr_videos['description_length'].fillna(0).astype(int)","2cae44ab":"fr_videos['tags'].head()","6b67a328":"# Lower case tags, remove \"\" then retreive each tag separated from '|'\n# It's delicate to work with accents & encoding because some characters might be erased e.g. arabic characters\nsplit_tags = fr_videos['tags'].str.replace('\"', '').str.lower().str.split('|')\nsplit_tags.head()","bd513e3a":"# Second row contains [[none]] which is weird: is it a tag itself or an error ? Let's find out\nsplit_tags.iloc[1]","624576b1":"# First check if there are empty lists\nprint(split_tags.apply(lambda l: len(l) == 0).sum())\n\n# Check if there are videos with 'none' as tag\nmatchers = ['none','None', 'NONE']\n# This retreive matchers only\n# Convert to tuple temporarily because using value_counts() on lists objects raise error with pandas 0.25.0\nnones = split_tags.apply(lambda l: tuple(s for s in l if any(xs in s for xs in matchers)))\nnones.value_counts()","606561b0":"# We don't want to remove tags containing 'none' but the [[none]]\nsplit_tags.apply(lambda l: l == ['[none]']).sum()","aef7a534":"split_tags_cleaned = split_tags.apply(lambda l: np.nan if l == ['[none]'] else l)\n\n# Input number of tags in the list and 0 if there's none (NaN)\nfr_videos['tags_count'] = split_tags_cleaned.apply(lambda x: int(len(x)) if type(x) == list else 0)","c4cf5b71":"# I'm not sure what to do with all these tags. I guess the order may be important therefore I'll add 5 features for the first 5 tags\n\ndef input_n_tag(tags, n):\n    try:\n        n_tag = tags[n]\n    # When dealing with NaN\n    except TypeError:\n        n_tag = 'notag'\n    # When list too short\n    except IndexError:\n        n_tag = 'notag' \n    return n_tag \n    \nfr_videos['tag1'] = split_tags_cleaned.apply(lambda l: input_n_tag(l, 0))\nfr_videos['tag2'] = split_tags_cleaned.apply(lambda l: input_n_tag(l, 1))\nfr_videos['tag3'] = split_tags_cleaned.apply(lambda l: input_n_tag(l, 2))\nfr_videos['tag4'] = split_tags_cleaned.apply(lambda l: input_n_tag(l, 3))\nfr_videos['tag5'] = split_tags_cleaned.apply(lambda l: input_n_tag(l, 4))","c55ceeac":"fr_videos.loc[:5, ['title', 'tags_count', 'tag1', 'tag2', 'tag5']]","32ffc26a":"# Adding all tags in a single list\nall_tags = split_tags_cleaned.explode().astype(str)\ntext = ', '.join(all_tags)\n\n# Create wordcloud from single string\nwordcloud = WordCloud().generate(text)\nwordcloud = WordCloud(background_color=\"white\", max_words=1000, max_font_size=40, relative_scaling=.5).generate(text)\n\nplt.figure(figsize=(14, 10))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()","a8a2d181":"fr_videos['title_length'] = fr_videos['title'].str.len()","ca735d6a":"fr_videos.loc[:5, ['title', 'title_length']]","7579b7e0":"print(\"Number of videos: {} for {} different channels.\".format(fr_videos.shape[0], len(fr_videos['channel_title'].unique())))","4c2fc733":"fr_videos['channel_title'] = fr_videos['channel_title'].str.lower()","44525221":"corr = fr_videos.loc[:, ['views', 'likes', 'dislikes', 'comments', 'trending_time', 'tags_count', 'description_length', 'title_length']].corr()","5c6d8fea":"fig2 = go.Figure(data=go.Heatmap(\n        z=corr.values,\n        x=corr.index,\n        y=corr.index,\n        colorscale=\"Earth\",\n        zmin=-1,\n        zmax=1\n    # negative values\n))\nfig2.update_layout(title='Correlations all Categories combined')\nfig2.show()","ecbbcd41":"# Prepare correlation dataframes for heatmaps\ncategories = fr_videos['category'].unique()\ninteractions_corr_list = [fr_videos[fr_videos['category'] == cat].loc[:, ['views', 'likes', 'dislikes', 'comments', 'trending_time', 'tags_count',\n                                                                          'description_length', 'title_length']].corr() for cat in categories]\n\n#Initialize figure\nfig3 = go.Figure()\n\n# Add each heatmap, let the first one visible only to avoid traces stacked\nfor idx, corr in enumerate(interactions_corr_list):\n    if idx==0:\n        fig3.add_trace(\n            go.Heatmap(\n                z=corr.values,\n                x=corr.index,\n                y=corr.index,\n                colorscale=\"Earth\",\n                zmin=-1,\n                zmax=1,\n                visible=True))\n    else:\n         fig3.add_trace(\n            go.Heatmap(\n                z=corr.values,\n                x=corr.index,\n                y=corr.index,\n                colorscale=\"Earth\",\n                zmin=-1,\n                zmax=1,\n                visible=False)) \n\n# Add buttons\nfig3.update_layout(\n    updatemenus=[\n        go.layout.Updatemenu(\n            active=0,\n            x=0.8,\n            y=1.2,\n            buttons=list([\n                dict(label=cat,\n                     method=\"update\",\n                     # This comprehension list let visible the current trace only by setting itself to True and others to False\n                     args=[{\"visible\": [False if sub_idx != idx else True for sub_idx, sub_cat in enumerate(categories)]},\n                           {\"title\": \"Correlation heatmap for category: \" + cat}])\n                for idx, cat in enumerate(categories)\n            ] ) \n        )\n    ])","dc3d8e79":"If there are too many unique values, we should remove this column otherwise it will be poor information for the model.","7c63afe0":"There's some work to do with these two datetime-like columns: formats are different and we aim to compute the time a video took to be considered trending.","c8fb4f4a":"## <a id='4.2'>4.2 trending_date & publish_time --> trending_time","03aa4474":"## <a id='2.3'>2.3. (Optional) JupyterLab extensions","b4f9ae17":"If, like me, you like working on JupyterLab and want it to render Plotly figures, you'll find a few mandatory steps [here](https:\/\/github.com\/plotly\/plotly.py#jupyterlab-support-python-35). Otherwise, Jupyter notebook supports Plotly well.","f524d680":"It's important to recall these statistics do not take the video category into account. Comparing these correlations between each category could underline stronger correlations. Let's add a dropdown button to switch category.","539c489a":"## <a id='4.4'> 4.4 comments_disabled, rating_disabled & video_error_or_removed --> is_any_disabled<\/a>","cb9e9b8c":"Coming soon !","d92154b4":"Indeed, few videos have no description. But we're not here for NLP, this shouldn't be an issue.","467839e1":"When it comes to a video, you can:\n- **watch it**: this will count as a view\n- **interact with it**: like, dislike and\/or comment it. These three interactions tell long about how trending a video is and how divergent the opinions can be.\n\nAlso we'll compare with trending_time we computed.","e4597760":"# <a id='5'> 5 Correlations<\/a>","49ed4faa":"## <a id='4.1'>4.1 category_title --> category","91472247":"Observations:\n- Only very few videos can be trending when the flag video_error_or_removed is up. I'm not sure what it means: has the video become trending then it was removed by the author ? Or by Youtube ? Or is it a simple flag to say the video has been uploaded several times before it became trending ?\n- Overall, few videos become trending with any of these options disabled.\n\nThefore, we'll add a column containing a boolean set to True (or 1) if any of these 3 options is disabled:","92327989":"This could be a strong predictor - depending on the channel. Let's just lowercase the values.","07763e75":"This scatter_matrix can quickly show any simple relationship between these 4 columns **all Categories combined**. When it comes to opinions about videos, we expect them to diverge i.e. we expect outliers. Therefore, setting opacity < 1 helps seeing a tendency if there is one. For example, it looks like:\n- The number of **views** is correlated with the number of **comments** and **likes**.\n- The number of **likes** is correlated with the number of **comments**.\n- The number of **dislikes** doesn't seem correlated with other interactions except maybe for **comments**.  \n\nComputing correlations between these variables could confirm these assumptions.","160ace6c":"# <a id='6'> 6 Predicting trending time with Machine Learning<\/a>","b9054e34":"There's nothing much to do except count the title's length.","9244f546":"Hi there, my name's Luc, I'm a French 23 years old Data Science student about to graduate from my engineering school. This is my first kernel and I hope you'll like it. It is mainly focus on **data exploration** using graphic library Plotly and **predictive modeling**. For this study, I chose a recent dataset: Trending Youtube Videos Statistics. ","aa95e6e8":"## <a id='4.7'> 4.7 title<\/a>","4e0064c4":"### <a id='3.2'>3.2. Missing data","0f5c44ea":"## <a id='4.6'> 4.6 tags<\/a>","cc9d3f85":"# <a id='1'>1. Introduction","706a0787":"As we guessed:\n- views and likes are highly correlated (**0.81**) and are correlated with comments (**0.71**)\n- likes and comments are highly correlated (**0.85**)\n- dislikes are correlated with comments (**0.66**)\n\nRegarding other features:\n- **trending_time is not linearly correlated with any feature**.\n- neither are tags_count, description_length & title_length","078d1a0a":"# <a id='3'>3. Overview","81ff1c56":"> Be aware of the **colorscale**: it fits the different values but you'll see **different colors for very close values** when the range is short (e.g. Trailers).  \nAlso, the sliding bar is thin and grey hence might be hard to see. But you can use it: it's just right to the dropdown list, starting at the top.","4e7aac59":"## <a id='2.1'>2.1. Modules import","8ab3dad4":"# <a id='2'>2. Getting ready","4773bf93":"![Youtube](http:\/\/i.ytimg.com\/vi\/GZmGmkOJ9ME\/maxresdefault.jpg)","2053fbe4":"![](http:\/\/)Let's get video category and id to merge with main dataframe.","63d94bee":"## <a id='2.2'>2.2. Data import","b0ad20da":"We'll start by exploring each column using brand new version [Plotly 4.0](https:\/\/community.plot.ly\/t\/introducing-plotly-py-4-0-0\/25639), hoping to discover some interesting aspects of the data that may lead us to a relevant prediction problem.  \nAlso, I just heard about [plotly express](https:\/\/plot.ly\/python\/plotly-express) which allows us to create plotly graphs quite easily. Plotly team describes it this way: \"*plotly.express is to plotly what seaborn is to matplotlib*\". Let's try it already !","1389811d":"Let's first have a look at trending_time distribution:","b10ae3ac":"# Table of contents\n- <a href='#1'>1 Introduction<\/a>  \n- <a href='#2'>2 Getting ready<\/a> \n    - <a href='#2.1'>2.1 Module import<\/a> \n    - <a href='#2.2'>2.2 Data import<\/a>\n    - <a href='#2.3'>2.3 (Optional) JupyterLab extensions<\/a>\n- <a href='#3'>3. Overview<\/a>\n    - <a href='#3.1'>3.1 Head and merge tables<\/a>\n    - <a href='#3.2'>3.2 Missing data<\/a>\n- <a href='#4'>4 Distributions, data wrangling and new features<\/a>\n    - <a href='#4.1'>4.1 category<\/a>\n    - <a href='#4.2'>4.2 trending time<\/a>\n    - <a href='#4.3'>4.3 views, likes, dislikes and comments (interactions)<\/a>\n    - <a href='#4.4'>4.4 comments_disabled & ratings_disabled<\/a>\n    - <a href='#4.5'>4.5 description<\/a>\n    - <a href='#4.6'>4.6 tags<\/a>\n    - <a href='#4.7'>4.7 title<\/a>\n    - <a href='#4.8'>4.8 channel_title<\/a>\n- <a href='#5'>5 Correlations<\/a>\n- <a href='#6'>6 Predicting trending time with Machine Learning<\/a>","69eebfee":"# <a id='4'>4. Distributions, data wrangling and new features","c9882942":"Few videos have no description. Now, we could study the content using NLP but that's not my goal for this kernel.  \nStill, we can create a feature with the description length.","8582c930":"Here, we can retreive the number of tags of the video and tags themselves with simple string work.","62461b31":"## <a id='4.8'> 4.8 channel_title<\/a>","19b6b2cc":"## <a id='4.5'> 4.5 description<\/a>","a9e2e76d":"Also, we're given this json file:","e5b97def":"# Trending Youtube Video Statistics: EDA with Plotly\n\nKernel by Luc Tremsal","5fdf89c8":"### <a id='3.1'>3.1. Head and merge tables","b591a3b4":"Since this data were directly retreived from Youtube with an API, we assume it's quite clean.","0fda57ac":"This shows news more precise insights and, as expected, shows categories with more or less interaction and of different kinds. For example:\n- **Music** only reveals interactions between **views and dislikes (0.90)** and between **likes and comments (0.79)**. In the first case, this happens when a music video goes viral but is overall not appreciated. It actually goes beyond non-appreciation because most people click on the dislike button only when they deeply dislike or disagree with its content (politics, nudity, really cheap\/bad content, ...).\n- **Shows** and **Trailers** display high correlations with any combination, which is weird. If we look closely, Shows and Trailers gather respectively **114 and 11 videos**. Hence, **statistics are less reliable.**\n\nIn addition to that, there's an **enhanced disappointement effect**. Indeed, watching a video doesn't mean you'll like it. Regarding trending videos, this feeling can be strengthened when Youtube shows you a viral video and you may have high expectations. Therefore, it can push you to dislike it or leave a (negative) comment.","39b1fc7c":"## <a id='4.3'> 4.3 Views, likes, dislikes and comments (interactions)<\/a>","459ef598":"Then join on our main table."}}