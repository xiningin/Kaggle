{"cell_type":{"9010c1bf":"code","8ff43d9e":"code","9108b723":"code","477b13fd":"code","b816852b":"code","87633888":"code","bd3a3e64":"code","ba7e90fb":"code","b26ed7d2":"code","db995015":"code","15ef0ca5":"code","0fb2e923":"code","38d692dd":"code","ca83c3b2":"code","71255d65":"code","f0dd3375":"code","6963b307":"code","67b907fc":"code","fd5b343a":"code","cc613107":"code","eb8467e2":"code","bb2b72a2":"code","9fde2a43":"code","a775b7ff":"code","bb66d6ef":"code","aaf9ebbb":"code","e93ac7c0":"code","c0f837ab":"code","c8f60269":"code","76bfd741":"code","611ddd46":"code","0e7c45c9":"code","42993838":"code","624d2a14":"code","148da7f5":"code","ebe5f577":"code","5a5d61c0":"markdown","0bb68923":"markdown","2bb36bc9":"markdown","33accf41":"markdown"},"source":{"9010c1bf":"import pandas as pd\nimport numpy as np","8ff43d9e":"df_train = pd.read_csv('..\/input\/train.csv', index_col='id')\ndf_test = pd.read_csv('..\/input\/test.csv', index_col='id')\ndf_train.shape, df_test.shape","9108b723":"target = 'target'\n\nX_train = df_train.drop([target], axis=1).values\ny_train = df_train[target]","477b13fd":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom stability_selection import StabilitySelection","b816852b":"Cs = np.logspace(-5, 5, 21)\n\npipe = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(solver='lbfgs', verbose=1, n_jobs=1, random_state=42))\n])\n\nss = StabilitySelection(base_estimator=pipe, \n                        lambda_name='clf__C', lambda_grid=Cs, \n                        n_jobs=-1, verbose=1, random_state=42)","87633888":"%%time\nss.fit(X_train, y_train)","bd3a3e64":"ss.stability_scores_[0]","ba7e90fb":"ss","b26ed7d2":"from stability_selection import plot_stability_path","db995015":"fig, ax = plot_stability_path(ss, figsize=(12,8))\nax.set_xscale('log')","15ef0ca5":"ss_indices = np.where(ss.get_support() == True)[0]\nss_indices","0fb2e923":"len(ss_indices)","38d692dd":"X_train = ss.transform(X_train)\nX_train.shape","ca83c3b2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom mlxtend.feature_selection import SequentialFeatureSelector","71255d65":"pipe = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(solver='lbfgs', verbose=1, n_jobs=1, random_state=42))\n])\n\ncv = RepeatedStratifiedKFold(2, 50, random_state=42)\n\nsfs = SequentialFeatureSelector(pipe, k_features=(5,10), floating=True,\n                                scoring='roc_auc', cv=cv, verbose=1, n_jobs=-1)","f0dd3375":"%%time\nsfs.fit(X_train, y_train)","6963b307":"for idx in sfs.k_feature_idx_:\n    print(ss_indices[idx])","67b907fc":"len(sfs.k_feature_names_)","fd5b343a":"import matplotlib.pyplot as plt","cc613107":"scores = [v['avg_score'] for k, v in sfs.subsets_.items()]\nplt.plot(scores)","eb8467e2":"X_train = sfs.transform(X_train)\nX_train.shape","bb2b72a2":"from sklearn.model_selection import GridSearchCV","9fde2a43":"Cs = np.logspace(-5, 5, 21)\n\nparams = {\n    'clf__C': Cs\n}\n\npipe = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(solver='lbfgs', verbose=1, n_jobs=1, random_state=42))\n])\n\ncv = RepeatedStratifiedKFold(2, 100, random_state=42)\n\ngrid = GridSearchCV(estimator=pipe, param_grid=params, cv=cv,\n                    return_train_score=True,\n                    scoring='roc_auc', verbose=1, n_jobs=-1)","a775b7ff":"%%time\ngrid.fit(X_train, y_train)","bb66d6ef":"np.max(grid.cv_results_['mean_test_score'])","aaf9ebbb":"pipe = grid.best_estimator_\npipe","e93ac7c0":"import matplotlib.pyplot as plt","c0f837ab":"plt.semilogx(Cs, grid.cv_results_['mean_train_score'], label='train')\nplt.semilogx(Cs, grid.cv_results_['mean_test_score'], label='test')\nplt.xlabel('C')\nplt.ylabel('ROC-AUC')\nplt.grid()\nplt.legend()","c8f60269":"X_test = df_test.values\nfor t in [ss, sfs]:\n    X_test = t.transform(X_test)","76bfd741":"pipe.fit(X_train, y_train)","611ddd46":"y_pred = pipe.predict_proba(X_test)[:, 1]","0e7c45c9":"plt.hist(y_pred, bins=50)\npass","42993838":"df_subm = pd.read_csv('..\/input\/sample_submission.csv', index_col='id')","624d2a14":"df_subm[target] = y_pred","148da7f5":"df_subm.head()","ebe5f577":"df_subm.to_csv('submission.csv')","5a5d61c0":"Fitting model on all data and forecasting","0bb68923":"Let's find the best value of regularization penalty hyperparameter with selected features","2bb36bc9":"Attempt to select features for classification using \"Stability Selection\" algorythm introduced in https:\/\/stat.ethz.ch\/~nicolai\/stability.pdf.\n\nThe main idea of algorythm is iterative fitting of multiple models using bootstraped subsamples; `stable`(significant) features should occur in models more often than `unstable`(non significant).\n\nImplementation of `StabilitySelection` is now deprecated in *scikit-learn* package and moved into *scikit-learn-contrib* project https:\/\/github.com\/scikit-learn-contrib\/stability-selection\/tree\/master\/stability_selection.\n\nStability selection used here with default settings as 1-st step of feature selection pipeline and shrinks number of features from 300 to 85 (~ 4 times). As 2-nd step the `SequentialFeatureSelector` used here.","33accf41":"After selecting stable features let's try to select 5..10 most significant of them using `SequentialFeatureSelector` from *mlxtend* package"}}