{"cell_type":{"0664000e":"code","bdcb0f17":"code","b80c2cdf":"code","65c97e38":"code","ff1a8d6b":"code","4a99dd3f":"code","a84eb6f1":"code","3e480a09":"code","8723cfe3":"code","27df5aea":"code","49fe0555":"code","b9352ddf":"code","cf0801dc":"code","6449f3de":"code","3079cf47":"code","2eaae758":"code","27c90c65":"code","137b1650":"code","bd0ee69b":"code","b71d5c77":"code","a88b3395":"code","35c56423":"code","c2ee9d8d":"code","e0aa6a6d":"code","56d38eb2":"code","3b278910":"code","5c249b0b":"code","56877471":"code","b2a5dc3b":"code","a234669f":"code","1bf70de1":"code","8fd02230":"code","3867d3dc":"code","14b7f40e":"code","ca42f5fb":"markdown","02d8c741":"markdown","a9c58565":"markdown","843eece4":"markdown","abb93592":"markdown","9b5df85a":"markdown","bc4d14e4":"markdown","13801435":"markdown","73ef2974":"markdown","709d73cb":"markdown","6cee111c":"markdown","22aa0305":"markdown","3af72feb":"markdown","d1cf2b8e":"markdown","ced3ac99":"markdown","db36fd9b":"markdown","3d8aedd9":"markdown","971f8f49":"markdown","050a721c":"markdown","88311787":"markdown","09af5759":"markdown","66f0a383":"markdown","c4d8459a":"markdown","5972225b":"markdown","3c61e75f":"markdown","0d5517fc":"markdown","4a108bc8":"markdown","a46d6a17":"markdown","6020fdbd":"markdown","832de348":"markdown","979f2b12":"markdown","f8469a21":"markdown","5cbf8145":"markdown","6e487ec4":"markdown","16b3b2b3":"markdown","d2ff538c":"markdown"},"source":{"0664000e":"# We are importing WARNINGS class to suppress warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","bdcb0f17":"# We are importing all necessary classes which we will use in thsi report.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b80c2cdf":"titanic = pd.read_csv('..\/input\/titaniceda\/titanic_dataset.csv')","65c97e38":"titanic.shape","ff1a8d6b":"titanic.head(2)","4a99dd3f":"titanic.drop([\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home.dest\"],axis=1,inplace=True)","a84eb6f1":"titanic.head(2)","3e480a09":"titanic.describe()","8723cfe3":"titanic.describe(include=\"all\")","27df5aea":"titanic.isnull().any()\ntitanic.age.fillna(titanic.age.mean(), inplace=True)\ntitanic.fare.fillna(titanic.fare.mean(), inplace=True)\ntitanic.embarked.fillna(titanic.embarked.mode()[0], inplace=True)","49fe0555":"print(\"Male vs Females count on ship:\\n\")\nprint(titanic.Gender.value_counts())\n\npd1 = pd.DataFrame(list(titanic.Gender.value_counts()), index=[\"Male\", \"Female\"])\npd1.plot(kind=\"bar\", width=0.5, title=\"Male - Female Distribution\", legend=False)\nplt.show()","b9352ddf":"print(\"Not Survived(0) vs Survived(1):\\n\")\nprint(titanic.survived.value_counts())\n\npd1 = pd.DataFrame(list(titanic.survived.value_counts()), index=[\"Not Survived\", \"Survived\"])\npd1.plot.bar(width=0.5, alpha=0.5, title=\"How many survived?\", color=\"green\")\nplt.show()\n\nprint(\"% of People who survived is \",(round((500\/(500+809))*100,2)), \"%\")","cf0801dc":"male = titanic[titanic.Gender==\"male\"].Gender\nfemale = titanic[titanic.Gender==\"female\"].Gender\nmale_s = titanic[titanic.survived==1].Gender[titanic.Gender==\"male\"]\nfemale_s = titanic[titanic.survived==1].Gender[titanic.Gender==\"female\"]\n\nplt.figure(figsize=(16,10))\n\nplt.subplot(2,2,1)\nplt.title(\"Total Males and Females\")\nplt.ylim(0,900)\nplt.bar(\"female\",female.size, color=\"pink\", width=0.4)\nplt.text(\"female\",female.size+7,female.size)\nplt.bar(\"male\",male.size, width=0.4)\nplt.text(\"male\",male.size+7,male.size)\n\nplt.subplot(2,2,2)\nplt.title(\"Total Males and Females who Survived\")\nplt.ylim(0,900)\nplt.bar(\"female_s\",female_s.size, color=\"pink\", width=0.4)\nplt.text(\"female_s\",female_s.size+3,female_s.size)\nplt.bar(\"male_s\",male_s.size, width=0.4)\nplt.text(\"male_s\",male_s.size+3,male_s.size)\n\nplt.subplot(2,2,3)\nsns.swarmplot(x=\"Gender\", y=\"age\", data=titanic)\n\nplt.subplot(2,2,4)\nsns.swarmplot(x=\"Gender\", y=\"age\", data=titanic, hue=\"survived\", dodge=True)\n\nplt.show()\n\nprint(\"Males who survived = \",round((161\/843)*100,2), \"%\")\nprint(\"Females who survived = \",round((339\/466)*100,2), \"%\")","6449f3de":"# dataset = sns.load_dataset(r\"C:\\Users\\User\\Documents\\LearnBay Material\\Datasets\\titanic_dataset.csv\")\nplt.figure(figsize=(16,4))\nsns.distplot(titanic.age)\n# ax = sns.catplot(x=\"Gender\",y=\"age\", data=\"titanic_dataset\")\nplt.show()","3079cf47":"child = titanic.age[titanic.age<13]\nprint(\"Child: age<13\")\nteen = titanic.age[(titanic.age>12) & (titanic.age<20)]\nprint(\"Teen: age>12 and age<20\")\nadult = titanic.age[(titanic.age>19) & (titanic.age<60)]\nprint(\"Adult: age>19 and age<60\")\nold= titanic.age[titanic.age>59]\nprint(\"Old: age>59\")\n\nchild_s = titanic[titanic.survived==1].age[titanic.age<13]\nteen_s = titanic[titanic.survived==1].age[(titanic.age>12) & (titanic.age<20)]\nadult_s = titanic[titanic.survived==1].age[(titanic.age>19) & (titanic.age<60)]\nold_s= titanic[titanic.survived==1].age[titanic.age>59]\n\nplt.figure(figsize=(16,4))\n\nplt.subplot(1,2,1)\nplt.title(\"Total passengers_age wise\")\nplt.ylim(0,1200)\nplt.bar(\"child\",child.size)\nplt.text(\"child\",child.size+5,child.size)\nplt.bar(\"teen\",teen.size)\nplt.text(\"teen\",teen.size+5,teen.size)\nplt.bar(\"adult\",adult.size)\nplt.text(\"adult\",adult.size+5,adult.size)\nplt.bar(\"old\",old.size)\nplt.text(\"old\",old.size+5,old.size)\n\nplt.subplot(1,2,2)\nplt.title(\"Total passengers who survived_age wise\")\nplt.ylim(0,1200)\nplt.bar(\"child_s\",child_s.size)\nplt.text(\"child_s\",child_s.size+5,child_s.size)\nplt.bar(\"teen_s\",teen_s.size)\nplt.text(\"teen_s\",teen_s.size+5,teen_s.size)\nplt.bar(\"adult_s\",adult_s.size)\nplt.text(\"adult_s\",adult_s.size+5,adult_s.size)\nplt.bar(\"old_s\",old_s.size)\nplt.text(\"old_s\",old_s.size+10,old.size)\n\nplt.show()\n\nprint(\"Children who survived = \",round((54\/94)*100,2), \"%\")\nprint(\"Teenagers who survived = \",round((52\/131)*100,2), \"%\")\nprint(\"Adults who survived = \",round((382\/1044)*100,2), \"%\")\nprint(\"Old people who survived = \",round((40\/40)*100,2), \"%\")","2eaae758":"plt.figure(figsize=(16,4))\ntitanic.age[titanic.pclass==1].plot(kind=\"kde\")\ntitanic.age[titanic.pclass==2].plot(kind=\"kde\")\ntitanic.age[titanic.pclass==3].plot(kind=\"kde\")\nplt.legend(('1st Class','2nd Class','3rd Class'),loc = 'best')\nplt.xlabel(\"Age Distribution\")\nplt.ylabel(\"No. of people\")\n\nplt.show()","27c90c65":"plt.figure(figsize=(16,4))\nfor i in range(titanic.age.size):\n    if(titanic.age[i]>0 and titanic.age[i]<20):\n        plt.scatter(i, titanic.age[i], alpha=0.5, color=\"cyan\")\n    elif(titanic.age[i]>19 and titanic.age[i]<40):\n        plt.scatter(i, titanic.age[i], alpha=0.5, color=\"orange\")\n    elif(titanic.age[i]>39 and titanic.age[i]<60):\n        plt.scatter(i, titanic.age[i], alpha=0.5, color=\"green\")\n    else:\n        plt.scatter(i, titanic.age[i], alpha=0.5, color=\"red\")\nplt.xlabel(\"No of people\")\nplt.ylabel(\"Age Distribution\")\nplt.show()","137b1650":"pc1 = titanic[titanic.pclass==1].pclass\npc2 = titanic[titanic.pclass==2].pclass\npc3 = titanic[titanic.pclass==3].pclass\npc1_s = titanic[titanic.survived==1].pclass[titanic.pclass==1]\npc2_s = titanic[titanic.survived==1].pclass[titanic.pclass==2]\npc3_s = titanic[titanic.survived==1].pclass[titanic.pclass==3]\n\nplt.figure(figsize=(16,4))\n\nplt.subplot(1,2,1)\nplt.title(\"Total passengers (pclass-wise)\")\nplt.bar(\"1\",pc1.size, color=\"gold\")\nplt.text(\"1\",pc1.size+7,pc1.size)\nplt.bar(\"2\",pc2.size)\nplt.text(\"2\",pc2.size+5,pc2.size)\nplt.bar(\"3\",pc3.size)\nplt.text(\"3\",pc3.size+5,pc3.size)\n\nplt.subplot(1,2,2)\nplt.title(\"Total passengers who survived (pclass-wise)\")\nplt.bar(\"1\",pc1_s.size)\nplt.text(\"1\",pc1_s.size+2,pc1_s.size)\nplt.bar(\"2\",pc2_s.size)\nplt.text(\"2\",pc2_s.size+2,pc2_s.size)\nplt.bar(\"3\",pc3_s.size)\nplt.text(\"3\",pc3_s.size+2,pc3_s.size)\n\nplt.show()\n\nprint(\"P_Class=1 who survived = \",round((200\/323)*100,2), \"%\")\nprint(\"P_Class=2 who survived = \",round((119\/277)*100,2), \"%\")\nprint(\"P_Class=3 who survived = \",round((181\/709)*100,2), \"%\")","bd0ee69b":"train_df = pd.read_csv('\/kaggle\/input\/train-testing-dataset\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/train-testing-dataset\/test.csv')","b71d5c77":"#we will drop \"Cabin\" column as it is of no use in ML modelling\ntrain_df = train_df.drop('Cabin', axis=1)\n\n#we will now create a function to fill missing values in Age bt taking average age of each Pclass\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 28\n        else:\n            return 24\n    else:\n        return Age\n    \ntrain_df['Age'] = train_df[['Age', 'Pclass']].apply(impute_age, axis=1)\n\n#we will drop all columns with null attributes\ntrain_df.dropna(inplace=True)\n\n#we will remove all the non numerical columns and then use pd.get_dummies to get the dummy values of the Pclass & Sex column\nsex = pd.get_dummies(train_df['Sex'], drop_first=True)\nembarked = pd.get_dummies(train_df['Embarked'], drop_first=True)\n\n#as we have the dummy values of Pclass & Sex, so we will drop these (Name, Sex, Ticket, Embarked) columns \ntrain_df.drop(train_df[['Name', 'Sex', 'Ticket', 'Embarked']], axis=1, inplace=True)\ntrain_df = pd.concat([train_df, sex, embarked], axis=1)","a88b3395":"print(\"TRAINING Dataset:-\")\ntrain_df.head()","35c56423":"#we will now create a function to fill missing values in Age bt taking average age of each Pclass\ntest_df['Age'] = test_df[['Age', 'Pclass']].apply(impute_age, axis=1)\n\n#we will fill NULL values in \"Fare\" column by taking Mean of Fare column\ntest_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)\n\n#we will remove all the non numerical columns and then use pd.get_dummies to get the dummy values of the Pclass & Sex column\nsex_test = pd.get_dummies(test_df['Sex'], drop_first=True)\nembarked_test = pd.get_dummies(test_df['Embarked'], drop_first=True)\n\n#as we have the dummy values of Pclass & Sex, so we will drop these (Name, Sex, Ticket, Embarked) columns\ntest_df.drop(['Name', 'Sex', 'Embarked', 'Ticket', 'Cabin'], axis=1, inplace=True)\ntest_df = pd.concat([test_df, sex_test, embarked_test],  axis=1)","c2ee9d8d":"print(\"TESTING Dataset:-\")\ntest_df.head()","e0aa6a6d":"# We will create a Train-Test split of the Train_df dataset in order to find the best Classification Model.\nX_train = train_df.drop(['Survived', 'PassengerId'], axis=1)\ny_train = train_df['Survived']\nX_test = test_df.drop('PassengerId', axis=1)","56d38eb2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\nlog_pred = log_reg.predict(X_test)\nlog_score = round(log_reg.score(X_train, y_train) *100, 2)","3b278910":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nknn_score = round(knn.score(X_train, y_train) * 100, 2)","5c249b0b":"from sklearn.tree import DecisionTreeClassifier\nd_tree = DecisionTreeClassifier()\nd_tree.fit(X_train, y_train)\ndt_pred = d_tree.predict(X_test)\ndt_score = round(d_tree.score(X_train, y_train) * 100, 2)","56877471":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nrf_score = round(rf.score(X_train, y_train) * 100,2)","b2a5dc3b":"from sklearn.naive_bayes import GaussianNB\nguassian = GaussianNB()\nguassian.fit(X_train, y_train)\ngua_pred = guassian.predict(X_test)\ngua_score = round(guassian.score(X_train, y_train)*100, 2)","a234669f":"from sklearn.svm import SVC\nsvm = SVC()\nsvm.fit(X_train, y_train)\nsvm_predict = svm.predict(X_test)\nsvm_score = round(svm.score(X_train, y_train)*100, 2)","1bf70de1":"# We will now check scores of all the models by comparing against each other.","8fd02230":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', \n              'Decision Tree'],\n    'Score': [svm_score, knn_score, log_score, \n              rf_score, gua_score, dt_score]})\nmodels.sort_values(by='Score', ascending=False)","3867d3dc":"#We will now save a copy of submission file which will have just PassengerId and Survived as columns and exactly 418 rows exluding the header.","14b7f40e":"pid = test_df['PassengerId'].tolist()\npid\ndict = {'PassengerId': pid, 'Survived': dt_pred}  \n     \nsubmission = pd.DataFrame(dict) \nsubmission\nsubmission.to_csv('submission.csv') \n","ca42f5fb":"##### (d) To see Age distribution using Dist plot","02d8c741":"##### (We will do the same cleaning as we did in Training dataset)","a9c58565":"### 3. Data Cleaning of \"Test\" Dataset","843eece4":"# II. Prediction using various ML Models","abb93592":"##### (b) To see the first 2 rows of the dataset","9b5df85a":"##### (h) To see how many passengers survived (Passenger Class-wise)","bc4d14e4":"# EDA & ML Modelling Report on TITANIC Dataset\n* Analysis By: NEELESH DUGAR \n* Email: dugar.nilesh23@gmail.com \n* Mob: +91-7838823636","13801435":"### 4. Now Analysis Begins....","73ef2974":"##### ***1. Logistic Regression***","709d73cb":"## We can see that the DECISION TREE Classifier gives the \"Best Accuracy\" with a score of 98.09.","6cee111c":"##### (a) To drop the unwanted columns","22aa0305":"##### (b) To see the first 2 rows of the dataset, after dropping the columns","3af72feb":"##### (b) To see how many survived","d1cf2b8e":"### 2. Data Cleaning of \"Training\" Dataset ","ced3ac99":"##### (c) To see how many survived (Gender-wise)","db36fd9b":"##### (g) To see Age distribution with Scatter plot","3d8aedd9":"#### *2. K-Nearest Neighbor*","971f8f49":"##### (a) To see how many rows and columns are there in Titanic Dataset","050a721c":"##### (a) To see how many males and females were there on the ship","88311787":"### 1. Load the Test & Training Data","09af5759":"#### *6. Support Vector Machine*","66f0a383":"### 4. PREDICTIONS (Finding the best ML model)","c4d8459a":"##### (c) .describe() is used to get 5 Number Summary of the data (column-wise)","5972225b":"**INSIGHTS:-**\n    \n    1. % of people who survived is 38.19%.\n    2. 72.75% of all females survived, whereas, only 19.10% of all males survived.\n    3. All the old age people (whose age>59) survived, and more than 50% of kids (whose age<13) also survived.\n    4. Survival Rate (Passenger-Class wise) = PC1 > PC2 > PC3. This means who paid more were the ones who survived more.","3c61e75f":"# I. Exploratory Descriptive Analysis (EDA)","0d5517fc":"#### *4. Random Forest*","4a108bc8":"# ---INFERENCES---\n1. There are 1309 rows and 14 columns.\n2. Out of 14 columns, some are not of much importance, like, name, ticket, cabin, boat, body & home.dest. \n> >    So I am removing them from our dataframe.","a46d6a17":"##### (f) To see the distribution of age and passenger class","6020fdbd":"### 1. Load the dataset","832de348":"#### *3. Decision Tree*","979f2b12":"### 2. Dropping unwanted columns (This step is part of Data Cleansing)","f8469a21":"##### (d) if we use include=\"all\" as argument with .describe() method, it gives additional info about the data","5cbf8145":"##### (e) To see how many survived (Age-wise)","6e487ec4":"#### I hope this report is easy to understand for the beginners in this line. I will start posting more Notebooks in public on Kaggle to help those in need. And you can contact me for any queries\/collaboration\/discussion. My contact details are available at the Top. \n\nWelcome to Data Science & Machine Learning Club! All the best for future endeavours! :)","16b3b2b3":"### 3. Filling empty rows\/columns with appropriate data\n> (This step is part of Data Pre-processing)","d2ff538c":"#### *5. Naive Bayes*"}}