{"cell_type":{"d368a70d":"code","6f8201df":"code","d1780274":"code","6fd6ee18":"code","66fc1d11":"code","a4ed4d85":"code","305692a2":"code","122f3bc5":"code","0fd09bb9":"code","10c55ef5":"code","21b576b8":"code","ccc8905a":"code","f2229043":"code","1da2698b":"code","994ce169":"code","211ce067":"code","de1cfc83":"code","cd182aa0":"code","baf8b756":"markdown","db15810c":"markdown"},"source":{"d368a70d":"import torch\nimport numpy as np\nimport pandas as pd\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch\nimport matplotlib.pyplot as plt\nfrom torch.utils.data.sampler import SubsetRandomSampler\n%matplotlib inline","6f8201df":"import warnings\nwarnings.filterwarnings(\"ignore\")","d1780274":"# load dataset\ntrain_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","6fd6ee18":"print(\"Total number of samples\",len(train_data),\"\\nTotal pixels: \", len(train_data.columns))","66fc1d11":"train_data.head()","a4ed4d85":"class Get_Data(torch.utils.data.Dataset):\n    def __init__(self, data, transform=transforms.Compose([transforms.ToPILImage(),\n                                                                      transforms.RandomRotation(0, 0.5),\n                                                                      transforms.RandomHorizontalFlip(p=0.5),\n                                                                      transforms.ToTensor(),\n                                                                      transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n        \n        self.data = data\n        if len(data.columns) == len(train_data.columns):\n            self.X = data.iloc[:,1:].values.reshape((-1,28,28)).astype(np.float32)[:,:,:,None]\n            self.X = np.multiply(self.X, 1.0\/255.0)\n            self.y = torch.from_numpy(data.iloc[:,0].values)\n        else : \n            self.X = data.values.reshape((-1,28,28)).astype(np.float32)[:,:,:,None]\n            self.X = np.multiply(self.X, 1.0\/255.0)\n            self.y = None\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        if self.y is not None:\n            return self.transform(self.X[index]), self.y[index]\n        else:\n            return self.transform(self.X[index])\n","305692a2":"train_df = Get_Data(train_data)\ntest_df = Get_Data(test_data)\n","122f3bc5":"num_workers = 0\nvalid_size = 0.1\nbatch_size = 128\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)","0fd09bb9":"train_loader = torch.utils.data.DataLoader(train_df, batch_size=batch_size,\n    sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_df, batch_size=batch_size, \n    sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_df, batch_size=batch_size, \n    num_workers=num_workers)","10c55ef5":"import matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\n    \n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy()\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20\/2, idx+1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(images[idx]), cmap=matplotlib.cm.binary)\n    # print out the correct label for each image\n    # .item() gets the value contained in a Tensor\n    ax.set_title(str(labels[idx].item()))","21b576b8":"img = np.squeeze(images[1])\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nax.imshow(img, cmap='gray')\nwidth, height = img.shape\nthresh = img.max()\/2.5\nfor x in range(width):\n    for y in range(height):\n        val = round(img[x][y],2) if img[x][y] >=0 else 0\n        ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center',\n                    color='white' if img[x][y]<thresh else 'black')","ccc8905a":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# define the NN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.features =nn.Sequential(\n            nn.Conv2d(1,64,kernel_size = 3, stride = 1 , padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.MaxPool2d(2,2),\n            nn.Conv2d(64,128,kernel_size = 3, stride = 1 , padding = 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.MaxPool2d(2,2),\n            nn.Conv2d(128,256,kernel_size = 3, stride = 1 , padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.MaxPool2d(2,2),\n            nn.Conv2d(256,512,kernel_size = 3, stride = 1 , padding = 2),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n            nn.MaxPool2d(2,2),\n            nn.Conv2d(512,1024,kernel_size = 3, stride = 1 , padding = 2),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(True),\n            nn.MaxPool2d(2,2))\n        self.fc1 = nn.Linear(1024*2*2,512)\n        self.fc2 = nn.Linear( 512,10)\n        self.dropout = nn.Dropout(0.8)\n        \n    def forward(self, x):\n        # flatten image input\n        x = self.features(x)\n        x = self.dropout(x)\n        x = x.view(-1,1024*2*2)\n        # add hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        # add hidden layer, with relu activation function\n        x = self.fc2(x)\n        # add dropout layer\n        return x\n\n# initialize the NN\nmodel = Net()\nprint(model)\n\n","f2229043":"import torch.optim as optim\nfrom torch.optim import lr_scheduler\ntrain_on_gpu = torch.cuda.is_available()\nif train_on_gpu:\n        model.cuda()\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.0001,betas= (0.9,0.999))\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n","1da2698b":"# number of epochs to train the model\nn_epochs =60\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    ###################\n    # train the model #\n    ###################\n    model.train()\n    exp_lr_scheduler.step()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n        \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss < valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), '.\/model.pt')\n        valid_loss_min = valid_loss","994ce169":"model.load_state_dict(torch.load('model.pt'))","211ce067":"from torch.autograd import Variable\nmodel.eval()\ntest_pred = torch.LongTensor()\n\nfor i, data in enumerate(test_loader):\n    data = Variable(data, volatile=True)\n    if torch.cuda.is_available():\n        data = data.cuda()\n\n    output = model(data)\n\n    pred = output.cpu().data.max(1, keepdim=True)[1]\n    test_pred = torch.cat((test_pred, pred), dim=0)\n\n","de1cfc83":"sub = pd.DataFrame(np.c_[np.arange(1, len(test_df)+1)[:,None], test_pred.numpy()], \n                      columns=['ImageId', 'Label'])","cd182aa0":"sub.to_csv('submission.csv', index=False)","baf8b756":"# Exploring Dataset","db15810c":"**Viewing Image in More Detail**"}}