{"cell_type":{"79adef81":"code","412154e5":"code","4fe133fa":"code","b3eac9bf":"code","ff6a2572":"code","87eb7c5e":"code","b8b1d4a5":"code","25cabdf5":"code","90590151":"code","e2ea26b5":"code","56237006":"markdown","06254b74":"markdown","bd7dbeb6":"markdown","0c58e1d5":"markdown","bebf0a0c":"markdown"},"source":{"79adef81":"# Cargar datos\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing.image import ImageDataGenerator\n\nENTRENAMIENTO_DIR = \"\/kaggle\/input\/anime-faces\/data\/\"\nSIZE = 64\n\n# configuracion de entrenamiento\ndatagen = ImageDataGenerator(rescale = 1.\/255)\n\n# generador\ngen = datagen.flow_from_directory(\n    ENTRENAMIENTO_DIR,\n    target_size=(SIZE,SIZE),\n    batch_size=16,\n    class_mode='input'\n)","412154e5":"K = keras.backend\n\nclass Sampling(keras.layers.Layer):\n    def call(self, inputs):\n        mean, log_var = inputs\n        return K.random_normal(tf.shape(log_var)) * K.exp(log_var \/ 2) + mean\n    \ndef rounded_accuracy(y_true, y_pred):\n    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))","4fe133fa":"tf.random.set_seed(42)\nnp.random.seed(42)\ncodings_size = 25\n\n# ENCODER\ninputs = keras.layers.Input(shape=[64, 64,3])\nz = keras.layers.Flatten()(inputs)\nz = keras.layers.Dense(256, activation=\"selu\")(z)\nz = keras.layers.Dense(128, activation=\"selu\")(z)\nz = keras.layers.Dense(64, activation=\"selu\")(z)\ncodings_mean = keras.layers.Dense(codings_size)(z) # media\ncodings_log_var = keras.layers.Dense(codings_size)(z) # std\ncodings = Sampling()([codings_mean, codings_log_var]) # generacion de los codings del mean y std (Guasiana)\nvariational_encoder = keras.models.Model(\n    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n\n# DECODER\ndecoder_inputs = keras.layers.Input(shape=[codings_size])\nx = keras.layers.Dense(64, activation=\"selu\")(decoder_inputs)\nx = keras.layers.Dense(128, activation=\"selu\")(x)\nx = keras.layers.Dense(256, activation=\"selu\")(x)\nx = keras.layers.Dense(512, activation=\"selu\")(x)\nx = keras.layers.Dense(1024, activation=\"selu\")(x)\nx = keras.layers.Dense(64 * 64*3, activation=\"sigmoid\")(x)\noutputs = keras.layers.Reshape([64, 64,3])(x)\nvariational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n\n# VARIATIONAL AE\n_, _, codings = variational_encoder(inputs)\nreconstructions = variational_decoder(codings)\nvariational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n\n# LATENT LOSS\nlatent_loss = -0.5 * K.sum(\n    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n    axis=-1)\nvariational_ae.add_loss(K.mean(latent_loss) \/ 784.)\n\n","b3eac9bf":"# COMPILE & TRAIN\nvariational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[rounded_accuracy])\nhistory = variational_ae.fit_generator(gen, epochs=40, shuffle=True)","ff6a2572":"def plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n    \ndef show_reconstructions(model, images=gen, n_images=5):\n    images, classes_batch = next(gen)\n    reconstructions = model.predict(images[:n_images])\n    fig = plt.figure(figsize=(n_images * 1.5, 3))\n    for image_index in range(n_images):\n        plt.subplot(2, n_images, 1 + image_index)\n        plot_image(images[image_index])\n        plt.subplot(2, n_images, 1 + n_images + image_index)\n        plot_image(reconstructions[image_index])\n        \ndef plot_multiple_images(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","87eb7c5e":" images, classes_batch = next(gen)","b8b1d4a5":"images.shape","25cabdf5":"show_reconstructions(variational_ae)\nplt.show()","90590151":"tf.random.set_seed(24)\n\ncodings = tf.random.normal(shape=[12, codings_size])\ncodings.shape\nimages = variational_decoder(codings).numpy()\nplot_multiple_images(images, 4)","e2ea26b5":"tf.random.set_seed(48)\nnp.random.seed(48)\n\ncodings_grid = tf.reshape(codings, [1, 3, 4, codings_size])\nlarger_grid = tf.image.resize(codings_grid, size=[5, 5])\ninterpolated_codings = tf.reshape(larger_grid, [-1, codings_size])\nimages = variational_decoder(interpolated_codings).numpy()\n\nplt.figure(figsize=(7, 5))\nfor index, image in enumerate(images):\n    plt.subplot(5,5, index + 1)\n    if index%7%2==0 and index\/\/7%2==0:\n        plt.gca().get_xaxis().set_visible(False)\n        plt.gca().get_yaxis().set_visible(False)\n    else:\n        plt.axis(\"off\")\n    plt.imshow(image, cmap=\"binary\")","56237006":"# Interpolaci\u00f3n Sem\u00e1ntica","06254b74":"# Generaci\u00f3n de im\u00e1genes","bd7dbeb6":"# Entrenamiento","0c58e1d5":"# Modelo Variacional Profundo","bebf0a0c":"# Carga de im\u00e1genes"}}