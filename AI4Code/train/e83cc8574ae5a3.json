{"cell_type":{"4e0337bb":"code","47d1a20d":"code","4679bd21":"code","09252451":"code","0256a76b":"code","2ee67562":"code","1f782f2c":"code","22c97820":"code","6901b2f2":"code","82edc58d":"code","b3b9a890":"code","dea9aff6":"code","356ee28e":"code","b621d8e6":"code","6f75e565":"code","33afd91c":"code","9b5237df":"code","cbc3ad83":"code","0fbb35b5":"code","90820d57":"code","80d32e91":"code","e853f514":"code","78b49aa8":"code","fede2ba8":"code","8ce56bbf":"code","e79131ed":"code","1704bee4":"code","1507fae5":"code","ec3a3235":"code","adbf1b5b":"code","45b473d4":"code","9fdb27b4":"code","02ef4d23":"code","4991874d":"code","20d726b1":"code","cec7dcfe":"code","d201ed05":"code","f49d843a":"code","ff409b43":"code","055f1a28":"code","cd9b1948":"code","2c40b768":"code","3acd9b46":"code","17e8885f":"code","ca5db8e4":"code","a3269f8a":"code","cf5f9db6":"code","94816a39":"code","9b1c1de8":"markdown","ef3fd14c":"markdown","435f585e":"markdown","cd68a1cf":"markdown","6017b897":"markdown","af454dea":"markdown","32d836b6":"markdown","abf3bb21":"markdown","465c28c9":"markdown","c39c9781":"markdown","f782f123":"markdown","725bb41d":"markdown","4a9665d6":"markdown","644ac5c6":"markdown","a799ef51":"markdown","293aabaa":"markdown","91badc73":"markdown","cdfb6179":"markdown","3bc40d1d":"markdown","e319237d":"markdown","24b2b0df":"markdown","88dfa750":"markdown","e5c03ca7":"markdown","f959bdd2":"markdown","2d8d922d":"markdown","0a07f0e9":"markdown","40efb24f":"markdown","9d637885":"markdown","994410cc":"markdown","34b3a2bb":"markdown","3a372951":"markdown"},"source":{"4e0337bb":"!pip install plotly\n!pip install chart_studio\n!pip install cufflinks","47d1a20d":"import os\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom scipy.stats import skew\nfrom pandas_profiling import ProfileReport\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport chart_studio.plotly as py\nimport cufflinks as cf\nimport plotly.express as px\n%matplotlib inline\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected = True)\ncf.go_offline();\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.base import  clone\n\nimport xgboost as xgb\ncolors = ['#494BD3','#E28AE2','#F1F481','#79DB80','#DF5F5F',\n          '#69DADE','#C2E37D','#E26580','#D39F49','#B96FE3']\n\nsns.palplot(sns.color_palette(colors))\nplt.title('Notebook Colors', size = 12)\nplt.axis('off')\nplt.show()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4679bd21":"auto = pd.read_csv('\/kaggle\/input\/autompg-dataset\/auto-mpg.csv', na_values = \"?\")\ndf = auto.copy()\nauto_misspelled = {'chevroelt': 'chevrolet',\n                   'chevy': 'chevrolet',\n                   'vokswagen': 'volkswagen',\n                   'vw': 'volkswagen',\n                   'hi': 'harvester',\n                   'maxda': 'mazda',\n                   'toyouta': 'toyota',\n                   'mercedes-benz': 'mercedes'}\n\ndf['brand'] = [auto_misspelled[key].title() if key in auto_misspelled else \\\n               key.title() for key in [i.split()[0] for i in df['car name']]]\n\ndf['name'] = [' '.join(i.split()[1:]).title() for i in df['car name']]\ndf = df.drop(columns = 'car name', axis = 0)\ndf.head()","09252451":"def check_df(dataframe, head=5):\n    \n    print(\" SHAPE \".center(70,'-'))\n    print('Rows: {}'.format(dataframe.shape[0]))\n    print('Columns: {}'.format(dataframe.shape[1]))\n    print(\" TYPES \".center(70,'-'))\n    print(dataframe.dtypes)\n    print(\" HEAD \".center(70,'-'))\n    print(dataframe.head(head))\n    print(' TAIL '.center(70,'-'))\n    print(dataframe.tail(head))\n    print(' MISSING VALUES '.center(70,'-'))\n    print(dataframe.isnull().sum())\n    print(' DUPLICATED VALUES '.center(70,'-'))\n    print(dataframe.duplicated().sum())\n    print(\" QUANTILES \".center(70,'-'))\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)","0256a76b":" df.profile_report()","2ee67562":"def check_class(dataframe):\n    nunique_df = pd.DataFrame({'Variable': dataframe.columns,\n                               'Classes': [dataframe[i].nunique() \\\n                                           for i in dataframe.columns]})\n\n    nunique_df = nunique_df.sort_values('Classes', ascending=False)\n    nunique_df = nunique_df.reset_index(drop = True)\n    return nunique_df\n\ncheck_class(df)","1f782f2c":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","22c97820":"def desc_stats(dataframe):\n    desc = dataframe.describe().T\n    desc_df = pd.DataFrame(index= dataframe.columns, \n                           columns= desc.columns,\n                           data= desc)\n    \n    f,ax = plt.subplots(figsize=(10,\n                                 desc_df.shape[0]*0.78))\n    sns.heatmap(desc_df,\n                annot=True,\n                cmap = \"Blues\",\n                fmt= '.2f',\n                ax=ax,\n                linecolor='#C6D3E5',\n                linewidths = 1.3,\n                cbar = False,\n                annot_kws={\"size\": 14})\n    plt.xticks(size = 18)\n    plt.yticks(size = 14,\n               rotation = 0)\n    plt.title(\"Descriptive Statistics\", size = 16)\n    plt.show()\n    \ndesc_stats(df[num_cols])","6901b2f2":"def cat_summary(dataframe, col_name):\n    fig = make_subplots(rows=1,cols=2,\n                        subplot_titles=('Countplot','Percentages'),\n                        specs=[[{\"type\": \"xy\"}, {'type':'domain'}]])\n\n    fig.add_trace(go.Bar( y = dataframe[col_name].value_counts().values.tolist(), \n                          x = [str(i) for i in dataframe[col_name].value_counts().index], \n                          text=dataframe[col_name].value_counts().values.tolist(),\n                          textfont=dict(size=15),\n                          name = col_name,\n                          textposition = 'auto',\n                          showlegend=False,\n                          marker=dict(color = colors,\n                                      line=dict(color='#DBE6EC',\n                                                width=1))),\n                  row = 1, col = 1)\n    \n    fig.add_trace(go.Pie(labels=dataframe[col_name].value_counts().keys(),\n                         values=dataframe[col_name].value_counts().values,\n                         textfont = dict(size = 20),\n                         textposition='auto',\n                         showlegend = False,\n                         name = col_name,\n                         marker=dict(colors=colors)),\n                  row = 1, col = 2)\n    \n    fig.update_layout(title={'text': col_name,\n                             'y':0.9,\n                             'x':0.5,\n                             'xanchor': 'center',\n                             'yanchor': 'top'},\n                      template='plotly_white')\n    \n    iplot(fig)\n\nfor i in cat_cols:\n    cat_summary(df,i)","82edc58d":"def num_summary(dataframe, col_name):\n    fig = make_subplots(rows=1,cols=2,\n                        subplot_titles=('Quantiles','Distribution'))\n\n    fig.add_trace(go.Box(y=dataframe[col_name],\n                         name = str(col_name),\n                         showlegend = False,\n                         marker_color = colors[1]),\n                  row = 1, col = 1)\n    \n    fig.add_trace(go.Histogram(x = dataframe[col_name],\n                               xbins = dict(start = dataframe[col_name].min(),\n                                            end = dataframe[col_name].max()),\n                               showlegend = False,\n                               name = str(col_name),\n                               marker=dict(color=colors[0],\n                                           line=dict(color='#DBE6EC',\n                                                     width=1))),\n                  row = 1, col = 2)\n    \n    fig.update_layout(title={'text': col_name,\n                             'y':0.9,\n                             'x':0.5,\n                             'xanchor': 'center',\n                             'yanchor': 'top'},\n                      template='plotly_white')\n    \n    iplot(fig)\n\nfor i in num_cols:\n    num_summary(df,i)","b3b9a890":"fig = px.bar(df[['horsepower','brand','name']]. \\\n             sort_values('horsepower', ascending = False)[:10],\n             y = 'name',\n             x = 'horsepower',\n             text='horsepower',\n             labels={'name':'',\n                     'horsepower': 'Horsepower',\n                     'brand': ''},\n             color = 'brand',\n             color_discrete_sequence = colors)\n\nfig.update_layout(title= dict(text = 'TOP 10 Horsepower',\n                              x = 0.5,\n                              y = 0.95,\n                              xanchor = 'center',\n                              yanchor = 'top'),\n                  xaxis = dict(title = 'Horsepower'),\n                  yaxis = dict(categoryorder='total ascending'),\n                  font=dict(family='Verdana',\n                            size=14,\n                            color='black'),\n                  template='plotly_white')\n\nfig.show()","dea9aff6":"fig = px.bar(df[['weight','brand','name']]. \\\n             sort_values('weight', ascending = False)[:10],\n             y = 'name',\n             x = 'weight',\n             text='weight',\n             labels={'name':'',\n                     'weight': 'Weight',\n                     'brand': ''},\n             color = 'brand',\n             color_discrete_sequence = colors)\n\nfig.update_layout(title= dict(text = 'TOP 10 Weight',\n                              x = 0.5,\n                              y = 0.95,\n                              xanchor = 'center',\n                              yanchor = 'top'),\n                  xaxis = dict(title = 'Weight'),\n                  yaxis = dict(categoryorder='total ascending'),\n                  font=dict(family='Verdana',\n                            size=14,\n                            color='black'),\n                  template='plotly_white')\n\nfig.show()","356ee28e":"data = [go.Scatter(x = df['mpg'],\n                   y = df['horsepower'],\n                   mode = 'markers',\n                   text=df['weight'],\n                   marker=dict(size=10,\n                               color = df['weight'],\n                               showscale=True,\n                               colorscale = 'Viridis',\n                               colorbar = dict(title='Weight'),\n                               opacity=0.8))]\n\nlayout = go.Layout(title=dict(text='Horsepower - MPG - Weight',\n                              y=0.9,\n                              x=0.5,\n                              xanchor= 'center',\n                              yanchor= 'top'),\n                              xaxis = dict(title='MPG'),\n                              yaxis =dict(title='Horsepower'),\n                   template='plotly_white')\n\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","b621d8e6":"data = go.Scatter3d(x = df['horsepower'],\n                    y = df['mpg'],\n                    z = df['displacement'],\n                    mode='markers', marker=dict(color=df['weight'],\n                                                showscale=True,\n                                                colorbar=dict(title='Weight'),\n                                                colorscale = 'Viridis',\n                                                opacity=0.7))\n\nlayout = go.Layout(title = dict(text='Horsepower - MPG - Displacement - Weight',\n                                y=0.9,\n                                x=0.5,\n                                xanchor= 'center',\n                                yanchor= 'top'),\n                   scene = dict(xaxis = dict(title='Horsepower'),\n                                yaxis = dict(title = 'MPG'),\n                                zaxis = dict(title='Displacement')),\n                   template='plotly_white')\n\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","6f75e565":"fig = go.Figure(data=go.Splom(dimensions=[dict(label='mpg',\n                                               values=df['mpg']),\n                                          dict(label='displacement',\n                                               values=df['displacement']),\n                                          dict(label='horsepower',\n                                               values=df['horsepower']),\n                                          dict(label='weight',\n                                               values=df['weight']),\n                                          dict(label='acceleration',\n                                               values=df['acceleration']),\n                                          dict(label='model year',\n                                               values=df['model year'])],\n                showupperhalf=True, \n                text=df['cylinders'],\n                marker=dict(color = [colors[i] for i in df['cylinders']. \\\n                                     astype('category').cat.codes],\n                            showscale = False,\n                            opacity = 0.65)))\n\nfig.update_layout(title = {'text': 'Pairwise Relationships by Cylinders',\n                          'xanchor': 'center',\n                          'yanchor': 'top',\n                          'x': 0.5,\n                          'y': 0.95},\n                  width=950,\n                  height=950,\n                  template = 'plotly_white')\n\niplot(fig)","33afd91c":"fig = go.Figure(data=go.Splom(dimensions=[dict(label='mpg',\n                                               values=df['mpg']),\n                                          dict(label='displacement',\n                                               values=df['displacement']),\n                                          dict(label='horsepower',\n                                               values=df['horsepower']),\n                                          dict(label='weight',\n                                               values=df['weight']),\n                                          dict(label='acceleration',\n                                               values=df['acceleration']),\n                                          dict(label='model year',\n                                               values=df['model year'])],\n                showupperhalf=True, \n                text=df['origin'],\n                marker=dict(color = [colors[i] for i in df['origin']. \\\n                                     astype('category').cat.codes],\n                            showscale = False,\n                            opacity = 0.65)))\n\nfig.update_layout(title = {'text': 'Pairwise Relationships by Origins',\n                          'xanchor': 'center',\n                          'yanchor': 'top',\n                          'x': 0.5,\n                          'y': 0.95},\n                  width=950,\n                  height=950,\n                  template = 'plotly_white')\n\niplot(fig)","9b5237df":"def pearson_corr(dataframe):\n    sns.set_style(\"white\")\n    matrix = np.triu(dataframe.corr(method=\"pearson\"))\n    f,ax=plt.subplots(figsize = (matrix.shape[0]*0.75,\n                                 matrix.shape[1]*0.75))\n    sns.heatmap(dataframe.corr(method=\"pearson\"),\n                annot= True,\n                fmt = \".2f\",\n                ax=ax,\n                vmin = -1,\n                vmax = 1,\n                mask = matrix,\n                cmap = \"Blues\",\n                linewidth = 0.4,\n                linecolor = \"white\",\n                annot_kws={\"size\": 12})\n    plt.xticks(rotation=80,size=14)\n    plt.yticks(rotation=0,size=14)\n    plt.title('Pearson Correlation Map', size = 14)\n    plt.show()\n    \npearson_corr(df)","cbc3ad83":"def spearman_corr(dataframe):\n    sns.set_style(\"white\")\n    matrix = np.triu(dataframe.corr(method=\"spearman\"))\n    f,ax=plt.subplots(figsize = (matrix.shape[0]*0.75,\n                                 matrix.shape[1]*0.75))\n    sns.heatmap(dataframe.corr(method = \"spearman\"),\n                annot= True,\n                fmt = \".2f\",\n                ax=ax,\n                vmin = -1,\n                vmax = 1,\n                mask = matrix,\n                cmap = \"Blues\",\n                linewidth = 0.4,\n                linecolor = \"white\",\n                annot_kws={\"size\": 12})\n    plt.xticks(rotation=80,size=14)\n    plt.yticks(rotation=0,size=14)\n    plt.title('Spearman Rank Correlation Map', size = 14)\n    plt.show()\n    \nspearman_corr(df)","0fbb35b5":"def check_missing(dataframe):\n    \n    missing = pd.DataFrame({'Variable': dataframe.columns,\n                           'Missing': [dataframe[i].isnull().sum() for i in dataframe.columns],\n                           'Ratio': [100 * dataframe[i].isnull().sum() \/ dataframe.shape[0] \\\n                                    for i in dataframe.columns]})\n    missing = missing[missing['Missing'] > 0]\n    \n    if missing.shape[0] == 0:\n        print('No missing values')\n    else:\n        missing = missing.reset_index(drop = True)\n        missing = missing.sort_values('Missing', ascending = False)\n        return missing\n    \ncheck_missing(df)","90820d57":"df.groupby(cat_cols).agg({'horsepower': ['mean','median']})","80d32e91":"df['horsepower'] = df['horsepower'].fillna(df.groupby(cat_cols) \\\n                                           ['horsepower'].transform('median'))\n\ncheck_missing(df)","e853f514":"def outlier_thresholds(dataframe, col_name, q1 = 0.25, q3 = 0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable, q1 = 0.25, q3 = 0.75):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1 = q1, q3 = q3)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n    \nfor col in df[num_cols].columns:\n    replace_with_thresholds(df, col, q1 = 0.1, q3 = 0.9)\n    \ndesc_stats(df[num_cols])","78b49aa8":"sns.set_style('darkgrid')\nplt.figure(figsize = (8,6))\nsns.distplot(df.mpg, fit= norm)\nplt.show()","fede2ba8":"(mu, sigma) = norm.fit(df[\"mpg\"])\nprint(\"mu: {} sigma = {}\".format(mu, sigma))","8ce56bbf":"fig = plt.figure(figsize = (8,6))\nstats.probplot(df[\"mpg\"], plot = plt)\nplt.title(\"Before Log1p Transformation\", size = 12)\nplt.show()","e79131ed":"df[\"mpg\"] = np.log1p(df[\"mpg\"])\n\nplt.figure(figsize = (8,6))\nsns.distplot(df.mpg, fit= norm)\nplt.show()","1704bee4":"(mu, sigma) = norm.fit(df[\"mpg\"])\nprint(\"mu: {} sigma = {}\".format(mu, sigma))","1507fae5":"fig = plt.figure(figsize = (8,6))\nstats.probplot(df[\"mpg\"], plot = plt)\nplt.title(\"After Log1p Transformation\", size = 12)\nplt.show()","ec3a3235":"def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n    dataframe = pd.get_dummies(dataframe,\n                               columns = categorical_cols,\n                               drop_first = drop_first)\n    return dataframe\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2]\nprint('Binary Variables: {}'.format(binary_cols))\n\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\nohe_cols.append('brand')\nprint('Multiclass Variables: {}'.format(ohe_cols))","adbf1b5b":"df['cylinders'] = df['cylinders'].astype(int)\ndf['origin'] = df['origin'].astype(int)\ndf = one_hot_encoder(df, ohe_cols)\ndf.head()","45b473d4":"check_class(df)","9fdb27b4":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","02ef4d23":"def rare_analyser(dataframe, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe)}), end=\"\\n\\n\\n\")\n\nrare_analyser(df, cat_cols)","4991874d":"useless_cols = [col for col in df.columns if df[col].nunique() == 2 and\n                (df[col].value_counts() \/ len(df) < 0.03).any(axis=None)]\n\nprint('Number of useless variables: {}'.format(len(useless_cols)))\ndf.drop(useless_cols, axis=1, inplace=True)","20d726b1":"pearson_corr(df)","cec7dcfe":"spearman_corr(df)","d201ed05":"check_df(df)","f49d843a":"df = df.drop(['name'], axis = 1)\nx = df.drop([\"mpg\"], axis = 1)\ny = df.mpg\nx.head()","ff409b43":"test_size = 0.2\nrandom_state = 42\nX_train, X_test, Y_train, Y_test = train_test_split(x,\n                                                    y,\n                                                    test_size  = test_size,\n                                                    random_state = random_state)","055f1a28":"scaler = StandardScaler() #RobustScaler - StandardScaler\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","cd9b1948":"knn_reg = KNeighborsRegressor(n_neighbors = 5,\n                              weights ='uniform',\n                              metric = 'minkowski',\n                              algorithm = 'auto')\n\nknn_reg.fit(X_train,Y_train)\n\ny_predicted_dummy = knn_reg.predict(X_test)\n\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"KNN Regression MSE:\", mse)","2c40b768":"n_folds = 10\nknn_reg_grid_params = {'n_neighbors': [3,4,5,6,7,11,13,15,19,45,64],\n                      'weights': ['uniform', 'distance'],\n                      'metric': ['minkowski','euclidean','manhattan'],\n                      'algorithm':['auto', 'kd_tree']}\n\nknn_reg_grid = GridSearchCV(knn_reg,\n                            knn_reg_grid_params,\n                            cv = n_folds,\n                            verbose = 2,\n                            n_jobs = -1)\n\nknn_reg_grid.fit(X_train, Y_train)\ny_predicted_dummy = knn_reg_grid.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Tuned KNN Reg MSE:\", mse)","3acd9b46":"lr = LinearRegression()\nlr.fit(X_train,Y_train)\n\nprint(\"LR Coef:\", lr.coef_, '\\n')\ny_predicted_dummy = lr.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Linear Regression MSE:\", mse)","17e8885f":"sns.set_style('whitegrid')\nridge = Ridge(random_state = random_state,\n              max_iter = 10000)\nalphas = np.logspace(-4,-0.5,30)\ntuned_parameters = [{'alpha':alphas}]\nn_folds = 5\n\nclf = GridSearchCV(ridge,\n                   tuned_parameters,\n                   cv = n_folds,\n                   scoring= \"neg_mean_squared_error\",\n                   refit = True)\n\nclf.fit(X_train, Y_train)\nscores = clf.cv_results_[\"mean_test_score\"]\nscores_std = clf.cv_results_[\"std_test_score\"]\n\nprint(\"Ridge Coef:\", clf.best_estimator_.coef_, '\\n')\nridge = clf.best_estimator_\nprint(\"Ridge Best Estimator:\", ridge, '\\n')\ny_predicted_dummy = clf.predict(X_test)\n\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Ridge MSE:\", mse)\nprint(\"--------------------------------------\")\n\nplt.figure(figsize = (8,6))\nplt.semilogx(alphas, scores)\nplt.xlabel(\"alpha\")\nplt.ylabel(\"score\")\nplt.title(\"Ridge\")","ca5db8e4":"lasso = Lasso(random_state = random_state,\n              max_iter = 10000)\ntuned_parameters = [{'alpha':alphas}]\n\nclf = GridSearchCV(lasso,\n                   tuned_parameters,\n                   cv = n_folds,\n                   scoring= \"neg_mean_squared_error\",\n                   refit = True)\nclf.fit(X_train, Y_train)\nscores = clf.cv_results_[\"mean_test_score\"]\nscores_std = clf.cv_results_[\"std_test_score\"]\n\nprint(\"Lasso Coef:\", clf.best_estimator_.coef_, '\\n')\nlasso = clf.best_estimator_\n\nprint(\"Lasso Best Estimator:\", lasso, '\\n')\ny_predicted_dummy = clf.predict(X_test)\n\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Lasso MSE:\", mse)\nprint(\"--------------------------------------\")\n\nplt.figure(figsize = (8,6))\nplt.semilogx(alphas, scores)\nplt.xlabel(\"alpha\")\nplt.ylabel(\"score\")\nplt.title(\"Lasso\")","a3269f8a":"parametersGrid = {'alpha':alphas,\n                  'l1_ratio': np.arange(0.0,1.0,0.05)}\n\neNet = ElasticNet(random_state = random_state, max_iter = 10000)\nclf = GridSearchCV(eNet, parametersGrid,\n                   cv = n_folds,\n                   scoring= \"neg_mean_squared_error\",\n                   refit = True)\nclf.fit(X_train, Y_train)\n\nprint(\"ElasticNet Coef:\", clf.best_estimator_.coef_, '\\n')\nprint(\"ElasticNet Best Estimator:\", clf.best_estimator_, '\\n')\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"ElasticNet MSE:\", mse)","cf5f9db6":"parametersGrid  = {'nthread': [4],\n                  'objective': ['reg:linear'],\n                  'learning_rate':[0.03, 0.05, 0.07, 0.1],\n                  'max_depth': [5, 6, 7],\n                  'min_child_weight': [4],\n                  'silent': [1],\n                  'subsample': [0.7],\n                  'colsample_bytree': [0.7],\n                  'n_estimators':[500, 700, 1000]}\n\nmodel_xgb = xgb.XGBRegressor()\n\nclf = GridSearchCV(model_xgb,\n                   parametersGrid,\n                   cv = n_folds,\n                   scoring= \"neg_mean_squared_error\",\n                   refit = True)\n\n\nclf.fit(X_train, Y_train)\nmodel_xgb = clf.best_estimator_\n\ny_predicted_dummy = clf.predict(X_test)\nmse = mean_squared_error(Y_test,y_predicted_dummy)\nprint(\"XGBRegressor MSE:\", mse)","94816a39":"class AveragingModels():  \n    def __init__(self, models):\n        self.models = models\n        \n    def fit(self, X,y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        for model in self.models_:\n            model.fit(X,y)\n        \n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack([model.predict(X) for model in self.models_])\n        return np.mean(predictions, axis=1)\n    \naveraged_models = AveragingModels(models = (model_xgb, lasso))\naveraged_models.fit(X_train, Y_train)\n\ny_predicted_dummy = averaged_models.predict(X_test)\nmse = mean_squared_error(Y_test, y_predicted_dummy)\nprint(\"Averaged Models MSE:\", mse)","9b1c1de8":"<a id = \"2\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nLoad and Check Data","ef3fd14c":"<img src=\"https:\/\/media.giphy.com\/media\/J1YcBgUveXNkY\/giphy.gif\">\n\n<a id = \"19\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nKNN Regression","435f585e":"<img src=\"https:\/\/media.giphy.com\/media\/sDCma70RplcNG\/giphy.gif\">","cd68a1cf":"<a id = \"21\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nLasso Regression","6017b897":"<a id = \"16\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nPreprocessing\n    \n<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nTrain-Test Split","af454dea":"<span style=\"color:#494BD3;\n             font-size:140%;\n             font-family:Verdana;\">\nIf you liked this notebook, please upvote \ud83d\ude0a\n    \n<span style=\"color:#494BD3;\n             font-size:140%;\n             font-family:Verdana;\">\nIf you have any suggestions or questions, feel free to comment!\n    \n<span style=\"color:#494BD3;\n             font-size:140%;\n             font-family:Verdana;\">\nBest Wishes!\n\n","32d836b6":"<a id = \"25\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nAveraging Models","abf3bb21":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nLog1p Transformation\n    \n$$\\Huge y_i = {\\log_e (x_i+1)} $$\n    \n![image.png](attachment:f8230df1-74c9-4db5-bfe5-a9a16ef654c4.png)","465c28c9":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nTOP 10 Weight","c39c9781":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nScaling","f782f123":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nHorsepower - MPG - Displacement - Weight ","725bb41d":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nAnalysis of Numerical Variables","4a9665d6":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nPairwise Relationships","644ac5c6":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nEncoding","a799ef51":"<a id = \"11\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nOutliers","293aabaa":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nHorsepower - MPG - Cylinders","91badc73":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nDescriptive Statistics","cdfb6179":"<a id = \"26\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nLinear Regression","3bc40d1d":"<a id = \"1\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nLibraries and Utilities","e319237d":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nVariable Types","24b2b0df":"<a id = \"12\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nFeature Engineering\n    \n<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nMPG (Dependent Variable)","88dfa750":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nTOP 10 Horsepower","e5c03ca7":"<a id = \"22\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nElasticNet","f959bdd2":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nPearson Correlation Map","2d8d922d":"<img src=\"https:\/\/media.giphy.com\/media\/6swcfDQHr3UTm\/giphy.gif\">","0a07f0e9":"<a id = \"3\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nExploratory Data Analysis\n\n<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nAnalysis of Categorical Variables","40efb24f":"<span style=\"color:#494BD3;\n             font-size:160%;\n             font-family:Verdana;\">\nSpearman Rank Correlation Map","9d637885":"<a id = \"24\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nXGBoost","994410cc":"<a id = \"4\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nMissing Values","34b3a2bb":"<a id = \"20\"><\/a>\n<span style=\"color:#494BD3;\n             font-size:180%;\n             font-family:Verdana;\">\nRidge Regression","3a372951":"<p style=\"padding: 10px;\n          color: #494BD3;\n          text-align: center;\n          font-family:Verdana;\n          font-size:220%;\">\nFuel Consumption Prediction\n\n<\/p>\n\n\n          \n<img src=\"https:\/\/media.giphy.com\/media\/l2R0e9y6A304JkFOg\/source.gif\"> \n\n<div class=\"inner_cell\">\n<div class=\"text_cell_render border-box-sizing rendered_html\">\n<p><\/p><div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\" style = \"border:2px solid #494BD3;background-color:#494BD3; color:white; font-family:Verdana;text-align: center; font-size:140%;font-weight: Bold;\">Notebook Content<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#1\" role=\"tab\" aria-controls=\"profile\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Libraries and Utilities<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#2\" role=\"tab\" aria-controls=\"messages\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Load and Check Data<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#3\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Exploratory Data Analysis<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#4\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Missing Values<span class=\"badge badge-primary badge-pill\">4<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#11\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Outliers<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#12\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Feature Engineering<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n      <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#16\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Preprocessing<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>\n      <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#19\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">KNN Regression<span class=\"badge badge-primary badge-pill\">8<\/span><\/a>\n    <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#26\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Linear Regression<span class=\"badge badge-primary badge-pill\">9<\/span><\/a>\n      <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#20\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Ridge Regression<span class=\"badge badge-primary badge-pill\">10<\/span><\/a>\n      <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#21\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Lasso Regression<span class=\"badge badge-primary badge-pill\">11<\/span><\/a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#22\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">ElasticNet<span class=\"badge badge-primary badge-pill\">12<\/span><\/a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#24\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">XGBoost<span class=\"badge badge-primary badge-pill\">13<\/span><\/a>\n     <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#25\" role=\"tab\" aria-controls=\"settings\" target=\"_self\" style = \"color:#494BD3; font-family:Verdana;text-align: center; font-size:130%;font-weight: Bold;\">Averaging Models<span class=\"badge badge-primary badge-pill\">14<\/span><\/a>\n\n\n<\/div>\n<\/div>\n<\/div>"}}