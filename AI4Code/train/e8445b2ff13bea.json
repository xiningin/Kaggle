{"cell_type":{"ee27b09f":"code","8ab48e07":"code","b1d4c1c8":"code","13cfbd2b":"code","77adf3c5":"code","5636fe04":"code","8d46a88a":"code","98f35d2b":"code","e83cde12":"code","e6df7f6c":"code","00be7d79":"code","96293f59":"code","e7906be9":"code","b7085b51":"code","791048a0":"code","e6d50aab":"code","c10fd048":"code","a598b5fd":"code","eb7b8892":"code","151a067c":"code","3509f1e2":"code","503b9d5f":"code","eb01f05b":"code","ebbac491":"code","9c439754":"code","ac923e2f":"code","ac259cda":"code","8b3b9290":"code","5417373c":"code","8c6111ff":"code","c575df5e":"code","cc6b3a21":"code","ddc3a9c1":"code","c69d9645":"code","9cd2323a":"code","cbe6c8ee":"code","54e17f5c":"code","6539c542":"code","16365cb9":"code","b84ce531":"code","d694a56c":"code","e2783970":"code","a7ecadb6":"code","b640497c":"code","a74d709a":"code","a5abb320":"code","5f2f7a6f":"code","62dbf04b":"code","949a37fd":"code","a4fa20bb":"code","f19f5474":"code","86f5b6d8":"code","a4a1f111":"code","0895e151":"code","6a084dcc":"code","00be9118":"code","5cfc6c0e":"code","1c991870":"code","64c2fc5f":"code","93f46b2c":"code","43ae254b":"code","cf412ec5":"code","8988e9c7":"code","fa13378e":"code","11089e06":"code","a13a38f3":"code","767f245e":"code","14224db8":"code","747c73b9":"code","d050209a":"code","ade741bc":"code","3b621843":"code","9ce853bc":"code","d32b5d6b":"code","ec5acc4f":"code","01a6a1a7":"code","5c7640da":"code","5ca5e07c":"code","4da9e1df":"code","ffd54874":"code","227dcf7c":"code","85bf40de":"code","328b69cb":"code","4e3b084f":"code","fd057bd8":"code","fcf3a0ee":"code","55ab3227":"code","788a7c3b":"code","5a49d7c4":"code","ffbf1a99":"code","f1ac6b22":"code","d28dc7ff":"code","8ee6e384":"code","2341cf91":"code","28a68fb1":"code","c653fdc7":"code","9ad71a13":"code","d4f30486":"code","e0c1cd77":"code","7fb0ff5b":"code","b4d3ca69":"code","19468d8e":"code","06106a5d":"code","b3d82e76":"code","06e13022":"code","6e390fb0":"code","2f94fe6b":"code","8df45f52":"markdown","5e2bdab0":"markdown","2e75f17d":"markdown","4284aa29":"markdown","7aa3d339":"markdown","ed386e68":"markdown","4f9c8e7a":"markdown","b8fcb0f7":"markdown","8445e800":"markdown","a7ccd477":"markdown","99545d15":"markdown","27ff35ab":"markdown","6ecf6036":"markdown","28fef80b":"markdown","c74bb5da":"markdown","fa6bc818":"markdown","4aff6c91":"markdown","7a17f755":"markdown","a76449b2":"markdown","b430517b":"markdown","25ee1966":"markdown","5dac6a08":"markdown","839c976c":"markdown","eb0c897f":"markdown","ce59be6b":"markdown","43c3e7c0":"markdown","f8b8270f":"markdown","770c5851":"markdown","f199077f":"markdown","5945012f":"markdown","65d001bf":"markdown","9f4f2afe":"markdown","09a630a3":"markdown","8995495c":"markdown","76f7826d":"markdown","6ad4d877":"markdown","97a5b1c4":"markdown","a8042c4c":"markdown","265f5aea":"markdown","135c6e7b":"markdown","85ecb85c":"markdown"},"source":{"ee27b09f":"from sklearn.preprocessing import *\nfrom sklearn.cluster import DBSCAN, KMeans\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import LinearRegression, ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import IsolationForest,GradientBoostingRegressor\nfrom sklearn.model_selection import ShuffleSplit, GridSearchCV\n\nfrom IPython.core.display import display, HTML\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport seaborn as sns\nimport missingno\nimport markdown\n\nfrom scipy import stats\nimport pandas as pd\nimport numpy as np\n\nfrom mlxtend.regressor import StackingCVRegressor,StackingRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nhtml = markdown.markdown('<img style=\"max-height: 700px; \\\n                           align=center\" \\\n                           src=\"https:\/\/sun9-53.userapi.com\/impg\/ETdrzYnU_3MnOd3fkaLI8oWCBHt9XNDCgo1dUQ\/Ua2rbr3Wt1k.jpg?size=1000x400&quality=96&sign=38aa16cdd20dea8825a2c2b640ea6108&type=album\">')\ndisplay(HTML(html))\n\npalette = ['#2f4c28',\"#c3762c\",\"#b14404\",'#3a6049',\"#8f6e60\",\"#a03031\"]\ngradient = ['#2f4c28','#3a6049','#4e7f76',\"#8f6e60\",'#a96d46',\"#c3762c\",\"#b14404\",\"#a03031\"]\nsns.palplot(gradient)","8ab48e07":"path = \"..\/input\/house-prices-advanced-regression-techniques\"\ndf = pd.concat([pd.read_csv(f\"{path}\/train.csv\",index_col=0),\n                pd.read_csv(f\"{path}\/test.csv\",index_col=0)])\ndf = df.reset_index(drop=True)\nnan_mask = df[\"SalePrice\"].isna()\nprint(\"\\033[4mDATA SHAPE CHECK:\\033[0m\")\nprint(f\" Train dataset length: \\t{len(df[~nan_mask])}\")\nprint(f\" Train dataset length: \\t{len(df[nan_mask])}\")\nprint(f\" Number of features: \\t{len(df.columns)-1}\")","b1d4c1c8":"print(\"\\033[4mFEATURE DESCRIPTION EXTRACTION:\\033[0m\")\nf = open(f\"{path}\/data_description.txt\").read().split('\\n')\ndescriptions = {}\nfor s in f:\n    s=s.strip()\n    if (\":\" in s) and not (\"2nd level\" in s):\n        k,v = s.split(\":\")\n        print(f\"  {k} \\t:{v}\")\n        descriptions[k] = v ","13cfbd2b":"print(\"\\033[4mATTRIBUTES TYPES:\\033[0m\")\ncategorical, numerical = [],[]\nfor c in df.columns:\n    t = df.dtypes[c]\n    if t=='object':\n        categorical.append(c)\n    else:\n        numerical.append(c)\nprint(\"\\n\\033[4mCATEGORICAL:\\033[0m\")\nprint(categorical)\nprint(\"\\n\\033[4mNUMERICAL:\\033[0m\")\nprint(numerical)","77adf3c5":"print(\"\\033[4mNAN VALUES:\\033[0m\")\n_df = df.loc[:,df.isna().any().values]\n_df = _df.drop(\"SalePrice\",axis=1)\nmissingno.bar(_df, color=gradient, figsize=(30,2), sort=\"ascending\")\ndisplay(df.head(3))","5636fe04":"less_50p_nans = [\"Alley\", \"PoolQC\", \"Fence\", \"MiscFeature\", \"FireplaceQu\"]\nprint(\"Attributes that have more then 50% NaN values:\\n\")\nfor k in less_50p_nans:\n    print(f\"{k}   \\t:{descriptions[k]}\")","8d46a88a":"# We only leave MiscFeature cause it can affec to the SalePrice\ndf = df.drop([\"Alley\",\"PoolQC\",\"Fence\",\"FireplaceQu\"], axis=1)","98f35d2b":"target_scaler = QuantileTransformer(output_distribution='normal', random_state=0)\ndf.loc[~nan_mask,\"SalePrice_transformed\"] = \\\n    target_scaler.fit_transform(df.loc[~nan_mask,\"SalePrice\"].to_numpy().reshape(-1,1))\n\nfig = make_subplots(rows=1, cols=2)\nfig.add_trace(go.Violin(y = df.loc[~nan_mask,\"SalePrice\"], \n                        line={\"color\":palette[0]}, name=\"original target\"), row=1, col=1)\nfig.add_trace(go.Violin(y = df.loc[~nan_mask,\"SalePrice_transformed\"], \n                        line={\"color\":palette[1]}, name=\"scaled target\"), row=1, col=2)\nfig.update_traces(meanline_visible=True)\nfig.show()","e83cde12":"attributes_grouped = {\n    \"qualitative\" : [\"OverallQual\",\"OverallCond\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"HeatingQC\",\n                     \"LowQualFinSF\",\"KitchenQual\",\"GarageQual\",\"GarageCond\"],\n    \"environment\" : [\"MSZoning\",\"LotFrontage\",\"Street\",\"Neighborhood\",\"Condition1\",\"Condition2\",\"PavedDrive\"],\n    \"sellterms\"   : [\"MoSold\",\"YrSold\",\"SaleType\",\"SaleCondition\"],\n    \"landplot\"    : [\"LotArea\",\"LotShape\",\"LandContour\",\"LotConfig\",\"LandSlope\"],\n    \"dwelling\"    : [\"BldgType\",\"HouseStyle\",\"YearBuilt\",\"YearRemodAdd\",\"RoofStyle\",\"RoofMatl\",\"Exterior1st\",\"Exterior2nd\",\"MasVnrType\",\"MasVnrArea\",\n                     \"Foundation\",\"KitchenQual\",\"Fireplaces\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"MSSubClass\"],\n    \"benefits\"    : [\"Heating\",\"CentralAir\",\"Electrical\",\"Utilities\",\"Functional\",\"TotRmsAbvGrd\"],\n    \"sqrfeets\"    : [\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\"],\n    \n    # Repeats some of the qualitative attributes\n    \"basement\"    : [\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinSF1\",\"BsmtFinType2\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\"],\n    \"garage\"      : [\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageCars\",\"GarageArea\",\"GarageQual\",\"GarageCond\"],\n    \"other\"       : [\"MiscVal\",\"MiscFeature\"]}\n\nprint(\"\\033[4mATTRIBURTES GROUPS:\\033[0m\")\nfor k in attributes_grouped:\n    print(f\"\\n\\033[1m{k}\\033[0m:\")\n    print(\",\".join(attributes_grouped[k]))","e6df7f6c":"def save_to_df(group_name:str, new_df:pd.DataFrame):\n    \"\"\"\n    Saves processed dataset of some group of features into main df\n    :param group_name: name of the feature group\n    :param new_df:     precessed DataFrame features\n    \"\"\"\n    if \"target\" in new_df:\n        new_df = new_df.drop(\"target\", axis=1)\n    global df\n    df = df.drop(attributes_grouped[group_name], axis=1)\n    df = pd.concat([df,new_df], axis=1)\n    attributes_grouped[group_name] = new_df.columns.values\n    return attributes_grouped[group_name]\n        \ndef replace_dummies(name , df):\n    \"\"\"\n    Replace feature with dummies\n    :param name: str feature name\n    :param df:   pd.DataFrame data\n    \"\"\"\n    _d = pd.get_dummies(df[name])\n    _d = _d.rename({i:f\"{name}_{i}\" for i in _d.columns}, axis=1)\n    df = df.drop(name, axis=1)\n    return pd.concat([df,_d],axis=1)\n\ndef attribute_slice(attributes_group):\n    attr_list = attributes_grouped[attributes_group]\n    _df = df.copy()[attr_list]\n    _df[\"target\"] = df[\"SalePrice\"]\n    missingno.bar(_df, color=palette, figsize=(30,2))\n    display(_df.head(3))\n    return attr_list, _df","00be7d79":"attr_list,_df = attribute_slice(\"qualitative\")","96293f59":"categorical = {\"Gd\":3,\"Av\":2,\"Mn\":1,\"No\":0}\n_df.loc[:,\"BsmtExposure\"] = _df[\"BsmtExposure\"].replace(categorical)\n\ncategorical = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"No\":0}\n_df = _df.replace(categorical)\n\ncategorical = {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1}\n_df = _df.replace(categorical)\n\n_df = _df.fillna(0).astype(int)","e7906be9":"_model = LinearRegression()\n_model.fit(_df[~nan_mask][attr_list],_df[~nan_mask][\"target\"])\n_df[\"_GeneralQuality\"] = QuantileTransformer().fit_transform(_model.predict(_df[attr_list]).reshape(-1,1))","b7085b51":"pltdf = _df[~nan_mask].copy()\nfig = px.scatter(pltdf, x=\"_GeneralQuality\", y=\"target\",color=\"target\",height=400, color_continuous_scale=gradient)\nfig.show()","791048a0":"save_to_df(\"qualitative\", _df)\n_df.head(1)","e6d50aab":"attr_list,_df = attribute_slice(\"environment\")","c10fd048":"_df = replace_dummies(\"MSZoning\",_df)","a598b5fd":"_df.loc[_df[\"LotFrontage\"].isna(),\"LotFrontage\"] = _df.mode()[\"LotFrontage\"].values[0]\n_df[\"LotFrontage\"] = QuantileTransformer().fit_transform(_df[\"LotFrontage\"].to_numpy().reshape(-1,1))\npx.scatter(_df, x=\"LotFrontage\", y=\"target\", color=\"target\", height=400, color_continuous_scale=gradient)","eb7b8892":"_df[\"_LfOverNormal\"] = 0\n_df.loc[_df[\"LotFrontage\"]>0.8,\"_LfOverNormal\"] = 1\npx.box(_df, color=\"_LfOverNormal\", x=\"target\", height=400, color_discrete_sequence=palette)","151a067c":"# \"Street\" feature, only contains 2 values, so we will transfet it into binary \"Is_Pave_Street feature\"\nprint(set(_df[\"Street\"]))\n_df[\"_IsPaveStreet\"] = (_df[\"Street\"]=='Pave').astype(int)\n_df = _df.drop(\"Street\", axis=1)","3509f1e2":"# for \"PavedDrive\" we will manually endoe lables. Partially paved will be 0.5\n_df.loc[:,\"PavedDrive\"] = _df[\"PavedDrive\"].replace({\"Y\":1,\"N\":0,\"P\":0.5}) ","503b9d5f":"# This one may be inaccurate, cause some of the loaction names are umbiquose\nll = {\"Blmngtn\":(40.480592,-89.033689),\"Blueste\":(47.5248776,-118.1266345),\"BrDale\":(36.5723285,-82.1790214),\"BrkSide\":(39.66706, -75.72688),\n      \"ClearCr\":(39.645833,-111.151667),\"CollgCr\":(37.225412, -76.693987),\"Crawfor\":(42.683024,-103.405479),\"Edwards\":(39.64499, -106.5942),\n      \"Gilbert\":(33.35283, -111.78903),\"IDOTRR\":(41.6613, -91.5299),\"MeadowV\":(40.0172943, -81.6192906),\"Mitchel\": (43.70943, -98.0298),\"NAmes\":(42.034722, -93.62),\n      \"NoRidge\":(34.22834, -118.53675),\"NPkVill\":(32.580697,-92.0804111),\"NridgHt\":(48.218016,-114.3329096),\"NWAmes\":(42.034722, -93.62),\n      \"OldTown\":(29.601657, -82.981928),\"SWISU\":(42.023949, -93.647595),\"Sawyer\":(45.907319, -91.320396),\"SawyerW\": (46.333407, -87.365986),\n      \"Somerst\":(40.4976, -74.48849),\"StoneBr\":(35.3465056, -82.4917868),\"Timber\":(45.6760608,-92.1060166),\"Veenker\": (42.0414857,-93.6501622),}","eb01f05b":"for k in ll:\n    _msk = _df[\"Neighborhood\"]==k\n    _df.loc[_msk,[\"_Lat\",\"_Lon\"]] = ll[k]\n    \n    _target = _df.loc[_msk,\"target\"]\n    _df.loc[_msk,\"mean\"] =  _target.mean()\n    _df.loc[_msk,\"max\"]  =  _target.max()","ebbac491":"_df[\"max\"] = MinMaxScaler().fit_transform(_df[\"max\"].to_numpy().reshape(-1,1))\nfig = px.scatter_mapbox(_df[~nan_mask], lat=\"_Lat\", lon=\"_Lon\", size=\"max\", hover_name=\"Neighborhood\", color=\"mean\", zoom=3, height=500,color_continuous_scale=gradient)\nfig.update_layout(mapbox_style='carto-positron')\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()","9c439754":"_df[\"_Lat\"] = MinMaxScaler().fit_transform(_df[\"_Lat\"].to_numpy().reshape(-1,1))\n_df[\"_Lon\"] = MinMaxScaler().fit_transform(_df[\"_Lon\"].to_numpy().reshape(-1,1))","ac923e2f":"px.box(_df, color=\"Neighborhood\", y=\"target\", height=400, color_discrete_sequence=palette)","ac259cda":"_df = _df.drop([\"mean\",\"max\"],axis=1)\n_df[\"_ExpenciveNh\"] = _df[\"Neighborhood\"].isin([\"NoRidge\",\"NridgHt\",\"StoneBr\"]).astype(int)\n_df = replace_dummies(\"Neighborhood\",_df)","8b3b9290":"encoder = OneHotEncoder(sparse=True)\ncond = encoder.fit_transform(_df[\"Condition1\"].to_numpy().reshape(-1,1)).toarray()\ncond += encoder.transform(_df[\"Condition2\"].to_numpy().reshape(-1,1)).toarray()\ncond = cond.astype(bool).astype(int)\ncond = pd.DataFrame(data=cond,columns=encoder.categories_, index=_df.index)\ncond.columns = [i[0] for i in cond.columns]","5417373c":"_df = _df.drop([\"Condition1\",\"Condition2\"], axis=1)\n_df = pd.concat([_df,cond], axis=1)","8c6111ff":"save_to_df(\"environment\", _df)\n_df.head(1)","c575df5e":"attr_list,_df = attribute_slice(\"sellterms\")","cc6b3a21":"_df =replace_dummies(\"SaleCondition\",_df)","ddc3a9c1":"ym_df = _df.groupby([\"YrSold\",\"MoSold\"],as_index=False).sum()\nym_df[\"&\"] = ym_df[\"YrSold\"].astype(str)+\".\"+ym_df[\"MoSold\"].astype(str)\nfig = px.line(ym_df, x=\"&\", y=\"target\", color_discrete_sequence=palette)\nfig.add_hline(y=ym_df[\"target\"].mean(), line_dash=\"dash\", line_color=palette[1])","c69d9645":"_df[\"_HighDemand\"] = ym_df[\"MoSold\"]\n_df.loc[:,\"_HighDemand\"] = _df[\"MoSold\"].replace([1,2,3,9,10,11,12],0)\n_df.loc[:,\"_HighDemand\"] = _df[\"MoSold\"].replace([4,5,6,7,8],1)","9cd2323a":"_df[\"YrSold\"] = _df[\"YrSold\"].astype(str)\n_df =replace_dummies(\"YrSold\",_df)","cbe6c8ee":"_df[\"SaleType\"] = _df[\"SaleType\"].fillna(\"Oth\")\n_df[\"SaleType\"] = _df[\"SaleType\"].astype(str)\n\n# Warranty deed\n_df[\"_Deed\"] = _df[\"SaleType\"].isin([\"WD\",\"CWD\",\"VWD\",\"COD\"]).astype(int)\n#Contract\n_df[\"_Contract\"] = _df[\"SaleType\"].isin([\"Con\",\"ConLw\",\"ConLI\",\"ConLD\"]).astype(int)\n\n_df =replace_dummies(\"SaleType\",_df)","54e17f5c":"save_to_df(\"sellterms\", _df)\n_df.head(1)","6539c542":"attr_list,_df = attribute_slice(\"landplot\")","16365cb9":"# We will scale Lot Area, to check the distribution\n_df[\"LotArea\"] = QuantileTransformer().fit_transform(_df[\"LotArea\"].values.reshape(-1,1))\npx.scatter(_df, x=\"LotArea\", y=\"target\", color=\"target\", color_continuous_scale=gradient, height=400)","b84ce531":"for k in [\"LotShape\",\"LandContour\",\"LotConfig\",\"LandSlope\"]:\n    _df = replace_dummies(k,_df)","d694a56c":"save_to_df(\"landplot\", _df)\n_df.head(1)","e2783970":"attr_list,_df = attribute_slice(\"dwelling\")","a7ecadb6":"_df[\"_WasRemod\"] = (_df[\"YearBuilt\"] != _df[\"YearRemodAdd\"]).astype(int)","b640497c":"# I shrink Exterior features, with a small lost of informations i hope\ne = 3\n_df[\"_Exterior\"] = _df[\"Exterior1st\"] + \"_\" + _df[\"Exterior2nd\"]\n_df.loc[:,[\"_Exterior\"]] = _df.loc[:,[\"_Exterior\"]].fillna(\"extra\")\n_df = _df.drop([\"Exterior1st\",\"Exterior2nd\"],axis=1)\n_a = _df[\"_Exterior\"].value_counts()\nto_replace = _a[_a==1].index.values\nfor i in _a[_a<=e].index.values:\n    _df = _df.replace({i:\"extra\"})\npx.box(_df[~nan_mask], color=\"_Exterior\", y=\"target\", color_discrete_sequence=gradient, height=400)","a74d709a":"_df.loc[:,[\"MasVnrType\"]] = _df.loc[:,[\"MasVnrType\"]].fillna(\"None\")\n_df[\"_HasVnr\"] = (_df[\"MasVnrType\"]!=\"None\").astype(int)\n\n_df.loc[:,[\"MasVnrArea\"]] = _df.loc[:,[\"MasVnrArea\"]].fillna(0)\n_df[\"MasVnrArea\"] = MinMaxScaler().fit_transform(_df[\"MasVnrArea\"].values.reshape(-1,1))\n\n_df.loc[:,[\"BsmtFullBath\"]] = _df.loc[:,[\"BsmtFullBath\"]].fillna(0)\n_df.loc[:,[\"BsmtHalfBath\"]] = _df.loc[:,[\"BsmtHalfBath\"]].fillna(0)\n\n_df[\"_Bath\"] = 0.5 * (_df[\"BsmtHalfBath\"] + _df[\"HalfBath\"]) + _df[\"BsmtFullBath\"] + _df[\"FullBath\"]","a5abb320":"for f in [\"BldgType\",\"HouseStyle\",\"_Exterior\",\"Foundation\",\"RoofStyle\",\"MasVnrType\",\"MSSubClass\",\"RoofMatl\"]:\n    _df = replace_dummies(f,_df)","5f2f7a6f":"tsne = TSNE(n_components=2, perplexity=50, early_exaggeration=5,random_state=0)\nX = tsne.fit_transform(_df.drop([\"target\"],axis=1))\nX = pd.DataFrame(data=X, columns=[\"DwellTSNE1\",\"DwellTSNE2\"], index=_df.index)","62dbf04b":"gmm = DBSCAN(4)\nclusters = pd.Series(gmm.fit_predict(X), index=_df.index)[~nan_mask]+1","949a37fd":"fig = px.scatter(x=X.loc[~nan_mask,\"DwellTSNE1\"], \n                 y=X.loc[~nan_mask,\"DwellTSNE2\"], \n                 color=clusters, size_max=7,\n                 color_continuous_scale=gradient)\nfig.show()","a4fa20bb":"_df","f19f5474":"save_to_df(\"dwelling\", _df)\n_df.head(1)","86f5b6d8":"attr_list,_df = attribute_slice(\"benefits\")","a4a1f111":"_df[\"_GasHeating\"] = _df[\"Heating\"].isin([\"GasA\",\"GasW\"]).astype(int)\npx.box(_df[~nan_mask], color=\"_GasHeating\", y=\"target\", color_discrete_sequence=palette, height=400)","0895e151":"_df[\"CentralAir\"] = (_df[\"CentralAir\"]==\"Y\").astype(int)\n_df[\"Electrical\"] = _df[\"Electrical\"].fillna(\"NA\")\n_df[\"Utilities\"] = (_df[\"Utilities\"]!=\"AllPub\").astype(int)\n_df[\"Functional\"] = _df[\"Functional\"].fillna(\"Typ\")","6a084dcc":"for k in [\"Functional\",\"Electrical\",\"Heating\"]:\n    _df =replace_dummies(k,_df)","00be9118":"save_to_df(\"benefits\", _df)\n_df.head(1)","5cfc6c0e":"attr_list,_df = attribute_slice(\"sqrfeets\")","1c991870":"_df[\"_PorchSF\"] = _df[[\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\"]].sum(axis=1)\n_df[\"_PorchSF\"] = MinMaxScaler().fit_transform(_df[\"_PorchSF\"].values.reshape(-1,1))\n_df[\"_NoPorch\"] = (_df[\"_PorchSF\"]==0).astype(int)\npx.scatter(_df,x=\"_PorchSF\",y=\"target\",color=\"target\",color_continuous_scale=gradient)","64c2fc5f":"_df[\"_NoPool\"] = (_df[\"PoolArea\"]==0).astype(int)\n_df[\"_1to2floorSF\"] = _df[\"2ndFlrSF\"]\/_df[\"1stFlrSF\"]\n_df[\"_No2floor\"] = (_df[\"_1to2floorSF\"]==0).astype(int)","93f46b2c":"_df[\"1stFlrSF\"] = MinMaxScaler().fit_transform(_df[\"1stFlrSF\"].values.reshape(-1,1))\n_df[\"2ndFlrSF\"] = MinMaxScaler().fit_transform(_df[\"2ndFlrSF\"].values.reshape(-1,1))\n_df[\"GrLivArea\"] = MinMaxScaler().fit_transform(_df[\"GrLivArea\"].values.reshape(-1,1))\n_df[\"OpenPorchSF\"] = MinMaxScaler().fit_transform(_df[\"OpenPorchSF\"].values.reshape(-1,1))","43ae254b":"save_to_df(\"sqrfeets\", _df)\n_df.head(1)","cf412ec5":"attr_list,_df = attribute_slice(\"basement\")","8988e9c7":"_df.loc[_df[\"BsmtFinSF1\"].isna(),[\"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\",\"TotalBsmtSF\"]] = 0","fa13378e":"_df['_Nobsmt'] = (_df[\"TotalBsmtSF\"]==0).astype(int)","11089e06":"_df[\"BsmtUnfSF\"] = MinMaxScaler().fit_transform(_df[\"BsmtUnfSF\"].values.reshape(-1,1))\n_df[\"TotalBsmtSF\"] = MinMaxScaler().fit_transform(_df[\"TotalBsmtSF\"].values.reshape(-1,1))","a13a38f3":"_model = LinearRegression()\n_model.fit(_df[~nan_mask][attr_list],_df[~nan_mask][\"target\"])\n_df[\"_BasementSummary\"] = QuantileTransformer().fit_transform(_model.predict(_df[attr_list]).reshape(-1,1))","767f245e":"pltdf = _df[~nan_mask].copy()\nfig = px.scatter(pltdf, x=\"_BasementSummary\", y=\"target\",color=\"target\",height=400, color_continuous_scale=gradient)\nfig.show()","14224db8":"save_to_df(\"basement\", _df)\n_df.head(1)","747c73b9":"attr_list,_df = attribute_slice(\"garage\")","d050209a":"_df[\"GarageType\"] = _df[\"GarageType\"].fillna(\"NA\")\n\n_msk =_df[\"GarageYrBlt\"].isna()\n_df.loc[_msk,\"GarageYrBlt\"] = df.loc[_msk,\"YearBuilt\"]\n_df.loc[_msk,\"GarageFinish\"] = 'Fin'\n_df.loc[_df[\"GarageCars\"].isna(),\"GarageCars\"] = _df.mode()[\"GarageCars\"].values[0]\n_df.loc[_df[\"GarageArea\"].isna(),\"GarageArea\"] = _df.mode()[\"GarageArea\"].values[0]\n\n_df[\"_NoGarage\"] = (_df[\"GarageArea\"] == 0).astype(int)","ade741bc":"px.box(_df[~nan_mask], color=\"_NoGarage\", y=\"target\", color_discrete_sequence=palette, height=400)","3b621843":"_df[\"GarageArea\"] = QuantileTransformer().fit_transform(_df[\"GarageArea\"].to_numpy().reshape(-1,1))\npx.scatter(_df[~nan_mask], x=\"GarageArea\", y=\"target\", color=\"target\", color_continuous_scale=gradient, height=400)","9ce853bc":"for f in [\"GarageType\",\"GarageFinish\"]:\n    _df = replace_dummies(f,_df)","d32b5d6b":"save_to_df(\"garage\", _df)\n_df.head(1)","ec5acc4f":"attr_list,_df = attribute_slice(\"other\")","01a6a1a7":"plt_df = _df.copy()\nplt_df[\"MiscFeature\"] = plt_df[\"MiscFeature\"].astype(str)\npx.box(plt_df[~nan_mask], color=\"MiscFeature\", y=\"target\", color_discrete_sequence=palette, height=400)","5c7640da":"_df.loc[_df[\"MiscFeature\"] == \"TenC\",\"MiscFeature\"] = np.nan","5ca5e07c":"_df= replace_dummies(\"MiscFeature\",_df)","4da9e1df":"save_to_df(\"other\", _df)\n_df.head(1)","ffd54874":"_df = df.copy(deep=True)\ntsne = TSNE(n_components=2, perplexity=50, early_exaggeration=12,random_state=0)\nX = tsne.fit_transform(_df.drop([\"SalePrice\",\"SalePrice_transformed\"],axis=1))\nX = pd.DataFrame(data=X, columns=[\"DwellTSNE1\",\"DwellTSNE2\"], index=_df.index)","227dcf7c":"gmm = DBSCAN(7, min_samples=10)\n_df = df.copy(deep=True)\ncolor = pd.Series(gmm.fit_predict(X), index=_df.index)[~nan_mask]+1","85bf40de":"fig = px.scatter(x=X.loc[~nan_mask,\"DwellTSNE1\"], \n                 y=X.loc[~nan_mask,\"DwellTSNE2\"], \n                 color= color, \n                 size_max=7,\n                 color_continuous_scale=gradient)\nfig.show()","328b69cb":"df[\"_cluster\"] = gmm.fit_predict(X)","4e3b084f":"print(f\"Number of attributes: {len(df.columns)}\")","fd057bd8":"# Pruning of the features with less then 30 non-zero values\nfor c in df.columns:\n    if (len(df) - df[df[c]==0][c].count()) < 30:\n        df = df.drop(c,axis=1)\nprint(f\"Number of attributes (Pruned): {len(df.columns)}\")","fcf3a0ee":"X = df.loc[~df[\"SalePrice_transformed\"].isna(),:]\nX[\"outlier\"] = IsolationForest(random_state=0, n_estimators=1000).fit_predict(X)*-1+2\ndf = df.drop(X[X[\"outlier\"]!=1].index)\npx.scatter(X, y=\"SalePrice_transformed\", color=\"outlier\", size=\"outlier\",color_continuous_scale=gradient,size_max=7)","55ab3227":"_df = df.drop(\"SalePrice\",axis=1)\n_df.index = _df.index+1\nmask = _df[\"SalePrice_transformed\"].isna()","788a7c3b":"train, deploy = _df.loc[~mask,:], _df.loc[mask,:]\nmodels = {}","5a49d7c4":"x_tr, y_tr = train.drop(\"SalePrice_transformed\", axis=1), train[\"SalePrice_transformed\"] ","ffbf1a99":"name = \"lin\"\nmodels[name] = LinearRegression().fit(x_tr, y_tr)\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(\"lin.csv\", index=False)\n# \"lin\" : 0.12696","f1ac6b22":"name= \"lassocv\"\n\n_grid = {\"alphas\":np.arange(0.0005,0.0015,0.0001)}\n_cv =ShuffleSplit(n_splits=30, test_size=400, random_state=0)\nmodels[name] = LassoCV(cv=_cv,**_grid)\nmodels[name].fit(x_tr, y_tr)\nprint(f\"alpha for the best model: {models[name].alpha_}\")\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"lassocv\" : 0.12479 ","d28dc7ff":"name= \"ridgecv\"\n\n_grid = {\"alphas\":np.arange(0.4,0.5,0.001)}\n_cv =ShuffleSplit(n_splits=50, test_size=400, random_state=0)\nmodels[name] = RidgeCV(cv =_cv, **_grid)\nmodels[name].fit(x_tr, y_tr)\nprint(f\"alpha for the best model: {models[name].alpha_}\")\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"ridgecv\" : 0.12686","8ee6e384":"name= \"elasticcv\"\n_grid = {\"alphas\" : np.arange(0.0001,0.1,0.0001),\n         \"l1_ratio\" : [.1, .5, .7, .9, .95, .96, .97,.98, .99, 1]}\n_cv =ShuffleSplit(n_splits=30, test_size=400, random_state=0)\nmodels[name] = ElasticNetCV(cv =_cv,max_iter=1e5, **_grid)\nmodels[name].fit(x_tr, y_tr)\nprint(f\"alpha for the best model: {models[name].alpha_}\")\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"elasticcv\" : 0.12479","2341cf91":"#name= \"sk_gbr\"\n#_grid = {\"subsample\":[0.4,0.3],\n#         \"max_depth\":[5],\n#         \"min_samples_split\":[15,],\n#         \"min_samples_leaf\":[5],\n#         \"learning_rate\":np.arange(0.05,0.2,0.001)}\n\n#model = GradientBoostingRegressor(verbose=False,random_state=0, loss='huber')\n#_cv =ShuffleSplit(n_splits=30, test_size=400, random_state=0)\n#clf = GridSearchCV(estimator=model, param_grid=_grid, cv=_cv, verbose=2)\n#clf.fit(x_tr, y_tr) \n#clf.best_params_","28a68fb1":"name= \"sk_gbr\"\nparams = {'learning_rate': 0.05,'max_depth': 5,'min_samples_leaf': 5,'min_samples_split': 15,'subsample': 0.4}\nmodels[name] = GradientBoostingRegressor(verbose=False,random_state=0, loss='huber', **params)\nmodels[name].fit(x_tr, y_tr)\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"sk_gbr\" : 0.13215","c653fdc7":"#name= \"lightgbm\"\n#_grid = {\"learning_rate\": [0.018999999999999996],\n#         \"n_estimators\":[500,5000],\n#         \"min_split_gain\":[0],\n#         \"min_child_samples\":[20],\n#         \"subsample\":[1],\n#         \"reg_alpha\":[0.03],\n#         \"reg_lambda\":[0.02]}\n\n#model = LGBMRegressor(silent=True, random_state=0, max_depth=-1)\n#_cv =ShuffleSplit(n_splits=30, test_size=400, random_state=0)\n#clf = GridSearchCV(estimator=model, param_grid=_grid, cv=_cv, verbose=2)\n#clf.fit(x_tr, y_tr)","9ad71a13":"name= \"lightgbr\"\nparams = {'learning_rate': 0.018999999999999996,'min_child_samples': 20,'min_split_gain': 0,\n          'n_estimators': 500,'reg_alpha': 0.03,'reg_lambda': 0.02,'subsample': 1}\nmodels[name] = LGBMRegressor(silent=True, random_state=0, max_depth=-1, **params)\nmodels[name].fit(x_tr, y_tr)\n\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"lightgbr\" : 0.12948","d4f30486":"#_grid = {\"max_depth\":[6],\n#         \"learning_rate\":[0.022985,0.02299,0.022995],\n#         \"subsample\":[0.5],\n#         \"reg_alpha\":[0.0011,0.001],\n#         \"reg_lambda\":[0.405,0.41,0.415],\n#         \"n_estimators\": [500]}\n\n#model = XGBRegressor(random_state=0,**{'tree_method': 'gpu_hist', 'max_bin': 16, 'gpu_id': 0})\n#_cv =ShuffleSplit(n_splits=30, test_size=400, random_state=0)\n#clf = GridSearchCV(estimator=model, param_grid=_grid, cv=_cv, verbose=2)\n#clf.fit(x_tr, y_tr)","e0c1cd77":"name= \"xgbm\"\nparams = {'learning_rate': 0.02299,'max_depth': 6,'n_estimators': 500,'reg_alpha': 0.001,'reg_lambda': 0.41,'subsample': 0.5}\nmodels[name] = XGBRegressor(random_state=0, **params)\nmodels[name].fit(x_tr, y_tr)\n\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"xgbm\" : 0.12843","7fb0ff5b":"#name= \"cat\"\n#_grid = {\"l2_leaf_reg\":(0.0038,0.004,0.0042),\n#         \"rsm\":(0.05,0.1,0.25),\n#         \"learning_rate\":np.arange(0.0108,0.011,0.00001)} \n\n#model = CatBoostRegressor(verbose=False, iterations=5000, depth=6)\n#_cv =ShuffleSplit(n_splits=50, test_size=1400, random_state=0)\n#model.grid_search(_grid, X=x_tr, y=y_tr, cv=_cv, plot=True, verbose=False)","b4d3ca69":"name= \"cat\"\nparams = {\"rsm\":0.05, \"depth\":6, \"learning_rate\": 0.0109, \"l2_leaf_reg\": 0.004}\nmodels[name] = CatBoostRegressor(verbose=False, iterations=5000, **params)\nmodels[name].fit(x_tr, y_tr)\n\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"cat\" : 0.12245","19468d8e":"name = \"lin_mix\"\nnames = [\"elasticcv\",\"ridgecv\",\"lassocv\",\"lin\"]\nmodels[name] = StackingCVRegressor(regressors= set(models[k] for k in names),\n                                   meta_regressor=CatBoostRegressor(verbose=False),\n                                   use_features_in_secondary=True)\nmodels[name].fit(x_tr, y_tr)\n\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"lin_mix\" : 0.11957","06106a5d":"name = \"adv_mix\"\nnames = [\"xgbm\",\"lightgbr\",\"sk_gbr\",\"cat\"]\nmodels[name] = StackingRegressor(regressors= set(models[k] for k in names),\n                                   meta_regressor=CatBoostRegressor(verbose=False),\n                                   use_features_in_secondary=True)\nmodels[name].fit(x_tr, y_tr)\n\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"adv_mix\" : 0.12678","b3d82e76":"name = \"mix_mix\"\nnames = [\"lin_mix\",\"adv_mix\"]\nmodels[name] = StackingRegressor(regressors= set(models[k] for k in names),\n                                   meta_regressor=CatBoostRegressor(verbose=False),\n                                   use_features_in_secondary=True)\nmodels[name].fit(x_tr, y_tr)\n\nprint(f\"SCORE:{models[name].score(x_tr, y_tr)}\")\n\nd = models[name].predict(deploy.drop([\"SalePrice_transformed\"], axis=1))\nd  = target_scaler.inverse_transform(d.reshape(-1,1)).squeeze()\nd = pd.DataFrame({\"Id\":deploy.index,\"SalePrice\":d})\nd.to_csv(f\"{name}.csv\", index=False)\n# \"mix_mix\" : 0.12246","06e13022":"dep_acc = {\"lin\" : 0.12696, \"lassocv\" : 0.12479, \"ridgecv\" : 0.12686, \"elasticcv\" : 0.12479, \n           \"sk_gbr\" : 0.13100, \"lightgbr\" : 0.12701, \"xgbm\" : 0.12985, \"cat\" : 0.12638,\n           \"lin_mix\" : 0.11957, \"adv_mix\" : 0.12678, \"mix_mix\" : 0.12246}\nscaled = MinMaxScaler(feature_range=(0,1)).fit_transform((1-np.array(list(dep_acc.values()))).reshape(-1,1))\nscaled = scaled\/sum(scaled)\ndep_acc = {k:scaled[i][0] for i,k in enumerate(dep_acc)}\ndep_acc","6e390fb0":"deploy = pd.read_csv(\"cat.csv\")\ndeploy[\"SalePrice\"]= 0\nfor k in dep_acc:\n    _d = pd.read_csv(f\"{k}.csv\")\n    _d[\"SalePrice\"] = _d[\"SalePrice\"]*dep_acc[k]\n    deploy[\"SalePrice\"] = deploy[\"SalePrice\"] + _d[\"SalePrice\"]","2f94fe6b":"d.to_csv(f\"final.csv\", index=False)\n# \"final\" : 0.12226","8df45f52":"## <a class=\"anchor\" id=\"1.10_bullet\" style=\"color:#b14404\"> 1.10 Other features <\/a>\n---","5e2bdab0":"## <a class=\"anchor\" id=\"1.9_bullet\" style=\"color:#b14404\"> 1.9 Garage features <\/a>\n---","2e75f17d":"## <a class=\"anchor\" style=\"color:#8f6e60\"> Clusters <\/a>\n---","4284aa29":"## <a class=\"anchor\" id=\"1.4_bullet\" style=\"color:#b14404\"> 1.4 Land plot features <\/a>\n---","7aa3d339":"## <a class=\"anchor\" style=\"color:#8f6e60\"> LightGBM <\/a>\n---","ed386e68":"\n\n\ud83d\udcaa\ud83d\udcaa\ud83d\udcaa **I will be very happy to get your upvote for this kernel and the notebook, enjoy** \n\n\ud83d\udcaa\ud83d\udcaa\ud83d\udcaa **Also, check my \"Top 3% Titanic solution\" (https:\/\/www.kaggle.com\/nikitakudriashov\/top-4-titanic-solution)** ","4f9c8e7a":"## <a class=\"anchor\" style=\"color:#8f6e60\"> General Quality weak regressor<\/a>\n---\nAfter a bunch of prunings I've chosen the set of features for general quality feature.","b8fcb0f7":"<a style=\"font-size:200%;color:#2f4c28\">Table Of Content\n* [<a style=\"font-size:150%;color:#2f4c28\">0. EDA \/ Data Preparation (Primary)](#0_bullet)\n* [<a style=\"font-size:150%;color:#2f4c28\">1. EDA \/ Feature engeneering (Attributes)](#1_bullet)\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.1 Qualitative features](#1.1_bullet)\n      -Desctibes the lot from the qualitative point of view (ordinal categorical data).\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.2 Environment features](#1.2_bullet)\n      -Describes the location, area and the environment condition of the lot.\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.3 Selling terms features](#1.3_bullet)\n      -Describes the particular qualities of the selling process.\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.4 Land plot features](#1.4_bullet)\n      -Describes the land quality features.\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.5 Dwelling features](#1.5_bullet)\n      -Describes the house in objective values   \n    * [<a style=\"font-size:130%;color:#b14404\"> 1.6 Benefits features](#1.6_bullet)\n      -Describes lot benefits or utilities\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.7 Square feet features](#1.7_bullet)\n      -Describes sqr feets of the lot areas\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.8 Basement features](#1.8_bullet)\n      -Describes the basement quality and other features\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.9 Garage features](#1.9_bullet)\n      -Describes the garage features\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.10 Other features](#1.10_bullet)\n      -Describes the misk features\n    * [<a style=\"font-size:130%;color:#b14404\"> 1.11 Clusterization](#1.10_bullet)\n      -General classes of the data  \n* [<a style=\"font-size:150%;color:#2f4c28\">2. Modeling](#2_bullet)\n    * [<a style=\"font-size:130%;color:#b14404\"> 2.1 Data Preprocessing](#2.1_bullet)\n    * [<a style=\"font-size:130%;color:#b14404\"> 2.2 Linear models](#2.2_bullet)\n    * [<a style=\"font-size:130%;color:#b14404\"> 2.3 Advanced models](#2.3_bullet)\n    * [<a style=\"font-size:130%;color:#b14404\"> 2.4 Mixture models](#2.4_bullet)\n    * [<a style=\"font-size:130%;color:#b14404\"> 2.5 Avaraging](#2.5_bullet)\n","8445e800":"## <a class=\"anchor\" style=\"color:#8f6e60\"> General dwelling type feature <\/a>\n---","a7ccd477":"## <a class=\"anchor\" id=\"2.4_bullet\" style=\"color:#b14404\"> 2.4 Mixture models <\/a>\n## <a class=\"anchor\" style=\"color:#8f6e60\"> Linear Mixture <\/a>\n---","99545d15":"## <a class=\"anchor\" style=\"color:#8f6e60\"> RidgeCV Regression<\/a>\n---","27ff35ab":"In the end of this part we will initialise some usefull methods to wirk with attributes groups:\n* **save_to_df** - updates the general DataFrame with processed group attributes\n* **replace_dummies** - replaces given feature with dummies values\n* **attribute_slice** - gets the subframe of group attributes","6ecf6036":"<h1 style=\"font-size:200%;color:#2f4c28\"> House Prices - Advanced Regression Techniques <\/h1>\n\nStarting this solution I was drowning in all the 79 variables describing (almost) every aspect of residential homes. Which do I have to start from? Or is it better just to take all of them end let it go as it goes.\n\nSo in this case I developed such approach for this task:\n1. **General EDA** with general data preparation - on this step I just tried to get some general information about the data and in some cases drop some data. After that a got the idea of separating all the attributes into several groups by their meanings and their nature.\n\n2. On the second part of EDA (actually the EDA + feature engineering)\u00a0 I decided to analyze the **values in every group separately**. During this part I analyzed the data, filled None values and created new in-group features.\n\n3. After the in-group operations with data I decided to create some **new features, based on all 79 of them, and on some intergroup relations**.\n\n4. Fourth part is the **modeling** - I just create several variants, based on different models and put everything together.\u00a0\n\nI hope such structure will be usefull for others who try to solve this task. Also, i spent some time to create good and strainforward visualisation for you to be comfortable with reading this.\n\n**Let's start**\n","28fef80b":"## <a class=\"anchor\" id=\"1.8_bullet\" style=\"color:#b14404\"> 1.8 Basement features <\/a>","c74bb5da":"## <a class=\"anchor\" style=\"color:#8f6e60\"> CatBoostRegressor <\/a>\n---","fa6bc818":"# <a class=\"anchor\" id=\"0_bullet\" style=\"color:#2f4c28\"> 0. EDA \/ Data Preparation (Primary) <\/a>\n----\n----","4aff6c91":"## <a class=\"anchor\" id=\"2.5_bullet\" style=\"color:#b14404\"> 2.5 Avaraging (may not be the best one)<\/a>\n---","7a17f755":"## <a class=\"anchor\" id=\"1.5_bullet\" style=\"color:#b14404\"> 1.5 Dwelling features <\/a>\n---","a76449b2":"## <a class=\"anchor\" id=\"1.6_bullet\" style=\"color:#b14404\"> 1.6 Benefits features <\/a>\n---","b430517b":"# <a class=\"anchor\" id=\"1.2_bullet\" style=\"color:#b14404\"> 1.2 Environment features <\/a>\n---------------------------","25ee1966":"# <a class=\"anchor\" id=\"2_bullet\" style=\"color:#2f4c28\"> 2. Modeling <\/a>\n## <a class=\"anchor\" id=\"2.1_bullet\" style=\"color:#b14404\"> 2.1 Data Preprocessing <\/a>\n---","5dac6a08":"We will reaplce categorical values manually, for not to loose there connections.","839c976c":"## <a class=\"anchor\" style=\"color:#8f6e60\"> Basement summary feature <\/a>\n---","eb0c897f":"## <a class=\"anchor\" style=\"color:#8f6e60\"> YrSold and MoSold feature <\/a>\n---","ce59be6b":"## <a class=\"anchor\" style=\"color:#8f6e60\"> Neighborhood features<\/a> \n---","43c3e7c0":"## <a class=\"anchor\" style=\"color:#8f6e60\"> ElasticNet <\/a>\n---","f8b8270f":"## <a class=\"anchor\" style=\"color:#8f6e60\"> Advanced Mixture <\/a>\n---","770c5851":"## <a class=\"anchor\" id=\"1.7_bullet\" style=\"color:#b14404\"> 1.7 Square feet features <\/a>","f199077f":"## <a class=\"anchor\" style=\"color:#8f6e60\"> SaleType feature <\/a>\n---","5945012f":"## <a class=\"anchor\" id=\"1.3_bullet\" style=\"color:#b14404\"> 1.3 Selling terms features <\/a>\n---------------------","65d001bf":"## <a class=\"anchor\" style=\"color:#8f6e60\"> XGBoost <\/a>\n---","9f4f2afe":"## <a class=\"anchor\" style=\"color:#8f6e60\"> LassoCV Regression<\/a>\n---","09a630a3":"For this feature wew will just use the normality test for distrebutions, and shrink those values, that influence target equally.","8995495c":"## <a class=\"anchor\" id=\"2.2_bullet\" style=\"color:#b14404\"> 2.2 Linear models <\/a>\n## <a class=\"anchor\" style=\"color:#8f6e60\"> Linear Regression<\/a>\n---","76f7826d":"# <a class=\"anchor\" id=\"1.1_bullet\" style=\"color:#b14404\"> 1.1 Qualitative features <\/a>\n---","6ad4d877":"## <a class=\"anchor\" id=\"2.3_bullet\" style=\"color:#b14404\"> 2.3 Advanced models <\/a>\n## <a class=\"anchor\" style=\"color:#8f6e60\"> GradientBoostingRegressor <\/a>\n---","97a5b1c4":"## <a class=\"anchor\" style=\"color:#8f6e60\"> Mixture of Mixtures <\/a>\n---","a8042c4c":"## <a class=\"anchor\" style=\"color:#8f6e60\"> Conditions features<\/a>\n---","265f5aea":"We can see that original target contains a bunch of outliers. \\\nIt will complicate our visualisation and analysis. \\\nIn this case, we will transform out target into normal dstrebution with the QuantileTransformer","135c6e7b":"## <a class=\"anchor\" id=\"1.11_bullet\" style=\"color:#b14404\"> 1.11 Clusterization <\/a>\n---","85ecb85c":"# <a class=\"anchor\" id=\"1_bullet\" style=\"color:#2f4c28\"> 1. EDA \/ Feature engeneering (Attributes) <\/a>\n----\n----"}}