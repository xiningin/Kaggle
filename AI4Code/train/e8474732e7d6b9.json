{"cell_type":{"e88d5220":"code","bb5891d1":"code","963993db":"code","f4414fb3":"code","fc058af8":"code","c98587fc":"code","d406c720":"code","d174584d":"code","779f7daf":"code","107545b5":"code","1b9e50aa":"code","1162d792":"code","38531eaa":"code","70d1ee9b":"code","3f2f58ec":"code","4170aca7":"code","e3b2ec0d":"code","481ae023":"code","66f371f5":"code","7936ab16":"code","6b317665":"markdown","bef0b45e":"markdown","21fc9b34":"markdown"},"source":{"e88d5220":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport seaborn\nimport matplotlib.dates as md\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.svm import OneClassSVM\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb5891d1":"!pip install xlrd\n!pip install openpyxl","963993db":"# return Series of distance between each point and his distance with the closest centroid\ndef getDistanceByPoint(data, model):\n    distance = pd.Series()\n    for i in range(0,len(data)):\n        Xa = np.array(data.loc[i])\n        Xb = model.cluster_centers_[model.labels_[i]-1]\n        distance.set_value(i, np.linalg.norm(Xa-Xb))\n    return distance\n\n# train markov model to get transition matrix\ndef getTransitionMatrix (df):\n\tdf = np.array(df)\n\tmodel = msm.estimate_markov_model(df, 1)\n\treturn model.transition_matrix\n\ndef markovAnomaly(df, windows_size, threshold):\n    transition_matrix = getTransitionMatrix(df)\n    real_threshold = threshold**windows_size\n    df_anomaly = []\n    for j in range(0, len(df)):\n        if (j < windows_size):\n            df_anomaly.append(0)\n        else:\n            sequence = df[j-windows_size:j]\n            sequence = sequence.reset_index(drop=True)\n            df_anomaly.append(anomalyElement(sequence, real_threshold, transition_matrix))\n    return df_anomaly","f4414fb3":"path = '\/kaggle\/input\/anomaly-detection-smart-meter-data-sample\/Lastgang Elektroverbruche 160101-170511.xlsx'\ndf = pd.read_excel(path, engine = 'openpyxl', index_col=0)","fc058af8":"df.index.name = 'datetime'\ndf.columns = ['energy']\ndf.index = pd.date_range('1\/1\/2016', periods=47581, freq='15Min')\ndate_range = pd.date_range('1\/1\/2016', periods=47581, freq='15Min')\ndf.head()","c98587fc":"df.plot(y='energy', figsize=(20,5))","d406c720":"# the hours and if it's night or day (7:00-22:00)\ndf['hours'] = df.index.hour\ndf['daylight'] = ((df['hours'] >= 7) & (df['hours'] <= 22)).astype(int)","d174584d":"# the day of the week (Monday=0, Sunday=6) and if it's a week end day or week day.\ndf['DayOfTheWeek'] = df.index.dayofweek\ndf['WeekDay'] = (df['DayOfTheWeek'] < 5).astype(int)","779f7daf":"# time with int to plot easily\ndf['time_epoch'] = (df.index.astype(np.int64)\/100000000000).astype(np.int64)","107545b5":"df['categories'] = df['WeekDay']*2 + df['daylight']\n\na = df.loc[df['categories'] == 0, 'energy']\nb = df.loc[df['categories'] == 1, 'energy']\nc = df.loc[df['categories'] == 2, 'energy']\nd = df.loc[df['categories'] == 3, 'energy']\n\nfig, ax = plt.subplots()\na_heights, a_bins = np.histogram(a)\nb_heights, b_bins = np.histogram(b, bins=a_bins)\nc_heights, c_bins = np.histogram(c, bins=a_bins)\nd_heights, d_bins = np.histogram(d, bins=a_bins)\n\nwidth = (a_bins[1] - a_bins[0])\/6\n\nax.bar(a_bins[:-1], a_heights*100\/a.count(), width=width, facecolor='blue', label='WeekEndNight')\nax.bar(b_bins[:-1]+width, (b_heights*100\/b.count()), width=width, facecolor='green', label ='WeekEndLight')\nax.bar(c_bins[:-1]+width*2, (c_heights*100\/c.count()), width=width, facecolor='red', label ='WeekDayNight')\nax.bar(d_bins[:-1]+width*3, (d_heights*100\/d.count()), width=width, facecolor='black', label ='WeekDayLight')\n\nplt.legend()\nplt.show()","1b9e50aa":"#select and standardize data\ndata_n = df[['energy', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\nmin_max_scaler = preprocessing.StandardScaler()\nnp_scaled = min_max_scaler.fit_transform(data_n)\ndata_n = pd.DataFrame(np_scaled)\n\n# important parameters and train\/test size\nprediction_time = 1 \ntestdatasize = 15000\nunroll_length = 50\ntestdatacut = testdatasize + unroll_length  + 1\n\n#train data\nx_train = data_n[0:-prediction_time-testdatacut].to_numpy()\ny_train = data_n[prediction_time:-testdatacut  ][0].to_numpy()\n\n# test data\nx_test = data_n[0-testdatacut:-prediction_time].to_numpy()\ny_test = data_n[prediction_time-testdatacut:  ][0].to_numpy()","1162d792":"#unroll: create sequence of 50 previous data points for each data points\ndef unroll(data,sequence_length=24):\n    result = []\n    for index in range(len(data) - sequence_length):\n        result.append(data[index: index + sequence_length])\n    return np.asarray(result)\n\n# adapt the datasets for the sequence data shape\nx_train = unroll(x_train,unroll_length)\nx_test  = unroll(x_test,unroll_length)\ny_train = y_train[-x_train.shape[0]:]\ny_test  = y_test[-x_test.shape[0]:]\n\n# see the shape\nprint(\"x_train\", x_train.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"x_test\", x_test.shape)\nprint(\"y_test\", y_test.shape)","38531eaa":"# specific libraries for RNN\n# keras is a high layer build on Tensorflow layer to stay in high level\/easy implementation\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nimport time #helper libraries\nfrom keras.models import model_from_json\nimport sys","70d1ee9b":"model = Sequential()\nmodel.add(LSTM(128,input_dim=x_train.shape[-1],return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(64,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32,return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.add(Activation('linear'))\n\nstart = time.time()\nmodel.compile(loss='mse', optimizer='rmsprop')\nprint('compilation time : {}'.format(time.time() - start))","3f2f58ec":"model.fit(\n    x_train,\n    y_train,\n    batch_size=10,\n    epochs=30,\n    validation_split=0.1)","4170aca7":"# create the list of difference between prediction and test data\nloaded_model = model\ndiff=[]\nratio=[]\np = loaded_model.predict(x_test)\n# predictions = lstm.predict_sequences_multiple(loaded_model, x_test, 50, 50)\nfor u in range(len(y_test)):\n    pr = p[u][0]\n    ratio.append((y_test[u]\/pr)-1)\n    diff.append(abs(y_test[u]- pr))","e3b2ec0d":"# plot the prediction and the reality (for the test data)\nfig, axs = plt.subplots()\naxs.plot(p,color='red', label='prediction')\naxs.plot(y_test,color='blue', label='y_test')\nplt.legend(loc='upper left')\nplt.show()","481ae023":"mse = []\nmse = (np.square(p - y_test)).mean(axis=1)\n\nmse_avg = np.convolve(mse, np.ones(96*4)\/(96*4), mode='valid')\nmse_avg_mean = np.mean(mse_avg)\n\nfig, ax1 = plt.subplots()\nax1.plot(mse,color='red', label='mse_error')\nax1.plot(mse_avg,color='blue', label='mse_avg')\n\nplt.legend(loc='upper left')\nplt.show()","66f371f5":"correction = 0.78\nthreshold = np.mean(mse_avg)*correction\nanomaly = []\nfor x in mse_avg:\n    if x <= threshold:\n        anomaly.append(1)\n    elif x >threshold:\n        anomaly.append(0)\n# test = (mse_avg<threshold).astype(int)\n\ndf['anomaly_rnn'] = 0\ndf['anomaly_rnn'][-(len(anomaly)):] = anomaly\ndf['anomaly_rnn'].value_counts()","7936ab16":"# visualisation of anomaly throughout time (viz 1)\nfig, ax = plt.subplots()\n\na = df.loc[df['anomaly_rnn'] == 1, ['time_epoch', 'energy']] #anomaly\n\nax.plot(df['time_epoch'], df['energy'], color='blue')\nax.scatter(a['time_epoch'],a['energy'], color='red')\nfig.set_figheight(10)\nfig.set_figwidth(20)\nplt.show()","6b317665":"# Features","bef0b45e":"# RNN Anomaly","21fc9b34":"# Data Loading"}}