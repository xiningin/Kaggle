{"cell_type":{"09acb6f4":"code","0ae497bf":"code","30d65688":"code","83c178cf":"code","3088634e":"code","c837b121":"code","4edd5f3d":"code","5c045010":"code","8c3aff97":"code","cefe2f59":"code","c24e725b":"code","e1e1738a":"code","13b2a7c2":"code","96ce7b90":"code","657d2b7f":"code","fd2f11ce":"code","d4d05c32":"code","bb807277":"code","7aa63fea":"code","7c995891":"code","9bfb0ece":"code","932326e1":"code","fb4367ae":"code","64d6193d":"code","b536ed50":"code","f58f357b":"code","0a1263fe":"code","4f0da851":"code","34745bcd":"code","0827e2f1":"code","78ed27f7":"code","94158e7b":"code","a287e62f":"code","f591a0c0":"code","a9bc25d1":"code","5c32d256":"markdown","10d3041b":"markdown","ee2e00ee":"markdown","8b616381":"markdown","e21683c8":"markdown"},"source":{"09acb6f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ae497bf":"data_path = '..\/input\/seoul-bike-rental-ai-pro-iti'\ntrain_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(data_path, 'test.csv'))\ntrain_df.head()","30d65688":"print(\"Train Shape:\", train_df.shape)\nprint(\"Test  Shape:\", test_df.shape)","83c178cf":"train_df.info()","3088634e":"test_df.info()","c837b121":"train_df.describe()","4edd5f3d":"test_df.describe()","5c045010":"visualization_df = train_df.drop(['ID'], axis=1)\nvisualization_df['Date'] = pd.to_datetime(visualization_df['Date'])\nvisualization_df = visualization_df.select_dtypes(exclude='object')\nvisualization_df['Week Days'] = visualization_df['Date'].apply(lambda x:x.dayofweek)\nvisualization_df['month']= visualization_df['Date'].apply(lambda x:x.month)\nvisualization_df.head()","8c3aff97":"corr = visualization_df.corr()\ncorr_mask = np.ones_like(corr)\ncorr_mask[np.tril_indices_from(corr_mask)] = False\n\nplt.subplots(figsize=(10,10))\nsns.heatmap(corr, mask=corr_mask, \n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, annot=True)\nplt.show()","cefe2f59":"r = 4\nc = 3\nfig, axs = plt.subplots(r, c, figsize=(20, 20))\n\ni = 0\nj = 0\nfor column in visualization_df.drop(['Date'], axis=1).columns:\n    sns.distplot(visualization_df[column], rug=True, bins=30, kde=True, hist=True, color='b', ax=axs[i, j])\n    if(j == c-1):\n        j = 0\n        i += 1\n    else:\n        j += 1","c24e725b":"i = 1\nplt.figure(figsize = [15, 15], tight_layout = 5)\nfor column in visualization_df.drop(['y'], axis=1).columns:\n    plt.subplot(5, 3, i)\n    plt.scatter(data = visualization_df, x = column, y = 'y', c='c', edgecolors='black')\n    plt.xlabel(column)\n    plt.ylabel('Bikes Count')\n    plt.title(column + ' VS ' + 'Bikes Count')\n    i += 1\nplt.show()","e1e1738a":"visualization_df.plot(kind='box', title='Box Plot', sharex=False, sharey=False, figsize=(18,7), subplots=True, layout=(2, 6))","13b2a7c2":"i = 1\nprint(train_df['Hour'])\nplt.figure(figsize = [20, 10], tight_layout = 5)\nfor column in train_df[['Seasons', 'Holiday', 'Functioning Day', 'Hour']].columns:\n    plt.subplot(3, 2, i)\n    sns.boxplot(data=train_df, x=column, y='y')\n    plt.xlabel(column)\n    plt.ylabel('Bikes Count')\n    plt.title(column + ' VS ' + 'Bikes Count')\n    i += 1\n\nplt.subplot(3, 2, i)\nsns.boxplot(data=visualization_df, x='Week Days', y='y')\nplt.xlabel('Week Days')\nplt.ylabel('Bikes Count')\nplt.title('Week Days VS ' + 'Bikes Count')","96ce7b90":"visualization_df['Season'] = train_df['Seasons']\nfor column in visualization_df[['Hour', 'Week Days']].columns:    \n    sns.catplot(data=visualization_df, x=column, y='y', hue='Season', kind='swarm', height=8, aspect=2.2)\n    plt.xlabel(column)\n    plt.ylabel('Bikes Count')\n    plt.title(column + ' VS ' + 'Bikes Count With Color Coding For Season')","657d2b7f":"train_df['Date']=pd.to_datetime(train_df['Date'],dayfirst=True).dt.date\ntest_df['Date']=pd.to_datetime(test_df['Date'],dayfirst=True).dt.date","fd2f11ce":"def map_2_cols(df,col1,col2,group,gby):\n    return df.loc[:,[col1, col2]].astype(str).sum(axis=1).map(group[gby])","d4d05c32":"def group_2_cols(df,col1,col2,gby,func='mean'):\n    group = df[[col1, col2,gby]].groupby([col1, col2],as_index=False).agg('mean')\n    group['comp'] = group[[col1,col2]].astype(str).sum(axis=1)\n    group.set_index('comp',inplace = True)\n    group.drop([col1, col2],axis=1,inplace = True)\n    return group","bb807277":"def cyclical(df, column, max_value):\n    \"\"\"\n    The function is encoding time series cyclical features with sin and cos.\n    Input: \n    ---------\n    df - pandas DataFrame\n    column - column name\n    max_value - column max value\n    Output: \n    -----------\n    -same dataframe with _sin and _cos columns added\n    \"\"\"    \n    df[column + '_sin'] = np.sin(2 * np.pi * df[column] \/ max_value)\n    df[column + '_cos'] = np.cos(2 * np.pi * df[column] \/ max_value)\n    return df","7aa63fea":"def shift_col(df, col_name, shift_num=1):\n    df[f\"{col_name}_shifted{shift_num}\"]= df[col_name] - df[col_name].shift(shift_num)\n    df[f\"{col_name}_shifted{shift_num}\"].fillna(method='bfill',inplace=True)\n#     if shift_num == 1:\n    df[f\"{col_name}_shifted{shift_num}**\"]= df[f\"{col_name}_shifted{shift_num}\"] * df[f\"{col_name}_shifted{shift_num}\"]\n#     else:\n#         df[f\"{col_name}_shifted{shift_num}**\"]= df[f\"{col_name}_shifted{shift_num}\"] ** df[f\"{col_name}_shifted{shift_num}\"]\n    df[f\"{col_name}_shifted{shift_num}**\"].fillna(method='bfill',inplace=True)\n    df[f\"{col_name}_shifted{shift_num}**\"].fillna(method='ffill',inplace=True)\n    df[f\"{col_name}_shifted{shift_num}**\"].fillna(method='ffill',inplace=True)\n    return df","7c995891":"def preprocess(df, seasons_Hour_3cut=None, seaons_mean=None,test_set=False):\n    df['Holiday'].replace({\"Holiday\": 0, \"No Holiday\": 1}, inplace=True)\n    df['Functioning Day'].replace({\"Yes\": 0, \"No\": 1}, inplace=True)\n    df['Seasons'].replace({\"Autumn\": 2, \"Spring\": 3, \"Summer\": 1, \"Winter\": 4}, inplace=True)\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['year']= df['Date'].apply(lambda x:1 if x.year == 2018 else 0)\n    df['Hour_3cut']=pd.cut(df['Hour'],\n                       bins=[-np.inf,7,18,np.inf],\n                       labels=[1,2,3]).astype('int')\n    dummies = pd.get_dummies(df, columns=['Hour', 'Seasons'], prefix=['col1', 'col2'])\n#     print(dummies)\n  \n    # split the fractions\n    df['snow_frac'] = df['Snowfall (cm)'].apply(lambda x: x - int(x))\n    df['rain_frac'] = df['Rainfall(mm)'].apply(lambda x: x - int(x))\n    df['solar_frac'] = df['Solar Radiation (MJ\/m2)'].apply(lambda x: x - int(x))\n    df['wind_frac'] = df['Wind speed (m\/s)'].apply(lambda x: x - int(x))\n#     df['wind_log'] = df['Wind speed (m\/s)'].apply(lambda x: np.log(x+1))\n    \n    #create dates columns\n    df['month']= df['Date'].apply(lambda x:x.month)\n    df['Week Days'] = df['Date'].apply(lambda x:x.dayofweek+1)\n    \n    \n    #shift columns -1\n    df = shift_col(df, 'Temperature(\ufffdC)', -1)\n    df = shift_col(df, 'Rainfall(mm)', -1)\n    df = shift_col(df, 'Humidity(%)', -1)\n    df = shift_col(df, 'Wind speed (m\/s)', -1)\n    \n    #shift columns\n    df = shift_col(df, 'Temperature(\ufffdC)')\n    df = shift_col(df, 'Rainfall(mm)')\n    df = shift_col(df, 'Humidity(%)')\n    df = shift_col(df, 'Wind speed (m\/s)')\n    \n    \n    df = cyclical(df, \"month\", 12)\n    df = cyclical(df, \"Hour\", 23)\n#     df = pd.concat([df, dummies], axis=1)\n#     print(type(df))\n    \n    return df.drop([\"ID\", 'Date', 'Temperature(\ufffdC)_shifted-1','Temperature(\ufffdC)_shifted1'],axis=1)","9bfb0ece":"train_X  = preprocess(train_df)\ntest_X = preprocess(test_df, test_set=True)\ntrain_X = train_X[train_X['Functioning Day'] == 0]\n\ntrain_X.drop('Functioning Day', axis=1, inplace=True)\ntest_X.drop('Functioning Day', axis=1, inplace=True)\n\ntrain_X['y'] = train_X['y'].apply(lambda y: np.log(y+1)) ","932326e1":"train_X.info()","fb4367ae":"test_X.isnull().sum()","64d6193d":"train_X.head()","b536ed50":"test_X.head()","f58f357b":"X = train_X.drop(columns=['y'])\ny = train_X['y']","0a1263fe":"X.head()","4f0da851":"def rmse(y_hat, y):\n    return np.mean((y - y_hat)**2)**0.5","34745bcd":"from sklearn.preprocessing import QuantileTransformer\nqt = QuantileTransformer(n_quantiles=1500)\nX = pd.DataFrame(qt.fit_transform(X))\ntest_X = pd.DataFrame(qt.transform(test_X))","0827e2f1":"import catboost as cb\nfrom sklearn.model_selection import KFold\n\n\nsplits = 10\nskf = KFold(n_splits=splits, shuffle=True, random_state=42)\n# Creating an array of zeros for storing \"out of fold\" predictions\ny_cbm = 0\noof_preds_m2 = np.zeros((X.shape[0],))\nmodel_fi_m2 = 0\ntotal_mean_rmse_m2 = 0\n\n# Generating folds and making training and prediction for each of 10 folds\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X)):\n    X_train = X.iloc[train_idx]\n    X_valid = X.iloc[valid_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n    \n\n    model2 = cb.CatBoostRegressor(learning_rate=0.09, iterations=5000,max_depth=4, \n                                  verbose=False, loss_function='MAE',\n                                  bootstrap_type='MVS', use_best_model=True, eval_metric=\"MAE\",)\n#     model2 = xgb.XGBRegressor(**params)\n    model2.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)])\n    \n    # Getting mean test data predictions (i.e. devided by number of splits)\n    y_cbm += model2.predict(test_X) \/ splits\n    \n    # Getting mean feature importances (i.e. devided by number of splits)\n    model_fi_m2 += model2.feature_importances_ \/ splits\n    \n    # Getting validation data predictions. Each fold model makes predictions on an unseen data.\n    # So in the end it will be completely filled with unseen data predictions.\n    # It will be used to evaluate hyperparameters performance only.\n    oof_preds_m2[valid_idx] = model2.predict(X_valid)\n    \n    # Getting score for a fold model\n    fold_rmse_m2 = rmse(y_valid, oof_preds_m2[valid_idx])\n    print(f\"Fold {num} RMSE: {fold_rmse_m2}\")\n\n    # Getting mean score of all fold models (i.e. devided by number of splits)\n    total_mean_rmse_m2 += fold_rmse_m2 \/ splits\n    \nprint(f\"\\nOverall RMSE: {total_mean_rmse_m2}\")","78ed27f7":"y_hat = np.exp(y_cbm) - 1","94158e7b":"zero_days_id = test_df[test_df['Functioning Day'] == 1]['ID'].values\nzero_days_id","a287e62f":"sample_submission= pd.DataFrame({'ID':test_df['ID'].to_numpy(), 'y': y_hat })\nsample_submission['y'] = sample_submission.apply(lambda row: 0 if row.ID in zero_days_id else row.y, axis=1)\nsample_submission.to_csv(os.path.join('.\/',\"submission.csv\"), index=False)","f591a0c0":"sample_submission[sample_submission['ID']==8232]","a9bc25d1":"plt.hist(sample_submission['y'])","5c32d256":" # 4. **Model Training**","10d3041b":"# 6. **Model Submission**","ee2e00ee":"# 3. **Feature Engineering**","8b616381":"# 1. **Load and Preview The Data**","e21683c8":"# 2. **EDA**"}}