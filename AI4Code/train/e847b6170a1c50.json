{"cell_type":{"6dacc69a":"code","020b4ea7":"code","f018e49a":"code","880fb322":"code","ee7c92b7":"code","1390c21c":"code","3dc594d6":"code","3db2974d":"code","bc269fe5":"code","046ffb84":"code","ca357efd":"code","a1abfb56":"code","697d291a":"code","5a2c776a":"code","4c42406e":"code","42b3a91d":"code","a4c1064c":"code","4b158fcb":"markdown","d4bc25a7":"markdown","5d0b1c41":"markdown","1a66c762":"markdown","2c1199a6":"markdown","7e42af0c":"markdown"},"source":{"6dacc69a":"import nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom math import log, sqrt\nimport pandas as pd\nimport numpy as np\nimport re","020b4ea7":"train_df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest_df = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","f018e49a":"train_df.describe","880fb322":"train_df.isnull().sum()","ee7c92b7":"train_df['target'].value_counts()","1390c21c":"disaster_words = ' '.join(list(train_df[train_df['target'] == 1]['text']))\ndisaster_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(disaster_words)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(disaster_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()","3dc594d6":"n_disaster_words = ' '.join(list(train_df[train_df['target'] == 0]['text']))\nn_disaster_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(n_disaster_words)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(n_disaster_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()","3db2974d":"import string\ndef clean_text(text):\n    result = re.sub(r'http[^\\s]*', '',text)\n    result = re.sub(r'amp', '',text)\n    result = re.sub(r'^', '',text)\n    result = re.sub('[0-9]+','', result).lower()\n    result = re.sub('@[a-z0-9]+', 'user', result)\n    return re.sub('[%s]*' % string.punctuation, '',result)","bc269fe5":"sort=[]\nfor n in range(0, len(train_df)):\n    sort.append(clean_text(train_df['text'][n]))\ndf_cleaned = pd.DataFrame(sort) \ndf_cleaned.columns = ['cleaned_text']\nprint(df_cleaned['cleaned_text'])","046ffb84":"train_df= pd.concat([train_df, df_cleaned], axis=1)\ntrain_df","ca357efd":"disaster_words = ' '.join(list(train_df[train_df['target'] == 1]['cleaned_text']))\ndisaster_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(disaster_words)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(disaster_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()","a1abfb56":"n_disaster_words = ' '.join(list(train_df[train_df['target'] == 0]['cleaned_text']))\nn_disaster_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(n_disaster_words)\nplt.figure(figsize = (10, 8), facecolor = 'k')\nplt.imshow(n_disaster_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()","697d291a":"def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n    if lower_case:\n        message = message.lower()\n    words = word_tokenize(message)\n    words = [w for w in words if len(w) > 2]\n    if gram > 1:\n        w = []\n        for i in range(len(words) - gram + 1):\n            w += [' '.join(words[i:i + gram])]\n        return w\n    if stop_words:\n        sw = stopwords.words('english')\n        words = [word for word in words if word not in sw]\n    if stem:\n        stemmer = PorterStemmer()\n        words = [stemmer.stem(word) for word in words]   \n    return words","5a2c776a":"class TweetClassifier(object):\n    def __init__(self, trainData, method = 'tf-idf'):\n        self.tweets, self.targets = train_df['text'], train_df['target']\n        self.method = method\n\n    def train(self):\n        self.calc_TF_and_IDF()\n        if self.method == 'tf-idf':\n            self.calc_TF_IDF()\n        else:\n            self.calc_prob()\n\n    def calc_prob(self):\n        self.prob_depressive = dict()\n        self.prob_positive = dict()\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.tf_depressive[word] + 1) \/ (self.depressive_words + \\\n                                                                len(list(self.tf_depressive.keys())))\n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.tf_positive[word] + 1) \/ (self.positive_words + \\\n                                                                len(list(self.tf_positive.keys())))\n        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets \/ self.total_tweets, self.positive_tweets \/ self.total_tweets \n\n\n    def calc_TF_and_IDF(self):\n        noOfMessages = self.tweets.shape[0]\n        self.depressive_tweets, self.positive_tweets = self.targets.value_counts()[1], self.targets.value_counts()[0]\n        self.total_tweets = self.depressive_tweets + self.positive_tweets\n        self.depressive_words = 0\n        self.positive_words = 0\n        self.tf_depressive = dict()\n        self.tf_positive = dict()\n        self.idf_depressive = dict()\n        self.idf_positive = dict()\n        for i in range(noOfMessages):\n            message_processed = process_message(self.tweets.iloc[i])\n            count = list() #To keep track of whether the word has ocured in the message or not.\n                           #For IDF\n            for word in message_processed:\n                if self.targets.iloc[i]:\n                    self.tf_depressive[word] = self.tf_depressive.get(word, 0) + 1\n                    self.depressive_words += 1\n                else:\n                    self.tf_positive[word] = self.tf_positive.get(word, 0) + 1\n                    self.positive_words += 1\n                if word not in count:\n                    count += [word]\n            for word in count:\n                if self.targets.iloc[i]:\n                    self.idf_depressive[word] = self.idf_depressive.get(word, 0) + 1\n                else:\n                    self.idf_positive[word] = self.idf_positive.get(word, 0) + 1\n\n    def calc_TF_IDF(self):\n        self.prob_depressive = dict()\n        self.prob_positive = dict()\n        self.sum_tf_idf_depressive = 0\n        self.sum_tf_idf_positive = 0\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.tf_depressive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n                                                          \/ (self.idf_depressive[word] + self.idf_positive.get(word, 0)))\n            self.sum_tf_idf_depressive += self.prob_depressive[word]\n        for word in self.tf_depressive:\n            self.prob_depressive[word] = (self.prob_depressive[word] + 1) \/ (self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n            \n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.tf_positive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n                                                          \/ (self.idf_depressive.get(word, 0) + self.idf_positive[word]))\n            self.sum_tf_idf_positive += self.prob_positive[word]\n        for word in self.tf_positive:\n            self.prob_positive[word] = (self.prob_positive[word] + 1) \/ (self.sum_tf_idf_positive + len(list(self.prob_positive.keys())))\n            \n    \n        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets \/ self.total_tweets, self.positive_tweets \/ self.total_tweets \n                    \n    def classify(self, processed_message):\n        pDepressive, pPositive = 0, 0\n        for word in processed_message:                \n            if word in self.prob_depressive:\n                pDepressive += log(self.prob_depressive[word])\n            else:\n                if self.method == 'tf-idf':\n                    pDepressive -= log(self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n                else:\n                    pDepressive -= log(self.depressive_words + len(list(self.prob_depressive.keys())))\n            if word in self.prob_positive:\n                pPositive += log(self.prob_positive[word])\n            else:\n                if self.method == 'tf-idf':\n                    pPositive -= log(self.sum_tf_idf_positive + len(list(self.prob_positive.keys()))) \n                else:\n                    pPositive -= log(self.positive_words + len(list(self.prob_positive.keys())))\n            pDepressive += log(self.prob_depressive_tweet)\n            pPositive += log(self.prob_positive_tweet)\n        return pDepressive >= pPositive\n    \n    def predict(self, testData):\n        result = dict()\n        for (i, text) in enumerate(test_df):\n            processed_message = process_message(text)\n            result[i] = int(self.classify(processed_message))\n        return result","4c42406e":"def metrics(targets, predictions):\n    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n    for i in range(len(targets)):\n        true_pos += int(targets.iloc[i] == 1 and predictions[i] == 1)\n        true_neg += int(targets.iloc[i] == 0 and predictions[i] == 0)\n        false_pos += int(targets.iloc[i] == 0 and predictions[i] == 1)\n        false_neg += int(targets.iloc[i] == 1 and predictions[i] == 0)\n    precision = true_pos \/ (true_pos + false_pos)\n    recall = true_pos \/ (true_pos + false_neg)\n    Fscore = 2 * precision * recall \/ (precision + recall)\n    accuracy = (true_pos + true_neg) \/ (true_pos + true_neg + false_pos + false_neg)\n\n    print(\"Precision: \", precision)\n    print(\"Recall: \", recall)\n    print(\"F-score: \", Fscore)\n    print(\"Accuracy: \", accuracy)","42b3a91d":"sc_tf_idf = TweetClassifier(train_df, 'tf-idf')\nsc_tf_idf.train()\nsc_tf_idf.predict(test_df['text'])","a4c1064c":"for i in range(0, 10):\n    print(test_df['text'][i])\n    pm = process_message(test_df['text'][i])\n    print(sc_tf_idf.classify(pm))","4b158fcb":"## Read data","d4bc25a7":"## Wordcloud after cleaning text","5d0b1c41":"## Wordcloud before cleaning text","1a66c762":"## Cleaning data","2c1199a6":"## Tf-Idf Classification ","7e42af0c":"## Predicting text from test set"}}