{"cell_type":{"95882304":"code","9a95a2ab":"code","afa409ea":"code","b6873679":"code","58483f30":"code","515895a1":"code","b0125348":"code","fc5c2d2a":"code","6bcda0fb":"code","044e2919":"code","834b979e":"code","a7499205":"code","10230d9a":"code","e4682dd5":"code","8399ff43":"markdown"},"source":{"95882304":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a95a2ab":"df_crop = pd.read_csv('..\/input\/crop-recommendation-dataset\/Crop_recommendation.csv')\ndf_crop.head()","afa409ea":"df_crop.isna().sum()","b6873679":"df_crop['label'].unique()","58483f30":"label_encode = LabelEncoder()\n\ndf_crop['label'] = label_encode.fit_transform(df_crop['label'])\ncrop_category = {index : label for index, label in enumerate(label_encode.classes_)}\ncrop_category","515895a1":"df_crop","b0125348":"X = df_crop.drop('label', axis = 1)\ny = df_crop['label']","fc5c2d2a":"X","6bcda0fb":"y","044e2919":"X_train, X_test, y_train, y_test = tts(X, y, train_size = 0.8)","834b979e":"X_train.shape","a7499205":"inputs = tf.keras.Input(shape = (7, ))\nx = tf.keras.layers.Dense(64, activation = 'relu')(inputs)\n# x = tf.keras.layers.Dense(64, activation = 'relu')(x)\noutputs = tf.keras.layers.Dense(22, activation = 'softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = 'accuracy'\n)\n\nbatch_size = 128\nepochs = 89\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split = 0.2,\n    batch_size = batch_size,\n    epochs = epochs\n)","10230d9a":"plt.figure(figsize = (20, 10))\n\nplt.plot(range(epochs), history.history['loss'], label = 'Training loss')\nplt.plot(range(epochs), history.history['val_loss'], label = 'Validation loss')\n\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","e4682dd5":"model.evaluate(X_test, y_test)","8399ff43":"# Please give feedback and upvote my notebook if you like this"}}