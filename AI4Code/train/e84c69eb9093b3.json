{"cell_type":{"42c9ab66":"code","468b23d4":"code","95b881a9":"code","5a827508":"code","408fca61":"code","40fccc65":"code","2b753475":"code","ca70e51c":"code","2f3c6e48":"code","a20c6033":"code","7ee294ab":"code","a20fc673":"code","b999fc90":"markdown"},"source":{"42c9ab66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport wandb\nfrom torch.utils.data import Dataset\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","468b23d4":"d  =  pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","95b881a9":"d['Age'].dropna().mean()\n","5a827508":"def train(net, data, learning_rate = 0.1, num_epochs = 10, batch_size = 10, debug = False):\n    print('Starting training')\n    net.train()\n    train_loader = torch.utils.data.DataLoader(data, batch_size, shuffle=True)\n    mse_loss_function = nn.MSELoss()\n    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum = 0.9)\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        if debug:\n            print(\"---------------------------------------------\")\n        for data, labels in train_loader:\n            if debug:\n                print(\"********************************************\")\n            optimizer.zero_grad()\n            outputs = net(data)\n            if debug:\n                print(f\"Shape of input is {data.shape}\")\n                print(f\"Shape of output is {outputs.shape} and shape of labels is {labels.shape}\")\n                print(f\"{labels[0]} VS. {outputs[0]}\")\n            loss = mse_loss_function(outputs, labels.view(outputs.shape))\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        if epoch % 10 == 0:\n            print(f'[epoch - {epoch}]Loss is {running_loss}')\n    print('Done training')","408fca61":"age_features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\"]\nage_layers = [len(age_features), 50, 50, 1]\n\nclass AgeModel(nn.Module):\n    def __init__(self):\n        super(AgeModel, self).__init__()\n        nb_features = len(age_features)\n        layers = []\n        for i, age_layer in enumerate(age_layers[:len(age_layers) - 1]):\n            layer = nn.Linear(age_layer, age_layers[i + 1])\n            torch.nn.init.xavier_uniform_(layer.weight)\n            layers.append(layer)\n        self.layers = nn.ModuleList(layers)\n        #self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        for i, layer in enumerate(self.layers):\n            if i == len(self.layers) - 1:\n                x = layer(x)\n            else:\n                x = torch.sigmoid(layer(x))\n                #x = self.dropout(x)\n        return x\n\nclass AgeDataset(Dataset):\n    def __init__(self, filename, test=False):\n        self.test = test\n        data = pd.read_csv(filename)\n        ss= StandardScaler()\n        # Remove unknown age\n        if not test:\n            data = data.loc[data[\"Age\"] >= 0]\n        # Replace sex\n        data['Sex'] = data['Sex'].map({'female': 1, 'male': 0})\n        self.x = torch.tensor(ss.fit_transform(data[age_features])).float()\n        if test :\n            self.passengerId = torch.tensor(data['PassengerId'].values).float()\n            print(f\"Length are {len(data['PassengerId'])} VS {len(self.passengerId)}\")\n        else :\n            self.y = torch.tensor(data['Age'].values).float()\n        \n    def __len__(self):\n        return len(self.passengerId) if self.test else len(self.y)\n    \n    def __getitem__(self, idx):\n        y = self.passengerId[idx] if self.test else self.y[idx]\n        return self.x[idx], y\n    \nage_train_data = AgeDataset('\/kaggle\/input\/titanic\/train.csv')\nage_test_data = AgeDataset('\/kaggle\/input\/titanic\/test.csv', True)","40fccc65":"age_model = AgeModel()\ntrain(age_model, data = age_train_data, num_epochs = 1000, batch_size = 400, learning_rate = 0.0001, debug = False)","2b753475":"age_test_loader = torch.utils.data.DataLoader(age_test_data, batch_size = 10, shuffle=False)\ndf_ages = pd.DataFrame([], columns=['PassengerId', 'Age'])\nage_model.eval()\nfor data, ids in age_test_loader:\n    outputs = age_model(data)\n    df_temp = pd.DataFrame([], columns=['PassengerId', 'Age'])\n    df_temp['PassengerId'] = ids.view((-1)).int().numpy()\n    df_temp['Age'] = outputs.view((-1)).int().numpy()\n    df_ages = df_ages.append(df_temp)\ndf_ages","ca70e51c":"features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\nhidden_layers = [len(features), 50, 50, 1]\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        nb_features = len(features)\n        layers = []\n        for i, hidden_layer in enumerate(hidden_layers[:len(hidden_layers) - 1]):\n            layers.append(nn.Linear(hidden_layer, hidden_layers[i + 1]))\n        self.layers = nn.ModuleList(layers)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        for i, layer in enumerate(self.layers):\n            x = torch.sigmoid(layer(x))\n            if i > 0 and i < len(hidden_layers) - 1:\n                x = self.dropout(x)\n        return x\nclass FeatureDataset(Dataset):\n    def __init__(self, filename, test=False):\n        self.test = test\n        data = pd.read_csv(filename)\n        # Remove unknown age\n        data_clean = data.loc[data[\"Age\"] >= 0]\n        # Replace sex\n        data_clean['Sex'] = data_clean['Sex'].map({'female': 1, 'male': 0})\n        # Replace embark\n        labels_embark = data.Embarked.unique()\n        map_embark = {}\n        for i, val in enumerate(labels_embark):\n            map_embark[labels_embark[i]] = i\n        data_clean['Embarked'] = data_clean['Embarked'].map(map_embark)\n        self.x = torch.tensor(data_clean[features].values).float()\n        if test :\n            self.passengerId = data_clean['PassengerId']\n        else :\n            self.y = torch.tensor(data_clean['Survived'].values).float()\n        \n    def __len__(self):\n        return len(self.passengerId) if self.test else len(self.y)\n    \n    def __getitem__(self, idx):\n        y = self.passengerId[idx] if self.test else self.y[idx]\n        return self.x[idx], y\n    \ntrain_data = FeatureDataset('\/kaggle\/input\/titanic\/train.csv')\ntest_data = FeatureDataset('\/kaggle\/input\/titanic\/test.csv', True)","2f3c6e48":"def train(net, data, learning_rate = 0.1, num_epochs = 10):\n    print('Starting training')\n    #wandb.init(project='Titanic')\n    #wandb.watch(net)\n    net.train()\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size = 10, shuffle=True)\n    mse_loss_function = nn.MSELoss()\n    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum = 0.9)\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for data, labels in train_loader:\n            #print('D\u00e9but d\\'un nouveau batch')\n            for i in range(1):\n                optimizer.zero_grad()\n                data = data.view(-1,len(features))\n                outputs = net(data)\n                loss = mse_loss_function(outputs, labels)\n                #print(f'{outputs[0]} VS {labels[0]} -> {loss.item()}')\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n        print(f'Loss is {running_loss}')\n    print('Done training')","a20c6033":"net = Net()\ntrain(net, data = train_data, num_epochs = 10)","7ee294ab":"test_loader = torch.utils.data.DataLoader(test_data, batch_size = 1, shuffle=False)\nprint(len(test_loader))\nevaluations = []\nnet.eval()\nfor data, ids in test_loader:\n    data = data.view(-1,len(features))\n    outputs = net(data)\n    print(len(outputs))","a20fc673":"test_loader.get(0)\n","b999fc90":"We should notice that a lot of rows do not have an age value which we want to use as a predictor so first we're gonna train a model that will fill in the gaps based on the following features :\n* Pclass\n* Sex\n* SibSp\n* Parch\n* Fare"}}