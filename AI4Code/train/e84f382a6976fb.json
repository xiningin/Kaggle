{"cell_type":{"dbc16cfa":"code","2feaa435":"code","53c8045d":"code","0a4af902":"code","32744911":"code","8becae45":"code","cc8cf223":"code","ce9a99f7":"code","c3539f62":"code","254719c8":"code","f4564128":"code","0217f656":"code","0aa4d9c6":"code","0af8abe7":"code","530ca14c":"code","599d61be":"code","7484848e":"code","71d541df":"code","dd163586":"code","7b8a259d":"code","4a354c83":"code","8be02acd":"code","9fa3badd":"code","460e4fe8":"code","88b6b263":"code","371c85c1":"code","097a0bee":"code","fc01a133":"code","a813e1ab":"code","18c6dfc1":"code","40acca55":"code","7c2fe193":"code","2011f461":"code","b8efc2d3":"code","cdb2f6a8":"code","ba4b05b8":"code","0a41a214":"code","c338ccfb":"code","89ea0a29":"code","7506a975":"markdown","e2e407e5":"markdown","74716ca3":"markdown","8ac73a81":"markdown","fd7be952":"markdown","e9849c40":"markdown","d8e01052":"markdown","fdcc00a7":"markdown","b01d97ca":"markdown","abc380ed":"markdown","40fba785":"markdown","4c06c6ac":"markdown","021284ad":"markdown","3721fe22":"markdown","d84ccea3":"markdown","8e79e9c7":"markdown","96d2f8cb":"markdown","ac7671aa":"markdown","458d36bc":"markdown","f05947fa":"markdown","b7060f6d":"markdown","0958638e":"markdown","afcedb43":"markdown","2b2e2f0f":"markdown","1c5d18e3":"markdown","0fd65d81":"markdown","a7c93ebd":"markdown","2ea60225":"markdown","05736935":"markdown","76d2008e":"markdown"},"source":{"dbc16cfa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport cv2\n\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\n\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(os.listdir(\"..\/input\"))","2feaa435":"X=np.load('..\/input\/Sign-language-digits-dataset\/X.npy')\ny=np.load('..\/input\/Sign-language-digits-dataset\/Y.npy')","53c8045d":"print(\"X shape:\",X.shape)\nprint(\"y shape:\",y.shape)\nrandom_choice=np.random.randint(X.shape[0])\nprint(\"y[{}]:{}\".format(random_choice, y[random_choice]))","0a4af902":"y_new=list()\nfor target in y:\n    y_new.append(np.argmax(target))\ny=np.array(y_new)","32744911":"print(\"X shape:\",X.shape)\nprint(\"y shape:\",y.shape)\nprint(\"y[{}]:{}\".format(random_choice, y[random_choice]))","8becae45":"sample_per_class=np.unique(y, return_counts=True)\n \nfor sign, number_of_sample in zip(sample_per_class[0], sample_per_class[1]):\n    print(\"{} sign has {} samples.\".format(sign, number_of_sample))","cc8cf223":"def show_image_classes(image, label, n=10):\n    fig, axarr=plt.subplots(nrows=n, ncols=n, figsize=(18, 18))\n    axarr=axarr.flatten()\n    plt_id=0\n    start_index=0\n    for sign in range(10):\n        sign_indexes=np.where(label==sign)[0]\n        for i in range(n):\n\n            image_index=sign_indexes[i]\n            axarr[plt_id].imshow(image[image_index], cmap='gray')\n            axarr[plt_id].set_xticks([])\n            axarr[plt_id].set_yticks([])\n            axarr[plt_id].set_title(\"Sign :{}\".format(sign))\n            plt_id=plt_id+1\n    plt.suptitle(\"{} Sample for Each Classes\".format(n))\n    plt.show()","ce9a99f7":"show_image_classes(image=X, label=y)","c3539f62":"label_map={0:9,1:0, 2:7, 3:6, 4:1, 5:8, 6:4, 7:3, 8:2, 9:5}\ny_new=list()\nfor s in y:\n    y_new.append(label_map[s])\ny=np.array(y_new)","254719c8":"show_image_classes(image=X, label=y)","f4564128":"X_normal=X.reshape(X.shape[0],X.shape[1]*X.shape[2])","0217f656":"X_train, X_test, y_train, y_test=train_test_split(X_normal, y,\n                                                 stratify=y,\n                                                 test_size=0.3,\n                                                 random_state=42)","0aa4d9c6":"pca=PCA(n_components=2)\npca.fit(X_train)\nX_train_pca=pca.transform(X_train)\nX_test_pca=pca.transform(X_test)\nprint(\"PCA transform performed...\")","0af8abe7":"number_of_class=10\n\nfig=plt.figure(figsize=(10,8))\nax=fig.add_subplot(1,1,1)\nscatter=ax.scatter(X_train_pca[:,0],\n            X_train_pca[:,1], \n            c=y_train,\n            s=10,\n           cmap=plt.get_cmap('jet', number_of_class)\n          )\n\nax.set_xlabel(\"First Principle Component\")\nax.set_ylabel(\"Second Principle Component\")\nax.set_title(\"PCA projection of {} classes\".format(number_of_class))\n\nfig.colorbar(scatter)","530ca14c":"pca=PCA()\npca.fit(X_normal)\n\nplt.figure(1, figsize=(12,8))\n\nplt.plot(pca.explained_variance_, linewidth=2)\n \nplt.xlabel('Components')\nplt.ylabel('Explained Variaces')\nplt.xticks([50,100, 250, 500, 1000, 2050])\nplt.show()","599d61be":"determined_n_components=100","7484848e":"models=[LinearDiscriminantAnalysis(),\n       LogisticRegression(multi_class=\"auto\", solver=\"liblinear\"),\n       RandomForestClassifier(n_estimators=100),\n       KNeighborsClassifier(n_neighbors=5),\n       DecisionTreeClassifier(),\n       SVC(gamma=\"scale\")]","71d541df":"class Clf_Helper:\n    \n    def __init__(self, X, y, n_components):\n        self.train_test_split(X,y)\n        self.n_components=n_components\n        self.transform()\n        \n    \n    def train_test_split(self, X, y):\n        if np.max(X[0])>1:\n            X=X\/255.0\n            print(\"Data scaled...\")\n            \n        self.X_train, self.X_test, self.y_train, self.y_test=train_test_split(X, y,\n                                                 stratify=y,\n                                                 test_size=0.3,\n                                                 random_state=42)\n    def transform(self):\n        self.pca_transform()\n        \n    def pca_transform(self):\n        pca=PCA(n_components=self.n_components)\n        pca.fit(self.X_train)\n        self.X_train=pca.transform(self.X_train)\n        self.X_test=pca.transform(self.X_test)\n        print(\"PCA transform performed...\")\n    \n    def best_model(self, models, show_metrics=False):\n        print(\"INFO: Finding Accuracy Best Classifier...\", end=\"\\n\\n\")\n        best_clf=None\n        best_acc=0\n        for clf in models:\n            clf.fit(self.X_train, self.y_train)\n            y_pred=clf.predict(self.X_test)\n            acc=metrics.accuracy_score(self.y_test, y_pred)\n            print(clf.__class__.__name__, end=\" \")\n            print(\"Accuracy:{:.3f}\".format(acc))\n\n            if best_acc<acc:\n                best_acc=acc\n                best_clf=clf\n                best_y_pred=y_pred\n        \n        print(\"Best Classifier:{}\".format(best_clf.__class__.__name__))\n        if show_metrics:\n            self.metrics(y_true=self.y_test, y_pred=best_y_pred)\n    \n    def cv_best_model(self, models, show_metrics=False):\n        print(\"INFO: Finding Cross Validated Accuracy Best Classifier...\", end=\"\\n\\n\")\n        kfold=KFold(n_splits=5,  shuffle=True, random_state=0)\n        best_clf=None\n        best_acc=0\n        for clf in models:\n            cv_scores=cross_val_score(clf, self.X_train, self.y_train, cv=kfold)\n            print(clf.__class__.__name__, end=\" \")\n            cv_mean_acc=cv_scores.mean()\n            print(\"CV Mean Accuracy:{:.3f}\".format(cv_mean_acc))\n            if best_acc<cv_mean_acc:\n                  best_acc=cv_mean_acc\n                  best_clf=clf\n                \n        print(\"CV Best Classifier:{}\".format(best_clf.__class__.__name__))\n        if show_metrics:\n            y_pred = best_clf.predict(self.X_test)\n            self.metrics(y_true=self.y_test, y_pred=y_pred)\n        \n        return best_clf\n    \n    def grid_searc_cv_for_best_model(self, model, params, show_metrics=False):\n        kfold=KFold(n_splits=3,  shuffle=True, random_state=0)\n        grid_search_cv=GridSearchCV(SVC(), params, cv=kfold, scoring=\"accuracy\")\n        grid_search_cv.fit(self.X_train, self.y_train)\n        y_pred=grid_search_cv.predict(self.X_test)\n        print(\"Best pamameters for {}:{}\".format(model.__class__.__name__, \n                                              grid_search_cv.best_params_))\n        print(\"Accuracy:{:.3f}\".format(metrics.accuracy_score(self.y_test, y_pred)))\n        if show_metrics:\n            self.metrics(y_true=self.y_test, y_pred=y_pred)\n    \n    def metrics(self, y_true, y_pred):\n        print(\"Accuracy:{:.3f}\".format(metrics.accuracy_score(y_true, y_pred)))\n        print(\"Confusion Matrix:\\n{}\".format(metrics.confusion_matrix(y_true, y_pred)))\n        print(\"Classification Report:\\n{}\".format(metrics.classification_report(y_true, y_pred)))","dd163586":"clf_helper=Clf_Helper(X_normal, y, determined_n_components)","7b8a259d":"clf_helper.best_model(models)","4a354c83":"cv_best_clf=clf_helper.cv_best_model(models)","8be02acd":"parameters={'gamma': [1, 1e-1, 1e-2, 1e-3],\n                     'C': [1, 10, 100, 1000]}\nclf_helper.grid_searc_cv_for_best_model(cv_best_clf, parameters)\n","9fa3badd":"hist=cv2.calcHist(images=[X[0]],\n                 channels=[0],\n                 mask=None,\n                 histSize=[256],\n                 ranges=[0,1])","460e4fe8":"plt.figure(figsize=(6,2))\nplt.subplot(121)\nplt.plot(hist, color=\"black\")\n\nplt.subplot(122)\nplt.imshow(X[0],cmap=\"gray\")\nplt.xticks([])\nplt.yticks([])\n\nplt.show()","88b6b263":"image= X[0].copy()\n\nimage=np.uint8(image*255)\n\nplt.figure(figsize=(12,2))\nplt.subplot(141)\nplt.imshow(image, cmap=\"gray\")\nplt.subplot(142)\nplt.plot(hist, color=\"black\")\n\neq_image=cv2.equalizeHist(image)\neq_hist=cv2.calcHist(images=[eq_image],\n                 channels=[0],\n                 mask=None,\n                 histSize=[256],\n                 ranges=[0,256])\nplt.subplot(143)\neq_image=eq_image\/255.0\nplt.imshow(eq_image, cmap=\"gray\")\nplt.subplot(144)\nplt.plot(eq_hist, color=\"black\")\n","371c85c1":"X_eq=list()\ncount=0\nfor image in X.copy():\n    image=np.uint8(image*255)\n    eq_image=cv2.equalizeHist(image)\n    eq_image\/255.0\n    X_eq.append(eq_image)\n    count=count+1\n    \n\nX_eq=np.array(X_eq)\nprint(\"Histogram equalized performed...\")\n    ","097a0bee":"show_image_classes(image=X_eq, label=y)","fc01a133":"X_eq=X_eq.reshape(X_eq.shape[0],X.shape[1]*X.shape[2])","a813e1ab":"clf_helper=Clf_Helper(X_eq, y, determined_n_components)","18c6dfc1":"clf_helper.best_model(models)","40acca55":"cv_best_clf=clf_helper.cv_best_model(models)","7c2fe193":"parameters={'gamma': [1, 1e-1, 1e-2, 1e-3],\n                     'C': [1, 10, 100, 1000]}\nclf_helper.grid_searc_cv_for_best_model(cv_best_clf, parameters)","2011f461":"class Extended_Clf_Helper(Clf_Helper):\n    \n    def __init__(self, X, y, n_components, transform_type, kernel):\n        \n        self.transform_type=transform_type\n        self.kernel=kernel\n        Clf_Helper.__init__(self, X, y, n_components)\n        \n    \n    def transform(self):\n        if self.transform_type==\"pca\":\n            self.pca_transform()\n        elif self.transform_type==\"kernel_pca\":\n            self.kernel_pca_transform()\n        else:\n            raise ValueError(\"Bad transform choice!!!\")\n    \n    def kernel_pca_transform(self):\n        kernel_pca=KernelPCA(n_components=self.n_components, kernel=self.kernel)\n        kernel_pca.fit(self.X_train)\n        self.X_train=kernel_pca.transform(self.X_train)\n        self.X_test=kernel_pca.transform(self.X_test)\n        print(\"KernelPCA(kernel={}) transform performed...\".format(self.kernel))\n","b8efc2d3":"extended_clf_helper=Extended_Clf_Helper(X_eq, y, determined_n_components,\"kernel_pca\",\"linear\")","cdb2f6a8":"cv_best_clf=extended_clf_helper.best_model(models)","ba4b05b8":"extended_clf_helper.grid_searc_cv_for_best_model(cv_best_clf, parameters)","0a41a214":"from sklearn.pipeline import Pipeline","c338ccfb":"work_flow=[]\nwork_flow.append(('PCA',PCA(n_components=100)))\nwork_flow.append((\"SVC\", SVC(C=10, gamma=0.01)))\n\nX_train, X_test, y_train, y_test=train_test_split(X_normal, y, \n                                                    test_size=0.3, random_state=42)\nmodel=Pipeline(work_flow)\nmodel.fit(X_train, y_train)\ny_pred=model.predict(X_test)\nacc=metrics.accuracy_score(y_test, y_pred)\ncm=metrics.confusion_matrix(y_test, y_pred)\ncr=metrics.classification_report(y_test, y_pred)\nprint(\"Accuracy score:{:.3f}\".format(acc))\nprint(\"Confusion Matrix:\\n{}\".format(cm))\nprint(\"Classification Report:\\n{}\".format(cr))","89ea0a29":" \nprint(\" Many thanks for reading and upvoting the kernel\\n\"*10)","7506a975":"Histogram equalization process lift up accuracy %4. ","e2e407e5":"Machine learning methods are divided into two: supervised learning and unsupervised learning. In supervised learning, a dataset is divided into two main parts: 'data' and 'output'. The data holds the values of the sample in the dataset, while the 'output' holds the class (for classification) or the target value (for regression). In unsupervised learning, the dataset consists of only the data section.\n\nNon-supervised learning is generally divided into two: data transformation and clustering. In this study, the transformation of the data will be carried out using unsupervised learning. Unsupervised transformation methods allow for easier interpretation of data by computers and people.\n\nThe most common unsupervised transformation applications is to reduce data size. In the size reduction process, the dimension of the data reduced.\n\nPrinciple Component Analysis (PCA) is a method that allows data to be represented in a lesser size. According to this method, the data is transformed to new components and the size of the data is reduced by selecting the most important components.","74716ca3":"[Go to Content Menu](#0.)\n\n<a class a=\"anchor\" id=\"4.3.\"><\/a>**4.3.Histogram Equalization**\n\nConsider a histogram with a high peak. Applying the equalization to the histogram increases the image contrast by strecing the peak to the left and right.\n\nThe histogram equalization with OpenCV is accomplished by the equalizeHist () function. The function takes the image as the input and equaliza the histogram of the image it receives. The function  returns to the equalized histogram image.","8ac73a81":"# <a class=\"anchor\" id=\"0.\"><\/a> Content\n\n* [Summary](#0.1.)\n* [1. About The Dataset](#1.)\n* * [1.1. Visualizing The Dataset](#1.1.)\n* * [1.2. Correcting Mistarget Matches](#1.2.)\n* * [1.3. Visualizing After Correcting](#1.3.)\n* [2. Pricipla Component Anaylsis (PCA)](#2.)\n* * [2.1. PCA Transform](#2.1.)\n* * [2.2. Finding Optimum Number of Principle Component](#2.2.)\n* [3. Finding Best Classifier](#3.)\n* * [3.1. Clf_Helper Class](#3.1.)\n* * [3.2. Best Classifier Hyperparameter Tunning](#3.2.)\n* [4. Equalizing Histogram of Images in the Dataset ](#4.)\n* * [4.1. Histogram](#4.1.)\n* * [4.2. Obtaining Image Histogram](#4.2.)\n* * [4.3. Histogram Equalization](#4.3.)\n* * [4.4. Visualiazing After Histogram Equalization](#4.4.)\n* [5. Finding Best Classifier on Histogram Equalized Image](#5.)\n* * [5.1. Hyperparameter Tunning](#5.1.)\n* [6. Dimension Reduction with Kernel PCA](#6.)\n* [7. Machine Learning Automated Workflow: Pipeline](#7.)","fd7be952":"Before performing the PCA transformation, the data must be shaped in accordance with the sklearn model. The images in the matrix form in the dataset must be reshaped to a vector to match the sklearn model.\n\nIn the following, the image matrices are reshaped to a vector.","e9849c40":"[Go to Content Menu](#0.)\n\n <a class a=\"anchor\" id=\"4.\"><\/a>**4. Equalizing Histogram of Images in the Dataset **\n\nPreprocessing has an important place in traditional computer vision approaches. By applying the correct preprocesses to images, the performance of the machine learning model can be improved.\nWhen the figures visualizing the signs above are examined, it can be seen that there is a difference in light in the sign images. Light difference directly affects the performance of machine learning. In order to increase the performance of the model, the difference of light in the images should be as low as possible.\nHistogram equalization increases the contrast in the image by \u201cstretching\u201d the distribution of image pixels. After this process, the light regions are lighter and the darker regions are darker. Before moving on to histogram equalization, it is useful to understand and visualize the histogram in the images.\n\n[Go to Content Menu](#0.)\n\n<a class a=\"anchor\" id=\"4.1.\"><\/a>**4.1. Histogram**\n\nThe image histogram represents the pixel value distribution with boxes (bins). Visualization of histograms with graphs makes it very easy to comment on pixel distributions.\nWhen the histogram is created, the boxes are on the x-axis of the graph and the height of the boxes is seen on the y-axis of the graph according to the number of occurrences. For example, a histogram of the image consisting of values from 0 to 255 is found by counting how many times each value is in the image.\nThe image histogram can be for each value, as well as for the value in a given range. For example, the number of the four-box histogram of the image with the value 0 to 255 [0-63], [64-127], [128-191] and [192-255] how many of the values in the image are counted.\nThe image histogram can be reviewed and commented on the contrast, brightness and value distribution of the image.","d8e01052":"[Go to Content Menu](#0.)\n\n # <a class a=\"anchor\" id=\"3.1.\"><\/a>**3.1. Clf_Helper class**","fdcc00a7":"In the figure above, it can be seen that 100 and more PCA components represent the same data. Now let's make the classification process using 100 PCA components.","b01d97ca":"The target variable y in the dataset is created according to one-hot encoding. Therefore, the dimensions of the target variable are 2062X10. Since sklean machine learning models accept the target variable as a vector, the target variable must be converted to the vector. \n\nConversion of one-hot encoding targets to vector would be as follow:\n\n* [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]= 0 \n* [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]= 1 \n* [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]= 2 \n* [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]= 3 \n* [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]= 4 \n* [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]= 5 \n* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]= 6 \n* [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]= 7 \n* [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]= 8 \n* [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]= 9 ","abc380ed":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"2.\"><\/a> 2. Pricipla Component Anaylsis (PCA)","40fba785":"[Go to Content Menu](#0.)\n\n # <a class a=\"anchor\" id=\"1.3.\"><\/a> **1.3. Visualizing After Correcting**\n \nThe correct labeling will be as in the images in the chart below.","4c06c6ac":"[Go to Content Menu](#0.)\n\n <a class a=\"anchor\" id=\"3.2.\"><\/a>**3.2. Best Classifier Hyperparameter Tunning**","021284ad":"Since the dataset is one part, the training and test parts need to be separated. Below, 70 percent of the dataset is allocated for training and 30 percent for testing. Stratify = y is assigned to ensure that class distributions are balanced","3721fe22":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"2.2.\"><\/a> 2.2. Finding Optimum Number of Principle Component","d84ccea3":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"1.\"><\/a> 1. About the Dataset\n\nThe dataset consists of images with one-handed display of digits 0 to 9 in sign language. The images are 64X64 in size and gray in color. It was obtained by 218 people making 10 different signs once. There should be a total of 2180 samples, while there are 2062 samples in the data set. This is probably because some unfavorable images have been removed by creator of the dataset..","8e79e9c7":"[Go to Content Menu](#0.)\n\n<a class a=\"anchor\" id=\"5.1.\"><\/a>**5.1. Hyperparameter Tunning**","96d2f8cb":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"0.1.\"><\/a> Summary\n\nIn this study, sign language recognition was performed on Sign Language dataset. The steps for sign language recognition are as follows:\n\n* Principal components of sign language images were obtained by PCA.\n* Adequate number of principal components determined\n* Using six different classification models, accuracy scores obtained.\n* Using six different classification models, cross-validation accuracy scores  obtained.\n* Parameter optimization of the best model has been made.","ac7671aa":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"6.\"><\/a>6. Dimension Reduction with Kernel PCA","458d36bc":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"7.\"><\/a>7. Machine Learning Automated Workflow: Pipeline\n\nMachine learning application has a standard workflow. Sklearn offers the Pipeline object to automate this workflow. Pipeline allows standard workflow for performing machine learning operations such as scaling, feature extraction and modeling. The Pipeline guarantees the same operation in the entire dataset, ensuring that the training and test data are consistent.","f05947fa":"[Go to Content Menu](#0.)\n\n # <a class a=\"anchor\" id=\"1.2.\"><\/a> **1.2. Correcting Mistarget Matches**\n \nThe graph above shows the images from 0 to 9 on each line from the top down. There are  mistakes in the labeling of images. The above images do not match the order given in the dataset page. According to the dataset page, the sign of each line above will be as follows: 9, 0, 7, 6, 1, 8, 4, 3, 2, 5.\n\nLet's do the right labeling in the order we've determined.","b7060f6d":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"2.1.\"><\/a> 2.1. PCA Transform","0958638e":"<center><font size='6' color=\"red\">Many thanks for feedbacks and upvote ^______^<\/font><\/center>\n\n","afcedb43":"[Go to Content Menu](#0.)\n\n # <a class a=\"anchor\" id=\"1.1.\"><\/a> **1.1. Visualizing The Dataset**\n\nVisualizing the dataset before applying the machine learning model helps to provide concise information about the structure and content of dataset.\n\nBelow is a visualization of the desired number of samples for each class in the dataset.","2b2e2f0f":"The above figure shows the use of PCA transform for visualizing multidimensional data. The length of the feature vector 4096 has been reduced to 2. Although the reduction rate is very high, the difference between the classes can be seen in the above scatter graph, albeit slightly.\n\nThe length of the feature vector after reduction is obtained according to the number of PCA components. Since the characteristics of the dataset are different from each other, the appropriate number of PCA components is determined according to the dataset to be applied. The determination of the optimum number of Principla Components is described in the next section.","1c5d18e3":"GridSearchCV scores are almost same for normal and histogram equalized images.","0fd65d81":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"5.\"><\/a>5. Finding Best Classifier on Histogram Equalized Images","a7c93ebd":"[Go to Content Menu](#0.)\n\n<a class a=\"anchor\" id=\"4.2.\"><\/a>**4.2.Obtaining Image Histogram**\n\nThe image histogram will be obtained by OpenCV, which has Python bindings, which is implemented by Intel in C \/ C ++. OpenCV is an open source computer vision library that was developed in 1999 to enable real-time image processing. Although it is developed with C \/ C ++, it has adaptations to be used in Python, Java and C # languages.\nWith the OpenCV, the image histogram is calculated with the function **calcHist (images, channels, mask, histSize, ranges)**. The function returns to the histogram of the image or images. The explanation of the parameters of the function is as follows:\n\n**images**: It is the variable that holds the images to calculate the histogram. Even if there is only one image, it should be included in the Python list. For example, [image1] for a single image and [image1, image2, g\u00f6r\u00fcnt\u00fc, imageN] for multiple images.\n\n**channels**: Used to specify the image channels to be calculate the histogram. For gray images [0] is given with [0, 1, 2] for color images.\n\n**mask**: used to determine the desired region of the histogram calculation. If it is applied to the entire image, the value **None** is assigned.\n\n**histSize**: Used to determine the number of boxes to be used when calculating the histogram. It should be given separately for each channel. For the gray and color images to be obtained with 256 boxes, [256], [256, 256, 256] respectively.\n\n**ranges**: Used to determine the range of the image histogram. For images with values \u200b\u200bfrom 0 to 255, they are set to [0, 255] and [0,1] for images with values \u200b\u200bin the range 0 to 1.","2ea60225":"Histogram equalization process lift up cross validation accuracy %1.5. ","05736935":"[Go to Content Menu](#0.)\n\n<a class a=\"anchor\" id=\"4.4.\"><\/a>**4.4. Visualiazing After Histogram Equalization**","76d2008e":"[Go to Content Menu](#0.)\n\n# <a class a=\"anchor\" id=\"3.\"><\/a>3. Finding Best Classifier"}}