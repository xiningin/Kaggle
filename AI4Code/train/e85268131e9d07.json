{"cell_type":{"474eddc7":"code","b5a59c0e":"code","e5d3ecab":"code","0781dc3e":"code","9893f618":"code","188b74a7":"code","3d7edcc9":"code","8f02e0a0":"code","d2e4737c":"code","eda75b0f":"code","24567e57":"code","24af87e8":"code","5b668c89":"code","105217de":"code","299d901f":"code","b5474b59":"code","c393f12d":"code","f1a9da2a":"code","494d63b3":"code","c87188c8":"code","b85e3bf4":"code","2d51d4cd":"code","377b57f1":"code","05a6755d":"code","2c5f5e72":"code","655967ec":"code","caac75e6":"code","8ae57e8e":"code","f4696327":"code","02420054":"code","a9c0c41e":"code","63f03877":"code","057c2b50":"code","7fc35f8b":"code","259f00ec":"code","1ff92e28":"code","7c160e6d":"code","8e292c43":"code","654fc88e":"code","50963d5b":"code","29b05e4d":"code","060e73c7":"code","45c20638":"code","4a0bc0e6":"code","d4e1b271":"code","1049d43b":"code","313ee057":"code","2ae22d59":"markdown","9eae601a":"markdown","56011406":"markdown","2d6ab615":"markdown","3f0cea5c":"markdown","41770535":"markdown","8edb2a32":"markdown","17001188":"markdown","b79c60a4":"markdown","e221a0b3":"markdown","833e36e9":"markdown","0a398763":"markdown","a3f3c13e":"markdown","3af02824":"markdown","f18435fb":"markdown","95718aa1":"markdown","a2f32c67":"markdown","013c6d03":"markdown","aba214bd":"markdown","c6d2e921":"markdown","184b0d44":"markdown","85917d8e":"markdown","09dacfca":"markdown","35806ab2":"markdown","d0775a0c":"markdown","a9281886":"markdown","4d153ae8":"markdown","f9262ba3":"markdown","c7ffa573":"markdown","ff25c18b":"markdown","0546e112":"markdown","e8868fb9":"markdown","25c4c48b":"markdown","355b7bcc":"markdown","fb28da85":"markdown","f9b7e2bd":"markdown","6a78781d":"markdown","d691b2ac":"markdown","cded2b8a":"markdown","f8a142e4":"markdown","e412cf7b":"markdown","5965863d":"markdown","1071856d":"markdown"},"source":{"474eddc7":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix,accuracy_score\nfrom sklearn.utils import shuffle ","b5a59c0e":"import sys\nsys.version","e5d3ecab":"dataframe = glob(\"..\/input\/activity-recognition\/ActivityAccelerometer\/*.csv\")","0781dc3e":"#Dataset is loaded and merged, a new column named User_ID which gives the ID of the User after data is merged.\n\ndef load_data(dataframe):\n    dataset = pd.DataFrame()\n    for index,filename in enumerate(dataframe):\n        df = pd.read_csv(filename, header=None)\n        df['User_ID'] = index + 1\n        dataset = dataset.append(df.iloc[:,1:])\n    return dataset\n\ndata = load_data(dataframe)\n\n#Names are given for the columns\ndata.columns = ['x_acceleration','y_acceleration','z_acceleration','Label','User_ID']\n\ndata.head()","9893f618":"#The minimum and the maximum values of each column is checked for Sanity Check\nfor i in data.columns:\n    print(\"Maximum value of\",i ,\"is\",data[i].max())\n    print(\"Minimum value of\",i ,\"is\",data[i].min())  ","188b74a7":"#User_id represents that there are 15 users\ndata['User_ID'].value_counts()","3d7edcc9":"print(data.shape)\nprint(data.dtypes)","8f02e0a0":"#No missing values\ndata.isnull().sum()","d2e4737c":"data.describe()","eda75b0f":"for i in data.columns:\n    data[i].value_counts()","24567e57":"data.info()","24af87e8":"data['Label']=data['Label'].replace(0, np.nan)\ndata.dropna(subset = [\"Label\"], inplace=True)\ndata['Label'] = data['Label'].astype(int)\nprint(data['Label'].value_counts())\nprint(data['Label'].unique())","5b668c89":"plt.figure(figsize=(9,5))\nsns.set(font_scale=1.2)\nsns.heatmap(data.corr(), annot=True, annot_kws={\"size\":16})\nplt.show()","105217de":"plt.figure(figsize=[16,6])\nsns.set_style('whitegrid') \nsns.distplot(data['x_acceleration'],kde=False, color ='blue') \nplt.title('Acceleration in the x-axis',fontsize=20)\nplt.show()","299d901f":"plt.figure(figsize=[16,6])\nsns.set_style('whitegrid') \nsns.distplot(data['y_acceleration'],kde=False, color ='red') \nplt.title('Acceleration in the y-axis',fontsize=20)\nplt.show()","b5474b59":"plt.figure(figsize=[16,6])\nsns.set_style('whitegrid') \nsns.distplot(data['z_acceleration'],kde=False, color ='green') \nplt.title('Acceleration in the z-axis',fontsize=20)\nplt.show()","c393f12d":"plt.figure(figsize=[7,7])\nValues_Label= data['Label'].value_counts()\nplt.pie(Values_Label.values, labels=Values_Label.keys(), autopct='%0.2f')\nplt.title('Label for each of the tasks',fontsize=20)\nplt.show()","f1a9da2a":"plt.figure(figsize=[15,5])\nsns.set(style=\"darkgrid\")\nplt.title('User ID',fontsize=25)\nax = sns.countplot(x=\"User_ID\", data=data)\nplt.xlabel(\"User_ID\", fontsize=20)\nplt.ylabel(\"Count\", fontsize=20)\nplt.show()","494d63b3":"data.groupby(['User_ID','Label']).size().unstack().plot(kind='bar',stacked=True, figsize=[15,7])\nplt.title('Time spent on individual Tasks',fontsize=18)\nplt.xlabel('User ID',fontsize=15)\nplt.ylabel('Count of the Labels',fontsize=15)\nplt.show()","c87188c8":"Label_6 = data[(data['Label']==2) | (data['Label']==5 ) | (data['Label']==6)]","b85e3bf4":"Label_6.groupby(['User_ID','Label']).size().unstack().plot(kind='bar', figsize=[15,7])\nplt.title('Time spent on Tasks 2,5,6',fontsize=18)\nplt.xlabel('User ID',fontsize=15)\nplt.xticks(rotation=0)\nplt.ylabel('Count of the Labels',fontsize=15)\nplt.show()","2d51d4cd":"sns.regplot(x=data[\"x_acceleration\"], y=data[\"z_acceleration\"], fit_reg=False)\nplt.title('Relationship Acceleration in x-axis and z-axis',fontsize=18)\nplt.xlabel('X acceleration',fontsize=15)\nplt.ylabel('Z acceleration',fontsize=15)\nplt.show()","377b57f1":"sns.regplot(x=data[\"x_acceleration\"], y=data[\"y_acceleration\"], fit_reg=False)\nplt.title('Relationship Acceleration in x-axis and y-axis',fontsize=18)\nplt.xlabel('X acceleration',fontsize=15)\nplt.ylabel('Y acceleration',fontsize=15)\nplt.show()","05a6755d":"sns.regplot(x=data[\"y_acceleration\"], y=data[\"z_acceleration\"], fit_reg=False)\nplt.title('Relationship Acceleration in y-axis and z-axis',fontsize=18)\nplt.xlabel('Y acceleration',fontsize=15)\nplt.ylabel('Z acceleration',fontsize=15)\nplt.show()","2c5f5e72":"minimum_x_axis={}\nmaximum_x_axis={}\n\nfor i in data.Label.unique():\n    maximum_x_axis[i]=(data[(data['Label']==i)]['x_acceleration'].max())\n    minimum_x_axis[i]=(data[(data['Label']==i)]['x_acceleration'].min())\n\n\nX = np.arange(len(minimum_x_axis))\nfig, ax = plt.subplots(figsize=(12,6))\n                     \nax.bar(X, minimum_x_axis.values(), width=0.4, color='#008B8B', align='center', label='minimum')\nax.bar(X-0.4, maximum_x_axis.values(), width=0.4, color='#48c9b0', align='center',label='maximum')\n\nax.legend()\nplt.xticks(X, ['1','2','3','4','5','6','7'])\nplt.xlabel(\"Labels\",fontsize=15)\nplt.ylabel(\"Value of acceleration\",fontsize=15)\nplt.title(\"Minimum and Maximum values of acceleration in X-axis for each Label\", fontsize=17)\nplt.show()\n","655967ec":"minimum_y_axis={}\nmaximum_y_axis={}\n\nfor i in data.Label.unique():\n    maximum_y_axis[i]=(data[(data['Label']==i)]['y_acceleration'].max())\n    minimum_y_axis[i]=(data[(data['Label']==i)]['y_acceleration'].min())\n\n\nX = np.arange(len(minimum_y_axis))\nfig, ax = plt.subplots(figsize=(12,6))\n                     \nax.bar(X, minimum_y_axis.values(), width=0.4, color='#008B8B', align='center', label='minimum')\nax.bar(X-0.4, maximum_y_axis.values(), width=0.4, color='#48c9b0', align='center',label='maximum')\n\nax.legend()\nplt.xticks(X, ['1','2','3','4','5','6','7'])\nplt.xlabel(\"Labels\",fontsize=15)\nplt.ylabel(\"Value of acceleration\",fontsize=15)\nplt.title(\"Minimum and Maximum values of acceleration in Y-axis for each Label\", fontsize=17)\nplt.show()\n ","caac75e6":"minimum_z_axis={}\nmaximum_z_axis={}\n\nfor i in data.Label.unique():\n    maximum_z_axis[i]=(data[(data['Label']==i)]['z_acceleration'].max())\n    minimum_z_axis[i]=(data[(data['Label']==i)]['z_acceleration'].min())\n\n\nX = np.arange(len(minimum_z_axis))\nfig, ax = plt.subplots(figsize=(12,6))\n                     \nax.bar(X, minimum_z_axis.values(), width=0.4, color='#008B8B', align='center', label='minimum')\nax.bar(X-0.4, maximum_z_axis.values(), width=0.4, color='#48c9b0', align='center',label='maximum')\n\nax.legend()\nplt.xticks(X, ['1','2','3','4','5','6','7'])\nplt.xlabel(\"Labels\",fontsize=15)\nplt.ylabel(\"Value of acceleration\",fontsize=15)\nplt.title(\"Minimum and Maximum values of acceleration in Z-axis for each Label\", fontsize=17)\nplt.show()\n ","8ae57e8e":"def User_plot(User):\n    plt.figure()\n    for i in range(User.shape[1]):\n        plt.figure(figsize=(14,6))\n        plt.subplot(User.shape[1],1,i+1)\n        plt.plot(User[:,i],color='#008B8B')\n        plt.show()\n        ","f4696327":"for i in data.User_ID.unique():\n    print('User_ID',i)\n    print('The acceleration in x,y,z axis and the Labels')\n    User_plot(data[data.User_ID==i].iloc[:,:4].values)\n    print('End of',i,'plot\\n')","02420054":"new_data=[]\nfor k,values in data.groupby('User_ID'):\n    new_data.append(values.iloc[:,:4].values)\n\ndef activity_group(new_data,Labels):\n    activity_groups=[{label:new[new[:,-1]==label] for label in Labels} for new in new_data]\n    return activity_groups\n\ndef duration(activity_groups,Labels):\n    frequency=52\n    time_range = [[len(new[act])\/frequency for new in activity_groups] for act in Labels]\n    return time_range\n\ndef durations_plot(activity_groups,Labels):\n    time_range = duration(activity_groups,Labels)\n    plt.boxplot(time_range, labels=Labels)\n    plt.title(\"Tasks grouped by their duration\",fontsize=17 )\n    plt.xlabel(\"Labels\",fontsize=15)\n    plt.ylabel(\"Duration of the Task\",fontsize=15)\n    plt.show()\n    \nLabels=[label for label in range(1,8)]\nactivity_groups=activity_group(new_data,Labels)\ndurations_plot(activity_groups,Labels)\n\n\n","a9c0c41e":"X = data[['x_acceleration', 'y_acceleration', 'z_acceleration','User_ID']]\ny = data['Label']","63f03877":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\ndecision_tree_model = DecisionTreeClassifier(random_state=0)\nclf = decision_tree_model.fit(X_train, y_train)\ndecision_pred = decision_tree_model.predict(X_test)\n\nprint(\"Accuracy score using Decision tree is\",accuracy_score(y_test, decision_pred))","057c2b50":"data_col = []\ncurrent_Mscore = 0.0\nNum_columns = 4\nshuf_columns = shuffle(range(0,Num_columns), random_state=1)\nls=['x_acceleration', 'y_acceleration', 'z_acceleration','User_ID']\n\n\nfor cols in range(0, Num_columns): \n    data_col.append(ls[shuf_columns[cols]])\n    print(data_col)\n    \n    newData = data[data_col]\n    X_Train, X_Test, Y_Train, Y_Test = train_test_split(newData, data['Label'], test_size=0.30, random_state=0)\n    dtree_classifier = DecisionTreeClassifier()\n\n    fit = dtree_classifier.fit(X_Train, Y_Train)\n    new_Score = dtree_classifier.score(X_Test, Y_Test)\n    \n    if new_Score < current_Mscore:\n        data_col.remove(shuf_columns[cols])\n    else:\n        current_Mscore = new_Score\n        print(\"Score with \" + str(len(data_col)) + \" selected features: \" + str(new_Score))\n\nprint(\"There are \" + str(len(data_col)) + \" features selected:\", data_col)","7fc35f8b":"# Accuracy is put into a list to plot a graph for comparison\ntest_accuracy = decision_tree_model.score(X_test, y_test)\ntrain_accuracy = decision_tree_model.score(X_train, y_train)\n\ndecision_score=[test_accuracy,train_accuracy]","259f00ec":"cv = confusion_matrix(y_test, decision_pred)\nprint(\"Confusion matrix\\n\",cv)","1ff92e28":"decision_cr = classification_report(y_test,decision_pred)\nprint(\"Classification report\\n\",decision_cr)","7c160e6d":"target_names=[1,2,3,4,5,6,7]\n#The values are normalised in order to plot the confusion matrix\ndecision_tree_cm = cv.astype('float') \/ cv.sum(axis=1)[:, np.newaxis]\n\n#Confusion matrix is plotted for the normalised values obtained with the Labels\ndtree_cm = pd.DataFrame(decision_tree_cm, columns=np.unique(target_names), index = np.unique(target_names))\ndtree_cm.index.name = 'Actual values'\ndtree_cm.columns.name = 'Predicted values'\n\nplt.figure(figsize = (7,5))\nsns.set(font_scale=1.4)\nsns.heatmap(dtree_cm, cmap=\"Blues\",linewidth=0.5, annot=True,annot_kws={\"size\":13})\nplt.show()","8e292c43":"non_optimal=[]\n\nfor optimal_k in range(1,20):\n    KNN = KNeighborsClassifier(n_neighbors=optimal_k)\n    KNN.fit(X_train,y_train)\n    pred_optimal_k = KNN.predict(X_test)\n    non_optimal.append(np.mean(pred_optimal_k != y_test))\n    \nplt.figure(figsize=(10,6))\nplt.plot(range(1,20), non_optimal, '-ok')\nplt.title('To find Optimal K value')\nplt.xlabel('K')\nplt.ylabel('Error')\nplt.show()","654fc88e":"KNN_classifier = KNeighborsClassifier(8, weights='distance')\nKNN_classifier.fit(X_train, y_train)\ny_pred = KNN_classifier.predict(X_test)\n\nprint(\"Accuracy score using KNN Classifier is: {}\".format(accuracy_score(y_test, y_pred)))","50963d5b":"data_cols = []\ncurrent_MScore = 0.0\nnumber_cols = 4\nshuffle_data_cols = shuffle(range(0,number_cols), random_state=1)\nls = ['x_acceleration', 'y_acceleration', 'z_acceleration','User_ID']\n\n\nfor cols in range(0, number_cols): \n    data_cols.append(ls[shuffle_data_cols[cols]])\n    newData = data[data_cols]\n    X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(newData, data['Label'], test_size=0.30, random_state=0)\n    \n    KNN_classifier = KNeighborsClassifier(8, weights='distance')\n    fit = KNN_classifier.fit(X_TRAIN, Y_TRAIN)\n    present_Score = KNN_classifier.score(X_TEST, Y_TEST)\n    \n    if present_Score < current_MScore:\n        data_cols.remove(shuffle_data_cols[cols])\n    else:\n        current_MScore = present_Score\n        print(\"Score with \" + str(len(data_cols)) + \" selected features: \" + str(present_Score))\n\nprint(\"There are \" + str(len(data_cols)) + \" features selected:\", data_cols)","29b05e4d":"KNN_classifier = KNeighborsClassifier(8, weights='distance', p=1)\nKNN_classifier.fit(X_train, y_train)\ny_pred = KNN_classifier.predict(X_test)\n\nprint(\"Accuracy score using KNN Classifier after parameter tuning is\",accuracy_score(y_test, y_pred))","060e73c7":"KNN_classifier_param = KNeighborsClassifier(8, weights='distance', p=1)\nKNN_classifier_param.fit(X_train, y_train)\ny_pred = KNN_classifier_param.predict(X_test)\n\nprint(\"Accuracy score using KNN Classifier is: {}\".format(accuracy_score(y_test, y_pred)))","45c20638":"test_accuracy = KNN_classifier_param.score(X_test, y_test)\ntrain_accuracy = KNN_classifier_param.score(X_train, y_train)\n\nKNN_score=[test_accuracy,train_accuracy]","4a0bc0e6":"k_confusion_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion matrix is\\n\",k_confusion_matrix)","d4e1b271":"target_names=[1,2,3,4,5,6,7]\n#The values are normalised in order to plot the confusion matrix\nconf_matrix = k_confusion_matrix.astype('float') \/ k_confusion_matrix.sum(axis=1)[:, np.newaxis]\n\n#Confusion matrix is plotted for the normalised values obtained with the Labels\ndf_cm_k = pd.DataFrame(conf_matrix, columns=np.unique(target_names), index = np.unique(target_names))\ndf_cm_k.index.name = 'Actual values'\ndf_cm_k.columns.name = 'Predicted values'\n\nplt.figure(figsize = (7,5))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm_k, cmap=\"Greens\", annot=True,annot_kws={\"size\": 13})\nplt.show()","1049d43b":"knn_cr=classification_report(y_test, y_pred)\nprint(\"Classification report\\n\",knn_cr)","313ee057":"ind = np.arange(2) \nwidth = 0.35\nplt.figure(figsize=(10,6))\nplt.bar(ind, decision_score, width, label='decision_score')\nplt.bar(ind + width, KNN_score, width, label='KNN_score')\n\nplt.ylabel('Accuracy')\nplt.title('Comparison of Accuracy ')\n\nplt.xticks(ind + width \/ 2, ('Test_data', 'Train_data'))\nplt.legend(loc='best')\nplt.show()","2ae22d59":"**Goal:** The activities are predicted based the movements traced by the accelerometer for 15 users. Every participant wore a custom-developed chest mounted uncaliberated acceleraometer and the data was collected at 52 observations per second. The 7 activities in the Label column of the data is explored against the acceleration in x,y, and z-axis.","9eae601a":"Conclusion:\n    Most of the x_accelearation lies in between 1500 and 2500.\n    The maximum value of z_acceleration is aprroximately equal to 800000.","56011406":"Conclusion:\n1.     Most of the x_accelearation lies in between 2000 and 3000.\n2.     The maximum value of y_acceleration is above 800000","2d6ab615":"The Hill Climbing Technique gives the same accuracy as all the 4 features were selected previously.","3f0cea5c":"Conclusion:\n1.     Maximum amount of data is available from the Users 2,3,5,14 which is around 160000 data entries.\n2.     Minimum amount of data is available from the User 12.\n\n","41770535":"#### Conclusion: The Tasks other than the first one has the values of maximum and minimum values in the same range, The Task1 has extreme values.\n\n#### Hypothesis 8: The values of acceleration in the z-axis is plotted against the Labels, to determine the dependency.\n","8edb2a32":"# Comparison between Decision tree and KNN Classifier","17001188":"Conclusion:\n    Most of the x_accelearation lies in between 1500 and 2500.\n    The maximum value of x_acceleration is above 400000","b79c60a4":"#### Conclusion: No relationship can be plotted between the acceleration in x-axis and z-axis, Hence the hypothesis 3 is True.\n\n#### Hypothesis 4: Relationship between the acceleration in the x-axis and y-axis is minimum. As the correlation is found to be 0.363657 between the two columns\n","e221a0b3":"Heatmap to identify the corelation between the columns\n","833e36e9":"The accuracy has been increased by 0.004. Hence, the parameter tuning effect is taken into consideration.","0a398763":"Parameter tuning effect","a3f3c13e":"#### Conclusion: Task 6 is not the least performed action when it viewed individually. Hence, the hypothesis 2 is False\n\n#### Hypothesis 3: Relationship between the acceleration in the x-axis and z-axis is almost null. As the correlation is found to be 0.009827 between the two columns.\n","3af02824":"# Task 1: Retrieving and Preparing the Data","f18435fb":"## 3.1 Decision Tree","95718aa1":"#### Conclusion: A positive mild upward linear relationship is detected between the two columns. Hence the hypothesis 4 is True\n\n#### Hypothesis 5: Relationship between the acceleration in the y-axis and z-axis is minimum and is similar to the relationship between the acceleration in the x-axis and y-axis. As the correlation is found to be 0.345655 between the two columns which is similar to the correlation between the x_acceleration and y_acceleration column.\n","a2f32c67":"\n1.     Accuracy of Decision tree is 73.15% and KNN Classifier is 76.45% on the Test data, and the accuracy is same for the train data.\n2.     Accuracy from the KNN Classifier is slightly higher than that of Decision tree.\n3.     The computational complexity for KNN is comparatively more for the Decision tree on the dataset.\n4.     The precision score for Decision tree is 0.52 and KNN classifier is 0.59.\n\n### Recommendation: K-Nearest Neighbours is a better classifier on the Accelerometer dataset\n","013c6d03":"Conclusion:\n1.     People have spent most of the time on task 1 i.e. Working at Computer and the least time on task 6 i.e. Walking and Talking with Someone.\n2.     Task 2,6,5 are the least performed actions. which is around 2.5%\n3.     Task 1,7 are the most performed actions, which is around 30%.","aba214bd":"## **2.1 Explore each column**","c6d2e921":"## End","184b0d44":"#### Hill Climbing method to determine the parameters for the Decision tree","85917d8e":"### 2.1.1. x_acceleration","09dacfca":"#### Conclusion: Users 2,3,5,14 have spent more time on Task 7 than on Task 1, the stated Hypothesis 1 is false.\n\n#### Hypothesis 2: Time spent on Task 6 (Walking and Talking with Someone) by the individuals is minimum. Tasks 2,5,6 have the approximately a smaller number of observations on the whole data but task 6 has the least\n","35806ab2":"From the elbow method the value of K is choosen, The accuracy remains the same for the value of K from range (8 to 20), hence 8 is choosen as the optimal value.","d0775a0c":"### 2.1.2. y_acceleration","a9281886":"#### Conclusion: The maximum and minimum values for all tasks have different values and task 1 has the extreme value in both maximum and minimum values.\n\n#### Hypothesis 9: The labelling of the tasks is more dependent on the x_acceleration than on the y and z axis acceleration.As, the correlation of x-axis with Label is the highest.\n","4d153ae8":"The label values with 0 are deleted,but this was deleting the values in other labels too and the data shape chaged with a difference of 10000 values. Hence, Label 0 was replaced with NaN values and then dropped.","f9262ba3":"#### Conclusion: After grouping the activities for the individuals it can be seen that Task 5 is the least performed Task. Hence hypothesis 10 is False.","c7ffa573":"#### End of KNN Classifier","ff25c18b":"#### Hypothesis 1: Time spent by each individual on task 1 (Working on Computer) is the maximum. As the Task 1 is being seen 608667 times in the data, and it is the highest.","0546e112":"#### Conclusion: A mild positive relationship is found between the two columns, but there are more outliers. Hence the hypothesis 5 is True.\n\n#### Hypothesis 6: The maximum value of acceleration is for Task 1 in X-axis. Because, the Maximum value of acceleration in the X-axis is found to 3828 and Task 1 has most values(608667).\n","e8868fb9":"## 3.2 K - Nearest Neighbours Classifier","25c4c48b":"#### Elbow Method to determine the optimal value of K","355b7bcc":"# Task 2: Data Exploration","fb28da85":"### 2.1.3. z_acceleration","f9b7e2bd":"# Task 3: Data Modelling","6a78781d":"### 2.1.5 User_ID","d691b2ac":"## 2.2 Explore the relationship between the pairs of Columns with plausible hypothesis","cded2b8a":"#### Conclusion: The labels are dependent on all x,y,z axis acceleration.Hence, the hypothesis 9 is False\n\n#### Hypothesis 10: Time spent on Task 6 on a whole is the minimum. As the individual evaluation of the graph predicted that the Task 6 is least performed.\n","f8a142e4":"Hill Climbing Technique to select the Features for KNN classifier","e412cf7b":"### 2.1.4. Label","5965863d":"#### Conclusion: From the graph the hypothesis is True, as the maximum and minimum values are for Task 1\n\n#### Hypothesis 7: The values of acceleration in the y-axis is plotted against the Labels, to determine the dependency.\n","1071856d":"### End of Decision Tree"}}