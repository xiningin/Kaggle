{"cell_type":{"ae2a04c8":"code","8efc7127":"code","30aa822d":"code","c1aff81c":"code","c913cfd0":"code","df0a12a3":"code","81db45b7":"code","79edabb8":"code","18c69eee":"code","a9e2a0da":"code","a741aa7e":"code","5c2d7acd":"code","5f355151":"markdown","5db64813":"markdown"},"source":{"ae2a04c8":"import matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nfrom sklearn.utils import shuffle\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, Flatten, Conv2D\nfrom keras.layers import MaxPooling2D, Dropout\nfrom sklearn.model_selection import KFold\nfrom keras.models import Model\nfrom PIL import Image\nimport cv2\nimport IPython\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\n","8efc7127":"print(os.listdir('..\/input'))","30aa822d":"from PIL import Image\nX_train=[]\nX_test=[]\ntrain=[]\ntest=[]\nsize=50\nfor root, dirs, files in os.walk(\"..\/input\/fruits-360_dataset\/fruits-360\/Training\"):\n    for name in dirs:\n        for filename in os.listdir(os.path.join(root, name)):\n            image=Image.open( os.path.join(root, name) + \"\/\"+filename)\n            img_resized = np.array(image.resize((size,size)))\n            X_train.append(img_resized)\n            train.append(name)\n            \nfor root, dirs, files in os.walk(\"..\/input\/fruits-360_dataset\/fruits-360\/Test\"):\n    for name in dirs:\n        for filename in os.listdir(os.path.join(root, name)):\n            image=Image.open( os.path.join(root, name) + \"\/\"+filename)\n            img_resized = np.array(image.resize((size,size)))\n            X_test.append(np.array(img_resized))\n            test.append(name)\n            \nX_train=np.array(X_train)\nX_test=np.array(X_test)","c1aff81c":"X_train,train=shuffle(X_train,train,random_state=44)\nX_test,test=shuffle(X_test,test,random_state=44)","c913cfd0":"test=np.array(test)\ntrain=np.array(train)\nfrom sklearn.preprocessing import OneHotEncoder\nhot = OneHotEncoder()\ny_train=train.reshape(len(train), 1)\ny_train = hot.fit_transform(y_train).toarray()\ny_test=test.reshape(len(test), 1)\ny_test = hot.transform(y_test).toarray()\n","df0a12a3":"X_train=X_train\/255","81db45b7":"size=X_train.shape[1]\ncvscores = []\nmodel = Sequential()\nmodel.add(ZeroPadding2D(2, input_shape=(size, size, 3)))\nmodel.add(Conv2D(32, (7, 7),strides=(1, 1),padding=\"valid\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3),strides=(1, 1),padding=\"valid\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3,3),strides=(1, 1),padding=\"valid\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(256, (1,1),strides=(1, 1),padding=\"valid\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(114, activation=\"softmax\")) \nrmsprop = optimizers.RMSprop(lr=0.0001, decay=1e-6)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train,batch_size = 1024, epochs=30,verbose=0 )\n","79edabb8":"scores = model.evaluate(X_test, y_test, verbose=1)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\ncvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))  ","18c69eee":"for k in range(10):\n    i=np.random.randint(len(test))\n    plt.imshow(X_test[i,:,:,:])\n    plt.show()\n    cc=model.predict(X_test[i:i+1,:,:,:])\n    cc=hot.inverse_transform(cc)\n    print(\"prediction: \",cc)\n    print(\"Reference       :\",test[i])","a9e2a0da":"size=X_train.shape[1]\ncvscores = []\nmodel = Sequential()\nmodel.add(ZeroPadding2D(2, input_shape=(size, size, 3)))\nmodel.add(Conv2D(32, (7, 7),strides=(1, 1),padding=\"valid\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3),strides=(1, 1),padding=\"valid\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nfrom keras import optimizers\nmodel.add(Dense(114, activation=\"softmax\")) \nrmsprop = optimizers.RMSprop(lr=0.0001, decay=1e-6)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train,batch_size = 1024, epochs=30,verbose=0 )","a741aa7e":"scores = model.evaluate(X_test, y_test, verbose=1)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\ncvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))  ","5c2d7acd":"for k in range(10):\n    i=np.random.randint(len(test))\n    plt.imshow(X_test[i,:,:,:])\n    plt.show()\n    cc=model.predict(X_test[i:i+1,:,:,:])\n    cc=hot.inverse_transform(cc)\n    print(\"prediction: \",cc)\n    print(\"Reference       :\",test[i])","5f355151":"The model is still behaving well with accuracy level of 95% even with two convolutional layers!","5db64813":"\nThe model has excellent performance even with this low image quality. This should not be surprising as there are no complexities or too fine details in fruit figures. The model is able to recognize the image based on the shape edges and basic features with simply one or two convolutional layers. This can be easily verified by reducing the number of convolutional layers to two and rechecking accuracy of the model"}}