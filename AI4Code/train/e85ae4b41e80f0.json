{"cell_type":{"8ccebe00":"code","0fd05c33":"code","a31b943b":"code","d67741b5":"code","ba8234fe":"code","cc329d63":"code","c1df0e58":"code","6cc8b786":"code","d6351437":"code","000daea9":"code","d733a4f0":"code","10821435":"code","6f89f509":"code","c30adc53":"code","a48b97d3":"code","b5ca9b2c":"code","ad3855a0":"code","9f396899":"code","3fa5f8cd":"code","b1afbcb3":"code","80e28a2e":"code","4af1f0be":"code","9a2a7868":"code","fb122008":"code","d0309982":"code","49034455":"code","de6f6838":"code","661a6358":"code","ddafd765":"code","e4a70ca9":"code","385bd117":"code","2be9403f":"code","f751368e":"code","4ff1f2d6":"code","b44376fd":"code","cddf6030":"code","8df6ca0c":"code","c9cf4d8c":"code","a29187c7":"code","fd17d9b0":"code","2e283c50":"code","6fc61935":"code","aecd892a":"code","b45f3bb8":"code","c86f9c7e":"code","b41edb69":"code","129eaddf":"code","365d0d9c":"code","0b2e3320":"code","ec74e222":"code","ed422b3f":"code","b08c954c":"code","04922a64":"code","1df3fb60":"code","58315ca5":"code","06fc460f":"code","c3848955":"code","4d2c4ed4":"code","ac5abd30":"code","23d3cef5":"code","1d1b8ef2":"code","252b15b7":"code","c8351849":"code","a4df8a5c":"code","27e84bbd":"code","8a41d353":"code","5ae06f49":"code","8ce29bdb":"code","ab060e79":"code","8c8b3a52":"code","90b0058a":"code","a9cf96ac":"code","9b7bef0a":"code","194a53f7":"code","ecb2dc22":"code","9d75c62c":"code","197c13ae":"code","889001c1":"code","c677b360":"code","c851dfd5":"code","10e6e06d":"markdown","e818e5b7":"markdown","51291e95":"markdown","c96d660a":"markdown","98aac7eb":"markdown","b6fd041e":"markdown","b685fc63":"markdown","89fc66e5":"markdown","a7b90757":"markdown","11df4f44":"markdown","068e76a8":"markdown","47577cfd":"markdown","7e1d9cfc":"markdown","96a8d38a":"markdown","41fbac2a":"markdown","d9ea2e35":"markdown","49a23504":"markdown","2236978b":"markdown","b5ed6d01":"markdown","911713e6":"markdown","059b1dcb":"markdown","b999396a":"markdown","9eb94ac9":"markdown","63d65fab":"markdown","a755d182":"markdown","77bbaca9":"markdown","4cb04e96":"markdown","bb4fd439":"markdown","2ef8c712":"markdown","09327915":"markdown","a5d3442a":"markdown","3c111af1":"markdown","c1f89d84":"markdown","94247222":"markdown","cab2d282":"markdown","963ddd1c":"markdown","258ad7e2":"markdown","fd0e3262":"markdown"},"source":{"8ccebe00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.simplefilter(action = 'ignore')\n\n# Standardization\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\n# Train-Test split\nfrom sklearn.model_selection import train_test_split \n\n# Importing classification report and confusion matrix from sklearn metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Importing the PCA module\nfrom sklearn.decomposition import PCA\n\n# Importing random forest classifier from sklearn library\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Importing Ridge, Lasso and GridSearch\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\n\n# Importing XGBoost libraries\nfrom sklearn.ensemble import AdaBoostClassifier\n\nimport gc # for deleting unused variables\n\n# Importing the below library and configuring to display all columns in a dataframe\nfrom IPython.display import display\npd.options.display.max_columns = None\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","0fd05c33":"training_df = pd.read_csv('\/kaggle\/input\/widsdatathon2020\/training_v2.csv')\ntraining_df.head()","a31b943b":"test_df = pd.read_csv('\/kaggle\/input\/widsdatathon2020\/unlabeled.csv')\ndf_unlabel = test_df.copy()\ntest_df.head()","d67741b5":"print(training_df.shape)\nprint(test_df.shape)","ba8234fe":"train_len = len(training_df)","cc329d63":"training_df = pd.concat(objs = [training_df,test_df], axis = 0)\ntraining_df.shape","c1df0e58":"training_df.info(verbose = True)","6cc8b786":"training_df.isnull().sum()","d6351437":"# percentage of missing values in columns greater than 50%\nnull_cols = training_df.columns[round(training_df.isnull().sum()\/len(training_df.index)*100,2) > 50].tolist()\nnull_cols","000daea9":"# deleting cols having missing %age greater than 50%\nprint(training_df.shape)\ntraining_df = training_df.drop(null_cols,axis = 1)\nprint(training_df.shape)","d733a4f0":"# numeric columns\ndf_numeric = training_df.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\ndf_numeric.head() ","10821435":"# missing values in columns\nnum_null_cols = df_numeric.columns[df_numeric.isnull().any()].tolist()\nprint(num_null_cols)\nprint(len(num_null_cols))","6f89f509":"# dividing the null columns in 5 part \nnum_null_cols_1 = num_null_cols[:19]\nnum_null_cols_2 = num_null_cols[19:38]\nnum_null_cols_3 = num_null_cols[38:57]\nnum_null_cols_4 = num_null_cols[57:76]\nnum_null_cols_5 = num_null_cols[76:]","c30adc53":"# Visualizing first part of num_null_cols which is num_null_cols_1 using box_plot\nplt.figure(figsize=(15,15))\nsns.boxplot(x=\"value\", y=\"variable\", data=pd.melt(df_numeric[num_null_cols_1]))\nplt.show()","a48b97d3":"# Visualizing first part of num_null_cols which is num_null_cols_2 using box_plot\nplt.figure(figsize=(15,15))\nsns.boxplot(x=\"value\", y=\"variable\", data=pd.melt(df_numeric[num_null_cols_2]))\nplt.show()","b5ca9b2c":"# Visualizing first part of num_null_cols which is num_null_cols_3 using box_plot\nplt.figure(figsize=(15,15))\nsns.boxplot(x=\"value\", y=\"variable\", data=pd.melt(df_numeric[num_null_cols_3]))\nplt.show()","ad3855a0":"# Visualizing first part of num_null_cols which is num_null_cols_4 using box_plot\nplt.figure(figsize=(15,15))\nsns.boxplot(x=\"value\", y=\"variable\", data=pd.melt(df_numeric[num_null_cols_4]))\nplt.show()","9f396899":"# Visualizing first part of num_null_cols which is num_null_cols_5 using box_plot\nplt.figure(figsize=(15,15))\nsns.boxplot(x=\"value\", y=\"variable\", data=pd.melt(df_numeric[num_null_cols_5]))\nplt.show()","3fa5f8cd":"# imputing missing values\ndf_numeric = df_numeric.fillna(df_numeric.median())\nprint(df_numeric.isnull().sum())","b1afbcb3":"# non numeric columns\ndf_non_numeric = training_df.select_dtypes(exclude=['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\nprint(df_non_numeric.head())","80e28a2e":"# percentage of missing values\nround(df_non_numeric.isnull().sum()\/len(training_df.index)*100,2)","4af1f0be":"# Visualizing them using countplot\nplt.figure(figsize=(10,15))\nplt.subplot(4,1,1)\nsns.countplot(y = 'ethnicity',data= df_non_numeric)\nplt.subplot(4,1,2)\nsns.countplot(y = 'gender',data= df_non_numeric)\nplt.subplot(4,1,3)\nsns.countplot(y = 'hospital_admit_source',data= df_non_numeric)\nplt.subplot(4,1,4)\nsns.countplot(y = 'icu_admit_source',data= df_non_numeric)\nplt.show()","9a2a7868":"# Visualizing them using countplot\nplt.figure(figsize=(10,15))\nplt.subplot(4,1,1)\nsns.countplot(y = 'icu_stay_type',data= df_non_numeric)\nplt.subplot(4,1,2)\nsns.countplot(y = 'icu_type',data= df_non_numeric)\nplt.subplot(4,1,3)\nsns.countplot(y = 'apache_3j_bodysystem',data= df_non_numeric)\nplt.subplot(4,1,4)\nsns.countplot(y = 'apache_2_bodysystem',data= df_non_numeric)\nplt.show()","fb122008":"for column in df_non_numeric.columns:\n    df_non_numeric[column].fillna(df_non_numeric[column].mode()[0], inplace = True)","d0309982":"df_non_numeric.isnull().sum()","49034455":"# merging df_numeric and df_non_numeric on their index\ndf_train = pd.concat([df_numeric, df_non_numeric], axis=1)\ndf_train.head()","de6f6838":"df_train.shape","661a6358":"# checking outliers\ndf_train.describe(percentiles=[.25,.5,.75,.90,.95,.99])","ddafd765":"df_train['hospital_death'].value_counts().plot('bar')\nplt.show()","e4a70ca9":"df_train['hospital_death'].sum()\/len(df_train['hospital_death'].index)*100","385bd117":"# get correlation of 'hospital_death' with other variables\nplt.figure(figsize=(30,9))\ndf_train.corr()['hospital_death'].sort_values(ascending = False).plot('bar')\nplt.show()","2be9403f":"df_train.head()","f751368e":"df_train.shape","4ff1f2d6":"df_train = df_train.drop(['encounter_id','patient_id'], axis = 1)\ndf_train.columns","b44376fd":"import copy\ntrain = copy.copy(df_train[:train_len])\ntest = copy.copy(df_train[train_len:])\nprint('train             ', train.shape)\nprint('test              ', test.shape)","cddf6030":"X = train.drop('hospital_death',1)\nX.head()","8df6ca0c":"X.shape","c9cf4d8c":"y = train['hospital_death']\ny.head()","a29187c7":"test = test.drop('hospital_death', axis = 1)\ntest.shape","fd17d9b0":"X.info(verbose=True)","2e283c50":"X.shape","6fc61935":"test.shape","aecd892a":"X_len = len(X)","b45f3bb8":"combined_df = pd.concat(objs = [X,test], axis = 0)\ncombined_df.shape","c86f9c7e":"combined_df[['elective_surgery','readmission_status','apache_post_operative','arf_apache','gcs_unable_apache','intubated_apache','ventilated_apache','aids','cirrhosis','diabetes_mellitus','hepatic_failure','immunosuppression','leukemia','lymphoma','solid_tumor_with_metastasis']] = combined_df[['elective_surgery','readmission_status','apache_post_operative','arf_apache','gcs_unable_apache','intubated_apache','ventilated_apache','aids','cirrhosis','diabetes_mellitus','hepatic_failure','immunosuppression','leukemia','lymphoma','solid_tumor_with_metastasis']].astype(object)","b41edb69":"combined_df_categorical = combined_df[['elective_surgery','readmission_status','apache_post_operative','arf_apache','gcs_unable_apache',\n                   'intubated_apache','ventilated_apache','aids','cirrhosis','diabetes_mellitus','hepatic_failure',\n                   'immunosuppression','leukemia','lymphoma','solid_tumor_with_metastasis','ethnicity','gender','hospital_admit_source',\n                   'icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem','icu_admit_source']]\n\n# convert into dummies\ncombined_dummies = pd.get_dummies(combined_df_categorical, drop_first=True)\n\n# drop cateorical variables from X dataframe\ncombined_df = combined_df.drop(combined_df_categorical, axis = 1)\n\n# concat dummy variables with X dataframe\ncombined_df = pd.concat([combined_df, combined_dummies], axis = 1)\nprint(combined_df.shape)","129eaddf":"import copy\nX = copy.copy(combined_df[:X_len])\ntest = copy.copy(combined_df[X_len:])\nprint('X             ', X.shape)\nprint('test          ', test.shape)","365d0d9c":"X.corr()","0b2e3320":"# create correlation matrix\ncorr_matrix = X.corr().abs()\n\n# select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n\n# find index of feature columns with correlation greater than 0.80\nto_drop = [column for column in upper.columns if any((upper[column]>0.80))]\nto_drop","ec74e222":"X = X.drop(to_drop,1)\nprint(X.shape)","ed422b3f":"test = test.drop(to_drop ,1)\nprint(test.shape)","b08c954c":"# plotting heat map to see correlation \nplt.figure(figsize=(15,10))\nsns.heatmap(data = X.corr())\nplt.show()","04922a64":"X.info(verbose = True)","1df3fb60":"# standardization of X\nscaler = preprocessing.StandardScaler().fit(X)\nX = scaler.transform(X)\nX = pd.DataFrame(X)\n\n# test\ntest = scaler.transform(test)\ntest = pd.DataFrame(test)","58315ca5":"test.shape","06fc460f":"# splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, test_size = 0.3, random_state = 100)","c3848955":"X_orig = X.copy()\ny_orig = y.copy()","4d2c4ed4":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n\nX = X_orig.copy()\ny = y_orig.copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X_train, y_train)\n\n# Make predictions\nprediction_test = model_rf.predict(X_test)\nprint(classification_report(y_test,prediction_test))","ac5abd30":"# Printing confusion matrix\nprint(confusion_matrix(y_test, prediction_test))","23d3cef5":"# Defining a genric function to calculate sensitivity\ndef sensitivity_score(inp_y_test, inp_y_pred):\n    positives = confusion_matrix(inp_y_test,inp_y_pred)[1]\n    # print('True Positives: ', positives[1], ' False Positives: ', positives[0])\n    return (positives[1]\/(positives[1] + positives[0]))","1d1b8ef2":"print ('Random Forest Accuracy with Default Hyperparameter', metrics.accuracy_score(y_test, prediction_test))\nprint ('Random Forest Sensitivity with Default Hyperparameter', sensitivity_score(y_test, prediction_test))","252b15b7":"import lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV\nclf = lgb.LGBMClassifier(silent=True, random_state = 304, metric='roc_auc', n_jobs=4)","c8351849":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nparams ={'cat_smooth' : sp_randint(1, 100), 'min_data_per_group': sp_randint(1,1000), 'max_cat_threshold': sp_randint(1,100)}","a4df8a5c":"fit_params={\"early_stopping_rounds\":2, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_train, y_train),(X_test,y_test)],\n            'eval_names': ['train','valid'],\n            'verbose': 300,\n            'categorical_feature': 'auto'}","27e84bbd":"gs = RandomizedSearchCV( estimator=clf, param_distributions=params, scoring='roc_auc',cv=3, refit=True,random_state=304,verbose=True)","8a41d353":"gs.fit(X_train, y_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))","5ae06f49":"gs.best_params_, gs.best_score_","8ce29bdb":"# clf2 = lgb.LGBMClassifier(random_state=304, metric = 'roc_auc', n_jobs=4)\nclf2 = lgb.LGBMClassifier(random_state=304, metric = 'roc_auc', cat_smooth = 32, max_cat_threshold = 75, min_data_per_group = 82, n_jobs=4)","ab060e79":"params_2 = {'learning_rate': [0.04, 0.05, 0.08],   \n            'num_iterations': [1400,1600, 1800]}","8c8b3a52":"gs2 = GridSearchCV(clf2,params_2, scoring='roc_auc',cv=3)","90b0058a":"gs2.fit(X_train, y_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs2.best_score_, gs2.best_params_))","a9cf96ac":"gs2.best_params_, gs2.best_score_","9b7bef0a":"params_2 = {\n 'bagging_fraction': 0.4,\n 'boosting': 'dart',\n 'num_iterations': 1400, \n 'learning_rate': 0.04,\n 'colsample_bytree': 0.5048747931447324,\n 'cat_smooth': 32, \n 'max_cat_threshold':75, \n 'min_data_per_group': 82,\n 'max_bin': 1312,\n 'max_depth': 12,\n 'num_leaves': 4090,\n 'min_child_samples': 407,\n 'min_child_weight': 0.1,\n 'min_data_in_leaf': 2420,\n 'reg_alpha': 0.1,\n 'reg_lambda': 20,\n 'scale_pos_weight': 3,\n 'subsample': 0.7340872997512691,\n 'subsample_for_bin': 512,\n 'scoring': 'roc_auc',\n 'metric': 'auc',\n 'objective': 'binary'}","194a53f7":"lgbm_train2 = lgb.Dataset(X_train, y_train)\nlgbm_val2 = lgb.Dataset(X_test, y_test)","ecb2dc22":"evals_result = {}  # to record eval results for plotting\nmodel_lgbm_2 = lgb.train(params_2,\n                lgbm_train2,\n                num_boost_round=250,\n                valid_sets=[lgbm_train2, lgbm_val2],\n                feature_name=['f' + str(i + 1) for i in range(X_train.shape[-1])],\n                categorical_feature= [182],\n                evals_result=evals_result,\n                verbose_eval=100)","9d75c62c":"ax = lgb.plot_metric(evals_result, metric='auc', figsize=(15, 8))\nplt.show()","197c13ae":"df_unlabel[\"hospital_death\"] = model_lgbm_2.predict(test, pred_contrib=False)","889001c1":"df_unlabel.shape","c677b360":"df_unlabel.head()","c851dfd5":"df_unlabel[['encounter_id','hospital_death']].to_csv('submission.csv',index = False)\ndf_unlabel[['encounter_id','hospital_death']].head()","10e6e06d":"## Checking death rate","e818e5b7":"### On treating the outliers the large part of data is getting deleted, therefore we are not treating them and moving forward ","51291e95":"#### 'elective_surgery', 'readmission_status', 'apache_post_operative', 'arf_apache', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache', 'aids', 'cirrhosis', 'diabetes_mellitus', 'hepatic_failure', 'immunosuppression', 'leukemia', 'lymphoma', 'solid_tumor_with_metastasis' are categorical therefore changing their datatype as object  ","c96d660a":"### From the above observations we can conclude that we can impute the missing values of all the numeric columns with their median    ","98aac7eb":"## Treating missing values","b6fd041e":"#### The above analysis concludes that we can impute the missing values with their respective modes","b685fc63":"### Dropping 'encounter_id' and 'patient_id' as they have nothing to do with 'hospital_death' ","89fc66e5":"## Model Building","a7b90757":"# Data Preparation","11df4f44":"### Analyzing missing values in numeric columns of training set","068e76a8":"## Checking correlation of death with every variable ","47577cfd":"### Imputing the missing values of the numeric data frame with their median ","7e1d9cfc":"## Feature Scaling ","96a8d38a":"### Analyzing Numeric columns","41fbac2a":"## Treating the missing values","d9ea2e35":"### Deleting variables from 'X' data frame having more than 80% correlation[](http:\/\/)","49a23504":"## Splitting the data into train and test set","2236978b":"### Analyzing missing values in non-numeric columns of training set","b5ed6d01":"## Dividing dataframe based on numeric and non-numeric columns ","911713e6":"## Random forest with default parameters","059b1dcb":"### With default parameters, we get a 92% accuracy in Random forest model","b999396a":"## Creating dummy variables for categorical columns of X","9eb94ac9":"## Treating Outliers","63d65fab":"## Modelling using decision tree","a755d182":"#### there are 97 columns having missing columns\n#### dividing them into 5 parts and visualizing them using box plot","77bbaca9":"## Merging numeric and non-numeric dataFrame back to original training dataFrame based on their index  ","4cb04e96":"## Separating train dataset into independent(X) and dependent(y) variables ","bb4fd439":"## Checking Correlation between variables of X","2ef8c712":"#### Here also, we can impute the variables with their median ","09327915":"### Inferences:\n- 'hospital_death' is highly positively correlated to 'apache_4a_hospital_death_prob', 'apache_4a_icu_death_prob' and 'ventilated_apache'\n- 'hospital_death' is highly negatively correlated to 'gcs_eyes_apache', 'gcs_motor_apache' and 'readmission_status' ","a5d3442a":"### We have almost 5% death rate","3c111af1":"#### Inference:\n- icu_stay_type is mostly 'admit'\n- icu_type is 'Med_Surg ICU'\n- apache body stream is 'Cardiovascular'","c1f89d84":"### Analyzing Non-Numeric Columns ","94247222":"#### In this set of columns, many outliers are present so we can impute the missing values with their median  ","cab2d282":"#### Inference:\n- Mostly ethinicity is 'Caucasian' and gender is 'Male'\n- Most of the hospital admit source is 'Emergency' \n- And ICU admit score is 'Accident and Emergency'","963ddd1c":"### Imputing the missing values of non numeric columns with their modes ","258ad7e2":"#### We can impute the missing value with their mean for the above set of numeric columns as there are not much outliers present in the column set 1  ","fd0e3262":"# Data Understanding and Data Cleaning"}}