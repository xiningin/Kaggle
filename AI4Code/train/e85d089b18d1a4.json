{"cell_type":{"078aa1da":"code","514ce230":"code","c6da8d08":"code","3fb532e8":"code","faa8156a":"code","01b9a562":"code","6efed271":"code","a8dd952f":"code","bcd8ca92":"code","8073120d":"code","09c2776d":"code","768ee7fd":"code","2f39d643":"code","2fcc3453":"code","663ee625":"code","23dda020":"code","1a1b8a7c":"code","bcc040f5":"code","0890af06":"code","4f8f0566":"code","74fe3b49":"code","2a4a4abf":"code","3e057a55":"code","56a73956":"code","a5f76321":"code","bf4e160f":"markdown","16ed6eba":"markdown","15e9f0b8":"markdown","62985fcf":"markdown","976c92b5":"markdown","33b9aa7b":"markdown","b4bc34f6":"markdown","00a3538b":"markdown","dcf03e43":"markdown","f4f6676a":"markdown","f43f75bc":"markdown","4077d191":"markdown","299e826d":"markdown","4b70c76f":"markdown","8e0dca00":"markdown","fe33707a":"markdown","3f007af4":"markdown","006fe740":"markdown","4fa8bd46":"markdown","18c33479":"markdown","dc9469c2":"markdown","2872f2cf":"markdown","5074f33c":"markdown","c2de6954":"markdown"},"source":{"078aa1da":"import numpy as np\nimport sklearn as sk\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn.model_selection as ms\nimport sklearn.preprocessing as p\nimport math","514ce230":"tf.version.VERSION","c6da8d08":"mnist = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","3fb532e8":"mnist.shape, mnist.columns","faa8156a":"height = 28\nwidth = 28\nchannels = 1","01b9a562":"n_outputs = 10","6efed271":"def show_digit(digit):\n    plt.imshow(digit.reshape(height, width))\n    plt.show()","a8dd952f":"def show_digit_and_print_label(row):\n    print(row.loc['label'], ':')\n    show_digit(row.loc[mnist.columns != 'label'].values)","bcd8ca92":"mnist.loc[:3].apply(show_digit_and_print_label, axis=1)\n","8073120d":"X_data = mnist.drop(columns='label')\ny_data = mnist['label']","09c2776d":"y_data = tf.keras.utils.to_categorical(y_data, num_classes = n_outputs)\ny_data.shape","768ee7fd":"X_train, X_val, y_train, y_val  = ms.train_test_split(X_data, y_data, test_size=0.15)","2f39d643":"scaler = p.StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_train = X_train.reshape(-1, height, width, channels)\n\nX_val = scaler.transform(X_val)\nX_val = X_val.reshape(-1, height, width, channels)","2fcc3453":"X_train.shape, X_val.shape","663ee625":"y_train.shape, y_val.shape","23dda020":"image_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range=10,\n        zoom_range = 0.1, \n        width_shift_range=0.1, \n        height_shift_range=0.1\n) ","1a1b8a7c":"batch_size = 250","bcc040f5":"train_data_gen = image_gen.flow(X_train, y=y_train, batch_size=batch_size)","0890af06":"class CosineAnnealingLearningRateCallback(tf.keras.callbacks.Callback):\n\n    def __init__(self, n_epochs, n_cycles, lrate_max, n_epochs_for_saving, verbose=0):\n        self.epochs = n_epochs\n        self.cycles = n_cycles\n        self.lr_max = lrate_max\n        self.n_epochs_for_saving = n_epochs_for_saving\n        self.best_val_acc_per_cycle = float('-inf')\n        \n    # allow to save model only in the last n_epochs_for_saving  \n    def is_save_range(self, epoch, epochs_per_cycle, n_epochs_for_saving):\n        epoch += 1\n\n        f, d = math.modf(epoch \/ epochs_per_cycle)\n        next_end = epochs_per_cycle * (d + (1 if f > 0 else 0))\n\n        need_to_save = epoch > (next_end - n_epochs_for_saving) \n        return need_to_save\n\n    # calculate learning rate for an epoch\n    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n        epochs_per_cycle = math.floor(n_epochs\/n_cycles)\n        cos_inner = (math.pi * (epoch % epochs_per_cycle)) \/ (epochs_per_cycle)\n        return lrate_max\/2 * (math.cos(cos_inner) + 1)\n    \n    # calculate and set learning rate at the start of the epoch\n    def on_epoch_begin(self, epoch, logs=None):\n        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n        \n    # make a snapshots if necessary\n    def on_epoch_end(self, epoch, logs={}):\n        # check if we can save model\n        epochs_per_cycle = math.floor(self.epochs \/ self.cycles)\n        \n        if epoch % epochs_per_cycle == 0:\n            self.best_val_acc_per_cycle = float('-inf')\n            \n            #test log\n            #print('MyCheckpointer. New cycle - best_val_acc_per_cycle has been erased')\n        \n        isr = self.is_save_range(epoch, epochs_per_cycle, self.n_epochs_for_saving)\n        \n        last_val_acc = logs['val_accuracy']\n        \n        #test logs\n        #print('MyCheckpointer. epoch: ', epoch)\n        #print('MyCheckpointer. epochs_per_cycle: ', epochs_per_cycle)\n        #print('MyCheckpointer. isr: ', isr)\n        #print('MyCheckpointer. best_val_acc_per_cycle: ', self.best_val_acc_per_cycle, ', last_val_acc: ', last_val_acc)\n        \n        # check is snapshot necessary \n        if epoch != 0 and isr and last_val_acc > self.best_val_acc_per_cycle:\n            self.best_val_acc_per_cycle = last_val_acc\n            \n            # save model to file\n            filename = f'snapshot_model_{epoch \/\/ epochs_per_cycle}.h5'\n            self.model.save(filename)\n            print(f'saved snapshot {filename}, epoch: {epoch}, val_accuracy: {last_val_acc:.5f}')\n        \n# we can also play with these hyperparameters         \nn_epochs = 300\nn_cycles = n_epochs \/ 50\nn_epochs_for_saving = 20\n\ncalrc = CosineAnnealingLearningRateCallback(n_epochs, n_cycles, 0.01, n_epochs_for_saving)","4f8f0566":"model = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(32, 3, 1, padding='same', activation='relu', input_shape=(height, width, channels)))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Conv2D(32, 3, 1, padding='same', activation='relu', input_shape=(height, width, channels)))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.20))\n\n\nmodel.add(tf.keras.layers.Conv2D(64, 3, 1, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Conv2D(64, 3, 1, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.20))\n\n\nmodel.add(tf.keras.layers.Conv2D(128, 3, 1, padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.20))\n\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='Adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","74fe3b49":"model.fit(train_data_gen, batch_size=batch_size, epochs = n_epochs, validation_data = (X_val, y_val), callbacks=[calrc], verbose=2)","2a4a4abf":"def load_all_models(n_models):\n    all_models = list()\n    for i in range(n_models):\n        filename = f'snapshot_model_{str(i)}.h5'\n        model = tf.keras.models.load_model(filename)\n        all_models.append(model)\n    return all_models\n \ndef ensemble_predictions(models, testX):\n    yhats = [model.predict(testX) for model in models]\n    yhats = np.array(yhats)\n    summed = np.sum(yhats, axis=0)\n    result = np.argmax(summed, axis=1)\n    return result\n \ndef evaluate_n_models(models, n_models, testX, testy):\n    subset = models[:n_models]\n    yhat = ensemble_predictions(subset, testX)\n    return sk.metrics.accuracy_score(testy, yhat)","3e057a55":"models = load_all_models(6)\n\nsingle_scores, ensemble_scores = list(), list()\nfor i in range(1, len(models)+1):\n\n    ensemble_score = evaluate_n_models(models, i, X_val, np.argmax(y_val, axis=1))\n\n    _, single_score = models[i-1].evaluate(X_val, y_val, verbose=0)\n\n    print(f'{i}: single={single_score:.5f}, ensemble={ensemble_score:.5f}')\n    ensemble_scores.append(ensemble_score)\n    single_scores.append(single_score)\n\nx_axis = [i for i in range(1, len(models)+1)]\nplt.plot(x_axis, single_scores, marker='o', linestyle='None')\nplt.plot(x_axis, ensemble_scores, marker='x')\nplt.show()","56a73956":"X_pred = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nX_pred = scaler.transform(X_pred)\nX_pred = X_pred.reshape(-1, height, width, channels)","a5f76321":"y_pred = pd.DataFrame()\ny_pred['ImageId'] = pd.Series(range(1,X_pred.shape[0] + 1))\ny_pred['Label'] = ensemble_predictions(models, X_pred)\n\ny_pred.to_csv(\"submission.csv\", index=False)","bf4e160f":"Now let's define a few functions for the ensemble usage","16ed6eba":"Work on this learning rate and checkpoint callback is the most interesting thing in this notebook for me.\n\nHere is the original paper about snapshot ensembles with the cosine annealing: https:\/\/arxiv.org\/pdf\/1704.00109.pdf\n\nThis image best describes the used ensemble creation method:","15e9f0b8":"# Modeling","62985fcf":"And load and test our models","976c92b5":"This learning rate cosine annealing ensemble creation method with another used techniques gives pretty good results. Cosine annealing is also quite intuitive and easy to use learning rate scheduling method.","33b9aa7b":"# Trained ensemble usage","b4bc34f6":"Let's use our ensemble as intended","00a3538b":"I also want to apply data augmentation for our models, let's define ImageDataGenerator","dcf03e43":"# Predicting","f4f6676a":"# Data preprocessing","f43f75bc":"# Data augmentation","4077d191":"Today we will train CNN ensemble using cosine annealing and model checkpoints for the MNIST dataset classification task.","299e826d":"# Data visualization","4b70c76f":"Now we need to split the dataset on the train and validation parts","8e0dca00":"This was preceded by a lot of manual and auto hyperparameters tuning sessions and different model architectures testing, but now I skip this so as not to confuse the reader.","fe33707a":"# Conclusion","3f007af4":"# Cosine annealing and model checkpoints","006fe740":"Check shape and where is the 'label' column","4fa8bd46":"# Introduction","18c33479":"Let's define a few functions for displaying images","dc9469c2":"# Settings","2872f2cf":"Import required libs and check Tensorflow version","5074f33c":"![Screenshot from 2020-07-01 00-22-54.png](attachment:f6e2baf3-2a44-46a9-bdf1-6f387833a818.png)","c2de6954":"# Import data"}}