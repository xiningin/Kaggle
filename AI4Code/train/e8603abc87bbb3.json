{"cell_type":{"6daf5c7e":"code","706c24b0":"code","986204df":"code","46fe6ab9":"code","10a89804":"code","54b7442c":"code","3589a15d":"code","22c98ccc":"code","bce6c9dc":"code","a079f0b0":"code","6e23cd18":"code","08dc0af2":"code","7e04dd75":"code","1ce0a07a":"code","40153813":"code","aa735f7e":"code","8e900fb8":"code","175d3147":"code","b9a401e8":"code","dc209b4f":"markdown","8b83cfee":"markdown","bbedccb8":"markdown","6360f989":"markdown"},"source":{"6daf5c7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","706c24b0":"data = pd.read_csv('\/kaggle\/input\/salary-data-simple-linear-regression\/Salary_Data.csv')\ndata.head()","986204df":"# shape of Data\ndata.shape","46fe6ab9":"# Numerical Details of data\ndata.describe()","10a89804":"# checking null values in data\ndata.isnull().sum()","54b7442c":"# scatter plot b\/w dependent and Independent variable\nplt.scatter(x=data['YearsExperience'], y=data['Salary'])\nplt.show()","3589a15d":"### As we can see there is a linear relation between the variable. so we can go ahead with our linear regression","22c98ccc":"# creating X and y\nX = data['YearsExperience']\ny = data['Salary']","bce6c9dc":"# importing library for train test split\nfrom sklearn.model_selection import train_test_split\n\n# splitting data into train and test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)","a079f0b0":"# add constant to train data\nX_train_sm = sm.add_constant(X_train)\nX_test_sm = sm.add_constant(X_test)","6e23cd18":"lr = sm.OLS(y_train, X_train_sm).fit()\nlr.params","08dc0af2":"# One benefit of using statsmodel is it gives us statical summary of the model\nprint(lr.summary())","7e04dd75":"# Plot prediction\nplt.scatter(X_train, y_train)\nplt.plot(X_train, 25918.438335+9339.081724*X_train, 'r')\nplt.show()","1ce0a07a":"# Residual Analysis\ny_train_prediction = lr.predict(X_train_sm)\nresidual = y_train - y_train_prediction\nresidual.head()","40153813":"# distribution of residual\nsns.distplot(residual)\nplt.show()","aa735f7e":"# distribution between residual and prediction\nplt.scatter(X_train, residual)\nplt.show()","8e900fb8":"#  Prediction on Test set\ny_test_prediction = lr.predict(X_test_sm)","175d3147":"# import libraries to see RMSE and R2 score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","b9a401e8":"train_score = r2_score(y_train, y_train_prediction)\ntest_score = r2_score(y_test, y_test_prediction)\nprint('r2 score on train set', train_score)\nprint('r2 score on test set', test_score)","dc209b4f":"We are confident that the model fit isn't by chance, and has decent predictive power.","8b83cfee":"# **Residual Analysis**","bbedccb8":"The residuals are following the normally distributed with a mean 0. All good!","6360f989":"After checking the R2 score on test and train data. Our model is ready and feasible for future predictions"}}