{"cell_type":{"a9cbd8ff":"code","119a3238":"code","da0b0cbe":"code","417acb7d":"code","5777135b":"code","af326b85":"code","2c079a5a":"code","330804b0":"code","174e5e7c":"code","29e4d60e":"code","48b38ded":"code","08e1cbb0":"code","6a6e7e26":"code","e6aa847b":"code","aa6ccf76":"code","704b57c8":"code","fdcd6a37":"code","ee5a11ca":"code","088a5481":"markdown","d93dba62":"markdown","ba38c43b":"markdown","6c6f853b":"markdown","fffd68cf":"markdown","4833dee3":"markdown"},"source":{"a9cbd8ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","119a3238":"print(os.listdir('..\/input\/flowers-recognition\/flowers'))\n","da0b0cbe":"import os\nimport cv2\nimport numpy as np\n\n#Encoding and Split data into Train\/Test Sets\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n#Tensorflow Keras CNN Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n\n#Plot Images\nimport matplotlib.pyplot as plt","417acb7d":"data = []\nlabel = []\n\nSIZE = 128 #Crop the image to 128x128\nfolder_dir = '..\/input\/flowers-recognition\/flowers'\nfor folder in os.listdir(folder_dir):\n    for file in os.listdir(os.path.join(folder_dir, folder)):\n        if file.endswith(\".jpg\"):\n            label.append(folder)\n            img = cv2.imread(os.path.join(folder_dir, folder, file))\n            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            im = cv2.resize(img_rgb, (SIZE,SIZE))\n            data.append(im)\n        else:\n            continue","5777135b":"data_arr = np.array(data)\nlabel_arr = np.array(label)","af326b85":"len(label)","2c079a5a":"encoder = LabelEncoder()\ny = encoder.fit_transform(label_arr)\ny = to_categorical(y,5)\nX = data_arr\/255","330804b0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)","174e5e7c":"model = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(5, activation = \"softmax\"))","29e4d60e":"datagen = ImageDataGenerator(\n        rotation_range=20,\n        zoom_range = 0.20,\n        width_shift_range=0.3,\n        height_shift_range=0.3,\n        horizontal_flip=True,\n        vertical_flip=True)\n\ndatagen.fit(X_train)","48b38ded":"import matplotlib.pyplot as plt\nimg = plt.imshow(X_train[0])","08e1cbb0":"model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\nbatch_size=25\nepochs=30","6a6e7e26":"history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),epochs = epochs,validation_data = (X_test,y_test),verbose = 1,)","e6aa847b":" # Loss\nplt.plot(history.history['loss'], \"r\")\nplt.plot(history.history['val_loss'], \"b\")\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'validation'])\nplt.show()\n\n# Accuracy\nplt.plot(history.history['accuracy'], \"r\")\nplt.plot(history.history['val_accuracy'],\"b\")\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'validation'])\nplt.show()","aa6ccf76":"categories = np.sort(os.listdir(folder_dir))\nfig, ax = plt.subplots(3,3, figsize=(25, 40))\nfolder_dir = '..\/input\/flowers-recognition\/flowers'\n\nfor i in range(3):\n    for j in range(3):\n        k = int(np.random.random_sample() * len(X_test))\n        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n        else:\n            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')","704b57c8":"pred=model.predict(X_test)\npred_digits=np.argmax(pred,axis=1)\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])==pred_digits[i]):\n        prop_class.append(i)\n    if(len(prop_class)==8):\n        break\n\ni=0\nfor i in range(len(y_test)):\n    if(not np.argmax(y_test[i])==pred_digits[i]):\n        mis_class.append(i)\n    if(len(mis_class)==8):\n        break","fdcd6a37":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\ncount=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(X_test[prop_class[count]])\n        ax[i,j].set_title(\"Predicted Watch :\"+str(encoder.inverse_transform([pred_digits[prop_class[count]]]))+\"\\n\"+\"Actual Watch : \"+str(encoder.inverse_transform([np.argmax(y_test[prop_class[count]])])))\n        plt.tight_layout()\n        count+=1\n        ","ee5a11ca":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(X_test[mis_class[count]])\n        ax[i,j].set_title(\"Predicted Watch :\"+str(encoder.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(encoder.inverse_transform([np.argmax(y_test[mis_class[count]])])))\n        plt.tight_layout()\n        count+=1","088a5481":"# Splitting dataset for modelling","d93dba62":"## MISCLASSIFIED IMAGES OF FLOWERS","ba38c43b":"## CORRECTLY CLASSIFIED FLOWER IMAGES","6c6f853b":"# Importing dataset","fffd68cf":"# Importing libraries","4833dee3":"# Fitting the model"}}