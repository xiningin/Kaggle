{"cell_type":{"96ce8a2c":"code","9e628c2e":"code","a6c2f1a4":"code","8e70845f":"code","77b8d099":"code","3845ae33":"code","339b1978":"code","223562fa":"code","8bb49ec4":"code","cb0a1f50":"code","b7ba9677":"code","208a3261":"code","97443624":"code","93d9b629":"code","7cba02ce":"code","b875681a":"code","4748f8b3":"code","b4f95d32":"code","701e61ed":"code","489283a9":"code","d1e97317":"code","48e5f940":"code","e0e12f53":"code","b7bde595":"code","7e22d036":"markdown","1895dfd5":"markdown","8f7d3a6e":"markdown","9e4b4b1a":"markdown","24bf309e":"markdown","58035209":"markdown","b0aa26b3":"markdown","6b6a5107":"markdown","5806ef6d":"markdown","9b1566c3":"markdown","ee049100":"markdown","6ec00e51":"markdown","dc8a22b8":"markdown","c7a313b1":"markdown","4c186688":"markdown","bb8dfce3":"markdown","5119d189":"markdown","a0ed73b5":"markdown","134eb3f5":"markdown","c1eaecb7":"markdown","835960c5":"markdown"},"source":{"96ce8a2c":"import os\nimport glob\nimport json \nimport random\nfrom pathlib import Path\nfrom difflib import SequenceMatcher\nimport shutil\nfrom PIL import Image, ImageDraw, ImageFont\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom IPython.display import display\nimport matplotlib\nfrom matplotlib import pyplot, patches","9e628c2e":"sroie_folder_path = Path('\/kaggle\/input\/sroie20192021\/SROIE2019')\nexample_file = Path('X51005757324.txt')\nimage = Image.open(\"..\/input\/sroie20192021\/SROIE2019\/0325updated.task1train(626p)\/X51005757324.jpg\")\nimage = image.convert(\"RGB\")\nnew_image = image.resize((300, 600))\nnew_image","a6c2f1a4":"def read_bbox_and_words(path: Path):\n  bbox_and_words_list = []\n\n  with open(path, 'r') as f:\n    for line in f.read().splitlines():\n      split_lines = line.split(\",\")\n\n      bbox = np.array(split_lines[0:8], dtype=np.int32)\n      text = \",\".join(split_lines[8:])\n\n      # From the splited line we save (filename, [bounding box points], text line).\n      # The filename will be useful in the future\n      bbox_and_words_list.append([path.stem, *bbox, text])\n    \n  dataframe = pd.DataFrame(bbox_and_words_list, columns=['filename', 'x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'line'], dtype=np.int16)\n  dataframe = dataframe.drop(columns=['x1', 'y1', 'x3', 'y3'])\n\n  return dataframe\n\n\n# Example usage\nbbox_file_path = sroie_folder_path \/ \"0325updated.task1train(626p)\" \/ example_file\nprint(\"== File content ==\")\n!tail -n 10 \"{bbox_file_path}\"\n\nbbox = read_bbox_and_words(path=bbox_file_path)\nprint(\"\\n== Dataframe ==\\n\")\nbbox.head(5)","8e70845f":"def read_entities(path: Path):\n  with open(path, 'r') as f:\n    data = json.load(f)\n\n  dataframe = pd.DataFrame([data])\n  return dataframe\n\n\n# Example usage\nentities_file_path = sroie_folder_path \/ \"0325updated.task2train(626p)\" \/ example_file\nprint(\"== File content ==\")\n!head \"{entities_file_path}\"\n\nentities = read_entities(path=entities_file_path)\nprint(\"\\n\\n== Dataframe ==\")\nentities","77b8d099":"# Assign a label to the line by checking the similarity\n# of the line and all the entities\ndef assign_line_label(line: str, entities: pd.DataFrame):\n    line_set = line.replace(\",\", \"\").strip().split()\n    for i, column in enumerate(entities):\n        entity_values = entities.iloc[0, i].replace(\",\", \"\").strip()\n        entity_set = entity_values.split()\n\n        matches_count = 0\n        for l in line_set:\n          if any(SequenceMatcher(a=l, b=b).ratio() > 0.8 for b in entity_set):\n            matches_count += 1\n\n        if matches_count == len(line_set) or matches_count == len(entity_set):\n            return column.upper()\n\n    return \"O\"\n\n\nline = bbox.loc[0,\"line\"]\nlabel = assign_line_label(line, entities)\nprint(\"Line:\", line)\nprint(\"Assigned label:\", label)","3845ae33":"def assign_labels(words: pd.DataFrame, entities: pd.DataFrame):\n    max_area = {\"TOTAL\": (0, -1), \"DATE\": (0, -1)}  # Value, index\n    already_labeled = {\"TOTAL\": False,\n                       \"DATE\": False,\n                       \"ADDRESS\": False,\n                       \"COMPANY\": False,\n                       \"O\": False\n    }\n\n    # Go through every line in $words and assign it a label\n    labels = []\n    for i, line in enumerate(words['line']):\n        label = assign_line_label(line, entities)\n\n        already_labeled[label] = True\n        if label == \"ADDRESS\" and (already_labeled[\"DATE\"] or already_labeled[\"TOTAL\"]):\n            label = \"O\"\n\n        # Assign to the largest bounding box\n        if label in [\"TOTAL\", \"DATE\"]:\n            x0_loc = words.columns.get_loc(\"x0\")\n            bbox = words.iloc[i, x0_loc:x0_loc+4].to_list()\n            area = (bbox[2] - bbox[0]) + (bbox[3] - bbox[1])\n\n            if max_area[label][0] < area:\n                max_area[label] = (area, i)\n\n            label = \"O\"\n\n        labels.append(label)\n\n    labels[max_area[\"DATE\"][1]] = \"DATE\"\n    labels[max_area[\"TOTAL\"][1]] = \"TOTAL\"\n\n    words[\"label\"] = labels\n    return words\n\n\n# Example usage\nbbox_labeled = assign_labels(bbox, entities)\nbbox_labeled.head(10)","339b1978":"Color_labeled = {\"TOTAL\": \"Red\",\"DATE\": \"Yellow\",\"ADDRESS\": \"Green\",\"COMPANY\": \"Blue\",\"O\": \"Gray\"}\n\ndef Draw_BBox(image_path,_bbox_labeled: pd.DataFrame):\n    actual_boxes = []\n    for idx, row in _bbox_labeled.iterrows():\n        x0 = row['x0']\n        y0 = row['y0']\n        x2 = row['x2']\n        y2 = row['y2']\n        label= row['label']\n        color=Color_labeled[label]\n        actual_box = [x0, y0, x2, y2] # we turn it into (left, top, left+width, top+height) to get the actual box \n        draw = ImageDraw.Draw(image, \"RGB\")\n        draw.rectangle(actual_box, outline=color,width=4)\n        new_image = image.resize((300, 600))\n    return new_image","223562fa":"Draw_BBox(image,bbox_labeled)","8bb49ec4":"def split_line(line: pd.Series):\n  line_copy = line.copy()\n\n  line_str = line_copy.loc[\"line\"]\n  words = line_str.split(\" \")\n\n  # Filter unwanted tokens\n  words = [word for word in words if len(word) >= 1]\n\n  x0, y0, x2, y2 = line_copy.loc[['x0', 'y0', 'x2', 'y2']]\n  bbox_width = x2 - x0\n  \n\n  new_lines = []\n  for index, word in enumerate(words):\n    x2 = x0 + int(bbox_width * len(word)\/len(line_str))\n    line_copy.at['x0', 'x2', 'line'] = [x0, x2, word]\n    new_lines.append(line_copy.to_list())\n    x0 = x2 + 5 \n\n  return new_lines\n\n\n# Example usage\nnew_lines = split_line(bbox_labeled.loc[0])\nprint(\"Original row:\")\ndisplay(bbox_labeled.loc[0:0,:])\n\nprint(\"Splitted row:\")\npd.DataFrame(new_lines, columns=bbox_labeled.columns)","cb0a1f50":"from time import perf_counter\ndef dataset_creator(folder: Path, total=1000):\n  bbox_folder = folder \/ '0325updated.task1train(626p)'\n  entities_folder = folder \/ '0325updated.task2train(626p)'\n\n  # Ignoring unwanted files which produced problems when I wanted to fine-tune the model with them included\n  ignore = ['X51006619545.txt', 'X51006619785.txt', 'X51005663280(1).txt', 'X51005663280.txt'] \n  files = [file for file in bbox_folder.glob(\"*.txt\") if file.name not in ignore]\n  files = files[:total]\n\n  data = []\n\n  print(\"Reading dataset:\")\n  for file in tqdm(files, total=len(files)):\n    bbox_file_path = file\n    entities_file_path = entities_folder \/ file.name\n    image_file_path = bbox_folder \/ file.with_suffix(\".jpg\")\n  \n    # Check if all the required files exist\n    if not bbox_file_path.is_file() or not entities_file_path.is_file() or not image_file_path.is_file():\n      continue\n  \n    # Read the files\n    bbox = read_bbox_and_words(bbox_file_path)\n    entities = read_entities(entities_file_path)\n    image = Image.open(image_file_path)\n\n    # Assign labels to lines in bbox using entities\n    bbox_labeled = assign_labels(bbox, entities)\n    del bbox\n\n    # Split lines into separate tokens\n    new_bbox_l = []\n    for index, row in bbox_labeled.iterrows():\n      new_bbox_l += split_line(row)\n    new_bbox = pd.DataFrame(new_bbox_l, columns=bbox_labeled.columns, dtype=np.int16)\n    del bbox_labeled\n\n\n    # Do another label assignment to keep the labeling more precise \n    for index, row in new_bbox.iterrows():\n      label = row['label']\n\n      if label != \"O\":\n        entity = entities.iloc[0, entities.columns.get_loc(label.lower())]\n        if row['line'] not in entity:\n          label = \"O\"\n        else:\n            # Not really IOB tagging, but it gives the best results\n            label = \"S-\" + label\n      \n      new_bbox.at[index, 'label'] = label\n\n    width, height = image.size\n  \n    data.append([new_bbox, width, height])\n\n  return data\n\n\ndataset = dataset_creator(sroie_folder_path)","b7ba9677":"random.Random(4).shuffle(dataset)\n\n# Set split point to be 80% of the dataset\nsplit_point = int(len(dataset) * 0.8) \n\ndataset_train  = dataset[:split_point]\ndataset_test = dataset[split_point:]\ndel(dataset)","208a3261":"def normalize(points: list, width: int, height: int) -> list:\n  x0, y0, x2, y2 = [int(p) for p in points]\n  \n  x0 = int(1000 * (x0 \/ width))\n  x2 = int(1000 * (x2 \/ width))\n  y0 = int(1000 * (y0 \/ height))\n  y2 = int(1000 * (y2 \/ height))\n\n  return [x0, y0, x2, y2]\n\n\ndef write_dataset(dataset: list, output_dir: Path, name: str):\n  print(f\"Writing {name}ing dataset:\")\n  with open(output_dir \/ f\"{name}.txt\", \"w+\", encoding=\"utf8\") as file, \\\n       open(output_dir \/ f\"{name}_box.txt\", \"w+\", encoding=\"utf8\") as file_bbox, \\\n       open(output_dir \/ f\"{name}_image.txt\", \"w+\", encoding=\"utf8\") as file_image:\n\n      # Go through each dataset\n      for datas in tqdm(dataset, total=len(dataset)):\n        data, width, height = datas\n        \n        filename = data.iloc[0, data.columns.get_loc('filename')]\n\n        # Go through every row in dataset\n        for index, row in data.iterrows():\n          bbox = [int(p) for p in row[['x0', 'y0', 'x2', 'y2']]]\n          normalized_bbox = normalize(bbox, width, height)\n\n          file.write(\"{}\\t{}\\n\".format(row['line'], row['label']))\n          file_bbox.write(\"{}\\t{} {} {} {}\\n\".format(row['line'], *normalized_bbox))\n          file_image.write(\"{}\\t{} {} {} {}\\t{} {}\\t{}\\n\".format(row['line'], *bbox, width, height, filename))\n\n        # Write a second newline to separate dataset from others\n        file.write(\"\\n\")\n        file_bbox.write(\"\\n\")\n        file_image.write(\"\\n\")","97443624":"dataset_directory = Path('\/kaggle\/working','dataset')\n\ndataset_directory.mkdir(parents=True, exist_ok=True)\n\nwrite_dataset(dataset_train, dataset_directory, 'train')\nwrite_dataset(dataset_test, dataset_directory, 'test')\n\n# Creating the 'labels.txt' file to the the model what categories to predict.\nlabels = ['COMPANY', 'DATE', 'ADDRESS', 'TOTAL']\nIOB_tags = ['S']\nwith open(dataset_directory \/ 'labels.txt', 'w') as f:\n  for tag in IOB_tags:\n    for label in labels:\n      f.write(f\"{tag}-{label}\\n\")\n  f.write(\"O\")","93d9b629":"%%bash\ncd \/kaggle\/working\ngit clone https:\/\/github.com\/microsoft\/unilm.git\ncd unilm\/layoutlm\/deprecated\npip install .","7cba02ce":"pretrained_model_folder_input=Path('\/kaggle\/input\/d\/patriciamedyna\/layoutlm\/unilm\/layoutlm\/layoutlm-base-uncased\/') # Define it so we can copy it into our working directory\nlabel_file=Path(dataset_directory, \"labels.txt\")\ndataset_dir=\"\/kaggle\/working\/dataset\"\n\n# Move to the  directory\nos.chdir(\"\/kaggle\/working\/unilm\/layoutlm\/deprecated\/examples\/seq_labeling\")","b875681a":"! cat \"\/kaggle\/input\/d\/patriciamedyna\/layoutlm\/unilm\/layoutlm\/layoutlm-base-uncased\/config.json\"","4748f8b3":"print(os.getcwd())","b4f95d32":"! python run_seq_labeling.py \\\n                            --data_dir \"{dataset_dir}\" \\\n                            --labels \"{label_file}\" \\\n                            --model_name_or_path \"{pretrained_model_folder_input}\" \\\n                            --model_type layoutlm \\\n                            --max_seq_length 512 \\\n                            --do_lower_case \\\n                            --do_train \\\n                            --num_train_epochs 40 \\\n                            --logging_steps 50 \\\n                            --save_steps -1 \\\n                            --output_dir output \\\n                            --overwrite_output_dir \\\n                            --per_gpu_train_batch_size 8 \\\n                            --per_gpu_eval_batch_size 16","701e61ed":"# Evaluate for test set and make predictions\n! python run_seq_labeling.py \\\n                            --data_dir \/kaggle\/working\/dataset \\\n                            --labels \/kaggle\/working\/dataset\/labels.txt \\\n                            --model_name_or_path \"{pretrained_model_folder_input}\" \\\n                            --model_type layoutlm \\\n                            --do_lower_case \\\n                            --max_seq_length 512 \\\n                            --do_predict \\\n                            --logging_steps 10 \\\n                            --save_steps -1 \\\n                            --output_dir output \\\n                            --per_gpu_eval_batch_size 8","489283a9":"cat output\/test_results.txt","d1e97317":"import cv2\nfrom matplotlib import pyplot, patches\nimport matplotlib\n\ndata = pd.read_csv(\"\/kaggle\/working\/dataset\/test_image.txt\", delimiter=\"\\t\", names=[\"name\", \"bbox\", \"size\", \"image\"])\ndata_category = pd.read_csv(\"\/kaggle\/working\/dataset\/test.txt\", delimiter=\"\\t\", names=[\"name\", \"true_category\"]).drop(columns=[\"name\"])\ndata_prediction_category = pd.read_csv(\"output\/test_predictions.txt\", delimiter=\" \", names=[\"name\", \"prediction_category\"]).drop(columns=[\"name\"])\n\ndata_merge = data.merge(data_category, left_index=True, right_index=True)\nmerged = data_merge.merge(data_prediction_category, left_index=True, right_index=True)\nmerged_groups = list(merged.groupby(\"image\"))","48e5f940":"def display_prediction(data):\n  colors = {\n      \"S-TOTAL\": (255,0,0),\n      \"S-DATE\": (0,255,0),\n      \"S-ADDRESS\": (0,0, 255),\n      \"S-COMPANY\": (255,255,0),\n      \"O\": (192,192,192)\n  }\n\n  imagename = data[0].split(\".\")[0] + \".jpg\"\n  print(\"Filename:\",imagename)\n  image_path = str(sroie_folder_path \/ \"0325updated.task1train(626p)\" \/ imagename)\n\n  img=cv2.imread(image_path)\n  img_prediction=cv2.imread(image_path)\n\n  data = data[1]\n  for bbox, category, prediction_category in zip(data['bbox'], data['true_category'], data['prediction_category']):\n    (x1, y1, x2, y2) = [int(coordinate) for coordinate in bbox.split()]\n\n    img_prediction = cv2.rectangle(img_prediction, (x1, y1), (x2, y2), colors[prediction_category], 2 if \"O\" in prediction_category else 4)\n    img = cv2.rectangle(img, (x1, y1), (x2, y2), colors[category], 2 if \"O\" in category else 4)\n\n  matplotlib.rcParams['figure.figsize'] = 15 ,18\n\n  cv2.imwrite(\"prediction.jpg\", img_prediction)\n\n  # Plot\n  fig, ax = matplotlib.pyplot.subplots(1,2)\n  ax[0].set_title(\"Original\", fontsize= 30)\n  ax[0].imshow(img);\n  ax[1].set_title(\"Prediction\", fontsize= 30)\n  ax[1].imshow(img_prediction);\n\n  # Legend\n  handles = [\n      patches.Patch(color='yellow', label='Company'),\n      patches.Patch(color='blue', label='Address'),\n      patches.Patch(color='green', label='Date'),\n      patches.Patch(color='red', label='Total'),\n      patches.Patch(color='gray', label='Other')\n  ]\n\n  fig.legend(handles=handles, prop={'size': 25}, loc='lower center')","e0e12f53":"display_prediction(merged_groups[12])","b7bde595":"display_prediction(merged_groups[13])","7e22d036":"## Fine-tuning LayoutLM \nIn this notebook, we are going to fine-tune the LayoutLM model on the SROIE dataset,which is a collection of annotated receipts.The goal of our model is to learn the the annotations of a number of labels(\"company\",\"address\",\"date\",\"total\",\"other\") on those receipts,such that it can be used to annotate unseen receipts in the future.","1895dfd5":"## Training","8f7d3a6e":"# 4-Fine tune LayoutLM\nWe downloaded and transformed our dataset into a trainable and testable set, now we can start the fine-tuning of the model.\n\n## Download the model\nFirst we're going to clone the LayoutLM Github project which contains the script to fine tune our model.","9e4b4b1a":"1. https:\/\/huggingface.co\/transformers\/model_doc\/layoutlm.html\n1. https:\/\/www.kaggle.com\/urbikn\/layoutlm-using-the-sroie-dataset","24bf309e":"## Reading the words and bounding boxes\nIn the OCR data,each line in the file includes a group of words and a bounding box which defines them,we have to do is read the file and discard the unneeded points in the bounding box (because the model requires only the top-left and bottom-right points) and save it in Pandas Dataframe.","58035209":"## Example of a prediction\nThe example shows two side by side images of the same receipt, where the colored boxes are the labeled lines. The left is the *original*, so the data we labeled and the right is the model's prediction.","b0aa26b3":"This is an example when my preprocessing wasn't perfect, but the model still predicted the correct result. From this we can see that if my preprocessing was better, the model would have a better accuracy score.","6b6a5107":"## Split words\nFor the last part we're splitting the lines into separate tokens with their own bounding boxes.\n\nSplitting the bounding boxes based on word length is probably not the best approach, but it's good enough.","5806ef6d":"# 1-LayoutLM","9b1566c3":"With a function which can handle the labeling of our lines, we'll create another function to label all our line in one DataFrame (so one receipt).\n\nAs simple as this could be, the problem arises when we get lines which would all pass the same match, like **TOTAL** for example; a receipt could have only one item on it and its price could be the same as the final total, so duplicate labels. Or maybe part of the address is also present at the end of the receipt.\n\nTo ignore such examples, I wrote simple hard-coded rules to assign *total* and *date* to only the largest bounding boxes it could find (based on its area) and to not allow the address to be assigned after date or total.","ee049100":"# 6-References","6ec00e51":"## Writing the dataset into training and testing files\nWith our dataset transformed, we'll split the dataset into a training and test set.","dc8a22b8":"## Preparing the dataset","c7a313b1":"## Assigning labels to words using the entities data\nWe have our words\/lines and entities, now we just need to put them together by labeling our lines using the entities values. We'll be doing that by substring matching the entities values with the lines and if they don't match to a similarity check using pythons _difflib.SequenceMatcher_ and assigning anything above the 0.8 (80%) prediction match.\n\nThe **label \"O\"** will define all our words not labeled during the assignment step, because it's required for us to label everything.","4c186688":"# 5-Predicting","bb8dfce3":"The LayoutLM model was proposed in the paper [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https:\/\/arxiv.org\/abs\/1912.13318).\n It\u2019s a simple but effective pretraining method of text and layout for document image understanding and information extraction tasks, such as form understanding and receipt understanding. It obtains state-of-the-art results on several downstream tasks:\n* form understanding: the FUNSD dataset (a collection of 199 annotated forms comprising more than 30,000 words).\n* receipt understanding: the SROIE dataset (a collection of 626 receipts for training and 347 receipts for testing).\n* document image classification: the RVL-CDIP dataset (a collection of 400,000 images belonging to one of 16 classes).","5119d189":"## Reading the entities file","a0ed73b5":"## Putting it all together\nWe defined all our functions, now we just have to use them on every file and transform the dataset into a format which the script\/model can parse.","134eb3f5":"## Defining the writing function\nWe'll use the same function to write into the train and test files\n\nThe normalization function is meant to normalize the bounding boxes points in a range [0,1000] using the width and height of the image.","c1eaecb7":"# 2-Install libraries","835960c5":"# 3-Pre-processing the dataset\nThe first step, we have to preprocess the SROIE dataset which can be found from [here](https:\/\/www.kaggle.com\/onchutrng\/sroie20192021). The dataset contains multiple subfolders. For our purposes we only use two folders: \n- **0325updated.task1train(626p)** - contains receipt images (.jpg) and corresponding OCR'd bounding boxes and text (.txt)\n- **0325updated.task2train(626p)** - contains labeled text (.txt) in a JSON format."}}