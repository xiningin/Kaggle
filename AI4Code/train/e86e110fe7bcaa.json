{"cell_type":{"6826af67":"code","14390145":"code","81df33ee":"code","5a769c5b":"code","ca823b0d":"code","82916863":"code","28a15f2d":"code","8c82ea94":"code","8ffeeccf":"code","d52868c9":"code","55b643a4":"code","312601ef":"code","28f08c78":"code","6c150b85":"code","d309c7a6":"code","173f5819":"code","d3cdb70e":"code","0cd4b33a":"code","ef780b56":"code","4de83278":"code","a49e5678":"markdown","c5110559":"markdown","ac65659a":"markdown","d960e3c4":"markdown","6d109d45":"markdown","331a1470":"markdown","325cfa64":"markdown","edd5339e":"markdown","d30dc15a":"markdown","8daab302":"markdown","0607d498":"markdown","bd18ecf3":"markdown","87616745":"markdown","c37032b1":"markdown","97fde351":"markdown","80fc518a":"markdown","92da01ce":"markdown","eaef2068":"markdown","7e74a9df":"markdown","6b59bd5c":"markdown"},"source":{"6826af67":" \n\nimport numpy as np  \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","14390145":"# train.csv dosyas\u0131n\u0131 nas\u0131l okuruz.\ntrain = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()","81df33ee":"# test.csv dosyas\u0131n\u0131 nas\u0131l okuruz.\ntest= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()","5a769c5b":"# y_train olu\u015fturma\nY_train = train[\"label\"]\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) ","ca823b0d":"# train sette ka\u00e7 farkl\u0131 s\u0131n\u0131f ve bu s\u0131n\u0131fa ait veri var g\u00f6r\u00fcnt\u00fcleyelim.\nplt.figure(figsize=(15,7))\ng = sns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Number of digit classes\")\nY_train.value_counts()","82916863":"# baz\u0131 \u00f6rnekleri g\u00f6relim...\nimg = X_train.iloc[0].as_matrix()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()","28a15f2d":"# baz\u0131 \u00f6rnekleri g\u00f6relim...\nimg = X_train.iloc[3].as_matrix()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[3,0])\nplt.axis(\"off\")\nplt.show()","8c82ea94":"# Normalization\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","8ffeeccf":"# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","d52868c9":"# Label Encoding \nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(Y_train, num_classes = 10)","55b643a4":"# train test b\u00f6lme kodu...\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","312601ef":"# bir \u00f6rnek\nplt.imshow(X_train[2][:,:,0],cmap='gray')\nplt.show()","28f08c78":"# \nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical #one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n#\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n# fully connected\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","6c150b85":"# optimizer tan\u0131ml\u0131yoruz...\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","d309c7a6":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","173f5819":"epochs = 20  # en iyi de\u011fer i\u00e7in artt\u0131rmal\u0131s\u0131n\u0131z...\nbatch_size = 1000","d3cdb70e":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # veri k\u00fcmesinde girdi ortalamas\u0131n\u0131 0 olarak ayarla\n        samplewise_center=False,  # her numune ortalamas\u0131n\u0131 0 olarak ayarlay\u0131n\n        featurewise_std_normalization=False,  # giri\u015fleri veri k\u00fcmesinin standart sapmas\u0131na g\u00f6re b\u00f6lme\n        samplewise_std_normalization=False,  # her girdiyi standart sapmas\u0131na b\u00f6l\u00fcn\n        zca_whitening=False,  # derinlik azaltma\n        rotation_range=0.5,  # resimleri 5 derece kadar rastgele d\u00f6nd\u00fcrme\n        zoom_range = 0.5, # resimleri %5 kadar rastgele zoomlama\n        width_shift_range=0.5,  # resimleri %5 horizontal \u00e7evirme\n        height_shift_range=0.5,  # resimleri %5 vertical \u00e7evirme\n        horizontal_flip=False,  # g\u00f6r\u00fcnt\u00fcleri rastgele \u00e7evir\n        vertical_flip=False)  # g\u00f6r\u00fcnt\u00fcleri rastgele \u00e7evir\n\ndatagen.fit(X_train)","0cd4b33a":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size)","ef780b56":"# E\u011fitim ve do\u011frulama i\u00e7in kay\u0131p ve do\u011fruluk e\u011frilerini \u00e7izin\nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","4de83278":"# confusion matrix\nimport seaborn as sns\n# Do\u011frulama veri k\u00fcmesindeki de\u011ferleri tahmin etme\nY_pred = model.predict(X_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","a49e5678":"https:\/\/gym.openai.com\/","c5110559":"<a id=\"7\"><\/a>\n### Max Pooling\n* A\u015fa\u011f\u0131 \u00f6rnekleme veya alt \u00f6rnekleme yapar (Parametre say\u0131s\u0131n\u0131 azalt\u0131r)\n* \u00d6l\u00e7ek veya y\u00f6nelim de\u011fi\u015fikliklerinin de\u011fi\u015fmez \u00f6zelliklerinin alg\u0131lanmas\u0131n\u0131 sa\u011flar.\n* A\u011fdaki parametre ve hesaplama miktar\u0131n\u0131 azalt\u0131r ve b\u00f6ylece a\u015f\u0131r\u0131 takmay\u0131 da kontrol eder.\n* <a href=\"https:\/\/ibb.co\/ckTjN9\"><img src=\"https:\/\/preview.ibb.co\/gsNYFU\/maxpool.jpg\" alt=\"maxpool\" border=\"0\"><\/a>","ac65659a":"<a id=\"3\"><\/a>\n## Train Test B\u00f6lme\n* E\u011fer train setimiz yeteri kadar b\u00fcy\u00fckl\u00fckte ise x_test seti temiz bir \u015fekilde elde edebiliriz..\n* test 10%.\n* train 90% yapal\u0131m...","d960e3c4":"<a id=\"16\"><\/a>\n### Fit the model","6d109d45":"<a id=\"12\"><\/a>\n### Define Optimizer   \n* Adam optimizer: \u00f6\u011frenme oran\u0131n\u0131 de\u011fi\u015ftirir.\n","331a1470":"<a id=\"4\"><\/a>\n## Convolutional Neural Network \n* CNN  genellikle obje ya da resim s\u0131n\u0131fland\u0131rma i\u00e7in kullan\u0131lan bir y\u00f6ntemdir.\n* <a href=\"https:\/\/ibb.co\/kV1j9p\"><img src=\"https:\/\/preview.ibb.co\/nRkBpp\/gec2.jpg\" alt=\"gec2\" border=\"0\"><\/a>","325cfa64":"<a id=\"15\"><\/a>\n### Data Augmentation\n* A\u015f\u0131r\u0131 ezberleme problemini \u00f6nlemek i\u00e7in, el yaz\u0131s\u0131 rakam veri setimizi yapay olarak geni\u015fletmeliyiz\n* Rakam de\u011fi\u015fimlerini yeniden olu\u015fturmak i\u00e7in e\u011fitim verilerini k\u00fc\u00e7\u00fck d\u00f6n\u00fc\u015f\u00fcmlerle de\u011fi\u015ftirin.\n\n* <a href=\"https:\/\/ibb.co\/k24CUp\"><img src=\"https:\/\/preview.ibb.co\/nMxXUp\/augment.jpg\" alt=\"augment\" border=\"0\"><\/a>\n    \n","edd5339e":"* <a href=\"https:\/\/playground.tensorflow.org\/\">Tensorflow Playground<\/a>","d30dc15a":"<a id=\"2\"><\/a>\n## Normalization, Reshape and Label Encoding \n* Normalization\n    * Ayd\u0131nlatma farkl\u0131l\u0131klar\u0131n\u0131n etkisini azaltmak i\u00e7in gri tonlamal\u0131 bir normalle\u015ftirme ger\u00e7ekle\u015ftiriyoruz.\n    * Normalization yapt\u0131\u011f\u0131m\u0131zda cnn daha h\u0131zl\u0131 \u00e7al\u0131\u015f\u0131yor.\n* Reshape\n    * Train ve test resimler 28 x 28 piksel \n    * Resim datam\u0131z\u0131 matrise d\u00f6n\u00fc\u015ft\u00fcrelim 28x28x1 3D tek katman derinlikte \u00e7\u00fcnk\u00fc siyah beyaz tek katman RGB\n    * Keras'\u0131n sonunda kanallara kar\u015f\u0131l\u0131k gelen ekstra bir boyuta ihtiyac\u0131 var. G\u00f6r\u00fcnt\u00fclerimiz gri \u00f6l\u00e7eklidir, bu y\u00fczden sadece bir kanal kullan\u0131r.\n* Label Encoding  \n    * y_train datadaki labellar\u0131  one hot vectors  yaparak matrise d\u00f6n\u00fc\u015ft\u00fcrelim.\n        * 2 => [0,0,1,0,0,0,0,0,0,0]\n        * 4 => [0,0,0,0,1,0,0,0,0,0]","8daab302":"<a id=\"11\"><\/a>\n### Create Model\n* conv => max pool => dropout => conv => max pool => dropout => fully connected (2 layer)\n* Dropout: e\u011fitim s\u0131ras\u0131nda rastgele se\u00e7ilen n\u00f6ronlar\u0131n g\u00f6z ard\u0131 edildi\u011fi bir tekniktir.\n* <a href=\"https:\/\/ibb.co\/jGcvVU\"><img src=\"https:\/\/preview.ibb.co\/e7yPPp\/dropout.jpg\" alt=\"dropout\" border=\"0\"><\/a>","0607d498":"<a id=\"10\"><\/a>\n## Keras\u0131n uygulanmas\u0131","bd18ecf3":"<a id=\"17\"><\/a>\n### Evaluate the model\n* Test Loss visualization\n* Confusion matrix\n","87616745":"<a id=\"13\"><\/a>\n### Compile Model\n* categorical crossentropy\n* \u00d6nceki b\u00f6l\u00fcmlerde ve makine \u00f6\u011freniminde ikili \u00e7apraz entropi yap\u0131yoruz\n> * \u015eu anda categorical crossentropy kullan\u0131yoruz. Bu, \u00e7ok s\u0131n\u0131f\u0131m\u0131z oldu\u011fu anlam\u0131na gelir.\n* <a href=\"https:\/\/ibb.co\/jm1bpp\"><img src=\"https:\/\/preview.ibb.co\/nN3ZaU\/cce.jpg\" alt=\"cce\" border=\"0\"><\/a>\n","c37032b1":"<a id=\"14\"><\/a>\n### Epochs and Batch Size\n* <a id=\"14\"><\/a>\n### Epochs and Batch Size\n* farz edelimki datasetimiz 10 resimden olu\u015fmu\u015f olsun ve bizim **batch size** 2 olsun,  **epochs**. say\u0131s\u0131n\u0131da 3 olarak belirledi\u011fimiz **batches** 10\/2 den 5 olarak ger\u00e7ekle\u015fir. Yani bilgisayar ram bellek \u00f6l\u00e7\u00fcs\u00fcnde 5 kes ram\u0131n\u0131 doldur bo\u015fal yapar. Ram\u0131n\u0131za g\u00fcveniyorsan\u0131n batch size de\u011ferini artt\u0131rabilirsiniz h\u0131zl\u0131 yapman\u0131za yararl\u0131 olacakt\u0131r. fakat bu durumda elde etti\u011finiz sonu\u00e7lar\u0131n ba\u011flamsal olarak bir \u00f6nceki iterasyon ile ili\u015fkisi azalaca\u011f\u0131ndan epochs de\u011ferinide artt\u0131rmal\u0131s\u0131n\u0131z... biraz kar\u0131\u015f\u0131k de\u011filmi ;) \n","97fde351":"<a id=\"5\"><\/a>\n### Convolution Operation nedir ?\n* \u0130lk olarak g\u00f6r\u00fcnt\u00fc ve feature dedekt\u00f6rlerimiz var (3 * 3)\n* feature dedekt\u00f6r\u00fcn\u00fcn 3'e 3 matris olmas\u0131 gerekmez. 5 x 5 veya 7 x 7 olabilir.\n* feature dedekt\u00f6r\u00fc = kernel = filtre\n* feature dedekt\u00f6r\u00fc kenarlar veya d\u0131\u015fb\u00fckey \u015fekiller gibi \u00f6zellikleri alg\u0131lar. \u00d6rne\u011fin, input k\u00f6pek ise, feature detekt\u00f6r\u00fc k\u00f6pe\u011fin kulak veya kuyru\u011fu gibi \u00f6zellikleri alg\u0131layabilir.\n* feature map = d\u00f6n\u015f (giri\u015f g\u00f6r\u00fcnt\u00fcs\u00fc, \u00f6zellik dedekt\u00f6r\u00fc). Matrislerin eleman baz\u0131nda \u00e7arp\u0131m\u0131.\n* feature map  = k\u0131vr\u0131ml\u0131 \u00f6zellik\n* Ad\u0131m = giri\u015f g\u00f6r\u00fcnt\u00fcs\u00fcnde gezinme.\n* G\u00f6r\u00fcnt\u00fcn\u00fcn boyutunu k\u00fc\u00e7\u00fclt\u00fcriz. Bu bc kodu daha h\u0131zl\u0131 \u00e7al\u0131\u015f\u0131r \u00f6nemlidir. Ancak bilgileri kaybettik.\n* Birden fazla \u00f6zellik detekt\u00f6r\u00fc (filtre) kulland\u0131\u011f\u0131m\u0131z i\u00e7in birden \u00e7ok \u00f6zellik haritas\u0131 olu\u015ftururuz.\n\n* Evri\u015fim tabakas\u0131 yapt\u0131ktan sonra do\u011frusall\u0131\u011f\u0131 bozmak i\u00e7in ReLU kullan\u0131yoruz. Do\u011frusals\u0131zl\u0131\u011f\u0131 art\u0131r\u0131n. \u00c7\u00fcnk\u00fc g\u00f6r\u00fcnt\u00fcler do\u011frusal de\u011fildir.\n* <a href=\"https:\/\/ibb.co\/mVZih9\"> <img src = \"https:\/\/preview.ibb.co\/gbcQvU\/RELU.jpg\" alt = \"RELU\" border = \"0\"> <\/a>\n* <a href=\"https:\/\/cdn-images-1.medium.com\/freeze\/max\/1000\/1*yILgZZxuHnQQhtsK-b1HLQ.png?q=20\"> <img src = \"https:\/\/cdn-images-1.medium.com\/freeze\/max\/1000\/1*yILgZZxuHnQQhtsK-b1HLQ.png?q=20\" alt = \"features\" border = \"0\"> <\/a>","80fc518a":"<a id=\"9\"><\/a>\n### Full Connection\n* Tamamen ba\u011fl\u0131 bir katmandaki n\u00f6ronlar, bir \u00f6nceki katmandaki t\u00fcm aktivasyonlarla ba\u011flant\u0131l\u0131d\u0131r\n* Yapay Sinir A\u011f\u0131\n* <a href=\"https:\/\/ibb.co\/hsS14p\"><img src=\"https:\/\/preview.ibb.co\/evzsAU\/fullyc.jpg\" alt=\"fullyc\" border=\"0\"><\/a>","92da01ce":"<a id=\"1\"><\/a>\n## Data seti nas\u0131l y\u00fckleriz\n","eaef2068":"<a id=\"6\"><\/a>\n### Same Padding\n* As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n* input size and output size are same.\n* <a href=\"https:\/\/ibb.co\/jUPkUp\"><img src=\"https:\/\/preview.ibb.co\/noH5Up\/padding.jpg\" alt=\"padding\" border=\"0\"><\/a>","7e74a9df":"# Convolutional Neural Networks (CNN)\n<font color='blue'>\n<br>\u0130\u00e7erik: \n* [dataseti y\u00fckleme](#1)\n* [Normalization, Reshape and Label Encoding ](#2)\n* [Train seti Test sete b\u00f6lme](#3)\n* [Convolutional Neural Network](#4)\n    * [Convolution Operationlar nelerdir ?](#5)\n    * [Same Padding](#6)\n    * [Max Pooling](#7)\n    * [Flattening](#8)\n    * [Full Connection](#9)\n* [Keras](#10)\n    * [Model olu\u015fturma](#11)\n    * [Optimizer](#12)\n    * [Model y\u00fcr\u00fctme](#13)\n    * [Epochs and Batch Size](#14)\n    * [Data Augmentation](#15)\n    * [Model fit etme](#16)\n    * [Modeli de\u011ferlendirme](#17)\n\n","6b59bd5c":"<a id=\"8\"><\/a>\n### Flattening\n* <a href=\"https:\/\/imgbb.com\/\"><img src=\"https:\/\/image.ibb.co\/c7eVvU\/flattenigng.jpg\" alt=\"flattenigng\" border=\"0\"><\/a>"}}