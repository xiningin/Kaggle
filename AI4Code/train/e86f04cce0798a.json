{"cell_type":{"e468d503":"code","ae2d5fc9":"code","4a2c25e5":"code","72af20c4":"code","7c6ad59e":"code","33b9f581":"code","02bc3d98":"code","16e17061":"code","edbb1252":"code","30710d26":"code","dcd72ebc":"code","71d451a8":"code","4fd4bb83":"code","f1ac12f3":"code","bd40b505":"code","df7af9b0":"code","04823c80":"code","af7d19aa":"code","757b0277":"code","0ed6fbea":"code","2e483d3a":"code","ff184442":"code","92cf7218":"code","ae5367ce":"markdown"},"source":{"e468d503":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ae2d5fc9":"!ls ..\/working\/","4a2c25e5":"from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport json\nfrom sklearn.metrics import roc_curve\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)","72af20c4":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https:\/\/discuss.pytorch.org\/t\/how-to-optimize-inception-model-with-auxiliary-classifiers\/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() \/ len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'valid':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts) \n    \n    return model, val_acc_history, outputs, labels","7c6ad59e":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","33b9f581":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n","02bc3d98":"# Top level data directory. Here we assume the format of the directory conforms\n#   to the ImageFolder structure\ndata_dir = \"..\/input\/car_data\/car_data\/\"\n#test_data_dir = \"..\/input\/hackathon-blossom-flower-classification\/\"\n\n# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\nmodel_name = \"inception\"\n\n# Number of classes in the dataset\nnum_classes = 196\n\n# Batch size for training (change depending on how much memory you have)\nbatch_size = 16\n\n# Number of epochs to train for\nnum_epochs = 75\n\n# Flag for feature extracting. When False, we finetune the whole model,\n#   when True we only update the reshaped layer params\nfeature_extract = False","16e17061":"# Initialize the model for this run\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n\n# Print the model we just instantiated\n#print(model_ft)\nprint(\"Model Loading Process Done\")","edbb1252":"data_transforms = {\n    'transform': transforms.Compose([\n        transforms.RandomResizedCrop(input_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}\n\n#print(len(datasets.ImageFolder(data_dir + '\/train')))\nfull_dataset = datasets.ImageFolder(data_dir + '\/train', data_transforms['transform'])\n\ntrain_size = int(0.8 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\n#print(train_size)\n#print(test_size)\ntrain_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n\nimage_datasets = {\n    'train':train_dataset, \n    'valid':test_dataset\n}\ndataloaders_dict = {\n    'train':torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n    'valid':torch.utils.data.DataLoader(image_datasets['valid'], batch_size=batch_size, shuffle=True, num_workers=4)\n}","30710d26":"# Detect if we have a GPU available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","dcd72ebc":"# Send the model to GPU\nmodel_ft = model_ft.to(device)\n\n# Gather the parameters to be optimized\/updated in this run. If we are\n#  finetuning we will be updating all parameters. However, if we are\n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\n#print(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            #print(\"\\t\",name)\n            pass\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            #print(\"\\t\",name)\n            pass\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n#optimizer_ft = optim.Adam(params_to_update,lr=0.0001)","71d451a8":"# Setup the loss fxn\ncriterion = nn.CrossEntropyLoss()\n\n# Train and evaluate\nmodel_ft, hist, out, lab = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=75, is_inception=(model_name==\"inception\"))","4fd4bb83":"def save_checkpoint():\n    checkpoint = {\n        'model':model_ft, \n        'state_dict':model_ft.state_dict(),\n        'optimizer':optimizer_ft.state_dict()\n    }\n    torch.save(checkpoint, '..\/working\/checkpoint.pt')\ndef load_checkpoint(filepath, inference = False):\n    checkpoint = torch.load(filepath + 'checkpoint.pt')\n    model = checkpoint['model']\n    if inference:\n        for parameter in model.parameter():\n            parameter.require_grad = False\n        model.eval()\n    model.to(device)\n    return model","f1ac12f3":"save_checkpoint()","bd40b505":"model_ft = load_checkpoint(filepath='..\/working\/')","df7af9b0":"test_data_dir =\"..\/input\/car_data\/car_data\/\"\ndata_transforms = {\n    'testing': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}\ntest_image_datasets = {x: datasets.ImageFolder(os.path.join(test_data_dir, 'test'), data_transforms[x]) for x in ['testing']}\ntest_dataloaders_dict = {x: torch.utils.data.DataLoader(test_image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x in ['testing']}","04823c80":"import glob\nfiles = glob.glob(\"..\/input\/car_data\/car_data\/test\/\")\n#len(files)","af7d19aa":"# path = '..\/input\/car_data\/car_data\/test\/Ram C\/V Cargo Van Minivan 2012\/*.*'\n# files = glob.glob(path)\n# print(len(files))","757b0277":"data = []\nwith open(\"..\/input\/names.csv\", 'r') as G:\n     data.append(G.read())\n\ndata = data[0].split(\"\\n\")\ndata.remove('')\ndata = [item.replace(\"Ram C\/V Cargo Van Minivan 2012\", \"Ram C-V Cargo Van Minivan 2012\") for item in data]\n#print(data)\n#d = {index(i) for i in data: }\nfrom os import listdir\nfrom os.path import isfile, join\n\nids = []\nop = []\n#print(data)\nfor i in data:\n    path = \"..\/input\/car_data\/car_data\/test\/\"+ str(i)+\"\/*.*\"\n    #mypath = \"..\/input\/car_data\/car_data\/test\/\"+ str(i)+\"\/\"\n    #onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n    files = glob.glob(path)\n    for j in files:\n        ids.append(j.split('\/')[-1].split('.')[0])\n        op.append(data.index(i) + 1)\n    #print(len(files))\n    #print(len(onlyfiles))\n","0ed6fbea":"output = []\nfor inputs, labels in test_dataloaders_dict['testing']:\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    outputs = model_ft(inputs)\n    _, predicted = torch.max(outputs, 1)\n    for i in predicted:\n        output.append(int(i)+1)\n#output","2e483d3a":"sample_submission = pd.read_csv('..\/input\/sampleSubmission.csv')\n#ids = list(range(1, len(output)+1))\nsubmission = pd.DataFrame({\n    'Id' :ids,\n    'Predicted' : output\n}, columns= ['Id', 'Predicted'])\nsubmission['Id']=submission['Id'].apply(lambda x: '{0:0>5}'.format(x))\nsubmission.head()\nsubmission.to_csv('sampleSubmission.csv',index=False)\n#submission['Predicted'] = output\n#submission['Id'] = list(range(0, len(output+1)))\n#submission","ff184442":"from IPython.display import FileLink, FileLinks\nFileLinks('.') #lists all downloadable files on server","92cf7218":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n    print(submission)","ae5367ce":"### Author : Khush Patel (@Khush)\n###### Model : Inception\n###### Ephoch : 75\n###### Loss : CrossEntropyLoss\n###### Criterion : SGD"}}