{"cell_type":{"9f02a2c2":"code","34015c58":"code","65752df7":"code","f91fc687":"code","32b63980":"code","52075e2e":"code","7b1a62e0":"code","2c5f7542":"code","716ff202":"code","843e4673":"code","5a5faec6":"code","9c5e0c75":"code","8c68c0e6":"code","862b914f":"code","c9812c96":"markdown","19c4e470":"markdown","03900849":"markdown","8f01bfcd":"markdown","3080350c":"markdown","ab183666":"markdown","4f48e0f7":"markdown","f46ff2c8":"markdown","58d45d33":"markdown","0788680e":"markdown","e529bf86":"markdown","d540e4d6":"markdown","4e2666cf":"markdown"},"source":{"9f02a2c2":"# Import m\u1ed9t s\u1ed1 module c\u1ea7n thi\u1ebft\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport warnings, random\nwarnings.filterwarnings('ignore')\nprint(os.listdir('..\/input\/fashionmnist'))","34015c58":"# \u0110\u1ecdc l\u00ean t\u1eadp train v\u00e0 test\ntrain = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ntrain.shape, test.shape","65752df7":"train_label = train.label\ntrain.drop(columns = 'label', inplace = True)\n\ntest_label = test.label\ntest.drop(columns = 'label', inplace = True)","f91fc687":"import torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader, SubsetRandomSampler\nfrom torchvision import datasets, transforms\nimport random","32b63980":"# Vi\u1ebft class Dataset\nclass FashionDataset(Dataset):\n    def __init__(self, data, label, transform = None):\n        self.data = data\n        self.label = label\n  \n    def __len__(self):\n        return(len(self.data))\n\n    def __getitem__(self,idx):\n        self.x = self.data.loc[idx,:].values\n        self.y = self.label.loc[idx]\n        return(self.x, self.y)","52075e2e":"# Chia d\u1eef li\u1ec7u ban \u0111\u1ea7u th\u00e0nh 2 t\u1eadp train v\u00e0 validation\nindices = len(train)\nindices = [a for a in range(indices)]\nsplit = 0.20 # T\u1ec9 l\u1ec7 chia\nsplit = int(np.floor(split*len(train)))\nrandom.shuffle(indices)\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)","7b1a62e0":"# T\u1ea1o c\u00e1c DataLoader\ntraining = FashionDataset(train, train_label, transforms.ToTensor())\ntraining_loader = DataLoader(training, batch_size=64, sampler=train_sampler)\n\nvalid_loader = DataLoader(training, batch_size=64, sampler=valid_sampler)\n\ntesting = FashionDataset(test, test_label, transforms.ToTensor())\ntesting_loader = DataLoader(testing, batch_size=64)","2c5f7542":"pymodel_mlp = nn.Sequential(nn.Linear(784,784),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.3),\n                        nn.BatchNorm1d(784),\n                        nn.Linear(784,256),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.4),\n                        nn.BatchNorm1d(256),\n                        nn.Linear(256,128),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.3),\n                        nn.BatchNorm1d(128),\n                        nn.Linear(128,64),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.4),\n                        nn.BatchNorm1d(64),\n                        nn.Linear(64,10),\n                        nn.LogSoftmax(dim = 1),)\n\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(pymodel_mlp.parameters(), lr = 0.008)","716ff202":"# N\u1ebfu c\u00f3 GPU c\u00f3 s\u1eb5n th\u00ec s\u1eed d\u1ee5ng \u0111\u1ec3 t\u00ednh to\u00e1n nhanh, kh\u00f4ng th\u00ec s\u1eed d\u1ee5ng CPU.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npymodel_mlp = pymodel_mlp.to(device)\n\nepoch = 15\nvalid_score = np.inf\ntorch_valid_loss = []\ntorch_valid_acc  = []\n\nfor e in range(epoch):\n    training_loss = 0\n    valid_loss  = 0\n\n    running_loss = 0\n    pymodel_mlp.train()\n    for image, label in training_loader :\n        optimizer.zero_grad()\n        image = image.to(device)\n        label = label.to(device)\n        out = pymodel_mlp(image.float())\n        loss = criterion(out,label)\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n  \n    with torch.no_grad():\n        running_valid = 0\n        acc_valid = 0\n        pymodel_mlp.eval()\n        for image, label in valid_loader:\n            image = image.to(device)\n            label = label.to(device)\n            out = pymodel_mlp(image.float())\n            loss = criterion(out, label)\n            top_p, top_class = torch.exp(out).topk(1, dim = 1)\n            equal = top_class == label.view(top_class.shape)\n            accuracy = torch.mean(equal.type(torch.FloatTensor))\n            running_valid += loss.item()\n            acc_valid += accuracy.item()\n    \n    if running_valid < valid_score :\n        torch.save(pymodel_mlp.state_dict(), 'checkpoint.pth')\n        print('\\nError changes from {} to {}'.format(valid_score\/len(valid_loader), running_valid\/len(valid_loader)))\n        valid_score = running_valid\n        print('Saved model\\n')\n        \n    training_loss = running_loss\/len(training_loader)\n    valid_loss    = running_valid\/len(valid_loader)\n\n    torch_valid_loss.append(valid_loss)\n    torch_valid_acc.append(acc_valid\/len(valid_loader))\n    print('Epoch : %s\\nTraining_error : %s\\nValid_error    : %s\\nAccuracy_valid : %s\\n------------------------------' \n          %(e+1, training_loss, valid_loss, acc_valid\/len(valid_loader)))","843e4673":"from torch.nn import functional as f\nclass net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv2d_32 = nn.Conv2d(1,32,3,padding=1)\n        self.conv2d_64 = nn.Conv2d(32,64,3,padding=1)\n        self.max2d     = nn.MaxPool2d(2,2)\n        self.conv2d_128 = nn.Conv2d(64,128,3,padding=1)\n        self.conv2d_256 = nn.Conv2d(128,256,3, stride = 2,padding=1)\n        self.linear1    = nn.Linear(3*3*256, 256)\n        self.linear2    = nn.Linear(256,64)\n        self.linear3    = nn.Linear(64,10)\n        self.batch2d1     = nn.BatchNorm2d(64)\n        self.batch2d2    = nn.BatchNorm2d(256)\n        self.batch1d     = nn.BatchNorm1d(64)\n        self.drop      = nn.Dropout(p=0.3)\n        self.flat      = nn.Flatten()\n    \n    def forward(self,x):\n        x = x.view(-1,1,28,28)\n        x = f.relu(self.conv2d_32(x))\n        x = f.relu(self.conv2d_64(x))\n        x = self.batch2d1(x)\n        x = f.relu(self.max2d(x))\n        x = self.drop(x)\n        \n        x = f.relu(self.conv2d_128(x))\n        x = f.relu(self.conv2d_256(x))\n        x = self.batch2d2(x)\n        x = f.relu(self.max2d(x))\n        x = self.drop(x)\n        \n        x = self.flat(x)\n        x = f.relu(self.linear1(x))\n        x = self.drop(x)\n        x = f.relu(self.linear2(x))\n        x = self.drop(x)\n        x = self.batch1d(x)\n        x = f.log_softmax(self.linear3(x), dim=1)\n        return(x)\n\npymodel_cnn = net()\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(pymodel_cnn.parameters(), lr = 0.008)","5a5faec6":"# N\u1ebfu c\u00f3 GPU c\u00f3 s\u1eb5n th\u00ec s\u1eed d\u1ee5ng \u0111\u1ec3 t\u00ednh to\u00e1n nhanh, kh\u00f4ng th\u00ec s\u1eed d\u1ee5ng CPU.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npymodel_cnn = pymodel_cnn.to(device)\nepoch = 15\nvalid_score = np.inf\ntorch_valid_loss_cnn = []\ntorch_valid_acc_cnn  = []\n\nfor e in range(epoch):\n    training_loss = 0\n    valid_loss  = 0\n\n    running_loss = 0\n    pymodel_cnn.train()\n    for image, label in training_loader :\n        optimizer.zero_grad()\n        image = image.to(device)\n        label = label.to(device)\n        out = pymodel_cnn(image.float())\n        loss = criterion(out,label)\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n  \n    with torch.no_grad():\n        running_valid = 0\n        acc_valid = 0\n        pymodel_cnn.eval()\n        for image, label in valid_loader:\n            image = image.to(device)\n            label = label.to(device)\n            out = pymodel_cnn(image.float())\n            loss = criterion(out, label)\n            top_p, top_class = torch.exp(out).topk(1, dim = 1)\n            equal = top_class == label.view(top_class.shape)\n            accuracy = torch.mean(equal.type(torch.FloatTensor))\n            running_valid += loss.item()\n            acc_valid += accuracy.item()\n    \n    if running_valid < valid_score :\n        torch.save(pymodel_cnn.state_dict(), 'checkpoint_cnn.pth')\n        print('\\nError changes from {} to {}'.format(valid_score\/len(valid_loader), running_valid\/len(valid_loader)))\n        valid_score = running_valid\n        print('Saved model\\n')\n\n    training_loss = running_loss\/len(training_loader)\n    valid_loss    = running_valid\/len(valid_loader)\n\n    torch_valid_loss_cnn.append(valid_loss)\n    torch_valid_acc_cnn.append(acc_valid\/len(valid_loader))\n    print('Epoch : %s\\nTraining_error : %s\\nValid_error    : %s\\nAccuracy_valid : %s\\n------------------------------' \n          %(e+1, training_loss, valid_loss, acc_valid\/len(valid_loader)))","9c5e0c75":"state = torch.load('checkpoint.pth')\npymodel_mlp.load_state_dict(state)","8c68c0e6":"torch_test_loss  = []\ntorch_test_acc   = []\n\nfor e in range(1):\n    testing_loss = 0\n    running_test = 0\n    acc_test = 0\n    pymodel_mlp.eval()\n    for image, label in testing_loader:\n        image = image.to(device)\n        label = label.to(device)\n        out = pymodel_mlp(image.float())\n        loss = criterion(out, label)\n        top_p, top_class = torch.exp(out).topk(1, dim = 1)\n        equal = top_class == label.view(top_class.shape)\n        accuracy = torch.mean(equal.type(torch.FloatTensor))\n        running_test += loss.item()\n        acc_test += accuracy.item()\n    testing_loss = running_test\/len(testing_loader)\n    torch_test_loss.append(testing_loss)\n    torch_test_acc.append(acc_test\/len(testing_loader))\n    print('Epoch : %s\\nTesting_error : %s\\nAccuracy_test : %s\\n----------------' %(e+1, testing_loss, acc_test\/len(testing_loader)))","862b914f":"state = torch.load('checkpoint_cnn.pth')\npymodel_cnn.load_state_dict(state)\n\ntorch_test_loss_cnn  = []\ntorch_test_acc_cnn   = []\n\nfor e in range(1):\n    testing_loss = 0\n    running_test = 0\n    acc_test = 0\n    pymodel_cnn.eval()\n    with torch.no_grad():\n        for image, label in testing_loader:\n            image = image.to(device)\n            label = label.to(device)\n            out = pymodel_cnn(image.float())\n            loss = criterion(out, label)\n            top_p, top_class = torch.exp(out).topk(1, dim = 1)\n            equal = top_class == label.view(top_class.shape)\n            accuracy = torch.mean(equal.type(torch.FloatTensor))\n            running_test += loss.item()\n            acc_test += accuracy.item()\n    testing_loss = running_test\/len(testing_loader)\n    torch_test_loss_cnn.append(testing_loss)\n    torch_test_acc_cnn.append(acc_test\/len(testing_loader))\n    print('Epoch : %s\\nTesting_error : %s\\nAccuracy_test : %s\\n----------------' %(e+1, testing_loss, acc_test\/len(testing_loader)))","c9812c96":"Load data t\u1eeb \u1ed5 \u0111\u0129a b\u1eb1ng ph\u01b0\u01a1ng th\u1ee9c read_csv() c\u1ee7a pandas.","19c4e470":"# B\u01b0\u1edbc 2: X\u00e2y d\u1ef1ng ki\u1ebfn tr\u00fac m\u00f4 h\u00ecnh\nCh\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng ki\u1ebfn tr\u00fac m\u1ea1ng v\u00e0 hu\u1ea5n luy\u1ec7n n\u00f3 tr\u00ean t\u1eadp train. Li\u00ean t\u1ee5c \u0111\u00e1nh gi\u00e1 n\u00f3 tr\u00ean t\u1eadp validation","03900849":"X\u00e2y d\u1ef1ng class k\u1ebf th\u1eeba t\u1eeb class Dataset, ta \u0111\u1eb7t t\u00ean l\u00e0 **FashionData**.\n\n* G\u1ed3m 2 ph\u01b0\u01a1ng th\u1ee9c: get_item( ) and len().\n* get_item( ) tr\u1ea3 v\u1ec1 nh\u1eefng h\u00ecnh \u1ea3nh v\u00e0 nh\u00e3n t\u01b0\u01a1ng \u1ee9ng v\u00e0 len( ) tr\u1ea3 v\u1ec1 s\u1ed1 l\u01b0\u1ee3ng ph\u1ea7n t\u1eed trong dataset.","8f01bfcd":"# B\u01b0\u1edbc 3: \u0110\u00e1nh g\u00eda k\u1ebft qu\u1ea3 m\u00f4 h\u00ecnh tr\u00ean t\u1eadp test\nLoad m\u00f4 h\u00ecnh t\u1ed1t nh\u1ea5t tr\u00ean MLP v\u00e0 ki\u1ec3m tra n\u00f3 tr\u00ean t\u1eadp test","3080350c":"**ACC tr\u00ean t\u1eadp test c\u1ee7a CNN l\u00e0 93.25%**","ab183666":"# B\u01b0\u1edbc 1: Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u","4f48e0f7":"## V\u1eady k\u1ebft qu\u1ea3 thu \u0111\u01b0\u1ee3c t\u1eeb m\u00f4 h\u00ecnh CNN t\u1ed1t h\u01a1n MLP. V\u1eady ta c\u1ea3i ti\u1ebfn th\u00e0nh c\u00f4ng","f46ff2c8":"**ACC tr\u00ean t\u1eadp test c\u1ee7a MLP l\u00e0 81.58%**","58d45d33":"Notebook n\u00e0y c\u00e0i \u0111\u1eb7t m\u1ea1ng h\u1ecdc s\u00e2u b\u1eb1ng Pytorch cho b\u1ed9 d\u1eef li\u1ec7u FashionMNIST. Ta c\u00e0i \u0111\u1eb7t 2 ki\u1ebfn tr\u00fac: Multi-layer Perceptron l\u00e0 m\u00f4 h\u00ecnh baseline v\u00e0 Convolutional Neural Network l\u00e0 m\u00f4 h\u00ecnh c\u1ea3i ti\u1ebfn \u0111\u1ec3 d\u1ef1 \u0111o\u00e1n c\u00e1c class c\u1ee7a b\u1ed9 d\u1eef li\u1ec7u","0788680e":"## 2.2) M\u00f4 h\u00ecnh c\u1ea3i ti\u1ebfn: Convolutional Neural Network","e529bf86":"Load m\u00f4 h\u00ecnh t\u1ed1t nh\u1ea5t tr\u00ean CNN v\u00e0 ki\u1ec3m tra n\u00f3 tr\u00ean t\u1eadp test","d540e4d6":"T\u1ea1o Dataloader cho t\u1eadp train, validation v\u00e0 test","4e2666cf":"## 2.1) M\u00f4 h\u00ecnh Baseline: Multi Layer Perceptron"}}