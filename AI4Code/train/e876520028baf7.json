{"cell_type":{"c82c7d71":"code","303ac279":"code","a09ae8e8":"code","52005a7c":"code","c4b57427":"code","adedfc1b":"code","69c9979a":"code","b28d79d4":"code","59dddbe2":"code","b282e092":"code","caecc011":"code","c9c305dd":"code","6d51325b":"code","54e89981":"code","e2bd72e2":"markdown","f34e46f4":"markdown","e7608df4":"markdown","3a6b88f3":"markdown","e000edd6":"markdown","668e9c21":"markdown","05f6ae89":"markdown","e466c524":"markdown","969b940b":"markdown","c4c1f206":"markdown","8538b8d0":"markdown","506f76cf":"markdown","464ff39c":"markdown"},"source":{"c82c7d71":"import numpy as np \nimport pandas as pd\nimport os\nimport sklearn.datasets as dt\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nsn.set()\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","303ac279":"nomes = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"]\ndata = pd.read_csv(\"\/kaggle\/input\/creditscreening\/credit-screening.data\",na_values = '?', names=nomes, sep=\",\")\ndata.head()\n","a09ae8e8":"data.describe()","52005a7c":"data.isnull().sum()","c4b57427":"data.fillna({'A1':data['A1'].mode(0),'A4':data['A4'].mode(0), 'A5':data['A5'].mode(0), 'A6':data['A6'].mode(0), 'A7':data['A7'].mode(0)}, inplace= True)\ndata","adedfc1b":"data.fillna({'A2':data['A2'].mean()})\ndata.fillna({'A14':data['A14'].mean()})\n","69c9979a":"data[{'A1', 'A4', 'A5', 'A6','A7','A9','A10','A12','A13'}].astype('category')\n","b28d79d4":"data['A16'].astype('category').cat.codes","59dddbe2":"data = pd.get_dummies(data, columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])\ndata.head()\n","b282e092":"dic = dt.load_digits()\ndic.keys()","caecc011":"X = dic.data\ny = dic.target\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y)","c9c305dd":"y_train.shape\nX_train.shape","6d51325b":"y_test.shape\ny_train.shape","54e89981":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn\nmodel = knn.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_score = model.score(X_test, y_test)\ny_pred\ny_score","e2bd72e2":"4 - Preencha os campos das colunas com valores categ\u00f3ricos com a moda dos valores da coluna, para isso use a fun\u00e7\u00e3o fillna( ) e moda( )\n    * defina um vetor com as colunas a serem alteradas\n    * use um la\u00e7o para varrer o vetor   (for n in colunas: df.fillna...)","f34e46f4":"2 - Execute a fun\u00e7\u00e3o describe para ver um resumo estat\u00edstico descritivo","e7608df4":"1. Title: Credit Approval\n2. Sources: \n    (confidential)\n    Submitted by quinlan@cs.su.oz.au\n3.  Past Usage:\n    See Quinlan,\n    * \"Simplifying decision trees\", Int J Man-Machine Studies 27, Dec 1987, pp. 221-234.\n    * \"C4.5: Programs for Machine Learning\", Morgan Kaufmann, Oct 1992\n4.  Relevant Information:\n    This file concerns credit card applications.  All attribute names\n    and values have been changed to meaningless symbols to protect\n    confidentiality of the data.\n    This dataset is interesting because there is a good mix of\n    attributes -- continuous, nominal with small numbers of\n    values, and nominal with larger numbers of values.  There\n    are also a few missing values.\n5.  Number of Instances: 690\n6.  Number of Attributes: 15 + class attribute\n7.  Attribute Information:\n    A1:\tb, a.\n    A2:\tcontinuous.\n    A3:\tcontinuous.\n    A4:\tu, y, l, t.\n    A5:\tg, p, gg.\n    A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n    A7:\tv, h, bb, j, n, z, dd, ff, o.\n    A8:\tcontinuous.\n    A9:\tt, f.\n    A10:\tt, f.\n    A11:\tcontinuous.\n    A12:\tt, f.\n    A13:\tg, p, s.\n    A14:\tcontinuous.\n    A15:\tcontinuous.\n    A16: +,-         (class attribute)\n8.  Missing Attribute Values:\n    37 cases (5%) have one or more missing values.  The missing\n    values from particular attributes are:\n    A1:  12 ; A2:  12; A4:   6;  A5:   6; A6:   9;   A7:   9;    A14: 13\n9.  Class Distribution\n      +: 307 (44.5%)    -: 383 (55.5%)","3a6b88f3":"*  Colunas Categ\u00f3ricas: A1, A4, A5, A6, A7, A9, A10, A12, A13\n*  Colunas Categ\u00f3ricas com valores faltantes : A1, A4, A5, A6, A7 preencher com a moda (valor que mais aparece na coluna)\n*  Colunas com valores cont\u00ednuos: A2, A3, A8, A11, A14, A15\n*  Colunas com valores cont\u00ednuos com valores faltantes:  A2 e A14 preencher com m\u00e9dia","e000edd6":"6 - transforme todas as colunas com valores categ\u00f3ricos para o tipo \"category\"  use a fun\u00e7\u00e3o astype\n        * Colunas Categ\u00f3ricas: A1, A4, A5, A6, A7, A9, A10, A12, A13","668e9c21":"7 - Transforme a coluna objetivo  A16 primeiro para o tipo category e depois fa\u00e7a a codifica\u00e7\u00e3o num\u00e9rica utiliando a fun\u00e7ao df[\"A16\"].cat.codes","05f6ae89":"5 - Preencha os campos faltantes das colunas com valores cont\u00ednuos com a m\u00e9dia\n        * Colunas com valores cont\u00ednuos com valores faltantes:  A2 e A14","e466c524":"11 - Execute o algoritmo de \u00c1rvore de Decis\u00e3o, guarde o resultado da predi\u00e7\u00e3o em uma nova coluna predictAD","969b940b":"8 - utilize a fun\u00e7\u00e3o pd.get_dummies para transformar todas as colunas categ\u00f3ricas para indicadores de vari\u00e1veis. \n### df = pd.get_dummies( df, columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])","c4c1f206":"1 - Importar arquivo (credit-screening.data) procure o dataset no Kaggle, caso n\u00e3o encontre, importe o arquivo dispon\u00edvel no Google Classroom. Importe o arquivo substituindo valores faltantes \"?\" por NaN e inserir o nome das colunas utilizando o vetor abaixo.\n\n#### nomes = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"]5 - ","8538b8d0":"10 - Execute o algoritmo dos K vizinhos mais pr\u00f3ximos com K=3, guarde o resultado da predi\u00e7\u00e3o em uma nova coluna do dataframe \"predictKNN\"","506f76cf":"3 - utilize   df.isnull().sum() para saber em quais colunas h\u00e1 valores faltantes NaN\n","464ff39c":"9 - utilize train_test_split para criar bases de treino e teste"}}