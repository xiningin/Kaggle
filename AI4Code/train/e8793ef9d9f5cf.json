{"cell_type":{"de2815fb":"code","ac73a313":"code","54d24493":"code","34ac15f3":"code","bf14d0b2":"code","22940dda":"code","b13f8793":"code","61b46de6":"code","b9d83dbb":"code","8f594295":"code","2a8cff61":"code","e4661e83":"code","49133b0b":"code","08308b1b":"code","c47d1c34":"code","ce9e0b80":"code","6147af55":"code","2878bfb5":"markdown","7c14ed8c":"markdown","b5944268":"markdown","7925c350":"markdown"},"source":{"de2815fb":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndf = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","ac73a313":"df.info()  #Basic informations","54d24493":"#checking which are categorical columns\n\nfor feature in df.columns:\n    if df[feature].dtype not in ['int64', 'float64']:    #dtype means datatype\n        print(f\"{feature}:{df[feature].unique()}\")","34ac15f3":"#changing total charges column to float since total charges actually looks like number ;)\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')\ndf = df.dropna()  #Dropping null values\ndf = df.drop(['customerID'], axis = 1)  #dropping customer id because it is irrelevant for modelling\n\ndf.info()","bf14d0b2":"#encoding categorical variables to numeric ones\nfrom sklearn.preprocessing import LabelEncoder\nfor c in df.columns:\n    if df[c].dtype=='object':    #Since we are encoding object datatype to integer\/float\n        lbl = LabelEncoder()\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)","22940dda":"df.head()  #To check if properly encoded","b13f8793":"df.info()","61b46de6":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.figure(figsize = (18,10))\n\nsns.heatmap(df.corr(), annot =True)   #Basic correlation plot to understand which features are correlated","b9d83dbb":"df.hist(figsize=(20,16))\nplt.show()  #showing the charts of different columns\n#This also helps in finding number of counts in each column","8f594295":"zero  = df[df['Churn']==0]   #zero values in outcome column\none = df[df['Churn']==1]  # one values in outcome column\nfrom sklearn.utils import resample\ndf_minority_upsampled = resample(one, replace = True, n_samples = 5000) \n#concatenate\ndf = pd.concat([zero, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","2a8cff61":"zero  = df[df['PhoneService']==0]   #zero values in outcome column\none = df[df['PhoneService']==1]  # one values in outcome column\nfrom sklearn.utils import resample\ndf_minority_upsampled = resample(zero, replace = True, n_samples = 6000) \n#concatenate\ndf = pd.concat([one, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","e4661e83":"df.hist(figsize=(20,16))\nplt.show()","49133b0b":"#Checking which columns are mostly correlated with the target\ndf.corr().abs()['Churn'].sort_values(ascending = False)","08308b1b":"X = df[['Contract', 'tenure', 'TechSupport', 'OnlineSecurity', 'TotalCharges', 'PaperlessBilling',\n       'DeviceProtection', 'Dependents', 'OnlineBackup', 'SeniorCitizen', 'MonthlyCharges',\n       'PaymentMethod', 'Partner', 'PhoneService']] #taking only relevant columns\ny = df['Churn']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","c47d1c34":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom xgboost import XGBClassifier\nxgb =XGBClassifier(eval_metric = 'auc', use_label_encoder=False, objective = 'binary:logistic')\n#eval metric is auc because for classification auc metric is best\n#XGBoost\n#parameters for xgboost\n\nparams_xgb = {'n_estimators': [100,400,800], 'learning_rate': [0.3,0.5,1],\n             'max_depth': [6,8,15]}\ngs_xgb =  GridSearchCV(xgb, param_grid=params_xgb, cv=5)\ngs_xgb.fit(X_train, y_train)\nprint(\"Best parameters for XGBoost:\", gs_xgb.best_params_)\n","ce9e0b80":"#got the best parameters above\nxgb = XGBClassifier(learning_rate = 0.3, max_depth = 25, n_estimators = 400,\n                    eval_metric = 'auc',\n                    use_label_encoder=False, \n                    objective = 'binary:logistic', random_state = 42)\nxgb.fit(X_train, y_train)\n","6147af55":"y_pred = xgb.predict(X_test)\n#printing the classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","2878bfb5":"Churn column handled, let's do it for Phoneservice","7c14ed8c":"# 94% accuracy XGBOOST","b5944268":"## Do upvote if you like it or fork it, this helps us to get motivated and work more :)","7925c350":"Data is highly imbalanced since Customer churn column has 1 values less than 2000, and 0 value more than 5000. Imbalance is same for phone service and online backup!"}}