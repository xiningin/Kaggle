{"cell_type":{"6b96178b":"code","c9a68bb6":"code","8dbe3106":"code","5f58b394":"code","dd4169ad":"code","6804eadc":"code","6ddea160":"code","487dbe63":"code","b2513ea2":"code","12146e64":"code","2e74986b":"code","9158f93c":"code","ca2c9e5e":"code","f34290be":"code","f8060444":"code","56f84de9":"code","5c33b8d5":"code","3d853650":"code","f5d883b4":"code","80d8c262":"code","a77916d0":"code","6b60e620":"code","12d1c930":"code","e24e3573":"code","0530a64f":"code","8213293d":"code","255f4f2f":"code","8f141fa6":"code","04c5e0c6":"markdown","a03ed52c":"markdown","bbfa59dc":"markdown","fe7c0fcf":"markdown","937ce782":"markdown","9abc5778":"markdown","ce120784":"markdown","8bfb9673":"markdown","725322a9":"markdown","2e2fb0c2":"markdown","23ce9fd2":"markdown"},"source":{"6b96178b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c9a68bb6":"#\u9996\u5148\u5728excel\u4e2d\u5c06\u6240\u6709\u6570\u636e\u4e2d\u6ea2\u51fa\u5355\u51431.79769313e+308\u5168\u90e8\u6e05\u7a7a,\u518d\u8fdb\u884c\u6570\u636e\u8f7d\u5165\n#03\u5e741387\u884c\ndata_03 = pd.read_excel('..\/input\/GLAS_Landsat_2003.xlsx')\n#04\u5e741084\u884c\ndata_04 = pd.read_excel('..\/input\/GLAS_Landsat_2004.xlsx')\n#05\u5e741020\u884c\ndata_05 = pd.read_excel('..\/input\/GLAS_Landsat_2005.xlsx')\n#06\u5e741404\u884c\ndata_06 = pd.read_excel('..\/input\/GLAS_Landsat_2006.xlsx')","8dbe3106":"data_03.head()","5f58b394":"#\u53bb\u638903\u5e74\u83ab\u540d\u5176\u5999\u591a\u51fa\u6765\u7684\u7b2c30\u5217\ndata_03.drop(data_03.columns[30],axis=1,inplace=True) \n#\u53bb\u6389\u65e0\u7528\u5217\nuseless_columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19, 21,22,23]\ndata_03.drop(data_04.columns[useless_columns],axis=1,inplace=True) \ndata_04.drop(data_04.columns[useless_columns],axis=1,inplace=True) \ndata_05.drop(data_05.columns[useless_columns],axis=1,inplace=True)\ndata_06.drop(data_06.columns[useless_columns],axis=1,inplace=True) \n\ndata_03.info()","dd4169ad":"means = data_03['b1_extract'].get_values().mean()\ndata_03['b1_extract'] = data_03['b1_extract'].apply(lambda x : means if (x>(1.5*means)) else x ).apply(lambda x: means if x<0.3*means else x)","6804eadc":"#\u4f5c\u51fa\u76f8\u5173\u6027\u56fe\nplt.figure(figsize=(15,15))\ncorrDf=data_03.corr()\nmask=np.array(corrDf)\nmask[np.tril_indices_from(mask)]=False\nplt.subplot(2,2,1)\nsn.heatmap(corrDf,mask=mask,annot=True,square=True)\n\n\ncorrDf=data_04.corr()\nmask=np.array(corrDf)\nmask[np.tril_indices_from(mask)]=False\nplt.subplot(2,2,2)\nsn.heatmap(corrDf,mask=mask,annot=True,square=True)\n\ncorrDf=data_05.corr()\nmask=np.array(corrDf)\nmask[np.tril_indices_from(mask)]=False\nplt.subplot(2,2,3)\nsn.heatmap(corrDf,mask=mask,annot=True,square=True)\n\n\ncorrDf=data_06.corr()\nmask=np.array(corrDf)\nmask[np.tril_indices_from(mask)]=False\nplt.subplot(2,2,4)\nsn.heatmap(corrDf,mask=mask,annot=True,square=True)\n\n\nplt.show()","6ddea160":"def data_split(df, part1_percent=0.8, seed=None):\n    np.random.seed(seed)\n    perm = np.random.permutation(df.index)\n    m = len(df)\n    part1_end = int(part1_percent * m)\n    part1 = df.iloc[perm[:part1_end]]\n    part2 = df.iloc[perm[part1_end:]]\n    return part1, part2","487dbe63":"train_valid_03, test_03 = data_split(data_03)\ntrain_valid_04, test_04 = data_split(data_04)\ntrain_valid_05, test_05 = data_split(data_05)\ntrain_valid_06, test_06 = data_split(data_06)","b2513ea2":"train_valid_data = pd.concat([train_valid_03, train_valid_04, train_valid_05, train_valid_06])","12146e64":"plt.figure(figsize=(15,15))\ncorrDf=train_valid_data.corr()\nmask=np.array(corrDf)\nmask[np.tril_indices_from(mask)]=False\nplt.subplot(2,2,1)\nsn.heatmap(corrDf,mask=mask,annot=True,square=True)\nplt.show()","2e74986b":"train_valid_x = train_valid_data.drop(['Tree_Heigh'], axis=1)\ntrain_valid_y = train_valid_data['Tree_Heigh']\n#train_valid_x = train_valid_data.drop(['map_y','Tree_Heigh'], axis=1)\n#train_valid_y = train_valid_data['map_y']","9158f93c":"from sklearn.cross_validation import KFold\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.svm import SVR","ca2c9e5e":"ridge_regression = Ridge()\n\nparameters = {'alpha': [100, 20, 10, 7, 5, 3, 1, 0.5, 0.1, 0.005, 0.001, 0.0005, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001, 0],\n              'solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n             }\ngrid = GridSearchCV(ridge_regression, parameters, cv=5)\ngrid.fit(train_valid_x,train_valid_y)\nclf = grid.best_estimator_\nprint(clf)","f34290be":"clf.fit(train_valid_x, train_valid_y)\nacc_ridge = clf.score(test_03.drop(['Tree_Heigh'], axis=1), test_03['Tree_Heigh'])\nacc_ridge","f8060444":"\"\"\"\nsvr = SVR()\nparameters = {'C':[10, 1, 0.1, 0.01, 0.01, 0.001, 0.0001],\n              'epsilon':[1, 0.1, 0.001, 0.0001, 0.00001],\n              'kernel':['poly', 'rbf', 'sigmoid'],\n              'gamma':['scale']\n             }\ngrid = GridSearchCV(svr, parameters, cv=5)\ngrid.fit(train_valid_x,train_valid_y['Tree_Heigh'])\nclf = grid.best_estimator_\nprint(clf)\n\"\"\"","56f84de9":"#\u4ee5\u4e0b\u662f\u5f97\u51fa\u7684\u6700\u4f18\u6a21\u578b, \u4f46\u662fr^2\u8fd8\u662f\u63a5\u8fd1\u4e8e0\nclf = SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.001, gamma='scale',\n  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\nclf.fit(train_valid_x, train_valid_y)\nacc_svr = clf.score(test_03.drop(['Tree_Heigh'], axis=1), test_03['Tree_Heigh'])\nacc_svr","5c33b8d5":"#\u63a5\u4e0b\u6765\u6c42rmse\nfrom sklearn.metrics import mean_squared_error\nyp = clf.predict(test_03.drop(['Tree_Heigh'], axis=1))\nrmse = mean_squared_error(test_03['Tree_Heigh'],yp)\nrmse","3d853650":"#\u4ee5\u4e0b\u662f\u5f97\u51fa\u7684\u6700\u4f18\u6a21\u578b, \u4f46\u662fr^2\u8fd8\u662f\u63a5\u8fd1\u4e8e0\nclf = SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.001, gamma='scale',\n  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\nclf.fit(train_valid_x[['b2_extract', 'b4_extract', 'b5_extract']], train_valid_y)\nacc_svr = clf.score(test_03[['b2_extract', 'b4_extract', 'b5_extract']], test_03['Tree_Heigh'])\nacc_svr\n","f5d883b4":"test_test = train_valid_03.sample(frac=0.3)\nclf = SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.001, gamma='scale',\n  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\nclf.fit(train_valid_03[['b2_extract', 'b4_extract', 'b5_extract']], train_valid_03['Tree_Heigh'])\nacc_svr = clf.score(test_test[['b2_extract', 'b4_extract', 'b5_extract']], test_test['Tree_Heigh'])\nacc_svr\n","80d8c262":"train_valid_03.head()","a77916d0":"data_03.plot.scatter(x=['b1_extract'],y=['Tree_Heigh'])","6b60e620":"data_03['map_y'] = np.log(data_03['Tree_Heigh'])\ndata_03['map_x'] = data_03['b1_extract'] ** -5\ndata_03.head()","12d1c930":"plt.figure(figsize=[20,10])\nplt.scatter(data_03['map_x'],data_03['map_y'])\nplt.xlim((0,40))\n","e24e3573":"data_03['map_y'] = data_03['Tree_Heigh']** -2\ntrain_03,test_03 = data_split(data_03)\ntrain_03_x = train_03.drop(['map_y','Tree_Heigh'], axis=1)\ntrain_03_y = train_03['map_y']\ntest_03_x = test_03.drop(['map_y','Tree_Heigh'], axis=1)\ntest_03_y = test_03['map_y']","0530a64f":"from sklearn.linear_model import LassoCV\nlasso = LassoCV()\nlasso.fit(train_03_x,train_03_y)","8213293d":"predict_03_x = lasso.predict(test_03_x)\n\nlasso.score(test_03_x,test_03_y)","255f4f2f":"predict_03_x**(-1\/2)","8f141fa6":"test_03_y.get_values()\nplt.figure()\nplt.scatter(x=test_03_y.get_values()** (-1\/2), y=predict_03_x** (-1\/2))\n","04c5e0c6":"### \u8f7d\u5165\u76f8\u5173\u5e93\u548c\u6570\u636e","a03ed52c":"#### \u4f7f\u7528svr\u8fdb\u884c\u62df\u5408","bbfa59dc":"\u7ed3\u679c\u975e\u5e38\u662f\u975e\u5e38\u4e0d\u51c6\u786e, \u6240\u4ee5\u9700\u8981\u8fdb\u884c\u4e0b\u4e00\u4e2a\u65b9\u6cd5\u7684\u64cd\u4f5c","fe7c0fcf":"#### \u4f7f\u7528RidgeRegression","937ce782":"\u89c2\u5bdf\u76f8\u5173\u6027, \u53d1\u73b0123\u5217\u76f8\u5173\u6027\u975e\u5e38\u5f3a,  \u7b2c\u4e94\u5217\u548c\u7b2c\u516d\u5217\u6570\u636e\u4e5f\u6781\u5176\u76f8\u50cf, \u5e94\u8be5\u8fdb\u884c\u5408\u5e76\u5904\u7406","9abc5778":"#### \u5c06\u5408\u5e76\u540e\u6570\u636e\u8fdb\u884c\u76f8\u5173\u5ea6\u5bf9\u6bd4, \u53d1\u73b0\u76f8\u5173\u6027\u53d8\u5316\u5e76\u4e0d\u5927, \u6545\u5e94\u8be5\u53ef\u4ee5\u5408\u5e76\u4e3a\u4e00\u4e2a\u6a21\u578b","ce120784":"### \u5c06\u6570\u636e\u96c6\u5206\u4e3atrain_validate, test \u4e24\u90e8\u5206,\n\u5206\u522b\u4e3a80: 20\n\u7136\u540e\u5bf9 train_valid\u8fdb\u884ck\u6298\u8bad\u7ec3","8bfb9673":"\u53d1\u73b0\u6a21\u578b\u66f4\u5dee\u4e86","725322a9":"\u4e0d\u8bba\u662f\u5bf9\u5355\u5e74\u8fdb\u884c\u5efa\u6a21\u8fd8\u662f\u56db\u5e74\u4e00\u8d77\u6765\u5efa\u6a21, \u51c6\u786e\u6027\u4f9d\u7136\u975e\u5e38\u4f4e\u4e0b, \u73b0\u5728\u6000\u7591\u662f\u6570\u636e\u95ee\u9898\n\u63a5\u4e0b\u6765\u7ee7\u7eed\u5bf9\u6570\u636e\u8fdb\u884c\u5904\u7406\n\u6839\u636e\u76f8\u5173\u6027\u56fe, \u53ef\u4ee5\u770b\u51fa\u53ea\u9700\u8981b2, b4, b5\u6765\u8fdb\u884c\u62df\u5408","2e2fb0c2":"#### \u5148\u7528\u65b9\u6cd5\u4e00: \u5c06\u56db\u5e74\u7684\u6570\u636e\u8fdb\u884c\u5206\u5c42\u62bd\u6837, \u5185\u90e8\u8fdb\u884c\u968f\u673a\u62bd\u6837, \u518d\u8fdb\u884c\u5408\u5e76","23ce9fd2":"### \u53bb\u6389\u65e0\u7528\u5217"}}