{"cell_type":{"417540c0":"code","a101300a":"code","97b2fefa":"code","ea91b774":"code","6850eeee":"code","b256c78a":"code","e5dc90de":"code","653f3a21":"code","1f223b7d":"code","4c595492":"code","65d3fcd3":"code","225766c2":"code","c3651ccc":"code","663982e0":"code","2f9363d8":"code","344f1208":"code","b54fd77a":"code","39217f71":"code","6b36666f":"code","a411dada":"markdown","f596cce6":"markdown","38f747df":"markdown","6541e4b5":"markdown","abc9d4d0":"markdown","6927cba3":"markdown"},"source":{"417540c0":"# load data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nplt.style.use('ggplot') \n\nitems  = pd.read_csv('..\/input\/items.csv')\ntrain = pd.read_csv('..\/input\/sales_train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nitem_category = pd.read_csv('..\/input\/item_categories.csv')\nshops = pd.read_csv('..\/input\/shops.csv')\n\nDEBUG = False\n\n\ndef eda(data):\n    print(\"----------Top-5- Record----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types-----------\")\n    print(data.dtypes)\n    print(\"----------Missing value-----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n\ndef graph_insight(data):\n    if DEBUG:\n        print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8)\n    \ndef remove_duplicate(data, subset):\n    if DEBUG:\n        print('Before drop shape:', data.shape)\n    \n    before = data.shape[0]\n    data.drop_duplicates(subset, keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    \n    if DEBUG:\n        print('After drop shape:', data.shape)\n    \n    after = data.shape[0]\n    \n    if DEBUG:\n        print('Total Duplicate:', before-after)\n\n    \ndef remove_unreasonable_data(data):\n    size = 50\n\n    if DEBUG:\n        print(\"Max of item price records:\",data.nlargest(size, 'item_price'))\n        print(\"Min of item price records:\",data.nsmallest(size, 'item_price'))\n    \n        print(\"Max of item cnt day records:\",data.nlargest(size, 'item_cnt_day'))\n        print(\"Min of item cnt day records:\",data.nsmallest(size, 'item_cnt_day'))\n    \n    # remove item_price <= 0 and item_price > 300000\n    # item_cnt_day < 0 means customers return the sold goods.\n    error_train_data = data[(data.item_price <= 0) | (data.item_price == None) | (data.item_price > 300000)]\n    data.drop(error_train_data.index, inplace=True)\n\nprint(\"Rows to train\")\nprint(train.count())\nitem_category.head(5)\ntrain.head(5)","a101300a":"items.head(5)\ntrain.head(5)\nitem_category.head(5)\nshops.head(5)\n\ntrain.head(5)","97b2fefa":"items.head(5)","ea91b774":"item_category.head(5)","6850eeee":"if DEBUG:\n    eda(train)\n\n# Drop Duplicate Data\nsubset = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_cnt_day', 'item_price']\n\nremove_duplicate(train, subset = subset)\nremove_unreasonable_data(train)\n\ntrain = pd.merge(train, items, how='outer', on='item_id')\ntrain.head(4)\n\ndel train['item_name']\n# del train['item_category_id_x']\n# del train['item_category_id_y']\n# del train['item_name_x']\n# del train['item_name_y']\n# result = train.drop(['item_name'], axis=1)\n# result.head(4)\n\ntrain.head(4)\ntrain.to_csv('result.csv')","b256c78a":"train.head(20)\n\ntest_df = train.groupby(['date_block_num', 'shop_id', 'item_id'], as_index=False).agg({'item_cnt_day': 'sum'})\n\n#test_df.head(100)\n# test_df.to_csv('test.csv')","e5dc90de":"count_price = train.item_price.value_counts().sort_index(ascending=False)\nplt.subplot(221)\ncount_price.hist(figsize=(20,6))\nplt.xlabel('Item Price', fontsize=20)\nplt.title('Original Distiribution')\n\n# log1p() and exmp1()\n# log1p = log\uff08x+1\uff09\n# log1p \u53ef\u4ee5\u8ba9\u6570\u636e\u66f4\u52a0\u5e73\u6ed1\uff0c\u66f4\u670d\u4ece\u9ad8\u65af\u5206\u5e03\uff0c\u65b9\u4fbf\u540e\u9762\u66f4\u597d\u5730\u8fdb\u884c\u5206\u7c7b\n# \u4e5f\u53ef\u4ee5\u907f\u514d\u590d\u503c\u95ee\u9898\uff08\u4e00\u4e2a\u81ea\u53d8\u91cf\u5bf9\u5e94\u591a\u4e2a\u56e0\u53d8\u91cf\uff09\n\n# \u7531\u4e8e\u6211\u4eec\u4f7f\u7528\u4e86 log1p()\uff0c\u5bf9\u6570\u636e\u8fdb\u884c\u4e86\u538b\u7f29\uff0c\u6240\u4ee5\u540e\u9762\u8fd8\u9700\u8981\u518d\u8fdb\u884c\u4e00\u6b21 expm1() \u7684\u9006\u8fd0\u7b97\n\nplt.subplot(222)\ntrain.item_price.map(np.log1p).hist(figsize=(20,6))\nplt.xlabel('Item Price')\nplt.title('log1p Transformation')\ntrain.loc[:,'item_price'] = train.item_price.map(np.log1p)","653f3a21":"count_price = train.date_block_num.value_counts().sort_index(ascending=False)\nplt.subplot(221)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('Date Block')\nplt.title('Original Distiribution')\n\ncount_price = train.shop_id.value_counts().sort_index(ascending=False)\nplt.subplot(222)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('shop_id')\nplt.title('Original Distiribution')\n\ncount_price = train.item_id.value_counts().sort_index(ascending=False)\nplt.subplot(223)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('item_id')\nplt.title('Original Distiribution')\n\n","1f223b7d":"l = list(item_category.item_category_name)\nl_cat = l\n\n\nfor ind in range(1,8):\n    l_cat[ind] = 'Access'\n\nfor ind in range(10,18):\n    l_cat[ind] = 'Consoles'\n\nfor ind in range(18,25):\n    l_cat[ind] = 'Console Games'\n\nfor ind in range(26,28):\n    l_cat[ind] = 'Mobile games'\n\nfor ind in range(28,32):\n    l_cat[ind] = 'CD games'\n\nfor ind in range(32,37):\n    l_cat[ind] = 'Card'\n\nfor ind in range(37,43):\n    l_cat[ind] = 'Movie'\n\nfor ind in range(43,55):\n    l_cat[ind] = 'Books'\n\nfor ind in range(55,61):\n    l_cat[ind] = 'Music'\n\nfor ind in range(61,73):\n    l_cat[ind] = 'Gifts'\n\nfor ind in range(73,79):\n    l_cat[ind] = 'Soft'\n\n\nitem_category['cats'] = l_cat\nitem_category.head()","4c595492":"train['date'] = pd.to_datetime(train.date, format=\"%d.%m.%Y\")\ntrain.head()","65d3fcd3":"# \u900f\u89c6\u8868, \u5bf9\u6570\u636e\u52a8\u6001\u6392\u5e03\u5e76\u4e14\u5206\u7c7b\u6c47\u603b\np_df = train.pivot_table(index=['shop_id','item_id'], columns='date_block_num', values='item_cnt_day', aggfunc='sum').fillna(0.0)\np_df.head(50)","225766c2":"## \u91cd\u5efa\u7d22\u5f15\uff0c\u6240\u4ee5\u9700\u8981\u628a str -> int\n\ntrain_cleaned_df = p_df.reset_index()\ntrain_cleaned_df['shop_id']= train_cleaned_df.shop_id.astype('str')\ntrain_cleaned_df['item_id']= train_cleaned_df.item_id.astype('str')\n\nitem_to_cat_df = items.merge(item_category[['item_category_id','cats']], how=\"inner\", on=\"item_category_id\")[['item_id','cats']]\nitem_to_cat_df[['item_id']] = item_to_cat_df.item_id.astype('str')\n\ntrain_cleaned_df = train_cleaned_df.merge(item_to_cat_df, how=\"inner\", on=\"item_id\")\n\n# Encode Categories\nfrom sklearn import preprocessing\n\nnumber = preprocessing.LabelEncoder()\ntrain_cleaned_df[['cats']] = number.fit_transform(train_cleaned_df.cats)\n# \u4e00\u5171\u662f34\u4e2a\u6708\u7684\u6570\u636e\uff0c\u6240\u4ee5\u540e\u9762\u52a0\u4e86 list(range(34))\ntrain_cleaned_df = train_cleaned_df[['shop_id', 'item_id', 'cats'] + list(range(34))]\ntrain_cleaned_df.head()","c3651ccc":"import xgboost as xgb\nparam = {'max_depth':10, \n         'subsample':1,\n         'min_child_weight':0.5,\n         'eta':0.3, \n         'num_round':1000, \n         'seed':1,\n         'silent':0,\n         'eval_metric':'rmse'}\n\nprogress = dict()\nxgbtrain = xgb.DMatrix(train_cleaned_df.iloc[:,  (train_cleaned_df.columns != 33)].values, train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values)\nwatchlist  = [(xgbtrain,'train-rmse')]\n\nbst = xgb.train(param, xgbtrain)\npreds = bst.predict(xgb.DMatrix(train_cleaned_df.iloc[:,  (train_cleaned_df.columns != 33)].values))\nfrom sklearn.metrics import mean_squared_error \nrmse = np.sqrt(mean_squared_error(preds,train_cleaned_df.iloc[:, train_cleaned_df.columns == 33].values))\nprint(rmse)","663982e0":"xgb.plot_importance(bst)","2f9363d8":"apply_df = test\napply_df['shop_id']= apply_df.shop_id.astype('str')\napply_df['item_id']= apply_df.item_id.astype('str')\n\napply_df = test.merge(train_cleaned_df, how = \"left\", on = [\"shop_id\", \"item_id\"]).fillna(0.0)\napply_df.head()","344f1208":"# Move to one month front\nd = dict(zip(apply_df.columns[4:],list(np.array(list(apply_df.columns[4:])) - 1)))\n\napply_df  = apply_df.rename(d, axis = 1)\n\nprint('========')\ntrain.count()\napply_df.count()","b54fd77a":"preds = bst.predict(xgb.DMatrix(apply_df.iloc[:, (apply_df.columns != 'ID') & (apply_df.columns != -1)].values))","39217f71":"# Normalize prediction to [0-20]\npreds = list(map(lambda x: min(20,max(x,0)), list(preds)))\nsub_df = pd.DataFrame({'ID':apply_df.ID, 'item_cnt_month': preds, 'shop_id': apply_df.shop_id, 'item_id': apply_df.item_id })\nsub_df.describe()","6b36666f":"sub_df.to_csv('Submission_Predict Sales.csv',index=False)","a411dada":"# Convert Date Column data type from object to Date ","f596cce6":"# 1. Sales Train Data Cleaning","38f747df":"# Model Building","6541e4b5":"# 2. Sales Per Month Count","abc9d4d0":"# Map the Items","6927cba3":"# Distribution Checking"}}