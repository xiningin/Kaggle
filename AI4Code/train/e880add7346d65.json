{"cell_type":{"0a5ac4ab":"code","b5158b8b":"code","8310fcb3":"code","7190bb90":"code","a20ed4c9":"code","6d620ce4":"code","bfda2e8f":"code","8590a801":"code","ac57b4d5":"markdown","d3b2e1ed":"markdown","937a419f":"markdown","bc3601e9":"markdown","07f66ee7":"markdown","bb37e3f8":"markdown","bf146ded":"markdown","f4833c2d":"markdown"},"source":{"0a5ac4ab":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom functools import partial\nimport json\nimport glob\nimport pickle\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets","b5158b8b":"with open('..\/input\/sartorius-create-mask-dataset\/mask_dict.pkl', 'rb') as f:\n    mask_dict = pickle.load(f)","8310fcb3":"mask_dict['0030fd0e6378']","7190bb90":"# Function to get hardware strategy\ndef get_hardware_strategy():\n    try:\n        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n        # set: this is always the case on Kaggle.\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        tf.config.optimizer.set_jit(True)\n    else:\n        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n        strategy = tf.distribute.get_strategy()\n\n    return tpu, strategy\n\ntpu, strategy = get_hardware_strategy()","a20ed4c9":"if strategy.num_replicas_in_sync > 1:\n    DS_PATH = KaggleDatasets().get_gcs_path('sartorius-cell-instance-segmentation') # TPU\nelse:\n    DS_PATH = '..\/input\/sartorius-cell-instance-segmentation' # GPU or CPU","6d620ce4":"train_files = tf.io.gfile.glob(DS_PATH+'\/train\/*.png')\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 8 # adapt to needs\n\nIMAGE_SIZE = [520, 704]\nGRAYSCALE = True # set to false for color images\n\n# convert mask dictionary to TF hash table of encoded PNG masks\nblank = tf.io.encode_png(np.zeros((IMAGE_SIZE[0],IMAGE_SIZE[1],1), dtype=np.uint8)) \nmasks = []\nm_values = [*mask_dict.values()] # extract values\nfor i in range(len(mask_dict)):\n    masks.append(tf.io.encode_png(np.expand_dims(m_values[i]['mask'], -1)))\nmask_init = tf.lookup.KeyValueTensorInitializer([*mask_dict], masks)\nmask_table = tf.lookup.StaticHashTable(mask_init, default_value=blank)\n\n# read .png file and create mask from lookup table\ndef _read_png(filename):\n    img = tf.io.read_file(filename)\n    iid = tf.strings.split(tf.strings.split(filename, '\/')[-1], '.')[0]\n    mask = tf.io.decode_png(mask_table.lookup(iid))\n    img = tf.image.decode_png(img, channels=1)\n    img = tf.expand_dims(img, -1)\n    img = tf.cast(img, tf.float32)\n    img = img \/ 255.\n    if not GRAYSCALE:\n        img = tf.image.grayscale_to_rgb(img)\n        img = tf.reshape(img, [*IMAGE_SIZE, 3])\n    else:\n        img = tf.reshape(img, [*IMAGE_SIZE, 1])\n    return img, mask\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(train_files)\ntrain_ds = train_ds.map(_read_png, num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.shuffle(len(mask_dict))\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\ntrain_ds = train_ds.batch(BATCH_SIZE, drop_remainder=True)\ntrain_ds = train_ds.repeat()","bfda2e8f":"# fetch a batch\nimage_batch, mask_batch = next(iter(train_ds))","8590a801":"fig = plt.figure(figsize=(16,48))\nfor i in range(8):\n    axes = fig.add_subplot(8, 2, 2*i+1)\n    plt.setp(axes, xticks=[], yticks=[])\n    plt.imshow(image_batch[i].numpy(), cmap='gray')\n    axes = fig.add_subplot(8, 2, 2*i+2)\n    plt.setp(axes, xticks=[], yticks=[])\n    plt.imshow(mask_batch[i].numpy())\n    plt.tight_layout()","ac57b4d5":"# Intro\nIn this notebook we will create a Tensorflow dataset for segmentation. The dataset returns image and mask pairs. The dataset code runs on CPU, GPU and TPU.\n\nReferences:\n  * [Sartorius: Create Mask Dataset](https:\/\/www.kaggle.com\/mistag\/sartorius-create-mask-dataset)","d3b2e1ed":"# Dataset creation\nWe already created a mask dataset [here](https:\/\/www.kaggle.com\/mistag\/sartorius-create-mask-dataset). Next step is to create a TF dataset, which is quite straight forward. And the dataset fits in memory, so TPU can be supported without any private GCS bucket.   \nThere are three types of cells, but only one type per image, so masks can be binary.","937a419f":"![logo](https:\/\/cdn.freelogovectors.net\/wp-content\/uploads\/2018\/07\/tensorflow-logo.png)","bc3601e9":"HW strategy (works on CPU, GPU, TPU).","07f66ee7":"The dict format:","bb37e3f8":"Check if we are running on TPU, and set data path accordingly.","bf146ded":"Dataset creation. Note that the Python dictionary created [here](https:\/\/www.kaggle.com\/mistag\/sartorius-create-mask-dataset) is converted to a Tensorflow hash table.","f4833c2d":"# Test dataset\nFinally, test the dataset."}}