{"cell_type":{"02623d87":"code","23d35022":"code","582641b4":"code","f4858ff4":"code","dbbd4722":"code","37e1c014":"code","e528f6a5":"code","49747d3b":"code","6c73180d":"code","d2eb488d":"code","65fe6e35":"code","fcc6374e":"code","9373d989":"code","9cdf87ff":"code","e755aaa0":"code","364621c3":"code","c0505b50":"code","5c46eafc":"code","b9a80f33":"code","edbc1afe":"code","c8feeeb3":"code","82ef6fd3":"code","c0d55a0e":"code","991ddcce":"code","ab469fb9":"code","0a1d03e5":"code","1332512d":"code","9498fa69":"code","0e6162f8":"code","fbcd2160":"code","7b562e38":"code","62afe8da":"code","6edbae19":"code","9f599a14":"code","c853317c":"code","9aee8f25":"code","33f5bbd0":"code","c695c30d":"code","c0b823ec":"markdown","fb259554":"markdown","ab9d3a7c":"markdown","90ff3631":"markdown","f6a495c0":"markdown","7a5c2a43":"markdown","51b08fdc":"markdown","6a7a9846":"markdown","59b46c96":"markdown"},"source":{"02623d87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23d35022":"dataset = pd.read_csv(\"\/kaggle\/input\/wine-quality\/winequalityN.csv\")","582641b4":"dataset.head()  # looking into initial 5 rows of dataset","f4858ff4":"dataset.tail()  # looking into last 5 rows of dataset","dbbd4722":"dataset.describe()","37e1c014":"dataset.isnull().any()  ","e528f6a5":"dataset['fixed acidity'].fillna(dataset['fixed acidity'].mean(),inplace = True)\ndataset['volatile acidity'].fillna(dataset['volatile acidity'].mean(),inplace = True)\ndataset['citric acid'].fillna(dataset['citric acid'].mean(),inplace = True)\ndataset['residual sugar'].fillna(dataset['residual sugar'].mean(),inplace = True)\ndataset['chlorides'].fillna(dataset['chlorides'].mean(),inplace = True)\ndataset['pH'].fillna(dataset['pH'].mean(),inplace = True)\ndataset['sulphates'].fillna(dataset['sulphates'].mean(),inplace = True)","49747d3b":"dataset.isnull().any()  # Now we have removed all missing or null values and replaced them by the mean.","6c73180d":"dataset.corr()","d2eb488d":"import seaborn as sn\n\ncorrmat = dataset.corr()\nsn.heatmap(corrmat,annot = True)","65fe6e35":"dataset.quality.hist(bins=10)","fcc6374e":"# Now we will se the variations of each factor against the overall quality,\n\ncolumns = list(dataset.columns)\ncolumns.remove('type')\ncolumns.remove('quality')\n\n\nfor i in columns:\n  fig = plt.figure(figsize = (10,6))\n  sn.barplot(x = 'quality', y = i, data = dataset)","9373d989":"dataset = dataset.sample(frac=1).reset_index(drop=True)","9cdf87ff":"dataset.head()","e755aaa0":"dataset.tail()","364621c3":"for i in range(len(dataset['quality'])):\n    if dataset['quality'][i] <= 6.5:\n        dataset['quality'][i] = 0\n    else:\n        dataset['quality'][i] = 1\n        \n# We classify the good and bad wine with, using a certain threshold.","c0505b50":"lb = LabelEncoder()\n\ndataset['type'] = lb.fit_transform(dataset['type'])","5c46eafc":"x = dataset.iloc[:,0:12].values\ny = dataset.iloc[:,12:].values","b9a80f33":"x # we will scale these values","edbc1afe":"y","c8feeeb3":"sc = StandardScaler()","82ef6fd3":"x = sc.fit_transform(x)\nx","c0d55a0e":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)","991ddcce":"x_train.shape","ab469fb9":"x_test.shape","0a1d03e5":"y_train.shape","1332512d":"y_test.shape","9498fa69":"x_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","0e6162f8":"rfc = RandomForestClassifier(n_estimators=400)\nrfc.fit(x_train,y_train.ravel())","fbcd2160":"y_prediction = rfc.predict(x_test)","7b562e38":"print(accuracy_score(y_test,y_prediction))","62afe8da":"kn = KNeighborsClassifier(n_neighbors=2)\nkn.fit(x_train,y_train.ravel())","6edbae19":"y_prediction = kn.predict(x_test)","9f599a14":"print(accuracy_score(y_test,y_prediction))","c853317c":"s = SVC()\ns.fit(x_train,y_train.ravel())","9aee8f25":"y_prediction = s.predict(x_test)\nprint(accuracy_score(y_test,y_prediction))","33f5bbd0":"lr = LogisticRegression()\nlr.fit(x_train,y_train.ravel())","c695c30d":"y_prediction = lr.predict(x_test)\nprint(accuracy_score(y_test,y_prediction))","c0b823ec":"# Logistic Regression","fb259554":"# K nearest neighbours","ab9d3a7c":"# Random Forest","90ff3631":"Now, let's look into how each feature affects the quality of the Wine by plotting various graphs and histograms.","f6a495c0":"# Support Vector Machine","7a5c2a43":"Before processing any dataset it important to replace all the null values for computation flexibility, and replace their values with the mean value of that particular row.","51b08fdc":"Since the data is in ordered format we will shuffle the dataframe before dividing into train and test.","6a7a9846":"- Loading the data and performing data analysis, as the data is quiute uniform in ways like white wines are listed first followed by red wines.\n- We'll also look into various parameters and their behaviour, on the dataset","59b46c96":"# Training and Testing\n\nWe divide the dataset into dependent and independent variables, and convert them into numpy arrays.\nAlso, as we can see we have large differences in the values hence we scale all the values inside columns, so that its distribution will have a mean value 0 and standard deviation of 1."}}