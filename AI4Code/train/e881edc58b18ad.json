{"cell_type":{"626450c7":"code","8dd71356":"code","429f5555":"code","c46de420":"code","d5863bd3":"code","e197c4fb":"code","f3617b4d":"code","856647fd":"code","95cb5ba0":"code","c4305f73":"code","e18c2fdc":"code","137ce51b":"code","59f54c77":"code","18ebdc4e":"code","d698b67f":"code","e2049071":"code","2feeb29f":"code","ec9931e1":"code","f33b7a9b":"code","4fda8119":"markdown","75cc8b73":"markdown","2b14d369":"markdown"},"source":{"626450c7":"import numpy as np\nimport pandas as pd\n# from catboost import Pool, CatBoostRegressor\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler, RobustScaler,PowerTransformer,QuantileTransformer,OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor","8dd71356":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","429f5555":"#Target \ny = train['target']\nf = train.drop(['target'],axis = 1)","c46de420":"y.head()","d5863bd3":"f.nunique()","e197c4fb":"#Choosing categorical columns\n# cat_col = [c for c in features.columns if 'cat' in c]\n# cat_col = [c for c in f.columns if f[c].dtype =='object']\ncat_colhot=[\n#         'cat0',\n        'cat1', \n#         'cat2',\n#         'cat3',\n#         'cat4', \n#         'cat5'\n        ]\ncat_colo=  [ 'cat5',\n#             'cat7', \n            'cat8', \n#             'cat9'\n           ]\n# print(cat_col)\n#numerical columns\nnum_col = [c for c in f.columns if f[c].dtype in ['int64','float64']]\n# print(num_col)\n\n#cmbined categoricals and numericals\nall_col = cat_colhot+cat_colo + num_col\nX = f[all_col].copy()\nX_test = test[all_col].copy()\n","f3617b4d":"# Define column transfermer for standardizing num_col and encoding cat_col\npreprocessor = ColumnTransformer(\n    [\n        ('num',StandardScaler(),num_col),#StandardScaler RobustScaler QuantileTransformer\n        ('cat',OneHotEncoder(drop= 'if_binary'),cat_colhot),\n         ('cat1',OrdinalEncoder(),cat_colo)#OrdinalEncoder\n    ])","856647fd":"#Train test split\nX_t,X_v,y_t,y_v = train_test_split(X,y, train_size = 0.8,test_size = 0.2 ,random_state =10)","95cb5ba0":"rep_value = [5,10,20,30,40,50,60,70,80,90,95]\nall_value={}\nfor n in rep_value:\n    #Define Model\n    model = XGBRegressor(\n        n_estimators = 2500,\n        max_debth = 8,#5,\n        learning_rate = 0.05,#0.12,\n        n_jobs = 10, #10,\n        random_state = 10, #30,\n        colsample_bytree = 0.1,#0.85,\n        subsample = 0.6,#0.9,\n        booster='gbtree',\n        reg_lambda= 95,#30,\n        reg_alpha=30,\n#         gamma = n\n    )\n\n    #Define Pipeline\n    pipe = Pipeline(steps = [('preprocessor',preprocessor),('model',model)])\n\n    pipe[0].fit(X_t)\n\n    fit_param = {\"model__eval_set\":[(pipe[0].transform(X_v),y_v)],\n                                    \"model__early_stopping_rounds\":7}\n    pipe.fit(X_t,y_t,**fit_param)\n    predict_value = pipe.predict(X_v)\n    all_value[n]=mean_squared_error(predict_value,y_v)\n    print(\"Mean Square Error:\", mean_squared_error(predict_value,y_v))","c4305f73":"# {0.02: 0.5244700476255569,\n#  0.05: 0.5237069908393156,\n#  0.07: 0.5239774205922112,\n#  0.08: 0.5241931153016941,\n#  0.1: 0.5245118802581357,\n#  0.15: 0.5255665612682926,\n#  0.2: 0.5271434809834863,\n#  0.25: 0.5272137744609866,\n#  0.3: 0.5287256428846243}","e18c2fdc":"#  model = XGBRegressor(\n#         n_estimators = 2500,\n#         max_debth = 8,#5,\n#         learning_rate = 0.075,#0.12,\n#         n_jobs = 10, #10,\n#         random_state = 10, #30,\n#         colsample_bytree = 0.1,#0.85,\n#         subsample = 0.6,#0.9,\n#         booster='gbtree',\n#         reg_lambda= 50,#30,\n#         reg_alpha=30,\n# #         tree_method = 'gpu_hist'\n# #         gamma = n\n#     )\nmodel = XGBRegressor(\n    n_estimators = 2500,\n    max_debth = 8,#5,\n    learning_rate = 0.05,#0.12,\n    n_jobs = 10, #10,\n    random_state = 10, #30,\n    colsample_bytree = 0.1,#0.85,\n    subsample = 0.6,#0.9,\n    booster='gbtree',\n    reg_lambda= 30,#30,\n    reg_alpha=30,\n#         gamma = n\n)\n\n#Define Pipeline\npipe = Pipeline(steps = [('preprocessor',preprocessor),('model',model)])\n\npipe[0].fit(X_t)\n\nfit_param = {\"model__eval_set\":[(pipe[0].transform(X_v),y_v)],\n                                \"model__early_stopping_rounds\":7}\npipe.fit(X_t,y_t,**fit_param)\npredict_value = pipe.predict(X_v)\n# all_value[n]=mean_squared_error(predict_value,y_v)\nprint(\"Mean Square Error:\", mean_squared_error(predict_value,y_v))","137ce51b":"# #Define Pipeline\n# pipe = Pipeline(steps = [('preprocessor',preprocessor),('model',model)])","59f54c77":"# [1090]\tvalidation_0-rmse:0.72045\n# Mean Square Error: 0.519031572013811","18ebdc4e":"\n# pipe[0].fit(X_t)\n\n# fit_param = {\"model__eval_set\":[(pipe[0].transform(X_v),y_v)],\n#                                 \"model__early_stopping_rounds\":7}","d698b67f":"# pipe.fit(X_t,y_t,**fit_param)\n# predict_value = pipe.predict(X_v)\n# print(\"Mean Square Error:\", mean_squared_error(predict_value,y_v))","e2049071":"predict_test = pipe.predict(X_test)\npredict_test","2feeb29f":"# print(\"Mean Square Error:\", mean_squared_error(predict_test,y_v))\n# submission.target = predict_test\n# X_test\n# X_t\n# ,X_v,y_t,y_v","ec9931e1":"output = pd.DataFrame({'id': X_test.index,\n                       'target': predict_test})\noutput.to_csv('submission.csv', index=False)","f33b7a9b":"output","4fda8119":"## The Data","75cc8b73":"### Choose categorical features.","2b14d369":"# CatBoost Regressor"}}