{"cell_type":{"f091fad5":"code","1d96fcc0":"code","f9c716a5":"code","dace7df9":"code","ba1ee627":"code","5ec8e950":"code","f884a755":"code","d94734e8":"code","76731ee3":"code","c50ff3be":"code","26426f74":"code","71a88ea6":"code","6f575632":"code","34cbf3f8":"code","31928500":"code","42743d24":"code","2b8b1e78":"code","78bfa33c":"code","16e10ffc":"code","16bbe4d2":"markdown","dbb58702":"markdown","00aa2f2c":"markdown","5c766a30":"markdown","e1055559":"markdown","b27fd884":"markdown","19a5ff04":"markdown","09b1ab63":"markdown","ba908c51":"markdown","1b038e19":"markdown","96182ff2":"markdown","a71fd8bf":"markdown","6e3bb38a":"markdown"},"source":{"f091fad5":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.optim.lr_scheduler import StepLR\nimport pandas as pd\n\nfrom torchvision import transforms, utils\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import Dataset\n\nfrom PIL import Image","1d96fcc0":"n_epochs = 100 # number of epochs to train for\nbatch_size = 32 # batch size for training, validation and test data loaders\nlr = 0.0001 # Learning rate for Adam\nval_prop = 0.2 # proportion of training images to be used as validation\nval_iter = 10 # number of epochs before testing validation set","f9c716a5":"torch.cuda.is_available()","dace7df9":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","ba1ee627":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization values\ntrain_transformer = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    normalize\n])\n\ntest_transformer = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize\n])","5ec8e950":"class CovidCTDataset(Dataset):\n    def __init__(self, root_dir, index, label, transform=None):\n        \"\"\"\n        Args:\n            index (list): Index of images to be used for the data\n            label (list): List of annotations for the Covid CT scans (0 for non-Covid, 1 for Covid)\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.root_dir = root_dir\n        self.img_list = []\n        # basically want to store images using ['image path', class]\n        for i in range(len(index)):\n            self.img_list.append((self.root_dir+'\/'+str(index[i])+'.png',index[i], label[i]))\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_list)\n    \n    def get_image(self, idx):\n        img_path = self.img_list[idx][0]\n        index = self.img_list[idx][1]\n        label = self.img_list[idx][2]\n        image = Image.open(img_path).convert('RGB')\n        return image, index, label\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_path = self.img_list[idx][0]\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n            \n        sample = {'img': image,\n                  'index': int(self.img_list[idx][1]),\n                  'label': int(self.img_list[idx][2])}\n        return sample","f884a755":"def load_csv(csv_path):\n    data = pd.read_csv(csv_path)\n    return list(data['Index']), list(data['Label'])","d94734e8":"# This code was adapted to the Kaggle online data\n# if you put this python notebook in the same directory as your Train, Test, submission.csv, train.csv\n# change root to ''\nroot = '..\/input\/covidct\/'\n# root = ''\n\n# write code to load the index and labels from the csv file\ntrain_index, train_label = load_csv(root+'train.csv')\ntest_index, test_label = load_csv(root+'submission.csv')\n\n# set proportion of training images to be the validation\nsplit_index = int((1-val_prop)*len(train_index))\n\ntrainset = CovidCTDataset(root_dir=root+'Train\/Train',\n                          index = train_index[:split_index],\n                          label = train_label[:split_index],\n                          transform= train_transformer)\nvalset = CovidCTDataset(root_dir=root+'Train\/Train',\n                          index = train_index[split_index:],\n                          label = train_label[split_index:],\n                          transform= test_transformer)\ntestset = CovidCTDataset(root_dir=root+'Test\/Test',\n                          index = test_index,\n                         label = test_label,\n                          transform= test_transformer)\nprint('Training Dataset Length:', len(trainset))\nprint('Validation Dataset Length:', len(valset))\nprint('Test Dataset Length:', len(testset))\n\ntrain_loader = DataLoader(trainset, batch_size=batch_size, drop_last=False, shuffle=True)\nval_loader = DataLoader(valset, batch_size=batch_size, drop_last=False, shuffle=False)\ntest_loader = DataLoader(testset, batch_size=batch_size, drop_last=False, shuffle=False)","76731ee3":"labeldict = {\n    0: '(Non-Covid)',\n    1: '(Covid)'\n}\nimage, index, label = trainset.get_image(1)\nprint('Index:', index, 'Label', label, labeldict[label])\ndisplay(image)","c50ff3be":"image, index, label = trainset.get_image(5)\nprint('Index:', index, 'Label', label, labeldict[label])\ndisplay(image)","26426f74":"def train(optimizer, epoch):\n    \n    model.train()\n    \n    train_loss = 0\n    train_correct = 0\n    \n    for batch_index, batch_samples in enumerate(train_loader):\n        \n        # move data to device\n        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n        \n        output = model(data)\n        \n        criteria = nn.CrossEntropyLoss()\n        loss = criteria(output, target.long())\n        train_loss += loss\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        pred = output.argmax(dim=1, keepdim=True)\n        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n    \n    print('Epoch: {} Train set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)'.format(epoch,\n        train_loss\/np.ceil(len(train_loader.dataset)\/batch_size), train_correct, len(train_loader.dataset),\n        100.0 * train_correct \/ len(train_loader.dataset)))","71a88ea6":"def val():\n    \n    model.train()\n    \n    val_loss = 0\n    val_correct = 0\n    \n    for batch_index, batch_samples in enumerate(val_loader):\n        \n        with torch.no_grad():\n        \n            # move data to device\n            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n\n            output = model(data)\n            pred = output.argmax(dim=1, keepdim=True)\n            \n            criteria = nn.CrossEntropyLoss()\n            loss = criteria(output, target.long())\n            val_loss += loss\n            \n            val_correct += pred.eq(target.long().view_as(pred)).sum().item()\n    \n    print('\\tVal set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)'.format(\n        val_loss\/len(val_loader.dataset), val_correct, len(val_loader.dataset),\n        100.0 * val_correct \/ len(val_loader.dataset)))","6f575632":"def predict():\n    \n    model.eval()\n    criteria = nn.CrossEntropyLoss()\n    # Don't update model\n    with torch.no_grad():\n        \n        indexlist = []\n        labellist = []\n\n        # Predict\n        for batch_index, batch_samples in enumerate(test_loader):\n            data, index = batch_samples['img'].to(device), batch_samples['index'].cpu().numpy()\n            \n            output = model(data)\n            \n            pred = output.argmax(dim=1, keepdim=True).cpu().squeeze().numpy()\n            labellist.extend(list(pred))\n            indexlist.extend(list(index))\n           \n    return indexlist, labellist","34cbf3f8":"class SimpleCNN(torch.nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__() # b, 3, 32, 32\n        layer1 = torch.nn.Sequential() \n        layer1.add_module('conv1', torch.nn.Conv2d(3, 32, 3, 1, padding=1))\n \n        #b, 32, 32, 32\n        layer1.add_module('relu1', torch.nn.ReLU(True)) \n        layer1.add_module('pool1', torch.nn.MaxPool2d(2, 2)) # b, 32, 16, 16\n        self.layer1 = layer1\n        layer4 = torch.nn.Sequential()\n        layer4.add_module('fc1', torch.nn.Linear(401408, 2))       \n        self.layer4 = layer4\n \n    def forward(self, x):\n        conv1 = self.layer1(x)\n        fc_input = conv1.view(conv1.size(0), -1)\n        fc_out = self.layer4(fc_input)\n \nmodel = SimpleCNN().to(device)\nmodelname = 'SimpleCNN'","31928500":"## ResNet18\nimport torchvision.models as models\nmodel = models.resnet18(pretrained=True).to(device)\nmodelname = 'ResNet18'","42743d24":"### ResNet50\nimport torchvision.models as models\nmodel = models.resnet50(pretrained=True).to(device)\nmodelname = 'ResNet50'","2b8b1e78":"### VGGNet\nimport torchvision.models as models\nmodel = models.vgg16(pretrained=True)\nmodel = model.to(device)\nmodelname = 'vgg16'","78bfa33c":"#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\noptimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n# scheduler = StepLR(optimizer, step_size=10)\n\n# Initial validation set loss (to verify model is training from scratch)\nval()\nfor epoch in range(n_epochs):\n    train(optimizer, epoch)\n    if epoch%val_iter == 9:\n        val()","16e10ffc":"index, label = predict()\n\ndf = pd.DataFrame({'Index': index, 'Label': label})\n\nprint(df)\n\ndf.to_csv('mysubmission.csv', index = False, columns = ['Index', 'Label'])","16bbe4d2":"## Display a few sample images","dbb58702":"## Select a Neural Network\n\nChoose one of the following neural networks to do the training and testing\n\nFor the simulation below, ResNet18 was used","00aa2f2c":"## Load the data","5c766a30":"## Get the Dataset Loaders","e1055559":"## What to do now?","b27fd884":"## Train the Model","19a5ff04":"## How to improve further?","09b1ab63":"## How to use\n\nPut this Python notebook in the same directory (folder) as Train, Test, train.csv and submission.csv.\n\nRun the cells one by one. \n\nChoose a desired model to train and test your data.\n\nThis notebook was created by John Tan Chong Min, which is modified from https:\/\/github.com\/UCSD-AI4H\/COVID-CT\/blob\/master\/baseline%20methods\/DenseNet169\/DenseNet_predict.py\n\n## Dependencies\n- torch\n- torchvision\n- numpy\n- matplotlib\n- pandas\n- PIL\n- Python 3.0","ba908c51":"## Use the model for prediction","1b038e19":"With the \"mysubmission.csv\" file generated (it should be in the same folder\/directory as this Jupyter Notebook, you can now proceed to submit to Kaggle for the competition!\n\nGood luck!","96182ff2":"# Configure parameters here","a71fd8bf":"## Train and Test Helper Functions","6e3bb38a":"The training data shows that the model is overfitting as the training set can fit it 100%, but the validation set fits it at 84% at epoch 40 and drops down to 81% at epoch 50.\n\nPerhaps other methods to regularize may be helpful (i.e. Dropout, L1\/L2 Normalization), or use a learning rate scheduler.\n\nTweaking the train-validation ratio may also help. \n\nLots of possibilities to explore to be the top in Kaggle!"}}