{"cell_type":{"3a9c4262":"code","9429006d":"code","dbb4aa71":"code","89928bdd":"code","6340d790":"code","865d0a03":"code","5403a0b0":"code","d8b5bd75":"code","8511add1":"code","30c8c486":"code","532f9dde":"code","9bb54373":"code","1086553e":"code","a13ac8c2":"code","1a3cae43":"code","dabc7adc":"code","d0afc9d3":"code","84ef5596":"code","63aa087b":"code","5cd6b669":"code","0430d609":"code","41fdf2d6":"code","be72a049":"code","2905013c":"markdown","dde6b5ad":"markdown","f148f056":"markdown","97a326f3":"markdown","b3305a77":"markdown","4946e6a1":"markdown","ab0e7a2e":"markdown","3191989e":"markdown","ea9159b2":"markdown","0298885d":"markdown"},"source":{"3a9c4262":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","9429006d":"train =  pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","dbb4aa71":"train.head()","89928bdd":"y_train = train.iloc[:,0]","6340d790":"train.info()","865d0a03":"train.describe()","5403a0b0":"train.isnull().sum()","d8b5bd75":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \nX_train = X_train \/ 255.0\ntest = test \/ 255.0","8511add1":"sns.barplot(x = y_train.unique(), y=y_train.value_counts())\nplt.xlabel('Digits')\nplt.ylabel('Number of image samples')","30c8c486":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","532f9dde":"Y_train = tf.keras.utils.to_categorical(Y_train, 10)","9bb54373":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2)","1086553e":"batch_size = 128\nnum_classes = 10\nepochs = 50","a13ac8c2":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.Dropout(0.2),\n\n    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\n    tf.keras.layers.MaxPooling2D(),\n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","1a3cae43":"image_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10, \n        zoom_range = 0.1,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=False,\n        vertical_flip=False)\n\nimage_data_gen.fit(X_train)","dabc7adc":"h = model.fit_generator(image_data_gen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size)","d0afc9d3":"final_loss, final_acc = model.evaluate(X_val, Y_val, verbose=0)","84ef5596":"train_accuracies = h.history[\"accuracy\"]\nvalidation_accuracies = h.history[\"val_accuracy\"]\n\nepochs_range = list(range(1, epochs+1))\n\nscatter_accuracy_hovertemplate = \"Epoch: %{x}<br>Accuracy: %{y}\"\n\ndata = [\n    go.Scatter(x=epochs_range, y=train_accuracies, name=\"Train Accuracy\", hovertemplate=scatter_accuracy_hovertemplate),\n    go.Scatter(x=epochs_range, y=validation_accuracies, name=\"Validation Accuracy\", hovertemplate=scatter_accuracy_hovertemplate)\n]\n\ntitle = go.layout.Title(text=\"Train & Validation Accuracies\",\n                        font=dict(size=25))\n\nlayout = go.Layout(template=\"plotly_dark\",\n                    xaxis=dict(ticks=\"outside\", ticklen=5, tickvals=list(range(0, epochs+1, 2)), tickfont=dict(size=10), title=dict(text=\"Epochs\", font=dict(size=17))),\n                    yaxis=dict(title=dict(text=\"Accuracy\", font=dict(size=14))),\n                    title=title)\n\nfigure = go.Figure(data=data, layout=layout)\nfigure.show()","63aa087b":"train_losses = h.history[\"loss\"]\nvalidation_losses = h.history[\"val_loss\"]\n\nscatter_loss_hovertemplate = \"Epoch: %{x}<br>Loss: %{y}\"\n\ndata = [\n    go.Scatter(x=epochs_range, y=train_losses, name=\"Train Loss\", hovertemplate=scatter_loss_hovertemplate),\n    go.Scatter(x=epochs_range, y=validation_losses, name=\"Validation Loss\", hovertemplate=scatter_loss_hovertemplate)\n]\n\ntitle = go.layout.Title(text=\"Train & Validation Losses\",\n                        font=dict(size=25))\n\nlayout = go.Layout(template=\"plotly_dark\",\n                    xaxis=dict(ticks=\"outside\", ticklen=5, tickvals=list(range(0, epochs+1, 2)), tickfont=dict(size=10), title=dict(text=\"Epochs\", font=dict(size=17))),\n                    yaxis=dict(title=dict(text=\"Loss\", font=dict(size=14))),\n                    title=title)\n\nfigure = go.Figure(data=data, layout=layout)\nfigure.show()","5cd6b669":"Y_pred = model.predict(X_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) ","0430d609":"confusion_mtx","41fdf2d6":"results=model.predict(test)","be72a049":"results = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"result.csv\",index=False)","2905013c":"* The Input Layer is defined to read the images into the CNN\n* Convolution Layer - These are important when nearby associations among the features matter. Here it is less likely that the pixels in opposite corner of the images will contribute to the classification. Therefore, I used the convolutional layer\n* Max Pooling Layer - It selects the maximum element from the region of the feature map covered by the filter. So, the output would be a feature map containing the most prominent features of the previous feature map.\n* Batch Normalization - It is technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n* Dropout - It is a way of cutting too much association among features by dropping a specific percentage of weights randomly.\n* Flatten - It is used when we get multidimensional output and want to make it linear to pass it onto a Dense layer. It is equivalent to numpy.ravel (Look at the shape before and flatten in the model summary)\n* Dense - are used when association can exist among any feature to any other feature in data point\n\n**The output layer in a classification problem should always be a softmax layer with the number of output classes as its paramter**\n","dde6b5ad":"# Model Building","f148f056":"# Training Convolutional Neural Network","97a326f3":"# EDA","b3305a77":"# Plotting results","4946e6a1":"# Image Augmentation\nTo improve model's probability power, I will use Image Augmentations.","ab0e7a2e":"# Checking Null Values","3191989e":"## We are reshaping the data into images.\n\n* -1 is given so that the number of rows are dynamically written as per the dataset\n* 28*28 is the size of the image\n* 1 is channel as Images are in Black and White (Note - If it is in RGB, then channel value should be 3)","ea9159b2":"# Splitting into Train and Validation Datasets\n\nI split the dataset into train and validation datasets, and then while training, we can check accuracy by the validation dataset, which the neural network didn't see. I have chosen a 20%\/80% split because it is the most common way to split the dataset.","0298885d":"## Looking at this class distribution graph, I can see that the classes are almost evenly distributed. Therefore, it does not require any resampling to be applied"}}