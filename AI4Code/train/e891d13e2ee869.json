{"cell_type":{"23b9314c":"code","7d403699":"code","4b734306":"code","2d0a668f":"code","dfb32bb0":"code","eda3ecc0":"code","88af18a6":"code","df414ffe":"code","3701d2bd":"code","9957691a":"code","ba19159f":"code","8160ed3a":"code","db394024":"code","a950e005":"code","3fc36cf6":"code","3963ae28":"code","ca701c96":"code","093e94b3":"code","955773f5":"code","a00ee440":"code","f202deaa":"code","2ee8858a":"code","38db1d12":"code","274f6031":"code","6f2ef3a1":"code","a0af6e09":"code","62895559":"code","69c651e4":"code","d1c2d6ec":"code","b552d1e4":"code","27a619e5":"code","b5edf982":"code","bbb9a5bc":"code","02e0dda6":"code","23be78ef":"code","82bb3970":"code","7261edb3":"code","64910ead":"code","11cafa59":"code","1db5dd6d":"code","e6f57b82":"code","e6c95987":"code","7e5ab745":"code","8dac32d9":"code","046c5c51":"code","b4a8b885":"code","1386e7b1":"code","2373db66":"code","0cf9fbd8":"code","e4e92ef2":"code","eccf1d71":"code","9d8073e7":"code","88286e9f":"code","532eb2ac":"code","c8d68d90":"code","abb177d7":"code","90435374":"code","0a4e9fbe":"code","aa5b1835":"code","1a1fcc11":"code","3190b8c3":"code","1917d7be":"code","0462c311":"code","2827b84d":"code","6b981e85":"code","670aa161":"code","0c14adc7":"code","c9f8e1f9":"code","ffbb1f51":"code","e35eeac2":"code","c1366122":"code","22aff368":"code","95d8e12d":"code","0584b7fc":"code","7c0a798d":"code","8f5587be":"code","c7009ebd":"code","6d7bb231":"code","92e5aa54":"code","65e2fb4e":"code","a4697062":"code","00e74c02":"code","1a1c520c":"code","dff0c832":"code","fc5443da":"code","52e0b611":"code","7a8e41bd":"code","b1b80c17":"code","a3a247fa":"code","ba636152":"code","3016bd01":"code","9c06ca06":"code","fb5e1e06":"code","8a734e2d":"code","94c4248c":"code","1e6dd2b7":"code","d87b3441":"code","5eeddc7f":"code","ce95fa9d":"code","7fe9de41":"code","2f40d8b7":"code","6acb371a":"code","ecfb18ef":"code","99004259":"code","7855a08a":"code","c1708495":"code","558902c1":"code","6ea475de":"code","19c9c1e0":"code","7adff7aa":"code","a31e1cc3":"code","3962f940":"code","3de5b1cd":"code","c6145d57":"code","97dc566c":"code","c2403ac7":"code","002ade3c":"code","247ae65d":"code","b707cf1a":"code","1c2f75f4":"code","0b974976":"code","f67905ec":"code","33d7e697":"code","808dc947":"code","4b2f1830":"code","9f0e1f8a":"code","41be533b":"code","6077581f":"code","1ecc422a":"code","6e6c40c4":"code","ce1ffc6c":"code","17bd9294":"code","cdf9add5":"code","c2435627":"code","ac488691":"code","2692b383":"code","2546fc72":"code","032cc929":"code","c4888bec":"code","ae394a49":"code","ecb05e01":"code","be982b0c":"code","44f04a0f":"code","be1c7955":"code","d82f24ea":"code","eb2e034a":"code","cef6ea82":"code","1d41bcab":"code","e02a6ea6":"code","86487273":"code","f3430893":"code","0a7b01fe":"code","339441c0":"code","b0961e60":"code","5e66bb8b":"code","84f9f640":"code","c9f35be6":"code","e3baeccc":"code","475aba93":"code","fae09f5a":"code","e0bb7eda":"code","42210477":"code","a6c7218c":"code","17287013":"code","70eaa72a":"code","06e4026e":"code","4721d4d3":"code","42a9313c":"code","f1d37691":"code","094e75fa":"code","d73487bf":"code","4df20c36":"code","34f6ddbc":"code","8d50f11c":"code","cffd9fdd":"code","050fd856":"code","78554edb":"code","1e92c80a":"code","d97b5cfc":"code","af6faf17":"code","cce85cb9":"code","ed36db7b":"code","0dfad42e":"code","6e5a27fe":"code","53e96791":"markdown","e5c67a5e":"markdown","55c8caa5":"markdown","9dbb4cfd":"markdown","a3cd6568":"markdown","b498b6ea":"markdown","41af60ee":"markdown","3edd816a":"markdown","b7d0ce6d":"markdown","2749005a":"markdown","cff6e3e2":"markdown","3bf13ef6":"markdown","ed65cd0b":"markdown","da5f921c":"markdown","35c8e3f7":"markdown","a1b54a61":"markdown","d4f38484":"markdown","339df074":"markdown","58937630":"markdown","357aafd3":"markdown","5fd0b2c5":"markdown","e6015ec2":"markdown","4d13d75b":"markdown","3d267a5f":"markdown","4971503d":"markdown","471c5595":"markdown","6d116397":"markdown","0bfff1ba":"markdown","9f2a9003":"markdown","6d505158":"markdown","94cfb800":"markdown","b4be5e3a":"markdown","64412c26":"markdown","7b95a210":"markdown","2482e947":"markdown","5d024ffd":"markdown","850dabd4":"markdown","ad6d8dca":"markdown","2667a27b":"markdown","ff2cd2bb":"markdown","50239ba4":"markdown","1b55d420":"markdown","3797b9e8":"markdown","2dab4ad8":"markdown","b0379499":"markdown","8ed34a0e":"markdown","d710b554":"markdown","063e8fcf":"markdown","a0915588":"markdown","c1ff4b15":"markdown","6cb65566":"markdown","3a8fbf8e":"markdown","1633d09a":"markdown","2be0c9c5":"markdown","a403ef3f":"markdown","2f092f7c":"markdown","5c43299b":"markdown","11d2a793":"markdown","a58a3348":"markdown","145ca649":"markdown","c4361cca":"markdown","3401f148":"markdown","10720c61":"markdown","66a40718":"markdown","2c92c1cc":"markdown","8f5e71d3":"markdown","a54f18a1":"markdown","4ce026ba":"markdown","c0910dda":"markdown","445dcdb9":"markdown","28f83518":"markdown","33ad9bd2":"markdown","8aee7672":"markdown","accf74db":"markdown","b6b9f023":"markdown","762155b2":"markdown","9b66cf8c":"markdown","9b91df57":"markdown","9f4888b2":"markdown","7e4b9717":"markdown","a089f1e1":"markdown","c5c70efe":"markdown","1894b6ce":"markdown","96eaa4e3":"markdown","2199c2e4":"markdown","b568e7c1":"markdown","a9baa7f3":"markdown","b5b4a152":"markdown","8b0075da":"markdown","5aa6a748":"markdown","3758ba65":"markdown","21e614ca":"markdown","3d5fdeb0":"markdown","cf7cd5f8":"markdown","e2386f29":"markdown","3f4f9abf":"markdown","49318984":"markdown","34c34d78":"markdown","0e1c188c":"markdown","aef47680":"markdown","ef0b82f1":"markdown","33d44416":"markdown","28c503c3":"markdown","fec2ec1c":"markdown","efc7b764":"markdown","a017476d":"markdown","6c99e5b4":"markdown","f299d38a":"markdown","c986f452":"markdown","8fbe3d51":"markdown","14c54958":"markdown","9e087ef4":"markdown","3e863516":"markdown","76a05452":"markdown","a0199b82":"markdown","9f012918":"markdown","00693d35":"markdown","9ef64e5e":"markdown","de2eab52":"markdown","51fec119":"markdown","13eaeeea":"markdown","e57b1c23":"markdown","2284c676":"markdown","11bd35f8":"markdown","79210aa9":"markdown","15527b75":"markdown","43444794":"markdown","3dff0dcc":"markdown","dff683c8":"markdown","1882f955":"markdown","e49582cd":"markdown","939f3ce1":"markdown","74b1e79c":"markdown","1f461dda":"markdown","6b7d70fc":"markdown","3a476512":"markdown","a8bc98d4":"markdown","e6240f17":"markdown","68193650":"markdown","560878dc":"markdown","e8ebcf5a":"markdown","99baaea3":"markdown","b23bc72e":"markdown","af9c00b2":"markdown","65d9e765":"markdown","73ccfadb":"markdown","e5e1f3da":"markdown","b0ddf0d0":"markdown","3e903ddf":"markdown","ebf54e3d":"markdown","92ae7e74":"markdown","baf08a40":"markdown","48867ea2":"markdown","1f61e188":"markdown","22e43950":"markdown","584b24f0":"markdown","7be82743":"markdown","f4d4290c":"markdown","8c63e501":"markdown","e7fabacd":"markdown","4ca8a78a":"markdown","19f81b2a":"markdown","5062a991":"markdown","896cdc1f":"markdown"},"source":{"23b9314c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7d403699":"# plotting and stats libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n%matplotlib inline\n\n# report warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Encoders\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder","4b734306":"KEEP_COLS_WITH_MAX_PERCENT_OF_SAME_FEATURE=.99\nDROP_ROWS_WITH_1_NULL_ITEM = False","2d0a668f":"# read in the training data\ndf_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\n# read in the testing data\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","dfb32bb0":"df_train[\"SalePrice\"].describe()","eda3ecc0":"sns.distplot(df_train['SalePrice'], fit=stats.norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","88af18a6":"print(\"Skewness: %f\" % df_train['SalePrice'].skew())","df414ffe":"print(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","3701d2bd":"#transformed histogram and normal probability plot\nsns.distplot(np.log(df_train['SalePrice']), fit=stats.norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)\n\nprint(\"Skewness: %f\" % np.log(df_train['SalePrice']).skew())\nprint(\"Kurtosis: %f\" % np.log(df_train['SalePrice']).kurt())","9957691a":"df_train['SalePrice'] = np.log(df_train['SalePrice'])","ba19159f":"# before I start, I know there this is a typo in the Exterior2nd column\n\n# Cement Board is labeled as CmentBd instead of CemntBd. Therefore we must\n# update it.\ndf_train = df_train.replace({\"Exterior2nd\":{\"CmentBd\":\"CemntBd\"}})\ndf_test = df_test.replace({\"Exterior2nd\":{\"CmentBd\":\"CemntBd\"}})\n\n# Cement Board is labeled as Wd Shng instead of Wd Sdng. Therefore we must\n# update it.\ndf_train = df_train.replace({\"Exterior2nd\":{\"Wd Shng\":\"Wd Sdng\"}})\ndf_test = df_test.replace({\"Exterior2nd\":{\"Wd Shng\":\"Wd Sdng\"}})\n\ncombined = pd.concat([df_train, df_test], sort=False)","8160ed3a":"combined.loc[combined[\"Exterior1st\"]==combined[\"Exterior2nd\"],].shape","db394024":"diffext_values = (combined.loc[combined[\"Exterior1st\"]!=combined[\"Exterior2nd\"], \"Exterior1st\"]+ \\\n \",\"+ \\\n combined.loc[combined[\"Exterior1st\"]!=combined[\"Exterior2nd\"],\"Exterior2nd\"]).value_counts()\n\nfill_dict={}\nfor i, v in diffext_values.iteritems():\n    #print(fill_dict)\n    ex_vals=i.split(\",\")\n\n    dup=False\n    if ex_vals[1] in list(fill_dict.keys()):\n        if ex_vals[0] in fill_dict[ex_vals[1]]:\n            dup=True\n            \n    if ex_vals[0] in list(fill_dict.keys()):\n            fill_dict[ex_vals[0]].append(ex_vals[1])\n    else:\n        fill_dict[ex_vals[0]] =[ex_vals[1]]\n    if dup:\n        print(str(i)+\"\\t\"+str(v)+\" (DUP)\")\n    else:\n        print(str(i)+\"\\t\"+str(v))","a950e005":"#total_Exterior1st = combined.loc[:,[\"Exterior1st\"]].count()\n#total_Exterior2nd = combined.loc[:,[\"Exterior2nd\"]].count()\n#total_ExteriorCols = total_Exterior1st + total_Exterior2nd\n\n\nprint(\"Numbers of NaNs in Exterior1st\")\nprint(combined[\"Exterior1st\"].isnull().sum())\n\n\nprint(\"Numbers of NaNs in Exterior2nd\")\nprint(combined[\"Exterior2nd\"].isnull().sum())\n\nexterior_normCounts=pd.DataFrame()\nexterior_normCounts.loc[:,\"Exterior1st\"] = combined[\"Exterior1st\"].value_counts(normalize=True)\nexterior_normCounts.loc[:,\"Exterior2nd\"] = combined[\"Exterior2nd\"].value_counts(normalize=True)\nexterior_normCounts.loc[:,\"both\"] = combined[\"Exterior1st\"].append(combined[\"Exterior2nd\"]).value_counts(normalize=True)\nexterior_normCounts.fillna(0,inplace=True)\nexterior_normCounts = exterior_normCounts.reset_index()","3fc36cf6":"exterior_normCounts_melted =pd.melt(exterior_normCounts, id_vars=['index'],\n                                    value_vars=[\"Exterior1st\",\"Exterior2nd\",\"both\"])\n#exterior_normCounts_melted\nplt.figure(figsize=(10,5))\nsns.barplot(x=\"index\", y=\"value\", hue=\"variable\", data=exterior_normCounts_melted)\nplt.xticks(rotation=90);\nplt.show()","3963ae28":"\n\nexterior1_uniqVals = list(combined[\"Exterior1st\"].dropna().unique())\nexterior2_uniqVals = list(combined[\"Exterior2nd\"].dropna().unique())\nexterior_uniqVals = [x for x in exterior2_uniqVals if x not in exterior1_uniqVals]\nexterior_uniqVals = exterior_uniqVals +exterior1_uniqVals\n\nexterior_cols = []\nfor exterior_type in exterior_uniqVals:\n    new_exType_col = \"Exterior_\"+exterior_type\n    exterior_cols.append(new_exType_col)\n    df_train.loc[((df_train[\"Exterior1st\"]==exterior_type) |\n                  (df_train[\"Exterior2nd\"]==exterior_type)),new_exType_col] = 1\n    df_train.loc[((df_train[\"Exterior1st\"]!=exterior_type) &\n                  (df_train[\"Exterior2nd\"]!=exterior_type)),new_exType_col] = 0\n    df_test.loc[((df_test[\"Exterior1st\"]==exterior_type) |\n                  (df_test[\"Exterior2nd\"]==exterior_type)),new_exType_col] = 1\n    df_test.loc[((df_test[\"Exterior1st\"]!=exterior_type) &\n                  (df_test[\"Exterior2nd\"]!=exterior_type)),new_exType_col] = 0","ca701c96":"exterior_df = df_train.loc[:,exterior_cols+[\"SalePrice\"]].copy()\nfor ex_col in exterior_cols:\n    exterior_df.loc[:,ex_col] = exterior_df[ex_col] * exterior_df[\"SalePrice\"]\nexterior_df = exterior_df.drop([\"SalePrice\"],axis=1)\nexterior_melted_df = pd.melt(exterior_df)\nexterior_melted_df = exterior_melted_df.loc[exterior_melted_df[\"value\"]>0,:]\nexterior_melted_df.columns=[\"Exterior\",\"SalePrice\"]\nexterior_melted_df.sort_values(\"Exterior\", inplace=True)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x=\"Exterior\", y=\"SalePrice\", data=exterior_melted_df)\nplt.xticks(rotation=90);\nplt.show()","093e94b3":"df_train.loc[df_train[\"Exterior1st\"] != df_train[\"Exterior2nd\"],\"TwoExteriorMaterials\"]=1\ndf_train.loc[df_train[\"Exterior1st\"] == df_train[\"Exterior2nd\"],\"TwoExteriorMaterials\"]=0\nplt.figure(figsize=(5,5))\nsns.boxplot(x=\"TwoExteriorMaterials\", y=\"SalePrice\", data=df_train)\nplt.xticks(rotation=90);\nplt.show()","955773f5":"df_train = df_train.drop([\"Exterior1st\",\"Exterior2nd\"],axis=1)\ndf_test = df_test.drop([\"Exterior1st\",\"Exterior2nd\"],axis=1)","a00ee440":"combined.loc[combined[\"Condition1\"]==combined[\"Condition2\"],].shape","f202deaa":"diffext_values = (combined.loc[:, \"Condition1\"]+ \\\n \",\"+ \\\n combined.loc[:,\"Condition2\"]).value_counts()\n\nfill_dict={}\nfor i, v in diffext_values.iteritems():\n    #print(fill_dict)\n    ex_vals=i.split(\",\")\n\n    dup=False\n    if ex_vals[1] in list(fill_dict.keys()):\n        if ex_vals[0] in fill_dict[ex_vals[1]]:\n            dup=True\n            \n    if ex_vals[0] in list(fill_dict.keys()):\n            fill_dict[ex_vals[0]].append(ex_vals[1])\n    else:\n        fill_dict[ex_vals[0]] =[ex_vals[1]]\n    if dup:\n        print(str(i)+\"\\t\"+str(v)+\" (DUP)\")\n    else:\n        print(str(i)+\"\\t\"+str(v))","2ee8858a":"#total_Exterior1st = combined.loc[:,[\"Exterior1st\"]].count()\n#total_Exterior2nd = combined.loc[:,[\"Exterior2nd\"]].count()\n#total_ExteriorCols = total_Exterior1st + total_Exterior2nd\n\n\nprint(\"Numbers of NaNs in Condition1\")\nprint(combined[\"Condition1\"].isnull().sum())\n\n\nprint(\"Numbers of NaNs in Condition2\")\nprint(combined[\"Condition2\"].isnull().sum())\n\ncondition_normCounts=pd.DataFrame()\ncondition_normCounts.loc[:,\"Condition1\"] = combined[\"Condition1\"].value_counts(normalize=True)\ncondition_normCounts.loc[:,\"Condition2\"] = combined[\"Condition2\"].value_counts(normalize=True)\ncondition_normCounts.loc[:,\"both\"] = combined[\"Condition1\"].append(combined[\"Condition2\"]).value_counts(normalize=True)\ncondition_normCounts.fillna(0,inplace=True)\ncondition_normCounts = condition_normCounts.reset_index()","38db1d12":"condition_normCounts_melted =pd.melt(condition_normCounts, id_vars=['index'],\n                                    value_vars=[\"Condition1\",\"Condition2\",\"both\"])\n#exterior_normCounts_melted\nplt.figure(figsize=(10,5))\nsns.barplot(x=\"index\", y=\"value\", hue=\"variable\", data=condition_normCounts_melted)\nplt.xticks(rotation=90);\nplt.show()","274f6031":"plt.figure(figsize=(10,5))\nsns.barplot(x=\"index\", y=\"value\", hue=\"variable\", \n            data=condition_normCounts_melted.loc[condition_normCounts_melted[\"index\"]!=\"Norm\",:])\nplt.xticks(rotation=90);\nplt.show()\n","6f2ef3a1":"condition1_uniqVals = list(combined[\"Condition1\"].dropna().unique())\ncondition2_uniqVals = list(combined[\"Condition2\"].dropna().unique())\ncondition_uniqVals = [x for x in condition2_uniqVals if x not in condition1_uniqVals]\ncondition_uniqVals = condition_uniqVals + condition1_uniqVals\n\ncondition_cols=[]\nfor condition_type in condition_uniqVals:\n    print(condition_type)\n    new_condType_col = \"Condition_\"+condition_type\n    condition_cols.append(new_condType_col)\n    df_train.loc[((df_train[\"Condition1\"]==condition_type) |\n                  (df_train[\"Condition2\"]==condition_type)),new_condType_col] = 1\n    df_train.loc[df_train[new_condType_col].isnull(),new_condType_col] = 0\n    df_test.loc[((df_test[\"Condition1\"]==condition_type) |\n                  (df_test[\"Condition2\"]==condition_type)),new_condType_col] = 1\n    df_test.loc[df_test[new_condType_col].isnull(),new_condType_col] = 0","a0af6e09":"condition_df = df_train.loc[:,condition_cols+[\"SalePrice\"]].copy()\nfor cond_col in condition_cols:\n    condition_df.loc[:,cond_col] = condition_df[cond_col] * condition_df[\"SalePrice\"]\ncondition_df = condition_df.drop([\"SalePrice\"],axis=1)\ncondition_melted_df = pd.melt(condition_df)\ncondition_melted_df = condition_melted_df.loc[condition_melted_df[\"value\"]>0,:]\ncondition_melted_df.columns=[\"Condition\",\"SalePrice\"]\ncondition_melted_df.sort_values(\"Condition\", inplace=True)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x=\"Condition\", y=\"SalePrice\", data=condition_melted_df)\nplt.xticks(rotation=90);\nplt.show()","62895559":"df_train.loc[df_train[\"Condition1\"] != df_train[\"Condition2\"],\"TwoConditions\"]=1\ndf_train.loc[df_train[\"Condition1\"] == df_train[\"Condition2\"],\"TwoConditions\"]=0\nplt.figure(figsize=(5,5))\nsns.boxplot(x=\"TwoConditions\", y=\"SalePrice\", data=df_train)\nplt.xticks(rotation=90);\nplt.show()","69c651e4":"df_train = df_train.drop([\"Condition1\",\"Condition2\"],axis=1)\ndf_test = df_test.drop([\"Condition1\",\"Condition2\"],axis=1)","d1c2d6ec":"mssubclass_vals = {\"MSSubClass\":     {20:\"1-STORY 1946 & NEWER ALL STYLES\",\n        30:\"1-STORY 1945 & OLDER\",\n        40:\"1-STORY W\/FINISHED ATTIC ALL AGES\",\n        45:\"1-1\/2 STORY - UNFINISHED ALL AGES\",\n        50:\"1-1\/2 STORY FINISHED ALL AGES\",\n        60:\"2-STORY 1946 & NEWER\",\n        70:\"2-STORY 1945 & OLDER\",\n        75:\"2-1\/2 STORY ALL AGES\",\n        80:\"SPLIT OR MULTI-LEVEL\",\n        85:\"SPLIT FOYER\",\n        90:\"DUPLEX - ALL STYLES AND AGES\",\n       120:\"1-STORY PUD (Planned Unit Development) - 1946 & NEWER\",\n       150:\"1-1\/2 STORY PUD - ALL AGES\",\n       160:\"2-STORY PUD - 1946 & NEWER\",\n       180:\"PUD - MULTILEVEL - INCL SPLIT LEV\/FOYER\",\n       190:\"2 FAMILY CONVERSION - ALL STYLES AND AGES\",\n}}\ncombined = combined.replace(mssubclass_vals)","b552d1e4":"diffext_values = (combined.loc[:, \"MSSubClass\"].astype('str')+ \\\n \",\"+ \\\n combined.loc[:,\"HouseStyle\"]).value_counts()\n\nfill_dict={}\nfor i, v in diffext_values.iteritems():\n    #print(fill_dict)\n    ex_vals=i.split(\",\")\n\n    dup=False\n    if ex_vals[1] in list(fill_dict.keys()):\n        if ex_vals[0] in fill_dict[ex_vals[1]]:\n            dup=True\n            \n    if ex_vals[0] in list(fill_dict.keys()):\n            fill_dict[ex_vals[0]].append(ex_vals[1])\n    else:\n        fill_dict[ex_vals[0]] =[ex_vals[1]]\n    if dup:\n        print(str(i)+\"\\t\"+str(v)+\" (DUP)\")\n    else:\n        print(str(i)+\"\\t\"+str(v))","27a619e5":"mssubclass_counts = combined[\"MSSubClass\"].value_counts()","b5edf982":"#plt.figure(figsize=(5,20))\nsns.set(style=\"whitegrid\")\nax = sns.barplot(x=mssubclass_counts.index, \n                 y=mssubclass_counts)\n#x=0\n#for index, value in mssubclass_counts.iteritems():\n#    #print(index+\":\"+str(value))\n#    ax.text(0, x, va, color='black',\n#           va='center')\n#    x+=1\n#ax.set_xlim(0,1)\nplt.xticks(rotation=90);","bbb9a5bc":"#box plot overallqual\/saleprice\ndf_train_transMSSubClass = df_train.replace(mssubclass_vals).copy()\nvar = 'MSSubClass'\ndata = pd.concat([df_train_transMSSubClass['SalePrice'], df_train_transMSSubClass[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","02e0dda6":"\ndf_train_transMSSubClass[\"MSSubClass\"].unique()","23be78ef":"df_train.loc[((df_train[\"MSSubClass\"]==20) | \n             (df_train[\"MSSubClass\"]==60) |\n             (df_train[\"MSSubClass\"]==120) |\n             (df_train[\"MSSubClass\"]==160)),\"MSSubClass_1946nNewer\"] = 1\n\ndf_train.loc[df_train[\"MSSubClass_1946nNewer\"].isnull()==True,\"MSSubClass_1946nNewer\"]=0\ndf_train_transMSSubClass[\"MSSubClass_1946nNewer\"]=df_train[\"MSSubClass_1946nNewer\"]","82bb3970":"var = 'MSSubClass_1946nNewer'\ndata = pd.concat([df_train_transMSSubClass['SalePrice'], df_train_transMSSubClass[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","7261edb3":"df_test.loc[((df_test[\"MSSubClass\"]==20) | \n             (df_test[\"MSSubClass\"]==60) |\n             (df_test[\"MSSubClass\"]==120) |\n             (df_test[\"MSSubClass\"]==160)),\"MSSubClass_1946nNewer\"] = 1\n\ndf_test.loc[df_test[\"MSSubClass_1946nNewer\"].isnull()==True,\"MSSubClass_1946nNewer\"]=0","64910ead":"df_train.loc[((df_train[\"MSSubClass\"]==120) | \n             (df_train[\"MSSubClass\"]==150) |\n             (df_train[\"MSSubClass\"]==160) |\n             (df_train[\"MSSubClass\"]==180)),\"MSSubClass_PUD\"] = 1\n\ndf_train.loc[df_train[\"MSSubClass_PUD\"].isnull()==True,\"MSSubClass_PUD\"]=0\ndf_train_transMSSubClass[\"MSSubClass_PUD\"]=df_train[\"MSSubClass_PUD\"]\ndf_train[\"MSSubClass_PUD\"].value_counts()\n","11cafa59":"var = 'MSSubClass_PUD'\ndata = pd.concat([df_train_transMSSubClass['SalePrice'], df_train_transMSSubClass[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","1db5dd6d":"df_train = df_train.drop(\"MSSubClass_PUD\",axis=1)","e6f57b82":"df_train.loc[((df_train[\"MSSubClass\"]==90) | \n             (df_train[\"MSSubClass\"]==190)),\"ShareFloor\"] = 1\n\ndf_train.loc[df_train[\"ShareFloor\"].isnull()==True,\"ShareFloor\"]=0\ndf_train_transMSSubClass[\"ShareFloor\"]=df_train[\"ShareFloor\"]","e6c95987":"var = 'ShareFloor'\ndata = pd.concat([df_train_transMSSubClass['SalePrice'], df_train_transMSSubClass[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","7e5ab745":"df_test.loc[((df_test[\"MSSubClass\"]==90) | \n             (df_test[\"MSSubClass\"]==190)),\"ShareFloor\"] = 1\n\ndf_test.loc[df_test[\"ShareFloor\"].isnull()==True,\"ShareFloor\"]=0","8dac32d9":"#box plot overallqual\/saleprice\nvar = 'HouseStyle'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","046c5c51":"df_train.loc[(((df_train[\"HouseStyle\"]=='1Story')  |\n               (df_train[\"HouseStyle\"]=='1.5Unf'))),\"Stories\"] = 1.0\n\ndf_train.loc[(((df_train[\"HouseStyle\"]=='1.5Fin') |\n               (df_train[\"HouseStyle\"]=='SLvl'))),\"Stories\"] = 1.5\n\ndf_train.loc[(((df_train[\"HouseStyle\"]=='2Story')|\n              (df_train[\"HouseStyle\"]=='SFoyer') |\n              (df_train[\"HouseStyle\"]=='2.5Unf'))),\"Stories\"] = 2\n             \ndf_train.loc[(((df_train[\"HouseStyle\"]=='2.5Fin'))),\"Stories\"] = 2.5\n\ndf_train[\"Stories\"].value_counts()","b4a8b885":"var = 'Stories'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","1386e7b1":"df_train.loc[((df_train[\"HouseStyle\"]=='1Story')  |\n               (df_train[\"HouseStyle\"]=='1.5Unf') |\n             (df_train[\"HouseStyle\"]=='1.5Fin') |\n              (df_train[\"HouseStyle\"]=='SFoyer') |\n               (df_train[\"HouseStyle\"]=='SLvl')),\"2Stories\"] = 0.0\n\ndf_train.loc[((df_train[\"HouseStyle\"]=='2Story')  |\n              (df_train[\"HouseStyle\"]=='2.5Unf') |\n             (df_train[\"HouseStyle\"]=='2.5Fin')),\"2Stories\"] = 1\n\ndf_train[\"2Stories\"].value_counts()","2373db66":"var = '2Stories'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","0cf9fbd8":"df_train = df_train.drop(\"Stories\",axis=1)\n\ndf_test.loc[((df_test[\"HouseStyle\"]=='1Story')  |\n               (df_test[\"HouseStyle\"]=='1.5Unf') |\n             (df_test[\"HouseStyle\"]=='1.5Fin') |\n              (df_test[\"HouseStyle\"]=='SFoyer') |\n               (df_test[\"HouseStyle\"]=='SLvl')),\"2Stories\"] = 0.0\n\ndf_test.loc[((df_test[\"HouseStyle\"]=='2Story')  |\n              (df_test[\"HouseStyle\"]=='2.5Unf') |\n             (df_test[\"HouseStyle\"]=='2.5Fin')),\"2Stories\"] = 1","e4e92ef2":"df_train.loc[((df_train[\"HouseStyle\"]=='1Story')  |\n               (df_train[\"HouseStyle\"]=='2Story') |\n             (df_train[\"HouseStyle\"]=='1.5Fin') |\n              (df_train[\"HouseStyle\"]=='SFoyer') |\n               (df_train[\"HouseStyle\"]=='SLvl') |\n               (df_train[\"HouseStyle\"]=='2.5Fin')),\"Unfurnished\"] = 0.0\n\ndf_train.loc[((df_train[\"HouseStyle\"]=='1.5Unf')  |\n              (df_train[\"HouseStyle\"]=='2.5Unf')),\"Unfurnished\"] = 1\n\ndf_train[\"Unfurnished\"].value_counts()","eccf1d71":"var = 'Unfurnished'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","9d8073e7":"df_test.loc[((df_test[\"HouseStyle\"]=='1Story')  |\n               (df_test[\"HouseStyle\"]=='2Story') |\n             (df_test[\"HouseStyle\"]=='1.5Fin') |\n              (df_test[\"HouseStyle\"]=='SFoyer') |\n               (df_test[\"HouseStyle\"]=='SLvl') |\n               (df_test[\"HouseStyle\"]=='2.5Fin')),\"Unfurnished\"] = 0.0\n\ndf_test.loc[((df_test[\"HouseStyle\"]=='1.5Unf')  |\n              (df_test[\"HouseStyle\"]=='2.5Unf')),\"Unfurnished\"] = 1","88286e9f":"df_train = df_train.drop(\"MSSubClass\",axis=1)\ndf_test = df_test.drop(\"MSSubClass\",axis=1)\ndf_train = df_train.drop(\"HouseStyle\",axis=1)\ndf_test = df_test.drop(\"HouseStyle\",axis=1)","532eb2ac":"combined.loc[combined[\"MasVnrArea\"]==0,\"MasVnrType\"].value_counts()","c8d68d90":"fig = plt.figure()\nsns.distplot(combined.loc[combined[\"MasVnrArea\"]>0,\n    \"MasVnrArea\"].dropna().values, fit=stats.norm).set_title(\\\n    \"MasVnrArea\");","abb177d7":"fig = plt.figure()\nsns.distplot(np.sqrt(combined.loc[combined[\"MasVnrArea\"]>0,\n    \"MasVnrArea\"].dropna().values), fit=stats.norm).set_title(\\\n    \"MasVnrArea\");","90435374":"fill_masvnrarea = (np.mean(np.sqrt(combined.loc[combined[\"MasVnrArea\"]>0,\n    \"MasVnrArea\"].dropna().values)))**2","0a4e9fbe":"df_train.loc[(df_train[\"MasVnrArea\"]==0) & \\\n             (df_train[\"MasVnrType\"]!=\"None\"),\"MasVnrArea\"] = fill_masvnrarea\n\ndf_test.loc[(df_test[\"MasVnrArea\"]==0) & \\\n             (df_test[\"MasVnrType\"]!=\"None\"),\"MasVnrArea\"] = fill_masvnrarea","aa5b1835":"#missing training data\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.loc[missing_data[\"Total\"]>0,:]","1a1fcc11":"#missing testing data\ntotal = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.loc[missing_data[\"Total\"]>0,:]","3190b8c3":"LotFrontage_ser = df_train.loc[:,\"LotFrontage\"] + \\\n    df_test.loc[:,\"LotFrontage\"]\nnotNullLotFrontage_ser = LotFrontage_ser.dropna()\nnotNullLotFrontage_ser.describe()","1917d7be":"sns.distplot(notNullLotFrontage_ser, fit=stats.norm)\nfig = plt.figure()","0462c311":"var = 'Neighborhood'\ndata = pd.concat([df_train['LotFrontage'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"LotFrontage\", data=data)\nplt.xticks(rotation=90);","2827b84d":"var = 'YearBuilt'\ndata = pd.concat([df_train['LotFrontage'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"LotFrontage\", data=data)\nplt.xticks(rotation=90);","6b981e85":"var = 'YearRemodAdd'\ndata = pd.concat([df_train['LotFrontage'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"LotFrontage\", data=data)\nplt.xticks(rotation=90);","670aa161":"# correlation matrix\nLotFrontage_corrmat = combined.loc[:,['LotFrontage','LotArea']].corr()\ncorrLotFrontage = LotFrontage_corrmat.loc[:, \"LotFrontage\"]\ncorrLotFrontage = corrLotFrontage.sort_values(ascending=False)\n\n# plot correlation\nplt.figure(figsize=(5,5))\nsns.set(style=\"whitegrid\")\nax = sns.barplot(y=corrLotFrontage.index, \n                 x=corrLotFrontage.astype(np.float))\nx=0\nfor index, value in corrLotFrontage.iteritems():\n    #print(index+\":\"+str(value))\n    ax.text(0, x, round(float(value),4), color='black',\n           va='center')\n    x+=1\nax.set_xlim(0,1)\nplt.xticks(rotation=90);","0c14adc7":"list(df_train.columns)","c9f8e1f9":"cat_candidates = df_train.dtypes[df_train.dtypes==\"object\"].index.values\ncat_candidates","ffbb1f51":"frequencies = []\nfor col in cat_candidates:\n    overall_freq = combined.loc[:, col].value_counts().max() \/ combined.shape[0]\n    frequencies.append([col, overall_freq])\n\nfrequencies = np.array(frequencies)\nfreq_df = pd.DataFrame(index=frequencies[:,0], data=frequencies[:,1], columns=[\"frequency\"])\nsorted_freq = freq_df.frequency.sort_values(ascending=False).astype(float)","e35eeac2":"plt.figure(figsize=(5,20))\nsns.set(style=\"whitegrid\")\nax = sns.barplot(y=sorted_freq.index[0:30], \n                 x=sorted_freq[0:30].astype(np.float))\nx=0\nfor index, value in sorted_freq[0:30].iteritems():\n    #print(index+\":\"+str(value))\n    ax.text(0, x, round(float(value),4), color='black',\n           va='center')\n    x+=1\nax.set_xlim(0,1)\nplt.xticks(rotation=90);","c1366122":"lowInfoGainCols = list(sorted_freq[sorted_freq.astype(float) > KEEP_COLS_WITH_MAX_PERCENT_OF_SAME_FEATURE].index)\nprint(\"Low Info Gain Columns:\")\nprint(lowInfoGainCols)\n\nprint(\"\\nValue Amounts\\n\")\nfor col in lowInfoGainCols:\n    print(col)\n    print(combined[col].value_counts())\n    print(\"\\n\")","22aff368":"df_train = df_train.drop(['Utilities'] , axis=1)\ndf_test = df_test.drop(['Utilities'] , axis=1)","95d8e12d":"df_train['Neighborhood'].value_counts()","0584b7fc":"var = 'Neighborhood'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","7c0a798d":"df_train['SalePrice'].describe()","8f5587be":"neighboorhoodBySalePrice_df = df_train.groupby('Neighborhood')['SalePrice'].median().sort_values(ascending=False)\nneighboorhoodBySalePrice_df","c7009ebd":"top_tier_n = list(neighboorhoodBySalePrice_df[neighboorhoodBySalePrice_df.values >= df_train['SalePrice'].quantile(.75)].index)\nmid_upper_tier_n = list(neighboorhoodBySalePrice_df[(neighboorhoodBySalePrice_df.values < df_train['SalePrice'].quantile(.75)) & \\\n                                              (neighboorhoodBySalePrice_df.values >= df_train['SalePrice'].quantile(.50))].index)\nmid_low_tier_n = list(neighboorhoodBySalePrice_df[(neighboorhoodBySalePrice_df.values < df_train['SalePrice'].quantile(.50)) & \\\n                                              (neighboorhoodBySalePrice_df.values >= df_train['SalePrice'].quantile(.25))].index)\nlowest_tier_n = list(neighboorhoodBySalePrice_df[neighboorhoodBySalePrice_df.values < df_train['SalePrice'].quantile(.25)].index)\nprint(top_tier_n)\nprint(mid_upper_tier_n)\nprint(mid_low_tier_n)\nprint(lowest_tier_n)\n\ndf_train.loc[df_train['Neighborhood'].isin(top_tier_n), \"neighborhoodTier\"]=3\ndf_train.loc[df_train['Neighborhood'].isin(mid_upper_tier_n), \"neighborhoodTier\"]=2\ndf_train.loc[df_train['Neighborhood'].isin(mid_low_tier_n), \"neighborhoodTier\"]=1\ndf_train.loc[df_train['Neighborhood'].isin(lowest_tier_n), \"neighborhoodTier\"]=0\ndf_test.loc[df_test['Neighborhood'].isin(top_tier_n), \"neighborhoodTier\"]=3\ndf_test.loc[df_test['Neighborhood'].isin(mid_upper_tier_n), \"neighborhoodTier\"]=2\ndf_test.loc[df_test['Neighborhood'].isin(mid_low_tier_n), \"neighborhoodTier\"]=1\ndf_test.loc[df_test['Neighborhood'].isin(lowest_tier_n), \"neighborhoodTier\"]=0","6d7bb231":"df_test[\"neighborhoodTier\"].isnull().sum()","92e5aa54":"var = 'neighborhoodTier'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","65e2fb4e":"num_candidates = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n       '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\nfor num_feat in num_candidates:\n    fig = plt.figure()\n    sns.distplot(df_train.loc[:,\n        num_feat].dropna().values, fit=stats.norm).set_title(\\\n        num_feat);\n","a4697062":"num_sqrt_candidates = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', \\\n                       'BsmtFinSF2','BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', \\\n                       '2ndFlrSF', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']\nfor num_feat in num_sqrt_candidates:\n    fig = plt.figure()\n    sns.distplot(np.sqrt(df_train.loc[df_train[num_feat]>0,\n        num_feat].dropna().values), fit=stats.norm).set_title(\\\n        num_feat);\n","00e74c02":"num_log_candidates = ['LowQualFinSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\nfor num_feat in num_log_candidates:\n    fig = plt.figure()\n    sns.distplot(np.log(df_train.loc[df_train[num_feat]>0,\n        num_feat].dropna().values), fit=stats.norm).set_title(\\\n        num_feat);\n","1a1c520c":"for num_feat in num_sqrt_candidates:\n    new_num_col = num_feat +\"_SQRT\"\n    df_train.loc[:,new_num_col]=np.sqrt(df_train.loc[:,num_feat].values)\n    df_test.loc[:,new_num_col]=np.sqrt(df_test.loc[:,num_feat].values)\n    \nfor num_feat in num_log_candidates:\n    new_num_col = num_feat +\"_LOG\"\n    df_train.loc[:,new_num_col]=np.log(df_train.loc[:,num_feat].values+.001)\n    df_test.loc[:,new_num_col]=np.log(df_test.loc[:,num_feat].values+.001)","dff0c832":"# print shape before removing duplicates\nprint(df_train.drop([\"Id\"], axis=1).shape)\n# remove the duplicates and print shape\nprint(df_train.drop([\"Id\"], axis=1).drop_duplicates().shape)","fc5443da":"# print shape before removing duplicates\nprint(df_test.drop([\"Id\"], axis=1).shape)\n# remove the duplicates and print shape\nprint(df_test.drop([\"Id\"], axis=1).drop_duplicates().shape)","52e0b611":"cleanup_nums = {\"LotShape\":     {\"Reg\": 0, \"IR1\": 1, \"IR2\" : 2, \"IR3\" : 3},\n               \"LandSlope\":{\"Gtl\":0,\"Mod\":1,\"Sev\":2},\n               \"ExterQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n               \"ExterCond\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n               \"BsmtQual\": {\"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n               \"BsmtCond\": {\"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n               \"BsmtExposure\": {\"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4},\n               \"BsmtFinType1\": {\"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5,\n                               \"GLQ\":6},\n               \"BsmtFinType2\": {\"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5,\n                               \"GLQ\":6},\n               \"HeatingQC\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n               \"CentralAir\": {\"N\": 0, \"Y\": 1},\n               \"KitchenQual\": {\"Po\": 0, \"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                \"Functional\": {\"Sal\": 0, \"Sev\": 1, \"Maj2\": 2, \"Maj1\": 3, \"Mod\": 4,\n                              \"Min2\": 5, \"Min1\": 6, \"Typ\": 7},\n                \"FireplaceQu\": {\"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                 \"GarageFinish\": {\"Unf\": 1, \"RFn\": 2, \"Fin\": 3},\n                \"GarageQual\": {\"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                \"GarageCond\": {\"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5},\n                \"PavedDrive\": {\"N\": 0, \"P\": 1, \"Y\": 2},\n                \"PoolQC\": {\"Fa\": 1, \"TA\": 2, \"Gd\": 3, \"Ex\": 4},\n                \"Fence\": {\"MnWw\": 1, \"GdWo\": 2, \"MnPrv\": 3, \"GdPrv\": 4},\n               }","7a8e41bd":"df_train = df_train.replace(cleanup_nums)\ndf_test = df_test.replace(cleanup_nums)","b1b80c17":"cat_ord_vars_all=[ \"MSZoning\", \"Street\", \"LandContour\", \\\n             \"LotConfig\", \"Neighborhood\", \"BldgType\", \\\n             \"RoofStyle\", \"RoofMatl\", \"MasVnrType\", \\\n             \"Foundation\", \"Electrical\", \"Heating\", \"GarageType\", \"MiscFeature\", \\\n             \"SaleType\", \"SaleCondition\", \"MoSold\"]\ncat_ord_vars = [x for x in cat_ord_vars_all if x not in lowInfoGainCols]","a3a247fa":"df_train.columns[df_train.isnull().any()]","ba636152":"df_test.columns[df_test.isnull().any()]","3016bd01":"df_train.loc[df_train[\"Alley\"].isnull()==True,\"Alley\"]=0\ndf_test.loc[df_test[\"Alley\"].isnull()==True,\"Alley\"]=0","9c06ca06":"all_electrical_series = df_train[\"Electrical\"].append(df_test[\"Electrical\"])\nmostCommonElectricalValue=all_electrical_series.mode().values[0]\nprint(mostCommonElectricalValue)\n\ndf_train.loc[df_train[\"Electrical\"].isnull()==True,\"Electrical\"]=mostCommonElectricalValue\ndf_test.loc[df_test[\"Electrical\"].isnull()==True,\"Electrical\"]=mostCommonElectricalValue","fb5e1e06":"combined = pd.concat([df_train, df_test], sort=False)\nfor nieghborhood in list(combined[\"Neighborhood\"].unique()):\n    df_train.loc[(df_train[\"LotFrontage\"].isnull()==True) & \\\n        (df_train[\"Neighborhood\"]==nieghborhood), \\\n        \"LotFrontage\"] = \\\n        combined[\"LotFrontage\"].groupby(combined[\"Neighborhood\"]).median()[nieghborhood]\n    df_test.loc[(df_test[\"LotFrontage\"].isnull()==True) & \\\n        (df_test[\"Neighborhood\"]==nieghborhood), \\\n        \"LotFrontage\"] = \\\n        combined[\"LotFrontage\"].groupby(combined[\"Neighborhood\"]).median()[nieghborhood]","8a734e2d":"df_train.loc[df_train[\"Fireplaces\"]==0,\"FireplaceQu\"]=0\ndf_test.loc[df_test[\"Fireplaces\"]==0,\"FireplaceQu\"]=0","94c4248c":"df_train.loc[df_train[\"PoolArea\"]==0,\"PoolQC\"]=0\ndf_test.loc[df_test[\"PoolArea\"]==0,\"PoolQC\"]=0","1e6dd2b7":"if \"PoolQC\" not in lowInfoGainCols:\n    print(df_train[\"PoolQC\"].isnull().sum())\n    print(df_test[\"PoolQC\"].isnull().sum())","d87b3441":"sd_of_pool_sizes = np.mean(df_train.loc[df_train[\"PoolArea\"] > 0 , \"PoolArea\"].append(\n    df_test.loc[df_test[\"PoolArea\"] > 0 , \"PoolArea\"]))\nprint (sd_of_pool_sizes)\nfor idx, row in df_test.loc[df_test[\"PoolQC\"].isnull(),:].iterrows():\n    minPoolArea = row[\"PoolArea\"] - sd_of_pool_sizes\n    if minPoolArea < 0:\n        minPoolArea = 0\n    maxPoolArea = row[\"PoolArea\"] + sd_of_pool_sizes\n    df_train_poolqc_df = df_train.loc[(df_train[\"PoolArea\"] > minPoolArea) & \\\n                                      (df_train[\"PoolArea\"] < maxPoolArea),\n                                      [\"PoolQC\"]]\n    df_test_poolqc_df = df_test.loc[(df_test[\"PoolArea\"] > minPoolArea) & \\\n                                        (df_test[\"PoolArea\"] < maxPoolArea),\n                                        [\"PoolQC\"]]\n    meanPoolQC = np.round(df_train_poolqc_df.append(df_test_poolqc_df).mean(skipna=True),0)\n    df_test.loc[idx,\"PoolQC\"] = meanPoolQC.values[0]\n        #.mean(skipna=True)\n    ","5eeddc7f":"df_train.loc[df_train[\"Functional\"].isnull(),\"Functional\"]=7\ndf_test.loc[df_test[\"Functional\"].isnull(),\"Functional\"]=7","ce95fa9d":"df_train.loc[df_train[\"Fence\"].isnull(),\"Fence\"]=0\ndf_test.loc[df_test[\"Fence\"].isnull(),\"Fence\"]=0","7fe9de41":"df_train.loc[ \\\n             df_train.loc[:,[\"MasVnrArea\",\"MasVnrType\"]].isnull().all(axis=1), \\\n             \"HasMasVnr\"]=0\ndf_train.loc[ \\\n             df_train.loc[:,[\"MasVnrArea\",\"MasVnrType\"]].isnull().all(axis=1),\n             \"MasVnrArea\"]=0\ndf_train.loc[(df_train[\"MasVnrArea\"]>0) | (df_train[\"MasVnrType\"].isnull()==False),\"HasMasVnr\"]=1\n\ndf_test.loc[ \\\n            df_test.loc[:,[\"MasVnrArea\",\"MasVnrType\"]].isnull().all(axis=1), \\\n            \"HasMasVnr\"]=0\ndf_test.loc[ \\\n            df_test.loc[:,[\"MasVnrArea\",\"MasVnrType\"]].isnull().all(axis=1),\n            \"MasVnrArea\"]=0\ndf_test.loc[(df_test[\"MasVnrArea\"]>0) | (df_test[\"MasVnrType\"].isnull()==False),\"HasMasVnr\"]=1","2f40d8b7":"garage_cat_features_all=[\"GarageType\",\"GarageYrBlt\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"GarageFinish\"]\ngarage_cat_features = [x for x in garage_cat_features_all if x not in lowInfoGainCols]\ngarage_features = garage_cat_features + [\"GarageArea\", \"GarageCars\"]\ndf_train.loc[ \\\n    (df_train.loc[:,garage_cat_features].isnull().all(axis=1)) & \\\n             ((df_train[\"GarageArea\"] == 0) |  (df_train[\"GarageArea\"].isnull() == True)) & \\\n             ((df_train[\"GarageCars\"] == 0) |  (df_train[\"GarageCars\"].isnull() == True)), \\\n    \"HasGarage\"]=0\ndf_train.loc[ \\\n    (df_train.loc[:,garage_cat_features].notnull().any(axis=1)) | \\\n             (df_train[\"GarageArea\"] > 0) | \\\n             (df_train[\"GarageCars\"] > 0), \\\n    \"HasGarage\"]=1\n\ndf_test.loc[ \\\n    (df_test.loc[:,garage_cat_features].isnull().all(axis=1)) & \\\n             ((df_test[\"GarageArea\"] == 0) |  (df_test[\"GarageArea\"].isnull() == True)) & \\\n             ((df_test[\"GarageCars\"] == 0) |  (df_test[\"GarageCars\"].isnull() == True)), \\\n    \"HasGarage\"]=0\ndf_test.loc[ \\\n    (df_test.loc[:,garage_cat_features].notnull().any(axis=1)) | \\\n             (df_test[\"GarageArea\"] > 0) | \\\n             (df_test[\"GarageCars\"] > 0), \\\n    \"HasGarage\"]=1","6acb371a":"for gar_feat in garage_features:\n    if gar_feat not in cat_ord_vars:\n        df_train.loc[df_train[\"HasGarage\"]==0,gar_feat]=0\n        df_test.loc[df_test[\"HasGarage\"]==0,gar_feat]=0","ecfb18ef":"df_train.loc[df_train[\"GarageYrBlt\"].isnull(),\"GarageYrBlt\"] = df_train[\"GarageYrBlt\"].mode(dropna=True)\ndf_test.loc[df_test[\"GarageYrBlt\"].isnull(),\"GarageYrBlt\"] = df_test[\"GarageYrBlt\"].mode(dropna=True)","99004259":"low_cols=[]\nfor gcol in garage_features:\n    print(\"Number of %s Nulls in Training + Testing Respectively:\" % gcol)\n    print(df_train[gcol].isnull().sum())\n    print(df_test[gcol].isnull().sum())\n    if df_train[gcol].isnull().sum() + df_test[gcol].isnull().sum() < 3:\n        low_cols.append(gcol)\nprint(\"rows with low amount of null values\")\nprint(low_cols)","7855a08a":"garage_corrmat = df_train.loc[:,garage_features+[\"SalePrice\"]].corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(garage_corrmat, square=True);","c1708495":"df_test.loc[df_test.loc[:,low_cols].isnull().any(axis=1), \\\n            low_cols]","558902c1":"for grow in low_cols:\n    mean_val = df_train[grow].append(df_test[grow]).mean(skipna=True)\n    if (df_train[grow].dtypes == \"int64\"):\n        mean_val = int(np.round(mean_val,0))\n    df_test.loc[df_test[grow].isnull()==True,grow]=mean_val\n","6ea475de":"df_test.iloc[[666,1116],:].loc[:,low_cols]","19c9c1e0":"basement_cat_features_all=[\"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\"]\nbasement_cat_features = [x for x in basement_cat_features_all if x not in lowInfoGainCols]\nbasement_features= basement_cat_features + \\\n    [\"HasBasement\",\"BsmtFinSF1\",\"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"BsmtFullBath\", \"BsmtHalfBath\"]\n\ndf_train.loc[ \\\n    (df_train.loc[:,basement_cat_features].isnull().all(axis=1)) & \\\n             ((df_train[\"BsmtFinSF1\"] == 0) | (df_train[\"BsmtFinSF1\"].isnull() == True)) & \\\n             ((df_train[\"BsmtFinSF2\"] == 0) | (df_train[\"BsmtFinSF2\"].isnull() == True)) & \\\n             ((df_train[\"BsmtUnfSF\"] == 0) | (df_train[\"BsmtUnfSF\"].isnull() == True)) & \\\n             ((df_train[\"TotalBsmtSF\"] == 0) | (df_train[\"TotalBsmtSF\"].isnull() == True)) & \\\n             ((df_train[\"BsmtFullBath\"] == 0) | (df_train[\"BsmtFullBath\"].isnull() == True)) & \\\n             ((df_train[\"BsmtHalfBath\"] == 0) | (df_train[\"BsmtHalfBath\"].isnull() == True)), \\\n    \"HasBasement\"]=0\n#df_train.loc[ \\\n#    (df_train.loc[:,basement_features].isnull().all(axis=1)), \\\n#    \"HasBasement\"]=0\ndf_train.loc[ \\\n    (df_train.loc[:,basement_cat_features].notnull().any(axis=1)) | \\\n             (df_train[\"BsmtFinSF1\"] > 0) | \\\n             (df_train[\"BsmtFinSF2\"] > 0) | \\\n             (df_train[\"BsmtUnfSF\"] > 0) | \\\n             (df_train[\"TotalBsmtSF\"] > 0) | \\\n             (df_train[\"BsmtFullBath\"] > 0) | \\\n             (df_train[\"BsmtHalfBath\"] > 0), \\\n    \"HasBasement\"]=1\n\ndf_test.loc[ \\\n    (df_test.loc[:,basement_cat_features].isnull().all(axis=1)) & \\\n             ((df_test[\"BsmtFinSF1\"] == 0) | (df_test[\"BsmtFinSF1\"].isnull() == True)) & \\\n             ((df_test[\"BsmtFinSF2\"] == 0) | (df_test[\"BsmtFinSF2\"].isnull() == True)) & \\\n             ((df_test[\"BsmtUnfSF\"] == 0) | (df_test[\"BsmtUnfSF\"].isnull() == True)) & \\\n             ((df_test[\"TotalBsmtSF\"] == 0) | (df_test[\"TotalBsmtSF\"].isnull() == True)) & \\\n             ((df_test[\"BsmtFullBath\"] == 0) | (df_test[\"BsmtFullBath\"].isnull() == True)) & \\\n             ((df_test[\"BsmtHalfBath\"] == 0) | (df_test[\"BsmtHalfBath\"].isnull() == True)), \\\n    \"HasBasement\"]=0\n#df_test.loc[ \\\n#    (df_test.loc[:,basement_features].isnull().all(axis=1)), \\\n#    \"HasBasement\"]=0\ndf_test.loc[ \\\n    (df_test.loc[:,basement_cat_features].notnull().any(axis=1)) | \\\n             (df_test[\"BsmtFinSF1\"] > 0) | \\\n             (df_test[\"BsmtFinSF2\"] > 0) | \\\n             (df_test[\"BsmtUnfSF\"] > 0) | \\\n             (df_test[\"TotalBsmtSF\"] > 0) | \\\n             (df_test[\"BsmtFullBath\"] > 0) | \\\n             (df_test[\"BsmtHalfBath\"] > 0), \\\n    \"HasBasement\"]=1","7adff7aa":"for basem_feat in basement_features:\n    if basem_feat not in cat_ord_vars:\n        df_train.loc[df_train[\"HasBasement\"]==0,basem_feat]=0\n        df_test.loc[df_test[\"HasBasement\"]==0,basem_feat]=0","a31e1cc3":"for bcol in basement_features:\n    print(\"Number of %s Nulls in Training + Testing Respectively:\" % bcol)\n    print(df_train[bcol].isnull().sum())\n    print(df_test[bcol].isnull().sum())","3962f940":"basement_corrmat = df_train[basement_features].corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(basement_corrmat, square=True);","3de5b1cd":"print(df_train.loc[:,[\"BsmtQual\",\"BsmtCond\"]].isnull().all(axis=1).shape)","c6145d57":"df_train.loc[df_train[\"BsmtQual\"].isnull(),\"BsmtQual\"]=df_train.loc[df_train[\"BsmtQual\"].isnull(),\"BsmtCond\"]\ndf_test.loc[df_test[\"BsmtQual\"].isnull(),\"BsmtQual\"]=df_test.loc[df_test[\"BsmtQual\"].isnull(),\"BsmtCond\"]\ndf_train.loc[df_train[\"BsmtCond\"].isnull(),\"BsmtCond\"]=df_train.loc[df_train[\"BsmtCond\"].isnull(),\"BsmtQual\"]\ndf_test.loc[df_test[\"BsmtCond\"].isnull(),\"BsmtCond\"]=df_test.loc[df_test[\"BsmtCond\"].isnull(),\"BsmtQual\"]","97dc566c":"avg_basement_exposure_given_basement = np.round(\n    df_train.loc[df_train[\"HasBasement\"]==1,\"BsmtExposure\"].append(\n        df_test.loc[df_test[\"HasBasement\"]==1,\"BsmtExposure\"]).mean(skipna=True),0)\nprint(avg_basement_exposure_given_basement)\ndf_train.loc[df_train[\"BsmtExposure\"].isnull(),\"BsmtExposure\"] = avg_basement_exposure_given_basement\ndf_test.loc[df_test[\"BsmtExposure\"].isnull(),\"BsmtExposure\"] = avg_basement_exposure_given_basement","c2403ac7":"print(df_train.loc[df_train[\"BsmtFinType2\"].isnull(),\"BsmtFinSF2\"])","002ade3c":"BsmtFinSF2_train_test_df = \\\n    df_train.loc[df_train[\"BsmtFinSF2\"]>0,[\"BsmtFinSF2\",\"BsmtFinType2\"]].append(\n    df_test.loc[df_test[\"BsmtFinSF2\"]>0,[\"BsmtFinSF2\",\"BsmtFinType2\"]])\nnp.std(BsmtFinSF2_train_test_df[\"BsmtFinSF2\"])","247ae65d":"min_BsmtFinSF2 = df_train.loc[df_train[\"BsmtFinType2\"].isnull(),\"BsmtFinSF2\"] - \\\n    np.std(BsmtFinSF2_train_test_df[\"BsmtFinSF2\"])\nmax_BsmtFinSF2 = df_train.loc[df_train[\"BsmtFinType2\"].isnull(),\"BsmtFinSF2\"] + \\\n    np.std(BsmtFinSF2_train_test_df[\"BsmtFinSF2\"])\nsubset_BsmtFinSF2_train_test_df = BsmtFinSF2_train_test_df.loc[ \\\n    (BsmtFinSF2_train_test_df[\"BsmtFinSF2\"] > min_BsmtFinSF2.values[0]) & \\\n    (BsmtFinSF2_train_test_df[\"BsmtFinSF2\"] < max_BsmtFinSF2.values[0]),\"BsmtFinType2\"]\n\ndf_train.loc[df_train[\"BsmtFinType2\"].isnull(),\"BsmtFinType2\"] = \\\n    np.round(subset_BsmtFinSF2_train_test_df.mean(skipna=True),0)","b707cf1a":"print(df_train[\"KitchenQual\"].isnull().sum())\nprint(df_test[\"KitchenQual\"].isnull().sum())","1c2f75f4":"df_train.loc[df_train[\"KitchenQual\"].isnull(),\"KitchenQual\"] = np.round(df_train[\"KitchenQual\"].append(df_test[\"KitchenQual\"]).mean(skipna=True),0)\ndf_test.loc[df_test[\"KitchenQual\"].isnull(),\"KitchenQual\"] = np.round(df_train[\"KitchenQual\"].append(df_test[\"KitchenQual\"]).mean(skipna=True),0)","0b974976":"df_train.columns[df_train.isnull().any()]","f67905ec":"df_test.columns[df_test.isnull().any()]","33d7e697":"# add one-hot encoded columns based on `col` in `df` to `df`\ndef one_hot_encode(df, col):\n    df[col] = pd.Categorical(df[col])\n    dfDummies = pd.get_dummies(df[col], prefix = col)\n    df = pd.concat([df, dfDummies], axis=1)\n    #df = df.drop([col],axis=1)\n    return(df)","808dc947":"for cat_ord_col in cat_ord_vars:\n        df_train = one_hot_encode(df_train,cat_ord_col)\n        df_test = one_hot_encode(df_test,cat_ord_col)","4b2f1830":"train_cols = list(df_train.columns.sort_values().unique())\ntest_cols = list(df_test.columns.sort_values().unique())\nuniq_train_cols = [x for x in train_cols if (x not in test_cols and x != \"SalePrice\")]\nuniq_test_cols = [x for x in test_cols if x not in train_cols]\n\nprint(\"length of unique training columns: \"+ str(len(uniq_train_cols)))\nprint(\"length of unique test columns: \"+ str(len(uniq_test_cols)))\ndf_train = df_train.drop(uniq_train_cols,axis=1)\ndf_test = df_test.drop(uniq_test_cols,axis=1)","9f0e1f8a":"# Overall quality of the house\ndf_train[\"OverallGrade\"] = df_train[\"OverallQual\"] * df_train[\"OverallCond\"]\ndf_test[\"OverallGrade\"] = df_test[\"OverallQual\"] * df_test[\"OverallCond\"]\n\n#scatter plot OverallGrade\/saleprice\nvar = 'OverallGrade'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","41be533b":"# Overall quality of the garage\ndf_train[\"GarageGrade\"] = df_train[\"GarageQual\"] * df_train[\"GarageCond\"]\ndf_test[\"GarageGrade\"] = df_test[\"GarageQual\"] * df_test[\"GarageCond\"]\n\n#scatter plot GarageGrade\/saleprice\nvar = 'GarageGrade'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","6077581f":"# Overall quality of the exterior\ndf_train[\"ExterGrade\"] = df_train[\"ExterQual\"] * df_train[\"ExterCond\"]\ndf_test[\"ExterGrade\"] = df_train[\"ExterQual\"] * df_train[\"ExterCond\"]\n\n#scatter plot ExterGrade\/saleprice\nvar = 'ExterGrade'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","1ecc422a":"# Overall kitchen score\ndf_train[\"KitchenScore\"] = df_train[\"KitchenAbvGr\"] * df_train[\"KitchenQual\"]\ndf_test[\"KitchenScore\"] = df_train[\"KitchenAbvGr\"] * df_train[\"KitchenQual\"]\n\n#scatter plot KitchenScore\/saleprice\nvar = 'KitchenScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","6e6c40c4":"# Overall fireplace score\ndf_train[\"FireplaceScore\"] = df_train[\"Fireplaces\"] * df_train[\"FireplaceQu\"]\ndf_test[\"FireplaceScore\"] = df_train[\"Fireplaces\"] * df_train[\"FireplaceQu\"]\n\n\n#scatter plot FireplaceScore\/saleprice\nvar = 'FireplaceScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","ce1ffc6c":"# Overall garage score\ndf_train[\"GarageScore\"] = df_train[\"GarageArea\"] * df_train[\"GarageQual\"]\ndf_test[\"GarageScore\"] = df_train[\"GarageArea\"] * df_train[\"GarageQual\"]\n\n#scatter plot GarageScore\/saleprice\nvar = 'GarageScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","17bd9294":"# Total number of bathrooms\ndf_train[\"TotalBath\"] = df_train[\"BsmtFullBath\"] + (0.5 * df_train[\"BsmtHalfBath\"]) + df_train[\"FullBath\"] + (0.5 * df_train[\"HalfBath\"])\ndf_test[\"TotalBath\"] = df_train[\"BsmtFullBath\"] + (0.5 * df_train[\"BsmtHalfBath\"]) + df_train[\"FullBath\"] + (0.5 * df_train[\"HalfBath\"])\n#scatter plot TotalBath\/saleprice\nvar = 'TotalBath'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","cdf9add5":"# Total SF for house (incl. basement)\ndf_train[\"AllSF\"] = df_train[\"GrLivArea\"] + df_train[\"TotalBsmtSF\"]\ndf_test[\"AllSF\"] = df_train[\"GrLivArea\"] + df_train[\"TotalBsmtSF\"]\n#scatter plot GarageScore\/saleprice\nvar = 'GarageScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","c2435627":"# Total SF for 1st + 2nd floors\ndf_train[\"AllFlrsSF\"] = df_train[\"1stFlrSF\"] + df_train[\"2ndFlrSF\"]\ndf_test[\"AllFlrsSF\"] = df_train[\"1stFlrSF\"] + df_train[\"2ndFlrSF\"]\n#scatter plot GarageScore\/saleprice\nvar = 'GarageScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","ac488691":"# Total SF for porch\ndf_train[\"AllPorchSF\"] = df_train[\"OpenPorchSF\"] + df_train[\"EnclosedPorch\"] + df_train[\"3SsnPorch\"] + df_train[\"ScreenPorch\"]\ndf_test[\"AllPorchSF\"] = df_train[\"OpenPorchSF\"] + df_train[\"EnclosedPorch\"] + df_train[\"3SsnPorch\"] + df_train[\"ScreenPorch\"]\n#scatter plot GarageScore\/saleprice\nvar = 'GarageScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","2692b383":"# House completed before sale or not\ndf_train[\"BoughtOffPlan\"] = df_train.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\ndf_test[\"BoughtOffPlan\"] = df_train.SaleCondition.replace({\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n\nvar = 'BoughtOffPlan'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","2546fc72":"# drop categorical ordinal columns that are not encoded\ndf_train_numerical = df_train.drop(cat_ord_vars, axis=1)\n# drop categorical ordinal columns that are not encoded\ndf_test_numerical = df_test.drop(cat_ord_vars, axis=1)","032cc929":"combined = pd.concat([df_train_numerical, df_test_numerical])\none_hot_cols_lofl = []\nfor car_ord_predix in cat_ord_vars + [\"Exterior\", \"Condition\"]:\n    one_hot_cols_lofl.append(\n        [x for x in list(combined.columns) if car_ord_predix in x])\none_hot_cols = [item for sublist in one_hot_cols_lofl for item in sublist]","c4888bec":"# set minimum threshold of percent of 0's in the column we consider as low info gain\nMIN_PER_INFO_GAIN=.80\n\nfrequencies = []\n\nfor col in one_hot_cols:\n    overall_freq = combined.loc[:, col].value_counts()[0] \/ combined.shape[0]\n    frequencies.append([col, overall_freq])\n\nfrequencies = np.array(frequencies)\nfreq_df = pd.DataFrame(index=frequencies[:,0], data=frequencies[:,1], columns=[\"frequency\"])\nsorted_freq = freq_df.frequency.sort_values(ascending=False)\n\nlowInfoGainCols2 = list(sorted_freq[sorted_freq.astype(float) > KEEP_COLS_WITH_MAX_PERCENT_OF_SAME_FEATURE].index)\n\ntotal_catNom = len(sorted_freq)\ntotal_catNom_OverPerSameValue = len(lowInfoGainCols2)\n\nprint(\"total number of categorical-norminal columns:\")\nprint(total_catNom)\n\nprint(\"number of categorical-nominal columns with over %.0f%% of 0:\" % (round(KEEP_COLS_WITH_MAX_PERCENT_OF_SAME_FEATURE*100,0)))\nprint(total_catNom_OverPerSameValue)\n\nprint(\"percent of categorical-nominal columns with over %.0f%% of the same value over total:\" % (round(KEEP_COLS_WITH_MAX_PERCENT_OF_SAME_FEATURE*100,0)))\nprint(round(float(total_catNom_OverPerSameValue)\/float(total_catNom),2))\n\n#plt.figure(figsize=(5,20))\n#sns.set(style=\"whitegrid\")\n#ax = sns.barplot(y=sorted_freq.index[0:30], \n#                 x=sorted_freq[0:30].astype(np.float))\n#x=0\n#for index, value in sorted_freq[0:30].iteritems():\n#    #print(index+\":\"+str(value))\n#    ax.text(0, x, round(float(value),4), color='black',\n#           va='center')\n#    x+=1\n#ax.set_xlim(0,1)\n#plt.xticks(rotation=90);","ae394a49":"print(len(list(df_train_numerical.columns)))\ndf_train_numerical = df_train_numerical.drop(lowInfoGainCols2, axis=1)\ndf_test_numerical = df_test_numerical.drop(lowInfoGainCols2, axis=1)\ndf_train = df_train.drop(lowInfoGainCols2, axis=1)\ndf_test = df_test.drop(lowInfoGainCols2, axis=1)\n\nprint(len(list(df_train_numerical.columns)))","ecb05e01":"one_hot_cols = [x for x in one_hot_cols if x in list(df_train_numerical.columns)]","be982b0c":"# plot all the one_hot columns:\nif 1==0:\n    for var in one_hot_cols:\n        data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n        f, ax = plt.subplots(figsize=(8, 6))\n        fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n        plt.xticks(rotation=90);","44f04a0f":"# plot only the one hot cols where the mean SalePrice of the group is\n# greater than 1 SD above the mean SalePrice of not containing that\n# group\nbest_one_hot_cols=[]\nfor var in one_hot_cols:\n    val0_mean = df_train.groupby(var)['SalePrice'].mean()[0]\n    val0_std = df_train.groupby(var)['SalePrice'].std()[0]\n    val1_mean = df_train.groupby(var)['SalePrice'].mean()[1]\n    if val1_mean < (val0_mean-val0_std) or val1_mean >(val0_mean+val0_std):\n        if var not in best_one_hot_cols:\n            best_one_hot_cols.append(var)\n        data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n        f, ax = plt.subplots(figsize=(8, 6))\n        fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n        plt.xticks(rotation=90);\nprint(best_one_hot_cols)","be1c7955":"list(df_train_numerical.columns)","d82f24ea":"# correlation matrix\ncorrmat = df_train_numerical.corr()\ncorrSalePrice = corrmat.loc[abs(corrmat[\"SalePrice\"]) > .50, \"SalePrice\"]\ncorrSalePrice = corrSalePrice.sort_values(ascending=False)\n\n# plot correlation\nplt.figure(figsize=(5,20))\nsns.set(style=\"whitegrid\")\nax = sns.barplot(y=corrSalePrice.index, \n                 x=corrSalePrice.astype(np.float))\nx=0\nfor index, value in corrSalePrice.iteritems():\n    #print(index+\":\"+str(value))\n    ax.text(0, x, round(float(value),4), color='black',\n           va='center')\n    x+=1\nax.set_xlim(0,1)\nplt.xticks(rotation=90);","eb2e034a":"# how much are they correlated to each other?\ncorrSalePrice = corrmat.loc[abs(corrmat[\"SalePrice\"]) > 0.5, \"SalePrice\"]\ncorrSalePrice = corrSalePrice.sort_values(ascending=False)\ncorr2SalePrice = list(corrSalePrice.index)\n\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat.loc[corr2SalePrice,corr2SalePrice], square=True);","cef6ea82":"#box plot overallqual\/saleprice\nvar = 'OverallQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","1d41bcab":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","e02a6ea6":"df_train = df_train.drop(list(df_train.loc[df_train['GrLivArea']>4000,:].index))","86487273":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","f3430893":"#box plot overallqual\/saleprice\nvar = 'ExterQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n","0a7b01fe":"#box plot overallqual\/saleprice\nvar = 'KitchenQual'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","339441c0":"#box plot overallqual\/saleprice\nvar = 'GarageCars'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","b0961e60":"garageCarsReplaceDict = {\"GarageCars\":{4:3}}\n\ndf_train = df_train.replace(garageCarsReplaceDict)\ndf_test = df_test.replace(garageCarsReplaceDict)","5e66bb8b":"#box plot overallqual\/saleprice\nvar = 'GarageCars'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","84f9f640":"#scatter plot grlivarea\/saleprice\nvar = 'GarageScore'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","c9f35be6":"#scatter plot grlivarea\/saleprice\nvar = 'GarageScore'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","e3baeccc":"df_train.loc[:,'GarageScore']=np.log(df_train.loc[:,'GarageScore'].values)\ndf_test.loc[:,'GarageScore']=np.log(df_test.loc[:,'GarageScore'].values)","475aba93":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","fae09f5a":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\ndata = pd.concat([df_train['SalePrice'], np.log(df_train[var])], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","e0bb7eda":"df_train.loc[:,'TotalBsmtSF']=np.log(df_train.loc[:,'TotalBsmtSF'].values)\ndf_test.loc[:,'TotalBsmtSF']=np.log(df_test.loc[:,'TotalBsmtSF'].values)","42210477":"#box plot overallqual\/saleprice\nvar = 'FullBath'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","a6c7218c":"FullBathReplaceDict = {\"FullBath\":{0:1}}\n\ndf_train = df_train.replace(FullBathReplaceDict)\ndf_test = df_test.replace(FullBathReplaceDict)","17287013":"#box plot overallqual\/saleprice\nvar = 'FullBath'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","70eaa72a":"#box plot overallqual\/saleprice\nvar = 'GarageFinish'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","06e4026e":"df_train['TotRmsAbvGrd'].describe()","4721d4d3":"#box plot overallqual\/saleprice\nvar = 'TotRmsAbvGrd'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)","42a9313c":"#scatter plot grlivarea\/saleprice\nvar = 'TotRmsAbvGrd'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","f1d37691":"var = 'FireplaceQu'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","094e75fa":"var = 'YearBuilt'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","d73487bf":"var = 'YearRemodAdd'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","4df20c36":"var = 'YearRemodAdd'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.regplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","34f6ddbc":"year_data_released=2010\ndf_train_numerical['YearSinceRemodel'] = year_data_released - df_train_numerical['YearRemodAdd']\ndf_train_numerical['YearSinceBuilt'] = year_data_released - df_train_numerical['YearBuilt']\ndf_train_numerical['YearSinceRemodelPlusBuilt'] = df_train_numerical['YearSinceRemodel'] + df_train_numerical['YearSinceBuilt']","8d50f11c":"var = 'YearSinceRemodelPlusBuilt'\ndata = pd.concat([df_train_numerical['SalePrice'], df_train_numerical[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","cffd9fdd":"var = 'YearSinceRemodelPlusBuilt'\ndata = pd.concat([df_train_numerical['SalePrice'], df_train_numerical[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.regplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","050fd856":"df_train.loc[:,['MoSold','YrSold']]\ndf_train.loc[:,'YrMoSold'] = df_train['YrSold'].values + (df_train['MoSold'].astype(float).values-1)\/(12)","78554edb":"df_train.loc[:,'YrMoSold'].describe()","1e92c80a":"\n\nvar = 'YrMoSold'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\nplt.xticks(rotation=90);","d97b5cfc":"var = 'YrMoSold'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.regplot(x=var, y=\"SalePrice\", data=data, robust=True)\nplt.xticks(rotation=90);","af6faf17":"fav_variables=['OverallQual','YearRemodAdd','FireplaceQu', \\\n               'GarageFinish', 'FullBath', 'GarageCars', \\\n               'KitchenQual', 'ExterQual', 'ExterQual',\n              'GrLivArea', 'GarageScore', 'TotalBsmtSF'] + \\\n                best_one_hot_cols","cce85cb9":"b = np.log([1,10000,10000000])\nnp.exp(b)","ed36db7b":"from sklearn.linear_model import LinearRegression\nif 1==1:\n    X_train = df_train_numerical.loc[:,fav_variables].copy()\n    y_train = df_train_numerical.loc[:,\"SalePrice\"].copy()\n    X_pred = df_test_numerical.loc[:,fav_variables].copy()\n    reg = LinearRegression().fit(X_train, y_train)\n    pred = reg.predict(X_pred)\n    #pred=np.power(10,pred)\n    df_test.loc[:,\"SalePrice\"]=np.exp(pred)\n    sub_df = df_test.loc[:,[\"Id\",\"SalePrice\"]]\n    sub_df.to_csv(\"submission.csv\", index=False)","0dfad42e":"if 1==0:\n    X_train_n2 = df_train_numerical.loc[df_train_numerical['neighborhoodTier']==2,fav_variables].copy()\n    y_train_n2 = df_train_numerical.loc[df_train_numerical['neighborhoodTier']==2,\"SalePrice\"].copy()\n    X_sub_n2 = df_test_numerical.loc[df_test_numerical['neighborhoodTier']==2,[\"Id\",\"neighborhoodTier\"]+fav_variables]\n    X_pred_n2 = df_test_numerical.loc[df_test_numerical['neighborhoodTier']==2,fav_variables].copy()\n    print(\"Top Tier\")\n    print(X_train_n2.shape)\n    print(X_sub_n2.shape)\n    reg_n2 = LinearRegression().fit(X_train_n2, y_train_n2)\n    pred_n2 = reg_n2.predict(X_pred_n2)\n    print(len(pred_n2))\n    X_sub_n2.loc[:,\"SalePrice\"]=pred_n2\n    #X_sub_n2 = X_sub_n2.loc[:,[\"Id\",\"SalePrice\"]]\n    \n\n    X_train_n1 = df_train_numerical.loc[df_train_numerical['neighborhoodTier']==1,fav_variables].copy()\n    y_train_n1 = df_train_numerical.loc[df_train_numerical['neighborhoodTier']==1,\"SalePrice\"].copy()\n    X_sub_n1 = df_test_numerical.loc[df_test_numerical['neighborhoodTier']==1,[\"Id\",\"neighborhoodTier\"]+fav_variables]\n    X_pred_n1 = df_test_numerical.loc[df_test_numerical['neighborhoodTier']==1,fav_variables].copy()\n    print(\"Mid Tier\")\n    print(X_train_n1.shape)\n    print(X_sub_n1.shape)\n    reg_n1 = LinearRegression().fit(X_train_n1, y_train_n1)\n    pred_n1 = reg_n1.predict(X_pred_n1)\n    X_sub_n1.loc[:,\"SalePrice\"]=pred_n1\n    #X_sub_n1 = X_sub_n1.loc[:,[\"Id\",\"SalePrice\"]]\n    \n\n    X_train_n0 = df_train_numerical.loc[df_train_numerical['neighborhoodTier']==0,fav_variables].copy()\n    y_train_n0 = df_train_numerical.loc[df_train_numerical['neighborhoodTier']==0,\"SalePrice\"].copy()\n    X_sub_n0 = df_test_numerical.loc[df_test_numerical['neighborhoodTier']==0,[\"Id\",\"neighborhoodTier\"]+fav_variables]\n    X_pred_n0 = df_test_numerical.loc[df_test_numerical['neighborhoodTier']==0,fav_variables].copy()\n    print(\"Low Tier\")\n    print(X_train_n0.shape)\n    print(X_sub_n0.shape)\n    reg_n0 = LinearRegression().fit(X_train_n0, y_train_n0)\n    pred_n0 = reg_n0.predict(X_pred_n0)\n    X_sub_n0.loc[:,\"SalePrice\"]=pred_n0\n    #X_sub_n0 = X_sub_n0.loc[:,[\"Id\",\"SalePrice\"]]\n    \n    sub_unordered_df = pd.concat([X_sub_n2,X_sub_n1,X_sub_n0])\n    sub_df = df_test.merge(sub_unordered_df,on=\"Id\").loc[:,[\"Id\",\"SalePrice\"]]\n    sub_df.to_csv(\"submission.csv\", index=False)","6e5a27fe":"sub_df.head()","53e96791":"I wonder if Exterior1st and Exterior2nd are ever equal.","e5c67a5e":"Therefore we take the average pool quality of pools that are around the same Area of the Pool (+\/-1SD) and set the pool quality manually to whatever the average pool quality is of pools that are that size.","55c8caa5":"This plot shows a pretty good linear relationship! However, there seems to be 2 extreme outliers on the bottom right. The author of the dataset specifically recommends removing 'any houses with more than 4000 square feet' from the dataset.\nReference : https:\/\/ww2.amstat.org\/publications\/jse\/v19n3\/decock.pdf","9dbb4cfd":"## FireplaceQu","a3cd6568":"### Electrical\nOver 90% of the rows that contain `Electrical` values have the same value. Therefore, if row is missing the electrical variable then set it to the mode value of Electrical.","b498b6ea":"Let's look at how much skew is in Sales Price. In case you forgot, here are the general rules for skewness:\n\n* If the skewness is between -0.5 and 0.5, the data are fairly symmetrical.\n* If the skewness is between -1 and -0.5(negatively skewed) or between 0.5 and 1(positively skewed), the data are moderately skewed.\n* If the skewness is less than -1(negatively skewed) or greater than 1(positively skewed), the data are highly skewed.","41af60ee":"Add `HasGarage` variable to keep track of whether house has a Garage\n* Set `HasGarage` to 0 if \n    * `GarageArea` is 0\n    * `GarageCars` is 0\n    * the following are Null:\n        * GarageType\n        * GarageYrBlt\n        * GarageFinish\n        * GarageCars\n        * GarageQual\n        * GarageCond\n* Otherwise set `HasGarage` to 1 ","3edd816a":"First we must set some parameters for cleaning","b7d0ce6d":"It is confusing to me that the minimum of this is 2. Is there no 1 bed room places? Like a studio? I am very confused by this variable.","2749005a":"convert categorical-ordinal variables to integers","cff6e3e2":"This could be a useful feature so let's keep it!","3bf13ef6":"## Sum of years since remodeling and built","ed65cd0b":"So it looks like most rows have values for both the Exterior1st and Exterior2nd (only 1 null). In addition, it looks like most houses are made of VinylSd material. Since we are feature engineering these 2 columns into multiple True\/False columns of whether the house is made of the material True\/False, we don't need to fill the rows with Null since they will be false for everything. Let's do it!","da5f921c":"There aren't any Null features and it does seem like Condition2 was almost always equal to \"Norm\". Maybe in the future I will drop condition2 all together. For now I am going to One-Hot encode both Condition1 and Condition2 as if they were 1 column.","35c8e3f7":"## GarageFinish","a1b54a61":"## TotalBsmtSF","d4f38484":"turns out there were none...","339df074":"If we took the log of the \"LotArea\", would this make its distribution more normal?","58937630":"Let's drop these columns","357aafd3":"Set Fireplace Quality to 0 if there is no fireplace","5fd0b2c5":"Yep! Looks better now!","e6015ec2":"## duplicate rows","4d13d75b":"There is a slight decrease in price when 2 materials are used.","3d267a5f":"Much better! We will leave this variable transformed.","4971503d":"There are about 24 features with correlation values > 0.5. The next question is how much they are correlated to one another?","471c5595":"There is 1 row in the testing dataframe with no value for \"KitchenQual\"","6d116397":"I'm assuming that every property has a lot (since LotFrontage is always >0).It also looks like this features has a pretty normal distribution.  If there weren't a lot of null values I would just imput the mean, but I wonder if LotFrontage is dependent on other variables.","0bfff1ba":"## GarageScore","9f2a9003":"So it looks like neighborhoods tend to have significantly different LotFrontage sizes and Lot Area seems pretty correlated to Lot Frontage.","6d505158":"Add `HasBasement` variable to keep track of whether house has a Basement\n* Set `HasBasement` to 0 if\n    * the following are Null:\n        * BsmtQual\n        * BsmtCond\n        * BsmtExposure\n        * BsmtFinType1\n        * BsmtFinType2\n    * BsmtFinSF1 is 0 or Null\n    * BsmtFinSF2 is 0 or Null\n    * BsmtUnfSF is 0 or Null\n    * TotalBsmtSF is 0 or Null\n    * BsmtFullBath is 0 or Null\n    * BsmtHalfBath is 0 or Null\n* Otherwise set `HasBasement` to 1 ","94cfb800":"We expect that if the \"MasVnrArea\" is 0 that the \"MasVnrType\" is none.","b4be5e3a":"Since there are only 2 rows with null values in the GarageFinish,GarageQual, GarageCond, GarageArea, and GarageCars variables in the testing data I'll just set them to the average values since there are so few rows with nulls anyway.","64412c26":"There are a lot! I next wondered if the order of the covering types mattered. For example was Stone always in the Exterior1st column and Stucco in the Exterior2nd if the house was made of both.","7b95a210":"and now I can drop \"MSSubClass\" and \"HouseStyle\"","2482e947":"There are:\n* 2 rows with null values for `BsmtQual` in the testing set \n* 3 rows with null values for `BsmtCond` in the testing set \n* 1 row with null values for `BsmtExposure` in the training set \n* 2 rows with null values for `BsmtExposure` in the testing set\n* 1 row with null values for `BsmtFinType2` in the training set \n\nWe can either use the average value to replace the null values (since isBasement is 1 we cannot set these to 0), or we can base them off other features that are not null.","5d024ffd":"Interesting... This does seem to be generally linear...","850dabd4":"## Categorical feature importance\nI want to remove features that contain almost no information gain. A feature has no information gain if every row has the same value. Therefore, to measure information gain we can compute the frequency of the most common level in the train & test dat.","ad6d8dca":"### Functionality\nIn the \"data_description.txt\" file it says to \"Assume typical unless deductions are warranted\". Therefore, we set the rows with null functionality to 7 which means its typical","2667a27b":"# ExterQual","ff2cd2bb":"Homes with missing garage values most likely do not have garages. Therefore, I will impute 0 for most of these columns. Unfortunately setting the GarageYrBuilt to 0 doesn't make any sense so I'll just set these values to the mode. ","50239ba4":"We have a lot of columns in the testing data with null variables. Since we need to predict these rows we cannot drop rows. Our options are to either drop the column or fill in the null values.\n\nI decided to fill in these values since I believe I have a general idea of how to go about doing that and I don't want to lose any information yet.","1b55d420":"So much better! The data points are now fairly symmetrical and there isn't as many outliers on one particular tail.","3797b9e8":"I want to have a binary column for sharing a floor (AKA if the house is a 2 family conversion or a duplex)","2dab4ad8":"We see that the sales price:\n\n* Deviates from the normal distribution.\n* Has appreciable positive skewness.\n* Shows peakedness.","b0379499":"## Missing values","8ed34a0e":"I wonder if Condition1 and Condition2 are ever equal in values.","d710b554":"For `LotFrontage` I am confused why some of these values would be null. Could it be possible that these homes do not have a street connected to their property. I need to visualize the distribution of values of Lot Frontage.","063e8fcf":"There seems to be a positive trend with `YearRemodAdd` over time.","a0915588":"## Correlation between Target Variable and Features\ncompare correlation between the features and the target variable `SalePrice`","c1ff4b15":"Since there is only 1 null row with `BsmtFinType2` and `BsmtFinType2` is highly correlated with `BsmtFinSF2`, I got the \"BsmtFinSF2\" value of the null row:","6cb65566":"check for duplicate rows if there are any...","3a8fbf8e":"I am also interested in comparing PUD homes verses not.","1633d09a":"# Feature Engineering Part II\n## Combinations of Existing Features\nThe code was adapted came from https:\/\/www.kaggle.com\/juliencs\/a-study-on-regression-applied-to-the-ames-dataset","2be0c9c5":"Yeah I'll keep this feature.","a403ef3f":"Some Observations:\n* It make sense the `AllSF` is corelated to `GrLivArea` and `TotalBsmtSF` since it literally the sum of these two features. \n* It is interesting that  `AllSF`, `TotRmsAbvGrf` and `GrLivArea` are highly correlated to `AllFlrsSF`.\n* It makes sense the `ExterQual` and `ExterGrade` are correlated since `ExterGrade` is literally a multiple of `ExterQual`.\n* It makes sense that `KitchenScore` and `KitchenQu` are correlated\n* GarageArea, Garage Cars, and GarageScore are correlated which makes sense.\n* `TotalBath` and `FullBath` are correlated\n\n\n\nI am interested in looking at some of these variables more specifically...","2f092f7c":"So we have rows with \"Wd Sdng,HdBoard\" and \"HdBoard,Wd Sdng\". Even though these values are different in different columns, these houses are made of the same material. Therefore, I want to convert these columns so that we can check if the exterior has a specific type of covering. For example, `Exterior_CBlock` would be 1 if there is a Cinder Block covering on the house and 0 would be if `Exterior1st` and `Exterior2nd` are both not equal to \"CBlock\".\n\nBefore, we create these new features though I want to know how many of each material we have and how many nulls we have.","5c43299b":"There seems to be no trend in the year the house was sold. You probably need more datapoints beyond 5 years.","11d2a793":"Unfortunately we still have not dealt with all of the null values for basement features.\n","a58a3348":"### PoolQC","145ca649":"# Introduction\nThis kernel was inspired from the following notebooks:\n* https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\n* https:\/\/www.kaggle.com\/allunia\/house-prices-tutorial-with-catboost\n* https:\/\/www.kaggle.com\/juliencs\/a-study-on-regression-applied-to-the-ames-dataset\n\nIn this text-based competition we are given 79 features about houses located in Ames, Iowa and expected to predict the prices of these houses. Our training set and testing set are relatively small with about 1458 rows each (assuming there are no redundancies).","c4361cca":"Given our new features, we can drop \"Exterior1st\" and \"Exterior2nd\"","3401f148":"Cool, I wanna see how these values look compared to sale price.","10720c61":"Looks pretty linear to me!","66a40718":"How do these categories affect price?","2c92c1cc":"Cool so our data is positively skewed and has lots of outliers, but what happens if we transform the Sales Price using the log transformation?","8f5e71d3":"I am also interested how the number of stories affect Sales Price. ","a54f18a1":"# Cleaning and Reorganizing the training data","4ce026ba":"There are a lot! I next wondered if the order of the conditions mattered.","c0910dda":"There seem to be a lot of nulls in GarageType. GarageType is fine because I dealth with that by turning it into multiple columns with One Hot Coding.","445dcdb9":"# Target Variable: Sales Price","28f83518":"# KitchenQual","33ad9bd2":"### KitchenQual\n","8aee7672":"# Modeling\nOur target value, 'SalesPrice' is continuous, therefore this challenge is a regression problem.\n\n## Linear Regression","accf74db":"# Feature Engineering\n## Exterior Variables","b6b9f023":"\n### Lot frontage\nI'm assuming that every property has a lot (since LotFrontage is always >0) so I'll just imput the median based on the neighborhood of the house.","762155b2":"Basically, price increases if the house is 2 stories or more. Therefore we can make a variable that is specific to that.","9b66cf8c":"Then I found the standard deviation of the `BsmtFinSF2` in houses with basements","9b91df57":"This relationship isn't looks almost linear. I wonder what would happen if we log transform","9f4888b2":"In one-hot encoding, we made values of categorical nominal features their own row. For example, if our category was \"marital_status\" and the row was  [\u2018single,\u2019single\u2019,`married`,`divorced`] we would one-hot encode transform the sequence into the rows:\n* marital_status_single: [1,1,0,0]\n* marital_status_married: [0,0,1,0]\n* marital_status_divorced: [0,0,0,1]\n\nUnfotunately, not all values for every column that are found in the training set are also found in the test set. For example if those values were found in the training set, the test values may include some of the same values but not all and may even include values not found in the traning set. For example the row in the test set could be: [`married`,`single`,`seperated`] and have a new column called \"marital_status_seperated\" but not contain \"marital_status_divorced\". Since we don't have a \"marital_status_seperated\" column in the training set, we cannot train for that feature so it should be dropped from the test set. Similiarly, if we don't have a feature for \"marital_status_divorced\" in the test set then can't use it for prediction anyway so it should be dropped from the test set.\n","7e4b9717":"Next we can open the training and testing data","a089f1e1":"Let's look value counts of each category in MSSubClass","c5c70efe":"How does an unfinished floor affect the SalePrice?","1894b6ce":"# Garage Cars","96eaa4e3":"Cool so basically the information we gain from MSSubClass is style and whether the house is part of a bigger unit (2 family conversion or a duplex) or an individual house.\n\nI also noticed that there are some inconsistancies in the dataset. For example, \n* in 1 row MSSubCLass is \"2-STORY 1946 & NEWER\", but the \"HouseStyle\" is \"2.5Unf\". So its probably 2.5 floors, but has a newer style.\n* in 1 row MSSubCLass is \"1-STORY 1946 & NEWER ALL STYLES\", but the \"HouseStyle\" is \"2Story\". So if the housing style is correct it should have been in MSSubClass \"2-STORY 1946 & NEWER\"","2199c2e4":"Check to make sure there are no null values in our new feature \"neighborhoodTier\"","b568e7c1":"If there is no Kitchen Quality value then set it to the average kitchen quality value","a9baa7f3":"Yes! Linear!","b5b4a152":"There does seem to be some form of a linear pattern up until we get to 11. Given that 75% of the rows have `TotRmsAbvGrd` <=7, 12 and 14 seem to be outliers. It may be easier to visualize in a scatter plot actually.","8b0075da":"We see using the correlation plot that `BsmtCond` and `BsmtQual` are strongly correlated. I check to make sure that these two features are never both null when in our current dataframe.","5aa6a748":"# Weird values","3758ba65":"# Exploratory Analysis (Post-Cleaning)","21e614ca":"There are only 2 rows that have the \"Conditions\" in an order that is flipped, but given that most of the time the conditions are equal I was to perform feature engineering to build a relationship between these 2 seperate columns,\n\nI want to convert these columns so that we can check if the house has a specific confition. For example, `Condition_Norm` would be 1 if either \"Condition1\" or \"Condition2\" or both were equal to \"Norm\" and 0 would be if `Condition1` and `Condition2` are both not equal to \"Norm\".\n\nBefore, we create these new features though I want to know how many of each material we have and how many nulls we have.","3d5fdeb0":"## TotRmsAbvGrd","cf7cd5f8":"Observations:\n\n* The minimum is price is not 0 which make sense since houses aren't free. If there were free houses we may question our target values and drop those rows for training purposes\n* The median is about $20,000 less than the mean which means that the distribution will have at least a slight positive skew. I am interested in checking the \"normality\" of the target variable since this will effect the statistical tests I can do down the line.","e2386f29":"Great! Since there are only 2 and 3 missing values in these columns respectively and their values have the same range I just set the null values to the value of the other. However, if we dropped \"BsmtCond\" we will just have to set \"BsmtQual\" to the average \"BsmtQual\" given a basement.","3f4f9abf":"### Barement Features: 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2','BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'","49318984":"There are 3 rows in the testing set which have null \"PoolQC\", but contain a pool.","34c34d78":"* GRLivArea, and GarageArea seem to have relatively normal distributions\n* I want to try square root transformations of 'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2','BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', and '2ndFlrSF', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF'\n* I want to try log transformations on 'LowQualFinSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', and 'MiscVal'","0e1c188c":"Hmmm there are definitely better neighborhoods...","aef47680":"Looks pretty linear to me!","ef0b82f1":"Add `HasMasVnr` variable to keep track of whether house has a Masonry veneer area\n* Change `HasMasVnr` to 0 if `MasVnrArea` and `MasVnrType` are Null.\n* Change `MasVnrArea` to 0 if `MasVnrArea` is Null\n* Change `HasMasVnr` to 0 if `MasVnrArea` > 0 or `MasVnrType` is not Null.","33d44416":"perform 3 seperate linear regression models for each neighborhood tier","28c503c3":"I am only going to use the variables that I belive to show strong LINEAR correlation with Saleprice","fec2ec1c":"Yes! I feel like that helped! ","efc7b764":"### Fence","a017476d":"This looks rough. Lets log transform it... It still look questionable...","6c99e5b4":"## Year Built","f299d38a":"## Set up Categorical Ordinal Variables","c986f452":"I also wonder if price is affected by whether the row was set to have 1 or 2 conditions. My guess is probably not since I cannot logically wrap my head around the idea.","8fbe3d51":"# Exploratory Analysis (Pre-Cleaning)","14c54958":"## Continuous Variables Distribution\nI am interested in looking at the distribution of the continuous variables. Note that I remove 0's since 0's can skew the distribution.","9e087ef4":"## Month and Year the house was sold","3e863516":"unfortunately we are not done with the null features in the Garage Columns","76a05452":"*Although it's not a strong tendency, I'd say that 'SalePrice' is more prone to spend more money in new stuff than in old relics.*\n\n**Note**: we don't know if 'SalePrice' is in constant prices. Constant prices try to remove the effect of inflation. If 'SalePrice' is not in constant prices, it should be, so than prices are comparable over the years.","a0199b82":"perform linear regression on all the data at once","9f012918":"So I noticed that the columns with the most null values are features where a null value actually contains information. For example, if null is found in PoolQC, it means that the house does not have a pool. This observation led me to believe I am going to have to fill-in the rows that have NULL variables that mean something (see cleaning below).","00693d35":"I want to create a columns that tells what type of \"Tier\" neigborhood the house is located in. \n* The top Tier will have an average Sale price above or equal to the 75% percentile of the SalePrices. \n* The middle upper Tier will have an average Sale price between the 50th and 75th percentile. \n* The middle low Tier will have an average Sale price between the 25th and 50th percentile. \n* The bottom tier will have an average Sale price below the 25th percentile.","9ef64e5e":"## Information Gain of Categorical Norminal Variables\nSince we have One-Hot Encoded our Categorical Nominal Variables, which columns have the least information gain?","de2eab52":"this feature seems to not be related to price so I am going to drop it.","51fec119":"Yeah, I think that makes more sense.","13eaeeea":"## YearRemodAdd","e57b1c23":"### MasVnrType and MasVnrArea","2284c676":"# Time Series Exploration","11bd35f8":"For basement exposure, I just set it to the average value based on both the training and test set where HasBasement is true.","79210aa9":"This narrows down the features significantly. Let's identify their relationship with sale price.","15527b75":"I think I like these transformations!","43444794":"### Garage Features","3dff0dcc":"## Condition","dff683c8":"looks like a strong linear relationship!","1882f955":"Convert null variables which actually just mean that there is no basement.","e49582cd":"I convert this categorical feature into a numerical one. Note that I called \"Split-Foyer\" homes as 1.5 stories and \"Split-Level\" homes as 2 story.","939f3ce1":"It looks like the data is positively skewed\n\nKurtosis is used to describe the extreme values in one tail versus the other.\n* High kurtosis means there are a lot of outliers. (>3)\n* Low kurtosis means there are not a lot of outliers. (<3)","74b1e79c":"### Drop Columns not found in Training or Testing Set","1f461dda":"I feel like I could merge 3 and 4 into a single category as \"Above 2\"...","6b7d70fc":"## MSSubClass and HouseStyle\nMSSubClass and HouseStyle have values that are related. I am interested in seeing how their values relate.","3a476512":"If the there is no Garage, just set GarageYrBlt to the average year that Garages are built.","a8bc98d4":"## GrLivArea","e6240f17":"Oh Damn. I didn't realize you could have 0 FullBath. You need a bath in a house right? Does this mean we are missing information. Probably. Oy vey... Well at least its linear when we have the information... Maybe I should set the 0's to 1's?","68193650":"This may be a useful feature so I am going to keep it. ","560878dc":"## Location? Location? Location?","e8ebcf5a":"## Deal with Categorical-Ordinal Variables","99baaea3":"Cool. Since the sqrt numbers for \"MasVnrArea\" have a normal curve we can take the mean of these values and then square it to fill these rows.","b23bc72e":"### FireplaceQu","af9c00b2":"### Alley\nIf row is missing the `Alley` variable then there is no Alley Access so it should be set to 0.","65d9e765":"## FullBath","73ccfadb":"Given our new features, we can drop \"Condition1\" and \"Condition2\"","e5e1f3da":"I definitley want to drop the \"Utilities\" column","b0ddf0d0":"## Check for nulls","3e903ddf":"Set Fence Quality to 0 if there is no fence","ebf54e3d":"I took the average of \"BsmtFinType2\" values within 1 SD around the `BsmtFinSF2` value","92ae7e74":"Set Pool Quality to 0 if there is no pool","baf08a40":"It is interesting that houses made of VinylSd have generally higher prices given that most houses seem to have this material.","48867ea2":"## OverallQual","1f61e188":"## Deal with Null Values that contain information content","22e43950":"There are 3 rows where this is the case so I am going to assume the data collector accidentally forgot to calculate the \"MasVnrArea\". Let's look at the distribution of \"MasVnrArea\" when there is a Masonry vaneer wall.","584b24f0":"From this chart I made the following observations:\n* Being adjacent to Arterial street can have a negative impace on house SalePrice\n* The closer to the Positive Offset Feature -- park. greenbelt, etc. has a positive impact on price.\n* Distance from the Feeder St and RailRoads doesn't have much impact on the price.","7be82743":"This leads me to believe that I should have a column for houses that have \"1945 & Newer\" styles","f4d4290c":"Interesting, it does seem to have a small effect...","8c63e501":"I am just interested in the values of the features that have >90% of the same value.","e7fabacd":"This distribution looks skewed to the right. Let's transform it by taking the sqrt of it.","4ca8a78a":"## Deal with Categorical-Nominal Variables","19f81b2a":"I also wonder if price is affected by whether the Exterior covering has 1 or 2 materials on it.","5062a991":"Since there are so many more houses with the Norm condition it is hard to see the rest of the values.","896cdc1f":"This looks like a good feature, but it is also highly correlated with `GrLivArea` so I may leave it out of my final model."}}