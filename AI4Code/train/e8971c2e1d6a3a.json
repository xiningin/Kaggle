{"cell_type":{"00bbe461":"code","d4e354c7":"code","ad46ba8b":"code","8e19cdb5":"code","959d4bcc":"code","0cbb4614":"code","ea47ed27":"code","d5b4191f":"code","f3d38b2b":"code","ac844520":"markdown"},"source":{"00bbe461":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom lightgbm import LGBMClassifier\nfrom category_encoders import OneHotEncoder\nfrom sklearn.model_selection import cross_val_predict\nfrom warnings import filterwarnings\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold\nfilterwarnings('ignore')\nimport os\nimport xgboost as xgb\nprint(os.listdir(\"..\/input\"))","d4e354c7":"train = pd.read_csv(\"..\/input\/train_2.csv\")\nprint(\"train shape\", train.shape)\ntest = pd.read_csv(\"..\/input\/test_2.csv\")\nprint(\"test shape\", test.shape)","ad46ba8b":"target_column = \"target\"\nid_column = \"id\"\ncategorical_cols = [c for c in test.columns if test[c].dtype in [np.object]]\nnumerical_cols = [c for c in test.columns if test[c].dtype in [np.float, np.int] and c not in [target_column, id_column]]\nprint(\"Number of features\", len(categorical_cols)+len(numerical_cols))","8e19cdb5":"# Lowered learning rate from 0.3 to 0.02.\n# Set number of trees as 100 (this is the default value)\n# Set L1 Regularization to 5. Default value is 0. \n# Increased max_bin to 512. Default is 255. \nclassifier = make_pipeline(\n    ColumnTransformer([\n        ('num', StandardScaler(), numerical_cols),\n        ('cat', OneHotEncoder(), categorical_cols),    \n    ]),\n    LGBMClassifier(n_jobs=-1,learning_rate=0.02,num_tree=100,lambda_l1=5,max_bin=512)\n)","959d4bcc":"%%time\n# 3 fold CV; default option in cross_val_predict is Stratified k-Fold CV\noof_pred = cross_val_predict(classifier, \n                             train, \n                             train[target_column], \n                             cv=3,\n                             method=\"predict_proba\")","0cbb4614":"\nprint(\"Cross validation AUC {:.4f}\".format(roc_auc_score(train[target_column], oof_pred[:,1])))","ea47ed27":"# compute and print log-loss\nfrom sklearn.metrics import log_loss\nlog_loss_value = log_loss(train[target_column], oof_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)\nprint(\"The log-loss value is {:.4f}\".format(log_loss_value))","d5b4191f":"sub = pd.read_csv(\"..\/input\/sample_submission.csv\")\nsub.head()","f3d38b2b":"%%time\nclassifier.fit(train, train[target_column])\n# predict on test set and save to submission file\ntest_preds = classifier.predict_proba(test)[:,1]\nsub[target_column] = test_preds\nsub.to_csv(\"submission.csv\", index=False)","ac844520":"In recent sklearn they introduced ColumnTransformer which is a very compact way to define end-2-end solution."}}