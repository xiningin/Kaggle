{"cell_type":{"a44b3876":"code","6276bde1":"code","f1fe1b4d":"code","a3919972":"code","9a34f23a":"code","9a12114b":"code","493ae36a":"code","4e8d5a62":"code","5b594f0e":"code","af0ce8c8":"code","eaced5c7":"code","abc6e148":"code","4edd801b":"code","65603544":"code","ffd424bf":"code","43158a3f":"code","7774d448":"code","090be78c":"code","e1e14b90":"code","ed3d9914":"code","2c02c634":"code","25a6b3b1":"code","95b4377a":"code","456d8a87":"code","6df7be76":"code","c123352c":"code","60b2dbaf":"code","547b4f4a":"code","bae3009a":"code","8af9da98":"code","14a3ac1e":"code","a4ad033d":"code","5533bff2":"code","3713696e":"code","c62cb029":"code","380b4869":"code","35c2b199":"code","47afde1a":"code","e01f2fb0":"code","4873368e":"markdown","82de600e":"markdown","080a8638":"markdown","6e8ce6d3":"markdown","3dfa3d16":"markdown","6564a1c1":"markdown","13f7d6ce":"markdown","3e15331f":"markdown"},"source":{"a44b3876":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\nfrom PIL import Image\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","6276bde1":"run_model1 = False\nrun_model2 = True","f1fe1b4d":"def load_cifar10_data(filename):\n    with open('..\/input\/cifar10\/'+ filename, 'rb') as file:\n        batch = pickle.load(file, encoding='latin1')\n\n    features = batch['data']\n    labels = batch['labels']\n    return features, labels","a3919972":"# Load files\nbatch_1, labels_1 = load_cifar10_data('data_batch_1')\nbatch_2, labels_2 = load_cifar10_data('data_batch_2')\nbatch_3, labels_3 = load_cifar10_data('data_batch_3')\nbatch_4, labels_4 = load_cifar10_data('data_batch_4')\nbatch_5, labels_5 = load_cifar10_data('data_batch_5')\n\ntest, label_test = load_cifar10_data('test_batch')","9a34f23a":"# Merge files\nX_train = np.concatenate([batch_1,batch_2,batch_3,batch_4,batch_5], 0)\nY_train = np.concatenate([labels_1,labels_2,labels_3,labels_4,labels_5], 0)\n","9a12114b":"classes = ('airplane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndef return_photo(batch_file):\n    assert batch_file.shape[1] == 3072\n    dim = np.sqrt(1024).astype(int)\n    r = batch_file[:, 0:1024].reshape(batch_file.shape[0], dim, dim, 1)\n    g = batch_file[:, 1024:2048].reshape(batch_file.shape[0], dim, dim, 1)\n    b = batch_file[:, 2048:3072].reshape(batch_file.shape[0], dim, dim, 1)\n    photo = np.concatenate([r,g,b], -1)\n    return photo\n\n\n","493ae36a":"X_train = return_photo(X_train)\nX_test = return_photo(test)\nY_test = np.array(label_test)","4e8d5a62":"def plot_image(number, file, label, pred=None):\n    fig = plt.figure(figsize = (3,2))\n    #img = return_photo(batch_file)\n    plt.imshow(file[number])\n    if pred is None:\n        plt.title(classes[label[number]])\n    else:\n        plt.title('Label_true: ' + classes[label[number]] + '\\nLabel_pred: ' + classes[pred[number]])\n    \nplot_image(12345, X_train, Y_train)","5b594f0e":"# The cifar-10 is designed to balance distribution that the counts for each classification are 5000\nimport seaborn as sns\nsns.countplot(Y_train)\nhist_Y_train = pd.Series(Y_train).groupby(Y_train).count()\nprint(hist_Y_train)","af0ce8c8":"### \u82e5\u4f7f\u7528 CrossEntropyLoss\u70baLoss function, \u5247\u4e0d\u9700\u5728\u8f38\u5165\u524d\u5c07\u6a19\u7c64\u624b\u52d5\u8f49\u63db\u6210one-hot\u683c\u5f0f\n#\n#from sklearn import preprocessing\n#oh_encoder = preprocessing.OneHotEncoder(categories='auto')\n#oh_encoder.fit(Y_train.reshape(-1,1))\n\n### In pytorch we dont need to normalize here, the 'transform' will do it for us.\n#\n#X_train_nor = X_train.astype('float32') \/ 255.0\n#X_test_nor = X_test.astype('float32') \/ 255.0\n\n\n#Y_train_oh = oh_encoder.transform(Y_train.reshape(-1,1)).toarray()\n#Y_test_oh = oh_encoder.transform(Y_test.reshape(-1,1)).toarray()\n\n# print('One-hot:')\n# print(Y_train_oh[:5])\n# print('\\nLabel:')\n# print(Y_train[:5])","eaced5c7":"# Final check for dimensions before pre-pocessing\nprint('X_train shape:', X_train.shape)\nprint('Y_train shape:', Y_train.shape)\nprint('X_test shape:', X_test.shape)\nprint('Y_test shape:', Y_test.shape)","abc6e148":"# split the validation set out\nfrom sklearn.model_selection import train_test_split\nX_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(\n    X_train, Y_train, test_size=0.2, random_state=42)","4edd801b":"### \u81ea\u5b9a\u7fa9Dataset: \n### Prepare for training & testing dataset. Define dataset class.\nimport torch\nimport torchvision.transforms as transforms\nimport random\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\n# define the random seed for reproducible result\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n\n# \u7e7c\u627f\u81eaDataset\u7269\u4ef6\nclass CIFAR10_from_array(Dataset): \n    def __init__(self, data, label, transform=None):\n        ##############################################\n        ### Initialize paths, transforms, and so on\n        ##############################################\n        #self.data = torch.from_numpy(data).float()\n        #self.label = torch.from_numpy(label).long()\n        self.data = data\n        self.label = label\n        self.transform = transform\n        self.img_shape = data.shape\n        \n    def __getitem__(self, index):\n        ##############################################\n        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n        # 2. Preprocess the data (torchvision.Transform).\n        # 3. Return the data (e.g. image and label)\n        ##############################################\n        \n        img = Image.fromarray(self.data[index])\n        label = self.label[index]\n        if self.transform is not None:\n            img = self.transform(img)\n        else:\n            img_to_tensor = transforms.ToTensor()\n            img = img_to_tensor(img)\n            #label = torch.from_numpy(label).long()\n        return img, label\n        \n    def __len__(self):\n        ##############################################\n        ### Indicate the total size of the dataset\n        ##############################################\n        return len(self.data)\n    \n    def plot_image(self, number):\n        file = self.data\n        label = self.label\n        fig = plt.figure(figsize = (3,2))\n        #img = return_photo(batch_file)\n        plt.imshow(file[number])\n        plt.title(classes[label[number]])\n        \n        \n","65603544":"class CIFAR10_from_url(Dataset): \n    pass","ffd424bf":"# Normalize for R, G, B with img = img - mean \/ std\ndef normalize_dataset(data):\n    mean = data.mean(axis=(0,1,2)) \/ 255.0\n    std = data.std(axis=(0,1,2)) \/ 255.0\n    normalize = transforms.Normalize(mean=mean, std=std)\n    return normalize\n\n\n# apply transforms to return img as tensor type\n# ToTensor: \u51fd\u6570\u63a5\u53d7PIL Image\u6216numpy.ndarray\uff0c\u5c06\u5176\u5148\u7531HWC\u8f6c\u7f6e\u4e3aCHW\u683c\u5f0f\uff0c\u518d\u8f6c\u4e3afloat\u540e\u6bcf\u4e2a\u50cf\u7d20\u9664\u4ee5255.\n# Notice that the order in the \"compose\" does matter\ntrain_transform_aug = transforms.Compose([\n    transforms.Resize((40, 40)),       #\u5148\u8abf\u6574\u81f3\u7565\u5927\u7684\u5f71\u50cf\uff0c\n    transforms.RandomCrop((32, 32)),   #\u518d\u96a8\u6a5f\u64f7\u53d6\u81f3\u6a21\u578b\u8f38\u5165\u4e4b\u5927\u5c0f\uff0c\u662f\u5e38\u7528\u7684\u5f71\u50cf\u589e\u91cf\u6280\u5de7\u4e4b\u4e00\u3002\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    normalize_dataset(X_train)\n])\n\n# Also use X_train in normalize since train\/val sets should have same distribution\nval_transform = transforms.Compose([\n    transforms.ToTensor(),\n    normalize_dataset(X_train)\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    normalize_dataset(X_test)\n])\n\ntrainset = CIFAR10_from_array(data=X_train_split, label=Y_train_split, transform=train_transform_aug)\nvalset = CIFAR10_from_array(data=X_val_split, label=Y_val_split, transform=val_transform)\ntestset = CIFAR10_from_array(data=X_test, label=Y_test, transform=test_transform)","43158a3f":"print('data shape check')\nprint('training set:'.ljust(20) + '{}'.format(trainset.img_shape))\nprint('validation set:'.ljust(20) + '{}'.format(valset.img_shape))\nprint('testing set:'.ljust(20) + '{}'.format(testset.img_shape))\nprint('label numbers:'.ljust(20) + '{}'.format(len(set(trainset.label))))","7774d448":"# put into the data loader\nfrom torch.utils.data import DataLoader\n\nbatch_size = 64\nnum_workers = 1\n\ntrain_loader = DataLoader(dataset=trainset,\n                          batch_size=batch_size, \n                          shuffle=True,\n                          num_workers=num_workers)\n\n\nval_loader = DataLoader(dataset=valset,\n                          batch_size=batch_size, \n                          shuffle=False,\n                          num_workers=num_workers)\n\ntest_loader = DataLoader(dataset=testset,\n                          batch_size=batch_size, \n                          shuffle=False,\n                          num_workers=num_workers)","090be78c":"imgs, lbls = iter(train_loader).next()\nprint ('Size of image:', imgs.size())  # batch_size*3*224*224\nprint ('Type of image:', imgs.dtype)   # float32\nprint ('Size of label:', lbls.size())  # batch_size\nprint ('Type of label:', lbls.dtype)   # int64(long)\n\n### Or you can do this:\n#for imgs, lbls in train_loader:\n#    print ('Size of image:', imgs.size())  # batch_size*3*224*224\n#    print ('Type of image:', imgs.dtype)   # float32\n#    print ('Size of label:', lbls.size())  # batch_size\n#    print ('Type of label:', lbls.dtype)   # int64(long)\n#    break\n\n","e1e14b90":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.utils.data as Data\nimport torchvision.transforms as transforms","ed3d9914":"# Build the CNN\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n            \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        \n        ### view \u7b49\u540c reshape. \u5dee\u5225\u5728\u65bcpytorch\u4e2dreshape\u662f\u8907\u88fd, \u800cview\u5247\u662f\u6c38\u9060\u6307\u5411\u6e90\u982d\n        # \"Unlike reshape, reshape always copies memory. view never copies memory.\"\n        #ref: z = torch.zeros(3, 2)\n        #>>>  x = z.view(2, 3)\n        #>>>  z.fill_(1)\n        #>>>  x\n        #    tensor([[1., 1., 1.],\n        #            [1., 1., 1.]]) \n        \n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n#display net architecture\nprint(Net())\n\n","2c02c634":"import torch.optim as optim\nimport time\n\ndef update_info(idx, length, epoch_loss, acc, mode):\n    \n    if length >= 250:\n        update_size = int(length\/250)\n    else:\n        update_size = 5\n    \n    if idx % update_size == 0 and idx != 0:\n        #print ('=', end=\"\")        \n        finish_rate = idx\/length * 100\n        print (\"\\r   {} progress: {:.2f}%  ......  loss: {:.4f} , acc: {:.4f}\".\n               format(mode, finish_rate, epoch_loss\/idx, acc), end=\"\", flush=True)\n        \n\ndef val_per_epoch(model, loss_fn, dataloader, verbose):\n    # In validation, we only compute loss value\n    model.eval()\n    epoch_loss = 0.0\n    acc = 0.0\n    val_size = 0\n    with torch.no_grad(): \n        for i, (feature, target) in enumerate(dataloader):\n            \n            #feature, target = feature.to(device), target.to(device)\n            if torch.cuda.is_available():\n                feature = feature.cuda()\n                target = target.cuda()\n            \n            output = model(feature) #outputs.data.shape= batches_num * num_class\n            \n            #compute acc\n            _, pred = torch.max(output.data, dim=1) \n            correct = (pred == target).sum().item() #convert to number\n            val_size += target.size(0)\n            acc += correct\n            \n            \n            loss = loss_fn(output, target)\n            epoch_loss += loss.item()\n            \n            \n            idx = i\n            length = len(dataloader)\n            \n            #display progress\n            if verbose:\n                update_info(idx, length, epoch_loss, acc\/val_size, 'validating')\n                \n        acc = acc\/val_size\n    print('')\n    return epoch_loss\/len(dataloader), acc\n\n\ndef train_per_epoch(model, loss_fn, dataloader, optimizer, verbose): \n    #train mode\n    model.train()\n    \n    #initialize loss\n    epoch_loss = 0.0\n    acc = 0.0\n    train_size = 0\n    \n    for i, (feature, target) in enumerate(dataloader):\n        #feature, target = feature.to(device), target.to(device)\n        \n        if torch.cuda.is_available():\n            feature = feature.cuda()\n            target = target.cuda()\n        \n        #set zero to the parameter gradients for initialization\n        optimizer.zero_grad()\n        output = model(feature)\n        loss = loss_fn(output, target)\n        \n        \n        #compute acc\n        _, pred = torch.max(output.data, dim=1) \n        correct = (pred == target).sum().item() #convert to number\n        train_size += target.size(0)\n        acc += correct\n        \n        #compute current loss. Loss is a 0-dim tensor, so use tensor.item() to get the scalar value\n        epoch_loss += loss.item()  \n        \n        #backward propagation\n        loss.backward()\n        \n        #this represents one update on the weight\/bias for a mini-batch(16 images in our case): \n        #weights[k] + alpha * d_weights[k]\n        optimizer.step()\n        \n        #show the update information\n        idx = i\n        length = len(dataloader)\n        \n        #display progress\n        if verbose:\n            update_info(idx, length, epoch_loss, acc\/train_size, '  training')\n            \n    acc = acc\/train_size\n    print('') \n    return epoch_loss\/len(dataloader), acc\n\n\n\n\"\"\"\n            if i % 2000 == 1999:    # print every 2000 mini-batches\n                print('[%d, %5d] loss: %.3f' %\n                      (epoch + 1, i + 1, train_loss \/ 2000))\n                running_loss = 0.0\n\n    print('Finished Training')\n\"\"\"\n\n\ndef model_training(num_epochs, model, loss_fn, train_loader, optimizer, val_loader=None, verbose=True):\n    \n    train_batch_num = len(train_loader)\n    history = {}\n    history['train_loss'] = []\n    history['val_loss'] = []\n    history['train_acc'] = []\n    history['val_acc'] = []\n    \n    if val_loader is not None:\n        \n        val_batch_num = len(val_loader)\n        \n        print('Total Sample: Train on {} samples, validate on {} samples.'.\n             format(trainset.img_shape[0], valset.img_shape[0]))\n        \n        print(' Total Batch: Train on {} batches, validate on {} batches. {} samples\/minibatch \\n'.\n         format(train_batch_num, val_batch_num, batch_size))\n    \n    else:\n        print('Total Sample: Train on {} samples.'.\n             format(train_batch_num*batch_size))\n        \n        print(' Total Batch: Train on {} batches, {} samples\/minibatch \\n'.\n         format(train_batch_num, batch_size))\n    \n    \n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        train_loss, train_acc = train_per_epoch(model, loss_fn, train_loader, optimizer, verbose=verbose)\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        \n        \n        if val_loader is not None:\n            val_loss, val_acc = val_per_epoch(model, loss_fn, val_loader, verbose=verbose)\n            print('\\n        Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(train_loss,val_loss))\n            print('         Training acc: {:.4f},  Validation acc: {:.4f}\\n'.format(train_acc,val_acc))\n            history['val_loss'].append(val_loss)\n            history['val_acc'].append(val_acc)\n                        \n        else:\n            print('\\n        Training Loss: {:.4f}\\n'.format(train_loss))\n            print('\\n         Training acc: {:.4f}\\n'.format(train_acc))\n        \n    \n    return history","25a6b3b1":"# Training\/Validating the model\nclasses = ('airplane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n#\u82e5\u9700\u8981\u8a2d\u7f6e\u5b78\u7fd2\u7387\u8870\u6e1b, \u5728\u5916\u90e8\u5b9a\u7fa9\u7ba1\u7406\u51fd\u6578 \u518d\u704c\u5230optimzer\u5167\u8f38\u5165\ndef lr_decay(parm):\n    pass\n\nif __name__ == '__main__' and run_model1 == True:\n\n    num_epochs = 10\n    learning_rate = 0.001\n\n    net = Net()\n\n    if torch.cuda.is_available():\n        net = net.cuda()\n    print(net)\n    print('=================================================================')\n\n    #\u82e5\u4f7f\u7528 CrossEntropyLoss\u70baLoss function, \u5247\u4e0d\u61c9\u5728\u7db2\u8def\u7684\u6700\u5f8c\u4e00\u5c64\u6dfb\u52a0softmax\n    criterion = nn.CrossEntropyLoss() #loss function\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    #training and validating\n    hist1 = model_training(num_epochs, net, criterion, train_loader, optimizer, val_loader, verbose=True)\n","95b4377a":"def imshow(img):\n    img = img    # unnormalize\n    #print(img)\n    npimg = img.numpy()\n    print(np.transpose(npimg, (1, 2, 0)).shape)\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\nif __name__ == '__main__' and run_model1 == True:\n    dataiter = iter(test_loader)\n    images, labels = dataiter.next()\n\n    # print images\n    #imshow(torchvision.utils.make_grid(images))\n    #print(labels[0])\n    #print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(5)))\n\n    for i in range(len(images)):\n        plot_image(i, images.permute(0, 2, 3, 1).numpy(), labels.numpy())\n\n\n    if torch.cuda.is_available():\n        images = images.cuda()\n    outputs = net(images)\n\n    _, predicted = torch.max(outputs, 1)\n\n    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                                  for j in range(5)))","456d8a87":"# Build the CNN\nclass Net_dropout(nn.Module):\n    def __init__(self, dropout=0.2):\n        super(Net_dropout, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)\n        #3*32*32 -> 32*32*32\n        self.dropout1 = nn.Dropout(p=dropout)        \n        self.pool1 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n        #32*32*32 -> 16*16*32\n        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n        #16*16*32 -> 16*16*64\n        self.dropout2 = nn.Dropout(p=dropout)\n        self.pool2 = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n        #16*16*64 -> 8*8*64\n        self.fc1 = nn.Linear(8*8*64, 1024)\n        self.dropout3 = nn.Dropout(p=dropout)\n        self.fc2 = nn.Linear(1024, 512)\n        self.dropout4 = nn.Dropout(p=dropout)\n        self.fc3 = nn.Linear(512, 10)\n            \n\n    def forward(self, x):\n        x = self.dropout1(self.conv1(x))\n        x = self.pool1(F.relu(x))\n        x = self.dropout2(self.conv2(x))\n        x = self.pool2(F.relu(x))\n        x = x.view(-1, self.num_flat_features(x)) \n        #self.num_flat_features(x) = 8*8*64 here.\n        #-1 means: get the rest a row (in this case is 16 mini-batches)\n        #pytorch nn only takes mini-batch as the input\n        \n        x = F.relu(self.fc1(x))\n        x = self.dropout3(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout4(x)\n        x = self.fc3(x)\n        return x\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:] # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\n        \n#display net architecture\nprint(Net_dropout())  \n\n###\n# Keras structure\n#def build_basic_net(model, dropout=0.2):\n#    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', strides=1,\n#                     input_shape=X_train.shape[1:], activation='relu'))\n#    model.add(Dropout(dropout))\n#    model.add(MaxPooling2D(pool_size=(2, 2)))\n#    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', strides=1,\n#                     input_shape=X_train.shape[1:], activation='relu'))\n#    model.add(Dropout(dropout))\n#    model.add(MaxPooling2D(pool_size=(2, 2)))\n#    \n#    model.add(Flatten())\n#    model.add(Dense(1024, activation='relu'))\n#    model.add(Dropout(dropout))\n#    model.add(Dense(512, activation='relu'))\n#    model.add(Dropout(dropout))\n#    model.add(Dense(10,activation='softmax'))","6df7be76":"if __name__ == '__main__' and run_model2 == True:\n\n    num_epochs = 10\n    learning_rate = 0.001\n\n    net = Net_dropout(0.2)\n\n    if torch.cuda.is_available():\n        net = net.cuda()\n    print(net)\n    print('=================================================================')\n\n    #\u82e5\u4f7f\u7528 CrossEntropyLoss\u70baLoss function, \u5247\u4e0d\u61c9\u5728\u7db2\u8def\u7684\u6700\u5f8c\u4e00\u5c64\u6dfb\u52a0softmax\n    criterion = nn.CrossEntropyLoss() #loss function\n    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n\n    #training and validating\n    hist2 = model_training(num_epochs, net, criterion, train_loader, optimizer, val_loader, verbose=True)","c123352c":"def model_testing(model, loss_fn, dataloader, verbose=True):\n    Y_pred = []\n    correct = 0\n    total = 0\n    epoch_loss = 0.0\n    acc = 0.0\n    test_size = 0\n    with torch.no_grad():\n        for i, (feature, target) in enumerate(dataloader):\n            if torch.cuda.is_available():\n                feature = feature.cuda()\n                target = target.cuda()\n\n            outputs = model(feature)  #outputs.data.shape= batches_num * num_class\n            \n            #compute acc\n            _, pred = torch.max(outputs.data, 1)\n            correct = (pred == target).sum().item() #convert to number\n            test_size += target.size(0)\n            #print(test_size)\n            acc += correct\n            \n            loss = loss_fn(outputs, target)\n            epoch_loss += loss.item()\n            \n            idx = i\n            length = len(dataloader)\n\n\n            #if torch.cuda.is_available():\n            #    pred = pred.cuda()\n            \n            #Pred labels \n            Y_pred += pred.cpu().numpy().tolist()\n            \n            if verbose:\n                update_info(idx, length, epoch_loss, acc\/test_size, 'testing')    \n            \n    acc = acc\/test_size\n    print('\\n\\n Accuracy of the network on the {} test images: {}%'.format(test_size, 100*acc))\n    \n    return Y_pred\n\n\n\n\nif __name__ == '__main__' and run_model1 == True:\n    Y_pred1 = model_testing(net, criterion, test_loader, True)\n    \nif __name__ == '__main__' and run_model2 == True:\n    Y_pred2 = model_testing(net, criterion, test_loader, True)","60b2dbaf":"# Plot the loss and accuracy curves for training and validation \ndef loss_acc_plt(history):\n    fig, ax = plt.subplots(2,1)\n    ax[0].plot(history['train_loss'], color='b', label=\"Training loss\")\n    ax[0].plot(history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(history['train_acc'], color='b', label=\"Training accuracy\")\n    ax[1].plot(history['val_acc'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n    ","547b4f4a":"if __name__ == '__main__' and run_model1 == True:\n    loss_acc_plt(hist1)\n    \nif __name__ == '__main__' and run_model2 == True:\n    loss_acc_plt(hist2)\n","bae3009a":"if __name__ == '__main__' and run_model1 == True:\n    for i in range(10):\n        plot_image(i, test_loader.dataset.data, test_loader.dataset.label, Y_pred1)\n    \nif __name__ == '__main__' and run_model2 == True:\n    for i in range(10):\n        plot_image(i, test_loader.dataset.data, test_loader.dataset.label, Y_pred2)\n\n","8af9da98":"from sklearn.metrics import confusion_matrix\n\n\nif __name__ == '__main__' and run_model1 == True:\n    cm = confusion_matrix(Y_test, Y_pred1)\n    \n    \nif __name__ == '__main__' and run_model2 == True:\n    cm = confusion_matrix(Y_test, Y_pred2)\n\ncm","14a3ac1e":"plt.figure(figsize = (10,8))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n\nplt.title('Confusion Matrix', fontsize=14)\nplt.colorbar()\nn_classes = cm.shape[0]\nrange_class = range(n_classes)\ntick_marks = np.arange(len(range_class))\nplt.xticks(tick_marks, range_class, rotation=-45, fontsize=14)\nplt.yticks(tick_marks, range_class, fontsize=14)\nplt.xlabel('Predicted label', fontsize=14)\nplt.ylabel('True label', fontsize=14)\n\nfor i in range_class:\n    for j in range_class:        \n        plt.text(j, i, cm[i,j], horizontalalignment=\"center\", fontsize=14, \n                color=\"white\" if i==j else \"black\")\nplt.plot","a4ad033d":"for i in range(len(classes)):\n    correct = ((Y_test == i)*1) * ((np.array(Y_pred2) == Y_test)*1)\n    print('{}, {}: '.rjust(10).format(i, classes[i]) + '{}%'.\n          format(100*correct.sum()\/Y_test[Y_test == i].shape[0]))","5533bff2":"import zipfile, os\nkaggle_test_file_path = \"..\/input\/cifar10-object-recognition-in-images-zip-file\/train_test\/test.zip\"\nzipFile = zipfile.ZipFile(kaggle_test_file_path)\n\nzipFile_img = zipFile.open('test\/1.png')\nImage.open(zipFile_img)","3713696e":"#The order of the filename in ZIP info needs to be sorted first, that's why I use re here.\nimport re\n\n# make train & test dataset\nclass Cifar10_kaggle_test(Dataset):\n    def __init__(self, file_url):\n        self.file_url = file_url\n        self.img_size = 0\n        self.len = 0\n        \n        with zipfile.ZipFile(self.file_url) as archive:\n            self.infolist = archive.infolist()\n            \n            for i, entry in enumerate(self.infolist):\n                img_idx = int(re.split(r'[\/.]', entry.filename)[1])\n                with archive.open(entry) as file:\n                    img = Image.open(file)\n                    \n                    \n                    #def images array\n                    if i == 0:\n                        self.img_size = img.size\n                        self.len = len(self.infolist)\n                        images = np.zeros((self.len, self.img_size[0], self.img_size[1], 3))\n                        img_indices = np.zeros((self.len))\n                    img_array = np.asarray(img)\n                    images[i] = img_array\n                    img_indices[i] = img_idx\n                    \n                    #print(\"\\r loading ... {} \/ {}\".format(i, self.len), end=\"\")\n        #print('\\n Done!')            \n        self.images = images.astype('uint8')\n        self.img_indices = img_indices.astype('int64')\n        del img, img_array\n\n    def __len__(self):\n        return self.len\n\n    def __getitem__(self, index):\n        img = Image.fromarray(self.images[index])\n        img_to_tensor = transforms.ToTensor()\n        img = img_to_tensor(img)\n        return img\n    \nkaggle_test_url = \"..\/input\/cifar10-object-recognition-in-images-zip-file\/train_test\/test.zip\"\nkaggle_test = Cifar10_kaggle_test(kaggle_test_url)","c62cb029":"print(kaggle_test[0].shape)\n\nbatch_size=64\nnum_workers=1\nkaggle_test_loader = DataLoader(dataset=kaggle_test,\n                                batch_size=batch_size, \n                                shuffle=False,\n                                num_workers=num_workers)","380b4869":"def kaggle_model_testing(model, dataloader, verbose=True):\n    Y_pred = []\n    #correct = 0\n    #total = 0\n    #epoch_loss = 0.0\n    #acc = 0.0\n    test_size = 0\n    with torch.no_grad():\n        for i, feature in enumerate(dataloader):\n            if torch.cuda.is_available():\n                feature = feature.cuda()\n                #target = target.cuda()\n\n            outputs = model(feature)  #outputs.data.shape= batches_num * num_class\n            \n            #compute acc\n            _, pred = torch.max(outputs.data, 1)\n            #correct = (pred == target).sum().item() #convert to number\n            test_size += feature.size(0)\n            #print(test_size)\n            #acc += correct\n            \n            #loss = loss_fn(outputs, target)\n            #epoch_loss += loss.item()\n            \n            idx = i\n            length = len(dataloader)\n\n\n            #if torch.cuda.is_available():\n            #    pred = pred.cuda()\n            \n            #Pred labels \n            Y_pred += pred.cpu().numpy().tolist()\n            \n            if verbose:\n                #update_info(idx, length, epoch_loss, acc\/test_size, 'testing')\n                print('\\r Now predicting on the {}\/{} batch...'.format(idx,length), end='')\n            \n    #acc = acc\/test_size\n    print('\\n Done!')\n    \n    return Y_pred\n","35c2b199":"Y_pred_kaggle = kaggle_model_testing(net, kaggle_test_loader)\n\nprint(len(Y_pred_kaggle))","47afde1a":"kaggle_test_df = (pd.DataFrame({'label':Y_pred_kaggle}).applymap(lambda x:classes[x]))\nkaggle_test_df.insert(0, \"id\", kaggle_test.img_indices.astype('int64'))\nkaggle_test_df = kaggle_test_df.sort_values(by='id', ascending=True)\n\n#pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds})","e01f2fb0":"kaggle_test_df.to_csv(\"cifar10_kaggle_pytorch.csv\", index=False, header=True)\n","4873368e":"### Preprocessing","82de600e":"### Model with dropout","080a8638":"### Model Testing","6e8ce6d3":"### Kaggle Submission","3dfa3d16":"![pytorch flow](https:\/\/cdn-images-1.medium.com\/max\/800\/1*uZrS4KjAuSJQIJPgOiaJUg.png)","6564a1c1":"### Build Model\n\n### Model with out augmentation","13f7d6ce":"### Load Files","3e15331f":"### Confusion Matrix"}}