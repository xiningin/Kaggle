{"cell_type":{"e589224e":"code","374ab2e6":"code","b6ca51d8":"code","02c5ae02":"code","8c6392e9":"code","b119fa6d":"code","23e89bb1":"code","1f42bb19":"code","1c5b347e":"code","3cf449d1":"code","bb00b6a9":"code","1bcb8b28":"code","a1234ac5":"code","d81337eb":"code","bd74acd1":"code","1d5cb8b5":"code","6d035426":"code","b45c0c04":"code","1f626c54":"code","b123cf6b":"code","a7126abb":"code","9366e0e4":"code","52e6af92":"code","5282b6b4":"code","33b187cc":"code","f798119b":"code","fef2cb8b":"code","92682716":"code","25e9c563":"code","cfdb8e6e":"code","c5bd6896":"code","bec7902e":"code","916ecdbd":"code","2fc7f885":"code","d9ac570e":"code","8481adf2":"code","39ad0b1f":"code","967c1306":"code","c2d58a00":"code","ddbf48c5":"code","07ab87e0":"code","568090d1":"code","9c091222":"code","0a3d60c3":"code","16407178":"code","f5915621":"code","4c76d551":"code","6c14b8c6":"code","af7cdf31":"code","fbe1312c":"code","186eddca":"code","38a56a8f":"code","ca1b34b7":"code","cd67c7dc":"code","75ffa62e":"code","8a859584":"code","00218a3f":"code","fd2fd6e7":"code","460217ea":"code","cc02b96a":"code","a381f13d":"code","1ca6ccc9":"code","d525cf0b":"code","d090364e":"code","5a9fea07":"code","b1d09a67":"code","e09c24d8":"code","9500534b":"code","bb1b807a":"code","c13182cd":"code","a58acfe5":"code","950a4568":"code","3c46228f":"code","b1f75ac2":"code","05701a8c":"code","71d4c0d1":"code","23169b1e":"code","3a401d52":"code","0777f135":"code","e1c94fed":"code","6798f0dd":"code","ac759b3a":"code","2c78120b":"code","9e894ee3":"code","f5ef2dad":"code","30b679b4":"code","1fbce682":"code","44ecbe5c":"code","6c4a43f6":"code","f248873d":"code","c484d970":"code","3a78d815":"code","6d94ffee":"code","c72d19d1":"code","9953d925":"code","12e0a3c8":"code","24aeb41d":"code","b4a4df02":"code","714f712a":"code","ffcff1af":"code","def04109":"code","00db2fed":"code","063482e3":"code","f122698a":"code","23b51dba":"code","66499c3b":"code","e5c7ead3":"code","5170e275":"code","e53cae41":"code","3b640e93":"code","bcd93cb7":"code","19cf753e":"code","04099919":"code","5fe524d7":"code","52a39bcf":"code","23805981":"code","d67ed151":"code","b3601495":"code","a22b096a":"code","5186a08c":"code","a7a8f8e8":"code","034765db":"code","e63e5043":"code","83fea505":"code","1782c047":"code","32db99c2":"code","f0a1ea83":"code","82ff7160":"code","db234da9":"code","d631f380":"code","9ffb7c6d":"code","bb6f5eab":"code","0330653b":"code","462f780c":"code","b2689579":"code","5c3a5dc6":"code","2c0f6993":"code","98d7cabd":"code","d6a60964":"code","f33e6b77":"code","7d6a303e":"code","f27e305d":"code","065c9629":"code","ed6ee203":"code","dd89a344":"code","f0f455f7":"code","886ff403":"code","ad141772":"code","d4208fd4":"code","279000b3":"code","92d4331b":"code","04dd3c53":"code","2790a878":"code","f92a229b":"code","e4242e3c":"code","5fb3036c":"code","9b2a689d":"code","769ad03e":"code","a8b2c417":"code","e9b39d76":"code","3da0b0c2":"code","4ddd8c67":"code","7489879e":"code","4ed2ba96":"code","a9b05e2d":"code","7d091222":"code","032d4717":"code","2a6092eb":"code","ea25f3a4":"code","49feadd5":"code","3f073c93":"code","ad3ddcc7":"code","a2890209":"code","15c5375f":"code","dd54b0b1":"code","a21a2ca5":"code","504613bf":"code","7d70e934":"code","36362faa":"code","4270e0e5":"code","83d6deab":"code","b0ebc4f7":"code","e3e0e797":"code","5b3d617a":"code","d7f86180":"code","4abee67e":"code","27a8e143":"code","2e72ca2f":"code","b7968e1e":"code","c723a1fe":"code","639bf26a":"code","cbbc7f40":"code","0adeaea0":"code","dfee3b69":"code","b551e9a1":"code","c50c3a18":"code","68951c62":"code","cc9c2b5b":"code","39143696":"code","dd15378f":"code","7348f97b":"code","55281079":"code","4b819bf0":"code","1bb62175":"code","a649ae7a":"code","5831546b":"code","f0454e37":"code","940a39b8":"code","68795d34":"code","e7a488d4":"code","38d94e59":"code","310dd9db":"code","f1af5b50":"code","09fea0ee":"code","4b3a1e9b":"code","fbd4e31e":"code","429429b2":"code","5ff497f0":"code","e3983042":"markdown","a07de47a":"markdown","df129368":"markdown","7278b3b0":"markdown","4fa3cfba":"markdown","6b704b55":"markdown","c7b22e68":"markdown","22c77cba":"markdown","e9e38d86":"markdown","5216ed57":"markdown","556bdf57":"markdown","60fe2a53":"markdown","f83a1389":"markdown","3d4944fd":"markdown","3c813e37":"markdown","8ce363d8":"markdown","3fb91301":"markdown","47bfa94b":"markdown","a659d847":"markdown","cd017943":"markdown","c774e508":"markdown","1c1449ca":"markdown","eb21397a":"markdown","1bb2d965":"markdown","d9272ee8":"markdown","a07e743a":"markdown","83d0a3c6":"markdown","724f77a4":"markdown","71a0f57e":"markdown","0ed48a6b":"markdown","9d2f073b":"markdown","06fa5efb":"markdown","191c7979":"markdown","0544a554":"markdown","07294a98":"markdown","a330e05e":"markdown","79cc5e00":"markdown","656fda5f":"markdown","6d6d7c27":"markdown","0b16d38b":"markdown","0439acde":"markdown","35c6b1f3":"markdown","985fb443":"markdown","49ba1dd3":"markdown","5eed2ce3":"markdown","adf1b43f":"markdown","686da335":"markdown","497ef4a1":"markdown","6cc617f9":"markdown","29ac209b":"markdown","76f539b3":"markdown","741ac4df":"markdown","74c03709":"markdown","5a0fd72a":"markdown","e9ef1003":"markdown","98b77162":"markdown","d22e6ae2":"markdown","a809de37":"markdown","985b5755":"markdown","dcd24776":"markdown","e99fcd4b":"markdown","0c6d98f8":"markdown","97b0cabd":"markdown","61b481f2":"markdown","2c92b0c4":"markdown","30b6f23e":"markdown","a410add9":"markdown","86a92d05":"markdown","fb9a9a48":"markdown","8321b7f9":"markdown","721dea41":"markdown","ff637cc8":"markdown","c702d8fe":"markdown","41637653":"markdown","59cd0ab7":"markdown","e41e4fe8":"markdown","f5e62ed6":"markdown","2d1b840a":"markdown","fa98a96b":"markdown","bdce2d16":"markdown","727997b8":"markdown","45aef7e2":"markdown","2efb7904":"markdown","6a08db7e":"markdown","99e83e11":"markdown","b8745a44":"markdown","cbccb378":"markdown","6639070a":"markdown","a3062a20":"markdown","2b8d126d":"markdown","0cd2ba15":"markdown","4528a3fe":"markdown","3ba1a0cb":"markdown","262f9d1b":"markdown","6ec35319":"markdown","7868e74d":"markdown","a41c05a5":"markdown","bdb2b491":"markdown","c37756ce":"markdown","d2a6f8ab":"markdown","26644419":"markdown","85f58d43":"markdown"},"source":{"e589224e":"# Habilita op\u00e7\u00f5es de configura\u00e7\u00e3o de reload autom\u00e1tico e de mostrar gr\u00e1ficos na tela\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","374ab2e6":"# Importa as bibliotecas fastai\nfrom fastai import *\nfrom fastai.text import *","b6ca51d8":"# Importa o sklearn\nimport sklearn.feature_extraction.text as sklearn_text","02c5ae02":"# O comando ?? Checa a documenta\u00e7\u00e3o de URLs\n?? URLs","8c6392e9":"# Acessa os reposit\u00f3rios de dados da Fastai\npath = untar_data(URLs.IMDB_SAMPLE)\npath","b119fa6d":"df = pd.read_csv(path\/'texts.csv')\ndf.head()","23e89bb1":"# Busca todas as avaliacoes de filmes e salva em movie_reviews\nmovie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n                         .split_from_df(col=2)\n                         .label_from_df(cols=0))","1f42bb19":"# Mostra um exemplo de avalia\u00e7\u00e3o de filme\nmovie_reviews.valid.x[0], movie_reviews.valid.y[0]","1c5b347e":"# Mostra o tamanho do dataset de treino e de validacao\nlen(movie_reviews.train.x), len(movie_reviews.valid.x)","3cf449d1":"# Note que os tamanhos s\u00e3o diferentes se comparar de int-para-string e de string-para-int. Pense porque isso acontece.\nlen(movie_reviews.vocab.itos), len(movie_reviews.vocab.stoi)","bb00b6a9":"movie_reviews.vocab.stoi['language']","1bcb8b28":"movie_reviews.vocab.itos[917]","a1234ac5":"movie_reviews.vocab.itos[20:30]","d81337eb":"movie_reviews.vocab.itos[:20]","bd74acd1":"movie_reviews.vocab.stoi","1d5cb8b5":"# Testa uma palavra nao mapeada para xxunk\nmovie_reviews.vocab.itos[movie_reviews.vocab.stoi['rrachell']]","6d035426":"movie_reviews.vocab.itos[movie_reviews.vocab.stoi['language']]","b45c0c04":"t = movie_reviews.train[0][0]","1f626c54":"t.data[:30]","b123cf6b":"c = Counter([4,2,8,8,4,8])","a7126abb":"c","9366e0e4":"c.values()","52e6af92":"c.keys()","5282b6b4":"Counter((movie_reviews.valid.x)[0].data)","33b187cc":"movie_reviews.vocab.itos[6]","f798119b":"(movie_reviews.valid.x)[1]","fef2cb8b":"(movie_reviews.valid.x)[0]","92682716":"def get_term_doc_matrix(label_list, vocab_len):\n    j_indices = []\n    indptr = []\n    values = []\n    indptr.append(0)\n\n    for i, doc in enumerate(label_list):\n        feature_counter = Counter(doc.data)\n        j_indices.extend(feature_counter.keys())\n        values.extend(feature_counter.values())\n        indptr.append(len(j_indices))\n        \n#     return (values, j_indices, indptr)\n\n    return scipy.sparse.csr_matrix((values, j_indices, indptr),\n                                   shape=(len(indptr) - 1, vocab_len),\n                                   dtype=int)","25e9c563":"%%time\nval_term_doc = get_term_doc_matrix(movie_reviews.valid.x, len(movie_reviews.vocab.itos))","cfdb8e6e":"%%time\ntrn_term_doc = get_term_doc_matrix(movie_reviews.train.x, len(movie_reviews.vocab.itos))","c5bd6896":"trn_term_doc.shape","bec7902e":"trn_term_doc[:,-10:]","916ecdbd":"val_term_doc.shape","2fc7f885":"movie_reviews.vocab.itos[-1:]","d9ac570e":"val_term_doc.todense()[:10,:10]","8481adf2":"movie_reviews.vocab.itos[3]","39ad0b1f":"review = movie_reviews.valid.x[1]; review","967c1306":"# Exerc\u00edcio: confirme isso\n","c2d58a00":"val_term_doc","ddbf48c5":"val_term_doc[1]","07ab87e0":"val_term_doc[1].sum()","568090d1":"review.data","9c091222":"# Exerc\u00edcio\n\n[movie_reviews.vocab.itos[a] for a in review.data]","0a3d60c3":"# Exercicio\n\nlen(set(review.data))","16407178":"movie_reviews.vocab.itos[1000:1020]","f5915621":"len(movie_reviews.vocab.stoi) - len(movie_reviews.vocab.itos)","4c76d551":"unk = []\nfor word, num in movie_reviews.vocab.stoi.items():\n    if num==0:\n        unk.append(word)","6c14b8c6":"len(unk)","af7cdf31":"unk[:100]","fbe1312c":"movie_reviews.y.classes","186eddca":"x = trn_term_doc\ny = movie_reviews.train.y\nval_y = movie_reviews.valid.y","38a56a8f":"positive = y.c2i['positive']\nnegative = y.c2i['negative']","ca1b34b7":"v = movie_reviews.vocab","cd67c7dc":"v.itos[0]","75ffa62e":"np.squeeze(np.asarray(x[y.items==negative].sum(0)))","8a859584":"np.asarray(x[y.items==positive].sum(0))","00218a3f":"np.squeeze(np.asarray(x[y.items==positive].sum(0)))","fd2fd6e7":"p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\np0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))","460217ea":"p1[:10]","cc02b96a":"len(p1), len(p0)","a381f13d":"# Exercicio: Com que frequencia a palavra \"loved\" aparece em avalia\u00e7\u00f5es negativas X avalia\u00e7\u00f5es positivas?\n","1ca6ccc9":"# Exercicio: Com que frequencia a palavra \"hated\" aparece em avalia\u00e7\u00f5es negativas X avalia\u00e7\u00f5es positivas?\n","d525cf0b":"v.stoi['hated']","d090364e":"a = np.argwhere((x[:,1977] > 0))[:,0]; a","5a9fea07":"b = np.argwhere(y.items==positive)[:,0]; b","b1d09a67":"set(a).intersection(set(b))","e09c24d8":"review = movie_reviews.train.x[695]\nreview.text","9500534b":"v.stoi['loved']","bb1b807a":"a = np.argwhere((x[:,534] > 0))[:,0]; a","c13182cd":"b = np.argwhere(y.items==negative)[:,0]; b","a58acfe5":"set(a).intersection(set(b))","950a4568":"review = movie_reviews.train.x[792]\nreview.text","3c46228f":"p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\np0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))","b1f75ac2":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","05701a8c":"r = np.log(pr1\/pr0); r","71d4c0d1":"biggest = np.argpartition(r, -10)[-10:]\nsmallest = np.argpartition(r, 10)[:10]","23169b1e":"[v.itos[k] for k in biggest]","3a401d52":"np.argmax(trn_term_doc[:,v.stoi['biko']])","0777f135":"movie_reviews.train.x[515]","e1c94fed":"[v.itos[k] for k in smallest]","6798f0dd":"np.argmax(trn_term_doc[:,v.stoi['soderbergh']])","ac759b3a":"movie_reviews.train.x[434]","2c78120b":"trn_term_doc[:,v.stoi['soderbergh']]","9e894ee3":"[v.itos[k] for k in smallest]","f5ef2dad":"(y.items==positive).mean(), (y.items==negative).mean()","30b679b4":"b = np.log((y.items==positive).mean() \/ (y.items==negative).mean())","1fbce682":"preds = (val_term_doc @ r + b) > 0","44ecbe5c":"(preds == val_y.items).mean()","6c4a43f6":"path = untar_data(URLs.IMDB)\npath.ls()","f248873d":"(path\/'train').ls()","c484d970":"reviews_full = (TextList.from_folder(path)\n             #grab all the text files in path\n             .split_by_folder(valid='test')\n             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n             .label_from_folder(classes=['neg', 'pos']))\n             #label them all with their folders","3a78d815":"len(reviews_full.train), len(reviews_full.valid)","6d94ffee":"v = reviews_full.vocab","c72d19d1":"v.itos[100:110]","9953d925":"%%time\nval_term_doc = get_term_doc_matrix(reviews_full.valid.x, len(reviews_full.vocab.itos))","12e0a3c8":"%%time\ntrn_term_doc = get_term_doc_matrix(reviews_full.train.x, len(reviews_full.vocab.itos))","24aeb41d":"scipy.sparse.save_npz(\"trn_term_doc.npz\", trn_term_doc)","b4a4df02":"scipy.sparse.save_npz(\"val_term_doc.npz\", val_term_doc)","714f712a":"trn_term_doc = scipy.sparse.load_npz(\"trn_term_doc.npz\")\nval_term_doc = scipy.sparse.load_npz(\"val_term_doc.npz\")","ffcff1af":"x=trn_term_doc\ny=reviews_full.train.y\n\nval_y = reviews_full.valid.y.items","def04109":"x","00db2fed":"positive = y.c2i['pos']\nnegative = y.c2i['neg']","063482e3":"p0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))\np1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))","f122698a":"p1[:20]","23b51dba":"def neg_pos_given_word(word):\n    print(p0[v.stoi[word]]\/p1[v.stoi[word]])","66499c3b":"neg_pos_given_word('hated')","e5c7ead3":"neg_pos_given_word('liked')","5170e275":"neg_pos_given_word('loved')","e53cae41":"neg_pos_given_word('best')","3b640e93":"neg_pos_given_word('worst')","bcd93cb7":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","19cf753e":"r = np.log(pr1\/pr0)","04099919":"r[v.stoi['hated']]","5fe524d7":"r[v.stoi['loved']]","52a39bcf":"r[v.stoi['worst']]","23805981":"r[v.stoi['best']]","d67ed151":"negative = y.c2i['neg']\np0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))","b3601495":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","a22b096a":"b = np.log((y.items==positive).mean() \/ (y.items==negative).mean()); b","5186a08c":"preds = (val_term_doc @ r + b) > 0","a7a8f8e8":"(preds == val_y).mean()","034765db":"x=trn_term_doc.sign()\ny=reviews_full.train.y","e63e5043":"x.todense()[:10,:10]","83fea505":"negative = y.c2i['neg']\npositive = y.c2i['pos']","1782c047":"p1 = np.squeeze(np.asarray(x[y.items==positive].sum(0)))\np0 = np.squeeze(np.asarray(x[y.items==negative].sum(0)))","32db99c2":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","f0a1ea83":"r = np.log(pr1\/pr0)\nb = np.log((y.items==positive).mean() \/ (y.items==negative).mean())\n\npreds = (val_term_doc.sign() @ r + b) > 0","82ff7160":"(preds==val_y).mean()","db234da9":"from sklearn.linear_model import LogisticRegression","d631f380":"m = LogisticRegression(C=0.1, dual=True)\nm.fit(x, y.items.astype(int))\npreds = m.predict(val_term_doc)\n(preds==val_y).mean()","9ffb7c6d":"m = LogisticRegression(C=0.1, dual=True)\nm.fit(trn_term_doc.sign(), y.items.astype(int))\npreds = m.predict(val_term_doc.sign())\n(preds==val_y).mean()","bb6f5eab":"path = untar_data(URLs.IMDB_SAMPLE)","0330653b":"movie_reviews = (TextList.from_csv(path, 'texts.csv', cols='text')\n                .split_from_df(col=2)\n                .label_from_df(cols=0))","462f780c":"v = movie_reviews.vocab.itos","b2689579":"vocab_len = len(v)","5c3a5dc6":"min_n=1\nmax_n=3\n\nj_indices = []\nindptr = []\nvalues = []\nindptr.append(0)\nnum_tokens = vocab_len\n\nitongram = dict()\nngramtoi = dict()","2c0f6993":"for i, doc in enumerate(movie_reviews.train.x):\n    feature_counter = Counter(doc.data)\n    j_indices.extend(feature_counter.keys())\n    values.extend(feature_counter.values())\n    this_doc_ngrams = list()\n\n    m = 0\n    for n in range(min_n, max_n + 1):\n        for k in range(vocab_len - n + 1):\n            ngram = doc.data[k: k + n]\n            if str(ngram) not in ngramtoi:\n                if len(ngram)==1:\n                    num = ngram[0]\n                    ngramtoi[str(ngram)] = num\n                    itongram[num] = ngram\n                else:\n                    ngramtoi[str(ngram)] = num_tokens\n                    itongram[num_tokens] = ngram\n                    num_tokens += 1\n            this_doc_ngrams.append(ngramtoi[str(ngram)])\n            m += 1\n\n    ngram_counter = Counter(this_doc_ngrams)\n    j_indices.extend(ngram_counter.keys())\n    values.extend(ngram_counter.values())\n    indptr.append(len(j_indices))","98d7cabd":"train_ngram_doc_matrix = scipy.sparse.csr_matrix((values, j_indices, indptr),\n                                   shape=(len(indptr) - 1, len(ngramtoi)),\n                                   dtype=int)","d6a60964":"train_ngram_doc_matrix","f33e6b77":"len(ngramtoi), len(itongram)","7d6a303e":"itongram[20005]","f27e305d":"# Comentado, et\u00e1 com erro\n# ngramtoi[str(np.array([637,   0,  59]))]","065c9629":"itongram[100000]","ed6ee203":"v[189], v[1301]","dd89a344":"itongram[100010]","f0f455f7":"v[63], v[48]","886ff403":"itongram[6116]","ad141772":"v[94], v[36], v[84]","d4208fd4":"itongram[6119]","279000b3":"v[190], v[62], v[935]","92d4331b":"itongram[80000]","04dd3c53":"v[805], v[11], v[1202]","2790a878":"j_indices = []\nindptr = []\nvalues = []\nindptr.append(0)\n\nfor i, doc in enumerate(movie_reviews.valid.x):\n    feature_counter = Counter(doc.data)\n    j_indices.extend(feature_counter.keys())\n    values.extend(feature_counter.values())\n    this_doc_ngrams = list()\n\n    m = 0\n    for n in range(min_n, max_n + 1):\n        for k in range(vocab_len - n + 1):\n            ngram = doc.data[k: k + n]\n            if str(ngram) in ngramtoi:\n                this_doc_ngrams.append(ngramtoi[str(ngram)])\n            m += 1\n\n    ngram_counter = Counter(this_doc_ngrams)\n    j_indices.extend(ngram_counter.keys())\n    values.extend(ngram_counter.values())\n    indptr.append(len(j_indices))","f92a229b":"valid_ngram_doc_matrix = scipy.sparse.csr_matrix((values, j_indices, indptr),\n                                   shape=(len(indptr) - 1, len(ngramtoi)),\n                                   dtype=int)","e4242e3c":"valid_ngram_doc_matrix","5fb3036c":"train_ngram_doc_matrix","9b2a689d":"scipy.sparse.save_npz(\"train_ngram_matrix.npz\", train_ngram_doc_matrix)","769ad03e":"scipy.sparse.save_npz(\"valid_ngram_matrix.npz\", valid_ngram_doc_matrix)","a8b2c417":"with open('itongram.pickle', 'wb') as handle:\n    pickle.dump(itongram, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \nwith open('ngramtoi.pickle', 'wb') as handle:\n    pickle.dump(itongram, handle, protocol=pickle.HIGHEST_PROTOCOL)","e9b39d76":"train_ngram_doc_matrix = scipy.sparse.load_npz(\"train_ngram_matrix.npz\")\nvalid_ngram_doc_matrix = scipy.sparse.load_npz(\"valid_ngram_matrix.npz\")","3da0b0c2":"with open('itongram.pickle', 'rb') as handle:\n    b = pickle.load(handle)\n    \nwith open('ngramtoi.pickle', 'rb') as handle:\n    b = pickle.load(handle)","4ddd8c67":"x=train_ngram_doc_matrix\ny=movie_reviews.train.y","7489879e":"positive = y.c2i['positive']\nnegative = y.c2i['negative']","4ed2ba96":"x","a9b05e2d":"k=260428","7d091222":"pos = (y.items == positive)[:k]\nneg = (y.items == negative)[:k]","032d4717":"xx = x[:k]","2a6092eb":"valid_labels = [o == positive for o in movie_reviews.valid.y.items]","ea25f3a4":"p0 = np.squeeze(np.array(xx[neg].sum(0)))\np1 = np.squeeze(np.array(xx[pos].sum(0)))","49feadd5":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","3f073c93":"r = np.log(pr1\/pr0)","ad3ddcc7":"b = np.log((y.items==positive).mean() \/ (y.items==negative).mean())","a2890209":"b","15c5375f":"(y.items==positive).mean(), (y.items==negative).mean()","dd54b0b1":"pre_preds = valid_ngram_doc_matrix @ r.T + b","a21a2ca5":"pre_preds","504613bf":"preds = pre_preds.T>0","7d70e934":"preds[:10]","36362faa":"valid_labels = [o == positive for o in movie_reviews.valid.y.items]","4270e0e5":"(preds == valid_labels).mean()","83d6deab":"trn_x_ngram_sgn = train_ngram_doc_matrix.sign()\nval_x_ngram_sgn = valid_ngram_doc_matrix.sign()","b0ebc4f7":"xx = trn_x_ngram_sgn[:k]","e3e0e797":"p0 = np.squeeze(np.array(xx[neg].sum(0)))\np1 = np.squeeze(np.array(xx[pos].sum(0)))","5b3d617a":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","d7f86180":"r = np.log(pr1\/pr0)\nb = np.log((y.items==positive).mean() \/ (y.items==negative).mean())\n\npre_preds = val_x_ngram_sgn @ r.T + b\npreds = pre_preds.T>0","4abee67e":"(preds==valid_labels).mean()","27a8e143":"from sklearn.linear_model import LogisticRegression","2e72ca2f":"from sklearn.feature_extraction.text import CountVectorizer","b7968e1e":"veczr = CountVectorizer(ngram_range=(1,3), preprocessor=noop, tokenizer=noop, max_features=800000)","c723a1fe":"docs = movie_reviews.train.x","639bf26a":"train_words = [[docs.vocab.itos[o] for o in doc.data] for doc in movie_reviews.train.x]","cbbc7f40":"valid_words = [[docs.vocab.itos[o] for o in doc.data] for doc in movie_reviews.valid.x]","0adeaea0":"%%time\ntrain_ngram_doc = veczr.fit_transform(train_words)","dfee3b69":"train_ngram_doc","b551e9a1":"veczr.vocabulary_","c50c3a18":"val_ngram_doc = veczr.transform(valid_words)","68951c62":"val_ngram_doc","cc9c2b5b":"vocab = veczr.get_feature_names()","39143696":"vocab[200000:200005]","dd15378f":"y=movie_reviews.train.y","7348f97b":"m = LogisticRegression(C=0.1, dual=True)\nm.fit(train_ngram_doc.sign(), y.items);\n\npreds = m.predict(val_ngram_doc.sign())\n(preds.T==valid_labels).mean()","55281079":"m = LogisticRegression(C=0.1, dual=True)\nm.fit(train_ngram_doc, y.items);\n\npreds = m.predict(val_ngram_doc)\n(preds.T==valid_labels).mean()","4b819bf0":"m2 = LogisticRegression(C=0.1, dual=True)\nm2.fit(trn_x_ngram_sgn, y.items)","1bb62175":"preds = m2.predict(val_x_ngram_sgn)\n(preds.T==valid_labels).mean()","a649ae7a":"m2 = LogisticRegression(C=0.0001, dual=True, max_iter=50000)\nm2.fit(train_ngram_doc_matrix, y.items)","5831546b":"preds = m2.predict(valid_ngram_doc_matrix)\n(preds.T==valid_labels).mean()","f0454e37":"x=train_ngram_doc_matrix.sign()\nval_x=valid_ngram_doc_matrix.sign()\ny=movie_reviews.train.y","940a39b8":"positive = y.c2i['positive']\nnegative = y.c2i['negative']","68795d34":"k=260428","e7a488d4":"pos = (y.items == positive)[:k]\nneg = (y.items == negative)[:k]","38d94e59":"xx = x[:k]","310dd9db":"valid_labels = [o == positive for o in movie_reviews.valid.y.items]","f1af5b50":"p0 = np.squeeze(np.array(xx[neg].sum(0)))\np1 = np.squeeze(np.array(xx[pos].sum(0)))","09fea0ee":"pr1 = (p1+1) \/ ((y.items==positive).sum() + 1)\npr0 = (p0+1) \/ ((y.items==negative).sum() + 1)","4b3a1e9b":"r = np.log(pr1\/pr0)","fbd4e31e":"b = np.log((y.items==positive).mean() \/ (y.items==negative).mean())","429429b2":"np.exp(r)","5ff497f0":"x_nb = xx.multiply(r)\nm = LogisticRegression(dual=True, C=0.1)\nm.fit(x_nb, y.items);\n\nval_x_nb = val_x.multiply(r)\npreds = m.predict(val_x_nb)\n(preds.T==valid_labels).mean()","e3983042":"### Matrizes Esparsas (no Scipy)","a07de47a":"Counters vem do m\u00f3dulo de cole\u00e7\u00f5es (junto com OrderedDict, defaultdict, deque e namedtuple).","df129368":"Estes s\u00e3o os formatos mais comuns de matrizes esparsas:\n- coordinate-wise (scipy calls COO)\n- compressed sparse row (CSR)\n- compressed sparse column (CSC)\n\nVamos ver [alguns exemplos](http:\/\/www.mathcs.emory.edu\/~cheung\/Courses\/561\/Syllabus\/3-C\/sparse.html)\n\nExistem na verdade [muitos outros formatos](http:\/\/www.cs.colostate.edu\/~mcrob\/toolbox\/c++\/sparseMatrix\/sparse_matrix_compression.html) tamb\u00e9m.","7278b3b0":"N\u00e3o vamos usar este dataframe, apenas carregar para ter uma ideia de como ele \u00e9:","4fa3cfba":"**Exercicio**: compare com que frequencia a palavra \"loved\" aparece em avalia\u00e7\u00f5es positivas em compara\u00e7\u00e3o com as avalia\u00e7\u00f5es negativas. E quanto a palavra \"hate\"?","6b704b55":"Como falamos na \u00faltima li\u00e7\u00e3o, o term-document representa um documento como um saco de palavras ou bag of words. Isso significa que n\u00e3o temos a ordem de como as palavras est\u00e3o ordenadas, nem de quais palavras aparecem e em qual frequencia. Na sess\u00e3o anterior, usamos [sklearn's CountVectorizer](https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/55bf5d9\/sklearn\/feature_extraction\/text.py#L940). Hoje vamos criar nosso pr\u00f3pria vers\u00e3o similar. Isso por duas raz\u00f5es:\n* Para entender o que o sklearn est\u00e1 fazendo \n* Para criar algo que ir\u00e1 funcionar com a fastai TextList\n\nPara criar nossa matriz term-document, primeiro precisamos aprender sobre contadores (counters) e matrizes esparsas (sparse matrices).","c7b22e68":"### De volta para Naive Bayes","22c77cba":"**Exercicio**: Confirme que a avalia\u00e7\u00e3o de filme tem 81 tokens distintos ","e9e38d86":"A curiosidade de ver um exemplo de uma avalia\u00e7\u00e3o positiva com a palavra \"hated\": ","5216ed57":"Aqui est\u00e1 a propor\u00e7\u00e3o do $\\text{log-count}$ `r`.  ","556bdf57":"### Carrega os Dados","60fe2a53":"### Usamos a propor\u00e7\u00e3o para mais explora\u00e7\u00e3o de dados\n","f83a1389":"Aqui est\u00e1 a regress\u00e3o log\u00edstica onde as vari\u00e1veis s\u00e3o trigramas com propor\u00e7\u00e3o log-count.","3d4944fd":"## Cria a matriz de term-document ","3c813e37":"Quando armazenamos dados assim, sempre temos que garantir que est\u00e1 incluso no seu arquivo .gitignore","8ce363d8":"## Nossos Dados","3fb91301":"### Usa o CountVectorizer para comparar","47bfa94b":"### ngramas","a659d847":"Isso foi lento. Vamos salvar nossas matrizes com faster loading na proxima vez: ","cd017943":"Podemos converter nossa matriz esparsa para uma matriz densa:","c774e508":"# Trigramas com vari\u00e1veis NB ","1c1449ca":"Vamos iterar atrav\u00e9s de uma sequencia de palavras para criar nosso n-grama:","eb21397a":"#### Agradecimentos\n* C\u00f3digo Original: https:\/\/github.com\/fastai\/course-nlp, por [Rachel Thomas](https:\/\/www.kaggle.com\/mathrachel) e [Jeremy Howard](https:\/\/www.kaggle.com\/jhoward).\n* Curso Original: https:\/\/www.fast.ai\/2019\/07\/08\/fastai-nlp\/, por [Rachel Thomas](https:\/\/www.kaggle.com\/mathrachel), e [Jeremy Howard](https:\/\/www.kaggle.com\/jhoward).\n* Grupo de Estudo: https:\/\/contas.tcu.gov.br\/ords\/f?p=portal:detalhe:::::V:161124, organizado por [Erick Muzart](https:\/\/www.kaggle.com\/erickmuzart) e [Fernando Melo](https:\/\/www.kaggle.com\/nandobr).\n* Curso adaptado para o Kaggle em https:\/\/www.kaggle.com\/c\/nlpbsb por [Debora Reis](https:\/\/www.kaggle.com\/deborareis)\n* Tradu\u00e7\u00e3o por [Debora Reis](https:\/\/www.kaggle.com\/deborareis) e [Gustavo Silveira](https:\/\/www.kaggle.com\/gutaors) \n\n---","1bb2d965":"# Classifica\u00e7\u00e3o de Sentimentos de Avalia\u00e7\u00f5es de Filmes (usando Naive Bayes, Regress\u00e3o Log\u00edstica e Ngrams)","d9272ee8":"### Usando meus ngrams, binarizados:","a07e743a":"## Aplicando Naive Bayes","83d0a3c6":"Talvez s\u00f3 importe quando uma palavra est\u00e1 numa avalia\u00e7\u00e3o de filmes ou n\u00e3o (e n\u00e3o a frequencia da palavra):","724f77a4":"### Nossa Vers\u00e3o do CountVectorizer","71a0f57e":"#### Resposta","0ed48a6b":"Todos os tokens que come\u00e7am com \"xx\" s\u00e3o tokens especiais da fastai. Voc\u00ea pode ver a lista completa de todos eles na [documenta\u00e7\u00e3o de tokens da fastai](https:\/\/docs.fast.ai\/text.transform.html).\n\nAs regras listadas abaixo cont\u00e9m o significado dos tokens especiais:\n* `UNK` (xxunk) representa uma palavra desconhecida\n* `PAD` (xxpad) usada para padding, ou seja, usada para o caso de reagrupar textos de diferentes tamanhos\n* `BOS` (xxbos) representa o inicio de um texto no dataset\n* `FLD` (xxfld) usada para a opcao mark_fields=True no TokenizeProcessor, que identifica os textos separados em colunas\n* `TK_MAJ` (xxmaj) indica que a proxima palavra come\u00e7a com letra mai\u00fascula no texto original\n* `TK_UP` (xxup) indica que a proxima palavra cont\u00e9m todas as letras mai\u00fasculas no texto original\n* `TK_REP` (xxrep) indica que o proximo caractere \u00e9 repetido n vezes no texto original `xxrep n{char}` \n* `TK_WREP` (xxwrep) indica que a proxima palavra \u00e9 repetida n vezes no texto original `xxwrep n{palavra}` ","9d2f073b":"#### Naive Bayes Binarizada, usando ngrams do CountVectorizer","06fa5efb":"Isto acontece porque muitas palavras foram mapeadas como desconhecidas. Podemos confirmar aqui:","191c7979":"`stoi` (string-to-int) \u00e9 maior que `itos` (int-to-string).","0544a554":"#### Avalia\u00e7\u00f5es negativas com a palavra \"loved\"","07294a98":"### Cria uma matriz de treino","a330e05e":"### Download dos dados e processamento","79cc5e00":"Podemos usar p0 e p1 para realizar mais explora\u00e7\u00e3o de dados!","656fda5f":"## Regress\u00e3o Log\u00edstica","6d6d7c27":"**Exerc\u00edcio:** Como voc\u00ea pode converter review.data de volta para texto (sem usar review.text)?","0b16d38b":"Para cada palavra no vocabul\u00e1rio, resumimos quantas avalia\u00e7\u00f5es positivas e quantas negativas.","0439acde":"## Naive Bayes ou Redes Bayesianas","35c6b1f3":"### Cria uma matriz v\u00e1lida","985fb443":"A performance foi pior quando n\u00e3o foi binarizado. Manualmente tentei diversos valores de C e este foi o melhor resultado que tive:","49ba1dd3":"No futuro, vamos ser capazes de carregar nossos dados:","5eed2ce3":"### Naive Bayes Binarizada","adf1b43f":"### Vocabulario mais associado com as avalia\u00e7\u00f5es positivas \/ negativas ","686da335":"## Agora executaremos com o dataset completo","497ef4a1":"N\u00f3s vamos usar o [TextList](https:\/\/docs.fast.ai\/text.data.html#TextList) da biblioteca fastai:","6cc617f9":"Definimos a **propor\u00e7\u00e3o de log-count** $r$ para cada palavra $f$:\n\n$r = \\log \\frac{\\text{propor\u00e7\u00e3o de variaveis $f$ em documentos positivos}}{\\text{propor\u00e7\u00e3o de  $f$ em documentos negativos}}$\n\nonde a raz\u00e3o de vari\u00e1veis $f$ em documentos positivos \u00e9 o n\u00famero de vezes que um documento positivo tem a vari\u00e1vel dividida pelo n\u00famero de documentos positivos.","29ac209b":"## A biblioteca fastai","76f539b3":"## Dados do IMDB","741ac4df":"Apesar de termos reduzide de 19 mil palavras para 6 mil, isso ainda \u00e9 muito! Muitos tokens n\u00e3o aparecem na maioria das avalia\u00e7\u00f5es. Queremos tirar vantagem disso armazenando nossos dados como uma **matriz esparsa**.","74c03709":"### Naive Bayes no dataset completo","5a0fd72a":"\u00c9 sempre bom iniciar o trabalho numa amostra do seu dataset, antes de usar o dataset inteiro --  isso permite processamento mais r\u00e1pido para fazer seu c\u00f3digo funcionar. Para o IMDB, existe um dataset de amostra j\u00e1 dispon\u00edvel. \n","e9ef1003":"Palavras mais positivas:","98b77162":"Um n-grama ou n-gram \u00e9 uma sequencia cont\u00ednua de n itens (que podem ser caracteres, s\u00edlabas ou palavras). Um 1-grama \u00e9 um unigrama, um 2-grama \u00e9 um bigrama e um 3-grama \u00e9 um trigrama. \nAqui, estamos nos referindo a uma sequencia de palavras. Ent\u00e3o exemplos de bigramas incluem \"the dog\", \"said that\" e \"can't you\".","d22e6ae2":"Estava curiosa sobre a propor\u00e7\u00e3o entre a quantidade de vezes que uma palavra aparecia em avalia\u00e7\u00f5es negativas contra a quantidade de vezes que aparecia em avalia\u00e7\u00f5es positivas. Propor\u00e7\u00f5es maiores (>1) significam que a palavra indica uma avalia\u00e7\u00e3o negativa, enquanto que propor\u00e7\u00f5es menores (<1) indicam avalia\u00e7\u00f5es positivas.","a809de37":"* Baselines e Bigramas: uma Simples e Boa Classifica\u00e7\u00e3o de T\u00f3picos e de Sentimentos. Sida Wang and Christopher D. Manning [pdf](https:\/\/www.aclweb.org\/anthology\/P12-2018)","985b5755":"### Salva os Dados","dcd24776":"#### Resposta:","e99fcd4b":"Uma matriz com muitos zeros \u00e9 chamada de **esparsa** (o oposto de esparsa \u00e9 **densa**). Para matrizes esparsas, voc\u00ea pode economizar muita mem\u00f3ria se armazenar apenas os valores diferentes de zero.\n\n![](https:\/\/raw.githubusercontent.com\/fastai\/course-nlp\/85e505295efeed88ce61dc0ff5e424bde9741a15\/images\/sparse.png)\n\nOutro exemplo de uma matriz esparsa:\n\n![](https:\/\/raw.githubusercontent.com\/fastai\/course-nlp\/85e505295efeed88ce61dc0ff5e424bde9741a15\/images\/Finite_element_sparse_matrix.png)\n\n[Origem](https:\/\/commons.wikimedia.org\/w\/index.php?curid=2245335)","0c6d98f8":"### Counters","97b0cabd":"### Pesquisando nos nossos dados","61b481f2":"Aqui est\u00e1 como n\u00f3s podemos encaixar a regress\u00e3o log\u00edstica onde as vari\u00e1veis s\u00e3o os unigramas","2c92b0c4":"Agora que temos nossa abordagem funcionando num dataset de amostra, podemos tentar usar no dataset completo.","30b6f23e":"Fast.ai tem v\u00e1rios [datasets hospedados na AWS Open Datasets](https:\/\/course.fast.ai\/datasets.html) para download. ","a410add9":"N\u00e3o binarizado:","86a92d05":"### Mais Explora\u00e7\u00e3o de Dados","fb9a9a48":"Uma classe de matrizes (por exemplo, a diagonal) \u00e9 geralmente chamada de esparsa se o n\u00famero de elementos diferentes de zero \u00e9 proporcional ao n\u00famero de linhas (ou colunas) ao inv\u00e9s de ser proporcional ao produto de linhas x colunas.\n\n**Implementa\u00e7\u00e3o Scipy**\n\nNa [Documenta\u00e7\u00e3o de Matrizes Esparsas do Scipy](https:\/\/docs.scipy.org\/doc\/scipy-0.18.1\/reference\/sparse.html)\n\n- Para construir uma matriz eficientemente, use dok_matrix ou lil_matrix. A classe lil_matrix suporta basicamente a divis\u00e3o e a indexa\u00e7\u00e3o com uma sintaxe similar aos arrais do Numpy. Como ilustrado abaixo, o formato COO tamb\u00e9m pode ser usado para construir matrizes.\n- Para executar manipula\u00e7\u00f5es, como a multiplica\u00e7\u00e3o ou a invers\u00e3o, primeiro convertemos a matriz para CSC ou CSR.\n- Todas as convers\u00f5es para os formatos CSR, CSC e COO s\u00e3o eficientes, s\u00e3o opera\u00e7\u00f5es com custo de tempo linear.","8321b7f9":"Counters s\u00e3o objetos \u00fateis no Python. Se voc\u00ea n\u00e3o est\u00e1 familiarizado com eles, aqui est\u00e1 como eles funcionam:","721dea41":"Nosso pr\u00f3ximo modelo \u00e9 uma vers\u00e3o da regress\u00e3o log\u00edstica com as vari\u00e1veis Naive Bayes descritas [aqui](https:\/\/www.aclweb.org\/anthology\/P12-2018). Para cada documento, calculamos as vari\u00e1veis binarizadas descritas abaixo, desta vez usando tamb\u00e9m os bigramas e trigramas. Cada vari\u00e1vel tem uma propor\u00e7\u00e3o log-count. Uma regress\u00e3o log\u00edstica \u00e9 treinada e usada para prever os sentimentos. ","ff637cc8":"### Explorando os dados","c702d8fe":"Vamos come\u00e7ar usando a [biblioteca da fastai](https:\/\/docs.fast.ai) e vamos usar mais, uma vez que estamos indo em dire\u00e7\u00e3o \u00e0s redes neurais.\n\nA biblioteca fastai \u00e9 criada em cima do PyTorch e cont\u00e9m muitas das melhores pr\u00e1ticas do estado da arte. J\u00e1 \u00e9 usada em produ\u00e7\u00e3o por v\u00e1rias empresas. Voc\u00ea pode ler mais sobre isso aqui: \n\n- [Fast.ai na nuvem democratiza a Inteligencia Artificial](https:\/\/www.zdnet.com\/article\/fast-ais-new-software-could-radically-democratize-ai\/) (ZDNet)\n\n- [fastai v1 para PyTorch: Redes Neurais r\u00e1pidas e acuradas usando as melhores pr\u00e1ticas modernas](https:\/\/www.fast.ai\/2018\/10\/02\/fastai-ai\/) (fast.ai)\n\n- [fastai docs](https:\/\/docs.fast.ai\/)\n\n### Instala\u00e7\u00e3o\n\nNo conda:\n\n`conda install -c pytorch -c fastai fastai=1.0`\n\nNo pip:\n\n`pip install fastai==1.0`\n\nNo Kaggle:\n\n`n\u00e3o precisa instalar, a biblioteca j\u00e1 est\u00e1 no kaggle, basta importar`\n\nMais sobre [instala\u00e7\u00f5es aqui](https:\/\/github.com\/fastai\/fastai\/blob\/master\/README.md).\n\nCome\u00e7aremos aqui a usar GPU, para usar a GPU aqui no Kaggle basta habilitar a op\u00e7\u00e3o GPU na lateral ao lado, dentro de Settings -> GPU.","41637653":"**Exerc\u00edcio:** Como a palavra \"late\" \u00e9 mostrada duas vezes nessa revis\u00e3o (\"...as a kid on the late - late show...\"), confirme que ambos os valores s\u00e3o armazenados na matriz de termo-documento, para a linha correspondente dessa revis\u00e3o e para a coluna que corresponde \u00e0 palavra \"late\".","59cd0ab7":"### Tokeniza\u00e7\u00e3o e cria\u00e7\u00e3o da Matriz de Termos e Documentos (term document)","e41e4fe8":"### Continuando com Naive Bayes","f5e62ed6":"Um bom primeiro passo para qualquer problema de dados \u00e9 explorar os dados para ter uma ideia de como eles s\u00e3o. Neste caso, estamos procurando por avalia\u00e7\u00f5es de filmes, que foram classificadas como positivas ou negativas. ","2d1b840a":"C \u00e9 o inverso da for\u00e7a da regulariza\u00e7\u00e3o: quanto menor o valor, maior a for\u00e7a da regulariza\u00e7\u00e3o. Regularizado:","fa98a96b":"### Explora\u00e7\u00e3o de Dados: propor\u00e7\u00e3o entre negativos e positivos","bdce2d16":"### Naive Bayes Binarizada","727997b8":"A avalia\u00e7\u00e3o do filme tem 81 tokens distintos nele e 144 tokens no total.","45aef7e2":"E a vers\u00e3o binarizada: ","2efb7904":"Palavras mais negativas:","6a08db7e":"### Imports","99e83e11":"O conte\u00fado foi extendido da [Li\u00e7\u00e3o 10 do curso fast.ai de Machine Learning](https:\/\/course.fast.ai\/lessonsml1\/lesson10.html). Modelos lineares s\u00e3o bem pr\u00f3ximos ao estado da arte aqui, o Jeremy ultrapassou o estado da arte usando a RNN - Recurrent Neural Network ou Redes Neurais Recorrentes em 2017.","b8745a44":"Nossa acur\u00e1cia \u00e9 de 80% para o dataset inteiro:","cbccb378":"No Processamento de Linguagem Natural (NLP), um **token** \u00e9 uma unidade b\u00e1sica de processamento (os tokens dependem da aplica\u00e7\u00e3o e de suas escolhas). Aqui, um token corresponde principalmente a palavras e pontua\u00e7\u00f5es, assim como diversos tokens especiais correspondem a palavras desconhecidas, letras mai\u00fasculas ou min\u00fasculas, etc.","6639070a":"Agora, vamos ver um exemplo de uma avalia\u00e7\u00e3o negativa com a palavra \"loved\"","a3062a20":"O [maior dataset de avalia\u00e7\u00f5es de filmes](http:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/) cont\u00e9m uma cole\u00e7\u00e3o de 50 mil avalia\u00e7\u00f5e do IMDB, vamos usar a vers\u00e3o hospedada pela [fast.ai datasets](https:\/\/course.fast.ai\/datasets.html) na AWS Open Datasets. \n\nO dataset cont\u00e9m tanto avalia\u00e7\u00f5es positivas quanto negativas. Os autores consideraram apenas as avalia\u00e7\u00f5es altamente polarizadas. Uma avalia\u00e7\u00e3o negativa tem um score \u2264 4 de 10, enquant que uma avalia\u00e7\u00e3o positiva tem um score \u2265 7 out of 10. Avalia\u00e7\u00f5es neutras n\u00e3o foram inclu\u00eddas no dataset. O dataset \u00e9 dividido entre treino e teste. O treino cont\u00e9m os mesmos dados com 25 mil avalia\u00e7\u00f5es.\n\nA tarefa de **classifica\u00e7\u00e3o de sentimentos** consistem em prever a polaridade (positiva ou negativa) de um texto.","2b8d126d":"## Refer\u00eancias","0cd2ba15":"Vamos aplicar a regress\u00e3o log\u00edstica onde as vari\u00e1veis s\u00e3o trigramas.","4528a3fe":"Usando dicion\u00e1rios \u00e9 uma abordagem \u00fatil e comum para converter entre \u00edndices e strings (neste caso, nosso n-grama). Aqui, n\u00f3s temos `itongram` (index to n-gram) e `ngramtoi` (n-gram to index).","3ba1a0cb":"Como temos o n\u00famero igual de avalia\u00e7\u00f5es positivas e negativas neste dataset, b \u00e9 0.","262f9d1b":"### Salvar os Dados","6ec35319":"#### Avalia\u00e7\u00f5es positivas com a palavra \"hated\"","7868e74d":"A proposta deste notebook \u00e9 de cobrir Naive Bayes (Redes Bayesianas), Regress\u00e3o Log\u00edstica e Ngrams, t\u00e9cnicas para classifica\u00e7\u00e3o de sentimentos. N\u00f3s vamos usar sklearn e a biblioteca da fastai. \nNuma aula futura, vamos endere\u00e7ar este mesmo problema de classifica\u00e7\u00e3o de sentimentos usando deep learning, assim ser\u00e1 poss\u00edvel comparar as duas abordagens.","a41c05a5":"#### Resposta:","bdb2b491":"## Naive Bayes","c37756ce":"## Regress\u00e3o Log\u00edstica","d2a6f8ab":"#### Resposta","26644419":"### Propor\u00e7\u00e3o do Log-count","85f58d43":"Vamos armazenar o vocabul\u00e1rio na vari\u00e1vel `v`:"}}