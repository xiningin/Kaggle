{"cell_type":{"875fd255":"code","502a932c":"code","cf976dbb":"code","a17d64ca":"code","a4865318":"code","8d526dc0":"markdown"},"source":{"875fd255":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","502a932c":"train_file_path = '..\/input\/train.csv'\ntest_file_path = '..\/input\/test.csv'\n\n# create a pandas dataframe from the training and test data\ntrain_df = pd.read_csv(train_file_path)\ntest_df = pd.read_csv(test_file_path)\n# take a look at the training dataset\n'''\nprint(train_df.head(12))\nprint(train_df.describe())\nprint(train_df.shape)\nprint(train_df.columns)\n\nprint(train_df.Fare.head(10))\nprint(train_df.Sex.head(10))\nprint(train_df.Age.head(10))\nprint(train_df.SibSp.head(10))\nprint(train_df.Parch.head(10))\nprint(train_df.Ticket.head(10))\nprint(train_df.Cabin.head(10))\nprint(train_df.Embarked.head(10))\n'''\n","cf976dbb":"## dropping the rows wih missing data reduces the number of records significantly, so it might be worth seeing if an imputer will be better \nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\n\ny = train_df.Survived\n#predictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n#predictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\npredictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\nx = train_df[predictors]\n'''\nprint(x.shape)\nprint(x.head(10))\nprint(x.columns)\nprint(x.dtypes)\nprint(y) \n\n'''\n\n''' \n## get the unique values of each column\nprint(x.Pclass.unique()) ## 1, 2, 3\nprint(x.Sex.unique()) ## 'male', 'female'\nprint(x.Age.unique()) ## numeric \nprint(x.SibSp.unique()) ## 0-8\nprint(x.Parch.unique()) ## 0-6\n#print(x.Ticket.unique()) \nprint(x.Fare.unique()) \n#print(x.Cabin.unique()) ## too many individual ones\nprint(x.Embarked.unique()) ## S, C, Q, nan\n'''\nx_one_hot_encoded = pd.get_dummies(x)\none_hot_encoded_test_predictors = pd.get_dummies(test_df[predictors])\nfinal_train, final_test = x_one_hot_encoded.align(one_hot_encoded_test_predictors,join='inner',  axis=1)\n#print(x_one_hot_encoded.shape)\nx_imputed = pd.DataFrame(my_imputer.fit_transform(x_one_hot_encoded))\nx_imputed.columns = x_one_hot_encoded.columns\n#print(x_imputed)\nprint(x_imputed.dtypes)\n","a17d64ca":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n## build a model\ntitanic_model = RandomForestClassifier()\nprint(y.head())\n## split the dataset into training and validation for testing, so we are not testing on the same dataset\ntrain_x, val_x, train_y, val_y = train_test_split(x_imputed, y,random_state = 0)\n\nprint(train_x.shape)\nprint(train_y.shape)\nprint(train_y.unique())\ntitanic_model.fit(train_x, train_y)\npredictions = titanic_model.predict(val_x)\nprint(predictions)\nprint(pd.DataFrame(predictions).head())\nprint(predictions.shape)\nprint(mean_absolute_error(val_y, predictions))","a4865318":"\nfinal_test = my_imputer.transform(final_test)\n#print(type(final_test))\n\n\n## build a model\n#titanic_test_model = RandomForestRegressor()\n#titanic_test_model.fit(x_test, y_test)\nrandom_forest_predictions = titanic_model.predict(final_test)\n\n#print(random_forest_predictions)\n## ready to submit\nmy_submission = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': random_forest_predictions})\nmy_submission.to_csv('titanic_survival2.csv', index = False)\nprint(my_submission)\nprint(my_submission.describe())","8d526dc0":"''' \n## remove the missing data\ntrain_df_clean = train_df.dropna()\n\n## \"survived' is the output column, the rest can be the predictors\ny = train_df_clean.Survived\npredictors = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\nx = train_df_clean[predictors]\n\n#print(x_clean.head())\n#print(x_clean.describe())\n#print(x_clean.shape)\n\n## some of these columns are categorical values\n#print(x.dtypes)\nx_one_hot_encoded = pd.get_dummies(x)\n#print(x_one_hot_encoded)\n## o\n'''"}}