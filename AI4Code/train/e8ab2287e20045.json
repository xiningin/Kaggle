{"cell_type":{"7672fa5e":"code","884d43c8":"code","ec753e6f":"code","83163457":"code","f6b08165":"code","272c69cf":"markdown","359f7427":"markdown","f3b634d7":"markdown","412c0843":"markdown","c880829f":"markdown","0e873982":"markdown","0a3cb81c":"markdown"},"source":{"7672fa5e":"!pip install -U lightautoml","884d43c8":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task","ec753e6f":"df_train= pd.read_csv('..\/input\/titanic-extended\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic-extended\/test.csv')\ndf_train.head()","83163457":"%%time\n# def acc_score(y_true, y_pred, **kwargs):\n#     return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\nautoml = TabularAutoML(task = Task('binary', metric = 'logloss'))\noof_pred = automl.fit_predict(df_train, roles = {'target': 'Survived'})","f6b08165":"test_pred = automl.predict(df_test)\noutput = pd.DataFrame({'PassengerId':df_test.PassengerId, 'Survived': (test_pred.data[:, 0] > 0.5).astype(int)})\noutput.to_csv('lightautoml_titanic_ON_EXTENDED.csv', index = False)\noutput.head()","272c69cf":"#  Importing and Loading files","359f7427":"This submission scores ---- (see on the top of notebook) on LB. But once again - it's not a real solution for Titanic competition because of extended data. The real one on normal datasets is [here](https:\/\/www.kaggle.com\/alexryzhkov\/lightautoml-titanic-love)","f3b634d7":"# Install LightAutoML","412c0843":"# Train LightAutoML","c880829f":"## BE CAREFUL: it's not a real solution for Titanic competition because of extended data. The real one on normal datasets is [here](https:\/\/www.kaggle.com\/alexryzhkov\/lightautoml-titanic-love)","0e873982":"# Submission","0a3cb81c":"# Top1%: [LightAutoML](https:\/\/github.com\/sberbank-ai-lab\/LightAutoML) tutorial"}}