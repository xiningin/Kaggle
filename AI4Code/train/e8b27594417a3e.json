{"cell_type":{"aaa3612c":"code","7548a14f":"code","85726a8a":"code","0bca42c5":"code","dcbd1221":"code","1b5d9691":"code","93afb9be":"code","3b8fc376":"code","c8e24dcc":"code","3e382f6a":"code","e83e930a":"code","ac7d4142":"code","ffa54589":"code","a34052ea":"code","98b96826":"code","48be90bb":"code","0f4f9d3b":"code","c9a3b744":"code","3e804c4e":"code","f1534976":"code","b9922dce":"code","75a5d7e8":"code","40972b30":"code","4cee4f32":"code","bd97d98f":"code","9d73e84e":"code","0ffc3ec1":"code","5e2c6058":"code","32de99d5":"code","839eb74f":"code","65ced938":"code","89961ee3":"code","4ea5915f":"code","6230290e":"code","aa070faf":"code","1a823266":"code","8787787d":"code","77fcc266":"code","afa03815":"code","96ff049d":"code","9574c43a":"code","3a371865":"code","7b87c4a1":"code","a86fb641":"code","30adebaa":"code","4120242b":"code","272bdc79":"code","0b79d4e1":"code","5d5884b4":"code","ad7b7744":"code","89eb6b0b":"code","81032f12":"code","31fc6efa":"code","87837303":"code","47a3a8bb":"code","a789685b":"code","d15a3234":"code","431f038a":"code","96e766d6":"code","3586b257":"code","60d9c453":"code","df3e0b86":"code","35b37752":"code","eb77a4d6":"code","82972106":"code","309ecce4":"code","eb7ecb36":"code","cd06b60f":"code","e874469c":"code","d663476a":"code","64b45022":"code","e77452b5":"code","eb1f039c":"code","164bbc48":"code","fa9af91f":"code","65925861":"code","18c66eaf":"markdown","aa20f608":"markdown","64242f5f":"markdown","2d47a139":"markdown","785d4662":"markdown","d8a84a8f":"markdown","05cc4990":"markdown","578a04d1":"markdown","98d9e105":"markdown","a17837e8":"markdown","db6bc06c":"markdown","d1a5050c":"markdown","8ed94cc6":"markdown","0938d061":"markdown","ae5b21f0":"markdown","2ec14d10":"markdown","d2a29708":"markdown","d0d2b0f7":"markdown","da58434d":"markdown","6d3d0f47":"markdown","bc710f55":"markdown","07508e8c":"markdown","fb1b9581":"markdown","e0b60bdb":"markdown","1c1d2710":"markdown","c6f87e45":"markdown","e6c97132":"markdown","6efe7e20":"markdown","bab79afe":"markdown","cbeeb683":"markdown","1d903cf0":"markdown"},"source":{"aaa3612c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport librosa\nimport librosa.display\nfrom IPython import display\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics","7548a14f":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\")","85726a8a":"import warnings\nwarnings.filterwarnings('ignore')","0bca42c5":"birdcall_meta = pd.read_csv('\/kaggle\/input\/birdsong-recognition\/train.csv')","dcbd1221":"print('Dataset has %d rows and %d columns' % birdcall_meta.shape, end=\"\")","1b5d9691":"pd.set_option('display.max_columns', 35)\nbirdcall_meta.sample(5, random_state = 1)","93afb9be":"print('There are %d unique bird species in the dataset' % birdcall_meta['ebird_code'].nunique(), end=\"\")","3b8fc376":"species_count = birdcall_meta.groupby(['species']).size().reset_index()\nspecies_count['Number of audio files interval'] = pd.cut(species_count[0], np.arange(0,110,10))\nspecies_count_bins = species_count.groupby(['Number of audio files interval']).size()\nspecies_count_bins.plot(kind=\"barh\", title=\"Count of species by number of audio files\", color='green');","c8e24dcc":"species_duration = birdcall_meta.groupby(['species']).sum()['duration'].reset_index()\nspecies_duration['duration_mins'] = np.round(species_duration['duration']\/60)\nspecies_duration['Duration interval'] =  pd.cut(species_duration['duration_mins'], 10)\nspecies_duration_bins = species_duration.groupby(['Duration interval']).size()\nspecies_duration_bins.plot(kind=\"barh\", title=\"Count of species by total duration of recordings\", color='yellow');","3e382f6a":"species_duration_top = (\n    species_duration\n      .sort_values('duration', ascending=False)\n      .head(10)[['species', 'duration_mins']]\n      .set_index('species')\n)\nax = species_duration_top.plot(kind=\"barh\", title=\"Top 10 species by total duration of recordings\", color='darkblue');\nax.invert_yaxis()","e83e930a":"species_duration_bottom = (\n    species_duration\n      .sort_values('duration', ascending=True)\n      .head(10)[['species', 'duration_mins']]\n      .set_index('species')\n)\nax = species_duration_bottom.plot(kind=\"barh\", title=\"Bottom 10 species by total duration of recordings\", color='lightblue');\nax.invert_yaxis()","ac7d4142":"pitch_count =  birdcall_meta.groupby(['pitch']).size()\npitch_count.name = 'Pitch distribution'\npitch_count.plot.pie(y='Pitch distribution', figsize=(6, 6));","ffa54589":"speed_count =  birdcall_meta.groupby(['speed']).size()\nspeed_count.name = 'Speed distribution'\nspeed_count.plot.pie(y='Speed distribution', figsize=(6, 6));","a34052ea":"def extract_hour_of_day(time):\n    time = time.lower()\n    hour = time[:time.find(':')]\n    if hour.isnumeric():\n        hour = int(hour)\n    else:\n        hour = np.nan\n        \n    if ('pm' in time) & (hour !=12):\n        hour = hour+12    \n    if ('am' in time) & (hour ==12):\n        hour = 0    \n    return hour","98b96826":"birdcall_meta['hour_of_day'] = list(map(extract_hour_of_day, birdcall_meta['time']))","48be90bb":"birdcall_meta['month_of_year'] = birdcall_meta['date'].str[5:7]","0f4f9d3b":"time_count = pd.pivot_table(birdcall_meta, values='rating', index=['hour_of_day'],\n                    columns=['month_of_year'], aggfunc='count')\ndel time_count['00']","c9a3b744":"sns.heatmap(time_count);","3e804c4e":"def extract_elevation(elevation):\n    elevation = elevation.replace('m', '')\n    elevation = elevation.replace('~', '')\n    elevation = elevation.replace(',', '').strip()\n    if elevation.isnumeric():\n        elevation = float(elevation)\n    else:\n        elevation = np.nan\n    return elevation","f1534976":"birdcall_meta['elevation_clean'] = list(map(extract_elevation, birdcall_meta['elevation']))","b9922dce":"sns.distplot(birdcall_meta['elevation_clean'], kde=False);","75a5d7e8":"country_count = birdcall_meta.groupby(['country']).size().sort_values(ascending=False).head(10)\ncountry_count.name = 'count'\nax = country_count.plot(kind=\"barh\", title=\"Count of recordings by country\", color='darkgreen');\nax.invert_yaxis()","40972b30":"ex_file = ('\/kaggle\/input\/birdsong-recognition\/train_audio'+ '\/' + \n           birdcall_meta['ebird_code']+ '\/' + \n           birdcall_meta['filename']).iloc[4423] #4423\nx, sr = librosa.load(ex_file)","4cee4f32":"display.Audio(data=x, rate=sr)","bd97d98f":"plt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr);","9d73e84e":"plt.figure(figsize=(14, 5))\ns = librosa.feature.melspectrogram(x, sr=sr, n_fft=1028, hop_length=512, n_mels=128)\ns_db = librosa.power_to_db(s, ref=np.max)\nlibrosa.display.specshow(s_db, sr=sr);","0ffc3ec1":"norm_s = (s-s.min())\/(s.max()-s.min())","5e2c6058":"from scipy.ndimage.morphology import binary_erosion,binary_dilation","32de99d5":"column_medians = np.median(norm_s, axis=0)\nrow_medians = np.median(norm_s, axis=1)","839eb74f":"filtered_spectrogram = np.greater(norm_s, column_medians*3)&np.greater(norm_s.T, row_medians*3).T*1","65ced938":"librosa.display.specshow(filtered_spectrogram);","89961ee3":"eroded_spectrogram = binary_erosion(filtered_spectrogram)","4ea5915f":"librosa.display.specshow(eroded_spectrogram);","6230290e":"dilated_idx = binary_dilation(eroded_spectrogram.sum(axis=0)>0,  iterations=3)","aa070faf":"plt.plot(dilated_idx,'ro')","1a823266":"dilated_idx.mean()","8787787d":"x.shape[0]","77fcc266":"(np.round(np.interp(np.arange(x.shape[0]), np.arange(dilated_idx.shape[0])*x.shape[0]\/dilated_idx.shape[0], dilated_idx)))","afa03815":"plt.plot(np.round(np.interp(np.arange(x.shape[0]), np.arange(dilated_idx.shape[0])*x.shape[0]\/dilated_idx.shape[0], dilated_idx)),'ro')","96ff049d":"plt.figure(figsize=(14, 5))\ns = librosa.feature.melspectrogram(x, sr=sr, n_fft=1028, hop_length=512, n_mels=128)\ns_db = librosa.power_to_db(s[:,dilated_idx], ref=np.max)\nlibrosa.display.specshow(s_db, sr=sr);","9574c43a":"np.random.seed(0)\nsample_classes = 3\nsample_species = list(np.random.choice(birdcall_meta['ebird_code'].unique(), sample_classes, replace=False))","3a371865":"birdcall_meta_samp = birdcall_meta[(birdcall_meta['ebird_code'].isin(sample_species))]","7b87c4a1":"species_duration_samp =  birdcall_meta_samp.groupby(['species']).sum()['duration']\nspecies_duration_samp.plot.pie(y='Duration distribution', figsize=(6, 6));","a86fb641":"birdcall_meta_samp['path'] = '\/kaggle\/input\/birdsong-recognition\/train_audio'+ '\/' +  \\\n                            birdcall_meta_samp['ebird_code'] + '\/' + \\\n                            birdcall_meta_samp['filename']","30adebaa":"birdcall_meta_samp['chunks'] = np.floor(birdcall_meta_samp['duration']\/3).astype(int)","4120242b":"birdcall_meta_samp = birdcall_meta_samp[birdcall_meta_samp['chunks']>0]\nbirdcall_meta_samp = birdcall_meta_samp[birdcall_meta_samp['duration']<120]","272bdc79":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nbirdcall_meta_samp['class_code'] = le.fit_transform(birdcall_meta_samp['ebird_code'])","0b79d4e1":"from sklearn.model_selection import train_test_split\nbirdcall_train, birdcall_test = train_test_split(birdcall_meta_samp, test_size=0.2, random_state=0, stratify=birdcall_meta_samp[['ebird_code']])","5d5884b4":"birdcall_train[['path','chunks','duration','class_code']]","ad7b7744":"sample_size = birdcall_train.shape[0]","89eb6b0b":"sample_size","81032f12":"sec_split = 3","31fc6efa":"classes_size = birdcall_train['ebird_code'].nunique()","87837303":"classes_size","47a3a8bb":"obs_train = birdcall_train['chunks'].sum()","a789685b":"obs_train","d15a3234":"X_train = np.zeros((obs_train, 128, 130))\nY_train = np.zeros((obs_train, classes_size))","431f038a":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler = StandardScaler()\n#minmaxscaler = MinMaxScaler()","96e766d6":"i=0\nfor r in birdcall_train[['path','class_code']].iterrows():\n    x, sr = librosa.load(r[1]['path'])\n    S = librosa.feature.melspectrogram(x, sr=sr, n_fft=1028, hop_length=512, n_mels=128)\n    norm_S = (S-S.min())\/(S.max()-S.min())\n    column_medians = np.median(norm_S, axis=0)\n    row_medians = np.median(norm_S, axis=1)\n    eroded_spectrogram = binary_erosion(np.greater(norm_S, column_medians*3)&np.greater(norm_S.T, row_medians*3).T*1)\n    dilated_idx = binary_dilation(eroded_spectrogram.sum(axis=0)>0,  iterations=3)\n    x =x[np.round(np.interp(np.arange(x.shape[0]),\n                            np.arange(dilated_idx.shape[0])*x.shape[0]\/dilated_idx.shape[0],\n                            dilated_idx)).astype(bool)]\n    x=x[:int(np.floor(x.shape[0]\/sr\/sec_split)*sec_split*sr)]\n    if x.shape[0]>0:\n        for n in np.array_split(x, np.floor(x.shape[0]\/sr\/sec_split)):        \n            print('Loading train data [%.2f%%]\\r'% np.round(i\/obs_train*100, 2), end=\"\")\n            S = librosa.feature.melspectrogram(n, sr=sr, n_fft=1028, hop_length=512, n_mels=128)\n            S_DB_sc = scaler.fit_transform(librosa.power_to_db(S))\n    #         S_DB_mm = minmaxscaler.fit_transform(S_DB_sc)\n            X_train[i, :, :] = S_DB_sc\n            Y_train[i, r[1]['class_code']] = 1\n            i += 1","3586b257":"i","60d9c453":"X_train = X_train[:i, :, :]\nY_train = Y_train[:i, :]","df3e0b86":"obs_test = birdcall_test['chunks'].sum()","35b37752":"obs_test","eb77a4d6":"X_test = np.zeros((obs_test, 128, 130))\nY_test = np.zeros((obs_test, classes_size))","82972106":"j=0\nfor r in birdcall_test[['path','class_code']].iterrows():\n    x, sr = librosa.load(r[1]['path'])\n    S = librosa.feature.melspectrogram(x, sr=sr, n_fft=1028, hop_length=512, n_mels=128)\n    norm_S = (S-S.min())\/(S.max()-S.min())\n    column_medians = np.median(norm_S, axis=0)\n    row_medians = np.median(norm_S, axis=1)\n    eroded_spectrogram = binary_erosion(np.greater(norm_S, column_medians*3)&np.greater(norm_S.T, row_medians*3).T*1)\n    dilated_idx = binary_dilation(eroded_spectrogram.sum(axis=0)>0,  iterations=3)\n    x =x[np.round(np.interp(np.arange(x.shape[0]),\n                            np.arange(dilated_idx.shape[0])*x.shape[0]\/dilated_idx.shape[0],\n                            dilated_idx)).astype(bool)]\n    x=x[:int(np.floor(x.shape[0]\/sr\/sec_split)*sec_split*sr)]\n    if x.shape[0]>0:\n        for n in np.array_split(x, np.floor(x.shape[0]\/sr\/sec_split)):        \n            print('Loading test data [%.2f%%]\\r'% np.round(j\/obs_test*100, 2), end=\"\")\n            S = librosa.feature.melspectrogram(n, sr=sr, n_fft=1028, hop_length=512, n_mels=128)\n            S_DB_sc = scaler.fit_transform(librosa.power_to_db(S))\n    #         S_DB_mm = minmaxscaler.fit_transform(S_DB_sc)\n            X_test[j, :, :] = S_DB_sc\n            Y_test[j, r[1]['class_code']] = 1\n            j += 1","309ecce4":"j","eb7ecb36":"X_test = X_test[:j, :, :]\nY_test = Y_test[:j, :]","cd06b60f":"X_train = X_train.reshape(X_train.shape[0], 128, 130, 1)\nX_test = X_test.reshape(X_test.shape[0], 128, 130, 1)","e874469c":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\nfrom keras import backend as K","d663476a":"K.clear_session()\nmodel = Sequential()\nmodel.add(Conv2D(16, (4,4), strides=(1, 1), input_shape = (128, 130, 1), padding='same', activation = 'relu'))\n\nmodel.add(MaxPool2D((4,4)))\nmodel.add(Flatten())\n\nmodel.add(Dense(32))\n\nmodel.add(Dense(classes_size, activation = 'softmax'))\nmodel.summary()","64b45022":"class_weights = compute_class_weight(class_weight='balanced',\n                                     classes=np.arange(classes_size),\n                                     y=np.argmax(Y_train, axis=1))","e77452b5":"class_weights_dict = {}\nfor c in np.arange(classes_size):\n    class_weights_dict[c] = class_weights[c]","eb1f039c":"model.compile('Adam', loss = 'categorical_crossentropy',\n              metrics = ['categorical_crossentropy'])\nmodel.fit(x = X_train, y = Y_train, \n          batch_size = 64, \n          epochs = 20, \n          validation_split=0.2,\n          class_weight=class_weights_dict)","164bbc48":"Y_pred_test = model.predict_classes(X_test)","fa9af91f":"print(metrics.confusion_matrix(np.argmax(Y_test, axis=1), Y_pred_test))","65925861":"print(metrics.classification_report(np.argmax(Y_test, axis=1), Y_pred_test, digits=3))","18c66eaf":"Further the melspectrogram shows the frequency in the mel scale (a non-linear transformation of the Hz scale).","aa20f608":"Below I plot a few more interesting features: pitch, speed, time of day, month of year, elevation and country","64242f5f":"To showcase the general ideas in this notebook I only pick a few species out to the total 264 species.","2d47a139":"## Classification based on melspectrogram","785d4662":"I am following the procedure in this paper: http:\/\/ceur-ws.org\/Vol-1609\/16090547.pdf","d8a84a8f":"And below we see that most species have between 5 and 120 minutes of recordings","05cc4990":"Let's see how many training files we have and how many columns with information about the audio files","578a04d1":"Apply dilation","98d9e105":"### Melspectrogram","a17837e8":"Load an example file and plot melspectrogram","db6bc06c":"Load csv file with information about the training data","d1a5050c":"The model is performing ok on a few classes with a simple CNN and data pre-processing. Extending to more classes will probably involve using a more sophisticated CNN and more data manipulation like superimposing noise or multiple birds calls.","8ed94cc6":"Apply binary erosion","0938d061":"![ft-birdcall.gif](attachment:ft-birdcall.gif)","ae5b21f0":"Split audio files in 3s pieces","2ec14d10":"To retain the time information we can use apply the Fourier transform over widows of the audio signal. The result can be visualized in a spectrogram, in which one dimension represents time, the other frequency and the colors represent the amplitude.","d2a29708":"## Explore dataset","d0d2b0f7":"Extract month of year from date string","da58434d":"### Explore the distributions of the number of files and file duration","6d3d0f47":"Because we will split the audio files in chunks of 3 seconds for example, we want to see which are the species with longest and shortest total duration of recorded audio files","bc710f55":"We want to see how many distinct bird species there are in the data set and the distribution of observations and audio clip duration over species.","07508e8c":"### Remove silence","fb1b9581":"For each image keep the pixels which are 3 times higher that column and row median","e0b60bdb":"It looks like most data was collected in the morning around May and June","1c1d2710":"### Look at pitch, speed, time of day, month of year, elevation and country","c6f87e45":"The Fourier transform converts an audio signal from a time and amplitude domain to a frequency and amplitude domain.","e6c97132":"I create a function to extract the elevation values from various formats","6efe7e20":"### Train model","bab79afe":"I define a function to extract the time of day from various formats in the dataset","cbeeb683":"Pivot time and month to create a dataframe for a nice heatmap","1d903cf0":"From the bar chart below we can see that most species have between 90 and 100 observations"}}