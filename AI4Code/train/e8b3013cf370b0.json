{"cell_type":{"364aaa68":"code","1a8c7203":"code","0e3e3404":"code","7ef56a10":"code","dcae3f72":"code","ff9df6f4":"code","e48f2fba":"code","8ceb40a3":"code","ac204b87":"code","24c283e8":"code","00a8ee98":"code","1bd460fe":"code","a44361be":"code","e0c55019":"code","aa8bc0c8":"code","a50079b6":"code","b1220948":"code","012ed1c2":"code","e0e79c81":"code","5f1959dd":"code","7f1de9d6":"code","9b3864d5":"code","2e332380":"code","2d0e3e6d":"code","a71fd606":"code","aa2e56fb":"code","e54e1c3d":"code","5037a375":"code","254164d8":"code","fe5ddd38":"code","a2f78dd8":"code","6f15b771":"code","a2e0f7a5":"code","b7645eac":"code","eec3eb5d":"code","0c3b9fae":"code","89fd1d42":"code","508efea6":"code","8dcf3597":"code","443b8d80":"code","704df64b":"code","516373f1":"code","893ff6a8":"code","c3460e12":"code","d9b40f19":"code","aeefe287":"code","4d66a52c":"code","7b6711b5":"code","636161ca":"code","ac206f5a":"code","479b89a5":"code","dc50e91f":"code","85bb1b9c":"code","08992b76":"code","d3cdede1":"code","d407a63a":"code","f7d88af8":"code","3ca721cb":"code","29949518":"code","66a73d8a":"code","a41a42a9":"code","34737b05":"code","30169c5b":"code","67ec14b6":"code","e492373e":"code","977d0a80":"code","2b210c75":"code","2aee4a14":"code","118667a3":"code","bfcec2b9":"code","b6cbd0fa":"code","a422aa88":"code","d234f65d":"code","ea513ce6":"code","f7fc0719":"code","8a85a1f0":"code","da291b9a":"code","0004ec41":"code","d69e8c79":"code","bc5abc50":"code","1fdf871d":"code","2527e10c":"code","5cf153df":"code","9755399d":"code","631561b0":"code","2ee04ebd":"code","32fdf153":"code","6ac2fc6a":"code","8b0d0959":"code","14457b73":"code","058d878f":"code","ea34252c":"code","745def77":"code","382ad200":"code","b377fc6a":"code","66496dfc":"code","1de8a8b3":"code","12f7cb2e":"code","8f084ac4":"code","65bfeb53":"code","6296d795":"markdown","ccc1107b":"markdown","85f44716":"markdown","def4861f":"markdown","1cc74999":"markdown","d2dda593":"markdown","596d3cae":"markdown","69dea898":"markdown","a9097528":"markdown","285f021a":"markdown","a90330a1":"markdown","5d5f74d7":"markdown","13cc0896":"markdown","1935595d":"markdown","385402c0":"markdown","8947918c":"markdown","866201e8":"markdown"},"source":{"364aaa68":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\nimport matplotlib.dates as md\nimport matplotlib.ticker as ticker\nfrom plotly.offline import iplot, init_notebook_mode\nimport plotly.graph_objs as go\nfrom scipy.stats import norm, skew, boxcox\nimport statsmodels.api as sm\nfrom sklearn.feature_selection import VarianceThreshold\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Ridge ,Lasso\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.ensemble import GradientBoostingRegressor ,ExtraTreesClassifier,AdaBoostRegressor,RandomForestRegressor\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures,MinMaxScaler,LabelEncoder\nfrom sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error\nfrom sklearn.metrics import mean_squared_log_error as msle\nfrom sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom category_encoders import OrdinalEncoder, OneHotEncoder\n\nplt.style.use('ggplot')\nsns.set_style({'axes.grid':False}) \nsns.set_style(style=\"whitegrid\")\nsns.set()\n%matplotlib inline\nimport warnings\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()\n    \n%matplotlib inline","1a8c7203":"plt.rcParams['axes.unicode_minus']=False\nplt.rcParams.update({'font.size': 20}) ","0e3e3404":"train=pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/train.csv')\ntest=pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/test.csv')","7ef56a10":"train.head(5)","dcae3f72":"test.head(5)","ff9df6f4":"print('Dimensions of train data:', train.shape)\nprint('Dimensions of test data:', test.shape)","e48f2fba":"train.describe().T # Numerical Features Only","8ceb40a3":"train.iloc[:,0:7].describe(include=\"all\").T # All Coliumns (Categorical and Numerical)","ac204b87":"train.iloc[:,7:].describe(include=\"all\").T","24c283e8":"train.info()","00a8ee98":"train.columns","1bd460fe":"test.columns","a44361be":"train= train.rename(columns={'y':'count','Temperature(\ufffdC)': 'Temp', 'Dew point temperature(\ufffdC)': \n                             'dew_pt','Solar Radiation (MJ\/m2)':'solar_rad_(MJ\/m2)'})","e0c55019":"test= test.rename(columns={'Temperature(\ufffdC)': 'Temp', 'Dew point temperature(\ufffdC)': \n                             'dew_pt','Solar Radiation (MJ\/m2)':'solar_rad_(MJ\/m2)'})","aa8bc0c8":"#train.isna().sum() # No Null values Data is CleanTemperature(\ufffdC)","a50079b6":"def getu(data):\n\n    uniqe_col_val = data.value_counts().sort_index()\n    \n    return uniqe_col_val","b1220948":"def cols_types (data):\n    \n    numerical_cols = [f for f in data.columns if data.dtypes[f] != 'object' and data.dtypes[f] != 'datetime64[ns]']\n    categorical_cols=[f for f in data.columns if data.dtypes[f]=='object' or data.dtypes[f]=='datetime64[ns]' ]\n    return numerical_cols , categorical_cols\n    ","012ed1c2":"num_cols,cat_cols=cols_types(train)","e0e79c81":"print(num_cols,end=\"\")","5f1959dd":"print(cat_cols,end=\"\")","7f1de9d6":"for i in cat_cols:\n    print(f'{i}','\\n',getu(train[i]),'\\n')","9b3864d5":"train['Date']=pd.to_datetime(train['Date'],format=\"%d\/%m\/%Y\")\ntest['Date']=pd.to_datetime(train['Date'],format=\"%d\/%m\/%Y\")","2e332380":"train['month']=train['Date'].dt.month_name()\ntrain['year']=train['Date'].dt.year\n#train['day']=train['Date'].dt.day\ntrain['weekday']=train['Date'].dt.day_name()\n\ntrain['weekstatus'] = np.where(((train['Date']).dt.dayofweek) < 5,'weekday','weekend')","2d0e3e6d":"test['month']=train['Date'].dt.month_name()\ntest['year']=train['Date'].dt.year\n#test['day']=train['Date'].dt.day\ntest['weekday']=train['Date'].dt.day_name()\n\ntest['weekstatus'] = np.where(((test['Date']).dt.dayofweek) < 5,'weekday','weekend')","a71fd606":"df=train.copy()","aa2e56fb":"df.drop('ID',inplace=True,axis=1)\n#test.drop('ID',inplace=True,axis=1)","e54e1c3d":"# pd.options.display.max_columns=None\n# pd.options.display.max_rows=None","5037a375":"def get_working_days(x,y):\n    if x == 'No Holiday' and y== 'weekday':\n        return 'work'\n    elif x == 'No Holiday'  and y== 'weekend':\n        return 'nowork'\n    elif x == 'Holiday':\n        return \"nowork\"\n    elif y == 'weekdend':\n        return \"nowork\"\n","254164d8":"y=df['weekstatus']\nx=df['Holiday']\nfunc0 = np.vectorize(get_working_days)\nworkingday_tr = func0(x,y)\ndf['workingday'] =workingday_tr","fe5ddd38":"a=test['weekstatus']\nb=test['Holiday']\nfunc1 = np.vectorize(get_working_days)\nworkingday_ts = func1(b,a)\ntest['workingday'] =workingday_ts","a2f78dd8":"test.head()","6f15b771":"# Pandas profiling report\npandas_profiling.ProfileReport(df)","a2e0f7a5":"# Calculate covariance\ncovMat = df.cov()\nprint(covMat)","b7645eac":"fig = plt.figure(figsize=(20,20))\nsns.set_style(\"ticks\")\nsns.set_context(\"paper\", font_scale = 1.7, rc={\"grid.linewidth\": 10})\naxes = fig.add_subplot(4, 2, 1)\ngroup_weather = pd.DataFrame(df.groupby(['Temp'])['count'].mean()).reset_index()\npalette =sns.color_palette(\"pastel\")\nsns.scatterplot(data=group_weather, x='Temp', y='count', ax=axes,palette =palette)\naxes.set(xlabel='Temp', ylabel='Count', title='Average bike rentals across Temerature')\n\naxes = fig.add_subplot(4, 2, 2)\ngroup_season = pd.DataFrame(df.groupby(['Seasons'])['count'].mean()).reset_index()\nsns.barplot(data=group_season, x='Seasons', y='count', ax=axes)\naxes.set(xlabel='Seasons', ylabel='Count', title='Average bike rentals across Seasons')\n\naxes = fig.add_subplot(4, 2, 3)\ngroup_workingday = pd.DataFrame(df.groupby(['workingday'])['count'].mean()).reset_index()\nsns.barplot(data=group_workingday, x='workingday', y='count', ax=axes)\naxes.set(xlabel='Working Day', ylabel='Count', title='Average bike rentals across Working Day')\n\naxes = fig.add_subplot(4, 2, 4)\ngroup_season = pd.DataFrame(df.groupby(['Holiday'])['count'].mean()).reset_index()\nsns.barplot(data=group_season, x='Holiday', y='count', ax=axes)\naxes.set(xlabel='Holiday', ylabel='Count', title='Average bike rentals across Holiday')\n\n\naxes = fig.add_subplot(4,2,5)\ngroup_ra = pd.DataFrame(df.groupby(['Rainfall(mm)'])['count'].mean()).reset_index()\nsns.lineplot(data=group_ra, x='Rainfall(mm)', y='count', ax=axes)\naxes.set(xlabel='Rainfall(mm)', ylabel='Count', title='Average bike rentals across Rainfall')\n\naxes = fig.add_subplot(4,2,6)\ngroup_sn = pd.DataFrame(df.groupby(['Snowfall (cm)'])['count'].mean()).reset_index()\nsns.lineplot(data=group_sn, x='Snowfall (cm)', y='count', ax=axes)\naxes.set(xlabel='Snowfall (cm)', ylabel='Count', title='Average bike rentals across Snowfall')\n\naxes = fig.add_subplot(4,2,7)\ngroup_w = pd.DataFrame(df.groupby(['Wind speed (m\/s)'])['count'].mean()).reset_index()\nsns.lineplot(data=group_w, x='Wind speed (m\/s)', y='count', ax=axes)\naxes.set(xlabel='Wind speed (m\/s)', ylabel='Count', title='Average bike rentals across Windspeed')\n\naxes = fig.add_subplot(4,2,8)\ngroup_hd = pd.DataFrame(df.groupby(['Humidity(%)'])['count'].mean()).reset_index()\nsns.lineplot(data=group_hd, x='Humidity(%)', y='count', ax=axes)\naxes.set(xlabel='Humidity(%)', ylabel='Count', title='Average bike rentals across Humidity')\n\n\n\nplt.tight_layout()\nplt.show()","eec3eb5d":"# Mean of bikes rented sorted by day \ndf.groupby('weekday')['count'].mean()","0c3b9fae":"# Sum of bikes rented sorted by day \ndf.groupby('weekday')['count'].sum()","89fd1d42":"# Seasons bike trends\nsns.set_style(\"ticks\")\nsns.set_context(\"notebook\", font_scale = 5, rc={\"grid.linewidth\": 10})\nplt.style.use('bmh')\nfig = sns.FacetGrid(df, hue='Seasons', aspect=3,height=20)\nfig.map(sns.kdeplot, 'count', shade=True)\nfig.add_legend()","508efea6":"# Snowfall & Humidity\nsns.set_theme(style=\"ticks\")\nsns.set_context(\"paper\", font_scale =2, rc={\"grid.linewidth\": 10})\nplt.style.use('fivethirtyeight')\nsns.relplot('Snowfall (cm)','Humidity(%)', data=df, aspect=2,height=10,kind=\"scatter\", palette=\"r\")\n## Snowfall = higher humdity","8dcf3597":"# Scatter plot bikes rented by temperature. \nplt.style.use('bmh')\nsns.relplot('Temp','count',data=df, aspect=2,height=10)\n## When it's colder than -10 degrees, less than 500 bikes are rented\n## There is a positive correlation between the temperatre rising and the number of bikes rented increasing.","443b8d80":"# Bike rented by hour & season \nplt.style.use('bmh')\nsns.catplot('Hour','count' ,data=df,  hue='Seasons', aspect=2,height=10,legend=True)\n## Peaks Starts at 7 --> 19 ","704df64b":"feat_dist=['count','Seasons','Hour','Holiday','weekday','weekstatus','Functioning Day','workingday']","516373f1":"# def boxplot(x, y, **kwargs):\n#     plt.style.use('bmh')  \n#     box_plot=sns.boxplot(x=x, y=y)\n#     ax = box_plot.axes\n#     lines = ax.get_lines()\n#     categories = ax.get_xticks()\n#     x=plt.xticks(rotation=90)\n#     for cat in categories:\n   \n#         y = round(lines[4+cat*6].get_ydata()[0],1) \n\n#         ax.text(\n#             cat, \n#             y, \n#             f'{y}', \n#             ha='center', \n#             va='center', \n#             fontweight='bold', \n#             size=15,\n#             color='white',\n#             bbox=dict(facecolor='#445A64'))\n# sns.set_style(\"ticks\")\n# #sns.set_context(\"paper\", font_scale = 1.7, rc={\"grid.linewidth\": 10})\n# plt.style.use('bmh')  \n# f = pd.melt(df, id_vars=['count'], value_vars=feat_dist)\n# g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=10)\n# g.map(boxplot, \"value\", 'count')","893ff6a8":"daily = df.groupby(['Date'])['count'].sum()\nsns.set_context(\"paper\", font_scale =3, rc={\"grid.linewidth\": 10})\nplt.style.use('bmh')\nfig, ax1 = plt.subplots(1,1, figsize=(25,10))\npalette = sns.color_palette(\"flare\", as_cmap=True)\nsns.lineplot(daily.index, daily.values, ax=ax1,palette=palette)\nfig.autofmt_xdate()\nax1.xaxis.set_major_locator(md.MonthLocator(bymonthday = 1))\nax1.set_xlim(md.datestr2num((\"2017\/12\/01\", \"2018\/11\/20\")))\nax1.set_ylim((0, 37500))\nax1.xaxis.set_minor_locator(md.WeekdayLocator(byweekday = 1))\nax1.grid(b=True, which='major', color='r', lw=0.75)","c3460e12":"fig, ax1 = plt.subplots(1,1, figsize=(20,10),facecolor='cyan')\nsns.set_context(\"paper\", font_scale =3)\nsns.lineplot(x='Hour', y='count', data=df, hue='weekday', ci=None)\nax1.set_xlim((0,23))\nax1.xaxis.set_major_locator(ticker.MultipleLocator(2))","d9b40f19":"df.groupby('Hour')['count'].mean()\n","aeefe287":"df.groupby('Hour')['count'].sum()\n","4d66a52c":"plt.style.use('fivethirtyeight')\nsns.relplot('Temp','count',data=df, aspect=2,height=10)\n","7b6711b5":"# Scatter plot of bikes rented by temp & season \nplt.style.use('fivethirtyeight')\n\nsns.relplot('Temp','count', hue='Seasons', data=df, aspect=2,height=10)","636161ca":"plt.style.use('fivethirtyeight')\n\n# Scatter plot of bikes rented by temp & hour \nsns.relplot('Temp','count', hue='Hour',data=df, aspect=2,height=10)","ac206f5a":"def histogram_plot(x, title, yaxis, color):\n    trace = go.Histogram(x = x,\n                        marker = dict(color = color))\n    layout = go.Layout(hovermode = 'closest', title = title, yaxis = dict(title = yaxis))\n    fig = go.Figure(data = [trace], layout = layout)\n    return iplot(fig)","479b89a5":"histogram_plot(df['count'], 'Bike Rented Count', 'Frequency', '#EB89B5')","dc50e91f":"# logarithmic transformation of dependent cols\n# (adding 1 first so that 0 values don't become -inf)\ndf['log_count']=np.log(df['count']+1)","85bb1b9c":"histogram_plot(df['log_count'], 'Bike Rented Count', 'Frequency', '#EB89B5')","08992b76":"# Check Point \ndf_dummy=df.copy()","d3cdede1":"# q=df['count'].quantile(0.01)\n# df_dummy=df[df['count']>q]\n# df_dummy=df_dummy.reset_index(drop=True)","d407a63a":"# def tr_lf(x,lt=0.3,lz=0):\n#     if lt!=0:\n#         return ((x+lz)**lt-1)\/lt\n#     else:\n#         return np.log(x+lz)\n# def revtr (x,lt=0.3,lz=0):\n#     return (x*lt+1)**(1\/lt)-lz","f7d88af8":"# d_tr=df['count'].apply(tr_lf)   ","3ca721cb":"# def trans(x,l1=0.3,l2=0):\n#     if l1!=0:\n#         return ((x+l2)**l1-1)\/l1\n#     else:\n#         return np.log(x+l2)\n# def rev_trans(x,l1=0.3,l2=0):\n#     return (x*l1+1)**(1\/l1)-l2\n\n# z=train[label].apply(trans)   \n# sns.displot(z , kde=True, height=8.27, aspect=11.7\/8.27)","29949518":"#histogram_plot(d_tr, 'Bike Rented Count', 'Frequency', '#EB89B5')","66a73d8a":"#histogram_plot(np.log(df['count']+1), 'Bike Rented Count', 'Frequency', '#EB89B5')","a41a42a9":"num_cols,cat_cols=cols_types(df_dummy)","34737b05":"cat_cols","30169c5b":"num_cols","67ec14b6":"# category_list = ['Hour','year']\n# for var in category_list:\n#     df_dummy[var] = df_dummy[var].astype('category')\n#     test[var] = test[var].astype('category')","e492373e":"co_list=['Holiday', 'Functioning Day', 'workingday', 'weekstatus']","977d0a80":"df_dummy['weekstatus'] =np.where(df_dummy['weekstatus']=='weekday',1,df_dummy['weekstatus'])\ndf_dummy['weekstatus'] =np.where(df_dummy['weekstatus']=='weekend',0,df_dummy['weekstatus'])\n\ndf_dummy['workingday'] =np.where(df_dummy['workingday']=='work',1,df_dummy['workingday'])\ndf_dummy['workingday'] =np.where(df_dummy['workingday']=='nowork',0,df_dummy['workingday'])\n\ndf_dummy['Functioning Day']=np.where(df_dummy['Functioning Day'] == 'No', 0, df_dummy['Functioning Day'])\ndf_dummy['Functioning Day']=np.where(df_dummy['Functioning Day'] == 'Yes', 1, df_dummy['Functioning Day'])\n\ndf_dummy['Holiday']=np.where(df_dummy['Holiday'] == 'No Holiday', 1, df_dummy['Holiday'])\ndf_dummy['Holiday']=np.where(df_dummy['Holiday'] == 'Holiday', 0, df_dummy['Holiday'])","2b210c75":"# df_dummy['Seasons']=np.where(df_dummy['Seasons'] == 'Spring', 1, df_dummy['Seasons'])\n# df_dummy['Seasons']=np.where(df_dummy['Seasons'] == 'Summer', 2, df_dummy['Seasons'])\n# df_dummy['Seasons']=np.where(df_dummy['Seasons'] == 'Autumn', 3, df_dummy['Seasons'])\n# df_dummy['Seasons']=np.where(df_dummy['Seasons'] == 'Winter', 4, df_dummy['Seasons'])\n\n\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Monday', 1, df_dummy['weekday'])\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Tuesday', 2, df_dummy['weekday'])\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Wednesday', 3, df_dummy['weekday'])\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Thursday', 4, df_dummy['weekday'])\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Friday', 5, df_dummy['weekday'])\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Saturday', 6, df_dummy['weekday'])\n# df_dummy['weekday']=np.where(df_dummy['weekday'] == 'Sunday', 7, df_dummy['weekday'])","2aee4a14":"test['weekstatus'] =np.where(test['weekstatus']=='weekday',1,test['weekstatus'])\ntest['weekstatus'] =np.where(test['weekstatus']=='weekend',0,test['weekstatus'])\n\ntest['workingday'] =np.where(test['workingday']=='work',1,test['workingday'])\ntest['workingday'] =np.where(test['workingday']=='nowork',0,test['workingday'])\n\n\ntest['Functioning Day']=np.where(test['Functioning Day'] == 'No', 0, test['Functioning Day'])\ntest['Functioning Day']=np.where(test['Functioning Day'] == 'Yes', 1, test['Functioning Day'])\n\ntest['Holiday']=np.where(test['Holiday'] == 'No Holiday', 1, test['Holiday'])\ntest['Holiday']=np.where(test['Holiday'] == 'Holiday', 0, test['Holiday'])","118667a3":"# test['Seasons']=np.where(test['Seasons'] == 'Spring', 1, test['Seasons'])\n# test['Seasons']=np.where(test['Seasons'] == 'Summer', 2, test['Seasons'])\n# test['Seasons']=np.where(test['Seasons'] == 'Autumn', 3, test['Seasons'])\n# test['Seasons']=np.where(test['Seasons'] == 'Winter', 4, test['Seasons'])\n\n# test['weekday']=np.where(test['weekday'] == 'Monday', 1, test['weekday'])\n# test['weekday']=np.where(test['weekday'] == 'Tuesday', 2, test['weekday'])\n# test['weekday']=np.where(test['weekday'] == 'Wednesday', 3, test['weekday'])\n# test['weekday']=np.where(test['weekday'] == 'Thursday', 4, test['weekday'])\n# test['weekday']=np.where(test['weekday'] == 'Friday', 5, test['weekday'])\n# test['weekday']=np.where(test['weekday'] == 'Saturday', 6, test['weekday'])\n# test['weekday']=np.where(test['weekday'] == 'Sunday', 7, test['weekday'])","bfcec2b9":"df_dummy[co_list] = df_dummy[co_list].apply(pd.to_numeric, errors='coerce', axis=1)\ntest[co_list] = test[co_list].apply(pd.to_numeric, errors='coerce', axis=1)","b6cbd0fa":"input_features=['Hour', 'Temp', 'Humidity(%)', 'Functioning Day',\n       'Visibility (10m)', 'dew_pt', 'solar_rad_(MJ\/m2)', 'Rainfall(mm)',\n       'Snowfall (cm)', 'Seasons', 'Holiday', \n       'weekday',  'workingday']\ntarget='log_count'","a422aa88":"data=df_dummy[input_features].copy()\ntest_data=test[input_features].copy()","d234f65d":"data=pd.get_dummies(data,drop_first=True,columns=['Seasons','weekday'])\ntest_data=pd.get_dummies(test_data,drop_first=True,columns=['Seasons','weekday'])","ea513ce6":"X=data.copy()\ny=df_dummy[target]\nXtest=test_data.copy()","f7fc0719":"corr = df_dummy.corr()\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(20,20))\nk =20\ncols = corr.nlargest(k,'count')['count'].index\n\ncm = np.corrcoef(df_dummy[cols].values.T)\nsns.set(font_scale=1.6)\nsns.set_context(\"paper\", font_scale = 1.7, rc={\"grid.linewidth\": 10})\nplt.style.use('bmh')  \nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 15}, \n                 yticklabels=cols.values, xticklabels=cols.values,cmap=\"PiYG\")\nplt.title(\"Correlation_matrix\")","8a85a1f0":"#df_p = df_dummy[num_cols] \n#plt.style.use('bmh')  \n#g = sns.PairGrid(df_p, diag_sharey=False)\n#g.map_diag(sns.histplot)\n#g.map_upper(sns.kdeplot)\n#g.map_lower(sns.scatterplot)","da291b9a":"#df_dummy = df_dummy[df_dummy['Functioning Day'] != 0]","0004ec41":"#df_dummy.drop(columns='Functioning Day', inplace=True)","d69e8c79":"#df_dummy.drop(columns=['Date'],axis=1,inplace=True)","bc5abc50":"correlation=pd.DataFrame(data= corr.nlargest(20,'count'),columns=cols,index=cols)","1fdf871d":"cm = sns.light_palette(\"green\", as_cmap=True)\n\ncorrelation.style.background_gradient(cmap=cm)","2527e10c":"# var=df_dummy[num_cols]\n# vif=pd.DataFrame()\n# vif[\"VIF\"]=[variance_inflation_factor(var.values,i) for i in range (var.shape[1])]\n# vif['features']=var.columns","5cf153df":"\n# Splitting the data into training (80%) and test (20%) sets.  Since I will be\n# using cross validation to measure accuracy, we will not need an additional\n# validation set\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8, random_state=42)","9755399d":"# def get_rmsle(y_pred, y_actual):\n#     diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n#     mean_error = np.square(diff).mean()\n#     return np.sqrt(mean_error)\n\n# def predict_on_validation_set(model, X,y):\n\n\n#     X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.8, random_state=42)\n\n#     Model = model.fit(X_train, y_train)\n#     y_pred = np.exp(Model.predict(X_test)) - 1\n#     y_pred[y_pred < 0] = 0\n#     y_test = np.exp(y_test) - 1\n#     score = get_rmsle(y_pred, y_test)\n\n#     return (y_pred, y_test, score)\n\n\n\n# def predict_on_test_set(model,X_train,y_train,Xtest):\n \n   \n#     Model = model.fit(X_train, y_train)\n#     y_pred = Model.predict(Xtest)\n#     y_pred = np.exp(y_pred) - 1\n\n  \n#     return y_pred\n\n","631561b0":"# # random forest model\n# params = {'n_estimators': 1000, 'max_depth': 20, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\n# rf_model = RandomForestRegressor(**params)\n\n# rf_p, rf_t, rf_score = predict_on_validation_set(rf_model,X,y)\n# print(rf_score)","2ee04ebd":"# # GBM model\n# params = {'n_estimators': 150, 'max_depth':15, 'random_state': 0, 'min_samples_leaf' : 5, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n# gbm_model = GradientBoostingRegressor(**params)\n\n\n\n# (gbm_p, gbm_t, gbm_score) = predict_on_validation_set(gbm_model, X,y)\n# print(gbm_score)\n\n# # the blend gives a better score on the leaderboard, even though it does not on the validation set\n# y_p = np.round(.2*rf_p + .8*gbm_p)\n# print(get_rmsle(y_p, rf_t))","32fdf153":"# predctions on test dataset\n# rf_pred = predict_on_test_set(rf_model,X_train,y_train,Xtest)\n# gbm_pred = predict_on_test_set(gbm_model,X_train,y_train,Xtest)","6ac2fc6a":"# taking weighted average of output from two models\n# y_pred = np.round(.20*rf_pred + .80*gbm_pred)","8b0d0959":"# define dependent variable\ny = df['count']","14457b73":"# Configure Algorithms\nalgosClass = []\nalgosClass.append(('Random Forest Regressor',RandomForestRegressor()))\nalgosClass.append(('Linear Regression',LinearRegression()))\nalgosClass.append(('Support Vector Regression',SVR()))","058d878f":"\n# Regression\nresults = []\nnames = []\nfor name, model in algosClass:\n    result = cross_val_score(model, X,y, cv=5, scoring='r2')\n    names.append(name)\n    results.append(result)","ea34252c":"\n# print r2 results to determine best algorithm\nfor i in range(len(names)):\n    print(names[i],results[i].mean())","745def77":"# create the necessary training and testing data (75\/25)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 123)","382ad200":"#Modeling (Regression)\nalgo = RandomForestRegressor()\nmodel = algo.fit(X_train,y_train)","b377fc6a":"# Print CV score\nprint(cross_val_score(model, X, y, cv=5))","66496dfc":"predictions_train = model.predict(X_train)\npredRsquared = r2_score(y_train,predictions_train)\nrmse = np.sqrt(mean_squared_error(y_train, predictions_train))\nprint('R Squared: %.3f' % predRsquared)\nprint('RMSE: %.3f' % rmse)","1de8a8b3":"predictions_test = model.predict(X_test)\npredRsquared = r2_score(y_test,predictions_test)\nrmse = np.sqrt(mean_squared_error(y_test, predictions_test))\nprint('R Squared: %.3f' % predRsquared)\nprint('RMSE: %.3f' % rmse)","12f7cb2e":"yp=model.predict(Xtest)","8f084ac4":"test['y']=yp","65bfeb53":"\nFinal_prd = test[['ID', 'y']].copy()\nFinal_prd.to_csv('subm_3.csv', index=False)","6296d795":"# Trying Different ML Models","ccc1107b":"## Visualize The Distribution and realitons between Columns","85f44716":"# Load Packages","def4861f":"### Get WorkingDay Column based on  holiday or weekend","1cc74999":"## Date Timestamp","d2dda593":"# EDA","596d3cae":"### Get unique columns values","69dea898":"## Check point","a9097528":"# Loading Dataset","285f021a":"## Get Numerical And Categorical Columns Lists","a90330a1":"### change Weekstatus and workingday dtype to numerical \n### Make year and Hour Categorical type","5d5f74d7":"\n##### Keep dataset with only available bike to rent  drop the 'Functioning Day' column\n#### Drop Correlated Features ","13cc0896":"### Check Target Dist","1935595d":"# Checking Dataset' Information","385402c0":"##### Bikes usage rate is high in summer and working days","8947918c":"## Split Dataset","866201e8":"### Check some Categorical column's Values"}}