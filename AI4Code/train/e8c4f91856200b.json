{"cell_type":{"5ca8b03e":"code","b3eec8ff":"code","87afdc29":"code","cf879096":"code","18d8f24c":"code","768b5dcf":"code","8b7459ee":"code","8ebe0e3a":"code","22b1662a":"code","8b7039c7":"code","569f9a25":"code","aa2e2df2":"markdown","e3621778":"markdown","cb00bcc5":"markdown","7425b13c":"markdown","72f945a0":"markdown","4c7618b8":"markdown","1ecf8024":"markdown","a8087bd7":"markdown","38bbdb64":"markdown"},"source":{"5ca8b03e":"##### PACKAGES\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport cv2\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","b3eec8ff":"##### PARAMS\n\ndevice      = torch.device('cpu') \nnum_workers = 4\nbatch_size  = 64\nimage_size  = 300\ndata_path   = '\/kaggle\/input\/seti-breakthrough-listen\/'","87afdc29":"##### DATA IMPORT\n\ndef get_train_file_path(image_id):\n    '''\n    Borrowed from https:\/\/www.kaggle.com\/yasufuminakama\/seti-nfnet-l0-starter-training\n    '''\n    return data_path + '\/train\/{}\/{}.npy'.format(image_id[0], image_id)\n\n\ndf              = pd.read_csv(data_path + 'train_labels.csv')\ndf['file_path'] = df['id'].apply(get_train_file_path)\ndf.head()","cf879096":"##### DATASET\n\n'''\nAdapted from https:\/\/www.kaggle.com\/yasufuminakama\/seti-nfnet-l0-starter-training\n'''\n\nclass ImageData(Dataset):\n    \n    def __init__(self, df, transform = None):\n        self.df         = df\n        self.file_names = df['file_path'].values\n        self.transform  = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.load(self.file_names[idx])\n        image = image.astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n        image = self.transform(image = image)['image']\n            \n        return image","18d8f24c":"##### AUGMENTATIONS\n\naugs = A.Compose([A.Resize(height  = image_size, \n                           width   = image_size),\n                  ToTensorV2()])","768b5dcf":"##### EXAMINE SAMPLE BATCH\n\n# dataset\nimage_dataset = ImageData(df        = df, \n                          transform = augs)\n\n# data loader\nimage_loader = DataLoader(image_dataset, \n                          batch_size  = batch_size, \n                          shuffle     = False, \n                          num_workers = num_workers)\n\n# display images\nfor batch_idx, inputs in enumerate(image_loader):\n    fig = plt.figure(figsize = (14, 7))\n    for i in range(4):\n        ax = fig.add_subplot(2, 4, i + 1, xticks = [], yticks = [])     \n        plt.imshow(inputs[i].numpy()[0, :, :], cmap = 'gray')\n    break","8b7459ee":"##### COMPUTE PIXEL SUM AND SQUARED SUM\n\n# placeholders\npsum    = torch.tensor([0.0])\npsum_sq = torch.tensor([0.0])\n\n# loop through images\nfor inputs in tqdm(image_loader):\n    psum    += inputs.sum(axis        = [0, 2, 3])\n    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])","8ebe0e3a":"##### FINAL CALCULATIONS\n\n# pixel count\ncount = len(df) * image_size * image_size\n\n# mean and STD\ntotal_mean = psum \/ count\ntotal_var  = (psum_sq \/ count) - (total_mean ** 2)\ntotal_std  = torch.sqrt(total_var)\n\n# output\nprint('Training data stats:')\nprint('- mean: {:.4f}'.format(total_mean.item()))\nprint('- std:  {:.4f}'.format(total_std.item()))","22b1662a":"###### DATA IMPORT\n\ndf = pd.read_csv(data_path + 'sample_submission.csv')\n\ndef get_test_file_path(image_id):\n    return data_path + '\/test\/{}\/{}.npy'.format(image_id[0], image_id)\n\ndf['file_path'] = df['id'].apply(get_test_file_path)\ndf.head()","8b7039c7":"###### DATASET & DATALOADER\n\n# dataset\nimage_dataset = ImageData(df        = df, \n                          transform = augs)\n\n# data loader\nimage_loader = DataLoader(image_dataset, \n                          batch_size  = batch_size, \n                          shuffle     = False, \n                          num_workers = num_workers)","569f9a25":"##### CALCULATIONS\n\n# placeholders\npsum    = torch.tensor([0.0])\npsum_sq = torch.tensor([0.0])\n\n# loop through images\nfor inputs in tqdm(image_loader):\n    psum    += inputs.sum(axis        = [0, 2, 3])\n    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])\n    \n# pixel count\ncount = len(df) * image_size * image_size\n\n# mean and STD\ntotal_mean = psum \/ count\ntotal_var  = (psum_sq \/ count) - (total_mean ** 2)\ntotal_std  = torch.sqrt(total_var)\n\n# output\nprint('Test data stats:')\nprint('- mean: {:.4f}'.format(total_mean.item()))\nprint('- std:  {:.4f}'.format(total_std.item()))","aa2e2df2":"# CALCULATIONS\n\nThe computation is done in three steps:\n\n1. Define placeholders to store two batch-level stats: sum and squared sum of pixel values. The first will be used to compute means, and the latter will be needed for standard deviation calculations.\n2. Loop through the batches and add up channel-specific sum and squared sum values.\n3. Perform final calculations to obtain data-level mean and standard deviation.\n\n## Training images","e3621778":"# PREPARATIONS\n\nFirst, we import relevant libraries and specify some parameters. No need to use GPU because there is no modeling involved.","cb00bcc5":"In the `Dataset` class, we are stacking all images along the time axis. If you use a different way to merge the original arrays (e.g., only use a subset of cadences or do a channel-level stacking), the calculation results might be different.","7425b13c":"# DATA PREP\n\nNow, let's set up a Dataset and a DataLoader.","72f945a0":"# SUMMARY\n\nThis notebook demonstrates how to compute mean and standard deviation of training and test images in `PyTorch`. Knowing mean and STD may be helpful for normalizing images within the augmentation pipeline. While computing mean is easy (we can simply average means over batches), standard deviation is a bit more tricky: averaging STDs across batches is not the same as the overall STD. Let's see how to do it properly!\n\nNote: original pipeline comes from [this notebook](https:\/\/www.kaggle.com\/kozodoi\/computing-dataset-mean-and-std).\n\n\n### TL;DR\n\n- train images: `mean = -0.0001, std = 0.9055`\n- test images:  `mean = -0.0002, std = 0.8453`","4c7618b8":"## Test images","1ecf8024":"Finally, we make some further calculations:\n\n- mean: simply divide the sum of pixel values by the total count - number of pixels in the dataset computed as `len(df) * image_size * image_size`\n- standard deviation: use the following equation: `total_std = sqrt(psum_sq \/ count - total_mean ** 2)`\n\nWhy we use such a weird formula for STD? Well, because this is how the variance equation can be simplified to make use of the sum of squares when other data is not available. If you are not sure about this, expand the cell below to see a calculation example or [read this](https:\/\/www.thoughtco.com\/sum-of-squares-formula-shortcut-3126266) for some details.\n\n![variance equation](https:\/\/kozodoi.me\/images\/copied_from_nb\/images\/fig_variance.jpg)","a8087bd7":"Our augmentation pipeline only uses `A.Resize()` to resize the images.","38bbdb64":"# STD CALCULATION EXAMPLE\n\n## Consider three vectors: \nA = [1, 1]\nB = [2, 2]\nC = [1, 1, 2, 2]\n\n## Let's compute SDs in a classical way:\n1. Mean(A) = 1; Mean(B) = 2; Mean(C) = 1.5\n2. SD(A) = SD(B) = 0  # because there is no variation around the means\n3. SD(C) = sqrt(1\/4 * ((1 - 1.5)**2 + (1 - 1.5)**2 + (1 - 1.5)**2 + (1 - 1.5)**2)) = 1\/2\n\n## Note that SD(C) is clearly not equal to SD(A) + SD(B), which is zero. \n\n## Instead, we could compute SD(C) in three steps using the equation above:\n1. psum    = 1 + 1 + 2 + 2 = 6\n2. psum_sq = (1**2 + 1**2 + 2**2 + 2**2) = 10\n3. SD(C)   = sqrt((psum_sq - 1\/N * psum**2) \/ N) = sqrt((10 - 36 \/ 4) \/ 4) = sqrt(1\/4) = 1\/2\n\n## We get the same result as in the classical way!"}}