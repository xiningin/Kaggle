{"cell_type":{"b0570211":"code","24ab218c":"code","fd1856f5":"code","6e6be62f":"code","42fa69fd":"code","41b54ead":"code","c635bddf":"code","c3af79c7":"code","35c39735":"code","13e495ef":"code","2050e794":"code","f05a3b0b":"code","8fb5dba1":"code","a9004a50":"code","32830bed":"code","2f2a0663":"code","14593f70":"code","c49de05a":"code","96e75ba0":"code","3880957a":"code","88ceb595":"code","5eefad1a":"code","2d43f957":"code","da66efb1":"code","516ffad3":"code","a806389d":"code","7165ec5a":"code","99fe1929":"code","fe32c0b2":"code","f6763613":"code","c71eb703":"code","8ee116d7":"code","cae0f0a3":"code","f9c26638":"code","cc86a9b8":"code","fe178003":"code","5fd08d24":"code","552f874d":"code","cbcb8e30":"code","8cdb6aa9":"code","66b8d87c":"code","9d92005e":"code","e7aaaba6":"code","251ae810":"code","5fcfa744":"code","753a7eac":"code","51df8f56":"code","bb484a30":"code","7683f028":"code","f00f25a8":"code","9ee673f2":"code","f6703ca4":"code","a443007c":"code","177ee4cd":"code","e92cc66e":"code","16c6bb7f":"code","c92ad89d":"code","ac4478c3":"code","73acdf77":"code","509cec62":"code","287458db":"code","042b876c":"code","de8aa690":"code","2cc4ad98":"code","937f7332":"code","ac47dd2e":"code","dae38469":"code","26a412b4":"code","5679b590":"code","c45d651e":"code","c93038a3":"code","3985e65e":"code","2ec5e81b":"code","0799f820":"code","74439ffd":"code","9e0f5d02":"code","8d8bfdaa":"code","5d0baca2":"code","c6ab6e2f":"code","7566f901":"code","f0749358":"code","c03e78e4":"code","da8f40fa":"code","16ddf85f":"code","b5eb9d60":"code","30548c84":"code","b52dc315":"code","717eb7de":"code","939a3162":"code","83c67d4b":"code","f3192b62":"code","69e78eee":"code","c75606a5":"code","19fe5932":"code","481ca1a9":"code","930c4128":"code","0b81f042":"code","e35b04f3":"code","d72952e2":"code","8e2d5fbb":"code","8da7d84c":"code","a2a6fab7":"code","b0bf54a1":"code","762650a0":"code","c418e1c4":"code","0133b156":"code","3b06f25c":"code","84c9a1db":"code","7c60afba":"code","94942ad7":"code","26222331":"markdown","421c6838":"markdown","ac07b1aa":"markdown","25354171":"markdown","4448e436":"markdown","bbd46dc3":"markdown","1b21c601":"markdown","2929ea60":"markdown","a339da16":"markdown","af19a3a0":"markdown","6483503d":"markdown","ab3cb0ae":"markdown","63e6ef1a":"markdown","7691b8d3":"markdown","4e47d951":"markdown","14e70c43":"markdown","f436615e":"markdown","6a49dc73":"markdown","1d246da2":"markdown","3c3498db":"markdown","a89e95a8":"markdown","e63c9b58":"markdown"},"source":{"b0570211":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24ab218c":"# loading dataframe\ndf = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","fd1856f5":"df.head()","6e6be62f":"df.info()","42fa69fd":"## cleaning missing values\ndf.shape","41b54ead":"df[df.duplicated()] ## no duplicates","c635bddf":"#df['ever_married'] = df['ever_married'].map({'Yes': 1, 'No': 0})","c3af79c7":"df['gender'].value_counts()","35c39735":"#df['gender'] = df['gender'].replace({'Female': 1, 'Male': 0, 'Other': 2})\n# 2 - Other\n# 1 - Female\n# 0 - Male","13e495ef":"df.head()","2050e794":"df.info()","f05a3b0b":"df.work_type.value_counts()","8fb5dba1":"df.Residence_type.value_counts()\n# almost equal number of people from rural and urban areas in the ","a9004a50":"df['avg_glucose_level'].describe()","32830bed":"df['bmi'].describe()","2f2a0663":"df['smoking_status'].value_counts()","14593f70":"df['stroke'].value_counts()","c49de05a":"## handling missing data - BMI - by Prediction through decision tree - variables used: age and gneder\n\n\nfrom sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\n\n\n\nDT_bmi_pipeline = Pipeline(steps = [\n    ('scale', StandardScaler()),\n    ('lr', DecisionTreeRegressor(random_state = 42))\n])\n\n\nX = df[['age', 'gender', 'bmi']].copy()\nX.gender = X.gender.replace({'Male': 0, 'Female': 1, 'Other': -1})\n\nX.gender = X.gender.astype(np.uint8)\n","96e75ba0":"## Separting those values that have Missing BMI\n\n# test set would contain all bmi missing 201 values\nMissing = X[X.bmi.isna()]\n\n# train set would contain all non-missing bmi values\nX_train = X[~X.bmi.isna()]\nY_train = X_train.pop('bmi')\n\n# Fit regressor\nDT_bmi_pipeline.fit(X_train, Y_train)","3880957a":"## Predicting missing BMI and substituting in the original dataset\npredicted_bmi = pd.Series(DT_bmi_pipeline.predict(Missing[['age', 'gender']]), index = Missing.index)\npredicted_bmi","88ceb595":"# substituting in original dataset\ndf.loc[Missing.index, 'bmi'] = predicted_bmi","5eefad1a":"df.isnull().sum()","2d43f957":"df.corr(method = 'pearson')","da66efb1":"variables = [variable for variable in df.columns]\n\nconts = ['age','avg_glucose_level','bmi']","516ffad3":"variables","a806389d":"import matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(12, 12), facecolor='#f6f6f6')\ngs = fig.add_gridspec(4, 3)\ngs.update(wspace=0.1, hspace=0.4)\ngs","7165ec5a":"corr = df.corr()","99fe1929":"mask = np.triu(np.ones_like(corr, dtype=bool))\nmask","fe32c0b2":"# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\nimport seaborn as sns\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","f6763613":"# singular plots\n\n\n# hypertension\n# heart_disease\n# ever_married\n# gender\n# stroke\n# smoking\n\n\nsns.set_theme(style = 'darkgrid')\n#plot_hypertension = sns.countplot(data = df, x = 'hypertension')\n#plot_heart_disease = sns.countplot(data = df, x = 'heart_disease')\nplot = sns.countplot(data = df, x = 'work_type')","c71eb703":"# For Avergae Glucose level\nfig = plt.figure(figsize=(7,7))\nsns.displot(df.avg_glucose_level, color=\"green\", label=\"avg_glucose_level\", kde= True)\nplt.legend()","8ee116d7":"# For BMI distribution\nfig = plt.figure(figsize=(10,10))\nsns.displot(df.bmi, color = 'blue', label = 'BMI', kde = True)\nplt.legend()","cae0f0a3":"## Stroke vs No Stroke Avergae Glucose Level\nplt.figure(figsize=(12,10))\n\nsns.distplot(df[df['stroke'] == 0][\"bmi\"], color='green') # No Stroke - green\nsns.distplot(df[df['stroke'] == 1][\"bmi\"], color='red') # Stroke - Red\n\nplt.title('Stroke vs No Stroke BMI', fontsize = 15)\nplt.xlim([10,100])\nplt.show()","f9c26638":"plt.figure(figsize=(12,10))\nsns.distplot(df[df['stroke']==0]['avg_glucose_level'], color = 'green')\nsns.distplot(df[df['stroke'] == 1]['avg_glucose_level'], color = 'red')\nplt.title('Stroke vs No stroke Average Glucose Level', fontsize = 15)\nplt.xlim([30,300]) ## limit of x-axis\nplt.show()","cc86a9b8":"fig = plt.figure(figsize=(7,7))\ngraph = sns.scatterplot(data = df, x = \"age\", y = \"bmi\", hue = \"gender\")\n## to draw a line within the graph\ngraph.axhline(y = 25, linewidth = 4, color = \"r\", linestyle = '--')\ngraph.axhline()\nplt.show()","fe178003":"fig = plt.figure(figsize=(7,7))\ngraph = sns.scatterplot(data= df, x = \"age\", y = \"avg_glucose_level\", hue=\"gender\")\ngraph.axhline(y = 150, linewidth = 4, color = \"r\", linestyle = \"--\")\nfig.show()","5fd08d24":"# With respect to smokers and non-smokers\ndf.head()","552f874d":"fig = plt.figure(figsize=(7,7))\ngraph = sns.scatterplot(data = df, x = \"smoking_status\", y = \"avg_glucose_level\")\nfig.show()","cbcb8e30":"# pair plot - all possible scatter plots\nfig = plt.figure(figsize=(10,10))\nsns.pairplot(df)\nplt.show()","8cdb6aa9":"# Getting predictor and the target variables separate\nx = df.iloc[:, 1:-1].values\nx","66b8d87c":"y = df.iloc[:, -1].values\ny","9d92005e":"## One hot encoding for categorical variables: gender, work_type, smoking_status\n## Label encoding of binary variables: ever_married, residence_type","e7aaaba6":"df.rename(columns= {'Residence_type': 'residence_type'}, inplace=True)","251ae810":"df.head()","5fcfa744":"df['residence_type'].value_counts()","753a7eac":"# one hot encoding\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder()\n\nct = ColumnTransformer(transformers= [('encoder', ohe, [0])], remainder = 'passthrough')\nx = np.array(ct.fit_transform(x))\nx","51df8f56":"x = np.delete(x, 2, 1) # deleting the 3rd column so as to delete one gender one hot encoded variable to prevent multicollinearity","bb484a30":"x[0][6]","7683f028":"# one hot encoding of work_type\nct = ColumnTransformer(transformers = [('encoder', ohe, [6])], remainder = 'passthrough')\nx = np.array(ct.fit_transform(x))\nx","f00f25a8":"print(\"This should be private: \", x[0][2])\nprint(\"This should also be private: \", x[2][2])\nprint(\"This should also be private: \", x[3][2])","9ee673f2":"# Where does the work_type end\n# 0,1: gender\n# 2,3,4,5,6: work_type\nx[0][7] # age","f6703ca4":"# drop number 6 of work_type\nx = np.delete(x, 6, 1)\nx[0][6]","a443007c":"# what is the current index of smoking status\nx[0][13]","177ee4cd":"# One hot encoding of smoking status\nct = ColumnTransformer(transformers = [('encoder', ohe, [13])], remainder = 'passthrough')\nx = np.array(ct.fit_transform(x))\nx","e92cc66e":"# 0,1 : gender\n# 2,3,4,5: work_type\n# 6,7,8,9: smoking status\nx = np.delete(x, 9, 1)\nx.shape","16c6bb7f":"# Label Encoding\ni,j = np.where(x == \"Urban\")","c92ad89d":"i # row number","ac4478c3":"j # Column number","73acdf77":"#Index 15 is ever_married and index 16 is residence_type\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx[:, 12] = le.fit_transform(x[:, 12])\nx[:, 13] = le.fit_transform(x[:, 13])\nx","509cec62":"print(\"Shape x: \", x.shape) \nprint(\"Shape y: \", y.shape)","287458db":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","042b876c":"print(\"Number of records in training set: \", x_train.shape)\nprint(\"Shape of training set's labels: \", y_train.shape)\nprint(\"Number of records in test set: \", x_test.shape)\nprint(\"Shape of test set's labels: \", y_test.shape)","de8aa690":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","2cc4ad98":"x_test","937f7332":"print(\"Shape of training data: {} and {}\".format(x_train.shape, y_train.shape))","ac47dd2e":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state = 0)\nx_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())","dae38469":"x_train_res.shape","26a412b4":"print(\"Shape of training data after synthetic oversampling: {} and {} \".format(x_train_res.shape, y_train_res.shape))","5679b590":"print(\"Number of label 1 records before over_sampling: \", sum(y_train == 1))\nprint(\"Number of label 0 records before over_sampling: \", sum(y_train == 0))\nprint(\"\\n\")\nprint(\"Number of label 1 records before SMOTE: \", sum(y_train_res == 1))\nprint(\"Number of label 0 records after SMOTE: \", sum(y_train_res == 0))","c45d651e":"x_train_res","c93038a3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","3985e65e":"# importing all metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay,precision_score, recall_score, f1_score, classification_report, roc_auc_score, roc_curve, plot_roc_curve, precision_recall_curve, plot_precision_recall_curve, auc, average_precision_score\n\nfrom sklearn.model_selection import cross_val_score","2ec5e81b":"models_array = []\n\n## Adding it in an array so that could be made into a dataframe later\nmodels_array.append(['Logistic Regression', LogisticRegression(random_state = 0)])\nmodels_array.append(['K Nearest Neighbours', KNeighborsClassifier()])\nmodels_array.append(['SVM Classifier', SVC(random_state=0)])\nmodels_array.append(['Gaussian Naive Bayes', GaussianNB()])\nmodels_array.append(['Bernoulli Naive Bayes', BernoulliNB()])\nmodels_array.append(['Decision Tree Classifier', DecisionTreeClassifier(random_state = 0)])\nmodels_array.append(['Random Forest', RandomForestClassifier(random_state = 0)])\nmodels_array.append(['XGBoost Classifier', XGBClassifier(eval_metric = 'error',use_label_encoder=False)])","0799f820":"list1= []\n\nfor m in range(len(models_array)):\n    list2 = []\n    model = models_array[m][1]\n    model.fit(x_train_res, y_train_res)\n    y_pred = model.predict(x_test)\n    \n    # confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    \n    # training accuracies - K-fold cross validation\n    accuracies = cross_val_score(estimator = model, X = x_train_res, y = y_train_res, cv = 10)\n    \n    # Accuracy score of test set\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    # Area Score under Reciever Operating Characteristic Curve\n    roc = roc_auc_score(y_test, y_pred) \n    \n    # Precision\n    precision = precision_score(y_test, y_pred)\n    \n    # Recall\n    recall = recall_score(y_test, y_pred)\n    \n    # F1-score\n    f1 = f1_score(y_test, y_pred)\n    \n    # Printing the results for every model\n    print(models_array[m][0], \":\")\n    print(\"Training set mean accuracy: {:.2f} %\".format(accuracies.mean()*100))\n    print(\"Training set standard deviation: {:.2f} %\".format(accuracies.std()*100))\n    print(\"Test set accuracy: {:.2f} %\".format(accuracy*100))\n    print(\"Confusion Matrix: \", cm)\n    print(\"Precision: {:.2f} %\".format(precision*100))\n    print(\"Recall: {:.2f} %\".format(recall*100))\n    print(\"F1 score: {:.2f}\".format(f1))\n    print(\"AUROC score: {:.2f}\".format(roc))\n    print(\"-----------------------------------------\")\n    print(\"\\n\")\n    \n    \n    ## Adding all scores to a list so that we can form a dataframe later\n    list2.append(models_array[m][0])\n    list2.append(accuracies.mean()*100)\n    list2.append(accuracies.std()*100)\n    list2.append(accuracy)\n    list2.append(precision)\n    list2.append(recall)\n    list2.append(f1)\n    list2.append(roc)\n    \n    list1.append(list2) ## now list1 contains all the information of the results of the models - this can be put in a data frame\n    \n    ","74439ffd":"## Adding the results in a dataframe\ndf_results = pd.DataFrame(list1, columns = ['Model','Training Mean Accuracy', 'Training Standard Deviation', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC Value'])\ndf_results.sort_values(by = ['Test Accuracy', 'Training Mean Accuracy', 'AUC Value'], inplace=True, ascending = False)\ndf_results","9e0f5d02":"# Grid search to select hyper-parameters \nfrom sklearn.model_selection import GridSearchCV","8d8bfdaa":"grid_models = [\n    (LogisticRegression(), [{'C':[0.25, 0.5, 0.75, 1], 'random_state':[0]}]),\n    #(KNeighborsClassifier(), [{'n_neighbors': [5,7,8,10], 'metric': ['euclidian', 'manhattan', 'chebyshev', 'minkowski']}]),\n    (SVC(), [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear', 'rbf'], 'random_state':[0]}]),\n    (GaussianNB(), [{'var_smoothing': [1e-09]}]),\n    (BernoulliNB(), [{'alpha': [0.25, 0.5, 1]}]),\n    (DecisionTreeClassifier(), [{'criterion': ['gini', 'entropy'], 'random_state': [0]}]),\n    (RandomForestClassifier(), [{'n_estimators': [100, 150, 200], 'criterion': ['gini', 'entropy'], 'random_state': [0]}]),\n    (XGBClassifier(), [{'learning_rate': [0.01, 0.05, 0.1], 'eval_metric': ['error'], 'use_label_encoder': [False]}])\n]","5d0baca2":"for i,j in grid_models:\n    grid = GridSearchCV(estimator = i, param_grid = j, scoring = 'accuracy', cv = 10)\n    grid.fit(x_train_res, y_train_res)\n    best_accuracy = grid.best_score_\n    best_param = grid.best_params_\n    \n    print(\"{}: \", i)\n    print(\"Best Accuracy:  {:.2f} %\".format(best_accuracy*100))\n    print(\"Best parameters selected: \", best_param)\n    print(\"------------------------------\")\n    print(\"\\n\")\n    ","c6ab6e2f":"# Fitting the random forest model with the above hyper parameters obtained by grid search\n\nclassifier = RandomForestClassifier(criterion = 'entropy', n_estimators = 150, random_state = 0)\nclassifier.fit(x_train_res, y_train_res)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1] #probability with which the prediction is made\ncm = confusion_matrix(y_test, y_pred)\n\nprint(\"predicted y: \", y_pred)","7566f901":"cm","f0749358":"rf_results_df = pd.DataFrame({'Predicted Stroke': y_pred, \n                             'Predicted Stroke Probability': y_prob,\n                             'Actual Stroke': y_test})\nrf_results_df.head()","c03e78e4":"print(classification_report(y_test, y_pred))\nprint(\"ROC AUC Score: \", roc_auc_score(y_test, y_prob))\nprint(\"Test Accuracy: \", accuracy_score(y_test, y_pred))","da8f40fa":"# Visualizing Confusion Matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (10,10))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt='d', linewidths = 5, cbar = False,\n           annot_kws = {'fontsize': 15}, yticklabels= ['No Stroke', 'Stroke'], \n           xticklabels= ['Predicted No Stroke', 'Predicted Stroke'])\nplt.yticks(rotation = 0)\nplt.show()","16ddf85f":"# Visualizing the ROC-AUC curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc_score = auc(false_positive_rate, true_positive_rate)\nroc1 = roc_auc_score\nprint(\"AUC of tuned RF is: \", roc_auc_score)","b5eb9d60":"# Visualizing the ROC curve\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (10,10))\nplt.plot(false_positive_rate, true_positive_rate, color='#b01717', label = 'AUC = %0.4f' %roc_auc_score)\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], linestyle='--', color = '#174ab0')\nplt.axis('tight') # to remove additional white space in the plot\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.xlabel('False Positive rate (1-Specificity)')\nplt.legend()\nplt.show()","30548c84":"classifier = XGBClassifier(eval_metric = 'error', use_label_encoder = False, learning_rate = 0.1)\nclassifier.fit(x_train_res, y_train_res)\ny_pred = classifier.predict(x_test)\ny_prob = classifier.predict_proba(x_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)","b52dc315":"# Putting the results in a dataframe\ndf_xgboost_results = pd.DataFrame({'Predicted Stroke Variable': y_pred, \n                                  'Predicted Stroke Probability': y_prob,\n                                  'Actual Stroke Variable': y_test})\ndf_xgboost_results.head()","717eb7de":"cm","939a3162":"accuracy_score(y_test, y_pred)","83c67d4b":"# ROC AUC curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc_score = auc(false_positive_rate, true_positive_rate)\nroc_auc_score","f3192b62":"## Visualization - Confusion Matrix\nplt.figure(figsize = (10,10))\nsns.heatmap(cm, cmap = \"Blues\", annot = True, fmt = 'd', linewidth = 5, cbar = False, annot_kws = {'fontsize': 15},\n           xticklabels = ['Predicted No Stroke', 'Predicted Stroke'], yticklabels = ['No Stroke', 'Stroke'])\nplt.show()","69e78eee":"## Visualizaton - ROC AUC Curve\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (10,10))\nplt.plot(false_positive_rate, true_positive_rate, color='#b01717', label = 'AUC = %0.4f' %roc_auc_score)\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], linestyle='--', color = '#174ab0')\nplt.axis('tight') # to remove additional white space in the plot\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.xlabel('False Positive rate (1-Specificity)')\nplt.legend()\nplt.show()","c75606a5":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.regularizers import l2","19fe5932":"# Building the ANN with 3 dense layers\nimport tensorflow as tf\n\ndef ann_classifier():\n    ann = tf.keras.models.Sequential() ## Sequential layer has one input tensor and one output tensor\n    \n    # Dense layer 1\n    ann.add(tf.keras.layers.Dense(units=8, kernel_regularizer = l2(0.01), bias_regularizer = l2(0.01), activation = 'relu'))\n    \n    #Dense layer 2\n    ann.add(tf.keras.layers.Dense(units=8, kernel_regularizer = l2(0.01), bias_regularizer = l2(0.01), activation = 'relu'))\n    \n    # Dense layer 3\n    ann.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n    \n    \n    ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return ann","481ca1a9":"model = KerasClassifier(build_fn = ann_classifier, batch_size = 32, epochs = 50)","930c4128":"## Evaluating the basic untuned ANN\naccuracies = cross_val_score(estimator = model, X=x_train_res, y=y_train_res, cv = 5)","0b81f042":"## Checking the meand and std dev of the accuracies obtained\nmean = accuracies.mean()\nmean","e35b04f3":"std_dev = accuracies.std()\nstd_dev","d72952e2":"def ann_classifier(optimizer = 'adam'):\n    ann = tf.keras.models.Sequential() ## Sequential layer has one input tensor and one output tensor\n    \n    # Dense layer 1\n    ann.add(tf.keras.layers.Dense(units=8, kernel_regularizer = l2(0.01), bias_regularizer = l2(0.01), activation = 'relu'))\n    \n    #Dense layer 2\n    ann.add(tf.keras.layers.Dense(units=8, kernel_regularizer = l2(0.01), bias_regularizer = l2(0.01), activation = 'relu'))\n    \n    # Adding dropout which is a technique to randomly ignore neurons while training to reduce overfitting\n    tf.keras.layers.Dropout(0.6)\n     \n    # Dense layer 3\n    ann.add(tf.keras.layers.Dense(units=1, activation = 'sigmoid'))\n    \n    \n    ann.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \n    return ann","8e2d5fbb":"model = KerasClassifier(build_fn = ann_classifier, batch_size = 32, epochs = 50)\n\nparameters = {\n    'batch_size': [25, 32],\n    'epochs': [50,100,150],\n    'optimizer': ['adam', 'rmsprop']\n}\n\n\ngrid_search = GridSearchCV(estimator = model, param_grid = parameters, scoring = 'accuracy', cv = 5, n_jobs = -1)\ngrid_search.fit(x_train_res, y_train_res)","8da7d84c":"best_accuracy = grid_search.best_score_\nbest_params = grid_search.best_params_\n\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters: \", best_params)","a2a6fab7":"ann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units = 32, kernel_regularizer = l2(0.01), bias_regularizer = l2(0.01), activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 32, kernel_regularizer = l2(0.01), bias_regularizer = l2(0.01), activation = 'relu'))\ntf.keras.layers.Dropout(0.6)\nann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n\nann.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nmodel = ann.fit(x_train_res, y_train_res, batch_size = 25, epochs = 150, validation_split = 0.2)","b0bf54a1":"# Loss Graph\n# Here model is actually just the ann history\n\n\nloss_training = model.history['loss']\nloss_validation = model.history['val_loss']\nepochs = range(1,151)\n\nplt.plot(epochs, loss_training, 'g', label = 'Training Loss')\nplt.plot(epochs, loss_validation, 'b', label = 'Validation Loss')\n\nplt.title('Training and Validation Loss of Tuned ANN')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.legend()\nplt.show()","762650a0":"# Training and Validation accuracy plot\ntraining_accuracy = model.history['accuracy']\nvalidation_accuracy = model.history['val_accuracy']\nepochs = range(1,151)\n\nplt.plot(epochs, training_accuracy, 'g', label= 'Training Accuracy')\nplt.plot(epochs, validation_accuracy, 'b', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy for Tuned ANN')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","c418e1c4":"y_pred = ann.predict(x_test)","0133b156":"def threshold_prediction(y_pred):\n    y_pred_result = []\n    for i in y_pred:\n        if i > 0.5:\n            y_pred_result.append(1)\n        else:\n            y_pred_result.append(0)\n    return y_pred_result\n            \ny_pred_result = threshold_prediction(y_pred)","3b06f25c":"cm = confusion_matrix(y_test, y_pred_result)\ncm","84c9a1db":"accuracy_test = accuracy_score(y_test, y_pred_result)\naccuracy_test","7c60afba":"false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\nroc_auc_score = auc(false_positive_rate, true_positive_rate)\nroc1 = roc_auc_score\nprint(\"AUC of tuned ANN is: \", roc_auc_score)","94942ad7":"plt.figure(figsize=(8,5))\nsns.heatmap(cm, cmap = \"Blues\", annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws ={'fontsize': 15}, yticklabels = ['No Stroke', 'Stroke'], xticklabels = ['Predicted No Stroke', 'Predicted Stroke'])\nplt.show()","26222331":"# Final Tally:\n\n### 0,1 index are gender\n### 2,3,4,5 are work_type\n### 6,7,8: smoking status\n\n### Ellimination of one hot encoded variable per predictor is done to avoid Multicollineartity","421c6838":"From above results we can see that on training and test set the following models performed well:\n1. KNN\n2. Decision Tree\n3. Random Forest\n4. XGBoost\n\n\nThe following performed poorly:\n1. SVM\n2. Logistics Regression\n3. Naive Bayes (both Gausian and Bernoulli)\n\nHowever, before eliminating any models, we should try to select the best hyperparameter and see the performance of each","ac07b1aa":"## Tuning ANN using GridSearch","25354171":"# Tuning Models","4448e436":"# Keras ANN","bbd46dc3":"# Summary of Results","1b21c601":"### SMOTE is Synthetic Minority Oversampling Technique - overcoming the overfitting problem and class imbalance problem by generating synthetic minority records by random over-sampling","2929ea60":"\n# Final Tuned ANN Model","a339da16":"# Scatter Plot to see 3 variable variation","af19a3a0":"Clearly the 3 good performing models for Stroke Prediction are as follows:\n1. Random Forest: accuracy: 0.89 , auc: 0.75\n2. XG Boost: accuracy: 0.87 , auc: 0.74\n3. ANN: accuracy: 0.85 , auc: 0.73\n\nSo a tuned Random Forest performed best for this data","6483503d":"# Data Preprocessing","ab3cb0ae":"## Age, hypertension, heartdisease, ever_married, avg_glucose_level are the most correlated","63e6ef1a":"# Random Forest and XGBoost after hyperparmarater tuning","7691b8d3":"## PLOTS TO UNDERSTAND CORRELATIONS","4e47d951":"## Handling Imbalanced Data using SMOTE","14e70c43":"## Feature Scaling\n\n##### StandardScaler does normalization (x-x_bar)\/std_dev --> converts variables into normal dist. with mean 0 and standard dev = 1","f436615e":"## Random Forest","6a49dc73":"## XG Boost with tuning","1d246da2":"# Testing out Baseline Classification Models before Tuning","3c3498db":"According to the graph, all people above glucose level 150 and above BMI 25 are considered as having more risk to Stroke","a89e95a8":"****EDA****","e63c9b58":"#### Hyperparameter C is used to prevent overfitting and provide regularization strength:\n#### For more depth, I refered to this stackoverflow link: https:\/\/stackoverflow.com\/questions\/22851316\/what-is-the-inverse-of-regularization-strength-in-logistic-regression-how-shoul\n\n\n#### var_smoothing in Gaussian Naive Bayes artificially adds a user-defined standard deviation on how many samples to be included near or away from the mean in a gaussian distribution. Link: https:\/\/stackoverflow.com\/questions\/58046129\/can-someone-give-a-good-math-stats-explanation-as-to-what-the-parameter-var-smoo\n\n\n#### cv in grid search means the number of cross validation we have for each set of hyperparameters\n"}}