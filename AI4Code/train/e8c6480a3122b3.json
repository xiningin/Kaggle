{"cell_type":{"e1c7d766":"code","30469efc":"code","832c497d":"code","d10c0a60":"code","fe71ca2d":"code","9fcadc27":"code","97a7c844":"code","f813b177":"code","af72cfcd":"code","009beffa":"code","60714b0f":"code","516ff3ea":"code","3c0f1dd3":"code","9cd0e0e3":"code","50427828":"code","744530da":"code","64ef9840":"code","b040c371":"code","49425fee":"code","d2a2f7d9":"code","95f27598":"code","569ab04d":"code","7cfee9e0":"code","4a0fc990":"code","7766b484":"code","78553921":"markdown","3d158ddd":"markdown","5656770a":"markdown","9248774e":"markdown","b18e7014":"markdown","7371ca49":"markdown"},"source":{"e1c7d766":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","30469efc":"#Extracting the dataset\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","832c497d":"print(\"Number of training samples: \",len(train[\"Survived\"]))\nprint(\"Number of features: \",len(train.columns))\nprint(\"Number of Survivors: \",len(train[train[\"Survived\"]==1]))\nprint(\"Number of Non-Survivors: \",len(train[train[\"Survived\"]==0]))","d10c0a60":"#Visualizing Age feature using histograms\nimport matplotlib.pyplot as plt\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==1][\"Age\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of age')\nplt.text(23, 45,\"Survived = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==0][\"Age\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of age')\nplt.text(23, 75,\"Survived = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","fe71ca2d":"from sklearn.preprocessing import KBinsDiscretizer\n\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\ndiscretizer_age = KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='kmeans')\nage_discretized = discretizer_age.fit_transform(train[[\"Age\"]])\nlen(age_discretized)\ndf_age = pd.DataFrame(age_discretized,columns=['Age'])\ndf_age.info()","9fcadc27":"#Visualizing ticket fare\nimport matplotlib.pyplot as plt\n\nplt.subplot(1,3,1)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==1][\"Fare\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of fare')\nplt.text(23, 45,\"Survived = 1\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()\n\nplt.subplot(1,3,2)\nn, bins, patches = plt.hist(x=train[train[\"Survived\"]==0][\"Fare\"], bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\nplt.title('Visualizing effect of fare')\nplt.text(23, 75,\"Survived = 0\")\nmaxfreq = n.max()\nplt.ylim(ymax=np.ceil(maxfreq \/ 10) * 10 if maxfreq % 10 else maxfreq + 10)\nplt.show()","97a7c844":"#Visualizing Pclass\nimport seaborn as sns\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Pclass\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Pclass\", data=train[train[\"Survived\"]==0])","f813b177":"#Visualizing Sex feature\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Sex\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Sex\", data=train[train[\"Survived\"]==0])","af72cfcd":"#Visualizing Embarked feature\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Embarked\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Embarked\", data=train[train[\"Survived\"]==0])","009beffa":"#Visualizing SibSp(# of siblings or spouses) and parch(# of parents or children)\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"SibSp\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"SibSp\", data=train[train[\"Survived\"]==0])","60714b0f":"#Visualizing Parch(# of parents or siblings)\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Parch\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Parch\", data=train[train[\"Survived\"]==0])","516ff3ea":"#Combining Parch and SibSp and analyzing\n\ntrain[\"SibSpParCh\"] = train[\"SibSp\"] + train[\"Parch\"]\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"SibSpParCh\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"SibSpParCh\", data=train[train[\"Survived\"]==0])","3c0f1dd3":"train[\"Alone\"] = train[\"SibSpParCh\"] > 0","9cd0e0e3":"#Visualizing Alone feature\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Alone\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Alone\", data=train[train[\"Survived\"]==0])","50427828":"#Extracting title from the passenger name\n\ntitle = np.zeros((len(train[\"Name\"]),)).astype(str)\nfor i in range(len(train[\"Name\"])):\n    title[i] = train[\"Name\"][i].split(',')[1].split(' ')[1]\npd_title = pd.DataFrame(title,columns=['Title'])\ntrain = pd.concat([train,pd_title],axis=1)\nprint(train.Title.unique())\n\ntrain[\"Title\"].replace('Ms.','Miss.',inplace=True)\ntrain[\"Title\"].replace(['Don.', 'Rev.', 'Dr.', 'Mme.',  'Major.',\n 'Lady.', 'Sir.', 'Mlle.', 'Col.', 'Capt.', 'the', 'Jonkheer.'],'Other',inplace=True)\nprint(train.Title.unique())\ntrain[\"Title\"]\n\n#Visualizing\n\nplt.subplot(1,2,1)\nplt.title('Survived=1')\nax1 = sns.countplot(x=\"Title\", data=train[train[\"Survived\"]==1])\n\nplt.subplot(1,2,2)\nplt.title('Survived=0')\nax2 = sns.countplot(x=\"Title\", data=train[train[\"Survived\"]==0])","744530da":"#Encoding the categoircal features\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncategorical_cols = [\"Embarked\",\"Sex\",\"Alone\",\"Title\"]\ntrain[categorical_cols] = train[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\ntrain.head()","64ef9840":"features = [\"Pclass\",\"Embarked\",\"Sex\",\"Alone\",\"Fare\",\"Title\"]\nX_train = train[features]\nX_train = pd.concat([X_train,df_age],axis=1)\nY_train = train[\"Survived\"]\nX_train.info()\nX_train\n#np.any(np.isnan(X_train[\"Age\"]))","b040c371":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nss = StandardScaler()\nX_train_scaled = ss.fit_transform(X_train)\n\nsvm = SVC(C=1,kernel='rbf')\ngb = GradientBoostingClassifier(loss='exponential')\nlr = LogisticRegression()\ndecision_tree = DecisionTreeClassifier()\nrandom_forest = RandomForestClassifier(n_estimators=100)\nresult = cross_validate(gb,X_train_scaled,Y_train,scoring = ('accuracy','f1'), cv = 3, return_train_score=True)\n\nprint(\"Train Accuracy Score: \",result[\"train_accuracy\"].mean())\nprint(\"Test Accuracy Score: \",result[\"test_accuracy\"].mean())\nprint(\"Train F1 Score: \",result[\"train_f1\"].mean())\nprint(\"Test F1 Score: \",result[\"test_f1\"].mean())","49425fee":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","d2a2f7d9":"test[\"SibSpParCh\"] = test[\"SibSp\"] + test[\"Parch\"]\ntest[\"Alone\"] = test[\"SibSpParCh\"] > 0","95f27598":"title = np.zeros((len(test[\"Name\"]),)).astype(str)\nfor i in range(len(test[\"Name\"])):\n    title[i] = test[\"Name\"][i].split(',')[1].split(' ')[1]\npd_title = pd.DataFrame(title,columns=['Title'])\ntest = pd.concat([test,pd_title],axis=1)\nprint(test.Title.unique())\n\ntest[\"Title\"].replace('Ms.','Miss.',inplace=True)\ntest[\"Title\"].replace(['Col.' ,'Rev.', 'Dr.', 'Dona.'],'Other',inplace=True)\nprint(test.Title.unique())\ntest[\"Title\"]","569ab04d":"test[categorical_cols] = test[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\ntest.head(50)","7cfee9e0":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].mean())\nX_test = test[features]\nage_discretized = discretizer_age.transform(test[[\"Age\"]])\nlen(age_discretized)\ndf_age = pd.DataFrame(age_discretized,columns=['Age'])\nX_test = pd.concat([X_test,df_age],axis=1)\nX_test.info()","4a0fc990":"X_test_scaled = ss.transform(X_test)\nmodel = SVC(C=1.0,kernel='rbf').fit(X_train_scaled,Y_train)\nY_predict = model.predict(X_test_scaled)","7766b484":"submission_df = pd.DataFrame({'PassengerId' : test[\"PassengerId\"],'Survived' : Y_predict})\nsubmission = submission_df.to_csv('submission.csv',index=False)","78553921":"We can deduce that passengers having more than 4 siblings or spouses didn't survive. ","3d158ddd":"Most of the passengers embarked from port S. ","5656770a":"We can see that Alone passengers were more likely to survive than others.","9248774e":"We can see that more people in Pclass 1 and 2 survived than people in Pclass 3. Hence Pclass can be used for classification between survivors and non-survivors.","b18e7014":"Parch and SibSp does not give much information of survival or non-survival, but we can use it to find other features like if the passenger was alone or not. ","7371ca49":"Sex is an important categorical feature because more of female survived than male."}}