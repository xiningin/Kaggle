{"cell_type":{"cec113d4":"code","2337df4d":"code","b06419a8":"code","8e6c3a7a":"code","0a8c2da0":"code","9f2a30a6":"code","961b62dc":"code","243ae903":"code","1ad5427a":"code","54fc4269":"code","53bf4583":"code","1fb3ce2c":"code","262f21b7":"code","2a66ecef":"code","92474cce":"code","d4dbec46":"code","c2b06b58":"code","e97d8f8e":"code","9d699847":"code","dd9862ad":"code","a94a8167":"code","833e7fd4":"code","2b6c834a":"code","73422357":"code","765c8950":"code","d62d50a6":"code","67f040ee":"code","a450bbe8":"code","07d9ed9f":"code","dc66507b":"code","79a37f0f":"code","739e54c1":"code","af4c6e25":"code","a5988a84":"code","a83c0439":"code","057b9d0b":"markdown","f0b8be39":"markdown","e77a29b9":"markdown","fe7f9644":"markdown","57dbc392":"markdown","3bf8b64d":"markdown","79a7f3d4":"markdown","7168582e":"markdown","1adc40ae":"markdown","a8dbba28":"markdown","33e21655":"markdown","a4c04f39":"markdown","41b7fab4":"markdown","29492e7f":"markdown","4401c8ec":"markdown","7817e3b6":"markdown","8e288866":"markdown","40efbae2":"markdown","e9b58c02":"markdown"},"source":{"cec113d4":"# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","2337df4d":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np","b06419a8":"(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()","8e6c3a7a":"len(X_train)","0a8c2da0":"X_train[0].shape","9f2a30a6":"X_train[0]","961b62dc":"plt.matshow(X_train[0])","243ae903":"y_train[0]","1ad5427a":"X_train.shape\n# 60000 --> Is the Number of Samples.\n# 28 & 28 --> are each individual image.","54fc4269":"# Flatten the array. Keeping the no. of samples as is.\nX_train_flattened = X_train.reshape(len(X_train), 28*28)","53bf4583":"X_train_flattened.shape","1fb3ce2c":"X_train_flattened[0]","262f21b7":"# Doing the same for test dataset.\nX_test_flattened = X_test.reshape(len(X_test), 28*28)\nX_test_flattened.shape","2a66ecef":"model = keras.Sequential([\n    keras.layers.Dense(10, input_shape = (784,), activation = 'sigmoid')\n])\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nmodel.fit(X_train_flattened, y_train, epochs = 5)","92474cce":"# Scaled\nX_train_scaled = X_train \/ 255\nX_test_scaled = X_test \/ 255","d4dbec46":"X_train_scaled[0]\n# See the data not.. it will range from 0 to 1.","c2b06b58":"# Flatten the array. Keeping the no. of samples as is.\nX_train_scaled_flattened = X_train_scaled.reshape(len(X_train_scaled), 28*28)\nX_test_scaled_flattened  = X_test_scaled.reshape(len(X_test_scaled), 28*28)","e97d8f8e":"model.fit(X_train_scaled_flattened, y_train, epochs = 5)","9d699847":"# Evaluate the model\nmodel.evaluate(X_test_scaled_flattened, y_test)","dd9862ad":"plt.matshow(X_test[0])","a94a8167":"# Sample Prediction\ny_pred = model.predict(X_test_scaled_flattened)\ny_pred[0] # to get the predicted value of first array.","833e7fd4":"# Now get the max out of the array.\nnp.argmax(y_pred[0])","2b6c834a":"plt.matshow(X_test[1])","73422357":"print(y_pred[1])\nprint('-'*10)\nprint(np.argmax(y_pred[1]))","765c8950":"# Lets get the labels for all predcited values.\ny_pred_labels = [np.argmax(i) for i in y_pred]\ny_pred_labels[:5]","d62d50a6":"# Confursion Matrix.\n# Note, in below confusion matrix, we cannot direeclty pass y_pred in predictions, as y_pred is not real labels, where as y_test are representing real labels. Thus we have created y_pred_labels. \ncm = tf.math.confusion_matrix(labels = y_test, predictions = y_pred_labels)\ncm","67f040ee":"# Visualize the COnfusion Matrix.\nimport seaborn as sn\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot= True, fmt ='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","a450bbe8":"model = keras.Sequential([\n    keras.layers.Dense(100, input_shape = (784,), activation = 'relu'),\n    keras.layers.Dense(10, activation = 'sigmoid')\n])\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)\n","07d9ed9f":"model.fit(X_train_scaled_flattened, y_train, epochs = 5)","dc66507b":"# Evaluate the model\nmodel.evaluate(X_test_scaled_flattened, y_test)","79a37f0f":"# Sample Prediction\ny_pred_1_Layer = model.predict(X_test_scaled_flattened)\n\n# Lets get the labels for all predcited values.\ny_pred_1_Layer_labels = [np.argmax(i) for i in y_pred_1_Layer]\n# y_pred_1_Layer_labels[:5]\n\n# Confursion Matrix.\ncm_1_layer = tf.math.confusion_matrix(labels = y_test, predictions = y_pred_1_Layer_labels)\n\n#Visualize \nplt.figure(figsize = (10,7))\nsn.heatmap(cm_1_layer, annot= True, fmt ='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","739e54c1":"model_flatten = keras.Sequential([\n    keras.layers.Flatten(input_shape = (28,28)),\n    keras.layers.Dense(100, activation = 'relu'),\n    keras.layers.Dense(10, activation = 'sigmoid')\n])\n\nmodel_flatten.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)","af4c6e25":"model_flatten.fit(X_train_scaled, y_train, epochs = 5)","a5988a84":"# Evaluate the model\nmodel_flatten.evaluate(X_test_scaled, y_test)","a83c0439":"# Sample Prediction\ny_pred_f_Layer = model_flatten.predict(X_test_scaled)\n\n# Lets get the labels for all predcited values.\ny_pred_f_Layer_labels = [np.argmax(i) for i in y_pred_f_Layer]\n# y_pred_f_Layer_labels[:5]\n\n# Confursion Matrix.\ncm_f_layer = tf.math.confusion_matrix(labels = y_test, predictions = y_pred_f_Layer_labels)\n\n#Visualize \nplt.figure(figsize = (10,7))\nsn.heatmap(cm_f_layer, annot= True, fmt ='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","057b9d0b":"# Model - without any Hidden Layer - Scaled Data Set","f0b8be39":"# Model - without any Hidden Layer","e77a29b9":"Cool.. so our model predicted it as 7, which is correct.","fe7f9644":"Perfect... predicted 2 as expected.","57dbc392":"# Keras Flatten\nWe can use keras flatten... instead of flatten it manually.","3bf8b64d":"# Model - with one Hidden Layer","79a7f3d4":"Just now we have model our training dataset without layers.\nNot lets add some hidden layer.","7168582e":"Always remember to pass scaled dataset to the model.","1adc40ae":"`Sequential` is one of the model in Tensorflow, sequential meaning you simply stack layers one by one, sequentially.\n\nIn a sequential model, we stack layers sequentially. So, each layer has unique input and output, and those inputs and outputs then also come with a unique input shape and output shape.\n\nsequential is just a tensorflow class that allows you to define linear stack of neural network layers\n\n`Dense` layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output.\n\nA dense layer is just a regular layer of neurons in a neural network. Each neuron recieves input from all the neurons in the previous layer, thus densely connected. The layer has a weight matrix W, a bias vector b, and the activations of previous layer a. \n\n![image.png](attachment:image.png)\n","a8dbba28":"Observe the loss and accuracy now.\n","33e21655":"# DataSet","a4c04f39":"From this we say that our model is 0.9696 (96%) accurate with one hidden layer.\n\nWhere without any hiden layer the accuracy on test data set was 92%.\n","41b7fab4":"# Flatten the dataset using reshape","29492e7f":"# Model","4401c8ec":"# Import Library","7817e3b6":"What is tensor?\n\nIn the general case, an array of numbers arranged on a regular grid with a variable number of axes is know as a tensor","8e288866":"We see that the Loss is high and accuracy is low.\nOne of the root cuase for this is that our input data is not scaled.\nSo lets scale the data and do the activity again.","40efbae2":"![image.png](attachment:image.png)\nHere we are adding one Hidden Layer. For hiden layer we first define the number of neurons, so lets start with 100. There are some guidelines, which will see later. In Activation function lets use `relu` and output layer will be similar as before, except the input_shape as we already provided the input shape in first layer.","e9b58c02":"In realtime scenario , where it will use handwritten digits verification .. any example ?\n\nIn realtime scenario here in USA, USPS(postal service) uses it for handwritten address recognition. So they parse the address and feed into computer using this concept.\nif the classification score or confidence is less than certain threshold they will send it for human verification"}}