{"cell_type":{"748cb215":"code","ad438310":"code","8f9ac8a6":"code","1b8cf07a":"code","b3ce44e4":"code","3404b55e":"code","3ff2c0da":"code","b6395b0d":"code","12ba802d":"code","f9639ab2":"code","b1837de6":"code","1b5edd5f":"markdown","cf6b2997":"markdown","8afee8c9":"markdown","8e8a8ad4":"markdown","deea0372":"markdown","8c2870b5":"markdown","6d19eddd":"markdown","57ecafd4":"markdown","d85a8fac":"markdown","b633a271":"markdown"},"source":{"748cb215":"!pip install pytorch-tabnet","ad438310":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8f9ac8a6":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score,classification_report\nfrom catboost import CatBoostClassifier,CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\nfrom sklearn.model_selection import cross_val_predict\n\nimport itertools\nfrom tqdm import tqdm_notebook\nimport gc\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nimport lightgbm as lgb\n\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport torch\nimport warnings\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor","1b8cf07a":"data = pd.read_csv('\/kaggle\/input\/mf-accelerator\/contest_train.csv')\ntarget = data.TARGET\ndata = data.fillna(0)","b3ce44e4":"features = data.drop(columns=[\"TARGET\",\"ID\"])\nfeatures.head()","3404b55e":"data_test = pd.read_csv('\/kaggle\/input\/mf-accelerator\/contest_test.csv')\nfeatures_test = data_test.copy().drop(columns=[\"ID\"])\nfeatures_test.head()","3ff2c0da":"features_train,features_val,labels_train,labels_val = train_test_split(features,target, test_size = 0.3,\\\n                                                                   shuffle=True,random_state=1,\\\n                                                                   stratify = target)\nfeatures_train.head()","b6395b0d":"class Stacking(BaseEstimator, ClassifierMixin):  \n    \"\"\"\u0421\u0442\u0435\u043a\u0438\u043d\u0433 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \n    \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u043e\u0432 \u0410. \u0414\u044c\u044f\u043a\u043e\u043d\u043e\u0432\u0430\n    \"\"\"\n    \n\n    def __init__(self, models, metamodel,merge=False):\n        \"\"\"\n        \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f\n        models - \u0431\u0430\u0437\u043e\u0432\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043b\u044f \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430\n        metamodel - \u043c\u0435\u0442\u0430\u043c\u043e\u0434\u0435\u043b\u044c\n        \"\"\"\n        self.models = models\n        self.metamodel = metamodel\n        self.n = len(models)\n        self.meta = None\n        self.merge = merge\n\n\n    def fit(self, X, y=None, p=0.25, random_state=0):\n        \"\"\"\n        \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430\n\n        p - \u0432 \u043a\u0430\u043a\u043e\u043c \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0438 \u0434\u0435\u043b\u0438\u0442\u044c \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \n        \u043d\u0430 \u043f\u043e\u0434\u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0434\u043b\u044f \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0438 \u043c\u0435\u0442\u0430\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\n        random_state - \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\n        merge - \u0441\u043b\u0438\u0442\u044c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u043f\u0440\u0438 \u0440\u0430\u0431\u043e\u0442\u0435 \u043c\u0435\u0442\u0430\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430    \n        \"\"\"\n        # \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0438 \u043c\u0435\u0442\u0430\u043c\u043e\u0434\u0435\u043b\u0438\n        base, meta, y_base, y_meta = train_test_split(X, y, test_size=p, random_state=random_state,stratify = y)\n            \n        # \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0430\u043c\u043e\u0434\u0435\u043b\u0438\n        self.meta = np.zeros((meta.shape[0], self.n))\n        for t, base_model in enumerate(self.models):\n            base_model.fit(np.array(base), np.array(y_base))\n                \n            self.meta[:, t] = base_model.predict(meta).reshape((1,-1))#reshape \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0435\u0439 \u0438 \u043a\u0430\u0442\u0431\u0443\u0441\u0442\u0430\n            print(f\"Ok {t}\")\n\n        # \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u0430\u043c\u043e\u0434\u0435\u043b\u0438\n        if self.merge:#\u0435\u0441\u043b\u0438 \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u0435\u0442\u0430\u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u0441 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438 \u0438 \u043d\u043e\u0432\u044b\u043c\u0438\n            data_meta_ext = np.concatenate((meta,self.meta),axis=1)\n            self.metamodel.fit(data_meta_ext, y_meta)\n        else:\n            self.metamodel.fit(self.meta, y_meta)\n        print(\"------\")\n        print(\"Ok\")\n\n\n        return self\n    \n\n\n    def predict(self, X, y=None):\n        \"\"\"\n        \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u043e\u043c\n        \"\"\"\n        # \u0437\u0430\u043f\u043e\u043b\u0435\u043d\u0438\u0435 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f \u043c\u0435\u0442\u0430-\u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0430\n        X_meta = np.zeros((X.shape[0], self.n))\n        \n        print(\"------\")\n        print(\"Prediction\")  \n\n\n\n        for t, base_model in enumerate(self.models):\n            \n            X_meta[:, t] = base_model.predict(X).reshape((1,-1))\n          \n            print(f\"Ok{t}\")  \n          \n\n        if self.merge:#\u0435\u0441\u043b\u0438 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u043d\u0430\u044f \u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0430\u043c\u043e\u0434\u0435\u043b\u0438\n            data_meta_test = np.concatenate((X,X_meta),axis=1)\n            res = self.metamodel.predict(data_meta_test)\n\n        else:\n            res = self.metamodel.predict(X_meta)\n        \n        return (res)","12ba802d":"class NNWrapper(BaseEstimator, ClassifierMixin):  \n    \"\"\"\u041e\u0431\u0435\u0440\u0442\u043a\u0430 \u0434\u043b\u044f \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0435\u0439 \u0434\u043b\u044f \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u043e\u0441\u0442\u0438 \u0441\u043e \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u043e\u043c\"\"\"\n\n    def __init__(self, model,scaler,X_valid=None,\n                 y_valid=None,max_epochs=10, patience=150):\n        \n        self.model = model\n        self.X_valid = X_valid\n        self.y_valid = y_valid\n        self.max_epochs = max_epochs\n        self.patience = patience\n        self.scaler = scaler\n\n    def fit(self, X, y=None):\n        X_sc = self.scaler.fit_transform(X)\n        self.model.fit(X_train=np.array(X_sc), y_train=np.array(y), X_valid=self.X_valid,y_valid=self.y_valid,\n                  max_epochs=self.max_epochs, patience=self.patience) \n\n        return self\n\n    def predict(self, X_test, y=None):\n        X_test_sc = self.scaler.transform(np.array(X_test))\n        prediction = self.model.predict(np.array(X_test_sc)).reshape((1,-1))#\u041a\u043b\u044e\u0447\u0435\u0432\u0430\u044f \u0441\u0442\u0440\u043e\u043a\u0430\n        \n        \n        return prediction\n\nclass LMWrapper(BaseEstimator, ClassifierMixin):  \n    \"\"\"\u041e\u0431\u0435\u0440\u0442\u043a\u0430 \u0434\u043b\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0445 \u0438 \u0438\u043d\u044b\u0445 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \n    \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"\"\"\n\n    def __init__(self, model,scaler):\n        \n        self.model = model\n        self.scaler = scaler\n        \n    def fit(self, X, y=None):\n        \n        X_sc = self.scaler.fit_transform(X)\n        self.model.fit(X_sc, y) \n\n        return self\n\n    def predict(self, X_test, y=None):\n        X_test_sc = self.scaler.transform(X_test)\n        prediction = self.model.predict(X_test_sc)\n        \n        \n        return prediction","f9639ab2":"ls0 = Lasso(alpha=0.01,random_state=0)\nknn1 = LMWrapper(KNeighborsRegressor(n_neighbors=3,),StandardScaler())\nknn2 = LMWrapper(KNeighborsRegressor(n_neighbors=10),StandardScaler())\nrf2 = RandomForestRegressor(n_estimators=100, max_depth=10,random_state=100)\ngbm1 = lgb.LGBMRegressor(boosting_type='gbdt', learning_rate=0.05, max_depth=7, n_estimators=200, nthread=-1,\n                        objective='regression',random_state=0) \ncb_reg1 = CatBoostRegressor(task_type='GPU',random_state=0,\n                             iterations=1000,verbose=False)\nreg_tabnet = NNWrapper(TabNetRegressor(verbose=0,seed=0),StandardScaler(),max_epochs=100, patience=150,\n                       X_valid=np.array(features_val), y_valid = np.array(labels_val).reshape(-1, 1))\nclf_cb_1 = CatBoostClassifier(task_type='GPU',random_state=0, loss_function='MultiClass',\n                                auto_class_weights=\"Balanced\",iterations=1000,verbose=False)\nclf_lr = LMWrapper(LogisticRegression(multi_class=\"multinomial\",class_weight=\"balanced\",\n                                        C=1e-1,max_iter=300,random_state=0),StandardScaler())\nclf_nb1 =  BernoulliNB(alpha=1,binarize=0.3)","b1837de6":"%%time\nwarnings.filterwarnings(\"ignore\")\nmodels = [ls0,knn1, knn2,rf2,gbm1,cb_reg1,\n           reg_tabnet,clf_cb_1,clf_nb1,clf_lr]\n\nmeta_model = CatBoostClassifier(task_type='GPU',random_state=0, loss_function='MultiClassOneVsAll',\n                                auto_class_weights=\"Balanced\",iterations=1000,verbose=False)\n\nstack = Stacking(models, meta_model,merge=True)\nstack.fit(features_train,np.array(labels_train).reshape(-1, 1),p=0.2,random_state=0)# \u0441\u043b\u043e\u0436\u043d\u043e \u0438\u0437-\u0437\u0430 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438\npreds = stack.predict(features_val)\nprint(classification_report(labels_val,preds))\nprint(\"------\")\nprint(f\"Macro f1 score: {f1_score(labels_val,preds,average='macro')}\")","1b5edd5f":"\u0420\u0430\u0431\u043e\u0442\u0430 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430, \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 \u0432\u044b\u0431\u043e\u0440\u043a\u0438. \u0412\u0430\u0436\u043d\u043e \u043e\u0442\u043c\u0435\u0442\u0438\u0442\u044c, \u0447\u0442\u043e \u0437\u0434\u0435\u0441\u044c \u044f \u043e\u0431\u0443\u0447\u0430\u044e \u043c\u0435\u0442\u0430\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043d\u0430 \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435, \u0442\u043e \u0435\u0441\u0442\u044c \u0441\u043a\u043b\u0435\u0438\u0432\u0430\u044e \u0438\u0441\u0445\u043e\u0434\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0438 \u043d\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438, \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432. \u0415\u0441\u043b\u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043d\u0430 \u043a\u043b\u0430\u0441\u0441 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430, \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0439 \u0432\u044b\u0448\u0435, \u043c\u043e\u0436\u043d\u043e \u0437\u0430\u043c\u0435\u0442\u0438\u0442\u044c \u0433\u043b\u0430\u0432\u043d\u0443\u044e \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0434\u0430\u043d\u043d\u043e\u0439 \u0441\u0445\u0435\u043c\u044b - \u043c\u0435\u0442\u0430\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043e\u0431\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u043d\u0430 \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043b\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432. ","cf6b2997":"\u041c\u043e\u0439 \u0438\u0442\u043e\u0433\u043e\u0432\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u043c \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u044f 2-\u0445 \u0442\u0430\u043a\u0438\u0445 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u043e\u0432 (\u0432\u043e \u0432\u0442\u043e\u0440\u043e\u043c \u043c\u043e\u0434\u0435\u043b\u0435\u0439 15 \u0438 \u043e\u043d\u0438 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u0436\u043d\u0435\u0435) \u0438 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u043f\u043e\u043f\u044b\u0442\u043e\u043a CatBoost. \u041f\u0440\u043e \u043f\u043e\u0434\u0431\u043e\u0440 CatBoost \u043d\u0430 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0441\u0434\u0435\u043b\u0430\u044e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u043d\u043e\u0443\u0442\u0431\u0443\u043a. \u0412\u0441\u0435\u043c \u0443\u0434\u0430\u0447\u0438!","8afee8c9":"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438","8e8a8ad4":"\u0417\u0430\u0434\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0431\u0443\u0434\u0443\u0442 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u0434\u043b\u044f \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430. \u041e\u0431\u0440\u0430\u0442\u0438\u0442\u0435 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435, \u0447\u0442\u043e, \u043d\u0435\u0441\u043c\u043e\u0442\u0440\u044f \u043d\u0430 \u0437\u0430\u0434\u0430\u0447\u0443 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438, \u0441\u0440\u0435\u0434\u0438 \u0431\u0430\u0437\u043e\u0432\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043c\u043d\u043e\u0433\u043e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u043e\u0440\u043e\u0432, \u0442\u0430\u043a \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0431\u043e\u043b\u0435\u0435 \u0440\u0430\u0437\u043d\u043e\u043e\u0431\u0440\u0430\u0437\u043d\u044b\u0435 \u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435 \u043c\u0435\u0442\u0430\u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438.","deea0372":"**\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438:**\n\nPublic score: **0.52940**\n\nPrivate score: **0.54105**","8c2870b5":"\u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0435 \u044f \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u043b \u0441\u043e\u0431\u0440\u0430\u0442\u044c \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u0440\u0430\u0431\u043e\u0447\u0438\u0435 \u043c\u043e\u043c\u0435\u043d\u0442\u044b, \u043a\u0430\u0441\u0430\u044e\u0449\u0438\u0435\u0441\u044f \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043c\u043e\u0433\u043b\u0438 \u043c\u043d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0445\u043e\u0440\u043e\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043d\u0430 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438. \u041e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430 \u0432 \u0435\u0433\u043e \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u043e\u0441\u0442\u0438 \u043a\u0430\u043a \u043a \u0438\u0437\u043c\u0435\u043d\u0447\u0438\u0432\u043e\u0441\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0445, \u0442\u0430\u043a \u0438 \u043a \u0441\u043b\u0430\u0431\u044b\u043c \u043c\u0435\u0441\u0442\u0430\u043c \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432. \u0412 \u0441\u0432\u044f\u0437\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0430 \u0440\u0430\u0437\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u0441\u0442\u0435\u043a\u0438\u043d\u0433 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0441\u0435\u0431\u044f \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u044b\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u043c. \u0415\u0441\u043b\u0438 \u0433\u0434\u0435-\u0442\u043e \u0435\u0441\u0442\u044c \u043d\u0435\u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0432 \u043a\u043e\u0434\u0435, \u043d\u0435 \u0441\u0443\u0434\u0438\u0442\u0435 \u0441\u0442\u0440\u043e\u0433\u043e, \u043f\u043e\u0442\u043e\u043c\u0443 \u0447\u0442\u043e \u043e\u0444\u043e\u0440\u043c\u043b\u044f\u043b \u043d\u043e\u0443\u0442\u0431\u0443\u043a \u0432\u043f\u043e\u043f\u044b\u0445\u0430\u0445, \u043f\u043e\u0441\u043a\u043e\u043b\u044c\u043a\u0443 \u043f\u0440\u0438\u0448\u043b\u043e\u0441\u044c \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0438\u0442\u044c \u0438\u0437 Google Colab \u0438 \u043d\u0430\u0432\u043e\u0434\u0438\u0442\u044c \u043a\u0440\u0430\u0441\u043e\u0442\u0443.","6d19eddd":"# \u0420\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0440\u0430\u0431\u043e\u0447\u0435\u0433\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430 \u043f\u043e \u0441\u0445\u0435\u043c\u0435 1 \n(\u043f\u043e \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c \u0410. \u0414\u044c\u044f\u043a\u043e\u043d\u043e\u0432\u0430)\n\n\u0420\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0430\u043b \u0413\u043b\u0430\u0437\u0443\u043d\u043e\u0432 \u0410.\u0412.","57ecafd4":"\u041d\u0430\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441\u0442\u0435\u043a\u0438\u043d\u0433\u0430","d85a8fac":"\u0412\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0432\u044b\u0441\u043e\u043a\u043e\u0435, \u043d\u043e \u044f \u043f\u043e\u0434\u0431\u0438\u0440\u0430\u043b \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438, \u0447\u0442\u043e \u043f\u043e\u0442\u0440\u0435\u0431\u043e\u0432\u0430\u043b\u043e \u0433\u043e\u0440\u0430\u0437\u0434\u043e \u0431\u043e\u043b\u044c\u0448\u0435\u0433\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u043d\u043e \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u043b\u043e \u043e\u0446\u0435\u043d\u0438\u0442\u044c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0438 \u0435\u0435 \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u044e.\n\n\u0421\u0440\u0435\u0434\u043d\u0435\u0435 \u0431\u044b\u043b\u043e \u043e\u043a\u043e\u043b\u043e 0.538,min \u043e\u043a\u043e\u043b\u043e 0.525,max \u043e\u043a\u043e\u043b\u043e 0.545. (\u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e \u043f\u0440\u043e\u0432\u043e\u0434\u0438\u043b \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432\u0441\u0435 \u043f\u043e\u043f\u044b\u0442\u043a\u0438 \u043d\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0441\u044c:(, \u043f\u0438\u0448\u0443 \u0447\u0442\u043e \u0432\u0441\u043f\u043e\u043c\u043d\u0438\u043b)","b633a271":"\u041d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0435\u0432\u0430\u044f \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0434\u043b\u044f \u0442\u0430\u0431\u043b\u0438\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0435 \u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0435\u0440\u043e\u0432."}}