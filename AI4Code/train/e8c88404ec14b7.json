{"cell_type":{"96c9ba76":"code","7cb8229e":"code","34837c15":"code","c26dc5e6":"code","9dd9bcbe":"code","90734311":"code","cbeeeb07":"code","a66b3fca":"code","3298d399":"code","150e5ca0":"code","83e31e02":"code","6c78b601":"code","3042e98e":"code","c00e2ac6":"code","34188f71":"code","ffb32a51":"code","ef8bc507":"code","0884b0be":"code","4adf4fec":"code","e6c266db":"code","6c67310b":"code","9665e1d1":"code","4650886f":"code","c581b9f3":"code","e7267439":"code","32b6cace":"code","6745e683":"code","5c791bf2":"code","af6eb506":"code","7f3bb683":"code","823ed85d":"code","3698716f":"code","3f35a763":"code","da6b458b":"code","c330fb13":"code","b1263998":"code","bbda6002":"code","b77e99b2":"code","6cff6931":"code","488455bf":"code","54ad5959":"code","3bae8398":"code","606050db":"code","afcfcfee":"code","0632991a":"code","9528ec4d":"code","e918e067":"code","a505cf99":"code","35ba7e00":"code","991c7b83":"code","8d12b345":"code","17eb568b":"code","1d82808a":"code","50b6ae36":"code","e11519d5":"code","31d9e103":"code","204fc726":"code","9244fa7d":"code","11a19306":"code","5f9ad8fc":"markdown","cf35f4a5":"markdown","43b799b6":"markdown","fe0b5f2b":"markdown","2647c6e9":"markdown","56fb5680":"markdown","e48d7ced":"markdown","d02bf098":"markdown","2a3c33af":"markdown","37e0abd5":"markdown","f82471ce":"markdown","628ccf59":"markdown","3fef22c3":"markdown","026139c1":"markdown","443de50c":"markdown","a86a7cdb":"markdown","a6751159":"markdown","d1429645":"markdown","d71dd9fe":"markdown","90399922":"markdown","337a20bb":"markdown","b08895b8":"markdown","3ba6e3d9":"markdown","b483bc32":"markdown","f4737eaf":"markdown","1659d003":"markdown","dd9cc86b":"markdown","5d591893":"markdown","447b9f82":"markdown","4a4791d5":"markdown","faa52cd8":"markdown","1d19812e":"markdown","d13de3bf":"markdown","99bf6f88":"markdown","8a6cda47":"markdown","4b5e9ef1":"markdown","a9c34b8b":"markdown","04d910be":"markdown","111dcbc9":"markdown","bce49d43":"markdown","ac3d3c68":"markdown","238dce41":"markdown","80a89d0d":"markdown","5e060ed3":"markdown","7a77041b":"markdown"},"source":{"96c9ba76":"import numpy as np          # linear algebra\nimport pandas as pd         # data processing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport warnings; warnings.simplefilter('ignore')","7cb8229e":"book_data = pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX_Books.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\nbook_data.head()","34837c15":"book_data[book_data['ISBN']== \"078946697X\"]","c26dc5e6":"book_data.shape","9dd9bcbe":"user_data= pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX-Users.csv', sep= ';', encoding= 'latin-1')\nuser_data.head()","90734311":"rating_data= pd.read_csv('..\/input\/bookcrossing-dataset\/Book reviews\/BX-Book-Ratings.csv', sep= ';', encoding= 'latin-1')\nrating_data.head()","cbeeeb07":"book_data.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis= 1, inplace= True)\nbook_data.columns= book_data.columns.str.strip().str.lower().str.replace('-', '_')\nuser_data.columns= user_data.columns.str.strip().str.lower().str.replace('-', '_')\nrating_data.columns= rating_data.columns.str.strip().str.lower().str.replace('-', '_')","a66b3fca":"pd.set_option('display.max_colwidth', -1)","3298d399":"print(book_data.dtypes)\nprint('-'*40)\nprint(book_data.isnull().sum())","150e5ca0":"book_data.loc[(book_data['book_author'].isnull()),: ]","83e31e02":"book_data.loc[(book_data['isbn'] == '9627982032'),'book_author'] = 'other'","6c78b601":"book_data['year_of_publication'].unique()","3042e98e":"# def replace_df_value(df, idx, col_name, val):\n#     df.loc[idx, col_name] = val\n\n\n# replace_df_value(book_data, 209538, 'book_title', 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)')\n# replace_df_value(book_data, 209538, 'book_author', 'Michael Teitelbaum')\n# replace_df_value(book_data, 209538, 'year_of_publication', 2000)\n# replace_df_value(book_data, 209538, 'publisher', 'DK Publishing Inc')\n\n# replace_df_value(book_data, 221678, 'book_title', 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)')\n# replace_df_value(book_data, 221678, 'book_author', 'James Buckley')\n# replace_df_value(book_data, 221678, 'year_of_publication', 2000)\n# replace_df_value(book_data, 221678, 'publisher', 'DK Publishing Inc')\n\n# replace_df_value(book_data, 220731,'book_title', \"Peuple du ciel, suivi de 'Les Bergers\")\n# replace_df_value(book_data, 220731, 'book_author', 'Jean-Marie Gustave Le Cl\u00c3?\u00c2\u00a9zio')\n# replace_df_value(book_data, 220731, 'year_of_publication', 2003)\n# replace_df_value(book_data, 220731, 'publisher', 'Gallimard')","c00e2ac6":"book_data.loc[(book_data['publisher'].isnull()),'publisher'] = 'no mention'","34188f71":"print(book_data['publisher'].isnull().sum())","ffb32a51":"print(user_data.shape)","ef8bc507":"user_data['user_id'].unique()","0884b0be":"user_data['age'].unique()","4adf4fec":"user_data.loc[(user_data['age'] > 90) | (user_data['age'] < 5)] = np.nan\nuser_data['age'].fillna((user_data['age'].mean()), inplace=True)\nuser_data['age']= user_data['age'].astype('int64')\nuser_data['age'].unique()","e6c266db":"rating_data.head()","6c67310b":"unique_ratings = rating_data[rating_data.isbn.isin(book_data.isbn)]","9665e1d1":"rating_data = rating_data[rating_data.user_id.isin(user_data.user_id)]","4650886f":"print(rating_data.shape)\nprint(unique_ratings.shape)\nprint(book_data.shape)\nprint(user_data.shape)","c581b9f3":"unique_ratings['book_rating'].unique()","e7267439":"user_data.age.hist(bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\nplt.title('Age Distribution\\n')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.savefig('age_dist.png', bbox_inches='tight')\nplt.show()","32b6cace":"sns.set_style('darkgrid')\nsns.countplot(data= unique_ratings , x='book_rating')\nplt.show()","6745e683":"ratings_explicit= unique_ratings[unique_ratings['book_rating'] != 0]\nratings_implicit= unique_ratings[unique_ratings['book_rating'] == 0]","5c791bf2":"sns.set_style('darkgrid')\nsns.countplot(data= ratings_explicit , x='book_rating')\nplt.show()","af6eb506":"# book_data.year_of_publication = pd.to_numeric(book_data.year_of_publication, errors='coerce')\n\n# # Check for 0's or NaNs in Year of Publication\n# zero_year = book_data[book_data.year_of_publication == 0].year_of_publication.count()\n# nan_year = book_data.year_of_publication.isnull().sum()\n\n# print(f'There are {zero_year} entries as \\'0\\', and {nan_year} NaN entries in the Year of Publication field')\n\n# # Replace all years of zero with NaN\n# book_data.year_of_publication.replace(0, np.nan, inplace=True)","7f3bb683":"import plotly.express as px\n\nfig = px.histogram(book_data, x = \"year_of_publication\", nbins = 30, width = 800, height = 500)\nfig.update_xaxes(tick0 = 0 , dtick = 1000)\nfig.show()","823ed85d":"ratings_explicit.head()","3698716f":"print(unique_ratings.shape)\nprint(ratings_explicit.shape)","3f35a763":"new_book_df= pd.merge(book_data, ratings_explicit, on='isbn')\nnew_book_df.head()","da6b458b":"print(new_book_df.shape)","c330fb13":"new_book_df['book_title'].nunique()","b1263998":"top_ten_books= pd.DataFrame(new_book_df.groupby('book_title')['book_rating'].count()\n                         .sort_values(ascending=False).head(10))\n\nprint('The top ten books recommendation : ')\ntop_ten_books","bbda6002":"from sklearn import model_selection\ntrain_data, test_data = model_selection.train_test_split(new_book_df, test_size=0.20)","b77e99b2":"print(f'Training set lengths: {len(train_data)}')\nprint(f'Testing set lengths: {len(test_data)}')\nprint(f'Test set is {(len(test_data)\/(len(train_data)+len(test_data))*100):.0f}% of the full dataset.')","6cff6931":"# Get int mapping for user_id in train dataset\n\nu_unique_train = train_data.user_id.unique()  \ntrain_data_user2idx = {o:i for i, o in enumerate(u_unique_train)}\n\n# Get int mapping for isbn in train dataset\n\ni_unique_train = train_data.isbn.unique()  \ntrain_data_book2idx = {o:i for i, o in enumerate(i_unique_train)}\n\n# Get int mapping for user_id in test dataset\n\nu_unique_test = test_data.user_id.unique()  \ntest_data_user2idx = {o:i for i, o in enumerate(u_unique_test)}\n\n# Get int mapping for isbn in train dataset\n\ni_unique_test = test_data.isbn.unique() \ntest_data_book2idx = {o:i for i, o in enumerate(i_unique_test)}\n","488455bf":"# TRAINING SET\ntrain_data['u_unique'] = train_data['user_id'].map(train_data_user2idx)\ntrain_data['i_unique'] = train_data['isbn'].map(train_data_book2idx)\n\n# TESTING SET\ntest_data['u_unique'] = test_data['user_id'].map(test_data_user2idx)\ntest_data['i_unique'] = test_data['isbn'].map(test_data_book2idx)\n\n# Convert back to 3-column df\ntrain_data = train_data[['u_unique', 'i_unique', 'book_rating']]\ntest_data = test_data[['u_unique', 'i_unique', 'book_rating']]","54ad5959":"train_data.sample(5)","3bae8398":"n_users = train_data['u_unique'].nunique()\nn_books = train_data['i_unique'].nunique()\n\ntrain_matrix = np.zeros((n_users, n_books))\n\nfor entry in train_data.itertuples():                  # entry[1] is the user-id, entry[2] is the book-isbn\n    train_matrix[entry[1]-1, entry[2]-1] = entry[3]    # -1 is to counter 0-based indexing","606050db":"train_matrix.shape","afcfcfee":"n_users = test_data['u_unique'].nunique()\nn_books = test_data['i_unique'].nunique()\n\ntest_matrix = np.zeros((n_users, n_books))\n\nfor entry in test_data.itertuples():\n    test_matrix[entry[1]-1, entry[2]-1] = entry[3] ","0632991a":"test_matrix.shape","9528ec4d":"train_matrix_small = train_matrix[:5000, :5000]\ntest_matrix_small = test_matrix[:5000, :5000]\n\nfrom sklearn.metrics.pairwise import pairwise_distances\nuser_similarity = pairwise_distances(train_matrix_small, metric='cosine')\nitem_similarity = pairwise_distances(train_matrix_small.T, metric='cosine') ","e918e067":"def predict_books(ratings, similarity, type='user'): # default type is 'user'\n    if type == 'user':\n        mean_user_rating = ratings.mean(axis=1)\n        \n        # Use np.newaxis so that mean_user_rating has the same format as ratings\n        \n        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) \/ np.array([np.abs(similarity).sum(axis=1)]).T\n    elif type == 'item':\n        pred = ratings.dot(similarity) \/ np.array([np.abs(similarity).sum(axis=1)])\n    return pred","a505cf99":"item_prediction = predict_books(train_matrix_small, item_similarity, type='item')\nuser_prediction = predict_books(train_matrix_small, user_similarity, type='user')","35ba7e00":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\ndef rmse(prediction, test_matrix):\n    prediction = prediction[test_matrix.nonzero()].flatten()\n    test_matrix = test_matrix[test_matrix.nonzero()].flatten()\n    return sqrt(mean_squared_error(prediction, test_matrix))\n\nprint(f'Item-based CF RMSE: {rmse(item_prediction, test_matrix_small)}')\nprint(f'User-based CF RMSE: {rmse(user_prediction, test_matrix_small)}')\n","991c7b83":"from surprise import Reader, Dataset\n\n# Creating a 'Reader' object to set the limit of the ratings \n\nreader = Reader(rating_scale=(1, 10))\n\ndata = Dataset.load_from_df(ratings_explicit, reader)","8d12b345":"from surprise import SVD, model_selection, accuracy\n\nmodel = SVD()\n\n# Train on books dataset\n\n%time model_selection.cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)","17eb568b":"trainset, testset = model_selection.train_test_split(data, test_size=0.2)\n\nmodel = SVD()\n\nmodel.fit(trainset)\npredictions = model.test(testset)\n\naccuracy.rmse(predictions)","1d82808a":"uid = 276744  \niid = '038550120X' \npred = model.predict(uid, iid, verbose=True)","50b6ae36":"print(f'The estimated rating for the book with ISBN code {pred.iid} from user #{pred.uid} is {pred.est:.2f}.\\n')\nactual_rtg= ratings_explicit[(ratings_explicit.user_id==pred.uid) & \n                             (ratings_explicit.isbn==pred.iid)].book_rating.values[0]\nprint(f'The real rating given for this was {actual_rtg:.2f}.')","e11519d5":"# The following function was adapted from the surprise docs\n# and can be used to get the top book recommendations for each user.\nfrom collections import defaultdict\n\ndef get_top_n(predictions, n=10):\n    '''Return the top-N recommendation for each user from a set of predictions.\n\n    Args:\n        predictions(list of Prediction objects): The list of predictions, as\n            returned by the test method of an algorithm.\n        n(int): The number of recommendation to output for each user. Default\n            is 10.\n\n    Returns:\n    A dict where keys are user (raw) ids and values are lists of tuples:\n        [(raw item id, rating estimation), ...] of size n.\n    '''\n\n    # First map the predictions to each user.\n    \n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # Then sort the predictions for each user and retrieve the k highest ones.\n    \n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n        \n    return top_n","31d9e103":"pred = model.test(testset)\ntop_n = get_top_n(pred)","204fc726":"def get_reading_list(userid):\n    \"\"\"\n    Retrieve full book titles from full 'books_users_ratings' dataframe\n    \"\"\"\n    reading_list = defaultdict(list)\n    top_n = get_top_n(pred, n=10)\n    print(top_n[userid])\n\n    for n in top_n[userid]:\n        book, rating = n\n        title = new_book_df.loc[new_book_df.isbn==book].book_title.unique()[0]\n        reading_list[title] = rating\n    print(reading_list)\n    return reading_list","9244fa7d":"# Just take a random look at user_id=116866\nexample_reading_list = get_reading_list(userid = 116866)\nfor book, rating in example_reading_list.items():\n    print(f'{book}: {rating}')","11a19306":"example_reading_list","5f9ad8fc":"### Memory-Based Collaborative Filtering","cf35f4a5":"### Testing Results !","43b799b6":"Now let's try to build our first recommendation system based on popularity. This recommendations are usually given to every user irrespective of personal charecterization. ","fe0b5f2b":"Let's take an arbitrary user-id and item-id to test our model. ","2647c6e9":"### Train - Test Split","56fb5680":"* Ratings dataset should have ratings from users which exist in users dataset, unless new users are added to users dataset","e48d7ced":"At first I'll create an empty matrix of users * books and the will add the appropriate values to the matrix by extracting them from the dataset.","d02bf098":"**Let's investigate the user_rating dataset","2a3c33af":"At first, I'll investigate the tables to see if any improvement is needed. Then I will do necessary operations to make the data clean so that I can work better with them.","37e0abd5":"## Visualization","f82471ce":"Let's take care of the missing value in 'book_author' column.","628ccf59":"Avobe recommended books seems pretty much related. So my first recommender engine is finished. ","3fef22c3":"### Importing Dataset","026139c1":"To make item-item similarity we need to take the transpose of the matrix.","443de50c":"* As the problem of string 'year_of _publication' values was solved in the preprocessing steps, so now there's no need to convert the data types anymore and the code is commented out. Below the plot says there are 4619 'year_of_publication' values ranging from 0-99 which were not visible in the previous notebook. So, I plotted this interactive plot to see more accurately the 'year_of _publication' distribution. ","a86a7cdb":"So our 'All Time Favourite\" book recommendations are ready.","a6751159":"### User-Item Matrix for Train Data","d1429645":"This countplot shows users have rated 0 the most, which can mean they haven't rated bokks at all. We have to separate the explicit ratings represented by 1\u201310 and implicit ratings represented by 0.","d71dd9fe":"The age distribution of the readers: ","90399922":"Now I'll define a function to predict the similarity :","337a20bb":"* We see our recommendation system gives 7.94 RMSE score. I want to check if we can make any improvement in this score by using another method. For this I will use Single valu decomposition method from the Surprise library.","b08895b8":"### User-Item Matrix for Test Data","3ba6e3d9":"### Data Preprocessing","b483bc32":"Lat's now make some pretty plots to visualize the data. ","f4737eaf":"### Importing Usual Libraries","1659d003":"* So the corrections are made. We've seen there are two missing values in the 'publisher' column. Let's take care of that.","dd9cc86b":"Memory-Based Collaborative Filtering are of two kinds: \n1. user-item filtering \n2. item-item filtering\n\nA user-item filtering will take a particular user and find users that are similar to that user based on similarity of ratings. Then it will recommend items that are similar to the ones the users liked.\n\nUnlike user-item filtering, item-item filtering will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items and recommends other items.\n\n* Item-Item Collaborative Filtering: \u201cUsers who liked this item also liked \u2026\u201d\n* User-Item Collaborative Filtering: \u201cUsers who are similar to you also liked \u2026\u201d","5d591893":"* Let's see how one previously problematic line looks now after correction! ","447b9f82":"* So user_id's alright. Let's check out the age of the users.","4a4791d5":"We see the RMSE score has improved a lot. It is now on average 1.64 which is pretty good. ","faa52cd8":"I'll only consider ISBNs that were explicitely rated for this recommendation system.","1d19812e":"Book Recommender System using [Book Crossing Dataset](http:\/\/www2.informatik.uni-freiburg.de\/~cziegler\/BX\/)","d13de3bf":"### SVD Based recommendation System","99bf6f88":"### Cosine Similarity Based Recommendation System","8a6cda47":"As I am doing this calculations on my PC, so it is not a good idea to perform this huge calculation. So I'll perform on a subset initially. It will take a bit of time to calculate.","4b5e9ef1":"* I'll only take the ISBNs that also belongs to the main book_data set.","a9c34b8b":"* We need to investigate out rating dataset too. ","04d910be":"* Let's look at the unique years to realize the time period as this dataset was created in 2004. ","111dcbc9":"Everything looks nice and clean.","bce49d43":"Now this countplot of book_rating indicates that higher ratings are more common amongst users and rating 8 has been rated highest number of times.","ac3d3c68":"### Popularity Based Recommendation","238dce41":"### Train - Test Split","80a89d0d":"### Evaluation","5e060ed3":"A distance metric commonly used in recommender systems is *cosine similarity*, where the ratings are seen as vectors in ``n``-dimensional space and the similarity is calculated based on the angle between these vectors. ","7a77041b":"Let's see which rating people tend to give more : "}}