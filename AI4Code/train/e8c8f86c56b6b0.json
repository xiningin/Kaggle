{"cell_type":{"56fad6e4":"code","3b156ad8":"code","00e1c1a7":"code","abb6ed52":"code","8a7d4635":"code","5fe9016a":"code","c7fdc297":"code","b5b66230":"code","e3946101":"code","f4996fd1":"code","5c82eb07":"code","012f22d0":"code","a6be96a6":"code","419e1e99":"code","a07feee6":"code","e5731744":"code","c2de66d6":"code","8e3de3a7":"code","c2883384":"code","519d900f":"code","dd76e971":"markdown","ec8e3ff2":"markdown","46c77842":"markdown","ce172e53":"markdown","0b357e25":"markdown","ab04523d":"markdown","7b46e341":"markdown","2db1f01b":"markdown","a2f197b3":"markdown","487006c2":"markdown","a8cf933f":"markdown","4527d613":"markdown"},"source":{"56fad6e4":"import io #The io module provides Python\u2019s main facilities for dealing with various types of I\/O.\nimport json #JSON (JavaScript Object Notation) is a lightweight data-interchange format\nimport cv2 # cv2.imread(), cv2.imshow() , cv2.imwrite()\nimport numpy as np #create a NumPy array, use broadcasting, access values, manipulate arrays, and much more\nimport requests #Make a request to a web page, and print the response text\nimport matplotlib.pyplot as plt  #Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.","3b156ad8":"#import the necessary libraries and load the image using matplotlib. \nimg = cv2.imread(\"..\/input\/tbs-image\/TBS_image.png\")\nheight, width, _ = img.shape\nheight\nwidth,height","00e1c1a7":"plt.imshow(img)","abb6ed52":"url_api = \"https:\/\/api.ocr.space\/parse\/image\"","8a7d4635":"# Ocr\nurl_api = \"https:\/\/api.ocr.space\/parse\/image\"\n_, compressedimage = cv2.imencode(\".jpg\", img, [1, 90])\nfile_bytes = io.BytesIO(compressedimage)","5fe9016a":"#you execute this code \n\"\"\"\nresult = requests.post(url_api,\n              files = {\"screenshot.jpg\": file_bytes},\n              data = {\"apikey\": \"YOURAPIKEYHERE\",\n                      \"language\": \"eng\"})\n\n\"\"\"","c7fdc297":"result = requests.post(url_api,\n              files = {\"..\/input\/tbs-image\/TBS_image.png\": file_bytes},\n              data = {\"apikey\": \"eb516eb1f288957\",\n                      \"language\": \"eng\"})","b5b66230":"result = result.content.decode()\nresult = json.loads(result)","e3946101":"result","f4996fd1":"parsed_results = result.get(\"ParsedResults\")[0]\ntext_detected = parsed_results.get(\"ParsedText\")\ntext_detected","5c82eb07":"# Generic Libraries\nfrom PIL import Image\nimport os\nimport pandas as pd\nimport numpy as np\nimport re,string,unicodedata\n\n#Tesseract Library\nimport pytesseract\n\n#Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Garbage Collection\nimport gc\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pytesseract\n\n","012f22d0":"# Let's start with a simple image\nimg = cv2.imread(\"..\/input\/tbs-image\/TBS_image.png\") # image in BGR format\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig = plt.figure(figsize = [10,10])\nheight,width,channel = img.shape\nplt.imshow(img)\nprint(type(img))\nprint(height,width,channel)","a6be96a6":"# as the image is simple enough, image_to_string method reads all characters almost perfectly!\ntext = pytesseract.image_to_string(img)\nprint(text)","419e1e99":"# the output of OCR can be saved in a file in necessary\nfile = open('output.txt','a') # file opened in append mode\nfile.write(text)\nfile.close()","a07feee6":"!pip install https:\/\/github.com\/myhub\/tr\/archive\/1.5.1.zip","e5731744":"from tr import *\nfrom PIL import Image, ImageDraw, ImageFont","c2de66d6":"img_pil = Image.open(\"..\/input\/ocr-working-in-progress\/7.jpg\")\nMAX_SIZE = 2000\nif img_pil.height > MAX_SIZE or img_pil.width > MAX_SIZE:\n    scale = max(img_pil.height \/ MAX_SIZE, img_pil.width \/ MAX_SIZE)\n\n    new_width = int(img_pil.width \/ scale + 0.5)\n    new_height = int(img_pil.height \/ scale + 0.5)\n    img_pil = img_pil.resize((new_width, new_height), Image.BICUBIC)\n\nprint(img_pil.width, img_pil.height)\n# img_pil","8e3de3a7":"gray_pil = img_pil.convert(\"L\")\n\nrect_arr = detect(img_pil, FLAG_RECT)\n\nimg_draw = ImageDraw.Draw(img_pil)\ncolors = ['red', 'green', 'blue', \"yellow\", \"pink\"]\n\nfor i, rect in enumerate(rect_arr):\n    x, y, w, h = rect\n    img_draw.rectangle(\n        (x, y, x + w, y + h),\n        outline=colors[i % len(colors)],\n        width=4)\n\nimg_pil","c2883384":"!pip install jovian\nimport jovian","519d900f":"jovian.commit(project='Tesseract_bis')","dd76e971":"- load the image using opencv (cv2) \n- the image needs to be converted to a binary image ; grayscaling it if it is an RGB image. **GRAYSCALING** takes the threee RGB values of an image and transfors it with the following formula to a single value which represents a shade of gray. [0-255] : 255 being the brighest shade of grey (white) and 0 being the darkest shade of grey (black). \n![image.png](attachment:image.png)","ec8e3ff2":"# read image with openCv\nimg = cv2.imread(\"..\/input\/tbs-image\/TBS_image.png\")\n# Convert to GrayScale\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Apply dilation and erosion to remove some noise\nkernel = np.ones((1,1), np.uint8)\nimg = cv2.dilate(img, kernel,  iterations=1)\nimg = cv2.erode(img, kernel, iterations=1)\n\ncv2.imwrite(img + \"removed_noise.png\", img)\n\n#Apply threshold to get image with only black and white\nimg = cv2.adaptiveThreshold (img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\ncv2.imwrite(img + \"thres.png\",img)\n\n#Recognize text with tesseract for python\nresult = pytesseract.image_to_string(Image.open(img + \"thres.png\"))\n\n\nprint(\"---------Start Recognize text from image---------\")\nprint (get_string(img+img_path))\nprint(\"--------Done-----------\")\n ","46c77842":"Credits to : \n[https:\/\/www.kaggle.com\/ggck43\/ocr-using-pytesseract-bengali-english \n](http:\/\/)\n","ce172e53":"# NB: \nOCR Can help you save your time and your effort in extracting texts from images ; you save the time spent in typing the whole text by yourself. \n\nthere are some issues you should take care of : \n- the quality of your image, the written content \n- the font size , you can seperate the font from the background !! the font is skewed or distorted !! \n\n- the size of the image \n- the quality of the light ","0b357e25":"# OPEN CV ","ab04523d":"3rd method : \n","7b46e341":"HI all  \ud83d\ude0d\n\nIn this notebook we will write a simple code to recognize text from a picture using python and OCR.space API. \n\nif you don't know what is an API here is a useful link to get an overview: https:\/\/www.altexsoft.com\/blog\/engineering\/what-is-api-definition-types-specifications-documentation\/\n\nAn API is a set of programming code that enables data transmission between one software product and another. It also contains the terms of this data exchange\n\n![image.png](attachment:image.png)","2db1f01b":"**Optical Character Recognition (OCR)\n****\n\nis a process run by an OCR software. The software will open a digital image, e.g. a tiff file containing full text characters, and then attempt to read and translate the characters into recognizable full text and save them as a full text file. This is a quick process that enables automated conversion of millions of images into full-text files that can then be searched by word or character. This is a very useful and cost efficient process for large scale digitisation projects for text based materials including books, journals and newspapers. There are several OCR software packages on the market but a popular package for older material or that in languages other than English is Abbyy Finereader. This is currently being used by several newspaper digitisation projects internationally.\n\nThe OCR process is dependant upon a number of factors and these factors influence results quite radically. Experience to date has shown that using OCR software over good quality clean images (e.g. a new PDF file) has excellent results and most characters will be recognized correctly therefore leading to successful word searching and retrieval. However over older materials e.g. books and newspapers the OCR is extremely variable and for this reason some projects advocate re-keying the text from scratch, rather than attempting OCR. The process is labour intensive and sometimes a combination of both re-keying and OCR will be performed for a project. It is usual to undertake sample tests on the actual source material to be digitised before making decisions about OCR and re-keying.","a2f197b3":"***ocr.space is an OCR engine that offers free API*\n\n\nIt means that is going to do pretty much all the work regarding text detection. We only need to send through their API an image with the text we want to scan,\nand it will return us the text scanned.\n\nFirst of all, you need to get an API key.\n\nGo on http:\/\/ocr.space\/OCRAPI and then click on \u201cRegister for free API Key\u201d.\n\n*NB : The free OCR API plan has a rate limit of 500 requests within one day per IP address to prevent accidental spamming*****.","487006c2":"Extract text using tesseract : ","a8cf933f":"after the **grayscaling **, it comes the **thresholding ** ; the thresholding is used to decide whether the value of a pixel is below or above a certain threshold. \n1. pixels < the threshold ===> turned to white pixel \n2. pixels > the threshold ===> turned to black pixel \n\nthe result of 1 and 2 is that we get a binary image ( white background and black foreground) \n\nTo read more about thresholdig you can check this : [https:\/\/towardsdatascience.com\/understanding-the-basics-of-digital-image-processing-and-computer-vision-using-opencv-8bc0e67243c8](http:\/\/)\n\n\n\n","4527d613":"after loading the image of the TBS bachelor , we need to set the OCR engine : send the image to the ocr.space server in order to be processed. \nhere there are few notes : \n1. sending the image to the ocr.space server \n2. since we are using the free service, we can not send an image with maximum 1mb of size , so we need to shrink the size of our image by compressing it. \n3. also, to send the image to the server we need to convert the image into bytes. "}}