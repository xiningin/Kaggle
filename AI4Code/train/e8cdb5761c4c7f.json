{"cell_type":{"ba1bab9e":"code","af5d1a85":"code","ee4ecfb0":"code","a3e0bdfe":"code","1e4514dc":"code","8034e662":"code","5535138c":"code","2d88071f":"code","060a5cbf":"code","33d25eac":"code","37d15462":"code","272669ac":"code","395101be":"code","91930e81":"code","7835f6e1":"code","734b6313":"code","5e32dec0":"code","818b0773":"code","70afe1f2":"code","4a15c0f0":"code","103dd390":"code","5e47d1be":"markdown"},"source":{"ba1bab9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af5d1a85":"from tensorflow import keras","ee4ecfb0":"TPS_file_path = '..\/input\/tabular-playground-series-jan-2021\/train.csv'\nTPS_data = pd.read_csv(TPS_file_path)\nTPS_data.shape","a3e0bdfe":"TPS_data.head()","1e4514dc":"TPS_data.drop('id', axis=1, inplace=True)\nTPS_data.head()","8034e662":"from sklearn.model_selection import train_test_split\n# mieszamy nasze dane i dzielimy na zbiory treningowy i walidacyjny\n\ntrain_set, valid_set = train_test_split(TPS_data, test_size=0.2, random_state=42, shuffle=True)\n\n[train_set.shape, valid_set.shape]","5535138c":"X_train = train_set.drop('target', axis=1)\nX_valid = valid_set.drop('target', axis=1)\n\ny_train = train_set.target\ny_valid = valid_set.target","2d88071f":"X_train.hist(figsize=(20,15), bins=50)","060a5cbf":"X_train.hist(column='cont1', bins=50)","33d25eac":"X_train.max().sort_values(ascending=False)","37d15462":"from sklearn.preprocessing import MinMaxScaler #normalizacja danych\n\ncols = X_train.columns\n\nscaler = MinMaxScaler(feature_range=(0,1)) #sie\u0107 neuronowa 'lubi' dane w zakresie od 0 do 1\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train)) #scaler uczymy na X_train\nX_valid = pd.DataFrame(scaler.transform(X_valid)) #normalizujemy na podstawie statystyk z X_train","272669ac":"X_train.columns = cols\nX_train.head()","395101be":"X_train.hist(column='cont1', bins=50)","91930e81":"X_train.max().sort_values(ascending=False)","7835f6e1":"from keras import layers\n\nmodel = keras.models.Sequential([\n    layers.InputLayer(input_shape=[14]),\n    layers.Dense(50, activation='relu'),\n    layers.Dense(50, activation='relu'),\n    layers.Dense(50, activation='relu'),\n    layers.Dense(1)\n])","734b6313":"model.compile(loss='mse', #funkcj\u0119 straty rmse wprowadzimy w modelu zaawansowanym\n              optimizer=keras.optimizers.SGD(lr=0.01),\n              #metrics=['mse']\n             )","5e32dec0":"history = model.fit(X_train, y_train, epochs=10,\n                    validation_data=(X_valid, y_valid))","818b0773":"TEST_data_filepath = '..\/input\/tabular-playground-series-jan-2021\/test.csv'\nTEST_data = pd.read_csv(TEST_data_filepath)\n\nTEST_data.columns","70afe1f2":"id = TEST_data.id","4a15c0f0":"TEST_data = TEST_data.drop('id', axis=1)\nTEST_data = scaler.transform(TEST_data)\n\ntarget = model.predict(TEST_data).flatten()\ntarget","103dd390":"output = pd.DataFrame({'id': id,\n                      'target': target})\noutput.to_csv('submission.csv', index=False)","5e47d1be":"# Podstawowy model"}}