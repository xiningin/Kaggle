{"cell_type":{"6cd7f33d":"code","ecf0e7ce":"code","04ece1fa":"code","175225d2":"code","9b43f2de":"code","172cca66":"code","99a0ecff":"code","14fc0784":"code","4a45413c":"code","93c20e9b":"code","83a063bf":"code","36aa7caa":"code","c76f971c":"code","de0850b2":"code","0621de3a":"code","43d62cd7":"code","9db71d5e":"code","1ce6cf9d":"code","9fd65732":"code","92c559e2":"code","8dd37884":"code","774bd736":"code","a8050de2":"code","9239c7fe":"code","bdf2669a":"code","407f4bf8":"code","6ad0b61e":"code","fe940b58":"code","dcab5b7f":"code","a714964f":"code","1176e457":"code","3b2a7a56":"code","643b6837":"code","18e196b4":"code","02f79ad5":"code","50dd177f":"code","0072ea53":"code","c1b9ed0e":"code","6e650ac3":"code","afa071aa":"code","0d8c8b1d":"code","eeaf2d4d":"code","3a27fcfa":"code","b2f39f12":"code","9f02ff2c":"code","0cd5444c":"code","bdf6fb0b":"code","80c7cdb8":"code","4eb72afc":"code","8c8f4e76":"code","5dc81188":"code","11217e51":"markdown","2b2e3c26":"markdown","ded4465c":"markdown","987e1506":"markdown","6fd7ba29":"markdown","8b233b3f":"markdown","cf2262ba":"markdown","eb134834":"markdown","6d7823ba":"markdown","9ea75a71":"markdown","cb630aa4":"markdown","092fd6ab":"markdown","4e7675b0":"markdown","3137bde4":"markdown","c100350c":"markdown","4e9d09fb":"markdown","65796da9":"markdown","5f0b2e94":"markdown","22c9fb61":"markdown","8723648a":"markdown","91a55933":"markdown","aeddf96f":"markdown","d5976dc4":"markdown","7b88d004":"markdown","2aad4725":"markdown","76eda39f":"markdown","66eed3ea":"markdown","d677d9ee":"markdown","d294e4d9":"markdown","3b1e63d7":"markdown","ef0441e9":"markdown","373adece":"markdown","50f5fd00":"markdown","ae1e7960":"markdown"},"source":{"6cd7f33d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom tutorial_pandas_module_part1 import *\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ecf0e7ce":"# Create data frame\ndataframe = ___\n\n# Add three columns: 'Name' (string), 'Age' (number) and 'Driver' (boolean)\n# Names: 'Jacky Jackson' and 'Steven Stevenson'\n# Ages: 38 and 25\n# Drivers: True and False\n___\n\n# Show data frame\ndataframe","04ece1fa":"step1.check()\n#step1.solution()","175225d2":"# Create row\n# Name: 'Molly Mooney'\n# Age: 40\n# Driver: True \nrow = ___\n\n# Append row\nnew_dataframe = ___\n\n# Show new data frame\nnew_dataframe ","9b43f2de":"step2.check()\n#step2.solution()","172cca66":"\n# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Select the first five rows\nrows = ___\n\n# Show rows\nrows ","99a0ecff":"step3.check()\n#step3.solution()","14fc0784":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Show dimensions\ndimensions = ___\ndimensions","4a45413c":"step4.check()\n#step4.solution()","93c20e9b":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Show statistics\nstatistics = ___\nstatistics","83a063bf":"step5.check()\n#step5.solution()","36aa7caa":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Select first row\nrow = ___\n\n# Show row\nrow","c76f971c":"step6.check()\n#step6.solution()","de0850b2":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Select the second, third, and fourth row\nrows = ___\n\n# Show rows\nrows","0621de3a":"step7.check()\n#step7.solution()","43d62cd7":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Select all rows up to and including the fourth row\nrows = ___\n\n# Show rows\nrows","9db71d5e":"step8.check()\n#step8.solution()","1ce6cf9d":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Set 'Name' columnn as index\ndataframe = ___\n\n# Select row where 'Name' value is 'Allen, Miss Elisabeth Walton'\nrow = ___\n\n# Show row\nrow","9fd65732":"step9.check()\n#step9.solution()","92c559e2":"# Load data from a csv file as a data frame \ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Select top two rows where column 'Sex' is 'female'\nrows = ___\n\n# Show rows\nrows","8dd37884":"step10.check()\n#step10.solution()","774bd736":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Filter rows where the passenger is a 'female' and 'Age' is 65 or older\nrows = ___\n\n# Show rows\nrows","a8050de2":"step11.check()\n#step11.solution()","9239c7fe":"# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Replace \"female\" in 'Sex' column with \"Woman\"  \nnew_dataframe = ___\n\n# Select the five first rows\nrows = new_dataframe.head(5)\n\n# Show rows\nrows","bdf2669a":"step12.check()\n#step12.solution()","407f4bf8":"# Load data from a csv file as a data frame \ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Replace \"female\" and \"male\" with \"Woman\" and \"Man\"\nnew_dataframe = ___\n\n# Select the five first rows\nrows = new_dataframe.head(5)\n\n# Show rows\nrows","6ad0b61e":"step13.check()\n#step13.solution()","fe940b58":"# Load data from a csv file as a data frame \ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Replace value 1 with \"One\" in the whole data frame\nnew_dataframe = ___\n\n# Select the five firt rows\nrows = new_dataframe.head(5)\n\n# Show rows\nrows","dcab5b7f":"step14.check()\n#step14.solution()","a714964f":"# Load data from a csv file as a data frame \ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Replace \"1st\" with \"First\" using regular expressions\nnew_dataframe = ___\n\n# Select the five firt rows\nrows = new_dataframe.head(5)\n\n# Show rows\nrows","1176e457":"step15.check()\n#step15.solution()","3b2a7a56":"# Load data from a csv file as a data frame \ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Find first two names uppercased using loops\nnames = ['', '']\n___\n    \n# Show names array\nnames_array = np.array(names)\nnames_array","643b6837":"step16.check()\n#step16.solution()","18e196b4":"# Load data from a csv file as a data frame \ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Find first two names uppercased using use list comprehensions\nnames = ___\n\n# Show names array\nnames_array = np.array(names)\nnames_array","02f79ad5":"step17.check()\n#step17.solution()","50dd177f":"# Create function to uppercase a string\n___\n\n# Load data from a csv file as a data frame\ndataframe = pd.read_csv(\"\/kaggle\/input\/titanic\/titanic.csv\")\n\n# Apply function to first two names\nnames = ___\n\n# Show names array\nnames_array = np.array(names)\nnames_array","0072ea53":"step18.check()\n#step18.solution()","c1b9ed0e":"# Create first data frame\ndata_a = {'id': ['1', '2', '3'],\n          'first': ['Alex', 'Amy', 'Allen'],\n          'last': ['Anderson', 'Ackerman', 'Ali']}\ndataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n\n# Create second data frame\ndata_b = {'id': ['4', '5', '6'],\n          'first': ['Billy', 'Brian', 'Bran'],\n          'last': ['Bonder', 'Black', 'Balwner']}\ndataframe_b = pd.DataFrame(data_b, columns = ['id', 'first', 'last'])\n\n# Concatenate data frame by rows\nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","6e650ac3":"step19.check()\n#step19.solution()","afa071aa":"# Create first data frame\ndata_a = {'id': ['1', '2', '3'],\n          'first': ['Alex', 'Amy', 'Allen'],\n          'last': ['Anderson', 'Ackerman', 'Ali']}\ndataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n\n# Create second data frame\ndata_b = {'id': ['4', '5', '6'],\n          'first': ['Billy', 'Brian', 'Bran'],\n          'last': ['Bonder', 'Black', 'Balwner']}\ndataframe_b = pd.DataFrame(data_b, columns = ['id', 'first', 'last'])\n\n# Concatenate data frame by columns\nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","0d8c8b1d":"step20.check()\n#step20.solution()","eeaf2d4d":"# Create first data frame\ndata_a = {'id': ['1', '2', '3'],\n          'first': ['Alex', 'Amy', 'Allen'],\n          'last': ['Anderson', 'Ackerman', 'Ali']}\ndataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n\n# Create row\n# id: 10\n# first: 'Chris'\n# last: 'Chillon'\nrow = ___\n\n# Create data frame appending row to first data frame \nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","3a27fcfa":"step21.check()\n#step21.solution()","b2f39f12":"# Create first data frame\nemployee_data = {'employee_id': ['1', '2', '3', '4'],\n                 'name': ['Amy Jones', 'Allen Keys', 'Alice Bees',\n                 'Tim Horton']}\ndataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id', 'name'])\n\n# Create second data frame\nsales_data = {'employee_id': ['3', '4', '5', '6'],\n              'total_sales': [23456, 2512, 2345, 1455]}\ndataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id','total_sales'])\n\n# Merge data frames\nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","9f02ff2c":"step22.check()\n#step22.solution()","0cd5444c":"# Create first data frame\nemployee_data = {'employee_id': ['1', '2', '3', '4'],\n                 'name': ['Amy Jones', 'Allen Keys', 'Alice Bees',\n                 'Tim Horton']}\ndataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id', 'name'])\n\n# Create second data frame\nsales_data = {'employee_id': ['3', '4', '5', '6'],\n              'total_sales': [23456, 2512, 2345, 1455]}\ndataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id','total_sales'])\n\n# Merge data frames on 'employee_id' column using 'outer' join type\nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","bdf6fb0b":"step23.check()\n#step23.solution()","80c7cdb8":"# Create first data frame\nemployee_data = {'employee_id': ['1', '2', '3', '4'],\n                 'name': ['Amy Jones', 'Allen Keys', 'Alice Bees',\n                 'Tim Horton']}\ndataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id', 'name'])\n\n# Create second data frame\nsales_data = {'employee_id': ['3', '4', '5', '6'],\n              'total_sales': [23456, 2512, 2345, 1455]}\ndataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id','total_sales'])\n\n# Merge data frames on 'employee_id' column using 'left' join type\nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","4eb72afc":"step24.check()\n#step24.solution()","8c8f4e76":"# Create first data frame\nemployee_data = {'employee_id': ['1', '2', '3', '4'],\n                 'name': ['Amy Jones', 'Allen Keys', 'Alice Bees',\n                 'Tim Horton']}\ndataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id', 'name'])\n\n# Create second data frame\nsales_data = {'employee_id': ['3', '4', '5', '6'],\n              'total_sales': [23456, 2512, 2345, 1455]}\ndataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id','total_sales'])\n\n# Merge data frames on 'employee_id'\nnew_dataframe = ___\n\n# Show data frame\nnew_dataframe","5dc81188":"step25.check()\n#step25.solution()","11217e51":"**STEP 10:** \n\nWe want to select *data frame* rows based on some condition. This can be easily done in *pandas*.\n\nWe wanted to select all the women on the Titanic dataset. In the conditional statement **dataframe['Sex'] == 'female'**, we are telling pandas to select all the rows in the **DataFrame** where the value of **dataframe['Sex']** is **'female'**.","2b2e3c26":"**STEP 8:** \n\nWe can even use it to get all rows up to a point, such as all rows up to and including the fourth row.","ded4465c":"<h3>Creating a Data Frame<\/h3>\n\n*pandas* offers an infinite number of ways to create a **DataFrame**. In the real world, creating an empty **DataFrame** and then populating it will almost never happen. Instead, a **DataFrame** will be created from real data we have loading from other sources (e.g., a CSV file).\n","987e1506":"<h3>Navigating data frames<\/h3>\n\nAll rows in a *pandas* **DataFrame** have a unique index value. By default, this index is an integer indicating the row position in the **DataFrame**; however, it does not have to be. **DataFrame** indexes can be set to be unique alphanumeric strings or customer numbers. \n\nTo select individual rows and slices of rows, *pandas* provides two methods:\n\n* **loc** is useful when the index of the **DataFrame** is a label (e.g., a string).\n\n* **iloc** works by looking for the position in the **DataFrame**. For example, **iloc[0]** will return the first row regardless of whether the index is an integer or a label.\n\n","6fd7ba29":"**STEP 1:** \n\nWe want to create a new  *data frame* and *pandas* has many methods of creating a new **DataFrame** object. One easy method is to create an empty data frame using **DataFrame** constructor and then define each column separately.","8b233b3f":"<h3>Looping over a column<\/h3>\n\nWe want to iterate over every element in a column and apply some action. ","cf2262ba":"<h3>Replacing Values<\/h3>\n\nThe **replace** method is a tool we use to replace values that is simple and yet has the powerful ability to accept regular expressions.","eb134834":"**STEP 7:** \n\nWe can use the symbol **:** to define a slice of rows we want, such as selecting the second, third, and fourth row.","6d7823ba":"**STEP 16:** \n\nWe can treat a *pandas* column like any other sequence in Python when we iterate over every element in a column and we want to apply some action.","9ea75a71":"**STEP 11:** \n\nMultiple conditions are easy as well. We select all the rows where the passenger is a female 65 or older.","cb630aa4":"**STEP 15:** \n\nThe **replace** method also accepts regular expressions.","092fd6ab":"**STEP 6:** \n\nWe need to select individual data or slices of a **DataFrame**. Use **loc** or **iloc** to select one or more rows or values.","4e7675b0":"**STEP 19:** \n\nIf we want to concatenate two *data frames*, we can use **concat** with **axis=0** to concatenate along the row axis.","3137bde4":"**STEP 24:** \n\nThe same parameter can be used to specify left and right joins","c100350c":"<h3>Concatenating data frames<\/h3>\n\nThe informal definition of *concatenate* is to glue two objects together. We can glue together two *data frames* using the **axis** parameter to indicate whether we wanted to stack the two *data frames* on top of each other or place them side by side.","4e9d09fb":"**STEP 12:** \n\nWe need to replace values in a **DataFrame**. **replace** is an easy way to find and replace values. We can replace any instance of **\"female\"** in the **Sex** column with **\"Woman\"**.","65796da9":"**STEP 23:** \n\nIf we want to do an outer join (**merge** defaults to inner joins), we can specify that with the **how** parameter.","5f0b2e94":"**STEP 22:** \n\nWe want to merge two *data frames*. To inner join, use **merge** with the on parameter to specify the column to merge on.","22c9fb61":"**STEP 20:** \n\nWe can use **axis=1** to concatenate along the column axis.","8723648a":"**STEP 3:** \n\nWe want to view some characteristics of a **DataFrame**. One of the easiest things we can do after loading the data is view the first few rows using **head** but we have first to create a **DataFrame** from data about passengers on the Titanic stored in a csv file (https:\/\/tinyurl.com\/titanic-csv).\n\n\nIn this *data frame* each row corresponds to one *observation* (e.g., a passenger) and each column corresponds to one *feature* (gender, age, etc.). For example, by looking at the first *observation* we can see that Miss Elisabeth Walton Allen stayed in first class, was 29 years old, was female, and survived the disaster.\n\nEach column contains a name (e.g., **Name**, **PClass**, **Age**) and each row contains an index number (e.g., 0 for the lucky Miss Elisabeth Walton Allen). We will use these to select and manipulate *observations* and *features*.\n\nTwo columns, **Sex** and **SexCode**, contain the same information in different formats. In **Sex**, a woman is indicated by the string female, while in **SexCode**, a woman is indicated by using the integer 1. We will want all our *features* to be unique, and therefore we will need to remove one of these columns.\n","91a55933":"**STEP 21:** \n\nAlternatively we can use append to add a new row to a **DataFrame**.","aeddf96f":"**STEP 4:** \n\nWe can also take a look at the number of rows and columns using **shape**.","d5976dc4":"**STEP 14:** \n\nWe can also find and replace across the entire **DataFrame** object by specifying the whole *data frame* instead of a single column.","7b88d004":"**STEP 9:** \n\n*Data frames* do not need to be numerically indexed. We can set the index of a *data frame* to any value where the value is unique to each row. We can set the index to be passenger names and then select rows using a name.","2aad4725":"**STEP 13:** \n\nWe can also replace multiple values at the same time.","76eda39f":"<h3>Applying a function over all elements in a column<\/h3>\n\nDespite the temptation to fall back on **for** loops, a best solution would use **apply** method from *pandas*.\n\nThe **apply** method is a great way to do data wrangling and cleaning. It is common to write a function to perform some useful operation (separate first and last names, convert strings to floats, etc.) and then map that function to every element in a column.","66eed3ea":"**STEP 18:** \n\nWe want to apply some function over all elements in a column. Use **apply** method to apply a built-in or custom function on every element in a column.","d677d9ee":"**STEP 5:** \n\nWe can get descriptive statistics for any numeric columns using **describe**.\n\nIn this dataset, *pandas* treats the columns **Survived** and **SexCode** as numeric columns because they contain 1s and 0s. However,  the numerical values represent categories. For example, if **Survived** equals 1, it indicates that the passenger survived the disaster. For this reason, some of the summary statistics provided don\u2019t make sense, such as the *standard deviation* of the **SexCode** column (an indicator of the passenger\u2019s gender).","d294e4d9":"**STEP 17:** \n\nIn addition to loops (**for** loops), we can also use list comprehensions.","3b1e63d7":"<h3>Selecting rows based on conditionals<\/h3>\n\nConditionally selecting and filtering data is one of the most common tasks in data wrangling. We rarely want all the raw data from the source; instead, we are interested in only some subsection of it.","ef0441e9":"**STEP 2:** \n\nOnce we have created a **DataFrame** object, we can append new rows to the bottom.","373adece":"<h3>Describing the data<\/h3>\n\nAfter we load some data, it is a good idea to understand how it is structured and what kind of information it contains. Ideally, we would view the full data directly. But with most real-world cases, the data could have thousands to hundreds of thousands to millions of rows and columns. \n\nUsing **head** we can take a look at the first few rows (five by default) of the data. Alternatively, we can use **tail** to view the last few rows. Additionally, with **shape** we can see how many rows and columns the **DataFrame** contains and with **describe** we can see some basic descriptive statistics for any numerical column.\n","50f5fd00":"**STEP 25:** \n\nWe can also specify the column name in each **DataFrame** to merge on.\n\nIf instead of merging on two columns, we want to merge on the indexes of each **DataFrame**, we can replace the **left_on** and **right_on** parameters with **right_index=True** and **left_index=True**.","ae1e7960":"<h3>Merging data frames<\/h3>\n\nIn the real world, we\u2019re usually faced with  datasets from multiple database queries or files. To get all that data into one place, we can load each data query or data file into *pandas* as individual *data frames* and then merge them together into a single *data frame*.\n\nThis process might be familiar to anyone who has used SQL, a popular language for doing merging operations (called *joins*). While the exact parameters used by *pandas* will be different, they follow the same general patterns used by other software languages and tools.\n\nThere are three aspects to specify with any merge operation. First, we have to specify the two *data frames* we want to merge together.  Second, we have to specify the name(s) of the columns to merge on\u2014that is, the columns whose values are shared between the two *data frames*.  To merge the two *data frames* we will match up the values in each column with each other. If these two columns use the same name, we can use the **on** parameter. However, if they have different names we can use **left_on** and **right_on**.\n\nThe type of merge operation we want to conduct  is specified by the **how** parameter. **merge** supports the four main types of *joins*:\n\n* *Inner*: Return only the rows that match in both *data frames*.\n\n* *Outer*: Return all rows in both *data frames*. If a row exists in one *data frame* but not in the other, fill *NaN* values for the missing values.\n\n* *Left*:  Return all rows from the left *data frame* but only rows from the right *data frame* that matched with the left *data frame*. Fill *NaN* values for the missing values.\n\n* *Right*: Return all rows from the right *data frame* but only rows from the left *data frame* that matched with the right *data frame*. Fill *NaN* values for the missing values."}}