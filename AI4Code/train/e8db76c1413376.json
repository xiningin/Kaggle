{"cell_type":{"a4120056":"code","bc6a9b8f":"code","0af90839":"code","01b5efee":"code","1a576761":"code","9bd8214b":"code","fd9b8d3a":"code","32c05da1":"code","3729952f":"code","56997511":"code","ac67236f":"code","d0427be9":"code","13a3c7d1":"code","036d2106":"code","98132444":"code","8edaec32":"code","9c986242":"code","ab8af234":"code","4b7418ae":"code","f386b172":"code","7792e20e":"code","df58c7b4":"code","d203b5a4":"code","41216dc1":"code","dad6e445":"code","9d43fac9":"code","fdcb6ab9":"code","28da1c0f":"code","ababb3da":"code","46c4b18d":"code","22df06a4":"code","6e0fd290":"code","b3cfc7b8":"code","800bd3cf":"code","12ed8a9a":"markdown","69f4ba0f":"markdown","67b9955b":"markdown","f0588544":"markdown","79fcb48d":"markdown","442ba6c2":"markdown","43d7c809":"markdown"},"source":{"a4120056":"# Data handling\nimport pandas as pd\nimport numpy as np\n\n# Pre-processing\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import PowerTransformer\nfrom imblearn.over_sampling import SMOTE\n\n#Graficos\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n#Importing library to bring external files\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# Modeling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n# Metrics validation\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc, classification_report, plot_confusion_matrix\nfrom sklearn.metrics import f1_score    \n\n#Deploy\nimport pickle\n        ","bc6a9b8f":"#Importing Dataset        \ndf_eth_fraude = pd.read_csv('..\/input\/ethereum-frauddetection-dataset\/transaction_dataset.csv',delimiter=',',header='infer')\ndf_eth=df_eth_fraude.copy()\nprint(df_eth.shape)\ndf_eth.head()","0af90839":"df_eth.info()","01b5efee":"#Transform \"object\" variables into categories\ncategoricas = df_eth.select_dtypes('O').columns.astype('category')\ndf_eth[categoricas]","1a576761":"#Corroborate if the dataset is unbalanced\ncantidad = df_eth['FLAG'].value_counts()\n\nplt.pie(cantidad, labels=cantidad)\nplt.title('Cantidad de Fraudes')\nplt.legend(cantidad.keys().tolist())\nplt.show()","9bd8214b":"# Correlation matrix\ncorr = df_eth.corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, square=True)","fd9b8d3a":"# Explore missing values\ndf_eth[df_eth.isnull().any(axis=1)]","32c05da1":"df_eth.isnull().sum()","3729952f":"fraud=df_eth[df_eth['FLAG']==1]\nvalid=df_eth[df_eth['FLAG']==0]","56997511":"Columnas_nulas=df_eth.iloc[:,26:49]\nColumnas_fill_cero=[]\nfor nombre in Columnas_nulas:\n    p=df_eth[nombre].mean()\n    maxv=df_eth[nombre].max()\n    minv=df_eth[nombre].min()\n    if p == 0:\n        Columnas_fill_cero.append(nombre)\n        print('Columna: {}\\n ===> Promedio: {}\\n ===> Valor Max{}\\n ===> Valor Min{}\\n'.format(nombre,p,maxv,minv))","ac67236f":"Columnas_fill_median=[]\nfor nombre in Columnas_nulas:\n    p=df_eth[nombre].mean()\n    maxv=df_eth[nombre].max()\n    minv=df_eth[nombre].min()\n    if p != 0:\n        Columnas_fill_median.append(nombre)\n        print('Columna: {}\\n ===> Promedio: {}\\n ===> Valor Max{}\\n ===> Valor Min{}\\n'.format(nombre,p,maxv,minv))","d0427be9":"for col in Columnas_fill_cero:\n    df_eth[col].fillna(0,inplace=True)\n    \nfor col in Columnas_fill_median:\n    df_eth[col].fillna(df_eth[col].median(),inplace=True)","13a3c7d1":"df_eth = df_eth.dropna(axis=0, how='any')\ndf_eth = df_eth.drop(columns=['Unnamed: 0','Index'])\ndf_eth.isnull().sum()","036d2106":"df_eth['Address_enc'] = LabelEncoder().fit_transform(df_eth['Address'])\ndf_eth['ERC20 most sent token type_enc'] = LabelEncoder().fit_transform(df_eth[' ERC20 most sent token type'])\ndf_eth['ERC20_most_rec_token_type_enc'] = LabelEncoder().fit_transform(df_eth[' ERC20_most_rec_token_type'])\n\ndf_eth = df_eth.drop(columns=['Address',' ERC20 most sent token type',' ERC20_most_rec_token_type'])\ndf_eth","98132444":"no_var = df_eth.var() == 0\nprint(df_eth.var()[no_var])\nprint('\\n')\n\n#Delete the columns with variance 0 since they do not help in the model. \/ Borrar las columnas con varianza 0 ya que no ayudan en el modelo.\ndf_eth.drop(df_eth.var()[no_var].index, axis = 1, inplace = True)\nprint(df_eth.var())\nprint(df_eth.shape)","8edaec32":"df_eth.info()","9c986242":"corr = df_eth.corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, annot=False, cmap='CMRmap', center=0, square=True)","ab8af234":"drop = ['total transactions (including tnx to create contract', 'total ether sent contracts', 'max val sent to contract', ' ERC20 avg val rec',\n        ' ERC20 avg val rec',' ERC20 max val rec', ' ERC20 min val rec', ' ERC20 uniq rec contract addr', 'max val sent', ' ERC20 avg val sent',\n        ' ERC20 min val sent', ' ERC20 max val sent', ' Total ERC20 tnxs', 'avg value sent to contract', 'Unique Sent To Addresses',\n        'Unique Received From Addresses', 'total ether received', ' ERC20 uniq sent token name', 'min value received', 'min val sent', ' ERC20 uniq rec addr' ]\ndf_eth.drop(drop, axis=1, inplace=True)","4b7418ae":"# Correlation matrix without the null values of variability. \/ Matriz de correlacion sin los valores de nula variabilidad.\ncorr = df_eth.corr()\n\nmascara = np.zeros_like(corr)\nmascara[np.triu_indices_from(mascara)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mascara, annot=False, cmap='CMRmap', center=0, square=True)","f386b172":"# These two columns are eliminated for having variables that are mostly zero. \/ Se eliminan estas dos columnas por tener variables que son mayormente cero\ndrops = ['min value sent to contract', ' ERC20 uniq sent addr.1']\ndf_eth.drop(drops, axis=1, inplace=True)\nprint(df_eth.shape)\ndf_eth.head()","7792e20e":"# Distribution of features before log transformation \/ Distribucion de las variables explicativas antes de la transformacion logistica\n\nb=20\n\nfig, axes = plt.subplots(7, 3, figsize=(14, 14), constrained_layout =True)\nplt.subplots_adjust(wspace = 0.7, hspace=0.8)\naxes[-1, -1].axis('off') # hide axes\naxes[-1, -2].axis('off') # hide axes\nplt.suptitle(\"Distribution of features after log\",y=0.95, family='Sherif', size=18, weight='bold')\n \nax = sns.boxplot(ax = axes[0,0], data=df_eth, x=df_eth.columns[0])\nax.set_title(f'Distribution of {df_eth.columns[0]}')\n \nax1 = sns.boxplot(ax = axes[0,1], data=df_eth, x=df_eth.columns[1])\nax1.set_title(f'Distribution of {df_eth.columns[1]}')\n \nax2 = sns.boxplot(ax = axes[0,2], data=df_eth, x=df_eth.columns[2])\nax2.set_title(f'Distribution of {df_eth.columns[2]}')\n \nax3 = sns.boxplot(ax = axes[1,0], data=df_eth, x=df_eth.columns[3])\nax3.set_title(f'Distribution of {df_eth.columns[3]}')\n \nax4 = sns.boxplot(ax = axes[1,1], data=df_eth, x=df_eth.columns[4])\nax4.set_title(f'Distribution of {df_eth.columns[4]}')\n \nax5 = sns.boxplot(ax = axes[1,2], data=df_eth, x=df_eth.columns[5])\nax5.set_title(f'Distribution of {df_eth.columns[5]}')\n \nax6 = sns.boxplot(ax = axes[2,0], data=df_eth, x=df_eth.columns[6])\nax6.set_title(f'Distribution of {df_eth.columns[6]}')\n \nax7 = sns.boxplot(ax = axes[2,1], data=df_eth, x=df_eth.columns[7])\nax7.set_title(f'Distribution of {df_eth.columns[7]}')\n \nax8 = sns.boxplot(ax = axes[2,2], data=df_eth, x=df_eth.columns[8])\nax8.set_title(f'Distribution of {df_eth.columns[8]}')\n \nax9 = sns.boxplot(ax = axes[3,0], data=df_eth, x=df_eth.columns[9])\nax9.set_title(f'Distribution of {df_eth.columns[9]}')\n\nax10 = sns.boxplot(ax = axes[3,1], data=df_eth, x=df_eth.columns[10])\nax10.set_title(f'Distribution of {df_eth.columns[10]}')\n \nax11 = sns.boxplot(ax = axes[3,2], data=df_eth, x=df_eth.columns[11])\nax11.set_title(f'Distribution of {df_eth.columns[11]}')\n \nax12 = sns.boxplot(ax = axes[4,0], data=df_eth, x=df_eth.columns[12])\nax12.set_title(f'Distribution of {df_eth.columns[12]}')\n \nax13 = sns.boxplot(ax = axes[4,1], data=df_eth, x=df_eth.columns[13])\nax13.set_title(f'Distribution of {df_eth.columns[13]}')\n \nax14 = sns.boxplot(ax = axes[4,2], data=df_eth, x=df_eth.columns[14])\nax14.set_title(f'Distribution of {df_eth.columns[14]}')\n \nax15 = sns.boxplot(ax = axes[5,0], data=df_eth, x=df_eth.columns[15])\nax15.set_title(f'Distribution of {df_eth.columns[15]}')\n\nax16 = sns.boxplot(ax = axes[5,1], data=df_eth, x=df_eth.columns[16])\nax16.set_title(f'Distribution of {df_eth.columns[16]}')\n\nax17 = sns.boxplot(ax = axes[5,2], data=df_eth, x=df_eth.columns[17])\nax17.set_title(f'Distribution of {df_eth.columns[17]}')\n\nax18 = sns.boxplot(ax = axes[6,0], data=df_eth, x=df_eth.columns[18])\nax18.set_title(f'Distribution of {df_eth.columns[18]}')\n\nax19 = sns.boxplot(ax = axes[6,1], data=df_eth, x=df_eth.columns[19])\nax19.set_title(f'Distribution of {df_eth.columns[19]}')\n\n\n\n\nplt.show()","df58c7b4":"#Y Target value \/ Y variable explicada\ntarget = df_eth.FLAG\n#X Features values \/ X Variables explicativas\nfeatures = df_eth.drop('FLAG', axis=1)\nprint(features.shape, target.shape)","d203b5a4":"X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 123)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","41216dc1":"trans =  PowerTransformer()\ndf_eth_arr = trans.fit_transform(X_train)\n\ndf_eth_escal=pd.DataFrame(df_eth_arr, columns=X_train.columns)\ndf_eth_escal","dad6e445":"# Distribution of features after log transformation \/ Distribucion de las variables explicativas despues de la transformacion logistica\n\nb=20\n\nfig, axes = plt.subplots(7, 3, figsize=(14, 14), constrained_layout =True)\nplt.subplots_adjust(wspace = 0.7, hspace=0.8)\naxes[-1, -1].axis('off') # hide axes\naxes[-1, -2].axis('off') # hide axes\nplt.suptitle(\"Distribution of features after log\",y=0.95, family='Sherif', size=18, weight='bold')\n \nax = sns.boxplot(ax = axes[0,0], data=df_eth_escal, x=df_eth_escal.columns[0])\nax.set_title(f'Distribution of {df_eth_escal.columns[0]}')\n \nax1 = sns.boxplot(ax = axes[0,1], data=df_eth_escal, x=df_eth_escal.columns[1])\nax1.set_title(f'Distribution of {df_eth_escal.columns[1]}')\n \nax2 = sns.boxplot(ax = axes[0,2], data=df_eth_escal, x=df_eth_escal.columns[2])\nax2.set_title(f'Distribution of {df_eth_escal.columns[2]}')\n \nax3 = sns.boxplot(ax = axes[1,0], data=df_eth_escal, x=df_eth_escal.columns[3])\nax3.set_title(f'Distribution of {df_eth_escal.columns[3]}')\n \nax4 = sns.boxplot(ax = axes[1,1], data=df_eth_escal, x=df_eth_escal.columns[4])\nax4.set_title(f'Distribution of {df_eth_escal.columns[4]}')\n \nax5 = sns.boxplot(ax = axes[1,2], data=df_eth_escal, x=df_eth_escal.columns[5])\nax5.set_title(f'Distribution of {df_eth_escal.columns[5]}')\n \nax6 = sns.boxplot(ax = axes[2,0], data=df_eth_escal, x=df_eth_escal.columns[6])\nax6.set_title(f'Distribution of {df_eth_escal.columns[6]}')\n \nax7 = sns.boxplot(ax = axes[2,1], data=df_eth_escal, x=df_eth_escal.columns[7])\nax7.set_title(f'Distribution of {df_eth_escal.columns[7]}')\n \nax8 = sns.boxplot(ax = axes[2,2], data=df_eth_escal, x=df_eth_escal.columns[8])\nax8.set_title(f'Distribution of {df_eth_escal.columns[8]}')\n \nax9 = sns.boxplot(ax = axes[3,0], data=df_eth_escal, x=df_eth_escal.columns[9])\nax9.set_title(f'Distribution of {df_eth_escal.columns[9]}')\n\nax10 = sns.boxplot(ax = axes[3,1], data=df_eth_escal, x=df_eth_escal.columns[10])\nax10.set_title(f'Distribution of {df_eth_escal.columns[10]}')\n \nax11 = sns.boxplot(ax = axes[3,2], data=df_eth_escal, x=df_eth_escal.columns[11])\nax11.set_title(f'Distribution of {df_eth_escal.columns[11]}')\n \nax12 = sns.boxplot(ax = axes[4,0], data=df_eth_escal, x=df_eth_escal.columns[12])\nax12.set_title(f'Distribution of {df_eth_escal.columns[12]}')\n \nax13 = sns.boxplot(ax = axes[4,1], data=df_eth_escal, x=df_eth_escal.columns[13])\nax13.set_title(f'Distribution of {df_eth_escal.columns[13]}')\n \nax14 = sns.boxplot(ax = axes[4,2], data=df_eth_escal, x=df_eth_escal.columns[14])\nax14.set_title(f'Distribution of {df_eth_escal.columns[14]}')\n \nax15 = sns.boxplot(ax = axes[5,0], data=df_eth_escal, x=df_eth_escal.columns[15])\nax15.set_title(f'Distribution of {df_eth_escal.columns[15]}')\n\nax16 = sns.boxplot(ax = axes[5,1], data=df_eth_escal, x=df_eth_escal.columns[16])\nax16.set_title(f'Distribution of {df_eth_escal.columns[16]}')\n\nax17 = sns.boxplot(ax = axes[5,2], data=df_eth_escal, x=df_eth_escal.columns[17])\nax17.set_title(f'Distribution of {df_eth_escal.columns[17]}')\n\nax18 = sns.boxplot(ax = axes[6,0], data=df_eth_escal, x=df_eth_escal.columns[18])\nax18.set_title(f'Distribution of {df_eth_escal.columns[18]}')\n\nplt.show()","9d43fac9":"sm = SMOTE(random_state = 25, sampling_strategy = 1.0)\nprint(f'Shape of the training before SMOTE: {df_eth_escal.shape, y_train.shape}')\n\nX_tr_resamp, Y_tr_resamp = sm.fit_resample(df_eth_escal, y_train)\nprint(f'Shape of the training after SMOTE: {X_tr_resamp.shape, Y_tr_resamp.shape}')\n","fdcb6ab9":"#Distribution of the target column before applying SMOTE \/ Distribucion de la columna objetivo antes de aplicar SMOTE\nnon_fraud = 0\nfraud = 0\n\nfor i in y_train:\n    if i == 0:\n        non_fraud +=1\n    else:\n        fraud +=1\n\n#Distribution of the target column after applying SMOTE \/ Distribucion de la columna objetivo despues de aplicar SMOTE\nno = 0\nyes = 1\n\nfor j in Y_tr_resamp:\n    if j == 0:\n        no +=1\n    else:\n        yes +=1\n\n\nprint(f'Antes del OVERSAMPLING \\n \\tNon-frauds: {non_fraud} \\n \\tFauds: {fraud}')\nprint(f'Despues del OVERSAMPLING \\n \\tNon-frauds: {no} \\n \\tFauds: {yes}')","28da1c0f":"#Logistic regression \/ Regresion logistica\nlogrmodel = LogisticRegression(random_state=42)\nlogrmodel.fit(X_tr_resamp, Y_tr_resamp)\n\n# Transform test features \/ Transformar la parte de testeo\ndf_eth_arr_test = trans.transform(X_test)\npreds = logrmodel.predict(df_eth_arr_test)","ababb3da":"print(y_test.shape)\ny_test.value_counts()","46c4b18d":"print(classification_report(y_test, preds))\nprint(confusion_matrix(y_test, preds))\nplot_confusion_matrix(logrmodel, df_eth_arr_test, y_test)","22df06a4":"#Random forest\nrfor = RandomForestClassifier(random_state=42)\nrfor.fit(X_tr_resamp, Y_tr_resamp)\npreds_rfor = rfor.predict(df_eth_arr_test)\n\nprint(classification_report(y_test, preds_rfor))\nprint(confusion_matrix(y_test, preds_rfor))\nplot_confusion_matrix(rfor, df_eth_arr_test, y_test)","6e0fd290":"df_eth_arr_test_DF=pd.DataFrame(df_eth_arr_test, columns=X_train.columns)\n\nxgbmodel = xgb.XGBClassifier(random_state=42)\nxgbmodel.fit(X_tr_resamp, Y_tr_resamp)\npreds_xgb = xgbmodel.predict(df_eth_arr_test_DF)\n\nprint(classification_report(y_test, preds_xgb))\nprint(confusion_matrix(y_test, preds_xgb))\nplot_confusion_matrix(xgbmodel, df_eth_arr_test_DF, y_test)","b3cfc7b8":"probs = rfor.predict_proba(df_eth_arr_test)\npred = probs[:,1]\nfpr, tpr, threshold = roc_curve(y_test, pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(12,8))\nplt.title('ROC for tuned XGB Classifier')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","800bd3cf":"# Save the model for further use\npickle_out = open('RandomFor_FRAUD.pickle', 'wb')\npickle.dump(rfor, pickle_out)\npickle_out.close()","12ed8a9a":"Managing the imbalance \/ Administrando el desbalance\n\nSMOTE is used as a minority class oversample variant. But first it is important to divide the dataset for training and testing.\nSe utiliza SMOTE como variante de sobremuetreo de la clase minoritaria. Pero antes es importante dividir el dataset para entrenamiento y testeo.","69f4ba0f":"# Data exploration \/ Exploracion de la informacion","67b9955b":"# ETH fraud detection\/Deteccion de fraude en ETH\n\nThis dataset contains rows of known fraud and valid transactions made through Ethereum, a type of cryptocurrency.\nEste conjunto de datos contiene filas de fraudes conocidos y transacciones v\u00e1lidas realizadas a trav\u00e9s de Ethereum, un tipo de criptomoneda.\n\n*This data set is unbalanced.*\n*Este conjunto de datos est\u00e1 desequilibrado.*\n\n\n### A continuacion, una *descripci\u00f3n* de las filas en el dataset:\n### Here is a * description * of the rows in the dataset:\n\n- Index: the index number of a row\n\n- Address: the address of the ethereum account\n\n- **FLAG**: *whether the transaction is fraud or not* (This is our \"target\" column)\n\n- Avg min between sent tnx: Average time between sent transactions for account in minutes\n\n- Avgminbetweenreceivedtnx: Average time between received transactions for account in minutes\n\n- TimeDiffbetweenfirstand_last(Mins): Time difference between the first and last transaction\n\n- Sent_tnx: Total number of sent normal transactions\n\n- Received_tnx: Total number of received normal transactions\n\n- NumberofCreated_Contracts: Total Number of created contract transactions\n\n- UniqueReceivedFrom_Addresses: Total Unique addresses from which account received transactions\n\n- UniqueSentTo_Addresses20: Total Unique addresses from which account sent transactions\n\n- MinValueReceived: Minimum value in Ether ever received\n\n- MaxValueReceived: Maximum value in Ether ever receive d\n\n- AvgValueReceived5Average value in Ether ever received\n\n- MinValSent: Minimum value of Ether ever sent\n\n- MaxValSent: Maximum value of Ether ever sent\n\n- AvgValSent: Average value of Ether ever sent\n\n- MinValueSentToContract: Minimum value of Ether sent to a contract\n\n- MaxValueSentToContract: Maximum value of Ether sent to a contract\n\n- AvgValueSentToContract: Average value of Ether sent to contracts\n\n- TotalTransactions(IncludingTnxtoCreate_Contract): Total number of transactions\n\n- TotalEtherSent:Total Ether sent for account address\n\n- TotalEtherReceived: Total Ether received for account address\n\n- TotalEtherSent_Contracts: Total Ether sent to Contract addresses\n\n- TotalEtherBalance: Total Ether Balance following enacted transactions\n\n- TotalERC20Tnxs: Total number of ERC20 token transfer transactions\n\n- ERC20TotalEther_Received: Total ERC20 token received transactions in Ether\n\n- ERC20TotalEther_Sent: Total ERC20token sent transactions in Ether\n\n- ERC20TotalEtherSentContract: Total ERC20 token transfer to other contracts in Ether\n\n- ERC20UniqSent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n\n- ERC20UniqRec_Addr: Number of ERC20 token transactions received from Unique addresses\n\n- ERC20UniqRecContractAddr: Number of ERC20token transactions received from Unique contract addresses\n\n- ERC20AvgTimeBetweenSent_Tnx: Average time between ERC20 token sent transactions in minutes\n\n- ERC20AvgTimeBetweenRec_Tnx: Average time between ERC20 token received transactions in minutes\n\n- ERC20AvgTimeBetweenContract_Tnx: Average time ERC20 token between sent token transactions\n\n- ERC20MinVal_Rec: Minimum value in Ether received from ERC20 token transactions for account\n\n- ERC20MaxVal_Rec: Maximum value in Ether received from ERC20 token transactions for account\n\n- ERC20AvgVal_Rec: Average value in Ether received from ERC20 token transactions for account\n\n- ERC20MinVal_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n\n- ERC20MaxVal_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n\n- ERC20AvgVal_Sent: Average value in Ether sent from ERC20 token transactions for account\n\n- ERC20UniqSentTokenName: Number of Unique ERC20 tokens transferred\n\n- ERC20UniqRecTokenName: Number of Unique ERC20 tokens received\n\n- ERC20MostSentTokenType: Most sent token for account via ERC20 transaction\n\n- ERC20MostRecTokenType: Most received token for account via ERC20 transactions\n\n\n\n","f0588544":"# Modeling preprocess \/ Pre proceso para el modelado","79fcb48d":"The random forest is chosen because it has better metrics.\nSe elige el random forest por tener mejores metricas.","442ba6c2":"# Modeling\/Modelado\n\n### For the model, as it is a fraud detection case (binary case), different algorithms will be tested starting with logistic regression, then decision forests (random forest) and finally XGB\n### Para el modelo,al tratarse de un caso de deteccion de fraude(caso binario), se probaran diferentes algoritmos empezando por la regresion logistica luego bosques de decision (random forest) y finalmente XGB ","43d7c809":"# Cleaning the dataset \/ Limpieza del dataset"}}