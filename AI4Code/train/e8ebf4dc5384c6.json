{"cell_type":{"0a824b3a":"code","1efdc8bc":"code","cf630a09":"code","6a932011":"code","d89bbaf2":"code","172921cd":"code","8a471d90":"code","5c62f3c3":"code","b25c75b2":"code","1a28d007":"code","1d41e1b5":"code","df84527c":"code","224eab2d":"code","c095bc5e":"code","4e443e2f":"code","66d0eb59":"code","ac01520f":"code","5af62128":"markdown","1a44ba00":"markdown","fa68b2ea":"markdown","5a27fbbd":"markdown","00657689":"markdown","bd4f9951":"markdown","c1a8cd70":"markdown","e2066a83":"markdown","94eaa909":"markdown","0565c91a":"markdown","4bda19ec":"markdown","216926e2":"markdown","3d49a9f1":"markdown","ca590953":"markdown","9e9a741c":"markdown","832920e0":"markdown","f9fed16d":"markdown","402757b9":"markdown","bebcccec":"markdown","c824caa6":"markdown","6a136be4":"markdown","2d449f82":"markdown"},"source":{"0a824b3a":"!pip install imutils","1efdc8bc":"# importing all the libraries\nimport numpy as np \nimport pandas as pd \nimport cv2\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport imutils","cf630a09":"# reading a sample image and printing it's shape\npath = \"..\/input\/visual-yolo-opencv\/\"\nimg = cv2.imread(path+\"vehicles.jpg\")\nprint(img.shape)","6a932011":"fig,axs = plt.subplots(1,2, figsize=[15,15])\naxs[0].imshow(img)\naxs[0].set_title(\"Wrong color channel: RGB image, read in BGR\", fontsize = 15)\naxs[0].axis('off')\n\ncorrect_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n\naxs[1].imshow(correct_img)\naxs[1].set_title(\"Correct color channel: RGB image changed to BGR\", fontsize = 15)\naxs[1].axis('off')\n\nplt.show()\n","d89bbaf2":"rows = open('..\/input\/visual-yolo-opencv\/synset_words.txt').read().strip().split(\"\\n\")\nclasses = [ row [ row.find(\" \") + 1:].split(\",\")[0] for row in rows]\n\nprint(\"Total number of classes are: \", len(classes))","172921cd":"print(\"Before : \", rows[:5])\nprint(\"After : \", classes[:5])","8a471d90":"google_net = cv2.dnn.readNetFromCaffe('..\/input\/visual-yolo-opencv\/bvlc_googlenet.prototxt','..\/input\/visual-yolo-opencv\/bvlc_googlenet.caffemodel')","5c62f3c3":"# cafemodel requires image dimension to be 224x224\n# blob is a 4D tensor obtained from the image\n# blob from image parameters: ( image = input image , scalefactor = if scaling the image, \n# size = size of output image, mean, swapRB = swapping RGB to BGR, crop, ddepth)\nblob = cv2.dnn.blobFromImage(correct_img, 1, (224,224))\n\n# feeding the blob as input to the network\ngoogle_net.setInput(blob)\n\n# getting the 1000 probabilities\nresult = google_net.forward()\n\n# printing the result for first 10 classes\nprint(\"Length of the result: \", len(result[0]))\n\n# finding the max 3 probabilities after sorting all of them in descending order\nindex = np.argsort(result[0])[::-1][:3]\n\nprint(\"\\n\\nTop 3 probabilities index : \", index)\n\n# based on the index, retrieve the classes from synset\nprint(\"\\nTop 3 probabilties of classes based on retrieved index\\n\")\n      \nfor (i,id) in enumerate(index):\n    print(\"{}. {} : Probability {:.3}%\".format(i+1, classes[id], result[0][id]*100) + \"\\n\")\n","b25c75b2":"def display_match(image):\n    \n    # txt to store the results\n    txt=\"\"    \n    \n    blob = cv2.dnn.blobFromImage(image, 1, (224,224))\n    \n    google_net.setInput(blob)\n\n    result = google_net.forward()\n\n    index = np.argsort(result[0])[::-1][:3]\n    \n    for (i,id) in enumerate(index):\n        txt += \"{}. {} : Probability {:.3}%\".format(i+1, classes[id], result[0][id]*100) + \"\\n\"\n            \n    return txt        ","1a28d007":"result = display_match(correct_img)\n\nplt.figure(figsize=[10,10])\nplt.imshow(correct_img)\nplt.title(result)\nplt.axis('off')\nplt.show()","1d41e1b5":"img_list = [\"beach.jpg\",\"cycle.jpg\",\"dog.jpg\",\"elephant.jpg\",\"tiger.jpg\",'laptop.jpg']\n\nfor i in range(len(img_list)):\n    img_list[i] = path + img_list[i]","df84527c":"fig,axs = plt.subplots(3,2, figsize=[15,15])\nfig.subplots_adjust(hspace=.5)\n\ncount=0\nfor i in range(3):    \n    for j in range(2):        \n        new_img = cv2.imread(img_list[count])\n        new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n        txt = display_match(new_img)\n        #cv2.putText(new_img, txt, (0, 25 + 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n        \n        axs[i][j].imshow(new_img)\n        axs[i][j].set_title(txt, fontsize = 12)\n        axs[i][j].axis('off')\n        count+=1\n\nplt.suptitle(\"Top 3 predictions shown in title\", fontsize = 18)\nplt.show()","224eab2d":"img = cv2.imread(img_list[4])\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\ntxt = display_match(img)\nline = txt.split(\"\\n\")\n\nfor i in range(3):\n    cv2.putText(img, str(line[i]), (10, 30 + 40*i), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 3)\n\n\nplt.figure(figsize=[10,10])\nplt.imshow(img)\nplt.title(\"Writing probability on the image\", fontsize = 15)\nplt.axis('off')\n\nplt.show()\n","c095bc5e":"vid = cv2.VideoCapture('..\/input\/visual-yolo-opencv\/computer.mp4')\n\nfourcc = cv2.VideoWriter_fourcc(*'MP4V')\nout = cv2.VideoWriter('output_computer.mp4',fourcc, 20.0, (640, 640))\n\nif(vid.isOpened==False):\n    print(\"Can't open the video file\")\n    \ntry:\n    while(True):\n\n        ret, frame = vid.read()\n        if not ret:\n            vid.release()\n            out.release()\n            print(\"Completed! Read all the frames.\")\n            break\n            \n        txt = display_match(frame)\n        line = txt.split(\"\\n\")\n        for i in range(3):\n            cv2.putText(frame, str(line[i]), (10, 30 + 40*i), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255,0,0), 2)\n\n        resized_frame = cv2.resize(frame,(640,640))\n        out.write(resized_frame)\n        plt.imshow(resized_frame)\n        plt.show()\n        \n        clear_output(wait=True)\n\nexcept KeyboardInterrupt:\n    vid.release()\n    print(\"Error in reading frames\")","4e443e2f":"from IPython.display import YouTubeVideo\nYouTubeVideo('EX7ULuSPpaY', width=800, height=450)","66d0eb59":"vid = cv2.VideoCapture('..\/input\/visual-yolo-opencv\/video.mp4')\n\nfourcc = cv2.VideoWriter_fourcc(*'MP4V')\nout = cv2.VideoWriter('output_study.mp4',fourcc, 20.0, (1800, 1800))\n\nif(vid.isOpened==False):\n    print(\"Can't open the video file\")\n\ntry:\n    while(True):\n        \n           \n        ret, frame = vid.read()\n        if not ret:\n            vid.release()\n            out.release()\n            print(\"Completed! Read all the frames.\")\n            break\n            \n        txt = display_match(frame)\n        line = txt.split(\"\\n\")\n        for i in range(3):\n            cv2.putText(frame, str(line[i]), (70, 300 + 250*i), cv2.FONT_HERSHEY_SIMPLEX, 8, (255,0,0), 25)\n\n        resized_frame = cv2.resize(frame,(1800,1800))\n        out.write(resized_frame)\n        #plt.imshow(resized_frame)\n        #plt.show()\n        \n        #clear_output(wait=True)\n\nexcept KeyboardInterrupt:\n    vid.release()\n    print(\"Error in reading frames\")","ac01520f":"YouTubeVideo('liUmyzGuc70', width=800, height=450)","5af62128":"Here, the image contians 2584 x 4536 pixels and it has 3 colors channel which is RGB (Red Green Blue).","1a44ba00":"I have used a directory : \"visual-yolo-opencv\" to store images, videos and the caffe model. You can create your own folder to include all the files. The list of files are mentioned in the references at the bottom.","fa68b2ea":"Cv2 works with BGR (BLue Green Red). Thus, any image given in RGB (Red Green Blue) format will be treated as BGR. An example is shown below. The actual image is the second one.","5a27fbbd":"Now let's define a function to reuse the same code for using it on multiple images and videos","00657689":"imutils is necessary for changing the dimension of the images to generate it. It is not present Kaggle by default.Thus, downloading it first. ","bd4f9951":"## Applying the model ##","c1a8cd70":"**Background info:**\n\nSynset or synonyms set is a set of 1000 unique classes like tractor, tiger, shark etc.\n\nCaffe model is calculating probability for all these 1000 classes based on their index values. It means that the results obtained after feeding the image to the model will contain the proabiblity of the image belonging to each of thses 1000 classes. \n\nHowever, the proability for let's say a shark's image will be higher for class 'shark' than the probability of shark's image for class 'tractor'. \n\nThus we will have to choose top 3 or 5 probabilties out of these 1000. And based on the index returned we can find the correspondng class name.  \n\nSome synset classes contains synonym names and their id too. We are storing only the first name in a seperate list. We can always access the class name based on index thus removing the id too.\n\nThe link for Synset is provided below.\n\nLink : [Synset words](https:\/\/github.com\/HoldenCaulfieldRye\/caffe\/blob\/master\/data\/ilsvrc12\/synset_words.txt)","e2066a83":"In this project we will try to identify the objects from a set of images and videos. For this purpose we will use BVLC GoogleNet Caffe model which is already pre-trained on 1000 classes including animals and objects. So, we don't need to train any model. Let's start.","94eaa909":"## Adding the files","0565c91a":"[Video source: Reddit reaction GIFs](https:\/\/www.reddit.com\/r\/reactiongifs\/comments\/2wcxt8\/mrw_i_go_to_post_a_joke_my_friend_told_me_to\/)","4bda19ec":"The next step is to read the network model stored in the caffe model.\n\nThe prototxt contains the deep learning network architecture in Json format. These information includes the layer type (eg: RELU), weights etc information. The Caffe model is the pre-trained model. Thus, we have the model and we have it's architecture. Thus we can use it to find the probabilities.\n\n[BVLC GoogleNet Prototxt](https:\/\/github.com\/opencv\/opencv_extra\/blob\/master\/testdata\/dnn\/bvlc_googlenet.prototxt)\n\n[BVLC Caffe model](https:\/\/github.com\/BVLC\/caffe\/tree\/master\/models\/bvlc_googlenet)","216926e2":"The following markdown shows the synset before and after removing synonym names and id","3d49a9f1":"## References:##\n\nFiles required for training:\n\n1. [Synset words](https:\/\/github.com\/HoldenCaulfieldRye\/caffe\/blob\/master\/data\/ilsvrc12\/synset_words.txt)\n2. [BVLC GoogleNet Prototxt](https:\/\/github.com\/opencv\/opencv_extra\/blob\/master\/testdata\/dnn\/bvlc_googlenet.prototxt)\n3. [BVLC Caffe model](https:\/\/github.com\/BVLC\/caffe\/tree\/master\/models\/bvlc_googlenet)\n\nImages:\n\n1. [Photo by Nik Shuliahin on Unsplash](https:\/\/unsplash.com\/photos\/pGwXiFyB7JE)\n2. [Photo by bennett tobias on Unsplash](https:\/\/unsplash.com\/photos\/xOVS_XU1eeA)\n3. [Photo by AJ Robbie on Unsplash](https:\/\/unsplash.com\/photos\/BuQ1RZckYW4)\n4. [Photo by Radek Grzybowski on Unsplash](https:\/\/unsplash.com\/photos\/eBRTYyjwpRY)\n5. [Photo by Nick Karvounis on Unsplash](https:\/\/unsplash.com\/photos\/-KNNQqX9rqY)\n6. [Photo by Anoir Chafik on Unsplash](https:\/\/unsplash.com\/photos\/2_3c4dIFYFU)\n7. [Photo by Neil Thomas on Unsplash](https:\/\/unsplash.com\/photos\/tMkEedbhuDo)\n\nVideos:\n1. [A Group Of Young People In Discussion Of A Group Project: By Pressmaster on Pexels](https:\/\/www.pexels.com\/video\/a-group-of-young-people-in-discussion-of-a-group-project-3209298\/)\n2. [MRW I go to post a joke my friend told me to \/r\/jokes and figure out that's where he got the joke from.](https:\/\/www.reddit.com\/r\/reactiongifs\/comments\/2wcxt8\/mrw_i_go_to_post_a_joke_my_friend_told_me_to\/)\n","ca590953":"# Using OpenCV and BVLC GoogleNet to identify objects","9e9a741c":"Applying the function on multiple images:","832920e0":"We have try to predict the images. Now let's try it for videos.","f9fed16d":"Applying it on another video:\n\nVideo source: [A Group Of Young People In Discussion Of A Group Project: By Pressmaster on Pexels](https:\/\/www.pexels.com\/video\/a-group-of-young-people-in-discussion-of-a-group-project-3209298\/)\n","402757b9":"The results are uploaded on youtube and then shown here","bebcccec":"Let's see how we can use the model now:","c824caa6":"Again, the results are uploaded on Youtube and shown here","6a136be4":"## Thank You ##","2d449f82":"We can even type the predictions on the top of the image"}}