{"cell_type":{"2d61af79":"code","c2261542":"code","07e2cccb":"code","b7cec400":"code","2c2d1686":"code","fd7d8675":"code","27bfc49f":"code","380411ee":"code","1d51b821":"code","1d0a6db8":"code","63884d3d":"code","4748d140":"code","689ea146":"code","7b835373":"code","2d7326d9":"code","ce18c00a":"code","f03c1071":"code","3ea34121":"code","48183e9f":"code","4acf26dd":"code","2e7e3155":"markdown","04a41ddf":"markdown","101595f4":"markdown","f80ffe31":"markdown","d59bd1dc":"markdown","bfcf5333":"markdown","9ab6cb4a":"markdown","29c7a533":"markdown","eca15ec8":"markdown","90988725":"markdown","423bf0bd":"markdown","1332a7d4":"markdown","22df8618":"markdown","43facbaf":"markdown","308c19bc":"markdown"},"source":{"2d61af79":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import metrics\nfrom math import sqrt\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport time\nimport itertools\nimport warnings\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\n\nwarnings.filterwarnings(\"ignore\")","c2261542":"# generamos una lista de 110 a\u00f1os para nuestre serie temporal \na\u00f1os = np.arange(1821, 1931)\n\n# la cantidad de pieles de linces captadas cada a\u00f1o\n\nPieles = [\n269, 321, 585, 871, 1475, 2821, 3928, 5943, 4950, 2577,\n523, 98, 184, 279, 409, 2285, 2685, 3409, 1824, 409,\n151, 45, 68, 213, 546, 1033, 2129, 2536, 957, 361,\n377, 225, 360, 731, 1638, 2725, 2871, 2119, 684, 299,\n236, 245, 552, 1623, 3311, 6721, 4254, 687, 255, 473,\n358, 784, 1594, 1676, 2251, 1426, 756, 299, 201, 229,\n469, 736, 2042, 2811, 4431, 2511, 389, 73, 39, 49,\n59, 188, 377, 1292, 4031, 3495, 587, 105, 387, 758,\n1307, 3465, 6991, 6313, 3794, 1836, 345, 382, 808, 1388,\n2713, 3800, 3091, 2985, 790, 674, 81, 80, 108, 229,\n1132, 2432, 3574, 2935, 1537, 529, 485, 662, 1000, 1590\n]","07e2cccb":"# generamos el dataframe completo de nuestro an\u00e1lisis\ndf = pd.DataFrame([a\u00f1os, Pieles]).T\ndf.columns = [\"A\u00f1o\", \"Pieles\"]\ndf[\"Pieles_log\"] = df[\"Pieles\"].apply(np.log)\ndf[\"Pieles_log_diff\"] = df[\"Pieles_log\"].diff()\ndf[\"A\u00f1o\"] = pd.to_datetime(df[\"A\u00f1o\"], format = \"%Y\")\ndf.set_index(\"A\u00f1o\", inplace = True)\ndf.dropna(inplace = True, axis = \"rows\")\ndf.head()","b7cec400":"# separar x y la y para el gr\u00e1fico\nx = df.index\n\ny = df[\"Pieles\"]\ny_media = [np.mean(y) for _ in y]\n\ny_log = df[\"Pieles_log\"]\ny_log_media = [np.mean(y_log) for _ in y_log]\n\ny_log_diff = df[\"Pieles_log_diff\"]\ny_log_diff_mean = [np.mean(y_log_diff) for _ in y_log_diff]\n\n# visualizaci\u00f3n de los datos anteriores a los largo de los a\u00f1os\nfig = plt.figure(figsize = (10, 10))\nax1, ax2, ax3 = fig.subplots(3, 1)\n\n# la serie original parece ser no estacionaria\n# si nos fijamos en su comportamiento, vemos muchos picos y que la media de diferentes\n# tramos de la serie es diferente.\n# adem\u00e1s la covarianza entre diferentes tramos tambi\u00e9n parece distinta.\nax1.plot(x, y, label = \"Serie Original\")\nax1.plot(x, y_media, label = \"Media de la Serie Original\")\nax1.set_ylim(0, np.max(y)*1.3)\nax1.legend(loc = \"upper left\")\n\n# Si transformamos la serie utilizando el logaritmo neperiano (ln)\n# tenemos una serie que YA es estacionaria en media y que oscila entorno\n# a 7.\nax2.plot(x, y_log, label = \"Serie Log.\")\nax2.plot(x, y_log_media, label = \"Media de la Serie Log.\")\nax2.set_ylim(0, np.max(y_log)*1.3)\nax2.legend(loc = \"lower left\")\n\n# Si aplicamos una diferenciaci\u00f3n a al serie logar\u00edtmica, seguimos teniendo\n# una serie estacionaria, pero esta vez, la media de la serie oscila entorno al cero.\n\n# La diferenciaci\u00f3n de una serie estacionaria SIEMPRE da lugar a otra serie estacionaria.\n# Por este motivo, no har\u00eda falta hacer la diferencia y con la serie transformada (logar\u00edtmica)\n# es suficiente.\n\nax3.plot(x, y_log_diff, label = \"Serie Logar\u00edtmica diferenciada\")\nax3.plot(x, y_log_diff_mean, label = \"Media de la Serie. Log. Diff\")\nax3.set_ylim(np.min(y_log_diff)*1.5, np.max(y_log_diff)*1.3)\nax3.legend(loc = \"lower left\")\n\nfig.suptitle(\"Capturaci\u00f3n de Pieles de Lince y sus transformaciones a lo largo de los a\u00f1os a lo largo de los a\u00f1os\");","2c2d1686":"\nfor serie, nombre_serie in zip([y, y_log, y_log_diff], [\"Serie Original\", \"Serie Log.\", \"Serie. Log. Diff\"]):\n    \n    print(\"------------------------------------------------------------------\")\n    \n    print(\"Estamos trabajando con la serie {}\\n\".format(nombre_serie))\n    resultado_analisis = adfuller(serie)\n    \n    valor_estadistico_adf = resultado_analisis[0]\n    p_valor = resultado_analisis[1]\n    \n    print(\"Valor estadistico de ADF de las tablas precalculadas: {}\".format(-2.89))\n    print(\"Valor estadistico de ADF: {}\\n\".format(valor_estadistico_adf))\n    \n    print(\"Nivel de significaci\u00f3n para tomar la serie como estacionaria {}\".format(0.05))\n    print(\"p-valor: {}\\n\".format(p_valor))\n    ","fd7d8675":"LAGS = 24\n\nfig = plt.figure(figsize = (10, 10))\n\n((ax1, ax2), (ax3, ax4), (ax5, ax6)) = fig.subplots(3, 2)\n\n# ----------------------------------------------------------------------------------------------------\n# plot the data using the built in plots from the stats module\nplot_acf(y, ax = ax1, lags = LAGS, title = \"Autocorrelaci\u00f3n\")\nplot_pacf(y, ax = ax2, lags = LAGS, title = \"Autocorrelaci\u00f3n Parcial\")\n\nplot_acf(y_log, ax = ax3, lags = LAGS, title = \"Autocorrelaci\u00f3n\")\nplot_pacf(y_log, ax = ax4, lags = LAGS, title = \"Autocorrelaci\u00f3n Parcial\")\n\nplot_acf(y_log_diff, ax = ax5, lags = LAGS, title = \"Autocorrelaci\u00f3n\")\nplot_pacf(y_log_diff, ax = ax6, lags = LAGS, title = \"Autocorrelaci\u00f3n Parcial\")\n\nfig.tight_layout()","27bfc49f":"serie_a_predecir = y_log","380411ee":"y_index = serie_a_predecir.index\n\ndate_train = int(len(y_index)*0.9)\n\ny_train = serie_a_predecir[y_index[:date_train]]\ny_test = serie_a_predecir[y_index[date_train:len(y_index)]]","1d51b821":"y_train.tail()","1d0a6db8":"y_test.head()","63884d3d":"# Para hacer el gridsearch, vamos a calcular los posibles valores que vamos a pasarle al modelo.\np = d = q = range(0, 3)\npdq = list(itertools.product(p, d, q))\n\n# Vamos a utilizar el modelo SARIMAX, porque en su implementaci\u00f2n en Python existen herramientas adicionales\n# que nos facilitan el an\u00e1lisis y que no est\u00e1n disponibles en la implementaci\u00f3n de ARIMA.\n\n# Ahora bien, SARIMAX es un modelo ARIMA pero con un componente estacional (la leta S de Seasonal) y tambi\u00e9n\n# un componente ex\u00f3geno (X de eXogenous regressors)\n# Por tanto un modelo SARIMAX de (1, 1, 1) x (0, 0, 0, 0)\n# Es un modelo ARIMA (1, 1, 1)\n\n# En caso de querer probar un modelo SARIMAX completo, ejecutar la siguiente l\u00ednea de itertools.\n# seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n\n# Los dejamos a cero para s\u00f3lo analizar un modelo ARIMA.\nseasonal_pdq = [(0, 0, 0, 0)]\n\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[0]))\nprint('SARIMAX: {} x {}'.format(pdq[3], seasonal_pdq[0]))","4748d140":"st = time.time()\n\nbest_score = 0\nbest_params = None\nbest_seasonal_params = None\n\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            \n            mod = sm.tsa.statespace.SARIMAX(y_train,\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity = False,\n                                            enforce_invertibility = False)\n\n            results = mod.fit()\n\n            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n            \n            # guardamos el mejor resultado\n            if best_score == 0:\n                best_score = results.aic\n                best_params = param\n                best_seasonal_params = param_seasonal\n                \n            elif abs(results.aic) < abs(best_score):\n                best_score = results.aic\n                best_params = param\n                best_seasonal_params = param_seasonal\n            \n        # alguna combinaci\u00f3n de par\u00e1metros en SARIMAX, no son v\u00e1lidos\n        # y los vamos a cazar con un except\n        except:\n            continue\n\net = time.time()\n\nprint(\"La b\u00fasqueda de par\u00e1metros no ha llevado {} minutos!\".format((et - st)\/60))","689ea146":"print(\"El mejor modelo es {}, \\nCon un AIC de {}\".format(best_params, best_score))","7b835373":"# Entrenamos el modelo con los mejores parametros.\n\nmod = sm.tsa.statespace.SARIMAX(y_train,\n                                order = best_params,\n                                seasonal_order = param_seasonal,\n                                enforce_stationarity = False,\n                                enforce_invertibility = False)\n\nresults = mod.fit()","2d7326d9":"results = mod.fit()\n\nprint(results.summary().tables[1])","ce18c00a":"results.plot_diagnostics(figsize = (15, 12), lags = 3);","f03c1071":"# Para hacer una predicci\u00f3n es suficiente con especificar el n\u00famero de steps\/pasos futuros a estimar.\npred_uc = results.get_forecast(steps = len(y_test))\n\n# Calcula el intervalo de confianza de la predicci\u00f3n.\npred_ci = pred_uc.conf_int()","3ea34121":"ax = serie_a_predecir.plot(label = 'Valores reales', figsize = (20, 15))\n\npred_uc.predicted_mean.plot(ax = ax, label = 'Predicci\u00f3n')\n\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color = 'k', alpha = .25)\n\nax.set_xlabel('A\u00f1o')\nax.set_ylabel('Pieles Capturadas')\n\nplt.legend()\nplt.show()","48183e9f":"y_pred = pred_ci.iloc[:, 0]","4acf26dd":"# El RMSE es de 2.52\nrmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n\nprint(\"El modelo ARIMA con los parametros {}, ha dado un rmse en test de {}\".format(best_params, round(rmse, 2)))","2e7e3155":"<a id = \"model_interpretation\"><\/a>\n# Interpretaci\u00f3n del mejor modelo\n[Volver al \u00edndice](#table_of_contents)","04a41ddf":"<a id = \"stationarity_check\"><\/a>\n# Comprobaci\u00f3n de la estacionaridad de la serie\n\n[Volver al \u00edndice](#table_of_contents)","101595f4":"Como hemos visto en la sesi\u00f3n te\u00f3rica, un modelo ARIMA se repsenta como ARIMA (p, d, q) donde:\n\nAR (p): representa la parte \"Autorregresiva\" del modelo. La intuici\u00f3n b\u00e1sica consiste en que los valores pasados m\u00e1s pr\u00f3ximos al momento \"t\", tendr\u00e1n mayor impacto en los valores presentes. Para determinar el orden \"p\" del modelo, podemos utilizar el plot de autocorrelaci\u00f3n parcial\n\nI (d): representa la parte \"Integral\" del modelo y este par\u00e1metro del modelo nos dice cuantos diferenciaciones (restas de la serie contra si misma) se tienen que llevar a cabo para convertir la serie en estacionaria.\n\nMA (q): representa la parte de \"Medias M\u00f3viles\". Como vimos, esto implica que el error del modelo se establece como una combinaci\u00f2n lineal de los errores observados en el pasado. Para determinar el orden \"q\" del modelo, podemos utilizar el plot de autocorrelaci\u00f3n.\n\nEl modelo b\u00e1sico de ARIMA se puede extender m\u00e1s alla incorporando la estacionalidad de la serie y variables ex\u00f3genas. En este caso estar\u00edamos hablado del modelo SARIMAX representado por (p, d, q) x (P, D, Q) S: donde los par\u00e1metros (P, D, Q) representan la misma idea que los (p, d, q) pero tratan sobre la parte estacional de la serie. \n\nEl par\u00e1metro S a su vez representa el n\u00famero de periodos que tienen que pasar para que la estacionalidad se repita: 12 para meses, 4 para trimestres etc.\n\nA continuaci\u00f3n utilizaremos una \"Gridsearch\" b\u00e1sico para buscar los par\u00e1metros \u00f3ptimos del modelo ARIMA.","f80ffe31":"Vemos de la tabla de coeficientes, que a pesar de seleccionar el modelo con el mejor AIC, tenemos 3 parametros que no son significativos porque su p - valor es superior a 0.05.\n\nEstamos hablando del ma.L1, ma.L2 y sigma2.","d59bd1dc":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#\u00cdndice\" data-toc-modified-id=\"\u00cdndice-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>\u00cdndice<\/a><\/span><\/li><li><span><a href=\"#Importaci\u00f3n-de-las-principales-librer\u00edas\" data-toc-modified-id=\"Importaci\u00f3n-de-las-principales-librer\u00edas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Importaci\u00f3n de las principales librer\u00edas<\/a><\/span><\/li><li><span><a href=\"#Importaci\u00f3n-de-datos\" data-toc-modified-id=\"Importaci\u00f3n-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Importaci\u00f3n de datos<\/a><\/span><\/li><li><span><a href=\"#An\u00e1lisis-exploratorio-de-datos\" data-toc-modified-id=\"An\u00e1lisis-exploratorio-de-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>An\u00e1lisis exploratorio de datos<\/a><\/span><\/li><li><span><a href=\"#Comprobaci\u00f3n-de-la-estacionaridad-de-la-serie\" data-toc-modified-id=\"Comprobaci\u00f3n-de-la-estacionaridad-de-la-serie-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Comprobaci\u00f3n de la estacionaridad de la serie<\/a><\/span><\/li><li><span><a href=\"#Separaci\u00f3n-Train-y-Test\" data-toc-modified-id=\"Separaci\u00f3n-Train-y-Test-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Separaci\u00f3n Train y Test<\/a><\/span><\/li><li><span><a href=\"#Gridsearch:-la-b\u00fasqueda-de-los-par\u00e1metros-\u00f3ptimos-para-el-modelo-ARIMA\" data-toc-modified-id=\"Gridsearch:-la-b\u00fasqueda-de-los-par\u00e1metros-\u00f3ptimos-para-el-modelo-ARIMA-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Gridsearch: la b\u00fasqueda de los par\u00e1metros \u00f3ptimos para el modelo ARIMA<\/a><\/span><\/li><li><span><a href=\"#Interpretaci\u00f3n-del-mejor-modelo\" data-toc-modified-id=\"Interpretaci\u00f3n-del-mejor-modelo-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;<\/span>Interpretaci\u00f3n del mejor modelo<\/a><\/span><\/li><li><span><a href=\"#Predicci\u00f3n-utilizando-el-modelo\" data-toc-modified-id=\"Predicci\u00f3n-utilizando-el-modelo-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;<\/span>Predicci\u00f3n utilizando el modelo<\/a><\/span><\/li><\/ul><\/div>","bfcf5333":"<a id = \"eda\"><\/a>\n# An\u00e1lisis exploratorio de datos \n[Volver al \u00edndice](#table_of_contents)","9ab6cb4a":"<a id = 'table_of_contents'><\/a>\n\n# \u00cdndice\n\n\n[Importaci\u00f3n de las principlaes librer\u00edas](#imports)\n\n[Importaci\u00f3n de datos](#data)\n\n[An\u00e1lisis exploratorio de datos](#eda)\n\n[Comprobaci\u00f3n de la estacionaridad de la serie](#stationarity_check)\n\n[Separaci\u00f3n Train y Test](#train_test_split)\n\n[Gridsearch: la b\u00fasqueda de los par\u00e1metros \u00f3ptimos para el modelo ARIMA](#gridsearch)\n\n[Interpretaci\u00f3n del mejor modelo](#model_interpretation)\n\n[Predicci\u00f3n utilizando el modelo](#forecasting)","29c7a533":"Interprentado los gr\u00e1ficos podemos observar lo siguiente:\n\n1. Arriba a la izquiera: los residuos del modelo parece que siguen un proceso de Ruido Blanco (White Noise) y no son predecibles. Esto implica que nuestro modelo ha extra\u00eddo toda la informaci\u00f3n de los datos.\n2. Arriba a la derecha: vemos que la distribuci\u00f3n de los residuos sigue una distribuci\u00f3n pr\u00f3xima a la Normal (0, 1).\n3. Abajo a la derecha: vemos que la autocorrelaci\u00f3n parcial entre los residuos y residuos - k, dan lugar a valores no significativos. Esto implica que no \"nos queda\" informaci\u00f3n a extraer de los residuos, es decir el modelo no ha sido capaz de reproducir el patr\u00f3n de comportamiento sistem\u00e1tico de la serie y habr\u00eda que reformularlo.\n4. Abajo a la izquierda: la distrbuci\u00f3n ordenada de los residuos sigue una Normal.","eca15ec8":"<a id = \"forecasting\"><\/a>\n# Predicci\u00f3n utilizando el modelo\n\n[Volver al \u00edndice](#table_of_contents)","90988725":"El \u00edndice de AIC es Akaike Information Criterion y sirve para elegir un modelo entre un conjunto de posibles modelos.\n\nEl \u00edndice calcula la distancia de Kullback - Leibler entre el modelo y la serie.\n\nUna forma de interpretar el \u00edndice es: buscamos el modelo con el menor \u00edndice porque este es el m\u00e1s simple que se ajusta a los datos.","423bf0bd":"<a id = \"train_test_split\"><\/a>\n# Separaci\u00f3n Train y Test\n\n[Volver al \u00edndice](#table_of_contents)","1332a7d4":"<a id = \"gridsearch\"><\/a>\n# Gridsearch: la b\u00fasqueda de los par\u00e1metros \u00f3ptimos para el modelo ARIMA\n\n[Volver al \u00edndice](#table_of_contents)","22df8618":"Si nos fijamos en los gr\u00e1ficos que obtenemos, vemos que hay para la serie y_log, el gr\u00e1fico de autocorrelaci\u00f3n parcial (segunda fila a la derecha) tiene 3 valores por encima del \u00e1rea sombreada por tanto estos valores son significativamente distintos de cero. Podemos suponer analizando esta serie que el proceso estoc\u00e1stico que ha generado la serie es un AR(3).\n\nAhora bien, tambi\u00e9n si analizamos conjuntamente con el ACF (gr\u00e1ficos a la izquierda) vemos que el 3 valor es pr\u00f3ximo a \u00e1rea sombreada y por tanto, podemos sugerir otro proceso que haya podido generar este serie como un ARMA(2, 1).\n\nTal y como sugiere la metodolog\u00eda Box - Jenkins: en la fase de an\u00e1lisis de los ACF y PACF, tenemos que \"acotar\" los posibles modelos que hayan podido generar la serie siempre optando por el m\u00e1s sencillo de todos.\n\nEn la fase de identificaci\u00f3n y estimaci\u00f3n de param\u00e9tros, tambi\u00e9n podemos calcular el par\u00e1metro &delta; (delta) que vendr\u00eda a ser la constante del modelo o la media.","43facbaf":"<a id = \"imports\"><\/a>\n# Importaci\u00f3n de las principales librer\u00edas\n\n[Volver al \u00edndice](#table_of_contents)","308c19bc":"<a id = \"data\"><\/a>\n# Importaci\u00f3n de datos\n\n[Volver al \u00edndice](#table_of_contents)"}}