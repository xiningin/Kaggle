{"cell_type":{"993b47b4":"code","04082683":"code","c5c1e17d":"code","5d47e56f":"code","8807a83a":"code","c38aeaa5":"code","0a9b2a58":"code","14fcc606":"code","d4406a7b":"code","f36ead82":"code","ef67f0e6":"code","7e894f88":"code","071f728f":"code","fb6e3283":"code","711b2425":"code","882c6b10":"code","94b0bc00":"code","2b93ca53":"code","0b245d4a":"code","d83e1988":"code","9ef4d76c":"code","112c2771":"code","0b7088ff":"code","9f2ed6db":"code","706aaaa8":"code","0ac98f09":"code","af61031a":"code","4a907a3b":"code","c04ac7c8":"code","22aa71ea":"code","cf7b6b16":"code","44ae58ba":"code","8f8ff2fe":"code","dec55e6b":"code","f200a736":"code","db6ba8eb":"code","df770dfc":"code","3e15484b":"code","d329ff34":"code","881a6eb8":"code","560fc166":"code","49fa2caf":"code","4fd0a7d2":"code","16ff4920":"code","196f9929":"code","677a21d0":"code","87f989cd":"code","45db74c1":"code","3e0c26cd":"code","802ca0f5":"code","1f1f77bb":"code","775f1cc6":"code","c83f8a34":"code","28801941":"code","518ce490":"code","35008809":"code","c51fe5d5":"code","aa8f4dd3":"code","7dc03577":"code","25156d3c":"code","aa4093af":"code","55fb80ef":"markdown","5bdbb5e0":"markdown","aad54dd2":"markdown","c4d3bb09":"markdown","5d76beb9":"markdown","a3bc41b1":"markdown","c588bb1e":"markdown","e960fe27":"markdown","1578ff8b":"markdown","69d3e0ca":"markdown","44a1dc89":"markdown","9b119bf5":"markdown","233015e6":"markdown","302a5818":"markdown","ba3b59db":"markdown","2ebecbdd":"markdown","c14e5426":"markdown","dd5875e8":"markdown","d5fbe97a":"markdown","a7170d68":"markdown","3488846b":"markdown","b3a4f5e5":"markdown","d01e0224":"markdown","9a2ae25e":"markdown","cc6a5248":"markdown","92f447e7":"markdown","a540fbec":"markdown","b570e2a7":"markdown","063a3423":"markdown","70993a17":"markdown","f1416043":"markdown","30e67282":"markdown","0ed27e99":"markdown","51334b04":"markdown","41a45531":"markdown","f588d05c":"markdown","6114d853":"markdown","0a39c8fc":"markdown","0f885be3":"markdown","990dee72":"markdown","c0394765":"markdown","2dc4cdc4":"markdown","4744123f":"markdown","373d9eee":"markdown","aab203b6":"markdown","9769324c":"markdown","64b735fe":"markdown","34451d57":"markdown","94baad6f":"markdown","8f906749":"markdown"},"source":{"993b47b4":"# Import Relevant Libraries\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix,f1_score,accuracy_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import StackingClassifier","04082683":"#Read the Data File\nparkDF = pd.read_csv(\"..\/input\/parkinsons-data-set\/parkinsons.data\")\nparkDF.head()","c5c1e17d":"# Let us ensure that there are no Null Values\nprint(\"Null Values Check\\n\")\nprint(parkDF.isnull().sum())\nprint(\"\\n\\n NAN Values Check \\n\")\nprint(parkDF.isna().sum())","5d47e56f":"parkDF.dtypes","8807a83a":"cols = parkDF.columns[1:]\nprint(cols)\nprint()\nprint(\"No. of Columns: \", len(cols))","c38aeaa5":"numRows = parkDF.count(axis=0)[0]\nprint(\"Total no. of rows in the data: \", numRows)","0a9b2a58":"numparkPat = parkDF[parkDF[\"status\"] == 1].status.count()\nprint(\"Parkinsons Patients:\\n\", numparkPat)\nprint(\"Percentage of patients with Parkinsons:\\n\", round((numparkPat * 100)\/numRows))","14fcc606":"parkDF.describe().T","d4406a7b":"fig,axes=plt.subplots(5,5,figsize=(15,15))\naxes=axes.flatten()\n\n# Skipping name since it's a string column \nfor i in range(1,len(parkDF.columns)-1):\n    sns.boxplot(x='status',y=parkDF.iloc[:,i],data=parkDF,orient='v',ax=axes[i])\nplt.tight_layout()\nplt.show()","f36ead82":"corr = parkDF.corr()\nplt.figure(figsize=(12,10))\nsns.heatmap(corr,annot=True, square=True)","ef67f0e6":"sns.distplot(parkDF[\"MDVP:Fo(Hz)\"])","7e894f88":"sns.distplot(parkDF[\"MDVP:Flo(Hz)\"])","071f728f":"sns.distplot(parkDF[\"MDVP:Jitter(%)\"])","fb6e3283":"sns.distplot(parkDF[\"MDVP:Jitter(Abs)\"])","711b2425":"sns.distplot(parkDF[\"MDVP:RAP\"])","882c6b10":"sns.distplot(parkDF[\"MDVP:PPQ\"])","94b0bc00":"sns.distplot(parkDF[\"Jitter:DDP\"])","2b93ca53":"sns.distplot(parkDF[\"MDVP:Shimmer\"])","0b245d4a":"sns.distplot(parkDF[\"MDVP:Shimmer(dB)\"])","d83e1988":"sns.distplot(parkDF[\"Shimmer:APQ3\"])","9ef4d76c":"sns.distplot(parkDF[\"Shimmer:APQ5\"])","112c2771":"sns.distplot(parkDF[\"MDVP:APQ\"])","0b7088ff":"sns.distplot(parkDF[\"Shimmer:DDA\"])","9f2ed6db":"sns.distplot(parkDF[\"NHR\"])","706aaaa8":"sns.distplot(parkDF[\"HNR\"])","0ac98f09":"sns.distplot(parkDF[\"RPDE\"])","af61031a":"sns.distplot(parkDF[\"DFA\"])","4a907a3b":"sns.distplot(parkDF[\"spread1\"])","c04ac7c8":"sns.distplot(parkDF[\"spread2\"])","22aa71ea":"sns.distplot(parkDF[\"D2\"])","cf7b6b16":"sns.distplot(parkDF[\"PPE\"])","44ae58ba":"#Lets first drop the name column as it has no impact on the status\nparkDF.drop(columns ='name',inplace=True)\n#Let us also drop a few parameters that have a strong relationship with another\nparkDF.drop(columns ='Shimmer:DDA',inplace=True)\nparkDF.drop(columns ='Jitter:DDP',inplace=True)\nparkDF.drop(columns ='MDVP:RAP',inplace=True)\n\nparkDF.head()\nX = parkDF.drop('status', axis=1) # X axis without the Target Variable\ny= parkDF['status'] # target variable on y Axis\ncols = X.columns\nprint(cols)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)","8f8ff2fe":"X_train.head()","dec55e6b":"# Let us scale training data set test data using MinMaxScaler\nscaler = MinMaxScaler()\ntrain_scaled = scaler.fit_transform(X_train)\ntest_scaled = scaler.fit_transform(X_test)\n\nX_train_scaled = pd.DataFrame(train_scaled)\nX_test_scaled = pd.DataFrame(test_scaled)\n\n# Replace the Columns Headers back\nX_train_scaled.columns = cols\nX_test_scaled.columns = cols\nX_train_scaled.head()","f200a736":"numRows = X_train_scaled.count(axis=0)[0]\nprint(\"Total no. of rows in the training set: \", numRows)\nnumRows = X_test_scaled.count(axis=0)[0]\nprint(\"Total no. of rows in the testing set: \", numRows)\n","db6ba8eb":"# A Dataframe to store Model Performance Results\nperf_column_name = ['Model','Train Accu','Test Accu','F1-Score','Recall','AUC']\nperfDF = pd.DataFrame(columns = perf_column_name)\n\n#Function to collect and add Model Performance Results\ndef BuildPerformanceData(model, modelname, y_predict, perfDF):\n    class_rep = classification_report(y_test,y_predict, output_dict=True)\n        #AUC Calculations\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict, pos_label=1)\n    arg1 = round(model.score(X_train_scaled,y_train) * 100,2)\n    arg2 = round(model.score(X_test_scaled,y_test) * 100,2)\n    arg4 = round(class_rep['1']['f1-score'] * 100, 2)\n    arg5 = round(class_rep['1']['recall'] * 100,2)\n    arg6 = round(metrics.auc(fpr, tpr)*100,2)\n    perfDF = perfDF.append({'Model':modelname,'Train Accu':arg1,'Test Accu':arg2, 'F1-Score':arg4,'Recall':arg5,'AUC':arg6},ignore_index=True)\n    return perfDF\n\n#Function to print Confusion Matrix and Classification Report\ndef Print_CM_CR_AUC(y_test,y_predict, algoname):\n    cm = confusion_matrix(y_test,y_predict)\n    sns.heatmap(cm,annot=True, fmt='.2f', xticklabels=[0,1], yticklabels=[0,1])\n    plt.ylabel('observed')\n    plt.xlabel('Predicted')\n    plt.show()\n    # get accuracy of model\n    acc_score = accuracy_score(y_test,y_predict)\n    # get F1-score of model\n    F1_score = f1_score(y_test,y_predict) \n    # get the classification report\n    class_rep = classification_report(y_test,y_predict)\n\n    print(\"Accuracy of \", algoname, \" is {} %\".format(acc_score*100))\n    print(\"F1-score of \", algoname, \" is {} %\".format(F1_score*100))\n    print(\"Classification report for \", algoname, \" is: \\n\",class_rep)\n    \n    #AUC Calculations\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predict, pos_label=1)\n    print(\"AUC for \", algoname, \":\", round(metrics.auc(fpr, tpr)*100,2))","df770dfc":"error_rate = []\n\nfor i in range(1,100):\n NNH = KNeighborsClassifier(n_neighbors=i)\n NNH.fit(X_train_scaled,y_train)\n KNN_predicted_labels = NNH.predict(X_test_scaled)\n error_rate.append(np.mean(KNN_predicted_labels != y_test))","3e15484b":"plt.figure(figsize=(10,6))\nplt.plot(range(1,100),error_rate,color= 'blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","d329ff34":"# From the \nK = 4\n\nNNH = KNeighborsClassifier(n_neighbors= K)\n\n# Call Nearest Neighbour algorithm\nNNH.fit(X_train_scaled, y_train)","881a6eb8":"#Predict using the test data and score the result \n\nKNN_predicted_labels = NNH.predict(X_train_scaled)\ntrain_acc = metrics.accuracy_score(y_train, KNN_predicted_labels)\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(metrics.accuracy_score(y_train, KNN_predicted_labels)*100))\nprint()\n\nKNN_predicted_labels = NNH.predict(X_test_scaled)\ntest_acc = metrics.accuracy_score(y_test, KNN_predicted_labels)\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(metrics.accuracy_score(y_test, KNN_predicted_labels)*100))\nprint()","560fc166":"# Set the parameters by cross-validation\n#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n#                     'C': [1, 10, 100, 1000]},\n#                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n\n#scores = ['precision', 'recall']\n\n#for score in scores:\n#    try:\n#        print(\"# Tuning hyper-parameters for %s\" % score)\n#        print()\n#\n#        clf = GridSearchCV(\n#            SVC(), tuned_parameters, scoring='%s_macro' % score\n#        )\n#        clf.fit(X_train_scaled, y_train)\n\n#        print(\"Best parameters set found on development set:\")\n#        print()\n#        print(clf.best_params_)\n#        print()\n#        print(\"Grid scores on development set:\")\n#        print()\n#        means = clf.cv_results_['mean_test_score']\n#        stds = clf.cv_results_['std_test_score']\n#        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n#            print(\"%0.3f (+\/-%0.03f) for %r\"\n#                  % (mean, std * 2, params))\n#        print()\n#\n#        print(\"Detailed classification report:\")\n#        print()\n#        print(\"The model is trained on the full development set.\")\n#        print(\"The scores are computed on the full evaluation set.\")\n#        print()\n#        y_true, y_pred = y_test, clf.predict(X_test)\n#        print(classification_report(y_true, y_pred))\n#        print()\n#    except ZeroDivisionError:\n#        res.append(0)","49fa2caf":"C = 100\ngamma=0.001\nSVCL = svm.SVC(C=C,gamma=gamma)\nSVCL.fit(X_train_scaled , y_train)\nSVC_Predicted_labels = SVCL.predict(X_train_scaled)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(metrics.accuracy_score(y_train, SVC_Predicted_labels)*100))\nprint()\n\nSVC_Predicted_labels = SVCL.predict(X_test_scaled)\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(metrics.accuracy_score(y_test, SVC_Predicted_labels)*100))\nprint()","4fd0a7d2":"# creat the model\nGNB = GaussianNB()\nGNB.fit(X_train_scaled, y_train)\nGNB_predicted_labels = GNB.predict(X_train_scaled)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(metrics.accuracy_score(y_train, GNB_predicted_labels)*100))\nprint()\n\nGNB_predicted_labels = GNB.predict(X_test_scaled)\n\nprint(\"Model Accuracy with Testing data: {0:.4f}\".format(metrics.accuracy_score(y_test, GNB_predicted_labels)*100))\nprint()","16ff4920":"# Fit the model on train\nLR = LogisticRegression(solver=\"liblinear\")\nLR.fit(X_train_scaled, y_train)\nLR_predicted_labels = LR.predict(X_train_scaled)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(metrics.accuracy_score(y_train, LR_predicted_labels)*100))\nprint()\n\nLR_predicted_labels = LR.predict(X_test_scaled)\n\nprint(\"Model Accuracy with Testing data: {0:.4f}\".format(metrics.accuracy_score(y_test, LR_predicted_labels)*100))\nprint()","196f9929":"#Draw Confusion Matrix and Classification Report for KNN\nPrint_CM_CR_AUC(y_test,KNN_predicted_labels, \"KNN\")\nperfDF = BuildPerformanceData(NNH, \"KNN\", KNN_predicted_labels, perfDF)\nperfDF","677a21d0":"#Draw Confusion Matrix and Classification Report for SVM\nPrint_CM_CR_AUC(y_test,SVC_Predicted_labels, \"SVC\")\nperfDF = BuildPerformanceData(SVCL, \"SVC\", SVC_Predicted_labels, perfDF)\nperfDF","87f989cd":"#Draw Confusion Matrix and Classification Report for Naive Bayes\nPrint_CM_CR_AUC(y_test,GNB_predicted_labels, \"Naive Bayes\")\nperfDF = BuildPerformanceData(GNB, \"Naive Bayes\", GNB_predicted_labels, perfDF)\nperfDF","45db74c1":"#Draw Confusion Matrix and Classification Report for Logistic Regression\nPrint_CM_CR_AUC(y_test,LR_predicted_labels, \"Logistic Regression\")\nperfDF = BuildPerformanceData(LR, \"Logistic Regression\", LR_predicted_labels, perfDF)\nperfDF","3e0c26cd":" estimators = [\n    ('knn', KNeighborsClassifier(n_neighbors= K)),\n     ('svm', svm.SVC(gamma=gamma, C=C)),\n     ('gnb', GaussianNB()),\n     ('lr', LogisticRegression(solver=\"liblinear\"))\n]\n\nSTCL = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n\nSTCL.fit(X_train_scaled, y_train)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(STCL.score(X_train_scaled,y_train)*100))\nprint()\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(STCL.score(X_test_scaled,y_test)*100))\nprint()\n\nSTCL_predicted_labels = STCL.predict(X_test_scaled)","802ca0f5":"#Draw Confusion Matrix and Classification Report for Logistic Regression\nPrint_CM_CR_AUC(y_test,STCL_predicted_labels, \"Meta Classifier\")\nperfDF = BuildPerformanceData(STCL, \"Meta Classifier\", STCL_predicted_labels, perfDF)\nperfDF","1f1f77bb":"dTree = DecisionTreeClassifier(criterion = 'gini', max_depth = 2, random_state=1)\ndTree.fit(X_train_scaled, y_train)\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(dTree.score(X_train_scaled,y_train)*100))\nprint()\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(dTree.score(X_test_scaled,y_test)*100))\nprint()\n\ndTree_predicted_labels = dTree.predict(X_test_scaled)","775f1cc6":"from sklearn.ensemble import BaggingClassifier\nBGCL = BaggingClassifier(base_estimator=dTree, n_estimators=50,random_state=1)\n#bgcl = BaggingClassifier(n_estimators=50,random_state=1)\nBGCL.fit(X_train_scaled, y_train)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(BGCL.score(X_train_scaled,y_train)*100))\nprint()\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(BGCL.score(X_test_scaled,y_test)*100))\nprint()\n\nBGCL_predicted_labels = BGCL.predict(X_test_scaled)","c83f8a34":"ABCL = AdaBoostClassifier(n_estimators=10, random_state=1)\nABCL.fit(X_train_scaled, y_train)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(ABCL.score(X_train_scaled,y_train)*100))\nprint()\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(ABCL.score(X_test_scaled,y_test)*100))\nprint()\n\nABCL_predicted_labels = ABCL.predict(X_test_scaled)","28801941":"GBCL = GradientBoostingClassifier(n_estimators = 10,random_state=1)\nGBCL.fit(X_train_scaled, y_train)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(GBCL.score(X_train_scaled,y_train)*100))\nprint()\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(GBCL.score(X_test_scaled,y_test)*100))\nprint()\n\nGBCL_predicted_labels = GBCL.predict(X_test_scaled)","518ce490":"RFCL = RandomForestClassifier(n_estimators = 10, random_state=1,max_features=10)\nRFCL.fit(X_train_scaled, y_train)\n\nprint(\"Model Accuracy with Training Data: {0:.4f}\".format(RFCL.score(X_train_scaled,y_train)*100))\nprint()\n\nprint(\"Model Accuracy with Testing Data: {0:.4f}\".format(RFCL.score(X_test_scaled,y_test)*100))\nprint()\n\nRFCL_predicted_labels = RFCL.predict(X_test_scaled)","35008809":"#Draw Confusion Matrix and Classification Report for Bagging\nPrint_CM_CR_AUC(y_test,dTree_predicted_labels, \"Decision Tree\")\nperfDF = BuildPerformanceData(dTree, \"Decision Tree\", dTree_predicted_labels, perfDF)\nperfDF","c51fe5d5":"#Draw Confusion Matrix and Classification Report for Bagging\nPrint_CM_CR_AUC(y_test,BGCL_predicted_labels, \"Bagging\")\nperfDF = BuildPerformanceData(BGCL, \"Bagging\", BGCL_predicted_labels, perfDF)\nperfDF","aa8f4dd3":"#Draw Confusion Matrix and Classification Report for AdaBoost\nPrint_CM_CR_AUC(y_test,ABCL_predicted_labels, \"AdaBoost\")\nperfDF = BuildPerformanceData(ABCL, \"AdaBoost\", ABCL_predicted_labels, perfDF)\nperfDF","7dc03577":"#Draw Confusion Matrix and Classification Report for Gradient Boost\nPrint_CM_CR_AUC(y_test,GBCL_predicted_labels, \"Gradiaent Boost\")\nperfDF = BuildPerformanceData(GBCL, \"Gradiaent Boost\", GBCL_predicted_labels, perfDF)\nperfDF","25156d3c":"#Draw Confusion Matrix and Classification Report for RandomForest\nPrint_CM_CR_AUC(y_test,RFCL_predicted_labels, \"Random Forest\")\nperfDF = BuildPerformanceData(RFCL, \"Random Forest\", RFCL_predicted_labels, perfDF)\nperfDF","aa4093af":"perfDF","55fb80ef":"#### Observation: \nData types all look fine. All of them are number reading and hence Float is the right type. Status is a 0 or 1 and hence it's a number.","5bdbb5e0":"MDVP:jitter is right skewed with a thin tail.","aad54dd2":"#### Observations\nWe see pockets of strong corelations.Two stand out very clearly; \"jitter:DDP\" and \"MDVP:RAP\", \"Shimmer-APQ3\" and \"Shimmer-DDA\". We could remove these columns for certain models like K-NN. But since I am not an expert at how these parameters impact Parkinsons, we will have to consult and expert to get an opinion if one of these parameters can be dropped<br>\nAlso MDVP:Shimmer has a strong corellation with MDVP:Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, and Shimmer:DDA\n\n#### We will drop the following Columns for final Modeling as they have linear relationships with other paremeters in their own family:\n1. name\n2. Shimmer:DDA\n3. Jitter:DDP\n4. MDVP:RAP","c4d3bb09":"#### Observation:\nDataset is a fairly skewed towards Parients with Parkinsons.","5d76beb9":"Now that we have collected all the data, let us study the performance of all and shorlist possible good models for the Given Dataset","a3bc41b1":"#### Observation:\nHNR, RPDA and DFA have some Central Tendency with multiple peaks.","c588bb1e":"### 6.4 Logistic Regression","e960fe27":"1. KNN has the best Training and Testing Accuracy and the best AUC amongst the Classification Algorthms. <br>\n2. SVC has a 100% rate on False Positives. For a Desease Classification, this is a good scenario as no one will go undetected even if the results are wrong. Further tests can then confirm or deny the positive result. But the AUC is very low. and F1-Score is the lowest<br>\n3. Naive Bayes has underfitted the data. The trainining Accuracy is much lower than testing accuracy.<br>\n4. Logistic Regression has good Accuracy and is slightly underfitted.It has high recall with no False Negatives. Similar performance to SVC but better AUC as error rate is lower.<br>\n5. Meta Classifier comibines all the 4 Models above and uses Linear Regression get the best results. It has faired well on all the parameters.<br>\n6. Decision Tree has the exact same result as Logistic Regression <br>\n7. Bagging uses Decision Tree as the base Model improves upon the Decission Tree results sligthy impoving the accuracy. Tuning some hyper-parameters might further increase accuracy. <br>\n8. Ada Boost has the great Training and Testing Accuracy and good fit. It has good overall performance and a good AUC.<br>\n9. Gradient Boost has the <b>BEST<\/b> performance. Great Accuracy and Fit. Best recall. Errors are all False Positives which is good. And it has a good AUC.\n10. Random Forest has overall Great Performance on accuracy, fit and Recall. It has the highest AUC amongst all the Ensemble Algorithms.\n\n","1578ff8b":"#### Random Forest","69d3e0ca":"#### Observation:\n<b>K = 4<\/b> should be a good number for KNN as that's the first sharp Elbow","44a1dc89":"## 5. Scale the data","9b119bf5":"### 8. Lets train 4 Ensemble Models","233015e6":"### 6.1 KNN","302a5818":"Before we start building and testing models, let us define some functions to help us reduce Code","ba3b59db":"## 3.1 Study the Data Distribution using Univariate and Bivariate analysis","2ebecbdd":"## 7. Train a meta-classifier and note the accuracy on test data","c14e5426":"While not overfitted, the difference between Training and Accuracy and Testing Accuracy is a bit more. Since accuracy levels are low, lets also test Logistic Regression","dd5875e8":"Since we have a few models to test, lets write a function to add Performance Data to a Dataframe that we can use later to evaluate","d5fbe97a":"#### Lets train a Meta Classifier to use the above algorithms and use a Logistic Regression as the final model to chose the best model\n\nWe will use the same Models and the Same parameters to build a Meta CLassifier","a7170d68":"#### Bagging","3488846b":"#### Now lets do a confusion matrix analysis analisys of these Algorithms and also collect all the Performance Data into a DataFrame so we can analyse all the Models together at the end.","b3a4f5e5":"#### Observation\n\n1. KNN has the best performance in terms of Testing Accuracy, AUC and Recall\n2. SVM has performed well on the Accuracy and Recall. False Positive Rates are 100%. But AUC is very bad. The model is not balanced\n3. Naive Bayes is underfitted. The training data accuracy is much lower than testing data\n4. Logistic Regression seems to have a good Balance of Performance.But the AUC is slightly on the lower side. More data could actually boost LR performance\n\nConclusion: Given this Data, I would go with KNN. KNN is anyway a good choice for Medical Classification problems. But given more Data, I would retrain Logical Regression and see how it performs and then make a choice.","d01e0224":"#### Observation:\nSome parameters like spread1, spread2, D2 look well distributed. But since there are so many variables, lets plot an array of box blots to see the distribution and outliers.","9a2ae25e":"## 1. Load the dataset","cc6a5248":"### 6.2 SVM Model\nSVM uses Gamma and C as two hyper parameters. To choose the best values for gamma and C, GridSearchCV should be used. However, the code was giving zero_division errors and I could not trust the result.\nFor for now we will use a C=100 and gamma = 0.001","92f447e7":"## 6. Train 3 standard classification algorithms - We will use the following\n### 1. KNN\n### 2. SVM \n### 3. Naive Bayes\n### 4. Linear Regression","a540fbec":"MDVP:Fo(Hz) is slightly right skewed with a thick tail.","b570e2a7":"### 9. Compare all the models (minimum 5) and pick the best one among them","063a3423":"## Conclusion\n \nA Meta Classifier that combines KNN, Naive Bayes, Logistic Regression and SVM provides the best Result for Classification Algorithms.\n\nGradient Boost provides the best result under the Ensemble Technique\n\nBust since <b>Gradient Boost<\/b> also has zero False Negatives, given the risk of having False Negatives, we should use Gradient Boost as the Model for this Problem.","70993a17":"#### We will then use a Meta Classifier and use these Models in a StackClassifer to get the best results ","f1416043":"#### Observation: \nSpread1, Spread2, D2 and PPE are fairly centrally distributed","30e67282":"#### Observation\nKNN Algorithm seems to havea good Accuracy for Training and Testing Dataset","0ed27e99":"#### Observation:\nMany columns have outliers. D2, Spread1, Spread2, RDPE seem to be normally distributed. ","51334b04":"#### GradientBoost","41a45531":"Since there is a lot of variation in the various Column values, some are large numbers and some are fractions, lets scale all the columns by using a MinMax Scaler","f588d05c":"#### Observation: \nThere are no missing values in the Data","6114d853":"For the Bagging Model we will use a Decision Tree as the Common Model. So let us train a Decision Tree model before we start Ensemble Model Training  ","0a39c8fc":"## 4. Create the Training and Testing Datasets (70:30 split) ","0f885be3":"## 2. Eyeball the Data and make observations","990dee72":"### 6.3 Naive Bayes Model ","c0394765":"Logistic Regression has much better accuracy for Training and Testing datasets. The difference is also not that high.","2dc4cdc4":"### Objectives\nGoal is to classify the patients into the respective labels using the attributes from\ntheir voice recordings\n\n_Data Credits: 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM.  BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)_\n","4744123f":"Lets do an Elbow analysis to find the best depth","373d9eee":"#### Observation: \nAll the parameters to this point are all right skewed with varying tales.","aab203b6":"#### AdaBoost","9769324c":"## 3.2 Bivariate Analysis to study Dependencies","64b735fe":"MDVP:Flo(Hz) is right skewed with a thick tail.","34451d57":"Brefore splitting the Training and Testing we will:\n\n1. Drop some columns that have a linear relationship with other columns\n2. Split the data set into X and y \n","94baad6f":"## Data Analytics and Prediction for Parkinson's Desease Data","8f906749":"## 3.3 Lets study the Distributions of the parameters"}}