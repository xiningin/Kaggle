{"cell_type":{"005ec740":"code","1e40b2f1":"code","8822ef0f":"code","5731ea0e":"code","d8031477":"code","baf2a8e6":"code","b1892d0c":"code","49c074d3":"code","470c9ff6":"code","e16b1550":"code","1bf7aec7":"code","6e93488d":"code","38f356ae":"markdown","17e1a9be":"markdown","1caf9b18":"markdown","af09ddc2":"markdown","a2fd56ae":"markdown"},"source":{"005ec740":"cd ..\/input\/gbdtmo-package\/GBDTMO","1e40b2f1":"pip install .","8822ef0f":"import numpy as np\nimport pandas as pd \nimport numpy.ctypeslib as npct\nfrom gbdtmo import load_lib, GBDTSingle, GBDTMulti\nfrom sklearn import datasets as dts\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5731ea0e":"from _ctypes import _SimpleCData\nfrom _ctypes import sizeof\n\ndef _check_size(typ, typecode=None):\n    # Check if sizeof(ctypes_type) against struct.calcsize.  This\n    # should protect somewhat against a misconfigured libffi.\n    from struct import calcsize\n    if typecode is None:\n        # Most _type_ codes are the same as used in struct\n        typecode = typ._type_\n    actual, required = sizeof(typ), calcsize(typecode)\n    if actual != required:\n        raise SystemError(\"sizeof(%s) wrong: %d instead of %d\" % \\\n                          (typ, actual, required))\n\nclass c_void_p(_SimpleCData):\n    _type_ = \"P\"\nc_voidp = c_void_p # backwards compatibility (to a bug)\n_check_size(c_void_p)\n\n\nclass c_int(_SimpleCData):\n    _type_ = \"i\"\n_check_size(c_int)\n\n\nclass c_bool(_SimpleCData):\n    _type_ = \"?\"\n\n    \nclass c_char_p(_SimpleCData):\n    _type_ = \"z\"\n    def __repr__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, c_void_p.from_buffer(self).value)\n_check_size(c_char_p, \"P\")    \n    \n    \nclass c_double(_SimpleCData):\n    _type_ = \"d\"\n_check_size(c_double)","d8031477":"Lib_path = \"\/kaggle\/input\/gbdtmo-package\/GBDTMO\/build\/gbdtmo.so\"\n\nDepth = {\"lightgbm\": {\"mnist\": 6, \"yeast\": 4, \"Caltech101\": 8, \"nus-wide\": 8, \"mnist_reg\": 8},\n         \"gbdtso\": {\"mnist\": 6, \"yeast\": 5, \"Caltech101\": 8, \"nus-wide\": 8, \"mnist_reg\": 8},\n         \"gbdtmo\": {\"mnist\": 8, \"yeast\": 6, \"Caltech101\": 9, \"nus-wide\": 8, \"mnist_reg\": 7},\n         }\n\nLearning_rate = {\"lightgbm\": {\"mnist\": 0.25, \"yeast\": 0.1, \"Caltech101\": 0.1, \"nus-wide\": 0.05, \"mnist_reg\": 0.1},\n                 \"gbdtso\": {\"mnist\": 0.1, \"yeast\": 0.1, \"Caltech101\": 0.05, \"nus-wide\": 0.05, \"mnist_reg\": 0.1},\n                 \"gbdtmo\": {\"mnist\": 0.1, \"yeast\": 0.25, \"Caltech101\": 0.1, \"nus-wide\": 0.1, \"mnist_reg\": 0.1},\n                }","baf2a8e6":"array_1d_double = npct.ndpointer(dtype=np.double, ndim=1, flags='CONTIGUOUS')\narray_2d_double = npct.ndpointer(dtype=np.double, ndim=2, flags='CONTIGUOUS')\narray_1d_int = npct.ndpointer(dtype=np.int32, ndim=1, flags='CONTIGUOUS')\narray_2d_int = npct.ndpointer(dtype=np.int32, ndim=2, flags='CONTIGUOUS')\narray_1d_uint16 = npct.ndpointer(dtype=np.uint16, ndim=1, flags='CONTIGUOUS')\narray_2d_uint16 = npct.ndpointer(dtype=np.uint16, ndim=2, flags='CONTIGUOUS')\n\n\n\n\ndef load_lib(path):\n    lib = npct.load_library(path, '.')\n\n    lib.SetData.argtypes = [c_void_p, array_2d_uint16, array_2d_double, array_2d_double, c_int, c_bool]\n    lib.SetBin.argtypes = [c_void_p, array_1d_uint16, array_1d_double]\n    lib.SetGH.argtypes = [c_void_p, array_2d_double, array_2d_double]\n\n    lib.Boost.argtypes = [c_void_p]\n    lib.Train.argtypes = [c_void_p, c_int]\n    lib.Dump.argtypes = [c_void_p, c_char_p]\n    lib.Load.argtypes = [c_void_p, c_char_p]\n\n    lib.MultiNew.argtypes = [c_int, c_int, c_int, c_char_p,\n                             c_int, c_int, c_int, c_int, c_int,\n                             c_double, c_double, c_double, c_double, c_double, c_int,\n                             c_bool, c_bool, c_int]\n\n    lib.SingleNew.argtypes = [c_int, c_char_p,\n                              c_int, c_int, c_int, c_int, c_int,\n                              c_double, c_double, c_double, c_double, c_double, c_int,\n                              c_bool, c_int]\n\n    lib.TrainMulti.argtypes = [c_void_p, c_int, c_int]\n    lib.PredictMulti.argtypes = [c_void_p, array_2d_double, array_1d_double, c_int, c_int, c_int]\n    lib.Reset.argtypes = [c_void_p]\n\n    return lib","b1892d0c":"LIB = load_lib(Lib_path)\nLIB","49c074d3":"out_dim = 10\nparams = {\"max_depth\": 5, \"lr\": 0.1}","470c9ff6":"booster = GBDTMulti(LIB, out_dim=out_dim, params=params)","e16b1550":"X, y = dts.load_iris(return_X_y = True)\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","1bf7aec7":"booster.set_data((x_train, y_train), (x_test, y_test))\nbooster.train(num_rounds)\npreds = booster.predict(x_test)\nprint(preds)","6e93488d":"print(accuracy_score(y_test, preds))","38f356ae":"# Define model","17e1a9be":"# C libs","1caf9b18":"# load_lib","af09ddc2":"# cfg","a2fd56ae":"# Import dataset"}}