{"cell_type":{"eec2e2e3":"code","902c219f":"code","c2efaf99":"code","5692eeca":"code","0bb63ea6":"code","69b67721":"code","1d5b1490":"code","93569458":"code","003a495b":"code","beefe904":"code","d684c074":"code","fb5b556a":"code","49b6cf7c":"code","5928a267":"code","1c63d71b":"code","8ef6abbf":"code","d1e548a2":"markdown","9d28c9c8":"markdown","ec0b21c1":"markdown","0352e383":"markdown","871733af":"markdown","7806b439":"markdown","8fa1514c":"markdown","372dfc85":"markdown","9c274f50":"markdown","c7519ed8":"markdown","333cdaf0":"markdown","4aa805a9":"markdown","b5401fba":"markdown","f5864686":"markdown","947e77c3":"markdown","1d580632":"markdown","f99d89f2":"markdown"},"source":{"eec2e2e3":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom zipfile import ZipFile","902c219f":"! conda install -y gdown\n!gdown --id 1zrSjHLpQQo8o6SOnqTYDk8hEJ-buAN1N","c2efaf99":"with ZipFile('.\/17) Image_Classification(Dog-Cat).zip', 'r') as zip:\n    zip.extractall()","5692eeca":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('.\/Dataset\/training_set',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')","0bb63ea6":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_set = test_datagen.flow_from_directory('.\/Dataset\/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","69b67721":"cnn = tf.keras.models.Sequential()","1d5b1490":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","93569458":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","003a495b":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","beefe904":"cnn.add(tf.keras.layers.Flatten())","d684c074":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","fb5b556a":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","49b6cf7c":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","5928a267":"cnn.fit(x = training_set, validation_data = test_set, epochs = 25)","1c63d71b":"import numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('.\/Dataset\/single_prediction\/cat_or_dog_1.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n  prediction = 'dog'\nelse:\n  prediction = 'cat'","8ef6abbf":"print(prediction)","d1e548a2":"### Preprocessing the Test set","9d28c9c8":"## Part 3 - Training the CNN","ec0b21c1":"### Step 1 - Convolution","0352e383":"### Step 2 - Pooling","871733af":"# Convolutional Neural Network","7806b439":"### Initialising the CNN","8fa1514c":"## Part 4 - Making a single prediction","372dfc85":"### Training the CNN on the Training set and evaluating it on the Test set","9c274f50":"### Preprocessing the Training set","c7519ed8":"### Step 3 - Flattening","333cdaf0":"## Part 1 - Data Preprocessing","4aa805a9":"## Part 2 - Building the CNN","b5401fba":"### Adding a second convolutional layer","f5864686":"### Importing the libraries","947e77c3":"### Step 4 - Full Connection","1d580632":"### Step 5 - Output Layer","f99d89f2":"### Compiling the CNN"}}