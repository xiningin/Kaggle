{"cell_type":{"ce906534":"code","ff36faad":"code","61803bb8":"code","4e437c83":"code","f8449aca":"code","ab6e1dc1":"code","c6fab78a":"code","aab75deb":"code","f78a4c93":"code","6bfdac66":"code","94103f22":"code","fb6a1b4a":"code","fe769ac2":"code","63fe7b50":"code","44572016":"markdown","065a4bbb":"markdown","5ee5e309":"markdown","4eb86256":"markdown","28a5357b":"markdown","72abef6c":"markdown","34066fa9":"markdown"},"source":{"ce906534":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff36faad":"\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\ntf.__version__\n\n","61803bb8":"# loading Test Data\ndef test_data():\n    # Loading Important Files\n    ListOfTestSet = pd.read_csv(\"..\/input\/kagglefsd\/ListOfTestSet.csv\")\n    test_df = pd.read_csv(\"..\/input\/kagglefsd\/test_post_competition_scoring_clips.csv\")\n    Test_Path = \"..\/input\/kagglefsd\/Spectrogram\/Test\/\"\n    # list to hold Test data\n    Labels = []\n    Images = []\n    # for loading spectrogram Images\n    length = len(test_df)\n    for i in range(length):\n        if ListOfTestSet[\"Spectrogram\"][i] != 0:\n            fname = Test_Path + test_df[\"fname\"][i] + \".png\"\n            img = image.load_img(fname)\n            image_array = image.img_to_array(img)\n            Images.append(image_array)\n            if test_df[\"label\"][i] == \"Cough\" or test_df[\"label\"][i] == \"cough\":\n                Labels.append(1)\n            else:\n                Labels.append(0)\n        print(\"***** \"+ str(i) +\" Done \"+\"*****\")\n\n    x_test = np.array(Images)\n    y_test = np.array(Labels)\n    x_test = preprocess_input(x_test)\n    #x_test, val_x, y_test, val_y = train_test_split(x_test, y_test, test_size=0.51)\n    return x_test, y_test\n\nval_x, val_y = test_data()","4e437c83":"# loading Train Data\ndef train_data():\n    # Loading Important Files\n    train_df = pd.read_csv(\"..\/input\/kagglefsd\/train.csv\")\n    ListOfTrainSet = pd.read_csv(\"..\/input\/kagglefsd\/ListOfTrainSet.csv\")\n    Train_Path = \"..\/input\/kagglefsd\/Spectrogram\/Train1\/\"\n    # list to hold Train data\n    Labels = []\n    Images = []\n    # for loading spectrogram Images\n    length = len(train_df)\n    for i in range(length):\n        if ListOfTrainSet[\"Spectrogram\"][i] != 0:\n            fname = Train_Path + train_df[\"fname\"][i] + \".png\"\n            img = image.load_img(fname)\n            image_array = image.img_to_array(img)\n            Images.append(image_array)\n            if train_df[\"label\"][i] == \"Cough\" or train_df[\"label\"][i] == \"cough\":\n                Labels.append(1)\n            else:\n                Labels.append(0)\n        print(\"***** \"+ str(i) +\" Done \"+\"*****\") \n    x_train = np.array(Images)\n    y_train = np.array(Labels)\n    x_train = preprocess_input(x_train)\n    return x_train, y_train\n\nx_train, y_train = train_data()\n","f8449aca":"y_train","ab6e1dc1":"es = EarlyStopping(monitor='loss', patience=3)\nfilepath=\"\/kaggle\/working\/bestmodel.h5\"\nmd = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min')","c6fab78a":"# defininig ImageDataGeneratore to increase data\n\n'''\ndatagen = ImageDataGenerator(zoom_range = 0.1,\n                            height_shift_range = 0,\n                            width_shift_range = 0,\n                            rotation_range = 10)\n                            '''","aab75deb":"##### Important Variables\nepochs = 18\nnum_classes = 2\nbatch_size = 1024\ninput_shape = (120, 124, 3)\nadam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)","f78a4c93":"model = Sequential()\n\n# Filter 1\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation= 'relu')) \nmodel.add(Conv2D(32, (3, 3), padding='same', activation= 'relu'))    \nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n#model.add(BatchNormalization())\n\n# Filter 2\nmodel.add(Conv2D(16, (3, 3), padding='same', activation= 'relu'))                          \nmodel.add(Conv2D(16, (3, 3), padding='same', activation= 'relu'))    \nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n#model.add(BatchNormalization())\n\n\n# Filter 3 \n#model.add(Conv2D(16, (3, 3), padding='same', activation= 'relu'))                         \n#model.add(Conv2D(16, (3, 3), padding='same', activation= 'relu'))                        \n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n#model.add(BatchNormalization())\n\n\n# 1st Dense Layer\nmodel.add(Flatten())\n#model.add(Dense(1024, activation='relu'))                                                \n#model.add(Dropout(0.25))\n#model.add(BatchNormalization())\n\n\n# 2nd Dense Layer\nmodel.add(Dense(512, activation='relu'))                                                \nmodel.add(Dropout(0.25))\n\n# 3rd Dense Layer\nmodel.add(Dense(256, activation='relu'))                                                \nmodel.add(Dropout(0.3))\n\n# 4th Dense Layer\nmodel.add(Dense(128, activation='relu'))                                                \nmodel.add(Dropout(0.3))\n\n# 5th Dense Layer\n\nmodel.add(Dense(64, activation='relu'))                                                \nmodel.add(Dropout(0.5))\n\n# 6th Dense Layer\n#model.add(Dense(32, activation='relu'))                                                \n#model.add(Dropout(0.5))\n\n# Output Layer\nmodel.add(Dense(1, activation= 'sigmoid'))   \n\n# Model Compile\nmodel.compile(optimizer= adam, loss= tf.keras.losses.binary_crossentropy, metrics=[\"accuracy\"])\n\n# Model Summery\nmodel.summary()\n","6bfdac66":"History = model.fit(x_train,\n                    y_train, \n                    batch_size=batch_size,\n                    #steps_per_epoch=2048,\n                    epochs = epochs,\n                    verbose=2,\n                    validation_data = (val_x, val_y),\n                    callbacks = [es,md],\n                    shuffle= True\n                    )","94103f22":"cnn = load_model(\"\/kaggle\/working\/bestmodel.h5\")\ncnn.summary()","fb6a1b4a":"'''\npred = cnn.predict(x_test)\npred[0][0]\n'''\n\n","fe769ac2":"'''from sklearn.metrics import mean_absolute_error\nprint(mean_absolute_error(y_test, pred_class))\ndf = pd.DataFrame(columns=['prediction','Actual_Result'])\ndf['prediction'] = pred_class\ndf['Actual_Result'] = y_test\ndf.to_csv('\/kaggle\/working\/prediction.csv', index=False)'''\n\n","63fe7b50":"# Saving Structre Of Neural Network\nfrom pathlib import Path\nmodel_structure = cnn.to_json()\nsaving_m = Path(\"\/kaggle\/working\/model_structure_17_256_0.1293_0.9722_0.1457_0.9812.jason\")\nsaving_m.write_text(model_structure)\n# Saving Model\nmodel.save(\"\/kaggle\/working\/17_256_0.1293_0.9722_0.1457_0.9812.h5\")\n# Saving weights only \nmodel.save_weights(\"\/kaggle\/working\/W_17_256_0.1293_0.9722_0.1457_0.9812.h5\")","44572016":" # 1. Importing Important Libraries","065a4bbb":"# 6. Creating Prediction From Saved Model","5ee5e309":"# 3. Defining Important Para","4eb86256":" **well guys I will sagest you start experiment with diferent batch size.** ","28a5357b":"# 5. Training Model","72abef6c":"# 2. Data Preprocessing","34066fa9":"# 4. Building CNN"}}