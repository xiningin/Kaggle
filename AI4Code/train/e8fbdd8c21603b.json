{"cell_type":{"d146ca0f":"code","3de80f58":"code","2c045d0b":"code","d15b53bb":"code","ba978612":"code","c02ab2cb":"code","48546ac0":"code","f7e3d213":"code","ac4ae73a":"code","cb5274b5":"code","33c66174":"code","428cd000":"code","62b67472":"code","c0b6c9b8":"code","2415c5fd":"code","1f85c08a":"code","cd4e2b7a":"code","c4ce935f":"code","485ca6f8":"code","66dee69b":"code","6885dab6":"code","1cb6456a":"code","24790d5f":"code","9ddf1a68":"code","99294bcc":"code","455049d7":"code","b2309915":"code","16d7099b":"code","e94af3b4":"markdown","223363c2":"markdown","779e5e73":"markdown","56856632":"markdown","d97b7fe4":"markdown","0216d6d3":"markdown","e4667620":"markdown"},"source":{"d146ca0f":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","3de80f58":"# importing dataset from drive\n\ndata = pd.read_csv(\"..\/input\/heartbeat\/mitbih_train.csv\", header=None)\ndf = pd.DataFrame(data)","2c045d0b":"df.head()","d15b53bb":"# showing column wise %ge of NaN values they contains \nnull_col = []\n\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n  if df[i].isna().mean()*100 > 0:\n    null_col.append(i)\n","ba978612":"classes = []\nsns.countplot(x=187, data = df) ","c02ab2cb":"class_1 = df[df[187]==1.0]\nclass_2 = df[df[187]==2.0]\nclass_3 = df[df[187]==3.0]\nclass_4 = df[df[187]==4.0]\nclass_0 = df[df[187]==0.0].sample(n = 8000)","48546ac0":"new_df = pd.concat([class_0, class_1, class_2, class_3, class_4])","f7e3d213":"new_df.head()","ac4ae73a":"sns.countplot(x=187, data = new_df) ","cb5274b5":"index = 0\n\nfig, ax = plt.subplots(nrows = 1, ncols = 5, figsize=(25,2))\n\nfor i in range(5):\n  ax[i].plot(new_df[new_df[187]==float(i)].sample(1).iloc[0,:186])\n  ax[i].set_title('Class: '+str(i))\n","33c66174":"#now lets split data in test train pairs\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(new_df.drop([187], axis=1), new_df[187], test_size = 0.1)","428cd000":"X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)","62b67472":"from tensorflow.keras import Sequential,utils\nfrom tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout","c0b6c9b8":"clf = Sequential()\n\nclf.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation='relu', input_shape = (X_train.shape[1],1)))\nclf.add(Conv1D(filters=64, kernel_size=(3,), padding='same', activation='relu')) \nclf.add(Conv1D(filters=128, kernel_size=(5,), padding='same', activation='relu'))    \n\nclf.add(MaxPool1D(pool_size=(3,), strides=2, padding='same'))\nclf.add(Dropout(0.5))\n\nclf.add(Flatten())\n\nclf.add(Dense(units = 512, activation='relu'))\nclf.add(Dense(units = 1024, activation='relu'))\n\nclf.add(Dense(units = 5, activation='softmax'))\n","2415c5fd":"clf.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","1f85c08a":"history = clf.fit(X_train, y_train, epochs = 10)","cd4e2b7a":"# Prediction\n\ny_pred = clf.predict(X_test)","c4ce935f":"acc = history.history['accuracy']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, color='red', label='Training acc')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","485ca6f8":"from sklearn.metrics import confusion_matrix\n\ny_lbl = [np.where(i == np.max(i))[0][0] for i in y_pred]\nmat = confusion_matrix(y_test, y_lbl)\nfig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(mat, annot = True)","66dee69b":"# Measure the Accuracy Score\n\nfrom sklearn import metrics\n\nprint(\"Accuracy score of the predictions: {0}\".format(metrics.accuracy_score(y_lbl, y_test)))\n","6885dab6":"test_data = pd.read_csv(\"..\/input\/heartbeat\/mitbih_test.csv\", header=None)\ntest_df = pd.DataFrame(test_data)","1cb6456a":"test_df.head()","24790d5f":"classes = []\nsns.countplot(x=187, data = test_df) ","9ddf1a68":"index = 0\n\nfig, ax = plt.subplots(nrows = 1, ncols = 5, figsize=(25,2))\n\nfor i in range(5):\n  ax[i].plot(test_df[test_df[187]==float(i)].sample(1).iloc[0,:186])\n  ax[i].set_title('Class: '+str(i))\n","99294bcc":"test_X = test_df.drop([187], axis=1) \ntest_y = test_df[187]\n\ntest_X = np.array(test_X).reshape(test_X.shape[0], test_X.shape[1], 1)","455049d7":"test_pred_y = clf.predict(test_X)","b2309915":"from sklearn.metrics import confusion_matrix\n\ntest_lbl_y = [np.where(i == np.max(i))[0][0] for i in test_pred_y]\nmat = confusion_matrix(test_y, test_lbl_y)\nfig, ax = plt.subplots(figsize=(7,7))\nsns.heatmap(mat, annot = True)","16d7099b":"# Measure the Accuracy Score\n\nfrom sklearn import metrics\n\nprint(\"Accuracy score of the predictions: {0}\".format(metrics.accuracy_score(test_lbl_y, test_y)))\n","e94af3b4":"> As we can see above CNN got accuracy of 96.6%, now we can predict the vaalues for our test dataset.","223363c2":"> Now for visualising each class, here is plot of any random sample of hearbeat in each class.","779e5e73":"> And here our CNN got us 96.5% accuracy on test dataset","56856632":"***","d97b7fe4":"> Since data does'nt contain any null values, we can move further","0216d6d3":"## ECG Heartbeat Categorization\n\n> This dataset is composed of two collections of heartbeat signals derived from two famous datasets in heartbeat classification, the MIT-BIH Arrhythmia Dataset and The PTB Diagnostic ECG Database.","e4667620":"> Here this bar graph easily shows how data is imbalanced. More than 80% data is in class 0. So, first, we have to balance th data in to get more precise predictions.\n\n> For balancing the data I'm using undersampling in which we will reduce the rows of class 0 to the number compareble to others\/"}}