{"cell_type":{"2d5dc581":"code","629d5e8b":"code","f57f0d2f":"code","a1e157b6":"code","7b6c2f5e":"code","ad2a1941":"code","ee13c58a":"code","59970437":"code","d42850d7":"code","bb7a216c":"code","ecfa1e4f":"code","19762281":"code","8ee7c3d3":"code","f53e0fc7":"code","53e80bef":"code","e1b791a6":"code","f89e409e":"code","dbd96bf8":"code","39853a2b":"code","257ac666":"code","13e7fe04":"code","9c6e0eb7":"code","7ef33fd4":"code","7c52e574":"code","b1d05e9f":"code","0525b29a":"code","5ff37b54":"code","140e1c42":"code","ae42d61b":"code","a1bcd787":"code","bf25c89c":"code","54fe94a9":"code","c7ac9b36":"code","7df110ef":"code","74f3e1cf":"code","b907ccaa":"code","e0c3cbf6":"code","15a89f87":"code","b4a8b0fe":"code","d21582f9":"code","fd5bf6df":"code","44ae672a":"code","ab1a461a":"code","c04f61f0":"code","a5eb8a3a":"code","3d483a6a":"code","9e186039":"code","b96bec6a":"code","8ba21abc":"code","34e3eea4":"code","9baf74e9":"code","5e0525f5":"code","f9797e0c":"code","1da2dce4":"code","53ff7155":"code","21cd3c10":"code","9dff74c0":"code","f725e852":"code","81b1a66f":"code","f84b7a73":"code","61e9c358":"code","0b39e486":"code","046ed15f":"code","0b5aced1":"code","8866da66":"code","cee8a900":"code","f920490b":"code","cab4c6e6":"code","8c6467f6":"code","eb93278c":"code","8a2426ec":"code","5463f9de":"code","06eaa55a":"code","777abbc9":"code","381e566d":"code","89439d18":"code","f701f9de":"code","2a5ba868":"markdown","33b1169f":"markdown","516183af":"markdown","30ce1466":"markdown","f521b003":"markdown","5f883a62":"markdown","42b9cf5e":"markdown","8af81d3a":"markdown","1cb6cf39":"markdown","4afaea8a":"markdown","17f263ed":"markdown","2d93e035":"markdown","6dc8df68":"markdown","2a8042ec":"markdown","1c528297":"markdown","df7122ce":"markdown","dd23b181":"markdown","52ae3134":"markdown","06460694":"markdown","1f04aef5":"markdown","fd45bc67":"markdown","781e4d46":"markdown","5c36c94a":"markdown","dc804ab9":"markdown","9f20c901":"markdown","80988108":"markdown","bd4a1b60":"markdown","5f0a5e70":"markdown","cac4a37f":"markdown","69d8cd28":"markdown","e8dd412d":"markdown","c713ca71":"markdown","1f22a6e1":"markdown","cb802912":"markdown","6120e746":"markdown","0e940d96":"markdown","cfe12594":"markdown","8cfe3ff5":"markdown","6d65da97":"markdown","9fc130a5":"markdown","ffdf958b":"markdown","912f2aaa":"markdown","62359a05":"markdown","0dfd97b8":"markdown","abffe976":"markdown","37b4c7c9":"markdown","63159bdf":"markdown","63c6d827":"markdown","9c653c7a":"markdown"},"source":{"2d5dc581":"%config IPCompleter.greedy=True\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport unidecode\nfig, ax=plt.subplots()\npd.set_option('display.max_columns', None)\nsns.set(style='darkgrid',palette=\"muted\")","629d5e8b":"# Distribution graphs (histogram\/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) \/ nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]}', size=20)\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()","f57f0d2f":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = 'df'\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()","a1e157b6":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()","7b6c2f5e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ad2a1941":"df=pd.read_csv('\/kaggle\/input\/employeetransport\/Cars.csv')\nprediction_set=pd.read_excel('\/kaggle\/input\/cars-prediction\/predict.xlsx')","ee13c58a":"df.head()","59970437":"df.describe().transpose()","d42850d7":"df.isna().any().any()","bb7a216c":"df.dtypes","ecfa1e4f":"df.Transport.value_counts()","19762281":"df.Gender.value_counts()","8ee7c3d3":"df.groupby('Transport').mean()","f53e0fc7":"df.groupby('Transport').mean().plot(kind='bar')","53e80bef":"plotPerColumnDistribution(df, 8, 4)","e1b791a6":"plotCorrelationMatrix(df, 7)","f89e409e":"plotScatterMatrix(df, 10, 4)","dbd96bf8":"#pair plots of entire dataset\npp = sns.pairplot(df, hue = 'Transport', palette = 'deep', size=2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])","39853a2b":"fig, axs=plt.subplots(nrows=1,ncols=3,figsize=(20,5))\nsns.kdeplot(df.Salary[(df['Transport']=='Public Transport')],color=\"g\",shade=True,ax=axs[0])\nsns.kdeplot(df.Salary[(df['Transport']=='2Wheeler')],color=\"b\",shade=True,ax=axs[0])\nsns.kdeplot(df.Salary[(df['Transport']=='Car')],color=\"r\",shade=True,ax=axs[0])\naxs[0].legend([\"Public trans\",\"2 Wheeler\",\"Cars\"],loc='upper right')\naxs[0].set_xlabel('Salary')\naxs[0].set_title('Density Distribution of Salary',size=15)\naxs[0].set_yticks([])\n#########\nsns.kdeplot(df['Work Exp'][(df['Transport']=='Public Transport')],color=\"g\",shade=True,ax=axs[1])\nsns.kdeplot(df['Work Exp'][(df['Transport']=='2Wheeler')],color=\"b\",shade=True,ax=axs[1])\nsns.kdeplot(df['Work Exp'][(df['Transport']=='Car')],color=\"r\",shade=True,ax=axs[1])\naxs[1].legend([\"Public trans\",\"2 Wheeler\",\"Cars\"],loc='upper right')\naxs[1].set_xlabel('Work Exp')\naxs[1].set_title('Density Distribution of Work Exp',size=15)\naxs[1].set_yticks([])\n#########\nsns.kdeplot(df['Age'][(df['Transport']=='Public Transport')],color=\"g\",shade=True,ax=axs[2])\nsns.kdeplot(df['Age'][(df['Transport']=='2Wheeler')],color=\"b\",shade=True,ax=axs[2])\nsns.kdeplot(df['Age'][(df['Transport']=='Car')],color=\"r\",shade=True,ax=axs[2])\naxs[2].legend([\"Public trans\",\"2 Wheeler\",\"Cars\"],loc='upper right')\naxs[2].set_xlabel('Age')\naxs[2].set_title('Density Distribution of Age',size=15)\naxs[2].set_yticks([])","257ac666":"fig, axs=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nsns.countplot(x='Engineer',hue='Transport' ,data=df, ax=axs[0])\nsns.countplot(x='MBA',hue='Transport' ,data=df, ax=axs[1])\nfig.suptitle('Transport by Profession', fontsize=16)","13e7fe04":"df['Male']=[1 if x=='Male' else 0 for x in df['Gender']]\ndf['Car']=[1 if x=='Car' else 0 for x in df['Transport']]\ndf['PublicTransport']=[1 if x=='Public Transport' else 0 for x in df['Transport']]\ndf['2Wheeler']=[1 if x=='2Wheeler' else 0 for x in df['Transport']]","9c6e0eb7":"df.head()","7ef33fd4":"df.describe().transpose()","7c52e574":"df.corr()","b1d05e9f":"df.columns.values","0525b29a":"dims = (8, 5)\nsns.set(style='darkgrid',palette=\"muted\")\nfig, ax=plt.subplots(figsize=dims)\ndf.corr()['Car'][:-3].sort_values(ascending = False).plot(kind='bar')","5ff37b54":"dfCar=df.loc[:,['Age', 'Engineer', 'MBA', 'Work Exp', 'Salary','Distance', 'license','Male','Car']]","140e1c42":"X=dfCar.iloc[:,:-1]\ny=dfCar.loc[:,'Car']","ae42d61b":"#plot precicion, recall and thresholds\n#predicted_proba[:,1]\ndef plotPrecisionRecallThreshold(y_test, pred_prob):\n    precision, recall, thresholds = metrics.precision_recall_curve(y_test, pred_prob) \n   #retrieve probability of being 1(in second column of probs_y)\n    pr_auc = metrics.auc(recall, precision)\n    plt.title(\"Precision-Recall vs Threshold Chart\")\n    plt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\n    plt.ylabel(\"Precision, Recall\")\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc=\"lower left\")\n    plt.ylim([0,1])\n    \ndef plotROC(y_test,pred_prob):\n    fpr, tpr, threshold=metrics.roc_curve(y_test,pred_prob)\n    plt.title(\"ROC Curve\")\n    sns.lineplot(x=fpr,y=tpr,palette=\"muted\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.xlabel(\"False Positive Rate\")\n    \ndef areaUnderROC(y_test, pred_prob):\n    precision, recall, thresholds = metrics.precision_recall_curve(y_test, pred_prob) \n    return metrics.auc(recall, precision)","a1bcd787":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=232)","bf25c89c":"model = LogisticRegression(penalty='none', solver='saga')\nresult = model.fit(X_train, y_train)","54fe94a9":"from math import exp\nprediction_test = model.predict(X_test)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in model.coef_.flatten()])\nprint('coefficients')\nprint(model.coef_.flatten())\nweights = pd.Series(model.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","c7ac9b36":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(2),range(2))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix for threshold: .5\")","7df110ef":"predicted_proba=model.predict_proba(X_test)\nplotPrecisionRecallThreshold(y_test, predicted_proba[:,1])","74f3e1cf":"plotROC(y_test, predicted_proba[:,1])\nprint('area under the curve: %.2f' %areaUnderROC(y_test, predicted_proba[:,1]))","b907ccaa":"#Car: 65,95,50\n#found these values with some hit and try\n#Logit CV with ridge\n#logistic regression CV. L1 Lasso\nfrom sklearn.linear_model import LogisticRegressionCV\nmodel = LogisticRegressionCV(Cs=[21,23,24],cv=5,penalty='l1',solver='saga', random_state=232)\nresult = model.fit(X_train, y_train)","e0c3cbf6":"print('best regularization strength: %d'  %model.C_)","15a89f87":"prediction_test = model.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in model.coef_.flatten()])\nprint('coefficients')\nprint(model.coef_.flatten())\nweights = pd.Series(model.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","b4a8b0fe":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(2),range(2))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix for threshold: .5\")","d21582f9":"plotROC(y_test, predicted_proba[:,1])\nprint('area under the curve: %.2f' %areaUnderROC(y_test, predicted_proba[:,1]))","fd5bf6df":"#l2\n#car:1,5,50\n#logistic regression CV. L2 Rigde\nfrom sklearn.linear_model import LogisticRegressionCV\nmodel = LogisticRegressionCV(Cs=np.linspace(1,10,50),cv=5,penalty='l2', random_state=232)\nresult = model.fit(X_train, y_train)","44ae672a":"print('best regularization strength: %d'  %model.C_)","ab1a461a":"prediction_test = model.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in model.coef_.flatten()])\nprint('coefficients')\nprint(model.coef_.flatten())\nweights = pd.Series(model.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","c04f61f0":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(2),range(2))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix for threshold: .5\")","a5eb8a3a":"#l2\n#car:1,5,50\n#logistic regression CV. L2 Rigde\nfrom sklearn.linear_model import LogisticRegressionCV\nmodel = LogisticRegressionCV(Cs=np.linspace(1,10,50),cv=5,penalty='l2', random_state=232)\nresult = model.fit(X_train, y_train)","3d483a6a":"print('best regularization strength: %d'  %model.C_)","9e186039":"prediction_test = model.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in model.coef_.flatten()])\nprint('coefficients')\nprint(model.coef_.flatten())\nweights = pd.Series(model.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","b96bec6a":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(2),range(2))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix for threshold: .5\")","8ba21abc":"plotROC(y_test, predicted_proba[:,1])\nprint('area under the curve: %.2f' %areaUnderROC(y_test, predicted_proba[:,1]))","34e3eea4":"modelCar = LogisticRegressionCV(Cs=np.linspace(1,50,50),cv=5,penalty='elasticnet',solver='saga',l1_ratios=np.linspace(0,1,10), random_state=232)\nresult = modelCar.fit(X_train, y_train)\nprint('best regularization strength: %d'  %model.C_)\nprint('l1_ration %.2f' %modelCar.l1_ratio_)","9baf74e9":"prediction_test = modelCar.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in modelCar.coef_.flatten()])\nprint('coefficients')\nprint(modelCar.coef_.flatten())\nweights = pd.Series(modelCar.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","5e0525f5":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(2),range(2))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix for threshold: .5\")","f9797e0c":"df2Wheeler=df.loc[:,['Age', 'Engineer', 'MBA', 'Work Exp', 'Salary','Distance', 'license','Male','2Wheeler']]\ndfPubTrans=df.loc[:,['Age', 'Engineer', 'MBA', 'Work Exp', 'Salary','Distance', 'license','Male','PublicTransport']]","1da2dce4":"X=df2Wheeler.iloc[:,:-1]\ny=df2Wheeler.loc[:,'2Wheeler']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=232)\nmodel2wheel = LogisticRegressionCV(Cs=np.linspace(1e-2,10,50),cv=5,penalty='elasticnet',solver='saga',l1_ratios=np.linspace(0,1,10), random_state=232)\nresult = model2wheel.fit(X_train, y_train)\nprint('best regularization strength: %d'  %model2wheel.C_)\nprint('l1_ration %.2f' %model2wheel.l1_ratio_)","53ff7155":"prediction_test = model2wheel.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in model2wheel.coef_.flatten()])\nprint('coefficients')\nprint(model2wheel.coef_.flatten())\nweights = pd.Series(model2wheel.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","21cd3c10":"X=dfPubTrans.iloc[:,:-1]\ny=dfPubTrans.loc[:,'PublicTransport']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=232)\nmodelPT = LogisticRegressionCV(Cs=np.linspace(1,20,50),cv=5,penalty='elasticnet',solver='saga',l1_ratios=np.linspace(0,1,10), random_state=232)\nresult = modelPT.fit(X_train, y_train)\nprint('best regularization strength: %d'  %modelPT.C_)\nprint('l1_ration %.2f' %modelPT.l1_ratio_)","9dff74c0":"prediction_test = modelPT.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in modelPT.coef_.flatten()])\nprint('coefficients')\nprint(modelPT.coef_.flatten())\nweights = pd.Series(modelPT.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","f725e852":"prediction_set['Male']=[1 if x=='Male' else 0 for x in prediction_set['Gender']]\nprediction_set","81b1a66f":"X_predict=dfCar=prediction_set.loc[:,['Age', 'Engineer', 'MBA', 'Work Exp', 'Salary','Distance', 'license','Male']]","f84b7a73":"modelPT.predict_proba(X_predict)","61e9c358":"pCar=modelCar.predict_proba(X_predict)\np2wheel=model2wheel.predict_proba(X_predict)\npPubTrans=modelPT.predict_proba(X_predict)\npd.concat([pd.DataFrame(data=pCar, index=[1,2], columns=['NoCar','Car']),pd.DataFrame(data=p2wheel, index=[1,2], columns=['No2Wheel','2Wheel']),\n          pd.DataFrame(data=pPubTrans, index=[1,2], columns=['NoPT','PT'])],axis=1)","0b39e486":"X=df.loc[:,['Age', 'Engineer', 'MBA', 'Work Exp', 'Salary','Distance', 'license','Male']]\ny=df.Transport","046ed15f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=232)\nmodel = LogisticRegressionCV(Cs=np.linspace(1e-4,10,50),cv=5,penalty='elasticnet',solver='saga',l1_ratios=np.linspace(0,1,10), multi_class='multinomial', random_state=232)\nresult = model.fit(X_train, y_train)\nprint('best regularization strength:' ,model.C_)\nprint('l1_ratios',model.l1_ratio_)","0b5aced1":"prediction_test = model.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))\nprint('probalbilities')\nprint([exp(x)\/(1+exp(x)) for x in modelPT.coef_.flatten()])\nprint('coefficients')\nprint(model.coef_.flatten())\nweights = pd.Series(model.coef_[0],\n                 index=X.columns.values)\nprint (weights.sort_values(ascending = False)[:10].plot(kind='bar'))","8866da66":"model.predict(X_predict)","cee8a900":"model.predict_proba(X_predict)\npd.DataFrame(data=model.predict_proba(X_predict), index=['1',2], columns=['Car','2Wheeler','PublicTransport'])","f920490b":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_validate   #Additional scklearn functions","cab4c6e6":"#defining X as transport for XGBoost.\nX=df.loc[:,['Age', 'Male', 'Engineer', 'MBA', 'Work Exp', 'Salary','Distance', 'license']]\ny=df.loc[:,['Transport']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=232)\nmodel=GradientBoostingClassifier(random_state=232)\nmodel.fit(X_train, y_train)","8c6467f6":"prediction_test = model.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))","eb93278c":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(3),range(3))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix with XGBoost\")","8a2426ec":"from sklearn.model_selection import RandomizedSearchCV","5463f9de":"random_grid = {\n    'learning_rate':[1e-4,1e-2,0.1,1],\n    'max_depth':[2,5,15],\n    'max_features':[2,4,7],\n    'max_leaf_nodes':[2,8,15],\n    'min_samples_leaf':[2,6,10],\n    'min_samples_split':[2,6,10],\n    'n_estimators':[100,200,300]}","06eaa55a":"xgb=GradientBoostingClassifier()\nrf_random = RandomizedSearchCV(estimator = xgb, param_distributions =\nrandom_grid, n_iter = 100, cv = 5, verbose=2, random_state=232,\nn_jobs = -1)\nrf_random.fit(X_train, y_train)","777abbc9":"best_random=rf_random.best_estimator_","381e566d":"prediction_test = best_random.predict(X_test)\n#df['logisticCVL1']=model.predict(X)\n# Print the prediction accuracy\nprint('accuracy %.2f' %(metrics.accuracy_score(y_test, prediction_test)))","89439d18":"arr=metrics.confusion_matrix(y_test,prediction_test)\ndf_cm = pd.DataFrame(arr, range(3),range(3))\n#plt.figure(figsize = (10,7))\nsns.set(font_scale=1)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 10},fmt=\"d\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix with XGBoost with Randomized search\")","f701f9de":"best_random.predict(X_predict)","2a5ba868":"Checking the probabilities","33b1169f":"**Logistic regression to predict preference for Cars**","516183af":"Pair plots","30ce1466":"**Confusion Matrix**","f521b003":"Checking for Datatypes","5f883a62":"**Logistic regression with LassoCV**","42b9cf5e":"This kernel shows the implementation of \n* Logistic regression for binary classification\n* Logistic regression CV with Lasso regularization\n* Logistic regression CV with Ridge Regularization\n* Using multiple binary classification for multi class classification using Logistic regression\n* Logistic regression multiclass classification\n* XG boost\n* XG boost with random search.\n\nThe dataset is data of employee transport. The aim for the kernel is to find car as the preference for transport and then extend it to predict the choice of transport for employees. ","8af81d3a":"**Public transport has the Highest probability.**","1cb6cf39":"**Correlation w.r.t Use of Car**","4afaea8a":"accuracy improved from 81% to 84%","17f263ed":"**Trying to analyze and predict usage of car.**","2d93e035":"**Declaring Functions**","6dc8df68":"**Accuracy: 95%**","2a8042ec":"Results are inline with logistic regression.","1c528297":"Trying this to predict on our predictiokn set","df7122ce":"Types of transport used by employees","dd23b181":"The probabilities are similar to binary classifier results.","52ae3134":"**ROC Curve**","06460694":"**Model gives an accuracy of 96%**","1f04aef5":"**Trying xgboost to improve accuracy**","fd45bc67":"Checking for Null values","781e4d46":"**choosing columns to run the model on**","5c36c94a":"Predicting on the prediction set using three logistic regression models above","dc804ab9":"**Accuracy 96%**","9f20c901":"**Modeliing for public transport**","80988108":"Male\/Female counts","bd4a1b60":"Converting to Numeric Types for Logistic regression","5f0a5e70":"**First trying without parameterization, default lbfs solver is not supported without l2 parameterization, so using saga**","cac4a37f":"**ROC Curve**","69d8cd28":"**Logistic regression with Multi classifier**","e8dd412d":"**Correlation Matrix**","c713ca71":"**Accuracy for mulyiclass classification is 77%**\nlicense and gender remain as the most important features.","1f22a6e1":"Density plots","cb802912":"Highest accuracy is with elastic net. Will try elastic net for predicting public transport and 2wheeler as well","6120e746":"Groupings by transport types","0e940d96":"**Precision Recall curve**","cfe12594":"**Confusion Matrix**","8cfe3ff5":"**Plotting the confusion matrix**","6d65da97":"**Logistic regression with Elastic net**","9fc130a5":"**Transport preference by profession**","ffdf958b":"**Hyper parameter tuning using Randomized Search**","912f2aaa":"**Logistic regression with Ridge CV**","62359a05":"Work Exp and Licence are the most importance positive for employees prefering cars, where as Age and MBA negatively show on preference of cars according to our logistic regression.","0dfd97b8":"**Accuracy 96%**","abffe976":"Distribution plots","37b4c7c9":"**Logistic regression with Ridge CV**","63159bdf":"Predicting out prediction set","63c6d827":"**Modelling for 2 wheeler**","9c653c7a":"Correlation plots"}}