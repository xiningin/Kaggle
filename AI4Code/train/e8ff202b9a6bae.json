{"cell_type":{"09bf4043":"code","06c845bf":"code","3606de97":"code","a284eaf0":"code","a0ecf752":"code","b5f564f5":"code","cbafc1e5":"code","f9ef816e":"code","965ea3e5":"code","6f048184":"code","5f84942a":"code","9d91742a":"code","9c3640fd":"code","7ca4383d":"code","be12d0e2":"code","edde0bf7":"code","9d679bb2":"code","a95e72db":"code","747fc30a":"code","e3228a43":"markdown","041e8b59":"markdown","85184cb5":"markdown","1c5a9bdd":"markdown","f6df71fe":"markdown","a411a31d":"markdown","aed79c65":"markdown","477c2b9a":"markdown","c2eacc86":"markdown","5df3d521":"markdown","94cadcd0":"markdown","919a8253":"markdown","4a7fb2c0":"markdown"},"source":{"09bf4043":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport keras\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n\n\nsns.set(style='white', context='notebook', palette='deep')","06c845bf":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","3606de97":"train.head()","a284eaf0":"g = sns.catplot(x=\"label\", kind=\"count\", palette='bright', data=train)\ng.fig.set_size_inches(16, 5)\n\ng.ax.set_title('MNIST by Class', fontsize=20)\ng.set_xlabels(' MNIST Class', fontsize=14)\ng.set_ylabels('Number of Data Points', fontsize=14)","a0ecf752":"X = train.drop(['label'], 1).values\nX = X \/ 255.0\n\ny = train['label'].values\n\ntest_x = test.values\ntest_x = test_x \/ 255.0","b5f564f5":"X = X.reshape(-1,28,28,1)\ntest_x = test_x.reshape(-1,28,28,1)","cbafc1e5":"y = to_categorical(y)\n\nprint(f\"Shape of Label Data {y.shape}\")","f9ef816e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)","965ea3e5":"X_train__ = X_train.reshape(X_train.shape[0], 28, 28)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train__[i], cmap='binary')\n    digit = y_train[i].argmax()\n    ax.set(title = f\"Real Number is {digit}\");","6f048184":"x_train = np.asarray(X_train)\nx_test = np.asarray(X_test)\n\nx_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\n\nx_test_mean = np.mean(x_test)\nx_test_std = np.std(x_test)\n\nx_train = (x_train - x_train_mean)\/x_train_std\nx_test = (x_test - x_test_mean)\/x_test_std","5f84942a":"input_shape = (28, 28, 1)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()\nplot_model(model, show_shapes=True, show_layer_names=True)","9d91742a":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(lr=0.001),\n              metrics=['accuracy'])","9c3640fd":"checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')","7ca4383d":"batch_size = 32 \nepochs = 50\n\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          callbacks = [checkpoint, early],\n          verbose=1,\n          validation_data=(x_test, y_test))\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","be12d0e2":"plt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","edde0bf7":"final_loss, final_acc = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Model loss: {0:.4f}, Model accuracy: {1:.4f}\".format(final_loss, final_acc))","9d679bb2":"y_pred_enc = model.predict(test_x)\ny_pred = [np.argmax(i) for i in y_pred_enc]","a95e72db":"fig, ax = plt.subplots(figsize=(18, 12))\nfor ind, row in enumerate(test_x[:15]):\n    plt.subplot(3, 5, ind+1)\n    plt.title(y_pred[ind])\n    img = row.reshape(28, 28)\n    fig.suptitle('Predictions', fontsize=20)\n    plt.axis('off')\n    plt.imshow(img, cmap='Dark2')","747fc30a":"mnist_test = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\nmnist_test = np.loadtxt(mnist_test, skiprows=1, delimiter=',')\nnum_images = mnist_test.shape[0]\nout_x = mnist_test.reshape(num_images, 28, 28, 1)\nout_x = out_x \/ 255\nresults = model.predict(out_x)\nresults = np.argmax(results,axis = 1)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(results)+1)),\"Label\": results})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)\nprint('Submission csv Generated!')\n","e3228a43":"<img src = https:\/\/media.giphy.com\/media\/W3a0zO282fuBpsqqyD\/giphy.gif>","041e8b59":"<img src = \"https:\/\/media.giphy.com\/media\/113PoJxEaRxKbm\/giphy.gif\">","85184cb5":"<b> Model Evaluation and Prediction <\/b>","1c5a9bdd":"<b> CNN Architecture <\/b>","f6df71fe":"#### To Do\n* Experiments with Data Preprocessing\n* Experiments with Model Build\n* Increase Score for Prediction\n\n##### Cheers!!!\n<img src = \"https:\/\/media.giphy.com\/media\/dZojblqWlIChGElasF\/giphy.gif\">","a411a31d":"<img src = \"https:\/\/media.giphy.com\/media\/jtirFYtVwG5a0o1t9o\/source.gif\">","aed79c65":"<b> Training <\/b>","477c2b9a":"<img src = \"https:\/\/media.giphy.com\/media\/MZM94AfS0jSG4dZhjf\/giphy.gif\">","c2eacc86":"# Digit Recognizer\n***Shape recognition, and handwritten digit recognition in particular, is one of the most graceful topics for anyone starting to learn AI. There are several reasons, but the two most important are the ease with which we can use well-prepared ready-made datasets and the ability to visualize these data.***\n***The set consists of 60,000 elements in the training set and 10,000 in the test set. Each element is a 28 by 28 pixel image. The images are not colored, so for each pixel we have one value representing the shade of gray.***\n<img src=\"https:\/\/aigeekprogrammer.com\/wp-content\/uploads\/2019\/08\/Handwriting-digit-recognition-Keras-MNIST.jpg\">","5df3d521":"<b> Submission csv Generation <\/b>","94cadcd0":"<b>Data Normalization <\/b>","919a8253":"<b> Displaying sample data <\/b>\n","4a7fb2c0":"<img src = \"https:\/\/media.giphy.com\/media\/WO5cigosk5WdK3b6bE\/giphy.gif\">"}}