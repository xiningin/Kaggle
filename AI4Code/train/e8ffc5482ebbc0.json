{"cell_type":{"51a6e7fc":"code","56228bc6":"code","7bb302d7":"code","afc0d6d1":"code","1a5eb31f":"code","c4acd57a":"code","5e0d0d5c":"code","7e324a1a":"code","30763ce0":"code","bf372dc0":"code","039137ef":"code","55f9dab5":"code","87a0bd89":"markdown","99b5422e":"markdown","7a40031c":"markdown","d79504b8":"markdown","30477d28":"markdown","6cf98c54":"markdown","c4bdffcd":"markdown","9de69093":"markdown","3bd3ebbf":"markdown","562bba58":"markdown"},"source":{"51a6e7fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","56228bc6":"import pandas as pd\n\ndf= pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","7bb302d7":"df.isna().sum()","afc0d6d1":"df.info()","1a5eb31f":"df['quality'].value_counts()","c4acd57a":"df['quality'] = ['Good' if x>=7 else 'bad' for x in df['quality']]\ndf.head()","5e0d0d5c":"# Split data\nx = df.drop('quality', axis=1)\ny = df['quality']\n\nx.head()","7e324a1a":"y.head()","30763ce0":"# Import standard scaler\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\n# apply scaler\nx = ss.fit_transform(x)\n\nx","bf372dc0":"#import modules\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# define and configure the model\nmodel = KNeighborsClassifier()\n\n# evaluate the model \ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n\n# report model performance\nprint('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n","039137ef":"#import modules\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.svm import SVC\n\n# define and configure the model\nmodel = SVC()\n\n# evaluate the model \ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n\n# report model performance\nprint('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n","55f9dab5":"#import modules\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\n\n# define and configure the model\nmodel = RandomForestClassifier()\n\n# evaluate the model \ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n\n# report model performance\nprint('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n","87a0bd89":"Woow our data is not having any null value. So there's no need to clean the data. \ud83d\ude03\ud83d\ude03\n\nNow let's check the information about the features we have.","99b5422e":"So we have total 1599 rows each having 12 features.\nLet's explore the data ","7a40031c":"Yehh! our data is ready for modelling and then predicting wheather a wine is of good or bad quality. \ud83d\ude00\n\n### Modelling\n\nWe'll use following models and then evaluate them to find which model works well:\n\n* KNN\n* SVM\n* Random Forest\n\n**KNN**","d79504b8":"**So we can see that accuracy of Random forest is the highest**\n\nHence we can easily classify that weather a wine is good or bad in quality using Random forest.\n\n**Accuracy is 90%**\n\n**PLEASE UPVOTE MY NOTEBOOK IF IT HELPED YOU** \ud83d\ude0a\ud83d\ude0a","30477d28":"Let's check if there are any null values","6cf98c54":"## Wine-quality-classifier \ud83c\udf77\ud83c\udf7e\n\nJust follow this notebook till the end and you could predict quality of wine is good or bad.\n\n**In this notebook we'll classify the quality of wine into Good or Bad.\nAlltough in the data the target variable have numbers between 0-10 but we can classify it by classifying all obsevations as:**\n        \n* quality >= 7  as  good\n* quality < 7 as bad\n\nLet's firstly import data and analyse it ","c4bdffcd":"See our quality variable have values good and bad.\nNow our data needs just one thing more to be ready for modelling.\n\nWe have to change data values all into one range by using **Standardization** so that our model can easily predict.\n\nFor this we have to do following steps.\n* Split data into x (input features) & y(target variable)\n* Then use Standard Scaler to to change data values of 'x'  into one range.","9de69093":"**SVM model**","3bd3ebbf":"**Random forest model**","562bba58":"So we can see there are only 217 (199+18) records having quality >=7 i.e of good quality\n\nNow let's change our target variable(quality) into good and bad."}}