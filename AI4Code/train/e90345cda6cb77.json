{"cell_type":{"a10dd1e1":"code","4609146b":"code","ee14fb00":"code","8f511507":"code","68425cc0":"code","bbec2dab":"code","31e44136":"code","22f65ce2":"code","73096729":"code","195b190a":"code","0e0af8e7":"code","5f2723ce":"code","dc0e19d6":"code","313ab226":"code","608279bf":"code","91f2d763":"code","cec7da0b":"code","a939709f":"code","325c7da7":"code","774d88cf":"code","a1932221":"code","25c06616":"code","cdaa01c2":"code","5f49fe07":"code","4c21ce56":"code","df2e2d68":"code","4172614d":"code","3a577a13":"code","1c5d87e3":"code","54b66c37":"code","4811bf15":"code","b617d096":"code","74dcef74":"code","59b6a219":"code","27f52f48":"code","3c394706":"code","df658405":"code","c28f2315":"code","95231269":"code","917784ac":"code","bb0166b7":"code","27e171dd":"code","09c0826a":"code","d3c635a1":"code","bdab0545":"code","b04bb4f0":"code","d1091f8b":"code","7a8f8cfa":"code","128dba68":"code","144d6783":"code","68b2c49e":"code","a2f859f7":"code","786880da":"code","86061f1e":"code","1fa5b5db":"code","2bac53a9":"code","2967064c":"code","24cf183d":"code","724bc98a":"code","a6f52d90":"code","db178942":"code","27ec626b":"code","dc663abd":"code","b48d407e":"code","9cced756":"code","58615b25":"markdown","40192444":"markdown","25157c30":"markdown","b8c7025d":"markdown","d97c0ee3":"markdown","c76c1263":"markdown","dee84e56":"markdown","b6687a66":"markdown","5a4b6d6d":"markdown","2db36ca8":"markdown","d4df1199":"markdown","937be902":"markdown","67631ed6":"markdown","9a5d4517":"markdown","0320fd5d":"markdown","f03dc2ed":"markdown","fe0a40ea":"markdown","911803fd":"markdown","0069dabb":"markdown","ddd5a51e":"markdown","b375993d":"markdown","6e2e8d46":"markdown","091d564d":"markdown","a14dc458":"markdown","6899b985":"markdown","b7cdb8e2":"markdown","97429b37":"markdown","a20d31c3":"markdown","f15a9f1a":"markdown"},"source":{"a10dd1e1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4609146b":"train_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.head()","ee14fb00":"test_data = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_data.head()","8f511507":"submission_example = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission_example.head()","68425cc0":"submission = pd.DataFrame()\nsubmission['PassengerId'] = test_data['PassengerId']","bbec2dab":"train_data.info()","31e44136":"test_data.info()","22f65ce2":"train_data.describe()","73096729":"test_data.describe()","195b190a":"train_data.isnull().sum()","0e0af8e7":"test_data.isnull().sum()","5f2723ce":"plt.hist(train_data['Age'])\nplt.show()","dc0e19d6":"plt.hist(test_data['Age'])\nplt.show()","313ab226":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())","608279bf":"train_data['Cabin'].value_counts()","91f2d763":"test_data['Cabin'].value_counts()","cec7da0b":"train_data.drop(['Cabin'], axis = 1, inplace = True)\ntest_data.drop(['Cabin'], axis = 1, inplace = True)\n","a939709f":"plt.hist(train_data['PassengerId'])\nplt.show()","325c7da7":"train_data['PassengerId'].value_counts()","774d88cf":"train_data.drop(['PassengerId'], axis = 1, inplace = True)\ntest_data.drop(['PassengerId'], axis = 1, inplace = True)","a1932221":"sns.countplot(train_data['Survived'])","25c06616":"sns.countplot(x = \"Pclass\", hue = \"Survived\", data = train_data)","cdaa01c2":"train_data['Name'].value_counts()","5f49fe07":"train_data.drop(['Name'], axis = 1, inplace = True)\ntest_data.drop(['Name'], axis = 1, inplace = True)","4c21ce56":"sns.countplot(train_data['Sex'])","df2e2d68":"sns.countplot(x = \"Sex\", hue = \"Survived\", data = train_data)","4172614d":"plt.hist(train_data['Age'])","3a577a13":"plt.hist(test_data['Age'])","1c5d87e3":"plt.hist(train_data['SibSp'])","54b66c37":"plt.hist(test_data['SibSp'])","4811bf15":"plt.hist(train_data['Parch'])","b617d096":"plt.hist(test_data['Parch'])","74dcef74":"train_data['Ticket'].unique()","59b6a219":"train_data.drop(['Ticket'], axis = 1, inplace = True)\ntest_data.drop(['Ticket'], axis = 1, inplace = True)","27f52f48":"train_data.isnull().sum()","3c394706":"test_data.isnull().sum()","df658405":"plt.hist(train_data['Fare'])\nplt.show()","c28f2315":"plt.hist(test_data['Fare'])\nplt.show()","95231269":"train_data['Fare'] = train_data['Fare'] ** (1 \/ 3)\ntest_data['Fare'] = test_data['Fare'] ** (1 \/ 3)","917784ac":"plt.hist(train_data['Fare'])\nplt.show()","bb0166b7":"plt.hist(test_data['Fare'])\nplt.show()","27e171dd":"test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())","09c0826a":"train_data.isnull().sum()","d3c635a1":"test_data.isnull().sum()","bdab0545":"sns.countplot(train_data['Embarked'])","b04bb4f0":"sns.countplot(x = \"Embarked\", hue = \"Survived\", data = train_data)","d1091f8b":"train_data['Embarked'] = train_data['Embarked'].fillna(train_data['Embarked'].mode())","7a8f8cfa":"train_data = pd.get_dummies(train_data, columns=['Sex', 'Embarked'])\ntest_data = pd.get_dummies(test_data, columns=['Sex', 'Embarked'])","128dba68":"train_data.head()","144d6783":"plt.figure(figsize=(20, 10))\nsns.heatmap(train_data.corr(), annot = True)","68b2c49e":"train_data.drop(['Sex_male', 'Embarked_S'], axis = 1, inplace = True)\ntest_data.drop(['Sex_male', 'Embarked_S'], axis = 1, inplace = True)","a2f859f7":"X = train_data.drop(['Survived'], axis = 1)\ny = train_data['Survived']","786880da":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\nlr = LogisticRegression()\nsvm = SVC()\ngnb = GaussianNB()\nrf = RandomForestClassifier()\ndt = DecisionTreeClassifier()\nknn = KNeighborsClassifier()\n\ndef evulate_model(model, X, y):\n    cv = cross_val_score(model, X, y, cv = 5)\n    print(cv)\n    print(cv.mean())","86061f1e":"print(\"Logistic regression\")\nevulate_model(lr, X, y)\n\nprint(\"SVC\")\nevulate_model(svm, X, y)\n\nprint(\"GaussianNB\")\nevulate_model(gnb, X, y)\n\nprint(\"Random forest classifier\")\nevulate_model(rf, X, y)\n\nprint(\"Decision tree\")\nevulate_model(dt, X, y)\n\nprint(\"KNN\")\nevulate_model(knn, X, y)","1fa5b5db":"train_data","2bac53a9":"test_data","2967064c":"rf.fit(X, y)","24cf183d":"from sklearn.model_selection import GridSearchCV \ngrid = {\n                'n_estimators': [10, 20, 40, 50, 100, 150, 200, 500],\n                'max_features': ['auto', 'sqrt'],\n                'max_depth': [3, 5, 7, 9, 11, 15],\n                'bootstrap': [True, False]\n                }\nrf = RandomForestClassifier()\nrf_random = GridSearchCV(estimator = rf, param_grid = grid, cv = 3, verbose=2, n_jobs = -1)\nrf_random.fit(X, y)","724bc98a":"rf_random.score(X, y)","a6f52d90":"pred = rf_random.predict(test_data)","db178942":"submission['Survived'] = pred","27ec626b":"submission.head()","dc663abd":"submission = submission.set_index('PassengerId')","b48d407e":"submission.head()","9cced756":"submission.to_csv(\"submission.csv\")","58615b25":"According to the pivot table train and test datasets have a equal distribution on numerical columns. ","40192444":"In this notebook, I will try to show the procceses I've done on the titanic dataset to predict final survival status.  The submission file in the end of this session has 0.78708 accuracy rate and placed to top 5.79% !(Currently 1,609th place out of 27,800)\n\nNow lets begin with importing the neccesary libraries!","25157c30":"# Data proccesing","b8c7025d":"Again, the sex column has a similar situation with the class column in here majority of the women survived but men did not.","d97c0ee3":"This is what our final submission to competition will look like! Lets make ready the our submission data frame before moving on the data proccesing!","c76c1263":"It appears like our age is close enough to normal distribution and since we don't have many null values we can replace the null values with mean.","dee84e56":"*** Feature: Ticket ***","b6687a66":"Looks like we only have few categorical variables in our dataset, this will make our job easier since its continous values are valuable for ML models. Now lets have a quick look at our central tendencies!","5a4b6d6d":"Looks like most of the first class passengers survived meanwhile majority of the third class passengers didn't","2db36ca8":"Our PassengerId is a unique value assigned to every passenger, we can drop this column since it will have 0 effect on our predictions.","d4df1199":"*** Feature: Parch ***","937be902":"*** Feature: SibSp ***","67631ed6":"# Feature Engineering","9a5d4517":"# Explorary data analysis & Feature Scaling","0320fd5d":"*** Feature: PassengerId ***","f03dc2ed":"*** Feature: Embarked ***","fe0a40ea":"# Loading the data & Data Cleaning","911803fd":"*** Feature: Survived ***","0069dabb":"*** Feature: PClass ***","ddd5a51e":"*** Feature: Name ***","b375993d":"We have total 10 column in our dataset with descriptions given bellow.\n\n\n***survival*** \tSurvival \t0 = No, 1 = Yes\n\n***pclass*** \t    Ticket class \t1 = 1st, 2 = 2nd, 3 = 3rd\n\n***sex*** \t    Sex \t\n\n***Age*** \t    Age in years \t\n\n***sibsp*** \t    # of siblings \/ spouses aboard the Titanic \t\n\n***parch*** \t    # of parents \/ children aboard the Titanic \t\n\n***ticket*** \t    Ticket number \t\n\n***fare*** \t    Passenger fare \t\n\n***cabin*** \t    Cabin number \t\n\n***embarked*** \tPort of Embarkation","6e2e8d46":"Since the Fare feature has a exponential distribution we can maybe with this issue with square root transformatio.","091d564d":"*** Missing values ***","a14dc458":"Since like the cabin feature has too many different and null values, I will drop this column to avoid curse of dimensionality.","6899b985":"*** Feature: Sex ***","b7cdb8e2":"The test dataset doesn't have the 'Survived' column since we will predict those values with model trained on training data set.","97429b37":"# Model Fitting","a20d31c3":"*** Feature: Age ***","f15a9f1a":"*** Feature: Fare ***"}}