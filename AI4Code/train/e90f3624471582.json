{"cell_type":{"0b51abc8":"code","9f1eed1b":"code","f713a25f":"code","293d1640":"code","ea58b3b2":"code","8f654894":"code","18cf9fae":"code","a9d2a6d9":"code","081650e0":"code","d652287c":"code","c91d579d":"code","328eea2c":"code","6e297712":"code","d483fa36":"code","a1e09d2e":"code","d15775b6":"code","ab8bf462":"code","a4905a33":"code","b69bd933":"code","69409a13":"code","816c7c8f":"code","35770b5e":"code","b34d8c7c":"code","5117a309":"code","86ee9ced":"code","4174bb40":"code","691666fd":"code","f3b5925b":"code","48763e60":"code","9b172d3e":"code","8594eba9":"code","24a1f3f9":"code","ee4b3b2a":"code","4e94df03":"code","871a1ad7":"code","aa740005":"code","cb016c2c":"code","cc479bd7":"code","6e70bb88":"code","58f30c69":"code","2879a84d":"code","e2686130":"code","b209de28":"code","a725f67b":"code","43087b4b":"code","505565e3":"code","3e8766fd":"code","fe05892f":"code","850a437f":"code","187a44b8":"code","f7ff5adb":"code","fea47bc2":"code","680c2d62":"code","2bbcaf31":"code","7a17217f":"code","06c83363":"code","1e3e4c7a":"code","06ccb00c":"code","71f2a474":"code","eeda645b":"code","de404bd7":"code","5999d634":"code","753c4d9d":"code","8f2823fe":"code","ac91bb93":"code","c73d7065":"code","f0f7be1e":"code","7cc941f8":"code","23982aeb":"code","81a6b4b9":"code","5381a2d3":"code","4055c81f":"code","11b04042":"code","c3782fe8":"code","2db5b1e7":"markdown","2aa381ac":"markdown","67f6b7b8":"markdown","ad8be84a":"markdown","c72a4b65":"markdown","10217794":"markdown","4d7b9ee6":"markdown","4fd5b1b3":"markdown","e3e26f3d":"markdown","00d72f25":"markdown","2660efa3":"markdown","18fd62f8":"markdown","de80c7fa":"markdown","9bde342b":"markdown","3a8f5725":"markdown","38d5da9a":"markdown","64dd3456":"markdown","0c0c1bef":"markdown","e1429052":"markdown","7326cc60":"markdown","54b47afa":"markdown","88cf441f":"markdown","4ce983cb":"markdown","22a959ca":"markdown","f2f09676":"markdown","0a4ece3c":"markdown","22174c7c":"markdown","98715a0f":"markdown","c1c50936":"markdown","6207de43":"markdown","049fb715":"markdown","66c358bd":"markdown","039f9def":"markdown","0783f12e":"markdown","9637ea09":"markdown","07cc3cb2":"markdown","ea942fe9":"markdown","1a620c57":"markdown","da7b1c8a":"markdown","0a435b8d":"markdown","011e1736":"markdown","db53029f":"markdown","4e0eb7cd":"markdown","abbfdf31":"markdown","7adf97f7":"markdown","18a4c9a4":"markdown","031aa52c":"markdown","9d941b58":"markdown","23d70a60":"markdown"},"source":{"0b51abc8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","9f1eed1b":"import pandas as pd\nfilename = \"..\/input\/black-friday\/train.csv\"\n\ntrain=  pd.read_csv(filename)\n\ntrain.head()","f713a25f":"test= pd.read_csv(\"..\/input\/black-friday\/test.csv\")\ntest.head()","293d1640":"train.describe()","ea58b3b2":"# Checking for null values\ntrain['Product_Category_1'].isna().mean()*100, train['Product_Category_2'].isna().mean()*100, train['Product_Category_3'].isna().mean()*100","8f654894":"# droping Product_Category_3 column\ntrain.drop([\"Product_Category_3\"],  axis=1, inplace=True)\n","18cf9fae":"train.columns","a9d2a6d9":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split  \nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","081650e0":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12,7))\nsns.distplot(train.Purchase, bins = 25)\nplt.xlabel(\"Amount spent in Purchase\")\nplt.ylabel(\"Number of Buyers\")\nplt.title(\"Purchase amount Distribution\")","d652287c":"numeric_features = train.select_dtypes(include=[np.number])\nnumeric_features.dtypes","c91d579d":"sns.countplot(train.Marital_Status)","328eea2c":"sns.countplot(train.Product_Category_1)\nplt.xticks()","6e297712":"sns.countplot(train.Product_Category_2)\nplt.xticks(rotation=90)","d483fa36":"corr = numeric_features.corr()\n","a1e09d2e":"#correlation matrix\nf, ax = plt.subplots(figsize=(20, 9))\nsns.heatmap(corr,  annot=True,annot_kws={'size': 15})","d15775b6":"sns.countplot(train.Gender)","ab8bf462":"sns.countplot(train.Age)","a4905a33":"sns.countplot(train.City_Category)","b69bd933":"sns.countplot(train.Stay_In_Current_City_Years)","69409a13":"marital_status_pivot= train.pivot_table(index='Marital_Status',values='Purchase', aggfunc=np.mean)\nmarital_status_pivot","816c7c8f":"marital_status_pivot.plot(kind='bar', color='blue',figsize=(12,7))\nplt.xlabel(\"Marital_Status\")\nplt.ylabel(\"Purchase\")\nplt.title(\"Marital_Status and Purchase Analysis\")\nplt.xticks(rotation=0)\nplt.show()","35770b5e":"Product_category_1_pivot = train.pivot_table(index='Product_Category_1', values=\"Purchase\", aggfunc=np.mean)\nProduct_category_1_pivot","b34d8c7c":"Product_category_1_pivot.plot(kind='bar', color='green',figsize=(12,7))\nplt.xlabel(\"Marital_Status\")\nplt.ylabel(\"Purchase\")\nplt.title(\"Marital_Status and Purchase Analysis\")\nplt.xticks(rotation=0)\nplt.show()","5117a309":"Product_category_2_pivot = train.pivot_table(index='Product_Category_2', values=\"Purchase\", aggfunc=np.mean)\n","86ee9ced":"Product_category_2_pivot.plot(kind='bar', color='brown',figsize=(12,7))\nplt.xlabel(\"Product_Category_2\")\nplt.ylabel(\"Purchase\")\nplt.title(\"Product_Category_2 and Purchase Analysis\")\nplt.xticks(rotation=0)\nplt.show()","4174bb40":"gender_pivot = train.pivot_table(index='Gender', values=\"Purchase\", aggfunc=np.mean)\ngender_pivot","691666fd":"gender_pivot.plot(kind='bar', color='orange',figsize=(12,7))\nplt.xlabel(\"Gender\")\nplt.ylabel(\"Purchase\")\nplt.title(\"Gender and Purchase Analysis \" \"AVERAGE\")\nplt.xticks(rotation=0)\nplt.show()","f3b5925b":"age_pivot = train.pivot_table(index='Age', values=\"Purchase\", aggfunc=np.sum)\nage_pivot","48763e60":"age_pivot.plot(kind='bar', color='pink',figsize=(12,7))\nplt.xlabel(\"Age\")\nplt.ylabel(\"Purchase\")\nplt.title(\"Age and Purchase Analysis \" \"AVERAGE\")\nplt.xticks(rotation=0)\nplt.show()","9b172d3e":"city_pivot = train.pivot_table(index='City_Category', values=\"Purchase\", aggfunc=np.mean)\ncity_pivot","8594eba9":"city_pivot.plot(kind='bar', color='blue',figsize=(12,7))\nplt.xlabel(\"City_Category\")\nplt.ylabel(\"Purchase\")\nplt.title(\"City_Category and Purchase Analysis\")\nplt.xticks(rotation=0)\nplt.show()\n","24a1f3f9":"Stay_In_Current_City_Years_pivot = train.pivot_table(index='Stay_In_Current_City_Years', values=\"Purchase\", aggfunc=np.mean)\nStay_In_Current_City_Years_pivot","ee4b3b2a":"Stay_In_Current_City_Years_pivot.plot(kind='bar', color='red',figsize=(12,7))\nplt.xlabel(\"Stay_in_Current_City_Years\")\nplt.ylabel(\"Purchase\")\nplt.title(\"Stay_in_Current_City_Years and Purchase Analysis\")\nplt.xticks(rotation=0)\nplt.show()","4e94df03":"test.head()","871a1ad7":"# Join Train and Test Dataset\ntrain['source']='train'\ntest['source']='test'\n\ndf = pd.concat([train,test], ignore_index = True, sort = False)\n\nprint(train.shape, test.shape, df.shape)","aa740005":"test.drop([\"Product_Category_3\"],  axis=1, inplace=True)\ndf.drop([\"Product_Category_3\"],  axis=1, inplace=True)","cb016c2c":"print(train.shape, test.shape, df.shape)","cc479bd7":"#Check the percentage of null values per variable\ndf.isnull().mean()*100","6e70bb88":"# Replacing Null Values in Product_Category_2 with the median of the column\ndf[\"Product_Category_2\"].fillna(train[\"Product_Category_2\"].median(), inplace = True)\n","58f30c69":"#Get index of all columns with product_category_1 equal 19 or 20 from train\n\nind = df.index[(df.Product_Category_1.isin([19,20])) & (df.source == \"train\")]\ndf = df.drop(ind)","2879a84d":"df.shape","e2686130":"df.dtypes","b209de28":"#Filter categorical variables and get dataframe will all strings columns names except Item_identfier and outlet_identifier\ncategory_cols = df.select_dtypes(include=['object']).columns.drop([\"source\"])\n#Print frequency of categories\nfor col in category_cols:\n    #Number of times each value appears in the column\n    frequency = df[col].value_counts()\n    print(\"\\nThis is the frequency distribution for \" + col + \":\")\n    print(frequency)","a725f67b":"gender_dict = {'F':0, 'M':1}\ndf[\"Gender\"] = df[\"Gender\"].apply(lambda x: gender_dict[x])\n\ndf[\"Gender\"].value_counts()","43087b4b":"age_dict={'0-17':0, '18-25':1, '26-35':2, '36-45':3, '46-50':4, '51-55':5, '55+':6}\ndf['Age']=df['Age'].apply(lambda x:age_dict[x])\ndf['Age'].value_counts()","505565e3":"city={'A':0,'B':1,'C':2}\ndf['City_Category']=df['City_Category'].apply(lambda x: city[x])\ndf['City_Category'].value_counts()","3e8766fd":"def stay(Stay_In_Current_City_Years):\n        if Stay_In_Current_City_Years == '4+':\n            return 4\n        else:\n            return Stay_In_Current_City_Years\ndf['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].apply(stay).astype(int) ","fe05892f":"#Divide into test and train:\ntrain = df.loc[df['source']==\"train\"]\ntest = df.loc[df['source']==\"test\"]\n\n#Drop unnecessary columns:\ntest.drop(['source'],axis=1,inplace=True)\ntrain.drop(['source'],axis=1,inplace=True)\n\n#Export files as modified versions:\ntrain.to_csv(\"train_clean.csv\",index=False)\ntest.to_csv(\"test_clean.csv\",index=False)","850a437f":"train= pd.read_csv('train_clean.csv')\ntrain.head()","187a44b8":"test= pd.read_csv('test_clean.csv')\ntest.head()","f7ff5adb":"X = train.drop(['Product_ID','User_ID','Purchase'], axis=1)\ny = train[\"Purchase\"]","fea47bc2":"# splitting train and test set\nX_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2, random_state=42)","680c2d62":"#model\n%time\n\n\n\nrf_regressor = RandomForestRegressor(n_jobs=-1, \n                              random_state=42)\n\nrf_regressor.fit(X_train, y_train)\n","2bbcaf31":"rf_regressor.score(X_test, y_test)","7a17217f":"y_pred = rf_regressor.predict(X_test)","06c83363":"R2 = r2_score(y_test, y_pred)\nMAE = mean_absolute_error(y_test, y_pred)\nMSE = mean_squared_error(y_test, y_pred)\nprint(\"R2_Score_tune: {}\\n Mean_absolute_error_: {}\\n Mean_Square_error_tune: {}\".format(R2, MAE, MSE))","1e3e4c7a":"fig, ax = plt.subplots(figsize=(12,5))\nax = plt.scatter(y_test, y_pred, c=\"brown\")","06ccb00c":"# 1.RandomSearchCV \n\ngrid =  {\"n_estimators\": [10,50,100],\n       \"max_depth\": [None,10,20,30,40,50,],\n       \"max_features\": [\"auto\", \"sqrt\"],\n       \"min_samples_leaf\": [2,10,15],\n       \"min_samples_split\": [2,5,20]}","71f2a474":"randomsearchCV = RandomizedSearchCV(rf_regressor, param_distributions = grid, n_iter = 5, cv=5,  verbose = True, n_jobs=-1)","eeda645b":"%time\n\nrandomsearchCV.fit(X_train, y_train)","de404bd7":"randomsearchCV.best_params_","5999d634":"rf_regressor_tune = RandomForestRegressor(n_estimators=100, max_depth = 40, max_features = 'auto', min_samples_leaf =15,\n                                     min_samples_split=5 )","753c4d9d":"rf_regressor_tune.fit(X_train, y_train) ","8f2823fe":"y_pred_tune = rf_regressor_tune.predict(X_test)\n","ac91bb93":"R2_tune= r2_score(y_test, y_pred_tune)\nMAE_tune= mean_absolute_error(y_test, y_pred_tune)\nMSE_tune= mean_squared_error(y_test, y_pred_tune)\nprint(\"R2_Score_tune: {}\\n Mean_absolute_error_: {}\\n Mean_Square_error_tune: {}\".format(R2_tune, MAE_tune, MSE_tune))","c73d7065":"# compare prediction before and after Tunning\n\ncompare = {\"R^2_score\":[R2_tune, R2],\n            \"Mean Squared Error\": [MSE_tune, MSE],\n            \"Mean Absolute Error\": [MAE_tune, MAE]}\n\n\nCompare = pd.DataFrame(compare, index=[[\"After_tune\", \"Before Tune\"]])\nCompare\n","f0f7be1e":"fig, ax = plt.subplots(figsize=(12,5))\nax = plt.scatter(y_test, y_pred_tune, c=\"brown\")","7cc941f8":"test.head()","23982aeb":"# No. of features used to train the model must match with the input\n# Droppping User_id , Product_id and purchase columns\npredicted= test[['User_ID','Product_ID']]\ntest =test.drop(['User_ID','Product_ID','Purchase'],axis=1)","81a6b4b9":"test.head()","5381a2d3":"test_pred = rf_regressor_tune.predict(test)\ntest_pred","4055c81f":"predicted['Predicted_Purchase']=test_pred","11b04042":"predicted.head()","c3782fe8":"#saving calculated purchase in a csv file\npredicted.to_csv(\"predict.csv\",index=False)\n","2db5b1e7":"<p>It seems like our target variable has an almost Gaussian distribution\/ Normal Distribution.<\/p>","2aa381ac":"<p>We had more single customers than married. However, on average an individual customer tends to spend the same amount independently if his\/her is married or not<\/p>","67f6b7b8":"<h2>Exporting Data<\/h2>","ad8be84a":"<p>it looks like product category 3 has more null values which is close to 70 percent of the data, so we delete the feature. \nkeep product category 2 and 1.<\/p>","c72a4b65":"<h3> Distribution of the variable Marital_Status<\/h3>","10217794":"now it is time to understand the relationship between our target variable and predictors as well as the relationship among predictors.","4d7b9ee6":"Again, we see the same pattern seen before which show that on average people tend to spend the same amount on purchases regardeless of their group. People who are new in city are responsible for the higher number of purchase, however looking at it individually they tend to spend the same amount independently of how many years the have lived in their current city.","4fd5b1b3":"<h3>Distribution of the target variable: Purchase<\/h3>\n","e3e26f3d":"<h3>Distribution of the variable Product_Category_1<\/h3>","00d72f25":"<p>most of the buyrs are from city B<\/p>","2660efa3":"Optimizing hyperparameters for machine learning models is a key step in making accurate predictions. Hyperparameters define characteristics of the model that can impact model accuracy and computational efficiency. They are typically set prior to fitting the model to the data. In contrast, parameters are values estimated during the training process that allow the model to fit the data. Hyperparameters are often optimized through trial and error; multiple models are fit with a variety of hyperparameter values, and their performance is compared.\n\nCross-validation is often used to determine the optimal values for hyperparameters; we want to identify a model structure that performs the best on records it has not been trained on. A variety of hyperparameter values should be considered.","18fd62f8":"<p>Now that we\u2019ve analysed our target variable, let\u2019s consider our predictors(IV). Let\u2019s start by seeing which of our features are numeric.<\/p>","de80c7fa":"<h3>Distribution of the variable Product_Category_2<\/h3>","9bde342b":"<p>most purchases are made by people between 18 to 45 years old.<\/p>","3a8f5725":"The tendency looks like the longest someone is living in that city the less chance they are to buy new things. Hence, if someone is new in town and needs a great number of new things for their house that they\u2019ll take advantage of the low prices in Black Friday to purchase all the things needed.","38d5da9a":"Since train set do not contain column product_category_3 , it has to be deleted from test as well as combined datt frame","64dd3456":"<h3> Delaing with Categorical Values","0c0c1bef":"<p>Make predictions on test data with the model whose hyperparameter are tuned<\/p>","e1429052":"<h2>Analysis on Categorical Predictors<\/h2>\n\n","7326cc60":"It is generally a good idea to combine both test and train sets into one, in order to perform data cleaning and feature engineering and later divide them again. With this step we do not have to go through the trouble of repeting twice the same code, for both datasets. Let\u2019 s combine them into a dataframe datawith a sourcecolumn specifying where each observation belongs","54b47afa":"<h2><b>1.Exploaratory Data Analysis<\/b><\/h2>\n\n","88cf441f":"<h1><b><u>Predict Black Friday Sales<\/u><\/b><\/h1>\n<h2><b>Background About Data<\/b><\/h2>\n<p>A retail company \u201cABC Private Limited\u201d wants to understand the customer purchase behaviour (specifically, purchase amount) against various products of different categories. They have shared purchase summary of various customers for selected high volume products from last month.\nThe data set also contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), product details (product_id and product category) and Total purchase_amount from last month.<\/p>\n\n<h2><b>Problem Statement<\/b><\/h2>\n<p>Now, they want to build a model to predict the purchase amount of customer against various products which will help them to create personalized offer for customers against different products<\/p>\n\n\n","4ce983cb":"<h2><b>Modelling<\/b><\/h2>","22a959ca":"<h3> Preiction and Metrices <\/h3>","f2f09676":"<h3>Converting Age to numeric values<\/h3>","0a4ece3c":"<h2> Bivariate Analysis<\/h2>","22174c7c":"<h3>Distribution of the variable Gender<","98715a0f":"Total amount spent in purchase is in accordance with the number of purchases made, distributed by age.","c1c50936":"<h2><b>Data Pre-Processing<\/b><\/h2>","6207de43":"We saw previously that city type \u2018B\u2019 had the highest number of purchases registered. However, the city whose buyers spend the most is city type \u2018C\u2019.","049fb715":"<h3>Correlation between Numerical Predictor( IV) and Target variable(DV)<h3>","66c358bd":"<h2><b>Feature Engineering<\/b><\/h2>","039f9def":"Most of the buysrs are male","0783f12e":"<h2><b> Understanding the Data<\/b><\/h2>\n<p> The data set consists of 2 files:\n<ol>\n<li>train.csv: This file will be used to build the model<\/li>\n<li>test.csv: This file will be used to predict the purchase <\/li>\n<\/ol>\nThe data set consists of following Columns:\n<ul>\n<li>User_ID : User id of the customer<\/li>\n<li>Product_ID: Product id of the product<\/li>\n<li>Gender: male of female<\/li>\n<li>Age: Age in bins i.e 0-17, 18-25, 26-35, 36-45, 46-50, 51-55, 55+<\/li>\n<li>Occupation: Occupation (Masked)<\/li>\n<li>City_Category: Category of the City (A,B,C)<\/li>\n<li>Stay_In_Current_City_Years: Number of years stay in current city<\/li>\n<li>Marital_Status: 0-Unmarried, 1-Married<\/li>\n<li>Product_Category_1: Product Category (Masked)<\/li>\n<li>Product_Category_2: Product may belongs to other category also (Masked)<\/li>\n<li>Product_Category_3: Product may belongs to other category also (Masked)<\/li>\n<li>Purchase: Purchase Amount (Target Variable)<\/li><\/ul>\n\n<p><b>Questions that may be intersting to folllow-up:<\/b>\n<ol>\n<li>Which type of client spends more?<\/li>\n<li>Which product category had the highest sales?<\/li>\n<li>Who spend more married or unmarried>\/li>\n<li>According to age and sex what are the most bought products?<\/li>\n<\/ol>\n\n<h2><b>Analysis step<\/b><\/h2>\n<p>Trying to identify the most important variables and defining the best regression model for predicting target variable.\nHence, this analysis will be divided into five stages:\n<ol>\n<li>Exploratory data analysis (EDA)<\/li>\n<li>Data Pre-processing<\/li>\n<li>Feature engineering<\/li>\n<li>Modeling<\/li>\n<li>Improving the Model (Hyperparameter tuning)<\/li>\n<li>Ensembling<\/li>\n\n\n\n\n\n","9637ea09":"<h3>Converting gender to binary<\/h3>","07cc3cb2":"In all the three cases our model performed good while tuning hyperparameters: We have got higher R^2, and lower MSE & MAE compared to same values before tuning the hyperparameters","ea942fe9":"<p> Fitting the data with Best Parameters","1a620c57":"<p>Removing Product_Category_1 group 19 and 20 from Train as this is not in Product_Category_2<\/p>\n","da7b1c8a":"<h3> Dealing with Null-Values<\/h3>","0a435b8d":"<p>As expected there are more single people buying products on Black Friday than married people<\/p>\n\n","011e1736":"<h2><b>Improving Model<\/b><\/h3>","db53029f":"On average the male gender spends more money on purchase contrary to female, and also the percentage of male buyers is higher than female buyers","4e0eb7cd":"<p>From the distribution for products from category one, it is clear that three products stand out, number 1, 5 and 8. Unfortunately, we do not know which product each number represents.<\/p>","abbfdf31":"<p>Although there were more products bought for categories 1,5,8 the average amount spent for those three is not the highest. It is interesting to see other categories appearing with high purchase values despite having low impact on sales number.","7adf97f7":"<h3> Converting Stay_In_Current_City_Year to numeric<\/h3>","18a4c9a4":"<h3>Converting city_category to Numeric<\/h3>","031aa52c":"<p>There seems to be no multicollinearity with our predictors which is a good thing, although there is some correlation among the product categories<\/p>","9d941b58":"<p> The categorical columns are Product_ID, Gender, Age, City_Category, Stay_In_Current_City_Years and Source<\/p>","23d70a60":"<p> It seems that columns Product_Catogory_2 and Product_category_2 has null values"}}