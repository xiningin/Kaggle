{"cell_type":{"01705ba7":"code","038fcf35":"code","f1d8746c":"code","3d2727a9":"code","2cd64d34":"code","298980eb":"code","48a061ed":"code","038a1123":"code","19a7401a":"code","2f6c1856":"code","144715a6":"code","91be848a":"code","15dd387c":"code","da5d0309":"code","475e152e":"code","2c1b5109":"code","1ef9e7d8":"code","2e31d67d":"code","839b41d4":"code","2d9938d5":"code","2777a29b":"markdown","a7040481":"markdown","3b04443c":"markdown","8ab36c07":"markdown","db533c8c":"markdown","8db37733":"markdown","aa32fc65":"markdown"},"source":{"01705ba7":"#IMPORTING THE NECESSARY LIBRARIES\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","038fcf35":"#READING THE CSV FILE\ndf = pd.read_csv(\"..\/input\/sms-spam-collection-dataset\/spam.csv\",encoding='latin-1')","f1d8746c":"#DISPLAYING THE FIRST 5 ROWS OF THE DATASET\ndf.head()","3d2727a9":"#DATA CLEANING\ndf.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\ndf.columns = ['Label', 'SMS']\ndf.head()","2cd64d34":"df['Label'] = df['Label'].map({'ham':0, 'spam':1})\ndf = df[['SMS', 'Label']]\ndf.head()","298980eb":"sns.countplot(df['Label'])\nplt.xlabel('Label')\nplt.title('Number of HAM and SPAM messages')\nplt.show()","48a061ed":"from wordcloud import WordCloud,STOPWORDS\nspam_msg=df[df['Label'] == 1]\nspam_words=' '.join(spam_msg['SMS'])\nspam_msg","038a1123":"ham_msg=df[df['Label'] == 0]\nham_words=' '.join(ham_msg['SMS'])\nham_msg","19a7401a":"#HAM WORD CLOUD\nham_cloud=WordCloud(width=1000,height=500).generate(ham_words)\nplt.figure(figsize=(12,12))\nplt.imshow(ham_cloud)\nplt.axis('off')\nplt.show()","2f6c1856":"#SPAM WORD CLOUD\nspam_cloud=WordCloud(width=1000,height=500).generate(spam_words)\nplt.figure(figsize=(12,12))\nplt.imshow(spam_cloud)\nplt.axis('off')\nplt.show()","144715a6":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nps=WordNetLemmatizer()\ncorpus=[]\nfor i in range(0,len(df)):\n    reviews=re.sub('[^a-zA-Z]',' ',df['SMS'][i])\n    reviews=reviews.lower()\n    reviews=reviews.split()\n    reviews=[ps.lemmatize(word) for word in reviews if not word in set(stopwords.words('english'))]\n    reviews=' '.join(reviews)\n    corpus.append(reviews)","91be848a":"#ASSIGNING FEATURES AND TARGET VARIABLE\nX = df['SMS'].values\ny = df['Label'].values","15dd387c":"#SPLITTING THE DATA\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","da5d0309":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n\ncv = CountVectorizer(max_features=3700)\n\nX_train = cv.fit_transform(X_train).toarray()\nX_test = cv.transform(X_test).toarray()\n\nclf = MultinomialNB()\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","475e152e":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","2c1b5109":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier(random_state=0)\ndtc.fit(X_train,y_train)\ndtc_pred=dtc.predict(X_test)","1ef9e7d8":"cm_dtc=confusion_matrix(y_test,dtc_pred)\ncm_dtc","2e31d67d":"acc_dtc=accuracy_score(y_test,dtc_pred)\nacc_dtc","839b41d4":"print(classification_report(y_test,dtc_pred))","2d9938d5":"#COMPARING THE TWO CLASSIFICATION REPORTS\nprint(classification_report(y_test, y_pred))\nprint(classification_report(y_test,dtc_pred))","2777a29b":"**DECISION TREE CLASSIFIER**","a7040481":"# **MESSAGE SPAM CLASSIFIER**","3b04443c":"**NAIVE BAYES**","8ab36c07":"THIS NOTEBOOK ANALYZISES THE SPAM CLASSIFIER DATASET AND CLASSIFIES THE SPAM AND HAM MESSAGES USING VARIOUS MACHINE LEARNING ALGORITHMS. ","db533c8c":" **WORD CLOUDS**","8db37733":"**DATA VISUALIZATION**","aa32fc65":"**MODELS**"}}