{"cell_type":{"4c007b14":"code","ae8493f1":"code","5900d978":"code","ed7309fb":"code","cdf1c26c":"code","1ff3b858":"code","1f04ed3e":"code","208413dd":"code","7b5bbde3":"code","98fbf4a3":"code","32c04a98":"code","f5fdb93a":"code","4d95d462":"code","1c747c71":"code","bcfd00d8":"code","75dbcff8":"markdown","a8d76c3e":"markdown","bc5368bf":"markdown","d9c0d49d":"markdown","14172f99":"markdown","69b35685":"markdown"},"source":{"4c007b14":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import mnist","ae8493f1":"(train_images, train_labels), (test_images, test_labels) = mnist.load_data()","5900d978":"train_images.shape","ed7309fb":"len(train_labels)","cdf1c26c":"train_labels","1ff3b858":"# checking shape of the test data\ntest_images.shape","1f04ed3e":"# length of the test label set\nlen(test_labels)","208413dd":"# importing the models\nfrom tensorflow.keras import models","7b5bbde3":"# the model\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))","98fbf4a3":"# display architecture of the convnet model\nmodel.summary()","32c04a98":"# flatten the output of the last conv2d layer into a densely connected layer neural network\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10, activation='softmax')) # 10 for the softmax layer to classify 0-9","f5fdb93a":"model.summary()","4d95d462":"from tensorflow.keras.utils import to_categorical","1c747c71":"train_images = train_images.reshape((60000, 28, 28, 1))\ntrain_images = train_images.astype('float32') \/ 255\n\ntest_images = test_images.reshape((10000, 28, 28, 1))\ntest_images = test_images.astype('float32') \/ 255\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\n# compiling and running the model\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_images, train_labels, epochs=5, batch_size=64)\n\n# evaluation of the model on test set\ntest_loss, test_acc = model.evaluate(test_images, test_labels)","bcfd00d8":"print(test_acc)","75dbcff8":"# Results","a8d76c3e":"**Now we will check the shape of the data. We will check how much big the training and test dataset are.**","bc5368bf":"# Introduction\n\nThe MNIST dataset is a dataset of the images of thousands of handwritten digits in the size of 28*28 pixels. The goal of the task for this dataset is to build a digit recognizer which can classify the images into the ten digits from 0-9.\n\nCheck out an Exploratory Data Analysis of the MNIST dataset [here](http:\/\/varianceexplained.org\/r\/digit-eda\/) to better understand the data.\n\n![Look at the MNIST dataset](https:\/\/d3i71xaburhd42.cloudfront.net\/243056f558c737cdd15e22f3015375446d959941\/76-Figure4.6-1.png)\n\n# Approach\n\nSince it is an image classification problem and a multiple class one, we are going to use a Convolutional Neural Network for the task and use the Softmax activation function in the last layer to classify the images.\n\n\n**Importing the dependencies**","d9c0d49d":"With that, this kernel comes to an end.\n\nFor more reference:\n\n[Different Activation Functions](https:\/\/missinglink.ai\/guides\/neural-network-concepts\/7-types-neural-network-activation-functions-right\/#:~:text=Activation%20functions%20are%20mathematical%20equations,relevant%20for%20the%20model's%20prediction.)\n\n[Convolutions for Deep Learning](https:\/\/towardsdatascience.com\/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)\n\n[More on Convoltional Neural Networks](http:\/\/https:\/\/medium.com\/technologymadeeasy\/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8#:~:text=CNNs%2C%20like%20neural%20networks%2C%20are,and%20responds%20with%20an%20output.)\n\n[A look at different Optimizers like RMSprop and Gradient Descent](https:\/\/towardsdatascience.com\/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b)\n\n[Understanding Convolutions and Pooling](https:\/\/towardsdatascience.com\/understanding-convolutions-and-pooling-in-neural-networks-a-simple-explanation-885a2d78f211)\n\n[Loss Functions](https:\/\/towardsdatascience.com\/cross-entropy-for-classification-d98e7f974451)\n\n[EDA of the MNIST dataset](http:\/\/varianceexplained.org\/r\/digit-eda\/)\n\nFinally, if you liked the kernel please cast an upvote to support me which helps us stay motivated.","14172f99":"**Loading the Dataset**","69b35685":"# Architecture\n\nWe are going to use convolutions since we are using a CNN. The convolution layers are used to help the computer determine features that could be missed in simply flattening an image into its pixel values. The convolution layers are typically split into two sections, convolutions and pooling. For pooling, we are going to use a Max Pooling Layers. In the final steps, we are going to feed the results of our CNN into a Dense layer in which, we are goint to use the softmax activation function to classify the digit images."}}