{"cell_type":{"ed1fc06b":"code","068d97ba":"code","63b14087":"code","2e5106c8":"code","fa556f1c":"code","1dbc255c":"code","46d7c6ff":"code","155070ac":"code","5c86c2de":"code","b54ec9b2":"code","259d7ea9":"code","c0a6760c":"code","aeb82bb8":"code","d214c04c":"code","530d104e":"code","ef4c7f3c":"code","79a6647b":"code","843be3ea":"code","6a35b053":"code","3d9da071":"code","5d04c496":"code","0f0898a8":"code","72fda6e5":"code","7cb32147":"code","afc75958":"code","404bf466":"code","f315d035":"code","ef798005":"code","8526c8f6":"code","d6c60141":"code","7d56ffd3":"code","53556657":"code","021f09b2":"code","697d16b8":"code","f26bd669":"code","540d0c66":"code","5ff863d3":"code","48b58851":"code","6eef7ab8":"code","4a1fed96":"code","9387a00e":"code","401d477b":"code","6fea36cf":"code","97caf1cf":"markdown","6286962a":"markdown","97a724b3":"markdown"},"source":{"ed1fc06b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport glob\nimport seaborn as sns\nimport random\nfrom sklearn.preprocessing import LabelBinarizer","068d97ba":"import os \nos.listdir('..\/input\/dogcat-release\/')","63b14087":"train = glob.glob('..\/input\/dogcat-release\/train\/*.jpg')\ntest =glob.glob('..\/input\/dogcat-release\/test\/*.jpg')","2e5106c8":"train = np.random.permutation(train)","fa556f1c":"train[:5]","1dbc255c":"label_names = set([p.split('\/')[-1].split('.')[0] for p in train])\nlabel_names ","46d7c6ff":"labels = [p.split('\/')[-1].split('.')[0] for p in train]\nlabels[:5]","155070ac":"labels = pd.DataFrame(labels,columns=['Type'])\nClass = labels['Type'].unique()\nClass_dict = dict(zip(Class, range(1,len(Class)+1)))\n\nlabels['str'] = labels['Type'].apply(lambda x: Class_dict[x])\nlb = LabelBinarizer()\nlb.fit(list(Class_dict.values()))\ntransformed_labels = lb.transform(labels['str'])\ny_bin_labels = []  \n\nfor i in range(transformed_labels.shape[1]):\n    y_bin_labels.append('str' + str(i))\n    labels['str' + str(i)] = transformed_labels[:, i]","5c86c2de":"Class_dict","b54ec9b2":"labels.drop('str',axis=1,inplace=True)\nlabels.drop('Type',axis=1,inplace=True)\nlabels = labels.str0.values\nlabels[:5]","259d7ea9":"#\u9884\u5904\u7406\u51fd\u6570\ndef preprocess_image(path,label):\n    image = tf.io.read_file(path)                           \n    image = tf.image.decode_jpeg(image,3)               \n    image = tf.image.resize(image,[224,224])       \n    image = tf.cast(image\/127.5 -1,tf.float32)     \n\n    return image,label       ","c0a6760c":"dataset = tf.data.Dataset.from_tensor_slices((train, labels)) \ndataset = dataset.shuffle(len(train))\ndataset","aeb82bb8":"#\u521b\u5efa\u6570\u636e\u96c6\nAUTO = tf.data.experimental.AUTOTUNE\ndataset = dataset.map(preprocess_image, num_parallel_calls = AUTO)","d214c04c":"#\u5207\u5206\u6570\u636e\u96c6\ntest_count = int(len(train)*0.2)\ntrain_count = len(train) - test_count\ntrain_count,test_count","530d104e":"train_dataset = dataset.skip(test_count) \ntest_dataset = dataset.take(test_count)","ef4c7f3c":"batch_size = 128","79a6647b":"train_dataset = train_dataset.repeat().shuffle(800).batch(batch_size)\ntrain_dataset = train_dataset.prefetch(AUTO)\ntest_dataset = test_dataset.batch(batch_size)\ntrain_dataset","843be3ea":"#Xception\nconv1 = keras.applications.xception.Xception(weights='imagenet',\n                                            include_top=False,\n                                            input_shape=(224,224,3),\n                                            pooling='avg')","6a35b053":"#ResNet152\nconv2 = keras.applications.resnet.ResNet152(weights='imagenet',\n                                            include_top=False,\n                                            input_shape=(224,224,3),\n                                            pooling='avg')","3d9da071":"#InceptionResNetV2\nconv3 = keras.applications.inception_v3.InceptionV3(weights='imagenet',\n                                                    include_top=False,\n                                                    input_shape=(224,224,3),\n                                                    pooling='avg')","5d04c496":"conv1.trainable = False\nconv2.trainable = False\nconv3.trainable = False","0f0898a8":"conv1.inputs,conv2.inputs,conv3.inputs","72fda6e5":"conv1.outputs,conv2.outputs,conv3.outputs","7cb32147":"def model():\n    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n    out1 = conv1(inputs)\n    out2 = conv2(inputs)\n    out3 = conv3(inputs)\n    out = tf.keras.layers.concatenate([out1,out2,out3],axis=1)\n    out = tf.keras.layers.Dropout(0.5)(out)\n    output = tf.keras.layers.Dense(1, activation='sigmoid')(out)\n    \n    return tf.keras.Model(inputs=inputs, outputs=output)","afc75958":"model = model()\nmodel.summary()","404bf466":"tf.keras.utils.plot_model(model,show_shapes=True,dpi=300)","f315d035":"model.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['acc'])","ef798005":"EPOCHS = 10","8526c8f6":"history = model.fit(train_dataset,\n                   steps_per_epoch=train_count\/\/batch_size,\n                   epochs=EPOCHS,\n                   validation_data=test_dataset,\n                   validation_steps=test_count\/\/batch_size,\n                   )","d6c60141":"def plot_history(history):                \n    hist = pd.DataFrame(history.history)           \n    hist['epoch']=history.epoch\n    \n    plt.figure()                                     \n    plt.xlabel('Epoch')\n    plt.ylabel('Binary_crossentropy')               \n    plt.plot(hist['epoch'],hist['loss'],\n            label='Train Loss')\n    plt.plot(hist['epoch'],hist['val_loss'],\n            label='Val Loss')                           \n    plt.legend()\n    \n    plt.figure()                                      \n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')               \n    plt.plot(hist['epoch'],hist['acc'],\n            label='Train Acc')\n    plt.plot(hist['epoch'],hist['val_acc'],\n            label='Val Acc')\n    plt.legend()      \n    \n    plt.show()\n    \nplot_history(history)          ","7d56ffd3":"y_pred = model.predict(test_dataset, verbose=1)\ny_pred = y_pred.clip(min=0.005, max=0.995)","53556657":"y_pred","021f09b2":"def preprocess_test(path):\n    image = tf.io.read_file(path)                           \n    image = tf.image.decode_jpeg(image,3)               \n    image = tf.image.resize(image,[224,224])       \n    image = tf.cast(image\/127.5 -1,tf.float32)     \n\n    return image  ","697d16b8":"Dir = \"..\/input\/dogcat-release\/test\/\"\nimgList = os.listdir(Dir)\nimgList.sort(key=lambda x: int(x.split('\/')[-1].split('.')[0]))\nimgList[:5]","f26bd669":"test_path = []\nfor count in range(0, len(imgList)):\n    im_name = imgList[count]\n    im_path = os.path.join(Dir,im_name)\n    test_path.append(im_path)\n    print(im_path)","540d0c66":"test_path[:5]","5ff863d3":"val_dataset = tf.data.Dataset.from_tensor_slices(test_path) \nval_dataset = val_dataset.map(preprocess_test, num_parallel_calls = AUTO)\nval_dataset = val_dataset.batch(batch_size)","48b58851":"y_pred = model.predict(val_dataset, verbose=1)\ny_pred[:10]","6eef7ab8":"pred = pd.DataFrame(y_pred).iloc[:,0].values","4a1fed96":"pred[:5]","9387a00e":"def type_change(data):\n    for i in range(data.shape[0]):\n        if data[i] > 0.5:\n            data[i] = 0.005\n        else: data[i] = 0.995\n    return data\n\npredict_labels = type_change(pred)","401d477b":"predict_labels[:10]","6fea36cf":"prediction = pd.DataFrame({\"label\":predict_labels})\nprediction.index += 1 \nprediction.to_csv('pred.csv',\n                  index_label='id')","97caf1cf":"\u6a21\u578b\u8bc4\u4f30","6286962a":"\u521b\u5efa\u4e09\u79cd\u8fc1\u79fb\u6a21\u578b\u7ed3\u5408\u6d4b\u8bd5","97a724b3":"\u5bfc\u5165\u56fe\u7247\u548c\u9884\u5904\u7406"}}