{"cell_type":{"975bbc5c":"code","2f8ffe77":"code","2f58c3f6":"code","be14df71":"code","7dbc7b3d":"code","ddae9fe2":"code","3d5adff8":"code","f22b1163":"code","6a272414":"code","b12f29ce":"code","68deaad6":"code","bd48343a":"code","b1935c50":"code","8953a221":"code","75c003cd":"code","06f0c80c":"code","c28a15dd":"code","df417724":"code","159378f5":"code","14462170":"code","b13906ac":"code","f2a91940":"code","6a85951d":"code","fcb9d3b6":"code","ea284f4d":"markdown","03b91aa2":"markdown","d379d637":"markdown","64cf73ac":"markdown","9ed725e7":"markdown","482d722c":"markdown","66420225":"markdown","4abfe0eb":"markdown"},"source":{"975bbc5c":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nnp.random.seed(0)\nplt.style.use(\"ggplot\")\n\nimport tensorflow as tf\nprint('Tensorflow version:', tf.__version__)\nprint('GPU detected:', tf.config.list_physical_devices('GPU'))","2f8ffe77":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2f58c3f6":"# Loading data\ndata = pd.read_csv('\/kaggle\/input\/ner-datasetcsv\/ner_dataset.csv',encoding='latin1')\ndata = data.fillna(method = 'ffill')\ndata.head(20)","be14df71":"print(\"Unique words in corpus:\",data['Word'].unique())\nprint(\"Unique Tags in corpus:\",data['Tag'].unique())","7dbc7b3d":"words = list(set(data[\"Word\"].values))\nwords.append(\"ENDPAD\")\nnum_words = len(words)","ddae9fe2":"tags = list(set(data[\"Tag\"].values))\nnum_tags = len(tags)","3d5adff8":"num_words, num_tags","f22b1163":"class SentanceGetter(object):\n    def __init__(self,data):\n        self.n_sent = 1\n        self.data = data\n        agg_func = lambda s: [(w,p,t) for w,p,t in zip(s[\"Word\"].values.tolist(),\n                                                       s[\"POS\"].values.tolist(),\n                                                       s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n        self.sentances = [s for s in self.grouped]","6a272414":"getter = SentanceGetter(data)\nsentances = getter.sentances","b12f29ce":"# checking the structure of sentances \nsentances[1]","68deaad6":"word2idx = {w: i+1 for i, w in enumerate(words)}\ntag2idx = { t: i for i,t in enumerate(tags)}","bd48343a":"word2idx","b1935c50":"plt.hist([len(s) for s in sentances], bins=60)\nplt.show()","8953a221":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nmax_len = 60\nX = [[word2idx[w[0]] for w in s] for s in sentances]\nX = pad_sequences(maxlen = max_len, sequences =X , padding ='post',value =num_words-1)\ny = [[tag2idx[w[2]] for w in s]for s in sentances]\ny = pad_sequences(maxlen=max_len,sequences =y,padding ='post',value=tag2idx[\"O\"])\ny = [to_categorical(i, num_classes=num_tags) for i in y]","75c003cd":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, random_state =1)\n","06f0c80c":"from tensorflow.keras import Model, Input\nfrom tensorflow.keras.layers import LSTM, Embedding, Dense\nfrom tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional","c28a15dd":"input_word = Input(shape = (max_len))\nmodel = Embedding(input_dim = num_words,output_dim = max_len,input_length  = max_len)(input_word)\nmodel = SpatialDropout1D(0.1)(model)\nmodel = Bidirectional(LSTM(units = 100,return_sequences=True,recurrent_dropout = 0.1))(model)\nout = TimeDistributed(Dense(num_tags, activation ='softmax'))(model)\nmodel = Model(input_word,out)\nmodel.summary()","df417724":"model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","159378f5":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","14462170":"early_stopping = EarlyStopping(monitor='val_accuracy',patience=2,verbose = 1, mode ='max',restore_best_weights = True)\ncallbacks = early_stopping\nhistory = model.fit( x_train,np.array(y_train), validation_split = 0.1, batch_size = 32,epochs = 20, verbose =1,callbacks=callbacks)\n","b13906ac":"model.evaluate(x_test,np.array(y_test))","f2a91940":"#Plot the Accuracy Curves\nplt.figure(figsize=[8,6])\nplt.plot(history.history['accuracy'],'r',linewidth=3.0)\nplt.plot(history.history['val_accuracy'],'g',linewidth=3.0)\nplt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Accuracy',fontsize=16)\nplt.title('Accuracy Curves',fontsize=16)","6a85951d":"#Plot the Loss Curves\nplt.figure(figsize=[8,6])\nplt.plot(history.history['loss'],'r',linewidth=3.0)\nplt.plot(history.history['val_loss'],'g',linewidth=3.0)\nplt.legend(['Training loss', 'Validation Loss'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Loss',fontsize=16)\nplt.title('Loss Curves',fontsize=16)","fcb9d3b6":"i = np.random.randint(0,x_test.shape[0])\np = model.predict(np.array([x_test[i]]))\np = np.argmax(p, axis =-1)\ny_true = np.argmax(np.array(y_test), axis =-1)[i]\nprint(\"{:15}{:5}\\t {} \\n\".format(\"Word\",\"True\",\"Pred\"))\nprint(\"-\"*30)\nfor w,true,pred in zip(x_test[i],y_true,p[0]):\n    print(\"{:15}{}\\t{}\".format(words[w-1],tags[true],tags[pred]))","ea284f4d":"# ### Padding Input Sentences and Creating Train\/Test Splits","03b91aa2":"# ###  Load and Explore the NER Dataset","d379d637":"# ### Evaluate Named Entity Recognition Model","64cf73ac":"*Essential info about tagged entities*:\n- geo = Geographical Entity\n- org = Organization\n- per = Person\n- gpe = Geopolitical Entity\n- tim = Time indicator\n- art = Artifact\n- eve = Event\n- nat = Natural Phenomenon","9ed725e7":"# ******Retrieve Sentences and Corresponsing Tags","482d722c":"# ### Build and Compile a Bidirectional LSTM Model","66420225":"# ###  Train the Model","4abfe0eb":"# ###  Define Mappings between Sentences and Tags"}}