{"cell_type":{"4591a4ce":"code","93653e9c":"code","667ec6e3":"code","b9f22f83":"code","b8c86dd6":"code","84996590":"code","dbabf921":"code","84c2986b":"code","2968c2e5":"code","85fd0ecb":"code","9d1347e1":"code","d52dc8c2":"code","9dc7fb8a":"code","e9ef5160":"code","f6a7ae0d":"code","99f49734":"code","34ad7347":"code","16622e72":"code","b58636d5":"code","58b9f6b2":"code","d1afcb2e":"code","f6d87538":"code","39ac9635":"code","10cc5568":"code","fa339517":"code","c9d41aee":"code","b98fab1e":"code","bf59c82c":"code","57d43750":"code","84cee000":"code","a3d1e6a2":"code","b0334f30":"code","2f0a4b53":"code","5661eed2":"code","fe123a85":"code","5f2adafc":"code","5c24ab41":"code","ae49c0f7":"code","a83fd0bd":"code","500e799e":"code","80127f64":"code","0e1443f7":"code","69ba9d3f":"code","d2ed17f6":"code","18ad951b":"code","946bb659":"code","8cae203f":"code","cba58456":"code","235491a5":"code","d0ad31aa":"code","ac96e1b8":"code","08177f71":"code","699306e1":"code","d9cfa23c":"code","632cea31":"code","0e615309":"code","391b1132":"code","9d97d148":"code","506b69f2":"code","afdd406b":"code","433cd303":"code","bf410646":"code","5be8b1cf":"code","1374f392":"code","43286c11":"code","ef4f63ee":"code","c7641f93":"code","562c4389":"code","f2855067":"code","89331210":"code","eb4c951b":"code","6f5c740a":"code","dd049932":"code","3ca15902":"code","6ed23fe3":"code","5ee53e20":"code","70424d63":"code","d9455015":"code","269d23cc":"code","d9cbc97f":"code","24bf908e":"code","f2dcfb24":"code","f7855a88":"code","d66b68d3":"code","7185a841":"code","1b17a880":"code","a16dc31e":"code","da45372e":"code","786214a4":"code","8f4af87b":"code","c7aebd1a":"markdown","9fea8949":"markdown","6cbf2525":"markdown","fd96b9ba":"markdown","8ca98be1":"markdown","9b0f2f3b":"markdown","07875f72":"markdown","96db5c50":"markdown","fa1a6542":"markdown","13c98266":"markdown","a184131e":"markdown","7b1aa748":"markdown","4c918e03":"markdown","71b501e7":"markdown","331e4be4":"markdown","b2666363":"markdown","1198e101":"markdown","078a530d":"markdown","059356fe":"markdown","2cdafe36":"markdown","d93c383b":"markdown","1edbac15":"markdown","125816f1":"markdown","2a42288e":"markdown","da2135b9":"markdown","98c8885f":"markdown","8e2d1e54":"markdown","f8709225":"markdown","c445a365":"markdown","47408a34":"markdown","af6de3b7":"markdown","2194bfc3":"markdown","a676b46b":"markdown","bb7d8471":"markdown","2acea087":"markdown","6ece5878":"markdown","e1da367f":"markdown","9d76ce35":"markdown","cd502ab4":"markdown","5fc12acd":"markdown","cf3200a9":"markdown","81d5ecab":"markdown","8adebe3d":"markdown","1a91ad19":"markdown","e1fa6f1f":"markdown","bf3a40a3":"markdown","bb2ed216":"markdown","51462322":"markdown","91d9638c":"markdown","c4aefd08":"markdown","b10006c6":"markdown","3bf7fb21":"markdown"},"source":{"4591a4ce":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ast import literal_eval\nimport json\n%matplotlib inline","93653e9c":"# reads the csv metadata and prints the head\ndf = pd.read_csv(\"..\/input\/the-movies-dataset\/movies_metadata.csv\", low_memory=False)","667ec6e3":"df.head(5)","b9f22f83":"drop_df = [\"homepage\", \"poster_path\", \"video\", \"imdb_id\", \"overview\", \"original_title\", \n           \"spoken_languages\", \"tagline\"]\ndf = df.drop(drop_df, axis=1) # drops the selected columns\ndf = df.drop_duplicates(keep='first') # removes the duplicates from existing dataframe\ndf.dropna(how=\"all\",inplace=True) # if each column is NaN or null in a row, drops this row","b8c86dd6":"df.shape\ndf.info()","84996590":"df.dropna(subset=[\"title\"], inplace=True)\ndf[\"id\"] =pd.to_numeric(df['id'], errors='coerce', downcast=\"integer\")\ndf[\"popularity\"] =pd.to_numeric(df['popularity'], errors='coerce', downcast=\"float\") \ndf[\"budget\"] =pd.to_numeric(df['budget'], errors='coerce', downcast=\"float\") \ndf['release_date'] = pd.to_datetime(df['release_date'])\ndf['release_year'] = df['release_date'].dt.year","dbabf921":"df['belongs_to_collection'] = df['belongs_to_collection'].fillna(\"None\")\ndf['belongs_to_collection'] = (df['belongs_to_collection'] != \"None\").astype(int)","84c2986b":"df[\"adult\"].value_counts()","2968c2e5":"df.drop([\"adult\"], inplace=True, axis=1)","85fd0ecb":"df.info()","9d1347e1":"df[\"status\"].fillna(df[\"status\"].value_counts().idxmax(), inplace=True)\ndf[\"runtime\"] = df[\"runtime\"].replace(0, np.nan)\ndf[\"runtime\"].fillna(df[\"runtime\"].mean(), inplace=True) ","d52dc8c2":"df.dropna(subset=[\"release_date\"],inplace=True)\ndf.dropna(subset=[\"original_language\"],inplace=True)","9dc7fb8a":"# converts json list to list of inputs (from the label specified with 'wanted' parameter)\ndef json_to_arr(cell, wanted = \"name\"): \n    cell = literal_eval(cell)\n    if cell == [] or (isinstance(cell, float) and cell.isna()):\n        return np.nan\n    result = []\n    counter = 0\n    for element in cell:\n        if counter < 3:\n            result.append(element[wanted])\n            counter += 1\n        else:\n            break\n    return result[:3]","e9ef5160":"df[['genres']] = df[['genres']].applymap(json_to_arr)\ndf[['production_countries']] = df[['production_countries']].applymap(lambda row: \n                                                                     json_to_arr(row, \"iso_3166_1\"))\ndf[['production_companies']] = df[['production_companies']].applymap(json_to_arr)","f6a7ae0d":"df['budget'] = df['budget'].replace(0 , pd.np.nan)\ndf['revenue'] = df['revenue'].replace(0 , pd.np.nan)","99f49734":"print(\"Number of rows with budget < 100: \", len((df[(df[\"budget\"].notna())&(df[\"budget\"] < 100)])))\nprint(\"Number of rows with budget > 100 and < 1000: \", len(df[(df[\"budget\"].notna())&(df[\"budget\"] > 100)\n                                                              &(df[\"budget\"] < 1000)]))\nprint(\"Number of rows with budget > 1000 and < 10000: \", len(df[(df[\"budget\"].notna())&(df[\"budget\"] > 1000)\n                                                              &(df[\"budget\"] < 10000)]))","34ad7347":"def scale_money(num):\n    if num < 100:\n        return num * 1000000\n    elif num >= 100 and num < 1000:\n        return num * 10000\n    elif num >= 1000 and num < 10000:\n        return num *100\n    else:\n        return num","16622e72":"df[['budget', 'revenue']] = df[['budget', 'revenue']].applymap(scale_money)","b58636d5":"sns.heatmap(df.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')","58b9f6b2":"print(\"NaN Genres Count: \", len(df[df[\"genres\"].isna()]))\nprint(\"NaN Revenue Count: \", len(df[df['revenue'].isna()])) \nprint(\"NaN Budget Count: \", len(df[df['budget'].isna()])) \nprint(\"NaN Production Company Count: \", len(df[df[\"production_companies\"].isna()]))\nprint(\"NaN Production Country Count: \", len(df[df[\"production_countries\"].isna()]))","d1afcb2e":"# returns the values and occurance times or \"limiter\" amount of different parameters in a 2D list\ndef list_counter(col, limiter = 9999, log = True):\n    result = dict()\n    for cell in col:\n        if isinstance(cell, float):\n            continue\n        for element in cell:\n            if element in result:\n                result[element] += 1\n            else:\n                result[element] = 1\n    if log:\n        print(\"Size of words:\", len(result))\n    result = {k: v for k, v in sorted(result.items(), key=lambda item: item[1], reverse=True)}\n    if log:\n        print(\"Sorted result is:\")\n    counter = 1\n    sum_selected = 0\n    total_selected = 0\n    rest = 0\n    returned = []\n    for i in result: \n        if counter > limiter:\n            total_selected += result[i]\n        else:\n            counter += 1\n            sum_selected += result[i]\n            total_selected += result[i]\n            if log:\n                print(result[i], \" - \", i) \n            returned.append([i, result[i]])\n    if log:\n        print(\"Covered:\", sum_selected, \"out of\", total_selected, \"\\n\")\n    return returned","f6d87538":"genres_occur = list_counter(df[\"genres\"].values, log=False)\ngenres = pd.DataFrame.from_records(genres_occur, columns=[\"genres\", \"count\"])\ngenres.plot(kind = 'bar', x=\"genres\")","39ac9635":"countries_occur = list_counter(df[\"production_countries\"].values, log=False)\ncountries = pd.DataFrame.from_records(countries_occur, columns=[\"countries\", \"count\"])\ncountries.head(20).plot(kind = 'bar', x=\"countries\")","10cc5568":"companies_occur = list_counter(df[\"production_companies\"].values, log=False)\ncompanies = pd.DataFrame.from_records(companies_occur, columns=[\"companies\", \"count\"])\ncompanies.head(20).plot(kind = 'bar', x=\"companies\")","fa339517":"def fill_na_with_list(cell, data):\n    if isinstance(cell, float):\n        return data\n    else:\n        return cell","c9d41aee":"df[['genres']] = df[['genres']].applymap(lambda row:\n                                        fill_na_with_list(row, [genres_occur[0][0]]))\ndf[['production_countries']] = df[['production_countries']].applymap(lambda row: \n                                        fill_na_with_list(row, [countries_occur[0][0]]))","b98fab1e":"df.shape\ndf.info()","bf59c82c":"df[\"profit\"] = df[\"revenue\"] - df[\"budget\"]\ndf[[\"popularity\", \"revenue\", \"budget\", \"runtime\", \"vote_average\",\"profit\", \"release_year\"]].describe()","57d43750":"min_val = df[\"budget\"].min()\nmax_val = df[\"budget\"].max()\ndf[[\"budget\", \"revenue\", \"profit\"]] = df[[\"budget\", \"revenue\", \"profit\"]].apply(lambda x: \n                                                            x \/ (max_val - min_val))","84cee000":"vote_counts = df[df['vote_count'].notnull()]['vote_count'].astype('int')\nvote_averages = df[df['vote_average'].notnull()]['vote_average'].astype('int')\nC = vote_averages.mean()\nm = vote_counts.quantile(0.75)\ndef weighted_rating(data):\n    v = data['vote_count'] + 1 # added +1\n    R = data['vote_average']\n    return (v \/ (v + m) * R) + (m \/ (m + v) * C)\n\ndf['weighted_rating'] = df.apply(weighted_rating, axis=1)","a3d1e6a2":"df_kwrd = pd.read_csv(\"..\/input\/the-movies-dataset\/keywords.csv\")\ndf_kwrd.head()","b0334f30":"df_kwrd[\"keywords\"] = df_kwrd[['keywords']].applymap(json_to_arr)","2f0a4b53":"df_kwrd.dropna(inplace=True)","5661eed2":"keywords_occur = list_counter(df_kwrd[\"keywords\"].values, log=False)\nkeywords = pd.DataFrame.from_records(keywords_occur, columns=[\"keywords\", \"count\"])\nkeywords.head(20).plot(kind = 'bar', x=\"keywords\")","fe123a85":"df = pd.merge(df, df_kwrd, on=['id'], how='left')","5f2adafc":"df.info()","5c24ab41":"df_cr = pd.read_csv(\"..\/input\/the-movies-dataset\/credits.csv\")\ndf_cr.head()","ae49c0f7":"df_cr[\"cast\"] = df_cr[['cast']].applymap(json_to_arr)","a83fd0bd":"def get_director(x):\n    x = literal_eval(x)\n    for i in x:\n        if i == \"[]\" or isinstance(i, float):\n            return np.nan\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan\n\ndf_cr['director'] = df_cr['crew'].apply(get_director)\ndf_cr.drop([\"crew\"], axis=1, inplace=True)","500e799e":"print(\"Entries with no cast:\", len(df_cr[df_cr[\"cast\"].isna()]))\nprint(\"Entries with no directors:\", len(df_cr[df_cr[\"director\"].isna()]))\nprint(\"Entries missing both:\", len(df_cr[(df_cr[\"cast\"].isna())&(df_cr[\"director\"].isna())]))\ndf_cr.drop(df_cr[(df_cr[\"cast\"].isna())&(df_cr[\"director\"].isna())].index, inplace=True)","80127f64":"df = pd.merge(df, df_cr, on=['id'], how='left')","0e1443f7":"df.shape\ndf.info()","69ba9d3f":"df.head(3)","d2ed17f6":"df.sort_values('weighted_rating', ascending=False)[[\"title\", \"director\", \"genres\", \"profit\", \n                                                    \"popularity\", \"weighted_rating\"]].head(10)","18ad951b":"df.sort_values('popularity', ascending=False)[[\"title\", \"director\", \"genres\", \"profit\", \n                                                    \"popularity\", \"weighted_rating\"]].head(10)","946bb659":"df.sort_values('profit', ascending=False)[[\"title\", \"director\", \"genres\", \"profit\", \n                                                    \"popularity\", \"weighted_rating\"]].head(10)","8cae203f":"sns.heatmap(df.corr(), cmap = 'YlGnBu')\ndf.drop([\"id\"], axis=1).corr()","cba58456":"g = sns.scatterplot(x=\"vote_count\", y=\"profit\", data=df[[\"profit\", \"vote_count\"]])","235491a5":"g = sns.scatterplot(x=\"budget\", y=\"revenue\", data=df[[\"budget\", \"revenue\"]])","d0ad31aa":"g = sns.scatterplot(x=\"vote_count\", y=\"popularity\", data=df[[\"popularity\", \"vote_count\"]])","ac96e1b8":"g = sns.scatterplot(x=\"popularity\", y=\"weighted_rating\", data=df[[\"popularity\", \"weighted_rating\"]])","08177f71":"df_genres = df[[\"title\", \"genres\", \"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]]","699306e1":"df_genres.head()","d9cfa23c":"genres = list_counter(df_genres[\"genres\"].values, log=False)","632cea31":"def list_to_col(data, col_name, col_list, limiter = 9999):\n    counter = 0\n    selected_items = set()\n    for item in col_list:\n        if counter >= limiter:\n            break\n        item = item[0]\n        data[item] = 0\n        selected_items.add(item)\n        counter += 1\n    \n    for index, row in data.iterrows():\n        for item in row[col_name]:  \n            if item in selected_items:\n                data.at[index, item] = 1\n    data.drop([col_name], axis=1, inplace=True)\n    return data","0e615309":"df_genres = list_to_col(df_genres, \"genres\", genres)\ndf_genres","391b1132":"def binary_mean_dataset_generator(data, col_list, limiter = 9999):\n    counter = 0\n    items = []\n    for item in col_list:\n        if counter >= limiter:\n            break\n        items.append(item[0])\n        counter += 1\n    rows = []\n    for item in items:\n        value = data[data[item] == 1].mean()\n        rows.append([item, value[0], value[1], value[2], value[3], value[4]])  \n    \n    df_genres_means = pd.DataFrame(rows, columns=[\"type\", \"popularity\", \"budget\", \"revenue\", \n                                            \"vote_count\", \"rating\"])\n    return df_genres_means","9d97d148":"df_means_genres = binary_mean_dataset_generator(df_genres, genres)\ndf_means_genres","506b69f2":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_genres))\nax.barh(y_pos, df_means_genres['rating'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_genres['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Rating')\nax.set_title('Average Rating w.r.t. Genres')\nplt.show()","afdd406b":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_genres))\nax.barh(y_pos, df_means_genres['popularity'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_genres['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Popularity')\nax.set_title('Popularity w.r.t. Genres')\nplt.show()","433cd303":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_genres))\nax.barh(y_pos, df_means_genres['vote_count'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_genres['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Vote Count')\nax.set_title('Vote Count w.r.t. Genres')\nplt.show()","bf410646":"sns.set(style=\"whitegrid\")\nf, ax = plt.subplots(figsize=(10, 5))\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x=\"revenue\", y=\"type\", data=df_means_genres[['type', 'budget', 'revenue']],\n            label=\"Revenue\", color=\"b\")\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"budget\", y=\"type\", data=df_means_genres[['type', 'budget', 'revenue']],\n            label=\"Budget\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, 0.5), ylabel=\"Movie Types\",\n       xlabel=\"Average Budget And Revenue w.r.t. Genres\")\nsns.despine(left=True, bottom=True)","5be8b1cf":"sns.heatmap(df_genres[[\"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]].corr(), \n            cmap = 'YlGnBu')","1374f392":"df_countries = df[[\"title\", \"production_countries\", \"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]]\ncountries = list_counter(df_countries[\"production_countries\"].values, limiter=10, log=False)\ndf_countries = list_to_col(df_countries, \"production_countries\", countries, 10)\ndf_means_ct = binary_mean_dataset_generator(df_countries, countries)\ndf_means_ct ","43286c11":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_ct))\nax.barh(y_pos, df_means_ct['rating'], height=0.5, align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_ct['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Rating')\nax.set_title('Average Rating w.r.t. Countries')\nplt.show()","ef4f63ee":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_ct))\nax.barh(y_pos, df_means_ct['popularity'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_ct['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Popularity')\nax.set_title('Popularity w.r.t. Countries')\nplt.show()","c7641f93":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_ct))\nax.barh(y_pos, df_means_ct['vote_count'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_ct['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Vote Count')\nax.set_title('Average Vote Count w.r.t. Countries')\nplt.show()","562c4389":"sns.set(style=\"whitegrid\")\nf, ax = plt.subplots(figsize=(8, 3))\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"revenue\", y=\"type\", data=df_means_ct[['type', 'budget', 'revenue']],\n            label=\"Revenue\", color=\"b\")\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x=\"budget\", y=\"type\", data=df_means_ct[['type', 'budget', 'revenue']],\n            label=\"Budget\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, 0.3), ylabel=\"Movie Types\",\n       xlabel=\"Average Budget And Revenue w.r.t. Countries\")\nsns.despine(left=True, bottom=True)","f2855067":"sns.heatmap(df_countries[[\"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]].corr(), \n            cmap = 'YlGnBu')","89331210":"df_dir= df[[\"title\", \"director\", \"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]]\ndf_dir.dropna(subset=[\"director\"], inplace=True)\ndirectors = df_dir[\"director\"].value_counts()\ndirectors = directors.index.to_list()","eb4c951b":"def str_to_col(data, col_name, col_list, limiter = 9999):\n    counter = 0\n    selected = set()\n    for item in col_list:\n        if counter >= limiter:\n            break\n        data[item] = 0\n        selected.add(item)\n        counter += 1\n    for index, row in data.iterrows():\n        item = row[col_name]\n        if(item in selected):\n            data.at[index, item] = 1\n    data.drop([col_name], axis=1, inplace=True)\n    return data","6f5c740a":"def str_mean_dataset_generator(data, col_list, limiter = 9999):\n    counter = 0\n    items = []\n    for item in col_list:\n        if counter >= limiter:\n            break\n        items.append(item)\n        counter += 1\n    rows = []\n    for item in items:\n        value = data[data[item] == 1].mean()\n        rows.append([item, value[0], value[1], value[2], value[3], value[4]])  \n    \n    df_genres_means = pd.DataFrame(rows, columns=[\"type\", \"popularity\", \"budget\", \"revenue\", \n                                            \"vote_count\", \"rating\"])\n    return df_genres_means","dd049932":"df_dir = str_to_col(df_dir, \"director\", directors[:15], 15)\ndf_means_dir = str_mean_dataset_generator(df_dir, directors[:15])\ndf_means_dir ","3ca15902":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_dir))\nax.barh(y_pos, df_means_dir['rating'], height=0.5, align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_dir['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Rating')\nax.set_title('Average Rating w.r.t. Directors')\nplt.show()","6ed23fe3":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_dir))\nax.barh(y_pos, df_means_dir['popularity'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_dir['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Popularity')\nax.set_title('Popularity w.r.t. Directors')\nplt.show()","5ee53e20":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_dir))\nax.barh(y_pos, df_means_dir['vote_count'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_dir['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Vote Count')\nax.set_title('Vote Count w.r.t. Directors')\nplt.show()","70424d63":"sns.set(style=\"whitegrid\")\nf, ax = plt.subplots(figsize=(8, 3))\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"revenue\", y=\"type\", data=df_means_dir[['type', 'budget', 'revenue']],\n            label=\"Revenue\", color=\"b\")\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x=\"budget\", y=\"type\", data=df_means_dir[['type', 'budget', 'revenue']],\n            label=\"Budget\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"upper right\", frameon=True)\nax.set(xlim=(0, 0.3), ylabel=\"Movie Types\",\n       xlabel=\"Average Budget And Revenue w.r.t. Directors\")\nsns.despine(left=True, bottom=True)","d9455015":"sns.heatmap(df_dir[[\"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]].corr(), \n            cmap = 'YlGnBu')","269d23cc":"df_key = df[[\"title\", \"keywords\", \"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]]\ndf_key.dropna(subset=[\"keywords\"], inplace=True)\nkeywords = list_counter(df_key[\"keywords\"].values, 20, log=False)\ndf_key = list_to_col(df_key, \"keywords\", keywords)\ndf_means_key = binary_mean_dataset_generator(df_key, keywords, 20)\ndf_means_key","d9cbc97f":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_key))\nax.barh(y_pos, df_means_key['rating'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_key['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Rating')\nax.set_title('Average Rating w.r.t. Keywords')\nplt.show()","24bf908e":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_key))\nax.barh(y_pos, df_means_key['popularity'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_key['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Popularity')\nax.set_title('Popularity w.r.t. Keywords')\nplt.show()","f2dcfb24":"plt.rcdefaults()\nfig, ax = plt.subplots()\ny_pos = np.arange(len(df_means_key))\nax.barh(y_pos, df_means_key['vote_count'], align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(df_means_key['type'])\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Vote Count')\nax.set_title('Vote Count w.r.t. Keywords')\nplt.show()","f7855a88":"sns.set(style=\"whitegrid\")\nf, ax = plt.subplots(figsize=(10, 5))\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x=\"revenue\", y=\"type\", data=df_means_key[['type', 'budget', 'revenue']],\n            label=\"Revenue\", color=\"b\")\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"budget\", y=\"type\", data=df_means_key[['type', 'budget', 'revenue']],\n            label=\"Budget\", color=\"b\")\n\n# Add a legend and informative axis label\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, 0.5), ylabel=\"Movie Types\",\n       xlabel=\"Average Budget And Revenue w.r.t. Keywords\")\nsns.despine(left=True, bottom=True)","d66b68d3":"sns.heatmap(df_key[[\"popularity\", \"budget\", \"revenue\", \"vote_count\", \"weighted_rating\"]].corr(), \n            cmap = 'YlGnBu')","7185a841":"df_cast_dir = df[[\"director\", \"cast\"]].dropna()\ndf_cast_dir.head()","1b17a880":"director_list = df_cast_dir[\"director\"].value_counts()\ndirector_list = director_list.index.to_list()\ndf_cast_dir = str_to_col(df_cast_dir, \"director\", director_list[:10], 10)","a16dc31e":"cast = list_counter(df_cast_dir[\"cast\"].values, 10, log=False)\ndf_cast_dir = list_to_col(df_cast_dir, \"cast\", cast, 10)","da45372e":"df_cast_dir = df_cast_dir.loc[(df_cast_dir!=0).any(axis=1)]","786214a4":"df_cast_dir.shape","8f4af87b":"sns.heatmap(df_cast_dir.corr(), cmap = 'YlGnBu')","c7aebd1a":"The final situation in the main dataframe is below:","9fea8949":"## Data Analysis","6cbf2525":"For **revenue, budget and production company** filling the values with the most appearing entry or mean is not so logical, since the number of null or NaN entries are huge (More than %20 of whoel dataset). But for **genres and country** it may be done. The function below analyzes the most occuring values for columns in list formats.","fd96b9ba":"## Data Clearing and Formatting\n\n### - Movies Metadata Dataset","8ca98be1":"Rows with all zeros are removed:","9b0f2f3b":"### - Numerical Data Analysis\nThen, let's look at the correlation values of each numeric column with each other:","07875f72":"Since **id** parameters in both metadata and keywords directing to the same movie, the datasets can be merged.","96db5c50":"Since there are around 70 null **release_date** entries and filling that is not logical, they will be dropped, too. And also 1 row that has null as in column **original_language** may be dropped.","fa1a6542":"First the dataset is read and first couple of columns are printed to see the appearance of the data:","13c98266":"After the analysis of the numerical data, we can also look at the categorical data entries:","a184131e":"In adult column, only 9 True values are present, this information will not give us anything significant, thus, that column is also dropped.","7b1aa748":"##### Results:\n- No significant correlation is found.","4c918e03":"Since difference between min and max values for **budget, revenue and profit** is not so small, I have normalized these. In order to preserve the signs of the parameters, the formula of normalization is applied as: \n- value \/ (max - min)","71b501e7":"First of all, let's list top 10 movies regarding **weighted_rating and popularity and profit**:","331e4be4":"### - Keywords Dataset","b2666363":"### - Credits Dataset","1198e101":"Let's apply this function to specified 3 parameters:","078a530d":"There are some cells, which have stringified list of json inputs such as **genres, production_companies and production_countries**. For easier processing, these have to be converted into list of inputs. The function below achieves this:","059356fe":"## What Can Be Done Next?","2cdafe36":"Cast is assigned into columns:","d93c383b":"Since cast and crew type is stringified list of json, we can again extract the names from the cast and directors from the crew.","1edbac15":"##### Results:\n- About **average ratings**, genre has no significant effect.\n- In **popularity**, the values differ w.r.t. countries. While for US, GB, CA, DE, FR the popularity is greater, for RU and IT the average popularity becomes lower.\n- In **vote count, revenue**, especially US, GB, DE, CA, JP gives higher values. For these 2 different aspects, the genre distributions are similar and thus we can conculde that these have correlation between each other. For some countries like US, **popularity** feature gives also similar rankings.","125816f1":"## Imported Libraries\n- **pandas** for holding dataset and processing\n- **numpy** for list operations etc.\n- **matplotlib and seaborn** for graphics and data analysis\n- **ast** for its herler functions","2a42288e":"After these steps, the columns can be osberved to see how many null or NaN entries there are. So, a heatmap and data is below:","da2135b9":"## Reading the Data","98c8885f":"##### Results:\n- About **average ratings**, genre has no significant effect.\n- In **popularity, vote count, revenue**, especially adventure, fantasy, animation, science fiction, family and action gives higher values. For these 3 different aspects, the genre distributions are similar and thus we can conculde that these have correlation between each other.","8e2d1e54":"From a notebook, I have found a way to arrange **vote_counts** and **vote_averages** with a weighted manner, since there are lots of 0s in the dataset in both columns. The process is implemented below and explained as:\n- Weighted Rating for a row (WR) = [(v + 1) \/ (v + m) * R] + [m \/ (m + v) * C]\n- v: number of votes for the movie\n- m: minimum votes required to be listed in the chart (quantile 0.75)\n- R: average rating of the movie \n- C: mean vote across the whole report","f8709225":"Directors are assigned into columns:","c445a365":"### - Country Analysis\nFirst of all, the same process made in **genres** has to be made. However, since there are many countries, first 10 will be analysed:","47408a34":"Correlation of the table is investigated:","af6de3b7":"For **status** column, less than 100 entries are null and it may be a good idea to fill these with most common data. For **runtime**, again a similar case occurs and it can be handled by filling NaN values with the mean.","2194bfc3":"- More analyses between different categorical values can be made,\n- Relationship between **cast** and numerical columns can be investigated,\n- A recommendation system can be implemented,\n- *ratings.csv* file can also be included to the analysis.","a676b46b":"##### Results:\n- In **average ratings**, the values differ not so significantly.\n- In **popularity**, the value difference between keywords significantly increases. The most popular keywords are: *based on novel, prison, sex, paris*.\n- In **vote count** again the most popular ones are the same with the most popular ones. However, when a movie is **based on a novel** then the aoumt of votes significantly higher than other categories.\n- In revenue & budget**, the movies with **monsters** profits more than others in average.","bb7d8471":"As one can see, **keywords** format is stringified list of json and it can be converted to simple list with using the function written above and problematic ones can be calculated:","2acea087":"### - Genre Analysis\nLet's construct a sub-dataset for specificly genres:","6ece5878":"As we can see, there are strong correlation (value > 0.7) between these:\n- 0.73, budget and revenue\n- 0.78, vote_count and revenue\n- 0.75, profit and vote_count\n- 0.98, profit and revenue\n\nThe more **revenue** a movie has, the more **profit** the movie will have and this result is expected therefore. However, other conclusions can be reached, too:\n- If a movie has a higher **budget**, it is excpected to also have higher **revenue**.\n- The more the **number of votes** a movie has, the more **revenue** and therefore **profit** the movie has. \n\nAbout 2nd part, it seemed logical, because number of votes also indicates the **popularity** of a movie and popular ones probably tends to have more **revenue**. However, the relationship between **popularity** and **vote_count** or **profit \/ revenue** is not so strong. This result is surprizing. However, we can still say that there is a moderate correlation between:\n- 0.46, popularity and revenue\n- 0.56, popularity and vote_count\n- 0.44, popularity and profit\n- 0.61, budget and vote_count\n\nThe most surprizing result was having almost no correlation between **vote_average** and any other parameter except **weighted_rating**. Because it seems logical that higher voted movies tends to have move popularity and revenue. However, this is not the case. On the other hand, after some processing of **vote_average** in order to create **weighted_rating**, some moderate correlations between **weighted_rating** and other parameters are seen:\n- 0.41, popularity and weighted_rating\n- 0.42, vote_count and weighted_rating\n- 0.30, profit and weighted_rating","e1da367f":"The **id** of metadata and **id** of credits columns point to the same movies, thus, both datasets can be converged.","9d76ce35":"In **genres** *Drama* is the most occurring one with 20189 and in **production_countries** *US* is the most frequent entry. These can be placed into NA cells of these columns:","cd502ab4":"# Movies Dataset Analysis\n- by barisbatuhan\n- link: https:\/\/www.kaggle.com\/rounakbanik\/the-movies-dataset\n\n## Contents:\n- Imported Libraries\n- Reading the Data\n- Data Clearing and Formatting\n- Data Analysis\n- What Can Be Done Next?","5fc12acd":"##### Results:\n- In **average ratings**, the values differ regarding the director. The highest rating belongs to Martin Scorsese and the lowest one is Julien Duvivier's.\n- In **popularity**, the value difference between directors significantly increases. However, the ones thathave higher **average ratings** usually haves higher **popularity** values, too (and vice versa). Therefore, **average_ratings** and **popularity** may have a significant correlation between each other.\n- In **vote count and revenue & budget**, Martin Scorsese has a great difference from all the other directors. But also, the ones that have higher values in previous categories are higher again compared to others.","cf3200a9":"### - Director and Cast Correlation\nFirst, top directors and casts have to be placed to columns. Since there are too many people in these categories, top 10 of each category will be selected:","81d5ecab":"Now, let's create new columns for each genre type:","8adebe3d":"There are some rows that have a budget and revenue value, that are not actually scaled. By checking some of the notebooks shared, I have decided to move on with the scaling function below. For example, if the value is 1, then it scales to 1 million. If an example will be given from the true data:\n- id: 17402\n- Title: Miami Rhapsody\n- Production Company: Hollywood Pictures\t\n- Date: 1995-01-27\t\n- Budget: 6\n- Revenue: 5 (by looking IMDB, actual revenue can be seen as around 5 million)","1a91ad19":"### - Keyword Analysis","e1fa6f1f":"Now, we can calculate average of **weighted_rating, vote_count, popularity, budget and revenue** for each type and compare the results:","bf3a40a3":"Many entries of **budget and revenue** are 0. However, instead of 0, having NaN is more logical for seeing how many entries are actually available.","bb2ed216":"As we can see from the dataset itself and *info()* function, **belongs_to_collection** column has too many null entries, therefore instead of giving the collection name, we can convert the data to 0 and 1, 0 for not belonging and 1 for belonging. ","51462322":"First the csv file is read and head if the file is printed to see the format:","91d9638c":"####  Columns to be Dropped\n- **original_title**: since title column is also included and original_title column has non-ASCII characters, it can be dropped.\n- **homepage**: there will be no analysis depending on the homepage of the movie, this column is uselesss for this specific analysis\n- **imdb_id**: both ratings.csv and keywords.csv has id column to match with metadata dataset, thus no need for this column.\n- **overview & tagline**: no text analysis will be made in this notebook. For retrieving the most important words, keywords.csv can be used\n- **video & poster_path**: no image, video related processing will be made\n- **spoken_languages**: original_language is included, no need","c4aefd08":"### - Director Analysis","b10006c6":"If there are cells with both missing cast and director columns, they should be dropped:","3bf7fb21":"Out of 45449 rows, there are 6 rows with no title. Let's drop that one, too. Moreover, the types of **id, popularity and budget** is object, although they had to be numeric. Errors will be handled with coerce option, thus invalid parsing will be set as NaN. Also converting release_date to datetime instead of object and extracting the year data may be helpful."}}