{"cell_type":{"3797a7e7":"code","99aa1a5d":"code","d7f98dbb":"code","daf26bfd":"code","ff2d5cde":"code","352ad56c":"code","22c0cdb9":"code","5433c856":"code","dc9bb573":"code","d8497ea8":"code","589beccf":"code","aa4cee73":"code","a924b257":"code","24ac0595":"code","7960beaa":"code","c3efd2dc":"code","ead531a2":"code","626f2494":"code","dc9d72a3":"code","bd325e0a":"code","b873727d":"code","e73b55e6":"code","82b5255e":"code","a8627871":"code","ac686c71":"code","5776a168":"code","7a68cdeb":"code","4bd86dff":"code","f42998a6":"code","da48b1fb":"code","62573650":"code","b77db31a":"code","83f5b682":"code","2df1166a":"code","e03c3303":"code","3e643027":"code","a8469186":"code","264ad784":"code","ed215e0f":"code","afe203b8":"code","0c478b83":"code","78ae38e8":"code","6c39b3c4":"code","9273d9b3":"code","45cb9ff3":"code","3a63b8f2":"code","eee67609":"code","2c7c85bd":"code","804ea207":"code","1ff40fd4":"code","17f740d3":"code","17eb1033":"code","531713f8":"code","02df9624":"code","c94383dc":"code","ef90a375":"code","9111abf2":"code","632933ab":"code","201287e6":"code","dd674cf9":"code","5042d48a":"code","3ee860f7":"code","6a9f826c":"code","b1daefb9":"code","d0c9adb8":"code","5bbdae80":"code","7ee52d58":"code","dc3d070e":"code","c765b193":"code","d621529f":"code","0e1e2eb2":"code","2049c60d":"code","1989e033":"code","acaf5991":"markdown"},"source":{"3797a7e7":"#!conda install '..\/input\/conda-packages\/python-3.8.10-h49503c6_1_cpython.tar.bz2' -c conda-forge -y -q\n!conda install '..\/input\/conda-packages\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y -q\n!conda install '..\/input\/conda-packages\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y -q\n!conda install '..\/input\/conda-packages\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y -q\n!conda install '..\/input\/conda-packages\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y -q\n!conda install '..\/input\/conda-packages\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y -q\n!conda install '..\/input\/conda-packages\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y -q","99aa1a5d":"!python --version","d7f98dbb":"#install pips\n# !pip install ..\/input\/pip-wheels\/pylibjpeg_openjpeg-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl --no-index\n# !pip install ..\/input\/pip-wheels\/pylibjpeg_rle-1.1.0-cp37-cp37m-manylinux2010_x86_64.whl --no-index\n# !pip install ..\/input\/pip-wheels\/pylibjpeg-1.3.0-py3-none-any.whl --no-index\n\n!pip install ..\/input\/pip-wheels\/torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl --no-index --no-deps\n!pip install ..\/input\/pip-wheels\/torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl --no-index --no-deps\n\n!pip install ..\/input\/pip-wheels\/pycocotools-2.0.2.tar.gz --no-index\n!pip install ..\/input\/pip-wheels\/albumentations-1.0.0-py3-none-any.whl --no-index\n!pip install ..\/input\/pip-wheels\/pycocotools-2.0.2.tar.gz --no-index\n!pip install ..\/input\/pip-wheels\/antlr4-python3-runtime-4.8.tar.gz --no-index\n!pip install ..\/input\/pip-wheels\/omegaconf-2.1.0-py3-none-any.whl --no-index\n!pip install ..\/input\/pip-wheels\/timm-0.4.13.zip --no-index\n!pip install ..\/input\/pip-wheels\/effdet-0.2.4-py3-none-any.whl --no-index \n\n!pip install ..\/input\/pip-wheels\/pretrainedmodels-0.7.4.tar.gz --no-index --no-deps\n!pip install ..\/input\/pip-wheels\/efficientnet_pytorch-0.6.3.tar.gz --no-index --no-deps\n!pip install ..\/input\/pip-wheels\/segmentation_models_pytorch-0.2.0-py3-none-any.whl --no-index --no-deps\n\n!pip install ..\/input\/pip-wheels\/ensemble_boxes-1.0.6-py3-none-any.whl --no-index","daf26bfd":"!mkdir configs\n!mkdir data\n!mkdir models\n\n!cp ..\/input\/kaggle-siim-covid-detection-9th-place\/* .\/\n!tar -xvf .\/configs.tar -C .\/configs >> \/dev\/null\n!tar -xvf .\/data.tar -C .\/data >> \/dev\/null\n!tar -xvf .\/models.tar -C .\/models >> \/dev\/null\n!rm .\/*.tar","ff2d5cde":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy as sp\nimport os\nimport timm\nimport sys\nimport os\nimport importlib\nimport multiprocessing as mp\nimport cv2\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport glob\nimport torch\nfrom copy import copy\nfrom torch.cuda.amp import GradScaler, autocast\n\nfrom torch.utils.data import DataLoader\n\ntorch.backends.cudnn.benchmark = True\ncv2.setNumThreads(0)","352ad56c":"sys.path.append('.\/configs')\nsys.path.append('.\/data')\nsys.path.append('.\/models')","22c0cdb9":"COMP_FOLDER = '..\/input\/siim-covid19-detection\/'\n\n\nSAMPLE_SUBMISSION = pd.read_csv(COMP_FOLDER + 'sample_submission.csv').set_index('id')\nN_CORES = mp.cpu_count()\n\nRAM_CHECK = False\nMIXED_PRECISION = False\nDEVICE = \"cuda\"\n\nif len(SAMPLE_SUBMISSION) == 2477:\n    DEBUG = True\nelse:\n    DEBUG = False","5433c856":"# convert all dicoms to png\n\nfrom pydicom import read_file\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n\ndef do_one(fp):\n    img = read_xray(fp)\n    h, w = img.shape\n    \n    study_id, series_id, image_id = fp.split('\/')[4:]\n    \n    img_025 = cv2.resize(img, (0, 0), fx=0.25, fy = 0.25)\n    folder = f'test_025\/{study_id}\/{series_id}\/'\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n    cv2.imwrite(folder + image_id.replace('dcm','png'),img_025)\n    \n    img_05 = cv2.resize(img, (0, 0), fx=0.5, fy = 0.5)\n    folder = f'test_05\/{study_id}\/{series_id}\/'\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n    cv2.imwrite(folder + image_id.replace('dcm','png'),img_05)\n        \n    return image_id, study_id, series_id, w, h","dc9bb573":"fps = []\nfor dirname, _, filenames in os.walk(f'{COMP_FOLDER}test'):\n    for file in filenames:\n        fps += [dirname + '\/' + file]\n        \nif DEBUG:\n    fps = fps[:50]","d8497ea8":"with mp.Pool(N_CORES) as p:\n    res = list(tqdm(p.imap(do_one, fps),total=len(fps)))\ntest_info = np.array(res)","589beccf":"test_df = pd.DataFrame({'PredictionString':['none 1 0 0 1 1']* len(test_info)})\ntest_df[['id','StudyInstanceUID','series_id','width','height']] = test_info\ntest_df['id'] = test_df['id'].str.replace('.dcm','_image')\ntest_df[['width','height']] = test_df[['width','height']].astype(int)\ntest_df.to_csv('test_image_level_v2.csv',index=False)\ntest_df.head()","aa4cee73":"#helper functions\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    #fix DDP if necessary\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\n\ndef pp_transform(logits, pp_transformation):\n    if pp_transformation == \"softmax\":\n        pred = logits.softmax(1)\n    elif pp_transformation == \"sigmoid\":\n        pred = logits.sigmoid()\n    else:\n        pred = logits.detach()\n    return pred","a924b257":"def run_study(config_file, state_dicts):\n    cfg = importlib.import_module('default_config')\n    importlib.reload(cfg)\n    cfg = importlib.import_module(config_file)\n    importlib.reload(cfg)\n    cfg = copy(cfg.cfg)\n    print(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights)\n\n    cfg.test_df = 'test_image_level_v2.csv'\n    cfg.test_data_folder = f\"test_{str(cfg.scale).replace('.','')}\/\"\n    print(config_file, cfg.test_data_folder)\n    cfg.pretrained = False\n\n    ds = importlib.import_module(cfg.dataset)\n    importlib.reload(ds)\n\n    CustomDataset = ds.CustomDataset\n    batch_to_device = ds.batch_to_device\n\n    cfg.batch_size = 8\n    test_ds = CustomDataset(test_df, cfg, cfg.val_aug, mode=\"test\")\n    test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES, pin_memory=True)\n\n    model = importlib.import_module(cfg.model)\n    importlib.reload(model)\n    Net = model.Net\n\n    nets = []\n\n    for i,state_dict in enumerate(state_dicts):\n        net = Net(cfg).eval().cuda()\n        sd = get_state_dict(state_dict)\n        print(\"loading dict\")\n        net.load_state_dict(sd, strict=True)\n        nets += [net]\n\n    #with torch.no_grad():    \n    with torch.inference_mode():\n\n        preds_0 = []\n        for batch in tqdm(test_dl):\n            batch = batch_to_device(batch, DEVICE)\n            preds_ = []\n            for net in nets:\n                with autocast():\n                    logits = net(batch)['class_logits'].float()\n                #pred = pp_transform(logits, cfg.pp_transformation)\n                pred = logits\n                preds_ += [pred.cpu().numpy()]\n\n            preds_0 += [np.array(preds_)]\n        preds_0 = np.concatenate(preds_0, axis=1)\n    preds_0.shape\n    return preds_0\n\npreds = []\n\nstate_dicts = []\nfor fold, seed in enumerate([487735,464165,633237,686759,203682]):\n    state_dicts.append(f'..\/input\/weights-cfg-ch-study-xcit-2e15\/fold{fold}\/checkpoint_last_seed{seed}.pth')\nprint(state_dicts)\n\np = run_study(\"cfg_ch_study_xcit_2e15\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor fold, seed in enumerate([226896,259854,476990,577158,258586]):\n    state_dicts.append(f'..\/input\/weights-cfg-ch-study-xcit-2d\/fold{fold}\/checkpoint_last_seed{seed}.pth')\nprint(state_dicts)\n\np = run_study(\"cfg_ch_study_xcit_2d\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor file in glob.glob(\"..\/input\/cfg-ps-study-ben-7-weights\/*.pth\"):\n    state_dicts.append(file)\nprint(state_dicts)\n\np = run_study(\"cfg_ps_study_ben_7\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor file in glob.glob(\"..\/input\/cfg-ps-study-7-weights\/*.pth\"):\n    state_dicts.append(file)\nprint(state_dicts)\n\np = run_study(\"cfg_ps_study_7\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor fold, seed in enumerate([322511,301949,777691,615690,207310]):\n    state_dicts.append(f'..\/input\/weights-cfg-ch-study-12d\/fold{fold}\/checkpoint_last_seed{seed}.pth')\nprint(state_dicts)\n\np = run_study(\"cfg_ch_study_12d\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor fold, seed in enumerate([825690,473862,975082,699448,879221]):\n    state_dicts.append(f'..\/input\/weights-cfg-ch-study-12d\/fold{fold}\/checkpoint_last_seed{seed}.pth')\nprint(state_dicts)\n\np = run_study(\"cfg_ch_study_12d\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor fold in range(5):\n    for file in glob.glob(f\"..\/input\/weights-cfg-ch-study-7-1024b5\/fold{fold}\/*.pth\"):\n        state_dicts.append(file)\n    #state_dicts.append(f'..\/input\/weights-cfg-ch-study-12d\/fold{fold}\/checkpoint_last_seed{seed}.pth')\nprint(state_dicts)\nprint(len(state_dicts))\n\n\np = run_study(\"cfg_ch_study_7_1024b5\", state_dicts)\npreds.append(p)\n\nstate_dicts = []\nfor fold, seed in enumerate([775009,776562,239357,624529,909642]):\n    state_dicts.append(f'..\/input\/weights-cfg-ch-study-7-1024b7-2\/fold{fold}\/checkpoint_last_seed{seed}.pth')\nprint(state_dicts)\n\np = run_study(\"cfg_ch_study_7_1024b7_2\", state_dicts)\npreds.append(p)\n\n#preds = [sp.special.softmax(p, axis=2).mean(axis=0) for p in preds]\npreds = np.concatenate(preds, axis=0)\npreds = sp.special.softmax(preds, axis=2)\npreds = np.mean(preds, axis=0)\n\nprint(preds.shape)\n\nstudy_ids = test_df['StudyInstanceUID']","24ac0595":"def create_pred_str_study(row):\n    items = []\n    for label in [\"negative\", \"typical\", \"indeterminate\", \"atypical\"]:\n        items += [label,row[label],'0','0','1','1']\n    return ' '.join([str(i) for i in items])\n\ndef create_sub(test_preds):\n    df_study = pd.DataFrame({'id':study_ids})\n    df_study['id'] = df_study['id'].astype(str) + '_study'\n    df_study[[\"negative\", \"typical\", \"indeterminate\", \"atypical\"]] = test_preds\n    df_study = df_study.groupby('id').agg('mean').reset_index()\n    df_study_orig = df_study.copy()\n    df_study['PredictionString'] = df_study.apply(lambda row: create_pred_str_study(row), axis = 1)\n    df_study= df_study[['id','PredictionString']].copy()\n    df_study_orig[\"study_id\"] = df_study_orig[\"id\"].str.replace(\"_study\", \"\")\n    return df_study, df_study_orig\n\ntest_preds_study = preds\ntest_preds_study.shape\n\ndf_study, df_study_orig = create_sub(test_preds_study)\ndf_study = df_study.set_index('id')\ndf_study.head()\n\nSAMPLE_SUBMISSION.loc[df_study.index,'PredictionString'] = df_study['PredictionString'].values","7960beaa":"TOPK_EFFDET = 75\n\ndef get_df_image_pred_effdet(cfg, detections, image_ids):\n\n    images = []\n    boxes = []\n    labels = []\n    confs = []\n    \n    for i,det in enumerate(detections):\n\n        detection = det#[det[:,4] > cfg.box_min_conf]\n        \n        images.append([image_ids[i]] * len(detection))\n        labels.append(['opacity'] * len(detection))\n        boxes.append((detection[:,:4] \/ cfg.image_size[0]).clip(0,1))\n        confs.append(detection[:,4])\n        images += [[image_ids[i]]]\n        labels += [['none']]\n        boxes += [np.array([0,0,1,1])[None,:]]\n        confs += [np.array([1-det[:,4].max()])]\n    \n    confs = np.concatenate(confs)\n    labels = np.concatenate(labels)\n    images = np.concatenate(images)\n    boxes = np.concatenate(boxes)\n    df_image_pred = pd.DataFrame({'ImageID':images,'LabelName':labels,'Conf':confs})\n    df_image_pred[['XMin','YMin','XMax','YMax']] = boxes\n\n    df_image_pred = df_image_pred[df_image_pred.XMin != df_image_pred.XMax]\n    df_image_pred = df_image_pred[df_image_pred.YMin != df_image_pred.YMax]\n\n    df_image_pred = df_image_pred[['ImageID','LabelName','Conf','XMin', 'XMax', 'YMin', 'YMax']].copy()\n    \n    return df_image_pred\n\ndef get_results_effdet(config_file, state_dicts):\n    cfg = importlib.import_module('default_config')\n    importlib.reload(cfg)\n    cfg = importlib.import_module(config_file)\n    importlib.reload(cfg)\n    cfg = copy(cfg.cfg)\n    print(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights)\n\n    cfg.test_df = 'test_image_level_v2.csv'\n    cfg.test_data_folder = f\"test_{str(cfg.scale).replace('.','')}\/\"\n    print(config_file, cfg.test_data_folder)\n    cfg.pretrained = False\n    cfg.pretrained_convhead = False\n\n    ds = importlib.import_module(cfg.dataset)\n    importlib.reload(ds)\n\n    CustomDataset = ds.CustomDataset\n    batch_to_device = ds.batch_to_device\n\n    cfg.batch_size = 8\n    test_ds = CustomDataset(test_df, cfg, cfg.val_aug, mode=\"test\")\n    test_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES, pin_memory=True)\n\n    model = importlib.import_module(cfg.model)\n    importlib.reload(model)\n    Net = model.Net\n\n    nets = []\n\n    for i,state_dict in enumerate(state_dicts):\n        net = Net(cfg).eval().cuda()\n        sd = get_state_dict(state_dict)\n        print(\"loading dict\")\n        net.load_state_dict(sd, strict=True)\n        nets += [net]\n\n    #with torch.no_grad():    \n    with torch.inference_mode():\n\n        preds_0 = []\n        for batch in tqdm(test_dl):\n            batch = batch_to_device(batch, DEVICE)\n            preds_ = []\n            for net in nets:\n                with autocast():\n                    detections_ = net(batch)['detections'].float()\n                    detections_ = detections_[:,:TOPK_EFFDET,:]\n                #pred = pp_transform(logits, cfg.pp_transformation)\n                preds_ += [detections_.cpu().numpy()]\n                \n            preds_0 += [np.array(preds_)]\n        preds_0 = np.concatenate(preds_0, axis=1)\n        \n        \n    dfs_pred = []\n    for fold in tqdm([0,1,2,3,4]):\n        df_image_pred = get_df_image_pred_effdet(cfg, preds_0[fold], test_df['id'])\n        dfs_pred += [df_image_pred]\n    dfs_pred = pd.concat(dfs_pred)\n    \n    \n    \n    return dfs_pred","c3efd2dc":"config_file = 'cfg_ps_35'\nstate_dicts = []\nfor file in glob.glob(\"..\/input\/cfg-ps-35-weights\/*.pth\"):\n    state_dicts.append(file)\nprint(state_dicts)\n\ndfs_pred_ps_35 = get_results_effdet(config_file, state_dicts)\ndfs_pred_ps_35.sort_values(['ImageID','Conf'])\n\ndfs_pred_ps_35.head()","ead531a2":"config_file = 'cfg_ps_27'\nstate_dicts = []\nfor file in glob.glob(\"..\/input\/cfg-ps-27-weights\/*.pth\"):\n    state_dicts.append(file)\nprint(state_dicts)","626f2494":"dfs_pred_ps_27 = get_results_effdet(config_file, state_dicts)\ndfs_pred_ps_27.sort_values(['ImageID','Conf'])","dc9d72a3":"dfs_pred_ps_27.head()","bd325e0a":"config_file = 'cfg_ps_13'\nstate_dicts = []\nfor file in glob.glob(\"..\/input\/cfg-ps-13-weights\/*.pth\"):\n    state_dicts.append(file)\nprint(state_dicts)","b873727d":"dfs_pred_ps_13 = get_results_effdet(config_file, state_dicts)","e73b55e6":"dfs_pred_ps_13.sort_values(['ImageID','Conf'])","82b5255e":"config_file = 'cfg_ps_9'\nstate_dicts = []\nfor file in glob.glob(\"..\/input\/cfg-ps-9-weights\/*.pth\"):\n    state_dicts.append(file)\nprint(state_dicts)","a8627871":"dfs_pred_ps_9 = get_results_effdet(config_file, state_dicts)","ac686c71":"dfs_pred_ps_9.sort_values(['ImageID','Conf'])","5776a168":"import yaml\n\nrun1 = dict(\n    path = '',\n    train = '\/kaggle\/working\/test_05',\n    val = '\/kaggle\/working\/test_05',\n    test = '\/kaggle\/working\/test_05',\n    nc =  1,  # number of classes\n    names = [ '0. opacity' ],  # class names\n\n)\n\nrun2 = dict(\n    path = '',\n    train = '\/kaggle\/working\/test_05',\n    val = '\/kaggle\/working\/test_05',\n    test = '\/kaggle\/working\/test_05',\n    nc =  2,  # number of classes\n    names = [ '0. opacity', '1. none' ],  # class names\n\n)\n\n\nwith open('data_1cls.yaml', 'w') as outfile:\n    yaml.dump(run1, outfile, default_flow_style=False)\n    \nwith open('data_2cls.yaml', 'w') as outfile:\n    yaml.dump(run2, outfile, default_flow_style=False)","7a68cdeb":"# ","4bd86dff":"!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_1b\/fold0\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_1b\/fold0\/test_tta >>yolo_run_ch_1b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_1b\/fold1\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_1b\/fold1\/test_tta >>yolo_run_ch_1b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_1b\/fold2\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_1b\/fold2\/test_tta >>yolo_run_ch_1b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_1b\/fold3\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_1b\/fold3\/test_tta >>yolo_run_ch_1b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_1b\/fold4\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_1b\/fold4\/test_tta >>yolo_run_ch_1b.logs","f42998a6":"!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_2b\/fold0\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_2b\/fold0\/test_tta >>yolo_run_ch_2b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_2b\/fold1\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_2b\/fold1\/test_tta >>yolo_run_ch_2b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_2b\/fold2\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_2b\/fold2\/test_tta >>yolo_run_ch_2b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_2b\/fold3\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_2b\/fold3\/test_tta >>yolo_run_ch_2b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_2b\/fold4\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_2b\/fold4\/test_tta >>yolo_run_ch_2b.logs","da48b1fb":"!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_3b\/fold0\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 640 --task test --save-txt --save-conf --project \"\" --name run_ch_3b\/fold0\/test_tta >>yolo_run_ch_3b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_3b\/fold1\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 640 --task test --save-txt --save-conf --project \"\" --name run_ch_3b\/fold1\/test_tta >>yolo_run_ch_3b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_3b\/fold2\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 640 --task test --save-txt --save-conf --project \"\" --name run_ch_3b\/fold2\/test_tta >>yolo_run_ch_3b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_3b\/fold3\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 640 --task test --save-txt --save-conf --project \"\" --name run_ch_3b\/fold3\/test_tta >>yolo_run_ch_3b.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_3b\/fold4\/weights\/last.pt --data \/kaggle\/working\/data_1cls.yaml --augment --imgsz 640 --task test --save-txt --save-conf --project \"\" --name run_ch_3b\/fold4\/test_tta >>yolo_run_ch_3b.logs","62573650":"!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_7_2cls_2\/fold0\/weights\/last.pt --data \/kaggle\/working\/data_2cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_7_2cls_2\/fold0\/test_tta >>yolo_run_ch_7_2cls_2.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_7_2cls_2\/fold1\/weights\/last.pt --data \/kaggle\/working\/data_2cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_7_2cls_2\/fold1\/test_tta >>yolo_run_ch_7_2cls_2.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_7_2cls_2\/fold2\/weights\/last.pt --data \/kaggle\/working\/data_2cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_7_2cls_2\/fold2\/test_tta >>yolo_run_ch_7_2cls_2.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_7_2cls_2\/fold3\/weights\/last.pt --data \/kaggle\/working\/data_2cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_7_2cls_2\/fold3\/test_tta >>yolo_run_ch_7_2cls_2.logs\n!python ..\/input\/yolov5-github\/yolov5\/test.py --conf-thres 0.0001 --weights ..\/input\/weights-yolo\/run_ch_7_2cls_2\/fold4\/weights\/last.pt --data \/kaggle\/working\/data_2cls.yaml --augment --imgsz 512 --task test --save-txt --save-conf --project \"\" --name run_ch_7_2cls_2\/fold4\/test_tta >>yolo_run_ch_7_2cls_2.logs","b77db31a":"TOPK = 75\n\ndef xywh2x1x2y1y2(x):\n    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = x[:, 0] - x[:, 2] \/ 2  # top left x\n    y[:, 1] = x[:, 0] + x[:, 2] \/ 2  # bottom right x\n    y[:, 2] = x[:, 1] - x[:, 3] \/ 2  # top left y\n    y[:, 3] = x[:, 1] + x[:, 3] \/ 2  # bottom right y\n    return y\n\nLAB = np.array(['opacity','none'])\n\ndef get_results_yolo(val_df, pred_folder):\n\n\n    results = {}\n\n    images = []\n    boxes = []\n    labels = []\n    targets = []\n    confs = []\n    target_boxes = []\n    study_ids = []\n    image_ids = val_df['id'].values\n    detections = []\n    missing_preds = []\n    n_boxes = 0\n    for i,id_ in enumerate(image_ids):\n\n        w = val_df.iloc[i]['width']\n        h = val_df.iloc[i]['height']\n        if 'label' in val_df.columns:\n            label_box = np.array(val_df.iloc[i]['label'].split()).reshape(-1,6)\n            box_target = label_box[:,2:].astype(np.float32)\n            target = label_box[:,0]\n            mask = target == 'opacity'\n            if mask.sum() > 0:\n                box_target[mask,0] \/= w\n                box_target[mask,2] \/= w\n                box_target[mask,1] \/= h\n                box_target[mask,3] \/= h\n            target_boxes.append(box_target)\n            targets.append(target)\n        try:\n            det = pd.read_csv(f'{pred_folder}labels\/{id_.replace(\"_image\",\"\")}.txt', sep=' ', header=None, names=['cls','x','y','w','h','Conf'])\n            det = det.values\n            det = det[det[:,0]==0]\n            det = det[det[:, 5].argsort()[::-1]]\n            det = det[:TOPK]\n        except:\n            det = np.empty((1,6))\n            missing_preds += [id_]\n\n        n_boxes += len(det)\n        images.append([image_ids[i]] * len(det))\n        labels.append(list(LAB[det[:,0].astype(int)]))\n        box = xywh2x1x2y1y2(det[:,1:-1])\n        box = box.clip(0,1)\n#         box[:,:2] *= w\n#         box[:,2:] *= h\n        boxes.append(box)\n        confs.append(det[:,5])\n\n        study_ids.append(val_df.iloc[i]['StudyInstanceUID'])\n#     print(len(no_preds))\n    #     images += [image_ids[i]]\n    #     labels += ['none']\n    #     boxes += [np.array([0,0,1,1])[None,:]]\n    #     confs += [1-det[:,5].max()]\n\n    results[\"images\"] = images\n    results[\"boxes\"] = boxes\n    results[\"box_target\"] = target_boxes\n    results[\"target\"] = targets\n    results[\"labels\"] = labels\n    results[\"confs\"] = confs\n    results[\"study_idx\"] = study_ids\n    print(n_boxes)\n    return results, missing_preds\n\ndef get_df_image_pred(results, single_class =True):\n    images = []\n    boxes = []\n    labels = []\n    confs = []\n\n\n    for i in range(len(results[\"boxes\"])):\n\n        images += results[\"images\"][i]\n        labels +=results[\"labels\"][i]\n        boxes += [results[\"boxes\"][i]]\n        confs += list(results[\"confs\"][i])\n        images += [results[\"images\"][i][0]]\n        labels += ['none']\n        boxes += [np.array([0,1,0,1])[None,:]]\n        confs += [1-results[\"confs\"][i].max()]\n\n\n    df_image_pred = pd.DataFrame({'ImageID':images,'LabelName':labels,'Conf':np.array(confs)})\n    df_image_pred[['XMin','XMax','YMin','YMax']] = np.concatenate(boxes)\n\n    df_image_pred = df_image_pred[df_image_pred.XMin != df_image_pred.XMax]\n    df_image_pred = df_image_pred[df_image_pred.YMin != df_image_pred.YMax]\n\n    df_image_pred = df_image_pred[['ImageID','LabelName','Conf','XMin', 'XMax', 'YMin', 'YMax']].copy()\n    return df_image_pred\n\n","83f5b682":"dfs_pred_1b = []\nmissing_preds = 0\nfor fold in tqdm([0,1,2,3,4]):\n    pred_folder = f'run_ch_1b\/fold{fold}\/test_tta\/'\n#     print(len(os.listdir(pred_folder + 'labels\/')))\n    results, m = get_results_yolo(test_df, pred_folder)\n    missing_preds += len(m)\n    df_image_pred = get_df_image_pred(results)\n    dfs_pred_1b += [df_image_pred]\ndfs_pred_1b = pd.concat(dfs_pred_1b)\nmissing_preds","2df1166a":"dfs_pred_1b.sort_values(['ImageID','Conf'])","e03c3303":"dfs_pred_2b = []\nfor fold in tqdm([0,1,2,3,4]):\n    pred_folder = f'run_ch_2b\/fold{fold}\/test_tta\/'\n#     print(len(os.listdir(pred_folder + 'labels\/')))\n    results, m = get_results_yolo(test_df, pred_folder)\n    missing_preds += len(m)\n    df_image_pred = get_df_image_pred(results)\n    dfs_pred_2b += [df_image_pred]\ndfs_pred_2b = pd.concat(dfs_pred_2b)\nmissing_preds","3e643027":"dfs_pred_3b = []\nfor fold in tqdm([0,1,2,3,4]):\n    pred_folder = f'run_ch_3b\/fold{fold}\/test_tta\/'\n#     print(len(os.listdir(pred_folder + 'labels\/')))\n    results, m = get_results_yolo(test_df, pred_folder)\n    missing_preds += len(m)\n    df_image_pred = get_df_image_pred(results)\n    dfs_pred_3b += [df_image_pred]\ndfs_pred_3b = pd.concat(dfs_pred_3b)\nmissing_preds","a8469186":"dfs_pred_7_2cls_2 = []\nfor fold in tqdm([0,1,2,3,4]):\n    pred_folder = f'run_ch_7_2cls_2\/fold{fold}\/test_tta\/'\n#     print(len(os.listdir(pred_folder + 'labels\/')))\n    results, m = get_results_yolo(test_df, pred_folder)\n    missing_preds += len(m)\n    df_image_pred = get_df_image_pred(results,single_class=False)\n    dfs_pred_7_2cls_2 += [df_image_pred]\ndfs_pred_7_2cls_2 = pd.concat(dfs_pred_7_2cls_2)\nmissing_preds","264ad784":"df_image_pred_test = [dfs_pred_1b,dfs_pred_2b,dfs_pred_3b,dfs_pred_7_2cls_2,dfs_pred_ps_9,dfs_pred_ps_13,dfs_pred_ps_27,dfs_pred_ps_35]","ed215e0f":"df_test_opacity = [df[df['LabelName'] == 'opacity'].copy() for df in df_image_pred_test]\ndf_test_none = [df[df['LabelName'] == 'none'].copy() for df in df_image_pred_test]","afe203b8":"df_test_opacity = pd.concat(df_test_opacity)","0c478b83":"df_test_opacity","78ae38e8":"dfs_test_none = []\nfor item in df_test_none:\n    df_image_pred_none = item[['ImageID','Conf','XMin','XMax','YMin','YMax']].groupby('ImageID').agg('max')\n    df_image_pred_none = df_image_pred_none.reset_index()\n    df_image_pred_none['LabelName'] = 'none'\n    df_image_pred_none[['XMin','YMin','XMax','YMax']] = [0,0,1,1]\n    dfs_test_none += [df_image_pred_none]\ndfs_test_none = pd.concat(dfs_test_none)","6c39b3c4":"dfs_test_none2 = dfs_test_none[['ImageID','Conf','XMin','XMax','YMin','YMax']].groupby('ImageID').agg('mean')\ndfs_test_none2 = dfs_test_none2.reset_index()\ndfs_test_none2['LabelName'] = 'none'\ndfs_test_none2[['XMin','YMin','XMax','YMax']] = [0,0,1,1]\ndfs_test_none2","9273d9b3":"test_df","45cb9ff3":"dfs_test_none2 = dfs_test_none2.merge(test_df[[\"id\", \"StudyInstanceUID\"]], left_on=\"ImageID\", right_on=\"id\")","3a63b8f2":"dfs_test_none2 = dfs_test_none2.merge(df_study_orig[[\"study_id\", \"negative\", \"atypical\"]], left_on=\"StudyInstanceUID\", right_on=\"study_id\")","eee67609":"# PP 3\ndfs_test_none2[\"Conf\"] = 0.5*dfs_test_none2[\"Conf\"] + 0.5*dfs_test_none2[\"negative\"] + 0.2*dfs_test_none2[\"atypical\"]","2c7c85bd":"# def create_pred_str_study(row):\n#     items = []\n#     for label in [\"negative\", \"typical\", \"indeterminate\", \"atypical\"]:\n#         items += [label,row[label],'0','0','1','1']\n#     return ' '.join([str(i) for i in items])\n\n# def create_sub(test_preds, none_preds_image):\n#     df_study = pd.DataFrame({'id':study_ids})\n#     df_study['id'] = df_study['id'].astype(str) + '_study'\n#     df_study[[\"negative\", \"typical\", \"indeterminate\", \"atypical\"]] = test_preds\n#     df_study = df_study.groupby('id').agg('mean').reset_index()\n#     df_study[\"study_id\"] = df_study[\"id\"].str.replace(\"_study\", \"\")\n#     df_study = df_study.merge(none_preds_image, on=\"study_id\")\n    \n#     #PP 2\n#     df_study[\"negative\"] = df_study[\"Conf\"]\n#     df_study[\"id\"] = df_study[\"id_x\"]\n    \n#     df_study_orig = df_study.copy()\n#     df_study['PredictionString'] = df_study.apply(lambda row: create_pred_str_study(row), axis = 1)\n#     df_study= df_study[['id','PredictionString']].copy()\n#     df_study_orig[\"study_id\"] = df_study_orig[\"id\"].str.replace(\"_study\", \"\")\n#     return df_study, df_study_orig\n# df_study, df_study_orig = create_sub(test_preds_study, dfs_test_none2)\n# df_study = df_study.set_index('id')\n# df_study.head()\n\n# SAMPLE_SUBMISSION.loc[df_study.index,'PredictionString'] = df_study['PredictionString'].values","804ea207":"del dfs_test_none2[\"negative\"]\ndel dfs_test_none2[\"atypical\"]\ndel dfs_test_none2[\"StudyInstanceUID\"]\ndel dfs_test_none2[\"study_id\"]","1ff40fd4":"dfs_test_none2","17f740d3":"from ensemble_boxes import weighted_boxes_fusion, non_maximum_weighted\nfrom joblib import Parallel, delayed\n# import warnings\n# import sys\n# if not sys.warnoptions:\n#     warnings.simplefilter(\"ignore\")\n\n#def run_blend_boxes():\ndef run_blend_boxes(df_image,image_id):\n    label = df_image['LabelName'].map({'opacity':0,'none':1}).values\n    box = df_image[['XMin','YMin','XMax','YMax']].values\n    conf = df_image['Conf'].values\n    box, conf, label  = weighted_boxes_fusion([box], [conf], [label], weights=None, iou_thr=0.5, conf_type=\"max\", skip_box_thr=0.0)\n    boxes = box\n    confs = conf\n    labels = label\n    image_ids = [image_id]*len(conf)\n    \n    return boxes, confs, labels, image_ids\n\ndef combine_boxes(df_image_pred):\n\n    image_ids_unique = df_image_pred['ImageID'].unique()\n    df_image_pred_gr = df_image_pred.groupby('ImageID')\n    boxes = []\n    confs = []\n    labels = []\n    image_ids = []\n    \n    res = Parallel(n_jobs=N_CORES)(delayed(run_blend_boxes)(df_image_pred_gr.get_group(image_id), image_id) for image_id in tqdm(image_ids_unique))\n\n    boxes = [x[0] for x in res]\n    confs = [x[1] for x in res]\n    labels = [x[2] for x in res]\n    image_ids = [x[3] for x in res]\n    \n    boxes = np.concatenate(boxes)\n    confs = np.concatenate(confs)\n    labels = np.concatenate(labels)\n    image_ids = np.concatenate(image_ids)\n\n    df = pd.DataFrame({'ImageID':image_ids,'LabelName':labels,'Conf':confs})\n    df[['XMin','YMin','XMax','YMax']] = boxes\n    df['LabelName'] = df['LabelName'].map({0:'opacity',1:'none'})\n    df = df[['ImageID','LabelName','Conf','XMin','XMax','YMin','YMax']]    \n    return df","17eb1033":"df_test_opacity = combine_boxes(df_test_opacity)\ndf_test_opacity.shape","531713f8":"df_test_opacity = df_test_opacity.merge(test_df[['id','width','height']],how='left',left_on='ImageID',right_on='id')\ndf_test_opacity.head()","02df9624":"mask = df_test_opacity['LabelName']=='opacity'\n\nw = df_test_opacity.loc[mask,'width'].values\nx1x2 = df_test_opacity.loc[mask,['XMin','XMax']].values\nx1x2 = x1x2 * w[:,None]\ndf_test_opacity.loc[mask,['XMin','XMax']] = x1x2\n\nh = df_test_opacity.loc[mask,'height'].values\ny1y2 = df_test_opacity.loc[mask,['YMin','YMax']].values\ny1y2 = y1y2 * h[:,None]\ndf_test_opacity.loc[mask,['YMin','YMax']] = y1y2\n\ndf_test_opacity.loc[~mask,['XMin','XMax','YMin','YMax']] = np.array([0,1,0,1])\n\ndf_test_opacity.shape, mask.sum()","c94383dc":"df_test_opacity=df_test_opacity[dfs_test_none2.columns].copy()","ef90a375":"df_image_pred_test = pd.concat([df_test_opacity,dfs_test_none2])\ndf_image_pred_test","9111abf2":"SAMPLE_SUBMISSION","632933ab":"sub_image_ids = np.array([item for item in SAMPLE_SUBMISSION.index if item.endswith('_image')])\nsub_image_ids.shape","201287e6":"def create_str(id_):\n    df_tmp = df_image_pred_test[df_image_pred_test['ImageID'] == id_].copy()\n    preds = df_tmp[['LabelName','Conf','XMin','YMin','XMax','YMax']].values\n    preds = preds.reshape(-1)\n    return ' '.join([str(i) for i in preds])","dd674cf9":"strs = [create_str(id_) for id_ in sub_image_ids]","5042d48a":"SAMPLE_SUBMISSION.loc[sub_image_ids,'PredictionString'] = strs","3ee860f7":"SAMPLE_SUBMISSION.to_csv('submission_image_ch_blend3.csv')","6a9f826c":"SAMPLE_SUBMISSION","b1daefb9":"SAMPLE_SUBMISSION[SAMPLE_SUBMISSION.PredictionString!=\"\"]","d0c9adb8":"SAMPLE_SUBMISSION.to_csv('submission.csv')","5bbdae80":"!rm -r test_025","7ee52d58":"!rm -r test_05","dc3d070e":"!rm -rd run_ch_1b","c765b193":"!rm -rd run_ch_2b","d621529f":"!rm -rd run_ch_3b","0e1e2eb2":"!rm -rd run_ch_7_2cls_2","2049c60d":"!rm -rd configs","1989e033":"!rm -rd models","acaf5991":"## install pip wheels"}}