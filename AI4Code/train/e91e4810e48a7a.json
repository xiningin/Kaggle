{"cell_type":{"a2d44ceb":"code","b1d5edec":"code","b70df80c":"code","b3d4a016":"code","6848fc18":"code","0050ebdc":"code","26dd74d6":"code","2b430389":"code","c448b536":"code","f47535ec":"code","05a9cf00":"code","89825ebf":"code","f87514e4":"code","10f84d25":"code","b033c5c6":"code","6963637c":"code","73f93526":"markdown","80a34c6e":"markdown"},"source":{"a2d44ceb":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\n\nfrom collections import OrderedDict\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport torch\nfrom torch import optim, nn\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image\n\nimport random, os","b1d5edec":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","b70df80c":"print(os.listdir(\"..\/input\"))\ndata_dir = '..\/input'\nlabel_file = '..\/input\/monkey_labels.txt'\ntrain_dir = data_dir + '\/training\/training'\nvalid_dir = data_dir + '\/validation\/validation'\nprint(os.listdir(train_dir))","b3d4a016":"labelCols = [\"label\", \"latin_name\", \"common_name\", \"train_images\", \"valid_images\"]\nmonkeyLabels = pd.read_csv(label_file, skiprows = 1, sep=',', names=labelCols)\nmonkeyLabels","6848fc18":"for i in ['label', 'latin_name', 'common_name']:\n    monkeyLabels[i] = monkeyLabels[i].map(lambda x: x.lstrip(' \\n\\t').rstrip(' \\n\\t'))\nmonkeyLabels","0050ebdc":"\"\"\"Constants\"\"\"\nCATEGORIES = len(monkeyLabels['label'])\nARCHITECTURE = 'resnet18'\nLAYERS = 3\nAVAILABLE_MODELS = ['vgg11', 'vgg13', 'vgg16', 'vgg19', 'alexnet', 'resnet18']\nEPOCHS = 40\nBATCH_SIZE = 64\nLEARN_RATE = 0.001\nMEANS = [0.485, 0.456, 0.406]\nSTANDARD_DEVIATIONS = [0.229, 0.224, 0.225]\nCROP_DIMENSION = 224\nRESIZE_DIMENSION = 256\nNAME_DISPLAY_TYPE = 'common_name'\n\n\ntrain_loss, validation_loss, train_accuracy, validation_accuracy = [], [], [], []","26dd74d6":"def create_classifier(hidden_units, current_in_features):\n    \"\"\"\n\n    :param hidden_units:\n    :param current_in_features:\n    :return:\n    \"\"\"\n    print(\"Creating Classifier\")\n    hidden_layers = []\n    hidden_steps = int((hidden_units - CATEGORIES)\/LAYERS)\n    start = current_in_features\n    end = hidden_units\n    for i in range(1, LAYERS + 1):\n        hidden_layers.append(('fc{}'.format(i), nn.Linear(start, end)))\n        hidden_layers.append(('dropout{}'.format(i), nn.Dropout(p=0.1)))\n        hidden_layers.append(('relu{}'.format(i), nn.ReLU()))\n        start = end\n        end = start - hidden_steps\n\n    hidden_layers.append(('outputs', nn.Linear(start, CATEGORIES)))\n    hidden_layers.append(('logsoftmax', nn.LogSoftmax(dim=1)))\n\n    classifier = nn.Sequential(OrderedDict(hidden_layers))\n    return classifier\n\n\ndef build_neural_net(architecture, hidden_units):\n    \"\"\"\n\n    :param architecture:\n    :param hidden_units:\n    :return:\n    \"\"\"\n    print('Building Neural Network')\n    if architecture in AVAILABLE_MODELS:\n        # Download the pretrained model based on architecture\n        neural_network_model = getattr(models, architecture)(pretrained=True)\n        \n        # Freeze model weights\n        for param in neural_network_model.parameters():\n            param.requires_grad = False\n            \n        # Acquire the current in features of the pretrained classifier for new feed forward network\n        if architecture == 'alexnet':\n            current_in_features = neural_network_model.classifier._modules['1'].in_features\n            neural_network_model.classifier = create_classifier(hidden_units, current_in_features)\n        elif architecture == 'resnet18':\n            current_in_features = neural_network_model.fc.in_features\n            neural_network_model.fc = create_classifier(hidden_units, current_in_features)\n        else:\n            current_in_features = neural_network_model.classifier._modules['0'].in_features\n            neural_network_model.classifier = create_classifier(hidden_units, current_in_features)\n    else:\n        # Raise exception if architecture doesn't match available models\n        raise Exception(\"Architecture of requested pretrained model is not available\")\n\n    return neural_network_model\n\ndef random_photo(directory):\n    random_dir = random.choice([x for x in os.listdir(directory)])\n    random_filename = random.choice([x for x in os.listdir(directory + '\/' + random_dir)])\n    full_path = \"%s\/%s\/%s\" % (directory,random_dir,random_filename)\n    return full_path\n\ndef plot_images(tensor, count=1, normalize=True):\n    \n    images, labels = next(tensor)\n    a = np.floor(count**0.5).astype(int)\n    b = np.ceil(1.*count\/a).astype(int)\n    fig = plt.figure(figsize=(3.*b,3.*a))\n    for i in range(1,count+1):\n        ax = fig.add_subplot(a,b,i)\n        ax.plot([1,2,3],[1,2,3])\n        forDisplay = images[i].numpy().transpose((1, 2, 0))\n\n        if normalize:\n            mean = np.array(MEANS)\n            standard_deviation = np.array(STANDARD_DEVIATIONS)\n            forDisplay = standard_deviation * forDisplay + mean\n            forDisplay = np.clip(forDisplay, 0, 1)\n        ax.imshow(forDisplay)\n        ax.set_title(monkeyLabels.loc[labels[i].item(), NAME_DISPLAY_TYPE])\n        ax.set_axis_off()\n    \n    plt.show()\n    \ndef plot_performance(train_loss, validation_loss, train_accuracy, validation_accuracy):\n    plt.subplot(1, 2, 1)\n    plt.plot(train_loss, label='Training loss')\n    plt.plot(validation_loss, label='Validation loss')\n    plt.title('Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epochs')\n    legend = plt.legend(loc='upper right', shadow=True, fontsize='small')\n\n    # Put a nicer background color on the legend.\n    legend.get_frame().set_facecolor('C7')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(train_accuracy, label='Training accuracy')\n    plt.plot(validation_accuracy, label='Validation accuracy')\n    plt.title('Accuracy')\n    plt.ylabel('Percent Accurate')\n    plt.xlabel('Epochs')\n    legend = plt.legend(loc='upper left', shadow=True, fontsize='small')\n\n    # Put a nicer background color on the legend.\n    legend.get_frame().set_facecolor('C7')\n    \n    plt.tight_layout()\n    \ndef train_model(model, criterion, optimizer, num_epochs=EPOCHS):\n    model = model.to(device)\n    \n    for epoch in range(num_epochs):\n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train()\n                print(\"Training: Epoch %d\" % epoch)\n            else:\n                model.eval()\n                print(\"Validation: Epoch %d\" % epoch)\n                \n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.detach() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.float() \/ len(dataloaders[phase].dataset)\n            \n            if phase == 'validation':\n                validation_loss.append(epoch_loss.item())\n                validation_accuracy.append(epoch_acc.item() * 100)\n            else:\n                train_loss.append(epoch_loss.item())\n                train_accuracy.append(epoch_acc.item() * 100)\n            \n    \n    plot_performance(train_loss, validation_loss, train_accuracy, validation_accuracy)","2b430389":"def process_image(image):\n    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n        returns an Numpy array'''\n    \n    process_transforms = transforms.Compose([transforms.Resize(RESIZE_DIMENSION),\n                                             transforms.CenterCrop(CROP_DIMENSION),\n                                             transforms.ToTensor(),\n                                             transforms.Normalize(MEANS, STANDARD_DEVIATIONS),\n                                            ])\n    \n    pil_image = Image.open(image)\n    tensor_image = process_transforms(pil_image)\n    numpy_image = tensor_image.numpy()\n    \n    return numpy_image\n\ndef imshow(image, ax=None, title=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    \n    # PyTorch tensors assume the color channel is the first dimension\n    # but matplotlib assumes is the third dimension\n    image = image.transpose((1, 2, 0))\n    \n    # Undo preprocessing\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n    \n    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n    image = np.clip(image, 0, 1)\n    \n    if title is not None:\n        ax.set_title(title)\n    ax.axis('off')    \n    ax.imshow(image)\n    \n    return ax\n\n\ndef convert_labels(labels):\n    names_array = np.array([])\n    for i in np.nditer(labels.cpu().numpy()):        \n        #print(monkeyLabels.loc[i.item(), NAME_DISPLAY_TYPE])\n        names_array = np.append(names_array, monkeyLabels.loc[i.item(), NAME_DISPLAY_TYPE])\n    return names_array\n\ndef process_image_tensor(image_path):\n    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n        returns an Numpy array'''\n    \n    process_transforms = transforms.Compose([transforms.Resize(RESIZE_DIMENSION),\n                                             transforms.CenterCrop(CROP_DIMENSION),\n                                             transforms.ToTensor(),\n                                             transforms.Normalize(MEANS, STANDARD_DEVIATIONS),\n                                            ])\n    \n    pil_image = Image.open(image_path)\n    tensor_image = process_transforms(pil_image)\n    \n    return tensor_image\n\ndef predict(image_path, model, topk=5):\n    ''' Predict the class (or classes) of an image using a trained deep learning model.\n    '''\n    model.to(device)\n    model.eval()\n    image_tensor = process_image_tensor(image_path).unsqueeze_(0)\n    \n    with torch.no_grad():\n        image_tensor = image_tensor.to(device)\n        output = model.forward(image_tensor)\n    \n    probabilities = torch.exp(output)\n    probs, labels = probabilities.topk(topk)\n    return probs.cpu().numpy()[0], convert_labels(labels);\n\ndef view_class_probability(image_path, neural_network_model):\n    probabilities, classes = predict(image_path, neural_network_model)\n    \n    \n    image_elements = image_path.split('\/')    \n    category_num = image_elements[-2]\n    \n    fig, (ax1, ax2) = plt.subplots(figsize = (6,10), ncols=2)\n    ax1 = plt.subplot(2,1,1)\n    imshow(process_image(image_path), ax1)\n    \n    \n    \n    # Set up title\n    title = monkeyLabels.loc[int(category_num[-1]), NAME_DISPLAY_TYPE]\n    \n    # Plot image\n    img = process_image(image_path)\n    imshow(img, ax1, title);\n    ax2 = fig.add_subplot(2,1,2)\n    y_pos = np.arange(len(classes))\n    error = np.random.rand(len(classes))\n\n    ax2.barh(y_pos, probabilities, align='center',\n        color='blue')\n    ax2.set_yticks(y_pos)\n    ax2.set_yticklabels(classes)\n    ax2.invert_yaxis()  # labels read top-to-bottom\n    ax2.set_xlabel('Probability')\n    ax2.set_title('Class Probability')\n    plt.tight_layout()\n       ","c448b536":"# Define your transforms for the training, validation, and testing sets\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.CenterCrop(CROP_DIMENSION),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.RandomVerticalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize(MEANS, STANDARD_DEVIATIONS)\n                                      ])\n\nvalid_transforms = transforms.Compose([transforms.Resize(RESIZE_DIMENSION), \n                                      transforms.CenterCrop(CROP_DIMENSION), \n                                      transforms.ToTensor(), \n                                      transforms.Normalize(MEANS, STANDARD_DEVIATIONS)\n                                     ])\n\n# Load the datasets with ImageFolder\ntrain_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\nvalid_dataset = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n\n# Using the image datasets and the trainforms, define the dataloaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n\ndataloaders = {\n    \"train\": train_loader,\n    \"validation\": valid_loader\n}","f47535ec":"plot_images(iter(train_loader), 9)","05a9cf00":"plot_images(iter(valid_loader), 9)","89825ebf":"neural_network_model = build_neural_net(ARCHITECTURE,LAYERS)\nneural_network_model","f87514e4":"criterion = nn.NLLLoss()\n\nif ARCHITECTURE == 'resnet18':\n    optimizer = optim.Adam(neural_network_model.fc.parameters(), lr=LEARN_RATE)\nelse:\n    optimizer = optim.Adam(neural_network_model.classifier.parameters(), lr=LEARN_RATE)\n","10f84d25":"train_model(neural_network_model, criterion, optimizer)","b033c5c6":"view_class_probability(random_photo(valid_dir), neural_network_model)","6963637c":"view_class_probability(random_photo(valid_dir), neural_network_model)","73f93526":"First lets load our labels from monkey_labels.txt\nI will use pandas to load the data from the monkey classification","80a34c6e":"It looks like there are some tabs and spaces left in our pandas import so let's clean those up.\n\n"}}