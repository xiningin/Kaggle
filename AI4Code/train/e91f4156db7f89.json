{"cell_type":{"db8becb0":"code","8360dd0e":"code","1b4ebf4a":"code","27f7ccde":"code","6552118d":"code","aef7dba3":"code","17262d78":"code","48d44089":"code","e5398114":"code","f36c08cc":"code","1d0d6b20":"code","d6b98aa4":"code","f1f77c4b":"code","85aa2198":"code","e30fa11e":"code","1860360a":"code","45a3b7e3":"code","6c9740d6":"code","319f31f4":"code","0be5a95d":"code","1e1995ab":"code","a754fac7":"code","6d9531be":"code","a0274066":"code","a4136fd0":"markdown","ecf384ea":"markdown","c5d27a09":"markdown","8d350ce1":"markdown","85900db5":"markdown","b06a0987":"markdown","fdb7c0e0":"markdown","f4984cef":"markdown","090c4199":"markdown","0122d85d":"markdown"},"source":{"db8becb0":"import pandas as pd\nimport random\nfrom google.cloud import bigquery\nfrom google.cloud import storage\nfrom kaggle_secrets import UserSecretsClient\n","8360dd0e":"pip install detoxify","1b4ebf4a":"bad_words = pd.read_csv(\n    'https:\/\/raw.githubusercontent.com\/LDNOOBW\/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words\/master\/en',\n    header=None\n)","27f7ccde":"url = 'https:\/\/github.com\/hadarishav\/Ruddit\/raw\/main\/Dataset\/Ruddit_individual_annotations.csv'\nruddit = pd.read_csv(url)","6552118d":"ruddit.head()","aef7dba3":"posts = pd.read_csv('https:\/\/github.com\/hadarishav\/Ruddit\/raw\/main\/Dataset\/Ruddit.csv')","17262d78":"good_bad = []\nids = set()\nfor row in ruddit.itertuples(index=False):\n  if row.BestItem != 'gold_comment':\n    for item in row[0:4]:\n      # Counter-intuitively BestItem is actually the most offensive.\n      if item != 'gold_comment' and item != row.BestItem:\n        good_bad.append((item, row.BestItem))\n        ids.add(item)\n        ids.add(row.BestItem)\n  if row.WorstItem != 'gold_comment':\n    for item in row[0:4]:\n      # WorstItem is the least offensive of the tuple.\n      if item != 'gold_comment' and item != row.WorstItem:\n        good_bad.append((row.WorstItem, item))\n        ids.add(row.WorstItem)\n        ids.add(item)","48d44089":"client = bigquery.Client(project=UserSecretsClient().get_secret('PROJECT_ID'))","e5398114":"query = \"\"\"\n  SELECT id as comment_id, body as comment_text\n  FROM [fh-bigquery.reddit_comments.all]\n  WHERE id IN(%s);\n  \"\"\" % ','.join([\"'\" + x + \"'\" for x in ids])","f36c08cc":"query_job = client.query(query, job_config=bigquery.QueryJobConfig(use_legacy_sql=True))","1d0d6b20":"comments = query_job.to_dataframe().drop_duplicates()","d6b98aa4":"comments['bad_words_count'] = comments['comment_text'].map(\n    lambda line: sum([x in line.lower() for x in bad_words[0]]))","f1f77c4b":"ordered_comments = comments.sort_values('bad_words_count', ascending=True)","85aa2198":"def aggreement_with_annotators(annotation_pairs, ordered_ids):\n    # Creates an enumeration of the comment ids with comment id -> ordinal count.\n    assert len(ordered_ids) == 6000\n    # You must submit 6000 comment ids.\n    score_dict = {k: v for v, k in enumerate(ordered_ids)}\n    # You must submit 6000 unique ids.\n    assert len(score_dict) == 6000\n    # For every annotation we map through the scores to see how often the\n    # comments aggree with the annotator's ranking for each pair.\n    sx = [score_dict[pair[0]] < score_dict[pair[1]] for pair in annotation_pairs]\n    return sum(sx) \/ len(sx)","e30fa11e":"aggreement_with_annotators(good_bad, comments['comment_id'].sample(frac=1.0))\n","1860360a":"aggreement_with_annotators(good_bad,  ordered_comments['comment_id'])","45a3b7e3":"perspective = pd.read_csv('..\/input\/rudditperspectivescores\/ruddit_persective.csv').drop_duplicates()","6c9740d6":"aggreement_with_annotators(\n    good_bad,\n    perspective.sort_values('toxicity', ascending=True)['comment_id'])","319f31f4":"from detoxify import Detoxify","0be5a95d":"results = Detoxify('original').predict('example text')","1e1995ab":"model = Detoxify('original')","a754fac7":"comments['unitary'] = comments['comment_text'].map(\n    lambda line: model.predict(line)['toxicity'])","6d9531be":"unitary_ordered_comments = comments.sort_values('unitary', ascending=True)","a0274066":"aggreement_with_annotators(\n    good_bad,\n    comments.sort_values('unitary', ascending=True)['comment_id'])","a4136fd0":"How about ordering by the number of bad words?","ecf384ea":"And let's compare with a score for a randomly shuffled set of comment ids.","c5d27a09":"In order to score these comments, we need to join with the public copy of the Reddit comments. This requires a Google cloud project, with the project ID stored in a secret for this notebook.","8d350ce1":"good_bad will be a list of pairs where the left size is worse than the right side.","85900db5":"Let's import the same comments scores using the PerspectiveAPI.","b06a0987":"Install Unitary Detoxify for scoring comments.","fdb7c0e0":"Import the comment annotations from the recent paper *[Ruddit: Norms of Offensiveness for English Reddit Comments](http:\/\/arxiv.org\/abs\/2106.05664)* by Rishav Had et al.","f4984cef":"Import a \"bad word\" list from a Github repository. This will be used to make a very primitive \"model\" for scoring.","090c4199":"Let's try scoring with the open source Detoxify model","0122d85d":"This notebook illustrates an application of ranking by severity (of offensiveness) and how we intend to use that in a future Kaggle competition."}}