{"cell_type":{"be7eff48":"code","29704592":"code","631319d6":"code","dc36522a":"code","3b4d7893":"code","1f0fe4a5":"code","7ef02e8b":"code","70eb9ceb":"code","eec9d5b9":"code","bb08f4b5":"code","157f4454":"code","784ca883":"code","fe404eaa":"code","8614f3b6":"code","b76931db":"code","30fc9953":"code","bee24e1f":"code","b5f01980":"code","714c7233":"code","0b0b00cf":"code","b4ec29af":"code","fbc93a9f":"code","4f4b3617":"code","f3c44e18":"code","a83f9af9":"code","bda34c69":"code","eb79d07b":"code","6f6ad1ac":"code","cef1dfa8":"code","f7637f5b":"code","ef2f9536":"code","56768034":"code","d17c7975":"markdown","321c850f":"markdown","71388182":"markdown","ad6f9dce":"markdown","dccad411":"markdown","c12beb68":"markdown","4f1b69e9":"markdown","6a7b62e6":"markdown","a5376554":"markdown","27e6c527":"markdown","07a270e3":"markdown","92b47ead":"markdown","c2870f30":"markdown","a4178f0e":"markdown","975f39ad":"markdown","ceebe58a":"markdown","6bc8ee79":"markdown","1af6d185":"markdown","50dee7be":"markdown","b941bb87":"markdown","aea184ba":"markdown","28c4a334":"markdown","60d43859":"markdown","81f98dfe":"markdown","3c767c34":"markdown","07a0dc33":"markdown","c57d8701":"markdown","334c2099":"markdown","dc49dde4":"markdown","7d74390e":"markdown","1e58ba70":"markdown","e0db8614":"markdown","105e33c7":"markdown","d74e4b82":"markdown","6acbce08":"markdown"},"source":{"be7eff48":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport numpy as np\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","29704592":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","631319d6":"print('Total de linhas e colunas\\n\\n',df.shape, '\\n')","dc36522a":"df.isnull().sum()","3b4d7893":"df.info()","1f0fe4a5":"df.describe().round()","7ef02e8b":"print ('Non Fraud % ',round(df['Class'].value_counts()[0]\/len(df)*100,2))\nprint ()\nprint (round(df.Amount[df.Class == 0].describe(),2))\nprint ()\nprint ()\nprint ('Fraud %    ',round(df['Class'].value_counts()[1]\/len(df)*100,2))\nprint ()\nprint (round(df.Amount[df.Class == 1].describe(),2))","70eb9ceb":"plt.figure(figsize=(10,8))\nsns.set_style('darkgrid')\nsns.barplot(x=df['Class'].value_counts().index,y=df['Class'].value_counts(), palette=[\"C1\", \"C8\"])\nplt.title('Non Fraud X Fraud')\nplt.ylabel('Count')\nplt.xlabel('0:Non Fraud, 1:Fraud')\nprint ('Non Fraud % ',round(df['Class'].value_counts()[0]\/len(df)*100,2))\nprint ('Fraud %    ',round(df['Class'].value_counts()[1]\/len(df)*100,2));","eec9d5b9":"feature_names = df.iloc[:, 1:30].columns\ntarget = df.iloc[:1, 30:].columns\n\n\ndata_features = df[feature_names]\ndata_target = df[target]","bb08f4b5":"feature_names","157f4454":"target","784ca883":"from sklearn.model_selection import train_test_split\nnp.random.seed(123)\nX_train, X_test, y_train, y_test = train_test_split(data_features, data_target, \n                                                    train_size = 0.70, test_size = 0.30, random_state = 1)","fe404eaa":"xg = xgb.XGBClassifier()","8614f3b6":"xg.fit(X_train, y_train)","b76931db":"def PrintStats(cmat, y_test, pred):\n    tpos = cmat[0][0]\n    fneg = cmat[1][1]\n    fpos = cmat[0][1]\n    tneg = cmat[1][0]","30fc9953":"def RunModel(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train.values.ravel())\n    pred = model.predict(X_test)\n    matrix = confusion_matrix(y_test, pred)\n    return matrix, pred","bee24e1f":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport scikitplot as skplt","b5f01980":"cmat, pred = RunModel(xg, X_train, y_train, X_test, y_test)","714c7233":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test, pred)","0b0b00cf":"accuracy_score(y_test, pred)","b4ec29af":"print (classification_report(y_test, pred))","fbc93a9f":"# The function \"len\" counts the number of classes = 1 and saves it as an object \"fraud_records\"\nfraud_records = len(df[df.Class == 1]) \n\n# Defines the index for fraud and non-fraud in the lines:\nfraud_indices = df[df.Class == 1].index\nnormal_indices = df[df.Class == 0].index\n\n# Randomly collect equal samples of each type:\nunder_sample_indices = np.random.choice(normal_indices, fraud_records, False)\ndf_undersampled = df.iloc[np.concatenate([fraud_indices, under_sample_indices]),:]\nX_undersampled = df_undersampled.iloc[:,1:30]\nY_undersampled = df_undersampled.Class\nX_undersampled_train, X_undersampled_test, Y_undersampled_train, Y_undersampled_test = train_test_split(X_undersampled, Y_undersampled, test_size = 0.30)","4f4b3617":"xg_undersampled = xgb.XGBClassifier() \ncmat, pred = RunModel(xg_undersampled, X_undersampled_train, Y_undersampled_train, X_undersampled_test, Y_undersampled_test)\nPrintStats(cmat, Y_undersampled_test, pred)","f3c44e18":"skplt.metrics.plot_confusion_matrix(Y_undersampled_test, pred)","a83f9af9":"accuracy_score(Y_undersampled_test, pred)","bda34c69":"print (classification_report(Y_undersampled_test, pred))","eb79d07b":"xg = xgb.XGBClassifier() \ncmat, pred = RunModel(xg, X_undersampled_train, Y_undersampled_train, X_test, y_test)\nPrintStats(cmat, y_test, pred)","6f6ad1ac":"skplt.metrics.plot_confusion_matrix(y_test, pred)","cef1dfa8":"accuracy_score(y_test, pred)","f7637f5b":"print (classification_report(y_test, pred))","ef2f9536":"from sklearn import metrics                                ","56768034":"# Creating XGBoost model\nclf = xgb.XGBClassifier()\nclf.fit(X_undersampled_train, Y_undersampled_train)\ny_pred = clf.predict(X_test)\n\n# AUC Curve XGBoost\ny_pred_probability = clf.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probability)\nauc = metrics.roc_auc_score(y_test, y_pred_probability)\nplt.plot(fpr,tpr,label=\"XGBoost, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","d17c7975":"### Verification of the existence of null or missing values","321c850f":"### Separation of input variables from target variable","71388182":"### Basic Libraries import","ad6f9dce":"Accuracy has decreased, but sensitivity has greatly increased. Looking at the confusion matrix, we can see a much higher percentage of correct classifications of fraudulent data.\n\nUnfortunately, a greater number of fraud classifications almost always means a correspondingly greater number of valid transactions also classified as fraudulent.","dccad411":"![image.png](attachment:image.png)","c12beb68":"### Statistical information in each class","4f1b69e9":"In this case, we will use the undersampling technique to obtain a uniform division between fraud and valid transactions. This will make the training set small, but with enough data to generate a good classifier.","6a7b62e6":"### Comparing the amount value of normal transactions versus fraud","a5376554":"### ### Applying the undersampling technique","27e6c527":"With the XGBoost Model, we have:\n\n85297 transactions classified as normal and were actually normal;\n\n11 transactions classified as fraud but that were really normal (type 1 error);\n\n34 transactions classified as normal but which were fraud (type 2 error);\n\n101 transactions classified as fraud and were actually fraud.\n\nThus, although the accuracy was excellent, the algorithm wrongly classified about 3 out of 10 fraudulent transactions.\n\nAccuracy in a highly unbalanced dataset does not represent a correct value for the efficiency of a model.\n\nInitially, a method should be applied to balance the data before taking into account any performance evaluation metrics.\n\n** Accuracy in a highly unbalanced data set does not represent a correct value for the efficiency of a model. Initially, a method should be applied to balance the data before taking into account any performance evaluation metrics.","07a270e3":"### Measurement of classifier performance through the ROC and AUC curve","92b47ead":"## Credit card transaction fraud detection - XGBoost example","c2870f30":"### Statistical information about the variables","a4178f0e":"We can see the total of 284,807 transactions, 284,315 were labeled as normal (99.83%), and only 492 transactions were labeled as fraud (0.17%). Although it may seem small, each fraud transaction can represent a very significant expense, which together can represent billions of dollars of lost revenue each year.","975f39ad":"![image.png](attachment:image.png)","ceebe58a":"We reached a very satisfactory number in detecting fraud transactions in relation to the initial model, rising from 75% to 98% of correctly identified transactions. In return, the detection of correctly identified normal transactions decreased from 99% to 97%.\n\nRemember that we need to determine where this exchange is worthwhile. Generally, the costs of losing a fraudulent transaction are often greater than mistakenly classifying a good transaction as fraud. One of the challenges is to find the balance in training your model and proceed accordingly.\n\nAs a way to further improve the performance of the model, there are several ways to explore the input variables, performing some techniques of \"Data Pre-Processing\" and \"Feature Engineering\".","6bc8ee79":"![image.png](attachment:image.png)","1af6d185":"The \"ROC\" curve is a probability curve that shows how much the classifier can distinguish between two things, through two parameters: the true-positive rate versus the false-positive rate, that is, the number of times the classifier hit the prediction against the number of times the classifier missed the prediction.\n\nThe \"AUC\" is derived from the \"ROC\" curve and represents the degree or measure of separability. The AUC summarizes the ROC curve in a single value, calculating the \u201carea under the curve\u201d. The higher the AUC the better the model is in predicting 0s as 0s and 1s as 1s. In this case, the higher the AUC the better the model is in distinguishing between fraudulent and normal transactions. The AUC value ranges from 0.0 to 1.0.\n\nAn excellent model has AUC close to 1, which means it has a good measure of separability. A poor model has AUC close to 0, which means that it has the worst measure of separability, that is, it is predicting 0s as 1s and 1s as 0s. And when the AUC is 0.5, it means that the model has no class separation capability.","50dee7be":"### Variable type in each column","b941bb87":"### Confusion Matrix - Model performance measures","aea184ba":"### Using the \"new\" classifier for the original data test","28c4a334":"The application of methods for data balancing, such as undersampling and oversampling techniques are widely used in these cases. Changing the sampling makes the algorithm more \"sensitive\" to fraudulent transactions.\n\nUndersampling is the technique of removing major class records from the sample. In this case, it is necessary to remove random records from the legitimate class (No fraud), in order to obtain a number of records close to the amount of the minority class (fraud) in order to train the model.\n\nOversampling is exactly the opposite: it means adding minority class records (fraud) to our training sample, thus increasing the overall proportion of fraud records. There are methods to generate samples from the minority class, either by duplicating existing records or artificially generating others.","60d43859":"With the dataset defined, separating the input variables from the target variable, we divided the data into training and test sets, importing the train_test_split function.\n\nThe train_test_split function uses a randomizer to separate data into training and test sets. In this case, 70% of the data for training and 30% for tests were defined.\n\nThe random seed (np.random.seed) is used to ensure that the same data is used for all runs.","81f98dfe":"### Reading the dataset","3c767c34":"According to Infosecurity Magazine, fraud cost the global economy \u00a3 3.2 trillion in 2018 (https:\/\/www.infosecurity-magazine.com\/news\/global-fraud-hits-32-trillion\/). For many companies, losses involving transaction fraud amount to more than 10% of their total expenses. The concern with these massive losses leads companies to constantly seek new solutions to prevent, detect and eliminate fraud. Machine Learning is one of the most promising technological weapons to combat financial fraud.\n\nThe objective of this project is to create a simple Logistic Regression model capable of detecting fraud in credit card operations, thus seeking to minimize the risk and loss of the business. The biggest challenge is to create a model that is very sensitive to fraud, since most transactions are legitimate, making detection difficult.\n\nThe dataset used, contains transactions carried out by European credit card holders that took place over two days in September 2013, and is available on kaggle at https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\/version\/3.\n\nIt is a very unbalanced data set, that is, it has 492 fraud transactions, which represents only 0.172% of the 284,807 transactions.\n\nThe input variables are numeric, the result of a PCA transformation. Due to confidentiality issues, the original data and other complementary information were not made available.\n\nThe only variables that have not been transformed with the PCA are 'Time' and 'Value'. The variable 'Time' contains the seconds between each transaction and the first transaction in the dataset. The 'Amount' variable refers to the amount of the transaction.\n\nThe 'Class' variable is the response variable (Target) and has a value \"1\" in case of fraud and \"0\" otherwise.","07a0dc33":"*The average value of fraud transactions is 122.21 and for normal transactions, 88.29.","c57d8701":"### Undersampling and Oversampling - Working with unbalanced data","334c2099":"### Using the \"new\" classifier for balanced data","dc49dde4":"The classifier had a very good result, with AUC of 0.99!","7d74390e":"### Building the XGBoost Model","1e58ba70":"### Number of rows and columns","e0db8614":"### Conclusion","105e33c7":"## Introduction","d74e4b82":"### Training the Model","6acbce08":"### Classification Report - Model performance measures"}}