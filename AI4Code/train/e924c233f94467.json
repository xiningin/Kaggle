{"cell_type":{"fd0f84f4":"code","9cdc5811":"code","c7efa2ea":"code","d2c25116":"code","72729b46":"code","8b9d0a89":"code","9d05ba40":"code","4b4f9123":"code","6e93ca6e":"code","37ab8908":"code","826226be":"code","d23ed12b":"code","175ce6d0":"code","893fce0e":"code","73dab099":"code","340b48e2":"code","c963457f":"code","f0c55c10":"markdown","189c8318":"markdown","c3b372f7":"markdown","c7f594be":"markdown","5e7e948f":"markdown","33a7e482":"markdown","85151b16":"markdown"},"source":{"fd0f84f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cdc5811":"samples = ['Google has Chrome Browser.', 'Microsoft has Bing Browser.']\ncorpus = []\nfor sample in samples:\n    for word in sample.split():\n        corpus.append(word)\nprint('Corpus make by me: ', corpus)","c7efa2ea":"samples = ['Google has Chrome Browser.', 'Microsoft has Bing Browser.']\nvocab = []\nfor sample in samples:\n    for word in sample.split():\n        if not word in vocab:\n            vocab.append(word)\nprint('vocab make by me: ', vocab)","d2c25116":"samples = ['Google has Chrome Browser.', 'Microsoft has Bing Browser']\ntoken_indx = {}\ncounter = 0\nprint(samples)\nfor sample in samples:\n    for word in sample.split():\n        if not word in token_indx:\n            token_indx.update({word: counter+1})\n            counter = counter + 1\ntoken_indx","72729b46":"max_len = 4 # sample[0] and sample[1] have 4 words\nresults = np.zeros(shape=(len(samples), max_len, max(token_indx.values())+1))\nresults","8b9d0a89":"for i, sample in enumerate(samples):\n    for j, word in list(enumerate(sample.split())):\n        indx = token_indx.get(word)\n        results[i, j, indx] = 1","9d05ba40":"results","4b4f9123":"results.shape # 3 dimensional tensor","6e93ca6e":"samples","37ab8908":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nbow = cv.fit_transform(corpus)\nprint('Order of words: ',cv.vocabulary_)\nprint('Features names: ', cv.get_feature_names())\nprint('Dense matrix of words: \\n', bow.todense())","826226be":"from nltk.util import ngrams\ndef ngrams_fun(sent, n):\n    n_grams = ngrams(sent.split(), n)\n    print(f'-->>For {n} grams')\n    for token in n_grams:\n        print(token)","d23ed12b":"sent = 'I love my country'\nprint(ngrams_fun(sent, 1))\nprint(ngrams_fun(sent, 2))\nprint(ngrams_fun(sent, 3))","175ce6d0":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\ntrain = ('The sky is blue.','The sun is bright.')\ntest = ('The sun in the sky is bright', 'We can see the shining sun, the bright sun.')","893fce0e":"countvectorizer = CountVectorizer(analyzer='word', stop_words='english')\ntfidfvectorizer = TfidfVectorizer(analyzer='word', stop_words='english')","73dab099":"count_tr = countvectorizer.fit_transform(train)\ntfidf_tr = tfidfvectorizer.fit_transform(train)","340b48e2":"count_te = countvectorizer.transform(test)\ntfidf_te = tfidfvectorizer.transform(test)","c963457f":"features = countvectorizer.get_feature_names()\nprint('Featues names: ',features)\nprint('-->>For Train\\n')\ncount_df = pd.DataFrame(data=count_tr.toarray(), index=['d1', 'd2'], columns=features)\nprint('Count Vectorizer: \\n',count_df)\ntfidf_df = pd.DataFrame(data=tfidf_tr.toarray(), index=['d1', 'd2'], columns=features)\nprint('Tfidf Vectorizer: \\n',tfidf_df)\nprint()\nprint('-->>For Test')\ncount_df = pd.DataFrame(data=count_te.toarray(), index=['d1', 'd2'], columns=features)\nprint('Count Vectorizer: \\n', count_df)\ntfidf_df = pd.DataFrame(data=tfidf_te.toarray(), index=['d1', 'd2'], columns=features)\nprint('Tfidf Vectorizer: \\n',tfidf_df)","f0c55c10":"## 4.TF-IDF(Term Frequency-Inverse Document Frequency)\n### Other methods does not give the priority of the main word.\n### Like, The sun is bright. \n### Where _bright_ is the main word. That's why TF-IDF comes into the picture","189c8318":"## 3.N-grams\n### sent = I love my country.\n### unigram: I || love || my || country\n### bigram: I love || love my || my country\n### trigram: I love my || love my country","c3b372f7":"## Text Representation| Text Vectorization\n### ML algorithm only works when the data in numerical form.\n### In NLP, We have to convert text or words into numerical values.","c7f594be":"## 1. One Hot Encoding","5e7e948f":"## 2. Bag of Words","33a7e482":"###  Common terms in text:\n+ Corpus: Merge all words of the one sentence.\n+ Vocabulary: Unique words in corpus.\n+ Document: One Record, One Document.\n+ Word: Sentence makes with many words. ","85151b16":"## There are many methods for covert text into numerical values.\n1. One Hot Encoding\n2. Bag of words\n3. N-grams\n4. TFIDF"}}