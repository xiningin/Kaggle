{"cell_type":{"57926263":"code","98daf3c2":"code","95fa9abe":"code","04294baf":"code","49b3ff0b":"code","86cc84af":"code","60ada84c":"code","01ddc7fd":"code","9e9819e3":"code","8efbf50e":"code","a093df05":"code","6e892b56":"code","b3bf8821":"code","cfa9aa08":"code","d249987b":"code","073f93e0":"code","2babc108":"code","90a1f184":"code","0cf73971":"code","73eb4fcb":"code","2615efcf":"code","c9414d80":"code","b3700007":"code","9c91a835":"code","d03dd81e":"code","f4988daa":"code","0ea75f82":"code","f06ca12f":"code","298145d0":"code","69c217c2":"code","8c4e7cb6":"code","0d7ea6a2":"code","24195dc8":"code","e626fda7":"code","b1b40148":"code","d5041fc4":"code","3ba21e3f":"code","0da97e97":"code","130220fc":"code","bbb38063":"code","3f1d2da6":"code","fc40b4d1":"code","6aa21859":"code","6246b89b":"code","246f943c":"code","bbe759cd":"code","e2264fb2":"code","6808b454":"code","992a8cbf":"markdown","56ee3415":"markdown","8ce92ab8":"markdown","449e08d3":"markdown","5c6e6654":"markdown","49c7a7a3":"markdown","a3381ea2":"markdown","904fbee2":"markdown","d353993a":"markdown","1d29abaa":"markdown","d6af6a27":"markdown","00a47629":"markdown","122a7aa2":"markdown","d373dbcc":"markdown","7651d689":"markdown"},"source":{"57926263":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rnd\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98daf3c2":"def okprint(message):\n    print('\\033[92m' + message + '\\033[0m')\n","95fa9abe":"def errprint(errmessage):\n    print('\\033[91m' + errmessage + '\\033[0m')","04294baf":"try:\n    os.chdir('\/kaggle\/input\/plant-pathology-2020-fgvc7\/')\n    okprint('success!')\nexcept:\n    errprint('can not load folder')","49b3ff0b":"path = os.getcwd() \nprint('current folder :',path)","86cc84af":"try:\n    train_csv = pd.read_csv('train.csv')\n    okprint('read successfully')\nexcept:\n    errprint('error while reading')","60ada84c":"header_names = list(train_csv.columns)\nprint('columns:', header_names)","01ddc7fd":"try:\n    os.chdir('\/kaggle\/working\/')\n    okprint('success!')\nexcept:\n    errprint('can not load folder')","9e9819e3":"main_folders = ['test\/','train\/','valid\/']","8efbf50e":"print('current dir:', os.getcwd())\ntry:\n    for fold in main_folders:\n        os.mkdir(fold)\n    okprint('test,valid and train folders created successfully!')\nexcept:\n    errprint('error while creating test,valid train folders! (may be they have already been created!)')","a093df05":"class_names = header_names[1:]\nprint('classes:', class_names)","6e892b56":"print('current dir:', os.getcwd())\ntry:\n    for folder_name in class_names:\n        for main_fold in main_folders:\n            if main_fold != 'test\/':\n                cur_new_folder = os.path.join(main_fold, folder_name)\n                os.mkdir(cur_new_folder)\n                okprint('folder ' + cur_new_folder + ' created successfully')\n                \nexcept:\n    errprint('can not create folder! (may be they have already been created)')","b3bf8821":"for main_folder in main_folders:\n    print('folders in', main_folder,':')\n    print(os.listdir(main_folder))\n    print()","cfa9aa08":"image_base_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'\nimage_direction_test_path = '\/kaggle\/working\/test\/'\nimage_direction_train_path = '\/kaggle\/working\/train\/'\nimage_direction_valid_path = '\/kaggle\/working\/valid\/'","d249987b":"all_train_images = []\ntrain_images = []\nvalid_images = []\ntest_images = []\nimage_pathes = os.listdir(image_base_path)\nfor image in image_pathes:\n    if 'Test' in image:\n        test_images.append(image)\n    else:\n        all_train_images.append(image)\nrnd.shuffle(all_train_images)\nvalid_percent = 13\ndivide_index = int(len(all_train_images) * (valid_percent) \/ 100)\ntrain_images, valid_images = all_train_images[divide_index:], all_train_images[:divide_index]\nprint('there are',len(train_images),'test,',len(valid_images),'valid and',len(test_images),'train images')","073f93e0":"def get_class_name(raw_id: int)-> str:\n    global class_names\n    for class_name in class_names:\n        if train_csv[class_name][raw_id] == 1:\n            return class_name\n    raise BaseException('Error! there is raw #', raw_id,'without any class.')","2babc108":"image_class_dict = {}\nfor i in range(len(all_train_images)):\n    image_class_dict[train_csv['image_id'][i] + '.jpg'] = get_class_name(i)\n    print(train_csv['image_id'][i],'is', get_class_name(i))","90a1f184":"import shutil","0cf73971":"def send_image_to_folder(image_default_path, image_next_path, verbose: bool=False):\n    shutil.copyfile(cur_img_full_path, image_next_path)\n    if verbose:\n        print('image (', cur_img_full_path,') was sent to', image_next_path)","73eb4fcb":"for valid_img in valid_images:\n    cur_img_full_path = image_base_path + valid_img\n    new_path = image_direction_valid_path + image_class_dict[valid_img] + '\/'+ valid_img\n    send_image_to_folder(cur_img_full_path, new_path, True)","2615efcf":"for train_img in train_images:\n    cur_img_full_path = image_base_path + train_img\n    new_path = image_direction_train_path + image_class_dict[train_img] + '\/'+ train_img\n    send_image_to_folder(cur_img_full_path, new_path, True)","c9414d80":"for test_img in test_images:\n    cur_img_full_path = image_base_path + test_img\n    new_path = image_direction_test_path + test_img\n    send_image_to_folder(cur_img_full_path, new_path, True)","b3700007":"num_of_files_in_class_folders = sum([len(os.listdir(image_direction_train_path + class_name)) for class_name in class_names])\nif num_of_files_in_class_folders == len(train_images):\n    okprint('correctly sent all the images to the folders')\nelse:\n    errprint('error while sending images to the class folders!')\nnum_of_files_in_class_folders = len(os.listdir(image_direction_test_path))\nif num_of_files_in_class_folders == len(test_images):\n    okprint('correctly sent all the images to test folder')\nelse:\n    errprint('error while sending images to the test folder!')","9c91a835":"import tensorflow as tf","d03dd81e":"import cv2\nimport matplotlib.pyplot as plt","f4988daa":"### if you want to get an image size\n#for class_name in class_names:\n#    for img in os.listdir(image_direction_train_path + class_name):\n#        print(cv2.imread(image_direction_train_path + class_name + '\/' + img).shape)","0ea75f82":"wanted_shape = (256, 256)\nimage_shape = wanted_shape +(3,)\nnum_of_classes = len(class_names)","f06ca12f":"for img_name in train_images[350:360]:\n    img_class = image_class_dict[img_name]\n    new_img = cv2.resize(cv2.imread(r'\/kaggle\/working\/train\/' + img_class + '\/' + img_name), wanted_shape)\n    plt.imshow(new_img, label=img_class)\n    plt.title(img_class)\n    plt.show()","298145d0":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                                rotation_range=180,\n                                                                width_shift_range=0.2,\n                                                                height_shift_range=0.2,\n                                                                shear_range=0.2,\n                                                                zoom_range=0.2,\n                                                                horizontal_flip=True,\n                                                                vertical_flip=True,\n                                                                fill_mode='nearest')\ntrain_generator = train_datagen.flow_from_directory(image_direction_train_path,\n                                                    target_size=wanted_shape,\n                                                    class_mode='categorical')","69c217c2":"validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                                rotation_range=180,\n                                                                width_shift_range=0.2,\n                                                                height_shift_range=0.2,\n                                                                shear_range=0.2,\n                                                                zoom_range=0.2,\n                                                                horizontal_flip=True,\n                                                                vertical_flip=True,\n                                                                fill_mode='nearest')\n\nvalidation_generator = validation_datagen.flow_from_directory(image_direction_valid_path,\n                                                    target_size=wanted_shape,\n                                                    class_mode='categorical')","8c4e7cb6":"learning_rate = 0.01 #0.0006","0d7ea6a2":"plant_pathology_model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=image_shape),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Dropout(0.1),\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', strides=2),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(num_of_classes, activation='softmax')\n    ])\n\nplant_pathology_model.compile(optimizer=tf.keras.optimizers.Adam(), \n                              loss='categorical_crossentropy',metrics='acc')\n\nplant_pathology_hist = plant_pathology_model.fit(train_generator,epochs=50,\n                                                    validation_data=validation_generator,\n                                                    validation_steps=2,\n                                                    verbose=1)\n","24195dc8":"plt.plot(range(len(plant_pathology_hist.history['acc'])), plant_pathology_hist.history['acc'], color='blue', label='rate='+str(learning_rate))\nplt.plot(range(len(plant_pathology_hist.history['acc'])),plant_pathology_hist.history['val_acc'], '--',color='blue')\nplt.legend()","e626fda7":"from keras.preprocessing import image \nimport numpy as np","b1b40148":"os.chdir('\/kaggle\/input\/')\nprint(os.getcwd())","d5041fc4":"sorted_test_image_names = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')['image_id'][:]","3ba21e3f":"sorted_test_image_names = list(sorted_test_image_names)","0da97e97":"def add_prediction_to_dir(cur_prediction, test_prediction_dir, test_img):\n    test_prediction_dir['image_id'].append(test_img)\n    for i, class_name in enumerate(class_names):\n        test_prediction_dir[class_name].append(cur_prediction[i])","130220fc":"test_prediction_dir = {}\nfor header in header_names:\n    test_prediction_dir[header] = []\nfor test_img in sorted_test_image_names:\n    full_test_img_path = os.path.join(image_direction_test_path, test_img + '.jpg')\n    test_obj_img = image.img_to_array(image.load_img(full_test_img_path, target_size=wanted_shape))\n    test_obj_img = np.expand_dims(test_obj_img, axis=0)\n    img_vector = np.vstack([test_obj_img])\n    cur_prediction = np.round(plant_pathology_model.predict(img_vector)[0])\n    add_prediction_to_dir(cur_prediction, test_prediction_dir, test_img)","bbb38063":"import time","3f1d2da6":"os.chdir('\/kaggle\/working\/')\nos.mkdir('submissions')","fc40b4d1":"os.listdir('\/kaggle\/working\/')","6aa21859":"print(test_prediction_dir['image_id'])","6246b89b":"df = pd.DataFrame(test_prediction_dir, columns=header_names)\nprint(df)\nnew_name = '\/kaggle\/working\/submission.csv'\ndf.to_csv(new_name, index = False, header=True)","246f943c":"new_img = cv2.resize(cv2.imread(r'\/kaggle\/working\/test\/Test_3.jpg'), wanted_shape)\nplt.imshow(new_img, label=img_class)\nplt.title(img_class)\nplt.show()","bbe759cd":"pd.read_csv(new_name).head()","e2264fb2":"pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv').head()","6808b454":"os.listdir('\/kaggle\/working\/')","992a8cbf":"Lets have a look on the preprocessed images","56ee3415":"Lets iterate through the items in the base folder","8ce92ab8":"Lets now create the same folders both in train and test folders","449e08d3":"Lets get the headers","5c6e6654":"Lets do the most important stuff: send images to the appropriate folders (according to the class names)","49c7a7a3":"First we need to define folder names so as to beautify the code of ours.","a3381ea2":"THEEE MOOOST INTERESTING PAAAAAAAAAAAAAART: **TRAAAAINING AAAA MOOOODEL**","904fbee2":"Read train table with appropriate information about training images classes.","d353993a":" Before we begin working with image copying, we need to know what 'class' each image has. So we've already read the csv file with appropriate data (classes etc.) and we only need to create a dictionary (I defently suppose that dictionary is the right way). After we create the dictionary (KEY - image name, VALUE - class_name)","1d29abaa":"We also need a special folder for all the sumbissions","d6af6a27":"Now lets create test and train folders","00a47629":"Check the number of loaded images","122a7aa2":"Lets import time so as to have different submissions.","d373dbcc":"As we've got the columns, we are ready to connect the data from \\images folder with the data in the given table.\n\nFirst lets go into the working directory so as to create test and training folders.","7651d689":"Lets predict images from the test folder"}}