{"cell_type":{"bf33b85f":"code","89cf93d1":"code","6a311a1e":"code","564f49eb":"code","12f04f21":"code","f2f1c6ed":"code","f54542ef":"code","70979efa":"code","0f1c7877":"code","bba49116":"code","e5c54613":"code","4abbbcac":"code","688ea75e":"code","4e644f3f":"code","31c93b18":"code","b3c84ffe":"code","bc935fc1":"code","6288dcf7":"code","594bfc25":"code","5ddd0c6f":"code","f0f84ded":"code","e92d106f":"code","c4bdb6fc":"markdown","5c9088de":"markdown","05fdef98":"markdown","0fe57c0d":"markdown","c3c12ed7":"markdown","94158b89":"markdown","1868e886":"markdown","9afc6ec1":"markdown","56337cfa":"markdown"},"source":{"bf33b85f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport gc\nimport time\nfrom contextlib import contextmanager\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom bayes_opt import BayesianOptimization\nfrom lightgbm import LGBMClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport pickle\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","89cf93d1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6a311a1e":"df = pd.read_csv(\"..\/input\/dfcsv\/df.csv\")","564f49eb":"df_model = df[df['TARGET'].notnull()]\nfeats = [f for f in df_model.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\ntrain_x, test_x, train_y, test_y = train_test_split(df_model[feats], df_model['TARGET'], random_state=42)\n\ndf_submission = df.loc[df['TARGET'].isnull(), feats]\nmain_id_submission =df.loc[df['TARGET'].isnull(), 'SK_ID_CURR']\ndel df","12f04f21":"DEBUG = False","f2f1c6ed":"ITER = 1\nSCORES = []\nMINUTES = time.time()\n\nif DEBUG == True:\n    init_pt = 1\n    n_iter_pt = 2\n    PT_GRAPH = 3\nelse:\n    init_pt = 10\n    n_iter_pt = 100  \n    PT_GRAPH = 10\n    \ndef lgb_evaluate(                \n                numLeaves,\n                maxDepth,\n                minChildWeight,\n                subsample,\n                colsample_bytree,\n                learn_rate,\n                reg_alpha,\n                reg_lambda,          \n                min_split_gain):\n    global ITER, SCORES, MINUTES\n    \n    clf = LGBMClassifier(\n        nthread=4,\n        n_estimators=100,\n        verbose =-1,       \n        silent=-1,        \n        num_leaves= int(numLeaves), \n        max_depth= int(maxDepth), \n        min_child_weight= minChildWeight,\n        colsample_bytree= colsample_bytree,\n        subsample= subsample,\n        learning_rate= learn_rate,\n        reg_alpha = reg_alpha,\n        reg_lambda= reg_lambda, \n        min_split_gain= min_split_gain\n    )\n    scores = cross_val_score(clf, train_x, train_y, cv=5, scoring='roc_auc')\n    \n    print(\"Mean cross validation score: {}\".format(np.mean(scores)))\n    SCORES.append(np.mean(scores))\n    if ITER % PT_GRAPH == 0:\n        plt.figure(figsize=(11,4))\n        plt.plot(range(len(SCORES)), SCORES)\n        plt.scatter(SCORES.index(max(SCORES)), max(SCORES), color='red')\n        plt.ylabel(\"Score\")\n        plt.xlabel(\"Attempt\")\n        plt.title(\"Real time evolution of the mean score\")\n        plt.show()\n        print(\"Minutes since beginning: {}\".format(float(time.time() - MINUTES) \/ 60))\n    ITER = ITER + 1    \n\n    return np.mean(scores)\n\nlgbBO = BayesianOptimization(lgb_evaluate, {                                                \n                                            'numLeaves':  (5, 50),\n                                            'maxDepth': (2, 63),\n                                            'minChildWeight': (0.01, 70),\n                                            'subsample': (0.4, 1),                                                \n                                            'colsample_bytree': (0.4, 1),\n                                            'learn_rate': (0.1, 1),\n                                            'reg_alpha': (0, 1),\n                                            'reg_lambda': (0, 1),          \n                                            'min_split_gain': (0, 1)\n                                        })\n\nlgbBO.maximize(init_points=init_pt, n_iter=n_iter_pt)","f54542ef":"best = max([lgbBO.res[i]['target'] for i in range(len(lgbBO.res))])\nbest","70979efa":"best_index = [lgbBO.res[i]['target'] for i in range(len(lgbBO.res))].index(best)\nbest_index","0f1c7877":"lgbBO.res[best_index]","bba49116":"# LightGBM parameters found by Bayesian optimization\nparam_dict = lgbBO.res[best_index][\"params\"]\n\nclf = LGBMClassifier(\n    nthread=4,\n    n_estimators=100,\n    silent=-1,\n    verbose=-1, \n    num_leaves=34,\n    colsample_bytree=param_dict[\"colsample_bytree\"], \n    subsample=param_dict[\"subsample\"], \n    max_depth=int(param_dict[\"maxDepth\"]), \n    min_child_weight=param_dict[\"minChildWeight\"], \n    learning_rate=param_dict[\"learn_rate\"], \n    reg_alpha=param_dict[\"reg_alpha\"], \n    reg_lambda=param_dict[\"reg_lambda\"],\n    min_split_gain=param_dict[\"min_split_gain\"]) \n\nclf.fit(train_x, train_y)","e5c54613":"y_pred_proba = clf.predict_proba(test_x)[:, 1]\n[fpr, tpr, thr] = metrics.roc_curve(test_y, y_pred_proba)\nplt.plot(fpr, tpr, color='coral', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1 - specificite', fontsize=14)\nplt.ylabel('Sensibilite', fontsize=14)\nplt.show()","4abbbcac":"print(metrics.auc(fpr, tpr))","688ea75e":"def display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.show()","4e644f3f":"importance_df = pd.DataFrame()\nimportance_df[\"feature\"] = feats\nimportance_df[\"importance\"] = clf.feature_importances_\nimportance_df = importance_df.sort_values(by='importance', ascending=False)\nimportance_df = importance_df.reset_index(drop=True)","31c93b18":"display_importances(importance_df)","b3c84ffe":"best_feature = importance_df.loc[0:30, \"feature\"].values","bc935fc1":"plt.figure(figsize=(12,8))\nax = sns.heatmap(train_x[best_feature].corr())\nplt.show()","6288dcf7":"values_x = pd.concat([train_x, test_x])\nvalues_y = pd.concat([train_y, test_y])","594bfc25":"# LightGBM parameters found by Bayesian optimization\nparam_dict = lgbBO.res[best_index][\"params\"]\n\nclf = LGBMClassifier(\n    nthread=4,\n    n_estimators=100,\n    silent=-1,\n    verbose=-1, \n    num_leaves=34,\n    colsample_bytree=param_dict[\"colsample_bytree\"], \n    subsample=param_dict[\"subsample\"], \n    max_depth=int(param_dict[\"maxDepth\"]), \n    min_child_weight=param_dict[\"minChildWeight\"], \n    learning_rate=param_dict[\"learn_rate\"], \n    reg_alpha=param_dict[\"reg_alpha\"], \n    reg_lambda=param_dict[\"reg_lambda\"],\n    min_split_gain=param_dict[\"min_split_gain\"]) \n\nclf.fit(values_x, values_y)","5ddd0c6f":"filename = 'clf.sav'\npickle.dump(clf, open(filename, 'wb'))","f0f84ded":"y_pred_proba = clf.predict_proba(df_submission)[:, 1]\ndf_results = pd.DataFrame(columns =['SK_ID_CURR', 'TARGET'])\ndf_results['SK_ID_CURR'] = main_id_submission\ndf_results['TARGET'] = y_pred_proba","e92d106f":"df_results.to_csv(\"submission.csv\", index=False)","c4bdb6fc":"<a id=\"section-3\"><\/a>\n# Last run for submission","5c9088de":"<a id=\"subsection-12\"><\/a>\n## LightGBM","05fdef98":"<a id=\"section-2\"><\/a>\n# Results","0fe57c0d":"<a id=\"subsection-21\"><\/a>\n## Errors ROC","c3c12ed7":"<a id=\"subsection-22\"><\/a>\n## Feature importance","94158b89":"<a id=\"subsection-11\"><\/a>\n## Bayesian Optimization","1868e886":"<h1 id=\"tocheading\">Table of Contents<\/h1>\n<div id=\"toc\"><\/div>\n1. [Predictive model LightGBM](#section-1)\n  1. [Bayesian Optimization](#subsection-11)\n  1. [LightGBM](#subsection-12)\n1. [Results](#section-2)\n  1. [Errors ROC](#subsection-12)\n  1. [Feature importance](#subsection-13)\n  1. [Feature correlations](#subsection-14)\n1. [Last run for submission](#section-3)","9afc6ec1":"<a id=\"section-1\"><\/a>\n# Predictive model LightGBM","56337cfa":"<a id=\"subsection-23\"><\/a>\n## Feature correlations"}}