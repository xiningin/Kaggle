{"cell_type":{"e58e058d":"code","0d88e11f":"code","efb501f5":"code","273d7437":"code","42ce4081":"code","8054f15d":"code","67abe479":"code","abf52646":"code","b8066018":"code","58f8f252":"code","41c3f149":"code","18d3e93c":"code","dbc9508e":"code","9a125d1e":"code","3ffec129":"code","e4e4f1a0":"code","34f29951":"code","4ded9fc3":"code","1532656e":"code","6158eb09":"code","84dc7ceb":"code","868dd2ff":"code","84869103":"code","c090a5c7":"code","e76e2082":"code","7387976f":"code","d3596688":"code","27186dfb":"code","030dbb21":"code","b2817923":"code","5741b745":"markdown","87cc5c59":"markdown","74e4d6b4":"markdown","82f8a70e":"markdown","8472631a":"markdown","b36051d8":"markdown","0589ad52":"markdown","67e9e1c3":"markdown","caabee78":"markdown","51f7dc8f":"markdown","d4eb9172":"markdown","a4c348b6":"markdown","2fe07328":"markdown","7a8b2abc":"markdown","dc40b9df":"markdown","69c9d3ad":"markdown","f8cc88dd":"markdown","edf2068c":"markdown","aefad602":"markdown","5d4db627":"markdown","bab117a9":"markdown","5ffa3311":"markdown","aba88a55":"markdown","74be9787":"markdown","2fcc1acd":"markdown","d1b58976":"markdown","640b4fcc":"markdown","89cf7295":"markdown","bceda5b4":"markdown","97dce1b2":"markdown","918e55f3":"markdown","46fdfa89":"markdown","b9a7f576":"markdown","caefaab4":"markdown","2d3fa1fd":"markdown","b6ba2b25":"markdown"},"source":{"e58e058d":"# we are biginners, just move on\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","0d88e11f":"# biring the data\n\ndf_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\n","efb501f5":"# check the columns\n\ndf_train.columns","273d7437":"# check 5 data\n\ndf_train.head()","42ce4081":"# lets see our purpose 'SalePrice'\ndf_train['SalePrice'].describe()","8054f15d":"#histogram\n\nsns.distplot(df_train['SalePrice']);","67abe479":"print(\"Skewness : %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis : %f\" % df_train['SalePrice'].kurt())","abf52646":"# scatter plot grlivarea\/saleprice\n \ndata = pd.concat([df_train['SalePrice'], df_train['GrLivArea']], axis=1)\ndata.plot.scatter('GrLivArea','SalePrice',ylim=(0,800000));","b8066018":"# scatter plot totalbsmtsf\/saleprice\n \ndata = pd.concat([df_train['SalePrice'], df_train['TotalBsmtSF']], axis=1)\ndata.plot.scatter('TotalBsmtSF','SalePrice',ylim=(0,800000));","58f8f252":"# box plot overallqual\/saleprice\n\ndata = pd.concat([df_train['SalePrice'], df_train['OverallQual']], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);","41c3f149":"# box plot yearbuilt\/saleprice\n\ndata = pd.concat([df_train['SalePrice'], df_train['YearBuilt']], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x='YearBuilt', y=\"SalePrice\", data=data)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","18d3e93c":"# correlation matrix\n\ncorrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat,vmax=.8,square=True);","dbc9508e":"#saleprice correlation matrix\n\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","9a125d1e":"#scatterplot\nsns.set()\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","3ffec129":"# missing data\n\ntotal =df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'])\nmissing_data.head(20)\n","e4e4f1a0":"# delete missing data\n\ndf_train = df_train.drop((missing_data[missing_data['Total'] > 1]).index,1)\ndf_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_train.isnull().sum().max()","34f29951":"# standardizing- converting data values to have mean of 0 and a standard deviation of 1.\n\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","4ded9fc3":"#bivariate analysis saleprice\/grlivarea\nvar = 'GrLivArea'\ndata = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));","1532656e":"#histogram and normal probability plot\n\nsns.distplot(df_train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","6158eb09":"# applying log transformation\n\ndf_train['SalePrice'] = np.log(df_train['SalePrice'])","84dc7ceb":"# transformed histogram and normal probablility plot\n\nsns.distplot(df_train['SalePrice'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'],plot=plt)","868dd2ff":"#histogram and normal probability plot\n\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","84869103":"#data transformation\n\ndf_train['GrLivArea'] = np.log(df_train['GrLivArea'])","c090a5c7":"#transformed histogram and normal probability plot\n\nsns.distplot(df_train['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['GrLivArea'], plot=plt)","e76e2082":"#histogram and normal probability plot\n\nsns.distplot(df_train['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","7387976f":"#create column for new variable (one is enough because it's a binary categorical feature)\n#if area>0 it gets 1, for area==0 it gets 0\n\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","d3596688":"#transform data\n\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","27186dfb":"#histogram and normal probability plot\n\nsns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)","030dbb21":"#scatter plot\n\nplt.scatter(df_train['GrLivArea'], df_train['SalePrice']);","b2817923":"#scatter plot\nplt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]['SalePrice']);","5741b745":"we can find out that 'SalePrice' and 'TotalBsmtSF' are linear relationship as well","87cc5c59":"we can find out that 'SalePrice' and 'GrLivArea' are linear relationship","74e4d6b4":"In this figure we can see the dots drawing a linear line, which almost acts like a border","82f8a70e":"# Data Exploration\n<hr>\n\n![121.png](attachment:121.png)\n* **Exploratory Data Analysis(EDA)** \n  \n  : understanding what is in a dataset and the characteristics of the data, rather than through traditional data management systems\n\n<hr>\n\n\nHow to use this notebook :\n\nThere is only minimum explanation\n\nThis notebook could be helpful for who want to see how code works right away\n\nPlease upvote if it was helpful.! \n\n\n<hr>\n\n## Content\n1. [Import libraries](#one)\n2. [Check our data](#two)\n3. [Preprocessing](#three)","8472631a":"we can find out from here\n\n* We can not use log transformation to here\n* A significant number of observations with value zero \n*  Positive skewness, log transformations usually works well\n\nTo apply a log transformation here, we'll create a variable that can get the effect of having or not having basement (binary variable). Then, we'll do a log transformation to all the non-zero observations, ignoring those with value zero. This way we can transform data, without losing the effect of having or not basement.\n\nI'm not sure if this approach is correct. It just seemed right to me. That's what I call 'high risk engineering","b36051d8":"we can find out from here\n\n* 'GrLivArea' is not normal. It shows 'peakedness', positive skewness and does not follow the diagonal line\n*  Positive skewness, log transformations usually works well","0589ad52":"<hr>\n\n## 2.1 Type\n\nWe have to know data type about our data\n\nThere are two possible data type \n\n* **Categorical** : values are categories\n\n  1. Norminal Data : even if value is changed, we dont know it is good or not\n  2. Ordinal Data : if value is changed, we can know it is good or not\n\n\n\n* **Numerical** : values are numbers\n\n  1. Discrete Data  : decimal representation is possible\n  2. Continuous Data : decimal representation is impossible","67e9e1c3":"Next","caabee78":"<hr>\n\n### Univariate analysis","51f7dc8f":"we can find out that overallqual is high then saleprice is high too","d4eb9172":"<hr>\n\n## 2.4 In summary\n\n* **Feature Selection** : choice of the right features\n\n* **Feature Engineering** : make simple definition of features\n\n\n* 'GrLivArea' and 'TotalBsmtSF' seem to be linearly related with 'SalePrice'. Both relationships are positive, which means that as one variable increases, the other also increases. In the case of 'TotalBsmtSF', we can see that the slope of the linear relationship is particularly high.\n\n* 'OverallQual' and 'YearBuilt' also seem to be related with 'SalePrice'. The relationship seems to be stronger in the case of 'OverallQual', where the box plot shows how sales prices increase with the overall quality.\n\nWe just analysed four features with subjective approaching\n\n* choose features with owner mind\n\nAs an engineer, we have to deal with objective approaching\n\n* Correlation matrix (heatmap style).\n* SalePrice correlation matrix (zoomed heatmap style).\n* Scatter plots between the most correlated variables (move like Jagger style).\n\n\n","a4c348b6":"There are few ways for missing data\n\n* More than 15%, we delete\n* Fill missing data with mean value\n* Fill missing data with min value\n* Fill missing data with max value","2fe07328":"not a strong tendency, but usually new builted houses seem to be more expensive","7a8b2abc":"we can find out that 'OverallQual', 'GrLivArea' are strongly correlated with 'SalePrice' ","dc40b9df":"<hr>\n\n## 3.1 Missing data\n\nImportant questions when thinking about missing data:\n\n* How prevalent is the missing data?\n* Is missing data random or does it have a pattern?","69c9d3ad":"we can find out from here\n\n* The two values with bigger 'GrLivArea' seem strange \n* High range values are far from 0 and the 7.something values are really out of range","f8cc88dd":"we can find out that data deviate from the normal distribution\n\nlets see skewness, kurtosis\n\n* **skewness** : balance between left and right of distribution\n\n* **kurtosis** : balance between up and down of distribution","edf2068c":"<hr>\n\n### Bivariate analysis","aefad602":"<hr>\n\n## 3.2 Outliar\n\nOutliers can markedly affect our models\n\nWe will find out outliers with 2-ways\n\n* **Univariate analysis** : analysis only one variable\n* **Bivariate analysis** : analysis of two variables","5d4db627":"We can find out from here\n\n* The current scatter plot doesn't have a conic shape anymore. That's the power of normality! Just by ensuring normality in some variables, we solved the homoscedasticity problem\n\nNow let's check 'SalePrice' with 'TotalBsmtSF'","bab117a9":"<hr>\n\n## 2.6 'SalePrice' correlation matrix (zoomed heatmap style)","5ffa3311":"we can find out from here\n\n* Low range values are similar and not too far from 0\n* High range values are far from 0 and the 7 (something values are really out of range)","aba88a55":"In my opinion, this heatmap is the best way to get a quick overview\n\nThis is very useful for features selection","74be9787":"<hr>\n\n## 2.3 Relationship with categorical features\n","2fcc1acd":"<a id=\"one\"><\/a>\n\n# 1. Import libraries\n\n<hr>","d1b58976":"\nDone! Let's check what's going on with 'GrLivArea'\n\n","640b4fcc":"<hr>\n\n## 3.3 Normalty\n\n\nNormality what we mean is that the data should look like a normal distribution\n\nThis is important because several statistic tests rely on this\n\n* **Histogram** - Kurtosis and skewness\n* **Normal probability plot** - Data distribution should closely follow the diagonal that represents the normal distribution.","89cf7295":"<hr>\n\n## 3.4 Homoscedasticity\n\nThe best approach to test homoscedasticity for two metric variables is graphically\n\nStarting by 'SalePrice' and 'GrLivArea'...","bceda5b4":"<a id=\"three\"><\/a>\n\n# 3.Preprocessing\n\n* **Preprocessing :** used in machine learning and data mining to make input data easier to work with","97dce1b2":"<hr>\n\n## 2.7 Scatter plots between 'SalePrice' and correlated variables ","918e55f3":"we can find out from here\n\n* 'SalePrice' is not normal. It shows 'peakedness', positive skewness and does not follow the diagonal line\n*  Positive skewness, log transformations usually works well","46fdfa89":"## 2.2 Relationship with numerical features\n\n<hr>","b9a7f576":"## Referneces\n\n[Comprehensive data exploration with Python](https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python#Out-liars!)","caefaab4":"<a id=\"two\"><\/a>\n\n# 2.Check our data\n\n<hr>","2d3fa1fd":"<hr>\n\n## 2.5 Correlation matrix (heatmap style)","b6ba2b25":"We can find out from here\n\n* We can say that, in general, 'SalePrice' exhibit equal levels of variance across the range of 'TotalBsmtSF"}}