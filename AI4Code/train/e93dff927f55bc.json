{"cell_type":{"8c75d9ff":"code","75f22808":"code","f59b7109":"code","8929e7c8":"code","4cb78ca0":"code","ae168e26":"code","30eaef69":"code","e9a80056":"code","dd31964b":"code","8a46a643":"code","0bb6d635":"code","01edacdd":"code","d41202d0":"code","94284313":"code","fde85ec1":"code","20f23353":"code","c050bc76":"code","1643f148":"code","468e4d11":"code","868d5106":"code","e4146c09":"code","3f3685a0":"code","57ae1eb5":"code","1b4b5880":"code","0a28da12":"markdown","bd6eb28e":"markdown","8d0c62a7":"markdown","eafed5e3":"markdown","9d7e95f7":"markdown","93a7474a":"markdown","561b29e6":"markdown","dd356513":"markdown","ceb2b64d":"markdown"},"source":{"8c75d9ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75f22808":"import torch\nimport torchvision\nfrom torchvision.utils import make_grid\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import FashionMNIST\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nfrom torchvision.transforms import ToTensor\nimport torch.nn as nn\nimport torch.nn.functional as F\n%matplotlib inline","f59b7109":"dataset = FashionMNIST(root='data\/', download=True, transform = ToTensor())\ntest = FashionMNIST(root='data\/', train=False, transform = ToTensor())","8929e7c8":"print(len(dataset))\nval_size = 10000\ntrain_size = 50000\ntrain_ds, valid_ds = random_split(dataset, [train_size, val_size])\nprint(len(train_ds), len(valid_ds))","4cb78ca0":"batch_size = 128\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size*2, shuffle=False, num_workers=4, pin_memory=True)\ntest_dl = DataLoader(test, batch_size*2, num_workers=4, pin_memory=True)\nfor images,_ in train_dl:\n    print(\"image_size: \", images.shape)\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute(1,2,0))\n    break\n    ","ae168e26":"def accuracy(output, labels):\n    _, preds = torch.max(output, dim=1)\n    return torch.tensor(torch.sum(preds==labels).item()\/ len(preds))\n    ","30eaef69":"class MNISTModel(nn.Module):\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        ## Hidden Layer\n        self.linear1 = nn.Linear(in_size, 16)\n        self.linear2 = nn.Linear(16, 32)\n        self.linear3 = nn.Linear(32, out_size)\n        \n    def forward(self, xb):\n        out = xb.view(xb.size(0), -1)\n        ## First layer\n        out = self.linear1(out)\n        out = F.relu(out)\n        ## Second Layer\n        out = self.linear2(out)\n        out = F.relu(out)\n        ## Third Layer\n        out = self.linear3(out)\n        out = F.relu(out)\n        return out\n    \n    def training_step(self, batch):\n        image, label = batch\n        out = self(image)\n        loss = F.cross_entropy(out, label)\n        return loss\n    \n    def validation_step(self, batch):\n        image, label = batch\n        out = self(image)\n        loss = F.cross_entropy(out, label)\n        acc = accuracy(out, label)\n        return {'val_loss': loss, 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        losses = [loss['val_loss'] for loss in outputs]\n        epoch_loss = torch.stack(losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))","e9a80056":"torch.cuda.is_available()","dd31964b":"def find_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n","8a46a643":"device = find_device()\ndevice","0bb6d635":"def to_device(data, device):\n    if isinstance(data, (tuple, list)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","01edacdd":"class DeviceLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b, self.device)\n    \n    def __len__(self):\n        return len(self.dl)","d41202d0":"train_loader = DeviceLoader(train_dl, device)\nvalid_loader = DeviceLoader(valid_dl, device)\ntest_loader = DeviceLoader(test_dl, device)","94284313":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","fde85ec1":"input_size = 784\nnum_classes = 10","20f23353":"model = MNISTModel(input_size, out_size=num_classes)\nto_device(model, device)","c050bc76":"history = [evaluate(model, valid_loader)]\nhistory","1643f148":"history += fit(5, 0.5, model, train_loader, valid_loader)\n","468e4d11":"losses = [x['val_loss'] for x in history]\nplt.plot(losses, '-x')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('Loss vs. No. of epochs');","868d5106":"def predict_image(img, model):\n    xb = to_device(img.unsqueeze(0), device)\n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1)\n    return preds[0].item()","e4146c09":"img, label = test[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', dataset.classes[label], ', Predicted:', dataset.classes[predict_image(img, model)])","3f3685a0":"evaluate(model, test_loader)\n","57ae1eb5":"saved_weights_fname='fashion-feedforward.pth'\n","1b4b5880":"torch.save(model.state_dict(), saved_weights_fname)\n","0a28da12":"Converting data to device","bd6eb28e":"# Prediction on Samples","8d0c62a7":"### Here we are going to do Deep learning for FashionMnist dataset with Pytorch.\n## Let's import the required libraries","eafed5e3":"### Loading data for training using Dataloader and Also plotting the data using make_grid function and also using permute to rearrange the images shape. Because pytorch image shape is like(1, 28, 28) but for matplot lib it expects the shape to be (28,28,1)","9d7e95f7":"## Defining accuracy","93a7474a":"# Fitting model","561b29e6":"## Connecting to GPU","dd356513":"## Train Model","ceb2b64d":"### Downloading dataset from torchvision API and transform it to pytorch tensor[](http:\/\/)"}}