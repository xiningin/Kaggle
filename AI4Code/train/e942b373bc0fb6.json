{"cell_type":{"f4d22274":"code","03b7d7de":"code","c990f2a7":"code","8872fe10":"code","00f3a9e9":"code","533a5ca0":"code","4f4c1c8d":"code","8612f73b":"code","9004446a":"code","3b82ddb4":"code","4a3bd2ee":"code","d5a66210":"code","295a783b":"code","2c3b7d36":"code","fd4dea7f":"code","494efc52":"code","7726cd45":"code","08757a29":"code","edd3a9ee":"code","49966e02":"code","06b8d001":"code","d0888c42":"code","95c522fc":"code","27f20526":"code","ad76a797":"code","7acd95d5":"code","27bc9e7b":"code","37263f52":"markdown","1686eda1":"markdown","041a8549":"markdown","7365a6ba":"markdown","2a634548":"markdown","54715c58":"markdown","f07c2051":"markdown","b33b6662":"markdown","49b9cedc":"markdown","5c468cb2":"markdown","8daf146f":"markdown","dc410cfa":"markdown","342d3eda":"markdown","f6ded652":"markdown","6c8d1c3f":"markdown","ed32c121":"markdown","d87c93bf":"markdown","c8612e4b":"markdown","52af924c":"markdown","1347c88e":"markdown","e31659d4":"markdown","7bb1aad1":"markdown","c7b757c0":"markdown","9c2aef10":"markdown"},"source":{"f4d22274":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.express as px\n\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom wordcloud import WordCloud\n\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03b7d7de":"data = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")","c990f2a7":"data.head()","8872fe10":"data.shape","00f3a9e9":"data.info()","533a5ca0":"data.describe(include= \"all\")","4f4c1c8d":"data.columns","8612f73b":"data.diagnosis.value_counts()","9004446a":"colors = [\"red\", \"green\"]\nsns.barplot(x = data.diagnosis.unique(),y = data.diagnosis.value_counts(),palette= colors)\nplt.xlabel(\"type of cancer cell\")\nplt.title(\"Counts of M and B Cancer Cell\")\nplt.show()","3b82ddb4":"data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\nprint(data.diagnosis.values)","4a3bd2ee":"labels = data.diagnosis.value_counts().index\ncolors = ['red','green']\nexplode = [0,0]\nsizes = data.diagnosis.value_counts().values\n\n# visual\nplt.figure(figsize = (7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%')\nplt.title('Percentage of Diagnosis Cancers',color = 'blue',fontsize = 15)\nplt.show()","d5a66210":"data.isnull().sum().values","295a783b":"import missingno as msno\nmsno.bar(data)\nplt.show()","2c3b7d36":"data.drop([\"id\",\"Unnamed: 32\"],axis=1, inplace = True)","fd4dea7f":"corr = data.corr().diagnosis\ncorr[np.argsort(corr, axis=0)[:-1]]","494efc52":"f,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(data.corr(), annot= True, linewidths= 0.3, linecolor= \"red\", fmt= \".0%\", ax= ax, cmap = 'coolwarm')\nplt.show()","7726cd45":"y = data.diagnosis # y is our target values\/ dependent variable\nx = data.drop(columns= \"diagnosis\") # x is undependent variable\n\nfor i in x:  # Distribution and Skewness\n    g = sns.distplot(data[i], color=\"b\", label=\"Skewness : %.2f\"%(data[i].skew()))\n    g = g.legend(loc=\"best\")\n    plt.show()\n","08757a29":"x_ = (x - x.mean()) \/ x.std()  #standardization","edd3a9ee":"x_.describe(include= \"all\")","49966e02":"plt.subplots(figsize=(8,8))\nwordcloud = WordCloud(\n                          background_color='white',\n                          width=512,\n                          height=384\n                         ).generate(\" \".join(data.columns))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.savefig('graph.png')\n\nplt.show()","06b8d001":"mean_data = pd.concat([y,x_.iloc[:,0:10]],axis=1)\nmean_data = pd.melt(mean_data,id_vars=\"diagnosis\", var_name=\"features\", value_name='value')\n\nse_data = pd.concat([y,x_.iloc[:,10:20]],axis=1)\nse_data = pd.melt(se_data,id_vars=\"diagnosis\", var_name=\"features\", value_name='value')\n\nworst_data = pd.concat([y,x_.iloc[:,20:30]],axis=1)\nworst_data = pd.melt(worst_data,id_vars=\"diagnosis\", var_name=\"features\", value_name='value')","d0888c42":"plt.figure(figsize=(10,10))\nsns.violinplot(x =\"features\", y =\"value\", hue =\"diagnosis\",palette = colors, data = mean_data, split = True, inner = \"quart\")\nplt.xticks(rotation=90)","95c522fc":"plt.figure(figsize=(10,10))\nsns.boxplot(x =\"features\", y =\"value\", hue =\"diagnosis\", data = se_data, palette = colors)\nplt.xticks(rotation=90)","27f20526":"plt.figure(figsize=(10,10))\nsns.swarmplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data= worst_data, palette = colors)\nplt.xticks(rotation=90)","ad76a797":"mean_data = pd.concat([y,x_.iloc[:,0:10]],axis=1)\nsns.pairplot(mean_data, hue = \"diagnosis\", palette = colors)\nplt.show()","7acd95d5":"se_data = pd.concat([y,x_.iloc[:,10:20]],axis=1)\nsns.pairplot(se_data, hue = \"diagnosis\", palette = colors)\nplt.show()","27bc9e7b":"worst_data = pd.concat([y,x_.iloc[:,10:20]],axis=1)\nsns.pairplot(worst_data, hue = \"diagnosis\", palette = colors)\nplt.show()","37263f52":"#### mean near zero, std is one\n#### our dataset is ready, we can begin visulation and analysis after categorising","1686eda1":"#### As we can see, our dataset has 3 categoriel features. We have mean, se and worst categories. So we will divide 3 categories all of features. \n#### The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n   * #### mean_data = radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave points_mean, symmetry_mean, fractal_dimension_mean\n   * #### se_data = radius_se, texture_se, perimeter_se, area_se, smoothness_se, compactness_se, concavity_se, concave points_se, symmetry_se, fractal_dimension_se\n   * #### worst_data = radius_worst, texture_worst, perimeter_worst, area_worst, smoothness_worst, compactness_worst, concavity_worst, concave points_worst, symmetry_worst, fractal_dimension_worst\n\n#### After categorising, we will add our target values(diagnosis\/ y) in 3 equels","041a8549":"<a id=\"3\"><\/a> \n## 3. Explaining Features and Determine Target Value","7365a6ba":" Diagnosis values are our target values. We have two classes. In this analysis, we will explain which features effect diagnosis values.\n   * M = Malignant is bad news for cancer patient beacuse malignant cell is fatal.\n   * B = Benign is good news for cancer patient because bening cell is not dangerous and do not harm patient.","2a634548":"#### In worst features, we can see what most of melignant cancer cells are dominant in  [-2, 0] range","54715c58":"# INTRODUCTION\n* In this portfolio project, we will anaysis breast cancer dataset and we will try to determine why the cancer cell is melignant or benign.\n    * We downloaded dataset from kaggle website.\n        * https:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data\n        * Our dataset is 49KB and it exists one dataset.\n        * We will use data.csv file and show important results.\n\n## Content:\n1. [Importing Packages and Loading Dataset](#1)\n1. [Describing Dataset](#2)\n1. [Explaining Features and Determine Target Value](#3)\n1. [Missing Analysis and Drop Missing Values](#4)\n1. [Correlation](#5)\n1. [Categorizing and Standardization Data Features](#6)\n1. [Visulation and Analysing](#7)\n1. [Conclusion](#8)","f07c2051":"<a id=\"6\"><\/a> \n## 6. Standardization and Categorizing Data Features","b33b6662":"#### In above table is correlation between our target feature(diagnosis) and other features\n#### As we can see, our most relative features are  compactness, concavity, area, radius, concave points and perimeter (_mean and worst).\n#### Let's look at all correlation between all features","49b9cedc":"#### We have 31 columns. Those features are about cancer cell. We will explain features one by one.\n* 1) ID number\n* 2) Diagnosis (M = malignant, B = benign)\n* 3) Ten real-valued features are computed for each cell nucleus:\n\n   * a) radius (mean of distances from center to points on the perimeter)\n   * b) texture (standard deviation of gray-scale values)\n   * c) perimeter\n   * d) area\n   * e) smoothness (local variation in radius lengths)\n   * f) compactness (perimeter^2 \/ area - 1.0)\n   * g) concavity (severity of concave portions of the contour)\n   * h) concave points (number of concave portions of the contour)\n   * i) symmetry\n   * j) fractal dimension (\"coastline approximation\" - 1)","5c468cb2":"#### As we can see, some of the variables are little skewed. As all the values are below 1.5, we can ommit it.\n#### The other clear conclusion is that the data is not scaled and standarized. We will try to standarized.","8daf146f":"<a id=\"2\"><\/a> \n## 2. Describing Dataset","dc410cfa":"#### Unnamed: 32 column has 569 null values. This column is completly null. So we do not need this columns. ID data has number ID so this column do not effect my target values. We will drop ID and Unnamed: 32 columns and will continue analysis without those dropping values.","342d3eda":"Our data has 33 columns and 569 rows. It has one integer type column, one class type column and 31 float type columns.","f6ded652":"#### In mean features, we can see which most of  melignant cancer cells are dominant in  [-2, 0] range ","6c8d1c3f":"#### We have 357 \"M\" and 212 \"B\" values. Most of analyzes people use 1 and 0 for class values. So we will convert out target values;  \n             M = 1 is cancer cell  and B = 0 is noncancer cell\n\n#### Now, we converted our data 1 and 0 instead of M and B.","ed32c121":"<a id=\"4\"><\/a> \n## 4. Missing Analysis and Drop Missing Values","d87c93bf":"# Analysis of Breast Cancer Wisconsin (Diagnostic) Data Set\n\n### Data Visulation and EDA","c8612e4b":"#### In se features, we can see what most of benign cancer cells are dominant in  [0, 2] range ","52af924c":"#### In a conclusion, we generally have some idea. Our idea about breast cancer dataset:\n   #### between [-2, 0] values are Malignant cancer cell which mean fatal\n   #### between [0, 2] values are Benign cancer cell which mean harmless ","1347c88e":"### In pair plot we can see  multivariate alaysis of all categorise variable. Some plot contradict our previous alaysis and estimates but generally we have some idea about target variable.","e31659d4":"#### This pie chart show us diagnosis of cancers. %62.7 are cancer(1), %37.3 are noncancer(0) amaunt of patients. So nearly 2\/3 all of patients are cancer.","7bb1aad1":"<a id=\"5\"><\/a> \n## 5. Correlation in Data","c7b757c0":"<a id=\"7\"><\/a> \n## 7. Visulation and Analysing","9c2aef10":"<a id=\"8\"><\/a> \n## 8. Conclusion"}}