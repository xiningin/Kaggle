{"cell_type":{"65a9c809":"code","ce5ae52d":"code","0268be3c":"code","45592ddc":"code","7f6f9452":"code","fd297822":"code","e2c9b03b":"code","5d06e491":"code","f61b5eac":"code","b86c72bb":"code","28f943b3":"code","23fc1dcb":"code","42e91869":"code","845c7c03":"code","dfef5d5f":"code","9b25f94e":"code","598820cd":"code","f510712a":"code","fc445107":"code","a062f327":"code","9f2cd90f":"code","6103fbef":"code","0ef2f4e0":"code","65e5f6e6":"code","750a13fa":"code","a4325169":"code","c82ccd61":"code","13d1b9ee":"markdown","511ed2c5":"markdown","e5d89cb4":"markdown","deb2e3ab":"markdown","763ae5e1":"markdown"},"source":{"65a9c809":"import pandas as pd\nimport numpy as np\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","ce5ae52d":"# Read the data\ndf = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\n# Look at a snapshot of data\ndf.head()","0268be3c":"df.shape","45592ddc":"# See the summary stats and frequency distribution of features\ndf.describe()","7f6f9452":"df.isnull().sum()","fd297822":"# Let's see if there is class imbalance in the target variable\nprint (df['Churn'].value_counts(ascending=True))","e2c9b03b":"df['TotalCharges'].replace(to_replace = ' ', value= np.nan, inplace = True)\ndf['TotalCharges'] = df['TotalCharges'].astype(float)\ndf.dropna(axis=0, inplace=True)","5d06e491":"### Remove customerID\ndf.drop(['customerID'], axis = 1, inplace=True)","f61b5eac":"from sklearn.model_selection import train_test_split\n\ny = df['Churn']\nX = df.loc[:, df.columns != 'Churn']\n\nX_train, X_test, y_train, y_test =   train_test_split(X, y, test_size=0.20, random_state=111)\n\nprint(X_train.shape, X_test.shape)","b86c72bb":"# Convert 'SeniorCitizen' column into categorical\nX_train['SeniorCitizen']=pd.Categorical(X_train['SeniorCitizen'])\nX_test['SeniorCitizen']=pd.Categorical(X_test['SeniorCitizen'])","28f943b3":"# Encode target variables to 0, 1\ny_train = y_train.map(dict(Yes=1, No=0))\ny_test = y_test.map(dict(Yes = 1, No=0))\nprint(y_train.shape, y_test.shape)","23fc1dcb":"# Divide the columns into 3 categories, one ofor standardisation, one for label encoding and one for one hot encoding\nnum_cols = [\"tenure\", 'MonthlyCharges', 'TotalCharges']\ncat_cols_ohe =['PaymentMethod', 'Contract', 'InternetService'] # those that need one-hot encoding\ncat_cols_le = list(set(X_train.columns)- set(num_cols) - set(cat_cols_ohe)) #those that need label encoding","42e91869":"from sklearn.preprocessing import StandardScaler\n\nscaler= StandardScaler()\n\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\nX_test[num_cols] = scaler.transform(X_test[num_cols])","845c7c03":"X_train = pd.DataFrame(X_train)\nX_test= pd.DataFrame(X_test)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nle = LabelEncoder()\nohe = OneHotEncoder()\n\nfor col in cat_cols_le:\n    le.fit(X_train[col])\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","dfef5d5f":"print(X_train.shape, X_test.shape)","9b25f94e":"ohe.fit(X_train[cat_cols_ohe])\ntr_cols= ohe.transform(X_train[cat_cols_ohe])\nte_cols = ohe.transform(X_test[cat_cols_ohe])\n\nX_train.drop(columns=cat_cols_ohe, inplace=True)\nX_test.drop(columns=cat_cols_ohe, inplace=True)\n\nX_train = np.hstack((X_train,tr_cols.toarray()))\nX_test = np.hstack((X_test, te_cols.toarray()))\nprint(X_train.shape, X_test.shape)","598820cd":"print(y_train.shape, y_test.shape)","f510712a":"print(y_train.value_counts(), '\\n', y_test.value_counts())","fc445107":"#Importing necessary modules\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom sklearn.model_selection import train_test_split","a062f327":"seed = 0\nnp.random.seed(seed)","9f2cd90f":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\ninput_shape = X_train.shape[1]","6103fbef":"model = Sequential()\nmodel.add(Dense(32, input_dim=input_shape, kernel_initializer='uniform', activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n\nmodel.fit(X_train, y_train,\n              epochs=25,\n          batch_size=24, class_weight={0:0.2, 1:0.8})","0ef2f4e0":"score = model.evaluate(X_test, y_test, batch_size=20)","65e5f6e6":"print(score)\nprint (\"Accuracy : %s\" % \"{0:.3%}\".format(score[1]))","750a13fa":"train_pred_dl=model.predict_classes(X_train)\ntest_pred_dl=model.predict_classes(X_test)","a4325169":"from sklearn import metrics\nmlp_conf_matrix = metrics.confusion_matrix(y_test, test_pred_dl)\nprint (mlp_conf_matrix)","c82ccd61":"accuracy = metrics.accuracy_score(y_test,test_pred_dl)\n    \nprint (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n\n#Print Recall\nrecall = metrics.recall_score(y_test,test_pred_dl)\n    \nprint (\"Recall : %s\" % \"{0:.3%}\".format(recall))","13d1b9ee":"ENCODING ATTRIBUTES","511ed2c5":"Customer Churn Prediction using Artificial Neural Network","e5d89cb4":"ANN MODEL BUILDING","deb2e3ab":"DATA PREPROCESSING","763ae5e1":"Standardizing numeric attributes"}}