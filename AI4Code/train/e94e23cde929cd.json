{"cell_type":{"66d7e943":"code","84a601e3":"code","c896f5fc":"code","70dd6622":"code","01d67d35":"code","ba176408":"code","7d881355":"code","43838cc8":"code","94b0db9d":"code","0a48cda3":"code","52ae13bf":"code","46237a7f":"markdown","56d474bd":"markdown","716228a3":"markdown","9f8dc825":"markdown","4218ed35":"markdown","4e43931b":"markdown","d57e2644":"markdown","fc51113a":"markdown"},"source":{"66d7e943":"import numpy as np\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.metrics import accuracy_score, classification_report","84a601e3":"train_dir = '..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TRAIN'\ntest_dir = '..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST'","c896f5fc":"# Create generators\n\ntrain_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","70dd6622":"# Flow image data\n\ntrain_images = train_gen.flow_from_directory(\n    directory=train_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_gen.flow_from_directory(\n    directory=train_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_gen.flow_from_directory(\n    directory=test_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False,\n    seed=42\n)","01d67d35":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","ba176408":"inputs = pretrained_model.input\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\noutputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(model.summary())","7d881355":"history = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","43838cc8":"fig = px.line(\n    history.history,\n    y=['loss', 'val_loss'],\n    labels={'index': \"Epoch\", 'value': \"Loss\"},\n    title=\"Training and Validation Loss Over Time\"\n)\n\nfig.show()","94b0db9d":"CLASS_NAMES = list(train_images.class_indices.keys())\nCLASS_NAMES","0a48cda3":"predictions = np.argmax(model.predict(test_images), axis=1)\n\nacc = accuracy_score(test_images.labels, predictions)\ncm = tf.math.confusion_matrix(test_images.labels, predictions)\nclr = classification_report(test_images.labels, predictions, target_names=CLASS_NAMES)\n\nprint(\"Test Accuracy: {:.3f}%\".format(acc * 100))\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks= np.arange(4) + 0.5, labels=CLASS_NAMES)\nplt.yticks(ticks= np.arange(4) + 0.5, labels=CLASS_NAMES)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","52ae13bf":"val_images = train_gen.flow_from_directory(\n    directory=train_dir,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False,\n    seed=42,\n    subset='validation'\n)\n\n\npredictions = np.argmax(model.predict(val_images), axis=1)\n\nacc = accuracy_score(val_images.labels, predictions)\ncm = tf.math.confusion_matrix(val_images.labels, predictions)\nclr = classification_report(val_images.labels, predictions, target_names=CLASS_NAMES)\n\nprint(\"Validation Accuracy: {:.3f}%\".format(acc * 100))\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks= np.arange(4) + 0.5, labels=CLASS_NAMES)\nplt.yticks(ticks= np.arange(4) + 0.5, labels=CLASS_NAMES)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","46237a7f":"# Task for Today  \n\n***\n\n## Blood Cell Type Prediction  \n\nGiven *images of blood cells*, let's try to predict the **type of cell** present in a given image.\n\nWe will use a TensorFlow pretrained CNN model to make our predictions.","56d474bd":"# Loading Image Data","716228a3":"# Results","9f8dc825":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/RmTsvLTypIE","4218ed35":"# Training","4e43931b":"# Getting Started","d57e2644":"# Build Classification Model","fc51113a":"# Build Pretrained Model"}}