{"cell_type":{"a274b3af":"code","fef7e5fe":"code","ef00d420":"code","76ad23da":"code","d50ec6e9":"code","1ed25548":"code","58db7ccf":"code","2e5fb70e":"code","71db5d51":"code","f99cb5c9":"code","9a66bde0":"code","e659c318":"code","b5dbf503":"code","64cb8676":"code","6472f684":"code","acaab21f":"code","2e35b7af":"code","e9b46e81":"code","b7f721df":"code","0f92156c":"code","fa731371":"code","e10e69ec":"code","3859f9f8":"markdown","0fccef6f":"markdown"},"source":{"a274b3af":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sys\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport random\nrandom.seed = 42\nnp.random.seed = 42\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","fef7e5fe":"train_path = \"..\/input\/stage1_train\/\"\ntest_path = \"..\/input\/stage1_test\/\"","ef00d420":"train_ids = next(os.walk(train_path))[1]\ntest_ids = next(os.walk(test_path))[1]","76ad23da":"print(\"total subfolders in stage1_train\",len(train_ids))\nprint(\"total subfolders in stage1_test \",len(test_ids))","d50ec6e9":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\ndef openCVdemo(path):\n    img = cv2.imread(path,0)\n    # Otsu's thresholding after Gaussian filtering\n    blur = cv2.GaussianBlur(img,(5,5),0)\n    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    # Plot Here\n    plt.figure(figsize=(15,5))\n    images = [blur, 0, th3]\n    titles = ['Original Image (X_train)','Gaussian filtered Image (OpenCV)',\"Segmened Image (OpenCV)\"]\n    plt.subplot(1,3,1),plt.imshow(img,'gray')\n    plt.title(titles[0]), plt.xticks([]), plt.yticks([])\n    plt.subplot(1,3,2),plt.imshow(images[0],'gray')\n    plt.title(titles[1]), plt.xticks([]), plt.yticks([])\n    plt.subplot(1,3,3),plt.imshow(images[2],'gray')\n    plt.title(titles[2]), plt.xticks([]), plt.yticks([])","1ed25548":"n = random.randint(0,len(train_ids))\npath = train_path+train_ids[n]+\"\/images\/\"+train_ids[n]+\".png\"\nopenCVdemo(path)","58db7ccf":"IMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3","2e5fb70e":"X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)","71db5d51":"from tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nfrom skimage.morphology import label","f99cb5c9":"\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = train_path + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '\/masks\/'))[2]:\n        mask_ = imread(path + '\/masks\/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask\n\n# Get and resize test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = test_path + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')","9a66bde0":"def plotTrainData(a,b):\n    for i in range(5):\n        ix = random.randint(0, len(train_ids))\n        plt.subplot(1,2,1)\n        plt.title(\"X_train\")\n        imshow(a[ix])\n        plt.axis('off')\n        plt.subplot(1,2,2)\n        plt.title(\"Y_train\")\n        imshow(np.squeeze(b[ix]))\n        plt.axis('off')\n        plt.show()\nplotTrainData(X_train,Y_train)","e659c318":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2)\nprint('\\nx_train',x_train.shape)\nprint('x_test',x_test.shape)\nprint('y_train',y_train.shape)\nprint('y_test',y_test.shape)","b5dbf503":"import tensorflow as tf\n# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","64cb8676":"from keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K","6472f684":"# Build U-Net model\ninputs = Input((IMG_WIDTH , IMG_HEIGHT , IMG_CHANNELS))\ns = Lambda(lambda x:x\/255)(inputs)\n#Layer1\nc1 = Conv2D(16,(3,3),activation = \"elu\",kernel_initializer = \"he_normal\",padding=\"same\")(s)\nc1 = Dropout(0.1)(c1)\nc1 = Conv2D(16,(3,3),activation = \"elu\",kernel_initializer = \"he_normal\", padding=\"same\")(c1)\np1 = MaxPooling2D((2,2))(c1)\n\n#Layer2\nc2 = Conv2D(32,(3,3),activation = \"elu\",kernel_initializer = \"he_normal\",padding=\"same\")(p1)\nc2 = Dropout(0.1)(c2)\nc2 = Conv2D(32,(3,3),activation = \"elu\",kernel_initializer = \"he_normal\", padding=\"same\")(c2)\np2 = MaxPooling2D((2,2))(c2)\n\n#Layer3\nc3 = Conv2D(64,(3,3),activation = \"elu\",kernel_initializer = \"he_normal\",padding=\"same\")(p2)\nc3 = Dropout(0.2)(c3)\nc3 = Conv2D(64,(3,3),activation = \"elu\",kernel_initializer = \"he_normal\", padding=\"same\")(c3)\np3 = MaxPooling2D((2,2))(c3)\n\n#layer4\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n#layer5\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","acaab21f":"# Fit model\nearlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n                    callbacks=[earlystopper, checkpointer])","2e35b7af":"# Predict on train, val and test\nmodel = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)\n\n# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in range(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","e9b46e81":"# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train_t))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\nimshow(np.squeeze(preds_train_t[ix]))\nplt.show()","b7f721df":"# Perform a sanity check on some random validation samples\nix = random.randint(0, len(preds_val_t))\nimshow(X_train[int(X_train.shape[0]*0.9):][ix])\nplt.show()\nimshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\nplt.show()\nimshow(np.squeeze(preds_val_t[ix]))\nplt.show()","0f92156c":"# Run-length encoding stolen from https:\/\/www.kaggle.com\/rakhlin\/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)","fa731371":"new_test_ids = []\nrles = []\nfor n, id_ in enumerate(test_ids):\n    rle = list(prob_to_rles(preds_test_upsampled[n]))\n    rles.extend(rle)\n    new_test_ids.extend([id_] * len(rle))","e10e69ec":"# Create submission DataFrame\nsub = pd.DataFrame()\nsub['ImageId'] = new_test_ids\nsub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\nsub.to_csv('sub-dsbowl2018-1.csv', index=False)","3859f9f8":"its a opencv demo to show how images look here we have taken a random image and try to print 3 versions of it A)original image B)by using Gaussian Blr c) by appling Threshold","0fccef6f":"Here we call os module to know all about data and folders in dataset. Os module will let you walk through the doors fo dataset foder"}}