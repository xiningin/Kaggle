{"cell_type":{"92124f8e":"code","9b3c0b68":"code","c343c219":"code","988837f3":"code","b4994676":"code","8de9ca42":"code","915422b7":"code","e08f8389":"code","a934a950":"code","3185dc60":"code","c2be3185":"code","e100d3ae":"code","b5a338db":"code","4fff8810":"code","f4445a7b":"code","8485d219":"code","6a8a7a8c":"code","fae10d2f":"code","9933675b":"code","428bcac8":"code","4c7cad6e":"code","b017ad93":"code","4f4c9d96":"code","cb475e84":"code","1d1aaadc":"code","73f62b1e":"code","37495500":"code","a9f4f02b":"code","5014f825":"code","dd22c35c":"code","b40b1c1c":"code","d7e7eb98":"code","3f18116b":"code","11497827":"code","08c8b204":"code","0dd0a097":"code","a6854066":"code","061275e9":"code","f28ba0fc":"code","62603627":"code","c3b078ad":"code","01cf5361":"code","4e52f290":"code","f2d78029":"code","b92f5afc":"code","559ae187":"code","7cce4eba":"code","536e18ad":"code","627ce754":"code","7bb562d0":"code","ec48da7b":"code","6d1b0ba0":"code","ee01be52":"code","535bc2a6":"code","8af7849f":"markdown","0cc5485f":"markdown","c85ba146":"markdown","63d4612c":"markdown","d255298b":"markdown","b9ed06f1":"markdown","c58ad456":"markdown","d42986c3":"markdown","65b43b27":"markdown","235f5364":"markdown","1c92b641":"markdown","c8154dd7":"markdown","fc67a674":"markdown","92cd71fb":"markdown","c91755f7":"markdown","0148e5e7":"markdown","54e284af":"markdown","6bf6caf5":"markdown","8ba3b079":"markdown","d86be0a0":"markdown","9f9f467e":"markdown"},"source":{"92124f8e":"# import packages\nimport gc\nimport os\nimport subprocess\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport featuretools as ft\nimport lightgbm as lgb\nfrom lightgbm import plot_tree\nfrom graphviz import Digraph\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold,GroupKFold\nfrom sklearn.metrics import roc_auc_score,mean_squared_error\nimport time\nimport pickle\n\n%matplotlib inline","9b3c0b68":"def check_fline(fpath):\n    \"\"\"check total number of lines of file for large files\n    \n    Args:\n    fpath: string. file path\n    \n    Returns:\n    None\n    \n    \"\"\"\n    lines = subprocess.run(['wc', '-l', fpath], stdout=subprocess.PIPE).stdout.decode('utf-8')\n    print(lines, end='', flush=True)","c343c219":"fs=['..\/input\/ashrae-energy-prediction\/train.csv', \n    '..\/input\/ashrae-energy-prediction\/test.csv', \n    '..\/input\/ashrae-energy-prediction\/weather_test.csv',\n    '..\/input\/ashrae-energy-prediction\/weather_train.csv',\n    '..\/input\/ashrae-energy-prediction\/building_metadata.csv']\n[check_fline(s) for s in fs]","988837f3":"# Load sample training data\ndf_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')\ndf_train_weather = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\ndf_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/test.csv')\ndf_test_weather = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')\ndf_building = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')","b4994676":"# Show data shape\n[print(item.shape) for item in [df_train,df_train_weather,df_test,df_test_weather,df_building]]","8de9ca42":"df_train.head()","915422b7":"df_test.head()","e08f8389":"df_train_weather.head()","a934a950":"df_building.head()","3185dc60":"df_train_total = pd.merge(df_train,df_building,how='left',on='building_id')\ndf_train_total = pd.merge(df_train_total,df_train_weather,how='left',on=[\"site_id\", \"timestamp\"])","c2be3185":"df_train_total.head()","e100d3ae":"df_test_total = pd.merge(df_test,df_building,how='left',on='building_id')\ndf_test_total = pd.merge(df_test_total,df_test_weather,how='left',on=[\"site_id\", \"timestamp\"])","b5a338db":"df_test_total.head()","4fff8810":"def feat_value_count(df,colname):\n    \"\"\"value count of each feature\n    \n    Args\n    df: data frame.\n    colname: string. Name of to be valued column\n    \n    Returns\n    df_count: data frame.\n    \"\"\"\n    df_count = df[colname].value_counts().to_frame().reset_index()\n    df_count = df_count.rename(columns={'index':colname+'_values',colname:'counts'})\n    return df_count","f4445a7b":"feat_value_count(df_train,'building_id')","8485d219":"feat_value_count(df_test,'building_id')","6a8a7a8c":"len(set(df_train.building_id) & set(df_test.building_id))","fae10d2f":"feat_value_count(df_train,'meter')","9933675b":"feat_value_count(df_train_weather,'site_id')","428bcac8":"feat_value_count(df_building,'primary_use')","4c7cad6e":"feat_value_count(df_building,'site_id')","b017ad93":"df_train_total.dtypes","4f4c9d96":"df_train_total[\"timestamp\"] = pd.to_datetime(df_train_total[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')","cb475e84":"df_test_total[\"timestamp\"] = pd.to_datetime(df_test_total[\"timestamp\"], format='%Y-%m-%d %H:%M:%S')","1d1aaadc":"def check_missing(df,cols=None,axis=0):\n    \"\"\"check data frame column missing situation\n    Args\n    df: data frame.\n    cols: list. List of column names\n    axis: int. 0 means column and 1 means row\n    \n    Returns\n    missing_info: data frame. \n    \"\"\"\n    if cols != None:\n        df = df[cols]\n    missing_num = df.isnull().sum(axis).to_frame().rename(columns={0:'missing_num'})\n    missing_num['missing_percent'] = df.isnull().mean(axis)*100\n    return missing_num.sort_values(by='missing_percent',ascending = False) ","73f62b1e":"df_colmissing = check_missing(df_train_total,cols=None,axis=0)\ndf_colmissing","37495500":"del df_colmissing\ngc.collect()","a9f4f02b":"print(max(df_train_total.timestamp),min(df_train_total.timestamp))","5014f825":"print(max(df_test_total.timestamp),min(df_test_total.timestamp))","dd22c35c":"df_one_building = df_train_total[df_train_total.building_id == 1258]","b40b1c1c":"df_one_building.head()","d7e7eb98":"# electricity\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 0])","3f18116b":"del df_one_building\ngc.collect()","11497827":"# chilledwater\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 1])","08c8b204":"# steam\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 2])","0dd0a097":"# hotwater\nsns.lineplot(x='timestamp',y='meter_reading',data=df_one_building[df_train_total.meter == 3])","a6854066":"df_lots_building = df_train_total[df_train_total['building_id'].isin([1258,1298,1249])]","061275e9":"for i in range(0,4):\n    f, ax = plt.subplots(figsize=(15, 6))\n    sns.lineplot(x='timestamp',y='meter_reading', hue = 'building_id',legend=False,\n             data=df_lots_building[df_lots_building.meter == i])","f28ba0fc":"del df_lots_building\ngc.collect()","62603627":"for i in range(0,4):\n    corr = df_train_total[df_train_total.meter == i][['timestamp','meter_reading','square_feet','year_built','floor_count',\n             'air_temperature','cloud_coverage','dew_temperature','precip_depth_1_hr',\n             'sea_level_pressure','wind_direction','wind_speed']].corr()\n    f, ax = plt.subplots(figsize=(15, 6))\n    sns.heatmap(corr, vmin=-1, vmax=1, annot=True)","c3b078ad":"del corr\ngc.collect()","01cf5361":"del df_train\ndel df_train_weather\ndel df_test\ndel df_test_weather\ndel df_building\ngc.collect()","4e52f290":"def label_encoder(df, categorical_columns=None):\n    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n    # if categorical_colunms are not given than treat object as categorical features\n    if not categorical_columns:\n        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for col in categorical_columns:\n        df[col], uniques = pd.factorize(df[col])\n    return df, categorical_columns","f2d78029":"df_train_total,colname = label_encoder(df_train_total, categorical_columns=['primary_use'])\ndf_test_total,colname = label_encoder(df_test_total, categorical_columns=['primary_use'])","b92f5afc":"params = {'objective':'regression',\n          'boosting_type':'gbdt',\n          'metric':'rmse',\n          'learning_rate':0.1,\n          'num_leaves': 2**8,\n          'max_depth':-1,\n          'colsample_bytree':0.5,# feature_fraction 0.7\n          'subsample_freq':1,\n          'subsample':0.7,\n          'verbose':-1,\n          #'num_threads':8,\n          'seed': 47,#42\n                } ","559ae187":"category_cols = ['building_id', 'site_id', 'primary_use']","7cce4eba":"def fold_train_model(splits_num,features_train,labels_train,features_test,categorical):\n    splits = splits_num\n    folds = KFold(n_splits = splits,random_state=50)\n    predictions = np.zeros(len(features_test))\n    ave_score = 0\n    \n    for fold_num, (trn_idx, val_idx) in enumerate(folds.split(features_train.values, labels_train.values)):\n        print(\"Fold {}\".format(fold_num))\n        train_df, y_train_df = features_train.iloc[trn_idx], labels_train.iloc[trn_idx]\n        valid_df, y_valid_df = features_train.iloc[val_idx], labels_train.iloc[val_idx]\n\n        trn_data = lgb.Dataset(train_df, label=y_train_df,categorical_feature=categorical)\n        val_data = lgb.Dataset(valid_df, label=y_valid_df,categorical_feature=categorical)\n\n        valid_results = {}\n        clf = lgb.train(params,\n                        trn_data,\n                        10000,\n                        valid_sets = [trn_data, val_data],\n                        verbose_eval=500,\n                        early_stopping_rounds=500,\n                        evals_result=valid_results)\n\n        pred = clf.predict(valid_df)\n        score = np.sqrt(mean_squared_error(y_valid_df, pred))\n        ave_score += score \/ splits\n        predictions += clf.predict(features_test) \/ splits\n    return ave_score,predictions","536e18ad":"def train_meter_type(meter_type,df_train_total,df_test_total,category_cols):\n    # prepare data\n    df_type_train = df_train_total[df_train_total.meter == meter_type]\n    # transfer label with log\n    df_type_label = np.log1p(df_type_train['meter_reading'])\n    df_type_train.drop(columns = ['meter','meter_reading'],inplace=True)\n    df_type_train['timestamp'] = df_type_train['timestamp'].astype('int64') \/\/ 10**9\n\n    df_type_test = df_test_total[df_test_total.meter == meter_type]\n    df_type_row_id = df_type_test['row_id']\n    df_type_test.drop(columns = ['row_id','meter'],inplace=True)\n    df_type_test['timestamp'] = df_type_test['timestamp'].astype('int64') \/\/ 10**9\n    \n    # train model\n    print('train model')\n    ave_score,predictions_type = fold_train_model(3,df_type_train,df_type_label,df_type_test,category_cols)\n    print('ave socre is %s'%(ave_score))\n    \n    # get prediction\n    print('get prediction')\n    sub_type = pd.DataFrame({'row_id': df_type_row_id, 'meter_reading': np.expm1(predictions_type)})\n    return sub_type,ave_score","627ce754":"#sub_ele_f,ave_score = train_meter_type(0,df_train_total,df_test_total,category_cols)","7bb562d0":"#sub_cw_f,ave_score_cw = train_meter_type(1,df_train_total,df_test_total,category_cols)","ec48da7b":"#sub_stm_f,ave_score_stm = train_meter_type(2,df_train_total,df_test_total,category_cols)","6d1b0ba0":"#sub_hw_f,ave_score_hw = train_meter_type(3,df_train_total,df_test_total,category_cols)","ee01be52":"#sub_all = pd.concat([sub_ele_f,sub_cw_f,sub_stm_f,sub_hw_f])\n#sub_all.sort_values(by='row_id')","535bc2a6":"#sub_all.to_csv(['..\/output\/baseline_log.csv', index = False)","8af7849f":"A total of 1449 buildings are in train data. Building 1298 has the most records and building 403 has the least records.","0cc5485f":"# Load Data","c85ba146":"So we have train data span the whole 2016 and we need to predict from day one of 2017 to the end of 2018.","63d4612c":"## Train Model","d255298b":"# Target Explore","b9ed06f1":"# Check Data Types","c58ad456":"## multiple building","d42986c3":"## set parameter","65b43b27":"We need to predict meter reading given building id, meter, and timestamp.\n\nbuilding_meta.csv --> train.csv by 'building_id'.\n\nweather.csv --> building_meta.csv by 'site_id' --> train.csv by 'timestamp'","235f5364":"### Task\nIn this competition we need to predict building energy consumption for **1449** buildings with **four** types of meter: electricity, chilledwater, steam and hotwater.\n\n### Time span\n\nTrain data starts from 2016-01-01 00:00:00 to 2016-12-31 23:00:00.\n\nTest data starts from 2017-01-01 00:00:00 to 2018-12-31 23:00:00.\n\n### Data Findings\n\n1) The energy consumption level of each building is very different. \nGood side is that train data and test data contain **the same** number buildings.\n\n2) The data clearly have some 'errors', like loss of data or unusual spikes. \nIt might be better that we clean the data before building the model.\nAnd in the choice of loss function, it might be better to choose one that is **robust towards outliers.**\n\n3) And from the visuals below, it's obvious that each meter type behave **very differently**. \nAlso we can't use other meter type reading for predictiong. I think we'd better building model seperately for each meter type.\n\n### Feature Engineering Thoughts\nThis is a time sereis regression problem. Things need to pay attention to :\n* seasonal effect\n* periodical trend\n* auto correlation\n* lag variables\n* stationary\n\nThis type of data is called panal data in ecometrics. Maybe panal regression technique can be applied here.\n\n### Model Structure\nAs pointed above, I think it's better to train model with different meter type. And from the correlation matrix below, each meter type's relating feature it's quite different as well. So I will try different feature set and parameter set for each of  the four meter type.\n\nAlso I believe there's auto correlation effect in the readings.But I haven't figure out how wo encorperate such info in the model. ","1c92b641":"## feature correlation with target","c8154dd7":"# Introduction","fc67a674":"Looks like meter 0: electricity has the most record.","92cd71fb":"# Baseline Model","c91755f7":"# Basic Data Structure","0148e5e7":"# Explore Unique Values","54e284af":"# Check Missing Values","6bf6caf5":"It looks that we need to predict all 1449 building meter readings. All buildings that need to be predicted appear in train data.","8ba3b079":"## single building","d86be0a0":"## helper function","9f9f467e":"Looks like there are some outliers."}}