{"cell_type":{"fa3f2877":"code","da4dd6db":"code","2cf88400":"code","8305e0d0":"code","b2d76080":"code","1247a378":"code","c9a02066":"code","b7d5b679":"code","2b614750":"code","b0d23584":"code","ef58f1ff":"code","97b91537":"code","9c8786e0":"code","323177b1":"code","19d8e968":"code","0d8a3484":"code","1b82cee2":"code","b182ac7f":"code","de6fd591":"code","13c98337":"code","736ffcd0":"markdown","3415f72f":"markdown","90bcbe32":"markdown","4b01bbbb":"markdown","2f5a1ad1":"markdown","4ae95091":"markdown"},"source":{"fa3f2877":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\n%matplotlib inline\n\nsns.set(style='white', context='notebook', palette='deep')\n\nmycols = [\"#66c2ff\", \"#5cd6d6\", \"#00cc99\", \"#85e085\", \"#ffd966\", \"#ffb366\", \"#ffb3b3\", \"#dab3ff\", \"#c2c2d6\"]\nsns.set_palette(palette = mycols, n_colors = 4)","da4dd6db":"train_set = pd.read_csv('..\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest_set  = pd.read_csv('..\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\nprint(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\nprint(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')","2cf88400":"#train_set\uc758 'Target' feature\uc758 \ubd84\ud3ec\ub3c4 \ud655\uc778 (1\uc744 \uae30\uc900\uc73c\ub85c \ud55c \ube44\uc728) (Target \uac12\uc740 1,2,3,4 \ucd1d 4\uac1c)\n\ntarget = train_set['Target']\ntarget.value_counts(normalize=True)","8305e0d0":"#test_set\uc744 \ubcf4\uba74 rez_esc\uac00 99.0\uc778 outlier\uac00 \uc874\uc7ac\ud55c\ub2e4.\n#rez_esc\ub294 7\uc138\uc5d0\uc11c 19\uc138 \uc0ac\uc774\uc758 \uc778\uad6c \uc911 \uc785\ud559\uc5d0 \ub2a6\ub294 \uc5f0\uc218\ub97c \uc758\ubbf8\ud55c\ub2e4. (8\uc0b4\uc5d0 \uc785\ud559\ud574\uc57c\ud588\ub294\ub370 11\uc0b4\uc5d0 \uc785\ud559\ud588\ub2e4\uba74 rez_esc=3)\n#https:\/\/www.kaggle.com\/c\/costa-rican-household-poverty-prediction\/discussion\/61403 Discussion\uc744 \ucc38\uace0\ud558\uba74, rez_esc\uc758 \ucd5c\ub300\uce58\ub294 5\ub85c \uc81c\ud55c\ub41c\ub2e4\uace0 \ub098\uc640\uc788\ub2e4.\n#\ub530\ub77c\uc11c, 99.0\uc73c\ub85c \uae30\ub85d\ub41c rez_esc\ub294 \ud5c8\uc6a9\ub418\ub294 \ucd5c\ub300\uce58\uc778 5\ub85c \ubcc0\ud658\ud55c\ub2e4.\n\ntest_set.loc[test_set['rez_esc'] == 99.0, 'rez_esc'] = 5","b2d76080":"#train_data\uc5d0 \ub300\ud558\uc5ec...\n\ndata_na = train_set.isnull().sum().values \/ train_set.shape[0] * 100\ndf_na = pd.DataFrame(data_na, index=train_set.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_value_count = df_na[df_na['Count'] > 0].shape[0]\n\nprint(f'We got {missing_value_count} rows which have missing value in train set ')\ndf_na.head(6)\n\n#rez_esc: years behind in school\n#meaneduc: average years of education for adults(18+)\n#v18q1: depends on v18q(owns a tablet)\n#v2a1: depends on tipovivi3\n#SQBmeaned: meaned squared(???) -> \uc774 \uc608\uce21\uc5d0\uc11c \ud544\uc694\uc5c6\ub294 \uac83\uc73c\ub85c \ud310\ub2e8\ub418\ubbc0\ub85c \uc774\ud6c4 step\uc5d0\uc11c 0\uc73c\ub85c \ucc44\uc6b8\uac83 (<- \uc798 \ubaa8\ub974\uaca0\uc74c...)","1247a378":"#test_data\uc5d0 \ub300\ud558\uc5ec...\n\ndata_na = test_set.isnull().sum().values \/ test_set.shape[0] *100\ndf_na = pd.DataFrame(data_na, index=test_set.columns, columns=['Count'])\ndf_na = df_na.sort_values(by=['Count'], ascending=False)\n\nmissing_value_count = df_na[df_na['Count']>0].shape[0]\n\nprint(f'We got {missing_value_count} rows which have missing value in test set ')\ndf_na.head(6)","c9a02066":"#Fill NA\n\ndef replace_v18q1(x):\n    if x['v18q'] == 0:\n        return x['v18q']\n    else:\n        return x['v18q1']\n\ntrain_set['v18q1'] = train_set.apply(lambda x : replace_v18q1(x),axis=1)\ntest_set['v18q1'] = test_set.apply(lambda x : replace_v18q1(x),axis=1)\n\ntrain_set['v2a1'] = train_set['v2a1'].fillna(value=train_set['tipovivi3'])\ntest_set['v2a1'] = test_set['v2a1'].fillna(value=test_set['tipovivi3'])","b7d5b679":"cols = ['edjefe', 'edjefa']\n#edjefe: years of education of male head of household\n#edjefa: years of education of female head of household\n\n#yes -> 1, no -> 0\uc73c\ub85c \ubcc0\ud658\ntrain_set[cols] = train_set[cols].replace({'no': 0, 'yes':1}).astype(float)\ntest_set[cols] = test_set[cols].replace({'no': 0, 'yes':1}).astype(float)","2b614750":"#\uc0c8\ub85c \ub9cc\ub4dc\ub294 feature 4\uc885\ntrain_set['roof_waste_material'] = np.nan\ntest_set['roof_waste_material'] = np.nan\ntrain_set['electricity_other'] = np.nan\ntest_set['electricity_other'] = np.nan\n\n#techozinc: =1 \uc9c0\ubd95\uc758 \uc8fc\uc694 \uc7ac\ub8cc\uac00 \uae08\uc18d \ud3ec\uc77c \ub610\ub294 \uc9d5\ud06c\uc778 \uacbd\uc6b0\n#techoentrepiso: =1 \uc9c0\ubd95\uc758 \uc8fc\uc694 \uc7ac\ub8cc\uac00 \uc12c\uc720 \uc2dc\uba58\ud2b8, \uba54\uc790\ub2cc\uc778 \uacbd\uc6b0\n#techocane: =1 \uc9c0\ubd95\uc758 \uc8fc\uc694 \uc7ac\ub8cc\uac00 \ucc9c\uc5f0 \uc12c\uc720\uc778 \uacbd\uc6b0\n#techootro: =1 \uc9c0\ubd95\uc758 \uc8fc\uc694 \uc7ac\ub8cc\uac00 \ub2e4\ub978 \uacbd\uc6b0\ndef fill_roof_exception(x):\n    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n        return 1\n    else:\n        return 0\n\n#public: =CNFL, ICE, ESPH\/JASEC\uc5d0\uc11c \ub098\uc624\ub294 \uc804\uae30 1\uac1c\n#planpri: =\ubbfc\uac04 \ubc1c\uc804\uc18c\uc5d0\uc11c \ub098\uc624\ub294 \uc804\uae30 1\uac1c\n#noelec: =1 \uc8fc\uac70\uc9c0\uc5d0 \uc804\uae30\uac00 \uc5c6\uc74c\n#coopele: =\ud611\ub3d9\uc870\ud569 \uc804\uae30 1\uac1c\ndef fill_no_electricity(x):\n    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n        return 1\n    else:\n        return 0\n\n#\uc704\uc5d0\uc11c \uc815\uc758\ud55c \ud568\uc218\uc5d0 \ub9de\ucdb0\uc11c \uc0c8\ub85c\uc6b4 4\uc885\uc758 feature\ub97c \ucc44\uc6c0.\ntrain_set['roof_waste_material'] = train_set.apply(lambda x : fill_roof_exception(x),axis=1)\ntest_set['roof_waste_material'] = test_set.apply(lambda x : fill_roof_exception(x),axis=1)\ntrain_set['electricity_other'] = train_set.apply(lambda x : fill_no_electricity(x),axis=1)\ntest_set['electricity_other'] = test_set.apply(lambda x : fill_no_electricity(x),axis=1)","b0d23584":"#18\uc138 \uc774\uc0c1\uc774 \uac00\uc7a5\uc778\uac00? \ub97c \ubcf4\uc5ec\uc8fc\ub294 feature \uc0dd\uc131(head<18>)\ndef owner_is_adult(x):\n    if x['age'] <= 18:\n        return 0\n    else:\n        return 1\n\ntrain_set['head<18'] = train_set.apply(lambda x : owner_is_adult(x),axis=1)\ntest_set['head<18'] = test_set.apply(lambda x : owner_is_adult(x),axis=1)","ef58f1ff":"#\ub354 \ub2e4\uc591\ud55c feature\ub4e4 \uc9c1\uc811\uc0dd\uc131\n\n#hogar_adul: \uc5b4\ub978\uc778 \uac00\uad6c\uc6d0 \uc218\n#hogar_mayor: 65\uc138 \uc774\uc0c1 \uac00\uad6c\uc6d0 \uc218\n#hogar_nin: 0~19\uc138\uc778 \uac00\uad6c\uc6d0 \uc218\n#hogar_total: \uac00\uad6c\uc6d0 \ucd1d \uc778\uc6d0\uc218\ntrain_set['adult'] = train_set['hogar_adul'] - train_set['hogar_mayor']\ntrain_set['dependency_count'] = train_set['hogar_nin'] + train_set['hogar_mayor']\ntrain_set['dependency'] = train_set['dependency_count'] \/ train_set['adult']\ntrain_set['child_percent'] = train_set['hogar_nin']\/train_set['hogar_total']\ntrain_set['elder_percent'] = train_set['hogar_mayor']\/train_set['hogar_total']\ntrain_set['adult_percent'] = train_set['hogar_adul']\/train_set['hogar_total']\ntest_set['adult'] = test_set['hogar_adul'] - test_set['hogar_mayor']\ntest_set['dependency_count'] = test_set['hogar_nin'] + test_set['hogar_mayor']\ntest_set['dependency'] = test_set['dependency_count'] \/ test_set['adult']\ntest_set['child_percent'] = test_set['hogar_nin']\/test_set['hogar_total']\ntest_set['elder_percent'] = test_set['hogar_mayor']\/test_set['hogar_total']\ntest_set['adult_percent'] = test_set['hogar_adul']\/test_set['hogar_total']\n\n#v2a1: \uc6d4\uc138 \ub0a9\ubd80\n#hhsize: \uac00\uad6c \ucfe0\uae30\ntrain_set['rent_per_adult'] = train_set['v2a1']\/train_set['hogar_adul']\ntrain_set['rent_per_person'] = train_set['v2a1']\/train_set['hhsize']\ntest_set['rent_per_adult'] = test_set['v2a1']\/test_set['hogar_adul']\ntest_set['rent_per_person'] = test_set['v2a1']\/test_set['hhsize']\n\n#hacdor: =1 \uce68\uc2e4\ubcc4 \uacfc\uc789 \uc218\uc6a9\n#hacapo: =1 \ubc29\ubcc4 \uacfc\uc77c \uc218\uc6a9\ntrain_set['overcrowding_room_and_bedroom'] = (train_set['hacdor'] + train_set['hacapo'])\/2\ntest_set['overcrowding_room_and_bedroom'] = (test_set['hacdor'] + test_set['hacapo'])\/2\n\n#refrig\/computer\/television: =1 \uac00\uad6c\uc5d0 \ub0c9\uc7a5\uace0\/\ucef4\ud4e8\ud130\/TV\uac00 \uc788\ub294 \uacbd\uc6b0\ntrain_set['no_appliances'] = train_set['refrig'] + train_set['computer'] + train_set['television']\ntest_set['no_appliances'] = test_set['refrig'] + test_set['computer'] + test_set['television']\n\n#rh41: 12\uc138 \ubbf8\ub9cc\uc758 \ub0a8\uc131\n#r4h2: 12\uc138 \uc774\uc0c1\uc758 \ub0a8\uc131\n#r4h3: \uac00\uad6c\uc6d0 \ub0a8\uc131 \ud569\uacc4\n#r4m1: 12\uc138 \ubbf8\ub9cc\uc758 \uc5ec\uc131\n#r4m2: 12\uc138 \uc774\uc0c1\uc758 \uc5ec\uc131\n#r4m3: \uac00\uad6c\uc6d0 \uc5ec\uc131 \ud569\uacc4\n#hhsize: \uac00\uad6c\uc6d0 \ud06c\uae30\ntrain_set['r4h1_percent_in_male'] = train_set['r4h1'] \/ train_set['r4h3']\ntrain_set['r4m1_percent_in_female'] = train_set['r4m1'] \/ train_set['r4m3']\ntrain_set['r4h1_percent_in_total'] = train_set['r4h1'] \/ train_set['hhsize']\ntrain_set['r4m1_percent_in_total'] = train_set['r4m1'] \/ train_set['hhsize']\ntrain_set['r4t1_percent_in_total'] = train_set['r4t1'] \/ train_set['hhsize']\ntest_set['r4h1_percent_in_male'] = test_set['r4h1'] \/ test_set['r4h3']\ntest_set['r4m1_percent_in_female'] = test_set['r4m1'] \/ test_set['r4m3']\ntest_set['r4h1_percent_in_total'] = test_set['r4h1'] \/ test_set['hhsize']\ntest_set['r4m1_percent_in_total'] = test_set['r4m1'] \/ test_set['hhsize']\ntest_set['r4t1_percent_in_total'] = test_set['r4t1'] \/ test_set['hhsize']\n\n#bedrooms: \uce68\uc2e4 \uc218\ntrain_set['rent_per_room'] = train_set['v2a1']\/train_set['rooms']\ntrain_set['bedroom_per_room'] = train_set['bedrooms']\/train_set['rooms']\ntrain_set['elder_per_room'] = train_set['hogar_mayor']\/train_set['rooms']\ntrain_set['adults_per_room'] = train_set['adult']\/train_set['rooms']\ntrain_set['child_per_room'] = train_set['hogar_nin']\/train_set['rooms']\ntrain_set['male_per_room'] = train_set['r4h3']\/train_set['rooms']\ntrain_set['female_per_room'] = train_set['r4m3']\/train_set['rooms']\ntrain_set['room_per_person_household'] = train_set['hhsize']\/train_set['rooms']\n\ntest_set['rent_per_room'] = test_set['v2a1']\/test_set['rooms']\ntest_set['bedroom_per_room'] = test_set['bedrooms']\/test_set['rooms']\ntest_set['elder_per_room'] = test_set['hogar_mayor']\/test_set['rooms']\ntest_set['adults_per_room'] = test_set['adult']\/test_set['rooms']\ntest_set['child_per_room'] = test_set['hogar_nin']\/test_set['rooms']\ntest_set['male_per_room'] = test_set['r4h3']\/test_set['rooms']\ntest_set['female_per_room'] = test_set['r4m3']\/test_set['rooms']\ntest_set['room_per_person_household'] = test_set['hhsize']\/test_set['rooms']\n\ntrain_set['rent_per_bedroom'] = train_set['v2a1']\/train_set['bedrooms']\ntrain_set['edler_per_bedroom'] = train_set['hogar_mayor']\/train_set['bedrooms']\ntrain_set['adults_per_bedroom'] = train_set['adult']\/train_set['bedrooms']\ntrain_set['child_per_bedroom'] = train_set['hogar_nin']\/train_set['bedrooms']\ntrain_set['male_per_bedroom'] = train_set['r4h3']\/train_set['bedrooms']\ntrain_set['female_per_bedroom'] = train_set['r4m3']\/train_set['bedrooms']\ntrain_set['bedrooms_per_person_household'] = train_set['hhsize']\/train_set['bedrooms']\n\ntest_set['rent_per_bedroom'] = test_set['v2a1']\/test_set['bedrooms']\ntest_set['edler_per_bedroom'] = test_set['hogar_mayor']\/test_set['bedrooms']\ntest_set['adults_per_bedroom'] = test_set['adult']\/test_set['bedrooms']\ntest_set['child_per_bedroom'] = test_set['hogar_nin']\/test_set['bedrooms']\ntest_set['male_per_bedroom'] = test_set['r4h3']\/test_set['bedrooms']\ntest_set['female_per_bedroom'] = test_set['r4m3']\/test_set['bedrooms']\ntest_set['bedrooms_per_person_household'] = test_set['hhsize']\/test_set['bedrooms']\n\n#v18q1: \uac00\uad6c \uc18c\uc720\uc758 \ud0dc\ube14\ub9bf \uc218\n#qmobilephone: \uac00\uad6c \uc18c\uc720\uc758 \ud734\ub300\uc804\ud654 \uc218\ntrain_set['tablet_per_person_household'] = train_set['v18q1']\/train_set['hhsize']\ntrain_set['phone_per_person_household'] = train_set['qmobilephone']\/train_set['hhsize']\ntest_set['tablet_per_person_household'] = test_set['v18q1']\/test_set['hhsize']\ntest_set['phone_per_person_household'] = test_set['qmobilephone']\/test_set['hhsize']\n\n#r4t1: 12\uc138 \ubbf8\ub9cc\uc778 \uc0ac\ub78c\ntrain_set['age_12_19'] = train_set['hogar_nin'] - train_set['r4t1']\ntest_set['age_12_19'] = test_set['hogar_nin'] - test_set['r4t1']    \n\n#escolari: \ub2e4\ub144\uac04\uc758 \uad50\uc721\ntrain_set['escolari_age'] = train_set['escolari']\/train_set['age']\ntest_set['escolari_age'] = test_set['escolari']\/test_set['age']\n\ntrain_set['rez_esc_escolari'] = train_set['rez_esc']\/train_set['escolari']\ntrain_set['rez_esc_r4t1'] = train_set['rez_esc']\/train_set['r4t1']\ntrain_set['rez_esc_r4t2'] = train_set['rez_esc']\/train_set['r4t2']\ntrain_set['rez_esc_r4t3'] = train_set['rez_esc']\/train_set['r4t3']\ntrain_set['rez_esc_age'] = train_set['rez_esc']\/train_set['age']\ntest_set['rez_esc_escolari'] = test_set['rez_esc']\/test_set['escolari']\ntest_set['rez_esc_r4t1'] = test_set['rez_esc']\/test_set['r4t1']\ntest_set['rez_esc_r4t2'] = test_set['rez_esc']\/test_set['r4t2']\ntest_set['rez_esc_r4t3'] = test_set['rez_esc']\/test_set['r4t3']\ntest_set['rez_esc_age'] = test_set['rez_esc']\/test_set['age']","97b91537":"train_set['dependency'] = train_set['dependency'].replace({np.inf: 0})\ntest_set['dependency'] = test_set['dependency'].replace({np.inf: 0})\n\nprint(f'train set has {train_set.shape[0]} rows, and {train_set.shape[1]} features')\nprint(f'test set has {test_set.shape[0]} rows, and {test_set.shape[1]} features')","9c8786e0":"df_train = pd.DataFrame()\ndf_test = pd.DataFrame()\n\naggr_mean_list = ['rez_esc', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco2',\n             'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12',\n             'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',]\n\nother_list = ['escolari', 'age', 'escolari_age']\n\n#aggr_mean_list\uc758 feature\ub4e4\uc5d0 \ub300\ud574 mean\uac12\uc744 \ub098\ud0c0\ub0b4 \uc8fc\ub294 feature \ucd94\uac00 \uc0dd\uc131\nfor item in aggr_mean_list:\n    group_train_mean = train_set[item].groupby(train_set['idhogar']).mean()\n    group_test_mean = test_set[item].groupby(test_set['idhogar']).mean()\n    new_col = item + '_aggr_mean'\n    df_train[new_col] = group_train_mean\n    df_test[new_col] = group_test_mean\n\n#other_list\uc758 feature\uc5d0 \ub300\ud574\uc11c\ub294 mean, std, min, max, sum\uac12\uc744 \ub098\ud0c0\ub0b4\uc8fc\ub294 \ucd94\uac00 feature \uc0dd\uc131\nfor item in other_list:\n    for function in ['mean','std','min','max','sum']:\n        group_train = train_set[item].groupby(train_set['idhogar']).agg(function)\n        group_test = test_set[item].groupby(test_set['idhogar']).agg(function)\n        new_col = item + '_' + function\n        df_train[new_col] = group_train\n        df_test[new_col] = group_test\n\nprint(f'new aggregate train set has {df_train.shape[0]} rows, and {df_train.shape[1]} features')\nprint(f'new aggregate test set has {df_test.shape[0]} rows, and {df_test.shape[1]} features')","323177b1":"#\uc704\uc758 \ucd94\uac00\uc801\uc778 aggregate feature\ub4e4\uc744 \uc6d0\ubcf8 \ub370\uc774\ud130\uc5d0 \ucd94\uac00\ndf_test = df_test.reset_index()\ndf_train = df_train.reset_index()\n\ntrain_agg = pd.merge(train_set, df_train, on='idhogar')\ntest = pd.merge(test_set, df_test, on='idhogar')\n\n#fill all na as 0\ntrain_agg.fillna(value=0, inplace=True)\ntest.fillna(value=0, inplace=True)\nprint(f'new train set has {train_agg.shape[0]} rows, and {train_agg.shape[1]} features')\nprint(f'new test set has {test.shape[0]} rows, and {test.shape[1]} features')","19d8e968":"#train_agg \uc911 parentesco1\uc774 1\uc778\uac12\ub9cc train\uac12\uc73c\ub85c \uc9c0\uc815\n#parentsco1: \uac00\uc815\uc758 \uac00\uc7a5\uc77c \uacbd\uc6b0 \uac12\uc774 1\uc784.\n#competition\uc758 \ub370\uc774\ud130 \uc124\uba85\uc5d0 \uc758\ud558\uba74, \ucc44\uc810 \uc2dc \uac00\uc7a5\uc778 \uacbd\uc6b0\uc758 \ub370\uc774\ud130\ub9cc \ucc44\uc810\ud558\uae30 \ub54c\ubb38\uc5d0 parentsco1\uac12\uc774 1\uc778 row\ub9cc \uc0ac\uc6a9\n#\ub2e4\ub978 \ub178\ud2b8\ubd81\uc744 \ubcf4\ub2c8, \uc774\ub807\uac8c \ud558\ub294 \uc0ac\ub78c\ub4e4\uc774 \ub9ce\uc558\uc74c.\ntrain = train_agg.query('parentesco1==1')","0d8a3484":"submission = test[['Id']]\n\n#\ud544\uc694\uc5c6\ub294 feature\ub4e4\uc744 \uc9c0\uc6b4\ub2e4. (\uae30\uc900\uc740 notebook\uc5d0 \ub098\uc640\uc788\uc9c0 \uc54a\uc544 \uc798 \ubaa8\ub974\uaca0\uc74c. \ub098\ub984\uc758 feature selection\uc744 \ud55c \uac83\uc73c\ub85c \ubcf4\uc784.)\ntrain.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\ntest.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n\ncorrelation = train.corr()\ncorrelation = correlation['Target'].sort_values(ascending=False)\nprint(f'The most 20 positive feature: \\n{correlation.head(20)}')\nprint('*'*50)\n\nprint(f'The most 20 negative feature: \\n{correlation.tail(20)}')","1b82cee2":"y = train['Target']\n\ntrain.drop(columns=['Target'], inplace=True)\n\n#https:\/\/www.kaggle.com\/mlisovyi\/lighgbm-hyperoptimisation-with-f1-macro Notebook\uc5d0\uc11c lightgbm\uc758 parameter\ub97c \uac00\uc838\uc634.\n#\uc704\uc758 \ub178\ud2b8\ubd81\uc5d0\uc11c\ub294 lightgbm\uc744 RandomizedSearchCV\ub97c \ud1b5\ud574 \ucc3e\uc544\ub0c8\uc74c.\n#Parameter\ub294 num_leaves, min_child_samples, subsample, colsample_bytree 4\uac00\uc9c0\n\n#num_leaves: \ud558\ub098\uc758 \ud2b8\ub9ac\uac00 \uac00\uc9c8 \uc218 \uc788\ub294 \ucd5c\ub300 leaf\uc758 \uac1c\uc218(\ub192\uc73c\uba74 \uc815\ud655\ub3c4 \uc99d\uac00, but \ubaa8\ub378 \ubcf5\uc7a1\ub3c4 \uc99d\uac00)\n#min_child_samples: \ucd5c\uc885 \uacb0\uc815 \ud074\ub798\uc2a4\uc778 leaf node\uac00 \ub418\uae30 \uc704\ud574 \ucd5c\uc18c\ud55c\uc73c\ub85c \ud544\uc694\ud55c \ub370\uc774\ud130 \uac1c\uccb4 \uc218\n#subsample: \uacfc\uc801\ud569\uc744 \uc81c\uc5b4\ud558\uae30 \uc704\ud574 \ub370\uc774\ud130\ub97c \uc0d8\ud50c\ub9c1\ud558\ub294 \ube44\uc728\n#colsample_bytree: \uac1c\ubcc4 \ud2b8\ub9ac\ub97c \ud559\uc2b5\ud560 \ub54c\ub9c8\ub2e4 \ubb34\uc791\uc704\ub85c \uc120\ud0dd\ud558\ub294 feature\uc758 \ube44\uc728\uc744 \uc81c\uc5b4\n\n#lightgbm\uc5d0\ub294 \uc774\uc678\uc5d0\ub3c4 max_depth, learning_rate, reg_alpha, reg_lambda, n_estimators \ub4f1\uc758 parameter\ub4e4\uc774 \uc788\ub2e4.\n#\uac01\uac01 \ud2b8\ub9ac\uc758 \ucd5c\ub300 \uae4a\uc774, \ud559\uc2b5\ub960, L1 \uaddc\uc81c\ud56d, L2 \uaddc\uc81c\ud56d, \ubc18\ubcf5 \uc218\ud589\ud558\ub294 \ud2b8\ub9ac\uc758 \uac1c\uc218\uc774\ub2e4.\n\nclf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=None, silent=True, metric='None', \n                             n_jobs=4, n_estimators=5000, class_weight='balanced',\n                             colsample_bytree =  0.93, min_child_samples = 95, num_leaves = 14, subsample = 0.96)","b182ac7f":"#\uc6d0\ubcf8 NOTEBOOK\uc5d0\uc11c\ub294 early_stopping\uc744 \uc801\uc6a9\ud588\uc73c\ub098, \uc801\uc6a9 \uc2dc \uc624\ub958\uac00 \ubc1c\uc0dd\ud574 \uc774 notebook\uc5d0\uc11c\ub294 \uc81c\uc678\ud568.\n\n#kfold\uc758 \uac1c\uc218\ub97c 5\uac1c\ub85c \uc9c0\uc815\ud558\uace0, stratified \ubc29\uc2dd\uc744 \uc801\uc6a9\ud568.\nkfold = 5\nkf = StratifiedKFold(n_splits=kfold, shuffle=True)\n\npredicts_result = []\nfor train_index, test_index in kf.split(train, y):\n    print(\"###\")\n    X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n    predicts_result.append(clf.predict(test))","de6fd591":"#feature importance\ub97c \ud655\uc778\ud558\uae30 \uc704\ud55c \ucf54\ub4dc\ub4e4\n\nindices = np.argsort(clf.feature_importances_)[::-1]\nindices = indices[:75]\n\n# \ub9c9\ub300 \uadf8\ub798\ud504\ub85c feature importance\ub97c \uc2dc\uac01\ud654\ud568.\nplt.subplots(figsize=(20, 15))\ng = sns.barplot(y=train.columns[indices], x = clf.feature_importances_[indices], orient='h', palette = mycols)\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=12)\ng.tick_params(labelsize=9)\ng.set_title(\"LightGBM feature importance\");","13c98337":"#submission file \uc81c\ucd9c\nsubmission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\nsubmission.to_csv('submission.csv', index = False)\n\n#0.41568\uc774\ub77c\ub294 score\uac00 \ub098\uc654\uc74c.","736ffcd0":"## Missing Value \ud0d0\uc0c9","3415f72f":"## Outlier \ucc98\ub9ac","90bcbe32":"## Library Import and Seaborn Setting","4b01bbbb":"## Dataset Input","2f5a1ad1":"# Costa Rican Household Poverty Level Prediction Tutorial (KOR)","4ae95091":"## Feature Engineering"}}