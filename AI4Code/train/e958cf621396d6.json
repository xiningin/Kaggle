{"cell_type":{"bd8078f0":"code","5f95b09c":"code","45b14005":"code","f5a6f827":"code","94a1d447":"code","d9d3d3f9":"code","6670f8f7":"code","51f265ac":"code","bf62aef9":"code","b8a62279":"code","0fba68f5":"code","1ea24257":"code","1d1217ea":"code","42a54a19":"code","64f1ee2e":"code","5cc1925e":"code","a6c5a99c":"code","ae6b8871":"code","b20ef98e":"code","e0a4919b":"code","28c7bb11":"code","558869ae":"code","8fe63bd5":"code","54f24e85":"code","a7c8cc8a":"code","b6d95c32":"code","3cb00fa1":"code","02c2b86e":"code","b6c74105":"code","26420b63":"code","d50954b3":"code","295be2bb":"code","d197ed0b":"markdown","3b87c8a9":"markdown","348020ab":"markdown","deb0262c":"markdown","a15ed42f":"markdown","f2208a7e":"markdown","aab37104":"markdown","48d928cf":"markdown","61a2657a":"markdown","373f8c6f":"markdown","a05e8214":"markdown","0b1fbc79":"markdown","6cdc10a6":"markdown","d0cf8368":"markdown","b5576c17":"markdown","7bc671d8":"markdown","737f4528":"markdown","077c4623":"markdown"},"source":{"bd8078f0":"import pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\ntqdm.pandas()\nimport matplotlib.pyplot as plt\nimport cv2\nimport keras \nimport keras.layers as L\nimport keras.models as M\nimport tensorflow as tf\nfrom keras.utils import Sequence\nimport os\nimport skimage.io as io\nimport gc\nfrom IPython.display import clear_output","5f95b09c":"train=pd.read_csv('..\/input\/bms-molecular-translation\/train_labels.csv')","45b14005":"train.head()","f5a6f827":"train['path'] = train['image_id'].progress_apply(\n    lambda x: \"..\/input\/bms-molecular-translation\/train\/{}\/{}\/{}\/{}.png\".format(\n        x[0], x[1], x[2], x))\ntrain.head()","94a1d447":"im=cv2.imread(train['path'][1])\n# Showing highlighted image\nimage=(cv2.erode(im,np.ones((2,2))))\nplt.imshow(image)","d9d3d3f9":"# Let's Get the First Part Of The Inchi and try to predict it in this file \ntrain['part 1'] = train['InChI'].progress_apply(\n    lambda x:  x.split('\/')[1]  )\ntrain.head()","6670f8f7":"train['Length']=train['part 1'].progress_apply(lambda x : len(x))\ntrain.head()","51f265ac":"# Getting the highest length \nmax_len=train['Length'].max()\nmax_len","bf62aef9":"# Let's get the character set of the usual characters in part 1\ncharacters=set()\nfor i in train['part 1'].values:\n    for j in i :\n        if j not in characters :\n            characters.add(j)\ncharacters=sorted(characters)\n    ","b8a62279":"# Having a look at the characters\ncharacters","0fba68f5":"# Making Dictionary for labelling\nchar_to_label={i:j for j,i in enumerate(characters) }\nlabel_to_char={j:i for j,i in enumerate(characters)}\n# Adding another label 100 which will show no character which means there is nothing there\nlabel_to_char[100]=''","1ea24257":"# Making a Custom DataGenerator to get the data from the DataFrame and changing it into custom output required for out CTC LAyer\nclass DataGenerator(Sequence):\n    def __init__(self,dataframe,char_map,batch_size=16,width=200,height=50,downsample_factor=4,max_length=20,shuffle=True):\n        self.dataframe=dataframe\n        self.char_map=char_map\n        self.batch_size=batch_size\n        self.width=width\n        self.height=height\n        self.downsample_factor=downsample_factor\n        self.max_length=max_length\n        self.shuffle=shuffle\n        self.indices = np.arange(len(dataframe))\n        self.on_epoch_end()\n    def __len__(self):\n        return len(self.dataframe)\/\/self.batch_size\n    def __getitem__(self,idx):\n        curr_batch_idx=self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n        \n        # Get the batch images\n        batch_images=np.ones((self.batch_size,self.width,self.height,1),dtype=np.float32)\n        batch_labels=np.ones((self.batch_size,self.max_length),dtype=np.float32)\n        input_length=np.ones((self.batch_size,1),dtype=np.float32)*(self.width\/\/self.downsample_factor-2)\n        label_length=np.zeros((self.batch_size,1),dtype=np.int64)\n        \n        # Starting the loop to get the data\n        for i,idx in enumerate(curr_batch_idx):\n            img=cv2.imread(self.dataframe['path'].values[idx])\n            img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            img=cv2.erode(img,((2,2)))\n            img=cv2.resize(img,(self.width,self.height))\n            img=img\/255   # Normalizing the image\n            img=img.T\n            img=np.expand_dims(img,axis=-1)\n            text=self.dataframe['part 1'].values[idx]\n            label=[]\n            for j in text: \n                label.append(self.char_map[j])\n            label.extend([100]*(20-len(label)))            \n            batch_images[i]=img\n            batch_labels[i]=label\n            label_length[i]=len(label)\n            \n        batch_inputs= {\n                'input_data':batch_images,\n                'input_label':batch_labels,\n                'input_length':input_length,\n                'label_length':label_length\n                \n            }\n        return batch_inputs,np.zeros((self.batch_size),dtype=np.float32)\n    def on_epoch_end(self):\n        if self.shuffle == True :\n            np.random.shuffle(self.indices)","1d1217ea":"len(train)","42a54a19":"train_datagenerator=DataGenerator(train[:150000],char_to_label)\nvalidation_datagenerator=DataGenerator(train[150000:160000],char_to_label)","64f1ee2e":"class CTCLayer(L.Layer):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.loss_fn = keras.backend.ctc_batch_cost\n\n    def call(self, y_true, y_pred, input_length, label_length):\n        # Compute the training-time loss value and add it\n        # to the layer using `self.add_loss()`.\n        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n        self.add_loss(loss)\n        \n        # On test time, just return the computed loss\n        return loss","5cc1925e":"# Making the Model now\ndef make_model():\n    inp=L.Input(shape=(200,50,1),dtype=np.float32,name='input_data')\n    labels=L.Input(shape=[5],dtype=np.float32,name='input_label')\n    input_length=L.Input(shape=[1],dtype=np.int64,name='input_length')\n    label_length=L.Input(shape=[1],dtype=np.int64,name='label_length')\n    x=L.Conv2D(32,(3,3),activation='relu',padding='same',kernel_initializer='he_normal')(inp)\n    x=L.MaxPooling2D(pool_size=(2,2))(x)\n    x=L.Conv2D(64,(3,3),activation='relu',padding='same',kernel_initializer='he_normal')(x)\n    x=L.MaxPooling2D(pool_size=(2,2))(x)\n    new_shape=((200\/\/4),(50\/\/4)*64)\n    x=L.Reshape(new_shape)(x)\n    x=L.Dense(64,activation='relu')(x)\n    x=L.Dropout(0.4)(x)\n    x=L.Bidirectional(L.LSTM(128,return_sequences=True,dropout=0.2))(x)\n    x=L.Bidirectional(L.LSTM(64,return_sequences=True,dropout=0.25))(x)\n    x=L.Dense(len(characters)+1,activation='softmax',kernel_initializer='he_normal',name='Dense_output')(x)\n    output=CTCLayer(name='outputs')(labels,x,input_length,label_length)\n    model=M.Model([inp,labels,input_length,label_length],output)\n    # Optimizer\n    sgd = keras.optimizers.SGD(learning_rate=0.0015,\n                               decay=1e-6,\n                               momentum=0.9,\n                               nesterov=True,\n                               clipnorm=5)\n    model.compile(optimizer=sgd)\n    return model\n    \n    \n    ","a6c5a99c":"model=make_model()\nmodel.summary()","ae6b8871":"# ### Add early stopping\n# es = keras.callbacks.EarlyStopping(monitor='val_loss',\n#                                    patience=2,\n#                                    restore_best_weights=True)\n\n# ### Train the model\n# if 'prediction_model.h5' not in os.listdir('.\/'):\n#     history = model.fit(train_datagenerator,\n#                         validation_data=validation_datagenerator,\n#                         steps_per_epoch=1500,\n#                         epochs=8,\n#                         callbacks=[es])","b20ef98e":"# prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n#                                         model.get_layer(name='Dense_output').output)\n","e0a4919b":"prediction_model=M.load_model('..\/input\/prediction-model-competition\/prediction_model_ocr (1).h5')\nprediction_model.summary()","28c7bb11":"label_to_char[100]=''\n# A utility to decode the output of the network\ndef decode_batch_predictions(pred):\n    pred = pred[:, :-2]\n    input_len = np.ones(pred.shape[0])*pred.shape[1]\n    \n    # Use greedy search. For complex tasks, you can use beam search\n    results = keras.backend.ctc_decode(pred, \n                                        input_length=input_len,\n                                        greedy=True)[0][0]\n    \n    # Iterate over the results and get back the text\n    output_text = []\n    for res in results.numpy():\n        outstr = ''\n        for c in res:\n            if c < len(characters) and c >=0:\n                outstr += label_to_char[c]\n        output_text.append(outstr)\n    \n    # return final text results\n    return output_text","558869ae":"for p, (inp_value, _) in enumerate(validation_datagenerator):\n    bs = inp_value['input_data'].shape[0]\n    X_data = inp_value['input_data']\n    labels = inp_value['input_label']\n    preds = prediction_model.predict(X_data)\n    pred_texts = decode_batch_predictions(preds)\n    \n    \n    orig_texts = []\n    for label in labels:\n        text = ''.join([label_to_char[int(x)] for x in label])\n        orig_texts.append(text)\n        \n    for i in range(bs):\n        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n    break","8fe63bd5":"sample=pd.read_csv('..\/input\/bms-molecular-translation\/sample_submission.csv')\nsample['path'] = sample['image_id'].progress_apply(\n    lambda x: \"..\/input\/bms-molecular-translation\/test\/{}\/{}\/{}\/{}.png\".format(\n        x[0], x[1], x[2], x))\nsample.head()","54f24e85":"del train\ngc.collect()","a7c8cc8a":"def transform(path):\n    img=cv2.imread(path)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img=cv2.erode(img,((2,2)))\n    img=cv2.resize(img,(200,50))\n    img=img\/255   # Normalizing the image\n    img=img.T\n    img=np.expand_dims(img,axis=-1)\n    return img","b6d95c32":"im=transform('..\/input\/bms-molecular-translation\/train\/2\/0\/1\/201013c95288.png')\nbatch_images=np.ones((128,200,50,1),dtype=np.float32)\nbatch_images[0]=im\n\nx=prediction_model.predict(batch_images)\npred_texts = decode_batch_predictions(x)\nplt.imshow(cv2.imread('..\/input\/bms-molecular-translation\/train\/2\/0\/1\/201013c95288.png'))\nprint(pred_texts[0])","3cb00fa1":"# predictions=[]\n# for i in range(len(sample)\/\/500):\n#     print(i*100\/3232)\n#     clear_output(wait=True)\n#     dd=sample[i*500:(i+1)*500]\n#     batch_images=np.ones((500,200,50,1),dtype=np.float32)\n#     for i in range(500):\n#         batch_images[i]=transform(dd['path'].values[i])\n#     x=prediction_model.predict(batch_images)\n#     pred_texts = decode_batch_predictions(x)\n#     predictions.extend(pred_texts)\n# dd=sample[3232*500:]\n# pt=len(sample)%500\n# batch_images=np.ones((pt,200,50,1),dtype=np.float32)\n# for j,k in enumerate(dd['path'].values) :\n#     im=transform(k)\n#     batch_images[j]=im\n# x=prediction_model.predict(batch_images)\n# pred_texts = decode_batch_predictions(x)\n# predictions.extend(pred_texts)\n# predictions=np.array(predictions)\n# np.save('Text Predicted.npy',predictions)","02c2b86e":"predictions=np.load('..\/input\/predicted-text\/Text Predicted.npy')","b6c74105":"# Baseline answers : label='InChI=1S\/'+'C15H22N2O2\/'+'c1-1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18(19)20\/'+'h1-1,1111,1,,,,,'\nlabel=['InChI=1S\/'+i+'\/c1-1-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18(19)20\/'+'h1-1,1111,1,,,,,' for i in predictions]","26420b63":"submission=pd.read_csv('..\/input\/bms-molecular-translation\/sample_submission.csv')","d50954b3":"submission['InChI']=label","295be2bb":"submission.to_csv('Submission.csv',index=False)","d197ed0b":"## You can use this code to make predictions and save it","3b87c8a9":"# Making Custom DataGenerator For Our Model","348020ab":"# Making the model","deb0262c":"# Saving the results","a15ed42f":"# Making CTC Layer","f2208a7e":"# One Prediction :)","aab37104":"# Making Predictions Model","48d928cf":"# Since there is a lot of testing data this might take some time have a snack :)","61a2657a":"# The Results Are Not too similar to baseline for sure :)","373f8c6f":"## Loading Predictions","a05e8214":"# Releasing Some RAM","0b1fbc79":"# Importing Libraries","6cdc10a6":"# Making Required changes and adding columns","d0cf8368":"# Load Model If Not Training Again","b5576c17":"# Importing Data","7bc671d8":"# Transform Function","737f4528":"# Getting to know Part 1 column better :)","077c4623":"# Training The Model"}}