{"cell_type":{"8756d13f":"code","3115f6ea":"code","c4da5603":"code","9f6c99e5":"code","5b25a957":"code","f762498a":"code","3e7a97c5":"code","bbbf120d":"code","0a14a66b":"code","e3f7949d":"code","760f984f":"code","d8fcb0f5":"code","c4e269d7":"code","9be1b009":"code","81f4fcda":"code","6b96d128":"code","ed749065":"code","b9d12e21":"code","7775f0fa":"code","d7b4e013":"code","ee830093":"code","e34c0563":"code","482ad065":"code","cc3afa4e":"code","1770bb6f":"code","50ebe876":"code","8c99775e":"code","96a4c09d":"code","49f48cb4":"code","7da989eb":"code","7b9f7d34":"code","c286a2d7":"code","c681a91d":"code","d96380a7":"code","99103ab4":"code","249787cd":"code","8603b162":"code","0cd5e90a":"code","cc4eda50":"code","f1113e7c":"code","a423dfe4":"code","8ee32950":"code","2decdbcd":"code","9d14af14":"code","e3691cec":"code","0faa29da":"code","ff02273a":"code","05164663":"code","2224a574":"code","eda8d857":"code","f1f4e22e":"code","7e1daf51":"code","f8ed4df9":"code","04f08fb6":"code","e994885f":"code","23a337be":"code","cd1b4f02":"code","d84215d4":"code","2fd105be":"code","91468e2e":"code","b3782bed":"code","a1088044":"code","a65a82c9":"code","760e6100":"code","ae4c4c42":"code","2cc4b665":"code","594b5785":"code","82414ff3":"code","029ded1e":"code","d7b74521":"code","ceabd172":"code","79a36726":"code","61f45030":"code","a3282e13":"code","e9b70c6e":"code","d9ba0dc3":"code","c2546863":"code","de17312c":"code","7895efbe":"markdown","0f75e706":"markdown","b9fe15bf":"markdown","f6e35385":"markdown","ea121b0e":"markdown","c028f78f":"markdown","52e2e5e4":"markdown","4b0378a0":"markdown","25bd0d40":"markdown","04fcf47a":"markdown","7f3853a2":"markdown","f217505f":"markdown","23236541":"markdown","db0e0f6f":"markdown","ca7f44e8":"markdown","7474b679":"markdown","5480e848":"markdown","9b63d117":"markdown","b1b5530d":"markdown","d094fc29":"markdown","21f12ca0":"markdown","4d8cd9d8":"markdown","7ee8ebc7":"markdown","eece80ad":"markdown","f3881d18":"markdown","0bc51df2":"markdown","d47ed1f3":"markdown","c26b332c":"markdown","69a8c4c3":"markdown","abb374e9":"markdown","ba0fdafd":"markdown","7beeb3ae":"markdown","60b8bb75":"markdown","dc984af7":"markdown","a1c60c54":"markdown","ef68113f":"markdown","ca52b3ed":"markdown","4a4a6b5a":"markdown","bbdd1a5b":"markdown","e43be078":"markdown","d48a45e3":"markdown","0a2f003e":"markdown","9a92f7ff":"markdown","b7b29300":"markdown","2b0d9912":"markdown","3106b9a8":"markdown","950854bd":"markdown","f9661414":"markdown","303ee44e":"markdown","abf97399":"markdown","0e276d75":"markdown","15948174":"markdown","fb568706":"markdown","766e8779":"markdown","650ceed0":"markdown","7d880081":"markdown"},"source":{"8756d13f":"import numpy as np\nimport pandas as pd \nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.cluster import KMeans\n\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","3115f6ea":"# specify encoding to deal with different formats\ndf = pd.read_csv('..\/input\/ecommerce-data\/data.csv', encoding = 'ISO-8859-1')\nprint(df)\n","c4da5603":"print(df.dtypes)","9f6c99e5":"df.describe()","5b25a957":"Cancellations = []\n\nfor i in range(len(df)):\n    \n    if \"c\" in df[\"InvoiceNo\"].loc[i] or \"C\" in df[\"InvoiceNo\"].loc[i] :\n        \n        Cancellations.append(1)\n        \n    else:\n        pass\n\nprint(\"No of cancellations: \", len(Cancellations))","f762498a":"df['InvoiceDate']= pd.to_datetime(df['InvoiceDate'])\n\ndf.set_index(np.arange(0,len(df),1),inplace=True)\nneg_df = df[df[\"Quantity\"]<0]\npos_df = df[~df[\"Quantity\"]<0]\n\nprint(\"No of total negative quantity: \",len(neg_df))","3e7a97c5":"neg_df.head(50)","bbbf120d":"check_for_truth = []\n\nfor j in neg_df.index:  \n    \n        for_ref = pos_df[(neg_df[\"CustomerID\"].loc[j]==pos_df[\"CustomerID\"]) & \\\n        (neg_df[\"Description\"].loc[j]==pos_df[\"Description\"])\\\n         &  (neg_df[\"InvoiceDate\"].loc[j]>pos_df[\"InvoiceDate\"]) & \\\n         (abs(neg_df[\"Quantity\"].loc[j])<=pos_df[\"Quantity\"])]\n        \n        if len(for_ref)>0:\n            print(\"Refunds exists\")\n            break    \n        \n        \n","0a14a66b":"df_neg = neg_df[['Quantity','Description']].groupby(\"Description\").sum()\ndf_neg[\"Quantity\"] = abs(df_neg[\"Quantity\"])\n\nplt.figure(figsize=(10,10))\ndf_neg = df_neg.nlargest(10,columns=\"Quantity\")\nplt.title(\"Top 10 items that were refunded\")\nplt.pie(df_neg[\"Quantity\"].to_list(),labels=df_neg.index,autopct='%1.1f%%')\nplt.show()","e3f7949d":"print(df[df.Description==\"printing smudges\/thrown away\"])\n\nprint(df[df.Description==\"Unsaleable, destroyed.\"])\n\nprint(df[df.Description==\"check\"])","760f984f":"neg_df.Description = neg_df.Description.astype(str)\nneg_df[\"Description\"] = neg_df[\"Description\"].apply(lambda x:np.nan if x.lower() == \"nan\" else x)\nneg_df.dropna(inplace=True)\n\ndf_neg = neg_df[['Quantity','Description']].groupby(\"Description\").sum()\ndf_neg[\"Quantity\"] = abs(df_neg[\"Quantity\"])\n\nplt.figure(figsize=(10,10))\ndf_neg = df_neg.nlargest(10,columns=\"Quantity\")\nplt.title(\"Top 10 items that were refunded\")\nplt.pie(df_neg[\"Quantity\"].to_list(),labels=df_neg.index,autopct='%1.1f%%')\nplt.show()","d8fcb0f5":"print(df[df.Description==\"Manual\"])\n\nprint(df[(df.InvoiceNo==\"536569\") & (df.CustomerID==16274)])","c4e269d7":"neg_price = df[df[\"UnitPrice\"]<0]\nprint(neg_price)","9be1b009":"df = df[df[\"UnitPrice\"]>0]","81f4fcda":"df = df.drop_duplicates(keep='first')\ndf.isnull().sum()","6b96d128":"df[\"Description\"] = df[\"Description\"].apply(lambda x:np.nan if x.lower() == \"nan\" else x)\nprint(df.isnull().sum()) # Seems to be zero for zero unit price","ed749065":"print(df[df[\"CustomerID\"].isna()])","b9d12e21":"# String nan\ncolumns = [\"InvoiceNo\",\"StockCode\",\"Country\",\"Description\"]\nfor column in columns:\n    print(column)\n    df[column] = df[column].apply(lambda x:np.nan if x.lower==\"nan\" else x)   \n  \ndf.dropna(inplace=True)\nprint(df)","7775f0fa":"df_sc = df[df.StockCode.str.len()<5]\nprint(df_sc[\"StockCode\"].value_counts())","d7b4e013":"print(\"POST\",df_sc[df_sc.StockCode==\"POST\"][\"Description\"].head(1))\nprint(\"DOT\",df_sc[df_sc.StockCode==\"DOT\"][\"Description\"].head(1)) \nprint(\"M\",df_sc[df_sc.StockCode==\"M\"][\"Description\"].head(1)) \nprint(\"C2\",df_sc[df_sc.StockCode==\"C2\"][\"Description\"].head(1))\nprint(\"D\",df_sc[df_sc.StockCode==\"D\"][\"Description\"].head(1)) \nprint(\"S\",df_sc[df_sc.StockCode==\"S\"][\"Description\"].head(1))\nprint(\"CRUK\",df_sc[df_sc.StockCode==\"CRUK\"][\"Description\"].head(1))\nprint(\"PADS\",df_sc[df_sc.StockCode==\"PADS\"][\"Description\"].head(1))\nprint(\"B\",df_sc[df_sc.StockCode==\"B\"][\"Description\"].head(1))\nprint(\"M\",df_sc[df_sc.StockCode==\"M\"][\"Description\"].head(1))","ee830093":"df_sc = df[(df.StockCode.str.len()>5)]\nprint(df_sc.head(2))\ndf_sc = df[(df.StockCode.str.len()>6)]\nprint(df_sc.head(2))\ndf_sc = df[(df.StockCode.str.len()>7)]\nprint(df_sc.head(2))","e34c0563":"df = df[~((df.StockCode.str.len()<5) & (df.StockCode!=\"D\"))]\ndf = df[df.StockCode.str.lower() !=\"bank charges\"]","482ad065":"stock_code_df = df[[\"StockCode\",\"Description\"]].groupby(\"StockCode\")[\"Description\"].nunique()\nstock_code_df = stock_code_df.sort_values(ascending=False)\nplt.figure(figsize=(20,10))\nstock_code_df.head(100).plot(kind='bar')","cc3afa4e":"stockcode = df[[\"StockCode\",\"Description\"]].groupby(\"StockCode\")[\"Description\"].unique()\nprint(\"Product for stock code 23196: \" + stockcode.at[\"23196\"])\n\nprint(\"Product for stock code 23236: \" + stockcode.at[\"23236\"])\n\nprint(\"Product for stock code 21243: \" + stockcode.at[\"21243\"])","1770bb6f":"df[\"Individual Revenue\"] = df[\"Quantity\"]*df[\"UnitPrice\"]\n\n# Group by geopgraphical distribution\ndf_revenue = df[[\"Country\",\"Individual Revenue\"]].groupby(\"Country\").sum()\ndf_customers = df[[\"Country\",\"CustomerID\"]].groupby(\"Country\").nunique()\ndf_customers.rename(columns ={\"CustomerID\":\"Number of customers\"},inplace=True)","50ebe876":"df_revenue[\"% of total revenue\"] = df_revenue[\"Individual Revenue\"]*100\/np.sum(df_revenue[\"Individual Revenue\"])\ndf_revenue.reset_index(inplace=True)\n\ndf_customers[\"% of total customers\"] = df_customers[\"Number of customers\"]*100\/np.sum(df_customers[\"Number of customers\"])\ndf_customers.reset_index(inplace=True)","8c99775e":"fig, ax = plt.subplots(nrows=1, ncols=2,sharey = True, figsize=(20,10))\n\nax[0].title.set_text('% of total revenue by country')\ng1 = sns.barplot(x= \"% of total revenue\",y= \"Country\",\n                data=df_revenue,\n                ax=ax[0])\n\nax[1].title.set_text('% of total customers by country')\ng2 = sns.barplot(x= \"% of total customers\",y= \"Country\",\n                data=df_customers,\n                ax=ax[1])\n\n","96a4c09d":"plt.figure(figsize=(20,20))\nsns.violinplot(x=\"UnitPrice\", y=\"Country\",\n                    data=df[df[\"Individual Revenue\"]>0],order=[\"EIRE\",\"Netherlands\", \"Germany\"],\n                    )\nplt.title(\"Violin plot of unit price with respect to the selected country (not for refunds)\")\nplt.show()","49f48cb4":"df[\"Seasonality\"] = \"Non seasonal\"\n\n# November, December are the seasonal months for sales\n\ndf.loc[df.InvoiceDate.dt.month.isin([11,12]),\"Seasonality\"] = \"Seasonal\"\n\nplt.figure(figsize=(20,20))\nsns.violinplot(x=\"UnitPrice\", y=\"Country\",\n                    data=df[df[\"Individual Revenue\"]>0],order=[\"EIRE\",\"Netherlands\", \"Germany\"],\n                    hue=\"Seasonality\",split=True)\nplt.title(\"Violin plot of unit price with respect to the selected country considering the seasonality (not for refunds)\")\nplt.show()","7da989eb":"df_price_analysis = df[(df[\"Individual Revenue\"]>0) & (df['StockCode']!=\"D\")]\n\n# Find optimal number of clusters\n\nSum_of_squared_distances_Price = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(df_price_analysis[\"UnitPrice\"].values.reshape(-1,1))\n    Sum_of_squared_distances_Price.append(km.inertia_)\n    \nplt.plot(K, Sum_of_squared_distances_Price, 'bx-')\nplt.title('Elbow Method For Optimal k - Unit Price')\nplt.show()","7b9f7d34":"# Optimal number of clusters\nk=6\n\nCluster_labels = []\nkmeans = KMeans(n_clusters=k).fit(df_price_analysis[\"UnitPrice\"].values.reshape(-1,1))\n# Order kmeans in sequential order\n# https:\/\/stackoverflow.com\/questions\/44888415\/how-to-set-k-means-clustering-labels-from-highest-to-lowest-with-python\nidx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\nlut = np.zeros_like(idx)\nlut[idx] = np.arange(k)\n\ndf_price_analysis[\"Labels_UnitPrice\"] = lut[kmeans.labels_]","c286a2d7":"sns.catplot(x=\"Labels_UnitPrice\", y=\"UnitPrice\", kind=\"box\", data=df_price_analysis)\nplt.show()","c681a91d":"df_high_share = df_price_analysis[(df_price_analysis[\"Labels_UnitPrice\"]>=3) & (df_price_analysis[\"Country\"]!=\"United Kingdom\")]\n\nfig = px.pie(df_high_share, values='Quantity', names=\"Country\",title=\"Distribution of high priced products sold with respect to different countries (apart from UK)\")\nfig.update_layout(title_x=0.5)\nfig.show()","d96380a7":"fig = px.treemap(df_high_share[(df_high_share[\"Country\"]==\"EIRE\") | (df_high_share[\"Country\"]==\"Netherlands\")], \\\n                                path=['Description'], values = \"Quantity\", title=\"Treemap of the most profitable products according to their quantity for Netherlands and EIRE\")\nfig.data[0].hovertemplate = '%{label}<br>%{value}'\nfig.update_layout(title_x=0.5)\nfig.show()","99103ab4":"df_neth = df[df.Country==\"Netherlands\"]\ndf_EIRE = df[df.Country==\"EIRE\"]\ndf_Germany = df[df.Country==\"Germany\"]\ndf_UK = df[df.Country==\"United Kingdom\"]\n\ndf_neth = df_neth.groupby(\"Description\").sum()\ndf_EIRE = df_EIRE.groupby(\"Description\").sum()\ndf_Germany = df_Germany.groupby(\"Description\").sum()\ndf_UK = df_UK.groupby(\"Description\").sum()","249787cd":"df_neth = df_neth.nlargest(10,columns=\"Quantity\")\ndf_neth = df_neth.groupby(\"Description\").sum()\ndf_neth.reset_index(inplace=True)\nplt.figure(figsize=(20,20))\nplt.title(\"Top 10 selling items in Netherlands\")\nsns.barplot(x=\"Quantity\",y=\"Description\",data=df_neth,palette='dark')\nplt.show()\n\ndf_EIRE = df_EIRE.nlargest(10,columns=\"Quantity\")\ndf_EIRE = df_EIRE.groupby(\"Description\").sum()\ndf_EIRE.reset_index(inplace=True)\nplt.figure(figsize=(20,20))\nplt.title(\"Top 10 selling items in EIRE\")\nsns.barplot(x=\"Quantity\",y=\"Description\",data=df_EIRE,palette='dark')\nplt.show()\n\ndf_Germany = df_Germany.nlargest(10,columns=\"Quantity\")\ndf_Germany = df_Germany.groupby(\"Description\").sum()\ndf_Germany.reset_index(inplace=True)\nplt.figure(figsize=(20,20))\nplt.title(\"Top 10 selling items in Germany\")\nsns.barplot(x=\"Quantity\",y=\"Description\",data=df_Germany,palette='dark')\nplt.show()\n\ndf_UK = df_UK.nlargest(10,columns=\"Quantity\")\ndf_UK = df_UK.groupby(\"Description\").sum()\ndf_UK.reset_index(inplace=True)\nplt.figure(figsize=(20,20))\nplt.title(\"Top 10 selling items in UK\")\nsns.barplot(x=\"Quantity\",y=\"Description\",data=df_UK,palette='dark')\nplt.show()","8603b162":"df_basket = df[df[\"Individual Revenue\"]>0]\nbasket_Netherlands = df_basket[df_basket['Country']==\"Netherlands\"].groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\nbasket_EIRE = df_basket[df_basket['Country']==\"EIRE\"].groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\nbasket_Germany = df_basket[df_basket['Country']==\"Germany\"].groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\nbasket_UK = df_basket[df_basket['Country']==\"United Kingdom\"].groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')","0cd5e90a":"def encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n\nbasket_sets_Neth = basket_Netherlands.applymap(encode_units)\nbasket_sets_EIRE = basket_EIRE.applymap(encode_units)\nbasket_sets_Germany = basket_Germany.applymap(encode_units)\nbasket_sets_UK = basket_UK.applymap(encode_units)","cc4eda50":"frequent_itemsets = apriori(basket_sets_Neth, min_support=0.05, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric=\"lift\")\nrules.sort_values(['lift','support'],ascending=False,inplace=True)\nrules.head(10)","f1113e7c":"frequent_itemsets = apriori(basket_sets_EIRE, min_support=0.05, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric=\"lift\")\nrules.sort_values(['lift','support'],ascending=False,inplace=True)\nrules.head(10)","a423dfe4":"frequent_itemsets = apriori(basket_sets_Germany, min_support=0.05, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric=\"lift\")\nrules.sort_values(['lift','support'],ascending=False,inplace=True)\nrules.head(10)","8ee32950":"frequent_itemsets = apriori(basket_sets_UK, min_support=0.02, use_colnames=True)\nrules = association_rules(frequent_itemsets, metric=\"lift\")\nrules.sort_values(['lift','support'],ascending=False,inplace=True)\nrules.head(10)","2decdbcd":"# change the invoice_date format from string to timestep\ndf['OrderPeriod'] = df.InvoiceDate.apply(lambda x: x.strftime('%Y-%m'))\ndf = df[df.Country==\"United Kingdom\"]\n\ndf.set_index('CustomerID', inplace=True)\ndf['CohortGroup'] = df.groupby(['CustomerID'])['InvoiceDate'].min().apply(lambda x: x.strftime('%Y-%m'))\ndf.reset_index(inplace=True)\ndf.drop(columns=[\"Country\",\"UnitPrice\"],inplace=True)","9d14af14":"cohorts = df.groupby(['CohortGroup', 'OrderPeriod']).agg({'CustomerID': pd.Series.nunique,\"Individual Revenue\":'sum'})\ncohorts.rename(columns={'CustomerID': 'Total Users', \"Individual Revenue\":'Total revenue'}, inplace=True)","e3691cec":"def cohort_period(df):\n    \"\"\"\n    Number of periods after the first purchase for each cohort group\n    \n    \"\"\"\n    df['CohortPeriod'] = np.arange(len(df)) + 1\n    return df\n\ncohorts = cohorts.groupby(level=0).apply(cohort_period)\ncohorts.head(20)","0faa29da":"# reindex the DataFrame\ncohorts.reset_index(inplace=True)\ncohorts.set_index(['CohortGroup', 'CohortPeriod'], inplace=True)\n\n# create individual holding the total revenue of each cohort group\ncohort_revenue = cohorts['Total revenue'].groupby(level=0).first()\nprint(cohort_revenue.head())","ff02273a":"cohorts.drop(columns = [\"OrderPeriod\"],inplace=True)\ncohorts.reset_index(inplace=True)\n\n# For total revenue\ncohorts_customer_revenue = cohorts.pivot(index=\"CohortPeriod\",columns=\"CohortGroup\",values=\"Total revenue\")\nprint(cohorts_customer_revenue.head(10))","05164663":"# Revenue retention\nCustomerRevenueRetentionAnalysis = cohorts_customer_revenue.div(cohort_revenue)\nprint(CustomerRevenueRetentionAnalysis)","2224a574":"plt.figure(figsize=(20,20))\nplt.title('Revenue Retention',fontsize=10, weight = 'bold', color=\"black\")\nsns.heatmap(CustomerRevenueRetentionAnalysis.T, mask=CustomerRevenueRetentionAnalysis.T.isnull(), annot=True,cmap=\"YlGnBu\", fmt='.0%')","eda8d857":"df = df[~df['InvoiceNo'].str.contains('C', na=False)]\ndf = df[df[\"Quantity\"]>0]\n\n# Non consideration of discounts\ndf = df[df[\"StockCode\"]!='D']","f1f4e22e":"# Latest purchase\nmax_date = df[\"InvoiceDate\"].max()\n\nrfm_df = df.groupby(\"CustomerID\").agg({\"InvoiceDate\":lambda date: (max_date - date.max()).days,\n                                      \"InvoiceNo\": 'count',\n                                      \"Individual Revenue\":'sum'})\n\nrfm_df.rename(columns={\"InvoiceDate\":\"Recency\",\"InvoiceNo\":\"Frequency\",\"Individual Revenue\":\"Monetary\"},inplace=True)\nprint(rfm_df)","7e1daf51":"km = KMeans(n_clusters=3)\ncluster_labels = km.fit_predict(rfm_df)\n\n# https:\/\/stackoverflow.com\/questions\/44888415\/how-to-set-k-means-clustering-labels-from-highest-to-lowest-with-python\nidx = np.argsort(km.cluster_centers_.sum(axis=1))\nlut = np.zeros_like(idx)\nlut[idx] = np.arange(3)\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,10))\nsns.boxplot(lut[km.labels_],rfm_df[\"Recency\"].tolist(),ax=ax[0])\nax[0].set(xlabel=\"Clusters\", ylabel = \"Recency in days\")\nax[0].title.set_text('Clusters - Recency')\nsns.boxplot(lut[km.labels_],rfm_df[\"Frequency\"].tolist(),ax=ax[1])\nax[1].set(xlabel=\"Clusters\", ylabel = \"Frequency in Days\")\nax[1].title.set_text('Clusters - Frequency')\nsns.boxplot(lut[km.labels_],rfm_df[\"Monetary\"].tolist(),ax=ax[2])\nax[2].set(xlabel=\"Clusters\", ylabel = \"Total Revenue\")\nax[2].title.set_text('Clusters - Monetary')","f8ed4df9":"rfm_df[\"Cluster labels\"] = lut[km.labels_]","04f08fb6":"typec1 = 'Customers who may or may have not bought recently,do not buy frequently enough and contribute the least' # 0\ntypec3 = 'Customers who have not bought recently, do not buy frequently enough but contribute the most'        # 2\ntypec2 = 'Customers who may or may have not bought recently, may or may not buy frequently enough but contribute sufficiently'# 1\n\ndef func(x):\n    if x == 0:\n        return typec1\n    elif x == 2:\n        return typec3\n    elif x == 1:\n        return typec2\n    else:\n        return 'N\/A'\n\nrfm_df[\"Customer segments\"] = rfm_df[\"Cluster labels\"].apply(func)\nprint(rfm_df)","e994885f":"plt.figure(figsize=(10,10))\n\nfig = px.pie(rfm_df, names='Customer segments',title=\"Distribution of customer buying behaviour\")\nfig.data[0].hovertemplate = '%{label}'\nfig.update_layout(showlegend=False, title_x=0.5)\nfig.show()\n\nplt.figure(figsize=(10,10))\n\nfig = px.pie(rfm_df, names='Customer segments',title=\"Distribution of customer buying behaviour with revenue\",values=\"Monetary\")\nfig.data[0].hovertemplate = '%{label}'\nfig.update_layout(showlegend=False, title_x=0.5)\nfig.show()","23a337be":"# Find optimal number of clusters\n\nSum_of_squared_distances_rec = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(rfm_df[\"Recency\"].values.reshape(-1,1))\n    Sum_of_squared_distances_rec.append(km.inertia_)\n    \nSum_of_squared_distances_freq = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(rfm_df[\"Frequency\"].values.reshape(-1,1))\n    Sum_of_squared_distances_freq.append(km.inertia_)\n    \n    \nSum_of_squared_distances_mon = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(rfm_df[\"Monetary\"].values.reshape(-1,1))\n    Sum_of_squared_distances_mon.append(km.inertia_)\n \nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,10))\nax[0].plot(K, Sum_of_squared_distances_rec, 'bx-')\nax[0].set_title('Elbow Method For Optimal k - Recency')\n\n\nax[1].plot(K, Sum_of_squared_distances_freq, 'bx-')\nax[1].set_title('Elbow Method For Optimal k - Frequency')\n\n\nax[2].plot(K, Sum_of_squared_distances_mon, 'bx-')\nax[2].set_title('Elbow Method For Optimal k - Monetary')\n\nfor a in ax.flat:\n    a.set(xlabel='k', ylabel='Sum_of_squared_distances')\n    \n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor a in ax.flat:\n    a.label_outer()\n    \nplt.show()","cd1b4f02":"k=5\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,10))\nlabels = [\"Recency\",\"Frequency\",\"Monetary\"]\n\nCluster_labels = []\n\nfor i in range(len(labels)):\n    kmeans = KMeans(n_clusters=k).fit(rfm_df[labels[i]].values.reshape(-1,1))   \n    idx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\n    lut = np.zeros_like(idx)\n    lut[idx] = np.arange(k)\n    \n\n    dict = {\n    labels[i]: rfm_df[labels[i]].tolist(),\n     \"Cluster_labels\": list(lut[kmeans.labels_])\n     }\n    param_df=pd.DataFrame.from_dict(dict,orient='index').transpose()\n    sns.boxplot(x=\"Cluster_labels\", y=labels[i], data=param_df,ax=ax[i])\n    \n    ax[i].set(xlabel=\"Cluster labels\", ylabel = labels[i])\n    ax[i].title.set_text(\"Clustering \" + labels[i])\n    \n        \n    rfm_df[\"Cluster labels - \" + str(labels[i])] = list(lut[kmeans.labels_])\n\n    \n    \nplt.show()\n","d84215d4":"# https:\/\/guillaume-martin.github.io\/rfm-segmentation-with-python.html\n\nsegt_map = {\n    r'[0-1][0-1]': 'First timers - SMS ads',\n    r'[0-1][2-3]': 'At risk - Discounts',\n    r'[0-1]4': 'Immediate targeting - Promotions',\n    r'2[0-1]': 'About to lose - Feedback form',\n    r'[2-3][3-4]': 'Regular customers - Loyalty cards',\n    r'30': 'Promising - Instant vouchers',\n    r'40': 'New customers - 50 % discounts on certain items',\n    r'[3-4][1-2]': 'Potential regular customers - Loyalty cards',\n    r'4[3-4]': 'Best customers - Loyalty cards',\n    r'22': 'Need attention - Discounts'\n}  # For example if customers hasn't bought for a long time and has tried the shop only once, an SMS ad might     \n   # rekindle interest\n\n\nrfm_df[\"RFM class\"] = rfm_df['Cluster labels - Recency'].apply(str)+ rfm_df['Cluster labels - Frequency'].apply(str) + \\\nrfm_df['Cluster labels - Monetary'].apply(str)\n\n# Marketing strategy based on recency and frequnecy of shopping alone\nrfm_df['Marketing strategy'] = rfm_df['Cluster labels - Recency'].apply(str)+ rfm_df['Cluster labels - Frequency'].apply(str)\nrfm_df['Marketing strategy'] = rfm_df['Marketing strategy'].replace(segt_map, regex=True)\nrfm_df.head(5)","2fd105be":"fig = px.treemap(rfm_df, path=['Marketing strategy'],title =\"Treemap of marketing strategies\")\nfig.data[0].hovertemplate = '%{label}'\nfig.update_layout(title_x=0.5)\nfig.show()","91468e2e":"# Latest purchase\nmax_date = df[\"InvoiceDate\"].max()\n\n# Analysis done with stock code as similar stock code denotes same type of item from multiple suppliers. Hence, there \n# is a flexibility for the supplier to buy the same product from multiple suppliers\nIM_df = df.groupby(\"StockCode\").agg({\"InvoiceDate\":lambda date: (max_date - date.max()).days,\n                                      \"Quantity\": 'sum',\n                                      \"Individual Revenue\":'sum'})\n\nIM_df.rename(columns={\"InvoiceDate\":\"Recency\",\"Quantity\":\"Frequency\",\"Individual Revenue\":\"Monetary\"},inplace=True)\n","b3782bed":"# Find optimal number of clusters\n\nSum_of_squared_distances_freq = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(IM_df[\"Recency\"].values.reshape(-1,1))\n    Sum_of_squared_distances_freq.append(km.inertia_)\n    \nplt.plot(K, Sum_of_squared_distances_freq, 'bx-')\nplt.title('Elbow Method For Optimal k - Frequency')\nplt.show()","a1088044":"k=5\n\nCluster_labels = []\nkmeans = KMeans(n_clusters=k).fit(IM_df[\"Frequency\"].values.reshape(-1,1))\nidx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\nlut = np.zeros_like(idx)\nlut[idx] = np.arange(k)\n    \ndict = {\n\"Frequency\": IM_df[\"Frequency\"].tolist(),\n\"Cluster_labels\": list(lut[kmeans.labels_])\n}\nparam_df=pd.DataFrame.from_dict(dict,orient='index').transpose()\nsns.boxplot(x=\"Cluster_labels\", y=\"Frequency\", data=param_df)\n\nplt.title(\"Clustering \" + \"Frequency\")\n    \nIM_df[\"Cluster labels - \" + \"Frequency\"] = list(lut[kmeans.labels_])    \n    \nplt.show()\n","a65a82c9":"IM_df.loc[IM_df[\"Cluster labels - Frequency\"]==0,\"Cluster labels - Frequency\"]= \"Low purchase rate\"\nIM_df.loc[IM_df[\"Cluster labels - Frequency\"]==1,\"Cluster labels - Frequency\"]= \"Lower mid purchase rate\"\nIM_df.loc[IM_df[\"Cluster labels - Frequency\"]==2,\"Cluster labels - Frequency\"]= \"Mid purchase rate\"\nIM_df.loc[IM_df[\"Cluster labels - Frequency\"]==3,\"Cluster labels - Frequency\"]= \"Higher mid purchase rate\"\nIM_df.loc[IM_df[\"Cluster labels - Frequency\"]==4,\"Cluster labels - Frequency\"]= \"Higher purchase rate\"","760e6100":"fig = px.treemap(IM_df, path=['Cluster labels - Frequency'],values=\"Monetary\", title=\"Treemap of product purchase rate with revenue\")\nfig.data[0].hovertemplate = '%{label}<br>%{value}'\nfig.update_layout(title_x=0.5)\nfig.show()","ae4c4c42":"print(IM_df[IM_df[\"Cluster labels - Frequency\"]==\"Higher purchase rate\"].head(10))","2cc4b665":"df[\"Seasonality\"] = \"Non seasonal\"\n\n# November, December are the seasonal months for sales\n# https:\/\/www.statista.com\/topics\/6297\/holiday-retail-in-the-uk\/#:~:text=Typically%2C%20during%20the%20months%20of,seen%20even%20more%20elevated%20numbers.\n\ndf.loc[df.InvoiceDate.dt.month.isin([11,12]),\"Seasonality\"] = \"Seasonal\"\n\nfig = px.pie(df, values='Individual Revenue', names=\"Seasonality\",title=\"Distribution of revenue according to seasonal and non seasonal sales\")\nfig.update_layout(title_x=0.5)\nfig.show()","594b5785":"Seasonal_df = df[df.Seasonality== \"Seasonal\"]\nNon_Seasonal_df = df[df.Seasonality== \"Non seasonal\"]","82414ff3":"Seasonal_df = Seasonal_df[[\"Quantity\",\"StockCode\"]].groupby(\"StockCode\").sum()\nNon_Seasonal_df  = Non_Seasonal_df[[\"Quantity\",\"StockCode\"]].groupby(\"StockCode\").sum()\n\nNon_Seasonal_df.rename(columns={\"Quantity\":\"IR_nonseasonal\"},inplace=True)\nSeasonal_df.rename(columns={\"Quantity\":\"IR_seasonal\"},inplace=True)\n","029ded1e":"mergedDf = Non_Seasonal_df.merge(Seasonal_df, left_index=True, right_index=True)","d7b74521":"# Find optimal number of clusters\n\nSum_of_squared_distances_freq = []\nK = range(1,10)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(mergedDf.values.reshape(-1,1))\n    Sum_of_squared_distances_freq.append(km.inertia_)\n    \nplt.plot(K, Sum_of_squared_distances_freq, 'bx-')\nplt.title('Elbow Method For Optimal k - Frequency')\nplt.show()","ceabd172":"k = 6\nkmeans = KMeans(n_clusters=k)\nclustered_cust = kmeans.fit_predict(mergedDf[['IR_nonseasonal','IR_seasonal']])\n\n# Ordering\nidx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\nlut = np.zeros_like(idx)\nlut[idx] = np.arange(k)\nmergedDf['cluster'] = list(lut[kmeans.labels_])\n\nplt.figure(figsize=(15,10))\ng1 = sns.scatterplot(mergedDf['IR_nonseasonal'],mergedDf['IR_seasonal'],hue=mergedDf['cluster'],palette=\"dark\")\ng1.set_xscale(\"log\")\nplt.xlabel('Seasonal orders')\nplt.title('Orders: Seasonal and non-seasonal segmentation by KNN')\nplt.ylabel('Non seasonal orders')","79a36726":"print(mergedDf)","61f45030":"df = pd.merge(df, mergedDf, left_on=\"StockCode\", right_index=True)\ndf.drop(columns=[\"Seasonality\",\"IR_nonseasonal\",\"IR_seasonal\"],inplace=True)\nprint(df.head(5))","a3282e13":"df[\"weeks\"] = df[\"InvoiceDate\"].dt.week\nprint(df)","e9b70c6e":"week_df = df[[\"Quantity\",\"cluster\",\"weeks\"]].groupby([\"cluster\",\"weeks\"]).sum()","d9ba0dc3":"# Number of clusters defined earlier\nclusters = np.arange(0,k,1)\n\nfor cluster in clusters:\n    plt.figure(figsize=(30,10))\n    sub_df = week_df.loc[cluster,:]\n    sub_df.reset_index(inplace=True)\n    \n    sns.lineplot(data=sub_df, x=\"weeks\", y=\"Quantity\")\n    plt.title(\"Orders for cluster \"+ str(cluster+1))\n    plt.show()","c2546863":"# Products in cluster 6\nprint(\"Products in demand in the month of January: \" + df[df.cluster==5][\"Description\"].unique()[0])\n","de17312c":"fig = px.pie(df[df.cluster==3], values='Quantity', names=\"Description\",\\\n             title=\"Distribution of orders for products sold throughout the year\")\nfig.update_layout(title_x=0.5)\nfig.show()","7895efbe":"- This could probably be customers whose details have not been taken down\n- To ensure our analysis are correct, drop rows with null values throughout\n- Additionally some items are coded less than 5, they seem to some kind of delivery charge","0f75e706":"- These seem to be additional charges for delivery and additional services. It would be better to remove them as they might inflate the revenue figures (except for discount)\n- Before that, let's check for stock code greater than 5","b9fe15bf":"## Conclusion - Inventory management\n\n- Company can do their inventory management either by replinishing their stocks by the frequency of products being sold\n- or prioritising the amount of products sold in seasonal or non-seasonal months","f6e35385":"## Customer segmentation will be achieved with an RFM matrix. It has three indicators \n```\n1. Recency - When the customer last bought from the store. Calculated with the difference between the last date of purchase ever to date of purchase\n2. Frequency - No of times customer has bought from the store\n3. Monetary - Total purchase from the customer\n```","ea121b0e":"- Analysing the stock code later can be helpful","c028f78f":"- Since this does not count as a customer, let's delete it ","52e2e5e4":"- 2010-12, 2011-01 and 2011-08 period has the highest revenue retention among all the periods. Maybe during these periods, the company had a effective marketing strategy. \n","4b0378a0":"- Market basket analysis for Netherlands","25bd0d40":"Some attributes of the data\n\n```\nInvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\nStockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\nDescription: Product (item) name. Nominal.\nQuantity: The quantities of each product (item) per transaction. Numeric.\nInvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\nUnitPrice: Unit price. Numeric, Product price per unit in sterling.\nCustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\nCountry: Country name. Nominal, the name of the country where each customer resides.\n```","04fcf47a":"# Study of distribution of sales and customers for each country","7f3853a2":"- Nearly 27 % of the sales come from the holiday months alone. Hence significant attention has to be paid to the products that are sold during this period in order to ensure that these stocks don't run out","f217505f":"- One way of customer segmentation is through dividing it with quantiles.\n- Another way is use unsupervised learning to divide into segments.","23236541":"- Null values need to be deleted later\n- What's manual?","db0e0f6f":"# Data cleaning","ca7f44e8":"## Products which are profitable\n- United Kingdom has the highest share of customers and revenue\n- Netherlands and ERIE have a lower share of customers but a higher share of revenue compared to Germany which has an equivalent amount of revenue and customers\n- This could be due to customer buying behaviour prefering higher priced products. However, it is essential to know these products as they can drive revenue and profitability with a lower customer share\n","7474b679":"- Delete additional and bank charges as bank charges might be due to transaction charges and will inflate actual revenue to the company through customers","5480e848":"- Since, they lack a CustomerID, they could be refunds at the company level i.e. refunds during purchase from the supplier\n- Let's delete null values and find correctly the items that were refunded","9b63d117":"- Remove possible duplicates and check for null values","b1b5530d":"### Top 10 selling products in Netherlands,EIRE,UK and Germany in terms of quantity","d094fc29":"## Inventory management as per purchase rate","21f12ca0":"- Market basket analysis for Germany","4d8cd9d8":"- Let's find the products which belong to this range which are driving the sales in Netherlands and EIRE","7ee8ebc7":"### Finding the optimal number of clusters","eece80ad":"-  From the data from Germany, UK and ERIE, indication of bulk purchases of similar type of goods seems to be happening.\n- This indicates that they are probably being bought by a wholesale retailer","f3881d18":"- These products have an almost equitable distribution between seasonal and non-seasonal months\n- In order to find these products or stock codes, we can implement K-means to segment these products","0bc51df2":"# Derivation of marketing strategies","d47ed1f3":"- Apart from an indicator of FOLDING BUTTERFLY MIRROR being bought in bulk,probably from a large bulk supplier. 10 COLOUR SPACEBOY PEN seems to be commonly associated with other supplies as indicated by it's high lift and consequnce when it is an ancedent","c26b332c":"- 5 clusters seem to be an acceptable number of clusters for frequncy, Recency and Monetary values","69a8c4c3":"Lets look at the stock code especially where there are instance of codes with length less than 5","abb374e9":"- Similar preferences in Netherlands, EIRE and Germany for sale of goods. However, occasionally higher priced goods are bought in Netherlands and EIRE\n- Let's take this one step further to check if high priced goods are mostly seasonal or not","ba0fdafd":"- Some interesting observations such as the clear segmentation on revenue\n1. Many high paying customers have not bought frequently and recently. \n2. Company haven't gained substantial income from frequent customers\n3. Let's break into segments","7beeb3ae":"- From above, some descriptions are NaN, but they don't appear here.\n- Maybe they are text, let's find them and convert them to null values","60b8bb75":"## Inventory management as per seasonality","dc984af7":"# Inventory management\n\n- As discussed earlier, major share of customers do not buy frequently and contribute individually a lower revenue to the company. Also, these customers also account for the bulk of the monetary value of the company.\n- Hence, inventory management is very critical\n- One strategy is to find products which sell quickly\n- Another involves arranging finding products which sell mostly at particular periods of time (example holidays or particular months)\n- Additionally analysis will be done for UK alone \n","a1c60c54":"Cancellations could amount to the negative quantity. Let's check for refunds. These can happen for\n- Quantity lower than total bought quantity\n- Bought after the purchase date\n- Same customer id","ef68113f":"- Market basket analysis for EIRE","ca52b3ed":"### Let's check which items contribute to the most refunds","4a4a6b5a":"### Customer segmentation by behaviour","bbdd1a5b":"## This notebook aims to answer the follwing questions -:\n- What is the distribution of sales for each geographical region and are there any specific products which drives the revenue or have a higher profit especially in cases where the customer share is low\n- What are the most ordered products in general?\n- Can we find mutually dependant buying patterns (Association Rule mining)?\n- How does the company perform with time. Are they gaining customers or revenue?\n- What are the possible ways to segment customers for efficient targeting and what are the possible ways for efficient marketing?\n- Are there efficient ways for inventory managment?\n","e43be078":"- Here, let's analyse only based on purchases not based on returns or cancellations\n- For UK alone, for targeted marketing","d48a45e3":"- As we can see some of the numerical fields are negative. This could be due to erronous values or refunds \n- This can be checked by comparing whether there are any duplicate invoice numbers or cancellations\n- Letter c indicates cancellations in Invoice number. Lets check that. ","0a2f003e":"## Association rule mining\n- Let's find any interesting relation between products for the top 4 revenue generating countries\n- Reference - https:\/\/pbpython.com\/market-basket-analysis.html\n- https:\/\/www.kaggle.com\/datatheque\/association-rules-mining-market-basket-analysis\n- https:\/\/towardsdatascience.com\/association-rules-2-aa9a77241654\n- https:\/\/www.kaggle.com\/anmoltripathi\/complete-e-commerce-analysis\n","9a92f7ff":"### Possible marketing strategies\n- In order for effective targeting, selective strategy specific to the use case must be undertaken\n- Hence selective clustering for frequency, monetary and recency must be undertaken","b7b29300":"- Groupby stock code as single stock code refers to similar products from different suppliers\n- Reference: https:\/\/www.kaggle.com\/anmoltripathi\/complete-e-commerce-analysis","2b0d9912":"## Would appreciate to receive any feedback. Also upvote if you find the notebook useful","3106b9a8":"# Analyse behaviour of revenue with time with a cohort analysis\n- As the customer list contains some ambiguities with respect to refunds, we can do cohort analysis for revenue as the negative sales values takes effect with addition\n- As marketing varies from different geographical conditions, let's perform cohort analysis for UK alone (Top revenue generation)\n- http:\/\/www.gregreda.com\/2015\/08\/23\/cohort-analysis-with-python\/","950854bd":"- Let's further check stock code. Is each product associated with a single stock code","f9661414":"- Market basket analysis for UK","303ee44e":"- Before I go further, I recieved a lot of interesting ideas from the notebook \"https:\/\/www.kaggle.com\/anmoltripathi\/complete-e-commerce-analysis\" especially on data cleaning, I will be using some of the ideas from that notebook here","abf97399":"- Paper craft little birdie along with medium ceramic top storage jar are the most refunded\n- Refunded item details will not be deleted from the dataframe as they are vital later for correctly finding the revenue retention\n- Additionally there are items mentioned as unsaleable, destroyed, printing smudges\/thrown away which don't point to a specific item. These can be checked with stockcode","0e276d75":"- Products which are brought infrequently contribute to a larger revenue","15948174":"- Major share of customers do not buy frequently and contribute individually a lower revenue to the company\n- However, these customers also account for the bulk of the monetary value of the company.\n- Hence, inventory managment here is very critical\n","fb568706":"- These stocks needs to be replenished at a faster rate as indicated also by their lower recency","766e8779":"- Let's check for negative price","650ceed0":"- Stockcode seems to denote similar items from different suppliers or with different spellings\n- So rather than analysing with product descriptions, it would be advisable with stock codes for some of the analysis","7d880081":"### Observations\n- Cluster 1, Cluster 2, Cluster 3 and Cluster 5 are seasonal in nature. Hence, efforts for restocking them in large numbers must be undertaken mostly in the months of November and December\n- Cluster 4 has a demand throughout the year. Hence, they need to be replinshed throughout\n- Cluster 6 seems to be be in demand mostly in the month of January. "}}