{"cell_type":{"b0dcf2e9":"code","378a9b2c":"code","d680ce98":"code","02c777a3":"code","66081e26":"code","3bae585a":"code","e3e589b2":"code","db4b2f17":"code","895944b0":"code","3c79c3db":"code","1703119e":"code","a02fbc06":"code","95822257":"code","5ff9feb7":"code","737d180f":"code","2a4e50fa":"code","e93bd0b7":"code","5a4c6624":"code","3404b1f1":"code","e13163d2":"code","215e9c04":"code","3236dbea":"markdown","b95f5306":"markdown","76b5f9da":"markdown","687730fd":"markdown","87c103dc":"markdown","bc8df669":"markdown","4f5743bc":"markdown","c38631ec":"markdown","7bec1679":"markdown","6f5c69ad":"markdown","d0cf0005":"markdown","6a3989ec":"markdown","cc7d6ac8":"markdown","5d92f532":"markdown","62956dfc":"markdown","a35dfd38":"markdown","f9970469":"markdown","e3d8913d":"markdown","00940008":"markdown","dae0fd58":"markdown","17099ae6":"markdown"},"source":{"b0dcf2e9":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport numpy as np\nfrom os import listdir\n\n# changing default size and style of plots\nplt.rcParams['figure.figsize'] = [12, 12]\nplt.style.use('fivethirtyeight')\n\n# adjusting chunksize to afford matplotlib speed\nmpl.rcParams['agg.path.chunksize'] = 10000\n\n# merging all csv files into one pandas DataFrame object\ncsv_list = []\nfor file in listdir('..\/input\/cyclistic'):\n    temp_df = pd.read_csv(f'..\/input\/cyclistic\/{file}')\n    csv_list.append(temp_df)\ndf = pd.concat(csv_list)\n\n# a view of our df\ndf.info(memory_usage='deep')","378a9b2c":"# renaming and converting our 'member_casual' column from a list of strings into a series of boolean values\ndf.rename(columns = {'member_casual': 'is_member'}, inplace=True)\ndf.replace({'is_member': {'member': True, 'casual': False}}, inplace=True)\n\n# renaming and converting the 'rideable_type' column from a list of strings into an index [0, 1, 2]\ndf.rename(columns = {'rideable_type': 'is_ebike'}, inplace=True)\ndf.replace({'is_ebike': {'classic_bike': 0, 'electric_bike': 1, 'docked_bike': 2}}, inplace=True)\n\n# casting our time data into datetime objects\ndf['started_at'] = pd.to_datetime(df['started_at'])\ndf['ended_at'] = pd.to_datetime(df['ended_at'])\n\n# creating new columns from our time data\ndf['hour'] = df['started_at'].dt.hour\ndf['ord_day'] = df['started_at'].dt.day_of_year\ndf['week_day'] = df['started_at'].dt.dayofweek\ndf['month'] = df['started_at'].dt.month\n\ndf['ride_minutes'] = (df['ended_at'] - df['started_at'])\ndf['ride_minutes'] = pd.to_numeric(df['ride_minutes']) \/ 6e+10\n    # the result is given in nanoseconds, so we divide by 6e+10 to return minutes\n    \ndf['ride_km'] = np.sqrt( ((df['end_lat'] - df['start_lat'])**2) + ((df['end_lng'] - df['start_lng'])**2) )\n    # formula for distance between two coordinates:\n    # sqrt( (x2-x1)^2 + (y2-y1)^2 ) \ndf['ride_km'] = df['ride_km'] * 111\n    # 111 is an approximate factor for converting degrees of lat\/long seperation into kilometers\n\n# checking our new dataframe for null values\ndf.isnull().sum()","d680ce98":"# statistics that summarize the shape of our dataset\ndf['ride_minutes'].describe(include='all')","02c777a3":"# percent of rides shorter than one minute or longer than four hours\ndrop_filter = (df['ride_minutes'] < 1) | (df['ride_minutes'] > 240)\ndrop_filter.value_counts(normalize=True)","66081e26":"# dropping bad data\ndf.drop(df.index[drop_filter], inplace=True)","3bae585a":"# a new search for null values\ndf.isnull().sum()","e3e589b2":"df.drop(columns=['ride_id',\n                 'start_station_id', 'end_station_id',\n                 'started_at', 'ended_at',\n                 'start_lat', 'start_lng',\n                 'end_lat', 'end_lng'], inplace=True)","db4b2f17":"df = df.round(2)\n\ndf['is_ebike'] = df['is_ebike'].astype('int8')\ndf['ride_minutes'] = df['ride_minutes'].astype('float32')\ndf['month'] = df['month'].astype('int8')\ndf['ord_day'] = df['ord_day'].astype('int16')\ndf['week_day'] = df['week_day'].astype('int8')\ndf['hour'] = df['hour'].astype('int8')\ndf['ride_km'] = df['ride_km'].astype('float32')\n\ndf.info(memory_usage='deep')","895944b0":"casuals = df[df['is_member']==False]\nmembers = df[df['is_member']==True]","3c79c3db":"plt.figure(figsize=(10,10))\nmembers['hour'].value_counts().sort_index().plot.barh(color='#f49264', align='edge', width=-.5, linewidth=.5, edgecolor='k')\ncasuals['hour'].value_counts().sort_index().plot.barh(color='#69a6d1', align='center', width=.5, linewidth=.5, edgecolor='k')\nplt.yticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23], \n           ['12am','1am','2am','3am','4am','5am','6am','7am','8am','9am','10am','11am','12pm','1pm','2pm','3pm','4pm','5pm','6pm','7pm','8pm','9pm','10pm','11pm'], rotation=0)\nplt.xlabel('Total Rides')\nplt.ylabel('Hour')\nplt.title('Total Rides by Hour')\nplt.legend(['Member', 'Casual'])\nplt.show()","1703119e":"plt.figure(figsize=(10,6))\nmembers['week_day'].value_counts().sort_index().plot.bar(color='#f49264', align='edge', width=-.4, linewidth=1, edgecolor='k')\ncasuals['week_day'].value_counts().sort_index().plot.bar(color='#69a6d1', align='edge', width=.4, linewidth=1, edgecolor='k')\nplt.xticks([-1,0,1,2,3,4,5,6], ['', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], rotation=60)\nplt.ylabel('Total Rides')\nplt.title('Total Rides by Day')\nplt.legend(['Member', 'Casual'])\nplt.show()","a02fbc06":"plt.figure(figsize=(10,6))\nmembers['month'].value_counts().sort_index().plot(color='#f49264')\ncasuals['month'].value_counts().sort_index().plot(color='#69a6d1')\nplt.xticks([1,2,3,4,5,6,7,8,9,10,11,12],\n           ['January','February','March','April','May','June','July','August','September','October','November','December'],\n           rotation=60)\nplt.xlabel('Month')\nplt.ylabel('Total Rides')\nplt.title('Total Rides by Month')\nplt.legend(['Member', 'Casual'])\nplt.annotate('unexpected\\n  decrease\\nin ridership',\n             xy=(6.3,145000), xycoords='data', xytext=(7.2,88000),\n            arrowprops={'facecolor': 'black'})\nplt.show()","95822257":"# creating Series objects where 'month' is May, June, or July\ncasual_summer_days = pd.Series((casuals['month'] >= 5) & (casuals['month'] <= 7))\nmember_summer_days = pd.Series((members['month'] >= 5) & (members['month'] <= 7))\n\n# filtering membership type by our aformentioned Series\ncasual_summer_rides = casuals.loc[casual_summer_days]\nmember_summer_rides = members.loc[member_summer_days]\n\nplt.figure(figsize=(14,6))\nmember_summer_rides['ord_day'].value_counts().sort_index().plot(kind='bar', color='#f49264', linewidth=.4, edgecolor='k')\ncasual_summer_rides['ord_day'].value_counts().sort_index().plot(kind='bar', color='#69a6d1', linewidth=.4, edgecolor='k')\nplt.xticks([0, 31, 62],['May','June','July'], rotation=60)\nplt.xlabel('Days')\nplt.ylabel('Rides per Day')\nplt.title('Ridership Type by Day')\nplt.legend(['Member', 'Casual'])\nplt.show()","5ff9feb7":"# a list of all ordinal calender days in 2020 (was a leap year)\ndays_in_2020 = [i for i in range(1,367)]\n\nfor day in df['ord_day']:\n    if day in days_in_2020:\n        days_in_2020.remove(day)\n\n# the resultant list shows only days for which there is no ride data\nprint(days_in_2020)","737d180f":"fig, (time, kms) = plt.subplots(2,1, figsize=(8,8))\n\navg_mem_mins = members['ride_minutes'].mean()\navg_cas_mins = casuals['ride_minutes'].mean()\ntime.barh(['Casual','Member'],[avg_cas_mins,avg_mem_mins], color=['#69a6d1', '#f49264'], linewidth=1, edgecolor='k')\ntime.title.set_text('Average Ride Minutes')\ntime.xaxis.set_ticks_position('top')\n\navg_mem_km = members['ride_km'].mean()\navg_cas_km = casuals['ride_km'].mean()\nkms.barh(['Casual','Member'],[avg_cas_km,avg_mem_km], color=['#69a6d1', '#f49264'], linewidth=1, edgecolor='k')\nkms.title.set_text('Average Ride Kilometers')\nkms.xaxis.set_ticks_position('top')","2a4e50fa":"# 0 - 'classic_bike'\n# 1 - 'electric_bike'\n# 2 - 'docked_bike' (no data about bicycle type)\ndf['is_ebike'].value_counts(normalize=True)","e93bd0b7":"fig, (cas_type, mem_type) = plt.subplots(2,1, figsize=(14,14))\nfig.suptitle('Bike Type Preference', fontsize=24)\n\ncas_type.pie(casuals['is_ebike'].value_counts(normalize=True),\n        colors=['#306f9c','#69a6d1','#b1d1e7'],\n        labels=['No Data','Electric','Classic'],\n        shadow=True, explode=[0, 0.05, 0.05], startangle=90, \n        wedgeprops={'edgecolor':'black', 'linewidth':1},\n        textprops={'size':18, 'color':'#0c1c27', 'family':'fantasy'},\n       autopct='%1.2f%%')\ncas_type.title.set_text('Casuals')\n\nmem_type.pie(members['is_ebike'].value_counts(normalize=True),\n        colors=['#d74e0f','#f49264','#facdb7'],\n        labels=['No Data','Classic','Electric'],\n        shadow=True, explode=[0, 0.05, 0.05], startangle=90, \n        wedgeprops={'edgecolor':'black', 'linewidth':1},\n        textprops={'size':18, 'color':'#0c1c27', 'family':'fantasy'},\n       autopct='%1.2f%%')\nmem_type.title.set_text('Members')","5a4c6624":"# top 10 most common stations for casuals to start a ride\ncasuals['start_station_name'].value_counts().head(10)","3404b1f1":"# top 10 most common stations for members to start a ride\nmembers['start_station_name'].value_counts().head(10)","e13163d2":"# filter is a dataframe object which will then be passed into .loc indexer\n# sorting by time, day of week, and month\ntarget_filter = pd.DataFrame((casuals['hour'] >= 11) & (casuals['hour'] <= 19)\n                               & ((casuals['week_day'] == 5) | (casuals['week_day'] == 6))\n                               & (casuals['month'] >= 5) & (casuals['month'] <= 9))\n\ntarget_stations = casuals.loc[target_filter[0]]\n\ntarget_stations['start_station_name'].value_counts().head(10)","215e9c04":"plt.figure(figsize=(12,12))\ncasuals.plot(x='ride_minutes', y='ride_km', kind='scatter', legend=True, color='#69a6d1', alpha=.5, marker='.')\nax = plt.gca()\nmembers.plot(x='ride_minutes', y='ride_km', kind='scatter', legend=True, color='#f49264', ax=ax, alpha=.5, marker='.')\nplt.xlabel('Duration (minutes)')\nplt.ylabel('Distance (km)')\nplt.title('All Rides by Time and Distance')\nplt.legend(['Casual', 'Member'])\nplt.show()","3236dbea":"The result is a similar, but different, list of stations. This is precisely the information we need to launch a targeted ad campaign which will have the highest exposure to casual riders.\n\n## Review\n\nOur journey through the Cyclistic bike-share data showed us how annual members and casual riders use the service differently, and we were able to garner some delightful insights along the way.  \n\nWe discovered several trends and relationships which aid us in answering our primary business question: how do we increase annual memberships by targeting casual riders?\n\nThe principal differences between members and casual riders can be summized with the following visualization:","b95f5306":"Trimming the 'ride_minutes' outliers did remove some of the missing values from our dataframe.  \n\nI have chosen not to remove observations where we are missing start\/end station names and ids.  \nThe approximately 5% of records this would affect are still meaningful to include in our analysis.  \n\nNext let's remove columns that we no longer have use for.","76b5f9da":"We can see that there are no rides in our database for the 152nd, 153rd, and 154th ordinal day of the year. These three days in 2020 were May 31, June 1st, and June 2nd.  \nThese dates correspond to the arrival of the national guard, declaration of curfew, and halting of public transit systems in Chicago in response to nationwide protests over the murder of George Floyd.  \nThe protests would continue for weeks in the downtown area and undoubtedly impact ridership.  \n  \nWhat correlations exist between distance travelled and duration of ride?","687730fd":"Casual riders are using the bikes for *significantly longer ride times*, even when distance travelled is relatively minimal.  \n\nOur earlier analysis also indicated that casual riders favor unlocking bikes at *recreational and commercial locations*.\n\nThis suggests that our target audience is using the bikes for *tourism, sightseeing, and leisurely rides*.  \n\nFurthermore we determined the highest capture of casual riders exists *between the hours of 11am - 7pm*, especially on *Saturdays and Sundays*, and most definitely *during the months of May - September*.\n\nTo this point, we have procured a *list of target stations* at, or around, which our ad campaign would be most effectively deployed.\n\n## Next Steps\n\nFurther analysis could certainly benefit increased membership conversion.  \nAdditional data would be needed to expand on these findings, preferably:\n* Tracking individual customer usage patterns.\n* Year over year comparison.\n* Cost of membership types.\n* Data from competitors.\n\nHaving shared these insights with the Cyclistic Marketing Analysis team, the next task is to approve and implement the new ad strategy.  \nPending group consensus, the analysis would be presented to the Director of Marketing and brought before corporate stakeholders for approval.\n\n## Conclusion\n\nThis exploratory look at a practical dataset was an exercise that immersed me in the world of data analytics.  \nI was challenged to put into practice the tools and methods I studied in the Google Data Analytics Certificate course, and along the way I discovered many new avenues on which to unleash my curiosity.  \nBoth the most difficult and the most rewarding aspect of studying Computer Science is the depth of the field - to which I have always found encouragement to grow and a challenge for tomorrow.","87c103dc":"We can see that the stations frequented by our casual riders include parks, theaters, and aquariums - while the stations most visited by members favor city streets.  \n\n\nWhile its helpful to know where our most frequented stations are throughout the year, we must also consider that our advertisement strategy will be more impactful if it targets the highest concentration of casual riders.  \nAs we discovered previously in our analysis, this comes between the hours of 11am-7pm, on Saturdays and Sundays, in the summer months.","bc8df669":"Next, we ask questions which our data can answer...  \n\nHow is the frequency of rides influenced by the time of day?","4f5743bc":"A count of null values in our dataset shows that we are missing information for some columns.  \n\nAnother important takeaway is that there are many columns in which we are not missing any data.  \nMost notably, all of our time-related data is complete.  \nLet's take a closer look at the distribution of total ride times (in minutes) across our dataframe:","c38631ec":"We can see that the casual riders use the bikes for a considerably longer duration.\n\nLet's examine what preferences riders have for bicycle type.","7bec1679":"We see that only 2.12% of our rides fall outside of these parameters so I proceed in removing this data.","6f5c69ad":"Taking a glimpse at the length of our rides, we learn that, surprisingly, our shortest ride lengths are of negative value,  \n> min     -2.904997e+04  \n\nand our longest ride lengths are over over five weeks!\n> max      5.428335e+04\n\nWe can speculate that these discrepancies may be due to errors in the algorithm which calculates start\/end time, faulty mechanical components, or offline bicycles. \n\nFor the purpose of this analysis I decided that any ride length shorter than one minute or longer than four hours should be excluded as outlying data.  \nWhat proportion of our dataset would this be trimming?\n  ","d0cf0005":"As expected, we see notably fewer rides in the month of June. But what was the cause of this sudden decline?  \n\nThe answer becomes evident when we ask if there were any days in the year where service was completely suspended.","6a3989ec":"We can see that peak hours for casual riders are typically between 11am-7pm, with the highest number of rides beginning in the 5pm hour.\n\nAre there trends to explore when considering the day of the week?","cc7d6ac8":"It appears that our members are consistently riding throughout the week, while casual riders exhibit a strong preference for riding on Saturdays and Sundays.\n\nWhat can we say about how the time of year affects ridership?","5d92f532":"While it seems that rides are increasing throughout the summer, we see an unexpected decline in the month of June.  \n\nLet's take a closer look at the rides from May through July by plotting the total rides per day.","62956dfc":"At a glance we can see that our new dataframe contains over four-million observations and is using 2.4 GB in memory.  \n> Index: 4073561 entries  \n> memory usage: 2.4 GB\n\n## Processing and Cleaning the Dataset\n\nIn order to filter and clean our data I will cast some columns into more memory-efficient datatypes, and I will extract relevant information into new columns for later analysis.","a35dfd38":"A look at our cleaned dataframe shows that we have significantly reduced it's size from 2.4 GB to 585.3 MB.\n> memory usage: 585.3 MB\n\nOur data is now flexible, relevant, and ready to tell a fascinating story.\n\n## Analysis\n\nOur task for this assignment is to maximize new memberships by converting casual riders and to understand how each use the bicycles differently.  \nWe can begin by creating filters that segregate our data by membership type.","f9970469":"We can now round down our floating point decimals and cast our columns into more memory-efficient datatypes.","e3d8913d":"When the data is available, it appears that our casual riders do prefer the electronic bikes.\n\nWhere are the most popular stations for our casual riders located?","00940008":"# Cyclistic Case Study\n### An exploratory look at bike-share data using Python","dae0fd58":"## About the Data  \n\nCyclistic is a fictitious company based on a real Chicago bike-share business.  \nThe data has been anonymized and made available for use under \n[this license](https:\/\/www.divvybikes.com\/data-license-agreement).\n\nThe data in this notebook was collected from the period of June 2020 through May 2021.  \nI recieved this data as coursework in the Google Data Analytics Certificate program.\n\n## Tools Used\n\nI've chosen to use Python to process this dataset for its ease of use and diverse functionality.  \nThe Pandas library is efficient in working with our large dataset, and the Matplotlib library allows us to create custom plots from Pandas objects.  \nThis case study was constructed in a Jupyter Notebook IDE, then manually imported onto Kaggle.\n\n## Our Task\n\nCyclistic offers nearly 6,000 bicycles that service the Chicago area with a network of approximately 700 docking stations.  \nRiders can choose between purchasing a single-ride pass, a full-day pass, or an annual membership.  \n\nAnnual memberships are much more profitable than casual riders purchasing passes.  \nOur business objective is to maximize the number of annual memberships by developing a marketing strategy which targets the conversion of casual riders into annual members.  \nOur marketing analyst team needs to know how members and casual riders are using the bikes differently.  \n\n## Importing the Data\n\nWe recieve our data as twelve CSV files, each representing a complete month of Cyclistic rides.","17099ae6":"It is important we notice that for over 58% of our data we do not have any indication if a bike is electric or classic.  \nHaving taken this into account, we may still glean useful insight from analyzing trends where we do have bike type data."}}