{"cell_type":{"7b7e0f20":"code","efa13196":"code","f2060b3a":"code","2bf78151":"code","ff89b301":"code","bfee1eb4":"code","620e723e":"code","5042cd3f":"code","02aaccfe":"code","d33b1f60":"code","486c5ba9":"code","3cc9b177":"code","5cd8f0d6":"code","a6878f10":"code","0d7137d9":"code","eceb8ee1":"code","215cf7ef":"code","29e50b56":"code","d4d91570":"code","8326c441":"code","7da4a59d":"code","e359d233":"code","1fb954f4":"markdown","6284f86f":"markdown","a0f7f9a2":"markdown"},"source":{"7b7e0f20":"import numpy as np\nimport pandas as pd\nfrom pandas import Series, DataFrame\n#data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\n\nimport sklearn\nfrom sklearn import *\nimport nltk,datetime\nfrom sklearn import ensemble, metrics, preprocessing","efa13196":"itemcat=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nitems=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/items.csv\")\ntrain=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\nshops=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ntest=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/test.csv\")\nresult=pd.read_csv(\"..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")","f2060b3a":"itemcat.info()","2bf78151":"items.info()","ff89b301":"train.info()","bfee1eb4":"shops.info()","620e723e":"test.info()","5042cd3f":"result.info()","02aaccfe":"train.head()","d33b1f60":"train.date_block_num.max()","486c5ba9":"test.head()","3cc9b177":"train.describe()","5cd8f0d6":"print(\"train\",train.shape)","a6878f10":"print(\"test\",test.shape)","0d7137d9":"train['date']= pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain['month']=train['date'].dt.month\ntrain['year']=train['date'].dt.year\ntrain=train.drop(['date','item_price'],axis=1)\ntrain=train.groupby([c for c in  train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\ntrain=train.rename(columns={'item_cnt_day':'item_cnt_month'})\n\ntrain.head()","eceb8ee1":"shop_item_mean= train[['shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'],as_index=False)[['item_cnt_month']].mean()\nshop_item_mean = shop_item_mean.rename(columns = {'item_cnt_month':'item_cnt_month_mean'})\n\n#just add our mean feature to our train set\n\ntrain = pd.merge(train, shop_item_mean, how='left',on=['shop_id', 'item_id'])\n\ntrain.head()","215cf7ef":"#add last month\nshop_prev_month= train[train['date_block_num']==33][['shop_id','item_id','item_cnt_month']]\nshop_prev_month = shop_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\nshop_prev_month.head()","29e50b56":"#add previous month feature to train dataset\ntrain = pd.merge(train, shop_prev_month, how= 'left', on =['shop_id','item_id']).fillna(0.)\n\n#add all item features\ntrain =  pd.merge(train, items, how= 'left', on='item_id')\n\n#adding item category features\ntrain = pd.merge(train,itemcat,how='left',on='item_category_id')\n\n#adding shop faetures\ntrain= pd.merge(train,shops,how='left', on='shop_id')\n\ntrain.head()","d4d91570":"#test dataset\n\n#adding november 2015\n\ntest['month']=11\ntest['year']=2015\ntest['date_block_num']=34\n\n#add mean feature\ntest = pd.merge(test,shop_item_mean,how='left',on=['shop_id','item_id']).fillna(0.)\n\n#add previous month feature\ntest = pd.merge(test, shop_prev_month,how='left',on=['shop_id','item_id']).fillna(0.)\n\n#add all the features\ntest= pd.merge(test,items,how='left',on=['item_id'])\n\n#adding item category features\ntest=pd.merge(test,itemcat,how='left',on=['item_category_id'])\n\n#adding shop features \ntest =pd.merge(test,shops,how='left',on='shop_id')\ntest['item_cnt_month']=0\ntest.head()","8326c441":"#Label encoding\nfor c in ['shop_name','item_name','item_category_name']:\n    lbl= preprocessing.LabelEncoder()\n    lbl.fit(list(train[c].unique())+list(test[c].unique()))\n    train[c]=lbl.transform(train[c].astype(str))\n    test[c]=lbl.transform(test[c].astype(str))\n    print(c)\n","7da4a59d":"#Lets train and predict using Random Forest algoritm\n\ncol = [c for c in train.columns if c not in ['item_cnt_month']]\nx1=train[train['date_block_num']<33]\ny1=np.log1p(x1['item_cnt_month'].clip(0.,20.)) #cliping values\nx1=x1[col]\nx2=train[train['date_block_num']==33]\ny2=np.log1p(x2['item_cnt_month'].clip(0.,20.))\nx2=x2[col]\n\n\nreg=ensemble.ExtraTreesRegressor(n_estimators=30,n_jobs=-1,max_depth=20, random_state=18)\n#no of trees are going to be in random forest=n_estimators\nreg.fit(x1,y1)\nprint('RMSE value is:',np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.),reg.predict(x2).clip(0.,20.))))","e359d233":"reg.fit(train[col],train['item_cnt_month'].clip(0.,20.))\ntest['item_cnt_month']=reg.predict(test[col]).clip(0.,20.)\ntest[['ID','item_cnt_month']].to_csv('result.csv',index=False)\n\n\ntest['item_cnt_month']=np.expm1(test['item_cnt_month'])\ntest[['ID','item_cnt_month']].to_csv('final_submission.csv',index=False)","1fb954f4":"row,column\n","6284f86f":"find the monthly mean","a0f7f9a2":"***date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33***"}}