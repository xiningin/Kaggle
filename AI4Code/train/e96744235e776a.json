{"cell_type":{"fba0e331":"code","3118ec11":"code","82de76bd":"code","1b4b2e26":"code","faea85cd":"code","6d24f9fb":"code","60107133":"code","b0867e9f":"code","b1dc4263":"code","bd1e00a8":"code","622eb7f8":"code","abfe8547":"code","a3e7a1b0":"code","3dfda77b":"code","6838366e":"code","8c37f37a":"code","4d3e197c":"code","98cf4b9d":"code","00034efb":"code","ecbf02b2":"code","9bd9b2ce":"code","e833d60a":"code","7cfc9972":"code","33457c95":"code","09b23168":"code","489058e6":"code","11e926d4":"code","dc2bae24":"code","78f5f3ea":"code","f941d05b":"code","21d2fe42":"code","3269e162":"code","9fe8e187":"code","a86c5835":"code","17dad893":"code","b3ece9fe":"code","9ae58a80":"code","999497ed":"code","8d4bd112":"code","d99e3a7d":"code","e01e778b":"code","d59ed83e":"code","0f5e8eea":"code","ab0b90d3":"code","659711ec":"code","37bbf743":"code","b98b0a50":"code","f2502a97":"code","f6641fd8":"code","2efdfc3e":"code","4fe2ee7f":"code","baae01a1":"code","cf65a6ef":"code","03f6cf4a":"code","f519e074":"code","07a56e66":"code","1217a630":"code","4105f8d0":"code","86e59d51":"code","7716856c":"code","036821ee":"code","ed092105":"code","7f544424":"markdown","232e70ba":"markdown","204e7589":"markdown","df3e1c8c":"markdown","0582f2d4":"markdown","4b7315ea":"markdown","c9251d76":"markdown","eb1f52a2":"markdown","fe171b1e":"markdown","9a97ffbd":"markdown","90e534dd":"markdown","96f21a23":"markdown","cbd3816e":"markdown","3c9ecce7":"markdown","b416fe55":"markdown","1c19b2da":"markdown","fa2a9397":"markdown","61d23206":"markdown","9dd2dfcf":"markdown","65fb9fd9":"markdown","f29e3bc8":"markdown","c7a146d1":"markdown","796f6fce":"markdown","6f986b77":"markdown","184f9fe8":"markdown","a78cc418":"markdown","effbbd06":"markdown"},"source":{"fba0e331":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport plotly.express as px\nfrom collections import Counter as count\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Dense\nfrom sklearn.model_selection import KFold","3118ec11":"train = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json', lines=True)\ntest = pd.read_json('..\/input\/stanford-covid-vaccine\/test.json', lines=True)\nsub = pd.read_csv('..\/input\/stanford-covid-vaccine\/sample_submission.csv')\n\nprint('Train shapes: ', train.shape)\nprint('Test shapes: ', test.shape)","82de76bd":"train.head(10)","1b4b2e26":"test.head(5)","faea85cd":"sub","6d24f9fb":"train.info()","60107133":"train.describe()","b0867e9f":"train[\"seq_scored\"].value_counts()","b1dc4263":"fig = px.histogram(\n    train, \n    \"signal_to_noise\", \n    nbins=25, \n    title='signal_to_noise column distribution', \n    width=700,\n    height=500\n)\nfig.show()","bd1e00a8":"ds = train['SN_filter'].value_counts().reset_index()\nds.columns = ['SN_filter', 'count']\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"SN_filter\", \n    title='SN_filter bar chart', \n    width=500, \n    height=500\n)\nfig.show()","622eb7f8":"train['seq_length'].value_counts()","abfe8547":"test['seq_length'].value_counts()","a3e7a1b0":"train['seq_scored'].value_counts()","3dfda77b":"test['seq_scored'].value_counts()","6838366e":"sample = train.iloc[0]\nsample","8c37f37a":"sample['sequence']","4d3e197c":"dict(count(sample['sequence']))","98cf4b9d":"bases = []\n\nfor j in range(len(train)):\n    counts = dict(count(train.iloc[j]['sequence']))\n    bases.append((\n        counts['A'] \/ 107,\n        counts['G'] \/ 107,\n        counts['C'] \/ 107,\n        counts['U'] \/ 107\n    ))\n    \nbases = pd.DataFrame(bases, columns=['A_percent', 'G_percent', 'C_percent', 'U_percent'])\nbases","00034efb":"len(sample['sequence']) == sample['seq_length']","ecbf02b2":"sample['structure']","9bd9b2ce":"dict(count(sample['structure']))","e833d60a":"pairs_rate = []\n\nfor j in range(len(train)):\n    res = dict(count(train.iloc[j]['structure']))\n    pairs_rate.append(res['('] \/ 53.5)\n    \npairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\npairs_rate","7cfc9972":"pairs_dict = {}\nqueue = []\nfor i in range(0, len(sample['structure'])):\n    if sample['structure'][i] == '(':\n        queue.append(i)\n    if sample['structure'][i] == ')':\n        first = queue.pop()\n        try:\n            pairs_dict[(sample['sequence'][first], sample['sequence'][i])] += 1\n        except:\n            pairs_dict[(sample['sequence'][first], sample['sequence'][i])] = 1\npairs_dict","33457c95":"pairs = []\nall_partners = []\nfor j in range(len(train)):\n    partners = [-1 for i in range(130)]\n    pairs_dict = {}\n    queue = []\n    for i in range(0, len(train.iloc[j]['structure'])):\n        if train.iloc[j]['structure'][i] == '(':\n            queue.append(i)\n        if train.iloc[j]['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] += 1\n            except:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] = 1\n                \n            partners[first] = i\n            partners[i] = first\n    \n    all_partners.append(partners)\n    \n    pairs_num = 0\n    pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n    for item in pairs_dict:\n        pairs_num += pairs_dict[item]\n    add_tuple = list()\n    for item in pairs_unique:\n        try:\n            add_tuple.append(pairs_dict[item]\/pairs_num)\n        except:\n            add_tuple.append(0)\n    pairs.append(add_tuple)\n    \npairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\npairs","09b23168":"train['partners'] = all_partners","489058e6":"pairs_dict = {}\nqueue = []\nfor j in range(len(train)):\n    sam = train.iloc[j]\n    for i in range(0, len(sam['structure'])):\n        if sam['structure'][i] == '(':\n            queue.append(i)\n        if sam['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(sam['sequence'][first], sam['sequence'][i])] += 1\n            except:\n                pairs_dict[(sam['sequence'][first], sam['sequence'][i])] = 1\n                \npairs_dict","11e926d4":"names = []\nvalues = []\nfor item in pairs_dict:\n    names.append(item)\n    values.append(pairs_dict[item])\n    \ndf = pd.DataFrame()\ndf['pair'] = names\ndf['count'] = values\ndf['pair'] = df['pair'].astype(str)\n\nfig = px.bar(\n    df, \n    x='pair', \n    y=\"count\", \n    orientation='v', \n    title='Pair types', \n    height=400, \n    width=800\n)\nfig.show()","dc2bae24":"sample['predicted_loop_type']","78f5f3ea":"dict(count(sample['predicted_loop_type']))","f941d05b":"loops = []\nfor j in range(len(train)):\n    counts = dict(count(train.iloc[j]['predicted_loop_type']))\n    available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n    row = []\n    for item in available:\n        try:\n            row.append(counts[item] \/ 107)\n        except:\n            row.append(0)\n    loops.append(row)\n    \nloops = pd.DataFrame(loops, columns=available)\nloops","21d2fe42":"res_dict = {}\nfor j in range(len(train)):\n    sam = train.iloc[j]\n    prom = dict(count(sam['predicted_loop_type']))\n    for item in prom:\n        try:\n            res_dict[item] += prom[item]\n        except:\n            res_dict[item] = prom[item]\nres_dict","3269e162":"names = []\nvalues = []\nfor item in res_dict:\n    names.append(item)\n    values.append(res_dict[item])\n    \ndf = pd.DataFrame()\ndf['loop_type'] = names\ndf['count'] = values","9fe8e187":"fig = px.bar(\n    df, \n    x='loop_type', \n    y=\"count\", \n    orientation='v', \n    title='Predicted loop types', \n    height=400, \n    width=600\n)\nfig.show()","a86c5835":"train = pd.concat([train, bases, pairs, loops, pairs_rate], axis=1)\ntrain","17dad893":"train.columns","b3ece9fe":"train_data = []\nfor mol_id in train['id'].unique():\n    sample_data = train.loc[train['id'] == mol_id]\n    for i in range(68): \n        if i < 3:\n            previousA = -1\n            previousB = -1\n            previousC = -1\n        else:\n            if i%3 == 0:\n                previousA = sample_data['sequence'].values[0][i - 3]\n                previousB = sample_data['sequence'].values[0][i - 2]\n                previousC = sample_data['sequence'].values[0][i - 1]\n            if i%3 == 1:\n                previousA = sample_data['sequence'].values[0][i - 4]\n                previousB = sample_data['sequence'].values[0][i - 3]\n                previousC = sample_data['sequence'].values[0][i - 2]\n            if i%3 == 2:\n                previousA = sample_data['sequence'].values[0][i - 5]\n                previousB = sample_data['sequence'].values[0][i - 4]\n                previousC = sample_data['sequence'].values[0][i - 3]\n            \n            \n        if i%3 == 0:\n            a = sample_data['sequence'].values[0][i]\n            b = sample_data['sequence'].values[0][i + 1]\n            c = sample_data['sequence'].values[0][i + 2]\n            \n            nextA = sample_data['sequence'].values[0][i + 3]\n            nextB = sample_data['sequence'].values[0][i + 4]\n            nextC = sample_data['sequence'].values[0][i + 5]\n            next2A = sample_data['sequence'].values[0][i + 6]\n            next2B = sample_data['sequence'].values[0][i + 7]\n            next2C = sample_data['sequence'].values[0][i + 8]\n            next3A = sample_data['sequence'].values[0][i + 9]\n            next3B = sample_data['sequence'].values[0][i + 10]\n            next3C = sample_data['sequence'].values[0][i + 11]\n            \n        if i%3 == 1:\n            a = sample_data['sequence'].values[0][i - 1]\n            b = sample_data['sequence'].values[0][i]\n            c = sample_data['sequence'].values[0][i + 1]\n            \n            nextA = sample_data['sequence'].values[0][i + 2]\n            nextB = sample_data['sequence'].values[0][i + 3]\n            nextC = sample_data['sequence'].values[0][i + 4]\n            next2A = sample_data['sequence'].values[0][i + 5]\n            next2B = sample_data['sequence'].values[0][i + 6]\n            next2C = sample_data['sequence'].values[0][i + 7]\n            next3A = sample_data['sequence'].values[0][i + 8]\n            next3B = sample_data['sequence'].values[0][i + 9]\n            next3C = sample_data['sequence'].values[0][i + 10]\n            \n        if i%3 == 2:\n            a = sample_data['sequence'].values[0][i - 2]\n            b = sample_data['sequence'].values[0][i - 1]\n            c = sample_data['sequence'].values[0][i]\n            \n            nextA = sample_data['sequence'].values[0][i + 1]\n            nextB = sample_data['sequence'].values[0][i + 2]\n            nextC = sample_data['sequence'].values[0][i + 3]\n            next2A = sample_data['sequence'].values[0][i + 4]\n            next2B = sample_data['sequence'].values[0][i + 5]\n            next2C = sample_data['sequence'].values[0][i + 6]\n            next3A = sample_data['sequence'].values[0][i + 7]\n            next3B = sample_data['sequence'].values[0][i + 8]\n            next3C = sample_data['sequence'].values[0][i + 9]\n            \n        if a==b and b==c:\n            all_the_same = 1\n        else:\n            all_the_same = 0\n            \n        if sample_data['structure'].values[0][i] == ')' or sample_data['structure'].values[0][i] == '(':\n            isPair = 1\n        else:\n            isPair = 0\n        \n        partner_index = sample_data['partners'].values[0][i]\n        if partner_index != -1:\n            partner =  sample_data['sequence'].values[0][partner_index]\n        else:\n            partner = -1\n        \n        sample_tuple = (\n            sample_data['id'].values[0], \n            sample_data['sequence'].values[0][i],\n            sample_data['structure'].values[0][i], \n            sample_data['predicted_loop_type'].values[0][i],\n            sample_data['reactivity'].values[0][i], \n            sample_data['reactivity_error'].values[0][i],\n            sample_data['deg_Mg_pH10'].values[0][i], \n            sample_data['deg_error_Mg_pH10'].values[0][i],\n            sample_data['deg_pH10'].values[0][i], \n            sample_data['deg_error_pH10'].values[0][i],\n            sample_data['deg_Mg_50C'].values[0][i], \n            sample_data['deg_error_Mg_50C'].values[0][i],\n            sample_data['deg_50C'].values[0][i], \n            sample_data['deg_error_50C'].values[0][i],\n            sample_data['A_percent'].values[0], \n            sample_data['G_percent'].values[0],\n            sample_data['C_percent'].values[0], \n            sample_data['U_percent'].values[0],\n            sample_data['U-G'].values[0], \n            sample_data['C-G'].values[0],\n            sample_data['U-A'].values[0], \n            sample_data['G-C'].values[0],\n            sample_data['A-U'].values[0], \n            sample_data['G-U'].values[0], \n            sample_data['E'].values[0],\n            sample_data['S'].values[0], \n            sample_data['H'].values[0],\n            sample_data['B'].values[0], \n            sample_data['X'].values[0],\n            sample_data['I'].values[0], \n            sample_data['M'].values[0],\n            sample_data['pairs_rate'].values[0],\n            i%3,\n            a,\n            b,\n            c,\n            (i%107) \/ 68,\n            all_the_same, \n            isPair,\n            previousA,\n            previousB,\n            previousC,\n            nextA,\n            nextB,\n            nextC,\n            next2A,\n            next2B,\n            next2C,\n            next3A,\n            next3B,\n            next3C,\n            partner\n        )\n        train_data.append(sample_tuple)","9ae58a80":"train_data = pd.DataFrame(\n    train_data, \n    columns=[\n        'id', \n        'sequence', \n        'structure', \n        'predicted_loop_type', \n        'reactivity', \n        'reactivity_error', \n        'deg_Mg_pH10', \n        'deg_error_Mg_pH10',\n        'deg_pH10', \n        'deg_error_pH10', \n        'deg_Mg_50C', \n        'deg_error_Mg_50C', \n        'deg_50C', \n        'deg_error_50C',\n        'A_percent',\n        'G_percent',\n        'C_percent',\n        'U_percent',\n        'U-G', \n        'C-G',\n        'U-A', \n        'G-C',\n        'A-U', \n        'G-U', \n        'E',\n        'S', \n        'H',\n        'B', \n        'X',\n        'I', \n        'M',\n        'pairs_rate',\n        'codon_position',\n        'base_0',\n        'base_1',\n        'base_2',\n        'general_position',\n        'all_bases_same',\n        'isPair',\n        'prevCodon_0',\n        'prevCodon_1',\n        'prevCodon_2',\n        'nextCodon_0',\n        'nextCodon_1',\n        'nextCodon_2',\n        'next2Codon_0',\n        'next2Codon_1',\n        'next2Codon_2',\n        'next3Codon_0',\n        'next3Codon_1',\n        'next3Codon_2',\n        'partner'\n    ])\ntrain_data","999497ed":"bases = []\nfor j in range(len(test)):\n    counts = dict(count(test.iloc[j]['sequence']))\n    bases.append((\n        counts['A'] \/ test.iloc[j]['seq_length'],\n        counts['G'] \/ test.iloc[j]['seq_length'],\n        counts['C'] \/ test.iloc[j]['seq_length'],\n        counts['U'] \/ test.iloc[j]['seq_length']\n    ))\n    \nbases = pd.DataFrame(bases, columns=['A_percent', 'G_percent', 'C_percent', 'U_percent'])\nbases","8d4bd112":"pairs = []\nall_partners = []\nfor j in range(len(test)):\n    partners = [-1 for i in range(130)]\n    pairs_dict = {}\n    queue = []\n    for i in range(0, len(test.iloc[j]['structure'])):\n        if test.iloc[j]['structure'][i] == '(':\n            queue.append(i)\n        if test.iloc[j]['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(test.iloc[j]['sequence'][first], test.iloc[j]['sequence'][i])] += 1\n            except:\n                pairs_dict[(test.iloc[j]['sequence'][first], test.iloc[j]['sequence'][i])] = 1\n                \n            partners[first] = i\n            partners[i] = first\n    \n    all_partners.append(partners)\n    \n    pairs_num = 0\n    pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n    for item in pairs_dict:\n        pairs_num += pairs_dict[item]\n    add_tuple = list()\n    for item in pairs_unique:\n        try:\n            add_tuple.append(pairs_dict[item]\/pairs_num)\n        except:\n            add_tuple.append(0)\n    pairs.append(add_tuple)\n    \npairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\npairs","d99e3a7d":"test['partners'] = all_partners","e01e778b":"pairs_rate = []\nfor j in range(len(test)):\n    res = dict(count(test.iloc[j]['structure']))\n    pairs_rate.append(res['('] \/ (test.iloc[j]['seq_length']\/2))\n    \npairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\npairs_rate","d59ed83e":"loops = []\nfor j in range(len(test)):\n    counts = dict(count(test.iloc[j]['predicted_loop_type']))\n    available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n    row = []\n    for item in available:\n        try:\n            row.append(counts[item] \/ test.iloc[j]['seq_length'])\n        except:\n            row.append(0)\n    loops.append(row)\n    \nloops = pd.DataFrame(loops, columns=available)\nloops","0f5e8eea":"test = pd.concat([test, bases, pairs, loops, pairs_rate], axis=1)\ntest","ab0b90d3":"test_data = []\nfor mol_id in test['id'].unique():\n    sample_data = test.loc[test['id'] == mol_id]\n    for i in range(sample_data['seq_scored'].values[0]):\n        if i < 3:\n            previousA = -1\n            previousB = -1\n            previousC = -1\n        else:\n            if i%3 == 0:\n                previousA = sample_data['sequence'].values[0][i - 3]\n                previousB = sample_data['sequence'].values[0][i - 2]\n                previousC = sample_data['sequence'].values[0][i - 1]\n            if i%3 == 1:\n                previousA = sample_data['sequence'].values[0][i - 4]\n                previousB = sample_data['sequence'].values[0][i - 3]\n                previousC = sample_data['sequence'].values[0][i - 2]\n            if i%3 == 2:\n                previousA = sample_data['sequence'].values[0][i - 5]\n                previousB = sample_data['sequence'].values[0][i - 4]\n                previousC = sample_data['sequence'].values[0][i - 3]\n                    \n        if i%3 == 0:\n            a = sample_data['sequence'].values[0][i]\n            b = sample_data['sequence'].values[0][i + 1]\n            c = sample_data['sequence'].values[0][i + 2]\n            \n            nextA = sample_data['sequence'].values[0][i + 3]\n            nextB = sample_data['sequence'].values[0][i + 4]\n            nextC = sample_data['sequence'].values[0][i + 5]\n            next2A = sample_data['sequence'].values[0][i + 6]\n            next2B = sample_data['sequence'].values[0][i + 7]\n            next2C = sample_data['sequence'].values[0][i + 8]\n            next3A = sample_data['sequence'].values[0][i + 9]\n            next3B = sample_data['sequence'].values[0][i + 10]\n            next3C = sample_data['sequence'].values[0][i + 11]\n            \n        if i%3 == 1:\n            a = sample_data['sequence'].values[0][i - 1]\n            b = sample_data['sequence'].values[0][i]\n            c = sample_data['sequence'].values[0][i + 1]\n            \n            nextA = sample_data['sequence'].values[0][i + 2]\n            nextB = sample_data['sequence'].values[0][i + 3]\n            nextC = sample_data['sequence'].values[0][i + 4]\n            next2A = sample_data['sequence'].values[0][i + 5]\n            next2B = sample_data['sequence'].values[0][i + 6]\n            next2C = sample_data['sequence'].values[0][i + 7]\n            next3A = sample_data['sequence'].values[0][i + 8]\n            next3B = sample_data['sequence'].values[0][i + 9]\n            next3C = sample_data['sequence'].values[0][i + 10]\n            \n        if i%3 == 2:\n            a = sample_data['sequence'].values[0][i - 2]\n            b = sample_data['sequence'].values[0][i - 1]\n            c = sample_data['sequence'].values[0][i]\n            \n            nextA = sample_data['sequence'].values[0][i + 1]\n            nextB = sample_data['sequence'].values[0][i + 2]\n            nextC = sample_data['sequence'].values[0][i + 3]\n            next2A = sample_data['sequence'].values[0][i + 4]\n            next2B = sample_data['sequence'].values[0][i + 5]\n            next2C = sample_data['sequence'].values[0][i + 6]\n            next3A = sample_data['sequence'].values[0][i + 7]\n            next3B = sample_data['sequence'].values[0][i + 8]\n            next3C = sample_data['sequence'].values[0][i + 9]\n            \n        if a==b and b==c:\n            all_the_same = 1\n        else:\n            all_the_same = 0\n            \n        if sample_data['structure'].values[0][i] == ')' or sample_data['structure'].values[0][i] == '(':\n            isPair = 1\n        else:\n            isPair = 0\n            \n        partner_index = sample_data['partners'].values[0][i]\n        if partner_index != -1:\n            partner =  sample_data['sequence'].values[0][partner_index]\n        else:\n            partner = -1\n            \n        sample_tuple = (\n            sample_data['id'].values[0] + f'_{i}', \n            sample_data['sequence'].values[0][i],\n            sample_data['structure'].values[0][i], \n            sample_data['predicted_loop_type'].values[0][i],\n            sample_data['A_percent'].values[0], \n            sample_data['G_percent'].values[0],\n            sample_data['C_percent'].values[0], \n            sample_data['U_percent'].values[0],\n            sample_data['U-G'].values[0], \n            sample_data['C-G'].values[0],\n            sample_data['U-A'].values[0], \n            sample_data['G-C'].values[0],\n            sample_data['A-U'].values[0], \n            sample_data['G-U'].values[0], \n            sample_data['E'].values[0],\n            sample_data['S'].values[0], \n            sample_data['H'].values[0],\n            sample_data['B'].values[0], \n            sample_data['X'].values[0],\n            sample_data['I'].values[0], \n            sample_data['M'].values[0],\n            sample_data['pairs_rate'].values[0],\n            i%3,\n            a,\n            b,\n            c,\n            (i%sample_data['seq_scored'].values[0]) \/ sample_data['seq_scored'].values[0],\n            all_the_same, \n            isPair,\n            previousA,\n            previousB,\n            previousC,\n            nextA,\n            nextB,\n            nextC,\n            next2A,\n            next2B,\n            next2C,\n            next3A,\n            next3B,\n            next3C,\n            partner\n        )\n        test_data.append(sample_tuple)","659711ec":"test_data = pd.DataFrame(\n    test_data, \n    columns=[\n        'id', \n        'sequence', \n        'structure', \n        'predicted_loop_type', \n        'A_percent',\n        'G_percent',\n        'C_percent',\n        'U_percent',\n        'U-G', \n        'C-G',\n        'U-A', \n        'G-C',\n        'A-U', \n        'G-U', \n        'E',\n        'S', \n        'H',\n        'B', \n        'X',\n        'I', \n        'M',\n        'pairs_rate',\n        'codon_position',\n        'base_0',\n        'base_1',\n        'base_2',\n        'general_position',\n        'all_bases_same',\n        'isPair',\n        'prevCodon_0',\n        'prevCodon_1',\n        'prevCodon_2',        \n        'nextCodon_0',\n        'nextCodon_1',\n        'nextCodon_2',        \n        'next2Codon_0',\n        'next2Codon_1',\n        'next2Codon_2',\n        'next3Codon_0',\n        'next3Codon_1',\n        'next3Codon_2',\n        'partner'\n    ])\ntest_data","37bbf743":"seq = pd.get_dummies(train_data['sequence'], prefix='Base')\nstruc = pd.get_dummies(train_data['structure'], prefix='Structure')\nloop = pd.get_dummies(train_data['predicted_loop_type'], prefix='Loop')\nposition = pd.get_dummies(train_data['codon_position'], prefix='Position')\nbase0 = pd.get_dummies(train_data['base_0'], prefix='Base0')\nbase1 = pd.get_dummies(train_data['base_1'], prefix='Base1')\nbase2 = pd.get_dummies(train_data['base_2'], prefix='Base2')\ncodon0 = pd.get_dummies(train_data['prevCodon_0'], prefix='prevCodon0')\ncodon1 = pd.get_dummies(train_data['prevCodon_1'], prefix='prevCodon1')\ncodon2 = pd.get_dummies(train_data['prevCodon_2'], prefix='prevCodon2') \nnext_codon0 = pd.get_dummies(train_data['nextCodon_0'], prefix='nextCodon0')\nnext_codon1 = pd.get_dummies(train_data['nextCodon_1'], prefix='nextCodon1')\nnext_codon2 = pd.get_dummies(train_data['nextCodon_2'], prefix='nextCodon2')\nnext2_codon0 = pd.get_dummies(train_data['next2Codon_0'], prefix='next2Codon0')\nnext2_codon1 = pd.get_dummies(train_data['next2Codon_1'], prefix='next2Codon1')\nnext2_codon2 = pd.get_dummies(train_data['next2Codon_2'], prefix='next2Codon2')\nnext3_codon0 = pd.get_dummies(train_data['next3Codon_0'], prefix='next3Codon0')\nnext3_codon1 = pd.get_dummies(train_data['next3Codon_1'], prefix='next3Codon1')\nnext3_codon2 = pd.get_dummies(train_data['next3Codon_2'], prefix='next3Codon2')\npart = pd.get_dummies(train_data['partner'], prefix='partner')\n\ntrain_set = pd.concat([seq, struc, loop, position, base0, base1, base2, codon0, codon1, codon2, \n                       next_codon0, next_codon1, next_codon2, next2_codon0, next2_codon1, next2_codon2, next3_codon0, next3_codon1, next3_codon2, part, train_data], \n                      axis=1).drop(['sequence', 'structure', 'predicted_loop_type', 'codon_position', 'base_0', \n                                    'base_1', 'base_2', 'prevCodon_0', 'prevCodon_1', 'prevCodon_2', \n                                    'nextCodon_0', 'nextCodon_1', 'nextCodon_2', 'next2Codon_0', 'next2Codon_1', 'next2Codon_2',\n                                    'next3Codon_0', 'next3Codon_1', 'next3Codon_2', 'partner'], axis=1)\ntrain_set","b98b0a50":"seq = pd.get_dummies(test_data['sequence'], prefix='Base')\nstruc = pd.get_dummies(test_data['structure'], prefix='Structure')\nloop = pd.get_dummies(test_data['predicted_loop_type'], prefix='Loop')\nposition = pd.get_dummies(test_data['codon_position'], prefix='Position')\nbase0 = pd.get_dummies(test_data['base_0'], prefix='Base0')\nbase1 = pd.get_dummies(test_data['base_1'], prefix='Base1')\nbase2 = pd.get_dummies(test_data['base_2'], prefix='Base2')\ncodon0 = pd.get_dummies(test_data['prevCodon_0'], prefix='prevCodon0')\ncodon1 = pd.get_dummies(test_data['prevCodon_1'], prefix='prevCodon1')\ncodon2 = pd.get_dummies(test_data['prevCodon_2'], prefix='prevCodon2') \nnext_codon0 = pd.get_dummies(test_data['nextCodon_0'], prefix='nextCodon0')\nnext_codon1 = pd.get_dummies(test_data['nextCodon_1'], prefix='nextCodon1')\nnext_codon2 = pd.get_dummies(test_data['nextCodon_2'], prefix='nextCodon2') \nnext2_codon0 = pd.get_dummies(test_data['next2Codon_0'], prefix='next2Codon0')\nnext2_codon1 = pd.get_dummies(test_data['next2Codon_1'], prefix='next2Codon1')\nnext2_codon2 = pd.get_dummies(test_data['next2Codon_2'], prefix='next2Codon2')\nnext3_codon0 = pd.get_dummies(test_data['next3Codon_0'], prefix='next3Codon0')\nnext3_codon1 = pd.get_dummies(test_data['next3Codon_1'], prefix='next3Codon1')\nnext3_codon2 = pd.get_dummies(test_data['next3Codon_2'], prefix='next3Codon2')\npart = pd.get_dummies(test_data['partner'], prefix='partner')\n\ntest_set = pd.concat([seq, struc, loop, position, base0, base1, base2, codon0, codon1, codon2, \n                       next_codon0, next_codon1, next_codon2, next2_codon0, next2_codon1, next2_codon2, next3_codon0, next3_codon1, next3_codon2, part, test_data], \n                      axis=1).drop(['sequence', 'structure', 'predicted_loop_type', 'codon_position', 'base_0', \n                                    'base_1', 'base_2', 'prevCodon_0', 'prevCodon_1', 'prevCodon_2', \n                                    'nextCodon_0', 'nextCodon_1', 'nextCodon_2', 'next2Codon_0', 'next2Codon_1', 'next2Codon_2',\n                                    'next3Codon_0', 'next3Codon_1', 'next3Codon_2', 'partner'], axis=1)\ntest_set","f2502a97":"train_target = train_set[['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\ntrain_set = train_set.drop(['id', 'reactivity', 'reactivity_error', 'deg_Mg_pH10', 'deg_error_Mg_pH10', 'deg_pH10', 'deg_error_pH10',\n                            'deg_Mg_50C', 'deg_error_Mg_50C', 'deg_50C', 'deg_error_50C'], axis=1)","f6641fd8":"test_id = test_set['id']\ntest_set = test_set.drop(['id'], axis=1)","2efdfc3e":"test_set","4fe2ee7f":"drop_columns = ['partner_-1', 'prevCodon1_-1', 'prevCodon2_-1', 'isPair', 'pairs_rate']\n\ntrain_set = train_set.drop(drop_columns, axis=1)\ntest_set = test_set.drop(drop_columns, axis=1)","baae01a1":"def MCRMSE(y_true, y_pred):\n    colwise_mse = K.mean(K.square(y_true - y_pred))\n    return K.mean(K.sqrt(colwise_mse))","cf65a6ef":"def create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(101),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(500, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.6),\n        tf.keras.layers.Dense(50, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(3, activation=\"elu\")\n    ])\n    model.compile(optimizer='adam', loss=MCRMSE)\n    return model","03f6cf4a":"from sklearn.metrics import mean_squared_error as mse\nimport math\n\ndef rmse(y_true, y_pred):\n    return math.sqrt(mse(y_true, y_pred)) \/ 3","f519e074":"train_target.columns","07a56e66":"target = train_target[['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']]","1217a630":"preds_df = pd.DataFrame()\npreds_df['id'] = test_id\npreds_df.loc[:, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] = 0\nres = target.copy()\nfor n, (tr, te) in enumerate(KFold(n_splits=10, random_state=666, shuffle=True).split(target)):\n    print(f'Fold {n}')\n    \n    model = create_model()\n    \n    model.fit(\n        train_set.values[tr],\n        target.values[tr],\n        epochs=45, \n        batch_size=64\n    )\n    \n    preds_df.loc[:, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] += model.predict(test_set)\n    res.loc[te, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] = model.predict(train_set.values[te])\n    \npreds_df.loc[:, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] \/= (n+1)","4105f8d0":"metrics = []\nfor _target in target.columns:\n    metrics.append(rmse(target.loc[:, _target], res.loc[:, _target]))","86e59d51":"print(f'OOF Metric: {np.mean(metrics)}')","7716856c":"preds_df","036821ee":"sub = pd.merge(sub[['id_seqpos']], preds_df, left_on='id_seqpos', right_on='id', how='left').drop(['id'],axis=1)\nsub = sub.fillna(0)\nsub['deg_pH10'] = 0\nsub['deg_50C'] = 0\nsub = sub[['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\nsub","ed092105":"sub.to_csv('submission.csv', index=False)","7f544424":"#### Here we can see 3 different types of characters. Chaacter ```.``` means that base is without pair. ```(``` - is start of pair, ```)``` - the end for current pair. So the number of ```(``` should be equal to ```)```.","232e70ba":"<a id=\"1\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>1. Quick Data Overview<\/center><h2>","204e7589":"#### Basically I don't know now is ('C', 'G') and ('G', 'C') the same - so I leave it as is.","df3e1c8c":"#### We can see that the most popular pair is with G and C, the less popular with U and G. And there is only 3 possible combinations of pairs - G and C, U and G, U and A.","0582f2d4":"S: paired \"Stem\" <br>\nM: Multiloop  <br>\nI: Internal loop <br>\nB: Bulge <br>\nH: Hairpin loop <br>\nE: dangling End <br>\nX: eXternal loop <br>","4b7315ea":"### 2. Structure","c9251d76":"#### Let's do it for all samples","eb1f52a2":"<a id=\"3\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>3. Feature Engineering<\/center><h2>","fe171b1e":"#### The length of sequence should be equal to value in ```seq_length``` column","9a97ffbd":"### In this kernel I am going to present some basic data overview, feature engineering and prepare keras neural network model. Let's fo it and have fun!\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h2>\n\n* [1. Quick Data Overview](#1)\n* [2. Sample Analysis](#2)\n* [3. Feature Engineering](#3)\n* [4. Keras Neural Network Model](#4)\n* [5. Prepare submission file](#5)","90e534dd":"<h1><center>OpenVaccine || EDA || Feature engineering || Modeling<\/center><\/h1>\n\n<center><img src=\"https:\/\/daslab.stanford.edu\/site_data\/news_img\/openvaccine_lores.png\"><\/center>","96f21a23":"### We have 4 possible nitrogeneous bases for RNA:\n\n1) Guanine (G) <br>\n2) Adenine (A) <br>\n3) Cytosine (C) <br>\n4) Uracil (U) <br>\n\n#### For more details you can check <a href=\"https:\/\/en.wikipedia.org\/wiki\/Nucleobase\">here.<\/a>\n\n<center><img src=\"https:\/\/www.thoughtco.com\/thmb\/jnQVk0_RZ4TRJHeFKR7xxqSV1Pk=\/1500x1000\/filters:fill(auto,1)\/dna-versus-rna-608191_sketch_Final-54acdd8f8af04c73817e8811c32905fa.png\" width=\"700\" height=\"500\"><\/center>","cbd3816e":"<a id=\"5\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>5. Prepare submission file<\/center><h2>","3c9ecce7":"#### We have 3 columns that represent structure of sequence: sequence, structure and predicted_loop_type","b416fe55":"### 1. Sequence","1c19b2da":"### 3. Predicted loop type","fa2a9397":"#### So we have 2400 sequences in training set and 3634 in test set.","61d23206":"<a id=\"2\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>2. Sample Analysis<\/center><h2>","9dd2dfcf":"### From documentation:\n\n```\nAt the beginning of the competition, Stanford scientists have data on 3029 RNA sequences of length 107. \nFor technical reasons, measurements cannot be carried out on the final bases of these RNA sequences, so we have experimental data (ground truth) in 5 conditions for the first 68 bases.\n```","65fb9fd9":"#### Let's check for all samples","f29e3bc8":"#### Let's check all training features","c7a146d1":"#### So the final step is to prepare submission file","796f6fce":"#### Let's explore 1 sample from train set. We will focus on some columns and see values.","6f986b77":"#### Let's check our cross validation score","184f9fe8":"#### Let's check all pairs for our sample","a78cc418":"#### As we can see every sequence from training set has only 68 scored bases (first 68 bases).","effbbd06":"<a id=\"4\"><\/a>\n<h2 style='background:black; border:0; color:white'><center>4. Keras Neural Network Model<\/center><h2>"}}