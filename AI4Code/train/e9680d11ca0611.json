{"cell_type":{"632f0ae3":"code","15c81255":"code","08bfc919":"code","4a38aeb3":"code","bb0d94f5":"code","cb068fc1":"code","6cb93935":"code","367e7c63":"code","ff690670":"code","548512f7":"code","fd241685":"code","08735161":"code","08881e0e":"code","1bf0f05a":"code","befd3947":"code","7b369d59":"code","f6c10b86":"code","9e770b0c":"code","db6da305":"code","f3a9b85e":"code","0f89077e":"code","55892318":"code","4d3a4ac3":"code","9e95c285":"code","c1cf498f":"code","a1d065f1":"code","9202efb2":"code","dca568df":"code","86240819":"code","b85a3c99":"code","e398477d":"code","39aca94d":"code","6eb17b4a":"code","8431883f":"code","2b63e5f1":"code","b952261d":"code","d40778db":"markdown","f1fa504b":"markdown","692d73a9":"markdown","de3b6aa8":"markdown","a66f1a8a":"markdown","b2b642bc":"markdown","8d57cc9a":"markdown","3c773db1":"markdown","6e345408":"markdown","21731f59":"markdown","59d15425":"markdown","48b4f07b":"markdown","bf028652":"markdown","b295a554":"markdown","fcfccf9a":"markdown","deb57bb2":"markdown","b8798b30":"markdown","d8b4c6ab":"markdown","d930f307":"markdown","24da8d85":"markdown","4c94761c":"markdown","d5e7e602":"markdown","a95d9b4e":"markdown","1e1abe6f":"markdown","1abd459b":"markdown","42a4fd38":"markdown","76379a0e":"markdown","9290be92":"markdown","12a3eee6":"markdown"},"source":{"632f0ae3":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom scipy.io import loadmat\nfrom keras.utils import to_categorical\nimport itertools\n\nimport warnings\nwarnings.simplefilter('ignore')","15c81255":"# Thanks to https:\/\/www.kaggle.com\/mosius\/cnn-over-mnist\ndef load_mnist_dataset():\n    \"\"\"\n    Load MNIST-original dataset\n\n    Returns:\n    - mnist_data -- an array of arrays in the shape of (784,)\n    - mnist_label -- an array of labels\n    - classes -- array of labels classes(a set of labels)\n    - shape -- shape of data item\n    - channels_count -- channel count of data images\n    \"\"\"\n\n    mnist = loadmat(\"..\/input\/mnist-original\/mnist-original.mat\")\n    mnist_data = mnist[\"data\"].T\n    mnist_data = mnist_data.reshape(len(mnist_data), 28, 28, 1)\n    mnist_label = mnist[\"label\"][0]\n    count = len(set(mnist_label))\n    return mnist_data, mnist_label, count, (28, 28, 1)","08bfc919":"# Download data from MNIST-original dataset\ndata, labels, classes_count, data_shape = load_mnist_dataset()\n\nprint(\"data shape: \" + str(data.shape))\nprint(\"labels shape: \" + str(labels.shape))\nprint(\"classes count: \" + str(classes_count))","4a38aeb3":"def plot_images_sample(X, Y):\n    # Draw plot for images sample\n    \n    plt.figure(figsize=(10,10))\n    rand_indicies = np.random.randint(len(X), size=25)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        index = rand_indicies[i]\n        plt.imshow(np.squeeze(X[index]), cmap=plt.cm.binary)\n        plt.xlabel(Y[index])\n    plt.show()","bb0d94f5":"# Draw plot for images sample\nplot_images_sample(data, labels)","cb068fc1":"def fe_data(df, target):\n    # FE: scaling data ant transform target to categorical\n    df = df \/ 255.\n    target = to_categorical(target)\n    return df, target","6cb93935":"# FE and data splitting\ntest_size_part = 0.1\nx_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(data, labels, test_size=test_size_part, shuffle=True)\nX_train, Y_train = fe_data(x_train_orig, y_train_orig)\nX_test, Y_test = fe_data(x_test_orig, y_test_orig)","367e7c63":"# Thanks to https:\/\/www.kaggle.com\/mosius\/cnn-over-mnist\n# Model building\nmodel = models.Sequential([\n        layers.Conv2D(8, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=data_shape),\n        layers.MaxPooling2D((5, 5), padding='same'),\n        layers.Conv2D(16, kernel_size=(2, 2), strides=(1, 1), padding='same', activation='relu'),\n        layers.MaxPooling2D((4, 4), padding='same'),\n#         layers.Conv2D(16, kernel_size=(4, 4), strides=(1, 1), padding='same', activation='relu'),\n        layers.Flatten(),\n        layers.Dense(classes_count, activation='softmax'),\n#         layers.Dropout(0.7)\n    ])\n\nmodel.summary()","ff690670":"# Model training\nepochs_num = 20\nvalidation_split_part = 0.2\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, Y_train, epochs=epochs_num, validation_split=validation_split_part)","548512f7":"# Draw plot for CNN training\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\nplt.show()","fd241685":"# Print test prediction accuracy\ntest_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\nprint(\"test accuracy: \" + str(test_acc))","08735161":"def get_predictions(X_test):\n    # Digits prediction\n\n    predictions = model.predict(X_test)    \n    predictions = np.argmax(predictions, axis=1)\n    \n    return predictions","08881e0e":"# Prediction and display it\npredictions = get_predictions(X_test)\nplot_images_sample(X_test, predictions)","1bf0f05a":"# Thanks to https:\/\/www.kaggle.com\/vbmokin\/tensorflow-keras-gpu-for-chinese-mnist-prediction\ndef create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(train_model):\n    hist = train_model.history\n    acc = hist['accuracy']\n    val_acc = hist['val_accuracy']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    #define the traces\n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    #add traces to the figure\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    #set the layout for the figure\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n    #plot\n    iplot(fig, filename='accuracy-loss')","befd3947":"# Plotting the loss error (Plotly)\nplot_accuracy_and_loss(history)","7b369d59":"def plot_cm(train, target_train):\n# Look at confusion matrix \n# Thanks to https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n\n    def plot_confusion_matrix(cm, classes,\n                              normalize=False,\n                              title='Confusion matrix',\n                              cmap=plt.cm.Blues):\n        \"\"\"\n        This function prints and plots the confusion matrix.\n        Normalization can be applied by setting `normalize=True`.\n        \"\"\"\n        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n        plt.title(title)\n        plt.colorbar()\n        tick_marks = np.arange(len(classes))\n        plt.xticks(tick_marks, classes, rotation=45)\n        plt.yticks(tick_marks, classes)\n\n        if normalize:\n            cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n        thresh = cm.max() \/ 2.\n        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            plt.text(j, i, cm[i, j],\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n        plt.tight_layout()\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n\n    # Predict the values from the validation dataset\n    Y_pred = model.predict(train)\n    # Convert predictions classes to one hot vectors \n    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n    # Convert validation observations to one hot vectors\n    Y_true = np.argmax(target_train,axis = 1) \n    # compute the confusion matrix\n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    # plot the confusion matrix\n    plot_confusion_matrix(confusion_mtx, classes = range(10)) ","f6c10b86":"# Draw confusing matrix for training data\nplot_cm(X_train, Y_train)","9e770b0c":"# Draw confusing matrix for test data\nplot_cm(X_test, Y_test)","db6da305":"def pred_wrong_display_MNIST_dataset(X_test, predictions, Y_test):\n    # Displays misclassified digits from MNIST dataset\n    \n    X_test_wrong = []\n    predictions_wrong = []\n    Y_test_pred = []\n    for i in range(len(X_test)):\n        Y_test_pred.append(np.argmax(Y_test[i]))\n        if predictions[i] != Y_test_pred[i]:\n            #print(i, predictions[i], Y_test_pred[i])\n            X_test_wrong.append(X_test[i])\n            predictions_wrong.append(predictions[i])\n\n    plot_images_sample(X_test_wrong, predictions_wrong)\n        \n    print('Accuracy is', round(accuracy_score(Y_test_pred, predictions),3))\n    \n    return Y_test_pred","f3a9b85e":"# Displays misclassified digits from MNIST\nY_test_pred = pred_wrong_display_MNIST_dataset(X_test, predictions, Y_test)","0f89077e":"# Find all images in input folder\ndata_files = []\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        data_files.append(os.path.join(dirname, filename))\ndata_files","55892318":"# Download data\nimage_file = '..\/input\/mnist-models-testing-handwritten-digits\/black_marker.jpg'\nimage_test = cv2.imread(image_file)\nplt.imshow(image_test)\nplt.show()","4d3a4ac3":"def digits_finder(image_file: str, erode_kernel=48, threshold_basic=100, out_size=28):\n    # Find digits on the image_file and transform it to [-1, out_size, out_size, 1]\n    \n    image_test = cv2.imread(image_file)\n    gray_test = cv2.cvtColor(image_test, cv2.COLOR_BGR2GRAY)\n    ret, thresh = cv2.threshold(gray_test, threshold_basic, 255, cv2.THRESH_BINARY)\n    image_erode = cv2.erode(thresh, np.ones((erode_kernel, erode_kernel), np.uint8), iterations=1)\n\n    # Find contours\n    contours, hierarchy = cv2.findContours(image_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n    output = image_erode.copy()\n\n    digits = []\n    j = 0\n    labels = []\n    for idx, contour in enumerate(contours):\n        (x, y, w, h) = cv2.boundingRect(contour)\n        #if (hierarchy[0][idx][3] == 0):\n        if (hierarchy[0][idx][3] == 0) and (w*h>3000):\n            cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n            digit_crop = image_erode[y:y + h, x:x + w]\n\n            # Resize digit canvas to square\n            size_max = max(w, h)\n            print(j, w*h)\n            digit_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n            if w > h:\n                y_pos = size_max\/\/2 - h\/\/2\n                digit_square[y_pos:y_pos + h, 0:w] = digit_crop\n            elif w < h:\n                x_pos = size_max\/\/2 - w\/\/2\n                digit_square[0:h, x_pos:x_pos + w] = digit_crop\n            else:\n                digit_square = digit_crop\n            \n            # Resize digit to 28x28 and add digit and its X-coordinate\n            digits.append((x,(cv2.resize(digit_square, (out_size, out_size), interpolation=cv2.INTER_AREA))))\n            labels.append(str(j))\n            j += 1\n            \n\n    # Sort array in place by X-coordinate\n    digits.sort(key=lambda x: x[0], reverse=False)\n    \n    # Tranform digits to tensor\n    digits_new =[]\n    for i in range(len(digits)):\n        digits_new.append(digits[i][1])\n    digits_res = np.reshape(digits_new, (j, 28, 28, 1))\n    digits_res = np.where(digits_res > 225, 255, digits_res)\n    digits_res = np.where(digits_res < 125, 0, digits_res)\n\n    return digits_res, labels","9e95c285":"# Preprocessing data\nX_user_test, Y_user_test = digits_finder(image_file, erode_kernel=3, threshold_basic=150)","c1cf498f":"def plot_images_test(X, Y):\n    # Draw plot for images sample\n    \n    plt.figure(figsize=(10,10))\n    plt.gray()\n    for i in range(len(Y)):        \n        plt.subplot(1,len(Y),i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(np.squeeze(X[i]))\n        plt.xlabel(Y[i])\n    plt.show()","a1d065f1":"# Draw plot for images sample\nplot_images_test(X_user_test, Y_user_test)","9202efb2":"# FE\nX_user_test, Y_user_test = fe_data(X_user_test, Y_user_test)","dca568df":"# Color inversion \nX_user_test = 1-X_user_test","86240819":"# Prediction and display it\npredictions_user = get_predictions(X_user_test)\nplot_images_test(X_user_test, predictions_user)","b85a3c99":"plot_cm(X_user_test, Y_user_test)","e398477d":"def pred_wrong_display_for_user_dataset(X_test, predictions, Y_test):\n    # Displays misclassified digits from user's dataset\n    \n    X_test_wrong = []\n    predictions_wrong = []\n    Y_test_pred = []\n    for i in range(len(X_test)):\n        Y_test_pred.append(np.argmax(Y_test[i]))\n        if predictions[i] != Y_test_pred[i]:\n            #print(i, predictions[i], Y_test_pred[i])\n            X_test_wrong.append(X_test[i])\n            predictions_wrong.append(predictions[i])\n\n    plot_images_test(X_test_wrong, predictions_wrong)\n        \n    print('Accuracy is', round(accuracy_score(Y_test_pred, predictions),3))\n    \n    return Y_test_pred","39aca94d":"Y_user_test_pred = pred_wrong_display_for_user_dataset(X_user_test, predictions_user, Y_user_test)","6eb17b4a":"X_train[100][6]","8431883f":"X_user_test[0][6]","2b63e5f1":"X_user_test[1][6]","b952261d":"X_user_test[9][6]","d40778db":"### 2.2. EDA & FE<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","f1fa504b":"### 3.3. EDA & FE<a class=\"anchor\" id=\"3.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","692d73a9":"## 3. User-digits prediction and analyze<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","de3b6aa8":"## 2. MNIST-digits model training<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","a66f1a8a":"### Tensor values output","b2b642bc":"### 2.5. Results visualization: plotting the loss error, confusing matrix, outliers<a class=\"anchor\" id=\"2.5\"><\/a>\n\n[Back to Table of Contents](#0.1)","8d57cc9a":"## Dataset [MNIST models testing: handwritten digits](https:\/\/www.kaggle.com\/vbmokin\/mnist-models-testing-handwritten-digits)\n\n\nYour upvote for my dataset are most welcome.","3c773db1":"### 3.2. Preprocessing<a class=\"anchor\" id=\"3.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","6e345408":"MNIST","21731f59":"### Plotting the loss error (Plotly)","59d15425":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","48b4f07b":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)","bf028652":"User's dataset","b295a554":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [MNIST-digits model training](#2)\n    - [Download data](#2.1)\n    - [EDA & FE](#2.2)\n    - [Model training](#2.3)\n    - [Prediction](#2.4)    \n    - [Results visualization: plotting the loss error, confusing matrix, outliers](#2.5)\n1. [User-digits prediction and analyze](#3)\n    - [Download data](#3.1)\n    - [Preprocessing](#3.2)\n    - [EDA & FE](#3.3)\n    - [Prediction](#3.4) \n    - [Results visualization: confusing matrix, outliers](#3.5)","fcfccf9a":"### 3.4. Prediction<a class=\"anchor\" id=\"3.4\"><\/a>\n\n[Back to Table of Contents](#0.1)","deb57bb2":"### 2.1. Download data<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","b8798b30":"**TASKS**: Experiment with CNN architecture and parameters:\n* number of layers\n* Conv2D parameters in each layers: number of neurons, kernel_size, strides, padding, activation functions\n* MaxPooling2D parameters\n* Dropout (add or no)\n* Softmax (add or no)\n* etc.","d8b4c6ab":"**TASK**: Experiment with different images - see in dataset [MNIST models testing: handwritten digits](https:\/\/www.kaggle.com\/vbmokin\/mnist-models-testing-handwritten-digits)","d930f307":"### Confuse matrix","24da8d85":"### 2.4. Prediction<a class=\"anchor\" id=\"2.4\"><\/a>\n\n[Back to Table of Contents](#0.1)","4c94761c":"### Outliers analysis","d5e7e602":"**TASKS**: Experiment with parameters:\n* erode_kernel\n* threshold_basic","a95d9b4e":"### Acknowledgements:\n* dataset [MNIST Original](https:\/\/www.kaggle.com\/avnishnish\/mnist-original)\n* [CNN over MNIST](https:\/\/www.kaggle.com\/mosius\/cnn-over-mnist)\n* [MNIST model testing : typographic digits](https:\/\/www.kaggle.com\/vbmokin\/mnist-model-testing-typographic-digits)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [Data Science with DL & NLP: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-with-dl-nlp-advanced-techniques)\n* [AI-ML-DS Training. L3AT: NH4 - NN models](https:\/\/www.kaggle.com\/vbmokin\/ai-ml-ds-training-l3at-nh4-nn-models)\n* [Introduction to CNN Keras - 0.997 (top 6%)](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)\n* [Tensorflow\/Keras\/GPU for Chinese MNIST Prediction](https:\/\/www.kaggle.com\/gpreda\/tensorflow-keras-gpu-for-chinese-mnist-prediction)","1e1abe6f":"**TASK**: Experiment with test_size_part","1abd459b":"### 3.1. Download data<a class=\"anchor\" id=\"3.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","42a4fd38":"### 3.5. Results visualization: confusing matrix, outliers<a class=\"anchor\" id=\"3.5\"><\/a>\n\n[Back to Table of Contents](#0.1)","76379a0e":"<a class=\"anchor\" id=\"0\"><\/a>\n# [AI-ML-DS : Training for beginners](https:\/\/www.kaggle.com\/vbmokin\/ai-ml-ds-training-for-beginners-in-kaggle). Level 4 (very difficult). 2021\n## Thanks to Kaggle GM, Prof. [@vbmokin](https:\/\/www.kaggle.com\/vbmokin)","9290be92":"**TASK**: Experiment with:\n* epochs_num\n* validation_split_part (optional)","12a3eee6":"### 2.3. Model training<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)"}}