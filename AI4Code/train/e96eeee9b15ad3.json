{"cell_type":{"4288259b":"code","feb1daad":"code","7778dee0":"code","e708b6e6":"code","92f432a4":"code","950db8a6":"code","f6d2241c":"code","b21d9eae":"code","6b8ed3fc":"code","f7e65b37":"code","dba8a630":"code","7aaddfb7":"code","ef5cc013":"code","36d2dbce":"code","61ae7845":"code","0fb6b558":"markdown","f6aac369":"markdown","f76627c9":"markdown","969bce68":"markdown","475f92a1":"markdown","ba1e02bb":"markdown","676194d6":"markdown","1601da11":"markdown","914fafdb":"markdown"},"source":{"4288259b":"\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport os, math, random, time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n\nfrom PIL import Image\n\nimport torch.nn as nn\nimport torch\nimport torchvision\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torch.optim as optim\n\nfrom collections import defaultdict\n\n","feb1daad":"def timer_start():\n    global t0\n    t0 = time.time()\n    \ndef timer_end():   \n    print('Time elapsed {:0.1f}s'.format(time.time() - t0))  \n\ndef display_grid(data, path, w =10, h =10, columns = 4, rows = 5):\n    fig=plt.figure(figsize=(12, 8))\n    for i in range(1, columns*rows +1):\n        file = data[i]\n        file = os.path.join(path, file)\n        img = Image.open(file)\n        fig.add_subplot(rows, columns, i)\n        imshow(img)\n    plt.show()\n    \ndef get_best_epcoh(history):\n    valid_acc = history['val_acc']\n    best_epoch = valid_acc.index(max(valid_acc)) +1\n    best_acc =  max(valid_acc)\n    print('Best Validation Accuracy Score {:0.5f}, is for epoch {}'.format( best_acc, best_epoch))\n    return best_epoch\n\ndef plot_results(history):\n    tr_acc = history['tr_acc']\n    val_acc = history['val_acc']\n    tr_loss = history['tr_loss']\n    val_loss = history['val_loss']\n    epochs = history['epoch']\n\n    plt.figure(figsize = (24, 6))\n    plt.subplot(1,2,1)\n    plt.plot(epochs, tr_acc, 'b', label = 'Training Accuracy')\n    plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n    plt.grid(True)\n    plt.legend()\n    plt.xlabel('Epoch')  \n    \n    plt.subplot(1,2,2)\n    plt.plot(epochs, tr_loss, 'b', label = 'Training Loss')\n    plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n    plt.grid(True)\n    plt.legend()\n    plt.xlabel('Epoch')\n    plt.show()\n    \ndef set_seed(seed):\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \ndef online_mean_and_sd(loader):\n    \"\"\"Compute the mean and sd in an online fashion\n\n        Var[x] = E[X^2] - E^2[X]\n    \"\"\"\n    cnt = 0\n    fst_moment = torch.empty(3)\n    snd_moment = torch.empty(3)\n\n    for images, _ in loader:\n\n        b, c, h, w = images.shape\n        nb_pixels = b * h * w\n        sum_ = torch.sum(images, dim=[0, 2, 3])\n        sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3])\n        fst_moment = (cnt * fst_moment + sum_) \/ (cnt + nb_pixels)\n        snd_moment = (cnt * snd_moment + sum_of_square) \/ (cnt + nb_pixels)\n\n        cnt += nb_pixels\n\n    return fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)\n","7778dee0":"base_dir = '\/kaggle\/input\/cars-wagonr-swift\/data\/'\ntrain_swift = os.listdir(os.path.join(base_dir, 'train\/swift') )\nval_swift  = os.listdir(os.path.join(base_dir, 'validation\/swift') )\ntest_swift  =  os.listdir(os.path.join(base_dir, 'test\/swift') )\nprint('Instances for Class Swift: Train {}, Validation {} Test {}'.format(len(train_swift), len(val_swift), len(test_swift)))","e708b6e6":"#Sanity checks: no overlaping bteween train test and validation sets\nval_train = [x for x in val_swift if x in train_swift]\ntest_train = [x for x in test_swift if x in train_swift]\nval_test =  [x for x in test_swift if x in val_swift]\nlen(val_train), len(test_train), len(val_test)","92f432a4":"display_grid(data = train_swift, path = os.path.join(base_dir, 'train\/swift'), w =10, h =10, columns = 8, rows = 5)","950db8a6":"train_wr = os.listdir(os.path.join(base_dir, 'train\/wagonr') )\nval_wr  = os.listdir(os.path.join(base_dir, 'validation\/wagonr') )\ntest_wr  =  os.listdir(os.path.join(base_dir, 'test\/wagonr') )\nprint('Instances for Class Wagonr: Train {}, Validation {} Test {}'.format(len(train_swift), len(val_swift), len(test_swift)))","f6d2241c":"#Sanity checks: no overlaping bteween train test and validation sets\nval_train = [x for x in val_wr if x in train_wr]\ntest_train = [x for x in test_wr if x in train_wr]\nval_test =  [x for x in test_wr if x in val_wr]\nlen(val_train), len(test_train), len(val_test)","b21d9eae":"display_grid(data = train_wr, path = os.path.join(base_dir, 'train\/wagonr'), w =10, h =10, columns = 8, rows = 5)","6b8ed3fc":"# from https:\/\/forums.fast.ai\/t\/normalizing-your-dataset\/49799\n# Compute the mean and standrad deviation of the training images for each channel. This will be used to normalize the tensors to [-1,1]\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation' )\n\ntransform = transforms.Compose( [                                  \n                                 transforms.Resize((150,150)), \n                                 transforms.ToTensor(),\n                                  ])\n\ntrainset = torchvision.datasets.ImageFolder( root= train_dir ,\n                                              transform=transform\n                                               )\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size= 512 ,\n                                          shuffle=True, num_workers=1)\nmean, std = online_mean_and_sd(trainloader)\nprint(mean, std)","f7e65b37":"\n\nBATCH_SIZE = 20\n# transforms.ToTensor() trasnforms the pixels from [0,255] to [0,1] which is then \n# trasnformed to [-1,1] using Normalize with mean computed mean and std for each of three channels\ntransform = transforms.Compose( [                                  \n                                 transforms.Resize((150,150)), \n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean, std),\n                                  ])\n\ntrainset = torchvision.datasets.ImageFolder( root= train_dir ,\n                                              transform=transform\n                                               )\n\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size= BATCH_SIZE,\n                                          shuffle=True, num_workers=1)\n\n\nvalidset = torchvision.datasets.ImageFolder( root= validation_dir ,\n                                              transform=transform\n                                               )\n\n\nvalidloader = torch.utils.data.DataLoader(validset , batch_size= BATCH_SIZE,\n                                          shuffle=True, num_workers=1)\n#Verify that mean is 0 and SD = 1\nprint(online_mean_and_sd(trainloader))","dba8a630":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels= 3, out_channels=32, kernel_size= 3)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride= 2)\n        \n        self.conv2 =  nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size= 3)\n        self.conv3 =  nn.Conv2d(in_channels= 64, out_channels= 128, kernel_size= 3)\n        self.conv4 =  nn.Conv2d(in_channels= 128, out_channels= 128, kernel_size= 3)\n    \n#       128 * 128 * 7 is the output of the last max pool layer\n        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n        self.fc2 = nn.Linear(512, 2)\n       \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        \n        #this is similar to flatten in keras but keras is smart to figure out dimensions by iteself.\n        x = x.view(-1, 128 * 7 * 7)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n       \n        return x","7aaddfb7":"\ndef train(model, epoch, train_loader, optimizer, criterion) :   \n    model.train()\n    epoch_loss = correct = 0\n    for i, data in enumerate(train_loader, 0):\n        # Load images with gradient accumulation capabilities\n        inputs, labels = data[0].to(device), data[1].to(device)\n        # Clear gradients w.r.t. parameters       \n        optimizer.zero_grad()\n\n        # Forward pass to get output\/logits\n        outputs = model(inputs)\n\n         # Calculate Loss: softmax --> cross entropy loss\n        loss =  criterion(outputs, labels)\n        \n        # Get predictions from the maximum value\n        _, predicted = torch.max(outputs.data, 1)           \n\n        # Total correct predictions \n        correct += (predicted == labels).sum().item()  \n\n        # Getting gradients w.r.t. parameters\n        loss.backward()\n\n         # Updating parameters\n        optimizer.step() \n        \n        #Multiple loss by number of batch as loss is averaged per batch\n        epoch_loss += outputs.shape[0] * loss.item()\n        \n    accuracy = correct \/ len(train_loader.dataset)\n    epoch_loss = epoch_loss \/ len(train_loader.dataset)\n    return epoch_loss, accuracy\n\n\ndef test(model, epoch, test_loader, optimizer, criterion):\n    model.eval()\n    epoch_loss = correct = 0\n\n    with torch.no_grad():\n        #Iterate through test dataset after every epoch\n        for i, data in enumerate(test_loader, 0):\n            images, labels = data[0].to(device), data[1].to(device)\n            # Forward pass only to get logits\/output\n            outputs = model(images)\n\n            # Calculate Validation Loss\n            loss =    criterion(outputs, labels)\n\n            # Get predictions from the maximum value\n            _, predicted = torch.max(outputs.data, 1)           \n\n            # Total correct predictions \n            correct += (predicted == labels).sum().item()  \n\n             #Multiple loss by number of batch as loss is averaged per batch so that we get\n            #total loss over an epoch and then divide by number of samples to get loss per epcoh\n            epoch_loss += outputs.shape[0] * loss.item()\n\n    \n    accuracy = correct \/ len(test_loader.dataset)\n    epoch_loss = epoch_loss \/ len(test_loader.dataset)\n  \n    return epoch_loss, accuracy \n\n\n","ef5cc013":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = Net()\nmodel.to(device)\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(model.parameters(), lr=0.0001)\nprint('Divice: ',device)\nmodel\n","36d2dbce":"%%time\nEPOCHS = 50\n\n#To get reprodicible results but not working at mommnet\n# set_seed(42)\n\ntrain_list  = os.listdir(os.path.join(base_dir, 'train\/swift') ) + os.listdir(os.path.join(base_dir, 'train\/wagonr') )\nnum_batches = math.ceil(len(train_list) \/ BATCH_SIZE)\n\nprint('Number of Training samples {}, Batch Size {}, Num Batch {}'.format( len(train_list), BATCH_SIZE, num_batches ))\n\nhistory = defaultdict(list)\n\n\n# Get Keras like outputs for Training and validation by using custom train and test functions.\nfor epoch in range( EPOCHS):  \n    timer_start()\n    print('[Epoch {} of {}]'.format(epoch +1, EPOCHS), end = ' ')\n    tr_loss, tr_acc = train(model, epoch, trainloader, optimizer, criterion)\n\n    val_loss, val_acc = test(model, epoch, validloader, optimizer, criterion)  \n    timer_end()\n    print('tr_loss: {:0.4f},tr_acc {:0.4f}| val_loss {:0.4f}, val_acc {:0.4f}'.format(tr_loss, tr_acc , val_loss, val_acc))\n    history['epoch'].append(epoch+1)\n    history['tr_loss'].append(round(tr_loss,5))\n    history['tr_acc'].append(round(tr_acc,5))\n    history['val_loss'].append(round(val_loss,5))\n    history['val_acc'].append(round(val_acc,5))\n","61ae7845":"\nplot_results(history)\nbest_epoch = get_best_epcoh(history)","0fb6b558":"### Custom Train and Test Function","f6aac369":"## Build CNN model","f76627c9":"## Data Preprocessing","969bce68":"### Train and Validate","475f92a1":"## Plot Training vs Validation results[](http:\/\/)","ba1e02bb":"## Class Wagonr","676194d6":"### Set Loss Function and Optimizers","1601da11":"## Train Model","914fafdb":"## Class Swift"}}