{"cell_type":{"47db761f":"code","73c4503d":"code","46bb6da4":"code","96a3a0fb":"code","575e286b":"code","31bf1dfa":"code","30cea037":"code","f26995b5":"code","261ac3ce":"code","3f5d9c56":"code","bbbaeee5":"code","f53abc57":"code","9ee59848":"code","6d1b957b":"markdown","3c11d1bb":"markdown","0d185d5b":"markdown","3ef270a7":"markdown","6f7477f8":"markdown","59104440":"markdown","11d402aa":"markdown","95ed5e0e":"markdown"},"source":{"47db761f":"#Install the library. Make sure the GPU option is selected and the internet is turned 'ON'\n!pip install hummingbird-ml","73c4503d":"\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom hummingbird.ml import convert,load","46bb6da4":"\ntrain = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\n\ntrain.head()","96a3a0fb":"# Filtering Columns to be used for training:\ncolumns = ['deg_C','relative_humidity','absolute_humidity','sensor_1','sensor_2','sensor_3','sensor_4','sensor_5']","575e286b":"# Setting the target variable and splitting the dataset. For demo purpose, only one of the target variable is used.\ntarget = 'target_carbon_monoxide'\nX_train, X_test, y_train, y_test = train_test_split(train[columns],train[target], test_size=0.20)\n","31bf1dfa":"# Training the sklearn model for 1000 estimators\nfrom sklearn.ensemble import RandomForestRegressor\nnum_est=1000\n\nskl_model = RandomForestRegressor(n_estimators=num_est, max_depth=8)\nskl_model.fit(X_train, y_train)","30cea037":"# Timing the inference for scikit-learn on CPU only \u23f2\nskl_time = %timeit -o skl_model.predict(X_test)\n","f26995b5":"\nmodel_pytorch = convert(skl_model, 'torch')","261ac3ce":"# Timing the inference for Pytorch on CPU only\npred_cpu = %timeit -o model_pytorch.predict(X_test)","3f5d9c56":"\n%%capture \nmodel_pytorch.to('cuda')","bbbaeee5":"\npred_gpu = %timeit -o model_pytorch.predict(X_test)","f53abc57":"def plot(title, skl_time, pred_cpu, pred_gpu):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from matplotlib.pyplot import cm\n\n    fig = plt.figure()\n\n    x = ['sklearn','pytorch-cpu','pytorch-gpu']\n    height = [skl_time.best,pred_cpu.best,pred_gpu.best]\n    width = 1.0\n    plt.ylabel('time in seconds')\n    plt.xlabel(title)\n\n    rects = plt.bar(x, height, width, color=cm.rainbow(np.linspace(0,1,5)))\n    def autolabel(rects):\n\n        for rect in rects:\n            height = rect.get_height()\n            plt.text(rect.get_x() + rect.get_width()\/2., 1.05*height,\n                    '%.4f' % (height),\n                    ha='center', va='bottom')\n\n    autolabel(rects)\n    plt.show()","9ee59848":"chartname = \"Random Forest Regressor on CPU and GPU\"\n\nplot(chartname, skl_time, pred_cpu, pred_gpu)","6d1b957b":"Deep learning frameworks consists of tensors as their basic computational unit. As a result, they are able to utilize the hardware accelerators (e.g. GPUs) thereby speeding up the model training and inference. However, the traditional machine learning libraries like scikit-learn are developed to run on CPUs and have no notion of tensors. As a result, they are unable to take advantage of GPUs and hence miss out on the potential accelerations that deep learning libraries enjoy.\n\n\ud83d\udc49 In this notebook, we'll learn about a library called **[Hummingbird](https:\/\/github.com\/microsoft\/hummingbird)**, created to bridge this gap. Hummingbird speedups up the inferencing in tradiotnal machine learning models by converting them to tensor-based models. This enables us to use model like scikit-learn's decision trees and random forest even on GPUs and take advantage of the hardware capabilities.\n\n![](https:\/\/miro.medium.com\/max\/700\/1*JWT4IwQsoRArNVmIZXJexQ.png)\n\n*Transforming a simple decision tree into neural networks | Reproduced from Hummingbird's [official blog](https:\/\/www.microsoft.com\/en-us\/research\/group\/gray-systems-lab\/articles\/announcing-hummingbird-a-library-for-accelerating-inference-with-traditional-machine-learning-models\/)*\n\n> \ud83d\uddd2\ufe0f **Incase you want to know more, here is an article that goes deeper into the theory behind the library along with other useful resources:** [Speed up Inference four your scikit-learn models](https:\/\/towardsdatascience.com\/speed-up-the-inference-in-traditional-machine-learning-models-by-converting-them-into-tensor-based-efe6bbe5c92d?sk=4b6761f06e81403fb6297cb4d7c66f3c)","3c11d1bb":"<center>\n<h1>Tensors are all you need<\/h1>\n<br>\n<h3>Speed up Inference of your traditional CPU based models by converting them to Tensor based models<\/h3>\n<br>\n<a href='https:\/\/towardsdatascience.com\/speed-up-the-inference-in-traditional-machine-learning-models-by-converting-them-into-tensor-based-efe6bbe5c92d?sk=4b6761f06e81403fb6297cb4d7c66f3c'>\n        <img src='https:\/\/img.shields.io\/badge\/Medium-grey?logo=medium'>\n    <\/a>\n<a href='https:\/\/twitter.com\/pandeyparul'>\n        <img src='https:\/\/img.shields.io\/twitter\/follow\/pandeyparul'>\n<\/a>\n<\/center>\n\n","0d185d5b":"# Training the sklearn model ","3ef270a7":"### Importing the dataset","6f7477f8":"## Comparing the results","59104440":"# Switching PyTorch from CPU to GPU ","11d402aa":"### Importing the necessary libraries and functions","95ed5e0e":"# Converting scikit-learn model to PyTorch on CPU "}}