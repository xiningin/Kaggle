{"cell_type":{"b1ff90fd":"code","a15a1b93":"code","a309ac82":"code","28123ebb":"code","baf75dd9":"code","7893c7b5":"code","6aefc208":"code","5052327a":"code","4799e12e":"code","34d09b80":"code","a2daba50":"code","e8b720d5":"code","ec23978c":"code","475a3256":"code","580c19a8":"code","4313e83d":"code","1e80a289":"code","7b660fb2":"code","1bf1576a":"code","57fb31e0":"code","2a8b84d6":"code","55a6656b":"code","449aa755":"code","ba28fb2c":"markdown","fb51470a":"markdown","0f045d2d":"markdown","44f00694":"markdown","fdf4691c":"markdown","b03ca172":"markdown","02703344":"markdown","b85233a1":"markdown","5d8c8354":"markdown","3ffe3f22":"markdown","fa8af850":"markdown"},"source":{"b1ff90fd":"!pip install imutils","a15a1b93":"import numpy as np\nimport os\nimport glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation,Dropout\nfrom keras.models import Model, model_from_json, Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import MaxPooling2D\n\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","a309ac82":"MODEL_WEIGHTS_SAVE_PATH = \".\/output\/trained_model_weights.h5\"\nMODEL_JSON_SAVE_PATH = \".\/output\/trained_model.json\"\n\nMODEL_CHECKPOINT_PATH = \".\/output\/model_checkpoint.h5\"\n\nTRAIN_VALIDATION_PLOT = \".\/output\/train_validation_plot.png\"\n\n\nif not (os.path.exists(\".\/output\/\")):\n    os.makedirs(\".\/output\")\n\n#Declaring constants\nFIG_WIDTH=20 # Width of figure\nROW_HEIGHT=3 # Height of each row when showing a figure which consists of multiple rows\n\n\nRESIZE_DIM=32 # The images will be resized to 50x50 pixels\n\nCHKPT = False\n\nBATCH_SIZE = 32\nEPOCHS = 33\nLEARNING_RATE = 1e-4","28123ebb":"data_dir=os.path.join('..','input')\npaths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\npaths_train_b=glob.glob(os.path.join(data_dir,'training-b','*.png'))\npaths_train_e=glob.glob(os.path.join(data_dir,'training-e','*.png'))\npaths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\npaths_train_d=glob.glob(os.path.join(data_dir,'training-d','*.png'))\npaths_train_all=paths_train_a+paths_train_b+paths_train_c+paths_train_d+paths_train_e\n\npaths_test_a=glob.glob(os.path.join(data_dir,'testing-a','*.png'))\npaths_test_b=glob.glob(os.path.join(data_dir,'testing-b','*.png'))\npaths_test_e=glob.glob(os.path.join(data_dir,'testing-e','*.png'))\npaths_test_c=glob.glob(os.path.join(data_dir,'testing-c','*.png'))\npaths_test_d=glob.glob(os.path.join(data_dir,'testing-d','*.png'))\npaths_test_f=glob.glob(os.path.join(data_dir,'testing-f','*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\npaths_test_auga=glob.glob(os.path.join(data_dir,'testing-auga','*.png'))\npaths_test_augc=glob.glob(os.path.join(data_dir,'testing-augc','*.png'))\npaths_test_all=paths_test_a+paths_test_b+paths_test_c+paths_test_d+paths_test_e+paths_test_f+paths_test_auga+paths_test_augc\n\npath_label_train_a=os.path.join(data_dir,'training-a.csv')\npath_label_train_b=os.path.join(data_dir,'training-b.csv')\npath_label_train_e=os.path.join(data_dir,'training-e.csv')\npath_label_train_c=os.path.join(data_dir,'training-c.csv')\npath_label_train_d=os.path.join(data_dir,'training-d.csv')","baf75dd9":"def connectedComp(img):\n\n\timg = cv2.threshold(img, 105, 255, cv2.THRESH_BINARY)[1]  # ensure binary\n\tret, labels = cv2.connectedComponents(img)\n\n\t# Map component labels to hue val\n\tlabel_hue = np.uint8(179*labels\/np.max(labels))\n\tblank_ch = 255*np.ones_like(label_hue)\n\tlabeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n\n\t# cvt to BGR for display\n\tlabeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n\n\t# set bg label to black\n\tlabeled_img[label_hue==0] = 0\n\n\treturn img\n\ndef process_image(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    gray = cv2.bilateralFilter(gray,33,33,99)\n    thresh_gray = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 99, 2)\n    equ = connectedComp(thresh_gray)\n    color = cv2.cvtColor(equ,cv2.COLOR_GRAY2RGB)\n    return color\n\n\ndef get_key(path):\n    # seperates the name of the image from the path\n    key=path.split(sep=os.sep)[-1]\n    return key\n\n  \ndef get_data(paths_img,path_label=None,resize_dim=None):\n    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n    Args:\n        paths_img: image filepaths\n        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n    Returns:\n        X: group of images\n        y: categorical true labels\n    '''\n    X=[] # initialize empty list for resized images\n    \n    for i,path in enumerate(paths_img):\n        img=cv2.imread(path,cv2.IMREAD_COLOR) # images loaded in color (BGR)\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        img = process_image(img)\n        if resize_dim is not None:\n            img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) # resize image to 28x28\n#         X.append(np.expand_dims(img,axis=2)) # expand image to 28x28x1 and append to the list.\n        X.append(img) # expand image to 28x28x1 and append to the list\n        # display progress\n        if i==len(paths_img)-1:\n            end='\\n'\n        else: end='\\r'\n        print('processed {}\/{}'.format(i+1,len(paths_img)),end=end)\n        \n    X=np.array(X) # tranform list to numpy array\n    if  path_label is None:\n        return X\n    else:\n        df = pd.read_csv(path_label) # read labels\n        df=df.set_index('filename') \n        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n        return X, y\n\n      \ndef imshow_group(X,y=None,y_pred=None,n_per_row=10):\n    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n    Args:\n        X: images\n        y: categorical true labels\n        y_pred: predicted class probabilities\n        n_per_row: number of images per row to be plotted\n    '''\n    n_sample=len(X)\n    img_dim=X.shape[1]\n    j=np.ceil(n_sample\/n_per_row)\n    fig=plt.figure(figsize=(FIG_WIDTH,ROW_HEIGHT*j))\n    for i,img in enumerate(X):\n        plt.subplot(j,n_per_row,i+1)\n        plt.imshow(img)\n        if y is not None:\n                plt.title('true label: {}'.format(np.argmax(y[i])))\n        if y_pred is not None:\n            top_n=3 # top 3 predictions with highest probabilities\n            ind_sorted=np.argsort(y_pred[i])[::-1]\n            h=img_dim+4\n            for k in range(top_n):\n                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n                plt.text(img_dim\/2, h, string, horizontalalignment='center',verticalalignment='center')\n                h+=4\n        plt.axis('off')\n    plt.show()","7893c7b5":"X_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\nX_train_b,y_train_b=get_data(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\nX_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\nX_train_d,y_train_d=get_data(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\nX_train_e,y_train_e=get_data(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)","6aefc208":"X_train_all=np.concatenate((X_train_a,X_train_b,X_train_c,X_train_d,X_train_e),axis=0)\ny_train_all=np.concatenate((y_train_a,y_train_b,y_train_c,y_train_d,y_train_e),axis=0)\nX_train_all.shape, y_train_all.shape","5052327a":"X_test_a=get_data(paths_test_a,resize_dim=RESIZE_DIM)\nX_test_b=get_data(paths_test_b,resize_dim=RESIZE_DIM)\nX_test_c=get_data(paths_test_c,resize_dim=RESIZE_DIM)\nX_test_d=get_data(paths_test_d,resize_dim=RESIZE_DIM)\nX_test_e=get_data(paths_test_e,resize_dim=RESIZE_DIM)\nX_test_f=get_data(paths_test_f,resize_dim=RESIZE_DIM)\nX_test_auga=get_data(paths_test_auga,resize_dim=RESIZE_DIM)\nX_test_augc=get_data(paths_test_augc,resize_dim=RESIZE_DIM)","4799e12e":"X_test_all=np.concatenate((X_test_a,X_test_b,X_test_c,X_test_d,X_test_e,X_test_f,X_test_auga,X_test_augc))","34d09b80":"(Xtrain,Xvalid,Ytrain,Yvalid) = train_test_split(X_train_all,y_train_all,test_size=0.2, shuffle=True, random_state=94743)\nXtrain = Xtrain.astype('float')\/255.0\nXvalid = Xvalid.astype('float')\/255.0\nn_sample = 50\n\nind=np.random.randint(0,len(Xtrain), size=n_sample)\nimshow_group(X=Xtrain[ind])\ndatagen = ImageDataGenerator(\n    rotation_range=35,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1)","a2daba50":"class SmallVGGNet:\n    @staticmethod\n    def build(width,height,depth,classes):\n        model = Sequential()\n        \n        inputShape = (height,width,depth)\n        chanDim = -1\n        \n        if(K.image_data_format()=='channels_first'):\n            inputShape = (depth,height,width)\n            chanDim = 1\n            \n        model.add(Conv2D(32,(3,3),padding=\"same\",input_shape = inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(64,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(64,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis = chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        \n        model.add(Conv2D(128,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        \n        model.add(Conv2D(256,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(256,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(256,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256,(3,3),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Flatten())\n        \n        model.add(Dense(512))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n#         model.add(Dense(1024))\n#         model.add(Activation(\"relu\"))\n#         model.add(BatchNormalization())\n#         model.add(Dropout(0.5))\n        \n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n        \n#         if(CHKPT):\n#           model.load_weights(MODEL_CHECKPOINT_PATH)\n        \n        model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n        return model","e8b720d5":"K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=SmallVGGNet.build(RESIZE_DIM,RESIZE_DIM,3,10)# create the model\nK.set_value(model.optimizer.lr, LEARNING_RATE) # set the learning rate\nmodel.summary()","ec23978c":"h=model.fit_generator(\n    datagen.flow(Xtrain, Ytrain, batch_size=BATCH_SIZE),\n    \n    steps_per_epoch=len(Xtrain)\/EPOCHS,\n    \n    epochs=EPOCHS, \n            verbose=1, \n            validation_data=(Xvalid,Yvalid),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=MODEL_CHECKPOINT_PATH),\n                EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=10,\n                              verbose=0, mode='auto',restore_best_weights=True)\n            ]\n            )","475a3256":"# plot the training loss and accuracy\nH=h\nN = np.arange(0,len(H.history[\"loss\"]))\nplt.style.use(\"ggplot\")\nplt.figure()\n\nplt.plot(N, H.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, H.history[\"acc\"], label=\"train_acc\")\nplt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy (LeNet)\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()\nplt.savefig(TRAIN_VALIDATION_PLOT)","580c19a8":"predictions_prob=model.predict(X_test_all) # get predictions for all the testing data","4313e83d":"n_sample=200\nnp.random.seed(42)\nind=np.random.randint(0,len(X_test_all), size=n_sample)","1e80a289":"imshow_group(X=X_test_all[ind],y=None,y_pred=predictions_prob[ind])","7b660fb2":"labels=[np.argmax(pred) for pred in predictions_prob]","1bf1576a":"labels","57fb31e0":"keys=[get_key(path) for path in paths_test_all ]","2a8b84d6":"keys","55a6656b":"def create_submission(predictions,keys,path):\n    result = pd.DataFrame(\n        predictions,\n        columns=['label'],\n        index=keys\n        )\n    result.index.name='key'\n    result.to_csv(path, index=True)\ncreate_submission(predictions=labels,keys=keys,path='submission_simple_keras_starter.csv')","449aa755":"!ls","ba28fb2c":"# Model","fb51470a":"Let's observe a few pedictions.","0f045d2d":"# Make Predictions on Test Set","44f00694":"# Setup path variables\n","fdf4691c":"# Bangla Handwritten Digit Recognizer (BHDR) Using VGGNet Like CNN Architecture","b03ca172":"# Train and Validate","02703344":"# Create Submission","b85233a1":"# Utility Functions","5d8c8354":"# Preprocess data","3ffe3f22":"Next, we are going to randomly choose 80% of the training data and use it to train our neural network. The remaining 20% images are going to be our validation data.","fa8af850":"We shall build a small model based on the classic [LeNet](http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-01a.pdf) architecture. We shall use only three convolutional layers. Each convolution layer has rectified linear unit (ReLU) activation which is followed by a max pooling layer. The convolution layers are followed by two dense layers. "}}