{"cell_type":{"513c0d1a":"code","253066e8":"code","fc17a7e5":"code","c8f753e6":"code","52fa48d0":"code","0d646c18":"code","bb2dac66":"code","a5607e88":"code","c53d2dcb":"code","e3dc5306":"code","8eb85482":"code","169c4ef9":"code","73fb89ba":"code","44ba9820":"code","a9f9f419":"code","3a684ad2":"code","52cec76d":"code","b7ef1c91":"code","8507c5a4":"code","cfe75be5":"code","e25f8e21":"code","0bc7cc7d":"code","d07cbcd6":"code","4930c9a5":"code","de9a2a71":"code","4d74b6fa":"code","345eee9c":"code","65e659f5":"code","c75dcf1a":"code","a3964152":"code","3fe75097":"code","be4ac2d2":"code","3e35f8ec":"code","38432221":"code","425473e8":"code","fdfc40af":"code","68469b14":"markdown","3fca26bf":"markdown","64be1892":"markdown","a6f91132":"markdown","057eed31":"markdown","456f7935":"markdown","49b54d40":"markdown","12099167":"markdown","0796f08f":"markdown","1d5f379b":"markdown","2a3bbc2b":"markdown","0a5443c5":"markdown","5fef9676":"markdown","1df7777c":"markdown","b70bb258":"markdown","c87d3644":"markdown","a70b421b":"markdown","5ef87213":"markdown"},"source":{"513c0d1a":"!pip install ipdb\n!pip install pytorch_lightning","253066e8":"\nimport numpy as np\nimport pandas as pd \nimport holidays\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly\nimport xgboost as xgb\nimport holidays\nimport shap\nimport datetime as dt\nfrom torch.utils.data import DataLoader,Dataset\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport plotly.offline as py\nfrom IPython.display import FileLink\nimport seaborn as sns\npd.plotting.register_matplotlib_converters()\n\n\npy.init_notebook_mode()\nFileLink('__notebook_source__.ipynb')\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","fc17a7e5":"data = pd.read_csv('\/kaggle\/input\/chicago-divvy-bicycle-sharing-data\/data.csv')\ndata['starttime'] = pd.to_datetime(data['starttime'])\ndata['stoptime'] = pd.to_datetime(data['stoptime'])\ndata = data.sort_values('starttime').set_index('starttime')\ndata['events'] = data.events.fillna('unknown')\n","c8f753e6":"daily_df = data.resample('1d').agg({'tripduration':'count','temperature':'max'})\nfig, ax = plt.subplots(figsize=(8,6))\ndaily_df['tripduration'].plot(ax=ax, label='Daily Trips')\nax2 = ax.twinx()\ndaily_df['temperature'].plot(ax=ax2, color='orange', label='Daily High Temperature')\nax.legend(bbox_to_anchor=(1.1,1))\nax2.legend(bbox_to_anchor=(1.1,0.95))\nax.set_ylabel(r\"Total Trips\")\nax2.set_ylabel(r\"Daily High ($^\\circ$F)\")\nax.set_title('Daily Trips vs Daily High')","52fa48d0":"daily_corr = daily_df[['tripduration','temperature']].rolling(30).corr().iloc[0::2,-1].reset_index().set_index('starttime')\nfig, ax = plt.subplots(figsize=(8,6))\ndaily_df['tripduration'].rolling(30).mean().plot(ax=ax, label='Daily Trips 30d MA')\nax2 = ax.twinx()\ndaily_corr['temperature'].plot(ax=ax2, color='orange', label='Trips-Temperature 30d Correlation')\nax.legend(bbox_to_anchor=(1.1,1))\nax2.legend(bbox_to_anchor=(1.1,0.95))\nax.set_ylabel(r\"Total Trips\")\nax2.set_ylabel(r\"Rolling 30d Correlation\")\nax.set_title('Trips vs Temperature Correlation Rolling')","0d646c18":"daily_df_trip_count = data.resample('1h').agg({'tripduration':'count'})\ndaily_df_trip_count = daily_df_trip_count.rename(columns={'tripduration':'trip_count'})\ndaily_df_trip_sum = data.resample('1h').agg({'tripduration':'sum'})\ndaily_df_trip_sum = daily_df_trip_sum.rename(columns={'tripduration':'trip_sum'})\ndaily_df_trip_sum = daily_df_trip_sum.merge(daily_df_trip_count, left_index=True, right_index=True,how='inner')\ndaily_df_trip_sum['Week Day'] = daily_df_trip_sum.index.weekday_name\ndaily_df_trip_sum['Hour'] = daily_df_trip_sum.index.hour\n\ntrip_length_count_corr = daily_df_trip_sum.groupby(['Hour','Week Day'])['trip_sum','trip_count'].corr().reset_index()\ncats = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ntrip_length_count_corr['Week Day'] = pd.Categorical(trip_length_count_corr['Week Day'], categories=cats, ordered=True)\n\nfig, ax = plt.subplots(figsize=(8,6))\nhmap = sns.heatmap(pd.pivot_table(trip_length_count_corr[trip_length_count_corr['trip_sum']!=1],\n                                  index='Week Day',columns='Hour', values='trip_sum'),\n                   cmap='viridis', cbar_kws={'label': 'Correlation'})\nax.set_title('Correlation between Trips Length and Trip Count by Hour and Day of Week')","bb2dac66":"data['Week Day'] = data.index.weekday_name\nhourly_correlation = data.groupby(['hour','Week Day'])['tripduration','temperature'].corr().reset_index()\ncats = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nhourly_correlation['Week Day'] = pd.Categorical(hourly_correlation['Week Day'], categories=cats, ordered=True)\n\nfig, ax = plt.subplots(figsize=(8,6))\nhmap = sns.heatmap(pd.pivot_table(hourly_correlation[hourly_correlation['tripduration']!=1],\n                                  index='Week Day',columns='hour', values='tripduration'),\n                   cmap='viridis', cbar_kws={'label': 'Correlation'})\nax.set_title('Correlation between Trips and Temperature by Hour and Day of Week')","a5607e88":"hourly = data.groupby('gender').resample('1h').agg({'tripduration':'count','temperature':'max','events':'first'})\nhourly['temperature'] = hourly['temperature'].interpolate() \nhourly['temperature'] = (hourly['temperature'] - hourly['temperature'].mean())\/hourly['temperature'].std()\n\nhourly['tripduration'] = np.log(hourly['tripduration']+1)\nhourly['tripduration'] = (hourly['tripduration'] - hourly['tripduration'].mean())\/hourly['tripduration'].std()\n\nhourly['lag_7'] = hourly.tripduration.shift(7*24)\nhourly['lag_1'] = hourly.tripduration.shift(24)\nhourly['yoy'] = hourly.tripduration.rolling(24*30).mean().pct_change(365*24).rolling(3*24).mean().shift(1)\n\nhourly['lag_14'] = hourly.tripduration.shift(14*24)\nhourly['lag_28'] = hourly.tripduration.shift(28*24)\nhourly['ma_28'] = hourly.tripduration.rolling(24*28).mean().shift(1)\nhourly['ma_7'] = hourly.tripduration.rolling(7*24).mean().shift(1)\nhourly['ma_1'] = hourly.tripduration.rolling(24).mean().shift(1)\nhourly['events'] = hourly['events'].fillna(method='ffill') \n\nhourly=hourly.reset_index()\nhourly['date'] = pd.to_datetime(hourly.starttime.dt.date)\n\ndaily_temp = data.resample('1d').agg({'temperature':'max'}).reset_index()\ndaily_temp['date'] = pd.to_datetime(daily_temp.starttime.dt.date)\ndaily_temp = daily_temp.rename(columns={'temperature':'daily_max_temp'})\n\n\ndaily_temp['daily_max_temp'] = (daily_temp['daily_max_temp'] - daily_temp['daily_max_temp'].mean())\/daily_temp['daily_max_temp'].std()\n\nholiday_df = pd.DataFrame(holidays.US(years = [2014,2015,2016,2017]).items(), columns =['date','holiday'] )\nholiday_df['date'] = pd.to_datetime(holiday_df['date'])\n\nhourly = hourly.merge(holiday_df, on='date', how='left')\nhourly = hourly.merge(daily_temp[['date','daily_max_temp']], on='date', how='left')\n\nhourly['holiday_indicator'] = hourly['holiday'].notnull().astype(int)\n\nhourly['day'] = hourly.starttime.dt.day-1\nhourly['hour'] = hourly.starttime.dt.hour\n\nhourly['wday'] = hourly.starttime.dt.weekday\nhourly['month'] = hourly.starttime.dt.month-1\n\n\nhourly['holiday_indicator_lag_minus_2'] = hourly.holiday_indicator.shift(-2)\nhourly['holiday_indicator_lag_minus_1'] = hourly.holiday_indicator.shift(-1)\nhourly['holiday_indicator_lag_1'] = hourly.holiday_indicator.shift(1)\nhourly['holiday_indicator_lag_2'] = hourly.holiday_indicator.shift(2)\n\n\nhourly['year'] = hourly.starttime.dt.year - 2014\nhourly['gender_enc'] = LabelEncoder().fit_transform(hourly['gender'])\nhourly['holiday_enc'] = LabelEncoder().fit_transform(hourly['holiday'].fillna('None'))\nhourly['events_enc'] = LabelEncoder().fit_transform(hourly['events'])\n\ntrain_data = hourly[(hourly['date']<pd.to_datetime('2017-07-15')) & (hourly['date']>pd.to_datetime('2015-02-01'))]\nval_data = hourly[(hourly['date']>=pd.to_datetime('2017-07-15'))&(hourly['date']<pd.to_datetime('2017-09-01'))]\ntest_data = hourly[(hourly['date']>pd.to_datetime('2017-09-01'))]\n","c53d2dcb":"cols = ['temperature','wday','holiday_enc','events_enc','year','lag_7', 'lag_14',\n       'ma_28', 'ma_7','hour','holiday_indicator_lag_minus_2',\n       'holiday_indicator_lag_minus_1', 'holiday_indicator_lag_1',\n       'holiday_indicator_lag_2','gender_enc', 'daily_max_temp','yoy']\n\nparams = {\"learning_rate\": 0.1,\n          'objective': 'reg:linear',\n          'max_depth':4,\n          'eval_metric':'rmse','verbose':0}\n\ndtrain = xgb.DMatrix(train_data[cols].values, label=train_data['tripduration'])\ndval = xgb.DMatrix(val_data[cols].values, label=val_data['tripduration'])\n\nwatchlist = [(dval, 'eval')]\nnum_round = 500\n\nmodel = xgb.train(params,dtrain, num_round , watchlist, early_stopping_rounds=20,verbose_eval=50)\ntest_data['y_pred'] = model.predict(xgb.DMatrix(test_data[cols].values))","e3dc5306":"test_data[test_data.gender=='Male'].set_index('starttime')[['y_pred','tripduration']].loc[pd.to_datetime('2017-09-01'):pd.to_datetime('2017-09-07')].plot()","8eb85482":"test_data[test_data.gender=='Female'].set_index('starttime')[['y_pred','tripduration']].loc[pd.to_datetime('2017-09-01'):pd.to_datetime('2017-09-07')].plot()","169c4ef9":"test_data[test_data.gender=='Female'].set_index('starttime')[['y_pred','tripduration']].loc[pd.to_datetime('2017-09-01'):pd.to_datetime('2017-12-31')].resample('1d').sum().plot()","73fb89ba":"test_data[test_data.gender=='Male'].set_index('starttime')[['y_pred','tripduration']].loc[pd.to_datetime('2017-09-01'):pd.to_datetime('2017-12-31')].resample('1d').sum().plot()","44ba9820":"shap.initjs()\nexplainer = shap.TreeExplainer(model, feature_perturbation='interventional' )\nsamples = train_data[cols].sample(2000)\nshap_values = explainer.shap_values(samples.values)","a9f9f419":"shap.summary_plot(shap_values, samples)","3a684ad2":"shap.dependence_plot(\"temperature\", shap_values, samples)","52cec76d":"shap.dependence_plot(\"daily_max_temp\", shap_values, samples)","b7ef1c91":"shap.dependence_plot(\"hour\", shap_values, samples)","8507c5a4":"from IPython.display import Image \nImage(\"\/kaggle\/input\/tftarch\/tft_arch.png\")","cfe75be5":"!mkdir training_data\n!mkdir validation_data\n!mkdir test_data","e25f8e21":"date_ranges = train_data.date.unique()\n\nx_cols = ['tripduration', 'temperature', 'daily_max_temp','ma_7', 'lag_7','yoy']\n\nidentifier_cols = ['gender_enc']\n\ntime_columns =['year','day', 'events_enc',\n       'holiday_enc','wday','hour']\n\nall_cols = x_cols + time_columns\nseq_len = 21\n\nbatch = 0\n\ncount = 1\nfor i in range(len(date_ranges)-1, 21, -1):\n    \n    \n    d_cols = date_ranges[i-seq_len: i]\n    if (i == (len(date_ranges)-1)):\n        x_vals = np.nan_to_num(np.array(train_data[train_data.date.isin(d_cols)].groupby('gender')[x_cols].apply(lambda x : x.values.tolist()).to_list()))\n        identifiers = np.array(train_data[train_data.date == d_cols[0]].groupby('gender')[identifier_cols].apply(lambda x : x.values.tolist()).to_list())\n        time_covariates = np.array(train_data[train_data.date.isin(d_cols)].groupby('gender')[time_columns].apply(lambda x : x.values.tolist()).to_list())\n    \n    else: \n        x_vals = np.append(x_vals, np.nan_to_num(np.array(train_data[train_data.date.isin(d_cols)].groupby('gender')[x_cols].apply(lambda x : x.values.tolist()).to_list())), axis=0)\n        identifiers = np.append(identifiers, np.array(train_data[train_data.date == d_cols[0]].groupby('gender')[identifier_cols].apply(lambda x : x.values.tolist()).to_list()), axis=0)\n        time_covariates = np.append(time_covariates, np.array(train_data[train_data.date.isin(d_cols)].groupby('gender')[time_columns].apply(lambda x : x.values.tolist()).to_list()), axis=0)\n\npath = 'training_data\/'\n\nnp.save('{}time_covariates.npy'.format(path),time_covariates)\nnp.save('{}x_vals.npy'.format(path),x_vals)\nnp.save('{}identifiers.npy'.format(path),identifiers)","0bc7cc7d":"date_ranges = val_data.date.unique()\nx_cols = ['tripduration', 'temperature','daily_max_temp','ma_7', 'lag_7','yoy']\n\nidentifier_cols = ['gender_enc']\n\ntime_columns =['year','day', 'events_enc',\n       'holiday_enc','wday','hour']\n\n\nbatch = 0\n\ncount = 1\nfor i in range(len(date_ranges)-1, seq_len, -1):\n    \n    \n    d_cols = date_ranges[i-seq_len: i]\n    if (i == (len(date_ranges)-1)):\n        x_vals = np.nan_to_num(np.array(val_data[val_data.date.isin(d_cols)].groupby('gender')[x_cols].apply(lambda x : x.values.tolist()).to_list()))\n        identifiers = np.array(val_data[val_data.date == d_cols[0]].groupby('gender')[identifier_cols].apply(lambda x : x.values.tolist()).to_list())\n        time_covariates = np.array(val_data[val_data.date.isin(d_cols)].groupby('gender')[time_columns].apply(lambda x : x.values.tolist()).to_list())\n    \n    else: \n        x_vals = np.append(x_vals, np.nan_to_num(np.array(val_data[val_data.date.isin(d_cols)].groupby('gender')[x_cols].apply(lambda x : x.values.tolist()).to_list())), axis=0)\n        identifiers = np.append(identifiers, np.array(val_data[val_data.date == d_cols[0]].groupby('gender')[identifier_cols].apply(lambda x : x.values.tolist()).to_list()), axis=0)\n        time_covariates = np.append(time_covariates, np.array(val_data[val_data.date.isin(d_cols)].groupby('gender')[time_columns].apply(lambda x : x.values.tolist()).to_list()), axis=0)\n\npath = 'validation_data\/'\n\nnp.save('{}time_covariates.npy'.format(path),time_covariates)\nnp.save('{}x_vals.npy'.format(path),x_vals)\nnp.save('{}identifiers.npy'.format(path),identifiers)\n","d07cbcd6":"date_ranges = test_data.date.unique()\nx_cols = ['tripduration', 'temperature','daily_max_temp','ma_7', 'lag_7','yoy']\n\nidentifier_cols = ['gender_enc']\n\ntime_columns =['year','day', 'events_enc',\n       'holiday_enc','wday','hour']\n\n\nbatch = 0\n\ncount = 1\nfor i in range(len(date_ranges)-1, seq_len, -1):\n    \n    \n    d_cols = date_ranges[i-seq_len: i]\n    if (i == (len(date_ranges)-1)):\n        x_vals = np.nan_to_num(np.array(test_data[test_data.date.isin(d_cols)].groupby('gender')[x_cols].apply(lambda x : x.values.tolist()).to_list()))\n        identifiers = np.array(test_data[test_data.date == d_cols[0]].groupby('gender')[identifier_cols].apply(lambda x : x.values.tolist()).to_list())\n        time_covariates = np.array(test_data[test_data.date.isin(d_cols)].groupby('gender')[time_columns].apply(lambda x : x.values.tolist()).to_list())\n    \n    else: \n        x_vals = np.append(x_vals, np.nan_to_num(np.array(test_data[test_data.date.isin(d_cols)].groupby('gender')[x_cols].apply(lambda x : x.values.tolist()).to_list())), axis=0)\n        identifiers = np.append(identifiers, np.array(test_data[test_data.date == d_cols[0]].groupby('gender')[identifier_cols].apply(lambda x : x.values.tolist()).to_list()), axis=0)\n        time_covariates = np.append(time_covariates, np.array(test_data[test_data.date.isin(d_cols)].groupby('gender')[time_columns].apply(lambda x : x.values.tolist()).to_list()), axis=0)\n\npath = 'test_data\/'\n\nnp.save('{}time_covariates.npy'.format(path),time_covariates)\nnp.save('{}x_vals.npy'.format(path),x_vals)\nnp.save('{}identifiers.npy'.format(path),identifiers)\n","4930c9a5":"class BikeShareDataset(Dataset):\n\n    def __init__(self, path='training_data\/'):\n        \n    \n            self.x = np.load('{}x_vals.npy'.format(path))\n            self.linspace = np.expand_dims(np.concatenate([np.linspace(-1,0, 24*14), np.linspace(0.05,1, 24*7)], axis=0), -1)\n            self.tv = np.load('{}time_covariates.npy'.format(path))\n            self.ids = np.load('{}identifiers.npy'.format(path))\n          \n    def __getitem__(self, index):\n        \n        return {'x': np.concatenate([self.x[index],self.linspace], axis=1) , 'dates':self.tv[index], 'id':self.ids[index].squeeze()}\n    \n    def __len__(self):\n        \n        return self.x.shape[0]","de9a2a71":"from torch import nn\nimport math\nimport torch\n\n\nclass TimeDistributed(nn.Module):\n    ## Takes any module and stacks the time dimension with the batch dimenison of inputs before apply the module\n    ## From: https:\/\/discuss.pytorch.org\/t\/any-pytorch-function-can-work-as-keras-timedistributed\/1346\/4\n    def __init__(self, module, batch_first=False):\n        super(TimeDistributed, self).__init__()\n        self.module = module\n        self.batch_first = batch_first\n\n    def forward(self, x):\n\n        if len(x.size()) <= 2:\n            return self.module(x)\n\n        # Squash samples and timesteps into a single axis\n        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size)\n\n        y = self.module(x_reshape)\n\n        # We have to reshape Y\n        if self.batch_first:\n            y = y.contiguous().view(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)\n        else:\n            y = y.view(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)\n\n        return y\n\nclass GLU(nn.Module):\n    #Gated Linear Unit\n    def __init__(self, input_size):\n        super(GLU, self).__init__()\n        \n        self.fc1 = nn.Linear(input_size,input_size)\n        self.fc2 = nn.Linear(input_size, input_size)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        \n        sig = self.sigmoid(self.fc1(x))\n        x = self.fc2(x)\n        return torch.mul(sig, x)\n\n\nclass GatedResidualNetwork(nn.Module):\n    def __init__(self, input_size, hidden_state_size, output_size, dropout, hidden_context_size=None, batch_first=False):\n        super(GatedResidualNetwork, self).__init__()\n\n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_context_size = hidden_context_size\n        self.hidden_state_size=hidden_state_size\n        self.dropout = dropout\n        \n        if self.input_size!=self.output_size:\n            self.skip_layer = TimeDistributed(nn.Linear(self.input_size, self.output_size))\n\n        self.fc1 = TimeDistributed(nn.Linear(self.input_size, self.hidden_state_size), batch_first=batch_first)\n        self.elu1 = nn.ELU()\n        \n        if self.hidden_context_size is not None:\n            self.context = TimeDistributed(nn.Linear(self.hidden_context_size, self.hidden_state_size),batch_first=batch_first)\n            \n        self.fc2 = TimeDistributed(nn.Linear(self.hidden_state_size,  self.output_size), batch_first=batch_first)\n        self.elu2 = nn.ELU()\n        \n        self.dropout = nn.Dropout(self.dropout)\n        self.bn = TimeDistributed(nn.BatchNorm1d(self.output_size),batch_first=batch_first)\n        self.gate = TimeDistributed(GLU(self.output_size), batch_first=batch_first)\n\n    def forward(self, x, context=None):\n\n        if self.input_size!=self.output_size:\n            residual = self.skip_layer(x)\n        else:\n            residual = x\n        \n        x = self.fc1(x)\n        if context is not None:\n            context = self.context(context)\n            x = x+context\n        x = self.elu1(x)\n        \n        x = self.fc2(x)\n        x = self.dropout(x)\n        x = self.gate(x)\n        x = x+residual\n        x = self.bn(x)\n        \n        return x\n\n\nclass VariableSelectionNetwork(nn.Module):\n    def __init__(self, input_size, num_inputs, hidden_size, dropout, context=None):\n        super(VariableSelectionNetwork, self).__init__()\n\n        self.hidden_size = hidden_size\n        self.input_size =input_size\n        self.num_inputs = num_inputs\n        self.dropout = dropout\n        self.context=context\n\n        if self.context is not None:\n            self.flattened_grn = GatedResidualNetwork(self.num_inputs*self.input_size, self.hidden_size, self.num_inputs, self.dropout, self.context)\n        else:\n            self.flattened_grn = GatedResidualNetwork(self.num_inputs*self.input_size, self.hidden_size, self.num_inputs, self.dropout)\n\n\n        self.single_variable_grns = nn.ModuleList()\n        for i in range(self.num_inputs):\n            self.single_variable_grns.append(GatedResidualNetwork(self.input_size, self.hidden_size, self.hidden_size, self.dropout))\n\n        self.softmax = nn.Softmax(dim=2)\n\n    def forward(self, embedding, context=None):\n\n        if context is not None:\n            sparse_weights = self.flattened_grn(embedding, context)\n        else:\n            sparse_weights = self.flattened_grn(embedding)\n\n        sparse_weights = self.softmax(sparse_weights).unsqueeze(2)\n\n        var_outputs = []\n        for i in range(self.num_inputs):\n            ##select slice of embedding belonging to a single input\n            var_outputs.append(self.single_variable_grns[i](embedding[:,:, (i*self.input_size) : (i+1)*self.input_size]))\n\n        var_outputs = torch.stack(var_outputs, axis=-1)\n\n        outputs = sparse_weights*var_outputs\n        \n        outputs = outputs.sum(axis=-1)\n\n        return outputs, sparse_weights\n","4d74b6fa":"\"\"\"\nImplementation of Temporal Fusion Transformers: https:\/\/arxiv.org\/abs\/1912.09363\n\"\"\"\nfrom torch import nn\nimport math\nimport torch\nimport ipdb\n\nfrom torch.utils.data import DataLoader,Dataset\nimport pytorch_lightning as pl\n\n\nclass TFT(pl.LightningModule):\n\n    def __init__(self, hparams):\n        super(TFT, self).__init__()\n\n        self.device = hparams['device']\n        self.batch_size = hparams['batch_size']\n        self.static_variables = hparams['static_variables']\n        self.encode_length = hparams['encode_length']\n        self.time_varying_categoical_variables =  hparams['time_varying_categoical_variables']\n        self.time_varying_real_variables_encoder =  hparams['time_varying_real_variables_encoder']\n        self.time_varying_real_variables_decoder =  hparams['time_varying_real_variables_decoder']\n        self.static_embedding_vocab_sizes =  hparams['static_embedding_vocab_sizes']\n        self.time_varying_embedding_vocab_sizes =  hparams['time_varying_embedding_vocab_sizes']\n        self.num_input_series_to_mask = hparams['num_masked_series']\n        self.hidden_size = hparams['lstm_hidden_dimension']\n        self.lstm_layers = hparams['lstm_layers']\n        self.dropout = hparams['dropout']\n        self.embedding_dim = hparams['embedding_dim']\n        self.attn_heads = hparams['attn_heads']\n        self.seq_length = hparams['seq_length']\n        self.learning_rate =hparams['learning_rate']\n        self.train_dl = hparams['train_dl']\n        self.val_dl = hparams['val_dl']\n        self.mse_loss = nn.MSELoss()\n        \n        self.static_embedding_layers = nn.ModuleList()\n        for i in range(self.static_variables):\n            emb = nn.Embedding(self.static_embedding_vocab_sizes[i], self.embedding_dim).to(self.device)\n            self.static_embedding_layers.append(emb)\n        \n        \n        self.time_varying_embedding_layers = nn.ModuleList()\n        for i in range(self.time_varying_categoical_variables):\n            emb = TimeDistributed(nn.Embedding(self.time_varying_embedding_vocab_sizes[i], self.embedding_dim), batch_first=True).to(self.device)\n            self.time_varying_embedding_layers.append(emb)\n\n            \n        self.time_varying_linear_layers = nn.ModuleList()\n        for i in range(self.time_varying_real_variables_encoder):\n            emb = TimeDistributed(nn.Linear(1, self.embedding_dim), batch_first=True).to(self.device)\n            self.time_varying_linear_layers.append(emb)\n\n        self.encoder_variable_selection = VariableSelectionNetwork(self.embedding_dim,\n                                (self.time_varying_real_variables_encoder +  self.time_varying_categoical_variables),\n                                self.hidden_size,\n                                self.dropout,\n                                self.embedding_dim*self.static_variables)\n\n        self.decoder_variable_selection = VariableSelectionNetwork(self.embedding_dim,\n                                (self.time_varying_real_variables_decoder +  self.time_varying_categoical_variables),\n                                self.hidden_size,\n                                self.dropout,\n                                self.embedding_dim*self.static_variables)\n\n        \n        self.lstm_encoder_input_size = self.embedding_dim*(self.time_varying_real_variables_encoder +  \n                                                        self.time_varying_categoical_variables +\n                                                        self.static_variables)\n        \n        self.lstm_decoder_input_size = self.embedding_dim*(self.time_varying_real_variables_decoder +  \n                                                        self.time_varying_categoical_variables +\n                                                        self.static_variables)\n                                      \n\n        self.lstm_encoder = nn.LSTM(input_size=self.hidden_size, \n                            hidden_size=self.hidden_size,\n                           num_layers=self.lstm_layers,\n                           dropout=self.dropout)\n        \n        self.lstm_decoder = nn.LSTM(input_size=self.hidden_size,\n                                   hidden_size=self.hidden_size,\n                                   num_layers=self.lstm_layers,\n                                   dropout=self.dropout)\n\n        self.post_lstm_gate = TimeDistributed(GLU(self.hidden_size))\n        self.post_lstm_norm = TimeDistributed(nn.BatchNorm1d(self.hidden_size))\n\n        self.static_enrichment = GatedResidualNetwork(self.hidden_size,self.hidden_size, self.hidden_size, self.dropout, self.embedding_dim*self.static_variables)\n        \n        self.multihead_attn = nn.MultiheadAttention(self.hidden_size, self.attn_heads)\n        self.post_attn_gate = TimeDistributed(GLU(self.hidden_size))\n\n        self.post_attn_norm = TimeDistributed(nn.BatchNorm1d(self.hidden_size, self.hidden_size))\n        self.pos_wise_ff = GatedResidualNetwork(self.hidden_size, self.hidden_size, self.hidden_size, self.dropout)\n\n        self.pre_output_norm = TimeDistributed(nn.BatchNorm1d(self.hidden_size, self.hidden_size))\n        self.pre_output_gate = TimeDistributed(GLU(self.hidden_size))\n\n        self.single_output_layer = TimeDistributed(nn.Linear(self.hidden_size, 1), batch_first=True)\n\n        \n    def init_hidden(self, batch_size):\n        return torch.zeros(self.lstm_layers, batch_size, self.hidden_size, device=self.device)\n        \n    def apply_embedding(self, x, static_embedding, dates, apply_masking):\n        ###x should have dimensions (batch_size, timesteps, input_size)\n        ## Apply masking is used to mask variables that should not be accessed after the encoding steps\n\n        #Time-varying real valued embeddings \n        if apply_masking:\n            time_varying_real_vectors = []\n            for i in range(self.time_varying_real_variables_decoder):\n                emb = self.time_varying_linear_layers[i+self.num_input_series_to_mask](x[:,:,i+self.num_input_series_to_mask].view(x.size(0), -1, 1))\n                time_varying_real_vectors.append(emb)\n            time_varying_real_embedding = torch.cat(time_varying_real_vectors, dim=2)\n\n        else: \n            time_varying_real_vectors = []\n            for i in range(self.time_varying_real_variables_encoder):\n                emb = self.time_varying_linear_layers[i](x[:,:,i].view(x.size(0), -1, 1))\n                time_varying_real_vectors.append(emb)\n            time_varying_real_embedding = torch.cat(time_varying_real_vectors, dim=2)\n        \n        \n        ##Time-varying categorical embeddings (ie hour)\n        time_varying_categoical_vectors = []\n        for i in range(self.time_varying_categoical_variables):\n            emb = self.time_varying_embedding_layers[i](dates[:, :,i].view(x.size(0), -1, 1).long())\n            time_varying_categoical_vectors.append(emb)\n        \n        time_varying_categoical_embedding = torch.cat(time_varying_categoical_vectors, dim=2)  \n\n        ##repeat static_embedding for all timesteps\n        static_embedding = static_embedding.unsqueeze(1)\n        static_embedding = static_embedding.repeat(1, time_varying_categoical_embedding.size(1), 1 )\n        \n        ##concatenate all embeddings\n        embeddings = torch.cat([static_embedding,time_varying_categoical_embedding,time_varying_real_embedding], dim=2)\n        \n        ##emddings are returned in (time_steps, batch_size, num_variables)\n        return embeddings.view(-1, embeddings.size(0), embeddings.size(2))\n    \n    def encode(self, x, hidden=None):\n    \n        if hidden is None:\n            hidden = self.init_hidden(x.size(1))\n            \n        output, (hidden, cell) = self.lstm_encoder(x, (hidden, hidden))\n        \n        return output, hidden\n        \n    def decode(self, x, hidden=None):\n        \n        if hidden is None:\n            hidden = self.init_hidden(x.size(1))\n            \n        output, (hidden, cell) = self.lstm_decoder(x, (hidden,hidden))\n        \n        return output, hidden\n\n\n    def forward(self, x, identifiers, dates, verbose=False):\n\n        ##x inputs should be in this order\n            # target (will be masked in the decoder)\n            # additional variables not known in the future (ie. temperature - will also be masked in the decoder)\n            # variable known in past and future\n\n        embedding_vectors = []\n        for i in range(self.static_variables):\n            emb = self.static_embedding_layers[i](identifiers[:,i].long())\n            embedding_vectors.append(emb)\n\n\n\n        ##Embedding and variable selection\n        static_embedding = torch.cat(embedding_vectors, dim=1)\n        embeddings_encoder = self.apply_embedding(x[:,:self.encode_length,:].float().to(self.device), \n                                                  static_embedding,\n                                                  dates[:,:self.encode_length,:].float(),\n                                                  apply_masking=False)\n        \n        embeddings_decoder = self.apply_embedding(x[:,self.encode_length:,:].float().to(self.device), \n                                                  static_embedding,\n                                                  dates[:,self.encode_length:,:].float(),\n                                                  apply_masking=True)\n\n        ##static embedding (end of the embeddings_encoder and embeddings_decoder tensors) are passed as the context vectors\n        embeddings_encoder, encoder_sparse_weights = self.encoder_variable_selection(embeddings_encoder[:,:,:-(self.embedding_dim*self.static_variables)],\n                                                                                     embeddings_encoder[:,:,-(self.embedding_dim*self.static_variables):])\n        embeddings_decoder, decoder_sparse_weights = self.decoder_variable_selection(embeddings_decoder[:,:,:-(self.embedding_dim*self.static_variables)],\n                                                                                     embeddings_decoder[:,:,-(self.embedding_dim*self.static_variables):])\n\n        \n        ##LSTM\n        lstm_input = torch.cat([embeddings_encoder,embeddings_decoder], dim=0)\n        encoder_output, hidden = self.encode(embeddings_encoder)\n        decoder_output, _ = self.decode(embeddings_decoder, hidden)\n        lstm_output = torch.cat([encoder_output, decoder_output], dim=0)\n\n        ##skip connection over lstm\n        lstm_output = self.post_lstm_gate(lstm_output+lstm_input)\n\n        ##static enrichment\n        static_embedding = static_embedding.unsqueeze(0)\n        static_embedding = static_embedding.repeat(lstm_output.size(0),1, 1)\n        attn_input = self.static_enrichment(lstm_output, static_embedding)\n\n        ##skip connection over lstm\n        attn_input = self.post_lstm_norm(lstm_output)\n\n        ##Decoder Attention\n        attn_output, attn_output_weights = self.multihead_attn(attn_input[self.encode_length:,:,:], attn_input[:self.encode_length,:,:], attn_input[:self.encode_length,:,:])\n\n        ##skip connection over attention\n        attn_output = self.post_attn_gate(attn_output) + attn_input[self.encode_length:,:,:]\n        attn_output = self.post_attn_norm(attn_output)\n\n        output = self.pos_wise_ff(attn_output)\n\n        ##skip connection over Decoder\n        output = self.pre_output_gate(output) + lstm_output[self.encode_length:,:,:]\n\n        #Final output layers\n        output = self.pre_output_norm(output)\n        single_output = self.single_output_layer(output.view(x.size(0), -1, self.hidden_size))\n\n        if verbose:\n            return single_output,encoder_output, decoder_output, attn_output, attn_output_weights, encoder_sparse_weights, decoder_sparse_weights\n        else:\n            return single_output\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch['x'].float(), batch['x'][:,self.encode_length:,0].float()\n        \n        categorical_vals = batch['id'].squeeze(1).long()\n        time_covs = batch['dates'].long()\n\n        y_hat = self.forward(x, categorical_vals, time_covs)\n        \n        rmseloss = torch.sqrt(self.mse_loss(y_hat.squeeze(), y.flatten(1)))\n\n        tensorboard_logs = {'train_loss': rmseloss}\n\n        return {'loss': rmseloss, 'log': tensorboard_logs}\n    \n    def validation_step(self, batch, batch_idx):\n\n        x, y = batch['x'].float(), batch['x'][:,self.encode_length:,0].float()\n        \n        categorical_vals = batch['id'].squeeze(1).long()\n        time_covs = batch['dates'].long()\n\n        y_hat = self.forward(x, categorical_vals, time_covs)\n        \n        rmseloss = torch.sqrt(self.mse_loss(y_hat.squeeze(), y.flatten(1)))\n        return {'val_loss': rmseloss} \n    \n    def validation_end(self, outputs):\n\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        tensorboard_logs = {'val_loss': avg_loss}\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs, 'progress_bar': {'val_loss': avg_loss}}\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optim, patience=2, verbose=True, min_lr=1e-7)  # note early stopping has patient 3\n        return [optim],[scheduler]\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dl, batch_size=self.batch_size, drop_last=False, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):      \n        return DataLoader(self.val_dl, batch_size=self.batch_size, drop_last=False, shuffle=True, num_workers=4)\n\n        ","345eee9c":"training_data = BikeShareDataset(path = 'training_data\/')\nvalidation_data = BikeShareDataset(path = 'validation_data\/')\nstatic_embedding_vocab_sizes = []\nfor i in range(training_data.ids.shape[-1]):\n    static_embedding_vocab_sizes.append(training_data.ids[:,:,i].max()+1)\nprint('Static Embedding Sizes: ' + str(static_embedding_vocab_sizes))\n\ntime_varying_embedding_vocab_sizes = []\nfor i in range(training_data.tv.shape[-1]):\n    time_varying_embedding_vocab_sizes.append(training_data.tv[:,:,i].max()+1)\nprint('Time Varying Embedding Sizes: ' + str(time_varying_embedding_vocab_sizes))\n","65e659f5":"config = {}\nconfig['static_variables'] = 1\nconfig['time_varying_categoical_variables'] = 6\nconfig['time_varying_real_variables_encoder'] = 7\nconfig['time_varying_real_variables_decoder'] = 6\nconfig['num_masked_series'] = 1\nconfig['static_embedding_vocab_sizes'] = static_embedding_vocab_sizes\nconfig['time_varying_embedding_vocab_sizes'] = time_varying_embedding_vocab_sizes\nconfig['embedding_dim'] = 8\nconfig['lstm_hidden_dimension'] = 64\nconfig['lstm_layers'] = 1\nconfig['dropout'] = 0.0\nconfig['device'] = 'cuda'\nconfig['batch_size'] = 32\nconfig['encode_length'] = 24*14\nconfig['seq_length'] = 24*21\nconfig['learning_rate'] = 0.005\nconfig['attn_heads'] = 2\nconfig['train_dl'] = training_data\nconfig['val_dl'] = validation_data","c75dcf1a":"model = TFT(config)","a3964152":"from pytorch_lightning import Trainer\n\ntrainer = Trainer(max_epochs=20, gpus=1, progress_bar_refresh_rate=4)    \ntrainer.fit(model) ","3fe75097":"testing_data = BikeShareDataset(path = 'test_data\/')\n\ntest_DL = DataLoader(testing_data, batch_size=64, drop_last=False, shuffle=True, num_workers=1)\n\nfor batch in test_DL:\n    break","be4ac2d2":"x, y = batch['x'].float().cuda(), batch['x'][:,model.encode_length:,0].float()\n        \ncategorical_vals = batch['id'].squeeze(1).long().cuda()\ntime_covs = batch['dates'].long().cuda()\n\noutput,encoder_output, decoder_output, \\\n    attn_output, attn_output_weights, \\\n    encoder_sparse_weights, decoder_sparse_weights = model.forward(x, categorical_vals, time_covs, verbose=True)\n\n","3e35f8ec":"index_select = 24\npd_test_data = test_data[[x.all() for x in  (test_data[['year','day', 'events_enc',\n       'holiday_enc','wday','hour']].values == time_covs[index_select][0].cpu().numpy())]]\n\npd_test_data  = pd_test_data[pd_test_data.gender_enc == categorical_vals[index_select][0].cpu().item()]\ndate_range = pd.date_range(start=pd_test_data.starttime.values[0], periods=504, freq='h')\n\ntest_data_slice = test_data[(test_data.starttime.isin(date_range)) & (test_data.gender_enc == categorical_vals[index_select][0].cpu().item())].reset_index()\ntest_data_slice['y_pred_tft'] =  pd.Series(np.concatenate([batch['x'][0,:model.encode_length,0].cpu().numpy(), output[index_select, :,0].detach().cpu().numpy()]))","38432221":"test_data_slice['starttime'] = pd.to_datetime(test_data_slice['starttime'])\ntest_data_slice=  test_data_slice.set_index('starttime')\ntest_data_slice[['tripduration','y_pred','y_pred_tft']].plot(figsize=(8,6))\n\n\nrmse_xgb = ((test_data_slice.iloc[24*14:]['tripduration'] - test_data_slice.iloc[24*14:]['y_pred'])** 2).mean() **.5\nrmse_tft = ((test_data_slice.iloc[24*14:]['tripduration'] - test_data_slice.iloc[24*14:]['y_pred_tft'])** 2).mean() **.5\n\nplt.legend(['Ground Truth','xgboost RMSE: {}'.format(round(rmse_xgb,2)),'TFT RMSE: {}'.format(round(rmse_tft,2))])\nplt.xlim(test_data_slice.index[24*14], )\nplt.title('Model Comparison')","425473e8":"pd.DataFrame(encoder_sparse_weights[:,:,0,:].mean(axis=1).mean(axis=0).detach().unsqueeze(0).cpu().numpy(), columns=all_cols[:]+['time_index']).T.sort_values(0).plot(kind='barh')\n\nplt.xlabel('Encoder Variable Weights')","fdfc40af":"pd.DataFrame(decoder_sparse_weights[:,:,0,:].mean(axis=1).mean(axis=0).detach().unsqueeze(0).cpu().numpy(), columns=all_cols[1:]+['time_index']).T.sort_values(0).plot(kind='barh')\nplt.xlabel('Decoder Variable Weights')","68469b14":"## Modelling\n\nNo we will examine a few different models to see how well we can estimate hourly bike trips for each gender (I split on gender to create more training data) and how important temperature is as a variable. \n\nBelow I start by creating various features as well as taking the log transform of the hourly trips and then standardizing. \n\nFinally I split the data into three partitions:\n* Train (2015-02-01 : 2017-07-14)\n* Validation (2017-07-15 : 2017-08-31) \n* Test (2017-09-01: 2017-12-31) ","3fca26bf":"The TFT model was presented in the paper: *Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting* available here: https:\/\/arxiv.org\/abs\/1912.09363. The architecture is shown below. I ported it (not exactly but closely) from TensorFlow to PyTorch and thought it would be interesting to see how it works on this bike share data. While this model is definitely overkill for the problem here, I thought it would be interesting to compare and see how 'interpretable' it is using the weights that come out of the 'Variable Selection Network' modules of the model. I use the Pytorch Lightning framework for the model training.\n\nI start by creating the same train, validation and test sets, but this time since the model takes in whole sequences I create a sequence based on 21 days of hourly data, of which 14 days will be used for the encoder and the task it to predict the next 7 days of hourly data. To do so we using a sliding window approach to create slices of 21 days of data over the training and validation datasets. ","64be1892":"Final we see what we would expect for the hourly effects, peaks at rush hour and lowest in the early morning hours. ","a6f91132":"In the following two plot we resample daily to see how well the model works over the entire testing horizon - pretty well. ","057eed31":"### Model code and DataLoader (for the training\/validation samples we just created)","456f7935":"To start to get a sense of the correlation between the two, we look at the rolling 30 day correlation between total daily trips and the daily high temperature. We see that the correlation seems highest (around 0.8) in the spring and fall each year and dips during the summer months.","49b54d40":"#### Now we can use the SHAP Package to examine the feature effects on the model output. \n\nThe SHAP methodology is based on 'Shapely Values' from Game Theory. We take take the average model output and the estimate the additive contributions from each feature to arrive at the final model output for each record. ","12099167":"## Initial Analysis and Visualizations\n\nStarting with a basic graph of daily trip counts and the daily high temperature we see that the two seem fairly highly correlated.","0796f08f":"## Temporal Fusion Transformer Model","1d5f379b":"No we look at a heatmap of the correlation between Temperature and Total Trips by hour of day and day of week. We see that the correlation is lowest during the commuting times (especially the morning commute) and lowest on evenings and weekends, which intuitively make sense.","2a3bbc2b":"For daily high temperature we see the contributions are more significantly effected for colder temperatures versus warmer temperatures. This confirms what we saw with rolling 30 day correlation between trips and temperature being lower in the summer.  ","0a5443c5":"### XGBoost\n\nXgboost is usually a solid baseline and we can use the SHAP package to get nice visualizations of various features effects on model outputs. ","5fef9676":"Overall the 7 day and 14 day lag are the most important, but both temperature and daily high temperature are fairly important as well. ","1df7777c":"### Variable weightings:\n\nThe variable selection network uses a learned sparse weight matrix to weight the input variable embeddings. We show the weights ","b70bb258":"Now we look whether it is important if we look at the total trips completed or the total trip length. The heatmap below shows the correlation by hour of day and day of week between total trips and the total trip length. Generally they are very highly correlated so we will stick to total trips completed for the rest of the analysis.","c87d3644":"When we look at the effect of temperature on model output we see a fairly linear relationship. ","a70b421b":"### TFT Output\nBelow we compare two sets of predections - one from above (xgboost) and the ones produced by the TFT model and include the RMSE on the slice shown below. The XGBoost model is slightly more accurate.  ","5ef87213":"We look at the predictions on the test data to evaluate how effective the model is. With a RMSE of 0.2 we would expect it to be pretty good."}}