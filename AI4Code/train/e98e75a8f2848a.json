{"cell_type":{"fa47a46e":"code","1bc8dce9":"code","df7250dd":"code","873b582d":"code","a565775a":"code","61a031d8":"code","711541ef":"code","510e67e5":"code","c5858160":"code","c455fe63":"code","61d95854":"code","b9148b06":"code","0d75fd45":"code","6b16758e":"code","6b0ae323":"code","fe899b02":"code","2ee83e57":"code","3485c0f1":"code","5c416945":"markdown","4c5726d7":"markdown","3f9f0759":"markdown","1c65bd9d":"markdown","42465df6":"markdown","844c45b6":"markdown","e0ce9036":"markdown","00b8fe14":"markdown"},"source":{"fa47a46e":"import pandas as pd\nimport numpy as np\nfrom pandas import Series\nfrom math import sqrt\n\n# metrics\nfrom sklearn.metrics import mean_squared_error\n\nimport statsmodels.api as sm\n\n# forecasting model\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\n# for analysis\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 7\n\nfrom IPython.display import display, HTML\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","1bc8dce9":"train_original=pd.read_csv('..\/input\/jetrail-traffic-dataset\/Train.csv')\ntest_original=pd.read_csv('..\/input\/jetrail-traffic-dataset\/Test.csv')\n\ntrain_original.dropna(inplace=True)\ntest_original.dropna(inplace=True)\ntest_original.drop(test_original.tail(1).index, inplace=True)\n\ntrain_df=train_original.copy()\ntest_df=test_original.copy()\ntest_df.sample(5)","df7250dd":"train_original['Datetime']=pd.to_datetime(train_original.Datetime, format='%d-%m-%Y %H:%M')\ntest_original['Datetime']=pd.to_datetime(test_original.Datetime, format='%d-%m-%Y %H:%M')\ntrain_df['Datetime']=pd.to_datetime(train_df.Datetime, format='%d-%m-%Y %H:%M')\ntest_df['Datetime']=pd.to_datetime(test_df.Datetime, format='%d-%m-%Y %H:%M')\n\n# generate day, month, year feature\nfor i in (train_original, test_original, train_df, test_df):\n    i['year']=i.Datetime.dt.year\n    i['month']=i.Datetime.dt.month\n    i['day']=i.Datetime.dt.day\n    i['hour']=i.Datetime.dt.hour","873b582d":"# sampling for daily basis\ntrain_df.index=train_df.Datetime\ntest_df.index=test_df.Datetime","a565775a":"def plot_result(train_data, valid_data, pred_data):\n    plt.figure(figsize=(12,7))\n    train_data.plot(label='Train')\n    valid_data.plot(label='Valid')\n    pred_data.plot(label='Prediction')\n    _=plt.legend(loc='best')","61a031d8":"# Change resample\ndef resample(data, sample_by):\n    data_resample=data.resample(sample_by).mean()\n    return data_resample","711541ef":"# train valid split\ndef train_valid_split(data, train_start_date='2012-08-25', train_end_date='2014-06-24', valid_start_date='2014-06-25', valid_end_date='2014-09-25'):\n    train=data.loc[train_start_date:train_end_date]\n    valid=data.loc[valid_start_date:valid_end_date]\n    return (train, valid)","510e67e5":"# rmse calculation\ndef rmse(valid, pred):\n    # calculate mse\n    rmse=mean_squared_error(valid, pred, squared=False)\n    return rmse","c5858160":"# check for stationary of data with daily basis\ndf=resample(train_df, 'D')\ndftest=adfuller(df.Count, autolag='AIC')\ndfout=pd.Series(dftest[0:4], index=['Test statistics', 'p-value', '#Lags used', 'Number of observation used'])\nfor key, val in dftest[4].items():\n    dfout['Critical value (%s)'%key]=val\nprint(dfout)\n# p-value > 0.05 -> non-stationary data\n# p-value < 0.05 -> stationary data","c455fe63":"# check rolling mean and std\n# resample data to daily basis\ndf=resample(train_df, 'D')\n# determine rolling stats\nrolmean=df.Count.rolling(window=7).mean() #for 7 days\nrolstd=df.Count.rolling(window=7).std()\nrolmean.dropna(inplace=True)\nrolstd.dropna(inplace=True)\n\nplt.figure(figsize=(12,7))\nrolmean.plot(label='Rolmean', color='black')\nrolstd.plot(label='rolstd')\ndf.Count.plot(label='Train')\n_=plt.legend(loc='best')\nplt.title('Rolling Mean & STD')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","61d95854":"# helper function for grid CV search hyperparameter tuning\ndef grid_search(params, train_data, valid_data):\n    best_rmse=1e10\n    best_param=0\n    for param1 in params['damped']:\n        for param2 in params['exp']:\n            for param3 in params['optim']:\n                for param4 in params['smooth_level_grid']:\n                    for param5 in params['smooth_slope_grid']:\n                        for param6 in params['damping_slope_grid']:\n                            for param7 in params['initial_level_grid']:\n                                for param8 in params['initial_slope_grid']:\n                                    fit1=Holt(train_data, damped=param1, exponential=param2).fit(\n                                        optimized=param3,\n                                        smoothing_level=param4, \n                                        smoothing_slope=param5,\n                                        damping_slope=param6,\n                                        initial_level=param7,\n                                        initial_slope=param8\n                                    )\n                                    pred=fit1.forecast(len(valid_data))\n                                    # check rmse\n                                    pred=np.nan_to_num(pred, nan=0)\n                                    # print(valid_data, pred)\n                                    rmse_err=rmse(pred, valid_data)\n                                    print('params: ',(param1, param2,param3, param4, param5, param6, param7, param8), \n                                          ' rmse: %.4f'%rmse_err)\n                                    if rmse_err<best_rmse:\n                                        best_rmse=rmse_err\n                                        best_param=(param1, param2,param3, param4, param5, param6, param7, param8)\n    print('Best param: ',best_param, ' rmse: %.4f'%best_rmse)\n    return best_param","b9148b06":"def holt_forecast(train_data, valid_data, params):\n    fit1=Holt(np.asarray(train_data), damped=params[0], exponential=params[1]).fit(\n        optimized=params[2],\n        smoothing_level=params[3], \n        smoothing_slope=params[4],\n        damping_slope=params[5],\n        initial_level=params[6],\n        initial_slope=params[7])\n    pred=fit1.forecast(len(valid_data))\n    pred=pd.Series(pred, index=valid_data.index)\n    plot_result(train_data, valid_data, pred)\n    return pred","0d75fd45":"# convert daily basis to hourly basis using hour traffic ratio\ndef convert_to_hourly(forecast, train_df_hourly, test_df_hourly, train_=1):\n    train_origin=train_df_hourly.copy()\n    test_origin=test_df_hourly.copy()\n    # convert to hourly basis\n    pred_df=pd.DataFrame(forecast, columns=['predict']).reset_index()\n    pred_df['year']=pred_df.Datetime.dt.year\n    pred_df['month']=pred_df.Datetime.dt.month\n    pred_df['day']=pred_df.Datetime.dt.day\n\n    if(train_==1):\n        pred_df=pd.merge(pred_df, train_origin, on=('year', 'month', 'day'), how='left')\n    else:\n        pred_df=pd.merge(pred_df, test_origin, on=('year', 'month', 'day'), how='left')\n\n    # count hour ratio\n    train_origin['ratio']=train_origin.Count\/train_origin.Count.sum()\n    grp_ratio=train_origin.groupby('hour')['ratio'].sum().reset_index()\n\n    pred_hour=pd.merge(pred_df, grp_ratio, on='hour', how='left')\n    pred_hour=pd.DataFrame(pred_hour.predict*pred_hour.ratio*24, columns=['Count']).set_index(pred_hour.Datetime_y)\n    return pred_hour.Count","6b16758e":"# split train valid\ntrain, valid=train_valid_split(train_df)\n\n# resample by day\ntrain_sample=resample(train, 'D')\nvalid_sample=resample(valid, 'D')\n\n# grid search for Holt linear\nPARAMS={\n    'damped':[False],\n    'exp':[False],\n    'optim':[True],\n    'smooth_level_grid':np.arange(0,1,0.35),\n    'smooth_slope_grid':np.arange(0,1,0.2),\n    'damping_slope_grid':[None],\n    'initial_level_grid':[None],\n    'initial_slope_grid':np.arange(0.9,1.5,0.2)#[1.2]\n}\nbest_param=grid_search(PARAMS, train_sample.Count.values, valid_sample.Count.values)","6b0ae323":"pred=holt_forecast(train_sample.Count, valid_sample.Count, best_param)\nplt.title('Forecast on Validation Dataset')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","fe899b02":"pred_hourly=convert_to_hourly(pred, train_df, test_df)\nplot_result(train.Count, valid.Count, pred_hourly)\nplt.title('Forecast on Validation Dataset')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","2ee83e57":"train_sample=resample(train_df, 'D')\ntest_sample=resample(test_df, 'D')\n\n# fit1=Holt(np.asarray(train_sample.Count)).fit(smoothing_level=best_param[3], smoothing_slope=best_param[4])\nfit1=Holt(np.asarray(train_sample.Count), damped=best_param[0], exponential=best_param[1]).fit(\n        optimized=best_param[2],\n        smoothing_level=best_param[3], \n        smoothing_slope=best_param[4],\n        damping_slope=best_param[5],\n        initial_level=best_param[6],\n        initial_slope=best_param[7])\npred=fit1.forecast(len(test_sample))\npred=pd.Series(pred, index=test_sample.index)\n\npred_hourly=convert_to_hourly(pred, train_df, test_df, train_=0)\nplot_result(train.Count, valid.Count, pred_hourly)\nplt.title('Forecast on Test Dataset')\nplt.xlabel('Date')\n_=plt.ylabel('Count')","3485c0f1":"# forecasting result\npred_hourly.index=test_df.ID\npd.DataFrame(pred_hourly).sample(10)\n# score 186.5 on AV Public LB","5c416945":"## Import all required libraries","4c5726d7":"# Holt's Linear Forecasting with Hyperparameter Tuning\n### Using Holt's Linear with Hyperparameter tuning to forecast Jetrail traffic for next 7 months for investment purpose. \n\n* Holt's two-parameter model, also known as linear exponential smoothing, is a popular smoothing model for forecasting data with trend. Holt's model has three separate equations that work together to generate a final forecast. The method is also called double exponential smoothing or trend-enhanced exponential smoothing.\n* In this notebook, we will sample data daily, forecast daily data and then transform back to hourly data.","3f9f0759":"## Helper Functions","1c65bd9d":"## Load Jetrail traffic dataset","42465df6":"## Hyperparameter tuning","844c45b6":"## Feature engineering","e0ce9036":"## Test forecasting","00b8fe14":"## Conclusion\n* RMSE validation score: 98.2379\n* RMSE test score: 186.5 still need improvement\n* Daily forecasting with Holt's not fit enough with real values\n\nNext, we will try to improve with Weekly or Monthly forecasting and do some feature engineering.\n\n#### Thank you :D"}}