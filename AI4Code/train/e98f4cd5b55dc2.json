{"cell_type":{"22a61044":"code","68184601":"code","1bf03528":"code","dacd5a6a":"code","6244ae5f":"code","b572e9c8":"code","f6d8b835":"code","93bc3304":"code","e6ee307a":"code","b38cb90e":"code","239fc9ae":"code","171df309":"code","381dfb1e":"code","d03580b6":"code","c9ea12cd":"code","03ddc244":"code","7ba4e58f":"code","00582d9a":"code","1d4650db":"code","8a16893a":"code","db6939a4":"code","78956cde":"code","bf514798":"markdown","6d267053":"markdown","dd8754ed":"markdown","8eba3700":"markdown","693d60f5":"markdown","0486db92":"markdown","0602cbbb":"markdown","c088465a":"markdown","a56c3385":"markdown","9bd59c45":"markdown","d690d510":"markdown"},"source":{"22a61044":"import pandas as pd\nimport sklearn.feature_extraction.text as ft\nimport sklearn.feature_selection as fs\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nimport sklearn.svm as svm\nimport sklearn.calibration as cal\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix,plot_roc_curve,brier_score_loss\nfrom sklearn.metrics import plot_precision_recall_curve,classification_report\nfrom sklearn.metrics import precision_score,roc_auc_score,log_loss\nfrom sklearn.metrics import confusion_matrix,jaccard_score,f1_score,recall_score\nfrom sklearn.preprocessing import FunctionTransformer\nimport seaborn as sns\nimport numpy as np\nimport time\nimport datetime\nimport sklearn.pipeline as pipe\nfrom lime import lime_text\nfrom nltk.corpus import stopwords\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n#from emotes import emotes\nfrom sklearn.decomposition import TruncatedSVD\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalMaxPooling1D, Conv1D, Embedding, LSTM\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom wordcloud import WordCloud, STOPWORDS\nstop_words=set(stopwords.words('english'))\nstopwords = set(STOPWORDS)\nimport warnings\nwarnings.filterwarnings(\"ignore\", 'This pattern has match groups')","68184601":"#!pip3 install tensorflow","1bf03528":"df = pd.read_csv(\"..\/input\/d\/brandonbenton\/botezlive-chat-classification\/botezlive_data.csv\")\n#tmp = pd.read_csv('.\/data\/botezlive_dataframe.csv',low_memory=False,keep_default_na=False)\n\n#df = tmp[['message','moderated']].copy()","dacd5a6a":"#df.rename(columns={'message':'text','moderated':'is_offensive'},inplace=True)","6244ae5f":"def clean_text(row):\n    words = []\n    for w in row.split():\n        word = re.sub('[^A-Za-z0-9]+', '', str(w))\n        words.append(word.lower())\n    return words\n\ndef get_words(df,text_label='text',target_label='is_offensive',value=0):\n    words = []\n    for row in df[df[target_label]==value].iloc[:][text_label]:\n        words += clean_text(row)\n    return ' '.join(words)    \n\ndef get_wordcloud(df,text_label='text',target_label='is_offensive',value=0):\n    words = get_words(df,text_label=text_label,target_label=target_label,value=value)\n    wc = WordCloud(background_color='white',\n                   max_words=500,\n                   stopwords=stopwords)\n    wc.generate(words)\n    return wc","b572e9c8":"def split_data(df,params):\n#trim number of zeros from dataset\n    df_ones = df.loc[df[\"is_offensive\"]==1]\n    df_tmp = df.loc[df[\"is_offensive\"]==0]\n        \n    ratio = len(df_ones)\/len(df_tmp)\n\n    msk = np.random.rand(len(df_tmp)) < params['multiplier']*ratio\n    df_zeros = df_tmp.loc[msk]\n    \n    df = pd.concat([df_ones,df_zeros]).reset_index(drop=True)\n    df_train,df_test = train_test_split(df,test_size=0.2,random_state=0)\n    \n    return df_train,df_test","f6d8b835":"def get_vectorizer(df_train,params):\n    vparams = dict({'stop_words':stop_words,#None,#stop_words,\n                    'min_df':params['min_df'],\n                    'max_df':params['max_df'],\n                    'smooth_idf':params['smooth_idf'],\n                    'analyzer':params['analyzer'],\n                    'ngram_range':params['ngram_range'],\n                    'sublinear_tf':params['sublinear_tf'],\n                    'max_features':params['max_features'],\n                    })\n    \n    vectorizer = ft.TfidfVectorizer(**vparams)\n    x_train = vectorizer.fit_transform(df_train['text'])\n    \n    if params[\"trim features\"]:\n    \n        y = df_train['is_offensive']#y_train\n        x_names = vectorizer.get_feature_names()\n        p_value_limit = params['pvalue limit']\n    \n        dtf_features = pd.DataFrame()\n        for cat in np.unique(y):\n            chi2, p_value = fs.chi2(x_train, y==cat)\n            entry = pd.DataFrame({\"feature\":x_names, \"score\":1-p_value, \"y\":cat})\n            dtf_features = dtf_features.append(entry)\n            dtf_features = dtf_features.sort_values([\"y\",\"score\"], \n                    ascending=[True,False])\n            dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n        x_names = dtf_features[\"feature\"].unique().tolist()   \n    \n        vparams['vocabulary'] = x_names\n        vectorizer = ft.TfidfVectorizer(**vparams)\n    \n    return vectorizer","93bc3304":"def get_dual_vectorizer(df_train,p1,p2):\n\n    vec1 = get_vectorizer(df_train,p1)\n    vec2 = get_vectorizer(df_train,p2)\n    \n    features = set(vec1.get_feature_names()) | set(vec2.get_feature_names())\n    features = list(features)\n    \n    vectorizer = ft.TfidfVectorizer(vocabulary=features,max_features=p1['max_features'])\n    \n    return vectorizer\n    ","e6ee307a":"def get_pca(params):\n    pca = TruncatedSVD(n_components=params['n_components'])\n    #pca.fit(X)\n    #principalDf = pd.DataFrame(data = principalComponents,\n    #                           columns = ['%s' %(i) for i in range(n_components)])\n    return pca\n    ","b38cb90e":"#def param_score(df,params):\ndef transformer(x):\n    return np.array(x.toarray())\n\ndef param_score(df,params):\n    \n    df_train,df_test = split_data(df,params)\n    vectorizer = get_vectorizer(df_train,params)\n    model = get_model(params)\n    \n    y_train = df_train['is_offensive']\n    y_test = df_test['is_offensive']\n    \n    num_splits = 1\n    \n    if params['classifier_type']=='NN': \n        \n        nn = KerasClassifier(build_fn=lambda:model)\n        nn._estimator_type = \"classifier\"\n        vectorizer.fit(df_train['text'])\n        num_rows = df_train.shape[0]\n        num_splits = 1#num_rows\/\/5000 + 1\n        \n        print(\"Number of samples: %s\" %num_rows)\n        print(\"Number of splits: %s\" %num_splits)\n        \n        if params['pca']:\n            pca = get_pca(params)\n            pca.fit(vectorizer.transform(df_train['text']))            \n\n        if num_splits == 1 and params['pca']:\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('pca',pca),\n                                         ('classifier',nn)])\n            my_pipeline.fit(df_train['text'],df_train['is_offensive'],\n                            classifier__verbose=1,\n                            classifier__epochs=params['epochs'],\n                            classifier__batch_size=4)\n        \n        elif num_splits == 1 and not params['pca']:\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('transformer',FunctionTransformer(transformer)),\n                                         ('classifier',nn)])\n            my_pipeline.fit(df_train['text'],df_train['is_offensive'],\n                            classifier__verbose=1,\n                            classifier__epochs=params['epochs'],\n                            classifier__batch_size=4)\n            \n        elif num_splits > 1 and params['pca']:\n            pca.fit(vectorizer.transform(df_train['text'])) \n            df_array = np.array_split(df_train,num_splits)\n            for i in range(num_splits):\n                print(\"Split number: %s\" %i)\n                df_tmp = df_array[i]\n                nn.fit(pca.transform(vectorizer.transform(df_tmp['text'])),\n                       df_tmp['is_offensive'],verbose=1,\n                       epochs=params['epochs'],batch_size=4)\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('pca',pca),\n                                         ('classifier',nn)])    \n                \n        elif num_splits > 1 and not params['pca']:\n            df_array = np.array_split(df_train,num_splits)\n            for i in range(num_splits):\n                print(\"Split number: %s\" %i)\n                df_tmp = df_array[i]\n                nn.fit(transformer(vectorizer.transform(df_tmp['text'])),\n                       df_tmp['is_offensive'],verbose=1,\n                       epochs=params['epochs'],batch_size=4)\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('transformer',FunctionTransformer(transformer)),\n                                         ('classifier',nn)])         \n        \n    else:# params['classifier_type']=='SVM': \n        clf = cal.CalibratedClassifierCV(model,cv=p1['cv'],method='sigmoid')\n        if params['pca']:\n            pca = get_pca(params)\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('pca',pca),\n                                         ('classifier',clf)])\n    \n        else:       \n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('classifier',clf)])\n    \n        my_pipeline.fit(df_train['text'],df_train['is_offensive'])\n    \n    score = my_pipeline.score(df_test['text'],df_test['is_offensive'])\n    print('test accuracy: %s' %score)\n\n    discrete_preds = my_pipeline.predict(df_test['text'])\n    confusion = confusion_matrix(y_test,discrete_preds)\n    \n    test_ones = sum(confusion[1][:])\n    test_zeros = sum(confusion[0][:])\n    \n    scores = dict({'classifier_type':params['classifier_type'],\n                   'splits':num_splits,\n                   'n_samples':df_train.shape[0],\n                   'ngram_range':params['ngram_range'],\n                   'pca':params['pca'],\n                   'n_components':params['n_components'],\n                   'max_features':params['max_features'],\n                   'trim features':params['trim features'],\n                   'pvalue limit':params['pvalue limit'],\n                   'multiplier':params['multiplier'],\n                   'precision':precision_score(y_test,discrete_preds),\n                   'jaccard':jaccard_score(y_test,discrete_preds),\n                   'recall':recall_score(y_test,discrete_preds),\n                   'F1':f1_score(y_test,discrete_preds),\n                   'TP':confusion[1][1]\/test_ones,\n                   'FP':confusion[0][1]\/test_zeros,\n                   'TN':confusion[0][0]\/test_zeros,\n                   'FN':confusion[1][0]\/test_ones,                   \n                  })\n    \n    return my_pipeline,discrete_preds,df_train,df_test,scores","239fc9ae":"def get_model(params):\n    \n    if params['classifier_type'] == 'NN':\n        if params['pca']: feature_num = params['n_components']\n        else: feature_num = params['max_features']    \n    \n        model = Sequential()\n        #model.add(Embedding(feature_num,128))\n        #model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n        model.add(Dense(128,activation='relu',\n              input_shape=(feature_num,)))\n        model.add(Dense(64,activation='relu'))\n        model.add(Dense(1,activation='sigmoid'))\n        model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n   \n        model.summary()\n    \n    if params['classifier_type'] == 'SVM':\n        cparams = dict({'max_iter':1000,'C':params['C'],'class_weight':params['class_weight']})\n        model = svm.LinearSVC(**cparams)\n        \n    if params['classifier_type'] == 'RFC':\n        model = RandomForestClassifier()\n        \n\n    return model#KerasClassifier(model_nn)","171df309":"headers = ['classifier_type',\n           'splits',\n           'n_samples',\n           'ngram_range',\n           'trim features',\n           'pca','n_components',\n           'max_features',\n           'pvalue limit',\n           'multiplier',\n           'precision',\n           'jaccard',\n           'recall',\n           'F1',\n           'TP', 'FP','TN','FN']\ndf_scores = pd.DataFrame(columns=headers)","381dfb1e":"p1 = dict({'classifier_type':'SVM',\n           'min_df':1,\n           'max_df':0.9,\n           'smooth_idf':1,\n           'sublinear_tf':1,\n           'ngram_range':(2,10),\n           'max_features':None,\n           'C':1.0,\n           'cv':5,\n           'analyzer':'char_wb',\n           'trim features':False,\n           'pvalue limit':0.4,\n           'class_weight':None,\n           'multiplier':1,\n           'n_components':400,\n           'epochs':10,\n           'pca':False})\n\np2 = p1.copy()\np2['classifier_type'] = 'NN'\np2['max_features'] = 20000\np2['pca'] = True","d03580b6":"print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))","c9ea12cd":"params_list = [p1]\n\nfor i,p in enumerate(params_list):\n    \n    start = time.time()\n    model,discrete_preds,df_train,df_test,scores = param_score(df,p)\n    df_scores = df_scores.append(scores,ignore_index=True)\n\n    end = time.time()\n    elapsed = end - start\n    \n    remaining_seconds = elapsed*(len(params_list)-i-1)\n    print(\"Done: {:.5f}, Remaining: {:<25}\".format((i+1)\/len(params_list),str(datetime.timedelta(seconds=remaining_seconds))),end=\"\\r\")","03ddc244":"df_scores[\"avg score\"]=df_scores[['precision','recall','jaccard','F1','TP','TN']].values.mean(axis=1)\ndf_scores","7ba4e58f":"df_scores.sort_values(by='avg score', ascending=False, inplace=True)\ndf_scores.head(1)\n\n#df_scores.loc[0,'avg score']","00582d9a":"txt_instance = \"its so hot out\"\n\nexplainer = lime_text.LimeTextExplainer(class_names=\n            np.unique(df_train['is_offensive']))\nexplained = explainer.explain_instance(txt_instance, \n            model.predict_proba, num_features=5)\nexplained.show_in_notebook(text=txt_instance, predict_proba=True)","1d4650db":"def plot_score_curves(clf,X,Y):\n     \n    ax = plt.gca()\n\n    preds = clf.predict_proba(X)[:,1]\n    discrete_preds = clf.predict(X)\n    \n    clf_score = brier_score_loss(Y,preds,pos_label=1)\n    frac_of_positives,mean_predicted_value = cal.calibration_curve(Y,preds,n_bins=20)\n    ax.plot(mean_predicted_value,frac_of_positives,\"s-\",label=\"Sigmoid calibration (Brier loss={:.4f})\".format(clf_score))\n\n    clf_score = brier_score_loss(Y,discrete_preds,pos_label=1)\n    frac_of_positives,mean_predicted_value = cal.calibration_curve(Y,discrete_preds,n_bins=20)\n    ax.plot(mean_predicted_value,frac_of_positives,\"s-\",label=\"Discrete predictions (Brier loss={:.4f})\".format(clf_score))\n\n    ax.plot([0,1],[0,1],\"s--\",label=\"Perfectly calibrated\".format(clf_score))\n\n    plt.legend()\n    \n    plot_roc_curve(clf,X,Y)\n    \n    plot_precision_recall_curve(clf,X,Y)\n    \n    plot_confusion_matrix(clf,X,Y)\n    ","8a16893a":"plot_score_curves(model,df_test['text'],df_test['is_offensive'])","db6939a4":"plot_score_curves(model,df_train['text'],df_train['is_offensive'])","78956cde":"fig = plt.figure(figsize=(15,10))\n\ndf_samp = df_train\n\ndf_samp['prediction'] = model.predict(df_train['text']) #discrete_preds\n\nfor i in range(4):\n    fig.add_subplot(2,2,i+1)\n    #try:\n    label = (i+1) % 2\n    \n    if 0 <= i <= 1:\n        wc = get_wordcloud(df_samp,text_label='text',target_label='is_offensive',value=label)\n        plt.title('Ground Truth: %s' %label)\n    else:   \n        wc = get_wordcloud(df_samp,text_label='text',target_label='prediction',value=label)\n        plt.title('Prediction: %s' %label)\n   #fig = plt.figure(figsize=(10,5))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    #except:\n     #   pass\n    \nplt.show()","bf514798":"### Plot evaluation curves and confusion matrix","6d267053":"**Funcs for wordclouds**","dd8754ed":"### Average of accuracy scores","8eba3700":"# Botezlive chat classification model","693d60f5":"### Classification explainer","0486db92":"**Neural network model**","0602cbbb":"### Builds dictionary of scores based on parameter set","c088465a":"**Get tfidf vectorizer**","a56c3385":"### Select parameter set with highest average accuracy","9bd59c45":"### Goes through each parameter set and builds dataframe with accuracy scores","d690d510":"**Trim features based on chi2 score**"}}