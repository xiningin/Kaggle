{"cell_type":{"cac08a26":"code","4feb649b":"code","64652b34":"code","48f8b1a2":"code","3d20e052":"code","6dce6a44":"code","a4397662":"code","1d097940":"code","099e1313":"code","bc49293d":"code","7ada65e1":"code","ff5327ef":"code","09592577":"code","7bfc16ac":"code","62796f80":"code","f289e214":"code","49f75fac":"code","26122439":"code","69eaacf5":"code","ee67be64":"code","40087ff2":"code","f1c541cb":"code","2341e196":"code","026d9107":"code","92f7ff36":"code","d0d9bfbc":"code","f1a323cc":"code","49713f50":"code","e28c856b":"markdown","777b01ac":"markdown","d0170a3f":"markdown","2558e2cc":"markdown","c11c6322":"markdown","e101f1ee":"markdown","984c50d7":"markdown","e8f4ed0b":"markdown","2efc50c3":"markdown","472a949a":"markdown","ed8a10c9":"markdown","1372bed6":"markdown","fd47a752":"markdown","9c628099":"markdown","24280e9a":"markdown","764f3a6d":"markdown","712744fe":"markdown","c49e6853":"markdown","33d343ef":"markdown","90202477":"markdown","f48a662e":"markdown","be169970":"markdown","1cbfac36":"markdown","d4566c38":"markdown","04f3644f":"markdown","311fb048":"markdown","a3d1ea90":"markdown","e1d31939":"markdown","223d5aa1":"markdown","8495fb32":"markdown","063ed787":"markdown","a88cc5b8":"markdown","8abb002c":"markdown","2e81be06":"markdown","016cf82d":"markdown"},"source":{"cac08a26":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split,cross_val_predict,cross_val_score\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,auc,classification_report,roc_auc_score\nfrom scikitplot.metrics import plot_confusion_matrix,plot_precision_recall_curve\n\nimport lightgbm as lgb\nfrom scipy.stats import randint as sp_randint\nfrom sklearn.model_selection import StratifiedKFold\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('whitegrid')\n","4feb649b":"#import the training dataset\ncc_df=pd.read_csv('..\/input\/creditcard.csv')\ncc_df.head()","64652b34":"#Shape of the dataset\ncc_df.shape","48f8b1a2":"#count of target classes\nprint(cc_df['Class'].value_counts())\n#count for target classes\nfig,ax=plt.subplots(figsize=(20,5))\nsns.countplot(cc_df.Class.values,palette='husl')","3d20e052":"#Percentage of target classes count\ncc_df['Class'].value_counts(normalize=True)","6dce6a44":"%%time\n#Distribution of attributes\nattributes=cc_df.columns.values[1:30]\ndef plot_attribute_distribution(attributes):\n    i=0\n    sns.set_style('whitegrid')\n    \n    fig=plt.figure()\n    ax=plt.subplots(5,6,figsize=(22,18))\n    \n    for var in attributes:\n        i+=1\n        plt.subplot(5,6,i)\n        sns.distplot(cc_df[var],hist=False)\n        plt.xlabel('var',)\n        sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n    plt.show()\n\nplot_attribute_distribution(attributes)","a4397662":"#Correlations in training attributes\nattributes=cc_df.columns.values[1:30]\ncorrelations=cc_df[attributes].corr().abs().unstack().sort_values(kind='quicksort').reset_index()\ncorrelations=correlations[correlations['level_0']!=correlations['level_1']]\nprint(correlations)","1d097940":"#normalized the amount variable by using standard scaler\nss=StandardScaler()\n#convert to numpy array\namount=np.array(cc_df['Amount']).reshape(-1,1)\n#fit transform the data\namount_ss=ss.fit_transform(amount)\n#Create a dataframe\namount_df=pd.DataFrame(amount_ss,columns=['Amount'])\namount_df.head()","099e1313":"#Drop the amount variable\ncc_df=cc_df.drop(['Amount'],axis=1)\ncc_df.head()","bc49293d":"#Creating the amount variable\ncc_df['Amount']=amount_df\ncc_df.head()","7ada65e1":"%%time\n#Training data\nX=cc_df.drop(['Time','Class'],axis=1)\nY=cc_df['Class']\n\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25)\nprint('Shape of X_train :',X_train.shape)\nprint('Shape of X_test:',X_test.shape)\nprint('Shape of y_train :',y_test.shape)\nprint('Shape of y_test :',y_test.shape)","ff5327ef":"%%time\nx=X_train\ny=y_train\n#StratifiedKFold cross validator\ncv=StratifiedKFold(n_splits=5,random_state=42)\nfor train_index,valid_index in cv.split(x,y):\n    X_t, X_v=x.iloc[train_index], x.iloc[valid_index]\n    y_t, y_v=y.iloc[train_index], y.iloc[valid_index]\n\nprint('Shape of X_train :',X_t.shape)\nprint('Shape of X_test:',X_v.shape)\nprint('Shape of y_train :',y_t.shape)\nprint('Shape of y_test :',y_v.shape)","09592577":"%%time\n#Synthetic Minority Oversampling Technique\nsm = SMOTE(random_state=42, ratio=1.0)\n#Generating synthetic data points\nX_smote,y_smote=sm.fit_sample(X_t,y_t)\nX_smote_v,y_smote_v=sm.fit_sample(X_v,y_v)\nprint('shape of X_smote :',X_smote.shape)\nprint('Shape of y_smote :',y_smote.shape)\nprint('shape of X_smote_v :',X_smote_v.shape)\nprint('Shape of y_smote_v :',y_smote_v.shape)","7bfc16ac":"%%time\n#Logistic regression model for SMOTE\nsmote=LogisticRegression(random_state=42)\n#fitting the smote model\nsmote.fit(X_smote,y_smote)","62796f80":"#Accuracy of the model\nsmote_score=smote.score(X_smote,y_smote)\nprint('Accuracy of the smote_model :',smote_score)","f289e214":"%%time\n#Cross validation prediction\ncv_pred=cross_val_predict(smote,X_smote_v,y_smote_v,cv=5)\n#Cross validation score\ncv_score=cross_val_score(smote,X_smote_v,y_smote_v,cv=5)\nprint('cross_val_score :',np.average(cv_score))","49f75fac":"%%time\n#Predicting the model\nsmote_pred=smote.predict(X_test)\nprint(smote_pred)","26122439":"#Confusion matrix\ncm=confusion_matrix(y_test,smote_pred)\n#Plot the confusion matrix\nplot_confusion_matrix(y_test,smote_pred,normalize=False,figsize=(15,8))","69eaacf5":"#ROC_AUC score\nroc_score=roc_auc_score(y_test,smote_pred)\nprint('ROC score :',roc_score)\n\n#ROC_AUC curve\nplt.figure()\nfalse_positive_rate,recall,thresholds=roc_curve(y_test,smote_pred)\nroc_auc=auc(false_positive_rate,recall)\nplt.title('Reciver Operating Characteristics(ROC)')\nplt.plot(false_positive_rate,recall,'b',label='ROC(area=%0.3f)' %roc_auc)\nplt.legend()\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.0])\nplt.ylabel('Recall(True Positive Rate)')\nplt.xlabel('False Positive Rate')\nplt.show()","ee67be64":"#Classification report\nscores=classification_report(y_test,smote_pred)\nprint(scores)","40087ff2":"%%time\n#train data\nlgb_train=lgb.Dataset(X_t,y_t)\n#validation data\nlgb_valid=lgb.Dataset(X_v,y_v)","f1c541cb":"#choosing the hyperparameters\nparams={'boosting_type': 'gbdt', \n          'max_depth' : 25,\n          'objective': 'binary',\n          'boost_from_average':False, \n          'nthread': 12,\n          'num_leaves': 120,\n          'learning_rate': 0.07,\n          'max_bin': 1000,  \n          'subsample_for_bin': 200,\n          'is_unbalance':True,\n          'metric' : 'auc',\n          }","2341e196":"%%time\n#training the model\nnum_round=5000\nlgbm= lgb.train(params,lgb_train,num_round,valid_sets=[lgb_train,lgb_valid],verbose_eval=500,early_stopping_rounds = 4000)\nlgbm","026d9107":"#predict the model\nlgbm_predict_prob=lgbm.predict(X_test,random_state=42,num_iteration=lgbm.best_iteration)\nprint(lgbm_predict_prob)\n#Convert to binary output\nlgbm_predict=np.where(lgbm_predict_prob>=0.5,1,0)\nprint(lgbm_predict)","92f7ff36":"lgb.plot_importance(lgbm,max_num_features=29,importance_type=\"split\",figsize=(15,8))","d0d9bfbc":"plt.figure()\n#confusion matrix\ncm=confusion_matrix(y_test,lgbm_predict)\nprint(cm)\nlabels=['True','False']\nplt.figure(figsize=(10,5))\nsns.heatmap(cm,xticklabels=labels,yticklabels=labels,cmap='Blues',vmin=0.2,annot=True,fmt='d')\nplt.title('Confusion_matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\nplt.show()","f1a323cc":"#printing the classification report\nprint(classification_report(y_test,lgbm_predict))","49713f50":"#submitting the prediction results\nsub_df=pd.DataFrame(data=lgbm_predict_prob,columns=['lgbm_pred'])\nsub_df['smote_pred']=smote_pred\n#Save to csv file\nsub_df.to_csv('submission.csv',index=False)","e28c856b":"**Training the lgbm model**","777b01ac":"**Import the necessary libraries**","d0170a3f":"**Model performance on test data**","2558e2cc":"**Import the dataset**\n\n**Where variables from V1-V28 is generated by PCA reduction technique.**","c11c6322":"**Adding normalized Amount variable to training data**","e101f1ee":"**Problem Statement:-**\n\nThe aim of this project is to identify the fraudulent credit card transactions for given class imbalance ratio.","984c50d7":"**Training the model**","e8f4ed0b":"**Cross validation prediction of smoth_model**","2efc50c3":"plot feature importance","472a949a":"**Choosing the hyperparameters**","ed8a10c9":"**Normalize the class labels**","1372bed6":"**Correlation Analysis**","fd47a752":"**Submission**","9c628099":"**Accuracy of model**","24280e9a":"Let us see how baseline logistic regression model performs on synthetic data points.","764f3a6d":"**Reciever operating characteristics (ROC)-Area under curve(AUC) score and curve**","712744fe":"**Classification report**","c49e6853":"**Distribution of attributes**","33d343ef":"**Normalization of Amount variable**","90202477":"**Classification report**","f48a662e":"We can observed that 99.8% of data is non fraud credit card transaction and 0.17% of data is fraud transaction.Dataset is highly imbalanced.","be169970":"SMOTE uses a nearest neighbors algorithm to generate new and synthetic data to balance the imbalance data used for training the model.","1cbfac36":"We can see that corelation between the attributes is very small.","d4566c38":"**Model performance on test data**","04f3644f":"**Synthetic Minority Oversampling Technique(SMOTE)**","311fb048":"**Shape of the dataset**","a3d1ea90":"**Confusion matrix**","e1d31939":"**Drop the old amount variable**","223d5aa1":"**Target classes count**","8495fb32":"Plot the confusion matrix","063ed787":"**Split the training dataset ","a88cc5b8":"**Exploratery Data Analysis**","8abb002c":"**Split the training dataset to train and validation dataset**","2e81be06":"**Credit Card Fraud Detection**","016cf82d":"**Conclusion:-**\n\nLightGBM model is performed well on imbalance data comapared to SMOTE model based on AUC score."}}