{"cell_type":{"c9784a01":"code","888cb8e8":"code","96cb3e9a":"code","aac696fa":"code","be89dca7":"code","fa4764ba":"code","30efcacb":"code","7c02c1b9":"code","650b10c0":"code","09816a18":"code","aadc9bfd":"code","8565636f":"code","b80a109b":"code","d4df6918":"code","4ebe1fc2":"code","1c8189a6":"code","f285a166":"code","8ead7dcf":"code","b714c534":"code","568216a4":"markdown","af2cd435":"markdown","1a517e0e":"markdown","56c1b93b":"markdown","04941339":"markdown","00f28d9b":"markdown","e0816b7a":"markdown","76c4c884":"markdown","540621e7":"markdown","f5fd389c":"markdown","2d9a4216":"markdown","4a5126b0":"markdown","349ab16d":"markdown"},"source":{"c9784a01":"import pandas as pd\nimport matplotlib.pyplot as plt","888cb8e8":"# reading the dataset\ndf = pd.read_csv('..\/input\/big-five-personality-test\/IPIP-FFM-data-8Nov2018\/data-final.csv', sep='\\t')\ndf.head()","96cb3e9a":"df.IPC.value_counts()","aac696fa":"# keep the records where the IPC column equals to 1.\ndf = df.loc[df[\"IPC\"]==1]","be89dca7":"# to check whether it keeps correct number of records. \ndf.shape","fa4764ba":"df.drop(df.columns[50:], axis=1, inplace=True)\n# alternatively:\n# df = df.iloc[:, 0:50]\ndf.head()","30efcacb":"print(df.isnull().any().sum())\ndf.isnull().sum().sort_values(ascending = False)\n","7c02c1b9":"# deleting the missing values\ndf.dropna(inplace = True)\nprint(df.shape)\nprint(df.isnull().sum())  # to check if we delete all cases with missing values.","650b10c0":"# to check whether the reverse items re-coded correctly - 1\ndf[[\"EXT2\",\"EXT4\", \"EST2\", \"AGR1\", \"CSN8\",\"OPN6\"]].head()\n","09816a18":"#re-encoding reverse items\ndf.EXT2 = 6 - df.EXT2.values\ndf.EXT4 = 6 - df.EXT4.values\ndf.EXT6 = 6 - df.EXT6.values\ndf.EXT8 = 6 - df.EXT8.values\ndf.EXT10 = 6 - df.EXT10.values\ndf.EST2 = 6 - df.EST2.values\ndf.EST4 = 6 - df.EST4.values\ndf.AGR1 = 6 - df.AGR1.values\ndf.AGR3 = 6 - df.AGR3.values\ndf.AGR5 = 6 - df.AGR5.values\ndf.AGR7 = 6 - df.AGR7.values\ndf.CSN2 = 6 - df.CSN2.values\ndf.CSN4 = 6 - df.CSN4.values\ndf.CSN6 = 6 - df.CSN6.values\ndf.CSN8 = 6 - df.CSN8.values\ndf.OPN2 = 6 - df.OPN2.values\ndf.OPN4 = 6 - df.OPN4.values\ndf.OPN6 = 6 - df.OPN6.values\n\n# alternatively : \n#df['EXT2'] = df['EXT2'].map({1:5, 2:4, 3:3, 4:2, 5:1})","aadc9bfd":"# to check whether the reverse items re-coded correctly - 2\ndf[[\"EXT2\",\"EXT4\", \"EST2\", \"AGR1\", \"CSN8\",\"OPN6\"]].head()","8565636f":"df_sample = df[0:5000]\n\n# Visualize the elbow\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n\nkmeans = KMeans()\nvisualizer = KElbowVisualizer(kmeans, k=(2,15))\nvisualizer.fit(df_sample)\nvisualizer.poof()","b80a109b":"# Set up k-means\nk_means = KMeans(n_clusters = 5)\n\n#define 5 clusters and fit the model\nk_fit = k_means.fit(df)","d4df6918":"# Predicting the Clusters\npd.options.display.max_columns = 10\npredictions = k_fit.labels_\ndf['Clusters'] = predictions\nprint(df.head())\ndf[\"Clusters\"].unique()","4ebe1fc2":"# calculating total scale score\n\ndf[\"extraversion\"] = 0\ndf[\"neuroticism\"] = 0\ndf[\"agreeableness\"] = 0\ndf[\"conscientiousness\"] = 0\ndf[\"openness\"] = 0\ndf[\"extraversion\"]= (df.EXT1 + df.EXT2 + df.EXT3 + df.EXT4 + df.EXT5 + df.EXT6 + df.EXT7 + df.EXT8 + df.EXT9 + df.EXT10)\/10\ndf[\"neuroticism\"] = (df.EST1 + df.EST2 + df.EST3 + df.EST4 + df.EST5 + df.EST6 + df.EST7 + df.EST8 + df.EST9 + df.EST10)\/10\ndf[\"agreeableness\"] = (df.AGR1 + df.AGR2 + df.AGR3 + df.AGR4 + df.AGR5 + df.AGR6 + df.AGR7 + df.AGR8 + df.AGR9 + df.AGR10)\/10\ndf[\"conscientiousness\"] = (df.CSN1 + df.CSN2 + df.CSN3 + df.CSN4 + df.CSN5 + df.CSN6 + df.CSN7 + df.CSN8 + df.CSN9 + df.CSN10)\/10\ndf[\"openness\"] = (df.OPN1 + df.OPN2 + df.OPN3 + df.OPN4 + df.OPN5 + df.OPN6 + df.OPN7 + df.OPN8 + df.OPN9 + df.OPN10)\/10\ndf.head()","1c8189a6":"# summary statistics of the total scores\ndf[[\"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"]].describe()\n","f285a166":"table = df.groupby('Clusters')[\"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"].mean()\nprint(table)\n\ntable.plot(figsize=(14,9), kind=\"bar\", colormap='Paired')","8ead7dcf":"df_total_scores = df[[\"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"]]\nprint(df_total_scores.head())\nprint(df_total_scores.mean(axis=0))\ndf_total_scores = df_total_scores.apply(lambda x: (x-x.mean())\/x.std(), axis = 0)\nprint(round(df_total_scores.std()))\nprint(round(df_total_scores.mean(axis=0)))\nprint(df_total_scores.head())\n","b714c534":"df_total_scores[\"clusters\"] = df[\"Clusters\"]\ntable = df_total_scores.groupby('clusters')[\"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"].mean()\nprint(table)\n\ntable.plot(figsize=(14,9), kind=\"bar\", colormap='Paired')","568216a4":"<br> IPC: The number of records from the user's IP address in the dataset. \nFor maximum cleanliness, it is suggested using only the records where IPC value 1. ","af2cd435":"Interesting only the answers of IPIP scale. So, we drop the other columns. ","1a517e0e":"![](http:\/\/)Each total score has a mean of 0. \n+1 means that total score of that trait is one standard deviation above the mean, while -1 means one standard deviation below the mean.  ","56c1b93b":"### Deciding the number of clusters\n\nThe elbow method is used to find the optimal value for clusters(k).\n\nFor more information about KElbowVisualizer:\nhttps:\/\/www.scikit-yb.org\/en\/latest\/api\/cluster\/elbow.html#:~:text=The%20elbow%20method%20runs%20k,point%20to%20its%20assigned%20center.","04941339":"### Standardization \nStandardization is the process of rescaling the values of the variables refers to the process of rescaling the values of the variables in your data set so they are on the same scale.In this scaling technique the values are centered around the mean with a unit standard deviation. \nIn cluster analysis, standardization may be crucial if the variables have a different unit or where the scales of each of variables are very different from one another (e.g., 0-1 vs 0-1000). In this dataset all questions are on the same scale. So, we dont make any standardization to the questions. \n","00f28d9b":"### Reverse items[](http:\/\/)\nIPIP Scale contains reverse items, such as EXT2 \"I dont talk a lot\" in Extraversion scale. Giving high points of these question should be related with low level of extraversion. \n<br> Reverse items will be re-encoded. ","e0816b7a":"**IPIP Scale** measures the big five five personality traits: extraversion, agreeableness, openness, conscientiousness, and neuroticism.\nEach trait represents a continuum. Individuals can fall anywhere on the continuum for that trait.\n<br> Scale contains 10 questions for each factor\/trait. ","76c4c884":"### Missing values","540621e7":"### Total scale scores","f5fd389c":"# Cluster analysis - K-means","2d9a4216":"Missing data is under 1%. So, we delete the cases which has missing values.  ","4a5126b0":"### Standardization of the total scores to increase the readability of the visualization","349ab16d":"### Distribution of total scale scores within the clusters"}}