{"cell_type":{"c8c5f465":"code","f25faac8":"code","35c43b00":"code","efb86c62":"code","dcb315dd":"code","dfe284eb":"code","c52c87ba":"code","5ee51855":"code","7a3d6dce":"code","53813c70":"code","a73579c1":"code","e7eea076":"code","a7bb784f":"code","eecc432d":"code","cc47cb2a":"markdown","546b412c":"markdown","7d7da957":"markdown"},"source":{"c8c5f465":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom nilearn import plotting, image, input_data, datasets\nimport nibabel as nb\nimport h5py\nimport matplotlib.pyplot as plt\nimport joblib\nimport seaborn as sns\nfrom tqdm.auto import tqdm\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f25faac8":"brain_mask = nb.load('..\/input\/trends-assessment-prediction\/fMRI_mask.nii')","35c43b00":"scores = pd.read_csv('..\/input\/trends-assessment-prediction\/train_scores.csv', index_col='Id')\nsample_submission = pd.read_csv('..\/input\/trends-assessment-prediction\/sample_submission.csv')\n# Test indices\ntest_index = sample_submission.Id.str.split('_', expand=True)[0].unique().astype('int')\n# Train indices\ntrain_index = scores.index.astype('int')","efb86c62":"try:\n    schaefer_400_data = datasets.fetch_atlas_schaefer_2018(n_rois=400, resolution_mm=2, resume=True, verbose=1)\nexcept:\n    print(\"Probably time out\")","dcb315dd":"plotting.plot_roi(schaefer_400_data.maps, title='Schaefer 2018, 400 rois parcellation');","dfe284eb":"from nilearn import input_data\n# We also use the brain_mask from the beginning\nschaefer_400_masker = input_data.NiftiLabelsMasker(schaefer_400_data.maps, mask_img=brain_mask, smoothing_fwhm=None,\n                                                  standardize=False, detrend=False)\n\ndef load_matlab(participant_id, masker, path='..\/input\/trends-assessment-prediction\/fMRI_train\/'):\n    mat = np.array(h5py.File(f'{path}{participant_id}.mat', mode='r').get('SM_feature'))\n    mat = masker.fit_transform(nb.Nifti1Image(mat.transpose([3,2,1,0]), affine=masker.mask_img.affine))\n    return mat.astype('float32').flatten()","c52c87ba":"tmp = load_matlab(list(train_index)[0], schaefer_400_masker)","5ee51855":"# Parallelization\nfrom joblib import Parallel, delayed\n\ntrain_sm_data = []\n\ntrain_sm_data = Parallel(n_jobs=-1)(delayed(load_matlab)(ii, schaefer_400_masker) for ii in tqdm(list(train_index)))","7a3d6dce":"train_sm_data = np.stack(train_sm_data)\ntrain_sm_data = pd.DataFrame(train_sm_data, index=train_index)","53813c70":"train_sm_data.to_csv('training_data_schaefer18_400.csv.gz', compression='gzip')","a73579c1":"joblib.dump(train_sm_data, 'training_data_schaefer18_400.pkl', compress=3)","e7eea076":"import gc\ntrain_sm_data = []\ngc.collect()","a7bb784f":"test_sm_data = []\n\ntest_sm_data = Parallel(n_jobs=-1)(delayed(load_matlab)(ii, schaefer_400_masker, '..\/input\/trends-assessment-prediction\/fMRI_test\/') for ii in tqdm(list(test_index)))\ntest_sm_data = np.stack(test_sm_data)\n","eecc432d":"\ntest_sm_data = pd.DataFrame(test_sm_data, index=test_index)\n\njoblib.dump(test_sm_data, 'test_data_schaefer18_400.pkl', compress=3)\ntest_sm_data.to_csv('test_data_schaefer18_400.csv.gz', compression='gzip')","cc47cb2a":"I thought it might help to make the 'SM' features more acessible to some people by reducing the amount of data (I'm also casting the values down to floats32 to reduce data - hopefully not losing too much information). \n\nIn neuroimaging parcellations of the brain are often used for this and average values per parcellation are extracted. \n\nThis way we can get to lower resolutions (i.e. 53 x 400 in this case). \n\nUsing nilearn masker objects it is also possible to back-project the data into 3D \/ 4D space, but at the much lower resolution. \n\nFor simplicity - and to add the participant Id, I am also flattening the data you can recover the structure by reshaping to (53, 400). \n\nUsing joblib, we get a datasize of around 1GB - which is nice. ","546b412c":"# Data Reduction \/ Extraction","7d7da957":"400 regions seem to provide a robust solution for feature extraction ([c.f. this article ](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5911196\/))"}}