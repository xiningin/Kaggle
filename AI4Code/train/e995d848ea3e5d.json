{"cell_type":{"3d9cc170":"code","973373af":"code","6d0c9a32":"code","c58592d5":"code","569cb51c":"code","75cebbd9":"code","7a2a7903":"code","7ef8b9e0":"code","ef2ce63a":"code","09ca9de3":"code","af644d73":"code","2a572f4c":"code","fd4ef421":"code","2516dc35":"code","a563c6b0":"code","0b607aa9":"code","5dcee525":"code","21555482":"code","5e925b73":"code","8fdc3d69":"code","67669c47":"code","fa29d971":"code","2a820036":"code","05578761":"code","bc160934":"code","124e1adb":"code","af00d975":"code","3a8581af":"code","5d20aa2c":"code","78ad3469":"code","02a03516":"code","f7cf8399":"code","001f3e54":"code","f118eda7":"code","991829ad":"code","6c795cbc":"code","d576f5cb":"code","0cecf6a1":"code","aa57b25c":"code","360adac6":"code","ebee6b01":"code","e265f670":"markdown","34577460":"markdown","d08dc21f":"markdown","9fe51bb7":"markdown","0eaab2b9":"markdown","8252511b":"markdown","7db2f13a":"markdown","8387fd6e":"markdown","33f0eabd":"markdown","11b2eb6d":"markdown","5858bd77":"markdown","f7f39c6b":"markdown","39ee9975":"markdown","3c440e73":"markdown","1c854898":"markdown","05df6d2e":"markdown","e2bb08f6":"markdown","3da1d392":"markdown","0ca966dd":"markdown","83035c88":"markdown","623c1efe":"markdown","d359de1b":"markdown"},"source":{"3d9cc170":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization library\nimport matplotlib.pyplot as plt # mathematical plotting library","973373af":"#read the dataset\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename));\n        \nadmission_df = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv',index_col=\"Serial No.\")\nadmission_df","6d0c9a32":"admission_df.info()","c58592d5":"admission_df.nunique()","569cb51c":"admission_df.columns","75cebbd9":"admission_df.describe()","7a2a7903":"df_univ = admission_df.groupby(by  = 'University Rating').mean()\ndf_univ","7ef8b9e0":"matrix = admission_df.corr()\nplt.figure(figsize=(8,6))\n#plot heat map\ng=sns.heatmap(matrix,annot=True,cmap=\"RdYlGn_r\")\nplt.title(\"Correltion Matrix\");","ef2ce63a":"#correlatoin pair plots\nsns.pairplot(admission_df.drop(columns=[\"LOR \",\"SOP\",\"Research\"]));","09ca9de3":"sns.jointplot(x=\"CGPA\",y=\"Chance of Admit \",data=admission_df);","af644d73":"num = [304.91176471, 309.13492063, 315.0308642 , 323.3047619 ,\n       327.89041096]","2a572f4c":"plt.figure(figsize=(10,8))\nsns.barplot(y=\"GRE Score\",x=\"University Rating\",data=admission_df)\nplt.ylim([300,330])\nli = 0.1\nfor i in range(5):\n    plt.text(li , num[i]+0.5, np.round(num[i],2) )\n    li+=1\nplt.title(\"Expected GRE score vs University Rating\");","fd4ef421":"sns.boxplot(x=\"LOR \",y=\"Chance of Admit \",data=admission_df)\nplt.title(\"Chance of admission depending on Letter of Recommendation\");","2516dc35":"sns.boxplot(x=\"SOP\",y=\"Chance of Admit \",data=admission_df)\nplt.title(\"Chance of admission depending on Letter of Recommendation\");","a563c6b0":"plt.figure(figsize=(12,8))\nsns.lineplot(x=\"SOP\",y=\"Chance of Admit \",data=admission_df, label=\"SOP\")\nsns.lineplot(x=\"LOR \",y=\"Chance of Admit \",data=admission_df, label=\"LOR\")\nsns.lineplot(x=\"University Rating\",y=\"Chance of Admit \",data=admission_df, label=\"Research\")\nplt.legend()\nplt.title(\"features affecting admission on Scale of 0-5\")\nplt.xlabel(\"Features Scale\")\nplt.show()","0b607aa9":"#creating histograms\nadmission_df.hist(bins = 30, figsize=(10,10), color= 'orange');","5dcee525":"#create the dependent and independent dataset\n#splitting training and test set \n#test set is last 100 observations\n\nX_train=admission_df.iloc[0:400,:-1].values\ny_train= admission_df.iloc[0:400,-1].values\nX_test=admission_df.iloc[400:500,:-1].values\ny_test= admission_df.iloc[400:500,-1].values","21555482":"#feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","5e925b73":"GRE=[]\nTOEFL=[]\n\nfor i in range(X_train.shape[0]):\n    GRE.append(X_train[i][1])\n    TOEFL.append(X_train[i][0])","8fdc3d69":"sns.kdeplot(GRE, shade=True, label=\"GRE\")\nsns.kdeplot(TOEFL, shade=True, label=\"TOEFL\")\nplt.title(\"Density chart of GRE vs TOEFL\")","67669c47":"from sklearn.linear_model import LinearRegression\nlinear_reg = LinearRegression()\nlinear_reg.fit(X_train, y_train)","fa29d971":"y_lin_pred = linear_reg.predict(X_test)","2a820036":"from sklearn.tree import DecisionTreeRegressor\nDecision_regressor = DecisionTreeRegressor(random_state = 0)\nDecision_regressor.fit(X_train, y_train)","05578761":"y_decision_pred = Decision_regressor.predict(X_test)","bc160934":"from sklearn.ensemble import RandomForestRegressor\nForest_regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\nForest_regressor.fit(X_train, y_train)","124e1adb":"y_forest_pred = Forest_regressor.predict(X_test)","af00d975":"#Libraries to train Neural network\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam","3a8581af":"ANN_model = keras.Sequential()\nANN_model.add(Dense(50, input_dim=7))\nANN_model.add(Activation('relu'))\n\nANN_model.add(Dense(150))\nANN_model.add(Activation('relu'))\nANN_model.add(Dropout(0.5))\n\nANN_model.add(Dense(150))\nANN_model.add(Activation('relu'))\nANN_model.add(Dropout(0.5))\n\nANN_model.add(Dense(50))\nANN_model.add(Activation('linear'))\nANN_model.add(Dense(1))\n\n\nANN_model.compile(loss = 'mse', optimizer = 'adam')\nANN_model.summary()\n","5d20aa2c":"#Using Adam optimizer\nANN_model.compile(optimizer = 'Adam', loss = 'mean_squared_error')","78ad3469":"epochs_hist = ANN_model.fit(X_train, y_train, epochs = 100, batch_size = 20);","02a03516":"y_ann_pred = ANN_model.predict(X_test)\nresult = ANN_model.evaluate(X_test, y_test)","f7cf8399":"epochs_hist.history.keys()","001f3e54":"plt.plot(epochs_hist.history['loss'])\nplt.title('Model Loss Progreess During Training')\nplt.xlabel('Epoch')\nplt.ylabel('Training Loss')\nplt.legend(['Training Loss'])","f118eda7":"from sklearn.metrics import accuracy_score\nacc_lin = linear_reg.score(X_test, y_test)\nprint(\"Liner Accuracy : {}\".format(acc_lin))","991829ad":"acc_decision = Decision_regressor.score(X_test, y_test)\nprint(\"Decision Accuracy : {}\".format(acc_decision))","6c795cbc":"acc_forest = Forest_regressor.score(X_test, y_test)\nprint(\"Forest Accuracy : {}\".format(acc_forest))","d576f5cb":"acc_ANN = 1 - ANN_model.evaluate(X_test, y_test)\nprint(\"ANN Accuracy : {}\".format(acc_ANN))","0cecf6a1":"plt.figure(figsize= (14,10))\n#y_test on x axis\n#y_pred on y axis\nplt.subplot(221)\nplt.plot(y_test, y_lin_pred,'o', color = 'b')\nplt.title('Linear plot')\nplt.ylabel(\"linear predict\")\nplt.xlabel(\"test cases\")\n\nplt.subplot(222)\nplt.plot(y_test, y_decision_pred, '^', color = 'r')\nplt.title('Decision plot')\n\nplt.subplot(223)\nplt.plot(y_test, y_forest_pred, 'v', color = 'g')\nplt.title('Forest plot')\n\nplt.subplot(224)\nplt.plot(y_test, y_decision_pred, '*', color = 'aqua')\nplt.title('ANN plot')\n","aa57b25c":"k = X_test.shape[1]\nn= len(X_test)\nk,n ","360adac6":"from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom math import sqrt\n\nr2 = r2_score(y_test, y_lin_pred)\nadj_r2 = 1- (1-r2)*(n-1)\/(n-k-1)\nMAE = mean_absolute_error(y_test, y_lin_pred)\nMSE = mean_squared_error(y_test, y_lin_pred)\nRMSE = float(format(np.sqrt(mean_squared_error(y_test, y_lin_pred)),'.3f'))\n\nprint('R2 - ', r2, '\\nAdjusted R2 - ', adj_r2, '\\nMAE - ', MAE, '\\nMSE - ', MSE, '\\nRMSE - ', RMSE)","ebee6b01":"from statsmodels.api import OLS\nsumm=OLS(y_train,X_train).fit()\nsumm.summary()","e265f670":"<a id=\"T8\"><\/a>\n# Checking the Score of Regressors","34577460":"No null entries in the records","d08dc21f":"$$\\textrm{If you like the work please upvote :-) }$$\n$$\\textrm{Comments are Welcome }$$","9fe51bb7":"Model performance metrics\n\n   In regression model, the most commonly known evaluation metrics include:\n\n   * **R-squared (R2)**, which is the proportion of variation in the outcome that is explained by the predictor variables. \n    \n    It provides an indication of Goodness Of Fit.\n         In multiple regression models, R2 corresponds to the squared correlation between the observed and the predicted values by the model. \n          The Higher the R-squared, the better the model.\n\n* **Adjusted R-squared**, which adjusts the R2 for having too many variables in the model.\n        If useless predictors are added to model, the R2 will decrease.\n        If useful predictoes are added to model, the R2 will increase.\n\n* Mean Absolute Error (MAE), the MAE measures the prediction error. \n        Mathematically,  MAE = mean(abs(observeds - predicteds))\n        MAE is less sensitive to outliers compared to RMSE.\n        If MAE is 0, indicates predictions are perfect.\n\n* Mean Squared Error is the average squared difference between the observed actual outome values and the values predicted by the model. \n        Mathematically, MSE = mean((observeds - predicteds)^2)\n\n* Root Mean Squared Error (RMSE), which measures the average error performed by the model in predicting the outcome for an observation. \n        Mathematically, RMSE = sqrt(MSE)\n        The lower the RMSE, the better the model.\n\n* Residual Standard Error (RSE), also known as the model sigma, is a variant of the RMSE adjusted for the number of predictors in the model. \n        Mathematically, RSE = abs(observed-predict)\n        The lower the RSE, the better the model. \n    ","0eaab2b9":"<a id=\"T61\"><\/a>\n## Linear regression","8252511b":"High CGPA increases the chance of admission","7db2f13a":"<a id=\"T62\"><\/a>\n## Decision Tress and Random Forest Models","8387fd6e":"SOP has a outlier at 5.0 ","33f0eabd":"<a id=\"T5\"><\/a>\n# Create training and testing dataset ","11b2eb6d":"<a id=\"T10\"><\/a>\n# Calculate Regression Model KPIs","5858bd77":"<a id=\"T2\"><\/a>\n# Importing Libraries and the Dataset","f7f39c6b":"<a id=\"T6\"><\/a>\n# Train and evaluate model","39ee9975":"GRE score, TOEFL score, CGPA is highly correlated with chance of admission.","3c440e73":"<a id=\"T3\"><\/a>\n# Perform Exploratory data analysis","1c854898":"<a id=\"T7\"><\/a>\n# Train and evaluate an Artificial Neural Network (ANN)","05df6d2e":"CGPA, GRE, TOEFL are positively related to chance of admit","e2bb08f6":"<a id=\"T4\"><\/a>\n# Perform data visualization","3da1d392":"LOR at 1.5 and 4.5 had an outlier, i.e. the chance of admission of a candidate is higher with low LOR, similarily at 4.5 the chance of admission become less.","0ca966dd":"$$\\textrm{Admission data Analysis and Prediction}$$","83035c88":"<a id=\"T9\"><\/a>\n# Plotting the plots","623c1efe":"<a id=\"T1\"><\/a>\n# Introduction\n\n  In this project, we have build different regression models to predict the chance of admission into a particular university based on the student\u2019s profile.\n\n## INPUTS (features)\n---\n  * GRE scores (out of 340)\n  *\tTOEFL Scores (out of 120)\n  *\tUniversity rating (out of 5)\n  *\tUndergraduate GPA (out of 10)\n  *\tStatement of purpose( SOP)\n  *\tLetter of Recommendation (LOR) strength (out of 5)\n  *\tResearch experience (either 0 or 1)\n\n\n## OUTPUTS (dependent variables)\n---\n     Chance of admission (ranging from 0 to 1)\n\n\n\n\n\n\n","d359de1b":"# Table of contents\n\n* [1: Introduction](#T1)\n* [2: Importing Libraries and Dataset](#T2)\n* [3: Perform Exploratory data Analysis](#T3)\n* [4: Perform data Visualization](#T4)\n* [5: Creating Train & Test set](#T5)\n* [6: Train and Evaluate Model](#T6)\n    - [6.1: Liner Regressor](#T61)\n    - [6.2: Decision Tree and Random Forest model](#T62)\n* [7: Train and Evaluate Artificial Neural Network(ANN)](#T7)\n* [8: Checking the score of Regressors](#T8)\n* [9: Plotting the Plots](#T9)\n* [10: Calculate Regression model KPIs](#T10)"}}