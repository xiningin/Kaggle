{"cell_type":{"c74ddc84":"code","75c22e87":"code","52c2d5cd":"code","9883ea69":"code","b91725cd":"code","1397ac2a":"code","2dd05be6":"code","31a3b524":"code","8985d550":"code","f8af5812":"code","f2700e1a":"code","c54baed1":"code","6b7734a6":"markdown","4f472b94":"markdown","66e7932b":"markdown","5a63d306":"markdown","2252e11b":"markdown","224d9bc4":"markdown","426c8cf7":"markdown","5ac46f97":"markdown","f4376a0b":"markdown","2dc634d8":"markdown","1f67bbf5":"markdown","6e5e6a67":"markdown","bdfaa5ee":"markdown","3927eff3":"markdown","1aa66867":"markdown","6af8c29c":"markdown"},"source":{"c74ddc84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","75c22e87":"wbc = pd.read_csv('\/kaggle\/input\/wisconsin-breast-cancer-cytology-features\/wisconsin_breast_cancer.csv')\nwbc.head()","52c2d5cd":"wbc.info()","9883ea69":"new_data = wbc.dropna()\n\nnew_data.info()","b91725cd":"import seaborn as sns\nsns.pairplot(data=new_data, hue=\"class\", palette=\"Set2\" ,diag_kind=\"hist\")","1397ac2a":"X = new_data.iloc[0:683 , 1:10]\nprint(X)","2dd05be6":"y = new_data.iloc[0:683 , 10:11]\nprint(y)","31a3b524":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=1502775)\nprint(X_test)\nprint(y_train)","8985d550":"from sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(X_train, y_train)","f8af5812":"pred = model.predict(X_test)\nprint(pred[0:10])\nprint(y_test[0:10])","f2700e1a":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test,pred))","c54baed1":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,pred))","6b7734a6":"more info on the data","4f472b94":"The above test report states that the program had a 95% accuracy in finding out the class of each row of data that corresponds to their respective class.","66e7932b":"plotting the data ","5a63d306":"Now that we have a X_train and y_train we make the program learn the data based on these 2 sets using the support vector classification ","2252e11b":"Generating the classification report of the test","224d9bc4":"since 'nuclei' has some null value it better remove all the null data values from the original and create a new dataset ","426c8cf7":"In the above graphs orange indicated data corresponding to Class 1 and green with Class 0","5ac46f97":"using the diag_kind as a \"hist\" since the hue has only 2 values.","f4376a0b":"in the above result we can see that the model was able to predict the first 10 data values but to understand it better we can produce a confusion matrix and a classification report.","2dc634d8":"in the above confusion matrix we can see that the diagnol matrix makes up for most of the data with is a good thing.","1f67bbf5":"Splitting th data into X and y ... X contains all features from column 1 to 10 and y contains \"id\" and \"class\".","6e5e6a67":"Now that we have a model ready to we can test the set called X_test to predict its restective class in y_test.","bdfaa5ee":"splitting the X and y into train and test","3927eff3":"Author : Shashank Mylarapu, ID: 1502775","1aa66867":"the above data set represents the set which our model will learn so as to predict the class of out test data sets.  ","6af8c29c":"because if not it gives us some error which we might want to avoid."}}