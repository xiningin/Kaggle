{"cell_type":{"bbe6d631":"code","2099607f":"code","32c81168":"code","9e55adb3":"code","c78852ca":"code","6794a41c":"code","543ecda1":"code","0e1a79db":"code","b0ee2ef8":"code","25c39552":"code","d09c8b5a":"code","50eb6fbe":"code","002c03d5":"code","710eb7af":"code","a73bcaf5":"code","f5ace30f":"code","b90959aa":"code","f8a011eb":"code","bd40094a":"code","b79a8751":"code","f5eb9f93":"code","2cbb9763":"code","bd57bb73":"code","531e4f9a":"code","f2386759":"code","054d795b":"code","813ff790":"code","b7fc8233":"code","247b4853":"code","22170b17":"code","d5d7e496":"code","e2bec143":"code","150a881d":"code","6c50a94a":"code","035a6319":"code","f15ba7cd":"code","1b96239b":"code","9dece65e":"code","cd4c667e":"code","8438deaa":"code","f01824cb":"code","07218432":"code","768b7285":"code","8f509371":"code","80fccd59":"code","f63746dc":"code","f6a686a1":"code","a6365cea":"code","86cbd058":"code","f14728ee":"code","3b5cf848":"code","a197dc0e":"code","3f5b9dea":"markdown","606f20ba":"markdown","dd22cbef":"markdown","38bad39a":"markdown","682b6fad":"markdown","82277ea0":"markdown","dbdc32d8":"markdown","fb844be3":"markdown"},"source":{"bbe6d631":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2099607f":"#Features\ndf = pd.read_csv(\"\/kaggle\/input\/tsc-ctetw21\/StudentClueFeatures.csv\")\ndf","32c81168":"df.info()","9e55adb3":"df.isna().sum()","c78852ca":"#Train, Test\ntrain = pd.read_csv(\"\/kaggle\/input\/tsc-ctetw21\/train.csv\")\ntrain.info()","6794a41c":"train.describe()","543ecda1":"train.isna().sum()","0e1a79db":"train['Collaboration'].value_counts()","b0ee2ef8":"#Train, Test\ntest = pd.read_csv(\"\/kaggle\/input\/tsc-ctetw21\/test.csv\")\ntest.info()","25c39552":"test.isna().sum()","d09c8b5a":"cols = df.columns\ndf[cols] = df[cols].apply(pd.to_numeric)","50eb6fbe":"cols = train.columns\ntrain[cols] = train[cols].apply(pd.to_numeric)","002c03d5":"cols = test.columns\ntest[cols] = test[cols].apply(pd.to_numeric)","710eb7af":"df = df.set_index('StudentID')","a73bcaf5":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(df)","f5ace30f":"print(pca.explained_variance_ratio_)","b90959aa":"df = pd.DataFrame(df_pca, index=df.index)","f8a011eb":"df","bd40094a":"#Take 5000 Collaborators :3\nCollaborators = train[train['Collaboration']==1].sample(2249784)\n\n#Take 5000 Honest ;-;\nHonest = train[train['Collaboration']==0].sample(3049784)\n\n#Join!\ntrain = pd.concat([Collaborators, Honest]).sample(frac=1)","b79a8751":"# train = train.sample(frac=0.05)","f5eb9f93":"train['Collaboration'].value_counts()","2cbb9763":"train","bd57bb73":"d = df.to_dict(\"index\")","531e4f9a":"s1 = pd.DataFrame.from_records(train['Student1_ID'].apply(lambda x:d[x]).values.tolist())\ns1","f2386759":"s2 = pd.DataFrame.from_records(train['Student2_ID'].apply(lambda x:d[x]).values.tolist())\ns2","054d795b":"x = np.concatenate((s1, s2), axis=1)\nx","813ff790":"x.shape","b7fc8233":"y = np.array(train['Collaboration'])\ny","247b4853":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=2)\nx, y = sm.fit_resample(x, y)","22170b17":"print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))","d5d7e496":"from sklearn.model_selection import train_test_split\n\n#Split into training and test splits\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=64)","e2bec143":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","150a881d":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","6c50a94a":"def accuracy(y_predict, y_true):\n    total = len(y_predict)\n    correct = sum(y_predict==y_true)\n    return 100 * correct\/total","035a6319":"from xgboost import XGBClassifier\nmodel = XGBClassifier(use_label_encoder=False)\npreds = model.fit(X_train, y_train).predict(X_test)\nprint('Forest Train accuracy %s' % model.score(X_train, y_train)) \nprint('Trees Test accuracy %s' % accuracy(preds, y_test)) ","f15ba7cd":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))","1b96239b":"# build the lightgbm model\nimport lightgbm as lgb\nclf = lgb.LGBMClassifier()\nclf.fit(X_train, y_train)","9dece65e":"preds = clf.predict(X_test)\nprint('LightGBM Train accuracy %s' % model.score(X_train, y_train)) \nprint('LightGBM Test accuracy %s' % accuracy(preds, y_test)) ","cd4c667e":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))","8438deaa":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter=500)\nlr.fit(X_train, y_train)","f01824cb":"print(lr.score(X_train, y_train), lr.score(X_test, y_test))","07218432":"y_predict=model.predict(X_test)\nprint(\"The Validation Accuracy is %0.2f percent\" % accuracy(y_predict, y_test))","768b7285":"print(classification_report(y_test, y_predict))","8f509371":"s1_test = pd.DataFrame.from_records(test['Student1_ID'].apply(lambda x:d[x]).values.tolist())\ns2_test = pd.DataFrame.from_records(test['Student2_ID'].apply(lambda x:d[x]).values.tolist())\ns1_test = pca.fit_transform(s1_test)\ns2_test = pca.fit_transform(s2_test)","80fccd59":"X_test = np.concatenate((s1_test, s2_test), axis=1)\nX_test = scaler.fit_transform(X_test)","f63746dc":"X_test.shape","f6a686a1":"y_pred = clf.predict(X_test)","a6365cea":"submission = pd.read_csv(\"\/kaggle\/input\/tsc-ctetw21\/sample_submission.csv\")\nsubmission.head()","86cbd058":"submission['Collaboration'].value_counts()","f14728ee":"submission[\"Collaboration\"] = y_pred","3b5cf848":"submission['Collaboration'].value_counts()","a197dc0e":"submission.to_csv(\"submission.csv\", index=False)","3f5b9dea":"## Inference\nThe dataset contains no null values and there are a lot of 0s and lesser 1s, which means not everyone collaborates with everyone.","606f20ba":"## Generating Submission","dd22cbef":"## Now What ?\nNow I need to replace the Student ID with their features, train an algorithm and then do the same thing for test and Voila!","38bad39a":"## Reading Data","682b6fad":"## Training Model","82277ea0":"Checking if dataset contains any missing values","dbdc32d8":"## Testing Model","fb844be3":"## Defining Training and Testing Data"}}