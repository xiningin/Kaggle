{"cell_type":{"0ef4f760":"code","8345d0aa":"code","4eb45dd6":"code","00d6309b":"code","ba3e2cf5":"code","2ded85fd":"code","8a77929b":"code","c4c31c76":"code","94bdd89d":"code","275bfd24":"code","ef01d544":"markdown","76badf54":"markdown","8ee9f220":"markdown"},"source":{"0ef4f760":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport numpy as np\nimport pandas as pd\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n%matplotlib inline\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport shap","8345d0aa":"%%time\ntrain = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv', index_col=0)\n\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\n\nfeature_cols = test.columns.tolist()","4eb45dd6":"folds = 5\ntrain[\"kfold\"] = -1\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(train,train[\"target\"])):\n    train.loc[valid_indicies, \"kfold\"] = fold","00d6309b":"%%time\nfinal_test_predictions = []\nscores = []\n\nfor fold in range(folds):\n    x_train = train[train.kfold != fold].copy()\n    x_valid = train[train.kfold == fold].copy()\n    x_test  = test[feature_cols].copy()\n    \n    y_train = x_train['target']\n    y_valid = x_valid['target']\n    \n    x_train = x_train[feature_cols]\n    x_valid = x_valid[feature_cols]\n    xgb_params = {\n        'eval_metric': 'auc', \n        'objective': 'binary:logistic', \n        'tree_method': 'gpu_hist', \n        'gpu_id': 0, \n        'predictor': 'gpu_predictor', \n        'n_estimators': 10000, \n        'learning_rate': 0.01063045229441343, \n        'gamma': 0.24652519525750877, \n        'max_depth': 4, \n        'seed': 42,       \n        'min_child_weight': 366, \n        'subsample': 0.6423040816299684, \n        'colsample_bytree': 0.7751264493218339, \n        'colsample_bylevel': 0.8675692743597421, \n        'use_label_encoder': False,\n        'lambda': 0, \n        'alpha': 10\n    }\n    \n    xgb_model = XGBClassifier(**xgb_params)\n    xgb_model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n    \n    preds_train = xgb_model.predict_proba(x_train)[:,1]\n    preds_valid = xgb_model.predict_proba(x_valid)[:,1]\n    auc_train = roc_auc_score(y_train, preds_train)\n    auc = roc_auc_score(y_valid, preds_valid)\n    print(\"Fold\",fold,\", train:\", f\"{auc_train:.5f}\", \", valid:\", f\"{auc:.5f}\")\n    scores.append(auc)\n    \n    preds_test = xgb_model.predict_proba(x_test)[:,1]\n    final_test_predictions.append(preds_test)\n    \n    \nprint(\"AVG AUC:\",np.mean(scores))","ba3e2cf5":"shap_values = shap.TreeExplainer(xgb_model).shap_values(x_valid)\nshap.summary_plot(shap_values, x_valid)","2ded85fd":"shap.dependence_plot(\"f34\", shap_values, x_valid)","8a77929b":"idx = 5\ndata_for_prediction = x_valid.iloc[idx]\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\nprint(xgb_model.predict_proba(data_for_prediction_array))\n\nshap.initjs()\nexplainer = shap.TreeExplainer(xgb_model)\nshap_values = explainer.shap_values(data_for_prediction_array)\nshap.force_plot(explainer.expected_value, shap_values, data_for_prediction)","c4c31c76":"shap.decision_plot(explainer.expected_value, shap_values, data_for_prediction)","94bdd89d":"labels = [f'fold {i}' for i in range(folds)]\n\nfig = ff.create_distplot(final_test_predictions, labels, bin_size=.3, show_hist=False, show_rug=False)\nfig.show()","275bfd24":"sample_submission['target'] = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)","ef01d544":"# Plot Prediction","76badf54":"# KFold","8ee9f220":"# SHAP Values"}}