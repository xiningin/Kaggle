{"cell_type":{"ee470fd1":"code","1ed89faf":"code","1f13b2d7":"code","bb5ee408":"code","75f2a82c":"code","821efa16":"code","baa5ff8d":"code","d0a9906c":"code","831deccb":"code","0b5c3d4c":"code","7c727815":"code","fc984f1b":"code","abb97e7c":"code","68397bc6":"code","c8565a2c":"code","3079814c":"code","8106a7c4":"code","ec6d5d9f":"code","e86521d8":"code","cba0a24e":"code","adff6c59":"code","60d62f41":"code","8fd37ed2":"code","da46e320":"code","6db7aca9":"code","143516c9":"code","01fdec53":"code","921708fe":"code","7628ee5d":"code","5adb64cb":"markdown","7cd94fdb":"markdown","adfc8db9":"markdown","576b4432":"markdown","0aa5e79f":"markdown","bb0a87ed":"markdown","0a659511":"markdown","1246df0a":"markdown","a9f8b177":"markdown","4f6aaee6":"markdown","26640274":"markdown","a33611f6":"markdown","49fe622e":"markdown","e3c41a97":"markdown"},"source":{"ee470fd1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ed89faf":"%%time\nimport tensorflow as tf\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport itertools \nimport matplotlib.pyplot as plt\n%matplotlib inline","1f13b2d7":"%%time\ntrain_dir = '..\/input\/dog-breed-identification\/train'\ntest_dir ='..\/input\/dog-breed-identification\/test'","bb5ee408":"%%time\ndef append_ext(fn):\n    return fn+\".jpg\"\ntraindf = pd.read_csv('..\/input\/dog-breed-identification\/labels.csv',dtype=str)\ntestdf = pd.read_csv('..\/input\/dog-breed-identification\/sample_submission.csv',dtype=str)\ntraindf[\"id\"] = traindf[\"id\"].apply(append_ext)\ntestdf[\"id\"] = testdf[\"id\"].apply(append_ext)\n","75f2a82c":"traindf.head()","821efa16":"testdf.head()","baa5ff8d":"\nsrc_path = \"..\/input\/dog-breed-identification\/train\"\nsub_class = os.listdir(src_path)\n\nfig = plt.figure(figsize=(10,5))\nfor e in range(len(sub_class[:8])):\n    plt.subplot(2,4,e+1)\n    img = plt.imread(os.path.join(src_path,sub_class[e]))\n    plt.imshow(img, cmap=plt.get_cmap('gray'))\n    plt.axis('off')","d0a9906c":"%%time\ntrain_datagen=ImageDataGenerator( rescale=1.\/255.,\n                                  #rotation_range = 20,\n                                  #brightness_range=[0.2,1.0],\n                                  #width_shift_range = 0.2,\n                                  #height_shift_range = 0.2,\n                                  #shear_range = 0.2,\n                                  #zoom_range = [0.7,1],\n                                  horizontal_flip = True,\n                                  #Setting validation split to 2% \n                                  validation_split=0.02 \n                                  )","831deccb":"BATCH_SIZE = 32","0b5c3d4c":"image_size=(331,331)","7c727815":"train_generator=train_datagen.flow_from_dataframe(\ndataframe=traindf,\ndirectory=train_dir,\nx_col=\"id\",\ny_col=\"breed\",\nsubset=\"training\",\nbatch_size=BATCH_SIZE,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",\ntarget_size=image_size,\ncolor_mode=\"rgb\" \n)","fc984f1b":"x,y = next(train_generator)","abb97e7c":"print(type(x))\nprint(x.shape)\nprint(y.shape)","68397bc6":"def show_grid(image_list,nrows,ncols,figsize=(10,10),showaxis='off'):\n    \n    image_list = [image_list[i,:,:,:] for i in range(image_list.shape[0])]\n    fig = plt.figure(None, figsize,frameon=False)\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(nrows, ncols),  # creates 2x2 grid of axes\n                     axes_pad=0.3,  # pad between axes in inch.\n                     share_all=True,\n                     )\n    for i in range(nrows*ncols):\n        ax = grid[i]\n        ax.imshow(image_list[i],cmap='Greys_r')  # The AxesGrid object work as a list of axes.\n        ax.axis('off')\n        ","c8565a2c":"%%time\nshow_grid(x,8,3,figsize=(25,25))\n","3079814c":"valid_generator=train_datagen.flow_from_dataframe(\ndataframe=traindf,\ndirectory=train_dir,\nx_col=\"id\",\ny_col=\"breed\",\nsubset=\"validation\",\nbatch_size=BATCH_SIZE,\nseed=42,\nshuffle=True,\nclass_mode=\"categorical\",\ntarget_size=image_size,\ncolor_mode=\"rgb\")\n","8106a7c4":"test_datagen=ImageDataGenerator(rescale=1.\/255.)\n\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=testdf,\ndirectory=test_dir,\nx_col=\"id\",\ny_col=None,\nbatch_size=BATCH_SIZE,\nseed=42,\nshuffle=False,\nclass_mode=None,\ntarget_size=image_size,\ncolor_mode=\"rgb\")","ec6d5d9f":"shape=(331,331,3)","e86521d8":"pretrained_model = tf.keras.applications.NASNetLarge(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=shape\n    )\npretrained_model.trainable = False\n    \nmodel = tf.keras.Sequential([ \n        pretrained_model,   \n        tf.keras.layers.GlobalAveragePooling2D(),\n        #tf.keras.layers.Dense(256, activation='relu'),\n        #tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(120, activation='softmax')\n    ])","cba0a24e":"#opt = tf.keras.optimizers.Adam(learning_rate=0.001)\nopt=tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9)\nmodel.compile(optimizer = opt ,\n              loss=\"categorical_crossentropy\",\n              metrics=[\"accuracy\"])\nmodel.summary()","adff6c59":"#reduce = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss',factor=0.2,patience=5, min_lr=0.001 )\n\nearly = tf.keras.callbacks.EarlyStopping( patience=2,\n                                          min_delta=0.001,\n                                          restore_best_weights=True)","60d62f41":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nhistory = model.fit(train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=25,\n                    callbacks=[early],)","8fd37ed2":"def display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('MODEL '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","da46e320":"display_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'LOSS',\n    211,\n)\n\ndisplay_training_curves(\n    history.history['accuracy'],\n    history.history['val_accuracy'],\n    'ACCURACY',\n    212,\n)\n","6db7aca9":"score = model.evaluate(valid_generator,batch_size=32)\nprint(\"Accuracy: {:.2f}%\".format(score[1] * 100)) \nprint(\"Loss: \",score[0])\n\n","143516c9":"%%time\npred=model.predict(test_generator)","01fdec53":"df_submission = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/sample_submission.csv')\ndf_submission.head()","921708fe":"df_submission.iloc[:,1:] = pred\ndf_submission.head()","7628ee5d":"%%time\nfinal_df = df_submission.set_index('id')\nfinal_df.to_csv('Submission.csv')","5adb64cb":"# Data preprocessing","7cd94fdb":"# Accuracy","adfc8db9":"# Validation Data","576b4432":"# Plotting Augmented images","0aa5e79f":"# Pretrained model NASNetLarge","bb0a87ed":"# Training Labels","0a659511":"# Test id or Sample Submission","1246df0a":"# Early stopping","a9f8b177":"# Predicting Test Images","4f6aaee6":"# Submission","26640274":"# Loss and Accuracy Curves","a33611f6":"# Training Images","49fe622e":"# Fitting the Model:","e3c41a97":"# Test Data"}}