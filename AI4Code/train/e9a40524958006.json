{"cell_type":{"46fefba8":"code","5af8239e":"code","d1829f2c":"code","11a16fc1":"code","c97c2482":"code","73ea2b05":"code","7efa7f5a":"code","3d70a983":"code","54e84770":"code","bec97736":"code","407c1852":"code","f239b973":"code","c5f24ba9":"code","28298d8c":"code","32ff831e":"code","f387f323":"code","2d35275d":"code","a996137a":"code","4d5cf8f2":"code","65bad91a":"code","b8309f1a":"code","60a7cc14":"code","3955b835":"code","190fa02e":"code","c5923e3e":"code","40ad214d":"code","7cea4378":"code","39ad6fb5":"code","e5456c81":"code","8aad634d":"code","f994462f":"code","69084bf1":"code","2907e00b":"code","fbd2cfce":"code","f44a0c0a":"code","23360684":"code","be5f7428":"code","c5820da3":"code","1ac9dd62":"code","54fc28a5":"code","23b7796a":"code","bec4ae72":"code","b8430c61":"code","1609710c":"code","41a3b811":"code","43611fd6":"code","86ec3554":"code","61658c3b":"code","7e7ec248":"code","ebdc48fd":"code","e4ecc5b6":"code","7ab3b735":"code","4bd44571":"code","85214989":"code","4d3d970e":"code","421194ea":"code","ea03d277":"code","309273df":"code","2b6fc4d6":"code","d7b5a88b":"code","9884ac81":"code","96df9416":"code","f2de4832":"code","a31c7d4f":"code","ec7275b6":"code","cf90c318":"code","8f396d9f":"code","3111f230":"code","95d67ce6":"markdown","1c62b3fc":"markdown","d7fa6d81":"markdown","59f1803f":"markdown","a890bb15":"markdown","f42ae52d":"markdown","d9aa9b94":"markdown","7f217f24":"markdown","9765e694":"markdown","143516d7":"markdown","2b34b56e":"markdown","5ce4d392":"markdown","05c0aedf":"markdown","3628b1c7":"markdown","c249c000":"markdown","6c921981":"markdown","83c8ffb8":"markdown","dd477501":"markdown","16833438":"markdown","d28b41a8":"markdown","ac9a94a3":"markdown","67d7d5db":"markdown","7fc080be":"markdown","753b202e":"markdown","d88f30f5":"markdown","406dab59":"markdown","31a6d6ae":"markdown","a6627ea1":"markdown","f4556f0f":"markdown"},"source":{"46fefba8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5af8239e":"from sklearn.preprocessing import OrdinalEncoder\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","d1829f2c":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","11a16fc1":"train_data.shape","c97c2482":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","73ea2b05":"train = train_data.copy()\ntest = test_data.copy()","7efa7f5a":"train.head()","3d70a983":"test.head()","54e84770":"train.shape","bec97736":"test.shape","407c1852":"train.info()","f239b973":"test.info()","c5f24ba9":"train.isnull().sum()","28298d8c":"test.isnull().sum()","32ff831e":"list_features = test.columns\nprint('Number of features : ',len(list_features))\nprint('')\nfor f in list_features:\n    print('feature:', f, '|| Type:', type(train[f][0]), '|| Example:', train[f][0], '|| number of unique values', len(train[f].unique()) )","f387f323":"train[['Pclass', 'Survived']].groupby('Pclass').mean().sort_values(by='Survived', ascending=False)","2d35275d":"train[['Sex', 'Survived']].groupby('Sex').mean().sort_values(by='Survived', ascending=False)","a996137a":"train[['Embarked', 'Survived']].groupby('Embarked').mean().sort_values(by='Survived', ascending=False)","4d5cf8f2":"train[['Embarked', 'Pclass']].groupby('Embarked').mean().sort_values(by='Pclass', ascending=False)","65bad91a":"train[[\"SibSp\", \"Survived\"]].groupby(['SibSp']).mean().sort_values(by='Survived', ascending=False)","b8309f1a":"train[[\"Parch\", \"Survived\"]].groupby(['Parch']).mean().sort_values(by='Survived', ascending=False)","60a7cc14":"num = sns.FacetGrid(train, col='Survived')\nprint(num.map(plt.hist, 'Age', bins=40))","3955b835":"# Visualize with a countplot\nsns.countplot(x=\"Survived\", data=train)\nplt.show()\n\n# Print the proportions\nprint(train[\"Survived\"].value_counts(normalize=True))","190fa02e":"# Visualize with a countplot\nsns.countplot(x=\"Pclass\", hue=\"Survived\", data=train)\nplt.show()\n\n# Proportion of people survived for each class\nprint(train[\"Survived\"].groupby(train[\"Pclass\"]).mean())\n\n# How many people we have in each class?\nprint(train[\"Pclass\"].value_counts())","c5923e3e":"# Visualize with a countplot\nsns.countplot(x=\"Sex\", hue=\"Survived\", data=train)\nplt.show()\n\n# Proportion of people survived for each class\nprint(train[\"Survived\"].groupby(train[\"Sex\"]).mean())\n\n# How many people we have in each class?\nprint(train[\"Sex\"].value_counts())","40ad214d":"# Make a countplot\nsns.countplot(x=\"Embarked\", hue=\"Survived\", data=train)\nplt.show()\n\n# Print the value counts\nprint(train[\"Embarked\"].value_counts())\n\n# Surviving rates of Embarked\nprint(train[\"Survived\"].groupby(train[\"Embarked\"]).mean())","7cea4378":"# Make a countplot\nsns.countplot(x=\"Embarked\", hue=\"Pclass\", data=train)\nplt.show()\n\n# Print the value counts\nprint(train[\"Embarked\"].value_counts())\n\n# Surviving rates of Embarked\nprint(train[\"Pclass\"].groupby(train[\"Embarked\"]).mean())","39ad6fb5":"train[[\"Name\"]].head()","e5456c81":"# Extract titles feature using name\ntrain[\"Title\"] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\n# Print title counts\nprint(train[\"Title\"].value_counts())","8aad634d":"#display title column\ntrain[[\"Title\"]].head()","f994462f":"train[[\"Title\", \"Survived\"]].groupby(['Title']).mean().sort_values(by='Survived', ascending=False)","69084bf1":"# Extract titles feature using name in test set\ntest[\"Title\"] = test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\n# Print title counts\nprint(test[\"Title\"].value_counts())","2907e00b":"# Survived by age\nsns.histplot(train[train.Survived==1][\"Age\"],color=\"r\", bins=7, label=\"1\")\n\n# Death by age\nsns.histplot(train[train.Survived==0][\"Age\"], bins=7, label=\"0\")\nplt.legend()\nplt.title(\"Age Distribution\")\nplt.show()\n\n#there are missing values in age but we impute them later","fbd2cfce":"#drop passengerId column in both train and test sets\ntrain.drop('PassengerId', axis = 1, inplace = True)\ntest.drop('PassengerId', axis = 1, inplace = True)","f44a0c0a":"#ordinal encoding\n#map classes 1-->1,2-->0,3-->-1\npclass_map = {1:1, 2:0, 3:-1}\ntrain['Pclass'] = train['Pclass'].map(pclass_map)\ntest['Pclass'] = test['Pclass'].map(pclass_map)","23360684":"# Group the Title column    \ndef assign_label_title(title):\n    if title in [\"the Countess\", \"Mlle\", \"Lady\", \"Ms\", \"Sir\", \"Mme\", \"Mrs\", \"Miss\", \"Master\"]:\n        return \"Title_high\"\n    elif title in [\"Major\", \"Col\", \"Dr\"]:\n        return \"Title_middle\"\n    else:\n        return \"Title_low\"","be5f7428":"# Title\ntrain[\"Title\"] = train[\"Title\"].apply(assign_label_title)\ntest[\"Title\"] = test[\"Title\"].apply(assign_label_title)","c5820da3":"train[['Title', 'Survived']].groupby('Title').mean().sort_values(by='Survived', ascending=False)","1ac9dd62":"train.head()","54fc28a5":"imp_age = IterativeImputer(max_iter=100, random_state=34, n_nearest_features=2)\n\n# Impute Age\ntrain[\"Age\"] = np.round(imp_age.fit_transform(train[[\"Age\"]]))\ntest[\"Age\"] = np.round(imp_age.transform(test[[\"Age\"]]))","23b7796a":"# train[\"Age\"].fillna(train.groupby([\"Sex\",\"Pclass\"])[\"Age\"].transform(\"median\"), inplace=True)\n# test[\"Age\"].fillna(test.groupby([\"Sex\",\"Pclass\"])[\"Age\"].transform(\"median\"), inplace=True)","bec4ae72":"test.isnull().sum()","b8430c61":"#after filling missing values\nsns.histplot(train[train.Survived==1][\"Age\"],color=\"r\", bins=7, label=\"1\")\n\n#before filling missing values\nsns.histplot(train_data[train_data.Survived==1][\"Age\"],color=\"y\", bins=7, label=\"1\")\n\nplt.legend()\nplt.title(\"Age Distribution\")\nplt.show()","1609710c":"train.head()","41a3b811":"train.isnull().sum()","43611fd6":"# train[\"Embarked\"] = train[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0])\n# test[\"Embarked\"] = test[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0])","86ec3554":"train.isnull().sum()","61658c3b":"# #Imputers\nimp_embarked = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n\n# # Impute Embarked\ntrain[\"Embarked\"] = imp_embarked.fit_transform(train[[\"Embarked\"]])\ntest[\"Embarked\"] = imp_embarked.transform(test[[\"Embarked\"]])","7e7ec248":"# Imputers\nimp_cabin = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n\n# Impute Embarked\ntrain[\"Cabin\"] = imp_cabin.fit_transform(train[[\"Cabin\"]])\ntest[\"Cabin\"] = imp_cabin.transform(test[[\"Cabin\"]])","ebdc48fd":"train.isnull().sum()","e4ecc5b6":"# Ticket first letters\ntrain[\"Ticket\"] = train[\"Ticket\"].apply(lambda x: str(x)[0])\ntest[\"Ticket\"] = test[\"Ticket\"].apply(lambda x: str(x)[0])\n\n# Cabin first letters\ntrain[\"Cabin\"] = train[\"Cabin\"].apply(lambda x: str(x)[0])\ntest[\"Cabin\"] = test[\"Cabin\"].apply(lambda x: str(x)[0])","7ab3b735":"train.head()","4bd44571":"sns.histplot(train[train.Survived==1][\"Ticket\"],bins=7, label=\"1\")\n\nplt.legend()\nplt.title(\"Ticket Distribution\")\nplt.show()\n\nprint(train.groupby(\"Ticket\")[\"Survived\"].mean().sort_values(ascending=False))","85214989":"# Family Size\ntrain[\"Fsize\"] = train[\"SibSp\"] + train[\"Parch\"]\ntest[\"Fsize\"] = test[\"SibSp\"] + test[\"Parch\"]","4d3d970e":"# Put the mean into the missing value\ntest['Fare'].fillna(train['Fare'].mean(), inplace = True)","421194ea":"# Group the family_size column\ndef assign_passenger_label(family_size):\n    if family_size == 0:\n        return \"Alone\"\n    elif family_size <=3:\n        return \"Small_family\"\n    else:\n        return \"Big_family\"\n    \n# Group the Ticket column\ndef assign_label_ticket(first):\n    if first in [\"F\", \"1\", \"P\", \"9\"]:\n        return \"Ticket_high\"\n    elif first in [\"S\", \"C\", \"2\"]:\n        return \"Ticket_middle\"\n    else:\n        return \"Ticket_low\"\n\n# Group the Cabin column  \ndef assign_label_cabin(cabin):\n    if cabin in [\"D\", \"E\", \"B\", \"F\", \"C\"]:\n        return \"Cabin_high\"\n    elif cabin in [\"G\", \"A\"]:\n        return \"Cabin_middle\"\n    else:\n        return \"Cabin_low\"\n    \n#Group the Age column\ndef assign_label_age(age):\n    if age <= 20:\n        return 0\n    elif 20 < age <= 40:\n        return 2\n    elif 40 < age <= 60:\n        return 3\n    else:\n        return 4","ea03d277":"# Family size\ntrain[\"Fsize\"] = train[\"Fsize\"].apply(assign_passenger_label)\ntest[\"Fsize\"] = test[\"Fsize\"].apply(assign_passenger_label)\n\n# Ticket\ntrain[\"Ticket\"] = train[\"Ticket\"].apply(assign_label_ticket)\ntest[\"Ticket\"] = test[\"Ticket\"].apply(assign_label_ticket)\n\n# Cabin\ntrain[\"Cabin\"] = train[\"Cabin\"].apply(assign_label_cabin)\ntest[\"Cabin\"] = test[\"Cabin\"].apply(assign_label_cabin)\n\n#age grouping\ntrain[\"Age\"] = train[\"Age\"].apply(assign_label_age)\ntest[\"Age\"] = test[\"Age\"].apply(assign_label_age)","309273df":"test.isnull().sum()","2b6fc4d6":"target = train[\"Survived\"]\ntrain.drop([\"Survived\"], axis=1, inplace=True)","d7b5a88b":"object_cols=[\"Pclass\", \"Embarked\", \"Sex\",\"Ticket\",\"Title\",\"Cabin\",\"Fsize\"]\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = train.index\nOH_cols_valid.index = test.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = train.drop(object_cols, axis=1)\nnum_X_valid = test.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\ntrain = pd.concat([num_X_train, OH_cols_train], axis=1)\ntest = pd.concat([num_X_valid, OH_cols_valid], axis=1)","9884ac81":"train.head()","96df9416":"test.head()","f2de4832":"train.drop([\"Name\",\"SibSp\", \"Parch\"], axis=1, inplace=True)\ntest.drop([\"Name\",\"SibSp\", \"Parch\"], axis=1, inplace=True)","a31c7d4f":"train.head()","ec7275b6":"train.shape","cf90c318":"# Function for comparing different approaches\ndef score_dataset(X, y, model=RandomForestClassifier(n_estimators=100, random_state=0)):\n    # Label encoding for categoricals\n    # for colname in X.select_dtypes([\"category\", \"object\"]):\n    #     X[colname], _ = X[colname].factorize()\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n    # Metric is ROC AUC\n    score = cross_val_score(\n        model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n    print('ROC AUC: %.3f (%.3f)' % (mean(score), std(score)))","8f396d9f":"score_dataset(train, target)","3111f230":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(train, target)\npredictions = model.predict(test)\n\ncolumn_names = [\"PassengerId\", \"Survived\"]\noutput = pd.DataFrame(columns = column_names)\noutput[\"PassengerId\"] = test_data.PassengerId\noutput[\"Survived\"] = predictions\nprint(output.head())\noutput.to_csv('my_submission2.csv', index=False)\nprint(\"Your submission was successfully saved!\")","95d67ce6":"# **Fare**","1c62b3fc":"**Get copies of train and test sets**","d7fa6d81":"Survival Rate\n* higher = the Countess, Mlle, Lady, Ms , Sir, Mme, Mrs, Miss, Master\n* neutral = Major, Col, Dr\n* lower = Mr, Rev, Jonkheer, Don, Capt","59f1803f":"# **Analysis**","a890bb15":"# **Age**","f42ae52d":"# **Name**","d9aa9b94":"# **Functions**","7f217f24":"# **Cabin**","9765e694":"# **PClass**","143516d7":"# **Name**","2b34b56e":"# **Sex**","5ce4d392":"# **One-Hot-Encoding**","05c0aedf":"* if class is 1st have more chance to survie\n* if sex is female have more chance to survie\n* if Embarked is S have low chance of survival and the most of C are in 1st class\n* Having a lage family will reduce the chance of survival\n* Age 20-40 has low chance of survival","3628b1c7":"# **Family**","c249c000":"# **Age**","6c921981":"# **Embarked**","83c8ffb8":"# **Survived**","dd477501":"**Imports**","16833438":"# **PClass**","d28b41a8":"We have to consider both training and test sets","ac9a94a3":"# **Machine Learning**","67d7d5db":"* Passenger ID is a unique value and no need to consider\n* for Pclass, we can use ordinal encoding 1-->1 2-->0 3-->-1 \n* Name is like a unique ID and no need to consider but we can extract the title as a new feature\n* Sex - two values - one hot encoding\n* Age - first fill missing values - then group and map them to numeric values\n* SibSp, Parch, Ticket - let's see it later\n* Fare - numeric value\n* Cabin - there are missing values\n* Embarked - drop two missing rows and one-hot-encoding for 4 unique values","7fc080be":"# **Feature Engineering**","753b202e":"# **Embarked**","d88f30f5":"# **Ticket & Cabin**","406dab59":"**Feature Exploration**","31a6d6ae":"**NaN Values**","a6627ea1":"# **PassengerId**","f4556f0f":"* Now we can use one-hot-encoding for title column"}}