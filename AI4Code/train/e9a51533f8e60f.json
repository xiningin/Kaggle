{"cell_type":{"0bff1a37":"code","d2693632":"code","72ce8432":"code","680c9936":"code","7d5bb9c2":"code","08ade59e":"code","9346bcc8":"code","750d5c3b":"code","70bcbd03":"markdown"},"source":{"0bff1a37":"#credit to Martin Beck. Code samples taken from: \n#https:\/\/towardsdatascience.com\/how-to-scrape-tweets-from-twitter-59287e20f0f1\n!pip install GetOldTweets3\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport GetOldTweets3 as got\n\n#import functions for part-of-speech tagging\nfrom nltk import pos_tag, pos_tag_sents\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.stem.porter import PorterStemmer\n#input data files are available in the \"..\/input\/\" directory.\n#for example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#any results you write to the current directory are saved as output.","d2693632":"#function the pulls tweets from a specific username and turns to csv file\n\n#parameters: (list of twitter usernames), (max number of most recent tweets to pull from)\ndef username_tweets_to_csv(username, count):\n    #creation of query object\n    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n                                            .setMaxTweets(count)\n    #creation of list that contains all tweets\n    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n\n    #creating list of chosen tweet data\n    user_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n\n    #creation of dataframe from tweets list\n    tweets_df = pd.DataFrame(user_tweets, columns = ['Datetime', 'Text'])\n\n    #converting dataframe to CSV\n    tweets_df.to_csv('{}-{}k-tweets.csv'.format(username, int(count\/1000)), sep=',')","72ce8432":"\n#function that pulls tweets based on a general search query and turns to csv file\n\n#parameters: (text query you want to search), (max number of most recent tweets to pull from)\ndef text_query_to_csv(text_query, count):\n    #creation of query object\n    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query)\\\n                                                .setMaxTweets(count)\n    #creation of list that contains all tweets\n    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n\n    #creating list of chosen tweet data\n    text_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n\n    #creation of dataframe from tweets\n    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text'])\n\n    #converting tweets dataframe to csv file\n    tweets_df.to_csv('{}-{}k-tweets.csv'.format(text_query, int(count\/1000)), sep=',')\n\n","680c9936":"#execution of this code block may take several minutes\n#input Twitter username(s) to scrape tweets and name csv file\n#change the count variable to change number of most recent Tweets to be scraped\nusername = 'sebastmarsh'\ncount = 3000\n\n#calling function to turn username's past x amount of tweets into a CSV file\nusername_tweets_to_csv(username, count)\n","7d5bb9c2":"#place tweets into dataframe, drop columns, convert column type to string, tokenize.\ndf = pd.read_csv('sebastmarsh-3k-tweets.csv')\ndf = df.drop(columns=['Unnamed: 0', 'Datetime'])\ndf['Text'] = df['Text'].astype(str)\ntext = pos_tag_sents(df['Text'].apply(word_tokenize).tolist())","08ade59e":"#prints the 2000th most recent Tweet\ntext[2000]","9346bcc8":"#remove all words not considered proper nouns (NNPs) in NLTK libray,\n#counts number of occurrences for each\nwordFrequency = list()\nfor line in text:\n    for tag in line:\n        if tag[1] == 'NNP':\n            if tag[0].lower() not in wordFrequency:\n                wordFrequency.append((tag[0].lower(),1))\n            else:\n                index = 0\n                for word in wordFrequency:\n                    if tag[0].lower() == word[index][0]:\n                        word[index][1] = word[index][1] + 1\n                    index = index + 1","750d5c3b":"#make downloadable as csv\ndf = pd.DataFrame(wordFrequency)\ndf.to_csv('wordFrequency.csv')","70bcbd03":"This script that receives a username from Twitter and produces a list of proper nouns used across all Tweets for that account and the number of times each proper noun was used. \nNLTK parsing is far from perfect. The resulting csv file will contain false positives from ambiguous contexts. For example, \"Day\" might be included since there is chance the word is a surname, when in reality it simply occurs at the beginning of the sentence. \n\nThis script led to the data visualization \"Intellectual Inluence in Twitter Posts', which can be viewed [here](https:\/\/public.tableau.com\/profile\/will.luna#!\/vizhome\/IntellectualInfluenceinTwitterPosts\/Dashboard1)"}}