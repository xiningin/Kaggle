{"cell_type":{"838fb568":"code","6fdbc392":"code","efe1ce57":"code","ef49bdaf":"code","1318c26a":"code","876a4029":"code","0d4b1dce":"code","23929551":"code","29a7e427":"code","de360b41":"code","b7132f29":"code","97840805":"code","54a1bf95":"code","331751a5":"code","99495f93":"code","b21b367c":"code","f0f550e8":"code","992a4a02":"code","6321078a":"code","b5fbb0a2":"code","82d80ac5":"code","83cec90e":"code","07304241":"code","3ed96164":"code","3ec0bcc2":"code","827a231e":"code","5605c369":"code","3321c861":"code","83ebb61b":"code","77b374f9":"markdown","52418ce1":"markdown","fe7a6b94":"markdown"},"source":{"838fb568":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nimport random\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\nfrom scipy.signal import resample\nprint(os.listdir(\"..\/input\"))\nfrom keras import backend as K\n\n# Any results you write to the current directory are saved as output.","6fdbc392":"Dataset=pd.read_csv(\"..\/input\/X_train.csv\")\nLabels=pd.read_csv(\"..\/input\/y_train.csv\")\nTest=pd.read_csv(\"..\/input\/X_test.csv\")","efe1ce57":"encode_dic = {'fine_concrete': 0, \n              'concrete': 1, \n              'soft_tiles': 2, \n              'tiled': 3, \n              'soft_pvc': 4,\n              'hard_tiles_large_space': 5, \n              'carpet': 6, \n              'hard_tiles': 7, \n              'wood': 8}\ndecode_dic = {0: 'fine_concrete',\n              1: 'concrete',\n              2: 'soft_tiles',\n              3: 'tiled',\n              4: 'soft_pvc',\n              5: 'hard_tiles_large_space',\n              6: 'carpet',\n              7: 'hard_tiles',\n              8: 'wood'}","ef49bdaf":"Dataset[Dataset[\"series_id\"]==0].head(1)","1318c26a":"Labels.head(1)","876a4029":"Labels[\"group_id\"].unique()","0d4b1dce":"Test.head(1)","23929551":"# missing values and NaN checking","29a7e427":"print(pd.isnull(Dataset).any())\nprint(pd.isna(Dataset).any())","de360b41":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(15, 5))\nsns.countplot(Labels['surface'])\nplt.title('Target distribution', size=15)\nplt.show()\n\nLabels['surface'].value_counts()","b7132f29":"Labels.drop(['series_id', \"group_id\"], axis=1, inplace=True)","97840805":"Dataset.drop(['row_id', \"series_id\", \"measurement_number\"], axis=1, inplace=True)\nDataset = Dataset.values.reshape((3810, 128, 10))","54a1bf95":"Test.drop(['row_id', \"series_id\", \"measurement_number\"], axis=1, inplace=True)\nTest = Test.values.reshape((3816, 128, 10))\n","331751a5":"for j in range(0,10):\n    plt.figure(figsize=(15, 5))\n    plt.title(\"Target : \" + Labels['surface'][j], size=15)\n    for i in range(10):\n        plt.plot(Dataset[j, :, i], label=i)\n    plt.legend()\n    plt.show()","99495f93":"y_train = Labels['surface'].map(encode_dic).astype(int)","b21b367c":"from keras.models import Sequential,Model\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.layers import Embedding\nfrom keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten,Add\nfrom keras.layers import Conv1D, GlobalAveragePooling1D,Softmax\nfrom keras.optimizers import SGD,Adam\nbatch_size = 500\nsgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\ndef gen_model(kernel_size):\n    K.clear_session()\n\n    inp = Input(shape=(128, 10))\n    C = Conv1D(filters=32, kernel_size=kernel_size, strides=1)(inp)\n\n    C11 = Conv1D(filters=32, kernel_size=kernel_size, strides=1, padding='same')(C)\n    A11 = Activation(\"relu\")(C11)\n    C12 = Conv1D(filters=32, kernel_size=kernel_size, strides=1, padding='same')(A11)\n    M11 = MaxPooling1D(pool_size=kernel_size, strides=2)(C12)\n    F1 = Flatten()(M11)\n    \n    D1 = Dense(32)(F1)\n    A6 = Activation(\"relu\")(D1)\n    D2 = Dense(32)(A6)\n    D3 = Dense(9)(D2)\n    A7 = Softmax()(D3)\n\n    model = Model(inputs=inp, outputs=A7)\n    model.compile(loss='sparse_categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n    return model\n    ","f0f550e8":"from keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger, LearningRateScheduler,ReduceLROnPlateau\nimport math\nimport random\ndef exp_decay(epoch):\n    initial_lrate = 0.001\n    k = 0.75\n    t = 3810\/\/(10000 * batch_size)  # every epoch we do n_obs\/batch_size iteration\n    lrate = initial_lrate * math.exp(-k*t)\n    return lrate\n\nlrate = LearningRateScheduler(exp_decay)\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=2)\nlr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)","992a4a02":"model_6=gen_model(kernel_size=6)\nmodel_6.fit(Dataset,y_train,epochs=100,batch_size=batch_size, validation_split=0.2,verbose=0)\nx_train_6=model_6.predict(Dataset)\ny_test_6=model_6.predict(Test)\ny_test_6 = np.argmax(y_test_6, axis=1)","6321078a":"model_7=gen_model(kernel_size=7)\nmodel_7.fit(Dataset,y_train,epochs=100,batch_size=batch_size, validation_split=0.2,verbose=0)\nx_train_7=model_7.predict(Dataset)\ny_test_7=model_7.predict(Test)\ny_test_7 = np.argmax(y_test_7, axis=1)","b5fbb0a2":"model_8=gen_model(kernel_size=8)\nmodel_8.fit(Dataset,y_train,epochs=100,batch_size=batch_size, validation_split=0.2,verbose=0)\nx_train_8=model_8.predict(Dataset)\ny_test_8=model_8.predict(Test)\ny_test_8 = np.argmax(y_test_8, axis=1)","82d80ac5":"x_train_8= np.argmax(x_train_8, axis=1)\nx_train_7= np.argmax(x_train_7, axis=1)\nx_train_6= np.argmax(x_train_6, axis=1)","83cec90e":"x_train_enriched=np.vstack((x_train_6,x_train_7,x_train_8))\nx_train_enriched=np.transpose(x_train_enriched)","07304241":"import xgboost as xgb\nRg2_Classifier=xgb.XGBClassifier()","3ed96164":"Rg2_Classifier.fit(x_train_enriched,y_train)\nRg2_Classifier.score(x_train_enriched,y_train)","3ec0bcc2":"y_test_enriched=np.vstack((y_test_6,y_test_7,y_test_8))\ny_test_enriched=np.transpose(y_test_enriched)","827a231e":"y_test=Rg2_Classifier.predict(y_test_enriched)","5605c369":"sub = pd.read_csv(\"..\/input\/sample_submission.csv\")\nsub['surface'] = y_test\nsub['surface'] = sub['surface'].map(decode_dic)","3321c861":"sub.head()","83ebb61b":"sub.to_csv('submission_MNA_6.csv', index=False)","77b374f9":"Everything about rotations ==>  between 0 to 1. ","52418ce1":"inspired  from : https:\/\/www.kaggle.com\/theoviel\/deep-learning-starter\nhttps:\/\/www.kaggle.com\/coni57\/model-from-arxiv-1805-00794","fe7a6b94":"Group_id : maybe some reference to the team who performed tests... but doesn't appear in test data "}}