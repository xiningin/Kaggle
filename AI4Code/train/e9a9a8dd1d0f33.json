{"cell_type":{"a88dbdc6":"code","71adb8f0":"code","00c68170":"code","80bc22bb":"code","cde95591":"code","4757e159":"code","8c5497a3":"code","fda30ab6":"code","547fed7f":"code","610933b0":"code","a431290d":"code","bf274144":"code","a01bc218":"code","bf2023d6":"code","6912c770":"code","6adb2485":"code","7c419caf":"code","bd6532e3":"code","4579523b":"code","fb0a44d3":"code","e3000772":"code","49bb4cc0":"code","c198ffbf":"code","3a09513e":"code","f01c0119":"code","3ab3006e":"code","96bae25e":"code","5ea42726":"code","992992d8":"code","72d1ce96":"code","9efceaae":"code","1e2e19eb":"code","34fa7db3":"code","1f2e4832":"code","433a186a":"code","7689cdeb":"code","4f3ee280":"code","6f7fdd08":"code","199df94c":"code","ac188110":"code","131adae0":"code","f5a89e8f":"code","ec860666":"code","314e42ef":"code","23c15206":"code","8a4f0452":"code","ab10c8b5":"code","9605b625":"code","feeaca67":"code","b9ab08b1":"code","61fba285":"code","8570682a":"code","6abc4c01":"code","881d42e5":"code","77e47320":"code","a6efd40a":"code","e0448411":"code","3750cd4e":"code","c4d3d4c1":"code","4f1e0215":"code","cfc57fd1":"code","9a630ba9":"code","b3c4af39":"code","2465d5d3":"code","81031ef3":"code","c32f9449":"code","2b2ad9a5":"code","66e2768a":"code","902022c3":"code","3838961d":"code","ff4bb019":"code","d7578de8":"code","336aad03":"code","bea3f52a":"code","84d06048":"code","bc078898":"code","939f5961":"code","d1d824e9":"code","e00ef8be":"code","a327e776":"code","dfba9e99":"code","e3d35a89":"code","00f2370a":"code","d01cc65d":"code","1337243e":"code","0b0c7c4c":"code","da035149":"code","5edba4d2":"code","846f31fa":"code","737ca91a":"code","99743795":"code","a887dc44":"code","3bd8db0d":"markdown","0c91f86a":"markdown","b78f1ff0":"markdown","542e0262":"markdown","a7941fa7":"markdown","d08c43a1":"markdown","fe8502aa":"markdown","cd58f1f7":"markdown","bb4fd5aa":"markdown","256f0c50":"markdown","2a547ce5":"markdown","e795418c":"markdown","ab130cdb":"markdown","3c3a58d8":"markdown","e837eaac":"markdown","ac4aad43":"markdown","2e70db4c":"markdown","0c00c522":"markdown","c0444bf0":"markdown","2f055095":"markdown"},"source":{"a88dbdc6":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport random\nimport time\nimport warnings\nfrom numpy.random import seed\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error\nwarnings.filterwarnings(\"ignore\")\n#import missingno as msno\nfrom sklearn.metrics import roc_auc_score\nimport joblib\nimport statsmodels.api as sm","71adb8f0":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n#from sklearn.compose import make_column_selector as selector\nfrom sklearn.compose import ColumnTransformer","00c68170":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import GridSearchCV","80bc22bb":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n#from sklearn.linear_model import LogisticRegression","cde95591":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n#import xgboost as xgb","4757e159":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\n#from xgboost import XGBRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline","8c5497a3":"df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf","fda30ab6":"test_data=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest_data","547fed7f":"df.dtypes","610933b0":"df.isnull().sum().reset_index().rename(columns={0:'count_null',\n                                                'index':'variable'}).sort_values('count_null',ascending=False).head(25)","a431290d":"plt.figure(figsize=(15,10))\nsns.heatmap(df.isna(), cmap=plt.cm.gist_gray)","bf274144":"#df= df[df1.drop('SalePrice',axis=1).columns]","a01bc218":"df.Alley =df.Alley.fillna('No Alley')\ndf.BsmtQual= df.BsmtQual.fillna('No Basement')\ndf.BsmtCond= df.BsmtCond.fillna('No Basement')\ndf.BsmtExposure= df.BsmtExposure.fillna('No Basement')\ndf.BsmtFinType1= df.BsmtFinType1.fillna('No Basement')\ndf.BsmtFinType2= df.BsmtFinType2.fillna('No Basement')\ndf.FireplaceQu= df.FireplaceQu.fillna('No Fireplace')\ndf.GarageType= df.GarageType.fillna('No Garage')\ndf.GarageFinish= df.GarageFinish.fillna('No Garage')\ndf.GarageQual= df.GarageQual.fillna('No Garage')\ndf.GarageCond= df.GarageCond.fillna('No Garage')\ndf.PoolQC= df.PoolQC.fillna('No Pool')\ndf.Fence= df.Fence.fillna('No Fence')\ndf.MiscFeature= df.MiscFeature.fillna('None')","bf2023d6":"pd.set_option('display.max_columns',100)\npd.set_option('display.max_rows',100)","6912c770":"del df['Id']","6adb2485":"df.describe()","7c419caf":"plt.figure(figsize=(15,10))\nsns.heatmap(df.isna(), cmap=plt.cm.gist_gray)","bd6532e3":"df.columns","4579523b":"df[['GarageYrBlt', 'GarageFinish', 'GarageCars']][df.GarageYrBlt.isnull()==True]","fb0a44d3":"df.GarageYrBlt.hist()","e3000772":"df[['GarageYrBlt','SalePrice']].corr()","49bb4cc0":"df.GarageYrBlt= df.GarageYrBlt.fillna(round(df.GarageYrBlt.mean(),0))","c198ffbf":"df[['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea',]][df.LotFrontage.isnull()==True]","3a09513e":"df[['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea',]][df.LotFrontage.isnull()==True].MSZoning.value_counts()","f01c0119":"df[['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea',]][df.LotFrontage.isnull()==True].MSSubClass.value_counts()","3ab3006e":"mean_lotfronge =df[(df.MSZoning=='RL') & (df.LotFrontage.isnull()==False)].LotFrontage.mean()\ndf.LotFrontage = df.LotFrontage.fillna(round(mean_lotfronge,2))","96bae25e":"plt.figure(figsize=(15,10))\nsns.heatmap(df.isna(), cmap=plt.cm.gist_gray)","5ea42726":"df[df.MasVnrArea.isna()==True]","992992d8":"df[(df.MasVnrArea.isna()==False) & (df.BldgType=='1Fam')].MasVnrType.value_counts()","72d1ce96":"df.MasVnrType= df.MasVnrType.fillna('None')","9efceaae":"df[(df.MasVnrArea.isna()==False) & (df.MasVnrType=='None')].MasVnrArea.median()","1e2e19eb":"df.Electrical= df.Electrical.fillna('FuseA')","34fa7db3":"df.isnull().sum().reset_index().rename(columns={0:'count_null','index':'variable'}).sort_values('count_null',ascending=False).head(25)","1f2e4832":"df[df.isnull().any(axis=1)]","433a186a":"df.BsmtUnfSF.value_counts().reset_index().sort_values('BsmtUnfSF',ascending=False)","7689cdeb":"df.MasVnrArea= df.MasVnrArea.fillna(round(df[(df.MasVnrArea.isna()==False) & (df.MasVnrType=='None')].MasVnrArea.mean(),0))\nmean_lotfronge =df[(df.MSZoning=='RL') & (df.LotFrontage.isnull()==False)].LotFrontage.mean()\ndf.LotFrontage = df.LotFrontage.fillna(round(mean_lotfronge,2))","4f3ee280":"df.Exterior1st= df.Exterior1st.fillna('MetalSd')\ndf.Utilities=df.Utilities.fillna('AllPub')\ndf.Exterior2nd=df.Exterior2nd.fillna('HdBoard')\ndf.BsmtFinSF1=df.BsmtFinSF1.fillna(df.BsmtFinSF1.min())\ndf.BsmtFinSF2=df.BsmtFinSF2.fillna(df.BsmtFinSF2.min())\ndf.MSZoning=df.MSZoning.fillna('RL')\ndf.BsmtUnfSF=df.BsmtUnfSF.fillna(df.BsmtUnfSF.median())","6f7fdd08":"test_data.Alley =test_data.Alley.fillna('No Alley')\ntest_data.BsmtQual= test_data.BsmtQual.fillna('No Basement')\ntest_data.BsmtCond= test_data.BsmtCond.fillna('No Basement')\ntest_data.BsmtExposure= test_data.BsmtExposure.fillna('No Basement')\ntest_data.BsmtFinType1= test_data.BsmtFinType1.fillna('No Basement')\ntest_data.BsmtFinType2= test_data.BsmtFinType2.fillna('No Basement')\ntest_data.FireplaceQu= test_data.FireplaceQu.fillna('No Fireplace')\ntest_data.GarageType= test_data.GarageType.fillna('No Garage')\ntest_data.GarageFinish= test_data.GarageFinish.fillna('No Garage')\ntest_data.GarageQual= test_data.GarageQual.fillna('No Garage')\ntest_data.GarageCond= test_data.GarageCond.fillna('No Garage')\ntest_data.PoolQC= test_data.PoolQC.fillna('No Pool')\ntest_data.Fence= test_data.Fence.fillna('No Fence')\ntest_data.MiscFeature= test_data.MiscFeature.fillna('None')\ntest_data.GarageYrBlt= test_data.GarageYrBlt.fillna(round(test_data.GarageYrBlt.mean(),0))\ntest_data.MasVnrArea= test_data.MasVnrArea.fillna(round(test_data[(test_data.MasVnrArea.isna()==False) & (test_data.MasVnrType=='None')].MasVnrArea.mean(),0))\nmean_lotfronge =test_data[(test_data.MSZoning=='RL') & (test_data.LotFrontage.isnull()==False)].LotFrontage.mean()\ntest_data.LotFrontage = test_data.LotFrontage.fillna(round(mean_lotfronge,2))\ntest_data.MasVnrType= test_data.MasVnrType.fillna('None')\ntest_data.Exterior1st= test_data.Exterior1st.fillna('MetalSd')\ntest_data.Utilities=test_data.Utilities.fillna('AllPub')\ntest_data.Exterior2nd=test_data.Exterior2nd.fillna('HdBoard')\ntest_data.BsmtFinSF1=test_data.BsmtFinSF1.fillna(df.BsmtFinSF1.min())\ntest_data.BsmtFinSF2=test_data.BsmtFinSF2.fillna(df.BsmtFinSF2.min())\ntest_data.MSZoning=test_data.MSZoning.fillna('RL')\ntest_data.BsmtUnfSF=test_data.BsmtUnfSF.fillna(test_data.BsmtUnfSF.median())","199df94c":"plt.figure(figsize=(15,10))\nsns.heatmap(test_data.isna(), cmap=plt.cm.gist_gray)","ac188110":"test_data.Functional.value_counts()","131adae0":"test_data[test_data.LotArea>10000].Functional.value_counts()","f5a89e8f":"test_data[test_data.LotArea>10000].BsmtFullBath.hist()","ec860666":"test_data[test_data.Functional.isnull()==True]","314e42ef":"test_data.GarageArea.value_counts()","23c15206":"test_data[test_data.SaleType.isnull()==True]","8a4f0452":"test_data.SaleType=test_data.SaleType.fillna('WD')","ab10c8b5":"test_data.KitchenQual=test_data.KitchenQual.fillna('Gd')\ntest_data.TotalBsmtSF=test_data.TotalBsmtSF.fillna(0)\ntest_data.GarageCars=test_data.GarageCars.fillna(0)","9605b625":"test_data.GarageArea=test_data.GarageArea.fillna(test_data.GarageArea.median())","feeaca67":"test_data.Functional=test_data.Functional.fillna('Typ')","b9ab08b1":"test_data.BsmtFullBath=test_data.BsmtFullBath.fillna(1)\ntest_data.BsmtHalfBath=test_data.BsmtHalfBath.fillna(0)","61fba285":"test_data.Electrical=test_data.Electrical.fillna('FuseF')","8570682a":"test_data.isnull().sum().reset_index().rename(columns={0:'count_null','index':'variable'}).sort_values('count_null',ascending=False).head(25)","6abc4c01":"df.loc[1298,'BsmtFinSF1'] = 3000","881d42e5":"df.TotalBsmtSF.max()","77e47320":"df.TotalBsmtSF.hist()","a6efd40a":"df[df.TotalBsmtSF > 4000]","e0448411":"df.loc[1298,'TotalBsmtSF']=df.TotalBsmtSF.mean()","3750cd4e":"#data_features.drop(index=1298, inplace=True)","c4d3d4c1":"df.MiscVal.max()","4f1e0215":"df.MiscVal.hist()","cfc57fd1":"df[df.MiscVal > 10000]","9a630ba9":"df.loc[346,'MiscVal']=5000\ndf.loc[1230,'MiscVal']=4000","b3c4af39":"len(df.columns)","2465d5d3":"len(test_data.columns)","81031ef3":"df.describe()","c32f9449":"for i in df.columns[:10]:\n    plt.figure(figsize=(4,3))\n    df[i].hist()\n    plt.xticks(rotation='vertical')\n    plt.show()\n    \n# skipped data visualization and analysis in this notebook since there are good visualization notebooks submitted here","2b2ad9a5":"mask = np.triu(np.ones_like(df.drop(['SalePrice'],axis=1).corr(), dtype=np.bool))","66e2768a":"plt.figure(figsize=(20,20))\nsns.heatmap(df.drop(['SalePrice'],axis=1).corr(),mask=mask ,fmt='.2f',cmap=\"Blues\",\n           linewidth=0.3, cbar_kws={\"shrink\": .8})","902022c3":"def correlation_test(cols):\n    high_cor=[]\n    item=1\n    corr=x_train.corr()\n    for i in corr.columns:\n        var_cors = abs(corr[i])\n        var_cors =var_cors.reset_index()\n        var_cors= var_cors.rename(columns={var_cors.columns[0]:'variables',var_cors.columns[1]:'correlations_'})\n        var_cors=var_cors[item:]\n        var_cors=var_cors[var_cors.correlations_ >= 0.8]\n        vars_=var_cors['variables'].values.tolist()\n        for j in vars_:\n            if j not in high_cor:\n                high_cor.append(j)\n        item+=1\n    cols=x_train.columns.tolist()\n    for i in high_cor:\n        cols.remove(i)\n    return cols","3838961d":"target=df['SalePrice']\ntarget_log=np.log(target)","ff4bb019":"data_obj=df.select_dtypes(include=['object'])\ndata_exclude_obj=df.select_dtypes(exclude=['object'])\ndata_obj['MSSubClass']=data_exclude_obj['MSSubClass']\ndata_exclude_obj.drop(['MSSubClass','SalePrice'],axis=1,inplace=True)\nnum_features = data_exclude_obj.columns\ncat_features = data_obj.columns","d7578de8":"def _preprocessing_columns(num_transform,cat_transform):\n    x_train,x_test,y_train,y_test=train_test_split(df.drop('SalePrice',axis=1),\n                                               target_log,test_size=0.15, random_state=0)\n    ct = ColumnTransformer(\n        transformers=[\n            (\"num\", num_transform, num_features),\n            (\"cat\", cat_transform, cat_features),\n        ]\n    )\n\n    train_indexs=x_train.index.tolist()\n    test_indexs=x_test.index.tolist()\n    test_data_=test_data.drop(columns=['Id'],axis=1)\n    ct.fit(x_train)\n    x_train_=ct.transform(x_train).toarray()\n    x_test_=ct.transform(x_test).toarray()\n    test_data_=pd.DataFrame(ct.transform(test_data_).toarray())\n    x_train=pd.DataFrame(data=x_train_)\n    x_test=pd.DataFrame(data=x_test_)\n\n    x_train['indexs']=train_indexs\n    x_train=x_train.set_index(['indexs'])\n    x_test['indexs']=test_indexs\n    x_test=x_test.set_index(['indexs'])\n    return x_train,x_test,y_train,y_test,test_data_","336aad03":"#from sklearn.preprocessing import LabelEncoder","bea3f52a":"# le=LabelEncoder()\n\n# for i in data_obj.columns:\n#   data_obj[i]= le.fit_transform(data_obj[i])","84d06048":"def select_cols(res,threshod_p_value_):\n    res_p_value= res.pvalues.reset_index()\n    res_p_value=res_p_value.rename(columns={res_p_value.columns[0]:'variable',res_p_value.columns[1]:'p_value'})\n    return res_p_value[res_p_value.p_value<=threshod_p_value_]['variable'].values.tolist()","bc078898":"def feature_selection_ols(cols1,threshod_p_value_):\n    for i in range(0,10):\n        ols=sm.OLS(y_train,x_train[cols1])\n        res= ols.fit()\n        featur= select_cols(res,threshod_p_value_)\n        if len(cols1) == len(featur):\n            break\n        else:\n            cols1=featur\n    return cols1","939f5961":"# def feature_selection_RF():\n#     rf=RandomForestRegressor(n_estimators=100)\n#     rf.fit(x_train,y_train)\n#     list_imp=pd.DataFrame(columns=['feature','importance'])\n#     list_imp['feature']=x_train.columns\n#     list_imp['importance']=np.array(rf.feature_importances_)\n#     list_imp=list_imp.sort_values('importance',ascending=False)\n#     return list_imp[list_imp.importance>0.001].feature.tolist()","d1d824e9":"def model_training_cross_validation(model2,n_folds):\n        kf = KFold(n_folds, shuffle=True, random_state=0).get_n_splits(x_train[cols].values)\n        scores= np.sqrt(-cross_val_score(model2, x_train[cols].values, \n                                   y_train.values, scoring=\"neg_mean_squared_error\", cv = kf))\n        valid_score=validation_test(model2)\n        return [np.mean(scores),np.std(scores),\n                    np.mean(scores)+np.std(scores),\n                   valid_score,abs(np.mean(scores)-valid_score)]","e00ef8be":"def validation_test(model_):\n    model_.fit(x_train[cols],y_train)\n    return np.sqrt(mean_squared_log_error(np.exp(y_test), np.exp(model_.predict(x_test[cols]))))","a327e776":"def min_error_parameter_(res, feature):\n    return res[res[feature].min()==res[feature]].index[0]","dfba9e99":"x_train,x_test,y_train,y_test, test_data_=_preprocessing_columns(MinMaxScaler(),\n                                                                 OneHotEncoder(handle_unknown='ignore'))\n\ncols=feature_selection_ols(correlation_test(x_train.columns),0.4)","e3d35a89":"n_estimators_list=[]\nfor i in range(800,2000,200):\n    n_estimators_list.append(i)\n    \nlearning_rate_list=[]\nfor i in range(1,5):\n    learning_rate_list.append(i\/100)\n    for j in range(0,20):\n        learning_rate_list.append((i\/100)+(random.random()\/100))\n\nmax_features_list=[]\nfor i in range(15,35):\n    max_features_list.append(i)\n    \nmin_samples_leaf_list=[]\nfor i in range(1,25,2):\n    min_samples_leaf_list.append(i)\n    \nmax_leaf_nodes_list=[]\nfor i in range(2,20,2):\n    max_leaf_nodes_list.append(i)","00f2370a":"def model_tuning(n_folds,param_method_selection,model1):\n        temp = pd.DataFrame(columns=['mean_rsme','std','sum_mean_std','valid_rsme','deviation'])\n      \n        parameter_list=[]\n        #model_list=[]\n        for learning_rate_ in learning_rate_list:\n            #model_list.append(model1.set_params(learning_rate=learning_rate_))\n            temp.loc[len(temp)]= model_training_cross_validation(model1.set_params(learning_rate=learning_rate_),n_folds)\n            parameter_list.append(learning_rate_)\n        model1.set_params(learning_rate=parameter_list[min_error_parameter_(temp,param_method_selection)])\n        \n        start=len(temp)\n        for n_estimators_ in n_estimators_list:\n            #model_list.append(model1.set_params(n_estimators=n_estimators_))\n            parameter_list.append(n_estimators_)\n            temp.loc[len(temp)]= model_training_cross_validation(model1.set_params(n_estimators=n_estimators_),n_folds)\n        model1.set_params(n_estimators=int(parameter_list[min_error_parameter_(temp[start:],\n                                                                                 param_method_selection)]))\n        \n        start=len(temp)\n        for max_features_ in max_features_list:\n            #model_list.append(model1.set_params(max_features=max_features_))\n            parameter_list.append(max_features_)\n            temp.loc[len(temp)]= model_training_cross_validation(model1.set_params(max_features=max_features_),n_folds)\n        model1.set_params(max_features=int(parameter_list[min_error_parameter_(temp[start:],\n                                                                                 param_method_selection)]))\n        \n        start=len(temp)\n        for max_leaf_nodes_ in max_leaf_nodes_list:\n            #model_list.append(model1.set_params(max_leaf_nodes=max_leaf_nodes_))\n            parameter_list.append(max_leaf_nodes_)\n            temp.loc[len(temp)]= model_training_cross_validation(model1.set_params(max_leaf_nodes=max_leaf_nodes_),n_folds)\n        model1.set_params(max_leaf_nodes=int(parameter_list[min_error_parameter_(temp[start:],\n                                                                                 param_method_selection)]))\n        \n        start=len(temp)\n        for min_samples_leaf_ in min_samples_leaf_list:\n            #model_list.append(model1.set_params(min_samples_leaf=min_samples_leaf_))\n            parameter_list.append(min_samples_leaf_)\n            temp.loc[len(temp)]= model_training_cross_validation(model1.set_params(min_samples_leaf=min_samples_leaf_),n_folds)\n        model1.set_params(min_samples_leaf=int(parameter_list[min_error_parameter_(temp[start:],\n                                                                                 param_method_selection)]))\n        temp['param_value']=parameter_list\n        #temp['model_']=model_list\n        model = model1\n        return temp","d01cc65d":"df_rmse = pd.DataFrame(columns=['mean_rsme','std','sum_mean_std','param_value','valid_rsme','deviation'])\n\n# Basline Model\nmodel = GradientBoostingRegressor(max_depth=4,random_state=30)\n\nfor iterate in range(0,3):\n    df_rmse=df_rmse.append(model_tuning(2,'sum_mean_std',model))","1337243e":"model","0b0c7c4c":"df_rmse=df_rmse.reset_index(drop=True)\ndf_rmse","da035149":"model_training_cross_validation(model,2),model_training_cross_validation(model,3),model_training_cross_validation(model,4),model_training_cross_validation(model,5)\n#'mean_rsme','std','sum_mean_std','valid_rsme','deviation'","5edba4d2":"model","846f31fa":"model.fit(x_train[cols],y_train)\nnp.sqrt(mean_squared_log_error(np.exp(y_test), np.exp(model.predict(x_test[cols]))))","737ca91a":"y_pred=np.exp(model.predict(test_data_[cols]))\ny_pred","99743795":"temp=pd.DataFrame()\ntemp['Id']= test_data['Id']\ntemp['SalePrice']= y_pred\ntemp.to_csv('submission.csv',index=False)\ntemp","a887dc44":"#filename = 'house_price_prediction_model.pkl'\n#joblib.dump(model, filename)","3bd8db0d":"# Feature Selection Methods","0c91f86a":"# Replace Missing values in the test data","b78f1ff0":"    I chose p-valu>= 0.4 as threshold to drop the columns to try to reduce the chance of overfitting since I do this on the training data. You could try different p-valeus to find the best threshold to drop columns","542e0262":"### Find the best parameter value based on your choosen method\n    average RSME\n    Sum of RSMEs and SDs\n    Deviation of averafe RSME from Validation test","a7941fa7":"    1. choose the number of iterations to repeat the process of model tuning \n    \n    2. choose the method of selecting the best parameter\n        - mean_score\n        - sum_mean_std\n        - deviation\n    3. number of folds for cross validation","d08c43a1":"# Prediction for the Test Data","fe8502aa":"    Just Checking the model fitting with different number of folds","cd58f1f7":"## Replace Missing Values","bb4fd5aa":"## Check missing values","256f0c50":"# Save Model","2a547ce5":"# Check the Distribusions ","e795418c":"## Parameters Value Setup","ab130cdb":"# Model Parameter Tuning","3c3a58d8":"## Column Transformation and Feature Selection","e837eaac":"# Outliers","ac4aad43":"# Model","2e70db4c":"# Cross Validation Test And Model Tuning","0c00c522":"# Load Data","c0444bf0":"# Check Multicolinearity","2f055095":"## Column transformation"}}