{"cell_type":{"b65580c3":"code","84699f72":"code","3ded8aa2":"code","a7ded54b":"code","02f1ab1f":"code","4643308f":"code","074edc66":"code","4f9fc6c0":"code","cf892a14":"code","b6bc3c13":"code","c798708a":"code","451eb07a":"markdown","4959d263":"markdown","677897eb":"markdown","a83d1788":"markdown"},"source":{"b65580c3":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport gc\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import StratifiedKFold\nfrom pytorch_lightning import seed_everything, LightningModule, Trainer\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping","84699f72":"def seed_everything(seed=47):\n    #os.environ['PYTHONSEED'] = str(seed)\n    np.random.seed(seed%(2**32-1))\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic =True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()\n# device optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","3ded8aa2":"train = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nsubmission = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\ntrain.head()","a7ded54b":"META_FEATURES = [col for col in train if col not in ['Id','Pawpularity']]\ntrain, y = train[META_FEATURES], train['Pawpularity']\ntest = test[META_FEATURES]","02f1ab1f":"class CustomDatasetGet(Dataset):\n    def __init__(self, data: pd.core.frame.DataFrame, is_test: bool=False):\n        self.is_test = is_test\n        self.target = y.values\n        self.features = data.values\n    def __getitem__(self, idx):\n        data = self.features[idx]\n        if self.is_test:\n            return torch.tensor(data, dtype=torch.float32)\n        else:\n            target = self.target[idx]\n            return torch.tensor(data, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n    def __len__(self):\n        return len(self.features)","4643308f":"def get_datasets(data: pd.core.frame.DataFrame, split: int=0.2):\n    \"\"\"\n    Split the data into training and validation splits\n    Make them into Torch Dataset format\n    \"\"\"\n    # Shuffle the data\n    data = data.sample(frac=1).reset_index(drop=True)\n    # Split the data\n    split_nb = int(split * len(data))\n    train_split = data[split_nb:]\n    val_split = data[:split_nb]\n    \n    # Make them Torch Datasets\n    training_set = CustomDatasetGet(\n        train_split,\n        is_test=False\n    )\n    validation_set = CustomDatasetGet(\n        val_split,\n        is_test=False\n    )\n    return {'train': training_set, 'val' : validation_set}","074edc66":"data_config = {\n    'data': train,\n    'split_pcent': 0.1,\n    'data_ret': get_datasets,\n    'num_workers': 1,\n    'train_bs': 128,\n    'val_bs': 128\n}","4f9fc6c0":"def fc_block(in_f, out_f):\n    return nn.Sequential(\n        nn.Linear(in_f, out_f),\n        nn.ReLU(),\n    )  \n\nclass TPSModel(LightningModule):\n    def __init__(self,\n                 input_size: int = data_config['data'].shape[1], \n                 classes: int = 1,\n                 learning_rate: float = 1e-4,\n                 data_config: dict = data_config\n        ):\n        super(TPSModel, self).__init__()\n        \n        if not data_config:\n            raise ValueError(\"Data Config Cannot be empty\")\n        self.epoch_counter = 0\n        self.data_config = data_config\n        self.input_size = input_size\n        self.learning_rate = learning_rate\n\n        # Mode Architecture\n        self.fc1 = fc_block(self.input_size, 128)\n        self.fc2 = fc_block(128, 64)\n        self.fc_relu = fc_block(192, 64)\n        self.fc3 = fc_block(64, 64)\n        self.out = nn.Linear(64, classes)\n        self.dropout = nn.Dropout(0.3)\n        \n    def forward(self, x):\n        # Model Compuatation Code\n        #x = self.flatten(x)\n        x1 = self.fc1(x)\n        x = self.fc2(x1)\n        x_cat = torch.cat((x, x1), dim=1)\n        x = self.dropout(x_cat)\n        x = self.fc_relu(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        x = self.dropout(x)\n        x = self.out(x)\n        return x\n\n    def prepare_data(self):\n        \"\"\"\n        Get the datasets related variables and functions from the data config dictionary\n        Then use it to split data.\n        \"\"\"\n        # Get stuff from dict\n        data = self.data_config['data']\n        split_pcent = self.data_config['split_pcent']\n        data_ret_fn = self.data_config['data_ret']\n        \n        # Call the retriever function to split data and make datasets\n        # Also extract the datasets from the returned dictionary\n        dataset_cache = data_ret_fn(data, split_pcent)\n        self.train_set = dataset_cache['train']\n        self.val_set = dataset_cache['val']\n        \n    def train_dataloader(self):\n        \"\"\"\n        Initializes and returns the training dataloader\n        \"\"\"\n        num_workers = self.data_config['num_workers']\n        train_bs = self.data_config['train_bs']\n        train_loader = DataLoader(\n            dataset = self.train_set,\n            shuffle = True,\n            batch_size = train_bs,\n            num_workers = num_workers\n        )\n        return train_loader\n        \n    def val_dataloader(self):\n        \"\"\"\n        Initializes and returns the validation dataloader\n        \"\"\"\n        num_workers = self.data_config['num_workers']\n        val_bs = self.data_config['val_bs']\n        val_loader = DataLoader(\n            dataset = self.val_set,\n            shuffle = False,\n            batch_size = val_bs,\n            num_workers = num_workers,\n        )\n        return val_loader\n    \n    def training_step(self, batch, batch_idx):\n        data, targets = batch\n        data, targets = data.to(device), targets.to(device)\n        outputs = self(data)\n        loss = torch.sqrt(F.mse_loss(outputs.squeeze(1), targets))\n        return {'loss': loss}\n\n    def training_epoch_end(self, outputs):\n        self.epoch_counter += 1\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        print(f'Epoch: {self.epoch_counter} \\t Average train_loss: {avg_loss}')\n    \n    def validation_step(self, batch, batch_idx):\n        data, targets = batch\n        data, targets = data.to(device), targets.to(device)\n        outputs = self(data)\n        val_loss = torch.sqrt(F.mse_loss(outputs.squeeze(1), targets))\n        self.log(\"val_loss\", val_loss)\n        return {'val_loss': val_loss}\n\n    def validation_epoch_end(self, outputs):\n        # 'outputs' is a list of dictionaries containing validation loss of each batch\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        print(f'Epoch: {self.epoch_counter} \\t Average val_loss: {avg_loss}')\n        return {'val_loss': avg_loss}\n        self.log(f\"Average loss: {avg_loss}\")\n    \n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)","cf892a14":"model = TPSModel()\nmodel = model.to(device)\nes_scheduler = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=False, min_delta=0.0001, mode=\"min\")\ntrainer = Trainer(max_epochs=100, gpus=1, callbacks=[es_scheduler])\ntrainer.fit(model)","b6bc3c13":"test_dataset = CustomDatasetGet(\n        test,\n        is_test=True\n    )\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)","c798708a":"def prediction(model_):\n    predictions = []\n    model_.eval()\n    with torch.no_grad():\n        for inputs in test_loader:\n            inputs = inputs.to(device)\n            inputs = inputs.to(torch.float32)\n            model_ = model_.to(device)\n            pred = model_(inputs)\n            predictions.append(pred)\n        return torch.tensor(predictions)\n\ny_pred = prediction(model)\n\n# submission\nsubmission['Pawpularity'] = y_pred.cpu().detach().numpy()\nsubmission.to_csv('submission.csv', index=None)\nsubmission.head(3)","451eb07a":"# Submission","4959d263":"# Lightning Model","677897eb":"# Training","a83d1788":"# Imports"}}