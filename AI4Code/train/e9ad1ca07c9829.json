{"cell_type":{"6ec2d567":"code","5a7ab62a":"code","ab5ee375":"code","9fb2d6be":"code","df2bedf3":"code","8ef75238":"code","42641d49":"markdown","729ede26":"markdown","bffe0c56":"markdown","ec659b5b":"markdown","ebd810db":"markdown"},"source":{"6ec2d567":"import os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')","5a7ab62a":"def encodeLabels(X_train, X_test):\n    # Label Encoding\n    for f in X_train.columns:\n        if X_train[f].dtype=='object' or X_test[f].dtype=='object':\n            lbl = LabelEncoder()\n            lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n            X_train[f] = lbl.transform(list(X_train[f].values))\n            X_test[f] = lbl.transform(list(X_test[f].values))\n    return X_train, X_test\n\ndef readData(path, encode=True):\n    \"\"\"\n    Read train\/test data\n    Parameters:\n        1. path: input path to the train\/test csv files (String)\n        2. encode: weather to label encode categorical columns (Boolean)\n    Outputs:\n        1. X_train:\n        2. y_train:\n        3. X_test:\n        4. y_test:\n    \"\"\"\n    # Loading train\/test data\n    train_transaction = pd.read_csv(os.path.join(path, 'train_transaction.csv'), index_col='TransactionID')\n    train_identity = pd.read_csv(os.path.join(path, 'train_identity.csv'), index_col='TransactionID')\n    test_transaction = pd.read_csv(os.path.join(path, 'test_transaction.csv'), index_col='TransactionID')\n    test_identity = pd.read_csv(os.path.join(path, 'test_identity.csv'), index_col='TransactionID')\n    sample_submission = pd.read_csv(os.path.join(path, 'sample_submission.csv'), index_col='TransactionID')\n\n    # Merging the transaction and identity\n    train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n    test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\n    # Creating dataframes\n    X_train = train.drop('isFraud', axis=1)\n    y_train = train['isFraud'].copy()\n    X_test = test.copy()\n    y_test = sample_submission.copy()\n\n    if encode==True:\n        X_train, X_test = encodeLabels(X_train, X_test)\n\n    return X_train, y_train, X_test, y_test","ab5ee375":"X, y, test, submission = readData(\"..\/input\/\")","9fb2d6be":"print(\"Percentage of fraud records = {:.2f}%\".format((y[y==1].shape[0]\/y.shape[0])*100))","df2bedf3":"nsplits = 5\nsubmission[\"isFraud\"] = 0\nskf = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=0)\n\nparameters = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'n_estimators': 500,\n    'max_depth': 9,\n    'bagging_fraction': 0.9,\n    'feature_fraction': 0.9,\n}\n\nfor idx_train, idx_test in skf.split(X, y):\n    train_data = lgb.Dataset(data=X.iloc[idx_train], label=y.iloc[idx_train])\n    valid_data = lgb.Dataset(data=X.iloc[idx_test], label=y.iloc[idx_test])\n    model = lgb.train(params=parameters, train_set=train_data, valid_sets=valid_data, \\\n                      verbose_eval=500, early_stopping_rounds=100)\n    submission['isFraud'] = submission['isFraud'] + model.predict(test)\n    \nsubmission['isFraud'] = submission['isFraud'] \/ 5","8ef75238":"submission.to_csv(\"submission.csv\")","42641d49":" ## Problem: Imbalanced Data","729ede26":"## Training LightGBM Model\nHere we are training a baseline LightGBM model with 5-folds.","bffe0c56":"#### Function to read train and test data\nThis also include function to label encode all the categorical features","ec659b5b":"# Introduction to Fraud Detection\n\nThe main challenge when it comes to modeling fraud detection as a classification problem comes from the fact that in real world data, the majority of transactions is not fraudulent and investment in technology for fraud detection has increased over the years.","ebd810db":"There are only 3.5% fraud transactions out of total records in training data.<br>\nThis is a hugely inbalanced dat for a classification task in fraud detection."}}