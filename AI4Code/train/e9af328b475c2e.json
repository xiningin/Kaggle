{"cell_type":{"6eed3157":"code","96dfdd54":"code","f98c695b":"code","b1c4ae65":"code","2b39886f":"code","fecbcfdc":"code","4fd1b974":"code","836bb909":"code","93632678":"code","aa2c63af":"code","c84a805c":"code","15e899eb":"code","7bd17bca":"code","93a9c8f9":"code","13643129":"code","1482581e":"code","03e5fa17":"code","fefa5100":"code","ea9a59b6":"code","c5833d3a":"code","d0bbebd1":"code","e30f705f":"code","312f4381":"code","eca2cd07":"code","67569aa9":"code","8f50441f":"code","83992e63":"code","bcd9d221":"code","78787ff1":"code","5878c337":"code","cdd1e6f6":"code","a2ea8809":"code","8a7b9b22":"code","9aa0db5e":"code","2e20c69b":"code","e820cc05":"code","bb10cf01":"code","1a3a7464":"code","85d5e2b0":"code","11337b7c":"code","92353886":"code","1f557bf4":"code","2fce732c":"code","9ccee3a1":"code","ccb67418":"code","ea6d8b55":"code","ad96ffd8":"code","a59f3f06":"code","16153d27":"code","6aedbe17":"code","1916362c":"code","61024967":"code","216a8d55":"code","914f69aa":"code","7859addd":"code","0be4a501":"code","b1035c28":"code","7eed7d50":"code","38dc66b3":"code","bada1c90":"code","c0bfacff":"code","0429a881":"code","b59ad436":"code","353693fe":"code","e45dbae8":"code","20fc7bf4":"code","6626a512":"code","d69673b8":"code","2c4e5a3f":"code","96fe83f8":"code","dd5d3995":"code","1d17b39e":"code","ef0c54ab":"code","2bdaf9a4":"code","37cb8e13":"markdown","687bed57":"markdown","d00d561f":"markdown","3264329b":"markdown","165d3433":"markdown","9ae66aa3":"markdown","f62b6345":"markdown","09c6be74":"markdown","89951757":"markdown","78fa2622":"markdown","07d3aa65":"markdown","18290006":"markdown","9bb5bb17":"markdown","c42fc8df":"markdown","94f706c7":"markdown","d7b36dc1":"markdown","7872ad3b":"markdown","31bd9a82":"markdown","3b705168":"markdown","244c6eed":"markdown","c51b5517":"markdown","82f020fc":"markdown","df7dc7e1":"markdown","d4c68bd6":"markdown","4412d92d":"markdown","35671b77":"markdown","1ab0954c":"markdown","286ebebf":"markdown","539644f2":"markdown","1f1039ec":"markdown","a6b2d49a":"markdown","0d4e2561":"markdown","d8ec7bac":"markdown","8c39d46f":"markdown","2c7b0d8f":"markdown","2f808476":"markdown","391fd915":"markdown","0b7b5733":"markdown","bc33af3d":"markdown","73a1f093":"markdown","16f8c3f4":"markdown","a8251c3c":"markdown","b2c62946":"markdown","e6b615ef":"markdown","2d14f28e":"markdown","8042dc88":"markdown","d6b481b2":"markdown","a9aee1be":"markdown","b7133fa7":"markdown","9ba05566":"markdown","e197b289":"markdown","3e90b646":"markdown","28cd8da5":"markdown","959ceb7d":"markdown","540c82f0":"markdown","3e078903":"markdown"},"source":{"6eed3157":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom os import path\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n% matplotlib inline\n\npd.set_option('display.max_rows', 100)","96dfdd54":"online_retail = pd.read_csv(\n    \"\/kaggle\/input\/onlineretail\/OnlineRetail.csv\",\n    sep=\",\",\n    dtype={\"CustomerID\": \"object\"},\n    encoding=\"unicode_escape\",\n)","f98c695b":"online_retail.columns","b1c4ae65":"online_retail.head()","2b39886f":"\"\"\"\n!pip uninstall pandas-profiling\n!pip install pandas-profiling[notebook,html]\n\"\"\"\n\n\"\"\"\nfrom pandas_profiling import ProfileReport\nonline_retail_profile = ProfileReport(online_retail, title='Pandas Profiling Report', html={'style':{'full_width':True}})\nonline_retail_profile\n\"\"\"","fecbcfdc":"online_retail[\"InvoiceDate\"] = pd.to_datetime(online_retail[\"InvoiceDate\"])\n\n# Create an additional column for date as year and month\nonline_retail[\"date\"] = online_retail[\"InvoiceDate\"].dt.strftime(\"%Y-%m\")\n\n# Create a new column for the total expenditure of that product in the purchase.\nonline_retail[\"total_sales_amount\"] = (\n    online_retail[\"UnitPrice\"] * online_retail[\"Quantity\"]\n)","4fd1b974":"min(online_retail['InvoiceDate'])","836bb909":"max(online_retail['InvoiceDate'])","93632678":"# Remove days from December 2011\nonline_retail = online_retail[online_retail.InvoiceDate < '2011-12-01']","aa2c63af":"# Remove rows were Unit price is 0.0\nonline_retail = online_retail[online_retail['UnitPrice'] !=0.0]","c84a805c":"# Add column for cancelations \nonline_retail['cancelation'] = online_retail['InvoiceNo'].apply(lambda x: x.startswith(\"C\"))\nonline_retail['cancelation'] = online_retail['total_sales_amount'] <0","15e899eb":"# Only positive purchases (No cancelations)\nonline_retail_purchases = online_retail[online_retail['cancelation'] == False] ","7bd17bca":"# Group by Purchase (Invoice)\ninvoices = (\n    online_retail_purchases.groupby([\"InvoiceNo\"])[[\"Quantity\", \"total_sales_amount\"]]\n    .agg(\"sum\")\n    .reset_index()\n)","93a9c8f9":"# Correlation Quantity & total_sales_amount\nsns.set_style({'axes.grid' : False})\nsns.set_style(\"darkgrid\")\nax = sns.regplot(x=invoices[\"Quantity\"], y=invoices[\"total_sales_amount\"], marker=\"+\", fit_reg=False)\nax.set_title('Purchases')\nax.set(xlabel='Quantity (units)', ylabel='Total Amount')\nplt.show()","13643129":"# Removing outlier \ninvoices = invoices[invoices[\"Quantity\"] < 20000]","1482581e":"# Correlation graph quantity & total_sales_amount\nsns.set_style({'axes.grid' : False})\nsns.set_style(\"darkgrid\")\nax = sns.regplot(x=invoices[\"Quantity\"], y=invoices[\"total_sales_amount\"], marker=\"+\", fit_reg=False)\nax.set_title('Purchases')\nax.set(xlabel='Quantity (units)', ylabel='Total Amount')\nplt.show()","03e5fa17":"corrMatrix = invoices.corr()\nsns.heatmap(corrMatrix, annot=True)","fefa5100":"invoices[invoices['total_sales_amount'] == max(invoices['total_sales_amount'])]","ea9a59b6":"invoices[invoices['total_sales_amount'] == min(invoices['total_sales_amount'])]","c5833d3a":"np.sqrt(invoices['total_sales_amount'].var())","d0bbebd1":"monthly_purchases = (\n    online_retail_purchases.groupby([\"date\"])[[\"total_sales_amount\"]]\n    .agg(\"sum\")\n    .reset_index()\n)\nmonthly_purchases = monthly_purchases.sort_values(by=[\"date\"])\n\n\ndef millions(x, pos):\n    \"The two args are the value and tick position\"\n    return \"$%1.1fM\" % (x * 1e-6)\n\n\nformatter = FuncFormatter(millions)\n\nfig, ax = plt.subplots()\nax.yaxis.set_major_formatter(formatter)\nmonthly_purchases.plot(\n    kind=\"line\", x=\"date\", y=\"total_sales_amount\", ax=ax, title=\"Monthly Purchases\"\n)\nplt.show()","e30f705f":"monthly_customers = online_retail.groupby([\"date\", \"CustomerID\"]).count().reset_index()\nmonthly_customers = monthly_customers[[\"date\", \"CustomerID\"]]\nmonthly_customers[[\"date\", \"unique_customers\"]] = (\n    monthly_customers.groupby(\"date\")[\"CustomerID\"].count().reset_index()\n)\n\nfig, ax = plt.subplots()\nmonthly_customers.plot(\n    kind=\"line\", x=\"date\", y=\"unique_customers\", ax=ax, title=\"Monthly Customers\"\n)\nplt.xticks(rotation=45)\nplt.show()\n","312f4381":"customers_purchases = (\n    online_retail_purchases.groupby([\"CustomerID\"])[[\"Quantity\", \"total_sales_amount\"]]\n    .agg(\"sum\")\n    .reset_index()\n)","eca2cd07":"# Calculate Quantiles\ncustomers_purchases['total_sales_amount'].quantile([.25, .5, 0.75,  0.80, 0.90, 0.95 , 0.99])","67569aa9":"# Threshold\nthreshold = 3500","8f50441f":"minority_customers = customers_purchases[\n    customers_purchases[\"total_sales_amount\"] <= threshold\n]\n\nmayority_customers = customers_purchases[\n    customers_purchases[\"total_sales_amount\"] > threshold\n]","83992e63":"sns.boxplot(y=minority_customers['total_sales_amount'])","bcd9d221":"minority_customers['total_sales_amount'].quantile([.25, .5, 0.75, 0.99])","78787ff1":"sns.distplot(a=minority_customers['total_sales_amount'], hist=True, kde=False, rug=False )","5878c337":"# By total amount spent \ncustomers_purchases.sort_values(by=['total_sales_amount'], ascending=False)","cdd1e6f6":"cancelations = online_retail[online_retail[\"cancelation\"] == True]\n\n# Graph with the number of Invoices that are cancelations vs purchases\nonline_retail.cancelation.value_counts().sort_values().plot(\n    kind=\"barh\", title=\"Purchase Cancelled\"\n)","a2ea8809":"top_ten_countries = online_retail['Country'].value_counts()\ntop_ten_countries = top_ten_countries.iloc[0:11]","8a7b9b22":"top_ten_countries.plot(kind='bar', title = 'Top 10 - Purchases by Country')","9aa0db5e":"products = (\n    online_retail_purchases.groupby([\"StockCode\", \"Description\"])[[\"Quantity\"]]\n    .agg(\"sum\")\n    .reset_index()\n)","2e20c69b":"products.sort_values(by=['Quantity'], ascending=False)[0:10]","e820cc05":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","bb10cf01":"descriptions = online_retail_purchases.Description.str.cat(sep=' ')","1a3a7464":"# Start with one review:\ntext = descriptions\n\n# Create and generate a word cloud image:\nwordcloud = WordCloud().generate(text)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","85d5e2b0":"!pip install lifetimes","11337b7c":"from dateutil import parser\nimport datetime\nfrom dateutil import relativedelta\nfrom lifetimes import BetaGeoFitter\nfrom lifetimes.utils import summary_data_from_transaction_data\nfrom sklearn.metrics import mean_squared_error","92353886":"transactional_purchases = (\n    online_retail_purchases.groupby([\"InvoiceNo\", \"CustomerID\", \"InvoiceDate\"])[\n        [\"Quantity\", \"total_sales_amount\"]\n    ]\n    .agg(\"sum\")\n    .reset_index()\n)","1f557bf4":"transactional_purchases.head()","2fce732c":"# Configurable experimental variables \nSPLIT_DATE = \"2011-06-01\" # Date to be used to end train date\nPERIOD_LENGTH = 2 # Months","9ccee3a1":"date = parser.parse(SPLIT_DATE)\nend_date = date + relativedelta.relativedelta(months=2)\nend_test_date = end_date.strftime(\"%Y-%m-%d\")\n\ntrain = transactional_purchases[transactional_purchases[\"InvoiceDate\"] < SPLIT_DATE]\ntest = transactional_purchases[\n    (transactional_purchases[\"InvoiceDate\"] >= SPLIT_DATE)\n    & (transactional_purchases[\"InvoiceDate\"] < end_test_date)\n]\n\nprint(\"Start Train dataset date {}\".format(train[\"InvoiceDate\"].min()))\nprint(\"End Train dataset date {}\".format(train[\"InvoiceDate\"].max()))\nprint(\"---------------------------------------------\")\nprint(\"Start Test dataset date {}\".format(test[\"InvoiceDate\"].min()))\nprint(\"End Test dataset date {}\".format(test[\"InvoiceDate\"].max()))","ccb67418":"# Create Features (Frequency, Recency and T) for customers\nfeatures_train = summary_data_from_transaction_data(\n    train,\n    customer_id_col=\"CustomerID\",\n    datetime_col=\"InvoiceDate\",\n    monetary_value_col=\"total_sales_amount\",\n    freq=\"D\",\n)\nfeatures_train.reset_index(level=0, inplace=True)","ea6d8b55":"features_train","ad96ffd8":"# Fit to the BG\/NBD model \nbgf = BetaGeoFitter(penalizer_coef=0.1)\nbgf.fit(features_train['frequency'], features_train['recency'], features_train['T']) \nprint(bgf)","a59f3f06":"customers = features_train[['CustomerID']]","16153d27":"# Predict future total amount spent for individual customers (next period)\nt = PERIOD_LENGTH*30  # Days (2 Months aprox)\ncustomers[\"pred_n_purchases\"] = bgf.predict(\n    t, features_train[\"frequency\"], features_train[\"recency\"], features_train[\"T\"]\n)","6aedbe17":"y_predictions = customers[[\"CustomerID\", \"pred_n_purchases\"]]\n\ntest_n_purchases = (\n    test[\"CustomerID\"]\n    .value_counts()\n    .rename_axis(\"CustomerID\")\n    .to_frame(\"true_n_purchases\")\n)\n\ndataset = pd.merge(y_predictions, test_n_purchases, on='CustomerID', how='left')\ndataset['true_n_purchases'].fillna(0, inplace= True) # No sales ","1916362c":"# Example prediction individual customer 14646\ndataset[dataset.CustomerID=='14646']","61024967":"y_true_n_purchases = dataset['true_n_purchases']\ny_pred_n_purchases = dataset['pred_n_purchases']","216a8d55":"mean_squared_error(y_true_n_purchases, y_pred_n_purchases, squared=False)","914f69aa":"# Amount spent by customer current period\ntest_amount_spent = (\n    test.groupby([\"CustomerID\"])[[\"total_sales_amount\"]]\n    .agg(\"sum\")\n    .reset_index()\n    .rename(columns={\"total_sales_amount\": \"true_amount_spent_next_period\"})\n)","7859addd":"# In order to fit model remove the onems that have 0 en monetary value\nf_r_t_summary2 = features_train[features_train['monetary_value']>0]","0be4a501":"# Fit GammaGamma model \nfrom lifetimes import GammaGammaFitter\n\nggf = GammaGammaFitter(penalizer_coef = 0)\nggf.fit(f_r_t_summary2['frequency'],\n        f_r_t_summary2['monetary_value'])\nprint(ggf)","b1035c28":"f_r_t_summary2[\"pred_amount_spent_next_period\"] = ggf.customer_lifetime_value(\n    bgf, #the model to use to predict the number of future transactions\n    f_r_t_summary2['frequency'],\n    f_r_t_summary2['recency'],\n    f_r_t_summary2['T'],\n    f_r_t_summary2['monetary_value'],\n    time=PERIOD_LENGTH, # months\n    discount_rate=0.01 # monthly discount rate\n)","7eed7d50":"y_predictions = f_r_t_summary2[[\"CustomerID\", \"pred_amount_spent_next_period\"]]","38dc66b3":"dataset = pd.merge(customers['CustomerID'], y_predictions, on='CustomerID', how='left')\ndataset = pd.merge(dataset, test_amount_spent, on='CustomerID', how='left')\ndataset['pred_amount_spent_next_period'].fillna(0, inplace= True) # Fill No sales with 0\ndataset['true_amount_spent_next_period'].fillna(0, inplace= True) # Fill No sales with 0","bada1c90":"dataset","c0bfacff":"y_true_amount_spent = dataset['true_amount_spent_next_period']\ny_pred_amount_spent = dataset['pred_amount_spent_next_period']","0429a881":"mean_squared_error(y_true_amount_spent, y_pred_amount_spent, squared=False)","b59ad436":"def create_features_split(transactions, split_date, period_length, datetime_col, total_sales_col):\n    \"\"\"\n    Taket historic transactional level data and returns train and test dataset in \n    costumer level useful to be used by machine learning models. \n    \n    Arguments:\n        transactions - Dataframe at transaction level with war list of purchases.\n        split_date - Date to be used to end train date\n        period_length - The length of period in Months.\n        datetime_col - Column of date time\n        \n    Returns:\n        train - Dataframe at customer level to be used for training\n        test - Dataframe at customer level to be used for testing \n        \n    \"\"\"\n\n    train = transactions[transactions[datetime_col] < split_date]\n\n    date = parser.parse(split_date)\n    end_test_date = date + relativedelta.relativedelta(months=period_length)\n    end_test_date = end_test_date.strftime(\"%Y-%m-%d\")\n\n    train_transactions = transactions[transactions[datetime_col] < split_date]\n    test_transactions = transactions[transactions[datetime_col] < end_test_date]\n\n    print(\"Creating Train ...\")\n    train = _transactions_to_dataset(\n        train_transactions,\n        split_date,\n        period_length,\n        \"InvoiceDate\",\n        \"CustomerID\",\n        total_sales_col,\n    )\n\n    print(\"Creating Test ...\")\n    test = _transactions_to_dataset(\n        test_transactions,\n        end_test_date,\n        period_length,\n        \"InvoiceDate\",\n        \"CustomerID\",\n        total_sales_col,\n    )\n\n    return train, test\n\n\ndef _transactions_to_dataset(\n    transactions,\n    end_date,\n    period_length,\n    datetime_col,\n    customer_id_col,\n    total_sales_col,\n):\n    \"\"\"\n    Take historic transactions and create a dataset with basics staticts features,\n    number of purchases from past, current and next period and amount spent from \n    past, current and next period.\n    \n    Begining dataset: t0\n    Past period: t1 - t2\n    Current period: t2 - t3\n    Target period: t3 - t4\n    \n    Arguments: \n        transactions - Dataframe at transaction level with war list of purchases.\n        end_date - Last date to use to create dataset\n        period_length - The length of period in Months.\n        customer_id_col - Name of column with the ids of costumers\n        total_sales_col - Name of column of the total amount spent in purchase\n    \n    Returns: \n        dataset - Data for customer level with number of transactions and total \n                    amount spent in the last, current and next period\n    \n    \"\"\"\n\n    t4 = end_date\n    t3 = (\n        parser.parse(t4) - relativedelta.relativedelta(months=period_length)\n    ).strftime(\"%Y-%m-%d\")\n    t2 = (\n        parser.parse(t3) - relativedelta.relativedelta(months=period_length)\n    ).strftime(\"%Y-%m-%d\")\n    t1 = (\n        parser.parse(t2) - relativedelta.relativedelta(months=period_length)\n    ).strftime(\"%Y-%m-%d\")\n    t0 = transactions[datetime_col].min().strftime(\"%Y-%m-%d\")\n\n    # Define time periods\n    transactions_dev = transactions[transactions[datetime_col] < t3]\n\n    current_period = transactions_dev[\n        (transactions_dev[datetime_col] >= t2) & (transactions_dev[datetime_col] < t3)\n    ]\n\n    past_period = transactions_dev[\n        (transactions_dev[datetime_col] >= t1) & (transactions_dev[datetime_col] < t2)\n    ]\n\n    target_period = transactions[\n        (transactions[datetime_col] >= t3) & (transactions[datetime_col] < t4)\n    ]\n\n    # Basic Features (Frequency, Recency and T) since t0\n    features_train = summary_data_from_transaction_data(\n        transactions_dev,\n        customer_id_col=customer_id_col,\n        datetime_col=datetime_col,\n        monetary_value_col=total_sales_col,\n        freq=\"D\",\n    )\n    features_train.reset_index(level=0, inplace=True)\n\n    # Purchases by customers current period\n    purchases_current_period = (\n        current_period[customer_id_col]\n        .value_counts()\n        .rename_axis(customer_id_col)\n        .to_frame(\"purchases_current_period\")\n    )\n    purchases_current_period.reset_index(level=0, inplace=True)\n\n    # Purchases by customer past period\n    purchases_past_period = (\n        past_period[customer_id_col]\n        .value_counts()\n        .rename_axis(customer_id_col)\n        .to_frame(\"purchases_past_period\")\n    )\n\n    purchases_past_period.reset_index(level=0, inplace=True)\n\n    # Amount spent by customer current period\n    amount_spent_current_period = (\n        current_period.groupby([customer_id_col])[[total_sales_col]]\n        .agg(\"sum\")\n        .reset_index()\n        .rename(columns={\"total_sales_amount\": \"amount_spent_current_period\"})\n    )\n\n    # Amount spent by customer last period\n    amount_spent_past_period = (\n        past_period.groupby([customer_id_col])[[total_sales_col]]\n        .agg(\"sum\")\n        .reset_index()\n        .rename(columns={\"total_sales_amount\": \"amount_spent_past_period\"})\n    )\n\n    # Create Targets\n    purchases_target = (\n        target_period[customer_id_col]\n        .value_counts()\n        .rename_axis(customer_id_col)\n        .to_frame(\"purchases_next_period\")\n    )\n\n    amount_spent_target = (\n        target_period.groupby([customer_id_col])[[total_sales_col]]\n        .agg(\"sum\")\n        .reset_index()\n        .rename(columns={total_sales_col: \"amount_spent_next_period\"})\n    )\n\n    # Join the Datasets\n    dataset = pd.merge(\n        features_train, purchases_past_period, on=customer_id_col, how=\"left\"\n    )\n    dataset = pd.merge(\n        dataset, purchases_current_period, on=customer_id_col, how=\"left\"\n    )\n    dataset = pd.merge(dataset, purchases_target, on=customer_id_col, how=\"left\")\n    dataset = pd.merge(\n        dataset, amount_spent_past_period, on=customer_id_col, how=\"left\"\n    )\n    dataset = pd.merge(\n        dataset, amount_spent_current_period, on=customer_id_col, how=\"left\"\n    )\n    dataset = pd.merge(dataset, amount_spent_target, on=customer_id_col, how=\"left\")\n\n    # Fill NA (No sales) with 0\n    dataset[\"purchases_past_period\"].fillna(0, inplace=True)\n    dataset[\"purchases_current_period\"].fillna(0, inplace=True)\n    dataset[\"purchases_next_period\"].fillna(0, inplace=True)\n    dataset[\"amount_spent_past_period\"].fillna(0, inplace=True)\n    dataset[\"amount_spent_current_period\"].fillna(0, inplace=True)\n    dataset[\"amount_spent_next_period\"].fillna(0, inplace=True)\n\n    print(\"Data statistics starts from {}\".format(t0))\n    print(\"Past period from [{} to {})\".format(t1, t2))\n    print(\"Current period from [{} to {})\".format(t2, t3))\n    print(\"Next period from [{} to {})\".format(t3, t4))\n\n    return dataset","353693fe":"train, test = create_features_split(\n    transactional_purchases,\n    split_date=SPLIT_DATE,\n    period_length=PERIOD_LENGTH,\n    datetime_col=\"InvoiceDate\",\n    total_sales_col=\"total_sales_amount\"\n)","e45dbae8":"train.columns","20fc7bf4":"feature_cols = ['frequency', 'recency', 'T', 'monetary_value',\n       \t\t\t'purchases_past_period', 'purchases_current_period',\n       \t\t\t'amount_spent_past_period','amount_spent_current_period']\n\ny_col = ['purchases_next_period']","6626a512":"X_train = train[feature_cols]\ny_train = train[y_col]\n\nX_test = test[feature_cols]\ny_test = test[y_col]","d69673b8":"from sklearn.ensemble import RandomForestRegressor\n\nclf = RandomForestRegressor(random_state=0)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)","2c4e5a3f":"mean_squared_error(y_pred, y_test, squared=False)","96fe83f8":"y_col = ['amount_spent_next_period']","dd5d3995":"X_train = train[feature_cols]\ny_train = train[y_col]\n\nX_test = test[feature_cols]\ny_test = test[y_col]","1d17b39e":"clf = RandomForestRegressor(random_state=0)\nclf.fit(X_train, y_train)","ef0c54ab":"y_pred = clf.predict(X_test)","2bdaf9a4":"mean_squared_error(y_pred, y_test, squared=False)","37cb8e13":"In order to make predictions of next purchases and amount of purchases in a Customer level in a future period of time, transactions needs to be at a customer level. ","687bed57":"### Monthly Purchases","d00d561f":"#### Top 10 products\n\nMost selled products","3264329b":"## Products ","165d3433":"#### Auxiliary Functions ","9ae66aa3":"Last purchase in the dataset ","f62b6345":"#### Monthly Customers ","09c6be74":"First purchase in the dataset ","89951757":"#### Top 10 - Purchases by Country ","78fa2622":"Minimum Invoice Number ","07d3aa65":"We remove the data points from December as they are incomplete for that month.","18290006":"The mean price for a purchase for a minority customer is 570 (Unit price), but there is high dispersion according to the graph. ","9bb5bb17":"-----","c42fc8df":"Error metric (RMSE)","94f706c7":"#### Predict number of future purchases for individual customers (next period)","d7b36dc1":"This Jupyter Notebook is divided into three parts. \n\n1. Initial exploratory data analysis (EDA), the structure of the dataset discussed and other insights and information about the data explored.\n\n2. Attempt to predict future purchases and revenues from customer using a portion of the past.\n    * Using Lifemiles library \n    * Using ML with scikit learn","7872ad3b":"#### Predict future total amount spent for individual customers (next period)","31bd9a82":"* **Frequency:** represents the number of repeat purchases the customer has made. \n\n* **Recency:** represents the age of the customer when they made their most recent purchases. **This is equal to the duration between a customer\u2019s first purchase and their latest purchase.** (Thus if they have made only 1 purchase, the recency is 0.) \n\n* **T:** represents the age of the customer in whatever time units chosen. **This is equal to the duration between a customer\u2019s first purchase and the end of the period under study.**\n\n* **monetary_value** represents the average value of a given customer\u2019s purchases. This is equal to the sum of all a customer\u2019s purchases divided by the total number of purchases.","3b705168":"# 1.Exploratory Data Analysis (EDA)\n\n","244c6eed":"## Using [Lifetimes](https:\/\/https:\/\/lifetimes.readthedocs.io\/en\/latest\/) \n\nThis is a probabilistic approach where the goal is to fit several probability distributions.","c51b5517":"#### Predict number of future purchases for individual customers (next period)","82f020fc":"From september the sells break the 1M level ","df7dc7e1":"Metrics RMSE on test set ","d4c68bd6":"## Descriptions WordCloud","4412d92d":"Majority of the purchases comes from UK but taking into account \nthat retailer is from United Kingdom this behavior is expected. ","35671b77":"Transform date column to a proper data format.","1ab0954c":"## ML approach (Scikit-Learn)  ","286ebebf":"The standard deviation is aprox 1208 Unit prices","539644f2":"Error metric (RMSE)","1f1039ec":"The time window for the prediction will be the next two months from the training period ending. ","a6b2d49a":"### Cancelations","0d4e2561":"From the time stamps we can see that the first one in our dataset was from 2010-12-01 at 8 am and the last one 2011-12-09 at 12:50 am. In this case the month of December is incomplete as we might not include it in the Analysis. ","d8ec7bac":"* `InvoiceNo`: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n* `StockCode`: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product\n* `Description`: Product (item) name. Nominal.\n* `Quantity`: The quantities of each product (item) per transaction. Numeric. \n* `InvoiceDate`: Invice Date and time. Numeric, the day and time when each transaction was generated.\n* `UnitPrice`: Unit price. Numeric, Product price per unit in sterling.\n* `CustomerID`: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n* `Country`: Country name. Nominal, the name of the country where each customer resides.\n","8c39d46f":"![](https:\/\/drive.google.com\/uc?export=view&id=12ncYfgu1s77BScvVHu_PKliSwioC8glr)    \n","2c7b0d8f":"Dataset is presented in a *product by purchase level* with 541909 rows and with the following columns.","2f808476":"Quick peek to the data at transactional level","391fd915":"### Data Cleansing ","0b7b5733":"### Data Set Organization","bc33af3d":"#### Customer Ranking","73a1f093":"### Purchases (Invoices)","16f8c3f4":"A great majority of the purchases from minority_customers tends to be from 0 to 1000 (Unit prices) and tends to decrease greater that amount. ","a8251c3c":"#### Maximimun Invoice number \n\nNot taking into account the outlier","b2c62946":"#### Predict future total amount spent for individual customers (next period)","e6b615ef":"From Pandas profile report it can be seen that CustomerID has 135080 (24.9%) missing values.","2d14f28e":"# 0.Online Retail Dataset\n\nThis is a transnational data set which contains all the transactions occurring between 01\/12\/2010 and 09\/12\/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n","8042dc88":"### Wholesaler VS Minoritary Customers","d6b481b2":"Quick peek to the data ","a9aee1be":"As expected there is a correlation between Quantity and  total sales amount \n","b7133fa7":"Metrics RMSE on test set ","9ba05566":"Looking into the word cloud it re affirms that the company sells all location gifts and *red color*, *bags* are important words in this context.  ","e197b289":"# 2.Predictive Analysis\n\n* Predictions number of purchases for a future time period at a individual customer level.\n* Predictions of total amount spent for a future time period at a individual customer level.\n* Calculate RMSE for next period.\n* This Analysis will use as input data in a transactional level.\n\n\n","3e90b646":"Because this problem relates with **Time Aware Modeling** where validation set is made up of observations from a time window outside of (and more recent than) the time window used for model training, test is done in a Out-of-time validation (OTV) approach. ","28cd8da5":"## Countries ","959ceb7d":"A small amount of the purchases are cancelled ","540c82f0":"\n\n\n* Original dataset from UCI ML http:\/\/archive.ics.uci.edu\/ml\/datasets\/Online+Retail\n\n","3e078903":"### Load Data "}}