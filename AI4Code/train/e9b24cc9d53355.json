{"cell_type":{"6dfe8af8":"code","f515053f":"code","2ff3a0b0":"code","b7cc7725":"code","08fc9948":"code","a21ee2d0":"code","87853a0e":"code","4ab652ec":"code","e2c4ab07":"code","d6d8fd84":"code","fef77f3a":"code","486a87a7":"code","6366af36":"code","21e86b1a":"code","b02aeab8":"code","87f454b9":"code","4bc3eff5":"code","dbbab668":"code","8dd7a741":"code","6c79c052":"code","c3be88ea":"code","bf85e1ec":"code","78c4bcba":"code","9ba6f606":"code","e6f450e5":"code","fe355800":"code","50f9d03a":"code","a8151703":"code","7065711c":"code","c855c46a":"code","b2680bd5":"code","8ff96c9d":"code","5e0e0811":"code","899ce4e0":"code","68107d63":"code","1865af47":"code","6bf4c143":"code","d396ded9":"code","b0271606":"code","fb383de7":"code","bde39bc2":"code","7fbdce1a":"code","5eb36639":"code","b652ad51":"code","83e5b096":"code","ec3a1291":"code","b7bad489":"code","01ae9a17":"code","c3cc3a00":"code","9ea4c551":"code","e5185f63":"code","7e4b2483":"code","336c25a2":"code","3e90888a":"code","5b679a7d":"code","246129bc":"markdown","79dc62b3":"markdown","0c545159":"markdown","4c8de24d":"markdown","200ae120":"markdown","bb212b18":"markdown","791a5fbd":"markdown","c8ff1aca":"markdown"},"source":{"6dfe8af8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","f515053f":"# import the data of images\ndataset = pd.read_csv(\"..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_L.csv\")\ndataset.head()","2ff3a0b0":"dataset.shape","b7cc7725":"# import the metatdata\n# it can be observed that the metadata contains different labels\nmetadata = pd.read_csv(\"..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv\")\nmetadata.head()","08fc9948":"metadata.shape","a21ee2d0":"# show the disease distribution in different positions\ndisease_location = metadata['localization'].value_counts()","87853a0e":"# it can be ovbserved that the disease location distribution is not balanced\ndisease_location","4ab652ec":"# plot the graph of disease distribution in different positions\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(20,5))\nsns.countplot(x = 'localization', data = metadata)\nplt.title('Disease location distribution')\nplt.show()","e2c4ab07":"# disease distribution in different classes\ndisease_class = metadata['dx'].value_counts()","d6d8fd84":"# it can be ovbserved that the disease classes distribution is not balanced\ndisease_class","fef77f3a":"# plot the disease class distribution\nsns.countplot(x = 'dx', data = metadata)\nplt.title('Disease class distribution')","486a87a7":"# disease distribution in different sexes\ndisease_sex = metadata['sex'].value_counts()","6366af36":"# it can be ovbserved that the disease distribution in sex is not balanced\ndisease_sex","21e86b1a":"# plot the disease sex distribution\nsns.countplot(x = 'sex', data = metadata)\nplt.title('Disease sex distribution')","b02aeab8":"# disease distribution in different ages\ndisease_age = metadata['age'].value_counts()","87f454b9":"# it can be ovbserved that the disease distribution in age is not balanced\ndisease_age","4bc3eff5":"# plot the disease age distribution\nplt.figure(figsize=(15,5))\nsns.countplot(x = 'age', data = metadata)\nplt.title('Disease age distribution')\nplt.show()","dbbab668":"# drop the column of 'label' in dataset to get the pure images dataset\nimage_data = dataset.drop(['label'], axis = 1)","8dd7a741":"# change the list to the np array\nimage_data = np.array(image_data)","6c79c052":"image_data","c3be88ea":"image_data.shape","bf85e1ec":"# the number of images\nimage_index = len(dataset.index)\n# reshape the images(it is 28 since the dataset is 28_28_L)\nimages = image_data.reshape(image_index, 28, 28)","78c4bcba":"# the collection of disease class labels\nimage_label = metadata['dx']","9ba6f606":"image_label","e6f450e5":"# show some example images in the data\nplt.figure(figsize = (10,20))\nfor i in range(5) :\n    plt.subplot(1,5,i+1)\n    plt.imshow(images[i],'gray')\n    plt.title(image_label[i])","fe355800":"from sklearn.model_selection import train_test_split\nx_train = []\ny_train = []\nx_test = []\ny_test = []\n# drop the column of 'label' in dataset to get the pure images dataset\npure_data = dataset.drop(['label'], axis = 1)\n# if does not set the variable 'random_state', the split will be random\n# different value of 'random_state' can lead to different split result\nx_train, x_test, y_train, y_test = train_test_split(pure_data, dataset['label'], random_state = 20)","50f9d03a":"x_train.shape","a8151703":"np.array(y_train).shape","7065711c":"# y group is the collection of labels\ny_train.value_counts()","c855c46a":"# y group is the collection of labels\ny_test.value_counts()","b2680bd5":"x_test.shape","8ff96c9d":"# from the data overview part, it can be observed that the data is not balanced distributed\n# so we need to balance the data for training\nfrom imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=42)\nx_train_balanced, y_train_balanced = smote.fit_resample(x_train, y_train)","5e0e0811":"x_train_balanced.shape","899ce4e0":"y_train_balanced.shape","68107d63":"y_train_balanced.value_counts()","1865af47":"def reshape_data(data):\n    # when I firstly wrote this part, I missed to change the data to np array\n    # the error reported: DataFrame' object has no attribute 'reshape'\n    data_array = np.array(data)\n    # reshape the data for CNN input\n    # -1 represents the number of images, but the specific number can lead the same result\n    # 28, 28, 1 is the image height, width, and color channel\n    data = data_array.reshape(-1, 28, 28, 1)\n    return data","6bf4c143":"x_train_balanced = reshape_data(x_train_balanced)","d396ded9":"x_train_balanced.shape","b0271606":"y_train_balanced.shape","fb383de7":"x_train_balanced = x_train_balanced\/255","bde39bc2":"x_test_reshape = reshape_data(x_test)","7fbdce1a":"x_test_reshape = x_test_reshape\/255","5eb36639":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n# define the CNN model\ndef CNN_model():\n    # the input layer\n    model = Sequential()\n    \n    # the first Conv2D layer\n    # the fiters are 32, the kernel size is 3*3\n    model.add(Conv2D(32, 3, input_shape = (28, 28, 1), padding='same', activation = 'relu'))\n    # the first pooling layer, the pool size is 2*2\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    # use BatchNormalization to decrease overfitting problem\n    model.add(BatchNormalization())\n    \n    # the second Conv2D layer\n    model.add(Conv2D(64, 3, padding='same', activation = 'relu'))\n    # the second pooling layer\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    # use BatchNormalization to decrease overfitting problem\n    model.add(BatchNormalization())\n    \n    # the third Conv2D layer(add more Conv2D layers for the accuracy of model)\n    model.add(Conv2D(128, 3, padding='same', activation = 'relu'))\n    # use BatchNormalization to decrease overfitting problem\n    model.add(BatchNormalization())\n    \n    # the fourth Conv2D layer\n    model.add(Conv2D(256, 3, padding='same', activation = 'relu'))\n    # use BatchNormalization to decrease overfitting problem\n    model.add(BatchNormalization())\n    \n    # the flatten layer\n    model.add(Flatten())\n    # use dropout to decrease overfitting problem\n    # here use dropout but not BatchNormalization since dropout is more effective in the Dense layer\n    model.add(Dropout(0.2))\n    \n    # the first dense layer\n    model.add(Dense(128, activation = 'relu'))\n    # use dropout to decrease overfitting problem\n    model.add(Dropout(0.2))\n    # the first dense layer\n    model.add(Dense(64, activation = 'relu'))\n    # use dropout to decrease overfitting problem\n    model.add(Dropout(0.2))\n    # the first dense layer\n    model.add(Dense(32, activation = 'relu'))\n    # use dropout to decrease overfitting problem\n    model.add(Dropout(0.2))\n    # the output densen layer, 7 means the number of labels\n    model.add(Dense(7, activation = 'softmax'))\n    return model","b652ad51":"model = CNN_model()","83e5b096":"model.summary()","ec3a1291":"from keras import optimizers\noptm = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)","b7bad489":"model.compile(optimizer= optm, loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])","01ae9a17":"# here I set the epochs to 25, validation group to 20%, and shuffle the data\ntraining = model.fit(x_train_balanced, y_train_balanced, epochs = 25, batch_size= 256, validation_split=0.2, shuffle = True)","c3cc3a00":"print (np.mean(training.history['accuracy']))","9ea4c551":"print (np.mean(training.history['loss']))","e5185f63":"print (np.mean(training.history['val_accuracy']))","7e4b2483":"print (np.mean(training.history['val_loss']))","336c25a2":"model.save('CNN.model')","3e90888a":"# plot the accuracy of training and validation\nplt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])","5b679a7d":"# plot the loss of training and validation\nplt.plot(training.history['loss'])\nplt.plot(training.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.show()","246129bc":"# Plot the accuracy of the model","79dc62b3":"# Split the data for training and testing","0c545159":"# Skin canner image examples","4c8de24d":"# Graph the disease distribution with different labels","200ae120":"# Balance the data","bb212b18":"# CNN","791a5fbd":"# Reshape the data","c8ff1aca":"# Dataset overview"}}