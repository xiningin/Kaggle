{"cell_type":{"81867981":"code","3ea3c1d2":"code","431c6ab8":"code","8336f21b":"code","3302f5f4":"code","92b4097b":"code","d63655f2":"code","5b59ffad":"code","22312d51":"code","081a5e38":"code","a437b502":"code","31d4a90e":"code","21fa2e75":"code","868edfa5":"code","5a8b161e":"code","55f4c883":"code","6cb3ca5f":"code","5dd54941":"code","b5766b71":"code","eb286090":"code","e755f864":"code","5b02404c":"code","2ced51ee":"code","cb21f8ec":"code","b68be52e":"code","380fd28a":"code","3c8b7faf":"markdown","3ff6e02c":"markdown","229126c9":"markdown","23f3c857":"markdown","5ac737fd":"markdown","cc43117d":"markdown","6397b39e":"markdown","05dac3d5":"markdown","22f791d9":"markdown","04109c28":"markdown","ded01102":"markdown","8ca84619":"markdown","2126d4b4":"markdown","27b4977b":"markdown","e810d0f0":"markdown","178e692c":"markdown"},"source":{"81867981":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nfrom glob import glob \nimport matplotlib.pyplot as plt\n\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nfrom keras_preprocessing.image import ImageDataGenerator\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom IPython.display import clear_output\n","3ea3c1d2":"path = \"..\/input\/\" \nlabels = pd.read_csv(path + 'train_labels.csv')\ntrain_path = path + 'train\/'\ntest_path = path + 'test\/'","431c6ab8":"df = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))})\ndf['id'] = df.path.map(lambda x: ((x.split(\"n\")[2].split('.')[0])[1:]))\ndf = df.merge(labels, on = \"id\")\ndf.head(3)","8336f21b":"def readImage(path):\n    # OpenCV reads the image in bgr format by default\n    bgr_img = cv2.imread(path)\n    # We flip it to rgb for visualization purposes\n    b,g,r = cv2.split(bgr_img)\n    rgb_img = cv2.merge([r,g,b])\n    return rgb_img","3302f5f4":"positive_indices = list(np.where(df[\"label\"] == True)[0])\nnegative_indices = list(np.where(df[\"label\"] == False)[0])\nrand_pos_inds = random.sample(positive_indices, 4)\nrand_neg_inds = random.sample(negative_indices, 4)\n\nfig, ax = plt.subplots(2,4, figsize=(20,8))\nfig.suptitle('Histopathologic scans of lymph node sections',fontsize=20, fontweight='bold')\n\nfor i in range(0, 4):\n    ax[0,i].imshow(readImage(df.iloc[rand_pos_inds[i],0]))\n    ax[0,i].set_title(\"Positive Example\", fontweight='bold')\n    \n    ax[1,i].imshow(readImage(df.iloc[rand_neg_inds[i],0]))\n    ax[1,i].set_title(\"Negative Example\", fontweight='bold')","92b4097b":"IMG_SIZE = 196\nBATCH_SIZE = 128","d63655f2":"test_list = os.listdir(test_path)\ntrain_list = os.listdir(train_path)\nprint(\"There are \" + str(len(train_list)) + \" training examples.\")\nprint(\"There are \" + str(len(test_list)) + \" test examples.\")","5b59ffad":"df['label'] = df['label'].astype(str)\ntrain, valid = train_test_split(df, test_size=0.2, stratify = df['label'])\n","22312d51":"def crop_centre(image, crop_length):\n    original_size = image.shape[0]\n    centre = original_size \/\/ 2\n    lower_bound = centre - crop_length \/\/ 2 \n    upper_bound = centre + crop_length \/\/ 2\n    image = image[(lower_bound):(upper_bound),(lower_bound):(upper_bound)]\n    return image","081a5e38":"\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  vertical_flip = True,\n                                  horizontal_flip = True,\n                                  rotation_range=90,\n                                  zoom_range=0.2, \n                                  width_shift_range=0.1,\n                                  height_shift_range=0.1,\n                                  shear_range=0.05,\n                                  channel_shift_range=0.1)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255) ","a437b502":"\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = train, \n                                                    directory = None,\n                                                    x_col = 'path', \n                                                    y_col = 'label',\n                                                    target_size = (IMG_SIZE,IMG_SIZE),\n                                                    class_mode = \"binary\",\n                                                    batch_size=BATCH_SIZE,\n                                                    seed = 110318,\n                                                    shuffle = True)","31d4a90e":"valid_generator = test_datagen.flow_from_dataframe(dataframe = valid,\n                                                   directory = None,\n                                                   x_col = 'path',\n                                                   y_col = 'label',\n                                                   target_size = (IMG_SIZE,IMG_SIZE),\n                                                   class_mode = 'binary',\n                                                   batch_size = BATCH_SIZE,\n                                                   shuffle = False)","21fa2e75":"from keras.applications.resnet50 import ResNet50\n\ndropout_fc = 0.5\n\nconv_base = ResNet50(weights = 'imagenet', include_top = False, input_shape = (IMG_SIZE,IMG_SIZE,3))\n\nmy_model = Sequential()\n\nmy_model.add(conv_base)\nmy_model.add(Flatten())\nmy_model.add(Dense(256, use_bias=False))\nmy_model.add(BatchNormalization())\nmy_model.add(Activation(\"relu\"))\nmy_model.add(Dropout(dropout_fc))\nmy_model.add(Dense(1, activation = \"sigmoid\"))\n","868edfa5":"my_model.summary()","5a8b161e":"conv_base.Trainable=True\n\nset_trainable=False\nfor layer in conv_base.layers:\n    if layer.name == 'res5a_branch2a':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","55f4c883":"from keras import optimizers\nmy_model.compile(optimizers.Adam(0.001), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])","6cb3ca5f":"train_step_size = train_generator.n \/\/ train_generator.batch_size\nvalid_step_size = valid_generator.n \/\/ valid_generator.batch_size","5dd54941":"earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=2, restore_best_weights=True)\nreduce = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)","b5766b71":"history = my_model.fit_generator(train_generator,\n                                     steps_per_epoch = train_step_size,\n                                     epochs = 10,\n                                     validation_data = valid_generator,\n                                     validation_steps = valid_step_size,\n                                     callbacks = [reduce, earlystopper],\n                                     verbose = 2)\n\n    ","eb286090":"epochs = [i for i in range(1, len(history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('training')\nplt.xlabel('epoch')\nplt.savefig(\"training.png\", bbox_inches='tight')\nplt.show()\n\nplt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('validation')\nplt.xlabel('epoch')\nplt.savefig(\"validation.png\", bbox_inches='tight')\nplt.show()","e755f864":"roc_validation_generator = ImageDataGenerator(rescale=1.\/255).flow_from_dataframe(valid,\n                                                                                  x_col = 'path',\n                                                                                  y_col = 'label',\n                                                                                  target_size = (IMG_SIZE,IMG_SIZE),\n                                                                                  class_mode = 'binary',\n                                                                                  batch_size = BATCH_SIZE,\n                                                                                  shuffle = False)\npredictions = my_model.predict_generator(roc_validation_generator, steps=len(roc_validation_generator), verbose=2)\nfalse_positive_rate, true_positive_rate, threshold = roc_curve(roc_validation_generator.classes, predictions)\narea_under_curve = auc(false_positive_rate, true_positive_rate)\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.savefig('ROC_PLOT.png', bbox_inches='tight')\nplt.show()","5b02404c":"testdf = pd.DataFrame({'path': glob(os.path.join(test_path, '*.tif'))})\ntestdf['id'] = testdf.path.map(lambda x: (x.split(\"\/\")[3].split('.')[0]))\ntestdf.head(3)","2ced51ee":"tta_datagen = ImageDataGenerator(rescale=1.\/255, #Normalise\n                                 vertical_flip = True,\n                                 horizontal_flip = True,\n                                 rotation_range=90,\n                                 zoom_range=0.2, \n                                 width_shift_range=0.1,\n                                 height_shift_range=0.1,\n                                 shear_range=0.05,\n                                 channel_shift_range=0.1)","cb21f8ec":"tta_steps = 5\nsubmission = pd.DataFrame()\nfor index in range(0, len(testdf)):\n    data_frame = pd.DataFrame({'path': testdf.iloc[index,0]}, index=[index])\n    data_frame['id'] = data_frame.path.map(lambda x: x.split('\/')[3].split('.')[0])\n    img_path = data_frame.iloc[0,0]\n    test_img = cv2.imread(img_path)\n    test_img = cv2.resize(test_img,(IMG_SIZE,IMG_SIZE))\n    test_img = np.expand_dims(test_img, axis = 0)  \n    predictionsTTA = []\n    for i in range(0, tta_steps):\n        preds = my_model.predict_generator(tta_datagen.flow_from_dataframe(dataframe = data_frame,\n                                                                           directory = None,\n                                                                           x_col = 'path',\n                                                                           target_size = (IMG_SIZE, IMG_SIZE),\n                                                                           class_mode = None,\n                                                                           batch_size = 1,\n                                                                           shuffle = False), steps = 1)\n        predictionsTTA.append(preds)\n    clear_output()\n    prediction_entry = np.array(np.mean(predictionsTTA, axis=0))\n    data_frame['label'] = prediction_entry\n    submission = pd.concat([submission, data_frame[['id', 'label']]])\n    ","b68be52e":"submission.set_index('id')\nsubmission.head(3)","380fd28a":"submission.to_csv('submission.csv', index=False, header=True)","3c8b7faf":"# Histopathologic Cancer Detection\n\nThis is my entry for the Kaggle playground competition on cancer detection. This is my second machine learning project and was motivated by my completion of Course 4 of the Deeplearning.ai specialisation on Coursera. Pandas, matplotlib, experimenting with different hyper-parameters and transfer learning are among the skills I have practiced during my time doing this.\n\n\n","3ff6e02c":"Now it's time to import the data.\nWhat I want to do is:\n\n1. Load and display some positive and negative test examples\n2. Split the train data into train and dev sets","229126c9":"Increasing the size of the image results in a much higher performance.","23f3c857":"# Predictions","5ac737fd":"# Analysis\nNow that our model has been trained, it is time to plot some training graphs to see how our accuracies and losses varied over epochs.","cc43117d":"## Creating the model","6397b39e":"ROC Plot","05dac3d5":"Going to split 20% of the training set into a validation set.","22f791d9":"# References\nHeavily inspired by these kernels:\n\n1. [https:\/\/www.kaggle.com\/qitvision\/a-complete-ml-pipeline-fast-ai](http:\/\/)\n\n2. [https:\/\/www.kaggle.com\/fadhli\/starter-code-keras-resnet50-0-9275-lb](http:\/\/)\n\n3. [https:\/\/www.kaggle.com\/gomezp\/complete-beginner-s-guide-eda-keras-lb-0-93](http:\/\/)\n\n4. [https:\/\/www.kaggle.com\/greg115\/histopathologic-cancer-detector-lb-0-958](http:\/\/)","04109c28":"Choose 4 random positve and negative examples, find their respective path then display them in a subplot:","ded01102":"# Train\/Validation Split and Loading the Data","8ca84619":"For my predictions I'm going to use Test Time Augmentation. For each test image I will augment it 5 ways and average the prediction. I've also used ensemble learning by averaging the results of 3 versions of this model, due to this I was able to achieve my highest leaderboard score of 0.964.","2126d4b4":"I originally thought about cropping the image to the central region but that proved to be ineffective.","27b4977b":"As we're using ResNet50 trained on ImageNet, we're going to need to train the last few layers instead of the just the last one.  Cell images are quite different to what you see on ImageNet. ","e810d0f0":"Create a dataframe which contains every training examples path, id and label:","178e692c":"## Processing the data"}}