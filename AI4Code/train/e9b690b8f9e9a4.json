{"cell_type":{"683b033a":"code","3883b71f":"code","68ee2bd1":"code","de847e6f":"code","c4887b1f":"code","4da02e08":"code","61e1a0f8":"code","d4be7468":"code","8cf7bd72":"code","5b1f0a19":"code","8cc70727":"code","cf94a9a7":"code","b23baebf":"code","70e1fe9f":"code","c29fccba":"code","6ba7f7bb":"code","8b73095a":"code","c6843a03":"code","4d227c0c":"code","4f1d372a":"code","6909b69e":"code","623eb1b6":"code","b975ea09":"code","c766530b":"code","e0eb4c0c":"code","348836ec":"code","25c0b565":"code","65340154":"code","fb126e7e":"code","a4b6f770":"code","00cc4ce1":"code","8ca4d46c":"code","1fa707cc":"code","c19b17b2":"code","fcfed480":"code","eeeef806":"code","d09d7cf5":"code","5b5d6ca3":"code","fbe5ffde":"code","d141b1f5":"code","25cd5100":"code","c6688e00":"code","e5b230bc":"code","752a6cba":"code","ec63e89e":"code","bdbefb8f":"code","99b41049":"code","a1a02479":"code","b8003c9d":"code","6b793a8e":"code","4f3a3eb0":"code","a37f050b":"code","6dddee29":"code","d5639545":"code","655a7fff":"code","0d5bc19d":"code","98c63b2b":"code","ece95a63":"code","c49d74cf":"code","d9a88326":"code","571fcaa0":"code","ffcbf9fd":"code","839e44ad":"code","0a603a7a":"code","81bccb9e":"code","5070055c":"code","f50553e1":"code","8a8a047d":"code","f499aeaf":"code","707de667":"code","367767a0":"code","13c4dcd6":"code","c81a6468":"code","1cabcfbb":"code","995e4276":"code","17af0ab0":"code","c109bc5f":"code","9cbeba99":"code","3eda7772":"code","1c9ebc14":"code","51c3d361":"code","a39a5164":"code","6ab3ada9":"code","e194e406":"code","3046d40e":"code","d091db1c":"code","3992e6ce":"code","5aaca3cb":"code","6496b158":"code","ac1645e6":"code","c23c129f":"code","0f618777":"code","656bdae5":"code","4ddc6164":"code","a1659a58":"code","48a30695":"code","ab2a1944":"code","9935cce4":"code","f4d2c537":"code","63844677":"code","34b6a843":"code","5341e15e":"code","f55b8480":"code","56af88f5":"code","9de67540":"code","67d72ef9":"code","95275429":"code","9426b53b":"code","c0a73ce5":"code","476501f5":"code","5eaaa142":"code","d690f18f":"code","e28aa4a4":"code","62d9ba41":"code","deaacca2":"markdown","5d386059":"markdown","eaa9764d":"markdown","ac1a529e":"markdown","1aa13f1f":"markdown","34d894ed":"markdown","92c295c2":"markdown","17e9773a":"markdown","8dcfe19e":"markdown","d43d3562":"markdown","6d72f495":"markdown","9f0bbf25":"markdown","c56ebd8f":"markdown","f28d6189":"markdown","d7efab99":"markdown","b1d7e17e":"markdown","80102521":"markdown","d1932d91":"markdown","e3c0134f":"markdown","4c08245e":"markdown","fbf65c4b":"markdown","bb4771c4":"markdown","1f5051bd":"markdown","5074bdf5":"markdown","40bb1c4e":"markdown","43bee335":"markdown","56234707":"markdown","f830f1c1":"markdown","478034ad":"markdown","f42fe01c":"markdown","3cfbd97e":"markdown","6e7d2f79":"markdown","df8ad629":"markdown","c8dcbc59":"markdown","b1a9835f":"markdown","4e62bb79":"markdown","68e3277b":"markdown","b94bf5d4":"markdown","fc6d65d8":"markdown","217f586e":"markdown","28137627":"markdown","8226129c":"markdown","4c5a9f3a":"markdown","7c675a02":"markdown","5bde43db":"markdown","50034d66":"markdown","379f1577":"markdown","66cb11c0":"markdown","8bf1b9f7":"markdown","df84142f":"markdown","8b7d5e55":"markdown","635a7df4":"markdown","a3369df7":"markdown","8fb33f4b":"markdown","c4a8eada":"markdown","59267fe6":"markdown","13b5a2dc":"markdown","92bd26eb":"markdown","fdf3d8f6":"markdown","063d7f61":"markdown","5bffc0a8":"markdown"},"source":{"683b033a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n#!pip install catboost\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# ignore the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(rc={'figure.figsize': [7, 7]}, font_scale=1.2)\n%config Completer.use_jedi=False\npd.set_option(\"display.max_columns\", None)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3883b71f":"dataset_path = '\/kaggle\/input\/bike-sharing-demand\/'\n\ndfTrainO = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\ndfTestO = pd.read_csv(os.path.join(dataset_path, 'test.csv'))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(dfTrainO.shape))\nprint(\"The shape of the dataset is {}.\\n\\n\".format(dfTestO.shape))\ndfTrainO.head()","68ee2bd1":"# dfTrainO=pd.read_csv(\"train.csv\")\n# print('---'*30)\n# print('Train Head')\n# print('---'*30)\n# display(dfTrainO.sample(5))\n# dfTestO=pd.read_csv(\"test.csv\")\n# print('---'*30)\n# print('Test Head')\n# print('---'*30)\n# display(dfTestO.sample(5))\n# # dfTestTrueY=pd.read_csv(\"yTest.csv\")\n# # dfTestTrueY.drop(columns='Unnamed: 0',inplace=True)\n# # dfTestTrueY['WorkingDay'] = np.where((dfTestTrueY['WorkingDay']==1 )& (dfTestTrueY['Holiday']==\"Holiday\"), 0, dfTestTrueY['WorkingDay'])\n# # print('---'*30)\n# # print('Teat True Head')\n# # print('---'*30)\n# # display(dfTestTrueY.head())","de847e6f":"dictYears={2011:0,2012:1}\n##############################################################################\ndfTrainO[\"Date\"]            = pd.to_datetime(dfTrainO[\"datetime\"], format='%Y\/%m\/%d')\ndfTrainO[\"Year\"]            = dfTrainO['Date'].dt.year\ndfTrainO[\"Month\"]           = dfTrainO['Date'].dt.month\ndfTrainO[\"Day\"]             = dfTrainO[\"Date\"].dt.day\ndfTrainO[\"Hour\"]             = dfTrainO[\"Date\"].dt.hour\ndfTrainO[\"DayName\"]         = dfTrainO['Date'].dt.day_name()\ndfTrainO[\"DayNumber\"]       = dfTrainO[\"Date\"].dt.dayofweek\ndfTrainO[\"Year\"]            = dfTrainO[\"Year\"].map(dictYears)\ndfTrainO.drop(columns='Date',inplace=True)","c4887b1f":"dfTrainO.head()","4da02e08":"dfTestO[\"Date\"]            = pd.to_datetime(dfTestO[\"datetime\"], format='%Y\/%m\/%d')\ndfTestO[\"Year\"]            = dfTestO['Date'].dt.year\ndfTestO[\"Month\"]           = dfTestO['Date'].dt.month\ndfTestO[\"Day\"]             = dfTestO[\"Date\"].dt.day\ndfTestO[\"Hour\"]             = dfTestO[\"Date\"].dt.hour\ndfTestO[\"DayName\"]         = dfTestO['Date'].dt.day_name()\ndfTestO[\"DayNumber\"]       = dfTestO[\"Date\"].dt.dayofweek\ndfTestO[\"Year\"]            = dfTestO[\"Year\"].map(dictYears)\ndfTestO.drop(columns='Date',inplace=True)","61e1a0f8":"dfTestO.head()","d4be7468":"dfTrainO.columns","8cf7bd72":"dfTrainO.rename(columns={\"season\": 'Seasons',\"holiday\": 'Holiday','humidity':'Humidity','windspeed':'Wind_Speed','weather':'Weather','temp':'Temperature','atemp':'aTemperature','casual':'Casual','registered':'Registered','workingday':'WorkingDay'},inplace=True)","5b1f0a19":"dfTrainO.columns","8cc70727":"dfTrainO.head()","cf94a9a7":"dfTestO.columns","b23baebf":"dfTestO.rename(columns={\"season\": 'Seasons',\"holiday\": 'Holiday','humidity':'Humidity','windspeed':'Wind_Speed','weather':'Weather','temp':'Temperature','atemp':'aTemperature','workingday':'WorkingDay'},inplace=True)","70e1fe9f":"dfTestO.columns","c29fccba":"dfTestO.head()","6ba7f7bb":"dfTrainO = dfTrainO[['datetime','Year', 'Month','Day', 'DayName',\n       'DayNumber','Hour', 'Weather','Temperature','count',\n       'Humidity', 'Wind_Speed','Seasons', 'Holiday',\n       'WorkingDay','Casual','Registered']]","8b73095a":"dfTrainO.head()","c6843a03":"dfTestO = dfTestO[['datetime','Year', 'Month','Day', 'DayName',\n       'DayNumber','Hour', 'Weather','Temperature', 'Humidity', 'Wind_Speed',\n       'Seasons', 'Holiday','WorkingDay']]","4d227c0c":"dfTestO.head()","4f1d372a":"dfTrainO.shape","6909b69e":"dfTestO.shape #(The difference is the Y Target)","623eb1b6":"dfTrainO['Temperature']=np.floor(dfTrainO['Temperature']).astype(int)","b975ea09":"dfTrainO.head()","c766530b":"dfTestO['Temperature']=np.floor(dfTestO['Temperature']).astype(int)","e0eb4c0c":"dfTestO.head()","348836ec":"dfTrainNEW=dfTrainO.copy()","25c0b565":"dfTrainNEW.info()","65340154":"dfTestNEW=dfTestO.copy()","fb126e7e":"dfTestNEW.info()","a4b6f770":"dfTrainNEW.groupby('Hour')['count'].sum().plot(kind='bar');","00cc4ce1":"dfTrainNEW.groupby('Seasons')['count'].sum().plot(kind='bar');","8ca4d46c":"def extract_period_of_day1(hour):\n    if hour in range(12):\n        return 'Morning'\n    elif hour in range(12, 18):\n        return 'Afternoon'\n    elif hour in range(18, 22):\n        return 'Evening'\n    else:\n        return 'Night'\ndef extract_period_of_day2(hour):\n    if hour in range(6,19):\n        return 1\n    elif hour in range(19,24):\n        return 0\n    else:\n        return 0\ndef is_rush_hour(hour):\n    return 0 if hour in [0,1,2,3,4,5,6,10,21,22,23] else 1","1fa707cc":"dfTrainNEW['Hour_Sin']    = np.sin(dfTrainNEW['Hour']*(2.*np.pi\/24))\ndfTrainNEW['Hour_Cos']    = np.cos(dfTrainNEW['Hour']*(2.*np.pi\/24))\ndfTrainNEW['DayName_Sin'] = np.sin(pd.Categorical(dfTrainNEW['DayName']).codes*(2.*np.pi\/7))\ndfTrainNEW['DayName_Cos'] = np.cos(pd.Categorical(dfTrainNEW['DayName']).codes*(2.*np.pi\/7))","c19b17b2":"dfTrainNEW['Day_Period'] = dfTrainNEW['Hour'].apply(extract_period_of_day1)\ndfTrainNEW['Rush_Hour']  = dfTrainNEW['Hour'].apply(is_rush_hour)\ndfTrainNEW.head()","fcfed480":"dfTrainNEW.info()","eeeef806":"dfTestNEW['Hour_Sin']    = np.sin(dfTestNEW['Hour']*(2.*np.pi\/24))\ndfTestNEW['Hour_Cos']    = np.cos(dfTestNEW['Hour']*(2.*np.pi\/24))\ndfTestNEW['DayName_Sin'] = np.sin(pd.Categorical(dfTestNEW['DayName']).codes*(2.*np.pi\/7))\ndfTestNEW['DayName_Cos'] = np.cos(pd.Categorical(dfTestNEW['DayName']).codes*(2.*np.pi\/7))","d09d7cf5":"dfTestNEW['Day_Period'] = dfTestNEW['Hour'].apply(extract_period_of_day1)\ndfTestNEW['Rush_Hour']  = dfTestNEW['Hour'].apply(is_rush_hour)\ndfTestNEW.head()","5b5d6ca3":"dfTestNEW.info()","fbe5ffde":"print('dfTrainNew Columns:\\n',dfTrainNEW.columns.tolist())\nprint('----'*50)\nprint('dfTestNew Columns:\\n',dfTestNEW.columns.tolist())\nprint('----'*50)\n#print('dfTestTrueY Columns:\\n',dfTestTrueY.columns.tolist())","d141b1f5":"dfTrainNEW['Day_Period'].value_counts()","25cd5100":"dfTestNEW['Day_Period'].value_counts()","c6688e00":"dfTrainNEW[\"Rush_Hour\"].value_counts()","e5b230bc":"dfTestNEW[\"Rush_Hour\"].value_counts()","752a6cba":"def ValueCounts(df):\n    for c in df.columns:\n        print(c+\"\\n\"+\"-----------------\"+\"\\n\")\n        print(df[c].value_counts().to_frame())\n        print(\"\\n\"+\"******************\"+\"\\n\")","ec63e89e":"def UniqueValues(df,l):\n    for c in l:\n        print(c+\"\\n\"+\"-----------------\"+\"\\n\")\n        print(df[c].unique())\n        print(\"\\n\"+\"******************\"+\"\\n\")","bdbefb8f":"ValueCounts(dfTrainNEW)","99b41049":"ValueCounts(dfTestNEW)","a1a02479":"UniqueValues(dfTrainNEW,dfTrainNEW.columns)","b8003c9d":"UniqueValues(dfTestNEW,dfTestNEW.columns)","6b793a8e":"dfTrainNEW.describe().T","4f3a3eb0":"dfTestNEW.describe().T","a37f050b":"# dfTestTrueY.describe().T","6dddee29":"# dfTestTrueY.groupby('Hour')['y'].sum().plot(kind='bar');","d5639545":"# dfTestTrueY.groupby('Seasons')['y'].sum().plot(kind='bar');","655a7fff":"dfTrainNEW.columns","0d5bc19d":"figure, axes = plt.subplots(nrows=3, ncols=3)\nfigure.set_size_inches(20,15)\nfigure.tight_layout()\nsns.kdeplot(dfTrainNEW['Temperature']    ,shade=True, ax=axes[0][0]);\nsns.kdeplot(dfTrainNEW['count']          ,shade=True, ax=axes[0][1]);\nsns.kdeplot(dfTrainNEW['Humidity']       ,shade=True, ax=axes[0][2]);\nsns.kdeplot(dfTrainNEW['Wind_Speed']     ,shade=True, ax=axes[1][0]);\nsns.kdeplot(dfTrainNEW['Weather']        ,shade=True, ax=axes[1][1]);\nsns.kdeplot(dfTrainNEW['Hour']           ,shade=True, ax=axes[1][2]);\nsns.kdeplot(dfTrainNEW['Seasons']        ,shade=True, ax=axes[2][0]);\nsns.kdeplot(dfTrainNEW['Registered']     ,shade=True, ax=axes[2][1]);\nsns.kdeplot(dfTrainNEW['Casual']         ,shade=True, ax=axes[2][2]);","98c63b2b":"figure, axes = plt.subplots(nrows=2, ncols=3)\nfigure.set_size_inches(20,15)\nfigure.tight_layout()\nsns.kdeplot(dfTestNEW['Temperature']    ,shade=True, ax=axes[0][0]);\nsns.kdeplot(dfTestNEW['Humidity']       ,shade=True, ax=axes[0][1]);\nsns.kdeplot(dfTestNEW['Wind_Speed']     ,shade=True, ax=axes[0][2]);\nsns.kdeplot(dfTestNEW['Weather']        ,shade=True, ax=axes[1][0]);\nsns.kdeplot(dfTestNEW['Hour']           ,shade=True, ax=axes[1][1]);\nsns.kdeplot(dfTestNEW['Seasons']        ,shade=True, ax=axes[1][2]);","ece95a63":"dfTrainNEW['logcount']   =dfTrainNEW['count'].apply(np.log1p)\ndfTrainNEW['sqrtcount']  =dfTrainNEW['count'].apply(np.sqrt)\ndfTrainNEW['squarcount'] =np.power(dfTrainNEW['count'],2)","c49d74cf":"figure, axes = plt.subplots(nrows=1, ncols=4)\nfigure.set_size_inches(20,10)\nsns.kdeplot(dfTrainNEW['count']      ,shade=True, ax=axes[0]);\nsns.kdeplot(dfTrainNEW['logcount']   ,shade=True, ax=axes[1]);\nsns.kdeplot(dfTrainNEW['sqrtcount']  ,shade=True, ax=axes[2]);\nsns.kdeplot(dfTrainNEW['squarcount'] ,shade=True, ax=axes[3]);","d9a88326":"dfTrainNEW['logWind_Speed']   =dfTrainNEW['Wind_Speed'].apply(np.log1p)\ndfTrainNEW['sqrtWind_Speed']  =dfTrainNEW['Wind_Speed'].apply(np.sqrt)\ndfTrainNEW['squarWind_Speed'] =np.power(dfTrainNEW['Wind_Speed'],2)","571fcaa0":"figure, axes = plt.subplots(nrows=1, ncols=4)\nfigure.set_size_inches(20,10)\nsns.kdeplot(dfTrainNEW['Wind_Speed']      ,shade=True, ax=axes[0]);\nsns.kdeplot(dfTrainNEW['logWind_Speed']   ,shade=True, ax=axes[1]);\nsns.kdeplot(dfTrainNEW['sqrtWind_Speed']  ,shade=True, ax=axes[2]);\nsns.kdeplot(dfTrainNEW['squarWind_Speed'] ,shade=True, ax=axes[3]);","ffcbf9fd":"dfTrainNEW.columns","839e44ad":"dfTrainNEW.drop(columns=['logcount','squarcount','sqrtWind_Speed','logWind_Speed','squarWind_Speed'],inplace=True)","0a603a7a":"dfTrainNEW.info()","81bccb9e":"dfTestNEW.info()","5070055c":"set(dfTrainNEW[\"Seasons\"])","f50553e1":"# print('Train')\n# sns.pairplot(dfTrainNEW)\n\n# print('Test True')\n# sns.pairplot(dfTestNEW)","8a8a047d":"corr_matrix = dfTrainNEW.corr()\nmask = np.array(corr_matrix)\nmask[np.tril_indices_from(mask)] = False\n\nfig = plt.figure(figsize=(25, 20))\nsns.heatmap(np.round(corr_matrix,2), mask=mask, annot=True, cbar=True, vmax=0.8, vmin=-0.8, cmap='RdYlGn')\nplt.show()","f499aeaf":"abs(dfTrainNEW.corr()[\"count\"]).sort_values(ascending=False)","707de667":"def zscore(series): \n    return (series-series.mean())\/series.std()\ndfTrainNEW_O=dfTrainNEW.copy()\ndfTrainNEW_O['count_zscore'] = dfTrainNEW.groupby(['Hour', 'WorkingDay'])['count'].transform(zscore)\noutlier_idx = np.abs(dfTrainNEW_O['count_zscore'])>3\noutlier_data = dfTrainNEW_O.loc[outlier_idx, :]\nprint('Shape of the outlier data entries: ', outlier_data.shape)\noutlier_data","367767a0":"#Removing outliers from Data\ndfTrainNEW_Wo = dfTrainNEW_O.loc[~outlier_idx, :]\nprint('Shape of Data Before Outlier Pruning: ', dfTrainNEW.shape)\nprint('Shape of Data After Outlier Pruning: ', dfTrainNEW_Wo.shape)","13c4dcd6":"# dfTrainNEW.drop(['Hour', 'DayName'], axis=1, inplace=True)\n# dfTestNEW.drop(['Hour', 'DayName'], axis=1, inplace=True)","c81a6468":"dfTrainNEW.head()","1cabcfbb":"dfTestNEW.head()","995e4276":"dfTrainNEW.info()","17af0ab0":"dfTrainEncoded_Dummies =dfTrainNEW.copy()\ndfTestEncoded_Dummies  =dfTestNEW.copy()","c109bc5f":"dfTrainEncoded_Dummies = pd.get_dummies(dfTrainEncoded_Dummies,columns=['Day_Period'],drop_first=True)\ndfTestEncoded_Dummies  = pd.get_dummies(dfTestEncoded_Dummies, columns=['Day_Period'],drop_first=True)","9cbeba99":"dfTrainEncoded_Dummies.head()","3eda7772":"dfTrainEncoded_Dummies.info()","1c9ebc14":"dfTestEncoded_Dummies.head()","51c3d361":"dfTestEncoded_Dummies.info()","a39a5164":"dfTrainEncoded_Labels =dfTrainNEW.copy()\ndfTestEncoded_Labels  =dfTestNEW.copy()","6ab3ada9":"class MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)","e194e406":"dfTrainEncoded_Labels=MultiColumnLabelEncoder(columns = ['Day_Period']).fit_transform(dfTrainEncoded_Labels)\ndfTestEncoded_Labels=MultiColumnLabelEncoder(columns =  ['Day_Period']).fit_transform(dfTestEncoded_Labels)","3046d40e":"dfTrainEncoded_Labels.head()","d091db1c":"dfTrainEncoded_Labels.info()","3992e6ce":"dfTestEncoded_Labels.head()","5aaca3cb":"dfTestEncoded_Labels.info()","6496b158":"abs(dfTrainEncoded_Dummies.corr()[\"count\"]).sort_values()","ac1645e6":"abs(dfTrainEncoded_Dummies.corr()[\"count\"]).sort_values().index","c23c129f":"dfTrainEncoded_Dummies.columns","0f618777":"abs(dfTrainEncoded_Labels.corr()[\"count\"]).sort_values()","656bdae5":"abs(dfTrainEncoded_Labels.corr()[\"count\"]).sort_values().index","4ddc6164":"dfTrain = dfTrainEncoded_Dummies.drop(columns = ['Casual','Registered','sqrtcount','DayName'])#hour, snowfall, windspeed\n# dfTrain.info()","a1659a58":"dfTest  = dfTestEncoded_Dummies.drop(columns = ['DayName'])\n# dfTest.info()","48a30695":"def normalize(df):\n    result = df.copy()\n    for feature_name in df.columns:\n        max_value = df[feature_name].max()\n        min_value = df[feature_name].min()\n        result[feature_name] = (df[feature_name] - min_value) \/ (max_value - min_value)\n    return result","ab2a1944":"from sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(dfTrain, test_size=0.2, random_state=42,stratify =None)\nX_train = train_df.drop(columns=[\"datetime\",\"count\"])\ny_train = train_df['count']\n################################################################################################\nX_val = val_df.drop(columns=[\"datetime\",\"count\"])\ny_val = val_df['count']","9935cce4":"y_trainLog=np.log1p(y_train)\ny_valLog=np.log1p(y_val)","f4d2c537":"# X_train=normalize(X_train)\n# X_val=normalize(X_val)\n# dfTest=normalize(dfTest)","63844677":"# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler()\n# scaler.fit(X_train)\n# X_train = scaler.transform(X_train)\n# X_val = scaler.transform(X_val)","34b6a843":"# from sklearn.preprocessing import minmax_scale\n# X_train = minmax_scale(X_train, feature_range=(0, 1))\n# X_val = minmax_scale(X_val, feature_range=(0, 1))","5341e15e":"# from sklearn.preprocessing import RobustScaler\n# rb = RobustScaler()\n# X_train= rb.fit_transform(X_train)\n# X_val = rb.fit_transform(X_val)","f55b8480":"from sklearn.preprocessing import StandardScaler\nscaler  = StandardScaler()\nX_train = scaler.fit_transform(X_train.values)\nX_val   = scaler.fit_transform(X_val.values)","56af88f5":"from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import BaggingRegressor\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import r2_score","9de67540":"def rmsle(y_true, y_pred, convertExp=True):\n    # Apply exponential transformation function\n    if convertExp:\n        y_true = np.exp(y_true)\n        y_pred = np.exp(y_pred)\n        \n    # Convert missing value to zero after log transformation\n    log_true = np.nan_to_num(np.array([np.log(y+1) for y in y_true]))\n    log_pred = np.nan_to_num(np.array([np.log(y+1) for y in y_pred]))\n    \n    # Compute RMSLE\n    output = np.sqrt(np.mean((log_true - log_pred)**2))\n    return output","67d72ef9":"models = {\n    \"LinearRegression\":            LinearRegression(),\n    \"Ridge\":                       Ridge(),\n    \"Lasso\":                       Lasso(),\n    \"ElasticNet\":                  ElasticNet(),\n    \"KNeighborsRegressor\":         KNeighborsRegressor(), \n    \"DecisionTreeRegressor\":       DecisionTreeRegressor(),\n    \"RandomForestRegressor\":       RandomForestRegressor(),\n    \"BaggingRegressor\":            BaggingRegressor(),\n    \"AdaBoostRegressor\":           AdaBoostRegressor(),\n    \"CatBoostRegressor\":           CatBoostRegressor(verbose=False),\n    \"LGBMRegressor\":               LGBMRegressor(),\n    \"GradientBoostingRegressor\":   GradientBoostingRegressor(),\n    \"XGBRegressor\":                XGBRegressor()\n}","95275429":"for name, model in models.items():\n    print(f'Using model: {name}')\n    model.fit(X_train, y_trainLog)\n    print(f\"train score : {model.score(X_train,y_trainLog)}\")\n    print(f'RMSLETrain: {rmsle(y_trainLog, model.predict(X_train))}')\n    print(f'RMSLEVal: {rmsle(y_valLog, model.predict(X_val))}')\n    print('-'*30)","9426b53b":"datetime=dfTest[\"datetime\"]\nX_test = dfTest.drop(columns=['datetime'])\nX_test=scaler.transform(X_test)","c0a73ce5":"# Model=XGBRegressor(\"reg:squaredlogerror\")\n# Model.fit(X_train, y_trainLog)\n\n# print(f'RMSLETrain: {rmsle(y_trainLog, Model.predict(X_train))}')\n# print(f'RMSLEVal: {rmsle(y_valLog, Model.predict(X_val))}')\n# print(\"-\"*10)","476501f5":"# model = CatBoostRegressor(verbose=False)\n# parameters = {'depth'          : [1,2,3,4,5,6],\n#               'learning_rate'  : [0.01, 0.05, 0.1,0.15,0.2,0.25],\n#               'n_estimators'   : [100,200,300,400,500,600],\n#               'l2_leaf_reg'    : [1,2,3,4,5,6],\n#               'random_strength': [0.6,0.61,0.62,0.65,0.665,0.7]\n#               }\n\n# grid = GridSearchCV(estimator=model, param_grid = parameters, cv = 4, n_jobs=-1)\n# grid.fit(X_train, y_trainLog)","5eaaa142":"Model=CatBoostRegressor(verbose=False, n_estimators=500 ,learning_rate=0.15,depth=3,l2_leaf_reg=2,random_strength=0.665)\nModel.fit(X_train, y_trainLog)\n\nprint(f'RMSLETrain: {rmsle(y_trainLog, Model.predict(X_train))}')\nprint(f'RMSLEVal: {rmsle(y_valLog, Model.predict(X_val))}')\n","d690f18f":"y_test_predicted = Model.predict(X_test)\n\ndfTest['count'] = np.floor(np.exp(y_test_predicted)).astype('int') \nyPredictTest=dfTest['count']","e28aa4a4":"dfTest.drop(columns=\"datetime\",inplace=True)\ndfTest=pd.concat([dfTest, datetime],axis=1)\ndfTest.head()","62d9ba41":"dfTest[['datetime', 'count']].to_csv('\/kaggle\/working\/submission.csv', index=False)\n# dfTest[['datetime', 'count']].to_csv('submission.csv', index=False)","deaacca2":"### Train","5d386059":"###### Test","eaa9764d":"_______________________________","ac1a529e":"## 2. Label Encoding","1aa13f1f":"## Train","34d894ed":"# Features to Check: `Count`, `Wind_Speed`","92c295c2":"### Train","17e9773a":"##### Train","8dcfe19e":"# Check for skewness","d43d3562":"# Machine Learning Model ","6d72f495":"# Correlations","9f0bbf25":"### Test","c56ebd8f":"## `Wind_Speed`","f28d6189":"# Rearrange the Columns","d7efab99":"________________________________________________","b1d7e17e":"## Check","80102521":"### Train","d1932d91":"## 1. One Hot Encoding","e3c0134f":"#### Test","4c08245e":"********************************************\n********************************************\n********************************************","fbf65c4b":"## 1. One Hot Encoding","bb4771c4":"### Test","1f5051bd":"________________________________________________________","5074bdf5":"# DateTime Handel","40bb1c4e":"**************************************\n**************************************\n**************************************","43bee335":"_______________________________________________________","56234707":"## `count`","f830f1c1":"### Test","478034ad":"__________________________________________________","f42fe01c":"## Train","3cfbd97e":"### Train","6e7d2f79":"# `SquareRoot` Y        ------> Best","df8ad629":"# Rename Columns","c8dcbc59":"_____________________________________________________________","b1a9835f":"# Edit the Temperature to be Integer","4e62bb79":"# Categorical Columns Encoding","68e3277b":"## Test","b94bf5d4":"# Read Train and Test Data","fc6d65d8":"### Train","217f586e":"________________","28137627":"# Feature Engineering to the Date and Hour (Sin & Cos) DayName (Sin & Cos)","8226129c":"## 2. Label Encoding","4c5a9f3a":"# Check the Correlation","7c675a02":"## True Test","5bde43db":"##### Train","50034d66":"## Train","379f1577":"# Create a Copy of the Data Frames to work with","66cb11c0":"# Plots To Visualize the Data","8bf1b9f7":"###### Test","df84142f":"## Test Data","8b7d5e55":"##### Removing Outliers from Data","635a7df4":"## Outliers Check","a3369df7":"# Drop the Columns we Don't Need","8fb33f4b":"____________________________________________","c4a8eada":"# Import Required Libraries","59267fe6":"#### Train","13b5a2dc":"_________________________________________________","92bd26eb":"## Check The Shape","fdf3d8f6":"# Value Counts and Uniques Equations","063d7f61":"## Train Data","5bffc0a8":"### Check"}}