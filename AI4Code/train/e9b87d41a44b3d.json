{"cell_type":{"178c42ae":"code","23de76ea":"code","7b3c012f":"code","47e3169c":"code","60b34834":"code","aeca7833":"code","86741492":"code","bf762d85":"code","4a66bd3d":"code","19b6bff8":"code","ed2dfd0e":"code","d4cb134e":"code","2663e213":"code","6c538174":"code","16fc1484":"code","6980b22c":"code","96d7966b":"code","ecfb1f06":"code","e1551792":"code","7e2607ae":"code","6529b026":"code","8710fc61":"code","243943cc":"code","701afac8":"code","d1f8366d":"code","a77098c9":"code","8c500125":"code","2dc0b932":"code","e570ca2d":"code","a9aa78e5":"code","17ccae86":"code","191ac1bf":"code","9ea81f50":"code","180fd2d9":"code","e63412b6":"code","95b5abe5":"code","e6446352":"code","fc63c54f":"code","3e40784a":"markdown","445990b7":"markdown","bcab6ac0":"markdown","73dd14b5":"markdown","8d3ed0ca":"markdown","11d6dd9a":"markdown","3303785d":"markdown","9e447c9b":"markdown","48601be3":"markdown","973c8993":"markdown","d2e4037f":"markdown"},"source":{"178c42ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom keras.models import Sequential, load_model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import layers\nfrom keras.layers import *\nfrom keras.utils import np_utils\n\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","23de76ea":"train_df = pd.read_csv('\/kaggle\/input\/emnist\/emnist-balanced-train.csv', header=None)\ntrain_df.head()","7b3c012f":"train_df.shape","47e3169c":"X_train = train_df.loc[:, 1:]\ny_train = train_df.loc[:, 0]\n\nX_train.shape, y_train.shape","60b34834":"X_train.head()","aeca7833":"y_train.head()","86741492":"label_map = pd.read_csv(\"\/kaggle\/input\/emnist\/emnist-balanced-mapping.txt\", \n                        delimiter = ' ', \n                        index_col=0, \n                        header=None, \n                        squeeze=True)\nlabel_map.head()","bf762d85":"label_dictionary = {}\nfor index, label in enumerate(label_map):\n    label_dictionary[index] = chr(label)\n\nlabel_dictionary","4a66bd3d":"# Sample entry number 42\nsample_image = X_train.iloc[42]\nsample_label = y_train.iloc[42]\nsample_image.shape, sample_label","19b6bff8":"W = 28\nH = 28","ed2dfd0e":"print(\"Label entry 42:\", label_dictionary[sample_label])\nplt.imshow(sample_image.values.reshape(W, H), cmap=plt.cm.gray)\nplt.show()","d4cb134e":"def reshape_and_rotate(image):\n    W = 28\n    H = 28\n    image = image.reshape(W, H)\n    image = np.fliplr(image)\n    image = np.rot90(image)\n    return image\n\nprint(\"Label entry 42:\", label_dictionary[sample_label])\nplt.imshow(reshape_and_rotate(sample_image.values), cmap=plt.cm.gray)\nplt.show()","2663e213":"# note: np.apply_along_axis returns a numpy array, X_train is not a pandas.DataFrame anymore\nX_train = np.apply_along_axis(reshape_and_rotate, 1, X_train.values)\nX_train.shape","6c538174":"sample_image = X_train[42]\nsample_label = y_train.iloc[42]\nprint(\"Label entry 42:\", label_dictionary[sample_label])\nplt.imshow(sample_image.reshape(W, H), cmap=plt.cm.gray)\nplt.show()\n\n\nfor i in range(100, 106):\n    plt.subplot(390 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.cm.gray)\n    plt.title(label_dictionary[y_train[i]])","16fc1484":"X_train = X_train.astype('float32') \/ 255","6980b22c":"number_of_classes = y_train.nunique()\nnumber_of_classes","96d7966b":"y_train = np_utils.to_categorical(y_train, number_of_classes)\ny_train.shape","ecfb1f06":"y_train","e1551792":"# Reshape to fit model input shape\n# Tensorflow (batch, width, height, channels)\nX_train = X_train.reshape(-1, W, H, 1)\nX_train.shape","7e2607ae":"# Split 10% validation \nX_train, X_val, y_train, y_val = train_test_split(X_train, \n                                                  y_train, \n                                                  test_size= 0.1, \n                                                  random_state=88)","6529b026":"model = Sequential()\n\nmodel.add(layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(W, H, 1)))\nmodel.add(layers.MaxPool2D(strides=2))\nmodel.add(layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\nmodel.add(layers.MaxPool2D(strides=2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(84, activation='relu'))\nmodel.add(layers.Dense(number_of_classes, activation='softmax'))\n\nmodel.summary()","8710fc61":"optimizer_name = 'adam'\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer_name, metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\nmcp_save = ModelCheckpoint('my_model.h5', save_best_only=True, monitor='val_loss', verbose=1, mode='auto')","243943cc":"history = model.fit(X_train,\n                    y_train, \n                    epochs=30, \n                    batch_size=32, \n                    verbose=1, \n                    validation_split=0.1,\n                    callbacks=[early_stopping, mcp_save])","701afac8":"# plot accuracy and loss\ndef plotgraph(epochs, acc, val_acc):\n    # Plot training & validation accuracy values\n    plt.plot(epochs, acc, 'b')\n    plt.plot(epochs, val_acc, 'r')\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper left')\n    plt.show()\n    \nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1,len(acc)+1)","d1f8366d":"# Accuracy curve\nplotgraph(epochs, acc, val_acc)","a77098c9":"# loss curve\nplotgraph(epochs, loss, val_loss)","8c500125":"# Load best model\nmodel = load_model('\/kaggle\/working\/my_model.h5')\nmodel.summary()","2dc0b932":"y_pred = model.predict(X_val)\ny_pred.shape","e570ca2d":"for i in range(10, 16):\n    plt.subplot(380 + (i%10+1))\n    plt.imshow(X_val[i].reshape(28, 28), cmap=plt.cm.gray)\n    plt.title(label_dictionary[y_pred[i].argmax()])","a9aa78e5":"for i in range(42, 48):\n    plt.subplot(380 + (i%10+1))\n    plt.imshow(X_val[i].reshape(28, 28), cmap=plt.cm.gray)\n    plt.title(label_dictionary[y_pred[i].argmax()])","17ccae86":"model.evaluate(X_val, y_val)","191ac1bf":"test_df = pd.read_csv('\/kaggle\/input\/emnist\/emnist-balanced-test.csv', header=None)\ntest_df.shape","9ea81f50":"test_df.describe()","180fd2d9":"X_test = test_df.loc[:, 1:]\ny_test = test_df.loc[:, 0]\n\nX_test.shape, y_test.shape","e63412b6":"X_test = np.apply_along_axis(reshape_and_rotate, 1, X_test.values)\ny_test = np_utils.to_categorical(y_test, number_of_classes)\n\nX_test.shape, y_test.shape","95b5abe5":"X_test = X_test.astype('float32') \/ 255","e6446352":"X_test = X_test.reshape(-1, W, H, 1)\nX_test.shape","fc63c54f":"model.evaluate(X_test, y_test)","3e40784a":"### Test model","445990b7":"## Visualize more sample","bcab6ac0":"### Define model","73dd14b5":"#### Test accuracy","8d3ed0ca":"### Visualize sample data","11d6dd9a":"### Create label dictionary","3303785d":"### One Hot Encode Label","9e447c9b":"Next we want to apply reshape_and_rotate to all images in X_train","48601be3":"### Load test dataset & preprocess image like how we did to train dataset","973c8993":"Looks good\n\n### Normalize Data","d2e4037f":"### Split train dataframe into X & y"}}