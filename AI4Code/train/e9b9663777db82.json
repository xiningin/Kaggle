{"cell_type":{"cef4d92d":"code","53355041":"code","bd5c263f":"code","3bcbaed0":"code","a75077b3":"code","18e17098":"code","05832d44":"code","91ce4a24":"code","65d4fe3b":"code","54dd2fa1":"code","2397c883":"code","5f3f6782":"code","b16e07e9":"code","170400a8":"code","4d39963a":"code","603d922c":"code","dbeeccf5":"code","18a6c962":"code","76f3d4c4":"code","7473aa79":"code","d2877baa":"code","001de729":"code","e7a89810":"code","8e29b065":"code","03961ff8":"code","9f50b579":"code","b079d4c5":"code","e8654ea1":"code","99b506a2":"code","98f34337":"code","b5c0f528":"code","3122095f":"code","7ae6a34d":"code","0c1e691a":"code","5fe53fb9":"code","3f36198b":"code","be4ac3a8":"code","418dfe9a":"code","95288edb":"code","881e0410":"code","17c73bf3":"code","ee3f558e":"code","0f85eb03":"code","c0906d91":"code","7be8b5e2":"code","ace04db5":"code","07c6f251":"code","6d1a6411":"code","02ee9899":"code","475eea29":"code","57d87a54":"code","b6b88d89":"code","2748fa0d":"code","5a91c5c5":"code","0e39072e":"code","febe177f":"code","e2a373a8":"code","4e148064":"code","9de5c815":"code","75e92955":"code","b0c66de8":"code","543fca60":"code","4b3ebb22":"code","51e29f15":"code","5c16b36a":"code","a94b9347":"code","7ea8de37":"code","75f2ef53":"code","9a04fe4f":"code","631bdbc5":"code","a5a1bf96":"code","f4ddc1dc":"code","75246151":"code","2dcc3603":"code","26ef333f":"markdown","029c7d12":"markdown","269d36ab":"markdown","cf7f42ef":"markdown","c8c680ea":"markdown","0f5ca95c":"markdown","40a9b6bb":"markdown","fb902dfe":"markdown","9a732893":"markdown","9d2a2f39":"markdown","ab12a9be":"markdown","fda41119":"markdown","cd827f4c":"markdown","5916b708":"markdown","74a408ba":"markdown","6918476c":"markdown","bac4a7d8":"markdown","2928132e":"markdown","feaa8aa1":"markdown","5b1c4a92":"markdown","c8cdb992":"markdown","abfa32ac":"markdown","b7727edf":"markdown","f4b602da":"markdown","f22d5726":"markdown","def62999":"markdown","3fbea1cc":"markdown","951ae40c":"markdown","bab2a563":"markdown","3d27a0c2":"markdown","922bbfe7":"markdown","9af72051":"markdown","5fbe6aba":"markdown","5d487aa8":"markdown","577a4f76":"markdown","d395bf1a":"markdown","3ba72427":"markdown","846bb7c6":"markdown","83c1142f":"markdown","13777458":"markdown","bb7c17f3":"markdown","2edb638c":"markdown","22409ac6":"markdown","30e1f893":"markdown","d6d62b7f":"markdown","27dde48c":"markdown","2c300829":"markdown"},"source":{"cef4d92d":"# for visualization -------------------\n\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom matplotlib import rcParams\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport os # accessing directory structure\n\n# for data pipeline --------------------\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import*\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\n\n# for prediction (machine learning models) ------------------------\n\nfrom sklearn.linear_model import*\nfrom sklearn.preprocessing import*\nfrom sklearn.ensemble import*\nfrom sklearn.neighbors import*\nfrom sklearn import svm\nfrom sklearn.naive_bayes import*","53355041":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bd5c263f":"df=pd.read_csv('\/kaggle\/input\/home-sales-data-details-in-istanbul\/Home Sale Data.csv', delimiter=';')\ndf.head()","3bcbaed0":"#rename column names\ndf.columns=df.columns.str.replace(\" \",\"_\")\ndf.columns=df.columns.str.replace(\"(\",\"\")\ndf.columns=df.columns.str.replace(\")\",\"\").str.lower()\ndf.head()","a75077b3":"print('shape of the data :',df.shape)","18e17098":"print('total number of duplicate values : ',sum(df.duplicated()))","05832d44":"df=df.drop_duplicates()","91ce4a24":"df.info()","65d4fe3b":"objList = df.select_dtypes(include = \"object\").columns\nprint (objList)","54dd2fa1":"df[\"pick_up_data_time\"]=pd.to_datetime(df[\"pick_up_data_time\"])\ndf[\"adrtisement_date\"]=pd.to_datetime(df[\"adrtisement_date\"])","2397c883":"#Create year and month columns from advertisement date and remove unnecessary columns\ndf[\"adv_year\"]=df.adrtisement_date.dt.strftime('%Y').astype(float)\ndf[\"adv_month\"]=df.adrtisement_date.dt.strftime('%B')\ndf.drop(columns=[\"adrtisement_date\",\"pick_up_data_time\"],inplace=True)","5f3f6782":"# Price column has TL character\ndf[\"price\"]=df[\"price\"].str.replace(\"TL\",\"\")\ndf[\"price\"]=df[\"price\"].str.replace(\"\\s+\",\"\")\ndf[\"price\"]=df[\"price\"].str.replace(\".\",\"\").astype(float)\ndf.head()","b16e07e9":"objList = df.select_dtypes(include = \"object\").columns\nprint (objList)","170400a8":"df.groupby(\"neighborhood\").size().sort_values(ascending=False)\ndf.groupby(\"neighborhood\").size().describe()","4d39963a":"neighborhood=df.groupby(\"neighborhood\").size().sort_values(ascending=False).to_frame()\nneighborhood_biggerthan15=neighborhood[neighborhood[0]>15].index\n#Remove neighborhoods that has below 15 frequency\ndata = df[df.neighborhood.isin(neighborhood_biggerthan15)]","603d922c":"ax=data[\"number_of_rooms\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"number_of_rooms\")\nax.set_xlabel(\"number_of_rooms\")\nax.set_ylabel(\"Frequency\")","dbeeccf5":"data.groupby(\"number_of_rooms\").size().sort_values(ascending=False).to_frame()\ndata.groupby(\"number_of_rooms\").size().describe()","18a6c962":"#Remove neighborhoods that has below 150 frequency\nnumber_of_rooms=data.groupby(\"number_of_rooms\").size().sort_values(ascending=False).to_frame()\nnumber_of_rooms_biggerthan150=number_of_rooms[number_of_rooms[0]>150].index\ndata = data[data.number_of_rooms.isin(number_of_rooms_biggerthan150)]","76f3d4c4":"ax=data[\"floor_location\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"floor_location\")\nax.set_xlabel(\"floor_location\")\nax.set_ylabel(\"Frequency\")","7473aa79":"data.groupby(\"floor_location\").size().sort_values(ascending=False)\ndata.groupby(\"floor_location\").size().describe()","d2877baa":"list_change=['16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','30  and more than']\nfor x in list_change:\n    data.loc[(data.floor_location == x),'floor_location']=\"+15\"\ndata.groupby(\"floor_location\").size().sort_values(ascending=False)","001de729":"data.groupby(\"floor_location\").size().describe()","e7a89810":"#Remove floor_location that has below 200 frequency\nfloor_location=data.groupby(\"floor_location\").size().sort_values(ascending=False).to_frame()\n\nfloor_location_biggerthan200=floor_location[floor_location[0]>200].index\n\ndata = data[data.floor_location.isin(floor_location_biggerthan200)]","8e29b065":"ax=data[\"heating\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"heating\")\nax.set_xlabel(\"heating\")\nax.set_ylabel(\"Frequency\")","03961ff8":"data.groupby(\"heating\").size().sort_values(ascending=False)\ndata.groupby(\"heating\").size().describe()","9f50b579":"#Remove heating that has below 100 frequency\nheating=data.groupby(\"heating\").size().sort_values(ascending=False).to_frame()\n\nheating_biggerthan100=heating[heating[0]>100].index\n\ndata = data[data.heating.isin(heating_biggerthan100)]","b079d4c5":"ax=data[\"number_of_floors\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"number_of_floors\")\nax.set_xlabel(\"number_of_floors\")\nax.set_ylabel(\"Frequency\")","e8654ea1":"data.groupby(\"number_of_floors\").size().sort_values(ascending=False)\ndata.groupby(\"number_of_floors\").size().describe()","99b506a2":"list_change=['16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','30  and more than']\nfor x in list_change:\n    data.loc[(data.number_of_floors == x),'number_of_floors']=\"+15\"\ndata.groupby(\"number_of_floors\").size().sort_values(ascending=False)","98f34337":"#Remove number_of_floors that has below 200 frequency\nnumber_of_floors=data.groupby(\"number_of_floors\").size().sort_values(ascending=False).to_frame()\n\nnumber_of_floors_biggerthan200=number_of_floors[number_of_floors[0]>200].index\n\ndata = data[data.number_of_floors.isin(number_of_floors_biggerthan200)]","b5c0f528":"ax=data[\"number_of_bathrooms\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"number_of_bathrooms\")\nax.set_xlabel(\"number_of_bathrooms\")\nax.set_ylabel(\"Frequency\")","3122095f":"data.groupby(\"number_of_bathrooms\").size().sort_values(ascending=False)\ndata.groupby(\"number_of_bathrooms\").size().describe()","7ae6a34d":"#Remove number_of_bathrooms that has below 200 frequency\n\nnumber_of_bathrooms=data.groupby(\"number_of_bathrooms\").size().sort_values(ascending=False).to_frame()\n\nnumber_of_bathrooms_biggerthan200=number_of_bathrooms[number_of_bathrooms[0]>200].index\n\ndata = data[data.number_of_bathrooms.isin(number_of_bathrooms_biggerthan200)]","0c1e691a":"ax=data[\"balcony\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"balcony\")\nax.set_xlabel(\"balcony\")\nax.set_ylabel(\"Frequency\")","5fe53fb9":"data.groupby(\"balcony\").size().sort_values(ascending=False)","3f36198b":"#Replace unknown as available\ndata.loc[(data.balcony==\"Unknown\"),'balcony']='Available'\ndata.groupby(\"balcony\").size().sort_values(ascending=False)","be4ac3a8":"ax=data[\"furnished\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"furnished\")\nax.set_xlabel(\"furnished\")\nax.set_ylabel(\"Frequency\")","418dfe9a":"data.groupby(\"furnished\").size().sort_values(ascending=False)","95288edb":"#Replace unknown as No\ndata.loc[(data.furnished == \"Unknown\"),'furnished']=\"No\"\ndata.groupby(\"furnished\").size().sort_values(ascending=False)                                       ","881e0410":"ax=data[\"available_for_loan\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"available_for_loan\")\nax.set_xlabel(\"available_for_loan\")\nax.set_ylabel(\"Frequency\")","17c73bf3":"data.groupby(\"available_for_loan\").size().sort_values(ascending=False)","ee3f558e":"#Replace unknown as Yes\ndata.loc[(data.available_for_loan == \"Unknown\"),'available_for_loan']=\"Yes\"\ndata.groupby(\"available_for_loan\").size().sort_values(ascending=False)    ","0f85eb03":"ax=data[\"from_who\"].value_counts().plot(kind=\"bar\",figsize=(8,6),title=\"from_who\")\nax.set_xlabel(\"from_who\")\nax.set_ylabel(\"Frequency\")","c0906d91":"data.groupby(\"from_who\").size().sort_values(ascending=False)","7be8b5e2":"#Remove from_whos that has below 1000 frequency\nfrom_who=data.groupby(\"from_who\").size().sort_values(ascending=False).to_frame()\n\nfrom_who_biggerthan1000=from_who[from_who[0]>1000].index\n\ndata = data[data.from_who.isin(from_who_biggerthan1000)]","ace04db5":"data.describe()","07c6f251":"data.boxplot(\"m\u00b2_gross\")","6d1a6411":"#Remove outlier\ndata=data[data[\"m\u00b2_gross\"]!=9140.000000]","02ee9899":"data","475eea29":"objList2 = data.select_dtypes(include = \"object\").columns\nprint (objList2)","57d87a54":"data_new=pd.get_dummies(data,columns=objList2,drop_first=True)\ndata_new.columns","b6b88d89":"data_new","2748fa0d":"#Clean column names\ndata_new.columns = data_new.columns.str.replace('[^0-9a-zA-Z]+', '_').str.lower()","5a91c5c5":"data_new.info()","0e39072e":"data_new.describe()","febe177f":"data_new[data_new.isna().any(axis=1)]","e2a373a8":"data_new.isna().sum()","4e148064":"#impute the missing values, replace with m2 mean\ndata_manipulated=data_new.copy()\ndata_manipulated[\"m_net\"]=data_manipulated[\"m_net\"].fillna(data_new[\"m_net\"].mean())","9de5c815":"data_manipulated[data_manipulated.isna().any(axis=1)]","75e92955":"data_manipulated","b0c66de8":"X=data_manipulated.drop([\"price\"],axis=1)\ny=data_manipulated[\"price\"]","543fca60":"X_train,X_test,y_train, y_test=train_test_split(X,y,test_size=0.2, random_state=0)","4b3ebb22":"print('shape of X and y respectively(train) :',X_train.shape,y_train.shape)\nprint('shape of X and y respectively(test) :',X_test.shape,y_test.shape)","51e29f15":"cols=X_train.columns\ncols","5c16b36a":"r2_model_scores=[]\nr2_scores=[]","a94b9347":"mdl=LinearRegression()\n\nmdl.fit(X_train,y_train)\nypred= mdl.predict(X_test)\n\nlinear_r2=r2_score(y_test, ypred)\nr2_model_scores.append(linear_r2)\nprint('r2 :', linear_r2)","7ea8de37":"from sklearn.feature_selection import SelectKBest, f_regression\n\nr2_scores=[]\nn=X_train.shape[1]\n\nfor i in range(n):\n    mdl_select=SelectKBest(f_regression,k=i+1)\n    X_new=mdl_select.fit_transform(X_train,y_train)\n    X_new_test=mdl_select.transform(X_test)\n    \n    mdl=LinearRegression()\n    mdl.fit(X_new,y_train)\n    ypred=mdl.predict(X_new_test)\n    r2_scores.append(r2_score(y_test,ypred))\n    \nplt.plot(np.arange(1,n+1),r2_scores)\nplt.grid(True)\nplt.xlabel(\"num features\")\nplt.ylabel(\"r2 score\")\n\nf_regression_r2=np.max(r2_scores)\nr2_model_scores.append(f_regression_r2)\n\nprint(\"Optimal number of features:\",np.argmax(r2_scores))\nprint('r2 :', np.max(r2_scores))","75f2ef53":"from sklearn.feature_selection import RFE\n\nmdl=LinearRegression()\nmdl_rfe=RFE(estimator=mdl, n_features_to_select=1, step=1)\nmdl_rfe.fit(X_train,y_train)\nindexs=mdl_rfe.support_\nix=mdl_rfe.ranking_\n\nr2_scores=[]\nn=X_train.shape[1]\nfor i in range(n):\n    X_new=X_train.iloc[:,ix[:i+1]-1]\n    X_new_test=X_test.iloc[:,ix[:i+1]-1]\n    \n    mdl=LinearRegression()\n    mdl.fit(X_new,y_train)\n    ypred=mdl.predict(X_new_test)\n    r2_scores.append(r2_score(y_test,ypred))\n    \nplt.plot(np.arange(1,n+1),r2_scores)\nplt.grid(True)\nplt.xlabel(\"num features\")\nplt.ylabel(\"r2 score\")\n\nRFE_r2=np.max(r2_scores)\nr2_model_scores.append(RFE_r2)\n\nprint(\"Optimal number of features:\",np.argmax(r2_scores))\nprint('r2 :', np.max(r2_scores))","9a04fe4f":"from sklearn.feature_selection import mutual_info_regression\n\nmdl_f=mutual_info_regression(X_train,y_train)\nix=np.argsort(mdl_f)[::-1]\nr2_scores=[]\nn=X_train.shape[1]\n\nfor i in range(n):\n    X_new=X_train.iloc[:,ix[:i+1]]\n    X_new_test=X_test.iloc[:,ix[:i+1]]\n    \n    mdl=LinearRegression()\n    mdl.fit(X_new,y_train)\n    ypred=mdl.predict(X_new_test)\n    r2_scores.append(r2_score(y_test,ypred))\n    \nplt.plot(np.arange(1,n+1),r2_scores)\nplt.grid(True)\nplt.xlabel(\"num features\")\nplt.ylabel(\"r2 score\")\n\nmutual_info_regression_r2=np.max(r2_scores)\nr2_model_scores.append(mutual_info_regression_r2)\n\nprint(\"Optimal number of features:\",np.argmax(r2_scores))\nprint('r2 :', np.max(r2_scores))","631bdbc5":"from sklearn.feature_selection import SelectFromModel\n\nmdl=LinearRegression()\nmdl.fit(X_train,y_train)\n\nr2_scores = []\nn = X_train.shape[1]\n\nfor i in range(n):\n    mdl_sfm = SelectFromModel(mdl,max_features=i+1)\n    mdl_sfm.fit(X_train,y_train)\n    X_new = mdl_sfm.transform(X_train)\n    X_new_test = mdl_sfm.transform(X_test)\n\n    mdl = LinearRegression()\n    mdl.fit(X_new,y_train)\n    ypred = mdl.predict(X_new_test)\n    r2_scores.append(r2_score(y_test, ypred))\n    \nplt.plot(np.arange(1,n+1),r2_scores)\nplt.grid(True)\nplt.xlabel(\"num features\")\nplt.ylabel(\"r2 score\")\n\nSelectFromModel_r2=np.max(r2_scores)\nr2_model_scores.append(SelectFromModel_r2)\n\nprint(\"Optimal number of features:\",np.argmax(r2_scores))\nprint('r2 :', np.max(r2_scores))","a5a1bf96":"from sklearn.decomposition import PCA\n\nr2_scores = []\nn = X_train.shape[1]\n\nfor i in range(n):\n    mdl_pca = PCA(n_components=i+1)\n    mdl_pca.fit(X_train)\n    X_new = mdl_pca.transform(X_train)\n    X_new_test = mdl_pca.transform(X_test)\n\n    mdl = LinearRegression()\n    mdl.fit(X_new,y_train)\n    ypred = mdl.predict(X_new_test)\n    r2_scores.append(r2_score(y_test, ypred))\n    \nplt.plot(np.arange(1,n+1),r2_scores)\nplt.grid(True)\nplt.xlabel(\"num features\")\nplt.ylabel(\"r2 score\")\n\nPCA_R2=np.max(r2_scores)\nr2_model_scores.append(PCA_R2)\n\nprint(\"Optimal number of features:\",np.argmax(r2_scores))\nprint('r2 :', np.max(r2_scores))","f4ddc1dc":"from sklearn.ensemble import GradientBoostingRegressor\n\nmodel = GradientBoostingRegressor()\nmodel.fit(X_train,y_train)\n\nypred=model.predict(X_test)\ny_tr1=model.predict(X_train)\n\nGradientBoostingRegressor_r2=r2_score(y_test, ypred)\nmodel.score(X_test,y_test)\n\nr2_model_scores.append(GradientBoostingRegressor_r2)\n\nprint('r2 :',GradientBoostingRegressor_r2)","75246151":"from sklearn.ensemble import RandomForestRegressor\n\nmdl_select = SelectKBest(f_regression, k = 718)\nX_new = mdl_select.fit_transform(X_train,y_train)\nX_new_test = mdl_select.transform(X_test)\n\nmdl = RandomForestRegressor(random_state=0)\nmdl.fit(X_new,y_train)\ny_tr1=mdl.predict(X_new)\ny_pr=mdl.predict(X_new_test)\n\nr2_score_rfr=r2_score(y_test, y_pr)\nr2_model_scores.append(r2_score_rfr)\n\nprint('r2 :',r2_score_rfr)","2dcc3603":"models=['Linear','SelectKBest','RFE','Mutual_info','SelectFromModel','PCA','GradientBoost','RandomForest']\n#r2_model_scores=[linear_r2,f_regression_r2,RFE_r2,mutual_info_regression_r2,SelectFromModel_r2,PCA_R2,GradientBoostingRegressor_r2,r2_score_rfr]\n#plt.figure(dpi=150)\nfig, ax = plt.subplots(figsize=(15, 6))\nplt.grid(b=True,which='major',axis='both',linestyle='--',color='c')\n\nplt.title('Model R2 scores')\nplt.plot(models,r2_model_scores)\nplt.yticks(np.arange(0,1,0.05))\nplt.plot(r2_model_scores,marker='o',color=\"#1F4DB4\")\n\nfor i in range(len(r2_model_scores)):\n    plt.text(i, r2_model_scores[i] , str(round(r2_model_scores[i],5)),\n            horizontalalignment='center',\n            verticalalignment='bottom',\n            fontsize=8,\n            color = '#1F4DB4',\n            fontproperties=fm.FontProperties(weight=\"semibold\"))\n    \nplt.xticks(rotation = 30)\nplt.ylim(0,0.85)  \nplt.rc('font', family='monospace') \n\nplt.rc('font', style='normal') \nplt.rc('text', usetex='false') \n\nplt.rcParams.update({'font.size': 16})\nplt.show()","26ef333f":"# Train and validation data","029c7d12":"![1.png](attachment:1.png)","269d36ab":"![3.png](attachment:3.png)","cf7f42ef":"#### 1.Quantitative analysis for Neighborhood feature","c8c680ea":"#### -LinearRegression with Mutual Info Regression","0f5ca95c":"#### Categorical Features","40a9b6bb":"Now we can start the prediction.","fb902dfe":"#### - LinearRegression with SelectKBest, F_Regression","9a732893":"#### Random Forest Regressor","9d2a2f39":"#### LinearRegression without Feauture Selection Method","ab12a9be":"![Home%20Sales%20Picture.png](attachment:Home%20Sales%20Picture.png)","fda41119":"#### 3.Quantitative analysis for Floor Location feature","cd827f4c":"#### -LinearRegression with RFE","5916b708":"Identify categorical and numerical features, Identify duplicate rows, columns with missing values","74a408ba":"As we are predicting the price of the Houses we are going to put the prices column in the Y and rest of the data in X","6918476c":"# Descriptive Analytics","bac4a7d8":"Since residential real estate is a property with many different features, these properties are of great importance in determining the price. The absence of precise price determining rules in housing purchase and sale transactions causes serious price differences to occur even in the purchase and sale transactions of houses located in the same region. This situation increases the need for systems that will make price estimates according to the properties of the house.\n\nIn this dataset, the data of the houses offered for sale in Istanbul in July and October 2020 are presented. There are __34844__ records with a total of __179__ qualifications. This dataset can be used in house price estimation studies.","2928132e":"#### -LinearRegression with Select From Model","feaa8aa1":"# Data Visualization by Qlik Sense","5b1c4a92":"After model evaluation we can conclude that, high dimensional data can not be fit well in low dimensional models and can give abrupt conclusions that may led to lower accuracy.\n\nThe Random Forest uses leafs that can reduce the dimensional complexity and generalize the model in a better approach. Thus it presents the best accuracy over the data.","c8cdb992":"#### 9.Quantitative analysis for Available for Loan feature","abfa32ac":"# Data gathering and Primary visualization","b7727edf":"#### Find Missing Data","f4b602da":"#### Home Properties Analysis","f22d5726":"#### 6.Quantitative analysis for Number of Bathrooms feature","def62999":"#### 11.Quantitative analysis for m\u00b2_gross feature: Find Irregular Data (Outliers)","3fbea1cc":"#### 5.Quantitative analysis for Number of Floors feature","951ae40c":"At first we have to encode all the categorical columns to dig deep into the data","bab2a563":"So, after visualizing , we have found that ,\n\nModel performance :\n Random Forest > Gradient Boosting > PCA > SelectKbest > Mutual_info_regression > Linear Regression > RFE >SelectFromModel\n        ","3d27a0c2":"# Home Sales Data","922bbfe7":"If there is any duplicates we can remove them now.","9af72051":"# Data Cleaning and Preprocessing","5fbe6aba":"#### Feature Selection Methods","5d487aa8":"![2.png](attachment:2.png)","577a4f76":"# Model Evaluation & Conclusion","d395bf1a":"#### 2.Quantitative analysis for Number of Rooms feature","3ba72427":"#### Price&m2 Analysis","846bb7c6":"### LinearRegression with PCA","83c1142f":"# Pipelines","13777458":"#### Gradient Boosting Regressor","bb7c17f3":"As this is a regression problem we are going to use famous regression models -\n   1. LinearRegression without Feauture Selection Method\n   2. LinearRegression with SelectKBest, F_Regression\n   3. LinearRegression with RFE\n   4. LinearRegression with Mutual Info Regression\n   5. LinearRegression with Select From Model\n   6. LinearRegression with PCA\n   7. Gradient Boosting Regressor\n   8. Random Forest Regressor\n    ","2edb638c":"# Libraries","22409ac6":"#### 10.Quantitative analysis for From Who feature","30e1f893":"#### 7.Quantitative analysis for Balcony feature","d6d62b7f":"#### 8.Quantitative analysis for Furnished feature","27dde48c":"#### 4.Quantitative analysis for Heating feature","2c300829":"We created some dashboards to get initial insights from Home Sales Data.Our data contains lots of categorical features, so it is needed to monitor the distribution of those features."}}