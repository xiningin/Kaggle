{"cell_type":{"9c2f07af":"code","087b4010":"code","d5ace812":"code","e08ad567":"code","2e06cb2b":"code","a880addf":"code","7c08573c":"code","acd7a8b4":"code","4326ba79":"code","b5873458":"code","21574502":"code","cb7b8e1c":"code","d52784e8":"markdown","e088554b":"markdown","3c7a9621":"markdown","61615b24":"markdown","9b78a335":"markdown"},"source":{"9c2f07af":"import torch\nimport torchvision\nimport torchvision.transforms as T\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image","087b4010":"#VGG-19 pretrained model for image classification and freeze the gradients.\n\nmodel = torchvision.models.vgg19(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\n","d5ace812":"# Opening the image\nimg = Image.open('..\/input\/input-image\/input.jpg') \nimg","e08ad567":"\ndef preprocess(image, size=224):\n    transform = T.Compose([\n        T.Resize((size,size)),\n        T.ToTensor(),\n        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        T.Lambda(lambda x: x[None]),\n    ])\n    return transform(image)\n","2e06cb2b":"# preprocess the image using the function defined\nX = preprocess(img)\n\nprint('The shape of image Tensor after preprocess:',X.shape)","a880addf":"# Run the model in evaluation mode.\nmodel.eval()","7c08573c":"# need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\nX.requires_grad_()\n","acd7a8b4":"#forward pass the image tensor through the model to get the logit scores.\n\nlogits = model(X)\nprint('The logits scores:',logits)","4326ba79":"# the 1000 class scores of vgg19\nlogits.shape","b5873458":"# Get the index corresponding to the maximum score and the maximum score itself.\nlogits_max_index = logits.argmax()\nlogits_max = logits[0,logits_max_index]\nprint('The max score value index:',logits_max_index,'\\n')\nprint('The max score value:',logits_max)\n","21574502":"#backward function on logits_max performs the backward pass in the computation graph and calculates the gradient of \n#score_max with respect to nodes in the computation graph\n\nlogits_max.backward()","cb7b8e1c":"#Saliency would be the gradient with respect to the input image now. But note that the input image has 3 channels,\n#R, G and B. To derive a single class saliency value for each pixel (i, j),  we take the maximum magnitude\n#across all colour channels.\n\n\n\nsaliency_map, _ = torch.max(X.grad.data.abs(),dim=1)\nprint('The saliency_map Tensor:\\n',saliency_map,'\\n')\nprint('shape of saliency map:',saliency_map.shape,'\\n')\nprint ('The mean and max values of saliency map:',torch.mean(saliency_map),torch.max(saliency_map))\n\n# code to plot the saliency map as a heatmap\nplt.imshow(saliency_map[0], cmap=plt.cm.hot)\nplt.axis('off')\nplt.show()","d52784e8":"#  **Visualize saliency map of VGG19 pretrained model using simple gradient method**","e088554b":"# **Open an Image**","3c7a9621":"# **Import required Packages**","61615b24":"# **Load the VGG19 pretrained Model**","9b78a335":"# **Preprocessing function for input Image**"}}