{"cell_type":{"79e4d0cc":"code","68b95aba":"code","c419dde0":"code","705a696e":"code","d5ee340e":"code","7255c11b":"code","af197cef":"markdown","1aa5016e":"markdown","6cdf7fb3":"markdown","db712115":"markdown","c64a74c1":"markdown","9c32378a":"markdown","dd0b1503":"markdown"},"source":{"79e4d0cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport shutil\n\n# helpful character encoding module\nimport chardet\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","68b95aba":"titles = pd.read_csv(\"\/kaggle\/input\/character-encoding-examples\/file_guide.csv\")\ntitles","c419dde0":"encoding_array = []\nfor i in titles['File']:\n    src = '\/kaggle\/input\/character-encoding-examples\/' + str(i)\n    with open(src,'rb') as rawdata:\n        result = chardet.detect(rawdata.read())\n        encoding_array.append(result)\nprint(encoding_array)\n","705a696e":"\n# 'utf8-'+ titles['File'][0]\nfor i in range(0,len(titles['File'])):\n    src = '\/kaggle\/input\/character-encoding-examples\/' + str(titles['File'][i])\n    with open(src,'rb') as rawdata:\n        dest = 'utf8-' + str(titles['File'][i])\n        with open(dest,'wb') as file:\n            file.write(rawdata.read().decode(encoding_array[i]['encoding']).encode())\n\n# dst = \"\/kaggle\/working\/olaf_Utf8.txt\"\n# shutil.copyfile(src,dst)","d5ee340e":"path = r\"\/kaggle\/working\/\"\nencoded_file_names = []\nfor files in os.listdir(path):\n    if (os.path.isfile(os.path.join(path, files))) & (files.endswith('.txt')):\n        encoded_file_names.append(files)\nprint(encoded_file_names)\n","7255c11b":"array_encoded = []\nfor i in encoded_file_names:\n    src = path + i\n    with open(src,'rb') as rawdata:\n        result = chardet.detect(rawdata.read())\n        array_encoded.append(result)\nprint(array_encoded)","af197cef":"# This is my attempt at the character decoding challenge from the Data Cleaning course. \n\n## I am a learner at python so if anyone has any suggestions as to how I can reduce my code length, (constructive!) criticism regarding my approach, or advice on how better to face this problem, please let me know!","1aa5016e":"# 5. Assess whether the process has been successful","6cdf7fb3":"# 1. Read in metadata to obtain file names","db712115":"# 3. Create forloop to decode each document based on the estimated encoding from previous step and encode in utf8","c64a74c1":"# 2. Create array of encoding estimations using chardet","9c32378a":"# 4. Check directory to confirm ","dd0b1503":"# Encoding appears to have been successful in all cases except 'Harper's round table.'\n### Why is this?"}}