{"cell_type":{"128d6881":"code","758eb9ba":"code","9818cab6":"code","f7cfbb18":"code","fc9354cf":"code","0e0fa78a":"code","dd02b1d4":"code","70684850":"code","6507a5bf":"code","f380bf1f":"code","9c323868":"code","7d3e4b88":"code","4228fd68":"code","6d422866":"code","72cbca6a":"code","cffce3cd":"code","1b5d8cf1":"code","eef1cd72":"code","1bf6cbe5":"code","04bc92bd":"code","dca1254b":"markdown","326098d2":"markdown"},"source":{"128d6881":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","758eb9ba":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch\nimport keras_tuner\nimport warnings\nwarnings.filterwarnings('ignore')","9818cab6":"# Load the data\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")","f7cfbb18":"# Take out the sample\nsample_train = train.sample(frac = 0.1, random_state=100)\nsample_validation = train.sample(frac = 0.05, random_state=101)\nsample_test = train.sample(frac = 0.05, random_state=102)","fc9354cf":"# Split the data into features and target variable\n\nX_train = sample_train.drop(['id', 'target'], axis=1)\ny_train = sample_train['target']\n\nX_val = sample_validation.drop(['id', 'target'], axis=1)\ny_val = sample_validation['target']\n\nX_test = sample_test.drop(['id', 'target'], axis=1)\ny_test = sample_test['target']\n\n# Scale the data\n\nmms = MinMaxScaler()\nX_train_scaled = mms.fit_transform(X_train)\nX_val_scaled = mms.transform(X_val)\nX_test_scaled = mms.transform(X_test)","0e0fa78a":"# Setting up metrics and callbacks\nm = keras.metrics.AUC(curve='ROC')\nstop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)","dd02b1d4":"# Using KerasTuner to chose hyperparameters\ndef build_model(hp):\n    model = keras.Sequential()\n    # Adding 2 to 20 layers\n    for i in range(hp.Int('num_layers',2, 20)):\n        \n        # add hidden layers and neurons\n        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n                                           min_value=32, \n                                           max_value=512,\n                                           step=32),\n                              activation='relu'))\n\n    # Add the output layer\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    # Compile the model\n    model.compile(\n        optimizer=keras.optimizers.Adam(\n            hp.Choice('learning_rate', [1e-1, 1e-2, 1e-3, 1e-4])),\n            loss='binary_crossentropy',\n            metrics = [m])\n\n    return model","70684850":"tuner = RandomSearch(\n        build_model,\n        objective=keras_tuner.Objective(\"val_auc\", direction=\"max\"),\n        max_trials=5, \n        executions_per_trial=3,\n        directory='MyProject',\n        project_name='TPS_DL')","6507a5bf":"# Print the summary\ntuner.search_space_summary()","f380bf1f":"# Perform the search operation\ntuner.search(X_train_scaled, y_train, epochs=20, validation_data=(X_val_scaled, y_val), callbacks = [stop_early])","9c323868":"best_model = tuner.get_best_models(num_models=1)[0]","7d3e4b88":"best_model.evaluate(X_train_scaled, y_train)","4228fd68":"best_model.evaluate(X_val_scaled, y_val)","6d422866":"best_model.evaluate(X_test_scaled, y_test)","72cbca6a":"# Transform the data\nfinal_training = mms.transform(train.drop(['id', 'target'], axis=1))\ntarget_var = train['target']\n\n# fit the model\nbest_model.fit(final_training, target_var, epochs=20)","cffce3cd":"test_scaled = mms.transform(test.drop(['id'], axis=1))","1b5d8cf1":"predictions = np.round(best_model.predict(test_scaled)).astype('int')\nids = test.id","eef1cd72":"# Store the submissions in the dataframe\nsubmissions = pd.DataFrame(np.concatenate((ids.values.reshape(-1,1), predictions), axis=1), columns=['id', 'target'])","1bf6cbe5":"# Plot the predictions\nfigure, ax = plt.subplots(1, 2, figsize=(12,8))\nsns.countplot(data=submissions, x='target', ax = ax[0])\nax[0].set_title(\"Predictions\")\n\nsns.countplot(data=train, x='target', ax = ax[1])\nax[1].set_title(\"Actual\")\n\nfigure.show()","04bc92bd":"# Make Submissions\nsubmissions.to_csv('.\/.\/MyProject\/TPS_DL\/dl_submissions.csv', index=False)","dca1254b":"# Train the model on the entire data","326098d2":"# Make Submissions"}}