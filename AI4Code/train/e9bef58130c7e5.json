{"cell_type":{"de38b488":"code","5865c83c":"code","82db45dd":"code","75c12990":"code","46a8be7f":"code","595f9048":"code","72eef20d":"code","aea49783":"code","8c87578f":"code","be4fa620":"code","519e5528":"code","3123f2a5":"code","cfaeb853":"code","bf61c1a0":"code","f52733f6":"code","5fe6e4b3":"code","841930b9":"code","73d249de":"code","4d1c88f3":"code","46b80a03":"code","359f78ed":"code","419c4459":"code","06ab6500":"code","a9751b95":"code","6c9697b9":"code","e978a4ef":"code","bacc7de6":"markdown","51ceb5b9":"markdown","eb8c3194":"markdown","d1626d63":"markdown","dc8d3775":"markdown","373b0cc6":"markdown","cd0f6e64":"markdown","c215fc92":"markdown","a208e037":"markdown","de317989":"markdown"},"source":{"de38b488":"import sys\nsys.path.append('..\/input\/timmmaster\/')\nsys.path.append('..\/input\/tez-lib\/')","5865c83c":"import pandas as pd\nimport numpy as np\nimport glob\nimport os\nimport random\nimport cv2\nimport albumentations\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\n\nimport timm\nimport tez\nfrom tez.callbacks import EarlyStopping","82db45dd":"path = '..\/input\/food41\/'\ntrain_path= '..\/input\/food41\/images\/'\noutput_dir = '.\/'","75c12990":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https:\/\/wandb.ai\/authorize')","46a8be7f":"class CFG:\n    batch_size = 32\n    image_size = 224\n    epochs = 10\n    model_name = 'tf_efficientnet_b6_ns'\n    target_size = 101\n    target_col='target'\n    n_fold = 10\n    trn_fold = [0,1,2,3,4,5,6,7,8,9]\n    seed = 42","595f9048":"Config = dict(\n    nfolds = 5,\n    epochs = 5,\n    LR = 2e-4,\n    img_size = (224, 224),\n    model_name = 'tf_efficientnet_b6_ns',\n    target_size = 101,\n    batch_size = 32,\n    min_lr = 1e-6,\n    num_workers = 4,\n    infra = \"Kaggle\",\n    dataset= 'Food101',\n    wandb = False,\n    scheduler = 'ReduceROnPlateau',\n    optimizer = 'Adam'\n)","72eef20d":"run = wandb.init(project='Food101', \n                 config=Config,\n                 job_type='train',\n                 group='Models',\n                 anonymous='must')","aea49783":"file_pathAll = list(glob.glob(train_path+'\/**\/*.jpg'))\nlabels = list(map(lambda x :os.path.split(os.path.split(x)[0])[1], file_pathAll))\n\nfile_path = pd.Series(file_pathAll, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\ndata = pd.concat([file_path, labels], axis=1)\ndata = data.sample(frac=1).reset_index(drop=True)\n\nle = LabelEncoder()\nle.fit(data.Label)\ndata['target']=le.transform(data.Label)\n\ndata.head()","8c87578f":"data = data.sample(10100).reset_index(drop=True)","be4fa620":"fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(17,7),subplot_kw={'xticks':[],'yticks':[]})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(data.Filepath[i]))\n    ax.set_title(data.Label[i])\nplt.tight_layout()\nplt.show()","519e5528":"import imageio\nfrom tqdm import tqdm\nwidths = []\nheights = []\nratios = []\nfor file_path in tqdm(data['Filepath']):\n    image = imageio.imread(file_path)\n    h, w, _ = image.shape\n    heights.append(h)\n    widths.append(w)\n    ratios.append(w \/ h)","3123f2a5":"plt.figure(figsize=(15,6))\nplt.title(f'Images Height and Width Distribution', size=24)\nplt.hist(heights, bins=32, label='Image Heights')\nplt.hist(widths, bins=32, label='Image Widths')\nplt.legend(prop={'size': 16})\nplt.show()","cfaeb853":"data.Label.nunique()","bf61c1a0":"def create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n\n    kf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n    \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.Label.values)):\n        data.loc[v_, 'kfold'] = f\n\n    return data\n\ndf_5 = create_folds(data, num_splits=5)\ndf_5.to_csv(\"train_5folds.csv\", index=False)\n\ndf_10 = create_folds(data, num_splits=10)\ndf_10.to_csv(\"train_10folds.csv\", index=False)","f52733f6":"df_10['kfold'].value_counts()","5fe6e4b3":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)\n\ndef init_logger(log_file=output_dir+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()","841930b9":"def generate_transforms():\n\n    train_aug = albumentations.Compose(\n        [\n            albumentations.RandomResizedCrop(CFG.image_size, CFG.image_size, p=1),\n            albumentations.HorizontalFlip(p = 0.5),\n            albumentations.VerticalFlip(p = 0.5),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0,\n            ),\n        ],\n        p=1.0,\n    )\n\n    valid_aug = albumentations.Compose(\n        [\n            albumentations.Resize(CFG.image_size, CFG.image_size, p=1),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0,\n            ),\n        ],\n        p=1.0,\n    )\n    return {\"train_transforms\": train_aug, \"valid_transforms\": valid_aug}","73d249de":"class FoodDataset():\n    \n    def __init__(self, image_paths , targets, augmentation = None):\n        \n        self.image_paths = image_paths \n        self.targets = targets\n        self.augmentation = augmentation\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        \n        image = cv2.imread(self.image_paths[item])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        targets = self.targets[item]\n        \n        if self.augmentation is not None:\n            augmented = self.augmentation(image = image)\n            image = augmented['image']\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        return {\n            'image':torch.tensor(image, dtype=torch.float),\n            'targets':torch.tensor(targets, dtype=torch.long)\n        }","4d1c88f3":"dfx = pd.read_csv(\".\/train_10folds.csv\")\ndf_train = dfx[dfx.kfold != 0].reset_index(drop=True)\ndf_valid = dfx[dfx.kfold == 0].reset_index(drop=True)\n\n\ntrain_image_paths = df_train.Filepath.values\nvalid_image_paths = df_valid.Filepath.values\ntrain_targets = df_train.target.values\nvalid_targets = df_valid.target.values\n\ntrain_dataset = FoodDataset(\n    image_paths=train_image_paths,\n    targets=train_targets,\n    augmentation=generate_transforms()[\"train_transforms\"],\n)\n\nvalid_dataset = FoodDataset(\n    image_paths=valid_image_paths,\n    targets=valid_targets,\n    augmentation=generate_transforms()[\"valid_transforms\"],\n)","46b80a03":"i = 20\ninp=np.array(train_dataset[i]['image'])\ninp=inp.transpose((1, 2, 0))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ninp = std * inp + mean\nplt.figure(figsize=(8,4))\nplt.title(train_dataset[i]['targets'])\nplt.imshow(inp,aspect=1)","359f78ed":"import numpy as np\nfrom tez import enums\nfrom tez.callbacks import Callback\n\n\nclass EarlyStopping(Callback):\n    def __init__(self, monitor, model_path, patience=5, mode=\"min\", delta=0.001, save_weights_only=False):\n        self.monitor = monitor\n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        self.save_weights_only = save_weights_only\n        self.model_path = model_path\n        if self.mode == \"min\":\n            self.val_score = np.Inf\n        else:\n            self.val_score = -np.Inf\n\n        if self.monitor.startswith(\"train_\"):\n            self.model_state = \"train\"\n            self.monitor_value = self.monitor[len(\"train_\") :]\n        elif self.monitor.startswith(\"valid_\"):\n            self.model_state = \"valid\"\n            self.monitor_value = self.monitor[len(\"valid_\") :]\n        else:\n            raise Exception(\"monitor must start with train_ or valid_\")\n\n    def on_epoch_end(self, model):\n        epoch_score = model.metrics[self.model_state][self.monitor_value]\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n        else:\n            score = np.copy(epoch_score)\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(\"EarlyStopping counter: {} out of {}\".format(self.counter, self.patience))\n            if self.counter >= self.patience:\n                model.model_state = enums.ModelState.END\n        else:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model)\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model):\n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            print(\"Validation score improved ({} --> {}). Saving model!\".format(self.val_score, epoch_score))\n            model.save(self.model_path, weights_only=self.save_weights_only)\n        self.val_score = epoch_score\n        wandb.log({\"Valid RMSE\":self.val_score})","419c4459":"import warnings\n\nimport psutil\nimport torch\nimport torch.nn as nn\nfrom tez import enums\nfrom tez.callbacks import CallbackRunner\nfrom tez.utils import AverageMeter\nfrom tqdm import tqdm\nimport time\n\nclass FoodModel(tez.Model):\n    def __init__(self, pretrained = True):\n        super().__init__()\n        self.model = timm.create_model(model_name = CFG.model_name, pretrained = pretrained)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, CFG.target_size)\n        \n        self.step_scheduler_after = \"epoch\"\n        self.step_scheduler_metric = \"valid_accuracy\"\n        \n    def monitor_metrics(self, outputs, targets):\n        if targets is None:\n            return {}\n        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        accuracy = metrics.accuracy_score(targets, outputs)\n        return {\"accuracy\": accuracy}\n    \n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-4, weight_decay = 1e-6)\n        return opt\n    \n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode = 'min', factor = 0.2,patience = 5, eps =1e-6, verbose = True)\n        return sch\n\n    def forward(self, image, targets=None):\n        batch_size, _, _, _ = image.shape\n\n        outputs = self.model(image)\n        \n        if targets is not None:\n            loss = nn.CrossEntropyLoss()(outputs, targets)\n            metrics = self.monitor_metrics(outputs, targets)\n            return outputs, loss, metrics\n        return outputs, None, None\n    \n    def fit(\n        self,\n        train_dataset,\n        valid_dataset=None,\n        train_sampler=None,\n        valid_sampler=None,\n        device=\"cuda\",\n        epochs=10,\n        train_bs=16,\n        valid_bs=16,\n        n_jobs=8,\n        callbacks=None,\n        fp16=False,\n        train_collate_fn=None,\n        valid_collate_fn=None,\n        train_shuffle=False,\n        valid_shuffle=False,\n        accumulation_steps=1,\n        clip_grad_norm=None,\n    ):\n        \"\"\"\n        The model fit function. Heavily inspired by tf\/keras, this function is the core of Tez and this is the only\n        function you need to train your models.\n\n        \"\"\"\n        if device == \"tpu\":\n            if XLA_AVAILABLE is False:\n                raise RuntimeError(\"XLA is not available. Please install pytorch_xla\")\n            else:\n                self.using_tpu = True\n                fp16 = False\n                device = xm.xla_device()\n        self._init_model(\n            device=device,\n            train_dataset=train_dataset,\n            valid_dataset=valid_dataset,\n            train_sampler=train_sampler,\n            valid_sampler=valid_sampler,\n            train_bs=train_bs,\n            valid_bs=valid_bs,\n            n_jobs=n_jobs,\n            callbacks=callbacks,\n            fp16=fp16,\n            train_collate_fn=train_collate_fn,\n            valid_collate_fn=valid_collate_fn,\n            train_shuffle=train_shuffle,\n            valid_shuffle=valid_shuffle,\n            accumulation_steps=accumulation_steps,\n            clip_grad_norm=clip_grad_norm,\n        )\n\n        for epoch in range(epochs):\n            start_time = time.time()\n            self.train_state = enums.TrainingState.EPOCH_START\n            self.train_state = enums.TrainingState.TRAIN_EPOCH_START\n            train_loss = self.train_one_epoch(self.train_loader)\n            self.train_state = enums.TrainingState.TRAIN_EPOCH_END\n            if self.valid_loader:\n                self.train_state = enums.TrainingState.VALID_EPOCH_START\n                valid_loss = self.validate_one_epoch(self.valid_loader)\n                self.train_state = enums.TrainingState.VALID_EPOCH_END\n            \n            elapsed = time.time() - start_time\n            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_loss:.4f}  avg_val_loss: {valid_loss:.4f} time: {elapsed:.0f}s')\n            wandb.log({\"Train Loss\": train_loss})\n            wandb.log({\"Valid Loss\": valid_loss})\n        \n            if self.scheduler:\n                if self.step_scheduler_after == \"epoch\":\n                    if self.step_scheduler_metric is None:\n                        self.scheduler.step()\n                    else:\n                        step_metric = self.name_to_metric(self.step_scheduler_metric)\n                        self.scheduler.step(step_metric)\n            self.train_state = enums.TrainingState.EPOCH_END\n            if self._model_state.value == \"end\":\n                break\n            self.current_epoch += 1\n        self.train_state = enums.TrainingState.TRAIN_END","06ab6500":"def predict(valid_dataset,fold):\n    model = FoodModel(pretrained = False)\n    model.load(output_dir+f'{CFG.model_name}_fold{fold}_best.bin', device=\"cuda\", weights_only=True)\n    preds = model.predict(valid_dataset, batch_size=2*CFG.batch_size )\n    \n    temp_preds = None\n    for p in preds:\n        if temp_preds is None:\n            temp_preds = p\n        else:\n            temp_preds = np.vstack((temp_preds, p))\n    return temp_preds.argmax(axis=1)","a9751b95":"def train(fold):\n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n    \n    dfx = pd.read_csv(\".\/train_5folds.csv\")\n    df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n\n    train_image_paths = df_train.Filepath.values\n    valid_image_paths = df_valid.Filepath.values\n    train_targets = df_train.target.values\n    valid_targets = df_valid.target.values\n\n    train_dataset = FoodDataset(\n        image_paths=train_image_paths,\n        targets=train_targets,\n        augmentation=generate_transforms()[\"train_transforms\"],\n    )\n\n    valid_dataset = FoodDataset(\n        image_paths=valid_image_paths,\n        targets=valid_targets,\n        augmentation=generate_transforms()[\"valid_transforms\"],\n    )\n    \n    model = FoodModel()\n    es = EarlyStopping(\n        monitor=\"valid_accuracy\", \n        model_path=output_dir+f'{CFG.model_name}_fold{fold}_best.bin', \n        patience=2, \n        mode=\"max\",\n        save_weights_only=True\n    )\n    wandb.watch(model)\n    model.fit(\n        train_dataset,\n        valid_dataset=valid_dataset,\n        train_bs=CFG.batch_size,\n        valid_bs=2*CFG.batch_size,\n        device=\"cuda\",\n        epochs=CFG.epochs,\n        callbacks=[es],\n    )\n    wandb.save(output_dir+f'{CFG.model_name}_fold{fold}_best.bin')\n    df_valid['preds'] = predict(valid_dataset, fold)\n    return df_valid","6c9697b9":"def get_score(y_true, y_pred):\n        score = metrics.accuracy_score(y_true, y_pred) \n        return score\n\ndef get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n        wandb.log({\"OOF RMSE\":score})\n\noof_df = pd.DataFrame()\nfor fold in range(CFG.n_fold):\n    _oof_df = train(fold)\n    oof_df = pd.concat([oof_df, _oof_df])\n    LOGGER.info(f\"========== fold: {fold} result ==========\")\n    score = get_result(_oof_df)\n\n# CV result\nLOGGER.info(f\"========== CV ==========\")\nget_result(oof_df)\n# save result\noof_df.to_csv(output_dir+'oof_df.csv', index=False)","e978a4ef":"run.finish()","bacc7de6":"### Augmentation","51ceb5b9":"### Define Model","eb8c3194":"### Predict","d1626d63":"### Config Class","dc8d3775":"### Login on W&B","373b0cc6":"### Display Some Images","cd0f6e64":"### Create Pytorch DataLoader","c215fc92":"### Create Folds","a208e037":"### Load Dataset","de317989":"### Utills"}}