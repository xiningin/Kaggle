{"cell_type":{"0d9c6a71":"code","c8ccbf2f":"code","ab31cadc":"code","6fd76303":"code","b320a6e6":"code","a8daa548":"code","4ad49d14":"code","4bbbf5ad":"code","c4abdede":"code","93dbeecb":"code","bc407cda":"code","805c25f6":"code","e0acd297":"code","908381f6":"code","e7d83709":"code","6a0c314d":"code","f86c0874":"code","3a26416e":"code","8354707a":"markdown","9d82b258":"markdown","2f9e5535":"markdown","004b88d2":"markdown"},"source":{"0d9c6a71":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nfrom torch.utils.data.dataset import Subset\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","c8ccbf2f":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","ab31cadc":"def display_examples(data_loader,img_size):\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(11,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size),\n                      cmap=pl.cm.bone)\n        break","6fd76303":"def model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()\/num_examples*100\n@register_line_magic\ndef print_acc(n):\n    if int(n)==1:\n        data_loader=\\\n        [train_loader,valid_loader,test_loader]\n    if int(n)==2:\n        data_loader=\\\n        [train_loader2,valid_loader2,test_loader2]\n    print('Train accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[0])))\n    print('Valid accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[1])))\n    print('Test accuracy: %.4f%%'%\\\n    (model_acc(model,data_loader[2])))","b320a6e6":"random_seed=12; batch_size=128\ntr0=(.5); tr1=(.25); img_size=28\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor(),\n          transforms.Normalize(tr0,tr1)])\ntrain_ids=torch.arange(0,54000)\nvalid_ids=torch.arange(54000,60000)\ntrain_valid=tmnist(root='data',train=True,\n                   download=True,transform=trans)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tmnist(root='data',train=False, \n            transform=trans)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\nvalid_loader=tdl(dataset=valid,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","a8daa548":"display_examples(valid_loader,img_size)","4ad49d14":"fpath='..\/input\/classification-of-handwritten-letters\/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=1-np.array(f[keys[1]],dtype='float32')\/255\nx=timage.resize(x,[img_size,img_size])\nx=(np.dot(x.numpy(),[.299,.587,.114]))\\\n.reshape(-1,1,img_size,img_size)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\nrandom_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,shuffle=True,\n                  batch_size=batch_size2)\nvalid_loader2=tdl(dataset=valid2,shuffle=True,\n                  batch_size=batch_size2)\ntest_loader2=tdl(dataset=test2,shuffle=False,\n                 batch_size=batch_size2)","4bbbf5ad":"display_examples(valid_loader2,img_size)","c4abdede":"def conv3x3(in_planes,out_planes,stride=1):\n    return tnn.Conv2d(in_planes,out_planes,\n                      kernel_size=3,stride=stride,\n                      padding=1,bias=False)\nclass BasicBlock(tnn.Module):\n    expansion=1\n    def __init__(self,inplanes,planes,\n                 stride=1,downsample=None):\n        super(BasicBlock,self).__init__()\n        self.conv1=conv3x3(inplanes,planes,stride)\n        self.bn1=tnn.BatchNorm2d(planes)\n        self.relu=tnn.ReLU(inplace=True)\n        self.conv2=conv3x3(planes,planes)\n        self.bn2=tnn.BatchNorm2d(planes)\n        self.downsample=downsample\n        self.stride=stride\n    def forward(self,x):\n        residual=x\n        y=self.conv1(x); y=self.bn1(y)\n        y=self.relu(y)\n        y=self.conv2(y); y=self.bn2(y)\n        if self.downsample is not None:\n            residual=self.downsample(x)\n        y+=residual\n        y=self.relu(y)\n        return y","93dbeecb":"class ResNet(tnn.Module):\n    def __init__(self,block,layers,num_classes,grayscale):\n        self.inplanes=64\n        if grayscale: in_dim=1\n        else: in_dim=3\n        super(ResNet,self).__init__()\n        self.conv1=tnn\\\n        .Conv2d(in_dim,64,kernel_size=7,stride=2,\n                padding=3,bias=False)\n        self.bn1=tnn.BatchNorm2d(64)\n        self.relu=tnn.ReLU(inplace=True)\n        self.maxpool=tnn\\\n        .MaxPool2d(kernel_size=3,stride=2,padding=1)\n        self.layer1=self._make_layer(block,64,layers[0])\n        self.layer2=self._make_layer(block,128,\n                                     layers[1],stride=2)\n        self.layer3=self._make_layer(block,256,\n                                     layers[2],stride=2)\n        self.layer4=self._make_layer(block,512,\n                                     layers[3],stride=2)\n        self.avgpool=tnn.AvgPool2d(7,stride=1)\n        self.fc=tnn.Linear(512*block.expansion,num_classes)\n        for m in self.modules():\n            if isinstance(m,tnn.Conv2d):\n                n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n                m.weight.data.normal_(0,(2.\/n)**.5)\n            elif isinstance(m,tnn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n    def _make_layer(self,block,planes,blocks,stride=1):\n        downsample=None\n        if stride!=1 or self.inplanes!=planes*block.expansion:\n            downsample=tnn.Sequential(\n                tnn.Conv2d(self.inplanes,planes*block.expansion,\n                           kernel_size=1,stride=stride,bias=False),\n                tnn.BatchNorm2d(planes*block.expansion))\n        layers=[]\n        layers.append(block(self.inplanes,planes,\n                            stride,downsample))\n        self.inplanes=planes*block.expansion\n        for i in range(1,blocks):\n            layers.append(block(self.inplanes,planes))\n        return tnn.Sequential(*layers)\n    def forward(self,x):\n        x=self.conv1(x); x=self.bn1(x)\n        x=self.relu(x); x=self.maxpool(x)\n        x=self.layer1(x)\n        x=self.layer2(x)\n        x=self.layer3(x)\n        x=self.layer4(x)\n#        x=self.avgpool(x)        \n        x=x.view(x.size(0),-1)\n        logits=self.fc(x)\n        probs=tnnf.softmax(logits,dim=1)\n        return logits,probs\ndef ResNN(num_classes):\n    model=ResNet(block=BasicBlock,layers=[2,2,2,2],\n                num_classes=num_classes,\n                grayscale=True)\n    return model","bc407cda":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%200:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)\/\/batch_size,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader),\n                   model_acc(model,valid_loader)))","805c25f6":"torch.manual_seed(random_seed)\nnum_classes=10; learning_rate=.001\nmodel=ResNN(num_classes)\nmodel.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","e0acd297":"%train_run 55","908381f6":"%print_acc 1","e7d83709":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev); targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnn.functional.cross_entropy(logits,targets.long())\n            optimizer2.zero_grad(); cost.backward()\n            optimizer2.step()\n            if not batch_ids%50:\n                print ('Epoch: %03d\/%03d | Batch %03d\/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)\/\/batch_size2,cost))\n        model.eval()         \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d\/%03d train acc: %.2f%% valid acc: %.2f%%'%\\\n                  (epoch+1,epochs,\n                   model_acc(model,train_loader2),\n                   model_acc(model,valid_loader2)))","6a0c314d":"torch.manual_seed(random_seed)\nnum_classes=33; learning_rate=.001\nmodel=ResNN(num_classes)\nmodel.to(dev)\noptimizer2=torch.optim.Adam(model.parameters(),\n                            lr=learning_rate)","f86c0874":"%train_run2 50","3a26416e":"%print_acc 2","8354707a":"## Training","9d82b258":"Reading classics [Deep Learning Models](https:\/\/nbviewer.jupyter.org\/github\/rasbt\/deeplearning-models\/blob\/master\/pytorch_ipynb\/cnn\/cnn-resnet18-mnist.ipynb)\n\n## Code Modules, Classes, & Functions\n\n[GoogleColaboratory Variant](https:\/\/colab.research.google.com\/drive\/1OBmekkzdgivSLrJq_6HTtHZKc5ZNXbqX)","2f9e5535":"## ResNet","004b88d2":"## Data"}}