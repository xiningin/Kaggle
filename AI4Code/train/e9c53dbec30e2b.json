{"cell_type":{"6af0d1d1":"code","77689237":"code","f1508aad":"code","47278ef7":"code","9bce5bb6":"code","09b6acbe":"code","b5cec1c6":"code","d760a01b":"code","0a755723":"code","49141a2d":"code","61ceaf87":"code","61383021":"code","7e871925":"code","adde83e7":"code","2a2b59a2":"code","b0529f4b":"code","55e22b7a":"code","0a69ccc1":"code","6f4fe75c":"markdown","f8d802e7":"markdown","5be4781f":"markdown","dd2613f2":"markdown"},"source":{"6af0d1d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","77689237":"import matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nsns.set()\n\nfrom scipy import stats\nstats.chisqprob = lambda chisq, df:stats.chi12.sf(chisq,df)","f1508aad":"raw_data = pd.read_csv('..\/input\/logistic-regression-heart-disease-prediction\/framingham_heart_disease.csv')\nraw_data.describe(include = 'all')","47278ef7":"raw_data.isnull().sum()","9bce5bb6":"data_no_mv = raw_data.dropna(axis=0)","09b6acbe":"data_no_mv.isnull().sum()","b5cec1c6":"data = data_no_mv.drop(['education'], axis = 1)\ndata","d760a01b":"y = data['TenYearCHD']\nx1 = data.drop(['TenYearCHD'], axis = 1)","0a755723":"x = sm.add_constant(x1)\nreg_log = sm.Logit(y,x)\nresults_log = reg_log.fit()\nresults_log.summary()","49141a2d":"data_cleaned = x.copy()\ndata_cleaned = data_cleaned.drop(['BPMeds'], axis = 1)","61ceaf87":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train, y_test = train_test_split(data_cleaned, y, test_size=0.2, random_state = 365)","61383021":"x_cleaned = x_train\nx_new = sm.add_constant(x_cleaned)\nreg_log = sm.Logit(y_train,x_new)\nresults_log = reg_log.fit()\nresults_log.summary()","7e871925":"def confusion_matrix(data,actual_values,model):\n        \n        # Confusion matrix \n        \n        # Parameters\n        # ----------\n        # data: data frame or array\n            # data is a data frame formatted in the same way as your input data (without the actual values)\n            # e.g. const, var1, var2, etc. Order is very important!\n        # actual_values: data frame or array\n            # These are the actual values from the test_data\n            # In the case of a logistic regression, it should be a single column with 0s and 1s\n            \n        # model: a LogitResults object\n            # this is the variable where you have the fitted model \n            # e.g. results_log in this course\n        # ----------\n\n        #Predict the values using the Logit model\n        pred_values = model.predict(data)\n        # Specify the bins \n        bins=np.array([0,0.5,1])\n        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n        # if they are between 0.5 and 1, they will be considered 1\n        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n        # Calculate the accuracy\n        accuracy = (cm[0,0]+cm[1,1])\/cm.sum()\n        # Return the confusion matrix and\n        string = 'Accuracy is ' + repr(accuracy*100)+' %'\n        return cm, string","adde83e7":"confusion_matrix(x_new,y_train,results_log)","2a2b59a2":"x_test1 = x_test\nreg_log = sm.Logit(y_test,x_test)\nresults_log1 = reg_log.fit()\nresults_log1.summary()","b0529f4b":"def confusion_matrix(data,actual_values,model):\n        \n        # Confusion matrix \n        \n        # Parameters\n        # ----------\n        # data: data frame or array\n            # data is a data frame formatted in the same way as your input data (without the actual values)\n            # e.g. const, var1, var2, etc. Order is very important!\n        # actual_values: data frame or array\n            # These are the actual values from the test_data\n            # In the case of a logistic regression, it should be a single column with 0s and 1s\n            \n        # model: a LogitResults object\n            # this is the variable where you have the fitted model \n            # e.g. results_log in this course\n        # ----------\n\n        #Predict the values using the Logit model\n        pred_values = model.predict(data)\n        # Specify the bins \n        bins=np.array([0,0.5,1])\n        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n        # if they are between 0.5 and 1, they will be considered 1\n        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n        # Calculate the accuracy\n        accuracy = (cm[0,0]+cm[1,1])\/cm.sum()\n        # Return the confusion matrix and\n        string = 'Accuracy is ' + repr(accuracy*100)+' %'\n        return cm, string","55e22b7a":"confusion_matrix(x_new,y_train,results_log)","0a69ccc1":"cm_df = pd.DataFrame(results_log.pred_table())\ncm_df.columns = ['Predicted 0','Predicted 1']\ncm_df = cm_df.rename(index={0:'Actual 0',1:'Actual 1'})\ncm_df","6f4fe75c":"## Testing Model","f8d802e7":"## Hence, the model produced an accurate prediction 2496 times out of 2924 times resulting in,\n# Accuracy = 85.36%","5be4781f":"## Creating the Regression","dd2613f2":"## Defining Features and Targets"}}