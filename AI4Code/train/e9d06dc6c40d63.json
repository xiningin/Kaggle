{"cell_type":{"134ead34":"code","124ede0c":"code","3e99fadb":"code","38f4f64f":"code","146057bd":"code","dbe1b34d":"code","ad7cad19":"code","d889a816":"code","df707b12":"code","db9502a4":"code","f64f4306":"code","e0d3e15c":"code","57a1d54d":"code","6a30e2c3":"code","b5be67e8":"code","24741d9a":"code","02a16c9e":"code","ac7b062a":"code","53ac6e64":"code","1d674ae2":"code","851d2156":"code","b483fc37":"code","14a37e65":"code","f230bf73":"code","f0286c77":"markdown"},"source":{"134ead34":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns \nsns.set()\nfrom scipy import misc\nimport imageio as im\nimport os\nimport warnings\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport itertools\nwarnings.filterwarnings('ignore')\n%config InlineBackend.figure_format = 'retina'","124ede0c":"path = \"\/kaggle\/input\/shapes\/shapes\/\"\nos.chdir(path)\nos.getcwd()","3e99fadb":"img = im.imread('circles\/drawing(1).png')\nplt.imshow(img, cmap='gray')","38f4f64f":"def make_labels(directory, data=[], y_hat=[], label=0):\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            img = im.imread(directory+file)\n            data.append(img)\n        y_hat = [label] * len(data)\n    return np.array(data), np.array(y_hat)","146057bd":"circles, y_circles = [], []\ncircles, y_circles = make_labels('circles\/', data=circles, y_hat=y_circles)\n\nsquares, y_squares = [], []\nsquares, y_squares = make_labels('squares\/', data=squares, y_hat=y_squares, label=1)\n\ntriangles, y_triangles = [], []\ntriangles, y_triangles = make_labels('triangles\/', data=triangles, y_hat=y_triangles, label=2)","dbe1b34d":"print(circles.shape, squares.shape, triangles.shape)\nprint(y_circles.shape, y_squares.shape, y_triangles.shape)","ad7cad19":"X, y = np.vstack((circles, squares, triangles)), np.hstack((y_circles, y_squares, y_triangles)).reshape(-1, 1)","d889a816":"X.shape, y.shape","df707b12":"import tensorflow as tf\n\nconfig = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \nsess = tf.Session(config=config) ","db9502a4":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n \n# AlexNet-like\ndef createModel(input_shape, nclasses):\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n \n    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n \n    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n \n    model.add(Flatten())\n    model.add(Dense(512, activation='relu')) # we can drop \n    model.add(Dropout(0.5))                  # this layers\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(nclasses, activation='softmax'))\n         \n    return model","f64f4306":"model = createModel(img.shape, nclasses=3)\nmodel_gen = createModel(img.shape, nclasses=3)\nmodel.summary()","e0d3e15c":"from sklearn.preprocessing import OneHotEncoder\n\noh = OneHotEncoder()\noh.fit(y)\ny_hot = oh.transform(y)\n\nfrom keras.utils.np_utils import to_categorical\n\ny_cat = to_categorical(y)","57a1d54d":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_hot, test_size=.2, random_state=42)\nx_train, x_test, y_cat_train, y_cat_test = train_test_split(X, y_cat, test_size=.2, random_state=42)","6a30e2c3":"%%time\nbatch_size = 40\nepochs = 60\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_gen.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n \nhistory = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n                   validation_data=(X_test, y_test))\n","b5be67e8":"scores = model.evaluate(X_test, y_test)\nprint(f'Logloss = {scores[0]: .5f} \\nAccuracy = {scores[1]: .2f}')","24741d9a":"from keras.preprocessing.image import ImageDataGenerator\n\n# we can use image augmentation\n# basically it needs to redifine for normal actual scores like 0.9 of accuracy and more\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=12,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=False)","02a16c9e":"datagen.fit(x_train)","ac7b062a":"%%time\nepochs=120\nhistory_generator = model_gen.fit_generator(datagen.flow(x_train, y_cat_train, batch_size=batch_size),\n                    epochs=epochs, \n                    validation_data=(x_test, y_cat_test))","53ac6e64":"scores = model_gen.evaluate(x_test, y_cat_test)\nprint(f'Logloss = {scores[0]: .5f} \\nAccuracy = {scores[1]: .2f}')","1d674ae2":"# https:\/\/www.kaggle.com\/danbrice\/keras-plot-history-full-report-and-grid-search\ndef plot_history(history):\n    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n    \n    if len(loss_list) == 0:\n        print('Loss is missing in history')\n        return \n    \n    ## As loss always exists\n    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n    \n    ## Loss\n    plt.figure(1)\n    for l in loss_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    for l in val_loss_list:\n        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    \n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    ## Accuracy\n    plt.figure(2)\n    for l in acc_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n    for l in val_acc_list:    \n        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n    \ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        title='Normalized confusion matrix'\n    else:\n        title='Confusion matrix'\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    \n## multiclass or binary report\n## If binary (sigmoid output), set binary parameter to True\ndef full_multiclass_report(model,\n                           x,\n                           y_true,\n                           classes,\n                           batch_size=32,\n                           binary=False):\n\n    # 1. Transform one-hot encoded y_true into their class number\n    if not binary:\n        y_true = np.argmax(y_true,axis=1)\n    \n    # 2. Predict classes and stores in y_pred\n    y_pred = model.predict_classes(x, batch_size=batch_size)\n    \n    # 3. Print accuracy score\n    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n    \n    print(\"\")\n    \n    # 4. Print classification report\n    print(\"Classification Report\")\n    print(classification_report(y_true,y_pred,digits=5))    \n    \n    # 5. Plot confusion matrix\n    cnf_matrix = confusion_matrix(y_true,y_pred)\n    print(cnf_matrix)\n    plot_confusion_matrix(cnf_matrix,classes=classes)","851d2156":"plot_history(history)","b483fc37":"full_multiclass_report(model,\n                       X_test,\n                       y_test,\n                       ['circles', 'squares', 'triangles'])","14a37e65":"plot_history(history_generator)","f230bf73":"full_multiclass_report(model_gen,\n                       X_test,\n                       y_test,\n                       ['circles', 'squares', 'triangles'])","f0286c77":"### N.B. : this is due to the wrong settings in the datagenerator"}}