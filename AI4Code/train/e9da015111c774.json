{"cell_type":{"5bba3816":"code","ce8cbab8":"code","6f93be95":"code","a89961fe":"code","e03a9ccd":"code","ffcc3b03":"code","fb817740":"code","3e2715de":"code","da072ced":"code","9432ef90":"code","7bf9db14":"code","abd7af02":"code","ddaf3b40":"code","31f680aa":"code","c08e0baa":"code","69db51af":"code","174148ce":"code","3b2743b9":"code","6be7e7f1":"code","4947fb30":"code","2c7805d8":"code","9992f711":"code","fcf20755":"code","db1de0ee":"code","ac4fa355":"code","0378b4be":"code","5734ab3a":"code","6a9f301f":"code","f47560f5":"code","07abc459":"code","a1212782":"code","984705f4":"code","64887e62":"code","07202a97":"code","ccb53574":"code","dbbf6208":"code","b45e582b":"code","c22e33c3":"code","c660d35e":"code","42461885":"code","e2e32322":"code","390c6478":"code","6cb52d28":"code","eede10b3":"markdown","ae9ecbac":"markdown","29fab748":"markdown","6bd01c09":"markdown","91abce79":"markdown","23a73429":"markdown","72a7050d":"markdown","0314b49c":"markdown","a3ff08f2":"markdown","7cc2ab80":"markdown","e376e3fa":"markdown","1519a691":"markdown","bcf17074":"markdown","fefe1672":"markdown","c5b3c2c8":"markdown","ebbd869f":"markdown","8416957f":"markdown","3e416961":"markdown","146dc51c":"markdown","b3388976":"markdown","26dea432":"markdown","b03a2ec1":"markdown","79633fd4":"markdown","7dc6a811":"markdown","c2874b52":"markdown","e1501693":"markdown","bfa5f244":"markdown","39f3157f":"markdown","9e18b68e":"markdown","03c3c907":"markdown","ed98705b":"markdown","1e49b896":"markdown","2b572103":"markdown","e5cc211d":"markdown","6b0389f9":"markdown","39551271":"markdown"},"source":{"5bba3816":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load prueba\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Importamos estas librerias para poder realizar el EDA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce8cbab8":"data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata.head()","6f93be95":"#test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n#test_data.head()","a89961fe":"def bar_plot (variable):\n    \"\"\"\n        input: variable --- Una de las variables categ\u00f3ricas\n        output: bar plot con el valor\n    \"\"\"\n    \n    # Conseguimos caracter\u00edstica\n    feature = data[variable]\n    \n    # Conseguimos el n\u00famero de esa variable que acabamos de obtener\n    varValue = feature.value_counts()\n    \n    # Mostrar\n    \n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue, color=['red', 'blue', 'green', 'blue', 'cyan'])\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(str(variable))\n\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))\n    ","e03a9ccd":"categorical_variables = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\n\nfor cat in categorical_variables:\n    bar_plot(cat)","ffcc3b03":"def cake_plot(category, variable2 = 'Survived'):\n    \"\"\"\n        input: variable1 --- Una de las variables categ\u00f3ricas\n               variable2 --- Ser\u00e1 supervivientes, pero se adapta por si cambia en un futuro \n        output: bar plot con el valor\n    \"\"\"\n    \n    # Conseguimos caracter\u00edstica\n    feature = data[category]\n    \n    # Conseguimos el n\u00famero de esa variable que acabamos de obtener\n    varValue = feature.value_counts()\n    \n    \n    # Mostrar\n    f,ax=plt.subplots(1,len(varValue),figsize=(12,8))\n    etiquetas = [\"Survived\", \"No Survived\"]\n    feature = data[category]\n    valValue = data[[category, variable2]].groupby([category])\n    count = 0\n    for name, dat in valValue:\n        porcentas = [dat[variable2].mean(),1-dat[variable2].mean()]\n        desfase = (0, 0.1)\n        ax[count].pie(porcentas, labels = etiquetas, autopct=\"%0.1f %%\", explode=desfase)\n        ax[count].axis(\"equal\")\n        ax[count].set_title(str(category) +\" \"+ str(name))\n        count +=1\n    plt.show()\n    ","fb817740":"cake_plot('Pclass') \ncake_plot('Sex')","3e2715de":"data.isnull().sum()","da072ced":"data['Initial']=0\nfor i in data:\n    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.') \n    data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n                              ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)","9432ef90":"data.groupby('Initial')['Age'].mean()","7bf9db14":"data.loc[(data.Age.isnull())&(data.Initial=='Mr'),'Age']=33\ndata.loc[(data.Age.isnull())&(data.Initial=='Mrs'),'Age']=36\ndata.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age']=5\ndata.loc[(data.Age.isnull())&(data.Initial=='Miss'),'Age']=22\ndata.loc[(data.Age.isnull())&(data.Initial=='Other'),'Age']=46","abd7af02":"# Creando los intervalos de edades\ninterval = (0, 5, 12, 18, 25, 35, 60, 120)\n\n# Otorgando nombres de intervalos que necesitamos para cada franja de edad\ncats = ['bebes', 'ninos', 'adolescentes', 'estudiantes', 'jovenes', 'adultos', 'senior']\n\n# Empleamos el pd.cut y usamos los parametros que acabamos de crear\ndata[\"Age_cat\"] = pd.cut(data.Age, interval, labels=cats)\n\ndata.groupby('Age_cat')['Age'].mean()","ddaf3b40":"#Separamos supervivientes de no-supervivientes\n\nplt.figure(figsize=(12,5))\n\n# Usar Facetgrid es una buena manera de obtener informaci\u00f3n del dataset\ng = sns.FacetGrid(data, col='Survived',size=5)\ng = g.map(sns.distplot, \"Age\")\nplt.show()","31f680aa":"\nprint(pd.crosstab(data.Age_cat, data.Survived))\n\nplt.figure(figsize=(12,10))\n\nplt.subplot(2,1,1)\nsns.countplot(\"Age_cat\",data=data,hue=\"Survived\", palette=\"hls\")\nplt.ylabel(\"Cantidad\", fontsize=18)\nplt.xlabel(\"Categorias de edad\", fontsize=18)\nplt.title(\"Distribuci\u00f3n de edad \", fontsize=20)\n\nplt.subplot(2,1,2)\nsns.swarmplot(x='Age_cat',y=\"Fare\",data=data,\n              hue=\"Survived\", palette=\"hls\", )\nplt.ylabel(\"Distribuci\u00f3n de tarifas\", fontsize=18)\nplt.xlabel(\"Categorias por edad\", fontsize=18)\nplt.title(\"Distribuci\u00f3n de tarifas por edad \", fontsize=20)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show()","c08e0baa":"pd.crosstab([data.Sex,data.Embarked],data.Pclass,margins=True).style.background_gradient(cmap='Pastel2')","69db51af":"data.head()","174148ce":"# Empleamos one-hot encoding y dropeamos la columna Embarked\ndata = data.join(pd.get_dummies(data.Embarked, prefix='Embarked'))\ndata = data.drop('Embarked', axis=1)\ndata.head()","3b2743b9":"print(data.SibSp.isnull().sum())\nprint(data.Parch.isnull().sum())","6be7e7f1":"data['Accompanied_Count']  = data.SibSp + data.Parch\ndata = data.drop(['SibSp','Parch' ], axis=1)\ndata.head()","4947fb30":"data = data.drop(['Name','Ticket' ], axis=1)\ndata.head()","2c7805d8":"#def drop_column (column):\n #   aux = (data[column].isnull().sum()\/data[column].shape[0])*100\n  #  print(\"Porcentaje de valores nulos en la columna: \"+str(column)+\" =\"+str(aux))\n          \n   # if(data[column].isnull().sum()\/data[column].shape[0])*100 > 65.0:\n    #    return data.drop([column], axis=1)","9992f711":"print(data['Cabin'].isnull().sum())\n\naux = (data['Cabin'].isnull().sum()\/data['Cabin'].shape[0])*100\n\n\nprint(\"Porcentaje de valores nulos en la columna: \"+'Cabin'+\" =\"+str(aux))         \nif(data['Cabin'].isnull().sum()\/data['Cabin'].shape[0])*100 > 65.0:\n    data = data.drop(['Cabin'], axis=1)\ndata.head()","fcf20755":"pd.crosstab(data.Accompanied_Count,data.Pclass).style.background_gradient(cmap='Pastel2')","db1de0ee":"f,ax=plt.subplots(1,7,figsize=(40,8))\nsns.distplot(data[data['Age_cat']=='bebes'].Fare,ax=ax[0])\nax[0].set_title('Tarifa para bebes')\nsns.distplot(data[data['Age_cat']=='ninos'].Fare,ax=ax[1])\nax[1].set_title('Tarifa para ninos')\nsns.distplot(data[data['Age_cat']=='adolescentes'].Fare,ax=ax[2])\nax[2].set_title('Tarifa para adolescentes')\nsns.distplot(data[data['Age_cat']=='estudiantes'].Fare,ax=ax[3])\nax[3].set_title('Tarifa para estudiantes')\nsns.distplot(data[data['Age_cat']=='jovenes'].Fare,ax=ax[4])\nax[4].set_title('Tarifa para jovenes')\nsns.distplot(data[data['Age_cat']=='adultos'].Fare,ax=ax[5])\nax[5].set_title('Tarifa para adultos')\nsns.distplot(data[data['Age_cat']=='senior'].Fare,ax=ax[6])\nax[6].set_title('Tarifa para senior')\nplt.show()\n","ac4fa355":"data['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata.head()","0378b4be":"sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.4) \nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","5734ab3a":"data.head()","6a9f301f":"passengerId = data['PassengerId']\ndata.drop(['PassengerId', 'Initial'], axis = 1, inplace = True)\ndata['Age_cat'] = pd.to_numeric(data['Age_cat'].map({\n    'bebes': 0,\n    'ninos': 1,\n    'adolescentes': 2,\n    'estudiantes': 3,\n    'jovenes': 4,\n    'adultos': 5,\n    'senior': 6,\n},na_action=None))\n\ndata.head()","f47560f5":"for elem in data:\n    data.loc[data['Fare'] < 30, 'Fare'] = 1\n    data.loc[(data['Fare'] >= 30) & (data['Fare'] < 50),'Fare'] = 2\n    data.loc[(data['Fare'] >= 50) & (data['Fare'] < 100),'Fare'] = 3\n    data.loc[(data['Fare'] >= 100),'Fare'] = 4\n    \ndata.head()","07abc459":"from sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.model_selection import train_test_split #training and testing data split\nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix #for confusion matrix","a1212782":"train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\ntrain_X=train[train.columns[1:]]\ntrain_Y=train[train.columns[:1]]\ntest_X=test[test.columns[1:]]\ntest_Y=test[test.columns[:1]]\nX=data[data.columns[1:]]\nY=data['Survived']","984705f4":"model=DecisionTreeClassifier()\nmodel.fit(train_X,train_Y)\nprediction4=model.predict(test_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction4,test_Y))","64887e62":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras import models \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping","07202a97":"model = Sequential([\n    layers.Dense(units = 32, input_shape = (9,), activation = 'relu'),\n    layers.Dense(units = 64, activation = 'relu', use_bias = False),\n    layers.BatchNormalization(),\n    layers.Dense(units = 128, activation = 'relu', use_bias = True),\n    layers.Dropout(0.1),\n    layers.Dense(units = 64, activation = 'relu', use_bias = False),\n    layers.Dropout(0.1),\n    layers.Dense(units = 32, activation = 'relu',  use_bias = True),\n    layers.Dropout(0.1),\n    layers.Dense(units = 16, activation = 'relu',  use_bias = True),\n     layers.Dropout(0.1),\n    layers.Dense(units = 8, activation = 'relu', use_bias = False),\n    layers.Dense(units =1 , activation = 'sigmoid')\n])","ccb53574":" model.summary()","dbbf6208":"model.compile(\n    loss = tf.keras.losses.binary_crossentropy, \n    optimizer = tf.keras.optimizers.SGD(), \n    metrics = ['accuracy']\n)","b45e582b":"early_stopping = EarlyStopping(\n    min_delta=0.02, # minimium amount of change to count as an improvement.\n    patience=10, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)","c22e33c3":"model.fit(\n    train_X, train_Y,\n    batch_size = 32,\n    verbose = 2,\n    epochs = 80,\n    callbacks=[early_stopping]\n)","c660d35e":"predict = model.predict(test_X)","42461885":"predict = (predict > 0.5).astype(int).ravel()\nprint(predict)\n","e2e32322":"test['PassengerId'] = passengerId\nsubmit = pd.DataFrame({\"PassengerId\":test.PassengerId, 'Survived':predict})\nsubmit.to_csv(\"submission.csv\",index = False)","390c6478":"from sklearn import metrics\nY_pred_rand = (model.predict(train_X) > 0.5).astype(int)\nprint('Precision : ', np.round(metrics.precision_score(train_Y, Y_pred_rand)*100,2))\nprint('Accuracy : ', np.round(metrics.accuracy_score(train_Y, Y_pred_rand)*100,2))\nprint('Recall : ', np.round(metrics.recall_score(train_Y, Y_pred_rand)*100,2))\nprint('F1 score : ', np.round(metrics.f1_score(train_Y, Y_pred_rand)*100,2))\nprint('AUC : ', np.round(metrics.roc_auc_score(train_Y, Y_pred_rand)*100,2))","6cb52d28":"matrix = metrics.confusion_matrix(train_Y, Y_pred_rand)\nsns.heatmap(matrix, annot = True,fmt = 'g')\nplt.show()","eede10b3":"Cargamos primero los datos de entrenamiento, y mostramos los primeros datos.\n\nEstas son las columnas y su significado:\n - PassengerId -> Id \u00fanico que se agencia a cada pasajero\n - Survived -> Caracter\u00edstica binaria que indica si el pasajero ha sobrevivido o no. 1 si lo ha hecho, 0 si no lo ha hecho.\n - Pclass -> Clase del ticket a la que pertenece el pasajero. 1, Clase alta; 2, Clase media; 3, Clase baja\n - Name -> Nombre y apellidos de cada pasajero\n - Sex -> Sexo de cada pasajero. Hombre (male) o mujer (female)\n - Age -> Edad del pasajero. \n - SibSp. N\u00famero de herman@s y\/o espos@s del pasajero sobre el barco del Titanic.\n - Parch. N\u00famero de padres o hijos del pasajero abordo.\n - Ticket. N\u00famero del ticket del pasajero\n - Fare. Tarifa del pasajero\n - Cabin. N\u00famero de cabina del pasajero\n - Embarked. Puerto de embarque. C = Cherbourg, Q = Queenstown, S = Southampton","ae9ecbac":"En el fichero existen 3 archivos:\n- train.csv (de d\u00f3nde sacamos los datos de entrenamiento)\n- test.csv (de d\u00f3nde sacamos los datos de test)\n- gender_submission.csv (ejemplo de como estructurar las predicciones)","29fab748":"Ahora vamos a reemplazarlo con la media","6bd01c09":"Ahora vamos a ver como el precio de la tarifa var\u00eda seg\u00fan la clase social de cada pasajero","91abce79":"Apreciamos varias cosas. La edad va a ser una columna importante, por lo que no podemos permitirnos tener tantos valores NaN en ella, deberemos proceder a limpiar esa columna de alguna manera.\nAdem\u00e1s tenemos como la cabina tiene much\u00edsimos valores NaN, esto nos es de menos importancia, puesto que la Cabina en principio la vamos a desechar m\u00e1s adelante.\nLa columna de embarque tiene tan solo 2 valores NaN, por lo que vamos a obviarlos.","23a73429":"Vamos a arreglar la columna de la edad, para ello vamos a reemplazar los valores de NaN, asignandoles el valor de la media. Vamos a aprovechar otra columna que no tiene datos vac\u00edos, como es el nombre, para asignar la media de edades seg\u00fan el prefijo del nombre","72a7050d":"Ahora vamosa  realizar una red neuronal. Primero importamos librer\u00edas","0314b49c":"Eliminamos *PassengerId*, *Initial*, y transformamos Age_cat a intervalos","a3ff08f2":"Podemos observar varias cuestiones:\n- Murieron m\u00e1s personas de las que sobrevivieron\n- Hab\u00eda m\u00e1s hombres que mujeres en el barco\n- La mayor\u00eda de las personas eran de clase baja (PClass = 3)\n- La mayor\u00eda embarcaron en Southampton (Embarked = S)\n- La mayor\u00eda no ten\u00edan acompa\u00f1antes de ning\u00fan tipo","7cc2ab80":"Para evitar tener datos String que no nos ofrecen nada de valor, vamos a crear nuevas columnas para la categor\u00eda Embarked. Como son 3 posibilidades, al asignarles n\u00fameros 0,1,2 por ejemplo, al ordenador le estamos dando a entender que hay una diferencia de 2 unidades entre el primer tipo de embarcamiento y el \u00faltimo. Cosa que no es as\u00ed. Es por ello por lo que usamos la t\u00e9cnica de One-Hot Encoding para poder representar n\u00famericamente cada embarcamiento solo con 0 o 1 indicando si es ese embarcamiento o no","e376e3fa":"Podemos apreciar como aquellas personas de clase m\u00e1s baja (Clase 3 sobre todo) son m\u00e1s propensas a tener m\u00e1s personas como acompa\u00f1antes","1519a691":"Simplemente vamos a ejecutar la funci\u00f3n de arriba para mostrar la cantidad de elementos que tiene cada categoria","bcf17074":"Llega el momento de  realizar el modelo predictivo,primero de todo vamos a dividir el dataset en train_data y test_data.\n\n- Nuestros datos de entrenamiento estar\u00e1n en train_X\n- Nuestra caracter\u00edstica de salida (que es *Survived*) estar\u00e1 en train_Y\n- Nuestra red recibir\u00e1 test_X y test_Y para realizar las predicciones tras haber entrenado el modelo.","fefe1672":"Ahora vamos a ver una distribuci\u00f3n de supervivientes seg\u00fan la edad. Survived = 1 es que ha sobrevivido, y Survived = 0 es que ha fallecido","c5b3c2c8":"Como ninguno de los dos tiene valores nulos, podemos sumar directamente ambas y dropear las columnas base *SibSp* y *Parch*","ebbd869f":"Cargamos ahora los datos de test. (Por el momento lo vamos a dejar comentado)","8416957f":"Ahora vamos a hacer otra representaci\u00f3n de las edades pero de otra manera distinta, vamos a agrupar las edades en una nueva columna llamada Age_cat, donde se har\u00e1n intervalos de edades para diferenciar seg\u00fan: *Beb\u00e9s, Ni\u00f1os, Adolescentes, Estudiantes, J\u00f3venes, Adultos, Seniors*","3e416961":"Vamos a realizar una serie de gr\u00e1ficas de datos cruzados con mapas de calor.","146dc51c":"Vamos a usar una categor\u00eda ordinal, cuyos valores tienen ordene entre s\u00ed, para ello vamos a usar un gr\u00e1fico de calor.","b3388976":"Separamos en los conjuntos que hemos nombrado previamente","26dea432":"Vamos a probar con un Decision Tree","b03a2ec1":"Ahora vamos a observar cual es la media de edad por el prefijo del nombre","79633fd4":"Vamos a cambiar la tarifa a caracter\u00edstica categ\u00f3rica","7dc6a811":"Ahora vamos a dropear aquellas columnas que considero que no nos pueden otorgar informaci\u00f3n relevante para el estudio y para el posterior entrenamiento del modelo, que son:\n1. Name\n2. Ticket\n\nDespu\u00e9s, vamos a calcular que porcentaje de NaN hay en la columna de *Cabin*, si es superior al 65% la vamos a eliminar, puesto que no es viable realizar *Imputation* ya que la cantidad de valores nulos es enorme","c2874b52":"Volvemos a mostrar las columnas para ver que hemos creado una nueva columna llamada Age_cat, pero respetamos la columna Age","e1501693":"Mapa de calor que cruza todas las caracter\u00edsticas que tenemos","bfa5f244":"Vamos a mostrar gr\u00e1ficos pastel de PClass (clase social de cada pasajero del barco) que es una categor\u00eda ordinal (existen orden entre sus valores), y de Sex, que es el sexo de cada pasajero","39f3157f":"Importamos algunas librer\u00edas que necesitamos","9e18b68e":"Funci\u00f3n para dropear columnas con m\u00e1s de un 65% de valores NaN","03c3c907":"Ahora nuestra intenci\u00f3n es sintetizar las columnas de acompa\u00f1antes, creando una \u00fanica que contenga el n\u00famero de acompa\u00f1antes de cada pasajero, para ello vamos a sumar los valores de las columnas *SibSp* y *Parch* en una llamada *Accompained*, y despu\u00e9s vamos a eliminar las 2 primeras columnas nombradas.\n\nPrimero de todo comprobamos si las columnas de SibSp y Parch tiene valores NaN, en ese casos se rellenar\u00e1n con la media de cada columna.","ed98705b":"Necesitamos tener todo el dataset con caracter\u00edsticas categ\u00f3ricas. Vemos lo que tenemos y procedemos a eliminar","1e49b896":"Vamos antes de todo a realizar un Exploratory Data Analysis, EDA. An\u00e1lisis Exploratorio de datos.\nEl an\u00e1lisis exploratorio de datos implica el uso de gr\u00e1ficos y visualizaciones para explorar y analizar un conjunto de datos. El objetivo es explorar, investigar y aprender, no confirmar hip\u00f3tesis estad\u00edsticas. ","2b572103":"Ahora vamos a definir otra funci\u00f3n para ver los datos en forma de gr\u00e1fica pastel donde podamos ver los porcentajes de supervivientes seg\u00fan cada caracter\u00edstica","e5cc211d":"Vamos a mostrar una serie de gr\u00e1ficas con las *Categorical Variables: Survived, Sex, PClass, Embarked, Cabin, Name, Ticket*\n- Las variables categ\u00f3ricas contienen un n\u00famero finito de categor\u00edas o grupos distintos. Los datos categ\u00f3ricos pueden no tener un orden l\u00f3gico.","6b0389f9":"Por \u00faltimo vamos a sustituir la columna *Sex* por 0,1, ahora no tenemos problemas puesto que es un valor binario","39551271":"Vamos a comprobar que columnas tienend datos nulos"}}