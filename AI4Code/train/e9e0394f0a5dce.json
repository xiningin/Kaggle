{"cell_type":{"fc99ef96":"code","6ef409b7":"code","87a12af7":"code","40685361":"code","230dd0e9":"code","f84ba4aa":"code","2ea297f6":"code","66b51880":"code","49bcff9f":"code","ab89387d":"code","1d1a729f":"code","91e061c9":"code","191b6579":"code","e019d6b3":"code","88eea9a0":"code","a798250a":"code","51652215":"code","4f61309e":"code","2306e033":"code","a2a0006e":"code","1b362787":"code","cdde710a":"code","7e06795f":"code","397571c1":"code","eefed2f3":"code","d54cfbd3":"code","82f8715f":"code","865567fe":"code","7b837441":"code","597780b0":"code","527a096d":"code","de6b5546":"code","136baee8":"code","1b2bfac7":"code","cb3cf92a":"code","2adf3da0":"code","667625e6":"code","3e9c206f":"code","d27abc6a":"code","fb830db3":"code","a5a980b7":"code","fb370cff":"code","6cbc8f77":"code","10033b10":"code","af094324":"code","7389bb33":"code","dfa8af8d":"code","f5c42852":"code","6d3e203c":"code","79831ffb":"code","13358e08":"code","38975635":"code","1b8431d6":"code","6d93422e":"markdown","66694bbe":"markdown","44b18ca1":"markdown","d64da617":"markdown","9e077f6a":"markdown","54f46000":"markdown","2306f6c7":"markdown","9456e244":"markdown","ea1a6d09":"markdown","23842cdb":"markdown","74c41d71":"markdown","34031d5a":"markdown","414bf99b":"markdown","ffa5cc1b":"markdown","1d619993":"markdown","c77da02d":"markdown","f7277e40":"markdown","f3dd9dcf":"markdown","672bb00a":"markdown","d29218bb":"markdown","6251c002":"markdown","03e30dde":"markdown","98c12d8b":"markdown","f74e1340":"markdown","0e9908ab":"markdown","c6f4546a":"markdown","ef3c077b":"markdown","8c94dfbc":"markdown","29bede12":"markdown","ae9fb062":"markdown","463e50bc":"markdown","868df856":"markdown"},"source":{"fc99ef96":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nimport collections\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n","6ef409b7":"ResponseData = pd.read_csv(\"..\/input\/deepnlp\/Sheet_1.csv\",encoding='latin-1')\nResumeData = pd.read_csv(\"..\/input\/deepnlp\/Sheet_2.csv\",encoding='latin-1')","87a12af7":"ResponseData.head()","40685361":"ResponseData.drop(['response_id','Unnamed: 3', 'Unnamed: 4','Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'],axis=1, inplace=True)\nResponseData.head()","230dd0e9":"ResponseData.shape","f84ba4aa":"ResponseData.info()","2ea297f6":"sns.countplot(x='class', data=ResponseData ,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))","66b51880":"def cloud(text):\n    plt.figure(figsize=(15,15))\n    plt.imshow(WordCloud(background_color=\"white\",stopwords=set(stopwords.words('english')))\n               .generate(\" \".join([i for i in text.str.lower()])))\n    plt.axis(\"off\")\n    plt.title(\"Response could words\")","49bcff9f":"cloud(ResponseData[ResponseData['class']=='flagged']['response_text'])","ab89387d":"cloud(ResponseData[ResponseData['class']=='not_flagged']['response_text'])","1d1a729f":"def CommonWords(text , kk=10) : \n\n    all_words = []\n\n    for i in range(text.shape[0]) : \n        this_phrase = list(text)[i]\n        for word in this_phrase.split() : \n            all_words.append(word)\n\n    print(f'Total words are {len(all_words)} words')   \n    print('')\n\n    common_words = collections.Counter(all_words).most_common()\n    k=0\n    word_list =[]\n    for word, i in common_words : \n        if not word.lower() in  nlp.Defaults.stop_words :\n            print(f'The word is   {word}   repeated   {i}  times')\n            word_list.append(word)\n            k+=1\n        if k==kk : \n            break\n            \n    return word_list","91e061c9":"words1 = CommonWords(ResponseData[ResponseData['class']=='not_flagged']['response_text'],5)","191b6579":"words2 = CommonWords(ResponseData[ResponseData['class']=='flagged']['response_text'],5)","e019d6b3":"filtered_words = words1+words2\nfiltered_words","88eea9a0":"def RemoveWords(data , feature , new_feature, words_list ) : \n    new_column = []\n    for i in range(data.shape[0]) : \n        this_phrase = data[feature][i]\n        new_phrase = []\n        for word in this_phrase.split() : \n            if not word.lower() in words_list : \n                new_phrase.append(word)\n        new_column.append(' '.join(new_phrase))\n    \n    data.insert(data.shape[1],new_feature,new_column)","a798250a":"RemoveWords(ResponseData , 'response_text' , 'filtered_text' , filtered_words)","51652215":"ResponseData.head()","4f61309e":"cloud(ResponseData[ResponseData['class']=='flagged']['filtered_text'])","2306e033":"cloud(ResponseData[ResponseData['class']=='not_flagged']['filtered_text'])","a2a0006e":"enc  = LabelEncoder()\nenc.fit(ResponseData['class'])\nResponseData['class'] = enc.transform(ResponseData['class'])","1b362787":"ResponseData.head()","cdde710a":"X = ResponseData['filtered_text']\ny = ResponseData['class']","7e06795f":"X.shape","397571c1":"y.shape","eefed2f3":"VecModel = TfidfVectorizer()\nX = VecModel.fit_transform(X)\n\nprint(f'The new shape for X is {X.shape}')","d54cfbd3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=402)","82f8715f":"print('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","865567fe":"DecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini',max_depth=10,random_state=33) \nDecisionTreeClassifierModel.fit(X_train, y_train)","7b837441":"print('DecisionTreeClassifierModel Train Score is : ' , DecisionTreeClassifierModel.score(X_train, y_train))\nprint('DecisionTreeClassifierModel Test Score is : ' , DecisionTreeClassifierModel.score(X_test, y_test))\nprint('DecisionTreeClassifierModel Classes are : ' , DecisionTreeClassifierModel.classes_)","597780b0":"y_pred = DecisionTreeClassifierModel.predict(X_test)\ny_pred_prob = DecisionTreeClassifierModel.predict_proba(X_test)\nprint('Predicted Value for DecisionTreeClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for DecisionTreeClassifierModel is : ' , y_pred_prob[:10])","527a096d":"phrase = ['I went to my friend to talk about normal issues']\nenc.inverse_transform(DecisionTreeClassifierModel.predict(VecModel.transform(phrase)))","de6b5546":"phrase = ['I know a Friend was thinking about suicide']\nenc.inverse_transform(DecisionTreeClassifierModel.predict(VecModel.transform(phrase)))","136baee8":"ResumeData.head()","1b2bfac7":"ResumeData.shape","cb3cf92a":"ResumeData.info()","2adf3da0":"sns.countplot(x='class', data=ResumeData ,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))","667625e6":"cloud(ResumeData[ResumeData['class']=='flagged']['resume_text'])","3e9c206f":"cloud(ResumeData[ResumeData['class']=='not_flagged']['resume_text'])","d27abc6a":"words1 = CommonWords(ResumeData[ResumeData['class']=='flagged']['resume_text'],10)","fb830db3":"words2 = CommonWords(ResumeData[ResumeData['class']=='not_flagged']['resume_text'],10)","a5a980b7":"filtered_words = words1+words2\nfiltered_words","fb370cff":"RemoveWords(ResumeData , 'resume_text' , 'filtered_text' , filtered_words)\nResumeData.head()","6cbc8f77":"cloud(ResumeData[ResumeData['class']=='flagged']['filtered_text'])","10033b10":"cloud(ResumeData[ResumeData['class']=='not_flagged']['filtered_text'])","af094324":"enc.fit(ResumeData['class'])\nResumeData['class'] = enc.transform(ResumeData['class'])\nResumeData.head()","7389bb33":"X = ResumeData['filtered_text']\ny = ResumeData['class']","dfa8af8d":"X.shape","f5c42852":"y.shape","6d3e203c":"X = VecModel.fit_transform(X)\n\nprint(f'The new shape for X is {X.shape}')","79831ffb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","13358e08":"SVCModel = SVC(kernel= 'linear',# it can be also linear,poly,sigmoid,precomputed\n               max_iter=10000,C=10,gamma='auto')\nSVCModel.fit(X_train, y_train)","38975635":"print('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))","1b8431d6":"y_pred = SVCModel.predict(X_test)\nprint('Predicted Value for SVCModel is : ' , y_pred[:10])","6d93422e":"suitable ratios , now let's define the cloud function , to show most repeated words in each sector","66694bbe":"does it contain any nulls ? ","44b18ca1":"now we can show most repeated words in flagged reponses","d64da617":"let's use Decision Tree Classifier , with gini criterion& depth 10","9e077f6a":"& even we can make cloud again for flagged responses","54f46000":"here we'll use SVC since it will make better accuracy ","2306f6c7":"many related words appear like : suicide , anxiety , addiction \n\nnow how not-flagged looks like","9456e244":"how data looks like ? ","ea1a6d09":"great , now to form a weired phrase which looks like offensive","23842cdb":"and here most common 5 words in flagged","74c41d71":"now how data looks like","34031d5a":"great , now we need to label encode the output","414bf99b":"then define the removal function ","ffa5cc1b":"now to remove these words & make a new column call filtered_text","1d619993":"good job , not let's move to Resume Data , to apply same steps\n\n______\n\n# Resume Data\n\nwe'll apply almost same steps here , as we did in responses ","c77da02d":"and split the data","f7277e40":"then apply count vectorizer to make the sparse matrix to X","f3dd9dcf":"now words are more representative \n\n& cloud for nonflagged responses","672bb00a":"and read both files","d29218bb":"# NLP Classification\nBy : Hesham Asem\n\n_____\n\nwe have 2 files sheet 1 & sheet 2\n\nsheet 1 contain 80 replies from users to chatbot , & it either classied as offensive (flagged) or non-offensive (not flagged)\n\nand sheet 2 contain 125 resumes , some of them looks unreal so it flagged & some are real : not flagged\n\nwe need to use NLP techniques to train our model , so he can be able to diffrentiate between them \n\n\nData File : https:\/\/www.kaggle.com\/samdeeplearning\/deepnlp\n\nlet's first import needed libraries\n\n","6251c002":"ok 90% is fine enough , let's predict some result","03e30dde":"then we define X & y","98c12d8b":"then here . we'll get most common 5 words in not flagged responses","f74e1340":"great , now how many flagged & non-flagged we have here ? ","0e9908ab":"many normal words appear . \n\nbut since several words appeared here , so it might mislead the training , so we have to know most common words , then remove them since they are like stop words\n\nso we we'll define a function to know most common words","c6f4546a":"so we'll start witjh responses file \n\n_____\n\n\n# Response File\n\nlet's have a look to the file","ef3c077b":"what is the shape ? ","8c94dfbc":"how is scores ? ","29bede12":"now we camn add the two lists ","ae9fb062":"we'll just need 2 columns , which is response_text as X & class as y , let's drop the rest ","463e50bc":"how is X & y shapes ? ","868df856":"also we can use the model to predict new phrases we just invent now\n\nlet's form a normal phrase , it should classified as not-flagged"}}