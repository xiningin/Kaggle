{"cell_type":{"d2d52125":"code","409047b2":"code","2566d151":"code","af597960":"code","0b483690":"code","628f0c2c":"code","4575e712":"code","3c3be4ad":"code","40096fcd":"code","43238edb":"code","3d592eed":"code","423307c2":"code","c8e1357b":"code","414bc85b":"code","e94164a9":"code","eb494725":"code","691f2485":"code","f4759e4a":"code","386064ac":"code","74964ecd":"code","ec525baa":"code","85ebaf03":"code","05d1bada":"code","21601233":"code","1f4d8454":"code","574436c7":"code","dcce23d0":"markdown","c8194d90":"markdown","0384eb57":"markdown","a7cc3e12":"markdown","02599fe0":"markdown","d7486d9d":"markdown","22b92ca8":"markdown"},"source":{"d2d52125":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","409047b2":"df = pd.read_excel(\"\/kaggle\/input\/data.xlsx\")","2566d151":"df.head()","af597960":"df[\"target\"].value_counts() #\u043a\u043b\u0430\u0441\u0441\u044b \u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u044b","0b483690":"Y = df[\"target\"] # \u043e\u0442\u0434\u0435\u043b\u044f\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043e\u0442 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\nX = df.drop(\"target\", axis=1, inplace=False)","628f0c2c":"scaler = StandardScaler()\nscaled_X = scaler.fit_transform(X) # \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0434\u043b\u044f \u0440\u0430\u0432\u043d\u043e\u043f\u0440\u0430\u0432\u043d\u043e\u0433\u043e \u0438\u0445 \u0432\u043b\u0438\u044f\u043d\u0438\u044f \u043d\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u0442\u0435\u0440\u044c \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438","4575e712":"X_train, X_test, y_train, y_test = train_test_split(scaled_X, Y, test_size=0.33, random_state=42) # \u0440\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e\u0441\u044f \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e","3c3be4ad":"clf = LogisticRegression(random_state=0).fit(X_train, y_train) # \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 (\u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e)\ny_pred = clf.decision_function(X_test) # \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b (\u0441\u0443\u043c\u043c\u0430) \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0441\u043e\u0431\u044b\u0442\u0438\u044f \u0432 \u0442\u0435\u0441\u0442\u0435","40096fcd":"y_pred","43238edb":"precision, recall, thresholds = precision_recall_curve(y_test, y_pred) # thresholds-\u043f\u043e\u0440\u0433\u0438 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n                                                                       # precision[i], recall[i] \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043f\u043e\u0440\u043e\u0433\u0443 thresholds[i]","3d592eed":"plt.plot(thresholds, precision[:-1]) # \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438 \u0440\u0430\u0437\u043d\u044b\u0445 \u043f\u043e\u0440\u043e\u0433\u0430\u0445 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f","423307c2":"plt.plot(thresholds, recall[:-1]) # \u043f\u043e\u043b\u043d\u043e\u0442\u0430 \u043f\u0440\u0438 \u0440\u0430\u0437\u043d\u044b\u0445 \u043f\u043e\u0440\u043e\u0433\u0430\u0445 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u044f (\u0427\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0442\u0435\u043c \u043c\u0435\u043d\u044c\u0448\u0435 \u0441\u043e\u0431\u044b\u0442\u0439 \u043f\u043e\u043f\u0430\u0434\u0430\u0435\u0442 \u0432 \u043a\u043b\u0430\u0441\u0441 '1')","c8e1357b":"plt.plot(recall, precision)\naverage_precision_score(y_test, y_pred)\n#plot_precision_recall_curve(clf, X_test, y_test)","414bc85b":"fpr, tpr, thresholds = roc_curve(y_test, y_pred)","e94164a9":"plt.plot(fpr, tpr)\nroc_auc_score(y_test, y_pred)","eb494725":"class RaisingLogisticRegression(LogisticRegression):\n    def fit(self, *args, **kwargs):\n        \"\"\"\n        \u0422\u0430\u043a \u043a\u0430\u043a \u043f\u0440\u0438 penalty=\"none\" \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 C \u0438\u0433\u043d\u043e\u0440\u0438\u0440\u0443\u0435\u0442\u0441\u044f, \u0442\u043e \u043d\u0435\u0442 \u0441\u043c\u044b\u0441\u043b\u0430 \u0435\u0433\u043e \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0438 \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0442\u044c \u043e\u0434\u043d\u043e \u0438 \u0442\u043e \u0436\u0435.\n        \"\"\"\n        if (not np.isnan(self.C)) == (self.penalty == \"none\"):\n            raise ValueError(f\"Not allowed!!! C={self.C}, penalty={self.penalty}\")\n        if self.penalty == \"none\":\n            self.C = 1.0\n        return super().fit(*args, **kwargs)\n    \nclf = RaisingLogisticRegression(random_state=0)\n\n# \u041e\u0442\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u043d\u0430\u0434\u043e\u0435\u0434\u043b\u0438\u0432\u044b\u0445 \u0432\u043e\u0440\u0438\u043d\u0433\u043e\u0432\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning, FitFailedWarning\nwarnings.filterwarnings(action='ignore', category=ConvergenceWarning) # \u041f\u0440\u0435\u0434\u0443\u043f\u0440\u0435\u0436\u0434\u0435\u043d\u0438\u0435 \u043e \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u0438 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0439\nwarnings.filterwarnings(action='ignore', category=FitFailedWarning)   # \u041f\u0440\u0435\u0434\u0443\u043f\u0440\u0435\u0436\u0434\u0435\u043d\u0438\u0435 \u043e \u043d\u0435 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u043d\u043e\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438","691f2485":"parameters = {\n    'penalty': ['l1', 'l2', 'none'], # \u041c\u0435\u0442\u043e\u0434\u044b \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n    'C': np.append(np.linspace(0.05, 2.5, num=5), np.nan), # \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438\n    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], # \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438\n    'max_iter': np.linspace(20, 300, num=5) # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0439 \u043c\u0435\u0442\u043e\u0434\u0430\n}\ngs = GridSearchCV(clf, parameters, scoring=['accuracy', 'f1', 'precision', 'recall', 'roc_auc'], cv=10, return_train_score=True, refit=\"accuracy\")\ngs.fit(X, Y)","f4759e4a":"list(gs.cv_results_.keys())","386064ac":"results = pd.concat(\n    [pd.DataFrame(gs.cv_results_[\"params\"])] + \n        [\n            pd.DataFrame(gs.cv_results_[\"mean_test_\" + metric], columns=[metric])\n                for metric in ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n        ] + \n        [\n            pd.DataFrame(gs.cv_results_[\"mean_train_\" + metric], columns=[\"train \" + metric])\n                for metric in ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n        ] + \n        [pd.DataFrame(gs.cv_results_[\"mean_fit_time\"], columns=[\"mean_fit_time\"])],\n    axis=1)\nresults","74964ecd":"results = results[~results.loc[:, 'accuracy':'roc_auc'].isnull().all(axis=1)]\ndupl = results.duplicated(subset=[\"C\",\t\"penalty\", \"solver\", \"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_auc\",\n                                  \"train accuracy\", \"train f1\", \"train precision\", \"train recall\", \"train roc_auc\"], keep=\"first\")\nresults = results[~dupl]\nresults","ec525baa":"results.sort_values(\"accuracy\", ascending=False).head(10)","85ebaf03":"results.sort_values(\"f1\", ascending=False).head(10)","05d1bada":"results.sort_values(\"roc_auc\", ascending=False).head(10)","21601233":"gs.best_params_","1f4d8454":"gs.best_score_","574436c7":"gs.best_estimator_","dcce23d0":"# **6.2**","c8194d90":"\u0421\u043b\u0430\u0431\u0430\u044f \u0432\u044b\u043f\u0443\u043a\u043b\u043e\u0441\u0442\u044c, \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u0438 \u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u043e\u0442 \u0442\u043e\u0447\u043a\u0438 (0, 1) \u0434\u043e \u0433\u0440\u0430\u0444\u0438\u043a\u0430 \u0442\u0430\u043a\u0436\u0435 \u0433\u043e\u0432\u043e\u0440\u0438\u0442 \u043e \u043a\u0440\u043e\u0445\u043e\u0442\u043d\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 (\u0447\u0443\u0442\u044c \u043b\u0443\u0447\u0448\u0435 \u0447\u0435\u043c \u043c\u043e\u043d\u0435\u0442\u043a\u0443 \u043f\u043e\u0434\u043a\u0438\u0434\u044b\u0430\u0432\u0442\u044c)","0384eb57":"\u0422\u0430\u043a \u043a\u0430\u043a \u0440\u0430\u0437\u043d\u044b\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u044b \u043d\u0435 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0435\u0442\u043e\u0434\u0430\u043c\u0438 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438, \u043d\u0430 \u043d\u0435\u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u044b\u0445 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u044f\u0445 \u0440\u0430\u0441\u0447\u044f\u0451\u0442\u044b \u043d\u0435 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043b\u0438\u0441\u044c \u0438 \u043d\u0430 \u043f\u0440\u043e\u0442\u0438\u0432 \u043c\u0435\u0442\u0440\u0438\u043a \u0441\u0442\u043e\u044f\u0442 NaN. \u0422\u0430\u043a\u0438\u0435 \u0441\u0442\u0440\u043e\u043a\u0438 \u0441\u0442\u043e\u0438\u0442 \u0443\u0434\u0430\u043b\u0438\u0442\u044c","a7cc3e12":"\u041d\u0435\u0431\u043e\u043b\u044c\u0448\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043f\u043e\u0434 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u043c \u0438 \u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u0440\u0430\u0441\u0441\u0442\u043e\u044f\u043d\u0438\u0435 \u0434\u043e \u0442\u043e\u0447\u043a\u0438 (1, 1) \u0433\u043e\u0432\u043e\u0440\u0438\u0442 \u043e \u0441\u043b\u0430\u0431\u043e\u0441\u0442\u0438 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438****","02599fe0":"\u041f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u0440\u043e\u0441\u0442\u0430 \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043d\u0435 \u043f\u0440\u0438\u043d\u0451\u0441. \u041f\u0440\u0438\u0440\u043e\u0441\u0442 <1%. \u041f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0442\u043e\u0436\u0435 \u043d\u0435 \u043d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f.\n\u041c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434 \u0447\u0442\u043e \u043b\u0438\u0431\u043e \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u043d\u0435 \u043f\u043e\u0434\u0445\u043e\u0434\u0438\u0442 \u043f\u043e\u0434 \u0434\u0430\u043d\u043d\u0443\u044e \u0437\u0430\u0434\u0430\u0447\u0443, \u043b\u0438\u0431\u043e \u043a\u043b\u0430\u0441\u0441\u044b \u0432 \u0446\u0435\u043b\u043e\u043c \u0441\u043b\u0430\u0431\u043e \u0437\u0430\u0432\u0438\u0441\u044f\u0442 \u043e\u0442 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432","d7486d9d":"\u0420\u0435\u0439\u0442\u0438\u043d\u0433 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u043e\u0432","22b92ca8":"\u041f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u0438\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432 \u0432\u0438\u0434\u0435 \u0442\u0430\u0431\u043b\u0438\u0446\u044b \u0434\u043b\u044f \u0431\u043e\u043b\u0435\u0435 \u043d\u0430\u0433\u043b\u044f\u0434\u043d\u043e\u0433\u043e \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0438 \u0443\u043f\u0440\u043e\u0449\u0435\u043d\u0438\u044f \u043f\u043e\u0441\u0442\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438"}}