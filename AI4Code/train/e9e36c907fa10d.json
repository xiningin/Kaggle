{"cell_type":{"c2df70cc":"code","5f2a53eb":"code","43f031be":"code","6e8db19a":"code","3aca4237":"code","54b99b06":"code","5bcac058":"code","8745c5cb":"code","6f01739a":"code","1f30ca38":"code","647e3b02":"code","028ffa73":"code","699bf0d5":"code","a5111adb":"code","1d28e169":"code","7aa7567a":"code","79004dce":"code","5b1e8e25":"code","691ded89":"code","a3f421c9":"code","5f35de0e":"code","c2add69a":"code","d1de7c2e":"code","29dc01d6":"code","e90dc64a":"code","0201bac3":"code","b6d4aa69":"code","37d3a1ef":"code","03cd5407":"code","6a63aab7":"code","6146c973":"code","536ed951":"code","5751d103":"code","1aade1a0":"code","1abf919a":"code","b849b2cb":"code","9b496fe7":"code","225a4923":"code","36cac9b5":"code","7d4db10f":"code","e35dbe74":"code","421524c9":"code","200210b3":"code","f66ffd89":"code","b944f239":"code","7d1e8436":"code","c8ac4616":"code","f80054f0":"code","a2035def":"code","905a69da":"code","427556ff":"code","404d27cf":"code","7363c18e":"markdown","1ba3d6d7":"markdown","0b13703a":"markdown","e03a6eaa":"markdown","d335ad80":"markdown","408df14c":"markdown","398e8b2a":"markdown","6e7d060b":"markdown","9133277d":"markdown","6f0d0895":"markdown","934f68c2":"markdown","9dabdb7e":"markdown","4ca7e95e":"markdown"},"source":{"c2df70cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f2a53eb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\n%matplotlib inline\nimport warnings as wr\nwr.filterwarnings('ignore')\n","43f031be":"df=pd.read_csv(\"..\/input\/loan-application-data\/df1_loan.csv\")\ndf.head()","6e8db19a":"df.shape","3aca4237":"df.describe().T.style.bar(subset=[\"mean\"],color=\"#606ff2\").background_gradient(subset=[\"std\"],cmap=\"PuBu\").background_gradient(subset=[\"50%\"],cmap=\"PuBu\")","54b99b06":"df.tail()\n","5bcac058":"#df.columns=[column.replace(\" \",\"_\") for column in df.columns]\ndf=df.drop([\"Unnamed: 0\",\"Loan_ID\"],axis=1)","8745c5cb":"#removing doller sign from Total_Income column\ndf['Total_Income']=df['Total_Income'].str.replace('$','')","6f01739a":"df[\"Total_Income\"]=df[\"Total_Income\"].apply(pd.to_numeric)","1f30ca38":"#removing + sign from dependents column\ndf['Dependents']=df['Dependents'].str.replace('+','')","647e3b02":"df[\"Dependents\"]=df[\"Dependents\"].apply(pd.to_numeric)","028ffa73":"plt.figure(figsize=(20,6))\nsns.heatmap(df.isnull(),yticklabels=False,cbar=True,cmap='mako')","699bf0d5":"df.isnull().sum()","a5111adb":"total_null = df.isnull().sum().sort_values(ascending=False) #First sum and order all null values for each variable\npercentage = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False) #Get the percentage\nmissing_data = pd.concat([total_null, percentage], axis=1, keys=['Total', 'Percentage'])\nmissing_data.head()","1d28e169":"num_col=df._get_numeric_data().columns.tolist()\nnum_col","7aa7567a":"cat_col=set(df.columns)-set(num_col)\ncat_col\n","79004dce":"for col in num_col:\n    df[col].fillna(df[col].mean(),inplace=True)","5b1e8e25":"for col in cat_col:\n\n    df[col].fillna(df[col].mode()[0],inplace=True)","691ded89":"df.isnull().sum()","a3f421c9":"df.duplicated().sum()","5f35de0e":"plt.figure(figsize=(12,6))\nax=plt.axes()\nax.set_facecolor(\"green\")\nfor i in cat_col:\n    sns.countplot(df[i])","c2add69a":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True,cmap=\"tab20c\")\nplt.show()","d1de7c2e":"#ApplicantIncome analysis\n\nsns.distplot(df['ApplicantIncome']);\nprint(\"Skewness coeff. is: %f\" % df['ApplicantIncome'].skew())\nprint(\"Kurtosis coeff. is: %f\" % df['ApplicantIncome'].kurt())","29dc01d6":"#CoapplicantIncome analysis\n\nsns.distplot(df['CoapplicantIncome']);\nprint(\"Skewness coeff. is: %f\" % df['CoapplicantIncome'].skew())\nprint(\"Kurtosis coeff. is: %f\" % df['CoapplicantIncome'].kurt())","e90dc64a":"sns.kdeplot(data=df,x='ApplicantIncome',hue=\"Gender\",fill=True,common_norm=False,palette=\"husl\")","0201bac3":"x=df.drop([\"Loan_Status\"],axis=1)\ny=df[\"Loan_Status\"]\nx.head()","b6d4aa69":"X=pd.get_dummies(x)\nX.columns","37d3a1ef":"from sklearn.preprocessing import LabelBinarizer\nlb = LabelBinarizer()\ny=lb.fit_transform(y)\n\n","03cd5407":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.30,random_state=10)","6a63aab7":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\n\nlr.fit(X_train,y_train)","6146c973":"from sklearn.svm import SVC\nsvc = SVC()\n\nsvc.fit(X_train, y_train)\n","536ed951":"from sklearn.tree import DecisionTreeClassifier\ndtf = DecisionTreeClassifier()\ndtf.fit(X_train, y_train)","5751d103":"from sklearn.naive_bayes import GaussianNB\nn_b = GaussianNB()\nn_b.fit(X_train, y_train)","1aade1a0":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()  \nknn.fit(X_train, y_train)","1abf919a":"print(lr.score(X_test, y_test))\nprint(dtf.score(X_test, y_test))\nprint(n_b.score(X_test, y_test))\nprint(knn.score(X_test, y_test))\nprint(svc.score(X_test, y_test))","b849b2cb":"from sklearn.metrics import confusion_matrix \ny_predict=lr.predict(X_test)\nresults = confusion_matrix(y_test, y_predict)\nfrom sklearn.metrics import confusion_matrix \ny_predict=lr.predict(X_test)\nresults = confusion_matrix(y_test, y_predict) \nprint('Confusion Matrix :')\nprint(results)\n\nprint('Confusion Matrix :')\nprint(results)\n\n","9b496fe7":"print(lr.predict_proba(X_test[0:5]))","225a4923":"from sklearn.metrics import roc_curve, auc,roc_auc_score\nfpr,tpr,threshold = roc_curve(y_test,lr.predict_proba(X_test)[:,1])\nfpr1,tpr1,threshold1 = roc_curve(y_test,knn.predict_proba(X_test)[:,1])\n","36cac9b5":"fpr","7d4db10f":"tpr","e35dbe74":"threshold","421524c9":"roc_auc=roc_auc_score(y_test,lr.predict(X_test))\nroc_auc1=roc_auc_score(y_test,knn.predict(X_test))\n","200210b3":"roc_auc1","f66ffd89":"import matplotlib.pyplot as plt\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw,label='ROC curve (area = %0.2f)' % roc_auc)\n\nplt.plot(fpr1, tpr1, color='blue',\n         lw=lw,label='ROC curve (area = %0.2f)' % roc_auc1)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.1])\nplt.ylim([0.0, 1.1])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","b944f239":"y_predict=lr.predict_proba(X_test)\ny_predict","7d1e8436":"\nfrom sklearn.preprocessing import binarize\n\ny_pred_class=binarize(y_predict,0.60)\n#y_pred_class","c8ac4616":"y_pred_class1=y_pred_class[:,1]\ny_pred_class1","f80054f0":"y_pred=y_pred_class1.astype(int)\ny_pred","a2035def":"from sklearn.metrics import confusion_matrix \nresults = confusion_matrix(y_test, y_pred) \nprint('Confusion Matrix :')\nprint(results)\n\n","905a69da":"y_pred_class=binarize(y_predict,0.70)\ny_pred_class1=y_pred_class[:,1]\ny_pred=y_pred_class1.astype(int)\nresults = confusion_matrix(y_test, y_pred) \nprint('Confusion Matrix :')\nprint(results)","427556ff":"from sklearn.ensemble import RandomForestClassifier\n\nrfc=RandomForestClassifier()\nrfc.fit(X_train,y_train)\n\ny_pred=rfc.predict(X_test)\nprint(rfc.score(X_test, y_test))\n\n","404d27cf":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","7363c18e":"* Here we can see there are two unnessary column (unnamed: 0 and Loan_ID) \n* so we remove them","1ba3d6d7":"* Now we can see there are min missing values so we need to fill them\n* **Finding numeric column**","0b13703a":"### roc_curve, auc,roc_auc_score","e03a6eaa":"# Model Buliding","d335ad80":"## finding cat column","408df14c":"* Here we can see there are many featuers have NaN values.\n* Now we fill all the missing values using pandas fill na \n### Now we print percentage of null values","398e8b2a":"# Data Preposesing\n","6e7d060b":"# *Thank YOU*","9133277d":"* Here we find zero duplicated values\n## Now finding correlation","6f0d0895":"## Checking for Duplicate","934f68c2":"## Filling categorical missing values","9dabdb7e":"## Dealing with null values\nNow our goal is to deal with null values and try to understand for each one what can we do: maybe we can replace them or maybe we can just skip them.","4ca7e95e":"## Filling numerical missing values"}}