{"cell_type":{"9a637723":"code","7950127d":"code","fbc679f5":"code","054c8c0d":"code","e027aaa8":"code","ecf5bea4":"code","8e1c2176":"code","43164887":"code","cbbcc784":"code","3d564e38":"code","4c8b7145":"markdown","ce8097d2":"markdown","edca00f5":"markdown","f53f805b":"markdown","e5976183":"markdown","58dfe231":"markdown"},"source":{"9a637723":"#Importing Libraries\nimport torch\n# Assign Device \ncuda0 = torch.device(\"cuda:0\")","7950127d":"x = torch.tensor([5],dtype=torch.float32,requires_grad=True)\ny = torch.tensor([6],dtype=torch.float32,requires_grad=True)\nprint(x)\nprint(y)","fbc679f5":"#defining the function\nz = ((x**2)*y) + (x*y)\nprint(z)","054c8c0d":"#Using autograd\n# Autograd to be applied on Scalars\ntotal = torch.sum(z) # Converting to scalar\ntotal","e027aaa8":"print(x.grad,y.grad)","ecf5bea4":"total.backward() # to call grad function we need to call .backward() if not it will show as None","8e1c2176":"print(\"Def with resp. to  x   :\",x.grad)\nprint(\"Def with resp. to  y   :\",y.grad)","43164887":"x = torch.randint(-100,100,(100,), dtype = torch.float32 , device = cuda0)\ny = (1.32*x) + 25                       # y = (w*x) + b     we are going to predict w & b","cbbcc784":"w = torch.ones(1,requires_grad = True, device = cuda0 )\nb = torch.ones(1,requires_grad = True, device = cuda0 ) \ny_hat = (w*x) + b\n\nepochs = 10000\nlr = 0.000001","3d564e38":"count = 0\nfor i in range(epochs):\n  loss = torch.sum((y_hat - y)**2) \n  loss.backward() \n  #w -= lr*w.grad --> this will be considered as relationship\n  with torch.no_grad(): # this will switch off gradients\n\n    w -= lr*w.grad\n    b -= lr*b.grad\n    count += 1\n    #setting gradients to be zero\n    w.grad.zero_()\n    b.grad.zero_() \n  \n  y_hat = (w*x ) + b\n\nprint(count)\nprint(\"Predicted w value  :\",w.item())\nprint(\"Predicted b value  :\",b.item())","4c8b7145":"# PyTorch Tutorials\n\n\nPyTorch is the premier open-source deep learning framework developed and maintained by Facebook.\n\nAt its core, PyTorch is a mathematical library that allows you to perform efficient computation and automatic differentiation on graph-based models. Achieving this directly is challenging, although thankfully, the modern PyTorch API provides classes and idioms that allow you to easily develop a suite of deep learning models.\n\n1. [PyTorch Tutorial - 1 (Basic)](https:\/\/www.kaggle.com\/anandsubbu007\/pytorch-basics-tutorial-1)\n2. [PyTorch Tutorial - 2 (Autograd)](https:\/\/www.kaggle.com\/anandsubbu007\/pytorch-autograd-tutorial-2)\n3. [PyTorch Tutorial - 3 (Deep Neural Network)](https:\/\/www.kaggle.com\/anandsubbu007\/deep-nn-pytorch-tutorial-3)\n4. [PyTorch Tutorial - 3 (CNN-CIFAR10)](https:\/\/www.kaggle.com\/anandsubbu007\/cnn-cifar10-pytorch-tutorial-4)","ce8097d2":"# Autograd","edca00f5":"Finding Deferintial for x & y\n\n    z = (x^2)*y + xy\n      = (5^2 * 6) + 5*6\n      = 180\n\n    dz\/dx = 2xy + y\n          = (2 * 5 * 6) + 6\n          = 66\n\n    dz\/dy = x^2 + x\n          = 5^2 + 5\n          = 30","f53f805b":"<a href=\"https:\/\/colab.research.google.com\/github\/anandsubbu007\/Pytorch-Tutorial-Beginner\/blob\/master\/Pytorch_Autograd_2.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","e5976183":"## Differential in Pytorch","58dfe231":"# Implementing Autograd"}}