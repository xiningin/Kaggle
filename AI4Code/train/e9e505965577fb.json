{"cell_type":{"03ebe871":"code","2fd30010":"code","b64378fd":"code","251076ed":"code","0fc0f2d5":"code","17aa0f38":"code","3a0d4e16":"code","c6a9a715":"code","a4f5c4b4":"code","1ee3e662":"code","ad603419":"code","e4e83321":"code","ca784500":"code","49d13f88":"code","11dcfd5f":"code","5b9813a2":"code","af0e2807":"code","7888221d":"code","2b1d34e9":"code","5a34d7c9":"code","9f4b2449":"code","1971c605":"code","87bf9fde":"code","fbe2f593":"code","94c29d13":"code","2efa2405":"code","4c18ac23":"code","0da21f81":"code","4687fda3":"code","9c679e97":"code","72558390":"code","4f1a7370":"code","db84dadc":"code","cc127df2":"code","ca1e48c7":"code","dbc3339a":"code","03460ce9":"code","41cca418":"code","05fd27ec":"code","33cdc1a3":"code","1fab57e6":"code","1ac64ad4":"code","64a8472e":"code","8cb9c317":"code","f0c5b9a6":"code","bd0e6f7f":"code","6fcd567b":"code","11b80f4b":"code","5d0f3464":"markdown","7597ecc4":"markdown","75d8e91d":"markdown","83d10515":"markdown","8130ae35":"markdown","0294b460":"markdown"},"source":{"03ebe871":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pathlib import Path\nimport cv2\nimport os\nimport glob\nimport random\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, f1_score,classification_report\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n","2fd30010":"train_dir = Path('..\/input\/10-monkey-species\/training\/training\/')\ntest_dir = Path('..\/input\/10-monkey-species\/validation\/validation\/')","b64378fd":"monkey_labels = pd.read_csv('..\/input\/10-monkey-species\/monkey_labels.txt')\nmonkey_labels","251076ed":"monkey_labels.info","0fc0f2d5":"## using lambda function to remove white spaces:\n\nmonkey_labels[\"Label\"] = monkey_labels[\"Label\"].apply(lambda x: x.replace(\" \",\"\"))\nmonkey_labels[' Common Name                   '] = monkey_labels[' Common Name                   '].apply(lambda x: x.replace(\" \",\"\"))","17aa0f38":"labels_list = list(monkey_labels[\"Label\"])\ncommon_names_list = list(monkey_labels[' Common Name                   '])","3a0d4e16":"labels_list","c6a9a715":"common_names_list","a4f5c4b4":"class_names = labels_list","1ee3e662":"for dir_path, folder, files in os.walk(train_dir):\n    print(f\"There are {len(folder)} directories and {len(files)} images in '{dir_path}'.\")","ad603419":"image_count = len(list(train_dir.glob(\"*\/*\")))                                                \nprint(\"Number_of_Training_Images_Is:\",image_count)","e4e83321":"list_ds = tf.data.Dataset.list_files(str(train_dir\/\"*\/*\"),shuffle=False)\nlist_ds = list_ds.shuffle(image_count,reshuffle_each_iteration=False)\n","ca784500":"##splitting our dataset (train=80% && Test=20%)\ntest_size = int(image_count*0.2)\ntrain_ds = list_ds.skip(test_size)\ntest_ds = list_ds.take(test_size)","49d13f88":"def get_label(file_path):\n    \n    ## converts file_path into parts\n    file_path_parts = tf.strings.split(file_path,os.path.sep)\n    \n    ## the second last part is our label and we are comparing it with class_names list\n    one_hot = file_path_parts[-2] == class_names  ## we ll get one hot result\n    \n    return tf.argmax(one_hot)   ## will return index where value is max(that is 1) in one_hot\n\ndef decode_img(img):\n    \n    img = tf.image.decode_jpeg(img,channels=3)\n    return tf.image.resize(img,[180,180]) \n\ndef process_path(file_path):\n    \n    label = get_label(file_path)     ## get label using the 1st function\n    img = tf.io.read_file(file_path)    ## read image from file_path\n    img = decode_img(img)              ## decode image using 2nd function\n    \n    return img,label\n\n","11dcfd5f":"AUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.map(process_path,num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(process_path,num_parallel_calls=AUTOTUNE)","5b9813a2":"def optimize_performance(ds):\n    \n    ds = ds.cache()\n    ds = ds.shuffle(buffer_size = 879) \n    ds = ds.batch(32)\n    ds = ds.prefetch(buffer_size = AUTOTUNE) ##\n    return ds  \n\ntrain_ds = optimize_performance(train_ds)\ntest_ds = optimize_performance(test_ds)","af0e2807":"for image, label in train_ds.take(1):\n    print(f'Image shape: {image.shape}')\n    print(f'Image label: {label}')","7888221d":"\nimage_batch, label_batch = next(iter(train_ds)) \n\nplt.figure(figsize=(12,8))\nfor i in range(9):\n    ax = plt.subplot(3,3,i+1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = label_batch[i]\n    plt.title(class_names[label] + \" : \"+common_names_list[label])\n    plt.axis(\"off\")","2b1d34e9":"generate_train_data = ImageDataGenerator(rescale=1.\/255)\ntrain_generator = generate_train_data.flow_from_directory(train_dir,target_size=(60,60),batch_size=32,class_mode='categorical') \n\n\ngenerate_test_data = ImageDataGenerator(rescale=1.\/255)\ntest_generator = generate_test_data.flow_from_directory(test_dir,target_size=(60,60),batch_size=32,class_mode='categorical')","5a34d7c9":"model =Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(60,60,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(60,60,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation='relu'))\n\nmodel.add(Dense(10,activation='softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","9f4b2449":"model.summary()\n","1971c605":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=2)\n","87bf9fde":"model.fit_generator(train_generator, epochs = 10 , validation_data=train_generator,callbacks = early_stop,verbose = 1)","fbe2f593":"losse = pd.DataFrame(model.history.history)\nlosse","94c29d13":"losse[['accuracy','val_accuracy']].plot()","2efa2405":"losse[['loss','val_loss']].plot()","4c18ac23":"model2 =Sequential()\nmodel2.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(60,60,3),activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\n\nmodel2.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(60,60,3),activation='relu'))\nmodel2.add(MaxPool2D(pool_size=(2,2)))\n\n\nmodel2.add(Flatten())\n\nmodel2.add(Dense(128,activation='relu'))\n\nmodel2.add(Dense(10,activation='softmax'))\n\nmodel2.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","0da21f81":"model2.fit_generator(train_generator, epochs = 10 , validation_data=test_generator,callbacks = early_stop,verbose = 1)","4687fda3":"losse2 = pd.DataFrame(model2.history.history)\nlosse2","9c679e97":"losse2[['accuracy','val_accuracy']].plot()","72558390":"losse2[['loss','val_loss']].plot()","4f1a7370":"val_dir = \"..\/input\/10-monkey-species\/validation\/validation\/\"","db84dadc":"validation_data = tf.keras.preprocessing.image_dataset_from_directory(val_dir,\n                                                                label_mode=\"categorical\",\n                                                                image_size=(60,60),\n                                                                shuffle=False) ","cc127df2":"pred_probs = model.predict(validation_data,verbose=1)\npred_probs2 = model2.predict(validation_data,verbose=1)","ca1e48c7":"len(pred_probs)\n","dbc3339a":"pred_probs.shape\n","03460ce9":"pred_probs","41cca418":"pred_probs2","05fd27ec":"pred_probs[:50].max()\n","33cdc1a3":"pred_probs2[:10].max()","1fab57e6":"pred_classes = pred_probs.argmax(axis=1)\npred_classes[:7]\n","1ac64ad4":"pred_classes2 = pred_probs2.argmax(axis=1)\npred_classes2[:20]","64a8472e":"y_labels = []\nfor image, label in validation_data.unbatch():\n    y_labels.append(label.numpy().argmax())\ny_labels[:20]","8cb9c317":"\ndef load_prepare_image(file_name,scale=True):\n    \n    img = tf.io.read_file(file_name)\n    img = tf.io.decode_image(img)\n    img = tf.image.resize(img,[120,120])\n    \n    if scale:\n        return img\/255.\n    else:\n        return img","f0c5b9a6":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_labels,pred_classes))","bd0e6f7f":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_labels,pred_classes2))","6fcd567b":"classification_report_dict = classification_report(y_labels,pred_classes,output_dict=True)\nclassification_report_dict\n\nf1_scores = {}\n\nfor k,v in classification_report_dict.items():\n    if k == \"accuracy\":\n        break\n    else:\n        f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n\nf1_scores","11b80f4b":"classification_report_dict2 = classification_report(y_labels,pred_classes2,output_dict=True)\nclassification_report_dict2\n\nf1_scores2 = {}\n\nfor k,v in classification_report_dict2.items():\n    if k == \"accuracy\":\n        break\n    else:\n        f1_scores2[class_names[int(k)]] = v[\"f1-score\"]\n\nf1_scores2","5d0f3464":"_____________________\n**`Ola El-Shiekh ||| Samsung Innovation Campus`** ","7597ecc4":"# Reading Data","75d8e91d":"# IMG_Generation","83d10515":"# MODELLING","8130ae35":"# Data Preprocessin","0294b460":"# Prediction&Evaluation"}}