{"cell_type":{"f9774879":"code","ff54b298":"code","28b048e6":"code","af3e81cc":"code","da4dbc29":"code","98f44c58":"code","0afdeeca":"code","fae88328":"code","27cda94e":"code","2225b549":"code","12d97e4c":"code","75ab4ba3":"code","bd5b3e09":"code","aec7a057":"code","78e91060":"markdown","a5ce272b":"markdown","366123c8":"markdown","4a1c20d9":"markdown","7830d2a4":"markdown","c9318ae8":"markdown","7db64f66":"markdown","46a1024c":"markdown","19eb1b1d":"markdown","b1fb1718":"markdown","9ca91d5d":"markdown","dca4a6e2":"markdown"},"source":{"f9774879":"# import standard libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\n\n# hide warnings for cleaner output (there were some regarding indexing not using pandas .loc reference)\nimport warnings\nwarnings.filterwarnings('ignore')","ff54b298":"# read in data (provided via course website), week 1\ndata_dir = '\/kaggle\/input\/covid19-global-forecasting-week-1'\nwk1_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\nwk1_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n\n# extract geocode, use average location\ngc = wk1_train[['Country\/Region', 'Lat', 'Long']]\ngc = gc.groupby('Country\/Region').mean().reset_index()","28b048e6":"# read in data (provided via course website), week 2\ndata_dir = '\/kaggle\/input\/covid19-global-forecasting-week-2'\nwk2_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\nwk2_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n\n# make heading consistent with week1\nwk2_train.columns = list(wk1_train.columns[:3]) + list(wk2_train.columns[3:])\nwk2_test.columns = list(wk1_test.columns[:3]) + list(wk2_test.columns[3:])\n\n# add geocode to week 2\nwk2_train = wk2_train.merge(gc, on='Country\/Region')\nwk2_test = wk2_test.merge(gc, on='Country\/Region')\n","af3e81cc":"# daily visualization\n# Note: resource intensive\n\ncases = wk2_train[['Country\/Region', 'Lat', 'Long', 'Date', 'ConfirmedCases', 'Fatalities']]\ncases_melt = pd.melt(cases, id_vars = ['Country\/Region', 'Lat', 'Long', 'Date'])\n\nfig = px.scatter_geo(cases_melt, lat = 'Lat', lon = 'Long', \n                     size = 'value', color = 'variable', \n                     animation_frame='Date', projection = 'natural earth')\nfig.show()","da4dbc29":"# visualizing the cases by date for hot spots: China, Italy, Spain, US\n# these should represent the major topics that are in the news in recent days\ncases_by_date = wk2_train[['Country\/Region', 'Date', 'ConfirmedCases', 'Fatalities']]\ncountries = ['China', 'Italy', 'Spain', 'US']\ncases_by_date = cases_by_date[cases_by_date['Country\/Region'].isin(countries) ]\ncases_by_date = cases_by_date.groupby(['Country\/Region', 'Date']).sum().reset_index()\n\ncases_by_date_melt = pd.melt(cases_by_date, id_vars=['Country\/Region', 'Date'])\n\nfig = px.line(cases_by_date_melt, x = 'Date', y = 'value', color='Country\/Region', facet_col='variable')\nfig.show()","98f44c58":"# does the fatalitiy rate increase? decrease? remain steady?\nfatalities_ratio = cases_by_date['Fatalities'] \/ cases_by_date['ConfirmedCases']\nfatalities_ratio.name = 'Fatalities Ratio'\nfatalities_ratio = cases_by_date[['Date', 'Country\/Region']].join(fatalities_ratio)\nfig = px.line(fatalities_ratio, x = 'Date', y = 'Fatalities Ratio', color = 'Country\/Region')\nfig.show()","0afdeeca":"# evaluating the mean number of cases globally\nmean_cases_by_date = cases_by_date_melt.groupby(['Date', 'variable']).mean().reset_index()\nstd_cases_by_date = cases_by_date_melt.groupby(['Date', 'variable']).std().reset_index()\n\nmean_cases_by_date['std'] = std_cases_by_date['value']\n\nfig = px.scatter(mean_cases_by_date, x='Date', y='value', facet_col='variable')\nfig.show()","fae88328":"# looking at the standard deviation of the average\nfig = px.scatter(mean_cases_by_date, x='Date', y='std', facet_col='variable')\nfig.show()","27cda94e":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\n\n# Note on RMSLE (root mean squrared log error) https:\/\/www.kaggle.com\/questions-and-answers\/60012\nfrom sklearn.metrics import mean_squared_log_error\n\n# method for evaluating both the linear (with log transformation) and logistic fit\ndef regressions(train_X, train_y, test_X, test_y):\n    # linear regression (with log transformation)\n    lin_reg = LinearRegression().fit(train_X, np.log1p(train_y))\n    lin_train_RMSLE = np.sqrt(mean_squared_log_error(train_y, np.exp(lin_reg.predict(train_X))))\n    lin_test_RMSLE = np.sqrt(mean_squared_log_error(test_y, np.exp(lin_reg.predict(test_X))))\n    print('Linear regresion (with log transformation) train RMSLE: ' + str(lin_train_RMSLE))\n    print('Linear regresion (with log transformation) test RMSLE: ' + str(lin_test_RMSLE))\n    print(' ')\n    \n    # logistic regression\n    logistic_reg = LogisticRegression(max_iter=500).fit(train_X, train_y)\n    logistic_train_RMSLE = np.sqrt(mean_squared_log_error(train_y, logistic_reg.predict(train_X)))\n    logistic_test_RMSLE = np.sqrt(mean_squared_log_error(test_y, logistic_reg.predict(test_X)))\n    print('Logistic regression train RMSLE: ' + str(logistic_train_RMSLE))\n    print('Logistic regression test RMSLE: ' + str(logistic_test_RMSLE))\n    print(' ')\n    \n    # tying the data sets together and return an output\n    day = train_X.append(test_X)['days']\n    actual = train_y.append(test_y)\n    exp_predictions = pd.Series(np.exp(lin_reg.predict(train_X.append(test_X))))\n    exp_predictions.index = day.index\n    logistic_predictions = pd.Series(logistic_reg.predict(train_X.append(test_X)))\n    logistic_predictions.index = day.index\n    \n    df = pd.DataFrame({'day':day,\n                      'actual':actual,\n                      'exp_predictions':exp_predictions,\n                      'logistic_predictions': logistic_predictions})\n    return df\n    \n","2225b549":"US_train = wk1_train[wk1_train['Country\/Region'] == 'US']\n\n# set start data day before first case\nstart_date_index = (US_train['ConfirmedCases'] != 0).idxmax() - 27\n\n# alternative method of setting start date\n# start_date_index = (US_train['ConfirmedCases'] >= 100).idxmax() \nstart_date = pd.Timestamp(US_train.loc[start_date_index, 'Date'])\n\nUS_start_date = start_date\n\nUS_train['days'] = (US_train['Date'].apply(pd.Timestamp) - start_date).dt.days\nUS_train = US_train.groupby('days').sum()[['ConfirmedCases']].reset_index()\nUS_train = US_train[US_train['days'] >= 0]\n\nUS_test = wk2_train[wk2_train['Country\/Region'] == 'US']\nUS_test['days'] = (US_test['Date'].apply(pd.Timestamp) - start_date).dt.days\nUS_test = US_test.groupby('days').sum()[['ConfirmedCases']].reset_index()\nUS_test = US_test[US_test['days'] >= 0]\n\n# subset for Mar 24, 25, 26\nday_delta = (pd.Timestamp('2020-03-24') - start_date).days\nday_delta_end = (pd.Timestamp('2020-03-26') - start_date).days\nUS_test = US_test[(US_test['days'] >= day_delta) & (US_test['days'] <= day_delta_end)] \n\ndf = regressions(US_train[['days']], US_train['ConfirmedCases'], US_test[['days']], US_test['ConfirmedCases'])\ndf_melt = pd.melt(df, id_vars='day')\nfig = px.line(df_melt, x='day', y='value', color='variable')\nfig.show()","12d97e4c":"China_train = wk1_train[wk1_train['Country\/Region'] == 'China']\n\n# define start date (no offset needed since China data starts with a postive ConfirmedCase)\nstart_date = pd.Timestamp(wk1_train['Date'].min())\n\nChina_start_date = start_date\n\nChina_train['days'] = (China_train['Date'].apply(pd.Timestamp) - start_date).dt.days\nChina_train = China_train.groupby('days').sum()[['ConfirmedCases']].reset_index()\nChina_train = China_train[China_train['days'] >= 0]\n\nChina_test = wk2_train[wk2_train['Country\/Region'] == 'China']\nChina_test['days'] = (China_test['Date'].apply(pd.Timestamp) - start_date).dt.days\nChina_test = China_test.groupby('days').sum()[['ConfirmedCases']].reset_index()\nChina_test = China_test[China_test['days'] >= 0]\n\n# subset for Mar 24, 25, 26\nday_delta = (pd.Timestamp('2020-03-24') - start_date).days\nday_delta_end = (pd.Timestamp('2020-03-31') - start_date).days\nChina_test = China_test[(China_test['days'] >= day_delta) & (China_test['days'] <= day_delta_end)] \n\n\ndf = regressions(China_train[['days']], China_train['ConfirmedCases'], China_test[['days']], China_test['ConfirmedCases'])\ndf_melt = pd.melt(df, id_vars='day')\nfig = px.line(df_melt, x='day', y='value', color='variable')\nfig.show()","75ab4ba3":"# using previous algorithm to predict future (wk3)\ndata_dir = '\/kaggle\/input\/covid19-global-forecasting-week-4'\nwk4_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))","bd5b3e09":"# using the same start date as previous part (week 2)\nstart_date = US_start_date\n\nUS_test = wk4_train[wk4_train['Country_Region'] == 'US']\nUS_test['days'] = (US_test['Date'].apply(pd.Timestamp) - US_start_date).dt.days\nUS_test = US_test.groupby('days').sum()[['ConfirmedCases']].reset_index()\nUS_test = US_test[US_test['days'] >= 0]\n\n# subset for Mar 24 - 31\nday_delta = (pd.Timestamp('2020-03-24') - start_date).days\nday_delta_end = (pd.Timestamp('2020-03-31') - start_date).days\nUS_test = US_test[(US_test['days'] >= day_delta) & (US_test['days'] <= day_delta_end)] \n\n# get results and graph\ndf = regressions(US_train[['days']], US_train['ConfirmedCases'], US_test[['days']], US_test['ConfirmedCases'])\ndf_melt = pd.melt(df, id_vars='day')\nfig = px.line(df_melt, x='day', y='value', color='variable')\nfig.show()","aec7a057":"# using the same start date as previous part (week 2)\nstart_date = China_start_date\n\nChina_test = wk4_train[wk4_train['Country_Region'] == 'China']\nChina_test['days'] = (China_test['Date'].apply(pd.Timestamp) - start_date).dt.days\nChina_test = China_test.groupby('days').sum()[['ConfirmedCases']].reset_index()\nChina_test = China_test[China_test['days'] >= 0]\n\n# subset for Mar 24 - 31\nday_delta = (pd.Timestamp('2020-03-24') - start_date).days\nday_delta_end = (pd.Timestamp('2020-03-31') - start_date).days\nChina_test = China_test[(China_test['days'] >= day_delta) & (China_test['days'] <= day_delta_end)] \n\ndf = regressions(China_train[['days']], China_train['ConfirmedCases'], China_test[['days']], China_test['ConfirmedCases'])\ndf_melt = pd.melt(df, id_vars='day')\nfig = px.line(df_melt, x='day', y='value', color='variable')\nfig.show()","78e91060":"From the visual exploration above, the trends seemed to have followe two distinct patters: 1) China, more of an \"S\" shape where it tapers off towards the latter half and 2) US, where it seemed to follow an exponential growth. Spin and Italy aalso followed a similar path to US (exponential). Therefore, 2 models will be explored, one for exponenential and one for logistic\n","a5ce272b":"# problem 2-4","366123c8":"# Affiliation: Whiting School of Engineering, Johns Hopkins University (685.621) Programming Assignment 2 - Problem 2","4a1c20d9":"# problem 2-3","7830d2a4":"Based on the above regression, there are two key tuning parameters that can be modified to make the model better. For exponential regression, defining the start day (day 0) can have a dramatic impact on the fit (see US data). Since China effectively started at the beginning of the data set, no offset for the start date was necessary. For the logistic regression, the number of iteration can make the fit better.","c9318ae8":"# problem 2-2","7db64f66":"Based on the analysis above, it suggests different country follows a differetn infection growth rate. For example, China's confirmed cases has tapered off where as in other countries it may still be growing rapidly. The realtively death rate alos follow a different rate, with Spain and Italy increasing over time where as China and US remaining fairly staganant.","46a1024c":"# problem 2-5","19eb1b1d":"Based on the results above, the exponential growth graph was too fast, the actual results for US lagged behind the theoritical exponential curve. Which is good, the social distancing and other preventative measures may have contributed to lowering the number of cases. In the case of China, the logistic regression does a better job. This is to be expected since the number of cases has tappered off and the curve has effectively been 'flattened' in this time period.","b1fb1718":"Based on above analysis, the average number of cases is increasing, initially following the China growth shape but then get dominated by other countries rapid increase torward the latter stages. At times the spread of the cases vary dramatically as shown by the standard deviation.","9ca91d5d":"# problem 2-1","dca4a6e2":"Authors: Jack Shu, Sriharshareddy Katpally, Sarah Henry"}}