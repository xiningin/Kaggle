{"cell_type":{"1f22425e":"code","5e4b0ada":"code","08feb135":"code","99b22357":"code","f024c4e5":"code","cc7275d8":"code","b2d73b1c":"code","d97f288b":"code","f3eddf2f":"code","f719cb74":"code","8191fc8e":"code","18b06a74":"code","00800734":"code","019a54d7":"code","b4d0d113":"code","921b4a69":"code","b4442e0b":"code","1a715883":"code","e7ab7459":"code","cdc9f1fe":"code","72f2f287":"code","cb15753e":"code","25a88db6":"code","017345fe":"code","d367befe":"code","3b98194c":"code","93dd9d6b":"code","fe2e8869":"code","f978e4e1":"code","56471161":"code","9cec13d2":"code","92959dbf":"code","426cb38a":"code","303c88be":"code","30dc8974":"code","ad642cd1":"code","561b7e7e":"code","de441d9a":"code","9ca12607":"code","934140c5":"code","df3118a5":"code","0fdd7116":"code","40df3ecf":"code","4bec8d6c":"code","7ba1edc3":"code","acc960b2":"code","14590b52":"code","117336a5":"code","59b5c552":"code","93980486":"code","5de176b6":"code","3048ddbf":"code","9a8acbd7":"markdown","a09862d1":"markdown","33cc08bb":"markdown","f83e0a44":"markdown","b53868bc":"markdown","cca87b2c":"markdown","e6a2b835":"markdown","59ba96ee":"markdown","d7e353f8":"markdown"},"source":{"1f22425e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5e4b0ada":"train = pd.read_csv('..\/input\/train.csv')","08feb135":"df = pd.DataFrame(train.groupby(['USER_ID', 'ITEM_CODE']).ITEM_AMOUNT.count()).reset_index()","99b22357":"df.head()","f024c4e5":"def create_interaction_matrix(df,user_col, item_col, rating_col, norm= False, threshold = None):\n    '''\n    Function to create an interaction matrix dataframe from transactional type interactions\n    Required Input -\n        - df = Pandas DataFrame containing user-item interactions\n        - user_col = column name containing user's identifier\n        - item_col = column name containing item's identifier\n        - rating col = column name containing user feedback on interaction with a given item\n        - norm (optional) = True if a normalization of ratings is needed\n        - threshold (required if norm = True) = value above which the rating is favorable\n    Expected output - \n        - Pandas dataframe with user-item interactions ready to be fed in a recommendation algorithm\n    '''\n    interactions = df.groupby([user_col, item_col])[rating_col] \\\n            .sum().unstack().reset_index(). \\\n            fillna(0).set_index(user_col)\n    if norm:\n        interactions = interactions.applymap(lambda x: 1 if x > threshold else 0)\n    return interactions","cc7275d8":"%%time\ninteractions = create_interaction_matrix(df = df,\n                                         user_col = 'USER_ID',\n                                         item_col = 'ITEM_CODE',\n                                         rating_col = 'ITEM_AMOUNT')","b2d73b1c":"from scipy import sparse\nfrom lightfm import LightFM\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef create_user_dict(interactions):\n    '''\n    Function to create a user dictionary based on their index and number in interaction dataset\n    Required Input - \n        interactions - dataset create by create_interaction_matrix\n    Expected Output -\n        user_dict - Dictionary type output containing interaction_index as key and user_id as value\n    '''\n    user_id = list(interactions.index)\n    user_dict = {}\n    counter = 0 \n    for i in user_id:\n        user_dict[i] = counter\n        counter += 1\n    return user_dict","d97f288b":"interactions.head()","f3eddf2f":"user_dict = create_user_dict(interactions=interactions)","f719cb74":"len(user_dict)","8191fc8e":"inv_user_dict = {v: k for k, v in user_dict.items()}","18b06a74":"movie_id = list(interactions.columns)\nmovie_dict = {}\ncounter = 0 \nfor i in movie_id:\n    movie_dict[i] = counter\n    counter += 1","00800734":"inv_movie_dict = {v: k for k, v in movie_dict.items()}","019a54d7":"%%time\nx = sparse.csr_matrix(interactions.values)","b4d0d113":"sparse.save_npz('sparse_matrix.npz', x)","921b4a69":"!ls","b4442e0b":"model = LightFM(no_components= 30, loss='warp',k=30)","1a715883":"model.fit(x,epochs=30,num_threads = 10, verbose=True)","e7ab7459":"from lightfm.evaluation import precision_at_k\nfrom lightfm.evaluation import auc_score","cdc9f1fe":"# %%time\n# train_auc = auc_score(model, x, num_threads=10)","72f2f287":"# train_auc.mean()","cb15753e":"# %%time\n# train_precision_at_k = precision_at_k(model, x, num_threads=10, k=30)","25a88db6":"# train_precision_at_k.mean()","017345fe":"n_items = train.ITEM_CODE.nunique()","d367befe":"x","3b98194c":"n_items","93dd9d6b":"user_id = 2\nscores = model.predict(user_id, np.arange(n_items))\ntop_items = np.argsort(-scores)[0:30]\ntop_items","fe2e8869":"sub = pd.read_csv('..\/input\/sample_submission.csv')","f978e4e1":"def aply(x):\n    try:\n        scores = model.predict(user_dict[x], np.arange(n_items))\n        items_30 = np.argsort(-scores)[0:30]\n        return ' '.join([str(inv_movie_dict[x]) for x in list(items_30)])\n    except:\n        pass","56471161":"%%time\nsub['lightFM_preds_top30'] = sub.USER_ID.apply(aply)","9cec13d2":"#\u043f\u043e\u0445\u043e\u0436\u0435 \u043d\u0430 \u0442\u043e, \u0447\u0442\u043e 735 \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u043d\u0435 \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u043b\u0441\u044f \u0440\u0430\u043d\u044c\u0448\u0435\nsub.lightFM_preds_top30.isnull().sum()","92959dbf":"sub.head()","426cb38a":"ttt = '19956 17772 17773 40006 1109 40004 40005 39964 39966 39754 19250 39963 39755 39671 39968 50164 18508 39967 18507 21970 40533 39628 39176 18509 40534 40824 27318 39426 32143 18510'\nttt","303c88be":"sub.ITEM_CODES = sub.lightFM_preds_top30.fillna(ttt)","30dc8974":"sub.head()","ad642cd1":"sub[['USER_ID','ITEM_CODES']].to_csv('sub_lightfm_fixed_user_item_dict.csv', index=False)","561b7e7e":"!ls","de441d9a":"from sklearn.decomposition import PCA\nfrom sklearn import decomposition","9ca12607":"pca = decomposition.PCA(n_components=2)\nITEMS = model.get_item_representations()[1]\nITEMS_centered = ITEMS - ITEMS.mean(axis=0)\npca.fit(ITEMS_centered)\nITEMS_pca = pca.transform(ITEMS)","934140c5":"def get_closest_items(item_n, n=10, verbose=True):\n    items_vecs = model.get_item_representations()[1]\n    dists = [np.linalg.norm(items_vecs[item_n]-x) for x in items_vecs]\n    top_items = np.argsort(np.array(dists))[1:n]\n    \n    return top_items","df3118a5":"def get_cos_closest_items(item_n, n=10, verbose=True):\n    item_embndg = model.item_embeddings[[item_n], :]\n    dists = cosine_similarity(item_embndg, model.item_embeddings)\n    top_items = np.argsort(np.array(-dists))[0][1:n]\n    \n    return top_items","0fdd7116":"import matplotlib.pyplot as plt\n%matplotlib inline","40df3ecf":"def plot_items(items_list, similarity_function):\n    plt.plot(ITEMS_pca[:, 0], \n             ITEMS_pca[:, 1], 'ko', label='items')\n\n    for item in items_list:\n        item_n = item[0]\n        item_color = item[1]\n        close_items = similarity_function(item_n, verbose=False, n=50)\n        plt.plot(ITEMS_pca[close_items, 0], \n                 ITEMS_pca[close_items, 1], item_color, label=item_n)\n\n    plt.legend(bbox_to_anchor=(1.04, 0.9), loc='upper left',\n               ncol=1,# mode=\"expand\",\n               borderaxespad=-5.\n              )","4bec8d6c":"plt.plot(ITEMS_pca[:, 0], \n         ITEMS_pca[:, 1], 'ko', label='items');","7ba1edc3":"items_list = [(13000, 'yo'),\n              (2000, 'go'),\n              (3000, 'co'),\n              (4000, 'mo'),\n              (5000, 'bo'),\n              (6000, 'wo'),\n              (7000,'ro'),\n              (8000, 'cv')]\n\nplot_items(items_list, get_closest_items)","acc960b2":"items_list = [(13000, 'yo'),\n              (2000, 'go'),\n              (3000, 'co'),\n              (4000, 'mo'),\n              (5000, 'bo'),\n              (6000, 'wo'),\n              (7000,'ro'),\n              (8000, 'cv')]\n\nplot_items(items_list, get_cos_closest_items)","14590b52":"train.columns","117336a5":"train['ITEMS_IN_GROUP'] = train.groupby('GROUP_LVL1')['ITEM_CODE'].transform('nunique')","59b5c552":"df = pd.DataFrame(train.groupby('GROUP_LVL1')['ITEM_CODE'].agg('nunique')).reset_index()\ndf = df.rename(index=str, columns={'ITEM_CODE':'GROUP_SIZE'})\ndf.head()","93980486":"df.sort_values('GROUP_SIZE', ascending=False).sample(10)","5de176b6":"items = train[train.GROUP_LVL1 == 357].ITEM_CODE.unique()","3048ddbf":"plt.plot(ITEMS_pca[:, 0], \n         ITEMS_pca[:, 1], 'ko', label='items');\n\nplt.plot(ITEMS_pca[items, 0], \n         ITEMS_pca[items, 1], 'yo', label='items');","9a8acbd7":"# \u0422\u043e \u0431\u044b\u043b\u0438 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0435 \u0442\u043e\u0432\u0430\u0440\u044b, \u0430 \u0447\u0442\u043e \u0435\u0441\u043b\u0438 \u0433\u0440\u0443\u043f\u043f\u0443 \u0442\u043e\u0432\u0430\u0440\u043e\u0432 \u043e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u0442\u044c?","a09862d1":"# \u041d\u0430\u0440\u0438\u0441\u0443\u0435\u043c \u0442\u043e\u0432\u0430\u0440\u044b \u043d\u0430 \u043f\u043b\u043e\u0441\u043a\u043e\u0441\u0442\u0438","33cc08bb":"\u0422\u0430\u043a, \u043d\u0430\u0434\u043e \u043a\u0430\u043a-\u0442\u043e \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u0442\u044c \u0440\u0430\u0437\u0431\u0440\u043e\u0441 \u0442\u043e\u0447\u0435\u043a \u0432\u043d\u0443\u0442\u0440\u0438 \u0433\u0440\u0443\u043f\u043f\u044b, \u0442\u0435\u043c \u0441\u0430\u043c\u044b\u043c \u043c\u044b \u0441\u043c\u043e\u0436\u0435\u043c \u043d\u0430\u0439\u0442\u0438 \u043e\u0434\u043d\u043e\u0440\u043e\u0434\u043d\u044b\u0435 \u0433\u0440\u0443\u043f\u043f\u044b.","f83e0a44":"\u041a\u043b\u044e\u0447\u0438 - \u0430\u0439\u0434\u0438\u0448\u043d\u0438\u043a\u0438 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f; \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f - \u043f\u043e\u0440\u044f\u0434\u043a\u043e\u0432\u044b\u0439 \u043d\u043e\u043c\u0435\u0440.","b53868bc":"\u041a\u043b\u044e\u0447\u0438 - \u043f\u043e\u0440\u044f\u0434\u043a\u043e\u0432\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f; \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f - \u0430\u0439\u0434\u0438\u0448\u043d\u0438\u043a \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f.","cca87b2c":"\u041a\u043b\u044e\u0447\u0438 - \u043f\u043e\u0440\u044f\u0434\u043a\u043e\u0432\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0442\u043e\u0432\u0430\u0440\u0430. \u0417\u043d\u0430\u0447\u0435\u043d\u0438\u044f - \u0430\u0439\u0434\u0438\u0448\u043d\u0438\u043a \u0442\u043e\u0432\u0430\u0440\u0430.","e6a2b835":"\u041a\u043b\u044e\u0447\u0438 - \u0430\u0439\u0434\u0438\u0448\u043d\u0438\u043a\u0438 \u0442\u043e\u0432\u0430\u0440\u043e\u0432 - \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f - \u043f\u043e\u0440\u044f\u0434\u043a\u043e\u0432\u044b\u0439 \u043d\u043e\u043c\u0435\u0440.","59ba96ee":"usefull:\n\n- https:\/\/towardsdatascience.com\/solving-business-usecases-by-recommender-system-using-lightfm-4ba7b3ac8e62\n- https:\/\/github.com\/aayushmnit\/cookbook\/blob\/master\/recsys.py\n- https:\/\/lyst.github.io\/lightfm\/docs\/examples\/movielens_implicit.html\n- https:\/\/lyst.github.io\/lightfm\/docs\/lightfm.evaluation.html\n- https:\/\/towardsdatascience.com\/how-to-build-a-movie-recommender-system-in-python-using-lightfm-8fa49d7cbe3b","d7e353f8":"\u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043a\u043e\u0440 0.03328 \u043d\u0430 \u043f\u0430\u0431\u043b\u0438\u043a\u0435"}}