{"cell_type":{"05f605f6":"code","64c7d9ad":"code","55c5fb2b":"code","eb654686":"code","96e0b6da":"code","cd7f7ae2":"code","64f65a64":"code","5aba30a7":"code","a6d3062a":"code","8f42b81e":"code","61207903":"code","be0df383":"code","cd516dc2":"code","4dbb1b77":"code","c2ad24d9":"code","b2efa850":"code","362aab61":"code","5da82a5f":"code","de5e0216":"code","14f3ada3":"code","5165b4aa":"markdown","a3dcb788":"markdown","2bf2eb48":"markdown","ffff4caf":"markdown","cfbdfd01":"markdown"},"source":{"05f605f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64c7d9ad":"!pip install nlpaug","55c5fb2b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport nlpaug.augmenter.word as naw\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.combine import SMOTETomek\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nsns.set_style('darkgrid')","eb654686":"data = pd.read_csv('..\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv')\ndata.head()","96e0b6da":"plt.figure(figsize=(7, 5))\nplt.title('Couting the labels', fontsize=13)\nsns.countplot(data=data, x='label')\nplt.xlabel('Label', fontsize=12)\nplt.ylabel('Count', fontsize=12)","cd7f7ae2":"#Tweets without hate speech represents almost 93% of the dataset\n\ncounts = pd.DataFrame({\n    'Label': data['label'].value_counts().index,\n    'Count': data['label'].value_counts().values,\n    'Percentage':  data['label'].value_counts().values\/data.shape[0]\n})\n\ncounts.head()","64f65a64":"ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\nX_resampled, y_resampled = ros.fit_resample(data[['tweet']], data['label'])\ndata_resampled_ros = pd.concat([X_resampled, y_resampled], axis=1)\ndata_resampled_ros.head()","5aba30a7":"plt.figure(figsize=(7, 5))\nplt.title('Couting the labels', fontsize=13)\nsns.countplot(data=data_resampled_ros, x='label')\nplt.xlabel('Label', fontsize=12)\nplt.ylabel('Count', fontsize=12)","a6d3062a":"counts = pd.DataFrame({\n    'Label': data_resampled_ros['label'].value_counts().index,\n    'Count': data_resampled_ros['label'].value_counts().values,\n    'Percentage':  data_resampled_ros['label'].value_counts().values\/data_resampled_ros.shape[0]\n})\n\ncounts.head()","8f42b81e":"# First of all we need to tokenize the tweets so we can augmentate them\n\ndata_smote = data.copy()\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(data_smote)\n\ndata_smote['tweet'] = tokenizer.texts_to_sequences(data_smote['tweet'])\nvocab_size = len(tokenizer.word_index) + 1\n\nmaxlen = 100\n\ndata_smote['tweet'] = pad_sequences(data_smote['tweet'], padding='post', maxlen=maxlen)","61207903":"smote = SMOTE(random_state=42, sampling_strategy='minority')\nX_resampled, y_resampled = smote.fit_resample(data_smote[['tweet']], data_smote['label'])\ndata_resampled_smote = pd.concat([X_resampled, y_resampled], axis=1)","be0df383":"plt.figure(figsize=(7, 5))\nplt.title('Couting the labels', fontsize=13)\nsns.countplot(data=data_resampled_smote, x='label')\nplt.xlabel('Label', fontsize=12)\nplt.ylabel('Count', fontsize=12)","cd516dc2":"counts = pd.DataFrame({\n    'Label': data_resampled_smote['label'].value_counts().index,\n    'Count': data_resampled_smote['label'].value_counts().values,\n    'Percentage':  data_resampled_smote['label'].value_counts().values\/data_resampled_smote.shape[0]\n})\n\ncounts.head()","4dbb1b77":"# First of all we need to tokenize the tweets so we can augmentate them\n\ndata_smotetomek = data.copy()\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(data_smotetomek)\n\ndata_smotetomek['tweet'] = tokenizer.texts_to_sequences(data_smotetomek['tweet'])\nvocab_size = len(tokenizer.word_index) + 1\n\nmaxlen = 100\n\ndata_smotetomek['tweet'] = pad_sequences(data_smotetomek['tweet'], padding='post', maxlen=maxlen)","c2ad24d9":"tomek = SMOTETomek(random_state=42)\nX_resampled, y_resampled = tomek.fit_resample(data_smotetomek[['tweet']], data_smotetomek['label'])\ndata_resampled_smotetomek = pd.concat([X_resampled, y_resampled], axis=1)","b2efa850":"plt.figure(figsize=(7, 5))\nplt.title('Couting the labels', fontsize=13)\nsns.countplot(data=data_resampled_smotetomek, x='label')\nplt.xlabel('Label', fontsize=12)\nplt.ylabel('Count', fontsize=12)","362aab61":"counts = pd.DataFrame({\n    'Label': data_resampled_smotetomek['label'].value_counts().index,\n    'Count': data_resampled_smotetomek['label'].value_counts().values,\n    'Percentage':  data_resampled_smotetomek['label'].value_counts().values\/data_resampled_smote.shape[0]\n})\n\ncounts.head()","5da82a5f":"data_resampled_nlpaug = data.copy()\n\naug_texts = []\nminority_data = data_resampled_nlpaug[data_resampled_nlpaug['label'] == 1]\naug = naw.SynonymAug(aug_src='wordnet')\n\ntexts = minority_data['tweet'].tolist()\n\nfor text in texts:\n    augmented_texts = aug.augment(text, n=12)\n    \n    for augmented in augmented_texts:\n        aug_texts.append(augmented)\n\nprint(len(aug_texts))\n\ntemp = pd.DataFrame({\n    'tweet': aug_texts\n})\n        \ntemp['label'] = 1\n        \ndata_resampled_nlpaug = pd.concat([data_resampled_nlpaug, temp], axis=0)\ndata_resampled_nlpaug = data_resampled_nlpaug.reset_index()\ndata_resampled_nlpaug = data_resampled_nlpaug.drop(columns=['index'])\ndel temp, minority_data","de5e0216":"plt.figure(figsize=(7, 5))\nplt.title('Couting the labels', fontsize=13)\nsns.countplot(data=data_resampled_nlpaug, x='label')\nplt.xlabel('Label', fontsize=12)\nplt.ylabel('Count', fontsize=12)","14f3ada3":"counts = pd.DataFrame({\n    'Label': data_resampled_nlpaug['label'].value_counts().index,\n    'Count': data_resampled_nlpaug['label'].value_counts().values,\n    'Percentage':  data_resampled_nlpaug['label'].value_counts().values\/data_resampled_nlpaug.shape[0]\n})\n\ncounts.head()","5165b4aa":"## Data Augmentation","a3dcb788":"### Random Over Sampler (ROS)","2bf2eb48":"### SMOTETomek","ffff4caf":"#### NLPAUG","cfbdfd01":"### SMOTE"}}