{"cell_type":{"8ba51d01":"code","56b22d67":"code","fa51d9fc":"code","60198aea":"code","6f75562f":"code","6830b002":"code","3ecb38ed":"code","3f67524a":"code","7d3e4d4b":"code","6d023859":"code","a5c4b250":"code","5a7f91ef":"code","04e77223":"code","312809d3":"code","27631d4e":"code","3a0b78aa":"code","76bd9aa3":"code","5af9e697":"code","cc916cbf":"code","de6b9158":"code","780bb8d7":"code","b086d68b":"code","14040307":"code","21d1afe1":"code","41bc25e8":"code","68cc7a2b":"code","6c794eef":"code","ec4a61c4":"code","1a3a54a6":"code","ed12b0ac":"code","fb171f11":"code","0b02c997":"code","0e55b543":"code","aca8b9fc":"code","e9e54fad":"code","46357446":"code","029e2611":"code","54d41709":"code","1539f349":"code","3bcf85c0":"code","00b54610":"code","78d067a1":"code","bd9d7608":"code","9c565c3f":"code","58abb0b5":"code","e70935be":"code","23a37db2":"code","a2fe7a89":"code","cc51dfb8":"code","add7b8b3":"code","1708c9ba":"code","37da28a0":"code","4923fc59":"code","4b426e02":"code","9a5a452e":"code","3c2b0314":"code","60c828fb":"markdown","0dcda25b":"markdown","5822b3ff":"markdown","16914768":"markdown","daf99ee7":"markdown","3c31e2da":"markdown","3e422832":"markdown","377b8b41":"markdown","395a24a6":"markdown","460497a0":"markdown","bdedbe68":"markdown","edfe0a18":"markdown","074a29c0":"markdown","1e0f97bb":"markdown","6a48cd3d":"markdown","d01a4430":"markdown","ca83f06f":"markdown","e9a19b32":"markdown","d1c3027d":"markdown","f73a5c8e":"markdown","7832c866":"markdown","c1e3efe5":"markdown","ac598f48":"markdown"},"source":{"8ba51d01":"import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","56b22d67":"import os\n\nreal = \"..\/input\/real-and-fake-face-detection\/real_and_fake_face\/training_real\/\"\nfake = \"..\/input\/real-and-fake-face-detection\/real_and_fake_face\/training_fake\/\"\ndatadir = \"..\/input\/real-and-fake-face-detection\/real_and_fake_face\/\"\n\n\nreal_path = os.listdir(real)\nfake_path = os.listdir(fake)","fa51d9fc":"def load_img(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (224, 224))\n#     print(labels)\n    return image[...,::-1]","60198aea":"plt.imshow(load_img(real + real_path[2]), cmap='gray')","6f75562f":"plt.imshow(load_img(real + real_path[20]), cmap='gray')","6830b002":"plt.imshow(load_img(fake + fake_path[20]), cmap='gray')","3ecb38ed":"plt.imshow(load_img(fake + fake_path[80]), cmap='gray')","3f67524a":"# datadir = \"dataset\"\ncategories = [\"training_real\" , \"training_fake\"]\n\nfor category in categories:\n    path = os.path.join(datadir, category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n        plt.imshow(img_array, cmap=\"gray\")\n        # plt.imshow(img_array, cmap= plt.cm.binary)\n        plt.show()\n        print(category)\n        break\n    break","7d3e4d4b":"training_data = []\nIMG_SIZE = 224\n\n## This means 0 will indicate Real facial Images and 1 to Fake facial Images.\n\ncategories = [\"training_real\" , \"training_fake\"]\n\ndef create_training_data():\n    for category in categories:\n        path = os.path.join(datadir, category)\n        class_num = categories.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n                training_data.append([new_array,class_num])\n            except:\n                pass\ncreate_training_data()\n","6d023859":"training_data = np.array(training_data)\nprint(training_data.shape)","a5c4b250":"import random\n\nnp.random.shuffle(training_data)\nfor sample in training_data[:10]:\n    print(sample[1])","5a7f91ef":"X = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny = np.array(y)","04e77223":"print(X.shape)\nprint(y.shape)","312809d3":"print(np.unique(y, return_counts = True))\n## (array([0, 1]), array([1081,  960])) This should be the answer\n\nprint(y[1:10])","27631d4e":"## Normalization \nX = X\/255.0 \n","3a0b78aa":"\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","76bd9aa3":"print(\"Shape of test_x: \",X_train.shape)\nprint(\"Shape of train_y: \",y_train.shape)\nprint(\"Shape of test_x: \",X_test.shape)\nprint(\"Shape of test_y: \",y_test.shape)","5af9e697":"print(y_test[1:10])","cc916cbf":"print(np.unique(y_train, return_counts = True))\nprint(np.unique(y_test, return_counts = True))","de6b9158":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n\ntrain_x = tf.keras.utils.normalize(X_train,axis=1)\ntest_x = tf.keras.utils.normalize(X_test, axis=1)","780bb8d7":"model = tf.keras.models.Sequential([\n            tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',\n                            input_shape= X.shape[1:]),\n            tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n            tf.keras.layers.MaxPooling2D(2,2),\n            tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n            tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n            tf.keras.layers.MaxPooling2D(2,2),\n            tf.keras.layers.Dropout(0.25),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(128, activation=tf.nn.relu),\n            tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhist = model.fit(X_train,y_train, batch_size=20, epochs = 5, validation_split=0.1)","b086d68b":"epochs = 5\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","14040307":"val_loss, val_acc = model.evaluate(X_test, y_test)\nprint(val_loss)\nprint(val_acc)","21d1afe1":"predictions = model.predict(X_test)\n# predictions","41bc25e8":"rounded_predictions = model.predict_classes(x = X_test, batch_size=10, verbose=0)\nfor i in rounded_predictions[:10]:\n    print(i)","68cc7a2b":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix","6c794eef":"cm = confusion_matrix(y_test,rounded_predictions)","ec4a61c4":"def plot_confusion_matrix(cm, classes,\n    normalize=False,\n    title='Confusion matrix',\n    cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"black\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","1a3a54a6":"cm_plot_labels = ['Real', 'Fake']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","ed12b0ac":"import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n## I don't know why but without running this cell the below code is shown an error. \n## Running all these imports again solved it.\n## Will figure out soon.","fb171f11":"vgg16_model = keras.applications.vgg16.VGG16()","0b02c997":"vgg16_model.summary()","0e55b543":"type(vgg16_model)\n## This is not a sequential model.","aca8b9fc":"from keras.models import Sequential\n\nmodel = Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    model.add(layer)\n    \n# Now, we have replicated the entire vgg16_model\n# (excluding the output layer) to a new Sequential model, which we've just given the name model","e9e54fad":"for layer in model.layers:\n    layer.trainable = False\n    \n# Next, we\u2019ll iterate over each of the layers in our new Sequential model and set them to\n# be non-trainable. This freezes the weights and other trainable parameters \n# in each layer so that they will not be updated when we pass in our images of fake and real faces.","46357446":"model.add(Dense(2, activation='softmax'))","029e2611":"model.summary()","54d41709":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nhist = model.fit(X_train,y_train, batch_size=20, epochs = 50, validation_split=0.1)","1539f349":"epochs = 50\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","3bcf85c0":"val_loss, val_acc = model.evaluate(X_test, y_test)\nprint(val_loss)\nprint(val_acc)","00b54610":"predictions = model.predict(X_test)\n# predictions","78d067a1":"rounded_prediction = model.predict_classes(x = X_test, batch_size=10, verbose=0)\nfor i in rounded_predictions[:10]:\n    print(i)","bd9d7608":"print(y_test[1:10])\nprint(np.unique(y_test, return_counts = True))","9c565c3f":"rounded_prediction = np.array(rounded_prediction)\nprint(np.unique(rounded_prediction, return_counts = True))","58abb0b5":"cm = confusion_matrix(y_test,rounded_prediction)\ncm_plot_labels = ['Real', 'Fake']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","e70935be":"## Just Run this once and you can change the number of the images mentioned for prediction and model result.\n\n## For Image Display.\ndef load_img(path):\n    image = cv2.resize(path, (224, 224))\n    return image[...,::-1]\n\n## For Predicting result.\ndef prepare(image):\n    IMG_SIZE = 224\n    new_array = cv2.resize(image, (IMG_SIZE, IMG_SIZE)) \n    return new_array.reshape(-1, IMG_SIZE,IMG_SIZE,3)","23a37db2":"## Change the value of n for other images. I have chosen these images randomly.\n\nn = 43\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\n\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","a2fe7a89":"n = 120\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","cc51dfb8":"n = 41\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","add7b8b3":"n = 140\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","1708c9ba":"n = 162\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","37da28a0":"n = 16\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","4923fc59":"n = 101\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","4b426e02":"n = 201\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","9a5a452e":"n = 250\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","3c2b0314":"n = 171\n\nprediction = model.predict(prepare(X_test[n]))\nprint(\"Probabilities: \",prediction)\nx = [\"Real-Face\" if y_test[n]== 0 else \"Fake-Face\"]\nprint(\"Actual: \",x[0])\nrounded_prediction = model.predict_classes(x = prepare(X_test[n]), batch_size=10, verbose=0)\ny = [\"Real-Face\" if rounded_prediction[0]== 0 else \"Fake-Face\"]\nprint(\"Prediction: \", y[0])\nplt.imshow(load_img(X_test[n]), cmap='gray')\nplt.show()","60c828fb":"### Creating Training Data","0dcda25b":"### Customizing our model","5822b3ff":"### Building X(Features) and Y(Labels) for train test split.","16914768":"- This means our model predicted every single time and got the 54% accuracy.","daf99ee7":"### Evaluation on Test Data","3c31e2da":"### Visualizing Training Loss and Accuracy.\n\n- Credits : [Anuj Shah](https:\/\/github.com\/anujshah1003\/own_data_cnn_implementation_keras\/blob\/master\/updated_custom_data_cnn.py)\n\n- The code below is taken from the github repository of Anuj Shah. You can visit the link given to see any other details.","3e422832":"### Let's take a closer look.\n\n**1. Real Face**","377b8b41":"- **predictions (Dense)          (None, 1000)              4097000**\n\n- Vgg-16 is trained for classification of 1000 different classes, but we do not need that.\n- So we will remove that last layer and add one of our own.","395a24a6":"### Predictions.","460497a0":"## Imports","bdedbe68":"### [Train-Test Split](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html)","edfe0a18":"## 0 is Real Face\n## 1 is Fake Face\n","074a29c0":"## Introduction:\n\n- A few months ago deep fakes are in news for creating nuisance. So  I thought of it and tried to develop a model which will classify the Real and Fake faces present in test data provided.\n\n**Things to look forward to:**\n\n- Pretrained Model Integration.\n- Model Accuracy and Loss Visualization.\n- Confusion Matrix.\n- Predictions on few images.\n\n","1e0f97bb":"## References:\n\n1. [Keras Documentation](https:\/\/keras.io\/api\/)\n\n2. [Deep Lizard Tutorials](https:\/\/deeplizard.com\/learn\/video\/LhEMXbjGV_4)\n\nand that's it.\n\n- Feel free to copy and edit and if you found the notebook useful, do upvote.","6a48cd3d":"## Explanation of Matrix:\n\n**True Positive**\n\n- Correct Real Faces Predictions: 157 \n\n**False Positive**\n\n- Incorrect Real Faces Predictions: 106\n\n**True Negative**\n\n- Correct Fake Faces Predictions: 94\n\n**False Negative**\n\n- Incorrect Fake Faces Predictions: 52","d01a4430":"**Model is Ready, time to Compile it**\n","ca83f06f":"## [Confusion Matrix.](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.plot_confusion_matrix.html)","e9a19b32":"## Predictions vs Actual.","d1c3027d":"## VGG 16\n\n- Checkout [this](https:\/\/neurohive.io\/en\/popular-networks\/vgg16\/) article for better Explanation.","f73a5c8e":"### [np.random.shuffle(array)](https:\/\/docs.scipy.org\/doc\/numpy-1.15.0\/reference\/generated\/numpy.random.shuffle.html)\n\n- Shuffling here is important as the data is sequential therefore if directly fed into the network, the network just learn to give a single prediction and not on merit. ","7832c866":"### Performance Analysis:\n\n- **Actual Test Data**:  Real Faces[209], Fake Faces[200]\n\n- **Predicted Data** :   Real Faces[263], Fake Faces[146]","c1e3efe5":"### Path Specification","ac598f48":"**2. Fake Face**"}}