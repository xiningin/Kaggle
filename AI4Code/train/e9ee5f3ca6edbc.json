{"cell_type":{"31c6747e":"code","d760b17d":"code","4a681adc":"code","6099f5f2":"code","a0a472f9":"code","5b9f862e":"code","bac917e1":"code","227892fc":"code","31c73067":"code","c8cfd453":"code","a9c035af":"code","ea2ad265":"code","df23c3ad":"markdown","c6e304b6":"markdown","ea00c046":"markdown","75945dd3":"markdown","5f14c24f":"markdown","5320cbc5":"markdown"},"source":{"31c6747e":"#Dont forget enable GPU its full compatble running on GPU ","d760b17d":"ls \"..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\"\n","4a681adc":"import cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nimport time\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import RMSprop\n\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.nasnet  import NASNetLarge  \nfrom tensorflow.keras.applications.densenet  import DenseNet121 \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns","6099f5f2":"tahminler = []\ngercekler = []\nhistoryler = []\nCATEGORIES = ['NORMAL', 'PNEUMONIA']\nDIR_TRAINING = \"..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/train\"\nDIR_TEST = \"..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/test\"\nNEW_SIZE = 331\nX_data = []\ny_data = []\n\nfor category in CATEGORIES:\n    label = CATEGORIES.index(category)\n    path_train = os.path.join(DIR_TRAINING, category)\n    path_test = os.path.join(DIR_TEST, category)\n    for img in os.listdir(path_train):\n        try:\n            img_train = cv2.imread(os.path.join(path_train,img), cv2.IMREAD_COLOR)\n            img_train = cv2.resize(img_train, (NEW_SIZE, NEW_SIZE))\n            X_data.append(img_train)\n            y_data.append(label)\n        except Exception as e:\n            pass\n    for img in os.listdir(path_test):\n        try:\n            img_test = cv2.imread(os.path.join(path_test,img), cv2.IMREAD_COLOR)\n            img_test = cv2.resize(img_test, (NEW_SIZE, NEW_SIZE))\n            X_data.append(img_test)\n            y_data.append(label)\n        except Exception as e:\n            pass\nprint(len(y_data))\nprint(len(X_data))\nprint(type(X_data))\nprint(type(y_data))","a0a472f9":"\n# \u00d6n e\u011fitimli model olarak kullan\u0131lacak modeller base_models dizisine eklenmelidir.\nbase_models = ['Xception'] # yap\u0131lan deneysel \u00e7al\u0131\u015fmada her bir \u00f6n e\u011fitimli model ayr\u0131 ayr\u0131 pipe line a sokulmu\u015ftur\n#base_models = ['Xception','VGG16','VGG19','NASNetLarge','DenseNet121','InceptionV3','MobileNetV2']\n#base_models = ['Xception','DenseNet121','InceptionV3']\ndef makeBaseModel(x):\n  if x == 'Xception':\n    print(\"Base model is : Xception\")\n    base_model = Xception(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  elif x == 'VGG16':\n    print(\"Base model is : VGG16\")\n    base_model = VGG16(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  elif x == 'VGG19':\n    print(\"Base model is : VGG19\")\n    base_model = VGG19(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  elif x == 'NASNetLarge':\n    print(\"Base model is : NASNetLarge\")\n    base_model = NASNetLarge(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  elif x == 'DenseNet121':\n    print(\"Base model is : DenseNet121\")\n    base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  elif x == 'InceptionV3':\n    print(\"Base model is : InceptionV3\")\n    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  elif x == 'MobileNetV2':\n    print(\"Base model is : MobileNetV2\")\n    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')\n  else:\n    print(\"Unknow Base Model\")\n\n  return base_model\n\n","5b9f862e":"def makeModel(base_model):\n  model=tf.keras.Sequential()\n  model.add(base_model)\n  model.add(Dense(256))\n  model.add(Activation('relu'))\n  model.add(Dropout(0.2))\n  model.add(Dense(2,activation='softmax'))\n  model.summary()\n  \n  for layer in base_model.layers:\n      layer.trainable = False\n  \"\"\"\n  model.layers[0].trainable = False\n  print(\"ModelE\u011fitilebilirLayers\"*3)\n  for i in model.layers:\n    print(i.trainable)  \n  \"\"\"\n  \"\"\"\n  for layer in model.layers:# base modelin layerleri false i\u015faretlendi yani e\u011fitilmeyecek\n      print(layer.trainable)\n  for layer in base_models.layers:# modelin layerlar\u0131 true yani e\u011fitilebilir\n      print(layer.trainable)\n  \"\"\"\n  model.compile(loss='binary_crossentropy', \n                optimizer='rmsprop', \n                metrics=['accuracy'])\n  return model","bac917e1":"\nprint(type(X_data))\nprint(type(y_data))\nX_data = np.array(X_data, dtype=\"float32\").reshape(-1, NEW_SIZE, NEW_SIZE, 3)\ny_data = np.asarray(y_data)\n\nprint(X_data.shape)\nprint(y_data.shape)\n#print(X_data[0])\n#print(y_data)\ny_cat = to_categorical(y_data)\nprint(y_cat.shape)\n","227892fc":"execTimeList = []\nhow_many = 1\nfor j in base_models:# hangi \u00f6n e\u011fitimli modelleri kullanarak modeller e\u011fitilsin \n  for i in range(how_many):# se\u00e7ilen \u00f6n e\u011fitimli model i\u00e7in ka\u00e7 adet model e\u011fitilsin\n   # \u00c7al\u0131\u015f\u0131lan platformdaki ram k\u0131s\u0131t\u0131ndan dolay\u0131 her base model i\u00e7in  1 er adet model e\u011fietecek \u015fekilde de\u011fi\u015ftirdim \n   # istenildi\u011fi takdirde base_models dizisine eklenen \u00f6n e\u011fitimli model say\u0131s\u0131 azalt\u0131larak daha fazla say\u0131da model e\u011fitilebilir\n   # Deneysel \u00e7al\u0131\u015fmada her her bir \u00f6ne\u011fitimli model i\u00e7in 10 ar adet model e\u011fitilmi\u015ftir\n    model = makeModel(makeBaseModel(j))\n    print(\"*\"*30 +\"   \" + str(i)+\".ci Model E\u011fitiliyor \" + \"*\"*30)\n    start_time = time.time()\n    index = np.arange(X_data.shape[0])\n    np.random.shuffle(index)\n\n    X_data = X_data[index]\n    y_data = y_data[index]\n\n    y_cat = to_categorical(y_data)\n\n    (X_train, X_test, y_train, y_test) = train_test_split(X_data, y_cat, test_size=0.2, random_state=None, shuffle= False, stratify=None) \n    (X_train, X_val , y_train, y_val ) = train_test_split(X_train, y_train, test_size=0.25, random_state=None, shuffle = False, stratify=None)\n\n    a = np.argmax(y_test, axis = 1)\n    b = np.count_nonzero(a == 1)\n    # O model i\u00e7in haz\u0131rlanan test datas\u0131nda ka\u00e7\u0131 normal ka\u00e7\u0131 zat\u00fcrreli\n    print(\"1 = Pnomonia  : \" + str(b))\n    print(\"0 = Normal    : \" + str(len(a)-b))\n\n    train_datagen = ImageDataGenerator(\n        rescale=1.0\/255.0,\n        samplewise_center=True,\n        rotation_range=20,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\")\n\n    validation_datagen = ImageDataGenerator(rescale=1.0\/255.0, samplewise_center=True)\n\n    test_datagen = ImageDataGenerator(rescale=1.0\/255.0, samplewise_center=True)\n    # Ka\u00e7 kere ve ka\u00e7ar \u00f6rneklem ile  \n    batch_size = 16\n    Epocs = 100\n\n    train_iterator = train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=False)\n    validation_iterator = validation_datagen.flow(X_val, y_val, batch_size=batch_size, shuffle=False)\n\n    test_iterator = test_datagen.flow(X_test, y_test, batch_size=len(X_test), shuffle=False)\n\n    learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n                                                patience=3, \n                                                verbose=1,\n                                                factor=0.5, \n                                                min_lr=0.00001)\n    earlystop = EarlyStopping(patience=10)# monitor=\"val_loss\", default\n\n    history = model.fit_generator(train_iterator,\n                                  validation_data=validation_iterator,\n                                  steps_per_epoch=X_train.shape[0] \/\/ batch_size,# b\u00f6l\u00fcm\u00fc int d\u00f6n\n                                  epochs=Epocs,\n                                callbacks=[earlystop, learning_rate_reduction]\n                                )\n\n    predicted_label = model.predict(test_iterator)\n\n    predicted_label = np.argmax(predicted_label, axis = 1)\n    try:\n        y_test = np.argmax(y_test, axis = 1)    \n    except Exception as e:\n        print(\"exception\")\n        pass\n\n    print(\"Model Accuracy on test set: {:.4f}\".format(accuracy_score(y_test, predicted_label)))\n    tahminler.append(predicted_label)\n    gercekler.append(y_test)\n    historyler.append(history)\n    execTime = time.time() - start_time\n    execTimeList.append(execTime)","31c73067":"dogruluk = []\nfor i in range(len(tahminler)): # 1 ler pnomnoia   \/\/\/ 0 lar normal  && 0 lar true \/\/ 1 ler false\n  class_names2 = ['Normal', 'Covid19']\n  print(str(i)+ \". Model\")\n  cm  = confusion_matrix(tahminler[i], gercekler[i])\n  sns.heatmap(cm, annot=True, cmap='inferno_r', square=True, )\n  #plot_confusion_matrix(cm, cmap=plt.cm.Blues) # matplotlib cm heat map\n  print(\"Model Accuracy on Test set: {:.4f}\".format(accuracy_score(gercekler[i], tahminler[i])))\n  dogruluk.append(accuracy_score(gercekler[i], tahminler[i]))\n  print ('Classification Report :\\n\\n' ,classification_report( gercekler[i], tahminler[i]))\n  plt.show()\n\n","c8cfd453":"print(type(dogruluk[0]))\ndef Average(lst): \n    return sum(lst) \/ len(lst)\nfor i in range(len(dogruluk)):\n  dogruluk[i]= round(dogruluk[i],5)\nprint(min(dogruluk))\nprint(max(dogruluk))\nprint(Average(dogruluk))","a9c035af":"\nfor i in range(len(historyler)):\n\n  print(\"*\"*100)\n  print(str(i)+ \". model: \")\n  plt.figure(figsize=(14,6))\n  plt.subplot(1, 2, 1)\n  sns.set_context('talk')\n  plt.plot(historyler[i].history['loss'], 'b', label='Train', marker='x')\n  plt.plot(historyler[i].history['val_loss'], 'r', label='Val', marker='o')\n  plt.legend()\n  plt.title('Learning Curve')\n  plt.xlabel('Iterations')\n  plt.ylabel('Loss')\n  \n  sns.set_context('talk')\n  plt.subplot(1, 2, 2)\n  plt.plot(historyler[i].history['accuracy'], 'b', label='acc', marker='x')\n  plt.plot(historyler[i].history['val_accuracy'], 'r', label='val_acc', marker='o')\n  plt.title('Accuracy & Validation Accuracy Curve')\n  plt.xlabel('Iterations')\n  plt.ylabel('acc')\n  plt.legend()\n  plt.show()","ea2ad265":"print(execTimeList)\np=(round(min(execTimeList)))\np2 = (round(max(execTimeList)))\np3 =(round(Average(execTimeList)))\nprint(\"ort:\" + str(p3) + \",  min:\" + str(p) +\",  max:\" + str(p2))","df23c3ad":"\u0130mports","c6e304b6":"Preprocess for my data set im convert to matrixs this images and push in array and also push this images labes I do this without breaking the ranking between data and tags","ea00c046":"Simple CNN & Transfer Learning Pnomonia prediction pipeline \ntrain your CNN using different pre trained models \nadd \"base_models\" array \nif you want to multiple models using this pre trained models \nchange \"how_many\" variable \nforexample;\nif you want use 3 different pre trained models and if you want train 2 model using each one\n#how_many=2# 2 model for each pre trained\n#base_models = ['Xception','DenseNet121','InceptionV3'] # using xception, densenet and inceptionv3 \nso this pipe line is train you totally 3*2 6 model and make predict using this model also draw your confusion matrixs as a heat map and draw your model performance(loss,acc) as a polt\n","75945dd3":"makeBasemodel() is fucntion for create base models using tf.keras.applications\nBurada hangi modelleri e\u011fitmek istiyorsan\u0131z base_models listesinin i\u00e7erisine eklemelisiniz ka\u00e7 tane model eklendi ise o modellerin her birisinden birer base model haz\u0131rlanacak t\u0131r.\nhaz\u0131rlanan modellerin son fc katmanlar\u0131 include_top a false parametresi verilerek al\u0131nm\u0131yor giri\u015f katman\u0131 t\u00fcm modeller i\u00e7in veriyi haz\u0131rlarken se\u00e7ti\u011fimi 331,331,3 olarak ayarlan\u0131yor ve bu \u00f6n e\u011fitimli modelin a\u011f\u0131rl\u0131klar\u0131 keras.application \u00fczerinden imagenet a\u011f\u0131rl\u0131klar\u0131 ile getiriliyor. ","5f14c24f":"makeModel() is a fucntion for generate our model using basemodel fucntion  create a base_model and  added dense layers for learning and added dropout for prevent overfitting.\n\nmakeModel fonksiyonu, base modeli i al\u0131p katman a\u011f\u0131rl\u0131klar\u0131n\u0131 e\u011ftmemesi i\u00e7in e\u011fitilemez olarka i\u015faretleyip sonuna modelin \u00f6\u011frenebilmesi i\u00e7in 2 tane fc katma  ve a\u015f\u0131r\u0131 \u00f6\u011frenmeyi engellemek i\u00e7in dropout ekletip modeli derliyor ve bizim e\u011fitece\u011fimiz modeli bize d\u00f6n\u00fcyor","5320cbc5":"Resimlerin ve labelleri diziden numpy nd arraylere \u00e7evrilmesi\nve bu arreylerin formatlar\u0131n\u0131  do\u011frumu diye yazd\u0131yorum"}}