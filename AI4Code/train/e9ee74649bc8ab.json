{"cell_type":{"ba89fe3d":"code","afaf6742":"code","91733722":"code","e95b3790":"code","453c579f":"code","ed5bc32a":"code","8d2f9da1":"code","877ca53d":"code","eb8a6485":"code","3901bbe2":"code","43f69f81":"code","0a6173e8":"code","4d4a9cff":"code","09aa7cec":"code","162e9209":"code","65087534":"code","4ea8f873":"code","9c2c12d5":"code","ae9cd67c":"code","5035bb69":"code","a28fefc0":"code","5dddd69a":"code","b04d903c":"code","d2c8545c":"markdown","cb57427e":"markdown","2e85b87b":"markdown","ed823eb2":"markdown"},"source":{"ba89fe3d":"# import necessary libraries\nimport os\nimport warnings\n#ignore tf warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nfrom datetime import datetime\nimport random\nimport numpy as np\nimport pandas as pd\nimport scipy.io as sio\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\n\n","afaf6742":"def reset_random_seeds(seed):\n   os.environ['PYTHONHASHSEED']=str(seed)\n   tf.random.set_seed(seed)\n   np.random.seed(seed)\n   random.seed(seed)\n\n# set random seeds\nreset_random_seeds(0)","91733722":"# load dataset\ndata = sio.loadmat(\"..\/input\/proteinelyazisi\/el-yazisi-sayi.mat\")","e95b3790":"# read training and test datasets\nX_train, y_train, X_test, y_test = [data[key] for key in [\"X_train\", \"y_train\", \"X_test\", \"y_test\"]]","453c579f":"# print shapes\nprint(\"X_train: \", X_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"X_test: \", X_test.shape)\nprint(\"y_test: \", y_test.shape)","ed5bc32a":"# plot digit classes\nplt.figure(figsize=(10,5))\nsns.countplot(x = y_train.ravel(),palette=\"icefire\")\nplt.title(\"number of digit classes\")","8d2f9da1":"# show 50th value\nimg = X_train[49]\nimg = img.reshape((20,20))\nplt.imshow(img)\nplt.title(y_train[0][49])\nplt.axis(\"off\")\nplt.show()","877ca53d":"# Utility function to display digits in a mosaic\ndef plot_digit_mosaic(data, rows=5, cols=5):\n    vertical_line = []\n    count = 0\n    for i in range(0,rows):\n        horizontal_line = []\n        for j in range(0,cols):\n            horizontal_line.append(data[count].reshape(20,20))\n            count += 1\n        h = np.hstack((horizontal_line))\n        vertical_line.append(h)\n    image_matrix = np.vstack((vertical_line))\n    \n    fig, axarr = plt.subplots(1, 1, figsize=(12, 12))\n    plt.imshow(image_matrix)","eb8a6485":"# plot first 50 digits together\nplot_digit_mosaic(data=X_train, rows=5, cols=10)","3901bbe2":"# reshape data from 400x1 to 20x20\nX_train = X_train.reshape(-1,20,20,1)\nX_test = X_test.reshape(-1,20,20,1)","43f69f81":"# Pad images with 0s since LeNet accepts 32x32 images. \"The reason is that it is desirable\n# that potential distinctive features such as stroke end-points or corner can appear in the\n# center of receptive field of the highest level feature detectors.\"\nX_train = np.pad(X_train, ((0,0),(6,6),(6,6),(0,0)), 'constant')\nX_test = np.pad(X_test, ((0,0),(6,6),(6,6),(0,0)), 'constant')","0a6173e8":"# one-hot encode labels\ny_train = to_categorical(y_train.ravel())\ny_test = to_categorical(y_test.ravel())","4d4a9cff":"print(\"shape of training set: \", X_train.shape, y_train.shape)\nprint(\"shape of test set: \", X_test.shape, y_test.shape)","09aa7cec":"##### Build the model according to the architecture given above.\nleNet5 = keras.Sequential()\n\nleNet5.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', input_shape=(32,32,1)))\nleNet5.add(layers.AveragePooling2D())\nleNet5.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='tanh'))\nleNet5.add(layers.AveragePooling2D())\n\nleNet5.add(layers.Flatten())\n\nleNet5.add(layers.Dense(units=120, activation='tanh'))\nleNet5.add(layers.Dense(units=84, activation='tanh'))\n\nleNet5.add(layers.Dense(units=10, activation = 'softmax'))\n\nleNet5.summary()","162e9209":"# define the type of augmentation techniques we will apply.\ndatagen = ImageDataGenerator(\n   # rescale =1\/255,\n    shear_range=5,\n    zoom_range = 0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    rotation_range=10,\n    fill_mode = 'nearest',\n)","65087534":"# Compiling settings. Writers used custom learning rate scheduler so it is implemented below.\n\ndef scheduler(epoch, lr):\n# 0.0005 for the first two passes, 0.0002 for next three, 0.0001 for the next three,\n# 0.00005 for the next four and 0.00001 for thereafter.\n    if epoch < 2:\n        return 0.0005\n    elif epoch < 5:\n        return 0.0002\n    elif epoch < 8:\n        return 0.0001\n    elif epoch < 12:\n        return 0.00005\n    else:\n        return 0.00001\n\ncallback = keras.callbacks.LearningRateScheduler(scheduler)\n","4ea8f873":"# define loss, metrics and optimizer\nleNet5.compile(loss='categorical_crossentropy', \n              optimizer=keras.optimizers.SGD(), \n              metrics=['accuracy'])","9c2c12d5":"# save initial weights to reset the model later\nleNet5.save_weights('my_model_weights.h5')","ae9cd67c":"# fitting model without custom learning rate scheduler. Because the dataset used on the paper\n# is significantly different than ours and custom scheduler stops learning due to local minima\n# in our case.\ndef train_and_evaluate_model(X_train, y_train, X_test, y_test):\n    start=datetime.now()\n    history = leNet5.fit(\n                        datagen.flow(X_train, y_train, batch_size= 32),\n                        epochs=20,\n                        batch_size = 32,\n                        validation_data = datagen.flow(X_train, y_train, batch_size= 8),\n                        # callbacks=[callback],\n                        verbose = 2\n                        )\n    results = leNet5.evaluate(X_test, y_test)\n    runtime = datetime.now()-start\n    return history, results, runtime","5035bb69":"# accuracy plots on training and valdiation sets\ndef plot_model(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.ylim(0, 1)\n    plt.show()","a28fefc0":"# run and get results for the first 1000 data\nmodel_w_1000_samples = train_and_evaluate_model(X_train[:1000], y_train[:1000], X_test, y_test)","5dddd69a":"# clear session and reset weights\nkeras.backend.clear_session()\nleNet5.load_weights('my_model_weights.h5')\n\n# run and get results for whole data\nmodel_w_4000_samples = train_and_evaluate_model(X_train, y_train, X_test, y_test)","b04d903c":"# print results\nprint(\"Runtime of first model: \", model_w_1000_samples[2])\nprint(\"Training loss (categorical CE) of first model: \", model_w_1000_samples[0].history['loss'][-1])\nprint(\"Training accuracy of first model: \", model_w_1000_samples[0].history['accuracy'][-1])\nprint(\"Validation loss (categorical CE) of first model: \", model_w_1000_samples[0].history['val_loss'][-1])\nprint(\"Validation accuracy of first model: \", model_w_1000_samples[0].history['val_accuracy'][-1])\nprint(\"Test loss (categorical CE) of first model: \", model_w_1000_samples[1][0])\nprint(\"Test accuracy of first model: \", model_w_1000_samples[1][1])\nplot_model(model_w_1000_samples[0])\nprint()\nprint(\"Runtime of second model: \", model_w_4000_samples[2])\nprint(\"Training loss (categorical CE) of second model: \", model_w_4000_samples[0].history['loss'][-1])\nprint(\"Training accuracy of second model: \", model_w_4000_samples[0].history['accuracy'][-1])\nprint(\"Validation loss (categorical CE) of second model: \", model_w_4000_samples[0].history['val_loss'][-1])\nprint(\"Validation accuracy of second model: \", model_w_4000_samples[0].history['val_accuracy'][-1])\nprint(\"Test loss (categorical CE) of second model: \", model_w_4000_samples[1][0])\nprint(\"Test accuracy of second model: \", model_w_4000_samples[1][1])\nplot_model(model_w_4000_samples[0])","d2c8545c":"# Exploratory Data Analysis","cb57427e":"# Model Training\n\nIn this section, we will re-implement [Yann LeCun's famous LeNet architecture](http:\/\/http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-01a.pdf) with modern modifications. This is **not about getting high scores** on the dataset since it was the first succesful CNN approach to the handwritten character recognition problem. We will try to examine what was the idea behind LeCun's experiments.","2e85b87b":"![image.png](attachment:20668fc8-e914-418b-813a-5873c004a7de.png)\n**LeNet-5 architecture:** It comprises of 7 layers, not counting the input, all of which contain trainable parameters. \n- **2 convolution layers** (C1 and C2) of 6-16 kernels with the size of 5x5. Their activation function choice is **tanh**.\n- **Sub-sampling layers** (S1 and S2) are the standard average pooling layers we know but with two differences; LeNet uses trainable multiplication coefficient+bias and selective connections to next layer. We will choose standard **average pooling** since its more straightforward.\n- 2 **fully connected** layers\n- 1 output layer with **MSE** loss. Instead, we will use **softmax**.","ed823eb2":"### COMMENTS:\n- First model gets worse results due to underfitting.\n- Second model is better since it has more data and according to the trend of training plots its success rate will be increase with additional data.\n- One drawback of second model is runtime.\n- Their memory consumption are equal since they are exactly same models with same number of parameters."}}