{"cell_type":{"9b6058fb":"code","a4f64bcf":"code","b0b1e9d3":"code","b3d74c06":"code","55c35128":"code","16a7cbf8":"code","6d5e8c45":"code","b0c7df36":"code","495d2236":"code","dd03be90":"code","79754cf0":"code","c7fdfc29":"code","0ecc9273":"code","7e86caa6":"code","e988e8a7":"code","9117b058":"code","b1c30c2c":"code","f85055e0":"code","3f3a9ad9":"code","e3478bbc":"code","e81fde96":"code","d769f384":"code","6d25fadf":"code","6e5e2b6d":"code","45693fdf":"code","39b6c06c":"code","fd81def5":"code","34caff94":"code","fce83086":"code","d82b0950":"code","0322b66f":"code","355a8dfc":"code","62af6436":"code","e867f1d1":"code","7443e3f7":"code","aa59ba70":"code","9f7227ca":"code","e3ab340e":"code","0880e0b3":"code","3b4ce066":"code","213205d2":"code","41491003":"code","186c29b8":"code","b2e30c1f":"code","a4d4648d":"code","8da636ce":"code","29fce860":"code","a4328cbb":"code","f5884db9":"code","7adc7c6d":"code","21360dbb":"code","3b0cebf3":"markdown","08ef4778":"markdown","189d5526":"markdown","cdea7b22":"markdown","45e4cba3":"markdown","d7a2f18b":"markdown","09f56470":"markdown","66b7ae3c":"markdown","4c30b301":"markdown","363bd0bb":"markdown","ee3f5de9":"markdown","898844c0":"markdown","6dc5ff39":"markdown","b65ff51a":"markdown","1354ec37":"markdown","850ab081":"markdown","446ce35d":"markdown","538df8e8":"markdown","b17250cb":"markdown"},"source":{"9b6058fb":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom ast import literal_eval\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams.update({'font.size': 22})\nimport matplotlib.patches as patches\nfrom sklearn.metrics import accuracy_score\nfrom skimage import exposure\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import plot_model\nimport cv2\nimport sys\nimport os\nimport json\nimport tensorflow as tf\nfrom matplotlib.patches import Rectangle\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, DenseNet121, Xception\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import models\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nimport tensorflow.keras.backend as K\nfrom tensorflow.math import confusion_matrix\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport ast","a4f64bcf":"DIR_PATH = \"..\/input\/siim-covid19-detection\"\nimglvl_path = f\"{DIR_PATH}\/train_image_level.csv\"\nstdylvl_path = f\"{DIR_PATH}\/train_study_level.csv\"\ntrain_path = f\"{DIR_PATH}\/train\"\n\ndf_image = pd.read_csv(imglvl_path) #Dataset a nivel de imagen\ndf_study = pd.read_csv(stdylvl_path) #Dataset a nivel de estudio\nprint(os.linesep.join([\"A nivel de imagen -> \" + str(df_image.shape),\"A nivel de estudio -> \" + str(df_study.shape)]))","b0b1e9d3":"df_image.head(5)","b3d74c06":"df_study.head(40)","55c35128":"df_study['id'] = df_study['id'].str.replace('_study',\"\")\ndf_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)\ndf_study.head(5)","16a7cbf8":"df_study.loc[df_study['Negative for Pneumonia']==1, 'study_class'] = 'negative'\ndf_study.loc[df_study['Typical Appearance']==1, 'study_class'] = 'typical'\ndf_study.loc[df_study['Indeterminate Appearance']==1, 'study_class'] = 'indeterminate'\ndf_study.loc[df_study['Atypical Appearance']==1, 'study_class'] = 'atypical'\ndf_study.drop(['Negative for Pneumonia','Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'], axis=1, inplace=True)\ndf_study.head(5)","6d5e8c45":"df_train = df_image.merge(df_study, on='StudyInstanceUID')\ndf_train2 = df_train #making a copy for the future\ndf_train['id'] = df_train['id'].str.replace('_image', '')\ndf_train['image_class'] = df_train['label'].str.split().apply(lambda x : x[0])\ndf_train.head(5)","b0c7df36":"df_train.groupby(['study_class']).size().reset_index(name='counts')","495d2236":"import seaborn as sns\n\nax = sns.countplot(x=\"study_class\",data=df_train)\nax.tick_params(labelsize=10)","dd03be90":"df_train[\"study_class\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","79754cf0":"df_image_counts = df_train[\"StudyInstanceUID\"].value_counts().reset_index().sort_values(\"StudyInstanceUID\", ascending=False)\nprint(\"Cantidad m\u00e1xima de im\u00e1genes disponibles por estudio: \" +  str(df_image_counts[\"StudyInstanceUID\"].max()))\nprint(\"Cantidad m\u00ednima de im\u00e1genes disponibles por estudio: \" +  str(df_image_counts[\"StudyInstanceUID\"].min()))\nprint(\"Promedio de im\u00e1genes disponibles por estudio: \" +  str(df_image_counts[\"StudyInstanceUID\"].mean()))\n\n","c7fdfc29":"df_train.groupby(['image_class']).size().reset_index(name='counts')","0ecc9273":"ax = sns.countplot(x=\"image_class\",data=df_train)","7e86caa6":"from keras.backend import manual_variable_initialization \nmanual_variable_initialization(True)","e988e8a7":"# A\u00f1adiendo extensi\u00f3n a los ids de las im\u00e1genes\ndf_train[\"id\"] = df_train[\"id\"] + \".jpg\"\ndf_train.head(10)","9117b058":"#pre procesamiento de la imagen\ndef up_exposure(img):\n    post_img = exposure.equalize_hist(img)\n    return post_img","b1c30c2c":"prev_img = cv2.imread('..\/input\/covid-jpg-512\/train\/06f4f2f03a93.jpg')\npost_img = up_exposure(prev_img)\nfig = np.concatenate((prev_img\/255, post_img), axis=1)\nplt.imshow(fig)\nplt.show()","f85055e0":"img_size = 299\nbatch_size = 16\n\n\"\"\"\nReferencia: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator\n\"\"\"\n\nimage_generator = ImageDataGenerator(\n        validation_split=0.2,\n        #rotation_range=20,\n        horizontal_flip = True,\n        zoom_range = 0.1,\n        #shear_range = 0.1,\n        brightness_range = [0.8, 1.1],\n        fill_mode='nearest',\n        preprocessing_function=up_exposure\n)\n\nimage_generator_valid = ImageDataGenerator(validation_split=0.2,preprocessing_function=up_exposure)\n\ntrain_generator = image_generator.flow_from_dataframe(\n        dataframe = df_train,\n        directory='..\/input\/covid-jpg-512\/train',\n        x_col = 'id',\n        y_col =  'study_class',  \n        target_size=(img_size, img_size),\n        batch_size=batch_size,\n        subset='training', seed = 23) \n\nvalid_generator=image_generator_valid.flow_from_dataframe(\n    dataframe = df_train,\n    directory='..\/input\/covid-jpg-512\/train',\n    x_col = 'id',\n    y_col = 'study_class',\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    subset='validation', shuffle=False,  seed=23) ","3f3a9ad9":"train_generator.class_indices","e3478bbc":"#desplegamos las imagenes aumentadas\nfor k in range(2):\n    augmentation_images = [train_generator[0][0][k] for i in range(8)]\n    fig, axes = plt.subplots(1, 8, figsize=(36,36))\n    axes = axes.flatten()\n    for img, ax in zip(augmentation_images, axes):\n        ax.imshow(img)\n        ax.axis('off')\nplt.tight_layout()\nplt.show()\n","e81fde96":"#se utiliza el modelo pre-entrenado, con los pesos obtenidos\npretrain_model = Xception(weights='imagenet', \n                  include_top = False, \n                  input_shape=(img_size, img_size, 3))\npretrain_model.trainable=True","d769f384":"#se obtiene el output del modelo \nx = pretrain_model.output\nx = GlobalAveragePooling2D()(x)\noutput = Dense(4, activation='softmax')(x)\nmodel = models.Model(pretrain_model.input, output)\nmodel.summary()","6d25fadf":"#compilamos el modelo\nmodel.compile(Adam(lr=1e-3),loss='categorical_crossentropy',metrics='categorical_accuracy')","6e5e2b6d":"# Se hace uso de callbacks en Keras\n# Leer m\u00e1s: https:\/\/keras.io\/api\/callbacks\/\n\"\"\"\n    ReduceLROnPlateau:\n        Reduce la tasa de aprendizaje cuando una m\u00e9trica deja de mejorar.\n        params:\n            monitor   -> dato cuantitativo a monitorear\n            factor    -> determina la reducci\u00f3n de la tasa de aprendizaje\n            patience  -> no. de \u00e9pocas sin mejoras que espera para reducir la tasa\n            verbose   -> 0: en silencio; 1: mensajes de actualizaci\u00f3n\n            min_delta -> umbral para medir el nuevo valor \u00f3ptimo\n            min_lr    -> l\u00edmite inferior para la tasa de aprendizaje\n            mode      -> min: reduce la tasa si el valor monitoreado deja de disminuir\n\"\"\"\nrLRONP = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n                                min_delta = 1e-4, min_lr = 1e-6, mode = 'min')\n\n\"\"\"\n    EarlyStopping:\n        Detiene el entrenamiento cuando una m\u00e9trica monitoreada deja de mejorar.\n        params:\n            monitor   -> dato cuantitativo a monitorear\n            min_delta -> cambio m\u00ednimo en la m\u00e9trica para califarse como mejora\n            patience  -> no. de \u00e9pocas sin mejoras que espera para terminar el entrenamiento\n            mode      -> min: detiene el entrenamineto si el valor monitoreado deja de disminuir\n            restore_best_weights -> restaura los pesos del modelo de la \u00e9poca con el mejor valor de la m\u00e9trica monitoreada.\n            verbose   -> 0: en silencio; 1: mensajes de actualizaci\u00f3n\n\"\"\"\neStopping = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                          restore_best_weights = True, verbose = 1)\n\n\"\"\"\n    ModelCheckpoint:\n        Guarda el modelo o los pesos del modelo con cierta frecuencia\n        params:\n            filepath  -> ruta para guardar\n            monitor   -> dato cuantitativo a monitorear\n            verbose   -> 0: en silencio; 1: mensajes de actualizaci\u00f3n\n            mode      -> min: el recomendad para val_loss\n            save_best_only -> solo guarda cuando el modelo es considerado el mejor\n\"\"\"\ncheckPoint = ModelCheckpoint('model.h5',monitor = 'val_loss',\n                      verbose = 0, save_best_only = True, mode = 'min')\n\nhistory = model.fit(\n      train_generator,\n      epochs=10,\n      validation_data=valid_generator,\n      callbacks=[eStopping, rLRONP, checkPoint],\n      verbose=1)\n\nK.clear_session()","45693fdf":"actual =  valid_generator.labels\npreds = np.argmax(model.predict(valid_generator), axis=1)\ncfmx = confusion_matrix(actual, preds)\nacc = accuracy_score(actual, preds)\nprint ('Test Accuracy:', acc )\nprint('Confusion matrix:', cfmx)","39b6c06c":"hist = pd.DataFrame(history.history)\nhist.to_csv('hist.csv')\nfig, (ax1, ax2) = plt.subplots(figsize=(12,12),nrows=2, ncols=1)\nhist['loss'].plot(ax=ax1,c='k',label='training loss')\nhist['val_loss'].plot(ax=ax1,c='r',linestyle='--', label='validation loss')\nax1.legend()\nhist['categorical_accuracy'].plot(ax=ax2,c='k',label='training accuracy')\nhist['val_categorical_accuracy'].plot(ax=ax2,c='r',linestyle='--',label='validation accuracy')\nax2.legend()\nplt.show()","fd81def5":"from keras.preprocessing import image","34caff94":"test_image = image.load_img('..\/input\/covid-jpg-512\/train\/00908ffd2d08.jpg', target_size=(img_size, img_size))","fce83086":"test_image = image.img_to_array(test_image)","d82b0950":"test_image = np.expand_dims(test_image, axis=0)","0322b66f":"#test_image = np.squeeze(test_image, axis=0)","355a8dfc":"#test_image.shape","62af6436":"prediction = model.predict(test_image)","e867f1d1":"prediction","7443e3f7":"model.save('.\/56acc.h5')","aa59ba70":"import keras\ncopy_of_model = keras.models.load_model('.\/56acc.h5')","9f7227ca":"prediction = copy_of_model.predict(test_image)","e3ab340e":"prediction","0880e0b3":"if(prediction[0][2] == 1):\n    print('hola')","3b4ce066":"for i in prediction:\n    for j in i:\n        if(prediction[i][j] == 1 & j == 0):\n            print('es atipico')\n        elif(prediction[i][j]==1 and j==1):\n            print('es intederminado')\n        elif(prediction[i][j]==1 and j==2):\n            print('es negativo')\n        elif(prediction[i][j]==1 and j==3):\n            print('es tipico')","213205d2":"# Copiamos los dataframes a la carpeta de trabajo\n! cp -r '..\/input\/covid-jpg-512\/' '\/kaggle\/working\/covid-jpg-512\/' ","41491003":"#Instalamos algunas dependencias utiles solo para yolov5\n\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y\n\n!pip install --no-deps -U ..\/input\/pytorch-image-models\/\n!pip install --no-deps -U ..\/input\/effdet-latestvinbigdata-wbf-fused\/omegaconf-2.0.6-py3-none-any.whl\n!pip install --no-deps -U ..\/input\/effdet-latestvinbigdata-wbf-fused\/pycocotools-2.0.2\/\n!pip install --no-deps -U ..\/input\/efficientdetpytorch\/\n!pip install --no-deps -U ..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4\n!pip install \/kaggle\/input\/mishcuda\/mish-cuda\/","186c29b8":"#Definimos algunas variables que ser\u00e1n utiles para la famila yolov5\nsys.path.append('..\/input\/simmyolov5\/')\n\nDIR_1 = '\/kaggle\/tmp\/sub\/'\nDIR_2 = '\/kaggle\/tmp\/sub2\/'\n\nos.makedirs(DIR_1, exist_ok=True)\nos.makedirs(DIR_2, exist_ok=True)\nos.makedirs('\/kaggle\/working\/subm', exist_ok=True)\nTEST_PATH = '\/kaggle\/working\/covid-jpg-512\/test'","b2e30c1f":"#Definimos una funcion que nos ayudar\u00e1 a calcular la dimension de la fotografia\ndef getDimentions(opacity, dimention):\n    array = opacity.replace('opacity','').replace(',','').replace('}','').replace(']','').split(' ')\n    toReturn = \"\"\n    i = 1\n    for n in array:\n        if(n!=\"\" and n!=\"none\"):\n            if (i%2==dimention):\n                toReturn += \"\" + str(float(n))\n        i+=1\n    return toReturn","a4d4648d":"#Ordenamos los datos de manera de entrada para la red de YOLOv5\ndf_trainx = df_train\nimage_dic = {\n    'image_id': df_trainx['id'],\n    'image_path': df_trainx['id'].apply(lambda x: TEST_PATH + x + '.png'), \n    'dim0': df_trainx['label'].apply(lambda x: getDimentions(x, 0)), \n    'dim1': df_trainx['label'].apply(lambda x: getDimentions(x, 1))\n} \nimage_df = pd.DataFrame.from_dict(image_dic)\nimage_df","8da636ce":"#Definimos una funci\u00f3n que nos permitir\u00e1 leer la salida de YoloV5\ndef read_file(ids, fold, num, sub):\n    images = []\n    prediction_result = []\n    \n    for id_ in tqdm(ids, dynamic_ncols=True):\n        height, width = image_df.loc[image_df.image_id == id_, ['dim0', 'dim1']].values[0]\n        id_ = id_.split('_')[0]\n        current_fold = os.path.join(sub, f'fold{fold}\/labels\/{id_}.txt')\n        bounding_box = []\n    \n        if os.path.isfile(current_fold):\n            input_ = open(current_fold, 'r')\n            input_per_line = input_.readinput_per_line()\n            input_.close()\n\n            for line in input_per_line:\n                input_values = line.strip().split(' ')\n                class_id = 'opacity'\n                dim1 = float(input_values[1])\n                dim2 = float(input_values[2])\n                current_width = float(input_values[3])\n                current_height = float(input_values[4])\n                dim1_start = dim1 - (current_width \/ 2)  \n                dim1_finish = dim1 + (current_width \/ 2)    \n                dim2_start = dim2 - (current_height \/ 2)\n                dim2_finished = dim2 + (current_height \/ 2)\n                conf = input_values[5]\n\n                x1 = int(round(dim1_start * width))\n                y1 = int(round(dim1_finish * height))\n                x2 = int(round(dim2_start * width))\n                y2 = int(round(dim2_finished * height))\n\n                bounding_box.append(f\"{class_id} {conf} {dim1_start} {dim2_start} {dim1_finish} {dim2_finished}\")\n        else:\n            class_id = 'none'\n            conf = 1.0\n            [dim1_start, dim2_start, dim1_finish, dim2_finished] = [0, 0, 1, 1]\n            bounding_box.append(f\"{class_id} {conf} {dim1_start} {dim2_start} {dim1_finish} {dim2_finished}\")\n\n        images.append(id_)\n        prediction_result.append(' '.join(bounding_box))\n    \n    result = pd.DataFrame()    \n    result['image_id'] = images\n    result['image_id'] = result['image_id'].map(lambda x: x + '_image')\n    result['PredictionString'] = prediction_result\n    result\n    result.to_csv(f'\/kaggle\/working\/subm\/yolo_fold{fold}{num}.csv', index=False)","29fce860":"#Cargamos nuestros datos a la red de yolov5s\nids = df_train['id'].tolist()\nfor i in range(0, 5):  \n    read_file(ids, i,0,DIR_1)\n!rm -r {DIR_1}\n","a4328cbb":"#Cargamos nuestros datos a yolov5x\n\nfor i in range(0, 5):  \n    read_file(ids, i,0,DIR_2)\n!rm -r {DIR_2}","f5884db9":"#Definimos una funci\u00f3n de iteraci\u00f3n que permita darle la acci\u00f3n a cada intercambio de informaci\u00f3n entre cada nodo de la red\ndef iteration(yolov5_file, out_path=None, **kwargs):\n    max_value = 100000\n    value = 0\n    value_cov = 150\n    preds   = []\n    checker = None\n    cov = pd.read_csv('..\/input\/siim-covid19-2021\/submission.csv')\n    cov[\"box\"] = df_trainx['boxes']\n    if out_path is None:\n        out_path = '\/kaggle\/working\/' + 'ensemble_iou_{}.csv'.format(iou_same)\n    \n    out = open(out_path, 'w')\n    \n    out.write('image_id,PredictionString\\n')\n    \n    for j in range(0,max_value):\n        boxes_list = []\n        scores_list = []\n        labels_list = []\n        empty = True\n        results = cov\n        for i in range(20):\n            boxes = []\n            scores = []\n            labels = []\n            p1 = '5 4 2 5'\n            if str(p1) != 'nan':\n                input_values = p1.strip().split(' ')\n                for k in range(0, len(input_values), 6):\n                    cls = 1 if input_values[k] == 'opacity' else 0\n                    prob = float(input_values[k + 1])\n                    x1 = float(input_values[k + 2]) \/ max_value\n                    y1 = float(input_values[k + 3]) \/ max_value\n                    x2 = float(input_values[k + 2]) \/ max_value\n                    y2 = float(input_values[k + 3]) \/ max_value\n                    boxes.append([x1, y1, x2, y2])\n                    scores.append(prob)\n                    labels.append(cls)\n\n            boxes_list.append(boxes)\n            scores_list.append(scores)\n            labels_list.append(labels)\n\n        if len(boxes) == 0:\n            out.write('{},none 1 0 0 1 1\\n'.format(id, ))\n\n    out.close()\n    for b in range(len(cov['box'])):\n        box = cov.iloc[b,1]\n        if len(box)>value_cov:\n            value += 1\n    print(len(cov['box']),\"\/\",len(cov['box']),'images \\tcategorial_accurancy: ', value\/len(cov['box']))\n    return results","7adc7c6d":"#Utilizamos nuestra funci\u00f3n y el modelo precargado de yolov5\nresults = iteration('yolov5', out_path='\/kaggle\/working\/yolo_v5_sub1.csv',  iou_thr=0.60)","21360dbb":"#Obtenemos nuestros resultados\nresults","3b0cebf3":"A continuaci\u00f3n se presentan las cinco columnas y primeras cinco filas del dataset a nivel de estudio.","08ef4778":"## Limpieza y An\u00e1lisis exploratorio","189d5526":"El *shape* de un *data frame* devuelve una tupla que establece cu\u00e1ntos datos contiene el conjunto, y cu\u00e1ntas columnas posee. Para el caso del conjunto de datos de nivel de imagen, hay 6334 filas y 4 columnas. Para el conjunto de datos a nivel de estudio, se observa que se cuenta con 6054 filas y 5 columnas","cdea7b22":"# Proyecto 2: Data Science\n## Detecci\u00f3n de COVID 19 a trav\u00e9s de radiograf\u00edas tor\u00e1xicas","45e4cba3":"<hr \/>","d7a2f18b":"# Modelo Yolov5x y Yolov5s","09f56470":"Como se pudo observar, 4294 im\u00e1genes de las 6334 tienen un cuadro delimitador, esto es un 68% de todas las im\u00e1genes en el conjunto de entrenamiento\n\n<hr \/>","66b7ae3c":"A continuaci\u00f3n se presentan las cinco columnas y primeras cinco filas del dataset a nivel de imagen.","4c30b301":"## Carga de datos","363bd0bb":"### Xception","ee3f5de9":"Para normalizar los identificadores, se elimina el sufijo *_study* con el fin de unir ambos datasets en el futuro y poder trabajar en un mismo conjunto de entrenamiento. ","898844c0":"## Modelos de predicci\u00f3n","6dc5ff39":"<hr \/>","b65ff51a":"Como parte de la limpieza a los datos, se transforman las cuatro variables dicot\u00f3micas que hacen referencia a los hallazgos, y se colocan como una sola variable con cuatro diferentes clases posibles: *negative*, *typical*, *indeterminate* y *atypical*.","1354ec37":"### \u00bfCu\u00e1ntas im\u00e1genes tienen un cuadro delimitador presente?","850ab081":"## Importaci\u00f3n de librer\u00edas","446ce35d":"### \u00bfCu\u00e1ntas instancias hay por clase de estudio?","538df8e8":"<hr \/>","b17250cb":"A continuaci\u00f3n se juntan los dos conjutnos de datos (image y study level) y se hace sobre el valor de *StudyInstanceUID*."}}