{"cell_type":{"2267be6a":"code","a6310db5":"code","f063d435":"code","099bc67c":"code","31cda5fe":"code","50492918":"code","b8fdad61":"code","bc712e27":"code","98c090d1":"code","b5bfd1d0":"code","d8a083c8":"code","64d00d6c":"code","9d01b429":"code","a0cec137":"code","2756e5d3":"code","8a1e58d1":"code","721fc355":"code","1a3bacf8":"code","cc75423c":"code","c35c7963":"markdown","69dfa3d0":"markdown","652bb03a":"markdown","6bc72644":"markdown"},"source":{"2267be6a":"import numpy as np\nimport pandas as pd\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport re\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = 20, 15\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.models import Sequential\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","a6310db5":"df = pd.read_csv('..\/input\/twitter-and-reddit-sentimental-analysis-dataset\/Reddit_Data.csv')\ndf.dropna(inplace=True)\ndf.category.value_counts(normalize=True)","f063d435":"df = df.sample(n=10000).reset_index(drop=True)\ndf.category.value_counts(normalize=True)\ndf.columns = ['Comment', 'Category']\ndf","099bc67c":"X, y = df.iloc[:,:-1],df.iloc[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(f'X_train, X_test, y_train, y_test shapes are {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')","31cda5fe":"allwords = \" \".join([com for com in df.Comment])\nwc = WordCloud().generate(allwords)\nplt.imshow(wc,interpolation='bilinear')\nplt.axis('off')","50492918":"new = df.Comment.apply(lambda x:len(x))\nplt.hist(new)","b8fdad61":"# Vocab size\nvocab_size = 5000\n\ndef preprocess(messages, sentence_length=60):\n    # Stemming\n    ps = PorterStemmer()\n    corpus = []\n    for i in range(len(messages)):\n        review = re.sub('^a-zA-Z', ' ', messages[i])\n        review = review.lower()\n        review = review.split()\n        review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n        review = ' '.join(review)\n        corpus.append(review) \n    # Oen hot coding\n    oh_repr = [one_hot(sent, vocab_size) for sent in corpus]\n\n    padded_seq = pad_sequences(oh_repr, maxlen=sentence_length)\n    return padded_seq","bc712e27":"padded_seq = preprocess(X_train.Comment.reset_index(drop=True))\npadded_seq.shape","98c090d1":"no_of_features = 200\nsent_len=60\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, no_of_features, input_length=sent_len))\nmodel.add(LSTM(100, return_sequences=True))\nmodel.add(Dropout(.2))\nmodel.add(LSTM(100))\nmodel.add(Dropout(.2))\nmodel.add(Dense(3,activation='softmax'))\nmodel.compile(optimizer=Adam(.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Add callbacks\nfilepath = '.\/Sentiment.h5'\ncheckpoint = ModelCheckpoint(filepath, save_best_only=True, verbose=1)\nearlystop = EarlyStopping(patience=5, verbose=1)\n#csvlg = CSVLogger('mylogs.csv', separator=',', append=False)\n\ncallback_list = [earlystop, checkpoint]\n","b5bfd1d0":"enc = LabelEncoder()\ny = enc.fit_transform(y_train)\n\nX, y = np.array(padded_seq), np.array(y)","d8a083c8":"history = model.fit(X, y, validation_split=.2, epochs=30, batch_size=32, callbacks=callback_list)","64d00d6c":"def plot_history(history):\n    plt.plot(history['loss'], label='Original loss')\n    plt.plot(history['val_loss'], label='Validation loss')\n    plt.plot(history['accuracy'], label='Original accuracy')\n    plt.plot(history['val_accuracy'], label='Validation accuracy')\n    plt.legend()\nplot_history(history.history)","9d01b429":"model.evaluate(preprocess(X_test.Comment.reset_index(drop=True)), enc.transform(y_test))","a0cec137":"def polarity(text):\n    return TextBlob(text).sentiment.polarity\ndef subjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n    \n\ndf['polarity'] = df.Comment.apply(polarity)\ndf['subjectivity'] = df.Comment.apply(subjectivity)\ndf","2756e5d3":"X, y = df.iloc[:,-2:],df.iloc[:,-3]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(f'X_train, X_test, y_train, y_test shapes are {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')","8a1e58d1":"X[:5], y[:5]","721fc355":"classifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\n","1a3bacf8":"preds = classifier.predict(X_test)\npreds","cc75423c":"accuracy_score(y_test,preds)","c35c7963":"# Imports","69dfa3d0":"# Preprocessing","652bb03a":"# TextBlob","6bc72644":"# Model"}}