{"cell_type":{"8aba2068":"code","bcff0095":"code","5353d5ad":"code","84da0b5e":"code","1c0b107a":"code","60d20a6d":"code","ff62bc00":"code","ad7efbc4":"code","6990764b":"code","73142f1d":"code","f02ece3a":"code","bb1885e6":"code","1242c519":"code","48e0eade":"code","143906c8":"code","48bdf8e2":"code","8109d6fc":"code","5ecc7b8e":"code","9bee0859":"code","ae98de7b":"code","684f9921":"code","e1af2ef2":"code","2c1dc897":"code","5a3dd3e4":"code","8ec54abd":"code","a5a1907d":"code","29c802a5":"code","56fd094d":"code","5a2accd1":"code","ba2fbacf":"code","db6a8421":"code","e7c585a1":"code","3beabbb8":"code","999ef6d2":"code","152c7633":"code","36485546":"code","c5c5e3ec":"code","975c500b":"code","e5de7955":"code","3eae82b9":"code","6fd5adc2":"code","6e40f2e9":"markdown","8402c6bf":"markdown"},"source":{"8aba2068":"#importing data visualization and manipulation libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n#importing machine learning libraries\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.model_selection import train_test_split","bcff0095":"#importing dataset\n\ndf = pd.read_csv(\"\/kaggle\/input\/co2-emission-by-vehicles\/CO2 Emissions_Canada.csv\")","5353d5ad":"#checking for null values, didn't expect any\n\ndf.isnull().sum()","84da0b5e":"#I chose to rename this column to something easier to type as it is used very frequently \n\ndf.rename(columns={'CO2 Emissions(g\/km)' : 'CO2_emission'}, inplace=True)","1c0b107a":"df2 = df.copy()","60d20a6d":"df2.drop('Fuel Consumption Comb (mpg)', axis = 1, inplace = True)","ff62bc00":"df2.rename(columns={'Fuel Consumption Comb (L\/100 km)' : 'Fuel_Cons_comb_(l\/100km)'}, inplace=True)\ndf2.rename(columns={'Fuel Consumption Hwy (L\/100 km)' : 'Fuel_Cons_hwy_(l\/100km)'}, inplace=True)\ndf2.rename(columns={'Fuel Consumption City (L\/100 km)' : 'Fuel_Cons_city_(l\/100km)'}, inplace=True)","ad7efbc4":"df2.rename(columns={'Fuel Type' : 'Fuel_type'}, inplace=True)","6990764b":"#updated dataset\n\ndf","73142f1d":"#getting to know the dataset a little more in the next few steps\n\ndf['Fuel Type'].value_counts()","f02ece3a":"df['Transmission'].value_counts()","bb1885e6":"#discovering correlation\n\ndf.corr()['CO2_emission'].sort_values()","1242c519":"#heatmap for a better understanding of correlated values\n\nplt.figure(figsize = (8,6))\ncorr = df.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap = 'Blues', square = True)","48e0eade":"#I have a habit of using pairplot function of seaborn to see how each individual graph looks like\n\nsns.pairplot(df)","143906c8":"#Some visualizations to show our understanding of the dataset\n\nmkI = df['Make'].value_counts().index\nmkV = df['Make'].value_counts().values\nplt.figure(figsize = (10,8))\nsns.barplot(mkI,mkV)\nplt.xticks(rotation='vertical')","48bdf8e2":"mkI = df['Vehicle Class'].value_counts().index\nmkV = df['Vehicle Class'].value_counts().values\nplt.figure(figsize = (10,8))\nsns.barplot(mkV,mkI, orient = 'h', palette='Spectral')\nplt.xticks(rotation='vertical')","8109d6fc":"#this boxplot shows us that Vans typically emit more CO2 when compared to other vehicle classes\n\nplt.figure(figsize = (10,8))\nsns.boxplot(x=\"Vehicle Class\", y=\"CO2_emission\", data=df)\nplt.xticks(rotation = 'vertical')","5ecc7b8e":"sns.boxplot(df['Fuel Consumption City (L\/100 km)'], color = \"red\")\nplt.show()\nsns.boxplot(df['Fuel Consumption Hwy (L\/100 km)'])\nplt.show()\nsns.boxplot(df['Fuel Consumption Comb (L\/100 km)'], color = 'green')\nplt.show()","9bee0859":"plt.figure(figsize = (10,8))\nsns.boxplot(x = 'Fuel Type' , y = 'CO2_emission', data = df)\nplt.xticks([0,1,2,3,4],['Premium Gasoline','Diesel','Regular Gasoline','Ethanol','Natural Gas'])\nplt.show()","ae98de7b":"plt.figure(figsize = (10,8))\nsns.catplot(x = 'Cylinders' , y = 'CO2_emission', data = df)\nplt.show()","684f9921":"#Ethanol typically is the most efficient fuel type \n\nplt.figure(figsize = (10,8))\nsns.boxplot(y = 'Fuel Consumption Comb (mpg)', x = 'Fuel Type', data = df, palette = 'muted')\nplt.xticks([0,1,2,3,4],['Premium Gasoline','Diesel','Regular Gasoline','Ethanol','Natural Gas'])","e1af2ef2":"plt.figure(figsize = (10,8))\nsns.distplot(df['Fuel Consumption Comb (mpg)'], bins = 10, color = 'purple')","2c1dc897":"df2.drop('Make', axis = 1, inplace = True)\ndf2.drop('Model', axis = 1, inplace = True)\ndf2.drop('Vehicle Class', axis = 1, inplace = True)","5a3dd3e4":"df2","8ec54abd":"from sklearn.preprocessing import LabelEncoder\n\nencode = LabelEncoder()\n\nencode.fit(df2.Fuel_type.drop_duplicates()) \ndf2.Fuel_type = encode.transform(df2.Fuel_type)\n\nencode.fit(df2.Transmission.drop_duplicates())\ndf2.Transmission = encode.transform(df2.Transmission)","a5a1907d":"#assigning dependent and independent variables\n#can be used with any column across the dataset provided hyperparameters are adjusted accordingly\n\nx = df2.iloc[:, :-1].values\ny = df2.iloc[:, -1].values","29c802a5":"#splitting and reshaping data into testing and training sets\n\nxTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = 0.2, random_state = 0)\n\n# xTrain= xTrain.reshape(-1, 1)\n# yTrain= yTrain.reshape(-1, 1)\n# xTest = xTest.reshape(-1, 1)\n# yTest = yTest.reshape(-1, 1)","56fd094d":"#linear regression model achieving 85% accuracy\n#at the end of the kernel I attempted to create and use my own linear regression model to find out coefficient and intercept without using scikit learn\n\nreg = LinearRegression()\nreg.fit(xTrain, yTrain)\nregYpred = reg.predict(xTest)\nprint(reg.score(xTest,yTest))","5a2accd1":"#I printed the coefficient and the intercept here to compare my model built from scratch against the imported scikit learn model\n\nprint('regression coefficient', reg.coef_, 'intercept', reg.intercept_)","ba2fbacf":"f, ax = plt.subplots(1, figsize=(10, 8), sharex=True)\n\nsns.stripplot(y = yTest.flatten(), color = 'darkmagenta', alpha = 0.7, label = 'Test Data')\nsns.stripplot(y = regYpred.flatten(), color = 'lawngreen', alpha = 0.7, label = 'Train Data')\nplt.legend()\nplt.show()","db6a8421":"#I used these histograms to show Predicted values vs. Actual values in all three models\n\nsns.distplot(regYpred, bins = 20, color = 'red')\nplt.title = 'Predicted values'\nplt.show()\nsns.distplot(yTest, bins = 20)\nplt.title = 'Actual values'\nplt.show()","e7c585a1":"#Regression line showing best fit\n\nsns.regplot(x = 'Fuel Consumption Comb (L\/100 km)', y = 'CO2_emission', data  = df, color = 'blue')","3beabbb8":"#Decision Tree model got us a higher accuracy at 88%\n\nfrom sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor(random_state = 0)\ndtr.fit(xTrain, yTrain)\ndtrYpred = dtr.predict(xTest)\ndtrScore = r2_score(yTest,dtrYpred)\nprint('Score: %.3f' % dtrScore)","999ef6d2":"f, ax = plt.subplots(1, figsize=(10, 8), sharex=True)\n\nsns.stripplot(y = yTest.flatten(), color = 'darkmagenta', alpha = 0.7, label = 'Test Data')\nsns.stripplot(y = dtrYpred.flatten(), color = 'lawngreen', alpha = 0.7, label = 'Train Data')\nplt.legend()\nplt.show()","152c7633":"sns.distplot(dtrYpred, bins = 20, color = 'red')\nplt.show()\nsns.distplot(yTest, bins = 20)\nplt.show()","36485546":"#Random Forest Regressor had the highest accuracy standing at 89%\n#I used a for loop for the n estimators to see which yielded the highest accuracy, it landed at 20\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators = 20, random_state = 0)\nrfr.fit(xTrain, yTrain)\nrfrYpred = rfr.predict(xTest)\nrfrScore = r2_score(yTest,rfrYpred)\nprint('Score: %.3f' % rfrScore)","c5c5e3ec":"f, ax = plt.subplots(1, figsize=(10, 8), sharex=True)\n\nsns.stripplot(y = yTest.flatten(), color = 'darkmagenta', alpha = 0.7, label = 'Test Data')\nsns.stripplot(y = regYpred.flatten(), color = 'lawngreen', alpha = 0.7, label = 'Train Data')\nplt.legend()\nplt.show()","975c500b":"sns.distplot(rfrYpred, bins = 20, color = 'red')\nplt.show()\nsns.distplot(yTest, bins = 20)\nplt.show()","e5de7955":"#calculating mean of x and y values\n\nX,Y = xTrain,yTrain\nxMean = np.mean(X)\nyMean = np.mean(Y)","3eae82b9":"#calculating variance and covariance\n\ncovar = 0\nvar = 0\nfor i in range (len(X)):\n    covar += (X[i] - xMean) * (Y[i] - yMean)\n    var += (X[i]-xMean) ** 2      ","6fd5adc2":"#computing coefficient and intercepts based on previous calculations\n\ncoeff = covar\/var\nintercept = yMean - (coeff * xMean)\n\nprint('intercept is',intercept, 'coefficient is', coeff)","6e40f2e9":"Below is my attempt to build my own linear regression model from scratch to calculate coefficient and slope of the regression line","8402c6bf":"This was my first attempt to build a linear regression model from scratch. Any and all critiques welcomed!"}}