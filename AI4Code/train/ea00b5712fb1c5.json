{"cell_type":{"430a912b":"code","4c23d493":"code","c1d814af":"code","56b1e45b":"code","7e9cb6e5":"code","82c5d305":"code","fcd46613":"code","e892ca6c":"code","dbdbe8fb":"code","400e40bd":"code","6431f185":"code","27b428fd":"code","ab38dc65":"code","9f25e1b5":"code","afd10bdd":"code","8802202c":"code","a18593e5":"code","ca85f88d":"code","cd55bbb0":"code","c5cd1232":"code","8911d66b":"code","d800d26a":"code","11f49e46":"code","e0ce6b96":"code","6f74ffd5":"code","0455d91b":"code","30a42fe3":"code","999ad1dc":"code","36230c95":"code","f3b0a826":"code","2a6e7f27":"code","7e2eba37":"code","8dd6aecb":"markdown","9d0ca3cd":"markdown","56908320":"markdown","11d6ebda":"markdown","a435a7c4":"markdown","f9be5fe4":"markdown","d12185f3":"markdown","12cecc02":"markdown","0fcf8f11":"markdown","fb715d88":"markdown","5277adfd":"markdown","cbc57e2c":"markdown","46893adb":"markdown","55c2ffe4":"markdown","0e4bcee1":"markdown","8535f0e5":"markdown","6b0c9f54":"markdown","ca1fa5c3":"markdown","57165854":"markdown","b2a37ad0":"markdown","3da27561":"markdown","8cc57e3f":"markdown","6f1736e4":"markdown"},"source":{"430a912b":"import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4c23d493":"test_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain_data.head()","c1d814af":"train_data = train_data[train_data['Embarked'].notna()]\ntrain_data['Embarked'].isnull().sum()\ntrain_data.head()","56b1e45b":"clean_data = train_data.drop(['PassengerId','Survived'], axis=1)\nclean_data.head()","7e9cb6e5":"clean_test_data = test_data.drop(['PassengerId'], axis=1)\nclean_test_data.head()","82c5d305":"clean_data['CabinType'] = clean_data['Cabin'].fillna('X')\nclean_test_data['CabinType'] = clean_test_data['Cabin'].fillna('X')","fcd46613":"clean_data['CabinType'] = clean_data['CabinType'].apply(lambda x: x[0])\nclean_data['CabinType'] = clean_data['CabinType'].astype('category')\nclean_data['CabinType'] = clean_data['CabinType'].cat.codes\nclean_data.sample(3)","e892ca6c":"clean_test_data['CabinType'] = clean_test_data['CabinType'].apply(lambda x: x[0])\nclean_test_data['CabinType'] = clean_test_data['CabinType'].astype('category')\nclean_test_data['CabinType'] = clean_test_data['CabinType'].cat.codes\nclean_test_data.sample(3)","dbdbe8fb":"clean_data['Cabin'] = (clean_data['Cabin'].notnull()).astype('int')\nclean_test_data['Cabin'] = (clean_test_data['Cabin'].notnull()).astype('int')","400e40bd":"clean_data['Title'] = clean_data['Name'].str.extract(' ([A-Za-z]+)\\.')\nclean_data['Title'] = clean_data['Title'].replace(['Ms', 'Mlle'], 'Miss')\nclean_data['Title'] = clean_data['Title'].replace(['Mme', 'Countess', 'Lady', 'Dona'], 'Mrs')\nclean_data['Title'] = clean_data['Title'].replace(['Dr', 'Major', 'Col', 'Sir', 'Rev', 'Jonkheer', 'Capt', 'Don'], 'Mr')\nclean_data = clean_data.drop(['Name'], axis=1)\nclean_data.head()","6431f185":"clean_test_data['Title'] = clean_test_data['Name'].str.extract(' ([A-Za-z]+)\\.')\nclean_test_data['Title'] = clean_test_data['Title'].replace(['Ms', 'Mlle'], 'Miss')\nclean_test_data['Title'] = clean_test_data['Title'].replace(['Mme', 'Countess', 'Lady', 'Dona'], 'Mrs')\nclean_test_data['Title'] = clean_test_data['Title'].replace(['Dr', 'Major', 'Col', 'Sir', 'Rev', 'Jonkheer', 'Capt', 'Don'], 'Mr')\nclean_test_data = clean_test_data.drop(['Name'], axis=1)\nclean_test_data.head()","27b428fd":"clean_data['Ticket']","ab38dc65":"clean_data['Ticket'] = clean_data['Ticket'].apply(lambda x: x[0:3])\nclean_data['Ticket'] = clean_data['Ticket'].astype('category')\nclean_data['Ticket'] = clean_data['Ticket'].cat.codes\nclean_data.sample(3)","9f25e1b5":"clean_test_data['Ticket'] = clean_test_data['Ticket'].apply(lambda x: x[0:3])\nclean_test_data['Ticket'] = clean_test_data['Ticket'].astype('category')\nclean_test_data['Ticket'] = clean_test_data['Ticket'].cat.codes\nclean_test_data.sample(3)","afd10bdd":"clean_data['FamSize'] = clean_data['SibSp']+clean_data['Parch']\nclean_data.sample(3)","8802202c":"clean_test_data['FamSize'] = clean_test_data['SibSp']+clean_test_data['Parch']\nclean_test_data.sample(3)","a18593e5":"clean_data['Alone'] = (clean_data['FamSize']==0).astype('int')\nclean_data.sample(3)","ca85f88d":"clean_test_data['Alone'] = (clean_test_data['FamSize']==0).astype('int')\nclean_test_data.sample(3)","cd55bbb0":"sns.set_style('white')","c5cd1232":"sns.boxplot(x = 'Pclass', y = 'Age', data = clean_data,  palette = 'rainbow')","8911d66b":"sns.distplot(clean_data['Age'])","d800d26a":"sns.boxplot(x = 'Survived', y = 'Age', data = train_data, palette = 'prism')","11f49e46":"sns.countplot(x='Sex',data=clean_data)","e0ce6b96":"plt.figure(figsize=(10,10))\nsns.heatmap(clean_data.corr(),linewidths=0.1,vmax=1.0, square=True, cmap='coolwarm', linecolor='white', annot=True).set_title(\"Correlation Map\")","6f74ffd5":"clean_data.info()","0455d91b":"clean_data['Alone'] = clean_data['Alone'].astype('object', copy=True, errors='raise')\nclean_data['Ticket'] = clean_data['Ticket'].astype('object', copy=True, errors='raise')\nclean_data['Cabin'] = clean_data['Cabin'].astype('object', copy=True, errors='raise')\nclean_data['CabinType'] = clean_data['CabinType'].astype('object', copy=True, errors='raise')\nclean_data['Pclass'] = clean_data['Pclass'].astype('object', copy=True, errors='raise')\nclean_data.sample(4)","30a42fe3":"clean_test_data['Alone'] = clean_test_data['Alone'].astype('object', copy=True, errors='raise')\nclean_test_data['Ticket'] = clean_test_data['Ticket'].astype('object', copy=True, errors='raise')\nclean_test_data['Cabin'] = clean_test_data['Cabin'].astype('object', copy=True, errors='raise')\nclean_test_data['CabinType'] = clean_test_data['CabinType'].astype('object', copy=True, errors='raise')\nclean_test_data['Pclass'] = clean_test_data['Pclass'].astype('object', copy=True, errors='raise')\nclean_test_data.sample(4)","999ad1dc":"s = (clean_data.dtypes == 'object')\ncategorical_cols = list(s[s].index)\n\nt = (clean_data.dtypes != 'object')\nnumerical_cols = list(t[t].index)","36230c95":"numerical_transformer = Pipeline(steps = [\n    ('imputer',SimpleImputer(strategy = 'most_frequent')),\n    ('scaler', StandardScaler(with_mean = False))\n])\n\ncategorical_transformer = Pipeline(steps = [\n    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown = 'ignore')),\n    ('scaler', StandardScaler(with_mean = False))\n])\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","f3b0a826":"y = train_data[\"Survived\"]\nX = clean_data\nX_test = clean_test_data\nX.columns = clean_data.columns\nX_test.columns = clean_test_data.columns\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size = 0.2, random_state = 1)\n\n\ndemo_model = RandomForestClassifier(n_estimators = 100, max_depth = 8, max_features = 'auto', random_state = 1)\n\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', demo_model)])\n\npipeline.fit(train_X, train_y)\n\nval_predictions = pipeline.predict(val_X)\n\n\nprint(classification_report(val_y, val_predictions)) ","2a6e7f27":"predictions = pipeline.predict(X_test)","7e2eba37":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\noutput","8dd6aecb":"# Model","9d0ca3cd":"Let's drop the column which aren't very significant.","56908320":"Import the data.","11d6ebda":"Create a Pipeline.","a435a7c4":"Save them.","f9be5fe4":"Thanks for checking out my notebook. If you found it helpful, please do upvote. Have a great day.","d12185f3":"Let's predict!","12cecc02":"# Pipeline","0fcf8f11":"# Submission","fb715d88":"Let's now find out the family sizes.","5277adfd":"Generate a new feature called \"Title\".","cbc57e2c":"Filling X for passengers with no cabins.","46893adb":"Differentiate numberical columns from the non-numerical ones.","55c2ffe4":"# Prediction","0e4bcee1":"# Clean the Data","8535f0e5":"There is a pattern in cabin names which can tell us the type of cabin.\n\nThe format of a cabin number is - **{letter}{number}**\n\nThis letter can tell us the type of cabin.","6b0c9f54":"Having a cabin could be a sign of importance of a person, so let's put false for the NaN values and true for the rest.","ca1fa5c3":"# Set up the enviornment","57165854":"# Data Visualisation","b2a37ad0":"# Feature Engineering","3da27561":"The \"Embarked\" column has some NaN values. To fix that we will remove the rows containing them. We are doing this because it doesn't affect our model very much as there are only two of them.","8cc57e3f":"Let's now explore the ticket numbers.","6f1736e4":"Import all of the necessary libraries."}}