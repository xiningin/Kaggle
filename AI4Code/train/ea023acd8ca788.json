{"cell_type":{"bc1024b1":"code","a9e17984":"code","d9cbe831":"code","776a66ab":"code","5f54185f":"code","8ea61445":"code","269807e4":"code","27d4d065":"code","2b9d0810":"code","16948336":"code","4003c25b":"code","734b7924":"code","efb7941f":"code","a8d05fa2":"code","8b043f35":"code","cc8acc0e":"code","bb5d5dcd":"code","c8ee0e7f":"code","f5068873":"code","2d0f8c0c":"code","000b904b":"code","d22f5022":"code","05673eae":"code","f0cef0a2":"code","fdb8e849":"code","500e548b":"code","229f9564":"code","c4a0048a":"code","80f4b1f1":"code","5039103e":"code","013a74f5":"code","453c7314":"code","d92a4542":"code","c33f87c8":"code","d2358c69":"code","3b58cf6d":"code","a8fde6ef":"code","cdae75e1":"code","d00aecfa":"code","f959f53a":"markdown","da115523":"markdown","3a4034aa":"markdown","3fe40806":"markdown","90298ffc":"markdown","4e6e54aa":"markdown","1bd6427a":"markdown","8381c381":"markdown","1e7e216f":"markdown","2129ae01":"markdown","acaf5791":"markdown","a0f4fc6a":"markdown","2a3c53ce":"markdown","9d963000":"markdown"},"source":{"bc1024b1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\n%matplotlib inline","a9e17984":"sub_pth = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\"\ndf_sub = pd.read_csv(sub_pth)\ndf_sub.head()","d9cbe831":"PARENT_DIRS = [\"test\",\"train\"]\nCHILD_DIRS = [\"FLAIR\", \"T1w\",\"T1wCE\",\"T2w\"]\n\nSplit_Types = []\nStudy_IDs = []\nTumour_Types = []\nImage_IDs = []\nAbsolute_Paths = []\nIMG_FORMAT = \".dcm\"","776a66ab":"def splitall(path):\n    # https:\/\/www.oreilly.com\/library\/view\/python-cookbook\/0596001673\/ch04s16.html\n    allparts = []\n    while 1:\n        parts = os.path.split(path)\n        if parts[0] == path:  # sentinel for absolute paths\n            allparts.insert(0, parts[0])\n            break\n        elif parts[1] == path: # sentinel for relative paths\n            allparts.insert(0, parts[1])\n            break\n        else:\n            path = parts[0]\n            allparts.insert(0, parts[1])\n    return allparts\nsplitall(\"Split_Type\/Study_ID\/Tumour_Type\/Image_ID.dcm\")","5f54185f":"file_count = 400*1000 # from kaggle files counter\nDATA_FOLDER = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\n\nwith tqdm(total=file_count) as pbar:\n    for path, directories, files in os.walk(DATA_FOLDER):\n         for file in files:\n                if file.endswith(IMG_FORMAT):\n                    pbar.update(1)\n                    abs_path = os.path.join(path, file)\n                    Image_ID = os.path.basename(abs_path)\n                    Splitted_Path = splitall(abs_path)\n                    Tumour_Type =  Splitted_Path[-2]\n                    Study_ID = Splitted_Path[-3]\n                    Split_Type = Splitted_Path[-4]\n\n                    Split_Types.append(Split_Type)\n                    Study_IDs.append(Study_ID)\n                    Tumour_Types.append(Tumour_Type)\n                    Image_IDs.append(Image_ID)\n                    Absolute_Paths.append(abs_path)","8ea61445":"df_ext = pd.DataFrame.from_dict({\"Split_Type\":Split_Types,\n                             \"Study_ID\":Study_IDs,\n                             \"Tumour_Type\":Tumour_Types,\n                             \"Image_ID\": Image_IDs,\n                             \"Absolute_Path\":Absolute_Paths})\ndf_ext.head()","269807e4":"train_pth = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\"\ndf_train = pd.read_csv(train_pth)\ndf_train.head()","27d4d065":"df_train.shape","2b9d0810":"train_df = df_ext[df_ext[\"Split_Type\"]==\"train\"]\ntrain_df.shape","16948336":"set_1 = set(list(df_train[\"BraTS21ID\"]))\nset_2 = set(list(map(int,train_df[\"Study_ID\"])))\n\nset_1==set_2","4003c25b":"df_ext[\"Ground_Truth_Class\"] = -1","734b7924":"for index, row in tqdm(df_ext.iterrows(),total=400114):\n    i = 0\n    # print(int(row['Study_ID']))\n    study_id = int(row['Study_ID'])\n    single_df = df_train[df_train[\"BraTS21ID\"] == study_id]\n    # print(single_df.shape)\n    if not single_df.shape[0]==0:\n        label_val = single_df[\"MGMT_value\"].values.flatten()[0]\n        df_ext.loc[index,\"Ground_Truth_Class\"] = label_val","efb7941f":"df_train[\"MGMT_value\"].value_counts()","a8d05fa2":"df_ext[\"Ground_Truth_Class\"].value_counts()","8b043f35":"images_per_study = df_ext.groupby(['Study_ID']).size()\nimages_per_study","cc8acc0e":"df_ext.shape","bb5d5dcd":"df_ext.describe()","c8ee0e7f":"df_ext.info()","f5068873":"df_ext.head()","2d0f8c0c":"train_df = df_ext[df_ext[\"Split_Type\"]==\"train\"]\ntrain_df.shape","000b904b":"import seaborn as sns","d22f5022":"def get_count_viz(data, column,title = \"Distribution Count\",figure_size= (20,4)):\n    print(\"Absolute Value Counts :\")\n    print(data[column].value_counts())\n    print(\"Normalized (Percentage) Value Counts :\")\n    print(data[column].value_counts(normalize=True))\n    plt.figure(figsize=figure_size)\n    ax = sns.countplot(data=data, y=column)\n    ax.set_title(title)\n    plt.show()","05673eae":"get_count_viz(data = train_df, column = \"Ground_Truth_Class\",title = \"Label Distribution Count\")","f0cef0a2":"get_count_viz(data = df_ext, column = \"Split_Type\",title = \"Train\/Test Distribution Count\")","fdb8e849":"per_study = dict(images_per_study)","500e548b":"plt.figure(figsize=(20,12))\nplt.plot(list(per_study.keys()), list(per_study.values()))\nplt.show()","229f9564":"import seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","c4a0048a":"data = list(per_study.values())\nplt.figure(figsize=(20,12))\n\nsns.distplot(data,bins=\"doane\",kde=True,hist_kws={\"align\" : \"left\"})\nplt.show()","80f4b1f1":"from tqdm import tqdm\n\n# Pydicom related imports\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\n# Reference: https:\/\/www.kaggle.com\/xhlulu\/siim-covid-19-convert-to-jpg-256px\n# and https:\/\/www.kaggle.com\/ayuraj\/brain-tumor-eda-and-interactive-viz-with-w-b\ndef ReadMRI(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","5039103e":"np.random.seed(42)","013a74f5":"def props(img):\n    print(\"Shape :\",img.shape,\"Maximum :\",img.max(),\"Minimum :\",img.min())\n\ndef view_data(sample_set,label_col=\"Study_ID\",path_col = \"Absolute_Path\",figure_size = (20,20),ht = 5,wd = 4):\n    n = ht * wd\n    fig, axs = plt.subplots(wd, ht, figsize=figure_size)\n    fig.subplots_adjust(hspace=.2, wspace=.2)\n    axs = axs.ravel()\n    sample_set = sample_set.reindex(np.random.permutation(sample_set.index))\n    sample_set.reset_index(drop=True, inplace=True)\n    i = 0\n    plots_done = 0\n    while plots_done<20:\n    # for i in range(n):\n        img_path = sample_set.loc[i,path_col]\n        img =  ReadMRI(img_path)  \n        # props(img)\n        if not img.max()==0:\n            axs[plots_done].imshow(img,cmap=plt.cm.gist_ncar)\n            axs[plots_done].set_title(sample_set.loc[i,label_col])\n            plots_done+=1\n        i+=1","453c7314":"train_df = df_ext[df_ext[\"Split_Type\"]==\"train\"]\ntrain_df.shape","d92a4542":"view_data(train_df[train_df[\"Ground_Truth_Class\"]==1])","c33f87c8":"view_data(train_df[train_df[\"Ground_Truth_Class\"]==0])","d2358c69":"view_data(df_ext[df_ext[\"Ground_Truth_Class\"]==-1])","3b58cf6d":"df_ext.columns","a8fde6ef":"data_path = df_ext.loc[0,'Absolute_Path']\ndata_path","cdae75e1":"data = ReadMRI(data_path)\nprint('Shape of data: ', data.shape)\n\nplt.figure(figsize=(5, 5))\nplt.imshow(data, cmap=plt.cm.gist_ncar);","d00aecfa":"df_ext.to_csv('Extracted_Study_Series_Img.csv',index=False)","f959f53a":"### `len(Images)` per Study","da115523":"### Get Paths : Directory Structure\n\n```\nTest\/Train Directory\n    Study_ID_Number - 00001, ....\n        FLAIR\n        T1w\n        T1wCE\n        T2w\n            Image-{Img_ID}.dcm\n```","3a4034aa":"### More About Columns","3fe40806":"### Distribution Plot\nWell, That's a bit too ragged, let's try breaking it down to a frequency-range plot","90298ffc":"### Test Set","4e6e54aa":"### Insert Ground Truth Values into the DataFrame","1bd6427a":"### Train Set - Positive Classes","8381c381":"# Data Insights & Visualizations","1e7e216f":"### Visualize How Many Images Per Study","2129ae01":"### Train Set - Negative Classes","acaf5791":"File Absolute Paths will be of the following format :\n```\nSplit_Type\/Study_ID\/Tumour_Type\/Image_ID.dcm\n```","a0f4fc6a":"# Combining to a Single DataFrame\n\nOkay Yeah!    \nLet me be pretty honest about this : I want **ONE** DataFrame.  \nJust One Good Big DF that has everything in it and I don't have to fumble accross all dfs to lookup again.    \nSo let's just get on with it!","2a3c53ce":"# View MRI Scans","9d963000":"### Helper Functions\n\nWe need these functions to preprocess the dcm images to the array because of which we use the `pydicom API`. This uses the `gdcm` library, which has to be installed beforehand.  \nHowever using this tool isn't easy because\n1. Pydicom isn't previously installed on Kaggle Notebooks.\n2. For Submissions, we need notebooks that run offline, so we can't use the internet to perform `pip install`.\n\n**The Solution** - Using Offline Installation as Dataset from a different Notebook. This approach is being used here."}}