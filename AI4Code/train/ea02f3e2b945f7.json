{"cell_type":{"64aa4f4f":"code","e368a5c6":"code","9df8991b":"code","38195059":"code","5bb21c1e":"code","c6467968":"code","3c499190":"code","d3ddc345":"code","08315b8c":"code","e89bd874":"code","765827c9":"code","3e2f5a17":"code","b9851115":"code","dbe21963":"code","f71424b8":"code","7dfc654c":"code","2d801a1f":"code","50e967e3":"code","75e762d7":"code","e4b4686b":"code","b655b6d4":"code","37dfddeb":"code","b526c23e":"code","cbd14daf":"code","3ec59f14":"code","5cecba66":"code","27efa67b":"code","40bc3001":"code","a97f2367":"code","a7bafc56":"code","324398a2":"code","9b1d7b62":"code","33e7ddcf":"code","1376fe7a":"code","3e6fd46c":"code","a1203266":"code","948337a5":"code","45a967a9":"code","2ea459aa":"code","27fdcdde":"code","2a360a37":"code","be21bfe9":"code","3ca4ca26":"code","58a4cd69":"markdown","cec54a23":"markdown","b090f870":"markdown","96f10716":"markdown","944db00e":"markdown","04763134":"markdown","c57710ee":"markdown","7d82cf38":"markdown","86ff9d78":"markdown","a25c5019":"markdown","e74b8739":"markdown","de775175":"markdown"},"source":{"64aa4f4f":"\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \n\nimport os\nfrom PIL import Image\n\n\nimport IPython.display \nfrom keras.preprocessing.image import array_to_img \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom keras.callbacks import TensorBoard \nfrom time import strftime ","e368a5c6":"IMAGES_PATH = '..\/input\/plant-pathology-2020-fgvc7\/images' \nTRAIN_PATH =  '..\/input\/plant-pathology-2020-fgvc7\/train.csv'\nTEST_PATH =  '..\/input\/plant-pathology-2020-fgvc7\/test.csv' \n\n\nIMG_WIDTH = IMG_HEIGHT = 300 \nNR_CHANNELS = 3\nTOTAL_INPUTS = NR_CHANNELS * IMG_HEIGHT * IMG_WIDTH\n\nLOG_DIR = '\/kaggle\/working\/tensorboard_plant_logs\/'\n\nCOLUMNS = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nLABEL_ENCODE = np.array([0,1,2,3])","9df8991b":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH) ","38195059":"train.shape","5bb21c1e":"train.head()","c6467968":"train.tail()","3c499190":"train.info() ","d3ddc345":"train['healthy'].value_counts()","08315b8c":"train['multiple_diseases'].value_counts()","e89bd874":"train['rust'].value_counts()","765827c9":"train['scab'].value_counts()","3e2f5a17":"ex_image = os.path.join(IMAGES_PATH, train.image_id[0] + '.jpg')\nex_image = np.asanyarray(Image.open(ex_image)) \nex_image.shape","b9851115":"def load_images(dataset, folder): \n    arr = [] \n    for imageName in dataset:\n        path = os.path.join(folder, imageName + '.jpg') \n        img = Image.open(path) \n        img = img.resize((300, 300)) \n        arr.append(np.asanyarray(img)) \n        img.close() \n    \n    return arr ","dbe21963":"train_images_all = np.array(load_images(train.image_id, IMAGES_PATH)) \ntrain_images_all.shape","f71424b8":"test_images_all = np.array(load_images(test.image_id, IMAGES_PATH))\ntest_images_all.shape","7dfc654c":"# get target from train \ntrain_all_y = train.iloc[:, 1:5]","2d801a1f":"# Split data for validation set and flatten data \nx_train = train_images_all[:1638] \nx_train = x_train.reshape(x_train.shape[0], -1)\ny_train = train_all_y[:1638] \ny_train = np.dot(y_train, LABEL_ENCODE.T) # to label encoding\n\nx_val = train_images_all[1638:] # %10 for validation set \nx_val = x_val.reshape(x_val.shape[0], -1)\ny_val = train_all_y[1638:]\ny_val = np.dot(y_val, LABEL_ENCODE.T) # to label encoding\n\nprint(\"x_val shape: \" , x_val.shape) \nprint(\"x_train shape: \",x_train.shape)","50e967e3":"plt.figure(figsize=(15,7)) \nfor i in range(1,10): \n    plt.subplot(1, 10, i) \n    plt.yticks([])\n    plt.xticks([]) \n    plt.imshow(train_images_all[i]) ","75e762d7":"type(train_images_all[0][0][0][0])","e4b4686b":"train_images_all, test_images_all = train_images_all \/ 255.0, test_images_all \/ 255.0","b655b6d4":"print(type(train_images_all[0][0][0][0])) \nprint(train_images_all[0][0][0][0])","37dfddeb":"# Flat Images to one single vector \ntrain_images_all = train_images_all.reshape(len(train_images_all), TOTAL_INPUTS)\ntest_images_all = test_images_all.reshape(len(test_images_all), TOTAL_INPUTS)","b526c23e":"train_images_all.shape","cbd14daf":"model_1 = Sequential([\n    Dense(units=32, input_dim=TOTAL_INPUTS, activation='relu'),  \n    Dense(units=16, activation='relu'), \n    Dense(units=4, activation='softmax') \n])","3ec59f14":"type(model_1)","5cecba66":"model_1.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \nmodel_1.summary() ","27efa67b":"def get_tensorboard(model_name): \n    folder_name = f'{model_name} at {strftime(\"%H %M\")}'\n    dir_paths = os.path.join(LOG_DIR, folder_name) \n    \n    try: \n        os.makedirs(dir_paths) \n    except OSError as err:\n        print(err.strerror)\n    else: \n        print('Succesfully created.') \n    \n    return TensorBoard(log_dir=dir_paths), dir_paths ","40bc3001":"samples_per_batch = 200 \nnr_epoch = 100","a97f2367":"%%time \ntensorboard, logdir = get_tensorboard('model_1') \nhistory_model_1 = model_1.fit(x_train, y_train, batch_size=samples_per_batch, validation_data=(x_val, y_val), epochs= nr_epoch, \n           callbacks=[tensorboard], verbose=0)","a7bafc56":"def display_model_hist(train_loss, train_accuracy, val_loss, val_accuracy): \n    \n    fig, axs = plt.subplots(2, 2)\n    fig.set_figheight(15)\n    fig.set_figwidth(15)\n    \n    axs[0,0].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[0,0].set_ylabel('Train Loss', fontsize=18)\n    axs[0,0].plot(train_loss,color='green')\n\n    axs[0,1].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[0,1].set_ylabel('Train Accuracy', fontsize=18)\n    axs[0,1].plot(train_accuracy, color='green') \n    \n    axs[1,0].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[1,0].set_ylabel('Val Loss', fontsize=18)\n    axs[1,0].plot(val_loss,color='magenta')\n\n    axs[1,1].set_xlabel('Nr of Epochs', fontsize=18)\n    axs[1,1].set_ylabel('Val Accuracy', fontsize=18)\n    axs[1,1].plot(val_accuracy, color='magenta') \n    \n\n    plt.show()","324398a2":"loss = history_model_1.history['loss'] \naccs = history_model_1.history['accuracy'] \n\nval_loss = history_model_1.history['val_loss']\nval_accuracy = history_model_1.history['val_accuracy']\n\ndisplay_model_hist(loss, accs, val_loss, val_accuracy) ","9b1d7b62":"nr_epoch = 200","33e7ddcf":"%%time \ntensorboard, logdir = get_tensorboard('model_2') \nhistory_model_2 = model_1.fit(x_train, y_train, batch_size=samples_per_batch, validation_data=(x_val, y_val), epochs= nr_epoch, \n           callbacks=[tensorboard], verbose=0)","1376fe7a":"loss = history_model_2.history['loss'] \naccs = history_model_2.history['accuracy'] \n\nval_loss = history_model_2.history['val_loss']\nval_accuracy = history_model_2.history['val_accuracy']\n\ndisplay_model_hist(loss, accs, val_loss, val_accuracy) ","3e6fd46c":"model_3 = Sequential([\n    Dropout(0.2, seed=42, input_shape=(TOTAL_INPUTS,)),\n    Dense(units=64, activation='relu'),  \n    Dense(units=32, activation='relu'),\n    Dense(units=16, activation='relu'), \n    Dense(units=4, activation='softmax') \n])\n\nmodel_3.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \nmodel_3.summary()","a1203266":"%%time \ntensorboard, logdir = get_tensorboard('model_3') \nhistory_model_3 = model_3.fit(x_train, y_train, batch_size=samples_per_batch, validation_data=(x_val, y_val), epochs= nr_epoch, \n           callbacks=[tensorboard], verbose=0)","948337a5":"loss = history_model_3.history['loss'] \naccs = history_model_3.history['accuracy'] \n\nval_loss = history_model_3.history['val_loss']\nval_accuracy = history_model_3.history['val_accuracy']\n\ndisplay_model_hist(loss, accs, val_loss, val_accuracy) ","45a967a9":"test_ph = np.expand_dims(test_images_all[0], axis=0)\ntest_ph.shape","2ea459aa":"model_3.predict(test_ph)","27fdcdde":"test_images_all.shape","2a360a37":"%%time\nresult = model_3.predict(test_images_all)","be21bfe9":"submission = pd.DataFrame(columns=train.columns[1:], data=result)\nsubmission = pd.concat([test, submission], axis=1)","3ca4ca26":"submission.head() ","58a4cd69":"# Get the Data","cec54a23":"* As you can see, we have large images. \n* We can't load all of them in main memory. \n* There is several ways to handle this problem but we just resize it. \n* For now its size is going to be fixed, at the end we can arrange it again. ","b090f870":"# Pre-process Data ","96f10716":"# Fit the Model ","944db00e":"# Imports","04763134":"# Constants","c57710ee":"# Tensorboard","7d82cf38":"## Get the imgs","86ff9d78":"* Try early stopping, because we have obtained high accuracy and low loss previous epoch.  ","a25c5019":"# Prediction and Evaluate Model","e74b8739":"# Define the Neural Network Using Keras ","de775175":"### In train set; \n* image_id: the foreign key for the parquet files\n* combinations: one of the target labels\n* healthy: one of the target labels\n* rust: one of the target labels\n* scab: one of the target labels"}}