{"cell_type":{"8fdda530":"code","602af786":"code","20f38ccb":"code","c6723d19":"code","3d8e021f":"code","7ebfc260":"code","c31a2040":"code","3dd57e4e":"code","bd4feab1":"code","d578fcea":"code","8a45331b":"code","15d91561":"code","90c87b5b":"code","49a31adb":"code","e80b4502":"code","06bc874b":"code","eb6d889d":"code","a64e69c6":"code","ee064dde":"code","48a20cc9":"code","f6880e5e":"code","978f744a":"code","b2e28623":"code","e53302a1":"code","f70bd867":"code","fd5ba116":"code","93c8f6dd":"code","a373d47d":"code","16836fb9":"markdown","20083b5b":"markdown","b81710b0":"markdown","975617ab":"markdown","15f3f788":"markdown","e0692f98":"markdown","fc51bf1f":"markdown","afe14d68":"markdown"},"source":{"8fdda530":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n+98999\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","602af786":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","20f38ccb":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","c6723d19":"train.head()","3d8e021f":"X = train.drop('label', axis = 1)\ny = train['label']\ndel train","7ebfc260":"sns.countplot(y)","c31a2040":"some_value = X.values[27]\nsome_value = some_value.reshape(28,28)\nsns.heatmap(some_value, cmap= 'binary', yticklabels=False, xticklabels= False)","3dd57e4e":"display(y.values[27])","bd4feab1":"np.unique(X.values)","d578fcea":"X = X \/ 255.0\ntest = test \/ 255.0","8a45331b":"X = X.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","15d91561":"#converting y into one hot encoding\nlabels = pd.get_dummies(y)\nlabels = labels.values","90c87b5b":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, labels, test_size = 0.1,random_state=42)","49a31adb":"display(X_train.shape)\ndisplay(y_train.shape)","e80b4502":"from keras.preprocessing.image import ImageDataGenerator","06bc874b":"datagen = ImageDataGenerator(shear_range= 0.2, zoom_range= 0.2)\ndatagen.fit(X_train)","eb6d889d":"#import the required libraries\n\nfrom keras.layers import Dropout, Conv2D, MaxPool2D, Dense, Flatten\nfrom keras.models import Sequential","a64e69c6":"model = Sequential()\n\n#First Layer\n#Convolutional Layers\nmodel.add(Conv2D(filters = 64, kernel_size = 5,activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = 5,activation ='relu'))\n#Pooling\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#Dropout\nmodel.add(Dropout(0.2))\n\n#Second Layer\n#Convolutional Layers\nmodel.add(Conv2D(filters = 32, kernel_size = 3,activation ='relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = 3,activation ='relu'))\n#Pooling\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#Dropout\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation = \"softmax\"))","ee064dde":"#compile the model\nmodel.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])","48a20cc9":"performance = model.fit_generator(datagen.flow(X_train,y_train, batch_size=64), epochs = 30, \n                                  validation_data = (X_val,y_val), verbose = 3)","f6880e5e":"loss = pd.DataFrame(performance.history)\n#plotting\nfig, axes = plt.subplots(2,1, figsize = (10,12))\naxes[0].plot(loss['loss'], \"r\", label = 'Training loss')\naxes[0].plot(loss['val_loss'], \"b\", label = 'Validation loss')\nlegend = axes[0].legend()\n\naxes[1].plot(loss['accuracy'], \"r\", label = 'Training Accuracy')\naxes[1].plot(loss['val_accuracy'], \"b\", label = 'Validation Accuracy')\nlegend = axes[1].legend()","978f744a":"from sklearn.metrics import confusion_matrix, classification_report","b2e28623":"#creating confusion matrix\npred = model.predict(X_val)","e53302a1":"# Convert predictions classes to one hot vectors \npred_classes = np.argmax(pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1)","f70bd867":"conf = confusion_matrix(y_true, pred_classes)\nplt.figure(figsize= (10,8))\nsns.heatmap(conf, annot= True)","fd5ba116":"print(classification_report(y_true, pred_classes))","93c8f6dd":"test_preds = model.predict(test)\ntest_preds = np.argmax(test_preds,axis = 1)\ntest_preds = pd.Series(test_preds,name=\"Label\")","a373d47d":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),test_preds],axis = 1)\nsubmission.to_csv(\"cnn_mnist.csv\",index=False)","16836fb9":"# Fit the Model","20083b5b":"# Data Augmentation","b81710b0":"# Reshape the training and test images\n\nKeras required images to be order 3 tensors. Thus, we require an additional dimension in our data. Apart from this, the images needs to go inside in batches and thus requires another dimension to specify that","975617ab":"# Training and Validation Set","15f3f788":"# Normalization","e0692f98":"# Submissions","fc51bf1f":"# Creating a CNN Model","afe14d68":"# Visualizing the Data"}}