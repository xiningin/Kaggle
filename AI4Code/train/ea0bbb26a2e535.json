{"cell_type":{"13bd9ef1":"code","de6f89f7":"code","8b43d563":"code","347645e3":"code","b98c093e":"code","cdac22c7":"code","b50db249":"code","c3fdcc05":"code","5a5ddd1d":"code","2a62843c":"code","08ea6faa":"code","4f60e605":"code","63d0e37a":"code","aec8795c":"code","9dadc113":"code","1eeea1c0":"code","27caa16b":"code","009e9438":"code","953387ff":"code","f96ddf1a":"code","83a800ad":"code","d394ed44":"code","9995d98f":"code","be2b53e8":"code","9e01ae63":"code","94d38211":"code","172c7797":"code","070432d0":"code","ad05a154":"code","f79f6023":"code","4d340407":"code","4fb64a83":"code","112518cd":"code","79f0e1f7":"code","fcfdfa40":"code","a2fe20a8":"code","29eb07b8":"code","e5ae1041":"code","0bd47fc8":"code","b677c77d":"code","85d39be7":"code","6bbd6240":"code","4adb8372":"code","a6351212":"code","07ada218":"code","8d747ded":"code","bbb328dc":"code","59af72ba":"markdown","aa212ab3":"markdown","e01f341a":"markdown","bfb54bed":"markdown","24884f50":"markdown","cef51cc2":"markdown","d77833bf":"markdown","9ef7eb2e":"markdown","865eb48a":"markdown","f469fcc4":"markdown","dfe1f8e6":"markdown","fde11389":"markdown","f8a88e47":"markdown","220c7d2a":"markdown","fe633672":"markdown","8235289a":"markdown","76df4af2":"markdown","a89adea0":"markdown","509b5110":"markdown","6ca88492":"markdown","d820f1d0":"markdown","b5a11204":"markdown","d48ad4db":"markdown","5970010f":"markdown","3ca86a8b":"markdown","02d7db90":"markdown","5900e1f1":"markdown","a412c56f":"markdown","d31e6ee2":"markdown","a418f4d8":"markdown","7441843a":"markdown","48b26832":"markdown","4dbe9cee":"markdown","da651135":"markdown","1f3da247":"markdown","6c670d3e":"markdown","ba7dfba2":"markdown","87a9ce54":"markdown","0eb48b40":"markdown","634664b1":"markdown","e13ed0cb":"markdown","67be8f71":"markdown"},"source":{"13bd9ef1":"# Usual Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sklearn\n\n# Librosa (the mother of audio files)\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport warnings\nwarnings.filterwarnings('ignore')","de6f89f7":"import os\ngeneral_path = '..\/input\/gtzan-dataset-music-genre-classification\/Data'\nprint(list(os.listdir(f'{general_path}\/genres_original\/')))","8b43d563":"# Importing 1 file\ny, sr = librosa.load(f'{general_path}\/genres_original\/reggae\/reggae.00036.wav')\n\nprint('y:', y, '\\n')\nprint('y shape:', np.shape(y), '\\n')\nprint('Sample Rate (KHz):', sr, '\\n')\n\n# Verify length of the audio\nprint('Check Len of Audio:', 661794\/22050)","347645e3":"# Trim leading and trailing silence from an audio signal (silence before and after the actual audio)\naudio_file, _ = librosa.effects.trim(y)\n\n# the result is an numpy ndarray\nprint('Audio File:', audio_file, '\\n')\nprint('Audio File shape:', np.shape(audio_file))","b98c093e":"plt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(y = audio_file, sr = sr, color = \"#A300F9\");\nplt.title(\"Sound Waves in Reggae 36\", fontsize = 23);","cdac22c7":"# Default FFT window size\nn_fft = 2048 # FFT window size\nhop_length = 512 # number audio of frames between STFT columns (looks like a good default)\n\n# Short-time Fourier transform (STFT)\nD = np.abs(librosa.stft(audio_file, n_fft = n_fft, hop_length = hop_length))\n\nprint('Shape of D object:', np.shape(D))","b50db249":"plt.figure(figsize = (16, 6))\nplt.plot(D);","c3fdcc05":"# Convert an amplitude spectrogram to Decibels-scaled spectrogram.\nDB = librosa.amplitude_to_db(D, ref = np.max)\n\n# Creating the Spectogram\nplt.figure(figsize = (16, 6))\nlibrosa.display.specshow(DB, sr = sr, hop_length = hop_length, x_axis = 'time', y_axis = 'log',\n                        cmap = 'cool')\nplt.colorbar();","5a5ddd1d":"y, sr = librosa.load(f'{general_path}\/genres_original\/metal\/metal.00036.wav')\ny, _ = librosa.effects.trim(y)\n\n\nS = librosa.feature.melspectrogram(y, sr=sr)\nS_DB = librosa.amplitude_to_db(S, ref=np.max)\nplt.figure(figsize = (16, 6))\nlibrosa.display.specshow(S_DB, sr=sr, hop_length=hop_length, x_axis = 'time', y_axis = 'log',\n                        cmap = 'cool');\nplt.colorbar();\nplt.title(\"Metal Mel Spectrogram\", fontsize = 23);","2a62843c":"y, sr = librosa.load(f'{general_path}\/genres_original\/classical\/classical.00036.wav')\ny, _ = librosa.effects.trim(y)\n\n\nS = librosa.feature.melspectrogram(y, sr=sr)\nS_DB = librosa.amplitude_to_db(S, ref=np.max)\nplt.figure(figsize = (16, 6))\nlibrosa.display.specshow(S_DB, sr=sr, hop_length=hop_length, x_axis = 'time', y_axis = 'log',\n                        cmap = 'cool');\nplt.colorbar();\nplt.title(\"Classical Mel Spectrogram\", fontsize = 23);","08ea6faa":"# Total zero_crossings in our 1 song\nzero_crossings = librosa.zero_crossings(audio_file, pad=False)\nprint(sum(zero_crossings))","4f60e605":"y_harm, y_perc = librosa.effects.hpss(audio_file)\n\nplt.figure(figsize = (16, 6))\nplt.plot(y_harm, color = '#A300F9');\nplt.plot(y_perc, color = '#FFB100');","63d0e37a":"tempo, _ = librosa.beat.beat_track(y, sr = sr)\ntempo","aec8795c":"# Calculate the Spectral Centroids\nspectral_centroids = librosa.feature.spectral_centroid(audio_file, sr=sr)[0]\n\n# Shape is a vector\nprint('Centroids:', spectral_centroids, '\\n')\nprint('Shape of Spectral Centroids:', spectral_centroids.shape, '\\n')\n\n# Computing the time variable for visualization\nframes = range(len(spectral_centroids))\n\n# Converts frame counts to time (seconds)\nt = librosa.frames_to_time(frames)\n\nprint('frames:', frames, '\\n')\nprint('t:', t)\n\n# Function that normalizes the Sound Data\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)","9dadc113":"#Plotting the Spectral Centroid along the waveform\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(audio_file, sr=sr, alpha=0.4, color = '#A300F9');\nplt.plot(t, normalize(spectral_centroids), color='#FFB100');","1eeea1c0":"# Spectral RollOff Vector\nspectral_rolloff = librosa.feature.spectral_rolloff(audio_file, sr=sr)[0]\n\n# The plot\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(audio_file, sr=sr, alpha=0.4, color = '#A300F9');\nplt.plot(t, normalize(spectral_rolloff), color='#FFB100');","27caa16b":"mfccs = librosa.feature.mfcc(audio_file, sr=sr)\nprint('mfccs shape:', mfccs.shape)\n\n#Displaying  the MFCCs:\nplt.figure(figsize = (16, 6))\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time', cmap = 'cool');","009e9438":"# Perform Feature Scaling\nmfccs = sklearn.preprocessing.scale(mfccs, axis=1)\nprint('Mean:', mfccs.mean(), '\\n')\nprint('Var:', mfccs.var())\n\nplt.figure(figsize = (16, 6))\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time', cmap = 'cool');","953387ff":"# Increase or decrease hop_length to change how granular you want your data to be\nhop_length = 5000\n\n# Chromogram\nchromagram = librosa.feature.chroma_stft(audio_file, sr=sr, hop_length=hop_length)\nprint('Chromogram shape:', chromagram.shape)\n\nplt.figure(figsize=(16, 6))\nlibrosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm');","f96ddf1a":"data = pd.read_csv(f'{general_path}\/features_30_sec.csv')\ndata.head()","83a800ad":"# Computing the Correlation Matrix\nspike_cols = [col for col in data.columns if 'mean' in col]\ncorr = data[spike_cols].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(16, 11));\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(0, 25, as_cmap=True, s = 90, l = 45, n = 5)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\nplt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 25)\nplt.xticks(fontsize = 10)\nplt.yticks(fontsize = 10);\nplt.savefig(\"Corr Heatmap.jpg\")","d394ed44":"x = data[[\"label\", \"tempo\"]]\n\nf, ax = plt.subplots(figsize=(16, 9));\nsns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'husl');\n\nplt.title('BPM Boxplot for Genres', fontsize = 25)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 10);\nplt.xlabel(\"Genre\", fontsize = 15)\nplt.ylabel(\"BPM\", fontsize = 15)\nplt.savefig(\"BPM Boxplot.jpg\")","9995d98f":"from sklearn import preprocessing\n\ndata = data.iloc[0:, 1:]\ny = data['label']\nX = data.loc[:, data.columns != 'label']\n\n#### NORMALIZE X ####\ncols = X.columns\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X)\nX = pd.DataFrame(np_scaled, columns = cols)\n\n\n#### PCA 2 COMPONENTS ####\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n\n# concatenate with target label\nfinalDf = pd.concat([principalDf, y], axis = 1)\n\npca.explained_variance_ratio_\n\n# 44.93 variance explained","be2b53e8":"plt.figure(figsize = (16, 9))\nsns.scatterplot(x = \"principal component 1\", y = \"principal component 2\", data = finalDf, hue = \"label\", alpha = 0.7,\n               s = 100);\n\nplt.title('PCA on Genres', fontsize = 25)\nplt.xticks(fontsize = 14)\nplt.yticks(fontsize = 10);\nplt.xlabel(\"Principal Component 1\", fontsize = 15)\nplt.ylabel(\"Principal Component 2\", fontsize = 15)\nplt.savefig(\"PCA Scattert.jpg\")","9e01ae63":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom xgboost import plot_tree, plot_importance\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE","94d38211":"data = pd.read_csv(f'{general_path}\/features_3_sec.csv')\ndata = data.iloc[0:, 1:] \ndata.head()","172c7797":"y = data['label'] # genre variable.\nX = data.loc[:, data.columns != 'label'] #select all columns but not the labels\n\n#### NORMALIZE X ####\n\n# Normalize so everything is on the same scale. \n\ncols = X.columns\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(X)\n\n# new data frame with the new scaled data. \nX = pd.DataFrame(np_scaled, columns = cols)","070432d0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","ad05a154":"def model_assess(model, title = \"Default\"):\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    #print(confusion_matrix(y_test, preds))\n    print('Accuracy', title, ':', round(accuracy_score(y_test, preds), 5), '\\n')","f79f6023":"# Naive Bayes\nnb = GaussianNB()\nmodel_assess(nb, \"Naive Bayes\")\n\n# Stochastic Gradient Descent\nsgd = SGDClassifier(max_iter=5000, random_state=0)\nmodel_assess(sgd, \"Stochastic Gradient Descent\")\n\n# KNN\nknn = KNeighborsClassifier(n_neighbors=19)\nmodel_assess(knn, \"KNN\")\n\n# Decission trees\ntree = DecisionTreeClassifier()\nmodel_assess(tree, \"Decission trees\")\n\n# Random Forest\nrforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\nmodel_assess(rforest, \"Random Forest\")\n\n# Support Vector Machine\nsvm = SVC(decision_function_shape=\"ovo\")\nmodel_assess(svm, \"Support Vector Machine\")\n\n# Logistic Regression\nlg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\nmodel_assess(lg, \"Logistic Regression\")\n\n# Neural Nets\nnn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1)\nmodel_assess(nn, \"Neural Nets\")\n\n# Cross Gradient Booster\nxgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nmodel_assess(xgb, \"Cross Gradient Booster\")\n\n# Cross Gradient Booster (Random Forest)\nxgbrf = XGBRFClassifier(objective= 'multi:softmax')\nmodel_assess(xgbrf, \"Cross Gradient Booster (Random Forest)\")","4d340407":"# Final model\nxgb = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nxgb.fit(X_train, y_train)\n\n\npreds = xgb.predict(X_test)\n\nprint('Accuracy', ':', round(accuracy_score(y_test, preds), 5), '\\n')\n\n# Confusion Matrix\nconfusion_matr = confusion_matrix(y_test, preds) #normalize = 'true'\nplt.figure(figsize = (16, 9))\nsns.heatmap(confusion_matr, cmap=\"Blues\", annot=True, \n            xticklabels = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"],\n           yticklabels=[\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]);\nplt.savefig(\"conf matrix\")","4fb64a83":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(estimator=xgb, random_state=1)\nperm.fit(X_test, y_test)\n\neli5.show_weights(estimator=perm, feature_names = X_test.columns.tolist())","112518cd":"# Libraries\nimport IPython.display as ipd\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn import preprocessing\n\n# Read data\ndata = pd.read_csv(f'{general_path}\/features_30_sec.csv', index_col='filename')\n\n# Extract labels\nlabels = data[['label']]\n\n# Drop labels from original dataframe\ndata = data.drop(columns=['length','label'])\ndata.head()\n\n# Scale the data\ndata_scaled=preprocessing.scale(data)\nprint('Scaled data type:', type(data_scaled))","79f0e1f7":"# Cosine similarity\nsimilarity = cosine_similarity(data_scaled)\nprint(\"Similarity shape:\", similarity.shape)\n\n# Convert into a dataframe and then set the row index and column names as labels\nsim_df_labels = pd.DataFrame(similarity)\nsim_df_names = sim_df_labels.set_index(labels.index)\nsim_df_names.columns = labels.index\n\nsim_df_names.head()","fcfdfa40":"def find_similar_songs(name):\n    # Find songs most similar to another song\n    series = sim_df_names[name].sort_values(ascending = False)\n    \n    # Remove cosine similarity == 1 (songs will always have the best match with themselves)\n    series = series.drop(name)\n    \n    # Display the 5 top matches \n    print(\"\\n*******\\nSimilar songs to \", name)\n    print(series.head(5))","a2fe20a8":"# pop.00019 - Britney Spears \"Hit me baby one more time\"\nfind_similar_songs('pop.00019.wav') \n\nipd.Audio(f'{general_path}\/genres_original\/pop\/pop.00019.wav')","29eb07b8":"ipd.Audio(f'{general_path}\/genres_original\/pop\/pop.00023.wav')","e5ae1041":"ipd.Audio(f'{general_path}\/genres_original\/pop\/pop.00034.wav')","0bd47fc8":"ipd.Audio(f'{general_path}\/genres_original\/pop\/pop.00078.wav')","b677c77d":"ipd.Audio(f'{general_path}\/genres_original\/pop\/pop.00088.wav')","85d39be7":"ipd.Audio(f'{general_path}\/genres_original\/pop\/pop.00091.wav')","6bbd6240":"# metal.00002 - Iron Maiden \"Flight of Icarus\"\nfind_similar_songs('metal.00002.wav') \n\nipd.Audio(f'{general_path}\/genres_original\/metal\/metal.00002.wav')","4adb8372":"ipd.Audio(f'{general_path}\/genres_original\/metal\/metal.00028.wav')","a6351212":"ipd.Audio(f'{general_path}\/genres_original\/metal\/metal.00059.wav')","07ada218":"ipd.Audio(f'{general_path}\/genres_original\/rock\/rock.00018.wav')","8d747ded":"ipd.Audio(f'{general_path}\/genres_original\/rock\/rock.00017.wav')","bbb328dc":"ipd.Audio(f'{general_path}\/genres_original\/rock\/rock.00016.wav')","59af72ba":"# Machine Learning Classification\n\nUsing the `features_3_sec.csv` file, we can try to build a classifier that accurately predicts for any new audio file input it's genre.\n\n### Libraries","aa212ab3":"### Similar song match no.5\n*Queen* - **Tie Your Mother Down**","e01f341a":"### Similar song match no.3\n*Queen* - **Another One Bites The Dust**","bfb54bed":"### Trying 10 different models to assess their performance\n\nWe tried 10 classification models, the best performing model was XGBooster.","24884f50":"### Similar song match no.5\n*Mandy Moore* - **Everything my heart desires**","cef51cc2":"### Spectral Centroid\n\n* indicates where the \u201dcentre of mass\u201d for a sound is located and is calculated as the weighted mean of the frequencies present in the sound.","d77833bf":"### Song similarity scoring\n\n`find_similar_songs()` - is a predefined function that takes the name of the song and returns top 5 best matches for that song.","9ef7eb2e":"### Feature Importance","865eb48a":"### 2D Representation: Sound Waves","f469fcc4":"### Box Plot for Genres Distributions","dfe1f8e6":"### Cosine similarity\n\nCalculates the *pairwise cosine similarity* for each combination of songs in the data. This results in a 1000 x 1000 matrix (with redundancy in the information as item A similarity to item B == item B similarity to item A).","fde11389":"### Creating a Predefined function to assess the accuracy of a model\n\n* input is the model\n* fits the model on the training dataset\n* predicts on the testing features\n* compares the predictions with the actuals","f8a88e47":"### Principal Component Analysis - to visualize possible groups of genres\n\n1. Normalization\n2. PCA\n3. The Scatter Plot","220c7d2a":"### Putting the Similarity Function into Action:\n\n### POP Example","fe633672":"### Chroma Frequencies\n\n* Chroma features are an interesting and powerful representation for music audio in which the entire spectrum is projected onto 12 bins representing the 12 distinct semitones (or chroma) of the musical octave.","8235289a":"### Mel Spectrogram\n\n* The Mel Scale, mathematically speaking, is the result of some non-linear transformation of the frequency scale. The Mel Spectrogram is a normal Spectrogram, but with a Mel Scale on the y axis.","76df4af2":"### Features and Target variable\n\n* creates the target and feature variables\n* normalizes the data","a89adea0":"### Reading in the Data\n\nNow let's try to predict the Genre of the audio using Machine Learning techniques.","509b5110":"### XGBoost is the winner - 90% accuracy\n\n* create the final model\n* compute confusion matrix\n* Compute Feature Importance","6ca88492":"## Audio Features\n\n### Zero Crossing Rate\n\n* the rate at which the signal changes from positive to negative or back.","d820f1d0":"### Mel-Frequency Cepstral Coefficients:\n\n* The Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10\u201320) which concisely describe the overall shape of a spectral envelope. It models the characteristics of the human voice.","b5a11204":"### Fourier Transform\n\n* Function that gets a signal in the time domain as input, and outputs its decomposition into frequencies\n* Transform both the y-axis (frequency) to log scale, and the \u201ccolor\u201d axis (amplitude) to Decibels, which is approx. the log scale of amplitudes.","d48ad4db":"## EDA\n\nEDA is going to be performed on the `features_30_sec.csv`. This file contains the mean and variance for each audio file fo the features analysed above. \n\nSo, the table has a final of 1000 rows (10 genrex x 100 audio files) and 60 features (dimensionalities).","5970010f":"<div class=\"alert alert-block alert-info\">\n<p>If you liked this, don't be shy, upvote! \ud83d\ude01<p>\n\n<b>Toodles!<b>\n<\/div>","3ca86a8b":"### Spectral Rolloff\n* is a measure of the shape of the signal. It represents the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies","02d7db90":"![](https:\/\/i.imgur.com\/LZB5LEa.png)\n\n# Introduction\n\n### Why are we doing this?\nMusic. Experts have been trying for a long time to understand sound and what differenciates one song from another. How to visualize sound. What makes a tone different from another.\n\nIn this notebook we will go through an in depth analysis of sound and how we can **visualize, classify and ultimately understand** it.\n\n### The data:\n* **genres original** - A collection of 10 genres with 100 audio files each, all having a length of 30 seconds (the famous GTZAN dataset, the MNIST of sounds)\n* **images original** - A visual representation for each audio file. One way to classify data is through neural networks. Because NNs (like CNN, what we will be using today) usually take in some sort of image representation, the audio files were converted to Mel Spectrograms to make this possible (we'll be talking about this more in depth later)\n* **2 CSV files** - Containing features of the audio files. One file has for each song (30 seconds long) a mean and variance computed over multiple features that can be extracted from an audio file (more in depth later). The other file has the same structure, but the songs were split before into 3 seconds audio files (this way increasing 10 times the amount of data we fuel into our classification models). *With data, more is always better*.\n\n### Purpose:\n1. We want to understand **what is an Audio file**. What features we can visualize on this kind of data.\n2. **EDA**. ALways good, here very necessary.\n3. **Genres Classification** on the 3 seconds CSV file (trying multiple models and identify which has the best accuracy)\n4. A **recommender system**: given a song, give me top X songs most similar.\n\n### Credits and Acknowledgements:\n* This was a team project for uni, so the effort in creating this wasn't only my own. So, I want to thank **James Wiltshire, Lauren O'Hare and Minyu Lei** for being the best teammates ever and for having so much fun and learning so much during the 3 days we worked on this.\n* You can do a lot of documentation online, but an article that helped us a lot in doing this was [Parul Pandey's](https:\/\/www.kaggle.com\/parulpandey) notebook for [Music Genre Classification with Python](https:\/\/towardsdatascience.com\/music-genre-classification-with-python-c714d032f0d8)","5900e1f1":"### Similar song match no.4\n*Queen* - **Under Pressure**","a412c56f":"### Similar song match no.4\n*Mandy Moore* - **Candy**","d31e6ee2":"### Similar song match no.1 \n*Motorhead* - **Ace of Spades**","a418f4d8":"### Similar song match no.2\n*Queen* - **Tear it Up**","7441843a":"### Similar song match no.1 \n*Britney Spears* - **I'm so curious (2009 remaster)**","48b26832":"### Correlation Heatmap for feature means","4dbe9cee":"### The Spectrogram\n\n* What is a spectrogram? A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. When applied to an audio signal, spectrograms are sometimes called sonographs, voiceprints, or voicegrams ([wiki](https:\/\/en.wikipedia.org\/wiki\/Spectrogram)).\n* Here we convert the frequency axis to a logarithmic one.","da651135":"# Recommender Systems\n\n\"Recomender\" Systems enable us for any given vector to find the best similarity, ranked in descending order, from the bast match to the least best match. \n\nFor Audio files, this will be done through `cosine_similarity` library.","1f3da247":"### Tempo BMP (beats per minute)\n\nDynamic programming beat tracker.","6c670d3e":"Data needs to be scaled:","ba7dfba2":"### Harmonics and Perceptrual\n\n* Harmonics are characteristichs that human years can't distinguish (represents the sound color)\n* Perceptrual understanding shock wave represents the sound rhythm and emotion","87a9ce54":"### METAL Example","0eb48b40":"### Similar song match no.3\n*Jennifer Lopez* - **Play**","634664b1":"# Explore Audio Data\n\nWe will use `librosa`, which is the mother of audio files.\n\n## Understanding Audio\nLet's first Explore our Audio Data to see how it looks (we'll work with `reggae.00036.wav` file).\n\n* **Sound**: sequence of vibrations in varying pressure strengths (`y`)\n* The **sample rate** (`sr`) is the number of samples of audio carried per second, measured in Hz or kHz","e13ed0cb":"### Similar song match no.2\n*Britney Spears* - **Sometimes**","67be8f71":"### Splitting the data into training and testing\n\n* 70% - 30% split"}}