{"cell_type":{"279cf99a":"code","a6e65f60":"code","1e8dd0c3":"code","d70da305":"code","b8eb2671":"code","2bab4dcd":"code","877b61bd":"code","413c72c0":"code","ab852b4c":"code","d5d75a05":"code","52544413":"code","7d383d4c":"code","0af089aa":"code","39fcbf99":"code","fec767fd":"code","df70a629":"code","6a48d277":"code","e9405a43":"code","4b781286":"code","ca7ac7ed":"code","29deba6a":"code","c6bc2791":"code","40ff22dd":"code","e842ed74":"code","3f041af2":"code","e6e7f51b":"code","0e47b3c3":"code","b7403260":"code","c9f85edc":"code","f1017c15":"markdown","7e1eec0b":"markdown","4fa89436":"markdown","13d9bed4":"markdown","71b1154d":"markdown","3a98ec8c":"markdown","aa273de9":"markdown","ced55b61":"markdown"},"source":{"279cf99a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tensorflow import keras  # tensorflow is our library, keras on top of it makes it simpler\nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom keras.activations import relu","a6e65f60":"train_data = pd.read_csv('..\/input\/train.csv')","1e8dd0c3":"train_data.head()   # looking to our DataFrame","d70da305":"train_data.info()    # we see that they are all integers","b8eb2671":"train_data.describe()   # we see that it needs to be scaled (now it's between 0 and 255 )","2bab4dcd":"train_y = train_data[\"label\"] \n\ntrain_data.drop([\"label\"],axis=1,inplace=True)\n\ntrain_x = train_data","877b61bd":"train_x = train_x.values.reshape(-1,28,28,1)\ntrain_y = train_y.values","413c72c0":"from keras.utils.np_utils import to_categorical\ntrain_y = to_categorical(train_y)","ab852b4c":"train_y.shape","d5d75a05":"train_x.shape","52544413":"train_x = train_x \/ 255.0","7d383d4c":"train_x.shape","0af089aa":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Dropout,Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom tensorflow.nn import leaky_relu ","39fcbf99":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = (5,5),padding = 'same',activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(32,kernel_size=(5,5),padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),padding=\"same\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),padding=\"same\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(32,activation=leaky_relu))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(20,activation=leaky_relu))\n\nmodel.add(Dense(10, activation = \"softmax\"))","fec767fd":"model.summary()","df70a629":"model.compile(Adam(lr=0.0003),loss=keras.losses.categorical_crossentropy,metrics=['accuracy'])","6a48d277":"datagen = ImageDataGenerator(\n       # rotation_range=0.5, \n       # zoom_range = 0.5, \n       # width_shift_range=0.5,  \n       # height_shift_range=0.5\n)\n\ndatagen.fit(train_x)","e9405a43":"model.fit_generator(datagen.flow(train_x,train_y, batch_size=80),steps_per_epoch=525,epochs=30)","4b781286":"test_x = pd.read_csv('..\/input\/test.csv')\n\ntest_x.head(10)","ca7ac7ed":"test_x = test_x.values.reshape(-1,28,28,1)","29deba6a":"test_x = test_x \/ 255.0","c6bc2791":"predictions = model.predict(test_x)","40ff22dd":"predictions[354]","e842ed74":"pred = np.argmax(predictions, axis=1)","3f041af2":"import matplotlib.pyplot as plt\nplt.imshow(test_x[354][:,:,0],cmap='gray')\nplt.show()","e6e7f51b":"pred[354]","0e47b3c3":"my_submission = pd.DataFrame({'ImageId': range(1,len(test_x)+1) ,'Label':pred })\n\nmy_submission.to_csv(\"cnn_results3.csv\",index=False)","b7403260":"my_submission.head(10)","c9f85edc":"#efe erg\u00fcn","f1017c15":"Labels and Features are splitted","7e1eec0b":"## Keras Model Starts Here","4fa89436":"# Hello\n### this kernel consist my effort to get higher on this challenge. I will try using CNN.","13d9bed4":"importing the required libraries","71b1154d":"Transformed to numpy arrays","3a98ec8c":"getting the Dataset","aa273de9":"### EDA","ced55b61":"### Scaling"}}