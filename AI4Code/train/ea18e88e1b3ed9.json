{"cell_type":{"b27a67c5":"code","234d9d0e":"code","794146f7":"code","b3a4c93a":"code","5ab6de9d":"code","3a87452d":"code","1ebecc1b":"code","d7c2c747":"code","390fce1a":"code","665adbff":"code","79b4f8f5":"code","dc30c4f8":"code","02941944":"code","019b0722":"code","dd91b1d5":"code","f1a148a5":"code","6aa802d4":"code","c2efc069":"code","857232e2":"code","65ab4593":"code","510467a1":"code","8de1a4e2":"code","1d3a4420":"markdown","cf34e600":"markdown","0ebaf0ef":"markdown","82ca430e":"markdown","8b3ffd1a":"markdown"},"source":{"b27a67c5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","234d9d0e":"def reduce_mem_usage(df, verbose=True):\n    numerics = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","794146f7":"!free","b3a4c93a":"sales_train_validations = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")","5ab6de9d":"sales_train_validations.info()","3a87452d":"!free","1ebecc1b":"sales_train_validations = reduce_mem_usage(sales_train_validations)","d7c2c747":"!free","390fce1a":"sales_train_validations.info()","665adbff":"!free","79b4f8f5":"a = pd.DataFrame(np.ones(10000000))","dc30c4f8":"a.info(all)","02941944":"a.iloc[:,0] = a.iloc[:,0].astype(np.int8)","019b0722":"a.info()","dd91b1d5":"!free","f1a148a5":"pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\").info()","6aa802d4":"sell_prices = reduce_mem_usage(pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv\"))\nsamplesubmission = reduce_mem_usage(pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv\"))\ncalendar = reduce_mem_usage(pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\"))\nsales_train_validation = reduce_mem_usage(pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\"))","c2efc069":"samplesubmission.to_feather(\"sample_submission.feather\")","857232e2":"##float16 may not be changed to feather, we should possibly use pickle\nsell_prices[\"sell_price\"] = sell_prices[\"sell_price\"].astype(np.float32)","65ab4593":"sell_prices.to_feather(\"sell_prices.feather\")\nsamplesubmission.to_feather(\"sample_submission.feather\")\ncalendar.to_feather(\"calendar.feather\")\nsales_train_validation.to_feather(\"sales_train_validation.feather\")","510467a1":"pd.read_feather('sell_prices.feather').info()","8de1a4e2":"%%time\npd.read_feather(\"sell_prices.feather\")\npd.read_feather(\"sample_submission.feather\")\npd.read_feather(\"calendar.feather\")\npd.read_feather(\"sales_train_validation.feather\")","1d3a4420":"dataset:https:\/\/www.kaggle.com\/yasagure\/featherm5","cf34e600":"* The memory which we consumed get larger than before\n* only to make file, we should use this function.\n* It is not good idea to use this function many times in the same ???","0ebaf0ef":"## rem_memory_usage\nI don't know why, but we shold much care about using rem_memory_usage","82ca430e":"we find int 64\u2192int 16 when we read file","8b3ffd1a":"* I have some trouble in memory and boring time in reducing it.\n* In ASHARE competition, @corochann shared us the solution, but in this compettion most of people don't use it.\n* I share it. https:\/\/www.kaggle.com\/corochann\/ashrae-feather-format-for-fast-loading"}}