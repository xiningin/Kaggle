{"cell_type":{"69b94fc6":"code","5de03cb9":"code","3d4dd5de":"code","7ae87846":"code","7b695ee8":"code","786525fe":"code","b6f1926a":"code","e493c448":"code","dce7b8a2":"code","6f3f62d2":"code","3065999b":"code","bc7c718b":"code","e99f22e7":"code","321b83ca":"code","66a57ab6":"code","53222d05":"code","e46701f0":"code","0d411ec1":"code","70b8a8e4":"code","b6b70dff":"code","21b7ca46":"code","59f4f7a2":"code","e006e664":"code","f927ea07":"code","75c57557":"code","3af5c6b6":"code","f07d5ed9":"code","145b7abf":"code","b23c2573":"code","fe78acea":"code","9d4c03ce":"code","d08f1a23":"code","7482b36f":"code","46083f20":"code","d015a662":"markdown","8aeb5c63":"markdown","fe0a6480":"markdown","a7b48434":"markdown","9de91d13":"markdown","efa83283":"markdown","184c6756":"markdown","a93afd85":"markdown","b78d7648":"markdown","10b991c8":"markdown","bd7d6fa8":"markdown","af26ed0d":"markdown","3b6ddbf2":"markdown","df5b9c7a":"markdown","9c00a69f":"markdown","a989897c":"markdown","8a7a3778":"markdown","784f4155":"markdown","fa6515ae":"markdown","b12b305d":"markdown","5f6ed3df":"markdown","3f7b5300":"markdown","cd7b187c":"markdown","a96f3439":"markdown","315a5071":"markdown","01ae8989":"markdown","1e4f3622":"markdown","842305f7":"markdown","77d7becc":"markdown","06cbe27c":"markdown","134fdf3d":"markdown","80305975":"markdown","1991297e":"markdown","b33b8332":"markdown","5742adca":"markdown","5d904553":"markdown","23f4faf3":"markdown","f4642996":"markdown","bd3e8053":"markdown","86b7147a":"markdown","188f9c70":"markdown","2351c919":"markdown","8f97c47c":"markdown","a48db58e":"markdown","96adfe24":"markdown","4fd47917":"markdown","a02e24f5":"markdown","0af4b223":"markdown","39218525":"markdown","b66a5c52":"markdown","335548ab":"markdown","9b764c55":"markdown","cbf3b783":"markdown","2d6bbbdd":"markdown","5d4c9d56":"markdown","61fe8896":"markdown","8f0f7c30":"markdown"},"source":{"69b94fc6":"import numpy as np\nimport pandas as pd\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot, download_plotlyjs\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport matplotlib.pyplot as plt\ninit_notebook_mode(connected=True)\nfrom plotly.tools import FigureFactory as ff\nimport random\nfrom collections import Counter\nimport warnings\nimport json\nimport os\nimport datetime\nfrom pandas.io.json import json_normalize\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 500)\nimport pycountry\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5de03cb9":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n# train_df = pd.read_csv('flatten_train.csv')\n# test_df = pd.read_csv('flatten_test.csv')","3d4dd5de":"# helper functions\ndef constant_cols(df):\n    cols = []\n    columns = df.columns.values\n    for col in columns:\n        if df[col].nunique(dropna = False) == 1:\n            cols.append(col)\n    return cols\n\ndef diff_cols(df1,df2):\n    columns1 = df1.columns.values\n    columns2 = df2.columns.values\n    print(list(set(columns1) - set(columns2)))\n    \n\ndef count_mean(col,color1,color2):\n    col_count = train_df[col].value_counts()\n    col_count_chart = go.Bar(x = col_count.head(10).index, y = col_count.head(10).values, name=\"Count\",marker = dict(color=color1))\n\n    col_mean_count = train_df[[col,'totals.transactionRevenue']][(train_df['totals.transactionRevenue'] >1)]\n    col_mean_count = col_mean_count.groupby(col)['totals.transactionRevenue'].mean().sort_values(ascending=False)\n    col_mean_count_chart = go.Bar(x = col_mean_count.head(10).index, y = col_mean_count.head(10).values, name=\"Mean\",marker = dict(color=color2))\n\n    fig = tools.make_subplots(rows = 1, cols = 2,subplot_titles=('Total Count','Mean Revenue'))\n    fig.append_trace(col_count_chart, 1,1)\n    fig.append_trace(col_mean_count_chart,1,2)\n    py.iplot(fig)\n","7ae87846":"train.head()","7b695ee8":"def load_df(csv_path='..\/input\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","786525fe":"train_df = load_df()","b6f1926a":"train_df.head()","e493c448":"test_df = load_df(\"..\/input\/test.csv\")","dce7b8a2":"# train_df.to_csv('flatten_train.csv')\n# test_df.to_csv('flatten_test.csv')\ndiff_cols(train_df,test_df)","6f3f62d2":"train_constants = constant_cols(train_df)\ntest_constants = constant_cols(test_df)\nprint(train_constants)\nprint(test_constants)","3065999b":"train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\ntrain_df['totals.transactionRevenue'] = train_df['totals.transactionRevenue'].fillna(0)\ntrain_df['date'] = train_df['date'].astype(str)\ntrain_df[\"date\"] = train_df[\"date\"].apply(lambda x : x[:4] + \"-\" + x[4:6] + \"-\" + x[6:])\ntrain_df[\"date\"] = pd.to_datetime(train_df[\"date\"])","bc7c718b":"train_constants = constant_cols(train_df)\ntest_constants = constant_cols(test_df)\ntrain_df = train_df.drop(columns=train_constants,axis = 1)\ntest_df = test_df.drop(columns=test_constants, axis = 1)","e99f22e7":"null_values = train_df.isna().sum(axis = 0).reset_index()\nnull_values = null_values[null_values[0] > 50]\nnull_chart = [go.Bar(y = null_values['index'],x = null_values[0]*100\/len(train_df), orientation = 'h')]\npy.iplot(null_chart)","321b83ca":"data = train_df[['channelGrouping','totals.transactionRevenue']]\ntemp = data['channelGrouping'].value_counts()\nchart = [go.Pie(labels = temp.index, values = temp.values)]\npy.iplot(chart)","66a57ab6":"temp = train_df['device.isMobile'].value_counts()\nchart = go.Bar(x = [\"False\",\"True\"], y = temp.values)\npy.iplot([chart])","53222d05":"count_mean('device.browser',\"#7FDBFF\",\"#3D9970\")","e46701f0":"count_mean('device.deviceCategory',\"#FF851B\",\"#FF4136\")","0d411ec1":"count_mean('device.operatingSystem',\"#80DEEA\",\"#0097A7\")","70b8a8e4":"count_mean('geoNetwork.continent',\"#F48FB1\",\"#C2185B\")","b6b70dff":"data = train_df[['geoNetwork.country','totals.transactionRevenue']][(train_df['totals.transactionRevenue'] >1)]\ntemp = data.groupby('geoNetwork.country',as_index=False)['totals.transactionRevenue'].mean()\ntemp['code'] = 'sample'\nfor i,country in enumerate(temp['geoNetwork.country']):\n    mapping = {country.name: country.alpha_3 for country in pycountry.countries}\n    temp.set_value(i,'code',mapping.get(country))\nchart = [ dict(\n        type = 'choropleth',\n        locations = temp['code'],\n        z = temp['totals.transactionRevenue'],\n        text = temp['geoNetwork.country'],\n        autocolorscale = True,\n        reversescale = True,\n        marker = dict(\n            line = dict (\n                color = 'rgb(180,180,180)',\n                  width = 0.5\n            ) ),\n        colorbar = dict(\n            autotick = True,\n            title = 'Mean Revenue'),\n      ) ]\n\nlayout = dict(\n    title = 'Mean revenue based on country',\n    geo = dict(\n        showframe = True,\n        showcoastlines = True,\n         showocean = True,\n        projection = dict(\n            type = 'Mercator'\n        )\n    )\n)\n\nfig = dict( data=chart, layout=layout )\npy.iplot( fig, validate=False)","21b7ca46":"count_mean('geoNetwork.metro',\"#CE93D8\", \"#7B1FA2\")","59f4f7a2":"count_mean('geoNetwork.networkDomain','#90CAF9','#1976D2')","e006e664":"count_mean('geoNetwork.region','#DCE775','#AFB42B')","f927ea07":"count_mean('geoNetwork.subContinent','#FFE082','#FFA000')","75c57557":"train_df['totals.pageviews'] = train_df['totals.pageviews'].fillna(0).astype('int32')\ntrain_df['totals.bounces'] = train_df['totals.bounces'].fillna(0).astype('int32')\n\npageview = train_df.groupby('date')['totals.pageviews'].apply(lambda x:x[x >= 1].count()).reset_index()\nbounce = train_df.groupby('date')['totals.bounces'].apply(lambda x:x[x >= 1].count()).reset_index()\n\npageviews = go.Scatter(x = pageview['date'],y= pageview['totals.pageviews'], name = 'Pageview',marker=dict(color = \"#B0BEC5\"))\n\n\nbounces = go.Scatter(x = bounce['date'],y= bounce['totals.bounces'],name = 'Bounce',marker=dict(color = \"#37474F\"))\n\npy.iplot([pageviews,bounces])","3af5c6b6":"train_df['totals.newVisits'] = train_df['totals.newVisits'].fillna(0).astype('int32')\ntrain_df['totals.hits'] = train_df['totals.hits'].fillna(0).astype('int32')\n\nnewvisit = train_df.groupby('date')['totals.newVisits'].apply(lambda x:x[x == 1].count()).reset_index()\noldVisit = train_df.groupby('date')['totals.newVisits'].apply(lambda x:x[x == 0].count()).reset_index()\nhit = train_df.groupby('date')['totals.hits'].apply(lambda x:x[x >= 1].count()).reset_index()\n\n\nhits = go.Scatter(x = hit['date'],y = hit['totals.hits'], name = 'total hits', marker=dict(color = '#FFEE58'))\n\nnew_vist = go.Scatter(x = newvisit['date'],y= newvisit['totals.newVisits'],name = 'New Vists', marker=dict(color = '#F57F17'))\n\noldvisit = go.Scatter(x = oldVisit['date'],y = oldVisit['totals.newVisits'], name = 'Old Visit', marker=dict(color = '#FFD600'))\n\npy.iplot([hits, new_vist, oldvisit])","f07d5ed9":"temp = train_df[(train_df['totals.transactionRevenue'] >0)]\ndata = temp[['totals.transactionRevenue','date']].groupby('date')['totals.transactionRevenue'].agg(['min','max']).reset_index()\nmean = go.Scatter(x = data['date'], y = data['min'],name = \"Min\",marker = dict(color = '#00E676'))\ncount = go.Scatter(x = data['date'],y = data['max'], name = \"Max\",marker = dict(color = '#00838F'))\npy.iplot([mean,count])","145b7abf":"train_df['month'] = train_df['date'].dt.month\ntrain_df['day'] = train_df['date'].dt.day\ntrain_df['weekday'] = train_df['date'].dt.weekday","b23c2573":"temp = train_df.groupby('month')['totals.transactionRevenue'].agg(['count','mean']).reset_index()\ncount_chart = go.Bar(x = temp['month'], y = temp['count'],name = 'Count',marker = dict(color = \"#E6EE9C\"))\nmean_chart = go.Bar(x = temp['month'],y = temp['mean'], name = 'Mean',marker = dict(color = \"#AFB42B\"))\n\nfig = tools.make_subplots(rows = 1, cols = 2, subplot_titles = ('Total Count', 'Mean Count'))\nfig.append_trace(count_chart,1,1)\nfig.append_trace(mean_chart, 1,2)\npy.iplot(fig)","fe78acea":"temp = train_df.groupby('day')['totals.transactionRevenue'].agg(['count','mean']).reset_index()\ncount_chart = go.Bar(x = temp['day'], y = temp['count'],name = 'Count', marker = dict(color = '#1DE9B6'))\nmean_chart = go.Bar(x = temp['day'],y = temp['mean'], name = 'Mean', marker = dict(color = '#00796B'))\n\nfig = tools.make_subplots(rows = 1, cols = 2, subplot_titles = ('Total Count', 'Mean Count'))\nfig.append_trace(count_chart,1,1)\nfig.append_trace(mean_chart, 1,2)\npy.iplot(fig)","9d4c03ce":"temp = train_df.groupby('weekday')['totals.transactionRevenue'].agg(['count','mean']).reset_index()\ncount_chart = go.Bar(x = temp['weekday'], y = temp['count'],name = 'Count', marker = dict(color = '#9575CD'))\nmean_chart = go.Bar(x = temp['weekday'],y = temp['mean'], name = 'Mean', marker = dict(color = '#B388FF'))\n\nfig = tools.make_subplots(rows = 1, cols = 2, subplot_titles = ('Total Count', 'Mean Count'))\nfig.append_trace(count_chart,1,1)\nfig.append_trace(mean_chart, 1,2)\npy.iplot(fig)","d08f1a23":"train_df['trafficSource.adContent'] = train_df['trafficSource.adContent'].fillna('')\nwordcloud2 = WordCloud(width=800, height=400).generate(' '.join(train_df['trafficSource.adContent']))\nplt.figure( figsize=(15,20))\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()","7482b36f":"train_df['trafficSource.keyword'] = train_df['trafficSource.keyword'].fillna('')\nwordcloud2 = WordCloud(width=800, height=400).generate(' '.join(train_df['trafficSource.keyword']))\nplt.figure( figsize=(20,20) )\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()","46083f20":"train_df['trafficSource.source'] = train_df['trafficSource.source'].fillna('')\nwordcloud2 = WordCloud(width=800, height=400).generate(' '.join(train_df['trafficSource.source']))\nplt.figure( figsize=(15,20) )\nplt.imshow(wordcloud2)\nplt.axis(\"off\")\nplt.show()","d015a662":"**Summary**<br>\n-  Most of the users came via organic search.<br>\n-   Paid search and affilate users are very less.","8aeb5c63":"# <a id='minmax'>Minmum & maximum revenue on daily basis<\/a><br>","fe0a6480":"# Glad that you made it till end.\n# Please Upvote to boost me :-).","a7b48434":"# <a id='device'>Device Category<\/a><br>","9de91d13":"# <a id='mobile'>Mobile users<\/a><br>","efa83283":"## both the df has same cols with constant values lets remove them ","184c6756":"# <a id='adcontent'>Most Ad Content<\/a><br>","a93afd85":"<img src=\"https:\/\/www.amazeemetrics.com\/sites\/default\/files\/Getting-Started-with-Google-Analytics.jpg\">","b78d7648":"**Summary**\n- Many users browse the site from desktop or tablet","10b991c8":"# <a id='keywords'>Keywords used by users<\/a><br>","bd7d6fa8":"** Summary **\n- Most of the revenue is generated on monday.\n- very less revenue is generated on weekend.","af26ed0d":"<a href='#'>Preface<\/a><br>\n<a href='#desc'>description<\/a><br>\n<a href='#about'>About notebook<\/a><br>\n<a href='#load_lib'>Load libraries<\/a><br>\n<a href='#load_data'>Load Dataset<\/a><br>\n<a href='#description'>Column Description<\/a><br>\n<a href='#cleaning'>Cleaning Dataset<\/a><br>\n<a href='#eda'>EDA<\/a><br>\n- <a href='#null'>Null values<\/a><br>\n- <a href='#channel'>Via which channel did user visited <\/a><br>\n- <a href='#mobile'>Mobile users<\/a><br>\n- <a href='#browser'>Browser based <\/a><br>\n- <a href='#device'>Device Category<\/a><br>\n- <a href='#os'>Operating system<\/a><br>\n- <a href='#continent'>Continent Based<\/a><br>\n- <a href='#metro'>Metro Based<\/a><br>\n- <a href='#networkdomain'>Network Domain<\/a><br>\n- <a href='#region'>Region<\/a><br>\n- <a href='#country'>Country Based<\/a><br>\n- <a href='#subcountry'>Sub Continent Based<\/a><br>\n- <a href='#pVb'>Page view V\/S bounces<\/a><br>\n- <a href='#customers'>new cusotmer or old customer<\/a><br>\n- <a href='#minmax'>Minmum & maximum revenu on daily basis<\/a><br>\n- <a href='#month'>Revenue based on month<\/a><br>\n- <a href='#day'>Revenue based on day<\/a><br>\n- <a href='#weekday'>Revenue based on weekday<\/a><br>\n- <a href='#adcontent'>Most Ad Content<\/a><br>\n- <a href='#keywords'>Keywords used by users<\/a><br>\n- <a href='#source'>Source from where users came<\/a><br>","3b6ddbf2":"**Summary**\n- Desktop site has generated more user count as well as more revenue\n- One thing to note is tablet users have generated almost same revenue as mobile users ","df5b9c7a":"# <a id='month'>Revenue based on month<\/a><br>","9c00a69f":"In this competition, you\u2019re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. ","a989897c":"# <a id='continent'>Continent Based<\/a><br>","8a7a3778":"# <a id='channel'>Via which channel did user visited <\/a><br>","784f4155":"**Summary**\n- African Users have generated more than a billion mean revenue.\n- Users from american have used the website a lot but didnt purchased products.","fa6515ae":"# <a id='metro'>Metro Based<\/a><br>","b12b305d":"**Summary**\n- We can see the revenue generated based on the countries\n- only 4 countries in africa have generated huge mean revenue.","5f6ed3df":"# <a id='weekday'>Revenue based on weekday<\/a><br>","3f7b5300":"**Summary**\n- No surprise Africa stands top in mean revenue ","cd7b187c":"# <a id='null'>Null values<\/a><br>","a96f3439":"**Summary**\n- The user visit count is very high for Chrome but Firefox users have genereted more revenue","315a5071":"# <a id='networkdomain'>Network Domain<\/a><br>","01ae8989":"# <a id='customers'>new cusotmer or old customer<\/a><br>","1e4f3622":"** Summary **\n- It is seen that on 31th day the view count is very less I dont blame any because only Jan, Mar, May, Jul, Aug, Oct, Dec has 31 days.\n- But the intresting fact is that the 2nd highest mean revenue is on day 31st.\n- I think it can either be because of Jan or Dec as they are the start or end of the year.","842305f7":"In this notebook we will look into the Dataset provided in the competetion and we will analyze the users of GStore.","77d7becc":"# <a id='region'>Region<\/a><br>","06cbe27c":"** Summary **\n- I have removed all the non-zero transaction.\n- This graph is to understand the minimum and maximum revenue the company generates.\n- 5th april the company generated the maximum revenue.\n- there are few days where the maximum and minimum revenue are same(Eg - 15 Jan 2017)","134fdf3d":"** Summary **\n- Out of all the hits we have more new visit than old visit\n- That means the returning customer is very less than the new customers.\n- Or there can be other meaning.","80305975":"# <a id='about'>About notebook<\/a>","1991297e":"# <a id='load_lib'>Load libraries<\/a>","b33b8332":"Source from where i got the code to flatten the json columns<br>\nhttps:\/\/www.kaggle.com\/julian3833\/1-quick-start-read-csv-and-flatten-json-fields\/notebook","5742adca":"**Summary**\n- Most users who generate revenue uses digitalwest.net\n- Again same we have huge users count from unknown source\/ (not set)","5d904553":"**Summary**\n- Less chrome OS users but high revenue is generated.\n-For windows phone users also generated good revenue.","23f4faf3":"# <a id='os'>Operating system<\/a><br>","f4642996":"# <a id='subcountry'>Sub Continent Based<\/a><br>","bd3e8053":"** Summary **\n- Image speak for it self","86b7147a":"**Summary**\n- We can see the based on pageview we have increase\/decrease of bounce rate ","188f9c70":"** Summary **\n- It is seen that November month has higest number of visitors but the transaction generated in that month is very low.\n- April month has generated higest mean revenue while its visitors are not high.","2351c919":"# <a id='day'>Revenue based on day<\/a><br>","8f97c47c":"# <a id='eda'>EDA<\/a><br>","a48db58e":"**Summary**<br>\n- So many coloumns has null values<br>\n- we will find why these columns are null and we will also see how we can manage them.","96adfe24":"# <a id='cleaning'>Cleaning Dataset<\/a>","4fd47917":"Since totals transaction Revenue is what we are going to predict.\nand there is no campaignCode in test set","a02e24f5":"# <a id='desc'> Description<\/a>","0af4b223":"# <a id='pVb'>Page view V\/S bounces<\/a><br>","39218525":"**Summary**\n- Most of the users metro location is not present in the dataset.\n- may be we have to assume some hypothesis here","b66a5c52":"# <a id='browser'>Browser based<\/a><br>","335548ab":"# <a id='load_data'>Load Dataset<\/a>","9b764c55":"# <a id='country'>Country Based<\/a><br>","cbf3b783":"Since few columns have json values lets convert flatten them","2d6bbbdd":"<a id='source'>Source from where users came<\/a><br>","5d4c9d56":"** Summary**\n- Tokyo has generated more than 1 Billion mean revenue","61fe8896":"- fullVisitorId- A unique identifier for each user of the Google Merchandise Store.\n- channelGrouping - The channel via which the user came to the Store.\n- date - The date on which the user visited the Store.\n- device - The specifications for the device used to access the Store.\n- geoNetwork - This section contains information about the geography of the user.\n- sessionId - A unique identifier for this visit to the store.\n- socialEngagementType - Engagement type, either \"Socially Engaged\" or \"Not Socially Engaged\".\n- totals - This section contains aggregate values across the session.\n- trafficSource - This section contains information about the Traffic Source from which the session originated.\n- visitId - An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.\n- visitNumber - The session number for this user. If this is the first session, then this is set to 1.\n-visitStartTime - The timestamp (expressed as POSIX time)","8f0f7c30":"# <a id='description'>Column Description<\/a><br>"}}