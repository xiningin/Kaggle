{"cell_type":{"91f61f78":"code","d65be974":"code","8d87de7d":"code","fcb2bb28":"code","187ce248":"markdown","c1d37494":"markdown","e751fc63":"markdown","55fe6671":"markdown"},"source":{"91f61f78":"from tqdm import tqdm\nimport numpy as np\nimport torch\nimport pandas as pd\nfrom torchvision import transforms\nfrom PIL import Image\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\nimport os\n\ndevice = torch.device('cuda:0')","d65be974":"def mask_to_rle(img, width, height):\n    rle = []\n    lastColor = 0\n    currentPixel = 0\n    runStart = -1\n    runLength = 0\n\n    for x in range(width):\n        for y in range(height):\n            currentColor = img[x][y]\n            if currentColor != lastColor:\n                if currentColor == 1:\n                    runStart = currentPixel\n                    runLength = 1\n                else:\n                    rle.append(str(runStart))\n                    rle.append(str(runLength))\n                    runStart = -1\n                    runLength = 0\n                    currentPixel = 0\n            elif runStart > -1:\n                runLength += 1\n            lastColor = currentColor\n            currentPixel+=1\n    return \" \" + \" \".join(rle)","8d87de7d":"num_classes = 2\n\nsample_df = pd.read_csv(\"..\/input\/siim-acr-pneumothorax-segmentation\/sample_submission.csv\")\n\n# this part was taken from @raddar's kernel: https:\/\/www.kaggle.com\/raddar\/better-sample-submission\nmasks_ = sample_df.groupby('ImageId')['ImageId'].count().reset_index(name='N')\nmasks_ = masks_.loc[masks_.N > 1].ImageId.values\n#\n\nsample_df = sample_df.drop_duplicates('ImageId', keep='last').reset_index(drop=True)\n\nmodel_ft = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\nin_features = model_ft.roi_heads.box_predictor.cls_score.in_features\nmodel_ft.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\nin_features_mask = model_ft.roi_heads.mask_predictor.conv5_mask.in_channels\nhidden_layer = 256\nmodel_ft.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n\nmodel_ft.load_state_dict(torch.load(\"..\/input\/mask-rcnn-with-augmentation\/model.bin\"))\nmodel_ft = model_ft.to(device)\n\nfor param in model_ft.parameters():\n    param.requires_grad = False\n\nmodel_ft.eval()","fcb2bb28":"tt = transforms.ToTensor()\nsublist = []\ncounter = 0\nfor index, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n    image_id = row['ImageId']\n    if image_id in masks_:\n        img_path = os.path.join('..\/input\/siim-png-images\/input\/test_png', image_id + '.png')\n\n        img = Image.open(img_path).convert(\"RGB\")\n        width, height = img.size\n        img = img.resize((256, 256), resample=Image.BILINEAR)\n        img = tt(img)\n        result = model_ft([img.to(device)])[0]\n        if len(result[\"masks\"]) > 0:\n            counter += 1\n            res = transforms.ToPILImage()(result[\"masks\"][0].permute(1, 2, 0).cpu().numpy())\n            res = np.asarray(res.resize((width, height), resample=Image.BILINEAR))\n            res = (res[:, :] * 255. > 127).astype(np.uint8).T\n            rle = mask_to_rle(res, width, height)\n        else:\n            rle = \" -1\"\n    else:\n        rle = \" -1\"\n    sublist.append([image_id, rle])\n\nsubmission_df = pd.DataFrame(sublist, columns=sample_df.columns.values)\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(counter)","187ce248":"# Prediction Loop","c1d37494":"# The cool imports","e751fc63":"# Model and Data","55fe6671":"# Mask to RLE helper"}}