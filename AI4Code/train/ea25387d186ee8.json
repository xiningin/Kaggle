{"cell_type":{"d8dbe06d":"code","a25a1478":"code","dcec4934":"code","3e029991":"code","ff348423":"code","caac88ba":"code","38f579e3":"code","50962d4f":"code","a3f816af":"code","3b11ce0e":"code","8ffb7615":"code","f0be909d":"code","58355376":"code","dfa930b8":"code","4069a2fc":"code","ec364b46":"code","61978cc8":"code","c1007e11":"code","ec533b22":"code","b7818afd":"code","a8fb26e0":"code","fcb5ca10":"code","42aa7da0":"markdown","efc2be83":"markdown","3397e157":"markdown","e4792cb9":"markdown","df5c2686":"markdown","2cce0c3b":"markdown","5f97628b":"markdown","f80fcaa0":"markdown","af6ed2b9":"markdown","a6bdd4c1":"markdown","3d4724b4":"markdown","404884a2":"markdown","0804dede":"markdown","a25b70d1":"markdown"},"source":{"d8dbe06d":"#Start installing Beautiful Soup library\n!pip install beautifulsoup4","a25a1478":"#Let's Import \n#Running the text documents through Beautiful Soup gives us a BeautifulSoup object, \n#which represents the document as a nested data structure.\n\nfrom bs4 import BeautifulSoup\nimport urllib.request\n\n#urllib is a package that collects several modules for working with URLs\n#urllib.request for opening and reading URLs","dcec4934":"#Saves the project gutenberg web page link into \"url\"\nurl=\"https:\/\/www.gutenberg.org\/browse\/scores\/top\"\n\n#Let's read the entire url\nourUrl=urllib.request.urlopen(url)","3e029991":"#Beautiful Soup then parses the document using the best available parser. \n#It will use an HTML parser unless you specifically tell it to use an XML parser.\n#And stores the results in the \"SOUP OBJECT\"\nsoup=BeautifulSoup(ourUrl, \"html.parser\")","ff348423":"#The prettify() method will turn a Beautiful Soup parse tree into a nicely \n#formatted Unicode string, with a separate line for each tag and each string:\n\nprint(soup.prettify)","caac88ba":"listoftop100books=[]\nfor i in soup.find_all(\"div\", {\"class\":\"page_content\"}):\n    booki=i.find(\"ol\")\n    listoftop100books.append(booki)\n    print(booki)","38f579e3":"listbooks1=[]\nfor each in listoftop100books:\n    link=str(each).replace('<li><a href=\"\/ebooks\/', \"https:\/\/www.gutenberg.org\/files\/\")+str()\n    link=link[4:-5]\n    listbooks1.append(link)\n\n    \nlistbooks1","50962d4f":"listbooks2=[]\nfor each in listbooks1:\n    link2=str(each).replace('<\/a><\/li>', \",\")\n    listbooks2.append(link2)","a3f816af":"listbooks3=[]\nfor each in listbooks1:\n    link3=str(each).replace('\\n', \"\")\n    listbooks3.append(link3)","3b11ce0e":"ohgod=str(listbooks3).split('<\/a><\/li>')\nohgod","8ffb7615":"# install wordcloud\n!pip install wordcloud\n\n# import package and its set of stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\nprint ('Wordcloud is installed and imported!')","f0be909d":"%matplotlib inline\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# check for latest version of Matplotlib\nprint ('Matplotlib version: ', mpl.__version__) # >= 2.0.0","58355376":"# download file and save as 1661-0.txt\n!wget --quiet https:\/\/www.gutenberg.org\/files\/1661\/1661-0.txt\n\n# open the file and read it into a variable sherlock_novel\nsherlock_novel = open('1661-0.txt', 'r').read()\n    \nprint ('File downloaded and saved!')","dfa930b8":"stopwords = set(STOPWORDS)","4069a2fc":"# instantiate a word cloud object\nsherlock_wc = WordCloud(\n    background_color='white',\n    max_words=2000,\n    stopwords=stopwords\n)\n\n# generate the word cloud\nsherlock_wc.generate(sherlock_novel)","ec364b46":"fig = plt.figure()\nfig.set_figwidth(14) # set width\nfig.set_figheight(18) # set height\n\n# display the cloud\nplt.imshow(sherlock_wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","61978cc8":"stopwords.add('said') # add the words said to stopwords\nstopwords.add('upon')\nstopwords.add('S')\n# re-generate the word cloud\nsherlock_wc.generate(sherlock_novel)\n\n# display the cloud\nfig = plt.figure()\nfig.set_figwidth(14) # set width\nfig.set_figheight(18) # set height\n\nplt.imshow(sherlock_wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","c1007e11":"from PIL import Image # converting images into arrays","ec533b22":"# download image\n!wget --  https:\/\/i.postimg.cc\/YqGbZp2s\/Sherlockkpng.png","b7818afd":"import pandas as pd\nimport numpy as np\n\n# save mask to alice_mask\nsherlock_mask = np.array(Image.open('Sherlockkpng.png'))\n    \nprint('Image downloaded and saved!')","a8fb26e0":"fig = plt.figure()\nfig.set_figwidth(14) # set width\nfig.set_figheight(18) # set height\n\nplt.imshow(sherlock_mask, cmap=plt.cm.gray, interpolation='bilinear')\nplt.axis('off')\nplt.show()","fcb5ca10":"# instantiate a word cloud object\nsherlock_wc = WordCloud(background_color='white', max_words=2000, mask=sherlock_mask, stopwords=stopwords, contour_width=0.5, contour_color='black')\n\n# generate the word cloud\nsherlock_wc.generate(sherlock_novel)\n\n# display the word cloud\nfig = plt.figure( figsize=(2000,2000) )\nfig.set_figwidth(14) # set width\nfig.set_figheight(18) # set height\n\nplt.imshow(sherlock_wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","42aa7da0":"Create a word cloud object and generate a word cloud. For simplicity, let's generate a word cloud using only the first 2000 words in the novel.","efc2be83":"<div id=\"Visual1\">\n<h1 style=\"background-color:black;font-family:Arial Black;font-size:250%;text-align:center; color: white\"; >\nWordClouds Visualization<\/h1>\n\nWord clouds are commonly used to perform high-level analysis and visualization of text data. Accordinly, we'll work with an example from Gutenberg Project that involves analyzing text data. \nLet's try to analyze one of my personal favourites books written by Sir Arthur Conan Doyle titled \"The Adventures of Sherlock Holmes\". Let's go ahead and download a .txt file of the novel.\n\n![](https:\/\/64.media.tumblr.com\/0e4a028c309f99de08df5a60e949f1b0\/tumblr_oay14rr4Vv1sjwwzso1_540.gifv)    \n<div>","3397e157":"<div id=\"about_dataset\">\n    \n   <h1 style=\"background-color:black;font-family:Arial Black;font-size:250%;text-align:center; color: white\"; >\n    About the dataset\n<\/h1>\n   \n  *  Project Gutenberg (PG) is a volunteer effort to digitize and archive cultural works, as well as to \"encourage the creation and distribution of eBooks.\" It was founded in 1971 by American writer Michael S. Hart and is the oldest digital library. Most of the items in its collection are the full texts of books in the public domain. The Project tries to make these as free as possible, in long-lasting, open formats that can be used on almost any computer. As of 22 May 2021, Project Gutenberg had reached 65,405 items in its collection of free eBooks.The releases are available in plain text, but other formats, such as HTML, PDF, EPUB, MOBI, and Plucker are included wherever possible. Most releases are in the English language, but many non-English works are also available. There are multiple affiliated projects that provide additional content, including region- and language-specific works. Project Gutenberg is closely affiliated with Distributed Proofreaders, an Internet-based community for proofreading scanned texts.\n    \n[More in Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Project_Gutenberg)     \n    \n**In this notebook we will obtain a list with the TOP 100 Books (Most Donwloaded) in .txt format using webscraping in the PROJECT GUTENBERG web page and with those files proced to create WordClouds.**\n    \nWe'll also need a .png image with siloutes of some characteristic of a chosen book for a great effect in the wordclound. In this notenbook as an example, we'll use the Sherlock Holmes siloute. \n<\/div>","e4792cb9":"**After a few \"for\" and cleaning tags we can have the link for each Book. In this example we'll select \"The Adventure's of Sherlock Holmes\".**\n\n![](https:\/\/i.gifer.com\/9ZM5.gif)","df5c2686":"<h1>Table of contents<\/h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li><a href=\"#about_dataset\">About the dataset<\/a><\/li>\n        <li><a href=\"#BeautifulSoup\">Beautiful Soup WebScraping<\/a><\/li>\n        <li><a href=\"#installing\">Installing and creating Soup Objects<\/a><\/li>\n        <li><a href=\"#Clean\">Top 100 books links - Procesing and cleaning<\/a><\/li>\n        <li><a href=\"#AboutWord\">About WordClouds - Install and Import<\/a><\/li>\n        <li><a href=\"#prediction\">Prediction<\/a><\/li>\n        <li><a href=\"#evaluation\">Evaluation<\/a><\/li>\n        <li><a href=\"#visualization\">Visualization<\/a><\/li>\n    <\/ol>\n<\/div>\n<br>\n<hr>\n","2cce0c3b":"Excellent! This looks really interesting! Another cool thing you can implement with the word_cloud package is superimposing the words onto a mask of any shape. Let's use a mask of Alice and her rabbit. We already created the mask for you, so let's go ahead and download it and call it alice_mask.png.","5f97628b":"<img style=\"float: center;\" src=\"https:\/\/i.ibb.co\/wYV8rCZ\/Banner-Gutenberg.jpg\">","f80fcaa0":"<div id=\"BeautifulSoup\">\n<h1 style=\"background-color:black;font-family:Arial Black;font-size:250%;text-align:center; color: white\"; >\n    Beautiful Soup WebScraping<\/h1>\n\n**Beautiful Soup** is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n\n[You can learn more here](https:\/\/beautiful-soup-4.readthedocs.io\/en\/latest\/#)\n\n<img style=\"float: right;\" src=\"https:\/\/i.pinimg.com\/736x\/ce\/4b\/a8\/ce4ba8962ea593c0e3af54b481b34740.jpg\">\n\n<\/div>","af6ed2b9":"Next, let's use the stopwords that we imported from word_cloud. We use the function set to remove any redundant stopwords.","a6bdd4c1":"Much better! However, said isn't really an informative word. So let's add it to our stopwords and re-generate the cloud.","3d4724b4":"Awesome! Now that the word cloud is created, let's visualize it.","404884a2":"<div id=\"AboutWord\">\n<h1 style=\"background-color:black;font-family:Arial Black;font-size:250%;text-align:center; color: white\"; >\nAbout WordClouds - Install and Import<\/h1>\n\nWord clouds (also known as text clouds or tag clouds) work in a simple way: the more a specific word appears in a source of textual data (such as a speech, blog post, or database), the bigger and bolder it appears in the word cloud.\n\nLuckily, a Python package already exists in Python for generating word clouds. The package, called word_cloud was developed by Andreas Mueller. You can learn more about the package by following [this link](https:\/\/amueller.github.io\/word_cloud\/).\n\nLet's use this package to learn how to generate a word cloud for a given text document.\n\nFirst, let's install the package.\n<div>","0804dede":"<div id=\"Clean\">\n<h1 style=\"background-color:black;font-family:Arial Black;font-size:250%;text-align:center; color: white\"; >\nTop 100 books links - Procesing and cleaning<\/h1>\n\n    \n**In this section I think it's possible to do this with less code, so any piece of advice will be well received!!**\n    \n<div>","a25b70d1":"<div id=\"installing\">\n<h1 style=\"background-color:black;font-family:Arial Black;font-size:250%;text-align:center; color: white\"; >\n    Installing and creating Soup Objects<\/h1>\n    \n<div>"}}