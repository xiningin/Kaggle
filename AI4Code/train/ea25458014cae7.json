{"cell_type":{"a53277f5":"code","ef9354b1":"code","f019a89d":"code","337e6136":"code","bb157d4e":"code","933a5392":"code","b3dfff3a":"code","f98221a7":"code","0bd0d411":"code","c1bd14cb":"code","dd229b8c":"code","a34bc179":"code","9ff10edf":"code","88184cbc":"code","bd050df4":"code","9539005e":"code","973779ae":"code","ac5834a7":"code","0b9d005f":"code","e6bddb83":"code","08c19f00":"code","3301ec48":"code","19615336":"code","d9836347":"code","ce4e5af2":"code","918e3ffa":"code","b6af655e":"code","95b804c9":"code","eae9530b":"code","ce57e1c9":"code","df52a897":"code","07e10f8c":"code","f158d3c3":"code","84990fc9":"code","b0b6831c":"code","3d7c1f7e":"code","dc25d9ba":"code","3b9419a4":"markdown"},"source":{"a53277f5":"from IPython import display\ndef dhtml(st):\n    display.display(display.HTML(\"\"\"<style>\n    @import url('https:\/\/fonts.googleapis.com\/css?family=Roboto|Orbitron&effect=3d');      \n    <\/style><p class='font-effect-3d' onclick='setStyle(this,\"#ff6600\")'\n    style='font-family:Roboto; font-size:25px; color:#ff355e;'>\n    %s<\/p>\"\"\"%st+\"\"\"<script>\n    function setStyle(element,c) {\n     var docs=document.getElementsByClassName('font-effect-3d');\n     for (var i=0; i<docs.length; i++) {\n         docs[i].style='font-family:Orbitron; font-size:22px;'; \n         docs[i].style.color=c;}; };\n    <\/script>\"\"\"))\ndhtml('Code Modules & Parameters')","ef9354b1":"!pip install git+https:\/\/github.com\/tensorflow\/docs","f019a89d":"import numpy as np,pylab as pl,pandas as pd\nimport sys,h5py,imageio,PIL\nimport tensorflow as tf\nimport tensorflow_hub as th\nfrom tensorflow_docs.vis import embed","337e6136":"seed_size=16; noise_dim=100; epochs=120\nbuffer_size=60000; batch_size=128\nnorm_img=tf.random.normal([1,noise_dim])\nseed_imgs=tf.random.normal([seed_size,noise_dim])","bb157d4e":"dhtml('Data')","933a5392":"(x,y),(_, _)=tf.keras.datasets.mnist.load_data()\nx=x.reshape(x.shape[0],28,28,1).astype('float32')\nx=(x-127.5)\/127.5\ndigits=tf.data.Dataset.from_tensor_slices(x)\\\n.shuffle(buffer_size).batch(batch_size)","b3dfff3a":"dhtml('Deep Convolutional Generative Adversarial Network')","f98221a7":"def tfgenerator():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Dense(7*7*256,use_bias=False,input_shape=(noise_dim,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Reshape((7,7,256)))\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(256,(5,5),strides=(1,1),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(16,(5,5),strides=(2,2),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(1,(5,5),strides=(2,2),\n                     padding='same',use_bias=False,\n                     activation='tanh'))\n    return model\ntfgenerator=tfgenerator()","0bd0d411":"def tfdiscriminator():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Conv2D(16,(5,5),strides=(2,2),\n            padding='same',input_shape=[28,28,1]))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers\\\n    .Conv2D(256,(5,5),strides=(2,2),padding='same'))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1))\n    return model\ntfdiscriminator=tfdiscriminator()","c1bd14cb":"generated_img=tfgenerator(norm_img,training=False)\npl.imshow(generated_img[0,:,:,0],cmap=pl.cm.bone)\npl.title(generated_img.shape)\ntfdiscriminator(generated_img)","dd229b8c":"cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real_output,fake_output):\n    real_loss=cross_entropy(tf.ones_like(real_output),real_output)\n    fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)\n    total_loss=real_loss+fake_loss\n    return total_loss\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\ngenerator_optimizer=tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer=tf.keras.optimizers.Adam(1e-4)\ncheckpoint=tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                               discriminator_optimizer=discriminator_optimizer,\n                               generator=tfgenerator,\n                               discriminator=tfdiscriminator)","a34bc179":"dhtml('Training')","9ff10edf":"@tf.function\ndef train_step(imgs):\n    random_imgs=tf.random.normal([batch_size,noise_dim])\n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        generated_imgs=tfgenerator(random_imgs,training=True)\n        real_output=tfdiscriminator(imgs,training=True)\n        fake_output=tfdiscriminator(generated_imgs,training=True)\n        gen_loss=generator_loss(fake_output)\n        disc_loss=discriminator_loss(real_output,fake_output)\n        gradients_of_generator=\\\n        gen_tape.gradient(gen_loss,tfgenerator.trainable_variables)\n        gradients_of_discriminator=\\\n        disc_tape.gradient(disc_loss,tfdiscriminator.trainable_variables)\n        generator_optimizer\\\n        .apply_gradients(zip(gradients_of_generator,\n                             tfgenerator.trainable_variables))\n        discriminator_optimizer\\\n        .apply_gradients(zip(gradients_of_discriminator,\n                             tfdiscriminator.trainable_variables))","88184cbc":"def generate_images(model,epoch,test_input):\n    predictions=model(test_input,training=False)\n    fig=pl.figure(figsize=(4,4))\n    for i in range(predictions.shape[0]):\n        pl.subplot(4,4,i+1)\n        pl.imshow(predictions[i,:,:,0]*127.5+127.5,\n                  cmap=pl.cm.bone)\n        pl.axis('off')\n    pl.savefig('epoch_{:04d}.png'.format(epoch+1))\n    pl.suptitle('Epoch: %04d'%(epoch+1),\n                color='#ff355e',fontsize=20)\n    pl.show()","bd050df4":"def train(data,epochs):\n    for epoch in range(epochs):\n        for image_batch in data:\n            train_step(image_batch)\n #           display.clear_output(wait=True)\n        if (epoch+1)%20==0:\n            generate_images(tfgenerator,epoch,seed_imgs)","9539005e":"train(digits,epochs)","973779ae":"PIL.Image.open('epoch_{:04d}.png'.format(epochs))","ac5834a7":"dhtml('Interpolation')","0b9d005f":"def animate(images):\n    converted_images=np.clip(images*255,0,255)\\\n    .astype(np.uint8)\n    imageio.mimsave('animation.gif',converted_images)\n    return embed.embed_file('animation.gif')\ndef interpolate_hypersphere(v1,v2,steps):\n    v1norm=tf.norm(v1)\n    v2norm=tf.norm(v2)\n    v2normalized=v2*(v1norm\/v2norm)\n    vectors=[]\n    for step in range(steps):\n        interpolated=v1+(v2normalized-v1)*step\/(steps-1)\n        interpolated_norm=tf.norm(interpolated)\n        interpolated_normalized=\\\n        interpolated*(v1norm\/interpolated_norm)\n        vectors.append(interpolated_normalized)\n    return tf.stack(vectors)\ndef interpolate_between_vectors(steps):\n    tf.random.set_seed(1)\n    v1=tf.random.normal([noise_dim])\n    v2=tf.random.normal([noise_dim])\n    vectors=interpolate_hypersphere(v1,v2,steps)\n    interpolated_imgs=tfgenerator(vectors,training=False)\n    interpolated_imgs=\\\n    tf.image.resize(interpolated_imgs,[128,128])\n    return interpolated_imgs","e6bddb83":"imgs=interpolate_between_vectors(120)\nanimate(imgs)","08c19f00":"dhtml('Parameters 2 & Data 2')","3301ec48":"seed_size=16; noise_dim=256; img_size=42\nepochs=200; buffer_size=11000; batch_size=128\nnorm_img=tf.random.normal([1,noise_dim])\nseed_imgs=tf.random.normal([seed_size,noise_dim])","19615336":"fpath='..\/input\/classification-of-handwritten-letters\/'\nzf='LetterColorImages_123.h5'\nf=h5py.File(fpath+zf,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\nx=tf.image.resize(x,[img_size,img_size]).numpy()\nx=np.dot(x,[.299,.587,.114])\nx=x.reshape(-1,img_size,img_size,1)\ny=np.array(f[keys[2]],dtype='int32')\\\n.reshape(-1,1)-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]","d9836347":"x=(x-127.5)\/127.5\npl.imshow((255-x[0]).reshape(img_size,img_size),\n          cmap=pl.cm.bone)\npl.title(x[0].shape)\nletters=tf.data.Dataset.from_tensor_slices(x)\\\n.shuffle(buffer_size).batch(batch_size)","ce4e5af2":"dhtml('DCGAN 2')","918e3ffa":"def tfgenerator2():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Dense(7*7*256,use_bias=False,input_shape=(noise_dim,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Reshape((7,7,256)))\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(256,(7,7),strides=(3,3),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(32,(7,7),strides=(2,2),\n                     padding='same',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers\\\n    .Conv2DTranspose(1,(7,7),strides=(1,1),\n                     padding='same',use_bias=False,\n                     activation='tanh'))\n    return model\ntfgenerator2=tfgenerator2()","b6af655e":"def tfdiscriminator2():\n    model=tf.keras.Sequential()\n    model.add(tf.keras.layers\\\n    .Conv2D(32,(7,7),strides=(2,2),padding='same',\n            input_shape=[img_size,img_size,1]))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers\\\n    .Conv2D(256,(7,7),strides=(2,2),padding='same'))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(.2))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1))\n    return model\ntfdiscriminator2=tfdiscriminator2()","95b804c9":"generated_img=tfgenerator2(norm_img,training=False)\npl.imshow(generated_img[0,:,:,0],cmap=pl.cm.bone)\npl.title(generated_img.shape);\ntfdiscriminator2(generated_img)","eae9530b":"cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\ndef discriminator_loss(real_output,fake_output):\n    real_loss=cross_entropy(tf.ones_like(real_output),real_output)\n    fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)\n    total_loss=real_loss+fake_loss\n    return total_loss\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\ngenerator_optimizer2=tf.keras.optimizers.Adam(1e-3)\ndiscriminator_optimizer2=tf.keras.optimizers.Adam(1e-3)","ce57e1c9":"dhtml('Training')","df52a897":"@tf.function\ndef train_step2(imgs):\n    random_imgs=tf.random.normal([batch_size,noise_dim])\n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        generated_imgs=tfgenerator2(random_imgs,training=True)\n        real_output=tfdiscriminator2(imgs,training=True)\n        fake_output=tfdiscriminator2(generated_imgs,training=True)\n        gen_loss=generator_loss(fake_output)\n        disc_loss=discriminator_loss(real_output,fake_output)\n        gradients_of_generator=\\\n        gen_tape.gradient(gen_loss,tfgenerator2.trainable_variables)\n        gradients_of_discriminator=\\\n        disc_tape.gradient(disc_loss,tfdiscriminator2.trainable_variables)\n        generator_optimizer2\\\n        .apply_gradients(zip(gradients_of_generator,\n                             tfgenerator2.trainable_variables))\n        discriminator_optimizer2\\\n        .apply_gradients(zip(gradients_of_discriminator,\n                             tfdiscriminator2.trainable_variables))","07e10f8c":"def generate_images2(model,epoch,test_input):\n    predictions=model(test_input,training=False)\n    fig=pl.figure(figsize=(4,4))\n    for i in range(predictions.shape[0]):\n        pl.subplot(4,4,i+1)\n        pl.imshow(127.5-predictions[i,:,:,0]*127.5,\n                  cmap=pl.cm.bone)\n        pl.axis('off')\n    pl.savefig('epoch_{:04d}.png'.format(epoch+1))\n    pl.suptitle('Epoch: %04d'%(epoch+1),\n                color='#ff355e',fontsize=20)\n    pl.show()","f158d3c3":"def train2(data,epochs):\n    for epoch in range(epochs):\n        for image_batch in data:\n            train_step2(image_batch)\n        if (epoch+1)%10==0:\n            generate_images2(tfgenerator2,epoch,seed_imgs)","84990fc9":"train2(letters,epochs)","b0b6831c":"PIL.Image.open('epoch_{:04d}.png'.format(epochs))","3d7c1f7e":"def interpolate_between_vectors2(steps):\n    tf.random.set_seed(123)\n    v1=tf.random.normal([noise_dim])\n    v2=tf.random.normal([noise_dim])\n    vectors=interpolate_hypersphere(v1,v2,steps)\n    interpolated_imgs=tfgenerator2(vectors,training=False)\n    interpolated_imgs=\\\n    tf.image.resize(interpolated_imgs,[128,128])\n    return interpolated_imgs\ndef animate2(images):\n    converted_images=np.clip(127.5-images*255,0,255)\\\n    .astype(np.uint8)\n    imageio.mimsave('animation.gif',converted_images)\n    return embed.embed_file('animation.gif')","dc25d9ba":"imgs=interpolate_between_vectors2(180)\nanimate2(imgs)","3b9419a4":"## [Google Colaboratory Variant](https:\/\/colab.research.google.com\/drive\/1ZT6ujInkGn_U0cqkPLsoOW8KzTmGQzFi)"}}