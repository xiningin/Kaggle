{"cell_type":{"77f01c67":"code","408b4e2e":"code","6e72a49a":"code","317ad581":"code","f8c88b5a":"code","4a766dde":"code","7038a418":"code","4a895b6d":"code","8158c261":"code","9747e8c1":"code","d5e777c6":"code","13fbfe4c":"code","03c6315d":"code","a5e9973c":"code","ed7c1246":"code","718f85a8":"code","6491039f":"code","59fc9665":"code","2d9373a1":"code","602b4788":"code","f805e292":"code","d6db8b7b":"code","89ba7efd":"code","047afa12":"code","06ddbc83":"code","208d63b2":"code","fe356e85":"code","0be821f2":"code","fe73a1df":"code","d316fd70":"code","d9f8a0eb":"code","9dee2c5f":"code","09d26aa1":"code","8f37c1ac":"code","a6dfb518":"code","55cc79fd":"code","7cda85f8":"markdown","acea9f87":"markdown","0408b095":"markdown","a7f67378":"markdown","2976e91e":"markdown","86d6bd59":"markdown","32dcdf9a":"markdown","1bc450df":"markdown","4a093c5b":"markdown"},"source":{"77f01c67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 25)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","408b4e2e":"# load dataset\nmovie = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")\ncredit = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv\")","6e72a49a":"# first look\nmovie.head()","317ad581":"credit.head()","f8c88b5a":"# merge two dataset\ncredit.columns = ['id','cast', 'title', 'crew']\nmovie= movie.merge(credit, on='id')","4a766dde":"movie.head(3)","7038a418":"movie.info() # some information of dataset","4a895b6d":"# Wordcolud\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt","8158c261":"# word cloud function\ndef cloud(col):    \n    wcloud = \" \".join(f for f in movie[col])\n    wc_ = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS)\n    wc_.generate(wcloud)\n    plt.subplots(figsize=(10,6))\n    plt.imshow(wc_, interpolation=\"bilinear\")\n    plt.axis(\"off\")","9747e8c1":"# for title column\ncloud(\"original_title\")","d5e777c6":"# fill overview column\nmovie[\"overview\"] = movie[\"overview\"].fillna(\"\")","13fbfe4c":"cloud(\"overview\")","03c6315d":"# Tfidf Vectorize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(stop_words=\"english\")\n\ntfidf_matrix = tfidf.fit_transform(movie[\"overview\"])\n\ntfidf_matrix","a5e9973c":"# we will use sklearn's linear_kernel() instead of cosine_similarities() since it is faster.\nfrom sklearn.metrics.pairwise import linear_kernel\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","ed7c1246":"# reverse map of indices and movie original_title\nindices = pd.Series(movie.index, index=movie['original_title']).drop_duplicates()","718f85a8":"# recommendation function\n\ndef get_recommendation(title, cosine_sim):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    movies = [i[0] for i in sim_scores]\n    movies = movie[\"original_title\"].iloc[movies]\n    return movies","6491039f":"# IF you search \"Spectre\", name of the movies below will be recommended\nget_recommendation('Spectre', cosine_sim)","59fc9665":"get_recommendation(\"John Carter\", cosine_sim)","2d9373a1":"# Parse the stringified features into their corresponding python objects\nfrom ast import literal_eval\n\nfeatures = ['keywords', 'genres']\nfor feature in features:\n    movie[feature] = movie[feature].apply(literal_eval)","602b4788":"movie[['original_title', 'keywords', 'genres']].head(3)","f805e292":"# Extract list of genres\ndef list_genres(x):\n    l = [d['name'] for d in x]\n    return(l)\nmovie['genres'] = movie['genres'].apply(list_genres)\n\n# Extract list of keywords\ndef list_keyword(y):\n    i = [a['name'] for a in y]\n    return(i)\nmovie['keywords'] = movie['keywords'].apply(list_keyword)","d6db8b7b":"# join genre and keywords\ndef genre(x):\n    return ''.join(' '.join(x['genres']) + ' ' + ' '.join(x['keywords']))\n\n# new column\nmovie['mix'] = movie.apply(genre, axis=1)","89ba7efd":"movie[\"mix\"]","047afa12":"# Countvectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncountvect = CountVectorizer(stop_words=\"english\")\n\ncountvect_mat = tfidf.fit_transform(movie[\"mix\"])\n\ncountvect_mat","06ddbc83":"from sklearn.metrics.pairwise import cosine_similarity\n\ncos_sim = cosine_similarity(countvect_mat, countvect_mat)","208d63b2":"# reverse map of indices and movie original_title\nmovie = movie.reset_index()\nindices = pd.Series(movie.index, index=movie['original_title'])","fe356e85":"get_recommendation(\"John Carter\", cos_sim)","0be821f2":"get_recommendation(\"Soldier\", cos_sim)","fe73a1df":"# avarage rating\navg = movie[\"vote_average\"].mean()\n#  We will use 90th percentile as our cutoff. In other words, for a movie to feature in the charts, it must have more votes than at least 90% of the movies in the list.\nq = movie[\"vote_count\"].quantile(0.9)","d316fd70":"print(avg)\nprint(q)","d9f8a0eb":"movies = movie[movie[\"vote_count\"] >= q]","9dee2c5f":"# function of weighted_rating \ndef weighted_rating(x, q=q, avg=avg):\n    v = x['vote_count']\n    R = x['vote_average']\n    # Calculation based on the IMDB formula\n    return (v\/(v+q) * R) + (q\/(q+v) * avg)","09d26aa1":"# apply for qualfied movies\nmovies[\"score\"] = movies.apply(weighted_rating, axis=1)","8f37c1ac":"# Sort movies based on score calculated above\nmovies = movies.sort_values('score', ascending=False)\n\n# Print the top 10 movies\nlisted = movies[['original_title', 'vote_count', 'vote_average', 'score', \"popularity\"]].head(10)","a6dfb518":"# Visualize\nimport seaborn as sns\n\n\nplt.subplots(figsize=(10,6))\nsns.barplot(listed[\"score\"], listed[\"original_title\"], palette=\"Set2\")\nplt.title(\"Movie Vs Score\")","55cc79fd":"popular= movies.sort_values('popularity', ascending=False)\nplt.figure(figsize=(12,4))\n\nplt.barh(popular['original_title'].head(10),popular['popularity'].head(10), align='center',\n        color=\"#313131\")\nplt.gca().invert_yaxis()\nplt.xlabel(\"Popularity\")\nplt.title(\"Popular Movies\")","7cda85f8":"![imdb.jpeg](attachment:imdb.jpeg)\n[IMDB WEBSITE](https:\/\/www.imdb.com)\n\n# IMDb (also known as the Internet Movie Database) is an online database owned by Amazon of information related to films, television programs, home videos, video games, and streaming content online \u2013 including cast, production crew and personal biographies, plot summaries, trivia, ratings, and fan and critical reviews. An additional fan feature, message boards, was abandoned in February 2017. Originally a fan-operated website, the database is owned and operated by IMDb.com, Inc., a subsidiary of Amazon.\n\n# As of January 2020, IMDb has approximately 6.5 million titles (including episodes) and 10.4 million personalities in its database, as well as 83 million registered users. ","acea9f87":"# If you like, Please Upvote","0408b095":"# Filtering Based On Vote : Demographic Filter","a7f67378":"# qualified movies","2976e91e":"# Trending Movies","86d6bd59":"# Cosine Similarity\n\n![cosine.png](attachment:cosine.png)\n\n**Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis.\nA document can be represented by thousands of attributes, each recording the frequency of a particular word (such as a keyword) or phrase in the document. Thus, each document is an object represented by what is called a term-frequency vector.**\n\n**We all are familiar with vectors: they can be 2D, 3D or whatever-D. Let\u2019s think in 2D for a moment, because it\u2019s easier to picture in our mind, and let\u2019s refresh the concept of dot product first. The dot product between two vectors is equal to the projection of one of them on the other. Therefore, the dot product between two identical vectors (i.e. with identical components) is equal to their squared module, while if the two are perpendicular (i.e. they do not share any directions), the dot product is zero. Generally, for n-dimensional vectors, the dot product can be calculated as shown below.**\n\n**The dot product is important when defining the similarity, as it is directly connected to it. The definition of similarity between two vectors u and v is, in fact, the ratio between their dot product and the product of their magnitudes.**\n\n**By applying the definition of similarity, this will be in fact equal to 1 if the two vectors are identical, and it will be 0 if the two are orthogonal. In other words, the similarity is a number bounded between 0 and 1 that tells us how much the two vectors are similar.**","32dcdf9a":"# Content Based Filtering\n\n![content.png](attachment:content.png)\n\n***This type of filter does not involve other users if not ourselves. Based on what we like, the algorithm will simply pick items with similar content to recommend us. In this case there will be less diversity in the recommendations, but this will work either the user rates things or not. If we compare this to the example above, maybe user B potentially likes dark comedy but he\/she will never know, unless he\/she decides to give it a try autonomously, because this filter will only keep recommending dystopian movies or similar. Of course there are many categories we can calculate the similarity on: in the case of movies we can decide to build our own recommender system based on genre only, or maybe we want to include director, main actors and so on.***","1bc450df":"average rating is 6 out of 10","4a093c5b":"# If you like, Please Upvote"}}