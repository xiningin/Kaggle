{"cell_type":{"5b07ad3d":"code","a4f498b6":"code","02c8b515":"code","313c021a":"code","c5941580":"code","0dcc24b2":"code","f8c14973":"code","ef274ba5":"code","334783b5":"code","aa9c88e0":"code","1a255e89":"code","f4965d69":"code","0c2b34a1":"code","a004e5c3":"code","ee9f31a8":"code","8fb27f76":"code","387ecc9d":"code","2aa15d13":"code","d77d31c0":"code","a52730df":"code","29de79bc":"code","5d0a493e":"code","148dc65a":"markdown","e0a62bc1":"markdown","902d2c87":"markdown","a40dc749":"markdown","b6cfbfe0":"markdown","89588c12":"markdown","c7a15b63":"markdown","98661dd1":"markdown","271f886b":"markdown","ed82f7c6":"markdown","49ad24c7":"markdown","325aca25":"markdown","e3d74a87":"markdown","0c1c2a13":"markdown","a77bad58":"markdown","0639539c":"markdown","b18764c5":"markdown","4a2a68ab":"markdown","98002058":"markdown","b24dbe0a":"markdown"},"source":{"5b07ad3d":"# Import some packages needed\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn import linear_model\nfrom datetime import datetime\n\n# Read the train and test dataset\ntrain_df = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/train.csv.zip\")\ntest_df = pd.read_csv(\"..\/input\/restaurant-revenue-prediction\/test.csv.zip\")\n\n# Remove Id field from train dataset\ntrain_df = train_df.drop([\"Id\"], axis = 1)\n\n# Look at some train data examples\ntrain_df.head(10)","a4f498b6":"# Turn Open Date field into datetime type\ntrain_df[\"Open Date\"] = train_df[\"Open Date\"].astype('datetime64[ns]')\n\n# Get competition date\ncompetition_date = datetime.strptime('2015-09-14', '%Y-%m-%d')\n\n# Convert Open Date field into integer\ntrain_df[\"Dummy\"] = competition_date\ntrain_df[\"Open Date\"] = train_df[\"Open Date\"] - train_df[\"Dummy\"]\ntrain_df[\"Open Date\"] = train_df[\"Open Date\"].dt.days\ntrain_df = train_df.drop([\"Dummy\"], axis = 1)\ntrain_df[\"Open Date\"] = train_df[\"Open Date\"].abs()\n\n# Look the Open Date converted field\ntrain_df[[\"Open Date\"]].head(10)","02c8b515":"# Draw scatter plot of Open Date vs Revenue\nplt.scatter(train_df[\"Open Date\"], train_df[\"revenue\"])\nplt.xlabel(\"Open Date\")\nplt.ylabel(\"Revenue\")\nplt.show()","313c021a":"# Get index of those outliars\nindex_out = train_df[train_df['revenue'] > 12500000].index\n\n# Remove outliar data from train dataset\ntrain_df = train_df.drop(index_out)\n\n# Copy train_df for later observations\nfor_corr_df = train_df\n\n# To confirm, we now only have 134 rows\ntrain_df","c5941580":"# Get the frequency of each unique value on City field\ntrain_df[[\"City\"]].value_counts()","0dcc24b2":"# Turn City field into one-hot-encoding form\ncity_dummy_df = pd.get_dummies(train_df[[\"City\"]], prefix = ['City'])\n\n# Create new column titled City_Other\ncity_dummy_df[\"City_Other\"] = 0\nfor index, rows in city_dummy_df.iterrows():\n    if (\n        rows[\"City_\u0130stanbul\"] == 0 and\n        rows[\"City_Ankara\"] == 0 and\n        rows[\"City_\u0130zmir\"] == 0 and\n        rows[\"City_Bursa\"] == 0 and\n        rows[\"City_Samsun\"] == 0 and\n        rows[\"City_Antalya\"] == 0 and\n        rows[\"City_Sakarya\"] == 0\n    ):\n        city_dummy_df[\"City_Other\"][index] = 1\n\n# Choose only 8 features\ncity_dummy_df = city_dummy_df[[\"City_\u0130stanbul\", \"City_Ankara\", \"City_\u0130zmir\", \"City_Bursa\", \"City_Samsun\", \"City_Antalya\", \"City_Sakarya\", \"City_Other\"]]\n\n# Merge that one-hot-encoding dataframe to train_df\ntrain_df = pd.merge(train_df, city_dummy_df, left_index = True, right_index = True)\n\n# Look at the result\ntrain_df.head(10)","f8c14973":"# Draw a chart about the frequency of each value of City Group field\nax = sns.countplot(x = \"City Group\", data = train_df)","ef274ba5":"# Turn City Group field into one-hot-encoding form\ngroup_dummy_df = pd.get_dummies(train_df[[\"City Group\"]], prefix = ['Group'])\n\n# Merge that one-hot-encoding dataframe to train_df\ntrain_df = pd.merge(train_df, group_dummy_df, left_index = True, right_index = True)\n\n# Look at the result\ntrain_df.head(10)","334783b5":"# Draw a chart about the frequency of each value of Type field (from train dataset and test dataset)\nplt.figure(1)\nax = sns.countplot(x = \"Type\", data = train_df)\nplt.figure(2)\nax = sns.countplot(x = \"Type\", data = test_df)","aa9c88e0":"# Get information about revenue's average in each type\nrev_avg_df = train_df[[\"Type\", \"revenue\"]].groupby(\"Type\").mean()\ntype_freq_df = train_df[[\"Type\", \"revenue\"]].groupby(\"Type\").count()\nrev_info_by_type_df = pd.merge(type_freq_df, rev_avg_df, on = \"Type\").sort_values(by = ['revenue_x'], ascending = False)\nrev_info_by_type_df = rev_info_by_type_df.rename(columns = {\"revenue_y\": \"Average Rev\", \"revenue_x\": \"Frequency\"})\nrev_info_by_type_df","1a255e89":"# Replace all DT with IL\nfor index, rows in train_df.iterrows():\n    if rows[\"Type\"] == \"DT\":\n        train_df[\"Type\"][index] = \"IL\"\n\n# Turn into one-hot-encoding form\ntype_dummy_df = pd.get_dummies(train_df[[\"Type\"]], prefix = ['Type'])\n\n# Merge that one-hot-encoding dataframe to train_df\ntrain_df = pd.merge(train_df, type_dummy_df, left_index = True, right_index = True)\n\n# Look at the result\ntrain_df.head(10)","f4965d69":"# Get sub dataframe of all numerical type fields\nnumerical_df = for_corr_df.drop([\"City\", \"City Group\", \"Type\"], axis = 1)\n\n# Normalize the dataset\nnumerical_df_val = numerical_df.values # Returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nnumerical_scaled = min_max_scaler.fit_transform(numerical_df_val)\nnormal_numerical_df = pd.DataFrame(numerical_scaled)\n\n# Get correlation matrix\ncorr_df = normal_numerical_df.corr()\ncorr_df = corr_df.abs()\n\n# Draw correlation heatmap for all numerical type fields\nplt.figure(figsize = (39, 39))\nax = sns.heatmap(corr_df)","0c2b34a1":"# Draw scatter plot for each feature vs revenue\nfeatures_index = [2, 28]\ncounter = 1\nfor index in features_index:\n    plt.figure(counter)\n    x_field_name = \"P\" + str(index)\n    plt.scatter(train_df[x_field_name], train_df[\"revenue\"])\n    plt.xlabel(x_field_name)\n    plt.ylabel(\"Revenue\")\n    counter += 1\n\n# Draw the plot in a frame\nplt.show()","a004e5c3":"# Feature selection\nto_drop = []\nfor index in list(range(1, 38)):\n    if index not in features_index:\n        to_drop.append(\"P\" + str(index))\ntrain_df = train_df.drop(to_drop, axis = 1)\n\n# Look at the result\ntrain_df","ee9f31a8":"# Create regresson object and prepare the dataset\nregr = linear_model.LinearRegression()\ntrain_x = np.asanyarray(train_df.drop(['revenue', 'City', 'City Group', 'Type'], axis = 1))\ntrain_y = np.asanyarray(train_df[['revenue']])\n\n# Feed the data into the model\nregr.fit(train_x, train_y)","8fb27f76":"# --------------- Convert Open Date ---------------\n# Turn Open Date field into datetime type\ntest_df[\"Open Date\"] = test_df[\"Open Date\"].astype('datetime64[ns]')\n\n# Convert Open Date field into integer\ntest_df[\"Dummy\"] = competition_date\ntest_df[\"Open Date\"] = test_df[\"Open Date\"] - test_df[\"Dummy\"]\ntest_df[\"Open Date\"] = test_df[\"Open Date\"].dt.days\ntest_df = test_df.drop([\"Dummy\"], axis = 1)\ntest_df[\"Open Date\"] = test_df[\"Open Date\"].abs()\n\n# Look the Open Date converted field\ntest_df[[\"Open Date\"]].head(10)","387ecc9d":"# --------------- Convert City ---------------\n# Turn City field into one-hot-encoding form\ncity_dummy_df = pd.get_dummies(test_df[[\"City\"]], prefix = ['City'])\n\n# Create new column titled City_Other\ncity_dummy_df[\"City_Other\"] = 0\nfor index, rows in city_dummy_df.iterrows():\n    if (\n        rows[\"City_\u0130stanbul\"] == 0 and\n        rows[\"City_Ankara\"] == 0 and\n        rows[\"City_\u0130zmir\"] == 0 and\n        rows[\"City_Bursa\"] == 0 and\n        rows[\"City_Samsun\"] == 0 and\n        rows[\"City_Antalya\"] == 0 and\n        rows[\"City_Sakarya\"] == 0\n    ):\n        city_dummy_df[\"City_Other\"][index] = 1\n\n# Choose only 8 features\ncity_dummy_df = city_dummy_df[[\"City_\u0130stanbul\", \"City_Ankara\", \"City_\u0130zmir\", \"City_Bursa\", \"City_Samsun\", \"City_Antalya\", \"City_Sakarya\", \"City_Other\"]]\n\n# Merge that one-hot-encoding dataframe to train_df\ntest_df = pd.merge(test_df, city_dummy_df, left_index = True, right_index = True)\n\n# Look at the result\ntest_df.head(10)","2aa15d13":"# --------------- Convert City Group ---------------\n# Turn City Group field into one-hot-encoding form\ngroup_dummy_df = pd.get_dummies(test_df[[\"City Group\"]], prefix = ['Group'])\n\n# Merge that one-hot-encoding dataframe to train_df\ntest_df = pd.merge(test_df, group_dummy_df, left_index = True, right_index = True)\n\n# Look at the result\ntest_df.head(10)","d77d31c0":"# --------------- Convert Type ---------------\n# Replace all DT with IL\nfor index, rows in test_df.iterrows():\n    if rows[\"Type\"] == \"DT\":\n        test_df[\"Type\"][index] = \"IL\"\n    elif rows[\"Type\"] == \"MB\":\n        test_df[\"Type\"][index] = \"FC\"\n\n# Turn into one-hot-encoding form\ntype_dummy_df = pd.get_dummies(test_df[[\"Type\"]], prefix = ['Type'])\n\n# Merge that one-hot-encoding dataframe to train_df\ntest_df = pd.merge(test_df, type_dummy_df, left_index = True, right_index = True)\n\n# Look at the result\ntest_df.head(10)","a52730df":"# --------------- Feature Selection ---------------\nto_drop = []\nfor index in list(range(1, 38)):\n    if index not in features_index:\n        to_drop.append(\"P\" + str(index))\ntest_df = test_df.drop(to_drop, axis = 1)\n\n# Look at the result\ntest_df.head(10)","29de79bc":"# Prepare the dataset\ntest_x = np.asanyarray(test_df.drop(['Id', 'City', 'City Group', 'Type'], axis = 1))","5d0a493e":"# Predict restaurant revenue\ny_predict = regr.predict(test_x)\n\n# Save into csv format\ntest_df[\"Prediction\"] = y_predict\nsubmit_df = test_df[[\"Id\", \"Prediction\"]]\nsubmit_df.to_csv(\"submission.csv\", index = False)","148dc65a":"Now, we will build and train our model. We will simply use simple linear regression model from sklearn packages. But before we fit in the dataset into the model, we separate the features and target first, then convert them into numpy array.","e0a62bc1":"In this first step, we will gather as much information we need from the dataset. We will start from Open Date field. As we see, Open Date field gives us information about when the restaurant started their business. In this form, we only get categorical type variable with so many unique values. So, we will try to convert it first into an integer that have meaningful measurement. We can do it in the following way. First, we take an anchor date. In this case we can take the date when this competition launched. Then, we can calculate how old that restaurant by counting how many days are there between the open date and anchor date. So now, the Open Date gives us information about the age of the restaurant, which is measurable. After that, we will plot the Open Date field with the revenue Field using scatter plot, and try to gain information from their relationship.","902d2c87":"We will try to predict restaurant revenue based on given information. The steps can be divided into the following.\n1. Analyzing and preprocessing the dataset\n2. Feed the data into regression model\n3. Use trained regression model from previous step to predict other restaurant revenue\n\nBefore we begin analyzing and preprocessing the dataset, we need to import some packages and read the dataset in.","a40dc749":"Next, we will take a look at Type field. We will draw a countplot for that field, which will give us information about what unique values are there, and how much the appearance of each value.","b6cfbfe0":"Now we are ready to use the model to predict restaurant revenue based on information given in test dataset. But before we can predict, first we need to preprocess the data like we did before to train dataset (convert open date, turn city, city group, and type to one-hot-encoding form, etc).","89588c12":"Next, we will look at correlation between each feature pair (Open Date, P1 - P37, and Revenue), and draw a heatmap. But before we calculate the correlation, we will normalize the dataset first.","c7a15b63":"Next, we will take a look at City Group field. We will draw a countplot for that field, which will give us information about what unique values are there, and how much the appearance of each value.","98661dd1":"As we can see there are 3 unique values in train dataset. But, one of them has frequency of appearance so small. So we will change all DT values into one of IL or FC. To do this we can use the same strategy as we used before for City field, using revenue average. Furthermore, if we look at the test dataset, there are 4 unique values for this field. This means we don't have any information about MB type from train dataset. And since this is added in test dataset, we cannot turn it into FC or IL based on revenue. So we will just simply turn them into FC type (the most common type) later.","271f886b":"Before we build the model, we will do feature selection. From our observation, we get that there are no strong correlation between P1 - P37 to revenue. But at least, we find that P2 and P28 is better than the other, so we will choose P2 and P28 as our features. We also know that Open Date is still better than those P1-P37 columns, so we will include Open Date too. We also have turned some categorical variables into one-hot-encoding form, which we will use as our features too.","ed82f7c6":"From above result, we can see that DT's average revenue is closer to IL rather than FC, so we will replace DT into IL.","49ad24c7":"## **Feed the Dataset Into Regression Model**","325aca25":"First of all, we notice that there are 3 outliar data (the point which revenue above 1.25). We will remove those 3 data from train dataset in next step. Other than those outliar data, this plot doesn't give us any reliable information. It is more likely that there is a poor to no correlation between Open Date and Revenue. We will talk about correlation more later.","e3d74a87":"Next, we will try to gather information from City field. First, we will count how many unique values are there, and what is the occurence frequency of each value. We can use value_counts syntax as the following.","0c1c2a13":"We can see that there are only 2 unique values, where those values appear almost balance. So we will just turn it into standard one-hot-encoding form using following syntax.","a77bad58":"There are 37 unique values, where most of them only appear once. And if we want to turn them into one-hot-encoding form (which is a needed step to deal with categorical type data), it will be too much if we convert them to be 37 different features. So, we can try to make it becomes only 8 features. Those cities who have occurence frequency greater than or equal to 4 will have their own class (so there are 7 classes), and for the rest will be categorized as \"other\". Following syntax will do our target and turn them into one-hot-encoding form.","0639539c":"## **Predict Restaurant Revenue**","b18764c5":"We are ready to predict restaurant revenue using our trained regression model. After we get the prediction, we will convert it into pandas dataframe and save it to csv.","4a2a68ab":"# **Predict Restaurant Revenue Using Regression**\n**By : Garry Ariel**","98002058":"We are interested to find a good correlation from any features to revenue. Darker tiles mean weaker correlation, and brighter tiles mean stronger correlation. Notice that row 38 is about the correlation of revenue to any other features. We can see there that most of the tiles is almost totally black (If we look closer, it is more that likely they only have around maximum 0.2 correlation with revenue). But among them, there still some features who get \"brighter\" than the other. We will focus our observation to such features, which are column 0, 2, and 28. Column 0 for Open Date feature, column 2 and 28 for P2 and P28 features respectively. Next we will look at the scatter plot of P2 vs Revenue and P28 vs Revenue.","b24dbe0a":"## **Analyze and Preprocess the Dataset**"}}