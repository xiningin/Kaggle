{"cell_type":{"4951f64d":"code","545576e1":"code","3261d56b":"code","8e1d3e99":"code","fa3de9c7":"code","74368006":"code","82c5feb4":"code","7e6db4aa":"code","659092bb":"code","5eba9642":"code","f2f3d9e2":"code","09ce925d":"code","664aa22c":"code","88a8bad3":"code","ca61fc15":"code","8a973724":"code","4c43ac38":"code","8e7a3b68":"code","5aeef190":"code","a0d0083e":"code","4d647132":"code","ea62f462":"code","6b5f74a9":"markdown","f5508510":"markdown","a9daed75":"markdown","7f899534":"markdown","6cf9e7b3":"markdown","7e13325c":"markdown","c54a58b9":"markdown"},"source":{"4951f64d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport time\nimport os\nfrom IPython.display import clear_output","545576e1":"sample_size = 500\nwidth = 100\nheight = 100","3261d56b":"files = ['Fresh', 'Spoiled']\nadress = '\/kaggle\/input\/meat-quality-assessment-based-on-deep-learning\/{}'\ndata = {}\nfor f in files:\n    data[f]=[]\nfor col in files:\n    os.chdir(adress.format(col))\n    for i in os.listdir(os.getcwd()):\n        if i.endswith('.jpg'):\n            data[col].append(i)","8e1d3e99":"pd.DataFrame(data).head()","fa3de9c7":"sizes = [len(data['Fresh']), len(data['Spoiled'])]\n\nplt.figure(figsize=(10,5), dpi=100)\n\nplt.pie(x=sizes,autopct='%1.0f%%',shadow=False, textprops={'color':\"w\",\"fontsize\":15}, startangle=90,explode=(0,.01))\nplt.legend(files,bbox_to_anchor=(0.4, 0, .7, 1))\nplt.title(\"Data Split\")\nplt.show()","74368006":"start = time.time()\nimage_data = []\nimage_target = []\n\nfor title in files:\n    os.chdir(adress.format(title))\n    counter = 0\n    for i in data[title]:\n        img = cv2.imread(i)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        image_data.append(cv2.resize(img,(width, height)))\n        image_target.append(title)\n        counter += 1\n        if counter == sample_size:\n            break\n    clear_output(wait=True)\n    print(\"Compiled Class\",title)\ncalculate_time = time.time() - start    \nprint(\"Calculate Time\",round(calculate_time,5))","82c5feb4":"image_data = np.array(image_data)\nsize = image_data.shape[0]\nimage_data.shape","7e6db4aa":"plt.figure(figsize=(15,15))\nfor i in range(1,17):\n    fig = np.random.choice(np.arange(size))\n    plt.subplot(4,4,i)\n    plt.imshow(image_data[fig])\n    if image_target[fig]=='Fresh':\n        c='green'\n    else:\n        c='red'\n    plt.title(image_target[fig], color=c)\n    plt.xticks([]), plt.yticks([])\nplt.show()","659092bb":"import tensorflow as tf\n\nfrom tensorflow.keras import datasets, layers, models\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split","5eba9642":"labels = LabelEncoder()\nlabels.fit(image_target)","f2f3d9e2":"X = image_data \/ 255.0\ny = labels.transform(image_target)\ntrain_images, test_images, train_labels, test_labels = train_test_split(X,y, test_size=0.3, random_state=123)","09ce925d":"model = models.Sequential()\nmodel.add(layers.Conv2D(35, (3, 3), activation='relu', input_shape=(width,height,3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))","664aa22c":"model.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(2))","88a8bad3":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_labels, epochs=10, \n                    validation_data=(test_images, test_labels))","ca61fc15":"plt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1.01])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)","8a973724":"result=model.evaluate(test_images, test_labels)","4c43ac38":"for i in range(len(model.metrics_names)):\n    print(model.metrics_names[i],\":\",result[i])","8e7a3b68":"model.summary()","5aeef190":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns","a0d0083e":"y_pred = model.predict(test_images)\n\ndef toClass(pred):\n    \n    class_ = np.zeros(len(pred))\n    for i in range(len(pred)):\n        index = pred[i].argmax()\n        class_[i] = index\n        \n    return class_\n\ncm = confusion_matrix(test_labels,toClass(y_pred))\n\ndf1 = pd.DataFrame(columns=[\"Fresh\",\"Spoiled\"], index= [\"Fresh\",\"Spoiled\"], data= cm )\n\nf,ax = plt.subplots(figsize=(6,6))\n\nsns.heatmap(df1, annot=True,cmap=\"Greens\", fmt= '.0f',ax=ax,linewidths = 5, cbar = False,annot_kws={\"size\": 16})\nplt.xlabel(\"Predicted Label\")\nplt.xticks(size = 12)\nplt.yticks(size = 12, rotation = 0)\nplt.ylabel(\"True Label\")\nplt.title(\"YSA Confusion Matrix\", size = 12)\nplt.show()","4d647132":"def Prediction(image):\n    \n    global width, height, files, labels\n    \n    img = cv2.resize(image,(width,height))\n    \n    test = img \/ 255.0\n    \n    pred = model.predict(np.array([image])).argmax()\n    \n    return labels.inverse_transform([pred])[0]","ea62f462":"plt.figure(figsize=(15,15))\nfor i in range(1,17):\n    fig = np.random.choice(np.arange(size))\n    plt.subplot(4,4,i)\n    plt.imshow(image_data[fig])\n    if image_target[fig]=='Fresh':\n        c='green'\n    else:\n        c='red'\n    plt.title(image_target[fig], color=c)\n    plt.ylabel(\"| Pred:{} |\".format(Prediction(image_data[fig])),fontsize=17, color=c)\n    plt.xticks([]), plt.yticks([])\nplt.show()","6b5f74a9":"# **Contents**\n\n1. [Import data and python packages](#t1.)\n\n\n2. [Data visualization](#t2.)\n\n\n3. [Classification (CNN)](#t3.)\n\n\n4. [Prediction](#t4.)","f5508510":"<a id=\"t4.\"><\/a>\n# 4. Prediction","a9daed75":"<a id=\"t2.\"><\/a>\n# 2. Data visualization","7f899534":"***Meat Quality Assessment based on Deep Learning***\n\nAuthors: O. Ulucan, D. Karakaya, M. Turkan\nDepartment of Electrical and Electronics Engineering, Izmir University of Economics, Izmir, Turkey\nCorresponding author: M. Turkan\nContact Information: mehmet.turkan@ieu.edu.tr\n\n\n***General Introduction***\n\nThis dataset contains 2 classes, fresh and spoiled red meat samples collected from a supermarket in Izmir, Turkey\nfor a university-industry collaboration project at Izmir University of Economics, and this work\nwas published in ASYU 2019. \n\nIf you use this dataset in your work, please consider to cite:\n* O.Ulucan , D.Karakaya and M.Turkan.(2019) Meat quality assessment based on deep learning.\nIn Conf. Innovations Intell. Syst. Appli. (ASYU)\n\n***Purpose of the work***\n\nThis dataset was collected in order to develop a meat quality assessment system which is based on deep learning. \nAll of the experimental results which are explained in the paper, prove the usability of our dataset and our model can successfully distinguish between the classes with high accuracy.\n\n\n***Resolution and the Number of the Images***\n\nImages were collected via an IP camera and the resolution of the images are 1280 x 720. There are 1896 images in total, 948 per class. ","6cf9e7b3":"<h1><center>Meat Quality Assessment<\/center><\/h1>\n\n<center><img src=\"https:\/\/im.haberturk.com\/2019\/02\/23\/ver1550911120\/2382763_810x458.jpg\"><\/center>","7e13325c":"<a id=\"t1.\"><\/a>\n# 1. Import data and python packages","c54a58b9":"<a id=\"t3.\"><\/a>\n# 3. Classification (CNN)"}}