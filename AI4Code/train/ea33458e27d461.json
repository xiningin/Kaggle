{"cell_type":{"13bbbaf3":"code","a7678867":"code","2a73ef2d":"code","1b8327a5":"code","8887552c":"code","770eb597":"code","53fdd96b":"code","e438eb2d":"code","0411cfc6":"code","ec2cfdce":"code","0452c59e":"code","283d70a5":"markdown"},"source":{"13bbbaf3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers import  BatchNormalization\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import KFold\nfrom six.moves import cPickle as pickle\nfrom keras import regularizers\nimport os\nimport platform\nfrom subprocess import check_output\nimport matplotlib.pyplot as plt\nimport argparse\nimport random\nimport cv2\nimport os\nfrom keras.layers.core import Dense, Dropout, Flatten\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a7678867":"#making class of lenet neural network\nclass leNet:\n    def initilize_model(height, width, depth,classes):\n        model=Sequential()\n        input_shape=(height,width,depth)\n        # if we are using \"channel first\" than our first arugemnt of input_shape will change to depth\n        if K.image_data_format()==\"channels first\":\n            input_shape=(depth,height,width)\n        # conv2d set  =====> Conv2d====>relu=====>MaxPooling\n        model.add(Conv2D(20,(5,5),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        #model.add(Conv2D(20,(3,3),padding=\"same\"))\n        #model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        model.add(Dropout(0.2))\n        \n        # conv2d set2  =====> Conv2d====>relu=====>MaxPooling\n        model.add(Conv2D(50,(5,5),padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        #model.add(Conv2D(50,(3,3),padding=\"same\"))\n        #model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        model.add(Dropout(0.5))\n        \n        model.add(Conv2D(80,(5,5),padding='same'))\n        model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        #model.add(Conv2D(80,(5,5),padding='same'))\n        #model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        model.add(Dropout(0.2))\n        \n        model.add(Conv2D(110,(5,5),padding='same'))\n        model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        #model.add(Conv2D(110,(5,5),padding='same'))\n        #model.add(Activation(\"relu\"))\n        #model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        model.add(Dropout(0.6))\n        \n        #now adding fully connected layer\n        model.add(Flatten())\n        model.add(Dense(1024))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(512))\n        model.add(Activation(\"relu\"))\n        \n        #now adding Softmax Classifer because we want to classify 10 class\n        \n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n        \n        return model","2a73ef2d":"def load_pickle(f):\n    version = platform.python_version_tuple()\n    if version[0] == '2':\n        return  pickle.load(f)\n    elif version[0] == '3':\n        return  pickle.load(f, encoding='latin1')\n    raise ValueError(\"invalid python version: {}\".format(version))\n\ndef load_CIFAR_batch(filename):\n    \"\"\" load single batch of cifar \"\"\"\n    with open(filename, 'rb') as f:\n        datadict = load_pickle(f)\n        X = datadict['data']\n        Y = datadict['labels']\n        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n        Y = np.array(Y)\n        return X, Y\n\ndef load_CIFAR10(ROOT):\n    \"\"\" load all of cifar \"\"\"\n    xs = []\n    ys = []\n    for b in range(1,6):\n        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n        X, Y = load_CIFAR_batch(f)\n        xs.append(X)\n        ys.append(Y)\n    Xtr = np.concatenate(xs)\n    Ytr = np.concatenate(ys)\n    del X, Y\n    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n    return Xtr, Ytr, Xte, Yte\ndef get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n    # Load the raw CIFAR-10 data\n    cifar10_dir = '..\/input\/cifar10'\n    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n\n    # Subsample the data\n    mask = range(num_training, num_training + num_validation)\n    X_val = X_train[mask]\n    y_val = y_train[mask]\n    mask = range(num_training)\n    X_train = X_train[mask]\n    y_train = y_train[mask]\n    mask = range(num_test)\n    X_test = X_test[mask]\n    y_test = y_test[mask]\n    \n    # Normalize the data: subtract the mean image\n    #Zscores\n    std = np.std(X_train,axis=(0,1,2,3))\n    std = np.std(X_val,axis=(0,1,2,3))\n    std = np.std(X_test,axis=(0,1,2,3))\n    mean_image = np.mean(X_train, axis=0)\n    X_train =(X_train - mean_image)\/(std)\n    X_val = (X_val - mean_image)\/std\n    X_test = (X_test - mean_image)\/std\n\n    return X_train, y_train, X_val, y_val, X_test, y_test\n\n\n# Invoke the above function to get our data.\nX_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\nprint('Train data shape: ', X_train.shape)\nprint('Train labels shape: ', y_train.shape)\nprint('Validation data shape: ', X_val.shape)\nprint('Validation labels shape: ', y_val.shape)\nprint('Test data shape: ', X_test.shape)\nprint('Test labels shape: ', y_test.shape)\ny=y_train\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical( y_test, num_classes=10)\ny_val = to_categorical( y_val, num_classes=10)","1b8327a5":"EPOCHS = 5\nINIT_LR = 1e-3\nBS = 32\n#data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    )\ndatagen.fit(X_train)\n\n# Model\nmodel = leNet.initilize_model(width=32, height=32, depth=3, classes=10)\nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\n   # Compile the model\nmodel.compile(loss='categorical_crossentropy',\n                  optimizer=Adam(lr=0.0001, decay=1e-6),\n                  metrics=['accuracy'])","8887552c":"history= model.fit(X_train, y_train,\n              batch_size=128,\n              shuffle=True,\n              epochs=10,\n              validation_data=(X_val, y_val),\n              \n             )","770eb597":"scores = model.evaluate(X_test,y_test)\n\nprint('Loss: %.3f' % scores[0])\nprint('Accuracy: %.3f' % scores[1])","53fdd96b":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e438eb2d":"model.summary()","0411cfc6":"def predict_label(a): # a is the number of index for which model predict the max value\n    if a==0:p=\"Aeroplane\"\n    if a==1: p=\"automobile\"\n    if a==2: p=\"bird\"\n    if a==3: p=\"cat\"\n    if a==4: p=\"deer\"\n    if a==5: p=\"dog\"\n    if a==6: p=\"frog\"\n    if a==7: p=\"hourse\"\n    if a==8: p=\"Ship\"\n    if a==9: p=\"truck\"\n    \n    return p","ec2cfdce":"x = np.expand_dims(X_test[45], axis=0)\na=model.predict(x)\nmaxindex = a.argmax()\np=predict_label(maxindex)\nplt.title(\"Model Prediction =\"+p)\nplt.imshow(X_test[45])\n","0452c59e":"from sklearn.metrics import classification_report\nimport numpy as np\n\nY_test = np.argmax(y_test, axis=1) # Convert one-hot to index\ny_pred = model.predict_classes(X_test)\nprint(classification_report(Y_test, y_pred))","283d70a5":"**Accuracy of Every Class**"}}