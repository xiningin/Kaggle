{"cell_type":{"c9cc4052":"code","32f5c036":"code","09dc3678":"code","30a5456b":"code","f8780a11":"code","128c22cf":"code","7a8675d5":"code","6517b0db":"code","3b61471e":"code","b6eaabb9":"code","a5c9de55":"code","fb5abf61":"code","a2facca4":"code","750172db":"code","b70eb14d":"code","1ae3bb51":"code","18e1cac9":"code","889616a1":"code","32b9a13a":"code","548df665":"code","38e15a90":"code","00838c8a":"code","7c76787a":"markdown","f4791f8f":"markdown","df889d16":"markdown"},"source":{"c9cc4052":"!pip uninstall kaggle\n!pip install --upgrade pip\n!pip install kaggle==1.5.6","32f5c036":"!mkdir -p ~\/.kaggle\n!cp kaggle.json ~\/.kaggle\n!ls -lha kaggle.json\n!chmod 600 ~\/.kaggle\/kaggle.json","09dc3678":"!kaggle competitions download -c solarenergy-meteorologicalphenomenon2","30a5456b":"!unzip solarenergy-meteorologicalphenomenon2.zip","f8780a11":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nfrom sklearn import preprocessing","128c22cf":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","7a8675d5":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate = 1e-5\ntraining_epochs = 700\nbatch_size = 50\n\n#Scaler = preprocessing.StandardScaler()","6517b0db":"train_data=pd.read_csv('Solar_TrainData_3.csv',header=None,skiprows=[0], usecols=range(1,9))\ntest_data=pd.read_csv('Solar_TestData_2.csv',header=None,skiprows=[0], usecols=range(1,8))","3b61471e":"x_train_data=train_data.loc[:,0:7]\ny_train_data=train_data[[8]]\n\nx_train_data=np.array(x_train_data)\ny_train_data=np.array(y_train_data)\n#x_train_data = Scaler.fit_transform(x_train_data)\n\nx_train_data=torch.FloatTensor(x_train_data)\ny_train_data=torch.FloatTensor(y_train_data)\nprint(x_train_data)\nprint(y_train_data)\n","b6eaabb9":"train_dataset = torch.utils.data.TensorDataset(x_train_data, y_train_data)","a5c9de55":"data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)","fb5abf61":"linear1 = torch.nn.Linear(7,1024,bias=True)\nlinear2 = torch.nn.Linear(1024,1024,bias=True)\nlinear3 = torch.nn.Linear(1024,1024,bias=True)\nlinear4 = torch.nn.Linear(1024,1024,bias=True)\nlinear5= torch.nn.Linear(1024,1024,bias=True)\nlinear6= torch.nn.Linear(1024,1024,bias=True)\nlinear7= torch.nn.Linear(1024,1,bias=True)\n","a2facca4":"# Random Init => Xavier Init\n\ntorch.nn.init.xavier_uniform_(linear1.weight)\n\ntorch.nn.init.xavier_uniform_(linear2.weight)\n\ntorch.nn.init.xavier_uniform_(linear3.weight)\n\ntorch.nn.init.xavier_uniform_(linear4.weight)\n\ntorch.nn.init.xavier_uniform_(linear5.weight)\n\ntorch.nn.init.xavier_uniform_(linear6.weight)\n\ntorch.nn.init.xavier_uniform_(linear7.weight)\n\n","750172db":"# ======================================\n# relu\ub294 \ub9e8 \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\uc5d0\uc11c \ube7c\ub294 \uac83\uc774 \uc88b\ub2e4.\n# ======================================\nmodel = torch.nn.Sequential(linear1,\n                            linear2,\n                            linear3,\n                            linear4,\n                            linear5,\n                            linear6,\n                            linear7\n                            ).to(device)","b70eb14d":"# \uc190\uc2e4\ud568\uc218\uc640 \ucd5c\uc801\ud654 \ud568\uc218\nloss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","1ae3bb51":"total_batch = len(data_loader)\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        X = X.to(device)\n        Y = Y.to(device)\n\n        # \uadf8\ub798\ub514\uc5b8\ud2b8 \ucd08\uae30\ud654\n        optimizer.zero_grad()\n        # Forward \uacc4\uc0b0\n        hypothesis = model(X)\n        # Error \uacc4\uc0b0\n        cost = loss(hypothesis, Y)\n        # Backparopagation\n        cost.backward()\n        # \uac00\uc911\uce58 \uac31\uc2e0\n        optimizer.step()\n\n        # \ud3c9\uade0 Error \uacc4\uc0b0\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n    \n\nprint('Learning finished')","18e1cac9":"# Test the model using test sets\nwith torch.no_grad():\n\n  x_test_data=test_data.loc[:,:]\n  x_test_data=np.array(x_test_data)\n  #x_test_data = Scaler.transform(x_test_data)\n  x_test_data=torch.from_numpy(x_test_data).float().to(device)\n\n  prediction = model(x_test_data)","889616a1":"correct_prediction = prediction.cpu().numpy().reshape(-1,1)","32b9a13a":"submit=pd.read_csv('Solar_SubmitForm_2.csv')\nsubmit","548df665":"test1_date=pd.read_csv('Solar_TestData_2.csv',header=None,skiprows = [0])\ntest1_data=test1_date.loc[:,0]\ntest1_data=np.array(test1_data)\n\nprint(test1_data)","38e15a90":"for i in range(len(correct_prediction)):\n  submit['YYYY\/MM\/DD'][i]=test1_data[i]\n  submit['Predict'][i]=correct_prediction[i].item()\n\nsubmit","00838c8a":"submit.to_csv('submit.csv',index=False,header=True)\n\n!kaggle competitions submit -c solarenergy-meteorologicalphenomenon2 -f submit.csv -m \"Message\"","7c76787a":"[\uba54\ub274\uc5bc] https:\/\/pytorch.org\/docs\/stable\/nn.init.html#torch.nn.init.xavier_uniform_","f4791f8f":"[\uba54\ub274\uc5bc] https:\/\/pytorch.org\/docs\/stable\/nn.html#crossentropyloss","df889d16":"![\ub300\uccb4 \ud14d\uc2a4\ud2b8](https:\/\/user-images.githubusercontent.com\/11758940\/83336289-229ec200-a2ed-11ea-9fb8-88a51198e475.png)"}}