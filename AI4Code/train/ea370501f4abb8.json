{"cell_type":{"e46f37c7":"code","c5e9ff2b":"code","c9cfbc4e":"code","4c741f00":"code","96698e59":"code","9f77d9ae":"code","5982d62d":"code","ae39700d":"code","a669b6af":"code","22a13f05":"code","4b961238":"code","44a204f4":"code","88da0463":"code","8c11ebe5":"code","5a49c8c5":"code","0cd994ad":"markdown","555cf6d7":"markdown","cba75d78":"markdown","d9dbca8a":"markdown","a90dffe5":"markdown","5033d52d":"markdown","8d65f559":"markdown","1077d433":"markdown","cf99a81d":"markdown","d7f6a9a0":"markdown","b5b900dc":"markdown","f8cd2714":"markdown","5e34b961":"markdown"},"source":{"e46f37c7":"import numpy as np \nimport pandas as pd\nimport os\nimport sklearn.datasets as dt\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nsn.set()\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c5e9ff2b":"nomes = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"]\ndata = pd.read_csv(\"\/kaggle\/input\/credit-screening.data\",na_values = '?', names=nomes, sep=\",\")\ndata.head()","c9cfbc4e":"data.describe()","4c741f00":"data.isnull().sum()","96698e59":"data.fillna({'A1':data['A1'].mode(0),'A4':data['A4'].mode(0), 'A5':data['A5'].mode(0), 'A6':data['A6'].mode(0), 'A7':data['A7'].mode(0)}, inplace= True)\ndata","9f77d9ae":"data.fillna({'A2':data['A2'].mean()})\ndata.fillna({'A14':data['A14'].mean()})\n","5982d62d":"data[{'A1', 'A4', 'A5', 'A6','A7','A9','A10','A12','A13'}].astype('category')\n","ae39700d":"data['A16'].astype('category').cat.codes\n","a669b6af":"data = pd.get_dummies(data, columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])\ndata.head()","22a13f05":"dic = dt.load_digits()\ndic.keys()","4b961238":"X = dic.data\ny = dic.target\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y)","44a204f4":"y_train.shape\nX_train.shape","88da0463":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn\nmodel = knn.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_score = model.score(X_test, y_test)\ny_pred\ny_score","8c11ebe5":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\npred = dtree.predict(X_test)","5a49c8c5":"\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(y_test, pred))","0cd994ad":"11 - Execute o algoritmo de \u00c1rvore de Decis\u00e3o, guarde o resultado da predi\u00e7\u00e3o em uma nova coluna predictAD","555cf6d7":"5 - Preencha os campos faltantes das colunas com valores cont\u00ednuos com a m\u00e9dia\n        * Colunas com valores cont\u00ednuos com valores faltantes:  A2 e A14","cba75d78":"2 - Execute a fun\u00e7\u00e3o describe para ver um resumo estat\u00edstico descritivo","d9dbca8a":"9 - utilize train_test_split para criar bases de treino e teste","a90dffe5":"6 - transforme todas as colunas com valores categ\u00f3ricos para o tipo \"category\"  use a fun\u00e7\u00e3o astype\n        * Colunas Categ\u00f3ricas: A1, A4, A5, A6, A7, A9, A10, A12, A13","5033d52d":"4 - Preencha os campos das colunas com valores categ\u00f3ricos com a moda dos valores da coluna, para isso use a fun\u00e7\u00e3o fillna( ) e moda( )\n    * defina um vetor com as colunas a serem alteradas\n    * use um la\u00e7o para varrer o vetor   (for n in colunas: df.fillna...)","8d65f559":"3 - utilize   df.isnull().sum() para saber em quais colunas h\u00e1 valores faltantes NaN\n","1077d433":"*  Colunas Categ\u00f3ricas: A1, A4, A5, A6, A7, A9, A10, A12, A13\n*  Colunas Categ\u00f3ricas com valores faltantes : A1, A4, A5, A6, A7 preencher com a moda (valor que mais aparece na coluna)\n*  Colunas com valores cont\u00ednuos: A2, A3, A8, A11, A14, A15\n*  Colunas com valores cont\u00ednuos com valores faltantes:  A2 e A14 preencher com m\u00e9dia","cf99a81d":"8 - utilize a fun\u00e7\u00e3o pd.get_dummies para transformar todas as colunas categ\u00f3ricas para indicadores de vari\u00e1veis. \n### df = pd.get_dummies( df, columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])","d7f6a9a0":"7 - Transforme a coluna objetivo  A16 primeiro para o tipo category e depois fa\u00e7a a codifica\u00e7\u00e3o num\u00e9rica utiliando a fun\u00e7ao df[\"A16\"].cat.codes","b5b900dc":"10 - Execute o algoritmo dos K vizinhos mais pr\u00f3ximos com K=3, guarde o resultado da predi\u00e7\u00e3o em uma nova coluna do dataframe \"predictKNN\"","f8cd2714":"1 - Importar arquivo (credit-screening.data) procure o dataset no Kaggle, caso n\u00e3o encontre, importe o arquivo dispon\u00edvel no Google Classroom. Importe o arquivo substituindo valores faltantes \"?\" por NaN e inserir o nome das colunas utilizando o vetor abaixo.\n\n#### nomes = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"]5 - ","5e34b961":"1. Title: Credit Approval\n2. Sources: \n    (confidential)\n    Submitted by quinlan@cs.su.oz.au\n3.  Past Usage:\n    See Quinlan,\n    * \"Simplifying decision trees\", Int J Man-Machine Studies 27, Dec 1987, pp. 221-234.\n    * \"C4.5: Programs for Machine Learning\", Morgan Kaufmann, Oct 1992\n4.  Relevant Information:\n    This file concerns credit card applications.  All attribute names\n    and values have been changed to meaningless symbols to protect\n    confidentiality of the data.\n    This dataset is interesting because there is a good mix of\n    attributes -- continuous, nominal with small numbers of\n    values, and nominal with larger numbers of values.  There\n    are also a few missing values.\n5.  Number of Instances: 690\n6.  Number of Attributes: 15 + class attribute\n7.  Attribute Information:\n    A1:\tb, a.\n    A2:\tcontinuous.\n    A3:\tcontinuous.\n    A4:\tu, y, l, t.\n    A5:\tg, p, gg.\n    A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n    A7:\tv, h, bb, j, n, z, dd, ff, o.\n    A8:\tcontinuous.\n    A9:\tt, f.\n    A10:\tt, f.\n    A11:\tcontinuous.\n    A12:\tt, f.\n    A13:\tg, p, s.\n    A14:\tcontinuous.\n    A15:\tcontinuous.\n    A16: +,-         (class attribute)\n8.  Missing Attribute Values:\n    37 cases (5%) have one or more missing values.  The missing\n    values from particular attributes are:\n    A1:  12 ; A2:  12; A4:   6;  A5:   6; A6:   9;   A7:   9;    A14: 13\n9.  Class Distribution\n      +: 307 (44.5%)    -: 383 (55.5%)"}}