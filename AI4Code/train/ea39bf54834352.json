{"cell_type":{"27edc313":"code","1043eed4":"code","c038e8eb":"code","5acdb32c":"code","a62df7fb":"code","070e3edf":"code","47e56cbc":"code","acc5bfb9":"code","b9e3dc18":"code","5ab1f6be":"code","9ff448a1":"code","aabf280b":"code","891ce396":"code","66037fa6":"code","9be6f3e1":"code","74eb6725":"code","d88987ef":"code","1a3da12d":"code","1afff4f5":"code","c301ee46":"code","b2a53673":"code","0922be6c":"code","77cdd957":"code","22f1234e":"code","4efa788e":"code","8a1de309":"code","c385c20e":"code","817c7db9":"code","4b74ad4a":"code","5d864b6b":"code","091a79b4":"code","22cbad4d":"code","e2f43e2e":"code","35548933":"code","a9eb7888":"code","56a33f2a":"code","e7f6f6e9":"code","b874b979":"code","82dc1fcd":"code","0c517175":"code","fa69f005":"code","453810bc":"code","5379e5a0":"code","3124ce28":"code","f56282f4":"code","a68c0780":"markdown","06e7bc96":"markdown","c51df767":"markdown","2d76bbbc":"markdown","57f349de":"markdown","20228c1f":"markdown","68625937":"markdown","b3f2bbb7":"markdown","2b3743ab":"markdown","e696ced5":"markdown","50b1cca6":"markdown","6b14a307":"markdown","ec3827d1":"markdown","5977ecda":"markdown","ee63dd08":"markdown","d55a680c":"markdown","2af036af":"markdown","aacb5184":"markdown","1092f004":"markdown","a3100032":"markdown","fcfb40e5":"markdown","9c701689":"markdown","985c19b1":"markdown","aff02f39":"markdown","836e595b":"markdown","c1b01d25":"markdown","c891d4b0":"markdown","cdffa693":"markdown","59cf119e":"markdown","bd5d60b2":"markdown","18a107dd":"markdown","a6144ec6":"markdown","8ace7993":"markdown","9f33fdd3":"markdown","2adab7c8":"markdown","9a2b6618":"markdown","d365b82f":"markdown","c7e79bd1":"markdown","90f8bb1a":"markdown","96bdea2d":"markdown","1accb6e9":"markdown","bc9bed3f":"markdown","6c04f8da":"markdown","e08e1f77":"markdown","022ea4a3":"markdown","e59e9c16":"markdown","e7cf62c5":"markdown","1b4e5989":"markdown","c34870f0":"markdown"},"source":{"27edc313":"import pandas as pd","1043eed4":"train = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/train.csv\")","c038e8eb":"'''\nfor i,_ in train.iterrows():\n    print(\"Text :\")\n    print(train.loc[i,\"text\"])\n    print(\"Selected Text: \")\n    print(train.loc[i,\"selected_text\"])\n'''","5acdb32c":"failures = pd.read_csv(\"..\/input\/failures\/failures.csv\")","a62df7fb":"failures.shape","070e3edf":"failures.head()","47e56cbc":"fail = pd.merge(train, failures, how='inner', on=['textID'])","acc5bfb9":"fail.shape","b9e3dc18":"fail.head()","5ab1f6be":"'''\nfor i,_ in fail.iterrows():\n    print(\"Text: \")\n    print(fail.loc[i,\"text_x\"])\n    print(\"Selected text: \")\n    print(fail.loc[i,\"selected_text_x\"])\n'''","9ff448a1":"x=0\nfor i,row in fail.iterrows():\n    if (fail.loc[i,\"text_x\"].count(\"  \")>0):\n        x= x+1","aabf280b":"x","891ce396":"train = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/train.csv\")","66037fa6":"train[\"Space\"] = train[\"text\"].str.count(\"  \")","9be6f3e1":"noise = train[train[\"Space\"] > 0 ]","74eb6725":"noise.shape","d88987ef":"noise = noise[noise[\"sentiment\"]!=\"neutral\"]","1a3da12d":"'''\nfor i,row in noise.iterrows():\n    print('Text :')\n    print(noise.loc[i,\"text\"])\n    print('Selected text :')\n    print(noise.loc[i,\"selected_text\"])\n'''","1afff4f5":"fail.head()","c301ee46":"fail[\"Space\"] = fail[\"text_x\"].str.count(\"  \")","b2a53673":"fail = fail[fail[\"Space\"] >0]","0922be6c":"fail.shape","77cdd957":"'''\nfor i,row in fail.iterrows():\n    print('Text :')\n    print(fail.loc[i,\"text_x\"])\n    print('Selected text :')\n    print(fail.loc[i,\"selected_text_x\"])\n'''","22f1234e":"text =  \" Haha I know, I cant handle the fame!  and thank you!\"","4efa788e":"selected = \"thank you!\"","8a1de309":"#find how many spaces we have at the beginning ( this is pure exceeding spaces )\nspaces_begin = len(text) - len(text.lstrip(' '))","c385c20e":"#get the index of the selected_text\ni = text.find(selected)","817c7db9":"extra_left = 0\nspaces = 0\ncount = False\nfor j in range(spaces_begin,i):\n    if (text[j] == ' ' and count == True):\n        spaces = spaces+1\n        \n    if (text[j] == ' '):\n        count = True\n    else:\n        count = False\n        extra_left = extra_left + spaces\n        spaces = 0","4b74ad4a":"extra_left","5d864b6b":"extra_right = 0\nspaces = 0\ncount = False\nfor j in range(i,len(text)):\n    if (text[j] == ' ' and count == True):\n        spaces = spaces+1\n        \n    if (text[j] == ' '):\n        count = True\n    else:\n        count = False\n        extra_right = extra_right + spaces\n        spaces = 0","091a79b4":"extra_right","22cbad4d":"start = i-extra_left-spaces_begin","e2f43e2e":"text[start:i + len(selected)]","35548933":"sub = pd.read_csv(\"..\/input\/sample-submission\/submission (13).csv\")","a9eb7888":"test = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/test.csv\")","56a33f2a":"sub[\"text\"]= test[\"text\"]\nsub[\"sentiment\"] = test[\"sentiment\"]","e7f6f6e9":"cols= ['textID','text','selected_text','sentiment']\nsub = sub[cols]","b874b979":"sub[\"Space\"] = sub[\"text\"].str.count(\"  \")","82dc1fcd":"sub[\"selected_text\"] = sub[\"selected_text\"].str.strip()","0c517175":"df_noise = sub[(sub[\"Space\"] > 0) & ( sub[\"sentiment\"] != \"neutral\")]","fa69f005":"#Iterating all the should-be noise rows\nfor i, row in df_noise.iterrows():\n    #Getting the original text\n    text = df_noise.loc[i,\"text\"]\n    #Getting the selected_text\n    selected = df_noise.loc[i,\"selected_text\"]\n    \n    #First extra spaces\n    spaces_begin = len(text) - len(text.lstrip(' '))\n    #Finding the selected_text in Text\n    idx = text.find(selected)\n    #Now we sometimes have the double space inside the selected_text which would give us idx = -1\n    #And thus, gives us selected_text= nan\n    #This will hinder your score. I did this mistake when I first tried this and almost lost hope if I hadn't visualized the outputs\n    if ( idx != -1):\n        #left spaces\n        extra_left = 0\n        spaces = 0\n        count = False\n        for j in range(spaces_begin,idx):\n            if (text[j] == ' ' and count == True):\n                spaces = spaces+1\n\n            if (text[j] == ' '):\n                count = True\n            else:\n                count = False\n                extra_left = extra_left + spaces\n                spaces = 0\n        #right spaces (unneeded here)\n        extra_right = 0\n        spaces = 0\n        count = False\n        for j in range(idx,len(text)):\n            if (text[j] == ' ' and count == True):\n                spaces = spaces+1\n\n            if (text[j] == ' '):\n                count = True\n            else:\n                count = False\n                extra_right = extra_right + spaces\n                spaces = 0\n        start = idx-extra_left-spaces_begin\n        #Creating the new selected_text\n        new_selected = text[start:idx + len(selected)]\n    else:\n        #If idx=-1, I just kep the selected_text without noise\n        new_selected = selected\n\n    df_noise.loc[i,\"selected_text\"] = new_selected.strip()","453810bc":"for i, row in df_noise.iterrows():\n    sub.loc[i,\"selected_text\"] = df_noise.loc[i,\"selected_text\"]","5379e5a0":"#Dropping unecessary columns\nsub = sub.drop([\"text\",\"sentiment\",\"Space\"], axis=1)","3124ce28":"sub.head()","f56282f4":"sub.to_csv(\"submission.csv\", index=False)","a68c0780":"**Alright it's time to check if its really about the spaces**","06e7bc96":"**Let's count how many tweets with double spaces there is in the failures dataset**","c51df767":"**Alright so after days of looking at these examples I found a pattern:**","2d76bbbc":"**So, this is a key visualization, when going through all these tweets, I notice that there are so many spaces somtimes**","57f349de":"**We need to concatenate text and sentiment to our sub**","20228c1f":"# **And there it is boys.**\n**This simple yet effective change gave us 0.005 in LB**\n\n**Although this works, I'm pretty sure there are other improvements ( other magic tricks ) that can improve the score**","68625937":"**So, I used this failure dataset that has the majority of noise in the tweet dataset ( I downloaded this earlier and forgot where I got it from so if this belongs to you tell me so i can tag you here )**","b3f2bbb7":"**So the obvious conclusion is that we need to add a certain number n of previous characters to the selected_text**","2b3743ab":"**Rearrange the columns**","e696ced5":"# **Now for the main algorithm**","50b1cca6":"**Obviously here i'm gonna eliminate neutral tweets**","6b14a307":"**Adding these to your submission**","ec3827d1":"**I hope this helped some of you. If there are any improvements or any remarks please comment down below and don't forget to upvote it really helps me out a bunch**\n\n**Thank you all for your interest and time and I hope you have a great day !**","5977ecda":"**In here i visualize all the tweets to check them out one by one ( Yeah this took a lot of time :'( )**","ee63dd08":"**In here I merged the failures and the train in order to get the original text ( with the spaces )**","d55a680c":"# **Adding \u2728Magic\u2728 to your submission**","2af036af":"**Okay so this is how we discovered the magic**\n**So, I knew that there was something fishy in the data so I visualized all the tweets and selected_text in the train dataset and kept on reading them until I found some interesting things**","aacb5184":"**Btw, I know i haven't used the extra_right value, its because still don't know that part of magic. From my observations, I didn't get a stable pattern from this so I won't be using it here.**","1092f004":"**Hello guys, I hope you all had some nice kaggling and enjoyed this competition**\n\n**Best of luck for all other competitions and congratz to all of you  for having this wonderful journey**","a3100032":"**Stripping the selected_text ( as our model was always adding space in the beginning, this might not be the case for you)**","fcfb40e5":"**Creating a df_noise that contains (almost) all the ouputs that should have noise**","9c701689":"**This function gets all the extra spaces on the left of our selected_text**","985c19b1":"**Make sure to upvote the notebook if you found it useful, it really helps me out \ud83d\ude03**","aff02f39":"**And boom there you got it.. Spaces. I knew there was something fishy with spaces so I went back looking at the training set**","836e595b":"# **Failures analysis**","c1b01d25":"**This is an example tweet I took from the training**","c891d4b0":"**Some kind of shift is happening**","cdffa693":"**Wow O.O**","59cf119e":"**If you focus on the cases where the double space is before the selected_text, the selected_text gets the previous character allocated to it ( this also happens if we have a leading space )**","bd5d60b2":"# **Et voil\u00e0 \ud83e\udd29** ","18a107dd":"**So in here I'm gonan show you how I added this magic to my submission**","a6144ec6":"**Consider sub your submission**","8ace7993":"**Great! It works! It's just like the selected_text in the training set ( You can try this with many examples to understand it better )**","9f33fdd3":"**Interesting: 2134.. Which is a lot ( more than half )**","2adab7c8":"**This function gets all the extra spaces on the left of our selected_text**","9a2b6618":"# **Creating a function that gets this noise to our data**","d365b82f":"**Let's visualize this**","c7e79bd1":"# **Magic**","90f8bb1a":"**And now we create the new starting position**","96bdea2d":"**As for the real reason you're here for, which is the \u2728\u2728 M A G I C\u2728\u2728**\n\n**Well enjoy this quick demonstration of one part of the magic we discovered 1 days before the competition ends**","1accb6e9":"**That number n is the number of exceeding spaces before the selected_text**","bc9bed3f":"**So for example if we have:**\n\n**\" This \u200f\u200f\u200e \u200eis a test\"**\n\n**In here we have 1 exceeding space at the beginning + 1 exceeding space from the double space between \"This\" and \"is\"**\n\n**So, if the selected_text was = \"test\" it would now be \"a test\"**","6c04f8da":"# **\ud83d\ude80 Spaces Theory \ud83d\ude80**","e08e1f77":"**So, this is a  <span style=\"color:Red\">MAJOR <\/span> part of the magic. As i visualized the selected_text and text in this failures dataset I noticed that there are no \"spaces\"**","022ea4a3":"**The next code snippet just prints the whole train tweets and selected_text \ud83d\ude05\ud83d\ude05. I didn't run it here because it would slow down the notebook, you're free to remove the ( ''' ) at the beginning and end to run it**","e59e9c16":"**So, in all these different examples I didn't quite get anything except some very vague clues.**","e7cf62c5":"**Count the double spaces**","1b4e5989":"**Here's a trick you can do: Press CTRL + F to search for words and write \"  \" (that's a double space :p ) and then all the double spaces will be highlighted. Then, just scroll through the tweets above and see that double spaces are consistant**","c34870f0":"**Hmm 3641 failures, this should narrow it down**"}}