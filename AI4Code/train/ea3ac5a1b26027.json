{"cell_type":{"c231d29a":"code","b7235ae0":"code","ce61353e":"code","2f641690":"code","bec323a4":"code","dcd5950e":"code","55a04a7a":"code","68045c30":"code","d6922e0a":"code","227b7292":"code","3b2b5fb1":"code","df596e56":"code","8df1ffcc":"code","63f7433d":"code","13c7a691":"code","e11c97c1":"code","a3173b72":"code","fd96429e":"code","335193ec":"code","0ffe6f2c":"code","bf12cb2f":"code","2dd5b0aa":"code","9ab46293":"code","46d6d603":"code","3bc67c64":"code","90445d9f":"code","fb70fedc":"code","a78cfea0":"code","7e0e0d2e":"markdown","6d776854":"markdown","19412569":"markdown","1fce66f0":"markdown","82fb3638":"markdown","b73e16c4":"markdown","e59a1e1a":"markdown","2577e833":"markdown"},"source":{"c231d29a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n\n# Any results you write to the current directory are saved as output.","b7235ae0":"# Importing the libraries\n\ndata = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/trn.us.txt\")","ce61353e":"data.head()","2f641690":"traindata = data.loc[:,[\"Open\"]].values","bec323a4":"traindata.shape","dcd5950e":"# split into train and test sets\n\ntrain_size = int(len(traindata) * 0.9938)\ntest_size = len(traindata) - train_size\ntrain, test = traindata[0:train_size,:], traindata[train_size:len(traindata),:]\nprint(len(train), len(test))","55a04a7a":"train.shape","68045c30":"test.shape","d6922e0a":"# Feature Scaling\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range= (0,1))\ntrain_scaled =scaler.fit_transform(train)\ntrain_scaled","227b7292":"plt.plot(train_scaled)\nplt.show()","3b2b5fb1":"# Creating a data structure with 50 timesteps and 1 output\n\nX_train = []\ny_train = []\ntimesteps = 50\nprint(train_scaled[0, 0])\nfor i in range(timesteps, train.shape[0]):\n   \n    X_train.append(train_scaled[i-timesteps:i, 0])\n    y_train.append(train_scaled[i, 0])\n    \nX_train, y_train = np.array(X_train), np.array(y_train)","df596e56":"# Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_train.shape","8df1ffcc":"\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 250, batch_size = 32)","63f7433d":"# Getting the predicted stock price of 2017\ndataset_total = data['Open']\ninputs = dataset_total[len(dataset_total) - len(test) - timesteps:].values.reshape(-1,1)\ninputs\ninputs.shape","13c7a691":"# min max scaler\ninputs = scaler.transform(inputs)  \n","e11c97c1":"X_test = []\nfor i in range(timesteps, 70):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\n\nplt.plot(test, color = 'red', label = 'Real  Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted  Stock Price')\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel(' Stock Price')\nplt.legend()\nplt.show()\n","a3173b72":"data.columns","fd96429e":"dataset = data.iloc[:,1].values\nplt.plot(dataset)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Stock Price\")\nplt.title(\"Stock Market Dataset\")\nplt.show()","335193ec":"dataset = dataset.reshape(-1,1)\ndataset = dataset.astype(\"float32\")\ndataset.shape","0ffe6f2c":"# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","bf12cb2f":"train_size = int(len(dataset) * 0.50)\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","2dd5b0aa":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = np.array(dataX)\ntrainY = np.array(dataY)  ","9ab46293":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = np.array(dataX)\ntestY = np.array(dataY) ","46d6d603":"trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","3bc67c64":"\nimport matplotlib.pyplot as plt\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","90445d9f":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=250, batch_size=1)","fb70fedc":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","a78cfea0":"# shifting train\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset[:200]))\nplt.plot(trainPredictPlot[:200])\nplt.plot(testPredictPlot[:200])\nplt.show()","7e0e0d2e":"# Recurrent Neural Network with Keras","6d776854":"### Loading and Preprocessing Data","19412569":"### Create RNN Model","1fce66f0":"## Long Short Term Memory with Keras","82fb3638":"### Predictions and Visualising RNN Model","b73e16c4":"# LSTM","e59a1e1a":"### Create LSTM Model","2577e833":"### We will use the same data set"}}