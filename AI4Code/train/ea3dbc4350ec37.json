{"cell_type":{"702afd36":"code","ceb2e5c8":"code","611008b1":"code","cd9167c7":"code","ac440d2e":"code","f9f51bcf":"code","69232da6":"code","69f92dc6":"code","71bc8359":"code","a1c39612":"code","4a9e3c8e":"code","55be3958":"code","31256365":"code","206e8508":"code","43113937":"code","6e2ae55f":"code","5808e5ec":"code","ac780e0a":"code","4d7b63f1":"code","f996f151":"code","cb46d6e7":"code","389059cd":"code","93e55315":"code","39e4843c":"code","66ba9443":"code","6d0fd246":"markdown","cff44acf":"markdown","7d3466e3":"markdown","cce8891e":"markdown"},"source":{"702afd36":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display, Markdown\nimport matplotlib.cm as cm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport tensorflow as tf\nfrom time import perf_counter\nimport seaborn as sns\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))","ceb2e5c8":"image_dir = Path('..\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images')\n\n# Get filepaths and labels\nfilepaths = list(image_dir.glob(r'**\/*.png'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))","611008b1":"filepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\n# Concatenate filepaths and labels\nimage_df = pd.concat([filepaths, labels], axis=1)\n\n# Shuffle the DataFrame and reset index\nimage_df = image_df.sample(frac=1).reset_index(drop = True)\n\n# Show the result\nimage_df.head(3)","cd9167c7":"# Display some pictures of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=4, figsize=(10, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[i]))\n    ax.set_title(image_df.Label[i])\nplt.tight_layout()\nplt.show()","ac440d2e":"# Display the number of pictures of each category\nvc = image_df['Label'].value_counts()\nplt.figure(figsize=(9,5))\nsns.barplot(x = vc.index, y = vc, palette = \"rocket\")\nplt.title(\"Number of pictures of each category\", fontsize = 15)\nplt.show()","f9f51bcf":"def create_gen():\n    # Load the Images with a generator and Data Augmentation\n    train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n        validation_split=0.1\n    )\n\n    test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n    )\n\n    train_images = train_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=(224, 224),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=True,\n        seed=0,\n        subset='training',\n        rotation_range=30, # Uncomment to use data augmentation\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\"\n    )\n\n    val_images = train_generator.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=(224, 224),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=True,\n        seed=0,\n        subset='validation',\n        rotation_range=30, # Uncomment to use data augmentation\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\"\n    )\n\n    test_images = test_generator.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='Filepath',\n        y_col='Label',\n        target_size=(224, 224),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=False\n    )\n    \n    return train_generator,test_generator,train_images,val_images,test_images","69232da6":"def get_model(model):\n# Load the pretained model\n    kwargs =    {'input_shape':(224, 224, 3),\n                'include_top':False,\n                'weights':'imagenet',\n                'pooling':'avg'}\n    \n    pretrained_model = model(**kwargs)\n    pretrained_model.trainable = False\n    \n    inputs = pretrained_model.input\n\n    x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n\n    outputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    model.compile(\n        optimizer='adam',\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model","69f92dc6":"# Separate in train and test data\ntrain_df, test_df = train_test_split(image_df, train_size=0.9, shuffle=True, random_state=1)","71bc8359":"# Dictionary with the models\nmodels = {\n    \"DenseNet121\": {\"model\":tf.keras.applications.DenseNet121, \"perf\":0},\n    \"DenseNet169\": {\"model\":tf.keras.applications.DenseNet169, \"perf\":0},\n    \"InceptionResNetV2\": {\"model\":tf.keras.applications.InceptionResNetV2, \"perf\":0},\n    \"InceptionV3\": {\"model\":tf.keras.applications.InceptionV3, \"perf\":0},\n    \"MobileNet\": {\"model\":tf.keras.applications.MobileNet, \"perf\":0},\n    \"MobileNetV2\": {\"model\":tf.keras.applications.MobileNetV2, \"perf\":0},\n    \"ResNet101\": {\"model\":tf.keras.applications.ResNet101, \"perf\":0},\n    \"ResNet50\": {\"model\":tf.keras.applications.ResNet50, \"perf\":0},\n    \"VGG16\": {\"model\":tf.keras.applications.VGG16, \"perf\":0},\n    \"VGG19\": {\"model\":tf.keras.applications.VGG19, \"perf\":0}\n}\n\n# Create the generators\ntrain_generator,test_generator,train_images,val_images,test_images=create_gen()\nprint('\\n')\n\n# Fit the models\nfor name, model in models.items():\n    \n    # Get the model\n    m = get_model(model['model'])\n    models[name]['model'] = m\n    \n    start = perf_counter()\n    \n    # Fit the model\n    history = m.fit(train_images,validation_data=val_images,epochs=1,verbose=1)\n    \n    # Sav the duration, the train_accuracy and the val_accuracy\n    duration = perf_counter() - start\n    duration = round(duration,2)\n    models[name]['perf'] = duration\n    print(f\"{name:20} trained in {duration} sec\")\n    \n    val_acc = history.history['val_accuracy']\n    models[name]['val_acc'] = [round(v,4) for v in val_acc]\n    \n    train_acc = history.history['accuracy']\n    models[name]['train_accuracy'] = [round(v,4) for v in train_acc]","a1c39612":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    models_result.append([ name, \n                          models[name]['train_accuracy'][-1],\n                          models[name]['val_acc'][-1], \n                          models[name]['perf']])\n    \ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','train_accuracy','val_accuracy','Training time (sec)'])\ndf_results.sort_values(by='val_accuracy', ascending=False, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","4a9e3c8e":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'train_accuracy', data = df_results)\nplt.title('Accuracy on the Training Set (after 1 epoch)', fontsize = 15)\nplt.ylim(0,1)\nplt.xticks(rotation=90)\nplt.show()","55be3958":"# Load the pretained model\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","31256365":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(5, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy','AUC']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=10,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=2,\n            restore_best_weights=True\n        )\n    ]\n)","206e8508":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","43113937":"pd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()","6e2ae55f":"results = model.evaluate(test_images, verbose=0)","5808e5ec":"printmd(\" ## Test Loss: {:.5f}\".format(results[0]))\nprintmd(\"## Accuracy on the test set: {:.2f}%\".format(results[1] * 100))","ac780e0a":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","4d7b63f1":"from sklearn.metrics import classification_report\ny_test = list(test_df.Label)\nfrom sklearn import metrics\nprint('Accuracy:', np.round(metrics.accuracy_score(y_test, pred),5))\nprint('Precision:', np.round(metrics.precision_score(y_test, pred, average='weighted'),5))\nprint('Recall:', np.round(metrics.recall_score(y_test,pred, average='weighted'),5))\nprint('F1 Score:', np.round(metrics.f1_score(y_test, pred, average='weighted'),5))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, pred),5))\nprint(classification_report(y_test, pred))","f996f151":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (10,6))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","cb46d6e7":"# Map the labels to have only \"No_DR\" and \"DR\"\nimage_df_red = image_df.copy()\nimage_df_red['Label'] = image_df_red['Label'].apply(lambda x: x if x == 'No_DR' else 'DR')\nimage_df_red.head(5)","389059cd":"# Display the number of pictures of each category\nvc = image_df_red['Label'].value_counts()\nplt.figure(figsize=(9,5))\nsns.barplot(x = vc.index, y = vc, palette = \"rocket\")\nplt.title(\"Number of pictures of each category\", fontsize = 15)\nplt.show()","93e55315":"# Separate in train and test data\ntrain_df, test_df = train_test_split(image_df_red, train_size=0.9, shuffle=True, random_state=1)","39e4843c":"# Create the generators\ntrain_generator,test_generator,train_images,val_images,test_images=create_gen()\n\n# Load the pretained model\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False\n\n\ninputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy','AUC']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=10,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","66ba9443":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()\n\npd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()\n\nresults = model.evaluate(test_images, verbose=0)\n\nprintmd(\" ## Test Loss: {:.5f}\".format(results[0]))\nprintmd(\"## Accuracy on the test set: {:.2f}%\".format(results[1] * 100))\nprint('\\n')\n\n# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\nfrom sklearn.metrics import classification_report\ny_test = list(test_df.Label)\nfrom sklearn import metrics\nprint('Accuracy:', np.round(metrics.accuracy_score(y_test,pred),5))\nprint('Precision:', np.round(metrics.precision_score(y_test,pred, average='weighted'),5))\nprint('Recall:', np.round(metrics.recall_score(y_test,pred, average='weighted'),5))\nprint('F1 Score:', np.round(metrics.f1_score(y_test,pred, average='weighted'),5))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test,pred),5))\nprint(classification_report(y_test, pred))\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (10,6))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","6d0fd246":"# Load the Images with a generator<a class=\"anchor\" id=\"2\"><\/a>","cff44acf":"# MobileNetV2<a class=\"anchor\" id=\"4\"><\/a>","7d3466e3":"# Using a two-class model (DR and No_DR)<a class=\"anchor\" id=\"7\"><\/a>\n\nAs we have seen before, the prediction are very accurate to predict if someone has Diabetic Retinopathy or not. Nevertheless, it is not good at predicting the intensity of Diabetic Retinopathy when it is present. Maybe because it is subjective to the doctor to rate the intensity degree and different doctors don't have the same way to evaluate them. Maybe there are other factors taken in consideration to evaluate the intensity, which are independent from the pictures. As this point, without knowing more about the data, we can only speculate.\n\nIn this chapter, we'll reduce the label to a two-class model, because we can imagine that the most important part of this analysis is to find out if someone has Diabetic Retinopathy or not.","cce8891e":"# Visualization"}}