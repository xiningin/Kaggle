{"cell_type":{"ab899345":"code","c0028245":"code","69d773c9":"code","f0cca75d":"code","619f34da":"code","b5edffae":"code","5dc87697":"code","2b52d6b5":"code","93c91c0e":"code","8ab8163e":"code","973595aa":"code","694ed5a7":"code","bb13008e":"code","071cb712":"code","dce4190a":"code","db51197f":"code","18ec2c74":"code","5a4c9880":"code","aa186a43":"code","765efa3a":"code","352cde3a":"code","0bc9f25e":"code","2135907a":"code","d30ab112":"code","44634236":"code","263e6d9f":"code","ccab1823":"code","fed7a62b":"code","3398f3b3":"code","ed2060d9":"code","988c2493":"code","8437e238":"code","f83ff39e":"code","a689620a":"code","7a962c59":"code","1c9579b1":"code","a91e5563":"code","0658ca8d":"code","b5f257f7":"code","8045ae93":"code","b1241ae9":"code","d84ca125":"code","ee9ae846":"code","0a36b9db":"code","e0663f03":"code","d8c1e49f":"code","01773b1b":"code","ba5289c9":"code","e3bfc954":"code","b6002565":"code","fd529122":"code","942388de":"code","1c05fb20":"code","d997a7fb":"code","fb0d90b1":"code","fe7ebc2a":"code","ad656c42":"code","a4765abc":"code","430675af":"code","6802f814":"code","b63adef9":"code","8499d9f3":"code","6f2d59b0":"code","1a009eed":"code","97fa7662":"code","360ec87e":"code","1025f633":"code","61418cf3":"code","e4b58f17":"code","a5085cde":"code","79ed161e":"code","d95a42a9":"code","0a11f371":"code","97a52092":"code","38f2852b":"code","6d8f8979":"code","ea9e43e3":"code","5946a008":"code","22e8e158":"code","bb107ebc":"code","5676c671":"code","d4603326":"code","06060947":"code","bef518df":"code","b1ce99d4":"code","3c942caa":"code","455d32bc":"code","3f2c9337":"code","5bc79669":"code","ec40e48f":"code","e55bbef3":"code","947d8cf0":"code","f75b35a4":"code","382deaf1":"code","77ac8209":"code","33afcdcc":"code","d424ddfd":"code","887e9c20":"code","1cb4371b":"code","a5e56f7a":"code","a29f6dad":"code","aa52081c":"code","5b28590d":"markdown","ae4d4066":"markdown","bd9697ae":"markdown","554cf7e8":"markdown","8849d7e0":"markdown","f1d42510":"markdown","40cb31e9":"markdown","b07a10a2":"markdown","0e6aad5b":"markdown","a185fcc8":"markdown","97c9f681":"markdown","597df559":"markdown","c2c0ee27":"markdown","8f354d2f":"markdown","4cefb6de":"markdown","1690a189":"markdown","23cb1537":"markdown","88cb737d":"markdown","8b9ab7c9":"markdown","619cd4ab":"markdown","d5e150ac":"markdown","53c2cc1f":"markdown","7c90cf1f":"markdown","cebea6fc":"markdown","ef46eb26":"markdown","12244e41":"markdown","c6fbddbe":"markdown","9201c4c4":"markdown","a69a7ef7":"markdown","ad0e525a":"markdown","ca567de9":"markdown","10ba6f6d":"markdown","a94b729d":"markdown","0281166d":"markdown","dbfd8790":"markdown","40c8b5c2":"markdown","7ffc81a2":"markdown","b7db79c3":"markdown","1e4e10c9":"markdown","7f942410":"markdown","2b1fe8c0":"markdown","88e56ce9":"markdown","ed69ee2e":"markdown","19b68803":"markdown","5e7fd0ee":"markdown","002b273e":"markdown"},"source":{"ab899345":"# Get libraries\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as st\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nimport time\nfrom sklearn.cluster import KMeans","c0028245":"# Reading the data\ndf1 = pd.read_csv('..\/input\/bank-marketing-dataset\/bank.csv', sep=',')","69d773c9":"df1.head()","f0cca75d":"df1.tail()","619f34da":"print(df1.info(), '\\n')\nprint(df1.describe(), '\\n')\nprint('The shape of the data matrix: ', df1.shape)","b5edffae":"# Change dependent variable name 'deposit' to 'y'\ndf1 = df1.rename({'deposit':'y'}, axis=1)","5dc87697":"# Count the number of rows for each outcome\nprint(df1.groupby('y').size())","2b52d6b5":"# Define output labels and drop the 'y' column\ndf1['deposit'] = (df1['y'] == 'yes').astype('int')\ndf1.drop('y', axis=1, inplace=True)","93c91c0e":"# Calculating the ratio of positive respondents\nprint(sum(df1['deposit']) \/ len(df1['deposit']))","8ab8163e":"# Numeric features\ncols_num = ['age', 'balance', 'day', 'duration', 'campaign']\n#print(df1[cols_num].isnull().sum())\n\n# Categorical and binary features\ncols_cat = ['job', 'marital', 'education', 'contact', 'month', 'default', 'housing', 'loan']\n#print(df1[cols_cat].isnull().sum())","973595aa":"# Discover elements in categorical features\nfor feature in cols_cat:\n    print(df1.groupby(feature).size().sort_values(ascending=False), '\\n')","694ed5a7":"# One-Hot Encoding\ncols_new_cat = pd.get_dummies(df1[cols_cat], drop_first=False)\ncols_new_cat.head()\n\ndf2 = pd.concat([df1, cols_new_cat], axis=1)","bb13008e":"df2.head()","071cb712":"# Create a list for column names of the categorical data to keep track of them easily\ncols_all_cat = list(cols_new_cat.columns)","dce4190a":"# Create a df that has all features(categoricals are encoded) and the 'deposit'\ncols_input = cols_num + cols_all_cat\ndf_encoded = df2[cols_input + ['deposit']]","db51197f":"df_encoded.head()","18ec2c74":"# Independent variables and dependent variable split\nX = df_encoded.iloc[:, :-1]\ny = df_encoded.iloc[:, -1]","5a4c9880":"# Standardize the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)","aa186a43":"# Stratified CV  splits the data into k folds, making sure each fold is an appropriate\n# representative of the original data.\n# I tend to weight each instance equally (no term deposit vs. term deposit)\n\nskf = StratifiedKFold(n_splits=5, random_state=None)\n\n# skf.get_n_splits(X_scaled, y)\n# for train_index, test_index in skf.split(X_scaled, y):\n#    print('TRAIN:', train_index, 'TEST:', test_index)\n#    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n#    y_train, y_test = y[train_index], y[test_index]\n","765efa3a":"# Baseline models\nbaseline_model_dict = {}","352cde3a":"# K Nearest Neighbors (KNN)\nknn = KNeighborsClassifier()\nknn_results = cross_val_score(knn, X_scaled, y, cv=skf)\nprint(\"KNN Accuracy: %.2f%%\" % (knn_results.mean() * 100.0))\nbaseline_model_dict['KNN'] = knn_results.mean() * 100.0","0bc9f25e":"# Logistic Regression\nlr = LogisticRegression()\nlr_results = cross_val_score(lr, X_scaled, y, cv=skf)\nprint(\"LogReg Accuracy: %.2f%%\" % (lr_results.mean() * 100.0))\nbaseline_model_dict['LogReg'] = lr_results.mean() * 100.0","2135907a":"# Support Vector Classifier\nsvc = SVC()\nsvc_results = cross_val_score(svc, X_scaled, y, cv=skf)\nprint(\"SVC Accuracy: %.2f%%\" % (svc_results.mean() * 100.0))\nbaseline_model_dict['SVC'] = svc_results.mean() * 100.0","d30ab112":"# Naive Bayes\nnb = GaussianNB()\nnb_results = cross_val_score(nb, X_scaled, y, cv=skf)\nprint(\"NB Accuracy: %.2f%%\" % (nb_results.mean() * 100.0))\nbaseline_model_dict['NB'] = nb_results.mean() * 100.0","44634236":"# Decision Tree\ntree = DecisionTreeClassifier()\ntree_results = cross_val_score(tree, X_scaled, y, cv=skf)\nprint(\"Decision Tree Accuracy: %.2f%%\" % (tree_results.mean() * 100.0))\nbaseline_model_dict['Decision Tree'] = tree_results.mean() * 100.0","263e6d9f":"# Random Forest\nrf = RandomForestClassifier()\nrf_results = cross_val_score(rf, X_scaled, y, cv=skf)\nprint(\"Random Forest Accuracy: %.2f%%\" % (rf_results.mean() * 100.0))\nbaseline_model_dict['Random Forest'] = rf_results.mean() * 100.0","ccab1823":"# Gradient Boosting Classifier\ngbc = GradientBoostingClassifier()\ngbc_results = cross_val_score(gbc, X_scaled, y, cv=skf)\nprint(\"GBC Accuracy: %.2f%%\" % (gbc_results.mean() * 100.0))\nbaseline_model_dict['GBC'] = gbc_results.mean() * 100.0","fed7a62b":"# XGBoost Classifier\nxgb = XGBClassifier()\nxgb_results = cross_val_score(xgb, X_scaled, y, cv=skf)\nprint(\"XGB Accuracy: %.2f%%\" % (xgb_results.mean() * 100.0))\nbaseline_model_dict['XGB'] = xgb_results.mean() * 100.0","3398f3b3":"# Plot Baseline Model Accuracies\nkeys = baseline_model_dict.keys()\nvalues = baseline_model_dict.values()\n\nfig1, ax1 = plt.subplots()\nax1.bar(keys, values)\nax1.set_xlabel('Baseline Models')\nax1.set_ylabel('Accuracy(%)')\nax1.set_xticklabels(keys, rotation=70)\nplt.show()","ed2060d9":"tuned_model_dict = {}","988c2493":"# number of trees\nn_estimators = range(200, 1000, 200)\n\n# maximum number of features to use at each split\nmax_features = ['auto', 'sqrt']\n\n# maximum depth of the tree\nmax_depth = range(2, 20, 2)\n\n# criterion for evaluating a split\ncriterion = ['gini', 'entropy']\n\n# Random Grid\nrandom_grid_rf = {'n_estimators': n_estimators,\n                  'max_features': max_features,\n                  'max_depth': max_depth,\n                  'criterion': criterion}\n\nacc = make_scorer(accuracy_score)","8437e238":"rf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid_rf,\n                                scoring='accuracy', n_iter=100,\n                                cv=skf, verbose=1, random_state=42, n_jobs=-1)\n\nt1 = time.time()\nrf_random.fit(X_scaled, y)\nt2 = time.time()\nprint(t2-t1)\n\nprint(rf_random.best_params_)","f83ff39e":"# Tuned Random Forest\nrf_tuned = RandomForestClassifier(n_estimators=600, max_features='sqrt', max_depth=2, \n                                  criterion='entropy', random_state=42)\nrf_tuned_results = cross_val_score(rf_tuned, X_scaled, y, cv=skf)\nprint(\"Tuned Random Forest Accuracy: %.2f%%\" % (rf_tuned_results.mean() * 100.0))\ntuned_model_dict['Random Forest'] = rf_tuned_results.mean() * 100.0","a689620a":"# Get feature importances\ndef plot_feature_importance(importance,names,model_type):\n\n    #Create arrays from feature importance and feature names\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n    \n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n    \n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n    #Define size of bar plot\n    plt.figure(figsize=(10,8))\n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    #Add chart labels\n    plt.title(model_type + ' Feature Importance')\n    plt.xlabel('Feature Importance')\n    plt.ylabel('Feature Names')","7a962c59":"results_rf = rf_tuned.fit(X_scaled, y)\nplot_feature_importance(results_rf.feature_importances_,X_scaled.columns,'Tuned Random Forest')","1c9579b1":"# number of trees\nn_estimators = range(50, 200, 50)\n\n# maximum depth of the tree\nmax_depth = range(1, 5, 1)\n\n# learning rate\nlearning_rate = [0.001, 0.01, 0.1]\n\nrandom_grid_gbc = {'n_estimators': n_estimators,\n                  'max_depth': max_depth,\n                  'learning_rate': learning_rate}","a91e5563":"gbc = GradientBoostingClassifier()\ngbc_random = RandomizedSearchCV(estimator=gbc, param_distributions=random_grid_gbc, \n                                n_iter=20, cv=skf, scoring='accuracy')\nt1 = time.time()\ngbc_random.fit(X_scaled, y)\nt2 = time.time()\nprint(t2-t1)\n\nprint(gbc_random.best_params_)","0658ca8d":"# Tuned Gradient Boosting Classifier\ngbc_tuned = GradientBoostingClassifier(n_estimators=100, learning_rate=0.001,\n                                       max_depth=2, random_state=42)\ngbc_tuned_results = cross_val_score(gbc_tuned, X_scaled, y, cv=skf)\nprint(\"Tuned GBC Accuracy: %.2f%%\" % (gbc_tuned_results.mean() * 100.0))\ntuned_model_dict['GBC'] = gbc_tuned_results.mean() * 100.0","b5f257f7":"results_gbc = gbc_tuned.fit(X_scaled, y)\nplot_feature_importance(results_gbc.feature_importances_,X_scaled.columns,'Tuned  Gradient Boosting')","8045ae93":"# number of trees\nn_estimators = range(50, 200, 50)\n\n# maximum depth of the tree\nmax_depth = range(1, 5, 1)\n\n# learning rate\nlearning_rate = [0.001, 0.01, 0.1]\n\n# buraya comment yaz\u0131lacak\ncolsample_bytree = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n\n# gamma\ngamma = st.uniform(0, 10)\n\nrandom_grid_xgb = {'n_estimators': n_estimators,\n                  'max_depth': max_depth,\n                  'learning_rate': learning_rate,\n                  'colsample_bytree': colsample_bytree,\n                  'gamma': gamma}","b1241ae9":"xgb = XGBClassifier()\nxgb_random = RandomizedSearchCV(estimator=xgb, param_distributions=random_grid_xgb, \n                                n_iter=20, cv=skf, scoring='accuracy')\nt1 = time.time()\nxgb_random.fit(X_scaled, y)\nt2 = time.time()\nprint(t2-t1)\n\nprint(xgb_random.best_params_)","d84ca125":"# Tuned XGBoost Classifier\nxgb_tuned = XGBClassifier(objective= 'binary:logistic', n_estimators=150, max_depth=3,\n                         learning_rate=0.01, colsample_bytree=0.2, gamma=0.01)\nxgb_tuned_results = cross_val_score(xgb_tuned, X_scaled, y, cv=skf)\nprint(\"Tuned XGB Accuracy: %.2f%%\" % (xgb_tuned_results.mean() * 100.0))\ntuned_model_dict['XGB'] = xgb_tuned_results.mean() * 100.0","ee9ae846":"results_xgb = xgb_tuned.fit(X_scaled, y)\nplot_feature_importance(results_xgb.feature_importances_,X_scaled.columns,'Tuned XGBoost')","0a36b9db":"# Aggregate the results and compare to the baseline models\ndf_accuricies = pd.DataFrame([baseline_model_dict, tuned_model_dict], index=['Base','Tuned']).transpose()\n\nfig2, ax2= plt.subplots(1,1, figsize=(6,5))\n\ndf_accuricies.plot.bar(ax=ax2)\nax2.set_ylabel('Accuracy(%)')\nax2.set_xlabel('All Models')\nax2.set_xticklabels(baseline_model_dict.keys(), rotation=70)\n\nfig2.tight_layout()\nfig2.show()\n","e0663f03":"# Examine the numerical data distributions\n\ndf_main = df1.copy()\ndf_main.hist(bins=20, figsize=(14,10))\nplt.show()","d8c1e49f":"# Calculating the ratio of positive respondents \nprint(\"The ratio of outcome 'yes':\" ,sum(df_main['deposit']) \/ len(df_main['deposit']))\n\n# Calculating the ratio of negative respondents \nprint(\"The ratio of outcome 'no':\", 1 - sum(df_main['deposit']) \/ len(df_main['deposit']))","01773b1b":"# Create a pairplot in order to see pairwise distributions of data points\nsns.pairplot(df_main, hue='deposit')","ba5289c9":"# Categorize the customers by age\n\ndf_main.loc[df_main['age'] < 30, 'age_cat'] = 20\ndf_main.loc[(df_main['age'] >= 30) & (df_main['age'] < 40), 'age_cat'] = 30\ndf_main.loc[(df_main['age'] >= 40) & (df_main['age'] < 50), 'age_cat'] = 40\ndf_main.loc[(df_main['age'] >= 50) & (df_main['age'] < 60), 'age_cat'] = 50\ndf_main.loc[df_main['age'] >= 60, 'age_cat'] = 60\n\ndf_main['age_cat'] = df_main['age_cat'].astype(np.int64)","e3bfc954":"# How likely is each age category to suscribe to a term deposit\ntable_age_cat = pd.crosstab(df_main['deposit'], df_main['age_cat']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_age_cat","b6002565":"# Number of customers in each age category\nprint(df_main['age_cat'].value_counts())","fd529122":"# Countplot of Age Categories\nfig6, ax6 = plt.subplots()\nsns.countplot(x='age_cat', data=df_main)\nax6.set_title('Age Categories', fontsize=10)\nax6.set_xlabel('Age Categories')\nplt.show()","942388de":"# Deposits by Age Frequency Distributions (KDE Plot)\nfig7 = plt.figure(figsize=(12,4))\nax7 = sns.kdeplot(df_main.loc[(df_main['deposit'] == 0), 'age'], \n                  shade=True, label='Refused')\n\nax7 = sns.kdeplot(df_main.loc[(df_main['deposit'] == 1), 'age'], \n                  shade=True, label='Accepted')\n\nax7.set(xlabel='Age', ylabel='Frequency')\nplt.title('Deposits by Age')\nplt.show()","1c05fb20":"# How likely is each job category to suscribe to a term deposit\ntable_job_cat = pd.crosstab(df_main['deposit'], df_main['job']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_job_cat","d997a7fb":"# How likely is each job category to suscribe to a term deposit (plotted)\nstacked = table_job_cat.stack().reset_index().rename(columns={0:'value'})\n\nfig7 = plt.figure(figsize=(15,5),)\nax7 = sns.barplot(x=stacked['deposit'], y=stacked['value'], hue=stacked['job'], palette='Paired')","fb0d90b1":"# Number of customers in each job category\nprint(df_main['job'].value_counts())","fe7ebc2a":"# Number of customers in each job category (plotted)\nfig8, ax8 = plt.subplots(figsize=(16,4))\nsns.countplot(x='job', data=df_main, palette='Paired')\nax8.set_title('Job Categories', fontsize=10)\nax8.set_xlabel('Jobs')\nplt.show()","ad656c42":"# Age vs Occupation Box Plots\nax9 = plt.figure(figsize=(15,8))\nax9 = sns.boxplot(x='job', y='age', hue='deposit', data=df_main)\n\nax9.set_title('Age vs Occupation', fontsize=15)\nax9.set_xlabel('Jobs', fontsize=15)\nax9.set_ylabel('Age', fontsize=15)\nhandles, _ = ax9.get_legend_handles_labels()\nax9.legend(handles, [\"Refused\", \"Accepted\"])\nplt.show()","a4765abc":"# The percent of suscribed term deposits for different marital status\ntable_marital = pd.crosstab(df_main['deposit'], df_main['marital']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_marital","430675af":"# Number of customers for each marital status\nprint(df_main['marital'].value_counts())","6802f814":"# Countplot of each marital status for each outcome\nfig11, ax11 = plt.subplots(figsize=(12,8))\nax11 = sns.countplot(x=\"marital\", data=df_main, hue='deposit')\n\nax11.set_xlabel('Marital Status', fontsize=12)\nplt.legend(labels=['Refused', 'Accepted'])\nplt.show()","b63adef9":"# The percent of suscribed term deposits for different education levels\ntable_education = pd.crosstab(df_main['deposit'], df_main['education']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_education","8499d9f3":"# Number of customers for each education level info\nprint(df_main['education'].value_counts())","6f2d59b0":"# Countplot of each education levels for each outcome\nfig12, ax12 = plt.subplots(figsize=(12,8))\nax12 = sns.countplot(x=\"education\", data=df_main, hue='deposit')\n\nax12.set_xlabel('Education Levels', fontsize=12)\nplt.legend(labels=['Refused', 'Accepted'])\nplt.show()","1a009eed":"# Default - Term Deposit Ratio\ntable_default = pd.crosstab(df_main['deposit'], df_main['default']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_default","97fa7662":"# Number of customers for default info\nprint(df_main['default'].value_counts())","360ec87e":"# Countplot of each default info for each outcome\nfig13, ax13 = plt.subplots(figsize=(12,8))\nax13 = sns.countplot(x=\"default\", data=df_main, hue='deposit')\n\nax13.set_xlabel('Default Info', fontsize=12)\nplt.legend(labels=['Refused', 'Accepted'])\nplt.show()","1025f633":"# Categorize the customers by balance amount\n\ndf_main.loc[df_main['balance'] <= 0, 'balance_cat'] = 'no balance'\ndf_main.loc[(df_main['balance'] > 0) & (df_main['balance'] <= 1000), 'balance_cat'] = 'low balance'\ndf_main.loc[(df_main['balance'] > 1000) & (df_main['balance'] <= 5000), 'balance_cat'] = 'avg balance'\ndf_main.loc[df_main['balance'] >= 5000, 'balance_cat'] = 'high balance'\n\ndf_main['balance_cat'].value_counts()","61418cf3":"# Countplot of each balance category for each outcome\nfig10, ax10 = plt.subplots(figsize=(12,8))\nax10 = sns.countplot(x=\"balance_cat\", data=df_main, hue='deposit')\n\nax10.set_xlabel('Balance Categories', fontsize=12)\nplt.legend(labels=['Refused', 'Accepted'])\nplt.show()","e4b58f17":"# For different age groups, countplot of each balance category for each outcome\ng = sns.factorplot(x='balance_cat',\n                      hue='deposit', col='age_cat',\n                      data=df_main, kind='count', size=4)\n\ng.set_xticklabels(rotation=60)\ng.fig.set_size_inches(15,4)\ng.set(xlabel='Balance Category')\ntitles = ['Age 20s', 'Age 30s', 'Age 40s', 'Age 50s', 'Age 60s']\nfor ax, title in zip(g.axes.flat, titles):\n    ax.set_title(title)\nlabels = ['Refused', 'Accepted']\nfor t, l in zip(g._legend.texts, labels): t.set_text(l)\nplt.show()","a5085cde":"# The percent of suscribed term deposits for each housing loan status of customers\ntable_house = pd.crosstab(df_main['deposit'], df_main['housing']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_house","79ed161e":"# Number of customers for each housing info\nprint(df_main['housing'].value_counts())","d95a42a9":"# The percent of having mortgage in each balance category\ntable_house_balance = pd.crosstab(df_main[\"housing\"], df_main[\"balance_cat\"]).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_house_balance","0a11f371":"# The percent of suscribed term deposits for each personal loan status of customers\ntable_loan = pd.crosstab(df_main['deposit'], df_main['loan']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_loan","97a52092":"# Number of customers for each loan info\nprint(df_main['loan'].value_counts())","38f2852b":"# The percent of having personal loan in each balance category\ntable_loan_balance = pd.crosstab(df_main['loan'], df_main['balance_cat']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_loan_balance","6d8f8979":"# The percent of suscribed term deposits regarding different days of a month\ntable_day = pd.crosstab(df_main['deposit'], df_main['day']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_day","ea9e43e3":"# Number of customers depending last contact day of the month \nprint(df_main['day'].value_counts())","5946a008":"fig15, ax15 = plt.subplots(figsize=(16,8))\nax15 = sns.countplot(x=\"day\", data=df_main, hue='deposit')\n\nax15.set_xlabel('Last Contact Day', fontsize=12)\nplt.legend(labels=['Refused', 'Accepted'])\nplt.show()","22e8e158":"df_day = table_day.transpose()\ndf_day.sort_values(by=1, ascending=False)","bb107ebc":"# Create a column with the numeric values of the months\n\ndf_main.loc[df_main['month'] == 'jan', 'month_num'] = 1\ndf_main.loc[df_main['month'] == 'feb', 'month_num'] = 2\ndf_main.loc[df_main['month'] == 'mar', 'month_num'] = 3\ndf_main.loc[df_main['month'] == 'apr', 'month_num'] = 4\ndf_main.loc[df_main['month'] == 'may', 'month_num'] = 5\ndf_main.loc[df_main['month'] == 'jun', 'month_num'] = 6\ndf_main.loc[df_main['month'] == 'jul', 'month_num'] = 7\ndf_main.loc[df_main['month'] == 'aug', 'month_num'] = 8\ndf_main.loc[df_main['month'] == 'sep', 'month_num'] = 9\ndf_main.loc[df_main['month'] == 'oct', 'month_num'] = 10\ndf_main.loc[df_main['month'] == 'nov', 'month_num'] = 11\ndf_main.loc[df_main['month'] == 'dec', 'month_num'] = 12\n\ndf_main[\"month_num\"] = df_main[\"month_num\"].astype(np.int64)\n\n#df_main.head()","5676c671":"# Amount of suscribed vs non-suscribed term deposits accounts per month\nmonths_table = pd.crosstab(index=df_main['deposit'], columns=df_main['month_num'], margins=True)\nmonths_table","d4603326":"# The percent of suscribed term deposits per month\nmonths_table_pct = (months_table\/months_table.loc['All']) * 100\nmonths_table_pct.round(2)","06060947":"# Frequency of distribution of deposits by month\nfig4 = plt.figure(figsize=(15,8),)\nax4 = sns.kdeplot(df_main.loc[(df_main['deposit'] == 0),'month_num'], \n                  shade=True, label='Refused')\nax4 = sns.kdeplot(df_main.loc[(df_main['deposit'] == 1),'month_num'], \n                  shade=True, label='Accepted')\nax4.set(xlabel='Months of the Year', ylabel='Frequency')\nplt.title('Deposits by Month')\nplt.show()","bef518df":"# Convert duration to minutes of conversation\ndf_main['duration_min'] = df_main['duration'] \/ 60\ndf_main['duration_min'] = df_main['duration_min'].round(2)\ndf_main.head()","b1ce99d4":"# Deposits by Age Frequency Distributions (KDE Plot)\nfig16 = plt.figure(figsize=(12,4))\nax16 = sns.kdeplot(df_main.loc[(df_main['deposit'] == 0), 'duration_min'], \n                  shade=True, label='Refused')\n\nax16 = sns.kdeplot(df_main.loc[(df_main['deposit'] == 1), 'duration_min'], \n                  shade=True, label='Accepted')\n\nax16.set(xlabel='Duration', ylabel='Frequency')\nplt.title('Deposits by Duration')\nplt.show()","3c942caa":"campaign_pct = pd.crosstab(df_main['deposit'], df_main['campaign']).apply(lambda x: x\/x.sum() * 100).round(2)\n\n# Creates a table that indicates success rates of each campaigns\ncampaign_pct","455d32bc":"# How likely customers in each campaign to suscribe to a term deposit (plotted)\nstacked = campaign_pct.stack().reset_index().rename(columns={0:'value'})\n\nfig5 = plt.figure(figsize=(10,5),)\nax5 = sns.barplot(x=stacked['deposit'], y=stacked['value'], hue=stacked['campaign'])\nax5.get_legend().remove()","3f2c9337":"# The percent of suscribed term deposits for each contact types\ntable_contact = pd.crosstab(df_main['deposit'], df_main['contact']).apply(lambda x: x\/x.sum() * 100).round(2)\ntable_contact","5bc79669":"# Number of customers for each contact type\nprint(df_main['contact'].value_counts())","ec40e48f":"# Countplot of each contact types for each outcome\nfig14, ax14 = plt.subplots(figsize=(12,8))\nax14 = sns.countplot(x=\"contact\", data=df_main, hue='deposit')\n\nax14.set_xlabel('Contact Types', fontsize=12)\nplt.legend(labels=['Refused', 'Accepted'])\nplt.show()","e55bbef3":"corr = df_main.corr()\n\nplt.figure(figsize=(16,6))\nsns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=0.2, cbar=True)\nplt.title('Correlation Matrix', fontsize=16)\n#fig=plt.gcf()\n#fig.set_size_inches(18,15)\n#plt.xticks(fontsize=14)\n#plt.yticks(fontsize=14)\nplt.show()","947d8cf0":"# Eliminate columns that we don\u00b4t want to include in the analysis (all marketing campaign columns).","f75b35a4":"customer_cols = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan']\ndf_customer = df_main[customer_cols]\ndf_customer.head()","382deaf1":"# One-Hot Encoding\ndf_cluster = pd.get_dummies(df_customer)\ndf_cluster.head()","77ac8209":"# Standardize the data\nscaler = StandardScaler()\nX_cluster_scaled = scaler.fit_transform(df_cluster)\nX_cluster_scaled = pd.DataFrame(X_cluster_scaled, columns=df_cluster.columns)","33afcdcc":"X_cluster_scaled.head()","d424ddfd":"def plot_cluster(X, y, title=\"Cluster plot\"):\n    fig = X.plot.scatter(x='age', y='balance', color=y)\n    fig.layout.update(autosize=False, width=600, height=600,\n                  coloraxis = dict(showscale=False, colorscale='Portland'),\n                  font=dict(size=18),\n                  title=dict(text=title, x=0.5, y=0.95, xanchor='center'))\n    fig.update_traces(marker=dict(size=3))\n    return fig","887e9c20":"pd.options.plotting.backend = \"plotly\"","1cb4371b":"# Defining the kmeans function with initialization as k-means++\nmodel = KMeans(n_clusters=3, random_state=123, init='k-means++').fit(pd.get_dummies(df_customer))\npred = model.labels_\nfig = plot_cluster(df_customer, pred, title=\"Encoded Categorical Data\")\nfig","a5e56f7a":"# Inertia on the fitted data\nmodel.inertia_","a29f6dad":"# Fitting multiple k-means algorithms and storing the values in an empty list\nerrors = []\nfor cluster in range(1,20):\n    model = KMeans(n_jobs=-1, n_clusters=cluster, init='k-means++')\n    model.fit(pd.get_dummies(df_customer))\n    errors.append(model.inertia_)\n\n# converting the results into a dataframe and plotting them\nframe = pd.DataFrame({'Cluster':range(1,20), 'Errors':errors})\nplt.figure(figsize=(12,6))\nplt.plot(frame['Cluster'], frame['Errors'], marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()","aa52081c":"# Defining the kmeans function with optimal clusters\nmodel_optimum = KMeans(n_clusters=5, random_state=123, init='k-means++').fit(pd.get_dummies(df_customer))\npred = model_optimum.labels_\nfig = plot_cluster(df_customer, pred, title=\"Encoded Categorical Data\")\nfig","5b28590d":"# Exploratory Data Analysis","ae4d4066":"##### Notes:\n- Based from the graph above we know that the first campaigns are the most successfull with 8.59% success rate.\n- Notice rejection for offers increases after four calls that should be the threshold for the marketing team.\n- Obviously, the more the calls to a customer in a shorter period of time, the more irritated the customer will be and thus, a higher level of probability for the customer to refuse suscribing a term deposit.","bd9697ae":"#### Notes:\n- Most of the customers the bank targeted have 30-39 years old.\n- There are many customers in their 40s and 50s, but their deposit suscription is low.\n- The youngest and eldest population segments were the most likely to open a term deposit account with 10.88% and 18.02% respectively.\n","554cf7e8":"#### Notes:\n- There is a wide gap during the month of May between rejected and accepted term deposit suscriptions.\n- October(61.25%), March(48.45%) and April(%16.59) have high ratios meaning there were more accepted requests for term deposits suscriptions than rejected requests.","8849d7e0":"##### Notes:\n- For most of the variables our pair plot is overlapping a lot.\n- Pair plots of age-campaign and day-campaign are much efficient in distinguishing between different classes with very few overlapes.","f1d42510":"### Contact Variable","40cb31e9":"### Job Variable","b07a10a2":"# Bonuses\n\n## Exploratory Data Analysis","0e6aad5b":"##### Notes:\n- As we can see from the plot, 'accepted' clients and 'refused' clients are forming two relatively separate distributions. Compared to 'refused' clients, 'accepted' clients were contacted had longer call durations.","a185fcc8":"- First of all, the marketing team should try to engage customers and have longer calls. The correlation of the \u2018duration\u2019 variable with the target variable shows that the higher the duration, the more likely it is that the customer will subscribe to the term deposits.This makes intuitive sense because longer duration shows that the customer is interested in the product.\n\n- The cell phone seems to be the most suitable mode of communication (for this case).\n\n- I think, the customer's account balance has a high influence on the campaign's outcome. People who are in average or high balance categories are more likely to subscribe for term deposit. Therefore, future campaigns should concentrate on these customers.\n\n- The marketing team should target relatively old age customers who would be looking for safe and profitable investment options. In addition, they should consider to reach younger customers much more. This is because they may not have enough information about sophisticated investment products such as stoks and bonds. Therefore, they may respond positively even if the return will be small.\n\n- The call center should shift its marketing focus from blue-Collars, technicians to students and retired clients which is consistent with the previous finding of higher subscription rates among the younger and older.\n\n- The call center should resist calling a client for more than four times, which can be disturbing and increase dissatisfaction.\n\n- The timing is important. To improve the marketing campaign, the marketing managers should consider initiating the campaign at an end of a mounth or at an exact beginning of a mount when the subscription rate tends to be higher. \n\n- If a client has a long term loan such as a mortgage, it will be very difficult for her or him to subscribe a term deposit. Therefore, more attention should be given to customers who do not have mortgage in future campaigns.\n\n- There is no information about interest rates in this data set. I think it is most important factor when a customer subscribe to a term deposit. In fact, people are considering not only the interest rate but also the actual rate of return, especially in countries with high inflation like Turkey.(If we can know the exact date of the calls, short term treasury bill interest can be used as an indicator that can be a reference to the interest offered to the customers. It can be useful for prediction purposes.)","97c9f681":"##### Notes:\n- Apparently, having a house loan was a huge reason for not suscribing a term deposit.\n- People with no balance and low balance have a higher probability of having a house loan which in return will lead to customers that refused suscribing term deposits.","597df559":"##### Notes:\n- It is obvious that the customers has financial compromises to pay back its personal loan and thus, there is no cash for he or she to suscribe to a term deposit account.","c2c0ee27":"##### Notes:\n- Although the number of data for the first day of a month is small, the highest success rate(22.73%) belongs to this day. \n- 30th of a month has the second best figure with %15.37 success rate.\n- It is not surprising to see this results because salary payments are usually made at this time of a month.\n- The call center should consider to contact much more with customers on the first day of a month.","8f354d2f":"##### Notes:\n- Customers with cell-phone contact tend to be more likely to suscribe a term deposit than customers who use a telephone in their communication to the call center.","4cefb6de":"# Hyperparameter Tuning\n\nI am only going to optimize the hyper parameters for stochastic gradient descent, random forest, and gradient boosting classifiers. I will not optimize KNN because it took a while to train. I will not optimize logistic regression since it performs similarly to stochastic gradient descent. Similarly, I will not optimize decision trees since they tend to overfit and perform worse than random forests and gradient boosting classifiers.","1690a189":"##### Notes:\n- Customers with tertiary level education have the highest subscription rate with 9.18%.\n- It could be argued that as the level of education increases, people are more likely to invest in less risky assets like term deposit.\n- Moreover, it can be asserted that income level is directly proportional to the education of people especially in Europe. Therefore, people may subscribe more frequently to a term deposit with more income.","23cb1537":"### Balance Variable","88cb737d":"##### Notes:\n- I would expect much more spread between success rate of term deposit subscription depending on customer default info.(Success rate: default:'no' - 7.26%  vs. default:'yes' - 6.06%)\n- However, sample size of customers who has credit in detail inherently is very small. ","8b9ab7c9":"# Pre-processing","619cd4ab":"### Random Forest ","d5e150ac":"### Cluster Analysis","53c2cc1f":"### Month Variable","7c90cf1f":"### Default Variable","cebea6fc":"### Duration Variable","ef46eb26":"### Correlation Matrix","12244e41":"#### Notes:\n- Blue-Collars, people working in Management and Technicians received the most offers from the call-center to suscribe term deposits.\n- Students, entrepreneurs and unemployed peoples received the less amount of offers from the call-center.\n- Students and retires people have the highest subscription rate with 15.65% and 10.51% respectively. This result is consistent with the age variable outputs.\n- In the boxplot, the customers who belong to the retired category and refused to suscribe a term deposit are much younger than the customers who accepted to suscribe a term deposit.\n- In addition, the median age difference between self employed customers based on term deposit subscription is high. \n","c6fbddbe":"# Feature Engineering","9201c4c4":"##### Notes:\n- The marketing campaign targets excessively customers who has the low balance.\n- On the other hand, it targets fewer people who have an average balance and high balance.","a69a7ef7":"### Gradient Boosting Classifier(GBC)","ad0e525a":"##### Notes:\n- Duration of the call is the feature that most positively correlates with whether a potential client will open a term deposit or not.","ca567de9":"## Recommendations","10ba6f6d":"### XGBoost Classifier","a94b729d":"##### Notes:\n- Single and divorced customers tend to be more likely to suscribe a term deposit than married customers.\n- In other words, married customers are less likely to subscribe for term deposit.","0281166d":"# Stratified KFold\n\nWhen I split the data into folds, I want to make sure that each fold is a good representative of the whole data. In this dataset with underrepresentation of term deposit subscribers (7.24%), I have to enforce a correct distribution for each five fold.","dbfd8790":"### Age Variable","40c8b5c2":"### Loan Variable","7ffc81a2":"##### Notes:\n\n92.76% refused to suscribe to term deposits while 7.24% accepted to suscribe term deposits. ","b7db79c3":"# Model Selection","1e4e10c9":"### Marital Variable","7f942410":"### Day Variable","2b1fe8c0":"### Housing Variable","88e56ce9":"Looking at the results, we can see that the hyperparameter tuning improved the models. Random Forest and Gradient Boosting models are powerful algorithms which can be frequently used for this kind of classification problems. Tuned Random Forest and Tuned Gradient Boosting Classifier have both highest accurcy with 92.76%. Tuned Stochastic Gradient Descent Classifier is also very successful with 92.64% prediction accuracy.","ed69ee2e":"### Evaluation","19b68803":"### Education Variable","5e7fd0ee":" It can be concluded that 'Stochastic Gradient Descent' base model has the highest accuracy score with 92.47%.","002b273e":"### Campaign Variable"}}