{"cell_type":{"4da05778":"code","f8192b23":"code","0c8a54df":"code","52d11155":"code","be657f0b":"code","f66b8d16":"code","deb0cd75":"code","8c7b1c9a":"code","d073bd8d":"code","3a297bde":"code","250104b1":"code","b3ad00e3":"code","8b501afe":"code","d1ab1497":"code","15c924a1":"code","1bc2c61a":"code","e2381a47":"code","9046cba6":"code","ca74762d":"code","3f5b702f":"code","050848e3":"code","7c11490d":"code","52508410":"code","d9602a86":"code","2d0043df":"code","2d266dd8":"code","eb780682":"code","fa207987":"code","0adac5ad":"code","2ff4f6c3":"code","1831f0b9":"code","4416c7e4":"code","b2072693":"code","845c3412":"code","1ccf0c40":"code","a7936d73":"code","bca45f72":"code","484918a7":"code","36a87148":"code","94f34886":"code","c5b46383":"code","dd9027f0":"code","767113bb":"code","df1766d0":"code","d711fff7":"code","82a403ce":"code","162bd546":"code","896b1a93":"code","1d7c1967":"code","2944b2e8":"code","3b056ed8":"code","66f00144":"code","0f04257b":"code","72b81c31":"code","16bdf002":"code","65619c80":"code","2ef09fb4":"code","82407377":"code","15176970":"code","6ab453ab":"code","8757b131":"code","47041d09":"code","333f8b09":"code","429e0ff1":"code","e1bf4cb9":"code","76630033":"code","980b58e1":"code","6da5f4d4":"code","ccc92a51":"code","b02fcfaa":"code","ec1c80f5":"code","f22f4ef8":"code","d27182e1":"code","255c0bc8":"code","923aea90":"code","10c55a6b":"code","be2d8dd0":"code","517805ff":"markdown","25f09a96":"markdown","a2631073":"markdown","03c37c9e":"markdown","915efaf2":"markdown","5dbf2ada":"markdown"},"source":{"4da05778":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8192b23":"from warnings import filterwarnings\nfilterwarnings('ignore')","0c8a54df":"test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest_c  = test.copy()\ntrain_c = train.copy()","52d11155":"train_c.head()","be657f0b":"test_c.head()","f66b8d16":"new_corr = train_c.corr().abs()\nnew_corr['SalePrice'].sort_values(ascending=False)\n","deb0cd75":"top16_corr=new_corr['SalePrice'].sort_values(ascending=False)[:16].drop('SalePrice')\n# Top 16 most correlated feature. \ntop16_corr_names=top16_corr.index.values","8c7b1c9a":"top16_corr_names","d073bd8d":"#Check the correlation between features before multivariate outlier analysis\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.figure(figsize= (50,20))\nsns.heatmap(train_c.corr(),vmax=0.9, square=True, annot=True)","3a297bde":"# Before Log Transformation\n\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(train_c['SalePrice'], color=\"red\");\n\n\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice Distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\n\n# Skewness and Kurtosis\nprint(\"Skewness: %f\" % train_c['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % train_c['SalePrice'].kurt())","250104b1":"# After Log Transformation\n\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(np.log(train_c['SalePrice']), color=\"blue\");\n\n\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice Distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\n\n# Skewness and Kurtosis\nprint(\"Skewness: %f\" % np.log(train_c['SalePrice']).skew())\nprint(\"Kurtosis: %f\" % np.log(train_c['SalePrice']).kurt())","b3ad00e3":"# Most Correlated 16 Features Relationship SalesPrice\n\nn_rows = 4\nn_cols = 4\n\ncounter=0\nfig, axc = plt.subplots(n_rows,n_cols,figsize=(22,16))\nfor i in range(n_rows):\n    for j in range(n_cols):\n        if counter>=len(top16_corr_names):\n            break\n        name=top16_corr_names[counter]\n        axc[i][j].scatter(x = train_c[name], y = train_c['SalePrice'])\n        axc[i][j].set(xlabel=name, ylabel='SalePrice')\n\n        counter+=1\n\nplt.show()","8b501afe":"train_c.shape","d1ab1497":"#  Delete some Outliers that we have observed.\n\n\ntrain_c = train_c.drop(train_c[(train_c['GrLivArea']>4000) & (train_c['SalePrice']<300000)].index)","15c924a1":"train_c.shape","1bc2c61a":"train_c['train']  = 1\ntest_c['train']  = 0\ndf = pd.concat([train_c, test_c], axis=0,sort=False)","e2381a47":"df.head()","9046cba6":"import missingno as msno\n\nmsno.matrix(df); # Observation of Missing Value of Train Data","ca74762d":"def miss_value_detection(data):\n# Find missing values in the data\n    features=data.shape[0]\n    miss_values=data.isnull().sum()\n    \n    miss_values=miss_values[miss_values!=0].sort_values(ascending=False)\n\n    if miss_values.shape[0]==0:\n        print(\"There is no missing value in the data\")\n        print(miss_values)\n    else:\n        print(miss_values)","3f5b702f":"miss_value_detection(df)","050848e3":"#Percentage of NAN Values \nper_Nan = [(c, df[c].isna().mean()*100) for c in df]\nper_Nan = pd.DataFrame(per_Nan, columns=[\"column_name\", \"Percentage\"])","7c11490d":"# Detection of over %50 NaN value Features\nper_Nan = per_Nan[per_Nan.Percentage > 50]\nper_Nan.sort_values(\"Percentage\", ascending=False)","52508410":"#Drop PoolQC, MiscFeature, Alley and Fence features because there are too many missing value\ndf = df.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1)","d9602a86":"df.info()","2d0043df":"# Select object and numeric features\nobject_columns_df = df.select_dtypes(include=['object'])\nnumerical_columns_df =df.select_dtypes(exclude=['object'])","2d266dd8":"object_columns_df.shape","eb780682":"numerical_columns_df.shape","fa207987":"miss_value_detection(numerical_columns_df)","0adac5ad":"miss_value_detection(object_columns_df)","2ff4f6c3":"columns_None = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','FireplaceQu','GarageCond']\nobject_columns_df[columns_None]= object_columns_df[columns_None].fillna('None')","1831f0b9":"columns_with_lowNA = ['MSZoning','Utilities','Exterior1st','Exterior2nd','MasVnrType','Electrical','KitchenQual','Functional','SaleType']\n#fill missing values for each column (using its own most frequent value)\nobject_columns_df[columns_with_lowNA] = object_columns_df[columns_with_lowNA].fillna(object_columns_df.mode().iloc[0])","4416c7e4":"miss_value_detection(numerical_columns_df)","b2072693":"print((numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt']).median())\n","845c3412":"numerical_columns_df['GarageYrBlt'] = numerical_columns_df['GarageYrBlt'].fillna(numerical_columns_df['YrSold']-35)\nnumerical_columns_df[\"LotFrontage\"] = numerical_columns_df[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))","1ccf0c40":"numerical_columns_df= numerical_columns_df.fillna(0)","a7936d73":"object_columns_df['Utilities'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Utilities'].value_counts() ","bca45f72":"object_columns_df['Street'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Street'].value_counts() ","484918a7":"object_columns_df['Condition2'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Condition2'].value_counts() ","36a87148":"object_columns_df['RoofMatl'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['RoofMatl'].value_counts() ","94f34886":"object_columns_df['Heating'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Heating'].value_counts() #======> Drop feature one Type","c5b46383":"object_columns_df = object_columns_df.drop(['Heating','RoofMatl','Condition2','Street','Utilities'],axis=1)","dd9027f0":"# Manually calculate the Age_House feature using the YrSold and YearBuilt features\n# Age_House = YrSold - YearBuilt \nnumerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()","767113bb":"# Since the Age_House variable cannot be negative,\n# we questioned if there is a negative value and we detected 1 negative value.\nNegative = numerical_columns_df[numerical_columns_df['Age_House'] < 0]\nNegative","df1766d0":"# The process of correcting the negative output variable. 2009 new YrSold value\nnumerical_columns_df.loc[numerical_columns_df['YrSold'] < numerical_columns_df['YearBuilt'],'YrSold' ] = 2009\nnumerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()","d711fff7":"# TotalBsmtBath = BsmtFullBath + 0.5*BsmtHalfBath\n\n# TotalBath     = FullBath + 0.5*HalfBath\n\n# TotalSA       = TotalBsmtBath + 1stFlrSF + 2ndFlrSF \n\nnumerical_columns_df['TotalBsmtBath'] = numerical_columns_df['BsmtFullBath'] + numerical_columns_df['BsmtFullBath']*0.5\nnumerical_columns_df['TotalBath'] = numerical_columns_df['FullBath'] + numerical_columns_df['HalfBath']*0.5 \nnumerical_columns_df['TotalSA']=numerical_columns_df['TotalBsmtSF'] + numerical_columns_df['1stFlrSF'] + numerical_columns_df['2ndFlrSF']","82a403ce":"# Now the next step is to encode categorical features\n# Ordinal categories features - Mapping from 0 to N\n\nbin_map  = {'TA':2,'Gd':3, 'Fa':1,'Ex':4,'Po':1,'None':0,'Y':1,'N':0,'Reg':3,'IR1':2,'IR2':1,'IR3':0,\"None\" : 0,\n            \"No\" : 2, \"Mn\" : 2, \"Av\": 3,\"Gd\" : 4,\"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3,\"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6\n            }\nobject_columns_df['ExterQual'] = object_columns_df['ExterQual'].map(bin_map)\nobject_columns_df['ExterCond'] = object_columns_df['ExterCond'].map(bin_map)\nobject_columns_df['BsmtCond'] = object_columns_df['BsmtCond'].map(bin_map)\nobject_columns_df['BsmtQual'] = object_columns_df['BsmtQual'].map(bin_map)\nobject_columns_df['HeatingQC'] = object_columns_df['HeatingQC'].map(bin_map)\nobject_columns_df['KitchenQual'] = object_columns_df['KitchenQual'].map(bin_map)\nobject_columns_df['FireplaceQu'] = object_columns_df['FireplaceQu'].map(bin_map)\nobject_columns_df['GarageQual'] = object_columns_df['GarageQual'].map(bin_map)\nobject_columns_df['GarageCond'] = object_columns_df['GarageCond'].map(bin_map)\nobject_columns_df['CentralAir'] = object_columns_df['CentralAir'].map(bin_map)\nobject_columns_df['LotShape'] = object_columns_df['LotShape'].map(bin_map)\nobject_columns_df['BsmtExposure'] = object_columns_df['BsmtExposure'].map(bin_map)\nobject_columns_df['BsmtFinType1'] = object_columns_df['BsmtFinType1'].map(bin_map)\nobject_columns_df['BsmtFinType2'] = object_columns_df['BsmtFinType2'].map(bin_map)\n\nPavedDrive =   {\"N\" : 0, \"P\" : 1, \"Y\" : 2}\nobject_columns_df['PavedDrive'] = object_columns_df['PavedDrive'].map(PavedDrive)","162bd546":"#Select categorical features\nrest_object_columns = object_columns_df.select_dtypes(include=['object'])\n#Using One hot encoder\nobject_columns_df = pd.get_dummies(object_columns_df, columns=rest_object_columns.columns) ","896b1a93":"df_final = pd.concat([object_columns_df, numerical_columns_df], axis=1,sort=False)\ndf_final.head()","1d7c1967":"df_final = df_final.drop(['Id',],axis=1)\n\ndf_train = df_final[df_final['train'] == 1]\ndf_train = df_train.drop(['train',],axis=1)\n","2944b2e8":"df_test = df_final[df_final['train'] == 0]\ndf_test = df_test.drop(['SalePrice'],axis=1)\ndf_test = df_test.drop(['train',],axis=1)","3b056ed8":"df_train[\"SalePrice\"] = np.log1p(df_train[\"SalePrice\"])\ntarget= df_train['SalePrice']\ndf_train = df_train.drop(['SalePrice'],axis=1)","66f00144":"from xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nfrom sklearn.metrics import mean_squared_error","0f04257b":"X_train, X_test, y_train, y_test = train_test_split(df_train,target,test_size=0.2,random_state=0)","72b81c31":"# The parameters to be sent for the Grid Search CV were created in the form of a dictionary structure.\nxgb_grid = {\n     'colsample_bytree': [0.3,0.4], \n     'n_estimators':[2500,3000,3500],\n     'max_depth': [3,4],\n     'learning_rate': [0.01, 0.001],\n    'min_child_weight' :[1.8000],\n    'gamma' : [0.043],\n    'max_depth' : [3],\n    'reg_alpha' : [0.5]\n}","16bdf002":"xgb = XGBRegressor(booster = 'gbtree') \n# Creating the model object\n# booster = 'gbtree' parameter is set as none by default, so we set it manually!","65619c80":"xgb_cv = GridSearchCV(xgb, \n                      param_grid = xgb_grid, # model\n                      cv = 5, # To make a 10-fold CV\n                      n_jobs = -1,# Number of jobs to be run in parallel (-1: means to use all processors)\n                      verbose = 2) # Controls the level of detail: higher means more messages gets value as integer.","2ef09fb4":"xgb_cv.fit(X_train, y_train) # model fit process","82407377":"# The best parameter obtained as a result of CV process\n\nprint(\"The best parameters: \" + str(xgb_cv.best_params_))","15176970":"# Setting the Final Model with the best parameter\n\nxgb_cv_tuned = xgb_cv.best_estimator_\n\n# Fitting Final Model\nxgb_cv_tuned.fit(X_train, y_train)","6ab453ab":"# K-fold rmse\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = -cross_val_score(xgb_cv_tuned, X_test, y_test, cv=kf, scoring= \"neg_mean_squared_error\")\n\nprint(\"K-fold Cross Validation rmse Results: \",np.sqrt(cv_results_kfold))\nprint(\"K-fold Cross Validation rmse Results Mean: \",np.sqrt(cv_results_kfold).mean())","8757b131":"y_pred = xgb_cv_tuned.predict(X_test) ","47041d09":"# RMSE \nnp.sqrt(mean_squared_error(y_test, y_pred)) \n","333f8b09":"# R2 Score\nfrom sklearn import metrics\nmetrics.r2_score(y_test,y_pred)","429e0ff1":"# The parameters to be sent for the Grid Search CV were created in the form of a dictionary structure.\nlgbm_grid = {\n    'colsample_bytree': [0.3, 0.5,0.6],\n    'learning_rate': [0.02, 0.2,0.5],\n    'n_estimators': [200, 500,1000,1500],\n    'max_depth': [7,8],\n    'bagging_fraction' : [0.8],\n    'feature_fraction' : [0.2,0.25],\n    'min_data_in_leaf' : [6],\n    'min_sum_hessian_in_leaf' : [11],\n    'num_leaves' : [5,10],\n    'max_bin' : [55]}","e1bf4cb9":"lgbm = LGBMRegressor(objective='regression',feature_fraction_seed=9, bagging_seed=9)\n\n# Creating the model object","76630033":"lgbm_cv = GridSearchCV(lgbm, \n                      param_grid = lgbm_grid, # model\n                      cv = 5, # To make a 10-fold CV\n                      n_jobs = -1,# Number of jobs to be run in parallel (-1: means to use all processors)\n                      verbose = 2) # Controls the level of detail: higher means more messages gets value as integer.","980b58e1":"lgbm_cv.fit(X_train, y_train) # model fit process","6da5f4d4":"# The best parameter obtained as a result of CV process\n\nprint(\"The best parameters: \" + str(lgbm_cv.best_params_))","ccc92a51":"# Setting the Final Model with the best parameter\n\nlgbm_cv_tuned = lgbm_cv.best_estimator_\n\n# Fitting Final Model\nlgbm_cv_tuned.fit(X_train, y_train)","b02fcfaa":"# K-fold rmse\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf2 = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold2 = -cross_val_score(lgbm_cv_tuned, X_test, y_test, cv=kf2, scoring= \"neg_mean_squared_error\")\n\nprint(\"K-fold Cross Validation rmse Results: \",np.sqrt(cv_results_kfold2))\nprint(\"K-fold Cross Validation rmse Results Mean: \",np.sqrt(cv_results_kfold2).mean())","ec1c80f5":"y_pred2 = lgbm_cv_tuned.predict(X_test) ","f22f4ef8":"# RMSE \nnp.sqrt(mean_squared_error(y_test, y_pred2)) ","d27182e1":"# R2 Score\nfrom sklearn import metrics\nmetrics.r2_score(y_test,y_pred2)","255c0bc8":"y_pred3 = lgbm_cv_tuned.predict(df_test) ","923aea90":"y_pred4 = xgb_cv_tuned.predict(df_test) ","10c55a6b":"y_pred5 = np.round( (y_pred3*0.3 + y_pred4*0.7 ) )","be2d8dd0":"submision = pd.DataFrame()\nsubmision['Id'] = test_c['Id']\nsubmision['SalePrice'] = y_pred3\nsubmision.to_csv('submission.csv',index=False)","517805ff":"# Data Read and Copy","25f09a96":"# XGBO0ST","a2631073":"# MODELL\u0130NG","03c37c9e":"A brief explanation of each feature in the data set is as follows:\n\n* SalePrice - the selling price of the property in dollars. This is the target variable trying to guess.\n* MSSubClass: Construction class\n* MSZoning: General zoning classification\n* LotFrontage: Whether the property has a direct connection to the street\n* LotArea: Parcel size\n* Street: Type of road access\n* Alley: Street entrance type\n* LotShape: General shape of the property\n* LandContour: Flatness of the property\n* Utulities: Type of services available\n* LotConfig: Parcel configuration\n* LandSlope: The slope of the property\n* Neighborhood: Physical location within Ames city limits\n* Condition1: Close to main road or railway\n* Condition2: Proximity to main road or railway (if there is a second place)\n* BldgType: Residential type\n* HouseStyle: Housing style\n* OverallQual: Overall material and finish quality\n* OverallCond: General situation assessment\n* YearBuilt: Original production date\n* YearRemodAdd: Refactor date\n* RoofStyle: Roof type\n* RoofMatl: Roof material\n* Exterior1st: Exterior coating in the house\n* Exterior2nd: Exterior coating in the house (if there is more than one material)\n* MasVnrType: Wall covering type\n* MasVnrArea: Square footed wall covering area\n* ExterQual: Outside material quality\n* ExterCond: Current state of the material outside\n* Foundation: Foundation type\n* BsmtQual: Height of the basement\n* BsmtCond: General condition of the basement\n* BsmtExposure: Walk or garden floor basement walls\n* BsmtFinType1: Quality of basement finished area\n* BsmtFinSF1: Type 1 square meter of finished area\n* BsmtFinType2: Quality of the second finished space (if any)\n* BsmtFinSF2: Type 2 square meter of finished area\n* BsmtUnfSF: Square meter of unfinished area of the basement\n* TotalBsmtSF: Total square meter of basement area\n* Heating: Heating type\n* HeatingQC: Heating quality and condition\n* CentralAir: Central air conditioning\n* Electrical : Electrical system\n* 1stFlrSF: First Floor square meter area\n* 2ndFlrSF: Second floor square meter area\n* LowQualFinSF: Low quality finished areas (all floors)\n* GrLivArea: Above (floor) seating area square meter\n* BsmtFullBath: Full baths in the basement\n* BsmtHalfBath: Half baths in the basement\n* FullBath: Full bathrooms on upper floors\n* HalfBath: Half baths on upper floors\n* BedroomAbvGr: Number of bedrooms above basement level\n* KitchenAbvGr: Number of kitchens above basement level\n* KitchenQual: Kitchen quality\n* TotRmsAbvGrd: Total rooms on upper floors (no bathroom)\n* Functional: Home functionality assessment\n* Fireplaces: Fireplaces\n* FireplaceQu: Fireplace quality\n* Garage Type: Garage place\n* GarageYrBlt: Year of construction of the garage\n* GarageFinish: The interior of the garage\n* GarageCars: Vehicle capacity\n* GarageArea: The area of the garage\n* GarageQual: Garage quality\n* GarageCond: Garage status\n* PavedDrive: The road between the garage and the road\n* WoodDeckSF: Standing wooden deck area\n* OpenPorchSF: Open patio area in front of the door\n* EnclosedPorch: Closed patio area in front of the door\n* 3SsPorch: The three-season patio area\n* ScreenPorch: Patio cover area\n* PoolArea: Square meter area of the pool\n* PoolQC: Pool quality\n* Fence: Fence quality\n* MiscFeature: Features not available in other categories\n* MiscVal: The value of various properties\n* MoSold: Month of sale\n* YrSold: Year of sale\n* SaleType: Sale Type\n* SaleCondition: Sales Status","915efaf2":"# Light GBM","5dbf2ada":"# Information about the Data Set"}}