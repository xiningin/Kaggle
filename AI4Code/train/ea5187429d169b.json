{"cell_type":{"600f21a0":"code","4c582c1c":"code","19c51390":"code","4cb6b59d":"code","70cea9de":"code","4d8bea0e":"code","23e0d07e":"code","ae119ac7":"code","67adfe46":"code","7eedb644":"code","cdde3698":"code","c37db078":"code","cf99f9f5":"code","6bdb351e":"code","b5f9f5fb":"code","2bfcd8b2":"code","de737e05":"code","a3917c25":"code","fd757e44":"code","92b6b2bb":"code","4d904c03":"code","fcbb8c79":"code","a96c01e3":"code","aa7a9489":"code","e8e062b1":"code","69da6fa2":"code","a58b2bbe":"code","1beddc78":"code","cf93e900":"code","da46a390":"code","fdd1a4c5":"markdown","6a46d494":"markdown","c90d8eef":"markdown","d5aa161b":"markdown","5c8f5ce8":"markdown","a9617b32":"markdown","bee3748c":"markdown","565992eb":"markdown","bf7948ac":"markdown","5f64ecd6":"markdown","8bdb5f67":"markdown","637fcb41":"markdown","5d7b719e":"markdown"},"source":{"600f21a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport psutil\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom math import ceil\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import set_random_seed\nimport tensorflow as tf\nimport keras\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Flatten, Dense\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Input\nfrom keras import backend as K\n\nprint(os.listdir('\/kaggle\/input'))\nprint(os.listdir('\/kaggle\/input\/inceptionv3\/'))\n","4c582c1c":"SEED = 7\nnp.random.seed(SEED)\nset_random_seed(SEED)\ndir_path = \"\/kaggle\/input\/\"\nIMG_DIM = 299  # 224\nBATCH_SIZE = 8\nCHANNEL_SIZE = 3\nNUM_EPOCHS = 60\nTRAIN_DIR = 'train_images'\nTEST_DIR = 'test_images'\nFREEZE_LAYERS = 2  # freeze the first this many layers for training\nCLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}\nNUM_CLASSS = 5","19c51390":"ROOT_PATH = '\/kaggle\/input\/aptos2019-blindness-detection'\nTRAIN_PATH = '\/kaggle\/input\/aptos2019-blindness-detection\/' + TRAIN_DIR \nTEST_PATH = '\/kaggle\/input\/aptos2019-blindness-detection\/' + TEST_DIR \ndir_path = ROOT_PATH + '\/'","4cb6b59d":"# print names of train images\ntrain_img_names = glob.glob(TRAIN_PATH + '\/*.png')\n#print(train_img_names)\n\ndf_train = pd.read_csv(ROOT_PATH + '\/train.csv')\n#print(df_train)","70cea9de":"# print names of test images\ntest_img_names = glob.glob(TEST_PATH + '\/*.png')\n#print(test_img_names)\ndf_test = pd.read_csv(ROOT_PATH + '\/test.csv')\n#print(df_test)","4d8bea0e":"# Function to show one image\n\ndef draw_img(imgs, target_dir, class_label='0'):\n    for row in enumerate(imgs.iterrows()):\n        name = row[1][1]['id_code'] + '.png'\n        print(name)\n        plt.figure(figsize=(15,10))\n        img = plt.imread(dir_path + target_dir + '\/' + name)\n        plt.imshow(img)\n        plt.title(class_label)\n        plt.show()\n        del img\n        gc.collect","23e0d07e":"# Showing the class 0 image randomly\nCLASS_ID = 0\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])","ae119ac7":"# Showing the class 1 image randomly\nCLASS_ID = 1\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])","67adfe46":"# Showing the class 2 image randomly\nCLASS_ID = 2\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])","7eedb644":"# Showing the class 3 image randomly\nCLASS_ID = 3\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])","cdde3698":"# Showing the class 4 image randomly\nCLASS_ID = 4\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].sample(n=1), 'train_images', CLASSS[CLASS_ID])","c37db078":"gc.collect()","cf99f9f5":"# Split Dataset\n\nx_train, x_test, y_train, y_test = train_test_split(df_train.id_code, df_train.diagnosis, test_size=0.2,\n                                                    random_state=SEED, stratify=df_train.diagnosis)","6bdb351e":"input_tensor = Input(shape = (299, 299, 3))\n\n# create the base pre-trained model\nbase_model = InceptionV3(weights=None, include_top=False, input_tensor=input_tensor)\nbase_model.load_weights('\/kaggle\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n# add a global spatial average pooling layer\nx = base_model.output\noutput = BatchNormalization()(x)\nx = GlobalAveragePooling2D()(x)\n\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(NUM_CLASSS, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nfor layer in model.layers:\n    layer.trainable = True\n    \nprint(model.summary())","b5f9f5fb":"epochs = 25\nlrate = 0.01\ndecay = lrate\/epochs\nsgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","2bfcd8b2":"print(\"available RAM:\", psutil.virtual_memory())\ngc.collect()\nprint(\"available RAM:\", psutil.virtual_memory())\n\ndf_train.id_code = df_train.id_code.apply(lambda x: x + \".png\")\ndf_test.id_code = df_test.id_code.apply(lambda x: x + \".png\")\ndf_train['diagnosis'] = df_train['diagnosis'].astype('str')","de737e05":"# Data Generator\ntrain_datagen = image.ImageDataGenerator(rescale=1. \/ 255, validation_split=0.15, horizontal_flip=True,\n                                         vertical_flip=True, rotation_range=360, zoom_range=0.2, shear_range=0.1)","a3917c25":"train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory= TRAIN_PATH + '\/',\n                                                    x_col='id_code',\n                                                    y_col='diagnosis',\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode='categorical',\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='training',\n                                                    shaffle=True,\n                                                    seed=SEED\n                                                    )\nvalid_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory= TRAIN_PATH + '\/',\n                                                    x_col='id_code',\n                                                    y_col='diagnosis',\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode='categorical',\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='validation',\n                                                    shaffle=True,\n                                                    seed=SEED\n                                                    )\n#del x_train\n# # del x_test\n#del y_train\n# del y_test\ngc.collect()\n#  color_mode= \"grayscale\",","fd757e44":"NUB_TRAIN_STEPS = train_generator.n \/\/ train_generator.batch_size\nNUB_VALID_STEPS = valid_generator.n \/\/ valid_generator.batch_size\n\nNUB_TRAIN_STEPS, NUB_VALID_STEPS","92b6b2bb":"eraly_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n# Reducing the Learning Rate if result is not improving. \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n                              verbose=1)","4d904c03":"history = model.fit_generator(generator=train_generator,\n                                     steps_per_epoch=NUB_TRAIN_STEPS,\n                                     validation_data=valid_generator,\n                                     validation_steps=NUB_VALID_STEPS,\n                                     epochs=NUM_EPOCHS,\n                                     #                            shuffle=True,  \n                                     callbacks=[eraly_stop, reduce_lr],\n                                     verbose=1)\ngc.collect()","fcbb8c79":"# STEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\n(eval_loss, eval_accuracy) = tqdm(\n    model.evaluate_generator(generator=valid_generator, steps=NUB_VALID_STEPS, pickle_safe=False))\nprint(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\nprint(\"[INFO] Loss: {}\".format(eval_loss))","a96c01e3":"'''scores = model.evaluate(x_test, y_test, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))'''","aa7a9489":"accu = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(accu, label=\"Accuracy\")\nplt.plot(val_acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['Acc', 'val_acc'])\nplt.plot(np.argmax(history.history[\"val_acc\"]), np.max(history.history[\"val_acc\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","e8e062b1":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(history.history[\"loss\"], label=\"loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","69da6fa2":"test_datagen = image.ImageDataGenerator(rescale=1. \/ 255, validation_split=0.2, horizontal_flip=True)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n                                                  directory= TEST_PATH  + '\/',\n                                                  x_col=\"id_code\",\n                                                  target_size=(IMG_DIM, IMG_DIM),\n                                                  batch_size=1,\n                                                  shuffle=False,\n                                                  class_mode=None,\n                                                  seed=SEED)\n# del df_test\nprint(df_test.shape[0])\n# del train_datagen\n# del traabsin_generator\ngc.collect()","a58b2bbe":"# evaluating the model on test data\n\ntta_steps = 5\npreds_tta = []\nfor i in tqdm(range(tta_steps)):\n    test_generator.reset()\n    preds = model.predict_generator(generator=test_generator, steps=ceil(df_test.shape[0]))\n    #     print('Before ', preds.shape)\n    preds_tta.append(preds)\n#     print(i,  len(preds_tta))","1beddc78":"final_pred = np.mean(preds_tta, axis=0)\npredicted_class_indices = np.argmax(final_pred, axis=1)\nlen(predicted_class_indices)","cf93e900":"results = pd.DataFrame({\"id_code\": test_generator.filenames, \"diagnosis\": predicted_class_indices})\nresults.id_code = results.id_code.apply(lambda x: x[:-4])  # results.head()\nresults.to_csv(\"submission.csv\", index=False)","da46a390":"print(results)","fdd1a4c5":"**keras Callbacks:**\nDefining callback for EarlyStopping of training if the result is not significantly improving through some mentioned number of epochs. Defining callback for Reducnig learning rate on Platau regions of the underlying cost function.","6a46d494":"**Declaring the constansts**","c90d8eef":"**Split the train data into train and test(validation) set**","d5aa161b":"**Showing randomly chosen No-DR image one at a time** ","5c8f5ce8":"**Showing randomly chosen Proliferative DR image one at a time** ","a9617b32":"**Defining the inception network**","bee3748c":"**Loading the dataframes**","565992eb":"**Image Data Generator**: with Image Data Generator we can use Model.fit_generator() instead of Model.fit(). The 1st one exploits multiprocessing in python, while the 2nd one does not.","bf7948ac":"**Obervations:**\nThe differences between the classes are very minute and intricate in *some cases*, which is difficult to detect by human eyes. So to capture the intricacies we can consider using Inception Network as it combines the information from different scales of the image and the 1x1 convolution helps to detect the complex functions as well as it helps to reduce dimension. Let's see how it goes.... I have taken help from the following link for the inception module architecture:\nhttps:\/\/becominghuman.ai\/understanding-and-coding-inception-module-in-keras-eb56e9056b4b","5f64ecd6":"**Importing the required libraries**","8bdb5f67":"**Showing randomly chosen Mild DR image one at a time** ","637fcb41":"**Showing randomly chosen Severe DR image one at a time** ","5d7b719e":"**Showing randomly chosen Moderate DR image one at a time** "}}