{"cell_type":{"2b56deba":"code","be4b56b0":"code","66f622d7":"code","21b327ca":"code","df343cf6":"code","07e0222f":"code","1885e4db":"code","49b3ec22":"code","ae1ee6b0":"code","ae53b51c":"code","fabe6bd3":"code","620daf12":"code","3f43b310":"code","243b90b4":"code","c789d66f":"code","294bbfe4":"code","4f17452d":"code","5924f69c":"code","586e672d":"code","515516b3":"code","2d46758b":"markdown","527318c9":"markdown","d720f9d1":"markdown","fed65b39":"markdown","110469c9":"markdown","fbd08ca5":"markdown","3bbc0c01":"markdown","6a2ecdc2":"markdown","f355722a":"markdown","235a8a17":"markdown","2ba9d574":"markdown","3f30b1ce":"markdown","0e4468ee":"markdown","46f34cbb":"markdown","742fc1b8":"markdown","4fbc446d":"markdown","feb0a693":"markdown","a4e4a56d":"markdown"},"source":{"2b56deba":"import requests\npage = requests.get(\"http:\/\/dataquestio.github.io\/web-scraping-pages\/simple.html\")\npage","be4b56b0":"page.status_code","66f622d7":"page.content","21b327ca":"from bs4 import BeautifulSoup\nsoup = BeautifulSoup(page.content, 'html.parser')","df343cf6":"print(soup.prettify())","07e0222f":"soup = BeautifulSoup(page.content, 'html.parser')\nsoup.find_all('p')","1885e4db":"soup.find_all('p')[0].get_text()","49b3ec22":"page = requests.get(\"http:\/\/dataquestio.github.io\/web-scraping-pages\/ids_and_classes.html\")\nsoup = BeautifulSoup(page.content, 'html.parser')\nsoup","ae1ee6b0":"soup.find_all('p', class_='outer-text')","ae53b51c":"soup.find_all(class_=\"outer-text\")","fabe6bd3":"page = requests.get(\"http:\/\/forecast.weather.gov\/MapClick.php?lat=37.7772&lon=-122.4168\")\nsoup = BeautifulSoup(page.content, 'html.parser')\nseven_day = soup.find(id=\"seven-day-forecast\")\nforecast_items = seven_day.find_all(class_=\"tombstone-container\")\ntonight = forecast_items[0]\nprint(tonight.prettify())","620daf12":"period = tonight.find(class_=\"period-name\").get_text()\nshort_desc = tonight.find(class_=\"short-desc\").get_text()\n#temp = tonight.find(class_=\"temp\").get_text()\nprint(period)\nprint(short_desc)\n#print(temp)","3f43b310":"img = tonight.find(\"img\")\ndesc = img['title']\nprint(desc)","243b90b4":"#lets extract all info\nperiod_tags = seven_day.select(\".tombstone-container .period-name\")\nperiods = [pt.get_text() for pt in period_tags]\nperiods","c789d66f":"short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\ntemps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\ndescs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\nprint(short_descs)\nprint(temps)\nprint(descs)","294bbfe4":"import pandas as pd\nweather = pd.DataFrame({\n    \"period\": periods,\n    \"short_desc\": short_descs,\n    \"desc\":descs\n})\nweather","4f17452d":"temp_nums = weather[\"temp\"].str.extract(\"(?P<temp_num>d+)\", expand=False)\nweather[\"temp_num\"] = temp_nums.astype('int')\ntemp_nums","5924f69c":"weather[\"temp_num\"].mean()","586e672d":"is_night = weather[\"temp\"].str.contains(\"Low\")\nweather[\"is_night\"] = is_night\nis_night","515516b3":"weather[is_night]","2d46758b":"Let\u2019s try downloading a simple sample website, http:\/\/dataquestio.github.io\/web-scraping-pages\/simple.html. We\u2019ll need to first download it using the requests.get method.","527318c9":"We\u2019ll extract the name of the forecast item, the short description, and the temperature first, since they\u2019re all similar:","d720f9d1":"## lets get other fields too","fed65b39":"After running our request, we get a Response object. This object has a status_code property, which indicates if the page was downloaded successfully:","110469c9":"## Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. To illustrate this principle, we\u2019ll work with the following page:","fbd08ca5":"# lets build a weather dataset from webscraping","3bbc0c01":"A status_code of 200 means that the page downloaded successfully. ","6a2ecdc2":"# save our data into pandas dataframe","f355722a":"Now, we can extract the title attribute from the img tag. To do this, we just treat the BeautifulSoup object like a dictionary, and pass in the attribute we want as a key:","235a8a17":"# Lets build an webscraper and build dataset","2ba9d574":"## If we want to extract a single tag, we can instead use the find_all method, which will find all the instances of a tag on a page","3f30b1ce":"find div tag with the id seven-day-forecast\nThe div that contains the extended forecast items.\n-->>\nin summary:\nDownload the web page containing the forecast.\nCreate a BeautifulSoup class to parse the page.\nFind the div with id seven-day-forecast, and assign to seven_day\nInside seven_day, find each individual forecast item.\nExtract and print the first forecast item\n","0e4468ee":"Note that find_all returns a list, so we\u2019ll have to loop through, or use list indexing, it to extract text:","46f34cbb":"# We can print out the HTML content of the page using the content property:","742fc1b8":"## We can now do some analysis on the data. For example, we can use a regular expression and the Series.str.extract method to pull out the numeric temperature values:","4fbc446d":"We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object:","feb0a693":"We now know enough to proceed with extracting information about the local weather from the National Weather Service website. The first step is to find the page we want to scrape. page link: https:\/\/forecast.weather.gov\/MapClick.php?lat=37.7772&lon=-122.4168\n\n## We\u2019ll extract data about the extended forecast.","a4e4a56d":"## We  use the \"BeautifulSoup\" library to parse this document, and extract the text from the p tag. We first have to import the library, and create an instance of the BeautifulSoup class to parse our document:"}}