{"cell_type":{"475746b3":"code","cfe26c8e":"code","f1852517":"code","cdcc61ca":"code","0395f653":"code","baa9ce77":"code","c073b17a":"code","7d529a56":"code","2001d0bf":"code","975a9de3":"code","65707f62":"code","58f0cf54":"code","4f2a4a4c":"code","f485a0ce":"code","d1fdc118":"code","0bf3ab88":"code","cbdb4faa":"code","87459de8":"code","0b434a92":"code","59879d2d":"code","8694ad96":"code","90f0f438":"code","ebb1b453":"code","1a0fcba0":"code","9e239ec9":"code","e82038a2":"code","4bbc8947":"code","5d59dee7":"code","72c8b175":"code","91bf2e0c":"code","ce88a101":"code","613e3156":"code","dc472c6e":"markdown","30a57f3b":"markdown","dde6d720":"markdown","adf64b07":"markdown","60674dee":"markdown","21adc993":"markdown","c888fdd4":"markdown","6965507c":"markdown","d674671a":"markdown","206e2f45":"markdown","7daed57f":"markdown","34cbabda":"markdown"},"source":{"475746b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cfe26c8e":"# Directive pour afficher les graphiques dans Jupyter\n%matplotlib inline","f1852517":"# Pandas : librairie de manipulation de donn\u00e9es\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\n# SeaBorn : librairie de graphiques avanc\u00e9s\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","cdcc61ca":"# Lecture des donn\u00e9es d'apprentissage et de test\ndf = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")","0395f653":"df.head().T","baa9ce77":"df.columns","c073b17a":"from IPython.core.display import HTML # permet d'afficher du code html dans jupyter\ndisplay(HTML(df.head(20).to_html()))","7d529a56":"sns.pairplot(df, hue = \"Outcome\")","2001d0bf":"df.shape","975a9de3":"df.Outcome.value_counts()","65707f62":"df.describe()","58f0cf54":"data_train = df.sample(frac = 0.8, random_state = 1) # 80% des donn\u00e9es avec frac=0.8\ndata_test = df.drop(data_train.index)                # le reste des donn\u00e9es pour le test","4f2a4a4c":"X_train = data_train.drop(['Outcome'], axis=1)\ny_train = data_train['Outcome']\nX_test = data_test.drop(['Outcome'], axis=1)\ny_test = data_test['Outcome']","f485a0ce":"from sklearn import ensemble\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)\n\nrf_score = accuracy_score(y_test, y_rf)\nprint(rf_score)","d1fdc118":"pd.crosstab(y_test, y_rf, rownames=['Reel'], colnames=['Prediction'], margins=True)","0bf3ab88":"importances = rf.feature_importances_\nindices = np.argsort(importances)","cbdb4faa":"plt.figure(figsize=(12,8))\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), df.columns[indices])\nplt.title('Importance des caracteristiques')","87459de8":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nscore_arbres = accuracy_score(y_test, y_dtc)\nprint(score_arbres)","0b434a92":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","59879d2d":"dtc1 = tree.DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\ndtc1.fit(X_train,y_train)","8694ad96":"plt.figure(figsize=(30,30))\ntree.plot_tree(dtc1, feature_names=X_train.columns, class_names=['benin','malin'], fontsize=14, filled=True)  ","90f0f438":"y_dtc1 = dtc1.predict(X_test)\nprint(accuracy_score(y_test, y_dtc1))","ebb1b453":"pd.crosstab(y_test, y_dtc1, rownames=['Reel'], colnames=['Prediction'], margins=True)","1a0fcba0":"def replace_0(df,col) :\n    df1 = df.copy()\n    n = df.shape[0]\n    m = df[col].mean()\n    s = df[col].std()\n    for i in range(len(df.index)):\n        if df.loc[i,col] == 0 :\n            df1.loc[i,col] = np.random.normal(m, s);\n    return df1","9e239ec9":"lista = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\nfor column in lista :\n    df = replace_0(df, column)","e82038a2":"display(HTML(df.head(10).to_html()))","4bbc8947":"data_train = df.sample(frac = 0.8, random_state = 1) # 80% des donn\u00e9es avec frac=0.8\ndata_test = df.drop(data_train.index)                # le reste des donn\u00e9es pour le test","5d59dee7":"X_train = data_train.drop(['Outcome'], axis=1)\ny_train = data_train['Outcome']\nX_test = data_test.drop(['Outcome'], axis=1)\ny_test = data_test['Outcome']","72c8b175":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)\n\nnew_rf_score = accuracy_score(y_test, y_rf)\n","91bf2e0c":"print(rf_score)\nprint(new_rf_score)","ce88a101":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ny_dtc = dtc.predict(X_test)\nnew_score_arbres = accuracy_score(y_test, y_dtc)","613e3156":"print(score_arbres)\nprint(new_score_arbres)","dc472c6e":"On peut voir que pour les m\u00e9thodes la correction de data am\u00e9liorer (ou pas) le score +- 2%.","30a57f3b":"# Visualisation","dde6d720":"# Arbres de d\u00e9cision","adf64b07":"# Random Forests","60674dee":"***Score et matrice de confusion***","21adc993":"# Machine Learning","c888fdd4":"# Arbres de d\u00e9cision","6965507c":"Et la matrice de confusion :","d674671a":"imporance des caract\u00e9ristiques","206e2f45":"# Correction des donn\u00e9es","7daed57f":"# Analyse des donn\u00e9es","34cbabda":"# Random Forest"}}