{"cell_type":{"739b1ed1":"code","cd8695dd":"code","ea5a3e60":"code","4f1a486a":"code","fb53b630":"code","81ac2408":"code","7b903e6e":"code","edd0eaba":"code","17604916":"code","c3623de5":"code","2753c087":"code","f860961c":"code","696c31d6":"code","f96744fb":"code","b9e754d0":"code","ad3713b1":"code","424783f2":"markdown","bac33966":"markdown","fd2d1ba6":"markdown","1a36bcb8":"markdown","20815ea5":"markdown","a07a6ef1":"markdown","f4298458":"markdown","ef961c06":"markdown","0516955e":"markdown","6078cbff":"markdown","0639ffcd":"markdown","a8d7330a":"markdown","43c0fb5d":"markdown","6b3ac744":"markdown","a002cd1b":"markdown"},"source":{"739b1ed1":"#Numerical Manipulations\nimport numpy as np\nimport pandas as pd\n\n\n# Visualisation Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\n# Preprocessing Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# Model\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\n\n\nplt.rcParams['figure.figsize'] = 12,4","cd8695dd":"data = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndata.head()","ea5a3e60":"# Renaming the Columns\n\ndata.columns = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',\n       'death']","4f1a486a":"data.isnull().sum()","fb53b630":"x= data.iloc[:,:-1]\ny = data.iloc[:,-1]\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)","81ac2408":"feat_imp = pd.Series(model.feature_importances_, index= x.columns)\nfeat_imp.nlargest(12).plot(kind = 'barh')","7b903e6e":"# Ejection Fraction\n\nsns.boxplot(x = data.ejection_fraction, color='steelblue')\nplt.show()","edd0eaba":"data = data[data.ejection_fraction < 70].reset_index()","17604916":"# Outliers in Time\n\nsns.boxplot(x = data.time, color = 'steelblue')\nplt.show()","c3623de5":"# Outliers in Serum Creatinine\n\nfig = plt.figure()\nax = fig.add_subplot(3,1,1)\nsns.boxplot(x = data.serum_creatinine, color='steelblue',ax=ax) #general\nax = fig.add_subplot(3,1,2)\nsns.boxplot(x = data.serum_creatinine[data.sex == 1], color='steelblue', ax = ax) #male\nax = fig.add_subplot(3,1,3)\nsns.boxplot(x = data.serum_creatinine[data.sex == 0], color='steelblue', ax = ax) # female\n\nplt.show()","2753c087":"X = data.iloc[:,[5,8,12]].values \ny = data.iloc[:,-1].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)","f860961c":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","696c31d6":"# Defining the models to be fed in Voting Classifier\n\nlogreg = LogisticRegression()\nknn = KNeighborsClassifier(n_neighbors=6)\nsvc = SVC(C = 0.6, random_state=0, kernel='rbf')\ndectree = DecisionTreeClassifier(max_leaf_nodes= 3, random_state=0, criterion='entropy')\nrnd = RandomForestClassifier(n_estimators=11, criterion='entropy', random_state=0)","f96744fb":"vot_clf = VotingClassifier(\n    estimators= [\n        ('lr', logreg),\n        ('knn',knn),\n        ('svc',svc),\n        ('tree',dectree),\n        ('rnd',rnd)],\n    voting = 'hard'\n)\n\nvot_clf.fit(X_train,y_train)\ny_pred = vot_clf.predict(X_test)","b9e754d0":"print(f'Accuracy Score: {accuracy_score(y_test,y_pred) * 100} %')","ad3713b1":"cm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm\/np.sum(cm), annot=True, fmt = '.2%', cmap = 'ocean_r')","424783f2":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nNo Outliers spotted.\n<\/p>","bac33966":"<p style=\"text-align:justify;font-family:fantasy;font-size:25px\">\nStep 2: Loading the Dataset\n<\/p>","fd2d1ba6":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nNow, let us move to the code; Step-by-Step\n<\/p>","1a36bcb8":"<p style=\"text-align:justify;font-family:timesnewroman;font-size:30px\">Heart failure<\/p>\n\n\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:19px\">\nSometimes known as congestive heart failure \u2014 occurs when the heart muscle doesn't pump blood as well as it should. When this happens, blood often backs up and fluid can build up in the lungs, causing shortness of breath.<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:19px\">\nCertain heart conditions, such as narrowed arteries in the heart (coronary artery disease) or high blood pressure, gradually leave the heart too weak or stiff to fill and pump blood properly.<\/p>\n\n<p style=\"text-align:center;\"><img src=\"https:\/\/img.webmd.com\/dtmcms\/live\/webmd\/consumer_assets\/site_images\/articles\/health_tools\/rise_above_heart_failure_slideshow\/1800ss_getty_rf_heart.jpg?resize=650px:*\" alt=\"Heart-Failure\"><\/p>","20815ea5":"<p style=\"text-align:justify;font-family:fantasy;font-size:25px\">\nStep 4: Outlier Detection and Removal\n<\/p>","a07a6ef1":"<p style=\"text-align:justify;font-family:fantasy;font-size:19px\">\nWith the aid of Machine Learning, we will try to build a Voting Classifier to predict whether a person will get affected by a Heart Attack or not; given a few features regarding the same. \n<\/p>\n\n<p>\n    \n<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:19px\">\nLet us get to know a little theory about voting classifier then we will go Step by Step to implement the same.\n<\/p>\n","f4298458":"<p style=\"text-align:justify;font-family:fantasy;font-size:25px\">\nStep 5: Preparing & Training the Model\n<\/p>","ef961c06":"<p style=\"text-align:justify;font-family:fantasy;font-size:25px\">\nStep 1: Importing the Packages\n<\/p>","0516955e":"<p style=\"text-align:justify;font-family:fantasy;font-size:25px\">\nStep 3: Selecting the important Features\n<\/p>","6078cbff":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nWith this we can see that just conglomerating diffrent classifiers with no or very less fine-tuning; we are able to achieve <span><b> 95 % Accuracy<\/b><\/span>.\n<\/p>","0639ffcd":"<p style=\"text-align:justify;font-family:fantasy;font-size:25px\">\nWhat is Voting Classifier ?\n<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nA collection of several models working together on a single set is called an ensemble. The method is called Ensemble Learning. It is much more useful use all different models rather than any one.\n<p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nWhy ensembles?\n<li>Lower error\n<li>Less over-fitting\n<p>\n\n    \n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nVoting is one of the simplest way of combining the predictions from multiple machine learning algorithms. Voting classifier isn\u2019t an actual classifier but a wrapper for set of different ones that are trained and valuated in parallel in order to exploit the different peculiarities of each algorithm.\n<p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nThe final output on a prediction is taken by majority vote according to two different strategies :\n<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\n1. Hard voting \/ Majority voting : Hard voting is the simplest case of majority voting. In this case, the class that received the highest number of votes will be chosen. Here we predict the class label via majority voting of each classifier.\n<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\n2. Soft voting : In this case, the probability vector for each predicted class (for all classifiers) are summed up &averaged. The winning class is the one corresponding to the highest value (only recommended if the classifiers are well calibrated).\n<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nA voting classifier can be a good choice whenever a single strategy is not able to reach the desired accuracy threshold. In short voting classifier instead allows the mixing of different classifiers adopting a majority vote to decide which class must be considered as the winning one during a prediction.\n<\/p>","a8d7330a":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nWe can see the two outliers; and we will remove the same.\n<\/p>","43c0fb5d":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nThis indicates the general distribution which lies in the normal range of each gender; and the outliers infact indicated \"Death\".\n<\/p>\n\n<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nHence, removal of these outliers won't be of any use.\n<\/p>\n","6b3ac744":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\nWe can see that Serum Creatinine, Ejection Fraction and Time seem to be the most important feature to determine the death; so we will be training the model on the same.\n<\/p>","a002cd1b":"<p style=\"text-align:justify;font-family:fantasy;font-size:17px\">\n<b>If you liked the work, make sure to Upvote the Notebook and do Comment your feedback or any suggestions. <\/b>\n<\/p>"}}