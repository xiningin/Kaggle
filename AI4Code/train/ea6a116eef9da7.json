{"cell_type":{"ac4fa92c":"code","fa31ba89":"code","20a74e5f":"code","949aa75e":"code","7916be82":"code","4b27471a":"code","0f5c9375":"code","bd4e0a25":"code","c4420c2a":"code","d9320938":"code","4be62e2b":"code","7a3b2849":"code","19ca2e16":"code","d928ef80":"code","0868540c":"code","39ba614b":"code","a7d680a1":"code","ed455441":"code","1e53b78a":"code","e16844b5":"code","cd309893":"code","167873e2":"code","2f33163b":"code","a6b3a637":"code","54ef8be6":"code","c4f02381":"code","ee80cc81":"code","9e07c22c":"code","5bcd2198":"markdown"},"source":{"ac4fa92c":"pip install feature_engine","fa31ba89":"!pip install pytorch-tabnet","20a74e5f":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc, random, time\n# import cudf\nimport pandas as pd\nimport numpy as np\n# import cupy as cp\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve, log_loss\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss, MSELoss\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\n\nfrom pytorch_tabnet.tab_model import TabNetClassifier","949aa75e":"# function to process data\nfrom sklearn.metrics import confusion_matrix, make_scorer, f1_score\nfrom scipy.optimize import differential_evolution\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn import metrics\nfrom feature_engine.encoding import MeanEncoder, RareLabelEncoder, CountFrequencyEncoder, OneHotEncoder\nfrom feature_engine.selection import DropFeatures\nfrom feature_engine.imputation import AddMissingIndicator\nfrom feature_engine.imputation import ArbitraryNumberImputer, MeanMedianImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.mixture import GaussianMixture","7916be82":"import os\n\nimport optuna\nfrom optuna.trial import TrialState\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport random","4b27471a":"KAGGLE_FLAG = True\nSEED = 945\nNUM_FOLDS = 5 #10\nNUM_REPEATS = 10 #5","0f5c9375":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n    \n    \nseed_everything(seed=SEED)","bd4e0a25":"train_input_path = ('..\/input\/porto-seguro-data-challenge\/train.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/train.csv')\ntest_input_path = ('..\/input\/porto-seguro-data-challenge\/test.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/test.csv')\nsubmission_input_path = ('\/kaggle\/input\/porto-seguro-data-challenge\/submission_sample.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/submission_sample.csv')\nmetadata_input_path = ('\/kaggle\/input\/porto-seguro-data-challenge\/metadata.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/metadata.csv')","c4420c2a":"train = pd.read_csv(train_input_path, na_values = -999).drop(['id'], axis=1)\ntest = pd.read_csv(test_input_path, na_values = -999).drop(['id'], axis=1)\nsubmission = pd.read_csv(submission_input_path)\nmetadata = pd.read_csv(metadata_input_path)","d9320938":"cat_nom = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Qualitativo nominal\")].iloc[:,0]]\ncat_ord = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Qualitativo ordinal\")].iloc[:,0]]\nnum_dis = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Quantitativo discreto\")].iloc[:,0]]\nnum_con = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Quantitativo continua\")].iloc[:,0]]\n\ncat_cols = cat_nom+cat_ord\nnum_cols = num_dis+num_con","4be62e2b":"def preprocess(df):\n    \n    df = df.replace(-999, np.nan)\n    df = df.fillna(df.mean())\n    \n    return df\n\ndef preprocess_cat(df):\n    \n    df = df.replace(-999, np.nan)\n    df = df.fillna(df.mode().iloc[0])\n    \n    return df # df = df.fillna(df.mode().iloc[0])\n\ndef preprocess_num(df):\n    \n    df = df.replace(-999, np.nan)\n    df = df.fillna(0)\n    \n    return df\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler = MinMaxScaler()\nscaler1 = MinMaxScaler()","7a3b2849":"meta = pd.read_csv(metadata_input_path)\ncat_var = [ 'var1', 'var2', 'var7', 'var8', 'var9', 'var10', 'var14', 'var15',\n       'var16', 'var17', 'var18', 'var20', 'var22', 'var23', 'var28', 'var29',\n       'var30',  'var33', 'var34', 'var37', 'var39',\n       'var41', 'var5', 'var6', 'var11', 'var57']\ncat_ord = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==\"Qualitativo ordinal\")].iloc[:,0]]\ncat_var.extend(cat_ord)\n\nnum_dis = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==\"Quantitativo discreto\")].iloc[:,0]]\nnum_con = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==\"Quantitativo continua\")].iloc[:,0]]\n\nnum_cols = num_dis + num_con\nto_drop = ['var65', 'var66', 'var19', 'var31', 'var36', 'var68', 'var38']\n           \naddBinary_imputer = AddMissingIndicator()\nmedian_Imputer = MeanMedianImputer(imputation_method='median', variables = num_cols)\narbitrary_imputer = ArbitraryNumberImputer(arbitrary_number=-999)\narbitrary_imputer_zero = ArbitraryNumberImputer(arbitrary_number=0.22)\nrare_encoder = RareLabelEncoder(tol=0.02, n_categories=2, variables=cat_var,\n                           replace_with=-999, ignore_format = True)\nmean_encoder = MeanEncoder(variables=cat_var, ignore_format = True)\ndrop_Features = DropFeatures(features_to_drop = to_drop)\n\n\npipe1 = Pipeline([('indicator', addBinary_imputer),\n                  ('median_imputer', median_Imputer),\n                  ('ReplaceNa', arbitrary_imputer),\n                  ('RareLabelEncoder1', rare_encoder),\n                  ('MeanEncoder', mean_encoder),\n                  ('arbitrary_imputer_zero', arbitrary_imputer_zero),\n                 ('dropFeatures', drop_Features)])","19ca2e16":"X = train[cat_nom+cat_ord+num_dis+num_con]\ny = train.y\nX_test = test[cat_nom+cat_ord+num_dis+num_con]\ntarget = y","d928ef80":"X = pipe1.fit_transform(X, y)\nX_test = pipe1.transform(X_test)","0868540c":"# num_cols = list(set(num_cols) - set(to_drop))\n# cat_cols = list(set(cat_cols) - set(to_drop))\n\n# num_cols = sorted(num_cols)\n# cat_cols = sorted(cat_cols)\n\n# columns = num_cols + cat_cols","39ba614b":"DEVICE = torch.device(\"cpu\")\nBATCHSIZE = 4096\nCLASSES = 1\nDIR = os.getcwd()\nEPOCHS = 20\nLOG_INTERVAL = 10\nN_TRAIN_EXAMPLES = BATCHSIZE * 30\nN_VALID_EXAMPLES = BATCHSIZE * 10","a7d680a1":"# fun\u00e7\u00f5es criadas para resolver o problema do neg\u00f3cio\n\ndef optimal_cutoff(y_target, y_predict_prob, only_fun = True, random_state = 1997):\n    \n    optimization = differential_evolution(lambda c: (-f1_score(y_target, (y_predict_prob > c[0]))),\n                                          [(0, 0.5)], tol = 0.00001, seed = random_state, popsize=3)\n    if only_fun == False:\n        return -optimization['fun'], optimization['x']\n    else:\n        return 'f1score', -optimization['fun'], True\n        ","ed455441":"rkf = RepeatedStratifiedKFold(n_splits=NUM_FOLDS, n_repeats=NUM_REPEATS, random_state=SEED)\nkf = StratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)","1e53b78a":"def cross_valid(model, train, target, test, num_folds=10, random_state=42):\n\n    train_oof = np.zeros((len(train)))\n    test_preds = 0\n\n    scores=[]\n    cut = []\n    models=[]\n    \n    for f, (train_ind, val_ind) in tqdm(enumerate(rkf.split(train, target))):\n        \n        model = TabNetClassifier(**tabnet_params)\n\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        \n        train_target, val_target = target[train_ind], target[val_ind]\n        \n        \n        model.fit(train_df.values, \n            train_target.values,\n                  num_workers=0,\n        )\n\n        temp_oof = pd.Series(model.predict_proba(val_df.values)[:, -1], index=val_df.index)\n        \n        business_metric_opt, cutoff = optimal_cutoff(val_target, temp_oof, only_fun= False)\n        cut.append(cutoff[0])        \n        \n        temp_oof  = (temp_oof > cutoff[0]).astype(int)\n        train_oof[val_ind] = temp_oof \n\n        temp_test = model.predict_proba(test[columns].values)[:, -1]\n        temp_test = (temp_test > cutoff[0]).astype(int)\n\n        test_preds += (temp_test\/(NUM_FOLDS*NUM_REPEATS))\n\n        scores.append(f1_score(val_target, temp_oof))\n\n        print(f'Fold {f}: {f1_score(val_target, temp_oof)}')\n        print(f'Best f1 score: {business_metric_opt} ----  cutoff: {cutoff[0]}')\n        models.append(model)\n\n        \n        \n    print(f\"Mean F1 Score: {np.mean(scores)}, std: {np.std(scores)}\")\n    print(f'F1 Score OOF: {f1_score(y, train_oof)}')\n    \n    return train_oof, (test_preds >= 0.5).astype(int), np.mean(scores), models, cut","e16844b5":"#Trial 11 finished with value: 0.8532423208191127 and parameters: {'n_d': 62, 'n_a': 63, 'n_steps': 3, 'gamma': 1.2753699667141867, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.0867816854156831}. Best is trial 11 with value: 0.8532423208191127.\n\ntabnet_params = {\n    #'n_d': 62, 'n_a': 63, 'n_steps': 3, 'gamma': 1.2753699667141867, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.0867816854156831,\n    # 'n_d': 40, 'n_a': 21, 'n_steps': 3, 'gamma': 1.7793171767710656, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.010862973994067937,\n    #'n_d': 26, 'n_a': 54, 'n_steps': 3, 'gamma': 1.9628330029277388, 'n_independent': 3, 'n_shared': 2, 'momentum': 0.016624888955875106,\n    # 'n_d': 43, 'n_a': 61, 'n_steps': 10, 'gamma': 1.0547277888825082, 'n_independent': 2, 'n_shared': 2, 'momentum': 0.3959018835824779,\n    #'n_d': 19, 'n_a': 8, 'n_steps': 4, 'gamma': 1.0033425193233454, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.3955973019705906,\n    'n_d': 19, 'n_a': 8, 'n_steps': 4, 'gamma': 1.0033425193233454, 'n_independent': 1, 'n_shared': 1, 'momentum': 0.3955973019705906,\n    'seed' : SEED,\n}\n\ncolumns = X_test.columns\n\nclf = None\n\ntrain_oof_1, test_preds_1, score_oof_1, models, cut = cross_valid(clf, X, y, X_test, num_folds=NUM_FOLDS, random_state=SEED)","cd309893":"print(f'CV: {f1_score(y, train_oof_1)}')","167873e2":"# def cross_valid(train, target, test, num_folds=10, random_state=42):\n\n#     train_oof = np.zeros((len(train)))\n#     test_preds = 0\n\n#     kf = StratifiedKFold(n_splits=num_folds, random_state=SEED, shuffle=True)\n#     scores=[]\n#     cut = []\n\n#     for f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n\n#         train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n\n#         train_target, val_target = target[train_ind], target[val_ind]\n\n        \n#         train_df = pipe1.fit_transform(train_df, train_target)\n#         val_df = pipe1.transform(val_df)\n#         x_test = pipe1.transform(test[columns])\n\n#         temp_oof = pd.Series(models[f].predict_proba(val_df.values)[:, -1], index=val_df.index)\n\n#         business_metric_opt, cutoff = optimal_cutoff(val_target, temp_oof, only_fun= False)\n        \n#         temp_oof  = (temp_oof > cutoff[0]).astype(int)\n#         print(f'Fold {f}: {f1_score(val_target, temp_oof)}, cutoof {cutoff[0]}')\n        \n        \n        \n#         temp_test = models[f].predict_proba(x_test.values)[:, -1]\n#         temp_test = (temp_test > cutoff[0]).astype(int)\n\n#         test_preds += (temp_test\/NUM_FOLDS)\n        \n#         print(temp_test)\n#         print(test_preds)\n#     return test_preds","2f33163b":"# columns = columns\n\n\n# #Trial 11 finished with value: 0.8532423208191127 and parameters: {'n_d': 62, 'n_a': 63, 'n_steps': 3, 'gamma': 1.2753699667141867, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.0867816854156831}. Best is trial 11 with value: 0.8532423208191127.\n\n# tabnet_params = {\n#     'n_d': 62, 'n_a': 63, 'n_steps': 3, 'gamma': 1.2753699667141867, 'n_independent': 1, 'n_shared': 5, 'momentum': 0.0867816854156831,\n#     'seed' : SEED,\n# }\n\n# clf = None#TabNetClassifier(**tabnet_params)\n\n# test_preds = cross_valid(X, y, X_test, num_folds=NUM_FOLDS, random_state=SEED)","a6b3a637":"# Mean F1 Score:  0.6793118763865499\n# F1 Score OOF: 0.675357710651828\n# CV: 0.6753577106518283","54ef8be6":"np.bincount(train_oof_1.astype(int))","c4f02381":"np.bincount(test_preds_1.astype(int))","ee80cc81":"np.save('train_oof_tabnet.npy', train_oof_1)\nnp.save('test_preds_tabnet.npy', test_preds_1)","9e07c22c":"submission['predicted'] = test_preds_1.astype(int)\nsubmission.to_csv('submission_output_tabnet.csv', index=False)\nprint(submission)","5bcd2198":"## Pip install pytorch-tabnet"}}