{"cell_type":{"10622c0d":"code","eaeef9c3":"code","c92f048b":"code","daa57a71":"code","897e2e44":"code","945a38da":"code","6093944c":"code","0b6b8a2e":"code","7e8b1cc2":"code","707b6219":"code","762c3039":"code","bbad9d14":"code","313fb7fb":"code","7ab36455":"code","0953ac5f":"code","d0d61402":"code","4d500fea":"code","ab7b447f":"code","9fae7585":"code","ab5c8a10":"code","49237aa0":"code","fdb38659":"code","0391d98a":"code","9049f62a":"code","cdee58e3":"code","7daeca03":"code","8196653a":"markdown","0ff5c554":"markdown","9d8921a4":"markdown","3fbd68a1":"markdown","1470a791":"markdown","7040f80c":"markdown","07b5c784":"markdown","ff29f117":"markdown"},"source":{"10622c0d":"!pip install optax","eaeef9c3":"import jax\nimport jax.numpy as jnp               # JAX NumPy\nimport optax                          # The Optax gradient processing and optimization library\nimport numpy as np                    # Ordinary NumPy\nimport tensorflow_datasets as tfds    # TFDS for Omniglot\nimport tensorflow as tf\nfrom jax import grad\nfrom jax import vmap # for auto-vectorizing functions\nfrom functools import partial # for use with vmap\nfrom jax import jit # for compiling functions for speedup\nfrom jax.experimental import stax # neural network library\nfrom jax.experimental.stax import Conv, Dense, MaxPool, Relu, Flatten, Softmax, LogSoftmax, AvgPool, BatchNorm\nimport matplotlib.pyplot as plt # visualization\n# from jax import random as jaxrandom\nimport numpy as np\nfrom jax.experimental import optimizers\nfrom jax.tree_util import tree_multimap # Element-wise manipulation of collections of numpy arrays\nimport random\nimport matplotlib.pyplot as plt\n\nimport time","c92f048b":"from sklearn.utils import shuffle","daa57a71":"rng = jax.random.PRNGKey(0)\nrng, init_rng = jax.random.split(rng)","897e2e44":"learning_rate = 0.1\nmeta_step_size = 0.001\n\n# inner_batch_size = 25\n# eval_batch_size = 25\n\nbatch_size = 25\n\nmeta_iters = 2000\neval_iters = 5\ninner_iters = 4\n\neval_interval = 1\ntrain_shots = 20\nshots = 5\nclasses = 5","945a38da":"import  torch.utils.data as data\nimport  os\nimport  os.path\nimport  errno\n\n\nclass Omniglot(data.Dataset):\n    urls = [\n        'https:\/\/github.com\/brendenlake\/omniglot\/raw\/master\/python\/images_background.zip',\n        'https:\/\/github.com\/brendenlake\/omniglot\/raw\/master\/python\/images_evaluation.zip'\n    ]\n    raw_folder = 'raw'\n    processed_folder = 'processed'\n    training_file = 'training.pt'\n    test_file = 'test.pt'\n\n    '''\n    The items are (filename,category). The index of all the categories can be found in self.idx_classes\n    Args:\n    - root: the directory where the dataset will be stored\n    - transform: how to transform the input\n    - target_transform: how to transform the target\n    - download: need to download the dataset\n    '''\n\n    def __init__(self, root, transform=None, target_transform=None, download=False):\n        self.root = root\n        self.transform = transform\n        self.target_transform = target_transform\n\n        if not self._check_exists():\n            if download:\n                self.download()\n            else:\n                raise RuntimeError('Dataset not found.' + ' You can use download=True to download it')\n\n        self.all_items = find_classes(os.path.join(self.root, self.processed_folder))\n        self.idx_classes = index_classes(self.all_items)\n\n    def __getitem__(self, index):\n        filename = self.all_items[index][0]\n        img = str.join('\/', [self.all_items[index][2], filename])\n\n        target = self.idx_classes[self.all_items[index][1]]\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.all_items)\n\n    def _check_exists(self):\n        return os.path.exists(os.path.join(self.root, self.processed_folder, \"images_evaluation\")) and \\\n               os.path.exists(os.path.join(self.root, self.processed_folder, \"images_background\"))\n\n    def download(self):\n        from six.moves import urllib\n        import zipfile\n\n        if self._check_exists():\n            return\n\n        # download files\n        try:\n            os.makedirs(os.path.join(self.root, self.raw_folder))\n            os.makedirs(os.path.join(self.root, self.processed_folder))\n        except OSError as e:\n            if e.errno == errno.EEXIST:\n                pass\n            else:\n                raise\n\n        for url in self.urls:\n            print('== Downloading ' + url)\n            data = urllib.request.urlopen(url)\n            filename = url.rpartition('\/')[2]\n            file_path = os.path.join(self.root, self.raw_folder, filename)\n            with open(file_path, 'wb') as f:\n                f.write(data.read())\n            file_processed = os.path.join(self.root, self.processed_folder)\n            print(\"== Unzip from \" + file_path + \" to \" + file_processed)\n            zip_ref = zipfile.ZipFile(file_path, 'r')\n            zip_ref.extractall(file_processed)\n            zip_ref.close()\n        print(\"Download finished.\")\n\n\ndef find_classes(root_dir):\n    retour = []\n    for (root, dirs, files) in os.walk(root_dir):\n        for f in files:\n            if (f.endswith(\"png\")):\n                r = root.split('\/')\n                lr = len(r)\n                retour.append((f, r[lr - 2] + \"\/\" + r[lr - 1], root))\n    print(\"== Found %d items \" % len(retour))\n    return retour\n\n\ndef index_classes(items):\n    idx = {}\n    for i in items:\n        if i[1] not in idx:\n            idx[i[1]] = len(idx)\n    print(\"== Found %d classes\" % len(idx))\n    return idx","6093944c":"import  torchvision.transforms as transforms\nfrom    PIL import Image\nimport  os.path\nimport  numpy as np\n\n\nclass OmniglotNShot:\n\n    def __init__(self, root, batchsz, n_way, k_shot, k_query, imgsz):\n        \"\"\"\n        Different from mnistNShot, the\n        :param root:\n        :param batchsz: task num\n        :param n_way:\n        :param k_shot:\n        :param k_qry:\n        :param imgsz:\n        \"\"\"\n\n        self.resize = imgsz\n        if not os.path.isfile(os.path.join(root, 'omniglot.npy')):\n            # if root\/data.npy does not exist, just download it\n            self.x = Omniglot(root, download=True,\n                              transform=transforms.Compose([lambda x: Image.open(x).convert('L'),\n                                                            lambda x: x.resize((imgsz, imgsz)),\n                                                            lambda x: np.reshape(x, (imgsz, imgsz, 1)),\n                                                            lambda x: np.transpose(x, [2, 0, 1]),\n                                                            lambda x: x\/255.])\n                              )\n\n            temp = dict()  # {label:img1, img2..., 20 imgs, label2: img1, img2,... in total, 1623 label}\n            for (img, label) in self.x:\n                if label in temp.keys():\n                    temp[label].append(img)\n                else:\n                    temp[label] = [img]\n\n            self.x = []\n            for label, imgs in temp.items():  # labels info deserted , each label contains 20imgs\n                self.x.append(np.array(imgs))\n\n            # as different class may have different number of imgs\n            self.x = np.array(self.x).astype(np.float)  # [[20 imgs],..., 1623 classes in total]\n            # each character contains 20 imgs\n            print('data shape:', self.x.shape)  # [1623, 20, 84, 84, 1]\n            temp = []  # Free memory\n            # save all dataset into npy file.\n            np.save(os.path.join(root, 'omniglot.npy'), self.x)\n            print('write into omniglot.npy.')\n        else:\n            # if data.npy exists, just load it.\n            self.x = np.load(os.path.join(root, 'omniglot.npy'))\n            print('load from omniglot.npy.')\n\n        # [1623, 20, 84, 84, 1]\n        # TODO: can not shuffle here, we must keep training and test set distinct!\n        self.x_train, self.x_test = self.x[:1200], self.x[1200:]\n\n        # self.normalization()\n\n        self.batchsz = batchsz\n        self.n_cls = self.x.shape[0]  # 1623\n        self.n_way = n_way  # n way\n        self.k_shot = k_shot  # k shot\n        self.k_query = k_query  # k query\n        assert (k_shot + k_query) <=20\n\n        # save pointer of current read batch in total cache\n        self.indexes = {\"train\": 0, \"test\": 0}\n        self.datasets = {\"train\": self.x_train, \"test\": self.x_test}  # original data cached\n        print(\"DB: train\", self.x_train.shape, \"test\", self.x_test.shape)\n\n        self.datasets_cache = {\"train\": self.load_data_cache(self.datasets[\"train\"]),  # current epoch data cached\n                               \"test\": self.load_data_cache(self.datasets[\"test\"])}\n\n    def normalization(self):\n        \"\"\"\n        Normalizes our data, to have a mean of 0 and sdt of 1\n        \"\"\"\n        self.mean = np.mean(self.x_train)\n        self.std = np.std(self.x_train)\n        self.max = np.max(self.x_train)\n        self.min = np.min(self.x_train)\n        # print(\"before norm:\", \"mean\", self.mean, \"max\", self.max, \"min\", self.min, \"std\", self.std)\n        self.x_train = (self.x_train - self.mean) \/ self.std\n        self.x_test = (self.x_test - self.mean) \/ self.std\n\n        self.mean = np.mean(self.x_train)\n        self.std = np.std(self.x_train)\n        self.max = np.max(self.x_train)\n        self.min = np.min(self.x_train)\n\n    # print(\"after norm:\", \"mean\", self.mean, \"max\", self.max, \"min\", self.min, \"std\", self.std)\n\n    def load_data_cache(self, data_pack):\n        \"\"\"\n        Collects several batches data for N-shot learning\n        :param data_pack: [cls_num, 20, 84, 84, 1]\n        :return: A list with [support_set_x, support_set_y, target_x, target_y] ready to be fed to our networks\n        \"\"\"\n        #  take 5 way 1 shot as example: 5 * 1\n        setsz = self.k_shot * self.n_way\n        querysz = self.k_query * self.n_way\n        data_cache = []\n\n        # print('preload next 50 caches of batchsz of batch.')\n        for sample in range(10):  # num of episodes\n\n            x_spts, y_spts, x_qrys, y_qrys = [], [], [], []\n            for i in range(self.batchsz):  # one batch means one set\n\n                x_spt, y_spt, x_qry, y_qry = [], [], [], []\n                selected_cls = np.random.choice(data_pack.shape[0], self.n_way, False)\n\n                for j, cur_class in enumerate(selected_cls):\n\n                    selected_img = np.random.choice(20, self.k_shot + self.k_query, False)\n\n                    # meta-training and meta-test\n                    x_spt.append(data_pack[cur_class][selected_img[:self.k_shot]])\n                    x_qry.append(data_pack[cur_class][selected_img[self.k_shot:]])\n                    y_spt.append([j for _ in range(self.k_shot)])\n                    y_qry.append([j for _ in range(self.k_query)])\n\n                # shuffle inside a batch\n                perm = np.random.permutation(self.n_way * self.k_shot)\n                x_spt = np.array(x_spt).reshape(self.n_way * self.k_shot, 1, self.resize, self.resize)[perm]\n                y_spt = np.array(y_spt).reshape(self.n_way * self.k_shot)[perm]\n                perm = np.random.permutation(self.n_way * self.k_query)\n                x_qry = np.array(x_qry).reshape(self.n_way * self.k_query, 1, self.resize, self.resize)[perm]\n                y_qry = np.array(y_qry).reshape(self.n_way * self.k_query)[perm]\n\n                # append [sptsz, 1, 84, 84] => [b, setsz, 1, 84, 84]\n                x_spts.append(x_spt)\n                y_spts.append(y_spt)\n                x_qrys.append(x_qry)\n                y_qrys.append(y_qry)\n\n\n            # [b, setsz, 1, 84, 84]\n            x_spts = np.array(x_spts).astype(np.float32).reshape(self.batchsz, setsz, 1, self.resize, self.resize)\n            y_spts = np.array(y_spts).astype(np.int).reshape(self.batchsz, setsz)\n            # [b, qrysz, 1, 84, 84]\n            x_qrys = np.array(x_qrys).astype(np.float32).reshape(self.batchsz, querysz, 1, self.resize, self.resize)\n            y_qrys = np.array(y_qrys).astype(np.int).reshape(self.batchsz, querysz)\n\n            data_cache.append([x_spts, y_spts, x_qrys, y_qrys])\n\n        return data_cache\n\n    def next(self, mode='train'):\n        \"\"\"\n        Gets next batch from the dataset with name.\n        :param mode: The name of the splitting (one of \"train\", \"val\", \"test\")\n        :return:\n        \"\"\"\n        # update cache if indexes is larger cached num\n        if self.indexes[mode] >= len(self.datasets_cache[mode]):\n            self.indexes[mode] = 0\n            self.datasets_cache[mode] = self.load_data_cache(self.datasets[mode])\n\n        next_batch = self.datasets_cache[mode][self.indexes[mode]]\n        self.indexes[mode] += 1\n\n        return next_batch\n","0b6b8a2e":"import  time\nimport  torch\n\ndb = OmniglotNShot('db\/omniglot', batchsz=20, n_way=5, k_shot=5, k_query=15, imgsz=64)\n\nfor i in range(1):\n    x_spt, y_spt, x_qry, y_qry = db.next('train')\n\n\n    # [b, setsz, h, w, c] => [b, setsz, c, w, h] => [b, setsz, 3c, w, h]\n    x_spt = torch.from_numpy(x_spt)\n    x_qry = torch.from_numpy(x_qry)\n    y_spt = torch.from_numpy(y_spt)\n    y_qry = torch.from_numpy(y_qry)\n    batchsz, setsz, c, h, w = x_spt.size()\n\n    print(batchsz, setsz, c, h, w)","7e8b1cc2":"net_init, net_apply = stax.serial(Conv(32, (5, 5), (2, 2), padding=\"SAME\"),\n                                 BatchNorm(), Relu,\n                                 Conv(32, (5, 5), (2, 2), padding=\"SAME\"),\n                                 BatchNorm(), Relu,\n                                 Conv(10, (3, 3), (2, 2), padding=\"SAME\"),\n                                 BatchNorm(), Relu,\n                                 Conv(10, (3, 3), (2, 2), padding=\"SAME\"), Relu,\n                                 Flatten,\n                                 Dense(classes))\n\nin_shape = (20, 1, 64, 64)\nout_shape, net_params = net_init(rng, in_shape)","707b6219":"@jit\ndef loss(params, inputs, targets):\n    predictions = net_apply(params, inputs)\n    return jnp.mean(optax.softmax_cross_entropy(predictions, jax.nn.one_hot(targets, num_classes=classes)))","762c3039":"def compute_metrics(logits, labels):\n    loss_ = jnp.mean(optax.softmax_cross_entropy(logits, jax.nn.one_hot(labels, num_classes=classes)))\n    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n    return accuracy, loss_","bbad9d14":"@jit\ndef inner_update(params, inputs, outputs, alpha = learning_rate):\n    '''\n    input:\n    - params: model's parameters\n    - inputs\n    - targets: true label\n    output\n    - updated parameters\n    '''\n    grads = grad(loss)(params, inputs, outputs)\n    grad_update_fn = lambda g, state: (state - alpha * g)\n    return tree_multimap(grad_update_fn, grads, params)","313fb7fb":"@jit\ndef maml_loss(params, support_img, support_lab, query_img, query_lab):\n    '''\n    input:\n    - params: model's parameters\n    - x1, y1: task's train set\n    - x2, y2: task's test set\n    output:\n    - Loss after update parameters 1 time on the test set.\n    '''\n    params_updated = inner_update(params, support_img, support_lab)\n    return loss(params_updated, query_img, query_lab)\n\n@jit\ndef maml_loss_batch(params, x1_b, y1_b, x2_b, y2_b):\n    '''\n    input:\n    - params\n    - x1_b, y1_b, x2_b, y2_b: batches of sample task \n    output:\n    - combined loss of the batch\n    '''\n    return np.mean(vmap(partial(maml_loss, params))(x1_b, y1_b, x2_b, y2_b))","7ab36455":"# Define optimizer\nopt_init, opt_update, get_params = optimizers.adam(step_size=meta_step_size)\nopt_state = opt_init(net_params)","0953ac5f":"from tqdm import tqdm\n#Define a step (using jit to improve speed)\n@jit\ndef step(i, opt_state, support_img, support_lab, query_img, query_lab):\n    '''\n    input:\n    - step number, opt_state (contains params)\n    -x1, y1: train, x2, y2: test and get loss\n    output:\n    - new opt_state and loss\n    '''\n    # Get params from opt_state\n    p = get_params(opt_state)\n    # calculate gradient from maml_loss\n    g = grad(maml_loss)(p, support_img, support_lab, query_img, query_lab)\n    # pre-model update trial on task.\n    l = maml_loss(p, support_img, support_lab, query_img, query_lab)\n    \n    return opt_update(i, g, opt_state), l\n\n@jit\ndef batch_step(i, opt_state, x1_b, y1_b, x2_b, y2_b):\n    p = get_params(opt_state)\n    g = grad(maml_loss_batch)(p, x1_b, y1_b, x2_b, y2_b)\n    l = maml_loss_batch(p, x1_b, y1_b, x2_b, y2_b)\n    return opt_update(i, g, opt_state), l","d0d61402":"@jit\ndef maml_loss_batch(params, x1_b, y1_b, x2_b, y2_b):\n    '''\n    input:\n    - params\n    - x1_b, y1_b, x2_b, y2_b: batches of sample task \n    output:\n    - combined loss of the batch\n    '''\n    return np.mean(vmap(partial(maml_loss, params))(x1_b, y1_b, x2_b, y2_b))","4d500fea":"@jit\ndef batch_step(i, opt_state, x1_b, y1_b, x2_b, y2_b):\n    p = get_params(opt_state)\n    g = grad(maml_loss_batch)(p, x1_b, y1_b, x2_b, y2_b)\n    l = maml_loss_batch(p, x1_b, y1_b, x2_b, y2_b)\n    return opt_update(i, g, opt_state), l","ab7b447f":"TRAIN_STEPS = 1\nmaml_losses = []\nstart_time = time.time()\nfor i in tqdm(range(240)):\n    # get x_support, y_support, x_query, y_query batch\n    x_support_batch, y_support_batch, x_query_batch, y_query_batch = db.next('train')\n    opt_state, l = batch_step(i, opt_state, x_support_batch, y_support_batch, x_query_batch, y_query_batch)\n    maml_losses.append(l)\n    \n    \n    \nnet_params = get_params(opt_state)","9fae7585":"plt.plot(np.arange(240), np.array(maml_losses))","ab5c8a10":"maml_losses[-10:]","49237aa0":"TEST_TASKS_BATCHES = db.datasets_cache['test']","fdb38659":"epochs= 10\naccuracies = []\ntest_losses = []\nresults = []\n\nfor i in tqdm(range(len(TEST_TASKS_BATCHES))):\n    params = net_params.copy()\n    x_support_batch, y_support_batch, x_query_batch, y_query_batch = db.next('test')\n    batch_size = x_support_batch.shape[0]\n    for j in range(batch_size):\n        params = net_params.copy()\n        x_support = x_support_batch[j]\n        y_support = y_support_batch[j]\n        x_query = x_query_batch[j]\n        y_query = y_query_batch[j]\n        for k in range(epochs):\n            params = inner_update(params, x_support, y_support)\n        y_prediction = net_apply(params, x_query)\n        accuracy, test_loss = compute_metrics(y_prediction, y_query)\n        accuracies.append(accuracy)\n        test_losses.append(test_loss)\n        results.append((x_query, y_prediction, y_query))","0391d98a":"np.mean(accuracy)","9049f62a":"np.mean(test_losses)","cdee58e3":"str(results[0][2][0])","7daeca03":"_, axarr = plt.subplots(nrows=5, ncols=5, figsize=(20, 20))\nsth = 10\nfor a in range(5):\n    for b in range(5):\n        temp_image = results[a + sth][0][b].reshape(64,64,1)\n        temp_image = np.stack((temp_image[:, :, 0],) * 3, axis=2)\n        temp_image *= 255\n        temp_image = np.clip(temp_image, 0, 255).astype(\"uint8\")\n        axarr[a, b].imshow(temp_image, cmap=\"gray\")\n        axarr[a, b].set_title(\"ori and guess: \" + str(results[a + sth][2][b]) + \" \" + str(np.argmax(results[a + sth][1][b])))\n        axarr[a, b].imshow(temp_image, cmap=\"gray\")\n        axarr[a, b].xaxis.set_visible(False)\n        axarr[a, b].yaxis.set_visible(False)\nplt.show()","8196653a":"***Define a step***","0ff5c554":"***Optimizer Initialization:***","9d8921a4":"**Test model**","3fbd68a1":"**1. Import library**","1470a791":"***3. Build the model (CNN)***","7040f80c":"***MAML Loss***","07b5c784":"***2. Import the dataset***\n\nWe reuse the omniglot loader from https:\/\/github.com\/dragen1860\/MAML-Pytorch","ff29f117":"***Now let's do the same thing for batch***"}}