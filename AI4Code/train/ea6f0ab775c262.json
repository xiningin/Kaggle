{"cell_type":{"f2f77fe9":"code","6f1eec97":"code","4ab7de47":"code","3487dbed":"code","31f6e721":"code","83a449e9":"code","3d3427cd":"code","5bd1b428":"code","dc7a1a53":"code","57ed0492":"code","b18f92f6":"code","80dda928":"code","72b58552":"code","8350055a":"code","f526f1d5":"code","237cc0c1":"code","c3ad4027":"code","9634247e":"code","377fa02c":"code","e86bd266":"code","b5fb6e1f":"code","fcf1a0cf":"code","c17abcfe":"code","42e41146":"code","9bad0210":"code","a62e761c":"code","e13c2dad":"code","2e99ffcd":"code","f81ab19b":"code","7adb4de6":"code","009845e3":"code","1801696c":"code","1fefc2e5":"code","f1f90e03":"code","4f883254":"code","005512ad":"code","d9055695":"code","f0e2917c":"code","298fd919":"code","dbaa4794":"code","465c681a":"code","3dfbf3d4":"code","f52d5b11":"code","0f3a8f08":"code","978a7cc5":"code","a6e2881d":"code","1ea2a7e4":"code","10fbbeb1":"code","ef1ac284":"code","9dcab596":"code","90ecdca8":"code","985c8b0b":"code","f7e17f7a":"code","72bfaeea":"markdown","5a26c113":"markdown","afe7ff03":"markdown","ca9797b7":"markdown","025f6d39":"markdown","d7c9c667":"markdown","9a4b40cd":"markdown","6ad8d9e3":"markdown"},"source":{"f2f77fe9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","6f1eec97":"data=pd.read_csv('..\/input\/africa-economic-banking-and-systemic-crisis-data\/african_crises.csv')\ndata","4ab7de47":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"white\", color_codes=True)\nsns.set(font_scale=1.5)\n\n# import libraries for model validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n# import libraries for metrics and reporting\nfrom sklearn.metrics import confusion_matrix\n","3487dbed":"df = data","31f6e721":"df.shape","83a449e9":"df.head()","3d3427cd":"df['banking_crisis'] = df['banking_crisis'].astype('category')\ndf['banking_crisis'] = df['banking_crisis'].cat.codes\ndf","5bd1b428":"x = df.iloc[:,4:13]\nx","dc7a1a53":"y = df.iloc[:,13].values\ny","57ed0492":"len(df)\ndf.head()\ndf.isnull().any()\ndf.isnull().sum()","b18f92f6":"df.isnull().sum()\n","80dda928":"df.columns","72b58552":"import seaborn as sns\nsns.set(style=\"white\", color_codes=True)\nsns.set(font_scale=1.5)","8350055a":"len(df)","f526f1d5":"# Splitting Training and Test Dataset","237cc0c1":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)","c3ad4027":"print (x_train.shape)\nprint (x_test.shape)\nprint (y_train.shape)\nprint (y_test.shape)","9634247e":"from sklearn.linear_model import LogisticRegression\n\n# fit the model to the training data\nmodel = LogisticRegression()\nmodel.fit(x_train, y_train)\n\nprint (model.intercept_)\nprint (model.coef_)\nprint (x_train.columns)","377fa02c":"display (x_test[:10])\nprint ()\ndisplay (model.predict_proba(x_test)[:10]) # prob\nprint ()\ndisplay (model.predict(x_test)[:10])","e86bd266":"from sklearn.metrics import accuracy_score\nprint (\"Logistic testing accuracy is %2.2f\" % accuracy_score(y_test,model.predict(x_test)))","b5fb6e1f":"print (\"Logistic training accuracy is %2.2f\" % accuracy_score(y_train,model.predict(x_train)))","fcf1a0cf":"from sklearn.tree import DecisionTreeClassifier\nclassifier =DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train, y_train)","c17abcfe":"y_pred = classifier.predict(x_test)","42e41146":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","9bad0210":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","a62e761c":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors= 5,\n                                 metric = 'minkowski', p=2)","e13c2dad":"classifier.fit(x_train, y_train)","2e99ffcd":"y_pred = classifier.predict(x_test)","f81ab19b":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","7adb4de6":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","009845e3":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)","1801696c":"y_pred = classifier.predict(x_test)","1fefc2e5":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","f1f90e03":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","4f883254":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(x_train, y_train)","005512ad":"cm = confusion_matrix(y_test, y_pred)\ncm","d9055695":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","f0e2917c":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(x_train, y_train)","298fd919":"cm = confusion_matrix(y_test, y_pred)\ncm","dbaa4794":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","465c681a":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10,\n                                   criterion = 'entropy', random_state = 0)","3dfbf3d4":"cm = confusion_matrix(y_test, y_pred)\ncm","f52d5b11":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","0f3a8f08":"from sklearn.decomposition import PCA\n#Principal component Analysis\npca = PCA(n_components=None)\nx_train_n = pca.fit_transform(x_train)\nx_test_n = pca.fit_transform(x_test)","978a7cc5":"x_train","a6e2881d":"pd.DataFrame(x_train_n)","1ea2a7e4":"from sklearn.decomposition import PCA\n#Principal component Analysis\npca = PCA(n_components=2)\nx_train_2 = pca.fit_transform(x_train)\nx_test_2 = pca.fit_transform(x_test)","10fbbeb1":"explained_variance = pca.explained_variance_ratio_","ef1ac284":"explained_variance","9dcab596":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(x_train_2, y_train)","90ecdca8":"y_pred = logmodel.predict(x_test_2)","985c8b0b":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred)","f7e17f7a":"x_test_2","72bfaeea":"#Random Forest","5a26c113":"#Fitting Naive Bayes to Training Set\u00b6\n","afe7ff03":"#Decision Tree","ca9797b7":"#SVM - Fitting SVM to the Training set","025f6d39":"#PCA","d7c9c667":"#Model Building - Logistic Regression","9a4b40cd":"#SUPPORT VECTOR MACHINE","6ad8d9e3":"#Fitting K-NN to Training Set\u00b6\n"}}