{"cell_type":{"b0b6b346":"code","a5c4130f":"code","53fa240f":"code","e9578128":"code","0fd7a06a":"code","a9a37d65":"code","2a9f67a5":"code","8bbdf2b8":"code","1581d652":"code","49fdc560":"code","4fa3b86c":"code","1e217a39":"code","db260a3a":"code","b284d55b":"code","0eeda7b5":"code","c01fd655":"code","081710f3":"code","6d04c2ff":"code","e985f09a":"code","be5ee88b":"code","38f9fa5b":"code","03392a35":"code","28f4700b":"code","1473f29f":"code","da75eaf7":"code","24e4d437":"code","2443b9b3":"code","b02b9b9d":"code","e3a8d8e9":"markdown"},"source":{"b0b6b346":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a5c4130f":"train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nitems = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')","53fa240f":"train","e9578128":"#Dropping null values\n\ntrain.dropna(inplace=True)","0fd7a06a":"train.dtypes","a9a37d65":"#Here, df['column'].apply() performs an operation on that column\n#Look up datetime.strptime on how it works.\n#lambda is used for defining functions with only one statement.\n\nfrom datetime import datetime\n\ntrain['date'] = train['date'].apply(lambda x:datetime.strptime(x, '%d.%m.%Y'))","2a9f67a5":"train.dtypes","8bbdf2b8":"monthly_sales = train.groupby(['date_block_num','shop_id','item_id'])['date', 'item_price', 'item_cnt_day'].agg({'date':['min','max'],'item_price':'mean', 'item_cnt_day':'sum'})","1581d652":"#Now we have the monthly estimates\n\naggregation = monthly_sales.reset_index()\naggregation","49fdc560":"#Calculate duration\ndiff = aggregation['date']['max'] - aggregation['date']['min']\n\n#Convert to integers\ndiff = diff.dt.days.astype('int16')\ndiff = diff + 1","4fa3b86c":"aggregation['duration'] = diff\naggregation = aggregation.drop(columns=['date'])","1e217a39":"#Convert 2D columns to 1D\n\naggregation['item_cnt_month'] = aggregation['item_cnt_day']['sum']\naggregation['item_cost'] = aggregation['item_price']['mean']\naggregation = aggregation.drop(columns = ['item_cnt_day','item_price'])","db260a3a":"#Output first row\n#Understand what it means\n\nprint(aggregation.iloc[0])\n\nprint('\\nThis means',aggregation['item_cnt_month'].iloc[0], 'instances of item',aggregation['item_id'].iloc[0] ,'were sold over', aggregation['duration'].iloc[0],'days, for shop',aggregation['shop_id'].iloc[0],'in month',aggregation['date_block_num'].iloc[0],',thereby netting an average of',aggregation['item_cost'].iloc[0],'units of money.')","b284d55b":"#We need to get the sum of all durations and items sold, for each tuple of item_id and shop_id.\n\nmonthly_sales_new = aggregation.groupby(['item_id','shop_id']).agg({'item_cnt_month':['sum'], 'duration':['sum'], 'item_cost':['mean']}).reset_index()","0eeda7b5":"#We've gotten our main features. Let's transform them.\n\nmonthly_sales_new","c01fd655":"monthly_sales_new['item_cnt_month_sum'] = monthly_sales_new['item_cnt_month']['sum']\/30\nmonthly_sales_new['duration_sum'] = monthly_sales_new['duration']['sum']\nmonthly_sales_new['item_cost_mean'] = monthly_sales_new['item_cost']['mean']","081710f3":"monthly_sales_new = monthly_sales_new.drop(columns = ['item_cnt_month','duration','item_cost'])","6d04c2ff":"#Voila!\n\nmonthly_sales_new","e985f09a":"#The wacky approach: Using item_id and shop_id (!!!) to predict item_cost\n#Then using that to predict duration\n#Then using the whole thing to predict item_cnt_month\n\nX = monthly_sales_new[['item_id','shop_id']]\ny = monthly_sales_new[['item_cost_mean']]\n\n#If we don't include this following code, there's an error. I don't really know why, some feature name mismatch.\n#Apparently the monthly_sales_new has a space after item_id and shop_id.\n#OR XGB adds a space after the feature names? I don't really know.\n\ntest.fillna(0, inplace = True)\ntest.columns = ['ID', 'shop_id ', 'item_id ']\ntest = test.reindex(columns = ['ID', 'item_id ', 'shop_id '])\ntest","be5ee88b":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(learning_rate=0.01, n_estimators = 1000, max_depth=3, subsample=0.8, colsample_bytree=1, gamma=1)","38f9fa5b":"xgb.fit(X, y)","03392a35":"pred = xgb.predict(test.drop(columns = ['ID']))","28f4700b":"test['item_cost_mean '] = pred","1473f29f":"X = monthly_sales_new[['item_id', 'shop_id', 'item_cost_mean']]\ny = monthly_sales_new[['duration_sum']]\n\nxgb.fit(X, y)\npred = xgb.predict(test.drop(columns = ['ID']))\ntest['duration_sum '] = pred","da75eaf7":"X = monthly_sales_new[['item_id','shop_id', 'item_cost_mean', 'duration_sum']]\ny = monthly_sales_new[['item_cnt_month_sum']]\n\nxgb.fit(X, y)\npred = xgb.predict(test.drop(columns = ['ID']))","24e4d437":"pred","2443b9b3":"result = pd.DataFrame({'ID':test['ID'], 'item_cnt_month':pred})","b02b9b9d":"result.to_csv('submission.csv', index=False)","e3a8d8e9":"**First, we need to convert the 'date' column to the date datatype.**"}}