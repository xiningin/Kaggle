{"cell_type":{"219bb883":"code","1842c293":"code","6132b7f9":"code","fd5015c8":"code","61e5ff90":"code","042495a8":"code","63c77b14":"code","fb9ae956":"code","e484eff8":"code","316b00b0":"code","0c4ddf4d":"code","167c3fea":"code","7afc795e":"code","f1d42e73":"code","eda26561":"code","9f39663c":"code","a8db6844":"code","78d95222":"code","f740cfab":"code","f04cd764":"code","edbb6bed":"code","fa2aa525":"code","b5fe2ce2":"code","8bdf07a6":"code","dd5eb8fb":"code","2afc349a":"code","089f17d6":"code","342c8638":"code","2d65d7e7":"code","e80e3a2e":"code","d2fc5184":"code","701ef9e6":"code","a712a716":"code","21b4caf0":"code","5f4ed1f3":"code","a65f6620":"code","5f6bd358":"code","708f1f10":"code","43bf831c":"code","00568ae9":"code","c5e7b630":"code","63968aa5":"code","dd04ddd5":"code","c1591679":"code","dbf1e762":"code","16451404":"code","77ea60cd":"code","99817ab8":"code","df00eacd":"code","e59c4565":"code","a8224b88":"code","8182b425":"code","a4aed5a8":"code","f4957046":"code","4394d09d":"code","95461797":"code","278a765b":"code","90721003":"code","b0fcb840":"code","dbe5e17b":"code","789f2d77":"code","6228370c":"code","576e13db":"code","ec1f9a86":"markdown","9864785b":"markdown","7c8393b0":"markdown","d0aa5bed":"markdown","0c02e33b":"markdown","74bc0d4b":"markdown","d8e4d570":"markdown","15ea5690":"markdown","add3f419":"markdown","7a5e05be":"markdown"},"source":{"219bb883":"import numpy as np\nfrom numpy import array\nfrom numpy import hstack\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nimport seaborn as sns\nimport missingno as mno\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom tensorflow.keras.models import Sequential\nimport tensorflow.keras.models as models\n\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.layers import ConvLSTM2D\nfrom tensorflow.keras.layers import RepeatVector\n\nfrom tensorflow.python.keras.layers.convolutional import Conv1D\nfrom tensorflow.python.keras.layers.convolutional import MaxPooling1D\n\nfrom scipy.signal import detrend\nfrom scipy import arange","1842c293":"# reading the csv file\ndf = pd.read_csv('..\/input\/onion-yeild-prediction\/Yield_model_onion.csv')\ndf.tail()","6132b7f9":"# column name correction\ndf.columns = df.columns.str.replace('\\n', '_')\ndf.columns = df.columns.str.replace(' ', '_')\ndf.head()","fd5015c8":"# # drops the NaN row\n# df.drop([30], axis=0, inplace=True)\n# df.tail()","61e5ff90":"for i in range(len(df)):\n    df['Year'].values[i] = df['Year'].values[i][:2]+df['Year'].values[i][-2:]\n\ndf['Year']","042495a8":"# handing missing data\ndf = df.interpolate()\nmno.matrix(df, figsize = (20,6))","63c77b14":"df.drop([0], axis=0, inplace=True)\nmno.matrix(df, figsize = (20,6))","fb9ae956":"df.columns","e484eff8":"drop_cols = ['Yield', 'Area','Production', 'SPEI_3_Dec', 'SPEI_3_Jan', \n             'SPEI_3_Feb', 'SPEI_3_Mar', 'SPEI_9_Dec', 'SPEI_9_Jan', \n             'SPEI_9_Feb', 'SPEI_9_Mar', 'SPEI_3_Dec', 'SPEI_12_Jan', \n             'SPEI_12_Feb', 'SPEI_12_Mar']\n\ndata = df.drop(drop_cols, axis=1)\ndata = data.set_index('Year')\ndata.head()","316b00b0":"data.columns","0c4ddf4d":"temp = df.set_index('Year')\nTarget = temp['Yield']\n# Target = temp['Yield']\nTarget.head()","167c3fea":"plt.plot(Target)","7afc795e":"y = Target.to_numpy()\ny","f1d42e73":"y_detrend = detrend(y)\ny_detrend","eda26561":"Target.iloc[:] = y_detrend","9f39663c":"Target","a8db6844":"plt.plot(Target)","78d95222":"data['Target'] = Target\ndata.head()","f740cfab":"values = data.values\nvalues[:,0]","f04cd764":"# Normalizing\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled = scaler.fit_transform(values)\n\nscaled[:,0]","edbb6bed":"values.shape","fa2aa525":"scaled.shape","b5fe2ce2":"# split a multivariate sequence into samples\ndef split_sequences(sequences, n_steps_in, n_steps_out):\n\tX, y = list(), list()\n\tfor i in range(len(sequences)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps_in\n\t\tout_end_ix = end_ix + n_steps_out\n\t\t# check if we are beyond the dataset\n\t\tif out_end_ix > len(sequences):\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn array(X), array(y)\n \n# # define input sequence\n# in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n# in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n# out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n# # convert to [rows, columns] structure\n# in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n# in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n# out_seq = out_seq.reshape((len(out_seq), 1))\n# # horizontally stack columns\n# dataset = hstack((in_seq1, in_seq2, out_seq))\n# # choose a number of time steps\n# n_steps_in, n_steps_out = 3, 2\n# # covert into input\/output\n# X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n# print(X.shape, y.shape)\n# # summarize the data\n# for i in range(len(X)):\n# \tprint(X[i], y[i])","8bdf07a6":"print(values.shape, scaled.shape)","dd5eb8fb":"n_steps_in, n_steps_out = 8, 5  # n_steps_out should be the model no.\n# covert into input\/output\nX, y = split_sequences(scaled, n_steps_in, n_steps_out)\nprint(X.shape, y.shape)\n# summarize the data\n# for i in range(5):\n# \tprint(X[i], y[i])","2afc349a":"n_features = X.shape[2]\nn_features","089f17d6":"# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\nn_seq = 2\nn_steps = 4\nX = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n\nX.shape","342c8638":"#bidirectional\n\n# n_train_time = 13\n# train_X = X[:n_train_time]\n# train_y = y[:n_train_time]\n# test_X = X[n_train_time:]\n# test_y = y[n_train_time:]\n\n# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","2d65d7e7":"#cnn\nyears = y.shape[1]-1\n\nn_train_time = X.shape[0]-4\ntrain_X = X[:n_train_time]\ntrain_y = y[:n_train_time, years,45]\ntest_X = X[n_train_time:]\ntest_y = y[n_train_time:, years, 45]\n\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","e80e3a2e":"# del model","d2fc5184":"# # Building model\n\n# model = Sequential()\n# model.add(TimeDistributed(Conv1D(filters=32, kernel_size=2, activation='relu'), input_shape=(None, n_steps, n_features)))\n# model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n# model.add(TimeDistributed(Flatten()))\n# model.add((LSTM(50, activation='relu')))\n# # model.add(LSTM(200, activation='relu'))\n# model.add(Dense(1))\n# model.compile(optimizer='adam', loss='mse')","701ef9e6":"# Loading model\n\nmodel = models.load_model(\"..\/input\/onion-yeild-prediction\/onion_model5.h5\")\nmodel","a712a716":"# # fit model\n# model.fit(train_X, train_y, epochs=100, verbose=0)","21b4caf0":"# demonstrate prediction\n# yhat = model.predict(train_X, verbose=0)\nyhat = model.predict(test_X, verbose=0)\nprint(yhat.shape)\n# print(yhat[:,1,45])","5f4ed1f3":"test_y.shape","a65f6620":"test_y = test_y.reshape(test_y.shape[0], 1)\ntest_y.shape","5f6bd358":"truth = test_y","708f1f10":"print(yhat.shape, truth.shape)","43bf831c":"inv_yhat = np.concatenate((scaled[0:yhat.shape[0], :45], yhat), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,45]\n\ninv_y = np.concatenate((scaled[0:yhat.shape[0], :45], truth), axis=1)\ninv_y = scaler.inverse_transform(inv_y)\ninv_y = inv_y[:,45]\n\nprint(inv_yhat.shape, inv_y.shape)","00568ae9":"# aa=list(range(len(train_X)))\n# plt.plot(aa, inv_y, marker='.', label=\"actual\")\n\naa=[int(i) for i in list(data.index)][-len(truth):]\nplt.xticks(aa)\nplt.plot(aa, inv_y, marker='.', label=\"actual\")\n\nplt.plot(aa, inv_yhat, 'r', label=\"prediction\")\nplt.ylabel('Detrended Yield', size=12)\nplt.xlabel('Year', size=12)\nplt.legend(fontsize=12)\nplt.show()","c5e7b630":"round(mean_squared_error(inv_y, inv_yhat), 3)","63968aa5":"print(inv_y)\nprint(inv_yhat)","dd04ddd5":"# model.save('.\/onion_model5_update.h5')","c1591679":"import tensorflow as tf\nimport math\ndef metrics(Y_test, Y_prediction):\n\n    mse = tf.keras.losses.MeanSquaredError()\n    print('MSE:',mse(Y_test, Y_prediction).numpy())\n    mae = tf.keras.losses.MeanAbsoluteError()\n    print('RMSE:', math.sqrt(mse(Y_test, Y_prediction).numpy()))\n    print('MAE:',mae(Y_test, Y_prediction).numpy())\n    mape = tf.keras.losses.MeanAbsolutePercentageError()\n    print('MAPE:',mape(Y_test, Y_prediction).numpy())\n    print('Standard deviation of error:',np.std(tf.keras.losses.mean_absolute_error(Y_test, Y_prediction).numpy()))\n    #print('MdAE:',scipy.stats.median_absolute_deviation(tf.keras.losses.mean_absolute_error(Y_test, Y_prediction).numpy()))","dbf1e762":"metrics(inv_y, inv_yhat)","16451404":"# model.summary()","77ea60cd":"values.shape","99817ab8":"n_steps_in, n_steps_out = 8, 0  # n_steps_out should be the model no.\n# covert into input\/output\nX, y = split_sequences(values, n_steps_in, n_steps_out)\nprint(X.shape, y.shape)","df00eacd":"n_features = X.shape[2]\nn_features","e59c4565":"# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\nn_seq = 2\nn_steps = 4\nX = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n\nX.shape","a8224b88":"# Loading model\n\nmodel = models.load_model(\"..\/input\/onion-yeild-prediction\/onion_model1.h5\")\n\n# demonstrate prediction\n# yhat = model.predict(train_X, verbose=0)\nyhat = model.predict(X, verbose=0)\nprint(yhat.shape)\n# print(yhat[:,1,45])\n\ninv_yhat = np.concatenate((scaled[0:yhat.shape[0], :45], yhat), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,45]\n\nforecast_2020 = inv_yhat[22]\nforecast_2020","8182b425":"# Loading model\n\nmodel = models.load_model(\"..\/input\/onion-yeild-prediction\/onion_model2.h5\")\n\n# demonstrate prediction\n# yhat = model.predict(train_X, verbose=0)\nyhat = model.predict(X, verbose=0)\nprint(yhat.shape)\n# print(yhat[:,1,45])\n\ninv_yhat = np.concatenate((scaled[0:yhat.shape[0], :45], yhat), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,45]\n\nforecast_2021 = inv_yhat[22]\nforecast_2021","a4aed5a8":"# Loading model\n\nmodel = models.load_model(\"..\/input\/onion-yeild-prediction\/onion_model3.h5\")\n\n# demonstrate prediction\n# yhat = model.predict(train_X, verbose=0)\nyhat = model.predict(X, verbose=0)\nprint(yhat.shape)\n# print(yhat[:,1,45])\n\ninv_yhat = np.concatenate((scaled[0:yhat.shape[0], :45], yhat), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,45]\n\nforecast_2022 = inv_yhat[22]\nforecast_2022","f4957046":"# Loading model\n\nmodel = models.load_model(\"..\/input\/onion-yeild-prediction\/onion_model4.h5\")\n\n# demonstrate prediction\n# yhat = model.predict(train_X, verbose=0)\nyhat = model.predict(X, verbose=0)\nprint(yhat.shape)\n# print(yhat[:,1,45])\n\ninv_yhat = np.concatenate((scaled[0:yhat.shape[0], :45], yhat), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,45]\n\nforecast_2023 = inv_yhat[22]\nforecast_2023","4394d09d":"# Loading model\n\nmodel = models.load_model(\"..\/input\/onion-yeild-prediction\/onion_model5.h5\")\n\n# demonstrate prediction\n# yhat = model.predict(train_X, verbose=0)\nyhat = model.predict(X, verbose=0)\nprint(yhat.shape)\n# print(yhat[:,1,45])\n\ninv_yhat = np.concatenate((scaled[0:yhat.shape[0], :45], yhat), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,45]\n\nforecast_2024 = inv_yhat[22]\nforecast_2024","95461797":"dic = {'2021': [forecast_2020],\n       '2022': [forecast_2021],\n       '2023': [forecast_2022],\n       '2024': [forecast_2023],\n       '2025': [forecast_2024],}\n\npred = pd.DataFrame(dic, dtype='float64')\n\npred = pred.T\npred","278a765b":"# data.Target.index = data.Target.index.astype('int64')\n# data.Target.index = data.Target.index.astype('string')","90721003":"data.Target.index","b0fcb840":"# pred.index = pred.index.astype('int64')\n# pred.index = pred.index.astype('string')\n# pred.index","dbe5e17b":"test = pd.DataFrame(inv_yhat)\ntest","789f2d77":"test.index = data.Target.index[-4:]\ntest","6228370c":"test.index","576e13db":"plt.figure(figsize=(20,5))\nplt.plot(data.Target, label='Actual')\nplt.plot(pred, label='Future Prediction')\nplt.plot(test, 'r', label='Test Prediction')\nplt.ylabel('Detrended Yield', size=15)\nplt.xlabel('Year', size=15)\nplt.legend(fontsize=15)\nplt.show()","ec1f9a86":"### plotting","9864785b":"## Importing libraries","7c8393b0":"## Multiple Parallel Input and Multi-Step Output","d0aa5bed":"## Data Preparation","0c02e33b":"## Predicting Future","74bc0d4b":"### Forecast 2020","d8e4d570":"### Forecast 2024","15ea5690":"### Forecast 2023","add3f419":"### Forecast 2021","7a5e05be":"### Forecast 2022"}}