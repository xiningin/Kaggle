{"cell_type":{"1b8357b5":"code","ab814215":"code","ccde3ed5":"code","e46af0b1":"code","7400acc5":"code","dabfb0c8":"code","10d09272":"code","d4501da6":"code","e651f656":"code","7e0531f8":"code","40dc8ef9":"code","175dfaf2":"code","897b5d97":"code","402f8aeb":"code","28d1df26":"code","121b181e":"code","07238525":"code","7bdbdac9":"code","17388849":"code","bd677a19":"code","d6ee3a1d":"code","076252ac":"code","080deca8":"code","c4ed67fb":"code","c16b2e79":"code","d71de226":"code","e832d092":"code","326215dd":"code","a94fadc3":"code","9737c25c":"code","794a4674":"code","68de0a40":"code","0de238dc":"code","88f30f5f":"code","7ade9dca":"code","21683042":"code","6165080a":"code","87c6990d":"code","492b98ee":"code","6054880d":"code","c8370958":"code","3f47126b":"code","4f1e3b1e":"code","6fd9cba4":"code","1b241cb7":"code","ddf04867":"code","4260b133":"code","3a6b1995":"code","1121cf7d":"code","de0ea1cd":"code","34fbd7bb":"code","221ea644":"code","5a18ee12":"markdown","57242e4f":"markdown","db9c68cd":"markdown","24ee7da5":"markdown","63a229b7":"markdown","5ce30c7e":"markdown","33f2e58c":"markdown","abd0c349":"markdown","ce53eded":"markdown","58155256":"markdown","30e58485":"markdown","a4a37d1c":"markdown","6a02256b":"markdown","c311e81e":"markdown","5af048b8":"markdown","0b7b85b0":"markdown","8b7c460a":"markdown","e8e6754f":"markdown","91c44935":"markdown","2927ae7b":"markdown","e267abf2":"markdown","5197b5a2":"markdown","6b9dad2f":"markdown","60feba66":"markdown","2795dc88":"markdown","65bf0524":"markdown","c5e54c4e":"markdown","b9505e0f":"markdown","fee2f3ec":"markdown","a59badcc":"markdown","ad4da446":"markdown","e1fd88bb":"markdown","937c0285":"markdown","b15d28c8":"markdown","028b346a":"markdown","6055dd82":"markdown","43ff9786":"markdown","f3279d10":"markdown","3a4a7f31":"markdown","78a0f08e":"markdown","209d581a":"markdown","d103a361":"markdown","9e38be2e":"markdown","b2c7996d":"markdown","24e69716":"markdown","b0730532":"markdown","9a95e395":"markdown","bca4b914":"markdown","60324748":"markdown","80206838":"markdown","a633fb9d":"markdown","205c804d":"markdown","679f4f46":"markdown","d4a5530a":"markdown","5778b33d":"markdown"},"source":{"1b8357b5":"import pandas as pd  \ndataset  =  pd.read_csv('https:\/\/raw.githubusercontent.com\/insaid2018\/Term-3\/master\/Data\/CaseStudy\/AirPassengers.csv')\ndataset.head()","ab814215":"from datetime import datetime\n\ndataset['Month']  =  pd.to_datetime(dataset['Month'],infer_datetime_format = True)             #convert from string to datetime\n\nindexedDataset  =  dataset.set_index(['Month'])\nindexedDataset.head(5)","ccde3ed5":"import matplotlib.pylab as plt \n%matplotlib inline                        \n\nplt.xlabel('Yearl')\nplt.ylabel('Number of air passengers')\nplt.plot(indexedDataset)","e46af0b1":"from matplotlib.pylab import rcParams\nrcParams['figure.figsize']  =  10, 5\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomposed_dataset  =  seasonal_decompose(indexedDataset)         \nfigure  =  decomposed_dataset.plot()\nplt.show()","7400acc5":"def test_stationarity(time_series):\n    rolling_means(time_series)\n    adf_test(time_series)","dabfb0c8":"# Determine rolling statistics\ndef rolling_means(time_series):\n    rolmean  =  time_series.rolling(window = 12).mean()    #window size 12 denotes 12 months, giving rolling mean at yearly level\n    rolstd  =  time_series.rolling(window = 12).std()\n\n    #Plot rolling statistics\n\n    rcParams['figure.figsize']  =  10, 5 \n\n    orig  =  plt.plot(time_series, color = 'blue', label = 'Original')\n    mean  =  plt.plot(rolmean, color = 'red', label = 'Rolling Mean')\n    std  =  plt.plot(rolstd, color = 'black', label = 'Rolling Std')\n    plt.legend(loc = 'best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block = False)","10d09272":"rolling_means(indexedDataset)","d4501da6":"#Perform Augmented Dickey\u2013Fuller test:\ndef adf_test(time_series):\n    from statsmodels.tsa.stattools import adfuller\n    dftest  =  adfuller(time_series['#Passengers'], autolag = 'AIC')\n\n    dfoutput  =  pd.Series(dftest[0:4], index = ['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key]  =  value\n    \n    print('Results of Dickey Fuller Test:')    \n    print(dfoutput)","e651f656":"adf_test(indexedDataset)","7e0531f8":"import numpy as np\nindexedDataset_logScale  =  np.log(indexedDataset)\nrcParams['figure.figsize']  =  10, 5\nplt.plot(indexedDataset_logScale)","40dc8ef9":"test_stationarity(indexedDataset_logScale)","175dfaf2":"movingAverage  =  indexedDataset_logScale.rolling(window = 12).mean()\ndatasetLogScaleMinusMovingAverage  =  indexedDataset_logScale - movingAverage\nplt.plot(datasetLogScaleMinusMovingAverage)\n\n#Remove NAN values\ndatasetLogScaleMinusMovingAverage.dropna(inplace = True)\n","897b5d97":"test_stationarity(datasetLogScaleMinusMovingAverage)","402f8aeb":"exponentialDecayWeightedAverage  =  indexedDataset_logScale.ewm(halflife = 12, min_periods = 0, adjust = True).mean()\nplt.plot(indexedDataset_logScale)\nplt.plot(exponentialDecayWeightedAverage, color = 'red')","28d1df26":"test_stationarity(exponentialDecayWeightedAverage)","121b181e":"datasetLogScaleMinusExponentialMovingAverage  =  indexedDataset_logScale - exponentialDecayWeightedAverage\ntest_stationarity(datasetLogScaleMinusExponentialMovingAverage)","07238525":"datasetLogDiffShifting  =  indexedDataset_logScale - indexedDataset_logScale.shift()\nplt.plot(datasetLogDiffShifting)","7bdbdac9":"datasetLogDiffShifting.dropna(inplace = True)\n\ntest_stationarity(datasetLogDiffShifting)\n","17388849":"#ACF & PACF plots\n\nfrom statsmodels.tsa.stattools import acf, pacf\n\nlag_acf  =  acf(datasetLogDiffShifting, nlags = 20)\nlag_pacf  =  pacf(datasetLogDiffShifting, nlags = 20, method = 'ols')\nrcParams['figure.figsize']  =  10, 5\n#Plot ACF:\nplt.subplot(121)\nplt.plot(lag_acf)\nplt.axhline(y = 0, linestyle = '--', color = 'gray')\nplt.axhline(y = -1.96\/np.sqrt(len(datasetLogDiffShifting)), linestyle = '--', color = 'gray')\nplt.axhline(y = 1.96\/np.sqrt(len(datasetLogDiffShifting)), linestyle = '--', color = 'gray')\nplt.xticks(np.arange(0,22,2))\nplt.title('Autocorrelation Function')            \n\n#Plot PACF\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y = 0, linestyle = '--', color = 'gray')\nplt.axhline(y = -1.96\/np.sqrt(len(datasetLogDiffShifting)), linestyle = '--', color = 'gray')\nplt.axhline(y = 1.96\/np.sqrt(len(datasetLogDiffShifting)), linestyle = '--', color = 'gray')\nplt.xticks(np.arange(0,22,2))\nplt.title('Partial Autocorrelation Function')\n            \nplt.tight_layout()            ","bd677a19":"datasetLogDiffShifting.head()","d6ee3a1d":"# Data Preparation\ntrain, test = datasetLogDiffShifting[1:len(datasetLogDiffShifting)-7], datasetLogDiffShifting[len(datasetLogDiffShifting)-7:]\ntrain.head()","076252ac":"from statsmodels.tsa.ar_model import AR\nmodel = AR(train)\nmodel_fit = model.fit()\nprint('Lag: %s' % model_fit.k_ar)\nprint('Coefficients: %s' % model_fit.params)","080deca8":"# make predictions\npredictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)\npredictions.head()\nfor i in range(len(predictions)):\n    print('predicted=%f, expected=%f' % (predictions[i], test.iloc[i]))\n","c4ed67fb":"from sklearn.metrics import mean_squared_error\nfrom matplotlib import pyplot\nerror = mean_squared_error(test, predictions)\nprint('Test MSE: %.3f' % error)\n# plot results\n\npyplot.plot(test)\npyplot.plot(predictions, color='red')\npyplot.show()","c16b2e79":"plt.plot(train)\nplt.plot(model_fit.fittedvalues, color = 'red')\nprint('Plotting AR model')","d71de226":"from statsmodels.tsa.arima_model import ARMA\nmodel = ARMA(train,order=(2,2))\nmodel_fit = model.fit()\nprint('Lag: %s' % model_fit.k_ar)\nprint('Coefficients: %s' % model_fit.params)","e832d092":"# make predictions\npredictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)\nfor i in range(len(predictions)):\n    print('predicted=%f, expected=%f' % (predictions[i], test.iloc[i]))","326215dd":"from sklearn.metrics import mean_squared_error\nfrom matplotlib import pyplot\nerror = mean_squared_error(test, predictions)\nprint('Test MSE: %.3f' % error)\n# plot results\n\npyplot.plot(test)\npyplot.plot(predictions, color='red')\npyplot.show()","a94fadc3":"plt.plot(train)\nplt.plot(model_fit.fittedvalues, color = 'red')\nprint('Plotting ARMA model')","9737c25c":"plot = model_fit.plot_predict()","794a4674":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(datasetLogDiffShifting,order=(2,0,2))\nprint('Lag: %s' % model_fit.k_ar)\nprint('Coefficients: %s' % model_fit.params)","68de0a40":"results_ARIMA = model.fit()","0de238dc":"from sklearn.metrics import mean_squared_error\nfrom matplotlib import pyplot\nerror = mean_squared_error(datasetLogDiffShifting, results_ARIMA.fittedvalues)\nprint('Test MSE: %.3f' % error)","88f30f5f":"results_ARIMA.fittedvalues.head()","7ade9dca":"datasetLogDiffShifting.plot()\nresults_ARIMA.fittedvalues.plot(color='red')","21683042":"fitted_values = results_ARIMA.plot_predict()","6165080a":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\npredictions_ARIMA_diff.head()","87c6990d":"predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_cumsum.head()","492b98ee":"predictions_ARIMA_log = pd.Series(indexedDataset_logScale['#Passengers'].iloc[0], index=datasetLogDiffShifting.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head()","6054880d":"reverted_back_prediction = pd.DataFrame(np.exp(predictions_ARIMA_log))\nreverted_back_prediction.head()","c8370958":"from matplotlib import pyplot\npyplot.plot(indexedDataset)\npyplot.plot(reverted_back_prediction, color='red')\npyplot.show()","3f47126b":"indexedDataset_logScale.columns = ['Passengers in logscale']\nreverted_back_prediction.columns = ['ARIMA Predicted passengers']\ndatasetLogDiffShifting.columns = ['Passengers after log diff shifting']","4f1e3b1e":"df = pd.concat([indexedDataset,indexedDataset_logScale, datasetLogDiffShifting,reverted_back_prediction], axis=1, sort=False)\ndf.tail()","6fd9cba4":"results_ARIMA.plot_predict(1,264) ","1b241cb7":"ten_yr_forecast = results_ARIMA.predict(start=len(datasetLogDiffShifting),end = len(datasetLogDiffShifting) + 120 ) ","ddf04867":"predictions_ARIMA_diff = pd.Series(ten_yr_forecast, copy=True)\npredictions_ARIMA_diff.head()","4260b133":"predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_cumsum.head()","3a6b1995":"predictions_ARIMA_log = pd.Series(indexedDataset_logScale['Passengers in logscale'].iloc[-1], index=predictions_ARIMA_diff.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head()","1121cf7d":"reverted_back_prediction = pd.DataFrame(np.exp(predictions_ARIMA_log))\nreverted_back_prediction.head()","de0ea1cd":"from matplotlib import pyplot\npyplot.plot(indexedDataset)\npyplot.plot(reverted_back_prediction, color='red')\npyplot.show()","34fbd7bb":"#AR Model\n#making order = (2,1,0) gives RSS = 1.5023\n \nfrom statsmodels.tsa.arima_model import ARIMA\nmodel  =  ARIMA(indexedDataset_logScale, order = (2,1,0))\nresults_AR  =  model.fit()\nplt.plot(datasetLogDiffShifting)\nplt.plot(results_AR.fittedvalues, color = 'red')\nplt.title('RSS: %.4f'%sum((results_AR.fittedvalues - datasetLogDiffShifting['Passengers after log diff shifting'])**2))\nprint('Plotting AR model')","221ea644":"#MA Model\nmodel  =  ARIMA(indexedDataset_logScale, order = (0,1,2))\nresults_MA  =  model.fit()\nplt.plot(datasetLogDiffShifting)\nplt.plot(results_MA.fittedvalues, color = 'red')\nplt.title('RSS: %.4f'%sum((results_MA.fittedvalues - datasetLogDiffShifting['Passengers after log diff shifting'])**2))\nprint('Plotting MA model')","5a18ee12":"- p-value has __reduced__ from 0.99 to 0.022.  \n- The __critical values__ at 1%,5%,10% confidence intervals are pretty __close to the Test Statistic__.\n\nThus, from above 2 points, we can say that our given series is stationary.  \n\nFrom above graph, we observe that our intuition that *\"subtracting two related series having similar trend components will make the result stationary\"* is true.   \n\n\n\nBut, in the spirit of getting higher accuracy, let us explore & try to find a better scale than our current log.\n\nLet us try out Exponential decay.  ","57242e4f":"Time series deals with 2 columns,\n- one is temporal i.e: __month__ in this case &\n- another is the value to be forecasted ie: __airplane passengers__. <br\/>\n\n\nTo make plotting graphs easier, we set __Month as the index__ of pandas dataframe as during plots, the index will act by default as the x-axis & since it has only 1 more column, that will be automatically taken as the y-axis.","db9c68cd":"MSE is more than that obtained with AR model. <br\/>\nObserving the plot of <span style=\"color:blue\">**__expected__** <\/span> vs the <span style=\"color:red\">**__predicted__** <\/span>.\nThe forecast doesnt look good with large deviation at 3 and 5.","24ee7da5":"### Prediction & Reverse transformations of fittedvalues ","63a229b7":"- Observe that a __2-lag model__ was chosen and trained. ","5ce30c7e":"- Using AR model to forecast the number of passengers for __7 months__. \n- Dividing the dataset into __train and test__. Keeping last 7 months data for testing the performance of our time series model.","33f2e58c":"- __Model evaluation__ using Mean_squared_error","abd0c349":"- Deploying the autoregression model of __statsmodels library__ provided in the ar_model class.\n- It automatically selects an appropriate lag value using statistical tests and trains a linear regression model.","ce53eded":"![Imgur](https:\/\/i.imgur.com\/TOsgav1.jpg)","58155256":"- Observe that a __2-lag model__ was chosen and trained. ","30e58485":"### Forecasting the number of air passengers for the next 10 years","a4a37d1c":"- Note that, these models will give a value of RSS. __Lower RSS values indicate a better model.__","6a02256b":"### 4. Stationarity Check <a name = \"Stationarity Check\"><\/a>\n\nWe will see two methods two check stationarity. ","c311e81e":"#### 7.2 ARMA Model <a name = \"ARMA Model\"><\/a>","5af048b8":"We observe that the Time Series is stationary & also the series for moving avg & std. dev. is almost parallel to x-axis thus they also have no trend.  \nAlso,     \n1. p-value has __decreased__ from 0.022 to 0.005.  \n2. Test Statistic value is very __much closer__ to the Critical values.  \n\n\nBoth the points say that our current transformation is better than the previous logarithmic transformation. Even though, we couldn't observe any differences by visually looking at the graphs, the tests confirmed decay to be much better.\n\nBut lets try one more time & find if an even better solution exists. We will try out the simple time shift technique, which is simply:  \n\nGiven a set of observation on the time series:  \n$ x0, x1, x2, x3, .... xn $  \n\nThe shifted values will be:    \n$ null, x0, x1, x2,.... xn $                             <---- basically all xi's shifted by 1 pos to right  \n\nThus, the time series with time shifted values are:   \n$ null, (x1-x0), (x2-x1), (x3-x2), (x4-x3),.... (xn-x_{n-1}) $   ","0b7b85b0":"- __Model evaluation__ using Mean_squared_error","8b7c460a":"#### 5.2 Log Scale - Moving Average Transformation  <a name = \"Log Scale - Moving Average Transformation\"><\/a>","e8e6754f":"We see that our predicted forecasts are very close to the real time series values indicating a fairly accurate model.","91c44935":"For a Time series to be __stationary__, its ADF test should have:\n1. __low p-value__ (according to the null hypothesis)\n2. __Critical values__ at 1%, 5%, 10% confidence intervals should be as __close__ as possible __to__ the __Test Statistics__","2927ae7b":"### Prediction & Reverse transformations of 10 year forecast","e267abf2":"### 5. Data Transformation to achieve Stationarity <a name = \"Data Transformation to achieve Stationarity\"><\/a>\n\nThere are a couple of ways to achieve stationarity through data transformation like taking $log_{10}$,$log_{e}$, square, square root, cube, cube root, exponential decay, time shift and so on ...\n\nIn our notebook, lets start of with log transformations. ","5197b5a2":"### 7. Building Models <a name = \"Building Models\"><\/a>","6b9dad2f":"### 8. Extra Material  <a name = \"Extra Material\"><\/a>\n\nUsing ARIMA for making AR and MA models by setting the values of (p,d,q) as (2,1,0) and (0,1,2) respectively.","60feba66":"Let us forecaste deploying AR, ARMA and ARIMA model.","2795dc88":"- __Forecasting__ using the developed model and printing out the __7 month forecast__.","65bf0524":"### 5.4 Time Shift Transformation  <a name = \"Time Shift Transformation\"><\/a>","c5e54c4e":"## Table of contents\n1. [Objective](#Objective)\n2. [Data Loading and Visualization](#Data Loading and Visualization)\n3. [Decomposition](#Decomposition)\n4. [Stationarity Check](#Stationarity Check)<br\/>\n    4.1. [Rolling Statistics Methodology](#Rolling Statistics Methodology)<br\/>\n    4.2. [ADF(Augmented Dickey-Fuller)Test](#ADF)   \n5. [Data Transformation to achieve Stationarity](#Data Transformation to achieve Stationarity)<br\/>\n    5.1. [Log Scale Transformation](#Log Scale Transformation)<br\/>\n    5.2. [Log Scale - Moving Average Transformation](#Log Scale - Moving Average Transformation)<br\/>\n    5.3. [Exponential Decay Transformation](#Exponential Decay Transformation)<br\/>\n    5.4. [Time Shift Transformation](#Time Shift Transformation)<br\/>\n6. [Plotting ACF & PACF](#Plotting ACF & PACF)\n7. [Building Models](#Building Models)<br\/>\n    7.1. [AR Model](#AR Model)<br\/>\n    7.2. [ARMA Model](#ARMA Model)<br\/>\n    7.3. [ARIMA Model](#ARIMA Model)<br\/>\n8. [Extra Material ](#Extra Material )\n","b9505e0f":"### 6. Plotting ACF & PACF <a name = \"Plotting ACF & PACF\"><\/a>","fee2f3ec":"From the __ACF graph__, \n- Curve touches y = 0.0 line at x = 2. Thus, __Q  =  2__\n\n\nFrom the __PACF graph__,\n- Curve touches y = 0.0 line at x = 2. Thus, __P  =  2__\n\nARIMA is AR + I + MA. Before, we see an ARIMA model, let us check the results of the individual AR & MA model. Note that, these models will give a value of RSS. Lower RSS values indicate a better model.","a59badcc":"#### 4.2  ADF(Augmented Dickey-Fuller) Test <a name = \"ADF\"><\/a>","ad4da446":"- Rolling mean has a __trend__ component \n- Rolling standard deviation is fairly __constant__ with time.\n\nFor our time series to be stationary, we need to ensure that both the __rolling statistics__ i.e: __mean & stdandard deviation remain time invariant__ or constant with time. Thus the curves for both of them have to be parallel to the x-axis, which in our case is not so. \n\nTo further augment our hypothesis that the time series is not stationary, let us perform the __ADCF test__.","e1fd88bb":"### 2. Data Loading and Visualization <a name = \"Data Loading and Visualization\"><\/a>\n\n__Import the dataset__ ","937c0285":"From above graph, we see that even though rolling mean is __not stationary__, it is still better than the previous case, where no transfromation were applied to series. So we can atleast say that we are heading in the right direction.\n\nWe know from above graph that both the Time series with log scale as well as its moving average have a trend component. Thus we can apply a elementary intuition: subtraction one from the other should remove the trend component of both. Its like:  \n\n$log scale L  =  stationary part(L1) + trend(LT)$   \n$moving avg of log scale A  =  stationary part(A1) + trend(AT)$   \n$result series R  =  L - A  =  (L1+LT) - (A1+AT)  =  (L1-A1) + (LT-AT)$\n\nSince, L & A are series & it moving avg, their trend will be more or less same, Hence  \nLT-AT nearly equals to 0  \n\nThus trend component will be almost removed. And we have,  \n  \n$R  =  L1 - A1$, our final non-trend curve","b15d28c8":"Still not stationary","028b346a":"### 1. Objective <a name = \"Objective\"><\/a>\n- Build a model to forecast the demand ( passenger traffic) in Airplanes.\n- The data is classified in date\/time and the passengers travelling per month","6055dd82":"From the plot below, we can see that there is a __Trend compoenent__ in the series.<br\/> Now for better clarity lets decompose the time series in its constituent components. ","43ff9786":"From above graph, it seems that exponential decay is not holding any advantage over log scale as both the corresponding curves are similar.","f3279d10":"#### 5.1 Log Scale Transformation  <a name = \"Log Scale Transformation\"><\/a>","3a4a7f31":"Making a function to check stationarity in one go using both __rolling statistics plot and ADF test__.","78a0f08e":"## The End","209d581a":"#### 7.3 ARIMA Model <a name = \"ARIMA Model\"><\/a>","d103a361":"### 3. Decomposition <a name = \"Decomposition\"><\/a>","9e38be2e":"#### 4.1 Rolling Statistics Methodology <a name = \"Rolling Statistics Methodology\"><\/a>","b2c7996d":"- __Model evaluation__ using Mean_squared_error","24e69716":"- __large p-value__.\n- Also critical values (1%, 5%, 10%) are __no where close to__ the Test Statistics.\n\nHence, we can safely say that **our Time Series at the moment is not stationary**","b0730532":"- Training ARIMA model with __stationary__ made dataset \"datasetLogDiffShifting\" using the (p,d,q) = __(2,0,2)__. \n- p and q values are chosen considering observations of ACF and PACF plots.","9a95e395":"### 5.3 Exponential Decay Transformation   <a name = \"Exponential Decay Transformation \"><\/a>","bca4b914":"Observing the plot of <span style=\"color:blue\">**__expected__** <\/span> vs the <span style=\"color:red\">**__predicted__** <\/span>.\n\nThe forecast does look pretty good with slightly large deviation on month 4.","60324748":"- Alternatively you can also use __plot_predict()__ method. ","80206838":"#### 7.1 AR Model <a name = \"AR Model\"><\/a>","a633fb9d":"- We have 144(existing data of 12 yrs in months) data points. <br\/>\nTo forecast additional 120 data points or __10 yrs__.\n- Using plot_predict method","205c804d":"- Observe that a __13-lag model__ was chosen and trained. This is interesting given how close this lag is to the number of months in a year.","679f4f46":"From above 2 graphs, we can see that, visually this is the best result as our series along with rolling statistic values of moving avg & moving std. dev. is very much flat & stationary. But, the ADCF test shows us that:\n1. p-value of 0.07 is not as good as 0.005 of exponential decay.  \n2. Test Statistic value not as close to the critical values as that for exponential decay.  \n  \nWe have thus tried out 3 different transformation: log, exp decay & time shift. We will go ahead with the __timeshifted dataset.__ ","d4a5530a":"- Alternatively you can also use __plot_predict()__ method. ","5778b33d":"- __Forecasting__ using the developed model and printing out the __7 month forecast__."}}