{"cell_type":{"610ad88d":"code","a1629bea":"code","9213ff62":"code","0c70d982":"code","2f8b9496":"code","cb53345f":"code","44916cd3":"code","8591a90a":"code","b6c712c6":"code","1f386a22":"code","83be8649":"code","cfabe511":"code","abe0fe84":"code","66e65f53":"code","eaf9213d":"code","b34d59c9":"code","55007612":"code","ff8d4f82":"code","c487fe51":"code","2c2c0997":"code","75f0ba41":"code","786b48f2":"code","0506716d":"code","6e2d1757":"code","e9e231a4":"code","9ea22147":"code","fa58449e":"code","ba352e30":"code","4fab5123":"markdown","687d07cf":"markdown","2d254452":"markdown","3a7eff08":"markdown","dcecb5fa":"markdown","fe10122c":"markdown","4c49f4ce":"markdown","f4fa7712":"markdown","dcf2b70d":"markdown","852e4389":"markdown","ce2a7b66":"markdown","839a3f0d":"markdown","88e87b25":"markdown","b664ef67":"markdown","327df8dc":"markdown","721ef1ff":"markdown","7cb8d469":"markdown","614ccc23":"markdown","de4447f0":"markdown","c90db48e":"markdown","3e31a90f":"markdown","78f13383":"markdown","a8fa7d77":"markdown"},"source":{"610ad88d":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # plotting\nfrom sklearn.metrics import mean_squared_error # MSE metric\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostClassifier\nfrom catboost import Pool \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom imblearn.over_sampling import SMOTENC\nimport shap as shap\n#import pandas_profiling as pp # Auto EDA\n\nSEED = 91 # random seed","a1629bea":"# Input data files are available in the read-only \"..\/input\/\" directory\nPATH = '\/kaggle\/input\/30-days-of-ml\/' # you can use your own local path\n\nprint('Files in directory:')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print('  '+os.path.join(dirname, filename))\nprint()\n\n# Load the training data\ntry:\n    df_train = pd.read_csv(PATH+'train.csv', index_col=0)\n    df_test = pd.read_csv(PATH+'test.csv', index_col=0)\n    submission = pd.read_csv(PATH+'sample_submission.csv', index_col=0)\n    print('All of the data has been loaded successfully!')\nexcept Exception as err:\n    print(repr(err))\nprint()","9213ff62":"print(f\"Train data length: {len(df_train)}\")\nprint(f\"Test data length: {len(df_test)}\")","0c70d982":"df_train.head()","2f8b9496":"df_train.info()","cb53345f":"df_test.info()","44916cd3":"CAT_FEATURES = ['cat1', 'cat6', 'cat7', 'cat8', 'cat9']\nNUM_FEATURES = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8',\n                'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\nALL_FEATURES = CAT_FEATURES+NUM_FEATURES","8591a90a":"df_train[NUM_FEATURES].describe()","b6c712c6":"sns.pairplot(df_train[[\n    *NUM_FEATURES[:7],\n    'target'\n]])","1f386a22":"sns.pairplot(df_train[[\n    *NUM_FEATURES[7:],\n    'target'\n]])","83be8649":"df_train['target'].describe()","cfabe511":"f,ax=plt.subplots(2,1,figsize=(12,8))\n#plt.title('Target values', fontsize=16)\nsns.histplot(df_train['target'], ax=ax[0])\nsns.boxplot(x=df_train['target'], color='lightblue', saturation=0.8, ax=ax[1])\nplt.axvline(np.percentile(df_train['target'],.1), label='.1%', c='orange', linestyle=':', linewidth=3)\nplt.axvline(np.percentile(df_train['target'],.5), label='.5%', c='darkblue', linestyle=':', linewidth=3)\nplt.legend()\nplt.xticks(np.arange(0,10.8,.5))\nplt.show()","abe0fe84":"corrMatrix = df_train.corr(method='pearson', min_periods=1)\nplt.figure(figsize=(15,10))\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corrMatrix, dtype=bool))\nax = sns.heatmap(corrMatrix, annot=True, mask=mask, cbar_kws={\"shrink\": .5})\nplt.show()","66e65f53":"TARGET_TRESHOLD = 6.9 # manualy choice\ndf_train[df_train['target'] < TARGET_TRESHOLD]['target'].describe()","eaf9213d":"df_train['target_outlier'] = df_train['target'].apply(lambda x: 1 if (x < TARGET_TRESHOLD) else 0)","b34d59c9":"df_train[['target', 'target_outlier']].groupby('target_outlier').agg(['count', 'mean'])","55007612":"df_train[[*NUM_FEATURES, 'target_outlier']].groupby('target_outlier').agg('mean')","ff8d4f82":"df_train[[*NUM_FEATURES, 'target_outlier']].groupby('target_outlier').agg('median')","c487fe51":"df = df_train[df_train['target_outlier'] == 1]","2c2c0997":"sns.pairplot(df[[\n    *NUM_FEATURES[:7],\n    'target'\n]])","75f0ba41":"sns.pairplot(df[[\n    *NUM_FEATURES[7:],\n    'target'\n]])","786b48f2":"X = df_train[ALL_FEATURES]\ny = df_train['target_outlier']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=SEED)\n\nprint(np.bincount(y_train.values))\noversample = SMOTENC(categorical_features=[i for i in range(len(CAT_FEATURES))], sampling_strategy=0.2, random_state=SEED)\nX_train, y_train = oversample.fit_resample(X_train, y_train)\nprint(np.bincount(y_train.values))","0506716d":"catboost_classifier_params = {\n    'class_weights': [1,2],\n    'cat_features': CAT_FEATURES,\n    #'iterations': 15000,\n    'iterations': 7000,\n    'early_stopping_rounds': 30,\n    #'task_type': 'GPU',\n    'verbose': 1000,\n    'random_seed': SEED,\n}","6e2d1757":"model_classifier = CatBoostClassifier(**catboost_classifier_params)\nmodel_classifier.fit(X_train, y_train,\n          eval_set=(X_val, y_val))\n\npredicted = model_classifier.predict(X_val)","e9e231a4":"print(f\"Accuracy: {accuracy_score(y_val, predicted)}\")\nprint(f\"Recall: {recall_score(y_val, predicted)}\")\nprint(f\"Precision: {precision_score(y_val, predicted)}\")\nprint(f\"ROC-AUC: {roc_auc_score(y_val, predicted)}\")\ndf_cm = pd.DataFrame(confusion_matrix(y_val, predicted), columns=np.unique(y_val), index = np.unique(y_val))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='g')# font size","9ea22147":"# Plot ROC curve\ndef plot_roc_curve(fpr=None, tpr=None):\n    \"\"\"Plot custom histogram\"\"\"\n    plt.figure(figsize=(5,5))\n    plt.title('ROC-curve', fontsize=16)\n    plt.xlabel('False Positive Rate', fontsize=14)\n    plt.ylabel('True Positive Rate', fontsize=14)\n    \n    plt.plot(fpr, tpr)\n\n    # ROC-curve of random model\n    plt.plot([0, 1], [0, 1], linestyle='--')\n    \n    plt.ylim([0.0, 1.0])\n    plt.xlim([0.0, 1.0])\n    plt.grid(True)\n    \n    plt.show()\n    \n\nprobabilities_valid = model_classifier.predict_proba(X_val)\nfpr, tpr, thresholds = roc_curve(y_val, probabilities_valid[:,1])\nplot_roc_curve(fpr, tpr)","fa58449e":"feature_importance_df = pd.DataFrame(model_classifier.feature_importances_, index=X_train.columns)\nfeature_importance_df.sort_values(by=0, ascending=False)","ba352e30":"train_data = Pool(data=X_train,\n                  label=y_train,\n                  cat_features=CAT_FEATURES\n                 )\n                 \nexplainer = shap.TreeExplainer(model_classifier)\nshap_values = explainer.shap_values(train_data)\nshap.summary_plot(shap_values, X_train, feature_names=ALL_FEATURES)","4fab5123":"Add new features as target outlier or not","687d07cf":"Quantile 25% is 7.74 but min is 0.14. We have outliers at the bottom.","2d254452":"Additionally we use weights for classes as 1:2","3a7eff08":"We observe a certain boundary of target values. Target has outliers in left tail.","dcecb5fa":"**Extremely bad result!**","fe10122c":"# 3. Data preproccesing","4c49f4ce":"There is no significance difference of continous features if target outlier or not ","f4fa7712":"There's no significance linear correlation.","dcf2b70d":"## Correlation matrix","852e4389":"### Continuous features","ce2a7b66":"Let's look on continous features when target class is outlier","839a3f0d":"# 4. Train Model\n\nApply upsampling technique using SMOTE library.\nGenerate minor class up to 20% of major class.","88e87b25":"# 2. Exploratory Data Analysis (EDA)","b664ef67":"# Model evaluate","327df8dc":"### Import libraries","721ef1ff":"# 1. Load data and first look","7cb8d469":"**Conclusion: We can't divide target into 2 classes. Features are very similar when target is outlier or not.**","614ccc23":"Use only meaningful features obtained in prevous version on feature importance","de4447f0":"### Target","c90db48e":"We can see that visible difference has relationship cont1-target","3e31a90f":"No missing values in dataset","78f13383":"#### If you find it useful please upvote","a8fa7d77":"## <center>30 Days of ML competition<\/center>\n### <center>Target classification with CatBoost<\/center>\n\nFeature engineering is important aspects in Kaggle competitions. In this notebook I classificate continous target into 2 classes using threshold. Then train classification model so we could predict class in test data and add target class as feature.\n\n\n#### Dataset:\nThe dataset is used for this competition is synthetic (and generated using a CTGAN), but based on a real dataset. The original dataset deals with predicting the amount of an insurance claim. \n* 'cat0' - 'cat9' categorical features\n* 'cont0' - 'cont13' continuous features\n* 'target' - continous target\n\nAlthough the features are anonymized, they have properties relating to real-world features."}}