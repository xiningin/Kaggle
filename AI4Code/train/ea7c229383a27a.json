{"cell_type":{"7ed348da":"code","165bf7e1":"code","8bbff6f8":"code","adfbe420":"code","e33a7bbb":"code","cb4c9f1a":"code","8ca589fa":"code","b465ad43":"code","dda23237":"code","bce7a3c1":"code","4f8b23f4":"code","ac00e0ac":"code","fb77e9ef":"code","77cecb3e":"markdown","3ad20b9f":"markdown"},"source":{"7ed348da":"import warnings\nwarnings.filterwarnings('ignore')\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nimport pandas as pd\nimport numpy as np \nimport random \nimport cv2 \nimport os","165bf7e1":"# Load train and test data \ntrain_data = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\n\n# Store the paths \ntrain_path = '\/kaggle\/input\/petfinder-pawpularity-score\/train\/'\ntest_path = '\/kaggle\/input\/petfinder-pawpularity-score\/test\/'","8bbff6f8":"# Visualize some random images \nimage_list = os.listdir('\/kaggle\/input\/petfinder-pawpularity-score\/train\/')\nIMG_SIZE = 512\nrandom.seed(0)\n\nfor i in range(3):\n    ax = plt.subplot(3, 3, i + 1)\n    random_img = random.choice(image_list)\n    x = random_img.split('.')[0]\n    img = cv2.imread(os.path.join(train_path,random_img))\n    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n    pawpularity = train_data.loc[train_data['Id'] == x, 'Pawpularity'].item()\n    plt.title(f'{pawpularity}.')\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.show()","adfbe420":"class DataProcessing(): \n    '''\n    Class for creating training and test data. Combines feature extraction with meta-features.\n    Returns featues from the images along with the corrsponding meta-data. \n    '''\n    def __init__(self,train_df,train_path,test_df,test_path,IMG_SIZE):\n        self.augmentation = None \n        self.normalization = None  \n        self.model = None \n        \n        self.train_path = train_path\n        self.train_df = train_df\n        self.test_path = test_path \n        self.test_df = test_df\n        self.IMG_SIZE = IMG_SIZE \n        self.meta_features = ['Subject Focus','Eyes','Face','Near','Action','Accessory',\\\n                              'Group','Collage','Human','Occlusion','Info','Blur']\n        \n        self.transform = A.Compose([ A.CLAHE(),\n                                    A.HorizontalFlip(),\n                                    A.RandomRotate90(),\n                                    A.Transpose(),\n                                    A.ShiftScaleRotate(shift_limit=0.0425,\n                                                       scale_limit=0.40, \n                                                       rotate_limit=25),\n                                    A.HueSaturationValue()])\n        \n        self.normalize = A.Normalize(mean=[0.485, 0.456, 0.406],\n                                    std=[0.229, 0.224, 0.225],\n                                    max_pixel_value=255.0,\n                                    p=1.0)\n        \n    def feature_extractor(self):\n        # Load base model \n        base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n        # Freeze the base model (so the pre-learned patterns remain)\n        base_model.trainable = False\n        # Inputs to the base model\n        inputs = tf.keras.layers.Input(shape=(self.IMG_SIZE, self.IMG_SIZE, 3), name=\"input_layer\")\n        x = base_model(inputs)\n        # Apply global average pooling to the outputs of the base model to aggregate the most important features\n        outputs = tf.keras.layers.GlobalAveragePooling2D(name=\"average_pooling_layer\")(x)\n        model = tf.keras.Model(inputs, outputs)\n        return model \n        \n    def create_training_data(self,target_col,normalization=False,augmentation=False):\n        X = []; y = []; meta = []\n        # Initialize the model for feature extraction\n        self.model = self.feature_extractor()\n        train_img_ids = self.train_df['Id']\n        meta_data = np.array(self.train_df[self.meta_features])\n        for i,img in enumerate(train_img_ids):\n            try:\n                # Get the label of the current img \n                label = self.train_df.loc[self.train_df['Id'] == img, target_col].item()\n                # Add the jpg to the relative path \n                img += '.jpg'\n                # Read and resize the image \n                img = cv2.imread(os.path.join(self.train_path,img))\n                img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n                # Apply image-augmentation if desired\n                if self.augmentation:\n                    img = self.transform(image=img)[\"image\"]\n                # Apply normalization if desired \n                if self.normalization:\n                    img = self.normalize(image = img)['image']\n                # Reshape the img\n                img = img.reshape(1,IMG_SIZE,IMG_SIZE,3)\n                # Extract features using transfer learning\n                img = self.model.predict(img)\n                # Get the meta features for the current img \n                meta_features = meta_data[i]\n                X.append(img.squeeze())\n                y.append(label)\n                meta.append(meta_features)\n            except Exception as e:\n                print(e)     \n        return X, y, meta                \n    \n    def create_test_data(self,normalization=False):\n        X = [] ; meta = []\n        self.model = self.feature_extractor()\n        test_img_ids = self.test_df['Id']\n        meta_data = np.array(self.test_df[self.meta_features])\n        for i,img in enumerate(test_img_ids):\n            try:\n                img += '.jpg'\n                img = cv2.imread(os.path.join(self.test_path,img))\n                img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n                if self.normalization:\n                    img = self.normalize(image = img)['image']\n                img = img.reshape(1,IMG_SIZE,IMG_SIZE,3)\n                img = self.model.predict(img)\n                meta_features = meta_data[i]\n                X.append(img.squeeze())\n                meta.append(meta_features)\n            except Exception as e:\n                print(e)      \n        return X, meta","e33a7bbb":"# Create the training data \npreprocessing = DataProcessing(train_data,train_path,test_data,test_path,IMG_SIZE=512)\nX,y,meta_data = preprocessing.create_training_data(target_col='Pawpularity')\n\nX = np.array(X,dtype=np.float32)\ny = np.array(y,dtype=np.float32)\nmeta_data = np.array(meta_data)","cb4c9f1a":"from sklearn.model_selection import train_test_split\nX_train_img, X_test_img, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train_meta, X_test_meta, y_train, y_test = train_test_split(meta_data,y, test_size=0.1, random_state=42)","8ca589fa":"# Build a new model for classification using tensorflow's functional API\ninputs_meta = tf.keras.layers.Input(shape= X_train_img[0].shape, name=\"input_meta_layer\")\ninputs_img = tf.keras.layers.Input(shape= X_train_meta[0].shape, name=\"input_img_layer\")\n# Concatenate both inputs\nmerged = tf.keras.layers.Concatenate()([inputs_meta, inputs_img])\nx = tf.keras.layers.Dense(3000, kernel_initializer='normal',activation = tf.keras.layers.LeakyReLU())(merged)\nx = tf.keras.layers.Dense(2000, kernel_initializer='normal',activation = tf.keras.layers.LeakyReLU())(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Dense(512, kernel_initializer='normal',activation = tf.keras.layers.LeakyReLU())(x)\nx = tf.keras.layers.Dense(256, kernel_initializer='normal',activation = tf.keras.layers.ReLU())(x)\nx = tf.keras.layers.Dense(512, kernel_initializer='normal',activation = tf.keras.layers.ReLU())(x)\nx = tf.keras.layers.Dropout(0.1)(x)\noutputs = tf.keras.layers.Dense(1,kernel_initializer='normal')(x)\nmodel = tf.keras.Model(inputs = [inputs_meta, inputs_img], outputs =outputs )\nmodel.summary()\n# Plot the model's architecture \ntf.keras.utils.plot_model(model,show_shapes=True,rankdir='TB',expand_nested=False,dpi=56)","b465ad43":"# Create a directory for saving the best model \ndirectory = '\/kaggle\/working\/trained_model'\nos.mkdir(directory)","dda23237":"import tensorflow.keras.backend as K\nEPOCHS = 450 \n\n# Define the rmse for tracking model performance \ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n\n# Define the optimizer\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.00003, momentum=0.9)\n\n# Compile the model \nmodel.compile(loss= rmse,\n                  optimizer=optimizer, \n                  metrics=tf.keras.metrics.RootMeanSquaredError())\n\n# Create checkpoints \ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='\/kaggle\/working\/trained_model',\n                                                monitor = 'val_root_mean_squared_error', \n                                                verbose = 0, \n                                                save_best_only = True)\n# Save history \nhistory = model.fit([X_train_img,X_train_meta],y_train,validation_data = ([X_test_img,X_test_meta],y_test),\n                        epochs=EPOCHS, verbose=0, callbacks=[checkpoint])\n\n\n# Plot the model's loss curves \npd.DataFrame(history.history).plot()\nplt.ylabel(\"loss\")\nplt.xlabel(\"epochs\")\nplt.show()\n","bce7a3c1":"# Load the best model \nmodel = tf.keras.models.load_model('\/kaggle\/working\/trained_model',compile=False)\n# Utilize the best model for making predictions  \npredictions = model.predict([X_test_img,X_test_meta]).squeeze().round()\n# Get the error of the predictions with the true labels\nrmse(predictions,y_test) ","4f8b23f4":"# Load test data and make predictions \ntest_features,test_meta = preprocessing.create_test_data()\npredictions = model.predict([np.array(test_features),np.array(test_meta)])\npredictions = predictions.squeeze().squeeze()\ntest_data['Pawpularity'] = predictions ","ac00e0ac":"test_data = test_data[[\"Id\", \"Pawpularity\"]]\ntest_data.to_csv(\"submission.csv\", index=False)","fb77e9ef":"test_data","77cecb3e":"## **Since we are loading the data from a directory and utilizing the meta-features (and labels) from a dataframe, we will create a flexible class that allows us to create both training and test data easily.**\n## **Pixel-normalization can be applied, and image augmentation for the training data, although we need to be careful to not have any conflict with the meta-features (e.g. additional blur).**","3ad20b9f":"## **In this notebook we will be applying a flexible approach for loading and preprocessing the data that will allow for swiflty experimenting between different strategies.** \n## Particularly, this notebook covers:\n\n* **Transfer Learning-Feature Extraction**\n* **Data Augmentation** \n* **Exploiting meta features** \n* **Creating a model with multiple inputs** \n* **Saving the best model and making predictions**"}}