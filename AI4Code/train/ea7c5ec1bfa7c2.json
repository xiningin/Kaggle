{"cell_type":{"2b86d235":"code","c32853e1":"code","6809580f":"code","fafc01e3":"code","820119ad":"code","17ad2345":"code","c6af5cbd":"code","29080bae":"code","89b60eb4":"code","e1e1a50f":"code","81574210":"code","fefb4bc7":"code","0a6bd7d7":"code","b00d30f6":"code","919f001e":"code","27cba266":"code","2157a473":"code","becfe7b9":"code","314bc999":"code","eb4e0d31":"markdown","03223912":"markdown","f2f9cb33":"markdown","e566a412":"markdown","5baf6b1a":"markdown","f9531921":"markdown","21cba89b":"markdown","ee783e87":"markdown","112279df":"markdown","e3763ccd":"markdown","08ff27ed":"markdown","51fc62b0":"markdown","a10390a7":"markdown","84261297":"markdown","17070d09":"markdown","fbff978e":"markdown","bd00e9f4":"markdown","48851fe9":"markdown","e52479b9":"markdown","71b0589a":"markdown"},"source":{"2b86d235":"!pip install mlforecast","c32853e1":"from copy import copy\nfrom functools import partial\nfrom pathlib import Path\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nfrom mlforecast.core import TimeSeries\nfrom mlforecast.forecast import Forecast\nfrom window_ops.rolling import rolling_mean","6809580f":"input_path = Path('..\/input\/m5-preprocess\/processed\/')\n\ndata = pd.read_parquet(input_path\/'sales.parquet')\ndata","fafc01e3":"dates = sorted(data['date'].unique())\ndata = data[data['date'] >= dates[349]]\ndata.shape","820119ad":"data = data.rename(columns={'id': 'unique_id', 'date': 'ds'})\ndata = data.set_index('unique_id')\ndata","17ad2345":"prices = pd.read_parquet(input_path\/'prices.parquet')\nprices","c6af5cbd":"cal = pd.read_parquet(input_path\/'calendar.parquet')\ncal = cal.rename(columns={'date': 'ds'})\ncal.head()","29080bae":"lgb_params = {\n    'objective': 'poisson',\n    'metric': 'rmse',\n    'force_row_wise': True,    \n    'learning_rate': 0.075,\n    'bagging_freq': 1,\n    'bagging_fraction': 0.75,\n    'lambda_l2': 0.1,\n    'n_estimators': 1200,\n    'num_leaves': 128,\n    'min_data_in_leaf': 100,\n}\n\nmodel = lgb.LGBMRegressor(**lgb_params)\nmodel","89b60eb4":"ts = TimeSeries(\n    freq='D',\n    lags=[7, 28],\n    lag_transforms = {\n        7:  [(rolling_mean, 7), (rolling_mean, 28)],\n        28: [(rolling_mean, 7), (rolling_mean, 28)],\n    },\n    date_features=['year', 'month', 'day', 'dayofweek', 'quarter', 'week'],\n)\nts","e1e1a50f":"fcst = Forecast(model, ts)","81574210":"%%time\nfeatures_df = fcst.preprocess(\n    data,\n    dropna=True,\n    keep_last_n=28+27,\n    static_features=['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n)\ndel data","fefb4bc7":"features_df.columns","0a6bd7d7":"np.random.seed(11)\ntrain_mask = np.random.rand(features_df.shape[0]) < 0.95\ntrain, valid = features_df[train_mask], features_df[~train_mask]\nX_train, y_train = train.drop(columns=['ds', 'y']), train.y\nX_valid, y_valid = valid.drop(columns=['ds', 'y']), valid.y\ndel features_df, train, valid","b00d30f6":"%time fcst.model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], verbose=20)","919f001e":"def my_predict_fn(model, new_x, features_order, alpha):\n    new_x = new_x.reset_index()  # remove unique_id for sorting later\n    new_x = new_x.merge(cal)\n    new_x = new_x.merge(prices)\n    new_x = new_x.sort_values('unique_id')\n    new_x = new_x[features_order]\n    predictions = model.predict(new_x)\n    return alpha * predictions","27cba266":"fcst.ts.num_threads","2157a473":"%%time\nalphas = [1.028, 1.023, 1.018]\npreds = None\nfor alpha in alphas:\n    alpha_preds = fcst.predict(28, my_predict_fn, alpha=alpha)\n    alpha_preds = alpha_preds.set_index('ds', append=True)\n    if preds is None:\n        preds = 1 \/ 3 * alpha_preds\n    else:\n        preds += 1 \/ 3 * alpha_preds\npreds","becfe7b9":"wide = preds.reset_index().pivot_table(index='unique_id', columns='ds')\nwide.columns = [f'F{i+1}' for i in range(28)]\nwide.columns.name = None\nwide.index.name = 'id'\nwide","314bc999":"sample_sub = pd.read_csv(\n    '..\/input\/m5-forecasting-accuracy\/sample_submission.csv', index_col='id'\n)\nsample_sub.update(wide)\nnp.testing.assert_allclose(sample_sub.sum().sum(), preds['y_pred'].sum())\nsample_sub.to_csv('submission.csv')","eb4e0d31":"Metadata for predictions","03223912":"## Data loading","f2f9cb33":"## Forecast setup","e566a412":"If we only want to preprocess our data and train on all of it we can just call `Forecast.fit`. In this case we're going to make a train-valid split to get some information on the training, so we instead call `Forecast.preprocess` to get the dataframe with all our features and (internally) save the information for the forecasting step. `Forecast.preprocess` takes the following additional arguments:\n\n* **dropna**: whether or not to drop rows with null values after building all the features. Using lags and transformations on the lags generates many rows with `np.nan`s, this is a flag to indicate whether we want to drop them when we're done.\n* **keep_last_n**: keep only last `n` samples from each time serie after computing the features. The updates are performed by applying the transformations on the series again and taking only the last value. This can save memory if you have very long series and your transformations only use a small window, like in this case where we have series with thousands of data points and our transformations require only 28 (lag) + 27 (window) samples.\n* **static_features**: define which features are static. By default all extra columns (other than **ds** and **y**) are considered static and are replicated when building the features for the next timestep, setting this overrides that and repeats only the ones defined here.","5baf6b1a":"### Define forecaster\nOnce we have our model and flow configuration setup, we instantiate a `Forecast` object with them.","f9531921":"## Libraries","21cba89b":"Calling `Forecast.fit` performs the preprocessing step as well. If we've already done that we just call `Forecast.model.fit` instead.","ee783e87":"# M5 using mlforecast\n\n[mlforecast](https:\/\/nixtla.github.io\/mlforecast\/) is a framework to perform time series forecasting using machine learning models. It abstracts away most of the details and tries to mimic the scikit-learn API.\n\nThis notebook is inspired by https:\/\/www.kaggle.com\/kneroma\/m5-first-public-notebook-under-0-50.","112279df":"The names of the transformations are built using the name of the function and its arguments.\n\nThe order is always:\n1. Static features\n2. Lags\n3. Lag transforms\n4. Date features","e3763ccd":"Perform a train-valid split with 95% on train and 5% on valid.","08ff27ed":"## Submission","51fc62b0":"### TimeSeries\nThis is where we define the features. A brief description of each argument:\n\n* **freq**: frequency of our time series. This is a pandas abbreviation and is used to get the next dates when computing the predictions.\n* **lags**: lags that we want to use as features.\n* **lag_transforms**: dictionary where the keys are the lags that we want to use and the values are a list of transformations to apply to them. The transformations are defined as `numba` jitted functions. If the function takes more arguments than the input array, these are passed as a tuple `(func, arg1, arg2, ...)`.\n* **date_features**: date attributes to use for training. These are computed from the `ds` column and are updated in each timestep.\n* **num_threads**: number of threads to use in preprocessing and updates, defaults to all cpus. Since the transformations are `numba` jitted functions, we can use multithreading to compute our features.","a10390a7":"mlforecast requires a dataframe with an index named **unique_id** which identifies each time serie, a column **ds** containing the datestamps and a column **y** with the series values.","84261297":"## Predictions","17070d09":"These are all sales in the dataset, however due to memory limitations we'll take from the 350th day onwards.","fbff978e":"### Model","bd00e9f4":"Calling `Forecast.predict(horizon)` computes the predictions for the next `horizon` steps. We can also provide a custom `predict_fn` like we do in this case, using `my_predict_fn` defined above. This step uses multithreading if `num_threads` was set to a value greater than 1 or was left empty and you have more than 1 cpu (here we have 4).","48851fe9":"## Training","e52479b9":"There are two inputs needed: a regressor that follows the scikit-learn API and a time series object which defines the features to be computed.","71b0589a":"By default the predictions are computed repeating the static features and updating the transformations and the date features. If you want to do something different you can define your own predict function as explained [here](https:\/\/nixtla.github.io\/mlforecast\/forecast.html#Custom-predictions)."}}