{"cell_type":{"26b790a3":"code","725d809c":"code","7e8247c5":"code","d309fc38":"code","a78150d5":"code","85a10bca":"code","067ac6c5":"code","cf6aa412":"code","ec2dcc20":"code","e02de1e8":"markdown","70f9017f":"markdown"},"source":{"26b790a3":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","725d809c":"data_path = '..\/input\/'\n\n# read data\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nprint('train_data shape is :' + str(train.shape))\nprint('test_data shape is :' + str(test.shape))","7e8247c5":"# form train.csv => split data to train and validation using stratified random shuffling\nstrat_train_set = []\nstrat_val_set = []\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=76)\nfor train_index, val_index in split.split(train, train['label']):\n    strat_train_set = train.loc[train_index]\n    strat_val_set = train.loc[val_index]","d309fc38":"X_train = strat_train_set.drop(labels=['label'], axis=1)\nX_val = strat_val_set.drop(labels=['label'], axis=1)\n\nY_train = strat_train_set['label']\nY_val = strat_val_set['label']\n\n# Free some memmory\ndel strat_val_set\ndel strat_train_set","a78150d5":"# one-hot encoding\nY_train = to_categorical(Y_train, num_classes = 10)\nY_val = to_categorical(Y_val, num_classes = 10)\n# reshape\nX_train = X_train.values.reshape(-1,28,28,1).astype(np.float32)\nX_val = X_val.values.reshape(-1,28,28,1).astype(np.float32)\ntest = np.array(test).reshape(-1,28,28,1).astype(np.float32)\n# Preprocess test,validation and train data\ntest\/=255.0\nX_train\/=255.0\nX_val\/=255.0","85a10bca":"# define model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='elu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='elu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='elu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='elu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"elu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\n# Compile the model\nmodel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","067ac6c5":"epochs = 32\nbatch_size = 64\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n# data augmentation\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","cf6aa412":"# train the model\nhist = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","ec2dcc20":"# ready prediction on test set for submitting...\npreds = model.predict(test)\nindex = [i for i in range(1,len(preds)+1)]\nresult = []\nfor i in range(len(preds)):\n    result.append(np.argmax(preds[i]).astype(np.int))\n\nout = pd.DataFrame({'ImageId':index,'Label':result})\n\nout.to_csv(\"cnn_mnist_submission.csv\",index=False)","e02de1e8":"Special thanks to :Yassine Ghouzam's kernel\nThis is my code that acheived 99.6% acc.","70f9017f":"**Preprocessing**\n\n1.apply one-hot encoding on labels\n\n2.reshape data to 28*28 2D array image\n\n![](http:\/\/)3.scale intensities between 0 to 1"}}