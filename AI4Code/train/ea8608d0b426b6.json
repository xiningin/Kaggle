{"cell_type":{"ee6bb3de":"code","627370cd":"code","3dbb5469":"code","c69b8a94":"code","55a44d83":"code","17a5ca90":"code","77a00127":"code","d303977a":"code","82ab7e95":"code","aa88b903":"code","aa52ffd6":"code","c95cdaf7":"code","837541b2":"code","2121e754":"code","25adbc2a":"code","618ca6ce":"code","a5fd9a89":"code","583d48c9":"code","02186a59":"code","13b3e104":"code","35da1d73":"code","b687eec3":"code","7dec8f01":"code","57683c7f":"code","23abe80a":"code","ca80fa2e":"code","73878250":"code","e0c0c8af":"code","ed52b2ec":"code","b86c8cae":"code","e28ecb20":"code","764d8e7d":"code","6fd91fc5":"code","5eed3af7":"code","6b747ae6":"code","6bebb1eb":"code","2dc0a1e4":"markdown","371f81df":"markdown","be6d9130":"markdown","31d8d1a2":"markdown","0ef8f938":"markdown","84732cdd":"markdown","6eeeb68f":"markdown","f62b25e2":"markdown","a2b99beb":"markdown","ed3e2a29":"markdown","bc42721b":"markdown","af3fa221":"markdown","7f6c4f90":"markdown","d2f92537":"markdown","dd05c597":"markdown"},"source":{"ee6bb3de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","627370cd":"path = '\/kaggle\/input\/siim-isic-melanoma-classification'\ndf_train = pd.read_csv(f\"{path}\/train.csv\")\ndf_test = pd.read_csv(f\"{path}\/test.csv\")","3dbb5469":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly","c69b8a94":"print(f'Train\/Test ratio: {df_train.shape[0]\/df_test.shape[0]}')","55a44d83":"print(f\"Train Male-female ratio: {df_train.loc[df_train['sex']=='male'].shape[0]\/df_train.loc[df_train['sex']=='female'].shape[0]}\")","17a5ca90":"print(f\"Test Male-female ratio: {df_test.loc[df_test['sex']=='male'].shape[0]\/df_test.loc[df_test['sex']=='female'].shape[0]}\")","77a00127":"num_malignant_males = df_train.loc[(df_train['target']==1) & (df_train['sex']=='male'), :].shape[0]\nnum_malignant_females = df_train.loc[(df_train['target']==1) & (df_train['sex']=='female'), :].shape[0]\nprint(f\"Male ratio in Malignant: {num_malignant_males\/(num_malignant_males + num_malignant_females)}\")\n\nnum_benign_males = df_train.loc[(df_train['target']==0) & (df_train['sex']=='male'), :].shape[0]\nnum_benign_females = df_train.loc[(df_train['target']==0) & (df_train['sex']=='female'), :].shape[0]\nprint(f\"Male ratio in Benign: {num_benign_males\/(num_benign_males + num_benign_females)}\")","d303977a":"fig, ax = plt.subplots(figsize=(6,6))\nsns.countplot(x='sex', data=df_train.loc[df_train['target']==1], ax=ax, palette={'male': '#5db1e4','female': '#fb9ed6'})\nax.set_title('Sex Distribution in Malignant')","82ab7e95":"fig, ax = plt.subplots(figsize=(6,6))\nsns.countplot(x='sex', \n              data=df_train.loc[df_train['target']==0], \n              ax=ax, \n              palette={'male': '#5db1e4','female': '#fb9ed6'})\nax.set_title('Sex Distribution in Benign')","aa88b903":"fig, ax = plt.subplots(figsize=(12,9))\nsns.countplot(x='age_approx', \n              hue='sex', \n              data=df_train.loc[df_train['target']==1], \n              ax=ax, \n              palette={'male': '#5db1e4','female': '#fb9ed6'})\nax.set_title('Age-Sex Distribution in Malignant cases')","aa52ffd6":"fig, ax = plt.subplots(figsize=(12,9))\nsns.countplot(x='age_approx', \n              hue='sex', \n              data=df_train.loc[df_train['target']==0], \n              ax=ax, \n              palette={'male': '#5db1e4','female': '#fb9ed6'})\nax.set_title('Age-Sex Distribution in Benign cases')","c95cdaf7":"fig, ax = plt.subplots(figsize=(12,9))\nsns.countplot(x='anatom_site_general_challenge', \n              hue='sex', \n              data=df_train.loc[df_train['target']==1], \n              ax=ax, \n              palette={'male': '#5db1e4','female': '#fb9ed6'})\nax.set_title('Site-Sex Distribution in Malignant cases')","837541b2":"fig, ax = plt.subplots(figsize=(12,9))\nsns.countplot(x='anatom_site_general_challenge', \n              hue='sex', \n              data=df_train.loc[df_train['target']==0], \n              ax=ax, \n              palette={'male': '#5db1e4','female': '#fb9ed6'})\nax.set_title('Site-Sex Distribution in Benign cases')","2121e754":"fig, ax = plt.subplots(figsize=(6,6))\nsns.countplot(x='diagnosis', \n              data=df_train.loc[df_train['target']==1], \n              ax=ax)\nax.set_title('Diagnosis Distribution in Malignant cases')","25adbc2a":"fig, ax = plt.subplots(figsize=(24,6))\nsns.countplot(x='diagnosis', \n              data=df_train.loc[df_train['target']==0], \n              ax=ax)\nax.set_title('Diagnosis Distribution in Benign cases')","618ca6ce":"import os\n\n# benign images only\nimages = df_train.loc[df_train['target']==0, 'image_name'].values\n\n# Extract 9 random images from it\nrandom_images = [np.random.choice(images+'.jpg') for i in range(9)]\n\n# Location of the image dir\nimg_dir = path +'\/jpeg\/train'\n\nprint('Display Random Benign Images')\n\n# Adjust the size of your images\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(os.path.join(img_dir, random_images[i]))\n    plt.title(str(df_train.loc[df_train['image_name']==random_images[i].split('.')[0], 'benign_malignant'].item()))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()   ","a5fd9a89":"import os\n\n# malignant images only\nimages = df_train.loc[df_train['target']==1, 'image_name'].values\n\n# Extract 9 random images from it\nrandom_images = [np.random.choice(images+'.jpg') for i in range(9)]\n\n# Location of the image dir\nimg_dir = path +'\/jpeg\/train'\n\nprint('Display Random Malignant Images')\n\n# Adjust the size of your images\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(os.path.join(img_dir, random_images[i]))\n    plt.title(str(df_train.loc[df_train['image_name']==random_images[i].split('.')[0], 'benign_malignant'].item()))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()   ","583d48c9":"import os\n\n# benign-unknown images only\nimages = df_train.loc[(df_train['target']==0) & (df_train['diagnosis']=='unknown'), 'image_name'].values\n\n# Extract 9 random images from it\nrandom_images = [np.random.choice(images+'.jpg') for i in range(9)]\n\n# Location of the image dir\nimg_dir = path +'\/jpeg\/train'\n\nprint('Display Random Bening - unknown diagnosed Images')\n\n# Adjust the size of your images\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(os.path.join(img_dir, random_images[i]))\n    plt.title('benign-' + str(df_train.loc[df_train['image_name']==random_images[i].split('.')[0], 'diagnosis'].item()))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()   ","02186a59":"import os\n\n# benign nevus images only\nimages = df_train.loc[(df_train['target']==0) & (df_train['diagnosis']=='nevus'), 'image_name'].values\n\n# Extract 9 random images from it\nrandom_images = [np.random.choice(images+'.jpg') for i in range(9)]\n\n# Location of the image dir\nimg_dir = path +'\/jpeg\/train'\n\nprint('Display Random  Benign - nevus diagnosed Images')\n\n# Adjust the size of your images\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(os.path.join(img_dir, random_images[i]))\n    plt.title('benign-' + str(df_train.loc[df_train['image_name']==random_images[i].split('.')[0], 'diagnosis'].item()))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()   ","13b3e104":"IMG_SIZE = 100","35da1d73":"df_train.head()","b687eec3":"from tqdm import tqdm","7dec8f01":"import cv2\nX = []\ny = []\nfor img in tqdm(os.listdir(f'{path}\/jpeg\/train')):\n    img_array = cv2.imread(os.path.join(f'{path}\/jpeg\/train', img))\n    img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n    X.append(img_array.flatten())\n    y.append(df_train.loc[df_train['image_name'] == img.split('.')[0], 'target'])","57683c7f":"train = pd.DataFrame(data=X)","23abe80a":"import os\nimport tensorflow as tf","ca80fa2e":"tfrecord_location = f'{path}\/tfrecords'\nfilename = os.path.join(tfrecord_location)","73878250":"dataset = tf.data.TFRecordDataset(filename)","e0c0c8af":"filenames = f'{path}\/tfrecords\/train00-2071.tfrec'\nraw_dataset = tf.data.TFRecordDataset(filenames)\nraw_dataset","ed52b2ec":"for raw_record in raw_dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(raw_record.numpy())\n    print(example)","b86c8cae":"tf.io.parse_single_example(example_proto, feature_description)\n","e28ecb20":"def read_tfrecord(serialized_example):\n    feature_description = { 'image': tf.FixedLenFeature([], tf.string),\n               'label': tf.FixedLenFeature([], tf.int64)\n           }\n    example = tf.io.parse_single_example(serialized_example, feature_description)\n    \n    image = tf.io.parse_tensor(example['image'], out_type = float)\n    image_shape = [example['height'], example['width'], example['depth']]\n    image = tf.reshape(image, image_shape)\n    \n    return image, example['label']","764d8e7d":"tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_location)\nparsed_dataset = tfrecord_dataset.map(read_tfrecord)\n\nplt.figure(figsize=(10,10))\nfor i, data in enumerate(parsed_dataset.take(9)):\n    img = tf.keras.preprocessing.image.array_to_img(data[0])\n    plt.subplot(3,3,i+1)\n    plt.imshow(img)\nplt.show()","6fd91fc5":"print(tf.__version__)","5eed3af7":"import glob\nreader = tf.TFRecordReader()\nfilenames = glob.glob('\/tfrecords\/train*')\nfilename_queue = tf.train.string_input_producer(\n   filenames)\n_, serialized_example = reader.read(filename_queue)\nfeature_set = { 'image': tf.FixedLenFeature([], tf.string),\n               'label': tf.FixedLenFeature([], tf.int64)\n           }\n           \nfeatures = tf.parse_single_example( serialized_example, features= feature_set )\nlabel = features['label']\n \nwith tf.Session() as sess:\n    print(sess.run([image,label]))","6b747ae6":"def decode(serialized_example):\n  \"\"\"\n  Parses an image and label from the given `serialized_example`.\n  It is used as a map function for `dataset.map`\n  \"\"\"\n  IMAGE_SIZE = 28\n  IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n  \n  # 1. define a parser\n  features = tf.parse_single_example(\n      serialized_example,\n      # Defaults are not specified since both keys are required.\n      features={\n          'image_raw': tf.FixedLenFeature([], tf.string),\n          'label': tf.FixedLenFeature([], tf.int64),\n      })\n\n  # 2. Convert the data\n  image = tf.decode_raw(features['image_raw'], tf.uint8)\n  label = tf.cast(features['label'], tf.int32)\n  # 3. reshape\n  image.set_shape((IMAGE_PIXELS))\n  return image, label","6bebb1eb":"dataset = dataset.map(decode)","2dc0a1e4":"Lets see types of benign","371f81df":"## EDA","be6d9130":"Inspiration\n\nhttps:\/\/www.kaggle.com\/parulpandey\/melanoma-classification-eda-starter","31d8d1a2":"So number of males in malignant cases are more","0ef8f938":"The video said if the the shape is not symmetric and if the circumference is rugged it might be mealnoma. We might make some feature around this but lets keep this for later","84732cdd":"Melanoma is the deadliest form of skin cancer. The goal of this competition is to develop a model which can classifiy benign and malignant skin lesions. Let's first understand some basic statistics and charachteristics about Melanoma through this [video](https:\/\/www.youtube.com\/watch?v=DS9eIhcuWEM) \n[![video](https:\/\/img.youtube.com\/vi\/DS9eIhcuWEM\/0.jpg)](https:\/\/www.youtube.com\/watch?v=DS9eIhcuWEM)","6eeeb68f":"It will be interesting to see Nevus, seborrheic keratosis etc and malanoma if we can find some clue","f62b25e2":"### Benign images","a2b99beb":"## Modelling","ed3e2a29":"# SIIM - ISIC - Melanoma Classification","bc42721b":"Not accurately but it seems that men are more likely to get Melanoma especially for age group of above 60 number of malignant cases in men are marginally high","af3fa221":"Train set is 3 times as bigger as test set","7f6c4f90":"### Malignant images","d2f92537":"So in general torso is where people get skin patches. ","dd05c597":"We have slightly more males in test than in train but I think that is fine because train set is also 3 times bigger than test set"}}