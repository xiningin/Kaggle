{"cell_type":{"acfe4bb9":"code","5c378752":"code","bcf4e53d":"code","befa114f":"code","416c2285":"code","89b5d9a6":"code","0b8def93":"code","461abfac":"code","64cd7755":"code","f312a82d":"code","b465d39c":"code","7761e795":"code","9acee891":"code","3599852a":"code","25a37ea7":"code","d48c3719":"code","c837c4f3":"code","1a930883":"code","7882991c":"code","2894aea4":"code","64ea1d64":"code","309a5559":"code","6d8829f5":"code","b4ff9217":"code","4cfe9fa9":"code","15559e99":"code","fdfb4550":"code","a3dab151":"code","3c277b14":"code","e3e50754":"code","cc343cd8":"code","1b08ed89":"code","ce715da6":"code","bf665c53":"code","38a758f0":"code","b87668d1":"code","49c5217e":"code","e93ae6ff":"code","484f8815":"code","2a8f9442":"markdown"},"source":{"acfe4bb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as ms\n% matplotlib inline\n\n# Any results you write to the current directory are saved as output.","5c378752":"train_data = pd.read_csv('..\/input\/twitter-hate-speech\/train_E6oV3lV.csv')\ntest_data = pd.read_csv('..\/input\/twitter-hate-speech\/test_tweets_anuFYb8.csv')","bcf4e53d":"train_data.shape, test_data.shape","befa114f":"train_data.head()","416c2285":"train_data.info()","89b5d9a6":"train_data['label'].value_counts()\n","0b8def93":"test_data.head()","461abfac":"#cleaning the data\n\ndef drop_features(features,data):\n    data.drop(features,inplace=True,axis=1)","64cd7755":"import re\n## example ## \nre.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",\"ouch...junior is angry\u00f0\u009f\u0098\u0090#got7 #junior #yugyo..., @user\")","f312a82d":"def process_tweet(tweet):\n    return \" \".join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",tweet.lower()).split())","b465d39c":"train_data['processed_tweets'] = train_data['tweet'].apply(process_tweet)","7761e795":"train_data.head(10)","9acee891":"drop_features(['id','tweet'],train_data)","3599852a":"train_data.info()\n","25a37ea7":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_data[\"processed_tweets\"], train_data[\"label\"], test_size = 0.2, random_state = 42)\n","d48c3719":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\ncount_vect = CountVectorizer(stop_words='english')\ntransformer = TfidfTransformer(norm='l2',sublinear_tf=True)","c837c4f3":"x_train_counts = count_vect.fit_transform(x_train)\nx_train_tfidf = transformer.fit_transform(x_train_counts)","1a930883":"print(x_train_counts.shape)\nprint(x_train_tfidf.shape)","7882991c":"x_train_counts","2894aea4":"x_test_counts = count_vect.transform(x_test)\nx_test_tfidf = transformer.transform(x_test_counts)","64ea1d64":"print(x_test_counts.shape)\nprint(x_test_tfidf.shape)","309a5559":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=500)\nmodel.fit(x_train_tfidf,y_train)","6d8829f5":"predictions = model.predict(x_test_tfidf)","b4ff9217":"from sklearn.metrics import confusion_matrix,f1_score\nconfusion_matrix(y_test,predictions)","4cfe9fa9":"#tp=5904\n#tn = 237\n#fn = 33\n#fp = 219\n\n#precision = tp\/(tp+fp)\n#recall = tp\/(tp+fn)\n#f1score = 2 * (recall * precision) \/ (recall + precision)\n#f1score","15559e99":"f1_score(y_test,predictions)","fdfb4550":"predictions","a3dab151":"test_data.info()","3c277b14":"test_data['processed_tweet'] = test_data['tweet'].apply(process_tweet)","e3e50754":"test_data.head()\n","cc343cd8":"drop_features(['tweet'],test_data)","1b08ed89":"train_counts = count_vect.fit_transform(train_data['processed_tweets'])\ntest_counts = count_vect.transform(test_data['processed_tweet'])","ce715da6":"print(train_counts.shape)\nprint(test_counts.shape)","bf665c53":"train_tfidf = transformer.fit_transform(train_counts)\ntest_tfidf = transformer.transform(test_counts)","38a758f0":"\nprint(train_tfidf.shape)\nprint(test_tfidf.shape)\n","b87668d1":"model.fit(train_tfidf,train_data['label'])","49c5217e":"predictions = model.predict(test_tfidf)","e93ae6ff":"final_result = pd.DataFrame({'id':test_data['id'],'label':predictions})\nfinal_result.to_csv('Output.csv',index=False)","484f8815":"final_result.head()","2a8f9442":"**preparing for test data**"}}