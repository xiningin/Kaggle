{"cell_type":{"db4f9367":"code","ff42f3ac":"code","29074d94":"code","11733983":"code","7e4a5480":"code","ac05c4f2":"code","8ca9023e":"code","167f31ba":"code","3741fef9":"code","b308c6ac":"code","261f9a96":"code","0e68c800":"code","4871b75d":"code","ee5cb6dc":"code","203024af":"code","5dd48df3":"code","afac9d33":"code","24701202":"code","5a5ce96d":"code","81853224":"code","0c6cf291":"code","4d5ae603":"code","9255fdc6":"code","08139ab7":"code","7429f8b3":"code","651a16df":"code","249e8403":"code","8160c70b":"code","cb1fb4ef":"code","442dfd68":"code","3b53bf2a":"code","aee3b375":"code","f9043f1c":"code","bdb1c7d9":"code","3f8d741c":"code","7b68a5c1":"code","d15ad48a":"code","793f3306":"code","b020e306":"code","99591d6a":"code","bddcc561":"code","4bbc96f8":"code","02b44caf":"code","7158c07f":"code","45e53cc2":"code","30d46086":"code","c7edce13":"code","b471ae93":"code","59517796":"code","c7dedaff":"code","c00e864e":"code","eb6a6875":"code","7a13d1d7":"code","d8bda610":"code","041f9b3e":"code","597b5150":"code","101cd270":"code","a0f7498c":"code","65bd19a9":"code","6fbe0e69":"code","a99436e3":"code","47b38a1f":"code","330a66ef":"code","aae0a795":"code","0f04169f":"code","371c41ad":"code","4c8b6736":"code","e5888a49":"code","bc240e6d":"code","db1a4705":"code","68367c3b":"code","9b0e041d":"code","03050841":"code","e8d74766":"code","2c3cefbb":"code","e561094c":"code","f82f197c":"code","595a7835":"code","8b87d809":"code","3a8d5a60":"code","e863db9d":"code","bc758e3b":"code","49955081":"code","bf3660a4":"code","a604ba82":"code","7cdbd76c":"code","caf9c866":"code","7289b71b":"code","4d162603":"code","b04eed1a":"code","bda72af4":"code","2dc318b2":"code","25f90eee":"code","ba18995a":"code","cef2bd7f":"code","6761361d":"markdown","c3f3a19d":"markdown","9d7ec3d6":"markdown","78c753d6":"markdown","ac598cd2":"markdown","b408443d":"markdown","a95384ce":"markdown","d710abbd":"markdown","bdd73074":"markdown","a2595b86":"markdown","687b7930":"markdown","1b387ef6":"markdown","2cd93c14":"markdown"},"source":{"db4f9367":"import pandas as pd\nimport numpy as np\nimport category_encoders as ce\nimport hyperopt\nimport xgboost as xgb\n\nimport warnings\nimport sys\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.utils import shuffle\n\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\n\nfrom catboost import CatBoostClassifier, Pool, cv","ff42f3ac":"train = pd.read_csv(\"..\/input\/ef-msu-autumn-1\/train.csv\")\ntest = pd.read_csv(\"..\/input\/ef-msu-autumn-1\/test.csv\")","29074d94":"# \u0438\u0441\u043f\u0440\u0430\u0432\u0438\u043c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u0432 \u0434\u0430\u043d\u043d\u044b\u0445\n\ntrain[\"Gender\"] = train[\"Gender\"].replace(\"Fe Male\", \"Female\")\ntrain[\"MonthlyIncome\"] = np.log(train[\"MonthlyIncome\"])\n\ntest[\"Gender\"] = test[\"Gender\"].replace(\"Fe Male\", \"Female\")\ntest[\"MonthlyIncome\"] = np.log(test[\"MonthlyIncome\"])","11733983":"rounded_duration = round(train[\"DurationOfPitch\"].mean())\nrounded_monthly_income = round(train[\"MonthlyIncome\"].mean())\n\ntrain[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mode().values[0])\ntrain[\"TypeofContact\"] = train[\"TypeofContact\"].fillna(\n    train[\"TypeofContact\"].mode().values[0]\n)\ntrain[\"DurationOfPitch\"] = train[\"DurationOfPitch\"].fillna(rounded_duration)\ntrain[\"NumberOfFollowups\"] = train[\"NumberOfFollowups\"].fillna(\n    train[\"NumberOfFollowups\"].mode().values[0]\n)\ntrain[\"PreferredPropertyStar\"] = train[\"PreferredPropertyStar\"].fillna(\n    train[\"PreferredPropertyStar\"].mode().values[0]\n)\ntrain[\"NumberOfTrips\"] = train[\"NumberOfTrips\"].fillna(\n    train[\"NumberOfTrips\"].mode().values[0]\n)\ntrain[\"NumberOfChildrenVisiting\"] = train[\"NumberOfChildrenVisiting\"].fillna(\n    train[\"NumberOfChildrenVisiting\"].mode().values[0]\n)\ntrain[\"MonthlyIncome\"] = train[\"MonthlyIncome\"].fillna(rounded_monthly_income)\n\ntest[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mode().values[0])\ntest[\"TypeofContact\"] = test[\"TypeofContact\"].fillna(\n    test[\"TypeofContact\"].mode().values[0]\n)\ntest[\"DurationOfPitch\"] = test[\"DurationOfPitch\"].fillna(rounded_duration)\ntest[\"NumberOfFollowups\"] = test[\"NumberOfFollowups\"].fillna(\n    test[\"NumberOfFollowups\"].mode().values[0]\n)\ntest[\"PreferredPropertyStar\"] = test[\"PreferredPropertyStar\"].fillna(\n    test[\"PreferredPropertyStar\"].mode().values[0]\n)\ntest[\"NumberOfTrips\"] = test[\"NumberOfTrips\"].fillna(\n    test[\"NumberOfTrips\"].mode().values[0]\n)\ntest[\"NumberOfChildrenVisiting\"] = test[\"NumberOfChildrenVisiting\"].fillna(\n    test[\"NumberOfChildrenVisiting\"].mode().values[0]\n)\ntest[\"MonthlyIncome\"] = test[\"MonthlyIncome\"].fillna(rounded_monthly_income)","7e4a5480":"train, test = shuffle(train, random_state=42).reset_index(drop=True), shuffle(test, random_state=42).reset_index(drop=True)\n\ntest_ids = test[\"CustomerID\"]","ac05c4f2":"train, test = train.drop([\"CustomerID\"], axis=1), test.drop([\"CustomerID\"], axis=1)","8ca9023e":"cat_features = [\n    \"TypeofContact\",\n    \"Occupation\",\n    \"Gender\",\n    \"ProductPitched\",\n    \"MaritalStatus\",\n    \"Designation\",\n]","167f31ba":"y = train[\"ProdTaken\"]\nX = train[[col for col in train.columns if col != \"ProdTaken\"]]","3741fef9":"min_max_scaler = MinMaxScaler()\nstandard_scaler = StandardScaler()\nrobust_scaler = RobustScaler()\n\noh_encoder = ce.OneHotEncoder(cols=cat_features)\ntarget_encoder = ce.TargetEncoder(cols=cat_features)\ncb_encoder = ce.CatBoostEncoder(cols=cat_features)","b308c6ac":"def validate(model):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        res = cross_val_score(model, X, y, scoring=\"roc_auc\", cv=4, verbose=1)\n    return res, np.mean(res), np.median(res)","261f9a96":"def search(model, params_grid):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        clf = GridSearchCV(model, params_grid, scoring=\"roc_auc\", cv=4, verbose=1)\n        clf.fit(X, y)\n    return clf.best_params_","0e68c800":"knn_params = {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n\nknn1 = make_pipeline(oh_encoder, min_max_scaler, KNeighborsClassifier(**knn_params))\nknn2 = make_pipeline(target_encoder, min_max_scaler, KNeighborsClassifier(**knn_params))\nknn3 = make_pipeline(cb_encoder, min_max_scaler, KNeighborsClassifier(**knn_params))\n\nknn4 = make_pipeline(oh_encoder, standard_scaler, KNeighborsClassifier(**knn_params))\nknn5 = make_pipeline(target_encoder, standard_scaler, KNeighborsClassifier(**knn_params))\nknn6 = make_pipeline(target_encoder, robust_scaler, KNeighborsClassifier(**knn_params))","4871b75d":"validate(knn1)","ee5cb6dc":"validate(knn2)","203024af":"validate(knn3)","5dd48df3":"validate(knn4)","afac9d33":"validate(knn5)","24701202":"validate(knn6)","5a5ce96d":"knn_params_grid = dict(kneighborsclassifier__n_neighbors=np.arange(1, 30, 2), \n                   kneighborsclassifier__weights=['uniform', 'distance'],\n                   kneighborsclassifier__p=[1, 2, 3, 4, 5])\nsearch(knn5, knn_params_grid)","81853224":"best_knn_params = {'p': 1, 'n_neighbors': 7, 'weights': 'distance'}\nknn_clf = make_pipeline(target_encoder, standard_scaler, KNeighborsClassifier(**best_knn_params))","0c6cf291":"validate(knn_clf)","4d5ae603":"extra_params = {\"max_features\": 9 , \"n_estimators\": 1100, 'max_depth': 22}\n\nextra1 = make_pipeline(oh_encoder, min_max_scaler, ExtraTreesClassifier(**extra_params, random_state=42))\nextra2 = make_pipeline(target_encoder, min_max_scaler, ExtraTreesClassifier(**extra_params, random_state=42))\nextra3 = make_pipeline(cb_encoder, min_max_scaler, ExtraTreesClassifier(**extra_params, random_state=42))\n\nextra4 = make_pipeline(oh_encoder, standard_scaler, ExtraTreesClassifier(**extra_params, random_state=42))\nextra5 = make_pipeline(target_encoder, standard_scaler, ExtraTreesClassifier(**extra_params, random_state=42))\nextra6 = make_pipeline(target_encoder, robust_scaler, ExtraTreesClassifier(**extra_params, random_state=42))","9255fdc6":"validate(extra1)","08139ab7":"validate(extra2)","7429f8b3":"validate(extra3)","651a16df":"validate(extra4)","249e8403":"validate(extra5)","8160c70b":"validate(extra6)","cb1fb4ef":"extra_params_grid = dict(extratreesclassifier__n_estimators=[1350, 1400, 1450])\nsearch(extra5, extra_params_grid)","442dfd68":"best_extra_params = {\"max_features\": 9 , \"n_estimators\": 1350, 'max_depth': 22}\nextra_clf = make_pipeline(target_encoder, standard_scaler, ExtraTreesClassifier(**best_extra_params, random_state=42))","3b53bf2a":"validate(extra_clf)","aee3b375":"xgb_params = {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, \n              'reg_lambda': 0, 'scale_pos_weight': 3, 'subsample': 0.8}\n\nxgb1 = make_pipeline(oh_encoder, min_max_scaler, xgb.XGBClassifier(**xgb_params, random_state=42))\nxgb2 = make_pipeline(target_encoder, min_max_scaler, xgb.XGBClassifier(**xgb_params, random_state=42))\nxgb3 = make_pipeline(cb_encoder, min_max_scaler, xgb.XGBClassifier(**xgb_params, random_state=42))\n\nxgb4 = make_pipeline(oh_encoder, standard_scaler, xgb.XGBClassifier(**xgb_params, random_state=42))\nxgb5 = make_pipeline(target_encoder, standard_scaler, xgb.XGBClassifier(**xgb_params, random_state=42))\nxgb6 = make_pipeline(target_encoder, robust_scaler, xgb.XGBClassifier(**xgb_params, random_state=42))","f9043f1c":"validate(xgb1)","bdb1c7d9":"validate(xgb2)","3f8d741c":"validate(xgb3)","7b68a5c1":"validate(xgb4)","d15ad48a":"validate(xgb5)","793f3306":"validate(xgb6)","b020e306":"cb_params = {\"logging_level\": \"Silent\"}\n\ncb1 = make_pipeline(oh_encoder, min_max_scaler, CatBoostClassifier(**cb_params, random_state=42))\ncb2 = make_pipeline(target_encoder, min_max_scaler, CatBoostClassifier(**cb_params, random_state=42))\ncb3 = make_pipeline(cb_encoder, min_max_scaler, CatBoostClassifier(**cb_params, random_state=42))\n\ncb4 = make_pipeline(oh_encoder, standard_scaler, CatBoostClassifier(**cb_params, random_state=42))\ncb5 = make_pipeline(target_encoder, standard_scaler, CatBoostClassifier(**cb_params, random_state=42))\ncb6 = make_pipeline(target_encoder, robust_scaler, CatBoostClassifier(**cb_params, random_state=42))","99591d6a":"validate(cb1)","bddcc561":"validate(cb2)","4bbc96f8":"validate(cb3)","02b44caf":"validate(cb4)","7158c07f":"validate(cb5)","45e53cc2":"validate(cb6)","30d46086":"class ClassifierObjective(object):\n    def __init__(self, dataset, const_params, fold_count):\n        self._dataset = dataset\n        self._const_params = const_params.copy()\n        self._fold_count = fold_count\n        self._evaluated_count = 0\n        \n    def _to_catboost_params(self, hyper_params):\n        return {\n            'learning_rate': hyper_params['learning_rate'],\n            'iterations': hyper_params['iterations'],\n            'l2_leaf_reg': hyper_params['l2_leaf_reg']}\n    \n    # hyperopt optimizes an objective using `__call__` method (e.g. by doing \n    # `foo(hyper_params)`), so we provide one\n    def __call__(self, hyper_params):\n        # join hyper-parameters provided by hyperopt with hyper-parameters \n        # provided by the user\n        params = self._to_catboost_params(hyper_params)\n        params.update(self._const_params)\n        \n        print('evaluating params={}'.format(params), file=sys.stdout)\n        sys.stdout.flush()\n        \n        # we use cross-validation for objective evaluation, to avoid overfitting\n        scores = cv(\n            pool=self._dataset,\n            params=params,\n            fold_count=self._fold_count,\n            partition_random_seed=42,\n            verbose=False)\n        \n        # scores returns a dictionary with mean and std (per-fold) of metric \n        # value for each cv iteration, we choose minimal value of objective \n        # mean (though it will be better to choose minimal value among all folds)\n        # because noise is additive\n        max_mean_auc = np.max(scores['test-AUC-mean'])\n        print('evaluated score={}'.format(max_mean_auc), file=sys.stdout)\n        \n        self._evaluated_count += 1\n        print('evaluated {} times'.format(self._evaluated_count), file=sys.stdout)\n        \n        # negate because hyperopt minimizes the objective\n        return {'loss': -max_mean_auc, 'status': hyperopt.STATUS_OK}","c7edce13":"def find_best_hyper_params(dataset, const_params, max_evals=100):  \n    # we are going to optimize these three parameters, though there are a lot more of them (see CatBoost docs)\n    parameter_space = {\n        'learning_rate': hyperopt.hp.uniform('learning_rate', 0.01, 1),\n        'iterations': 500 + hyperopt.hp.randint('iterations', 1500),\n        'l2_leaf_reg': hyperopt.hp.uniform('l2_leaf_reg', 1, 20)}\n    objective = ClassifierObjective(dataset=dataset, const_params=const_params, fold_count=4)\n    trials = hyperopt.Trials()\n    best = hyperopt.fmin(\n        fn=objective,\n        space=parameter_space,\n        algo=hyperopt.rand.suggest,\n        max_evals=max_evals,\n        rstate=np.random.RandomState(seed=42))\n    return best\n\ndef train_best_model(X, y, const_params, max_evals=100, use_default=False):\n    # convert pandas.DataFrame to catboost.Pool to avoid converting it on each \n    # iteration of hyper-parameters optimization\n    dataset = Pool(X, y, cat_features=np.where(X.dtypes != np.float)[0])\n    \n    if use_default:\n        # pretrained optimal parameters\n        best = {\n            'learning_rate': 0.1, \n            'depth': 5, \n            'l2_leaf_reg': 1}\n    else:\n        best = find_best_hyper_params(dataset, const_params, max_evals=max_evals)\n    \n    # merge subset of hyper-parameters provided by hyperopt with hyper-parameters \n    # provided by the user\n    hyper_params = best.copy()\n    hyper_params.update(const_params)\n    \n    # drop `use_best_model` because we are going to use entire dataset for \n    # training of the final model\n    hyper_params.pop('use_best_model', None)\n    \n    model = CatBoostClassifier(**hyper_params)\n    model.fit(dataset, verbose=False)\n    \n    return model, hyper_params","b471ae93":"# make it True if your want to use GPU for training\nhave_gpu = False\n# skip hyper-parameter optimization and just use provided optimal parameters\nuse_optimal_pretrained_params = False\n# number of iterations of hyper-parameter search\nhyperopt_iterations = 75\n\nconst_params = dict({\n    'task_type': 'GPU' if have_gpu else 'CPU',\n    'loss_function': 'Logloss',\n    'eval_metric': 'AUC', \n    'random_seed': 42})\n\nmodel, params = train_best_model(\n    X, y, \n    const_params, \n    max_evals=hyperopt_iterations, \n    use_default=use_optimal_pretrained_params)\n\nprint('best params are {}'.format(params), file=sys.stdout)","59517796":"best_cb_params = {\"logging_level\": \"Silent\", 'iterations': 897, 'l2_leaf_reg': 18.97, 'learning_rate': 0.1919}\ncb_clf = CatBoostClassifier(**best_cb_params, cat_features=cat_features, random_state=42)","c7dedaff":"validate(cb_clf)","c00e864e":"rf_params = {\"n_estimators\": 1000}\n\nrf1 = make_pipeline(oh_encoder, min_max_scaler, RandomForestClassifier(**rf_params, random_state=42))\nrf2 = make_pipeline(target_encoder, min_max_scaler, RandomForestClassifier(**rf_params, random_state=42))\nrf3 = make_pipeline(cb_encoder, min_max_scaler, RandomForestClassifier(**rf_params, random_state=42))\n\nrf4 = make_pipeline(oh_encoder, standard_scaler, RandomForestClassifier(**rf_params, random_state=42))\nrf5 = make_pipeline(target_encoder, standard_scaler, RandomForestClassifier(**rf_params, random_state=42))\nrf6 = make_pipeline(target_encoder, robust_scaler, RandomForestClassifier(**rf_params, random_state=42))","eb6a6875":"validate(rf1)","7a13d1d7":"validate(rf2)","d8bda610":"validate(rf4)","041f9b3e":"validate(rf5)","597b5150":"validate(rf6)","101cd270":"rf_params_grid = dict(randomforestclassifier__max_features=[2],\n                      randomforestclassifier__max_depth=[15, 20, 21, 22],\n                      randomforestclassifier__n_estimators=[550, 600, 650])\nsearch(rf2, rf_params_grid)","a0f7498c":"best_rf_params = {\"max_features\": 2 , \"n_estimators\": 600, 'max_depth': 21}\nrf_clf = make_pipeline(target_encoder, min_max_scaler, RandomForestClassifier(**best_rf_params, random_state=42))","65bd19a9":"validate(rf_clf)","6fbe0e69":"svc1 = make_pipeline(oh_encoder, min_max_scaler, SVC(random_state=42))\nsvc2 = make_pipeline(target_encoder, min_max_scaler, SVC(random_state=42))\nsvc3 = make_pipeline(cb_encoder, min_max_scaler, SVC(random_state=42))\n\nsvc4 = make_pipeline(oh_encoder, standard_scaler, SVC(random_state=42))\nsvc5 = make_pipeline(target_encoder, standard_scaler, SVC(random_state=42))\nsvc6 = make_pipeline(target_encoder, robust_scaler, SVC(random_state=42))","a99436e3":"validate(svc1)","47b38a1f":"validate(svc2)","330a66ef":"validate(svc3)","aae0a795":"validate(svc4)","0f04169f":"validate(svc5)","371c41ad":"validate(svc6)","4c8b6736":"svc_params_grid = dict(svc__C=[24],\n                       svc__kernel=['rbf'],\n                       svc__shrinking=[True, False],\n                       svc__probability=[True, False],\n                       svc__gamma=['scale'])\nsearch(svc4, svc_params_grid)","e5888a49":"best_svc_params = {'C': 24, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True, 'shrinking': False}\nsvc_clf = make_pipeline(oh_encoder, standard_scaler, SVC(**best_svc_params, random_state=42))","bc240e6d":"validate(svc_clf)","db1a4705":"mpl_params = {\"max_iter\": 800}\n\nmpl1 = make_pipeline(oh_encoder, min_max_scaler, MLPClassifier(**mpl_params, random_state=42))\nmpl2 = make_pipeline(target_encoder, min_max_scaler, MLPClassifier(**mpl_params, random_state=42))\nmpl3 = make_pipeline(cb_encoder, min_max_scaler, MLPClassifier(**mpl_params, random_state=42))\n\nmpl4 = make_pipeline(oh_encoder, standard_scaler, MLPClassifier(**mpl_params, random_state=42))\nmpl5 = make_pipeline(target_encoder, standard_scaler, MLPClassifier(**mpl_params, random_state=42))\nmpl6 = make_pipeline(target_encoder, robust_scaler, MLPClassifier(**mpl_params, random_state=42))","68367c3b":"validate(mpl1)","9b0e041d":"validate(mpl2)","03050841":"validate(mpl3)","e8d74766":"validate(mpl4)","2c3cefbb":"validate(mpl5)","e561094c":"validate(mpl6)","f82f197c":"mpl_params_grid = dict(mlpclassifier__max_iter=[850, 900, 950])\nsearch(mpl5, mpl_params_grid)","595a7835":"best_mpl_params = {'max_iter': 850}\nmpl_clf = make_pipeline(target_encoder, standard_scaler, MLPClassifier(**best_mpl_params, random_state=42))","8b87d809":"validate(mpl_clf)","3a8d5a60":"best_knn_params = {'p': 1, 'n_neighbors': 7, 'weights': 'distance'}\nknn_clf = make_pipeline(target_encoder, standard_scaler, KNeighborsClassifier(**best_knn_params))\n\nbest_extra_params = {\"max_features\": 9 , \"n_estimators\": 1350, 'max_depth': 22}\nextra_clf = make_pipeline(target_encoder, standard_scaler, ExtraTreesClassifier(**best_extra_params, random_state=42))\n\nbest_cb_params = {\"logging_level\": \"Silent\", 'iterations': 897, 'l2_leaf_reg': 18.97, 'learning_rate': 0.1919}\ncb_clf = CatBoostClassifier(**best_cb_params, cat_features=cat_features, random_state=42)\n\nbest_rf_params = {\"max_features\": 2 , \"n_estimators\": 600, 'max_depth': 21}\nrf_clf = make_pipeline(target_encoder, min_max_scaler, RandomForestClassifier(**best_rf_params, random_state=42))\n\nbest_svc_params = {'C': 24, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True, 'shrinking': False}\nsvc_clf = make_pipeline(oh_encoder, standard_scaler, SVC(**best_svc_params, random_state=42))\n\nbest_mpl_params = {'max_iter': 850}\nmpl_clf = make_pipeline(target_encoder, standard_scaler, MLPClassifier(**best_mpl_params, random_state=42))\n\nbest_xgb_params = {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, \n                   'reg_lambda': 0, 'scale_pos_weight': 3, 'subsample': 0.8}\nxgb_clf = make_pipeline(target_encoder, standard_scaler, xgb.XGBClassifier(**best_xgb_params, random_state=42))","e863db9d":"stacking1 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf), ('mpl', mpl_clf)],\n                                  final_estimator=ExtraTreesClassifier(random_state=41), cv=4)\n\nstacking2 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf)],\n                                  final_estimator=ExtraTreesClassifier(random_state=41), cv=4)\n\nstacking3 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf)],\n                                  final_estimator=CatBoostClassifier(logging_level=\"Silent\", random_state=41), cv=4)\n\nstacking4 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf)], cv=4)\n\nstacking5 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf)], cv=4)\n\nstacking6 = StackingClassifier(estimators=[('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf)], cv=4)\n\nstacking7 = StackingClassifier(estimators=[('cb', cb_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf)], cv=4)\n\nstacking8 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('rf', rf_clf)], cv=4)\n\nstacking9 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf)],\n                                  final_estimator=LogisticRegression(C=20, random_state=41), cv=4)\n\nstacking10 = StackingClassifier(estimators=[('cb', cb_clf), ('svc', svc_clf), ('extra', extra_clf), \n                                              ('knn', knn_clf), ('rf', rf_clf), ('mpl', mpl_clf), ('xgb', xgb_clf)],\n                                  final_estimator=LogisticRegression(C=20, random_state=41), cv=4)","bc758e3b":"validate(stacking1)","49955081":"validate(stacking2)","bf3660a4":"validate(stacking3)","a604ba82":"validate(stacking4)","7cdbd76c":"validate(stacking5)","caf9c866":"validate(stacking6)","7289b71b":"validate(stacking7)","4d162603":"validate(stacking8)","b04eed1a":"validate(stacking9)","bda72af4":"validate(stacking10)","2dc318b2":"with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        stacking10.fit(X, y);","25f90eee":"pred_test = stacking10.predict_proba(test)","ba18995a":"submission = pd.DataFrame()\nsubmission[\"CustomerID\"] = test_ids\nsubmission[\"ProdTaken\"] = pred_test[:, 1]","cef2bd7f":"submission.sort_values(by=\"CustomerID\").reset_index(drop=True).to_csv(\"stacking_sub.csv\", index=False)","6761361d":"## Random Forest","c3f3a19d":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u043c\u043e\u0434\u0443\u043b\u0435\u0439","9d7ec3d6":"## Multi-layer Perceptron classifier","78c753d6":"## Encoders \u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438","ac598cd2":"# \u0420\u0430\u0431\u043e\u0442\u0430 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438","b408443d":"## Stacked generalization","a95384ce":"## \u0413\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u044b\u0439 \u0431\u0443\u0441\u0442\u0438\u043d\u0433 `catbooost`","d710abbd":"## SVM","bdd73074":"# \u041c\u043e\u0434\u0435\u043b\u0438","a2595b86":"## Extremely Randomized Trees","687b7930":"> \u041c\u043e\u0434\u0435\u043b\u0438 `catboost` \u043f\u043b\u043e\u0445\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 \u0441\u043e \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u043c **GridSearchCV** \u0438\u0437 `sklearn`, \u043e\u0434\u043d\u0430\u043a\u043e \u0432\u0441\u0451 \u0440\u0430\u0432\u043d\u043e \u043c\u043e\u0436\u043d\u043e \u0443\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043f\u043e\u0438\u0441\u043a \u0441 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0435\u0439,   \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, `hyperopt`. \u041a\u043e\u0434 \u043d\u0438\u0436\u0435 \u0437\u0430\u0438\u043c\u0441\u0442\u0432\u043e\u0432\u0430\u043d \u0438\u0437 \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u043f\u043e\u043b\u0435\u0437\u043d\u043e\u0433\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u043e\u0440\u0438\u044f [catboost tuorials](https:\/\/github.com\/catboost\/tutorials\/blob\/master\/classification\/classification_with_parameter_tuning_tutorial.ipynb).","1b387ef6":"## \u0413\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u044b\u0439 \u0431\u0443\u0441\u0442\u0438\u043d\u0433 `xgboost`","2cd93c14":"## kNN"}}