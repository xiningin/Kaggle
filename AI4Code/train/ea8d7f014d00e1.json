{"cell_type":{"9762a5b6":"code","173903e3":"code","2ad3401a":"code","bd356dbb":"code","3e6d8967":"code","a1db0394":"code","d00b4cd2":"code","5e8685bc":"code","4f274ce5":"code","530b2cf5":"code","fd263278":"code","6b9c8876":"code","4a669e49":"code","12723bf5":"code","af4d19f4":"code","da95cfbc":"code","2837df04":"code","e7725372":"code","f78c6f12":"code","4a86e4aa":"code","8b97bf50":"code","0b8f8ed5":"code","fe58383c":"code","0ff394d4":"code","a19630ca":"code","ace14815":"code","aa3e5b49":"code","d3a4b299":"code","fae7b90f":"code","601913e1":"code","c6aea24b":"code","f3747307":"code","0e6a3035":"code","8ff1bd0d":"code","7faa4d28":"code","f24d4cd8":"code","1380c538":"code","2845aeff":"code","851a40fa":"code","757fdcd2":"code","ed32c8e2":"code","c6d203c8":"code","a2fc0f41":"code","d9e8f5a5":"code","0137bf1e":"code","b5491c8d":"code","74963de3":"code","85bb1e16":"code","3072f56a":"markdown","751fe7e5":"markdown","486b4ee2":"markdown","df89f841":"markdown","262c98ee":"markdown","8ea052b6":"markdown","4b282ef8":"markdown","f48c2b8f":"markdown","9f1f79ab":"markdown","baf69a5d":"markdown","ce1b8020":"markdown","de84b26d":"markdown","497bdce1":"markdown","cd168e80":"markdown","c54694c8":"markdown","161491b9":"markdown","3da705e7":"markdown","1f99f3c2":"markdown"},"source":{"9762a5b6":"!pip install pyspark","173903e3":"from pyspark import SparkContext, SQLContext   # required for dealing with dataframes\nfrom pyspark.sql.functions import isnan, count, col\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pyspark.ml.recommendation import ALS      # for Matrix Factorization using ALS ","2ad3401a":"sc = SparkContext()      # instantiating spark context \nsqlContext = SQLContext(sc) # instantiating SQL context ","bd356dbb":"jester_ratings_df = sqlContext.read.csv(\"\/kaggle\/input\/jester-17m-jokes-ratings-dataset\/jester_ratings.csv\",header = True, inferSchema = True)\njester_items_df = sqlContext.read.csv(\"\/kaggle\/input\/jester-17m-jokes-ratings-dataset\/jester_items.csv\",header = True, inferSchema = True)","3e6d8967":"print(\"Ratings dataset shape:\", (jester_ratings_df.count(), len(jester_ratings_df.columns)))\njester_ratings_df.show(5)","a1db0394":"df = pd.read_csv(\"\/kaggle\/input\/jester-17m-jokes-ratings-dataset\/jester_ratings.csv\")","d00b4cd2":"df2 = pd.read_csv(\"\/kaggle\/input\/jester-17m-jokes-ratings-dataset\/jester_items.csv\")","5e8685bc":"df2[\"jokeId\"].nunique()","4f274ce5":"df.dtypes","530b2cf5":"set(df2[\"jokeId\"].unique().tolist()) - set(df[\"jokeId\"].unique().tolist())","fd263278":"df[df[\"jokeId\"].isin([1, 2, 3, 4, 6, 9, 10, 11, 12, 14])]","6b9c8876":"df[\"rating\"].max()","4a669e49":"jester_ratings_df.show(5)","12723bf5":"print(\"Number of unique users: \", jester_ratings_df.select(\"userId\").distinct().count())\nprint(\"Number of unique jokes: \", jester_ratings_df.select(\"jokeId\").distinct().count())\nprint(\"Total number of ratings: \", jester_ratings_df.count())","af4d19f4":"fig, ax = plt.subplots(figsize=(12,8))\nax.set_title('Ratings distribution', fontsize=15)\nsns.distplot(jester_ratings_df.toPandas()['rating'], kde=False, bins = 8,hist_kws=dict(edgecolor=\"k\", linewidth=2))\nax.set_xlabel(\"ratings in interval\")\nax.set_ylabel(\"Total number of ratings\")","da95cfbc":"ratings_per_user = jester_ratings_df.groupby('userId').agg({\"rating\":\"count\"})\nratings_per_user.describe().show()","2837df04":"ratings_per_joke = jester_ratings_df.groupby('jokeId').agg({\"rating\":\"count\"})\nratings_per_joke.describe().show()","e7725372":"X_train, X_test = jester_ratings_df.randomSplit([0.9,0.1])   # 90:10 ratio\nprint(\"Training data size : \", X_train.count())\nprint(\"Test data size : \", X_test.count())\nprint(\"Number of unique users in Training set\", X_train[[\"userId\"]].distinct().count())\nprint(\"Number of unique users in Test set\", X_test[[\"userId\"]].distinct().count())","f78c6f12":"als = ALS(userCol=\"userId\",itemCol=\"jokeId\",ratingCol=\"rating\",rank=5, maxIter=10, seed=0)\nmodel = als.fit(X_train)","4a86e4aa":"# displaying the latent features for five users\nmodel.userFactors.show(5, truncate = False)  ","8b97bf50":"model.transform(X_test).show(5)","0b8f8ed5":"model.transform(X_test).where(isnan('prediction')).show(5)","fe58383c":"X_train[X_train.userId.isin([24578,54401,63338,19639,479])].show()","0ff394d4":"# total number of NaN predictions\nmodel.transform(X_test).where(isnan('prediction')).count()","a19630ca":"model.transform(X_test[[\"userId\",\"jokeId\"]]).na.drop()[[\"prediction\"]].show()","ace14815":"evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")","aa3e5b49":"train_predictions = model.transform(X_train)\ntest_predictions = model.transform(X_test).na.drop()\nprint(\"RMSE on training data : \", evaluator.evaluate(train_predictions))\nprint(\"RMSE on test data: \", evaluator.evaluate(test_predictions))","d3a4b299":"from pyspark.ml.tuning import CrossValidator,ParamGridBuilder","fae7b90f":"params = ParamGridBuilder()","601913e1":"params = ParamGridBuilder().addGrid(ALS.rank, [5, 6, 7, 8, 9, 10]) \\\n        .addGrid(ALS.regParam, [0.001, 0.01, 0.1, 1, 10]) \\\n        .build()","c6aea24b":"params = ParamGridBuilder().addGrid(ALS.rank, [5]).build()\n        #.addGrid(ALS.regParam, [0.001]) \\\n        #.build()","f3747307":"params = ParamGridBuilder().build()","0e6a3035":"cv = CrossValidator(estimator=ALS(userCol=\"userId\",itemCol=\"jokeId\",ratingCol=\"rating\",coldStartStrategy=\"drop\"),estimatorParamMaps=params, evaluator=evaluator)\ncv.fit(X_train)\n#cv = cv.setNumFolds(10).setSeed(0).fit(X_train)","8ff1bd0d":"cv = cv.fit(X_train)","7faa4d28":"cv.avgMetrics","f24d4cd8":"cv.avgMetrics","1380c538":"cv.avgMetrics","2845aeff":"cv.avgMetrics","851a40fa":"cv.avgMetrics","757fdcd2":"evaluator.evaluate(cv.transform(X_test).na.drop())","ed32c8e2":"evaluator.evaluate(cv.transform(X_test))","c6d203c8":"evaluator.evaluate(cv.transform(X_test))","a2fc0f41":"predictions.show(5)","d9e8f5a5":"X_train.where((X_train.userId == 5518) & (X_train.jokeId==148)).show()","0137bf1e":"# joining X_test and prediction dataframe and also dropping the records for which no predictions made\nratesAndPreds = X_test.join(other=predictions,on=['userId','jokeId'],how='inner').na.drop() \nratesAndPreds.show(5)","b5491c8d":"# converting the columns into numpy arrays for direct and easy calculations \nrating = np.array(ratesAndPreds.select(\"rating\").collect()).ravel()\nprediction = np.array(ratesAndPreds.select(\"prediction\").collect()).ravel()\nprint(\"RMSE : \", np.sqrt(np.mean((rating - prediction)**2)))","74963de3":"# recommending top 3 jokes for all the users with highest predicted rating \nmodel.recommendForAllUsers(3).show(5,truncate = False)","85bb1e16":"model.recommendForAllUsers(3).count()","3072f56a":"### Notebook - Table of Content\n\n1. [**Importing necessary libraries**](#1.-Importing-necessary-libraries)   \n2. [**Loading the data into PySpark dataframes**](#2.-Loading-the-data-into-PySpark-dataframes) \n3. [**Basic data exploration**](#3.-Basic-data-exploration)  \n    3.1 [**Total number of users, movies and ratings**](#3.1-Total-number-of-users,-movies-and-ratings)  \n    3.2 [**Distribution of ratings**](#3.2-Distribution-of-ratings)  \n    3.3 [**Ratings per user**](#3.3-Ratings-per-user)      \n    3.4 [**Ratings per movie**](#3.4-Ratings-per-movie)  \n4. [**Train-test split**](#4.-Train-test-split)  \n5. [**ALS based recommendation**](#5.-ALS-based-recommendation)  \n    5.1 [**Analysing the model**](#5.1-Analysing-the-model)     \n    5.2 [**Evaluating the results**](#5.2-Evaluating-the-results)  \n    5.3 [**Hyperparameter tuning**](#5.3-Hyperparameter-tuning)\n6. [**Additional performance measures for Recommendation**](#6.-Additional-performance-measures-for-Recommendation)      \n    6.1 [**Precision and Recall**](#6.1-Precision-and-Recall)    \n7. [**Handling Cold Start problem**](#7.-Handling-Cold-Start-problem)        ","751fe7e5":"#### 5.2. Evaluating the results","486b4ee2":"#### 5.1 Analysing the model\n\nIt is common to have users and\/or items in the test dataset that were not part of the training dataset and transform() method implementation of ALS returns **NaN** predictions for such records.  ","df89f841":"**Matrix factorization** is a class of collaborative filtering algorithms used in recommender systems. **Matrix factorization** approximates a given rating matrix as a product of two lower-rank matrices.\nIt decomposes a rating matrix R(nxm) into a product of two matrices W(nxd) and U(mxd).\n\n\\begin{equation*}\n\\mathbf{R}_{n \\times m} \\approx \\mathbf{\\hat{R}} = \n\\mathbf{V}_{n \\times k} \\times \\mathbf{V}_{m \\times k}^T\n\\end{equation*}","262c98ee":"* Minimum number of ratings given by a user = **1**\n* Maximum number of ratings given by a user = **140**\n* Average ratings per user = **30**(after rounding)","8ea052b6":"#### 3.2 Distribution of ratings","4b282ef8":"#### Step 6. Recommending jokes","f48c2b8f":"### 4. Train-test Split","9f1f79ab":"### 3. Basic data exploration\n\n#### 3.1 Total number of users, movies and ratings","baf69a5d":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python\/","ce1b8020":"#### 3.4 Ratings per joke","de84b26d":"#### Step 5. Evaluating the model","497bdce1":"User with ids [24578,54401,63338,19639,479] from the test set are not available in the training dataset. Hence, the trained model does not generate latent factors for such users and the transform() method returns **NaN** predictions for them. ","cd168e80":"### 1. Importing the necessary libraries","c54694c8":"#### 3.3 Ratings per user","161491b9":"* Minimum number of ratings to a joke = **166** \n* Maximum number of ratings to a joke = **59122**\n* Average ratings per joke = **12582**(after rounding) ","3da705e7":"### 2. Loading the data into PySpark dataframes","1f99f3c2":"### 5. ALS based recommendation"}}