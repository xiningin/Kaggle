{"cell_type":{"63a6b5c8":"code","f2141702":"code","c430a3d0":"code","35b398f8":"code","bbc736a9":"code","6837f4d1":"code","2e659c13":"code","7212f15f":"code","6ff3ce57":"code","e424f77e":"code","d3de7862":"code","088eb1b9":"code","5a109b6c":"code","77dcf7bf":"code","5b614450":"code","6f1eda19":"code","61b44c27":"code","72458e58":"code","0fb94684":"code","b9d62486":"code","8528b8ed":"code","914fb957":"code","9191a4ad":"code","e1db8aee":"code","01148b2a":"code","4fb8f8d0":"code","50383eee":"code","565c5087":"code","4eaf3599":"code","69c1c215":"code","5405253d":"code","ef40f62e":"code","62383d98":"code","7aa88559":"code","f57e2555":"markdown","070e7db2":"markdown","fca51576":"markdown","2d86f4fa":"markdown","fa6309fb":"markdown","549ea23d":"markdown","cedd4a4d":"markdown","ab519a03":"markdown","2c303a81":"markdown","430493fb":"markdown","c3a25a8e":"markdown","35a8261d":"markdown","3e9e77dd":"markdown","9a676a7b":"markdown","04478436":"markdown"},"source":{"63a6b5c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f2141702":"# ! pip install scikit-learn  -U\n\n# execute and restart","c430a3d0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nsns.set_style('darkgrid')\n\nfrom sklearn.preprocessing import OneHotEncoder,MinMaxScaler,StandardScaler\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV,SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import classification_report\n\nfrom pandas_profiling import ProfileReport","35b398f8":"df = pd.read_csv('..\/input\/adult-census-income\/adult.csv',na_values=['?'])","bbc736a9":"df","6837f4d1":"df.head()","2e659c13":"df.columns","7212f15f":"df.info()","6ff3ce57":"df.describe(include='all')","e424f77e":"plt.figure(figsize=(10,10))\nsns.heatmap(df.isna())","d3de7862":"df.isna().sum()","088eb1b9":"df=df.dropna()","5a109b6c":"plt.figure(figsize=(10,10))\nsns.heatmap(df.isna())","77dcf7bf":"def report(df):\n    design_report = ProfileReport(df)\n    return design_report.to_widgets()\n\nreport(df)","5b614450":"X=df.drop(['income'],axis=1)\ny=df[['income']]","6f1eda19":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=42)\nx_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.15,random_state=42)","61b44c27":"(x_train.shape,x_val.shape,x_test.shape)","72458e58":"df.info()","0fb94684":"for i in df.columns[df.dtypes=='object']:\n    print(df.value_counts(i))\n    print('-'*100)\ndf[['workclass', 'education', 'marital.status', 'occupation',\n       'relationship', 'race', 'sex', 'native.country']].nunique(axis=0).sum()","b9d62486":"df.columns[df.dtypes=='object']","8528b8ed":"oh=ColumnTransformer([\n    ('encoder',OneHotEncoder(drop='first',sparse=False),\n     ['workclass', 'education', 'marital.status', 'occupation',\n       'relationship', 'race', 'sex', 'native.country'])\n],remainder='passthrough')\n\npipeline=Pipeline([\n    ('encoder',oh),\n    ('scaler',StandardScaler())\n])","914fb957":"x_train.iloc[0,:]","9191a4ad":"x_train=pipeline.fit_transform(x_train)\nx_test=pipeline.transform(x_test)\nx_val=pipeline.transform(x_val)","e1db8aee":"(x_train.shape,x_val.shape,x_test.shape)","01148b2a":"pipeline[0].transformers_[0][1].categories_","4fb8f8d0":"x_train[0]","50383eee":"o1=OneHotEncoder(drop='first',sparse=False)\ny_train=o1.fit_transform(y_train)\ny_val=o1.transform(y_val)\ny_test=o1.transform(y_test)","565c5087":"o1.categories_","4eaf3599":"lr1=LogisticRegression(max_iter=3000)\n\nlr1.fit(x_train,y_train.ravel())\nlr1.fit(x_val,y_val.ravel())\n\npred1=lr1.predict(x_test)\n\nprint(classification_report(y_test,pred1))","69c1c215":"lr1=LogisticRegressionCV(max_iter=3000,Cs=20,n_jobs=-1)\n\nlr1.fit(x_train,y_train.ravel())\nlr1.fit(x_val,y_val.ravel())\n\npred1=lr1.predict(x_test)\n\nprint(classification_report(y_test,pred1))","5405253d":"lr1=SGDClassifier()\n\nlr1.fit(x_train,y_train.ravel())\nlr1.fit(x_val,y_val.ravel())\n\npred1=lr1.predict(x_test)\n\nprint(classification_report(y_test,pred1))","ef40f62e":"lr1=SVC()\n\nlr1.fit(x_train,y_train.ravel())\nlr1.fit(x_val,y_val.ravel())\n\npred1=lr1.predict(x_test)\n\nprint(classification_report(y_test,pred1))","62383d98":"# param=dict(C=[1,10,100,1000],gamma=[1,0.1,0.01])\n\n# lr1=GridSearchCV(SVC(),param,n_jobs=-1,verbose=1)\n\n# lr1.fit(x_train,y_train.ravel())\n# lr1.fit(x_val,y_val.ravel())\n\n# pred1=lr1.predict(x_test)\n\n# print(classification_report(y_test,pred1))","7aa88559":"lr1=RandomForestClassifier(n_estimators=500,n_jobs=-1,verbose=1)\n\nlr1.fit(x_train,y_train.ravel())\nlr1.fit(x_val,y_val.ravel())\n\npred1=lr1.predict(x_test)\n\nprint(classification_report(y_test,pred1))","f57e2555":"## Logistic Regression","070e7db2":"# Package Import","fca51576":"# Data preprocessing","2d86f4fa":"## Pandas Profiling","fa6309fb":"# Null Check","549ea23d":"## SGD Classifier","cedd4a4d":"# Data Input","ab519a03":"# Model bulding","2c303a81":"# SVC","430493fb":"# Null Removal","c3a25a8e":"# Train Test Split","35a8261d":"# Data Analysis","3e9e77dd":"## Logistic Regression CV","9a676a7b":"# SVC Grid Search","04478436":"# Random Forrest Classifier"}}