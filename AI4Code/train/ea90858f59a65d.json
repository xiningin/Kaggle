{"cell_type":{"2a62ac3f":"code","7b0a618c":"code","948a6c86":"code","ed59e1cd":"code","373d0650":"code","7df7fb96":"code","3f99951f":"code","c81c9742":"code","25d86eae":"code","586c284d":"code","7e549ca0":"code","bc39aaad":"code","e944ff31":"code","0ae2ac34":"code","2c3fd980":"code","19c6a40c":"code","45d1dad7":"code","65ef4e24":"code","718c54c7":"code","c5847bd4":"code","1ec592df":"code","0ffea403":"code","f6b31f01":"code","9d34b3c5":"code","a7a52b49":"code","c9cecbb7":"code","a7f6a5a9":"code","3883eb39":"code","93301618":"code","e0bbd730":"code","b57494a0":"code","9ab7a2e9":"code","38dc7448":"code","2571c70c":"code","ac3796f1":"code","e97abf92":"code","5fb0de31":"code","a4b52173":"code","21fc370c":"code","5423dac5":"code","8cdd1b7c":"code","07993ffd":"code","f75956d8":"code","af811c90":"code","2c760c47":"code","82359d27":"code","e1fd6c58":"code","5c0d7a6d":"code","d2060293":"code","9808b8f4":"code","d193c757":"code","52f35b61":"code","4ad80a18":"code","79526845":"code","cc2a284e":"code","db07f430":"code","16a4b7d3":"code","ca0fd4bc":"code","0731213b":"code","21a18a87":"markdown","9d3584c1":"markdown","95df6ef3":"markdown","8b7d0442":"markdown","89a3de2e":"markdown","69830691":"markdown","0afd64da":"markdown"},"source":{"2a62ac3f":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,Dense,Flatten,MaxPooling2D,BatchNormalization,Dropout\nfrom keras.utils import to_categorical\nfrom keras.utils.vis_utils import plot_model\n%matplotlib inline","7b0a618c":"df = pd.read_csv('..\/input\/train.csv')","948a6c86":"df.head()","ed59e1cd":"x = df.drop('label',1)\ny = df['label']\ny = to_categorical(y)","373d0650":"x = x\/255.0","7df7fb96":"x = x.values.reshape(42000,28,28,1)","3f99951f":"x.shape","c81c9742":"plt.imshow(x[3].reshape(28,28),cmap = 'gray')","25d86eae":"model1 = Sequential()\nmodel1.add(Convolution2D(32,(5,5),activation='relu',input_shape = (28,28,1),padding='same'))\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Convolution2D(32,(5,5),activation='relu',padding='same'))\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Convolution2D(64,(3,3),activation='relu',padding = 'same'))\nmodel1.add(MaxPooling2D(2,2))\nmodel1.add(Convolution2D(64,(3,3),activation = 'relu',padding = 'same'))\nmodel1.add(Flatten())\nmodel1.add(Dense(256,activation='relu'))\nmodel1.add(Dropout(0.2))\nmodel1.add(Dense(10,activation = 'softmax'))","586c284d":"model1.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])","7e549ca0":"model1.summary()","bc39aaad":"history = model1.fit(x,y,batch_size=32,epochs=10,validation_split=0.1)","e944ff31":"values = history.history\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\nvalidation_loss = values['val_loss']\ntraining_loss = values['loss']\nepochs = range(10)","0ae2ac34":"plt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","2c3fd980":"plt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.plot(epochs,training_loss,label = 'Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","19c6a40c":"model2 = Sequential()\nmodel2.add(Convolution2D(32,(3,3),activation='relu',input_shape = (28,28,1)))\nmodel2.add(Convolution2D(32,(3,3),activation='relu'))\nmodel2.add(Convolution2D(64,(3,3),activation='relu'))\nmodel2.add(Convolution2D(64,(3,3),activation = 'relu'))\nmodel2.add(Flatten())\nmodel2.add(Dense(256,activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(10,activation = 'softmax'))","45d1dad7":"model2.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])","65ef4e24":"model2.summary()","718c54c7":"history = model2.fit(x,y,batch_size=32,epochs=10,validation_split=0.1)","c5847bd4":"values = history.history\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\nvalidation_loss = values['val_loss']\ntraining_loss = values['loss']\nepochs = range(10)","1ec592df":"plt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","0ffea403":"plt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.plot(epochs,training_loss,label = 'Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","f6b31f01":"model3 = Sequential()\nmodel3.add(Convolution2D(32,(3,3),activation='relu',input_shape = (28,28,1)))\nmodel3.add(MaxPooling2D(2,2))\nmodel3.add(Convolution2D(64,(3,3),activation='relu'))\nmodel3.add(Flatten())\nmodel3.add(Dense(128,activation='relu'))\nmodel3.add(Dropout(0.2))\nmodel3.add(Dense(10,activation = 'softmax'))","9d34b3c5":"model3.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])","a7a52b49":"model3.summary()","c9cecbb7":"history = model3.fit(x,y,batch_size=32,epochs=10,validation_split=0.1)","a7f6a5a9":"values = history.history\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\nvalidation_loss = values['val_loss']\ntraining_loss = values['loss']\nepochs = range(10)","3883eb39":"plt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","93301618":"plt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.plot(epochs,training_loss,label = 'Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","e0bbd730":"model4 = Sequential()\nmodel4.add(Convolution2D(32,(5,5),activation='tanh',input_shape = (28,28,1),padding='same'))\nmodel4.add(MaxPooling2D(2,2))\nmodel4.add(Convolution2D(32,(5,5),activation='tanh',padding='same'))\nmodel4.add(MaxPooling2D(2,2))\nmodel4.add(Convolution2D(64,(3,3),activation='tanh',padding = 'same'))\nmodel4.add(MaxPooling2D(2,2))\nmodel4.add(Convolution2D(64,(3,3),activation = 'tanh',padding = 'same'))\nmodel4.add(Flatten())\nmodel4.add(Dense(256,activation='relu'))\nmodel4.add(Dropout(0.2))\nmodel4.add(Dense(10,activation = 'softmax'))","b57494a0":"model4.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])","9ab7a2e9":"model4.summary()","38dc7448":"history = model4.fit(x,y,batch_size=32,epochs=10,validation_split=0.1)","2571c70c":"values = history.history\nvalidation_acc = values['val_acc']\ntraining_acc = values['acc']\nvalidation_loss = values['val_loss']\ntraining_loss = values['loss']\nepochs = range(10)","ac3796f1":"plt.plot(epochs,validation_acc,label = 'Validation Accuracy')\nplt.plot(epochs,training_acc,label = 'Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","e97abf92":"plt.plot(epochs,validation_loss,label = 'Validation Loss')\nplt.plot(epochs,training_loss,label = 'Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","5fb0de31":"plot_model(model1,to_file='model1.png',show_layer_names=True,show_shapes=True)\nplot_model(model2,to_file='model2.png',show_layer_names=True,show_shapes=True)\nplot_model(model3,to_file='model3.png',show_layer_names=True,show_shapes=True)\nplot_model(model4,to_file='model4.png',show_layer_names=True,show_shapes=True)","a4b52173":"test = pd.read_csv('..\/input\/test.csv')","21fc370c":"test.head()","5423dac5":"sub = pd.read_csv('..\/input\/sample_submission.csv')","8cdd1b7c":"sub.head()","07993ffd":"test = test\/255.0","f75956d8":"test.shape","af811c90":"test = test.values.reshape(28000,28,28,1)","2c760c47":"predict_model1 = model1.predict_classes(test)","82359d27":"predict_model2 = model2.predict_classes(test)","e1fd6c58":"predict_model3 = model3.predict_classes(test)","5c0d7a6d":"predict_model4 = model4.predict_classes(test)","d2060293":"final_prediction = 0.25*predict_model1+0.25*predict_model2+0.25*predict_model3+0.25*predict_model4","9808b8f4":"final_prediction = np.round(final_prediction)\n","d193c757":"answer = []\nfor i in range(len(final_prediction)):\n    answer.append(int(final_prediction[i]))","52f35b61":"predict = pd.Series(answer,name=\"Label\")","4ad80a18":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predict],axis = 1)","79526845":"submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","cc2a284e":"predict = pd.Series(predict_model1,name=\"Label\")\nsubmission_1 = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predict],axis = 1)\nsubmission_1.to_csv(\"submission1.csv\",index=False)","db07f430":"predict = pd.Series(predict_model2,name=\"Label\")\nsubmission_2 = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predict],axis = 1)\nsubmission_2.to_csv(\"submission2.csv\",index=False)","16a4b7d3":"predict = pd.Series(predict_model3,name=\"Label\")\nsubmission_3 = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predict],axis = 1)\nsubmission_3.to_csv(\"submission3.csv\",index=False)","ca0fd4bc":"predict = pd.Series(predict_model4,name=\"Label\")\nsubmission_4 = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predict],axis = 1)\nsubmission_4.to_csv(\"submission4.csv\",index=False)","0731213b":"submission['Label'] = int(submission['Label'])","21a18a87":"**Reading the training dataset from CSV file and displaying it.**","9d3584c1":"* **Dividing the Dataset into X and Y**                                                 \nConverting y label to categorical variable that is doing one hot encoding of the labels.\n* 0 = [1,0,0,0,0,0,0,0,0,0]\n* 1 = [0,1,0,0,0,0,0,0,0,0]\n* 2 = [0,0,1,0,0,0,0,0,0,0]\nand so on till 9[](http:\/\/)","95df6ef3":"**Normalizing the data so that processing becomes fast**","8b7d0442":"**As we can see that the each row of the csv represents one image i.e digit in this case. We now want to reshape the data in order to make the one dimensional array of pixels that is one row into 28x28 square image.\nReshaping the values of X into 42000,28,28,1. 42000 are the number of images there in the training data. 28x28 is the image size and 1 represents the number of channels in the image. ! represent that it is a gray scale image.\nHad it been coloured image we would have mentioned 3 instead of 1.**","89a3de2e":"**Loading required libraries**","69830691":"**Displaying the image of the data.**","0afd64da":"Defining the model now\n1. First Layer is a convolution layer with 32 neurons and having a kernel size of (5,5). The padding is kept same which means we are not reducing the dimensions of the image after convolution. Convolution layer will extract features from the images and help it generalize in order to train the neural netwrok and find optimal values for the kernels. Padding will add an additional layer of zeros on all the sides of the image. This convolution layer is followed by the maxpooling layer. We add maxpooling layer for 2 reasons. First is to reduce the dimensions of the image so that processing becomes faster. Secondly to remove the spartiality from the image which is obtained after the convolution layer.\n\n2. Second layer is same as first layer\n3. Third and forth layer have Convolution layer with 64 neurons each and kernel size of (3,3) and activation function of relu with padding parameter as same followed by maxpooling layer.\n4. Then we flatten the output from convolution layer which is fed to the dense connected layers having 256 neurons and relu activation function followed by a dropout layer of 20% deactivation of neurons.\n5. Finally we have the output layer having 10 neurons because those are the number of classes in our y label which uses a softmax function which gives the probability of a particular input belonging to the particular y class."}}