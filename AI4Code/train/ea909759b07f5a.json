{"cell_type":{"781f32f6":"code","32a8f1de":"code","f8da700a":"code","b93e4c27":"code","ed033a74":"code","79e21b86":"code","b3031b89":"code","9dd8c658":"code","7ecda9d2":"code","2c974ca5":"code","67667f6c":"code","3aae09ae":"markdown","2234a330":"markdown","4c3f31b0":"markdown","f006f135":"markdown","174549f4":"markdown","4ab73e6c":"markdown","aa41a614":"markdown"},"source":{"781f32f6":"# Imports and helper functions\nimport tensorflow as tf\n\ndef int_list_to_hex(l):\n    return ''.join(\"{0:0{1}x}\".format(x, 2) for x in l)\n\ndef int_list_to_string(l):\n    return ''.join(chr(x) for x in l)","32a8f1de":"message_str = \"Hello this is a secret message.\"\nmessage = tf.constant([ord(c) for c in message_str], tf.uint8)\n\nkey_uint32 = tf.Variable(tf.random_uniform(message.shape, minval=0, maxval=2**8, dtype=tf.int32))\nkey = tf.cast(key_uint32, tf.uint8)\n\nencrypt_xor = tf.bitwise.bitwise_xor(message, key)\ndecrypt_xor = tf.bitwise.bitwise_xor(encrypt_xor, key)\n\nwith tf.Session().as_default() as session:\n    session.run(tf.global_variables_initializer())\n    print('key:'.ljust(24), int_list_to_hex(key.eval()))\n    print('message:'.ljust(24), int_list_to_string(message.eval()))\n\n    ciphertext = encrypt_xor.eval()\n    print('encrypted ciphertext:'.ljust(24), int_list_to_hex(ciphertext))\n\n    plaintext = decrypt_xor.eval()\n    print('decrypted plaintext:'.ljust(24), int_list_to_string(plaintext))","f8da700a":"BLOCK_SIZE = 32\nNUM_ROUNDS = 16\n\ndef feistel_network_encrypt_round(round_key, left_0, right_0):\n    \"\"\"Run one encryption round of a Feistel network.\n\n    Args:\n        round_key: The PRF is keyed with this round key.\n        left_0: the left half of the input.\n        right_0: the right half of the input.\n    Returns:\n        right n+1: the right half ouput.\n        left n+1: the left half output.\n    \"\"\"\n    # (Using bitwise inversion instead of a true PRF)\n    f_ri_ki = tf.bitwise.invert(right_0)\n    right_plusone = tf.bitwise.bitwise_xor(left_0, f_ri_ki)\n\n    return right_0, right_plusone\n\n\ndef feistel_network_decrypt_round(round_key, left_plusone, right_plusone):\n    \"\"\"Run one decryption round of a Feistel network.\n\n    Args:\n        round_key: The PRF is keyed with this round key.\n        left_plusone: the preceding left half of the input.\n        right_plusone: the precedingright half of the input.\n    Returns:\n        left n-1: the decrypted left half.\n        right n-1: the decrypted right half.\n    \"\"\"\n    # (Using bitwise inversion instead of a true PRF)\n    f_lip1_ki = tf.bitwise.invert(left_plusone)\n    right_0 = tf.bitwise.bitwise_xor(right_plusone, f_lip1_ki)\n\n    return right_0, right_plusone\n\ndef pkcs7_pad(text):\n    # Not true PKCS #7 padding, only for demo purposes.\n    val = BLOCK_SIZE - (len(text) % BLOCK_SIZE)\n    return text + ('%d' % val) * val\n\ndef pkcs7_unpad(text):\n    val = text[-1]\n    return text[:(len(text) - int(text[-1]))]\n\nmessage_str = pkcs7_pad(\"Hello this is a secret message.\")\ninput_tensor = tf.constant([ord(c) for c in message_str], tf.uint8)\n\nkey_uint32 = tf.Variable(tf.random_uniform((NUM_ROUNDS,), minval=0, maxval=2**8, dtype=tf.int32))\nkey = tf.cast(key_uint32, tf.uint8)\n\nwith tf.Session().as_default() as session:\n    session.run(tf.global_variables_initializer())\n\n    # Keys here are used to seed the random shuffle.\n    # Key is 16 bytes, one byte per round.\n    # (Note: this does not follow the DES key scheduling algorithm).\n    print('key:'.ljust(24), int_list_to_hex(key.eval()))\n    print('padded message:'.ljust(24), int_list_to_string(input_tensor.eval()))\n    \n    # Encryption: split the input in half and run the network for 16 rounds.\n    left, right = tf.split(input_tensor, num_or_size_splits=2)\n    \n    for round_num in range(NUM_ROUNDS):\n        right, left = feistel_network_encrypt_round(key[round_num], left, right)\n    \n    print('encrypted ciphertext:'.ljust(24), int_list_to_hex(left.eval()) + int_list_to_hex(right.eval()))\n\n    # Decryption: run the network in reverse.\n    for round_num in range(NUM_ROUNDS):\n        left, right = feistel_network_decrypt_round(key[round_num], left, right)\n    \n    print('decrypted plaintext:'.ljust(24), pkcs7_unpad(int_list_to_string(left.eval()) + int_list_to_string(right.eval())))","b93e4c27":"# Import libraries \n\n# To support both python 2 and python 3\n# from __future__ import division, print_function, unicode_literals\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import axis3d\nfrom mpl_toolkits import mplot3d \nimport os\nimport sys\nimport numpy.random as rnd\n\nimport tensorflow as tf\n# import tensorflow.compat.v1 as tf\n# tf.disable_v2_behavior() ","ed033a74":"rnd.seed(4)\nm = 5\nw1, w2 = 0.1, 0.3\nnoise = 0.1\n\nangles = rnd.rand(m) * 3 * np.pi \/ 2 - 0.5\ndata = np.empty((m, 3))\ndata[:, 0] = np.cos(angles) + np.sin(angles)\/2 + noise * rnd.randn(m) \/ 2\ndata[:, 1] = np.sin(angles) * 0.7 + noise * rnd.randn(m) \/ 2\ndata[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * rnd.randn(m)\n\nprint(f\"np.array([data[:, 1]])\\ndata is:\\n{data}\")","79e21b86":"x=np.array([[i for i in range(1,11)]])\ny=np.array([[i for i in range(5,15)]])\nz=np.array([[i for i in range(4,14)]])\n\nx = np.array([data[:, 0]])\ny = np.array([data[:, 1]])\nz = np.array([data[:, 2]])","b3031b89":"fig = pyplot.figure()\nax1 = fig.add_subplot(111, projection='3d')\nax1.plot_wireframe(x, y, z)\n# ax1.plot_wireframe(data[:, 0], data[:, 1], data[:, 2])\nax1.set_xlabel(\"X axis\")\nax1.set_ylabel(\"Y axis\")\nax1.set_zlabel(\"Z axis\")\npyplot.show()","9dd8c658":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(data[:m\/\/2])\nX_test = scaler.transform(data[m\/\/2:])","7ecda9d2":"# to make this notebook's output stable across runs\ndef reset_graph(seed=42):\n    tf.reset_default_graph()\n    tf.set_random_seed(seed)\n    np.random.seed(seed)\n    \n\nreset_graph()\n\nn_inputs = 3\nn_hidden = 2  # codings\nn_outputs = n_inputs\n\nlearning_rate = 0.01\n\nX = tf.placeholder(tf.float32, shape=[None, n_inputs])\nhidden = tf.layers.dense(X, n_hidden)\noutputs = tf.layers.dense(hidden, n_outputs)\n\nreconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n\noptimizer = tf.train.AdamOptimizer(learning_rate)\ntraining_op = optimizer.minimize(reconstruction_loss)\n\ninit = tf.global_variables_initializer()","2c974ca5":"n_iterations = 1000\ncodings = hidden\n\nwith tf.Session() as sess:\n    init.run()\n    for iteration in range(n_iterations):\n        training_op.run(feed_dict={X: X_train})\n    codings_val = codings.eval(feed_dict={X: X_test})","67667f6c":"fig = plt.figure(figsize=(4,3))\nplt.plot(codings_val[:,0], codings_val[:, 1], \"b.\")\nplt.xlabel(\"$z_1$\", fontsize=18)\nplt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n# save_fig(\"linear_autoencoder_pca_plot\")\nplt.show()","3aae09ae":"That's it for now. I don't think there are any practical use cases for writing cryptographic algorithms in TensorFlow, unless maybe if you need to encrypt an extremely large input by distributing your computation across many nodes. And even then, you shouldn't use TensorFlow for real cryptography, and more importantly, unless it is your career, you shouldn't be implementing your own cryptographic algorithms \ud83d\ude09.","2234a330":"### Normalize the data:","4c3f31b0":"# DES, the Data Encryption Standard\n\n<img style=\"float: right; width: 20%; margin-left: 1em;\" src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/6\/6a\/DES-main-network.png\/250px-DES-main-network.png\" \/>\n\nThe [Data Encryption Standard](https:\/\/en.wikipedia.org\/wiki\/Data_Encryption_Standard), or DES, was the crypto workhorse of the 1970's-1990's. The core of the algorithm is a Feistel Network, which is a construction that lets you create an invertible function (i.e. a function that can encrypt a message and decrypt it to the same message) out of a non-invertible pseudo-random function (for instance a hash function, but with the same output size as the input).\n\nThe Feistel Network works by splitting the input into two halves (a left half and a right half) and feeding those halves through 16 rounds, as illustrated in the image to the right.\n\nGiven a pseudo-random function $F$, the next round of the encryption algorithm (left half: $L_{i+1}$, right half: $R_{i+1}$) is computed as:\n\n$$L_{i+1} = R_i$$\n\n$$R_{i+1} = L_i  \\oplus F(R_i,K_i)$$\n\nSimilarly the decryption algorithm is the reverse:\n\n$$L_i = R_{i+1} \\oplus F(L_{i+1},K_i)$$\n\n$$R_i = L_{i+1}$$\n","f006f135":"# The One Time Pad\n\nThe One-Time Pad is the simplest and the most secure cipher. So why doesn't everything use it?\n\nFor a key $k$ and a message $m$, the OTP is defined as $k \\oplus m = c$. You just XOR ($\\oplus$) every byte of the key with the message. This gives you 100% perfect secrecy, since XOR'ing a uniform random distribution with anything always gives you a uniform random distribution.\n\nHowever, the key must be as large as the message you send, and if you have a secure way of transmitting a key that large, why not use that method to send the message? OTP is still used for extremely security-critical things, like the [president's red phone](https:\/\/www.hackthis.co.uk\/articles\/one-time-pad#practical-application-of-the-concept-of-the-one-time-pad).\n\nIn TensorFlow we define we can use the builtin method `tf.bitwise.bitwise_xor` to XOR vectors of arbitrary length, giving us a One-Time Pad.\n","174549f4":"### start to build an autoencoder\n\nNote: instead of using the `fully_connected()` function from the `tensorflow.contrib.layers` module (as in the book), we now use the `dense()` function from the `tf.layers` module, which did not exist when this chapter was written. This is preferable because anything in contrib may change or be deleted without notice, while `tf.layers` is part of the official API. As you will see, the code is mostly the same.\n\nThe main differences relevant to this chapter are:\n* the `scope` parameter was renamed to `name`, and the `_fn` suffix was removed in all the parameters that had it (for example the `activation_fn` parameter was renamed to `activation`).\n* the `weights` parameter was renamed to `kernel` and the weights variable is now named `\"kernel\"` rather than `\"weights\"`,\n* the bias variable is now named `\"bias\"` rather than `\"biases\"`,\n* the default activation is `None` instead of `tf.nn.relu`","4ab73e6c":"# Doing Cryptography in TensorFlow\n\n<img src=\"https:\/\/i.stack.imgur.com\/IGGiW.gif\" alt=\"A Feistel Network, the algorithm behind DES.\" style=\"max-width: 360px; display: inline;\" \/>\n<img src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*Gh5PS4R_A5drl5ebd_gNrg@2x.png\" alt=\"A neural network.\" style=\"max-width: 360px; display: inline;\" \/>\n\n**[TensorFlow](https:\/\/www.tensorflow.org\/)** is a popular machine learning framework. Under the hood, TensorFlow is a general platform for doing computation over tensors in the structure of a graph. While studying Cryptography, a completely different field of Computer Science, you might begin to notice that cryptographic algorithms are also frequently structured as the manipulation of vectors and matrices of bytes in the structure of a graph. You might begin to see where this is going.\n\nWhat follows is a completely frivolous experiment to implement various cryptographic algorithms in TensorFlow.\n\n_**Important note:** do not use this code for real cryptography!_\n\n----------\n\n<small>Above on the left: the Feistel Network from the DES cipher, implemented below. On the right: a deep neural network.<\/small>\n\n","aa41a614":"# With Neural Network"}}