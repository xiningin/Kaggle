{"cell_type":{"36c507a3":"code","0e2b046f":"code","d72d3f4b":"code","3b78113b":"code","2aedae1f":"code","d981d26a":"code","41d9beb4":"code","27b33e2e":"code","db4bd996":"code","988f5f79":"code","ed0b8471":"code","8143250b":"code","81ec8a1a":"code","90bd74e4":"code","77716a04":"code","6dd8d591":"code","145a8ed4":"code","2d747733":"code","f009914b":"code","30f7448a":"code","2e4e17e7":"code","a96f63f9":"code","54b00d06":"code","6f3a5601":"code","34c99b3a":"code","a6829a09":"code","bb342db2":"code","408d5184":"code","a3c19925":"code","4db1706d":"code","80e4d11f":"code","ce7c2172":"code","efccbdd7":"code","aebdfcb8":"code","968cf715":"code","3c43c935":"code","05a2cff4":"code","9cc1cf29":"code","18ca556d":"code","60a48228":"code","8d3f7687":"code","3b8ebc50":"code","96097649":"code","57db09d9":"code","e2022ca2":"markdown","64dbbd6a":"markdown","56d4a981":"markdown","3dd7c4df":"markdown","dccf5c16":"markdown","2ace4319":"markdown","cf2d3edd":"markdown","2e9136f4":"markdown"},"source":{"36c507a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e2b046f":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain","d72d3f4b":"y = train[\"label\"]\ny[:10]","3b78113b":"train2 = train.drop(\"label\",axis=1)\ntrain2","2aedae1f":"X = train2.iloc[0].values\nX","d981d26a":"\nX2 = X.reshape(28,28)\nimport matplotlib.pyplot as plt\nplt.imshow(X2)","41d9beb4":"import cv2","27b33e2e":"cv2.imwrite(\"tmp.bmp\",X2)\ntmp = cv2.imread(\"tmp.bmp\")\ntmp.shape","db4bd996":"plt.imshow(tmp)","988f5f79":"X = train2.iloc[0].values\nX2 = X.reshape(28,28)\ncv2.imwrite(\"tmp.bmp\",X2)\ntmp = cv2.imread(\"tmp.bmp\")\nplt.imshow(tmp)","ed0b8471":"for i in range(10):\n    X = train2.iloc[i].values\n    X2 = X.reshape(28,28)\n    cv2.imwrite(\"tmp.bmp\",X2)\n    tmp = cv2.imread(\"tmp.bmp\")\n    plt.figure()\n    plt.imshow(tmp)","8143250b":"def makeimage(num):\n    for i in range(num):\n        X = train2.iloc[i].values\n        X2 = X.reshape(28,28)\n        cv2.imwrite(\"tmp.bmp\",X2)\n        tmp = cv2.imread(\"tmp.bmp\")\n        plt.figure()\n        plt.imshow(tmp)","81ec8a1a":"makeimage(15)","90bd74e4":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torchvision.models import resnet18\nfrom albumentations import Normalize, Compose\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nimport glob\nimport multiprocessing as mp\n\n\n\nif torch.cuda.is_available():\n    device = 'cuda:0'\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')\nelse:\n    device = 'cpu'\nprint(f'Running on device: {device}')","77716a04":"preprocess = Compose([\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1)\n])\n\n# resnext\u306a\u3069\u306epre-train\u30e2\u30c7\u30eb\u306f\u5168\u3066\u3001\u540c\u3058\u65b9\u6cd5\u3067\u6b63\u898f\u5316\u3055\u308c\u305f\u5165\u529b\u753b\u50cf\u3092\u4f7f\u7528\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\u305d\u308c\u306e\u5909\u63db\u3092\u3053\u306e\u95a2\u6570\u3067\u884c\u3046\u3002\u5024\u306fdefault\u3002\n# Compose\u306f\u4eca\u56de\u3042\u307e\u308a\u3001\u610f\u5473\u3092\u306a\u3055\u306a\u3044\n# https:\/\/betashort-lab.com\/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9\/albumentations%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\/ \u306b\u8a73\u7d30\u306f\u66f8\u3044\u3066\u3042\u308b","6dd8d591":"preprocess2 = Compose([\n    Normalize(mean=[0.5,], std=[0.5, ])\n])","145a8ed4":"# \u753b\u50cf\u3092\u3069\u308c\u3060\u3051\u5c0f\u3055\u304f\u3059\u308b\u304b\u306e\u51e6\u7406\nROWS = 32\nCOLS = 32","2d747733":"class GLDataset(Dataset):\n    \n    def __init__(self,df,labels,preprocess=None):\n        self.df = df\n        self.labels = labels\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        \n        # \u3053\u3053\u304b\u3089dataset\u306b\u98df\u308f\u305b\u308b\u524d\u306e\u524d\u51e6\u7406\u306e\u8a18\u8ff0\u3002\n        \n        \n        \n        label = self.labels[idx]\n        \n        #img_pass = self.img_pass[idx]\n        \n        X = self.df.iloc[idx].values\n        X2 = X.reshape(28,28)\n        cv2.imwrite(\"tmp.bmp\",X2)\n        land = cv2.imread(\"tmp.bmp\") \n        \n        land = cv2.resize(land,(ROWS,COLS),interpolation = cv2.INTER_CUBIC)\n       \n        land = cv2.cvtColor(land,cv2.COLOR_BGR2RGB) # augment\u3092\u4f7f\u3046\u3068\u304d\u306bBGR\u304b\u3089RGB\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n        \n        if self.preprocess is not None: # \u3053\u3053\u3067\u3001\u524d\u51e6\u7406\u3092\u5165\u308c\u3066normalization\u3057\u3066\u3044\u308b\u3002\n                augmented = self.preprocess(image=land) # preprocess\u306eimage\u3092face\u3067\u8aad\u3080\n                land = augmented['image'] # https:\/\/betashort-lab.com\/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9\/albumentations%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\/\u3000\u306b\u66f8\u3044\u3066\u3042\u308b\n                \n        return {'landmarks': land.transpose(2, 0, 1), 'label': np.array(label, dtype=int)}  # pytorch\u306fchannnl, x, y\u306e\u5f62\u3002\u3053\u308c\u306f\u8f9e\u66f8\u578b\u3067\u8fd4\u3057\u3066\u3044\u308b\u3002(\u6271\u3044\u3084\u3059\u3044\u3068\u3044\u3046\u3060\u3051\u304b\u3082\u3002)\n        \n        \n        \n        \n        \n        \n        \n        ","f009914b":"train2","30f7448a":"traindf = train2.iloc[:30000,:]\nvaldf = train2.iloc[30000:,:]\n\ntrainlabel = y[:30000]\nvallabel = y[30000:]","2e4e17e7":"# instance\u5316\ntrain_dataset = GLDataset(\n    df=traindf,\n    labels=trainlabel.to_numpy(),\n    preprocess=preprocess\n)\n\nval_dataset = GLDataset(\n    df=valdf,\n    labels=vallabel.to_numpy(),\n    preprocess=preprocess\n)","a96f63f9":"BATCH_SIZE = 1028\n\n#NUM_WORKERS = mp.cpu_count()\nNUM_WORKERS = 0 # \u3053\u3053\u30920\u306b\u3057\u306a\u3044\u3068\u52d5\u304b\u306a\u3044\u3002cpu\u306e\u4ed5\u69d8\u500b\u6570\u3002\u2190\u5b9f\u306f\u52d5\u304f\u3053\u3068\u304c\u5224\u660e\u3002class\u306e\u4e2d\u8eab\u6b21\u7b2c\uff01","54b00d06":"## DataLoader\u306fimport torch.utils.data.Dataset\u3067import\u6e08\u307f\u306e\u3082\u306e\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True, #https:\/\/schemer1341.hatenablog.com\/entry\/2019\/01\/06\/024605 \u3092\u53c2\u8003. id\u304c\u308f\u304b\u3089\u306a\u304f\u306a\u308b\n    num_workers=NUM_WORKERS\n)\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS\n)","6f3a5601":"encoder = resnet18(pretrained=True) #  pretrained = True\u306fimagenet\u304b\u3089pre-train\u30e2\u30c7\u30eb\u3092\u4f7f\u3046","34c99b3a":"class LandmarkClassifier(nn.Module): # nn.Module\u304c\u5165\u3063\u3066\u3044\u308b\u306e\u304c\u3001\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\u3063\u307d\u3044\n    \n    def __init__(self, encoder, in_channels=3, num_classes=10): \n        \n        super(LandmarkClassifier, self).__init__() # nn.Module\u306e__init__\u3092\u7d99\u627f\u3002https:\/\/blog.codecamp.jp\/python-class-2\n        \n        self.encoder = encoder\n        \n        # Modify input layer. # \u5165\u53e3\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u3092\u5408\u308f\u305b\u308b\u3002default\u306eResnet\u306eclass\u306f64 channel\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u305d\u308c\u3092in_channels\u306b\u3059\u308b\u3002\n        # \u3053\u3053\u306e\u8a18\u8ff0\u304cencoder\u3054\u3068\u306b\u4ee3\u308f\u308b\u306e\u3067\u3001efficientnet\u4f7f\u3046\u3068\u304d\u306f\u5909\u3048\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\n        \n        self.encoder.conv1 = nn.Conv2d(\n            in_channels,\n            64,\n            kernel_size=7,\n            stride=2,\n            padding=3,\n            bias=False\n        )\n        \n        # Modify output layer.# \u51fa\u53e3\u306e\u500b\u6570\u3082\u5408\u308f\u305b\u308b\u3002default\u306eResnet\u306e\u51fa\u53e3\u306f\u30011000\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001num_classes\u306b\u5909\u66f4\n        # \u3053\u3053\u306e\u8a18\u8ff0\u304cencoder\u3054\u3068\u306b\u4ee3\u308f\u308b\u306e\u3067\u3001efficientnet\u4f7f\u3046\u3068\u304d\u306f\u5909\u3048\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\n        \n        self.encoder.fc = nn.Linear(512 * 1, num_classes)\n\n    def forward(self, x): # \u547c\u3073\u51fa\u3055\u308c\u305f\u3068\u304d\u306b\u3001x\u306e\u5f15\u6570\u304c\u3042\u308b\u3068\u3001sigmoid\u3067\u8fd4\u3059\u3002ex) \u5f8c\u307b\u3069\u306eclassifier(sample_batched[\"landmark\"]) \u307f\u305f\u3044\u306a\u3068\u3053\u308d\u3002\n        \n        # sigmoid\u3067\u8fd4\u3059\u3068\u304d\u306f\u4ee5\u4e0b\u306e\u611f\u3058\u3000https:\/\/aidiary.hatenablog.com\/entry\/20180203\/1517629555\n        # return torch.sigmoid(self.encoder(x))\n        \n        # \u591a\u5024\u554f\u984c\u3067\u3082\u3001softmax\u306f\u3053\u3053\u3067\u306f\u4f7f\u308f\u306a\u3044\u3002nn.CrossEntropy\u306b\u65e2\u306b\u5165\u3063\u3066\u3044\u308b\u305f\u3081\n        return self.encoder(x)\n    \n    \n    \n    \n    \n    ### \u4ee5\u4e0b\u3001\u3069\u3053\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u6700\u9069\u5316\u3059\u308b\u304b\u3002\u7c21\u6613\u30c6\u30b9\u30c8\u7528\u306f\u771f\u3093\u4e2d\u3002\u30d5\u30eb\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u4e0b\u3002\u3053\u3053\u306f\u3054\u53c2\u8003\u3002###\n    \n    def freeze_all_layers(self):# \u4e2d\u9593\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc(\u91cd\u307f\u3065\u3051)\u3092\u5168\u90e8\u5909\u3048\u306a\u3044\u3002\n        for param in self.encoder.parameters():\n            param.requires_grad = False\n\n    def freeze_middle_layers(self):\n        self.freeze_all_layers()\n        \n        for param in self.encoder.conv1.parameters():# \u6700\u521d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc(\u91cd\u307f\u3065\u3051)\u3092\u5909\u3048\u308b\u3002\n            param.requires_grad = True\n            \n        for param in self.encoder.fc.parameters():# \u6700\u5f8c\u306e(\u91cd\u307f\u3065\u3051)\u3092\u5909\u3048\u308b\u3002\n            param.requires_grad = True\n\n    def unfreeze_all_layers(self):# \u4e2d\u9593\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc(\u91cd\u307f\u3065\u3051)\u3092\u5168\u90e8\u5909\u3048\u308b\u3002\n        for param in self.encoder.parameters():\n            param.requires_grad = True","a6829a09":"\nclassifier = LandmarkClassifier(encoder=encoder, in_channels=3, num_classes=10) # classifier\u306fDeepfakeClassifier\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\n\nclassifier = classifier.to(device) # \u3053\u3053\u304cKeras\u3068\u306f\u9055\u3046\u3068\u3053\u308d\u3002GPU\u306b\u9001\u308a\u307e\u3059\u3088\u30fc\u3068\u3044\u3046\u610f\u5473\u3002\u4eca\u56de\u306fcpu\u306a\u306e\u3067\u3001pass.\n\nclassifier.train() # \u3053\u3053\u304cKeras\u3068\u306f\u9055\u3046\u3068\u3053\u308d\u3002 \u8a13\u7df4\u30e2\u30fc\u30c9\u306e\u5834\u5408 classifier.train() , \u63a8\u8ad6\u306e\u5834\u5408 classifier.eval() \u3068\u66f8\u304f\u3002Normalize\u306e\u30d7\u30ed\u30bb\u30b9\u306a\u3069\u304c\u9055\u3046\u3089\u3057\u3044\u3002","bb342db2":"# \u4eca\u56de\u306f\u5168\u90e8\u6700\u9069\u5316\nclassifier.unfreeze_all_layers()","408d5184":"criterion = nn.CrossEntropyLoss()\n# \u591a\u5024\u5206\u985e\u306fcrossentropy","a3c19925":"#optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()),lr=1e-5)\noptimizer = optim.Adam(classifier.parameters(),lr=0.01)\n#optimizer = optim.SGD(classifier.parameters(),lr=1e-5)\n\n# conv\u5c64(model.features)\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u56fa\u5b9a\u3057\u3001\u5168\u7d50\u5408\u5c64(model.classifier)\u306e\u307f\u3092finetune\u3059\u308b\u8a2d\u5b9a\u3067\u3059\u3002\n# \u5168\u5c64\u306e\u3046\u3061\u3001requires_grad\u304cTrue\u306e\u5c64\u306e\u307f\u3092finetune\u3059\u308b\u3068\u3044\u3046\u610f\u5473\u3067\u3059\u3002\n# lr : \u5b66\u7fd2\u7387","4db1706d":"def trainmodel(train_dataloader):\n    classifier.train()\n    \n    for a in train_dataloader:\n        \n        input1 = a[\"landmarks\"].to(device)\n        \n        y_pred = classifier(input1) # onenote\u3067\u3044\u3046output = model(train_x)\n        label = a[\"label\"].to(device)\n\n        loss = criterion(y_pred, label)\n\n        # Zero gradients, perform a backward pass, and update the weights.\n        optimizer.zero_grad() # \u304a\u304d\u307e\u308a\u3002\u521d\u671f\u5316\u3002\n        loss.backward() # \u5f8c\u65b9\u306b\u30d0\u30c3\u30af\n        optimizer.step() # \u91cd\u307f\u3065\u3051\u306e\u6700\u9069\u5316\n        \n    return(loss.item())\n    \n    ","80e4d11f":"def valmodel(val_dataloader):\n    \n    classifier.eval()\n    \n    for a in val_dataloader:\n        \n        input1 = a[\"landmarks\"].to(device)\n\n        y_pred = classifier(input1) # onenote\u3067\u3044\u3046output = model(train_x)\n        label = a[\"label\"].to(device)\n\n        loss = criterion(y_pred, label)\n        \n    return(loss.item())\n    \n    ","ce7c2172":"epochs = 3\nsavename = \"resnet18.pth\"","efccbdd7":"def savemodel(bestloss,valloss):\n    \n    #######model\u3092save#######\n    \n    if bestloss is None:\n        bestloss = valloss[-1]\n        state = {\n                'state_dict': classifier.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                \"bestloss\":bestloss,\n            }\n\n        torch.save(state, savename)\n        \n        print(\"save the first model\")\n    \n    elif valloss[-1] < bestloss:\n        \n        bestloss = valloss[-1]\n        state = {\n                'state_dict': classifier.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                \"bestloss\":bestloss,\n            }\n\n        torch.save(state, savename)\n        \n        print(\"found a better point\")\n    \n    else:\n        pass\n    \n    return bestloss\n","aebdfcb8":"trainloss = []\nvalloss = []\n\nbestloss = None\n\nfor epoch in range(epochs):\n    \n    trainloss.append(trainmodel(train_dataloader))\n    valloss.append(valmodel(val_dataloader))\n    \n    print(str(epoch) + \"_end\")\n    \n    bestloss= savemodel(bestloss,valloss)\n    \n    print(bestloss)\n    \n    \n    ","968cf715":"x = np.arange(epochs)\nplt.scatter(x,trainloss)\nplt.scatter(x,valloss)","3c43c935":"testdf = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntestdf","05a2cff4":"class GLDataset_inf(Dataset):\n    \n    def __init__(self,df,testid,preprocess=None):\n        self.df = df\n        self.testid = testid\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        \n        # \u3053\u3053\u304b\u3089dataset\u306b\u98df\u308f\u305b\u308b\u524d\u306e\u524d\u51e6\u7406\u306e\u8a18\u8ff0\u3002\n        \n        \n        \n        testid = self.testid[idx]\n        \n        #img_pass = self.img_pass[idx]\n        \n        X = self.df.iloc[idx].values\n        X2 = X.reshape(28,28)\n        cv2.imwrite(\"tmp.bmp\",X2)\n        land = cv2.imread(\"tmp.bmp\") \n        \n        land = cv2.resize(land,(ROWS,COLS),interpolation = cv2.INTER_CUBIC)\n       \n        land = cv2.cvtColor(land,cv2.COLOR_BGR2RGB) # augment\u3092\u4f7f\u3046\u3068\u304d\u306bBGR\u304b\u3089RGB\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n        \n        if self.preprocess is not None: # \u3053\u3053\u3067\u3001\u524d\u51e6\u7406\u3092\u5165\u308c\u3066normalization\u3057\u3066\u3044\u308b\u3002\n                augmented = self.preprocess(image=land) # preprocess\u306eimage\u3092face\u3067\u8aad\u3080\n                land = augmented['image'] # https:\/\/betashort-lab.com\/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9\/albumentations%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\/\u3000\u306b\u66f8\u3044\u3066\u3042\u308b\n                \n        return {'landmarks': land.transpose(2, 0, 1), 'testid': testid}  # pytorch\u306fchannnl, x, y\u306e\u5f62\u3002\u3053\u308c\u306f\u8f9e\u66f8\u578b\u3067\u8fd4\u3057\u3066\u3044\u308b\u3002(\u6271\u3044\u3084\u3059\u3044\u3068\u3044\u3046\u3060\u3051\u304b\u3082\u3002)\n        \n        \n        \n        \n        \n        \n        \n        ","9cc1cf29":"testid2 = testdf.index.values + 1","18ca556d":"# instance\u5316\ntest_dataset = GLDataset_inf(\n    df=testdf,\n    testid=testid2,\n    preprocess=preprocess\n)\n\n## DataLoader\u306fimport torch.utils.data.Dataset\u3067import\u6e08\u307f\u306e\u3082\u306e\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False, #https:\/\/schemer1341.hatenablog.com\/entry\/2019\/01\/06\/024605 \u3092\u53c2\u8003. id\u304c\u308f\u304b\u3089\u306a\u304f\u306a\u308b\n    num_workers=NUM_WORKERS\n)\n","60a48228":"classifier.eval()\npresub = []\n\n    \nfor a in test_dataloader:\n\n    input1 = a[\"landmarks\"].to(device)\n\n    y_pred = classifier(input1) # onenote\u3067\u3044\u3046output = model(train_x)\n    \n    soft = F.softmax(y_pred).cpu().detach().numpy()\n    \n    y_pred = y_pred.cpu().detach().numpy()\n    \n    for b in range(len(y_pred)):\n        \n        predid = np.argmax(soft[b])\n        conf = np.max(soft[b])\n        \n        testid = a[\"testid\"][b]\n        \n        presub.append([testid,predid,conf])\n    \n    \n    \n\n    ","8d3f7687":"submission = pd.DataFrame(presub,columns = [\"ImageId\",\"labels\",\"conf\"])\nsubmission","3b8ebc50":"sample = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\nsample","96097649":"sample[\"Label\"]=submission[\"labels\"]\nsample","57db09d9":"sample.to_csv(\"submission.csv\",index=False)","e2022ca2":"# 1. transform\u306e\u5b9a\u7fa9","64dbbd6a":"# \u63a8\u8ad6","56d4a981":"# 1\u6b21\u5143\u30c7\u30fc\u30bf\u3067\u51e6\u7406\u3057\u3066\u3044\u304f\u306e\u304b\u3001\n# RGB3\u6b21\u5143\u30c7\u30fc\u30bf\u3067\u51e6\u7406\u3057\u3066\u3044\u304f\u306e\u304b\u3002","3dd7c4df":"# Deep learning","dccf5c16":"\u52b9\u7387\u7684\u306a\u3084\u308a\u65b9\n# Process 1 : Simple\u306b\u3057\u3066\u3067\u304d\u308b\u3068\u3053\u308d\u304b\u3089\u3084\u308b\u3002\u4f8b\u3048\u30701\u3064\u3060\u3051\u3084\u308b\n# Process 2 : \u3044\u3063\u305f\u3093\u307e\u3068\u3081\u3066\u307f\u308b\n# Process 3 : for\u6587\u306b\u3057\u3066\u56de\u3057\u3066\u307f\u308b\n# Process 4 : \u6c4e\u7528\u6027\u3092\u6301\u305f\u305b\u308b (\u6570\u5b57 \u2192 \u6587\u5b57\u5316)\n# Process 5 : \u3055\u3089\u306b\u6c4e\u7528\u6027\u3092\u6301\u305f\u305b\u308b (\u95a2\u6570\u5316)\n# Process 6 : class","2ace4319":"# 2.Dataset","cf2d3edd":"# 3.Dataloader","2e9136f4":"# Pytorch"}}