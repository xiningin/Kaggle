{"cell_type":{"1fa8fa3f":"code","ae8e606e":"code","850203fa":"code","a6550c6f":"code","c20879ed":"code","35a8805a":"code","adadc903":"code","1ec80b9f":"code","7cd0f38c":"code","8f82420e":"code","105e95ba":"code","1925435a":"code","c3c55e22":"code","2cd2f2ee":"markdown","94c62b27":"markdown","47b6472d":"markdown","a276c6e4":"markdown","99a08697":"markdown","8758925d":"markdown","b129f1b8":"markdown","83a3158e":"markdown","56c72db1":"markdown","02873159":"markdown","aac85731":"markdown","09983c74":"markdown","5614b863":"markdown","f808b724":"markdown","5fc7dd20":"markdown"},"source":{"1fa8fa3f":"import copy\nimport time\nimport gc\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom skmultilearn.model_selection import IterativeStratification\n\nfrom torch import nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\n\nfrom tqdm import tqdm\n\nfrom torchvision import models\nfrom torchvision import transforms as T\n","ae8e606e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\n\ndevice = get_default_device()\n\n\n\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n\ndef decode_target(target, text_labels=False, threshold=0.5):\n    \"\"\"Converts a probabilities vector to string of the definitive results, based on the threshold value\"\"\"\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)\n\n\n\ndef show_sample(img, target, invert=True):\n    \"\"\"Display a sample in the notebook.\n    \n    In a python IDE, you should additionally call plt.show()\"\"\"\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', decode_target(target, text_labels=True))\n\n\ndef show_batch(dl, invert=True):\n    \"\"\"Displays a batch of samples in the notebook.\n    \n    In a python IDE, you should additionally call plt.show()\"\"\"\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        data = 1 - images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break\n\n\n\ndef plot_scores(history):\n    \"\"\"Displays the evolution of the scores.\n    \n    In a python IDE, you should additionally call plt.show()\"\"\"\n    scores = [x['val_score'] for x in history]\n    plt.plot(scores, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('score')\n    plt.title('F1 score vs. No. of epochs')\n\n\ndef plot_losses(history):\n    \"\"\"Displays the evolution of the losses.\n    \n    In a python IDE, you should additionally call plt.show()\"\"\"\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n\n\ndef plot_lrs(history):\n    \"\"\"Displays the evolution of the learning rates.\n    \n    In a python IDE, you should additionally call plt.show()\"\"\"\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.')\n\n\n@torch.no_grad()\ndef predict_dl_one_hot(dl, model, threshold=0.5):\n    \"\"\"Evaluates the model on a pytorch DataLoader\"\"\"\n    torch.cuda.empty_cache()\n    batch_probs = []\n    for xb, _ in tqdm(dl):\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    return batch_probs\n        \n\ndef get_lr(optimizer):\n    \"\"\"Get the current learning rate from a pytorch optimizer\"\"\"\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n","850203fa":"# The following gave wrong means due to the substitution of channels before the dataloader\n# I do not know why the sd were also different from Roberto's, I leave it here for now.\n\n#def online_mean_and_sd(loader):\n#    \"\"\"Compute the mean and sd of a Pytorch Dataloader\n#\n#        Var[x] = E[X^2] - E^2[X]\n#\n#        Caution: slow and CPU-heavy\n#    \"\"\"\n#    cnt = 0\n#    fst_moment = torch.empty(3)\n#    snd_moment = torch.empty(3)\n#\n#    for data, _ in loader:\n#\n#        b, c, h, w = data.shape\n#        nb_pixels = b * h * w\n#        sum_ = torch.sum(data, dim=[0, 2, 3])\n#        sum_of_square = torch.sum(data**2, dim=[0, 2, 3])\n#        fst_moment = (cnt * fst_moment + sum_) \/ (cnt + nb_pixels)\n#        snd_moment = (cnt * snd_moment + sum_of_square) \/ (cnt + nb_pixels)\n#\n#        cnt += nb_pixels\n#\n#    return fst_moment, torch.sqrt(snd_moment - fst_moment**2)\n\n\ndef statistics_from_pictures(train, test):\n    \"\"\"Compute the mean and sd of the images\n\n        Var[x] = E[X^2] - E^2[X]\n\n        Caution: slow and CPU-heavy\n    \"\"\"\n    train_set = set(Path(train).iterdir())\n    #test_set = set(Path(test).iterdir())\n    whole_set = train_set #.union(test_set)\n\n    x_tot, x2_tot = [], []\n    for file in tqdm(whole_set):\n       img = cv2.imread(str(file), cv2.COLOR_RGB2BGR)\n       img = img\/255.0\n       x_tot.append(img.reshape(-1, 3).mean(0))\n       x2_tot.append((img**2).reshape(-1, 3).mean(0))\n\n    #image stats\n    img_avr =  np.array(x_tot).mean(0)\n    img_std =  np.sqrt(np.array(x2_tot).mean(0) - img_avr**2)\n    print('mean:',img_avr, ', std:', np.sqrt(img_std))\n    # mean = torch.as_tensor(x_tot)\n    # std =torch.as_tensor(x2_tot)\n\n    return img_avr, img_std\n\n\ndef F_score(output, label, threshold=0.5, beta=1):\n    \"\"\"Provides a usable score system for evaulating the models' performances\"\"\"\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","a6550c6f":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas'\nTRAIN_DIR = DATA_DIR + '\/train'\nTEST_DIR = DATA_DIR + '\/test'\nTRAIN_CSV = DATA_DIR + '\/train.csv'\nTEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv'\n\nlabels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}\n\ntrain_images = {int(x.stem): x for x in Path(TRAIN_DIR).iterdir() if x.suffix == '.png'}\ntest_images = {int(x.stem): x for x in Path(TEST_DIR).iterdir() if x.suffix == '.png'}\n\n\nsize = 512  # 512\n\nimagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nwrong_proteins_stats = ([0.0793, 0.0530, 0.0545], [0.1487, 0.1129, 0.1556])\nproteins_stats = ([0.05438065, 0.05291743, 0.07920227], [0.39414383, 0.33547948, 0.38544176])\n\ntrain_tfms = T.Compose([\n    T.Resize(size),\n    T.RandomCrop(size, padding=8, padding_mode='edge'),  # 512 if no size\n    #     T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)),\n    #     T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    T.RandomHorizontalFlip(),\n    T.RandomRotation(90),\n    T.ToTensor(),\n    T.Normalize(*proteins_stats, inplace=True),\n    T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n    T.Resize(size),\n    T.ToTensor(),\n    T.Normalize(*proteins_stats)\n])\n\n\n\nNUM_WORKERS = 4\n\nbatch_size = 80\n# resnet18: 80\n# resnet34: 50\n# resnet50: 20\n# densenet121: 30\n\nmodel_name = \"resnet18\"\nNETWORK = getattr(models, model_name)(pretrained=True)\n\nINTER_LAYER = 100","c20879ed":"class DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n\n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n\n\nclass HumanProteinDatasetOneHot(Dataset):\n    def __init__(self, df, transform=None, is_test=False):\n        self.df = df\n        self.transform = transform\n        self.files = test_images if is_test else train_images\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = int(row['Image']), row.drop('Image').values.astype(np.float32)\n        img = self.files[img_id]\n        img = Image.open(img)\n        if self.transform:\n            img = self.transform(img)\n        return img, img_label\n\n\ndef create_split_df(data_df, nfolds=5, order=2):\n    df = data_df.set_index(\"Image\").sort_index()\n    split_df = df.Label.str.split(\" \").explode()\n    split_df.value_counts()\n    dummies_df = pd.get_dummies(split_df).groupby(split_df.index).sum()\n\n    X, y = dummies_df.index.values, dummies_df.values\n    k_fold = IterativeStratification(n_splits=nfolds, order=order)\n\n    splits = list(k_fold.split(X, y))\n\n    fold_splits = np.zeros(dummies_df.shape[0]).astype(np.int)\n\n    for i in range(nfolds):\n        fold_splits[splits[i][1]] = i\n\n    dummies_df['Split'] = fold_splits\n\n    df_folds = []\n\n    for fold in range(nfolds):\n        df_fold = dummies_df.copy()\n\n        train_df = df_fold[df_fold.Split != fold].drop('Split', axis=1).reset_index()\n\n        val_df = df_fold[df_fold.Split == fold].drop('Split', axis=1).reset_index()\n\n        df_folds.append((train_df, val_df))\n\n    return df_folds\n\n\n\ndef get_split_dataloaders(split):\n    train_df, val_df = split\n\n    train_ds = HumanProteinDatasetOneHot(train_df, transform=train_tfms)\n    val_ds = HumanProteinDatasetOneHot(val_df, transform=valid_tfms)\n\n    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n    val_dl = DataLoader(val_ds, batch_size * 2, num_workers=NUM_WORKERS, pin_memory=True)\n\n    train_dl = DeviceDataLoader(train_dl, device)\n    val_dl = DeviceDataLoader(val_dl, device)\n\n    return train_dl, val_dl\n\n\ndef get_test_dl(submission):\n    test_ds = HumanProteinDatasetOneHot(submission, transform=valid_tfms, is_test=True)\n    test_dl = DataLoader(test_ds, batch_size*2, num_workers=NUM_WORKERS, pin_memory=True)\n    return DeviceDataLoader(test_dl, device)","35a8805a":"def focal_loss(out, targets, alpha=1, gamma=2, reduction='mean'):\n    bce_loss = F.binary_cross_entropy(out, targets, reduction='none')\n\n    # Prevents nans when probability 0\n    pt = torch.exp(-bce_loss)\n\n    F_loss = alpha * (1 - pt) ** gamma * bce_loss\n\n    if reduction == \"mean\":\n        return torch.mean(F_loss)\n    elif reduction == \"sum\":\n        return torch.sum(F_loss)\n    else:\n        return F_loss\n\n\ndef multi_label_loss(out, targets):\n    return F.binary_cross_entropy(out, targets)","adadc903":"class MultilabelImageClassificationBase(nn.Module):\n    def training_step(self, batch, alpha=1, gamma=2):\n        images, targets = batch\n        out = self(images)\n        loss = focal_loss(out, targets, alpha=alpha, gamma=gamma)\n        return loss\n\n    def validation_step(self, batch, threshold=0.5, alpha=1, gamma=2):\n        images, targets = batch\n        out = self(images)  # Generate predictions\n        loss = focal_loss(out, targets, alpha=alpha, gamma=gamma)  # Calculate loss\n        score = F_score(out, targets, threshold=threshold)\n        return {'val_loss': loss.detach(), 'val_score': score.detach()}\n\n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()  # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n\n    def epoch_end(self, epoch, result):\n        print(\n            \"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\"\n            .format(epoch, result['lrs'][-1], result['train_loss'],\n                    result['val_loss'], result['val_score']))\n        \n        \nclass ProteinResnet(MultilabelImageClassificationBase):\n    def __init__(self, resnet, inter_layer):\n        super().__init__()\n        # Use a pretrained model\n        self.network = resnet\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        # self.network.fc = nn.Sequential(\n        #     nn.Linear(num_ftrs, inter_layer),\n        #     nn.ReLU(inplace=True),\n        #     nn.Linear(inter_layer, 10),\n        # )\n        self.network.fc = nn.Linear(num_ftrs, 10)\n\n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n\n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n\n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True\n\n\nclass ProteinDensenet(MultilabelImageClassificationBase):\n    def __init__(self, densenet):\n        super().__init__()\n        # Use a pretrained model\n        self.network = densenet\n        # Replace last layer\n        num_ftrs = self.network.classifier.in_features\n        self.network.classifier = nn.Linear(num_ftrs, 10)\n\n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n\n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.classifier.parameters():\n            param.require_grad = True\n\n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True\n","1ec80b9f":"@torch.no_grad()\ndef evaluate(model, val_loader, threshold=0.5, alpha=1, gamma=2):\n    model.eval()\n    outputs = [model.validation_step(batch, threshold=threshold, alpha=alpha, gamma=gamma) for batch in tqdm(val_loader)]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit_one_cycle(epochs,\n                  max_lr,\n                  model,\n                  train_loader,\n                  val_loader,\n                  weight_decay=0,\n                  grad_clip=None,\n                  opt_func=torch.optim.Adam,\n                  adam_betas=(0.9, 0.999),\n                  adam_amsgrad=False,\n                  scheduler=True,\n                  threshold=0.5,\n                  alpha=1,\n                  gamma=2,\n                  save_best=\"val_loss\"):\n\n    since = time.time()\n\n    torch.cuda.empty_cache()\n    history = []\n\n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay, betas=adam_betas, amsgrad=adam_amsgrad)\n\n    if scheduler:\n        # Set up one-cycle learning rate scheduler\n        sched = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss, best_score = 1e4, 0.0\n\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch, alpha=alpha, gamma=gamma)\n            train_losses.append(loss)\n            loss.backward()\n\n            # Gradient clipping\n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n\n            if scheduler:\n                sched.step()\n\n        # Validation phase\n        result = evaluate(model, val_loader, threshold=threshold)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n\n        if result['val_loss'] < best_loss:\n            best_loss = result['val_loss']\n            if save_best == 'val_loss':\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        if result['val_score'] > best_score:\n            best_score = result['val_score']\n            if save_best == 'val_score':\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        history.append(result)\n\n    time_elapsed = time.time() - since\n\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n\n    print(f'Best val Score: {best_score:4f}')\n\n    print(f'Best val loss: {best_loss:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n\n    return model, history\n","7cd0f38c":"nfolds = 5\n\nTHRESHOLD = 0.3\nALPHA = 1\nGAMMA = 2\n\nfreeze_unfreeze = True\n\nepochs = 6\nmax_lr = 0.0005\nsched_first_pass = True\n\nsecond_epochs = 6\nsecond_lr = 0.0005\nsched_second_pass = True\n\ngrad_clip = 0.1\nweight_decay = 1e-5\nopt_func = torch.optim.AdamW\nadam_betas = (0.9, 0.999)\nadam_amsgrad = False\n\n\nsub_fname = f'submission_{model_name}_{\"sched\" if sched_first_pass else \"\"}{epochs}_lr{max_lr}_' \\\n            f'{\"sched\" if sched_second_pass else \"\"}{second_epochs}_lr{second_lr}_crossv_{nfolds}.csv'\nweights_fname = f'protein-{model_name}_{epochs}_lr{max_lr}_sched{second_epochs}_lr{second_lr}_crossv_{nfolds}.pth'\nproject_name = 'protein-advanced'\n","8f82420e":"histories = []\npredictions = []\nsince = time.time()\n\ndata_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\ntest_dl = get_test_dl(test_df)\n\nsplits = create_split_df(data_df, nfolds, order=2)\n\nfor i, split in enumerate(splits):\n    history = []\n    train_dl, val_dl = get_split_dataloaders(split)\n\n\n    # If you want to try with densenets, you should replace ProteinResnet with ProteinDensenet\n    model = to_device(ProteinResnet(NETWORK, inter_layer=INTER_LAYER), device)\n\n    if freeze_unfreeze:\n        model.freeze()\n\n    model, hist = fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n                             grad_clip=grad_clip,\n                             weight_decay=weight_decay,\n                             opt_func=opt_func,\n                             adam_betas=adam_betas,\n                             adam_amsgrad=adam_amsgrad,\n                             scheduler=sched_first_pass,\n                             threshold=THRESHOLD,\n                             alpha=ALPHA,\n                             gamma=GAMMA)\n\n    history += hist\n\n    \n    if freeze_unfreeze:\n        model.unfreeze()\n\n        \n    if second_epochs > 0:\n        model, hist = fit_one_cycle(second_epochs, second_lr, model, train_dl, val_dl,\n                                    grad_clip=grad_clip,\n                                    weight_decay=weight_decay,\n                                    opt_func=opt_func,\n                                    adam_betas=adam_betas,\n                                    adam_amsgrad=adam_amsgrad,\n                                    scheduler=sched_second_pass,\n                                    threshold=THRESHOLD)\n\n        history += hist\n\n        \n    test_preds = predict_dl_one_hot(test_dl, model, threshold=THRESHOLD)\n\n    predictions.append(test_preds)\n\n    del model\n    gc.collect()\n\nprint(f'Total Training time: {(time.time() - since)\/60:.2f} minutes')\n\nprediction_cv = torch.stack(predictions).mean(axis=0)\n\nsubmission_df = pd.read_csv(TEST_CSV)\nsubmission_df.Label = [decode_target(t.tolist()) for t in prediction_cv] # test_preds\n\n\nsubmission_df.to_csv(sub_fname, index=False)\n\n\n# This is informative and will create the prediction CSVs for all the splits\nfor index, pred in enumerate(predictions):\n    submission_df = pd.read_csv(TEST_CSV)\n    submission_df.Label = [decode_target(t.tolist()) for t in pred]  # test_preds\n\n    submission_df.to_csv(f\"part{index}_\" + sub_fname, index=False)","105e95ba":"!pip install kaggle --upgrade","1925435a":"import os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"KAGGLE_KEY\")\nsecret_value_1 = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n\nos.putenv(\"KAGGLE_KEY\", user_secrets.get_secret(\"KAGGLE_KEY\"))\nos.putenv(\"KAGGLE_USERNAME\", user_secrets.get_secret(\"KAGGLE_USERNAME\"))","c3c55e22":"!kaggle competitions submit -f .\/submission_resnet18_sched6_lr0.0005_sched6_lr0.0005_crossv_5.csv jovian-pytorch-z2g -m \"public_notebook\"","2cd2f2ee":"## Main Algorithm","94c62b27":"## Helpers","47b6472d":"## Constants","a276c6e4":"## Data Loading","99a08697":"### Acknowledgements \n\n* This notebook is forked from Aakash's [Advanced Transfer Learning Starter Notebook](https:\/\/www.kaggle.com\/aakashns\/advanced-transfer-learning-starter-notebook)\n\nPlease have a look at it for the Data exploration which I did not redo in this notebook.\n\n* The Stratified Cross Validation, Ensemble and Renormalisation come from Roberto's [Multilabel Stratification, CV and Ensemble](https:\/\/www.kaggle.com\/ronaldokun\/multilabel-stratification-cv-and-ensemble)\n\nThe notebook gives a very good sense of how the Dataset is modified and split.\n\n* The Focal Loss implementation is taken from [A Pytorch implementation of Focal Loss](https:\/\/www.kaggle.com\/c\/tgs-salt-identification-challenge\/discussion\/65938)","8758925d":"# Zero to GANs - Human Protein Classification\n\nThis notebook is a rework of the code that I used throughout the kaggle competition, shared for educational purposes.\n","b129f1b8":"## Training foundation","83a3158e":"## Models","56c72db1":"### Competition overview\n\n1) **Transfer learning**  \n\nTo win time, all along the competition I have used pretrained existing models\n\n2) **Using Resnet18**  \n\nThe initial model in the starter notebook was ResNet18.\n\nMy first attempts were to pick more complex models (ResNet34, ResNet50, DenseNet121, ...).\nThis was a loss of time since the inital hyperparameters were not optimal and the complex models took a lot of time for mediocre results.\n\nThe learning code of the starter notebook had 2 phases: one gradient descent only on the last linear layer (Frozen) and then a gradient descent on the whole weights (Unfrozen).\nBoth phases initially used learning rates scheduling and hardcoded maximum learning rates.\n\n3) **Improving hyperparameters**  \n\nHence I focused instead on ResNet18 and reduced the max learning rates and the number of epochs to increase my results.  \n\nI set both epoch numbers to 4. It was not reaching the best score but allowed me to tests a lot of combinations.\n\nI tweaked the code to be able to fine tune the presence of a scheduler and the learning rates independantly.\nMy best results were for maximum lrs of 0.0005 if both scheduling were activated and (max_lr: 0.0005, final_lr: 0.00005) if the scheduling was deactivated on the second phase.\n\nI got better results after changing the threshold to 0.3 and the weight decay to 1e-5\n\nStarting from there I could do more advanced experimentations.\n\n4) **Data augmentation**\n\nI had done my own estimation of the means and standard deviations of the Dataset values. \nI have used them for renormalisation of the data for most of the competition and it helped my scores.\nBut I got aware the numbers were actually wrong after checking the ones used in Ronaldo's notebook. I will check out later what I did wrong there.\n\n5) **Optimizer, loss function**\n\nI empirically tried several optimizers and got the best results with AdamW. I had in mind to optimize the hyperparameters (gammas and amsgrad) but did not give it a try.\nI replaced the binary cross entropy with focal loss which gives more importance to rare cases in an unbalanced dataset (The paper in the Acknowledgement is a nice read).\n\ngamma = 2 gave me the best scores.\n\n6) **Stratified Cross Validation and Ensemble**\n\nAfter reading Ronaldo's notebook (see Acknowledgements), I got aware that I was using only 80% of the dataset for training and that maybe some rare cases were only in the training set.  \nThe Stratified Cross Validation technique allows to train several times, each time with a different split of the Dataset.  \nWith nfold = 5, there will be 5 subsets, and in turn the splitting will be: 1 subset is used for validation, and the 4 others are used for training.  \nThen with nfold = 5, proportion of 80% of training data - 20% of validation data will be kept.  \nThe stratification ensures rare data is equally distributed among the subsets.  \nFinally, the ensembling takes the mean of the *nfold* trainings. \n\nIn the end all in this technique, all the data in the dataset has effectively been trained on at some point.\n\n\n7) **Resnet34**\n\nFinally, I switched again to more complex models for which I found best learning rates.\nI also increased again the epochs to get closer to the overfitting points: 6-8 epochs are the best.  \nEventually, my best submission was with Resnet34 and it allowed me to be on the first place for a few hours on the final day.\n\n","02873159":"## Stats","aac85731":"## Imports","09983c74":"## Losses","5614b863":"### What's next?\n\nI will try to include the model weights dump again in the code, so that the result can be replicated.  \nI also want to have a look at the bests notebooks shared and maybe integrate the missing bits (efficient nets, ...) in this code.  \nI will create other versions, feel free to comment.","f808b724":"### Disclaimer\n\nThis was my first Kaggle competition and first use of Pytorch.  \nI feel more comfortable with plain python scripts than notebooks and I have been mostly running them on my own PC.  \n\nSo this notebook is not exactly the code that gave me my besty performing model but a reformated copy of my code.\nAlso, I did not write the code to save my model weights initially and I did not try to seed all libraries to get reproducible results (I might write some other versions of this notebook if I get the time)","5fc7dd20":"## Hyperparameters"}}