{"cell_type":{"487dd93b":"code","d8e4aeb8":"code","5ed0499a":"code","003759a5":"code","27056173":"code","f56c3341":"code","9d06c806":"code","d2a68b96":"code","72b96e00":"code","91e17a38":"code","5b254b9b":"code","c5f951e2":"code","ab702fe4":"code","92c705d4":"code","997a812b":"code","fcf1659b":"code","124346ea":"code","6f766c29":"code","4627b39f":"code","fa919f36":"code","b6d20851":"code","f8bf5a25":"code","ab17e0f3":"code","6f0b0f68":"code","ba5e0694":"markdown","a7c079bd":"markdown","709838b8":"markdown","062a71e7":"markdown","5c633143":"markdown","2b49d64a":"markdown","f4074a67":"markdown","026120c2":"markdown","a190f9c6":"markdown","8ef40266":"markdown","e3da3b75":"markdown","46201012":"markdown","970e225b":"markdown"},"source":{"487dd93b":"#import needed libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.preprocessing\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, RidgeCV, MultiTaskLassoCV, LassoLarsCV, LogisticRegression\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, LeaveOneOut\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, mean_squared_error, r2_score, roc_auc_score, mean_absolute_error, f1_score\nfrom sklearn.feature_selection import RFE\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import OrdinalEncoder ","d8e4aeb8":"df=pd.read_csv('..\/input\/vehicle-dataset-from-cardekho\/Car details v3.csv')\ndf.head()","5ed0499a":"df.info()","003759a5":"df.describe()","27056173":"# Data Transformation \ndata=df.copy(deep=True)\ndf['mileage']= df['mileage'].str.extract(r'(\\d+.\\d+)').astype('float')\ndf['engine']=df['engine'].str.extract('(^\\d*)')\ndf['max_power']=df['max_power'].str.extract('(^\\d*)')\n#Torque Extraction\ndf['torque']= df['torque'].str.extract('(^\\d*)')\ndf['torque']= df['torque'].fillna(150)\ndf['torque']= df['torque'].astype(int)\n#if it's in kgm, change it to N.m by multiplying by g= 9.8\ndf['torque'] = df['torque'].apply(lambda x: 9.8*x if x <= 50 else x)\n### Ordinal Encoding ###\nord_enc = OrdinalEncoder()\ndf[\"fuel\"] = ord_enc.fit_transform(df[[\"fuel\"]])\ndf[\"seller_type\"] = ord_enc.fit_transform(df[[\"seller_type\"]])\ndf[\"transmission\"] = ord_enc.fit_transform(df[[\"transmission\"]])\ndf[\"owner\"] = ord_enc.fit_transform(df[[\"owner\"]])\ndf[\"name\"] = ord_enc.fit_transform(df[[\"name\"]])\n\ndf.dropna(inplace=True)\ndf['engine']=df['engine'].astype(int)\ndf['max_power']=df['max_power'].dropna()\ndf['max_power'].replace({'': 0}, inplace=True)\ndf['max_power']=df['max_power'].astype(int)","f56c3341":"cat_cols = ['fuel','seller_type','transmission','owner']\nfig = plt.figure(figsize=[15,10])\nfor i in range(len(cat_cols)):\n    plt.subplot(2,2,i+1)\n    ax= sns.countplot(x=cat_cols[i], data=data, palette= 'Set2')\n    ax.set_xticklabels(ax.get_xticklabels(),rotation = 20)","9d06c806":"plt.subplots(figsize=(12,8))\nsns.distplot(df['selling_price']);","d2a68b96":"plt.subplots(figsize=(12,8))\nplt.hist(df['km_driven'], bins= 200,edgecolor='black');\nplt.xlim([0, 300000]);\nplt.xlabel('Km driven', fontsize=13)\nplt.ylabel('Count', fontsize=13)\nplt.title('Km driven distribution', fontsize=16);","72b96e00":"df.corr().selling_price.sort_values().to_frame()","91e17a38":"plt.subplots(figsize=(16,10))\nsns.heatmap(df.corr(), annot=True, cmap=\"RdBu\")\nplt.show()","5b254b9b":"X= df.drop('selling_price', axis=1)\ny= df[['selling_price']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","c5f951e2":"lin_reg= Ridge()\nlin_reg.fit(X_train, y_train)\ny_pred= lin_reg.predict(X_test)\nprint('R2 Score for Linear Regression on test data: {}'.format( np.round(r2_score(y_test, y_pred), 3)))","ab702fe4":"plt.scatter(y_test,y_pred);","92c705d4":"n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'bootstrap': bootstrap}","997a812b":"rf = RandomForestRegressor()\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\n%time _= rf_random.fit(X_train, y_train)","fcf1659b":"rf_random.best_params_, rf_random.best_score_","124346ea":"rf= RandomForestRegressor(**rf_random.best_params_)\nrf.fit(X_train, y_train)","6f766c29":"scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')\nprint('R2 Score CV for RandomForest = {}'.format( np.round(scores.mean(),2)))","4627b39f":"y_pred= rf.predict(X_train)\nprint('RandomForestRegressor results on train data: R2 Score: {}  - MSE Score: {}'.format(r2_score(y_train, y_pred),mean_squared_error(y_train, y_pred )))","fa919f36":"y_pred= rf.predict(X_test)\nprint('RandomForestRegressor results on train data: R2 Score: {}  - MSE Score: {}'.format(r2_score(y_test, y_pred),mean_squared_error(y_test, y_pred)))\nplt.figure(figsize=(12,8))\nplt.scatter(y_test,y_pred);","b6d20851":"data={'feature_names':X_train.columns,'feature_importance':rf.feature_importances_}\nfi_df = pd.DataFrame(data)\n#Sort the DataFrame in order decreasing feature importance\nfi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\nplt.figure(figsize=(16,12))\nsns.barplot(x=fi_df['feature_importance']*100, y=fi_df['feature_names']);\nplt.title( 'Random Forest Feature Importance')\nplt.xlabel('Feature Importance')\nplt.ylabel('Feature Names');","f8bf5a25":"lgb_reg= LGBMRegressor()\nlgb_reg.fit(X_train, y_train)\ny_pred= lgb_reg.predict(X_test)\nr2_score(y_test, y_pred )","ab17e0f3":"plt.figure(figsize=(12,8))\nplt.scatter(y_test,y_pred);\nplt.title('Target and LGBM Predicted values');","6f0b0f68":"train_scores, test_scores = list(), list()\nvalues = [i for i in range(40)]\n# evaluate a decision tree for each depth\nfor i in values:\n\tmodel = DecisionTreeClassifier(max_depth=i+1)\n\tmodel.fit(X_train, y_train)\n\t# evaluate on the train dataset\n\ttrain_yhat = model.predict(X_train)\n\ttrain_acc = mean_squared_error(y_train, train_yhat)\n\ttrain_scores.append(train_acc)\n\t# evaluate on the test dataset\n\ttest_yhat = model.predict(X_test)\n\ttest_acc = mean_squared_error(y_test, test_yhat)\n\ttest_scores.append(test_acc)\nfig, ax = plt.subplots(figsize=(18,4))\nplt.plot(values, train_scores, '-o', label='Train')\nplt.plot(values, test_scores, '-s', label='Test')\nplt.xlabel('Tree Depth')\nplt.ylabel('Mean Squared Error')\nplt.title('MSE over Tree depth changes')\nplt.legend()\nplt.show()","ba5e0694":"#### Test Score","a7c079bd":"### 2) Random Forest Regressor","709838b8":"### 1) Data Transformation ","062a71e7":"### 1) Linear Regression","5c633143":"#### Train Score","2b49d64a":"## A- Exploratory Data Analysis","f4074a67":"### 3) LGBM Regressor ","026120c2":"## B- Train\/Test Models","a190f9c6":"#### Feature Importance","8ef40266":"#### CV Score","e3da3b75":"# [Vehicle Dataset - V3](https:\/\/www.kaggle.com\/nehalbirla\/vehicle-dataset-from-cardekho)","46201012":"### 4) Learning Curves","970e225b":"### 2) Univariate Analysis"}}