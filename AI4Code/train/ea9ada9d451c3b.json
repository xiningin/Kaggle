{"cell_type":{"b804ab83":"code","caa3f2d4":"code","d62348bd":"code","095745ba":"code","f7d9ef1c":"code","05f3fb31":"code","2d733b7c":"code","31548c3c":"code","c7f629d1":"code","9a603a10":"code","2139701a":"code","8fb2c039":"code","ad542bb2":"code","27b2b24b":"code","529ee3aa":"code","39c349dd":"code","2095688d":"code","1b6f42e2":"code","736f9c68":"code","cbe791f5":"code","54fefa6f":"markdown","747afb63":"markdown","cf51435c":"markdown","f8c9eb53":"markdown","48c33426":"markdown","98376565":"markdown","6a828ccc":"markdown","663e1c8f":"markdown","15435887":"markdown"},"source":{"b804ab83":"# General Library\nimport numpy as np #linear algebra\nimport pandas as pd #data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Descriptive Statistics\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import ceil \n%matplotlib inline\n\n# Preprocessing (Ordinal encoding categorical variables, splitting data)\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Training Model\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = Warning)","caa3f2d4":"# Load the data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")","d62348bd":"# Preview the data\nprint(\"Shape of Train dataset =\", train.shape)\ntrain.head()","095745ba":"print(\"Shape of Test dataset =\", test.shape)\ntest.head()","f7d9ef1c":"# Target Distribution using Histogram\nhist = np.arange(1, 12, 0.25)\nsns.displot(train.target, height = 6, aspect = 2, bins = hist);","05f3fb31":"# Target Distribution using Kernel Distribution Estimation Plot \nfig = plt.figure(figsize = (15,5))\nax0 = fig.add_subplot()\nsns.kdeplot(train.target, ax = ax0, shade = True, color = \"#9d91b3\", edgecolor = \"#27114f\",\n            alpha = 0.75, zorder = 3)\nax0.grid(which = \"major\", axis = \"x\", zorder = 0, color = \"gray\", linestyle = \":\", dashes = (1,5))\nax0.set_xlim(0, 12)\nax0.set_xlabel(\"target\")\nax0.set_ylabel(\"Count\")\n\nplt.show()","2d733b7c":"# Target Distribution using KDE & Histogram\nfig = plt.figure(figsize = (15,5))\nsns.distplot(train.target, kde_kws = {\"color\": \"#628ec4\", \"linewidth\": 3, \"alpha\": 1},\n                           hist_kws = {\"color\": \"#d6769b\", \"linewidth\": 1, \"alpha\": 0.75})\nplt.show()","31548c3c":"# Correlation of Train Dataset\nplt.figure(figsize = (20,7))\nmask = np.transpose(np.tril(np.ones(train.corr().shape))) #mask to hide upper-right part of plot as it is a duplicate\nsns.heatmap(train.corr(), vmin = -.1, vmax = 0.1, annot = True, cmap = \"YlGnBu\", mask = mask);","c7f629d1":"# Correlation of Test Dataset\nplt.figure(figsize = (20,7))\nmask = np.transpose(np.tril(np.ones(test.corr().shape))) #mask to hide upper-right part of plot as it is a duplicate\nsns.heatmap(test.corr(), vmin = -.05, vmax = 0.5, annot = True, cmap = \"RdYlBu\", mask = mask);","9a603a10":"# List of continuous columns\nnum_cols = [col for col in train.columns if 'cont' in col] \nnum_cols","2139701a":"# List of categorical columns\nobject_cols = [col for col in train.columns if 'cat' in col]\nobject_cols","8fb2c039":"# Separate Target from Features\ny = train['target']\nfeatures = train.drop(['target'], axis = 1)\n\n# Preview Features\nfeatures.head()","ad542bb2":"# Ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\n\nordinal_encoder = OrdinalEncoder()","27b2b24b":"# Ordinal-encoding for Train Dataset\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\n\n# Preview the ordinal-encoded Features from Train dataset\nX.head()","529ee3aa":"# Ordinal-encoding for Test Dataset\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded Features from Test dataset\nX_test.head()","39c349dd":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 42)","2095688d":"# Define the Model\nxgb_params = {\n    'random_state': 1,\n    'n_jobs': 4,\n    'booster': 'gbtree',\n    'n_estimators': 10000,\n    'learning_rate': 0.0362,\n    'reg_lambda': 0.000874,\n    'reg_alpha': 23.131,\n    'subsample': 0.787,\n    'colsample_bytree': 0.118,\n    'max_depth': 3}\n\n# Train the Model\nmodel = XGBRegressor(**xgb_params)\nmodel.fit(X_train, y_train) \npredictions = model.predict(X_valid)\nprint(mean_squared_error(y_valid, predictions, squared = False))","1b6f42e2":"preds_final = model.predict(X_test)","736f9c68":"# Use sample submission to generate target predictions predictions\nsubmission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")\nsubmission.target = preds_final\n\nsubmission.head()","cbe791f5":"# Save the predictions to a CSV file\nsubmission.to_csv('submission_xgb_bestparams.csv', index = False)\nprint(\"Submission file created.\")","54fefa6f":"**2. Correlation between Datasets**","747afb63":"# Submission","cf51435c":"# Load Datasets","f8c9eb53":"**1. Target Distribution on Train Dataset**","48c33426":"# Train Model","98376565":"# Prepare Data (Preprocessing)","6a828ccc":"# Libraries","663e1c8f":"# *The chosen model is Model 3 without using k-folds because it gives the best result.*","15435887":"# Descriptive Statistics"}}