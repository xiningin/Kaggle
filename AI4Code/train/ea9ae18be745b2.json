{"cell_type":{"8156701c":"code","6a934cd3":"code","3f9c2dd9":"code","2b31d40b":"code","2920d4e5":"code","29a7632c":"code","0bdd40c6":"code","b9c8da27":"code","019f0ae8":"code","d282c62e":"code","84b8f65f":"code","ecb6b8ff":"code","8bfa395c":"code","5a50ca32":"code","6120dba1":"code","9d767a18":"code","836e1ce8":"code","490c28c0":"code","32325723":"code","7642a27a":"code","8766d3fc":"code","9356008b":"code","87f08a2b":"code","793093f4":"code","8434cd08":"code","496070b6":"code","8dc22e04":"code","a2b1f3ef":"code","4b60c603":"markdown","fe45cce6":"markdown","df656754":"markdown","ddd47313":"markdown","502f09c0":"markdown","74ef998b":"markdown","1108e845":"markdown","1ec4fde8":"markdown","2f0b6ea6":"markdown","bb3bc795":"markdown","97a50f93":"markdown","8383698d":"markdown","bd136a77":"markdown","b9923916":"markdown"},"source":{"8156701c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', 120)\npd.set_option('display.width', 500)\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly\nplotly.offline.init_notebook_mode(connected = True)\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set()\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS","6a934cd3":"ITEMS_CAT_PATH = '..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv'\nITEMS_PATH = '..\/input\/competitive-data-science-predict-future-sales\/items.csv'\nSALES_TRAIN_PATH = '..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv'\nSAMPLE_SUBMISSION_PATH = '..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv'\nSHOPS_PATH = '..\/input\/competitive-data-science-predict-future-sales\/shops.csv'\nTEST_PATH = '..\/input\/competitive-data-science-predict-future-sales\/test.csv'","3f9c2dd9":"items_cats = pd.read_csv(ITEMS_CAT_PATH)\nitems = pd.read_csv(ITEMS_PATH)\nsales_train = pd.read_csv(SALES_TRAIN_PATH)\nsample_submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nshops = pd.read_csv(SHOPS_PATH)\ntest = pd.read_csv(TEST_PATH)\n","2b31d40b":"items_cats['item_category_id'] = pd.to_numeric(items_cats['item_category_id'], downcast='signed')\nitems[['item_id', 'item_category_id']] = items[['item_id', 'item_category_id']].apply(pd.to_numeric, downcast='signed')\nsales_train[['date_block_num', 'shop_id', 'item_id']] = sales_train[['date_block_num', 'shop_id', 'item_id']].apply(pd.to_numeric, downcast='signed')\nsales_train[['item_price', 'item_cnt_day']] = sales_train[['item_price', 'item_cnt_day']].apply(pd.to_numeric, downcast='float')\nsample_submission['ID'] = pd.to_numeric(sample_submission['ID'], downcast='signed')\nsample_submission['item_cnt_month'] = pd.to_numeric(sample_submission['item_cnt_month'], downcast='float')\nshops['shop_id'] = pd.to_numeric(shops['shop_id'], downcast='signed')\ntest[['ID', 'shop_id', 'item_id']] = test[['ID', 'shop_id', 'item_id']].apply(pd.to_numeric, downcast='signed')","2920d4e5":"sales_item = sales_train.merge(items, on='item_id', how='left')\nsales_item_shops = sales_item.merge(shops, on='shop_id', how='left')\ndf = sales_item_shops.merge(items_cats, on='item_category_id', how='left')\ndf.sample(10)","29a7632c":"df.info()","0bdd40c6":"columns = ['item_name', 'shop_name', 'item_category_name']\nfor column in columns: df[column] = df[column].str.lower()","b9c8da27":"print('Count rows: ', df.shape[0])\nprint('Count columns: ', df.shape[1])","019f0ae8":"df.describe().T","d282c62e":"print('Count of rows with abnormal price: {:.0f}'.format(len(df[df['item_price'] <= 0])))\nprint('Count of rows with abnormal quantity of goods sold per day: {:.0f}'.format(len(df[df['item_cnt_day'] < 0])))","84b8f65f":"df = df[~(df['item_price'] <= 0) & ~(df['item_cnt_day'] < 0)]","ecb6b8ff":"df.describe(include = ['object']).T","8bfa395c":"print(f'Count duplicates: {df.duplicated().sum()}')\ndf = df.drop_duplicates()","5a50ca32":"df.info()","6120dba1":"df['date'] = df['date'].astype('datetime64[Y]')","9d767a18":"print('Min date:', df['date'].min().date())\nprint('Max date', df['date'].max().date())","836e1ce8":"df_cnt_item = df.groupby('date_block_num').agg({'item_cnt_day':'sum'}).reset_index().rename(columns={'date_block_num':'number_of_month', 'item_cnt_day':'item_cnt'})\nfig = px.line(df_cnt_item, x=\"number_of_month\", y=\"item_cnt\")\nfig.update_layout(\n    title='The number of goods sold on a monthly basis',\n    xaxis_title='Time',\n    yaxis_title='Sales')\nfig.show()","490c28c0":"df['sum_price'] = df.item_price * df.item_cnt_day","32325723":"df_sales_sum = df.groupby('date_block_num').agg({'sum_price':'sum'}).reset_index().rename(columns={'date_block_num':'number_of_month', 'sum_price':'total_sales'})\nfig = px.line(df_sales_sum, x='number_of_month', y='total_sales')\nfig.update_layout(\n    title='Total Sales',\n    xaxis_title='Time',\n    yaxis_title='Total prise')\nfig.show()","7642a27a":"top_categories = df.groupby('item_category_id').agg({'item_id':'nunique'}).reset_index().rename(columns={'item_id':'count_items'}).sort_values(by='count_items', ascending=False).head(10)","8766d3fc":"plt.figure(figsize=(25,8))\nplt.title('Top-10 selling categories', size=20)\nax = sns.barplot(y=top_categories['count_items'], \n                 x=top_categories['item_category_id'])\nfor p in ax.patches:\n        ax.annotate (str(int(p.get_height())), (p.get_x() + p.get_width() \/ 2., p.get_height()),\n             ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')\nplt.xlabel('Category id', size=15)\nplt.ylabel('Count selling categories', size=15)\nplt.ylim(None,6000)\nplt.show()","9356008b":"distribution_categories = df[df['item_category_id'].isin(top_categories['item_category_id'])]","87f08a2b":"plt.figure(figsize=(25,8))\nplt.title('Distribution of Top-10 selling categories depending on item_id', size=20)\nax = sns.boxplot(x=\"item_category_id\", y=\"item_id\", data=distribution_categories)\nplt.xlabel('Category id', size=15)\nplt.ylabel('Count selling items', size=15)\nplt.show()","793093f4":"plt.rcParams['figure.figsize'] = (12, 8)\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'pink',\n                      max_words = 200, \n                      stopwords = stopwords,\n                     width = 1000,\n                     height = 500,\n                     random_state = 42).generate(str(items_cats['item_category_name']))\n\n\nplt.title('Wordcloud for Item Category Names', fontsize = 20)\nplt.axis('off')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.show()","8434cd08":"items_per_shop = df.groupby('shop_name').agg({'item_cnt_day':'sum'}).reset_index().rename(columns={'item_cnt_day':'total_cnt_items'}).sort_values(by='total_cnt_items', ascending=False)","496070b6":"plt.figure(figsize=(15,18), dpi=80)\nplt.title('Sales per shop', size=20)\nax = sns.barplot(x=items_per_shop['total_cnt_items'], y=items_per_shop['shop_name'])\nplt.xlabel('Count of items', size=15)\nplt.ylabel('Shop name', size=15)\nplt.show()","8dc22e04":"cnt_items_shop_monthly = df.groupby(['shop_id', 'date_block_num']).agg({'item_cnt_day':'sum'}).reset_index().sort_values(by='item_cnt_day', ascending=False)","a2b1f3ef":"plt.figure(figsize=(30,10))\nplt.title('Average number of items sold per month in each shop', size=20)\nax = sns.barplot(y=cnt_items_shop_monthly['item_cnt_day'], \n                 x=cnt_items_shop_monthly['shop_id'])\nfor p in ax.patches:\n        ax.annotate (str(int(p.get_height())), (p.get_x() + p.get_width() \/ 2., p.get_height()),\n             ha='center', va='center', rotation=0, xytext=(0, 30), textcoords='offset points')\nplt.xlabel('Shop id', size=15)\nplt.ylabel('the average number of items sold', size=15)\nplt.show()","4b60c603":"In the graph we see two sales peaks - in December 2013 (183. thousand) and December 2014 (169. thousand) . This is the time when people make the most purchases for New Year's Eve gifts.","fe45cce6":"The greatest variation in values is observed for items in categories 37, 40 and 55. However, the categories 40 and 55 have no outliers. Goods in categories 19, 23 and 72 have the most abnormal values.","df656754":"Lowercase the columns.","ddd47313":"Lower the digit capacity of data types to optimise code work.","502f09c0":"Most goods were sold from category 40 - 4964 items during the whole period of the survey. In second place is category 55 with 2327 items and in third place the category 37 with 1777 items sold.","74ef998b":"Remove all rows with anomalies.","1108e845":"Merge several tables into one for easy reference.","1ec4fde8":"Most goods were sold from the shop in \u041c\u043e\u0441\u043a\u0432\u0430 \u0422\u0426 \"\u0421\u0435\u043c\u0435\u043d\u043e\u0432\u0441\u043a\u0438\u0439\" during the entire period.","2f0b6ea6":"On average, shop 31 sold about 9,153 items monthly. Shop 25 sold 7,124 items and Shop 54 sold 6,648 items monthly. From the number of sales we can judge the size of the shop, so it is likely - they are the largest in our sample.","bb3bc795":"Here we can see anomalies in the data: a negative value for the price and quantity of goods sold per day.","97a50f93":"## Conclusions","8383698d":"* There are two sales peaks in the data - in December 2013 (183. thousand) and December 2014 (169. thousand) . This is the time when people make the most purchases for New Year's Eve gifts.\n* In December 2014, there were fewer purchases than in December 2013, but they were more expensive. There is a clear seasonality in the data.\n* Most goods were sold from category 40 - 4964 items during the whole period of the survey. In second place is category 55 with 2327 items and in third place the category 37 with 1777 items sold.\n* The greatest variation in values is observed for items in categories 37, 40 and 55. However, the categories 40 and 55 have no outliers. Goods in categories 19, 23 and 72 have the most abnormal values.\n* Most goods were sold from the shop in \u041c\u043e\u0441\u043a\u0432\u0430 \u0422\u0426 \"\u0421\u0435\u043c\u0435\u043d\u043e\u0432\u0441\u043a\u0438\u0439\" during the entire period.\n* On average, shop 31 sold about 9,153 items monthly. Shop 25 sold 7,124 items and Shop 54 sold 6,648 items monthly. From the number of sales we can judge the size of the shop, so it is likely - they are the largest in our sample.","bd136a77":"In December 2014, there were fewer purchases than in December 2013, but they were more expensive. There is a clear seasonality in the data.","b9923916":"### Predict Future Sales\n\nWe are provided with daily historical sales data. Our task is to analyse the data and highlight interesting features.\n\n**File descriptions**\n\n    sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.\n    test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.\n    sample_submission.csv - a sample submission file in the correct format.\n    items.csv - supplemental information about the items\/products.\n    item_categories.csv  - supplemental information about the items categories.\n    shops.csv- supplemental information about the shops.\n\n**Data fields**\n\n    ID - an Id that represents a (Shop, Item) tuple within the test set\n    shop_id - unique identifier of a shop\n    item_id - unique identifier of a product\n    item_category_id - unique identifier of item category\n    item_cnt_day - number of products sold. You are predicting a monthly amount of this measure\n    item_price - current price of an item\n    date - date in format dd\/mm\/yyyy\n    date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33\n    item_name - name of item\n    shop_name - name of shop\n    item_category_name - name of item category\n"}}