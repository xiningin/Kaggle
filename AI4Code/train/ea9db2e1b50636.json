{"cell_type":{"b2fad150":"code","6f5cd066":"code","cf1da296":"code","518064a2":"code","a074da3c":"code","e959f92f":"code","9063dfbd":"code","7e8958f2":"code","4dd995e0":"code","232a04fb":"code","794b1e82":"code","9d68f517":"code","272fe5d4":"code","967362c1":"code","1d6794e5":"code","f42b7c4e":"code","37bdcf2f":"code","2cc0083a":"code","fc315938":"code","58f13c22":"code","b0fa39c3":"code","6a53f912":"markdown"},"source":{"b2fad150":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f5cd066":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","cf1da296":"df.shape","518064a2":"df.info()","a074da3c":"df.isnull().sum()","e959f92f":"import matplotlib.pyplot as plt\n\ndf.hist(figsize=(15,15))\nplt.show()","9063dfbd":"labels = []\nfor i, df_visualize in enumerate(df.groupby([\"Outcome\"])):\n    labels.append(df_visualize[0])\n    plt.bar(i, df_visualize[1].count(), label=df_visualize[0])\nplt.xticks(range(len(labels)), labels)\nplt.legend()\nplt.show()","7e8958f2":"df.corr()","4dd995e0":"import seaborn as sb\n\n\nplt.figure(figsize=(12,10))\nsb.heatmap(df.corr(), annot=True)","232a04fb":"df[df.columns[1:]].corr()['Outcome'][:].sort_values(ascending=False)","794b1e82":"features = df.drop(['Outcome'], axis='columns')\nlabels = df.Outcome","9d68f517":"from sklearn.preprocessing import MinMaxScaler\n\n\nfeatures_scaler = MinMaxScaler()\nfeatures = features_scaler.fit_transform(features)","272fe5d4":"labels.value_counts()","967362c1":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(sampling_strategy='minority')\nx_sm, y_sm = smote.fit_resample(features, labels)\n\ny_sm.value_counts()","1d6794e5":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_params = {\n    'svm': {\n        'model': SVC(gamma='auto'),\n        'params' : {\n            'C': [1,10,20,30,50],\n            'kernel': ['rbf','linear','poly']\n        }  \n    },\n    'random_forest': {\n        'model': RandomForestClassifier(),\n        'params' : {\n            'n_estimators': [10,50,100]\n        }\n    },\n    'logistic_regression' : {\n        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n        'params': {\n            'C': [1,5,10]\n        }\n    },\n    'KNN' : {\n        'model': KNeighborsClassifier(),\n        'params': {\n            'n_neighbors': [3,7,11,13]\n        }\n    }\n    \n}","f42b7c4e":"from sklearn.model_selection import GridSearchCV\nscores = []\n\nfor model_name, mp in model_params.items():\n    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n    clf.fit(x_sm, y_sm)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    \ndf_score = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_score","37bdcf2f":"pd.crosstab(df_score.best_score,df_score.model).plot(kind='barh')","2cc0083a":"x_train_smote, x_test_smote, y_train_smote, y_test_smote = train_test_split(x_sm, y_sm, test_size=0.25, random_state=101, stratify=y_sm)","fc315938":"model_smote = LogisticRegression(solver='liblinear',multi_class='auto', C=5)\nmodel_smote.fit(x_train_smote,y_train_smote)\nmodel_smote.score(x_test_smote,y_test_smote)","58f13c22":"from sklearn.metrics import confusion_matrix\n\ny_predicted_smote = model_smote.predict(x_test_smote)\ncm = confusion_matrix(y_test_smote,y_predicted_smote)\nplt.figure(figsize = (10,7))\nsb.heatmap(cm, annot=True, fmt=\".1f\")\nplt.xlabel('Predicted')","b0fa39c3":"from sklearn.metrics import classification_report\nprint(classification_report(y_test_smote,y_predicted_smote))","6a53f912":"# Data Explanation\n\n* Pregnancies: Number of times pregnant\n* Glucose: Plasma glucose concentration over 2 hours in an oral glucose tolerance test\n* BloodPressure: Diastolic blood pressure (mm Hg)\n* SkinThickness: Triceps skinfold thickness (mm)\n* Insulin: 2-Hour serum insulin (mu U\/ml)\n* BMI: Body mass index (weight in kg\/(height in m)^2)\n* Pedigree: Diabetes pedigree function - A function that scores likelihood of diabetes based on family history.\n* Age: Age in years\n* Outcome: Class variable (0: the person is not diabetic or 1: the person is diabetic)"}}