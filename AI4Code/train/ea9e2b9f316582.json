{"cell_type":{"0f1a627b":"code","e950913c":"code","2ec6e117":"code","6f8263fe":"code","c7289fe8":"code","231eb899":"code","8fbf65d8":"code","ff22d6cc":"code","a4074ba1":"code","a1c77c97":"code","1353be8f":"code","376cdc51":"code","96a09e56":"code","53522eb0":"code","2eec03ce":"markdown","9954779e":"markdown"},"source":{"0f1a627b":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport nltk\nfrom nltk.stem import SnowballStemmer, WordNetLemmatizer\nfrom tqdm import tqdm\nimport re\nfrom nltk.corpus import stopwords","e950913c":"def create_folds(df, num_splits):\n    \n    skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n\n    for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.worker)):\n        df.loc[val_ , \"kfold\"] = int(fold)\n\n    df[\"kfold\"] = df[\"kfold\"].astype(int)\n    return df.drop('worker', axis=1)","2ec6e117":"df = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')","6f8263fe":"df.head(2)","c7289fe8":"def washing_machine(comments):\n    corpus=[]\n    for i in tqdm(range(len(comments))):\n        comment = re.sub('[^a-zA-Z]', ' ', comments[i])\n        comment = comment.lower()\n        comment = comment.split()\n        stemmer = SnowballStemmer('english')\n        lemmatizer = WordNetLemmatizer()\n        all_stopwords = stopwords.words('english')\n        comment = [stemmer.stem(word) for word in comment if not word in set(all_stopwords)]\n        comment = [lemmatizer.lemmatize(word) for word in comment]\n        comment = ' '.join(comment)\n        corpus.append(comment)\n\n    return corpus","231eb899":"# df['cleaned_less_toxic'] = washing_machine(df['less_toxic'].values)\n# df['cleaned_more_toxic'] = washing_machine(df['more_toxic'].values)","8fbf65d8":"df = df[['worker', 'less_toxic', 'more_toxic']]","ff22d6cc":"df.head(2)","a4074ba1":"df2 =pd.read_csv('..\/input\/data-augmentation\/augmented_text.csv')","a1c77c97":"df2['kfold'] = [-1]*len(df2)\ndf2 = df2.sample(frac=1)","1353be8f":"df_5 = create_folds(df.copy(), num_splits=5)\n","376cdc51":"df_5 = pd.concat([df_5, df2])\n","96a09e56":"df_5.tail()","53522eb0":"df_5.to_csv('5folds.csv', index=False)\n","2eec03ce":"# Cleaning the data.\n\n* Stripping off the symbols (only keeping alphabets)\n* Stemming\n* Lemmatizing\n\nTo learn more about Stemming and Lemmatizing visit : [All about Stemming and Lemmatization + Cleaning \u2b50\ufe0f](https:\/\/www.kaggle.com\/kishalmandal\/all-about-stemming-and-lemmatization-cleaning)","9954779e":"# Creating 5 folds and 10 folds"}}