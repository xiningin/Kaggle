{"cell_type":{"9eaea1d6":"code","20dea82b":"code","ddd93a0f":"code","2b64eb54":"code","44db6fad":"code","3447f302":"code","a54f0778":"code","9a793fd3":"code","de89f4b5":"code","a2ca2b0e":"code","96b1fde3":"code","1f0f477b":"code","068bee9e":"code","ac51afe2":"code","09d14878":"code","748e2a21":"code","09281b0e":"code","b9bbe3cf":"code","38ea9694":"code","16d68bf5":"code","017b8cd2":"code","5db89312":"code","1d196cb1":"markdown","07162da6":"markdown","441d292e":"markdown","4c787bfe":"markdown"},"source":{"9eaea1d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","20dea82b":"# Importing Essential Libraries\nimport os\n# import cv2\nimport time\n# import math\n# import glob\n# import random\n# import tensorflow\n# import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger","ddd93a0f":"# Required Parameters\n#dataset = \"UCF-101\/\"                                                            # Dataset Path\n#dataset2 = \"dataset\/\"                                                           # Dataset2 Path\n#train_path = \"\/kaggle\/input\/vid-classification-ucf101\/UCF\/training_set\/\"        # Training Path for Kaggle\n#test_path = \"\/kaggle\/input\/vid-classification-ucf101\/UCF\/testing_set\/\"          # Testing Path for Kaggle\nno_of_frames = 1650                                                             # Number of Frames\nch = 4                                                                          # Model Selection Choice\nepochs = 20                                                                     # Number of epochs\nbatch_size = 32                                                                 # Batch Size\nn_classes = 101                                                                 # Number of Classes\npatience = 2                                                                    # Patience for EarlyStopping\nstime = int(time.time())                                                        # Defining Starting Time\n#categories = os.listdir(dataset)                                                # Name of each Class\/Category","2b64eb54":"categories.sort()\nprint(categories)","44db6fad":"# Defining ResNet Architecture\n# resnet = tensorflow.keras.applications.resnet_v2.ResNet50V2()","3447f302":"ch = 4","a54f0778":"# Defining Base Model\nif ch == 1:\n    from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n    base_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 2:\n    from tensorflow.keras.applications.resnet import ResNet101, preprocess_input\n    base_model = ResNet101(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 3:\n    from tensorflow.keras.applications.resnet import ResNet150, preprocess_input\n    base_model = ResNet150(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 4:\n    from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n    base_model = ResNet50V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 5:\n    from tensorflow.keras.applications.resnet_v2 import ResNet101V2, preprocess_input\n    base_model = ResNet101V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 6:\n    from tensorflow.keras.applications.resnet_v2 import ResNet150V2, preprocess_input\n    base_model = ResNet150V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 7:\n    from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n    base_model = MobileNet(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 8:\n    from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n    base_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))","9a793fd3":"x = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation = 'relu')(x)\nx = Dropout(0.5)(x)\n# x = Dense(512, activation = 'relu')(x)\n# x = Dense(256, activation = 'relu')(x)\n\npreds = Dense(n_classes, activation = 'softmax')(x)","de89f4b5":"model = Model(inputs = base_model.input, outputs = preds)","a2ca2b0e":"# Printing names of each layer\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name)","96b1fde3":"# Setting each layer as trainable\nfor layer in model.layers:\n    layer.trainable = True","1f0f477b":"# # Setting 1\/3 layers as trainable\n# for layer in model.layers[:65]:\n#     layer.trainable = False\n# for layer in model.layers[65:]:\n#     layer.trainable = True","068bee9e":"# Defining Image Data Generators\ntrain_datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input,\n                                         validation_split = 0.1)\n\ntest_datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input)","ac51afe2":"train_generator = train_datagenerator.flow_from_directory(train_path,\n                                                          target_size = (224, 224),\n                                                          color_mode = 'rgb',\n                                                          batch_size = batch_size,\n                                                          class_mode = 'categorical',\n                                                          shuffle = True)\n\nvalidation_generator = train_datagenerator.flow_from_directory(train_path,\n                                                               target_size = (224, 224),\n                                                               color_mode = 'rgb',\n                                                               batch_size = batch_size,\n                                                               class_mode = 'categorical',\n                                                               subset = 'validation')\n\ntest_generator = test_datagenerator.flow_from_directory(test_path,\n                                                        target_size = (224, 224),\n                                                        color_mode = 'rgb',\n                                                        class_mode = 'categorical')","09d14878":"print(train_generator.class_indices)\nprint(validation_generator.class_indices)\nprint(test_generator.class_indices)","748e2a21":"# Compiling the Model\nmodel.compile(optimizer = \"Adam\",\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])","09281b0e":"# CSVLogger\nfilename = \"{}_{}b_{}e\\\\file.csv\".format(stime, batch_size, epochs)\ncsv_log = CSVLogger(filename)\n\n# Tensorboard\n# tensorboard = TensorBoard(log_dir = \"{}_{}b_{}e\\logs\".format(stime, batch_size, epochs))\n\n# Defining Model Checkpoint\ncheckpoint_name = \"{}_{}b_{}e\".format(stime, batch_size, epochs)\ncheckpoint_path = checkpoint_name + \"\\cp-{epoch:04d}-{accuracy:.4f}a-{loss:.4f}l-{val_accuracy:.4f}va-{val_loss:.4f}vl.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nmodelcheckpoint = ModelCheckpoint(checkpoint_path, save_best_only = True)","b9bbe3cf":"# Training the Model\nhistory = model.fit(train_generator,\n                    validation_data = validation_generator,\n                    epochs = epochs,\n                    callbacks = [modelcheckpoint, csv_log])","38ea9694":"# Plotting the Graph\nmodel_history = pd.DataFrame(history.history)\nmodel_history.plot()","16d68bf5":"# Loading Model\nfrom tensorflow.keras.models import load_model\n# model = r\"____h5_file_location.h5_Evaluating___\"","017b8cd2":"# Evaluating Model's Performance\nhistory2 = model.evaluate_generator(test_generator)\n# history2 = model.evaluate(test_generator)","5db89312":"history2","1d196cb1":"# Evaluating","07162da6":"# Training","441d292e":"Using Callbacks","4c787bfe":"# Building Model"}}