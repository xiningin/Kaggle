{"cell_type":{"bf058640":"code","4ac0e74c":"code","90ad3877":"code","3a6d8136":"code","6e109168":"code","f80f6b76":"code","81d5ef30":"code","d3b96a08":"code","9c7eaf45":"code","c3542f5d":"code","dd640998":"code","acad8492":"code","6d024743":"code","64b98ed5":"code","f1432674":"code","27b5a6f8":"code","89c67bb4":"code","b37f509f":"markdown","dbe4a46b":"markdown","5395423b":"markdown","2a0ec417":"markdown","9627606e":"markdown","7d62adf7":"markdown","f2be88e4":"markdown","45e068a4":"markdown","6018ec0c":"markdown","0323d4a6":"markdown","fc1bf4ac":"markdown","49f1fe3c":"markdown"},"source":{"bf058640":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4ac0e74c":"# Install Clustered Linear Regression (Part of KUtils Package)\n!pip install kesh-utils","90ad3877":"# Load the custom packages from kesh-utils\nfrom KUtils.eda import chartil\nfrom KUtils.eda import data_preparation as dp\nfrom KUtils.linear_regression import auto_linear_regression as autolr\nfrom KUtils.linear_regression import clustered_linear_regression as clustlr","3a6d8136":"# Some warning from pandas and Numpy need to ignore for time being (Some like conversion from int to float, cyclyic subset etc)\nimport warnings  \nwarnings.filterwarnings('ignore')","6e109168":"# Use 3 decimal places for decimal number (to avoid displaying as exponential format)\npd.options.display.float_format = '{:,.3f}'.format","f80f6b76":"# Load the dataset\ndiamond_df = pd.read_csv('..\/input\/diamonds.csv')","81d5ef30":"# Have a quick look on the top few records of the dataset \ndiamond_df.head()","d3b96a08":"diamond_df.describe()","9c7eaf45":"# Drop first column which is just a sequence\ndiamond_df = diamond_df.drop(diamond_df.columns[0], axis=1)","c3542f5d":"diamond_df['price'] = diamond_df['price'].astype(float) # One of the warning can be escaped","dd640998":"diamond_df.head()","acad8492":"# Auto Linear Regression - Single model for entire dataset\nmodel_info = autolr.fit(diamond_df, 'price', \n                     scale_numerical=True, acceptable_r2_change = 0.005,\n                     include_target_column_from_scaling=True, \n                     dummies_creation_drop_column_preference='dropMin',\n                     random_state_to_use=44, include_data_in_return=True, verbose=True)","6d024743":"# model_iteration_info\nmodel_info['model_iteration_info'].head()","64b98ed5":"group_model_info, group_model_summary = clustlr.fit(diamond_df, feature_group_list=['cut', 'color','clarity'], dependent_column='price', \n                                                    max_level = 1, min_leaf_in_filtered_dataset=500,\n                                                    verbose=True)","f1432674":"# Check the modle summary\ngroup_model_summary","27b5a6f8":"# Check subgroup level model efficieny and the dataset size used for each subset\ngroup_model_info","89c67bb4":"# Do some visualization and analysis on feature 'clarity' and see why it performs better when it is split using that feature\nchartil.plot(diamond_df, ['clarity', 'price'], chart_type='violinplot')","b37f509f":"# How \"Clustered Linear Regression\" works?\n- First it lists possible combinations\n- For each possible combinations split the data into subset\n- For each subset execute the Auto Linear Regression. Check previous [kaggle post](https:\/\/www.kaggle.com\/keshavshetty\/auto-linear-regression) on this.\n- Return summary or consolidated kpi measures at group level.","dbe4a46b":"# How to find the feature which splits the dataset into multiple sub dataset (and there after build and apply different models)\nThere is no easy solution, instead use trial and error or brute force to subset data on different feature and build multiple model.\nThis clustred or grouped Linear Regression does the same.\nYou send the entire dataset and specifiy list of columns to separate the dataset individually and return the kpi measures like rmse or r2 etc and then decide which way to go.","5395423b":"# Clustered Linear Regression\n\nFor a linear regression approach we try to fit a best model on entire dataset. \nHowever often we have seen within dataset based on a particular feature the dataset behaves totally different and single model is not the best solutions, instead have multiple model which applied on different subset or filtered data does better.\n\nThe library\/package can be found on [pypi.org here](https:\/\/pypi.org\/project\/kesh-utils\/) and source code on [github here](https:\/\/github.com\/KeshavShetty\/ds\/tree\/master\/KUtils\/linear_regression)","2a0ec417":"### We can see that splitting dataset by feature 'clarity' and applying different models will gives the best return of R2=0.943.\nOther values are \n\n- By 'cut' - RMSE=0.286 & R2=0.918\n- By 'color' - RMSE=0.314 & R2=0.897\n- By 'clarity' - RMSE=0.237 & R2=0.943","9627606e":"## Dropping feature may not always lose information. In fact splitting dataset on feature and using multiple model may have better result. This is mainly caused by differnt behaviour amoung the subset data.\n\nPlease explore further to understand how the library works and suits for your dataset.","7d62adf7":"# Perfromance of single model\nWe can clearly see the final model has RSquare=0.913 and RMSE=0.295 with 20 features","f2be88e4":"# First check the Single model on entire dataset and see the best model and its performance \nWe will use Auto Linear Regression and check the result. Refer previous [kaggle post](https:\/\/www.kaggle.com\/keshavshetty\/auto-linear-regression) on this","45e068a4":"## Conclusion: Splitting the dataset on feature'clarity' and building seperate model for each subset will give much better result than a single model.\n\nThe perfromance of single model was RSquare=0.913 and RMSE=0.295\n\nWhereas multiple model by splittin dataset on feature 'clarity' has mean performance RMSE=0.237 & R2=0.943.\n\n#### * <font color='red'>Caution: When you filter dataset the new subset will have reduced population which may not be sufficient or suitable to build the model. Use the parameter \"min_leaf_in_filtered_dataset\" control or condition the subset size.<\/font>\n","6018ec0c":"#### So it clearly shows there is wide distribution of price among different subgroup of feature clarifty.\n\nDo further analysis on the feature subset.","0323d4a6":"## The function Clustered Linear Regression fit() returns group_model_info, group_model_summary\n- group_model_info - This contains each subgroup\/subset level model built and its performance.\n- group_model_summary - This contains group level consolidated measurements.**","fc1bf4ac":"# Now Clustered Linear regression\nNow lets try clustred or grouped Linear regression. For this we need to send list of columns as dataset filtering parameter.\nIn this case we will use [ 'cut', 'color','clarity' ] which are categorical features. \n\nIn this demo it will create 3 groups 'cut', 'color','clarity'.\nWithin eachgroup data is further divided or filtered based on number of unique level or label in that respective categorcial feature.\n\n*We can use continuous variable as well which gets auto 10 bins created. For now we will use only categorical columns\n\n# The API clustlr.fit() has below parameters\n- data_df (Full dataset)\n- feature_group_list (List of column on which filter and group the data\n- dependent_column (The target column)\n- max_level = 2 (When it is 2 it uses two feature combination to filter)\n- min_leaf_in_filtered_dataset=1000 (Condition the minimum datapoints in subgroup without which autolr will not be executed)\n- no_of_bins_for_continuous_feature=10 (number of bins to be created when you use continuous varibale for grouping)\n- verbose (Use True if you want detailed debug\/log message)","49f1fe3c":"# Action time\n\nLets try this library and see how it works\n\nTo demonstrate the library I used the one of the popular dataset [UCI Diamond dataset](https:\/\/www.kaggle.com\/shivam2503\/diamonds) from Kaggle\n"}}