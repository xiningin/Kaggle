{"cell_type":{"21f1ebb7":"code","af1d8fed":"code","93e07fdc":"code","20315f23":"code","cd182695":"code","96c38916":"code","ba12ec02":"code","a0a207ff":"code","0cc15b2c":"code","eec414ce":"code","119cd3ef":"code","a272cb20":"code","8ae00f2f":"code","88ecf411":"code","3480034d":"code","80ee5723":"code","0d98a341":"code","6949fc32":"code","9c27b13f":"code","e7a4702f":"code","8c6a4502":"code","d82fdee5":"code","36b01708":"code","aabd6c96":"code","b9c977ae":"code","4cc364a4":"code","58fd33d9":"code","63e918bd":"code","ec1113d0":"code","a6624b34":"code","e0863b3c":"code","d294aaf5":"code","f2c4774e":"code","5786a26c":"code","85fe03ff":"code","65e4ab36":"code","97c53893":"code","2703d1f9":"code","921f7864":"code","fb6ee10d":"markdown","fc6413ea":"markdown","a46a8538":"markdown","ca8adfbd":"markdown","c3d8c16a":"markdown","62c9f20a":"markdown","66310154":"markdown","416242be":"markdown","f7e71c79":"markdown","4889eb7d":"markdown","e2d59f94":"markdown","666c1607":"markdown"},"source":{"21f1ebb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af1d8fed":"# Skin Cancer detection using a pre trained model VGG19.\n\n# Dataset can be downloaded from\n# https:\/\/www.kaggle.com\/fanconic\/skin-cancer-malignant-vs-benign\n\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\n#from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random \nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n","93e07fdc":"# re-size all the images to standard size 224 x 224\nIMAGE_SIZE = [224, 224]\n\n# specifying path for train and test data folders\ntrain_path = '..\/input\/skin-cancer-malignant-vs-benign\/train'\nvalid_path = '..\/input\/skin-cancer-malignant-vs-benign\/test'","20315f23":"#function to visualize image\ndef plot_image(file, directory=None, sub=False, aspect=None):\n    path = directory + file\n    \n    img = plt.imread(path)\n    \n    plt.imshow(img, aspect=aspect)\n#     plt.title(file)\n    plt.xticks([])\n    plt.yticks([])\n    \n    if sub:\n        plt.show()","cd182695":"def plot_img_dir(directory=train_path, count=5):\n    selected_files = random.sample(os.listdir(directory), count)\n    \n    ncols = 5\n    nrows = count\/\/ncols if count%ncols==0 else count\/\/ncols+1\n    \n    figsize=(20, ncols*nrows)\n\n    ticksize = 14\n    titlesize = ticksize + 8\n    labelsize = ticksize + 5\n\n\n    params = {'figure.figsize' : figsize,\n              'axes.labelsize' : labelsize,\n              'axes.titlesize' : titlesize,\n              'xtick.labelsize': ticksize,\n              'ytick.labelsize': ticksize}\n\n    plt.rcParams.update(params)\n    \n    i=0\n    \n    for file in selected_files:        \n        plt.subplot(nrows, ncols, i+1)\n        path = directory + file\n        plot_image(file, directory, aspect=None)\n\n        i=i+1\n    \n    plt.tight_layout()\n    plt.show()\n    \ndef plot_img_dir_main(directory=train_path, count=5):\n    labels = os.listdir(directory)\n    for label in labels:\n        print(label)\n        plot_img_dir(directory=directory+\"\/\"+label+\"\/\", count=count)\n        ","96c38916":"plot_img_dir_main(directory=train_path, count=5)","ba12ec02":"# added preprocessing layer to the front of VGG\nvgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n","a0a207ff":"# Freezing the existing layers \nfor layer in vgg.layers:\n  layer.trainable = False\n  ","0cc15b2c":"\n# fetching number of classes\nfolders = glob('..\/input\/skin-cancer-malignant-vs-benign\/train\/*')","eec414ce":"folders\n","119cd3ef":"len(folders)","a272cb20":"# Flatten the output layer to 1 dimension\n#x = layers.Flatten()(base_model.output)\nx = Flatten()(vgg.output)\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n\n# Add a fully connected layer with 256 hidden units and ReLU activation\nx = Dense(256, activation='relu')(x)\n\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n\n# Add a final sigmoid layer for classification\nprediction = Dense(len(folders), activation='softmax')(x)\n\n#model = tf.keras.models.Model(base_model.input, x)\n\n#model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])","8ae00f2f":"# model object creation\nmodel = Model(inputs=vgg.input, outputs=prediction)","88ecf411":"# view model structure\nmodel.summary()\n","3480034d":"# setting model cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\n","80ee5723":"# Image Data Generator to import the images from the dataset\nfrom keras.preprocessing.image import ImageDataGenerator","0d98a341":"# Addition of data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   rotation_range = 40,\n                                   horizontal_flip = True)\n ","6949fc32":"# validation data should not be augmented\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/skin-cancer-malignant-vs-benign\/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 64,\n                                                 class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory('..\/input\/skin-cancer-malignant-vs-benign\/test',\n                                            target_size = (224, 224),\n                                            batch_size = 64,\n                                            class_mode = 'categorical')","9c27b13f":"# number of  benign test data\nDIR = '..\/input\/skin-cancer-malignant-vs-benign\/test\/benign'\nbenign_test = ([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\nprint(\"number of benign test data:\" + str(len(benign_test)))","e7a4702f":"# number of malignant test data\nDIR = '..\/input\/skin-cancer-malignant-vs-benign\/test\/malignant'\nmalignant_test = ([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\nprint(\"number of malignant test data:\" + str(len(malignant_test)))","8c6a4502":"# number of malignant train data\nDIR = '..\/input\/skin-cancer-malignant-vs-benign\/train\/malignant'\nmalignant_train = ([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\nprint(\"number of malignant train data:\" + str(len(malignant_train)))","d82fdee5":"# number of malignant train data \nDIR = '..\/input\/skin-cancer-malignant-vs-benign\/train\/benign'\nbenign_train = ([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])\nprint(\"number of benign train data:\" + str(len(benign_train)))","36b01708":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)","aabd6c96":"# fit the model\nr = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=12,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set),\n  callbacks = [learning_rate_reduction]\n)","b9c977ae":"\nX_test, y_test = next(test_set)","4cc364a4":"print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")","58fd33d9":"# loss visualization\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n","63e918bd":"# accuracies visualization\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')\n\n","ec1113d0":"import tensorflow as tf\n\nfrom keras.models import load_model\n\n# save the fine tuned model\nmodel.save('model_vgg19.h5')","a6624b34":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image","e0863b3c":"# loading back the saved model\nmodel=load_model('model_vgg19.h5')","d294aaf5":"img=image.load_img('..\/input\/skin-cancer-malignant-vs-benign\/test\/benign\/1006.jpg',target_size=(224,224))\n\n","f2c4774e":"x=image.img_to_array(img)\nx","5786a26c":"x.shape","85fe03ff":"x=x\/255","65e4ab36":"x=np.expand_dims(x,axis=0)\nimg_data=preprocess_input(x)\nimg_data.shape","97c53893":"# model prediction on an image\nmodel.predict(img_data)","2703d1f9":"a=np.argmax(model.predict(img_data), axis=1)","921f7864":"if(a==1):\n    print(\"Uninfected\")\nelse:\n    print(\"Infected\")","fb6ee10d":"Image Augmentation\nSince we took up a much smaller dataset of images earlier, we can make up for it by augmenting this data and increasing our dataset size. If you are working with the original larger dataset, you can skip this step and move straight on to building the model.","fc6413ea":"## About the dataset\nThis dataset can be used to classify the type of mole into cancerous or non cancerous. It contains a balanced dataset of images of benign skin moles and malignant skin moles. The data consists of 1800 images with size 224 x 224.\n\n![Images-showing-comparison-between-benign-and-malignant-skin-lesion-using-the-ABCD-rule_Q640.jpg](attachment:5cb5e580-9560-4d1f-8f1b-f1e741467140.jpg)","a46a8538":"## Dataset image Visualization","ca8adfbd":"## Model Prediction","c3d8c16a":"We will then build the last fully-connected layer. I have just used the basic settings, but feel free to experiment with different values of dropout, and different Optimisers and activation functions.","62c9f20a":"## Saving the fine-tuned model","66310154":"## Implementing Data Augmentation","416242be":"## Model Summary","f7e71c79":"## Model Fitting\n","4889eb7d":"## Addition of fully connected layer in the last layers","e2d59f94":"## Model Implementation (VGG 19) using Transfer Learning","666c1607":"## Loss and Accuracy Visualization"}}