{"cell_type":{"a41874e9":"code","7ec31215":"code","4061eb3c":"code","978c2f5e":"code","d1b75ef4":"code","85d7b4ac":"code","482bd42f":"code","c2d08e83":"code","196b64f4":"code","b7450d07":"code","3b9891bf":"code","38aeb3b9":"code","86336096":"code","8d5286b5":"code","e6fd9350":"code","0276ee59":"code","a057146a":"code","60f76c64":"code","32e5d638":"code","e6c66b2f":"code","51c9f5bc":"code","ffcc5202":"code","9e82b6b4":"code","82cb8efc":"code","8670edcb":"code","c3003d8c":"code","c3d6813c":"code","e64fe2cb":"code","21c49b99":"code","94338127":"code","6a9cea25":"code","1d94c1ab":"code","c0c2e2f7":"code","b2d92cbe":"code","0353b341":"code","563ea6e1":"code","278ba39f":"code","e5ad7736":"code","6fdb5f57":"code","70491326":"code","0418cc26":"code","73866c8e":"code","d61bb23c":"code","73905298":"code","c3eaebfb":"code","2cc263b0":"code","4ad5f9b3":"code","117c6c8f":"code","05228687":"code","0163105d":"code","a5ddc0fd":"code","881c9246":"code","1124ca6a":"code","dbbd28e9":"markdown","ffdcb889":"markdown","50d65f48":"markdown","f81c2b0a":"markdown","6e8b9256":"markdown","3fbeb770":"markdown","d96128b6":"markdown","ea398ed5":"markdown","96a0ebda":"markdown","24811213":"markdown","829b2f0c":"markdown","1815b0ac":"markdown","b98eda78":"markdown","8c629020":"markdown","a8dab943":"markdown","157d2bf7":"markdown","ba1c9298":"markdown","20a2cce2":"markdown","d7b6b765":"markdown","0c89e1bf":"markdown","a3b394e4":"markdown","308a22cf":"markdown","3202cbac":"markdown","241088f6":"markdown","22b626aa":"markdown","d85efd58":"markdown"},"source":{"a41874e9":"import numpy as np\nimport pandas as pd\nimport os\nfrom skimage.io import imread, imsave, imshow\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport cv2\nfrom warnings import filterwarnings\n%matplotlib inline\nfilterwarnings('ignore')","7ec31215":"labels=['NORMAL','PNEUMONIA']\ndir_train= '..\/input\/chest-xray-pneumonia\/chest_xray\/train'","4061eb3c":"normal_image=[]\npneu_image=[]\nlabel_normal=[]\nlabel_pneu=[]\nfor i in labels:\n  for file in os.listdir(dir_train+'\/'+i):\n    if i=='NORMAL':\n      img=imread(dir_train+'\/'+i+'\/'+file)\n      normal_image.append(img)\n      label_normal.append(i)\n    else:\n      img=imread(dir_train+'\/'+i+'\/'+file)\n      pneu_image.append(img)\n      label_pneu.append(i)","978c2f5e":"len(normal_image)","d1b75ef4":"normal_image=np.array(normal_image)\npneu_image=np.array(pneu_image)","85d7b4ac":"small=normal_image[0]\nfor i in range(len(normal_image)):\n  if normal_image[i].size<small.size:\n    small=normal_image[i]\n    print(i,\" \",small.shape)","482bd42f":"small=pneu_image[0]\nfor i in range(len(pneu_image)):\n  if pneu_image[i].size<small.size:\n    small=pneu_image[i]\n    print(i,\" \",small.shape)","c2d08e83":"normal_image[1226].shape","196b64f4":"imshow(normal_image[1226])","b7450d07":"for i in range(len(normal_image)):\n  if len(normal_image[i].shape)>2:\n    print('Images have 3 channels')","3b9891bf":"count=0\nfor i in range(len(pneu_image)):\n  if len(pneu_image[i].shape)>2:\n    count+=1\nprint(count,\" \",len(pneu_image))","38aeb3b9":"row,col=10,10\nfig=plt.figure(figsize=(20,20))\nfor i in range(row*col):\n    fig.add_subplot(row,col,i+1)\n    plt.imshow(normal_image[i])\n    plt.axis('off')\n    plt.title(label_normal[i])","86336096":"row,col=10,10\nfig=plt.figure(figsize=(20,20))\nfor i in range(row*col):\n    fig.add_subplot(row,col,i+1)\n    plt.imshow(pneu_image[i])\n    plt.axis('off')\n    plt.title(label_pneu[i])","8d5286b5":"for i in range(len(pneu_image)):\n  if len(pneu_image[i].shape)>2:\n    pneu_image[i] = cv2.cvtColor(pneu_image[i], cv2.COLOR_BGR2GRAY)","e6fd9350":"count=0\nfor i in range(len(pneu_image)):\n  if len(pneu_image[i].shape)>2:\n    count+=1\nprint(count,\" \",len(pneu_image))","0276ee59":"small=pneu_image[0]\nfor i in range(len(pneu_image)):\n  if pneu_image[i].size < small.size:\n    small=pneu_image[i]\n    print(i,\" \",small.shape)","a057146a":"pneu_image[3536].shape","60f76c64":"# resizing all the images\nresized_ims=[]\nfor i in normal_image:\n  im= cv2.resize(i,(126,126))\n  resized_ims.append(im)","32e5d638":"for i in pneu_image:\n  im= cv2.resize(i,(126,126))\n  resized_ims.append(im)","e6c66b2f":"clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\nfor i in resized_ims:\n  i=clahe.apply(i)","51c9f5bc":"label=label_normal+label_pneu","ffcc5202":"len(label)","9e82b6b4":"all_data={label[i]:resized_ims[i] for i in range(len(label))}","82cb8efc":"all_data","8670edcb":"for i in resized_ims:\n  if i.shape!=(126,126):\n    print('Image size not valid')","c3003d8c":"x=np.array(resized_ims)\ny=label","c3d6813c":"x.shape\n","e64fe2cb":"len(y)","21c49b99":"from keras.models import *\nfrom keras.layers import *","94338127":"from keras.utils.np_utils import to_categorical","6a9cea25":"y=pd.get_dummies(y,drop_first=True)\n\ny=to_categorical(y)","1d94c1ab":"len(y)","c0c2e2f7":"y[1].shape","b2d92cbe":"y[1]","0353b341":"x.max()","563ea6e1":"x=x\/x.max()","278ba39f":"x.max()","e5ad7736":"x=x.reshape(x.shape[0],126,126,1)","6fdb5f57":"model=Sequential()\nmodel.add(InputLayer(input_shape=(126,126,1)))\nmodel.add(Conv2D(64,(5,5),activation='relu',strides=(1,1)))\nmodel.add(MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128,(3,3),activation='relu',strides=(1,1)))\nmodel.add(MaxPool2D((4,4)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256,(3,3),activation='relu',strides=(1,1)))\nmodel.add(MaxPool2D(4,4))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128,(3,3),activation='relu',strides=(1,1)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\n\nmodel.add(Dense(units=288,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units=50,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=2,activation='sigmoid'))\nmodel.summary()","70491326":"x=np.array(x)\nfrom sklearn.model_selection import train_test_split as tts\nx_train1,x_test,y_train1,y_test=tts(x,y,test_size=0.2)\nx_train,x_val,y_train,y_val=tts(x_train1,y_train1)","0418cc26":"x_train.shape","73866c8e":"imshow(x_train[2].reshape(126,126))","d61bb23c":"y_train,y_test,y_val=np.array(y_train),np.array(y_test),np.array(y_val)","73905298":"y_train[2]","c3eaebfb":"from keras.optimizers import Adam","2cc263b0":"model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=['accuracy'])\nhist=model.fit(x_train,y_train,epochs=50,batch_size=64,validation_data=(x_val,y_val))","4ad5f9b3":"model_history=hist.history","117c6c8f":"train_loss=model_history.get('loss')\nval_loss=model_history.get('val_loss')\ntrain_acc=model_history.get('accuracy')\nval_acc=model_history.get('val_accuracy')","05228687":"plt.plot(np.arange(1,51),train_loss,label='Train loss')\nplt.plot(np.arange(1,51),val_loss,label='Val loss')\nplt.title('Training_loss vs Validation_loss')\nplt.legend()\nplt.show()\n \nplt.plot(np.arange(1,51),train_acc,label='Train accuracy')\nplt.plot(np.arange(1,51),val_acc,label='Val accuracy')\nplt.title('Training_accuracy vs Validation_accuracy')\nplt.legend()\nplt.show()","0163105d":"sn.countplot(label)","a5ddc0fd":"train_count=[]\nfor i in range(len(y_train)):\n  if y_train[i][0]==1:\n    train_count.append('Normal')\n  else: train_count.append('Pneu')","881c9246":"sn.countplot(train_count)\nplt.show()","1124ca6a":"model.evaluate(x_test,y_test)","dbbd28e9":"# Plotting (train and test) (accuracies and losses) over epochs","ffdcb889":"***While preprocssing, define functions to preprocess the data instead of performing it in cells because using the latter method, I couldn't go all the way up to the preprocessing part to perform the same operations again on the actual test set in the test folder. Hence, I evaluated the model using test samples from the training set itself.***","50d65f48":"# Converting images with 3 channels to greyscale as the rest of the images have 1 channel only","f81c2b0a":"# Resizing all the images to shape (126,126)","6e8b9256":"**Converting y to output shape of the model by one hot encoding and then converting them into categorical variable:**","3fbeb770":"**Now all images have a single channel**","d96128b6":"# Looking for the smallest image whose shape will be used to resize all the other images","ea398ed5":"# Normalizing input images","96a0ebda":"# Reshaping x for model. Adding an axis for single channel","24811213":"# Evaluating the test data","829b2f0c":"# Defining directory to import data from","1815b0ac":"# Get the metrics over each epoch as a dictionary","b98eda78":"# Importing Data","8c629020":"# Defining a CNN model","a8dab943":"# Number of samples belonging to each label","157d2bf7":"# Splitting into training, validation and testing data (note that due to time constraints, I've only used the training data throughout)","ba1c9298":"# Storing the entire data in a dictionary for future use (if any)","20a2cce2":"# Processing labels","d7b6b765":"# Checking for any discrepencies in shapes of images:","0c89e1bf":"# Counting number of images with 3 channels:","a3b394e4":"# A bit of image processing using Contrast Limited Adaptive Histogram Equalization","308a22cf":"# Summary: ","3202cbac":"# Compiling the model and fitting training data:","241088f6":"**Since all images from both the classes have been merged, we do the same for labels**","22b626aa":"# Samples in each class in the training set","d85efd58":"**X and Y for training, testing and validating:**"}}