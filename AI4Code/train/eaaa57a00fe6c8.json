{"cell_type":{"c8026e63":"code","24359602":"code","0259b382":"code","585fca72":"code","30c683b0":"code","01a4847a":"code","de240c5c":"code","f637fbdb":"code","7c056c40":"code","600d36de":"code","51a275c4":"code","5d0ea514":"code","798c1c22":"code","a3b70e0d":"code","64d1dbb3":"code","7ee57ddc":"code","72cd5bfe":"code","802308b4":"code","c67f16bd":"code","d5ea9f29":"code","d96c9e3f":"code","bf0d6e6d":"code","326cb980":"code","43d44478":"code","3e8ae79c":"code","a4d26476":"code","77aa1553":"code","2ee4aec3":"code","9bbc2217":"code","c8ea8392":"code","9a6bb695":"code","b5b313c8":"code","60cb9a1b":"code","3e75d944":"code","b9f77002":"code","a9d794f1":"code","105a148e":"code","92d87f01":"code","415beb31":"code","bf6906ae":"code","1750df61":"code","e8136b04":"code","8d37a226":"code","93510fe1":"code","ecbbbc94":"code","1e6d30ef":"code","107bc0c6":"code","5cceefe0":"code","c31e75ad":"code","07592972":"code","08524110":"code","c2c4b176":"code","58f60e2a":"code","0f87e7fc":"code","fac4173b":"code","1b29b8d5":"code","8cc1685e":"code","8c777b7b":"code","4867507e":"code","4c2a21b0":"code","da3da747":"code","456e65c8":"code","bfccf42f":"code","2a1c4e96":"code","ab360565":"code","c7441950":"code","c9ea99d8":"code","626de307":"code","f9188b60":"code","bc0a069a":"code","a6d99081":"code","c43fbf0f":"code","5075242b":"code","05768bad":"code","9090be89":"code","038f0581":"code","91800fcf":"code","60377780":"code","08fe71ba":"code","cffd6f07":"code","6800e462":"code","05c125e5":"code","7720ce5e":"code","815f523b":"code","4ab55f47":"code","5503988a":"code","a4ca3186":"code","2a281dac":"code","91318de7":"code","30f7f120":"code","ec366ec5":"code","89026b95":"code","0c4948ba":"code","b5bd09d2":"code","4639d21b":"code","8bd99ca9":"code","c76906e4":"code","0a6252bf":"code","b4922a49":"markdown","5981d412":"markdown","f3135476":"markdown","b7b32b2b":"markdown","38a34030":"markdown","0df85ec6":"markdown","04fc01c3":"markdown","e13388c8":"markdown","401bd02d":"markdown","4d4cfab0":"markdown","40101f6f":"markdown","0b2ff7be":"markdown","460d4cef":"markdown","d91adcc6":"markdown","acb0220d":"markdown","e6a05b32":"markdown","1c7fffa5":"markdown","9c8fbc39":"markdown","f592a1c1":"markdown"},"source":{"c8026e63":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt \nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc","24359602":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","0259b382":"bank = pd.read_csv(\"..\/input\/bank.csv\")","585fca72":"bank.head()","30c683b0":"bank.shape","01a4847a":"bank.dtypes","de240c5c":"bank.describe(include='object')","f637fbdb":"bank.describe()","7c056c40":"bank['education'].unique()","600d36de":"bank['job'].unique()","51a275c4":"bank['marital'].unique()","5d0ea514":"bank['contact'].unique()","798c1c22":"bank['poutcome'].unique()","a3b70e0d":"bank['y'].value_counts()","64d1dbb3":"sns.countplot(x='y',data=bank,palette='hls')\nplt.show()","7ee57ddc":"sns.distplot(bank['age'])","72cd5bfe":"sns.distplot(bank['balance'])","802308b4":"sns.distplot(bank['day'])","c67f16bd":"sns.distplot(bank['duration'])","d5ea9f29":"sns.distplot(bank['campaign'])","d96c9e3f":"sns.distplot(bank['previous'])","bf0d6e6d":"bank.groupby('age').mean()","326cb980":"bank.groupby('duration').mean()","43d44478":"bank.age.hist()\nplt.title('Histogram of Age')\nplt.xlabel('Age')\nplt.ylabel('Frequency')","3e8ae79c":"fig, ax=plt.subplots(figsize=(20,20))\ncorrelation=bank.corr()\nsns.heatmap(correlation,square=True, vmin=-0.2, vmax=0.8,cmap=\"YlGnBu\",annot=True)","a4d26476":"bank= pd.get_dummies(bank, drop_first=True)\nbank.head(3)","77aa1553":"x=bank.iloc[:,0:42]\ny=bank['y_yes']\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .2, random_state=10) ","2ee4aec3":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","9bbc2217":"x_train.head()","c8ea8392":"y_train.head()","9a6bb695":"y_train.value_counts()","b5b313c8":"import statsmodels.api as sm\nlogit_model1 = sm.Logit(y, x)\nresult=logit_model1.fit()\nprint(result.summary())","60cb9a1b":"logreg1=LogisticRegression()\nlogreg1.fit(x_train,y_train)\npred1 = logreg1.predict(x_test)\nprint('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg1.score(x_test, y_test)))","3e75d944":"y_test.value_counts()","b9f77002":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test,pred1)\nprint(confusion_matrix)","a9d794f1":"plt.clf()\nplt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Wistia)\nclassNames = ['Negative','Positive']\nplt.title('Confusion Matrix - Test Data')\nplt.ylabel('True')\nplt.xlabel('Predicted')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\ns = [['TN','FP'], ['FN', 'TP']]\nfor i in range(2):\n    for j in range(2):\n        plt.text(j,i, str(s[i][j])+\" = \"+str(confusion_matrix[i][j]))\nplt.show()","105a148e":"total=sum(sum(confusion_matrix))\n\nsensitivity1 = confusion_matrix[0,0]\/(confusion_matrix[0,0]+confusion_matrix[1,0])\nprint('Sensitivity : ', sensitivity1 )\n\nspecificity1 = confusion_matrix[1,1]\/(confusion_matrix[1,1]+confusion_matrix[0,1])\nprint('Specificity : ', specificity1)","92d87f01":"fpr, tpr, thresholds = roc_curve(y_test, pred1)\na=auc(fpr,tpr)\nprint(\"Area under the curve:\",a)","415beb31":"plt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % a)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","bf6906ae":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred1))","1750df61":"cols=['balance', 'day', 'previous', 'job_entrepreneur', 'job_housemaid', \n      'job_management', 'job_self-employed','job_services','job_unknown','education_secondary',\n     'education_tertiary','default_yes','contact_telephone','month_dec','month_feb','month_jun',\n     'month_oct','poutcome_other'] \nx=bank[cols]\ny=bank['y_yes']","e8136b04":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .2, random_state=10) ","8d37a226":"print(\"x_train:\",x_train.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"x_test:\",x_test.shape)\nprint(\"y_test:\",y_test.shape)","93510fe1":"x.head()","ecbbbc94":"logit_model2=sm.Logit(y_train,x_train)\nresult=logit_model2.fit()\nprint(result.summary2())","1e6d30ef":"logreg2=LogisticRegression()\nlogreg2.fit(x_train,y_train)\npred2 = logreg2.predict(x_test)","107bc0c6":"print('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg2.score(x_test, y_test)))","5cceefe0":"y_test.value_counts()","c31e75ad":"from sklearn.metrics import confusion_matrix\nconfusion_matrix2 = confusion_matrix(y_test,pred2)\nprint(confusion_matrix2)","07592972":"plt.clf()\nplt.imshow(confusion_matrix2, interpolation='nearest', cmap=plt.cm.Wistia)\nclassNames = ['Negative','Positive']\nplt.title('Confusion Matrix - Test Data')\nplt.ylabel('True')\nplt.xlabel('Predicted')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\ns = [['TN','FP'], ['FN', 'TP']]\nfor i in range(2):\n    for j in range(2):\n        plt.text(j,i, str(s[i][j])+\" = \"+str(confusion_matrix2[i][j]))\nplt.show()","08524110":"sensitivity2 = confusion_matrix2[0,0]\/(confusion_matrix2[0,0]+confusion_matrix2[1,0])\nprint('Sensitivity : ', sensitivity2 )\n\nspecificity2 = confusion_matrix2[1,1]\/(confusion_matrix2[1,1]+confusion_matrix2[0,1])\nprint('Specificity : ', specificity2)","c2c4b176":"fpr, tpr, thresholds = roc_curve(y_test, pred2)\na=auc(fpr,tpr)\nprint(\"Area under the curve:\",a)","58f60e2a":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred2))","0f87e7fc":"cols=['balance', 'day', 'previous', 'job_entrepreneur', 'job_housemaid', \n      'job_management', 'job_self-employed','job_services','job_unknown','education_secondary',\n     'education_tertiary','default_yes','contact_telephone','month_dec','month_feb','month_jun',\n     'month_oct','poutcome_other'] \nx=bank[cols]\ny=bank['y_yes']","fac4173b":"x.head()","1b29b8d5":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx_std=scaler.fit_transform(x)","8cc1685e":"x_train, x_test, y_train, y_test = train_test_split(x_std,y,test_size = .3, random_state=99,stratify=y) ","8c777b7b":"print(\"x_train:\",x_train.shape)\nprint(\"y_train:\",y_train.shape)\nprint(\"x_test:\",x_test.shape)\nprint(\"y_test:\",y_test.shape)","4867507e":"logit_model3=sm.Logit(y_train,x_train)\nresult=logit_model3.fit()\nprint(result.summary2())","4c2a21b0":"logreg3=LogisticRegression(C=0.001)\nlogreg3.fit(x_train,y_train)\npred3 = logreg3.predict(x_test)","da3da747":"logreg3","456e65c8":"print('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg3.score(x_test, y_test)))","bfccf42f":"y_test.value_counts()","2a1c4e96":"from sklearn.metrics import confusion_matrix\nconfusion_matrix3 = confusion_matrix(y_test,pred3)\nprint(confusion_matrix3)","ab360565":"plt.clf()\nplt.imshow(confusion_matrix3, interpolation='nearest', cmap=plt.cm.Wistia)\nclassNames = ['Negative','Positive']\nplt.title('Confusion Matrix - Test Data')\nplt.ylabel('True')\nplt.xlabel('Predicted')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\ns = [['TN','FP'], ['FN', 'TP']]\nfor i in range(2):\n    for j in range(2):\n        plt.text(j,i, str(s[i][j])+\" = \"+str(confusion_matrix3[i][j]))\nplt.show()","c7441950":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred3))","c9ea99d8":"x=bank.iloc[:,0:42]\ny=bank['y_yes']","626de307":"from imblearn.over_sampling import SMOTE\ny.value_counts()","f9188b60":"smt = SMOTE()\nx_smote, y_smote = smt.fit_sample(x, y)","bc0a069a":"x_train, x_test, y_train, y_test = train_test_split(x_smote,y_smote,test_size = .2, random_state=10) ","a6d99081":"np.bincount(y_train)","c43fbf0f":"logit_model4=sm.Logit(y_train,x_train)\nresult=logit_model4.fit()\nprint(result.summary2())","5075242b":"logreg4=LogisticRegression()\nlogreg4.fit(x_train,y_train)\npred4 = logreg4.predict(x_test)","05768bad":"print('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logreg4.score(x_test, y_test)))","9090be89":"np.unique(y_test,return_counts=True)","038f0581":"from sklearn.metrics import confusion_matrix\nconfusion_matrix4 = confusion_matrix(y_test,pred4)\nprint(confusion_matrix4)","91800fcf":"plt.clf()\nplt.imshow(confusion_matrix3, interpolation='nearest', cmap=plt.cm.Wistia)\nclassNames = ['Negative','Positive']\nplt.title('Confusion Matrix - Test Data')\nplt.ylabel('True')\nplt.xlabel('Predicted')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=45)\nplt.yticks(tick_marks, classNames)\ns = [['TN','FP'], ['FN', 'TP']]\nfor i in range(2):\n    for j in range(2):\n        plt.text(j,i, str(s[i][j])+\" = \"+str(confusion_matrix4[i][j]))\nplt.show()","60377780":"sensitivity4 = confusion_matrix4[0,0]\/(confusion_matrix4[0,0]+confusion_matrix4[1,0])\nprint('Sensitivity : ', sensitivity4 )\n\nspecificity4 = confusion_matrix4[1,1]\/(confusion_matrix4[1,1]+confusion_matrix4[0,1])\nprint('Specificity : ', specificity4)","08fe71ba":"fpr, tpr, thresholds = roc_curve(y_test, pred4)\na=auc(fpr,tpr)\nprint(\"Area under the curve:\",a)","cffd6f07":"plt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % a)\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","6800e462":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred4))","05c125e5":"x=bank.iloc[:,0:42]\ny=bank['y_yes']","7720ce5e":"y.value_counts()","815f523b":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .3, random_state=99,stratify=y) ","4ab55f47":"print(\"x_train:\",x_train.shape)\nprint(\"y_train:\",y_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_test\",y_test.shape)","5503988a":"from sklearn import linear_model\nclf = linear_model.Lasso(alpha=0.1)\nclf.fit(x_train,y_train) \nprint(\"Coefficients:\",clf.coef_)\nprint(\"Intercept:\",clf.intercept_)","a4ca3186":"x=bank.iloc[:,0:42]\ny=bank['y_yes']","2a281dac":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .3, random_state=99,stratify=y)","91318de7":"print(\"x_train:\",x_train.shape)\nprint(\"y_train:\",y_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_test\",y_test.shape)","30f7f120":"from sklearn.linear_model import Ridge\nclf = Ridge(alpha=1.0)\nclf.fit(x_train, y_train) ","ec366ec5":"clf.predict(x_test)","89026b95":"from sklearn.model_selection import GridSearchCV\nridge=Ridge()\nparameters={'alpha': [3.175, 3.77, 4.823]}\nridge_regressor=GridSearchCV(ridge, parameters,cv=5)\nridge_regressor.fit(x_train,y_train)","0c4948ba":"print(\"Best parameter:\", ridge_regressor.best_params_)\nprint(\"Best score:\",ridge_regressor.best_score_)","b5bd09d2":"x=bank.iloc[:,0:42]\ny=bank['y_yes']","4639d21b":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = .2, random_state=10) ","8bd99ca9":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\ngrid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\nlogreg5=LogisticRegression()\nlogreg_cv=GridSearchCV(logreg5,grid,cv=10)\nlogreg_cv.fit(x_train,y_train)\n\nprint(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\nprint(\"accuracy :\",logreg_cv.best_score_)","c76906e4":"logreg5","0a6252bf":"logreg6=LogisticRegression(C=1,penalty=\"l1\")\nlogreg6.fit(x_train,y_train)\nprint(\"Score:\",logreg6.score(x_test,y_test))","b4922a49":"### Rebuilding the model after standardization","5981d412":"**age:** numeric\n<br>**job:** type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n<br>**marital:** marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n<br>**education:** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n<br>**default:** has credit in default? (categorical: 'no','yes','unknown')\n<br>**housing:** has housing loan? (categorical: 'no','yes','unknown')\n<br>**loan:** has personal loan? (categorical: 'no','yes','unknown')\n<br>**contact:** contact communication type (categorical: 'cellular','telephone') \n<br>**month:** last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n<br>**day_of_week:** last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n<br>**duration:** last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n<br>**campaign:** number of contacts performed during this campaign and for this client (numeric, includes last contact)\n<br>**pdays:** number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n<br>**previous:** number of contacts performed before this campaign and for this client (numeric)\n<br>**poutcome:** outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n<br>**emp.var.rate:** employment variation rate - quarterly indicator (numeric)\n<br>**cons.price.idx:** consumer price index - monthly indicator (numeric) \n<br>**cons.conf.idx:** consumer confidence index - monthly indicator (numeric) \n<br>**euribor3m:** euribor 3 month rate - daily indicator (numeric)\n<br>**nr.employed:** number of employees - quarterly indicator (numeric)","f3135476":"## Ridge Regression","b7b32b2b":"## Correlation Matrix","38a34030":"# Building models in Logistic","0df85ec6":"## Using SMOTE ","04fc01c3":"**Precision:** is the ratio TP \/ (TP + FP) where TP is number of true positives and FP number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n\n<br>**Recall:** is the ratio TP \/ (TP + FN) where TP is the number of true positives and FN number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n\n<br>**F-score:** can be interpreted as a weighted harmonic mean of the precision and recall, where an F score reaches its best value at 1 and worst score at 0. The F score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall.\n\n<br>**Support:** is the number of occurrences of each class in y_test.","e13388c8":"### Confusion Matrix","401bd02d":"Splitting the data into train and test data set","4d4cfab0":"We can see from the output above that the coefficients of certain variables have been reduced to zero.","40101f6f":"## Grid Search ","0b2ff7be":"## Lasso Regression","460d4cef":"### Rebuilding the model with only significant variables","d91adcc6":"As we can see the area under the curve is 65% which is very less.","acb0220d":"## Data Description-","e6a05b32":"It is a parameter tuning approach that will build model for each combination of algorithm parameters in a grid. And then returns that model which has the highest accuracy.","1c7fffa5":"## Building the Logistic Model","9c8fbc39":"Lasso Regression performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.\n<br>It imposes a constraint on the model parameters that causes regression coefficients for some variables to shrink towards zero.","f592a1c1":"## Creating Dummy Variables"}}