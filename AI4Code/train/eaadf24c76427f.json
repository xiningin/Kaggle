{"cell_type":{"2e5d47be":"code","0c58904c":"code","fd83e890":"code","4acbee07":"code","0efb244b":"code","0a25adda":"code","b3cd648e":"code","5ab630bf":"code","a5b88548":"code","0576a4d2":"code","4541d5f9":"code","4957b715":"code","a9b76c36":"code","599a716d":"code","0cda44dc":"code","1d5d7293":"code","88913259":"code","483e3e30":"code","25de99ec":"code","6e3e8be4":"code","e699e146":"code","986228cc":"code","4f3b0e7c":"code","5fafe9f9":"code","645bcf5b":"code","3816189d":"code","f9a8e690":"code","0795c45d":"code","74db9024":"code","de5939c2":"code","2688b05e":"code","81e750f5":"code","04bbe9d8":"code","d9af427d":"code","acee8f47":"code","e4eafd3c":"code","82fd25f7":"code","8b702a45":"code","5b8114c6":"code","02590a54":"code","68154a54":"code","342a9e09":"code","4a02de9e":"code","4adc2f21":"code","b998c9ce":"code","a0037570":"code","37649aee":"code","f2ba0f4d":"code","db94ed9c":"code","e9a03b81":"code","3e8401d5":"code","93c6a283":"code","b3e15113":"code","374d2a53":"code","5ef16ff0":"code","c2f2d2ab":"code","8d3454f7":"code","765e97a3":"markdown","db159333":"markdown","973a8f85":"markdown","429fe2dd":"markdown","ded8f302":"markdown","fcc485ff":"markdown","9fad7237":"markdown","1d66f45a":"markdown","b5463232":"markdown","89dd6652":"markdown","5cff2b75":"markdown","53083835":"markdown","f5e6522e":"markdown","c12ba1b2":"markdown","1e9bdf46":"markdown","b2081dc1":"markdown","26a66e9c":"markdown","c8abd434":"markdown","7127d5ff":"markdown","6092388f":"markdown","c94b8de0":"markdown","b20212a2":"markdown","1c90693d":"markdown","ee7fca48":"markdown","b6f66259":"markdown","3bb0d639":"markdown","65fc5ddc":"markdown","e8e9df3b":"markdown","925aa265":"markdown","38c6e0fa":"markdown","306b6514":"markdown","de8e95e5":"markdown","5bcee52c":"markdown","dd8a3e4e":"markdown"},"source":{"2e5d47be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0c58904c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","fd83e890":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","4acbee07":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","0efb244b":"train_data.describe()","0a25adda":"train_data.info()","b3cd648e":"pd.isnull(train_data).sum()","5ab630bf":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nwomen_survival = sum(women)\/len(women)\n\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nmen_survival = sum(men)\/len(men)\n\nprint(\"Percentage of women who survived: \" +str(women_survival))\nprint(\"Percentage of men who survived: \" +str(men_survival))","a5b88548":"plt.figure(figsize=(4,4))\nsns.barplot(x = train_data['Sex'], y = train_data['Survived'])","0576a4d2":"g = sns.catplot(x = \"Sex\", col = \"Survived\", kind='count', data = train_data, height=4)","4541d5f9":"class1 = train_data.loc[train_data['Pclass'] == 1]['Survived']\nclass1_survival = sum(class1)\/len(class1)\n\nclass2 = train_data.loc[train_data['Pclass'] == 2]['Survived']\nclass2_survival = sum(class2)\/len(class2)\n\nclass3 = train_data.loc[train_data['Pclass'] == 3]['Survived']\nclass3_survival = sum(class3)\/len(class3)\n\nprint(\"Percentage of 1st Class passengers who survived: \" +str(class1_survival))\nprint(\"Percentage of 2nd Class passengers who survived: \" +str(class2_survival))\nprint(\"Percentage of 3rd Class passengers who survived: \" +str(class3_survival))","4957b715":"sns.barplot(x = 'Pclass', y = 'Survived', data =train_data)","a9b76c36":"p = sns.FacetGrid(train_data, col='Survived')\np.map(plt.hist, 'Age', bins=20)","599a716d":"From the above: It seems that infants have a higher survival rate. ","0cda44dc":"sns.barplot(x='SibSp', y='Survived', data=train_data)","1d5d7293":"sns.barplot(x = 'Parch', y = 'Survived', data = train_data)","88913259":"sns.barplot(x = 'Embarked', y='Survived', data=train_data)","483e3e30":"sns.catplot(x = 'Survived', col = 'Embarked', kind = 'count', data = train_data, height=4)","25de99ec":"sns.catplot(x = 'Embarked', hue='Pclass', kind='count' ,data = train_data)","6e3e8be4":"sns.catplot(x = 'Pclass', y = 'Survived', hue = 'Sex', data = train_data, kind = 'bar',height=4)","e699e146":"pd.crosstab([train_data.Survived], [train_data.Sex, train_data.Pclass, train_data.Embarked], margins=True)","986228cc":"pd.isnull(train_data).sum()","4f3b0e7c":"train_data = train_data.drop(columns=['Cabin'], axis=1)\ntest_data = test_data.drop(columns=['Cabin'], axis=1)","5fafe9f9":"train_data.Embarked.value_counts()","645bcf5b":"train_data = train_data.fillna({\"Embarked\": \"S\"})","3816189d":"train_data.head(1)","f9a8e690":"#train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\n#train_data['Age'] = train_data['Age'].apply(lambda x: int(x))\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')\nimputer.fit(train_data.iloc[:, 5:6])\ntrain_data.iloc[:, 5:6] = imputer.transform(train_data.iloc[:, 5:6])","0795c45d":"train_data.head()","74db9024":"test_data.head()","de5939c2":"test_data.iloc[:, 4:5] = imputer.transform(test_data.iloc[:, 4:5])","2688b05e":"train_data.isnull().sum()","81e750f5":"test_data.isnull().sum()","04bbe9d8":"train_data = train_data.drop(['Ticket','Name'], axis=1)\ntest_data = test_data.drop(['Ticket','Name'], axis=1)","d9af427d":"sex_mapping = {\"male\": 0, \"female\": 1}\n\ntrain_data['Sex'] = train_data['Sex'].map(sex_mapping)\ntest_data['Sex'] = test_data['Sex'].map(sex_mapping)","acee8f47":"train_data.head()","e4eafd3c":"embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain_data['Embarked'] = train_data['Embarked'].map(embarked_mapping)\ntest_data['Embarked'] = test_data['Embarked'].map(embarked_mapping)","82fd25f7":"train_data.head()","8b702a45":"test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].dropna().median())","5b8114c6":"test_data.head()","02590a54":"from sklearn.model_selection import train_test_split\n\nX = train_data.drop(['Survived', 'PassengerId'], axis=1)\ny = train_data[\"Survived\"]\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.20, random_state = 0)","68154a54":"from sklearn.tree import DecisionTreeClassifier\n\nclassifier = DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)","342a9e09":"y_preds = classifier.predict(X_val)","4a02de9e":"print(\"Confusion Matrix of Decision Tree Classifier: \")\nprint(confusion_matrix(y_preds, y_val))","4adc2f21":"from sklearn.metrics import accuracy_score, confusion_matrix\n\nprint(\"Accuracy of Decision Tree Classifier: \" +str(accuracy_score(y_preds,y_val)*100))","b998c9ce":"from sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression(max_iter=200)\nclassifier.fit(X_train, y_train)","a0037570":"y_preds = classifier.predict(X_val)","37649aee":"print(\"Accuracy of Logistic Regression Classifier: \" +str(accuracy_score(y_preds,y_val)*100))","f2ba0f4d":"from sklearn.svm import SVC\n\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)","db94ed9c":"y_preds = classifier.predict(X_val)","e9a03b81":"print(\"Accuracy of SVM Classifier: \" +str(accuracy_score(y_preds,y_val)*100))","3e8401d5":"from sklearn.neighbors import KNeighborsClassifier\n\nclassifier = KNeighborsClassifier()\nclassifier.fit(X_train, y_train)","93c6a283":"y_preds = classifier.predict(X_val)","b3e15113":"print(\"Accuracy of KNN Classifier: \" +str(accuracy_score(y_preds,y_val)*100))","374d2a53":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(random_state=0)\nclassifier.fit(X_train, y_train)","5ef16ff0":"y_preds = classifier.predict(X_val)","c2f2d2ab":"print(\"Accuracy of Random Forest Classifier: \" +str(accuracy_score(y_preds,y_val)*100))","8d3454f7":"passengerIds = test_data['PassengerId']\ntest_data = test_data.drop(['PassengerId'], axis=1)\ntest_preds = classifier.predict(test_data)\n\n\noutput = pd.DataFrame({ 'PassengerId' : passengerIds, 'Survived': test_preds })\noutput.to_csv('submission.csv', index=False)\n","765e97a3":"From the above: The survival rate is higher for the passengers who had a few siblings. The survival rate reduces as the number of sibling increases. \n\nPassengers with > 4 siblings seem to have no survivors.\n\nIt also seems that passengers with no siblings have a lower survival rate than those with 1 or 2 siblings.","db159333":"### 4.5 Random Forest Classifier","973a8f85":"### 3.1 Missing Values","429fe2dd":"### 4.4 KNN Classifier","ded8f302":"From the above: 62% of the Upper class passengers survived, 47% of the Middle class and 24% of the Lower class.\nThis is probably because life boats were handed to the Upper class passengers first. \n\nHence, higher the socio-economic status, more the chances of survival.","fcc485ff":"* Categorical Cols = Pclass, Name, Sex, Cabin\tEmbarked\n* Numeric Cols = Age, SibSp, Parch, TicketFare of which Continuous: Age, Fare and Discrete: Parch and SibSp","9fad7237":"* There are 891 passengers.\n* Age, Cabin and Embarked missing values.\n* Age - Probably missed recording age of some passengers.\n* Cabin - More than 80% missing, it will be hard to impute. Probably better to drop.\n* EMbarked - Possibly missed recording a few. ","1d66f45a":"From the above: The passengers who embarked from Cherbourg had a higher chance of survival and those from Southampton had the least.\n\nThis follows from the previous inference that the 1st class had a higher rate of survival. Percentage of 1st class passengers who boarded at Cherbourg is higher and hence, the higher survival rate follows.","b5463232":"From the above: Passengers with a parent or two or with less than 4 children have a higher survival rate. This is probably because families were loaded on to life boats.\n\nPassengers with more than 3 parents\/children have a lower chance of survival.\n\nIt also seems that passengers travelling solo had a lower survival rate than those with small(1-3) families.","89dd6652":"### 2.1 Sex and Survival","5cff2b75":"### 2.6 Embarked and Survived","53083835":"### 3.2 Categorical Features","f5e6522e":"**3.2.3 Replace the missing Fare in test data**","c12ba1b2":"### 2.2 Class and Survival","1e9bdf46":"### 4.2 Logistic Regression","b2081dc1":"From the above: It is clear that the women of higher socio-economic class had a better chance of surivival than those of a lower class.\n\nIt is also clear that the lowest chance of survival in this group was that of the men in Lower class.","26a66e9c":"From the above: 74% of the women survived and only 18% of the men did. This follows from the fact that women were loaded onto life boats first.\n\nHence, we can predict that women have a higher chance of survival.","c8abd434":"## 4.3 SVM","7127d5ff":"### 2.5 Parch and Survival","6092388f":"**3.2.2 Mapping Embarked**","c94b8de0":"### 4.1 Decision Tree Classifier","b20212a2":"**3.1.2 Imputing values for Embarked**","1c90693d":"**3.1.3 Imputing values for Age**","ee7fca48":"# 2. Data Visualization","b6f66259":"# 4. Modelling","3bb0d639":"**3.1.4 Dropping the ticket and name columns**","65fc5ddc":"### 2.4 SibSp and Survival ","e8e9df3b":"# 5. Prediction","925aa265":"Sources:\n[Titanic Survival](https:\/\/www.kaggle.com\/nadintamer\/titanic-survival-predictions-beginner)\n","38c6e0fa":"### 2.7 Class, Sex and Survival","306b6514":"# 3. Data Cleaning ","de8e95e5":"**3.1.1 Dropping the Cabin column as it has too many missing values and does not contribute much.**","5bcee52c":"**3.1.1 Mapping Sex**","dd8a3e4e":"### 2.3 Age and Survival"}}