{"cell_type":{"c587a16e":"code","bcb6e716":"code","8fc806c8":"code","48d38280":"code","1c82acc0":"code","93738219":"code","1bbe2658":"code","4175d157":"code","f564952d":"code","b69231b7":"code","7a84cee2":"code","f4a63397":"code","3f3fc7f8":"code","17d838e0":"code","ff04653f":"code","4ca2f41e":"code","2d245fc0":"code","3efdcc0e":"code","a69fb010":"code","03876c06":"code","dc6b2803":"code","f5cd77ff":"code","89aa8ae0":"code","ce9f53e6":"markdown","4add0025":"markdown","e8d4b17f":"markdown","da298715":"markdown","91b3b684":"markdown","55f92be1":"markdown","d7caef3e":"markdown","8aa209e8":"markdown"},"source":{"c587a16e":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport seaborn as sns\nimport pickle\nimport random","bcb6e716":"# load data from the pickle files\n\nwith open('..\/input\/traffic-sign-classification\/train.p', mode = 'rb') as training_data:\n    train = pickle.load(training_data)\nwith open('..\/input\/traffic-sign-classification\/test.p', mode = 'rb') as testing_data:\n    test = pickle.load(testing_data)\nwith open('..\/input\/traffic-sign-classification\/valid.p', mode = 'rb') as validation_data:\n    valid = pickle.load(validation_data)","8fc806c8":"X_train, y_train = train['features'], train['labels'] \nX_valid, y_valid = valid['features'], valid['labels'] \nX_test, y_test = test['features'], test['labels']\n\nprint('Shape of train data:\\t\\t X =', X_train.shape,'\\t y =', y_train.shape)\nprint('Shape of validation data:\\t X =', X_valid.shape,'\\t\\t y =', y_valid.shape)\nprint('Shape of test data:\\t\\t X =', X_test.shape,'\\t y =', y_test.shape)","48d38280":"# check the class distribution\n# the dataset has 43 different classes of traffic signs\nuniqueValues, occurCount = np.unique(y_train, return_counts=True)\nclass_dist = dict(zip(uniqueValues, occurCount))\nplt.figure(figsize=(15,5))\nplt.bar(list(class_dist.keys()), class_dist.values(), 0.8)\nplt.xticks(range(43), fontsize = 12)\nplt.yticks(fontsize = 12)\nplt.title('Class Distribution', fontsize = 20)\nplt.xlabel('Class', fontsize = 15)\nplt.ylabel('Frequency', fontsize = 15)\nplt.show()","1c82acc0":"# visualize any one image from train data\ni = np.random.randint(1,len(X_train))\nplt.imshow(X_train[i])\ny_train[i]","93738219":"# let's visualize some more images in a grid format\n# define the dimensions of the plot grid\nW_grid = 5\nL_grid = 5\n\n# subplot returns figure object and axes object\n# axes object can be used to plot specific figures at various locations\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (12,12))\n\naxes = axes.ravel() # flatten the 5x5 matrix into 25 array\n\nfor i in np.arange(0, L_grid * W_grid):\n    \n    # select a random number\n    index = np.random.randint(0,  len(X_train))\n    \n    #read and display an image with the selected index\n    axes[i].imshow(X_train[index])\n    axes[i].set_title(y_train[index], fontsize = 15, color = 'red')\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace = 0.8)","1bbe2658":"from sklearn.utils import shuffle\n# shuffle train data to ensure a random order input\nX_train, y_train = shuffle(X_train, y_train)","4175d157":"# convert to grayscale\nX_train_gray = np.sum(X_train\/3, axis = 3, keepdims = True)\nX_valid_gray = np.sum(X_valid\/3, axis = 3, keepdims = True)\nX_test_gray = np.sum(X_test\/3, axis = 3, keepdims = True)\n\nprint('Shape of grayscale train data:\\t\\t X =', X_train_gray.shape,'\\t y =', y_train.shape)\nprint('Shape of grayscale validation data:\\t X =', X_valid_gray.shape,'\\t\\t y =', y_valid.shape)\nprint('Shape of grayscale test data:\\t\\t X =', X_test_gray.shape,'\\t y =', y_test.shape)","f564952d":"# normalize the data\nX_train_gray_norm = (X_train_gray - 128)\/128\nX_valid_gray_norm = (X_valid_gray - 128)\/128\nX_test_gray_norm = (X_test_gray - 128)\/128","b69231b7":"# compare the original image with the grayscale and grayscale-normalized images\ni = np.random.randint(0, len(X_train))\nplt.imshow(X_train[i])\nplt.title('Original Coloured Image', fontsize = 15)\nplt.figure()\nplt.imshow(X_train_gray[i].squeeze(), cmap = 'gray')\nplt.title('Grayscale Image', fontsize = 15)\nplt.figure()\nplt.imshow(X_train_gray_norm[i].squeeze(), cmap = 'gray')\nplt.title('Grayscale normalized Image', fontsize = 15)\nplt.figure()","7a84cee2":"from tensorflow.keras import datasets, layers, models\n\nCNN_model = models.Sequential()\n\nCNN_model.add(layers.Conv2D(32, (7,7), activation = 'relu', padding = 'valid', input_shape = (32,32,1)))\nCNN_model.add(layers.BatchNormalization())\nCNN_model.add(layers.Dropout(0.15))\n\nCNN_model.add(layers.Conv2D(64, (3,3), padding = 'valid', activation = 'relu'))\nCNN_model.add(layers.MaxPooling2D())\nCNN_model.add(layers.BatchNormalization())\nCNN_model.add(layers.Dropout(0.25))\n\nCNN_model.add(layers.Conv2D(64, (3,3), padding = 'valid', activation = 'relu'))\nCNN_model.add(layers.MaxPooling2D())\nCNN_model.add(layers.BatchNormalization())\nCNN_model.add(layers.Dropout(0.35))\n\nCNN_model.add(layers.Flatten())\n\nCNN_model.add(layers.Dense(240, activation = 'relu'))\nCNN_model.add(layers.BatchNormalization())\nCNN_model.add(layers.Dropout(0.5))\nCNN_model.add(layers.Dense(43, activation = 'softmax'))\nCNN_model.summary()","f4a63397":"CNN_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","3f3fc7f8":"# defining the class weights for the loss function\nvalues, counts = np.unique(y_train, return_counts = True)\nweights = sum(counts)\/counts\nclass_weights = dict(zip(values,weights))","17d838e0":"#save the weights\/parameters which give the best validation accuracy\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_accuracy', verbose=1,\n                             save_best_only=True, mode='auto', period=1)\ncallbacks_list = [checkpoint]","ff04653f":"CNN_fit = CNN_model.fit(X_train_gray_norm,\n             y_train,\n             batch_size = 16,\n             epochs = 50,\n             verbose = 2,\n             validation_data = (X_valid_gray_norm, y_valid),\n             class_weight = class_weights,\n             callbacks = callbacks_list\n            )","4ca2f41e":"score = CNN_model.evaluate(X_test_gray_norm, y_test)\nprint('Test Accuracy: {}'.format(100*score[1]))","2d245fc0":"CNN_model.load_weights(\"best_model.hdf5\")\nCNN_model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\nscore = CNN_model.evaluate(X_test_gray_norm, y_test)\nprint('Test Accuracy using the saved parameters: {}'.format(100*score[1]))","3efdcc0e":"CNN_fit.history.keys()","a69fb010":"# get the loss and accuracy for each epoch\ntrain_loss = CNN_fit.history['loss']\ntrain_acc = CNN_fit.history['accuracy']\nval_loss = CNN_fit.history['val_loss']\nval_acc = CNN_fit.history['val_accuracy']","03876c06":"# plot the training and validation loss\nepochs = range(len(train_acc))\nplt.plot(epochs, train_loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.legend()\nplt.title('Training and Validation Loss', size = 15)","dc6b2803":"# plot the training and validation accuracy\nepochs = range(len(train_acc))\nplt.plot(epochs, train_acc, 'r', label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy', size = 15)","f5cd77ff":"# plot the confusion matrix\npredicted_classes = CNN_model.predict_classes(X_test_gray_norm)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, predicted_classes)\nplt.figure(figsize = (35,35))\nsns.heatmap(cm, annot = True, cmap=\"Blues\")","89aa8ae0":"# check actual class label vs predicted class label\n# define dimensions of the plot grid\nL = 5\nW = 5\n\n# subplot returns figure object and axes object\n# axes object can be used to plot specific figures at various locations\nfig, axes = plt.subplots(L, W, figsize = (12,12))\naxes = axes.ravel() # flatten the 5x5 matrix into 25 array\n\nfor i in np.arange(0, L*W):\n    axes[i].imshow(X_test[i])\n    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], y_test[i]))\n    axes[i].axis('off')\n    \nplt.subplots_adjust(hspace = 1)","ce9f53e6":"### **Convert Images to Grayscale and Normalize**","4add0025":"### **Load the Dataset**","e8d4b17f":"### **Perform Image Visualization**","da298715":"### **Asses the Performance of Trained Model on Test Data**","91b3b684":"### **Import Libraries**","55f92be1":"### **Use the Saved Weights\/Parameters for Evaluation**","d7caef3e":"### **Build Deep Convolutional Neural Network Model**","8aa209e8":"### **Compile and Train Deep CNN Model**"}}