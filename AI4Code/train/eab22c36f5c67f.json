{"cell_type":{"676a26d4":"code","ec4c504e":"code","df47daeb":"code","c1724caa":"code","c9b9f3db":"code","59784aab":"code","92fff093":"code","2c9be624":"code","27032712":"code","c0dcef12":"code","ce2042a1":"code","3355122d":"code","ae99afaf":"code","4b31c197":"code","93948372":"code","7f371d79":"code","a220ce82":"code","d5d4af8d":"code","ca6a56f4":"code","15cfe255":"code","3de278fc":"code","7eec77d9":"code","3d0ec286":"code","5b15f82e":"code","679f7ce0":"code","71e8f65f":"code","a30e6860":"code","44beda2c":"code","97c82e11":"code","3931da58":"code","b5999d01":"markdown","38bab093":"markdown","ca5c6d75":"markdown","a976de7d":"markdown","c67811d5":"markdown","34719f52":"markdown","8d455e90":"markdown","6cd39e21":"markdown","3dff821a":"markdown","a36d4b25":"markdown","0fc82aac":"markdown","c527d4e1":"markdown","3dc53304":"markdown","f6b9a1d1":"markdown","9f15cfbd":"markdown","39b09dd4":"markdown","66f95d76":"markdown","197f8d72":"markdown","e666885f":"markdown","16d787e6":"markdown","a99be356":"markdown","5c96bc7a":"markdown","96135d52":"markdown","58a44e62":"markdown","b8742820":"markdown","ec76e0fb":"markdown","2d9d18a9":"markdown","a7376356":"markdown","6329a950":"markdown","877d31dc":"markdown","4e88fc11":"markdown","fec589c8":"markdown","7f814fab":"markdown","3f8332b3":"markdown","8fbdf0cb":"markdown"},"source":{"676a26d4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples,silhouette_score\nfrom sklearn.cluster import AgglomerativeClustering\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.cluster import DBSCAN\nfrom collections import Counter\nfrom sklearn.decomposition import PCA","ec4c504e":"df = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","df47daeb":"df.head()","c1724caa":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_mix = [\"#17869E\", '#264D58', '#179E66', '#D35151', '#E9DAB4', '#E9B4B4', '#D3B651', '#6351D3']\n\nsns.palplot(colors_dark)\nsns.palplot(colors_mix)","c9b9f3db":"d= pd.DataFrame(df['Gender'].value_counts())\nfig = px.pie(d,values='Gender',names=['Male','Female'],hole=0.4,opacity=0.7,\n            color_discrete_sequence=[colors_mix[7],colors_mix[2]])\n\nfig.add_annotation(text='Gender',\n                   x=0.5,y=0.5,showarrow=False,font_size=18,opacity=0.7,font_family='monospace')\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Gender Ratio',x=0.5,y=0.98,\n               font=dict(color=colors_dark[2],size=20)),\n    legend=dict(x=0.37,y=-0.05,orientation='h',traceorder='reversed'),\n    hoverlabel=dict(bgcolor='white'))\n\nfig.update_traces(textposition='outside', textinfo='percent+label')\n\nfig.show()","59784aab":"fig = px.histogram(df,x='Age',template='plotly_white',opacity=0.7,nbins=25,\n                   color_discrete_sequence=[colors_mix[7]])\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Distribution Of Age',x=0.5,y=0.95,\n               font=dict(color=colors_dark[2],size=20)),\n    xaxis_title_text='Age',\n    yaxis_title_text='Count',\n    legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n    bargap=0.3,\n)\nfig.show()","92fff093":"fig = px.histogram(df,x='Annual Income (k$)',template='plotly_white',opacity=0.7,nbins=20,\n                   color_discrete_sequence=[colors_mix[7]])\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Distribution Of Annual Income',x=0.5,y=0.95,\n               font=dict(color=colors_dark[2],size=20)),\n    xaxis_title_text='Annual Income (k$)',\n    yaxis_title_text='Count',\n    legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n    bargap=0.3,\n)\nfig.show()","2c9be624":"fig = px.histogram(df,x='Spending Score (1-100)',template='plotly_white',opacity=0.7,nbins=20,\n                   color_discrete_sequence=[colors_mix[7]])\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Distribution Of Spending Score',x=0.5,y=0.95,\n               font=dict(color=colors_dark[2],size=20)),\n    xaxis_title_text='Spending Score',\n    yaxis_title_text='Count',\n    legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n    bargap=0.3,\n)\nfig.show()","27032712":"df.drop('CustomerID',axis=1,inplace=True)","c0dcef12":"df.columns","ce2042a1":"df['Gender'] = df['Gender'].apply(lambda x: 0 if x=='Male' else 1)","3355122d":"df['Gender']","ae99afaf":"scaler = StandardScaler()\nscaler.fit(df)\nX = scaler.transform(df)","4b31c197":"wcss= []    # within cluster sum of squares\nss = []     # silouette score\nfor i in range(2,11):\n    model = KMeans(n_clusters=i)\n    model.fit_transform(X)\n    wcss.append(model.inertia_)\n    ss.append(silhouette_score(X,labels=model.predict(df)))","93948372":"fig,ax1 = plt.subplots(figsize=(14,8))\n\nax1.plot(range(2, 11), wcss , '--', color=colors_mix[2], linewidth=2)\nax1.legend(['Inertia'],bbox_to_anchor=(0.9365,1),frameon=False)\nax1.plot(range(2, 11), wcss , 'o', color=colors_mix[7],alpha=0.7)\nax1.set_ylabel('Inertia')\n\nax2 = ax1.twinx()\nax2.plot(range(2, 11), ss, '-', color=colors_mix[7], linewidth=2)\nax2.legend(['Silhouette Score'],bbox_to_anchor=(1,0.95),frameon=False)\nax2.plot(range(2, 11), ss, 'o', color=colors_mix[2], alpha=0.7)\nax2.set_ylabel('Silhouette Score')\n\nplt.xlabel('Number of clusters')\nplt.show()","7f371d79":"range_n_clusters =[2,4,6,8,10]\n\nfor n_clusters in range_n_clusters:\n    # Create a subplot with 1 row and 2 columns\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_size_inches(18, 7)\n\n    # The 1st subplot is the silhouette plot\n    # The silhouette coefficient can range from -1, 1 but in this example all\n    # lie within [-0.1, 1]\n    ax1.set_xlim([-0.1, 1])\n    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n    # plots of individual clusters, to demarcate them clearly.\n    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n\n    # Initialize the clusterer with n_clusters value and a random generator\n    # seed of 10 for reproducibility.\n    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n    cluster_labels = clusterer.fit_predict(X)\n\n    # The silhouette_score gives the average value for all the samples.\n    # This gives a perspective into the density and separation of the formed\n    # clusters\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    print(\"For n_clusters =\", n_clusters,\n          \"The average silhouette_score is :\", silhouette_avg)\n\n    # Compute the silhouette scores for each sample\n    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n\n    y_lower = 10\n    for i in range(n_clusters):\n        # Aggregate the silhouette scores for samples belonging to\n        # cluster i, and sort them\n        ith_cluster_silhouette_values = \\\n            sample_silhouette_values[cluster_labels == i]\n\n        ith_cluster_silhouette_values.sort()\n\n        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n        y_upper = y_lower + size_cluster_i\n\n        color = cm.nipy_spectral(float(i) \/ n_clusters)\n        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                          0, ith_cluster_silhouette_values,\n                          facecolor=color, edgecolor=color, alpha=0.7)\n\n        # Label the silhouette plots with their cluster numbers at the middle\n        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n\n        # Compute the new y_lower for next plot\n        y_lower = y_upper + 10  # 10 for the 0 samples\n\n    ax1.set_title(\"The silhouette plot for the various clusters.\")\n    ax1.set_xlabel(\"The silhouette coefficient values\")\n    ax1.set_ylabel(\"Cluster label\")\n\n    # The vertical line for average silhouette score of all the values\n    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n\n    ax1.set_yticks([])  # Clear the yaxis labels \/ ticks\n    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n\n    # 2nd Plot showing the actual clusters formed\n    colors = cm.nipy_spectral(cluster_labels.astype(float) \/ n_clusters)\n    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n                c=colors, edgecolor='k')\n\n    # Labeling the clusters\n    centers = clusterer.cluster_centers_\n    # Draw white circles at cluster centers\n    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n                c=\"white\", alpha=1, s=200, edgecolor='k')\n\n    for i, c in enumerate(centers):\n        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n                    s=50, edgecolor='k')\n\n    ax2.set_title(\"The visualization of the clustered data.\")\n    ax2.set_xlabel(\"Feature space for the 1st feature\")\n    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n\n    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n                  \"with n_clusters = %d\" % n_clusters),\n                 fontsize=14, fontweight='bold')\n\nplt.show()","a220ce82":"model = KMeans(n_clusters=2)\npredictions = model.fit_predict(X)","d5d4af8d":"new_df = pd.merge(df,pd.Series(predictions,name='Cluster'),on=df.index)\nnew_df.drop('key_0',axis=1,inplace=True)\nnew_df.head()","ca6a56f4":"fig = px.histogram(new_df,x='Age',color='Cluster',template='plotly_white',\n                  marginal='box',opacity=0.7,nbins=50,color_discrete_sequence=[colors_mix[2],colors_mix[7]],\n                  barmode='group',histfunc='count')\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Distribution Of Age After Clustering',x=0.5,y=0.95,\n               font=dict(color=colors_dark[2],size=20)),\n    xaxis_title_text='Age',\n    yaxis_title_text='Count',\n    legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n    bargap=0.3,\n)\nfig.show()","15cfe255":"fig = px.histogram(new_df,x='Annual Income (k$)',color='Cluster',template='plotly_white',\n                  marginal='box',opacity=0.7,nbins=50,color_discrete_sequence=[colors_mix[2],colors_mix[7]],\n                  barmode='group',histfunc='count')\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Distribution Of Annual Income After Clustering',x=0.5,y=0.95,\n               font=dict(color=colors_dark[2],size=20)),\n    xaxis_title_text='Annual Income (k$)',\n    yaxis_title_text='Count',\n    legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n    bargap=0.3,\n)\nfig.show()","3de278fc":"fig = px.histogram(new_df,x='Spending Score (1-100)',color='Cluster',template='plotly_white',\n                  marginal='box',opacity=0.7,nbins=25,color_discrete_sequence=[colors_mix[2],colors_mix[7]],\n                  barmode='group',histfunc='count')\n\nfig.update_layout(\n    font_family='monospace',\n    title=dict(text='Distribution Of Spending Score After Clustering',x=0.5,y=0.95,\n               font=dict(color=colors_dark[2],size=20)),\n    xaxis_title_text='Spending Score (1-100)',\n    yaxis_title_text='Count',\n    legend=dict(x=1,y=0.96,bordercolor=colors_dark[4],borderwidth=0,tracegroupgap=5),\n    bargap=0.3,\n)\nfig.show()","7eec77d9":"pca = PCA(2)\npca.fit(X)\nX_PCA = pca.transform(X)\nplt.figure(figsize=(15,8))\nsns.scatterplot(x=X_PCA[:, 0], y=X_PCA[:, 1], \n                hue=predictions, palette=[colors_mix[7],colors_mix[2]], s=50)\nplt.title('Cluster of Customers in 2D', size=15, pad=10)\nsns.despine()\nplt.legend(loc=0, bbox_to_anchor=[1,1])\nplt.show()","3d0ec286":"pca = PCA(3)\npca.fit(X)\nX_PCA = pca.transform(X)\n\n\nfig = px.scatter_3d(x=X_PCA[:,0], y=X_PCA[:,1], z=X_PCA[:,2],\n                    color=predictions,opacity=0.8,color_continuous_scale=[colors_mix[2],colors_mix[7]],\n                   width=800,height=800)\n\nfig.update_layout(font_family='monospace',\n    title=dict(text='Customer Clusters in 3D',x=0.5,y=0.95,\n    font=dict(color=colors_dark[2],size=20)),\n    coloraxis_showscale=False)\nfig.show()","5b15f82e":"model = AgglomerativeClustering(distance_threshold=0,n_clusters=None)\nmodel.fit(X)","679f7ce0":"def plot_dendrogram(model, **kwargs):\n    # Create linkage matrix and then plot the dendrogram\n\n    # create the counts of samples under each node\n    counts = np.zeros(model.children_.shape[0])\n    n_samples = len(model.labels_)\n    for i, merge in enumerate(model.children_):\n        current_count = 0\n        for child_idx in merge:\n            if child_idx < n_samples:\n                current_count += 1  # leaf node\n            else:\n                current_count += counts[child_idx - n_samples]\n        counts[i] = current_count\n\n    linkage_matrix = np.column_stack([model.children_, model.distances_,\n                                      counts]).astype(float)\n\n    # Plot the corresponding dendrogram\n    dendrogram(linkage_matrix, **kwargs)","71e8f65f":"plt.figure(figsize=(14,8))\nplot_dendrogram(model,truncate_mode = 'level',p=3)\nplt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\nplt.show()","a30e6860":"model = DBSCAN(eps=1,min_samples=5)\ncluster_labels = model.fit_predict(X)","44beda2c":"silhouette_score(X,cluster_labels)","97c82e11":"pca = PCA(2)\npca.fit(X)\nX_PCA = pca.transform(X)\nplt.figure(figsize=(15,8))\nsns.scatterplot(x=X_PCA[:, 0], y=X_PCA[:, 1], \n                hue=cluster_labels, palette=[colors_mix[3],colors_mix[2],colors_mix[7]], s=50)\nplt.title('Cluster of Customers in 2D', size=15, pad=10)\nsns.despine()\nplt.legend(loc=0, bbox_to_anchor=[1,1])\nplt.show()","3931da58":"pca = PCA(3)\npca.fit(X)\nX_PCA = pca.transform(X)\n\n\nfig = px.scatter_3d(x=X_PCA[:,0], y=X_PCA[:,1], z=X_PCA[:,2],\n                    color=cluster_labels,opacity=0.8,\n                    color_continuous_scale=[colors_mix[3],colors_mix[7],colors_mix[2]],\n                    width=800,height=800)\n\nfig.update_layout(font_family='monospace',\n    title=dict(text='Customer Clusters in 3D',x=0.5,y=0.95,\n    font=dict(color=colors_dark[2],size=20)),\n    coloraxis_showscale=False)\nfig.show()","b5999d01":"Agglomerative Clustering is a technique which forms groups or clusters based on the similarity between points. This is a pairwise process as each unit of the data is compared with another one to find how similar they are and group them into a small cluster. It has a bottom-up appraoch as it starts with the smallest units to make small clusters and then at the end of the computation makes one huge cluster with all the sub-clusters and units in them.","38bab093":"<div class=\"alert alert-block alert-success\">\n<b>Result: <\/b>After looking at the Silhouette Analysis graphs, I've chosen n_clusters = 2 for my KMeans model.\n<\/div>","ca5c6d75":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Data Preprocessing<\/center><\/h1>\n<\/div>","a976de7d":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Loading the Dataset<\/center><\/h1>\n<\/div>","c67811d5":"We know that CustomerID is unnessary for our model so we'll drop that column","34719f52":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Introduction<\/center><\/h1>\n<\/div>","8d455e90":"1. We used the **Silhouette Analysis** to find the correct value of n_clusters.\n2. With K-Means, 2 clusters divided the Customers based on **Age** and **Spending Score** quite distinctly.\n3. With Heirarchal Clustering, 2 clusters were formed and were visualized using **dendograms**.\n4. With DBSCAN, the clusters formed were different than that made by K-Means and we also found out the points which were not counted in any cluster and were termed as **outliers**.","6cd39e21":"With the help of **PCA**, we can observe the clusters which the models formed.","3dff821a":"<div class=\"alert alert-block alert-info\">\n<b>3 things to keep in mind when we look at the graph below are:<\/b><br>\n <ol>\n  <li>The difference between the widths of the clusters should not be large.<\/li>\n  <li>Part of clusters with < 0 silhouette score means that some points have been assigned to a wrong cluster, so we need to minimize that.<\/li>\n  <li>We also need to look at the overall Silhouette score of a model for a particular cluster.<\/li>\n<\/ol> \n<\/div>","a36d4b25":"<div class=\"alert alert-block alert-danger\">\nAs we can see that the inertia curve is smooth and there is no abrupt decrease, we cannot find the value of n_clusters and be sure about it with this method.\n<\/div>","0fc82aac":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Colors<\/center><\/h1>\n<\/div>","c527d4e1":"The distinction between clusters doesn't seem too clear with the 2D representation, so let's make a 3D representation of it to understand how these clusters are distinct from one another.","3dc53304":"<div class=\"alert alert-block alert-info\">\n<b>Note: <\/b>\n-1 is assigned to the points which are termed as <b>outliers<\/b> as these points aren't part of a cluster\n<\/div>","f6b9a1d1":"We'll look at a few models with which we can use make clusters and segment our customers.","9f15cfbd":"Now, we'll encode the labels from the **Gender** feature into numerical values.","39b09dd4":"When you perform customer segmentation, you find similar characteristics in each customer\u2019s behaviour and needs. Then, those are generalized into groups to satisfy demands with various strategies. Moreover, those strategies can be an input of the:\n\n1. Targeted marketing activities to specific groups\n2. Launch of features aligning with the customer demand\n3. Development of the product roadmap\n\nIn this notebook, I'll be performing Unsupervised Machine Learning with Python to give everyone a basic understanding of how we can segment data into particular groups and find valuable insights from it.\n\nI'll be using 3 algorithms to understand how each algorithm segments the data using different techniques.\n\nThe 3 algorithms will be:\n\n1. K-Means Clustering\n2. Heirarchal (Agglomerative) Clustering\n3. DBSCAN (Density Based Spatial Clustering of Applications with Noise)","66f95d76":"We can also use PCA to visualize the clusters in 3D","197f8d72":"### 2. Hierarchal Clustering","e666885f":"With the help of dendograms, we can see 2 distinct clusters being made from this model.","16d787e6":"### 1. K-Means Clustering","a99be356":"DBSCAN uses 2 major parameters to make clusters:\n\n1. **eps** - Radius of each core.\n2. **min_samples** -  Minimum number of points that should be inside the radius of a point to consider it as a core point","5c96bc7a":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Importing Libraries<\/center><\/h1>\n<\/div>","96135d52":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Modelling<\/center><\/h1>\n<\/div>","58a44e62":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Visualizations<\/center><\/h1>\n<\/div>","b8742820":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Conclusion<\/center><\/h1>\n<\/div>","ec76e0fb":"Now we can clearly see how these clusters are formed and how these are distinct from one another.","2d9d18a9":"Code to plot Dendograms:","a7376356":"We can use **PCA** to visualize the clusters and observe how our model performed.","6329a950":"We'll scale the data as algorithms like K-Means Clustering uses Euclidean Distance and other such distance metrics for computation of distances between data points, therefore making it sensitive to outliers.","877d31dc":"<div style=\"background-color:#bf80ff; color:#636363;\">\n    <h1><center>Thank You!<\/center><\/h1>\n<\/div>","4e88fc11":"<div style=\"background-color:#B4DBE9;\">\n    <center><img src=\"https:\/\/raw.githubusercontent.com\/jaykumar1607\/Customer-Segmentation\/main\/source.gif\">\n<\/div>","fec589c8":"We'll first start off by trying the elbow method to find out the best value for the **n_clusters** parameter.","7f814fab":"<div class=\"alert alert-block alert-info\">\n<h4>If you like this notebook, feel free to upvote it! Comment down your suggestions\/opinions, I get to learn alot from them and it's very valuable to me! Thanks you! :D<\/h3>\n<\/div>","3f8332b3":"To validate the number of clusters we're going to make from the model, we'll use the **Silhouette analysis.**","8fbdf0cb":"### 3. DBSCAN"}}