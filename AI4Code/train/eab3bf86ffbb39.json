{"cell_type":{"c9f3a88b":"code","0bc9308b":"code","7ad169ce":"code","8214d263":"code","600aa8f3":"code","35c2e179":"code","0d95d8c6":"code","88c8a745":"code","68972ac0":"code","c373375e":"code","082a08c4":"code","b4859688":"code","c5a33632":"code","b90e17c6":"code","fa7d2c3a":"code","ee7b768f":"code","c927e2f5":"code","3503cb97":"code","ac745580":"markdown","45961480":"markdown","59f678e8":"markdown","5a3c25dc":"markdown","34f6d4d6":"markdown","f6859975":"markdown","50896cb5":"markdown","d57a81d2":"markdown","fda6941e":"markdown","387ba678":"markdown","d8f962af":"markdown","d5aa7051":"markdown","5bd6c735":"markdown","08be8c33":"markdown","5a3602c0":"markdown","404b4d84":"markdown","1362871e":"markdown","2e2000a4":"markdown","ecd9cb14":"markdown"},"source":{"c9f3a88b":"#Installing the library containing some segmentation models\n!pip install segmentation-models-pytorch","0bc9308b":"import numpy as np\nimport pandas as pd\nimport os\n\n!pip install torchviz\n%matplotlib inline\nimport cv2\nimport random\nimport tqdm\nfrom tqdm import notebook\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom PIL import Image\nimport torch.nn as nn\nfrom torchviz import make_dot\n\n#Importing the library into the notebook\nimport segmentation_models_pytorch as seg_models","7ad169ce":"image_dir = \"..\/input\/cityscapes-image-pairs\/cityscapes_data\"\ntrain_images = os.path.join(image_dir, 'train')\nval_images = os.path.join(image_dir, 'val')\n\ntrain_files = os.listdir(train_images)\nval_files = os.listdir(val_images)\n\n# Print any image of your choice from the training set\ns_no = 20\n\nimg = Image.open(os.path.join(train_images, train_files[s_no])).convert(\"RGB\")\n\nplt.imshow(img)\nplt.show()","8214d263":"class data_load(object):\n    def __init__(self, images_dir, batch_size, shuffle = True, rescale = 1.00, target_size = (128, 128)):\n        super(data_load, self).__init__()\n        self.images_dir = images_dir\n        self.batch_size = batch_size\n        self.rescale = rescale\n        self.shuffle = shuffle\n        self.target_size = target_size\n        self.filenames = [os.path.join(self.images_dir, filename) for filename in os.listdir(self.images_dir)]\n        self.step_number = 0\n        self.total_steps = int(len(self.filenames) \/\/ self.batch_size)\n        \n    def generate_batch(self):\n        start = self.step_number * self.batch_size\n        stop = (self.step_number + 1) * self.batch_size\n        filenames_batch = self.filenames[start:stop]\n        \n        images_batch = [cv2.imread(filename) for filename in filenames_batch]\n        images_batch = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in images_batch])\n        \n        # To separate images and their labels\n        images_batch = np.array([(image[:, :256,], image[:, 256:]) for image in images_batch])\n        \n        images_batch = np.array([(cv2.resize(image, self.target_size), cv2.resize(mask, self.target_size)) for (image, mask) in images_batch], dtype = np.float32)\n        images_batch = np.array([(np.moveaxis(image, -1, 0), np.moveaxis(mask, -1, 0)) for (image, mask) in images_batch])\n        images_batch \/= self.rescale\n        images_batch = np.moveaxis(images_batch, 1, 0)\n        \n        return torch.Tensor(images_batch)\n    \n    def __next__(self):\n        if self.step_number > self.total_steps:\n            self.step_number = 0\n        images, masks = self.generate_batch()\n        self.step_number += 1\n        return images, masks\n    \n    def __len__(self):\n        return self.total_steps","600aa8f3":"names = [\"PSPNet\", \"UNet\", \"Unet++\", \"FPN\", \"DeepLab V3\", \"DeepLab V3+\"]\nmodels_dict = {\n    \"PSPNet\": seg_models.PSPNet(classes=3),\n    \"UNet\": seg_models.Unet(classes=3),\n    \"Unet++\": seg_models.UnetPlusPlus(classes=3),\n    \"FPN\": seg_models.FPN(classes=3),\n    \"DeepLab V3\": seg_models.DeepLabV3(classes=3),\n    \"DeepLab V3+\": seg_models.DeepLabV3Plus(classes=3),\n}","35c2e179":"def dice(pred, label):\n    pred = (pred > 0).float()\n    return 2. * (pred*label).sum() \/ (pred+label).sum()","0d95d8c6":"def training(model, epochs, batch_size):\n \n    train_generator = data_load(images_dir = train_images, batch_size = batch_size, rescale = 255.0)\n    test_generator = data_load(images_dir = val_images, batch_size = batch_size, rescale = 255.0)\n    \n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    \n    main_pbar = tqdm.notebook.tqdm(range(epochs))\n    main_pbar.set_description('common progress ')\n    \n    for epoch in main_pbar:\n        running_params = dict(train_loss = [], \n                               train_dice = [], \n                               test_loss = [], \n                               test_dice = [])\n        train_pbar = tqdm.notebook.tqdm(range(len(train_generator)))\n        \n        for step in train_pbar:\n             \n            train_imgs, train_masks = next(train_generator)\n            train_imgs, train_masks = train_imgs.to(device), train_masks.to(device)\n            \n            optimizer.zero_grad()\n            \n            train_predictions = model(train_imgs)\n\n            train_loss = criterion(train_predictions, train_masks)\n            train_loss.backward()\n            \n            train_dice = dice(pred = train_predictions, label = train_masks)\n            \n            optimizer.step()\n        \n        \n       \n            with torch.no_grad():\n                test_images, test_masks = next(test_generator)\n                test_images, test_masks = test_images.to(device), test_masks.to(device)\n            \n                test_predictions = model(test_images)\n    \n                test_loss = criterion(test_predictions, test_masks)\n        \n                test_dice = dice(pred = test_predictions, label = test_masks)\n                \n            \n            current_metrics = dict(train_loss = [train_loss.item(), ], \n                                   train_dice = [train_dice.item(), ], \n                                   test_loss = [test_loss.item(),], \n                                   test_dice = [test_dice.item(),])\n            \n            running_params.update(current_metrics)\n            \n            mean_metrics = dict(zip(running_params.keys(), [(sum(tensor) \/ (step + 1)) for tensor in running_params.values()]))\n    \n            train_pbar.set_postfix(mean_metrics)\n            torch.cuda.empty_cache()\n        \n        temp = [train_loss.item(), train_dice.item(), test_loss.item(), test_dice.item()]\n        logs.append(temp)\n        history.update(running_params)\n        best_loss = max(history['test_loss'])\n        best_loss_index =  history['test_loss'].index(best_loss)\n        current_loss_index = history['test_loss'].index(test_loss.item())\n        if abs(current_loss_index - best_loss_index) >= 5:\n            for param_group in optim.param_groups:\n                if param_group['lr'] * 0.1 > 1e-6:\n                    print('reduce learning rate to', {param_group['lr'] * 0.1})\n                    param_group['lr'] *= 0.1\n","88c8a745":"# Stores the values of losses and dice coeff.\nhistories = []   \n\nfor model_name, model_instance in models_dict.items():\n    name = model_name\n    model_name = model_instance\n    model_name.to(\"cuda:0\")\n    x = torch.zeros(8, 3, 128, 128, dtype=torch.float, requires_grad=False)\n    x = x.to(\"cuda:0\")\n    outputs_x = model_name(x)\n    make_dot(outputs_x, params=dict(list(model_name.named_parameters())))\n    \n    optimizer = torch.optim.Adam(params = model_name.parameters(), \n                             lr=1e-4, \n                             betas=(0.9, 0.999), \n                             eps=1e-08, \n                             weight_decay=0, \n                             amsgrad=False)\n\n    criterion = torch.nn.BCEWithLogitsLoss()\n\n    history = dict(train_loss = [], \n                   train_dice = [], \n                   test_loss = [], \n                   test_dice = [])\n    \n    logs = []\n    \n    training(model = model_name, epochs = 20, batch_size = 32)\n    \n    histories.append(logs)\n    \n    # Saving the model weights for each model in working directory\n    working_dir = '\/kaggle\/working'\n    weights_path = os.path.join(working_dir, name + '_weights.pth')\n    logs_path = os.path.join(working_dir, name + '_logs')\n    torch.save(model_name.state_dict(), weights_path)","68972ac0":"def show(model_name, num_cols):\n    generator = data_load(images_dir = val_images, \n                           batch_size = 8, \n                           rescale = 255.0)\n    result = []\n    for iteration in range(num_cols):\n        images, masks = next(generator)\n        images_1 = images.to(\"cuda:0\")\n        \n        prediction = torch.sigmoid(model_name(images_1))\n        prediction = prediction.cpu().detach().numpy()\n        prediction = np.moveaxis(prediction, 1, -1)\n        masks = np.moveaxis(masks.numpy(), 1, -1)\n        images = np.moveaxis(images.numpy(), 1, -1)\n        prediction = np.concatenate(prediction)\n        images = np.concatenate(images)\n        masks = np.concatenate(masks)\n        outputs = np.hstack([images, masks, prediction])\n        result.append(outputs)\n    result = np.hstack(result)\n    plt.figure(figsize = (30, 30))\n    plt.axis('off')\n    plt.imshow(result)","c373375e":"name = \"PSPNet\"\nmodel_name = models_dict[\"PSPNet\"]\nmodel_name.load_state_dict(torch.load(os.path.join(working_dir, name + '_weights.pth')))\nmodel_name.eval()\nshow(model_name, num_cols = 2)","082a08c4":"name = \"UNet\"\nmodel_name = models_dict[\"UNet\"]\nmodel_name.load_state_dict(torch.load(os.path.join(working_dir, name + '_weights.pth')))\nmodel_name.eval()\nshow(model_name, num_cols = 2)","b4859688":"name = \"Unet++\"\nmodel_name = models_dict[\"Unet++\"]\nmodel_name.load_state_dict(torch.load(os.path.join(working_dir, name + '_weights.pth')))\nmodel_name.eval()\nshow(model_name, num_cols = 2)","c5a33632":"name = \"FPN\"\nmodel_name = models_dict[\"FPN\"]\nmodel_name.load_state_dict(torch.load(os.path.join(working_dir, name + '_weights.pth')))\nmodel_name.eval()\nshow(model_name, num_cols = 2)","b90e17c6":"name = \"DeepLab V3\"\nmodel_name = models_dict[\"DeepLab V3\"]\nmodel_name.load_state_dict(torch.load(os.path.join(working_dir, name + '_weights.pth')))\nmodel_name.eval()\nshow(model_name, num_cols = 2)","fa7d2c3a":"name = \"DeepLab V3+\"\nmodel_name = models_dict[\"DeepLab V3+\"]\nmodel_name.load_state_dict(torch.load(os.path.join(working_dir, name + '_weights.pth')))\nmodel_name.eval()\nshow(model_name, num_cols = 2)","ee7b768f":"DataFrames = {}\nfor i in range(6):\n    name_df = pd.DataFrame(columns=['Train Loss', 'Train Dice Coefficient', 'Test Loss', 'Test Dice Coefficient'])\n    for j in range(len(histories[i])):\n        name_df.loc[len(name_df.index)] = histories[i][j]\n    DataFrames[names[i]] = name_df","c927e2f5":"DataFrames","3503cb97":"for i in names:\n    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize = (40, 20))\n    fig.suptitle('Plots for '+i)\n    ax1.plot(DataFrames[i][\"Train Loss\"])\n#     ax1.set_ylim([0.5, 0.6])\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Train Loss')\n    \n    ax3.plot(DataFrames[i][\"Test Loss\"])\n#     ax3.set_ylim([0.5, 0.6])\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('Test Loss')\n    \n    ax2.plot(DataFrames[i][\"Train Dice Coefficient\"])\n#     ax2.set_ylim([0.4, 0.5])\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Train Dice Coefficient')\n    \n    ax4.plot(DataFrames[i][\"Test Dice Coefficient\"])\n#     ax4.set_ylim([0.4, 0.5])\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Test Dice Coefficient')","ac745580":"# UNet","45961480":"# DeepLab V3+","59f678e8":"## Dice Coefficient","5a3c25dc":"## Models\n\nStoring the names of the models to be used and their instances in a dictionary.","34f6d4d6":"### Though all the models perform decently and almost similar loss on the Validation Set. We get best Dice Coefficients and loss for **UNet++** on the Validation Set","f6859975":"# DeepLab V3","50896cb5":"The images and their labels are clubbed together. We'll have to separate while loading them as well.","d57a81d2":"## Results of each model","fda6941e":"# Implementing Image Segmentation using 6 different models\n\n* PSPNet\n* UNet\n* UNet++\n* FPN\n* DeepLab V3\n* DeepLab V3+","387ba678":"## Train Function","d8f962af":"## Training & Saving Weights","d5aa7051":"## Data Loader Pipeline","5bd6c735":"# FPN","08be8c33":"# PSPNet","5a3602c0":"## Storing & Plotting (Losses & Dice Coefficient)\n\nStoring all the train and test values in a dictionary of DataFrames for easy fetch.","404b4d84":"## Importing Libraries","1362871e":"## Installing the library containing segmentation models.\n\nThis library contains some of the well-known segmentation models. You can look up the models, their architectures and their code on github. \nThe github link to the library : https:\/\/github.com\/qubvel\/segmentation_models.pytorch.","2e2000a4":"# UNet++","ecd9cb14":"## Checking out an example"}}