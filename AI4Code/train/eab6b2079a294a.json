{"cell_type":{"3c643ebd":"code","9328ae6d":"code","578a4297":"code","5c040f1a":"code","5d902808":"code","b76fcaa9":"code","6365a8a0":"code","8d36fc14":"code","85f1e723":"code","7faca8c6":"code","7b25901f":"code","72024dba":"code","78f4c433":"code","a6f21990":"code","8cc6a94a":"code","6ca5af51":"code","6c51d446":"code","771b5a8f":"code","11d39e95":"code","72de6869":"code","7af4eeaa":"code","2194f340":"code","58272121":"code","3ebaf940":"code","97464d67":"code","5043390a":"code","f7d24ab2":"code","24cd042b":"code","2f6e4034":"code","8e9e698f":"code","a8e93339":"code","5d6fcc01":"code","9f10cdbd":"code","68b6d915":"code","9c098929":"markdown","cc70173e":"markdown","0c8d53f3":"markdown","08c6c62d":"markdown","5cd0dbbb":"markdown","55c0f8df":"markdown","7bb07442":"markdown","e779ee8a":"markdown","3270e6ab":"markdown","d11a22b0":"markdown","60f67c5a":"markdown"},"source":{"3c643ebd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import ensemble\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas_profiling\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9328ae6d":"import matplotlib\nmatplotlib.__version__","578a4297":"data_train=pd.read_csv('\/kaggle\/input\/learn-together\/train.csv')\ndata_test=pd.read_csv('\/kaggle\/input\/learn-together\/test.csv')","5c040f1a":"print(\"train data:\",data_train.shape, \"test data:\",data_test.shape)","5d902808":"profile = data_train.profile_report(title='Pandas Profiling Report')","b76fcaa9":"profile","6365a8a0":"for column in data_train.iloc[:,1:11]:\n    plt.figure()\n    data_train.boxplot([column],sym='k.')","8d36fc14":"data_train.iloc[:, 2:11].hist(figsize=(16, 12), bins=50)","85f1e723":"def r(x):\n    if x + 180 > 360:\n        return x - 180\n    else:\n        return x + 180","7faca8c6":"data_train['Aspect2'] = data_train.Aspect.map(r)\ndata_test['Aspect2'] = data_test.Aspect.map(r)","7b25901f":"data_train['Highwater']=data_train.Vertical_Distance_To_Hydrology < 0\ndata_test['Highwater'] = data_test.Vertical_Distance_To_Hydrology < 0","72024dba":"def plotc(c1, c2):\n    fig = plt.figure(figsize=(16, 8))\n    sel = np.array(list(data_train.Cover_Type.values))\n\n    plt.scatter(c1, c2, c=sel, cmap=plt.cm.jet,s=100)\n    plt.xlabel(c1.name)\n    plt.ylabel(c2.name)\n    plt.show()\n\n","78f4c433":"plotc(data_train.Elevation, data_train.Vertical_Distance_To_Hydrology)","a6f21990":"plotc(data_train.Elevation-data_train.Vertical_Distance_To_Hydrology, data_train.Vertical_Distance_To_Hydrology)","8cc6a94a":"data_train['EVDtH'] = data_train.Elevation - data_train.Vertical_Distance_To_Hydrology\ndata_test['EVDtH'] = data_test.Elevation - data_test.Vertical_Distance_To_Hydrology","6ca5af51":"data_train['EHDtH'] = data_train.Elevation - data_train.Horizontal_Distance_To_Hydrology * 0.2\ndata_test['EHDtH'] = data_test.Elevation - data_test.Horizontal_Distance_To_Hydrology * 0.2","6c51d446":"data_train['Distance_to_Hydrology'] = (data_train['Horizontal_Distance_To_Hydrology'] ** 2 + data_train[\n    'Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\ndata_test['Distance_to_Hydrology'] = (data_test['Horizontal_Distance_To_Hydrology'] ** 2 + data_test[\n    'Vertical_Distance_To_Hydrology'] ** 2) ** 0.5","771b5a8f":"data_train['Hydro_Fire_1'] = data_train['Horizontal_Distance_To_Hydrology'] + data_train['Horizontal_Distance_To_Fire_Points']\ndata_test['Hydro_Fire_1'] = data_test['Horizontal_Distance_To_Hydrology'] + data_test['Horizontal_Distance_To_Fire_Points']\n\ndata_train['Hydro_Fire_2'] = abs(data_train['Horizontal_Distance_To_Hydrology'] - data_train['Horizontal_Distance_To_Fire_Points'])\ndata_test['Hydro_Fire_2'] = abs(data_test['Horizontal_Distance_To_Hydrology'] - data_test['Horizontal_Distance_To_Fire_Points'])\n\ndata_train['Hydro_Road_1'] = abs(data_train['Horizontal_Distance_To_Hydrology'] + data_train['Horizontal_Distance_To_Roadways'])\ndata_test['Hydro_Road_1'] = abs(data_test['Horizontal_Distance_To_Hydrology'] + data_test['Horizontal_Distance_To_Roadways'])\n\ndata_train['Hydro_Road_2'] = abs(data_train['Horizontal_Distance_To_Hydrology'] - data_train['Horizontal_Distance_To_Roadways'])\ndata_test['Hydro_Road_2'] = abs(data_test['Horizontal_Distance_To_Hydrology'] - data_test['Horizontal_Distance_To_Roadways'])\n\ndata_train['Fire_Road_1'] = abs(data_train['Horizontal_Distance_To_Fire_Points'] + data_train['Horizontal_Distance_To_Roadways'])\ndata_test['Fire_Road_1'] = abs(data_test['Horizontal_Distance_To_Fire_Points'] + data_test['Horizontal_Distance_To_Roadways'])\n\ndata_train['Fire_Road_2'] = abs(data_train['Horizontal_Distance_To_Fire_Points'] - data_train['Horizontal_Distance_To_Roadways'])\ndata_test['Fire_Road_2'] = abs(data_test['Horizontal_Distance_To_Fire_Points'] - data_test['Horizontal_Distance_To_Roadways'])","11d39e95":"feature_cols = [col for col in data_train.columns if col not in ['Cover_Type', 'Id']]","72de6869":"features = data_train[feature_cols]\nfeatures_test = data_test[feature_cols]\ntarget = data_train['Cover_Type']\ntest_ids = data_test['Id']","7af4eeaa":"from bayes_opt import BayesianOptimization\nfrom sklearn.model_selection import train_test_split","2194f340":"X_train,X_test,y_train,y_test =train_test_split(features,target,test_size=0.3,random_state=0,stratify=target)","58272121":"#Bayesian optimization\ndef bayesian_optimization(dataset, function, parameters):\n   X_train, y_train, X_test, y_test = dataset\n   n_iterations = 5\n   gp_params = {\"alpha\": 1e-4}\n\n   BO = BayesianOptimization(function, parameters)\n   BO.maximize(n_iter=n_iterations, **gp_params)\n\n   return BO.max","3ebaf940":"def rfc_optimization(cv_splits):\n    def function(n_estimators, max_depth, min_samples_split):\n        return cross_val_score(\n               RandomForestClassifier(\n                   n_estimators=int(max(n_estimators,0)),                                                               \n                   max_depth=int(max(max_depth,1)),\n                   min_samples_split=int(max(min_samples_split,2)), \n                   n_jobs=-1, \n                   random_state=42,   \n                   class_weight=\"balanced\"),  \n               X=X_train, \n               y=y_train, \n               cv=cv_splits,\n               #scoring=\"roc_auc\",\n               n_jobs=-1).mean()\n\n    parameters = {\"n_estimators\": (10, 1000),\n                  \"max_depth\": (1, 150),\n                  \"min_samples_split\": (2, 10)}\n    \n    return function, parameters","97464d67":"def train(X_train, y_train, X_test, y_test, function, parameters):\n    dataset = (X_train, y_train, X_test, y_test)\n    cv_splits = 4\n    \n    best_solution = bayesian_optimization(dataset, function, parameters)      \n    params = best_solution[\"params\"]\n\n    model = RandomForestClassifier(\n             n_estimators=int(max(params[\"n_estimators\"], 0)),\n             max_depth=int(max(params[\"max_depth\"], 1)),\n             min_samples_split=int(max(params[\"min_samples_split\"], 2)), \n             n_jobs=-1, \n             random_state=42,   \n             class_weight=\"balanced\")\n\n    model.fit(X_train, y_train)\n    \n    return model","5043390a":"function,parameters = rfc_optimization(4)","f7d24ab2":"from sklearn.model_selection import cross_val_score\n\nfrom sklearn.ensemble import RandomForestClassifier\n","24cd042b":"classifier = train(X_train, y_train, X_test, y_test, function, parameters)","2f6e4034":"y_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix,accuracy_score\ncm = confusion_matrix(y_test, y_pred)\naccuracy_score=accuracy_score(y_test,y_pred )\naccuracy_score","8e9e698f":"test_pred=classifier.predict(features_test)","a8e93339":"sel = np.array(list(data_train.Cover_Type.values))\nsel1=np.unique(sel)\ndata_train.groupby('Cover_Type').count()[['Id']].plot.pie(subplots=True,radius = 2, autopct = '%1.1f%%')\nplt.legend(sel1,loc='upper center')\nplt.title(\"Cover Type distributions\")\nplt.show()\n","5d6fcc01":"output = pd.DataFrame({'Id':data_test.Id, \n                       'Cover_Type': test_pred})","9f10cdbd":"sel = np.array(list(output.Cover_Type.values))\nsel1=np.unique(sel)\noutput.groupby('Cover_Type').count()[['Id']].plot.pie(subplots=True,radius = 2, autopct = '%1.1f%%')\nplt.legend(sel1,loc='upper center')\nplt.title(\"Cover Type distributions\")\nplt.show()\n","68b6d915":"output.to_csv('submission.csv', index=False)","9c098929":"*  References\n\n* [https:\/\/douglas-fraser.com\/forest_cover_management.pdf]\n* Feature Engineering\n* [https:\/\/github.com\/jaustinrdi\/kaggle\/blob\/master\/kaggle_forest\/guschin_example.py#L64]\n\nMore to enhance......................","cc70173e":"Above plot clearly shows there are observations of vertical distance to hydrology which are negative.","0c8d53f3":"*  Above Profile shows all the details about the data.","08c6c62d":"* Below calculations are to calculate the distance between the hydrology and fire points,hydrology and \n  road ways,fire points and road ways\n","5cd0dbbb":"Angle of the Aspect\n","55c0f8df":"* By looking at the boxplots .It clearly shows there are outliers in the data.Except for Elevation and Aspect.","7bb07442":"* Problem statement* \n\n\n  Given the data on the forest cover type can be analyzed to predict what type of forest or tree will arise\n  in a specific area.\n \n ","e779ee8a":"Above plots depict the spread of data ","3270e6ab":"Depth of the hydrology or water","d11a22b0":"* Below calculation is to calculate the distance of the hydrology ,the formaula used is hypotenuse = sqrt(a2+b2).","60f67c5a":"* Below boxplots are for only numeric columns to check the outliers"}}