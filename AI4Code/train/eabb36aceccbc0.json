{"cell_type":{"8030e8e3":"code","43391850":"code","d9325852":"code","e0f221c4":"code","8bd69d58":"code","b0a36ec4":"code","bfa724d7":"code","c0df5f6b":"code","52c65ab6":"code","a89c908c":"code","bb9b421f":"code","07cffe49":"code","72246a67":"code","17e91e61":"code","e943060b":"code","3e3aadce":"code","0deda670":"code","48690f3e":"code","3625a02e":"code","b4186204":"code","f7de0fdd":"code","ea6146aa":"code","d3941f54":"code","5ad38d58":"code","ccfce9c6":"code","85d3ccfb":"code","b4182e10":"code","773a13f3":"code","92ece634":"code","f5d5018f":"code","0980ddcb":"code","31de1343":"code","12fdc5c0":"code","573a81fa":"code","6d882e64":"code","f391da7f":"code","c56b27cb":"code","f0ff24d0":"code","ede5ed09":"code","f103fd59":"code","8819e1f9":"code","b6d6c2a9":"markdown","acae37b0":"markdown","5ef6775e":"markdown","bf8c63a7":"markdown","b7aeb35c":"markdown","87a181f4":"markdown","eff94d1d":"markdown","fcda87a3":"markdown","69158b94":"markdown","83693762":"markdown","c733e44d":"markdown","bb473b64":"markdown","be341d4a":"markdown","b1236fe1":"markdown","915e56ea":"markdown","4a78f8d8":"markdown","81ba53c5":"markdown","3dd05c64":"markdown","4f9e7747":"markdown","cd339120":"markdown","c4c20a4b":"markdown","9019e13d":"markdown","030cac70":"markdown","04de37c1":"markdown","4a2f8f6e":"markdown","1ddace1b":"markdown","23aef34f":"markdown","cfba4d5c":"markdown","7ece2598":"markdown","1d9a65f6":"markdown","e9f8e075":"markdown","5f52ec92":"markdown","ac5bae8c":"markdown","9818f3d3":"markdown","60de7df1":"markdown","fdda4383":"markdown","72d60834":"markdown","9a8776cf":"markdown","8d201b8e":"markdown","2a46d817":"markdown"},"source":{"8030e8e3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport sklearn\nimport numpy as np \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","43391850":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","d9325852":"print('Total de linhas e colunas\\n\\n',df.shape,'\\n')","e0f221c4":"df.isnull().sum()","8bd69d58":"df.info()","b0a36ec4":"df.describe().round()","bfa724d7":"print ('Not Fraud % ',round(df['Class'].value_counts()[0]\/len(df)*100,2))\nprint ()\nprint (round(df.Amount[df.Class == 0].describe(),2))\nprint ()\nprint ()\nprint ('Fraud %    ',round(df['Class'].value_counts()[1]\/len(df)*100,2))\nprint ()\nprint (round(df.Amount[df.Class == 1].describe(),2))","c0df5f6b":"plt.figure(figsize=(10,8))\nsns.set_style('darkgrid')\nsns.barplot(x=df['Class'].value_counts().index,y=df['Class'].value_counts(), palette=[\"C1\", \"C8\"])\nplt.title('Non Fraud X Fraud')\nplt.ylabel('Count')\nplt.xlabel('0: Non Fraud,  1: Fraud')\nprint ('Non Fraud % ',round(df['Class'].value_counts()[0]\/len(df)*100,2))\nprint ('Fraud %    ',round(df['Class'].value_counts()[1]\/len(df)*100,2));","52c65ab6":"feature_names = df.iloc[:, 1:30].columns\ntarget = df.iloc[:1, 30:].columns\n\ndata_features = df[feature_names]\ndata_target = df[target]","a89c908c":"feature_names","bb9b421f":"target","07cffe49":"from sklearn.model_selection import train_test_split\nnp.random.seed(123)\nX_train, X_test, y_train, y_test = train_test_split(data_features, data_target, \n                                                    train_size = 0.70, test_size = 0.30, random_state = 1)","72246a67":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()","17e91e61":"lr.fit(X_train, y_train)","e943060b":"def PrintStats(cmat, y_test, pred):\n    tpos = cmat[0][0]\n    fneg = cmat[1][1]\n    fpos = cmat[0][1]\n    tneg = cmat[1][0]","3e3aadce":"def RunModel(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train.values.ravel())\n    pred = model.predict(X_test)\n    matrix = confusion_matrix(y_test, pred)\n    return matrix, pred","0deda670":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport scikitplot as skplt","48690f3e":"cmat, pred = RunModel(lr, X_train, y_train, X_test, y_test)","3625a02e":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test, pred)","b4186204":"accuracy_score(y_test, pred)","f7de0fdd":"print (classification_report(y_test, pred))","ea6146aa":"# The function \"len\" counts the number of classes = 1 and saves it as an object \"fraud_records\"\nfraud_records = len(df[df.Class == 1])\n\n# Defines the index for fraud and non-fraud in the lines:\nfraud_indices = df[df.Class == 1].index\nnot_fraud_indices = df[df.Class == 0].index\n\n# Randomly collect equal samples of each type:\nunder_sample_indices = np.random.choice(not_fraud_indices, fraud_records, False)\ndf_undersampled = df.iloc[np.concatenate([fraud_indices, under_sample_indices]),:]\nX_undersampled = df_undersampled.iloc[:,1:30]\nY_undersampled = df_undersampled.Class\nX_undersampled_train, X_undersampled_test, Y_undersampled_train, Y_undersampled_test = train_test_split(X_undersampled, Y_undersampled, test_size = 0.30)","d3941f54":"lr_undersampled = LogisticRegression()\ncmat, pred = RunModel(lr_undersampled, X_undersampled_train, Y_undersampled_train, X_undersampled_test, Y_undersampled_test)\nPrintStats(cmat, Y_undersampled_test, pred)","5ad38d58":"skplt.metrics.plot_confusion_matrix(Y_undersampled_test, pred)","ccfce9c6":"accuracy_score(Y_undersampled_test, pred)","85d3ccfb":"print (classification_report(Y_undersampled_test, pred))","b4182e10":"lr_undersampled = LogisticRegression()\ncmat, pred = RunModel(lr_undersampled, X_undersampled_train, Y_undersampled_train, X_test, y_test)\nPrintStats(cmat, y_test, pred)","773a13f3":"skplt.metrics.plot_confusion_matrix(y_test, pred)","92ece634":"accuracy_score(y_test, pred)","f5d5018f":"print (classification_report(y_test, pred))","0980ddcb":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\"C\": [1,2,3,4,5,6,7,8,9,10], \n              \"penalty\": ['l1','l2']} #Parameters\n            \ngrid_search = GridSearchCV(lr, param_grid, scoring=\"precision\") #score\ngrid_search.fit(y_test, pred)\n\nlr = grid_search.best_estimator_ \ngrid_search.best_params_, grid_search.best_score_","31de1343":"lr_undersampled = LogisticRegression(C=1, penalty='l2')\ncmat, pred = RunModel(lr_undersampled, X_undersampled_train, Y_undersampled_train, X_undersampled_test, Y_undersampled_test)\nPrintStats(cmat, Y_undersampled_test, pred)","12fdc5c0":"skplt.metrics.plot_confusion_matrix(Y_undersampled_test, pred)","573a81fa":"accuracy_score(Y_undersampled_test, pred)","6d882e64":"print (classification_report(Y_undersampled_test, pred))","f391da7f":"lr = LogisticRegression(C=1, penalty='l2')\ncmat, pred = RunModel(lr, X_undersampled_train, Y_undersampled_train, X_test, y_test)\nPrintStats(cmat, y_test, pred)","c56b27cb":"skplt.metrics.plot_confusion_matrix(y_test, pred)","f0ff24d0":"accuracy_score(y_test, pred)","ede5ed09":"print (classification_report(y_test, pred))","f103fd59":"from sklearn import metrics                           ","8819e1f9":"clf = LogisticRegression(C=1, penalty='l2')\nclf.fit(X_undersampled_train, Y_undersampled_train)\ny_pred = clf.predict(X_test)\n\ny_pred_probability = clf.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred_probability)\nauc = metrics.roc_auc_score(y_test, pred)\nplt.plot(fpr,tpr,label=\"LogisticRegression, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","b6d6c2a9":"### Reading the dataset","acae37b0":"With the Logistic Regression Model, we have:\n\n85290 transactions classified as normal and were actually normal;\n\n18 transactions classified as fraud but that were really normal (type 1 error);\n\n61 transactions classified as normal but which were fraud (type 2 error);\n\n74 transactions classified as fraud and were actually fraud.\n\nThus, although the accuracy was excellent, the algorithm wrongly classified about 4 out of 10 fraudulent transactions.\n\nAccuracy in a highly unbalanced data set does not represent a correct value for the efficiency of a model.\n\nInitially, a method should be applied to balance the data before taking into account any performance evaluation metrics.\n\n** Accuracy in a highly unbalanced data set does not represent a correct value for the efficiency of a model. Initially, a method should be applied to balance the data before taking into account any performance evaluation metrics.","5ef6775e":"With the dataset defined, separating the input variables from the target variable, we divided the data into training and test sets, importing the train_test_split function.\n\nThe train_test_split function uses a randomizer to separate data into training and test sets. In this case, 70% of the data for training and 30% for tests were defined.\n\nThe random seed (np.random.seed) is used to ensure that the same data is used for all runs.","bf8c63a7":"![image.png](attachment:image.png)","b7aeb35c":"### Comparing the amount value of normal transactions versus fraud","87a181f4":"In this case, we will use the undersampling technique to obtain a uniform division between fraud and valid transactions. This will make the training set small, but with enough data to generate a good classifier.","eff94d1d":"The application of methods for data balancing, such as undersampling and oversampling techniques are widely used in these cases. Changing the sampling makes the algorithm more \"sensitive\" to fraudulent transactions.\n\nUndersampling is the technique of removing major class records from the sample. In this case, it is necessary to remove random records from the legitimate class (No fraud), in order to obtain a number of records close to the amount of the minority class (fraud) in order to train the model.\n\nOversampling is exactly the opposite: it means adding minority class records (fraud) to our training sample, thus increasing the overall proportion of fraud records. There are methods to generate samples from the minority class, either by duplicating existing records or artificially generating others.","fcda87a3":"### Training the model","69158b94":"### Application of the Model to the original data test","83693762":"### Undersampling and Oversampling - Working with unbalanced data","c733e44d":"### Classification Report - Model performance measures","bb473b64":"### GridSearchCV - Parameter optimization","be341d4a":"The algorithms have several parameters that can be optimized. The best values for these parameters change as the data changes, as we add or remove features and as we change the other parameters as well.\n\nOne of the techniques that can be used to find the best values for these parameters is the Grid Search CV. You give him a list of possible values and the score used to measure the efficiency of the model, he will run Cross Validation with all possible combinations and at the end will inform which combination has the best score.\n\nOnce we have the best values, we pass them directly to the model. Only after some really significant changes in data and features can it be worth running again, depending on the base and the number of combinations.","b1236fe1":"*The average value of fraud transactions is 122.21 and for normal transactions, 88.29.","915e56ea":"### Applying the undersampling technique","4a78f8d8":"According to Infosecurity Magazine, fraud cost the global economy \u00a3 3.2 trillion in 2018 (https:\/\/www.infosecurity-magazine.com\/news\/global-fraud-hits-32-trillion\/). For many companies, losses involving transaction fraud amount to more than 10% of their total expenses. The concern with these massive losses leads companies to constantly seek new solutions to prevent, detect and eliminate fraud. Machine Learning is one of the most promising technological weapons to combat financial fraud.\n\nThe objective of this project is to create a simple Logistic Regression model capable of detecting fraud in credit card operations, thus seeking to minimize the risk and loss of the business. The biggest challenge is to create a model that is very sensitive to fraud, since most transactions are legitimate, making detection difficult.\n\nThe dataset used, contains transactions carried out by European credit card holders that took place over two days in September 2013, and is available on kaggle at https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\/version\/3.\n\nIt is a very unbalanced data set, that is, it has 492 fraud transactions, which represents only 0.172% of the 284,807 transactions.\n\nThe input variables are numeric, the result of a PCA transformation. Due to confidentiality issues, the original data and other complementary information were not made available.\n\nThe only variables that have not been transformed with the PCA are 'Time' and 'Value'. The variable 'Time' contains the seconds between each transaction and the first transaction in the data set. The 'Amount' variable refers to the amount of the transaction.\n\nThe 'Class' variable is the response variable (Target) and has a value \"1\" in case of fraud and \"0\" otherwise.","81ba53c5":"The algorithm was much better at capturing fraudulent transactions (61 classification errors at the beginning of the project to 12 current), but much worse at incorrectly labeling valid transactions (15 to 2857).","3dd05c64":"The classifier had a good result, with AUC of 0.94!","4f9e7747":"### Building the Regression Logistic model","cd339120":"Accuracy has decreased, but sensitivity has greatly increased. Looking at the confusion matrix, we can see a much higher percentage of correct classifications of fraudulent data.\n\nUnfortunately, a greater number of fraud classifications almost always means a correspondingly greater number of valid transactions also classified as fraudulent.","c4c20a4b":"### Variable type in each column","9019e13d":"### Basic Libraries import","030cac70":"### Statistical information in each class","04de37c1":"### Verification of the existence of null or missing values","4a2f8f6e":"### Measurement of classifier performance through the ROC and AUC curve","1ddace1b":"### Application of the Model with balanced data and parameter optimization","23aef34f":"### Separation of input variables from target variable","cfba4d5c":"![image.png](attachment:image.png)","7ece2598":"We reached a very satisfactory number in detecting fraud transactions in relation to the initial model, rising from 55% to 91% of correctly identified transactions. In return, the detection of correctly identified normal transactions decreased from 99% to 97%.\n\nRemember that we need to determine where this exchange is worthwhile. Generally, the costs of losing a fraudulent transaction are often greater than mistakenly classifying a good transaction as fraud. One of the challenges is to find the balance in training your model and proceed accordingly.\n\nAs a way to further improve the performance of the model, there are several ways to explore the input variables, performing some techniques of \"Data Pre-Processing\" and \"Feature Engineering\".","1d9a65f6":"### Statistical information about the variables","e9f8e075":"## Introduction","5f52ec92":"# Credit card transaction fraud detection - Logistic Regression example","ac5bae8c":"### Confusion Matrix - Model performance measures","9818f3d3":"![image.png](attachment:image.png)","60de7df1":"### Using the \"new\" classifier for balanced data","fdda4383":"We can see the total of 284,807 transactions, 284,315 were labeled as normal (99.83%), and only 492 transactions were labeled as fraud (0.17%). Although it may seem small, each fraud transaction can represent a very significant expense, which together can represent billions of dollars of lost revenue each year.","72d60834":"### Number of rows and columns","9a8776cf":"### Using the \"new\" classifier for the original data test","8d201b8e":"### Conclusion","2a46d817":"The \"ROC\" curve is a probability curve that shows how much the classifier can distinguish between two things, through two parameters: the true-positive rate versus the false-positive rate, that is, the number of times the classifier hit the prediction against the number of times the classifier missed the prediction.\n\nThe \"AUC\" is derived from the \"ROC\" curve and represents the degree or measure of separability. The AUC summarizes the ROC curve in a single value, calculating the \u201carea under the curve\u201d. The higher the AUC the better the model is in predicting 0s as 0s and 1s as 1s. In this case, the higher the AUC the better the model is in distinguishing between fraudulent and normal transactions. The AUC value ranges from 0.0 to 1.0.\n\nAn excellent model has AUC close to 1, which means it has a good measure of separability. A poor model has AUC close to 0, which means that it has the worst measure of separability, that is, it is predicting 0s as 1s and 1s as 0s. And when the AUC is 0.5, it means that the model has no class separation capability."}}