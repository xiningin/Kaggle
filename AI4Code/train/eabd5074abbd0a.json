{"cell_type":{"e7900bf9":"code","4d4b2665":"code","da54b258":"code","20038750":"code","c3429be2":"code","2c592455":"code","51e309ae":"code","585b0bfa":"code","fed82438":"code","3a5fad89":"code","403be330":"code","74e36a85":"code","3c9478e2":"code","aabe4ff0":"code","749d8d62":"code","4700a9a8":"code","72cd774b":"markdown","ec2845a7":"markdown","a56bd8f2":"markdown"},"source":{"e7900bf9":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.models as Models\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nimport tensorflow.keras.layers as Layers\nimport os\nimport matplotlib.pyplot as plot\nimport cv2\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom keras.utils.vis_utils import model_to_dot\nimport tensorflow.keras.utils as Utils\nfrom sklearn.metrics import confusion_matrix as CM\nfrom random import randint\nfrom IPython.display import SVG\nimport matplotlib.gridspec as gridspec\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nimport random\nimport itertools\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","4d4b2665":"!pip install Pillow\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory","da54b258":"train_path = '..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_train'\ntest_path = '..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_test'","20038750":"#display image of a cup\nimage = Image.open('..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_train\/cups\/cup10.jpg')\nplt.imshow(np.array(image))","c3429be2":"datagen = ImageDataGenerator()","2c592455":"datagen_flow = datagen.flow_from_directory(\n    # the folder with the dataset\n    train_path,\n    # the target image size\n    target_size=(256, 256), \n    # the batch size\n    #batch_size=3,\n    # class mode\n    class_mode=None,\n    # set a random number generator\n    seed=0)","51e309ae":"train_batches = ImageDataGenerator().flow_from_directory(directory=train_path, target_size=(224, 224), batch_size=3)\ntest_batches = ImageDataGenerator().flow_from_directory(directory=test_path, target_size=(224, 224), batch_size=1, \n                                     shuffle=False)","585b0bfa":"img = load_img('..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_train\/cups\/cup4.jpg')\nplt.figure(figsize = (3,3))\nplt.imshow(img)\nplt.axis('off')\nplt.title('Cup 4')\nplt.show()","fed82438":"x = img_to_array(img)\nx2 = x.reshape((1,) + x.shape)","3a5fad89":"i = 0\nfig = plt.figure(figsize = (6,6))\nplt.title('Pre-processed')\nfor batch in datagen.flow(x2, batch_size = 1):\n    i += 1\n    if i > 9:\n        break\n    temp = batch.reshape(x.shape)\n    plt.subplot(3, 3, i)\n    plt.imshow(temp.astype('uint8'))\n    plt.axis('off')\nplt.show()","403be330":"img = load_img('..\/input\/cup-spoon-and-plate\/cup-spoon-plate\/cup-spoon-plate\/csp_train\/plates\/plate1.jpg')\nplt.figure(figsize = (3,3))\nplt.imshow(img)\nplt.axis('off')\nplt.title('Plate 1')\nplt.show()","74e36a85":"# data pre-processing for training\ntrain_datagen =  ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    fill_mode = 'nearest',\n    horizontal_flip = True)\n","3c9478e2":"# data pre-processing for validation\nvalidate_datagen =  ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    fill_mode = 'nearest',\n    horizontal_flip = True)","aabe4ff0":"model = Models.Sequential()\n\nmodel.add(Layers.Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Conv2D(180,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(140,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(100,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.Conv2D(50,kernel_size=(3,3),activation='relu'))\nmodel.add(Layers.MaxPool2D(5,5))\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(180,activation='relu'))\nmodel.add(Layers.Dense(100,activation='relu'))\nmodel.add(Layers.Dense(50,activation='relu'))\nmodel.add(Layers.Dropout(rate=0.5))\nmodel.add(Layers.Dense(6,activation='softmax'))\n\nmodel.compile(optimizer=Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nUtils.plot_model(model,to_file='model.png',show_shapes=True)","749d8d62":"trained = model.fit(Images,Labels,epochs=35,validation_split=0.30)","4700a9a8":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])","72cd774b":"# Beginner: Simple Model Creation\nSteps are:\n\n    1.Build the model,\n    2.Compile the model,\n    3.Train \/ fit the data to the model,\n    4.Evaluate the model on the testing set,\n    5.Carry out an error analysis of our model.\nWe can build an easy model composed of different layers such as:\n\n    *Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n    *MaxPooling2D: The images get half sized.\n    *Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\n    *Relu : given a value x, returns max(x, 0).\n    *Softmax: 6 neurons, probability that the image belongs to one of the classes.","ec2845a7":"Then, we can compile it with some parameters such as:\n\n** Optimizer: adam = RMSProp + Momentum. What is Momentum and RMSProp ?\n** Momentum = takes into account past gradient to have a better update.\n** RMSProp = exponentially weighted average of the squares of past gradients.\n** Loss function: we use sparse categorical crossentropy for classification, each images belongs to one class only\n","a56bd8f2":"In this notebook, I will try the process of implementing CNN with Keras in order to classify images.\n\n  1.Firstly, we'll import usefull packages.\n  2.Then, we'll load the data, before visualize and preprocess it.\n  3.We'll try a simple CNN model and then we will evaluate its performances.\n  4.We will then use pre trained model to address this challenge aswell."}}