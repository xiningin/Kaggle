{"cell_type":{"ed717e15":"code","4edf6c45":"code","4ddfa91f":"code","2eacb3be":"code","dabe4f36":"code","ec27ca1b":"code","5e99f824":"code","273895bc":"code","2c2d5394":"code","69835d17":"code","9e028246":"code","15491269":"code","1a4a130b":"code","f04038b0":"code","659e58da":"code","cd91cb57":"markdown"},"source":{"ed717e15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4edf6c45":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, r2_score, confusion_matrix, classification_report\n\nimport warnings\n#warnings.filterwarnings('ignore')\n\nRANDOM_SEED = 22\nSPLIT_TEST_SIZE = 0.3\nX, y, train_X, test_X, train_y, test_y, numerical, categorical = ([] for _ in range(8))","4ddfa91f":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","2eacb3be":"train_orig = train.copy()\ntest_orig = test.copy()\nsubmission_orig = submission.copy()","dabe4f36":"display(train.head(), test.head(), submission.head())","ec27ca1b":"print(train.columns.difference(test.columns), train.columns.intersection(submission.columns))\ntgt_var = train.columns.difference(test.columns)\nprint(tgt_var)","5e99f824":"print(\"Train:\\n\",train.isna().sum()[train.isna().sum().values>0].sort_index(), \\\n      \"\\nTest:\\n\",test.isna().sum()[test.isna().sum().values>0].sort_index())","273895bc":"train.duplicated().sum(), test.duplicated().sum()","2c2d5394":"train.shape, test.shape, submission.shape, \\\ntrain.index, test.index, submission.index, \\\ntrain.iloc[:,0].min(),train.iloc[:,0].max(), \\\ntest.iloc[:,0].min(),test.iloc[:,0].max(), \\\nsubmission.iloc[:,0].min(),submission.iloc[:,0].max()","69835d17":"def split_data(data):\n    global X, y, train_X, test_X, train_y, test_y, numerical, categorical# = ([] for _ in range(8))\n    X = data.drop(columns=tgt_var)\n    y = data[tgt_var]\n    train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = SPLIT_TEST_SIZE, random_state=RANDOM_SEED)\n\n    numerical = data.drop(columns=tgt_var).select_dtypes(include = np.number).columns\n    categorical = data.select_dtypes(exclude = np.number).columns\n    display(numerical, categorical)\n    print(X.shape, y.shape, train_X.shape, test_X.shape, train_y.shape, test_y.shape)\n    ","9e028246":"def pipe_preprocess(pp_cat,pp_num,col_cat,col_num):\n    cat_pipe=num_pipe=[]\n    #print(pp_cat)\n    #print(pp_num)\n    pipe = []\n    \n    cat_pipe = \"['cat',Pipeline([\"\n    for cat in pp_cat:\n        #print(cat)\n        #cat_pipe = ['cat',Pipeline([cat]),col_cat]\n        pipe.append(cat)\n    cat_pipe = [cat_pipe + str(pipe) + \"]),col_cat]\"]\n    print(\"cat_pipe=\",cat_pipe)\n    \n    pipe=[]\n    num_pipe = \"['num',Pipeline([\"\n    for num in pp_num:\n        #print(num)\n        #num_pipe = [(['num',num])]#Pipeline(['num',num,col_num])        \n        pipe.append(num)\n    num_pipe = num_pipe + str(pipe) + \"]),col_num]\"\n    print(\"num_pipe=\",num_pipe)\n\n    pipe=r\"\"+str(cat_pipe)+\",\"+str(num_pipe)\n    print('\\nPipe=',pipe)\n    preprocessor_ct = ColumnTransformer([pipe\n                #[('cat',cat_pipe,col_cat) if cat_pipe != \"\" else None],\n                #[('num',num_pipe,col_num) if num_pipe != \"\" else None],\n                                        ])                            \n            #],remainder='passthrough')\n    return preprocessor_ct","15491269":"col_drop=train[['PassengerId','Name','Ticket']].columns\n\nprint(col_drop)\ndisplay(train.drop(columns=col_drop))\n\nsplit_data(train.drop(columns=col_drop))\nprint(train_X.head(1),train_y.head(1))","1a4a130b":"pp_num=[('SImputer_num',SimpleImputer(strategy='median')),\n        ('MinMaxScaler',MinMaxScaler())]\ncol_tr=\"\"\npp_cat = [('SImputer_cat',SimpleImputer(strategy='constant',fill_value='missing')),\n        ('OHEncoder',OneHotEncoder(handle_unknown='ignore',sparse=False))]\n\ncol_tr = pipe_preprocess(pp_cat,pp_num,categorical,numerical)\nprint('col_tr=',col_tr)","f04038b0":"pipe_model = Pipeline([\n    ('preprocessor', col_tr),\n    ('model', LogisticRegression(penalty='l2'))\n])\nprint(pipe_model)","659e58da":"print(train_X,train_y)","cd91cb57":"#print(X)\n      #,y.head(1))\npipe_model.fit(train_X, train_y)\ntrain_y_pred = pipe_model.predict(X)\nprint(\"Full Train RMSE: \",accuracy_score(y, pipe_model.predict(X)))\nprint(\"Train RMSE     : \",accuracy_score(train_y, pipe_model.predict(train_X)))\nprint(\"Test RMSE      : \",accuracy_score(test_y, pipe_model.predict(test_X)))"}}