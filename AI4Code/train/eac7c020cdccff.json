{"cell_type":{"40c4048f":"code","20de7170":"code","779ed196":"code","634fb1fe":"code","f3c3aa5f":"code","ffe53861":"code","5d115396":"code","934873e2":"code","33013456":"code","a513405e":"code","fd31de39":"code","a74fbfba":"code","c1fc1448":"code","0677f755":"code","78a75b42":"code","56f5bf00":"code","a268a08f":"code","f4af177f":"code","280e40ab":"code","43405bf4":"code","605f4d23":"code","426bf531":"code","ca4276af":"code","36e0ebd3":"code","217483b4":"code","6b9690b7":"code","7e29ff34":"code","0b9fdacd":"code","b5af1039":"code","ab7e695c":"code","a18c1455":"code","e637a971":"code","9ba232b6":"code","8b2c94dd":"code","14527e9b":"code","61b08fcc":"code","b774aa7c":"code","bcba3185":"code","0b23c3bc":"code","2032c98b":"code","90c1fb84":"code","000f9d86":"code","539d1307":"code","24e31682":"code","c6070b6b":"code","c84af247":"code","66fe12ba":"code","1ed0dfab":"code","a9e1fa7a":"code","c353d69c":"code","2d4ca555":"code","a0b47017":"code","c7906bf5":"code","0a565d81":"code","af005180":"code","1bc683ad":"code","5a248265":"code","6b1158c5":"code","ebfdd941":"code","70747964":"code","1106f3d1":"code","2009e79b":"code","3d60a710":"code","3284a48f":"code","908d3225":"code","d786a004":"code","3efaba06":"code","53061568":"code","6d7d32c9":"code","b9beeb41":"code","64f944d7":"code","fe52db9d":"code","01533a23":"code","a6ecc75a":"code","0162b5ba":"code","5ff3446f":"code","ac8cef6a":"code","9ed83ae2":"code","e50b1503":"code","9c102c17":"code","b366f7d5":"code","b7e16a62":"code","1108ea30":"code","dadd7815":"code","59108c38":"code","233b1ca1":"code","94168e81":"code","6b23300a":"code","3172002b":"code","89d0a132":"code","6c088493":"code","6003ca27":"code","35d4fbe4":"code","062a1580":"code","7927ed68":"code","82b5a68a":"code","a4a27f06":"code","25b472a1":"code","0662c5b9":"code","600b7fa8":"code","52e242e2":"code","782b650b":"code","1cba8437":"code","5e11c9d1":"code","ca02cd62":"code","14b79074":"code","35bd911d":"code","89406c4b":"code","af7a2732":"code","ccc16f39":"code","04312b16":"markdown","022b32d7":"markdown","6959d2ec":"markdown","01d611f7":"markdown","aeb5fbe2":"markdown","d4b44541":"markdown","c4ff7e2b":"markdown","896780ce":"markdown","7cfcdccb":"markdown","6eb889fe":"markdown","7082fa5b":"markdown","d9d2e76c":"markdown","bc30ac2c":"markdown","cf43cfa5":"markdown","df492d1a":"markdown","fc2d8485":"markdown","3d3da093":"markdown","c2bccf16":"markdown","bcf1a704":"markdown","d84d6a0f":"markdown","0f34d2ba":"markdown","eb9feb7d":"markdown","2747d26b":"markdown","6b95d03b":"markdown","056e6ff8":"markdown","fd695c3c":"markdown","6a58c49f":"markdown","ac83239d":"markdown","71cc0557":"markdown","97b81117":"markdown","f6abf203":"markdown","bd3213df":"markdown","1c7d2ab8":"markdown","485b1f45":"markdown","1bd5ee69":"markdown","1c66da88":"markdown","a08fdd18":"markdown","87ec5f22":"markdown","bf15250a":"markdown","3b3f0141":"markdown","96a9e641":"markdown"},"source":{"40c4048f":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","20de7170":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")","779ed196":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","634fb1fe":"train.head()","f3c3aa5f":"test.head()","ffe53861":"train.info()","5d115396":"train.describe().T","934873e2":"train['Pclass'].value_counts()","33013456":"train['Sex'].value_counts()","a513405e":"train['SibSp'].value_counts()","fd31de39":"train['Parch'].value_counts()","a74fbfba":"train['Ticket'].value_counts()","c1fc1448":"train['Cabin'].value_counts()","0677f755":"train['Embarked'].value_counts()","78a75b42":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","56f5bf00":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","a268a08f":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","f4af177f":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","280e40ab":"sns.barplot(x = 'Embarked', y = 'Survived', data = train);","43405bf4":"train.head()","605f4d23":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","426bf531":"train.describe([0.10,0.25,0.50,0.75,0.90,0.99]).T","ca4276af":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","36e0ebd3":"Q1 = train['Fare'].quantile(0.05)\nQ3 = train['Fare'].quantile(0.95)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","217483b4":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","6b9690b7":"train.sort_values(\"Fare\", ascending=False).head()","7e29ff34":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","0b9fdacd":"train.sort_values(\"Fare\", ascending=False).head()","b5af1039":"test.sort_values(\"Fare\", ascending=False)","ab7e695c":"test['Fare'] = test['Fare'].replace(512.3292, 300)","a18c1455":"test.sort_values(\"Fare\", ascending=False)","e637a971":"train.isnull().sum()","9ba232b6":"100*train.isnull().sum()\/len(train)","8b2c94dd":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","14527e9b":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","61b08fcc":"train.isnull().sum()","b774aa7c":"test.isnull().sum()","bcba3185":"train.isnull().sum()","0b23c3bc":"test.isnull().sum()","2032c98b":"train[\"Embarked\"].value_counts()","90c1fb84":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","000f9d86":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","539d1307":"train.isnull().sum()","24e31682":"test.isnull().sum()","c6070b6b":"test[test[\"Fare\"].isnull()]","c84af247":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","66fe12ba":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","1ed0dfab":"test[\"Fare\"].isnull().sum()","a9e1fa7a":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","c353d69c":"train.isnull().sum()","2d4ca555":"test.isnull().sum()","a0b47017":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","c7906bf5":"train.head()","0a565d81":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","af005180":"train.head()","1bc683ad":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","5a248265":"train.head()","6b1158c5":"train[\"Title\"].value_counts()","ebfdd941":"train['Title'] = train['Title'].replace(['Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","70747964":"test['Title'] = test['Title'].replace(['Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","1106f3d1":"train.head()","2009e79b":"test.head()","3d60a710":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","3284a48f":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).agg({\"count\",\"mean\"})","908d3225":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","d786a004":"train.isnull().sum()","3efaba06":"test['Title'] = test['Title'].map(title_mapping)","53061568":"test.head()","6d7d32c9":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","b9beeb41":"train.head()","64f944d7":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","fe52db9d":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","01533a23":"train.head()","a6ecc75a":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","0162b5ba":"train.head()","5ff3446f":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","ac8cef6a":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","9ed83ae2":"train.head()","e50b1503":"train.head()","9c102c17":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","b366f7d5":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","b7e16a62":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","1108ea30":"train.head()","dadd7815":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","59108c38":"test.head()","233b1ca1":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"],drop_first=True)\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], drop_first=True,prefix=\"Em\")","94168e81":"train.head()","6b23300a":"test = pd.get_dummies(test, columns = [\"Title\"],drop_first=True)\ntest = pd.get_dummies(test, columns = [\"Embarked\"],drop_first=True, prefix=\"Em\")","3172002b":"test.head()","89d0a132":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","6c088493":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","6003ca27":"train.head()","35d4fbe4":"test.head()","062a1580":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","7927ed68":"x_train.shape","82b5a68a":"x_test.shape","a4a27f06":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","25b472a1":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","0662c5b9":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","600b7fa8":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","52e242e2":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","782b650b":"xgb_cv_model.fit(x_train, y_train)","1cba8437":"xgb_cv_model.best_params_","5e11c9d1":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","ca02cd62":"xgb_tuned =  xgb.fit(x_train,y_train)","14b79074":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","35bd911d":"test","89406c4b":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = randomforest.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","af7a2732":"output.head()","ccc16f39":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","04312b16":"## Analysis and Visualization of Numeric and Categorical Variables","022b32d7":"## Deleting Unnecessary Variables","6959d2ec":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","01d611f7":"### Embarked","aeb5fbe2":"### Visualization","d4b44541":"# Deployment","c4ff7e2b":"### AgeGroup","896780ce":"## Gradient Boosting Classifier","7cfcdccb":"**Variable Notes:**\n\nPclass: A proxy for socio-economic status (SES)\n- 1st = Upper\n- 2nd = Middle\n- 3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","6eb889fe":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","7082fa5b":"### Age","d9d2e76c":"## Logistic Regression","bc30ac2c":"### Fare","cf43cfa5":"# Data Understanding (Exploratory Data Analysis)","df492d1a":"#### Sex vs survived:","fc2d8485":"**Variables and Their Types:**\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton","3d3da093":"## Loading Data","c2bccf16":"## Importing Librarires","bcf1a704":"## Feature Engineering","d84d6a0f":"### Pclass","0f34d2ba":"#### Parch vs survived:","eb9feb7d":"# Modeling, Evaluation and Model Tuning","2747d26b":"## Missing Value Treatment","6b95d03b":"## Spliting the train data","056e6ff8":"# Data Preparation","fd695c3c":"### Fare","6a58c49f":"### Name - Title","ac83239d":"### Embarked & Title","71cc0557":"## Variable Transformation","97b81117":"## Outlier Treatment","f6abf203":"# Business Understanding \/ Problem Definition","bd3213df":"### Family Size","1c7d2ab8":"### Classes of some categorical variables","485b1f45":"## Random Forest","1bd5ee69":"#### SibSp vs survived:","1c66da88":"### Ticket","a08fdd18":"### Basic summary statistics about the numerical data","87ec5f22":"### Embarked","bf15250a":"### Sex","3b3f0141":"#### Pclass vs survived:","96a9e641":"### Cabin"}}