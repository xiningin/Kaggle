{"cell_type":{"cde3de8c":"code","cb0b52a4":"code","ca03b0f0":"code","205071ce":"code","8d9ae4f9":"code","b8ab79b8":"code","e0782cdc":"code","5eae0205":"code","1f028148":"code","25827ba2":"code","7ddd66df":"code","ad177907":"code","d1db1b0f":"code","f6eb42a3":"code","c94849e7":"code","7c029e0f":"code","c3b64c6e":"code","d6bb196d":"code","b17a7e0e":"code","7e84c1cf":"code","c74b0c0a":"code","29cfda53":"code","e2055ed4":"code","fbb1a332":"code","7ef46c45":"code","5915b420":"code","b519bff6":"code","87290802":"code","7ba277ea":"code","790bd61c":"code","a56e00f3":"code","0e537950":"markdown","d4db3c3a":"markdown","b82bdd5a":"markdown","04d9b9d6":"markdown","569cfabd":"markdown","4729761c":"markdown","5a9cef3e":"markdown","bbba955e":"markdown","b906ee3e":"markdown","7b9a73a8":"markdown","6efe0f34":"markdown","4bdf7ae9":"markdown","08d4ef85":"markdown","d676c0ed":"markdown","1d5c8076":"markdown","a35e4cde":"markdown"},"source":{"cde3de8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb0b52a4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score\nfrom sklearn.model_selection import train_test_split","ca03b0f0":"# Load the fake and real news datasets\nfake_news = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/Fake.csv\")\nfake_news[\"fake\"] = 1\n\n# Load the real news \nreal_news = pd.read_csv(\"..\/input\/fake-and-real-news-dataset\/True.csv\")\nreal_news[\"fake\"] = 0\n\n# We will join the two dataframes and create the combined one for modelling\n\nnews = pd.concat([fake_news, real_news])\nnews.head()","205071ce":"# Check for any null values\nnews.isna().sum()","8d9ae4f9":"# Check the data structure\nnews.info()","b8ab79b8":"# Explore the target variable\nsns.countplot(x='fake', data=news)\nprint(\"Distributions...\")\nprint(news['fake'].value_counts())","e0782cdc":"# Explore 2 texts for the fake dataset\nnews[news['fake'] == 1]['text'].head(2)","5eae0205":"# Explore 2 textx for the real news\nnews[news['fake'] == 0]['text'].head(2)","1f028148":"# Explore the Subject column\n\nplt.figure(figsize=(10, 6))\nsns.countplot(x='subject', data=news, hue='fake')","25827ba2":"news['date'] = pd.to_datetime(news['date'], errors='coerce')\nnews['Year'] = news['date'].dt.year\nnews['Month'] = news['date'].dt.month\n\nnews.head()","7ddd66df":"# Check the impact of Year on the target variable\nsns.countplot(x='Year', data=news, hue='fake')","ad177907":"# Check the impact of Month on the target variable\nsns.countplot(x='Month', data=news, hue='fake')","d1db1b0f":"news['text'] = news['title'] + news['text']\nnews.drop(labels=['title'], axis=1, inplace=True)\n\nnews.head()","f6eb42a3":"news.drop(labels=['subject', 'date', 'Year', 'Month'], axis=1, inplace=True)\nnews.head()","c94849e7":"# We will shuffle the dataframe and extract the feature and label\n\nnews = news.sample(frac=1)\nfeature_text = news['text']\ntarget = news['fake']","7c029e0f":"# Perform the split\nfeatures_train, features_test, target_train, target_test = train_test_split(feature_text, target, test_size=0.3, \n                                                                            random_state=101)\n\n# We will further split the training set into validatoion to evaluate the Neural Network training\nfeatures_train, features_val, target_train, target_val = train_test_split(features_train, target_train, test_size=0.3, \n                                                                            random_state=101)\n\nprint(\"Training Features shape: \", features_train.shape)\nprint(\"Training Target shape: \", target_train.shape)\n\nprint(\"Validation Features shape: \", features_val.shape)\nprint(\"Validation Target shape: \", target_val.shape)\n\nprint(\"Test Features shape: \", features_test.shape)\nprint(\"Training Target shape: \", target_test.shape)","c3b64c6e":"# First 10 training samples\nfeatures_train[: 10]","d6bb196d":"# First 10 training classes (target)\ntarget_train[: 10]","b17a7e0e":"# Define some global Model Constants\n\nINPUT_SHAPE = []\n\nOUTPUT_UNITS = 1\nHIDDEN_UNITS_SINGLE = 16\nHIDDEN_UNITS_DEEP = 8\nACTIVATION_HIDDEN = tf.keras.activations.relu\nACTIVATION_OUTPUT = tf.keras.activations.sigmoid\nLEARNING_RATE = 1e-3\nOPTIMIZER = tf.keras.optimizers.Adam(LEARNING_RATE)\nLOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nL2_REGULARIZER = tf.keras.regularizers.L2(0.001)\nDROPOUT_RATE = 0.2\n\nEPOCHS = 3","7e84c1cf":"# Define the Metrics - These are the metrics we will evaluate during training\n\nMETRICS = [tf.keras.metrics.TruePositives(name='tp'),\n          tf.keras.metrics.FalsePositives(name='fp'),\n          tf.keras.metrics.TrueNegatives(name='tn'),\n          tf.keras.metrics.FalseNegatives(name='fn'), \n          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n          tf.keras.metrics.Precision(name='precision'),\n          tf.keras.metrics.Recall(name='recall'),\n          tf.keras.metrics.AUC(name='auc')]","c74b0c0a":"model_embeddings = \"https:\/\/tfhub.dev\/google\/nnlm-en-dim128\/2\"\nhub_layer = hub.KerasLayer(model_embeddings, input_shape=INPUT_SHAPE, dtype=tf.string, trainable=True)\n\n# We will use it in the first two samples and check\nhub_layer(features_train[:2])","29cfda53":"# Defining a function which will build and compile the model\n\n'''\nThis will build and compile a model with one hidden layer and 16 neurons\n'''\ndef make_model(metrics=METRICS, output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    model = tf.keras.Sequential()\n    model.add(hub_layer)\n    model.add(tf.keras.layers.Dense(units=HIDDEN_UNITS_SINGLE, activation=ACTIVATION_HIDDEN))\n    model.add(tf.keras.layers.Dense(units=OUTPUT_UNITS, activation=ACTIVATION_OUTPUT))\n    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=metrics)\n    return model","e2055ed4":"# Defining a function to plot training loss vs validation loss\n\n'''\nThis function will take a epoch model from training a neural network\nWill plot training loss vs validation loss\n'''\n\ndef plotTrainLossVsValLoss(epochs_history):\n    plt.figure(figsize=(12, 8))\n    loss_train = epochs_history.history['loss']\n    loss_val = epochs_history.history['val_loss']\n\n    plt.figure(figsize=(12, 8))\n\n    loss_train = epochs_history.history['loss']\n    loss_val = epochs_history.history['val_loss']\n\n    epochs = range(1, (EPOCHS + 1))\n    plt.plot(epochs, loss_train, 'g', label='Training loss')\n    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n    plt.title('Training Loss vs Validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    plt.show()","fbb1a332":"# Defining a function to plot training accuracy vs validation accuracy\n\n'''\nThis function will take a epoch model from training a neural network\nWill plot training accuracy vs validation accuracy\n'''\n\ndef plotTrainAccuracyVsValAccuracy(epochs_history):\n    plt.figure(figsize=(12, 8))\n\n    loss_train = epochs_history.history['accuracy']\n    loss_val = epochs_history.history['val_accuracy']\n\n    epochs = range(1, (EPOCHS + 1))\n    plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n    plt.plot(epochs, loss_val, 'b', label='Validation Accuracy')\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    plt.show()","7ef46c45":"# Defining a function to plot the confusion matrix\n# Let us visualize the Confusion Matrix and detail out some key metrices including classification report\n\n'''\nThis function will plot the confusion matrix \nThis will also display various performance metrices\n'''\ndef plot_cm(labels, predictions, threshold=0.5):\n    cm = confusion_matrix(labels, predictions > threshold)\n    plt.figure(figsize=(5, 5))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title(\"Confusion Matrix %0.2f\" %threshold)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"Actual Label\")\n    \n    print('True Negatives: ', cm[0][0])\n    print('Incorrectly Detected (False Positives): ', cm[0][1])\n    print('Missed (False Negatives): ', cm[1][0])\n    print('True Positives: ', cm[1][1])\n    print('Total Transactions: ', np.sum(cm[1]))\n    print(\"\\n\")\n    print(\"F1-Score\")\n    print(f1_score(target_test, target_predictions > 0.5))\n    print(\"\\n\")\n    print(\"Accuracy Score\")\n    print(accuracy_score(target_test, target_predictions > threshold))\n    print(\"\\n\")\n    print(\"Classification Report\")\n    print(classification_report(target_test, target_predictions > 0.5))","5915b420":"# Lets build the model and see the mmodel summary\n\nsimplemodel = make_model()\nsimplemodel.summary()","b519bff6":"# we will now train the model on training and validation data\n# Now use the function to plot the confusion matrix\n\nstart = datetime.now()\nepochs_history_simple = simplemodel.fit(features_train, target_train, epochs=EPOCHS,\n                          validation_data=(features_val, target_val),\n                          verbose=1)\nend = datetime.now()\nprint(f\"The training of simple model completed in time - {end - start}\")","87290802":"# Plot training loss vs validation loss\nplotTrainLossVsValLoss(epochs_history=epochs_history_simple)","7ba277ea":"# Plot Training accuracy vs Validation accuracy\nplotTrainAccuracyVsValAccuracy(epochs_history=epochs_history_simple)","790bd61c":"# Let us run the predictions\ntarget_predictions = simplemodel.predict(features_test)","a56e00f3":"# Now use the function to plot the confusion matrix\nplot_cm (target_test, target_predictions)","0e537950":"#### In order to perform text processing, we would be using a pre-trained embedding layer from tensorflow-hub\nWe will create a Keras Layer that uses tensorflow hub model to embed sentences\n\n#### The first layer is a TensorFlow Hub layer. This layer uses a pre-trained Saved Model to map a sentence into its embedding vector. The model that we are using (google\/nnlm-en-dim128\/2) splits the sentence into tokens, embeds each token and then combines the embedding.","d4db3c3a":"### Build and Compile the Model","b82bdd5a":"All news in the year 2015 in the dataset is a fake news. So this attribute has a level which perfectly distributes the target variable.","04d9b9d6":"## Load the dataset and validate the data load\n\nWe will load the individual dataset, create a target attribute which will indicate 1 if the news is fake. Combine both the dataframes and create the combined dataframe for modelling","569cfabd":"## Library imports","4729761c":"## Preparing the final data\n\nWe will remove the subject attribute - Since it perfectly distributes the target variable\nWe will remove the Year attribute - This also has a clear division for the target variable\nWe will remove the Month Attribute - This also has a very clear approach of demarcating the target variable\n\nFor now we will just go ahead with the \"text attribute\"","5a9cef3e":"## Feature Engineering","bbba955e":"#### We will create a new columns called Month and Year from Date and analyse whether fake or real news has some correlation with Month or Year in the timeline","b906ee3e":"This shows an interesting pattern - The number of fake news is higher till month 8, post which the number of real news increases drastically. Which essentially means if the month is <= 8, the probability of fake news is higher. ","7b9a73a8":"## Train-Test Split","6efe0f34":"#### We will combine the title and text column","4bdf7ae9":"### Model Validation","08d4ef85":"## Exploratory Data Analysis and Data Visualizations","d676c0ed":"### Check Performance Graphs","1d5c8076":"### Define the Model Evaluation Metrics","a35e4cde":"## Build and Train the Neural Network Model"}}