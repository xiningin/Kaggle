{"cell_type":{"8fa08b71":"code","8ac9e9eb":"code","13c8dd73":"code","7cf87c4e":"code","043494c8":"code","43cf7c13":"code","3adcd9e1":"code","f8c543d8":"code","d3d1a218":"code","94871308":"code","2208bd1a":"code","d3a165fc":"code","03d268e9":"code","52484b2f":"code","a2702bcc":"code","488e57fe":"code","dedcfb21":"code","4f8b07ff":"code","bea35441":"markdown","977e696c":"markdown","32f57b9c":"markdown","26d8e8de":"markdown","0e881703":"markdown","c36d6909":"markdown","96f8089d":"markdown"},"source":{"8fa08b71":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\nimport random\n\nimport os","8ac9e9eb":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","13c8dd73":"data = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndata.head()","7cf87c4e":"data.info()","043494c8":"data.describe()","43cf7c13":"data.drop(columns = ['Id'], axis = 1, inplace = True)\ndata.head()","3adcd9e1":"sns.pairplot(data, hue = 'Species', height = 5)\nplt.show()","f8c543d8":"X = data.drop(['Species'], axis = 1)\ny = data['Species']","d3d1a218":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)","94871308":"y[:5]","2208bd1a":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","d3a165fc":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 0)\n\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","03d268e9":"import tensorflow as tf\ntf.__version__","52484b2f":"# let's build a model to find patterns in it\n\n# Set random seed\ntf.random.set_seed(42)\n\n# 1. Create a model\nmodel_1 = tf.keras.Sequential([\n           tf.keras.layers.Dense(3, activation='relu'),\n           tf.keras.layers.Dense(5, activation='relu'),\n           tf.keras.layers.Dense(3, activation='softmax')\n])\n\n# 2. Comile the model\nmodel_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n                 metrics=['accuracy'])\n\n# 3. Fit the model\nhistory = model_1.fit(X_train, \n                      tf.one_hot(y_train, depth=3), \n                      epochs=100,\n                      verbose = 1)","a2702bcc":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.0, 1.0])\nplt.legend(loc='lower right');","488e57fe":"plt.plot(history.history['loss'], label='loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0.0, 1])\nplt.legend(loc='upper right');","dedcfb21":"model_1.evaluate(X_test, tf.one_hot(y_test, depth=3))[1] * 100","4f8b07ff":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nplt.figure(figsize=(15, 10))\nsns.heatmap(confusion_matrix(y_true=y_test, \n                 y_pred=model_1.predict(X_test).argmax(axis=1)), annot=True,\n                 fmt=\"d\");","bea35441":"# Encoding the Categories for the Label","977e696c":"## Multivariate Analysis\nIt refers to an analysis involving multiple dependent variables resulting in one outcome. Creating different graphs for all the features to perform bivariate analysis would be extremely tedious. Seaborn provides a convenient way to perform multivariate analysis using the pairplot function.","32f57b9c":"# Split labels from Data","26d8e8de":"# Import TensorFlow","0e881703":"## Mustafa Mohammed Kataa\n\n# Import Packages\nLets load all the needed packages for this notebook:","c36d6909":"## Removing the Id column from our dataset as it is not needed","96f8089d":"# The Dataset\nFor this notebook we will use the Iris competition dataset.\n\nLet's define the path to the dataset:"}}