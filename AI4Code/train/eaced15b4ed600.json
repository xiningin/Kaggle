{"cell_type":{"c77bd6db":"code","a36f37b7":"code","656d5614":"code","598c7a05":"code","51c9acbb":"code","4d6ad035":"code","935e0177":"code","3f4ec3bd":"code","92480ab4":"code","303e4378":"code","60378feb":"code","0dd25cef":"code","113816b6":"code","62792b50":"code","ea699fe9":"code","30cf18f2":"code","111b8e60":"code","8e213d33":"code","1fb5bec9":"markdown","39c038b3":"markdown","5b292bd7":"markdown","a7c1e6d9":"markdown","09c93427":"markdown","de9ce133":"markdown"},"source":{"c77bd6db":"import time\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb","a36f37b7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","656d5614":"train = pd.read_csv('\/kaggle\/input\/demand-forecasting-kernels-only\/train.csv', parse_dates=['date'])\ntest = pd.read_csv('\/kaggle\/input\/demand-forecasting-kernels-only\/test.csv', parse_dates=['date'])\nsample_sub = pd.read_csv('\/kaggle\/input\/demand-forecasting-kernels-only\/sample_submission.csv')\ndf = pd.concat([train, test], sort=False)","598c7a05":"train.head(2),test.head(2),sample_sub.head(2), df.head(2)","51c9acbb":"df['month'] = df.date.dt.month\ndf.loc[(df[\"month\"] >= 1) & (df[\"month\"] < 4), \"quantile_of_year\"] = 1\ndf.loc[(df[\"month\"] >= 4) & (df[\"month\"] < 7), \"quantile_of_year\"] = 2\ndf.loc[(df[\"month\"] >= 7) & (df[\"month\"] < 10), \"quantile_of_year\"] = 3\ndf.loc[(df[\"month\"] >= 10) & (df[\"month\"] < 13), \"quantile_of_year\"] = 4\ndf['day_of_month'] = df.date.dt.day\ndf.loc[(df[\"day_of_month\"] >= 1) & (df[\"day_of_month\"] < 8), \"first_week\"] = 1\ndf[\"first_week\"].fillna(0)\ndf['day_of_year'] = df.date.dt.dayofyear\ndf['week_of_year'] = df.date.dt.weekofyear\ndf['day_of_week'] = df.date.dt.dayofweek+1\ndf['year'] = df.date.dt.year\ndf[\"is_wknd\"] = df.date.dt.weekday \/\/ 4\ndf['is_month_start'] = df.date.dt.is_month_start.astype(int)\ndf['is_month_end'] = df.date.dt.is_month_end.astype(int)\ndf.head(2)","4d6ad035":"df.sort_values(by=['store', 'item', 'date'], axis=0, inplace=True)\ndef random_noise(dataframe):\n    return np.random.normal(scale=1.6, size=(len(dataframe)))\ndef lag_features(dataframe, lags):\n    for lag in lags:\n        dataframe['sales_lag_' + str(lag)] = dataframe.groupby([\"store\", \"item\"])['sales'].transform(\n            lambda x: x.shift(lag)) + random_noise(dataframe)\n    return dataframe\ndf = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 546, 728])","935e0177":"def roll_mean_features(dataframe, windows):\n    for window in windows:\n        dataframe['sales_roll_mean_' + str(window)] = dataframe.groupby([\"store\", \"item\"])['sales']. \\\n                                                          transform(\n            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n            dataframe)\n    return dataframe\ndf = roll_mean_features(df, [182, 365, 546])","3f4ec3bd":"def ewm_features(dataframe, alphas, lags):\n    for alpha in alphas:\n        for lag in lags:\n            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n                dataframe.groupby([\"store\", \"item\"])['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n    return dataframe\nalphas = [0.95, 0.9, 0.8, 0.7, 0.5]\nlags = [91, 98, 105, 112, 180, 270, 365, 546, 728]\ndf = ewm_features(df, alphas, lags)","92480ab4":"df = pd.get_dummies(df, columns=['store', 'item', 'day_of_week', 'month'])","303e4378":"df['sales'] = np.log1p(df[\"sales\"].values)","60378feb":"def smape(preds, target):\n    n = len(preds)\n    masked_arr = ~((preds == 0) & (target == 0))\n    preds, target = preds[masked_arr], target[masked_arr]\n    num = np.abs(preds - target)\n    denom = np.abs(preds) + np.abs(target)\n    smape_val = (200 * np.sum(num \/ denom)) \/ n\n    return smape_val\ndef lgbm_smape(preds, train_data):\n    labels = train_data.get_label()\n    smape_val = smape(np.expm1(preds), np.expm1(labels))\n    return 'SMAPE', smape_val, False","0dd25cef":"train = df.loc[(df[\"date\"] < \"2017-01-01\"), :]\nval = df.loc[(df[\"date\"] >= \"2017-01-01\") & (df[\"date\"] < \"2017-04-01\"), :]\ncols = [col for col in train.columns if col not in ['date', 'id', \"sales\", \"year\"]]\nY_train = train['sales']\nX_train = train[cols]\nY_val = val['sales']\nX_val = val[cols]","113816b6":"lgb_params = {'metric': {'mae'},\n              'num_leaves': 10, # maksimum yaprak say\u0131s\u0131\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8, # rf'nin random subspace \u00f6zelli\u011fi\n              'max_depth': 5,\n              'verbose': 0,\n              'num_boost_round': 20000, # n_estimators, number of boosting iterations\n              'early_stopping_rounds': 200, # 200 iterasyon boyunca hata de\u011feri k\u00fc\u00e7\u00fclm\u00fcyorsa, durdur, k\u00fc\u00e7\u00fcl\u00fcyorsa num_boost_round miktar\u0131 kadar devam et\n              'nthread': -1}\nlgbtrain = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\nlgbval = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain, feature_name=cols)","62792b50":"model = lgb.train(lgb_params, lgbtrain,\n                  valid_sets=[lgbtrain, lgbval],\n                  num_boost_round=lgb_params['num_boost_round'],\n                  early_stopping_rounds=lgb_params['early_stopping_rounds'],\n                  feval=lgbm_smape,\n                  verbose_eval=200)","ea699fe9":"y_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\nsmape(np.expm1(y_pred_val), np.expm1(Y_val))","30cf18f2":"train = df.loc[~df.sales.isna()]\nY_train = train['sales']\nX_train = train[cols]\ntest = df.loc[df.sales.isna()]\nX_test = test[cols]","111b8e60":"lgb_params = {'metric': {'mae'},\n              'num_leaves': 10,\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'nthread': -1,\n              \"num_boost_round\": model.best_iteration}\n\n\nlgbtrain_all = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\nmodel = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model.best_iteration)\ntest_preds = model.predict(X_test, num_iteration=model.best_iteration)","8e213d33":"submission_df = test.loc[:, ['id', 'sales']]\nsubmission_df['sales'] = np.expm1(test_preds)\nsubmission_df['id'] = submission_df.id.astype(int)\nsubmission_df.to_csv('submission.csv', index=False)","1fb5bec9":"# Encoding","39c038b3":"# Exponentially Weighted Mean Features","5b292bd7":"# Date Features","a7c1e6d9":"# Lag\/Shifted Features","09c93427":"# Rolling Mean Features","de9ce133":"# Scaling"}}