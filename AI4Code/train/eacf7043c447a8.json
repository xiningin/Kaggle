{"cell_type":{"a6f5eb6d":"code","4e96e9d2":"code","5a02ed42":"code","dbdb6426":"code","266c6b67":"code","6d77e0c2":"code","7cfc7a8d":"code","fc92f3c0":"code","73520497":"code","341a1ca4":"code","78e6a060":"code","f978e1dc":"code","0cc45ea9":"code","56e31b3c":"code","361aa967":"code","42917727":"code","a12bd440":"code","76eb142c":"code","febd30e3":"code","1faed721":"code","9d930c62":"code","b4a396cb":"code","7caeee26":"code","901e09c9":"code","44b1d5f4":"code","139cd2a3":"code","383aa637":"code","2c68c7c9":"code","168e8bd8":"code","86450abe":"code","a737a93e":"code","87b3289b":"code","798af579":"code","746299f7":"code","bd860a57":"code","d703974b":"code","1c4c12c7":"code","e72b0741":"code","20ad3fb4":"code","cda98f5a":"code","92befb75":"code","afa6aa0f":"code","edfdb48f":"code","009b3c3a":"code","ec0b03c3":"code","625c4c5c":"code","2f664d9f":"code","c11b6d34":"code","9d88fc90":"code","b2a0fb39":"code","624b840e":"code","6c3da491":"code","93ad12fb":"code","5b984f71":"code","0942e87d":"code","9729e1e4":"code","860e5bee":"markdown","b6f87273":"markdown","1b7a7429":"markdown","8a4bd7c9":"markdown","d4541b45":"markdown","fc06f798":"markdown","36e49e17":"markdown","36627f54":"markdown","74e252cc":"markdown","13c86771":"markdown","58f50c2c":"markdown","7f6b5d60":"markdown","701cb90e":"markdown","017bda82":"markdown","e0cf36e8":"markdown","df6fa843":"markdown","37fbe011":"markdown","372f9110":"markdown","a017b98e":"markdown","d7d096e8":"markdown","18a1dde9":"markdown","d7107be3":"markdown","c4bd1520":"markdown","bdf18f60":"markdown","4ac2b8b1":"markdown","e848a1e9":"markdown","7e8fae17":"markdown","f4a24f81":"markdown","ccb5ee70":"markdown","54b340be":"markdown","590d6a83":"markdown","32bc3cb4":"markdown","7d66520d":"markdown","59360f21":"markdown"},"source":{"a6f5eb6d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4e96e9d2":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error","5a02ed42":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dbdb6426":"\nimport requests\nimport pandas as pd\nimport io\n\nBASE_URL = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/'\nCONFIRMED = 'time_series_covid19_confirmed_global.csv'\nDEATH = 'time_series_covid19_deaths_global.csv'\nRECOVERED = 'time_series_covid19_recovered_global.csv'\nCONFIRMED_US = 'time_series_covid19_confirmed_US.csv'\nDEATH_US = 'time_series_covid19_deaths_US.csv'\n\ndef get_covid_data(subset = 'CONFIRMED'):\n    \"\"\"This function returns the latest available data subset of COVID-19. \n        The returned value is in pandas DataFrame type.\n    Args:\n        subset (:obj:`str`, optional): Any value out of 5 subsets of 'CONFIRMED',\n        'DEATH', 'RECOVERED', 'CONFIRMED_US' and 'DEATH_US' is a valid input. If the value\n        is not chosen or typed wrongly, CONFIRMED subet will be returned.\n    \"\"\"    \n    switcher =  {\n                'CONFIRMED'     : BASE_URL + CONFIRMED,\n                'DEATH'         : BASE_URL + DEATH,\n                'RECOVERED'     : BASE_URL + RECOVERED,\n                'CONFIRMED_US'  : BASE_URL + CONFIRMED_US,\n                'DEATH_US'      : BASE_URL + DEATH_US,\n                \n                }\n\n    CSV_URL = switcher.get(subset, BASE_URL + CONFIRMED)\n\n    with requests.Session() as s:\n        download        = s.get(CSV_URL)\n        decoded_content = download.content.decode('utf-8')\n        data            = pd.read_csv(io.StringIO(decoded_content))\n\n    return data","266c6b67":"deaths=get_covid_data(subset = 'DEATH') # global deaths\nconfirmed_cases=get_covid_data(subset = 'CONFIRMED')# confirmed cases","6d77e0c2":"countries=['Brazil', 'Canada', 'Germany','US','Spain','Italy']\ny=confirmed_cases.loc[confirmed_cases['Country\/Region']=='Italy'].iloc[0,4:]\ns = pd.DataFrame({'Italy':y})\nfor c in countries:    \n    s[c] = confirmed_cases.loc[confirmed_cases['Country\/Region']==c].iloc[0,4:]\n    plt.plot(range(y.shape[0]),s[c],label=c)#    print(s[c])\nplt.title('Total Number of Confirmed Cases from 1\/22\/20')\nplt.xlabel('Day')\nplt.ylabel('Number of Cases')\nplt.legend(loc=\"best\")\nplt.show()","7cfc7a8d":"dates=confirmed_cases.columns.values.tolist()\ndates=dates[4:]","fc92f3c0":"country_list=confirmed_cases['Country\/Region'].unique()\nconfirmed = pd.DataFrame({'Italy':y})\ndict={}\na=[]\nb=[]\n\nfor c in country_list:\n    a.append(c)\n    confirmed=( confirmed_cases.loc[confirmed_cases['Country\/Region']==c].iloc[:,4:].sum(axis=0))\n    b.append(confirmed[y.shape[0]-1])  \n    dict[c]=confirmed[y.shape[0]-1]","73520497":"import matplotlib.pyplot as plt\n\nf = plt.figure(figsize=(90,40))\nf.add_subplot(111)\n\nbarWidth=1\nplt.axes(axisbelow=True)\n#langs = ['C', 'C++', 'Java', 'Python', 'PHP']\n#students = [23,17,35,29,12]\nplt.bar(a,b,linewidth=17.0)\n\nplt.xlabel(\"Countries \",fontsize=45)\nplt.ylabel(\"Number of cases \",fontsize=45)\nplt.title(\"Confirmed cases of all countries around the world\",fontsize=60)\nplt.grid(alpha=0.3)\nplt.tick_params(size=5,labelsize = 30,rotation=90)\nplt.show()","341a1ca4":"plt.figure(figsize=(15, 8))\ncanada = confirmed_cases.loc[confirmed_cases['Country\/Region']=='Canada'].iloc[:,4:].sum(axis=0)\ncanada.tail()\ncanada.plot(label='Canada')\nplt.legend()\nplt.title(\"Number of confirmed cases in Canada\")\nplt.xlabel(\"Dates \",fontsize=15)\nplt.ylabel(\"Number of deaths \",fontsize=15)\nplt.show()","78e6a060":"CAN = confirmed_cases[confirmed_cases['Country\/Region']=='Canada']\n\nCAN = pd.DataFrame(CAN.iloc[0,4:-2])\n\ndef plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n\n    rolling_mean = series.rolling(window=window).mean()\n    \n    plt.figure(figsize=(20,8))\n    plt.title('Moving average\\n window size = {}'.format(window))\n    plt.plot(rolling_mean, 'g', label='Rolling mean trend')\n    \n    #Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bound = rolling_mean - (mae + scale * deviation)\n        upper_bound = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bound, 'r--', label='Upper bound \/ Lower bound')\n        plt.plot(lower_bound, 'r--')\n        \n            \n    plt.plot(series[window:], label='Actual values')\n    plt.legend(loc='best')\n    plt.xticks(rotation=90)\n    plt.grid(True)\n\n#Smooth by the previous 5 days (by week)\nplot_moving_average(CAN, 5)","f978e1dc":"plot_moving_average(CAN, 30, plot_intervals=True)","0cc45ea9":"c=[]\nfor i in dates:\n  c= confirmed_cases.iloc[:,4:].sum(axis=0)\n  ","56e31b3c":"\n\ndf = pd.DataFrame(columns=['ds','y'])\ndf\ndf['ds'] = pd.to_datetime(dates)\nfor  j in range(0,len(c)):\n  df['y'][j]=pd.to_numeric(c[j])\n","361aa967":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport datetime\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, BayesianRidge","42917727":"X = np.array([i for i in range(len(dates))]).reshape(-1, 1)\nY = np.array(c).reshape(-1, 1)","a12bd440":"days_in_future = 15 #next 2 weeks\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-15]\nstart = '1\/22\/2020'\nstart_date = datetime.datetime.strptime(start, '%m\/%d\/%Y')\nfuture_forcast_dates = []\nfor i in range(len(future_forcast)):\n    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%m\/%d\/%Y'))\n    \nX_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(X, Y, test_size=0.10, shuffle=False)","76eb142c":"# svm_confirmed = svm_search.best_estimator_\nsvm_confirmed = SVR(C=1,degree=5,kernel='poly',epsilon=0.01)\nsvm_confirmed.fit(X_train_confirmed, y_train_confirmed)\nsvm_pred = svm_confirmed.predict(future_forcast)","febd30e3":"# check against testing data\nsvm_test_pred = svm_confirmed.predict(X_test_confirmed)\nplt.plot(y_test_confirmed)\nplt.plot(svm_test_pred)\nplt.legend(['Test Data', 'SVM Predictions'])\nprint('MAE:', mean_absolute_error(svm_test_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(svm_test_pred, y_test_confirmed))","1faed721":"\npoly = PolynomialFeatures(degree=3)\npoly_X_train_confirmed = poly.fit_transform(X_train_confirmed)\npoly_X_test_confirmed = poly.fit_transform(X_test_confirmed)\npoly_future_forcast = poly.fit_transform(future_forcast)\n\nbayesian_poly = PolynomialFeatures(degree=4)\nbayesian_poly_X_train_confirmed = bayesian_poly.fit_transform(X_train_confirmed)\nbayesian_poly_X_test_confirmed = bayesian_poly.fit_transform(X_test_confirmed)\nbayesian_poly_future_forcast = bayesian_poly.fit_transform(future_forcast)","9d930c62":"linear_model = LinearRegression(normalize=True, fit_intercept=True)\nlinear_model.fit(poly_X_train_confirmed, y_train_confirmed)\ntest_linear_pred = linear_model.predict(poly_X_test_confirmed)\nlinear_pred = linear_model.predict(poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_linear_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(test_linear_pred, y_test_confirmed))","b4a396cb":"\nprint(linear_model.coef_)","7caeee26":"plt.plot(y_test_confirmed)\nplt.plot(test_linear_pred)\nplt.legend(['Test Data', 'Polynomial Regression Predictions'])","901e09c9":"# bayesian ridge polynomial regression\ntol = [1e-4, 1e-3, 1e-2]\nalpha_1 = [1e-7, 1e-6, 1e-5, 1e-4]\nalpha_2 = [1e-7, 1e-6, 1e-5, 1e-4]\nlambda_1 = [1e-7, 1e-6, 1e-5, 1e-4]\nlambda_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n\nbayesian_grid = {'tol': tol, 'alpha_1': alpha_1, 'alpha_2' : alpha_2, 'lambda_1': lambda_1, 'lambda_2' : lambda_2}\n\nbayesian = BayesianRidge(fit_intercept=False, normalize=True)\nbayesian_search = RandomizedSearchCV(bayesian, bayesian_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\nbayesian_search.fit(bayesian_poly_X_train_confirmed, y_train_confirmed)","44b1d5f4":"bayesian_search.best_params_","139cd2a3":"bayesian_confirmed = bayesian_search.best_estimator_\ntest_bayesian_pred = bayesian_confirmed.predict(bayesian_poly_X_test_confirmed)\nbayesian_pred = bayesian_confirmed.predict(bayesian_poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_bayesian_pred, y_test_confirmed))\nprint('MSE:',mean_squared_error(test_bayesian_pred, y_test_confirmed))","383aa637":"plt.plot(y_test_confirmed)\nplt.plot(test_bayesian_pred)\nplt.legend(['Test Data', 'Bayesian Ridge Polynomial Predictions'])","2c68c7c9":"def plot_predictions(x, y, pred, algo_name, color):\n    plt.figure(figsize=(7, 5))\n    plt.plot(x, y)\n    plt.plot(future_forcast, pred, linestyle='dashed', color=color)\n    plt.title('Growth of Confirmed Cases Over Time', size=15)\n    plt.xlabel('Days Since 1\/22\/2020', size=15)\n    plt.ylabel('Number of Cases', size=15)\n    plt.legend(['Confirmed Cases', algo_name], prop={'size': 15})\n    plt.xticks(size=10)\n    plt.yticks(size=10)\n    plt.show()\n","168e8bd8":"plot_predictions(adjusted_dates, c, svm_pred, 'SVM Predictions', 'purple')","86450abe":"plot_predictions(adjusted_dates, c, linear_pred, 'Polynomial Regression Predictions', 'orange')","a737a93e":"plot_predictions(adjusted_dates, c, bayesian_pred, 'Bayesian Ridge Regression Predictions', 'green')","87b3289b":"\nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'SVM Prediction of Confirmed Cases Worldwide': np.round(svm_pred[-10:])})\nsvm_df","798af579":"# \nlinear_pred = linear_pred.reshape(1,-1)[0]\nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'Polynomial Prediction of Confirmed Cases Worldwide': np.round(linear_pred[-10:])})\nsvm_df","746299f7":"#  \nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'Bayesian Ridge Prediction of Confirmed Cases Worldwide': np.round(bayesian_pred[-10:])})\nsvm_df","bd860a57":"from fbprophet import Prophet","d703974b":"m = Prophet(interval_width=0.95)\nm.fit(df)\nfuture = m.make_future_dataframe(periods=7)\nfuture_confirmed = future.copy() # for non-baseline predictions later on\nfuture.tail()","1c4c12c7":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","e72b0741":"confirmed_forecast_plot = m.plot(forecast)","20ad3fb4":"forecast_components = m.plot_components(forecast)","cda98f5a":"import torch\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import register_matplotlib_converters\nfrom torch import nn, optim\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 14, 10\nregister_matplotlib_converters()\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","92befb75":"c=[]\nworld_cases = []\nY=[]\nfor i in dates:\n  c= confirmed_cases.iloc[:,4:].sum(axis=0)\ndaily_cases=c.copy()\ndaily_cases.head()","afa6aa0f":"plt.figure(figsize=(30, 15))\nplt.plot(daily_cases)\nplt.title(\"Cumulative daily cases\");\nplt.tick_params(size=15,labelsize = 15,rotation=90)\nplt.show()","edfdb48f":"daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)\ndaily_cases.head","009b3c3a":"plt.figure(figsize=(30, 15))\nplt.plot(daily_cases)\nplt.title(\"Daily cases\");\nplt.tick_params(size=15,labelsize = 15,rotation=90)\nplt.show()","ec0b03c3":"test_data_size = 14\n\ntrain_data = daily_cases[:-test_data_size]\ntest_data = daily_cases[-test_data_size:]\n\ntrain_data.shape","625c4c5c":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(train_data, axis=1))\n\ntrain_data = scaler.transform(np.expand_dims(train_data, axis=1))\n\ntest_data = scaler.transform(np.expand_dims(test_data, axis=1))","2f664d9f":"def create_sequences(data, seq_length):\n    xs = []\n    ys = []\n\n    for i in range(len(data)-seq_length-1):\n        x = data[i:(i+seq_length)]\n        y = data[i+seq_length]\n        xs.append(x)\n        ys.append(y)\n\n    return np.array(xs), np.array(ys)\nseq_length = 5\nX_train, y_train = create_sequences(train_data, seq_length)\nX_test, y_test = create_sequences(test_data, seq_length)\n\nX_train = torch.from_numpy(X_train).float()\ny_train = torch.from_numpy(y_train).float()\n\nX_test = torch.from_numpy(X_test).float()\ny_test = torch.from_numpy(y_test).float()","c11b6d34":"class CoronaVirusPredictor(nn.Module):\n\n  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n    super(CoronaVirusPredictor, self).__init__()\n\n    self.n_hidden = n_hidden\n    self.seq_len = seq_len\n    self.n_layers = n_layers\n\n    self.lstm = nn.LSTM(\n      input_size=n_features,\n      hidden_size=n_hidden,\n      num_layers=n_layers,\n      dropout=0.5\n    )\n    self.rnn = nn.RNN( input_size=n_features, hidden_size=n_hidden,  num_layers=n_layers, batch_first=True, nonlinearity='relu')\n \n\n    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n\n  def reset_hidden_state(self):\n    self.hidden = (\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n    )\n\n  def forward(self, sequences):\n    \n    lstm_out, self.hidden = self.lstm(\n      sequences.view(len(sequences), self.seq_len, -1),\n      self.hidden\n    )\n    last_time_step = \\\n      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n    y_pred = self.linear(last_time_step)\n    return y_pred","9d88fc90":"def train_model(\n  model,\n  train_data,\n  train_labels,\n  test_data=None,\n  test_labels=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 100\n\n  train_hist = np.zeros(num_epochs)\n  test_hist = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred = model(X_train)\n\n    loss = loss_fn(y_pred.float(), y_train)\n\n    if test_data is not None:\n      with torch.no_grad():\n        y_test_pred = model(X_test)\n        test_loss = loss_fn(y_test_pred.float(), y_test)\n      test_hist[t] = test_loss.item()\n\n      if t % 10 == 0:\n        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n    elif t % 10 == 0:\n      print(f'Epoch {t} train loss: {loss.item()}')\n\n    train_hist[t] = loss.item()\n\n    optimiser.zero_grad()\n\n    loss.backward()\n\n    optimiser.step()\n\n  return model.eval(), train_hist, test_hist","b2a0fb39":"model = CoronaVirusPredictor(\n  n_features=1,\n  n_hidden=32,\n  seq_len=seq_length,\n  n_layers=2\n)\nmodel, train_hist, test_hist = train_model(\n  model,\n  X_train,\n  y_train,\n  X_test,\n  y_test\n)","624b840e":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(daily_cases, axis=1))\n\nall_data = scaler.transform(np.expand_dims(daily_cases, axis=1))\n\nall_data.shape","6c3da491":"X_all, y_all = create_sequences(all_data, seq_length)\n\nX_all = torch.from_numpy(X_all).float()\ny_all = torch.from_numpy(y_all).float()\n\nmodel = CoronaVirusPredictor(\n  n_features=1,\n  n_hidden=512,\n  seq_len=seq_length,\n  n_layers=2\n)\nmodel, train_hist, _ = train_model(model, X_all, y_all)\n","93ad12fb":"DAYS_TO_PREDICT = 12\n\nwith torch.no_grad():\n  test_seq = X_all[:1]\n  preds = []\n  for _ in range(DAYS_TO_PREDICT):\n    y_test_pred = model(test_seq)\n    pred = torch.flatten(y_test_pred).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()","5b984f71":"predicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","0942e87d":"daily_cases.index[-1]\npredicted_index = pd.date_range(\n  start=daily_cases.index[-1],\n  periods=DAYS_TO_PREDICT + 1,\n  closed='right'\n)\n\npredicted_cases = pd.Series(\n  data=predicted_cases,\n  index=predicted_index\n)\n\nplt.plot(predicted_cases, label='Predicted Daily Cases')\nplt.legend();","9729e1e4":"predicted_cases","860e5bee":"***References***\n1. https:\/\/facebook.github.io\/prophet\/\n2. https:\/\/facebook.github.io\/prophet\/docs\/\n3. https:\/\/github.com\/facebook\/prophet\n ","b6f87273":"Building a model","1b7a7429":"Forecasting Confirmed Cases Worldwide with Prophet (Baseline)  \nWe perform a week's ahead forecast with Prophet, with 95% prediction intervals. Here, no tweaking of seasonality-related parameters and additional regressors are performed.\n","8a4bd7c9":"Prediction via Bayesian Ridge Regression","d4541b45":"**DATA EXPLORATION AND PLOTTING**","fc06f798":"Currently, we have a big sequence of daily cases. We\u2019ll convert it into smaller ones","36e49e17":"World wide growth of cases","36627f54":"**Future forcasting**","74e252cc":"# Analysis and Prediction of Daily Global Confirmed Cases","13c86771":"Future predictions using polynomial regression","58f50c2c":"Analysis using RNN via PyTorch","7f6b5d60":"Model for predicting confirmed cases\n\n1. Support vector machines","701cb90e":"Preprocessing","017bda82":"**ANALYSIS AND TRAINING OF DATA**","e0cf36e8":"Testing on available data","df6fa843":"By  \nZahra Jalia (20858708)  \nAnnanya Panda (20861832)  \nGroup Name:- A-Z  \nGroup No:- 48","37fbe011":"Growth of cases in Brazil, Canada, Germany, US, Spain, Italy from 1\/22\/20","372f9110":"**Predictions **","a017b98e":"Prediction via Polynomial Regression","d7d096e8":"Training","18a1dde9":"Growth of cases in Canada","d7107be3":"2. Linear regression","c4bd1520":"**Using prophet for automate future forecasting and predictions**","bdf18f60":"Thanks to Mehdi Afshari for providing the latest data.","4ac2b8b1":"Future predictions using SVM ","e848a1e9":"Moving Average","7e8fae17":"Predicting future cases","f4a24f81":"3. Bayesian ridge polynomial regression ","ccb5ee70":"Transforming our data for polynomial regression","54b340be":"***Prophet***  \nWe use Prophet, a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well. It is also an open source software released by Facebook\u2019s Core Data Science team. It is available for download on CRAN and PyPI.\n\n","590d6a83":"***Why Prophet?***  \nProphet is easy to customize and use, and to produce accurate forecasts which can be explained intuitively with supporting evidence such as forecast seasonality components. It allows the analyst to explain in an intuitive and convinving manner to higher management as to why the forecasts are as such, and the plausible underlying factors that contribute to its result. Furthermore, it is also open-source! :)\n\n","32bc3cb4":"Use all data for training to predict future cases","7d66520d":"Prediction via SVM","59360f21":"Future predictions using Bayesian Ridge"}}