{"cell_type":{"3da6782d":"code","e4044db9":"code","cb994392":"code","f3ef9d81":"code","e0f8e36a":"code","4e2314c0":"code","85a6fbe7":"code","f68c1b78":"code","64f750c2":"code","20cd8fb0":"code","6a178f27":"code","4d99b255":"code","f921baa8":"code","fedabc5c":"code","9862e4b3":"code","7b1598b8":"markdown"},"source":{"3da6782d":"import pandas as pd, numpy as np\nfrom matplotlib import pyplot as plt\n\nimport scipy.stats  as stats","e4044db9":"pd.options.display.max_columns = 50","cb994392":"best = pd.read_csv(\"..\/input\/accuracy-best-public-lbs\/kkiller_first_public_notebook_under050_v5.csv\")\nbest.head()","f3ef9d81":"sales = pd.read_csv(\"..\/input\/m5-forecasting-uncertainty\/sales_train_validation.csv\")\nsales.head()","e0f8e36a":"sub = best.merge(sales[[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]], on = \"id\")\nsub[\"_all_\"] = \"Total\"\nsub.shape","4e2314c0":"sub.head()","85a6fbe7":"qs = np.array([0.005,0.025,0.165,0.25, 0.5, 0.75, 0.835, 0.975, 0.995])\nqs.shape","f68c1b78":"qs2 = np.log(qs\/(1-qs))*.065\n\nratios = stats.norm.cdf(qs2)\nratios \/= ratios[4]\nratios = pd.Series(ratios, index=qs)\nratios.round(3)","64f750c2":"def quantile_coefs(q):\n    return ratios.loc[q].values","20cd8fb0":"def get_group_preds(pred, level):\n    df = pred.groupby(level)[cols].sum()\n    q = np.repeat(qs, len(df))\n    df = pd.concat([df]*9, axis=0, sort=False)\n    df.reset_index(inplace = True)\n    df[cols] *= quantile_coefs(q)[:, None]\n    if level != \"id\":\n        df[\"id\"] = [f\"{lev}_X_{q:.3f}_validation\" for lev, q in zip(df[level].values, q)]\n    else:\n        df[\"id\"] = [f\"{lev.replace('_validation', '')}_{q:.3f}_validation\" for lev, q in zip(df[level].values, q)]\n    df = df[[\"id\"]+list(cols)]\n    return df","6a178f27":"def get_couple_group_preds(pred, level1, level2):\n    df = pred.groupby([level1, level2])[cols].sum()\n    q = np.repeat(qs, len(df))\n    df = pd.concat([df]*9, axis=0, sort=False)\n    df.reset_index(inplace = True)\n    df[cols] *= quantile_coefs(q)[:, None]\n    df[\"id\"] = [f\"{lev1}_{lev2}_{q:.3f}_validation\" for lev1,lev2, q in \n                zip(df[level1].values,df[level2].values, q)]\n    df = df[[\"id\"]+list(cols)]\n    return df","4d99b255":"levels = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"_all_\"]\ncouples = [(\"state_id\", \"item_id\"),  (\"state_id\", \"dept_id\"),(\"store_id\",\"dept_id\"),\n                            (\"state_id\", \"cat_id\"),(\"store_id\",\"cat_id\")]\ncols = [f\"F{i}\" for i in range(1, 29)]","f921baa8":"df = []\nfor level in levels :\n    df.append(get_group_preds(sub, level))\nfor level1,level2 in couples:\n    df.append(get_couple_group_preds(sub, level1, level2))\ndf = pd.concat(df, axis=0, sort=False)\ndf.reset_index(drop=True, inplace=True)\ndf = pd.concat([df,df] , axis=0, sort=False)\ndf.reset_index(drop=True, inplace=True)\ndf.loc[df.index >= len(df.index)\/\/2, \"id\"] = df.loc[df.index >= len(df.index)\/\/2, \"id\"].str.replace(\n                                    \"_validation$\", \"_evaluation\")\n\ndf.shape","fedabc5c":"df.head()","9862e4b3":"df.to_csv(\"submission.csv\", index = False)","7b1598b8":"This notebook will help you switching easily from **M5 accuracy** prediction to **uncertainty** . We just use a multiplier scheme under the hood."}}