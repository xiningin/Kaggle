{"cell_type":{"db1bf914":"code","35bf371b":"code","5de5f77e":"code","8b8ec2c9":"code","dcf2ab3c":"code","7800537f":"code","6db10d59":"code","882f8b33":"code","67a6384c":"code","2ffae0cb":"code","87489f39":"code","e786b592":"code","65dd5d4d":"code","68575d2e":"code","805c52e7":"code","83435e60":"code","2a22e9b0":"code","56e0440f":"code","5ee67702":"code","08d5a26e":"markdown","93077f14":"markdown"},"source":{"db1bf914":"# IMPORT MODULES\nimport sys\nfrom os.path import join\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n#from tensorflow.python.keras.applications import ResNet50\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils, to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.applications import ResNet50\n\nimport os\nprint(os.listdir(\"..\/input\"))","35bf371b":"PATH = \"..\/input\/dermmel\/DermMel\/\"\nprint(os.listdir(PATH))","5de5f77e":"# Check content of the dirs\n\nPATHtrain = PATH + 'train_sep\/'\nprint(len(os.listdir(PATHtrain)), \" TRAIN Directories of photos\")\nLabels = os.listdir(PATHtrain)\nsig = 0\nfor label in sorted(Labels):\n    print(label,len(os.listdir(PATHtrain + label +'\/')))\n    sig = sig + len(os.listdir(PATHtrain + label +'\/'))\n\nprint(\"Total TRAIN photos \", sig)\nprint(\"_\"*50)\n\nPATHvalid = PATH + 'valid\/'\nprint(len(os.listdir(PATHvalid)), \" VALID Directories of photos\")\nLabels = os.listdir(PATHvalid)\nsig = 0\nfor label in sorted(Labels):\n    print(label,len(os.listdir(PATHvalid + label +'\/')))\n    sig = sig + len(os.listdir(PATHvalid + label +'\/'))\n\nprint(\"Total Validation photos \", sig)\nprint(\"_\"*50)\n\nPATHtest = PATH + 'test\/'\nprint(len(os.listdir(PATHtest)), \" TEST Directories of photos\")\nLabels = os.listdir(PATHtest)\nsig = 0\nfor label in sorted(Labels):\n    print(label,len(os.listdir(PATHtest + label +'\/')))\n    sig = sig + len(os.listdir(PATHtest + label +'\/'))\n\nprint(\"Total Testing photos \", sig)\nprint(\"_\"*50)","8b8ec2c9":"# Check the photos and their labels \n\nTestNum = 77\ndiag = 'Melanoma'\n\nimage_dir = PATHtrain +'\/'+diag+'\/'\nimg_name = os.listdir(image_dir)[TestNum]\nimg_path = image_dir+str(img_name)\nimg = image.load_img(img_path, target_size=(224, 224))\nimgplot = plt.imshow(img)\nprint(\"TRAIN \",diag,\" photo number \", TestNum)\nplt.show()\n\nimage_dir = PATHvalid +'\/'+diag+'\/'\nimg_name = os.listdir(image_dir)[TestNum]\nimg_path = image_dir+str(img_name)\nimg = image.load_img(img_path, target_size=(224, 224))\nimgplot = plt.imshow(img)\nprint(\"VALID \",diag,\" photo number \", TestNum)\nplt.show()\n\nimage_dir = PATHtest +'\/'+diag+'\/'\nimg_name = os.listdir(image_dir)[TestNum]\nimg_path = image_dir+str(img_name)\nimg = image.load_img(img_path, target_size=(224, 224))\nimgplot = plt.imshow(img)\nprint(\"TEST \",diag,\" photo number \", TestNum)\nplt.show()\n","dcf2ab3c":"# Convoluted Base MODEL\n\nconv_base = ResNet50(weights='imagenet',\ninclude_top=False,\ninput_shape=(224, 224, 3))\n\nprint(conv_base.summary())","7800537f":"# MODEL\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2, activation='sigmoid'))\n\nprint(model.summary())","6db10d59":"# Make the conv_base NOT trainable:\n\nfor layer in conv_base.layers[:]:\n   layer.trainable = False\n\nprint('conv_base is now NOT trainable')","882f8b33":"for i, layer in enumerate(conv_base.layers):\n   print(i, layer.name, layer.trainable)","67a6384c":"# Compile frozen conv_base + my top layer\n\nmodel.compile(optimizer=optimizers.Adam(),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nprint(\"model compiled\")\nprint(model.summary())","2ffae0cb":"# Prep the Train Valid and Test directories for the generator\n\ntrain_dir = PATHtrain\nvalidation_dir = PATHvalid\ntest_dir = PATHtest\nbatch_size = 20\ntarget_size=(224, 224)\n\n#train_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,target_size=target_size,batch_size=batch_size)\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,target_size=target_size,batch_size=batch_size)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,target_size=target_size,batch_size=batch_size)","87489f39":"print(train_generator.class_indices)\nprint(validation_generator.class_indices)\nprint(test_generator.class_indices)","e786b592":"# Short training ONLY my top layers \n#... so the conv_base weights will not be destroyed by the random intialization of the new weights\n\nhistory = model.fit_generator(train_generator,\n                              epochs=3,\n                              steps_per_epoch = 10682 \/\/ batch_size,\n                              validation_data = validation_generator,\n                              validation_steps = 3562 \/\/ batch_size)","65dd5d4d":"# Make last block of the conv_base trainable:\n\nfor layer in conv_base.layers[:165]:\n   layer.trainable = False\nfor layer in conv_base.layers[165:]:\n   layer.trainable = True\n\nprint('Last block of the conv_base is now trainable')","68575d2e":"for i, layer in enumerate(conv_base.layers):\n   print(i, layer.name, layer.trainable)","805c52e7":"# Compile frozen conv_base + UNfrozen top block + my top layer ... SLOW LR\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-5),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nprint(\"model compiled\")\nprint(model.summary())","83435e60":"# Long training with fine tuning\n\nhistory = model.fit_generator(train_generator,\n                              epochs=50,\n                              steps_per_epoch = 10682 \/\/ batch_size,\n                              validation_data = validation_generator,\n                              validation_steps = 3562 \/\/ batch_size)","2a22e9b0":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","56e0440f":"test_loss, test_acc = model.evaluate_generator(test_generator, steps= 3561 \/\/ batch_size, verbose=1)\nprint('test acc:', test_acc)","5ee67702":"# SAVE or LOAD model (Keras - all batteries included: architecture, weights, optimizer, last status in training, etc.)\n# YOU supply this model.h5 file from previous training session(s) - expected as a data source by Kaggle\n\n# SAVE model\nmodel.save('MelanomaResNet50FineTune.h5')\nprint(\"MelanomaResNet50FineTune.h5 was saved\")\n\n# LOAD model\n#del model\n#model = load_model('..\/input\/weather-v9\/modelWeatherV10.h5')\n#print(\"modelWeatherV10.h5 was loaded\")","08d5a26e":"Classify pigmented skin lesions dermatoscopic images from HAM10k https:\/\/www.nature.com\/articles\/sdata2018161 into 7 diagnosis\n","93077f14":"It\u2019s necessary to freeze the convolution base of the conv base in order to\nbe able to train a randomly initialized classifier on top. For the same reason, it\u2019s only\npossible to fine-tune the top layers of the convolutional base **once the classifier on top\nhas already been trained**. If the classifier isn\u2019t already trained, then the error signal\npropagating through the network during training will be too large, and the representations\npreviously learned by the layers being fine-tuned will be destroyed\n\n**Below, first train with no limit to lr - with conv_base frozen - only  my top layers**\n\n**Then, unfreeze last model conv block , recompile and train all with LOW lr=1e-5**"}}