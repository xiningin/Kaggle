{"cell_type":{"3f470550":"code","13307096":"code","01720c17":"code","e2ebf8cf":"code","d6954626":"code","775c9c3a":"code","13bb62fb":"code","a8db5112":"code","9bf675c4":"code","cc5e4f58":"code","aeb994cc":"markdown","449bf2ea":"markdown","7df476e2":"markdown","be0b983f":"markdown","2837a78d":"markdown","29f27d31":"markdown","ce8663ce":"markdown","53f96b38":"markdown","8a4e42dc":"markdown","bd40c077":"markdown","29b3b517":"markdown","f1823b29":"markdown"},"source":{"3f470550":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report ","13307096":"dataset = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndataset.head()","01720c17":"dataset.isnull().sum()\nsns.heatmap(dataset.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')","e2ebf8cf":"dataset.info()","d6954626":"X = dataset.iloc[:, 0:8].values\ny = dataset.iloc[:, 8].values","775c9c3a":"imputer = SimpleImputer(missing_values=0, strategy='mean')\nimputer.fit(X[:, 1:6])\nX[:, 1:6] = imputer.transform(X[:, 1:6])\n","13bb62fb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","a8db5112":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","9bf675c4":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy')\nclassifier.fit(X_train, y_train)","cc5e4f58":"y_pred_test = classifier.predict(X_test)\nprint('Confusion Matrix :')\nprint(confusion_matrix(y_test, y_pred_test)) \nprint('Accuracy Score :',accuracy_score(y_test, y_pred_test))\nprint('Report : ')\nprint(classification_report(y_test, y_pred_test))","aeb994cc":"**As there is no categorical data so we need not to take care of categorical or string data**","449bf2ea":"# Checking Null values in dataset\n**First of all we will check is there any null or nan value in our dataset.For This I will use two methods.**\n\n1. By using inbuilt method of our data ,i.e., isnull() method\n2. By using heatmap function of seaborn library","7df476e2":"**As we can see here that there is no null value. But if we see our data there is one problem some the columns like Glucose, BloodPressure, SkinThickness, Insulin and BMI.So actually these column have nan values which are represented by 0.So we will treat it after making our independent and dependent variables.**","be0b983f":"# Training the train dataset ","2837a78d":"# Applying feature scaling on test and train dataset","29f27d31":"# Taking care of missing data","ce8663ce":"# Predicting the Test set results","53f96b38":"# Importing the libraries","8a4e42dc":"# Splitting the dataset into the Training set and Test set\n**Here I had given a 20% of my whole dataset to the test data as we want to feed the maximum of our data to our training set so that our model can predict with a very high accuracy**","bd40c077":"# Importing the dataset","29b3b517":"# Making our dependent and independent features\nNow making our dependent and independent features to test our model and predict for future values.","f1823b29":"**And here we have achieved an accuracy of around 78% on our test dataset by using random forest classifier.**"}}