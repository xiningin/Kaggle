{"cell_type":{"c2184b9d":"code","88497836":"code","5b45dc33":"code","4ce37acd":"code","31bbedfe":"code","b47f95e6":"code","9ee357fb":"code","4ac6568d":"code","f4c7915c":"code","6c3a5a36":"code","1f2a1966":"code","7a4ee718":"code","88ea6411":"code","7a9d71ae":"code","8225a916":"code","59ad9c8a":"code","833c1b25":"code","89e524bc":"code","dbf42eb4":"code","ad264ed1":"markdown","786d6045":"markdown","81780352":"markdown","f0cf5689":"markdown","ac0d5943":"markdown","60dc3674":"markdown","529cf98f":"markdown","ab7bb99a":"markdown"},"source":{"c2184b9d":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n%matplotlib inline","88497836":"df=pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","5b45dc33":"df.shape","4ce37acd":"all(df.isnull().any())","31bbedfe":"df['Class'].value_counts()","b47f95e6":"print((492\/(284807+492))*100)","9ee357fb":"plt.figure(dpi=100)\nsns.set_style('darkgrid')\nsns.countplot('Class',data=df)\nplt.xlabel('Target Class')\nplt.ylabel('Count')\nplt.xticks([0,1],['Not Fraud','Fraud'])\nplt.show()","4ac6568d":"mask = np.triu(np.ones_like(df.corr(),dtype=bool))\nplt.figure(dpi=100,figsize=(10,8))\nsns.heatmap(df.corr(),yticklabels=True,mask=mask,cmap='viridis',annot=False, lw=1)\nplt.show()","f4c7915c":"x=df.iloc[:,:-1]\ny=df.iloc[:,-1]","6c3a5a36":"print((x.shape,y.shape))","1f2a1966":"from imblearn.combine import SMOTETomek\nsmk=SMOTETomek(ratio=1,random_state=0)\nx_new,y_new=smk.fit_sample(x,y)\n","7a4ee718":"print(x_new.shape,y_new.shape)","88ea6411":"\nfrom sklearn.model_selection import train_test_split as tts\nx_train,x_test,y_train,y_test=tts(x_new,y_new,test_size=0.80,random_state=0,stratify=y_new)","7a9d71ae":"\nprint(x_train.shape,x_test.shape)","8225a916":"from sklearn.linear_model import LogisticRegression\nlrm=LogisticRegression(C=0.1,penalty='l1',n_jobs=-1)\nlrm.fit(x_train,y_train)","59ad9c8a":"y_pred=lrm.predict(x_test)","833c1b25":"print(\"Train Set Accuracy is ==> \",metrics.accuracy_score(y_train,lrm.predict(x_train)))\nprint(\"Test Set Accuracy is ==> \",metrics.accuracy_score(y_test,y_pred))","89e524bc":"print(\"Classification Report on Hold Out Dataset==>\\n\\n\",metrics.classification_report(y_test,y_pred))","dbf42eb4":"probs = lrm.predict_proba(x_test)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc = metrics.auc(fpr, tpr)\nplt.figure(dpi=100)\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","ad264ed1":"# Logistic Regression Model","786d6045":"**Dataset is highly imbalanced, only 0.17 % obseravations are detected as Fraud**","81780352":"# Model Evaluation","f0cf5689":"# Data Reshampling\nHere i am reshampling data using **SMOTE** method because dataset is imbalaned.","ac0d5943":"**We can see there are only less variable which are weakly correalted with class, May be this is because data is already reduced to lower domension using PCA and other Feature engineering method and these varables are explaining significant variance in data**","60dc3674":"# Data Understanding\nThere is 284807 observation of 31 variable. Class is target variable where as others are predictor variable. Information given in data is sesitive so i think data has been preprocessed with technique such as PCA or Factor Analysis, So we need not to put extra effort on Data Cleaning and Wrangling. Out of 284807 only 492 observations are detected Fraud so this data is highly imbalanced we will use different sampling technique to increase accuracy.","529cf98f":"**There is no missing value**","ab7bb99a":"**Model is validated , we can see accuracy at both train and test set is almost sam which means model is not overfitting, ROC-AUC score is also enough good 0.98.**\n\n### Please Upvote this kernel, if it is useful for you :)"}}