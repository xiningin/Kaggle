{"cell_type":{"6e00608c":"code","a4c73d80":"code","1783c4fb":"code","a4b403c3":"code","5a5b524c":"code","4bbb87b5":"code","6b8cf8ea":"markdown","7155a6d2":"markdown","74cd077e":"markdown","9f8716a7":"markdown","5b3ecd18":"markdown","460d80a9":"markdown","e40ad961":"markdown","c19061d4":"markdown"},"source":{"6e00608c":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm, tqdm_notebook\nimport cv2\nimport sys","a4c73d80":"#beautiful library to get tree view of folders\n!apt-get install tree","1783c4fb":"!tree -L 1 '..\/input'","a4b403c3":"#view 5 files from each folder\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    count = 0\n    for filename in filenames:\n        if count > 5:\n            break\n        print(os.path.join(dirname, filename))\n        count = count+1","5a5b524c":"#sample image\nplt.imshow(cv2.imread(\"..\/input\/training\/0_101.jpg\"))","4bbb87b5":"folder_train = \"..\/input\/food-11\/training\/\"\ntraining_data = []\ntraining_target = []\ncount = 0\n\n#loop through all the files in train folder\nfor files in tqdm_notebook(os.listdir(folder_train)):\n    img = cv2.imread(os.path.join(folder_train,files))\n    #reshape all image to same size\n    img = cv2.resize(img,(224,224) )\n    #scale pixel values for training process to be efficient\n    img = img\/255\n    #ignore images with different size\n    if(img.shape != (224,224,3)):\n        print(\"error case\", img.shape)\n        print(\"file name: \",files)\n        continue\n    #letter before \"_\" has the class number \n    target = int(files.split(\"_\")[0])\n    training_data.append(img)\n    training_target.append(target)\n    \n    #we will just load 5k images\n    count = count + 1\n    if(count>5000):\n        break\n\nprint(\"size:(in mb) \",sys.getsizeof(training_data)\/1048576)\ntraining_data = np.array(training_data)\nprint(\"size:(in mb) \",sys.getsizeof(training_data)\/1048576)\ntraining_data = training_data.reshape(-1,224,224,3)\ntraining_target = np.array(training_target)\nprint(\"training data shape\",training_data.shape)\nprint(\"target for training data shape\", training_target.shape)","6b8cf8ea":"There is 0 csv file in the current version of the dataset:\n","7155a6d2":"Take a peek at how files are arranged...","74cd077e":"### You will be working with evaluation, training and validation folders\n\nFile naming has been done in following fashion:- class_someImagenumber.jpg  (e.g. 3_49.jpg)","9f8716a7":"## Conclusion\nAs you can see, on loading training dataset only, it's taking a reasonable space of RAM. As suggested, load data in batches. You can either write your own custom data generator or use keras ImageDataGenerator. \nHappy Kaggling!","5b3ecd18":"## Introduction\nGreetings kaggler!!. Below code is to help you getting started with this dataset.","460d80a9":"I would demonstrate step 1 here and for training dataset.","e40ad961":"So loading data would involve extraction of class from file name.\nAnother major point:\n    1. Either you can load complete dataset at once\n    2. Or Loading a bach of images at a time to train and repeat the process.\n\nGiven that images would occupy large RAM space, it's better to go ahead with step 2. ","c19061d4":"## Exploratory Analysis\n"}}