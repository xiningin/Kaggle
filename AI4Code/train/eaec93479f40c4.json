{"cell_type":{"855a8522":"code","ab5a20cd":"code","69bcf75e":"code","80be46de":"code","bf5c7472":"code","1b2096cf":"code","46225a68":"code","4d792299":"markdown"},"source":{"855a8522":"!pip install -q -U git+https:\/\/github.com\/mljar\/mljar-supervised.git@master","ab5a20cd":"conda install -c conda-forge python-snappy fastparquet snappy","69bcf75e":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\nimport gc\nimport datatable as dt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import classification_report, accuracy_score, average_precision_score\nimport fastai\nfrom fastai import *\nfrom fastai.tabular.all import *\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, LabelEncoder\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.model_selection import train_test_split, KFold , StratifiedKFold, cross_val_score\nimport optuna\nimport plotly\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom supervised.automl import AutoML \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","80be46de":"def cef(data_0):\n    data = data_0.copy()\n    age_map = data[['Age', 'Pclass']].dropna().groupby('Pclass').mean().to_dict()\n    data.Age = data.Age.fillna(data.Pclass.map(age_map['Age']))\n    data.Cabin = data['Cabin'].fillna('X').map(lambda x: x[0].strip())\n    data.Ticket = data['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n    fare_map = data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n    data['Fare'] = data['Fare'].fillna(data['Pclass'].map(fare_map['Fare']))\n    data['Fare'] = np.log1p(data['Fare'])\n    data['Embarked'] = data['Embarked'].fillna('X')\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1    \n    data['FirstName'] = data.Name.map(lambda x: str(x).split(',')[0])\n    data['Surname'] = data.Name.map(lambda x: str(x).split(',')[1])   \n    for col in ['Name', 'FirstName', 'Surname']:\n        data['Counter_' + col] = data[col].map(data.groupby(col)['PassengerId'].count().to_dict())\n    data.drop(columns = [\"PassengerId\",'Name','Surname'], inplace = True)\n    label_cols = ['FirstName', 'Ticket', 'Sex', 'Cabin', 'Embarked', 'Pclass']\n    numerical_cols = ['Age', 'SibSp', 'Parch', 'Fare','FamilySize', 'Counter_Name','Counter_FirstName','Counter_Surname']\n    def label_encoder(c):\n        le = LabelEncoder()\n        return le.fit_transform(c)\n    #scaler = StandardScaler()\n    #onehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\n    label_encoded_df = data[label_cols].apply(label_encoder)\n    #numerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), columns=numerical_cols)\n    target_df = data['Survived']\n    #all_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)\n    data = pd.concat([data[numerical_cols], label_encoded_df, target_df], axis=1)\n    return data","bf5c7472":"TARGET = 'Survived'\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\ntrain_data = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\n# file1 = pd.read_csv(\"..\/input\/proba\/proba th 0.5.csv\")\n# file2 = pd.read_csv(\"..\/input\/proba\/0.816.csv\")\ntest_id = test_data[\"PassengerId\"]\n#file = file1.merge(file2, on =\"PassengerId\", how = \"inner\")\n#file.columns = 'PassengerId', 'proba', 'Survived'\n#pseudo_label_test = (file[(file.proba <= 0.1) | (file.proba >= 1)].reset_index(drop = True))\n#pseudo_label_test.drop(\"proba\", axis=1, inplace=True)\npseudo_label_test = pd.read_csv(\"..\/input\/425425425\/file 1 0.81759.csv\")\npseudo_merge_test = test_data.merge(pseudo_label_test, on = \"PassengerId\", how = \"inner\")\ndf = pd.concat([train_data, pseudo_merge_test]).reset_index(drop = True)\n#df.drop(\"PassengerId\", axis=1, inplace=True)\ny = df[\"Survived\"]\n#test_data.drop(\"PassengerId\", axis=1, inplace=True)\nall_df = pd.concat([df, test_data]).reset_index(drop = True)\nall_df = cef(all_df)\ntrain_data, test_data = all_df[:len(df)], all_df[len(df):]\nX = train_data.drop(\"Survived\", axis=1)\nto_test = test_data.drop(\"Survived\", axis=1)\nto_test = to_test.reset_index(drop = True)\nX_male = X[X[\"Sex\"] == 1]\ny_male = y[X_male.index]\nX_female = X[X[\"Sex\"] == 0]\ny_female = y[X_female.index]\nto_test_male = to_test[to_test[\"Sex\"] == 1]\nto_test_female = to_test[to_test[\"Sex\"] == 0]\nX_male = X_male.drop(\"Sex\", axis = 1)\nX_female = X_female.drop(\"Sex\", axis = 1)\nto_test_male = to_test_male.drop(\"Sex\", axis = 1)\nto_test_female = to_test_female.drop(\"Sex\", axis = 1)\ntmp = 200000 - (X_female.shape[0] + X_male.shape[0])\ntmp2 = tmp \/ 100000\nprint (\"filter out\", tmp, \"unconfident fake label data\")\nprint (\"which holds\", tmp2 * 100, \"% error\")\nprint (\"which means you are supposed to have\", (1 - tmp2) * 100, \"% accuracy right now\")\ndel train_data\ndel test_data\ndel all_df","1b2096cf":"model_male = AutoML(mode=\"Compete\", \n                    total_time_limit = 1000\n                    # 14400\n                    ,algorithms = [\"Random Forest\", \"CatBoost\",\"LightGBM\", \"Extra Trees\"], random_state = 42)\nmodel_male.fit(X_male, y_male)\ny_pred_male = model_male.predict_proba(to_test_male)[:,1]\nto_test.loc[to_test_male.index, \"Survived\"] = y_pred_male\n\nmodel_female = AutoML(mode=\"Compete\", \n                    total_time_limit = 1000\n                    # 14400\n                    ,algorithms = [\"Random Forest\", \"CatBoost\",\"LightGBM\", \"Extra Trees\"], random_state = 42)\nmodel_female.fit(X_female, y_female)\ny_pred_female = model_female.predict_proba(to_test_female)[:,1]\nto_test.loc[to_test_female.index, \"Survived\"] = y_pred_female\n","46225a68":"threshold = 0.5\n#threshold = pd.Series(to_test.Survived).sort_values(ascending = False).head(34911).values[-1]\nprint(f\"Current threshold is: {threshold}\")\n\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\nsubmission['submit_1'] = (to_test.Survived > threshold).astype(int)\nsubmission['submit_2'] = pd.read_csv(\"..\/input\/425425425\/dae.csv\")[TARGET]\nsubmission['submit_3'] = pseudo_label_test[TARGET]\nsubmission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()\nsubmission[TARGET] = (submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis=1) >= 2).astype(int)\nsubmission[TARGET].mean()\nsubmission[['PassengerId', TARGET]].to_csv(\"TPS425.csv\", index = False)","4d792299":"I just combine different ideas from kagglers. You can see some shadow from the codes below."}}