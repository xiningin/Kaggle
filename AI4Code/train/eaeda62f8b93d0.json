{"cell_type":{"c7a3bb40":"code","b78eb2fe":"code","227eb51f":"code","abdbded7":"code","783486e1":"code","f373d31c":"code","432ccf9f":"code","d52697a0":"code","13d3aca0":"code","79466eb0":"code","bbdcd7a7":"code","56a80b35":"code","b082b01a":"code","746a71c4":"code","637eb5bb":"code","3145046b":"code","3d1870f2":"code","6882280e":"code","2a5d7583":"code","c7b99ff4":"code","50f40573":"code","df204f75":"code","b92b0d17":"code","dd27e49e":"code","bfd18c37":"code","9e81a6ca":"code","23fec45f":"code","748bed26":"code","644cda90":"code","c71af2e6":"code","df5f6db8":"code","aacc6cb7":"code","5f151d64":"code","c9f84bd6":"code","aae2b41b":"code","c479b8d7":"code","590ef17f":"code","bea9188d":"code","5a5ca5fd":"code","20e6cf90":"code","f08d040e":"code","454b8bfc":"code","3c2d5ddb":"markdown","b7f42a72":"markdown","83308f01":"markdown","3818e113":"markdown","f353646b":"markdown","5edd8c5f":"markdown","fc03a32d":"markdown","04fa187c":"markdown","b7b43c0b":"markdown","1dd5b94f":"markdown","5b795555":"markdown","23f2f05b":"markdown","65e2a4c5":"markdown","8897ba95":"markdown","c59cd6a4":"markdown","212fb2aa":"markdown","83f2e259":"markdown","6eeceee8":"markdown","5fdfa8e2":"markdown","0dcce5d7":"markdown","fc634413":"markdown","ed39a242":"markdown","bc4a8e7a":"markdown","9c0d5fd0":"markdown","9a3085b4":"markdown","f548aaf8":"markdown","2b87f41a":"markdown","a3fe8a9c":"markdown","fa4cf860":"markdown","2e1af332":"markdown","e17d6e60":"markdown","e5cfa0a0":"markdown","667c9356":"markdown","1993892c":"markdown","6038f213":"markdown","263e1b2c":"markdown","6a96cf92":"markdown","e50965bc":"markdown","dd96b272":"markdown"},"source":{"c7a3bb40":"import numpy as np\n# Linear algebra\nimport scipy\n# Standard scientific Python imports\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport sklearn\n# Import datasets, classifiers and performance metrics\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\n","b78eb2fe":"print(np.__version__)\nprint(sklearn.__version__)\nprint(matplotlib.__version__)\nprint(scipy.__version__)","227eb51f":"dataset = datasets.load_boston()","abdbded7":"dataset.keys()","783486e1":"dataset","f373d31c":"data = dataset.data\nprint(data)\ndata.shape","432ccf9f":"target = dataset.target\nprint(target)\ntarget.shape","d52697a0":"dataset.feature_names","13d3aca0":"digits = datasets.load_digits()","79466eb0":"# To apply a classifier on this data, we need to flatten the image, to\n# turn the data in a (samples, feature) matrix:\nn_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))","bbdcd7a7":"# Create a classifier: a support vector classifier\nclassifier = svm.SVC(gamma=0.001)","56a80b35":"# Split data into train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(\n    data, digits.target, test_size=0.5, shuffle=False)","b082b01a":"# We learn the digits on the first half of the digits\nclassifier.fit(X_train, y_train)","746a71c4":"# Now predict the value of the digit on the second half:\npredicted = classifier.predict(X_test)","637eb5bb":"predicted","3145046b":"# plot 4 samples from the training\/test set and their corresponding labels\/prediction \n_, axes = plt.subplots(2, 4)\nimages_and_labels = list(zip(digits.images, digits.target))\nfor ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Training: %i' % label)\n    \nimages_and_predictions = list(zip(digits.images[n_samples \/\/ 2:], predicted))\nfor ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n    ax.set_axis_off()\n    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n    ax.set_title('Prediction: %i' % prediction)","3d1870f2":"print(\"Classification report for classifier %s:\\n%s\\n\"\n      % (classifier, metrics.classification_report(y_test, predicted)))\ndisp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n\nplt.show()","6882280e":"iris_dataset = datasets.load_iris()","2a5d7583":"iris_dataset.target_names","c7b99ff4":"X=iris_dataset.data\nX","50f40573":"\ny=iris_dataset.target\nprint(y)\n","df204f75":"np.unique(y)","b92b0d17":"iris_dataset.target_names","dd27e49e":"x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=67)","bfd18c37":"clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,solver='sgd', verbose=10,  random_state=21,tol=0.000000001)","9e81a6ca":"clf.fit(x_train, y_train)","23fec45f":"y_pred = clf.predict(x_test)","748bed26":"y_pred","644cda90":"metrics.accuracy_score(y_test, y_pred)","c71af2e6":"cm = metrics.confusion_matrix(y_test, y_pred)\ncm","df5f6db8":"print(\"Classification report for classifier %s:\\n%s\\n\"\n      % (clf, metrics.classification_report(y_test, y_pred)))\ndisp = metrics.plot_confusion_matrix(clf, x_test, y_test)\ndisp.figure_.suptitle(\"Confusion Matrix\")\nprint(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n\nplt.show()","aacc6cb7":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)\nscore=metrics.accuracy_score(y_test, y_pred)\nscore","5f151d64":"from sklearn.model_selection import KFold\n\nscores = []\n\nfor train, test in KFold(n_splits=5, random_state=42).split(X):\n    X_train, y_train = X[train], y[train]\n    X_test, y_test = X[test], y[test]\n    \n    clf = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n    scores.append(metrics.accuracy_score(y_test, clf.predict(X_test)))\n\nprint(\"CV accuracy = %f +-%f\" % (np.mean(scores), np.std(scores)))","c9f84bd6":"# Shortcut\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(KNeighborsClassifier(n_neighbors=5), X, y, \n                         cv=KFold(n_splits=5, random_state=42), \n                         scoring=\"accuracy\")\nprint(\"CV accuracy = %f +-%f\" % (np.mean(scores), np.std(scores)))","aae2b41b":"x_train, x_test, y_train, y_test = train_test_split(X,y, test_size= 0.25, random_state=27)\n# experimenting with different n values\nk_range = list(range(1,26))\nscores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train, y_train)\n    y_pred = knn.predict(x_test)\n    scores.append(metrics.accuracy_score(y_test, y_pred))\n    \nplt.plot(k_range, scores)\nplt.xlabel('Value of k for KNN')\nplt.ylabel('Accuracy Score')\nplt.title('Accuracy Scores for Values of k of k-Nearest-Neighbors')\nplt.show()","c479b8d7":"from sklearn.model_selection import GridSearchCV","590ef17f":"# define the parameter values that should be searched\nk_range = list(range(1, 31))\nprint(k_range)","bea9188d":"# create a parameter grid: map the parameter names to the values that should be searched\n# simply a python dictionary\n# key: parameter name\n# value: list of values that should be searched for that parameter\n# single key-value pair for param_grid\nparam_grid = dict(n_neighbors=k_range,)\nprint(param_grid)\n\n","5a5ca5fd":"# initiate the grid object with our parameters\ngrid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')","20e6cf90":"# fit to the grid our data\ngrid.fit(X, y)","f08d040e":"#print the cross validation for each run with a the differents values of k \ngrid.cv_results_","454b8bfc":"# Print the best k for our approach\ngrid.best_index_","3c2d5ddb":"__Pre processing__\n\n* Standardization, or mean removal and variance scaling\n* Non-linear transformation\n* Normalization\n* Encoding categorical features\n* Discretization\n* Imputation of missing values\n* Generating polynomial features\n* Custom transformers\n\n","b7f42a72":"### Version lib","83308f01":"__Unsupervised learning:__\n\n* K-means for clustering problems.\n* Apriori algorithm for association rule learning problems.\n* Principal Component Analysis (PCA).\n* Singular Value Decomposition (SVD).\n* Independent Component Analysis (ICA)","3818e113":"![pipelineapi](https:\/\/raw.githubusercontent.com\/YouvenZ\/Apprentissage_automatique_cours\/master\/Diapositive13.PNG)","f353646b":"<div class=\"alert alert-warning\" role=\"alert\">\n  <h4 class=\"alert-heading\">Here we have introduced the confusion matrix<\/h4>\n  <p>\ud83d\udd11  We will not explain in detail what is the confusion matrix in this tutorial but in the next one. For now you just need to now that this matrix indicate how a model is accurate or wrong according to all classes on the test set<\/p>\n  <hr>\n<\/div>","5edd8c5f":"\n\n<div class=\"alert alert-info\" role=\"alert\">\n \u2714\ufe0f With the module datasets from sklearn we can load pre built dataset. The dataset loaded is a dictionnary that contain our data already pre-processed. The dictionnary do have the following information:\n<\/div>\n\n   * data: An array containing our features.\n   * target: An array containing our targets.\n   * features names: Name of the features present in the dataset.\n   * DESCR: Some description of the nature of the data, how it was colleted, and other details.\n   * filename: Path location of the dataset\n   \n<div class=\"alert alert-danger\" role=\"alert\">\n\u26a0\ufe0f  Scikit-learn is doing a lot of work for us like spliting the features and the targets and also describing the dataset. Often in competition or open data science problem we will have to do it by ourselves.\n<\/div>   ","fc03a32d":"## The python eco system for data analytic \n\n- The __open source__ Python ecosystem provides __a flexible, easy to use and powerful scientific working environment__, including: [NumPy](http:\/\/numpy.org), [SciPy](http:\/\/scipy.org), [IPython](http:\/\/ipython.org), [Matplotlib](http:\/\/matplotlib.org), [Pandas](http:\/\/pandas.pydata.org\/).\n\n<center> \n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/05\/Scikit_learn_logo_small.svg\/langfr-440px-Scikit_learn_logo_small.svg.png\" style=\"max-width: 120px; display: inline\" \/>\n<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQhUpRU6IHxEA8tGqyG5GDhBYJLcuQvP9qCuA&usqp=CAU\" style=\"max-width: 120px; display: inline\" \/>\n<img src=\"data:image\/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWQAAACNCAMAAAC3+fDsAAAAmVBMVEX\/\/\/8NVqYAAAAGVKUATqMAUaTb5PDy9vrj6vMATKLu8vjM2OpXhMD39\/dOfb11mMm7y+NtkcaswNwASaFGcbLD0+aft9c1a7AlZK0YXapeh76astaGpM2NqdJ9nsyxsbHn5+fc3Ny8vLybm5tubm5YWFhHR0d9fX2kpKQzMzNkZGSOjo5QUFAnJyfNzc0XFxc8PDxee7YANpvEYiE6AAAUu0lEQVR4nO1dCXebPLO2K7EIMPtmbGPH2dombvPd\/\/\/jLgMYBhBIOHnbpPZzTnMaB4R5GEazSovFO2CYbrzNbNu2ahT\/83ZupL5n0Bsa6NHOsrOdPyC0IH6TW7bjm6u\/8sX+FRiRYzubSMMsagXwr7q\/taz4JtKXQfczb2fWhBqq6W+dzA7DJE3TMAwzb+ubql7+sSDayXJTmxjsBg4M1\/PiikJD3Xh2SgJGFYU0UBTKApLaXqwa5VFmnu30v\/qdvxj03NqVCkBTd1kaMGB3yQGQzYI02+ggxZqbee5NnOVgelYEWliLnCSgCpfeDtUKY+FWhVPUnbW50SxGZHmlEJv5OqBCghuiaZBuQG9ofri70TwN085LxRonMxhueM4iONdNdn\/3Jj43VNsDirUdYzMZrqAEqQ\/j+Gv\/L9\/Jp4WW26AoDIfOFWIkzmwdw1ib0PzLd\/M54YYgfsZ2eTnFNc0wju55xt++o08Hw8uBlDil72G4opmGoJtd2\/3bN\/XJUDGihpfp4j4UxdFB7zg3OwNhB+\/2aqMoH0HxEoS51Bm+fYtpnGFYm8XHiXFNcwCGim7fzIwKZgKWgE8+Soxr0GWhgVZO\/rdv71PATUBVeMHHUrwEYQaCN9ZNMRckFD\/05P1GBQcsNOqHeN3IQdrM95nG41CWxcxnplfOcg5hBvcjZ7wuCHXhPblq988DsyJm0pTVmMVy4Wbr6RWznM\/gGKLG68QuEKaMUXmmleIianq1SZNSV8QyUx6hLHR81SgNBc3Q3Twk0nqcbcEIv1KWN85CjuPCf3MGaVJ1m0iqcsJAlu2rnP1csN18CV1B1xsuQZqbyEkzCWK43BXay2pS\/IjELClkIp3kr6XsaxIUE1\/s\/bmb+yQwwEXQxdMXCydjPJKeIlGKUbabP3VznwVWIVvaWsQxCbaigeSMbLIunql1ZQHmHUiVLQwJBRK0qGuZyBK14O25KrUcgX7ciSa90l0TQ09lWGaFvRjZ\/\/F9fSYYdmG1mqL3nJA+x2q0yfN8Y\/bUtJ5KaAxCo0ItN+FlTf3X4\/lOwZ4mYobQbsDdzMNlwCilLFiG2w5F5lKGZYgTpbXC8JPQ\/rcT2hF4IblIWdDOnGdaFLnShCoeduF8cTFXMaADw1TfYFmcHa3\/ZZYTuEORslBsVJVseEGPRkJpjIbcSjg1pcLwQAWtQtVwtgv3H1bRu4IdLRQpC4YUQsTzOUjgIWNBbKmAwtCKC2uQG19kLNho\/\/vzN\/+HYICrt5mjLNyA\/0RY2LKsC21uGLSwMPziX+ZqAWHxP0yyV2hCXSx1bbjCH3XqKHrfXQnXjwTFqLZhpDBmoMlYdIfj9xL74\/s7U1bfG9wf3j3aFNSw+OGJQg5IkKOJY5nTDiycSZfV3OfmrrNIiJJV+nkKx5\/fMJ5\/ve\/WD2isO3SVPQ\/HX4fLrwTVx6bQGAga28GYNPUCNPslEgoDIkXOWlULQY70cNoBPP7+1sfpePmNFwO2A\/1o34vD4Cpn\/H7dHy66kJoVPzLRLKVYzQnOtNCT1gxTR1R3f2AzW+SULBe7bOqL3j1xb\/z1buqkady3w\/xEFxolGfByiZZyTBlBZo0fogqOJet2bJlEFojyQl2TYg507WS8lYcjxrV4XS7Mz+0oz+2nvyZJ\/naa\/1R1EFGhIC+DZtrzRMdSJI9jqp4s64YpWqhiI\/IKS4QksQHZlZECo+PEbV\/M8ls7xvf20\/vxK1WYzfKumGtUYaS+FU9DrAGC1vvm6G\/oj2JknRZudJblu7T4Lyt7qQhbF2+V5nF1xvQrfCHLKz5xDyKST4d51zGsQsXkwmyG0ty5K9YAhLbvvNt\/foQkXmya6rmp1QSCCSVrBqIdJO5izQkUrX5M3vXvmXddA89waIRXEcnfHuddx4Uwsnh+ok0OQzDtVY8Embv944Oo9w02tHhPtqrmJ7Q4VKHcfIlIuH4OT5HAEQknMi6mH2iJ7xOjDgFRHYncaTvv2TJpj6DtdurH9oKBlZbQws+LYuj5IwFbL5y4f0RfWfx8fn4+dT+6SGEg5fswejEufswxMVSI1UuYs6yRP7lyWiSvZvcMNvA3XLbWF9G6bEdzN8bi\/4ZfE7sgP2o+V987dz3jphug9wMZF0c07PP3+wLPDz\/70j3nocY+WLNi0hDJcjl\/VCDkd7QRG7T0aQnktJLCgFtvdM1cD7UFnqAeR97rd1jLPaCHh5TIYt\/h+WH8\/AGygoudhJZtSDYky+Ro67wsNohlth56ziEt3qccAihbO+TlVpFsdaa4w+myu54Gem3eViN\/+PYkry9KbSGTKmolWbbekyKJjevYM6EKp9FaX0OKxCxjIyuuX833GRaY\/adnznl3+4fXJ8Djy4y4A3Isu1YEfqYzrDg\/ltMWiGSZAGYJBZkRps0YZSzNeYVHlrKk5mKVjH9NJEK9aR1u+\/T4\/OswFKzVvmOKnR4GCuXu9bFBe\/4KUfnSPQErksNi0Z7dc+3354EP8JustphrXQBIp25TdXexya3tymilqCeKtpBs3fdu+\/X+7sA9Zz80xJ57TwIZF0hksXGx756A\/3Q3\/rUao756u+DGLBnW2pdf6pmUUMJR1lpoNq0PjcfbotDdSKreFdew7ilSvhY6ohN6kVTsEt2NhZfaEX6X8m3mxUwmVSJIGvfClO8loeJaN7Xud11D2GL0KBx+k7KdDigoMc4y0kJIEns6oTPsqfOn48jAZzVVPTlQyTL5C8hgNENIK+XCWhZ1kzXJW8iojgt+J1Lff+k5WPU8FXQyPor\/6EaNi466KL0RNAAO+Xc\/A3dPHLeo+GqixPL6Qsiy2pQUsHhKKb90mXrcT\/O8GpFjANKyWMMe2o\/Ryf0QBRLyJ\/gdaQ\/0lM6aqlYhkOOXUslYKetzGkSYx2FOi6oP1falgND9drSC6Pitj98vExm+58HhLZA\/jEmWMi7wn557F7ofDlspdM0S5ZJaoFC8TIiofTiDPid1u2alZtCT1uGG4d3xQlouX097vpfXeSSn+7u7I54FWxsQzVun9mxMfU\/\/P\/f\/tG9\/\/zk4qn4N1FzSSga05ZxSuf6WPuIgU06LLEIJKdOnuCqRKKvy64ygpy8avHLkuaOQHw4V721WpVUB\/MgFIq5nXOAvUb0Q6IE0M18zOdZPyI2lwsMV2ojyIp7V5UfoMnN1bbUw9MhJWOX70dDuBEGIYi4MZzGG8Znsx\/c+zZiLhtFj89HvRvwf2+NExsVqdbfvKPr6qaCvdT72\/JBe6+\/lu3OmsXbqWzgzeymVYJmEdoIX4+r3\/kFwzh53R7B89fDWVRrYZmgJXbXe31kH4AfHNy5OP2u8PvU9m3rgh+EQb73fYaYRZuxaptpI\/MqhcxcQEHVUgkuZTbRDTeXdOq42DoCiiauV77N9MWJcSETsW\/WCnn39MhzrXxvrL5P19yqg1N3C9JYf2xkMtTPOVGffFMvY+8VvNeLu2Hx4fiQoJ\/0bGRcyHDcMojHqme\/sNzVfyZYoM0Qga0yC4afsAxcSKG24yfbJI+92a7QaA8vnY\/fs0+n19eH55XwsEnkU8ZdJi7SXQyrnqTsVNo\/NkiyJb4joVaqZWxLM6PadBEmL+UFQnTwuzE\/cY+4nxuroUxQQmVD+Q45xzrUKdJ\/tt\/bS9kySO4VuFdSNxWRW75Qi2R0m93rYP\/Jvu525sEl8mBwLDTWn5qIxG\/qHw1do0t\/tMRZ2bKVAeUEcc5OtA\/ZOogmTIRmixNz4WqMZsEqedL5X0z7xKLoB7WP7BxDe8\/SKZtz5JJdeBO8bq7GTvItoWZLhYncvQ4Gu\/4YrKV4nR+nFhs8YNchLvN33HhyKy8HMd\/7\/4T0kFxpjdM0xWP07mbMiw4DkSH7Z1MN9rwLlbkgdLyHVAsngiW9cvD108Pyy5+Rf2q9RmBx7zpUvIXmpkHzcCNDMbUgvsjmAZHXW2rTHjgtWm0y4VvBl8nRkXLy1n+I3QSpy3cYzipnv\/I2we3QRybDy2HAZhhZaYUJfQPNMSS4JwSzXqhJL8nuNC6kiA\/RC\/Do\/4c4rdCHJBc0sqdb55kN35q8oJ9LJq9Xweti5qxnFJE+XUr1yD8TGxWHy\/MXggi9nqe48nYtJLtefXuf+qN7Qs7n+4ATJd\/v7F6jgGdw01g0cSd73j8fAgX2kF1A082n8ZDxOmxo71ZNgN9QPdvL6Io4rnlmw9uIRB8KVamLH4JK8+snlogJHbMdIPtx\/P96Nncs3LiRTtkObrxsgnevxcYhWWBAkW5cj0potvSRXORJ4fJxh0D289f92RHdWPwE8cd0PD317OEdG0bk\/+MbF9LzZYOAi9nJW5VoIH+CsUUrTPBqE0Jw561CSkB+7wPfQn8mwEJ2JQhY0Zqn5+HU4LtILs40LTrCjdx5E4WT6RiUoKoheWm6P53wGy5AT4EXhOp1IXS2LhLEN8SCl+sY79DzJfZBx0a3dwk\/xDIgni7tF5Hkq2xEwHHmNAelqbjy5Uw6AHS7McWsg4E\/bYFkzyzXJjifOud2symEhh55S7r8AkBlxPnL5XkIVq0OzvDKCoD03M9Lh8tuP+7tDYc2tDr+6XZMNIx2XbahDzhpnJHKB3gPpgudu\/nFQ7Qmz+eZjF5ctZkK8IoMqs+xFCRqN5fj6cYoTlGn22s2Q+Y9Tyk93xS2vfiEr60zBiHGB7Lpppxyhq5QHmhzSw9FHr5JM6BqVc8o+Q0L0sWy1RBgdNxd020l\/PD7ifFKj1I\/ck\/G5ksZF74KngcsEdRf6x6\/hS3CeSlphjNddiEO8HfEZKx\/4hqc45CyimUralekAv2ocV95eSdhwhdMBK+CwGds+IZZ9OVGGgsbRCiJRjLfHx2iRFhIzvnFxRAcfpEnGT5UTawCbSWBeKIEdR7phqNF2LdEpfWa5mf6ECxtVgMU7x2vhpuquhjJ3GOsPRrzxW1EFdI1gmLLuwBfNfNWOCme4qaxJRtKGsK2UKEPZxUQ581TmbbgaQ990rYDrYEdqLpB8nwajjgIZNLwnYwrqtDpzGEDavWCNfhX3xgOm65OLGxkTZm4h7YGTCuwcOGJcoMjcnD6f5onxLZLiDR1fOZIwa+AdxJIsk2bpQqmKRjJdaV8S9zIsOzk9H0aOPvaWbXjsmlbozUDtVBcZFwukzfjfBnpGxmqICOXF0GVZbrWyTPmMoGekwuruBfUsQjvOhN5c\/Xo+8\/z78bnvIq8OLdDH6NM5HadnkkdMa38z2vRL034TdAXJwtk2ry1TZS7ofsI03FXokMPHqj5WfOT70LwAI9EO6OMzuPF1lo1F5BMpR7wtApXwR0iyqPv4viJepgW50hfWkDWijBdk61KustIsPiZhKdO86kj9kjietdJo2A5mm6G+oL3lHFU3QgpzsIQFVzjDVXO48OCgcEPS\/4KA\/x6rxh8dD3aAvtB6TgYJso7a99MgCPASkVIrRDatkmKSwbaIvpi22Bcz78PDQzsRT61r4g3sC6W7tqyeVM8gQE15llg4W3UhJhmMaueLaYtBhGSqAMHd9SJxvSXr48aXQAuFSCStSEOyxIpa+sKQ6V79TOg7R\/2Wvw4MME9bf4EEW2yuaii3QdByIKZ4C4dG8IUNE1BfJ\/BEPh\/6QavpZBWsptXs30K7q1Gonf3iCFqBaXy1zhptIE7YMMHMhTb0LT85BEmnHnSot69ZDKyOcewvu\/zILPh2fiDKeSRhLT9Y1O4Xm\/Z6+Rrx8n9goJZeWc841vKBl8JaE0OwWUbb8C4snwEH3JpsZPiMwCT\/PAgPV+1yYV\/S6x1V7aEnSJatwpjeZaBtrRQ1CpZrdY538H1WNAGo0yAwwgUsn+xQ2u2CjpY8VUrQviBTq1q3roiw5gAE2ft6+zL8OlaQXV8KtLLa29xiO5IFwZX2E9Zyu2KZqEe4bAD+eoI8H17fETDCUSlF6TttNFSETGrBxnPlSuDhVzMtLoHRixuYE\/uuk3ax6uI8\/nEMWSGCkD0sT+lfxzZbm07N6m5ySsPNfNx9lwlDS8KJBDmB1+ZK9n9CW2nqlqB+myHBM6yB7iYM2byGwNBTzIV4Hft\/BVHjBLvCTQsJwyp8s8SBT6KwztZCAm8PnoeJ5P4fh1OJE8cB4bDc2d9Nz1NGlXJfZcqI5eK\/CRaRUkBRpFeiLBb1LmYQq5DJevS6f40ot8IkDW3H7dq7qmDxe3Bt8q8WGXoPIrAIZGvjGac0kLMGp8CyACf9qvbjq3eWlO0gYRJbyIp2PgQ35Mp2liwcuMJLM2S7o5nQ7lIFHCtJfc2rggb7xUkvEqnQ6XiDK9yNpHDz8utwQzDKfat92S5HEkwwZHiC2Fu5o3J8DTGLPsotBzfSLLPR3TaFO4QTiCC52ZUp5AobEC2ZhH9NFck4NBt+ItzQVnFh4epriAtxkEP4bCvdRkIUxd7oSB413fVS4atAoIhDDb9cNuSjUE5FM9rvCGEs8baxG0WRv3HsZX\/nVN45S9gSIrlajs+yPG+dSIUyFgQBk1vwqdQVenrFHF\/E8iwQqN7X0yvVx2fkMPvF0k04M0GheMO8do4LgiH4GE1kR94BBq297rWE6afggqBN5PkuBimXX99cp33ch5pEEFv+aJVBl8WUp3nzlnP6d2FYYMqJsyRzQCiU9av2tWSbJLCDwmU9+zhhpmvI1saja\/ddJaJS5Pz1xzS4k7LRx\/CcmzruoGAE5j\/nI8wMlsATc2+qYgg3hAScyak8nCfFVNmsCt1TPrQb+tC2ZW9DJAyrTYHSLZC7Gw2MXj10q2yajEKJwA9XihnZAcXx+pqy0rNhWmVhq+oFs8WZ0KBUOAs\/vb4800xEWUmzEYfBjNVbCoaTcjU9LbZ3N5tCDNOpKoPUbSiz3DdsZE\/DXWkRq1srvlEsB31rlaRp6iZLC6IV\/mq1sFM9DUjo+DqU2htu5rk3iuWhuZ63KYXTUGMnTAkE6asauBIKpSwgaZhtoyohZbhOxlvi9IZJ6IVgbutFwA3V9LdOZodhmCTFDztztr6p1qRqeuxk4\/vr3TAJI8ptb9dd+bSnDzQ1zq3MvzH8LujRJrOzbeyqPXp1E3Kpg+LOGy6Fprr+1rMt26oA\/3M2rnlTwl38P2OIbWI5LAWPAAAAAElFTkSuQmCC\" style=\"max-width: 120px; display: inline\" \/>\n<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRx9owRjFQC-KPycfs5b7MgyUI8Pg_IOhvcgw&usqp=CAU\" style=\"max-width: 220px; display: inline\" \/>\n<img src=\"https:\/\/matplotlib.org\/_static\/logo2_compressed.svg\" style=\"max-width: 170px; display: inline\"\/>\n<\/center>\n\n- Scikit-Learn is the machine learning package in python, easy to use and easy and no background in machine learning is required to use any algorithm, just the python programming language is required and even..\n\n- The main purpose of sklearn is to provide the core algorithms of machine learning for everyone in a gentle way.\n\n\n\n\n","04fa187c":"## 1.1. Load a pre built dataset \n<a class=\"anchor\" id=\"1.1\"><\/a>\n[Back to Table of Contents](#0.1)","b7b43c0b":"![modelselection](https:\/\/raw.githubusercontent.com\/YouvenZ\/Apprentissage_automatique_cours\/master\/Diapositive14.PNG)","1dd5b94f":"<div class=\"jumbotron\">\n  <h1 class=\"display-4\">This is the end of tutorial of scikit-learn From Zero To Hero Part I.<\/h1>\n  <p class=\"lead\">I hope this notebook helped you understand how scikit-learn works and how it can really  facilitate the construction of predictive models and more. If you have comments or suggestions do not hesitate. I will update this notebook with new examples when I have time.<\/p>\n  <hr class=\"my-4\">\n  <p>In the next tutorials we will tackle Classification models with scikit-learn.<\/p>\n<\/div>","5b795555":"### 2.3 Pipeline API\n\n<a class=\"anchor\" id=\"2.3\"><\/a>\n[Back to Table of Contents](#0.1)","23f2f05b":"<a class=\"anchor\" id=\"0.1\"><\/a>\n# Table of contents\n\n\n\n1. [Load or create a dataset with Sklearn](#1)\n\n    - 1.1 [Load a pre built dataset](#1.1)\n      \n    \n2. [The 3 main API in sklearn](#2)\n\n   - 2.1 [Estimator API](#2.1)\n   - 2.2 [Transformer API](#2.2)\n   - 2.3 [Pipeline API](#2.3)\n   \n   \n   \n\n3. [Classic training workflow with scikit-learn](#3)\n\n   - 3.1. [Study case: MNIST dataset and SVM classifier](#3.1)\n   - 3.2 [Study case: Iris dataset and MLP classifier](#3.2)\n   \n   \n   \n   \n\n\n4. [Classic modele selection workflow with scikit learn](#4)\n\n   - 4.1 [Introduction to cross validation](#4.1)\n   - 4.2 [Native approaches to hyperparameter selection vs. optimized search with RandomizedSearchCV](#4.2)\n\n","65e2a4c5":"__Model selection and evaluation:__\n\n* Cross-validation\n* Grid-search\n* Lots of metrics\n","8897ba95":"## Overview of what scikit-learn propose","c59cd6a4":"<div class=\"alert alert-warning\" role=\"alert\">\n  <h4 class=\"alert-heading\">Here we have introduced the confusion matrix<\/h4>\n  <p>\ud83d\udca1 During project in data science with often use multiple models in our pipeline. But those models have parameters.And in order to find the best models we need to find the best parameters according to our data.<\/p>\n  <hr>\n<\/div>\n\n\n\n\nWe could do this by just using for loops but that will become hard if you have a lot a parameters to twick. Fortunetly sklearn give us a way to test a range different parameters directly in our pipeline. To illustrate what we just introduced we will use a KNN model and find the best K \"by hand\" with a for loop, then apply the GridSearch method provided by sklearn to our problem to automatically find the best K within a cross validation with a little amount of code.","212fb2aa":"![estimatorapi](https:\/\/raw.githubusercontent.com\/YouvenZ\/Apprentissage_automatique_cours\/master\/Diapositive12.PNG)","83f2e259":"### 2.1 Estimator API\n<a class=\"anchor\" id=\"2.1\"><\/a>\n[Back to Table of Contents](#0.1)","6eeceee8":"### 2.2 Transformer API\n<a class=\"anchor\" id=\"2.2\"><\/a>\n[Back to Table of Contents](#0.1)","5fdfa8e2":"### 3.1 Study case: MNIST dataset and SVM classifier\n<a class=\"anchor\" id=\"3.1\"><\/a>\n[Back to Table of Contents](#0.1)","0dcce5d7":"<center>  \n    <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/05\/Scikit_learn_logo_small.svg\/langfr-440px-Scikit_learn_logo_small.svg.png\" width=\"40%\" \/>\n    <br \/>\n<\/center>","fc634413":"## How the data should be in order to be used in sklearn ?  \nThe input data should be a Numpy arrays or Scipy sparse matrices or pandas dataframe.    \n\n### Loading external data\n   - Numpy provides us [simple tools](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/routines.io.html) to read file (CSV, binary, etc) __ie #np.load(file)__\n   - For structured data, Pandas provides us [advanced tools](http:\/\/pandas.pydata.org\/pandas-docs\/stable\/io.html) (CSV, JSON, Excel, HDF5, SQL, etc); \n    __ie#pd.read_csv(file)__\n    \n### Loading internal data\n   - With scikit learn we can create toy dataset for regression or classification problem or load direclty pre build dataset contained in the scikit-learn package. ","ed39a242":"## 1. Load or create a dataset with Sklearn \n<a class=\"anchor\" id=\"1\"><\/a>\n\nIn scikit-learn we can load pre build dataset or create toy dataset for classification or regression models. In the following example we will use a famous dataset, the boston house price. In the next tutorial we will see how we can generate a dataset for classification.\n\n[Back to Table of Contents](#0.1)","bc4a8e7a":"Cross Validation is used to assess the predictive performance of the models and and to judge how they perform outside the sample to a new data (test set)\n\nThe motivation to use cross validation techniques is that when we fit a model, we are fitting it to a training dataset. Without cross validation we only have information on how does our model perform to our in-sample data. This approach could bring severe issues in term of biais in the unseen set. Because our split train\/test could not have the same distribution, moreover this affect is amplified when we do have a little amount of data or large number of classes.\n\nThere two types of cross validation you can perform: leave one out and k fold. The former may be more computationally demanding.\n\nTo illustrate what we just introduced will first use __KNN with a basic split__ then a __KNN with K-fold cross validation with 5 fold.__ ","9c0d5fd0":"## 4. Classic modele selection workflow with scikit learn\n<a class=\"anchor\" id=\"4\"><\/a>\n[Back to Table of Contents](#0.1)","9a3085b4":"<div class=\"jumbotron\">\n  <h1 class=\"display-4\"><h1>Zero to Hero with scikit learn: Part I<\/h1><\/h1>\n  <p class=\"lead\">This tutorial will be giving a first introduction of scikit learn. In order to use this tutorial you should have some knowledge of the python programming but no more. During the next tutorial we will go deeper in term of machine learning methods and explaination of those.<\/p>\n  <hr class=\"my-4\">\n  <hr class=\"my-4\">\n  <p>Understand and use scikit-learn \ud83d\udd8b<\/p>\n<\/div>","f548aaf8":"### 4.1 Introduction to cross validation\n<a class=\"anchor\" id=\"4.1\"><\/a>\n[Back to Table of Contents](#0.1)","2b87f41a":"<center>\n    <img src=\"https:\/\/raw.githubusercontent.com\/YouvenZ\/Apprentissage_automatique_cours\/master\/Diapositive10.PNG\" width=\"80%\" \/>\n    <br \/>\n<\/center>\nIn order to use cross validation in sklearn we will use the following codes (the second is shorter), we decided to go for 5 fold as presented in the image.","a3fe8a9c":"### 4.2 Native approaches to hyperparameter selection vs. optimized search with RandomizedSearchCV\n\n<a class=\"anchor\" id=\"4.2\"><\/a>\n[Back to Table of Contents](#0.1)","fa4cf860":"```python\nclass Pipeline(Transformer):\n    \n    @property \n    def named_steps(self):\n        \"\"\" return a sequence of estimators\"\"\"\n        return self.steps\n    \n    def final_estimator(self):\n        \n        \"\"\" return the last estimator\n        \"\"\"\n        return self.steps[-1]\n    ```","2e1af332":"```python\nclass Estimator(...):\n    \"\"\"\n    y: Target matrixe\n    X: Feature matrixe\n    hp_1,...,hp_i: Hyperparameters 1,...,Hyperparameters i\n    \"\"\"\n    \n    def __init__(self, hp_1, ..):\n        \"\"\" set the hyperparameters of the given model picked\"\"\"\n        self.hp_1,... = hp_1,...\n        \n    def fit(self,X,y):\n        \"\"\" Calculate the decision function based on the data in input \"\"\"\n        self.fit_attribut_\n        return self\n    \n    def predict(self,X):\n        \"\"\" Predict target matrixe based on feature matrixe\"\"\"\n        ...\n        return pred\n    \n    def score(self,X,y):\n        \"\"\"Return R square for regression model and accuracy for classification models\n        \"\"\"\n        ...\n        return clas_score\n    \n        ...\n        return reg_score\n    \n    def our_defined_method(self,..):\n        \"\"\"Your own specific method \n        \"\"\"\n        ...\n            ...\n        ...\n    \n```\n","e17d6e60":"This was a simple overview of what we can do with scikit-learn to get more details go directly check they website very well documented [[link](https:\/\/scikit-learn.org\/stable\/index.html)]","e5cfa0a0":"```python\nclass Transformer(Estimator):\n    \n    ...\n    ...\n    def transform(self,X):\n        \n        \"Apply the transformation to the given input data\"\n```        \n        \nSince the Transformator API inherit from the Estimator API. The same logic will be used with transformer object. We need to specify some parameters according to the transformation that we want in order to create or object and ```.fit``` the data into the transformer object. Instead of predicting after fitting we will use the method ```.transform```to our object with input data in parameter.\n        ","667c9356":"### 3.2 Study case: Iris dataset and MLP classifier\n<a class=\"anchor\" id=\"3.2\"><\/a>\n[Back to Table of Contents](#0.1)","1993892c":"## 2. The 3 main API in sklearn\n<a class=\"anchor\" id=\"2\"><\/a>\n[Back to Table of Contents](#0.1)","6038f213":"![estimatorapi](https:\/\/raw.githubusercontent.com\/YouvenZ\/Apprentissage_automatique_cours\/master\/Diapositive11.PNG)","263e1b2c":"__Supervised learning:__\n\n* Support Vector Machines.\n* Linear regression.\n* Logistic regression.\n* Naive Bayes.\n* Linear discriminant analysis.\n* Decision trees.\n* K-nearest neighbor algorithm.\n* Neural Networks (Multilayer perceptron)","6a96cf92":"We also have the same idea here, the pipeline API directly inherite from the transformer API which was itself inheriting from the estimator API. So in the pipeline during the different steps ```.fit``` and ```.transform``` method can explicitly be used during the training. That will make our whole pipeline simpler and flexible.","e50965bc":"# Librairies required for this tutoral \ud83d\udcda","dd96b272":"## 3. Classic training workflow with scikit-learn\n<a class=\"anchor\" id=\"3\"><\/a>\n[Back to Table of Contents](#0.1)"}}