{"cell_type":{"5455d6a8":"code","1974a3bf":"code","3eb630a7":"code","e19e63a0":"code","16165ba2":"code","024f8eec":"code","8b3d08b2":"code","acfcc439":"code","22e32515":"code","389ca3a6":"code","5d7da768":"code","a9ba7b90":"code","f28466d1":"code","6d912547":"code","7ec11bd7":"code","af4a354a":"code","bebb2101":"code","5dc42d57":"code","063f73b5":"code","91e91c61":"code","9fc6ddb3":"code","7850a9b9":"code","8b9dd657":"code","1889d6a5":"code","6c31b039":"code","14a6098e":"code","1cd74234":"code","0f74f5de":"code","85a5dea1":"code","fc760c75":"code","d138decf":"code","76a2ba83":"code","28c77410":"code","799f90f4":"code","0eb599a0":"code","4e1e4810":"code","96769bef":"code","94d3bc3f":"code","e1432315":"code","a4599c72":"code","7c757230":"code","7b05615d":"code","7cca91ad":"code","a5e45d4a":"code","4dfd93e5":"code","6f09dd0e":"code","aa1f7c74":"code","69de6777":"code","71a1db39":"code","3be73557":"code","6637909c":"code","0cb66fc7":"code","19568d72":"code","c84403e4":"code","c8ccb5bf":"code","7e0083f6":"code","9685c59a":"code","4ca9d160":"code","cd0aa700":"code","19fd25c7":"code","e8fefeab":"code","4f43375d":"code","966c3dd9":"code","34518b94":"code","6e5b6929":"code","1ee3500c":"code","4008566e":"code","aaca27b5":"code","202de46a":"code","99e3904f":"code","e18ccba4":"code","2dbfd5d3":"code","0b575312":"code","34ddae3f":"code","d2ab80a5":"code","061982d2":"code","bb5703b8":"code","46cda9f8":"code","73bbeacf":"code","f641d4ca":"code","d6f1c70e":"code","e86cf919":"code","c6baeebf":"code","01ab4086":"code","4ab8ce67":"code","d27e0382":"markdown","e95b3696":"markdown","2c3d44b3":"markdown","c8b51372":"markdown","01c8f537":"markdown","dc96c932":"markdown","52e67047":"markdown","accd7611":"markdown","52104380":"markdown","37921647":"markdown","7c7ef680":"markdown","43f32644":"markdown","0a40b16d":"markdown","069a6c3e":"markdown","ed4c26c8":"markdown","d06b8744":"markdown","6b387bef":"markdown","107ccbf8":"markdown","1d9a9250":"markdown","42207498":"markdown","34a439d4":"markdown","02f148e4":"markdown","175fa045":"markdown","0831423c":"markdown","2799ae01":"markdown","0e592843":"markdown","525cf0cf":"markdown","47ba9858":"markdown","9b514ccd":"markdown","05d18543":"markdown","c4e861af":"markdown","58f966a9":"markdown","472a41f0":"markdown"},"source":{"5455d6a8":"from IPython.display import Image\nImage(url= \"https:\/\/i.ytimg.com\/vi\/1PhMWUoPDsk\/maxresdefault.jpg\")","1974a3bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in\nfrom __future__ import print_function\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import Conv1D, GlobalMaxPooling1D\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3eb630a7":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nsurvived = train_df['Survived']\npassenger_id = test_df['PassengerId']","e19e63a0":"submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\nsubmission.head()","16165ba2":"# print first five rows\ntrain_df.head()","024f8eec":"# print first five rows\ntest_df.head()","8b3d08b2":"print(train_df.shape)\nprint(test_df.shape)","acfcc439":"train_df.info()","22e32515":"test_df.info()","389ca3a6":"print(train_df.isnull().sum())\nprint(test_df.isnull().sum())","5d7da768":"# The plots gives a good idea about the basic data distribution of any of the attributes.\ntrain_df.hist(bins=15, color='steelblue', edgecolor='black', linewidth=1.0,\n           xlabelsize=8, ylabelsize=8, grid=False)    \nplt.tight_layout(rect=(0, 0, 1.2, 1.2))   ","a9ba7b90":"# The plots gives a good idea about the basic data distribution of any of the attributes.\ntest_df.hist(bins=15, color='steelblue', edgecolor='black', linewidth=1.0,\n           xlabelsize=8, ylabelsize=8, grid=False)    \nplt.tight_layout(rect=(0, 0, 1.2, 1.2))   ","f28466d1":"def bar_chart(feature):\n    survived = train_df[train_df['Survived']==1][feature].value_counts()\n    dead = train_df[train_df['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","6d912547":"bar_chart('Sex')","7ec11bd7":"bar_chart('Pclass')","af4a354a":"bar_chart('SibSp')","bebb2101":"bar_chart('Parch')\n","5dc42d57":"bar_chart('Embarked')","063f73b5":"train_df.head()","91e91c61":"train_test_data = [train_df, test_df] # combining train and test dataset\nprint(train_test_data)\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","9fc6ddb3":"train_df['Title'].value_counts()\n","7850a9b9":"test_df['Title'].value_counts()\n","8b9dd657":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","1889d6a5":"train_df.head()","6c31b039":"test_df.head()","14a6098e":"bar_chart('Title')","1cd74234":"# delete unnecessary feature from dataset\ntrain_df.drop('Name', axis=1, inplace=True)\ntest_df.drop('Name', axis=1, inplace=True)","0f74f5de":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","85a5dea1":"bar_chart('Sex')","fc760c75":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain_df[\"Age\"].fillna(train_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest_df[\"Age\"].fillna(test_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","d138decf":"train_df.groupby(\"Title\")[\"Age\"].transform(\"median\")\n","76a2ba83":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_df['Age'].max()))\nfacet.add_legend()\n \nplt.show()","28c77410":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_df['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","799f90f4":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_df['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","0eb599a0":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_df['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","4e1e4810":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_df['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","96769bef":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_df['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","94d3bc3f":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","e1432315":"train_df.head()","a4599c72":"bar_chart('Age')","7c757230":"Pclass1 = train_df[train_df['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train_df[train_df['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train_df[train_df['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","7b05615d":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","7cca91ad":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","a5e45d4a":"# fill missing Fare with median fare for each Pclass\ntrain_df[\"Fare\"].fillna(train_df.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest_df[\"Fare\"].fillna(test_df.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain_df.head(5)","4dfd93e5":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train_df['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","6f09dd0e":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train_df['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","aa1f7c74":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train_df['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","69de6777":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train_df['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","71a1db39":"train_df.head()\n","3be73557":"train_df.Cabin.value_counts()\n","6637909c":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","0cb66fc7":"Pclass1 = train_df[train_df['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train_df[train_df['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train_df[train_df['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","19568d72":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","c84403e4":"# fill missing Fare with median fare for each Pclass\ntrain_df[\"Cabin\"].fillna(train_df.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest_df[\"Cabin\"].fillna(test_df.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","c8ccb5bf":"train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntest_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1","7e0083f6":"train_df.loc[train_df['FamilySize'] <= 0.0,'IsAlone'] = 0\ntrain_df.loc[train_df['FamilySize'] > 0.0,'IsAlone'] = 1\ntest_df.loc[test_df['FamilySize'] <= 0.0,'IsAlone'] = 0\ntest_df.loc[test_df['FamilySize'] > 0.0,'IsAlone'] = 1","9685c59a":"train_df.head()","4ca9d160":"facet = sns.FacetGrid(train_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train_df['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","cd0aa700":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","19fd25c7":"# Correlation Matrix Heatmap\nf, ax = plt.subplots(figsize=(10, 6))\ncorr = train_df.corr()\nhm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f',\n                 linewidths=.05)\nf.subplots_adjust(top=0.93)\nt= f.suptitle('Wine Attributes Correlation Heatmap', fontsize=14)","e8fefeab":"test_df.head()","4f43375d":"train_df.head()","966c3dd9":"# Pair-wise Scatter Plots\ncols = ['Title', 'Sex', 'Cabin', 'Pclass']\npp = sns.pairplot(train_df[cols], size=1.8, aspect=1.8,\n                  plot_kws=dict(edgecolor=\"k\", linewidth=0.5),\n                  diag_kind=\"kde\", diag_kws=dict(shade=True))\n\nfig = pp.fig \nfig.subplots_adjust(top=0.93, wspace=0.3)\nt = fig.suptitle('Titanic Attributes Pairwise Plots', fontsize=14)","34518b94":"features_drop = ['Ticket', 'Parch', ]\n# features_drop = ['Pclass', 'Fare', 'Cabin', 'Ticket']\n\ntrain_df = train_df.drop(features_drop, axis=1)\ntest_df = test_df.drop(features_drop, axis=1)\ntrain_df = train_df.drop(['PassengerId'], axis=1)","6e5b6929":"train_df.head()","1ee3500c":"train_data = train_df.drop('Survived', axis=1)\ntarget = train_df['Survived']\n\ntrain_data.shape, target.shape","4008566e":"train_df.info()","aaca27b5":"test_df.info()","202de46a":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","99e3904f":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","e18ccba4":"round(np.mean(score)*100, 2)","2dbfd5d3":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","0b575312":"# decision tree Score\nround(np.mean(score)*100, 2)","34ddae3f":"rand_clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","d2ab80a5":"# Random Forest Score\nround(np.mean(score)*100, 2)","061982d2":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","bb5703b8":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","46cda9f8":"svm = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","73bbeacf":"round(np.mean(score)*100,2)","f641d4ca":"svm = SVC()\nclf.fit(train_data, target)\n\ntest_data = test_df.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","d6f1c70e":"# fit model no training data\nmodel = XGBClassifier()\nmodel.fit(train_data, target)","e86cf919":"# make predictions for test data\ny_pred = clf.predict(test_data)\npredictions = [round(value) for value in y_pred]","c6baeebf":"# turn run_gs to True if you want to run the gridsearch again.\nrun_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [4, 6, 8],\n                 'n_estimators': [50, 10],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [2, 3, 10],\n                 'min_samples_leaf': [1, 3, 10],\n                 'bootstrap': [True, False],\n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(n_splits=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation,\n                               verbose=1\n                              )\n\n    grid_search.fit(train_data, target)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\n    \nelse: \n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    model = RandomForestClassifier(**parameters)\n    model.fit(train_data, target)\n","01ab4086":"output = model.predict(test_data).astype(int)","4ab8ce67":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": output\n    })\n\nsubmission.to_csv('submission.csv', index=False)","d27e0382":"# 2. Collecting the data","e95b3696":"# 3. Exploratory data analysis","2c3d44b3":"Feature Sex\n- male: 0,  female: 1","c8b51372":"# 1. Defining the problem statement","01c8f537":"Bar Chart for Categorical Features\n- Pclass\n- Sex\n- SibSp ( # of siblings and spouse)\n- Parch ( # of parents and children)\n- Embarked\n- Cabin","dc96c932":"# Embarked\n**filling missing values**","52e67047":"# Import required modules","accd7611":"\n- The Chart confirms a person aboarded from C slightly more likely survived\n- The Chart confirms a person aboarded from Q more likely dead\n- The Chart confirms a person aboarded from S more likely dead","52104380":"# Fare","37921647":"# Name\n","7c7ef680":"- The Chart confirms a person aboarded with more than 2 parents or children more likely survived\n- The Chart confirms a person aboarded alone more likely dead","43f32644":"# SVM","0a40b16d":"# Cabin","069a6c3e":"# Naive Bayes","ed4c26c8":"# Data Dictionary\n- Survived: 0 = No, 1 = Yes\n- pclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n- sibsp: # of siblings \/ spouses aboard the Titanic\n- parch: # of parents \/ children aboard the Titanic\n- ticket: Ticket number\n- cabin: Cabin number\n- embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\nTotal rows and columns\n\nWe can see that there are 891 rows and 12 columns in our training dataset.","d06b8744":"Thanks ...","6b387bef":"# FamilySize","107ccbf8":"**Titanic**: Machine Learning from Disaster\n- **Predict survival on the Titanic**\n- **Defining the problem statement**\n-  **Collecting the data**\n- **Exploratory data analysis**\n- **Feature engineering**\n- **Modelling**\n- **Testing**","1d9a9250":"The Chart confirms Women more likely survivied than Men","42207498":"# 4. Feature engineering\nFeature engineering is the process of using domain knowledge of the data\nto create features (feature vectors) that make machine learning algorithms work.\n\nfeature vector is an n-dimensional vector of numerical features that represent some object.\nMany algorithms in machine learning require a numerical representation of objects,\nsince such representations facilitate processing and statistical analysis.","34a439d4":"- more than 50% of 1st class are from S embark\n- more than 50% of 2nd class are from S embark\n- more than 50% of 3rd class are from S embark\n\nfill out missing embark with S embark","02f148e4":"Converting Numerical Age to Categorical Variable\n\nfeature vector map:\n- child: 0\n- young: 1\n- adult: 2\n- mid-age: 3\n- senior: 4","175fa045":"**Age**\n- some age is missing\n- Let's use Title's median age for missing Age","0831423c":"# Ramdom Forest","2799ae01":"Complete the analysis of what sorts of people were likely to survive.\nIn particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy.","0e592843":"# KNN","525cf0cf":"- The Chart confirms a person aboarded with more than 2 siblings or spouse more likely survived\n- The Chart confirms a person aboarded without siblings or spouse more likely dead","47ba9858":"- The Chart confirms 1st class more likely survivied than other classes\n- The Chart confirms 3rd class more likely dead than other classes","9b514ccd":"# load train, test dataset using Pandas","05d18543":"<h1 style= \"color:red\"> Please UpVote If You find this Kernel helpFul..<\/h1>","c4e861af":"We can see that Age value is missing for many rows.\n\nOut of 891 rows, the Age value is present only in 714 rows.\n\nSimilarly, Cabin values are also missing in many rows. Only 204 out of 891 rows have Cabin values.","58f966a9":"There are 177 rows with missing Age, 687 rows with missing Cabin and 2 rows with missing Embarked information.\n","472a41f0":"# Decision Tree"}}