{"cell_type":{"a3a4c973":"code","e04f6689":"code","8ef3da1f":"code","167410f6":"code","9b3fd081":"code","29104a12":"code","fe13d2ae":"code","8e9a4c19":"code","ab99a75d":"code","fa7b4f62":"code","c034f3b0":"code","8a7125d1":"code","fcd1cabe":"code","3677b2c9":"code","a5e3a47b":"code","bef7684e":"code","d018cd41":"code","690ebf82":"code","b6f40f86":"code","a855cf66":"code","247b0280":"code","0835b4d7":"code","96ff8fff":"code","dbde57a4":"code","10f59588":"code","e926a9d0":"code","6b900752":"code","3a7a5f91":"code","d4ccc9bd":"code","7d64a9f2":"code","55d11c6a":"code","662b5c1b":"code","0296cc2d":"code","d8519b50":"code","30e6b8f0":"code","7f382406":"code","80a603d3":"code","809faac8":"code","62aa7cca":"code","1d322430":"markdown","72f3c160":"markdown","cbf94bf1":"markdown","708aeb45":"markdown","f43e23e7":"markdown","bce1c76b":"markdown","44120d81":"markdown","1376bb02":"markdown","ec4610ca":"markdown","4fc2e35f":"markdown","a8e99db8":"markdown","811263d9":"markdown","f8c93b02":"markdown","bf134495":"markdown","0140b0aa":"markdown","050eb12a":"markdown","bfa3e12b":"markdown"},"source":{"a3a4c973":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e04f6689":"# Importing the libraries \nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns","8ef3da1f":"\n# Importing the Boston Housing dataset\nfrom sklearn.datasets import load_boston\nboston = load_boston()\n","167410f6":"# Initializing the dataframe\ndata = pd.DataFrame(boston.data)","9b3fd081":"# Adding feature name to the dataframe\ndata.columns = boston.feature_names","29104a12":"# the upper 5 data\ndata.head()","fe13d2ae":"# the lower 5 data\ndata.tail()","8e9a4c19":"data.shape","ab99a75d":"data.columns","fa7b4f62":"data.dtypes","c034f3b0":"data.info()","8a7125d1":"data.isnull().sum()","fcd1cabe":"data['CRIM'].unique()","3677b2c9":"data['ZN'].unique()","a5e3a47b":"data['INDUS'].unique()","bef7684e":"data['NOX'].unique()","d018cd41":"data['RM'].unique()","690ebf82":"data['AGE'].unique()","b6f40f86":"data['DIS'].unique()","a855cf66":"data['RAD'].unique()","247b0280":"data['PTRATIO'].unique()","0835b4d7":"data['B'].unique()","96ff8fff":"data['LSTAT'].unique()","dbde57a4":"# Assign the target column\ndata['PRICE'] = boston.target ","10f59588":"# Shows the statistical summary\ndata.describe()","e926a9d0":"data.CRIM.quantile(0.999)","6b900752":"cor=data.corr()\n#Heatmap for visualisation of correlation analysis\nplt.figure(figsize=(10,8))\nsns.heatmap(cor,annot=True,cmap='coolwarm')\n#when we write annot= True , it shows the values .\nplt.show()","3a7a5f91":"x=data[['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']]\ny=data['PRICE']","d4ccc9bd":"# split data into train and test\nfrom sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts = train_test_split(x,y,test_size=0.2)\n# we have to split the data into 80% as train and 20% as test so we have specified test_size as 0.2\nprint(x.shape)\nprint(xtr.shape)\nprint(xts.shape)\nprint(y.shape)\nprint(ytr.shape)\nprint(yts.shape)","7d64a9f2":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(xtr, ytr)","55d11c6a":"y_pred = regressor.predict(xts)","662b5c1b":"#calculating r2score\nfrom sklearn.metrics import r2_score\nr2_score(yts,y_pred)","0296cc2d":"#To find the error\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(yts,y_pred)","d8519b50":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(yts,y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","30e6b8f0":"# Import Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Create a Random Forest Regressor\nreg = RandomForestRegressor()\n\n# Train the model using the training sets \nreg.fit(xtr, ytr)","7f382406":"y_pred = reg.predict(xts)","80a603d3":"r2_score(yts,y_pred)","809faac8":"mean_squared_error(yts,y_pred)","62aa7cca":"# Visualizing the differences between actual prices and predicted values\nplt.scatter(yts,y_pred)\nplt.xlabel(\"Prices\")\nplt.ylabel(\"Predicted prices\")\nplt.title(\"Prices vs Predicted prices\")\nplt.show()","1d322430":"so we have applied two algorithem one is multiple linear regression and the other is random forest regressor algorithm .\nIncase of multiple linear regression we got 76% accuracy and in case of random forest the accuracy is 91% . \nthe performance of second model is good so we can use this model to predict the price of the house .","72f3c160":"From the above observation it is clear that there is no missing values in the data set .","cbf94bf1":"From the above analysis we can observe that 75% of CRIM values are below 3.677083 but the max value is 88.976200 , so there nay be some wrong entry exist in the dataset","708aeb45":"### details of the features:\n- CRIM per capita crime rate by town \n- ZN proportion of residential land zoned for lots over 25,000 sq.ft. \n- INDUS proportion of non-retail business acres per town \n- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n- NOX nitric oxides concentration (parts per 10 million) \n- RM average number of rooms per dwelling \n- AGE proportion of owner-occupied units built prior to 1940 \n- DIS weighted distances to five Boston employment centres \n- RAD index of accessibility to radial highways \n- TAX full-value property-tax rate per 10,000usd \n- PTRATIO pupil-teacher ratio by town \n- B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n- LSTAT % lower status of the population \n\nEach record in the database describes a Boston suburb or town.","f43e23e7":"From the above analysis we can onserve that the attributes are having a good correlation value with each other .\nHence there exist some linear relation among the attributes so we can apply linear regression in this case. ","bce1c76b":"- In this project we are given with a dataset having 506 rows and 13 attributes (features) with a target column (price). \n- The features describe a house in Boston.\n- We have to prepare a machine learning model that will predict the house price.\n- To train our machine learning model with boston housing data, we will be using scikit-learn\u2019s boston dataset.","44120d81":"#  Applying Random Forest Regressor algorithm","1376bb02":"# Evaluating the model","ec4610ca":"#  **Boston House Price Predict**","4fc2e35f":"# Evaluating the model","a8e99db8":"# Spliting the dataset","811263d9":"# Visualisation of data","f8c93b02":"# Importing dataset","bf134495":"As the 99 percentile data of the column has the value 81 so we can say that there is no incorrect entry in the dataset","0140b0aa":"# Applying simplelinearregression algorithm","050eb12a":"# Aanalysis of data","bfa3e12b":"# Importing libraries"}}