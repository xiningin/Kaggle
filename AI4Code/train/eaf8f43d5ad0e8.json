{"cell_type":{"eddcd45b":"code","71bd32f2":"code","8789f99d":"code","751a57ac":"code","ef418b7c":"code","beffd5c7":"code","a33ce181":"code","160ab735":"code","b44f7024":"code","dec01461":"code","71620308":"code","f7990fb9":"code","c7e0c3d4":"code","d01e2d2d":"code","0172f87c":"code","4c68b1a9":"code","8169481a":"code","29fb8d12":"code","aa49612f":"code","dc16d9e1":"code","02d8494d":"code","08f28399":"code","38a64d9f":"code","c93977d9":"code","1934b176":"markdown","8e1d8093":"markdown","d0f9049c":"markdown","f2bda016":"markdown","4a651b01":"markdown"},"source":{"eddcd45b":"!pip install swifter","71bd32f2":"import re\nimport string\nimport swifter\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nsns.set(rc={'figure.figsize':(10,6)})\nsns.set(font_scale=1.3)\nplt.style.use('fivethirtyeight')\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.initializers import Constant\nfrom keras.layers import (LSTM, Embedding, BatchNormalization, Dense, TimeDistributed, \n                          Dropout, Bidirectional, Flatten,  GlobalMaxPool1D)\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')","8789f99d":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","751a57ac":"train.head()","ef418b7c":"train.info()","beffd5c7":"train.drop(columns=['id','keyword','location'], inplace=True)","a33ce181":"train['text_len'] = train['text'].apply(lambda x: len(x.split(' ')))","160ab735":"values = train['target'].value_counts().values\nfig = go.Figure(data=[go.Pie(labels=['Count 0','Count 1',], values=values)])\nfig.update_layout(template=\"plotly_dark\",title={'text': \"Count of Type\",'y':0.9,\n                                                'x':0.45,'xanchor': 'center','yanchor': 'top'},\n                  font=dict(size=18, color='white', family=\"Courier New, monospace\"))\nfig.show()","b44f7024":"fig = px.histogram(train, x='text_len')\nfig.update_layout(template=\"plotly_dark\",title={'text': \"Phrase Length\",'y':0.9,\n                                                'x':0.45,'xanchor': 'center','yanchor': 'top'},\n                  font=dict(size=18, color='white', family=\"Courier New, monospace\"))\nfig.show()","dec01461":"train = train[train['text_len'] <=31]","71620308":"fig = px.histogram(train, x='text_len')\nfig.update_layout(template=\"plotly_dark\",title={'text': \"Phrase Length\",'y':0.9,\n                                                'x':0.45,'xanchor': 'center','yanchor': 'top'},\n                  font=dict(size=18, color='white', family=\"Courier New, monospace\"))\nfig.show()","f7990fb9":"def text_clear(data):\n    tx = data.apply(lambda x: x.lower())\n    tx = tx.apply(lambda x: re.sub(\"http\\S+\", '', str(x)))\n    tx = tx.swifter.apply(lambda x: re.sub(u'[^a-zA-Z0-9\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00e2\u00ea\u00ee\u00f4\u00c2\u00ca\u00ce\u00d4\u00e3\u00f5\u00c3\u00d5\u00e7\u00c7: ]', '',x))\n    tx = tx.swifter.apply(lambda x: re.sub(' +', ' ', x)) # remover espa\u00e7os em brancos\n    tx = tx.swifter.apply(lambda x: re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', x)) # remover as hashtag\n    tx = tx.swifter.apply(lambda x: re.sub('(@[A-Za-z]+[A-za-z0-9-_]+)', '', x)) # remover os @usuario\n    tx = tx.swifter.apply(lambda x: re.sub('rt', '', x)) # remover os rt\n    tx = tx.swifter.apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n    return tx\n\nnltk.download('stopwords');\nstopwords = stopwords.words('english')\nmore_stopwords = ['u', 'im', 'c']\nstop_words = stopwords + more_stopwords\n\ndef remove_stopwords(text):    \n    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n    return text\n\n\nstemmer = nltk.SnowballStemmer(\"english\")\ndef stemm_text(text):\n    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n    return text","c7e0c3d4":"train['text'] = text_clear(train['text'])\ntrain['text'] = train['text'].apply(remove_stopwords)\ntrain['text'] = train['text'].apply(stemm_text)\n\ntrain.head()","d01e2d2d":"text = train['text']\ntarget = train['target']\n\nword_tokenizer = Tokenizer()\nword_tokenizer.fit_on_texts(text)\n\nvocab_length = len(word_tokenizer.word_index) + 1\nvocab_length","0172f87c":"max_palavra = vocab_length \nembedding_dim = 32","4c68b1a9":"x = word_tokenizer.texts_to_sequences(text)\nx = pad_sequences(x, padding='post')","8169481a":"x_train, x_test, y_train, y_test = train_test_split(x, target, stratify=target)\nprint(len(x_train), len(y_train))\nprint(len(x_test), len(y_test))","29fb8d12":"from sklearn.naive_bayes import MultinomialNB\n\nnb = MultinomialNB()\n\nnb.fit(x_train, y_train)\npred = nb.predict(x_test)\nacc = accuracy_score(y_test, pred)\nprint('Acuracy:', acc*100)\nplot_confusion_matrix(nb, x_test, y_test);\nplt.grid(False)\nplt.title('Result');","aa49612f":"def modelo():\n    model = Sequential()\n    model.add(Embedding(max_palavra, embedding_dim, input_length=len(x[0])))    \n    model.add(Bidirectional(LSTM(embedding_dim, return_sequences=True, recurrent_dropout=0.2)))    \n    model.add(GlobalMaxPool1D())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(embedding_dim, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(embedding_dim, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return model","dc16d9e1":"model = modelo()\nmodel.summary()","02d8494d":"checkpoint = ModelCheckpoint('model.h5', monitor = 'val_loss', verbose=1, save_best_only = True)\nreduce = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=3, min_lr=0.001)\nstoped = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)","08f28399":"history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test),\n                    verbose=1, callbacks=[reduce, checkpoint, stoped])","38a64d9f":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Acur\u00e1cia')\nplt.legend(['Acur\u00e1cia em Treino','Acur\u00e1cia em Teste'])\nplt.show()","c93977d9":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Erro')\nplt.legend(['Erro em Treino','Erro em Teste'])\nplt.show()","1934b176":"# <p style=\"background-color:#80ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">EDA<\/p>","8e1d8093":"# <p style=\"background-color:#80ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">Model<\/p>","d0f9049c":"# <p style=\"background-color:#80ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">Processing<\/p>","f2bda016":"## Keras","4a651b01":"## Naive Bayes"}}