{"cell_type":{"37edc9bd":"code","ea5b0c64":"code","cfc0d1d3":"code","c55a314a":"code","42373b52":"code","2505c4c6":"code","46d51cda":"code","2404d179":"code","825a5d9e":"code","85ba593a":"code","8bbabcb7":"code","420fa2f1":"code","96f46f0a":"code","555e8ee5":"code","4e795643":"code","5309e08f":"code","5cc8b83b":"code","221d69a6":"code","b50119cd":"code","81ebdeb5":"code","f3018aeb":"code","bc69cad5":"code","80df5bbd":"code","9247b25c":"code","278edc3d":"code","8ac68b09":"code","2e61b15c":"code","563ab2e9":"code","afdeac06":"code","497e20e6":"code","2c91f57b":"code","f71c2cd5":"code","16edb47a":"code","0742c8e3":"code","6215826c":"code","de0fd4d8":"code","a772afc9":"code","46abfb56":"code","0af09d4d":"code","c5de680d":"code","b65e6175":"code","79be051f":"code","01fcc64d":"code","75cae9f3":"code","474c0e7d":"code","32f99a1a":"code","3622cd48":"code","68876b92":"code","1e01f3d0":"code","09339987":"code","8fadcb68":"code","214e409d":"code","a0aee5c5":"code","3aec327d":"code","9b8eaa0f":"code","49963915":"code","c397b96f":"code","40313c2b":"code","0849f5f3":"code","e7ae0f7f":"markdown","5a44d7d0":"markdown","5e01f48e":"markdown","169e91ef":"markdown","913bd20a":"markdown","35c7be33":"markdown","2beacab1":"markdown","bb87b188":"markdown","98685b2d":"markdown","01f4deb2":"markdown","8a0c8b3a":"markdown","eeda83b3":"markdown","fec6f1d4":"markdown","848b7e6f":"markdown","76668f84":"markdown","84213223":"markdown","46aab4fa":"markdown","f0bc77ae":"markdown","b1be22db":"markdown","b68a4fc8":"markdown"},"source":{"37edc9bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea5b0c64":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom itertools import product\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans","cfc0d1d3":"marketing_campaign = pd.read_csv('\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv', sep='\\t')\nmarketing_campaign.head()","c55a314a":"marketing_campaign.info()","42373b52":"marketing_campaign.describe()","2505c4c6":"var = 'Response'\nsns.countplot(x=var, data=marketing_campaign)\nprint(marketing_campaign[var].value_counts())","46d51cda":"var = 'Age'\nmarketing_campaign[var] = ((2021 - marketing_campaign['Year_Birth']) \/\/ 10) * 10\nprint(marketing_campaign[var].value_counts())\nsns.countplot(x=var, data=marketing_campaign)","2404d179":"marketing_campaign.query('Age >= 80')['Response'].value_counts()","825a5d9e":"mkt_campaign = marketing_campaign.copy()\nmkt_campaign = mkt_campaign.query('Age < 80').drop(['Year_Birth'], axis=1)\nprint(mkt_campaign['Age'].value_counts())\nmkt_campaign.head()","85ba593a":"# Recency\nfig, axes = plt.subplots(1, 2, figsize=(10, 3))\nvar = 'Recency'\nsns.histplot(x=var, data=mkt_campaign, kde=True, ax=axes[0])\n\nres0 = mkt_campaign.query('Response==0')\nres1 = mkt_campaign.query('Response==1')\n\nsns.histplot(x=var, data=res0, kde=True, bins=20, ax=axes[1])\nsns.histplot(x=var, data=res1, bins=20, ax=axes[1])","8bbabcb7":"# Frequency\nfig, axes = plt.subplots(1, 2, figsize=(10, 3))\nvar = 'NumWebVisitsMonth'\nsns.histplot(x=var, data=mkt_campaign, kde=True, ax=axes[0], bins=20)\n\nres0 = mkt_campaign.query('Response==0')\nres1 = mkt_campaign.query('Response==1')\n\nsns.histplot(x=var, data=res0, kde=True, bins=20, ax=axes[1])\nsns.histplot(x=var, data=res1, bins=20, ax=axes[1])","420fa2f1":"# Monetary\n\n# we get the colname \nNum_col = [colname for colname in mkt_campaign.columns if colname.startswith('Mnt')]\n\nmkt_campaign['M_total'] = np.sum(mkt_campaign[Num_col], axis=1)\nsns.histplot(x='M_total', data=mkt_campaign, kde=True)","96f46f0a":"axis_cord = product([0, 1], [0 ,1, 2])\nfig, axes = plt.subplots(2, 3, figsize=(13, 6), sharey=True, sharex=True)\n\nfor idx, col_name in zip(axis_cord, Num_col):\n    res0 = mkt_campaign.query('Response==0')\n    res1 = mkt_campaign.query('Response==1')\n    \n    axes[idx[0], idx[1]].hist(res0[col_name], label=f'{col_name}_Res0')\n    axes[idx[0], idx[1]].hist(res1[col_name], label=f'{col_name}_Res1')\n    axes[idx[0], idx[1]].legend()\n    axes[idx[0], idx[1]].set_title(f'{col_name}')\n\nplt.tight_layout()","555e8ee5":"# RFM DataFrame\nrfm = mkt_campaign[['ID', 'Recency', 'NumWebVisitsMonth', 'M_total']].set_index('ID')\nrfm.columns = ['Recency', 'Frequency', 'Monetary']\nrfm.head()","4e795643":"# Use quantile to split and rank customers with 1~4\nthreshold = rfm.quantile([0.25, 0.5, 0.75]).to_dict()\nthreshold","5309e08f":"# recency is opposit. the less recency is, the more rank is\ndef FM_rank(val, col, dict):\n    if dict[col][0.25] > val:\n        return 4\n    elif dict[col][0.5] > val:\n        return 3\n    elif dict[col][0.75] > val:\n        return 2\n    else:\n        return 1\n\ndef R_rank(val, col, dict):\n    if dict[col][0.25] > val:\n        return 1\n    elif dict[col][0.5] > val:\n        return 2\n    elif dict[col][0.75] > val:\n        return 3\n    else:\n        return 4","5cc8b83b":"rfm['R_rank'] = rfm['Recency'].apply(R_rank, args=('Recency', threshold))\nrfm['F_rank'] = rfm['Frequency'].apply(FM_rank, args=('Frequency', threshold))\nrfm['M_rank'] = rfm['Monetary'].apply(FM_rank, args=('Monetary', threshold))\nrfm['RFM_Score'] = rfm['R_rank'].astype(str) + rfm['F_rank'].astype(str) + rfm['M_rank'].astype(str)","221d69a6":"rfm.head(10)","b50119cd":"rfm_with_res = rfm.merge(mkt_campaign[['ID', 'Response']], on='ID').set_index('ID')\nrfm_with_res = rfm_with_res.drop(['Recency', 'Frequency', 'Monetary'], axis=1)\nrfm_with_res.head()","81ebdeb5":"# Each R, F, M \nvar = 'R_rank'\nres1 = rfm_with_res.query('Response==1')\nprint('Number')\nprint(res1[var].value_counts())\nprint('-'*10)\nprint('Rate')\nprint(res1[var].value_counts() \/ len(rfm_with_res[var]))\nsns.countplot(x=var, data=res1)","f3018aeb":"# Each R, F, M \nvar = 'F_rank'\nres1 = rfm_with_res.query('Response==1')\nprint('Number')\nprint(res1[var].value_counts())\nprint('-'*10)\nprint('Rate: each rank which res==1 devide each rank which res==1 and 0')\nprint(res1[var].value_counts() \/ len(rfm_with_res[var]))\nsns.countplot(x=var, data=res1)","bc69cad5":"# Each R, F, M \nvar = 'M_rank'\nres1 = rfm_with_res.query('Response==1')\nprint('Number')\nprint(res1[var].value_counts())\nprint('-'*10)\nprint('Rate')\nprint(res1[var].value_counts() \/ len(rfm_with_res[var]))\nsns.countplot(x=var, data=res1)","80df5bbd":"# matplot to show the number above bars\ndef autolabel(rects, xpos='center'):\n    \"\"\"\n    Attach a text label above each bar in *rects*, displaying its height.\n\n    *xpos* indicates which side to place the text w.r.t. the center of\n    the bar. It can be one of the following {'center', 'right', 'left'}.\n    \"\"\"\n    \n    offset = {'center': 0, 'right': 1, 'left': -1}\n\n    for rect in rects:\n        height = rect.get_height()\n        plt.annotate(f'{height:.2f}%',\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(offset[xpos]*3, 3),  # use 3 points offset\n                    textcoords=\"offset points\",  # in both directions\n                    va='bottom')","9247b25c":"var = 'RFM_Score'\nres1 = rfm_with_res.query('Response==1')\ntop10_RFM = (res1[var].value_counts() \/ len(rfm_with_res) * 100)[:10] # top 10 RFM\n\nfigure = plt.figure(figsize=(8, 6))\nplt.title('RFM TOP 10 and Rates')\nrects = plt.bar(top10_RFM.index, top10_RFM.values)\nautolabel(rects, 'left')","278edc3d":"mkt_cmp_rfm = mkt_campaign.merge(rfm_with_res, on=['ID', 'Response'])\nmkt_cmp_rfm = mkt_cmp_rfm.drop(['Recency', 'NumWebVisitsMonth'], axis=1) # we can replace those column cuz we can use the rank\nmkt_cmp_rfm.head()","8ac68b09":"# Income has outliers so we drop them\n# we drop the customer's income are more than mean \u00b1 3 * std (You can use zscore, of course!)\nvar = 'Income'\n# stats.zscore\nincome_mean, income_std = mkt_cmp_rfm[var].mean(), mkt_cmp_rfm[var].std()\n# check the amount\nprint('Percentage is: ')\nlen(mkt_cmp_rfm.query('@income_mean - 3*@income_std > Income or @income_mean + 3*@income_std < Income')) \/ len(mkt_cmp_rfm) * 100","2e61b15c":"# drop the outliers!\nleft = income_mean - 3*income_std\nright = income_mean + 3*income_std\nmkt_cmp_rfm = mkt_cmp_rfm.query('@left < Income < @right')","563ab2e9":"mkt_cmp_rfm.columns","afdeac06":"indices = ['Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome',\n       'MntWines', 'MntFruits', 'MntMeatProducts',\n       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n       'NumStorePurchases', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5',\n       'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Z_CostContact',\n       'Z_Revenue', 'Response', 'Age', 'M_total', 'R_rank', 'F_rank', 'M_rank',\n       'RFM_Score']","497e20e6":"data = mkt_cmp_rfm.copy()\ndata = data.sample(frac=1, random_state=123)[indices].reset_index(drop=True) # shuffle the data\ndata.head()","2c91f57b":"# without object col\nindices_int = ['Income', 'Kidhome', 'Teenhome',\n       'MntWines', 'MntFruits', 'MntMeatProducts',\n       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n       'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases',\n       'NumStorePurchases', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5',\n       'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Z_CostContact',\n       'Z_Revenue', 'Response', 'Age', 'M_total', 'R_rank', 'F_rank', 'M_rank',\n       'RFM_Score']","f71c2cd5":"# Elbow method\ndistortions = []\n\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data[indices_int].values)\n\nfor i in range(1, 11):\n   km = KMeans(n_clusters=i, n_init=10, max_iter=300, random_state=0)\n   \n   km.fit(data_scaled)\n   # inertia_\u3067\u6b6a\u307f\u3092\u6570\u5024\u7684\u306b\u8868\u793a\n   distortions.append(km.inertia_)\n   \n\n   \nplt.plot(range(1, 11), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.tight_layout()\nplt.show()","16edb47a":"indices_ = ['Income', 'Kidhome', 'Teenhome',\n       'MntWines', 'MntFruits', 'MntMeatProducts',\n       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', \n       'Age', 'R_rank', 'M_rank']\n\ndata_ = data.sample(frac=1, random_state=123)[indices_].reset_index(drop=True) # shuffle the data\ndistortions = []\n\nscaler = StandardScaler()\ndata_scaled_ = scaler.fit_transform(data_)\n\nfor i in range(1, 11):\n   km = KMeans(n_clusters=i, n_init=10, max_iter=300, random_state=0)\n   \n   km.fit(data_scaled_)\n   # inertia_\u3067\u6b6a\u307f\u3092\u6570\u5024\u7684\u306b\u8868\u793a\n   distortions.append(km.inertia_)\n   \n\n   \nplt.plot(range(1, 11), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.tight_layout()\nplt.show()","0742c8e3":"scaler = StandardScaler()\ndata_scaled_ = scaler.fit_transform(data[indices_])\n\nkm_2 = KMeans(n_clusters=2, n_init=10, max_iter=300, random_state=0)\ny_km2 = km_2.fit_predict(data_scaled_)","6215826c":"# function to show the graph\ndef show_bargraphs(var, figsize=(10, 5), cluster=2, y_km=y_km2):\n    fig, axes = plt.subplots(1, cluster, figsize=figsize, sharey=True)\n    \n    for cls in range(cluster):\n        sns.countplot(x=var, data=data[y_km==cls].sort_values(var), ax=axes[cls])\n        axes[cls].set_title(f'Cluster {cls+1}')","de0fd4d8":"var = 'Education'\nshow_bargraphs(var)","a772afc9":"var = 'Marital_Status'\nshow_bargraphs(var, figsize=(13, 5))","46abfb56":"var = 'Kidhome'\nshow_bargraphs(var)","0af09d4d":"var = 'Teenhome'\nshow_bargraphs(var)","c5de680d":"var = 'Age'\nshow_bargraphs(var)","b65e6175":"var = 'R_rank'\nshow_bargraphs(var)","79be051f":"var = 'M_rank'\nshow_bargraphs(var)","01fcc64d":"# next, we seek the numeric data.\ndef show_distplotgraphs(var, figsize=(10, 5), cluster=2, y_km=y_km2):\n    fig, axes = plt.subplots(1, cluster, figsize=figsize, sharey=True)\n    \n    for cls in range(cluster):\n        sns.histplot(x=var, data=data[y_km==cls].sort_values(var), ax=axes[cls], bins=25)\n        axes[cls].set_title(f'Cluster {cls+1}')","75cae9f3":"var = 'MntWines'\nshow_distplotgraphs(var)","474c0e7d":"km_3 = KMeans(n_clusters=3, n_init=10, max_iter=300, random_state=0)\ny_km3 = km_3.fit_predict(data_scaled_)\n\nvar = 'Education'\nshow_bargraphs(var, figsize=(15, 5), y_km=y_km3, cluster=3)","32f99a1a":"var = 'Marital_Status'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km3, cluster=3)","3622cd48":"var = 'Kidhome'\nshow_bargraphs(var, figsize=(15, 5), y_km=y_km3, cluster=3)","68876b92":"var = 'Teenhome'\nshow_bargraphs(var, figsize=(15, 5), y_km=y_km3, cluster=3)","1e01f3d0":"var = 'Age'\nshow_bargraphs(var, figsize=(15, 5), y_km=y_km3, cluster=3)","09339987":"var = 'M_rank'\nshow_bargraphs(var, figsize=(15, 5), y_km=y_km3, cluster=3)","8fadcb68":"corr = data[['M_rank', 'MntWines', 'MntFruits', 'MntMeatProducts',\n       'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']].corr()\nsns.heatmap(corr, annot=True)","214e409d":"indices2 = ['Income', 'Kidhome', 'Teenhome',\n       'Age', 'R_rank', 'M_rank']\n\ndata_2 = data.sample(frac=1, random_state=123)[indices2].reset_index(drop=True) # shuffle the data\ndistortions = []\n\nscaler = StandardScaler()\ndata_scaled_2 = scaler.fit_transform(data_2)\n\nfor i in range(1, 11):\n   km = KMeans(n_clusters=i, n_init=10, max_iter=300, random_state=0)\n   \n   km.fit(data_scaled_2)\n   # inertia_\u3067\u6b6a\u307f\u3092\u6570\u5024\u7684\u306b\u8868\u793a\n   distortions.append(km.inertia_)\n   \n\n   \nplt.plot(range(1, 11), distortions, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.tight_layout()\nplt.show()","a0aee5c5":"km_4 = KMeans(n_clusters=4, n_init=10, max_iter=300, random_state=0)\ny_km4 = km_4.fit_predict(data_scaled_2)","3aec327d":"var = 'Education'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km4, cluster=4)\nplt.tight_layout()","9b8eaa0f":"var = 'Marital_Status'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km4, cluster=4)\nplt.tight_layout()","49963915":"var = 'Kidhome'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km4, cluster=4)\nplt.tight_layout()","c397b96f":"var = 'Age'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km4, cluster=4)\nplt.tight_layout()","40313c2b":"var = 'R_rank'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km4, cluster=4)\nplt.tight_layout()","0849f5f3":"var = 'M_rank'\nshow_bargraphs(var, figsize=(17, 5), y_km=y_km4, cluster=4)\nplt.tight_layout()","e7ae0f7f":"#### above graph, the distortion score is really high. \n#### so, we try again with the particular columns which is seemed to be important with RFM result and something.","5a44d7d0":"#### That's OK to drop!\n#### and we do.","5e01f48e":"<h4> We figure out res1 customers are more likely to buy the <span style=\"color:red\">WINE!<\/span><\/h4>\n\n<hr>\n\n<h3>Let's start RFM<\/h3>","169e91ef":"### OK, the distortion is getting down and n_cluster-4 looks practical number, I guess.\n#### I check the cluster-4!","913bd20a":"#### I checked other params but the distributions are similar above graph\n#### and they are really close to M_rank, I guess\n\n<hr>\n\n<div style=\"background-color:lightgreen;padding:8px;\">\n    <h3> Next, I use n_cluster=3<\/h3>\n<\/div>","35c7be33":"#### By the way, I think M_rank covers the Mnt* params.\n#### Finaly, I modified to use the indices and see the elbow","2beacab1":"<div style=\"background-color:lightgreen; padding:8px\">\n    <h2>Conclusion<\/h2>\n    <h4>I think clustering is 2 or 3 n_cluster is suit for this time.<\/h4>\n    <ul>\n        <li>\n            The M_rank, sum the Num* columns and high M_rank customers have 1 teenhome or zero.\n        <\/li>\n    <\/ul>\n    <h4>If you find any interests in our analysis, feel free to comment and upvotes<\/h4>\n    <h3 style=\"color:red\">I'm so grateful to see my note. Thank you!<\/h3>\n<\/div>","bb87b188":"<div style=\"background-color:lightgreen; padding:8px\">\n    <h3>We get to know the clusters with categorical params<\/h3>\n    <ul>\n        <li>\n            <h4>Cluster 1<\/h4>\n            <p>that 'have 1 teen child and the Age is mainly 40~60'<\/p>\n            <p>And the cluster 1 is a little positive to spend the money in this shopping<\/p>\n        <\/li>\n        <li>\n            <h4>Cluster 2<\/h4>\n            they don't have no child but they are so good customer bacause the number of M_rank-1 is so high!!\n        <\/li>\n        <li>\n            <h4>Cluster 3<\/h4>\n            <p>Married and have 1 child which is under teen, Age range is 30~50s<\/p>\n            <p>however, this cluster is definetly negative to spend in this shop...<\/p>\n        <\/li>  \n    <\/ul>\n<\/div>","98685b2d":"<hr>\n\n#### Chech the dist with Each Part","01f4deb2":"<h3>OK, Monetary is also seemed to be important because rank-1 and rank-2 rates are more than 10%<\/h3>\n<h4> but rank-2 is less than rank-3. We may have to care about it??<\/h4>\n\n<hr>\n<h4>Next, We seek RFM_score<h4>","8a0c8b3a":"<h3>Frequency isn't important. F_rank isn't related to Res..<\/h3>","eeda83b3":"<h4> This data is <span style=\"color:red\">biased<\/span>, and we have to be careful.<\/h4>\n<hr>\n\n### Change Year_Birth to their generation (this current year is 2021)\n#### and see the some plots","fec6f1d4":"<div style=\"background-color:lightgreen; padding:8px\">\n    <h3>We get to know the cluster 1 and 2 with categorical params<\/h3>\n    <ul>\n        <li>\n            <h4>Cluster 1<\/h4>\n            <p>that 'be married, have 1 or 2 children including teen and the Age is mainly 40~50'<\/p>\n            <p>And the cluster 1 is pretty negative to spend the money in this shopping<\/p>\n        <\/li>\n        <li>\n            <h4>Cluster 2<\/h4>\n             that 'be married, have no children and the Age is over 40s'\n        <\/li>       \n    <\/ul>\n<\/div>","848b7e6f":"<div style=\"background-color:lightblue;padding:8px\">\n    <h3>RFM Summary<\/h3>\n    <h3>\n        <span style=\"color:blue;\">We seek the data and try to cluster customers with RFM!<\/span>\n    <\/h3>    \n    <h4>We can't figure out response-1 customer with RFM because the highest rate is 1.4%...<br>\n        But We can find the R and M ranks are necessary for responce because most of top10-RFMrank customers have rank-1 of R or M  \n    <\/h4>\n    <h4>Moreover, F-rank isn't necessary because no matter what F-rank is fine. \n        <span style=\"color:blue;\">So we can say we can drop the F-rank and those columns, Num~ cols.<\/span>\n    <\/h4>\n    <h4>So, I stop RFM and seek other columns<\/h4>\n<\/div>","76668f84":"<div style=\"background-color:lightgreen; padding:5px\">\n<h3> <span style=\"color:red\">We try the RFM analysis<\/span> <br>before analyzing with a little high level packages and modules.\n<\/h3>\n\n#### I use below the 'RFM'\n<ul>\n    <li>R -> Recency<\/li>\n    <li>F -> NumWebVisitsMonth (but this is counted only in a last month, this is not better idea for now)<\/li>\n    <li>M -> sum 'Products' col numbers (Mnt~)<\/li>\n<\/ul>\n\n#### If we figure out with RFM, This is really short cut to reach the loyal customers! \n#### But, we don't know the results so far.\n\n<h4>We, firstly, have to know distributions<\/h4>\n<\/div>","84213223":"#### Most of them are negativee correlation with M_rank and the corr is more than 60%.\n#### I think this approach is useful to try.","46aab4fa":"<h3>R rank is seemed to be related the Response. <span style=\"color:red;\">1 plus 2 ranks are more than 10%!<\/h3>\n<h4>This is seemed to be important<\/h4>","f0bc77ae":"#### As the rate of age, I think we can drop the age 80s, and 120s because they can be regarded as outfilters this analysis.\n#### But this time, people who response equal 1 are really tiny comparing to res=0. we must check 80s and 120s are res1 or res0.","b1be22db":"<div style=\"background-color:lightgreen;padding:8px\">\n    <h4>According to above elbow method, the better param is 2 or 3??<\/h4>\n    <h4>after this, We seek the cluster and figure out a detail of each cluter!<\/h4>\n<\/div>","b68a4fc8":"#### We check how many null in each col."}}