{"cell_type":{"37a6efe0":"code","6bea834b":"code","4f8b5b57":"code","233b56ca":"code","8875d3ad":"code","29c85813":"code","62f7bc13":"code","f3701735":"code","f3a4799b":"code","ff54cc46":"code","e724be09":"code","d73a8136":"code","62191dbe":"code","5d056609":"code","aad95643":"code","524a3d92":"code","76c63ae7":"code","86aff32f":"code","ec138ff1":"code","a5972a0d":"code","047a08da":"code","64919972":"code","ad7882e5":"code","94ac1f5a":"code","a9081eea":"code","2500550c":"code","074eb7a2":"code","4c3d2636":"code","542af604":"code","69b2b326":"code","f272cf93":"code","a1a82d14":"code","5b6efb4f":"code","1e3030f9":"code","df3c6ac5":"code","abef2374":"code","2ae452f1":"code","c64e70ad":"code","341e153d":"code","038f1747":"code","822b2da2":"code","59861989":"code","ea4793da":"code","028a29bb":"markdown","1ea892f9":"markdown","266a607f":"markdown","ebf98205":"markdown","b94bcde2":"markdown","42940299":"markdown","fc7fa35c":"markdown","804246d3":"markdown","7b101b9c":"markdown","16ae2390":"markdown","c1a2426d":"markdown","0ec9f46d":"markdown","8106596a":"markdown","49824c8f":"markdown","1b919c4a":"markdown","3d9332d0":"markdown","4484ad56":"markdown","3f43dcb5":"markdown","398e7d77":"markdown","da91bf31":"markdown","0e576fb6":"markdown"},"source":{"37a6efe0":"import pandas as pd\nimport numpy as np\nimport pickle\n\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport tensorflow as tf\nimport seaborn as sns\nfrom pylab import rcParams\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras import regularizers\n%matplotlib inline\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 14, 8\n\nRANDOM_SEED = 30\nLABELS = [\"Normal\", \"Fraud\"]","6bea834b":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","4f8b5b57":"df","233b56ca":"# k\u00edch th\u01b0\u1edbc t\u1eadp d\u1eef li\u1ec7u\ndf.shape","8875d3ad":"# Bi\u1ec3u \u0111\u1ed3 th\u1ec3 hi\u1ec7n s\u1ed1 giao d\u1ecbch h\u1ee3p l\u1ec7 (Normal) v\u00e0 ko h\u1ee3p h\u1ec7 (Fraud)\ndf.isnull().values.any()\ncount_classes = pd.value_counts(df['Class'], sort = True)\ncount_classes.plot(kind = 'bar', rot=0)\nplt.title(\"Transaction class distribution\")\nplt.xticks(range(2),( \"Normal\",\"Fraud\"))\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\");","29c85813":"frauds = df[df.Class == 1]\nnormal = df[df.Class == 0]","62f7bc13":"# s\u1ed1 c\u00e1c giao d\u1ecbch kh\u00f4ng h\u1ee3p l\u1ec7\nfrauds.shape\n","f3701735":"# Xem x\u00e9t c\u00e1c b\u1ea3n ghi giao d\u1ecbch kh\u00f4ng h\u1ee3p l\u1ec7\nfrauds","f3a4799b":"# T\u1ed5ng s\u1ed1 c\u00e1c b\u1ea3n ghi b\u00ecnh th\u01b0\u1eddng\nnormal.shape\n","ff54cc46":"# S\u1ed1 ti\u1ec1n giao d\u1ecbch trong c\u00e1c giao d\u1ecbch kh\u00f4ng h\u1ee3p l\u1ec7\nfrauds.Amount.describe()","e724be09":"#S\u1ed1 ti\u1ec1n giao d\u1ecbch trong c\u00e1c giao d\u1ecbch h\u1ee3p l\u1ec7\nnormal.Amount.describe()","d73a8136":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Amount per transaction by class')\n\nbins = 50\n\nax1.hist(frauds.Amount, bins = bins)\nax1.set_title('Fraud')\n\nax2.hist(normal.Amount, bins = bins)\nax2.set_title('Normal')\n\nplt.xlabel('Amount ($)')\nplt.ylabel('Number of Transactions')\nplt.xlim((0, 20000))\nplt.yscale('log')\nplt.show();","62191dbe":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Time of transaction vs Amount by class')\n\nax1.scatter(frauds.Time, frauds.Amount)\nax1.set_title('Fraud')\n\nax2.scatter(normal.Time, normal.Amount)\nax2.set_title('Normal')\n\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Amount')\nplt.show()","5d056609":"# X\u00f3a b\u1ecf thu\u1ed9c t\u00ednh Time trong t\u1eadp d\u1eef li\u1ec7u\ndata = df.drop(['Time'], axis=1)\n\n","aad95643":"#Chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u Amount trong kho\u1ea3ng [-1:1]\ndata['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))","524a3d92":"# t\u1eadp d\u1eef li\u1ec7u sau khi \u0111\u01b0\u1ee3c x\u1eed l\u00fd\nprint(data.shape)\ndata.head()","76c63ae7":"X = data.iloc[:, 0:30]\ny = data['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n\n\n","86aff32f":"# Xem x\u00e9t t\u1eadp d\u1eef li\u1ec7u train\nprint(X_train.shape)\nX_train.head()","ec138ff1":"print(y_train.shape)\n# y_train","a5972a0d":"# Xem x\u00e9t t\u1eadp d\u1eef li\u1ec7u test\nprint(X_test.shape)\nX_test.head()","047a08da":"#G\u1ecdi package sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\n#Kh\u1edfi t\u1ea1o bi\u1ebfn knn s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n ph\u00e2n l\u1edbp KNN, v\u1edbi n = 3\nknn = KNeighborsClassifier(algorithm='ball_tree',n_neighbors = 3,metric='euclidean')","64919972":"#Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh v\u1edbi t\u1eadp d\u1eef li\u1ec7u train:\nknn.fit(X_train, y_train)","ad7882e5":"# kh\u1edfi t\u1ea1o bi\u00ean d\u1ef1 \u0111o\u00e1n\ny_pred = knn.predict(X_test)","94ac1f5a":"#Hi\u1ec7n th\u1ecb d\u1ef1 do\u00e1n \u1edf d\u00f2ng 5000-6000\ny_pred[5000:6000]\n","a9081eea":"print(type(y_pred))\nprint(type(y_test))","2500550c":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","074eb7a2":"# tr\u1ef1c quan h\u00f3a .\nplt.figure(figsize=(12, 12))\nsns.heatmap(cm, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","4c3d2636":"print(f1_score(y_test, y_pred))","542af604":"# \u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh\nacc_knn =accuracy_score(y_test, y_pred)*100\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh l\u00e0: \",acc_knn,\"%\")","69b2b326":"from sklearn.svm import SVC\n\nsvc = SVC(gamma='auto')\n\n#Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh v\u1edbi d\u1eef li\u1ec7u Train:\nsvc.fit(X_train, y_train)\n\n#X\u00e1c \u0111\u1ecbnh \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh tr\u00ean t\u1eadp Train:\nacc_svc = round(svc.score(X_train, y_train) * 100, 2)\n\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh SVC tr\u00ean t\u1eadp Train: \", acc_svc, \"%\")\nprint(\"C\u00e1c tham s\u1ed1 c\u1ee7a model SVM:\\n\",svc)","f272cf93":"# kh\u1edfi t\u1ea1o bi\u00ean d\u1ef1 \u0111o\u00e1n\ny_pred_2 = svc.predict(X_test)","a1a82d14":"cm = confusion_matrix(y_test, y_pred_2)\nprint(cm)","5b6efb4f":"acc_svc = accuracy_score(y_test, y_pred_2)*100\n# \u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh l\u00e0: \",acc_svc,\"%\")","1e3030f9":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier(criterion='entropy')\ndecision_tree.fit(X_train, y_train)\n\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\n\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh NB tr\u00ean t\u1eadp Train: \", acc_decision_tree, \"%\")\nprint(\"C\u00e1c tham s\u1ed1 c\u1ee7a Model Decision Tree: \\n\", decision_tree)","df3c6ac5":"# kh\u1edfi t\u1ea1o bi\u00ean d\u1ef1 \u0111o\u00e1n\ny_pred_1 = decision_tree.predict(X_test)","abef2374":"cm = confusion_matrix(y_test, y_pred_1)\nprint(cm)","2ae452f1":"# tr\u1ef1c quan h\u00f3a .\nplt.figure(figsize=(12, 12))\nsns.heatmap(cm, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","c64e70ad":"# \u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh\nacc_Dtree = accuracy_score(y_test, y_pred_1)*100\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh l\u00e0: \",acc_Dtree,\"%\")","341e153d":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n#Hu\u1ea5n luy\u1ec7n m\u00f4 h\u00ecnh v\u1edbi t\u1eadp Train\nlogreg.fit(X_train,y_train)\n\n#\u0110\u1ed9 tin c\u1eady c\u1ee7a m\u00f4 h\u00ecnh (T\u00ednh tr\u00ean t\u1eadp Train)\nacc_log = round(logreg.score(X_train, y_train) * 100, 2)\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh LoR tr\u00ean t\u1eadp Train: \", acc_log, \"%\")\nprint(\"C\u00e1c tham s\u1ed1 c\u1ee7a Model LogisticRegression: \\n\",logreg)","038f1747":"# kh\u1edfi t\u1ea1o bi\u00ean d\u1ef1 \u0111o\u00e1n\ny_pred_3 = decision_tree.predict(X_test)","822b2da2":"cm = confusion_matrix(y_test, y_pred_3)\nprint(cm)","59861989":"# \u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh\nacc_logr = accuracy_score(y_test, y_pred_3)*100\nprint(\"\u0110\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a m\u00f4 h\u00ecnh l\u00e0: \",acc_logr,\"%\")","ea4793da":"#th\u1ed1ng k\u00ea \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a c\u00e1c Model:\n#T\u1ea1o m\u1ed9t DataFrame l\u01b0u tr\u1eef t\u00ean model v\u00e0 \u0111\u1ed9 ch\u00ednh x\u00e1c c\u1ee7a model, s\u1eafp x\u1ebfp theo th\u1ee9 t\u1ef1 gi\u1ea3m d\u1ea7n c\u1ee7a \u0111\u1ed9 ch\u00ednh x\u00e1c\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression','Decision Tree'],\n    'Score (%)': [acc_svc, acc_knn, acc_Dtree,acc_logr],\n    'Parameter':[svc,knn,logreg,decision_tree]})\n\nmodels.sort_values(by='Score (%)', ascending=False)","028a29bb":"# 2 .Ph\u00e2n t\u00edch, tr\u1ef1c quan h\u00f3a d\u1eef li\u1ec7u","1ea892f9":"\u0110\u1ec3 nh\u00ecn \u0111\u01b0\u1ee3c r\u00f5 h\u01a1n th\u00ec ta c\u00f9ng xem qua bi\u1ec3u \u0111\u1ed3 tr\u1ef1c quan h\u00f3a :","266a607f":"### 3.3: Ph\u00e2n chia t\u1eadp train, test\nB\u00e2y gi\u1edd ta s\u1ebd th\u1ef1c hi\u1ec7n ph\u00e2n chia t\u1eadp train v\u00e0 t\u1eadp test \u1edf \u0111\u00e2y t\u00f4i s\u1ebd s\u1eed d\u1ee5ng h\u00e0m * [train_test_split()](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html)* c\u00f3 s\u1eb5n c\u1ee7a th\u01b0 vi\u1ec7n Sklearn \u0111\u1ec3 ph\u00e2n chia theo t\u1ec9 l\u1ec7 l\u00e0 8:2 ( **80%** cho t\u1eadp train v\u00e0 **20%** cho t\u1eadp test)","ebf98205":"\n# 1.Nh\u1eadp d\u1eefu li\u1ec7u\n\nThe dataset we're going to use can be downloaded from Kaggle. It contains data about credit card transactions that occurred during a period of two days, with 492 frauds out of 284,807 transactions.\n\nAll variables in the dataset are numerical. The data has been transformed using PCA transformation(s) due to privacy reasons. The two features that haven't been changed are Time and Amount. Time contains the seconds elapsed between each transaction and the first transaction in the dataset.\n\nT\u1eadp d\u1eef li\u1ec7u ch\u00fang t\u00f4i s\u1ebd s\u1eed d\u1ee5ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c t\u1ea3i xu\u1ed1ng t\u1eeb Kaggle. N\u00f3 ch\u1ee9a d\u1eef li\u1ec7u v\u1ec1 c\u00e1c giao d\u1ecbch th\u1ebb t\u00edn d\u1ee5ng x\u1ea3y ra trong kho\u1ea3ng th\u1eddi gian hai ng\u00e0y, v\u1edbi 492 gian l\u1eadn trong t\u1ed5ng s\u1ed1 284.807 giao d\u1ecbch.\n\nT\u1ea5t c\u1ea3 c\u00e1c bi\u1ebfn trong t\u1eadp d\u1eef li\u1ec7u l\u00e0 s\u1ed1. D\u1eef li\u1ec7u \u0111\u00e3 \u0111\u01b0\u1ee3c chuy\u1ec3n \u0111\u1ed5i b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng (c\u00e1c) chuy\u1ec3n \u0111\u1ed5i PCA v\u00ec l\u00fd do b\u1ea3o m\u1eadt. Hai t\u00ednh n\u0103ng kh\u00f4ng \u0111\u01b0\u1ee3c thay \u0111\u1ed5i l\u00e0 Th\u1eddi gian v\u00e0 S\u1ed1 ti\u1ec1n. Th\u1eddi gian bao g\u1ed3m s\u1ed1 gi\u00e2y tr\u00f4i qua gi\u1eefa m\u1ed7i giao d\u1ecbch v\u00e0 giao d\u1ecbch \u0111\u1ea7u ti\u00ean trong t\u1eadp d\u1eef li\u1ec7u.","b94bcde2":"### 4.1: Gi\u1edbi thi\u1ec7u s\u01a1 thu\u1eadt to\u00e1n KNN\nB\u1eaft \u0111\u1ea7u x\u00e2y d\u1ef1ng model \u1edf \u0111\u00e2y t\u00f4i s\u1ebd s\u1eed d\u1ee5ng thu\u1eadt to\u00e1n [KNN](https:\/\/vi.wikipedia.org\/wiki\/Gi%E1%BA%A3i_thu%E1%BA%ADt_k_h%C3%A0ng_x%C3%B3m_g%E1%BA%A7n_nh%E1%BA%A5t). \n\n![link text](https:\/\/codelearn.io\/Upload\/Blog\/thuat-toan-knn-qua-vi-du-63732823036.1851.jpg)\n\n  Thu\u1eadt to\u00e1n KNN l\u00e0 m\u1ed9t thu\u1eadt to\u00e1n \u0111\u01a1n gi\u1ea3n trong ML. N\u00f3 \u0111\u01b0\u1ee3c x\u1ebfp v\u00e0o lo\u1ea1i Lazy learning.\n\n  \u00dd t\u01b0\u1edfng c\u1ee7a thu\u1eadt to\u00e1n n\u00e0y s\u1ebd g\u00e1n nh\u00e3n cho l\u1edbp c\u1ee7a ph\u1ea7n t\u1eed m\u1edbi, \u1ee9ng v\u1edbi ph\u1ea7n \u0111\u00f4ng trong s\u1ed1 c\u00e1c ph\u1ea7n t\u1eed l\u00e2n c\u1eadn g\u1ea7n n\u00f3 nh\u1ea5t. Nh\u00e3n \u0111\u00f3 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c quy\u1ebft \u0111\u1ecbnh b\u1eb1ng b\u1ea7u ch\u1ecdn theo \u0111a s\u1ed1 (major voting) trong s\u1ed1 K \u0111i\u1ec3m g\u1ea7n nh\u1ea5t, ho\u1eb7c n\u00f3 c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c suy ra b\u1eb1ng c\u00e1ch \u0111\u00e1nh tr\u1ecdng s\u1ed1 kh\u00e1c nhau cho m\u1ed7i trong c\u00e1c \u0111i\u1ec3m g\u1ea7n nh\u1ea5t \u0111\u00f3 r\u1ed3i suy ra k\u1ebft qu\u1ea3.\n\n  C\u00f3 m\u1ed9t c\u00e2u n\u00f3i r\u1ea5t n\u1ed5i ti\u1ebfng v\u1ec1 \u00fd t\u01b0\u1edfng c\u1ee7a thu\u1eadt to\u00e1n n\u00e0y l\u00e0 :  \n\" Tell me who your friends are, and I will tell you who you are. \"  \n( H\u00e3y cho t\u00f4i bi\u1ebft v\u1ec1 nh\u1eefng ng\u01b0\u1eddi b\u1ea1n c\u1ee7a b\u1ea1n, t\u00f4i s\u1ebd cho b\u1ea1n bi\u1ebft b\u1ea1n l\u00e0 ai. )","42940299":"### 4.2: Ch\u1ea1y model\n\u1ede \u0111\u00e2y th\u00ec t\u00f4i s\u1ebd s\u1eed d\u1ee5ng th\u01b0 vi\u1ec7n c\u00f3 s\u1eb5n c\u1ee7a sklearn.\n[C\u00e1c th\u00f4ng s\u1ed1 c\u1ee7a KNeighborsClassifier](https:\/\/ogrisel.github.io\/scikit-learn.org\/sklearn-tutorial\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html)","fc7fa35c":"# 5.\u0110\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh","804246d3":"### 6.1:SVC ( Suport Vector Machine)","7b101b9c":"# 3 Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u","16ae2390":"It's Sunday morning, it's quiet and you wake up with a big smile on your face. Today is going to be a great day! Except, your phone rings, rather \"internationally\". You pick it up slowly and hear something really bizarre - \"Bonjour, je suis Michele. Oops, sorry. I am Michele, your personal bank agent.\". What could possibly be so urgent for someone from Switzerland to call you at this hour? \"Did you authorize a transaction for $3,358.65 for 100 copies of Diablo 3?\" Immediately, you start thinking of ways to explain why you did that to your loved one. \"No, I didn't !?\". Michele's answer is quick and to the point - \"Thank you, we're on it\". Whew, that was close! But how did Michele knew that this transaction was suspicious? After all, you did order 10 new smartphones from that same bank account, last week - Michele didn't call then.\n\nProbably you feel very lucky if you are a fraud. About every 12 cents per $100 were stolen in the US during the same year. Our friend Michele might have a serious problem to solve here.\n\nIn this part of the series, we will train an Autoencoder Neural Network (implemented in Keras) in unsupervised (or semi-supervised) fashion for Anomaly Detection in credit card transaction data. The trained model will be evaluated on pre-labeled and anonymized dataset.\n\n# Set up\n\nWe will be using TensorFlow 1.2 and Keras 2.0.4. Let's begin:\n","c1a2426d":"### 4.3: K\u1ebft qu\u1ea3","0ec9f46d":"Nh\u00ecn v\u00e0o bi\u1ec3u \u0111\u1ed3 ta c\u00f3 th\u1ec3 nh\u1eadn ra r\u1eb1ng \u0111\u00e2y l\u00e0 m\u1ed9t t\u1eadp d\u1eef li\u1ec7u rarasrt m\u00e1t c\u00e2n b\u1eb1ng. C\u00e1c giao d\u1ecbch th\u00f4ng th\u01b0\u1eddng \u00e1p \u0111\u1ea3o c\u00e1c giao d\u1ecbch gian l\u1eadn. ( \u0110\u00e2y ph\u1ea3n \u1ea3nh r\u1eb1ng th\u1ef1c t\u1ebf \u0111a ph\u1ea7n c\u00e1c giao d\u1ecbch l\u00e0 b\u00ecnh th\u01b0\u1eddng nh\u01b0ng v\u1eabn c\u00f3 c\u00e1c giao d\u1ecbch kh\u00f4ng h\u1ee3p l\u1ec7 v\u00e0 kh\u00f4ng th\u1ec3 xem th\u01b0\u1eddng)\n\nTi\u1ebfp theo l\u00e0 th\u1ec3 c\u00e1c giao d\u1ecbch Normal v\u00e0 fraud b\u1eb1ng s\u1ed1:\n\n\n","8106596a":"### 6.2: Decision tree","49824c8f":"### 6.3:Model Logistic Regression","1b919c4a":"Sau khi xem x\u00e9t qua bi\u1ec3u \u0111\u1ed3 ta c\u00f3 th\u1ec3 nh\u1eadn th\u1ea5y r\u1eb1ng c\u00f3 v\u1ebb nh\u01b0 l\u00e0 th\u1eddi gian(***Time***) th\u1ef1c s\u1ef1 kh\u00f4ng \u1ea3nh h\u01b0\u1edfng nhi\u1ec1u \u0111\u1ebfn \u0111\u1ea7u ra","3d9332d0":"# 6.So s\u00e1nh v\u1edbi c\u00e1c thu\u1eadt to\u00e1n kh\u00e1c:","4484ad56":"Ti\u1ebfp theo ta s\u1ebd xem x\u00e9t s\u1ef1 kh\u00e1c nhau gi\u1eefa s\u1ed1 ti\u1ec1n giao d\u1ecbch(***Amount***) gi\u1eefa c\u00e1c giao d\u1ecbch b\u00ecnh th\u01b0\u1eddng (***Normal***) v\u00e0 c\u00e1c giao d\u1ecbch kh\u00f4ng h\u1ee3p l\u1ec7 (***Fraud***)","3f43dcb5":"### 3.2: Chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u\nV\u00e0 ta c\u0169ng \u0111\u01b0\u1ee3c bi\u1ebft l\u00e0 d\u1eef li\u1ec7u \u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd n\u00ean b\u00e2y gi\u1edd ta c\u0169ng s\u1ebd th\u01b0\u1ee3c hi\u1ec7n chu\u1ea9n h\u00f3a d\u1eef li\u1ec7u c\u1ee7a c\u1ed9t t\u1ed5ng ti\u1ec1n (***Amount***) b\u1eb1ng h\u00e0m  [StandardScaler](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html) trong kho\u1ea3ng (-1,1)","398e7d77":"B\u00e2y gi\u1edd ta s\u1ebd xem x\u00e9t th\u1eddi gian di\u1ec5n ra giao d\u1ecbch c\u00f3 \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn vi\u1ec7c giao d\u1ecbch \u0111\u00f3 c\u00f3 l\u00e0 b\u00ecnh th\u01b0\u1eddng (***Normal***) hay kh\u00f4ng b\u00ecnh th\u01b0\u1eddng (***Fraud***) kh\u00f4ng ?\n","da91bf31":"#### 3.1: Lo\u1ea1i b\u1ecf c\u00e1c thu\u1ed9c t\u00ednh kh\u00f4ng s\u1eed d\u1ee5ng trong m\u00f4 h\u00ecnh\n\nNh\u01b0 ta xem x\u00e9t \u1edf tr\u00ean v\u00ec nh\u1eadn ra r\u1eb1ng thu\u1ed9c t\u00ednh th\u1eddi gian(***Time***) kh\u00f4ng \u1ea3nh h\u01b0\u1edfng \u0111\u1ebfn \u0111\u1ea7u ra n\u00ean s\u1ebd quy\u1ebft \u0111\u1ecbnh b\u1ecf c\u1ed9t th\u1eddi gian ra. ","0e576fb6":"# 4.X\u00e2y d\u1ef1ng model\n"}}