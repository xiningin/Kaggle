{"cell_type":{"f24be088":"code","0aefe451":"code","1100fdba":"code","136a40f7":"code","0b60a0b2":"code","2d16b572":"code","757ed072":"code","45f1e43c":"code","ab18ce99":"code","77fca268":"code","249f3c6b":"code","03935150":"code","f1b2d49d":"code","bbec501e":"code","e5e9fede":"code","5b2452ab":"code","472fb7de":"code","ee30cd82":"code","3e4ffe64":"code","25e9ac0e":"code","b5b3ccb8":"code","eb943575":"code","ed8172cd":"code","0ba85e85":"code","b24ab60d":"code","d19050bf":"code","39b3c75e":"code","52548662":"markdown","2f261672":"markdown","69329324":"markdown","da8f47f3":"markdown","3ee8c11b":"markdown","a3a0449d":"markdown","bcaf45b6":"markdown","b4701076":"markdown","43dc7e36":"markdown","a9a2eeac":"markdown","dcbb1083":"markdown","f95f15c2":"markdown"},"source":{"f24be088":"!apt-get install -y graphviz libgraphviz-dev libcgraph6","0aefe451":"!pip install git+https:\/\/github.com\/danielegrattarola\/spektral","1100fdba":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom skimage.util import montage\nfrom IPython.display import Image, display, SVG, clear_output, HTML\nplt.rcParams[\"figure.figsize\"] = (6, 6)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'gray' # grayscale looks better\nimport networkx as nx\ndef draw_graph_mpl(g, pos=None, ax=None, layout_func=nx.drawing.layout.kamada_kawai_layout, draw_labels=True):\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n    else:\n        fig = None\n    if pos is None:\n        pos = layout_func(g)\n    node_color = []\n    node_labels = {}\n    shift_pos = {}\n    for k in g:\n        node_color.append(g.nodes[k].get('color', 'green'))\n        node_labels[k] = g.nodes[k].get('label', k)\n        shift_pos[k] = [pos[k][0], pos[k][1]]\n    \n    edge_color = []\n    edge_width = []\n    for e in g.edges():\n        edge_color.append(g.edges[e].get('color', 'black'))\n        edge_width.append(g.edges[e].get('width', 0.5))\n    nx.draw_networkx_edges(g, pos, font_weight='bold', edge_color=edge_color, width=edge_width, alpha=0.5, ax=ax)\n    nx.draw_networkx_nodes(g, pos, node_color=node_color, node_shape='p', node_size=300, alpha=0.75, ax=ax)\n    if draw_labels:\n        nx.draw_networkx_labels(g, shift_pos, labels=node_labels, arrows=True, ax=ax)\n    ax.autoscale()\n    return fig, ax, pos","136a40f7":"from keras import Input, Model\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Flatten, Lambda, Dropout\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n\nfrom spektral.layers import GraphConv, GlobalAttentionPool\nfrom spektral.layers.ops import sp_matrix_to_sp_tensor\nfrom spektral.utils import normalized_laplacian","0b60a0b2":"# Parameters\nl2_reg = 5e-4         # Regularization rate for l2\nlearning_rate = 1e-3  # Learning rate for SGD\nbatch_size = 16       # Batch size\nepochs = 20        # Number of training epochs\nes_patience = 10     # Patience fot early stopping","2d16b572":"import h5py\nfrom keras.utils.io_utils import HDF5Matrix\n_h5_path = '..\/input\/mnist-based-graphs\/disjoint_mnist.h5'\nraw_h5 = False\nstrip_xy = True\nif raw_h5:\n    _bare_h5 = h5py.File(_h5_path, 'r')\n    def load_xya(in_id):\n        in_group = _bare_h5[in_id]\n        feat = in_group['feature']\n        labels = in_group['label']\n        adj = in_group['adjacency_distance']\n        return feat, labels, adj\nelse:\n    def load_xya(in_id, normalize=False):\n        # use the hdf5matrix wrapper\n        feat = HDF5Matrix(_h5_path, f\"{in_id}\/feature\")\n        labels = HDF5Matrix(_h5_path, f\"{in_id}\/label\")\n        adj = HDF5Matrix(_h5_path, f\"{in_id}\/adjacency_distance\", normalizer=normalized_laplacian if normalize else None)\n        return feat, labels, adj\n\nx_train, y_train, adj_train = load_xya('train')\nx_valid, y_valid, adj_valid = load_xya('val')\nx_test, y_test, adj_test = load_xya('test')","757ed072":"print(adj_train[0].shape, 'adjacency matrix')\nplt.matshow(adj_train[0])","45f1e43c":"G = nx.from_numpy_array(adj_train[0])","ab18ce99":"draw_graph_mpl(G);","77fca268":"c_pos = x_train[0][:, :2]\nc_pos[c_pos==0] = np.NAN\ndraw_graph_mpl(G, pos=c_pos);","249f3c6b":"N = x_train.shape[1]\nF = x_train.shape[2]\nn_out = np.max(y_train)+1","03935150":"# Model definition\nX_in = Input(shape=(N, F), name='Features')\nA_in = Input(shape=(N, N), name='Topology')\n\nif strip_xy:\n    clean_x = Lambda(lambda x: x[:, :, 2:], name='StripXY')(X_in)\nelse:\n    clean_x = X_in\n\ngraph_conv_1 = GraphConv(32,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([clean_x, A_in])\n\ngraph_conv_2 = GraphConv(32,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([graph_conv_1, A_in])\n\n# keep the same\nmc_1, A_mincut = graph_conv_2, A_in\n# use a pooling layer\n# doesn't work yet\n#diffpool_1, A_mincut, _ = DiffPool(k=64)([graph_conv_22, A_mincut])\n\ngraph_conv_21 = GraphConv(64,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([mc_1, A_mincut])\n\ngraph_conv_22 = GraphConv(128,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([graph_conv_21, A_mincut])\n\ngraph_conv_31 = GraphConv(64,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([graph_conv_22, A_mincut])\n\ngraph_conv_32 = GraphConv(128,\n                       activation='elu',\n                       kernel_regularizer=l2(l2_reg),\n                       use_bias=True)([graph_conv_31, A_mincut])\n\ngap_1 = GlobalAttentionPool(64)(graph_conv_32)\ngap_dr = Dropout(0.5)(gap_1)\n\nfc = Dense(32, activation='relu')(gap_dr)\noutput = Dense(n_out, activation='softmax')(fc)\n\n# Build model\nmodel = Model(inputs=[X_in, A_in], outputs=output)\noptimizer = Adam(lr=learning_rate)\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['acc'])\nmodel.summary()","f1b2d49d":"from keras.utils.vis_utils import model_to_dot\nImage(model_to_dot(model, show_shapes=True).create_png())","bbec501e":"# Train model\nvalidation_data = ({'Features': x_valid, 'Topology': adj_valid}, y_valid)\nmodel.fit({'Features': x_train, 'Topology': adj_train},\n          y_train,\n          batch_size=batch_size,\n          validation_data=validation_data,\n          epochs=epochs,\n          shuffle=\"batch\",\n          callbacks=[\n              EarlyStopping(patience=es_patience, restore_best_weights=True)\n          ])","e5e9fede":"# Evaluate model\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nprint('Evaluating model.')\neval_pred = model.predict({'Features': x_test, 'Topology': adj_test},\n                              batch_size=batch_size,\n                         verbose=True)\neval_cat = np.argmax(eval_pred, -1)","5b2452ab":"print('Test acc: {:2.1%}'.format(accuracy_score(y_true=y_test[:], y_pred=eval_cat)))\nfig, ax1 = plt.subplots(1, 1, figsize=(15, 15))\nsns.heatmap(confusion_matrix(y_true=y_test[:], y_pred=eval_cat), annot=True, fmt='d', ax=ax1)","472fb7de":"W, b = model.layers[-8].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.bar(np.arange(W.shape[1]), W[0])\nax2.bar(np.arange(W.shape[1]), b)","ee30cd82":"W, b = model.layers[-7].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.imshow(W, vmin=-1, vmax=1, cmap='RdBu')\nax2.bar(np.arange(W.shape[1]), b)","3e4ffe64":"W, b = model.layers[-6].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.imshow(W, vmin=-1, vmax=1, cmap='RdBu')\nax2.bar(np.arange(W.shape[1]), b)","25e9ac0e":"W, b = model.layers[-5].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\nax1.imshow(W, vmin=-1, vmax=1, cmap='RdBu')\nax2.bar(np.arange(W.shape[1]), b)","b5b3ccb8":"W1, b1, W2, b2  = model.layers[-4].get_weights()\nprint(W1.shape, W2.shape, b1.shape, b2.shape)\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4))\nax1.imshow(W1, vmin=-1, vmax=1, cmap='RdBu')\nax2.bar(np.arange(b1.shape[0]), b1)\nax3.imshow(W1, vmin=-1, vmax=1, cmap='RdBu')\nax4.bar(np.arange(b2.shape[0]), b2)","eb943575":"W, b = model.layers[-2].get_weights()\nprint(W.shape, b.shape)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 4))\nax1.imshow(W, vmin=-1, vmax=1, cmap='RdBu')\nax2.bar(np.arange(W.shape[1]), b)","ed8172cd":"i_model = Model(inputs=[X_in, A_in], outputs=[graph_conv_1, \n                                              graph_conv_2, \n                                              graph_conv_21, \n                                              graph_conv_22, \n                                              graph_conv_31,\n                                              graph_conv_32,\n                                              gap_1])","0ba85e85":"*conv_outputs, gap_out = i_model.predict({'Features': x_test[:256], 'Topology': adj_test[:256]})","b24ab60d":"fig, m_axs = plt.subplots(5, 1+len(conv_outputs), figsize=(7*(1+len(conv_outputs)), 22))\nfor c_ax in m_axs.flatten():\n    c_ax.set_xlim(0, 1)\n    c_ax.set_ylim(0, 1)\n    c_ax.axis('off')\ndef show_wrapped(in_ax, in_pos, in_vec):\n    row_count = np.sqrt(in_vec.shape[1]).astype(int)\n    max_x, max_y = 0, 0\n    for i in range(in_vec.shape[1]):\n        x_offset = i % row_count\n        max_x = max(x_offset, max_x)\n        y_offset = i \/\/ row_count\n        max_y = max(y_offset, max_y)\n        nmax_val = np.percentile(np.abs(in_vec[:, i]), 95)\n        in_ax.scatter(in_pos[:, 0]+x_offset, \n                      in_pos[:, 1]+y_offset, \n                      c=in_vec[:, i], \n                      s=5\/row_count, \n                      cmap='RdBu', \n                      vmin=-nmax_val, \n                      vmax=nmax_val)\n    in_ax.set_xlim(0, row_count+1)\n    in_ax.set_ylim(0, max_y+1)\n\nfor i, n_axs in enumerate(m_axs):\n    ax1, *r_axs = n_axs\n    x_vec = x_test[i]\n    pos_vec = x_vec[:, :2].copy()\n    pos_vec[pos_vec==0] = np.NAN\n    x_topo = adj_test[i]\n    G = nx.from_numpy_array(x_topo)\n    draw_graph_mpl(G, pos=pos_vec, ax=ax1, draw_labels=False);\n    ax1.scatter(pos_vec[:, 0], pos_vec[:, 1], c=x_vec[:, 2])\n    ax1.set_title(y_test[i])\n    ax1.set_xlim(0, 1)\n    ax1.set_ylim(0, 1)\n    \n    for j, (c_ax, conv_out) in enumerate(zip(r_axs, conv_outputs)):\n        show_wrapped(c_ax, in_pos=pos_vec, in_vec=conv_out[i])\n        c_ax.set_title('{}: {}'.format(i_model.output_names[j], conv_out[i].shape))\nfig.savefig('layer_activations.png', dpi=300)","d19050bf":"fig, m_axs = plt.subplots(5, 1+len(conv_outputs), figsize=(4*(1+len(conv_outputs)), 15))\nfor c_ax in m_axs.flatten():\n    c_ax.set_xlim(0, 1)\n    c_ax.set_ylim(0, 1)\n    c_ax.axis('off')\n\nfor i, n_axs in enumerate(m_axs):\n    ax1, *r_axs = n_axs\n    x_vec = x_test[i]\n    pos_vec = x_vec[:, :2].copy()\n    pos_vec[pos_vec==0] = np.NAN\n    x_topo = adj_test[i]\n    G = nx.from_numpy_array(x_topo)\n    draw_graph_mpl(G, pos=pos_vec, ax=ax1, draw_labels=False);\n    ax1.scatter(pos_vec[:, 0], pos_vec[:, 1], c=x_vec[:, 2])\n    ax1.set_title(y_test[i])\n    ax1.set_xlim(0, 1)\n    ax1.set_ylim(0, 1)\n    \n    for j, (c_ax, conv_out) in enumerate(zip(r_axs, conv_outputs)):\n        top_comp = np.argsort(-1*np.mean(np.std(conv_out, axis=1), axis=0))[:9]\n        show_wrapped(c_ax, in_pos=pos_vec, in_vec=conv_out[:, :, top_comp][i])\n        c_ax.set_title('{}: {}'.format(i_model.output_names[j], conv_out[i].shape))\nfig.savefig('top_layer_activations.png', dpi=300)","39b3c75e":"n_keys = y_test[:gap_out.shape[0]]\nfig, m_axs = plt.subplots(4, 3, figsize=(12, 14))\nm_val = np.percentile(np.abs(gap_out.ravel()), 95)\nout_img_list = []\nfor i, c_ax in enumerate(m_axs.flatten()):\n    c_img = gap_out[n_keys==i, :]\n    if c_img.shape[0]>0:\n        out_img_list.append(c_img)\n        c_ax.imshow(c_img.T, vmin=-m_val, vmax=m_val, cmap='RdBu')\n        c_ax.set_title(i)\n    c_ax.axis('off')\nm_axs.ravel()[-1].imshow(np.concatenate(out_img_list, 0).T, vmin=-m_val, vmax=m_val, cmap='RdBu')\nm_axs.ravel()[-1].set_title('Combined')","52548662":"## Libraries\nHere are the libraries and imports to make the model","2f261672":"## Show intermediate output values\nHere we can rearrange the output of the graph convolutions to see if the model is learning similar sorts of features to the standard convolutional neural networks","69329324":"# Overview\nThe notebook is mainly done for my own benefit to better understand what graph convolutional networks do on a very basic and visual task (MNIST). \n\nThe notebook is just a slightly more visual version of the MNIST example provided at https:\/\/github.com\/danielegrattarola\/spektral\/blob\/master\/examples\/graph_signal_classification_mnist.py as part of the [Spektral](https:\/\/github.com\/danielegrattarola\/spektral) package. ","da8f47f3":"# Most Varying Components\nInstead of showing all components just show the one with the biggest variation across the digits we have","3ee8c11b":"## Global Attention Features\n- What sort of features do we have after the attention layer\n- Are there easily distinguishable between digits?","a3a0449d":"# Model Building\nNow we can build the model which uses the graph topology shown above as the basis. We feed the topology in as a constant tensor ($A_{in}$) and the convolutions occur across this topology. ","bcaf45b6":"- Use positions","b4701076":"# Weights\nNot sure exactly how to interpret these but we can show them easily enough","43dc7e36":"## Install Dependencies","a9a2eeac":"### Label Nodes and Show Connections\nHere we can visualize the topology a bit better and see what the graph actually looks like.","dcbb1083":"## Goal\nThe goal of the problem is to correctly classify the digits using the intensity values as the nodes and the neighborhood relationships as the edges. When we visualize the adjacency matrix we can see the effect of a simply unraveled 2D array","f95f15c2":"# What did the model actually learn?\nWe can now try and reassemble what the model actually learnt by exporting the intermediate layers"}}