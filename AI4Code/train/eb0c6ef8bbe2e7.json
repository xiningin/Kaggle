{"cell_type":{"6d6d1cf2":"code","7eec01fd":"code","8551ebbb":"code","f056a50f":"code","79ac9fc5":"code","cc505d59":"code","80f78c40":"code","fa2f28b8":"code","8a3a03a7":"code","7108d04c":"code","11e3ea49":"code","854871b7":"code","2c8cc95b":"code","f4ceda83":"code","3c3510e9":"code","d2a72506":"code","1ea37026":"code","ff18b64b":"code","4e9acfa2":"code","18d56b3d":"code","a7a5d331":"code","ee0adc04":"code","3c7ba555":"code","a1a04852":"code","01f614d4":"code","e9805f2c":"code","eb482be1":"code","070d81d1":"code","d98a5084":"code","e4c2ac26":"code","ca4215b4":"code","f11938ac":"code","7f9a7413":"code","b32f9a1b":"code","f518cd13":"code","b1820914":"code","5638b540":"code","88292860":"markdown","abd6767c":"markdown","3256e83c":"markdown","5db02b8d":"markdown","9a58f684":"markdown","8e960f1f":"markdown","e26bee94":"markdown","4745fa03":"markdown","ca9ac5c5":"markdown","5202e079":"markdown","643495bc":"markdown","3aafeeea":"markdown","4dbd0e72":"markdown","a9467aa3":"markdown","acc71eca":"markdown","4ce5191d":"markdown","4e03543b":"markdown","3368a3ea":"markdown","a6e2dc03":"markdown","9b12c7ca":"markdown","f0741e9e":"markdown","0b47c3cb":"markdown","dc910452":"markdown","d75516d8":"markdown","ae1595e5":"markdown","9d09b63b":"markdown","ee510258":"markdown","4c11a951":"markdown","0d7f3f22":"markdown","e8ebb9c6":"markdown","c3fbf239":"markdown","28ca45fc":"markdown","856c4ec0":"markdown","772e5501":"markdown","2aee1aa7":"markdown","1b9fb5dd":"markdown","ed1b073d":"markdown","5368272f":"markdown","ec44517b":"markdown","74b2522f":"markdown","e18ed9d8":"markdown","1aaa4697":"markdown","a466e46c":"markdown","57ed9c3d":"markdown","6e2f4523":"markdown","0623bad5":"markdown","1300eb57":"markdown","96ccfdb6":"markdown","247ca75d":"markdown","1a9ec8e1":"markdown","7daf830e":"markdown","f09d993e":"markdown","8ebd5536":"markdown","df2e23b8":"markdown","ae2147b1":"markdown","daab5d96":"markdown","8d51a358":"markdown","54aa6dae":"markdown","83af5f56":"markdown","ff335b1a":"markdown","8cf36412":"markdown","a67f0900":"markdown","9914773e":"markdown"},"source":{"6d6d1cf2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \npd.set_option(\"display.max_columns\",None) \npd.set_option(\"display.max_rows\",None) \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import Image\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import LocalOutlierFactor\nsns.set(style=\"darkgrid\", palette=\"pastel\", color_codes=True)\nsns.set_context('talk')\n\nfrom pathlib import Path\ndata_dir = Path('..\/input\/images')","7eec01fd":"Image(filename=data_dir\/'O2.jpeg')","8551ebbb":"Image(filename=data_dir\/'O5.png')","f056a50f":"Image(filename=data_dir\/'O6.png')","79ac9fc5":"df_1 = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf_1.head()","cc505d59":"df_1.isnull().sum()","80f78c40":"df_1.describe()","fa2f28b8":"plt.figure(figsize = (4,8))\nsns.boxplot(y = df_1.chol)","8a3a03a7":"Image(filename=data_dir\/'O3.png')","7108d04c":"def out_iqr(df , column):\n    global lower,upper\n    q25, q75 = np.quantile(df[column], 0.25), np.quantile(df[column], 0.75)\n    # calculate the IQR\n    iqr = q75 - q25\n    # calculate the outlier cutoff\n    cut_off = iqr * 1.5\n    # calculate the lower and upper bound value\n    lower, upper = q25 - cut_off, q75 + cut_off\n    print('The IQR is',iqr)\n    print('The lower bound value is', lower)\n    print('The upper bound value is', upper)\n    # Calculate the number of records below and above lower and above bound value respectively\n    df1 = df[df[column] > upper]\n    df2 = df[df[column] < lower]\n    return print('Total number of outliers are', df1.shape[0]+ df2.shape[0])","11e3ea49":"out_iqr(df_1,'chol')\n#Input the dataset and the required column","854871b7":"plt.figure(figsize = (10,6))\nsns.distplot(df_1.chol, kde=False)\nplt.axvspan(xmin = lower,xmax= df_1.chol.min(),alpha=0.2, color='red')\nplt.axvspan(xmin = upper,xmax= df_1.chol.max(),alpha=0.2, color='red')","2c8cc95b":"#Data Frame without outliers\ndf_new = df_1[(df_1['chol'] < upper) | (df_1['chol'] > lower)]","f4ceda83":"Image(filename=data_dir\/'O4.png')","3c3510e9":"df_2 = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\ndf_2.head()","d2a72506":"plt.figure(figsize = (10,5))\nsns.distplot(df_2['writing score'])","1ea37026":"def out_std(df, column):\n    global lower,upper\n    # calculate the mean and standard deviation of the data frame\n    data_mean, data_std = df[column].mean(), df[column].std()\n    # calculate the cutoff value\n    cut_off = data_std * 3\n    # calculate the lower and upper bound value\n    lower, upper = data_mean - cut_off, data_mean + cut_off\n    print('The lower bound value is', lower)\n    print('The upper bound value is', upper)\n    # Calculate the number of records below and above lower and above bound value respectively\n    df1 = df[df[column] > upper]\n    df2 = df[df[column] < lower]\n    return print('Total number of outliers are', df1.shape[0]+ df2.shape[0])","ff18b64b":"out_std(df_2,'writing score')","4e9acfa2":"plt.figure(figsize = (10,5))\nsns.distplot(df_2['writing score'], kde=False)\nplt.axvspan(xmin = lower,xmax= df_2['writing score'].min(),alpha=0.2, color='red')\nplt.axvspan(xmin = upper,xmax= df_2['writing score'].max(),alpha=0.2, color='red')","18d56b3d":"#Data Frame without outliers\ndf_new = df_2[(df_2['writing score'] < upper) | (df_2['writing score'] > lower)]","a7a5d331":"df_3 = pd.read_csv(\"..\/input\/insurance\/insurance.csv\")\ndf_3.head()","ee0adc04":"df_3.describe()","3c7ba555":"df_3.isnull().sum()","a1a04852":"plt.figure(figsize = (10,5))\nsns.distplot(df_3['charges'])","01f614d4":"def out_zscore(data):\n    global outliers,zscore\n    outliers = []\n    zscore = []\n    threshold = 3\n    mean = np.mean(data)\n    std = np.std(data)\n    for i in data:\n        z_score= (i - mean)\/std \n        zscore.append(z_score)\n        if np.abs(z_score) > threshold:\n            outliers.append(i)\n    return print(\"Total number of outliers are\",len(outliers))","e9805f2c":"out_zscore(df_3.charges)","eb482be1":"plt.figure(figsize = (10,5))\nsns.distplot(zscore)\nplt.axvspan(xmin = 3 ,xmax= max(zscore),alpha=0.2, color='red')","070d81d1":"#Data Frame without outliers\ndf_new = df_3[(df_3['charges'] < 3) | (df_3['charges'] > -3)]","d98a5084":"Image(filename=data_dir\/'O8.png')","e4c2ac26":"#Import necessary libraries\nfrom sklearn.ensemble import IsolationForest\n#The required columns\ncols = ['writing score','reading score','math score']\n#Plotting the sub plot\nfig, axs = plt.subplots(1, 3, figsize=(20, 5), facecolor='w', edgecolor='k')\naxs = axs.ravel()\n\nfor i, column in enumerate(cols):\n    isolation_forest = IsolationForest(contamination='auto')\n    isolation_forest.fit(df_2[column].values.reshape(-1,1))\n\n    xx = np.linspace(df_2[column].min(), df_2[column].max(), len(df_2)).reshape(-1,1)\n    anomaly_score = isolation_forest.decision_function(xx)\n    outlier = isolation_forest.predict(xx)\n    \n    axs[i].plot(xx, anomaly_score, label='anomaly score')\n    axs[i].fill_between(xx.T[0], np.min(anomaly_score), np.max(anomaly_score), \n                     where=outlier==-1, color='r', \n                     alpha=.4, label='outlier region')\n    axs[i].legend()\n    axs[i].set_title(column)","ca4215b4":"Image(filename=data_dir\/'O9.png')","f11938ac":"X = df_3[['age','bmi']].values\n\ndb = DBSCAN(eps=3.0, min_samples=10).fit(X)\nlabels = db.labels_","7f9a7413":"pd.Series(labels).value_counts()","b32f9a1b":"plt.figure(figsize=(12,12))\n\nunique_labels = set(labels)\ncolors = ['blue', 'red']\n\nfor color,label in zip(colors, unique_labels):\n    sample_mask = [True if l == label else False for l in labels]\n    plt.plot(X[:,0][sample_mask], X[:, 1][sample_mask], 'o', color=color);\nplt.xlabel('Age');\nplt.ylabel('BMI');","f518cd13":"Image(filename=data_dir\/'O10.png')","b1820914":"clf = LocalOutlierFactor(n_neighbors=50, contamination='auto')\nX = df_1[['age','chol']].values\ny_pred = clf.fit_predict(X)","5638b540":"plt.figure(figsize=(12,12))\n# plot the level sets of the decision function\n\nin_mask = [True if l == 1 else False for l in y_pred]\nout_mask = [True if l == -1 else False for l in y_pred]\n\nplt.title(\"Local Outlier Factor (LOF)\")\n# inliers\na = plt.scatter(X[in_mask, 0], X[in_mask, 1], c = 'blue',\n                edgecolor = 'k', s = 30)\n# outliers\nb = plt.scatter(X[out_mask, 0], X[out_mask, 1], c = 'red',\n                edgecolor = 'k', s = 30)\nplt.axis('tight')\nplt.xlabel('Age');\nplt.ylabel('Cholestrol');\nplt.show()","88292860":"### Let's move to some advanced methods of outlier detection ","abd6767c":"### For example, I'll take up the [Heart disease UCI DataSet](https:\/\/www.kaggle.com\/ronitf\/heart-disease-uci) for explaining IQR method.","3256e83c":"#### Here the red zone represents the outlier zone! The records present in that zone are considered as outliers","5db02b8d":"#### The concept of the Interquartile Range (IQR) is used to build the boxplot graphs. IQR is a concept in statistics that is used to measure the statistical dispersion and data variability by dividing the dataset into quartiles.\n\n#### In simple words, any dataset or any set of observations is divided into four defined intervals based upon the values of the data and how they compare to the entire dataset. A quartile is what divides the data into three points and four intervals.\n\n####  It is the difference between the third quartile and the first quartile (IQR = Q3 -Q1). Outliers in this case are defined as the observations that are below (Q1 \u2212 1.5x IQR) or boxplot lower whisker or above (Q3 + 1.5x IQR) or boxplot upper whisker. It can be visually represented by the box plot.","9a58f684":"#### Let's consider serum cholestoral in mg\/dl column i.e. \"chol\" for our analysis. I'll plot a simple box plot which is the best visualization for detecting outliers","8e960f1f":"### So as per the SD method, there are 4 ouliters","e26bee94":"## Conclusion:","4745fa03":"#### I'll consider the 'age' and 'bmi' columns of the insurance dataset for evaluation.","ca9ac5c5":"#### Here the red zone represents the outlier zone! The records present in that zone are considered as outliers","5202e079":"#### Outliers can have many causes, such as:\n\n#### - Measurement or input error.\n#### - Data corruption.\n#### - True outlier observation.\n\n#### There is no precise way to define and identify outliers in general because of the specifics of each dataset. Instead, you, or a domain expert, must interpret the raw observations and decide whether a value is an outlier or not.\n\n#### Nevertheless, we can use statistical methods to identify observations that appear to be rare or unlikely given the available data. This does not mean that the values identified are outliers and should be removed. A good tip is to consider plotting the identified outlier values, perhaps in the context of non-outlier values to see if there are any systematic relationships or patterns to the outliers. If there is, perhaps they are not outliers and can be explained, or perhaps the outliers themselves can be identified more systematically.","643495bc":"#### Let's define a function to find out the lower and the upper whisker using SDM:","3aafeeea":"#### The downside with this method is that the higher the dimension, the less accurate it becomes. You also need to make a few assumptions like estimating the right value for eps which can be challenging.","4dbd0e72":"### Contrary to what most data science courses would have you believe, not every dataset is a perfectly curated group of observations with no missing values or outliers (For example mtcars and iris datasets). Real-world data is messy which means we need to clean and wrangle it into an acceptable format before we can even start the analysis. Data cleaning is an un-glamorous, but necessary part of most actual data science problems. In this notebook, I will try to explain what are outliers and it's types, how to detect outliers and also remidial measures for outliers \n\n### Please do upvote the notebook if you find it insightful!\n\n### I hope that you find the notebook useful, let me know what you think in the comments section below and connect me on LinkedIn @ [Suraj RP](https:\/\/www.linkedin.com\/in\/suraj-rp\/)\n\n#### Let's start by importing all the required libraries","a9467aa3":"# What are outliers?","acc71eca":"#### Let's define a function to find out the IQR, lower and the upper whisker.","4ce5191d":"# 2) Standard Deviation Method","4e03543b":"#### From the above box plot, we can surely observe that there are outliers in it!","3368a3ea":"### Outlier can be of two types: \n### 1) Univariate \n### 2) Multivariate. \n\n#### Univariate outliers can be found when we look at distribution of a single variable. Multi-variate outliers are outliers in an n-dimensional space. In order to find them, you have to look at distributions in multi-dimensions.\n\n#### Let us understand this with an example. Let us say we are understanding the relationship between height and weight. Below, we have univariate and bivariate distribution for Height, Weight. Take a look at the box plot. We do not have any outlier (above and below 1.5*IQR, most common method). Now look at the scatter plot. Here, we have two values below and one above the average in a specific segment of weight and height.","a6e2dc03":"### Further to give examples on outlier detection and remidial measures, I'll take up a few datasets to work on","9b12c7ca":"#### Here the red zone represents the outlier zone! The records present in that zone are considered as outliers","f0741e9e":"#### Let's consider the \"writing score\" for inspection.  I'll plot a simple density plot which is also one of the best visualization for detecting outliers","0b47c3cb":"### Visual Representation:","dc910452":"# Types of outliers:","d75516d8":"# 3) Z-Score method:","ae1595e5":"### Remedial Measure:\n#### Remove the records which are above the upper bound value and records below the lower bound value!","9d09b63b":"#### There are no null values in the data frame","ee510258":"#### Now let's plot and visualize the outliers. I've set blue for the normal records and red for outliers","4c11a951":"#### The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured.\n\n#### The intuition behind Z-score is to describe any data point by finding their relationship with the Standard Deviation and Mean of the group of data points. Z-score is finding the distribution of data where mean is 0 and standard deviation is 1 i.e. normal distribution.\n\n#### You must be wondering that, how does this help in identifying the outliers? Well, while calculating the Z-score we re-scale and center the data and look for data points which are too far from zero. These data points which are way too far from zero will be treated as the outliers. In most of the cases a threshold of 3 or -3 is used i.e if the Z-score value is greater than or less than 3 or -3 respectively, that data point will be identified as outliers.\n\n#### This technique assumes a Gaussian distribution of the data. The outliers are the data points that are in the tails of the distribution and therefore far from the mean. How far depends on a set threshold zthr for the normalized data points zi calculated with the formula: \n\n###                      Z_score= (Xi - mean) \/ standard deviation \n\n#### where Xi is a data point, 'mean' is the mean of all X and 'standard deviation' the standard deviation of all X.\n\n#### An outlier is then a normalized data point which has an absolute value greater than Zthr. That is:\n\n###                                     |Z_score| > Zthr\n\n#### Commonly used Zthr values are 2.5, 3.0 and 3.5. Here we will be using 3.0","0d7f3f22":"## B) Mulitivariate Outliers:","e8ebb9c6":"#### I will perform basic EDA to analyse the Data Frame","c3fbf239":"### Here the -1's represent the outliers! \n\n#### Let's plot to differentiate the outliers. I'll set the blue colour to normal records and red colour to outliers.","28ca45fc":"### Remedial Measure:\n#### Remove the records which are above the upper bound value and records below the lower bound value!","856c4ec0":"#### Let's consider the \"charges\" for inspection.  I'll plot a simple density plot which is one of the best visualization for detecting outliers","772e5501":"# 1) Interquartile Range Method","2aee1aa7":"#### LOF uses density-based outlier detection to identify local outliers, points that are outliers with respect to their local neighborhood, rather than with respect to the global data distribution. The higher the LOF value for an observation, the more anomalous the observation.\n\n#### This is useful because not all methods will not identify a point that\u2019s an outlier relative to a nearby cluster of points (a local outlier) if that whole region is not an outlying region in the global space of data points.\n\n#### A point is labeled as an outlier if the density around that point is significantly different from the density around its neighbors.\n\n#### In the below feature space, LOF is able to identify P1 and P2 as outliers, which are local outliers to Cluster 2 (in addition to P3).","1b9fb5dd":"# 4) Isolation Forest","ed1b073d":"#### While outlier removal forms an essential part of a dataset normalization, it\u2019s important to ensure zero errors in the assumptions that influence outlier removal. Data with even significant number of outliers may not always be bad data and a rigorous investigation of the dataset in itself is often warranted, but overlooked, by data scientists in their processes.\n\n#### There are some more advanced outlier detection processes like:\n\n#### 1) Elliptic Envelope [https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.covariance.EllipticEnvelope.html]\n#### 2) One-Class Support Vector Machines [http:\/\/rvlasveld.github.io\/blog\/2013\/07\/12\/introduction-to-one-class-support-vector-machines\/]\n#### 3) Robust Random Cut Forest [https:\/\/github.com\/awslabs\/amazon-sagemaker-examples\/tree\/master\/introduction_to_amazon_algorithms\/random_cut_forest]\n\n#### We live in a world where the data is getting bigger by the second. The value of the data can diminish over time if not used properly. Finding anomalies in a dataset is crucial to identifying problems in the business or building a proactive solution to potentially discover the problem before it happens or even in the exploratory data analysis (EDA) phase to prepare a dataset for ML. \n\n### I hope that you find the notebook useful, let me know what you think in the comments section below and connect me on LinkedIn @ [Suraj RP](https:\/\/www.linkedin.com\/in\/suraj-rp\/)\n\n","5368272f":"### Visual representation:","ec44517b":"#### Standard deviation is a metric of variance i.e. how much the individual data points are spread out from the mean. In statistics, If a data distribution is approximately normal then about 68% of the data values lie within one standard deviation of the mean and about 95% are within two standard deviations, and about 99.7% lie within three standard deviations","74b2522f":"#### I will try to explain it in a simplified manner\n### An outlier is an observation that is unlike the other observations. It is rare, or distinct, or does not fit in some way. It is also called anomalies.","e18ed9d8":"## What is the impact of Outliers on a dataset?","1aaa4697":"#### Let's define a function to find out the lower and the upper whisker using Z-Score method:","a466e46c":"# 1) DBSCAN (Density-Based Spatial Clustering of Applications with Noise):","57ed9c3d":"### As per the IQR method, there are 5 outliers.","6e2f4523":"# 2) Local Outlier Factor Method(LOF):","0623bad5":"#### For example, I'll take up the [TMedical Cost Personal Datasets](https:\/\/www.kaggle.com\/mirichoi0218\/insurance) for explaining Z-Score method.","1300eb57":"### Visual Representation:","96ccfdb6":"#### By the looks of it, it is right tailed and it surely has outliers.","247ca75d":"#### As you can see, data set with outliers has significantly different mean and standard deviation. In the first scenario, we will say that average is 5.45. But with the outlier, average soars to 30. This would change the estimate completely.","1a9ec8e1":"### According to z-score method, it has 7 outliers","7daf830e":"#### In the snippet above, we have trained our IsolationForest using the data generated, computed the anomaly score for each observation, and classified each observation as an outlier or non-outlier. The chart shows the anomaly scores and the regions where the outliers are. As expected, the anomaly score reflects the shape of the underlying distribution and the outlier regions correspond to low probability areas.","f09d993e":"#### I'll consider the 'age' and 'chol' of the heart diseases dataset for the multivariate analysis!","8ebd5536":"#### Isolation forest is an algorithm to detect outliers. It partitions the data using a set of trees and provides an anomaly score looking at how isolated the point is in the structure found. The anomaly score is then used to tell apart outliers from normal observations. \n\n#### An important concept in this method is the isolation number. The isolation number is the number of splits needed to isolate a data point. This number of splits is ascertained by following these steps:\n\n#### - A point \u201ca\u201d to isolate is selected randomly.\n#### - A random data point \u201cb\u201d is selected that is between the minimum and maximum value and different from \u201ca\u201d.\n#### - If the value of \u201cb\u201d is lower than the value of \u201ca\u201d, the value of \u201cb\u201d becomes the new lower limit.\n#### - If the value of \u201cb\u201d is greater than the value of \u201ca\u201d, the value of \u201cb\u201d becomes the new upper limit.\n#### - This procedure is repeated as long as there are data points other than \u201ca\u201d between the upper and the lower limit. \n\n#### It requires fewer splits to isolate an outlier than it does to isolate a non-outlier, i.e. an outlier has a lower isolation number in comparison to a non-outlier point. A data point is therefore defined as an outlier if its isolation number is lower than the threshold. The threshold is defined based on the estimated percentage of outliers in the data, which is the starting point of this outlier detection algorithm. ","df2e23b8":"## A) Univariate Outliers:","ae2147b1":"<img src=\"https:\/\/media.giphy.com\/media\/bWlBE4EgQrXb2\/giphy.gif\">","daab5d96":"# Outlier Detection Techniques:","8d51a358":"#### This is a clustering algorithm (an alternative to K-Means) that clusters points together and identifies any points not belonging to a cluster as outliers. It\u2019s like K-means, except the number of clusters does not need to be specified in advance.\n\n#### I will show you an example of using DBScan but before we start, let\u2019s cover some important concepts. DBScan has three important concepts:\n\n#### - Core Points: In order to understand the concept of the core points, we need to visit some of the hyperparameters used to define DBScan job. First hyperparameter (HP) is min_samples. This is simply the minimum number of core points needed in order to form a cluster. second important HP is 'eps'. 'eps' is the maximum distance between two samples for them to be considered as in the same cluster.\n#### - Border Points are in the same cluster as core points but much further away from the centre of the cluster.\n#### - Everything else is called Noise Points, those are data points that do not belong to any cluster. They can be anomalous or non-anomalous and they need further investigation. Now, let\u2019s see some code.","54aa6dae":"#### Outliers can drastically change the results of the data analysis and statistical modeling. There are numerous unfavourable impacts of outliers in the data set:\n\n#### - It increases the error variance and reduces the power of statistical tests\n#### - If the outliers are non-randomly distributed, they can decrease normality\n#### - They can bias or influence estimates that may be of substantive interest\n#### - They can also impact the basic assumption of Regression, ANOVA and other statistical model assumptions.\n\n#### To understand the impact deeply, let\u2019s take an example to check what happens to a data set with and without outliers in the data set.","83af5f56":"#### Let's perform basic EDA to analyse the dataset","ff335b1a":"#### By the looks of it, it is left tailed and it surely has outliers.","8cf36412":"#### Let's consider the students performance dataset for analysis.","a67f0900":"#### For example, I'll take up the [Student Performance in Exam DataSet](https:\/\/www.kaggle.com\/spscientist\/students-performance-in-exams) for explaining SDM.","9914773e":"### Remedial Measure:\n#### Remove the records which are above the upper bound value and records below the lower bound value!"}}