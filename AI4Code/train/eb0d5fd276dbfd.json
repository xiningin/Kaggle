{"cell_type":{"2dc517b2":"code","0088449a":"code","836301d2":"code","b4ce6c6b":"code","37ffa2d8":"code","ee9d86fc":"code","bd98937e":"code","52c142e4":"code","56a850ef":"code","69952ef7":"code","7c4ee445":"code","b6723250":"code","9cc8391e":"code","208ac81f":"code","17748bc1":"code","05986f3c":"code","77dae4e8":"code","c5646af0":"code","33786789":"code","6847d9a8":"code","15e566e7":"code","27e9ec04":"code","4935d5d3":"code","9ef68af9":"code","af5d2b7e":"code","bccab6ed":"code","8b110314":"code","6391a40b":"code","6f87643d":"code","7544ab3c":"code","5398778b":"code","77066c50":"code","e2c35f41":"code","7bf02a04":"code","7649371f":"code","cbee7b77":"code","a54c6054":"code","b99dca00":"code","6ec525ee":"code","cc860bec":"code","975ae8c8":"code","d106a216":"code","a93a2d4f":"code","dd84fd1f":"code","e5426cf5":"code","c79fab28":"code","7b95b0c4":"code","e2147e11":"code","1859809d":"code","6e18c82f":"code","e75e7130":"code","935e07d7":"code","a54780ea":"code","43e9e839":"code","bcbb57cc":"code","3551eb0b":"code","af093002":"code","4279ed60":"code","75f7196e":"code","a57f3590":"code","dffb6a71":"code","33c7b9b0":"code","a5c2b5b5":"code","074a2e62":"code","ab7f2f68":"code","1c51aef4":"code","463dfbc3":"code","21ec31a8":"code","e78a9e2f":"code","715d74d7":"code","80add9b2":"code","5c611347":"code","fa3c4a2b":"code","a6e8366e":"code","b857b2ab":"code","36c4d9dd":"code","04677638":"code","39c44bbb":"code","7c82d93a":"code","cd5a6143":"code","0149b217":"code","fc578a7a":"code","94480d88":"code","fd51972e":"code","e14202e9":"code","3d9d2c6f":"code","e1c67319":"code","2707953f":"code","19c5294c":"code","d4e89473":"code","0845979a":"code","0286832c":"code","b97cdd39":"code","dcb95bcc":"markdown","786f8814":"markdown","e9b4d5fd":"markdown","b0cf5ce4":"markdown","eb320537":"markdown","f695fa12":"markdown","42228c1b":"markdown","e86adc83":"markdown","96c9a280":"markdown"},"source":{"2dc517b2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns","0088449a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","836301d2":"data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ndata.head()","b4ce6c6b":"data=pd.read_csv('\/kaggle\/input\/house-price\/trainhouse.csv')","37ffa2d8":"data.head()","ee9d86fc":"data.shape","bd98937e":"df=data.copy()","52c142e4":"df.dtypes","56a850ef":"df.dtypes.value_counts()","69952ef7":"df.dtypes.value_counts().plot.pie()","7c4ee445":"plt.figure(figsize=(20,10))\nsns.heatmap(df.isna(),cbar=False)","b6723250":"dl=((df.isna().sum()\/df.shape[0]).sort_values(ascending=True))\npd.set_option('display.max_rows', None)\nprint(dl)","9cc8391e":"for col in df.select_dtypes('object'):\n    print(f'{col :-<50} {df[col].unique()}')\n#### too much values for encoding we have to choose un type of encoding as estimator","208ac81f":"#df['SalePrice'].unique()","17748bc1":"df = df[df.columns[df.isna().sum()\/df.shape[0] <0.9]]\ndf.head()","05986f3c":"sns.set_style(\"whitegrid\")\nax=sns.distplot(df['SalePrice'])","77dae4e8":"sns.set_style(\"whitegrid\")\nax = sns.boxplot(x=df['SalePrice'])","c5646af0":"df['SalePrice'].hist()","33786789":"for col in df.select_dtypes('object'):\n    plt.figure(figsize=(6,10))#figsize=(10,10)\n    df[col].value_counts().plot.pie()","6847d9a8":"#for col in df.select_dtypes('object'):\n #   plt.figure()#figsize=(10,10)\n #   df[col].value_counts().plot.bar(rot=0, label=col)","15e566e7":"for col in df.select_dtypes('float'):\n    plt.figure()\n    sns.distplot(df[col])","27e9ec04":"# select the float columns\ndf_num = df.select_dtypes('float')\ndf_num1=df.select_dtypes('int64')","4935d5d3":"df_num.head()","9ef68af9":"for col in df_num:\n    plt.figure()\n    sns.distplot(df[col])","af5d2b7e":"\ndf_num1.head()","bccab6ed":"for col in df_num1:\n    plt.figure()\n    sns.distplot(df[col])","8b110314":"##3pd.concat([df['SalePrice'], df['YearBuilt']], axis=1).plot.scatter","6391a40b":"df.corr()","6f87643d":"plt.figure(figsize=(12,9))\nsns.heatmap(df.corr())","7544ab3c":"matrix = df.corr().round(2)\nsns.heatmap(matrix, annot=True)\nplt.show()","5398778b":"matrix =df.corr()\nmatrix= matrix.unstack()\nmatrix = matrix[abs(matrix) >=0.7 ]\nprint(matrix)","77066c50":"matrix = df.corr().round(2)\nmask = np.triu(np.ones_like(matrix, dtype=bool))\nplt.figure(figsize=(20,10))\nsns.heatmap(matrix, annot=True, mask=mask)\nplt.show()","e2c35f41":"#for col in df:\n #   plt.figure()\n  #  sns.heatmap(pd.crosstab(df['SalePrice'], df[col]), annot=True, fmt='d')","7bf02a04":"#print(df.columns)","7649371f":"#print(df.corr().columns)","cbee7b77":"related_columns= ['OverallQual','YearBuilt', 'TotalBsmtSF','GrLivArea', 'FullBath', 'TotRmsAbvGrd',\n        'GarageCars', 'SalePrice']","a54c6054":"sns.pairplot(df[related_columns])","b99dca00":"#sns.pairplot(df[related_columns], hue=\"smoker\")","6ec525ee":"ax = sns.boxplot(x=\"OverallQual\", y=\"SalePrice\",\n                 data=df, palette=\"Set3\")\n","cc860bec":"ax1 = df.plot.scatter(x='GrLivArea',\n                      y='SalePrice')","975ae8c8":"df = data.copy()\ndf.head()","d106a216":"df = df[df.columns[df.isna().sum()\/df.shape[0] <0.9]]## removing columns with 90% of miss values\ndf.head()","a93a2d4f":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline","dd84fd1f":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer,KNNImputer","e5426cf5":"X = df.drop('SalePrice', axis=1)\ny = df.SalePrice","c79fab28":"X_train,X_test,y_train,y_test= train_test_split(X,y, test_size=0.2, random_state=0)","7b95b0c4":"from sklearn.compose import make_column_selector,make_column_transformer","e2147e11":"numerical_features = make_column_selector(dtype_include=np.number)\ncategorecal_features = make_column_selector(dtype_exclude=np.number)","1859809d":"categorecal_features","6e18c82f":"numerical_pipline=make_pipeline(SimpleImputer(strategy='most_frequent'),StandardScaler())\ncategorical_pipeline=make_pipeline(SimpleImputer(strategy='most_frequent'),OneHotEncoder(handle_unknown='ignore', sparse=False))#strategy='most_frequent'","e75e7130":"numerical_pipline_kNN=make_pipeline(KNNImputer(n_neighbors=2),StandardScaler())\ncategorical_pipeline_KNN=make_pipeline(KNNImputer(n_neighbors=2),OneHotEncoder(handle_unknown='ignore', sparse=False))","935e07d7":"preprocessor=make_column_transformer((numerical_pipline,numerical_features),(categorical_pipeline,categorecal_features))","a54780ea":"preprocessor","43e9e839":"preprocessor_KNN=make_column_transformer((numerical_pipline_kNN,numerical_features),(categorical_pipeline_KNN,categorecal_features))","bcbb57cc":"preprocessor_KNN","3551eb0b":"from sklearn.ensemble import RandomForestRegressor,StackingRegressor\nfrom sklearn.linear_model import LinearRegression,SGDRegressor\n","af093002":"model = RandomForestRegressor(n_estimators=100, random_state=0)","4279ed60":"model = make_pipeline( preprocessor,model)\n#model_KNN = make_pipeline( preprocessor_KNN,model)                            ","75f7196e":"#model_KNN.fit(X_train,y_train)","a57f3590":"#model.fit(X_train, y_train)","dffb6a71":"from sklearn.metrics import * #mean_absolute_error,median_absolute_error,mean_squared_error,r2_score\nfrom sklearn.model_selection import learning_curve","33c7b9b0":"def evaluation(model):\n    model.fit(X_train, y_train)\n    print (model.score(X_train,y_train))\n    \n    \n    ypred = model.predict(X_test)\n    print(mean_absolute_error(y_test, ypred))\n    print(mean_squared_error(y_test, ypred))\n    N, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=4, scoring='r2',\n                                               train_sizes=np.linspace(0.1, 1, 10))\n    \n    \n    plt.figure(figsize=(12, 8))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='validation score')\n    plt.legend()","a5c2b5b5":"evaluation(model)","074a2e62":"RForeg= make_pipeline(preprocessor, RandomForestRegressor(random_state=0))\nLinRge= make_pipeline(preprocessor, LinearRegression())\nSGdreg=make_pipeline(preprocessor, SGDRegressor())","ab7f2f68":"dict_of_models = {'RForeg': RForeg,\n                  'LinRget' : LinRge,\n                  'SGdreg': SGdreg,\n                \n                 }","1c51aef4":"for name, model in dict_of_models.items(): # items retour la cle et la valeur\n    print(name)\n    evaluation(model)","463dfbc3":"\nestimators = [\n    ('RForeg', RandomForestRegressor(random_state=0)),\n    ('LinRget', LinearRegression())\n]\nreg = StackingRegressor(\n    estimators=estimators,\n    final_estimator=RandomForestRegressor(n_estimators=10,\n                                           random_state=42))\nStackRegressor = make_pipeline(preprocessor, reg)","21ec31a8":"evaluation(StackRegressor)","e78a9e2f":"\nestimators = [\n    ('RForeg', RandomForestRegressor(n_estimators=10,random_state=42)),\n    ('LinRget', LinearRegression())\n]\nreg = StackingRegressor(\n    estimators=estimators,\n    final_estimator=SGDRegressor())\nStackRegressor = make_pipeline(preprocessor, reg)","715d74d7":"evaluation(StackRegressor)","80add9b2":"#model_KNN = make_pipeline(preprocessor_KNN,RandomForestRegressor(random_state=0))  ","5c611347":"#model_KNN.fit(X,y)","fa3c4a2b":"preprocessor_KNN","a6e8366e":"#evaluation(model_KNN)","b857b2ab":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV,cross_val_score","36c4d9dd":"#Ridge, Lasso, or ElasticNet.\n#\"alpha\" : [0.0001, 0.001, 0.01, 0.1],","04677638":"params = {\n    \"sgdregressor__loss\" : [\"epsilon_insensitive\", \"huber\"],\n    \"sgdregressor__penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n}\nReg  = SGdreg\ngrid = GridSearchCV(Reg, param_grid=params, scoring='r2',cv=10)\ngrid.fit(X_train, y_train)\n\nypred = grid.predict(X_test)\nprint(model.score(X_train,y_train))\nprint(grid.best_params_)\nprint(mean_absolute_error(y_test, ypred))\nprint(mean_squared_error(y_test, ypred))\nN, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=4, scoring='neg_mean_squared_error',\n                                               train_sizes=np.linspace(0.1, 1, 10))\nplt.figure(figsize=(12, 8))\nplt.plot(N, train_score.mean(axis=1), label='train score')\nplt.plot(N, val_score.mean(axis=1), label='validation score')\nplt.legend()\n","39c44bbb":"params = {\n    \"sgdregressor__loss\" : [\"epsilon_insensitive\", \"huber\"],\n    \"sgdregressor__penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n}\nReg  = SGdreg\ngrid = GridSearchCV(Reg, param_grid=params, scoring='neg_mean_squared_error',cv=10)\ngrid.fit(X_train, y_train)\n\nypred = grid.predict(X_test)\nprint(model.score(X_train,y_train))\nprint(grid.best_params_)\nprint(mean_absolute_error(y_test, ypred))\nprint(mean_squared_error(y_test, ypred))\nN, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=10, scoring='neg_mean_squared_error',\n                                               train_sizes=np.linspace(0.1, 1, 10))\nplt.figure(figsize=(12, 8))\nplt.plot(N, train_score.mean(axis=1), label='train score')\nplt.plot(N, val_score.mean(axis=1), label='validation score')\nplt.legend()\n","7c82d93a":"#model = SGDRegressor(loss='epsilon_insensitive',penalty= 'l1')\n#model = make_pipeline( preprocessor,model)","cd5a6143":"params = {\n    \"sgdregressor__loss\" : [\"epsilon_insensitive\", \"huber\"],\n    \"sgdregressor__penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n}\nReg  = SGdreg\ngrid = GridSearchCV(Reg, param_grid=params, scoring='r2',cv=10)\ngrid.fit(X_train, y_train)\n\nypred = grid.predict(X_test)\nprint(model.score(X_train,y_train))\nprint(grid.best_params_)\nprint(mean_absolute_error(y_test, ypred))\nprint(mean_squared_error(y_test, ypred))\nN, train_score, val_score = learning_curve(model, X_train, y_train,\n                                              cv=10, scoring='r2',\n                                               train_sizes=np.linspace(0.1, 1, 10))\nplt.figure(figsize=(12, 8))\nplt.plot(N, train_score.mean(axis=1), label='train score')\nplt.plot(N, val_score.mean(axis=1), label='validation score')\nplt.legend()\n","0149b217":"grid.best_estimator_","fc578a7a":"model_final=grid.best_estimator_","94480d88":"data_test=pd.read_csv('test_house.csv')","fd51972e":"data_test.head()","e14202e9":"data_test= data_test[data_test.columns[data_test.isna().sum()\/data_test.shape[0] <0.9]]## removing columns with 90% of miss values\ndata_test.head()","3d9d2c6f":"Price = data_test['Id']","e1c67319":"prediction=model.predict(data_test)","2707953f":"prediction= pd.DataFrame(prediction,columns=['SalePrice'])\nprediction = pd.merge(Price, prediction, left_index=True, right_index=True)\nprediction","19c5294c":"prediction.shape","d4e89473":"prediction.to_csv('houcePriceSubmission.csv', index=False)","0845979a":"from sklearn.preprocessing import PolynomialFeatures\n#model = make_pipeline(PolynomialFeatures(2), preprocessor,model)\n#model = make_pipeline(PolynomialFeatures(2),model)","0286832c":"col_to_exclude ='MSSubClass'    \nnumerical_pipline = make_column_transformer((numerical_pipline, make_column_selector(pattern=f'^(?!{col_to_exclude})')))\n\ncategorical_pipeline =make_column_transformer((numerical_pipline, make_column_selector(pattern=f'^(?!{col_to_exclude})')))","b97cdd39":"#model = make_pipeline(PolynomialFeatures(2,include_bias=False), preprocessor,model)\n","dcb95bcc":"params = {\n    \"sgdregressor__loss\" : [\"epsilon_insensitive\", \"huber\"],\n    \"sgdregressor__penalty\" : [\"l2\", \"l1\", \"elasticnet\"],\n}\nReg  = SGdreg\ngrid = RandomizedSearchCV(Reg, param_grid=params, scoring='r2',cv=10,n_iter=10)\ngrid.fit(X_train, y_train)\nprint(model.score(X_train,y_train))\nypred = grid.predict(X_test)\n","786f8814":"### Objectif:\n\n    #### Undertsand our dataset\n    #### develop a first modeling strategy\n\n       Predict the Price of saling house (previor le prix dune maison a vendre): SalePrice\n       \n### Basic Checklist :\n       \n   #### Form Analysis:\n   \n       \n       *Targe varriable:  SalePrice\n       *Nmbr of rows and columns:  (1460, 81)\n       *Types of Variables:  object     43\n                             float64    38\n       **analysis of NaN variable:  Fence            80.7%\n                                    Alley            93.7%\n                                    MiscFeature      96.3%\n                                    PoolQC           99.5%\n           \n   #### Content Analysis :\n    *Targe varriable:  SalePrice: the min of price is about 50000 the max is 350000 the most houses have a price oround 160000 and 210000 \n    \n    *variable qualitative : dificult to make analysis some variable have too much values and some the frequency is very high \n           - street the 'Pave'is around 95% 'Grv 5%\n           -Alley ::Grvl' 50 %'Pave'50% ( same frequency) with some nan value\n           -Utilities: AllPub'95% 'NoSeWa'5%\n           -LandSlope:'Gtl' most frequence than'Mod' 'Sev'\n           -Condition2:'Norm'is the most value frequent    'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe'\n           -Heating::'GasA' is the most exist 'GasW' 'Grav' 'Wall' 'OthW' 'Floor'\n           -CentralAir::y and 'N', 'Y' the most used \n           -Electrical:SBrkr' the most used ve some houses are without  'FuseF' 'FuseA' 'FuseP' 'Mix' nan\n           -Functional: Typ' is the most 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev'\n           -GarageQual:'TA' is the most 'Fa' 'Gd' nan 'Ex' 'Po'\n           -GarageQual:TA' is the most 'Fa' 'Gd' nan 'Ex' 'Po'\n           -GarageCond: 'TA'is the most 'Fa' nan 'Gd' 'Po' 'Ex'\n           -PavedDrive:Y is the most used' 'N' 'P']\n           \n    *numeric variables :2 categories Continue and discontinue\n    \n            some variable got one value distubition is saw as a pic maye those variables have no effect to the Saleprice\n           \n            \n            \n  ### Relation Variables\/Variables       \n            \n           we have a fort correlation between GrLivArea and TotRmsAbvGrd    : 0.825489\n                                              1stFlrSF and TotalBsmtSF      : 0.819530\n                                              YearBuilt and GarageYrBlt     : 0.825667\n                                              GarageArea and GarageCars     : 0.88247\n                                              \n           ====> mayebe we can keep one variable                                   \n  ### Relation Variables\/Target                                           \n   #### fort correlation\n   \n      *For  OverallQual   0.790982\n       and we an see that the salePrice increase with  OverallQual(It rates the overall material and finish of the house on a scale from 1 (very poor) to 10 (very excellent).\n            \n       *For GrLivArea  ( Grade Living Area) big houses are expensive      0.708624\n       * there is 2 outliers big houses but with a low price\n         \n   #### weak correlation         \n               \n       after we chek the correletion between Saleprice and those value we result that no relation is between SalePrice and:\n               MSSubClass      -0.084284\n               OverallCond     -0.077856\n               BsmtFinSF2      -0.011378\n               LowQualFinSF    -0.025606\n               BsmtHalfBath    -0.016844\n               BedroomAbvGr     0.168213\n               KitchenAbvGr    -0.135907\n               EnclosedPorch   -0.128578\n               3SsnPorch        0.044584\n               ScreenPorch      0.111447\n               PoolArea         0.092404\n               MiscVal         -0.021190\n               MoSold           0.046432\n               YrSold          -0.028923\n               \n       Maybe we can remove them     \n       \n  #### Analyse of NaN :   \n                        Fence            80.7%\n                        Alley            93.7%\n                         MiscFeature      96.3%\n                        PoolQC           99.5%\n                        \n                        \n  #### Feature enginering:\n  ","e9b4d5fd":"#col_to_exclude ='MSSubClass'#, ' BsmtFinSF2','LowQualFinSF','BsmtHalfBath',\n                     #'BedroomAbvGr','KitchenAbvG','EnclosedPorch','3SsnPorch','ScreenPorch','MiscVal','MoSold','YrSold'], inplace=True)\n   \n    \n#col_to_exclude ='MiscVal'\n#numerical_pipline = make_column_transformer((numerical_pipline, make_column_selector(pattern=f'^(?!{col_to_exclude})')))\n\n#categorical_pipeline =make_column_transformer((numerical_pipline, make_column_selector(pattern=f'^(?!{col_to_exclude})')))\n\ncol_to_exclude ='MSSubClass'    \nnumerical_pipline = make_column_transformer((numerical_pipline, make_column_selector(pattern=f'^(?!{col_to_exclude})')))\n\ncategorical_pipeline =make_column_transformer((numerical_pipline, make_column_selector(pattern=f'^(?!{col_to_exclude})')))","b0cf5ce4":"###### for RandomRegression Forest we have the best score 97% but overfiting\n###### for Linerair Regression  we can see that the model learned but it seems there is a problem (mybe underfiting)\n###### the SGDRegross got the less Score but he seems learning good","eb320537":"### RandomForest model","f695fa12":"### PRE-PROCESSING","42228c1b":"### TrainTest - Nettoyage - Encodage","e86adc83":"OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\nprint(OH_X_train)","96c9a280":"### Relation Variables \/ Target:"}}