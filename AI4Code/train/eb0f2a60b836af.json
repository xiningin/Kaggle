{"cell_type":{"fc3a4024":"code","fd4dfadb":"code","3805ccb4":"code","1d4af486":"code","016ff310":"code","05e581ce":"code","d85d776e":"code","07988b84":"code","62ae048b":"code","9ba2b040":"code","110cd944":"code","450d0bd1":"code","9265e505":"code","c6b1d987":"code","65bddabd":"code","b1bf458d":"code","0cade647":"code","c45d1c23":"code","de5e5b3b":"code","711291a1":"code","9f0fb792":"code","c27c9a7a":"code","5e714f18":"code","5a081e18":"code","b2a1b368":"code","b46fedef":"code","751a13b6":"code","e892a4f5":"code","14133f56":"markdown","49edac84":"markdown","9c6ff4e9":"markdown","9b6b96c2":"markdown","dcde2537":"markdown","2d22c181":"markdown","4f903b7d":"markdown","81355a21":"markdown"},"source":{"fc3a4024":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd4dfadb":"%matplotlib inline\nimport os\nimport warnings\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as image\nimport pandas as pd\nplt.style.use(\"ggplot\")\nwarnings.simplefilter(\"ignore\")","3805ccb4":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_train.head()","1d4af486":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test.head()","016ff310":"df_train.info()","05e581ce":"pd.crosstab(df_train.Sex ,df_train.Survived).plot(kind='bar')\nplt.title('Survival rate as per Sex')\nplt.xlabel('Sex')\nplt.ylabel('Survived')\nplt.show()","d85d776e":"pd.crosstab(df_train.Pclass ,df_train.Survived).plot(kind='bar')\nplt.title('Survival rate as per Pclass')\nplt.xlabel('Pclass')\nplt.ylabel('Survived')\nplt.show()","07988b84":"df_train['Age'].isna().sum()","62ae048b":"df_train['Age'] = df_train['Age'].fillna(0)\ndf_train['Age'].isna().sum()","9ba2b040":"pd.crosstab(df_train.Embarked ,df_train.Survived).plot(kind='bar')\nplt.title('Survival rate as per Embarked')\nplt.xlabel('Embarked')\nplt.ylabel('Survived')\nplt.show()","110cd944":"pd.crosstab(df_train.Parch ,df_train.Survived).plot(kind='bar')\nplt.title('Survival rate as per Parch')\nplt.xlabel('Parch')\nplt.ylabel('Survived')\nplt.show()","450d0bd1":"df_train.drop(columns = ['Name','Ticket' ,'Fare' , 'Cabin']  , inplace= True)","9265e505":"df_train.head(5)","c6b1d987":"df_train.info()","65bddabd":"cat_vars=['Sex' , 'Embarked']\nfor var in cat_vars:\n    cat_list='var'+'_'+var\n    cat_list = pd.get_dummies(df_train[var], prefix=var)\n    df_train1=df_train.join(cat_list)\n    df_train=df_train1","b1bf458d":"df_train.columns","0cade647":"df_train.drop(columns = ['Sex','Embarked']  , inplace= True)\ndf_train.head(5)","c45d1c23":"df_train.info()","de5e5b3b":"s=0\nd=0\nfor i in df_train['Survived']:\n  if i==0:\n    d+=1\n  else:\n    s+=1\n\nprint('Dead - ',d,' Survived -',s)","711291a1":"X = df_train.loc[:, df_train.columns != 'Survived']\nY = df_train.Survived","9f0fb792":"df_test['Age'] = df_test['Age'].fillna(0)\ndf_test.info()","c27c9a7a":"df_test.drop(columns = ['Name','Ticket' ,'Fare','Cabin']  , inplace= True)\ndf_test.info()","5e714f18":"cat_vars=['Sex' , 'Embarked']\nfor var in cat_vars:\n    cat_list='var'+'_'+var\n    cat_list = pd.get_dummies(df_test[var], prefix=var)\n    df_test1=df_test.join(cat_list)\n    df_test=df_test1","5a081e18":"df_test.head()","b2a1b368":"df_test.drop(columns=['Sex' , 'Embarked'] , inplace=True)\ndf_test.info()","b46fedef":"from sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import export_graphviz # display the tree within a Jupyter notebook\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\nfrom ipywidgets import interactive, IntSlider, FloatSlider, interact\nimport ipywidgets\nfrom IPython.display import Image\nfrom subprocess import call\nimport matplotlib.image as mpimg","751a13b6":"@interact\ndef plot_tree_rf(crit=[\"gini\", \"entropy\"],\n                 bootstrap=[\"True\", \"False\"],\n                 depth=IntSlider(min=1,max=30,value=3, continuous_update=False),\n                 forests=IntSlider(min=1,max=200,value=100,continuous_update=False),\n                 min_split=IntSlider(min=2,max=5,value=2, continuous_update=False),\n                 min_leaf=IntSlider(min=1,max=5,value=1, continuous_update=False)):\n    \n    estimator = RandomForestClassifier(random_state=1,\n                                       criterion=crit,\n                                       bootstrap=bootstrap,\n                                       n_estimators=forests,\n                                       max_depth=depth,\n                                       min_samples_split=min_split,\n                                       min_samples_leaf=min_leaf,\n                                       n_jobs=-1,\n                                      verbose=False).fit(X, Y)\n\n    print('Random Forest Training Accuracy: {:.3f}'.format(accuracy_score(Y, estimator.predict(X))))\n    num_tree = estimator.estimators_[0]\n    print('\\nVisualizing Decision Tree:', 0)\n    \n    graph = Source(tree.export_graphviz(num_tree,\n                                        out_file=None,\n                                        feature_names=X.columns,\n                                        class_names=['0', '1'],\n                                        filled = True))\n    \n    display(Image(data=graph.pipe(format='png')))\n    \n    return estimator","e892a4f5":"estimator = plot_tree_rf(crit='gini', bootstrap='False' , depth =16  , forests=100 , min_split=3 , min_leaf= 3)\n\ny_pred_rf = estimator.predict(df_test)\nprint('len',len(y_pred_rf))\n\nsub = pd.DataFrame(columns=['PassengerId' , 'Survived'])\n\nsub['PassengerId'] = df_test['PassengerId'].astype(int)\nsub['Survived'] = y_pred_rf.astype(int)\n\nsub.to_csv('sub_rf.csv', index=False)","14133f56":"# If you like my work don't forget to Upvote!","49edac84":"# **Welcome to this Notebook on Interactive Training of Random Forest for Titanic Dataset!!**","9c6ff4e9":"I noticed that the sliders are not visible while viewing, so if you want to check that out just press the copy and edit button on the top right hand corner.","9b6b96c2":"Here comes the interactive training part!!\nYou have to just slide to the values you want and the model will train for that values!","dcde2537":"Modifying Test Data","2d22c181":"**Filling Null values of age with 0.\nUsually we don't do that but it seems to work fine for this**","4f903b7d":"Below I am using values which I have tested to get into top my best accuracy so far!!","81355a21":"**Training**"}}