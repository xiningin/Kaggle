{"cell_type":{"5db3a853":"code","f347648e":"code","a2abb588":"code","67fb2390":"code","384cf410":"code","8535c283":"code","81e10009":"code","5ce5548c":"code","b59e0bad":"code","86ee9093":"code","8611ade7":"code","902fa583":"code","47838afc":"code","8ecf875f":"code","4a3c3200":"markdown","11f03f14":"markdown","302d9fea":"markdown","17da48f4":"markdown"},"source":{"5db3a853":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f347648e":"# import essential modules\n\n# basic modules\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Models from scikit-learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import train_test_split\n\n\n# Model Evaluations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error,mean_squared_error, r2_score\nfrom sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.ensemble import RandomForestRegressor\n","a2abb588":"# import dataset\nfilename = '\/kaggle\/input\/body-performance-data\/bodyPerformance.csv'\ndf = pd.read_csv(filename)\ndf.head()","67fb2390":"# check dataset details\ndf.info()","384cf410":"%%time\n# let's view our correlaton matrix. (how each feature relates to another)\ncorr_matrix = df.corr()\nfig, ax = plt.subplots(figsize=(10, 10))\nax = sns.heatmap(corr_matrix,\n                annot = True,\n                linewidth = 0.5,\n                fmt=\".2f\",\n                cmap=\"YlGnBu\")","8535c283":"# add feature 'BMI' to dataset\n# calculate BMI\ndf['BMI'] = df['weight_kg']\/df['height_cm'] * 10000","81e10009":"# convert categorical data to numerical data\nfor label, content in df.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        # turn categories to numbers \n        df[label] = pd.Categorical(content).codes","5ce5548c":"# view new dataset\ndf.head()","b59e0bad":"# split data into X and y\n\nfeatures = df.drop(\"class\", axis=1)\nlabels = df['class']\n\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, \n                                                     labels,\n                                                     test_size=0.2)","86ee9093":"# train Random Forest Classifier Model\nrf_model = RandomForestClassifier()\n\n# fit model\nrf_model.fit(train_features, train_labels)","8611ade7":"# evaluate model\ndef evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors \/ test_labels)\n    accuracy = 100 - mape\n    print('Model Peformance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Precision Score: {:.2f}'.format(precision_score(test_labels, predictions, average='weighted')))\n#     print('Accuracy =',accuracy + 100)\n    print('\\n')\n    print(classification_report(test_labels, predictions))","902fa583":"evaluate(rf_model, test_features, test_labels)","47838afc":"%%time\n# improving our resut usig grid search\n\n# create param grid\nparam_grid = {\n    'bootstrap':[True],\n    'max_depth':[25, 26, 27, 28, 29, 30],\n    'max_features':['auto'],\n    'min_samples_leaf':[2, 4, 6, 8],\n    'min_samples_split':[5, 10, 25, 20],\n    'n_estimators':[100, 120, 130, 140, 150]\n}\n\n# create a base model\nrf_model_2 = RandomForestClassifier()\n\n# instantiate the grid search model\ngrid_search = GridSearchCV(estimator=rf_model_2,\n                          param_grid=param_grid,\n                          cv=5,\n                          n_jobs=-1, \n                          verbose=2)\n","8ecf875f":"%%time\n# fit the grid search to the data\ngrid_search.fit(train_features, train_labels)\n\ngrid_search.best_params_","4a3c3200":"## Picking suitable model\n\ncompare different model scores on the data to see which model is suitable to use.","11f03f14":"# Data Preprocessing","302d9fea":"## Body Performance - Predicting Body Class\n\nFrom the body performance Dataset, we have \n* age\n* gender\n* height\n* weight\n* body fat (%)\n* diastolic pressure\n* systolic pressure\n* grip-force\n* sit and bend forward\n* sit-up counts\n* broad jump (cm)\n\nin this notebook we will train an ML model to predict body class from the available features\n","17da48f4":"# Modeling\n\nnow we're done processing our data\n\nwe can build models to : \n* classifying data based on body class\n"}}