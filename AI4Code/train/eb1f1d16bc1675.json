{"cell_type":{"7803e4cd":"code","49281657":"code","ae9da65d":"code","1e331934":"code","5bed38de":"code","e15abfd4":"code","e8422bd7":"code","67efdc67":"code","5a69a019":"code","348b41ce":"code","89d6ae9a":"code","5425a853":"code","35d93e45":"code","2b01dc15":"code","82c05cae":"code","eb4054df":"code","7e7619b1":"code","6e844eb8":"code","ac8542a9":"code","7b3272bf":"code","b6994b57":"code","9ff5824e":"code","ce76ea6f":"code","15294c57":"code","5044a279":"code","0b193f49":"code","e263bc63":"code","07f8411a":"code","bd1be39c":"code","29931cac":"code","3a6ac5ff":"code","c42e253c":"code","9aecf5d5":"code","cbbeb001":"code","b8fa950f":"code","dc3c06bc":"code","c4485e8c":"code","112adcca":"code","4a771f5c":"code","0f618d40":"code","543904a8":"code","f7ca440c":"code","acf50bd5":"code","76030522":"code","dac9eb79":"code","14555cb5":"code","ef5ee215":"code","b698fcb1":"code","8092c26e":"code","b988662f":"code","706ea3b3":"code","c8359818":"code","80e47a5b":"code","2bf950b4":"code","8c457ca8":"code","3ef7823e":"code","d1f18b7b":"code","72e74e05":"code","26ea6a2e":"code","9e7c6f50":"code","cd90e497":"code","52cd17ff":"code","896b0ed5":"code","4ce50860":"code","f2e15877":"code","0ce18c69":"code","b0493fb6":"code","ec84def0":"code","5fbfd4ca":"code","78d98c5c":"code","d808e637":"code","967ae8b5":"code","1f6afaa9":"code","a5f4f12f":"code","1be011d9":"markdown"},"source":{"7803e4cd":"import sys\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport xgboost as xgb\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, make_scorer, matthews_corrcoef\n\nimport os\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom collections import Counter\nlabel = LabelEncoder()\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","49281657":"np.set_printoptions(threshold=sys.maxsize)","ae9da65d":"train = pd.read_csv(\"..\/input\/fraud-ug\/training.csv\")\ntrain[\"train\"] = 1\ntrain.head()","1e331934":"train.shape","5bed38de":"fraud_data = train[train[\"FraudResult\"] == 1.0]","e15abfd4":"train.shape","e8422bd7":"test = pd.read_csv(\"..\/input\/fraud-test\/test.csv\")\ntest[\"train\"] = 0\ntest.head()","67efdc67":"dataset = pd.concat([train, test], ignore_index=True)","5a69a019":"dataset.shape","348b41ce":"train.head()","89d6ae9a":"# time\ndataset[\"TransactionStartTime\"] = dataset[\"TransactionStartTime\"].apply(lambda x : pd.to_datetime(x))\n# dataset[\"Month\"] = dataset[\"TransactionStartTime\"].dt.month\n# dataset[\"day_of_month\"] = dataset[\"TransactionStartTime\"].dt.day\ndataset[\"day_of_week\"] = dataset[\"TransactionStartTime\"].dt.dayofweek\n# dataset[\"day_of_year\"] = dataset[\"TransactionStartTime\"].dt.dayofyear\ndataset[\"time\"] = dataset[\"TransactionStartTime\"].dt.time\ndataset[\"minute\"] = dataset[\"time\"].apply(lambda x: int(str(x).split(\":\")[0]) * 60 + int(str(x).split(\":\")[1]))","5425a853":"dataset.Amount.mean()","35d93e45":"dataset.SubscriptionId = pd.DataFrame(label.fit_transform(dataset.SubscriptionId))\ndataset.BatchId = pd.DataFrame(label.fit_transform(dataset.BatchId))\ndataset.CustomerId = pd.DataFrame(label.fit_transform(dataset.CustomerId))\ndataset.AccountId = pd.DataFrame(label.fit_transform(dataset.AccountId))\n","2b01dc15":"dataset = pd.concat([dataset, pd.get_dummies(dataset[\"ChannelId\"], prefix=\"Channel_Id_\")], axis=1)\ndataset = pd.concat([dataset, pd.get_dummies(dataset[\"PricingStrategy\"], prefix=\"PricingStrategy_\")], axis=1)\ndataset = pd.concat([dataset, pd.get_dummies(dataset[\"ProductCategory\"], prefix=\"ProductCategory_\")], axis=1)\ndataset = pd.concat([dataset, pd.get_dummies(dataset[\"ProductId\"], prefix=\"ProductId_\")], axis=1)\ndataset = pd.concat([dataset, pd.get_dummies(dataset[\"ProviderId\"], prefix=\"ProviderId_\")], axis=1)\n","82c05cae":"dataset[\"weekday\"] = dataset[\"TransactionStartTime\"].dt.weekday_name","eb4054df":"dataset = pd.concat([dataset, pd.get_dummies(dataset[\"weekday\"], prefix=\"weekday\")], axis=1)","7e7619b1":"# id\n# dataset.SubscriptionId = pd.DataFrame(label.fit_transform(dataset.SubscriptionId))\n# # dataset.BatchId = pd.DataFrame(label.fit_transform(dataset.BatchId))\n# dataset.CustomerId = pd.DataFrame(label.fit_transform(dataset.CustomerId))\n# dataset.AccountId = pd.DataFrame(label.fit_transform(dataset.AccountId))","6e844eb8":"# dataset[\"AccountId\"] = dataset[\"AccountId\"].apply(lambda x: int(x.split(\"_\")[1]))\n# dataset[\"SubscriptionId\"] = dataset[\"SubscriptionId\"].apply(lambda x: int(x.split(\"_\")[1]))\n# dataset[\"CustomerId\"] = dataset[\"CustomerId\"].apply(lambda x: int(x.split(\"_\")[1]))\n# dataset[\"BatchId\"] = dataset[\"BatchId\"].apply(lambda x: int(x.split(\"_\")[1]))","ac8542a9":"dataset.shape","7b3272bf":"dataset.shape","b6994b57":"# group = dataset[[\"AccountId\", 'Amount', 'Month']].groupby(by=[\"AccountId\", 'Amount'])[['Month']].mean().reset_index().rename(index=str, columns={'Month': 'Cust_value_month'})\n# dataset = dataset.merge(group, how='left')","9ff5824e":"# group = dataset[[\"AccountId\", 'Amount', 'Month']].groupby(by=[\"AccountId\", 'Amount'])[['Month']].count().reset_index().rename(index=str, columns={'Month': 'Cust_value_month_count'})\n# dataset = dataset.merge(group, how='left')","ce76ea6f":"# group = dataset[['AccountId','Amount', 'PricingStrategy', 'ProductId','ProviderId', 'CustomerId', 'day_of_week', 'ChannelId']].groupby(by=['CustomerId', 'ProductId', 'ProviderId', 'ChannelId', 'Amount'])[['day_of_week']].mean().reset_index().rename(index=str, columns={'day_of_week': 'Cust_prod_mean_dayofweek'})\n# dataset = dataset.merge(group, on=['CustomerId', 'ProductId', 'ProviderId', 'ChannelId'], how='left')\n","15294c57":"# group = dataset[['CustomerId', 'ProductId', 'ProviderId', 'ChannelId', 'Amount', 'day_of_week']].groupby(by=['CustomerId', 'ProductId', 'ProviderId', 'ChannelId', 'Amount',])[['day_of_week']].count().reset_index().rename(index=str, columns={'day_of_week': 'Cust_prod_mean_dayofweek'})\n# dataset = dataset.merge(group, on=['CustomerId', 'ProductId', 'ProviderId', 'ChannelId',], how='left')","5044a279":"dataset.drop([\"CurrencyCode\", \"CountryCode\", \"BatchId\", \"time\", \"TransactionStartTime\", \"ChannelId\", \"PricingStrategy\", \"ProductCategory\", \"ProductId\", \"ProviderId\", \"weekday\"], axis=1, inplace=True)","0b193f49":"train = dataset[dataset[\"train\"] == 1]\ntest = dataset[dataset[\"train\"] == 0]","e263bc63":"test.shape","07f8411a":"train.drop([\"train\"], axis=1, inplace=True)\ntest.drop([\"train\", \"FraudResult\"], axis=1, inplace=True)","bd1be39c":"from sklearn.decomposition import PCA\n\n\nreduced = PCA(n_components=2).fit_transform(train.drop([\"TransactionId\", \"FraudResult\"], axis=1).values)\n\nplt.figure()\nplt.scatter(reduced[train[\"FraudResult\"] == 0, 0], reduced[train[\"FraudResult\"] == 0, 1], color='blue')\nplt.scatter(reduced[train[\"FraudResult\"] == 1, 0], reduced[train[\"FraudResult\"] == 1, 1], color='red', marker='x')\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")","29931cac":"from sklearn.model_selection import train_test_split","3a6ac5ff":"train.drop([\"TransactionId\"], axis=1, inplace=True)","c42e253c":"X = train.drop([\"FraudResult\"], axis=1)\ny = train[\"FraudResult\"]","9aecf5d5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","cbbeb001":"print(\"Fraud case\", (train[\"FraudResult\"].value_counts()[1]\/ len(train) * 100), \"% of the dataset\")\nprint (\"Train size\", y_train.shape[0], \"Fraud in train size\", y_train[y_train == 1].shape[0] \/ y_train.shape[0] * 100)\nprint (\"Test size\", y_test.shape[0], \"Fraud in tesst size\", y_test[y_test == 1].shape[0] \/ y_test.shape[0] * 100)","b8fa950f":"# # implement grid search\n# rfc_param_grid = {\n#     'n_estimators': [200, 250, 300, 400],\n#     'max_depth': [5, 7, 8, 10],\n#   \n# }\n","dc3c06bc":"# rfc_sk =  RandomForestClassifier(random_state=1)","c4485e8c":"# from sklearn.model_selection import GridSearchCV\n# grid_mse = GridSearchCV(param_grid=rfc_param_grid, estimator=rfc_sk,\n# scoring=\"f1\", cv=4 )","112adcca":"# grid_mse.fit(X, y)","4a771f5c":"# grid_mse.best_params_","0f618d40":"# grid_mse.best_score_","543904a8":"from sklearn.svm import SVC","f7ca440c":"svc = SVC(random_state=1)","acf50bd5":"gbc = GradientBoostingClassifier(n_estimators=200, max_depth=5)","76030522":"gbc.fit(X_train, y_train)","dac9eb79":"gbc_pred = gbc.predict(X_test)","14555cb5":"print(classification_report(y_test, gbc_pred))","ef5ee215":"# classifier\nxg_cl = xgb.XGBClassifier(objective=\"binary:logistic\",\n                          n_estimators=200, colsample_bytree=0.7, subsample=0.7, max_depth=5, learning_rate=0.1, seed=1)\n","b698fcb1":"MCC_scorer = make_scorer(matthews_corrcoef)","8092c26e":"# rfc = RandomForestClassifier(random_state=1, max_depth=8, n_estimators=200,)\npipeline_rf = Pipeline([\n    ('model', RandomForestClassifier(max_depth=9, n_jobs=-1, random_state=1))\n])\nparam_grid_rf = {'model__n_estimators': [50, 75, 100, 150, 200, 250, 300]\n                 }\n\ngrid_rf = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid_rf,\n                       scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs',\n                       cv=8, verbose=1, return_train_score=False)\n\ngrid_rf.fit(X_train, y_train)","b988662f":"grid_rf.fit(X_train, y_train)","706ea3b3":"grid_rf_pred = grid_rf.predict(X_test)","c8359818":"print(\"rfc \", classification_report(y_test, grid_rf_pred) )","80e47a5b":"xg_cl.fit(X_train, y_train)","2bf950b4":"preds = xg_cl.predict(X_test)","8c457ca8":"print(classification_report(y_test, preds))","3ef7823e":"test.head()","d1f18b7b":"xgb.plot_importance(xg_cl)\nplt.rcParams['figure.figsize'] = [15, 5]","72e74e05":"# combine models\n# gbc\n# xgb\n# rfc\nmodels = [\n    xgb.XGBClassifier(objective=\"binary:logistic\",\n                          n_estimators=200, colsample_bytree=0.7, subsample=0.7, max_depth=5, learning_rate=0.1, seed=1),\n    RandomForestClassifier(random_state=1, max_depth=8, n_estimators=200,)\n    \n]\n\npreds = pd.DataFrame()\nfor i, m in enumerate(models):\n    print(m)\n    m.fit(X_train, y_train),\n    preds[i] = m.predict_proba(X_test)[:,1]\n\nweights = [0.3, 1]\npreds['weighted_pred'] = (preds * weights).sum(axis=1) \/ sum(weights)\npreds.head()","26ea6a2e":"total_pred = np.where(preds[\"weighted_pred\"] > 0.5, 1, 0)","9e7c6f50":"print(classification_report(y_test, total_pred))","cd90e497":"test_pred = pd.DataFrame()\ntest_pred['TransactionId'] = test[\"TransactionId\"]\ntest_sub = test.copy()\ntest_sub.drop([\"TransactionId\"], axis=1, inplace=True)","52cd17ff":"models = [\n    xgb.XGBClassifier(objective=\"binary:logistic\",\n                          n_estimators=200, colsample_bytree=0.7, subsample=0.7, max_depth=5, learning_rate=0.1, seed=1),\n    RandomForestClassifier(random_state=1, max_depth=8, n_estimators=200,)\n    \n]\n\npreds = pd.DataFrame()\nfor i, m in enumerate(models):\n    m.fit(X_train, y_train),\n    preds[i] = m.predict_proba(test_sub)[:,1]\n\nweights = [0.3, 1]\npreds['weighted_pred'] = (preds * weights).sum(axis=1) \/ sum(weights)\npreds.head()","896b0ed5":"# predict_test = np.where(preds[\"weighted_pred\"] > 0.5, 1, 0)\npredict_test = grid_rf.predict(test_sub)\ntest_pred['FraudResult'] = predict_test\ntest_pred.to_csv('submission.csv', index=False)","4ce50860":"import lightgbm as lgbm","f2e15877":"X_train, X_valid, Y_train, Y_valid = train_test_split(X, y, test_size=0.33, random_state=42)","0ce18c69":"# making lgbm datasets for train and valid\nd_train = lgbm.Dataset(X_train, Y_train)\nd_valid = lgbm.Dataset(X_valid, Y_valid)\n    ","b0493fb6":"params = {\n    'objective' :'binary',\n    'learning_rate' : 0.02,\n    'num_leaves' : 76,\n    'feature_fraction': 0.64, \n    'bagging_fraction': 0.8, \n    'bagging_freq':1,\n    'boosting_type' : 'gbdt',\n    'metric': 'binary_logloss'\n}","ec84def0":"bst =lgbm.train(params,\n                d_train,\n                valid_sets=[d_valid],\n                verbose_eval=10,\n                early_stopping_rounds=100)\n    ","5fbfd4ca":"test.head()","78d98c5c":"test_pred = pd.DataFrame()\ntest_pred['TransactionId'] = test[\"TransactionId\"]\ntest.drop([\"TransactionId\"], axis=1, inplace=True)","d808e637":"lgbm_preds = bst.predict(test)\nlen(lgbm_preds)\n# lgbm_preds = np.where(lgbm_preds > 0.5, 1, 0)\nlen(lgbm_preds)\ntest_pred['FraudResult'] = lgbm_preds\ntest_pred.to_csv('submission_lgbm.csv', index=False)","967ae8b5":"test.shape","1f6afaa9":"# len(y_pred)","a5f4f12f":"# print('this SVM', classification_report(y_test, y_pred_test))","1be011d9":"##### logistc regression"}}