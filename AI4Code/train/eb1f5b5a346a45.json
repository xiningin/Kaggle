{"cell_type":{"fe392e4a":"code","364a36f8":"code","ee560934":"code","c0c3b6df":"code","a70b9dae":"code","a0322221":"code","316d69f3":"code","ba9eafba":"code","ea4dc5a6":"code","0d2ded21":"code","1484988b":"code","4dbc0eab":"code","8ce5357f":"code","89cffb77":"code","62d6200d":"code","4eb2076c":"code","1ba05939":"code","bf393fd5":"code","5068f60c":"code","6b35c8a5":"code","5b20abb9":"code","579f56da":"markdown","33c29bc1":"markdown","8f684e18":"markdown","53a607eb":"markdown","31a820f6":"markdown","c7eee0d9":"markdown","6a40116f":"markdown","bc291d4c":"markdown","154745a8":"markdown","89d2d65b":"markdown","91595bec":"markdown","7fb92ff9":"markdown","38add8d9":"markdown","9e3e486e":"markdown","60412bf1":"markdown","93bc48dc":"markdown"},"source":{"fe392e4a":"# Importing necessary libraries\n\nimport pandas as pd\nimport numpy as np","364a36f8":"# Importing and Loading the data into data frame\n\nmarket_df = pd.read_csv(\"..\/input\/market.csv\")\ncustomer_df = pd.read_csv(\"..\/input\/customer.csv\")\nproduct_df = pd.read_csv(\"..\/input\/product.csv\")\nshipping_df = pd.read_csv(\"..\/input\/shipping.csv\")\norders_df = pd.read_csv(\"..\/input\/order.csv\")\n\n# Merging the dataframes to create a master_df\ndf_1 = pd.merge(market_df, customer_df, how='inner', on='Cust_id')\ndf_2 = pd.merge(df_1, product_df, how='inner', on='Prod_id')\ndf_3 = pd.merge(df_2, shipping_df, how='inner', on='Ship_id')\nmaster_df = pd.merge(df_3, orders_df, how='inner', on='Ord_id')\n","ee560934":"master_df.head()","c0c3b6df":"#Identifying Missing Values in Column\nmaster_df.isnull().sum()","a70b9dae":"#a single index\n#Using pandas.DataFrame.pivot_table\nmaster_df.pivot_table(index = 'Customer_Segment')\n","a0322221":"#Same as above - results in same output\n#Using pandas.pivot_table\npd.pivot_table(master_df, index = 'Customer_Segment')","316d69f3":"#multiple indexes\nmaster_df.pivot_table(index =['Customer_Segment','Product_Category'])","ba9eafba":"#Single value\nmaster_df.pivot_table(values = 'Sales', index = 'Customer_Segment')","ea4dc5a6":"#multiple value\nmaster_df.pivot_table(values = ['Order_Quantity','Sales'], index = 'Customer_Segment')","0d2ded21":"#Single aggrigate function(mean) and single value\nmaster_df.pivot_table(values = 'Sales', index = 'Customer_Segment', aggfunc = 'mean')","1484988b":"#Single aggrigate function(sum) and single value\nmaster_df.pivot_table(values = 'Order_Quantity', index = 'Region', aggfunc = 'sum')","4dbc0eab":"#Sum aggregate function is applied to both the values\nmaster_df.pivot_table(values = ['Order_Quantity','Sales'], index = 'Product_Category', aggfunc='sum')","8ce5357f":"#multiple Aggregating Function applied to single column\nmaster_df.pivot_table(values = 'Sales', index = 'Product_Category', aggfunc=['sum', 'count'])","89cffb77":"#Sum and Mean aggregate function is applied to both the values\nmaster_df.pivot_table(values = ['Order_Quantity','Sales'], index = 'Product_Category', aggfunc=[np.sum, np.mean])","62d6200d":"#different aggregate applied to different values\nmaster_df.pivot_table(index = 'Product_Category', aggfunc = {'Order_Quantity':sum, 'Sales':'mean'})","4eb2076c":"#Single column\n#Grouping by both rows and column\nmaster_df.pivot_table(values = 'Profit', \n                      index = 'Product_Category', \n                      columns = 'Customer_Segment', \n                      aggfunc = 'sum')","1ba05939":"#multiple columns\nmaster_df.pivot_table(values = 'Profit', \n                      index = 'Customer_Segment', \n                      columns = ['Product_Category','Ship_Mode'], \n                      aggfunc = 'count')","bf393fd5":"#Margin\nmaster_df.pivot_table(values = 'Profit', \n index = 'Product_Category', \n columns = 'Customer_Segment', \n aggfunc = 'sum', margins=True)","5068f60c":"#margins_name\nmaster_df.pivot_table(values = 'Profit', \n                      index = 'Product_Category', \n                      columns = 'Customer_Segment', \n                      aggfunc = 'sum', \n                      margins=True,\n                      margins_name ='TOTAL')","6b35c8a5":"#Displaying NaN values in the table\n#These can be imputed using fill_value\nmaster_df.pivot_table(values = 'Product_Base_Margin', \n                      index = 'Customer_Name', \n                     columns = 'Customer_Segment', \n                      aggfunc = 'mean')","5b20abb9":"#imputing with mean using fill_value\nmaster_df.pivot_table(values = 'Product_Base_Margin', \n                      index = 'Customer_Name', \n                     columns = 'Customer_Segment', \n                      aggfunc = 'mean', fill_value=np.mean(master_df['Product_Base_Margin']))","579f56da":"### **References**\n[Documentation](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.pivot_table.html)\n","33c29bc1":"![Capture_27%20%282%29.PNG](attachment:Capture_27%20%282%29.PNG)","8f684e18":"#### Extracting first few\u00a0rows","53a607eb":"#### At this point, we barely have any idea of what dataset looks like. So let's now look into the usage of pivot_table() in multiple different ways to explore the data further.","31a820f6":"### **1. group data using index in a pivot\u00a0table**\nIndex is the column, grouper, array, or list we'd like to group our data by. The simplest pivot table requires a dataframe and an index\u00a0. The index features will be displayed in the index column in the resultant table. By default, it will average all the numerical columns data when the value and aggfunc parameters are not specified.","c7eee0d9":"### Syntax : pandas.DataFrame.pivot_table()\n\n### Parameters :","6a40116f":"### **4. relationship between features with columns parameter**\nThe column parameter displays the values horizontally on the top of the resultant table. Most of the time there is confusion with the pivot_table related to the use of columns and values\u00a0. Bear in mind, columns are optional, they provide a supplementary way to segment the actual values we care about. The aggregation functions are applied to values we list.","bc291d4c":"### **3. Manipulating the data using\u00a0aggfunc**\nAs mentioned before, pivot_table uses mean function (numpy.mean) for aggregating or summarizing data by default. But there are other important function or list of functions to consider. aggfunc is an aggregate function that pivot_table applies to our grouped data. aggfunc (optional) accepts a function or list of functions we'd like to use in our group. The aggregation specification can be a string such as 'sum', 'mean', 'count', 'min', 'max', etc or a function that implements an aggregation (e.g. np.sum(), min(), sum(), etc). Now its time to experiment with the aggfunc parameter.","154745a8":"### Exploratory data analysis is an important phase of the Machine Learning projects. The wonderful Pandas library is equipped with several useful functions for this purpose. One among them is pivot_table that summarizes a feature's values in a neat two-dimensional table. The data summarization tool frequently found in data analysis software, offering a ton of flexibility. DataFrame has a pivot_table method(pandas.DataFrame.pivot_table), and additionally, there is a top-level pandas.pivot_table function(any of them can be used as per the convenience, both results in the same output). Most often we end up using pivot_table with the default parameters. This article will help you achieve more by optimal usage of the default parameters.","89d2d65b":"## Pivot Tables: Data Aggregation tools in\u00a0Python","91595bec":"![title](https:\/\/cdn-images-1.medium.com\/max\/1000\/0*Ol4m2kahvJyzHeIY)","7fb92ff9":"### **6. Handling missing\u00a0data**\nThe NaN's are a bit distracting. pivot_table helps us to deal with it through the parameters dropna and fill_value. Two of these options, fill_value and dropna, have to do with missing data and are fairly straightforward.\ndropna is type boolean, and allows us to drop the null values in the grouped table whose entries are all NaN. It defaults to True.\nfill_value is type scalar, and can be used to replace the NaN values in the table with the values that we provide. It defaults to None.","38add8d9":"### **5. Adding total rows\/columns**\nAt times it's useful to compute totals along each grouping. Now, if we want to see some totals of the data, margins=True does that for us. margins is type boolean that adds all rows and columns (e.g. for subtotal \/ grand totals) and defaults to 'False'.","9e3e486e":"## **pivot_table()**\nThe pivot_table() method returns a DataFrame which is an Excel-style pivot table. The pivot table aggregates a table of data by one or more keys, arranging the data in a rectangle with some of the group keys along the rows and some along the columns into a two-dimensional table that provides a multidimensional summarization of the data.","60412bf1":"### **2. Aggregate on specific features with\u00a0values**\nThe value parameter is where we tell the function which features to aggregate on. It is an optional field and if we don't specify this value, then the function will aggregate on all the numerical features of the dataset. In the previous example of indexes, we saw that the aggregation was done for all numerical columns. Since the value parameter was not specified, pivot_table, by default considered all numerical columns.","93bc48dc":"### Thus, we can see that pivot_table() is a handy tool, and we can do some interesting analysis with this single line of code. As you build up the pivot table, I think it's easiest to take it one step at a time. Add items and check each step to verify if you are getting the results you expect and see what presentation makes the most sense for your needs. As soon as you start playing with the data and slowly add the items, you can get a feel for how it works.We've covered the powerful parameters of pivot_table\u00a0, so you can get a lot out of it if you go experiment using these methods on your project."}}