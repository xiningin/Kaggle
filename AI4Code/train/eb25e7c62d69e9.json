{"cell_type":{"94d56bf2":"code","6f828cd3":"code","8eee8de7":"code","3b89bced":"code","ace957fa":"code","b5a8e15b":"code","47ffbcfb":"code","348a226f":"code","4b2c09b3":"code","4445dbc3":"code","b8ed56fa":"code","fc1fcb30":"code","9f69847f":"code","d3f44f9b":"code","f4025d44":"code","e5eb88b5":"code","22b35d26":"code","97bf0df9":"code","c50306f1":"code","2b1e5780":"code","2750a503":"code","fac81b2f":"code","99df87e3":"code","e0071201":"code","5aeea634":"code","4184eaec":"code","31d2ecfe":"code","ef97d348":"code","c2fd9eb6":"code","b75f1d2c":"code","7f1e7645":"code","465b8b3c":"code","68a53b8d":"code","5bde4b47":"code","cc799fa6":"code","9b0294a1":"code","7406adc7":"code","bbf89e28":"code","17fcf8b8":"code","c4a77b00":"code","ba9c01b0":"code","3b208040":"code","614fd444":"code","7c73ca92":"code","22be0511":"code","91d99236":"code","17fdaaaf":"code","7d5c1a11":"code","87e7db5b":"code","e011004e":"code","09bdc0ba":"code","7319d39e":"code","4380d8e0":"code","9922f58d":"code","0d835df4":"code","90a93135":"code","726b4766":"code","31c95f8b":"code","faaf52ba":"code","5a6984a8":"code","362c6498":"code","86aff1e9":"code","22255d69":"code","127a6cea":"code","8796beb3":"code","e1dd0000":"code","89fde0b3":"code","4b784995":"code","47f83553":"code","95f58403":"code","28d16215":"code","a6d95170":"code","ea72b26b":"code","e32f96dc":"code","5edb852b":"code","6bcbb677":"code","5e518b0b":"code","12f73a87":"code","f1ff5cf3":"code","53e336a1":"code","0aed9494":"code","1937856e":"code","cfe023ab":"code","cdbc9bf8":"code","d174f5dc":"code","6697bc29":"code","e79ef080":"code","2c594024":"code","0846c5a4":"code","717bde46":"code","f95ce7a5":"code","3db5cc97":"code","3520ab24":"markdown","58a4e3ab":"markdown","a46448d6":"markdown","7f958806":"markdown","29da3fef":"markdown","9178b2fe":"markdown","24048b94":"markdown","657ed00a":"markdown","22f133ae":"markdown","52f32eb1":"markdown","e6bbbbc5":"markdown","0debdeb0":"markdown","72b0467a":"markdown","ac35698b":"markdown","43ae7f01":"markdown","43d47d7c":"markdown","8d51d613":"markdown","8c2b5a26":"markdown","4a1a3a0b":"markdown","cb12225d":"markdown","03e4de70":"markdown","d003bf19":"markdown","b5d1958c":"markdown","4c9c50d2":"markdown","d6ca866e":"markdown","d16af59d":"markdown","91a1ee49":"markdown","ffe2575d":"markdown","ee175d84":"markdown","a6e1aa2c":"markdown","23eee783":"markdown","0deac503":"markdown","64f14d33":"markdown","16f50434":"markdown","915bc19e":"markdown","54c1aff2":"markdown","6eb6fbb6":"markdown","a5e7344b":"markdown","489b47ff":"markdown","aab1df44":"markdown","3bc6a64d":"markdown","39e4c699":"markdown","ba8f7c21":"markdown","dca27985":"markdown","8dbd7b64":"markdown","9a163fd8":"markdown","99e92399":"markdown","dd393e53":"markdown","319610f3":"markdown","81a29bae":"markdown","1696f5c4":"markdown"},"source":{"94d56bf2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.inspection import permutation_importance","6f828cd3":"df =pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","8eee8de7":"df.info()","3b89bced":"df.shape","ace957fa":"X = df.drop(['customerID','Churn'],axis=1)\nY = df['Churn']","b5a8e15b":"plt.figure(figsize=(8,8))\ndf.Churn.value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05))\nplt.title('Target Variable \"Churn\"')","47ffbcfb":"df.isnull().sum()","348a226f":"fig, (ax) = plt.subplots(8, 2, figsize=(15,60))\n\nfeat = df[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'PhoneService', 'MultipleLines', 'InternetService',\n       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n       'PaymentMethod']]\n\nfeat['gender'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05),ax =ax[0][0])\nax[0][0].set_title('Gender')\nfeat['SeniorCitizen'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05),ax =ax[0][1])\nax[0][1].set_title('Senior Citizen')\nfeat['Partner'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05),ax =ax[1][0])\nax[1][0].set_title('Partner')\nfeat['Dependents'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05),ax =ax[1][1])\nax[1][1].set_title('Dependent')\nfeat['PhoneService'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05),ax =ax[2][0])\nax[2][0].set_title('PhoneService')\nfeat['MultipleLines'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[2][1])\nax[2][1].set_title('MultipleLines')\nfeat['InternetService'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[3][0])\nax[3][0].set_title('InternetServices')\nfeat['OnlineSecurity'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[3][1])\nax[3][1].set_title('OnlineSecurity')\nfeat['OnlineBackup'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[4][0])\nax[4][0].set_title('OnlineBackup')\nfeat['DeviceProtection'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[4][1])\nax[4][1].set_title('DeviceProtection')\nfeat['TechSupport'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[5][0])\nax[5][0].set_title('TechSupport')\nfeat['StreamingTV'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[5][1])\nax[5][1].set_title('StreamingTV')\nfeat['StreamingMovies'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[6][0])\nax[6][0].set_title('StremingMovie')\nfeat['Contract'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05),ax =ax[6][1])\nax[6][1].set_title('Contract')\nfeat['PaperlessBilling'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05),ax =ax[7][0])\nax[7][0].set_title('PaperBilling')\nfeat['PaymentMethod'].value_counts().plot(kind='pie',autopct='%1.1f%%',explode=(0.05,0.05,0.05,0.05),ax =ax[7][1])\nax[7][1].set_title('PaymentMethod')\n\nplt.suptitle(\n    \"Categorical Features\", fontweight=\"bold\")\nplt.show()","4b2c09b3":"feat = feat.astype('category')","4445dbc3":"categorical_features = pd.get_dummies(feat)","b8ed56fa":"X.tenure = df.tenure.astype(int)","fc1fcb30":"X.TotalCharges = pd.to_numeric(X.TotalCharges, errors='coerce')","9f69847f":"numerical_features = X[['tenure','MonthlyCharges','TotalCharges']]","d3f44f9b":"## Tenure\nsns.violinplot(x=X.tenure, y=Y)\nplt.title('Tenure Distribution')","f4025d44":"## Monthly Charges\nsns.violinplot(x=X.MonthlyCharges, y=Y)\nplt.title('Monthly Charges Distribution')","e5eb88b5":"## Total Charges\nsns.violinplot(x=X.TotalCharges, y=Y)\nplt.title('Total Charges Distribution')","22b35d26":"dat = categorical_features\nfor col in numerical_features:\n    dat[col] = numerical_features[col]","97bf0df9":"dat.shape","c50306f1":"labelencoder = LabelEncoder()\ndaf = dat\ndaf['Y'] = Y\ndaf.Y = labelencoder.fit_transform(daf.Y)","2b1e5780":"colormap = plt.cm.RdBu\nplt.figure(figsize=(40,35))\nplt.title('Correlation', y=1.025, size=30)\nsns.heatmap(daf.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","2750a503":"colormap = plt.cm.BrBG\nplt.figure(figsize=(14,12))\nplt.title('Correlation', y=1.025, size=20)\nsns.heatmap(daf[['OnlineSecurity_No',\n       'OnlineSecurity_No internet service', 'OnlineSecurity_Yes',\n       'OnlineBackup_No', 'OnlineBackup_No internet service',\n       'OnlineBackup_Yes', 'DeviceProtection_No',\n       'DeviceProtection_No internet service', 'DeviceProtection_Yes',\n       'TechSupport_No', 'TechSupport_No internet service', 'TechSupport_Yes',\n       'StreamingTV_No', 'StreamingTV_No internet service', 'StreamingTV_Yes',\n       'StreamingMovies_No', 'StreamingMovies_No internet service',\n       'StreamingMovies_Yes', 'Contract_Month-to-month', 'Contract_One year',\n       'Contract_Two year', 'PaperlessBilling_No', 'PaperlessBilling_Yes','Y']].astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","fac81b2f":"# Monthly Charges\nsns.boxplot(x=X.MonthlyCharges, y=Y)\nplt.title('Monthly Charges Distribution')","99df87e3":"#Tenure\nsns.boxplot(x=X.tenure, y=Y)\nplt.title('Tenure Distribution')","e0071201":"dat.tenure[dat.tenure > 70].value_counts()","5aeea634":"# Total Charges\nsns.boxplot(x=X.TotalCharges, y=Y)\nplt.title('Total Charges Distribution')","4184eaec":"data_X = dat.drop(['Y'],axis=1) \ndata_X.shape","31d2ecfe":"data_Y = dat.Y","ef97d348":"total = data_X.isnull().sum().sort_values(ascending=False) # missing values analysis\npercent = (data_X.isnull().sum()\/data_X.isnull().count()).sort_values(ascending=False) # percentage of missing values \nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(5)","c2fd9eb6":"data_X.TotalCharges.fillna(data_X.TotalCharges.median(), inplace = True)","b75f1d2c":"data_X.TotalCharges.isnull().sum()","7f1e7645":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(data_X, data_Y, test_size = 0.2) ","465b8b3c":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX__train = scaler.fit_transform(X_train)\nX__test = scaler.transform(X_test)","68a53b8d":"plt.figure(figsize=(12,8))\nmodel = KNeighborsClassifier()\nmodel.fit(X__train, Y_train)\nresults = permutation_importance(model, X__train, Y_train, scoring='accuracy')\nimportance = results.importances_mean\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","5bde4b47":"model = KNeighborsClassifier()\nmodel.fit(data_X[['tenure','MonthlyCharges','TotalCharges',]], data_Y)\nresults = permutation_importance(model, data_X[['tenure','MonthlyCharges','TotalCharges']], data_Y, scoring='accuracy')\nimportance = results.importances_mean\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","cc799fa6":"data_le = feat\nfor cols in feat:\n    data_le[cols] = labelencoder.fit_transform(feat[cols])\n    \ndata_le['tenure'] = data_X['tenure']\ndata_le['MonthlyCharges'] = data_X['MonthlyCharges']\ndata_le['TotalCharges'] = data_X['TotalCharges']","9b0294a1":"colormap = plt.cm.RdBu\nplt.figure(figsize=(18,16))\nplt.title('Correlation', y=1.025, size=30)\nsns.heatmap(data_le.astype(float).corr(),linewidths=0.1,vmax=0.5, \n            square=True, cmap=colormap, linecolor='white', annot=True)","7406adc7":"X_tr, X_t, Y_tr, Y_t = train_test_split(data_le, data_Y, test_size = 0.2)\n\nX__tr = scaler.fit_transform(X_tr)\nX__t = scaler.transform(X_t)","bbf89e28":"plt.figure(figsize=(12,8))\nmodel = KNeighborsClassifier()\nmodel.fit(X__tr, Y_tr)\nresults = permutation_importance(model, X__tr, Y_tr, scoring='accuracy')\nimportance = results.importances_mean\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","17fcf8b8":"from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n\nclassifier = GradientBoostingClassifier()\nclassifier.fit(X__tr, Y_tr)","c4a77b00":"classifier.feature_importances_","ba9c01b0":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nMLP = MLPClassifier(hidden_layer_sizes=(20,6))\nMLP.fit(X__tr, Y_tr)","3b208040":"plt.figure(figsize=(12,8))\nresults = permutation_importance(MLP, X__tr, Y_tr, scoring='accuracy')\nimportance = results.importances_mean\n\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","614fd444":"'''\nlsst = []\nfor i in range(20):    \n    minimum,maximum = data_le[:,i].min(), data_le[:,i].max()  # minimum and maximum value of tenure\n    arr = np.arange(minimum, maximum, (maximum - minimum)\/100) # randomized array between min and max of 100 values\n\n    lst = []\n    for variation in arr:\n        val = list(data_le.median().values) # saving all rows median values in a list\n        val[i] = variation\n        lst.append(val)  \n    lst = np.array(lst)\n    lst = scaler.transform(lst)\n    MLP.predict(lst)\n'''","7c73ca92":"import shap\nfrom sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(max_depth=8, random_state=19)\nRFC.fit(X__tr, Y_tr)","22be0511":"shap_values = shap.TreeExplainer(RFC).shap_values(X__tr)\nshap.summary_plot(shap_values, X__tr)","91d99236":"import xgboost\n\n# train XGBoost model\n \nmodel_ = xgboost.XGBClassifier().fit(X__tr, Y_tr)\n\n# compute SHAP values\nshap_values = shap.TreeExplainer(model_).shap_values(X__tr)\n","17fdaaaf":"shap.summary_plot(shap_values, X__tr)","7d5c1a11":"data_for_prediction = pd.DataFrame(X__tr).iloc[35]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nprint(model_.predict_proba(data_for_prediction_array))","87e7db5b":"explainer = shap.TreeExplainer(model_)\nshap_values = explainer.shap_values(X__tr)","e011004e":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[0], data_for_prediction_array)","09bdc0ba":"shap.force_plot(explainer.expected_value, shap_values[1], data_for_prediction)","7319d39e":"shap.force_plot(explainer.expected_value, shap_values[2], data_for_prediction)","4380d8e0":"shap.force_plot(explainer.expected_value, shap_values[3], data_for_prediction)","9922f58d":"shap.force_plot(explainer.expected_value, shap_values[4], data_for_prediction)","0d835df4":"shap.force_plot(explainer.expected_value, shap_values[5], data_for_prediction)","90a93135":"shap.force_plot(explainer.expected_value, shap_values[6], data_for_prediction)","726b4766":"shap.force_plot(explainer.expected_value, shap_values, X__tr)","31c95f8b":"k_explainer = shap.KernelExplainer(model_.predict_proba, X__tr)\nk_shap_values = k_explainer.shap_values(data_for_prediction)\nshap.force_plot(k_explainer.expected_value[1], k_shap_values[1], data_for_prediction)","faaf52ba":"for cols in X_tr[['MonthlyCharges',\"TotalCharges\",\"tenure\"]]:\n    shap.dependence_plot(cols, shap_values, X_tr)","5a6984a8":"shap_interaction_values = shap.TreeExplainer(model_).shap_interaction_values(pd.DataFrame(X_tr).iloc[:2000,:])","362c6498":"shap.summary_plot(shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:])","86aff1e9":"fig, (ax) = plt.subplots(2, 2, figsize=(16,12))\nshap.dependence_plot(\n    ('tenure', 'SeniorCitizen'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[0][0]\n)\nshap.dependence_plot(\n    ('tenure', 'Partner'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[0][1]\n)\nshap.dependence_plot(\n    ('tenure', 'Contract'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[1][0]\n)\nshap.dependence_plot(\n    ('tenure','TotalCharges'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[1][1]\n)\n\nplt.show()","22255d69":"fig, (ax) = plt.subplots(2, 2, figsize=(16,12))\nshap.dependence_plot(\n    ('MonthlyCharges', 'Contract'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[0][0]\n)\nshap.dependence_plot(\n    ('MonthlyCharges', 'StreamingTV'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[0][1]\n)\nshap.dependence_plot(\n    ('MonthlyCharges', 'Dependents'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[1][0]\n)\nshap.dependence_plot(\n    ('MonthlyCharges','Partner'),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[1][1]\n)\n\nplt.show()","127a6cea":"fig, (ax) = plt.subplots(2, 2, figsize=(16,12))\nshap.dependence_plot(\n    ('TotalCharges', \"DeviceProtection\"),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[0][0]\n)\nshap.dependence_plot(\n    ('TotalCharges', \"OnlineBackup\"),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[0][1]\n)\nshap.dependence_plot(\n    ('TotalCharges', \"Contract\"),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[1][0]\n)\nshap.dependence_plot(\n    ('TotalCharges',\"MultipleLines\"),\n    shap_interaction_values, pd.DataFrame(X_tr).iloc[:2000,:],\n    display_features= X_tr.iloc[:2000,:],\n    show = False,\n    ax = ax[1][1]\n)\n\nplt.show()","8796beb3":"explainer = shap.TreeExplainer(model_)\nexpected_value = explainer.expected_value\n\nshap.decision_plot(expected_value, shap_values[0:100,], pd.DataFrame(X_tr).iloc[0:100,])","e1dd0000":"shap.decision_plot(expected_value, shap_values[0:1999,], pd.DataFrame(X_tr).iloc[0:1999,])","89fde0b3":"shap.decision_plot(expected_value, shap_values[2000:2500,], pd.DataFrame(X_tr).iloc[2000:2500,])","4b784995":"shap.decision_plot(expected_value, shap_values[0:1999,], pd.DataFrame(X_tr).iloc[0:1999,],  feature_order='hclust', return_objects=True)","47f83553":"shap.decision_plot(expected_value, shap_values[2000:3999,], pd.DataFrame(X_tr).iloc[2000:3999,],  feature_order='hclust', return_objects=True)","95f58403":"shap.decision_plot(expected_value, shap_values[4000:5999,], pd.DataFrame(X_tr).iloc[4000:5999,],  feature_order='hclust', return_objects=True)","28d16215":"df_s = data_le\ndf_y = labelencoder.fit_transform(df['Churn'])","a6d95170":"import seaborn as sns\nimport numpy as np\nimport math\nimport scipy.stats as ss\nimport matplotlib.pyplot as plt\n\ndef skew_autotransform(DF, include = None, exclude = None, plot = False, threshold = 1, exp = False):\n    \n    #Get list of column names that should be processed based on input parameters\n    if include is None and exclude is None:\n        colnames = DF.columns.values\n    elif include is not None:\n        colnames = include\n    elif exclude is not None:\n        colnames = [item for item in list(DF.columns.values) if item not in exclude]\n    else:\n        print('No columns to process!')\n    \n    #Helper function that checks if all values are positive\n    def make_positive(series):\n        minimum = np.amin(series)\n        #If minimum is negative, offset all values by a constant to move all values to positive teritory\n        if minimum <= 0:\n            series = series + abs(minimum) + 0.01\n        return series\n    \n    \n    #Go throug desired columns in DataFrame\n    for col in colnames:\n        #Get column skewness\n        skew = DF[col].skew()\n        transformed = True\n        \n        if plot:\n            #Prep the plot of original data\n            sns.set_style(\"darkgrid\")\n            sns.set_palette(\"Blues_r\")\n            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n            ax1 = sns.distplot(DF[col], ax=axes[0])\n            ax1.set(xlabel='Original ' + col)\n        \n        #If skewness is larger than threshold and positively skewed; If yes, apply appropriate transformation\n        if abs(skew) > threshold and skew > 0:\n            skewType = 'positive'\n            #Make sure all values are positive\n            DF[col] = make_positive(DF[col])\n            \n            if exp:\n               #Apply log transformation \n               DF[col] = DF[col].apply(math.log)\n            else:\n                #Apply boxcox transformation\n                DF[col] = ss.boxcox(DF[col])[0]\n            skew_new = DF[col].skew()\n         \n        elif abs(skew) > threshold and skew < 0:\n            skewType = 'negative'\n            #Make sure all values are positive\n            DF[col] = make_positive(DF[col])\n            \n            if exp:\n               #Apply exp transformation \n               DF[col] = DF[col].pow(10)\n            else:\n                #Apply boxcox transformation\n                DF[col] = ss.boxcox(DF[col])[0]\n            skew_new = DF[col].skew()\n        \n        else:\n            #Flag if no transformation was performed\n            transformed = False\n            skew_new = skew\n        \n        #Compare before and after if plot is True\n        if plot:\n            print('\\n ------------------------------------------------------')     \n            if transformed:\n                print('\\n %r had %r skewness of %2.2f' %(col, skewType, skew))\n                print('\\n Transformation yielded skewness of %2.2f' %(skew_new))\n                sns.set_palette(\"Paired\")\n                ax2 = sns.distplot(DF[col], ax=axes[1], color = 'r')\n                ax2.set(xlabel='Transformed ' + col)\n                plt.show()\n            else:\n                print('\\n NO TRANSFORMATION APPLIED FOR %r . Skewness = %2.2f' %(col, skew))\n                ax2 = sns.distplot(DF[col], ax=axes[1])\n                ax2.set(xlabel='NO TRANSFORM ' + col)\n                plt.show()\n                \n\n    return DF\n","ea72b26b":"transformedDF = df_s\ntransformedDF['MonthlyCharges'] = skew_autotransform(df_s[['MonthlyCharges']].copy(deep=True), plot = True, \n                                   exp = True, threshold = 0.7, exclude = ['B','LSTAT'])\n\ntransformedDF['TotalCharges'] = skew_autotransform(df_s[['TotalCharges']].copy(deep=True), plot = True, \n                                   exp = True, threshold = 0.7, exclude = ['B','LSTAT'])\n\ntransformedDF['tenure'] = skew_autotransform(df_s[['tenure']].copy(deep=True), plot = True, \n                                   exp = True, threshold = 0.7, exclude = ['B','LSTAT'])\n\n\n\nprint('Average skewness after transformation is %2.2f' %(np.mean(abs(transformedDF.skew()))))","e32f96dc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix, roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.over_sampling import SMOTE\nimport xgboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","5edb852b":"# transform the dataset Oversampling to be exact\noversample = SMOTE()\nx_, y_ = oversample.fit_resample(transformedDF, df_y)","6bcbb677":"x_train, x_test, y_train, y_test = train_test_split(x_, y_, test_size = 0.2) \nx__train = scaler.fit_transform(x_train)\nx__test = scaler.transform(x_test)","5e518b0b":"LR = LogisticRegression()\nSVD = SVC()\nKNC = KNeighborsClassifier()\nP = Perceptron()\nDTC = DecisionTreeClassifier()\nXGB = xgboost.XGBClassifier()\nRF = RandomForestClassifier()\nML = MLPClassifier()\nGBC = GradientBoostingClassifier()","12f73a87":"param_LR = {'C':[0.001,0.01,0.1,1,10,100]}\n\nclf1= GridSearchCV(LR, param_LR, cv=5)\nclf1.fit(x__train, y_train)\npred=clf1.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\nAcc_LR = acc","f1ff5cf3":"param_SVD =  {\n    'C' : [1, 2, 3, 4],\n    'kernel' : ['linear', 'rbf', 'sigmoid']    \n}\n\nclf2= GridSearchCV(SVD, param_LR, cv=5)\nclf2.fit(x__train, y_train)\npred=clf2.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\n\nAcc_SVD = acc","53e336a1":"param_KNC = {\n    'n_neighbors':np.arange(1,50),\n    'leaf_size' : [30,20,40] \n}\n\nclf3= GridSearchCV(KNC, param_KNC, cv=5, n_jobs= -1)\nclf3.fit(x__train, y_train)\npred=clf3.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\nAcc_KNC = acc","0aed9494":"perceptron = Perceptron()\nperceptron.fit(x__train, y_train)\npred = perceptron.predict(x__test)\nacc = accuracy_score(y_test,pred)\nprint('accuracy_score',acc)\nAcc_P = acc","1937856e":"param_DTC = {\n    'criterion' : ['gini' ,'entropy'],\n    'max_depth' : [ 3, 5, 7, 9, 11, 13, 15, 17],\n    \"min_samples_leaf\": [ 1, 3, 5, 7, 9, 13, 11]\n}\n\nclf4= GridSearchCV(DTC, param_DTC, cv=5, n_jobs= -1)\nclf4.fit(x__train, y_train)\npred=clf4.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\n\nAcc_DTC = acc","cfe023ab":"param_XGB = {\n     'max_depth':range(3,10,2),\n     'min_child_weight':range(1,10,2),\n     'max_depth':[4,5,6,7,8],\n     'min_child_weight':[4,5,6,7,8],\n     'learning_rate' : [0.1, 0.001],\n     'gamma':[i\/10.0 for i in range(0,5)]\n}\n\nclf5= GridSearchCV(XGB, param_XGB, cv=5, n_jobs= -1)\nclf5.fit(x__train, y_train)\npred=clf5.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\n\nAcc_XGB = acc","cdbc9bf8":"param_RFC = {\n    'max_depth' : [4, 6, 8, 10, 12],\n    'max_leaf_nodes' :  [3, 6, 9, 12, 14],\n    'min_samples_leaf': [1, 3, 5, 7],\n    'n_estimators' : [80, 100, 120, 140]\n}\nclf6= GridSearchCV(RF, param_RFC, cv=5, n_jobs= -1)\nclf6.fit(x__train, y_train)\npred=clf6.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\n\nAcc_RFC = acc","d174f5dc":"param_ML = {\n    'hidden_layer_sizes': [(10,30,10),(20,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}\n\nclf7= GridSearchCV(ML, param_ML, cv=3, n_jobs=-1)\nclf7.fit(x__train, y_train)\npred=clf7.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\nAcc_ML = acc","6697bc29":"param_GBC = {\n    'n_estimators':range(20,81,10),\n    'max_depth':range(5,16,2), \n    'min_samples_split':range(200,1001,200),\n    'min_samples_leaf':range(30,71,10)\n}\n\nclf8= GridSearchCV(GBC, param_GBC, cv=5, n_jobs= -1)\nclf8.fit(x__train, y_train)\npred=clf8.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\nAcc_GBC = acc","e79ef080":"from sklearn.ensemble import AdaBoostClassifier\nparam_AC = {\n    \"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n    \"base_estimator__splitter\" :   [\"best\", \"random\"],\n    \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n    \"n_estimators\" :[10, 100, 200, 250],\n    \"learning_rate\":  [0.05, 0.5, 1.5, 2.5]\n}\n\nAC = AdaBoostClassifier(\n    DecisionTreeClassifier())\n\nclf9= GridSearchCV(AC, param_AC, cv=3, n_jobs= -1)\nclf9.fit(x__train, y_train)\npred=clf9.predict(x__test)\nacc = accuracy_score(y_test,pred)\n\nprint('accuracy_score',acc)\nAcc_AC = acc","2c594024":"models = pd.DataFrame( {\n'Models' : ['Logistic Regression', 'Support Vector Machine', \n         'KNeighbours Classfier', 'Perceptron',\n         'Decision Tree Classifier', 'XGBoost Classifier',\n         'Random Forest Classifier', 'Multi-Layer Perceptron',\n         'Gradient Boosting Classifier', 'Ada Boost Classifier'],\n'Score' : [Acc_LR*100, Acc_SVD*100, Acc_KNC*100,\n        Acc_P*100, Acc_DTC*100, Acc_XGB*100,\n        Acc_RFC*100, Acc_ML*100, Acc_GBC*100, Acc_AC*100]\n})\n\nmodels.sort_values(by='Score', ascending=False)","0846c5a4":"# models.plot(kind='line',x='Score',y='Models',figsize=(14,12))\nplt.figure(figsize=(14,6))\nsns.lineplot(data=models, x=\"Models\", y=\"Score\",ci=None, marker='o')\nplt.xticks(rotation = 45)\nplt.show()","717bde46":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\ny_test_pred = clf5.predict(x__test)\ny_train_pred = clf5.predict(x__train)\n\nprint(\"TRAINIG RESULTS: \\n=========================================================\")\nclf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\nprint(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\nprint(\"\\n\")\nprint(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\nprint(\"\\n=========================================================\")\n\nprint(\"TESTING RESULTS: \\n=========================================================\")\nclf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\nprint(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\nprint(\"\\n\")\nprint(f\"CLASSIFICATION REPORT:\\n{clf_report}\")","f95ce7a5":"from sklearn.metrics import precision_recall_curve, roc_curve\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc=\"upper left\")\n    plt.title(\"Precision\/Recall Tradeoff\")\n    \n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], \"k--\")\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    \n    \nprecisions, recalls, thresholds = precision_recall_curve(y_test, clf5.predict(x__test))\nplt.figure(figsize=(14, 25))\nplt.subplot(4, 2, 1)\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n\nplt.subplot(4, 2, 2)\nplt.plot(precisions, recalls)\nplt.xlabel(\"Precision\")\nplt.ylabel(\"Recall\")\nplt.title(\"PR Curve: precisions\/recalls tradeoff\");\n\nplt.subplot(4, 2, 3)\nfpr, tpr, thresholds = roc_curve(y_test, clf5.predict(x__test))\nplot_roc_curve(fpr, tpr)","3db5cc97":"plt.figure(figsize=(12,6))\ny_pred_proba = clf5.predict_proba(x__test)[::,1]\nfpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"Area Under Curve=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","3520ab24":"###### Cloned\/Taken from https:\/\/github.com\/datamadness\/Automatic-skewness-transformation-for-Pandas-DataFrame\/blob\/master\/TEST_skew_autotransform.py","58a4e3ab":"### Feature Engineering","a46448d6":"### ReCreating Data","7f958806":"##### Models Accuracy Analysis","29da3fef":"##### Total Charges","9178b2fe":"##### KNN Label Encoded Feature PFI","24048b94":"##### K Neighbour Classifier","657ed00a":"##### PFI (Permutation Feature Importance)","22f133ae":"##### Kernel Explainer","52f32eb1":"##### Multi Layer Perceptron Feature Importance","e6bbbbc5":"##### Logistic Regression","0debdeb0":"##### Monthly Charges","72b0467a":"##### KNN Numerical Feature PFI","ac35698b":"##### SHAP Analysis","43ae7f01":"##### Correlation","43d47d7c":"##### Feature Desicion Explainer first 100 entries","8d51d613":"##### Outlier Detetction","8c2b5a26":"##### GradientBoost Label ENcoded Feature PFI","4a1a3a0b":"##### Gradient Boosting Classfier","cb12225d":"##### Area Under Curve","03e4de70":"##### Random Forest Classifier","d003bf19":"##### SKewness","b5d1958c":"##### KNN total feature PFI","4c9c50d2":"\n\n##### XGBoost Classifier","d6ca866e":"#### Feature Desicion Explainer  100-200 entries","d16af59d":"##### Numerical features","91a1ee49":"#### Missing Values","ffe2575d":"###### tenure","ee175d84":"#### Churn Data","a6e1aa2c":"### SHAP Explainer","23eee783":"#### Sorting Dataset","0deac503":"#####  Visualize the training set predictions","64f14d33":"##### Best Model Accuracy In-Depth Analysis (ADA Boost Classifier)","16f50434":"##### Missing Values","915bc19e":"##### Perceptron","54c1aff2":"##### Categorical Features","6eb6fbb6":"###### Variable Importance Plot \u2014 Global Interpretability","a5e7344b":"### Feature Hidden Patterns Analysis","489b47ff":"##### Decision Tree Classifier","aab1df44":"#### Basic Libraries","3bc6a64d":"##### XGBoost SHAP","39e4c699":"##### SHAP Feature Dependence plot ","ba8f7c21":"##### SHAP Interaction Value Summary Plot","dca27985":"### Introduction","8dbd7b64":"##### Support Vector Machine","9a163fd8":"##### Ada Boost Classifier","99e92399":"7043 rows, There are 21 columns with 19 features.","dd393e53":"This IBM Sample Dataset has information about Telco customers and if they left the company within the last month (churn). Each row represents a unique costumer, while the columns contains information about customer\u2019s services, account and demographic data. We will be using Python and Seaborn library to plot and analyze the data.","319610f3":"##### MLP Classifier","81a29bae":"### Modeling","1696f5c4":"##### Feature Desicion Explainer 2000-2500 entries"}}