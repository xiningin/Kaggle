{"cell_type":{"fd1dd1aa":"code","cf1ef0be":"code","a158d2f4":"code","fb8a64aa":"code","68c126d2":"code","2216a7df":"code","30f3357d":"code","07ea69fb":"code","07450d53":"code","f3a65fc0":"code","c9021b3c":"code","e8d61e3d":"code","2447b38f":"code","99074786":"code","6f3ddb01":"code","31bc6eec":"markdown","c4968125":"markdown","02bc6781":"markdown","56d6995f":"markdown","36f87ce9":"markdown","0e747947":"markdown","548b74db":"markdown","31eac07e":"markdown","e4f5daaa":"markdown"},"source":{"fd1dd1aa":"import pandas as pd\n\ndf= pd.read_csv(\"..\/input\/reddit-finance-data\/wallstreetbets\/submissions_reddit.csv\")\n\ndf.head(5)","cf1ef0be":"#Download stopwords\nimport nltk\n#nltk.download('stopwords')\n\n","a158d2f4":"# remove stopwords \n\n\ndef removeStopWords(texto):\n    texto= str(texto)\n    import nltk\n    from nltk.corpus import stopwords\n    stopwords= list(stopwords.words('english'))\n    stopwords.append(\"im\")\n    lista2= texto.lower().split()\n    for elemento in stopwords:\n        if elemento in lista2:\n            for i in range (lista2.count(elemento)):\n                lista2.remove(elemento)  \n\n    return lista2\n\n#Remove signs and simbols\n\ndef RemoveNotAlphabetCharacters(lista):\n    lista2=[]\n    for palabra in lista:\n        palabraN=\"\"\n        for letra in palabra:\n            if letra.isalpha()==True:\n                palabraN += letra\n        if palabraN != \"\":\n            lista2.append(palabraN)\n    return lista2\n\n#Create Dictionari with key: word , value: frec\n\ndef CountWords(lista):\n    dic={}\n    for palabra in lista:\n        if palabra not in dic:\n            dic[palabra] = 1\n        elif palabra in dic:\n            dic[palabra] += 1\n    return dic\n\ndf[\"words\"] = df[\"title\"].apply(removeStopWords)\n\ndf[\"words\"] = df[\"words\"].apply(RemoveNotAlphabetCharacters)\n\ndf[\"words\"] = df[\"words\"].apply(CountWords)","fb8a64aa":"# I will create and auxiliary class called \"Dic\" , with an __add__ function\n# The add function will allow us to sum dictionaries\n# This way having a = { \"apple\" : 1 , \"pineaple\" : 3 } and b = { \"apple\" : 2 } (a and b are Dic objects);  \n# a+b= { \"apple\" : 3 , \"pineapple\" : 3}\n\nclass Dic:\n    def __init__ (self, dic):\n        self.dic=(dic)\n        self.cdic= dic.copy()\n    \n    \n    def di(self):\n        return (self.dic)\n        \n    def __add__ (self, other):\n        \n        if isinstance(other, Dic):\n            other=(other).di()\n\n            dic= self.dic\n            \n            cdic= dic.copy()\n\n            for palabra in dict(other):\n                if palabra not in cdic:\n                    cdic[palabra] = other[palabra]\n                elif palabra in dic:\n                    cdic[palabra] += other[palabra]\n        \n        self.cdic=cdic\n        return Dic((cdic))\n    \n    def __str__ (self):\n        return str(self.dic)\n    \ndef toAux(x):\n    return Dic(x)\ndf[\"words\"] = df[\"words\"].apply(toAux)","68c126d2":"#I will group by day and have the dictionaries of df[\"words\"] summed\n\n#this function is to short \"created\" to only have days and not hours\ndef shortDate(t):\n    t=str(t)\n    return t[:10]\n\ndf[\"timestamp\"]= df[\"created\"].apply(shortDate)\n\n\ndf1 = df.groupby(\"timestamp\").agg({\"words\" :\"sum\"})\n\ndef todict(Aux):\n    return Aux.dic\n\ndf1[\"words\"] = df1[\"words\"].apply(todict)\n","2216a7df":"#EXECUTE PROGRAM TO SEE MOST COMMON WORDS IN A DAY\n\nimport operator\n\n\nrow_names = df1.index.values\n\ndate = input(\"Introduce the date where you want to search the most used words(YYYY-MM-DD): \")\nx= dict(zip(list(row_names), range(len(list(row_names)))))[date]\ndf1_sorted = sorted(df1[\"words\"][x].items(), key=operator.itemgetter(1), reverse=True)\n\nfor  y in range(0,10):\n    print(df1_sorted[y])","30f3357d":"def countGME(dic):\n    try: \n         return dic[\"gme\"]\n    except:\n        return 0\n    \n","07ea69fb":"df1[\"gme\"] = df1[\"words\"].apply(countGME)\n","07450d53":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(50,25))\nplt.xticks(range(200), size=5)\n\n\n\ndf1[\"gme\"].plot(color=\"red\")\n\nplt.grid(True)\n\n\n\n\n\n#plt.savefig(\"GME word appereance\")","f3a65fc0":"\nimport pandas as pd\n\n\n\n\n\ngme_data=pd.read_csv(\"..\/input\/gmedata\/gmedata.csv\")\n\n\n#df1=df1.reset_index()\ngme_data= gme_data.reset_index()\n\ngme_data[\"timestamp\"]= (gme_data[\"Date\"]).apply(shortDate)\n\ngg= pd.merge(df1, gme_data, on='timestamp')\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(50,25))\nplt.xticks(range(200), size=5)\n\ngg['Close2']=gg['Close']*50\n\ngg[\"gme\"].plot(color=\"red\")\ngg[\"Close2\"].plot(color=\"blue\")\n\nplt.grid(True)\n\n","c9021b3c":"import scipy.stats\nprint(f'The correlation coefficient is : {scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[0]}\\n')\nprint('The p-value is:' , scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[1])\nprint(f'\\nThe probability that the 2 graphs are not correlated is: {scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[1] *100} %')\nprint(f'The probability that the 2 graphs are correlated is: {100- scipy.stats.pearsonr(gg[\"gme\"], gg[\"Close2\"])[1] *100} %')\n\n\nmy_plot = gg.plot(\"gme\", \"Close2\", kind=\"scatter\")\nplt.show() ","e8d61e3d":"def gmeinwords(dic):\n    if \"gme\" in dic or \"gamestop\" in dic:\n        return 1\n    else:\n        return 0\n\ndf[\"words\"] = df[\"title\"].apply(removeStopWords)\n\ndf[\"words\"] = df[\"words\"].apply(RemoveNotAlphabetCharacters)\n\ndf[\"gmeindic\"] = df[\"words\"].apply(gmeinwords)","2447b38f":"df3= df[df[\"gmeindic\"] ==1]\ndf=df3.reset_index(drop=True)\n","99074786":"first=  pd.DataFrame()\nfirst[\"timestamp\"]= df[\"timestamp\"] \nfirst[\"title\"] = df[\"title\"]\nfirst[\"shortlink\"] = df[\"shortlink\"]","6f3ddb01":"for x in range(0,20):\n    print(first[\"timestamp\"][x] , first[\"title\"][x], first[\"shortlink\"][x])","31bc6eec":"...","c4968125":"\n\n## PLOT gme word appereance\n","02bc6781":"##### By Pablo Llobregat (pallobre@gmail.com)","56d6995f":"## P-VALUE\n\n#### The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Pearson correlation at least as extreme as the one computed from these datasets.\n","36f87ce9":"## Count frecuent words","0e747947":"# yfinance , (superimpose two graphs)","548b74db":"## Extra: \n\nget just messages containing gme chronologically","31eac07e":"# Reddit posts compared to Stock Price","e4f5daaa":"..."}}