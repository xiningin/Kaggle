{"cell_type":{"920f2552":"code","8edcbb84":"code","bd3e6073":"code","6ce93b48":"code","5bbe8839":"code","43ef73bc":"code","b3b3ef81":"code","a077dd94":"code","c52a511b":"code","af46a5a1":"code","e781cc03":"code","8f794a84":"code","3856c704":"code","2d4d35d5":"code","1b1c8f91":"code","c7691ec4":"code","10ba665b":"code","20d71174":"code","861e6003":"code","7bfbea37":"code","2c6e7216":"code","2d8dc5ed":"code","2c5a6626":"code","ea97a68a":"code","9c95e2f8":"code","6d81cf82":"code","cd9b6848":"markdown"},"source":{"920f2552":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8edcbb84":"# train_data_csv = pd.read_csv('..\/input\/ai-basic-test\/train.csv')\n# # train_data_csv.head()\n\n# train_data_csv[\"Image_Path\"] = '..\/input\/dataset\/'+train_data_csv[\"Image_Path\"]\n# train_data_csv.head()\n\n# import numpy as np\n# import pandas as pd\n# import matplotlib.pyplot as plt\n# %matplotlib inline\n# import seaborn as sns\n# import cv2\n# import os\n\n# from PIL import Image\n# image = Image.open(train_data_csv['Image_Path'][2])\n# plt.imshow(image)\n# plt.show()\n\n# Validation_data_csv = pd.read_csv('..\/input\/ai-basic-test\/val.csv')\n# # Validation_data_csv.head()\n\n# Validation_data_csv[\"Image_Path\"] = '..\/input\/dataset\/'+Validation_data_csv[\"Image_Path\"]\n# Validation_data_csv.head()\n\n# image = Image.open(Validation_data_csv['Image_Path'][2])\n# plt.imshow(image)\n# plt.show()\n\n# from IPython.display import Image\n# from keras.preprocessing import image\n# from keras import optimizers\n# import numpy as np\n# from keras import layers,models\n# from keras.applications.imagenet_utils import preprocess_input\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# from keras import regularizers\n# from keras.models import Sequential, Model \n# from keras.preprocessing.image import ImageDataGenerator\n# from keras import applications\n\n# datagen = ImageDataGenerator(\n# rescale=1.\/255)\n# batch_size=32\n\n# train_dir = '..\/input\/dataset\/Training'\n# validation_dir = '..\/input\/dataset\/Validation'\n\n# # ..\/input\/dataset\/Training\n\n# train_generator=datagen.flow_from_directory(directory='..\/input\/dataset\/Training',\n                                            \n#                                             class_mode='categorical',batch_size=batch_size,shuffle=True,\n#                                             classes = ['Bicycle', 'Boat', 'Cat', 'Motorbike', 'People', 'Table'],\n#                                             seed = 123,\n#                                             target_size=(150,150))\n\n\n\n\n# validation_generator=datagen.flow_from_directory(directory='..\/input\/dataset\/Validation',\n                                            \n#                                             class_mode='categorical',batch_size=batch_size,shuffle=True,\n#                                                  classes = ['Bicycle', 'Boat', 'Cat', 'Motorbike', 'People', 'Table'],\n#                                             seed = 123,\n#                                             target_size=(150,150))\n\n# # validation_generator=datagen.flow_from_dataframe(dataframe=Validation_data_csv,directory=None,x_col='Image_Path',\n# #                                             y_col='Class',class_mode='categorical',batch_size=batch_size,shuffle=True,\n# #                                             seed = 123,\n# #                                             target_size=(150,150))\n\n# import tensorflow as tf\n\n# model = tf.keras.models.Sequential([\n#     # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n#     # The first convolution\n#     tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n#     tf.keras.layers.MaxPooling2D(2, 2),\n#     # The second convolution\n#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # The third convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # The fourth convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # The fifth convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # Flatten the results to feed into a dense layer\n#     tf.keras.layers.Flatten(),\n#     # 128 neuron in the fully-connected layer\n#     tf.keras.layers.Dense(128, activation='relu'),\n#     # 5 output neurons for 6 classes with the softmax activation\n#     tf.keras.layers.Dense(6, activation='softmax')\n# ])\n\n# model.summary()\n\n\n# from tensorflow.keras.optimizers import RMSprop\n\n# model.compile(loss='categorical_crossentropy',\n#               optimizer=RMSprop(lr=0.001),\n#               metrics=['acc'])\n\n# n_epochs = 30\n# # history = model.fit_generator(\n# #         train_generator, \n# #         steps_per_epoch=int(train_generator.n\/batch_size),  validation_data=validation_generator,\n# #     validation_steps= int(validation_generator.n\/batch_size),\n# #         verbose=1,\n# #     epochs=n_epochs\n# #         )\n# history = model.fit_generator(training_set,\n#                          steps_per_epoch=training_set.samples\/\/batch_size,\n#                          validation_data=valid_set,\n#                          epochs=25,\n#                          validation_steps=valid_set.samples\/\/batch_size)\n\n# validation_labels = valid_set.classes\n# validation_labels\n\n# # make predictions on the testing images, finding the index of the\n# # label with the corresponding largest predicted probability, then\n# # show a classification report\n# print(\"[INFO] evaluating network...\")\n# predIdxs = model.predict(x=valid_set,\n#  steps=(valid_set.n \/\/ batch_size) + 1)\n# predIdxs = np.argmax(predIdxs, axis=1)\n\n# # import classification_report\n# from sklearn.metrics import classification_report\n# # get the classification report\n# print(classification_report(validation_labels, predIdxs))\n\n# from PIL import Image\n# img_crab=Image.open('..\/input\/dataset\/Testing\/2015_00401.jpg')\n# img_crab = img_crab.resize((200,200))\n# plt.imshow(img_crab)\n# plt.show()\n\n\n# # Expand dimensions for proper prediction\n# import numpy as np\n# img_crab=np.expand_dims(img_crab,axis=0)\n\n\n# model.predict(img_crab)\n\n# # **VGG16**\n\n# model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (150, 150, 3))\n# model.summary()\n\n# # model = S\n\n# # model.add(Dense(256, input_shape=(7 * 7 * 512,), activation=\"relu\"))\n# # model.add(Dense(16, activation=\"relu\"))\n# # model.add(Dense(6, activation=\"softmax\"))\n\n# #Adding some custom layers\n# from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n# for layer in model.layers[:5]:\n#     layer.trainable = False\n\n# #Adding custom Layers \n# x = model.output\n# x = Flatten()(x)\n# x = Dense(1024, activation=\"relu\")(x)\n# x = Dropout(0.5)(x)\n# x = Dense(1024, activation=\"relu\")(x)\n# predictions = Dense(6, activation=\"softmax\")(x)\n\n# # creating the final model \n# model_final =  Model(inputs=model.input, outputs=predictions)\n\n# model.input\n\n# opt = optimizers.Adam(learning_rate=0.01)\n\n# model_final.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\n\n# len(train_data_csv) \/\/ batch_size\n\n# train_generator\n\n# history=model_final.fit_generator(train_generator,steps_per_epoch=len(train_data_csv) \/\/ batch_size,epochs=25,\n#                                   validation_data=validation_generator,validation_steps=len(Validation_data_csv) \/\/ batch_size)\n\n# # #The implementation of VGG16 in Keras\n# # from keras.layers import Input, Conv2D, MaxPooling2D\n# # from keras.layers import Dense, Flatten\n# # from keras.models import Model\n\n# # _input = Input((224,224,1)) \n\n# # conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n# # conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n# # pool1  = MaxPooling2D((2, 2))(conv2)\n\n# # conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n# # conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n# # pool2  = MaxPooling2D((2, 2))(conv4)\n\n# # conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n# # conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n# # conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n# # pool3  = MaxPooling2D((2, 2))(conv7)\n\n# # conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n# # conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n# # conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n# # pool4  = MaxPooling2D((2, 2))(conv10)\n\n# # conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n# # conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n# # conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n# # pool5  = MaxPooling2D((2, 2))(conv13)\n\n# # flat   = Flatten()(pool5)\n# # dense1 = Dense(4096, activation=\"relu\")(flat)\n# # dense2 = Dense(4096, activation=\"relu\")(dense1)\n# # output = Dense(1000, activation=\"softmax\")(dense2)\n\n# # vgg16_model  = Model(inputs=_input, outputs=output)\n\n# # from keras.applications.vgg16 import decode_predictions\n# # from keras.applications.vgg16 import preprocess_input\n# # from keras.preprocessing import image\n# # import matplotlib.pyplot as plt \n# # from PIL import Image \n# # import seaborn as sns\n# # import pandas as pd \n# # import numpy as np \n# # import os \n\n# # img1 = \"..\/input\/dataset\/Training\/Bicycle\/2015_00001.png\"\n# # img2 = \"..\/input\/dataset\/Training\/Boat\/2015_00653.jpg\"\n# # img3 = \"..\/input\/dataset\/Training\/Cat\/2015_03042.jpg\"\n# # img4 = \"..\/input\/dataset\/Training\/Motorbike\/2015_05745.jpg\"\n# # # img5 = \"..\/input\/dataset\/Training\/People\/2015_06246.jpg\"\n# # # img6 = \"..\/input\/dataset\/Training\/Table\/2015_06852.jpg\"\n# # imgs = [img1, img2, img3, img4]\n\n# # def _load_image(img_path):\n# #     img = image.load_img(img_path, target_size=(224, 224))\n# #     img = image.img_to_array(img)\n# #     img = np.expand_dims(img, axis=0)\n# #     img = preprocess_input(img)\n# #     return img \n\n# # def _get_predictions(_model):\n# #     f, ax = plt.subplots(1, 4)\n# #     f.set_size_inches(80, 40)\n# #     for i in range(4):\n# #         ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))\n# #     plt.show()\n    \n# #     f, axes = plt.subplots(1, 4)\n# #     f.set_size_inches(80, 20)\n# #     for i,img_path in enumerate(imgs):\n# #         img = _load_image(img_path)\n# #         preds  = decode_predictions(_model.predict(img), top=3)[0]\n# #         b = sns.barplot(y=[c[1] for c in preds], x=[c[2] for c in preds], color=\"gray\", ax=axes[i])\n# #         b.tick_params(labelsize=55)\n# #         f.tight_layout()\n\n# # from keras.applications.vgg16 import VGG16\n# # vgg16_weights = '..\/input\/vgg16-weights-fchollet\/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n# # vgg16_model = VGG16(weights=vgg16_weights)\n# # _get_predictions(vgg16_model)\n\n\n\n# # **AlexNet**\n\n# # Importing Keras libraries and packages\n# from keras.models import Sequential\n# from keras.layers import Convolution2D\n# from keras.layers import MaxPooling2D\n# from keras.layers import Flatten\n# from keras.layers import Dense\n# from keras.layers import Dropout\n# from keras.layers.normalization import BatchNormalization\n\n# # Initializing the CNN\n# classifier = Sequential()\n\n# # Convolution Step 1\n# classifier.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n\n# # Max Pooling Step 1\n# classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n# classifier.add(BatchNormalization())\n\n# # Convolution Step 2\n# classifier.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n\n# # Max Pooling Step 2\n# classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\n# classifier.add(BatchNormalization())\n\n# # Convolution Step 3\n# classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n# classifier.add(BatchNormalization())\n\n# # Convolution Step 4\n# classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n# classifier.add(BatchNormalization())\n\n# # Convolution Step 5\n# classifier.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n\n# # Max Pooling Step 3\n# classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n# classifier.add(BatchNormalization())\n\n# # Flattening Step\n# classifier.add(Flatten())\n\n# # Full Connection Step\n# classifier.add(Dense(units = 4096, activation = 'relu'))\n# classifier.add(Dropout(0.4))\n# classifier.add(BatchNormalization())\n# classifier.add(Dense(units = 4096, activation = 'relu'))\n# classifier.add(Dropout(0.4))\n# classifier.add(BatchNormalization())\n# classifier.add(Dense(units = 1000, activation = 'relu'))\n# classifier.add(Dropout(0.2))\n# classifier.add(BatchNormalization())\n# classifier.add(Dense(units = 6, activation = 'softmax'))\n# classifier.summary()\n\n# # classifier.load_weights('..\/input\/-using-alexnet\/best_weights_9.hdf5')\n\n# # let's visualize layer names and layer indices to see how many layers\n# # we should freeze:\n# from keras import layers\n# for i, layer in enumerate(classifier.layers):\n#    print(i, layer.name)\n\n# # we chose to train the top 2 conv blocks, i.e. we will freeze\n# # the first 8 layers and unfreeze the rest:\n# print(\"Freezed layers:\")\n# for i, layer in enumerate(classifier.layers[:20]):\n#     print(i, layer.name)\n#     layer.trainable = False\n\n# classifier.summary()\n\n# from keras import optimizers\n# classifier.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n#               loss='categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# # image preprocessing\n# from keras.preprocessing.image import ImageDataGenerator\n\n# train_datagen = ImageDataGenerator(rescale=1.\/255,\n#                                    shear_range=0.2,\n#                                    zoom_range=0.2,\n#                                    width_shift_range=0.2,\n#                                    height_shift_range=0.2,\n#                                    fill_mode='nearest')\n\n# valid_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# batch_size = 128\n# base_dir = \"..\/input\/dataset\"\n\n# training_set = train_datagen.flow_from_directory(base_dir+'\/Training',\n#                                                  target_size=(224, 224),\n#                                                  batch_size=batch_size,\n#                                                  class_mode='categorical')\n\n# valid_set = valid_datagen.flow_from_directory(base_dir+'\/Validation',\n#                                             target_size=(224, 224),\n#                                             batch_size=batch_size,\n#                                             class_mode='categorical')\n\n# class_dict = training_set.class_indices\n# print(class_dict)\n\n# li = list(class_dict.keys())\n# print(li)\n\n# train_num = training_set.samples\n# valid_num = valid_set.samples\n\n# # checkpoint\n# from keras.callbacks import ModelCheckpoint\n# weightpath = \"best_weights_6.hdf5\"\n# checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n# callbacks_list = [checkpoint]\n\n# #fitting images to CNN\n# history = classifier.fit_generator(training_set,\n#                          steps_per_epoch=train_num\/\/batch_size,\n#                          validation_data=valid_set,\n#                          epochs=25,\n#                          validation_steps=valid_num\/\/batch_size,\n#                          callbacks=callbacks_list)\n# #saving model\n# filepath=\"AlexNetModel.hdf5\"\n# classifier.save(filepath)\n\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# # predicting an image\n# from keras.preprocessing import image\n# import numpy as np\n# image_path = \"..\/input\/dataset\/Testing\/2015_00430.jpg\"\n# new_img = image.load_img(image_path, target_size=(224, 224))\n# img = image.img_to_array(new_img)\n# img = np.expand_dims(img, axis=0)\n# img = img\/255\n\n# print(\"Following is our prediction:\")\n# prediction = classifier.predict(img)\n# # decode the results into a list of tuples (class, description, probability)\n# # (one such list for each sample in the batch)\n# d = prediction.flatten()\n# j = d.max()\n# for index,item in enumerate(d):\n#     if item == j:\n#         class_name = li[index]\n\n# ##Another way\n# # img_class = classifier.predict_classes(img)\n# # img_prob = classifier.predict_proba(img)\n# # print(img_class ,img_prob )\n\n\n# #ploting image with predicted class name        \n# plt.figure(figsize = (4,4))\n# plt.imshow(new_img)\n# plt.axis('off')\n# plt.title(class_name)\n# plt.show()","bd3e6073":"# YOLO v3\nimport os\n\nimport scipy.io\nimport scipy.misc\nimport numpy as np\nimport pandas as pd\nimport PIL\nimport struct\nimport cv2\nfrom numpy import expand_dims\nimport tensorflow as tf\nfrom skimage.transform import resize\nfrom keras import backend as K\nfrom keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\nfrom keras.models import load_model, Model\nfrom keras.layers.merge import add, concatenate\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom matplotlib.patches import Rectangle\n\n%matplotlib inline","6ce93b48":"class WeightReader:\n    def __init__(self, weight_file):\n        with open(weight_file, 'rb') as w_f:\n            major,    = struct.unpack('i', w_f.read(4))\n            minor,    = struct.unpack('i', w_f.read(4))\n            revision, = struct.unpack('i', w_f.read(4))\n\n            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n                w_f.read(8)\n            else:\n                w_f.read(4)\n\n            transpose = (major > 1000) or (minor > 1000)\n            \n            binary = w_f.read()\n\n        self.offset = 0\n        self.all_weights = np.frombuffer(binary, dtype='float32')\n        \n    def read_bytes(self, size):\n        self.offset = self.offset + size\n        return self.all_weights[self.offset-size:self.offset]\n\n    def load_weights(self, model):\n        for i in range(106):\n            try:\n                conv_layer = model.get_layer('conv_' + str(i))\n                print(\"loading weights of convolution #\" + str(i))\n\n                if i not in [81, 93, 105]:\n                    norm_layer = model.get_layer('bnorm_' + str(i))\n\n                    size = np.prod(norm_layer.get_weights()[0].shape)\n\n                    beta  = self.read_bytes(size) # bias\n                    gamma = self.read_bytes(size) # scale\n                    mean  = self.read_bytes(size) # mean\n                    var   = self.read_bytes(size) # variance            \n\n                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n\n                if len(conv_layer.get_weights()) > 1:\n                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n                    \n                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n                    kernel = kernel.transpose([2,3,1,0])\n                    conv_layer.set_weights([kernel, bias])\n                else:\n                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n                    kernel = kernel.transpose([2,3,1,0])\n                    conv_layer.set_weights([kernel])\n            except ValueError:\n                print(\"no convolution #\" + str(i))     \n    \n    def reset(self):\n        self.offset = 0","5bbe8839":"def _conv_block(inp, convs, skip=True):\n    x = inp\n    count = 0\n    \n    for conv in convs:\n        if count == (len(convs) - 2) and skip:\n            skip_connection = x\n        count += 1\n        \n        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n        x = Conv2D(conv['filter'], \n                   conv['kernel'], \n                   strides=conv['stride'], \n                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n                   name='conv_' + str(conv['layer_idx']), \n                   use_bias=False if conv['bnorm'] else True)(x)\n        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n\n    return add([skip_connection, x]) if skip else x","43ef73bc":"# creating the YOLO model\ndef make_yolov3_model():\n    input_image = Input(shape=(None, None, 3))\n\n    # Layer  0 => 4\n    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n\n    # Layer  5 => 8\n    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n\n    # Layer  9 => 11\n    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n\n    # Layer 12 => 15\n    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n\n    # Layer 16 => 36\n    for i in range(7):\n        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n        \n    skip_36 = x\n        \n    # Layer 37 => 40\n    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n\n    # Layer 41 => 61\n    for i in range(7):\n        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n        \n    skip_61 = x\n        \n    # Layer 62 => 65\n    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n\n    # Layer 66 => 74\n    for i in range(3):\n        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n        \n    # Layer 75 => 79\n    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n\n    # Layer 80 => 82\n    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n\n    # Layer 83 => 86\n    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n    x = UpSampling2D(2)(x)\n    x = concatenate([x, skip_61])\n\n    # Layer 87 => 91\n    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n\n    # Layer 92 => 94\n    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n\n    # Layer 95 => 98\n    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n    x = UpSampling2D(2)(x)\n    x = concatenate([x, skip_36])\n\n    # Layer 99 => 106\n    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n\n    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n    return model","b3b3ef81":"net_h, net_w = 416, 416\nobj_thresh, nms_thresh = 0.5, 0.45\nanchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\nlabels = [\"person\", \"bicycle\", \"motorbike\", \\\n              \"boat\", \\\n              \"cat\",\"diningtable\"]\n\n# make the yolov3 model to predict 80 classes on COCO\n\nyolov3 = make_yolov3_model()\n\n# load the weights trained on COCO into the model\nweight_reader = WeightReader('..\/input\/rrmqptest2\/second\/yolov3.weights')\nweight_reader.load_weights(yolov3)","a077dd94":"# save the model to file\nyolov3.save('yolov3.h5')","c52a511b":"# load yolov3 model\nyolov3 = load_model('yolov3.h5')","af46a5a1":"from numpy import expand_dims\ndef load_image_pixels(filename, shape):\n    # load the image to get its shape\n    image = load_img(filename)\n    width, height = image.size\n    # load the image with the required size\n    image = load_img(filename, target_size=shape)\n    # convert to numpy array\n    image = img_to_array(image)\n    # scale pixel values to [0, 1]\n    image = image.astype('float32')\n    image \/= 255.0\n    # add a dimension so that we have one sample\n    image = expand_dims(image, 0)\n    return image, width, height","e781cc03":"\n# define the expected input shape for the model\ninput_w, input_h = 416, 416\n# define our new photo\nphoto_filename = '..\/input\/dataset\/Testing\/2015_00401.jpg'\n# load and prepare image\nimage, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))","8f794a84":"class BoundBox:\n    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n        self.xmin = xmin\n        self.ymin = ymin\n        self.xmax = xmax\n        self.ymax = ymax\n        \n        self.objness = objness\n        self.classes = classes\n\n        self.label = -1\n        self.score = -1\n\n    def get_label(self):\n        if self.label == -1:\n            self.label = np.argmax(self.classes)\n        \n        return self.label\n    \n    def get_score(self):\n        if self.score == -1:\n            self.score = self.classes[self.get_label()]\n            \n        return self.score\n\ndef _sigmoid(x):\n    return 1. \/ (1. + np.exp(-x))\n\ndef _interval_overlap(interval_a, interval_b):\n    x1, x2 = interval_a\n    x3, x4 = interval_b\n\n    if x3 < x1:\n        if x4 < x1:\n            return 0\n        else:\n            return min(x2,x4) - x1\n    else:\n        if x2 < x3:\n             return 0\n        else:\n            return min(x2,x4) - x3 \ndef bbox_iou(box1, box2):\n    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n    \n    intersect = intersect_w * intersect_h\n\n    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n    \n    union = w1*h1 + w2*h2 - intersect\n    \n    return float(intersect) \/ union\n\ndef do_nms(boxes, nms_thresh):\n    if len(boxes) > 0:\n        nb_class = len(boxes[0].classes)\n    else:\n        return\n        \n    for c in range(nb_class):\n        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n\n        for i in range(len(sorted_indices)):\n            index_i = sorted_indices[i]\n\n            if boxes[index_i].classes[c] == 0: continue\n\n            for j in range(i+1, len(sorted_indices)):\n                index_j = sorted_indices[j]\n\n                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n                    boxes[index_j].classes[c] = 0","3856c704":"#decode_netout() that will take each one of the NumPy arrays, one at a time, \n#and decode the candidate bounding boxes and class predictions\ndef decode_netout(netout, anchors, obj_thresh,  net_h, net_w):\n    grid_h, grid_w = netout.shape[:2]\n    nb_box = 3\n    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n    nb_class = netout.shape[-1] - 5\n\n    boxes = []\n\n    netout[..., :2]  = _sigmoid(netout[..., :2])\n    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n\n    for i in range(grid_h*grid_w):\n        row = i \/ grid_w\n        col = i % grid_w\n        \n        for b in range(nb_box):\n            # 4th element is objectness score\n            objectness = netout[int(row)][int(col)][b][4]\n            #objectness = netout[..., :4]\n            \n            if(objectness.all() <= obj_thresh): continue\n            \n            # first 4 elements are x, y, w, and h\n            x, y, w, h = netout[int(row)][int(col)][b][:4]\n\n            x = (col + x) \/ grid_w # center position, unit: image width\n            y = (row + y) \/ grid_h # center position, unit: image height\n            w = anchors[2 * b + 0] * np.exp(w) \/ net_w # unit: image width\n            h = anchors[2 * b + 1] * np.exp(h) \/ net_h # unit: image height  \n            \n            # last elements are class probabilities\n            classes = netout[int(row)][col][b][5:]\n            \n            box = BoundBox(x-w\/2, y-h\/2, x+w\/2, y+h\/2, objectness, classes)\n            #box = BoundBox(x-w\/2, y-h\/2, x+w\/2, y+h\/2, None, classes)\n\n            boxes.append(box)\n\n    return boxes","2d4d35d5":"# bounding boxes will be stretched back into the shape of the original image\n#will allow plotting the original image and draw the bounding boxes, hopefully detecting real objects.\n# correct the sizes of the bounding boxes for the shape of the image\n#correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\ndef correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n    if (float(net_w)\/image_w) < (float(net_h)\/image_h):\n        new_w = net_w\n        new_h = (image_h*net_w)\/image_w\n    else:\n        new_h = net_w\n        new_w = (image_w*net_h)\/image_h\n        \n    for i in range(len(boxes)):\n        x_offset, x_scale = (net_w - new_w)\/2.\/net_w, float(new_w)\/net_w\n        y_offset, y_scale = (net_h - new_h)\/2.\/net_h, float(new_h)\/net_h\n        \n        boxes[i].xmin = int((boxes[i].xmin - x_offset) \/ x_scale * image_w)\n        boxes[i].xmax = int((boxes[i].xmax - x_offset) \/ x_scale * image_w)\n        boxes[i].ymin = int((boxes[i].ymin - y_offset) \/ y_scale * image_h)\n        boxes[i].ymax = int((boxes[i].ymax - y_offset) \/ y_scale * image_h)","1b1c8f91":"from matplotlib.patches import Rectangle\ndef draw_boxes(filename, v_boxes, v_labels, v_scores):\n    # load the image\n    data = plt.imread(filename)\n    # plot the image\n    plt.imshow(data)\n    # get the context for drawing boxes\n    ax = plt.gca()\n    # plot each box\n    for i in range(len(v_boxes)):\n        box = v_boxes[i]\n        # get coordinates\n        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n        # calculate width and height of the box\n        width, height = x2 - x1, y2 - y1\n        # create the shape\n        rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n        # draw the box\n        ax.add_patch(rect)\n        # draw text and score in top left corner\n        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n        plt.text(x1, y1, label, color='red')\n    # show the plot\n    plt.show()","c7691ec4":"# get all of the results above a threshold\n# takes the list of boxes, known labels, \n#and our classification threshold as arguments and returns parallel lists of boxes, labels, and scores.\ndef get_boxes(boxes, labels, thresh):\n    v_boxes, v_labels, v_scores = list(), list(), list()\n    # enumerate all boxes\n    for box in boxes:\n        # enumerate all possible labels\n        for i in range(len(labels)):\n            # check if the threshold for this label is high enough\n            if box.classes[i] > thresh:\n                v_boxes.append(box)\n                v_labels.append(labels[i])\n                v_scores.append(box.classes[i]*100)\n                # don't break, many labels may trigger for one box\n    return v_boxes, v_labels, v_scores","10ba665b":"testing_csv = pd.read_csv('..\/input\/ai-basic-test\/test_set.csv')\ntesting_csv.head()","20d71174":"testing_csv[\"full_Image_Path\"] = '..\/input\/dataset\/'+testing_csv[\"Image_Path\"]\ntesting_csv.head()","861e6003":"count = 0\nfor image in testing_csv['full_Image_Path']:\n    # define the expected input shape for the model\n    input_w, input_h = 416, 416\n    # define our new photo\n    photo_filename = image\n    # load and prepare image\n    image, image_w, image_h = load_image_pixels(photo_filename, (net_w, net_w))\n\n\n    # make prediction\n    yolos = yolov3.predict(image)\n    # summarize the shape of the list of arrays\n    print([a.shape for a in yolos])\n\n    # define the anchors\n    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n    # define the probability threshold for detected objects\n    class_threshold = 0.6\n    boxes = list()\n\n    for i in range(len(yolos)):\n            # decode the output of the network\n        boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh,  net_h, net_w)\n\n        # correct the sizes of the bounding boxes\n    correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n\n    # suppress non-maximal boxes\n    do_nms(boxes, nms_thresh)\n\n    # get the details of the detected objects\n    v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n    # summarize what we found\n#     for i in range(len(v_boxes)):\n#         print(v_labels[i], v_scores[i])\n    if v_labels != []:\n        testing_csv['Class'][count] = v_labels\n    else:\n        testing_csv['Class'][count] = 'unrecognised_object'\n    # draw what we found\n    # draw_boxes(photo_filename, v_boxes, v_labels, v_scores)\n    count += 1","7bfbea37":"# # get the details of the detected objects\n# v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n# # summarize what we found\n# for i in range(len(v_boxes)):\n#     print(v_labels[i], v_scores[i])\n# # draw what we found\n# draw_boxes(photo_filename, v_boxes, v_labels, v_scores)","2c6e7216":"# # define the expected input shape for the model\n# input_w, input_h = 416, 416\n# # define our new photo\n# photo_filename = '..\/input\/dataset\/Testing\/2015_07261.jpg'\n# # load and prepare image\n# image, image_w, image_h = load_image_pixels(photo_filename, (net_w, net_w))\n\n\n# # make prediction\n# yolos = yolov3.predict(image)\n# # summarize the shape of the list of arrays\n# print([a.shape for a in yolos])\n\n# # define the anchors\n# anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n# # define the probability threshold for detected objects\n# class_threshold = 0.6\n# boxes = list()\n\n# for i in range(len(yolos)):\n#         # decode the output of the network\n#     boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh,  net_h, net_w)\n\n#     # correct the sizes of the bounding boxes\n# correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n\n# # suppress non-maximal boxes\n# do_nms(boxes, nms_thresh)\n\n# # get the details of the detected objects\n# v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n# # summarize what we found\n# for i in range(len(v_boxes)):\n#     print(v_labels[i], v_scores[i])\n# # draw what we found\n# draw_boxes(photo_filename, v_boxes, v_labels, v_scores)","2d8dc5ed":"# testing_csv['Class'][count] = v_labels","2c5a6626":"# for i in range(len(v_boxes)):\n#     print(v_labels[i], v_scores[i])\n#     if v_labels != []:\n#         testing_csv['Class'][count] += v_labels[i]\n#     else:\n#         testing_csv['Class'][count] += 'unrecognised_object'","ea97a68a":"# testing_csv.head(10)","9c95e2f8":"submission = testing_csv","6d81cf82":"\nsubmission.to_csv('test_set.csv', columns=['Image_Path', 'Class'])","cd9b6848":"# **YOLO**"}}