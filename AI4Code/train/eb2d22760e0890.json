{"cell_type":{"3b9e8b45":"code","1907a434":"code","7a7f0e10":"code","5e48428c":"code","54699860":"code","f876b725":"code","930b1bdd":"code","e49f4167":"code","750039f5":"code","cd9681e4":"markdown","da9cabb4":"markdown","38f173c2":"markdown","9c103d39":"markdown","e86cb575":"markdown","65715ef5":"markdown","36123bdd":"markdown","9c3aceea":"markdown"},"source":{"3b9e8b45":"#importing necessary libraries and frameworks\n!pip install tensorflow_datasets\nimport numpy as np\nimport pandas as pd   \nimport os\nfrom pathlib import Path\nimport glob\nimport json\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport os\nimport nltk\nimport cv2\nimport matplotlib.pyplot as plt\nimport random","1907a434":"#Here we check is GPU is available for training or not Or whether the tensorflow version can utilize gpu \nphysical_devices = tf.config.list_physical_devices('GPU') \nprint(\"Number of GPUs :\", len(physical_devices)) \nprint(\"Tensorflow GPU :\",tf.test.is_built_with_cuda())\nif len(physical_devices)>0:\n    device=\"\/GPU:0\"\nelse:\n    device=\"\/CPU:0\"","7a7f0e10":"#train_dataframe and val_dataframe stores the path to the images and respective questions and answers\ntrainList=[]\nwith open('\/kaggle\/input\/clevr-dataset\/CLEVR_v1.0\/questions\/CLEVR_train_questions.json') as f:\n    data = json.load(f)\n    for i in data['questions']:\n        temp=[]\n        for path in glob.glob('\/kaggle\/input\/clevr-dataset\/CLEVR_v1.0\/images\/train\/'+i['image_filename']): \n            temp.append(path)\n        temp.append(i['question'])\n        temp.append(i['answer'])\n        trainList.append(temp)\nf.close()\nlabels=['Path','Question','Answer']\ntrain_dataframe = pd.DataFrame.from_records(trainList, columns=labels)#training Dataframe \ndel(data)\ndel(trainList)\n\nvalList=[]\nwith open('\/kaggle\/input\/clevr-dataset\/CLEVR_v1.0\/questions\/CLEVR_val_questions.json') as f:\n    data = json.load(f)\n    for i in data['questions']:\n        temp=[]\n        for path in glob.glob('\/kaggle\/input\/clevr-dataset\/CLEVR_v1.0\/images\/val\/'+i['image_filename']): \n            temp.append(path)\n        temp.append(i['question'])\n        temp.append(i['answer'])\n        valList.append(temp)\nf.close()\nval_dataframe = pd.DataFrame.from_records(valList, columns=labels)#validation Dataframe\ndel(data)\ndel(valList)\nval_dataframe.head()","5e48428c":"vocab_set=set()#set object used to store the vocabulary\n\ntokenizer = tfds.features.text.Tokenizer()\nfor i in val_dataframe['Question']:\n    vocab_set.update(tokenizer.tokenize(i))\nfor i in train_dataframe['Question']:\n    vocab_set.update(tokenizer.tokenize(i))\nfor i in val_dataframe['Answer']:\n    vocab_set.update(tokenizer.tokenize(i))\nfor i in train_dataframe['Answer']:\n    vocab_set.update(tokenizer.tokenize(i))\n","54699860":"#Creating an encoder\nencoder=tfds.features.text.TokenTextEncoder(vocab_set)\nindex=14\nprint(\"Testing the Encoder with sample questions - \\n \")\nexample_text=encoder.encode(train_dataframe['Question'][index])\nprint(\"Original Text = \"+train_dataframe['Question'][index])\nprint(\"After Encoding = \"+str(example_text))","f876b725":"BATCH_SIZE=8\nIMG_SIZE=(200,200)\n\n\n#Function that uses the encoder created to encode the input question and answer string\ndef encode_fn(text):\n    return np.array(encoder.encode(text.numpy()))\n\n\n#Function to load and decode the image from the file paths in the dataframe and use the encoder function\ndef preprocess(ip,ans):\n    img,ques=ip#ip is a list containing image paths and questions\n    img=tf.io.read_file(img)\n    img=tf.image.decode_jpeg(img,channels=3)\n    img=tf.image.resize(img,IMG_SIZE)\n    img=tf.math.divide(img, 255)#The image has been loaded , decoded and resized \n    \n    #The question string is converted to encoded list with fixed size of 50 with padding with 0 value\n    ques=tf.py_function(encode_fn,inp=[ques],Tout=tf.int32)\n    paddings = [[0, 50-tf.shape(ques)[0]]]\n    ques = tf.pad(ques, paddings, 'CONSTANT', constant_values=0)\n    ques.set_shape([50])#Explicit shape must be defined in order to create the Input pipeline\n    \n    #The Answer is also encoded \n    ans=tf.py_function(encode_fn,inp=[ans],Tout=tf.int32)\n    ans.set_shape([1])\n    \n    return (img,ques),ans\n    \ndef create_pipeline(dataframe):\n    raw_df=tf.data.Dataset.from_tensor_slices(((dataframe['Path'],dataframe['Question']),dataframe['Answer']))\n    df=raw_df.map(preprocess)#Preprocessing function is applied to the dataset\n    df=df.batch(BATCH_SIZE)#The dataset is batched\n    return df\n\n#The training and validation Dataset objects are created\ntrain_dataset=create_pipeline(train_dataframe)\nvalidation_dataset=create_pipeline(val_dataframe)","930b1bdd":"#Creating the CNN model for image processing\n\n\nCNN_Input=tf.keras.layers.Input(shape=(200,200,3),name='image_input')\n\nmobilenetv2=tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(200,200,3), alpha=1.0, include_top=False,\n                                                      weights='imagenet', input_tensor=CNN_Input)\n\nCNN_model=tf.keras.models.Sequential()\nCNN_model.add(CNN_Input)\nCNN_model.add(mobilenetv2)\nCNN_model.add(tf.keras.layers.GlobalAveragePooling2D())\n\n\n\n\n\n\n#Creating the RNN model for text processing\nRNN_model=tf.keras.models.Sequential()\nRNN_Input=tf.keras.layers.Input(shape=(50),name='text_input')\nRNN_model.add(RNN_Input)\nRNN_model.add(tf.keras.layers.Embedding (len(vocab_set)+1,256))\nRNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,stateful=False,return_sequences=True,recurrent_initializer='glorot_uniform')))\nRNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,stateful=False,return_sequences=True,recurrent_initializer='glorot_uniform')))\nRNN_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512,stateful=False,return_sequences=False,recurrent_initializer='glorot_uniform')))\n\n\nconcat=tf.keras.layers.concatenate([CNN_model.output,RNN_model.output])\ndense_out=tf.keras.layers.Dense(len(vocab_set),activation='softmax',name='output')(concat)\n\nmodel = tf.keras.Model(inputs=[CNN_Input,RNN_Input],\n                    outputs=dense_out)\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\nmodel.summary()","e49f4167":"def scheduler(epoch):\n  if epoch < 1:\n    return 0.001\n  else:\n    return 0.001 * tf.math.exp(0.1 * (1 - epoch))\n\nLRS = tf.keras.callbacks.LearningRateScheduler(scheduler)\ncsv_callback=tf.keras.callbacks.CSVLogger(\n    \"Training Parameters.csv\", separator=',', append=False\n)\nwith tf.device(device):\n    model.fit(train_dataset,\n              validation_data=validation_dataset,\n              callbacks=[csv_callback,LRS],\n              epochs=2)","750039f5":"print(\"Predictions Are as follows = \")\nfor i in range(5):\n    index=random.randrange(20, 5000, 3)\n    fig,axis=plt.subplots(1,2,figsize=(25, 8))\n    im=cv2.imread(val_dataframe.iloc[index]['Path'])\n    im=cv2.resize(im,(200,200))\n    q=val_dataframe.iloc[index]['Question']\n    q=encoder.encode(q)\n    paddings = [[0, 50-tf.shape(q)[0]]]\n    q=tf.pad(q, paddings, 'CONSTANT', constant_values=0)\n    q=np.array(q)\n    ans=model.predict([[im],[q]])\n    question=\"\"\n    flag=0\n    for i,j in enumerate(val_dataframe.iloc[index]['Question']):\n        if (flag==1) and (j==' '):\n            question+='\\n'\n            flag=0\n        question+=j\n        if (i%40==0)and (i!=0):\n            flag=1\n    axis[0].imshow(im)\n    axis[0].axis('off')\n    axis[0].set_title('Image', fontsize=30)\n    axis[1].text(0.05,0.5,\n             \"Question = {}\\n\\nPredicted Answer = {}\\n\\nActual Answer ={}\".format(question,encoder.decode([np.argmax(ans)]),val_dataframe.iloc[index]['Answer']),\n             transform=plt.gca().transAxes,fontsize=19)\n    axis[1].axis('on')\n    axis[1].set_title('Question And Answers', fontsize=30)\n","cd9681e4":"# Loading the data from the JSON files \nLoading the json files using JSON module and using pandas to create a dataframe consisting of the path to the images and respective questions and answers to the images.","da9cabb4":"# Creating Input pipeline for the model\nHere the tf.data.Dataset object is create for the formation of an input pipeline.The Dataset onjects yields Lists consisting of image and question pairs and the answers as well.","38f173c2":"# Creating the Model","9c103d39":"# Creating an Encoder and a Function to preprocess the text data during the training and inference","e86cb575":"# Training the model on the prepared data","65715ef5":"# Vocabulary set of the questions\nIn the next cell we prepare a vocabulary set for questions and answers present in the dataset, it will be used to create an encoder","36123bdd":"# Looking At the training results\nHere we look at some random image and questions and see how our model performs","9c3aceea":"# Visual Question Answering ML Model on CLEVR dataset\nThis interactive notebook utilizes tensorflow to create a VQA ML model that takes the image and the questions and answers the questions. It ultilizes both CNN as well as RNN in order give predictions."}}