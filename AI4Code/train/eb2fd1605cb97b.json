{"cell_type":{"d0cbfa1c":"code","b27eab50":"code","4ae751b1":"code","2e5bd916":"code","ef575346":"code","a1d9e4ca":"code","7f33b0e9":"code","48bf648c":"code","68a37940":"code","101797ea":"code","530cb161":"code","039a303a":"code","27e9a81b":"code","8470c099":"code","81fd5f80":"code","091957a0":"code","76e8069f":"code","17a56bd4":"code","c80a6fda":"code","ca038f74":"code","3634f664":"code","98f26b64":"code","08fd41d6":"code","66b3a932":"code","d884aa3a":"markdown","ba7c0efa":"markdown","1525b010":"markdown","27ca7049":"markdown","c6ea4a14":"markdown","8aa36e78":"markdown","c095a7bf":"markdown","d9f6578e":"markdown","e7394267":"markdown","9db0ade2":"markdown","f1a7ef7f":"markdown","b25697fd":"markdown","7ffd4cb6":"markdown","b8e9ad6e":"markdown","9082beea":"markdown","9ba131df":"markdown"},"source":{"d0cbfa1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b27eab50":"# Importing DataSet\ndataset = pd.read_csv(\"..\/input\/50-startups\/50_Startups.csv\")","4ae751b1":"dataset.head()","2e5bd916":"dataset.describe()","ef575346":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, 4].values","a1d9e4ca":"# Independent Variable X\nX","7f33b0e9":"# Dependent Variable y\ny","48bf648c":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\nX[:, 3] = labelencoder.fit_transform(X[:, 3])\nct =ColumnTransformer([('encoder', OneHotEncoder(), [3])],remainder='passthrough')\nX= np.array(ct.fit_transform(X), dtype=np.float)","68a37940":"X","101797ea":"# Avoiding Dummmy variable Trap\nX = X[:, 1:]","530cb161":"# Splitting the Dataset into Training and Testing Part\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","039a303a":"# Fitting in Linear Regression Model\nfrom sklearn.linear_model import LinearRegression\nle = LinearRegression()\nle.fit(X_train, y_train)","27e9a81b":"# Predicting the Data\ny_pred_test = le.predict(X_test)","8470c099":"y_pred_test","81fd5f80":"y_test","091957a0":"import statsmodels.regression.linear_model as sm\n\n# Adding a Constant bo in multilinaer regression feature equation\nX = np.append(arr = np.ones((50,1)).astype(int), values = X, axis = 1)\n\n# Writting all the indexes and copying all the features \nX_opt = X[:, [0, 1, 2, 3, 4, 5]]\n\n# Using Signiface Level SL = 0.500\n\n# Fit the Full model with all possible predictors\nregressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n\n#Seeing Summary of OLS fitting model\nregressor_OLS.summary()","76e8069f":"# Removing b2 its p-value > SL\n# Writting all the indexes and copying all the features \nX_opt = X[:, [0, 1, 3, 4, 5]]\n# Fit the Full model with all possible predictors\nregressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n# Seeing Summary of OLS fitting model\nregressor_OLS.summary()","17a56bd4":"# Removing b1 its p-value > SL\n# Writting all the indexes and copying all the features \nX_opt = X[:, [0, 3, 4, 5]]\n# Fit the Full model with all possible predictors\nregressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n# Seeing Summary of OLS fitting model\nregressor_OLS.summary()\n\n","c80a6fda":"# Removing b4 its p-value > SL\n# Writting all the indexes and copying all the features \nX_opt = X[:, [0, 3, 5]]\n# Fit the Full model with all possible predictors\nregressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n# Seeing Summary of OLS fitting model\nregressor_OLS.summary()","ca038f74":"# Performing Linear Regression again by using main features only\n\n# Allocating Data\nX_BE, y_BE = X_opt, y\n\n# Splitting the Dataset into Training and Testing Part\nfrom sklearn.model_selection import train_test_split\nX_BE_train, X_BE_test, y_BE_train, y_BE_test = train_test_split(X_BE, y_BE, test_size = 0.2, random_state = 0)\n\n# Fitting in Linear Regression Model\nle.fit(X_BE_train, y_BE_train)","3634f664":"# Predicting the Data\ny_BE_pred_test = le.predict(X_BE_test)","98f26b64":"y_BE_pred_test","08fd41d6":"y_pred_test","66b3a932":"y_test","d884aa3a":"[![forthebadge](https:\/\/forthebadge.com\/images\/badges\/built-with-love.svg)](https:\/\/forthebadge.com)","ba7c0efa":"### <center>Please Vote If you like our Kernel and share your Feedback<\/center> <img  src=\"https:\/\/raw.githubusercontent.com\/ABSphreak\/ABSphreak\/master\/gifs\/Hi.gif\" width=\"50px\">","1525b010":"Fitting Our Training part into Linear Regression Model","27ca7049":"# <center>**Multi Variable Linear Regression**<\/center>\n## <center>**Feature Selection - Backward Elimination**<\/center>\nMultiple linear regression attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. Every value of the independent variable x is associated with a value of the dependent variable y.","c6ea4a14":"Splitting dataset into two parts one of Dependent Variable X and second is Independent Variable Y","8aa36e78":"Our Model Predicting the values of X_test is very Close to it.","c095a7bf":"Predicting the Profit Value For X_test Data","d9f6578e":"Splitting Dataset Into Two Halves Training and Testing Part","e7394267":"### Dummy Variable Trap\n\nThe Dummy Variable trap is a scenario in which the independent variables are multicollinear - a scenario in which two or more variables are highly correlated; in simple terms one variable can be predicted from the others.\n\nThe solution to the dummy variable trap is to drop one of the categorical variables (or alternatively, drop the intercept constant) - if there are m number of categories, use m-1 in the model, the value left out can be thought of as the reference value and the fit values of the remaining categories represent the change from this reference.","9db0ade2":"Importing All Main Common Libraries going to used through out the Model.","f1a7ef7f":"## Backward Elimination\n\nBackward Elimination is a process of Selecting a Features from a dataset. This makes the model more precise. Selecting features for your model is the major task. \n\n### Steps to Implement Backward Elimination\n\n![](http:\/\/3.bp.blogspot.com\/-Q5NbRCOwVQc\/WVCRFGON1QI\/AAAAAAAABsc\/Nzu8UtbejwoqFf6FYWhUGuWpMd-jDfAtwCLcBGAs\/s1600\/Capture5.PNG)","b25697fd":"Data Our Model Predicted For X_test Part","7ffd4cb6":"Our Machines can Only Computate with numerical Values not Categorical Values But in Independent variable X their is a column of State (type - Categorical value) so we can not computate with Categorical Value.\n\n\nThere is Two Options to Deal this type of Data:\n\n1 - Leave it if it is not very Important factor for Scaling\n\n2 - Now, You don't have any Option rather than to learn it How to do handel this\n\nThe approach that you need to take when you face categorical variables in regression models is you need to create dummy variables.\n\nFirst you need to go through your column and find all the different categories you have. So in this case we have three categories. So for every single category that you followed you need to create a new column for New York we're going to create a column called New-Yorker for color for immigrants create calm California so we're kind of expanding our data set and adding some additional columns into it and how do we populate the column. So this is the fun part to populate these columns. ","b8e9ad6e":"Importing DataSet of 50 Startups","9082beea":"Original Profit Value That will given in Dataset for X_test Part","9ba131df":"Re-Creating Linear Model Now only for Specified features"}}