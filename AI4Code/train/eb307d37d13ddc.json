{"cell_type":{"d135cd95":"code","1a330fc0":"code","b3b52f9f":"code","557e1c5a":"code","11fb0cac":"code","7c8d2fb9":"code","261bbd6e":"code","67183240":"code","b342c98a":"code","33103954":"code","2eb959df":"code","0e816f77":"code","7f2a9f84":"code","4be95e86":"code","17e951fe":"code","e0aa8221":"markdown","b8f6c71d":"markdown","b67688d1":"markdown","e35e2308":"markdown","7eed0884":"markdown","bb84cf52":"markdown","8f28b1ba":"markdown"},"source":{"d135cd95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n","1a330fc0":"train_df = pd.read_csv('..\/input\/train.csv')\ntrain_df['diagnosis'] = train_df['diagnosis'].astype('str')\ntrain_df['id_code'] = train_df['id_code'].astype(str)+'.png'","b3b52f9f":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(\n    rescale=1.\/255, \n    validation_split=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nbatch_size = 16\nimage_size = 96\n\n\n\ntrain_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"..\/input\/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(image_size,image_size),\n    subset='training')\n\ntest_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"..\/input\/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\", \n    target_size=(image_size,image_size),\n    subset='validation')","557e1c5a":"y_train = train_df['diagnosis']\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\nnum_classes = y_train.shape[1]","11fb0cac":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, GaussianNoise, GaussianDropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, SeparableConv2D\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras import regularizers, optimizers","7c8d2fb9":"def build_model():\n    # create model\n    model = Sequential()\n    #model.add(Reshape((x_train.shape[0],),))\n    #model.add(GaussianDropout(0.3,input_shape=[96,96,3]))\n    model.add(Conv2D(15, (3, 3), input_shape=[96,96,3], activation='relu'))\n    model.add(GaussianDropout(0.3))\n    model.add(Conv2D(30, (5, 5), activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(30, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(50, (5, 5), activation='relu'))\n    model.add(Conv2D(50, (7, 7), activation='relu'))\n    \n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n                   ,activity_regularizer=regularizers.l1(0.01)))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model","261bbd6e":"model = build_model()","67183240":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\nmc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)","b342c98a":"model.fit_generator(generator=train_gen,              \n                                    steps_per_epoch=len(train_gen),\n                                    validation_data=test_gen,                    \n                                    validation_steps=len(test_gen),\n                                    epochs=50,\n                                    callbacks = [es, mc], \n                                    use_multiprocessing = True,\n                                    verbose=1)","33103954":"from keras.models import load_model\nmodel = load_model('model.h5')","2eb959df":"submission_df = pd.read_csv('..\/input\/sample_submission.csv')\n#submission_df['diagnosis'] = submission_df['diagnosis'].astype('str')\nsubmission_df['filename'] = submission_df['id_code'].astype(str)+'.png'","0e816f77":"submission_datagen=ImageDataGenerator(rescale=1.\/255)\nsubmission_gen=submission_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=\"..\/input\/test_images\",\n    x_col=\"filename\",    \n    batch_size=batch_size,\n    shuffle=False,\n    class_mode=None, \n    target_size=(image_size,image_size)\n)","7f2a9f84":"predictions=model.predict_generator(submission_gen, steps = len(submission_gen))","4be95e86":"max_probability = np.argmax(predictions,axis=1) ","17e951fe":"submission_df.drop(columns=['filename'], inplace= True)\nsubmission_df['diagnosis'] = max_probability\nsubmission_df.to_csv('submission.csv', index=False)","e0aa8221":"Preprocessing test images:","b8f6c71d":"Traditional CNN:\n","b67688d1":"To prevent overfitting,\n* monitoring the loss on validation\/test set for minimum value\n* run epochs for 20 times when there is no decrease in val_loss\n* save the best model that has low validation loss","e35e2308":"Function \n* to get image from respective directory(train_images, test_images)\n* to resize the large image\n","7eed0884":"* Extract target column from training data\n* Convert target column to categorical","bb84cf52":"Load train data:","8f28b1ba":"Run predictions for given test data and submit the output file in required format (submission.csv)"}}