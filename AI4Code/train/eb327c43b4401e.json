{"cell_type":{"bca882e8":"code","bf13e575":"code","fb2f703a":"code","5b42fa54":"code","ad4deb28":"code","df462ce8":"code","0edb475e":"code","3421a889":"code","f19d6130":"code","931cc15f":"code","d88ba157":"code","d58daab2":"code","6b3bdec5":"code","897a0357":"code","5fe9e338":"code","f0f0d5fe":"code","df45c639":"code","8bd3226f":"code","799cdad1":"code","00047e4b":"code","54e8a3bf":"code","ad37f5e4":"code","bd533ac0":"code","b69c3757":"code","83541686":"code","d1207125":"code","7f325d59":"code","5215d923":"code","c6402fe4":"code","01e5b9ff":"code","a31c5202":"code","d36b01c9":"code","8e34cd86":"code","7acc4d84":"code","46cafce1":"code","d7689d82":"code","24a11035":"code","30e67672":"code","66761356":"code","6080f1a4":"markdown","a9ca0c1d":"markdown","e7e14f79":"markdown","3140ea8c":"markdown","5919d322":"markdown","c1798ac7":"markdown","c992b150":"markdown","68392470":"markdown","3dc9b3db":"markdown","1fdce8aa":"markdown","f213ae33":"markdown","26d6c064":"markdown","bb98eddd":"markdown","e49f73c2":"markdown","97140953":"markdown","08c6d441":"markdown","5682ffa6":"markdown","c5b2a423":"markdown","926f5471":"markdown","a03e9e4a":"markdown","a66fbbc9":"markdown","d6db500e":"markdown","03ff7521":"markdown","8f925144":"markdown","289895bd":"markdown","682336a7":"markdown","d359ce88":"markdown","14fec943":"markdown"},"source":{"bca882e8":"EDA = False\n!ls -al \/kaggle\/input","bf13e575":"pip install tifffile","fb2f703a":"%matplotlib inline\n\nimport cv2\nimport json\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n#from imread import imread, imsave\n\nimport shutil\nimport psutil\n\nimport tensorflow as tf\n\nimport glob\nimport tifffile\nimport gc\nimport sys","5b42fa54":"!ls \/kaggle\/input\/","ad4deb28":"!ls -l \/kaggle\/input\/hubmap-kidney-segmentation\/","df462ce8":"basepath = '\/kaggle\/input\/hubmap-kidney-segmentation\/'\ntrain_df = pd.read_csv(basepath + \"train.csv\")\ntrain_df.head()","0edb475e":"train_df.shape","3421a889":"!ls -l \/kaggle\/input\/hubmap-kidney-segmentation\/train","f19d6130":"!ls -l \/kaggle\/input\/hubmap-kidney-segmentation\/test","931cc15f":"# verify that we can read all images\ndef verify_read(file_list):\n    for file_name in file_list:\n        baseimage = tifffile.imread(file_name)\n        #baseimage = tif.series[0].asarray()\n        print('img id = {}, shape = {}, dtype = {}'.format(file_name,baseimage.shape, baseimage.dtype ) )\n        baseimage = None\n        gc.collect()\n\nif EDA:\n    print( \"before verify_read:\", psutil.virtual_memory(), file = sys.stderr )\n    file_list = glob.glob('\/kaggle\/input\/hubmap-kidney-segmentation\/train\/*.tiff')\n    verify_read(file_list)\n    print( \"after verify_read:\", psutil.virtual_memory(), file = sys.stderr )\n","d88ba157":"#select an image to investigate\nworking_image_index = 0\nworking_image_id = train_df['id'][working_image_index]\nworking_image_id\nworking_image_path = '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/'+working_image_id+'.tiff'","d58daab2":"\nif EDA:\n    baseimage = tifffile.imread(working_image_path)\n    print ('original image shape',baseimage.shape)\n    print ('original image dtype', baseimage.dtype )\n    print ('original image min\/max', ( np.amin( baseimage ), np.amax( baseimage ) ) )\n    baseimage = np.squeeze(baseimage)\n    if( baseimage.shape[0] == 3):\n        baseimage = baseimage.swapaxes(0,1)\n        baseimage = baseimage.swapaxes(1,2)\n        print ('swaped shape',baseimage.shape)\n\n    plt.figure()\n\n    plt.imshow(baseimage)","6b3bdec5":"# read json mask\nworking_image_json_mask = '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/'+working_image_id+'.json'\nif EDA:\n    read_file = open(working_image_json_mask, \"r\") \n    mask_data = json.load(read_file)\n    print( mask_data[0] )\n    mask_data = None\n    gc.collect()\n    print( psutil.virtual_memory(), file = sys.stderr )","897a0357":"def read_mask(mask_file, mask_shape):\n    read_file = open(mask_file, \"r\") \n    mask_data = json.load(read_file)\n    polys = []\n    for index in range(mask_data.__len__()):\n        geom = np.array(mask_data[index]['geometry']['coordinates'])\n        polys.append(geom)\n\n    mask = np.zeros(mask_shape, dtype = np.uint8 )\n    cv2.fillPoly(mask, polys, 1)\n    mask = mask.astype(bool)\n    return mask\n   ","5fe9e338":"if EDA:\n    mask_shape = (baseimage.shape[0], baseimage.shape[1])\n    mask = read_mask(working_image_json_mask, mask_shape)\n    plt.imshow(mask)\n    gc.collect()\n    print( psutil.virtual_memory(), file = sys.stderr )","f0f0d5fe":"if EDA:\n    baseimage.dtype","df45c639":"if EDA:\n    mask.dtype","8bd3226f":"if EDA:\n    mask.shape","799cdad1":"class OverlappingTiledImage:\n    '''\n    A class whose objects can be used to extract overlapping tiles from a larger image,\n    whose primary method get_tile extends nominal tile size by specified overlap, \n    reflecting through the boundaries of the larger image if the tile + overlap would\n    extend past the boundary.  We use the convention that \"row\" and \"col\" (lower case)\n    refer to location of pixels in one tile, while \"ROW\" and \"COL\" (upper case) refer\n    to the location of the tile in the tableau of tiles covering the image.\n    '''\n    # Primary data members, specified by constructor arguments:\n    # self.image:   The large \"base\" image from which tiles are extracted\n    # self.tile_pixel_rows:  The number of rows of pixels in a tile\n    # self.tile_pixel_cols:  The number of columns of pixels in a tile\n    # self.tile_pixel_overlap: The overlap, in pixels, between adjacent tiles, in all directions\n    # self.image_pixel_row_start:  The pixel row number of the upper left corner of the (ROW=0, COL=0) tile\n    # self.image_pixel_col_start:  The pixel column number \" \" \"\n    # self.image_pixel_row_stop: The pixel row number past the lower right corner of the (ROW=tile_ROWS-1,COL=tile_COLS-1) tile\n    # self.image_pixel_col_stop: The pixel column number \" \" \"\n    # Derived data members:\n    # self.tile_ROWS:  The number of ROWS of tiles in the tableau of overlapping tiles\n    # self.tile_COLS:  The number of COLUMNS of tiles in the tableau of overlapping tiles\n    \n    # \"public\" methods:\n    def __init__ ( self, image, pixel_rows, pixel_cols, pixel_overlap, \n                   image_pixel_row_start = 0, image_pixel_col_start = 0,\n                   image_pixel_row_stop = None, image_pixel_col_stop = None ):\n        # Process defaults for last two args:\n        if image_pixel_row_stop is None:\n            image_pixel_row_stop = image.shape[ 0 ]\n        if image_pixel_col_stop is None:\n            image_pixel_col_stop = image.shape[ 1 ]\n        # Sanity checks\n        assert pixel_rows > 0\n        assert pixel_cols > 0\n        assert pixel_overlap >= 0\n        assert image_pixel_row_start >= 0\n        assert image_pixel_row_stop <= image.shape[ 0 ]\n        assert image_pixel_row_start < image_pixel_row_stop\n        assert image_pixel_col_start >= 0\n        assert image_pixel_col_stop <= image.shape[ 1 ]\n        assert image_pixel_col_start < image_pixel_row_stop\n        # Copy primary data members\n        self.image = image\n        self.tile_pixel_rows = pixel_rows\n        self.tile_pixel_cols = pixel_cols\n        self.tile_pixel_overlap = pixel_overlap\n        self.image_pixel_row_start = image_pixel_row_start\n        self.image_pixel_col_start = image_pixel_col_start\n        self.image_pixel_row_stop = image_pixel_row_stop\n        self.image_pixel_col_stop = image_pixel_col_stop\n        # Derive data members\n        self.tile_ROWS = ( image_pixel_row_stop - image_pixel_row_start ) \/\/ pixel_rows\n        self.tile_COLS = ( image_pixel_col_stop - image_pixel_col_start ) \/\/ pixel_cols\n        '''\n        print( \"image_pixel_row_stop\", image_pixel_row_stop, \"image_pixel_row_start\", image_pixel_row_start, file = sys.stderr )\n        print( \"image_pixel_col_stop\", image_pixel_col_stop, \"image_pixel_col_start\", image_pixel_col_start, file = sys.stderr )\n        print( \"pixel_rows\", pixel_rows, \"pixel_cols\", pixel_cols, file = sys.stderr )\n        '''\n        \n    def SHAPE( self ):\n        '''\n        Returns:  Shape of overlapping image in tiles\n        '''\n        return ( self.tile_ROWS, self.tile_COLS )\n    \n    def tile_shape( self ):\n        '''\n        Returns:  Shape + overlap of individual tile, in pixels\n        '''\n        return ( self.tile_pixel_rows, self.tile_pixel_cols, self.tile_pixel_overlap )\n    \n    def image_shape( self ):\n        '''\n        Returns:  shape of underlying image, ignoring image_pixel_row_start, etc.\n        '''\n        return self.image.shape\n    \n    def get_tile( self, tile_ROW, tile_COL ):\n        assert ( tile_ROW >= 0 ) & ( tile_ROW < self.tile_ROWS )\n        assert ( tile_COL >= 0 ) & ( tile_COL < self.tile_COLS )\n        pixel_row_start = self.image_pixel_row_start + tile_ROW * self.tile_pixel_rows - self.tile_pixel_overlap\n        pixel_col_start = self.image_pixel_col_start + tile_COL * self.tile_pixel_cols - self.tile_pixel_overlap\n        pixel_row_stop_no = min( self.image_pixel_row_start + ( 1 + tile_ROW ) * self.tile_pixel_rows, self.image_pixel_row_stop )\n        pixel_col_stop_no = min( self.image_pixel_col_start + ( 1 + tile_COL ) * self.tile_pixel_cols, self.image_pixel_col_stop )\n        pixel_row_stop = pixel_row_stop_no + self.tile_pixel_overlap\n        pixel_col_stop = pixel_col_stop_no + self.tile_pixel_overlap\n        '''\n        print( \"  pixel_row_stop_no\", pixel_row_stop_no, file = sys.stderr )\n        print( \"  pixel_col_stop_no\", pixel_col_stop_no, file = sys.stderr )\n        print( \"  pixel_row_start\", pixel_row_start, \"pixel_col_start\", pixel_col_start, file = sys.stderr )\n        print( \"  pixel_row_stop\", pixel_row_stop, \"pixel_col_stop\", pixel_col_stop, file = sys.stderr )\n        '''\n        \n        tile = self.image[ max( pixel_row_start, self.image_pixel_row_start ) : min( pixel_row_stop, self.image_pixel_row_stop ),\n                           max( pixel_col_start, self.image_pixel_col_start ) : min( pixel_col_stop, self.image_pixel_col_stop ) ]\n        if ( pixel_row_start < self.image_pixel_row_start ):\n            tile = self.extend_top( tile, pixel_row_start )\n            # print( \"  extend_top\", file = sys.stderr )\n        if ( pixel_row_stop > self.image_pixel_row_stop ):\n            tile = self.extend_bottom( tile, pixel_row_stop )\n            # print( \"  extend_bottom\", file = sys.stderr )\n        if ( pixel_col_start < self.image_pixel_col_start ):\n            tile = self.extend_left( tile, pixel_col_start )\n            # print( \"  extend_left\", file = sys.stderr )\n        if ( pixel_col_stop > self.image_pixel_col_stop ):\n            tile = self.extend_right( tile, pixel_col_stop )\n            # print( \"  extend_right\",file = sys.stderr )\n        return tile\n    \n    def remove_overlap( self, tile ):\n        '''\n        Returns: \"tile\" with overlap removed\n        '''\n        return tile[ self.tile_pixel_overlap : - self.tile_pixel_overlap, self.tile_pixel_overlap : - self.tile_pixel_overlap ]\n    \n    # \"private\" methods:\n    \n    def copyMakeBorder( self, tile, border_top, border_bot, border_left, border_right, treatment = cv2.BORDER_REFLECT ):\n        if tile.dtype == np.bool:\n            return cv2.copyMakeBorder( tile.astype( np.int8 ), border_top, border_bot, border_left, border_right, treatment ).astype( np.bool )\n        else:\n            return cv2.copyMakeBorder( tile, border_top, border_bot, border_left, border_right, treatment )\n        \n    \n    def extend_top( self, tile, pixel_row_start ):\n        return self.copyMakeBorder( tile, self.image_pixel_row_start - pixel_row_start, 0, 0, 0 )\n            \n    def extend_bottom( self, tile, pixel_row_stop ):\n        return self.copyMakeBorder( tile, 0, pixel_row_stop - self.image_pixel_row_stop, 0, 0 )\n    \n    def extend_left( self, tile, pixel_col_start ):\n        return self.copyMakeBorder( tile, 0, 0, self.image_pixel_col_start - pixel_col_start, 0 )\n\n    def extend_right( self, tile, pixel_col_stop ):\n        return self.copyMakeBorder( tile, 0, 0, 0, pixel_col_stop - self.image_pixel_col_stop )\n","00047e4b":"#explore a few tiles\ndef show_tile_and_mask(baseimage_oti, mask_oti, tile_col_pos, tile_row_pos):\n    tile_image = baseimage_oti.get_tile( tile_col_pos, tile_row_pos )\n    tile_mask = mask_oti.get_tile( tile_col_pos, tile_row_pos )\n    fig, ax = plt.subplots(1,2,figsize=(20,3))\n    ax[0].imshow(tile_image)\n    ax[1].imshow(tile_mask)\n'''    \ndef get_tile(baseimage, tile_size, tile_col_pos, tile_row_pos):\n    start_col = tile_col_pos*tile_size\n    end_col = start_col + tile_size\n    start_row = tile_row_pos * tile_size\n    end_row = start_row + tile_size\n    tile_image = baseimage[start_col:end_col, start_row:end_row,:]\n    return tile_image\n\ndef get_tile_mask(baseimage, tile_size, tile_col_pos, tile_row_pos):\n    start_col = tile_col_pos*tile_size\n    end_col = start_col + tile_size\n    start_row = tile_row_pos * tile_size\n    end_row = start_row + tile_size\n    tile_image = baseimage[start_col:end_col, start_row:end_row]\n    return tile_image\n\n'''  \ndef show_tile_dist(tile):\n    fig, ax = plt.subplots(1,2,figsize=(20,3))\n    #ax[0].set_title(\"Tile ID = {} Xpos = {} Ypos = {}\".format(img_mtd['tile_id'], img_mtd['tile_col_pos'],img_mtd['tile_row_pos']))\n    ax[0].imshow(tile)\n    ax[1].set_title(\"Pixelarray distribution\");\n    sns.distplot(tile.flatten(), ax=ax[1]);\n","54e8a3bf":"if EDA:\n    tile_size = 512\n    overlap = 64\n    baseimage_oti = OverlappingTiledImage( baseimage, tile_size, tile_size, overlap )\n    mask_oti = OverlappingTiledImage( mask, tile_size, tile_size, overlap )\n    tile = baseimage_oti.get_tile( 0, 0)\n    print( \"tile.shape\", tile.shape, file = sys.stderr )\n    show_tile_dist(tile)\n    print( \"baseimage_oti.SHAPE()\", baseimage_oti.SHAPE(), file = sys.stderr )\n    gc.collect()\n    print( psutil.virtual_memory(), file = sys.stderr )\n    mask_tile = mask_oti.get_tile( 0, 0 )\n    print( \"mask_tile.dtype\", mask_tile.dtype, file = sys.stderr )","ad37f5e4":"if EDA:\n    img_hist = np.histogram(tile)\n    print('histogram = {}'.format(img_hist[0]))\n    print('histogram_lowpass = {}'.format(np.sum(img_hist[0][0:4])))","bd533ac0":"if EDA:\n    tile = baseimage_oti.get_tile( 5, 5)\n    show_tile_dist(tile)","b69c3757":"if EDA:\n    img_hist = np.histogram(tile)\n    print('histogram = {}'.format(img_hist[0]))\n    print('histogram_lowpass = {}'.format(np.sum(img_hist[0][0:4])))","83541686":"if EDA:\n    tile = baseimage_oti.get_tile( 8, 20 )\n    print( \"tile.shape\", tile.shape, file = sys.stderr )\n    show_tile_dist(tile)","d1207125":"if EDA:\n    img_hist = np.histogram(tile)\n    print('histogram = {}'.format(img_hist[0]))\n    print('histogram_lowpass = {}'.format(np.sum(img_hist[0][0:4])))","7f325d59":"if EDA:\n    show_tile_and_mask(baseimage_oti, mask_oti, 8, 20)","5215d923":"if EDA:\n    tile_mask = mask_oti.get_tile( 8, 20)\n    mask_density = np.count_nonzero(tile_mask)\n    print( \"mask_density\", mask_density, \"\/\", tile_mask.shape[0] * tile_mask.shape[1] )","c6402fe4":"if EDA:\n    show_tile_and_mask(baseimage_oti, mask_oti, 9, 20)","01e5b9ff":"if EDA:\n    tile_mask = mask_oti.get_tile( 9, 20)\n    mask_density = np.count_nonzero(tile_mask)\n    mask_density","a31c5202":"if EDA:\n    show_tile_and_mask(baseimage_oti, mask_oti, 10, 20)","d36b01c9":"if EDA:\n    tile_mask = mask_oti.get_tile( 10, 20)\n    mask_density = np.count_nonzero(tile_mask)\n\n    print( \"\\nAt end of visualizations, before gc, memory is {}\", psutil.virtual_memory(), file = sys.stderr, flush = True )\n    baseimage = None\n    mask = None\n    baseimage_oti = None\n    mask_oti = None\n    gc.collect()\n    print( \"\\nAt end of visualizations, memory is {}\", psutil.virtual_memory(), file = sys.stderr, flush = True )\n\n    mask_density","8e34cd86":"# Utilities serialize data into a TFRecord\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float \/ double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","7acc4d84":"def image_example(image_index, image_tile, mask_tile, pixel_overlap, tile_id, tile_col_pos, tile_row_pos):\n    image_tile_shape = image_tile.shape\n    \n    img_bytes = image_tile.tostring()\n\n    mask_bytes = np.zeros((0,0)).tostring() if mask_tile is None else mask_tile.tostring()\n    \n    feature = {\n        'img_index': _int64_feature(image_index),\n        'height': _int64_feature(image_tile_shape[0]),  # NOTE this and \"width\" >includes< 2 * pixel_overlap\n        'width': _int64_feature(image_tile_shape[1]),\n        'pixel_overlap': _int64_feature(pixel_overlap),\n        'num_channels': _int64_feature(image_tile_shape[2]),\n        'image': _bytes_feature(img_bytes),\n        'mask' : _bytes_feature(mask_bytes),\n        'tile_id':  _int64_feature(tile_id),\n        'tile_col_pos': _int64_feature(tile_col_pos),\n        'tile_row_pos': _int64_feature(tile_row_pos),\n    }\n\n    return tf.train.Example(features=tf.train.Features(feature=feature))","46cafce1":"def write_tfrecord( image_index, image_tile, mask_tile, pixel_overlap, tile_id, tile_col_pos, tile_row_pos, tf_writer):\n    tf_example = image_example(image_index, image_tile, mask_tile, pixel_overlap, tile_id, tile_col_pos, tile_row_pos)\n    tf_writer.write(tf_example.SerializeToString())","d7689d82":"def write_tfrecord_tiles( image_index, image_id, image_oti, mask_oti, output_dir ):\n    '''\n    Write all the tiles for \"image_oti\" and \"mask_oti\" (if non-None) to \"output_path\".tfrec\n    Args:\n        image_index    0-origin index of original image\/mask\n        image_id       8-digit hexadecimal identifier of image\/mask\n        image_oti      Overlapping tile generator for original image\n        mask_oti       Overlapping tile generator for mask, may be None if not training\n        output_dir     For storing the single .tfrec file that all tiles are written to\n    Returns:\n    Dataframe describing all tiles for this image \/ mask \n    '''\n    print( \"write_tfrecord_tiles, output_dir\", output_dir, \"image_id\", image_id, file = sys.stderr )\n    # Check\" that \"image_oti\" and \"mask_oti\" match:\n    if mask_oti is not None:\n        assert image_oti.SHAPE() == mask_oti.SHAPE()\n        assert image_oti.tile_shape() == mask_oti.tile_shape()\n    \n    tile_rows, tile_cols = image_oti.SHAPE()\n    tile_pixel_rows, tile_pixel_cols, tile_pixel_overlap = image_oti.tile_shape()\n    tileID = 0\n    \n    print( \"write_tfrecord_tiles for image\", image_id, tile_rows, \"x\", tile_cols, \"tiles\", flush = True )\n\n    # create a pandas dataframe to store metadata for each tile\n    tile_df = pd.DataFrame(columns = ['img_index', 'img_id','tile_id', 'tile_rel_path',\n                                      'tile_col_num', 'tile_row_num', \n                                      'tile_pixel_rows', 'tile_pixel_cols', 'tile_pixel_overlap', \n                                      'lowband_density', 'mask_density'])\n\n    output_path = output_dir + image_id + \".tfrec\"\n    print( \"image_id\", image_id, \"output_path\", output_path, file = sys.stderr, flush = True )\n    \n    opts = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n    with tf.io.TFRecordWriter(output_path, opts) as tf_writer:\n\n        for col_number in range(tile_cols):\n\n            print('tile col_number {} '.format(col_number),end='', flush = True )\n    \n            for row_number in range(tile_rows):\n                \n                relative_path = image_id+'\/col{}_row{}.tfrec'.format(col_number,row_number)\n    \n                # Write this image, mask tile:\n                image_tile = image_oti.get_tile( row_number, col_number )\n                tile_mask = None if mask_oti is None else mask_oti.get_tile( row_number, col_number )\n\n                num_records = write_tfrecord( image_index, image_tile, tile_mask, tile_pixel_overlap, \n                                               tileID, col_number, row_number, tf_writer )\n                \n                # populate the metadata for this tile\n                img_hist = np.histogram(image_tile)\n                lowband_density = np.sum(img_hist[0][0:4])\n                mask_density = 0 if tile_mask is None else  np.count_nonzero(tile_mask)\n                tile_df = tile_df.append({'img_index':image_index, 'img_id':image_id, 'tile_id': tileID, \n                                          'tile_rel_path':relative_path, \n                                          'tile_col_num':col_number, 'tile_row_num':row_number,\n                                          'tile_pixel_rows':tile_pixel_rows, \n                                          'tile_pixel_cols':tile_pixel_cols, \n                                          'tile_pixel_overlap':tile_pixel_overlap,\n                                          'lowband_density':lowband_density, 'mask_density':mask_density},\n                                         ignore_index=True)\n                tileID += 1\n                \n    # Follow Wojtek Rosa's convention to include number of tiles in tfrec filename\n    os.rename( output_path, output_path.replace( image_id, image_id + \"-\" + str( tileID ) ) )\n                \n    return tile_df","24a11035":"def tile_and_build_tfr( input_dir, output_dir, do_mask = True, tile_size = 512, tile_overlap = 64  ):\n    '''\n    For all original images\/masks in \"input_dir\" ,\n    break the images\/masks into overlapping tiles and place in TFRecord files in \"output_dir\", one file per original image\/mask.  This aligns with input conventions\n    assumed by Wojtek Rosa's code that we will borrow from.\n\n    Args:\n        input_dir    (e.g., '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/')\n        output_dir   (e.g., \"\/kaggle\/working\/train\/\")\n        do_mask      Iff True, tile mask images as well\n        tile_size    Tiles are ( tile_size x tile_size ) PLUS border of tile_overlap on all four sides\n        tile_overlap\n    Returns:\n        None\n    '''\n    print( \"tile_and_build_tfr, input_dir\", input_dir, \"output_dir\", output_dir, file = sys.stderr, flush = True )\n    image_file_list = glob.glob( input_dir + '[0-9a-f]*.tiff')\n                              \n    if os.path.exists(output_dir):\n        shutil.rmtree(output_dir)\n    os.mkdir(output_dir)\n\n    for image_index, image_file_name in enumerate( image_file_list ):\n        \n        mask_file_name = image_file_name.replace( \"tiff\", \"json\" )\n        image_id = os.path.split( image_file_name )[1].split(\".\")[0]\n        \n        baseimage = tifffile.imread( image_file_name )\n        print ('original image {  }, shape, ID = {}',baseimage.shape, image_id, flush = True )\n        baseimage = np.squeeze(baseimage)\n        if( baseimage.shape[0] == 3):\n            baseimage = baseimage.swapaxes(0,1)\n            baseimage = baseimage.swapaxes(1,2)\n            print ('swapped shape',baseimage.shape)\n            \n        # read json mask\n        if do_mask:\n            mask_shape = (baseimage.shape[0], baseimage.shape[1])\n            mask = read_mask( mask_file_name, mask_shape)\n        else:\n            mask = None\n        \n        # Set up overlap tiling for image and mask:\n        image_oti = OverlappingTiledImage( baseimage, tile_size, tile_size, tile_overlap )\n        mask_oti = None if mask is None else OverlappingTiledImage( mask, tile_size, tile_size, tile_overlap )\n        \n        print('writing {} x {} tiles for image {}'.format(image_oti.SHAPE()[ 0 ], image_oti.SHAPE()[ 1 ], image_id ) )\n        if mask_oti is not None:\n            print('writing {} x {} tiles for mask {}'.format(mask_oti.SHAPE()[ 0 ], mask_oti.SHAPE()[ 1 ], image_id ) )\n        tile_df = write_tfrecord_tiles( image_index, image_id, image_oti, mask_oti, output_dir )\n        \n        #write the dataframe\n        print('writing tile metadata for image {}'.format(image_id))\n        df_path = output_dir+image_id+'_tiles.csv'\n        tile_df.to_csv(df_path)\n        \n        baseimage = None\n        mask = None\n        image_oti = None\n        mask_oti = None\n        gc.collect()\n        print( \"\\nAt end of writing tiles for {}, memory is {}\", image_id, psutil.virtual_memory(), file = sys.stderr )","30e67672":"\n# Tile and save train image\ninput_dir = \"\/kaggle\/input\/hubmap-kidney-segmentation\/train\/\"\noutput_dir = '\/kaggle\/working\/train\/'\ntile_and_build_tfr( input_dir, output_dir, do_mask = True )\n!ls -l \/kaggle\/working\/train","66761356":"!tar -cvzf \/kaggle\/working\/tiled_train_image_tfrecs.tar.gz \/kaggle\/working\/train\n!rm -fr \/kaggle\/working\/train\n!ls -al \/kaggle\/working","6080f1a4":"# Objective:\n\nThe objective of this notebook is to provide an example of how to transform the HubMAP Hacking the Kidney competition dataset into a form that can readily used to train models leveraging accelerators. The images in this competition have very high resolution, averaging 30,000 x 30,000 pixels, and this presents a difficult challenge in memory management. It is just not possible to read them all in memory in the Kaggle environment, and it is also not possible to build a model using the whole image as input. This notebooks provides some tips for reading the competitions images and masks, and proposes a strategy to deal with the large sizes. \nThe strategy adopted in this Notebook is to tile the images in 512X512 tiles, and then transforming the tiles into TFRecords such that we can later use them as input to train models using GPU or TPU accelerators. \n\nThis Notebook takes a long time to run because it processes all the competition files and the resulting, compressed dataset is 18.1G, almost exceeding the Kaggle VM limit. I was able to process all files and then uploaded the results to a Kaggle daset that I have made public:\n--> [Link to the TFRecord Dataset Produced by this Notebook.](https:\/\/www.kaggle.com\/marcosnovaes\/hubmap-tfrecord-512)\n\nI have also developed a Notebook that explains how to use the TFRecord Dataset: [https:\/\/www.kaggle.com\/marcosnovaes\/hubmap-looking-at-tfrecords\/](https:\/\/www.kaggle.com\/marcosnovaes\/hubmap-looking-at-tfrecords\/)\n\nIf you want to use the dataset without change you don't need to run the Notebook -- but do read through it because it provides a lot of insight on how the read the images, masks and convert them to TFRecords. I will be using this dataset on my subsequent notebooks. You can also easily costumize this Notebook if you want to produce tiles od different sizes (I used 512x512) or if you want to include more metadata for each tile. ","a9ca0c1d":"# Reading the Images\nSome of the images are in TIFF format, some are in BigTIFF. I used the tiffile library and it seems to read the images with no problem.","e7e14f79":"The following function converts the polygons into a numpy boolean mask with the same shape as the image.","3140ea8c":"So, the glom ends in that tile, and there are fewer TRUE pixels. Going further down we find a cortex tile with no gloms.","5919d322":"So, now we know how to read each image and mask, and that their types are uint8 and bool respectively. But they have very large dimensions, we would not be able to train a ML model at these dimensions. So, in the next section I takes the approach of tiling up the image and working with tiles.","c1798ac7":"Write tiles for all train images and verify they were written to file.","c992b150":"The next cell reads all tiffs and prints their shapes. It turns out that some TIFF images are channel first (number \"3\" first) and others channel last (number \"3\" last). When reading them, we must check if the \"3\" is first and swap the axis as needed. This loop will take a long time as each image is read just so we can tell its shape. ","68392470":"Libs used in this Notebook","3dc9b3db":"The masks are provided in the csv files in RLE format, but we are also provided json files that describe the mask as polygons. I will be using the json files:","1fdce8aa":"Now let's try to find a glomerulus. If we look back at the polygon dump above, it shows that the first glom starts at pixel [10503, 4384]. If we divide both indexes by 512, we expect to find a glom in tile [8,20]","f213ae33":"Bingo!!! We found our first glom. Let's now derive a metric for masks, so that in the future we can easily find tiles with gloms. This metric will be used when we want to filter the training dataset to make sure it includes a certain number of tiles with gloms. Simply counting the number of \"TRUE\" pixels in the mask is a great metric that indicate the tile contains a glom.","26d6c064":"Let's look at the input data. Find and read the competition train.csv file.","bb98eddd":"And here is the white one ([5,5]","e49f73c2":"Now let's move down the image by incrementing the height offset to [9,20], which should be the tile below [8,20]","97140953":"The id corresponds to the images provided. For each image, you are provided a .tiff image file and the Run Length Encoding Mask. \n\nBut notice that the masks are also provided as a .json file with polygon definitions. I used this option instead in this Notebook. ","08c6d441":"Here is the code that takes care of the difference in shapes. \nIMPORTANT: Notice that you need to use the numpy.swapaxes function to change the shape, using \"reshape\" will scramble the channels.","5682ffa6":"# Transforming the Tiles into a TFRecord Dataset\nWe are now ready to read all the images (one at a time or we will run out of memory!) and then writing each tile to a TFRecord file. Kaggle has a limit of 50 upper level directories, so we will create one dir for each image. We will also build a pandas dataframe that has the metadata for each tile, including the lowpass energy and mask density metrics that we derived above. \n\nUsing the TFRecord format for storing data should be easy, but unfortunately it requires data serialization which complicates it a little bit. This is done using [protocol buffers](https:\/\/developers.google.com\/protocol-buffers\/) and that is a bit of a learning curve. But in ML you only need to understand the [TFExample](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/train\/Example) format. In this Notebook I provide a little template code for dealing with TFExamples that can be quickly customized for any type of data. This template is explained in detail in [this tutorial](https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord); but you don't need to read all this, in this Notebook I provide an example specific for image data that you can quickly customize.\n\nFor serialization using TFExample, we have to make any data fit into either one of 3 types:\n* bytes_feature\n* float_feature\n* int_64_feature\n\nIn this Notebook and image and mask are passed as bytes_features and the other metadata as int_64. ","c5b2a423":"Black as predicted. As we explore the tiles, I also calculate the tile histogram. If we observe the histogram we will notice that it will provide a useful way to filter black and white tiles later. The numpy.histogram function divides the color spectrum in 10 bins and shows how many pixels call within each bin. We can notice that black and white fall into the higher end of the spectrum. Black tiles have 0 pixels in the lower end, while \"white\" (actually \"dirty gray\") has only about 20 pixels in that region. We then see that tiles with some actual tissue have a more even distribution. Let's call this metric \"lowpass energy\". It turns out that if we later select lowpass energy > 100 we are garanteed to have actual tissue in the slide, and we can discard anything with < 100. ","926f5471":"# ***Disclaimer:*** \nHello Kagglers! I am a Solution Architect with the Google Cloud Platform. I am a coach for this competition, the focus of my contributions is on helping users to leverage GCP components (GCS, TPUs, BigQueryetc..) in order to solve large problems. My ideas and contributions represent my own opinion, and are not representative of an official recommendation by Google. Also, I try to develop notebooks quickly in order to help users early in competitions. There may be better ways to solving particular problems, I welcome comments and suggestions. Use my contributions at your own risk, I don't garantee that they will help on winning any competition, but I am hoping to learn by collaborating with everyone.\n","a03e9e4a":"As can be noticed in the sample image displayed, there is a black border and then a lot of white surrounding the tissue. If we select [0,0] we expect to see a black tile. If we move a little to the right and down, we are then in the white zone. So let's try the values [0,0] and [5,5] and we should be a black and a white tile respectively.","a66fbbc9":"# Compress Output\n@Dustin (Kaggle Staff) recommends compressing the result to a single file to see whether that helps with the\nproblem of this notebook getting \"stuck\".","d6db500e":"This inline code will read each image and mask in the train set, swap axes when needed, loading the image and mask into numpy arrays and then invoking the above function for each image\/mask pair. This will take a long time...","03ff7521":"# Reading and Showing a sample image and mask\nThe next cells show the code that can read the first image in the csv file. \n\nIMPORTANT: Note that in the case of a \"channel first\" TIFF (number \"3\" first) we need to swap the axis of the numpy array as noted below. You CANNOT use \"reshape\" instead, that will scramble the channels.","8f925144":"Here is the function that takes an image, slices into tiles, calculates tile metadata and commits to storage. It also builds a pandas dataframe with the metadata for all tiles. ","289895bd":"# Lavin versions\n*  v.21, include \"pixel_overlap\" in output TFRecords","682336a7":"# ***Pre-Disclaimer:*** \nThis notebook was adapted from the excellent one by Marcos Novaes https:\/\/www.kaggle.com\/marcosnovaes\/hubmap-read-data-and-build-tfrecords; changes:\n* introduction of overlapping tiles.\n* write all tiles for a single original image into a single TFrecord file.\n* The notebook contains exploratory material that can be disabled by setting the variable EDA (Exploratory Data Analysis) to False.","d359ce88":"This function writes a tile to storage, notice the GZIP compression -- this makes possible for all the tiles to be stored locally without exceeding the HD allowance of the Kaggle machine.","14fec943":"# Tiling the Large Images into 512x512 tiles with overlap\nHere are some useful functions that use the numpy slicing capability to select specifc tiles of the image. \n\nNOTE: The numpy arrays have dimensions [height, width, channels]. This Notebook will tile the image using offsets for the height index and width index. So:\n- a Tile with coordinate [0,0] represents the first tile on the top left corner.  \n- a Tile with coordinate [1,0] represents a tile with height offset = 1*Tile Size, in this case it starts at numpy coordinates [512,0], which means it is the tile below [0,0]\n- a Tile with coordinate [0,1] represents a tile with wodth offset = 1*Tile Size, in this case it starts at numpy coordinates [0,512], which means it is the tile to the right of [0,0]"}}