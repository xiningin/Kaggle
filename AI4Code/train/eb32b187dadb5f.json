{"cell_type":{"b93bd359":"code","b9cc26ae":"code","f5966714":"code","091fbf9d":"code","25d92f13":"code","9df1f29e":"code","4bb82abe":"code","186da79f":"code","4e99b36d":"code","73816df5":"code","1031a9bb":"code","0c223843":"code","d0671a0e":"code","d33f7623":"markdown","aa6a8b1f":"markdown","f8e5588b":"markdown","7cd8f6e6":"markdown","0cc7e298":"markdown","5601de24":"markdown","0e79dd5f":"markdown"},"source":{"b93bd359":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9cc26ae":"\nimport tensorflow as tf\nimport warnings\nwarnings.simplefilter('ignore')\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n","f5966714":"\ntraindata=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ny=traindata['label']\nX=traindata.drop('label',axis=1)","091fbf9d":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.21,random_state=44)","25d92f13":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n","9df1f29e":"x_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test = tf.keras.utils.normalize(x_test, axis=1)","4bb82abe":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","186da79f":"model.fit(x_train, y_train, epochs=30)","4e99b36d":"val_loss, val_acc = model.evaluate(x_test, y_test)\nprint(val_loss)\nprint(val_acc)","73816df5":"y_pred = model.predict(x_test)","1031a9bb":"testdata=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nX_test=testdata\nX_test = tf.keras.utils.normalize(X_test, axis=1)\ny_pred=model.predict(X_test)","0c223843":"sample_submission=pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nImageId=sample_submission['ImageId']\nimport numpy as np\ny_pred2=[]\nfor i in range(len(y_pred)):\n    y_pred2.append(np.argmax(y_pred[i]))  \n\n","d0671a0e":"sample_submission = pd.DataFrame({'ImageId': ImageId,'Label': y_pred2})\nprint(sample_submission)\nsample_submission.to_csv('sample_submission.csv',index=False)","d33f7623":"**Import Library**","aa6a8b1f":"**Predict data from  test **","f8e5588b":"**Complie**","7cd8f6e6":"**Data Normalization**","0cc7e298":"**Read Data**","5601de24":"**Create Neural Network**","0e79dd5f":"**Split Train Data**"}}