{"cell_type":{"c605a86c":"code","24d74336":"code","08befa94":"code","5ed68951":"code","9cb8c458":"code","2aa2e692":"code","61921447":"code","a11e4449":"code","ca509ed2":"code","64dcba25":"code","904ac5d7":"code","2b472a14":"code","380782c9":"code","bb8b87a5":"code","48621d99":"code","12e7c461":"code","eecd88d9":"code","0fd92b58":"code","5164c4f3":"code","d982eb8e":"code","fbe9f3d2":"code","c6c7ec71":"code","1cb60b77":"code","154872d7":"code","61887b13":"code","daf89bf9":"code","fc288d33":"markdown"},"source":{"c605a86c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)","24d74336":"def missing_zero_values_table(df):\n        zero_val = (df == 0.00).astype(int).sum(axis=0)\n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n        mz_table = mz_table.rename(\n        columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n        mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n        mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] \/ len(df)\n        mz_table['Data Type'] = df.dtypes\n        mz_table = mz_table[mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"      \n            \"There are \" + str(mz_table.shape[0]) + \" columns that have missing values.\")\n        return mz_table","08befa94":"def show_corr(df):\n    fig = plt.subplots(figsize = (20,20))\n    sb.set(font_scale=1.5)\n    sb.heatmap(df.corr(),square = True,cbar=True,annot=True,annot_kws={'size': 10})\n    plt.show()","5ed68951":"def change_types(cols):\n    for col in cols:\n        labels = train[col].unique()\n        map_labels = dict(zip(labels, range(0,len(labels))))\n        train[col] = train[col].map(map_labels)\n        train[col] = train[col].astype(float)\n        \n        test[col] = test[col].map(map_labels)\n        test[col] = test[col].astype(float)","9cb8c458":"def change_categorical():\n    for col in features_cat:      \n        if col in features_ignore:\n            continue\n        features_ignore.append(col)\n        for item in train[col].unique():\n            if not item is np.NaN:            \n                for i in list(set(str(item))):\n                    new_col = col +'_'+ str.upper(str(i).replace(',',''))\n                    if not new_col in train.columns:\n                        train[new_col] = 0\n                        test[new_col] = 0\n                        #print('add', new_col)\n                    train[new_col] = train[col].apply(lambda x: float(str(x).find(item) >= 0))                 \n                    test[new_col] = test[col].apply(lambda x: float(str(x).find(item) >= 0))        ","2aa2e692":"def remove_outlier(df, col):\n    if col in features_ignore:\n        return\n    \n    if df[col].dtype == object:\n        return   \n    \n    fig = plt.subplots(figsize = (20,3))\n    \n    _std = round(df[col].std(), 5)\n    _mean= round(df[col].mean(), 5)    \n    _min = round(_mean - df[col].std()*3, 5)\n    if _min < 0:\n        _min = 0.00001\n    _max = round(_mean + df[col].std()*3, 5)\n    if _max > 20:\n        _max = 19.99999\n        \n    plt.hist(df[col], bins=100)\n    \n    df.loc[(df[col] < 0) | (df[col] < _min) | (df[col] > _max)] = _mean\n    df[col] = round(df[col], 5)\n    \n    plt.hist(df[col], bins=100)    \n    print('Process Remove Outlier', col, '| mean:', _mean, '| std:', _std,\n          '| min:', _min, '| max:', _max, '-> min:', df[col].min(), '| max:', df[col].max())\n    plt.show()    ","61921447":"train = pd.read_csv(\"\/kaggle\/input\/competicao-dsa-machine-learning-dec-2019\/dataset_treino.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/competicao-dsa-machine-learning-dec-2019\/dataset_teste.csv\")","a11e4449":"missing_zero_values_table(train)","ca509ed2":"train.head()","64dcba25":"test.head()","904ac5d7":"train.describe().T","2b472a14":"test.describe().T","380782c9":"train.dtypes","bb8b87a5":"features_cat = []\nfor col in train.columns:\n    if train[col].dtype == 'O':\n        features_cat.append(col)\nprint(features_cat)","48621d99":"features_ignore = ['ID', 'v22', 'v10', 'v109', 'v104', 'v105', 'v15', 'v121', 'v114', 'v29', 'v26', \n                   'v25', 'v41', 'v11', 'v46', 'v33', 'v26', 'v54', 'v17', 'v20', 'v41', \n                   'v32', 'v64','v67', 'v63', 'v55', 'v32', 'v63', 'v92', 'v41', 'v118']","12e7c461":"train.describe().T","eecd88d9":"%%time\n#changeTypes(features_cat)\nchange_categorical()","0fd92b58":"train.describe().T","5164c4f3":"features = []\nfor col in test.columns:\n    if col not in features_ignore:\n        features.append(col)\nfeatures_train = features + ['target']\nprint(features_train)","d982eb8e":"missing_zero_values_table(train)","fbe9f3d2":"train.columns[2:132]","c6c7ec71":"for col in train.columns[2:132]:\n    remove_outlier(train, col)","1cb60b77":"for col in test.columns[1:132]:\n    remove_outlier(test, col)","154872d7":"train.head()","61887b13":"train.to_csv('fe_train.csv', index=False)","daf89bf9":"test.to_csv('fe_test.csv', index=False)","fc288d33":"# [EDA with Pandas Profile Report](https:\/\/www.kaggle.com\/wentzforte\/eda-pandas-profiling)"}}