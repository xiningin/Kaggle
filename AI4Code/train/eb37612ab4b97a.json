{"cell_type":{"019d37ea":"code","c5ceda1a":"code","bb6788ca":"code","bbab97db":"code","62d4cb61":"code","567369b1":"code","b759d7fa":"code","48b0d8a1":"code","760e8f92":"code","56a7033a":"code","cb0c60f8":"code","02d77ccd":"code","57335128":"code","0183523a":"code","2a6aa147":"code","90332148":"code","2a2f3fca":"code","69e29504":"code","cf3f40d1":"code","737019f4":"code","29a93fef":"code","eb916435":"code","dbb3520f":"code","a8c3e177":"code","94c9601f":"code","f8274c78":"code","84f6fed5":"code","3aeb0a28":"code","71a8304b":"code","67513420":"code","5eabd531":"code","b58efd4c":"code","f8024484":"code","415eb6e4":"code","ea0f0a7b":"code","530e116d":"code","9b8337fd":"code","f11c58b0":"code","86d5aeeb":"code","007671b0":"code","a128c1a3":"code","446cff76":"code","727051e3":"code","f16385e0":"code","30b56404":"code","d108a3cf":"code","f7fe63ea":"code","788310d1":"code","a73a42a4":"code","6ce0b36a":"code","53f2fd06":"code","bb7b5bdc":"code","48f734b7":"code","ccb42fd5":"code","2d516439":"code","894445eb":"code","90741352":"code","326de40b":"code","4062ef87":"code","6498a42b":"code","1bfa3e2b":"code","65f92fb1":"code","f08ed9d9":"code","025e142e":"code","16545bd6":"code","3e4263db":"code","e8e42eb6":"code","2e889761":"code","9876f2f2":"code","74522622":"code","50fe8cd1":"code","4def2cb9":"code","d6559980":"code","a6cb25a0":"code","08f5ddc2":"code","7e01526f":"code","467cb2f3":"code","47482e44":"code","825d47a3":"code","339d2b1b":"code","e494f5f5":"code","31f3972e":"code","349cf4c6":"code","42cbe460":"code","4d3f5525":"code","03ab1400":"code","44dd45c8":"code","eb7c3ec5":"code","ad155a30":"code","cf7627fa":"code","27dee17d":"code","175021fa":"code","18a0a02e":"code","45d4882d":"code","bba034d4":"code","429d698e":"code","aa1aa9a0":"code","98eca457":"code","0ed39e92":"code","7e4bb8d6":"code","1f6f4ff0":"code","23d4253e":"code","2a083917":"code","e87539bf":"code","d70d6339":"code","2ceb3623":"code","e1c23d66":"code","a6a4f9b5":"code","b41065d5":"code","b833fcb0":"code","b9a99e94":"code","095020a9":"code","db4a0908":"code","8235e16a":"code","e36d88ad":"code","9a1a430b":"code","6ca7344b":"code","e5094aa6":"code","96607a3c":"code","6697d5d1":"code","b331b9e4":"code","e92952d6":"code","f3e6f243":"code","f2433403":"code","5e6e4bc8":"code","a6262da4":"code","c59ac0dc":"code","ec183639":"code","695ccffa":"code","9e9c7ccd":"code","ae31d0d2":"code","b70d6131":"code","c45e0349":"code","28389926":"code","9f797445":"code","1f392c57":"code","77a25b8a":"code","a7acf68d":"code","4403ec0f":"markdown","22a62cf4":"markdown","f06cc2ff":"markdown","05331d4c":"markdown","0cb7f806":"markdown","bf984fa8":"markdown","68a01757":"markdown","73864117":"markdown","2335b166":"markdown","e23126eb":"markdown","5bb2713e":"markdown","bfa0caeb":"markdown","196a547b":"markdown","44979608":"markdown","20abe695":"markdown","636219e9":"markdown","0446e107":"markdown","ef4d3471":"markdown","a2052937":"markdown"},"source":{"019d37ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c5ceda1a":"# General tools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt \n\n# For transformations and predictions\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom scipy.optimize import curve_fit\nfrom sklearn.tree import DecisionTreeRegressor, export_graphviz\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import pairwise_distances\n\n# For the tree visualization\nimport pydot\nfrom IPython.display import Image\nfrom sklearn.externals.six import StringIO\n\n# For scoring\nfrom sklearn.metrics import mean_squared_log_error as msle\nfrom sklearn.metrics import mean_squared_error as mse\n\n\n# For validation\nfrom sklearn.model_selection import train_test_split as split\n\n\n%matplotlib inline","bb6788ca":"import sys\n\nif 'google.colab' in sys.modules:\n    from google.colab import files\n    uploaded = files.upload()","bbab97db":"nyc= pd.read_csv('nyc.csv')\nnyc.head(3)","62d4cb61":"# Removing zero or negative prices\nnyc = nyc[nyc.log_price > 0]","567369b1":"# Removing bad data\ndef drop_zeros(nyc):\n    return nyc.loc[nyc.beds * nyc.accommodates * nyc.bathrooms * nyc.bedrooms != 0]\nzeros_dropper = FunctionTransformer(drop_zeros, validate=False)\n\nnyc = zeros_dropper.fit_transform(nyc) ","b759d7fa":"# Changing True\\False field into 1\\0 values\ncleaning_fee_dict = {True:1,False:0}\nhost_identity_verified_dict={'t':1,'f':0}\ninstant_bookable_dict={'t':1,'f':0}\n\nnyc.cleaning_fee.replace(cleaning_fee_dict,inplace=True)\nnyc.host_identity_verified.replace(host_identity_verified_dict,inplace=True)\nnyc.instant_bookable.replace(instant_bookable_dict,inplace=True)\n#nyc.head()","48b0d8a1":"# Creating Date\\Year and delta dates between first review and last review\n\nnyc['date_host'] = pd.to_datetime(nyc.host_since)\nnyc['year_host'] = nyc['date_host'].dt.year\n\nnyc['date_end'] = pd.to_datetime(nyc.last_review)\nnyc['year_end'] = nyc['date_end'].dt.year\n\nnyc['date_start'] = pd.to_datetime(nyc.first_review)\nnyc['year_start'] = nyc['date_start'].dt.year\n\nnyc['delta_dates'] = (nyc['date_end']-nyc['date_start'])\n\nnyc['delta_dates']=nyc['delta_dates'].dt.days\n\nnyc.drop(['date_host','date_end','date_start','date_host'],axis=1,inplace=True)\n\n#nyc.head()\n","760e8f92":"# Dropping irelevant fields\nnyc.drop(['id','description','host_has_profile_pic','name','thumbnail_url','first_review','host_since','last_review','city','zipcode','host_response_rate'],axis=1,inplace=True)","56a7033a":"# Converting Bed Type field to Real bed or Other\nprint(nyc.groupby('bed_type')['log_price'].count())\n\nnyc.groupby('bed_type')['log_price'].mean().plot.bar()\n\ndef bed_group_func(row):\n  if row.loc['bed_type'] == 'Real Bed':\n    return 1\n  else:\n    return 0\n\nnyc['real_bed'] = nyc.apply(bed_group_func, axis=1)\n\nnyc.drop('bed_type',axis=1,inplace=True)","cb0c60f8":"# Cancellation Policy field (Removing values with fiew data)\nprint(nyc.cancellation_policy.value_counts())\n\nnyc = nyc[nyc.cancellation_policy != ('super_strict_30')]\nnyc = nyc[nyc.cancellation_policy != ('super_strict_60')]","02d77ccd":"nyc['cancellation_policy'].unique()","57335128":"# Changing Property type field to property_group (after creating high level values using dictionary)\nprint(nyc.property_type.value_counts())\n\nproperty_type_dict1 = {'Apartment':['Condominium','Loft','Serviced apartment','Guest suite'],\n         'House':['Vacation home','Villa','Townhouse','In-law','Casa particular'],\n         'Hotel1':['Dorm','Hostel','Guesthouse'],\n         'Hotel2':['Boutique hotel','Bed & Breakfast'],\n         'Timeshare':['Timeshare'],\n         'Other':['Island','Castle','Yurt','Hut','Chalet','Treehouse',\n                  'Earth House','Tipi','Cave','Train','Parking Space','Lighthouse',\n                 'Tent','Boat','Cabin','Camper\/RV','Bungalow']\n        }\n\nproperty_type_dict2 = {i : k for k, v in property_type_dict1.items() for i in v}\n\nnyc['property_group'] = nyc['property_type'].replace(property_type_dict2)\n\nnyc.drop('property_type',axis=1,inplace=True)\n\nprint('---------------------------------------')\nprint(nyc['property_group'].unique())","0183523a":"# Adding price per room field (For neighnourhood price level)\nnyc['price_per_room'] = nyc['log_price'] \/ nyc['bedrooms']\n\nnyc.neighbourhood.value_counts().head(30).plot.bar(color=(.0, 0.4, 0.9, 1))\n\nneighbourhood_avg_price = nyc[['neighbourhood','price_per_room']].groupby('neighbourhood')['price_per_room'].mean().sort_values()","2a6aa147":"neighbourhood_avg_price.replace(np.inf, np.nan,inplace=True)\nneighbourhood_avg_price.fillna(neighbourhood_avg_price.mean(),inplace=True)\n\nprint(neighbourhood_avg_price.sort_values(ascending=False))\nprint('---------------------------------------')\nprint(neighbourhood_avg_price.describe())","90332148":"neighbourhood_class_df = neighbourhood_avg_price.to_frame()\ntype(neighbourhood_class_df)","2a2f3fca":"# Converting neighbourhoods to Levels\ndef neigbourhood_class(row):\n  if row['price_per_room'] >=0 and row['price_per_room'] <= 3.683610:\n    return 1\n  elif row['price_per_room'] > 3.6836100 and row['price_per_room'] <= 3.868928:\n    return 2\n  elif row['price_per_room'] >3.868928 and row['price_per_room'] <= 4.194452: \n    return 3\n  else:\n    return 4\n  \nneighbourhood_class_df['neigbourhood_level'] = neighbourhood_class_df.apply(neigbourhood_class,axis=1)","69e29504":"neighbourhood_class_df.sort_values(by='neigbourhood_level',ascending=False)","cf3f40d1":"neighbourhood_class_df.drop('price_per_room',axis=1,inplace=True)","737019f4":"# Joining between the Main Data Frame and the  neighbourhood_class data frame to get neighbourhood class\nnyc = nyc.join(neighbourhood_class_df,on='neighbourhood')","29a93fef":"# Using Longtitude and Latitude fields to create 0-1 scale (North to South \/ West to East)\n\nplt.scatter(nyc.longitude,nyc.latitude,c = nyc.log_price)\nplt.xlabel(\"longitude\")\nplt.ylabel(\"latitude\")\nplt.title('log_price on Map', x=0.5, y=1.05, ha='center', fontsize='xx-large')","eb916435":"nyc.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, figsize=(15,10),\n    c=\"log_price\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)","dbb3520f":"# The Formulas are:\n# 1. (latitude - min_latitude) \/ (max_latitude - min_latitude)\n# 2. (longitude - min_longitude) \/ (max_longitude - min_longitude)\n\nnyc['latitude_north'] = (nyc.latitude - nyc.latitude.min()) \/ (nyc.latitude.max() - nyc.latitude.min())\nnyc['longitude_east'] = (nyc.longitude - nyc.longitude.min()) \/ (nyc.longitude.max() - nyc.longitude.min())","a8c3e177":"# Distance from time Square\nnyc['distance_to_t_squre'] = np.sqrt((40.758896-nyc['latitude'])**2+(-73.985130-nyc['longitude'])**2)\n\nnyc_num_2 = nyc[['distance_to_t_squre','log_price']].select_dtypes(include=np.number)\nsns.pairplot(nyc_num_2, height=3)","94c9601f":"# Distance from central train\nnyc['distance_to_c_train'] = np.sqrt((40.752655-nyc['latitude'])**2+(-73.977295-nyc['longitude'])**2)\n\nnyc_num_2 = nyc[['distance_to_c_train','log_price']].select_dtypes(include=np.number)\nsns.pairplot(nyc_num_2, height=3)","f8274c78":"# Distance from Wall Street\nnyc['distance_to_w_street']=np.sqrt((40.706005-nyc['latitude'])**2+(-74.008827-nyc['longitude'])**2)\n\nnyc_num_2 = nyc[['distance_to_w_street','log_price']].select_dtypes(include=np.number)\nsns.pairplot(nyc_num_2, height=3)","84f6fed5":"nyc.drop(['latitude','longitude'],axis=1,inplace=True)","3aeb0a28":"# Checking null values\n\nnyc.info()\n\nnyc.dropna(subset=['bathrooms','host_identity_verified','bedrooms','beds'],inplace=True)\nprint('--------------------------------------------------')\nnyc.info()","71a8304b":"# Changing amenities field to booleans seperated fields\n\nl=list(nyc['amenities'])\nl=[[word.strip('[\" ]') for word in row[1:-1].split(',')] for row in list(nyc['amenities'])]\ncols = set(word for row in l  for word in row)\namenities_df=pd.DataFrame(columns=cols)\nprint(cols)\namenities_df = pd.DataFrame(columns=cols)\nfor row_idx in range(len(l)):\n    for col in cols:\n        amenities_df.loc[row_idx,col]=int(col in l[row_idx])","67513420":"amenities_df.head()","5eabd531":"# Building a new field aggregating fields from amenities_df\n# The new fields will be: kitchen, accesibility, Electricity_and_Technology, facilities, kids_friendly, security, services\n\namenities_group_df = pd.DataFrame()\n#--------------------------------------\namenities_group_df['kitchen'] = amenities_df['Kitchen']+amenities_df['Breakfast']+amenities_df['Cooking basics']+amenities_df['Cooking basics']+amenities_df['BBQ grill']+amenities_df['Oven']+amenities_df['Coffee maker']+amenities_df['Microwave']+amenities_df['Refrigerator']+amenities_df['Dishwasher']\namenities_group_df['accesibility'] = amenities_df['Free parking on premises']+amenities_df['Wide clearance to bed']+amenities_df['smooth pathway to front door']+amenities_df['Ground floor access']+amenities_df['Lake access']+amenities_df['Wheelchair accessible']+amenities_df['Wide clearance to shower & toilet']+amenities_df['Wide hallway clearance']+amenities_df['Wide doorway']+amenities_df['Accessible-height toilet']+amenities_df['Step-free access']+amenities_df['Well-lit path to entrance']+amenities_df['Waterfront']+amenities_df['Free parking on street']+amenities_df['Disabled parking spot']+amenities_df['Accessible-height bed']+amenities_df['Private entrance']+amenities_df['Elevator']\namenities_group_df['Elect_Tech'] = amenities_df['Wide entryway']+amenities_df['Air conditioning']+amenities_df['Ethernet connection']+amenities_df['Cable TV']+amenities_df['Internet']+amenities_df['EV charger']+amenities_df['Baby monitor']+amenities_df['TV']+amenities_df['Wireless Internet']+amenities_df['Pocket wifi']+amenities_df['Washer']+amenities_df['Dryer']+amenities_df['Keypad']+amenities_df['Game console']+amenities_df['Washer \/ Dryer']+amenities_df['Hair dryer']\namenities_group_df['facilities'] = amenities_df['Private living room']+amenities_df['Air purifier']+amenities_df['Handheld shower head']+amenities_df['Hot water kettle']+amenities_df['Extra pillows and blankets']+amenities_df['Hot tub']+amenities_df['Pets live on this property']+amenities_df['Heating']+amenities_df['Dishes and silverware']+amenities_df['Patio or balcony']+amenities_df['Bed linens']+amenities_df['First aid kit']+amenities_df['Crib']+amenities_df['Flat']+amenities_df['Laptop friendly workspace']+amenities_df['Buzzer\/wireless intercom']+amenities_df['Firm mattress']+amenities_df['Iron']+amenities_df['Changing table']+amenities_df['Hangers']+amenities_df['Roll-in shower with chair']+amenities_df['Gym']+amenities_df['Outlet covers']+amenities_df['Essentials']+amenities_df['Private bathroom']+amenities_df['Baby bath']+amenities_df['Bathtub']+amenities_df['Shampoo']+amenities_df['Beachfront']+amenities_df['Single level home']+amenities_df['Hot water']+amenities_df['High chair']+amenities_df['Bathtub with shower chair']+amenities_df['Pool']+amenities_df['Fixed grab bars for shower & toilet']+amenities_df['Room-darkening shades']+amenities_df['Beach essentials']+amenities_df['Garden or backyard']\namenities_group_df['kids_friendly'] = amenities_df['Babysitter recommendations']+amenities_df['Family\/kid friendly']+amenities_df['Children\u2019s books and toys']+amenities_df['Children\u2019s dinnerware']\namenities_group_df['security'] = amenities_df['Window guards']+amenities_df['Stair gates']+amenities_df['Fireplace guards']+amenities_df['Doorman']+amenities_df['Carbon monoxide detector']+amenities_df['Smoke detector']+amenities_df['Table corner guards']+amenities_df['Fire extinguisher']+amenities_df['Lock on bedroom door']+amenities_df['Smart lock']+amenities_df['Lockbox']\namenities_group_df['services'] = amenities_df['Ski in\/Ski out']+amenities_df['Cleaning before checkout']+amenities_df['Long term stays allowed']+amenities_df['Other pet(s)']+amenities_df['Cat(s)']+amenities_df['Self Check-In']+amenities_df['24-hour check-in']+amenities_df['Host greets you']+amenities_df['Luggage dropoff allowed']+amenities_df['Pack \u2019n Play\/travel crib']+amenities_df['Pets allowed']+amenities_df['Suitable for events']+amenities_df['Safety card']+amenities_df['Indoor fireplace']+amenities_df['Dog(s)']+amenities_df['Smoking allowed']","b58efd4c":"amenities_group_df.head()","f8024484":"amenities_group_df.describe()","415eb6e4":"# This field will use to join between nyc data frame and amenities_group data frame\nnyc['join_key'] = range(0,len(nyc))\nnyc.index = nyc['join_key']","ea0f0a7b":"# Joining between the main data set and the data set based on amenities field\nnyc_j = nyc.join(amenities_group_df)","530e116d":"nyc_j.head(3)","9b8337fd":"# Keeping Data Frame before Dummies\nnyc_before_dummies_df = nyc_j\nnyc_before_dummies_2_df = nyc_j","f11c58b0":"# Creating Dummy Variables to string fields\n\nroom_dummies = pd.get_dummies(nyc_j.room_type,prefix='room').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,room_dummies],axis=1)\n\ncancellation_dummies = pd.get_dummies(nyc_j.cancellation_policy,prefix='cancellation').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,cancellation_dummies],axis=1)\n\nproperty_dummies = pd.get_dummies(nyc_j.property_group,prefix='property').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,property_dummies],axis=1)\n\nbedrooms_dummies = pd.get_dummies(nyc_j.bedrooms,prefix='bedrooms').iloc[:,1:]\nnyc_j = pd.concat([nyc_j,bedrooms_dummies],axis=1)","86d5aeeb":"nyc_j.head()","007671b0":"# Dropping original fields after dummies\nnyc_j.drop(['bedrooms','amenities','room_type','cancellation_policy','neighbourhood','property_group','join_key','price_per_room'],axis=1,inplace=True)","a128c1a3":"# New Data Frame without losing the first dummy variable (For decision tree)\nroom_dummies = pd.get_dummies(nyc_before_dummies_df.room_type,prefix='room').iloc[:,:]\nnyc_before_dummies_df = pd.concat([nyc_before_dummies_df,room_dummies],axis=1)\n\ncancellation_dummies = pd.get_dummies(nyc_before_dummies_df.cancellation_policy,prefix='cancellation').iloc[:,:]\nnyc_before_dummies_df = pd.concat([nyc_before_dummies_df,cancellation_dummies],axis=1)\n\nproperty_dummies = pd.get_dummies(nyc_before_dummies_df.property_group,prefix='property').iloc[:,:]\nnyc_before_dummies_df = pd.concat([nyc_before_dummies_df,property_dummies],axis=1)\n\nnyc_before_dummies_df.drop(['amenities','room_type','cancellation_policy','neighbourhood','property_group','join_key','price_per_room'],axis=1,inplace=True)","446cff76":"nyc_j.head(3)","727051e3":"# Histogram of nyc data frame\nnyc_j.hist(figsize=(10, 10),color=(\"c\"))","f16385e0":"# Pair plot of nyc data frame\nnyc_num = nyc_j.select_dtypes(include=np.number)\nsns.pairplot(nyc_num, height=3)","30b56404":"# Log price Correlations matrix\ncorr_matrix = nyc_j.corr()\ncorr_matrix[\"log_price\"].sort_values(ascending=False)","d108a3cf":"# Using correlation graph\nfig, ax = plt.subplots(figsize =(20, 20)) \ncorr = nyc_j.corr()\ncax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(nyc_j.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(nyc_j.columns)\nax.set_yticklabels(nyc_j.columns)\nplt.show()","f7fe63ea":"# Log price by accommodates pair plot\nnyc_num_accommodates = nyc[['log_price','accommodates']]#.select_dtypes(include=np.number)\nsns.pairplot(nyc_num_accommodates, height=3)","788310d1":"# Log price by beds pair plot\nnyc_num_beds = nyc[['log_price','beds']]#.select_dtypes(include=np.number)\nsns.pairplot(nyc_num_beds, height=3)","a73a42a4":"nyc_j.dropna(inplace=True)\nnyc_before_dummies_df.dropna(inplace=True)","6ce0b36a":"# Splitting the data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price\n\n# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","53f2fd06":"# Using Scikitlearn Linear regression & fit func\nlinear_model_1 = LinearRegression()\nlinear_model_1.fit(X_train, y_train)","bb7b5bdc":"# list of linear regression coefficient\nlist(zip(X_train.columns, linear_model_1.coef_))","48f734b7":"linear_model_1.coef_[0]","ccb42fd5":"# y pred based on training set\ny_train_pred = linear_model_1.predict(X_train)","2d516439":"# Comparing between y_train and y_train_pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","894445eb":"# Checking the train set RMSE\nmse(y_train, y_train_pred)**0.5","90741352":"# Checking results on the test set\ny_test_pred = linear_model_1.predict(X_test)","326de40b":"# Comparing between y_test and y_test_pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","4062ef87":"# Checking test set RMSE\nmse(y_test, y_test_pred)**0.5","6498a42b":"# Removing anomalous dots\ncols=['accommodates',\t'bathrooms'\t,'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'beds'\t,'year_host']\n\nfor col in cols:\n    if nyc_j[col].dtype == 'float64':\n        std = nyc_j[col].std()\n        ave = nyc_j[col].mean()\n        nyc_j = nyc_j.loc[nyc_j[col].between(ave-3.6*std, ave+3.6*std)]\n        print(f'processing {col:10} --> {nyc_j.shape[0]:5} nyc_j remain')","1bfa3e2b":"# Splitting the data\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price\n\nX_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","65f92fb1":"linear_model_2 = LinearRegression().fit(X_train, y_train)\nlist(zip(X_train.columns, linear_model_2.coef_))","f08ed9d9":"# y train prediction\ny_train_pred = linear_model_2.predict(X_train)","025e142e":"# y train vs y train pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","16545bd6":"# Training RMSE\nmse(y_train, y_train_pred)**0.5","3e4263db":"# y test prediction\ny_test_pred = linear_model_2.predict(X_test)","e8e42eb6":"# y test vs y test pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","2e889761":"# Testing RMSE\nmse(y_test, y_test_pred)**0.5","9876f2f2":"# stepwise\nimport statsmodels.api as sm\n\ndef stepwise_selection(X, y, \n                       initial_list=[], \n                       threshold_in=0.01, \n                       threshold_out = 0.05, \n                       verbose=True):\n    \"\"\" Perform a forward-backward feature selection \n    based on p-value from statsmodels.api.OLS\n    Arguments:\n        X - pandas.DataFrame with candidate features\n        y - list-like with the target\n        initial_list - list of features to start with (column names of X)\n        threshold_in - include a feature if its p-value < threshold_in\n        threshold_out - exclude a feature if its p-value > threshold_out\n        verbose - whether to print the sequence of inclusions and exclusions\n    Returns: list of selected features \n    Always set threshold_in < threshold_out to avoid infinite looping.\n    See https:\/\/en.wikipedia.org\/wiki\/Stepwise_regression for the details\n    \"\"\"\n    included = list(initial_list)\n    while True:\n        changed=False\n        # forward step\n        excluded = list(set(X.columns)-set(included))\n        new_pval = pd.Series(index=excluded)\n        for new_column in excluded:\n            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        best_pval = new_pval.min()\n        if best_pval < threshold_in:\n            best_feature = new_pval.argmin()\n            included.append(best_feature)\n            changed=True\n            if verbose:\n                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n\n        # backward step\n        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n        # use all coefs except intercept\n        pvalues = model.pvalues.iloc[1:]\n        worst_pval = pvalues.max() # null if pvalues is empty\n        if worst_pval > threshold_out:\n            changed=True\n            worst_feature = pvalues.argmax()\n            included.remove(worst_feature)\n            if verbose:\n                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n        if not changed:\n            break\n    return included\n\nresult = stepwise_selection(X, y)\n\nprint('resulting features:')\nprint(result)","74522622":"X = X[['kids_friendly', 'room_Private room', 'distance_to_t_squre', 'room_Shared room', 'accommodates', 'neigbourhood_level', 'Elect_Tech', 'distance_to_w_street', 'bathrooms', 'distance_to_c_train', 'review_scores_rating', 'bedrooms_3.0', 'bedrooms_2.0', 'bedrooms_4.0', 'longitude_east', 'year_end', 'property_Hotel2', 'property_House', 'number_of_reviews', 'year_start', 'property_Timeshare', 'latitude_north', 'bedrooms_5.0', 'beds', 'accesibility', 'bedrooms_7.0', 'bedrooms_6.0', 'property_Other', 'year_host', 'real_bed']]\ny = nyc_j.log_price","50fe8cd1":"X_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","4def2cb9":"linear_model_3 = LinearRegression().fit(X_train, y_train)\nlist(zip(X_train.columns, linear_model_2.coef_))","d6559980":"# y train prediction\ny_train_pred = linear_model_3.predict(X_train)","a6cb25a0":"# y train vs y train pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","08f5ddc2":"# Training RMSE\nmse(y_train, y_train_pred)**0.5","7e01526f":"# y test prediction\ny_test_pred = linear_model_3.predict(X_test)","467cb2f3":"# y test vs y test pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","47482e44":"# Testing RMSE\nmse(y_test, y_test_pred)**0.5","825d47a3":"# Splitting data to X and y\nX = nyc_before_dummies_df.drop('log_price', axis=1)\ny = nyc_before_dummies_df.log_price","339d2b1b":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X,y,train_size=0.7,random_state=12345)","e494f5f5":"# The descision tree model\ndt_model_1 = DecisionTreeRegressor(max_depth=5)\ndt_model_1.fit(X_train, y_train)","31f3972e":"# Visualization Tree\ndef visualize_tree(model, md=3):\n    dot_data = StringIO()  \n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n    return Image(graph.create_png(), width=1800) ","349cf4c6":"visualize_tree(dt_model_1, 4)","42cbe460":"# Train Prediction\ny_train_pred = dt_model_1.predict(X_train)","4d3f5525":"ax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","03ab1400":"#Training RMSE\nmse(y_train, y_train_pred)**0.5","44dd45c8":"# Test Prediction\ny_test_pred = dt_model_1.predict(X_test)","eb7c3ec5":"ax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","ad155a30":"# Test RMSE\nmse(y_test, y_test_pred)**0.5","cf7627fa":"sub_model = nyc_before_dummies_df.copy()","27dee17d":"# Removing anomalous dots\ncols=['accommodates',\t'bathrooms'\t,'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'beds'\t,'year_host']\n\nfor col in cols:\n    if sub_model[col].dtype == 'float64':\n        std = nyc_j[col].std()\n        ave = nyc_j[col].mean()\n        sub_model = sub_model.loc[sub_model[col].between(ave-3.6*std, ave+3.6*std)]\n        print(f'processing {col:10} --> {sub_model.shape[0]:5} sub_model remain')","175021fa":"sub_X = sub_model.drop('log_price', axis=1)\nsub_y = sub_model.log_price\n\nsub_X_train, sub_X_test, sub_y_train, sub_y_test = split(sub_X, sub_y, train_size=0.7,random_state=12345)","18a0a02e":"# max_depth check\ncomplexity = range (2, 50 , 1)\nscores = pd.DataFrame(index=complexity, columns=['train', 'test'])\n\nfor leafs in complexity:\n    model = DecisionTreeRegressor(max_leaf_nodes=leafs).fit(sub_X_train, sub_y_train)\n    \n    sub_y_train_pred = model.predict(sub_X_train)\n    scores.loc[leafs, 'train'] = mse(sub_y_train_pred, sub_y_train) ** 0.5\n    \n    sub_y_test_pred = model.predict(sub_X_test)\n    scores.loc[leafs, 'test'] = mse(sub_y_test_pred, sub_y_test) ** 0.5\n\nscores.plot()","45d4882d":"# min_samples_leaf check\ncomplexity = range (1, 50 , 5)\nscores = pd.DataFrame(index=complexity, columns=['train', 'test'])\n\nfor comp in complexity:\n    model = DecisionTreeRegressor(min_samples_leaf=comp).fit(sub_X_train, sub_y_train)\n    \n    sub_y_train_pred = model.predict(sub_X_train)\n    scores.loc[comp, 'train'] = mse(sub_y_train_pred, sub_y_train) ** 0.5\n    \n    sub_y_test_pred = model.predict(sub_X_test)\n    scores.loc[comp, 'test'] = mse(sub_y_test_pred, sub_y_test) ** 0.5\n\nscores.plot()","bba034d4":"# max_leaf_nodes check\ncomplexity = range (2, 70 , 1)\nscores = pd.DataFrame(index=complexity, columns=['train', 'test'])\n\nfor comp in complexity:\n    model = DecisionTreeRegressor(max_leaf_nodes=comp).fit(sub_X_train, sub_y_train)\n    \n    sub_y_train_pred = model.predict(sub_X_train)\n    scores.loc[comp, 'train'] = mse(sub_y_train_pred, sub_y_train) ** 0.5\n    \n    sub_y_test_pred = model.predict(sub_X_test)\n    scores.loc[comp, 'test'] = mse(sub_y_test_pred, sub_y_test) ** 0.5\n\nscores.plot()","429d698e":"# Improving Hyper parameters\nl_max_depth = [2,3,4,5,6,7,8,9,10]\nl_min_samples_leaf = [20,25,30,35,40,45,50]\nl_min_impurity_decrease = [0.001,0.002,0.003,0.004,0.005]\nmax_leaf_nodes= [40,45,50,55,60]\n\nfrom itertools import product\n\nscores = []\nfor i, (md, msl, mid, mln) in enumerate(product(l_max_depth, l_min_samples_leaf, l_min_impurity_decrease,max_leaf_nodes)):\n    sub_model = DecisionTreeRegressor(max_depth=md, min_samples_leaf=msl, min_impurity_decrease=mid, max_leaf_nodes=mln)\n    sub_model.fit(sub_X_train, sub_y_train)\n    y_train_pred = sub_model.predict(sub_X_train)\n    train_score = mse(sub_y_train, sub_y_train_pred)**0.5\n    y_test_pred = sub_model.predict(sub_X_test)\n    test_score = mse(sub_y_test, sub_y_test_pred)**0.5\n    scores.append((md, msl, mid, mln,train_score, test_score))","aa1aa9a0":"sorted(scores, key=lambda x: x[3], reverse=False) ","98eca457":"dt_model_2 = DecisionTreeRegressor(max_leaf_nodes=12, max_depth=8, min_samples_leaf=150, min_impurity_decrease=0.002).fit(sub_X_train, sub_y_train)","0ed39e92":"def visualize_tree(model, md=5):\n    dot_data = StringIO()  \n    export_graphviz(model, out_file=dot_data, feature_names=X_train.columns, max_depth=md)\n    graph = pydot.graph_from_dot_data(dot_data.getvalue())[0]  \n    return Image(graph.create_png(), width=1200) \n\nvisualize_tree(dt_model_2, 7)","7e4bb8d6":"sub_y_train_pred = dt_model_2.predict(sub_X_train)","1f6f4ff0":"ax = sns.scatterplot(x=sub_y_train, y=sub_y_train_pred)\nax.plot(y_train, y_train, 'r')","23d4253e":"RMSE = mse(sub_y_train, sub_y_train_pred)**0.5\nRMSE","2a083917":"sub_y_test_pred = dt_model_2.predict(sub_X_test)","e87539bf":"ax = sns.scatterplot(x=sub_y_test, y=sub_y_test_pred)\nax.plot(y_test, y_test, 'r')","d70d6339":"RMSE = mse(sub_y_test, sub_y_test_pred)**0.5\nRMSE","2ceb3623":"# Splitting data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price","e1c23d66":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X, y, train_size=0.7, random_state=314159)","a6a4f9b5":"# Using feature scaling\nmy_scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(my_scaler.transform(X_train), columns=X_train.columns)","b41065d5":"# Building the model\nknn_model_1 = KNeighborsRegressor().fit(X_train_scaled, y_train)","b833fcb0":"# Train Prediction\ny_train_pred = knn_model_1.predict(X_train_scaled)","b9a99e94":"# y_train vs y_train_pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","095020a9":"# train RMSE\nRMSE = mse(y_train, y_train_pred)**0.5\nRMSE","db4a0908":"# Scaling X test\nX_test_scaled = my_scaler.transform(X_test)","8235e16a":"# y Test prediction\ny_test_pred = knn_model_1.predict(X_test_scaled)","e36d88ad":"ax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","9a1a430b":"RMSE = mse(y_test, y_test_pred)**0.5\nRMSE","6ca7344b":"# Removing anomalous dots\ncols=['accommodates',\t'bathrooms'\t,'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'beds'\t,'year_host']\n\nfor col in cols:\n    if nyc_j[col].dtype == 'float64':\n        std = nyc_j[col].std()\n        ave = nyc_j[col].mean()\n        nyc_j = nyc_j.loc[nyc_j[col].between(ave-3.6*std, ave+3.6*std)]\n        print(f'processing {col:10} --> {nyc_j.shape[0]:5} nyc_j remain')","e5094aa6":"# Choosing the best KNN\nRMSE = []\nfor num in range(1, 12):\n    knn_model_1 = KNeighborsRegressor(n_neighbors=num).fit(X_train, y_train)\n    y_test_pred = knn_model_1.predict(X_test)\n    RMSE1 = mse(y_test, y_test_pred)**0.5\n    RMSE.append(RMSE1)\n\n    print(num,'-',RMSE1)","96607a3c":"# Splitting data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price","6697d5d1":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X, y, train_size=0.7, random_state=314159)","b331b9e4":"# Using feature scaling\nmy_scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(my_scaler.transform(X_train), columns=X_train.columns)","e92952d6":"# Building the model\nknn_model_2 = KNeighborsRegressor(n_neighbors=10).fit(X_train_scaled, y_train)","f3e6f243":"# Train Prediction\ny_train_pred = knn_model_2.predict(X_train_scaled)","f2433403":"# y_train vs y_train_pred\nax = sns.scatterplot(x=y_train, y=y_train_pred)\nax.plot(y_train, y_train, 'r')","5e6e4bc8":"# train RMSE\nRMSE = mse(y_train, y_train_pred)**0.5\nRMSE","a6262da4":"# Scaling X test\nX_test_scaled = my_scaler.transform(X_test)","c59ac0dc":"# y Test prediction\ny_test_pred = knn_model_2.predict(X_test_scaled)","ec183639":"#y_test vs y_test_pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","695ccffa":"# Test RMSE\nRMSE = mse(y_test, y_test_pred)**0.5\nRMSE","9e9c7ccd":"# Splitting data to X and y\nX = nyc_j.drop('log_price', axis=1)\ny = nyc_j.log_price","ae31d0d2":"# Splitting data to train and test\nX_train, X_test, y_train, y_test = split(X, y, train_size=0.7, random_state=314159)","b70d6131":"# Using feature scaling\nmy_scaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(my_scaler.transform(X_train), columns=X_train.columns)","c45e0349":"# Building the model\nknn_model_3 = KNeighborsRegressor(n_neighbors=10,weights='distance').fit(X_train_scaled, y_train)","28389926":"# Train Prediction\ny_train_pred = knn_model_3.predict(X_train_scaled)","9f797445":"# Scaling X test\nX_test_scaled = my_scaler.transform(X_test)","1f392c57":"# y Test prediction\ny_test_pred = knn_model_3.predict(X_test_scaled)","77a25b8a":"#y_test vs y_test_pred\nax = sns.scatterplot(x=y_test, y=y_test_pred)\nax.plot(y_test, y_test, 'r')","a7acf68d":"# Test RMSE\nRMSE = mse(y_test, y_test_pred)**0.5\nRMSE","4403ec0f":"# 4. Machine Learning","22a62cf4":"# 4.1 Linear Regression","f06cc2ff":"# 5. Conclusions","05331d4c":"# 2. EDA Process","0cb7f806":"# First Steps","bf984fa8":"**Regression Project - NYC Airbnb data**\n\nThe project is about Airbnb NYC transactions.\n\nThe data was takken from Kaggle\n\nThe prediction variable is log price per night.\n\nThe project process:\n\n1. import packages and data frame creation\n2. EDA Process (80% of time)\n3. Investigatin data\n4. Machine learning(20% time):\n\n* Using 3 Models: Linear Regression,Decision Trees and KNN.\n* Trying to improve each model\n* Checking the Test RMSE\n\n5. Conclusion- Choosing the best model based on Test RMSE","68a01757":"# 4.2 Decision Trees","73864117":"# Try 2 - Removing anomalous dots & checking for Hyper Parameters","2335b166":"## Try 1","e23126eb":"# Try 1","5bb2713e":"# Linear Regression - Try 2 (Removing anomalous dots)","bfa0caeb":"# Try 3 - Changing weight to distance (Default=Uniform) and using K=10","196a547b":"# Introduction","44979608":"# Try 1","20abe695":"TEST RMSE:\n\nLinear Regression:\n\nLinear Regression try 1 - 0.34436456895591605\n\nLinear Regression try 2 - 0.34436456895591605\n\nLinear Regression try 3 - 0.3440292214619928\n\nDecision Trees:\n\nDecision Trees try 1 - 0.3567719793832864\n\nDecision Trees try 2 - 0.3639217173982088\n\nKNN:\n\nKNN Try 1 - 0.37266015133144564\n\nKNN Try 2 - 0.35106469798714157\n\nKNN Try 3 - 0.34845669081517083\n\nThe best Model for our data: Linear Regression try 3 (After removing anomalous dots and using stepwise)","636219e9":"# Try 2 - Choosing the K and dropping anomalous rows","0446e107":"# 3. Investigating the Date","ef4d3471":"# 4.3 KNN Model","a2052937":"# Linear Regression Try 3 (Using stepwise)"}}