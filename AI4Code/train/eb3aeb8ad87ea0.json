{"cell_type":{"3ad8a8a8":"code","05d58aba":"code","f9fc36a3":"code","f17364e4":"code","bbfe6140":"code","a5120b97":"code","389f6682":"code","7e057b58":"code","947f5b01":"code","67476208":"markdown","878c16fe":"markdown"},"source":{"3ad8a8a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.datasets import make_blobs,make_circles\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n#print(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","05d58aba":"# Helper Functions\ndef plot_data(pl,X,y):\n    pl.plot(X[y==0,0],X[y==0,1], 'ob',alpha=0.5)\n    pl.plot(X[y==1,0],X[y==1,1], 'xr',alpha=0.5)\n    pl.legend(['0','1'])\n    return pl\n\ndef plot_decision_boundary(model,X,y):\n    amin,bmin=X.min(axis=0)-0.1\n    amax,bmax=X.max(axis=0)+0.1\n    hticks = np.linspace(amin,amax,101)\n    vticks = np.linspace(bmin,bmax,101)\n    \n    aa,bb = np.meshgrid(hticks,vticks)\n    ab = np.c_[aa.ravel(),bb.ravel()]\n    \n    c=model.predict(ab)\n    Z=c.reshape(aa.shape)\n    \n    plt.figure(figsize=(12,18))\n    plt.contourf(aa,bb,Z,cmap='bwr',alpha=0.2)\n    plot_data(plt,X,y)\n    return plt","f9fc36a3":"#X,y =make_blobs(n_samples=1000, centers=2,random_state=42)\nX,y =make_circles(n_samples=1000, factor=.6,noise=.1,random_state=42)\n\npl = plot_data(plt,X,y)\npl.show()\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)","f17364e4":"#Importing Libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.layers import Input\n","bbfe6140":"#Sequential Model\n'''\nmodel = Sequential()\n\nmodel.add(Dense(4,input_shape=(2,),activation='tanh', name='Hidden-1'))\nmodel.add(Dense(4,activation='tanh', name='Hidden-2'))\nmodel.add(Dense(1,activation='sigmoid',name='Output_Layer'))\n'''\n#Implement as Functional API\n\n#Input\ninputs = Input(shape=(2,))\n\n#Hidden Layer\nx = Dense(4,activation='tanh', name='Hidden-1')(inputs)\nx = Dense(4,activation='tanh', name='Hidden-2')(x)\n\n#Output Layer\no = Dense(1,activation='sigmoid',name='Output_Layer')(x)\n\nmodel = Model(inputs=inputs, outputs=o)\n\nmodel.summary()\n\nmodel.compile(Adam(lr=0.05), 'binary_crossentropy', metrics=['accuracy'])","a5120b97":"#Ploting model for documentation and understanding purpose\nfrom keras.utils import plot_model\nplot_model(model,show_shapes=True,show_layer_names=True,to_file='model.png')\n#plot_model()","389f6682":"#Adding Callback\nfrom keras.callbacks import EarlyStopping\nmy_callback=[EarlyStopping(monitor='val_acc',patience=5,mode=max)]\n\n#Training Model using fit() method\nmodel.fit(X_train,y_train,epochs=100, verbose=1,callbacks=my_callback, validation_data=(X_test,y_test))\n","7e057b58":"eval_result = model.evaluate(X_test,y_test)\nprint('\\nTest loss:', eval_result[0], '\\nTest accuracy: ',eval_result[1])\n\nplot_decision_boundary(model,X,y).show()","947f5b01":"#save model\nmodel.save('..\/output')","67476208":"### **Creating Dataset **","878c16fe":"### **Helper Functions to plot data and decision boundary**"}}