{"cell_type":{"a715b8d1":"code","31692f1f":"code","9897e2ba":"code","938624ea":"code","2aa3e9ab":"code","fcce7b34":"code","f98f8b46":"code","91f854db":"code","109075e1":"code","3a63ff78":"code","f2c0eebc":"code","8c476560":"markdown","6612ff73":"markdown","ea1f06bb":"markdown","efc7512c":"markdown"},"source":{"a715b8d1":"# ! pip install -q detoxify\n! pip install -q https:\/\/github.com\/Borda\/detoxify\/archive\/refs\/heads\/load-offline.zip\n\n# ! pip download -q detoxify --prefer-binary --dest frozen_packages\n! pip wheel -q https:\/\/github.com\/Borda\/detoxify\/archive\/refs\/heads\/load-offline.zip --wheel-dir frozen_packages\n! rm frozen_packages\/torch-*\n! ls frozen_packages","31692f1f":"! ls -l \/kaggle\/input\/huggingface-roberta-variants","9897e2ba":"! mkdir checkpoints\n! wget -q https:\/\/github.com\/unitaryai\/detoxify\/releases\/download\/v0.1-alpha\/toxic_original-c1212f89.ckpt --directory-prefix=checkpoints\n! wget -q https:\/\/github.com\/unitaryai\/detoxify\/releases\/download\/v0.3-alpha\/toxic_debiased-c7548aa0.ckpt --directory-prefix=checkpoints\n! wget -q https:\/\/github.com\/unitaryai\/detoxify\/releases\/download\/v0.4-alpha\/multilingual_debiased-0b549669.ckpt --directory-prefix=checkpoints\n! wget -q https:\/\/github.com\/unitaryai\/detoxify\/releases\/download\/v0.1.2\/original-albert-0e1d6498.ckpt --directory-prefix=checkpoints\n! wget -q https:\/\/github.com\/unitaryai\/detoxify\/releases\/download\/v0.1.2\/unbiased-albert-c8519128.ckpt --directory-prefix=checkpoints\n! ls -l checkpoints","938624ea":"import pandas as pd\n\ncomments = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv', index_col='comment_id')\ndisplay(comments.head())","2aa3e9ab":"import torch\nloaded = torch.load('checkpoints\/toxic_debiased-c7548aa0.ckpt')\nloaded[\"config\"][\"arch\"][\"args\"]","fcce7b34":"from detoxify import Detoxify\n\nmodel = Detoxify(\n    checkpoint='checkpoints\/toxic_debiased-c7548aa0.ckpt',\n    pretrained_model_path=\"\/kaggle\/input\/huggingface-roberta-variants\/roberta-base\/roberta-base\",\n#     device='cuda',\n)\nprint(comments['text'].tolist()[0])\nmodel.predict(comments['text'].tolist()[0])","f98f8b46":"from tqdm import tqdm\n\ntqdm.pandas()\ncomments['score'] = comments['text'].progress_map(lambda line: model.predict(line)['toxicity'])\ncomments['score'].plot.hist(bins=50, grid=True)","91f854db":"comments['score'].to_csv('submission.csv')\n\n! head submission.csv","109075e1":"validation_data = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ndisplay(validation_data.head())\n\nvalidation_unique = set(validation_data[\"less_toxic\"].tolist() + validation_data[\"more_toxic\"].tolist())\nprint(f'all: {len(validation_data)} and unique (less_toxic): {len(validation_data[\"less_toxic\"].unique())}')\nprint(f'all: {len(validation_data)} and unique (more_toxic): {len(validation_data[\"more_toxic\"].unique())}')\nprint(f'all: {len(validation_data)} and unique (both): {len(validation_unique)}')","3a63ff78":"valid_text_score = {txt: model.predict(txt) for txt in tqdm(validation_unique)}","f2c0eebc":"import numpy as np\n\npred_fields = ('toxicity', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'sexual_explicit')\nfor field in pred_fields:\n    validation_data['score_less'] = validation_data[\"less_toxic\"].apply(lambda ln: valid_text_score[ln][field])\n    validation_data['score_more'] = validation_data[\"more_toxic\"].apply(lambda ln: valid_text_score[ln][field])\n    # Average Agreement with Annotators -- score by organizers\n    score_less = np.array(validation_data['score_less'])\n    score_more = np.array(validation_data['score_more'])\n    score_mean = (score_less < score_more).mean()\n    print(f\"score for {field}: \\t{score_mean}\")\n    validation_data[field] = score_more - score_less\n\n_= validation_data[list(pred_fields)].plot.hist(bins=50, grid=True, alpha=0.4, legend=True)","8c476560":"## Validation","6612ff73":"## Running predictions","ea1f06bb":"## Prepare environment","efc7512c":"# Score \ud83d\ude4atoxic comments with trained \ud83e\udd17\u26a1Detoxify\n\n**Repository:** https:\/\/github.com\/Borda\/detoxify\n\n**Inspiration:** https:\/\/www.kaggle.com\/sorenj\/scoring-comments-using-unitaryai-detoxify"}}