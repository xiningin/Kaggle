{"cell_type":{"b6ca5674":"code","0e214c1a":"code","918bff02":"code","bfc15c5c":"code","91d826ee":"code","d837c282":"code","05d3a9e2":"code","5c3053b0":"code","d0fb1873":"code","53f68ffa":"code","5ef5ad90":"code","21049960":"code","035011ea":"code","dc8ba98d":"code","13f4af9f":"code","84307614":"code","37ba5846":"code","267d361b":"code","e6785342":"code","9e264aa2":"code","a861b7f4":"code","f79b2024":"markdown","8303524a":"markdown","f0759240":"markdown","9872620c":"markdown","b7f36938":"markdown","6661d29e":"markdown","171d08bc":"markdown","0d0661ae":"markdown","ff5c20cd":"markdown","b6841fce":"markdown","284444c8":"markdown","479e3cc5":"markdown","e26220d3":"markdown","337ad769":"markdown"},"source":{"b6ca5674":"import torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nfrom torchvision.utils import make_grid\nimport PIL\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nimport glob","0e214c1a":"def show_tensor_images(image_tensor, num_images=2, size=(3,256,256)):\n    image_tensor = (image_tensor + 1) \/ 2\n    image_shifted = image_tensor\n    image_unflat = image_shifted.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=2)\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    plt.show()","918bff02":"class ImageDataset(Dataset):\n    def __init__(self,root_dir,transform=None):\n        self.transform = transform\n        self.file_monet = sorted(glob.glob(os.path.join(root_dir,\"monet_jpg\")+\"\/*.*\"))\n        self.file_photo = sorted(glob.glob(os.path.join(root_dir,\"photo_jpg\")+\"\/*.*\"))\n        self.new_perm()\n        \n    def new_perm(self):\n        self.randperm = torch.randperm(len(self.file_photo))[:len(self.file_monet)]\n        \n    def __getitem__(self,index):\n        item_monet = self.transform(Image.open(self.file_monet[index%len(self.file_monet)]))\n        item_photo = self.transform(Image.open(self.file_photo[self.randperm[index]]))\n        return (item_monet-0.5)*2,(item_photo-0.5)*2\n        \n    def __len__(self):\n        return min(len(self.file_monet),len(self.file_photo))","bfc15c5c":"class ResidualBlock(nn.Module):\n    def __init__(self, input_channels):\n        super(ResidualBlock,self).__init__()\n        self.conv1 = nn.Conv2d(input_channels,input_channels,kernel_size=3,padding=1,padding_mode='reflect')\n        self.conv2 = nn.Conv2d(input_channels,input_channels,kernel_size=3,padding=1,padding_mode='reflect')\n        self.instancenorm = nn.InstanceNorm2d(input_channels)\n        self.activation = nn.ReLU()\n        \n    def forward(self,x):\n        original_x = x.clone()\n        x = self.conv1(x)\n        x = self.instancenorm(x)\n        x = self.activation(x)\n        \n        x = self.conv2(x)\n        x = self.instancenorm(x)\n        return original_x + x","91d826ee":"class ContractingBlock(nn.Module):\n    def __init__(self,input_channels,use_bn=True,kernel_size=3,activation='relu'):\n        super(ContractingBlock,self).__init__()\n        self.conv1 = nn.Conv2d(input_channels,input_channels*2,kernel_size=kernel_size,padding=1,stride=2,padding_mode='reflect')\n        self.activation = nn.ReLU() if activation == 'relu' else nn.LeakyReLU(0.2)\n        if use_bn:\n            self.instancenorm = nn.InstanceNorm2d(input_channels * 2)\n        self.use_bn = use_bn\n    \n    def forward(self,x):\n        x = self.conv1(x)\n        if self.use_bn:\n            x = self.instancenorm(x)\n        x = self.activation(x)\n        return x\n    \n\nclass ExpandingBlock(nn.Module):\n    def __init__(self,input_channels,use_bn=True):\n        super(ExpandingBlock,self).__init__()\n        self.conv1 = nn.ConvTranspose2d(input_channels,input_channels\/\/2,kernel_size=3,stride=2,padding=1,output_padding=1)\n        if use_bn:\n            self.instancenorm = nn.InstanceNorm2d(input_channels\/\/2)\n        self.use_bn = use_bn\n        self.activation = nn.ReLU()\n    \n    def forward(self,x):\n        x = self.conv1(x)\n        if self.use_bn:\n            x = self.instancenorm(x)\n        x = self.activation(x)\n        return x\n\n\nclass FeatureMapBlock(nn.Module):\n    def __init__(self,input_channels,output_channels):\n        super(FeatureMapBlock,self).__init__()\n        self.conv = nn.Conv2d(input_channels,output_channels,kernel_size=7,padding=3,padding_mode='reflect')\n        \n    def forward(self,x):\n        x = self.conv(x)\n        return x","d837c282":"class Generator(nn.Module):\n    def __init__(self,input_channels,output_channels,hidden_channels=64):\n        super(Generator,self).__init__()\n        self.upfeature = FeatureMapBlock(input_channels,hidden_channels)\n        self.contract1 = ContractingBlock(hidden_channels)\n        self.contract2 = ContractingBlock(hidden_channels*2)\n        res_mult = 4\n        self.res0 = ResidualBlock(hidden_channels*res_mult)\n        self.res1 = ResidualBlock(hidden_channels*res_mult)\n        self.res2 = ResidualBlock(hidden_channels*res_mult)\n        self.res3 = ResidualBlock(hidden_channels*res_mult)\n        self.res4 = ResidualBlock(hidden_channels*res_mult)\n        self.res5 = ResidualBlock(hidden_channels*res_mult)\n        self.res6 = ResidualBlock(hidden_channels*res_mult)\n        self.res7 = ResidualBlock(hidden_channels*res_mult)\n        self.res8 = ResidualBlock(hidden_channels*res_mult)\n        self.expand1 = ExpandingBlock(hidden_channels*4)\n        self.expand2 = ExpandingBlock(hidden_channels*2)\n        self.downfeature = FeatureMapBlock(hidden_channels,output_channels)\n        self.tanh = torch.nn.Tanh()\n        \n    def forward(self,x):\n        x0 = self.upfeature(x)\n        x1 = self.contract1(x0)\n        x2 = self.contract2(x1)\n        x3 = self.res0(x2)\n        x4 = self.res1(x3)\n        x5 = self.res2(x4)\n        x6 = self.res3(x5)\n        x7 = self.res4(x6)\n        x8 = self.res5(x7)\n        x9 = self.res6(x8)\n        x10 = self.res7(x9)\n        x11 = self.res8(x10)\n        x12 = self.expand1(x11)\n        x13 = self.expand2(x12)\n        xn = self.downfeature(x13)\n        return self.tanh(xn)","05d3a9e2":"class Discriminator(nn.Module):\n    def __init__(self,input_channels,hidden_channels=64):\n        super(Discriminator,self).__init__()\n        self.upfeature = FeatureMapBlock(input_channels,hidden_channels)\n        self.contract1 = ContractingBlock(hidden_channels,use_bn=False,kernel_size=4,activation='lrelu')\n        self.contract2 = ContractingBlock(hidden_channels*2,kernel_size=4,activation='lrelu')\n        self.contract3 = ContractingBlock(hidden_channels*4,kernel_size=4,activation='lrelu')\n        self.final = nn.Conv2d(hidden_channels*8,1,kernel_size=1)\n        \n    def forward(self,x):\n        x0 = self.upfeature(x)\n        x1 = self.contract1(x0)\n        x2 = self.contract2(x1)\n        x3 = self.contract3(x2)\n        xn = self.final(x3)\n        return xn","5c3053b0":"adv_criterion = nn.MSELoss()    #BCE?\nrecon_criterion = nn.L1Loss()\n\nn_epochs = 40\ndim_P=3\ndim_M=3\ndisplay_step = 300    # img\/2epoch\nbatch_size=2\nlr = 0.0002      #0.0002->0.001->0.0004->0.0001->0.0003\ndevice='cuda'","d0fb1873":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor()\n])\ndataset = ImageDataset(\"..\/input\/gan-getting-started\",transform=transform)","53f68ffa":"gen_PM = Generator(dim_P,dim_M).to(device)\ngen_MP = Generator(dim_M,dim_P).to(device)\ngen_opt = torch.optim.Adam(list(gen_PM.parameters())+list(gen_MP.parameters()),lr=lr,betas=(0.5,0.999))\n\ndisc_P = Discriminator(dim_P).to(device)\ndisc_P_opt = torch.optim.Adam(disc_P.parameters(),lr=lr,betas=(0.5,0.999))\ndisc_M = Discriminator(dim_M).to(device)\ndisc_M_opt = torch.optim.Adam(disc_M.parameters(),lr=lr,betas=(0.5,0.999))\n\ndef weights_init(m):\n    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight,0.0,0.02)\n    if isinstance(m,nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight,0.0,0.02)\n        torch.nn.init.constant_(m.bias,0)\n\npretrain = False\nif pretrain:\n    pre_dict = torch.load(\"\")\n    gen_PM.load_state_dict(pre_dict[\"gen_PM\"])\n    gen_MP.load_state_dict(pre_dict[\"gen_MP\"])\n    gen_opt.load_state_dict(pre_dict[\"gen_opt\"])\n    disc_P.load_state_dict(pre_dict[\"disc_P\"])\n    disc_P_opt.load_state_dict(pre_dict[\"disc_P_opt\"])\n    disc_M.load_state_dict(pre_dict[\"disc_M\"])\n    disc_M_opt.load_state_dict(pre_dict[\"disc_M_opt\"])\nelse:\n    gen_PM = gen_PM.apply(weights_init)\n    gen_MP = gen_MP.apply(weights_init)\n    disc_P = disc_P.apply(weights_init)\n    disc_M = disc_M.apply(weights_init)","5ef5ad90":"def disc_loss(real_x,fake_x,disc_x,adv_criterion):\n    fake_pred = disc_x(fake_x.detach())\n    real_pred = disc_x(real_x)\n    fake_loss = adv_criterion(fake_pred,torch.zeros_like(fake_pred))\n    real_loss = adv_criterion(real_pred,torch.ones_like(real_pred))\n    \n    disc_loss = (fake_loss+real_loss)\/2\n    return disc_loss","21049960":"def gen_adversarial_loss(real_x,disc_y,gen_xy,adv_criterion):\n    fake_y = gen_xy(real_x)\n    y_pred = disc_y(fake_y)\n    adversarial_loss = adv_criterion(y_pred,torch.ones_like(y_pred))\n    return adversarial_loss,fake_y","035011ea":"def identity_loss(real_x,gen_yx,identity_criterion):\n    identity_x = gen_yx(real_x)\n    identity_loss = identity_criterion(identity_x,real_x)\n    return identity_loss,identity_x","dc8ba98d":"def cycle_consistency_loss(real_x,fake_y,gen_yx,cycle_criterion):\n    cycle_x = gen_yx(fake_y)\n    cycle_loss = cycle_criterion(cycle_x,real_x)\n    return cycle_loss,cycle_x","13f4af9f":"def gen_loss_func(real_x,real_y,gen_xy,gen_yx,disc_x,disc_y,adv_criterion,identity_criterion,cycle_criterion,lambda_identity=0.1,lambda_cycle=10):\n    adversarial_loss_y,fake_y = gen_adversarial_loss(real_x,disc_y,gen_xy,adv_criterion)\n    adversarial_loss_x,fake_x = gen_adversarial_loss(real_y,disc_x,gen_yx,adv_criterion)\n    \n    identity_loss_x,identity_x = identity_loss(real_x,gen_yx,identity_criterion)\n    identity_loss_y,identity_y = identity_loss(real_y,gen_xy,identity_criterion)\n    \n    cycle_loss_x,cycle_x = cycle_consistency_loss(real_x,fake_y,gen_yx,cycle_criterion)\n    cycle_loss_y,cycle_y = cycle_consistency_loss(real_y,fake_x,gen_xy,cycle_criterion)\n    \n    gen_loss = (adversarial_loss_x+adversarial_loss_y)+lambda_cycle*(cycle_loss_x+cycle_loss_y)+lambda_identity*(identity_loss_x+identity_loss_y)\n    return gen_loss,fake_x,fake_y","84307614":"plt.rcParams[\"figure.figsize\"] = (10,10)\n\ngenloss_plot=[]\ndiscloss_plot=[]\ndef train(save_model):\n    mean_generator_loss = 0\n    mean_discriminator_loss = 0\n    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n    cur_step=0\n    \n    for epoch in range(n_epochs):\n        for real_M,real_P in tqdm(dataloader):\n            #discriminator M\n            cur_batch_size = len(real_M)\n            real_M = real_M.to(device)\n            real_P = real_P.to(device)\n            \n            disc_M_opt.zero_grad()\n            with torch.no_grad():\n                fake_M = gen_PM(real_P)\n            disc_M_loss = disc_loss(real_M,fake_M,disc_M,adv_criterion)\n            disc_M_loss.backward(retain_graph=True)\n            disc_M_opt.step()\n            \n            #discriminator P\n            disc_P_opt.zero_grad()\n            with torch.no_grad():\n                fake_P = gen_MP(real_M)\n            disc_P_loss = disc_loss(real_P,fake_P,disc_P,adv_criterion)\n            disc_P_loss.backward(retain_graph=True)\n            disc_P_opt.step()\n            \n            #generator\n            gen_opt.zero_grad()\n            gen_loss,fake_M,fake_P = gen_loss_func(\n                real_M,real_P,gen_MP,gen_PM,disc_M,disc_P,adv_criterion,recon_criterion,recon_criterion\n            )\n            gen_loss.backward()\n            gen_opt.step()\n            \n            mean_discriminator_loss += disc_M_loss.item() \/ display_step\n            mean_generator_loss += gen_loss.item() \/ display_step\n            \n            if cur_step%display_step == 0:\n                genloss_plot.append(mean_generator_loss)\n                discloss_plot.append(mean_discriminator_loss)\n                \n                print(f\"epoch {epoch}: Step {cur_step}: Generator(U-Net) loss: {mean_generator_loss}, Discriminator loss: {mean_discriminator_loss}\")\n                show_tensor_images(torch.cat([real_M[0],real_P[0]]), size=(3,256,256))\n                show_tensor_images(torch.cat([fake_P[0],fake_M[0]]), size=(3,256,256))\n                mean_generator_loss = 0\n                mean_discriminator_loss = 0\n                ##save model##\n                if save_model:\n                    torch.save({\n                        'gen_PM':gen_PM.state_dict(),\n                        'gen_MP':gen_MP.state_dict(),\n                        'gen_opt':gen_opt.state_dict(),\n                        'disc_P':disc_P.state_dict(),\n                        'disc_P_opt':disc_P_opt.state_dict(),\n                        'disc_M':disc_M.state_dict(),\n                        'disc_M_opt':disc_M_opt.state_dict()\n                    },f\"cycleGAN_{cur_step}.pth\")\n                ##save model##\n            cur_step += 1","37ba5846":"train(False)","267d361b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nplt.figure(figsize=(15,6))\n\ndf = pd.DataFrame({\"generator_loss\":genloss_plot,\n                   \"discriminator_loss\":discloss_plot})\nwith sns.axes_style(\"darkgrid\"):\n    sns.lineplot(data=df,palette='flare')","e6785342":"os.makedirs('..\/images')","9e264aa2":"photo_imgs = sorted(glob.glob(os.path.join(\"..\/input\/gan-getting-started\",\"photo_jpg\")+\"\/*.*\"))\ni=0\ngen_PM.eval()\nfor i in tqdm(range(len(photo_imgs))):\n    photo_img = transform(Image.open(photo_imgs[i]))\n    photo_img = photo_img.detach().cuda().view(-1, *(3,256,256))\n    predict = gen_PM(photo_img).detach()\n    predict = (predict.cpu() + 1) \/ 2\n    predict = make_grid(predict[:1])\n    predict = predict.permute(1, 2, 0).squeeze().numpy()\n    predict  = (255 * predict).astype(np.uint8)\n    \n    im = PIL.Image.fromarray(predict)\n    im.save(\"..\/images\/\" + str(i) + \".jpg\")\n    i+=1","a861b7f4":"import shutil\nshutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","f79b2024":"#### identity loss","8303524a":"## PatchGAN Discriminator","f0759240":"## submission","9872620c":"#### cycleGAN generator","b7f36938":"#### residual blocks","6661d29e":"## Generator Loss","171d08bc":"#### contracting and expanding blocks","0d0661ae":"#### cycle consistency loss","ff5c20cd":"#### Training parameters","b6841fce":"#### adversarial loss","284444c8":"## Training","479e3cc5":"### generator loss (combine together)","e26220d3":"## Discriminator Loss","337ad769":"## Cycle GAN: Generator"}}