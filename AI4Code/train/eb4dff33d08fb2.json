{"cell_type":{"bfdcc7ae":"code","b993345b":"code","97b3d3cb":"code","5df74825":"code","0d9c72b3":"code","4b62b44c":"code","afca965a":"code","f713a721":"code","42afa94c":"code","866694ca":"code","ae9b645d":"code","0a9a539e":"code","c2a94853":"code","614321b9":"code","fdf7b4c2":"code","c5965cbc":"code","7a62e27d":"code","2f21fc4b":"code","e1297bf4":"code","1cc23d0d":"code","e39dbfa9":"code","efe46413":"code","8e7ab23a":"code","6f89782e":"code","e14b30bf":"code","7f13aec1":"code","738ec193":"code","af8b1d18":"code","9648af1c":"code","e78aa0b1":"code","a0bc5259":"code","c74189bb":"code","6c231191":"code","f0a4f86d":"code","1d5e3001":"code","e57ebc4f":"code","06581ee5":"code","435de17d":"code","b9a96b71":"code","a5869a21":"code","d813a7a6":"code","f457d09a":"code","c25e6774":"code","0740ccf0":"code","dd9cb7c1":"code","a0712cc3":"code","c4f1d456":"code","e642e9ee":"code","ee06b4d7":"code","6a3d0f70":"code","2f74f3d9":"code","42107361":"code","45cba022":"code","047511dc":"code","454384eb":"code","2a87a4e0":"code","8cb2c465":"code","ffab2af4":"code","394d72a4":"code","52e6d9f6":"code","49bf57cc":"code","b269d525":"code","e4ed0057":"code","315f8a62":"code","922721db":"code","89edb181":"code","76bc1a91":"code","09be6a1e":"code","7f42a396":"code","6cb9cdb3":"code","8829b41d":"code","ce49bcda":"code","e154b2aa":"code","5f3ce8b9":"code","02c404ca":"code","b181e0d0":"code","becbeb92":"code","7d5e2d06":"code","f475cb30":"code","b474827e":"code","b110305d":"markdown","9d63c516":"markdown","f619aa8a":"markdown","7cf1e9c8":"markdown","05434646":"markdown","244bd07a":"markdown","9bc12f12":"markdown","89ab2fce":"markdown","8189959e":"markdown","8fd1cc06":"markdown","ec968887":"markdown","4ee31d22":"markdown","0120d97a":"markdown"},"source":{"bfdcc7ae":"import pandas as pd\nimport os\nimport numpy as np","b993345b":"diamond = pd.read_csv('\/kaggle\/input\/diamonds\/diamonds.csv')\ndiamond.head()\n# can drop first column (just index)","97b3d3cb":"diamond.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)","5df74825":"diamond.head()","0d9c72b3":"diamond.isnull().sum()\n# no null values","4b62b44c":"# looks like I am going to make a regression model to find the price of a diamond\n\n# numeric data:\n#   price\n#   carat\n#   x-length\n#   y-width\n#   z-depth\n#   depth\n#   table width\n\n\n# categorical data:\n#   cut\n#   color\n#   clarity\n","afca965a":"diamond.info()\n\n# there is no null-values in the data!!","f713a721":"diamond.describe()\n\n#only for numeric","42afa94c":"# lets look at the value counts for the categorical data attributes\n\ndiamond.cut.value_counts()\/len(diamond.cut)","866694ca":"diamond.color.value_counts()\/ len(diamond.cut)","ae9b645d":"diamond.clarity.value_counts()\/len(diamond.cut)","0a9a539e":"%matplotlib inline\nimport matplotlib.pyplot as plt\ndiamond.hist(bins = 50, figsize = (20,15))\nplt.show()","c2a94853":"# x and carat aren't that close to a normal distribution\n# everything else ins't that bad, just needs to be scaled\n# table might be a little tail heavy but just barely\n\n# interesting that price isn't normally distributed, has a very long tail\n\n","614321b9":"# don't know if I should use train_test_split or do stratefied\n# have to see if dataset is large enough\nlen(diamond)\n\n# I think this is large enought","fdf7b4c2":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(diamond, test_size = 0.2, random_state = 42)","c5965cbc":"train.isnull().sum()","7a62e27d":"test.isnull().sum()","2f21fc4b":"diamond_corr = diamond.corr()\ndiamond_corr['price'].sort_values(ascending=False)\n\n# can see that table and depth are pretty weakly correlated\n# want to check for categorical data\n","e1297bf4":"diamond.plot(kind = 'scatter', x = 'carat', y='price')","1cc23d0d":"# need to transform categorical data first in order to explore it","e39dbfa9":"# lets see if any data combinations will give us anything valueable\n\ndiamond['table_depth'] = diamond.table\/diamond.depth\ndiamond['volume'] = diamond.x * diamond.y * diamond.z\ndiamond['density'] = diamond.carat \/ diamond.volume\n","efe46413":"diamond_corr_new = diamond.corr()\ndiamond_corr_new['price'].sort_values(ascending = False)\n\n# volume seems to have a high correlation!\n","8e7ab23a":"# start of with copying a clean training set\n\ndiamond = train.drop('price', axis = 1)\ndiamond_labels = train['price'].copy()","6f89782e":"diamond.head()\ndiamond_labels.head()\n","e14b30bf":"# the categorical data I have is very clearnly ordinal\n# cut, color, and clarity, all go from worst to best ","7f13aec1":"from sklearn.preprocessing import OrdinalEncoder","738ec193":"diamond_cat = diamond[['cut', 'color', 'clarity']]\ndiamond_cat.head(10)","af8b1d18":"ordinal_encoder = OrdinalEncoder(categories = [['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'], \n                                               ['J', 'I', 'H', 'G', 'F', 'E', 'D'],\n                                              ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']])\ndiamond_cat_encoded = ordinal_encoder.fit_transform(diamond_cat)\n","9648af1c":"diamond_cat_encoded[:10]\n\n# I encoded the ordinal categorical data!!","e78aa0b1":"# I want to look at the encoded data visually and correlations\n\ndiamond_cat_df = pd.DataFrame(data=diamond_cat_encoded, columns = ['cut', 'color', 'clarity'])\ndiamond_cat_df.head()","a0bc5259":"diamond_labels_df = pd.DataFrame(data=diamond_labels, columns = ['price'])\ndiamond_labels_df = diamond_labels_df.reset_index()\ndiamond_labels_df.drop('index', axis=1, inplace=True)\ndiamond_labels_df.head()","c74189bb":"diamond_cat_explore = diamond_cat_df.merge(diamond_labels_df, how = 'left', left_index = True, right_index = True)\ndiamond_cat_explore.head()","6c231191":"diamond_cat_explore.corr()['price']\n# interesting\n","f0a4f86d":"# make a tranformer that ads the volume attribute\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass VolumeAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, hyper = None):\n        self.hyper = hyper\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        volume = X['x'] * X['y'] * X['z']\n        return np.c_[X, volume]\n    ","1d5e3001":"add_vol = VolumeAdder()\ndiamond_vol = add_vol.transform(diamond)\ndiamond_vol","e57ebc4f":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer","06581ee5":"diamond = train.drop('price', axis = 1)\n","435de17d":"diamond_num = diamond.drop(['cut', 'color', 'clarity'], axis =1 , inplace = False)\ndiamond_cat = diamond.drop(list(diamond_num), axis = 1, inplace = False)","b9a96b71":"# start of by making pipeline for numerican data\n\nnum_pipeline = Pipeline([\n    ('vol_adder', VolumeAdder()),\n    ('scaler', StandardScaler())\n])","a5869a21":"num_labels = list(diamond_num)\nnum_labels.append('volume')\nnum_labels","d813a7a6":"diamond_num_prep = num_pipeline.fit_transform(diamond_num)\ndiamond_num_prep_df = pd.DataFrame(diamond_num_prep, columns = num_labels)\ndiamond_num_prep_df","f457d09a":"# full pipeline\n\nnum_attribs = list(diamond_num)\ncat_attribs = list(diamond_cat)\n\nfull_pipeline = ColumnTransformer([\n    ('num', num_pipeline, num_attribs),\n    ('cat', ordinal_encoder, cat_attribs)\n])","c25e6774":"full_labels = num_labels + ['cut', 'color', 'clarity']","0740ccf0":"diamond_prep = full_pipeline.fit_transform(diamond)\ndiamond_prep","dd9cb7c1":"\ndiamond_prep_df = pd.DataFrame(diamond_prep, columns = full_labels )","a0712cc3":"diamond_prep_df","c4f1d456":"from sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR","e642e9ee":"from scipy import stats\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score","ee06b4d7":"# time to try out a bunch of different models and see what we get","6a3d0f70":"# linear regression","2f74f3d9":"lin_reg = LinearRegression()\nlin_reg.fit(diamond_prep, diamond_labels)\nlin_pred = lin_reg.predict(diamond_prep)\nlin_rmse = np.sqrt(mean_squared_error(lin_pred, diamond_labels))\nlin_rmse","42107361":"# cross validation score","45cba022":"lin_scores = cross_val_score(lin_reg, diamond_prep, diamond_labels, scoring = 'neg_mean_squared_error', cv=5)\nlin_rmse = np.sqrt(-lin_scores)\nlin_rmse.mean()","047511dc":"# lets make a function that lets you put in the algorim and spits out cv_scores, mean, std","454384eb":"def get_scores(algorithm, data_prep, data_labels, n):\n    scores = cross_val_score(algorithm, data_prep, data_labels,\n                             scoring = 'neg_mean_squared_error',cv = n )\n    rmse_scores = np.sqrt(-scores)\n    print('Scores:', rmse_scores)\n    print('Mean:', rmse_scores.mean())\n    print('Std:', rmse_scores.std())","2a87a4e0":"get_scores(lin_reg, diamond_prep, diamond_labels, 5)","8cb2c465":"# logistic regression takes toooooo long!","ffab2af4":"#  Decistion Tree","394d72a4":"tree_reg = DecisionTreeRegressor().fit(diamond_prep, diamond_labels)\nget_scores(tree_reg, diamond_prep, diamond_labels, 5)","52e6d9f6":"# Random Forest","49bf57cc":"forest_reg = RandomForestRegressor(random_state=42).fit(diamond_prep, diamond_labels)\nget_scores(forest_reg, diamond_prep, diamond_labels, 5)","b269d525":"# check training set vs validation sets for random forest (over or underfitting)","e4ed0057":"forest_rmse = np.sqrt(mean_squared_error(forest_reg.predict(diamond_prep),diamond_labels))\nforest_rmse","315f8a62":"# check rmse of decision tree\ntree_rmse = np.sqrt(mean_squared_error(tree_reg.predict(diamond_prep),diamond_labels))\ntree_rmse\n","922721db":"# Support Vector Machine\n\nsvr_reg = SVR().fit(diamond_prep, diamond_labels)\n","89edb181":"svr_rmse = np.sqrt(mean_squared_error(svr_reg.predict(diamond_prep),diamond_labels))\nsvr_rmse","76bc1a91":"# randomized search\n# look at current hyperparameters\n\nforest_reg.get_params()","09be6a1e":"random_grid = {\n    'n_estimators': stats.randint(low=1, high = 200),\n    'max_features': stats.randint(low=1, high = 8),\n    'bootstrap': [True, False]\n}","7f42a396":"forest_rand_search = RandomizedSearchCV(forest_reg, random_grid, n_iter = 5, cv=5, \n                                        scoring = 'neg_mean_squared_error', random_state = 42)\nforest_rand_search.fit(diamond_prep, diamond_labels)","6cb9cdb3":"forest_rand_search.best_params_","8829b41d":"cv_res = forest_rand_search.cv_results_\nfor mean_score, params in zip(cv_res['mean_test_score'], cv_res['params']):\n    print(np.sqrt(-mean_score), params)","ce49bcda":"# now time to get feature importances\n\nfeature_importances = forest_rand_search.best_estimator_.feature_importances_\nfeature_importances","e154b2aa":"extra_attribs = ['volume','cut', 'color', 'clarity']\nattribs = num_attribs + extra_attribs\nsorted(zip(feature_importances,attribs), reverse=True)","5f3ce8b9":"# dropping the variables that are less than a tenth\n\ndiamond_prep_new = diamond_prep_df.drop(['depth','cut','table'], axis = 1, inplace = False)\ndiamond_prep_new\n\nforest_reg_new = RandomForestRegressor(bootstrap = True, max_features = 5, n_estimators = 100, random_state = 42)\nforest_reg_new.fit(diamond_prep_new, diamond_labels)","02c404ca":"forest_new_rmse = np.sqrt(mean_squared_error(forest_reg_new.predict(diamond_prep_new),diamond_labels))\nforest_new_rmse","b181e0d0":"get_scores(forest_reg_new, diamond_prep_new, diamond_labels, 5)","becbeb92":"final_model = forest_rand_search.best_estimator_\n\nX_test = test.drop('price', axis = 1)\nY_test = test['price'].copy()\n\nX_test_prep = full_pipeline.transform(X_test)\n","7d5e2d06":"final_predictions = final_model.predict(X_test_prep)\nfinal_rmse = np.sqrt(mean_squared_error(final_predictions,Y_test))\nfinal_rmse","f475cb30":"# see confidence interval\n\nsquared_errors = (final_predictions - Y_test)**2\nnp.sqrt(stats.t.interval(0.95, len(squared_errors)-1,\n                        loc = squared_errors.mean(),\n                        scale = stats.sem(squared_errors)))\n","b474827e":"plt.scatter(final_predictions, Y_test)\n\n# here we can see the graph of the actual vs predicted","b110305d":"## 2: Data Description (from kaggle)","9d63c516":"## 7: Categorical Attributes","f619aa8a":"## 8: Transformations","7cf1e9c8":"## 3: Quick Look at Data","05434646":"## 10: Model Selection \/ Training","244bd07a":"## 1: Upload Data","9bc12f12":"## 6: Data Cleaning \/ Processing","89ab2fce":"price price in US dollars (326--18,823)\n\ncarat weight of the diamond (0.2--5.01)\n\ncut quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n\ncolor diamond colour, from J (worst) to D (best)\n\nclarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n\nx length in mm (0--10.74)\n\ny width in mm (0--58.9)\n\nz depth in mm (0--31.8)\n\ndepth total depth percentage = z \/ mean(x, y) = 2 * z \/ (x + y) (43--79)\n\ntable width of top of diamond relative to widest point (43--95)","8189959e":"## 9: Scaling \/ Transformation Pipeline","8fd1cc06":"## 5: Further Data Exploration \/ Visualization","ec968887":"## 4: Create Training and Test Sets","4ee31d22":"## 12: Prediction Time","0120d97a":"## 11: Model Tuning"}}