{"cell_type":{"4448cd47":"code","37eef4fd":"code","ff253a22":"code","59963e01":"code","ad73cb42":"code","dd679deb":"code","9f67f96d":"code","430ce247":"code","75d2f966":"code","fafdbc0c":"code","61135951":"code","96691270":"code","e832ef36":"code","bd933bf1":"code","3ec98997":"code","a2b18e95":"code","a489c6d5":"code","d516cd0a":"code","2897d8da":"code","b42e8ae9":"code","29368e70":"code","441bfe46":"code","744baa2c":"code","a8cf5cd4":"code","549dceb1":"code","31cd732d":"code","6321d221":"code","d9860c60":"code","7c25e074":"markdown","12278489":"markdown"},"source":{"4448cd47":"import numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport matplotlib.image as mpimg\nimport cv2\nimport seaborn as sn\nimport torch\nfrom sklearn.preprocessing import LabelEncoder","37eef4fd":"directory = '..\/input\/landmark-recognition-2020\/'\ntrain_dir = '..\/input\/landmark-recognition-2020\/train\/*\/*\/*\/*'\ntest_dir = '..\/input\/landmark-recognition-2020\/test\/*\/*\/*\/*'\noutput_dir ='..\/output\/kaggle\/working\/'\nimage_dir_train='..\/input\/landmark-recognition-2020\/train\/'\nimage_dir_test='..\/input\/landmark-recognition-2020\/test\/'\nos.listdir(directory)","ff253a22":"test = pd.read_csv(os.path.join(directory,'sample_submission.csv'))\ntest['image_']=test.id.str[0]+\"\/\"+test.id.str[1]+\"\/\"+test.id.str[2]+\"\/\"+test.id+\".jpg\"\ntest.head()","59963e01":"# train_images = glob.glob(train_dir)\n# test_images = glob.glob(test_dir)\n# print('Training images : ',len(train_images))\n# print('Testing images : ',len(test_images))","ad73cb42":"# assert test.shape[0]==len(test_images)","dd679deb":"train = pd.read_csv(os.path.join(directory,'train.csv'))\ntrain[\"image_\"] = train.id.str[0]+\"\/\"+train.id.str[1]+\"\/\"+train.id.str[2]+\"\/\"+train.id+\".jpg\"\ntrain[\"target_\"] = train.landmark_id.astype(str)\ntrain.head()","9f67f96d":"Threshold_count = 150\n\nvalid_landmark_df = pd.DataFrame(train['landmark_id'].value_counts()).reset_index()\nvalid_landmark_df.columns =  ['landmark_id', 'count_']\nlist_valid_landmarks = list(valid_landmark_df[valid_landmark_df.count_ >= Threshold_count]['landmark_id'].unique())\n\n#or\n# y = train.landmark_id.values\n# valid_landmark_count = Counter(y).most_common(1000)\n# print(valid_landmark_count[:10])\n# list_valid_landmarks = [landmark[0] for landmark in valid_landmark_count]","430ce247":"print(train.shape)\ntrain= train[train.landmark_id.isin(list_valid_landmarks)]\ntrain.shape","75d2f966":"# for img in range(2):\n#     image = mpimg.imread(train_images[img])\n#     print(image.shape)\n#     plt.imshow(image)\n#     plt.axis('Off')\n#     plt.show()","fafdbc0c":"# for img in range(2):\n#     image = cv2.imread(test_images[img])\n#     print(image.shape)\n#     plt.imshow(image)\n#     plt.axis('Off')\n#     plt.show()","61135951":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom torchvision.transforms import transforms\n\nTRAIN_BS = 32\nTEST_BS = 32","96691270":"# [ s for s in train_images if '.jpg' not in s]","e832ef36":"# [ s for s in test_images if '.jpg' not in s]","bd933bf1":"class createDataset(Dataset):\n    def __init__(self, transform, image_dir, df, train_type = True):        \n        self.df = df \n        self.image_dir = image_dir    \n        self.transform = transform\n        self.train_type=train_type\n        \n    def __len__(self):\n        return self.df.shape[0] \n    \n    def __getitem__(self,idx):\n        image_id = self.df.iloc[idx].id\n        image_name = f\"{self.image_dir}\/{image_id[0]}\/{image_id[1]}\/{image_id[2]}\/{image_id}.jpg\"\n        self.image = Image.open(image_name).convert('RGB')               \n        self.image = self.transform(self.image)\n#         print(self.image)\n        \n#         self.Y = self.df.iloc[idx].landmark_id\n        self.Y = torch.Tensor([self.df.iloc[idx].landmark_id]).type(torch.LongTensor)        \n        if(self.train_type):\n            return {'image':self.image, \n                    'label':self.df.iloc[idx].landmark_id}\n        else:\n            return {'image':self.image}         ","3ec98997":"# idx=10\n\n# # test_data = createDataset(transform = transformations , df = test , image_dir = image_dir_test , train = False )\n\n# image_id = train.iloc[idx].id\n# image_name = f\"{image_dir_train}\/{image_id[0]}\/{image_id[1]}\/{image_id[2]}\/{image_id}.jpg\"\n# image = Image.open(image_name)                 \n# # image = image)\n# print(image)\n\n# #         Y = self.df.iloc[idx].landmark_id\n# Y = torch.Tensor([train.iloc[idx].landmark_id]).type(torch.LongTensor)\n# image","a2b18e95":"mean = (0.485, 0.456, 0.406)\nstd =  (0.229,0.225,0.224)\ntransformations = transforms.Compose([ transforms.Resize((64,64)),\n#                                     transforms.Resize((128,128),interpolation=Image.NEAREST),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean,std)\n                                     ]\n                                    )                               \n","a489c6d5":"label_encoder = LabelEncoder()\nle = label_encoder.fit(train.landmark_id.values)\nunique_classes = len(le.classes_)\nprint('Total number of classes ', unique_classes)","d516cd0a":"train_data = createDataset(transform = transformations , df = train , image_dir = image_dir_train , train_type = True )\ntrain_loader = DataLoader(dataset = train_data, batch_size = TRAIN_BS, shuffle = True)","2897d8da":"test_data = createDataset(transform = transformations , df = test , image_dir = image_dir_test , train_type = False )\ntest_loader = DataLoader(dataset = test_data, batch_size = TEST_BS)","b42e8ae9":"!pip install efficientnet_pytorch\n# import efficientnet_pytorch\n","29368e70":"# class EfficientNetEncoderHead(nn.Module):\n#     def __init__(self, depth, num_classes):\n#         super(EfficientNetEncoderHead, self).__init__()\n#         self.depth = depth\n#         self.base = efficientnet_pytorch.EfficientNet.from_pretrained(f'efficientnet-b{self.depth}')\n#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n#         self.output_filter = self.base._fc.in_features\n#         self.classifier = nn.Linear(self.output_filter, num_classes)\n#     def forward(self, x):\n#         x = self.base.extract_features(x)\n#         x = self.avg_pool(x).squeeze(-1).squeeze(-1)\n#         x = self.classifier(x)\n#         return x","441bfe46":"# model = EfficientNetEncoderHead(depth=0, num_classes=unique_classes)\n# model.cuda()","744baa2c":"import torchvision\nimport torch.nn as nn\nimport torch\n# model = torchvision.models.resnet50(pretrained=True)\n\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_name('efficientnet-b1')\nprint(model)","a8cf5cd4":"from tqdm import tqdm\nfor param in model.parameters():\n    param.requires_grad = False\n    \n\nmodel._fc = nn.Linear(model._fc.in_features, unique_classes)\nmodel.cuda()","549dceb1":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam([param for param in model.parameters() if param.requires_grad], lr=0.001)","31cd732d":"n_epochs = 1\nloss_list = []\nactivation = nn.Softmax(dim=1)\nfor epochs in range(n_epochs):    \n    for i, data_x_y in enumerate(tqdm(train_loader)):\n#         model.train()\n        x= data_x_y['image']\n        y=data_x_y['label']        \n        optimizer.zero_grad()\n        yhat =  model(x.cuda())\n        loss = criterion(yhat, y.cuda())\n        loss.backward()\n        optimizer.step()\n        loss_list.append(loss.item())\n    print('Epoch ', epochs, 'loss : ',loss.item())","6321d221":"for x_test, y_test in test_loader:        \n    x_test = x_test.to('cuda')\n    y_test=y_test.to('cuda')\n\n    model.eval()\n    z = model(x_test)\n    score, label = torch.max(z,1)\n    correct += (label == y_test).sum().item()\n    test_list.append(y_test)\n    lables_list(label)\n    scores_list.append(score)        \naccuracy = accuracy\/ n_test","d9860c60":"plt.plot(loss_list)\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()","7c25e074":"# **Visualize train and test images**","12278489":"### create DataSet"}}