{"cell_type":{"6da60542":"code","e2f835cc":"code","aba53c50":"code","7d2f2977":"code","612afb5c":"code","22f67293":"code","48030a9f":"code","e5f752cd":"code","0252d737":"code","325dcc70":"code","d8d8c3f2":"code","02d746e5":"code","3c895169":"code","e3a9b541":"code","a0830349":"code","b56203a7":"code","addff078":"code","e802737c":"code","9a848c5c":"code","485ae686":"code","74c61e1c":"code","b693d5e7":"code","54ff3e4b":"code","4f904354":"code","00ae787c":"code","5b125902":"code","c112e011":"code","ef649eb3":"code","10d888dc":"code","21f04883":"code","23410699":"code","9241bfc9":"code","5e6521f5":"code","3579f624":"code","a1a62890":"code","17327920":"code","70f8c633":"code","0fa4b7a3":"code","b05afc60":"code","3155490f":"code","f5a61293":"code","3b52b00b":"code","e88342c2":"code","b50ee9ff":"code","3cb63b09":"code","962f7475":"code","f7a89dc2":"code","eb3df588":"code","8bf52ced":"code","55ad8388":"code","9e4e8d83":"code","85c32125":"code","87761110":"code","bd0633e8":"code","f30c45e4":"code","c8c1fb54":"code","770c1e6c":"code","9b2050a4":"code","e0dc8375":"code","f27981fb":"code","1458bf01":"code","74193e8c":"code","40b8c0f4":"code","28a990f4":"code","c50c5e53":"code","9d6cac23":"code","ec935dfa":"code","6b4a9f97":"code","b270163b":"code","6ed25d5f":"code","5ecf6fb1":"code","21b0c7f5":"code","85282d4c":"code","28e0eabe":"code","8b445c7a":"code","bc57289f":"code","fab10681":"code","31fdc0ba":"code","6793740f":"code","3488816e":"code","332f585e":"markdown","107f0ccc":"markdown","e07dfbd9":"markdown","68195c23":"markdown","b4ecb6ed":"markdown","757684a2":"markdown","1700fa8c":"markdown","77f0ada1":"markdown","3e69ffa6":"markdown","260cd80e":"markdown","87c5e3da":"markdown","2532a503":"markdown","9889a3ab":"markdown","25c833af":"markdown","92f5b3e5":"markdown","8d5c9ef4":"markdown","106c0977":"markdown","2f9ad6e0":"markdown","de8f49a3":"markdown","dd0eb79c":"markdown","8df4f7b0":"markdown","8f420ff9":"markdown","73d8462c":"markdown","6b62a1c7":"markdown","672865e4":"markdown","bee23ab4":"markdown","5e230108":"markdown","011e6f65":"markdown","a3f7a306":"markdown","30653e56":"markdown","2b803dc7":"markdown","108a4ec0":"markdown","02bcf5f8":"markdown","2dcca20a":"markdown","28c8f965":"markdown","0fe90a4b":"markdown","13fcf49f":"markdown","e565a6cf":"markdown","b4f09adf":"markdown","55c4d363":"markdown","db98979b":"markdown","cf9dbbef":"markdown","a31c7a82":"markdown","efcd49bf":"markdown","dbb8ea0c":"markdown","ebec5e3a":"markdown","e3ca5a91":"markdown","21c8bd5b":"markdown","03dce6fc":"markdown","fe00565a":"markdown","a1e6176d":"markdown","9ed423d3":"markdown","3c507eb9":"markdown","7f95ec44":"markdown","fc38c4db":"markdown","72e2b978":"markdown","4e3b886b":"markdown","1e378e5f":"markdown","10b7d917":"markdown","1a118165":"markdown","a7b703e0":"markdown"},"source":{"6da60542":"!pip install pyspark","e2f835cc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aba53c50":"import warnings\nwarnings.filterwarnings(\"ignore\")","7d2f2977":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\")\n\nfrom scipy import stats\n\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\nfrom pyspark.ml.feature import OneHotEncoder, VectorAssembler, VectorIndexer, StringIndexer, IndexToString\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator \nfrom pyspark.ml.regression import GBTRegressor","612afb5c":"conf = SparkConf().set(\"spark.ui.showConsoleProgress\", \"false\")\nsc = SparkContext(appName=\"Pyspark, SQL and Machine Learning for salary prediction\", conf=conf)\nsc","22f67293":"spark = SparkSession(sc)\nspark.sparkContext.setLogLevel(\"ERROR\")","48030a9f":"sqlContext = SQLContext(spark.sparkContext)\nsqlContext","e5f752cd":"path = '\/kaggle\/input\/salarypredictions\/'\ndf_path = path + 'train_dataset.csv'\ndf1_path = path + 'train_salaries.csv'","0252d737":"df1 = spark.read.csv(df_path, header=True).cache()","325dcc70":"df2 = spark.read.csv(df1_path, header=True).cache()","d8d8c3f2":"df1.show(5)","02d746e5":"df2.show(5)","3c895169":"df1.printSchema()","e3a9b541":"df2.printSchema()","a0830349":"df1 = df1.withColumn(\"yearsExperience\",df1.yearsExperience.cast('int'))\ndf1 = df1.withColumn(\"milesFromMetropolis\",df1.milesFromMetropolis.cast('int'))","b56203a7":"df2 = df2.withColumn(\"salary\", df2.salary.cast('int'))","addff078":"df1.printSchema()","e802737c":"df2.printSchema()","9a848c5c":"df2 = df2.withColumnRenamed('jobId', 'job_id')","485ae686":"df = df1.join(df2, df1.jobId==df2.job_id)","74c61e1c":"df = df.drop('job_id')","b693d5e7":"df.show(5)","54ff3e4b":"df_dup=df.groupBy(\"yearsExperience\", \"milesFromMetropolis\",\"companyId\",\"jobType\", \"degree\", \"major\", \"industry\", \"jobId\").count().filter(\"count > 1\")\ndf_dup.drop('count').show()","4f904354":"df.show(10)","00ae787c":"print('Number of missing values for jobType: {}'.format(df.filter(df.jobType=='NONE').count()))\nprint('Number of missing values for degree: {}'.format(df.filter(df.degree=='NONE').count()))\nprint('Number of missing values for major: {}'.format(df.filter(df.major=='NONE').count()))\nprint('Number of missing values for industry: {}'.format(df.filter(df.industry=='NONE').count()))","5b125902":"df.describe(['yearsExperience', 'milesFromMetropolis','salary']).show()","c112e011":"df.createOrReplaceTempView(\"data\")","ef649eb3":"spark.sql('''\n    SELECT salary, jobtype, industry\n    FROM data\n    WHERE salary == (SELECT MAX(salary) FROM data)''').show()","10d888dc":"df_q2 = spark.sql('''\n          SELECT salary, jobtype, industry, RANK() OVER(PARTITION BY industry ORDER BY salary DESC) Rank\n          FROM data\n          ORDER BY salary DESC\n          LIMIT 20''')\ndf_q2.show(20)","21f04883":"spark.sql('''\n          SELECT salary, jobtype, industry, RANK() OVER(PARTITION BY industry ORDER BY salary ASC) Rank\n          FROM data\n          ORDER BY salary ASC''').show()","23410699":"df = df.where(\"salary != 0\")","9241bfc9":"df.createOrReplaceTempView(\"data\")","5e6521f5":"df_q3 = spark.sql('''\n          SELECT salary, jobtype, industry, RANK() OVER(PARTITION BY industry ORDER BY salary ASC) Rank\n          FROM data\n          ORDER BY salary ASC''')\ndf_q3.show()","3579f624":"df_q4 = spark.sql('''\n          SELECT industry, AVG(salary) as average_salary\n          FROM data\n          GROUP BY industry\n          ORDER BY average_salary DESC''')\ndf_q4.show(10)","a1a62890":"df_p = df_q4.toPandas()\nplt.figure(figsize=(6,3.5))\nsns.barplot(y='industry', x = 'average_salary', data=df_p, palette='viridis')\nplt.title('Average salary by Industry')\nplt.xlabel('Salary (k$)')\nplt.show()","17327920":"df_q5 = spark.sql('''\n    SELECT salary, jobtype, industry, yearsExperience\n    FROM data\n    ORDER BY salary DESC\n    ''') \ndf_q5.show()","70f8c633":"df_q5.groupBy('jobtype').count().show()","0fa4b7a3":"job_list = ['CEO','CFO','CTO','VICE_PRESIDENT','MANAGER','SENIOR','JUNIOR','JANITOR']","b05afc60":"df_p = df_q5.toPandas()","3155490f":"slope_list = []  #to save the slopes of the regression lines\nintercept_list = [] #to save the intercepts of the regression lines\n\nfor job in job_list:\n    df_x = df_p.loc[df_p['jobtype']==job]\n    slope, intercept, r_value, p_value, std_err = stats.linregress(df_x['yearsExperience'],df_x['salary'])\n    slope_list.append(slope)\n    intercept_list.append(intercept)\n    plt.figure(figsize=(8,2))\n    sns.regplot(x='yearsExperience', y = 'salary', data=df_x, color='#0d98ba', line_kws={'label':\"y={0:.1f}x+{1:.1f}\".format(slope,intercept)})\n    plt.legend()\n    plt.title('Salary by years of experience for ' + job)\n    plt.show()","f5a61293":"X = np.array([0, 5, 10, 15, 20, 25])\nplt.figure(figsize=(6.8,3))\nfor i in range(8):\n    plt.plot(X, slope_list[i]*X+intercept_list[i],label=job_list[i], marker='.')\n    plt.legend(bbox_to_anchor=(1, 1.03), ncol=1, fancybox=True, shadow=True)\nplt.ylabel('Salary (k$)')\nplt.xlabel('Years of Experience')\nplt.title('Salary vs years of experience (Linear Regression)')\nplt.show()","3b52b00b":"df_q6 = spark.sql('''\n                  SELECT degree, salary, jobtype\n                  FROM data\n                  ORDER BY salary\n                  ''')\ndf_q6.show(5)","e88342c2":"df_q6 = df_q6.replace('NONE',None)","b50ee9ff":"df_q6.show(5)","3cb63b09":"df_q6 = df_q6.na.drop()","962f7475":"df_q6.show(5)","f7a89dc2":"df_q6.groupBy('degree').count().show()","eb3df588":"degrees_list = ['HIGH_SCHOOL','BACHELORS','DOCTORAL','MASTERS']","8bf52ced":"df_p = df_q6.toPandas()","55ad8388":"for job in job_list:\n  df_x = df_p.loc[df_p['jobtype']==job]\n  plt.figure(figsize=(6,3))\n  sns.boxplot(x='degree', y = 'salary', data=df_x, palette='flare')\n  plt.title('Salary of ' + job + ' by degree type')\n  plt.show()","9e4e8d83":"plt.figure(figsize=(6,5))\nsns.barplot(x='degree', y = 'salary', data=df_p, hue='jobtype', palette='flare')\nplt.legend(loc='lower right', title='Job')\nplt.ylabel('Salary (k$)')\nplt.title('Salary of degree by jobtype')\nplt.show()","85c32125":"df_q7 = spark.sql('''\n                  SELECT jobtype, degree, major, salary\n                  FROM data\n                  ORDER BY salary''')\ndf_q7.show(5)","87761110":"df_q7 = df_q7.replace('NONE',None)\ndf_q7 = df_q7.na.drop()","bd0633e8":"df_q7.groupBy('major').count().show()","f30c45e4":"df_q7.groupBy('jobtype').count().show()","c8c1fb54":"job_list = ['CEO','CFO','CTO','VICE_PRESIDENT','MANAGER','SENIOR','JUNIOR']","770c1e6c":"df_p = df_q7.toPandas()","9b2050a4":"for job in job_list:\n  df_x = df_p.loc[df_p['jobtype']==job]\n  plt.figure(figsize=(10,3))\n  sns.boxplot(x='major', y = 'salary', data=df_x, palette='mako_r')\n  plt.title('Salary of ' + job + ' by major')\n  plt.show()","e0dc8375":"plt.figure(figsize=(10,5))\nsns.barplot(x='jobtype', y = 'salary', data=df_p, hue='major', palette='mako_r')\nplt.legend(loc='center right', title='Major')\nplt.ylabel('Salary (k$)')\nplt.title('Salary of jobtypes by major')\nplt.show()","f27981fb":"df.show(1)","1458bf01":"df_encoded = df.alias('df_encoded')\nid(df_encoded) == id(df)  # False","74193e8c":"df_encoded = df_encoded.drop('jobId')","40b8c0f4":"cols = df_encoded.columns","28a990f4":"salary_df = df_encoded.select('salary').toPandas()","c50c5e53":"fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,4),gridspec_kw={\"height_ratios\": (.2, .8)})\nax[0].set_title('Salary distribution',fontsize=18)\nsns.boxplot(x='salary', data=salary_df, ax=ax[0], color='#0d98ba')\nax[0].set(yticks=[])\nsns.histplot(x='salary', data=salary_df, ax=ax[1], color='#0d98ba')\nplt.axvline(salary_df['salary'].mean(), color='darkgreen', linewidth=2.2, label='mean=' + str(np.round(salary_df['salary'].mean(),1)) + 'k$')\nplt.axvline(salary_df['salary'].median(), color='red', linewidth=2.2, label='median='+ str(np.round(salary_df['salary'].median(),1)) + 'k$')\nplt.axvline(salary_df['salary'].mode()[0], color='purple', linewidth=2.2, label='mode='+ str(salary_df['salary'].mode()[0]) + 'k$')\nax[1].set_xlabel('Salary (k$)')\nplt.legend()\nplt.tight_layout()\nplt.show()","9d6cac23":"categoricalColumns = [\"companyId\",\"jobType\", \"degree\", \"major\", \"industry\"]\nstages = []\nfor categoricalCol in categoricalColumns:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n    stages += [stringIndexer]\nnumericCols =  [\"yearsExperience\", \"milesFromMetropolis\"]\nassemblerInputs = [c + \"Index\" for c in categoricalColumns] + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]","ec935dfa":"stages = []\nstringIndexer = StringIndexer(inputCol = \"degree\", outputCol = \"degreeIndex\")\nstages += [stringIndexer]","6b4a9f97":"categoricalColumns = [\"companyId\",\"jobType\", \"major\", \"industry\"]\nfor categoricalCol in categoricalColumns:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n    stages += [stringIndexer, encoder]\nnumericCols =  [\"yearsExperience\", \"milesFromMetropolis\"]\nassemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols + [\"degreeIndex\"]\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]","b270163b":"pipeline = Pipeline(stages = stages)\npipelineModel = pipeline.fit(df_encoded)\ndf_encoded = pipelineModel.transform(df_encoded)\nselectedCols = ['features'] + cols\ndf_encoded = df_encoded.select(selectedCols)","6ed25d5f":"df_encoded.show(1)","5ecf6fb1":"train, test = df_encoded.randomSplit([0.995, 0.005], seed = 42)\nprint(\"There are %d training examples and %d test examples.\" % (train.count(), test.count()))","21b0c7f5":"gbt =  GBTRegressor(featuresCol=\"features\", labelCol=\"salary\", maxBins=20, maxDepth=12)","85282d4c":"gbt_model = gbt.fit(train)","28e0eabe":"predictions = gbt_model.transform(test)","8b445c7a":"evaluator = RegressionEvaluator(labelCol=\"salary\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nrmse","bc57289f":"evaluator = RegressionEvaluator(labelCol=\"salary\", predictionCol=\"prediction\", metricName=\"r2\")\nr2 = evaluator.evaluate(predictions)\nr2","fab10681":"rf_results = predictions.toPandas()","31fdc0ba":"sns.scatterplot(x='salary', y='prediction', data=rf_results, color='blue')\nplt.plot([0, 300], [0, 300])\nplt.axis([0, 300, 0, 300])\nplt.xlabel('Actual Salary')\nplt.ylabel('Predicted Salary')\nplt.suptitle(\"RMSE: {:.2f} k$ R2: {:.2f} %\".format(rmse, r2*100))\nplt.title('Actual Salary VS Predicted Salary')\nplt.show()","6793740f":"print(\"RMSE: {:.2f} k$ \\nR2: {:.2f} %\".format(rmse, r2*100))","3488816e":"spark.stop()","332f585e":"## Train test split ","107f0ccc":"# Q3 Which is the least paid job?","e07dfbd9":"**We can see first two industries are OIL and FINANCE, with have a very similar average salary of 130k\\\\$. The third industry in terms of highest salary is WEB. We could expect this result by looking at the Q1 query result.**","68195c23":"# One hot Encoding","b4ecb6ed":"The minimum salary looks to be 0, is this related to volounteering jobs? This will be investigated later!","757684a2":"## Label Encoding","1700fa8c":"In order to improve the readability of the results, we will plot salary VS jobtype. Before doing so, we should check the different jobtypes in the dataframe:","77f0ada1":"Acutally they are not missing values! They indicate that the worker do not have a degree or major for example. We won't drop these values.","3e69ffa6":"**We can see that engineering is the major the major of workers with higher salaries, business is the second and while literature is the major of workers with the lowest paid jobs.**","260cd80e":"# Q7 Does the major affects the salary?","87c5e3da":"# Missing Values check","2532a503":"Before starting the analysis, we will join the two dataframes on jobid. If we join the two dataframe as is, we will have two identical columns jobId, which will create ambiguity. For this reason we will rename the JobId column in the second dataframe, so that we can drop it after the join without creating ambiguity with the jobId column of the first dataframe.","9889a3ab":"We can see some NONE values in the degree column: we will drop the rows with no degree.","25c833af":"<img src=\"https:\/\/i.imgur.com\/fBHkdi4.png\" width=\"1000px\">","92f5b3e5":"**We can find the previous result (obtained with a subquery) of the highest paid jobs, in particular we can see that 8 of the TOP20 paid jobs are in the OIL industry(5 of them in the TOP10), 10  are from FINANCE and 2 are from WEB. We also added a Rank column to improve the readability of the result.**","8d5c9ef4":"The following project aims to analyze data about 100'000'000 employees, with a special focus on the salary. In particular, Pyspark framework will be used to analyze the data and extract useful informations by SQL queries. Finally, Pyspark MLlib will be used to perform Feature Engineering and train Gradient Boosted Tree (GBT) algorithm to predict employers' salaries.","106c0977":"# **Main Results Summary Dashboard:**","2f9ad6e0":"First, we will create a copy of the dataframe called 'df_encoded', which will include the pre processed data.","de8f49a3":"# Gradient Boosting Trees","dd0eb79c":"# ML Modeling","8df4f7b0":"Next we need to convert the extracted dataframe by SQL query Q5 into a pandas dataframe:","8f420ff9":"We remove the 'jobid' column since it just identifies a specific worker.","73d8462c":"# Q6 Do workers with higher degrees have better paid jobs?","6b62a1c7":"**We can see that now the lowest paid job is 'janitor', with a minimum salary of 17k$.**","672865e4":"We can see the presence of a \"features\" column, including all the different encoded features by one hot encoding and the numerical features. This column 'featurs' and the target column 'salary' will be passed to the ML algorithm during the training.","bee23ab4":"We can see that the algorithm predicts better salaries lower than 130k\\\\$, and start to understimate salaries over 175k\\\\$. This could be due to the right skeweness of the salary distribution.<br>\nOverall, the results are satifying in both terms of RMSE and R2. Further improvements could be achieved by a proper hyperparameter tuning and feature engineering on the data.","5e230108":"We successfully changed the data type of the three mentioned columns.","011e6f65":"In this dataframe there is no JANITOR as a jobtype: it means that people with 'janitor' as a jobtype in the dataset all have 'High school' as degree, and so no major (as stated in the previous query Q6). We need to define a new list of jobs without janitor for the following plots!","a3f7a306":"# Dataset Analayis","30653e56":"We can also get informations about the column types:","2b803dc7":"Finally we can create the plots with a for loop, including a linear regression to improve the readability of the plots.","108a4ec0":"Then we can perform SQL queries!","02bcf5f8":"# Q5 Do workers with more years of experience get paid more?","2dcca20a":"In order to perform one hot encoding on the dataset, we need to first apply a string indexer, as seen in the label encoder, and then do the acutal one hot encoder. Finally, these steps will be added to a \"stages\" variable and passed a Pipeline object.","28c8f965":"# Prediction results","0fe90a4b":"Data Analysis:\n- The industry with highest income is OIL, second is FINANCE and third is WEB.\n- For every jobtype, workers with higher degree have a higher income.\n- The highest paid job is CEO, while the least paid is JANITOR.\n- For every jobtype, Engineering, Businees and Math are the majors which lead to higher income.\n- The average income of workers with no experience differs a lot among the jobtype:\n    - CEO has a base average income around 120k\\\\$, CFO around 110k\\\\$ while Janitor only 47k\\\\$.\n- Among all jobs, mean, median and mode salary are respectively 116k\\\\$, 114k\\\\$ and 108k\\\\$. They do not coincide due to the right skeweness of the salary distribution.\n\nPrediction :\n- We can see that the algorithm predicts better salaries lower than 130k\\\\$, and start to understimate salaries over 175k\\\\$. This could be due to the right skeweness of the salary distribution.<br>\nOverall, the results are satifying in both terms of RMSE and R2. Further improvements could be achieved by a proper hyperparameter tuning and feature engineering on the data.","13fcf49f":"**It looks like for all job types in this dataset, higher educated workers get paid more. In particular we can see a higher difference of salaries between 'high school' and 'bachelor'.\nLastly is it interesting to notice that in case of JANITOR as a jobtype, there are only people with a High school education.**","e565a6cf":"**I hope this can be helpful to anyone learning Pyspark and ML! Thanks for reading :)**","b4f09adf":"# Duplicated data check","55c4d363":"By printing the df schema, we can see that some features such as salary, yearsExperience and milesFromMetropolis should be converted to integer type!","db98979b":"Then, we also need to reload the table since we updated the dataframe df.","cf9dbbef":"**We can see an increasing trend between years of experience and salary among all different jobs: this means that more years of experience lead to higher salaries for all the job positions. \nBy looking at the slope and intercept for each linear model, we can see that the slope is rounded to 2.0 for all the positions: this means that, on average, all these jobs see an increase of salary by 2000\\\\$ annually. The difference is the intercept, which can be interpreted as the average salary of a worker with 0 years of experience. In particular we can see an intercept value of 121.5k\\\\$ for CEO and 46.7k\\\\$ for janitor.**","a31c7a82":"In this dataset, the only categorical feature where there is a hieracrhy\/order is degree, so we should encode this feature with label encoding.","efcd49bf":"We can get some basic insights on the numerical columns by calling the describe method","dbb8ea0c":"In order to perform SQL queries on the dataset, we must create a table based on the spark dataframe, as follows:","ebec5e3a":"# Q2 Which are the TOP 20 jobs in terms of highest salary?","e3ca5a91":"Label encoding is a naive method to encode the categorical features. Label encoding should be used when there is a order among the categories.","21c8bd5b":"Then, as seen for Q5, we will extract a list of different degrees:","03dce6fc":"**The highest paid jobs are CFO (Chief financial officer) and CTO (Chief technology officer ) in the OIL industry, with a salary of 301k$.**","fe00565a":"Salary feature has a right skewed long tail distribution, with some salaries which appears lots of times in the dataset (the \"spikes\" in this histograms).","a1e6176d":"We still have NONE values in degree and also in major (note: if the degree=High school, of course the major should be NONE!), we will drop these values!","9ed423d3":"# Q4 Which are the TOP 3 industries in terms of highest salary?","3c507eb9":"# Dataset Loading and first analysis","7f95ec44":"EDIT: we improve the R2 by 0.8% by encoding 'degree' with label encoding instead of one hot encoding.","fc38c4db":"Good news, apparently there are no duplicate rows!","72e2b978":"In this section we will prepreocess the data for ML training.","4e3b886b":"Moreover, it could be interesting to analyze the target variable 'salary':","1e378e5f":"# Q1 Which is the highest paid job?","10b7d917":"We can clearly see that the jobs with 0\\\\$ salary are probably missing values, since they are related for example to OIL and WEB industries, which are very weel paid (as seen before). Moreover, there is also a 'vice president' job, which is impossible to have 0$ salary. We will drop these rows. <br>\n","1a118165":"Finally we can convert the extracted dataframe by SQL query 'Q6' to a pandas dataframe in order to plot the desired result.","a7b703e0":"We can see that some columns have 'NONE' values, are these missing values?"}}