{"cell_type":{"a842801a":"code","71cb5d82":"code","2e6dc3b3":"code","30ba2121":"code","f6580bc5":"code","371d6313":"code","d79ead42":"code","ea8d116c":"code","cbefb4c1":"code","b591f2b6":"code","0feb17ac":"code","85697e23":"code","2e023abf":"code","0179744c":"code","481b16e3":"code","c9ebfcee":"code","b2ca70d5":"code","7d32a044":"code","0e0eb6dd":"code","425ac98f":"code","7ffa3a1a":"code","494ccad3":"code","c307e2b7":"code","e3fd57d1":"code","58287c3f":"code","ee16a785":"code","03a4d52d":"code","4cbc1b66":"code","56a27895":"code","9290c4f4":"code","a3d45940":"code","e9318b78":"code","961e5f44":"code","3e71a400":"code","4626cbfd":"markdown","8491744f":"markdown","de01efbd":"markdown","a07b96e8":"markdown","53f078a5":"markdown","2c33a3f4":"markdown","f8018ec9":"markdown","f71a95b5":"markdown","2188826b":"markdown","b6bbb661":"markdown","eb757471":"markdown","f05d3f9a":"markdown","70eccf78":"markdown","ac983011":"markdown","f99b15a1":"markdown","afb56d61":"markdown","f80e83a2":"markdown","57db194f":"markdown","0894a473":"markdown","98e3cd76":"markdown","81d53e6c":"markdown","887e54c6":"markdown","fdb538c3":"markdown","d2cde869":"markdown","a4417c33":"markdown","d09f3d01":"markdown","65ce1958":"markdown","38f9c89d":"markdown","d39ab132":"markdown","22335b49":"markdown","c3d50571":"markdown","15d0768f":"markdown","7f06a670":"markdown","78a5efbb":"markdown","75d4745b":"markdown","8ea9dffa":"markdown","adca8218":"markdown","c1354fbf":"markdown","9234f39c":"markdown","78b2bf26":"markdown","7199ab00":"markdown"},"source":{"a842801a":"import pandas as pd\nimport numpy as np\nfrom fuzzywuzzy import process, fuzz","71cb5d82":"# Load in the dataset\nramen = pd.read_csv('\/kaggle\/input\/ramen-ratings-latest-update-jan-25-2020\/Ramen_ratings_2020.csv')\n\n# Display the first columns\nramen.head()","2e6dc3b3":"ramen.drop('URL', axis=1, inplace=True)","30ba2121":"# Check data type and null values\nramen.info()","f6580bc5":"# Remove leading and trailing spaces in each string value\nfor col in ramen[['Brand','Variety','Style','Country']]:\n    ramen[col] = ramen[col].str.strip()\n    print('Number of unique values in ' + str(col) +' is ' + str(ramen[col].nunique()))","371d6313":"ramen['Country'].unique()","d79ead42":"brand_country = ramen['Brand'] +' '+ ramen['Country']\nbrand_country.nunique()","ea8d116c":"unique_brand = ramen['Brand'].unique().tolist()\nsorted(unique_brand)[:20]","cbefb4c1":"process.extract('7 Select', unique_brand, scorer=fuzz.token_sort_ratio)","b591f2b6":"process.extract('A-Sha', unique_brand, scorer=fuzz.token_sort_ratio)","0feb17ac":"process.extract('Acecook', unique_brand, scorer=fuzz.token_sort_ratio)","85697e23":"process.extract(\"Chef Nic's Noodles\", unique_brand, scorer=fuzz.token_sort_ratio)","2e023abf":"process.extract('Chorip Dong', unique_brand, scorer=fuzz.token_sort_ratio)","0179744c":"process.extract('7 Select', unique_brand, scorer=fuzz.token_set_ratio)","481b16e3":"process.extract('A-Sha', unique_brand, scorer=fuzz.token_set_ratio)","c9ebfcee":"process.extract('Acecook', unique_brand, scorer=fuzz.token_set_ratio)","b2ca70d5":"process.extract(\"Chef Nic's Noodles\", unique_brand, scorer=fuzz.token_set_ratio)","7d32a044":"process.extract('Chorip Dong', unique_brand, scorer=fuzz.token_set_ratio)","0e0eb6dd":"#Create tuples of brand names, matched brand names, and the score\nscore_sort = [(x,) + i\n             for x in unique_brand \n             for i in process.extract(x, unique_brand, scorer=fuzz.token_sort_ratio)]","425ac98f":"#Create dataframe from the tuples\nsimilarity_sort = pd.DataFrame(score_sort, columns=['brand_sort','match_sort','score_sort'])\nsimilarity_sort.head()","7ffa3a1a":"#Derive representative values\nsimilarity_sort['sorted_brand_sort'] = np.minimum(similarity_sort['brand_sort'], similarity_sort['match_sort'])\nsimilarity_sort.head()","494ccad3":"high_score_sort = similarity_sort[(similarity_sort['score_sort'] >= 80) &\n                                      (similarity_sort['brand_sort'] != similarity_sort['match_sort']) &\n                                      (similarity_sort['sorted_brand_sort'] != similarity_sort['match_sort'])]","c307e2b7":"#Drop the representative value column\nhigh_score_sort = high_score_sort.drop('sorted_brand_sort',axis=1).copy()","e3fd57d1":"#Group matches by brand names and scores\n#pd.set_option('display.max_rows', None)\nhigh_score_sort.groupby(['brand_sort','score_sort']).agg(\n                        {'match_sort': ', '.join}).sort_values(\n                        ['score_sort'], ascending=False)","58287c3f":"#Souper - Super - 91%\nramen[(ramen['Brand'] == 'Souper') | (ramen['Brand'] == 'Super')].sort_values(['Brand'])","ee16a785":"#Sura - Suraj - 89%\nramen[(ramen['Brand'] == 'Sura') | (ramen['Brand'] == 'Suraj')].sort_values(['Brand'])","03a4d52d":"#Ped Chef - Red Chef - 88%\nramen[(ramen['Brand'] == 'Ped Chef') | (ramen['Brand'] == 'Red Chef')].sort_values(['Brand'])","4cbc1b66":"#Create tuples of brand names, matched brand names, and the score\nscore_set = [(x,) + i\n             for x in unique_brand \n             for i in process.extract(x, unique_brand, scorer=fuzz.token_set_ratio)]","56a27895":"#Create dataframe from the tuples and derive representative values\nsimilarity_set = pd.DataFrame(score_set, columns=['brand_set','match_set','score_set'])\nsimilarity_set['sorted_brand_set'] = np.minimum(similarity_set['brand_set'], similarity_set['match_set'])\n\n#Pick values\nhigh_score_set = similarity_set[(similarity_set['score_set'] >= 80) & \n                                    (similarity_set['brand_set'] != similarity_set['match_set']) & \n                                    (similarity_set['sorted_brand_set'] != similarity_set['match_set'])]\n\n#Drop the representative value column\nhigh_score_set = high_score_set.drop('sorted_brand_set',axis=1).copy()","9290c4f4":"#Group brands by matches and scores\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)\nhigh_score_set.groupby(['match_set','score_set']).agg(\n                       {'brand_set': ', '.join}).sort_values(\n                       ['score_set'], ascending=False)","a3d45940":"#Create columns with brand names combining scores\nhigh_score_sort['brand_sort'] = high_score_sort['brand_sort'] + ': ' + high_score_sort['score_sort'].astype(str)\nhigh_score_set['brand_set'] = high_score_set['brand_set'] + ': ' + high_score_set['score_set'].astype(str)","e9318b78":"#Group data by matched name and store in new dataframe\ntoken_sort = high_score_sort.groupby(['match_sort']).agg({'brand_sort': ', '.join}).reset_index()\ntoken_set = high_score_set.groupby(['match_set']).agg({'brand_set': ', '.join}).reset_index()\n\n#Rename columns\ntoken_sort = token_sort.rename(columns={'match_sort':'brand'})\ntoken_set = token_set.rename(columns={'match_set':'brand'})","961e5f44":"#Outer join two tables by brand (matched names)\nsimilarity = pd.merge(token_sort, token_set, how='outer', on='brand')\n\n#Replace NaN values and rename columns for readability\nsimilarity = similarity.replace(np.nan,'')\nsimilarity = similarity.rename(columns={'brand_set':'token_set_ratio','brand_sort':'token_sort_ratio'})","3e71a400":"similarity.sort_values('brand')","4626cbfd":"# Overview of the dataset","8491744f":"This one got 100% just like the 7 Select case.","de01efbd":"Still good at 70% threshold.","a07b96e8":"### Token Sort Ratio","53f078a5":"In this part, I will create a merged table including results from token sort ratio and token set ratio with some changes.<br>\nThe tables will be merged by matched values to shorten the result table, and because I would like to keep the scores after grouping all values, I need to create new columns which combine brand names and scores. ","2c33a3f4":"## Import","f8018ec9":"Based on the tests above, I would care about those pairs which have at least 80% similarity. I also exclude those which match to themselves (brand value and match value are exactly the same), and those which are duplicated pairs.","f71a95b5":"Below 70%, there's no match for A-sha.","2188826b":"Since we're looking for matched values from the same column, one value pair would have another same pair in a reversed order. For example, we will find one pair of EDO Pack - Gau Do, and another pair of Gau Do - EDO Pack. To eliminate one of them later, I need to find a representative value for each of two same pairs.","b6bbb661":"Now we see A-Sha has another name as A-Sha Dry Noodle. And we can see this only by using token set ratio.","eb757471":"Since the token set ratio is more flexible, the score has increased from 70% to 100% for 7 Select - 7 Select\/Nissin.","f05d3f9a":"We can continue to check other pairs by the same method. From the threshold of 84% and below, we can ignore some pairs which are obviously different or we can make a quick check as above. Next, I will apply token set ratio scorer to find matched brand names, and then compare the results.","70eccf78":"I would choose 'outer' option to get all the data from two tables.","ac983011":"I would like to know if one brand can have multiple manufacturers in different countries.","f99b15a1":"Although the token set ratio is more flexible and can detect more similar strings than the token sort ratio, it might also bring in more wrong matches.","afb56d61":"Sura and Suraj are two different brands.","f80e83a2":"Here, we only have one record of the Ped Chef brand, and we also see the same pattern in its variety name in comparison with the Red Chef brand. I'm pretty sure these two brands are the same.","57db194f":"# FuzzyWuzzy","0894a473":"From the score of 95 and above, everything looks good. In each pair, the two values might have typos, one missing character, or inconsistent format, but overal they obviously refer to each other. Below 95, it would be harder to tell. We can look at some examples by listing out data from each pair.","98e3cd76":"FuzzyWuzzy has four scorer options to find the Levenshtein distance between two strings. In this example, I would check on the token sort ratio and the token set ratio, for I believe they are more suitable for this dataset which might have mixed words order and duplicated words.<br>\nI would pick four brand names and find their similar names in the Brand column. Since we're matching the Brand column with itself, the result would always include the selected name with a score of 100.","81d53e6c":"There are different ways to make data dirty, and inconsistent data entry is one of them. Inconsistent values are even worse than duplicates, and sometimes difficult to detect.<br>\nIn this notebook, I apply [FuzzyWuzzy](https:\/\/github.com\/seatgeek\/fuzzywuzzy) package to find similar ramen brand names in a ramen review dataset.<br>\nData source: [The ramen rater Big list](https:\/\/www.theramenrater.com\/resources-2\/the-list\/)\n\nOn my [GitHub](http:\/\/localhost:8888\/notebooks\/Desktop\/Github\/Python\/Ramen\/Find%20similar%20strings%20with%20FuzzyWuzzy.ipynb)","887e54c6":"### Token Set Ratio","fdb538c3":"Now, let's see the result.","d2cde869":"Now, I can group the two tables by matched names, and then rename the columns","a4417c33":"We will go over the same steps as above.","d09f3d01":"### Token Set Ratio\nThe token set ratio scorer also tokenizes the strings, and follows processing steps just like the token sort ratio. Then it collects common tokens between two strings and performs pairwise comparisons to find the similarity percentage.","65ce1958":"Now, we have a problem here. Token sort ratio scorer will gets the wrong pair of Chef Nic's Noodles - Mr. Lee's Noodles if I set 70% threshold.","38f9c89d":"### Token Sort Ratio\nThe token sort ratio scorer tokenizes the strings and cleans them by returning these strings to lower cases, removing punctuations, and then sorting them alphabetically. After that, it finds the Levenshtein distance and returns the similarity percentage.","d39ab132":"586 is greater than 510 brands, so yes, one brand can have different country values. Next, we need to get the list of unique brand names.","22335b49":"This one got much worse when token set ratio returns 100% for the pair of Chef Nic's Noodles - S&S.","c3d50571":"This result means that '7 Select\/Nissin' has 70% similarity when referring to '7 Select'. Not bad if I set the threshold at 70% to get the pair of 7 Select - 7 Select\/Nissin.","15d0768f":"We need to create a dataframe with brand names, matched brands, and their scores.","7f06a670":"We can see some suspicious names right at the beginning. Let's have some tests first.","78a5efbb":"Now we can see how different it is between two scorers. As expected, the token set ratio matches wrong names with high scores (e.g. S&S, Mr.Noodles). However, it does bring in more matches that the token sort ratio could not get (e.g. 7 Select\/Nissin, Sugakiya Foods, Vina Acecook).<br>\nIt would be beneficial to apply both methods in this case.","75d4745b":"For this pair, we see that these two brands come from different manufacturers, and there's also no similarity in their ramen types or styles. I would say that these brands are not the same.","8ea9dffa":"# Apply FuzzyWuzzy in one column","adca8218":"We have the same result for this one.","c1354fbf":"# Comparison","9234f39c":"# Find similar brand names with FuzzyWuzzy","78b2bf26":"Since the token set ratio scorer will tolerate more 'noise' when matching two values. I would group the result by matched values to reduce the number of rows.","7199ab00":"This one looks good enough."}}