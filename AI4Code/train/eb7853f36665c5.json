{"cell_type":{"780e3aa0":"code","7ffb214c":"code","830ededd":"code","a2dff832":"code","b077f3b3":"code","5af1b14e":"code","8f3e2cbd":"code","9e8408b8":"code","da61e3f7":"code","fc790ef3":"code","4732e31b":"code","dee2da67":"code","60743b67":"code","1b66ce46":"markdown","525210da":"markdown","04b7b0d8":"markdown","cb8f8c0a":"markdown","355d5ce5":"markdown","fd107ddd":"markdown","f4abd4a0":"markdown","9d0cc899":"markdown","afbd26d3":"markdown","85881f96":"markdown","d41dd6de":"markdown","d5e65d40":"markdown","65847727":"markdown","d399c0dd":"markdown","a7850d07":"markdown","8a7dc628":"markdown","4d1f7c8e":"markdown"},"source":{"780e3aa0":"import numpy as np \nimport pandas as pd \n\nimport os\nimport glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport xgboost as xgb\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay","7ffb214c":"BASE_DIR_1 = '..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images'\nBASE_DIR_2 = '..\/input\/animal-faces\/afhq\/'\n\nSIZE = 150  # resize images","830ededd":"# load model without the fully connected classifier layers\nVGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n\n# to work with pre-trained weights make layers non-trainable\nfor layer in VGG_model.layers:\n    layer.trainable = False\n    \nVGG_model.summary()  # num trainable parameters should be 0","a2dff832":"datagen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 20\n\ndef extract_features(directory, sample_size):\n    features = np.zeros(shape=(sample_size, 4, 4, 512))\n    labels = np.zeros(shape=(sample_size))\n    target_labels = []\n    \n    generator = datagen.flow_from_directory(directory, \n                                            target_size=(SIZE, SIZE),\n                                            batch_size=batch_size, \n                                            color_mode='rgb',\n                                            class_mode='binary',  #  set to binary  \n                                            seed= 2021)\n    # Note: Set class_mode to binary is for 1-D binary labels; categorical for 2-D one-hot encoded labels\n    target_labels = list(generator.class_indices.keys())\n    \n    i=0\n    for inputs_batch, labels_batch in generator:\n        features_batch = VGG_model.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_size:\n            break\n            \n    return features, labels, target_labels\n\n\ndef get_data(dir, sample_size):\n    features, labels, target_labels = extract_features(dir, sample_size)\n    features = features.reshape(features.shape[0], -1)\n    return features, labels, target_labels","b077f3b3":"TRAIN_DIR = os.path.join(BASE_DIR_1, 'TRAIN')\nTEST_DIR = os.path.join(BASE_DIR_1, 'TEST')\n\nX_train, y_train, _ = get_data(TRAIN_DIR, 9000)\nX_test, y_test, target_labels = get_data(TEST_DIR, 2000)","5af1b14e":"# XGBoost using sklearn methods e.g. model.fit()\n\nmodel = xgb.XGBClassifier(use_label_encoder=False, tree_method='hist')\nmodel.fit(X_train, y_train) ","8f3e2cbd":"y_pred = model.predict(X_test)\nprint (f'Accuracy = {metrics.accuracy_score(y_test, y_pred)}')","9e8408b8":"cm = confusion_matrix(y_test, y_pred)\ncmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_labels)\nfig, ax = plt.subplots(figsize=(10,8))\ncmp.plot(ax=ax, cmap=plt.cm.Blues, xticks_rotation=45)\nplt.show()","da61e3f7":"# # XGBoost using the internal DMatrix data structure directly\n# # Note: we bypass the scikit-learn fit() method\n\n# # create the DMatrix from the numpy arrays\n# dtrain = xgb.DMatrix(X_train, label=y_train)\n# dtest = xgb.DMatrix(X_test, label=y_test)\n\n# param = {'tree_method': 'hist',          # speedup\n#          'objective': 'multi:softprob',  # error evaluation for multiclass training\n#          'num_class': 4}                 # number of classes \n# # num_round = 50  -- default is 10\n\n# model = xgb.train(param, dtrain)\n\n# prob_pred = model.predict(dtest)\n# y_pred = np.asarray([np.argmax(line) for line in prob_pred])\n# print (f'Accuracy = {metrics.accuracy_score(y_test, y_pred)}')","fc790ef3":"# plot of test accuracy as the training set size is increased \n\naccuracy = [0.497, 0.515, 0.5095, 0.5145, 0.523, 0.5065]\ntrain_data_size = [1000, 2000, 3000, 4000, 5000, 9000]\nplt.plot(train_data_size, accuracy, marker='o', color='purple')\nplt.ylim(0.4, 0.6)\nplt.title('Accuracy (test) vs training set size', fontsize=15);","4732e31b":"TRAIN_DIR = os.path.join(BASE_DIR_2, 'train')\nTEST_DIR = os.path.join(BASE_DIR_2, 'val')\n\nX_train, y_train, _ = get_data(TRAIN_DIR, 10000)\nX_test, y_test, target_labels = get_data(TEST_DIR, 1500)","dee2da67":"model = xgb.XGBClassifier(use_label_encoder=False, tree_method='hist')\nmodel.fit(X_train, y_train) ","60743b67":"y_pred = model.predict(X_test)\nprint (f'Accuracy = {metrics.accuracy_score(y_test, y_pred)}')\n\ncm = confusion_matrix(y_test, y_pred)\ncmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_labels)\nfig, ax = plt.subplots(figsize=(10,8))\ncmp.plot(ax=ax, cmap=plt.cm.Blues, xticks_rotation=45)\nplt.show()","1b66ce46":"To understand the model behavior, we sweep across (increment) the training set size. The results are plotted below.","525210da":"### Utility functions","04b7b0d8":"## White blood cell dataset","cb8f8c0a":"Computer vision pipelines built for natural images often use a backbone model pretrained on ImageNet. The image statistics (e.g. the local covariance structure or the power spectrum) of natural images differ from images reconstructed from an MRI or obtained via a brighfield microscope. \nThe domain variance between biomedical and natural images restricts the way in which pretrained ImageNet models can be employed. Simply replicating pipelines optimized for natural images, on a biomedical imaging solution may be ineffective. \n\nIn this exercise we compare the performance of a classifier (a CNN feature extractor coupled with an XGBoost) on two datasets. The first dataset consists of four classes of white blood cell images obtained via microscopy; the second is a three-class dataset of animal faces. A VGG16 model pretrained on ImageNet serves as the feature extractor. This could introduce a bias on the white blood cell features and it remains to be seen if the XGBoost classifier, which is one of the best performing classifiers, can perform equally well for both datasets.","355d5ce5":"This outputs a flattened 1D array of 4x4x512 = 8192 features for each image.","fd107ddd":"The [Animal Faces dataset](https:\/\/www.kaggle.com\/andrewmvd\/animal-faces) has three balanced classes of animal images: *cat*, *dog*, *wildlife*. These are natural images and it will be interesting to see how a classifier that uses feature extraction based on pretrained ImageNet weights performs in this case. Once again we will use XGBoost with the default parameters.","f4abd4a0":"# VGG Feature Extraction + XGBoost Classification: \n## White Blood Cell (microscopy) vs Animal Faces (natural images) data\n\n**Keywords: VGG Feature Extractor, XGBoost Classifier, Image Analysis, Microscopy images, Natural images**","9d0cc899":"The baseline accuracy for the White Blood Cell data was around 51% for a training dataset of 9000. We experimented with the dataset size (sweeping the axis from 1000 to 9000) but could not improve the accuracy. This indicates that there is considerable bias in the learned features that serve as input to the XGBoost classifier.     \nWith the Animal Faces data, we comfortably get a baseline accuracy of 98.2% with a training set of 10,000 images.\n\nThere is obviously a mismatch in learned features between natural images from ImageNet and the microscopy images used here.  The experiment indicates that pretrained ImageNet models should be used with caution (perhaps restricting the learning to low-level features) in the biomedical domain.","afbd26d3":"**Author: Meena Mani**    \n**Date: December 2021**","85881f96":"We can see that increasing the data set size does not improve the test accuracy. This indicates high bias in the learned features obtained from the pretrained VGG16 model.","d41dd6de":"## Discussion","d5e65d40":"For comparison, you can try XGBoost that uses the DMatrix directly. Uncomment the code below.","65847727":"When we exclude the top fully connected dense layers of the VGG network, what remains is a fully convolutional network. This gives us the flexibility to use any image size. The larger the input image, the larger the feature dimensions at the end of the pipeline: for a 256x256 RGB image, the output feature dim is 8x8x512; for a 150x150 image it is 4x4x512.     \nHere we choose 150, the smaller of the two input image dimensions; we need to be cognizant that when $p \\gg n$ (where $p$ and $n$ are the number of parameters and images respectively), the XGBoost classifier does not perform well.","d399c0dd":"## Animal Faces (AFHQ) dataset","a7850d07":"### VGG feature extractor","8a7dc628":"#### XGBoost\n\nWe will use the `scikit-learn` XGBoost implementation. This implementation uses a wrapper function to access the DMatrix which is an internal XGBoost data structure. Note that the alternative to using the `scikit-learn` API is to access the DMatrix directly.\n\nWe will use the default parameters since the objective is to compare the accuracy of the two data sets and I expect the baseline results to be sufficiently different for the two cases.","4d1f7c8e":"The data set consists of digitized histopathology images of white blood cells. There are four classes of images: *Eosinophils*, *Lymphocytes*, *Monocytes*, *Neutrophils*. The training set has been balanced and augmented to yield approximately 9950 images. "}}