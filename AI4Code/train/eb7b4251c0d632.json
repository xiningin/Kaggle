{"cell_type":{"9d1f1310":"code","dbdc7da4":"code","c74172ba":"code","96b74e41":"code","4d604972":"code","2def2223":"code","02d70c9f":"code","82886963":"code","0cd52074":"code","35cdf1e1":"code","c8223262":"code","1fcf15b1":"code","61e1c1d2":"code","17aac109":"code","44f3c541":"markdown","f934caf7":"markdown","c451283c":"markdown","b1c87f0d":"markdown","db5df49e":"markdown","cb1a9412":"markdown","7600d2c3":"markdown","7df3e5c5":"markdown"},"source":{"9d1f1310":"# Libraries \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nimport matplotlib.image as mpimg\nimport os\nfrom PIL import Image\nimport seaborn as sns\nfrom sklearn.model_selection import  train_test_split\nfrom keras.utils import to_categorical\n\n\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n","dbdc7da4":"print(os.listdir('..\/input\/gtsrb-german-traffic-sign'))","c74172ba":"\ndf=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Train.csv')\n# finding the best values for Height and Width\nprint(df.head())\nprint(df['Height'].value_counts()[:5].sort_values(ascending=False))\nprint(df['Width'].value_counts()[:5].sort_values(ascending=False))\nheight=33\nwidth=33\n\n# examing the pictures\ndata_dir = \"..\/input\/gtsrb-german-traffic-sign\"\nimg_path= list((data_dir + '\/' + str(df.Path[i])) for i in range(len(df.Path)))\nfor i in range(0,9):\n    plt.subplot(331+i)\n    seed=np.random.randint(0,29222)\n    img= mpimg.imread(img_path[seed])\n    plt.imshow(img)\n    \nplt.show()\n\n","96b74e41":"data=[]\nlabels=[]\n\nclasses = 43\nn_inputs = height * width*3\n\nfor i in range(classes) :\n    path = \"..\/input\/gtsrb-german-traffic-sign\/train\/{0}\/\".format(i)\n    print(path)\n    Class=os.listdir(path)\n    for a in Class:\n        try:\n            image=cv2.imread(path+a)\n            image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n            image_from_array = Image.fromarray(image, 'RGB')\n            size_image = image_from_array.resize((height, width))\n            data.append(np.array(size_image))\n            labels.append(i)\n        except AttributeError:\n            print(\" \")\n            \ntrain_data=np.array(data)\nlabels=np.array(labels)\n\ndata=np.arange(train_data.shape[0])\ntrain_data=train_data[data]\nlabels=labels[data]","4d604972":"plt.figure(figsize=(20,5))\nsns.countplot(labels)\nplt.title('Pictures per Label', fontsize = 20)\nplt.xlabel('Labels', fontsize=20)\nplt.show()\n","2def2223":"\n\nx_train, x_val, y_train, y_val = train_test_split(train_data, labels , test_size = 0.2, random_state = 68)\nprint(\"Train :\", x_train.shape)\nprint(\"Valid :\", x_val.shape)\nx_train = x_train.astype('float32')\/255 \nx_val = x_val.astype('float32')\/255\n\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)\n","02d70c9f":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self,epoch,logs={}):\n    if logs.get('accuracy') is not None and logs.get('accuracy') > 0.985:\n      print(\"\\n reached 98.5% accuracy so canceling training!\")\n      self.model.stop_training=True","82886963":"#Definition of the DNN model\n\nmodel = tf.keras.models.Sequential([\n    # This is the first convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(x_train.shape[1:])),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n     tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)\n","0cd52074":"model.summary()","35cdf1e1":"epochs = 20\ncallbacks=myCallback()\nhistory = model.fit(x_train, y_train, batch_size=32, epochs=epochs,\nvalidation_data=(x_val, y_val),callbacks=[callbacks])\n\n","c8223262":"\nplt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()","1fcf15b1":"y_test=pd.read_csv(\"..\/input\/gtsrb-german-traffic-sign\/Test.csv\")\nlabels=y_test['Path']\ny_test=y_test['ClassId']\ny_test = to_categorical(y_test,43)\n\ndata=[]\n\nfor f in labels:\n    image=cv2.imread('..\/input\/gtsrb-german-traffic-sign\/test\/'+f.replace('Test\/', ''))\n    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((height, width))\n    data.append(np.array(size_image))\n\nX_test=np.array(data)\nX_test = X_test.astype('float32')\/255 \n\nresults = model.evaluate(X_test, y_test, batch_size=128)\n\nprint(\"test loss, test acc:\", results)\n","61e1c1d2":"image=cv2.imread('..\/input\/stopsign2\/stop.jpg')\n\n\n\ndata=[]\nimage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\nimage_from_array = Image.fromarray(image, 'RGB')\nsize_image = image_from_array.resize((height, width))\ndata.append(np.array(size_image))\n\nX_test=np.array(data)\nX_test = X_test.astype('float32')\/255     \npred=model.predict_classes(X_test)\nprint(pred)\nprint(model.predict(X_test)[0][14])\n\nplt.imshow(size_image)\n\nplt.show()","17aac109":"image=cv2.imread('..\/input\/stopsign\/.png')\n\n\n\ndata=[]\nimage=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\nimage_from_array = Image.fromarray(image, 'RGB')\nsize_image = image_from_array.resize((height, width))\ndata.append(np.array(size_image))\n\nX_test=np.array(data)\nX_test = X_test.astype('float32')\/255     \npred=model.predict_classes(X_test)\nprint(pred)\nprint(model.predict(X_test)[0][13])\n\nplt.imshow(size_image)\n\nplt.show()","44f3c541":"Suprisingly the model overfitted to Stop signs that dont have the Hand sign next to the \"Stop\" label.","f934caf7":"**The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. We cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Our benchmark has the following properties:\n**\nSingle-image, multi-class classification problem\nMore than 40 classes\n\n\nMore than 50,000 images in total\nLarge, lifelike database","c451283c":"finding the best values for Height and Width according to the pictures dimension.\n\n\nexaming 9 of the pictures in the dataset.\n* ","b1c87f0d":"**Plotting figures to see the Accuracy and the Loss per Epoch**","db5df49e":"> Building the CNN Model","cb1a9412":"# Verdict\n\n* 98.5% accuracy on Training Set\n* 99.3% accuracy on Validation Set\n* 96.1% accuracy on Testing Set \n\nseems like good results to me for a pretty basic model.\n","7600d2c3":"# taking a look at how many pictures there are in of the 43 diffrent traffic signs labels","7df3e5c5":"# Making Prediction with the Test Dataset\n"}}