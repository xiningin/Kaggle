{"cell_type":{"5db2de84":"code","b9c366ff":"code","350f2454":"code","53a7dd05":"code","29c908de":"code","53d615fc":"code","70f40e47":"code","dce2f0de":"code","d91a4bb8":"code","7a7ea73c":"code","3824939b":"code","a5bb7b6b":"code","27f5be5c":"code","eb37b212":"code","f743277a":"code","79d0f4bd":"code","9fdc4c27":"code","98ad450d":"code","fdf60ac0":"code","b540b055":"code","0ab9fec9":"code","5372dd91":"code","23b109d0":"code","3c007f09":"code","fe78e69a":"code","ee2ca843":"code","400a421f":"code","651229b4":"code","19ef70ce":"code","4ea846b6":"code","a70df2ea":"code","de8dd08b":"code","ee8cd81d":"code","13e36e7f":"code","3ce8421b":"code","44c0f637":"code","daa0d9ee":"code","927e91f2":"code","64a613cc":"code","b6925cc5":"code","bc9f8322":"code","f07eb987":"code","b5e0b2d5":"code","8557749d":"code","897826c9":"code","09b685a5":"code","4e689773":"code","bf1fc3e3":"code","778a02e2":"code","2a92d9fd":"code","ac1c159a":"code","fd80fb52":"code","8684be56":"code","24c71379":"code","248277e2":"code","d161f60a":"code","f2cbd225":"code","31f7bf57":"code","6d2a7ae6":"code","bcbd8013":"code","541534b9":"code","ecc6f563":"code","b195a9fe":"code","fff133d8":"code","528b26f4":"code","6db93a8a":"code","155298b2":"code","0388949a":"code","a058da77":"code","376351dd":"code","294650d1":"code","94fa3acb":"code","a660af4b":"code","326ea6f9":"code","5aa6535e":"code","7329639c":"code","ab5daa9a":"code","7154758e":"code","8a4bc8c3":"code","e42bc10d":"code","71925ac8":"code","5973d27c":"code","636a9683":"code","ad7043f7":"code","733a7124":"code","b30ecb69":"code","43527d9f":"code","0687d012":"code","934eab41":"code","a2931333":"code","f0d9b2f0":"code","cf8c4c5f":"code","ca9aecff":"code","2af7fafe":"markdown","73a462d3":"markdown"},"source":{"5db2de84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9c366ff":"from nibabel.testing import data_path\nimport os","350f2454":"example_filename = os.path.join(data_path, '\/kaggle\/input\/covid19-ct-scans\/ct_scans\/coronacases_org_001.nii')","53a7dd05":"example_filename ","29c908de":"import matplotlib.pyplot as plt\n\ndef multi_slice_viewer(volume):\n    #remove_keymap_conflicts({'j', 'k'})\n    fig, ax = plt.subplots()\n    ax.volume = volume\n    ax.index = volume.shape[0] \/\/ 2\n    ax.imshow(volume[ax.index])\n    fig.canvas.mpl_connect('key_press_event', process_key)\n\ndef process_key(event):\n    fig = event.canvas.figure\n    ax = fig.axes[0]\n    if event.key == 'j':\n        previous_slice(ax)\n    elif event.key == 'k':\n        next_slice(ax)\n    fig.canvas.draw()\n\ndef previous_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n    ax.images[0].set_array(volume[ax.index])\n\ndef next_slice(ax):\n    volume = ax.volume\n    ax.index = (ax.index + 1) % volume.shape[0]\n    ax.images[0].set_array(volume[ax.index])","53d615fc":"import nibabel as nib","70f40e47":"img = nib.load(example_filename)","dce2f0de":"img.shape","d91a4bb8":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[:,:,i])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","7a7ea73c":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(20):\n    plt.subplot(5, 5, i + 1)\n\n    plt.imshow(im_fdata[i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","3824939b":"def show_images(images):\n\n    n_ = min(images.shape[0], 20) \n    rows = 4\n    cols = (n_ \/\/ 4) + (1 if (n_ % 4) != 0 else 0)\n    figure = plt.figure(figsize=(2*rows, 2*cols))\n    plt.subplots_adjust(0, 0, 1, 1, 0.001, 0.001)\n    for i in range(n_):\n        plt.subplot(cols, rows, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        if images.shape[1] == 3:\n           \n            vol = images[i].detach().numpy()\n            img = [[[(1-vol[0,x,y])*vol[1,x,y], (1-vol[0,x,y])*vol[2,x,y], 0] \\\n                            for y in range(vol.shape[2])] \\\n                            for x in range(vol.shape[1])]\n            plt.imshow(img)\n        else: \n            plt.imshow((images[i, 0]*255).int(), cmap= \"gray\")\n\n    return figure","a5bb7b6b":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/ct_scans\/'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","27f5be5c":"def reshape(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cv2.resize(image[:,:,i], ( 64, 64))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","eb37b212":"# out=LoadLungData(64, 64,100)\n# print(out.shape)","f743277a":"# out.shape","79d0f4bd":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","9fdc4c27":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     value=out[0]['seg'][i,:,:]>0\n#     print(value)\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","98ad450d":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(20):\n#     plt.subplot(5, 5, i + 1)\n\n#     plt.imshow(out[0]['image'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","fdf60ac0":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(10,35):\n#     plt.subplot(5, 5, i + 1-10)\n\n#     plt.imshow(out[0]['seg'][:,:,i])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","b540b055":"# keys = range(len(out))\n# split = dict()\n# size=len(out)\n# split_1=int(size*0.7)\n# split_2=int(size*0.7)+int(size*0.2)\n# split['train']=range(0,split_1)\n# split['test']=range(split_1,split_2)\n# split['val']=range(split_2,size)\n# print('len val',len(split['val']))","0ab9fec9":"import os\nimport time\n\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","5372dd91":"n_epochs =10\ntime_start = \"\"\ntime_end = \"\"\nepoch = 0\n ","23b109d0":"# import torch\n# from torch.utils.data import Dataset\n\n\n# class SlicesDataset(Dataset):\n\n#     def __init__(self, data):\n#         self.data = data\n\n#         self.slices = []\n\n#         for i, d in enumerate(data):\n#             print(d[\"image\"].shape[0])\n#             for j in range(d[\"image\"].shape[0]):\n#                 self.slices.append((i, j))\n#         print('Len slices ',len(self.slices))\n\n#     def __getitem__(self, idx):\n\n#         slc = self.slices[idx]\n#         sample = dict()\n#         sample[\"id\"] = idx\n\n\n#         i,j=slc\n        \n#         #print('i ',i)\n#         #print('j ',j)\n    \n#         import numpy as np\n\n#         image_=self.data[i]['image']\n#         label_=self.data[i]['seg']\n#         image=image_[j,:,:]\n#         #print('Slice shape ',image.shape)\n#         print('1',image.shape)\n#         image=image.reshape(1,image.shape[0],image.shape[1])\n#         print('2',image.shape)\n#         label=label_[j,:,:]\n#         label=label.reshape(1,label.shape[0],label.shape[1])\n   \n#         sample['image']=torch.tensor(image)#\n#         sample['seg']=torch.tensor(label)#\n\n#         return sample\n\n#     def __len__(self):\n   \n#         return len(self.slices)","3c007f09":"import numpy as np\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom nilearn.surface import surface\nfrom nilearn.plotting import show","fe78e69a":"# train_loader = DataLoader(SlicesDataset(out[split[\"train\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)\n# val_loader = DataLoader(SlicesDataset(out[split[\"val\"]]),\n#                 batch_size=20, shuffle=True, num_workers=0)","ee2ca843":"# test_data = out[split[\"test\"]]","400a421f":"def build_model(inp_shape, k_size=3):\n    merge_axis = -1 # Feature maps are concatenated along last axis (for tf backend)\n    data = Input(shape=inp_shape)\n    conv1 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(data)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv2 = Convolution3D(padding='same', filters=32, kernel_size=k_size)(conv1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n\n    conv3 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool1)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv4 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n\n    conv5 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(pool2)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n    conv6 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv5)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv6)\n\n    conv7 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool3)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation('relu')(conv7)\n    conv8 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv7)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Activation('relu')(conv8)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conv8)\n\n    conv9 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(pool4)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Activation('relu')(conv9)\n\n    up1 = UpSampling3D(size=(2, 2, 2))(conv9)\n    conv10 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(up1)\n    conv10 = BatchNormalization()(conv10)\n    conv10 = Activation('relu')(conv10)\n    conv11 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(conv10)\n    conv11 = BatchNormalization()(conv11)\n    conv11 = Activation('relu')(conv11)\n    merged1 = concatenate([conv11, conv8], axis=merge_axis)\n    conv12 = Convolution3D(padding='same', filters=128, kernel_size=k_size)(merged1)\n    conv12 = BatchNormalization()(conv12)\n    conv12 = Activation('relu')(conv12)\n\n    up2 = UpSampling3D(size=(2, 2, 2))(conv12)\n    conv13 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up2)\n    conv13 = BatchNormalization()(conv13)\n    conv13 = Activation('relu')(conv13)\n    conv14 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv13)\n    conv14 = BatchNormalization()(conv14)\n    conv14 = Activation('relu')(conv14)\n    merged2 = concatenate([conv14, conv6], axis=merge_axis)\n    conv15 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged2)\n    conv15 = BatchNormalization()(conv15)\n    conv15 = Activation('relu')(conv15)\n\n    up3 = UpSampling3D(size=(2, 2, 2))(conv15)\n    conv16 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up3)\n    conv16 = BatchNormalization()(conv16)\n    conv16 = Activation('relu')(conv16)\n    conv17 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv16)\n    conv17 = BatchNormalization()(conv17)\n    conv17 = Activation('relu')(conv17)\n    merged3 = concatenate([conv17, conv4], axis=merge_axis)\n    conv18 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged3)\n    conv18 = BatchNormalization()(conv18)\n    conv18 = Activation('relu')(conv18)\n\n    up4 = UpSampling3D(size=(2, 2, 2))(conv18)\n    conv19 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(up4)\n    conv19 = BatchNormalization()(conv19)\n    conv19 = Activation('relu')(conv19)\n    conv20 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(conv19)\n    conv20 = BatchNormalization()(conv20)\n    conv20 = Activation('relu')(conv20)\n    merged4 = concatenate([conv20, conv2], axis=merge_axis)\n    conv21 = Convolution3D(padding='same', filters=64, kernel_size=k_size)(merged4)\n    conv21 = BatchNormalization()(conv21)\n    conv21 = Activation('relu')(conv21)\n\n    conv22 = Convolution3D(padding='same', filters=2, kernel_size=k_size)(conv21)\n    output = Reshape([-1, 2])(conv22)\n    output = Activation('softmax')(output)\n    output = Reshape(inp_shape[:-1] + (2,))(output)\n\n    model = Model(data, output)\n    return model","651229b4":"# out[0]['image'].shape","19ef70ce":"# len(out)","4ea846b6":"# # X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","a70df2ea":"# X=np.array(X)\n# # y=np.array(y)","de8dd08b":"# X.shape","ee8cd81d":"# X.shape","13e36e7f":"# y.shape","3ce8421b":"# X.shape[1:]","44c0f637":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv3D, Input, MaxPooling3D, Dropout, concatenate, UpSampling3D\nimport tensorflow as tf\n\ndef Unet3D(inputs,num_classes):\n    x=inputs\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv1)\n    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(pool1)\n    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv2)\n    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(pool2)\n    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv3)\n    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(pool3)\n    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\n\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(pool4)\n    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv3D(64, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(drop5))\n    merge6 = concatenate([drop4,up6],axis=-1)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(merge6)\n    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv6)\n\n    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n    merge7 = concatenate([conv3,up7],axis=-1)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(merge7)\n    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv7)\n\n    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv7))\n    merge8 = concatenate([conv2,up8],axis=-1)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(merge8)\n    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv8)\n\n    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv8))\n    merge9 = concatenate([conv1,up9],axis=-1)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(merge9)\n    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv9)\n    conv10 = Conv3D(1,1, activation = 'sigmoid')(conv9)\n    model = Model(inputs=inputs, outputs = conv10)\n    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","daa0d9ee":"def dice_loss(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.cast(tf.reshape(y_true,[-1]),tf.float32)\n    y_pred_f =tf.cast(tf.reshape(y_pred,[-1]),tf.float32)\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (1-(2. * intersection + smooth) \/ (union + smooth))","927e91f2":"def dice_coe(y_true,y_pred, loss_type='jaccard', smooth=1.):\n\n    y_true_f = tf.reshape(y_true,[-1])\n    y_pred_f = tf.reshape(y_pred,[-1])\n\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n\n    if loss_type == 'jaccard':\n        union = tf.reduce_sum(tf.square(y_pred_f)) + tf.reduce_sum(tf.square(y_true_f))\n\n    elif loss_type == 'sorensen':\n        union = tf.reduce_sum(y_pred_f) + tf.reduce_sum(y_true_f)\n\n    else:\n        raise ValueError(\"Unknown `loss_type`: %s\" % loss_type)\n\n    return (2. * intersection + smooth) \/ (union + smooth)","64a613cc":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","b6925cc5":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# #with tpu_strategy.scope():\n# inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n# Model_3D=Unet3D(inputs,num_classes=3)\n# Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n# Model_3D.summary()","bc9f8322":"def my_generator(x_train, y_train, batch_size):\n    data_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(x_train, x_train, batch_size)\n    mask_generator = ImageDataGenerator(\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rotation_range=10,\n            zoom_range=0.1).flow(y_train, y_train, batch_size)\n    while True:\n        x_batch, _ = data_generator.next()\n        y_batch, _ = mask_generator.next()\n        yield x_batch, y_batch","f07eb987":"!pip install nilearn","b5e0b2d5":"from nilearn.plotting import view_img, glass_brain, plot_anat, plot_epi","8557749d":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# image_batch, mask_batch = next(my_generator(X, y, 8))\n# fix, ax = plt.subplots(8,2, figsize=(8,20))\n# for i in range(8):\n    \n    \n#     ax[i,0].imshow(image_batch[i,:,:,0])\n#     ax[i,1].imshow(mask_batch[i,:,:,0])\n# plt.show()\n","897826c9":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","09b685a5":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nweight_saver = ModelCheckpoint('lung.h5', monitor='val_dice_coef', \n                                              save_best_only=True, save_weights_only=True)\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)","4e689773":"# X.shape","bf1fc3e3":"# y.shape","778a02e2":"# hist = Model_3D.fit(X, y,\n#                            steps_per_epoch = 20,\n                           \n#                            epochs=10, verbose=2,\n#                            )","2a92d9fd":"# np.array([X[0]]).shape","ac1c159a":"# segmented=Model_3D.predict(np.array([X[0]]))","fd80fb52":"# segmented_=segmented[0,:,:,:,0]","8684be56":"# segmented_.shape","24c71379":"# import SimpleITK as sitk\n# filtered_image = sitk.GetImageFromArray(segmented_)","248277e2":"# filtered_image ","d161f60a":"# import nibabel as nib\n# import numpy as np\n\n# data = np.arange(4*4*3).reshape(4,4,3)\n\n# new_image = nib.Nifti1Image(segmented_, affine=np.eye(4))\n\n# new_image_ = nib.Nifti1Image(np.array(X[0]), affine=np.eye(4))\n\n\n","f2cbd225":"# plot_anat(new_image)\n  \n","31f7bf57":"# view_img(new_image , new_image_)","6d2a7ae6":"# nib.save(new_image , '\/kaggle\/working\/segmented.nii')","bcbd8013":"# nib.save(new_image_ , '\/kaggle\/working\/original.nii')","541534b9":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/ct_scans\/'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","ecc6f563":"# out=LoadLungData(64, 64,200)\n# print(out.shape)","b195a9fe":"\n# import matplotlib.pyplot as plt\n# im_fdata=img.get_fdata()\n\n\n\n\n# plt.figure(figsize=(10,8))\n\n# # Iterate and plot random images\n# for i in range(30):\n#     plt.subplot(5, 6, i + 1)\n\n#     plt.imshow(out[0]['seg'][i,:,:])\n#     plt.axis('off')\n    \n# # Adjust subplot parameters to give specified padding\n# plt.tight_layout()  ","fff133d8":"# X=[out[i]['image'] for i in range(len(out))]\n# y=[out[i]['seg'] for i in range(len(out))]","528b26f4":"# X=np.array(X)\n# y=np.array(y)\n\n# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","6db93a8a":"# len(X_train)","155298b2":"# len(X_test)","0388949a":"# initial_epoch_of_training=0\n# TRAIN_CLASSIFY_LEARNING_RATE =1e-4\n# OPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\n# INPUT_PATCH_SIZE=(576,64,64, 1)\n# with tpu_strategy.scope():\n#     inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n#     Model_3D=Unet3D(inputs,num_classes=3)\n#     Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n#     Model_3D.summary()","a058da77":"# history = Model_3D.fit(X_train, y_train,\n#                            batch_size=2,\n#                            validation_data=(X_test,y_test),\n#                            epochs=50, verbose=2,\n#                            )\n# auc=max(history.history['dice_coe'])\n\n","376351dd":"\n\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('\/kaggle\/working\/singleinput'+'.csv')\n\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score single input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n# plt.savefig('\/kaggle\/working\/singleinput.png')\n# plt.show()\n","294650d1":"def cluster(img):\n            vectorized = img.reshape((-1,4))\n            vectorized = np.float32(vectorized)\n            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n            K = 4\n            attempts=10\n            ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)\n            center = np.uint8(center)\n            res = center[label.flatten()]\n            result_image = res.reshape((img.shape))\n            return result_image","94fa3acb":"from scipy import ndimage\nfrom skimage import filters","a660af4b":"from skimage.morphology import disk\n\ndef reshape_cluster2(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=filters.median(cv2.resize(image[:,:,i], ( 64, 64)),disk(1))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=filters.median(reshaped_image[:,i,:],disk(1))\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=filters.median(reshaped_image[i,:,:],disk(1))\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","326ea6f9":"from skimage.morphology import disk\n\ndef reshape_cluster(image, new_shape):\n  \n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        \n        reshaped_image[:,:,i]=cluster(cv2.resize(image[:,:,i], ( 64, 64)))\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]=cluster(reshaped_image[:,i,:])\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]=cluster(reshaped_image[i,:,:])\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","5aa6535e":"from skimage.morphology import disk\n\ndef reshape_cluster_spectral(image, new_shape):\n    \n    \n    import skimage.segmentation as seg\n\n\n\n    reshaped_image = np.zeros(new_shape)\n\n    print(reshaped_image.shape)\n    print(image.shape)\n    range_0=reshaped_image.shape[0]-image.shape[0]\n    range_1=reshaped_image.shape[1]-image.shape[1]\n    range_2=reshaped_image.shape[2]-image.shape[2]\n    \n    # if ((range_0>=0) and (range_1>=0)) and  (range_2>=0):\n    #reshaped_image[0:image.shape[0],0:image.shape[1],0:image.shape[2]]+=image\n    for i in range(image.shape[2]):\n        0\n        reshaped_image[:,:,i]= seg.slic(cv2.resize(image[:,:,i], ( 64, 64)),n_segments=30)\n\n    for i in range(reshaped_image.shape[1]):\n        \n        reshaped_image[:,i,:]= seg.slic(reshaped_image[:,i,:],n_segments=30)\n        \n        \n    for i in range(reshaped_image.shape[0]):\n        \n        reshaped_image[i,:,:]= seg.slic(reshaped_image[i,:,:],n_segments=30)\n    reshaped_image=reshaped_image.transpose(2,1,0)\n    print('Image reshaped ',reshaped_image.shape)\n    # else:\n    #   raise Exception(\"Invalid file shape\")\n       \n        \n    return reshaped_image","7329639c":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungMaskData(x_shape, y_shape,limit):\n    \n\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape(label, new_shape=( x_shape, y_shape,576))\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","ab5daa9a":"!pip install medpy\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom medpy.io import load\nimport cv2\nimport numpy as np\n\ndef LoadLungDataClusterData(x_shape, y_shape,limit):\n\n\n    image_dir = '\/kaggle\/input\/covid19-ct-scans\/lung_and_infection_mask'\n    label_dir = '\/kaggle\/input\/covid19-ct-scans\/infection_mask\/'\n\n    images = [f for f in listdir(image_dir) if (\n        isfile(join(image_dir, f)) and f[0] != \".\")]\n\n    out = []\n    count=0\n    for f in images:\n        \n        count+=1\n        if count<limit:\n            #print('Count ',count)\n            #print('Limit ',limit)\n\n            image, _ = load(os.path.join(image_dir, f))\n            label, _ = load(os.path.join(label_dir, f.replace('org_','')\n                                         .replace('org_covid-19-pneumonia-','')\n                                         .replace('covid-19-pneumonia-','')\n                                        .replace('-dcm','')))\n\n            if image.shape[0]!=label.shape[0]:\n               print('File and label with different shapes ',f)\n\n\n            #image=image\/255\n\n            try:\n\n                image = reshape_cluster(image, new_shape=( x_shape, y_shape,576))\n                #print('Image shape ',image.shape)\n                label = reshape_cluster(label, new_shape=( x_shape, y_shape,576)).astype(int)\n            except:\n                print('Error in file ',f)\n                raise\n\n            out.append({\"image\": image, \"seg\": label, \"filename\": f})\n        else:\n            break\n\n \n    print(f\"Processed {len(out)} files, total {sum([x['image'].shape[0] for x in out])} slices\")\n    return np.array(out)","7154758e":"out=LoadLungData(64, 64,100)","8a4bc8c3":"out_=LoadLungDataClusterData(64, 64,100)\n","e42bc10d":"out__=LoadLungMaskData(64, 64,100)","71925ac8":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[0]['seg'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","5973d27c":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(40,70,1):\n    plt.subplot(5, 6, i + 1-40)\n\n    plt.imshow(out_[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","636a9683":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out__[0]['image'][i,:,:]+out[0]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","ad7043f7":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(out[1]['image'][i,:,:]-out_[1]['image'][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","733a7124":"\nX=np.array([out[i]['image'] for i in range(len(out))])\ny=np.array([out[i]['seg'] for i in range(len(out))])\n","b30ecb69":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(y[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","43527d9f":"\nimport matplotlib.pyplot as plt\nim_fdata=img.get_fdata()\n\n\n\n\nplt.figure(figsize=(10,8))\n\n# Iterate and plot random images\nfor i in range(30):\n    plt.subplot(5, 6, i + 1)\n\n    plt.imshow(X[0][i,:,:])\n    plt.axis('off')\n    \n# Adjust subplot parameters to give specified padding\nplt.tight_layout()  ","0687d012":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","934eab41":"print(X_train.shape)\nprint(y_train.shape)","a2931333":"import tensorflow as tf\ninitial_epoch_of_training=0\nTRAIN_CLASSIFY_LEARNING_RATE =1e-4\nOPTIMIZER=tf.keras.optimizers.Adam(lr=TRAIN_CLASSIFY_LEARNING_RATE,epsilon=1e-5)\n\nINPUT_PATCH_SIZE=(576,64,64, 1)\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=(INPUT_PATCH_SIZE), name='CT')\n    \n    Model_3D=Unet3D(inputs,num_classes=3)\n    Model_3D.compile(optimizer=OPTIMIZER, loss=[dice_loss], metrics=['accuracy',dice_coe])\n    Model_3D.summary()","f0d9b2f0":"\n# history = Model_3D.fit(X_train, y_train,\n#                            batch_size=2,\n#                            validation_data=(np.array(X_test),np.array(y_test)),\n#                            epochs=50, verbose=2,\n#                            )\n# df_history=pd.DataFrame.from_dict(history.history)\n# df_history.to_csv('\/kaggle\/working\/withoutsoby.csv')\n# from matplotlib.pyplot import figure\n# figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\n\n# plt.plot(history.history['dice_coe'])\n# plt.plot(history.history['val_dice_coe'])\n# plt.title('Dice score multi input')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['dice', 'val_dice'], loc='upper left')\n\n\n\n","cf8c4c5f":"Model_3D.load_weights('\/kaggle\/input\/segmentationlung\/single.h5')","ca9aecff":"\nfor j in range(20):\n\n    segmented=Model_3D.predict(np.array([X[j]]))\n    segmented_=segmented[0,:,:,:,0]\n    print(len(segmented_[segmented_>0]))\n\n    import matplotlib.pyplot as plt\n    im_fdata=img.get_fdata()\n\n\n\n\n    plt.figure(figsize=(10,8))\n\n    # Iterate and plot random images\n    for i in range(0,30):\n        plt.subplot(6, 6, i + 1)\n\n        plt.imshow(segmented_[i,:,:])\n        plt.axis('off')\n\n    # Adjust subplot parameters to give specified padding\n    plt.tight_layout()  \n    plt.show()\n    \n    import nibabel as nib\n    import numpy as np\n\n    data = np.arange(4*4*3).reshape(4,4,3)\n\n    new_image = nib.Nifti1Image(X[1], affine=np.eye(4))\n    nib.save(new_image , '\/kaggle\/working\/infection'+str(j)+'.nii')","2af7fafe":"## Lung CT Segmentation","73a462d3":"## Load Sample Files"}}