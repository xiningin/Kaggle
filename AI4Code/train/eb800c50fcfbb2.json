{"cell_type":{"de7b2211":"code","18dbfc91":"code","cfc77b88":"code","d432b41f":"code","dcd2d07a":"code","7b001433":"code","c9847170":"code","b9a1b39a":"code","2ae9f484":"code","67121e85":"code","674a267f":"code","e20d3811":"code","998b8e55":"code","3e935c75":"code","8346a487":"code","05ce05b0":"code","1c5dd33e":"code","a0093fd5":"code","6641c953":"code","b1e672db":"markdown","c626342b":"markdown","968e522b":"markdown","91d6862b":"markdown","e6224c3c":"markdown","6bcd3674":"markdown","e6f75cf4":"markdown","3116abbe":"markdown","be31d230":"markdown","66943456":"markdown"},"source":{"de7b2211":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nflooded_img = mpimg.imread('..\/input\/louisiana-flood-2016\/train\/10003.png')\nnormal_img = mpimg.imread('..\/input\/louisiana-flood-2016\/train\/10003_1.png')\n\nplt.subplot(1,2,1)\nplt.imshow(flooded_img)\nplt.subplot(1,2,2)\nplt.imshow(normal_img)\nplt.tight_layout()\nplt.show()","18dbfc91":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nimport numpy as np\n\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader,Dataset\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom PIL import Image\nimport os\nimport time\nfrom tqdm.autonotebook import tqdm\n\n%matplotlib inline","cfc77b88":"img_augmentation = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean = [0.485, 0.456, 0.406], \n                             std = [0.229, 0.224, 0.225])       \n    ])","d432b41f":"class LouisianaDataset(Dataset):\n    def __init__(self, type):\n        if type == 'train':\n            self.df = pd.read_csv(\"..\/input\/louisiana-flood-2016\/train.csv\")\n            self.image_folder = \"..\/input\/louisiana-flood-2016\/train\/\"\n        else:\n            self.df = pd.read_csv(\"..\/input\/louisiana-flood-2016\/test.csv\")\n            self.image_folder = \"..\/input\/louisiana-flood-2016\/test\/\"\n        \n        self.imgs = self.df[self.df['Normal']==1]\n        self.imgs = self.imgs['Image ID'].values\n\n    def __getitem__(self, idx):\n        before_img_path = os.path.join(self.image_folder, self.imgs[idx])\n        flood_img_path = glob(self.image_folder+self.imgs[idx].split('.')[0]+'_*')[0]\n\n        before_img = Image.open(before_img_path)\n        before_img = img_augmentation(before_img)\n        flood_img = Image.open(flood_img_path)\n        flood_img = img_augmentation(flood_img)\n\n        label = int(flood_img_path.split('_')[-1].split('.')[0])\n        \n        return (before_img,flood_img,torch.as_tensor([label], dtype=torch.float))\n\n    def __len__(self):\n        return len(self.imgs)","dcd2d07a":"train_data = LouisianaDataset('train')\nprint('No. of training samples: ',len(train_data))\nvalid_data = LouisianaDataset('valid')\nprint('No. of validation samples: ',len(valid_data))","7b001433":"num_workers = 0\nbs = 8\n\ntrain_loader = DataLoader(train_data, batch_size=bs, shuffle=True, num_workers=num_workers)\nvalid_loader = DataLoader(valid_data, batch_size=bs, shuffle=True, num_workers=num_workers)","c9847170":"import torchvision.models as models\n\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.network1 = models.mobilenet_v2(pretrained=True)\n        self.network2 = models.mobilenet_v2(pretrained=True)\n        self.distance = torch.nn.PairwiseDistance(keepdim=True)\n        self._bn = torch.nn.BatchNorm1d(1)\n        self._act = torch.nn.Sigmoid()\n        \n    def forward(self, input1, input2):\n        feats1 = self.network1(input1)\n        feats2 = self.network2(input2)\n        distance = self.distance(feats1, feats2)\n        output = self._bn(distance)\n        output = self._act(output)\n        return output\n        ","b9a1b39a":"%%capture\nmodel = SiameseNetwork()\nmodel.cuda()","2ae9f484":"num_epochs = 25\ncriterion = torch.nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.0005)","67121e85":"train_losses = []\nvalid_losses = []","674a267f":"start_ts = time.time()\nfor epoch in range(num_epochs):\n    # ----------------- TRAINING  -------------------- \n    train_loss = 0.0\n    # progress bar (works in Jupyter notebook too!)\n    progress = tqdm(enumerate(train_loader), desc=\"Train_loss: \", total=len(train_loader))\n    # set model to training\n    model.train()\n    \n    for i, data in progress:\n        img0, img1, label = data\n        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n        \n        # training step for single batch\n        model.zero_grad()\n        optimizer.zero_grad()\n        pred = model(img0,img1)\n        loss = criterion(pred,label)\n        loss.backward()\n        optimizer.step()\n\n        # getting training quality data\n        train_loss += loss.item()\n\n        # updating progress bar\n        progress.set_description(\"Train_loss: {:.4f}\".format(train_loss\/(i+1)))\n        \n    # releasing unceseccary memory in GPU\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    train_loss = train_loss\/len(train_loader)\n\n    print(f\"Epoch {epoch+1}\/{num_epochs}, training loss: {train_loss}\")\n\n    train_losses.append(train_loss)\n    \n    # ----------------- VALIDATION -------------------- \n    \n    valid_loss = 0.0\n    # progress bar (works in Jupyter notebook too!)\n    progress = tqdm(enumerate(valid_loader), desc=\"Valid_loss: \", total=len(valid_loader))\n    # set model to training\n    model.eval()\n    \n    for i, data in progress:\n        img0, img1, label = data\n        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n        \n        pred = model(img0,img1)\n        loss = criterion(pred,label)\n\n        # getting validation quality data\n        valid_loss += loss.item()\n\n        # updating progress bar\n        progress.set_description(\"Valid_loss: {:.4f}\".format(train_loss\/(i+1)))\n        \n    # releasing unceseccary memory in GPU\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    valid_loss = valid_loss\/len(valid_loader)\n\n    print(f\"Epoch {epoch+1}\/{num_epochs}, valid loss: {valid_loss}\")\n\n    valid_losses.append(valid_loss)\n    \n    print('- '*50)\n\nprint(f\"Training time: {time.time()-start_ts}s\")","e20d3811":"plt.plot(train_losses, label=\"Training Loss\")\nplt.plot(valid_losses, label=\"Validation Loss\")\n\nplt.title('Train loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.legend()\nplt.savefig('traing_progress.png')\nplt.show()","998b8e55":"print(\"Inference\")\n\nmean = np.array([0.456, 0.406, 0.485])\nstd = np.array([0.224, 0.225, 0.229])\n\nmodel.eval()\n\ncolumns = 2; rows = 10\nfig=plt.figure(figsize=(columns*5, rows*5))\nfor i in range(0, columns*rows, 2):\n    image0, image1, label = valid_data[i]\n    img0, img1 = image0[None,:,:,:], image1[None,:,:,:]\n    img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n    pred = model(img0,img1)\n    \n    fig.add_subplot(rows,columns,i+1)\n    image0 = image0.permute(1, 2, 0).numpy()\n    image0 = image0 * std\n    image0 = image0 + mean\n    plt.imshow(image0)\n    plt.title(\"Before flood\")\n    plt.tight_layout()\n    fig.add_subplot(rows,columns,i+2)\n    image1 = image1.permute(1, 2, 0).numpy()\n    image1 = image1 * std\n    image1 = image1 + mean\n    plt.imshow(image1)\n    ftitle_true = 'Flooded' if int(label.cpu().detach().numpy())==1 else 'Not flooded'\n    plt.title('Label: '+ftitle_true +', Dissimilarity: '+str(round(float(pred.cpu().detach().numpy()), 4)))\n    plt.tight_layout()\n\nplt.show()","3e935c75":"all_preds = torch.tensor([]).cuda()\nall_targets = torch.tensor([]).cuda()\n\nfor i, data in enumerate(valid_loader):\n    model.eval()\n    \n    img0, img1, label = data\n    img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n    pred = model(img0,img1)\n    all_preds = torch.cat((all_preds, pred), dim=0)\n    all_targets = torch.cat((all_targets, label), dim=0)\n    \nall_preds = all_preds.squeeze().cpu().detach().numpy()\nall_targets = all_targets.squeeze().cpu().detach().numpy()\ntorch.cuda.empty_cache()","8346a487":"flood_preds = []\nnormal_preds = []\nfor i, label in enumerate(all_targets):\n    if label == np.float32(1.0):\n        flood_preds.append(float(all_preds[i]))\n    else:\n        normal_preds.append(float(all_preds[i]))","05ce05b0":"fig = plt.figure(tight_layout=True)\nfig.add_subplot(1, 2, 1)\nplt.hist(flood_preds)\nplt.title('Flood hist')\nplt.xlabel(\"Dissimilarity\")\nplt.ylabel(\"No of examples\")\nfig.add_subplot(1, 2, 2)\nplt.hist(normal_preds)\nplt.title('Normal hist')\nplt.xlabel(\"Dissimilarity\")\nplt.ylabel(\"No of examples\")\nplt.show()","1c5dd33e":"threshold = np.mean(normal_preds) + np.std(normal_preds)\nthreshold","a0093fd5":"all_preds[all_preds > threshold] = 1\nall_preds[all_preds != 1] = 0","6641c953":"from sklearn.metrics import confusion_matrix\nprint(\"Confusion Matrix : \")\nconfusion_matrix(all_preds, all_targets)","b1e672db":"# References\n- https:\/\/www.paperswithcode.com\/paper\/siamese-neural-networks-for-one-shot-image\n- https:\/\/keras.io\/examples\/vision\/siamese_network\/\n- https:\/\/sorenbouma.github.io\/blog\/oneshot\/","c626342b":"# Load the dataset","968e522b":"# Introduction\n\nThe idea presented in this notebook is to find the dissimilarity between a pair of satellite images of the same geograhical region. A pair of satellite image consist of an image taken during flood, and an image taken few days before the flood.\n\nAn example image pair is given below,\n","91d6862b":"# Inference","e6224c3c":"# Model\n\n![Untitled Diagram.png](attachment:1859e0b5-5f35-4b91-b04c-3a9e8a6febc3.png)","6bcd3674":"# Summary of prediction results","e6f75cf4":"# Imoprt libraries","3116abbe":"If the dissimilarity is high it means, that particular geographical region is flooded. Low value of dissimilarity means, that region is less affected by flood.\n\nThis approach to figure out flooded regions can be applied to all other natural disaster as well, since the main idea here is to measure the changes of a particular region before and during the disaster.","be31d230":"# Training","66943456":"# Preparing the data"}}