{"cell_type":{"1e636acc":"code","b06cd67d":"code","8fb718f4":"code","34e0cf06":"code","9aa42ca1":"code","221a1f26":"code","91cb6f93":"code","7385e7df":"code","628e94c4":"code","f780e2bf":"code","a9be15a6":"code","ed741d91":"code","c778b0c6":"markdown","1d6aa44a":"markdown","70f04832":"markdown","a30cd0f5":"markdown","1139a666":"markdown","419eedd5":"markdown","51f1a4b8":"markdown","daee5f2a":"markdown","16db9432":"markdown","a1fd031c":"markdown"},"source":{"1e636acc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import PolynomialFeatures # \uc88b\uc740 feature\ub4e4\ub07c\ub9ac \uacf1\ud558\uba74 \ub354 \uc88b\uc740 feature\ub97c \ub9cc\ub4e4\uc218\ub3c4 \uc788\uc74c.! \uadf8\ub54c \uacf1\ud558\uae30\ub97c \ud558\ub824\uba74 'PolynomialFeatures'\uac00 \ud544\uc694\nfrom sklearn.preprocessing import StandardScaler\n\n\n# VarianceThreshold : \uc88b\uc740 feature\ub97c \ucc3e\uae30 \uc704\ud574 \uc0ac\uc6a9\n# variance\uac00 \uc791\ub2e4\ub294 \ub9d0\uc740 \uc815\ubcf4\uac00 \uc801\ub2e4\ub294 \ub9d0\uacfc \ube44\uc2b7\n# \ub2e4\uc591\ud558\uac8c \uc2a4\ud399\ud2b8\ub7fc\uc774 \ub113\uc5b4\uc57c \uc5bb\uc744 \uc218 \uc788\ub294 \uc815\ubcf4\uac00 \uc788\uc744 \ud150\ub370  \n# example : 1\uac1c\uc758 feature\uc640 \uadf8 \uc548\uc5d0 100\uac1c\uc758 sample(\uc5ec\uae30\uc11c sample\uc740 [0 or 1]\uc758 \uac12\uc744 \uac00\uc9c4\ub2e4\uace0 \ud558\uba74)\uc774 \uc788\ub2e4\uace0 \ud560\ub54c, sample\uc758 \uad6c\uc131\uc774 1\uc774 99\uac1c\uace0 0\uc774 1\uac1c\ub2e4. \n# --> variance\uac00 \uac70\uc758 \uc5c6\uace0 \uc5bb\uc744 \uc815\ubcf4\uac00 \uc5c6\ub294 feature\ub77c\uace0 \ud310\ub2e8\ub428 --> \uadf8\ub7f0 feature\ub97c \uc81c\uac70\ud558\uae30 \uc704\ud574 'VarianceThreshold'\ub97c \uc0ac\uc6a9!\n\nfrom sklearn.feature_selection import VarianceThreshold\n\n\n# SelectFromModel : model\ub9c8\ub2e4 \ud559\uc2b5\uc744 \ud560 \ub54c Feature\uc758 \uc911\uc694\ub3c4\ub97c \uacb0\uc815\ud558\uac8c \ub418\ub294\ub370 \uadf8 \uc911\uc694\ub3c4\uc5d0 \ub530\ub77c\uc11c selection\ud558\ub294 \uac83.\n# \uacb0\uad6d \ubaa8\ub378\uc744 \ud558\ub098\uc529 \ud559\uc2b5\uc744 \ud574\uc57c \ud568. \ub9cc\uc57d feature\uac00 1000\uac1c\uba74 1000\uac1c\uc758 \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4\ub294 \ub73b \nfrom sklearn.feature_selection import SelectFromModel\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.ensemble import RandomForestClassifier\n\npd.set_option('display.max_columns', 100) # \ucd5c\ub300 100\uac1c\uae4c\uc9c0 \uc5f4\uc758 \uc218\ub97c \ubcf4\uc5ec\uc8fc\ub3c4\ub85d\n\n\n\n# from sklearn.preprocessing import Imputer \n\n# ---->\n\n# \ud574\uacb0 \ubc29\ubc95\n# Imputer 3 \ubc84\uc804 \uc804\uc5d0 \uc0ac\uc6a9\ub418\uc9c0 \uc54a\uc73c\uba70 0.22\uc5d0\uc11c \uc81c\uac70\ub418\uc5c8\ub2e4. \n# Imputer \ubaa8\ub4c8\uc744 \ubd88\ub7ec\uc624\uae30 \uc704\ud574\uc120 sklearn.impute\ub97c \uc0ac\uc6a9\ud558\uba74 \ub41c\ub2e4.\n# Imputer : \ube44\uc5b4\uc838\uc788\ub294 null value\ub97c \ucc44\uc6b0\ub294 sklearn \ub0b4\uc7a5 \ud568\uc218\n\nfrom sklearn.impute import SimpleImputer","b06cd67d":"# DEBUG = True\nDEBUG = False\n# debugging \ub9c8\ubb34\ub9ac \ud6c4 \n# DEBUG = False \uc0ac\uc6a9\ud574\uc11c \ud559\uc2b5 \ub9c8\ubb34\ub9ac \ud558\uae30","8fb718f4":"if DEBUG:\n    NROWS = 50000\nelse:\n    NROWS = None","34e0cf06":"%time\n\ntrain = pd.read_csv('..\/input\/porto-seguro-safe-driver-prediction\/train.csv', nrows = NROWS)\ntest = pd.read_csv('..\/input\/porto-seguro-safe-driver-prediction\/test.csv', nrows = NROWS)\n\n\n##--------------------train set\uc774 \ub108\ubb34 \ud074\ub54c!!-------------------------##\n\n# train = train.sample(frac=0.2)\n# train data\uc758 20%\ub97c sample\ub85c \uac00\uc838\uc624\uaca0\ub2e4.\n# \uc8fc\ub85c data\uc758 \ud06c\uae30\uac00 \ub108\ubb34 \ud074\ub54c ex)train data\uac00 80,000,00\uac1c \uc815\ub3c4 \uc788\ub2e4\uace0 \ud558\uba74 \n# \uac04\ub2e8\ud55c EDA\uc815\ub3c4\uc640 feature engineering \uc9c4\ud589\ud560 \ub54c\ub294 sample\ub85c 10~20%\uc815\ub3c4 (\ubcf8\uc778 \ucef4\ud4e8\ud130 \uc0ac\uc591\uc5d0 \ub530\ub77c) sampling\uc744 \ud574\uc11c \uc9c4\ud589\ud558\uba74 \uc218\uc6d4\ud558\ub2e4.! (\uc5ec\uae30\uc11c sampling\uc740 random_sampling)\n# \uc804\uccb4 set\uc744 \uac00\uc9c0\uace0 EDA\ub97c \ud558\ub294\uac83\uc740 \ubb34\ubaa8\ud558\uace0..\uc27d\uc9c0 \uc54a\ub2e4","9aa42ca1":"train.shape","221a1f26":"train.head()","91cb6f93":"train.tail()","7385e7df":"cat_cols = [col for col in train.columns if 'cat' in col]","628e94c4":"# for col in cat_cols:\n#     print(col, train[col].value_counts().shape[0])   #\uc5ec\uae30\uc11c shape[0]\uc740 \uac01 col\uc758 unique\ud55c \ud589\uc758 \uc218\ub97c \uac00\uc838\uc624\uae30 \uc704\ud568\n\nfor col in cat_cols:\n    print(col, train[col].nunique())   # 'nunique'\ub97c \uc0ac\uc6a9\ud574\ub3c4 \ub428","f780e2bf":"train.drop_duplicates()\ntrain.shape","a9be15a6":"test.shape","ed741d91":"train.info()","c778b0c6":"> we can see 'high cardinality' in the 'ps_car_11_cat' category! **104 !!**","1d6aa44a":"##### There are only about 600,000 train data for this competition, so I'll just read them all!","70f04832":">  let's investigate how many variables of each type we have! ","a30cd0f5":"> So later on we can create dummy variables for the 14 categorical variables. The bin variables are already binary and do not need dummification.! **(dummification == one-hot encoding)**","1139a666":"> we can see 'categorical variables of which the category values are integers! let's check it out","419eedd5":"- no duplicate rows, so that's fine","51f1a4b8":"#### Dummy variable\n\n1. what is Dummy variable\n- categorical variable -> continuous variable\n- \ubc94\uc8fc\ud615 \ubcc0\uc218\ub97c \uc5f0\uc18d\ud615 \ubcc0\uc218\ub85c \ubcc0\ud658. \uc989 \uc5f0\uc18d\ud615 \ubcc0\uc218'\uc2a4\ub7fd\uac8c' \ub9cc\ub4dc\ub294 \uac83\n\n2. Why we should make Dummy variable\n- \ubc94\uc8fc\ud615 \ubcc0\uc218\ub85c\ub294 \uc0ac\uc6a9\ud560 \uc218 \uc5c6\uace0 \uc5f0\uc18d\ud615 \ubcc0\uc218\ub85c\ub9cc \uac00\ub2a5\ud55c \ubd84\uc11d\uae30\ubc95\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ud574\uc90c.\n- linear regression, logistic regression : \uc124\uba85\ubcc0\uc218\uac00 \uc5f0\uc18d\ud615 \ubcc0\uc218\uc5ec\uc57c \uc0ac\uc6a9 \uac00\ub2a5.\n- \ub9cc\uc57d, \uc124\uba85\ubcc0\uc218 \uc911 \ubc94\uc8fc\ud615 \ubcc0\uc218\uac00 \uc788\ub2e4\uba74, \uadf8 \ubcc0\uc218\ub97c \ub354\ubbf8 \ubcc0\uc218\ub85c \ubcc0\ud658\ud574 \ubd84\uc11d\uc5d0 \uc0ac\uc6a9\n\n3. The features of Dummy variable\n- 0\ub610\ub2941\uc758 \uac12\uc744 \uac00\uc9c4\ub2e4\n- \ub354\ubbf8\ubcc0\uc218\ub294 \uc6d0\ub798 \ubc94\uc8fc\ud615 \ubcc0\uc218\uc758 \ubc94\uc8fc \uac1c\uc218\ubcf4\ub2e4 1\uac1c \uc801\uac8c \ub9cc\ub4e4\uc5b4\uc9c4\ub2e4(\ub354\ubbf8 \ubcc0\uc218\ub85c \ub9cc\ub4e4\uc5b4\uc9c0\uc9c0 \uc54a\uace0 \uc0dd\ub7b5\ub418\ub294 \ubc94\uc8fc\ub294 \uae30\uc900\uc774 \ub418\ub294 \uac12\uc774\ub77c\uace0 \uc774\ud574\ud558\uba74 \ub428)\n\n4. Make Dummy variable\n- \ubc94\uc8fc\ud615 \ubcc0\uc218\uc758 \ubc94\uc8fc \uc911 \uae30\uc900\uc774 \ub418\ub294 \uac12\uc744 \uc815\ud55c\ub2e4\n- \uae30\uc900\uc774 \ub418\ub294 \ubcc0\uc218\ub97c \uc81c\uc678\ud558\uace0 \ub354\ubbf8\ubcc0\uc218\ub97c \ub9cc\ub4e0\ub2e4\n\n5. The meaning of Dummy variable\n- \ud68c\uadc0\uc2dd\uc5d0\uc11c \ud574\ub2f9 \ubcc0\uc218\uc758 \ud6a8\uacfc\ub97c 0\ub610\ub294 \uc0c1\uc218\uac12\uc73c\ub85c \ub9cc\ub4e4\uc5b4 \uc900\ub2e4\n- \ub354\ubbf8\ubcc0\uc218\ub294 \ud68c\uadc0 \uae30\uc6b8\uae30\ub97c \ubc14\uafb8\uc9c0\ub294 \uc54a\uace0 \uc808\ud3b8\ub9cc \ubc14\uafb8\uc5b4 \ud3c9\ud589\ud558\uac8c \uc6c0\uc9c1\uc774\uac8c \ud558\ub294 \uc5ed\ud560\uc744 \ud55c\ub2e4","daee5f2a":"> let's see if there are duplicate rows in the training data. Using 'drop_duplicates()'\n","16db9432":"> DEBUGGING\n- DEBUGGING \ud558\ub294\ub370 \uad73\uc774 \uc804\uccb4 dataset\uc744 \ub2e4 \uc77d\uc5b4\uc11c \ud560 \uc774\uc720\ub294 \uc5c6\ub2e4..\n- DEBUGGING\uc744 \ud1b5\ud574 model\uc744 \ub9cc\ub4e4\uae30, ensemble,..\ub4f1\uc758 \uacfc\uc815\uc744 checking \ud574\ubcf4\uace0 \uc798 \ub418\uba74 \n- DEBUG = False \ub97c \ud1b5\ud574 \ub2e4\uc2dc \uc804\uccb4 dataset\uc744 \ub2e4 \uc77d\uc5b4\uc11c \ud559\uc2b5\uc744 \uc9c4\ud589\ud558\uba74 \ub428","a1fd031c":"# **Binary classification**\n## Tabular data"}}