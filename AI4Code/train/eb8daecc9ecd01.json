{"cell_type":{"bf93e498":"code","9afcb9da":"code","8f3291d0":"code","06c458db":"code","c6a9b08e":"code","a352a02c":"code","a0dc81f7":"code","8b8a0499":"code","60bf529c":"code","932b5cef":"code","97673dc1":"code","dbfe5246":"code","20984342":"code","8aa8567f":"code","27983b02":"code","11d4cbf2":"code","dbba9652":"code","1de01533":"code","1577e005":"code","8e8ba788":"code","95d2642e":"code","18020aac":"code","e7143e89":"code","182a4f72":"code","40e7c2ba":"code","5186ec81":"code","65c5f725":"code","b2274a33":"code","374591f7":"code","5bae50a2":"code","b830708d":"code","cfb666c5":"markdown","1f1d6a90":"markdown","415367cd":"markdown","88dc7dc1":"markdown","5fc0b0c4":"markdown"},"source":{"bf93e498":"#An attempt at using a siamese network to measure difference btween cars.  Will eventually develop\n#into one-shot learning","9afcb9da":"#import necessary libraries\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport cv2\nimport matplotlib.pyplot as plt\nimport math\nimport random\n%matplotlib inline","8f3291d0":"#set the path of training data\npath_root='\/kaggle\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/train'","06c458db":"#list the classes\nclass_names=os.listdir(path_root)\nclass_names.sort()\nprint(class_names)","c6a9b08e":"#loop to determine biggest\/smallest picture in training set and total number of pictures\nmin_width=9999\nmin_height=9999\nmax_width=0\nmax_height=0\npicture_count=0\npicture_list=[]\naspect_ratio=[]\nfor i in class_names:\n    path=os.path.join(path_root,i)\n    pictures=os.listdir(path)\n    pictures.sort()\n    for j in pictures:\n        img=cv2.imread(os.path.join(path,j),0)\n        min_width=min(min_width,np.shape(img)[1])\n        min_height=min(min_height,np.shape(img)[0])\n        max_width=max(max_width,np.shape(img)[1])\n        max_height=max(max_height,np.shape(img)[0])\n        picture_count=picture_count+1\n        aspect_ratio.append(np.shape(img)[1]\/np.shape(img)[0])","a352a02c":"plt.hist(aspect_ratio)\nplt.show()","a0dc81f7":"#most common aspect ratio.  I used 135x100px for the input image size\nnp.median(aspect_ratio)","8b8a0499":"print([min_width,min_height,max_width,max_height,picture_count])","60bf529c":"resize_width=135\nresize_height=100\nprint([resize_width,resize_height])","932b5cef":"def pair_generator(batch_size,training=True):\n    good_pairs=math.ceil(batch_size\/2)\n    bad_pairs=batch_size-good_pairs\n    left_pictures=[]\n    right_pictures=[]\n    labels=[]\n    if training:\n        path_root=('\/kaggle\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/train')\n        class_names=os.listdir(path_root)\n    else:\n        path_root=('\/kaggle\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/test')\n        class_names=os.listdir(path_root)\n    while True:\n        pair_classes=random.choices(class_names,k=batch_size)\n        for i in range(batch_size):\n            if i<good_pairs:\n                pics=random.sample(os.listdir(os.path.join(path_root,pair_classes[i])),k=2)\n                img=cv2.imread(os.path.join(path_root,pair_classes[i],pics[0]))\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                left_pictures.append(img)\n                img=cv2.imread(os.path.join(path_root,pair_classes[i],pics[1]))\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                right_pictures.append(img)\n                labels.append(1)\n            else:\n                classes=random.sample(pair_classes,k=2)\n                pic1=random.sample(os.listdir(os.path.join(path_root,classes[0])),k=1)\n                img=cv2.imread(os.path.join(path_root,classes[0],pic1[0]))\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                left_pictures.append(img)\n                pic2=random.sample(os.listdir(os.path.join(path_root,classes[1])),k=1)\n                img=cv2.imread(os.path.join(path_root,classes[1],pic2[0]))\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                right_pictures.append(img)\n                labels.append(0)\n        left_pictures=np.asarray(left_pictures)\n        right_pictures=np.asarray(right_pictures)\n        labels=np.asarray(labels)\n        out=([left_pictures,right_pictures],labels)\n        yield out\n        left_pictures=[]\n        right_pictures=[]\n        labels=[]\n        ","97673dc1":"#get 10 pairs to demonstrate the generator\nbatch_size=10\nfoo=pair_generator(batch_size)\nbar=next(foo)","dbfe5246":"#verify the shape of the output tensor.  [0][0] is the left image\n#expect 10 pairs, 100x135px images, 3 color channels\nnp.shape(bar[0][0])","20984342":"#plot the pairs to demonstrate output\ncount=1\nplt.figure(figsize=(40,40))\nfor i in range(batch_size):\n    for j in range(2):\n        plt.subplot(batch_size,2,count)\n        plt.imshow(bar[0][j][i])\n        count=count+1\n        plt.xlabel('Truth: '+str(bar[1][i]),fontsize=24)\n        plt.xticks([])\n        plt.yticks([])\nplt.show()","8aa8567f":"def make_model():\n    shape=(100,135,3)\n    left_input=keras.Input(shape)\n    right_input=keras.Input(shape)\n    model=keras.Sequential()\n    model.add(keras.layers.Conv2D(32,8,activation='relu',padding='same',input_shape=shape))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.MaxPooling2D(padding='same'))\n    model.add(keras.layers.Conv2D(64,4,activation='relu',padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.MaxPooling2D(padding='same'))\n    model.add(keras.layers.Conv2D(128,4,activation='relu',padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.MaxPooling2D(padding='same'))\n    model.add(keras.layers.Conv2D(256,4,activation='relu',padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.MaxPooling2D(padding='same'))\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(2048,activation='relu'))\n    encoded_l=model(left_input)\n    encoded_r=model(right_input)\n    L1_layer = keras.layers.Lambda(lambda tensors:tf.math.abs(tensors[0] - tensors[1]))\n    L1_distance = L1_layer([encoded_l, encoded_r])\n    prediction = keras.layers.Dense(1,activation='sigmoid')(L1_distance)\n    siamese_net = keras.Model(inputs=[left_input,right_input],outputs=prediction)\n    return siamese_net\n    ","27983b02":"model=make_model()","11d4cbf2":"model.compile(optimizer='adam',loss='BinaryCrossentropy',metrics=['Accuracy'])","dbba9652":"model.summary()","1de01533":"prayers=pair_generator(128)","1577e005":"#train the model.  128 batch size times 64 setps is approximately the entire training set.\n#100 Epochs is around 4 hours of training.  Note the CPU load from resizing the images\n#in the pair generator is by far the limiting factor\nmodel.fit_generator(prayers,epochs=200,steps_per_epoch=64,verbose=1)","8e8ba788":"#generate a batch to compare the prediction to actual labels visually\nbatch_size=10\nresults=pair_generator(batch_size,training=False)\ntest_data=next(results)\ntest_x=test_data[0]\ntest_y=test_data[1]\nout=model.predict(test_x,steps=1,verbose=1)","95d2642e":"count=1\nplt.figure(figsize=(40,40))\nfor i in range(batch_size):\n    for j in range(2):\n        plt.subplot(batch_size,2,count)\n        plt.imshow(test_x[j][i])\n        count=count+1\n        plt.ylabel('Truth: '+str(test_y[i]),fontsize=24)\n        plt.xlabel('Predicted: '+str(int(out[i][0])),fontsize=24)\n        plt.xticks([])\n        plt.yticks([])\nplt.show()","18020aac":"path_root=('\/kaggle\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/test')\nclass_names=os.listdir(path_root)","e7143e89":"#find the number of pictures in the test set\npicture_count=0\nfor i in class_names:\n    path=os.path.join(path_root,i)\n    pictures=os.listdir(path)\n    pictures.sort()\n    for j in pictures:\n        picture_count=picture_count+1\nprint(picture_count)","182a4f72":"#generate arrays of true and predicted values for the entire test set\ni=0\nfinal_predicted_y=[]\nfinal_true_y=[]\nwhile i<picture_count:\n    results=pair_generator(128,training=False)\n    test_data=next(results)\n    test_x=test_data[0]\n    test_y=test_data[1]\n    out=model.predict(test_x,steps=1,verbose=0)\n    out=np.reshape(out,128)\n    final_predicted_y.append(out)\n    final_true_y.append(test_y)\n    i=i+128\nfinal_predicted_y=np.asarray(final_predicted_y)\nfinal_predicted_y=np.reshape(final_predicted_y,(-1,1))\nfinal_true_y=np.asarray(final_true_y)\nfinal_true_y=np.reshape(final_true_y,(-1,1))","40e7c2ba":"#confusion matrix of results\nfoo=confusion_matrix(final_true_y,np.round(final_predicted_y))\nprint(foo)","5186ec81":"robs_class='Ferrari FF Coupe 2012'\nrobs_car='\/kaggle\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/train\/Ferrari FF Coupe 2012\/05423.jpg'","65c5f725":"img=cv2.imread(robs_car)\nimg[0]=img[0]\/255\nimg[1]=img[1]\/255\nimg=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg=cv2.resize(img,(resize_width,resize_height))","b2274a33":"plt.imshow(img)\nplt.show()","374591f7":"def one_shot_generator(batch_size):\n    good_pairs=math.ceil(batch_size\/2)\n    bad_pairs=batch_size-good_pairs\n    left_pictures=[]\n    right_pictures=[]\n    labels=[]\n    path_root=('\/kaggle\/input\/stanford-car-dataset-by-classes-folder\/car_data\/car_data\/test')\n    class_names=os.listdir(path_root)\n    while True:\n        for i in range(batch_size):\n            if i<good_pairs:\n                pics=random.sample(os.listdir(os.path.join(path_root,robs_class)),k=1)\n                img=cv2.imread(robs_car)\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                left_pictures.append(img)\n                img=cv2.imread(os.path.join(path_root,robs_class,pics[0]))\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                right_pictures.append(img)\n                labels.append(1)\n            else:\n                classes=random.sample(class_names,k=1)\n                img=cv2.imread(robs_car)\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                left_pictures.append(img)\n                pic2=random.sample(os.listdir(os.path.join(path_root,classes[0])),k=1)\n                img=cv2.imread(os.path.join(path_root,classes[0],pic2[0]))\n                img[0]=img[0]\/255\n                img[1]=img[1]\/255\n                img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img=cv2.resize(img,(resize_width,resize_height))\n                right_pictures.append(img)\n                labels.append(0)\n        left_pictures=np.asarray(left_pictures)\n        right_pictures=np.asarray(right_pictures)\n        labels=np.asarray(labels)\n        out=([left_pictures,right_pictures],labels)\n        yield out\n        left_pictures=[]\n        right_pictures=[]\n        labels=[]\n        ","5bae50a2":"batch_size=10\none_shot=one_shot_generator(batch_size)\ntest_data=next(one_shot)\ntest_x=test_data[0]\ntest_y=test_data[1]\nout=model.predict(test_x,steps=1,verbose=1)","b830708d":"#Lets see how this works\ncount=1\nplt.figure(figsize=(40,40))\nfor i in range(batch_size):\n    for j in range(2):\n        plt.subplot(batch_size,2,count)\n        plt.imshow(test_x[j][i])\n        count=count+1\n        plt.ylabel('Truth: '+str(test_y[i]),fontsize=24)\n        plt.xlabel('Predicted: '+str(int(out[i][0])),fontsize=24)\n        plt.xticks([])\n        plt.yticks([])\nplt.show()","cfb666c5":"Define a siamese model.  The sequential model is used by both sides of the net.  The L1 layer is a simple absoulte value of the difference between the two tensors.","1f1d6a90":"The pictures in the dataset are all different sizes.  I tried a few different strategies, but settled on resizing to a small image at the most common aspect ratio.","415367cd":"This generator is modified for one-shot learning.  The left image will always be Rob's car (drawn from the training set).  The good pairs are images of the same class, randomly drawn from the test set.  The remaining images are randomly drawn from other classes in the test set","88dc7dc1":"Suppose Rob drives a 2012 Ferrari FF Coupe.  We select one image as the reference for one shot learning.  The objective is to compare a random image to the reference image and determine if it is the same or different car.","5fc0b0c4":"Generator for image data.  Returns tensor consisting of two image columns and a label column.  For the first half of each batch the two images are of the same class of car (year make model) and the label is 1.  For the second half of the batch the two images are different classes and the label is 0.  Images are also resized when the generator is called"}}