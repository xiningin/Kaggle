{"cell_type":{"749909e7":"code","36218753":"code","74f20698":"code","0ce2b8d0":"code","2eaeaf28":"code","e464490d":"code","4b0b9edc":"code","84a094d5":"code","42502039":"code","68cf8579":"code","df569d61":"code","bbb6640e":"markdown","c45e7a1b":"markdown"},"source":{"749909e7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport glob\nimport cv2\nimport pickle\nfrom datetime import datetime\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import metrics\nfrom keras.models import Model\nimport os\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.utils import normalize\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow as tf","36218753":"# Tiling made easy with this libarary\npip install patchify","74f20698":"from PIL import Image, ImageDraw\nfrom patchify import patchify\nimport tifffile as tiff\nimport gc\nimport json\nimport csv\nimport math, re, os\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nimport keras\nfrom keras.models import Sequential, Model,load_model\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\nfrom keras.preprocessing import image\nfrom keras.initializers import glorot_uniform\nprint(\"Tensorflow version \" + tf.__version__)","0ce2b8d0":"#pip install imgaug\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nfrom imgaug import augmenters as iaa\nfrom imgaug import parameters as iap\nfrom imgaug.augmentables.segmaps import SegmentationMapsOnImage","2eaeaf28":"def augment(image,mask):\n    #image = m#ia.quokka(size=(128, 128), extract=\"square\")\n    n = mask\n    segmap = (n>0).astype('uint8')\n    segmap = SegmentationMapsOnImage(segmap, shape=image.shape)\n    \n    # We can do many transformations\n    seq = iaa.Sequential([\n        iaa.Dropout([0.05, 0.2]),      # drop 5% or 20% of all pixels\n        iaa.Affine(rotate=(-45, 45)),  # rotate by -45 to 45 degrees (affects segmaps)\n        iaa.ElasticTransformation(alpha=50, sigma=5),  # apply water effect (affects segmaps)\n        iaa.GaussianBlur(sigma=iap.Uniform(0.9, 1.0)),\n        iaa.MedianBlur(k=(3, 11))\n    ], random_order=True)\n\n    images_aug = []\n    segmaps_aug = []\n    #for _ in range(5):\n    images_aug_i, segmaps_aug_i = seq(image=image, segmentation_maps=segmap)\n    images_aug.append(images_aug_i)\n    segmaps_aug.append(segmaps_aug_i)\n\n    cells = []\n    for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n        cells.append(image)\n        cells.append(n)\n        cells.append(image_aug)\n        cells.append(segmap_aug.draw(size=image_aug.shape[:2])[0])\n    len(cells)\n\n    #fig, axs = plt.subplots(1,4,figsize=(10,10))\n    #axs[0].imshow(cells[0])\n    #axs[1].imshow(cells[1])\n    #axs[2].imshow(cells[2])\n    #axs[3].imshow(cells[3])\n    return cells[0],cells[1],cells[2],cells[3]","e464490d":"# The tile sizes\nsize_x = 4000\nsize_y = 4000","4b0b9edc":"def file_list(folder):\n    files_list = os.listdir('..\/input\/hubmap-kidney-segmentation\/'+folder)\n    files = []\n    for file in files_list:\n        if \".tiff\" in file:\n            files.append(file.split(\".\")[0])\n    return files","84a094d5":"# Create folder structure\ntry:\n    !rm -r images\n    !rm -r masks\n    print(\"Deleted\")\nexcept:\n    pass\n!mkdir images\n!mkdir masks\nprint(\"created\")","42502039":"def read_tiff(file_id,folder):\n    '''\n        This funciton will take a tiff file id with its folder location and read it. It should note that format of tiff\n        files are not same across the folder. Some tiff images has more dims than other and sometimes the color channel\n        is located differently. This need to checked manually before creating this funcion.\n    '''\n    print(\"Reading file \",file_id,end=\"\")\n    large_image_stack = tiff.imread('..\/input\/hubmap-kidney-segmentation\/'+folder+'\/'+file_id+'.tiff')#[0,0,:,:,:]\n    print(\"Done\")\n    shape = large_image_stack.shape\n    if(len(shape)>3):\n        print(\"Image has more dims\")\n        large_image_stack = tiff.imread('..\/input\/hubmap-kidney-segmentation\/'+folder+'\/'+file_id+'.tiff')[0,0,:,:,:]\n    else:\n        print(\"Image has 3 dims\")\n    shape = large_image_stack.shape\n    if shape[0]==3:\n        print(\"Image is channel first, converting\")\n        large_image_stack = np.einsum('ijk->jki',large_image_stack)\n    else:\n        print(\"Image is channel last, no need to convert\")\n    shape = large_image_stack.shape\n    print(shape)\n    return large_image_stack, shape\n\ndef read_mask(file_id):    \n    '''\n        This function will take the id of the tiff image and serach for its mask in the training file\n        folder. It first opens the json file, use geometry & coordinates fields to make polygons, draw\n        the image using the polygons and returns it as the mask\n    '''\n    json_filename = '..\/input\/hubmap-kidney-segmentation\/train\/'+file_id+'.json'\n    read_file = open(json_filename, \"r\") \n    data = json.load(read_file)\n\n    polys = []\n    for index in range(data.__len__()):\n        geom = np.array(data[index]['geometry']['coordinates'])\n        polys.append(geom)\n    #shape = (38160, 39000)\n\n    Image.MAX_IMAGE_PIXELS = None\n    mask = Image.new('L', (shape[1], shape[0]), 0)  # (w, h)\n    for i in range(len(polys)):\n        poly = polys[i]\n        ImageDraw.Draw(mask).polygon(tuple(map(tuple, poly[0])), outline=i + 1, fill=i + 1) \n    polys = []\n    mask = np.array(mask)\n    return mask","68cf8579":"%%time\nfiles = file_list('train') # to list all files in the train directory\nc = 0\npatch_length = size_x # tile size\nstep = 2000 # tile after every this much of pixels\nresize = 256 # whole image should be resized to this before saving it\nitems = 0\nfor file_id in files[:]:\n    large_image_stack, shape = read_tiff(file_id,\"train\")\n    # if needed do the resize as below, but it take lot of resources\n    #large_image_stack = cv2.resize(large_image_stack,(shape[1]\/\/3,shape[0]\/\/3))\n    print(\"New shape,\",shape)\n    # easy tiling of the large image\n    patches_img = patchify(large_image_stack, (patch_length, patch_length, 3), step=step)\n    # save memory\n    large_image_stack = \"\"\n    gc.collect()\n    \n    # do the same for the mask\n    mask = read_mask(file_id)\n    patches_mask = patchify(mask, (patch_length, patch_length), step=step)\n    mask = \"\"\n    gc.collect()\n    \n    # calculate the percentage of the mask in the tiled image\n    count = 0\n    sums = []\n    for row in range(patches_mask.shape[0]):\n        for col in range(patches_mask.shape[1]):\n            s = np.sum(patches_mask[row,col,:,:])\n            count+=1\n            sums.append([s, row, col, np.round(s\/(patch_length*patch_length*255),2)])\n    sums.sort()\n    #if wanted filter images based on the coverage of the mask\n    #ex: first 10% with zero masks + 40-60% mask coverage in the middle + more than 90% mask coverage\n    #sums = sums[0:int(len(sums)*.10)]+sums[int(len(sums)*.40):int(len(sums)*.60)]+(sums[int(len(sums)*.90):])\n    c = 0\n    for im in sums:\n        c+=1\n        row = im[1]\n        col = im[2]\n\n        # seperate corresponding image and its mask using sums list\n        image = patches_img[row,col,0,:,:,:]\n        image = cv2.resize(image, (resize, resize))\n        mask = patches_mask[row,col,:,:]\n        mask = cv2.resize(mask, (resize, resize))\n        mask = (mask>0).astype(int)\n        \n        # do augmentaions\n        org_img, org_msk, aug_img, aug_msk = augment(image,mask)\n\n        # create uniqe file names\n        filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n        cv2.imwrite(\".\/images\/\"+filename_image, org_img)\n        filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n        cv2.imwrite(\".\/masks\/\"+filename_mask, org_msk*255)\n        \n        #use following if some randomness is required in saving images\n#         num = random.randint(1,100)\n#         #print(\"Num is {}\".format(num))\n#         if num>=50:\n#             filename_image = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_image_aug.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"image.jpg\"\n#             cv2.imwrite(\".\/images\/\"+filename_image, aug_img)\n#             filename_mask = file_id+\"_\"+str(\"{0:0=3d}\".format(row))+\"_\"+str(\"{0:0=3d}\".format(col))+\"_mask_aug.jpg\"#file_id+\"_\"+str(str(\"{0:0=3d}\".format(c)))+\"mask.jpg\"\n#             cv2.imwrite(\".\/masks\/\"+filename_mask, org_msk*255)\n        print(\".\",end=\"\")\n            \n            #if im[3]>=.30: break\n            #print(row, col, filename_image, filename_mask, \"saved\")\n    print()\n    print(items,\" \",\"Done\",c,\" images\")\n    print()\n    items+=1\n    gc.collect()\n    \nprint(\"DONE=================\")","df569d61":"# Inspeck few images ans its masks\nims = os.listdir('.\/images')\nrandom.shuffle(ims)\nmsk = [i.replace(\"image\",\"mask\") for i in ims]\nims = ['.\/images\/'+x for x in ims]\nmsk = ['.\/masks\/'+x for x in msk]\nfig, axs = plt.subplots(1,2,figsize=(10,10))\nnum = random.randint(1,len(ims))\nprint(num)\nm = cv2.imread(ims[num])\nn = cv2.imread(msk[num])\naxs[0].imshow(m)\naxs[1].imshow(n)","bbb6640e":"## Now we can use images and its masks to create ML models","c45e7a1b":"# This is just to share what I have done in this competition. Kindly note that some code snippets were copies from other notebooks, unortunately I can't remeber the link to make the references."}}