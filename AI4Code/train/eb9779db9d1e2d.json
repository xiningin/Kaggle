{"cell_type":{"6a84cde8":"code","990b86d6":"code","099481c4":"code","5aac519a":"code","ea6cc100":"code","ef4f12ed":"code","7a5117c2":"code","a0eafc6c":"code","e3f59843":"code","8bb4f73c":"code","7afdd3ee":"code","905118fe":"code","4bf9397e":"code","0181cd05":"code","bb166ec0":"code","fed83c2d":"code","a9c72391":"code","d601a1ec":"code","2a77aeaa":"code","a9baf935":"code","8a16f0d1":"code","7c995d2d":"code","c2668acb":"code","df23bdb0":"code","6f4bbafa":"code","1b626c70":"code","714b102e":"code","b6f817fd":"code","27824ffb":"code","b5c81e98":"markdown","e710d13e":"markdown","4b2f7cee":"markdown","46ae78e0":"markdown","85d9ecb0":"markdown","1c1e434d":"markdown","79785ab6":"markdown","99461921":"markdown","45ff6ef0":"markdown","bf4af266":"markdown","13fd53b9":"markdown","28ba973a":"markdown","2add204e":"markdown","1424571d":"markdown","25fc8c05":"markdown","ed889a06":"markdown","d4111f27":"markdown"},"source":{"6a84cde8":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport glob as gb\nimport cv2\nimport tensorflow as tf\nimport keras\nfrom sklearn.metrics import confusion_matrix\n\ntrainpath = '..\/input\/intel-image-classification\/seg_train\/'\ntestpath = '..\/input\/intel-image-classification\/seg_test\/'\npredpath = '..\/input\/intel-image-classification\/seg_pred\/'","990b86d6":"for folder in  os.listdir(trainpath + 'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    print(f'For training data , found {len(files)} in folder {folder}')","099481c4":"for folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    print(f'For testing data , found {len(files)} in folder {folder}')","5aac519a":"files = gb.glob(pathname= str(predpath +'seg_pred\/*.jpg'))\nprint(f'For Prediction data , found {len(files)}')","ea6cc100":"# now how about the images sizes in train folder\n\nsize = []\nfor folder in  os.listdir(trainpath +'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image = plt.imread(file)\n        size.append(image.shape)\npd.Series(size).value_counts()\n","ef4f12ed":"size = []\nfor folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image = plt.imread(file)\n        size.append(image.shape)\npd.Series(size).value_counts()","7a5117c2":"# prediction images\nsize = []\nfiles = gb.glob(pathname= str(predpath +'seg_pred\/*.jpg'))\nfor file in files: \n    image = plt.imread(file)\n    size.append(image.shape)\npd.Series(size).value_counts()","a0eafc6c":"# since we have 6 categories , we first need to create a dictionary with their names & indices\n\ncode = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n\ndef getcode(label) :\n    \"\"\"\n    function to get the image code back by comparison with the sent label\n    \n    Parameters\n    ----------\n    label : the number sent to get the image name\n    \n    Returns\n    -------\n    img_name : name of the image with the assigned code\n    \"\"\"\n    for img_name , img_code in code.items() : \n        if label == img_code : \n            return img_name ","e3f59843":"\ndef images_read(file_path:str, folder_name:str, img_size:int, labeled:bool):\n    \"\"\"\n    read the images after resize it and assign the label value\n    \n    Parameters\n    ----------\n    file_path : str\n            the path of the file to get images from\n    \n    folder_name : str\n            the folder name that contain the images or folders of images\n    \n    img_size : int\n            size used to resize the image\n    \n    labeled : bool\n            if True the images will be labeled\n            if False will return only the X_matrix\n            \n    \"\"\"\n    X_mat = []\n    y_mat = []\n    \n    if labeled:\n        for folder in  os.listdir(file_path +folder_name) : \n            files = gb.glob(pathname= str( file_path + folder_name +'\/\/' + folder + '\/*.jpg'))\n            for file in files: \n                image = cv2.imread(file)\n                image_array = cv2.resize(image , (img_size,img_size))\n                X_mat.append(list(image_array))\n                y_mat.append(code[folder]) #code = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n        return X_mat, y_mat\n    else:\n        files = gb.glob(pathname= str(file_path + folder_name + '\/*.jpg'))\n        for file in files: \n            image = cv2.imread(file)\n            image_array = cv2.resize(image , (img_size,img_size))\n            X_mat.append(list(image_array))       \n        return X_mat","8bb4f73c":"def images_display(data, title=None):\n    \"\"\"\n    Display number of random images \n    \n    Parameters\n    ----------\n    data : array-like or PIL image\n           the images to be display\n           \n    title : the images labels to be set as a title\n    \n    Returns : image\n    \"\"\"\n    if title == None:\n        plt.figure(figsize=(20,20))\n        for n , i in enumerate(list(np.random.randint(0,len(data),36))) : \n            plt.subplot(6,6,n+1)\n            plt.imshow(data[i])    \n            plt.axis('off')\n    else:\n        plt.figure(figsize=(20,20))\n        for n , i in enumerate(list(np.random.randint(0,len(data),36))) : \n            plt.subplot(6,6,n+1)\n            plt.imshow(data[i])    \n            plt.axis('off')\n            plt.title(getcode(title[i]))","7afdd3ee":"# first we'll create a variable s , which refer to size , so we can change it easily\n\n# let's use now size = 100 , so it will be suitable amount to contain accuracy without losing so much time in training\n\ns = 100\n\nX_train, y_train = images_read(file_path=trainpath, folder_name=\"seg_train\", img_size=s, labeled=True)\nprint(f'we have {len(X_train)} items in X_train')","905118fe":"images_display(X_train, title=y_train)","4bf9397e":"# now read the test data and display some\nX_test, y_test = images_read(file_path=testpath, folder_name=\"seg_test\", img_size=s, labeled=True)\nprint(f'we have {len(X_test)} items in X_test')","0181cd05":"images_display(data=X_test, title=y_test)","bb166ec0":"# also with Prediction data , without having labeles ofcourse\n\nX_pred = images_read(file_path=predpath, folder_name=\"seg_pred\", img_size=s, labeled=False)  \nprint(f'we have {len(X_pred)} items in X_pred')","fed83c2d":"images_display(data=X_pred)","a9c72391":"# first to convert the data into arrays using numpy\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\nX_pred_array = np.array(X_pred)\n\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nprint(f'X_train shape  is {X_train.shape}')\nprint(f'X_test shape  is {X_test.shape}')\nprint(f'X_pred shape  is {X_pred_array.shape}')\nprint(f'y_train shape  is {y_train.shape}')\nprint(f'y_test shape  is {y_test.shape}')","d601a1ec":"KerasModel = keras.models.Sequential([\n        keras.layers.Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(s,s,3)),\n        keras.layers.Conv2D(144,kernel_size=(3,3),activation='relu'),\n        keras.layers.BatchNormalization(),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Dropout(rate=0.4),\n    \n        keras.layers.Conv2D(112,kernel_size=(3,3),activation='relu'),\n        keras.layers.Conv2D(72,kernel_size=(3,3),activation='relu'),\n        keras.layers.BatchNormalization(),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Dropout(rate=0.4),\n        \n        keras.layers.Flatten(),\n        keras.layers.Dense(120,activation='relu') ,\n        keras.layers.Dropout(rate=0.2),\n        keras.layers.Dense(72,activation='relu') ,\n        keras.layers.Dropout(rate=0.2),\n        keras.layers.Dense(6,activation='softmax') ,\n        ])","2a77aeaa":"opt = tf.keras.optimizers.Adam(learning_rate=0.01)\nKerasModel.compile(optimizer =opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])","a9baf935":"print('Model Details are : ')\nprint(KerasModel.summary())","8a16f0d1":"# Set a learning rate annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","7c995d2d":"from keras.callbacks import EarlyStopping\ncallback = EarlyStopping(monitor='val_loss', patience=2)","c2668acb":"# now to train the model\n\nepochs = 10\nThisModel = KerasModel.fit(X_train, y_train, \n                           epochs=epochs,\n                           validation_data=(X_test,y_test),\n                           batch_size=64,verbose=1,\n                           callbacks=[learning_rate_reduction, callback]\n                          )\n","df23bdb0":"from keras.models import model_from_json\n\n# serialize model to JSON\nmodel_json = KerasModel.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nKerasModel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","6f4bbafa":"# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")","1b626c70":"# now to predict X test\n\ny_pred = loaded_model.predict(X_test)\n\nprint('Prediction Shape is {}'.format(y_pred.shape))","714b102e":"# Look at confusion matrix \nimport itertools\n\nsns.set(style='white', context='notebook', palette='deep')\nplt.figure(figsize=(12,12))\n\ndef plot_confusion_matrix(cm, \n                          classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    \n    Parameters\n    ------------    \n    cm : confusion_matrix\n    \n    classes : int \n        the number of labels\n    \n    title : str default: 'Confusion matrix'\n        title to be set for the chart\n    \n    cmap : str or Colormap, (default: 'Blues')\n        A Colormap instance or registered colormap name. cmap is only used if c is an array of floats.\n        \n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = loaded_model.predict(X_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1)\n# get validation labels\nY_true = y_test\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(6)) ","b6f817fd":"y_result = loaded_model.predict(X_pred_array)\n\nprint('Prediction Shape is {}'.format(y_result.shape))","27824ffb":"# and to show random redicted pictures & its predicting category\n\nplt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])    \n    plt.axis('off')\n    plt.title(getcode(np.argmax(y_result[i])))","b5c81e98":"# Building The Model\n### now we need to build the model to train our data\n","e710d13e":"### now it's time to predict X Predict","4b2f7cee":"# Train the model\n\n#### lets use 10 epochs for now","46ae78e0":"### ok , almost all of them are 150,150,3 , how about test images and prediction images ?","85d9ecb0":"#### Stop training when a monitored metric has stopped improving.\n\n#### This callback allows you to specify the performance measure to monitor, the trigger, and once triggered, it will stop the training process.","1c1e434d":"# Confusion matrix ","79785ab6":"### now to compile the model , using adam optimizer , & sparse categorical crossentropy loss","99461921":"### ok , how about the test folder","45ff6ef0":"#### Reduce learning rate when a metric has stopped improving.\n\n#### Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","bf4af266":"### ok , since almost all of pictures are 150,150,3 , we can feel comfort in using all pictures in our model , after resizing it in a specific amount","13fd53b9":"### let's take a look at random pictures in X_train, and adjust their title using the y value","28ba973a":"### let's get some description on the model architecture","2add204e":"### now to build the CNN model by Keras , using Conv2D layers , MaxPooling & Denses","1424571d":"# Open Folders\n\n### now let's first check the Train folder to have a look to its content","25fc8c05":"# Checking Images\n### now we need to heck the images sizes , to know how they looks like","ed889a06":"# Reading Images\n### now it's time to read all images & convert it into arrays\n","d4111f27":"### now for prediction folder"}}