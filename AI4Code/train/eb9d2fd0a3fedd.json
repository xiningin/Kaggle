{"cell_type":{"2f7371d1":"code","3862e173":"code","d7a2f640":"code","fe9c9e0c":"code","a962f89d":"code","b631798a":"code","8628c662":"code","6495691b":"code","2c8ff094":"code","cb884c3d":"code","bfd21bdf":"code","93737eb2":"code","0e1db140":"code","3917d08a":"code","038d6b38":"code","69abc3f7":"markdown","6973c60b":"markdown","293c9ae6":"markdown","08de6761":"markdown","03b8b23a":"markdown","d8df4686":"markdown","061b1a20":"markdown","72828a81":"markdown","dbbc1683":"markdown","417abbd4":"markdown","6407f25b":"markdown","1e5458a9":"markdown","4f775872":"markdown","079be5ef":"markdown"},"source":{"2f7371d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3862e173":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n%matplotlib inline","d7a2f640":"train = pd.read_csv(r'\/kaggle\/input\/digit-recognizer\/train.csv')\ntrain.shape","fe9c9e0c":"train.head(5)","a962f89d":"train_labels = train['label']\ntrain_images = train.drop(['label'], axis=1)","b631798a":"test_images = pd.read_csv(r'\/kaggle\/input\/digit-recognizer\/test.csv')\ntest_images.shape","8628c662":"train_images_2d = np.reshape(np.array(train_images, dtype='float'), (-1, 28,28))\ntest_images_2d = np.reshape(np.array(test_images, dtype='float'), (-1, 28,28))\n\nfirst_image = train_images_2d[0]\nplt.imshow(first_image, cmap='gray')\nplt.show()","6495691b":"train_images_pad = np.array([np.pad(row, (2,2), 'constant') for row in train_images_2d])\ntest_images_pad = np.array([np.pad(row, (2,2), 'constant') for row in test_images_2d])","2c8ff094":"train_images_pad_channel = train_images_pad.reshape(-1,32,32,1)\nprint(train_images_pad_channel.shape)\ntest_images_pad_channel = test_images_pad.reshape(-1,32,32,1)\nprint(test_images_pad_channel.shape)","cb884c3d":"def build_lenet_model():\n    model = keras.Sequential()\n    model.add(layers.Conv2D(filters=6, kernel_size=5, activation='relu',\n              strides=1, padding='valid', input_shape=(32,32,1)))\n    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n    model.add(layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='valid'))\n    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='valid'))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(120, activation='relu'))\n    model.add(layers.Dense(84, activation='relu'))\n    model.add(layers.Dense(10, activation='softmax'))\n    model.compile(optimizer='adam', loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n    return model","bfd21bdf":"X_train, X_val, y_train, y_val = train_test_split(train_images_pad_channel, train_labels,\n                 test_size=0.2, train_size=0.8, random_state=23, shuffle=True)","93737eb2":"lenet_model = build_lenet_model()\nlenet_model.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val), batch_size=32)","0e1db140":"sample_submission = pd.read_csv(r'..\/input\/digit-recognizer\/sample_submission.csv')\nsample_submission.head(5)","3917d08a":"predictions = np.argmax(lenet_model.predict(test_images_pad_channel, batch_size=32), axis=-1)\npredictions.shape","038d6b38":"to_submit = sample_submission\nto_submit['Label'] = predictions.tolist()\nto_submit.head(5)\nto_submit.to_csv(r'.\/submission_file.csv', index=False, header=True)\n","69abc3f7":"Define function to implement deep learning according to the schema of lenet","6973c60b":"This corresponds to 42000 images, each with 784 features (28*28 pixels)","293c9ae6":"Column 'label' is the target. We need to separate data and labels","08de6761":"Build model and run for 5 epochs (v. high accuracy so more are not needed for this dataset)","03b8b23a":"File consists of 2 columns - imageId and label.\nFirst run prediction","d8df4686":"Import necessary libraries","061b1a20":"Load test set\nprint one of the images test set","72828a81":"Split train set into train and validation. Shuffle so model not influenced by order","dbbc1683":"Our images are 28*28, wheres lenet expects 32x32 image. Need to pad data with zeroes","417abbd4":"We have 28000 test images. In this notebook we well make predictions for the labels of this test set.\n\nNext we will reshape the input features to 28*28 and then view one of the images","6407f25b":"#explore mnist data","1e5458a9":"Create submission file","4f775872":"Very high train and validation accuracy, so proceed to test prediction.\nView sample submission to see how to submit data","079be5ef":"Add colour channel (1 as images are grayscale), then check dimensions"}}