{"cell_type":{"2a247945":"code","17031721":"code","d424e3ff":"code","a76eb4ff":"code","c42d90eb":"code","41750f68":"code","876e1314":"code","bbcfa5ed":"code","e49c1bfb":"code","df7cc44f":"markdown","59a7b1c1":"markdown","30dc67e5":"markdown","164b3e03":"markdown","4e571d04":"markdown"},"source":{"2a247945":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17031721":"# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import datasets","d424e3ff":"# Load the iris dataset\niris = pd.read_csv('..\/input\/iris\/Iris.csv')\niris.head() # See the first 5 rows","a76eb4ff":"x = iris.iloc[:, [0, 1, 2, 3]].values","c42d90eb":"from sklearn.cluster import KMeans\nwcs = []","41750f68":"for i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', \n                    max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcs.append(kmeans.inertia_)","876e1314":"\n# Plot and observe the elbow\nplt.plot(range(1, 11), wcs)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCS') # Within cluster sum of squares\nplt.show()","bbcfa5ed":"# Applying kmeans to the dataset \/ Creating the kmeans classifier\nkmeans = KMeans(n_clusters = 3, init = 'k-means++',\n                max_iter = 300, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit_predict(x)","e49c1bfb":"# Visualising the clusters - On the first two columns\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], \n            s = 100, c = 'red', label = 'Iris-setosa')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], \n            s = 100, c = 'blue', label = 'Iris-versicolour')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],\n            s = 100, c = 'green', label = 'Iris-virginica')\n\n# Plotting the centroids of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], \n            s = 100, c = 'yellow', label = 'Centroids')\n\nplt.legend()\nplt.show()","df7cc44f":"###  Since it's a unsupervised machine learning problem , let's do clustering in it\n\n### Let us find the number of clusters for K Means","59a7b1c1":"![image.png](attachment:image.png)","30dc67e5":"# Knowledge Fact - The Elbow Method\n\n\nIn cluster analysis, the elbow method is a heuristic used in determining the number of clusters in a data set. The method consists of plotting the explained variation as a function of the number of clusters, and picking the elbow of the curve as the number of clusters to use. The same method can be used to choose the number of parameters in other data-driven models, such as the number of principal components to describe a data set.","164b3e03":"# Knowledge Fact - K means\n\nK-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.\n\n\n\n","4e571d04":"### As we can see Elbow begins from 3 , therefore we choose number of clusters as 3"}}