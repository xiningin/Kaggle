{"cell_type":{"86af4fa8":"code","2221feee":"code","c3c4ed36":"code","859e148f":"code","9ae7df55":"code","863638b5":"code","49780c48":"code","ff4c03a8":"code","4cdb86e8":"code","b4bb20d0":"code","48671934":"code","f5d2ddac":"code","712a42ec":"code","c9fb336e":"code","282e352c":"code","a0574011":"code","061574b6":"code","cf1bbe03":"code","aee13b5b":"code","416538dc":"code","c63c756e":"code","0bf791f2":"code","0c9952da":"code","c05da769":"code","4b416ef4":"code","09b24449":"markdown","b67c4e19":"markdown","1c687a2c":"markdown","31439a3a":"markdown","8d9a96ce":"markdown","24d1a555":"markdown","2f981d4b":"markdown","8e78d406":"markdown","cf1831f5":"markdown","a7de3d0f":"markdown","0ea0d79c":"markdown","53b930a4":"markdown","d1c7469e":"markdown","dc1eae58":"markdown","9c86e53b":"markdown","10136dd5":"markdown","6f8e84a4":"markdown","aff7086a":"markdown","2a7e1ff4":"markdown","38761473":"markdown","8934c0ba":"markdown","083279f1":"markdown","332289c1":"markdown","7c031c7f":"markdown"},"source":{"86af4fa8":"import pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport torch\nfrom pathlib import Path\nfrom torch.utils.data import Dataset,DataLoader\nfrom PIL import Image\nfrom torchvision import transforms as T\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.transforms import Resize, Compose, ToTensor, Grayscale\nimport torchvision.models as models\nfrom fastprogress.fastprogress import master_bar, progress_bar\nfrom torchvision.transforms.functional import to_grayscale\nfrom sklearn.metrics import accuracy_score, roc_auc_score","2221feee":"path = Path('..\/input\/chest-xray-pneumonia\/chest_xray')\nim_sz = 256\nbs = 8","c3c4ed36":"train_normal = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL')\ntrain_disease = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA')\n\ntrain_data = [(o,0) for o in train_normal.iterdir()]\ntrain_data_disease = [(o,1) for o in train_disease.iterdir()]\ntrain_data.extend(train_data_disease)\n\ntrain_data = pd.DataFrame(train_data, columns=[\"filepath\",\"disease\"])\ntrain_data.head()","859e148f":"valid_normal = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL')\nvalid_disease = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA')\n\nvalid_data = [(o,0) for o in valid_normal.iterdir()]\nvalid_data_disease = [(o,1) for o in valid_disease.iterdir()]\nvalid_data.extend(valid_data_disease)\n\nvalid_data = pd.DataFrame(valid_data, columns=[\"filepath\",\"disease\"])\nvalid_data.head()","9ae7df55":"test_normal = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL')\ntest_disease = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA')\n\ntest_data = [(o,0) for o in test_normal.iterdir()]\ntest_data_disease = [(o,1) for o in test_disease.iterdir()]\ntest_data.extend(test_data_disease)\n\ntest_data = pd.DataFrame(test_data, columns=[\"filepath\",\"disease\"])\ntest_data.to_csv('test.csv',index=False)\ntest_data.head()","863638b5":"def list_files(path:Path):\n    \"\"\"\n    This function is used to list files in a directory\n    \"\"\"\n    return [o for o in path.iterdir()]","49780c48":"def get_device():\n    \"\"\"\n    This is used to get the device to run the training\n    \"\"\"\n    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\ndevice = get_device()","ff4c03a8":"fig,a =  plt.subplots(1,5)\nfig.set_figheight(30)\nfig.set_figwidth(30)\nfor i in range(5):\n    img = cv.imread(str(train_data.iloc[i]['filepath']))\n    a[i].imshow(img)\n    title = \"Normal Xray \" + str(i)\n    a[i].set_title(title)","4cdb86e8":"fig,a =  plt.subplots(1,5)\nfig.set_figheight(30)\nfig.set_figwidth(30)\nfor i in range(-5, 0):\n    img = cv.imread(str(train_data.iloc[i]['filepath']))\n    a[i].imshow(img)\n    title = \"Pneumonia Xray \" + str(5 + i)\n    a[i].set_title(title)","b4bb20d0":"class PneumoniaDatset(Dataset):\n    def __init__(self, df, transforms=None, is_test=False):\n        self.df = df\n        self.transforms = transforms\n        self.is_test = is_test\n    \n    def __getitem__(self, idx):\n        image_path = self.df.iloc[idx]['filepath']\n        img = Image.open(image_path)\n        \n        if self.transforms:\n            img = self.transforms(img)\n        if self.is_test:\n            return img\n        else:\n            disease = self.df.iloc[idx]['disease']\n            return img, torch.tensor([disease], dtype=torch.float32)\n        \n    def __len__(self):\n        return self.df.shape[0]","48671934":"train_tfms = Compose([ Grayscale(), Resize((512,512)),  ToTensor(), T.RandomErasing(inplace=True)])\ntest_tfms = Compose([Grayscale(), Resize((512,512)) , ToTensor()])","f5d2ddac":"class PneumoniaModel(nn.Module):\n    def __init__(self, backbone=models.resnet34(pretrained=True), n_out=1):\n        super().__init__()\n        backbone = backbone\n        in_features = backbone.fc.in_features\n        #make 3 input layer to work with 1 layer : https:\/\/discuss.pytorch.org\/t\/grayscale-images-for-resenet-and-deeplabv3\/48693\/2?u=vishnurapps\n        backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n        self.classifier = nn.Sequential(nn.Linear(in_features, n_out))\n        \n    def forward(self, x):\n        #Size of the input data             torch.Size([64, 1, 512, 512])\n        x = self.backbone(x)               #torch.Size([64, 512, 16, 16])\n        x = F.adaptive_avg_pool2d(x, 1)    #torch.Size([64, 512, 1, 1])\n        x = torch.flatten(x, 1)            #torch.Size([64, 512])\n        x = self.classifier(x)             #torch.Size([64, 1])\n        return x","712a42ec":"model = PneumoniaModel()\nmodel.to(device)\nopt = torch.optim.AdamW(model.parameters(), lr=1e-5,weight_decay=0.01)","c9fb336e":"train_ds = PneumoniaDatset(df=train_data,transforms=train_tfms)\ntrain_dl = DataLoader(dataset=train_ds,batch_size=bs,shuffle=True,num_workers=4)","282e352c":"def training_step(xb,yb,model,loss_fn,opt,device,scheduler):\n    xb,yb = xb.to(device), yb.to(device)\n    out = model(xb)\n    opt.zero_grad()\n    loss = loss_fn(out,yb)\n    loss.backward()\n    opt.step()\n    scheduler.step()\n    return loss.item()","a0574011":"def validation_step(xb,yb,model,loss_fn,device):\n    xb,yb = xb.to(device), yb.to(device)\n    out = model(xb)\n    loss = loss_fn(out,yb)\n    out = torch.sigmoid(out)\n    return loss.item(),out","061574b6":"def get_data(train_df,valid_df,train_tfms,test_tfms,bs):\n    train_ds = PneumoniaDatset(df=train_data,transforms=train_tfms)\n    valid_ds = PneumoniaDatset(df=valid_data,transforms=test_tfms)\n    train_dl = DataLoader(dataset=train_ds,batch_size=bs,shuffle=True,num_workers=4)\n    valid_dl = DataLoader(dataset=valid_ds,batch_size=bs*2,shuffle=False,num_workers=4)\n    return train_dl,valid_dl","cf1bbe03":"def fit(epochs,model,train_dl,valid_dl,opt,device=None,loss_fn=F.binary_cross_entropy_with_logits):\n    \n    device = device if device else get_device()\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_dl)*epochs)\n    val_rocs = [] \n    tloss = []\n    vloss = []\n    \n    #Creating progress bar\n    mb = master_bar(range(epochs))\n    mb.write(['epoch','train_loss','valid_loss','val_roc'],table=True)\n\n    for epoch in mb:    \n        trn_loss,val_loss = 0.0,0.0\n        val_preds = np.zeros((len(valid_dl.dataset),1))\n        val_targs = np.zeros((len(valid_dl.dataset),1))\n        \n        #Training\n        model.train()\n        \n        #For every batch \n        for xb,yb in progress_bar(train_dl,parent=mb):\n#             print(xb.shape)\n            trn_loss += training_step(xb,yb,model,loss_fn,opt,device,scheduler) \n        trn_loss \/= mb.child.total\n        tloss.append(trn_loss)\n\n        #Validation\n        model.eval()\n        with torch.no_grad():\n            for i,(xb,yb) in enumerate(progress_bar(valid_dl,parent=mb)):\n                loss,out = validation_step(xb,yb,model,loss_fn,device)\n                val_loss += loss\n                bs = xb.shape[0]\n                val_preds[i*bs:i*bs+bs] = out.cpu().numpy()\n                val_targs[i*bs:i*bs+bs] = yb.cpu().numpy()\n\n        val_loss \/= mb.child.total\n        vloss.append(val_loss)\n        val_roc = roc_auc_score(val_targs.reshape(-1),val_preds.reshape(-1))\n        val_rocs.append(val_roc)\n\n        mb.write([epoch,f'{trn_loss:.6f}',f'{val_loss:.6f}',f'{val_roc:.6f}'],table=True)\n    return model,val_rocs, tloss, vloss","aee13b5b":"train_dl,valid_dl = get_data(train_data,valid_data,train_tfms,test_tfms,bs=64)","416538dc":"model, val_rocs, train_loss, valid_loss = fit(200,model,train_dl,valid_dl,opt)","c63c756e":"plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(train_loss, '-bx')\nplt.plot(valid_loss, '-rx')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Training', 'Validation'])\nplt.title('Loss vs. No. of epochs');\nplt.grid()","0bf791f2":"test_ds = PneumoniaDatset(df=test_data,transforms=test_tfms,is_test=True)\ntest_dl = DataLoader(dataset=test_ds,batch_size=bs,shuffle=False,num_workers=4)","0c9952da":"def get_preds(model,device=None,tta=3):\n    if device is None:\n        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n    preds = np.zeros(len(test_ds))\n    for tta_id in range(tta):\n        test_preds = []\n        with torch.no_grad():\n            for xb in test_dl:\n                xb = xb.to(device)\n                out = model(xb)\n                out = torch.sigmoid(out)\n                test_preds.extend(out.cpu().numpy())\n            preds += np.array(test_preds).reshape(-1)\n        #print(f'TTA {tta_id}')\n    preds \/= tta\n    for i, x in enumerate (preds):\n        if x >= 0.5:\n            preds[i] = 1\n        else :\n            preds[i] = 0\n    return preds\n\npreds = get_preds(model)","c05da769":"submission = pd.read_csv('test.csv')\nsubmission['prediction'] = preds\nsubmission.to_csv('submission.csv',index=False)","4b416ef4":"cm = confusion_matrix(submission['disease'], submission['prediction'])\nsns.heatmap(cm, annot=True, fmt=\"d\")","09b24449":"<a id=\"model\"><\/a>\n## Pytorch model\n\n\nThis model can work with all reset architecture. We can pass the architecture while creating the model, default is resnet18. We get the in_features size. This is the input to the classifier. This is later used to make the classifier. We use all layers of the pretrained model except the last two.\n\nThe resnet is trained on RGB images but we are feeding in grayscale images. So I have updated the first layer of the resnet to accept the grayscale images. The `in_channels` was changed to 1 from 3.\n\nThe input to the backbone is `[64, 1, 512, 512]` and on passing through the backbone, it will be converted to `[64, 512, 16, 16]`. This is then passed through a `adaptive_avg_pool2d` layer and it produces `[64, 512, 1, 1]`. This is then flattened and the shape changes to `[64, 512]`. It is passed to classifier which produces the result of shape `[64, 1]`.","b67c4e19":"<a id=\"intro\"><\/a>\n## Introduction\nPneumonia is an inflammatory condition of the lung affecting primarily the small air sacs known as alveoli. Symptoms typically include some combination of productive or dry cough, chest pain, fever and difficulty breathing. The severity of the condition is variable. Pneumonia is usually caused by infection with viruses or bacteria and less commonly by other microorganisms, certain medications or conditions such as autoimmune diseases.\n\n[reference](https:\/\/en.wikipedia.org\/wiki\/Pneumonia)","1c687a2c":"<a id=\"conclusion\"><\/a>\n## Conclusion\n\nI have created a base model for showing how we can use pytorch and Resnet to create a model to seperate xrays having pneumonia from normal chest xrays. This is not the best model for this job. Please feel free to add more layers and dropouts in the classifier and see how the performance changes.","31439a3a":"<a id=\"dataset\"><\/a>\n## Dataset\n\nThis is the class used for creating the dataset. In the __getitem__(), we return the image and the label as tensor. If the is_test is set as true, then only image is returned.","8d9a96ce":"As you have seen above while plotting the sample images, we can see that the images are of different shapes. We need to make the images to a uniform shape before passing to the network. So I have used the Resize transformation from pytorch. Also while trying to train the data, I have encountered some errors complaining about the number of channels in the image. Some of the images are grey scale but some are rgb. We need to convert the rgb images to grayscale before doing the training. The Grayscale transform does that job. ToTensor converts the images to tensors.","24d1a555":"Created a model and moved to GPU. Created an instance of the AdamW optimizer.","2f981d4b":"<a id=\"uf\"><\/a>\n## Utility functions","8e78d406":"This function generate the output using the trained model and generate the preds. The preds is an average over all the predictions in all TTA's.","cf1831f5":"## Thanks for taking time to read this kernel.\n","a7de3d0f":"In the fit function, we pass the epoch, mode, data loaders, optimizer and loss function as argument. ","0ea0d79c":"Here the data is given in the form of pictures. There are three folders each contianing normal lung xrays and xrays containing pneumonia. I am traversing through these folders using iterdir() and making a dataframe. The dataframe has two parts. The first part is filepath of the image and second one is label. Normal xrays have a label 0 and the xrays of pneumonia will have a label 1.","53b930a4":"<a id=\"testing\"><\/a>\n## Testing\n\nFor testing, there is a seperate folder containing the test images. I have created a dataframe containing all test images and their labels. It is used to create the dataset and dataloader.","d1c7469e":"### Xrays with Pneumonia","dc1eae58":"<a id=\"#si\"><\/a>\n## Sample images\n\n### Normal xray","9c86e53b":"<a id=\"next\"><\/a>\n## Whats next\n\n- I have used the base model in the resnet family called the resnet18. Try with bigger models in the same family\n- Try to use the efficientnet family for much better performance\n- The classifier used here is basic one. Try to improve it by adding more layers and dropouts.\n- I have only used basic augmentations like grayscale, resize. There are many more transformations like rotation, padding etc try them out","10136dd5":"This is not a competition data so we dont have to submit any thing. However I am creating a submission csv for comparison purpose.","6f8e84a4":"## If you like this work, please consider upvoting. It will motivate me to create more kernels like this","aff7086a":"## Table of Contents\n* [Introduction](#intro)\n* [Import libraries and data](#ild)\n* [Utility functions](#uf)\n* [Sample images](#si)\n* [Dataset](#dataset)\n* [Pytorch model](#model)\n* [Training](#training)\n* [Testing](#testing)\n* [Confusion Matrix](#confusion)\n* [Conclusion](#conclusion)\n* [Whats next](#next)","2a7e1ff4":"![image.png](attachment:image.png)","38761473":"<a id=\"ild\"><\/a>\n## Import libraries and data","8934c0ba":"In the `validation_step`, the loss and the probablity of output is passed.","083279f1":"<a id=\"confusion\"><\/a>\n## Confusion Matrix\n\nLets see how well our model classifies the xrays with pneumonia.","332289c1":"<a id=\"training\"><\/a>\n## Training\n\nTo start training, created a couple of functions. The `training_step` function does the training. Gradiednt is calculated and optimizer is used to update the gradient. The learning rate is adjusted using the scheduler. This function returns the loss using the loss function passed in argument.  ","7c031c7f":"The `get_data` creates the train and validation dataset and uses these to create the dataloaders. The created dataloaders are returned."}}