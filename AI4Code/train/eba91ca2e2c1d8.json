{"cell_type":{"0b7348f8":"code","ca5b9c38":"code","6a6d7f66":"code","e528650d":"code","e7290f9b":"code","81b09e8c":"code","2f5bbc05":"code","95e89049":"code","76c4947b":"code","764a16b4":"code","9511d132":"markdown","28e8b73a":"markdown","413b05b7":"markdown","6db97bb7":"markdown","138497db":"markdown","f0d4ae7a":"markdown","82a1a847":"markdown","42ec99df":"markdown","b20c39bb":"markdown","2318dbd4":"markdown","b82a338e":"markdown"},"source":{"0b7348f8":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport time\nstart_time = time.time()","ca5b9c38":"random_seed = 2020\nnp.random.seed(random_seed)\n\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import Input, BatchNormalization, Add, Activation\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt","6a6d7f66":"#Load train and test data\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\n#Extract and separate prediction (Y) and Inputs (X)\nY = train['label']\nX = train.drop(labels=\"label\", axis=1)\n\n#Reshape: Original image is a 28x28 pixel image\nX = X.values.reshape(-1, 28, 28, 1) \/ 255\ntest = test.values.reshape(-1, 28, 28, 1) \/ 255\n\nprint(X.shape, test.shape)","e528650d":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',\n                                           patience = 3,\n                                           verbose = 1,\n                                           factor = 0.5,\n                                           min_lr = 0.0001)\n\nes = EarlyStopping(monitor='val_loss',\n                   mode='min',\n                   verbose=1,\n                   patience=15,\n                   restore_best_weights=True)\n\ndef new_model(hidden=512, learning_rate=0.00128):\n    #Input layer\n    INPUT   = Input((28, 28, 1))\n    \n    #First Convolution\n    inputs  = Conv2D(64, (5, 5), activation='relu', padding='same')(INPUT)\n    inputs  = MaxPool2D(pool_size=(3,3), strides=(1,1))(inputs)\n    inputs  = BatchNormalization()(inputs)\n    inputs  = Activation('relu')(inputs)\n    inputs  = Dropout(0.25)(inputs)\n    \n    #Branch off to Three Towers\n    #First Tower\n    tower_1 = Conv2D(64, (1, 1), activation='relu', padding='same')(inputs)\n    tower_1 = Conv2D(128, (2, 2), activation='relu', padding='same')(tower_1)\n    tower_1 = Dropout(0.5)(tower_1)\n    tower_1 = Conv2D(256, (3, 3), activation='relu', padding='same')(tower_1)\n    tower_1 = MaxPool2D(pool_size=(3,3), strides=(2,2))(tower_1)\n    tower_1 = BatchNormalization()(tower_1)\n    \n    #Second Tower\n    tower_2 = Conv2D(64, (2, 2), activation='relu', padding='same')(inputs)\n    tower_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(tower_2)\n    tower_2 = Dropout(0.5)(tower_2)\n    tower_2 = Conv2D(256, (5, 5), activation='relu', padding='same')(tower_2)\n    tower_2 = MaxPool2D(pool_size=(3,3), strides=(2,2))(tower_2)\n    tower_2 = BatchNormalization()(tower_2)\n    \n    #Third Tower\n    tower_3 = Conv2D(64, (1, 1), activation='relu', padding='same')(inputs)\n    tower_3 = Conv2D(128, (3, 3), activation='relu', padding='same')(tower_3)\n    tower_3 = Dropout(0.5)(tower_3)\n    tower_3 = Conv2D(256, (5, 5), activation='relu', padding='same')(tower_3)\n    tower_3 = MaxPool2D(pool_size=(3,3), strides=(2,2))(tower_3)\n    tower_3 = BatchNormalization()(tower_3)\n    \n    #Combine Three Towers\n    x       = Add()([tower_1, tower_2, tower_3])\n    x       = Activation('relu')(x)\n    \n    #Last Convolution\n    x       = Conv2D(256, (5, 5), activation='relu', padding='same')(x)\n    x       = MaxPool2D(pool_size=(5,5), strides=(4,4))(x)\n    x       = BatchNormalization()(x)\n    x       = Activation('relu')(x)\n    #Flatten Data\n    x       = Flatten()(x)\n    \n    #Dense Hidden Network\n    x       = Dense(hidden, activation='relu')(x)\n    x       = Dropout(0.5)(x)\n    x       = Dense(hidden\/\/4, activation='relu')(x)\n    x       = Dropout(0.5)(x)\n    \n    #Model Output\n    preds   = Dense(10, activation='softmax', name='preds')(x)\n    \n    #Build Model\n    model   = Model(inputs=INPUT, outputs=preds)\n    \n    #Define Optimizer\n    optimizer = Adam(lr=learning_rate)\n    #Compile model\n    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['acc'])\n    \n    return model\n\nmodel = new_model()","e7290f9b":"model.summary()\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","81b09e8c":"#Data Augmentation to prevent overfitting\ndatagen = ImageDataGenerator(featurewise_center=False,\n                            samplewise_center=False,\n                            featurewise_std_normalization=False,\n                            samplewise_std_normalization=False,\n                            zca_whitening=False,\n                            rotation_range=10,\n                            zoom_range=0.1,\n                            shear_range=0.02,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            horizontal_flip=False,\n                            vertical_flip=False)","2f5bbc05":"epochs = 200\nbatch_size = 128\n\nprint(\"Learning Properties: Epoch:%i \\t Batch Size:%i\" %(epochs, batch_size))\npredict_accumulator = np.zeros(model.predict(test).shape)\n\naccumulated_history = []\nfor i in range(1, 6):\n    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.20, shuffle=True, random_state=random_seed*i)\n    model = new_model(512, 0.01)\n    #Fit the model\n    datagen.fit(X_train)\n    history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n                                 epochs=epochs, validation_data=(X_val, Y_val), verbose=1,\n                                 steps_per_epoch=X_train.shape[0]\/\/batch_size,\n                                 callbacks=[learning_rate_reduction, es],\n                                 workers=4)\n    loss, acc = model.evaluate(X, Y)\n    if acc > 0.99:\n        predict_accumulator += model.predict(test)*acc\n        accumulated_history.append(history)\n        print(\"Current Predictions on fold number %i\" %i)\n        print(*np.argmax(predict_accumulator, axis=1), sep='\\t')","95e89049":"def graph(full_history):\n    '''Show and save the historical graph of the training model.'''\n    print('Accuracy:')\n    n=1\n    for history in full_history:\n        plt.plot(history.history['acc'])\n        plt.plot(history.history['val_acc'])\n        plt.title('Model Accuracy Fold No. {}'.format(n))\n        plt.ylabel('Accuracy')\n        plt.xlabel('Epoch')\n        plt.legend(['train', 'test'], loc='lower right')\n        plt.savefig('history_acc_{}.png'.format(n))\n        plt.show()\n        n+=1\n\n    print('Loss:')\n    n=1\n    for history in full_history:\n        plt.plot(history.history['loss'])\n        plt.plot(history.history['val_loss'])\n        plt.title('Model Loss Fold No. {}'.format(n))\n        plt.ylabel('Loss')\n        plt.xlabel('Epoch')\n        plt.legend(['train', 'test'], loc='upper right')\n        plt.savefig('history_loss_{}.png'.format(n))\n        plt.show()\n        n+=1\n\ngraph(accumulated_history)","76c4947b":"print(\"Completed Training.\")\nresults = np.argmax(predict_accumulator, axis=1)\nresults = pd.Series(results, name=\"Label\")\nprint(\"Saving prediction to output...\")\nsubmission = pd.concat([pd.Series(range(1, 1+test.shape[0]), name=\"ImageId\"), results], axis=1)\nsubmission.to_csv('submission.csv', index=False)","764a16b4":"end_time = time.time()\ntotal_time = int(end_time - start_time)\nprint(\"Total time spent: %i hours, %i minutes, %i seconds\" \\\n      %((total_time\/\/3600), (total_time%3600)\/\/60, (total_time%60)))","9511d132":"<a id='training'><\/a>\n# Training","28e8b73a":"<a id='overview'><\/a>\n# Overview","413b05b7":"<a id='bottom'><\/a>\n# End\n\nI hope this notebook could be of help to others! If you liked the notebook, please upvote!","6db97bb7":"<a id='import'><\/a>\n# Import Everything","138497db":"<a id='read'><\/a>\n## Read, Load and Pre-process Data","f0d4ae7a":"<a id='begin'><\/a>\n# Begin","82a1a847":"<a id='top'><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n  <h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Notebook Content!<\/h3>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#begin\" role=\"tab\" aria-controls=\"profile\">Begin<span class=\"badge badge-primary badge-pill\">1<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#import\" role=\"tab\" aria-controls=\"messages\">Import Everything<span class=\"badge badge-primary badge-pill\">2<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\"  data-toggle=\"list\" href=\"#read\" role=\"tab\" aria-controls=\"settings\">Read, Load and Pre-process Data<span class=\"badge badge-primary badge-pill\">3<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#model\" role=\"tab\" aria-controls=\"settings\">Design Model<span class=\"badge badge-primary badge-pill\">4<\/span><\/a> \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#image\" role=\"tab\" aria-controls=\"settings\">Overview of Model<span class=\"badge badge-primary badge-pill\">5<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#augment\" role=\"tab\" aria-controls=\"settings\">Data Augmentation<span class=\"badge badge-primary badge-pill\">6<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#training\" role=\"tab\" aria-controls=\"settings\">Training<span class=\"badge badge-primary badge-pill\">7<\/span><\/a>\n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#overview\" role=\"tab\" aria-controls=\"settings\">Overview<span class=\"badge badge-primary badge-pill\">8<\/span><\/a>  \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#output\" role=\"tab\" aria-controls=\"settings\">Output<span class=\"badge badge-primary badge-pill\">9<\/span><\/a>  \n  <a class=\"list-group-item list-group-item-action\" data-toggle=\"list\" href=\"#bottom\" role=\"tab\" aria-controls=\"settings\">End<span class=\"badge badge-primary badge-pill\">10<\/span><\/a>  ","42ec99df":"<a id='augment'><\/a>\n# Data Augmentation","b20c39bb":"<a id='model'><\/a>\n# Design Model","2318dbd4":"<a id='output'><\/a>\n# Save Output","b82a338e":"<a id='image'><\/a>\n# Overview of Model"}}