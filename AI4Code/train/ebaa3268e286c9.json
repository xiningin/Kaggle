{"cell_type":{"ad8da5b5":"code","f1706800":"code","2b2ff977":"code","4dd11815":"code","515c0191":"code","dc5a77b8":"code","432784c2":"code","4f5d4422":"code","9ae082bc":"code","30329048":"code","833a36f5":"markdown","6d7478ab":"markdown","c71efbb8":"markdown","b6789a82":"markdown","29dc56e0":"markdown","6f1c6c11":"markdown"},"source":{"ad8da5b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1706800":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt","2b2ff977":"tf.random.set_seed(3)","4dd11815":"base_dir = '..\/input\/dogs-cats-images\/dog vs cat\/dataset'\ntrain_dir = os.path.join(base_dir, 'training_set')\ntest_dir = os.path.join(base_dir, 'test_set')","515c0191":"# Directory with training cat pictures\ntrain_cats_dir = os.path.join(train_dir, '\/cats')\n\n# Directory with training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, '\/dogs')\n\n# Directory with test cat pictures\ntest_cats_dir = os.path.join(test_dir, '\/cats')\n\n# Directory with test dog pictures\ntest_dogs_dir = os.path.join(test_dir, '\/dogs')","dc5a77b8":"train_datagen = ImageDataGenerator(rescale = 1\/255.,\n                                   rotation_range = 40,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale = 1\/255.)","432784c2":"train_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size = (150,150),\n                                                    batch_size = 20,\n                                                    class_mode = 'binary')\n\ntest_generator = test_datagen.flow_from_directory(test_dir,\n                                                    target_size = (150,150),\n                                                    batch_size = 20,\n                                                    class_mode = 'binary')","4f5d4422":"model = models.Sequential([\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    layers.MaxPooling2D(2, 2),\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D(2,2),\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer = RMSprop(lr = 0.0001),\n              metrics = ['accuracy'])","9ae082bc":"history = model.fit(train_generator,\n                    validation_data = test_generator,\n                    epochs = 20,\n                    steps_per_epoch = 400,\n                    validation_steps = 100)\n# the number of steps = amount of data \/ batch size\n# steps_per_epoch = training data \/ batch size = 8000\/ 20 = 400\n# validation_steps = test data \/ batch size = 2000\/ 20 = 100","30329048":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'c-', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'y-', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'c-', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'y-', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","833a36f5":"# 2. Setting the paths to training and testing directories","6d7478ab":"# 1. Importing all the necessary libraries","c71efbb8":"## Creating the train and test generators\nReference: https:\/\/keras.io\/api\/preprocessing\/image\/#flowfromdirectory-method","b6789a82":"# 5. Evaluating the model by plotting graphs\n\n1. Training accuracy v\/s Validation accuracy\n2. Training loss v\/s Validation loss","29dc56e0":"# 3. Creating ImageDataGenerator objects to generate image data in batches and to apply image augmentation\nReference: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator\n\nNote: We apply image augmentation only to the training data","6f1c6c11":"# 4. Creating and compiling a CNN model"}}