{"cell_type":{"c98f6ab6":"code","113e2850":"code","e9173a9d":"code","2e2a8947":"code","03858bce":"code","0c30159c":"code","0bf4aee1":"code","ae9b7c37":"code","a5875b3c":"code","ea6b5043":"code","4e60cb3e":"code","96678e52":"code","5891e8a1":"code","0204efd0":"code","5327a1cc":"code","93ec418c":"code","0b062966":"code","c03b04f9":"code","224d4b50":"code","4cb3c3fb":"code","ede06175":"code","03736ab8":"code","617bbccb":"code","0cfc7ff6":"code","7c99a676":"code","54be0ab1":"code","9848f50c":"code","8e01dcfd":"code","5b4f23c0":"code","e71e1177":"code","a174b12e":"code","4ccd20a9":"code","f0928779":"code","737bd1eb":"code","f09e69cb":"code","ecaac759":"code","e3ba8c7d":"code","e6ebb27e":"markdown","d0e8ca2d":"markdown","ed13aa3e":"markdown","8b9595f1":"markdown","197f0615":"markdown","6f44aa27":"markdown","95c7e97e":"markdown","b7a1d836":"markdown","d1ac0c1c":"markdown","f135e233":"markdown","b2faffd3":"markdown","799d9404":"markdown","2e512532":"markdown","581e6fac":"markdown","38470ddd":"markdown","fa01946e":"markdown","0f3fbc24":"markdown","be7f3d6e":"markdown","fa1f3f0c":"markdown","2063df70":"markdown","8397d778":"markdown","ae892d73":"markdown","b9311e08":"markdown","d3b76881":"markdown"},"source":{"c98f6ab6":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom datetime import datetime\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport nltk, re, string, collections\nfrom nltk.util import ngrams\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","113e2850":"# Read CSV files\ncalendar_df = pd.read_csv(\"\/kaggle\/input\/boston\/calendar.csv\")\nlisting_df = pd.read_csv(\"\/kaggle\/input\/boston\/listings.csv\")\nreview_df = pd.read_csv(\"\/kaggle\/input\/boston\/reviews.csv\")","e9173a9d":"calendar_df.info()","2e2a8947":"calendar_df.head()","03858bce":"listing_df.info()","0c30159c":"pd.set_option('display.max_columns', None) #This helps all column names be displayed\nlisting_df.head(2)","0bf4aee1":"review_df.info()","ae9b7c37":"review_df.head()","a5875b3c":"# Drop the duplicates in the datasets\ncalendar_df.drop_duplicates(keep=False,inplace=True)\nlisting_df.drop_duplicates(keep=False,inplace=True)\nreview_df.drop_duplicates(keep=False,inplace=True)","ea6b5043":"# Check null values in the datasets\ncalendar_df_nulls = set(calendar_df.columns[calendar_df.isnull().any()])\nlisting_df_nulls = set(listing_df.columns[listing_df.isnull().any()])\nreview_df_nulls = set(review_df.columns[review_df.isnull().any()])\nprint (\"the columns having null values in calendar_df is: \", calendar_df_nulls)\nprint (\"the columns having null values in listing_df is: \", listing_df_nulls)\nprint (\"the columns having null values in review_df is: \", review_df_nulls)","4e60cb3e":"# Filter the calendar when the listings were available\navail_calendar = calendar_df[calendar_df.available == \"t\"]\navail_calendar_nulls = set(avail_calendar.columns[avail_calendar.isnull().any()])\nprint (\"the columns having null values in avail_calendar is: \", avail_calendar_nulls)","96678e52":"# Ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Convert to datetime value\navail_calendar[\"date\"] = pd.to_datetime(avail_calendar[\"date\"]) \n\n# Create a function to cleanse price values\nprice_w = lambda x : (x.replace('.00','').replace('$','').replace(',','')) \n\n# Use the function\navail_calendar.price = avail_calendar.price.apply(price_w)\n\n# Convert the \"price\" value to numeric\navail_calendar.price = pd.to_numeric(avail_calendar.price)\n\n#A quick look at the top results\navail_calendar.head(10) ","5891e8a1":"# Use the price_w function to price values in listing dataframe\nlisting_df.price = listing_df.price.apply(price_w) \n\n# Convert the \"price\" value to numeric\nlisting_df.price = pd.to_numeric(listing_df.price)\n\n# A quick look at the top results\nlisting_df.head(2)","0204efd0":"# Convert to datetime value\ncalendar_df[\"date\"] = pd.to_datetime(calendar_df[\"date\"])\n\n# Sort the data by date\ncalendar_df = calendar_df.sort_values(by = \"date\")\n\n# Find the first and the last day in the data set\nstart = calendar_df[\"date\"].min()\nend = calendar_df[\"date\"].max()\nprint(\"The calendar dataset is for\", end - start, \"; from\",start,\"to\", end)\n","5327a1cc":"# Convert to datetime value\nreview_df[\"date\"] = pd.to_datetime(review_df[\"date\"]) \n\n# Sort the data by date\nreview_df = review_df.sort_values(by = \"date\")\n\n# Find the first and the last day in the data set\nstart = review_df[\"date\"].min()\nend = review_df[\"date\"].max()\nprint(\"The review dataset is for\", end - start, \"; from\",start,\"to\", end)","93ec418c":"# A quick look at the top results\nreview_df.head()","0b062966":"# Select important columns\ncols = [\"id\", \"price\", \"summary\", \"host_response_time\", \"host_response_rate\", \"property_type\", \"accommodates\", \"bathrooms\", \"bedrooms\",\"beds\", \"review_scores_value\", \"review_scores_accuracy\", \"review_scores_rating\", \"review_scores_cleanliness\", \"review_scores_communication\", \"review_scores_location\"]\nlisting_1 = listing_df[cols]\nlisting_1.head()","c03b04f9":"listing_1.price.mean()","224d4b50":"listing_1.price.median()","4cb3c3fb":"# Plot the histogram of Price\nlisting_1.hist(column = \"price\", bins = 100, figsize = (15, 7) )\nplt.show()","ede06175":"# Plot the histograms of review scores\nlisting_1.hist(bins = 10, column = [\"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_communication\", \"review_scores_location\", \"review_scores_value\"], figsize= (17, 10))\nplt.show()","03736ab8":"# Boxplots about accommodates and prices\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.boxplot(x=\"accommodates\", y=\"price\", data=listing_1)\nplt.xlabel(xlabel=\"Number of Accommodates\", fontsize=15)\nplt.ylabel(ylabel=\"Price\", fontsize=15)\n \n# Boxplots about review_score_values and prices \nplt.subplot(1,2,2)\nsns.boxplot(x=\"review_scores_value\", y=\"price\", data=listing_1)\nplt.xlabel(xlabel=\"Review_scores_value\", fontsize=15)\nplt.ylabel(ylabel=\"Price\", fontsize=15)","617bbccb":"# Drop the outliers where prices are much higher than the median\nprice_hi  = listing_1[\"price\"].quantile(0.999)\nlisting_2 = listing_1[listing_1[\"price\"] < price_hi]","0cfc7ff6":"# Display the correlations\nplt.figure(figsize=(12,5))\nsns.heatmap(listing_2.corr(), annot=True)\nplt.show()","7c99a676":"# Drop null values of listing_2dr\nlisting_2 = listing_2.reset_index()\nlisting_2dr = listing_2.dropna(axis = 0)\n\n# The following features are the ones having high correlation with price\nX = listing_2dr[[\"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"review_scores_location\",\"review_scores_cleanliness\"]]\ny = listing_2dr[\"price\"]\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n\n# Fit the train sets to Linear regression model\nln_model = LinearRegression(normalize = True)\nln_model.fit(X_train, y_train)","54be0ab1":"# Predict using the model\ny_test_predict = ln_model.predict(X_test)\n\n# Score using the model\nr2_test = r2_score(y_test, y_test_predict)\nlength_y_test = len(y_test)\nprint(\"The r-squared score for your model was {} on {} values.\".format(r2_test, length_y_test))","9848f50c":"# drop null values in review_df\nreview_df_drna = review_df.dropna(subset = [\"comments\"], axis = 0)\n\nreview_df_drna.head(10)","8e01dcfd":"# Get rid of punctuation (except periods!)\n# Use regular expression to define the punctuation\npunctuationNoPeriod = \"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\" \n# Create punctuation dropping function\npunc_dr = lambda text: (re.sub(punctuationNoPeriod, \"\", text))  \n# Use the function\nreview_df_drna.comments = review_df_drna.comments.apply(punc_dr)\n\n# Merge all values of comments_column as a corpus\ncorpus = ' '.join(review_df_drna.comments)\n# Create English stop word set\nsw_set = set(stopwords.words(\"english\"))\n# Split the words in corpus\ntokenized = [w.lower() for w in corpus.split()]\n\n# Get a list of all the mono-gram, Bigram\nMonogram = tokenized\nBigram = ngrams(tokenized, 2)\n\n# Get the frequency of each monogram\/ Bigram in the corpus\nMono_Freq = dict(collections.Counter(Monogram))\nBi_Freq = dict(collections.Counter(Bigram))\n\n# Filter the n_grams that are not in stop word set\nMono_Freq_no_sw = { k: v for k, v in Mono_Freq.items() if k not in sw_set}\nBi_Freq_no_sw = { k: v for k, v in Bi_Freq.items() if (k[0] not in sw_set) and (k[1] not in sw_set)}\n","5b4f23c0":"# Create graph plotting function\ndef draw_graph(x):\n    data_items = x.items()\n    results_df = pd.DataFrame(list(data_items))\n    results_df.columns = [\"N_grams\", \"count\"]\n    results_df = results_df.sort_values(by = \"count\", ascending = False)\n    results_df[:30].plot(kind = \"barh\",  y= \"count\", x = \"N_grams\", figsize = (10,10),)","e71e1177":"# Plot the top 30 frequent monogram\ndraw_graph(Mono_Freq_no_sw)","a174b12e":"# Plot the top 30 frequent Bigram\ndraw_graph(Bi_Freq_no_sw)","4ccd20a9":"# Column \"month\" is created to easily group by month\navail_calendar[\"month\"] = avail_calendar[\"date\"].dt.to_period(\"m\")\navail_calendar.head(10)","f0928779":"# How does price distribute thoughout a year?\n\n# Group the data by month\navail_grouped = avail_calendar.groupby('month')\n\n# Calculate the mean value of price in each group\ndf_month_price = pd.DataFrame(avail_grouped['price'].mean()).reset_index()\n\n# Plot graph\ndf_month_price.plot.bar(x='month',y='price', title = \"The average listing price from 2016 September to 2017 September\", color='blue', figsize=(15,7))\nplt.show()","737bd1eb":"# How does supply distribute thoughout a year?\n\n# Count the observations of each group\ndf_month_supply = pd.DataFrame(avail_grouped['listing_id'].count()).reset_index()\n\n# Plot graph\ndf_month_supply.plot.bar(x= \"month\",color=\"blue\", title = \"The number of listings available from 2016 September to 2017 September\", figsize=(15,7))\nplt.show()","f09e69cb":"# Column \"month\" is created to easily group by month\nreview_df[\"month\"] = review_df[\"date\"].dt.to_period(\"m\")","ecaac759":"# Consider the last 3-year data \nreview_after20130906 = review_df[review_df.date > datetime.strptime(\"05\/09\/13\", \"%d\/%m\/%y\")]\nreview_after20130906","e3ba8c7d":"# Group the data by month\ndemand_grouped = review_after20130906.groupby('month')\n\n# Count the observations of each group\ndf_month_demand = pd.DataFrame(demand_grouped['listing_id'].count()).reset_index()\n\n# Plot graph\ndf_month_demand.plot.bar(x='month',color='green', title = \"The number of reviews from 2015 September to 2016 September\", figsize=(15,7))\nplt.show()","e6ebb27e":"### Calendar_df","d0e8ca2d":"### Reviews of visitors","ed13aa3e":"## Question 3: Considering the Most Frequent comments in Review dataset\nTo solve this question, I used nltk library to tokenize the language. \nThe portion of negative or positive comments can show satisfication of the visitors.","8b9595f1":"## Question 1: Consider the Correlations between Price and Other Features\nThere are some factors that are positively correlated to price, such as number of accomodates, number of bedrooms or number of beds, etc. These factors are also used to understand how much they affects the price by using a basic linear regression model.","197f0615":"## 2. Libraries\n#### In this project, some basic libraries to process datasets (pandas), linear algebra (numpy), to display charts and graphs (matplotlib.pyplot) are imported.","6f44aa27":"There are some notices after wrangling the datasets","95c7e97e":"### 4.1. Quick look","b7a1d836":"AirBNB is founded in 2008 and there are millions of hosts and travelers choosing to list their space and book unique accommodations anywhere in the world. Understanding the factors that drive the listing price or the seasonality of using the renting service is needed.\nIn this project, I accessed the data of AirBNB house in Boston which show the listing availability calendar from 2016 September to 2017 September; the listings' basic information; and the visitors' comments from 2009 March to 2016 September.","d1ac0c1c":"### Distributions of Prices in Listing dataset\nIt is found that the mean value of prices is 173.9 USD while its median value is 150 USD. There is a gap between the mean and the median vaules becaused of some extremely high values.","f135e233":"Three datasets are imported in this project:\n>- calendar_df\n>- listing_df\n>- review_df","b2faffd3":"### Review_df","799d9404":"## 6. Future work\nSome interesting and useful findings are made in this project. However, there are some points need to be improved in the future:\n>- The model to predict price (add\/replace by other features, use other approach like Lasso linear regression)\n>- Creating a model to understand the relation between review tokens and review scores (NLP sentiment analysis)\n>- Deeply study the accomodation rental demand and supply\n","2e512532":"These 2 plots show the top 30 frequent words or 2-word set in the comments. It can be said that the good reviews for rentals account for a large proportion.","581e6fac":"## Question 2: Formulate a model to Predict Price using Linear Regression Algorithm\nAs the correlations to price are equal or more than 0.15, \"accommodates\", \"bathrooms\", \"bedrooms\", \"beds\", \"review_scores_location\",\"review_scores_cleanliness\" are chosen to predict the estimates of price. Nonetheless, the R2_score is quite low so feature selection step should be carefully considered or other different regression models should be used.","38470ddd":"## 4.2 Data wrangling\nIn this steps, I have done following steps:\n>- Drop the duplicates in the datasets\n>- Check null values in the datasets\n>- Filter the calendar\n>- Convert to datetime, numeric value","fa01946e":"## Question 4: Distributions of Price, Listing supply and Listing demand\nCalendar dataset is used for prices and supply distribution and Review calendar is used for listing demand.\nI made the assumption that the number of reviews is proportional to the number of uses of the Airbnb service in Boston. With this assumption, it is easily seen that the demand for rooms in December, January and February is much lower than in the others. Meanwhile, service supply and price remained unchanged between months. Therefore, I recommend that listing owners should lower the room rates from December to February to increase competition and attract more visitors.","0f3fbc24":"### Listing availability calendar","be7f3d6e":"## 1. Introduction \u30fb Objective\nThis is my first project for Udacity Data Science Nanodegree and it is to understand some insights and to check the feature correlations of Boston AirBnB data.\nThe project focuses on 4 following questions:\n>- Question 1: Correlations between Price and other Features\n>- Question 2: Model formulation to predict Price using Linear Regression Algorithm\n>- Question 3: The most frequent n_grams in Review dataset's comments\n>- Question 4: Distribution of Price, Listing Supply and Listing Demand\n\n\nThe CRISP-DM methodology is used to build this data science project, including:\n>- Business Understanding\n>- Data Understanding\n>- Prepare Data\n>- Model Data\n>- Results\n","fa1f3f0c":"## 4. Business Understading \u30fb Data understanding (EDA)  \u30fb Data Preparation","2063df70":"### Listing information","8397d778":"# [Udacity Nanodegree: Data Science] Boston AirBNB\n![\u30ad\u30e3\u30d7\u30c1\u30e3.PNG](attachment:9b7c8d2a-f9f6-4162-ab3d-9f5319ba1943.PNG)\n## Table of content\n#### 1. Introduction \u30fb Objective\n#### 2. Libraries \n#### 3. Datasets\n#### 4. Business Understading \u30fb Data understanding (EDA)  \u30fb  Data preparation\n#### 5. Model \u30fb Results\n>- Question 1: Consider the Correlations between Price and Other Features\n>- Question 2: Formulate a model to Predict Price using Linear Regression Algorithm\n>- Question 3: The most frequent n_grams in Review dataset's comments\n>- Question 4: Distribution of Price, Listing Supply and Listing Demand\n\n#### 6. Future work\n\n\n\n","ae892d73":"Another way to observe the distributions is creating box plot. As the box plots show below, there are some extremely high values of price that make tha mean is much higher than median. Therefore, we can drop the outliers so the dataset can be cleaner.","b9311e08":"## 3. Importing datasets","d3b76881":"## 5. Modelling and Results"}}