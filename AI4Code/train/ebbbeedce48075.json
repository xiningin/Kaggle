{"cell_type":{"dd3caff9":"code","57293794":"code","cb632627":"code","8c680ac5":"code","e303f79b":"code","b6b3f5f5":"code","d4141a5f":"code","3c421a36":"code","c3617669":"code","a19165b8":"code","186d08ee":"code","d5d475a6":"code","bcdb7068":"code","422707e1":"code","b56956c2":"code","d104ed11":"code","26b649b2":"markdown","dfa30add":"markdown","765d542d":"markdown","da3f230b":"markdown","52d741de":"markdown","8898332a":"markdown","3aa0f433":"markdown","bf0c84c2":"markdown","254307dd":"markdown"},"source":{"dd3caff9":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.optimizers import Adam","57293794":"DATADIR = '..\/input\/covidistesgp\/CovidDataset'\n\nTRAIN_DIR = os.path.join(DATADIR, 'train')\nTEST_DIR = os.path.join(DATADIR, 'validation')","cb632627":"aug = ImageDataGenerator(\n    rotation_range=7,\n    width_shift_range=0.5,\n    height_shift_range=0.5,\n    brightness_range=(0.9, 1.1),\n    shear_range=2,\n    zoom_range=0.1,\n    fill_mode='nearest',\n    channel_shift_range=1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    data_format='channels_last',\n    rescale=1\/255,\n    validation_split=0.3,\n)\n\nload = ImageDataGenerator(\n    rescale=1\/255\n)","8c680ac5":"IMG_SIZE=299\n\ntrain_datagen = aug.flow_from_directory(\n    TRAIN_DIR,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=32,\n    shuffle=True,\n    class_mode='binary',\n    color_mode='rgb',\n    subset='training',\n)\nvalidation_datagen = aug.flow_from_directory(\n    TRAIN_DIR,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=8,\n    shuffle=True,\n    class_mode='binary',\n    color_mode='rgb',\n    subset='validation',\n)\n\ntest_datagen = load.flow_from_directory(\n    TEST_DIR,\n    class_mode='binary',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    color_mode='rgb',\n)","e303f79b":"base = InceptionV3(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n)","b6b3f5f5":"model = Sequential()\n\nmodel.add(base)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='tanh'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))","d4141a5f":"base.trainable = False","3c421a36":"for i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","c3617669":"model.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(lr=0.001), \n    metrics=tf.keras.metrics.AUC()\n)\n\nmodel.summary()","a19165b8":"model.fit(train_datagen, epochs=5, validation_data=validation_datagen)","186d08ee":"for layer in model.layers[-20:]:\n    if not isinstance(layer, BatchNormalization):\n        layer.trainable = True","d5d475a6":"for i, layer in enumerate(model.layers):\n    print(i, layer.name, layer.trainable)","bcdb7068":"model.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(lr=0.0001), \n    metrics=tf.keras.metrics.AUC()\n)\n\nmodel.summary()","422707e1":"model.fit(train_datagen, epochs=5, validation_data=validation_datagen)","b56956c2":"score = model.evaluate(train_datagen)\nprint('Train Loss: ', score[0])\nprint('Train Accuracy: ', score[1])","d104ed11":"score = model.evaluate(test_datagen)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy: ', score[1])","26b649b2":"# ISTE-DL-SGP-21 WEEK 4 ASSIGNMENT\n","dfa30add":"### Image Data Generator","765d542d":"## Importing Libraries ","da3f230b":"## Score","52d741de":"#### Unfreezing Base Layers","8898332a":"#### Freezing InceptionV3 Params\n","3aa0f433":"## Transfer Learning","bf0c84c2":"## Preprocessing the Dataset","254307dd":"### Using InceptionV3"}}