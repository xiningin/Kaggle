{"cell_type":{"fffe374c":"code","645cb37b":"code","d42e40fc":"code","f0102da3":"code","e06b370e":"code","f4be6d7f":"code","674e7bd9":"code","696c2c66":"code","93b75c49":"code","4fde7191":"code","ed696c1e":"code","90af9f69":"code","40bb4b3a":"code","d8bdcd7b":"code","95d44df8":"code","da92d082":"code","a0947a39":"code","fd4584a1":"code","d681ac9f":"code","921ff035":"code","8145fcf5":"code","39915d89":"code","9767599f":"code","74bdab09":"code","13df501a":"code","ac6c85a9":"code","2741a9bb":"code","a3fd82b0":"code","9866eae0":"code","c3c7037f":"code","17536864":"code","28d6eb11":"code","bbcaafe4":"code","42194771":"code","c9d63273":"code","96e95d16":"code","37f1f283":"code","85a5ea91":"code","40210e7f":"code","abd26a4c":"code","f00ebcee":"code","75ebe395":"code","6a7aef7c":"code","b920d35b":"code","d181f8c2":"code","753df832":"code","dfd0f781":"code","2b3ba36a":"code","fc77563f":"code","04317946":"code","c7f5a4b1":"code","d0bddc1d":"code","12a52d9b":"code","31470775":"code","23fd4562":"code","8bee7b5a":"code","5e7b5127":"code","6493e2a5":"code","979b6673":"code","e6261aad":"code","6a3f23a3":"code","b581b648":"code","fc1dee92":"code","6729fd87":"code","eed04c52":"code","fc46cda3":"code","3659381e":"code","829b27c3":"code","5e7364ac":"code","90db231b":"code","2ebf57b7":"code","eea7b3b2":"code","c412f188":"code","5b28584a":"code","ce8e09ef":"code","a6e4f708":"code","582d3717":"code","38244e42":"markdown","c2936617":"markdown","5be27f3d":"markdown","16f4c042":"markdown","086e43b1":"markdown","00dd3e47":"markdown","b63fe5fc":"markdown","3b70a1cb":"markdown","8c2ae701":"markdown","5fe638b0":"markdown","7ca4de03":"markdown","af53af16":"markdown","72f5b5bb":"markdown","c4caf47d":"markdown","5a4ad1a3":"markdown","feb5fc69":"markdown","775b9b5f":"markdown","ba6a2538":"markdown","09958e9f":"markdown","63f0c551":"markdown","3a965efa":"markdown","b5b7e2b4":"markdown","cd49a17b":"markdown","91d7fca6":"markdown","04fce25a":"markdown","61072265":"markdown","a82518c2":"markdown","34558436":"markdown","afd3c9b7":"markdown","029add9a":"markdown","f55c0721":"markdown","ef76f9a7":"markdown","1e7e7d2a":"markdown","0f2e1610":"markdown","878b3cc8":"markdown","77827d6a":"markdown","4710966c":"markdown","fc575acb":"markdown","cc857b42":"markdown","245a4615":"markdown","249d1cab":"markdown","ddacf61e":"markdown","2376d773":"markdown","2d051846":"markdown","61f21932":"markdown","c1869001":"markdown","198019ae":"markdown","a477d946":"markdown","669771b3":"markdown","25788617":"markdown","d084c585":"markdown","bd826b75":"markdown","1aadb366":"markdown","f492c541":"markdown","dcb8555e":"markdown","113cd616":"markdown","3f262b62":"markdown","4ff92dfe":"markdown"},"source":{"fffe374c":"# Link workspace to Comet experiment\n# !pip install comet_ml\n# from comet_ml import Experiment\n# experiment = Experiment(api_key=\"zNkJjcVKOMD5gKd05z6CwT4OD\", project_name=\"team-rm5-sigmoidfreuds\", workspace=\"lizette95\")","645cb37b":"# Ignore warnings\nimport warnings\nwarnings.simplefilter(action='ignore')\n\n# Install Prerequisites\n# import sys\n# import nltk\n# !{sys.executable} -m pip install bs4 lxml wordcloud scikit-learn scikit-plot\n# nltk.download('vader_lexicon')\n\n# Exploratory Data Analysis\nimport re\nimport ast\nimport time\nimport nltk\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom textblob import TextBlob\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\n# Data Preprocessing\nimport string\nfrom bs4 import BeautifulSoup\nfrom collections import Counter\nfrom nltk.corpus import wordnet\nfrom nltk.corpus import stopwords\nfrom sklearn.utils import resample\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import TweetTokenizer \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Classification Models\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Performance Evaluation\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import GridSearchCV\nfrom scikitplot.metrics import plot_roc, plot_confusion_matrix\nfrom sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n\n# Display\n%matplotlib inline\nsns.set(font_scale=1)\nsns.set_style(\"white\")","d42e40fc":"train_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ntest_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')\ndf_train = train_data.copy() #For EDA on raw data\ndf_test = test_data.copy()","f0102da3":"train_data.head()","e06b370e":"test_data.head()","f4be6d7f":"## Initial Cleaning\n# contractions = {\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"i'd\": \"I would\", \"i'd've\": \"I would have\", \"i'll\": \"I will\", \"i'll've\": \"I will have\", \"i'm\": \"I am\", \"i've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it had\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there had\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we had\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'alls\": \"you alls\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you had\", \"you'd've\": \"you would have\", \"you'll\": \"you you will\", \"you'll've\": \"you you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n# contractions_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n# def expand_contractions(text):\n#     \"\"\"\n#     Expand contractions using dictionary of contractions.\n#     \"\"\"\n#     def replace(match):\n#         return contractions[match.group(0)]\n#     return contractions_re.sub(replace, text)\n\n# punctuation = string.punctuation + '0123456789'\n# stop_words = stopwords.words('english')\n# stop_words.extend(['via','rt'])\n\n# def clean(df):\n#     \"\"\"\n#     Apply data cleaning steps to raw data.\n#     \"\"\"\n#     df['lower'] = df['message'].str.lower()\n#     df['html'] = df['lower'].apply(lambda x : BeautifulSoup(x, \"lxml\").text)\n#     df['url'] = df['html'].apply(lambda x : re.sub(r'http\\S+', 'weblink', x))\n#     df['newlines'] = df['url'].apply(lambda x : x.replace('\\n',' '))\n#     df['mentions'] = df['newlines'].apply(lambda x : re.sub('@\\w*', 'twittermention', x))\n#     df['hashtags'] = df['mentions'].apply(lambda x : re.sub('#\\w*', 'hashtag', x))\n#     df['expand'] = df['hashtags'].apply(expand_contractions)\n#     df['token'] = df['expand'].apply(TweetTokenizer().tokenize)\n#     df['stopwords'] = df['token'].apply(lambda x : [word for word in x if word not in stop_words])\n#     df['punc'] = df['stopwords'].apply(lambda x : [i for i in x if i not in punctuation])\n#     df['dig'] = df['punc'].apply(lambda x: [i for i in x if i not in list(string.digits)])\n#     df['final'] = df['dig'].apply(lambda x: [i for i in x if len(i) > 1])\n#     return df['final']\n\n# train_data['final'] = clean(train_data)\n# test_data['final'] = clean(test_data)","674e7bd9":"# Final Cleaning\ndef sentiment_changer(df):\n    \"\"\"\n    Change key words to reflect the general sentiment associated with it.\n    \"\"\"\n    df['message'] = df['message'].apply(lambda x: x.replace('global', 'negative'))\n    df['message'] = df['message'].apply(lambda x: x.replace('climate', 'positive'))\n    df['message'] = df['message'].apply(lambda x: x.replace('MAGA', 'negative'))\n    return df['message']\n\ntrain_data['message'] = sentiment_changer(train_data)\ntest_data['message'] = sentiment_changer(test_data)\n\ndef clean(df):\n    \"\"\"\n    Apply data cleaning steps to raw data.\n    \"\"\"\n    df['token'] = df['message'].apply(TweetTokenizer().tokenize) ## first we tokenize\n    df['punc'] = df['token'].apply(lambda x : [i for i in x if i not in string.punctuation])## remove punctuations\n    df['dig'] = df['punc'].apply(lambda x: [i for i in x if i not in list(string.digits)]) ## remove digits\n    df['final'] = df['dig'].apply(lambda x: [i for i in x if len(i) > 1]) ## remove all words with only 1 character\n    return df['final']\n\ntrain_data['final'] = clean(train_data)\ntest_data['final'] = clean(test_data)","696c2c66":"train_data.info()","93b75c49":"test_data.info()","4fde7191":"# Number of Tweets Per Sentiment Class\nfig, axis = plt.subplots(ncols=2, figsize=(15, 5))\n\nax = sns.countplot(x='sentiment', data=train_data, palette='winter', ax=axis[0])\naxis[0].set_title('Number of Tweets Per Sentiment Class',fontsize=14)\naxis[0].set_xlabel('Sentiment Class')\naxis[0].set_ylabel('Tweets')\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n\ntrain_data['sentiment'].value_counts().plot.pie(autopct='%1.1f%%', colormap='winter_r', ax=axis[1])\naxis[1].set_title('Proportion of Tweets Per Sentiment Class',fontsize=14)\naxis[1].set_ylabel('Sentiment Class')\n    \nplt.show()","ed696c1e":"# Remove noise\nstop_words = stopwords.words('english')\nstop_words.extend(['via','rt'])\n\ndef remove_noise(tweet):\n    \"\"\"\n    Remove noise from text data, such as newlines, punctuation, URLs and numbers.\n    \"\"\"\n    new_tweet = BeautifulSoup(tweet, \"lxml\").text #HTML Decoding\n    new_tweet = re.sub(r'http\\S+', '', new_tweet) #Remove URLs\n    new_tweet = new_tweet.lower() #Remove Capital Letters\n    new_tweet = new_tweet.replace('\\n',' ') #Remove Newlines\n    new_tweet = re.sub('#(RT|rt)*', '', new_tweet) #Remove RT #s\n    new_tweet = re.sub('@\\w*', '', new_tweet) #Remove Mentions\n    new_tweet = re.sub('\\w*\\d\\w*','', new_tweet) #Remove Numbers\/Words with Numbers\n    new_tweet = re.sub('[^a-zA-z\\s]', '', new_tweet) #Remove Punctuation\n    new_tweet = ' '.join(word for word in new_tweet.split() if word not in stop_words) #Remove Stopwords\n    return new_tweet\n\ndf_train['noise'] = df_train['message'].apply(remove_noise)\ndf_test['noise'] = df_test['message'].apply(remove_noise)","90af9f69":"# Make Wordclouds\ndef wc(df):\n    \"\"\"\n    Join words to create wordclouds.\n    \"\"\"\n    words = ''\n    for i in df:  \n        words += i+\" \"\n    return words\n# Training Set\ntrain_words = wc(df_train['noise'])\ntrain_wordcloud = WordCloud(width=1500, height=700, background_color='white', colormap='winter', min_font_size=10).generate(train_words)\n# Testing Set\ntest_words = wc(df_test['noise'])\ntest_wordcloud = WordCloud(width=1500, height=700, background_color='white', colormap='winter_r', min_font_size=10).generate(test_words)","40bb4b3a":"# Wordcloud Per Sentiment Class\nfig, axis = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))\n\nnews = wc(df_train['noise'][df_train['sentiment']==2])\nnews_wordcloud = WordCloud(width=900, height=600, background_color='white', colormap='winter').generate(news)\naxis[0, 0].imshow(news_wordcloud)\naxis[0, 0].set_title('News (2)',fontsize=14)\naxis[0, 0].axis(\"off\") \n\nneutral = wc(df_train['noise'][df_train['sentiment']==0])\nneutral_wordcloud = WordCloud(width=900, height=600, background_color='white', colormap='winter', min_font_size=10).generate(neutral)\naxis[1, 0].imshow(neutral_wordcloud)\naxis[1, 0].set_title('Neutral (0)',fontsize=14)\naxis[1, 0].axis(\"off\") \n\npro = wc(df_train['noise'][df_train['sentiment']==1])\npro_wordcloud = WordCloud(width=900, height=600, background_color='white', colormap='winter', min_font_size=10).generate(pro)\naxis[0, 1].imshow(pro_wordcloud)\naxis[0, 1].set_title('Pro (1)',fontsize=14)\naxis[0, 1].axis(\"off\") \n\nanti = wc(df_train['noise'][df_train['sentiment']==-1])\nanti_wordcloud = WordCloud(width=900, height=600, background_color='white', colormap='winter', min_font_size=10).generate(anti)\naxis[1, 1].imshow(anti_wordcloud)\naxis[1, 1].set_title('Anti (-1)',fontsize=14)\naxis[1, 1].axis(\"off\") \n\nplt.show()","d8bdcd7b":"# Wordcloud for Training Data\nplt.figure(figsize = (15, 7), facecolor = None) \nplt.title(\"Training Set\",fontsize=20)\nplt.imshow(train_wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\n\nplt.show() ","95d44df8":"# Wordcloud for Testing Data\nplt.figure(figsize = (15, 7), facecolor = None) \nplt.title(\"Testing Set\",fontsize=20)\nplt.imshow(test_wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\n\nplt.show() ","da92d082":"df1_train = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\n\ndrop1 = df1_train.drop_duplicates(['message', 'sentiment'])['tweetid'].values\ndrop2 = df1_train.drop_duplicates(['message'])['tweetid'].values\nprint(f\"Data is duplicated {len(df1_train)-len(drop2)} times\")\n\n# Check for tweets that are the same but have different sentiments\nids = [tweet_id for tweet_id in drop1 if tweet_id not in drop2]\nrepeated_tweets = []\n\nfor tweet_id in ids:\n    tweet = df_train[df1_train['tweetid']==tweet_id]['message']\n    repeated_tweets.append(tweet.values[0])\n\nprint('\\n\\n Tweets that are duplicate but have different sentiments:')\nfor repeated_tweet in repeated_tweets:\n    print(df1_train[df_train['message']==repeated_tweet])\n\n# Get dropped rows \n# https:\/\/stackoverflow.com\/questions\/28901683\/pandas-get-rows-which-are-not-in-other-dataframe\ndropped_rows = df1_train[~df1_train['tweetid'].isin(drop2)].dropna()\n\n# Drop all duplicates from data set\ndf1_train.drop_duplicates(['message', 'sentiment'], inplace=True)\n\n# Drop duplicates with inconsistent classes\ninds_to_drop = []\nfor tweet_id in ids:\n    inds_to_drop = df1_train[df_train['tweetid']==tweet_id].index[0] \n\ndf1_train.drop(index=inds_to_drop, inplace = True)\n\ndf1_train.set_index('tweetid', inplace=True)","a0947a39":"# Vader sentiment\nsid = SentimentIntensityAnalyzer() ## instantiate Sentiment analyzer\n\ndef sent_decider(compound):\n    \"\"\"\n    Function to determine if sentiment is positive, nuetral or negative.\n    \"\"\"\n    neutral_point = 0.00\n    if compound > neutral_point:\n        return 'positive'#1\n    elif compound < -neutral_point:\n        return 'negative' #-1\n    else: \n        return 'neutral'#0\n\n# Get sentiment\ndf1_train['scores'] = df1_train['message'].apply(lambda review: sid.polarity_scores(review))\ndf1_train['compound']  = df1_train['scores'].apply(lambda score_dict: score_dict['compound'])\ndf1_train['comp_score'] = df1_train['compound'].apply(sent_decider)\n\ndef put_numbers_on_bars(axis_object):\n    \"\"\"\n    Function to plot labels above countplot bars.\n    \"\"\"\n    for p in axis_object.patches:\n        axis_object.text(p.get_x() + p.get_width()\/2., p.get_height(),'%d' % round(p.get_height()), fontsize=11,ha='center', va='bottom')\n\nfig, axis = plt.subplots(ncols=2, figsize=(15, 5))\n\nax = sns.countplot(x='comp_score', data=df1_train, palette='winter', hue='sentiment', ax=axis[0])\naxis[0].set_title('Number of Tweets Per Vader Sentiment',fontsize=14)\naxis[0].set_xlabel('')\naxis[0].set_ylabel('Tweets')\nput_numbers_on_bars(ax)\n\nax = sns.countplot(x='sentiment', data=df1_train, palette='winter', hue='comp_score', ax=axis[1])\naxis[1].set_title('Number of Tweets Per Sentiment Class',fontsize=14)\naxis[1].set_xlabel('')\naxis[1].set_ylabel('')\nput_numbers_on_bars(ax)\n\nplt.show()\n\n# Plots as percentages\nfig, axis = plt.subplots(ncols=2, figsize=(15, 5))\ncounts = (df1_train.groupby(['comp_score'])['sentiment'].value_counts(normalize=True).rename('percentage_tweets').mul(100).reset_index())\n\nax = sns.barplot(x=\"comp_score\", y=\"percentage_tweets\", palette='winter', hue=\"sentiment\", data=counts, ax=axis[0])\nput_numbers_on_bars(ax)\nax.set_xlabel('Vader Sentiment')\nax.set_ylabel('Tweets (%)')\n\ncount = (df1_train.groupby(['sentiment'])['comp_score'].value_counts(normalize=True).rename('percentage_tweets').mul(100).reset_index())\n\nax = sns.barplot(x=\"sentiment\", y=\"percentage_tweets\", palette='winter', hue=\"comp_score\", data=counts, ax=axis[1])\nput_numbers_on_bars(ax)\nplt.xlabel('Sentiment Class')\nplt.ylabel('')\n\n# Plot pie charts\nfig, axis = plt.subplots(ncols=4, figsize=(20, 5))\ngroup = [\"(Anti)\", \"(Neutral)\", \"(Pro)\", \"(News)\"]\nfor i in range(4):\n    df1_train[df1_train['sentiment']==i-1]['comp_score'].value_counts().plot.pie(autopct='%1.1f%%',colormap='winter_r',ax=axis[i])\n    axis[i].set_title('Proportion of Tweets Per Vader Sentiment '+ group[i],fontsize=12)\n    axis[i].set_ylabel('')\nplt.show()","fd4584a1":"def subjectivity(text):\n    \"\"\"\n    Calculate subjectivity per tweet.\n    \"\"\"\n    return TextBlob(text).sentiment.subjectivity\ndf_train['Subjectivity'] = df_train['message'].apply(subjectivity)","d681ac9f":"# Sentiment Count from Subjectivity Threshold = 0.5\ndf_train['Subj'] = [\"> 0.5\" if i >=0.5 else \"< 0.5\" for i in df_train['Subjectivity']]\nplt.figure(figsize = (8,5))\nsns.countplot(x='sentiment', data=df_train, palette='winter', hue='Subj')\nplt.xlabel('sentiment')\nplt.ylabel('Counts')\nplt.legend(title = 'Subjectivity')\nplt.title('Sentiment Count from Subjectivity Threshold = 0.5',fontsize=14)\nplt.show()","921ff035":"# Tweet Character lengths\ndf_train['number_of_characters'] = df_train['message'].apply(lambda x: len(x))\n\n# Distribution of Character Count Per Sentiment Class\nfig, axis = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\nfig.suptitle('Distribution of Character Count Per Sentiment Class', fontsize=14)\n\nbins = range(0, 180, 10)\n\ntrain_news = df_train[df_train['sentiment']==2]\naxis[0, 0].hist(train_news['number_of_characters'], bins=bins, weights=np.zeros(len(train_news)) + 1. \/ len(train_news), color='#0017F3')\naxis[0, 0].set_title('News (2)')\naxis[0, 0].set_ylabel('Frequency')\n\ntrain_neutral = df_train[df_train['sentiment']==0]\naxis[1, 0].hist(train_neutral['number_of_characters'], bins=bins, weights=np.zeros(len(train_neutral)) + 1. \/ len(train_neutral), color='#008BB9')\naxis[1, 0].set_title('Neutral (0)')\naxis[1, 0].set_ylabel('Frequency')\naxis[1, 0].set_xlabel('Character Count')\n\ntrain_pro = df_train[df_train['sentiment']==1]\naxis[0, 1].hist(train_pro['number_of_characters'], bins=bins, weights=np.zeros(len(train_pro)) + 1. \/ len(train_pro), color='#00BAA2')\naxis[0, 1].set_title('Pro (1)')\n\ntrain_anti = df_train[df_train['sentiment']==-1]\naxis[1, 1].hist(train_anti['number_of_characters'], bins=bins, weights=np.zeros(len(train_anti)) + 1. \/ len(train_anti), color='#00E88B')\naxis[1, 1].set_title('Anti (-1)')\naxis[1, 1].set_xlabel('Character Count')\n\nplt.show()","8145fcf5":"# Tweet word lengths\ndf_train['number_of_words'] = df_train['message'].apply(lambda x: len(x.split(' ')))\n\n# Distribution of Word Count Per Sentiment Class\nfig, axis = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\nfig.suptitle('Distribution of Word Count Per Sentiment Class', fontsize=14)\n\nbins = range(0, 30, 2)\n\ntrain_news = df_train[df_train['sentiment']==2]\naxis[0, 0].hist(train_news['number_of_words'], bins=bins, weights=np.zeros(len(train_news)) + 1. \/ len(train_news), color='#0017F3')\naxis[0, 0].set_title('News (2)')\naxis[0, 0].set_ylabel('Frequency')\n\ntrain_neutral = df_train[df_train['sentiment']==0]\naxis[1, 0].hist(train_neutral['number_of_words'], bins=bins, weights=np.zeros(len(train_neutral)) + 1. \/ len(train_neutral), color='#008BB9')\naxis[1, 0].set_title('Neutral (0)')\naxis[1, 0].set_ylabel('Frequency')\naxis[1, 0].set_xlabel('Word Count')\n\ntrain_pro = df_train[df_train['sentiment']==1]\naxis[0, 1].hist(train_pro['number_of_words'], bins=bins, weights=np.zeros(len(train_pro)) + 1. \/ len(train_pro), color='#00BAA2')\naxis[0, 1].set_title('Pro (1)')\n\ntrain_anti = df_train[df_train['sentiment']==-1]\naxis[1, 1].hist(train_anti['number_of_words'], bins=bins, weights=np.zeros(len(train_anti)) + 1. \/ len(train_anti), color='#00E88B')\naxis[1, 1].set_title('Anti (-1)')\naxis[1, 1].set_xlabel('Word Count')\n\nplt.show()","39915d89":"# Check if URLs have anything to do with distribution of sentiments.\n# Count URLs\nurl_text = r\"https?:\/\/t\\.co\/\\S+\"\n\ndf_train['url_list'] = df_train['message'].apply(lambda tweet: re.findall(url_text, tweet))\n\ndf_train['url_count'] = df_train['url_list'].apply(len)\n\n# Plot sentiment\nplt.figure(figsize = (8,5))\nsns.countplot(x='sentiment', data=df_train, palette='winter', hue='url_count')\nplt.title('Number of URLs Per Sentiment Class',fontsize=14)\nplt.xlabel('Sentiment Class')\nplt.ylabel('Tweet Frequency')\nplt.legend(title='URL Count')\nplt.show()","9767599f":"def grab_hash_tags_or_mention(tweet, grab='#'):\n    \"\"\"\n    Extract hashtags and mentions based on prefix symbols.\n    \"\"\"\n    return [tag.lower() for tag in tweet.split() if tag.startswith(grab)]\n\npuntuations=string.punctuation+'\u2026'+'\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a6'\n\ndef remove_punct_end_of_tag(tag):\n    \"\"\"\n    Remove punctuation at end of hashtag.\n    \"\"\"\n    ortag = tag\n    not_alpha=True\n    tag_lenth = len(tag)\n    if tag_lenth <= 2:\n        return None\n    elif (tag[-8:]=='#\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a6') or (tag[-8:]=='@\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a6'):\n        return None\n    for i in range(tag_lenth):\n        if tag:\n            if (tag[-1] in puntuations):\n                tag = tag[:-1]\n                not_alpha = tag[-1] in puntuations\n            else:\n                break         \n    return tag","74bdab09":"# Grab hashtags and mentions\ndf_train['hash_tags'] = df_train['message'].apply(grab_hash_tags_or_mention)\ndf_train['hash_tags'] = df_train['hash_tags'].apply(lambda tags: [remove_punct_end_of_tag(tag) for tag in tags if tag])\n\ndf_train['mentions'] = df_train['message'].apply(lambda tweet: grab_hash_tags_or_mention(tweet, grab='@'))\ndf_train['mentions'] = df_train['mentions'].apply(lambda tags: [remove_punct_end_of_tag(tag) for tag in tags if tag])","13df501a":"# Split hashtags based on sentiment class\nHT_neg = df_train['hash_tags'][df_train['sentiment'] == -1]\nHT_neutral = df_train['hash_tags'][df_train['sentiment'] == 0]\nHT_pos = df_train['hash_tags'][df_train['sentiment'] == 1]\nHT_news = df_train['hash_tags'][df_train['sentiment'] == 2]\n\nHT_neg = sum(HT_neg, [])\nHT_neutral = sum(HT_neutral, [])\nHT_pos = sum(HT_pos, [])\nHT_news = sum(HT_news, [])","ac6c85a9":"# HT_neg\np = nltk.FreqDist(HT_neg)\nd = pd.DataFrame({'Hashtag': list(p.keys()), 'Count': list(p.values())})\nd = d.nlargest(columns = 'Count', n = 15)\nplt.figure(figsize=(12, 6))\nax = sns.barplot(data=d, y ='Hashtag', x ='Count', palette='winter', orient='h')\nplt.title('Negative Hashtags',fontsize=14)\nplt.show()","2741a9bb":"# HT_neutral\np = nltk.FreqDist(HT_neutral)\nd = pd.DataFrame({'Hashtag': list(p.keys()), 'Count': list(p.values())})\nd = d.nlargest(columns = 'Count', n = 15)\nplt.figure(figsize=(12, 6))\nax = sns.barplot(data=d, y ='Hashtag', x ='Count', palette='winter_r', orient='h')\nplt.title('Neutral Hashtags',fontsize=14)\nplt.show()","a3fd82b0":"# HT_pos\np = nltk.FreqDist(HT_pos)\nd = pd.DataFrame({'Hashtag': list(p.keys()), 'Count': list(p.values())})\nd = d.nlargest(columns = 'Count', n = 15)\nplt.figure(figsize=(12, 6))\nax = sns.barplot(data=d, y ='Hashtag', x ='Count', palette='winter', orient='h')\nplt.title('Positive Hashtags',fontsize=14)\nplt.show()","9866eae0":"# HT_news\np = nltk.FreqDist(HT_news)\nd = pd.DataFrame({'Hashtag': list(p.keys()), 'Count': list(p.values())})\nd = d.nlargest(columns = 'Count', n = 15)\nplt.figure(figsize=(12, 6))\nax = sns.barplot(data=d, y ='Hashtag', x ='Count', palette='winter_r', orient='h')\nplt.title('News Related Hashtags',fontsize=14)\nplt.show()","c3c7037f":"def mentions_or_hash_count_df(df, col = 'mentions'): \n    \"\"\"\n    Make count dataframes.\n    \"\"\"\n    tags = []\n    for i, row in df.iterrows():\n        for tag in row[col]:\n            if tag:\n                tags.append(tag)\n    counts = dict(Counter(tags)).items()\n    return pd.DataFrame(counts, columns=[col, col+'_count']).sort_values(by=col+'_count', ascending=False)\n\nmentions_counts = mentions_or_hash_count_df(df_train, col = 'mentions')\nhash_tags = mentions_or_hash_count_df(df_train, col = 'hash_tags')","17536864":"# Create tables for sentiment for Hashtag- and Mentions counts\ndf_sent_selctors = [df_train['sentiment']==sent for sent in [-1,0,1,2]]\n\n# Create empty dataframe that will store the counts with sentiments\nmentions_sents = pd.DataFrame(columns=['mentions', 'mentions_count', 'sentiment'])\nhash_sents = pd.DataFrame(columns=['hash_tags', 'hash_tags_count', 'sentiment'])\n\n# Add values to the empty dataframe\nfor i, selector in enumerate(df_sent_selctors): \n  # mentions\n    mentions_counts = mentions_or_hash_count_df(df_train[selector], col = 'mentions')\n    mentions_counts['sentiment'] = i-1\n    mentions_sents=pd.concat([mentions_sents, mentions_counts], ignore_index=True, copy=False)\n  \n  # hashtags\n    hash_counts = mentions_or_hash_count_df(df_train[selector], col = 'hash_tags')\n    hash_counts['sentiment'] = i-1\n    hash_sents = pd.concat([hash_sents, hash_counts], ignore_index=True, copy=False)","28d6eb11":"# Check Hashtag counts with Sentiments\nb = hash_sents.drop(columns=['sentiment']).groupby('hash_tags').sum()\n(b['hash_tags_count']).sort_values()\nb = b[b['hash_tags_count']>20].sort_values(by= 'hash_tags_count', ascending=False)\nprint(b)\ntop_hash_tags = list(b.index)","bbcaafe4":"# Check Mentions counts with sentiments\na = mentions_sents.drop(columns=['sentiment']).groupby('mentions').sum()\na = a[a['mentions_count']>40].sort_values(by= 'mentions_count', ascending=False)\nprint(a)\ntop_mentions = list(a.index)","42194771":"# Top Mentions and Hashtags\nconditions = [(mentions_sents['mentions']==mention) for mention in top_mentions]\nselector = mentions_sents['mentions'] == ',,,,,,'    \nfor condition in conditions:\n    selector = selector|condition\n\nfig,axis = plt.subplots(figsize=(15,5))\nsns.barplot(x='mentions', y='mentions_count', data=mentions_sents[selector], palette='winter', hue='sentiment')\nplt.xticks(rotation=90)\nplt.title('Number of Sentiment Classes Per Mention',fontsize=14)\nplt.legend(title='Class',loc='upper right')\nplt.ylabel('Count')\nplt.xlabel('Mention')\nplt.show()\n\nconditions = [(hash_sents['hash_tags']==hashtag) for hashtag in top_hash_tags]\nselector = hash_sents['hash_tags'] == ',,,,,,' \nfor condition in conditions:\n    selector = selector|condition\n    \nfig,axis = plt.subplots(figsize=(15,5))\nsns.barplot(x='hash_tags', y ='hash_tags_count', data=hash_sents[selector], palette='winter', hue='sentiment')\nplt.xticks(rotation=90)\nplt.title('Number of Sentiment Classes Per Hashtag',fontsize=14)\nplt.legend(title='Class',loc='upper right')\nplt.ylabel('Count')\nplt.xlabel('Hashtag')\nplt.show()","c9d63273":"# Class distribution for set of retweeted-tweets and set without retweets\nplt.figure(figsize = (8,5))\ndf_train['is_retweet'] = df_train['message'].apply(lambda tweet: 1 if tweet.startswith('RT @') else 0)\nsns.countplot(x='is_retweet', data=df_train, palette='winter', hue='sentiment')\nplt.title('Number of Retweets Per Sentiment Class',fontsize=14)\nplt.xlabel('Is Retweet')\nplt.ylabel('Count')\nplt.legend(title='Class')\nplt.show()","96e95d16":"# Top retweets per Sentiment\ndf_train1 = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ndef count_retweets(df):\n    retweets = []\n    for i, row in df.iterrows():\n        if row['message'].startswith('RT @'):\n            retweets.append(row['message'])\n    counts = dict(Counter(retweets)).items()\n    return pd.DataFrame(counts, columns=['retweeted', 'retweet_count']).sort_values(by='retweet_count', ascending=False)\n\ndf_sent_selctors = [df_train1['sentiment']==sent for sent in [-1,0,1,2]]\nretweet_sents = pd.DataFrame(columns=['retweeted', 'retweet_count', 'sentiment'])\n\nfor i, selector in enumerate(df_sent_selctors):\n    retweet_counts = count_retweets(df_train1[selector])\n    retweet_counts['sentiment'] = i-1\n    retweet_sents=pd.concat([retweet_sents, retweet_counts], ignore_index=True,copy=False)  \n    \nc = retweet_sents.drop(columns=['sentiment']).groupby('retweeted').sum()\nc = c[c['retweet_count']>20].sort_values(by= 'retweet_count').index\ntop_retweets = list(c)\n\n# Plot for all sents\nconditions = [(retweet_sents['retweeted']==retweet) for retweet in top_retweets]\nselector = retweet_sents['retweeted'] == ',,,,,,' \n\nfor condition in conditions:\n    selector = selector|condition\n\nshortened_retweets = retweet_sents.copy()\nshortened_retweets['retweeted'] = shortened_retweets['retweeted'].apply(lambda rt: rt[:20])\nfig,axis = plt.subplots(figsize=(10,5))\nsns.barplot(y='retweeted', x='retweet_count', data=shortened_retweets[selector], palette='winter', hue='sentiment', orient='h')\nplt.title('Sentiment Class Per Retweet for Top Retweets',fontsize=14)\nplt.xlabel('Count')\nplt.ylabel('Retweeted')\nplt.show()","37f1f283":"# Retweet Proportions\ndf1_train['is_retweet'] = df1_train['message'].apply(lambda tweet: 1 if tweet.startswith('RT @') else 0)\nfig, axis = plt.subplots(ncols=4, figsize=(25, 5))\nfig.suptitle('Proportion of Tweets to Retweets Per Sentiment Class', fontsize=20)\ngroup = [\"(Anti)\", \"(Neutral)\", \"(Pro)\", \"(News)\"]\nfor i in range(4):\n    df1_train[(df1_train['sentiment']==i-1) & (df1_train['comp_score']=='negative')]['is_retweet'].value_counts().plot.pie(autopct='%1.1f%%',colormap='winter_r',ax=axis[i])\n    axis[i].set_title('Negative Vader Sentiment '+ group[i])\n    axis[i].set_ylabel('')\nplt.show()\n\nfig, axis = plt.subplots(ncols=4, figsize=(25, 5))\nfor i in range(4):\n    df1_train[(df1_train['sentiment']==i-1) & (df1_train['comp_score']=='neutral')]['is_retweet'].value_counts().plot.pie(autopct='%1.1f%%',colormap='winter_r',ax=axis[i])\n    axis[i].set_title('Neutral Vader Sentiment '+ group[i])\n    axis[i].set_ylabel('')\nplt.show()\n\nfig, axis = plt.subplots(ncols=4, figsize=(25, 5))\nfor i in range(4):\n    df1_train[(df1_train['sentiment']==i-1) & (df1_train['comp_score']=='positive')]['is_retweet'].value_counts().plot.pie(autopct='%1.1f%%',colormap='winter_r',ax=axis[i])\n    axis[i].set_title('Positve Vader Sentiment '+ group[i])\n    axis[i].set_ylabel('')\nplt.show()","85a5ea91":"sid = SentimentIntensityAnalyzer() ## instantiate Sentiment analyzer\n\ndef sent_decider(compound):\n    \"\"\"\n    Function to determine if sentiment is positive, nuetral or negative.\n    \"\"\"\n    neutral_point = 0.00\n    if compound > neutral_point:\n        return 'positive'#1\n    elif compound < -neutral_point:\n        return 'negative' #-1\n    else: \n        return 'neutral'#0\n\n# Get sentiment\ndropped_rows['scores'] = dropped_rows['message'].apply(lambda review: sid.polarity_scores(review))\ndropped_rows['compound']  = dropped_rows['scores'].apply(lambda score_dict: score_dict['compound'])\ndropped_rows['comp_score'] = dropped_rows['compound'].apply(sent_decider)\n\n# Plots\n\nfig, axis = plt.subplots(ncols=2, figsize=(20, 5))\ncounts = (dropped_rows.groupby(['comp_score'])['sentiment'].value_counts(normalize=True).rename('percentage_tweets').mul(100).reset_index())\n\nax = sns.barplot(x=\"comp_score\", y=\"percentage_tweets\", palette='winter', hue=\"sentiment\", data=counts, ax=axis[0])\nput_numbers_on_bars(ax)\naxis[0].set_xlabel('Vader Sentiment')\naxis[0].set_ylabel('Tweets (%)')\naxis[0].set_title('Dropped Retweets Per Vader Sentiment',fontsize=14)\n\ncounts = (dropped_rows.groupby(['sentiment'])['comp_score'].value_counts(normalize=True).rename('percentage_tweets').mul(100).reset_index())\n\nax = sns.barplot(x=\"sentiment\", y=\"percentage_tweets\", palette='winter', hue=\"comp_score\", data=counts, ax=axis[1])\nput_numbers_on_bars(ax)\naxis[1].set_xlabel('Sentiment Class')\naxis[1].set_ylabel('Tweets (%)')\naxis[1].set_title('Dropped Retweets Per Sentiment Class',fontsize=14)\n\nfig, axis = plt.subplots(ncols=2, figsize=(20, 5))\n\nax = sns.countplot(x='comp_score', data=dropped_rows, palette='winter', hue='sentiment', ax=axis[0])\naxis[0].set_title('Dropped Retweets Per Vader Sentiment',fontsize=14)\naxis[0].set_xlabel('Vader Sentiment')\naxis[0].set_ylabel('Tweets')\nput_numbers_on_bars(ax)\n\nax = sns.countplot(x='sentiment', data=dropped_rows, palette='winter', hue='comp_score', ax=axis[1])\naxis[1].set_title('Dropped Retweets Per Sentiment Class',fontsize=14)\naxis[1].set_xlabel('Sentiment Class')\naxis[1].set_ylabel('Tweets')\nput_numbers_on_bars(ax)\n\nplt.show()\n\n# Plot Pie chart for duplicate retweets's Vader sentiment share and Class share\nfig, axis = plt.subplots(ncols=3, figsize=(20, 5))\naxis = axis.flat\n\n(dropped_rows['comp_score'].value_counts().plot.pie(autopct='%1.1f%%', colormap='winter_r', ax=axis[0]))\naxis[0].set_title('Proportion of Dropped Retweets Per Vader Sentiment',fontsize=14)\naxis[0].set_ylabel('')\n\n(dropped_rows['sentiment'].value_counts().plot.pie(autopct='%1.1f%%', colormap='winter_r', ax=axis[1]))\naxis[1].set_title('Proportion of Dropped Retweets Per Sentiment Class',fontsize=14)\naxis[1].set_ylabel('')\n\n(dropped_rows['comp_score'].value_counts().plot.pie(autopct='%1.1f%%', colormap='winter_r', ax=axis[2]))\naxis[2].set_title('Proportion of Pro-Climate Change \\n Dropped Retweets Per Vader Sentiment',fontsize=14)\naxis[2].set_ylabel('')\nplt.show()","40210e7f":"# Analyse dropped rows (retweets)\ndropped_rows['is_retweet'] = dropped_rows['message'].apply(lambda tweet: 1 if tweet.startswith('RT @') else 0)\ndropped_rows = dropped_rows[dropped_rows['is_retweet']==1]\n\nfig, axis = plt.subplots(ncols=2, figsize=(15, 5))\n\nax = sns.countplot(x=\"sentiment\", palette='winter', data=dropped_rows, ax=axis[0])\nput_numbers_on_bars(ax)\naxis[0].set_xlabel('Sentiment Class')\naxis[0].set_ylabel('Tweets')\naxis[0].set_title('Dropped Retweets Per Sentiment Class',fontsize=14)\n\n\nax = sns.countplot(x=\"sentiment\", palette='winter', data=df1_train[df1_train['is_retweet']==1], ax=axis[1])\nput_numbers_on_bars(ax)\naxis[1].set_xlabel('Sentiment Class')\naxis[1].set_ylabel('Tweets')\naxis[1].set_title('Retweets Per Sentiment Class',fontsize=14)\nplt.show()\n\n# As percentage\nfig, axis = plt.subplots(ncols=2, figsize=(15, 5))\n\n# Count retweets in duplicate retweets and complete orignal data\ncounts_original = (df1_train['sentiment'].value_counts())\ncounts_retweets = (dropped_rows['sentiment'].value_counts())\n\ncounts_retweets_fraction = ((counts_retweets\/counts_original*100).rename_axis('sentiment').reset_index(name='Number of Tweets'))\n\nax = sns.barplot(x='sentiment', y='Number of Tweets', data=counts_retweets_fraction, palette='winter', ax=axis[0])\nax.set_title('Dropped Retweets as Fraction of Total All Tweets',fontsize=14)\nax.set_xlabel('Sentiment Class')\nax.set_ylabel(\"Retweets (%)\")\nax.set_ylim(ymax=33)\nput_numbers_on_bars(ax)\n\n# Count retweets in orignal data\ncounts_original = (df1_train[df1_train['is_retweet']==1]['sentiment'].value_counts())\ncounts_retweets = (dropped_rows['sentiment'].value_counts())\n\ncounts_retweets_fraction = ((counts_retweets\/counts_original*100).rename_axis('sentiment').reset_index(name='Number of Tweets'))\n\nax = sns.barplot(x='sentiment', y='Number of Tweets', data=counts_retweets_fraction, palette='winter', ax=axis[1])\nax.set_title('Dropped Retweets as Fraction of Retweets',fontsize=14)\nax.set_xlabel('Sentiment Class')\nax.set_ylabel(\"Retweets (%)\")\nax.set_ylim(ymax=33)\nput_numbers_on_bars(ax)\nplt.show()","abd26a4c":"# Remove words used to scrape tweets\n# all_classes = ['globalwarming','global','warming','climatechange', 'climate', 'change']\n# train_data['final'] = train_data['final'].apply(lambda x : [i for i in x if i not in all_classes])\n# test_data['final'] = test_data['final'].apply(lambda x : [i for i in x if i not in all_classes])","f00ebcee":"# train_data['final'] = train_data['final'].replace(to_replace = r\"[\\d-]\", value = '', regex = True)\n# train_data['final'] = train_data['final'].replace(to_replace = \"...\", value = '')\n# train_data['final'] = train_data['final'].replace(to_replace = \"..\", value = '')","75ebe395":"# df_pro = train_data[train_data['sentiment']==1]\n# df_news =  train_data[train_data['sentiment']==2]\n# df_neutral = train_data[train_data['sentiment']==0]\n# df_anti = train_data[train_data['sentiment']==-1]\n# train_data['sentiment'].value_counts()","6a7aef7c":"# class_size = 3640 # Class size = can be roughly half the size of the largest size\n# def resampling(df):\n#     if len(df['sentiment']) > class_size:\n#         df = resample(df, replace=False, n_samples=class_size, random_state=42)\n#     else:\n#         df = resample(df, replace=True, n_samples=class_size, random_state=42)\n#     return df\n# df_pro_resampled = resampling(df_pro)\n# df_news_resampled =  resampling(df_news)\n# df_neutral_resampled = resampling(df_neutral)\n# df_anti_resampled = resampling(df_anti)\n# train_data = pd.concat([df_pro_resampled,df_news_resampled,df_neutral_resampled,df_anti_resampled])\n# train_data['sentiment'].value_counts()","b920d35b":"def get_part_of_speech(word):\n    \"\"\"\n    Find part of speech of word if part of speech is either noun, verb, adjective etc and add it to a list.\n    \"\"\"\n    probable_part_of_speech = wordnet.synsets(word) ## finding word that is most similar (synonyms) for semantic reasoning\n    pos_counts = Counter() ## instantiating our counter class\n    pos_counts[\"n\"] = len([i for i in probable_part_of_speech if i.pos()==\"n\"])\n    pos_counts[\"v\"] = len([i for i in probable_part_of_speech if i.pos()==\"v\"])\n    pos_counts[\"a\"] = len([i for i in probable_part_of_speech if i.pos()==\"a\"])\n    pos_counts[\"r\"] = len([i for i in probable_part_of_speech if i.pos()==\"r\"])\n    most_likely_part_of_speech = pos_counts.most_common(1)[0][0] ## will extract the most likely part of speech from the list\n    return most_likely_part_of_speech\n\nnormalizer = WordNetLemmatizer()\n\ntrain_data['final'] = train_data['final'].apply(lambda x: [normalizer.lemmatize(token, get_part_of_speech(token)) for token in x])\ntest_data['final'] = test_data['final'].apply(lambda x: [normalizer.lemmatize(token, get_part_of_speech(token)) for token in x])","d181f8c2":"X = train_data['final']\ny = train_data['sentiment']\nX_test = test_data['final']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state = 42)","753df832":"X_train = list(X_train.apply(' '.join))\nX_val = list(X_val.apply(' '.join))\n\nvectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\nvectorizer.fit(X_train)\n\n# vect_save_path = \"TfidfVectorizer.pkl\"\n# with open(vect_save_path,'wb') as file:\n#     pickle.dump(vectorizer,file)\n\nX_train = vectorizer.transform(X_train)\nX_val = vectorizer.transform(X_val)","dfd0f781":"modelstart = time.time()\nlogreg = LogisticRegression(C=1000, multi_class='ovr', solver='saga', random_state=42, max_iter=10)\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_val)\nlogreg_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('Accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\nresults = pd.DataFrame(report).transpose()\n# results.to_csv(\"logreg_report.csv\")\nresults\n# model_save_path = \"logreg_model.pkl\"\n# with open(model_save_path,'wb') as file:\n#     pickle.dump(logreg,file)","2b3ba36a":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","fc77563f":"modelstart= time.time()\nmultinb = MultinomialNB()\nmultinb.fit(X_train, y_train)\ny_pred = multinb.predict(X_val)\nmultinb_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('Accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\nresults = pd.DataFrame(report).transpose()\n# results.to_csv(\"multinb_report.csv\")\nresults\n# model_save_path = \"multinb_model.pkl\"\n# with open(model_save_path,'wb') as file:\n#     pickle.dump(multinb,file)","04317946":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","c7f5a4b1":"modelstart = time.time()\nrf = RandomForestClassifier(max_features=4, random_state=42)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_val)\nrf_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('Accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\npd.DataFrame(report).transpose()","d0bddc1d":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","12a52d9b":"modelstart = time.time()\nsvc = SVC(gamma = 0.8, C = 10, random_state=42)\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_val)\nsvc_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('Accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\nresults = pd.DataFrame(report).transpose()\n# results.to_csv(\"svc_report.csv\")\nresults\n# model_save_path = \"svc_model.pkl\"\n# with open(model_save_path,'wb') as file:\n#     pickle.dump(svc,file)","31470775":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","23fd4562":"modelstart = time.time() \nlinsvc = LinearSVC()\nlinsvc.fit(X_train, y_train)\ny_pred = linsvc.predict(X_val)\nlinsvc_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('Accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\nresults = pd.DataFrame(report).transpose()\n# results.to_csv(\"linsvc_report.csv\")\nresults\n# model_save_path = \"linsvc_model.pkl\"\n# with open(model_save_path,'wb') as file:\n#     pickle.dump(linsvc,file)","8bee7b5a":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","5e7b5127":"modelstart = time.time()\nkn = KNeighborsClassifier(n_neighbors=1)\nkn.fit(X_train, y_train)\ny_pred = kn.predict(X_val)\nkn_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\nresults = pd.DataFrame(report).transpose()\n# results.to_csv(\"kn_report.csv\")\nresults\n# model_save_path = \"kn_model.pkl\"\n# with open(model_save_path,'wb') as file:\n#     pickle.dump(kn,file)","6493e2a5":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","979b6673":"modelstart = time.time()\ndt = DecisionTreeClassifier(random_state=42)    \ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_val)\ndt_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\npd.DataFrame(report).transpose()","e6261aad":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","6a3f23a3":"modelstart = time.time()\nad = AdaBoostClassifier(random_state=42)\nad.fit(X_train, y_train)\ny_pred = ad.predict(X_val)\nad_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))\nreport = classification_report(y_val, y_pred, output_dict=True)\npd.DataFrame(report).transpose()","b581b648":"plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","fc1dee92":"# Compare Weighted F1-Scores Between Models\nfig,axis = plt.subplots(figsize=(10, 5))\nrmse_x = ['Multinomial Naive Bayes','Logistic Regression','Random Forest Classifier','Support Vector Classifier','Linear SVC','K Neighbours Classifier','Decision Tree Classifier','AdaBoost Classifier']\nrmse_y = [multinb_f1,logreg_f1,rf_f1,svc_f1,linsvc_f1,kn_f1,dt_f1,ad_f1]\nax = sns.barplot(x=rmse_x, y=rmse_y,palette='winter')\nplt.title('Weighted F1-Score Per Classification Model',fontsize=14)\nplt.xticks(rotation=90)\nplt.ylabel('Weighted F1-Score')\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2, p.get_y() + p.get_height(), round(p.get_height(),2), fontsize=12, ha=\"center\", va='bottom')\n    \nplt.show()","6729fd87":"LogisticRegression().get_params()","eed04c52":"param_grid = {'C': [1000], #[100,1000]\n              'max_iter': [10], #[10,100]\n              'multi_class': ['ovr'], #['ovr', 'multinomial']\n              'random_state': [42],\n              'solver': ['saga']} #['saga','lbfgs']\ngrid_LR = GridSearchCV(LogisticRegression(), param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\ngrid_LR.fit(X_train, y_train)\ny_pred = grid_LR.predict(X_val)\nprint(\"Best parameters:\")\nprint(grid_LR.best_params_)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(classification_report(y_val, y_pred))","fc46cda3":"LinearSVC().get_params()","3659381e":"param_grid = {'C': [100],#[0.1,1,10,100,1000]\n              'max_iter': [10], #[10,100]\n              'multi_class' : ['ovr'], #['crammer_singer', 'ovr']\n              'random_state': [42]} \ngrid_LSVC = GridSearchCV(LinearSVC(), param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\ngrid_LSVC.fit(X_train, y_train)\ny_pred = grid_LSVC.predict(X_val)\nprint(grid_LSVC.best_params_)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(classification_report(y_val, y_pred))","829b27c3":"SVC().get_params()","5e7364ac":"param_grid = {'C': [10],#[0.1,1,10,100,1000]\n              'gamma': [0.8], #[0.8,1]\n              'kernel': ['rbf'], #['linear','rbf']\n              'random_state': [42]} \ngrid_SVC = GridSearchCV(SVC(), param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\ngrid_SVC.fit(X_train, y_train)\ny_pred = grid_SVC.predict(X_val)\nprint(grid_SVC.best_params_)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(classification_report(y_val, y_pred))","90db231b":"y_pred = svc.predict(X_val)\nprint('accuracy %s' % accuracy_score(y_pred, y_val))\nprint(classification_report(y_val, y_pred))","2ebf57b7":"con_mat = plot_confusion_matrix(y_val, y_pred, normalize=True,figsize=(8,8),cmap='winter_r')\nplt.show()","eea7b3b2":"# If model doesn't take \"probability=True\" as an argument (e.g. LinearSVC)\novr =  OneVsRestClassifier(SVC(random_state=42,class_weight='balanced'))\n\ny_train_binarized = label_binarize(y_train, classes=[-1, 0, 1, 2])\ny_val_binarized = label_binarize(y_val, classes=[-1, 0, 1, 2])\nn_classes = 4\n\novr.fit(X_train, y_train_binarized)\n\n# decision_function predicts a \u201csoft\u201d score for each sample in relation to each class, \n# rather than the \u201chard\u201d categorical prediction produced by predict. Its input is \n# usually only some observed data, X.\ny_probas = ovr.decision_function(X_val)\n\nplot_roc(y_val, y_probas,figsize=(8,8),cmap='winter_r')\nplt.show()","c412f188":"# Make prediction on test data\nX = train_data['final']\ny = train_data['sentiment']\nX_test = test_data['final']\n\nX = list(X.apply(' '.join))\nX_test = list(X_test.apply(' '.join))\n\nvectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\nvectorizer.fit(X)\n\nX = vectorizer.transform(X)\nX_test = vectorizer.transform(X_test)\n\nsvc = SVC(gamma=0.8, C=10, random_state=42)\nsvc.fit(X, y)\ny_test = svc.predict(X_test)","5b28584a":"# Number of Tweets Per Sentiment Class\nfig, axis = plt.subplots(ncols=2, figsize=(15, 5))\n\nax = sns.countplot(y_test,palette='winter',ax=axis[0])\naxis[0].set_title('Number of Tweets Per Sentiment Class',fontsize=14)\naxis[0].set_xlabel('Sentiment Class')\naxis[0].set_ylabel('Tweets')\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2., p.get_height(), '%d' % int(p.get_height()), fontsize=11, ha='center', va='bottom')\n\nresults = pd.DataFrame({\"tweetid\":test_data['tweetid'],\"sentiment\": y_test})\nresults['sentiment'].value_counts().plot.pie(autopct='%1.1f%%',colormap='winter_r',ax=axis[1])\naxis[1].set_title('Proportion of Tweets Per Sentiment Class',fontsize=14)\naxis[1].set_ylabel('Sentiment Class')\n    \nplt.show()","ce8e09ef":"# Create Kaggle Submission File\nresults = pd.DataFrame({\"tweetid\":test_data['tweetid'],\"sentiment\": y_test})\nresults.to_csv(\"Team_RM5_final_submission.csv\", index=False)","a6e4f708":"## Create Comet logs\n# print(\"\\nResults\\nConfusion matrix \\n {}\".format(confusion_matrix(y_val, y_pred)))\n# f1 = f1_score(y_val, y_pred,average=\"macro\")\n# precision = precision_score(y_val, y_pred,average=\"macro\")\n# recall = recall_score(y_val, y_pred,average=\"macro\")\n# params = {\"random_state\": 42,\n#           \"model_type\": \"svc\",\n#           \"param_grid\": \"str(param_grid)\",\n#           \"stratify\": True,\n#           }\n# metrics = {\"f1\": f1,\n#            \"recall\": recall,\n#            \"precision\": precision\n#            }\n\n# experiment.log_parameters(params)\n# experiment.log_metrics(metrics)\n# experiment.end()","582d3717":"## Display Comet experiment\n# experiment.display()","38244e42":"### Label\nWe can examine the number of tweets that fall within a sentiment class and calculate the proportion of tweets that is represented by each class.","c2936617":"**Linear SVC**","5be27f3d":"### Performance Metrics of Best Models\n\nWe built and tested eight different classification models and compared their performance using a statistical measure known as the weighted F1 score, which takes into account the proportions of each class fed into the model. This is a weighted average of the precision and recall of the model and is the measure that will be used to test the accuracy of our Kaggle output. \n\n#### Precision\n\nWhen it predicts \"True\", how often is it correct? \n\n$$ Precision = \\frac{TP}{TP \\space + FP} = \\frac{TP}{Total \\space Predicted \\space Positive} $$\n\n#### Recall\n\nWhen the outcome is actually \"True\", how often do we predict it as such?\n\n$$ Recall = \\frac{TP}{TP \\space + FN} = \\frac{TP}{Total \\space Actual \\space Positive}$$\n\n#### F1 Score\n\nWeighted average of precision and recall. \n\n$$F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }$$","16f4c042":"### Support Vector Classifier\nA Support Vector Classifier is a discriminative classifier formally defined by a separating hyperplane. When labelled training data is passed to the model, also known as supervised learning, the algorithm outputs an optimal hyperplane which categorizes new data.","086e43b1":"### K Neighbours Classifier\nThe K Neighbours Classifier is a classifier that implements the k-nearest neighbours vote. In classification, the output is a class membership. An object is classified by a plurality vote of its neighbours, with the object being assigned to the class most common among its k-nearest neighbours.","00dd3e47":"From the above figures, we see that the opinion expressed earlier is not fully supported by the data. Anti and Pro classes have a similar  proportion of tweets that express themselves in a positive manner (38.5% and 38.1%, respectively). The Anti class has a higher proportion of tweets that are negatively expressed compared to the Pro class. This could possibly be because Anti climate proponents are associated with right wing politics, which is in turn associated with populist hostility ([Matthew Lockwood, 2018](http:\/\/sro.sussex.ac.uk\/id\/eprint\/81164\/1\/Right%20wing%20populism%20and%20the%20climate%20agenda%20Accepted%20Manuscript.pdf)).  \n\nSome observations worth noting:\n* The Anti class has the lowest proportion of tweets that are expressed with neutrality compared to the other classes' proportions. \n* Neutrally expressed tweets are largest for the News class, as they are expected to deliver information in a balanced manner. * The highest proportion of tweets are expressed negatively. \n* The tweets that fall under the Neutral class have a much larger proportion (49.2%) of tweets that are expressed positively. \n* Our assumption is therefore wrong: The distributions appear to be very similar, but we don't know how much of this is due to the number of positive vs. the number of negative sentiments.\n* The Neutral and News classes tend be more neutral compared to proportions of other classes. \n* The Neutral class also tends to be more positive than the rest.","b63fe5fc":"**Support Vector Classifier**","3b70a1cb":"### Table of Contents\n---\n1. [Introduction](#intro)\n * Background\n * Problem Statement\n---\n2. [Load Dependencies](#imports)\n---\n3. [Data Cleaning](#cleaning)\n---\n4. [Exploratory Data Analysis](#EDA)\n * Datasets and Variables\n * Data Summary\n * Label\n * WordClouds\n * Sentiment Analysis\n * Subjectivity\n * Character and Word Frequencies\n * URL Analysis\n * Hashtag and Mention Analysis\n * Retweet Analysis\n---\n5. [Data Preprocessing](#preprocessing)\n * Feature Engineering\n * Lemmatisation\n * Split Training and Validation Sets\n * Feature Extraction\n---\n6. [Modelling](#modelling)\n * Multinomial Naive Bayes\n * Logistic Regression\n * Random Forest Classifier\n * Support Vector Classifier\n * Linear SVC\n * K Neighbours Classifier\n * Decision Tree Classifier\n * AdaBoost Classifier\n---\n7. [Performance Evaluation](#evaluation)\n * Performance Metrics of Best Models\n * Hyperparameter Tuning of Best Models\n---\n8. [Model Analysis](#analysis)\n * Performance Metrics\n * ROC Curves and AUC\n * Results\n---\n9. [Conclusion](#conclusion)\n---\n10. [Save Output](#save)\n---","8c2ae701":"### Random Forest Classifier\nRandom forest models are an example of an ensemble method that is built on decision trees (i.e. it relies on aggregating the results of an ensemble of decision trees). Decision tree machine learning models represent data by partitioning it into different sections based on questions asked of independent variables in the data. Training data is placed at the root node and is then partitioned into smaller subsets which form the 'branches' of the tree. In random forest models, the trees are randomized and the model returns the mean prediction of all the individual trees.","5fe638b0":"### Linear SVC\nThe objective of a Linear Support Vector Classifier is to return a \"best fit\" hyperplane that categorises the data. It is similar to SVC with the kernel parameter set to \u2019linear\u2019, but it is implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and can scale better to large numbers of samples.","7ca4de03":"In this project, we succeeded in building a supervised machine learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data. Our top performing model has a weighted F1 score of 0.78, based on our validation set, and the results from our testing set are in line with what was observed in the training set. We think that it is possible that the number of Pro tweets is related to the fact that \"97% or more of actively publishing climate scientists agree: climate-warming trends over the past century are extremely likely due to human activities.\" ([Nasa](https:\/\/climate.nasa.gov\/scientific-consensus\/#*))\n\n**Impact investing** is an emerging field that refers to investments made into companies and organisations with the intention to generate measurable social or environmental impact alongside financial return. Many companies are built around lessening one\u2019s environmental impact or carbon footprint and they offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. These companies would like to determine how people perceive climate change and whether or not they believe it is a real threat. Our model provides a valuable solution to this problem and can add to their market research efforts in gauging how their product or service may be received. It gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories, thus increasing their insights and informing future marketing strategies.\n\nFrom our exploratory data analysis, we can draw some marketing-related insights. For maximum reach in marketing campaigns that target a specific group of people that have a certain stance with regard to climate change, a marketing team can consider the following:\n* Neutral class\n  - Tweets should have a positive Vader sentiment\n* Positive class\n  - Tweets with a positive Vader sentiment will have less reach than negative or neutral tweets. Marketing should focus on negative (highest priority) or neutral Vader sentiment when tweeting. \n* Negative class\n  - Less clear\n* News related class\n  - News agencies should consider writing their tweets with a positve Vader sentiment to have greatest reach and retweets. \n  \nThe rise of impact investment has caused companies to focus on generating a positive social and environmental impact in addition to financial returns. It would assist companies to ally their brand and products with the Pro climate change movement. Pro climate change tweets tend to have a wider reach than other classes. Not only is it an ethical stance but it has potential to increase exposure of the brand on Twitter. Their tweets could be used to add their voice to the fight against global warming and thus be expressed as a negative sentiment or possibly nuetral. This could maximize their reach even further and also introduces other considerations, such as financial rewards due to carbon taxes.","af53af16":"It appears that the majority of Sanders and Schlegel mentions (and others) are due to retweets. Could these retweets be the reason that there are so much more Pro climate change tweets compared to other classes? If we look at the non-retweeted (original) tweets, the Pro class is not as exaggerated.\n\nThe @realDonaldTrump tweets do not show up as much as the other mentions and hashtags. These mentions and hashtags also do not have an exaggerated difference between classes.","72f5b5bb":"### Hashtag and Mention Analysis","c4caf47d":"### Multinomial Naive Bayes\nThe Multinomial Naive Bayes model estimates the conditional probability of a particular feature given a class and uses a multinomial distribution for each of the features. The model assumes that each feature makes an independent and equal contribution to the outcome.","5a4ad1a3":"### Lemmatisation\nLemmatisation aims to remove inflectional word endings to return the base or dictionary form of a word, also known as \"lemma\". We used the WordNetLemmatizer() from nltk, as well as by way of applying part of speech.","feb5fc69":"### Split Training and Validation Sets\n* Training data: Data that contains a known label. The model is trained on this data to be able to generalize unlabeled data.\n* Validation data: A subset of the training data that is used to assess how well the algorithm was trained on the training data.\n* Test data: Data that is used to provide an unbiased evaluation of the final model fit on the training dataset.","775b9b5f":"[Back to top \u2191](#top)","ba6a2538":"### Feature Engineering","09958e9f":"**Logistic Regression**","63f0c551":"### ROC Curves and AUC\nROC curves show the trade-off between sensitivity and specificity of a classification model. Classifiers that produce curves closer to the top-left corner indicate a better performance. The area under the ROC curve (AUC), is equivalent to the probability that a randomly chosen positive instance is ranked higher than a randomly chosen negative instance. High AUC values are a general measure of good predictive accuracy.","3a965efa":"<a id=\"conclusion\"><\/a>\n## 9. Conclusion","b5b7e2b4":"### Data Summary","cd49a17b":"From the performance metrics, we see that the **Support Vector Classifier** performed the best on our validation set, closely followed by the **Linear SVC** and **Logistic Regression** models. The K Neighbours Classifier significantly performed the worst, which may be due to the k value that was selected for the model. To ensure that we get a robust measure of classifier performance, we will apply cross validation and hyperparameter tuning on the top three performing models.","91d7fca6":"<a id=\"EDA\"><\/a>\n## 4. Exploratory Data Analysis\n\n### Datasets and Variables\n\n**Datasets:**  \n* train.csv: We will use this data to train our model.  \n* test.csv: We will use this data to test our model.  \n\n**Variables:**  \n* sentiment: Sentiment of tweet  \n* message: Tweet body  \n* tweetid: Unique Twitter ID  \n\nThe collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected. Each tweet is labelled as one of the following classes:  \n\n| Class | Description                                                                              |\n| :----:|:-----------------------------------------------------------------------------------------|\n| **2** |**News:** The tweet links to factual news about climate change                            |\n| **1** |**Pro:** The tweet supports the belief of man-made climate change                         |\n| **0** |**Neutral:** The tweet neither supports nor refutes the belief of man-made climate change |\n| **-1**|**Anti:** The tweet does not believe in man-made climate change                           |","04fce25a":"<a id=\"modelling\"><\/a>\n## 6. Modelling","61072265":"We initially applied extensive cleaning steps to the data in order to remove noise that could influence the performance of our classification models. However, after testing multiple combinations of cleaning and preprocessing steps, our models showed better performance with minimal cleaning and preprocessing.","a82518c2":"### Hyperparameter Tuning of Best Models\n**Cross validation** is a technique used to test the accuracy of a model's prediction on unseen data (validation sets). This is important because it can assist in picking up issues such as over\/underfitting and selection bias. We used the K-fold technique to perform cross validation. \n\n**Hyperparameter tuning** is the process by which a set of ideal hyperparameters are chosen for a model. A hyperparameter is a parameter for which the value is set manually and tuned to control the algorithm's learning process.","34558436":"### URL Analysis","afd3c9b7":"### Retweet Analysis","029add9a":"<a id=\"save\"><\/a>\n## 10. Save Output","f55c0721":"<a id=\"top\"><\/a>\n# <font color='#0017F3'>Team <font color='#008BB9'>RM5 <font color='#00BAA2'>Classification <font color='#00C77C'>Predict <font color='#00E88B'>Notebook<\/font>\n### <font color='#082C64'>Kaggle Submission: Team_RM5_SigmoidFreuds <sup>*<\/sup><\/font>\n---\n<img src=\"https:\/\/github.com\/Lizette95\/classification-predict-streamlit-template\/blob\/master\/resources\/imgs\/rm5_banner.png?raw=true\" align=\"left\">  ","ef76f9a7":"### Performance Metrics","1e7e7d2a":"The graphs reveal that our data is **imbalanced**, as more than 50% of the entries fall within sentiment class \"1\". We addressed this in the data preprocessing phase by resampling the data before building our models. However, resampling the data did not improve the performance of the models.","0f2e1610":"From the figure, it appears that tweets related to news are more likely to have links than not, compared to other classes.","878b3cc8":"From the figure, we can conclude that the subjectivity measure is not a very good predictor of classifying sentiment and thus may not be an important feature.","77827d6a":"### WordClouds   \nWordclouds can be used to visualise text data, where the frequency of each word is proportional to the word size.","4710966c":"### Logistic Regression\nLogistic regression is a statistical model that makes use of a logistic function to model a binary dependent variable, however, multiclass classification with logistic regression can be done through the one-vs-rest scheme in which a separate model is trained for each class to predict whether an observation is that class or not (thus making it a binary classification problem).","fc575acb":"### Character and Word Frequencies","cc857b42":"**Team Members:** Abednego Pakaree, Iman Mokwena, Lizette Loubser, Omphile Louw, Refiloe Elvis Phipa, Silindokuhle Kubheka    \n**Supervisor:** Ridha Moosa\n\n* [Notebook repo](https:\/\/github.com\/Lizette95\/Team_RM5_ClassificationPredict_Notebook)\n* [Streamlit repo](https:\/\/github.com\/Lizette95\/classification-predict-streamlit-template)\n* [Trello board](https:\/\/trello.com\/b\/pFKnwtGF\/classificationteamrm5) \n\n_(Note: All outputs are displayed. This notebook runs for about 15 minutes from start to end.)_","245a4615":"### Subjectivity\nSubjective sentences generally refer to personal opinion, emotion or judgment and can be measured as a value between 0 and 1.","249d1cab":"<a id=\"analysis\"><\/a>\n## 8. Model Analysis\nWe used a TF-IDF vectorizer to compute a weight for each word token by its level of importance and vectorize it and we used a radial basis function support vector classifier (SVC) to train our model. After a bit of hyperparameter tuning, we found the following parameters to work well: {'C': 10, 'gamma': 0.8, 'kernel': 'rbf', 'random_state': 42}. An aggressive max_df removes the most common occuring words in the corpus. This improves our model as by looking at bag of words in our EDA, most frequent words have very little semantic meaning. A token pattern of alphanumeric words performed best and since the average tweet has around 17 words, an n-gram of 1 to 2 performs best in capturing semantic meaning. The SVC parameters were chosen because the radial basis function performs better than a Linear SVC at splitting up the areas in which the different semantic lies. This is possibly due to the fact that the classification is not binary.","ddacf61e":"---\nFrom the above summaries, we note that:\n* None of our datasets have **missing values**\n* There is no **sentiment** column in the test data, as this is the **label** that we want to predict\n* There are **15 819** entries in our training dataset\n* There are **10 546** entries in our testing dataset","2376d773":"From the above figures, we note that:\n* The number of repeated retweets in the News class are rarely neutral, but seem to favour tweets that have a positive Vader sentiment. \n* The majority of repeated retweets in the Neutral class favour positive Vader Sentiment tweets (70% of neutral class). \n* Tweets in the Anti class are rarely repeatedly retweeted if they tweet a neutral Vader sentiment tweet. \n* The Anti climate change tweets are retweeted repeatedly almost equally for retweets with negative and positive Vader sentiment. \n* The tweets that express a Pro-climate change stance dominate for all repeated retweets (82.5%). \n* Pro tweets are repeatedly retweeted the least when they express tweets with a positive Vader sentiment.","2d051846":"<a id=\"intro\"><\/a>\n## 1. Introduction  \n\n### Background\n\nMany companies are built around lessening one\u2019s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product or service may be received.\n\nCompanies require access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies. We can implement machine learning classification algorithms to solve this problem.\n\nMachine learning is the study of computer algorithms that improve automatically through experience. It is a powerful branch of Artificial intelligence, dating as far back as 1952. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.\n\nClassification is a process of categorizing a given set of data into classes, It can be performed on both structured or unstructured data. The process starts with predicting the class of given data points. The classes are often referred to as target, label or categories.\n\n\n### Problem Statement\n\nBuild a classification model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n","61f21932":"### Decision Tree Classifier\nDecision tree machine learning models represent data by partitioning it into different sections based on questions asked of independent variables in the data. Training data is placed at the root node and is then partitioned into smaller subsets which form the 'branches' of the tree.","c1869001":"<a id=\"preprocessing\"><\/a>\n## 5. Data Preprocessing","198019ae":"<a id=\"imports\"><\/a>\n## 2. Load Dependencies","a477d946":"It is interesting to note that the top hashtag for tweets that do not believe in climate change is political.","669771b3":"From the above wordclouds, we can see that the terms \"climate change\" and \"global warming\" occur frequently in all four sentiment classes. We can remove them during the data preprocessing phase, as these were most likely the terms that were used to identify and scrape tweets pertaining to climate change.","25788617":"### Resampling\nWe addressed the problem of imbalanced training data by resampling the data before building our models. A class size was determined based on the second largest sentiment class and other classes were either upsampled or downsampled according to the class size. However, resampling the data did not improve the performance of the models and we therefore excluded it.","d084c585":"<a id=\"cleaning\"><\/a>\n## 3. Data Cleaning","bd826b75":"### AdaBoost Classifier\nThe AdaBoost classifier is an iterative ensemble method that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset. In the second step, the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.","1aadb366":"### Sentiment Analysis\nAs part of the problem statement, we thought that it would be interesting to identify how each of the sentiment classes express themselves. This can give insights into whether classes express themselves with cynicism, positivity or neither of the two. \n\nIt would be reasonable to assume that Pro-class tweets would express negative sentiments because global warming is not a positive conversation topic. Pro Tweets believe in something negative and could express their belief with a level of cynicism or negativity.","f492c541":"<a id=\"evaluation\"><\/a>\n## 7. Performance Evaluation","dcb8555e":"### Results","113cd616":"For the Pro-climate change class, 18% of tweets are retweeted, whereas the rest of the classes are retweeted repeatedly well below 10%. It appears that in general, the Pro class leads to repeated retweets more than other classes.","3f262b62":"### Feature Extraction\nThe TfidfVectorizer transforms text to feature vectors that can be used as input to a classification model.","4ff92dfe":"<sub>*Team name credit: Ridha (& Freud's mom)<\/sub>"}}