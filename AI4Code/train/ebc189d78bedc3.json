{"cell_type":{"e680eeb3":"code","dfe7bfca":"code","d653fd4e":"code","75e8c87b":"code","d9931956":"code","757a9b81":"code","53a3cab6":"code","5ace9329":"code","46d3435e":"code","6fb726a2":"code","5fa1fe45":"code","ed8aa73b":"code","c00ad7ef":"code","ac46e3ca":"code","84fe61b7":"code","9e1e6374":"code","580186a8":"code","dcce7295":"code","b3b510cf":"code","d1482d34":"code","cfda5017":"code","09b19e01":"code","29000fe3":"code","cd44ab49":"code","5708b664":"code","e1f7e0ad":"code","d8bc582f":"code","373a1dd0":"code","da75c63d":"code","47c314c2":"code","54cb6bef":"code","a2fe4aba":"code","8c243688":"code","4a526600":"code","e0713463":"code","fe68bcba":"code","68d178b5":"code","583b11ee":"code","d471cca2":"code","fcf7534f":"code","0d4d488d":"code","7e35497b":"code","60c299f5":"code","91a02cac":"code","acc8feb9":"code","235d122d":"code","3cd99cbf":"code","3febbd1d":"code","0aec9fdc":"code","19aa6447":"code","00587603":"markdown","46850cf9":"markdown","8c9c20bb":"markdown","7203768e":"markdown","e7abc6af":"markdown","58c7b59c":"markdown","a6f7b2b5":"markdown","e396b625":"markdown","da285f54":"markdown","f6a61796":"markdown","5b73c330":"markdown","988657a5":"markdown","9770f07e":"markdown","0c9de6e9":"markdown","5f832536":"markdown"},"source":{"e680eeb3":"import numpy as np\nimport pandas\nimport seaborn\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report","dfe7bfca":"eeg_df = pandas.read_csv('..\/input\/confused-eeg\/EEG_data.csv')","d653fd4e":"eeg_df.head()","75e8c87b":"print(eeg_df.info())","d9931956":"dem_df = pandas.read_csv('..\/input\/confused-eeg\/demographic_info.csv')","757a9b81":"dem_df = dem_df.rename(columns = {'subject ID' : 'SubjectID'})","53a3cab6":"dem_df['SubjectID'] = dem_df['SubjectID'].astype(np.float64)","5ace9329":"dem_df","46d3435e":"eeg_df = eeg_df.merge(dem_df, how = 'inner', on = 'SubjectID')","6fb726a2":"eeg_df = pandas.get_dummies(eeg_df)","5fa1fe45":"from tabulate import tabulate\ninfo = [[col, eeg_df[col].count(), eeg_df[col].max(), eeg_df[col].min()] for col in eeg_df.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Max', 'Min'], tablefmt = 'orgtbl'))","ed8aa73b":"print('Number of missing values : ' + str(eeg_df.isna().sum().sum()))","c00ad7ef":"eeg_df = eeg_df.drop(['SubjectID', 'VideoID', 'predefinedlabel', ' gender_F'], axis = 1)","ac46e3ca":"eeg_df = eeg_df[eeg_df['Attention'] > 0.0]\neeg_df = eeg_df[eeg_df['Mediation'] > 0.0]","84fe61b7":"eeg_df.hist(figsize = (15, 15))\nplt.show()","9e1e6374":"plt.figure(figsize = (15,15))\nmat = eeg_df.corr()\nseaborn.heatmap(mat, vmin = -1.0, square = True, annot = True)","580186a8":"seaborn.pairplot(eeg_df.drop([col for col in eeg_df.columns if col != 'Gamma1' and col != 'Beta2'],axis=1))\nplt.show()","dcce7295":"eeg_df['user-definedlabeln'].unique()","b3b510cf":"info = [[col, eeg_df[col].count(), eeg_df[col].max(), eeg_df[col].min()] for col in eeg_df.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Max', 'Min'], tablefmt = 'orgtbl'))","d1482d34":"X = np.array(eeg_df.drop(['user-definedlabeln'], axis = 1))\ny = np.array(eeg_df['user-definedlabeln'])","cfda5017":"print(X.min())\nprint(X.max())","09b19e01":"print(y.min())\nprint(y.max())","29000fe3":"from sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","cd44ab49":"print(X.min())\nprint(X.max())","5708b664":"print(y.min())\nprint(y.max())","e1f7e0ad":"print(X.shape)\nprint(y.shape)","d8bc582f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","373a1dd0":"print(X_train.shape)\nprint(y_train.shape)","da75c63d":"print(X_test.shape)\nprint(y_test.shape)","47c314c2":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nmodel = ExtraTreesClassifier(n_estimators = 250, criterion = 'gini', min_samples_split = 2, max_features = None)\nmodel.fit(X_train, y_train)","54cb6bef":"pred = model.predict(X_test)","a2fe4aba":"print('Accuracy : ' + str(accuracy_score(y_test, pred)))\nprint(classification_report(y_test, pred))","8c243688":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, pred)","4a526600":"temp = pandas.DataFrame({'Not Confused' : mat[0,:], 'Confused' : mat[1,:]})","e0713463":"plt.figure(figsize = (10,10))\nseaborn.heatmap(temp, vmin = 0, annot = True, square = True)","fe68bcba":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Input\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization","68d178b5":"def dens_layer (hiddenx) :\n\n    model = Sequential()\n\n    model.add(Dense(hiddenx, activation = 'relu', kernel_regularizer = 'l2'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    return model","583b11ee":"def ann (hidden1, hidden2,hidden3) :\n\n    model = Sequential()\n\n    model.add(Input(shape= (16,)))\n    model.add(dens_layer(hidden1))\n    model.add(dens_layer(hidden2))\n    model.add(dens_layer(hidden3))\n\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\n    return model","d471cca2":"model = ann(32, 16, 16)\nmodel.summary()","fcf7534f":"from keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nreduce = ReduceLROnPlateau(monitor = 'val_loss', patience = 10, verbose = 1)\ncheckp = ModelCheckpoint('.\/result_model.h5', monitor = 'val_loss', save_best_only = True, verbose = 1)","0d4d488d":"history = model.fit(X_train, y_train, batch_size = 32, epochs = 250, callbacks = [checkp, reduce], validation_data = (X_test, y_test))","7e35497b":"plt.figure(figsize = (20,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy (training and validation) vs Epochs')\nplt.legend(['training accuracy' , 'validation accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('acccuracy')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss (training and validation) vs Epochs')\nplt.legend(['training loss', 'validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('losses')","60c299f5":"from keras.models import load_model\nmodel = load_model('.\/result_model.h5')","91a02cac":"pred = model.predict(X_test)","acc8feb9":"pred = pred.reshape(-1)","235d122d":"pred = np.around(pred)","3cd99cbf":"print(pred[:10])\nprint(y_test[:10])","3febbd1d":"print('Accuracy : ' + str(accuracy_score(y_test, pred)))\nprint(classification_report(y_test, pred))","0aec9fdc":"mat = confusion_matrix(y_test, pred)\ntemp = pandas.DataFrame({'Not Confused' : mat[0,:], 'Confused' : mat[1,:]})","19aa6447":"plt.figure(figsize = (10,10))\nseaborn.heatmap(temp, vmin = 0.0, square = True, annot = True)","00587603":"There is a good correlation between **Gamma1** and **Beta2**, so let's look at their graphs.","46850cf9":"# Decision Forests and Boosting algorithms","8c9c20bb":"# Data Visualization","7203768e":"# ANN Model","e7abc6af":"# Data Preprocessing","58c7b59c":"# Data Cleaning\nIt is obvious that **SubjectID** and **VideoID** will overfit the model, because there are 10 clips in all for each of the 10 students and these 60sec clips are divided into parts of 0.5sec samples. So, model may end up learning the IDs and predict on that basis.","a6f7b2b5":"# Add demographic data","e396b625":"# Get the arrays from dataset","da285f54":"### Confusion Matrix","f6a61796":"**Observations** : Mediation and Attention have some **0 value which is an error**, as claimed by the author in one of the discussions. Also the confusion is scaled between 0 and 1.\n","5b73c330":"# Description\n### EEG signals\nElectroencephalography helps to acquire brain signals from various parts of the brain from scalp to surface area. These signal are categorized as **delta**, **theta**, **alpha**, **beta**, and **gamma**.\n\n### Experiment\nEEG signal data from 10 college students was collected while they watched MOOC videos. There were twenty videos, 10 were on basic topics like algebra and the other 10 were complex like Quantum Mechanics.\n\n### Procedures\nThe students wore a single channel wireless headset, to capture their eeg signals and reported their confusion on a scale of one to seven, one being easiest and 7 being tough.","988657a5":"# Important Points to note (mentioned in discussions by the author)\n#### Participant #3 and #7 are outliers and can cause issues.\n#### 0 values for **Attention** and **Mediation**","9770f07e":"# One hot encoding","0c9de6e9":"# Split into training and testing set","5f832536":"This graph visually shows the correlation between **Gamma1** and **Beta2**. The correlation no longer looks promising enough to discard a column. So all columns will be used."}}