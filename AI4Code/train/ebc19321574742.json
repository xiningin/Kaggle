{"cell_type":{"e49841ee":"code","0cad2a8e":"code","299da235":"code","ec6f53fa":"code","c28da35e":"code","469d8af9":"code","4d5e97ad":"code","22b5a42b":"code","150302fb":"code","65728639":"code","f7f150d0":"code","58adf04c":"code","17d097d1":"code","a90ca816":"code","ffb3a4c4":"code","e2f3f9fe":"code","a850f9ca":"code","89f43911":"code","4474611f":"code","c6dbfdd2":"code","ed8f28be":"code","5138ab9b":"code","ddc10e28":"code","4d94d228":"code","e594bc46":"code","f8fe0a7e":"code","6ee4f314":"code","3b49f343":"code","4a147b43":"code","e10d9dd8":"code","4fac4220":"code","dcbd70e8":"code","30be9aa5":"code","2176164f":"code","c54ab774":"code","69db692e":"code","0e972d83":"code","c98c7bc0":"code","761e7eb7":"code","30c15b64":"code","b95c3a9d":"code","cb68be03":"code","e093bfac":"code","534adaad":"code","54ebf78d":"code","6ac0153b":"code","a07065fa":"code","67fe72d5":"code","f2844cbc":"code","71f736d2":"code","3ad6dd9c":"code","786d733a":"markdown","3b13f6b7":"markdown","f1769d19":"markdown","390bcd15":"markdown","e82d93c0":"markdown","de2fb32b":"markdown","9ecbbf91":"markdown","6a1260d8":"markdown","d4044701":"markdown","95d6efd5":"markdown","b83a6a61":"markdown","3ea1d9cc":"markdown","12b9ad28":"markdown","40397b45":"markdown","05de66ee":"markdown","a726c437":"markdown","5766a5cf":"markdown","943455fc":"markdown","bba9fa6e":"markdown","a91ad806":"markdown","308c3c92":"markdown","e1a8270c":"markdown","b683d228":"markdown","58f77cd2":"markdown","d499837e":"markdown","c092e978":"markdown"},"source":{"e49841ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cad2a8e":"train = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ntest = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\nsample = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')","299da235":"import pandas_profiling #pre-installed","ec6f53fa":"train_prof = pandas_profiling.ProfileReport(df=train)\ntest_prof = pandas_profiling.ProfileReport(df=test)","c28da35e":"# train_prof","469d8af9":"# test_prof","4d5e97ad":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom scipy import stats","22b5a42b":"def plot_graphs(df,feature):\n    (osm, osr), (slope, intercept, r) = stats.probplot(df[feature], plot=None)\n    fig = make_subplots(\n    rows=1, cols=2,\n\n    subplot_titles=(\n        \"Quantile-Quantile Plot of \" + feature,\n        \"Distribution Plot of \" + feature\n    )\n    )\n\n\n    fig.add_trace(go.Scatter(\n    x=osm,\n    y=slope*osm + intercept,\n    mode='lines',\n    line={\n        'color': '#c81515',\n        'width': 2.5\n    }\n\n    ), row=1, col=1)\n    fig.add_trace(go.Scatter(\n    x=osm,\n    y=osr,\n    mode='markers',\n    marker={\n        'color': '#496595'\n    }\n    ), row=1, col=1)\n    fig1 = ff.create_distplot([df[feature]],['target'], \n                         bin_size=.05, show_rug=False)\n    mean_value = df[feature].mean()\n    median_value = df[feature].median()\n\n    fig.add_trace(go.Scatter(\n    fig1['data'][1],\n    line=dict(\n\n    width=1.5,\n    ),\n    fill='tozeroy'\n    ),row=1,col=2)\n    fig.add_annotation(\n    yref=\"y domain\",\n    x=mean_value,\n    y=0.5,\n    axref=\"x\",\n    ayref=\"y domain\",\n    ax=mean_value + 0.2*mean_value,\n    ay=0.1,\n    text=f\"<span>{feature.capitalize()} mean<\/span>= {round(mean_value,3)}\",\n    row=1,col=2)\n    fig.add_annotation(\n    yref=\"y domain\",\n    x=median_value,\n    y=0.3,\n    axref=\"x\",\n    ayref=\"y domain\",\n    ax=median_value + 0.2*median_value,\n    ay=0.2,\n    text=f\"<span>{feature.capitalize()} median<\/span>= {round(median_value,3)}\",\n    row=1,col=2)\n    fig.add_vline(\n    x=mean_value, \n    line_width=2, \n    line_dash=\"dash\",row=1,col=2\n    )\n    fig.add_vline(\n    x=median_value, \n    line_width=2,line_dash=\"dash\",line_color='red' ,row=1,col=2\n\n    )\n\n    fig.update_layout(showlegend=False)\n    fig.show()","150302fb":"plot_graphs(train,'target')","65728639":"plot_graphs(train[train['standard_error']!=0],'standard_error')","f7f150d0":"sns.jointplot(data= train[train['standard_error']!=0],\n    x='target', \n    y='standard_error', \n    kind='hex',\n    height=8,\n\n)\nplt.suptitle(\"Target vs Standard error \",font=\"Serif\", size=20)\nplt.subplots_adjust(top=0.95)\nplt.show()","58adf04c":"import nltk\nfrom nltk.tokenize import sent_tokenize\nfrom statistics import mean","17d097d1":"#https:\/\/stackoverflow.com\/a\/55608579\ndef min_max_mean_sentence_length(text):\n\n    tokened_sent = sent_tokenize(text)\n    main_dict = {}\n    for item in tokened_sent:\n        item1 = list(item.split(\" \"))\n        item2 = [' '.join(item1)]\n        Length = []\n        Length.append(len(item1))\n        mydict = dict(zip(item2, Length))\n        main_dict.update(mydict)\n\n    return max(main_dict.values()), min(main_dict.values()), round(mean(main_dict.values()),3)","a90ca816":"def basic_features(_):\n    df= _.copy()\n    df['excerpt_len'] = df['excerpt'].apply(lambda x : len(x))\n    df['excerpt_word_count'] = df['excerpt'].apply(lambda x : len(x.split(' ')))\n    df[['max_len_sent','min_len_sent','avg_len_sent']] = df.apply(lambda x: min_max_mean_sentence_length(x['excerpt']),axis=1, result_type='expand')\n    return df","ffb3a4c4":"train = basic_features(train)","e2f3f9fe":"train.head()","a850f9ca":"def plot_feature(feature):\n\n    fig, axes = plt.subplots(ncols=2, figsize=(32, 6))\n\n    sns.regplot(x=train['target'], y=train[feature], line_kws={'color': 'red'}, ax=axes[0])\n    sns.kdeplot(train[feature], fill=True, ax=axes[1])\n\n    axes[0].set_xlabel(f'target', size=18)\n    axes[0].set_ylabel(feature, size=18)\n    axes[1].set_xlabel('')\n    axes[1].set_ylabel('')\n    axes[1].legend(prop={'size': 15})\n    for i in range(2):\n        axes[i].tick_params(axis='x', labelsize=15)\n        axes[i].tick_params(axis='y', labelsize=15)\n    axes[0].set_title(f'target vs {feature}', size=20, pad=20)\n    axes[1].set_title(f'{feature} Distribution', size=20, pad=20)\n\n    plt.show()","89f43911":"for feature in ['excerpt_len', 'excerpt_word_count', 'min_len_sent', 'max_len_sent', 'avg_len_sent']:\n    plot_feature(feature)","4474611f":"# Split into train and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(columns='target'), train['target'].values, random_state=42,test_size=0.20)\nprint(len(X_train), len(y_train))\nprint(len(X_test), len(y_test))","c6dbfdd2":"features = ['excerpt_len', 'excerpt_word_count', 'min_len_sent', 'max_len_sent', 'avg_len_sent']","ed8f28be":"from sklearn.metrics import mean_squared_error","5138ab9b":"pred_y = [train['target'].mean()] * len(y_test)\nprint(f' Test RMSE when we fill predictions with mean value of target in train data is {round(np.sqrt(mean_squared_error(y_test,pred_y)),4)}')","ddc10e28":"import lightgbm as lgb\ngbm = lgb.LGBMRegressor(random_state=42)\ngbm.fit(X_train[features],y_train,eval_metric='mse')\npred_y = gbm.predict(X_test[features])","4d94d228":"print(f' Test RMSE using basic features {round(np.sqrt(mean_squared_error(y_test,pred_y)),4)}')","e594bc46":"test = basic_features(test)\npred_y = gbm.predict(test[features])","f8fe0a7e":"def create_submission(_,predictions):\n    df =_.copy()\n    df['target'] = predictions\n    return df[['id','target']]","6ee4f314":"# submission = create_submission(test,pred_y)\n# submission.to_csv('.\/submission.csv',index=False)","3b49f343":"#https:\/\/www.kaggle.com\/duboisian\/first-draft-model?scriptVersionId=63553418&cellId=2\ndef GrunningFog(excerpt):\n    \"\"\"\n    function takes a passage and determines the grade level based on the Grunning Fog index method\n    \"\"\"\n    document = excerpt\n    document = document.replace('\\n',' ').split('.')\n    document = [x for x in document if len(x)>1]\n    lemmatizer = nltk.stem.WordNetLemmatizer()\n    words = []\n    ComplexCount = []\n    for sentence in document:\n        tokens = nltk.word_tokenize(sentence)\n        words.append(len(tokens))\n        tokens = [lemmatizer.lemmatize(x) for x in tokens]\n        Complex = [1 if syllable_count(token) >=3 else 0 for token in tokens]\n        ComplexCount.append(np.sum(Complex))\n    ASL = np.mean(words) #Average words per sentence\n    PropComplex = np.sum(ComplexCount)\/np.sum(words) #proprtion of complex words (>= 3 sylables)\n    GrunFog = 0.4*(ASL + (100*PropComplex))\n    return(GrunFog)","4a147b43":"def SMOG(excerpt):\n    document = excerpt\n    document = document.replace('\\n',' ').split('.')\n    document = [x for x in document if len(x)>1]\n    words = []\n    ComplexCount = []\n    for sentence in document:\n        tokens = nltk.word_tokenize(sentence)\n        words.append(len(tokens))\n        Complex = [1 if syllable_count(token) >=3 else 0 for token in tokens]\n        ComplexCount.append(np.sum(Complex))\n    SMOGScore = (1.0430 * np.sqrt(np.sum(ComplexCount) * (30\/len(words)))) + 3.1291\n    return(SMOGScore)","e10d9dd8":"#https:\/\/stackoverflow.com\/a\/46759549\ndef syllable_count(word):\n    word = word.lower()\n    count = 0\n    vowels = \"aeiouy\"\n    if word[0] in vowels:\n        count += 1\n    for index in range(1, len(word)):\n        if word[index] in vowels and word[index - 1] not in vowels:\n            count += 1\n    if word.endswith(\"e\"):\n        count -= 1\n    if count == 0:\n        count += 1\n    return count","4fac4220":"def asw_asl(_):\n    df = _.copy()\n    df['ASL'] = df['excerpt'].apply(lambda row: np.sum([len(x.split(' ')) for x in row.replace('\\n','').split('.')])\/len([len(x.split(' ')) for x in row.replace('\\n','').split('.')]))\n    df['ASW'] = df['excerpt'].apply(lambda row: np.sum([syllable_count(x) if len(x)>0 else 0 for x in row.replace('\\n','').replace('.','').split(' ')])\/len([x for x in row.replace('\\n','').replace('.','').split(' ')]))\n    df['RE'] = df.apply(lambda row: 206.835 - (1.015 * row['ASL']) - (84.6 * row['ASW']),axis = 1)\n    df['FKRA'] = df.apply(lambda row: (0.39 * row['ASL']) + (11.8 * row['ASW']) -15.59 ,axis = 1)\n    df['GrunFog'] = df['excerpt'].apply(lambda row: GrunningFog(row))\n    df['SMOG'] = df['excerpt'].apply(lambda row: SMOG(row))\n    return df","dcbd70e8":"train = asw_asl(train)","30be9aa5":"for feature in ['RE','FKRA','GrunFog','SMOG']:\n    plot_feature(feature)","2176164f":"# Split into train and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(columns='target'), train['target'].values, random_state=42,test_size=0.20)\nprint(len(X_train), len(y_train))\nprint(len(X_test), len(y_test))","c54ab774":"features = ['excerpt_len', 'excerpt_word_count', 'min_len_sent', 'max_len_sent', 'avg_len_sent','ASL',\n 'ASW',\n 'RE',\n 'FKRA',\n 'GrunFog',\n 'SMOG']","69db692e":"import lightgbm as lgb\ngbm = lgb.LGBMRegressor(random_state=42)\ngbm.fit(X_train[features],y_train,eval_metric='mse')\npred_y = gbm.predict(X_test[features])","0e972d83":"print(f' Test RMSE using basic features {round(np.sqrt(mean_squared_error(y_test,pred_y)),4)}')","c98c7bc0":"test = asw_asl(test)","761e7eb7":"test = basic_features(test)\npred_y = gbm.predict(test[features])","30c15b64":"# submission = create_submission(test,pred_y)\n# submission.to_csv('.\/submission.csv',index=False)","b95c3a9d":"import spacy\nfrom tqdm.notebook import tqdm\nnlp = spacy.load('en_core_web_lg')","cb68be03":"import re\ndef clean_text(text):\n    text= text.lower() # make text lowercase\n    text = text.replace(\"\\n\",\" \") #remove \\n from text\n#     text = re.sub('[^A-Za-z0-9., ], ' ', text)\n    return text","e093bfac":"train['excerpt'] = train['excerpt'].apply(lambda x: clean_text(x))\ntest['excerpt'] = test['excerpt'].apply(lambda x: clean_text(x))","534adaad":"X_train = np.vstack([nlp(text).vector for text in tqdm(train['excerpt'])])\ny_train = train['target']\nprint(f'Shape of Train vectors: {X_train.shape}')","54ebf78d":"X_test = np.vstack([nlp(text).vector for text in tqdm(test['excerpt'])])\nprint(f'Shape of Test vectors: {X_test.shape}')","6ac0153b":"from pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","a07065fa":"X_train_df = pd.concat([pd.DataFrame(X_train),train[features]],axis=1)","67fe72d5":"X_test_df = pd.concat([pd.DataFrame(X_test),test[features]],axis=1)","f2844cbc":"X_train, X_val, y_train, y_val = train_test_split(X_train_df, train['target'], test_size=0.2, random_state=42)","71f736d2":"for i in [1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100]:\n    print(f' aplha {i}')\n    regressor = Ridge(alpha=i,fit_intercept=True, normalize=True)\n    regressor.fit(X_train,y_train)\n    print(f'Train Root mean squared error: {mean_squared_error(y_train,regressor.predict(X_train),squared=False)}')\n    print(f'Validation Root mean squared error: {mean_squared_error(y_val,regressor.predict(X_val),squared=False)}')","3ad6dd9c":"regressor = Ridge(alpha=0.1,fit_intercept=True, normalize=False) #aplha =0.1\nregressor.fit(X_train, y_train) \ntest['target'] = regressor.predict(X_test_df)\ntest[['id','target']].to_csv('.\/submission.csv', index=False)","786d733a":"**Understanding \"target\"**","3b13f6b7":"# Basic Features\n* Excerpt Length\n* Excerpt Word Count\n* Max Length of sentence in excerpt\n* Average Length of Sentences","f1769d19":"Notes for test data:\n* only 7 rows are there\n* standard_error is not provided\n","390bcd15":"# Model on Basic Features + Readability Scores + Word 2 Vec","e82d93c0":"Notes for train data:\n* id, target, standard_error are all unique","de2fb32b":"References:\n* https:\/\/www.kaggle.com\/gunesevitan\/commonlit-readability-prize-eda\n* https:\/\/en.wikipedia.org\/wiki\/Bradley%E2%80%93Terry_model\n* https:\/\/www.kaggle.com\/andreshg\/commonlit-a-complete-analysis","9ecbbf91":"* ~19.6% improvement from baseline model","6a1260d8":"1. [The Flesch Reading Ease formula](https:\/\/www.kaggle.com\/prvnkmr\/domain-knowledge-readability-score-methods?scriptVersionId=62948009&cellId=10) <br>\nRE = 206.835 \u2013 (1.015 x ASL) \u2013 (84.6 x ASW)<br>\n*RE = Readability Ease<br>\nASL = Average Sentence Length (i.e., the number of words divided by the number of sentences) <br>\nASW = Average number of syllables per word (i.e., the number of syllables divided by the number of words) <br>\nThe output, i.e., RE is a number ranging from 0 to 100. The higher the number, the easier the text is to read.*\n\n","d4044701":"# Word 2 Vec","95d6efd5":"**Negative Valu**e_______Zero___________**Positive Value** <br>\n*Difficult Excerpt*____ Base Line_____*_Easy Excerpt*","b83a6a61":"* When standard_error is plotted against target without the baseline excerpt, a relationship can be seen. Excerpts with medium ease of read tend to have less spread of scores, however excerpts at both ends have more spread because they are either too easy or too hard for the raters. \n* Raters' subjective opinions vary a lot when they rate those easy and hard excerpts, but they give closer opinions when the excerpts have medium difficulty.","3ea1d9cc":"Version update: <br>\nAdded Word to Vec <br>\nDetailed Notebook with visualizations: https:\/\/www.kaggle.com\/getitdone\/commonlit-word-to-vec-with-umap","12b9ad28":"Let's use Pandas Profiling library to build an intuition around train and test data","40397b45":"* Target column is named as target and it is reading ease of the excerpt. The excerpt with *436ce79fe* id is set as baseline for comparisons. That's the reason why its target and standard_error values are 0. \n* Other excerpts are compared with *436ce79fe* and rated by multiple raters based on their ease of read. \n* After that, the excerpts are ranked with Bradley-Terry model. \n* Therefore, every excerpt with target value greater than 0 are easier to read and every excerpt with target value less than 0 are harder to read compared to that particular excerpt. \n* As there were multiple raters, standard_error tells us the measure of spread of scores among the raters for each excerpt.","05de66ee":"3. [The fog scale](https:\/\/www.kaggle.com\/prvnkmr\/domain-knowledge-readability-score-methods?scriptVersionId=62948009&cellId=12) <br>\nGrade Level = 0.4 (ASL + PHW)<br>\n*ASL = Average Sentence Length (i.e., number of words divided by the number of sentences)<br>\nPHW = Percentage of Hard Words*","a726c437":"* ~14% improvement from baseline model","5766a5cf":"**Baseline using mean value of target**","943455fc":"**LightGBM model**","bba9fa6e":"3. [The SMOG Index](https:\/\/www.geeksforgeeks.org\/readability-index-pythonnlp\/3) <br>","a91ad806":"# **Basic EDA using Pandas Profiling**","308c3c92":"# Model on Basic Features ","e1a8270c":"# Model on Basic Features + Readability Scores","b683d228":"2. [The Flesch-Kincaid Grade Level Readability Formula](https:\/\/www.kaggle.com\/prvnkmr\/domain-knowledge-readability-score-methods?scriptVersionId=62948009&cellId=11) <br>\nFKRA = (0.39 x ASL) + (11.8 x ASW) - 15.59<br>\n*FKRA = Flesch-Kincaid Reading Age<br>\nASL = Average Sentence Length (i.e., the number of words divided by the number of sentences) <br>\nASW = Average number of syllables per word (i.e., the number of syllables divided by the number of words) <br>*\n\n\n","58f77cd2":"# Readability Scores","d499837e":"* Strong negative relationships can be seen from the scatter plots of max_sent_len, avg_sent_len.\n* Other features don't look very promising from their skewed distributions and weak relationships, but they can be still useful in terms of predictive power.","c092e978":"Plotting Basic Features"}}