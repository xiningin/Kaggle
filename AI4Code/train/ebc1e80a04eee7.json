{"cell_type":{"fab8e983":"code","7ba61aa9":"code","437d62b6":"code","73a25edf":"code","6ef6dd35":"code","e3bf98e4":"code","89c3c91c":"code","84c6afa6":"code","bce558c5":"code","83a73bb4":"code","db344322":"code","27313b53":"code","1931d9d9":"code","7bebf929":"code","3b0e0c6f":"code","9b2d6f94":"code","45ecbebc":"code","26d63f4e":"code","ac09e04f":"code","b5762f71":"code","27876854":"code","2ee1655b":"code","696181d1":"code","f24bd817":"code","baf881a3":"code","88fafed7":"code","13089e5a":"code","d954bf31":"code","2d245000":"code","600ada0c":"code","995ed212":"code","70079091":"code","f87c7874":"code","9275e1a7":"code","497043a9":"code","8f51001a":"code","df1d66ee":"code","a26befb4":"code","a6c28ea2":"code","43ec63c6":"code","69272cd2":"code","5d992a20":"code","96ae21fa":"code","a5b43203":"code","0c34cc94":"code","75151605":"code","3ed77bf2":"markdown","8e5b2e70":"markdown","158e3cf6":"markdown","57cd5e38":"markdown","010b075b":"markdown","c59d4336":"markdown","3aa2b352":"markdown","023829cb":"markdown","4e0d35ed":"markdown","acf1cb97":"markdown","985ddbf1":"markdown","e71864f3":"markdown","a31e72a0":"markdown","9679de26":"markdown","b372441f":"markdown","19cc8d52":"markdown"},"source":{"fab8e983":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ba61aa9":"df = pd.read_csv(\"..\/input\/covid19-data-germany-robert-koch-institute\/ef4b445a53c1406892257fe63129a8ea_0.csv\")\ndf.head().style.background_gradient(cmap='afmhot')","437d62b6":"df1 = pd.read_csv(\"..\/input\/covid19-data-germany-robert-koch-institute\/covid19_events_measures.csv\")\ndf1.head()","73a25edf":"#Code by tpmeli  https:\/\/www.kaggle.com\/tpmeli\/barplots-of-all-questions-exploratory\/notebook\n\ndef graph_barplots(df1, colname, title, one_col = False, sort_vals = True, tall = False):\n    \n    if one_col:\n        series = df1[colname].value_counts()\n    else:\n        series = df1.filter(like = colname).sum()\n    \n    if sort_vals:\n        series = series.sort_values()\n        \n    # Get rid of colname in front\n    # Capitalize\n    \n    ax = series.plot(kind = \"barh\")\n    plt.title(title)\n    if tall:\n        plt.gcf().set_figheight(20)\n        \n    plt.show()","6ef6dd35":"graph_barplots(df1, \"In_Short\", \"Covid19, in short, Measures\", one_col = True)","e3bf98e4":"graph_barplots(df1, \"Description\", \"Covid19 Measures Descriptions\", one_col = True)","89c3c91c":"#Code by Puru Behl https:\/\/www.kaggle.com\/accountstatus\/mt-cars-data-analysis\n\nsns.distplot(df['Fallzahl'])\nplt.axvline(df['Fallzahl'].values.mean(), color='red', linestyle='dashed', linewidth=1)\nplt.title('Covid19 Cases Distribution')","84c6afa6":"#Code by Firat Gonen https:\/\/www.kaggle.com\/frtgnn\/elo-eda-lgbm\/notebook \n\nplt.figure(figsize=(10, 6))\nplt.title('Deaths by Covid-19 Distribution')\nsns.despine()\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\nsns.distplot(df['death7_bl'], hist=True, rug=False,norm_hist=True)","bce558c5":"dfcorr=df.corr()\ndfcorr","83a73bb4":"plt.figure(figsize=(10,4))\nsns.heatmap(df.corr(),annot=False,cmap='afmhot')\nplt.show()","db344322":"from sklearn.preprocessing import LabelEncoder\n\n#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')        ","27313b53":"df = pd.get_dummies(df)","1931d9d9":"X = df[['LAN_ew_AGS', 'LAN_ew_EWZ','OBJECTID', 'faelle_100000_EW', 'Death', 'cases7_bl_per_100k', 'cases7_bl', 'death7_bl', 'SHAPE_Length', 'SHAPE_Area']]\ny = df['Fallzahl']","7bebf929":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","3b0e0c6f":"from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\n\ndef cross_val(model):\n    pred = cross_val_score(model, X, y, cv=10)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    \ndef evaluate(true, predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    return mae, mse, rmse, r2_square","9b2d6f94":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('std_scalar', StandardScaler())\n])\n\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)","45ecbebc":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train,y_train)","26d63f4e":"# print the intercept\nprint(lin_reg.intercept_)","ac09e04f":"coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\ncoeff_df","b5762f71":"pred = lin_reg.predict(X_test)","27876854":"plt.scatter(y_test, pred)","2ee1655b":"sns.distplot((y_test - pred), bins=50);","696181d1":"test_pred = lin_reg.predict(X_test)\ntrain_pred = lin_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","f24bd817":"results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df","baf881a3":"from sklearn.linear_model import RANSACRegressor\n\nmodel = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","88fafed7":"results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","13089e5a":"from sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","d954bf31":"results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","2d245000":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=0.1, \n              precompute=True, \n#               warm_start=True, \n              positive=True, \n              selection='random',\n              random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","600ada0c":"results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","995ed212":"from sklearn.linear_model import ElasticNet\n\nmodel = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\nmodel.fit(X_train, y_train)\n\ntest_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","70079091":"results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","f87c7874":"from sklearn.preprocessing import PolynomialFeatures\n\npoly_reg = PolynomialFeatures(degree=2)\n\nX_train_2_d = poly_reg.fit_transform(X_train)\nX_test_2_d = poly_reg.transform(X_test)\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train_2_d,y_train)\n\ntest_pred = lin_reg.predict(X_test_2_d)\ntrain_pred = lin_reg.predict(X_train_2_d)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","9275e1a7":"results_df_2 = pd.DataFrame(data=[[\"Polynomail Regression\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","497043a9":"from sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\nsgd_reg.fit(X_train, y_train)\n\ntest_pred = sgd_reg.predict(X_test)\ntrain_pred = sgd_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","8f51001a":"results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","df1d66ee":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Activation, Dropout\n\nfrom tensorflow.keras.optimizers import Adam\n\nX_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nmodel = Sequential()\n\nmodel.add(Dense(X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(128, activation='relu'))\n# model.add(Dropout(0.2))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=Adam(0.00001), loss='mse')\n\nr = model.fit(X_train, y_train,\n              validation_data=(X_test,y_test),\n              batch_size=1,\n              epochs=100)","a26befb4":"plt.figure(figsize=(10, 6))\n\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()","a6c28ea2":"test_pred = model.predict(X_test)\ntrain_pred = model.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","43ec63c6":"results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","69272cd2":"from sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=1000)\nrf_reg.fit(X_train, y_train)\n\ntest_pred = rf_reg.predict(X_test)\ntrain_pred = rf_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","5d992a20":"results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","96ae21fa":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\nsvm_reg.fit(X_train, y_train)\n\ntest_pred = svm_reg.predict(X_test)\ntrain_pred = svm_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\n\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","a5b43203":"results_df_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\nresults_df = results_df.append(results_df_2, ignore_index=True)\nresults_df","0c34cc94":"results_df.set_index('Model', inplace=True)\nresults_df['R2 Square'].plot(kind='barh', figsize=(12, 8))","75151605":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#f54242','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Deutschland, Wird bald gesund! @mpwolke war Hier.' )","3ed77bf2":"Das Robert Koch-Institut erfasst kontinuierlich die aktuelle COVID-19-Lage, bewertet alle Informationen und sch\u00e4tzt das Risiko f\u00fcr die Bev\u00f6lkerung in Deutschland ein.\n\n\nDar\u00fcber hinaus stellt das RKI umfassende Empfehlungen f\u00fcr die Fach-\u00f6ffentlichkeit zur Verf\u00fcgung, u.a. zu Fallzahlen und Epidemiologie, allgemeinen Infektionsschutzma\u00dfnahmen, Diagnostik und Teststrategie und Pr\u00e4vention in Gesundheitseinrichtungen, und gibt einen \u00dcberblick \u00fcber eigene Forschungsvorhaben.\n\n\nDie Pandemiebew\u00e4ltigung ist eine gesamtgesellschaftliche Aufgabe \u2013 entscheidend ist, dass sich alle daran beteiligen.\n\nStand: 10.12.2020\nhttps:\/\/www.rki.de\/DE\/Home\/homepage_node.html","8e5b2e70":"#Codes by Fares Sayah https:\/\/www.kaggle.com\/faressayah\/linear-regression-house-price-prediction","158e3cf6":"#Ridge Regression","57cd5e38":"#Robust Regression","010b075b":"#Model Evaluation","c59d4336":"#LASSO Regression","3aa2b352":"#Artificial Neural Network","023829cb":"![](https:\/\/cdn.statcdn.com\/Infographic\/images\/normal\/20951.jpeg)de.statista.com","4e0d35ed":"#Support Vector Machine","acf1cb97":"#Elastic Net","985ddbf1":"#Polynomial Regression","e71864f3":"<body style=\"background-color:#99ffcc\">\n     <h2 style=\"color:black; background-color:#42f5ef\">\n          Das Robert Koch Institut\n     <\/h2>\n","a31e72a0":"#Random Forest Regressor","9679de26":"#Models Comparison","b372441f":"#Stochastic Gradient Descent","19cc8d52":"#Linear Regression"}}