{"cell_type":{"57311af6":"code","bd1cab08":"code","4f900a26":"code","24ab0fe0":"code","075e3df7":"code","cf6e8f57":"code","42994903":"code","94d045d0":"code","875cdc4f":"code","65a6093a":"code","9d9535f8":"code","9544ebe6":"code","95ca8aac":"code","40a8fe94":"code","033eca50":"code","5808df0f":"code","cf00e756":"code","a6452f34":"code","1f5c71a8":"code","fc1e8714":"code","474a43a0":"code","4b076a3a":"code","a46934ac":"code","ab650ddd":"code","cc8708dd":"code","b4feb9e7":"code","7fe6dad7":"code","8d3d8149":"code","2e2b765b":"code","7e62fa44":"code","620c7fac":"code","c432521e":"code","c0af6fb9":"code","682f55ba":"code","f5961083":"code","3e6644ae":"code","11cc221f":"code","63493a14":"code","3cc5b693":"code","f0cb6659":"code","71e89ac0":"code","19e55e14":"code","e028016c":"markdown","410d4954":"markdown","03552256":"markdown","843f8a96":"markdown","2f74b38d":"markdown","e41e0541":"markdown","a9a2146a":"markdown","11bcfe5c":"markdown","befc8ca4":"markdown","6bbd1ea1":"markdown"},"source":{"57311af6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd1cab08":"test = pd.read_csv(\"\/kaggle\/input\/airline-passenger-satisfaction\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/airline-passenger-satisfaction\/train.csv\")\ntrain.head()","4f900a26":"test.head()","24ab0fe0":"train.describe()","075e3df7":"train.isnull().sum()","cf6e8f57":"total = len(train)\npart = train['Arrival Delay in Minutes'].isnull().sum()\nprint((part \/ total), '% of', total)","42994903":"arrivalFilter = lambda df: df[np.isnan(df['Arrival Delay in Minutes']) == False]\ntrain = arrivalFilter(train)\ntest = arrivalFilter(test)","94d045d0":"categories = list(train.select_dtypes(exclude=['int64', 'float64']).columns)\ncategories","875cdc4f":"column_dicts = {}\n\ndef categorize(df, cat):\n    cats = df[cat].astype('category').cat.codes\n    if (cat not in column_dicts):\n        col_dict = dict(zip(cats, df[cat]))\n        col_dict = {k: col_dict[k] for k in sorted(col_dict)} # Because it doesn't sort by default, that was fun\n        column_dicts[cat] = col_dict\n    df[cat] = cats\n\ndef categorizeAll(df):\n    for cat in categories:\n        categorize(df, cat)\n\ncategorizeAll(train)\ncategorizeAll(test)\n\ntrain.head()","65a6093a":"column_dicts","9d9535f8":"class_dict = column_dicts['Class']\nclasses = class_dict.values()\n\ndef create_dummies(df):\n    dummies = pd.get_dummies(df['Class'])\n    df = df.join(dummies)\n    df.head()\n    for i, name in class_dict.items():\n        df[name] = df[i]\n        \n    df.drop(class_dict.keys(), axis=1, inplace=True)\n    return df\n\ntrain = create_dummies(train)\ntest = create_dummies(test)","9544ebe6":"ratings = []\n\n# Ratings 0-5, 6 is exclusive\nrating_like = list(range(6))\nrating_like_excl = list(range(1,6))\nfor col in train:\n    unique = sorted(train[col].unique())\n    if (unique == rating_like or unique == rating_like_excl):\n        ratings.append(col)\n        \nratings","95ca8aac":"def rating_average(df):\n    df['Rating average'] = df[ratings].mean(axis=1)\n\nrating_average(train)\nrating_average(test)\n\ntrain.head()","40a8fe94":"import seaborn as sns\nsns.countplot(x='Class', data=train, palette='viridis')","033eca50":"import matplotlib.pyplot as plt\n\ndef heatmap(df):\n    plt.figure(figsize=(2+df.columns.size, 0.7+(df.columns.size * 0.35)))\n    sns.heatmap(df.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap=plt.cm.viridis, linecolor='white', linewidths=0.1)\n    \nheatmap(train)","5808df0f":"def short_score(value):\n    return '{0:.3f}'.format(value)\n\ndef hist_avg(column):\n    ax = sns.histplot(x=column, hue='Class', data=train, kde=True, palette='viridis')\n    average = np.average(train[column])\n    plt.axvline(average, color='red')\n    plt.legend(labels=[*list(reversed(list(class_dict.values()))), f'Average ({short_score(average)})'], loc='center left', bbox_to_anchor=(1, 0.5))\n    return ax\n\ndef count_labeled(column):\n    c_dict = column_dicts[column]\n    temp = train.copy() # So we don't change the state of the 'real' data set\n    temp[column] = temp[column].map(c_dict)\n    ax = sns.countplot(x=column, hue='Class', data=temp, palette='viridis')\n    plt.legend(labels=class_dict.values(), loc='center left', bbox_to_anchor=(1, 0.5))\n    return ax","cf00e756":"count_labeled('Type of Travel')","a6452f34":"hist_avg('Flight Distance')","1f5c71a8":"hist_avg('Age')","fc1e8714":"hist_avg('Rating average')","474a43a0":"def corr(df, col):\n    return df[df.columns[0:]].apply(lambda x: x.corr(df['Class']))[col]","4b076a3a":"def show_corr():\n    corr_dict = {}\n    for col in train:\n        if (col not in [*classes, 'Class']):\n            corr_dict[col] = abs(corr(train, col))\n\n    corr_dict = dict(sorted(corr_dict.items(), key=lambda e: -e[1]))\n\n    corr_df = pd.DataFrame(corr_dict.items(), columns=[\"Column\", \"Correlation to class\"])\n    sns.catplot(x=\"Correlation to class\", y=\"Column\", kind=\"bar\", data=corr_df, palette='viridis')\n    \nshow_corr()","a46934ac":"dropped = []\n\nmax_corr = 0.1\nfor col in train:\n    cr = corr(train, col)\n    if (cr <= max_corr and cr >= -max_corr):\n        print('Dropping', col, 'with correlation:', cr)\n        dropped.append(col)\n        \ntrain.drop(dropped, axis=1, inplace=True)\ntest.drop(dropped, axis=1, inplace=True)","ab650ddd":"heatmap(train)","cc8708dd":"show_corr()","b4feb9e7":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ntrain.drop('Class', axis=1, inplace=True)\ntest.drop('Class', axis=1, inplace=True)\n\ndef split(df):\n    temp = df.copy()\n    x = temp.drop(classes, axis=1)\n    y = temp[classes]\n    return x, y\n\nX_train, y_train = split(train)\nX_test, y_test = split(test)","7fe6dad7":"X_train.shape","8d3d8149":"X_test.shape","2e2b765b":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","7e62fa44":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\n\ndef build_model():\n    print('Building new model with', X_train.shape[1], 'features')\n    \n    tfm = Sequential()\n\n    tfm.add(Dense(4, input_shape=(1,X_train.shape[1]), activation='sigmoid'))\n    tfm.add(Dense(1))\n\n    tfm.compile(Adam(learning_rate=0.005), loss='mean_squared_error', metrics=['accuracy'])\n\n    tfm.summary()\n    return tfm","620c7fac":"from tensorflow.keras import callbacks\nearlystopping = callbacks.EarlyStopping(monitor =\"loss\", patience = 3, restore_best_weights=True)\n\ndef train_model(model):\n    return model.fit(X_train, y_train, epochs = 25, callbacks =[earlystopping], batch_size=100, validation_split = 0.2)","c432521e":"def predictions(model):\n    score = model.evaluate(X_test, y_test, verbose=0)\n    print(f'Loss: {short_score(score[0])}\\tAccuracy: {short_score(score[1])}')\n    return score","c0af6fb9":"def drop_and_restore(drop):\n    train.drop(drop, axis=1, inplace=True)\n    test.drop(drop, axis=1, inplace=True)\n\n    # Visualize the new data correlation\n    heatmap(train)\n    \n    global X_train, y_train\n    global X_test, y_test\n    X_train, y_train = split(train)\n    X_test, y_test = split(test)\n\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)","682f55ba":"def run_model(drop):\n    drop_and_restore(drop)\n    model = build_model()\n    history = train_model(model)\n    predictions(model)","f5961083":"run_model([])","3e6644ae":"from matplotlib import pyplot as plt\n\ndef visualize(rate, histories):\n    plt.figure(figsize=(25,10))\n    for history in histories:\n        plt.plot(history[1], label = history[0])\n    plt.title('Model accuracy (' + str(rate) + ')')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n    plt.show()\n    \ndef custom_predictions(optimizer_func, learning_rate, activation, loss):\n    optimizer = optimizer_func(learning_rate)\n    label = type(optimizer_func(learning_rate)).__name__ + ' (' + str(learning_rate) + ')\\t' + activation + '\\t  ' + loss\n    print(label, end='\\t: ') # So we can print predictions in a single line\n    tfm2 = Sequential()\n\n    tfm2.add(Dense(X_train.shape[1], input_shape=(1, X_train.shape[1]), activation=activation))\n    tfm2.add(Dense(3, activation='softmax')) # So all values count up to 1.0\n    tfm2.compile(optimizer, loss=loss, metrics=['accuracy'])\n\n    history = tfm2.fit(X_train, y_train, epochs = 5, batch_size=100, validation_split = 0.2, verbose=0)\n    \n    score = predictions(tfm2)\n    return [label, history.history['accuracy'], score[0], score[1]]","11cc221f":"from tensorflow.keras.optimizers import Adagrad\n\nlearning_rates = [0.001, 0.01, 0.1, 1]\noptimizers = [lambda rate: Adam(learning_rate=rate), lambda rate: Adagrad(learning_rate=rate)]\nactivations = ['relu', 'sigmoid']\nlosses = ['mean_squared_error', 'mean_absolute_error', 'categorical_crossentropy']\n\nbest_histories = []\nbest_model = None\n\n# Forgive me for my sins..\nfor learning_rate in learning_rates:\n    histories = []\n    best = False\n    for optimizer_func in optimizers:\n        for activation in activations:\n            for loss in losses:\n                model_predictions = custom_predictions(optimizer_func, learning_rate, activation, loss)\n                histories.append(model_predictions)\n                if (best_model == None or best_model[3] < model_predictions[3]):\n                    best_model = model_predictions\n                    best = True\n                \n    visualize(learning_rate, histories)\n    # From earlier runs 0.1 was determined to yield the best results (low loss, high accuracy)\n    if (best):\n        best_histories = histories","63493a14":"print(best_model[0]) # Adam, 0.01, sigmoid, squared\nprint('Loss:', short_score(best_model[2]), '\\tAccuracy:', short_score(best_model[3]))","3cc5b693":"loss_dict = {}\n    \n# Only shows results for 0.1 LR\nfor history in best_histories:\n    loss_dict[history[0]] = history[2]\n    \nloss_dict = dict(sorted(loss_dict.items(), key=lambda e: -e[1]))\n\nloss_df = pd.DataFrame(loss_dict.items(), columns=[\"Model\", \"Loss\"])\nsns.catplot(x=\"Loss\", y=\"Model\", kind=\"bar\", data=loss_df, palette='viridis')","f0cb6659":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, hamming_loss\n\ndef best_model(X_train, y_train, X_test, y_test):\n    best_depth = -1\n    best_acc = -1\n\n    for max_depth in [1, 5, 10, 15, 25, 50]:\n        model = RandomForestClassifier(max_depth=max_depth, random_state=1)\n        model.fit(X_train, y_train)\n        predicted = model.predict(X_test)\n        accuracy = accuracy_score(y_test, predicted)\n        loss = hamming_loss(y_test, predicted)\n        print('Depth', max_depth, 'yields loss:', short_score(loss), 'and accuracy:', short_score(accuracy), end='')\n        if (best_acc < accuracy):\n            print(' <- Found new best!')\n            best_depth = max_depth\n            best_acc = accuracy\n        else:\n            print('')\n\n    model = RandomForestClassifier(max_depth=best_depth, random_state=1)\n    model.fit(X_train, y_train)\n    \n    return model","71e89ac0":"model = best_model(X_train, y_train, X_test, y_test)","19e55e14":"from sklearn.metrics import multilabel_confusion_matrix\npredicted = model.predict(X_test)\nmultilabel_confusion_matrix(y_test, predicted)","e028016c":"## Correlations at a glance\nFor a final easy comparison, we visualize all correlations sorted by relevance.","410d4954":"#### Several columns have values 0-5, as these indicate ratings. To ensure we don't include useless data (or overly strong data) we'll filter these and create an average, to see if the average has a high correlation","03552256":"### Is flight distance relevant, do we want to set the correlation minimum around 0.43? Answer: Yes","843f8a96":"## Preparing the data sets","2f74b38d":"# Comparison (RFC)","e41e0541":"### Is type of travel relevant, do we want to set the correlation minimum around 0.49? Answer: Yes","a9a2146a":"## Finding the best model\nTo find the best model we use different depths, storing the performance of each depth to choose the best result.","11bcfe5c":"### Is the average rating relevant, do we want to set the correlation minimum around 0.12? Answer: Yes","befc8ca4":"# Filtering data\nAs 15 of 26 of the features shown are ratings, which are not known until after the flight, these will be filtered out before the final model is chosen. To decide on the rest of the features to use, we use the correlation of each feature compared to the satisfaction, filtering out anything that has a too low correlation. What defines a 'too low' correlation is decided on based on the data below.","6bbd1ea1":"### Is age relevant, do we want to set the correlation minimum around 0.12? Answer: Yes"}}