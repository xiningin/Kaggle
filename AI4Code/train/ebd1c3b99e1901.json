{"cell_type":{"e30a1643":"code","05b92bbf":"code","5a6dc6a6":"code","ba9b327b":"code","142c6c91":"code","27963b73":"code","3861aefe":"code","f4262ddf":"code","a48f4310":"code","e1536096":"code","c24931a2":"code","9a035845":"code","1e77684b":"code","37282abc":"code","497c4c2c":"code","2fda7cf0":"code","3793f811":"code","cba9beab":"code","9b22e7c0":"code","9a4f843b":"code","0d37ba19":"code","2060948f":"code","a733aca9":"code","3eed4ffa":"code","0e935d14":"code","fc6bef75":"code","0ecccc2e":"code","c184fe1e":"code","f6b01899":"markdown","f882d014":"markdown","02b98892":"markdown","466bab3b":"markdown","23c26001":"markdown","7f3c5bc9":"markdown"},"source":{"e30a1643":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05b92bbf":"import missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n#from lightgbm import LGBMClassifier\n#import lightgbm as lgb\n#import optuna.integration.lightgbm as lgb\n\n#from xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5a6dc6a6":"pd.set_option('display.max_columns', 100)","ba9b327b":"sample_submission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")","142c6c91":"sample_submission","27963b73":"train","3861aefe":"test","f4262ddf":"train = train.drop(columns=[\"id\"])\ntest = test.drop(columns=[\"id\"])","a48f4310":"# Search for missing data\n\nmsno.matrix(df=train, figsize=(10,6), color=(0,.3,.3))","e1536096":"# Search for missing data\n\nmsno.matrix(df=test, figsize=(10,6), color=(0,.3,.3))","c24931a2":"plt.figure(figsize=(10,6))\n#sns.countplot(x='target', data=train, order=df_train['target'].value_counts().index)\nsns.countplot(x='target', data=train, order=sorted(train['target'].unique()))","9a035845":"train.drop(columns=['target']).describe().T\\\n        .style.bar(subset=['mean'], color=px.colors.qualitative.G10[0])\\\n        .background_gradient(subset=['std'], cmap='Greens')\\\n        .background_gradient(subset=['50%'], cmap='BuGn')","1e77684b":"test.describe().T\\\n        .style.bar(subset=['mean'], color=px.colors.qualitative.G10[0])\\\n        .background_gradient(subset=['std'], cmap='Greens')\\\n        .background_gradient(subset=['50%'], cmap='BuGn')","37282abc":"#train['target'] = train['target'].map({'Class_1':0, 'Class_2':1, 'Class_3':2, 'Class_4':3, 'Class_5':4, 'Class_6':5, 'Class_7':6, 'Class_8':7, 'Class_9':8})\nle = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])","497c4c2c":"train","2fda7cf0":"train_corr = train.corr()\ntrain_corr","3793f811":"plt.figure(figsize=(20,10))\nsns.heatmap(train_corr, vmin=0, vmax=0.12, center=0, square=False, annot=False, cmap='coolwarm');","cba9beab":"X = train.drop('target',axis=1)\ny = train['target']","9b22e7c0":"# split data for train and test\nx_train, x_test, t_train, t_test = train_test_split(X, y, test_size=0.2, random_state=43)# (0.2) (7,43)1\uff5e43","9a4f843b":"# XGBoost\ndtrain = xgb.DMatrix(x_train, label=t_train)\ndtest = xgb.DMatrix(x_test, label=t_test)\nxgb_params= {\n        'objective': 'multi:softprob',# \u591a\u5024\u5206\u985e\u554f\u984c(multi:softprob\uff1a\u5404\u30af\u30e9\u30b9\u306b\u5c5e\u3059\u308b\u78ba\u7387\u3001multi:softmax\uff1a\u4e88\u6e2c\u3057\u305f\u30af\u30e9\u30b9)\n        'num_class': 9,\n        'eval_metric': 'mlogloss',\n        'max_depth': 9,\n        'learning_rate': 0.0201,\n        'reg_lambda': 29.326,\n        'subsample': 0.818,\n        'colsample_bytree': 0.235,\n        'colsample_bynode': 0.82,\n        'colsample_bylevel': 0.453}","0d37ba19":"# Training\nevals = [(dtrain, 'train'), (dtest, 'eval')]\nevals_result = {}\nbst = xgb.train(xgb_params,\n                dtrain,\n                num_boost_round=10000,\n                early_stopping_rounds=10,\n                evals=evals,\n                evals_result=evals_result,\n                verbose_eval=10\n                )","2060948f":"pred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\npred_max = np.argmax(pred, axis=1)\n\n# Accuracy\nacc = accuracy_score(t_test, pred_max)\nprint('Accuracy:', acc)","a733aca9":"# Feature importance\nfig, ax = plt.subplots(figsize=(10, 10))\nxgb.plot_importance(bst, ax=ax)","3eed4ffa":"# Training performance\nplt.plot(evals_result['train']['mlogloss'], label='train')\nplt.plot(evals_result['eval']['mlogloss'], label='eval')\nplt.ylabel('Log loss')\nplt.xlabel('Boosting round')\nplt.title('Training performance')\nplt.legend()\nplt.show()","0e935d14":"testData = pd.DataFrame(test)\ntestData = xgb.DMatrix(testData)","fc6bef75":"pred = bst.predict(testData)","0ecccc2e":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4','Class_5','Class_6', 'Class_7', 'Class_8', 'Class_9']] = pred\nsample_submission.to_csv(f'xgb.csv',index=False)","c184fe1e":"sample_submission","f6b01899":"# 5.Prediction","f882d014":"# 2. Preprocessing","02b98892":"# 1.Import data","466bab3b":"# 4. Modeling","23c26001":"# 6.Make submission file","7f3c5bc9":"# 3. Check the correlation between each item"}}