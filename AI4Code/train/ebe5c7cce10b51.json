{"cell_type":{"37521326":"code","2f5aa219":"code","74f8bacc":"code","6218db1f":"code","806ed544":"code","857d62aa":"code","fd73a2d5":"code","3a4f096f":"code","167dbc53":"code","8f24b687":"code","d19c8843":"code","81c01054":"code","c913954d":"code","63414025":"code","c9032e62":"code","c1561d46":"code","463d0488":"code","25d4b9aa":"code","d0a1ba9c":"code","af621ad9":"code","80275b5c":"code","adea07b7":"code","e2f7efd3":"code","854e095a":"code","8850f10c":"code","e621d224":"code","ee24cc4a":"code","8172712b":"markdown","c1ca5665":"markdown","efdd7d87":"markdown","05347298":"markdown","d2183a92":"markdown","b6009f20":"markdown","cd379920":"markdown","5a8fa07a":"markdown","21a20a66":"markdown","684fc554":"markdown"},"source":{"37521326":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2f5aa219":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\nprint(tf.__version__)","74f8bacc":"# Load data\ntrain_df = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip').fillna(' ')\ntrain_df.sample(10, random_state = 1)","6218db1f":" x = train_df['comment_text'].values\n print(x)","806ed544":"# View few toxic comments\ntrain_df.loc[train_df['toxic'] == 1].sample(10 , random_state = 10)","857d62aa":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\ncomments = train_df['comment_text'].loc[train_df['toxic']==1].values\nwordcloud = WordCloud(\n    width = 640,\n    height = 640,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(comments))\nfig = plt.figure(\n    figsize = (12, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","fd73a2d5":"y = train_df['toxic'].values\nprint(y)","3a4f096f":"# Plot frequency of toxic comments\ntrain_df['toxic'].plot(kind = 'hist' , title = 'Distribution Of Toxic Comments')","167dbc53":"train_df['toxic'].value_counts()","8f24b687":"# Most frequent 20000 words will be embedded and rest will be ignored\nmax_features = 20000\n\n# The max lenth of the comments will be set as 400 and all those comments where lenght will not be 40\n# They'll be padded to 400 length\nmax_text_length = 400","d19c8843":"# text.Tokenizer - It vectorises the values of each text into integers where each integer is index of a token in a dictionary.\nx_tokenizer = text.Tokenizer(max_features)\n\n# We'll fit the tokenizer onto the list of x\nx_tokenizer.fit_on_texts(list(x))\n\n#After that we'll convert the tokenized text into list of list of sequences of numbers\nx_tokenized = x_tokenizer.texts_to_sequences(x)\n\n#We'll pad each of these sequences to the max_length of 400\nx_train_val = sequence.pad_sequences(x_tokenized , maxlen = max_text_length)","81c01054":"# # !wget http:\/\/nlp.stanford.edu\/data\/glove.6B.zip\n# !unzip glove.6B.zip.1","c913954d":"embedding_dim = 100\nembeddings_index = dict()\nf = open('\/kaggle\/input\/glove6b100dtxt\/glove.6B.100d.txt')\nfor line in f:\n  values = line.split()\n  word = values[0]\n  coefs = np.asarray(values[1:] , dtype = 'float32')\n  embeddings_index[word] = coefs\n\nf.close()\nprint(f'Found {len(embeddings_index)} word vectors. ')","63414025":"embedding_matrix = np.zeros((max_features , embedding_dim))\nfor word , index in x_tokenizer.word_index.items():\n  if index > max_features -1:\n    break\n  else:\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n      embedding_matrix[index] = embedding_vector","c9032e62":"model = Sequential()\nmodel.add(Embedding(max_features,\n                    embedding_dim,\n                    embeddings_initializer = tf.keras.initializers.Constant(\n                        embedding_matrix),\n                    trainable = False\n                    ))\n\nmodel.add(Dropout(0.2))","c1561d46":"filters = 250\nkernel_size = 3 \nhidden_dims = 250","463d0488":"model.add(Conv1D(filters,\n                 kernel_size,\n                 padding = 'valid'))\nmodel.add(MaxPooling1D())\nmodel.add(Conv1D(filters,\n                 5,\n                 padding = 'valid',\n                 activation = 'relu'))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(hidden_dims , activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1 , activation= 'sigmoid'))\nmodel.summary()","25d4b9aa":"model.compile(loss = 'binary_crossentropy' , optimizer= 'adam' , metrics = ['accuracy'])","d0a1ba9c":"x_train , x_val , y_train , y_val = train_test_split(x_train_val , y , test_size = 0.15 ,random_state = 1)","af621ad9":"batch_size = 32\nmodel.fit(x_train , y_train ,\n          batch_size = 32,\n          epochs =3,\n          validation_data = (x_val ,y_val))","80275b5c":"test_df = pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')","adea07b7":"x_test = test_df['comment_text'].values","e2f7efd3":"x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\nx_testing = sequence.pad_sequences(x_test_tokenized ,maxlen =max_text_length)","854e095a":"y_testing =model.predict(x_testing , verbose = 1 , batch_size= 32)","8850f10c":"y_testing.shape","e621d224":"y_testing[0]","ee24cc4a":"test_df['Toxic'] = ['not toxic' if x < .5 else 'toxic' for x in y_testing]\ntest_df[[ 'comment_text' , 'Toxic']].head(20)","8172712b":"### Task 4: Prepare Embedding Matrix with Pre-trained GloVe Embeddings","c1ca5665":"### Task 6: Build the Model","efdd7d87":"### Task 3: Data Prep \u2014 Tokenize and Pad Text Data","05347298":"### Task 1: Import Packages and Functions","d2183a92":"<h2 align=center> Toxic Comments Classification using 1D CNN with Keras<\/h2>","b6009f20":"### Task 2: Load and Explore Data","cd379920":"# **A NLP model using CNN to classify the toxic words from the comments.**","5a8fa07a":"### Task 5: Create the Embedding Layer","21a20a66":"### Task 7: Train Model","684fc554":"### Task 8: Evaluate Model"}}