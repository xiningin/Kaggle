{"cell_type":{"f670323e":"code","fc719a9c":"code","05199b82":"code","f52f5374":"code","80715af3":"code","8707b75e":"code","23212040":"code","a44a6ec0":"code","694575a1":"code","918a6221":"code","c47d63fd":"code","980ed085":"code","c78e8980":"code","b6cb25e5":"code","4208af25":"code","d9eb06a4":"code","5c3aab5d":"code","cc7b1558":"code","080e834c":"code","a7637070":"code","56c8c7ac":"code","327c1f16":"code","c870d0ea":"markdown","f08ceb19":"markdown","0aee0739":"markdown","69894047":"markdown","b4b89b94":"markdown","1500a6d9":"markdown","3b150916":"markdown","81225bfa":"markdown","29ac4984":"markdown"},"source":{"f670323e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc719a9c":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score","05199b82":"diabetes_dataset = pd.read_csv('..\/input\/diabetes-data-set\/diabetes.csv')","f52f5374":"diabetes_dataset.shape","80715af3":"diabetes_dataset.head()","8707b75e":"diabetes_dataset.info()","23212040":"diabetes_dataset.duplicated()","a44a6ec0":"diabetes_dataset.describe()","694575a1":"import seaborn as sns\nsns.boxplot(data=diabetes_dataset)","918a6221":"diabetes_dataset['Outcome'].value_counts().plot(kind='bar')","c47d63fd":"diabetes_dataset.groupby('Outcome').mean()","980ed085":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=[10,6])\nsns.heatmap(diabetes_dataset.corr(),annot=True)","c78e8980":"X = diabetes_dataset.drop(columns='Outcome', axis=1)\nY = diabetes_dataset['Outcome']\n\nprint(X)\nprint(Y)","b6cb25e5":"#Standard Scaler\nscaler = StandardScaler()\nscaler.fit(X)\nstandardized_data = scaler.transform(X)\nprint(standardized_data)\nX = standardized_data","4208af25":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)","d9eb06a4":"classifier = svm.SVC(kernel='linear')\n\nclassifier.fit(x_train, y_train)\n\nx_train_prediction = classifier.predict(x_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction, y_train)\nprint(training_data_accuracy)\n\nx_test_prediction = classifier.predict(x_test)\ntesting_data_accuracy = accuracy_score(x_test_prediction, y_test)\nprint(testing_data_accuracy)","5c3aab5d":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(x_train, y_train)\n\nx_train_prediction = model.predict(x_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction, y_train)\nprint(training_data_accuracy)\n\nx_test_prediction = model.predict(x_test)\ntesting_data_accuracy = accuracy_score(x_test_prediction, y_test)\nprint(testing_data_accuracy)","cc7b1558":"from sklearn.neighbors import KNeighborsClassifier\nmodel=KNeighborsClassifier(n_neighbors=50)\nmodel.fit(x_train,y_train)\n\nx_train_prediction = model.predict(x_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction, y_train)\nprint(training_data_accuracy)\n\nx_test_prediction = model.predict(x_test)\ntesting_data_accuracy = accuracy_score(x_test_prediction, y_test)\nprint(testing_data_accuracy)","080e834c":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\n\nx_train_prediction = model.predict(x_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction, y_train)\nprint(training_data_accuracy)\n\nx_test_prediction = model.predict(x_test)\ntesting_data_accuracy = accuracy_score(x_test_prediction, y_test)\nprint(testing_data_accuracy)","a7637070":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train,y_train)\n\nx_train_prediction = model.predict(x_train)\ntraining_data_accuracy = accuracy_score(x_train_prediction, y_train)\nprint(training_data_accuracy)\n\nx_test_prediction = model.predict(x_test)\ntesting_data_accuracy = accuracy_score(x_test_prediction, y_test)\nprint(testing_data_accuracy)","56c8c7ac":"model = ['Support Vector Machine', 'Logistic Regression', 'K Nearest Neighbor', 'Decision Tree Classifier', 'Random Forest Classifier']\ntrain_score = [0.7866449511400652, 0.7850162866449512, 0.7687296416938111, 1.0, 1.0]\ntest_score = [0.7727272727272727, 0.7597402597402597, 0.7272727272727273, 0.7077922077922078, 0.7337662337662337]","327c1f16":"pd.DataFrame({\"model\":model,\"Train set accuracy\":train_score, \"Test set accuracy\":test_score})","c870d0ea":"**K Nearest Neighbor**","f08ceb19":"**Support Vector Machine**","0aee0739":"Separating Data and label columns","69894047":"**Logistic Regression**","b4b89b94":"Splitting into Train and Test sets","1500a6d9":"Exploratory Data Analysis","3b150916":"**Random Forest Classifier**","81225bfa":"The Dataset","29ac4984":"**Decision Tree Classifier**"}}