{"cell_type":{"70b54d72":"code","baaf6607":"code","1965f8b3":"code","d5430c79":"code","7766bf90":"code","887038b1":"code","323b61dc":"code","d4071bb0":"code","6ed4b7eb":"code","70d8b5fb":"code","5809604b":"code","35a5322e":"code","cc53431d":"code","887d9730":"code","7827028a":"code","1d99f7f6":"code","03937131":"code","0dbc6c1a":"code","82059f00":"markdown","2bddeff2":"markdown","3a97618c":"markdown","a49d0589":"markdown","5519bcf4":"markdown","df6efac0":"markdown","1ce88e5b":"markdown","c8799a0d":"markdown","369cb7e3":"markdown","cfbbe0a9":"markdown","59c858e0":"markdown","af916f29":"markdown","1dd99216":"markdown","8853b327":"markdown","9fd1638c":"markdown","8f0ca180":"markdown","cb6d1a51":"markdown"},"source":{"70b54d72":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\n\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, SeparableConv2D, BatchNormalization, MaxPool2D, Dropout\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","baaf6607":"os.listdir('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray')","1965f8b3":"base_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray'\n\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'val')\nvalidation_dir = os.path.join(base_dir, 'test')\n\ntrain_normal_dir = os.path.join(train_dir, 'NORMAL')\ntrain_pneumonia_dir = os.path.join(train_dir, 'PNEUMONIA')\n\nvalidation_normal_dir = os.path.join(validation_dir, 'NORMAL')\nvalidation_pneumonia_dir = os.path.join(validation_dir, 'PNEUMONIA')\n\ntest_normal_dir = os.path.join(test_dir, 'NORMAL')\ntest_pneumonia_dir = os.path.join(test_dir, 'PNEUMONIA')","d5430c79":"train_normal_fnames = os.listdir(train_normal_dir)\ntrain_pneumonia_fnames = os.listdir(train_pneumonia_dir)\n\nprint(train_normal_fnames[:5])\nprint(train_pneumonia_fnames[:5])","7766bf90":"print('total training normal images :', len(os.listdir(train_normal_dir) ))\nprint('total training pneumonia images :', len(os.listdir(train_pneumonia_dir) ))\n\nprint('total validation normal images :', len(os.listdir(validation_normal_dir) ))\nprint('total validation pneumonia images :', len(os.listdir(validation_pneumonia_dir) ))\n\nprint('total test normal images :', len(os.listdir(test_normal_dir) ))\nprint('total test pneumonia images :', len(os.listdir(test_pneumonia_dir) ))","887038b1":"base_dir = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'\n\nfig, ax = plt.subplots(2, 3, figsize=(15, 7))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i, _set in enumerate(['train', 'val', 'test']):\n    set_path = base_dir+_set\n    ax[i].imshow(plt.imread(set_path+'\/NORMAL\/'+os.listdir(set_path+'\/NORMAL')[0]), cmap='gray')\n    ax[i].set_title('Set: {}, Condition: Normal'.format(_set))\n    ax[i+3].imshow(plt.imread(set_path+'\/PNEUMONIA\/'+os.listdir(set_path+'\/PNEUMONIA')[0]), cmap='gray')\n    ax[i+3].set_title('Set: {}, Condition: Pneumonia'.format(_set))","323b61dc":"train_normal_count = len(os.listdir(train_normal_dir))\ntrain_pneumonia_count = len(os.listdir(train_pneumonia_dir))\ntotal_train_count = train_normal_count + train_pneumonia_count\n\nval_normal_count = len(os.listdir(validation_normal_dir))\nval_pneumonia_count = len(os.listdir(validation_pneumonia_dir))\ntotal_val_count = val_normal_count + val_pneumonia_count","d4071bb0":"weight_for_normal_0 = (1 \/ train_normal_count)*(total_train_count)\/2.0 \nweight_for_pneumonia_1 = (1 \/ train_pneumonia_count)*(total_train_count)\/2.0\n\nclass_weight = {0: weight_for_normal_0, 1: weight_for_pneumonia_1}\n\nprint(f'Weight for class 0: {class_weight[0]}')\nprint(f'Weight for class 1: {class_weight[1]}')","6ed4b7eb":"image_shape = [150, 150]\nbatch_size = 64\nepochs = 30","70d8b5fb":"model = tf.keras.models.Sequential([\n    \n    # The first convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3),padding = 'same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2), padding = 'same'),\n    \n    # The second convolution    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2), padding = 'same'),\n\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2), padding = 'same'),\n\n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding = 'same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2), padding = 'same'),\n\n    # The fifth convolution\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding = 'same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D((2, 2), padding = 'same'),\n\n\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","5809604b":"model.summary()","35a5322e":"# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator(rescale = 1.0\/255,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.3,\n                                  )\n\nvalidation_datagen  = ImageDataGenerator(rescale = 1.0\/255)\n\n# Flow training images in batches using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=batch_size,\n                                                    class_mode='binary',\n                                                    target_size=(image_shape[0], image_shape[1]),\n                                                    shuffle=True\n                                                   )     \n\n# Flow validation images in batches using test_datagen generator\nvalidation_generator =  validation_datagen.flow_from_directory(validation_dir,\n                                                               batch_size=batch_size,\n                                                               class_mode  = 'binary',\n                                                               target_size = (image_shape[0], image_shape[1]), \n                                                               shuffle=True\n                                                              )","cc53431d":"metrics = ['accuracy',\n           tf.keras.metrics.Precision(name='precision'),\n           tf.keras.metrics.Recall(name='recall')\n          ]\n\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n              loss='binary_crossentropy',\n              metrics = metrics\n                 )\n\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_recall',\n                                                               patience = 3,\n                                                               verbose=1,\n                                                               factor=0.2,\n                                                               min_lr=0.000001)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=10,\n                                              restore_best_weights=True,\n                                              verbose=1)","887d9730":"history = model.fit(train_generator,\n                        validation_data=validation_generator,\n                        steps_per_epoch=total_train_count\/\/batch_size,\n                        epochs=epochs,\n                        validation_steps=total_val_count\/\/batch_size,\n                        class_weight=class_weight,\n                        verbose=2,\n                        callbacks=[learning_rate_reduction, early_stop]\n                       )","7827028a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nprecision = history.history['precision']\nval_precision = history.history['val_precision']\nrecall = history.history['recall']\nval_recall = history.history['val_recall']\n\n\nepochs = range(len(acc))\nplt.figure()\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, precision, 'r', label='Training precision')\nplt.plot(epochs, val_precision, 'b', label='Validation precision')\nplt.title('Training and validation precision')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, recall, 'r', label='Training recall')\nplt.plot(epochs, val_recall, 'b', label='Validation recall')\nplt.title('Training and validation recall')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","1d99f7f6":"# To get the data and labels to make prediction on the test set which contains 16 files which the model has not seen before\nimport cv2\ntest_data = []\ntrue_test_labels = []\n\nfor item in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n    for img in (os.listdir(base_dir + 'val' + item)):\n        img = plt.imread(base_dir+'val'+item+img)\n        img = cv2.resize(img, (image_shape[0], image_shape[1]))\n        img = np.dstack([img, img, img])\n        img = img.astype('float32') \/ 255.\n        if item=='\/NORMAL\/':\n            label = 0\n        elif item=='\/PNEUMONIA\/':\n            label = 1\n        test_data.append(img)\n        true_test_labels.append(label)\n        \ntest_data = np.array(test_data)\ntrue_test_labels = np.array(true_test_labels)","03937131":"prediction = model.predict(test_data)\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\ntn, fp, fn, tp = confusion_matrix(true_test_labels, np.round(prediction)).ravel()\n                                  \nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\nprint(f'Accuracy: {accuracy_score(true_test_labels, np.round(prediction))*100} %')\nprint(f'Precision: {precision} %')\nprint(f'Recall: {recall} %')","0dbc6c1a":"print(classification_report(true_test_labels, np.round(prediction)))","82059f00":"Note that we used the original 'test' set for validation and we will use the original 'val' set containing 16 images for testing our model.","2bddeff2":"# Introduction\n\nComputer Vision, image processing\/analysis and pattern recognition has found its way into Medical Image analysis. The goal of Machine Learning is to assist Doctors and healthcare providers to make better and efficient decisions by prioritizing high risk patients.\n\nIn this notebook we use the Chest X-Ray Images (Pneumonia) https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia\ndataset to build a Deep Learning Model to predict if an X-Ray image shows the presence of Pneumonia or not. We will build a Convolution Neural Network to train and predict the results. We will also use Data Augmentation techniques to increase the size of out training set.  \n\nIn this tutorial we run the code using GPU as Kaggle provides free access to NVidia K80 GPUs in kernels. We will use the ImageDataGenerator provided by the Keras deep learning library class to perform data augmentation and load the data efficiently for training and validating our model.","3a97618c":"## 6. Visualizing model performance","a49d0589":"Detect my accelerator","5519bcf4":"## 2. Take care of the data imbalance and defining some constant values\nWe can use the follwoing numbers to assign weights to each of the class to fix the data imbalance issue.","df6efac0":"Next, we'll configure the specifications for model training. We will train our model with the binary_crossentropy loss, because it's a binary classification problem and our final activation is a sigmoid. We will use the RMSprop optimizer. During training, we will want to monitor classification accuracy, recall, precision and loss.\n\nNOTE: In this case, using the adam or RMSprop or Adagrad optimization algorithm is preferable to stochastic gradient descent (SGD), because adam and RMSprop automates learning-rate tuning for us.\n\nWe will use Keras callbacks to improve our model. \n\nModelCheckpoint() callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.\n\nModels often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. ReduceLROnPlateau() callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n\nEarlyStopping() stops the training when a monitored metric has stopped improving, the model starts to get stagnant or starts to overfit.","1ce88e5b":"Note that because we are facing a two-class classification problem, i.e. a binary classification problem, we will end our network with a sigmoid activation, so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0).","c8799a0d":"## 1. Loading the data and visualize the X-Rays\n\nIn the dataset the validation dataset folder contains only 16 images so we will use the test set as validation and the validation folder for final prediction","369cb7e3":"## 4. Data Preprocessing\n\nNext we set up data generators that will read pictures in our source folders, convert them to float32 tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of images of size 150x150 and their labels (binary).\n\nWe will preprocess our images by normalizing the pixel values to be in the [0, 1] range (originally all values are in the [0, 255] range). We will perform some data augmentation for the training set like shifting the image horizontally and vertically and also zooming in or out by a certain amount.\n\nIn Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class using the rescale parameter. This ImageDataGenerator class allows you to instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs: fit, evaluate_generator, and predict_generator.","cfbbe0a9":"As we can see that there is data imbalance as there are a lot more of images that are classified as pneumonia than normal. Later in this notebook we will fix this.","59c858e0":"## 5. Training the model","af916f29":"## 3. CNN Model Building","1dd99216":"### Importing relevant libraries and packages","8853b327":"The model is converging which can be seen from the above plots. ","9fd1638c":"Let's take a look at some of the X-Ray images belonging to both the classes","8f0ca180":"## Model prediction and evaluation on unseen data","cb6d1a51":"Let's take a look at the first 5 files in the train folder for 'NORMAL' and 'PNEUMONIA' x-rays"}}