{"cell_type":{"1eb1f6d3":"code","59d5f351":"code","4f82e4d0":"code","756677c5":"code","7280948b":"code","c5c50667":"code","b4ee41e5":"code","9b1c835d":"code","4e5a140f":"code","7b335e86":"code","ce62a5bd":"code","1f88b32b":"code","7e275137":"code","bd7017c7":"code","fe391933":"code","f197a50e":"code","7e27f95c":"code","ad0121be":"code","7a379612":"code","7c46ae0b":"code","6813faa4":"code","8aeb28e1":"markdown","4c7a04ee":"markdown","b98831b0":"markdown","106579a6":"markdown"},"source":{"1eb1f6d3":"import numpy as np\nimport pandas as pd\nfrom nltk.corpus import stopwords\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom xgboost import XGBClassifier\nfrom scipy.sparse import hstack, csr_matrix\nimport gc\nimport sys\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB\nfrom sklearn.model_selection import cross_val_score\n\npd.set_option('display.max_colwidth', None)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","59d5f351":"def read_data():\n    data = pd.read_csv(\"\/kaggle\/input\/avito-category-prediction\/train.csv\", low_memory=False)#, nrows=300000)\n    data[\"Category\"] = data[\"Category\"].astype(\"int8\")\n    data.loc[data[\"description\"].isna() == True, [\"description\"]] = data.loc[data[\"description\"].isna() == True, [\"title\"]].values\n    return data\n","4f82e4d0":"data = read_data()\nprint(data.info(memory_usage=\"deep\"))","756677c5":"del read_data\ngc.collect()","7280948b":"display(data.head())","c5c50667":"stop_words = set(stopwords.words(\"russian\"))","b4ee41e5":"def prepare_data(text_column):\n    processed_column = []\n    for text_row in text_column:\n        text_row = re.sub('[^A-Za-z\u0410-\u042f\u0430-\u044f0-9]+', ' ', text_row)\n        text_row = ' '.join(word for word in text_row.lower().split() if word not in stop_words)\n        processed_column.append(text_row.lower().strip())\n    return processed_column","9b1c835d":"data[\"description\"] = prepare_data(data[\"description\"])\ndata[\"title\"] = prepare_data(data[\"title\"])\ndisplay(data.head())","4e5a140f":"def vectorize_train_data(data):\n    \n    title_vect = CountVectorizer(min_df=4)\n    X_train_title = title_vect.fit_transform(data[\"title\"]).astype(np.float32)\n\n    descr_vect = CountVectorizer(min_df=10)\n    X_train_descr = descr_vect.fit_transform(data[\"description\"]).astype(np.float32)\n\n    X_train = hstack((X_train_title, X_train_descr)).tocsr()\n    \n    return X_train, title_vect, descr_vect\n\ndef vectorize_test_data(data, title_vect, descr_vect):\n    \n    data[\"description\"] = prepare_data(data[\"description\"])\n    data[\"title\"] = prepare_data(data[\"title\"])\n    \n    X_test_title = title_vect.transform(data[\"title\"]).astype(np.float32)\n\n    X_test_descr = descr_vect.transform(data[\"description\"]).astype(np.float32)\n\n    X_test = hstack((X_test_title, X_test_descr)).tocsr()\n    \n    return X_test","7b335e86":"X_train, title_vect, descr_vect = vectorize_train_data(data)\ny_train = data[\"Category\"].copy()","ce62a5bd":"data.drop([\"Category\", \"Category_name\", \"title\", \"description\"], axis=1, inplace=True)","1f88b32b":"del vectorize_train_data, data\ngc.collect()\n","7e275137":"models = [SGDClassifier(random_state=42, max_iter=1000, n_jobs=-1, alpha=0.000001), \n          ComplementNB(alpha=0.01), \n          MultinomialNB(alpha=0.001)]","bd7017c7":"def train_estimators(models, X_train, y_train):\n    trained_models = []\n    cols = [type(x).__name__ for x in models]\n    preds = pd.DataFrame(columns=cols)\n    \n    for model in models:\n        model.fit(X_train, y_train)\n        preds[str(type(model).__name__)] = model.predict(X_train)\n        print(model.score(X_train, y_train))\n        trained_models.append(model)\n    \n    \n    #blender = RidgeClassifier(random_state=42)\n    #blender = SGDClassifier(random_state=42, max_iter=1000, n_jobs=-1)\n    #blender = CatBoostClassifier(random_state=42, thread_count=1, verbose=10, n_estimators=100)\n    blender = XGBClassifier(n_jobs=-1, random_state=42, verbosity=1, n_estimators=50)\n    blender.fit(preds, y_train)\n    print(blender.score(preds, y_train))\n    preds[\"blender\"] = blender.predict(preds)\n    display(preds.head(20))\n    \n    return trained_models, blender","fe391933":"%%time\ntrained_models, blender = train_estimators(models, X_train, y_train)","f197a50e":"del X_train, y_train, train_estimators\ngc.collect()","7e27f95c":"def read_test():\n    data = pd.read_csv(\"\/kaggle\/input\/avito-category-prediction\/test.csv\", low_memory=False)#, nrows=300000)\n    data.loc[data[\"description\"].isna() == True, [\"description\"]] = data.loc[data[\"description\"].isna() == True, [\"title\"]].values\n    return data","ad0121be":"test = read_test()\ntest.info()","7a379612":"X_test = vectorize_test_data(test, title_vect, descr_vect)","7c46ae0b":"def get_predictions(X_test, trained_models, blender):\n    cols = [type(x).__name__ for x in models]\n    preds = pd.DataFrame(columns=cols)\n    \n    for model in models:\n        preds[str(type(model).__name__)] = model.predict(X_test)\n    preds[\"blender\"] = blender.predict(preds)   \n    display(preds.head(20))\n\n    return preds[\"blender\"]","6813faa4":"df = pd.DataFrame(columns=[\"Id\", \"Category\"])\ndf[\"Id\"] = test[\"itemid\"]\ndf[\"Category\"] = get_predictions(X_test, trained_models, blender)\ndf.to_csv('submission.csv', index=False, header=df.columns)","8aeb28e1":"# **Data Import**","4c7a04ee":"# **Test data predictions**","b98831b0":"# **Data Preparation**","106579a6":"# **Base Models and Blender Training**"}}