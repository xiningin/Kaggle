{"cell_type":{"894e343f":"code","ed2679ee":"code","dda67d37":"code","1c89e6a4":"code","e8ba3552":"code","039b4e23":"code","87ddaf50":"code","ea656195":"code","ce893657":"code","447e3479":"code","88f30426":"code","19d67e61":"code","a85dfb37":"markdown","969ec3f8":"markdown","0393a7c2":"markdown","c2f0e229":"markdown","d2f82071":"markdown","60f16b89":"markdown","97c6245a":"markdown","ac63e4c0":"markdown"},"source":{"894e343f":"import cv2\nimport os\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1 import ImageGrid","ed2679ee":"# in the dataset I have stored an example parameters file\nparam_path = '..\/input\/stereocamera-chessboard-pictures\/data\/out\/parameters.npz'\n\n# the parameters are stored in a NPZ file\n# you can import them to a dictionary and access the parameters\nparams = dict(np.load(param_path))\nparams.keys()","dda67d37":"# will be added later ...","1c89e6a4":"# open an example image\npathL = '..\/input\/stereocamera-chessboard-pictures\/data\/imgs\/leftcamera\/Im_L_15.png'\nimgL = cv2.imread(pathL,0)\nimgL = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)\npathR = '..\/input\/stereocamera-chessboard-pictures\/data\/imgs\/rightcamera\/Im_R_15.png'\nimgR = cv2.imread(pathR,0)\nimgR = cv2.cvtColor(imgR, cv2.COLOR_BGR2RGB)","e8ba3552":"# we will extract the necessary parameters for the calibration\nK1,K2 = params['L_Intrinsic'], params['R_Intrinsic']\nD1,D2 = params['L_Distortion'], params['R_Distortion']\nImageSize = (imgL.shape[1], imgL.shape[0])\nRk = params['Transformation'][:3,:3]\nTk = params['Transformation'][:3,3:]","039b4e23":"# now we have to calculate the rectification maps\nRect = cv2.stereoRectify(K1,D1,K2,D2,ImageSize,Rk,Tk,alpha=0)\nmap1 = cv2.initUndistortRectifyMap(K1,D1,Rect[0],Rect[2],ImageSize,cv2.CV_32FC1)\nmap2 = cv2.initUndistortRectifyMap(K2,D2,Rect[1],Rect[3],ImageSize,cv2.CV_32FC1)","87ddaf50":"# with the maps we can rectify the images\nimgL_rect = cv2.remap(imgL,map1[0],map1[1],cv2.INTER_AREA)\nimgR_rect = cv2.remap(imgR,map2[0],map2[1],cv2.INTER_AREA)","ea656195":"fig = plt.figure(figsize=(20,20))\ngrid = ImageGrid(fig, 111, nrows_ncols=(1, 2), axes_pad=0.1)\nfor ax, im in zip(grid, [imgL, imgR]):\n    ax.imshow(im)\n    ax.axis('off')\n\nfig = plt.figure(figsize=(20,20))\ngrid = ImageGrid(fig, 111, nrows_ncols=(1, 2), axes_pad=0.1)\nfor ax, im in zip(grid, [imgL_rect, imgR_rect]):\n    ax.imshow(im)\n    ax.axis('off')","ce893657":"# so let's have a look to the parameters from the left camera.\nparams['L_Distortion']","447e3479":"# open an example image\npath = '..\/input\/stereocamera-chessboard-pictures\/data\/imgs\/leftcamera\/Im_L_15.png'\nimg = cv2.imread(path,0)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","88f30426":"# undistort the image with the buildin function\nimg_undistorted = cv2.undistort(img, params['L_Intrinsic'], params['L_Distortion'], None, params['L_DistortionIntrinsic'])","19d67e61":"fig = plt.figure(figsize=(20,20))\ngrid = ImageGrid(fig, 111, nrows_ncols=(1, 2), axes_pad=0.1)\nfor ax, im in zip(grid, [img, img_undistorted]):\n    ax.imshow(im)\n    ax.axis('off')","a85dfb37":"Now we can display the undistorted image and compare it to the original picture. We cannot see any visible change, but that's because the camera is realy flat and there is no big distortion anyway. When you calibrate a fisheye camera (like a GoPro) you can see the differences clearly and the undistortion is a really nice feature for Computer Vision and working with Cameras.","969ec3f8":"## Rectification\n\nImage rectification is a transformation process used to project images to a common image plane. It is used in computer vision to simplify the problem of finding matching points between images (correspondence problem). After a rectification of a stereocamera we have the same vertical coordinate of one point on both cameras. When you are interested in the calculation background you can have a look at (http:\/\/www.sci.utah.edu\/~gerig\/CS6320-S2013\/Materials\/CS6320-CV-F2012-Rectification.pdf).","0393a7c2":"## Epipolarlines\n\nThe *Epipolar Geometry* is the Geometry of a *Stereo Camera*. When two cameras look at the same point, they discribe a plane, the epipolar plane. With the known calibration parameters we can use this geometry to describe a point from one camera to the corresponding point on the other camera. More information about this can be found here: https:\/\/web.stanford.edu\/class\/cs231a\/course_notes\/03-epipolar-geometry.pdf ","c2f0e229":"## Load the Paramters","d2f82071":"# How to work with a calibrated stereo camera","60f16b89":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#51BC23;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:white;\">\n            Upvoting is for free ;)\n        <\/p>\n    <\/div>","97c6245a":"After the calculation of the new rectified images we can display them. The top image pair is the original data and underneath the rectified ones. When you have a closer look at the solution you see that every point has the same vertical coordinate.","ac63e4c0":"## Undistortion\n\nIn this section we are going to undistort an image. Therefore we need the distortion parameters from the calibration. Distortion must be seperated between radial and tangential distortion. To understand the difference and reading the parameters I recommmend to read the OpenCV documentation (https:\/\/docs.opencv.org\/3.4\/dc\/dbb\/tutorial_py_calibration.html)."}}