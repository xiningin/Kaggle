{"cell_type":{"aaa51762":"code","ebb243e4":"code","71aade17":"code","d9c740d0":"code","c70fd3c5":"code","1f05e883":"code","6a52f2b0":"code","6d6f4310":"code","639ae35b":"code","e28470a1":"code","1481a608":"code","bf10b608":"code","2cab7642":"code","0e81fb25":"code","999bca32":"code","5b3d9b46":"code","821c866a":"markdown","422ac39a":"markdown","f62a6a18":"markdown","1626309e":"markdown","9fe190b2":"markdown","956cffc1":"markdown","b2c64747":"markdown","4999c10c":"markdown","201b8b5f":"markdown"},"source":{"aaa51762":"import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport tensorflow as tf\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\n","ebb243e4":"general_path = '..\/input\/cassava-leaf-disease-classification\/'","71aade17":"train = pd.read_csv(general_path + 'train.csv')\ntrain['label'] = train['label'].astype('string')\ntrain.sample(5)","d9c740d0":"names_of_disease = pd.read_json(general_path + 'label_num_to_disease_map.json', typ='series')\nnames_of_disease","c70fd3c5":"plt.figure(figsize=(16, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    image = Image.open(general_path + 'train_images\/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    plt.imshow(array)\n    label=train.iloc[i]['label']\n    plt.title(f'{names_of_disease[int(label)]}')\nplt.show()\n    ","1f05e883":"sizes = []\nfor i in range(1, len(train), 250):\n    image = Image.open(general_path + 'train_images\/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    sizes.append(array.shape)\nprint('Picture size', set(sizes))","6a52f2b0":"img_width, img_height = 380, 380","6d6f4310":"datagen = ImageDataGenerator(validation_split=0.2,\n                             vertical_flip=True,\n                             horizontal_flip=True)\ntrain_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=general_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=20,\n    subset='training',\n    seed=12345)","639ae35b":"valid_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=general_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=20,\n    subset='validation',\n    seed=12345)","e28470a1":"current_balance = train['label'].value_counts(normalize=True)\ncurrent_balance","1481a608":"class_weight = {0: (1 - current_balance['0']) \/ (1 - current_balance.min()),\n                1: (1 - current_balance['1']) \/ (1 - current_balance.min()),\n                2: (1 - current_balance['2']) \/ (1 - current_balance.min()),\n                3: (1 - current_balance['3']) \/ (1 - current_balance.min()),\n                4: (1 - current_balance['4']) \/ (1 - current_balance.min())}\n\nclass_weight","bf10b608":"early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)","2cab7642":"model = Sequential()\noptimizer = Adam(lr=0.00105)\nbackbone = EfficientNetB4(include_top=False, \n                          weights=None, \n                          pooling='avg')\nmodel.add(backbone)\nmodel.add(Dense(5, activation='softmax'))\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizer, \n              metrics=[\"accuracy\"])\nmodel.fit_generator(train_datagen_flow,\n                    validation_data=valid_datagen_flow, \n                    epochs=50,\n                    class_weight=class_weight,\n                    callbacks=[early_stopping, mc],\n                    verbose=2)","0e81fb25":"saved_model = load_model('best_model.h5')","999bca32":"submission = pd.DataFrame(columns=['image_id','label'])\nfor image_name in os.listdir(general_path + 'test_images'):\n    image_path = os.path.join(general_path + 'test_images', image_name)\n    image = tf.keras.preprocessing.image.load_img(image_path)\n    resized_image = image.resize((img_width, img_height))\n    numpied_image = np.expand_dims(resized_image, 0)\n    tensored_image = tf.cast(numpied_image, tf.float32)\n    submission = submission.append(pd.DataFrame({'image_id': image_name,\n                                                 'label': saved_model.predict_classes(tensored_image)}))\n\nsubmission","5b3d9b46":"submission.to_csv('\/kaggle\/working\/submission.csv', index=False)","821c866a":"# Start Training","422ac39a":"# Submission","f62a6a18":"# Read train data","1626309e":"## Pictures","9fe190b2":"## Version history:\n* Ver. 7 Accuracy 0.748. Time 4559 s. Limit (32400)\n* Ver. 10 Change photo resolution to 224x224 from 150x300. And EfficientNetB3 from EfficientNetB0. Accuracy 0.787. Time 4559 s.\n* Ver. 11 Change photo resolution to 380x380 from 224x224. And EfficientNetB4 from EfficientNetB3. Accuracy 0.786. Time 16816 s.\n* Ver. 12 Change photo resolution to 260x260 from 380x380. And EfficientNetB2 from EfficientNetB4. And add EarlyStopping. Also change learning_rate to 0.0005 from 0.001. Not improving.\n* Ver. 13(14) Add photo rotaiting and change learning_rate to 0.001 from 0.0005. Not improving.\n* Ver. 18 Add class_weight. Quality got worse.\n* Ver. 22. Back to 260x260 and 20 epoch, remove EarlyStopping. Accuracy 0.817. Time 6239 s. New baseline.\n* Ver. 23. Add 2 Dense layer to model. Not improving.\n* Continue working...\n\n","956cffc1":"# The shortest way to baseline.","b2c64747":"## Implement EarlyStopping ","4999c10c":"## Load best saved after EarlyStopping model","201b8b5f":"## Adjust class balance."}}