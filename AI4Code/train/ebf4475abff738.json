{"cell_type":{"a2f9afe2":"code","4d96e4e1":"code","05cc9ce6":"code","4c4446d7":"code","13b4a75f":"code","18984da8":"code","15c49712":"code","2866199d":"code","2160c3f0":"code","5f22a989":"code","07ebb39f":"code","d4b2400f":"code","fa12cc00":"code","e1cebab2":"code","0515c27d":"code","11073c1b":"code","10d6aeae":"code","a82998fe":"code","7093cb55":"code","415c83ac":"code","d39b29ae":"code","c94db20f":"code","d7477946":"code","ffdf75c1":"code","6ede8118":"code","94d2ded6":"code","2b0b8afb":"code","a287ff8e":"code","b3e07133":"code","13cde1c2":"code","489cf7bd":"markdown","3de82043":"markdown","10923493":"markdown","f36e83f7":"markdown","06eb9e81":"markdown","350c46d2":"markdown","b09833ba":"markdown","01c8afce":"markdown","3ff36cb4":"markdown","98f24a14":"markdown","50fb76d9":"markdown","610e9648":"markdown","dfb004b1":"markdown","637985d4":"markdown","2aac003b":"markdown","8ba4cc13":"markdown"},"source":{"a2f9afe2":"import os\nprint(os.listdir(\"..\/input\"))\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n# Any results you write to the current directory are saved as output.","4d96e4e1":"mcr = pd.read_csv(\"..\/input\/multipleChoiceResponses.csv\", low_memory=False).iloc[1:, :]","05cc9ce6":"CONSIDERED_JOB_TITLE = ['Business Analyst', 'Chief Officer', 'Consultant',\n       'DBA\/Database Engineer', 'Data Analyst', 'Data Engineer',\n       'Data Journalist', 'Data Scientist', 'Developer Advocate',\n       'Manager', 'Marketing Analyst','Principal Investigator', 'Product\/Project Manager',\n       'Research Assistant', 'Research Scientist', 'Salesperson',\n       'Software Engineer', 'Statistician']","4c4446d7":"mcr_jobs = mcr.loc[mcr[\"Q6\"].isin(CONSIDERED_JOB_TITLE)]","13b4a75f":"plt.figure(figsize=(18, 10))\nmcr_jobs[\"Q6\"].value_counts().plot(kind='bar')\n_ = plt.style.use('ggplot')\n_ = plt.title(\"Number of respondents in each job title\")\n_ = plt.xlabel(\"Job title\")\n_ = plt.ylabel(\"Counts\")","18984da8":"CODING_TIME = ['0% of my time', '1% to 25% of my time',\n       '25% to 49% of my time','50% to 74% of my time', \n       '75% to 99% of my time', '100% of my time']\n\nmcr_jobs[[\"Q6\", \"Q23\"]]\\\n        .dropna().groupby([\"Q6\", \"Q23\"]).size()\\\n        .groupby(\"Q6\").apply(lambda x: 100 * x \/ float(x.sum()))\\\n        .unstack(1)[CODING_TIME]\\\n        .plot(kind=\"bar\", stacked=True, figsize=(18, 10), \n              fontsize=15, colormap=plt.get_cmap(\"tab20\")\n             )\n\nplt.style.use(\"ggplot\")\nplt.title(\"Percentage of time on coding for different jobs\", fontsize=20)\nplt.ylabel(\"Percentage of Time on Coding\", fontsize=15)\nplt.xlabel(\"Job Titles\", fontsize=15)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5), fontsize=14)\nplt.show()","15c49712":"CODING_YEAR = ['I have never written code and I do not want to learn',\n        'I have never written code but I want to learn', '< 1 year', '1-2 years', \n        '3-5 years', '5-10 years', '10-20 years', '20-30 years', \n        '30-40 years', '40+ years']\nmcr_code_year = mcr_jobs[[\"Q6\", \"Q24\"]]\\\n        .groupby([\"Q6\", \"Q24\"])\\\n        .size()\\\n        .to_frame(\"counts\")\\\n        .unstack(1)\\\n        .fillna(0)\nmcr_code_year = mcr_code_year[\"counts\"][CODING_YEAR]","2866199d":"mcr_code_year = mcr_code_year.apply(lambda x: ((x \/ mcr_code_year.sum(axis=1)) * 100).round(0))\nplt.figure(figsize=(20, 10))\nsns.heatmap(mcr_code_year, annot=True)\n_ = plt.title(\"Percentage of how many years of experience people have to use coding skill to analyze data for different jobs\")\n_ = plt.xlabel(\"Years of experience\")\n_ = plt.ylabel(\"Job titles\")","2160c3f0":"ML_YEARS = ['I have never studied machine learning and I do not plan to',\n        'I have never studied machine learning but plan to learn in the future',\n        '< 1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-10 years', \n        '10-15 years', '20+ years']\nmcr_ml_year = mcr_jobs[[\"Q6\", \"Q25\"]]\\\n        .groupby([\"Q6\", \"Q25\"])\\\n        .size()\\\n        .to_frame(\"counts\")\\\n        .unstack(1)\\\n        .fillna(0)\nmcr_ml_year = mcr_ml_year[\"counts\"][ML_YEARS]","5f22a989":"# create features for ml and non-ml\n\nno_ml = mcr_ml_year.iloc[:, :2].sum(axis=1).values\nwith_ml = mcr_ml_year.iloc[:, 2:].sum(axis=1).values\nmcr_ml_year_bi = pd.DataFrame(index=CONSIDERED_JOB_TITLE)\nmcr_ml_year_bi[\"No machine learning\"] = no_ml\nmcr_ml_year_bi[\"With machine learning\"] = with_ml\n\nmcr_ml_year_bi = mcr_ml_year_bi.apply(lambda x: ((x \/ mcr_ml_year_bi.sum(axis=1)) * 100).round(0))\\\n                            .stack()\\\n                            .reset_index()\\\n                            .rename(columns={\"level_0\": \"Q6\", \"level_1\": \"Q25\", 0: \"percentage\"})\n\nsns.catplot(x=\"Q6\", y='percentage', hue='Q25', height=12, data=mcr_ml_year_bi, kind='bar', palette=\"muted\")\n_ = plt.xticks(rotation=90)\n_ = plt.title(\"Percentage of positions having machine learning experience\")","07ebb39f":"mcr_ml_year_multi = mcr_ml_year.apply(lambda x: ((x \/ mcr_ml_year.sum(axis=1)) * 100).round(0))\nplt.figure(figsize=(20, 10))\nsns.heatmap(mcr_ml_year_multi, annot=True)\n_ = plt.title(\"Percentage of people's ML experience in different job positions\")\n_ = plt.xlabel(\"Years of experience\")\n_ = plt.ylabel(\"Job titles\")","d4b2400f":"DATA_TYPE_LIST = ['Audio Data', 'Categorical Data', 'Genetic Data',\n       'Geospatial Data', 'Image Data', 'Numerical Data', 'Sensor Data',\n       'Tabular Data', 'Text Data', 'Time Series Data', 'Video Data',\n       'Other Data']\nmcr_data_type = mcr_jobs.filter(regex=\"^(?!.*TEXT)(Q31)\").fillna(0)\nori_list = mcr_data_type.columns.tolist()\n\nfor col in mcr_data_type:\n    mcr_data_type[col] = mcr_data_type[col].apply(lambda x: 1 if x!=0 else 0)\n    \nmcr_data_type = mcr_data_type.rename(columns=dict(zip(ori_list, DATA_TYPE_LIST)))\nmcr_data_type = mcr_data_type.merge(mcr_jobs[[\"Q6\"]], left_index=True, right_index=True)\nsum_datatype = mcr_data_type.groupby(\"Q6\")[DATA_TYPE_LIST].sum().T","fa12cc00":"fig, ax = plt.subplots(nrows=6, ncols=3, sharex=True, sharey=True, figsize=(20, 30))\nn = 1\nfor job in sum_datatype:\n    plt.subplot(6, 3, n)\n    sum_datatype[job].plot(kind=\"bar\", title=job, fontsize=8)\n    n +=1\nplt.subplots_adjust(hspace = 1)\nplt.show()","e1cebab2":"ACTIVITIES = [\"Understand data\", \"Build service\", \n              \"Build infrastructure\", \"Build prototype\", \n              \"Advanced research\", \"Not related\", \"Other\"]\n\nmcr_activity = mcr_jobs.filter(regex=\"^(?!.*TEXT)(Q11)\").fillna(0)\nactivity_list = mcr_activity.columns.tolist()\nmcr_activity = mcr_activity.rename(columns=dict(zip(activity_list, ACTIVITIES)))","0515c27d":"for col in mcr_activity:\n    mcr_activity[col] = mcr_activity[col].apply(lambda x: 1 if x!=0 else 0)\nmcr_activity = mcr_activity.merge(mcr_jobs[[\"Q6\"]], left_index=True, right_index=True)\ntransposed_activities = mcr_activity.groupby(\"Q6\")[ACTIVITIES].sum().T","11073c1b":"full_activity = [\"Analyze and understand data to influence product or business decisions\",\n                \"Build and\/or run a machine learning service that operationally improves my product or workflows\",\n                \"Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\",\n                \"Build prototypes to explore applying machine learning to new areas\",\n                \"Do research that advances the state of the art of machine learning\",\n                \"None of these activities are an important part of my role at work\",\n                \"Others\"]\ncolors = [\"Red\", \"Blue\", \"Purple\", \"Grey\", \"Yellow\", \"Green\", \"Pink\"]\nfor col, act in zip(colors, full_activity):\n    print( col + \"  ->  \" + act)\nfig, ax = plt.subplots(nrows=6, ncols=3, sharex=True, sharey=True, figsize=(20, 20))\nn = 1\nfor job in transposed_activities:\n    plt.subplot(6, 3, n)\n    transposed_activities[job].plot(kind=\"bar\", title=job, fontsize=6)\n    n +=1\nplt.subplots_adjust(hspace = 1)\nplt.show()\n","10d6aeae":"WORK_DETAILS = ['Gathering data', 'Cleaning data', \n            'Visualizing data', 'Model building\/model selection', \n            'Putting the model into production', \n            'Finding insights in the data and communicating with stakeholders']\nmcr_time = mcr_jobs.filter(regex=(\"^(?!.*TEXT)(Q6|Q34)\"), axis=1)\\\n                .dropna()\nmcr_time.columns = [\"Q6\"] + WORK_DETAILS\nmcr_time[WORK_DETAILS] = mcr_time[WORK_DETAILS].astype(float)","a82998fe":"mcr_time.groupby(\"Q6\").agg(np.mean)\\\n    .plot.barh(stacked=True, figsize=(20, 10), fontsize=15)\n\nplt.title(\"Average time percentage devoted on data projects for different titles\", fontsize=20)\nplt.ylabel(\"Job Titles\", fontsize=15)\nplt.xlabel(\"Time percentage\", fontsize=15)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5), fontsize=14)\nplt.show()","7093cb55":"mcr_insight = mcr_jobs[[\"Q6\", \"Q46\"]]\\\n                        .dropna()\\\n                        .groupby([\"Q6\", \"Q46\"])\\\n                        .size()\\\n                        .unstack(1)\\\n                        .fillna(0)\n\nmcr_insight = mcr_insight.apply(lambda x: (x \/ mcr_insight.sum(axis=1) * 100).round(0))\n\nplt.figure(figsize=(20, 10))\nsns.heatmap(mcr_insight, cmap=\"YlGnBu\")\n\n_ = plt.title(\"Distribution of percentage of time people have on exploring model insights.\")\n_ = plt.xlabel(\"Slots\")\n_ = plt.ylabel(\"Job titles\")","415c83ac":"job_index = mcr_jobs.index\nmcr_ffr = pd.read_csv(\"..\/input\/freeFormResponses.csv\", low_memory=False).filter(regex=\"Q12\").iloc[job_index, :]\ndrop_cols = mcr_ffr.columns.tolist()","d39b29ae":"TOOLS = ['jupyter', 'python', 'pycharm', 'anaconda', 'matlab', 'rstudio', 'visual studio', 'excel', 'docker', 'sql'\n    , 'bash', 'spark', 'scala', 'emacs', 'tensor', 'torch', 'scikit', 'xgb', 'hadoop', 'jupyterlab', 'cloudera'\n, 'c++', 'tableau', 'pandas', 'keras', 'ide', 'orange', 'colab', 'aws', 'mxnet', 'databricks', 'spyder', 'java',\n'h2o', 'slack', 'zeppelin', 'sas', 'spss', 'nltk', 'powerbi']\n\nmcr_ffr[\"summary\"] = mcr_ffr.apply(lambda x: set([i for i in x if i is not np.nan]), axis=1)\nmcr_ffr[\"summary\"] = mcr_ffr[\"summary\"].apply(lambda x: [i.lower() for i in x])\nmcr_ffr = mcr_ffr[mcr_ffr[\"summary\"].apply(lambda x: len(x)) == 1]","c94db20f":"for t in TOOLS:\n    mcr_ffr[t] = 0\n    \nfor idx, r in mcr_ffr.iterrows():\n    for t in TOOLS:\n        if t in r['summary'][0]:\n            mcr_ffr.set_value(idx, t, 1)\n            \ndrop_cols = drop_cols + [\"summary\"]\nmcr_tool = mcr_ffr.merge(mcr_jobs[['Q6']], right_index=True, left_index=True)\\\n        .drop(drop_cols, axis=1)","d7477946":"fig, ax = plt.subplots(nrows=6, ncols=3, sharex=True, sharey=True, figsize=(20, 20))\nn = 1\nfor job in CONSIDERED_JOB_TITLE:\n    sub_job = mcr_tool[mcr_tool[\"Q6\"] == job]\n    txt = \",\".join(sub_job[TOOLS].sum(axis=0).sort_values(ascending=False).index)\n    plt.subplot(6, 3, n)\n    wordcloud = WordCloud(colormap=\"Reds\", width=900, height=480,\n                      normalize_plurals=False).generate(txt)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.title(job)\n    plt.axis(\"off\")\n    n +=1\nplt.subplots_adjust(hspace = 0.2)\nplt.show()","ffdf75c1":"mcr_tool[\"num_tools\"] = mcr_tool.iloc[:, :-1].apply(lambda x: sum(x), axis=1)\nmcr_num_tool = mcr_tool[[\"num_tools\", \"Q6\"]]","6ede8118":"pal = sns.cubehelix_palette(10, rot=-.25, light=1)\ng = sns.FacetGrid(mcr_num_tool, row=\"Q6\", hue=\"Q6\", aspect=15, height=1, palette=pal)\n\ng.map(sns.kdeplot, \"num_tools\", clip_on=False, shade=True, alpha=1, lw=1.5, bw=.2)\ng.map(sns.kdeplot, \"num_tools\", clip_on=False, color=\"w\", lw=2, bw=.2)\ng.map(plt.axhline, y=0, lw=2, clip_on=False)\n\ndef label(x, color, label):\n    ax = plt.gca()\n    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n            ha=\"left\", va=\"center\", transform=ax.transAxes)\n\ng.map(label, \"num_tools\")\ng.fig.subplots_adjust(hspace=.25)\n\ng.set_titles(\"\")\ng.set(yticks=[])\ng.despine(bottom=True, left=True)","94d2ded6":"TRAIN_CAT = [\"Self-taught\", \"Online courses\", \"Work\", \"University\", \"Kaggle competitions\", \"Other\"]\nmcr_train = mcr_jobs.filter(regex=\"^(?!.*TEXT)(Q35|Q6)\").dropna(axis=0)\nmcr_train.columns = [\"Q6\"] + TRAIN_CAT\nmcr_train[TRAIN_CAT] = mcr_train[TRAIN_CAT].astype(float)\n\nmcr_train.groupby(\"Q6\").mean()\\\n        .plot(kind=\"bar\", stacked=True, \n              figsize=(18, 10), fontsize=15, \n              colormap=plt.get_cmap(\"tab20\"))\n\nplt.title(\"Percentage of training on ML fell on different categories\", fontsize=20)\nplt.ylabel(\"Percentage\", fontsize=15)\nplt.xlabel(\"Job Titles\", fontsize=15)\nplt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5), fontsize=14)\nplt.show()","2b0b8afb":"EDU_BACKGROUND = [\"Bachelor\u2019s degree\", \"Master\u2019s degree\", \"Doctoral degree\", \n                  \"Professional degree\", \"Some college\/university study without earning a bachelor\u2019s degree\",\n                  \"No formal education past high school\"]\n\nmcr_job_edu = mcr_jobs[[\"Q6\", \"Q4\"]]\\\n        .groupby([\"Q6\", \"Q4\"])\\\n        .size()\\\n        .to_frame(\"counts\")\\\n        .unstack(1)\\\n        .fillna(0)\nmcr_job_edu = mcr_job_edu['counts'][EDU_BACKGROUND]\nmcr_job_edu = mcr_job_edu.apply(lambda x: ((x \/ mcr_job_edu.sum(axis=1)) * 100).round(0))","a287ff8e":"plt.figure(figsize=(20, 10))\nsns.heatmap(mcr_job_edu, cmap=\"Oranges\", annot=True)\n\n_ = plt.title(\"Distribution of percentage of education background people have in different occupations.\")\n_ = plt.xlabel(\"Educations\")\n_ = plt.ylabel(\"Job titles\")","b3e07133":"mcr_age = mcr_jobs[[\"Q6\", \"Q2\"]]\nrandom_sampled_age = mcr_age[\"Q2\"].apply(lambda x: np.random.randint(int(x.split(\"-\")[0]), int(x.split(\"-\")[1])) \n                                                  if (len(x.split(\"-\")) == 2) else 80)\nmcr_age[\"age\"] = random_sampled_age","13cde1c2":"plt.figure(figsize=(30, 15))\nsns.swarmplot(x=\"Q6\", y=\"age\", hue=\"Q2\",\n              palette=\"RdBu\", data=mcr_age)\n_ = plt.xticks(rotation=90)\n_ = plt.title(\"Age distribution among different job occupations\")\n_ = plt.xlabel(\"Job titles\")\n_ = plt.ylabel(\"Age\")","489cf7bd":"## Age distribution in different job occupations\n\nIn order better visualize this, I randomly sampled their age based on the range they select using np.random.randint. \n\n### Interesting facts:\n1. Most of research assistants are quite young, however, research scientists' ages are more sparsed. Probably, assistants will become scientists later, so, keey working!!\n2. It needs time to become principals, probably because it requires years of experience. However, Chief officers look more achievable at younger age, probably due to the fact that there are a lot of talented people in start-ups etc. \n3. 25-40 looks like the main forces!!","3de82043":"## How much time do they code?!\n\nSince I am a data scientist, and I know in my daily work, except for writing codes, I also need to have meetings with different stakeholders. I think it's the same for other data scientist. But if you are not a meeting guy, and you want to work in data, you definitely want to know which occupation requires less meeting time. Let's take a look at how much time people in different occupations spend in coding! \n\n### Results are not very surprising:\n1. As the result presents, for occupations that are quite technical, like data scientist, data engineer, software engineers, most of them spend at least half of their time in coding! \n2. For managers, chiefs and salesperson, they spend least of time in coding, which is quite common sense. Their focus is not coding but business, strategy etc.\n3. And analysts are looking like positions in between, on the one hand, they will analyze the data and find insights, and on the other hand, they work closely with business and engineers. ","10923493":"## Where do they train on machine learning?\n\nYou have known the work acitivities, the coding requirement, and the tool they use at work. But learning never stops, and we are curious where they learn and train their machine leanring skills?\n\n### You should believe in and rely on yourselves!!!\n1. Self-taught and online courses are most commonly ways people train their machine learning skill. Nowadays, we can easily get free online resources and learn everything online and by yourself, as long as you have strong learning ability, you can do a good job as well!\n2. Data scientists are working while learning!! I can also feel the same that through doing a project, I learn a lot along with the process.","f36e83f7":"## Gerneral look at distribution of job titles among all qualified respondents\n\nAs we expect, due to the nature of Kaggle, we can imagine that data scientist are the most.","06eb9e81":"# Future work and to be done:\n1. Get more insights through digging deeper, for example, check the impact of industry\/country\/age\/etc on the job content for different occupations\n2. Suggest a path or doing what can lead you to be a good ** for different occupations\n3. Trying to explore columns and responds to make up a final story to submit.\n4. Structure the functions and clean the codes to make it more efficient and reusable.","350c46d2":"## Data Loading and scope definition\n\nDue to the fact that in this analysis, I would like to focus on difference of job contents amaong different job titles, therefore, I will only consider the respondents who have a clear job title. For those who don't selected \"Others\" or \"Not employed\" or \"Students\", it's quite hard and unfair to be included in this analysis.","b09833ba":"# **What are differences of job contents among different jobs? **\n\n\nNo matter if you already have worked with data or plan to step into this field,  I think you all may be curious about what are the differences in job contents among different job positions! Knowing this can help you better blueprint your future and find the position that fits your capability & interest & strength the most. Especially for people who haven't learned about this, they might get confused with so many titles, such like analysts, scientists, engineers etc, therefore a deep insight of how these titles differ will be quite helpful (instead of looking at the salary ^^). We might have general ideas of what people with these jobs do, but let's dive into the Kaggle's survey data to see if our intuitions are the same as the fact (I assume all respondents are honest and serious about this survey) !!\n\n## Help prepare for your next move!\n\nMy idea is to use the survey data, and give the insights of what it looks like in different jobs. For those who haven't but prepare to step into this field, they could learn what they could prepare and which skills are most needed so as to expand their skill set. For those who have worked in this field, but prepare to either stay or switch to other positions, they could also have a self-check and see if they really like the job content of that job title in bigger picture, and plan their career path!\n\n## The questions I would like to explore:\n1. What percentage of time do people spend on coding? (Reason: especially for whose who are amateurs and lack of coding background, they can better evaluate themselves and improve in the correct direction towards different occupations in data.)\n2. Distribution of how long people have used coding skill to analyze data for different jobs? (Reason: Well, after knowing the coding, we can take a closer look to see the distribution of how many years people have in analyzing data with code in different occupations )\n3. Do people have machine learning experience? (Reason: Once we have learned about general coding requirements in different occupation, we defnitely want to know if machine learning is a must!)\n4. How many years of machine learning experience do people have in different jobs? (Reason: to get a more comprehensive picture of the machine learning experience distribution.)\n5. What types of data do people work with in different jobs? (Reason: SImple and direct, we wanna see what type of data people usually work with.)\n6. Find out the activities that make up an important part of role at work? (Reason: Is data work all about coding?! NO! In our real work, we have a lot of other things to do, so i wanna check out the important activities invovled at work, this should differ from job to job. It's good to improve your soft skills in the meantime!!)\n7. During a typical data project at work, approximately where and how much of your time is devoted to? (Reason: We already know the main acitivities at work, but what about that in a data project?? and then i also wanna know what makes up the time in a data project!!)\n8. Percentage of time people spend on exploring model insights? (Reason: You get your model! Don't you wanna explore the insights of it to be able to better interpret it to non-technical audience? How much time you need on this part?)\n9. What's the primary tool people use at work? (Reason: We have talked about all the experience, the work, the activities, the time allocations, and it makes you excited! And then you wanna learn and prepare for getting that job, and it comes to a simple question: what tools you need to master to be an eligible candidate?!)\n10. Through which category people have their training on machine learning? (Reason: We all need to carry on learning and growing, and how and where people learn after they start their career?)\n11. How to evaluate if your current education background is enough for the occupation? (Reason: If you would like to have a long-term plan to see if you need further education for career goal, check it out!)\n12. Are you young enough? Interested in knowing the age distribution among different jobs? (Reason: People may say they are still young, so they are not worried about things, or some group of people complain they are too old to become something, wanna see how old your peers are?)","01c8afce":"## What type of data do people work with?\n\nHere we take a glimpse at the different data type that people in different occupations work with! Although this can be significantly impacted by the industry you are in, we stilll can get some insights out of it!\n\n### We all use numeric data:\n1. Apparently, most of people regardless of occupation are working with numeric data. \n2. Categorical, text, tabular and time series are also common!\n3. Tecnical positions have more chance to explore more type of data.","3ff36cb4":"## Here it is, what tools are they primarily using at work?\n\nYou know all their work from a macro perspective, now it comes down to the ground, what tools do they use at work? If you wanna be in this occupation but haven't learned the tools that they all use, better start learning it! FYI, this counts are quite rough and i have to say not very accurate since it's extracted from free form responses, but the result at least tells something.\n\n### Jupyter dominates!!\n1. Jupyter are very widely used nowadays.\n2. Python, excel and Rstudio are coming after! We can aware that for the occupations that need storytelling or interpretation, Rstudio are very popular! It's not hard to understand since R is a very nice tool for visualization. \n3. Excel are still popular. And they are even more popular among data scientist!! hope it is because my mistake in transforming data :)","98f24a14":"## How much time you have on exploring model insights?\n\nThis is usually the part coming after obtaining the result! A deep and clear insight of the model can help improve the communication between business and technique very much!\n\n### Wanna tell a better story? Spend more time on exploring insights:\n1. Chief officers & pricipals & managers need to spend more time on it to tell a better story.\n2. Data scientists and statisticians need to gain more insights to help themselves evaluate, analyze and improve the result!","50fb76d9":"## How long have people been writing code to analyze data?\n\nAfter knowing much time they need to spend on coding, i would like to know the experience they have to analyze data with code. And I would like to see if some positions require loads of coding experience.\n\n### Wanna get to principal\/chief\/higher position? it will take time! (From the first question, they seem have no time for coding now, but probably most of them have been through it):\n1. As we can see, for some positions, especially high level positions, like chief\/principal, althgough right now, it looks like they are not coding, based on the figure below, most of them have lots of years of coding experience. It's quite easy to understand, a good leader should be very familiar to the work, and thus be able to lead and plan the project.\n2. Don't be afraid! Most of people have similar experience as you! We could see that most of people in these technical positions have less than 5 years of using code to analyze data.","610e9648":"## How the time is distributed in data project?\n\nIn a general data project, where do you spend your most time on?\n\n### From the last question, we know collecting and cleaning are very important part in the role. But they are always not EASY to do! \n1. Collecting and cleaning data are time consuming.\n2. Seeing 'putting model into production' just takes very little time (around 5% on average), this can explain the fact that most of our experiements\/exploration\/models will not impact the real world since the project will die before this stage. And putting the model into production really means something!","dfb004b1":"## Which activity makes up an important part of role at work?\n\nThere are many types of activities at work, and we would like to take a deeper look at which activities are important to which occupations. Once we know this, we can have a more complete picture of what job content they have.\n\n### You can have lots of ideas, but understand your data first!!!\n1. We can have a lot of ideas, but before buiding something from scratch, you have to spend time collecting, cleaning, analyzing and understanding your data!\n2. Engineers live with building infrastructure & service! Scientists and analysts can create hundreds of models, but they all need to place to run (especially if your company wants to productionize it), data engineers\/database engineer build the foundation for you!\n3. Build prototypes or experiment machine learning models are the first-go! Before putting things in production, they need prototypes to prove the feasibility.","637985d4":"### How many language tools people use primarily?\n\nLooks like most of people have only one main tool to use, quite disappointed at the result, but probably after some more corrections and better data wrangling, should get better and more accurate result!","2aac003b":"## Is machine learning experience important to your work?\n\nWe all talk about machine learning every single day, but is having machine learning a must?!\n\n### Wanna be data scientist, you'd better know it:\n1. For occupations like data scientist, statistician and research scientist, there is no doubt that they have experience since they constantly use them and develop new models and algorithms.\n2. For positions like chief or principal, similarly to coding experience, they also have learned machine learning for quite long time. It's not hard to understand, since they need to fully understand how models\/algorithms work so as to better interpret them to non-technical groups and lead a project (especially a huge one).\n3. If you are only into being analysts, you can spend less time on learning machine learning!\n","8ba4cc13":"## What kind of education background do they have?\nIf you want to evaluate yourself and think long-term of yourself in the career development at a certain stage, look at the education background most people have in that occupation.\n\n### Good! PhD is not a MUST-HAVE for data scientist!?\n1. Most of people have Master's degree. Should be sufficient for most of jobs.\n2. Would like to end up high? PhD might help!\n3. Researches really need high education background!\n4. Data Engineers\/DBA engineers prefer practical over academical."}}