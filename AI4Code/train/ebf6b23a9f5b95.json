{"cell_type":{"2f561537":"code","dfbd170d":"code","d8bdaffb":"code","17bee982":"code","ee3b5e6f":"code","af01db7a":"code","d4bea8ce":"code","9e8c357c":"code","d6b21328":"code","33f0464e":"code","364c18b0":"code","bd905a55":"code","6416e071":"code","0b61a68a":"code","a0854b56":"code","660d8d13":"code","887b8031":"code","d6b430eb":"code","f231e2e0":"code","af86ac18":"code","d0e46e54":"code","b8d234ed":"code","1b08805d":"code","4c131a81":"code","0becac38":"code","d0677336":"code","51d665f2":"markdown","d6021431":"markdown","a5b06194":"markdown","2170aa3d":"markdown","a6ac98ba":"markdown","38869ed0":"markdown","6c60bc45":"markdown","a99c7318":"markdown","a85c7004":"markdown","8aeb6059":"markdown","2f0f0dda":"markdown","f387fd7e":"markdown","d372c892":"markdown","2fcacb8a":"markdown","89d858c1":"markdown","535d605f":"markdown","b8d3269c":"markdown","ae422ff2":"markdown"},"source":{"2f561537":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport numpy as np\nimport matplotlib as mp\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport random\n\nimport cv2   # object detection\nimport tensorflow as tf  # deeplearning library\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split  # splitting my nn data easily\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n\n\nimport sys\nimport os\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/natural-images\/data\/natural_images\"))\n\n\nfrom distutils.version import StrictVersion\nfrom collections import defaultdict\nfrom io import StringIO\n\nsys.path.append(\"..\")\n","dfbd170d":"#from imageai.Detection import ObjectDetection\nprint(tf.__version__)","d8bdaffb":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","17bee982":"inp_img_width  = 224 #200\ninp_img_height = 224 #100\nimg_size = inp_img_height * inp_img_width","ee3b5e6f":"def load_images(image_dir):\n    \"\"\"Loads all images inside the imageDir into an array.\"\"\"\n    image_bond = [] # array for all images  \n    image_path_list = []\n    VALID_IMAGE_EXTENSIONS = [\".jpg\", \".jpeg\", \".png\"] # valid extensions\n\n    for file in os.listdir(image_dir):\n        extension = os.path.splitext(file)[1]\n        if extension.lower() not in VALID_IMAGE_EXTENSIONS:\n            continue\n        image_path_list.append(os.path.join(image_dir, file))\n        \n    for imagePath in image_path_list:       \n        img = cv2.imread(imagePath)  # reads all the images from the given path\n        if img is None: # choose next\n            continue\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        image_bond.append(img)\n        \n    return(image_bond)\n\n\ndef resize_images(img_arr, width, height):\n    \"\"\"Resizes a single image\"\"\" \n    img_res_arr = []\n    width = width\n    height = height\n    \n    for img in img_arr:\n        img = cv2.resize(img,(width, height))\n        img_res_arr.append(img)\n    \n    return img_res_arr\n\ndef gray_images(img_arr):\n    img_arr_gray = []\n    for img in img_arr:\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        img_arr_gray.append(img)\n    return img_arr_gray\n\ndef assign_images(img_arr,assignment):\n    #img_arr_assigned = []\n    #assignment_arr = [assignment]\n    img_arr_assigned = [assignment for img in img_arr]\n    #for img in img_arr:\n    #    img_arr_assigned.append(assignment)\n    return img_arr_assigned","af01db7a":"## Load images, resize and gray them and at least assign the correct object type\n\n## Airplanes\nimages_airplanes = load_images('..\/input\/natural-images\/data\/natural_images\/airplane\/')          ## Load image into array of arrays\nimages_airplanes = resize_images(images_airplanes, inp_img_width,inp_img_height)  ## Resize the image to the predefined size\n#images_airplanes = gray_images(images_airplanes)                                  ## Gray images \nimages_airplanes_assigned = assign_images(images_airplanes,'airplane')            ## Assign the correct object to the image (our target)\n\n## Motorbike\nimages_motorbikes = load_images('..\/input\/natural-images\/data\/natural_images\/motorbike\/')\nimages_motorbikes = resize_images(images_motorbikes, inp_img_width,inp_img_height)\n#images_motorbikes = gray_images(images_motorbikes)\nimages_motorbikes_assigned = assign_images(images_motorbikes,'motorbike')\n\n# Cars\nimages_cars      = load_images('..\/input\/natural-images\/data\/natural_images\/car\/')\nimages_cars      = resize_images(images_cars, inp_img_width,inp_img_height)\n#images_cars      = gray_images(images_cars)\nimages_cars_assigned = assign_images(images_cars,'car')\n\n# Cats\nimages_cats       = load_images('..\/input\/natural-images\/data\/natural_images\/cat\/')\nimages_cats       = resize_images(images_cats, inp_img_width,inp_img_height)\n#images_cats       = gray_images(images_cats)\nimages_cats_assigned = assign_images(images_cats,'cat')\n\n# Persons\nimages_persons    = load_images('..\/input\/natural-images\/data\/natural_images\/person\/')\nimages_persons    = resize_images(images_persons, inp_img_width,inp_img_height)\n#images_persons    = gray_images(images_persons)\nimages_persons_assigned = assign_images(images_persons,'person')","d4bea8ce":"images_features = images_airplanes + images_motorbikes + images_cars + images_cats + images_persons\nprint('lenght of feature set: ',len(images_features))","9e8c357c":"images_targets = images_airplanes_assigned + images_motorbikes_assigned + images_cars_assigned + images_cats_assigned + images_persons_assigned\nprint('lenght of target set: ',len(images_targets))","d6b21328":"# combine them in one list\ncomb_list = list(zip(images_features, images_targets))\n\n# shuffle both list equaly\nrandom.Random(45).shuffle(comb_list)\n\n# splitt them again\nimages_features, images_targets = zip(*comb_list)","33f0464e":"from IPython.display import display\n\ndisplay(Image.fromarray(images_features[0]))\ndisplay(images_targets[0])","364c18b0":"display(Image.fromarray(images_features[1]))\ndisplay(images_targets[1])","bd905a55":"display(Image.fromarray(images_features[10]))\ndisplay(images_targets[10])","6416e071":"# splitting features and targets into train- and test- set\nX_train, X_test, y_train, y_test = train_test_split(images_features, images_targets, test_size = 0.20, random_state = 45)","0b61a68a":"# scaling, normalizing the image pixels (between 0 and 1)\nX_train = tf.keras.utils.normalize(np.asfarray(X_train))#, axis = -1) \nX_test = tf.keras.utils.normalize(np.asfarray(X_test))#, axis = -1)","a0854b56":"#X_train = np.asfarray(X_train)\n#X_test = np.asfarray(X_test)","660d8d13":"# join train and test to encode(get_dummies) all categories in the same way \ny = y_train + y_test\ndf_y = pd.DataFrame(y) ","887b8031":"# Label encoding of the targets\nle = LabelEncoder()\nle.fit(df_y)\ndf_y_hot = le.transform(df_y)","d6b430eb":"# reshaping for the neural network\ndf_y_hot = pd.DataFrame(df_y_hot)\ndf_y_hot = np.asfarray(df_y_hot)","f231e2e0":"# write the created dummies back again\n# just to make this clear: I used the length of the train data set to split the combined lists into train ([:len(y_train)]) and test([len(y_train):]) again.\n#  in the same way I convert the result into in array, which is necessary for the use of an nn.\ny_train = np.asfarray( df_y_hot[:len(y_train)] )#.reshape(1,-5)\ny_test = np.asfarray( df_y_hot[len(y_train):] )#.reshape(1,-5)","af86ac18":"#y_train.reshape(1,-1)\ny_train.shape","d0e46e54":"#y_train[0\nX_train[0].shape\n\n#X_train[0]\n#Image.fromarray(np.asfarray(X_train[0]))\n\n#display(Image.fromarray(images_features[0]))","b8d234ed":"# shape of the feauture set\nprint(\"rows, height, length, color shape : \", X_train.shape)","1b08805d":"# Model building\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Conv2D(224, (2,2), activation=tf.nn.relu, input_shape=(224,224,3)))  \nmodel.add(tf.keras.layers.MaxPooling2D((2,2)))\nmodel.add(tf.keras.layers.Conv2D(112, (3,3), activation=tf.nn.relu))\nmodel.add(tf.keras.layers.MaxPooling2D((2,2)))\nmodel.add(tf.keras.layers.Conv2D(224, (3,3), activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(5, activation=tf.nn.softmax))\n\n##model.add(tf.keras.layers.Flatten())\n","4c131a81":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy']\n             )\n\nmodel.fit(X_train, y_train, epochs = 4)","0becac38":"# Test the model and show the accuracy\nval_loss, val_acc = model.evaluate(X_test, y_test)","d0677336":"model.save('first_fit_4e.model')","51d665f2":"# Installs","d6021431":"### Validation Loss\n","a5b06194":"## Preparing Training\nIn this chapter I will prepare the training set which will be a training set from different images of vehicles, persons and animals.","2170aa3d":"#### Features","a6ac98ba":"## Define the Image-Sets","38869ed0":"# The Model","6c60bc45":"#### Targets","a99c7318":"## Env Setup","a85c7004":"## Imports","8aeb6059":"Here the test now that feature (image) and target (typ) map.","2f0f0dda":"Next step will be the combination of all the lists above into two lists:\n\n* features and\n* targets","f387fd7e":"# Introduction","d372c892":"## Global Vars","2fcacb8a":"#### Features","89d858c1":"The following part will load, resize and gray the image for the neural network. Because there are no predefined targets for the images I need to create them by myself based on the image foldername.","535d605f":"## Model Building and Training with TensorFlow","b8d3269c":"#### Targets","ae422ff2":"### Random Shuffle of the two Lists\nI will use here a random shuffle for this two lists in a combined way to make sure all targets fit to their features and vice versa. It would be easier to hold both values (array-list based features and the targets) in one list instead of in two ones, but according to the array-list based features, it was difficult for me to find a good version that did not provoke the performances of this notebook. If you have any suggestions, please let me know in the comments."}}