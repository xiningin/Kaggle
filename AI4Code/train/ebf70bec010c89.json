{"cell_type":{"f95f40d9":"code","c8e10aec":"code","2ddefd0d":"code","462bc5b2":"code","2c969f6b":"code","ae852a96":"code","52532519":"code","4d6ccc27":"code","7530f6f4":"code","20b4c3ee":"code","a892bb4e":"code","a688ec1c":"code","44beb226":"code","7ff02070":"code","670b2bef":"code","dbbd2bfd":"code","fa408abf":"code","b3a5b48b":"code","fb4bab99":"code","09f2128a":"code","5f9e1809":"code","0d51105b":"code","197099b7":"code","b311e347":"code","64ba9384":"code","107474a1":"code","0c560f57":"code","2fa35cc1":"code","7a1f0a3b":"code","b1f7b109":"code","70a1ae85":"code","ef45905c":"code","8335a4ef":"code","9699adda":"code","8a6782cd":"code","484c1af8":"code","df79ae5a":"code","0e997987":"code","c0e83898":"code","74d7d916":"code","7dbada87":"code","af2f3aec":"code","4644f708":"code","75f7e5f1":"code","6cf8e7ab":"code","95ef7cb8":"code","16025044":"code","8c0d4ce5":"code","4998ea26":"code","e8bd031f":"code","fddf3cbd":"code","ea3d7000":"code","22d8be64":"code","d8bc575f":"code","c78c3af9":"code","75974a2d":"code","614a59a4":"code","2f2b01ae":"code","3198173e":"code","1fd9ebb5":"code","930f2a35":"code","27b135d9":"code","db0afd32":"code","abaeec56":"code","415af0d5":"code","96791876":"code","d9dae2c3":"code","6e22280f":"code","7358a333":"code","0235da31":"markdown","273d9352":"markdown","6881f4a8":"markdown","274e57b3":"markdown","52a2fed4":"markdown"},"source":{"f95f40d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8e10aec":"import matplotlib.pyplot as plt\nimport seaborn as sns\n# this allows plots to appear directly in the notebook\n%matplotlib inline","2ddefd0d":"df=pd.read_csv('\/kaggle\/input\/machine-learning-24-hrs-hackathon\/train_SJC.csv')","462bc5b2":"df.head()","2c969f6b":"df1=df.rename(columns={\"Unnamed: 0\":\"ClaimNumber\",\"Unnamed: 1\":\"DateTimeOfAccident\",\"Unnamed: 3\":\"Age\",\"Unnamed: 4\":\"Gender\",\"Unnamed: 5\":\"MaritalStatus\",\"Unnamed: 6\":\"DependentChildren\",\"Unnamed: 8\":\"WeeklyWages\",\"Unnamed: 9\":\"PartTimeFullTime\",\"Unnamed: 10\":\"HoursWorkedPerWeek\",\"Unnamed: 12\":\"ClaimDescription\",\"Unnamed: 13\":\"InitialIncurredCalimsCost\",\"Unnamed: 14\":'UltimateIncurredClaimCost'},inplace=False)","ae852a96":"df1.head()","52532519":"data=df1.drop(df1.index[0])\ndata.head()","4d6ccc27":"data.info()","7530f6f4":"data.shape","20b4c3ee":"data.describe()","a892bb4e":"data.isnull().sum()","a688ec1c":"data['MaritalStatus'].value_counts()","44beb226":"data['MaritalStatus'].mode()","7ff02070":"data=data.dropna()","670b2bef":"data.shape","dbbd2bfd":"data.isnull().sum()","fa408abf":"# Converting the datatypes\ndata['UltimateIncurredClaimCost']=data['UltimateIncurredClaimCost'].astype(np.float64)\nlog_UltimateIncurredClaimCost=np.log(data['UltimateIncurredClaimCost'])","b3a5b48b":"plt.figure(figsize=(12,10))\nsns.barplot(x='MaritalStatus',y='UltimateIncurredClaimCost',data=data)\nplt.show()","fb4bab99":"plt.figure(figsize=(12,10))\nsns.barplot(x='PartTimeFullTime',y='UltimateIncurredClaimCost',data=data)\nplt.show()","09f2128a":"sns.pairplot(data)","5f9e1809":"#heatmap to see corelation between each of the cloumns\nsns.heatmap(data.corr(),annot=True) #annot will dispaly the number for the corelation","0d51105b":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","197099b7":"data['Gender'].value_counts()","b311e347":"data['Gender'] = le.fit_transform(data['Gender'])\ndata['MaritalStatus'] = le.fit_transform(data['MaritalStatus'])                                      \ndata['PartTimeFullTime']=le.fit_transform(data['PartTimeFullTime'])","64ba9384":"data.head()","107474a1":"data.columns","0c560f57":"X = data[['Age','Gender','MaritalStatus','PartTimeFullTime',\n       'DependentChildren', 'DependentsOther', 'WeeklyWages',\n        'HoursWorkedPerWeek', 'DaysWorkedPerWeek','InitialIncurredCalimsCost']]\ny=data['UltimateIncurredClaimCost']\nX.head()","2fa35cc1":"print(X.shape)\nprint(y.shape)","7a1f0a3b":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.6, random_state =30)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","b1f7b109":"from sklearn.linear_model import LinearRegression","70a1ae85":"#creating linear regression object\nlm = LinearRegression()","ef45905c":"lm.fit(x_train,y_train)","8335a4ef":"lm.score(x_train,y_train)","9699adda":"lm.score(x_test,y_test)","8a6782cd":"from sklearn.ensemble import RandomForestRegressor\n#creating a regressor object\nregressor = RandomForestRegressor(n_estimators = 100, random_state = 50)\nregressor.fit(x_train, y_train)\n\ny_pred = regressor.predict(x_test)\nregressor.score(x_train,y_train)","484c1af8":"new_model=regressor.fit(x_train, y_train)\nnew_model.feature_importances_","df79ae5a":"regressor.score(x_test,y_test)","0e997987":"# print the intercept\nprint(lm.intercept_)","c0e83898":"coeff_data = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])\ncoeff_data","74d7d916":"lm.coef_","7dbada87":"x_train.columns","af2f3aec":"cdf=pd.DataFrame(lm.coef_,X.columns,columns=['coeff'])","4644f708":"cdf","75f7e5f1":"#we have coefficent for each feature","6cf8e7ab":"predictions = lm.predict(x_test)","95ef7cb8":"y_test","16025044":"plt.scatter(y_test,predictions)","8c0d4ce5":"from sklearn import metrics","4998ea26":"metrics.mean_absolute_error(y_test,predictions)","e8bd031f":"metrics.mean_squared_error(y_test,predictions)","fddf3cbd":"np.sqrt(metrics.mean_squared_error(y_test,predictions))","ea3d7000":"test_new=pd.read_csv('\/kaggle\/input\/machine-learning-24-hrs-hackathon\/Test_SJC.csv')","22d8be64":"test_new.head()","d8bc575f":"test_new.shape","c78c3af9":"test_new.isnull().sum()","75974a2d":"test_new=test_new.dropna()","614a59a4":"data.isnull().sum()","2f2b01ae":"test_new['Gender'].value_counts()","3198173e":"index_names = test_new[ test_new['Gender'] == 'U' ].index\ntest_new.drop(index_names, inplace = True)","1fd9ebb5":"test_new['Gender'].value_counts()","930f2a35":"# importing label encoder\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntest_new['Gender'] = le.fit_transform(test_new['Gender'])\ntest_new['MaritalStatus'] = le.fit_transform(test_new['MaritalStatus'])                                     \ntest_new['PartTimeFullTime']=le.fit_transform(test_new['PartTimeFullTime']) ","27b135d9":"x1=test_new['Age']\nx2=test_new['Gender']\nx3=test_new['MaritalStatus']\nx4=test_new['PartTimeFullTime']\nx5=test_new['DependentChildren']\nx6=test_new['DependentsOther']\nx7=test_new['WeeklyWages']\nx8=test_new['HoursWorkedPerWeek']\nx9=test_new['DaysWorkedPerWeek']\nx7=test_new['InitialIncurredCalimsCost']","db0afd32":"test_new=test_new.fillna('M')","abaeec56":"new_model.feature_importances_","415af0d5":"predection=0.10662819*x1+0.07007401*x2+0.05497839*x3+0.00313286*x4+0.00746627*x5+ 0.00142361*x6+0.19779586*x7+0.16558412*x8+0.00800054*x9+0.38491616*x1","96791876":"predection","d9dae2c3":"predection.mean()","6e22280f":"csv = pd.read_csv(\"\/kaggle\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")\ncsv[\"UltimateIncurredClaimCost\"]=predection","7358a333":"csv.to_csv(\"Sample Submission.csv\", index = False)","0235da31":"## Creating and Importing label encoder","273d9352":"# Creating and Training the Model","6881f4a8":"# Predictions from our Model","274e57b3":"# train test split on our data\n--Splitting the data into a training set and a testing set. We will train out model on the training set and then use the test set to evaluate the model.\n\n","52a2fed4":"## EDA"}}