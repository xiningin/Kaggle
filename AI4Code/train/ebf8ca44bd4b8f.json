{"cell_type":{"d1ad09e7":"code","5633cba4":"code","d2b316c0":"code","0ee76c59":"code","d6d47312":"code","8b06ee8a":"code","f02dc9cf":"code","349aa809":"code","a074eac8":"code","d9487233":"code","ab5ba1bb":"code","bc3a23b9":"code","827260a1":"code","3222dc7d":"code","2d57b258":"code","cc3b5225":"code","f1aa8943":"code","8d46d0d1":"code","358ff2aa":"code","bca12acd":"code","1ee35d6e":"markdown","846b49f3":"markdown"},"source":{"d1ad09e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom keras import layers, models, optimizers\n# from keras.utils import to_categorical, Sequence\nfrom keras.preprocessing.image import ImageDataGenerator","5633cba4":"print(os.listdir(\"..\/input\/fruits-360_dataset\/fruits-360\/Training\"))","d2b316c0":"print(os.listdir(\"..\/input\/fruits-360_dataset\/fruits-360\/Test\"))","0ee76c59":"def construct_fruits_dict(path):\n    _dict = {}\n    for fruit in os.listdir(path):\n        _dict[fruit] = []\n        for img in os.listdir(f'{path}\/{fruit}'):\n            _dict[fruit].append(f'{path}\/{fruit}\/{img}')\n    return _dict","d6d47312":"training_dict = construct_fruits_dict(\"..\/input\/fruits-360_dataset\/fruits-360\/Training\")\ntest_dict = construct_fruits_dict(\"..\/input\/fruits-360_dataset\/fruits-360\/Test\")","8b06ee8a":"fruits = list(training_dict.keys())","f02dc9cf":"fig, axs = plt.subplots(9, 9, figsize=(20,20))\nc = 0\nfor i in range(9):\n    for j in range(9):\n        f = fruits[c]\n        img = plt.imread(training_dict[f][0])\n        axs[i,j].set_title(f)\n        axs[i,j].imshow(img)\n        axs[i,j].axis('off')\n        c += 1","349aa809":"train_datagen = ImageDataGenerator(rescale=1\/255, validation_split=0.25)\ntrain_generator = train_datagen.flow_from_directory(\n    \"..\/input\/fruits-360_dataset\/fruits-360\/Training\",\n    target_size=(100, 100),\n    batch_size=128,\n    shuffle=True,\n    class_mode='categorical',\n    subset='training'\n)\nvalidation_generator = train_datagen.flow_from_directory(\n    \"..\/input\/fruits-360_dataset\/fruits-360\/Training\",\n    target_size=(100, 100),\n    batch_size=128,\n    shuffle=True,\n    class_mode='categorical',\n    subset='validation'\n)\ntest_datagen = ImageDataGenerator(rescale=1\/255)\ntest_generator = train_datagen.flow_from_directory(\n    \"..\/input\/fruits-360_dataset\/fruits-360\/Test\",\n    target_size=(100, 100),\n    batch_size=128,\n    class_mode='categorical'\n)","a074eac8":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu')) \nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(81, activation='sigmoid'))\nmodel.summary()","d9487233":"model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","ab5ba1bb":"history = model.fit_generator(\n    generator=train_generator, \n    epochs=15, \n    steps_per_epoch=int(np.ceil(31018 \/ 128)),\n    validation_data=validation_generator,\n    validation_steps=int(np.ceil(10304 \/ 128))\n)","bc3a23b9":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","827260a1":"model.evaluate_generator(generator=test_generator, steps=int(np.ceil(13877 \/ 128)))","3222dc7d":"model.predict(np.array([plt.imread(training_dict['Lemon'][50]) \/ 255]))[0]","2d57b258":"fruits[np.argmax(model.predict(np.array([plt.imread(training_dict['Lemon'][50]) \/ 255]))[0] )]","cc3b5225":"print(os.listdir(\"..\/input\/fruits-360_dataset\/fruits-360\/test-multiple_fruits\/\"))","f1aa8943":"multi = plt.imread(\"..\/input\/fruits-360_dataset\/fruits-360\/test-multiple_fruits\/cocos_kiwi_orange_dates_salak_plum_tamarilo_maracuja.jpg\") \/ 255\nmulti = cv2.resize(multi, (100, 100))","8d46d0d1":"pred = model.predict(np.array([multi]))","358ff2aa":"fruits[np.argmax(pred[0])]","bca12acd":"plt.imshow(multi)","1ee35d6e":"now lets visualize some fruits images","846b49f3":"first lets read all the training files names into dict"}}