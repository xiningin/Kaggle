{"cell_type":{"7fb605d9":"code","9b891215":"code","528683f7":"code","87f5c620":"code","37b54720":"code","d1e2b72d":"code","ef74c977":"code","59f580ba":"code","0a67a58a":"markdown","2bdd2862":"markdown","cb79381d":"markdown","ffd50ea6":"markdown","3bc67c14":"markdown","eced0aa4":"markdown","2fa39ecd":"markdown","9f5e6e1c":"markdown"},"source":{"7fb605d9":"import numpy as np\nimport pandas as pd","9b891215":"# RMSE (Root Mean Squared Error)\nfrom sklearn.metrics import mean_squared_error\n\ny_true = [1.0, 1.5, 2.0, 1.2, 1.8]\ny_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n\nrmse = np.sqrt(mean_squared_error(y_true, y_pred))\nprint(rmse)\n# 0.55317","528683f7":"# RMSLE (Root Mean Squared Logarithmic Error)\nfrom sklearn.metrics import mean_squared_log_error\n\ny_true = [100, 0, 400]\ny_pred = [200, 10, 200]\n\nrmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\nprint(rmsle)\n# 1.49449","87f5c620":"# MAE (Mean Absolute Error)\nfrom sklearn.metrics import mean_absolute_error\n\ny_true = [100, 160, 60]\ny_pred = [80, 100, 100]\n\nmae = mean_absolute_error(y_true, y_pred)\nprint(mae)\n# 40.0","37b54720":"# accuracy, error rate\nfrom sklearn.metrics import accuracy_score\n\n# Binary classification of 0 and 1\ny_true = [1, 0, 1, 1, 0, 1, 1, 0]\ny_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n\naccuracy = accuracy_score(y_true, y_pred)\nprint(accuracy)\n# 0.625","d1e2b72d":"# precision, recall\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n# Binary classification of 0 and 1\ny_true = [1, 0, 1, 1, 0, 1, 1, 0]\ny_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\n\nprint(precision, recall)\n# 0.75 0.6","ef74c977":"# logloss\nfrom sklearn.metrics import log_loss\n\n# True value and predicted probability of binary classification of 0 and 1\ny_true = [1, 0, 1, 1, 0, 1]\ny_prob = [0.1, 0.2, 0.8, 0.8, 0.1, 0.3]\n\nlogloss = log_loss(y_true, y_prob)\nprint(logloss)\n# 0.71356","59f580ba":"# confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n# Binary classification of 0 and 1\ny_true = [1, 0, 1, 1, 0, 1, 1, 0]\ny_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n\n\n# TP(True Positive), TN(True Negative), FP(False Positive), FN(False Negative)\ntp = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 1))\ntn = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 0))\nfp = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 1))\nfn = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 0))\n\nconfusion_matrix1 = np.array([[tp, fp], [fn, tn]])\nprint(confusion_matrix1)\n\n# array([[TP, FP]\n#        [FN, TN]])\n\n\nconfusion_matrix2 = confusion_matrix(y_true, y_pred)\nprint(confusion_matrix2)\n\n# array([[TN, FP]\n#        [FN, TP]]) ","0a67a58a":"## This Note Book describes the names, formulas, simple points, and Python implementation code of typical metrics for the model.","2bdd2862":"# MAE (Mean Absolute Error)\n$$MAE = \\frac 1N \\sum^{N}_{i=1} |y_{i} - \\hat{y}_{i}|$$\n- Indicators that reduce the effects of outliers\n- Difficult to handle when differentiating","cb79381d":"# RMSLE (Root Mean Squared Logarithmic Error)\n$$RMSLE = \\sqrt{ \\frac 1N \\sum ^{N}_{i=1} (log(1 + y_{i}) - log(1 + \\hat{y}_{i}))^2}$$\n\n- Use when the effect of a large value is strong if the objective variable is not converted\n- This indicator focuses on the ratio of the true value to the predicted value","ffd50ea6":"# logloss (cross entropy)\n$$logloss = - \\frac 1N \\sum^{N}_{i=1} (y_{i}\\log{p_{i}} + (1-y_{i})\\log(1-p_{i}))$$\n- Representative metrics for classification tasks\n- y is a label indicating whether it is a positive example, p is a probability that it is a positive example","3bc67c14":"# accuracy, error rate\n$$accuracy = \\frac {TP + TN}{TP + TN + FP + FN}$$\n$$$$\n$$error\\ rate = 1 - accuracy$$\n- Unbalanced data makes it difficult to evaluate model performance\n- Not often used in analytical competitions","eced0aa4":"## Extra","2fa39ecd":"# RMSE (Root Mean Squared Error)\n$$RMSE = \\sqrt{ \\frac 1N \\sum ^{N}_{i=1} (y_{i} - \\hat{y}_{i})^2}$$\n\n- Statistically meaningful indicators\n- Outliers must be removed beforehand because they are greatly affected by outliers","9f5e6e1c":"# precision, recall\n$$precision = \\frac {TP} {TP + FP}$$\n$$$$\n$$recall = \\frac {TP} {TP+ FN}$$\n- precision and recall are in a trade-off relationship with each other\n- Focus on precision if you want to reduce false positives\n- Focus on recall if you want to avoid missing a positive example"}}