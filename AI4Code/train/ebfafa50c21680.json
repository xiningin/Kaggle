{"cell_type":{"84f069a5":"code","af69f958":"code","6d6dcac8":"code","14a820f5":"code","03556aab":"code","a38fc786":"code","a2eee73a":"code","91d65f80":"code","bae2ff23":"code","8fea2f66":"code","93bc596f":"code","4ca4aa02":"code","c672ad72":"code","ef1d3204":"code","6216e89c":"code","450b1467":"code","beacf607":"code","9b0ece08":"code","f90ca2dd":"code","1772e01e":"code","62a14b5f":"code","ac2a49d0":"code","eb4d66a3":"code","e22bcc29":"markdown","340557b2":"markdown","eb183304":"markdown","eec73be6":"markdown","a99e79c4":"markdown","d2d1b7e2":"markdown","29b21bd8":"markdown","88084b53":"markdown","063b24e3":"markdown","9db7d616":"markdown","15669c3e":"markdown","2c665564":"markdown","e93df752":"markdown","8ffe7226":"markdown","ada58d13":"markdown","3041337c":"markdown","c297f2ad":"markdown","342d595a":"markdown","03a22407":"markdown","8d8ae979":"markdown","7a03bf52":"markdown","b9db7316":"markdown","462a2107":"markdown","54f75236":"markdown"},"source":{"84f069a5":"# Load Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # dataframes\nimport matplotlib.pyplot as plt # General visualisations\nimport matplotlib.ticker as mtick # Axis visuals\nimport seaborn as sns # Statistical visualisations\nimport statsmodels.api as sm # Linear Regression\n\n# Load data into pandas\ndf_customers = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\ndf_orders = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")\ndf_payments = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\ndf_items = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\n\n# Plot styling\nplt.style.use('ggplot')","af69f958":"print(\"Customer Dataframe has {} rows and {} columns\".format(*df_customers.shape))\nprint(\"Orders Dataframe has {} rows and {} columns\".format(*df_orders.shape))\nprint(\"Payments Dataframe has {} rows and {} columns\".format(*df_payments.shape))\nprint(\"Items Dataframe has {} rows and {} columns\".format(*df_items.shape))","6d6dcac8":"df_customers.head()","14a820f5":"df_orders.head()","03556aab":"df_payments.head()","a38fc786":"df_items.head()","a2eee73a":"# Inner join customers and orders\ndf_modelling = pd.merge(df_customers, df_orders, on=\"customer_id\", how=\"inner\").loc[:, ['customer_unique_id', 'order_id','order_purchase_timestamp']]\n\n# Calculate total payment per order\ndf_temp = df_payments.groupby('order_id').agg({'payment_value':'sum'}).reset_index().rename(columns ={'payment_value':'spend'})\n\n# Left join spend on to modelling dataframe\ndf_modelling = pd.merge(df_modelling, df_temp, on=\"order_id\", how=\"left\")\n\n# Calculate basket size for each order\ndf_temp = df_items.groupby('order_id').agg({'order_item_id':'count'}).reset_index().rename(columns={'order_item_id':'basket_size'})\n\n# Left join basket size on time modelling\ndf_modelling = pd.merge(df_modelling, df_temp, on=\"order_id\", how=\"left\")\n\n# Clear objects\ndel df_temp\n\n# View print out\ndf_modelling","91d65f80":"# Calculate and view missingness\ndf_temp = df_modelling.isnull().sum().reset_index().rename(columns={0:'n_missing'})\ndf_temp['pct_missing'] = df_temp.n_missing \/ len(df_modelling) * 100\ndisplay(df_temp)\n\n# clear objects\ndel df_temp","bae2ff23":"# Show order with missing spend\ndisplay(df_modelling[df_modelling.spend.isnull()])\n\n# Add total value to items\ndf_items.insert(7, 'total_value', df_items.price + df_items.freight_value)\n\n# Calculate total value for order\ndf_temp = df_items[df_items.order_id == \"bfbd0f9bdef84302105ad712db648a6c\"].groupby('order_id').agg({'total_value':'sum'})\n\n# Drop totabl column from items\ndf_items.drop(columns = ['total_value'], inplace = True)\n\n# Add data to modelling dataframe\ndf_modelling.iloc[np.flatnonzero(df_modelling.spend.isnull()), \n                  df_modelling.columns.get_loc('spend')] = df_temp.total_value[0]\n\n# Show order which previously had missing spend\ndisplay(df_modelling[df_modelling.order_id == \"bfbd0f9bdef84302105ad712db648a6c\"])\n\n# clear objects\ndel df_temp","8fea2f66":"# Create a temp dataframe\ndf_temp = df_modelling[['spend','basket_size']]\ndf_temp.groupby('basket_size').size()","93bc596f":"# Store averages per basket size\ndf_temp = df_temp.groupby('basket_size').agg({'spend':'mean'}).reset_index()\ndf_temp = df_temp[df_temp.basket_size <= 7]\n\n# Plot Relationship\nplt.figure(figsize=(16,5))\nax = sns.regplot(data = df_temp, \n                 x=\"spend\", \n                 y=\"basket_size\")\nplt.title(\"Relationship between Average Spend & Basket Size\")\nplt.xlabel(\"Order Value\")\nplt.ylabel(\"Basket Size\")\nplt.show()","4ca4aa02":"# Fit models\nlm_mod = sm.OLS(df_temp.basket_size, df_temp.spend)\nlm_mod = lm_mod.fit()\n\n# Update the missing entries\ndf_modelling['basket_size'] = \\\n    df_modelling['basket_size']. \\\n        fillna(np.round(lm_mod.predict(df_modelling.loc[df_modelling.basket_size.isnull(),'spend'])))\n\n# clear objects\ndel df_temp, lm_mod, ax","c672ad72":"# Create Summary Data\ndf_temp = df_modelling.groupby('customer_unique_id').agg({'order_id':'count'}).rename(columns={'order_id':'orders'}).reset_index()\ndf_temp = df_temp.groupby('orders').agg({'customer_unique_id':'count'}).rename(columns={'customer_unique_id':'n_customers'}).reset_index()\ndf_temp['pct_customers'] = df_temp['n_customers'] \/ np.sum(df_temp['n_customers']) * 100\ndf_temp['transition'] = df_temp.n_customers \/ df_temp.n_customers.shift(1) * 100\n\n# Plot relationship\nax = sns.set_style(style=None, rc=None )\nfig, ax = plt.subplots(figsize=(16,6))\nsns.lineplot(data = df_temp['transition'], marker='o', sort = False, ax=ax)\nsns.barplot(data = df_temp, x='orders', y='pct_customers', alpha=0.5, color = 'green', ax=ax)\nplt.title(\"Customers by Number of Orders and Transition Rate\")\nplt.xlabel(\"Number of Orders\")\nplt.ylabel(\"Percentage of Customers\")\nplt.show()\n\n# Clear Objects\ndel df_temp, ax, fig","ef1d3204":"# Identify customers with multiple purchases\ndf_multi = df_modelling.groupby('customer_unique_id').agg({'order_id':'count'}).reset_index().rename(columns = {'order_id':'count'})\ndf_multi = df_multi[df_multi['count'] > 1]\n\n# Filter for customers with multiple purchases\ndf_interval = df_modelling[df_modelling.customer_unique_id.isin(df_multi.customer_unique_id)]\ndel df_multi\n\n# Convert timestamp to date and order the dateframe by customer and order date\ndf_interval = df_interval[['customer_unique_id','order_purchase_timestamp']]\ndf_interval['order_date'] = pd.to_datetime(df_interval['order_purchase_timestamp']).dt.date\ndf_interval = df_interval.sort_values(by =['customer_unique_id','order_date'])\n\n# Calculate the time interval\ndf_interval['previous_date'] = df_interval.groupby('customer_unique_id')['order_date'].shift(1)\ndf_interval.dropna(inplace = True)\ndf_interval['order_interval'] = (df_interval['order_date'] - df_interval['previous_date']).dt.days\n\n# Remove orders made on the same day\ndf_interval = df_interval[df_interval['order_interval'] > 0]\n\n# Plot interval\nplt.figure(figsize =(16,6))\nax = sns.boxplot(df_interval['order_interval'])\nplt.title(\"Distribution of Days Between Orders\")\nplt.xlabel(\"Days\")\nplt.show()\n\n# Clear objects\ndel ax, df_interval ","6216e89c":"# Add order date to modelling dateframe\ndf_modelling['order_date'] = pd.to_datetime(df_modelling['order_purchase_timestamp']).dt.date\n\n# Identify Max Purchase Date\nv_maxdate = df_modelling.order_date.max()\n\n# Identify Max Purchase Date Per Customer\ndf_recency = df_modelling.groupby('customer_unique_id')['order_date'].max().reset_index()\ndf_recency['recency_days'] = (v_maxdate - df_recency['order_date']).dt.days\ndf_recency['segment_recency'] = np.where(df_recency['recency_days'] < 182, 'Active', \n                                         np.where(df_recency['recency_days'] <= 365, 'Inactive', 'Lapsed')) \n\n\n# Plot\nfig, ax = plt.subplots(1, 2, figsize=(16,6))\nax[0].set_title(\"Number of Customers\")\nax[1].set_title(\"Distribution of Days\")\nsns.countplot(data = df_recency, x = 'segment_recency', order = ['Active', 'Inactive', 'Lapsed'], ax = ax[0])\nsns.boxplot(data = df_recency, x = 'segment_recency', y = 'recency_days', order = ['Active', 'Inactive', 'Lapsed'], ax = ax[1])\nplt.setp(ax[:], xlabel='Recency Segment')\nplt.setp(ax[0], ylabel='Number of Customers')\nplt.setp(ax[1], ylabel='Number of Days')\nplt.show()\n\n# Create Segment Dataframe\ndf_segments = df_recency[['customer_unique_id', 'recency_days', 'segment_recency']].copy()\n\n# Clear Object\ndel v_maxdate, df_recency, fig, ax","450b1467":"# Function to create value segments\ndef f_seg_val(row):\n    '''Apply segmentation by row'''\n    \n    if (row.segment_recency == 'Active') & (row.decile_spend >= 6) & (row.decile_volume > 1):\n        return 'High Value & High Volume'\n    elif (row.segment_recency == 'Active') & (row.decile_spend >= 6) & (row.decile_volume == 1):\n        return 'High Value & Low Volume'\n    elif (row.segment_recency == 'Active') & (row.decile_spend < 6) & (row.decile_volume > 1):\n        return 'Low Value & High Volume'\n    elif (row.segment_recency == 'Active') & (row.decile_spend < 6) & (row.decile_volume == 1):\n        return 'Low Value & Low Volume'\n    elif (row.segment_recency == 'Inactive') & (row.decile_spend >= 6):\n        return 'High Value'\n    elif (row.segment_recency == 'Inactive') & (row.decile_spend < 6):\n        return 'Low Value'","beacf607":"# Identify Max Purchase Date\nv_maxdate = df_modelling.order_date.max()\n\n# Identify a year ago\nv_ly = pd.to_datetime(v_maxdate - pd.DateOffset(years=1))\n\n# Calculate the spend and volume for each customer\ndf_value = df_modelling.copy()\ndf_value = df_value[df_value.order_date > v_ly]\ndf_value = df_value.groupby('customer_unique_id').agg({'spend':'sum', 'basket_size':'sum'}).reset_index()\ndf_value.rename(columns = {'basket_size':'volume'}, inplace=True)\ndf_value = pd.merge(df_value, df_segments, on=\"customer_unique_id\", how=\"left\")\n\n# Filter customers as active\/ inactive\ndf_value = df_value[(df_value.segment_recency.isin(['Active', 'Inactive']))]\n\n# Calculate deciles and value segments\ndf_value['decile_spend'] = pd.qcut(df_value.spend, 10, labels=np.arange(1, 11, 1)).astype('int')\ndf_value['decile_volume'] = pd.qcut(df_value.volume, 2, duplicates='drop', labels=np.arange(1, 3, 1)).astype('int')\ndf_value['segment_value'] = df_value.apply(f_seg_val, axis=1)\n\n# Plotting counts\nfig, ax = plt.subplots(1,2, figsize=(16,6))\nax[0].set_title(\"Active Customers\")\nax[1].set_title(\"Inactive Customers\")\nsns.countplot(data = df_value[df_value.segment_recency == \"Active\"],\n            x=\"segment_value\",\n            order = ['High Value & High Volume', 'High Value & Low Volume', \n                     'Low Value & High Volume', 'Low Value & Low Volume'],\n            ax=ax[0])\nsns.countplot(data = df_value[df_value.segment_recency == \"Inactive\"],\n            x=\"segment_value\",\n            order = ['High Value', 'Low Value'],\n            ax=ax[1])\nplt.setp(ax[0].xaxis.get_majorticklabels(), rotation=45)\nplt.setp(ax[:], xlabel='')\nplt.setp(ax[:], ylabel='Number of Customers')\nplt.show()\n\n# Clear objects\ndel v_maxdate,v_ly,fig,ax,f_seg_val","9b0ece08":"# Summarise Lifetime Spend Behaviour\ndf_temp = df_value.groupby(['segment_recency', 'segment_value']).agg({'spend':'sum', 'customer_unique_id':'count'}).reset_index()\ndf_temp['spend_per_cust'] = df_temp['spend'] \/ df_temp['customer_unique_id']\n\n# Plotting counts\nfig, ax = plt.subplots(1,2, figsize=(16,6))\nax[0].set_title(\"Active Customers\")\nax[1].set_title(\"Inactive Customers\")\nsns.barplot(data = df_temp[df_temp.segment_recency == \"Active\"],\n            x=\"segment_value\",\n            order = ['High Value & High Volume', 'High Value & Low Volume', \n                     'Low Value & High Volume', 'Low Value & Low Volume'],\n            y=\"spend_per_cust\",\n            ax=ax[0])\nsns.barplot(data = df_temp[df_temp.segment_recency == \"Inactive\"],\n            x=\"segment_value\",\n            y=\"spend_per_cust\",\n            order = ['High Value', 'Low Value'],\n            ax=ax[1])\nax[0].set(ylim=(0, 400))\nax[1].set(ylim=(0, 400))\nplt.setp(ax[0].xaxis.get_majorticklabels(), rotation=45)\nplt.setp(ax[:], xlabel='')\nplt.setp(ax[:], ylabel='Average Spend Per Customer')\nplt.show()\n\n# clear objects\ndel df_temp,df_value,fig,ax","f90ca2dd":"# Function to create value segments\ndef f_segment_logic(row, typeof):\n    '''Apply segmentation by row'''\n    \n    if typeof == \"value\":\n        if (row.segment_recency == 'Lapsed'):\n            return 'Lapsed'\n        elif (row.segment_recency == 'Active') & (row.decile_spend >= 6) & (row.decile_volume > 1):\n            return 'High Value & High Volume'\n        elif (row.segment_recency == 'Active') & (row.decile_spend >= 6) & (row.decile_volume == 1):\n            return 'High Value & Low Volume'\n        elif (row.segment_recency == 'Active') & (row.decile_spend < 6) & (row.decile_volume > 1):\n            return 'Low Value & High Volume'\n        elif (row.segment_recency == 'Active') & (row.decile_spend < 6) & (row.decile_volume == 1):\n            return 'Low Value & Low Volume'\n        elif (row.segment_recency == 'Inactive') & (row.decile_spend >= 6):\n            return 'High Value'\n        elif (row.segment_recency == 'Inactive') & (row.decile_spend < 6):\n            return 'Low Value'\n        \n    if typeof == \"final\":\n        if (row.segment_recency == 'Lapsed'):\n            return 'Lapsed'\n        elif (row.segment_recency == 'Inactive') & (row.segment_value == 'Low Value'):\n            return 'Lower priority activation'\n        elif (row.segment_recency == 'Inactive') & (row.segment_value == 'High Value'):\n            return 'Prioritise activation'\n        elif (row.segment_recency == 'Active') & (row.segment_value == 'Low Value & Low Volume'):\n            return 'Low value'\n        elif (row.segment_recency == 'Active') & (row.segment_value == 'Low Value & High Volume'):\n            return 'Increase value'\n        elif (row.segment_recency == 'Active') & (row.segment_value == 'High Value & Low Volume'):\n            return 'Increase volume'\n        elif (row.segment_recency == 'Active') & (row.segment_value == 'High Value & High Volume'):\n            return 'Flagship'          \n\n\ndef f_segmentation(df):\n    '''This function segments customers'''\n    \n    # ------ Create Unique Customers ------\n        \n    df_segmentation = df[['customer_unique_id']].drop_duplicates() # Store unique customers\n    \n    # ------ Dates of Interest ------     \n      \n    v_maxdate = df.order_date.max() # Identify Max Purchase Date        \n    v_lydate = pd.to_datetime(v_maxdate - pd.DateOffset(years=1)) # Identify a year ago\n    \n    # ------ Recency Classification ------        \n\n    # Identify Max Purchase Date Per Customer\n    df_recency = df.groupby('customer_unique_id')['order_date'].max().reset_index()\n    df_recency['recency_days'] = (v_maxdate - df_recency['order_date']).dt.days\n    df_recency['segment_recency'] = np.where(df_recency['recency_days'] < 182, 'Active', \n                                             np.where(df_recency['recency_days'] <= 365, 'Inactive', 'Lapsed')) \n    \n    # Join recency to segmentation dataframe\n    df_segmentation = pd.merge(df_segmentation, df_recency, on=\"customer_unique_id\", how=\"left\")\n    \n    # ------ Value Classification ------   \n\n    # Calculate the spend and volume for each customer\n    df_value = df.copy()\n    df_value['date_flag'] = df_value['order_date'] > v_lydate\n    df_value['date_flag'] = df_value['date_flag'].astype('int64')\n    df_value['spend'] = df_value['spend'] * df_value['date_flag']\n    df_value['basket_size'] = df_value['basket_size'] * df_value['date_flag']\n    df_value = df_value.groupby('customer_unique_id').agg({'spend':'sum', 'basket_size':'sum'}).reset_index()\n    df_value.rename(columns = {'basket_size':'volume'}, inplace=True)\n    df_value = pd.merge(df_value, df_recency, on=\"customer_unique_id\", how=\"left\")\n\n    # Filter customers as active\/ inactive\n    df_value = df_value[(df_value.segment_recency.isin(['Active', 'Inactive']))]\n    \n    # Calculate deciles and value segments\n    df_value['decile_spend'] = pd.qcut(df_value.spend, 10, duplicates='drop', labels=np.arange(1, 11, 1)).astype('int')\n    df_value['decile_volume'] = pd.qcut(df_value.volume, 2, duplicates='drop', labels=np.arange(1, 3, 1)).astype('int')   \n    df_value['segment_value'] = df_value.apply(f_segment_logic, typeof=\"value\", axis=1)   \n    \n    # Select final rows\n    df_value = df_value[['customer_unique_id','decile_spend','decile_volume','segment_value']]\n    \n    # Join recency to segmentation dataframe\n    df_segmentation = pd.merge(df_segmentation, df_value, on=\"customer_unique_id\", how=\"left\").drop(columns=['order_date'])\n    \n    # ------ Final Classification ------ \n    \n    # Score segments\n    df_segmentation['segment'] = df_segmentation.apply(f_segment_logic, typeof=\"final\", axis=1)\n    \n    return df_segmentation","1772e01e":"# Score customers on full dataset\ndf_segmentation = f_segmentation(df_modelling)\n\n# Segmentation Order\nv_segment_order = ['Flagship','Increase volume','Increase value','Low value',\n                   'Prioritise activation','Lower priority activation','Lapsed']\n\n# Plot Segment membership\nplt.figure(figsize=(16,6))\nax = sns.countplot(data=df_segmentation, x='segment', order = v_segment_order)\nplt.title(\"Customers within each Value Segment\")\nplt.xlabel(\"Value Segment\")\nplt.ylabel(\"Number of Customers\")\nplt.show()","62a14b5f":"# Load products dataset\ndf_products = pd.merge(pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_products_dataset.csv\")[['product_id','product_category_name']],\n                       pd.read_csv(\"..\/input\/brazilian-ecommerce\/product_category_name_translation.csv\"),\n                       on=\"product_category_name\",\n                       how=\"left\")","ac2a49d0":"# ----- Create summary df with product prices for each item and customer segments\n\n# Add segments to the customer id\ndf_temp = pd.merge(df_customers[['customer_unique_id', 'customer_id']], \n                   df_segmentation[['customer_unique_id', 'segment']],\n                   on=\"customer_unique_id\",\n                   how=\"left\")\n\n# Get the order id\ndf_temp = pd.merge(df_orders[['order_id','customer_id']],\n                   df_temp,\n                   on=\"customer_id\",\n                   how=\"left\")\n\n# Pull product prices\ndf_temp = pd.merge(df_items[['order_id', 'product_id', 'price']],\n                   df_temp,\n                   on=\"order_id\",\n                   how=\"left\")\n\n# Get product names                       \ndf_temp = pd.merge(df_products[['product_id','product_category_name_english']],\n                   df_temp,\n                   on=\"product_id\",\n                   how=\"left\").rename(columns={'product_category_name_english':'category'})\n\n# Select products\ndf_temp = df_temp[['customer_unique_id','segment','category','price']]\n\n# -------- Plotting\nplt.figure(figsize=(16,6))\nax = sns.boxplot(data=df_temp, x='segment',y='price', order = v_segment_order, showfliers=False)\nplt.title(\"Distribution of Product Prices by Value Segmentation\")\nplt.xlabel(\"Value Segments\")\nplt.ylabel(\"Product Prices\")\nplt.show()\n\n# Clear objects\ndel ax, df_temp","eb4d66a3":"# Create a dictionary to order segments\ncustom_dict = {'Flagship': 0, 'Increase volume': 1, 'Increase value': 2, 'Low value': 3, 'Prioritise activation': 4, \n               'Lower priority activation': 5, 'Lapsed': 6}\n\n# Calculate the percentage of orders by each segment\ndf_category = pd.merge(df_items, df_products, on=\"product_id\", how=\"left\")[['order_id', 'product_category_name_english']]\ndf_category = df_category.groupby('product_category_name_english').agg({'order_id':'nunique'}).reset_index()\ndf_category.rename(columns={'product_category_name_english':'category', 'order_id':'orders'}, inplace=True)\ndf_category['pct'] = df_category['orders'] \/ sum(df_category['orders'])\n\n# Calculate the proportion of orders by purchase category for each segment\ndf_category_segment = pd.merge(df_customers[['customer_unique_id', 'customer_id']], \n                               df_segmentation[['customer_unique_id', 'segment']],\n                               on=\"customer_unique_id\",\n                               how=\"left\") # identify customer id\ndf_category_segment = pd.merge(df_orders[['order_id','customer_id']],\n                               df_category_segment,\n                               on=\"customer_id\",\n                               how=\"left\") # Get the order id\ndf_category_segment = pd.merge(df_items[['order_id', 'product_id']],\n                               df_category_segment,\n                               on=\"order_id\",\n                               how=\"left\") # Pull products\ndf_category_segment = pd.merge(df_products[['product_id','product_category_name_english']],\n                               df_category_segment,\n                               on=\"product_id\",\n                               how=\"left\").rename(columns={'product_category_name_english':'category'}) # Get product names          \ndf_category_segment = df_category_segment[['order_id','segment','category']] # Select products\ndf_category_segment = df_category_segment.groupby(['segment','category']).agg({'order_id':'count'}).reset_index() # count orders\ndf_category_segment.rename(columns={'order_id':'orders_segment'}, inplace=True) # rename\ndf_category_segment['pct_segment'] = df_category_segment['orders_segment']\ndf_category_segment = df_category_segment.set_index(['segment', 'category','orders_segment']) # set Index\ndf_category_segment = df_category_segment.groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum())).reset_index()\n\n# Join with overall orders\ndf_category_segment = pd.merge(df_category_segment,\n                               df_category,\n                              on=\"category\",\n                              how=\"left\")\n\n# Calculate Index\ndf_category_segment['idx'] = df_category_segment['pct_segment'] \/ df_category_segment['pct']\n\n# Filter for top indicies\ndf_category_segment = df_category_segment.sort_values(['segment','idx'],ascending=False).groupby('segment').head(3)\n\n# Plot index\nfig, ax=plt.subplots(1,7,figsize=(22, 6))\ncount = 0\nfor seg in v_segment_order:\n    df_temp = df_category_segment[df_category_segment.segment == seg]\n    sns.barplot(data = df_temp,x='category',y='idx', ax=ax[count])\n    plt.setp(ax[count].xaxis.get_majorticklabels(), rotation=90)\n    ax[count].set(ylim=(0, 1100))\n    ax[count].set_title(seg)\n    count += 1\nfig.suptitle(\"Top Product Categories Index by Segment\", fontsize=16)    \nplt.setp(ax[:], ylabel='')    \nplt.setp(ax[0], ylabel='Index')  \nplt.setp(ax[:], xlabel='') \nplt.show()\n\n# clear objects\ndel custom_dict, df_category, df_category_segment, fig, ax, count, seg, df_temp","e22bcc29":"A sample of rows from the customer table can be seen in the print out below, we can see that five fields relate to a customer id and the location where the customer lives in various levels of aggregation. It is worth noting that the field 'customer_unique_id' actually represents the individual customer while the 'customer_id' field is used to join to the order table, in which there is a unique customer value for each order. ","340557b2":"The next step is to have a quick health check of our new merged dataframe. The output below shows that column's spend and basket_size have missing data. Unfortunately, dropping these observations would mean that some customers are not scored or not accurately scored within our segmentation modelling. A slightly different approach will need to be included in our workflow.","eb183304":"The plot below provides some guidance on which product categories each value segment over index on. We can interpret the index as the ratio of category proportions within segment vs the overall purchase behavior. As such we can interpret customers in the flagship segment to have a higher association with 'signaling and security' and 'construction_tools_lights'. The segment Increase value has the highest index values, this is because of the small number of customers in the group.","eec73be6":"<a id=\"section-three-subsection-four\"><\/a>\n### Phase 4: Create Tenure Segmentation\n\nFrom a strategic perspective, we might want to consider customers differently based on their tenure. As an example, we might have new customers on a welcome journey, framing communication and interactions in a different way to a longer standing customer. \nFor this reason it would be good to include tenure in our segmentation, unfortunately, Olist haven't provided a customer registration date to allow us to do this, so we will not be able to include this in our modelling.","a99e79c4":"<a id=\"section-four\"><\/a>\n## Exploring Value Segments\n\nAs our segments are built around the concept of value, they don't provide intuition to what traits and attributes are associated with the customer groups.\n\nThe plot below looks at the range of prices associated with each segment, we can see that segment 2 ('Increase volume') have the highest distribution of product prices and in line with our ruling, we want to encourage this group to purchase more frequently. Segment 5 ('Prioritise activation') has the second highest price range of products purchased, this demonstrates that these customers were typically buying higher priced products but for some reason there has been a lapse in ordering making them become inactive. Segment 3 ('Increase value') are typically drawn to very low priced products relative to other segments.","d2d1b7e2":"<a id=\"section-three-subsection-six\"><\/a>\n### Phase 6: Final Value Segmentation\n\nNow that we have all the components that we need, we can put it all together and create our final value segmentation. We will end up with 7 segments, which will be a mixture of recency and value. The labels for the segments (seen below) are choosen to represent actions which can be focussed on\n\nSegments:\n\n1. Flagship\n1. Increase volume\n1. Increase value\n1. Low value\n1. Prioritise activation\n1. Lower priority activation\n1. Lapsed\n\nThe plot below shows the number of customers which have been allocated to each segment. We can see the membership numbers differ drastically between the segments, with lapsed and inactive customers accounting for large proportions of the customer base.","29b21bd8":"<a id=\"section-three\"><\/a>\n## Segmentation\n\nDeveloping a value segmentation is broken into multiple phases, in each step the idea is to gain insight into specific purchase habits of the customer base, which in turn supports reasoning for different categorisation logic.","88084b53":"<a id=\"section-three-subsection-five\"><\/a>\n### Phase 5: Understand Customer's Spend & Volume\n\nIn this section, we focus on active and inactive customers and use their annual spend and transaction volume to split them into groups.\n\nWe will finish with six segments which summarise customer spend and volume, the active customers will be split into 4 groups, while the inactive customers will be split into two groups.\n\nActive Customers:\n* High Value & High Volume\n* High Value & Low Volume\n* Low Value & High Volume\n* Low Value & Low Volume\n\nInactive Customers:\n* High Value\n* Low Value\n\nA simple percentile approach will be taken here, as there is a wide range of values, these will be broken into deciles, while the volume will be broken into two groups single purchase\/ item being the first or more than one purchase\/ basket.","063b24e3":"A sample of rows from the payments table can be seen below, we can see that it links to the orders table with the 'order_id' then provides information about the number of payment installments, order value and how the customer paid.","9db7d616":"The table below shows a sample of rows from the orders table, it captures a unique reference for the order and a link to the customer table. We also can see the order status and a series of timestamps relating to when the order was purchased, approved and delivery information.","15669c3e":"The plot below shows the mean order value for baskets sizes 1 to 7 and we can see a general trend that the order value increases linearly as the basket size increases by increments of 1. We can use this relationship as a simple imputing method to convert the spend values to a basket size and fill in the missing data. \n\nNow that we have a healthy dataset, we can begin to explore patterns and create a segmentation model.","2c665564":"The chart above shows the number of customers within each segment for both active and inactive customers. Firstly focussing on the active customers, we can see that most customers are low value and low volume. This is then followed by customers with a high value but low volume. We can take from this plot, that most customers actually order infrequently and\/ or only buy single items at a time. Now focussing on the inactive customers we can see that they are split almost 50\/50 between high and low value.\n\nThe plot below shows the average lifetime spend per customer for each of the segments. This provides a little context as to why this categorisation is important, on the inactive customer side we can see which customers typically are of high value. The active customers, we see a decline in the average lifetime spend as we move down the segments.","e93df752":"# Customer Science Part 1: Value Segmentation\n![](https:\/\/storage.googleapis.com\/kaggle-datasets-images\/55151\/105464\/d59245a7014a35a35cc7f7b721de4dae\/dataset-cover.png?t=2018-09-21-16-21-21)","8ffe7226":"A sample of rows from the final table (items) can be seen below, we can see that it holds information relating to the product id and seller id as well as price and frieght costs.","ada58d13":"<a id=\"section-two\"><\/a>\n## Data Reference\n\nIn this section, we familiarise ourselves with the data before progressing into developing a segmentation model.\n\nFirstly we see that the shape of the dataframes:\n* Customer dataframe has 99k rows with 5 columns\n* Order dataframe has 99k rows with 8 columns\n* Payments dataframe has 104k rows with 5 columns\n* Items dataframe has 113k rows with 7 columns","3041337c":"Firstly, focussing on the single order which doesn't have spend information, the first table below shows the order. We can see for this order that the 'basket_size' has been calculated and as such we can potentially grab the spend for the order from the items table. Within the items table the sum of the price and freight_value have been summed and is calculated as 143.46. This has then been added to the missing observation within the modelling table (second table below).","c297f2ad":"<a id=\"section-three-subsection-one\"><\/a>\n### Phase 1: Understand Lifetime Purchase Behaviour\n\nThe green bars in the plot below show the proportion of customers which have made different numbers of orders historically. We can see that all customers have made an order historically and that over 96% have only made 1 order. The red line in the plot refers to the transition rate between historic order sizes and can be thought of as the proportion of customers which move from order size x to order size x+1. With this understanding, we can infer that as a customer makes more orders they have a higher chance of ordering again.","342d595a":"<a id=\"section-three-subsection-three\"><\/a>\n### Phase 3: Create Recency Segmentation\n\nWe can now segment Olist's customer base usng the 6 month cut-off point identified in the previous section. As we are using a historical subset of the data, we will assume that \"today\" relates to the maximum date in database which is 17th October 2018. We will compare the last order date for each customer with our proxy today date and then categorise the customer into one of three categories:\n\n* Active\n* Inactive\n* Lapsed\n\nThe benchmarks for inactive will be a customer who hasn't purchased in the last 6 - 12 months, while Lapsed will be a customer who hasn't purchased in more than 12 months.\n\nThe plot below shows the number of customer within each recency segment as well as the distribution of recency days within each segment. We can see that there are roughly the same amount of customers considered active and lapsed, with the majority of customers being classified as inactive.","03a22407":"## Introduction\n\nThis notebook is the first of two notebooks to demonstrate a range of analytical and data science approaches which can be applied to typical operational and experiential data. Olist (a Brazillian ecommerce marketplace) have graciously shared 100k orders from 2016 - 2018, with information on customers, suppliers, products and reviews. It is worth noting that the underlying reason for this notebook series, is to help me develop my programming skills in python as I have decided to take the plunge and switch from R (or at least add python to my tool box).\n\nThis notebook will focus on strategic value segmentation, an old but gold approach which helps a business to understand which customers are driving value and how. This technique makes use of the marketing metrics recency, frequency and value to categorise customers into a number of small groups which can then be used as a bedrock for other business activities such as a communication strategy.\n\nThis notebook will be split into the following sections:\n\n1. [Prepare Environment](#section-one)\n1. [Data Reference](#section-two)\n1. [Segmentation](#section-three)\n    - [Phase 1: Understand Liftime Purchase Behaviour](#section-three-subsection-one)\n    - [Phase 2: Understand Intervals between Purchase](#section-three-subsection-two)\n    - [Phase 3: Create Recency Segmentation](#section-three-subsection-three)\n    - [Phase 4: Create Tenure Segmentation](#section-three-subsection-four)\n    - [Phase 5: Understand Customer's Spend & Volume](#section-three-subsection-five)\n    - [Phase 6: Final Value Segmentation](#section-three-subsection-six)\n1. [Exploring Value Segments](#section-four)\n1. [Conclusion](#section-five)","8d8ae979":"<a id=\"section-five\"><\/a>\n## Conclusion\n\nSegmentation is a vital tool in business and can be seen as a preliminary step to understanding customers and introducing a degree of personalisation when interacting with them. From a marketing communications perspective, value segmentation can allow a business to phrase communications appropriately, e.g. re-activating customers.","7a03bf52":"Unfortunately, we cannot derive the information from additional tables when considering the missing basket size. Instead, we can see if we can use a simple linear imputer, based on the mean spend per basket size. The output below shows that the vast majority of orders are 7 or below and we probably don't want to include basket sizes above 7 given low sample sizes.","b9db7316":"<a id=\"section-one\"><\/a>\n## Preparing Environment\n\nIn this section we prepare the environment for analysis which includes loading libraries for functionality and data to work with. \n\nThe following packages are used in this analysis:\n\n1. Numpy: Numerical computing\n1. Pandas: Dataframes\n1. Matplotlib: General visualisations\n1. Seaborn: Statistical visualisations\n1. Statsmodel: Linear Imputing\n1. Sklearn: Modelling framework\n\nWith regards to loading data, 'Olist' provides 9 files pertaining to different orders. Only the following .csv files will be loaded:\n\n1. olist_customers_dataset: Identifies customers as well as some geographical information\n1. olist_orders_dataset: Provides information on individual orders and links to which customer\n1. olist_order_payments_dataset: Information on the order value, how the customer paid and in how many installments\n1. olist_order_items_dataset: Information regarding the order, such as items and individual product prices\n\nThe image below shows the Olist database schema:\n\n![](https:\/\/i.imgur.com\/HRhd2Y0.png)\n\nThe final note is that a ggplot styling will be used (can't fully abandon R now can I).","462a2107":"<a id=\"section-three-subsection-two\"><\/a>\n### Phase 2: Understand Intervals between Purchase\n\nIn the next phase, we want to be able to establish a cut off point for a recent order\/ purchase. To do this we need to have some indication of how far back we should consider. One approach we can use is to understand the distribution of days between purchases for customers who have made multiple purchases. The boxplot below shows that the majority of customers who repurchase order leave between 22 and 168 days to do so. The vast majority of customers will purchase within 400 days with there being a few extreme cases which are over 600 days. The upper quartile suggests that there is a rough interval of 170 days which sits between 5 and 6 months. Using the upper bound of that interval, we can have this as our cut-off point for recency, ultimately any purchase within 6 months (182 days) will be considered as a recent purchase.","54f75236":"Now that we have an understanding of the datasets, a single dataframe will be created which houses all the information of interest. This dataframe simply identifies which customers made an order and for each order when it was made, how much was spent and what the basket size (i.e. how many items purchased). A summary of this table can be seen below."}}