{"cell_type":{"cf85a30f":"code","91ed68d2":"code","90189e14":"code","366bc2c0":"code","d40295b9":"code","fbc855fd":"code","a1f991cb":"code","8136aff4":"code","41e6bb84":"code","4e5a3be0":"code","b2d2f95e":"code","8111128a":"code","58cc3716":"code","287c6b6e":"code","2ffbb073":"code","b390686f":"code","aa9a3173":"code","2758ae72":"code","2be18ba7":"code","daaf429f":"code","a0d6f19b":"markdown","193c4394":"markdown","fb499140":"markdown"},"source":{"cf85a30f":"# !pip install --upgrade scikit-image\n# !pip install tqdm\n!pip install tensorflow==1.15.0\n!pip install keras==2.0.0\n","91ed68d2":"!git clone https:\/\/github.com\/Tony607\/efficientnet_keras_transfer_learning\n%cd efficientnet_keras_transfer_learning\/","90189e14":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\n\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization,AveragePooling2D\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,ResNet50\n\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom efficientnet import EfficientNetB0 as Net\nfrom efficientnet import center_crop_and_resize, preprocess_input","366bc2c0":"train_dir='..\/..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TRAIN'\nvalidation_dir='..\/..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST'\nheight=200\nwidth=200\nbatch_size=1\nepochs=10\nNUM_TRAIN=50\nNUM_TEST=50\ninput_shape=(200,200,3)\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input\n                                   \n        \n)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator()\n\n# define the ImageNet mean subtraction (in RGB order) and set the\n# the mean subtraction value for each of the data augmentation\n# objects\nmean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\ntrain_datagen.mean = mean\ntest_datagen.mean = mean\n\ntrain_generator = train_datagen.flow_from_directory(\n    # This is the target directory\n    train_dir,\n    # All images will be resized to target height and width.\n    target_size=(height, width),\n    batch_size=batch_size,\n    color_mode=\"rgb\",\n    # Since we use categorical_crossentropy loss, we need categorical labels\n    class_mode=\"categorical\",\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(height, width),\n    batch_size=batch_size,\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n)\n\n\n","d40295b9":"from tensorflow.keras.constraints import max_norm\n# loading pretrained conv base model\nconv_base = Net(weights=\"imagenet\", include_top=False, input_shape=input_shape)\nheadModel = conv_base.output\nheadModel = GlobalAveragePooling2D()(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = BatchNormalization()(headModel)\nheadModel = Dense(256, activation=\"relu\", kernel_constraint=max_norm(3), bias_constraint=max_norm(3))(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(4, activation=\"sigmoid\", kernel_constraint=max_norm(3), bias_constraint=max_norm(3))(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = models.Model(inputs=conv_base.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the training process\nfor layer in conv_base.layers:\n    layer.trainable = False\n# compile the model\nopt = optimizers.SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n","fbc855fd":"\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=NUM_TRAIN \/\/ batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=NUM_TEST \/\/ batch_size,\n    verbose=1\n)","a1f991cb":"predictions = model.predict_generator(\n    validation_generator,\n    steps=validation_generator.n \/ validation_generator.batch_size,\n    verbose=1)","8136aff4":"y_pred = np.argmax(predictions, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['altogrado', 'ascus', 'bajogrado','benigna']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))","41e6bb84":"baseModel = ResNet50(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=input_shape))","4e5a3be0":"from tensorflow.keras.constraints import max_norm\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = BatchNormalization()(headModel)\nheadModel = Dense(4, activation=\"sigmoid\", kernel_constraint=max_norm(3), bias_constraint=max_norm(3))(headModel)\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = models.Model(inputs=baseModel.input, outputs=headModel)\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the training process\n\nfor layer in baseModel.layers:\n    layer.trainable = False\n    \n    if layer.name.startswith('bn'):\n        layer.call(layer.input, training=False)\n# compile the model\nopt = optimizers.SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])   \n    ","b2d2f95e":"es_callback = EarlyStopping(monitor='val_loss', patience=5)\nhistory = model.fit_generator( train_generator,\n                            steps_per_epoch=NUM_TRAIN \/\/ batch_size,\n                            epochs=epochs,\n                            validation_data=validation_generator,\n                            validation_steps=NUM_TEST \/\/ batch_size,\n                            verbose=1,callbacks=[es_callback]\n                        )","8111128a":"predictions = model.predict_generator(\n    validation_generator,\n    steps=validation_generator.n \/ validation_generator.batch_size,\n    verbose=1)","58cc3716":"y_pred = np.argmax(predictions, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['altogrado', 'ascus', 'bajogrado','benigna']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))","287c6b6e":"base_model = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\nadd_model = models.Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(1, activation='sigmoid'))\n\nmodel = models.Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","2ffbb073":"validation_generator.classes=np.where(validation_generator.classes==3,1,0)\ntrain_generator.classes=np.where(train_generator.classes==3,1,0)\nvalidation_generator.class_mode='binary'\ntrain_generator.class_mode='binary'","b390686f":"train_generator.class_indices={'EOSINOPHIL': 0, 'LYMPHOCYTE': 0, 'MONOCYTE': 0, 'NEUTROPHIL': 1}\nvalidation_generator.class_indices={'EOSINOPHIL': 0, 'LYMPHOCYTE': 0, 'MONOCYTE': 0, 'NEUTROPHIL': 1}","aa9a3173":"train_generator.num_classes=2\nvalidation_generator.num_classes=2\n","2758ae72":"history = model.fit_generator( train_generator,\n                            steps_per_epoch=NUM_TRAIN \/\/ batch_size,\n                            epochs=1,\n                            validation_data=validation_generator,\n                            validation_steps=NUM_TEST \/\/ batch_size,\n                            verbose=1,\n                            use_multiprocessing=True,\n                            workers=4,\n                        )","2be18ba7":"predictions = model.predict_generator(\n    validation_generator,\n    steps=validation_generator.n \/ validation_generator.batch_size,\n    verbose=1)","daaf429f":"y_pred = np.argmax(predictions, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['altogrado', 'ascus', 'bajogrado','benigna']\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names))","a0d6f19b":"## ResNet ","193c4394":"### Using EfficientNet EfficientNetB0","fb499140":"### vgg16 binary classifier"}}