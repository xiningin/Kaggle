{"cell_type":{"de2fda9b":"code","96203f4b":"code","061544b0":"code","7ac4445d":"code","c6b10868":"code","604b1520":"code","ed5cb652":"code","8dd1623f":"code","37a72ac8":"markdown","ac7b1560":"markdown","438f2e7a":"markdown"},"source":{"de2fda9b":"import numpy as np \nimport pandas as pd\nimport h5py\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import RepeatedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils.np_utils import to_categorical,normalize","96203f4b":"!pip install imutils","061544b0":"# Input data files are available in the read-only \"..\/input\/\" directory\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7ac4445d":"f = h5py.File('\/kaggle\/input\/mnistsynthetic\/MNIST_synthetic.h5', 'r')\nlist(f.keys())","c6b10868":"# Load in data from h5py format\nX_train = f['train_dataset'].value\nX_test = f['test_dataset'].value\ny_train = f['train_labels'].value\n\n# Reduce certain channels (see below image); idk if this does anything\nX_train = np.where(X_train<100, 0, X_train)\nX_test = np.where(X_test<100, 0, X_test)\n\n\nprint(\"Train shape:\", X_train.shape)\nprint(\"Test shape:\", X_test.shape)\nprint(\"Train labels shape:\", y_train.shape)","604b1520":"import cv2\nimport imutils\n# print(cv2.__version__) # 4.4.0\n\n##### DIGIT EXTRACTION PARAMETERS #####\n# We can tweak these (using grid search or something)\n\nthreshold = 50    # binary threshold; pixels above this value are set to white, else set to black\nmin_digit_width = 5  # number of pixels wide a contour box must be to be detected as a digit\nmin_digit_height = 5  # number of pixels tall a contour box must be to be detected as a digit\nmax_digit_width = 30\nmax_digit_height = 30\n\nallDigitWindows = []   # holds the windows containing digits (in black & white)\n\nfor i, img in enumerate(X_train):\n        # threshold the image to only black (non-digit) or white (digit)\n    _, t_img = cv2.threshold(img.copy(), threshold, 255, cv2.THRESH_BINARY) # pixels above `threshold` are set to 255 (white), otherwise set to black\n    # ^ the first return is not needed, unless we use Otsu's binarization (for bimodal images)\n    digitBoxes = t_img.copy()\n\n    # find contours in the thresholded image\n    contours, _ = cv2.findContours(t_img.astype(np.uint8).copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # also try cv2.RETR_TREE for second arg\n\n    # loop over candidates and extract real digits\n    digitWindows = []\n    for c in contours:\n        # compute the bounding box of the contour\n        (x, y, w, h) = cv2.boundingRect(c)\n\n        # if the contour is sufficiently large, decide that it is a digit\n        if w >= min_digit_width and w <= max_digit_width and h >= min_digit_height and h <= max_digit_height:\n            digitWindows.append(np.asarray(t_img[y:y+h, x:x+w]))\n            cv2.rectangle(digitBoxes, (x, y), (x + w, y + h), (130, 130, 255), 1)\n        elif w >= min_digit_width or h >= min_digit_height:\n            digitWindows.append(np.asarray(t_img[y:y+h, x:x+w]))\n\n    # add digitContours to array\n    allDigitWindows.append(digitWindows)\n    \n    #### visualization ####\n    if(len(X_train) % 100*i == 0): # print some of the examples\n        cv.drawContours(t_img, contours, -1, (155,115,150), 3)\n        plt.figure(figsize = (20,20))\n        plt.subplot(131), plt.imshow(img[:,:,0], vmin=0, vmax=255) # original image\n        plt.subplot(132), plt.imshow(t_img, vmin=0, vmax=255) # thresholded image\n        plt.subplot(133), plt.imshow(digitBoxes, vmin=0, vmax=255) # digits identified\n\n        plt.show()\n    ################\n\n\n","ed5cb652":"from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU, ZeroPadding2D,Convolution2D\n\ndef cnn(): \n    # create model\n    model = Sequential()\n    model.add(ZeroPadding2D((1,1),input_shape=(64,64,1)))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.5))\n\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation='softmax'))\n    # Compile\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","8dd1623f":"model = cnn()\nhistory = model.fit(X_train, y_train, batch_size=100, epochs=10, shuffle=False)\npredictions = np.argmax(model.predict(X_test), axis=1)","37a72ac8":"# Reminders\n- ## Run with GPU accelerator or you'll hate yourself (need to verify phone # with kaggle)\n- ## Turn on Internet in order to pip install shit\n\n# So far\n- Tried with a generic CNN on the dataset as is, got around 50% accuracy\n- Digits are demarcated in each individual image, using openCV\n\n# TO DO\n- Get a model trained to identify INDIVIDUAL digits, then find a way to pass in images consisting of MULTIPLE digits (i.e. the original data) to that model, and then concatenate the outputs.\n    - from a friend: \"the output of our neural network is just 1 label, and then we combine multiple labels together\"\n    - my interpretation: each image passes thru the opencv pipeline, each digit is individually run on a prediction model, and then the labels are put together\n- note from a friend: \"don't use cv2 to resize the cropped image, need to resize by a scale\"\n","ac7b1560":"# Model\n\nJust a generic CNN model, from here: https:\/\/github.com\/alexanderhale\/COMP551\/blob\/master\/Project_3\/submission-notebooks\/kaggle_cnn.ipynb","438f2e7a":"# Preprocessing\n\nUse OpenCV to apply a threshold (to reduce signal-to-noise), extract contours, and draw rectangles around digits. Our goal is to make the number of digits extracted from each image AS CLOSE AS POSSIBLE to the actual number (which we must calculate). After, we can throw this all into the CNN.\n\nFrom here: https:\/\/github.com\/alexanderhale\/COMP551\/blob\/master\/Project_3\/submission-notebooks\/digit_localization.ipynb"}}