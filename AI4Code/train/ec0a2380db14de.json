{"cell_type":{"91b20b23":"code","4f86e4fd":"code","fd7d8b78":"code","3cf0960d":"code","27e56737":"code","f53ccfcb":"code","e75cab4e":"code","f0657bd1":"code","77148759":"code","49d15be7":"code","cbdb7934":"code","d20daa97":"markdown","8ee38394":"markdown","701c09c6":"markdown","bc427821":"markdown"},"source":{"91b20b23":"!pip install pyradox","4f86e4fd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nimport tensorflow as tf\nimport cv2\nfrom pyradox import convnets","fd7d8b78":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_all = np.concatenate([x_train, x_test])\ny_all = np.concatenate([y_train, y_test])\n\ndel x_train, y_train, x_test, y_test\nx_all.shape, y_all.shape","3cf0960d":"np.random.seed(19)\n\nfig, ax = plt.subplots(2, 5, figsize=(20, 6))\nfor i, idx in enumerate(np.random.choice(np.arange(70000), size=10)):\n    ax[i\/\/5][i%5].imshow(x_all[idx], cmap='gray')\nfig.suptitle('MNIST Data', fontsize=24);","27e56737":"IMG_SIZE = 64\nnp.random.seed(19)\n\n\nX = np.zeros((70000, IMG_SIZE, IMG_SIZE))\nY = np.zeros((70000, 4))\nfor i, x in tqdm(enumerate(x_all)):\n    resize = np.random.uniform(0.5,1.5)\n    im_size = int(resize*28)\n    y_min = np.random.randint(0, (IMG_SIZE-im_size)-2)\n    x_min = np.random.randint(0, (IMG_SIZE-im_size)-2)\n        \n    X[i, y_min:y_min+im_size, x_min:x_min+im_size] = cv2.resize(x, (im_size, im_size))\n    Y[i] = [x_min, y_min, x_min+im_size, y_min+im_size]\n    \nX = np.expand_dims(1 - X\/255.0, axis=-1)\nY = [tf.keras.utils.to_categorical(y_all), Y\/IMG_SIZE]","f53ccfcb":"np.random.seed(19)\n\nfig, ax = plt.subplots(2, 5, figsize=(20, 6))\nfor i, idx in enumerate(np.random.choice(np.arange(70000), size=10)):\n    ax[i\/\/5][i%5].imshow(cv2.rectangle(np.squeeze(X[idx].copy()), Y[1][idx]*IMG_SIZE, 0), cmap='gray')\nfig.suptitle('Prepared Data', fontsize=24);","e75cab4e":"inp = tf.keras.Input(shape=(64, 64, 1))\nx = tf.keras.layers.Convolution2D(3, 3, padding='same')(inp)\n# x = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')(x)\nx = convnets.MobileNetV3('small')(x)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\ny_clf = tf.keras.layers.Dense(10, activation='softmax', name='clf')(x)\ny_reg = tf.keras.layers.Dense(4, name='reg')(x)\n\nmodel = tf.keras.models.Model(inputs=inp, outputs=[y_clf, y_reg])\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(lr=0.0001), \n    loss={'clf': 'categorical_crossentropy','reg': 'mean_squared_error'}, \n    metrics={'clf': 'acc', 'reg': 'mean_absolute_error'}\n)\nmodel.summary()","f0657bd1":"tf.keras.utils.plot_model(model, expand_nested=True, show_shapes=True)","77148759":"es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001, restore_best_weights=True, verbose=1)\nrlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, min_lr=1e-7, verbose=1)\n\nhistory = model.fit(X, Y, epochs=1000, validation_split=0.1, callbacks=[es, rlp])","49d15be7":"sns.set_style('darkgrid')\nfig, ax = plt.subplots(3, 1, figsize=(20, 15))\nmodel_metrics = pd.DataFrame(history.history)\nmodel_metrics[['loss', 'val_loss', 'clf_loss', 'val_clf_loss', 'reg_loss', 'val_reg_loss']].plot(ax=ax[0])\nmodel_metrics[['clf_acc', 'val_clf_acc']].plot(ax=ax[1])\nmodel_metrics[['reg_mean_absolute_error', 'val_reg_mean_absolute_error']].plot(ax=ax[2])\nax[0].set_title('Model Loss', fontsize=18)\nax[1].set_title('Classification Accuracy', fontsize=18)\nax[2].set_title('Regression MAE', fontsize=18)\nfig.suptitle('Model Performance', fontsize=24);","cbdb7934":"np.random.seed(19)\nsns.reset_orig()\nY_pred = model.predict(X)\nfig, ax = plt.subplots(2, 5, figsize=(20, 6))\nfor i, idx in enumerate(np.random.choice(np.arange(70000), size=10)):\n    ax[i\/\/5][i%5].imshow(cv2.rectangle(np.squeeze(X[idx].copy()), Y_pred[1][idx]*IMG_SIZE, 0), cmap='gray')\n    ax[i\/\/5][i%5].set_title(np.argmax(Y_pred[0][idx]), fontsize=15)\nfig.suptitle('Model Performance', fontsize=24);","d20daa97":"# Evaluation","8ee38394":"# Modelling\nusing Mobile Net V2","701c09c6":"# Dataset","bc427821":"# Data Preparation\n\n* Paste images of handwritten digits on 64x64 blank images after resizing randomly \n* Color invert\n* Rescale the data from 0-255 to 0-1"}}