{"cell_type":{"d78672c1":"code","165e0fdf":"code","0a552545":"code","4deb427e":"code","437e8abe":"code","fc349ca7":"code","1ce2892d":"code","53910732":"code","aaa330da":"code","700d9540":"code","9348effe":"code","e86686c3":"code","b272319b":"code","abbce9f0":"code","04bb801f":"code","e8424bea":"code","02ec2645":"code","7937ba9b":"code","f5009cf1":"code","c7b4bc63":"code","72856e25":"code","abe39ae5":"markdown","7411dba1":"markdown","1d6e3fde":"markdown","a9b16a80":"markdown","a987e47f":"markdown","4a451b86":"markdown","ceb1f426":"markdown","4f51aada":"markdown","e5bdd27a":"markdown","7d5e0c04":"markdown","c9fea04a":"markdown","cb2d5acd":"markdown","d896665a":"markdown","a92532dc":"markdown","c19afce5":"markdown","4a0030ac":"markdown","641c0d58":"markdown"},"source":{"d78672c1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","165e0fdf":"try:\n    df_iris = pd.read_csv('..\/input\/iris\/Iris.csv')\n    print(\"Successfully loaded Iris.csv\")\n    \nexcept Exception as e:\n    print(e)","0a552545":"print(\"Null values in Iris dataset \\n\\n\", df_iris.isnull().sum())","4deb427e":"print(df_iris.head(10))         \n\nprint(\"\\nRows and columns in the Iris dataset : \", df_iris.shape)                 # shows rows and columns","437e8abe":"print(df_iris.info())   # check basic info of the dataset","fc349ca7":"print(\"Iris Statistical Summary \\n\", df_iris.describe())","1ce2892d":"print(\"Distinct Species of Iris are : \",df_iris.Species.unique())\n\nprint(\"\\n\", df_iris.groupby('Species').size())","53910732":"# 4.1 Create Univariate Plots\n\n# box and whisker plot\n\nplt.boxplot([df_iris.SepalLengthCm, df_iris.SepalWidthCm, df_iris.PetalLengthCm, df_iris.PetalWidthCm],\n           labels=['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'])\nplt.show()","aaa330da":"fig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.boxplot(x='Species',y='PetalLengthCm',data=df_iris,\n                order=['Iris-virginica','Iris-versicolor','Iris-setosa'],\n                linewidth=2.5,orient='v',dodge=False)","700d9540":"#scatter plot of Petal Length & Width\n%matplotlib inline\nsns.FacetGrid(df_iris,hue='Species',height=5)\\\n.map(plt.scatter,'SepalLengthCm','SepalWidthCm')\\\n.add_legend()","9348effe":"#scatter plot of Sepal Length & Width\n%matplotlib inline\nsns.FacetGrid(df_iris,hue='Species',height=5)\\\n.map(plt.scatter,'PetalLengthCm','PetalWidthCm')\\\n.add_legend()","e86686c3":" # Consolidated view of the scatter plot of Sepal and Petal - Length & Width\n\nsns.set(style=\"ticks\", color_codes=True)\n#iris = sns.load_dataset(\"iris\")\n%matplotlib inline\n\n#iris = sns.load_dataset(\"iris\")\nsns.pairplot(df_iris.iloc[:,1:6], hue=\"Species\")","b272319b":"df_iris.drop('Id', axis=1, inplace=True)\nprint(df_iris.columns)","abbce9f0":"plt.figure(figsize=(7,4)) \nsns.heatmap(df_iris.corr(),annot=True,cmap='cubehelix_r')    # heatmap of correlation matrix calculted by(iris.corr())\nplt.show()","04bb801f":"X = df_iris.iloc[:,0:4]\ny = df_iris.iloc[:,4]\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)","e8424bea":"print(X_train.shape, X_validation.shape, Y_train.shape, Y_validation.shape)","02ec2645":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))","7937ba9b":"model = SVC(gamma='auto')\nmodel.fit(X_train, Y_train)\npredictions = model.predict(X_validation)\n\nprint(\"Predicted the class of Iris for\",len(predictions), \"records\")","f5009cf1":"# Evaluate predictions\nprint(\"SVM Model accuracy on validation set is : \", accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","c7b4bc63":"X = df_iris.loc[:,['SepalLengthCm','SepalWidthCm', 'PetalWidthCm']]\ny = df_iris.loc[:,'Species']\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n\n\nmodel = SVC(gamma='auto')\nmodel.fit(X_train, Y_train)\npredictions = model.predict(X_validation)\n\nprint(\"SVM Model accuracy on validation set is : \", accuracy_score(Y_validation, predictions))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))\n                   ","72856e25":"#### xgboost\n\nimport xgboost as xgb\n\nxgb_clf = xgb.XGBClassifier()\nxgb_clf = xgb_clf.fit(X_train, Y_train)\n\nprint('Accuracy of xgb classifier is {:.5f} on training data'.format(xgb_clf.score(X_train, Y_train)))\nprint('Accuracy of xgb classifier is {:.5f} on validation data'.format(xgb_clf.score(X_validation, Y_validation)))","abe39ae5":"We drop off the id column, since it adds no value to our analysis","7411dba1":"- 3.4 See the distinct number of Iris Species, which need to be predicted, and their distribution in the dataset","1d6e3fde":"Though the validation acuracy did not improve much, normally the ensemble models provide better results than a single model","a9b16a80":"# 2. Load the csv file in a dataframe","a987e47f":"We will use stratified 10-fold cross validation to estimate model accuracy.\n\nThis will split our dataset into 10 parts, train on 9 and test on 1 and repeat for all combinations of train-test splits.","4a451b86":"* **6.2 Build Model**\n\nLet's try a few simple models\nWe will try to build the below models, and evaluate which one works best\n\n* * Logistic Regression (LR)\n* * Linear Discriminant Analysis (LDA)\n* * K-Nearest Neighbors (KNN).\n* * Classification and Regression Trees (CART).\n* * Gaussian Naive Bayes (NB).\n* * Support Vector Machines (SVM).","ceb1f426":"# 8. Ensemble\n\nTill now, we have evaluated only single models\n\nWe will now try a simple ensemble - xgboost\n","4f51aada":"Now we will to create a model without the highly correlated PetalLengthCm column\n","e5bdd27a":"# 7. Predict\n\n\n* 7.1 Make Predictions\n\nSince SVM has the best accuracy, we will use SVM to do the predictions","7d5e0c04":"The results look quite the same, and we have a simpler model (with lesser attributes)","c9fea04a":"# 6. Modeling\n\n*     6.1 - split dataset into train & validation","cb2d5acd":"    - 3.3 See the statistical summary of the data","d896665a":"\n\n* 7.2 Evaluate the result of prediction","a92532dc":"# 1. Import the necessary libraries","c19afce5":"# 5. Find correlation between columns\n\n**Observation** : \n - SepalLengthCm & SepalWidthCm do not have a high correlation\n - PetalLengthCm & PetalWidthCm have a very high correlation\n - PetalLengthCm & SepalLengthCm also have a high correlation\n ","4a0030ac":"# 3. View the dataset\n\n    - 3.1 First few records in the dataset\n    - 3.2 Total number of Rows and Columns loaded\n","641c0d58":"# 4. Visualize the data"}}