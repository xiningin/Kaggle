{"cell_type":{"1c91ad7b":"code","13bb06ef":"code","a257c1a4":"code","6d21abb5":"code","138dd4b2":"code","765306a7":"code","4bd0c49a":"code","925c6781":"code","3d66186c":"code","f2f6555e":"code","8cf3aa70":"code","ca28948e":"code","19ed336e":"code","7bc6eaa0":"code","181da571":"code","34c6c316":"code","002b868c":"code","d886b4ca":"code","2b7ad2f9":"code","f6924379":"code","bef6f5fe":"code","5d82aaa1":"code","1d0c49f7":"code","03da7e55":"code","f229e4dc":"code","cac5ca47":"code","15039b4e":"code","da344e1e":"code","1f09e8a4":"code","50b3be23":"code","25d63bc1":"code","da89c1a0":"code","2da2c6d2":"code","933d3e63":"code","9d82265d":"code","8308f4ea":"code","e1eaf21f":"code","f69c5146":"code","cac767eb":"code","3ee02664":"code","b6e83ec5":"code","9d0c98f7":"code","c20bdcb3":"code","ea17dc97":"code","4c13979e":"code","fe9f260a":"code","099f3c8f":"code","7fc708bb":"code","eaf18d86":"code","96cd94f8":"code","f1ac3b27":"code","e53ddd2b":"code","357ad0ce":"code","6bd198ed":"code","fad6e875":"code","887982ea":"code","a122e309":"code","710c22d2":"code","59348bf9":"code","7b8d9572":"code","a65a89bc":"code","1a9103f5":"code","20729dca":"code","3509f321":"code","d272c961":"code","953f94fd":"code","d91526f5":"code","3010cddd":"code","d9e90e33":"code","652e7bbe":"code","c5543b18":"code","e07b2629":"code","dc72ddd1":"code","ec312fd8":"code","4a907b5f":"code","746f39e0":"code","db7228d1":"code","de1fc3cb":"code","9eb7d29c":"code","85e2e04d":"code","b78c8bcb":"code","86a67cf4":"code","2a2e2b02":"code","2a6682dc":"code","38787654":"code","b4f13241":"code","f62d9493":"code","1abb6be8":"code","eb1efdcb":"code","6f41976b":"code","c4727a7a":"code","ab3f5a89":"code","b727bdd8":"code","e791dfd2":"code","96a1d221":"code","11e91481":"code","14490f04":"code","c7617197":"code","3a9b4027":"markdown","2bf9b426":"markdown","41789764":"markdown","893b3a66":"markdown","a3c18f8d":"markdown","20231604":"markdown","078e7a72":"markdown","ba236144":"markdown","3cff57a1":"markdown","3e01e7b5":"markdown","fab20989":"markdown","cf1a01b9":"markdown","2fe84ade":"markdown","89e698b2":"markdown","98e6f99c":"markdown","21fa92d3":"markdown","4b3d6a92":"markdown","dfb2946e":"markdown","e327e0c8":"markdown","22e43aa7":"markdown","443fafac":"markdown","4013f954":"markdown","837549d2":"markdown","680a48b7":"markdown","bbf0183d":"markdown","7e2f589b":"markdown","b8278c77":"markdown","d35ee23a":"markdown","439dbebc":"markdown","bbb25add":"markdown","9dd4954a":"markdown","b1157abd":"markdown","8a197060":"markdown","55589ecd":"markdown","be230391":"markdown","72bad71d":"markdown","5c1c87c8":"markdown","fc43d019":"markdown","9e1b837d":"markdown","53e1a85a":"markdown","2d573ea5":"markdown","ae8f4f7a":"markdown","0621abdd":"markdown","d5457151":"markdown","16cda6f4":"markdown","14c1f3d3":"markdown","853874c2":"markdown","f3a34875":"markdown"},"source":{"1c91ad7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13bb06ef":"data_US = pd.read_csv(\"\/kaggle\/input\/youtube-new\/USvideos.csv\")","a257c1a4":"data_US.columns","6d21abb5":"data_US.info()","138dd4b2":"data_US.head()","765306a7":"data_US.describe()","4bd0c49a":"population = data_US[\"views\"].copy() # get views of trending youtube videos","925c6781":"population.size","3d66186c":"# sampling\nsampling = population.sample(1000, random_state=203)","f2f6555e":"sampling.size # chosen 1000 random data from population (sampling)","8cf3aa70":"sampling.mean() # average with 1000 random data","ca28948e":"population.mean() # average with 40949 data","19ed336e":"# Sample Distribution\nnp.random.seed(10)\nsampling_1 = np.random.choice(a= population, size=1000)\nsampling_2 = np.random.choice(a= population, size=1000)\nsampling_3 = np.random.choice(a= population, size=1000)\nsampling_4 = np.random.choice(a= population, size=1000)\nsampling_5 = np.random.choice(a= population, size=1000)\nsampling_6 = np.random.choice(a= population, size=1000)\nsampling_7 = np.random.choice(a= population, size=1000)\nsampling_8 = np.random.choice(a= population, size=1000)\nsampling_9 = np.random.choice(a= population, size=1000)\nsampling_10 = np.random.choice(a= population, size=1000)","7bc6eaa0":"#  average with random 10 sampling \n(sampling_1.mean()+sampling_2.mean()+sampling_3.mean()+sampling_4.mean()+sampling_5.mean()+sampling_6.mean()+sampling_7.mean()+sampling_8.mean()+sampling_9.mean()+sampling_10.mean())\/10","181da571":"sampling_5.mean()","34c6c316":"sampling_1.mean()","002b868c":"data_US.describe().T","d886b4ca":"!pip install researchpy as rp\nimport researchpy as rp","2b7ad2f9":"rp.summary_cont(data_US[[\"views\",\"likes\",\"dislikes\",\"comment_count\"]]) # this function is used for continuous variables","f6924379":"rp.summary_cat(data_US[[\"channel_title\"]]) # this function is used for categorical variables","bef6f5fe":"data_US[[\"views\",\"comment_count\"]].cov()","5d82aaa1":"data_US[[\"views\",\"comment_count\"]].corr()","1d0c49f7":"import numpy as np\nrng = np.random.RandomState(15)\nfor i in np.arange(1,21):\n    experiments_num = 2**i\n    heads_tails = rng.randint(0,2, size=experiments_num)\n    heads_probability = np.mean(heads_tails)\n    print(\"Number of Shots:\",experiments_num,\"--->\",\"Heads Probability: %.2f\" %(heads_probability*100))","03da7e55":"likes_population = data_US[\"likes\"].copy() # get likes of trending youtube videos","f229e4dc":"# sampling\nnp.random.seed(50)\nlikes = np.random.choice(a=likes_population, size=1000)\nlikes[0:30]","cac5ca47":"likes.mean()","15039b4e":"import statsmodels.stats.api as sms\nsms.DescrStatsW(likes).tconfint_mean() # confidence interval","da344e1e":"from scipy.stats import bernoulli","1f09e8a4":"# define probability of success \np = 0.6","50b3be23":"rv = bernoulli(p)\nrv.pmf(k=1) # PMF -> Probability Mass Function","25d63bc1":"# get probability mass function\nx = [0,1]\np = 0.6\nprint(\"Probability Mass Function =\", bernoulli.pmf(x,p))","da89c1a0":"# get variance value\nvar = bernoulli.var(p)\nprint(\"Variance = \", var)","2da2c6d2":"from scipy.stats import binom","933d3e63":"p = 0.05\nn = 100\nrv = binom(n,p)\nprint(rv.pmf(1))\nprint(rv.pmf(8))\nprint(rv.pmf(12))","9d82265d":"var = binom.var(n,p)\nprint(\"Variance = \", var)","8308f4ea":"from scipy.stats import poisson","e1eaf21f":"lambda_ = 0.1","f69c5146":"rv = poisson(mu = lambda_)\nprint(rv.pmf(k=0))\nprint(rv.pmf(k=5))\nprint(rv.pmf(k=20))","cac767eb":"from scipy.stats import norm","3ee02664":"# for sd = 4, mean= 105\n1-norm.cdf(110,105,4) # probability of more than 110","b6e83ec5":"1-norm.cdf(100,105,4) # probability of more than 100","9d0c98f7":"norm.cdf(99,105,4) # probability of less than 99","c20bdcb3":"norm.cdf(110,105,4) - norm.cdf(100,105,4) # probability between 85 and 90","ea17dc97":"dislikes_population = data_US[\"dislikes\"].copy() # get dislikes of trending youtube videos","4c13979e":"# sampling\nnp.random.seed(25)\ndislikes = np.random.choice(a=dislikes_population, size=4000)\ndislikes[0:30]","fe9f260a":"import scipy.stats as stats\nstats.describe(dislikes)","099f3c8f":"from scipy.stats import shapiro\nshapiro(dislikes)","7fc708bb":"print(\"T Account Statistics:\"+str(shapiro(dislikes)[0]))\nprint(\"P-value:\"+str(shapiro(dislikes)[1]))","eaf18d86":"# qqplot\nimport pylab\nstats.probplot(dislikes, dist=\"norm\",plot=pylab)\npylab.show()","96cd94f8":"stats.ttest_1samp(dislikes, popmean = 3600)","f1ac3b27":"from statsmodels.stats.descriptivestats import sign_test\ntest_statistics, p_value = sign_test(dislikes,620)\nprint(\"Test Statistics = %.4f, P-value = %.4f\" %(test_statistics,p_value))","e53ddd2b":"from statsmodels.stats.proportion import proportions_ztest","357ad0ce":"count = 82 # number of successful attempts\nnobs = 500 # number of observations\nvalue = 0.2 # the ratio we want to test","6bd198ed":"proportions_ztest(count,nobs,value)","fad6e875":"A = np.random.randint(18,30,40)\nB = np.random.randint(26,39,40)","887982ea":"A = pd.DataFrame(A)\nB = pd.DataFrame(B)","a122e309":"# Type 1\nA_B = pd.concat([A,B],axis=1)\nA_B.columns=[\"A\",\"B\"]\n\nA_B.head()","710c22d2":"# Type 2\nGRUP_A = np.arange(len(A))\nGRUP_A = pd.DataFrame(GRUP_A)\nGRUP_A[:]=\"A\"\nA = pd.concat([A,GRUP_A],axis=1)\n\nGRUP_B = np.arange(len(B))\nGRUP_B = pd.DataFrame(GRUP_B)\nGRUP_B[:]=\"B\"\nB = pd.concat([B,GRUP_B],axis=1)\n\nAB = pd.concat([A,B])\nAB.columns = [\"Value\",\"Group\"]\nprint(AB.head())\nprint(AB.tail())","59348bf9":"import seaborn as sns\nsns.boxplot(x = \"Group\", y = \"Value\", data = AB);","7b8d9572":"# The Assumption(s) of Normality\nfrom scipy.stats import shapiro\n# A\nprint(\"T Account Statistics:\"+str(shapiro(A_B.A)[0]))\nprint(\"P-value:\"+str(shapiro(A_B.A)[1]))","a65a89bc":"# B\nprint(\"T Account Statistics:\"+str(shapiro(A_B.B)[0]))\nprint(\"P-value:\"+str(shapiro(A_B.B)[1]))","1a9103f5":"# Homogeneity of variance\nimport scipy.stats as stats\nstats.levene(A_B.A,A_B.B)","20729dca":"stats.ttest_ind(A_B[\"A\"],A_B[\"B\"], equal_var=True)","3509f321":"stats.mannwhitneyu(A_B[\"A\"],A_B[\"B\"])","d272c961":"C1 = np.random.randint(115,124,40)\nC2 = np.random.randint(120,138,40)","953f94fd":"C1 = pd.DataFrame(C1)\nC2 = pd.DataFrame(C2)","d91526f5":"C1[0:5]","3010cddd":"C2[0:5]","d9e90e33":"# Type 1\nC1_C2 = pd.concat([C1,C2],axis=1)\nC1_C2.columns=[\"C1\",\"C2\"]\n\nC1_C2.head()","652e7bbe":"# Type 2\nGRUP_C1 = np.arange(len(C1))\nGRUP_C1 = pd.DataFrame(GRUP_C1)\nGRUP_C1[:]=\"C1\"\nC1 = pd.concat([C1,GRUP_C1],axis=1)\n\nGRUP_C2 = np.arange(len(C2))\nGRUP_C2 = pd.DataFrame(GRUP_C2)\nGRUP_C2[:]=\"C2\"\nC2 = pd.concat([C2,GRUP_C2],axis=1)\n\nC1C2 = pd.concat([C1,C2])\nC1C2.columns = [\"Value\",\"Group\"]\nprint(C1C2.head())\nprint(C1C2.tail())","c5543b18":"sns.boxplot(x=\"Group\",y=\"Value\", data=C1C2)","e07b2629":"# The Assumption(s) of Normality\nfrom scipy.stats import shapiro\n# C1\nprint(\"T Account Statistics:\"+str(shapiro(C1_C2.C1)[0]))\nprint(\"P-value:\"+str(shapiro(C1_C2.C1)[1]))","dc72ddd1":"# C2\nprint(\"T Account Statistics:\"+str(shapiro(C1_C2.C2)[0]))\nprint(\"P-value:\"+str(shapiro(C1_C2.C2)[1]))","ec312fd8":"# Homogeneity of variance\nimport scipy.stats as stats\nstats.levene(C1_C2.C1,C1_C2.C2)","4a907b5f":"stats.ttest_rel(C1_C2.C1,C1_C2.C2)","746f39e0":"stats.wilcoxon(C1_C2.C1,C1_C2.C2)","db7228d1":"from statsmodels.stats.proportion import proportions_ztest","de1fc3cb":"success_num = np.array([500,450])\nobservations_num = np.array([1500,1600])","9eb7d29c":"proportions_ztest(count=success_num,nobs=observations_num)","85e2e04d":"A = np.random.randint(28,34,40)\nB = np.random.randint(28,36,40) \nC = np.random.randint(35,43,40) ","b78c8bcb":"A = pd.DataFrame(A)\nB = pd.DataFrame(B)\nC = pd.DataFrame(C)","86a67cf4":"dfs=[A,B,C]\n\nABC = pd.concat(dfs,axis=1)\nABC.columns = [\"GROUP_A\",\"GROUP_B\",\"GROUP_C\"]\nABC.head()","2a2e2b02":"# The Assumption(s) of Normality\nfrom scipy.stats import shapiro\n# Group A\nprint(\"T Account Statistics:\"+str(shapiro(ABC[\"GROUP_A\"])[0]))\nprint(\"P-value:\"+str(shapiro(ABC[\"GROUP_A\"])[1]))","2a6682dc":"# Group B\nprint(\"T Account Statistics:\"+str(shapiro(ABC[\"GROUP_B\"])[0]))\nprint(\"P-value:\"+str(shapiro(ABC[\"GROUP_B\"])[1]))","38787654":"# Group C\nprint(\"T Account Statistics:\"+str(shapiro(ABC[\"GROUP_C\"])[0]))\nprint(\"P-value:\"+str(shapiro(ABC[\"GROUP_C\"])[1]))","b4f13241":"# Homogeneity of variance\nstats.levene(ABC[\"GROUP_A\"],ABC[\"GROUP_B\"],ABC[\"GROUP_C\"])","f62d9493":"from scipy.stats import f_oneway\nf_oneway(ABC[\"GROUP_A\"],ABC[\"GROUP_B\"],ABC[\"GROUP_C\"])","1abb6be8":"print(\"{:.5f}\".format(f_oneway(ABC[\"GROUP_A\"],ABC[\"GROUP_B\"],ABC[\"GROUP_C\"])[1]))","eb1efdcb":"ABC.describe().T","6f41976b":"from scipy.stats import kruskal\nkruskal(ABC[\"GROUP_A\"],ABC[\"GROUP_B\"],ABC[\"GROUP_C\"])","c4727a7a":"data = data_US.copy()\ndata.head()","ab3f5a89":"data.plot.scatter(\"views\",\"likes\");","b727bdd8":"from scipy.stats import shapiro\ntest_statistics, p_value = shapiro(data[\"views\"])\nprint(\"Test Statistics = %.4f, P-value = %.4f\" %(test_statistics,p_value))\n\ntest_statistics, p_value = shapiro(data[\"likes\"])\nprint(\"Test Statistics = %.4f, P-value = %.4f\" %(test_statistics,p_value))","e791dfd2":"data[\"views\"].corr(data[\"likes\"], method=\"pearson\") # Pearson correlation coefficient is used when the normality assumption is provided.","96a1d221":"data[\"views\"].corr(data[\"likes\"], method=\"spearman\") # If normality assumption is not provided, Spearman correlation coefficient is used.","11e91481":"from scipy.stats.stats import pearsonr\ntest_statistics, p_value = pearsonr(data[\"views\"],data[\"likes\"])\nprint(\"Test Statistics = %.4f, P-value = %.4f\" %(test_statistics,p_value))","14490f04":"stats.spearmanr(data[\"views\"],data[\"likes\"])","c7617197":"stats.kendalltau(data[\"views\"],data[\"likes\"])","3a9b4027":"### Assumptions\n* The Assumption(s) of Normality\n* Homogeneity of variance","2bf9b426":"<a id='2'><\/a><br>\n# Sampling Theory","41789764":"## Assumptions","893b3a66":"## Assumptions\n* Independent Observations Assumption\n* The Assumption(s) of Normality\n* Homogeneity of variance","a3c18f8d":"* P-Value < 0.05 -> H0 hypothesis is rejected. However, we will perform both the hypothesis test and the one sample nonparametric test, ignoring the p-value.","20231604":"* The probability mass function:\n![image.png](attachment:image.png)","078e7a72":"<a id='11'><\/a><br>\n# Statistical Hypothesis Testing\n\n* Hypothesis testing is a method used to determine the accuracy of a hypothesis within a statistical reliability range.\n* Hypothesis tests are tests that determine whether the difference between a sample mean and the mean value of this sample is significant (ie whether there is a significant difference).\n* If the difference between the averages of the two main masses is tested; It can be understood whether the difference is correct or not by performing hypothesis tests on the averages of the samplings drawn from them. ","ba236144":"* The probability mass function:\n![image.png](attachment:image.png)","3cff57a1":"* P-value < 0.05 ->  H0 hypothesis is rejected. So p is not equal to 0.2. ","3e01e7b5":"## Hypothesis Testing","fab20989":"* The expected value - The variance: \n![image.png](attachment:image.png)","cf1a01b9":"<a id='7'><\/a><br>\n## Bernoulli Distribution\n\nSuppose you perform an experiment with two possible outcomes: either success or failure. Success happens with probability p, while failure happens with probability 1-p.\n","2fe84ade":"* The expected value: \n![image.png](attachment:image.png)","89e698b2":"* The variance:\n![image.png](attachment:image.png)","98e6f99c":"### Assumptions\n* The Assumption(s) of Normality\n* Homogeneity of variance","21fa92d3":"<a id='1'><\/a><br>\n# Load and Check Data","4b3d6a92":"###  One Sample Nonparametric Test\n\nIf the distribution is not normal, nonparametric test is used.","dfb2946e":"<a id='10'><\/a><br>\n## Normal Distribution\n\nThe normal distribution is a probability function that describes how the values of a variable are distributed.\n\n\u03bc - mean or expected value of the distribution.\n\n\u03c3 - standard deviation.\n\n\u03c32 - variance.","e327e0c8":"## Nonparametric Hypothesis Test","22e43aa7":"## Testing the Significance of the Correlation ","443fafac":"* The variance:\n![image.png](attachment:image.png)","4013f954":"### Hypothesis Testing","837549d2":"<a id='14'><\/a><br>\n## Independent Samples T-Test\n\nThe independent t-test, also called the two sample t-test or independent-samples t-test, is an inferential statistical test that determines whether there is a statistically significant difference between the means in two unrelated groups.","680a48b7":"### Probability Mass Function","bbf0183d":"<a id='4'><\/a><br>\n# Law of Large Numbers\n\nIn probability theory, the law of large numbers (LLN) is a theorem that describes the result of performing the same experiment a large number of times. ","7e2f589b":"* The expected value: \n![image.png](attachment:image.png)","b8278c77":"<a id='16'><\/a><br>\n## Two Proportion Z-Test\n\nIt is used to test between two ratios.","d35ee23a":"<a id='8'><\/a><br>\n## Binomial Distribution\n\nIt describes the outcome of binary scenarios, e.g. toss of a coin, it will either be head or tails.\n\nn - number of trials.\n\np - probability of occurrence of each trial. \n\nk - requested number.","439dbebc":"* The probability mass function:\n![image.png](attachment:image.png)\n","bbb25add":"<a id='12'><\/a><br>\n## One Sample T-Test\n\nThe One Sample T Test determines whether the sample mean is statistically different from a known or hypothesized population mean. The One Sample T Test is a parametric test.\n\n\n**Hypotheses:**\n\nH0: \u03bc = 50\n\nH1: \u03bc \u2260 50\n\n\nH0: \u03bc <= 50\n\nH1: \u03bc > 50\n\n\nH0: \u03bc >= 50\n\nH1: \u03bc < 50","9dd4954a":"#### Shapiro-Wilk Test\n\nH0: There is no statistically significant difference between sample distribution and theoretical normal distribution.\n\nH1: There is a statistically significant difference between sample distribution and theoretical normal distribution.","b1157abd":"<a id='18'><\/a><br>\n# Correlation Analysis\n\nCorrelation analysis is a statistical method used to evaluate the strength of relationship between two quantitative variables.","8a197060":"<a id='17'><\/a><br>\n# Analysis of Variance\n\nAnalysis of variance (ANOVA) is a collection of statistical models and their associated estimation procedures used to analyze the differences among group means in a sample.\n\nH0: M1 = M2 = M3 (There is no statistically significant difference between group averages.)\n\nH1: There is statistically significant difference between group averages. (at least one is different)","55589ecd":"### Hypothesis Testing\nH0: The average number of dislikes is 3600 \n\nH1: the average number of dislikes is not 3600","be230391":"<a id='6'><\/a><br>\n# Probability Distribution","72bad71d":"* The probability mass function:\n![image.png](attachment:image.png)","5c1c87c8":"## Hypothesis Testing","fc43d019":"<a id='13'><\/a><br>\n## One Proportion Z-Test\n\nUsed when trying to test a proportional expression.\n\nHO: p = 0.2\n\nH1: p != 0.2","9e1b837d":"<a id='9'><\/a><br>\n## Poisson Distribution\n\nThe Poisson distribution is the discrete probability distribution of the number of events occurring in a given time period, given the average number of times the event occurs over that time period.\n\n","53e1a85a":"<a id='3'><\/a><br>\n# Descriptive Statistics","2d573ea5":"### Hypothesis Testing","ae8f4f7a":"# Introduction\n\nThis notebook covers the uses of basic statistics for data science in Python.\n\n<font color= '#000091'>\n<b> \ud83d\udccc Content: <\/b>\n\n1. [Load and Check Data](#1)\n1. [Sampling Theory](#2)\n1. [Descriptive Statistics](#3)\n1. [Law of Large Numbers](#4)\n1. [Confidence Interval](#5)\n1. [Probability Distribution](#6) \n    * [Bernoulli Distribution](#7)\n    * [Binomial Distribution](#8)\n    * [Poisson Distribution](#9)\n    * [Normal Distribution](#10)\n1. [Statistical Hypothesis Testing](#11) \n    * [One Sample T-Test](#12)\n    * [One Proportion Z-Test](#13)\n    * [Independent Samples T-Test](#14)\n    * [Dependent Samples T-Test](#15)\n    * [Two Proportion Z-Test](#16)\n1. [Analysis of Variance (ANOVA)](#17) \n1. [Correlation Analysis](#18) ","0621abdd":"### Assumption\n* The Assumption of One Sample T-Test: The Assumption(s) of Normality","d5457151":"<a id='15'><\/a><br>\n## Dependent Samples T-Test\n\nThe dependent samples t-test (called the paired-samples t-test) compares the means between two related groups on the same continuous, dependent variable.","16cda6f4":"<a id='5'><\/a><br>\n# Confidence Interval\n\nThe confidence interval is a range of values. In the ideal condition, it should contain the best estimate of a statistical parameter. It is expressed as a percentage. 95% confidence interval is the most common.","14c1f3d3":"### Independent Samples Nonparametric Test","853874c2":"## Nonparametric Correlation Hypothesis Testing","f3a34875":"### Dependent Samples Nonparametric Test"}}