{"cell_type":{"2c3f9877":"code","7eccc10d":"code","0d2ef698":"code","c3287863":"code","e7aeea22":"code","d657903d":"code","d1353e3c":"code","78fe871b":"code","d4883ca1":"code","685990b2":"code","c9947d26":"code","6f317acf":"code","0f96feca":"code","a3d340d5":"code","24b41412":"code","53030d01":"code","618bd53c":"code","d3e8f590":"code","001c0a19":"code","1b41dbbb":"code","99c3c42b":"code","398506e6":"markdown","47cdea3a":"markdown"},"source":{"2c3f9877":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7eccc10d":"!pip install tensorflowjs","0d2ef698":"import cv2\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport tensorflowjs as tfjs\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import optimizers","c3287863":"datadir='..\/input\/indian-festival-classification\/train-20220202T070626Z-001\/train'\ncategories = ['CHITHIRAI THIRUVIZHA','DIWALI','HOLI','KARTHIGAI DEEPAM','PONGAL','RAKSHA BANDHAN']","e7aeea22":"training_data=[]\ndef create_training_data():\n    for category in categories:\n        path = os.path.join(datadir,category)\n        class_num = categories.index(category)\n        print(\"Processing \" + category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img))\n                new_array = cv2.resize(img_array,(96,96))\n                training_data.append([new_array,class_num])\n            except Exception as e:    \n                pass\n        print(\"Done \"+category)\ncreate_training_data()","d657903d":"x=[]\ny=[]\nfor features,label in training_data:\n    x.append(features)\n    y.append(label)\nx = np.array(x).reshape(len(x),96,96,3)\nx.shape","d1353e3c":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)","78fe871b":"x_train=x_train.astype('float32')\nx_test=x_test.astype('float32')\nx_train\/=255\nx_test\/=255","d4883ca1":"y_train = tf.keras.utils.to_categorical(y_train, 6)\ny_test = tf.keras.utils.to_categorical(y_test, 6)","685990b2":"model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (96, 96, 3))","c9947d26":"for layer in model.layers[:20]:\n    layer.trainable = False\nx = model.output\nx =  tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(512, activation=\"relu\")(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(256, activation=\"relu\")(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(128, activation=\"relu\")(x)\npredictions = tf.keras.layers.Dense(6, activation=\"softmax\")(x)   \nmodel_final = tf.keras.models.Model(model.input,predictions)\nmodel_final.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])","6f317acf":"history=model_final.fit(x_train, y_train,\n          batch_size=32,\n          epochs=5,\n          verbose=1,\n          validation_data=(x_test, y_test))","0f96feca":"score = model_final.evaluate(x_test, y_test, verbose=0)\ny_pred=model_final.predict(x_test)\nactual=[]\npred=[]\nfor i in range(260):\n  l = categories[y_test[i].argmax()]\n  m = categories[y_pred[i].argmax()]\n  actual.append(l)\n  pred.append(m)","a3d340d5":"from sklearn import metrics\nprint(metrics.classification_report(pred,actual))","24b41412":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(actual, pred)))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(actual, pred, average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(actual, pred, average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(actual, pred, average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(actual, pred, average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(actual, pred, average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(actual, pred, average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(actual, pred, average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(actual, pred, average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(actual, pred, average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(actual, pred))","53030d01":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n","618bd53c":"from sklearn.metrics import confusion_matrix\ncnf_matrix = confusion_matrix(actual, pred)\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(10,8))\nplot_confusion_matrix(cnf_matrix, classes=['CHITHIRAI THIRUVIZHA','DIWALI','HOLI','KARTHIKAI DEEPAM','PONGAL','RAKSHA BANDHAN'],\n                      title='Confusion matrix')\n","d3e8f590":"img=\"..\/input\/indian-festival-classification\/test-20220202T070625Z-001\/test\/DIWALI\/7.JPG\"\nimg_array = cv2.imread(img)\nnew_array = cv2.resize(img_array,(96,96))\nnew=new_array.reshape(1,96,96,3)\nx=new.astype('float32')\na=(model_final.predict(x))\na=a.tolist()\nif(a[0][0]==1.0):\n  print(\"CHITHIRAI THIRUVIZHA\")\nelif(a[0][1]==1.0):\n  print(\"DIWALI\")\nelif(a[0][2]==1.0):\n  print(\"HOLI\")\nelif(a[0][3]==1.0):\n  print(\"KARTHIGAI DEEPAM\")\nelif(a[0][4]==1.0):\n  print(\"PONGAL\")\nelse:\n  print(\"RAKCHA BANDHAN\")","001c0a19":"categories = ['CHITHIRAI THIRUVIZHA','DIWALI','HOLI','KARTHIGAI DEEPAM','PONGAL','RAKSHA BANDHAN','JALLIKATU','THAIPUSAM','THIRUVAIYARU']\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\ny_pred=[]\nactual=[]\npred=[]\nfor i in categories:\n    dir = '..\/input\/indian-festival-classification\/test-20220202T070625Z-001\/test\/'+i\n    count = 0\n    for dirname, _, filenames in os.walk(dir):\n        for filename in filenames:\n            count += 1\n    for j in range(1,count+1):\n        img = img = dir+'\/'+str(j)+'.JPG'\n        try:\n            img_array = cv2.imread(img)\n            new_array = cv2.resize(img_array,(96,96))\n            new=new_array.reshape(1,96,96,3)\n            x=new.astype('float32')\n            result = model_final.predict(x)\n            l = categories[result.argmax()]\n            pred.append(l)\n            actual.append(categories[0]);\n        except:\n            continue\n","1b41dbbb":"from sklearn import metrics\nprint(); print(metrics.classification_report(pred,actual))","99c3c42b":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nprint('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(actual, pred)))\n\nprint('Micro Precision: {:.2f}'.format(precision_score(actual, pred, average='micro')))\nprint('Micro Recall: {:.2f}'.format(recall_score(actual, pred, average='micro')))\nprint('Micro F1-score: {:.2f}\\n'.format(f1_score(actual, pred, average='micro')))\n\nprint('Macro Precision: {:.2f}'.format(precision_score(actual, pred, average='macro')))\nprint('Macro Recall: {:.2f}'.format(recall_score(actual, pred, average='macro')))\nprint('Macro F1-score: {:.2f}\\n'.format(f1_score(actual, pred, average='macro')))\n\nprint('Weighted Precision: {:.2f}'.format(precision_score(actual, pred, average='weighted')))\nprint('Weighted Recall: {:.2f}'.format(recall_score(actual, pred, average='weighted')))\nprint('Weighted F1-score: {:.2f}'.format(f1_score(actual, pred, average='weighted')))\n\nfrom sklearn.metrics import classification_report\nprint('\\nClassification Report\\n')\nprint(classification_report(actual, pred))","398506e6":"**Testing**","47cdea3a":"**Training**"}}