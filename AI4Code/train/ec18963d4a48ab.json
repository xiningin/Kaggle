{"cell_type":{"0bd83a36":"code","e6095cca":"code","45c907b7":"code","4aac75b3":"code","9a7e9d29":"code","f572275f":"code","77f27b7d":"code","415b1ee7":"code","36b1e0e0":"code","1ec2874f":"code","fd929a96":"code","75477b11":"code","da7418c6":"code","a9efd23f":"code","c9c0f38d":"code","4adc7143":"code","f6281c91":"code","1e09407a":"code","05f68b6e":"code","a2439e13":"code","05e39cdf":"code","515f375b":"code","bd67d3dc":"code","628a92e4":"code","0738b185":"code","ef7de809":"code","28aae6c3":"code","07c5e3c8":"code","a33fe50f":"code","23cf43f1":"code","67fe950f":"code","d2be3c4b":"code","de746a36":"code","9f7d19db":"code","320b2514":"code","18d9e20c":"code","efecf752":"code","6d016162":"code","abd72bab":"code","ae1c82f4":"markdown","c6ee84a8":"markdown","7a7157ab":"markdown","651b8239":"markdown","24657f48":"markdown","351b0722":"markdown","5fe25019":"markdown","e10b9b8a":"markdown","e60b0433":"markdown","f3762997":"markdown","17197e2b":"markdown","9b413d00":"markdown"},"source":{"0bd83a36":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","e6095cca":"train = pd.read_csv('\/kaggle\/input\/dlp-private-competition-dataset-modificated\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/dlp-private-competition-dataset-modificated\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/dlp-private-competition-dataset-modificated\/submission.csv')\n\nprint(train.shape, test.shape, submission.shape)\ndisplay(train.head(3), test.head(3), submission.head(3))","45c907b7":"print(train.corr()['Y'].sort_values(ascending=False)[:10])\nprint(train.corr()['Y'].sort_values(ascending=True)[:10])","4aac75b3":"# EDA (Exploratory Data Analysis, \ud0d0\uc0c9\uc801 \ub370\uc774\ud130 \ubd84\uc11d)\n# modeling \uc804 \uc0c1\uad00\ub3c4 \ubd84\uc11d (target\uac12\uacfc \uac01 column\uc758 \uc0c1\uad00\uad00\uacc4 \uc2dc\uac01\ud654)\nimport matplotlib.pyplot as plt\nprint(train.corr()['Y'].sort_values(ascending=False)[:10])\nprint(train.corr()['Y'].sort_values(ascending=True)[:10])\n\ncorr_with_Y = train.corr()[\"Y\"].sort_values(ascending=False)[:10]\nplt.figure(figsize=(20,6))\ncorr_with_Y.drop(\"Y\").plot.bar()\nplt.show();","9a7e9d29":"import seaborn as sns\n# saleprice correlation matrix\ncorrmat = train.corr()\n# corr_num = 15 #number of variables for heatmap\ncorr_num = 10\ncols_corr = corrmat.nlargest(corr_num, 'Y')['Y'].index\ncorr_mat_sales = np.corrcoef(train[cols_corr].values.T)\nsns.set(font_scale=1.25)\nf, ax = plt.subplots(figsize=(12, 9))\nhm = sns.heatmap(corr_mat_sales, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 7}, yticklabels=cols_corr.values, xticklabels=cols_corr.values)\nplt.show()","f572275f":"import missingno as msno\nmsno.matrix(df=train, figsize=(8, 8), color=(0.8, 0.5, 0.2))","77f27b7d":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.scatter(x = train['C109'], y = train['Y'])\nplt.ylabel('Y')\nplt.xlabel('C109')\nplt.show()","415b1ee7":"# outlier: \ud3c9\uade0\uce58\uc5d0\uc11c \ud06c\uac8c \ubc97\uc5b4\ub098\uc11c \ub2e4\ub978 \ub300\uc0c1\ub4e4\uacfc \ud655\uc5f0\ud788 \uad6c\ubd84\ub418\ub294 \ud45c\ubcf8\ntrain[train['Y'] > 80].index","36b1e0e0":"train = train.drop([4476],0)\nfig, ax = plt.subplots()\nax.scatter(x = train['C109'], y = train['Y'])\nplt.ylabel('Y')\nplt.xlabel('C109')\nplt.show()","1ec2874f":"# joint plot \uadf8\ub9ac\uae30\nsns.jointplot(x=train['C109'], y=train['Y'], kind='reg')","fd929a96":"fig = plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(train['Y'])\nplt.title('Y distribution')\nplt.subplot(1,2,2)\nsns.distplot(np.log1p(train['Y']))\nplt.title('Y distribution after normalization')\n# skewness (\uc65c\ub3c4, \uce58\uc6b0\uc9c4 \uc815\ub3c4) : 3(mean-median) \/ standard deviation)\n# skewness = 0 : normally distributed.\n# skewness > 0 : more weight in the left tail of the distribution.\n# skewness < 0 : more weight in the right tail of the distribution. \n# kurtosis (\ucca8\ub3c4, \ubfb0\uc871\ud55c \uc815\ub3c4) : E ((X-mean)\/ standard deviation)^4\nprint('skewness: %f' % train['Y'].skew())\nprint('kurtosis: %f' % train['Y'].kurt())\nprint('skewness after normalization: %f' % np.log1p(train['Y']).skew())\nprint('kurtosis after normalization: %f' % np.log1p(train['Y']).kurt())","75477b11":"# Pandas \nimport pandas as pd\nimport numpy as np\nnp.random.seed(1234)\n# dateframe \ub9cc\ub4e4\uae30\ndf = pd.DataFrame(np.random.randint(1,200,60).reshape(10,6))\n# \uc5f4 \uc774\ub984 \uc9c0\uc815\ndf.columns = ['\uc77c','\uc218\uba74','\ubc25','\uba4d','\uc601\ud654','\uac8c\uc784']\n# \ud589 \uc774\ub984 \uc9c0\uc815\ndate = pd.date_range('20210601', periods=10, freq='M')\ndf.index = date\n# \ud2b9\uc815 \ubd80\ubd84 \ucd94\ucd9c\ud558\uae30\ndf.loc['20210801':'20210930',['\uc77c','\uc218\uba74']]\n#\uc0c8\ub85c\uc6b4 \uc5f4 \ub9cc\ub4e4\uae30\ndf['\uc218\uba74\ube44\uc728'] = df['\uc218\uba74'] \/ df['\uc77c']\n# \uc815\ub82c \uae30\ub2a5\ndf.sort_values(by='\uc218\uba74\ube44\uc728', ascending=True)[:3].index\n# \uac8c\uc784 \ud50c\ub808\uc774 \uc2dc\uac04\uc774 100\uc2dc\uac04 \ubbf8\ub9cc\uc778 \ub2ec\uc758 \ud589\ub9cc \ucd9c\ub825\ndf[df['\uac8c\uc784'] < 100]\n# \ud2b9\uc815 \uac12\ub9cc \ucd94\ucd9c\ndf.loc['20210831','\uc218\uba74'], df['\uc218\uba74']['20210831']\n# \ud2b9\uc815 \uc870\uac74\uc758 \ubd80\ubd84\uc744 \ucc3e\uc544\uc11c \ubc14\uafb8\uae30\n# \uc218\uba74\uc2dc\uac04\uc774 50\uc2dc\uac04 \uc774\ud558\uba74 \uc880\ube44 -> \uc218\uba74 \uc2dc\uac04\uc744 0 \uc73c\ub85c \ubc14\uafb8\uae30\ndf.loc[df['\uc218\uba74'] <= 50, '\uc218\uba74'] = 0\n# \uc880\ube44\uc778 \uc0ac\ub78c\ub4e4\uc758 \uc218\uba74\ube44\uc728\uc744 -1 \ub85c \ubc14\uafb8\uae30\ndf.loc[df['\uc218\uba74'] == 0, '\uc218\uba74\ube44\uc728'] = -1\ndf","da7418c6":"test['Y'] = 9999\ntest.head()\n# test\uc14b\uc5d0 Y\uac12\uc5d0 9999\ub97c insert (\ub098\uc911\uc5d0 \ubd84\ud560\ub54c Y\uac12\uc774 9999\uc778 \uac83\ub4e4\ub9cc test\ub85c \ube7c\uc8fc\uba74 \ub428)","a9efd23f":"total = pd.concat([train,test],0, sort = True)     # train\uacfc test\ub97c \ud569\uccd0\uc90c \nprint(train.shape, test.shape, \"--> \",total.shape)     # train\uacfc test\uac00 \ud569\uccd0\uc838\uc11c total\uc774 \ub418\ub294\ub370 shape\ub97c \ud655\uc778\ntotal.head()     # total\uc758 \uc55e\uc5d0 5\uac1c \ud589 \ud655\uc778(\uc798 \ud569\uccd0\uc84c\ub098..)","c9c0f38d":"total = total.drop(['ID'], 1)\ntotal.head(3)","4adc7143":"cate_col = list(total.dtypes[total.dtypes == 'object'].index)\ncate_col","f6281c91":"from sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()\n\nlbl.fit(list(total['A'].values))\ntotal['A'] = lbl.transform(list(total['A'].values))\ntotal.head(3)","1e09407a":"cate_col = list(total.dtypes[total.dtypes == 'object'].index)\n\nfrom sklearn.preprocessing import LabelEncoder\nlbl = LabelEncoder()\n\nfor col in cate_col:\n    lbl.fit(list(total[col].values))\n    total[col] = lbl.transform(list(total[col].values))\ntotal.head(3)","05f68b6e":"pd.set_option('display.max_columns', 10000)\ntotal.head(3)","a2439e13":"len(total)","05e39cdf":"missing = list(round(total.isnull().sum() \/ len(total) *100, 2).sort_values(ascending=False)[:25].index)\nmissing","515f375b":"for col in missing:\n    total[col] = total[col].fillna(total[col].median())","bd67d3dc":"total.isnull().sum().sum()","628a92e4":"test = total[total['Y'] == 9999]\nprint(total.shape, test.shape)\ntest.head(3)","0738b185":"test = test.drop(['Y'],1)\nprint(test.shape)\ntest.head(3)","ef7de809":"train = total[total['Y'] != 9999]\nprint(total.shape, train.shape)\ntrain.head(3)","28aae6c3":"y = pd.DataFrame(train['Y'])\ny.head(3)","07c5e3c8":"X = train.drop(['Y'],1)\nX.head(3)","a33fe50f":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split (X, y, random_state=0)","23cf43f1":"# X_train.shape, X_valid.shape, y_train.shape, y_valid.shape\nimport lightgbm as lgb\nmodel = lgb.LGBMRegressor (objective = 'regression', num_leaves=144,\n                         learning_rate=0.005,n_estimators=720, max_depth=13,\n                         metric='rmse', is_training_metric=True, max_bin=55,\n                         bagging_fraction=0.8, verbose=-1, bagging_freq=5, feature_fraction=0.9)\n\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\n# model = Lasso(random_state = 0)\n# model = ElasticNet(random_state = 0)\n\nfrom catboost import CatBoostRegressor\n# model = CatBoostRegressor(verbose=0, n_estimators=100)\n\nfrom sklearn.ensemble import RandomForestRegressor\n# model = RandomForestRegressor(random_state = 0)","67fe950f":"model.fit(X_train, y_train)\n\nfrom sklearn.metrics import mean_squared_error\npred_train = model.predict(X_train)\npred_valid = model.predict(X_valid)\n\ntrain_score = round(mean_squared_error(pred_train, y_train),3)\nvalid_score = round(mean_squared_error(pred_valid, y_valid),3)\nprint('train_score:', train_score, '\/ valid_score:', valid_score)\n\n# Lgbm: 8.762, 18.638\n# Ridge: 24.573, 3198.748\n# Lasso: 44.373, 48.405\n# ElasticNet: 41.26, 45.518\n# Catboost: 19.22, 23.763\n# RandomFroest: 3.528, 19.788","d2be3c4b":"import matplotlib.pyplot as plt\nplot1 = pd.DataFrame(y_valid).reset_index(drop=True)\nplot2 = pd.DataFrame(pred_valid)\n\nfig, axes = plt.subplots(1,1,figsize=(14, 6))\nplot1.sort_index().plot(ax=axes).set_xlabel('index');\nplot2.sort_index().plot(ax=axes).set_ylabel('value');\naxes.legend(['y_valid', 'pred_valid']);\naxes.set_title('y_value vs Predicted_value', fontsize=16);","de746a36":"# feature importance \uc870\ud68c\nlgb.plot_importance(model)\nplt.rcParams['figure.figsize'] = [5,25]\nplt.show()","9f7d19db":"pred_test = model.predict(test)\npred_test","320b2514":"submission = submission.drop(['Y'],1)\nsubmission.head()","18d9e20c":"pred_test = pd.DataFrame(pred_test)\npred_test.head()","efecf752":"submission_final = pd.concat([submission,pred_test],1)\nsubmission_final.head()","6d016162":"submission_final.columns = ['ID','Y']\nsubmission_final.head()","abd72bab":"submission_final.to_csv('submission_final.csv', index = False)\n","ae1c82f4":"# Predict wafer thick (with test dataset)\n- \uc55e\uc5d0 \uac80\uc99d\uc744 \ud1b5\ud574 \ubaa8\ub378\uc774 \ud559\uc2b5\uc774 \uc798 \ub418\uc5c8\ub294\uc9c0 \ud655\uc778\uc774 \ub418\uc5c8\ub2e4\uba74 Test dataset\uc744 \uac00\uc9c0\uace0 \uc608\uce21\ud574\ubd04","c6ee84a8":"# Find column having a string data\n- Model\uc740 string(\ubb38\uc790) data\ub294 \ubd84\uc11d\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\n- dataset\uc5d0\uc11c string\uc744 \uac00\uc9c0\uace0 \uc788\ub294 column\uc744 \ucc3e\uc544\uc11c \uc22b\uc790\ub85c \ubc14\uafd4\uc8fc\uac70\ub098 \uc9c0\uc6cc\uc57c Model\uc774 \ubd84\uc11d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","7a7157ab":"# Split the dataset (total -> train \/ test)\n- \ubaa8\ub4e0 Feature Engineering\uc744 \uc9c4\ud589\ud588\uae30 \ub54c\ubb38\uc5d0 \ub2e4\uc2dc \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \uae30\uc874\uc5d0 total\ub85c \ud569\uccd0\uc9c4\uac83\uc744 \ub2e4\uc2dc train\uacfc test\ub85c \ubd84\ub9ac\ud569\ub2c8\ub2e4.","651b8239":"# Import Dataset\n- \ubd84\uc11d\uc5d0 \ud544\uc694\ud55c Dataset\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4","24657f48":"# Import Library\n- \ubd84\uc11d\uc5d0 \ud544\uc694\ud55c Library\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4","351b0722":"# Import Model (LightGBM)","5fe25019":"# Merge train & test dataset (for Feature Engineering)\n- Feature Engineering\uc744 \ud560\ub54c Train\uacfc Test dataset\uc744 \ub3d9\uc2dc\uc5d0 \uc9c4\ud589\ud574\uc57c \ud568\n- \ud560\ub54c\ub9c8\ub2e4 \ub530\ub85c \uc9c4\ud589\ud558\uba74 \ubd88\ud3b8\ud558\uae30 \ub54c\ubb38\uc5d0 \ud569\uccd0\ub193\uace0 \uc9c4\ud589\ud568(\ucd94\ud6c4 \ub2e4\uc2dc Train\uacfc Test\ub85c \ubd84\ub9ac\ud568)","e10b9b8a":"# Split the dataset(2) (train -> X \/ y)\n- train \ub370\uc774\ud130\ub97c X\ubcc0\uc218\uc640 y\ubcc0\uc218\ub85c \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \ud574\ub2f9\uc740 \ubaa8\ub378\uc744 \ub3cc\ub9ac\uae30\uc804\uc5d0 \uc0ac\uc804 \uacfc\uc815\uc774\ubbc0\ub85c \ud2b9\ubcc4\ud55c \uc774\uc720\uc5c6\uc774 \uc9c4\ud589\ub429\ub2c8\ub2e4.","e60b0433":"# Submit the result\n- test dataset\uc744 \uac00\uc9c0\uace0 \uc608\uce21\ud55c \uacb0\uacfc\ub97c submission dataset\uc5d0 import\ud558\uc5ec kaggle\uc5d0 \uc81c\ucd9c!","f3762997":"# Split the dataset(3) (X, y -> X_train, y_train, X_valid, y_valid)\n- \uc55e\uc5d0\uc11c \ubd84\ub9ac\ud55c X\uc640 y\ub97c train\uacfc valid\ub85c \ubd84\ub9ac\ud574\uc90d\ub2c8\ub2e4.\n- \ub370\uc774\ud130 \uc138\ud2b8\ub97c \ubd84\ub9ac\ud558\ub294 \uc774\uc720\ub294 \ubaa8\ub378\uc774 overfitting\uc774 \ub418\uc5c8\ub294\uc9c0 \uac80\uc99d\ud558\uae30 \uc704\ud568\uc785\ub2c8\ub2e4.\n- \uc774\ud574\uac00 \uc5b4\ub824\uc6b8 \uc2dc \uae30\uc874\uc5d0 \ubc30\ud3ec\ud55c Machine Learning Pipeline\uc744 \ucc38\uace0\ud574\uc8fc\uc2dc\uae38 \ubc14\ub78d\ub2c8\ub2e4.","17197e2b":"# Train the model\n- Train data\ub97c \uc0ac\uc6a9\ud558\uc5ec Model\uc744 \ud559\uc2b5\uc2dc\ud0b4\n# Calculate MSE (Loss function)\n- X_train \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc608\uce21\uac12 Pred_train\uacfc y_train\uac04\uc758 \ucc28\uc774 --- (1)\n- X_valid \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uc608\uce21\uac12 Pred_valid\uc640 y_valid\uac04\uc758 \ucc28\uc774 --- (2)\n- (1)\uacfc (2)\uac00 \ucc28\uc774\uac00 \ud06c\ub2e4\uba74 Overfitting\uc774\ubbc0\ub85c \ud5a5\ud6c4 \uc608\uce21\uc5d0 \uc5b4\ub824\uc6b8 \uc218 \uc788\uc74c","9b413d00":"# Change data from string to numeric(using Label Encoding)\n- \uc55e\uc5d0\uc11c \ucc3e\uc544\uc900 string data\ub97c numerical data(\uc22b\uc790\ud615)\uc73c\ub85c \ubc14\uafd4\uc90d\ub2c8\ub2e4.\n- \uc5ec\uae30\uc11c\ub294 Label Encoding\uc774\ub77c\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. (Label Encoding\uc740 \uc784\uc758\ub85c \uc21c\uc11c\ub300\ub85c 1\ubd80\ud130 \uc9c0\uc815\ud574\uc11c \ubc14\uafd4\uc90d\ub2c8\ub2e4.)"}}