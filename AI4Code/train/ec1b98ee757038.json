{"cell_type":{"41eb38d8":"code","1b6f5a42":"code","7f7fa689":"code","bed7ace2":"code","546fe406":"code","6512a71b":"code","64881c91":"code","7bf61d4c":"code","37420f13":"code","580fe035":"code","0fd9b25b":"code","975a7b09":"code","86078d66":"code","e6694dab":"code","007b05d6":"code","6224f47d":"code","2358b78a":"code","3eb75952":"code","8d886d9e":"code","603e21b4":"code","1099ef03":"code","80bfd1bf":"code","9fc03ba4":"code","f9beaa1d":"code","e25085d4":"code","642cb4a1":"code","c9721ac1":"code","6bc2e8e7":"code","4c098968":"code","4fc65dd3":"code","3269e105":"code","26336c88":"code","d03221da":"code","15078fdd":"code","32822c3c":"code","6eb0d434":"code","7474dfad":"code","4f5549cf":"code","65ab5d77":"code","9a99ac28":"code","af0aa24b":"code","50f96e0b":"code","d5ef287f":"code","fecabd64":"code","e5a3eadb":"code","b0179652":"code","0c6172bd":"code","4e78c1a7":"code","8d7ebbf0":"code","b9e248e3":"code","e3433020":"code","b2590ec6":"code","d78632f3":"code","354016b0":"code","d7f84d0c":"code","70baa80d":"code","45f6301a":"code","981308af":"code","eacb2460":"code","f2374edf":"code","6f40cc2a":"code","a0454fa6":"code","5e2b4cde":"code","a6b12d16":"code","f33b3925":"code","891380b6":"code","a19f88e0":"code","804dae05":"code","a888a9e7":"code","6afce94b":"code","a1fe3d9c":"code","15402fa6":"code","709600c3":"code","69d71db9":"code","f3f8ffc4":"code","6abf3bea":"code","15860791":"code","522e43ab":"code","ffbcf39c":"code","478c4f3f":"code","5bfcbcec":"code","f78f0c98":"code","de2af7d0":"code","a7d15b1d":"code","f0478762":"code","852d6544":"code","7b303eb4":"code","31aee448":"code","6f380e11":"code","559f7a09":"code","84dce9b6":"markdown","aab19e42":"markdown","333ffaf4":"markdown","2e409799":"markdown","2a581e56":"markdown","3828d291":"markdown","8771f77b":"markdown","be414b48":"markdown","ab3a2486":"markdown","6181f16d":"markdown","5b173611":"markdown","7edc2076":"markdown","87f53f5c":"markdown","b58726ea":"markdown","f29f1a4d":"markdown","e962c64b":"markdown","4f81c21c":"markdown","5d595766":"markdown"},"source":{"41eb38d8":"# Necessary imports\n\n## Data loading, processing and for more\nimport pandas as pd\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE\n\n## Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# set seaborn style because it prettier\nsns.set()\n\n## Metrics & utilities\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, \\\n                            precision_recall_curve, classification_report, \\\n                            confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split,GridSearchCV\n\n\n## Models\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.naive_bayes import GaussianNB","1b6f5a42":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","7f7fa689":"# Checking data\ncsvfile_path = '..\/input\/PS_20174392719_1491204439457_log.csv'\ndata = pd.read_csv(csvfile_path)\n\nraw_data = data.copy()\n\nprint (\"raw data shape:\", raw_data.shape)\nprint(raw_data.head())\nprint(raw_data.describe())\nprint(raw_data.info())","bed7ace2":"# PR-AUC curve\n\n# %% Function for plotting PR_AUC curve\ndef plot_precision_recall(y_test: np.array, y_score: np.array) -> None:\n    precision, recall, _ = precision_recall_curve(y_test, y_score)\n    auc_score = auc(recall, precision)\n\n    plt.step(recall, precision, color='b', alpha=0.2,\n             where='post')\n    plt.fill_between(recall, precision, alpha=0.2, color='b')\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.05])\n    plt.title('Precision-Recall curve: AUC={0:0.4f}'.format(auc_score))\n    plt.show()","546fe406":"data_used = raw_data.loc[(raw_data['type'].isin(['TRANSFER', 'CASH_OUT'])),:]\ndata_used.drop(['step', 'nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1, inplace=True)\n\ndata_used = data_used.reset_index(drop=True)\n\ntype_encoder = preprocessing.LabelEncoder()\ntype_category = type_encoder.fit_transform(data_used['type'].values)\ndata_used['type_code'] = type_category\n\nprint (\"data_used shape:\", data_used.shape)\ndata_used.head()","6512a71b":"# under sample\nfeature_names = ['amount', 'oldbalanceOrg', 'newbalanceOrig', \n                 'oldbalanceDest', 'newbalanceDest', 'type_code']\nnumber_records_fraud = len(data_used[data_used['isFraud'] == 1])\n\n#\u3000indices of fraud_indices\nfraud_indices = data_used[data_used['isFraud'] == 1].index.values\n\n#indices of the normal records\nnonfraud_indices = data_used[data_used['isFraud'] == 0].index\n\nrandom_nonfraud_indices = np.random.choice(nonfraud_indices, number_records_fraud, replace=False)\nrandom_nonfraud_indices = np.array(random_nonfraud_indices)\n\nunder_sample_indices = np.concatenate([fraud_indices, random_nonfraud_indices])\nunder_sample_data = data_used.iloc[under_sample_indices, :]\n                          \nprint(under_sample_data[feature_names].head())\nX_undersample = under_sample_data[feature_names].values\ny_undersample = under_sample_data['isFraud'].values\nprint(\"--------------------------------------------------------------------------\")\n\nprint(\"Ratio of nomal: \", len(under_sample_data[under_sample_data['isFraud'] == 0]) \/ len(under_sample_data))\nprint(\"Ratio of fraud: \", len(under_sample_data[under_sample_data['isFraud'] == 1]) \/ len(under_sample_data))\nprint(\"Number of data for model: \", len(under_sample_data))","64881c91":"X = data_used.drop(['isFraud', 'type'],axis=1)\ny = data_used['isFraud']\nprint(X.head(),\"\\n\")\nprint(y.head())","7bf61d4c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","37420f13":"alpha = np.logspace(-2, 2, 20)\nlr_model_cv = LogisticRegressionCV(Cs=alpha, penalty='l1', solver='liblinear', cv=5)\nlr_model_cv.fit(X_train, y_train)\n\ny_pred = lr_model_cv.predict(X_test)","580fe035":"print(\"Classification Report for Logistic Regression Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Logistic Regression Classifier: \\n\", confusion_matrix(y_test, y_pred))\nplot_precision_recall(y_test, lr_model_cv.predict_proba(X_test)[:,1])","0fd9b25b":"XGBoost_CLF = xgb.XGBClassifier(learning_rate =0.1, n_estimators=100, max_depth=6, min_child_weight=1,  \n                  gamma=0, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', \n                  nthread=4, scale_pos_weight=1, seed=42)","975a7b09":"XGBoost_CLF.fit(X_train, y_train)\ny_pred = XGBoost_CLF.predict(X_test)","86078d66":"print(\"Classification Report for XGBoost Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of XGBoost Classifier: \\n\", confusion_matrix(y_test, y_pred))\nplot_precision_recall(y_test, XGBoost_CLF.predict_proba(X_test)[:,1])","e6694dab":"meta_data = pd.read_csv(\"..\/input\/PS_20174392719_1491204439457_log.csv\")\ndel meta_data['nameDest']\ndel meta_data['nameOrig']\ndel meta_data['type']","007b05d6":"Cols = meta_data[['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest','isFlaggedFraud']]\ny = meta_data['isFraud']\nX = Cols","6224f47d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","2358b78a":"# Random Forest Classifier\nrfc = RandomForestClassifier() #using default values\nrfc.fit(X_train, y_train)\n                \ny_pred = rfc.predict(X_test)","3eb75952":"print(\"Classification Report for Random Forest Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Random Forest Classifier: \\n\", confusion_matrix(y_test, y_pred))\nplot_precision_recall(y_test, rfc.predict_proba(X_test)[:,1])","8d886d9e":"# Logistic Regression\n\nlrc = LogisticRegression() #using default values\nlrc.fit(X_train, y_train)\n                \ny_pred = lrc.predict(X_test)","603e21b4":"print(\"Classification Report for Logistic Regression Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Logistic Regression Classifier: \\n\", confusion_matrix(y_test, y_pred))\nplot_precision_recall(y_test, lrc.predict_proba(X_test)[:,1])","1099ef03":"gnb = GaussianNB()\ngnb.fit(X_train,y_train)\n\ny_pred = gnb.predict(X_test)","80bfd1bf":"print(\"Classification Report for Naive Bayes Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Naive Bayes Classifier: \\n\", confusion_matrix(y_test, y_pred))\nplot_precision_recall(y_test, gnb.predict_proba(X_test)[:,1])","9fc03ba4":"df = pd.read_csv(\"..\/input\/PS_20174392719_1491204439457_log.csv\")\ndf = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\nprint(df.head())","f9beaa1d":"dfFraudTransfer = df.loc[(df.isFraud == 1) & (df.type == 'TRANSFER')]\ndfFraudCashout = df.loc[(df.isFraud == 1) & (df.type == 'CASH_OUT')]\n\ndfTransfer = df.loc[df.type == 'TRANSFER']\ndfFlagged = df.loc[df.isFlaggedFraud == 1]\ndfNotFlagged = df.loc[df.isFlaggedFraud == 0]","e25085d4":"X = df.loc[(df.type == 'TRANSFER') | (df.type == 'CASH_OUT')]\n\nrandomState = 5\nnp.random.seed(randomState)\n\n#X = X.loc[np.random.choice(X.index, 100000, replace = False)]\n\nY = X['isFraud']\ndel X['isFraud']\n\n# Eliminate columns shown to be irrelevant for analysis in the EDA\nX = X.drop(['nameOrig', 'nameDest', 'isFlaggedFraud'], axis = 1)\n\n# Binary-encoding of labelled data in 'type'\nX.loc[X.type == 'TRANSFER', 'type'] = 0\nX.loc[X.type == 'CASH_OUT', 'type'] = 1\nX.type = X.type.astype(int) # convert dtype('O') to dtype(int)","642cb4a1":"X.loc[(X.oldBalanceOrig == 0) & (X.newBalanceOrig == 0) & (X.amount != 0), \\\n      ['oldBalanceOrig', 'newBalanceOrig']] = np.nan","c9721ac1":"X['errorBalanceOrig'] = X.newBalanceOrig + X.amount - X.oldBalanceOrig\nX['errorBalanceDest'] = X.oldBalanceDest + X.amount - X.newBalanceDest","6bc2e8e7":"trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.2, \\\n                                                random_state = randomState)","4c098968":"# Long computation in this cell (~1.8 minutes)\nweights = (Y == 0).sum() \/ (1.0 * (Y == 1).sum())\nclf = xgb.XGBClassifier(max_depth = 3, scale_pos_weight = weights, \\\n                n_jobs = 4)\nclf.fit(trainX, trainY)\n\ny_pred = clf.predict(testX)","4fc65dd3":"print(\"Classification Report for XGBoost Classifier: \\n\", classification_report(testY, y_pred))\nprint(\"Confusion Matrix of XGBoost Classifier: \\n\", confusion_matrix(testY, y_pred))\nplot_precision_recall(testY, clf.predict_proba(testX)[:,1])","3269e105":"data = pd.read_csv(\"..\/input\/PS_20174392719_1491204439457_log.csv\")","26336c88":"y = data.isFraud.values\nX = data.drop(labels=['type', 'nameOrig', 'nameDest', 'isFraud'], axis=1)\n","d03221da":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","15078fdd":"clf = KNeighborsClassifier(n_neighbors=19, metric='manhattan')\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","32822c3c":"print(\"Classification Report for KNeighbours Classifier: \\n\", classification_report(testY, y_pred))\nprint(\"Confusion Matrix of KNeighbours Classifier: \\n\", confusion_matrix(testY, y_pred))\nplot_precision_recall(testY, clf.predict_proba(testX)[:,1])","6eb0d434":"clf = RandomForestClassifier(n_estimators=50)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict_proba(X_test)","7474dfad":"print(\"Classification Report for Random Forest Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Random Forest Classifier: \\n\", confusion_matrix(y_test,y_pred))\nplot_precision_recall(y_test, rfc.predict_proba(X_test)[:,1])","4f5549cf":"clf = xgb.XGBClassifier(max_depth=5, \n                            n_estimators=100, n_jobs=-1, )\nclf.fit(X_train, y_train)\ny_pred = clf.predict_proba(X_test)","65ab5d77":"print(\"Classification Report for XGBoost Classifier Classifier: \\n\", classification_report(testY, y_pred))\nprint(\"Confusion Matrix of XGBoost Classifier Classifier: \\n\", confusion_matrix(testY, y_pred))\nplot_precision_recall(testY, clf.predict_proba(testX)[:,1])","9a99ac28":"# Normalization\nscl = StandardScaler()\nX_norm = scl.fit_transform(X)","af0aa24b":"X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42,)","50f96e0b":"clf = RandomForestClassifier(n_estimators=50)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)","d5ef287f":"print(\"Classification Report for Random Forest Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Random Forest Classifier: \\n\", confusion_matrix(y_test,y_pred))\nplot_precision_recall(y_test, clf.predict_proba(X_test)[:,1])","fecabd64":"# `PCA\npca = PCA(n_components=7)\nX_pca = pca.fit_transform(X)","e5a3eadb":"X_train, X_test, y_train, y_test = train_test_split(X_pca, y,\n                                                    test_size=0.3, \n                                                    random_state=42,)\n\nclf = RandomForestClassifier(n_estimators=50)\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)","b0179652":"print(\"Classification Report for Random Forest Classifier: \\n\", classification_report(y_test, y_pred))\nprint(\"Confusion Matrix of Random Forest Classifier: \\n\", confusion_matrix(y_test,y_pred))\nplot_precision_recall(y_test, clf.predict_proba(X_test)[:,1])","0c6172bd":"df = pd.read_csv('..\/input\/PS_20174392719_1491204439457_log.csv')\n\ndf = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})","4e78c1a7":"len(df)","8d7ebbf0":"data = df.copy()\n# add source and target type\ndata['OrigC']=data['nameOrig'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\ndata['DestC']=data['nameDest'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\ndata['TRANSFER']=data['type'].apply(lambda x: 1 if x=='TRANSFER' else 0)\ndata['CASH_OUT']=data['type'].apply(lambda x: 1 if x=='CASH_OUT' else 0)","b9e248e3":"# Trans Amount from Loan ? killed features from  Arjun Joshua\ndata['OrigAmntErr']=(abs(data.oldBalanceOrig-data.newBalanceOrig)-data.amount)*data['OrigC']\ndata['DestAmntErr']=(abs(data.oldBalanceDest-data.oldBalanceDest)-data.amount)*data['DestC']","e3433020":"# drop list \ndroplist=['isFlaggedFraud','OrigC','type','nameDest','nameOrig']","b2590ec6":"MLData=data.drop(labels=droplist,axis=1)\nX=MLData.drop('isFraud',axis=1)\nY=MLData.isFraud","d78632f3":"trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3,random_state=42, shuffle=False)","354016b0":"weights = (Y == 0).sum() \/ (1.0 * (Y == 1).sum())\nclf = xgb.XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n\nclf.fit(trainX, trainY)\n\ny_pred = clf.predict(testX)","d7f84d0c":"print(\"Classification Report for XGBoost Classifier: \\n\", classification_report(testY, y_pred))\nprint(\"Confusion Matrix of XGBoost Classifier: \\n\", confusion_matrix(testY, y_pred))\nplot_precision_recall(testY, clf.predict_proba(testX)[:,1])","70baa80d":"df = pd.read_csv('..\/input\/PS_20174392719_1491204439457_log.csv')\n\ndf = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})","45f6301a":"# Start Feature extraction\n# Merchant flag for source and dist\n# Trans tye for fraud trans type\ndata = df.copy()\n# add source and target type\ndata['OrigC']=data['nameOrig'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\ndata['DestC']=data['nameDest'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\ndata['TRANSFER']=data['type'].apply(lambda x: 1 if x=='TRANSFER' else 0)\ndata['CASH_OUT']=data['type'].apply(lambda x: 1 if x=='CASH_OUT' else 0)","981308af":"# Trans Amount from Loan ? killed features from  Arjun Joshua\ndata['OrigAmntErr']=(abs(data.oldBalanceOrig-data.newBalanceOrig)-data.amount)*data['OrigC']\ndata['DestAmntErr']=(abs(data.oldBalanceDest-data.oldBalanceDest)-data.amount)*data['DestC']","eacb2460":"# drop list \ndroplist=['isFlaggedFraud','OrigC','type','nameDest','nameOrig','DestC']","f2374edf":"MLData=data.drop(labels=droplist,axis=1)\nX=MLData.drop('isFraud',axis=1)\nY=MLData.isFraud","6f40cc2a":"# modify step to hours in day. \nX['step24']=X.step%24","a0454fa6":"#  drop DestAmntErr and update newBalanceDest\nX.loc[(X.DestAmntErr != 0) & (X.newBalanceDest == 0),'newBalanceDest'] = -1\nX=X.drop('DestAmntErr',axis=1)\nMLData.loc[(MLData.DestAmntErr != 0) & (MLData.newBalanceDest == 0),'newBalanceDest'] = -1\nMLData=MLData.drop('DestAmntErr',axis=1)","5e2b4cde":"trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3,random_state=42)","a6b12d16":"#Base metrics \nweights = (Y == 0).sum() \/ (1.0 * (Y == 1).sum())\nclf = xgb.XGBClassifier(scale_pos_weight = weights, n_jobs = 4, random_state=42)\nclf.fit(trainX, trainY)\n\ny_pred = clf.predict(testX)","f33b3925":"print(\"Classification Report for XGBoost Classifier: \\n\", classification_report(testY, y_pred))\nprint(\"Confusion Matrix of XGBoost Classifier: \\n\", confusion_matrix(testY, y_pred))\nplot_precision_recall(testY, clf.predict_proba(testX)[:,1])","891380b6":"df = pd.read_csv('..\/input\/PS_20174392719_1491204439457_log.csv')\n\ntmp = df.copy()","a19f88e0":"tmp.drop(['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'amount', 'type'], axis=1, inplace=True)\n\nX = tmp.ix[:, tmp.columns != 'isFraud']\ny = tmp.ix[:, tmp.columns == 'isFraud']","804dae05":"# Number of data points in the minority class\nnumber_records_fraud = len(tmp[tmp.isFraud == 1])\nfraud_indices = tmp[tmp.isFraud == 1].index.values\n\n# Picking the indices of the normal classes\nnormal_indices = tmp[tmp.isFraud == 0].index\n\n# Out of the indices we picked, randomly select \"x\" number (x - same as total fraud)\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\n# Appending the 2 indices\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\nunder_sample_data = tmp.iloc[under_sample_indices, :]\n\nX_undersample = under_sample_data.ix[:, under_sample_data.columns != 'isFraud']\ny_undersample = under_sample_data.ix[:, under_sample_data.columns == 'isFraud']\n\n# Showing ratio\nprint(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.isFraud == 0])\/len(under_sample_data))\nprint(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.isFraud == 1])\/len(under_sample_data))\nprint(\"Total number of transactions in resampled data: \", len(under_sample_data))","a888a9e7":"# Whole dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n\n# Undersampled dataset\nX_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n                                                                                                   ,y_undersample\n                                                                                                   ,test_size = 0.3\n                                                                                                   ,random_state = 0)","6afce94b":"lr = LogisticRegression(C = 0.001, penalty = 'l1')\nlr.fit(X_train_undersample,y_train_undersample.values.ravel())\n\ny_pred_undersample = lr.predict(X_test_undersample.values)","a1fe3d9c":"\nprint(\"Classification Report for Logistic Regression undersampled Classifier: \\n\", classification_report(X_test_undersample, y_pred_undersample))\nprint(\"Confusion Matrix of Logistic Regression undersampled Classifier: \\n\", confusion_matrix(X_test_undersample, y_pred_undersample))\nplot_precision_recall(testY, clf.predict_proba(X_test_undersample)[:,1])","15402fa6":"# Predict for not underampled data\ny_pred = lr.predict(X_test.values)","709600c3":"\nprint(\"Classification Report for Logistic Regression undersampled Classifier: \\n\", classification_report(X_test, y_pred))\nprint(\"Confusion Matrix of Logistic Regression undersampled Classifier: \\n\", confusion_matrix(X_test, y_pred))\nplot_precision_recall(testY, clf.predict_proba(X_test)[:,1])","69d71db9":"data = pd.read_csv('..\/input\/PS_20174392719_1491204439457_log.csv')","f3f8ffc4":"data.drop(['nameOrig','nameDest','isFlaggedFraud'], axis = 1, inplace=True)","6abf3bea":"sc = StandardScaler()\nX_toScale = data[['amount', 'oldbalanceOrg', 'newbalanceOrig',\n      'oldbalanceDest', 'newbalanceDest'\n       ]]\nnew_X = sc.fit(X_toScale)\nX_scaled = new_X.transform(X_toScale)","15860791":"#creating our dataframe with scaled values\n\nscaled_df = pd.DataFrame(X_scaled, columns=['amount', 'oldbalanceOrg', 'newbalanceOrig',\n      'oldbalanceDest', 'newbalanceDest'\n       ])","522e43ab":"# we have also some categorical variable, called Type. Let's convert it to dummies, and then add to our final dataframe\ndummy_df = pd.DataFrame(pd.get_dummies(data['type']))\n#now, final dataframe\nfinal_df = scaled_df.join(dummy_df, how = 'outer')","ffbcf39c":"X = final_df #dataset that we scaled and preprocessed\ny = data['isFraud'] #the column from our original dataset will be our label\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #use this random state to match my results only","478c4f3f":"rfc = RandomForestClassifier() #using default values\nrfc.fit(X_train,y_train)\n\ny_pred = rfc.predict(X_test)","5bfcbcec":"# \nprint(\"Classification Report for Logistic Regression undersampled Classifier: \\n\", classification_report(X_test, y_pred))\nprint(\"Confusion Matrix of Logistic Regression undersampled Classifier: \\n\", confusion_matrix(X_test, y_pred))\n# plot_precision_recall(y_test, clf.predict_proba(X_test)[:,1])","f78f0c98":"data = pd.read_csv('..\/input\/PS_20174392719_1491204439457_log.csv')","de2af7d0":"data = data.rename(columns = {'oldbalanceOrg': 'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \n                                    'oldbalanceDest':'oldBalanceDest', 'newbalanceDest' : 'newBalanceDest'})","a7d15b1d":"X = data.loc[(data.type == 'CASH_OUT') | (data.type == 'TRANSFER')]\nrandomState = 5\nnp.random.seed(randomState)","f0478762":"Y = X['isFraud']\ndel X['isFraud']\n\n\ndel X['nameDest'] \ndel X['nameOrig']\ndel X['isFlaggedFraud']","852d6544":"#Binary-encoding of labelled data in 'type'\nX.loc[X.type == 'TRANSFER', 'type'] = 0\nX.loc[X.type == 'CASH_OUT', 'type'] = 1\n\nX.type = X.type.astype(int)","7b303eb4":"X_fraud = X.loc[Y==1]\nX_nonFraud = X.loc[Y==0]","31aee448":"X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = randomState)","6f380e11":"weights = (Y==0).sum()\/(1.0 *  (Y==1).sum())\nxgb_cls = xgb.XGBClassifier(max_depth = 3, scale_pos_weight = weights, n_jobs = 4)\n\ny_pred = xgb_cls.fit(X_train, y_train).predict_proba(X_test)","559f7a09":"\nprint(\"Classification Report for Logistic Regression undersampled Classifier: \\n\", classification_report(X_test, y_pred))\nprint(\"Confusion Matrix of Logistic Regression undersampled Classifier: \\n\", confusion_matrix(X_test, y_pred))\nplot_precision_recall(testY, clf.predict_proba(X_test)[:,1])","84dce9b6":"#### Random Forest","aab19e42":"## fraud-detection-xgboost-lightgbm","333ffaf4":"## detecting-evil-money","2e409799":"# PaySim","2a581e56":"## ## predicting-fraud-in-financial-payment-services","3828d291":"## simple-prediction","8771f77b":"#### XGB classifier","be414b48":"## eda-and-fraud-detection","ab3a2486":"## xgboost-auc-0-99831","6181f16d":"## 4-financial-fraud-detection-xgboost","5b173611":"#### KNeighbours","7edc2076":"#### Logistic Regression","87f53f5c":"## Fraud Detection (XGBoost, LightGBM)","b58726ea":"#### XGBoost Classifier ","f29f1a4d":"# Notebooks","e962c64b":"## ml-anomaly-detection","4f81c21c":"### Feature engineering","5d595766":"#### XGBoost"}}