{"cell_type":{"5e5665ba":"code","0603327b":"code","eb994f37":"code","ac8bc258":"code","5231353c":"code","1f60b5f0":"code","c1175b6e":"code","25cb3dfc":"code","ecbc9f0f":"code","db19c0b7":"code","fc03e818":"code","5ca29fb5":"code","ef2b6666":"code","bfd24952":"code","fc6ef1d7":"code","ebe42583":"code","c931ca03":"code","b7355f76":"code","f6e5ec1c":"code","6c437efd":"markdown","91203327":"markdown","c70af2ad":"markdown","c3ab37a8":"markdown","b79da732":"markdown","3631ae34":"markdown","273c9ad5":"markdown","36c61ef6":"markdown","3b5ab957":"markdown","391c8c61":"markdown","3904a925":"markdown","a1dc6c13":"markdown","728343fa":"markdown","db38d9fd":"markdown","b41da440":"markdown","7dc41753":"markdown","e56ead59":"markdown"},"source":{"5e5665ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0603327b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import DenseNet121","eb994f37":"flower_types=['dandelion','daisy','tulip','rose','sunflower']\ndata_dir = '..\/input\/flowers-recognition\/flowers\/'\ntrain_dir = os.path.join(data_dir)","ac8bc258":"train_data = []\nfor flower_id, sp in enumerate(flower_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), flower_id, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'FlowerId','Flower Type'])\ntrain.tail()","5231353c":"# Randomize the order of training set\nSEED = 42\ntrain = train.sample(frac=1, random_state=SEED) \ntrain.index = np.arange(len(train)) # Reset indices\ntrain.head()","1f60b5f0":"# Plot a histogram\nplt.hist(train['FlowerId'])\nplt.title('Frequency Histogram of Flower Types')\nplt.figure(figsize=(12, 12))\nplt.show()","c1175b6e":"def plot_defects(flower_types, rows, cols):\n    fig, ax = plt.subplots(rows, cols, figsize=(12, 12))\n    flower_files = train['File'][train['Flower Type'] == flower_types].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, flower_files[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\nplot_defects('tulip', 5, 5)","25cb3dfc":"IMAGE_SIZE = 64\n\ndef read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath)) # Loading a color image is the default flag\n# Resize image to target size\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)","ecbc9f0f":"X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values)):\n    image = read_image(file)\n    if image is not None:\n        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n# Normalize the data\nX_Train = X_train \/ 255\nprint('Train Shape: {}'.format(X_Train.shape))","db19c0b7":"Y_train = train['FlowerId'].values\nY_train = to_categorical(Y_train, num_classes=5)","fc03e818":"BATCH_SIZE = 64\n\n# Split the train and validation sets \nX_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.2, random_state=SEED)","5ca29fb5":"fig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(X_train[i])\n    ax[i].set_title(flower_types[np.argmax(Y_train[i])])","ef2b6666":"EPOCHS = 50\nSIZE=64\nN_ch=3","bfd24952":"def build_densenet():\n    densenet = DenseNet121(weights='imagenet', include_top=False)\n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = densenet(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(5,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","fc6ef1d7":"model = build_densenet()\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\n\ndatagen.fit(X_train)\n# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=2,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))","ebe42583":"#model = load_model('..\/output\/kaggle\/working\/model.h5')\nfinal_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","c931ca03":"Y_pred = model.predict(X_val)\n\nY_pred = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_val, axis=1)\n\ncm = confusion_matrix(Y_true, Y_pred)\nplt.figure(figsize=(12, 12))\nax = sns.heatmap(cm, cmap=plt.cm.Greens, annot=True, square=True, xticklabels=flower_types, yticklabels=flower_types)\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","b7355f76":"# accuracy plot \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# loss plot\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f6e5ec1c":"from skimage import io\nfrom keras.preprocessing import image\n#path='imbalanced\/Scratch\/Scratch_400.jpg'\nimg = image.load_img('..\/input\/flowers-recognition\/flowers\/sunflower\/3893436870_034b79d118_n.jpg', grayscale=False, target_size=(64, 64))\nshow_img=image.load_img('..\/input\/flowers-recognition\/flowers\/sunflower\/3893436870_034b79d118_n.jpg', grayscale=False, target_size=(200, 200))\nflower_types=['dandelion','daisy','tulip','rose','sunflower']\n\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx \/= 255\n\ncustom = model.predict(x)\nprint(custom[0])\n\n\nx = np.array(x, 'float32')\n#x = x.reshape([64, 64]);\n\n#plt.gray()\nplt.imshow(show_img)\nplt.show()\n\na=custom[0]\nind=np.argmax(a)\n        \nprint('Prediction:',flower_types[ind])","6c437efd":"# Creating Training Dataset","91203327":"# Creating Y_train Dataset","c70af2ad":"# Importing Libraries","c3ab37a8":"# Building DenseNet121","b79da732":"# Showing Flower From Different Types","3631ae34":"# Display Images from a Flower Type","273c9ad5":"# Confusion Matrix","36c61ef6":"# Accuracy and Loss Curve","3b5ab957":"# Data Augmentation and Model Fitting","391c8c61":"# Creating X_train Dataset","3904a925":"# Creating Train and Validation Dataset","a1dc6c13":"# Final Accuracy","728343fa":"# Resizing and Image Reading ","db38d9fd":"# Testing Prediction ","b41da440":"# Randomizing Dataset","7dc41753":"# Histogram of Flower Types","e56ead59":"# Declaring Class Types and Data Folder"}}