{"cell_type":{"476d9ea9":"code","d03b816f":"code","b4b6c7d9":"code","70c07263":"code","f968e0f7":"code","5258fc5a":"code","14e768ef":"code","5438d433":"code","90927119":"code","737a1378":"code","ab811486":"markdown","93acfe9a":"markdown","316d3f23":"markdown"},"source":{"476d9ea9":"import sqlalchemy\nimport pandas as pd\nfrom pandas.io import sql\nimport calendar\nimport os\nimport requests\nimport json\nfrom bs4 import BeautifulSoup\n\n\nfrom time import sleep\nimport random\n\nimport re\nimport ast\nimport datetime as datetime\nfrom pytz import timezone\nimport requests, zipfile, io\n\nimport csv\nimport numpy as np\n\nimport zipfile\nimport sys\nimport time\n#import camelot\nfrom urllib3.util.retry import Retry\nfrom requests.adapters import HTTPAdapter\nfrom selenium import webdriver\nimport warnings\nwarnings.filterwarnings('ignore')\nimport xml.etree.ElementTree as ET\n\n\n\nfrom selenium import webdriver\nfrom selenium.common.exceptions import TimeoutException\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\n\nfrom selenium.common.exceptions import WebDriverException\n\n\n","d03b816f":"import re\nimport datetime as datetime\nfrom pytz import timezone\nfrom bs4 import BeautifulSoup\nimport json\nimport requests\nimport os\nimport sqlalchemy\nimport pandas as pd\n\nimport random\nimport time\nimport numpy as np\nimport math\nfrom selenium.common.exceptions import NoSuchElementException\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\n\nimport shutil\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium import webdriver\nfrom tqdm import tqdm\nimport sys\n\n","b4b6c7d9":"site_url = \"https:\/\/www.talabat.com\/uae\/restaurants\"\ndriver = webdriver.Chrome('\/Users\/Bharath\/chromedriver')  \ndriver.get(site_url)\ndriver.maximize_window()\nfinal_df = pd.DataFrame()\n\ni=1\nwhile (i<301):\n    driver.find_element_by_tag_name('body').send_keys(Keys.END)\n    i = i+1\n    sleep(0.2)\nmain_soup = BeautifulSoup(driver.page_source)\n\n","70c07263":"soup = main_soup.findAll('div', attrs = {'class':'col-lg-3 col-md-3 col-sm-4 col-xs-8 new-rest-item ng-scope'})","f968e0f7":"len(soup)","5258fc5a":"Restaurant = []\nCuisine = []\nfor i in range(len(soup)):\n    Restaurant.append(soup[i].findAll('p')[0].text)\n    Cuisine.append(soup[i].findAll('p')[1].text)\n    \n    ","14e768ef":"restaurant_database = pd.DataFrame({'Restaurant':Restaurant,'Cuisine':Cuisine})","5438d433":"restaurant_database.to_excel('Talabat_restaurants_data.xlsx',index=False)","90927119":"restaurant_database.to_csv('Talabat_restaurants_data.csv',index=False)","737a1378":"driver.quit()","ab811486":"# Data Scraping","93acfe9a":"![](http:\/\/www.promptcloud.com\/wp-content\/uploads\/2020\/02\/001-efficient-web-scraping.png)","316d3f23":"This is an example for Data Scraping using BeautifulSoup and Selenium tools."}}