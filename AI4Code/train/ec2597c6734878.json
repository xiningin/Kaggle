{"cell_type":{"376ad2b9":"code","ce2814b3":"code","75364c40":"code","490e5446":"code","abc583a2":"code","3f0765f1":"code","f90179bb":"code","47049648":"code","fd1deaf0":"code","6e285a18":"code","8239946e":"code","034c1c7b":"code","143c8bd2":"code","5a61578a":"code","006e12bb":"code","84ac5c59":"code","e2e2cdd7":"markdown","ad9edb83":"markdown","04f70600":"markdown","7fcb7581":"markdown","124f74f2":"markdown","de3f81e3":"markdown","62383cfc":"markdown","e19faf63":"markdown","925f9b34":"markdown","6ff8c801":"markdown","7fbed7c6":"markdown","c5c9a8e3":"markdown"},"source":{"376ad2b9":"# Load usefull libraries and helper functions\nimport os\n\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport matplotlib.image as mpimg\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","ce2814b3":"# Initial files are in r'input\\raw' directory\nroot_dir = '\/kaggle\/input\/geological-image-similarity\/geological_similarity'\n\n# Get all filenames in folder: \nimg_files = [os.path.join(path, name) for path, subdirs, files in os.walk(root_dir) for name in files]\nprint('dataset length = ', len(img_files))\nprint('First 5 files:', img_files[0:5])","75364c40":"# Dataset consists of 6 folders each containing around 5k photographs\nsubfolders = [f.path for f in os.scandir(root_dir) if f.is_dir()]\nfor subfolder in subfolders:\n    print(subfolder.split('\/')[-1], ':', len(os.listdir(subfolder)), 'images')","490e5446":"# Let's preview some randomly selected images of each class\nn_show = 15\n\nsubfolders = [f.path for f in os.scandir(root_dir) if f.is_dir()]\n\nfig, axes = plt.subplots(len(subfolders), n_show, figsize = (n_show,6))\n# Preview images:\nfor row_idx, subfolder in enumerate(subfolders):    \n    filenames = [f.path for f in os.scandir(subfolder)]   \n    files_to_preview = random.sample(filenames, n_show)\n    for col_idx, path in enumerate(files_to_preview):\n        image = mpimg.imread(path)\n        axes[row_idx, col_idx].imshow(image)\n        axes[row_idx, col_idx].set_xticklabels([])\n        axes[row_idx, col_idx].set_yticklabels([])\n\n# Set labels:\nfor ax, row in zip(axes[:,0], subfolders):\n    ax.set_ylabel(row.split('\/')[-1], rotation=90, size='large')\n\nplt.show()","abc583a2":"# Create Torch Dataset from input data:\nclass GeologicalDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, root_dir, transform=None, train=True):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.root_dir = root_dir\n        self.transform = transform\n        self.train = train\n        \n        img_names_list = [os.path.join(path, name) for path, subdirs, files in os.walk(root_dir) for name in files]\n        label_to_idx = {\n            'andesite': 0,\n            'gneiss': 1,\n            'marble': 2,\n            'quartzite': 3,\n            'rhyolite': 4,\n            'schist': 5\n            }\n        labels_list = [label_to_idx[os.path.join(path, name).split('\/')[-2]]\n                       for path, subdirs, files in os.walk(root_dir)\n                       for name in files\n                      ]\n        \n        img_names_train, img_names_test, labels_train, labels_test = train_test_split(\n            img_names_list,\n            labels_list,\n            test_size=0.1,\n            shuffle=True,\n            random_state=42\n        )\n\n        if self.train == True:\n            self.img_names = img_names_train\n            self.labels = labels_train\n        else:\n            self.img_names = img_names_test\n            self.labels = labels_test\n            \n    def __len__(self):\n        return len(self.img_names)\n\n    def __getitem__(self, idx):        \n        image = mpimg.imread(self.img_names[idx])\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","3f0765f1":"# Create transforms for train and test\n    # All data transformed to Tensor and Normalized (for each channel) - see the parameters below\n    # random horizontal and vertical flips are used for train\ntrain_transform = transforms.Compose([\n    transforms.ToPILImage(), \n    transforms.RandomHorizontalFlip(0.5),\n    transforms.RandomVerticalFlip(0.5),\n    #transforms.RandomRotation(degrees=(0,360)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5080, 0.5196, 0.5195],\n                         std=[0.1852, 0.1995, 0.2193])\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5080, 0.5196, 0.5195],\n                         std=[0.1852, 0.1995, 0.2193])\n])","f90179bb":"train_set = GeologicalDataset(root_dir = root_dir,transform=train_transform, train = True)\ntest_set = GeologicalDataset(root_dir = root_dir,transform=test_transform, train = False)\n\nprint('train_set:', len(train_set))\nprint('test_set:', len(test_set))\n\nbatch_size = 1024\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)","47049648":"# This is how the mean and std parameters were found for the dataset\n'''\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=100000)\nfor images, labels in train_loader:\n    for channel in range(3):\n        print('channel', channel, 'mean', torch.mean(images[:,channel,:,:]), 'std', torch.std(images[:,channel,:,:]))'''","fd1deaf0":"class CNN(nn.Module):\n    \n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        self.nn = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Flatten(),\n            nn.Linear(in_features=2304, out_features=512),\n            nn.Dropout2d(0.25),\n            nn.Linear(in_features=512, out_features=128),\n            )\n\n        self.linear = nn.Linear(in_features=128, out_features=6)\n        \n    def forward(self, x):\n        embedding = self.nn(x)\n        x = self.linear(embedding)\n        return embedding, x\n        \nmodel = CNN()\nprint(model)","6e285a18":"model = CNN()\n\n# model.load_state_dict(torch.load('model_state_dict.pth')) # load previously trained model\n\nloss_func = nn.CrossEntropyLoss()\n\nlearning_rate = 0.001\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","8239946e":"%%time\n# Train the model\n\nwriter = SummaryWriter()\n                                  \nnum_epochs = 30\n\nfor epoch in range(num_epochs):\n    \n    train_accuracy_epoch=[]\n    for train_batch_idx, (images, labels) in enumerate(train_loader):\n        model.train()\n        optimizer.zero_grad()\n        _, outputs = model(images)        \n        predictions = torch.max(outputs, 1)[1]\n        train_accuracy = accuracy_score(predictions, labels)\n        train_accuracy_epoch.append(train_accuracy)\n        loss = loss_func(outputs, labels)                \n        loss.backward()        \n        optimizer.step()\n    \n    avg_train_accuracy_epoch = np.mean(train_accuracy_epoch)\n    writer.add_scalar(\"Train_accuracy\", avg_train_accuracy_epoch, epoch)\n          \n    # At the end of epoch - evaluate test set accuracy\n    test_accuracy_epoch=[]\n    for test_batch_idx, (images, labels) in enumerate(test_loader):\n        model.eval()       \n        _, outputs = model(images)\n        predictions = torch.max(outputs, 1)[1]\n        test_accuracy = accuracy_score(predictions, labels)\n        test_accuracy_epoch.append(test_accuracy)        \n    \n    avg_test_accuracy_epoch = np.mean(test_accuracy_epoch)\n    writer.add_scalar(\"Test_accuracy\", avg_test_accuracy_epoch, epoch)\n    \n    print('Epoch: ', epoch,\n          '  Train accuracy:', round(avg_train_accuracy_epoch,4),\n          '  Test accuracy:', round(avg_test_accuracy_epoch,4)\n          )\n\nwriter.flush()\n\n# run in the terminal to see the progress: \n# tensorboard --logdir runs\n\n# Save the trained weights of the model\ntorch.save(model.state_dict(), 'model_state_dict.pth')","034c1c7b":"def get_embedding(file, model):\n    image = mpimg.imread(file)\n    image = test_transform(image)\n    image = image.unsqueeze(0)\n    model.eval()\n    with torch.no_grad():\n        emb, _ = model(image)\n    return emb.numpy()","143c8bd2":"%%time\nimage_embeddings = np.zeros((len(img_files), 128))\nfor idx, file in enumerate(img_files):\n    image_embeddings[idx] = get_embedding(file, model=model)\nprint(image_embeddings.shape)","5a61578a":"# Select random image from test\nrandom_file = random.choice(img_files)\n\n# Get the embedding for this image\nemb = get_embedding(random_file, model=model)\n\nprint(random_file)\nplt.rcParams[\"figure.figsize\"] = (3,3)\nimage = mpimg.imread(random_file)\nplt.imshow(image)\nplt.show()","006e12bb":"similarities = cosine_similarity(emb, image_embeddings)","84ac5c59":"# Select top n-similar file indeces\nK=5\nids = np.flip(similarities.argsort()[0])[0:K]\n\nfor index in ids:\n    image = img_files[index]\n    print(image)\n    image = mpimg.imread(image)\n    plt.imshow(image)\n    plt.show()","e2e2cdd7":"## Select Random Test Image","ad9edb83":"## Preview K-Most Similar Images to the Selected Image","04f70600":"## Load Files","7fcb7581":"## Preview the Images","124f74f2":"## Create CNN Architecture\n### Output for the penultimate layer (embedding) is also provided as output","de3f81e3":"## Calculate Embeddings for all Images","62383cfc":"## Instantiate the Model","e19faf63":"## Embeddings","925f9b34":"**No wonder that the first image found is the same image that was randomly selected - that's a good check that everything is working fine. If the new file is loaded, this function will preview K-closest files**","6ff8c801":"## Create PyTorch Dataset from the Data","7fbed7c6":"# Gelogical Image Similarity\n**This is a personal ML project on [Geological Image Similarity Dataset](https:\/\/www.kaggle.com\/tanyadayanand\/geological-image-similarity)**  \n\n### BACKGROUND\nA geology research company wants to create a tool for identifying interesting patterns in their imagery data. This tool\nwill possess a search capability whereby an analyst provides an image of interest and is presented with other images\nwhich are similar to it.\n\n### GOAL\nTask is to create the machine learning component for this image similarity application. The machine learning\nmodel should return the top K images that are most similar to this image based on a single image input.\n\n### ABOUT the DATA:\nThe data includes 6 different classes of 5000 28X28 RGB images (total of 29998 images)","c5c9a8e3":"## Calculate pairwise similarities between the selected image and all images "}}