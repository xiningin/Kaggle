{"cell_type":{"0eb5d95d":"code","c7e73598":"code","195ba308":"code","65d0b8a4":"code","2bf1d3d2":"code","50f6eef8":"code","bf3b8b48":"code","ff534e24":"code","53c0d564":"code","70241bde":"code","03d65952":"code","ef3ed494":"code","2f354fc3":"code","298f318f":"code","5168246e":"code","b526b7b8":"code","6f92a175":"code","f919e923":"code","5f7151db":"code","80c2ac38":"code","f7a7a3ae":"code","9a8f660a":"code","bacafa82":"code","5521af6f":"code","bbd577eb":"code","f2adcdb2":"code","47a945fe":"code","209049ff":"code","c2bb8552":"code","27ccee61":"markdown","b3a59cf0":"markdown","463db764":"markdown","13ec98fb":"markdown","d932752e":"markdown","5d7c72d8":"markdown","1719b9a6":"markdown","a3ed98cd":"markdown","f5f52091":"markdown","de134d65":"markdown","74ce43f6":"markdown","2a88cf72":"markdown","56fce679":"markdown","6b5e38e5":"markdown","a49716e7":"markdown","b0e4b0c0":"markdown","7cacb4c5":"markdown","2da05bf7":"markdown"},"source":{"0eb5d95d":"##Importing the packages\n#Data processing packages\nimport numpy as np \nimport pandas as pd \n\n#Visualization packages\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n#Machine Learning packages\nfrom sklearn.svm import SVC,NuSVC\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\t\nfrom sklearn.metrics import confusion_matrix\n\n#Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","c7e73598":"#Import Employee Attrition data\ndata=pd.read_csv('..\/input\/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndata.head()","195ba308":"data.info()","65d0b8a4":"data['Over18'].value_counts()","2bf1d3d2":"data.describe()","50f6eef8":"#These fields does not add value, hence removed\ndata = data.drop(['EmployeeCount','Over18'], axis = 1)","bf3b8b48":"#A lambda function is a small anonymous function.\n#A lambda function can take any number of arguments, but can only have one expression.\ndata['Attrition']=data['Attrition'].apply(lambda x : 1 if x=='Yes' else 0)","ff534e24":"data.head()","53c0d564":"#This function is used to convert Categorical values to Numerical values\ndata=pd.get_dummies(data)","70241bde":"data.head()","03d65952":"#Separating Feature and Target matrices\nX = data.drop(['Attrition'], axis=1)\ny=data['Attrition']","ef3ed494":"#Feature scaling is a method used to standardize the range of independent variables or features of data.\n#Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. \nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nX = scale.fit_transform(X)","2f354fc3":"# Split the data into Training set and Testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size =0.2,random_state=42)","298f318f":"#Function to Train and Test Machine Learning Model\ndef train_test_ml_model(X_train,y_train,X_test,Model):\n    model.fit(X_train,y_train) #Train the Model\n    y_pred = model.predict(X_test) #Use the Model for prediction\n\n    # Test the Model\n    from sklearn.metrics import confusion_matrix\n    cm = confusion_matrix(y_test,y_pred)\n    accuracy = round(100*np.trace(cm)\/np.sum(cm),1)\n\n    #Plot\/Display the results\n    cm_plot(cm,Model)\n    print('Accuracy of the Model' ,Model, str(accuracy)+'%')","5168246e":"#Function to plot Confusion Matrix\ndef cm_plot(cm,Model):\n    plt.clf()\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n    classNames = ['Negative','Positive']\n    plt.title('Comparison of Prediction Result for '+ Model)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=45)\n    plt.yticks(tick_marks, classNames)\n    s = [['TN','FP'], ['FN', 'TP']]\n    for i in range(2):\n        for j in range(2):\n            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n    plt.show()","b526b7b8":"from sklearn.svm import SVC,NuSVC  #Import packages related to Model\nModel = \"SVC\"\nmodel=SVC() #Create the Model\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","6f92a175":"from sklearn.svm import SVC,NuSVC  #Import packages related to Model\nModel = \"NuSVC\"\nmodel=NuSVC(nu=0.285)#Create the Model\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","f919e923":"from xgboost import XGBClassifier  #Import packages related to Model\nModel = \"XGBClassifier()\"\nmodel=XGBClassifier() #Create the Model\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","5f7151db":"from sklearn.neighbors import KNeighborsClassifier  #Import packages related to Model\nModel = \"KNeighborsClassifier\"\nmodel=KNeighborsClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","80c2ac38":"from sklearn.naive_bayes import GaussianNB,MultinomialNB  #Import packages related to Model\nModel = \"GaussianNB\"\nmodel=GaussianNB()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","f7a7a3ae":"from sklearn.linear_model import SGDClassifier, LogisticRegression #Import packages related to Model\nModel = \"SGDClassifier\"\nmodel=SGDClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","9a8f660a":"from sklearn.linear_model import SGDClassifier, LogisticRegression #Import packages related to Model\nModel = \"LogisticRegression\"\nmodel=LogisticRegression()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","bacafa82":"from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier #Import packages related to Model\nModel = \"DecisionTreeClassifier\"\nmodel=DecisionTreeClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","5521af6f":"from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier #Import packages related to Model\nModel = \"ExtraTreeClassifier\"\nmodel=ExtraTreeClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","bbd577eb":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis #Import packages related to Model\nModel = \"QuadraticDiscriminantAnalysis\"\nmodel = QuadraticDiscriminantAnalysis()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","f2adcdb2":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis #Import packages related to Model\nModel = \"LinearDiscriminantAnalysis\"\nmodel=LinearDiscriminantAnalysis()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","47a945fe":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Import packages related to Model\nModel = \"RandomForestClassifier\"\nmodel=RandomForestClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","209049ff":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Import packages related to Model\nModel = \"AdaBoostClassifier\"\nmodel=AdaBoostClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","c2bb8552":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Import packages related to Model\nModel = \"GradientBoostingClassifier\"\nmodel=GradientBoostingClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","27ccee61":"### **Check and remediate if there are any null values**","b3a59cf0":"### **PERFORM PREDICTIONS USING MACHINE LEARNING ALGORITHMS**","463db764":"\"Attrition\" field has values **Yes\/No**, however for machin learning algorithms we need numeric values.\nHence translating **Yes\/No** to binary **1\/0**","13ec98fb":"### **Perform datatype conversion or translation wherever required**","d932752e":"### **Convert Categorical values to Numeric Values**","5d7c72d8":"### **Split the data into Training set and Testing set**","1719b9a6":"**COMMENT:** It can be seen from the difference in the output of **data.head()** before and after the coversion that now **ALL the fields have numerical values.**","a3ed98cd":"### **Import data**","f5f52091":"### **Import packages**","de134d65":"**COMMENT:** Above output shows that there are No Null values.","74ce43f6":"### The dataset is about employee attrition. This analysis can discover if any particular factors or patterns that lead to attrition. If so, employers can take certain precausion to prevent attrition which in employer of view, employee attrition is a loss to company, in both monetary and non-monetary. ","2a88cf72":"### **Function definition**","56fce679":"### **Scaling the data values to standardize the range of independent variables**","6b5e38e5":"# IBM_HR_Analytics_Employee_Attrition_Performance ","a49716e7":"**COMMENT:** Standard deviation(std) for the fields \"EmployeeCount\" and .\"StandardHours\" are ZERO.  Hence these fields does not add value, hence they can be removed.","b0e4b0c0":"### **Check and remove if there are any fields which does not add value**","7cacb4c5":"### **Separating the Feature and Target Matrices**","2da05bf7":"**COMMENT:** From the above output ALL the employees are above 18, so this field does not add any value."}}