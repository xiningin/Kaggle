{"cell_type":{"db1b7af4":"code","2f786e63":"code","78751ab2":"code","e5a9e0be":"code","b65b0512":"code","bb375e07":"code","0ebcf078":"code","7e6f9906":"code","eac02f2e":"code","b13b2922":"code","57ff96c1":"code","b17106af":"code","6febe6f5":"markdown","ea6d4111":"markdown","612fa268":"markdown","f3e0ce0f":"markdown","bfd0b727":"markdown","652c2a55":"markdown","bf085f7c":"markdown","f0f14f66":"markdown","de407f61":"markdown","9564561a":"markdown"},"source":{"db1b7af4":"import numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score","2f786e63":"# Load the iris dataset\niris = datasets.load_iris()\n\n# Create a list of feature names\nfeat_labels = ['Sepal Length','Sepal Width','Petal Length','Petal Width']\n\n# Create X from the features\nX = iris.data\n\n# Create y from output\ny = iris.target","78751ab2":"# View the features\nX[0:5]","e5a9e0be":"# View the target data\ny","b65b0512":"# Split the data into 40% test and 60% training\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)","bb375e07":"# Create a random forest classifier\nclf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n\n# Train the classifier\nclf.fit(X_train, y_train)\n\n# Print the name and gini importance of each feature\nfor feature in zip(feat_labels, clf.feature_importances_):\n    print(feature)","0ebcf078":"# Create a selector object that will use the random forest classifier to identify\n# features that have an importance of more than 0.15\nsfm = SelectFromModel(clf, threshold=0.15)\n\n# Train the selector\nsfm.fit(X_train, y_train)","7e6f9906":"# Print the names of the most important features\nfor feature_list_index in sfm.get_support(indices=True):\n    print(feat_labels[feature_list_index])","eac02f2e":"# Transform the data to create a new dataset containing only the most important features\n# Note: We have to apply the transform to both the training X and test X data.\nX_important_train = sfm.transform(X_train)\nX_important_test = sfm.transform(X_test)\n","b13b2922":"# Create a new random forest classifier for the most important features\nclf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n\n# Train the new classifier on the new dataset containing the most important features\nclf_important.fit(X_important_train, y_train)","57ff96c1":"# Apply The Full Featured Classifier To The Test Data\ny_pred = clf.predict(X_test)\n\n# View The Accuracy Of Our Full Feature (4 Features) Model\naccuracy_score(y_test, y_pred)","b17106af":"# Apply The Full Featured Classifier To The Test Data\ny_important_pred = clf_important.predict(X_important_test)\n\n# View The Accuracy Of Our Limited Feature (2 Features) Model\naccuracy_score(y_test, y_important_pred)","6febe6f5":"**Train A Random Forest Classifier**","ea6d4111":"**Compare The Accuracy Of Our Full Feature Classifier To Our Limited Feature Classifier**","612fa268":"**As can be seen by the accuracy scores, our original model which contained all four features is 93.3% accurate while the our \u2018limited\u2019 model which contained only two features is 90% accurate. Thus, for a small cost in accuracy we halved the number of features in the model.**","f3e0ce0f":"The scores above are the importance scores for each variable. There are two things to note. First, all the importance scores add up to 100%. Second, Petal Length and Petal Width are far more important than the other two features. Combined, Petal Length and Petal Width have an importance of ~0.86! Clearly these are the most importance features.","bfd0b727":"**Split The Data Into Training And Test Sets**","652c2a55":"This tutorial is made to learn about feature selection in random forest to increase the accuracy of your random forest classifier.","bf085f7c":"**Identify And Select Most Important Features**","f0f14f66":"**Create A Data Subset With Only The Most Important Features\n**","de407f61":"**CREATE THE DATA..**\nThe data used in this tutorial is from famous iris dataset.\nThe Iris target data contains 50 samples from three species of Iris, y and four feature variables, X.","9564561a":"**Train A New Random Forest Classifier Using Only Most Important Features**"}}