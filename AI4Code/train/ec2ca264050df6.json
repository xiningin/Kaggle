{"cell_type":{"9543fce0":"code","2282ea57":"code","dab7c91b":"code","6d709c8c":"code","d53b7c62":"code","02bfd16d":"code","3b9ce6d2":"code","62205169":"code","0bdf0964":"markdown","dfd872e0":"markdown","0b61dc2f":"markdown","f52503ba":"markdown"},"source":{"9543fce0":"import pandas as pd\n\ntrain_data = pd.read_csv('\/kaggle\/input\/mnist-in-csv\/mnist_train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/mnist-in-csv\/mnist_test.csv')\n\n# X\ntrain_labels = train_data.label\ntest_labels = test_data.label\n# y\ntrain_images = train_data.iloc[:, 1:].to_numpy()\ntest_images = test_data.iloc[:, 1:].to_numpy()\n\nprint('Train size : ' , train_labels.shape)\nprint('Test  size : ', test_labels.shape)","2282ea57":"# For X \n\nimport numpy as np\n\n# 1. Reshape \ntrain_images = train_images.reshape((60000, 28, 28))\ntest_images = test_images.reshape((10000, 28, 28))\n\n\n# 2. Sacle\ntrain_images = train_images.astype('float32')\/255\ntest_images = test_images.astype('float32')\/255\n\n# 3. Bigger size. (becuase image is 2D, we have to repeat on axises 1 and 2 )\ntrain_images = np.repeat(train_images, 2, axis=1) \ntrain_images = np.repeat(train_images, 2, axis=2)\n\ntest_images = np.repeat(test_images, 2, axis=1)\ntest_images = np.repeat(test_images, 2, axis=2)\n\n# 4. GrayScale to  RGB\ntrain_images = np.stack((train_images,) * 3, axis=-1)\ntest_images = np.stack((test_images,) * 3, axis=-1)\n\n\n# 5. Valid \nvalid_images = train_images[50000:]\ntrain_images = train_images[:50000]","dab7c91b":"# For y\n\nfrom keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\nvalid_labels = train_labels[50000:]\ntrain_labels = train_labels[:50000]","6d709c8c":"from keras.layers import Input, Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten, Add\nfrom keras.models import Model\n\n# VGG16 + Skip Connection\n_input = Input((56,56,3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\nshortcut = pool1 # Skip connection\nshortcut = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(shortcut)\nshortcut  = MaxPooling2D((16, 16))(shortcut)\n\n\nconv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\nconv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\npool2  = MaxPooling2D((2, 2))(conv4)\n\nconv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\nconv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\nconv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\npool3  = MaxPooling2D((2, 2))(conv7)\n\nconv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\nconv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\nconv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\npool4  = MaxPooling2D((2, 2))(conv10)\n\nconv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\nconv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\nconv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\npool5  = MaxPooling2D((2, 2))(conv13)\n\nadd = Add()([shortcut, pool5]) # Skip connection joined\n\nflat   = Flatten()(add)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\nvgg16_skip_model  = Model(inputs=_input, outputs=output)\n\n# VGG16 \n_input = Input((56,56,3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\n\nconv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\nconv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\npool2  = MaxPooling2D((2, 2))(conv4)\n\nconv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\nconv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\nconv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\npool3  = MaxPooling2D((2, 2))(conv7)\n\nconv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\nconv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\nconv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\npool4  = MaxPooling2D((2, 2))(conv10)\n\nconv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\nconv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\nconv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\npool5  = MaxPooling2D((2, 2))(conv13)\n\nflat   = Flatten()(pool5)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\nvgg16_model  = Model(inputs=_input, outputs=output)\n\n\n# CNN \n_input = Input((56,56,3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\nflat   = Flatten()(pool1)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\ncnn_model  = Model(inputs=_input, outputs=output)\n\n# Dense\n_input = Input((56,56,3)) \nflat   = Flatten()(_input)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\ndense_model  = Model(inputs=_input, outputs=output)","d53b7c62":"#vgg16_model.summary()","02bfd16d":"# Training \nfrom keras import optimizers\n\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']\noptimizer = optimizers.RMSprop(lr=1e-5)\nbatch_size = 128\nepochs = 5\n\n#VGG16_skip\nvgg16_skip_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory1 = vgg16_skip_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)\n\n#VGG16\nvgg16_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory2 = vgg16_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)\n\n#CNN\ncnn_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory3 = cnn_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)\n\n#Dense\ndense_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory4 = dense_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)","3b9ce6d2":"import matplotlib.pyplot as plt\n\nhistories = [history1, history2, history3, history4]\ncolors = ['red','blue','green', 'orange']\nlegends = ['VGG16+skip', 'VGG16','CNN', 'Dense']\nf =  plt.figure(figsize=(10,10))\n\nfor i, history in enumerate(histories):\n\n    try:\n          acc = history.history['accuracy']\n          val_acc = history.history['val_accuracy']\n    except:\n          acc = history.history['acc']\n          val_acc = history.history['val_acc']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n\n    plt.plot(epochs, acc,'--', color=colors[i], label=legends[i]+'Train')\n    plt.plot(epochs, val_acc, color=colors[i], label=legends[i]+'Validation')\n    plt.title('Validation accuracy')\n    plt.legend()\n","62205169":"test_loss, test_acc = vgg16_skip_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"vgg16_skip\", \"test_acc\", test_acc, \"test_loss\", test_loss)\n\ntest_loss, test_acc = vgg16_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"vgg16     \", \"test_acc\", test_acc, \"test_loss\", test_loss)\n\ntest_loss, test_acc = cnn_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"cnn       \", \"test_acc\", test_acc, \"test_loss\", test_loss)\n\ntest_loss, test_acc = dense_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"dense     \", \"test_acc\", test_acc, \"test_loss\", test_loss)","0bdf0964":"## 2. Data Preprocessing\n\n### What to do \n\n#### 1) Data Handling : reshape the data (600000, 784) to (60000,28,28)\n\n#### 2) Data Handling : Rescale 0~255 to 0~1 \n\n#### 3) Data Handling : 28 x 28 size is too small. make the size double 56 x 56\n\n#### 4) Data Handling :It is gray scale. Lets make it RGB channels.\n\n#### 5) Data Handling :I will use valid data. \n\n#### 6) Data Handling :y to categorical. 123456789 --> One hot encoding\n\n|Data|size|\n|---|---|\n|train|50000|\n|valid|10000|\n|test|10000|\n\n","dfd872e0":"# This Notebook is about MNIST with VGG + Skip connection\ud83d\udc68\u200d\ud83c\udf93\n\nSince the first block of VGG detect the edges, I wanted to use this information when predicting the label.\n\nMy main ideas are\n\n* Deep layers (**VGG 16**)\n* First block is important (**Skip connection**)\n\n## 1. Data","0b61dc2f":"# VGG 16 layers + Skip connected layers\n\nI want to preserve the output of first block when prediction.\n\nSo I used the concept skip gram and added i to the last of the Convolutions.\n\nHere is the structure of my VGG 16 + Skip connection\n\n<br>\n\n\n![images](https:\/\/github.com\/fxnnxc\/prography-6th-deep-beomjinPark\/blob\/master\/images\/vgg16.png?raw=true)","f52503ba":"### Thank you for reading my notebook.\n\n## Feel free to comment on any things like misspell and ideas! \ud83d\ude00"}}