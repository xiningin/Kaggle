{"cell_type":{"acb11a05":"code","f5acdb9b":"code","b5544025":"code","f4cbec0c":"code","8f8ad5ac":"code","08585cb5":"code","68721751":"code","e1d938b6":"code","854813dd":"code","02d5fd14":"code","b20318b4":"code","4d2627aa":"code","8644aec7":"code","13914500":"code","04dc4509":"code","cd7de5be":"markdown","82a06be9":"markdown","c4cc7c94":"markdown","f2c3c99a":"markdown","b4cde955":"markdown","61e35571":"markdown"},"source":{"acb11a05":"import pip._internal as pip\npip.main(['install', '--upgrade', 'numpy==1.17.3'])\nimport numpy as np\nimport pandas as pd\n\nimport glob\nimport re\n\nimport warnings\n# warnings.simplefilter(action = 'ignore', category = FutureWarning)\nwarnings.filterwarnings('ignore')\n\nfrom itertools import combinations\nfrom scipy.stats import chisquare\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom xgboost import XGBClassifier\n\nfrom lwoku import get_accuracy\n\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt","f5acdb9b":"tactic_01_results = pd.read_csv('..\/input\/tactic-98-results\/tactic_01_results.csv', index_col='Id', engine='python')\n\nmodel = []\nS_test = []\nS_train = []\nfor index, row in tactic_01_results.iterrows():\n    model += [row['Model']]\n    S_test += [pd.read_csv('..\/input\/tactic-01-test-classifiers\/submission_' + row['Model'] + '.csv', index_col=0, engine='python')]\n    S_train += [pd.read_csv('..\/input\/tactic-01-test-classifiers\/train_' + row['Model'] + '.csv', index_col=0, engine='python')]","b5544025":"S_test = pd.concat(S_test, axis=1)\nS_test.columns = model\nS_test","f4cbec0c":"S_train = pd.concat(S_train, axis=1)\nS_train.columns = model\nS_train","8f8ad5ac":"tactic_01_results[['Model', 'Score']]","08585cb5":"low_scored_models = tactic_01_results[['Model', 'Score']].query('Score < 0.5')['Model'].tolist()\nlow_scored_models += ['rf']\nprint('Drop models: {}'.format(low_scored_models))\nS_test.drop(low_scored_models, axis='columns', inplace=True)\nS_train.drop(low_scored_models, axis='columns', inplace=True)","68721751":"def acc(p1, p2):\n    return np.sum(p1 == p2, axis=0) \/ float(p1.shape[0])\n\ncorr = S_test.corr(method=acc)\nf, ax = plt.subplots(figsize=(len(model), len(model)))\nsns.heatmap(corr, cmap=\"Oranges\", annot=True, fmt='.3f');","e1d938b6":"mean_corr = corr.mean()\nmean_corr","854813dd":"X = pd.read_csv('..\/input\/learn-together\/train.csv', index_col='Id', engine='python')\ny = X['Cover_Type'].copy()","02d5fd14":"# from sklearn.model_selection import GridSearchCV\n# parameters = {\n#     'n_estimators': range(5, 15),\n#     'max_depth': [3, 4, 5],\n#     'learning_rate': [x\/100 for x in range(5, 13)]\n# }\n# model = XGBClassifier(n_estimators=12, max_depth=3, learning_rate=0.08, random_state=0, n_jobs=-1)\n# clf = GridSearchCV(model, parameters, cv=5)\n# clf.fit(S_train, y)","b20318b4":"# from grid_search_table_plot import grid_search_table_plot\n# grid_search_table_plot(clf, 'learning_rate', negative=False)","4d2627aa":"# clf.best_estimator_","8644aec7":"results = pd.DataFrame(columns = ['Model combination',\n                                  'Accuracy'])\n\nmodel = XGBClassifier(n_estimators=12, max_depth=3, learning_rate=0.08, random_state=0, n_jobs=-1)\n\nimport time\nt0 = time.time()\n\n# Loop from single model to n models:\nfor n in range(1, len(mean_corr) + 1):\n    # Get combinations for n models\n    n_model_combinations = combinations(mean_corr.index, n)\n    # Loop for all the combinations of n models\n    for i in list(n_model_combinations):\n        n_model_combination = list(i)\n        print('Model combination {}'.format(n_model_combination))\n        accuracy = get_accuracy(model, S_train[n_model_combination], y, cv=3)\n        t1 = time.time()\n        print('Model combination {}: {} in {} seconds'.format(n_model_combination, accuracy, (t1 - t0)))\n        t0 = t1\n        results = results.append({\n            'Model combination': n_model_combination,\n            'Accuracy': accuracy\n        }, ignore_index = True)\n\nresults = results.sort_values('Accuracy', ascending=False).reset_index(drop=True)","13914500":"results = results.sort_values('Accuracy', ascending=False).reset_index(drop=True)\nresults.to_csv('results.csv', index=True, index_label='Id')\nresults[0:10]","04dc4509":"for index, row in results[0:10].iterrows():\n    model.fit(S_train[row['Model combination']], y)\n    y_test_pred = pd.Series(model.predict(S_test[row['Model combination']]), index=S_test.index)\n    name = '_'.join(row['Model combination'])\n    y_test_pred.to_csv('submission_' + name + '.csv', header=['Cover_Type'], index=True, index_label='Id')","cd7de5be":"# Correlations","82a06be9":"# 2nd level model","c4cc7c94":"# Read predictions","f2c3c99a":"## Drop low scored models","b4cde955":"# Submit\nFor the 10 first model combinations of the results, the model is fitted, predicted and submitted.","61e35571":"# Introduction\nThe aim of this notebook is to obtain the stack of classifiers which maximise the accuracy in the train set.\nThen use this stack to predict the dependent variable in the test set.\n\nIn the previous notebook [Tactic 01. Test classifiers](https:\/\/www.kaggle.com\/juanmah\/tactic-01-test-classifiers),\nthere are the predictions (for train and test) of the analised models.\n\nThe first thing to look is the correlations of the predictions.\n\n---\n\nCredits to the Experts (Please like their kernels)  \nPaulo Pinto: [GMEAN of low correlation](https:\/\/www.kaggle.com\/paulorzp\/gmean-of-low-correlation-lb-0-952x)  \n[Nanashi](https:\/\/www.kaggle.com\/jesucristo)"}}