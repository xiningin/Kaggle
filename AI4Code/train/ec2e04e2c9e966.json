{"cell_type":{"3ec0a879":"code","4c03804a":"code","80fe8456":"code","27ccf111":"code","5ad79181":"code","d42059a8":"code","aaf828c5":"code","8c610273":"code","3b2f655d":"code","564180d6":"code","6537893f":"code","83d2ce2f":"code","73da0107":"code","c1749365":"code","e8a347de":"markdown","a2ff385d":"markdown","74f06147":"markdown","810d6fab":"markdown","30d1d1ba":"markdown","109d0d6f":"markdown","b2152af5":"markdown","e4e0de21":"markdown"},"source":{"3ec0a879":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tqdm.auto import tqdm\n\nsns.set_style('darkgrid')","4c03804a":"#\u0111\u1ecdc d\u1eef li\u1ec7u\ntrain = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\n\n#k\u00edch th\u01b0\u1edbc c\u1ee7a m\u1ea3ng\nprint(train.shape)\n\n#In m\u1ea3ng\ntrain.head()","80fe8456":"from sklearn.preprocessing import MultiLabelBinarizer\n\n#s\u1eed d\u1ee5ng split() \u0111\u1ec3 t\u00e1ch nh\u00e3n trong label\n#s\u1eed d\u1ee5ng MultiLabelBinarizer() t\u1ea1o ma tr\u1eadn theo c\u00e1c tag \u0111\u00e3 t\u00e1ch \u0111\u01b0\u1ee3c d\u01b0\u1edbi d\u1ea1ng c\u1ed9t\nmlb = MultiLabelBinarizer().fit(train.labels.apply(lambda x: x.split()))\nlabels = pd.DataFrame(mlb.transform(train.labels.apply(lambda x: x.split())), columns=mlb.classes_)\n\n#kh\u1edfi t\u1ea1o figure v\u00e0 axes\nfig, ax = plt.subplots(figsize=(20, 6))\n\n#In bi\u1ec3u \u0111\u1ed3 d\u01b0\u1edbi d\u1ea1ng c\u1ed9t\nlabels.sum().plot.bar(title='Target Class Distribution');","27ccf111":"fig, ax = plt.subplots(figsize=(20, 6))\n\n#In bi\u1ec3u \u0111\u1ed3 s\u1ed1 l\u01b0\u1ee3ng tag c\u00f3 trong ti\u1ec1u \u0111\u1ec1 c\u1ee7a m\u1ed7i b\u1ee9c \u1ea3nh (vd: 1tag, 2tag, 3tag)\nlabels.sum(axis=1).value_counts().plot.bar(title='Distribution of Number of Labels per Image');","5ad79181":"#kh\u1edfi t\u1ecda 1 figure c\u00f3 3x4 axes\nfig, ax = plt.subplots(3, 4, figsize=(20, 10))\n\n#g\u00e1n t\u1eebng \u1ea3nh th\u1ee9 2 c\u1ee7a m\u1ea3ng trong t\u1eebng lo\u1ea1i label v\u00e0o t\u1eebng v\u1ecb tr\u00ed axes t\u1eeb tr\u00e1i sang ph\u1ea3i v\u00e0 t\u1eeb tr\u00ean xu\u1ed1ng d\u01b0\u1edbi\nfor i, img in enumerate(train.groupby('labels').first().reset_index().values):\n    ax[i\/\/4][i%4].imshow(plt.imread(f\"..\/input\/plant-pathology-2021-fgvc8\/train_images\/{img[1]}\"))\n    ax[i\/\/4][i%4].set_title(img[0])\n    ax[i\/\/4][i%4].axis('off')\nfig.suptitle('Image Samples', fontsize=18); ","d42059a8":"#s\u1eed d\u1ee5ng pd.concat() \u0111\u1ec3 gh\u00e9p n\u1ed1i image v\u1edbi labels\nlabels = pd.concat([train['image'], labels], axis=1)\nlabels.head()","aaf828c5":"# scale pixel values to [0, 1]\n# validation_split d\u00f9ng 90% d\u1eef li\u1ec7u \u0111\u1ea7u ti\u00ean \u0111\u1ec3 \u0111\u00e0o t\u1ea1o v\u00e0 10% d\u1eef li\u1ec7u ti\u1ebfp theo \u0111\u1ec3 ki\u1ec3m tra\nimage_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255, validation_split=0.1)\n\n# flow_from_dataframe \u0111\u1ec3 \u0111\u1ecdc \u1ea3nh t\u1eeb m\u1ea3ng \u0111\u00e3 t\u1ea1o \u1edf tr\u00ean\n# x_col = t\u00ean h\u00ecnh \u1ea3nh\n# y_col = t\u00ean nh\u00e3n\n# class_mode = raw: \u0111\u1ec1 ngh\u1ecb tr\u00ecnh t\u1ea1o tr\u1ea3 v\u1ec1 t\u1ea5t c\u1ea3 c\u00e1c gi\u00e1 tr\u1ecb trong y.\n# target_size=(224, 224): thay \u0111\u1ed5i k\u00edch th\u01b0\u1edbc h\u00ecnh \u1ea3nh th\u00e0nh 224 x 224 pixel.\n# batch_size=64: l\u00e0 m\u1ed7i l\u1ea7n c\u1eadp nh\u1eadt tr\u1ecdng s\u1ed1, ta d\u00f9ng 64 images.\ntrain_generator = image_data_generator.flow_from_dataframe(\n    dataframe=labels,\n    directory='..\/input\/plant-pathology-2021-fgvc8\/train_images',\n    x_col='image',\n    y_col=labels.columns.tolist()[1:],\n    class_mode='raw',\n    color_mode=\"rgb\",\n    target_size=(224, 224),\n    batch_size=64,\n    subset='training'\n)\n\nvalid_generator = image_data_generator.flow_from_dataframe(\n    dataframe=labels,\n    directory='..\/input\/plant-pathology-2021-fgvc8\/train_images',\n    x_col='image',\n    y_col=labels.columns.tolist()[1:],\n    class_mode='raw',\n    color_mode=\"rgb\",\n    target_size=(224, 224),\n    batch_size=64,\n    subset='validation'\n)","8c610273":"inputs = tf.keras.Input(shape=(224, 224, 3))\n\n# Load MobileNetV2\nx = tf.keras.applications.MobileNetV2(include_top=False)(inputs)\n# Load GlobalAveragePooling2D()\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n# t\u1ea1o c\u00e1c layer m\u1edbi v\u1edbi Dense() v\u1edbi '6' l\u00e0 s\u1ed1 class v\u00e0 s\u1eed d\u1ee5ng h\u00e0m sigmoid\n# L\u1ea5y x t\u1eeb output c\u1ee7a GlobalAveragePooling2D()\noutputs = tf.keras.layers.Dense(6, activation='sigmoid')(x)\n\n# T\u1ea1o model v\u1edbi output l\u00e0 l\u1edbp Dense v\u1eeba th\u00eam\nmodel = tf.keras.models.Model(inputs, outputs)\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=1e-4))\n\n# In c\u1ea5u tr\u00fac m\u1ea1ng\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True)","3b2f655d":"rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.01)\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\nhistory = model.fit(train_generator, validation_data=valid_generator, epochs=10, callbacks=[rlp, es])","564180d6":"fix, ax = plt.subplots(figsize=(20, 6))\npd.DataFrame(history.history)[['loss', 'val_loss']].plot(ax=ax, title='Model Loss Curve')","6537893f":"submissions = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\nsubmissions.head()","83d2ce2f":"test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_data_generator.flow_from_dataframe(\n    submissions,\n    directory = '..\/input\/plant-pathology-2021-fgvc8\/test_images',\n    x_col=\"image\",\n    y_col=None,\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    classes=None,\n    class_mode=None,\n    shuffle=False,\n    batch_size=1\n)\n\npredictions = model.predict(test_generator,steps=len(test_generator.filenames))","73da0107":"thresh = 0.5\nfor i in range(3):\n    submissions.iloc[i, 1] = ' '.join(labels.columns[1:][predictions[i] >= thresh])\n    \nsubmissions.to_csv('submission.csv', index=False)    ","c1749365":"model.save('mobilenetv2.h5')","e8a347de":"Ta c\u00f3 th\u1ec3 th\u1ea5y \u0111\u01b0\u1ee3c \u1ea3nh \"1\" mang nhi\u1ec1u h\u01a1n 1 nh\u00e3n n\u00ean \u0111\u00e2y l\u00e0 d\u1ea1ng b\u00e0i \u0111a nh\u00e3n n\u00ean \u1edf \u0111\u00e2y ch\u00fang ta s\u1eed d\u1ee5ng \nMulti-label classification cho b\u00e0i to\u00e1n","a2ff385d":"# Modelling","74f06147":"T\u1ea1i b\u01b0\u1edbc n\u00e0y, m\u00ecnh s\u1ebd s\u1eed d\u1ee5ng baseModel \u0111\u00f3 l\u00e0 m\u1ea1ng MobileNetV2","810d6fab":"T\u1ed5ng s\u1ed1 tham s\u1ed1 c\u1ee7a m\u1ea1ng l\u00e0 2,265,670 trong \u0111\u00f3 c\u00f3 2,231,558 \u0111\u00e3 fix c\u1ee9ng, c\u00f2n l\u1ea1i 34,112 tham s\u1ed1 s\u1ebd \u0111\u01b0\u1ee3c train.","30d1d1ba":"# Dataset Exploration","109d0d6f":"# Preprocessing and Augmentation","b2152af5":"# Submission","e4e0de21":" B\u00e2y gi\u1edd n\u1ebfu ch\u00fang ta s\u1eed d\u1ee5ng ngay \u1ea3nh n\u00f3i tr\u00ean \u0111\u1ec3 train cho model CNN Classify th\u00ec s\u1ebd b\u1ecb hi\u1ec7n t\u01b0\u1ee3ng Overfit v\u00ec d\u1eef li\u1ec7u nhi\u1ec1u nh\u01b0ng \u0111a ph\u1ea7n gi\u1ed1ng nhau. D\u1eabn \u0111\u1ebfn train s\u1ebd c\u00f3 ch\u1ea5t l\u01b0\u1ee3ng t\u1ed1t nh\u01b0ng khi test s\u1ebd th\u1ea5y kh\u00f4ng nh\u1eadn chu\u1ea9n l\u1eafm.\n \n Ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n augment d\u1eef li\u1ec7u \u0111\u1ec3 l\u00e0m phong ph\u00fa h\u01a1n d\u1eef li\u1ec7u, t\u0103ng data variance , t\u0103ng t\u00ednh t\u1ed5ng qu\u00e1t cho model \nb\u1eb1ng ImageDataGenerator c\u1ee7a Keras."}}