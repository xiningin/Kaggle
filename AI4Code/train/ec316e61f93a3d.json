{"cell_type":{"583ed99e":"code","7e17d60d":"code","a7364eca":"code","78f6e955":"code","d6c0b741":"code","fae249c1":"code","d9b01df4":"code","689cdc63":"code","009bbc9f":"code","f5f07e9c":"code","5cfcc772":"code","0b3d1485":"code","b03004c9":"code","08ad0446":"code","a71cd24b":"code","a50b8aa6":"code","ca6df056":"code","bd21e1c5":"code","6e682305":"code","ef7bd379":"code","cff7b7d7":"code","b1d5e6a6":"code","62f0b7b6":"code","86b69edb":"code","6d6e303e":"code","64deaec9":"code","a3610f2c":"code","75a94073":"code","e6bb4c1d":"code","68ba8642":"code","6cb8eccc":"code","5c9fa089":"code","5e842403":"code","213f6907":"code","bf819bbb":"code","c3b31be7":"code","d98697ea":"code","f545f9a8":"code","87b6c576":"code","2cda7bd4":"code","2cc18a2c":"code","b1b2f6e7":"code","0455d7e0":"code","0ce2253c":"code","bac005d1":"code","0b8c53ec":"code","a1cb4965":"code","8db8ed5c":"code","42282d4e":"code","a012a3f6":"code","823b27ce":"code","951d190b":"code","4a676d17":"code","f5304991":"code","d977c32d":"code","cae7fdee":"code","ccb37b68":"code","1063d39b":"code","f1190d3d":"code","b58896fe":"code","a2f5824f":"code","1f6011c9":"code","a9610089":"code","b6484e5f":"code","6bc78fe3":"code","0a1d086e":"code","86ae2dd0":"code","8cb97618":"code","ed9ac371":"code","cfad6026":"code","29fedb1f":"code","bf4af36b":"code","60f0617d":"code","9d038916":"code","899f6b03":"code","b980a199":"code","143efa3d":"code","dc0269a6":"code","e4df2734":"code","41d13440":"code","f63bf614":"code","ab2ae783":"code","aec59d0d":"code","fd166001":"code","96760b25":"code","c4561bb1":"code","74559e35":"code","d7b16f2b":"code","5056ae3b":"code","8ceaa7cb":"code","c97d452c":"code","3977ae98":"code","79837362":"code","3187ad7f":"code","7d58f68a":"code","a1f1180d":"code","186bd785":"code","83207ad8":"code","0890c1da":"code","70753293":"code","bc380aa7":"code","33b609f4":"code","b5492bd1":"code","17a8a45f":"code","6a55ce95":"code","9fb0594b":"code","17893d21":"code","bc273be2":"code","0a9b2c10":"code","690f8529":"code","ec341963":"code","8ba31bb8":"code","b5984ae6":"code","ad08b3c0":"code","49fcf3d3":"code","3919d341":"code","cfd5e620":"code","8cbb5f54":"code","f38f9a6a":"code","f8b9b0f6":"code","a503d9e7":"code","99f235b9":"code","a0fe2b53":"code","5067e371":"code","b38550c2":"code","0636d831":"code","6ed17268":"code","87ec3496":"code","9abafbc9":"code","cab81f83":"code","5dee2cb9":"code","b900a746":"code","64a412b1":"code","414868e1":"code","2a5ecbd3":"code","14b40e8b":"code","e2018957":"code","715681ec":"code","44ed5098":"code","1f68d888":"code","f1bde504":"code","4773d0ca":"code","8ae610e8":"code","03e29c96":"code","2498fb5f":"markdown","857a0cbd":"markdown","9a5555a3":"markdown","c9ebd14b":"markdown","d93d3277":"markdown","3c3632f4":"markdown","5fbad6d9":"markdown","4a3ad42e":"markdown","681e6e6c":"markdown","c74c76b1":"markdown","e4afe6dd":"markdown","91a230ad":"markdown","e57e52e9":"markdown","d527fb6a":"markdown","9c92272c":"markdown","2e255654":"markdown","d885d08e":"markdown","fafb3cc5":"markdown","ef113191":"markdown","edcdd5e4":"markdown","c8cac357":"markdown","163e6ea3":"markdown","11351a8a":"markdown","48d81c8b":"markdown","40800f0b":"markdown","0a254d28":"markdown","8b9058c0":"markdown","44a1e655":"markdown","4571909f":"markdown","c7c158af":"markdown","92ad4440":"markdown","9f4d2291":"markdown","a76399d2":"markdown","c7ba10c7":"markdown","d5254be6":"markdown","f684a125":"markdown","489e87c0":"markdown","0790cc77":"markdown","8a5ce65d":"markdown","d1cd9dbe":"markdown","26be5c26":"markdown","ae2b5571":"markdown","fcbe115d":"markdown","9caa39a2":"markdown","10c6e438":"markdown","4f7b3076":"markdown","1ea61396":"markdown","464e219a":"markdown","2ac9cce5":"markdown","cd64ca30":"markdown","9077401b":"markdown","f281d166":"markdown","5bacfb66":"markdown","388a51ce":"markdown","4cafced9":"markdown","b1ea2923":"markdown","bfc475a3":"markdown","0dfa8ff6":"markdown","0aadc77d":"markdown","308611b8":"markdown","91fa268d":"markdown","4f460c42":"markdown","ffef30bc":"markdown","ad383e4a":"markdown","e2302dbd":"markdown","51ad6605":"markdown","fdceb5f0":"markdown","644da0ed":"markdown","19a8efbb":"markdown","05ddff25":"markdown","4e4d125d":"markdown"},"source":{"583ed99e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7e17d60d":"import scipy","a7364eca":"from sklearn.cluster import KMeans","78f6e955":"import seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = 'iframe'","d6c0b741":"from sklearn.cluster import KMeans","fae249c1":"import warnings\nwarnings.filterwarnings('ignore') ","d9b01df4":"main_df = pd.read_csv('\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv', sep='\\t')","689cdc63":"main_df.head(10)","009bbc9f":"main_df.columns","f5f07e9c":"main_df.info()","5cfcc772":"\nmain_df.isna().sum()","0b3d1485":"# also dont forget to check for duplicates\nmain_df.duplicated().sum()","b03004c9":"main_df.columns","08ad0446":"main_df.columns=['id','yob','education','marital_status','income','kid_home','teen_home',\n                'dt_customer','recency','mnt_wines','mnt_fruits','mnt_meat_prod','mnt_fish_prod',\n                'mnt_sweet_prod','mnt_gold_prod','num_deal_purch','num_web_purch','num_catalog_purch',\n                'num_store_purch','web_visits_month','accept_cmp_3','accpt_cmp_4','accept_cmp_5','accept_cmp_1',\n                'accept_cmp_2','complain','z_cost_contact','z_revenue','response']","a71cd24b":"\npx.box(main_df[['yob']], y='yob', points='all', title='Year of birth distribution across dataset')","a50b8aa6":"# save data to a new dataframe where we will provide all cleaning-related operations\nclean_df=main_df[main_df['yob']>1900]","ca6df056":"clean_df.columns","bd21e1c5":"clean_df.groupby('education')['id'].count().to_frame().sort_values('id', ascending=False)","6e682305":"clean_df['education'] = clean_df['education'].astype('category')","ef7bd379":"clean_df.groupby('marital_status')['id'].count().to_frame().sort_values('id', ascending=False)","cff7b7d7":"clean_df['marital_status'] = clean_df['marital_status'].replace('Alone','Single')\nclean_df['marital_status'] = clean_df['marital_status'].replace(['Absurd','YOLO'],'Married')","b1d5e6a6":"clean_df.groupby('marital_status')['id'].count().to_frame().sort_values('id', ascending=False)","62f0b7b6":"clean_df['marital_status'] = clean_df['marital_status'].astype('category')\nclean_df['marital_status'].dtype","86b69edb":"clean_df.columns","6d6e303e":"px.box(clean_df[['income']], y='income', points='all', title='Income dispersion')","64deaec9":"clean_df['income'].describe()","a3610f2c":"clean_df = clean_df[clean_df['income']!=clean_df['income'].max()]","75a94073":"clean_df['income'].isna().sum()","e6bb4c1d":"px.box(clean_df[['income','education']], x='education',y='income',points='all',color='education',title='Dispersion of income based by education class')","68ba8642":"#2020 so we will have number of \"full\" years for every client\nclean_df['age'] = 2020-clean_df['yob']","6cb8eccc":"# cheacking pearson correlation coefficient\nclean_df[['age','income']].corr(method='pearson')","5c9fa089":"px.scatter(clean_df[['age','income']], x='age', y='income', title='income vs age')","5e842403":"clean_df.columns","213f6907":"px.scatter_matrix(clean_df[['income','mnt_wines','mnt_meat_prod','mnt_fish_prod','mnt_sweet_prod','mnt_gold_prod']],\n                  dimensions=['income','mnt_wines','mnt_meat_prod','mnt_fish_prod','mnt_sweet_prod','mnt_gold_prod'])","bf819bbb":"clean_df[['income','mnt_wines','mnt_meat_prod','mnt_fish_prod','mnt_sweet_prod','mnt_gold_prod']].corr(method='pearson')","c3b31be7":"px.box(clean_df[['mnt_meat_prod']],y='mnt_meat_prod', points='all',title='mnt_meat_prod dispersion across all values')","d98697ea":"px.histogram(clean_df[['mnt_meat_prod']],x='mnt_meat_prod', nbins=1000, title='mnt_meat_prod dispersion across all values')\n","f545f9a8":"clean_df['mnt_meat_prod'].describe()","87b6c576":"clean_df['mnt_meat_prod'].median()","2cda7bd4":"clean_df['mnt_meat_prod'].std()","2cc18a2c":"def define_missing_income(row):\n    \n    meat_prod_std = clean_df['mnt_meat_prod'].std()\n    \n    if pd.isna(row['income']) == True:\n    \n        client_meat_prod = row['mnt_meat_prod']\n        \n        upper_limit = client_meat_prod + meat_prod_std \n        \n        lower_limit = client_meat_prod - meat_prod_std\n    \n        client_df = clean_df[(clean_df['mnt_meat_prod'] > lower_limit) & (clean_df['mnt_meat_prod'] < upper_limit)]\n    \n        value = client_df['income'].median()\n        \n    else:\n        \n        value = row['income']\n        \n    return(value)","b1b2f6e7":"clean_df['income'] = clean_df.apply(define_missing_income, axis=1)","0455d7e0":"clean_df['income'].isna().sum()","0ce2253c":"clean_df.columns","bac005d1":"clean_df['kid_home'].describe()","0b8c53ec":"clean_df['teen_home'].describe()","a1cb4965":"clean_df['children_total'] = clean_df['kid_home'] + clean_df['teen_home']","8db8ed5c":"clean_df.columns","42282d4e":"# looks like \"points\" value where every customer measured from 0 to 99\n# data explonation says that it is number of days since last purchase\nclean_df['recency'].describe()\n","a012a3f6":"clean_df['complain'].describe()","823b27ce":"# less than 1% of total number of customers had any complains\nclean_df['complain'].value_counts()","951d190b":"clean_df.columns","4a676d17":"clean_df['total_spend']=clean_df['mnt_wines'] + clean_df['mnt_fruits'] + clean_df['mnt_meat_prod'] + clean_df['mnt_fish_prod']\\\n+ clean_df['mnt_sweet_prod'] + clean_df['mnt_gold_prod']","f5304991":"clean_df['total_purchases'] = clean_df['num_deal_purch'] + clean_df['num_web_purch'] + clean_df['num_catalog_purch'] + clean_df['num_store_purch']","d977c32d":"px.box(clean_df[['total_spend']], y='total_spend', points='all', title='total_spend dispersion')","cae7fdee":"px.box(clean_df[['total_purchases']], y='total_purchases', points='all', title='total_purchases dispersion')","ccb37b68":"clean_df[clean_df['total_purchases'] == 0]","1063d39b":"clean_df['total_purchases'] = clean_df['total_purchases'].replace(0,1)","f1190d3d":"clean_df['z_cost_contact'].describe()","b58896fe":"px.box(clean_df[['z_cost_contact']], y='z_cost_contact')","a2f5824f":"clean_df['z_revenue'].describe()","1f6011c9":"px.box(clean_df[['z_revenue']], y='z_revenue')","a9610089":"clean_df = clean_df.drop(['z_revenue','z_cost_contact'], axis='columns')","b6484e5f":"clean_df.columns","6bc78fe3":"clean_df.rename(columns={'accpt_cmp_4':'accept_cmp_4'}, inplace=True)","0a1d086e":"clean_df[['id','accept_cmp_1','accept_cmp_2','accept_cmp_3','accept_cmp_4','accept_cmp_5']]","86ae2dd0":"clean_df['campaigns_total'] = clean_df['accept_cmp_1'] + clean_df['accept_cmp_2'] + clean_df['accept_cmp_3'] + clean_df['accept_cmp_4'] + clean_df['accept_cmp_5']","8cb97618":"clean_df['campaigns_total'].value_counts()","ed9ac371":"clean_df.head()","cfad6026":"def define_percentile_category(series):\n    \n    category_class_list = []\n    \n    for result in series:\n        if result < np.percentile(series, 25):\n            category_class_list.append(1)\n        elif result < np.percentile(series, 50):\n            category_class_list.append(2)\n        elif result < np.percentile(series, 75):\n            category_class_list.append(3)\n        else:\n            category_class_list.append(4)\n        \n    return(category_class_list)","29fedb1f":"clean_df['income_category'] = define_percentile_category(clean_df['income'])","bf4af36b":"clean_df.columns","60f0617d":"clean_df['income_category'] = clean_df['income_category'].astype('category')","9d038916":"clean_df['spends_category'] = define_percentile_category(clean_df['total_spend'])","899f6b03":"clean_df['spends_category'] = clean_df['spends_category'].astype('category')","b980a199":"px.box(clean_df[['age']], y='age', title='age dispersion across dataset', points='all')","143efa3d":"clean_df['age_category'] = define_percentile_category(clean_df['age'])","dc0269a6":"clean_df['age_category'] = clean_df['age_category'].astype('category')","e4df2734":"import datetime as dt\nfrom datetime import datetime","41d13440":"# defining today's lifetime day number\nclean_df['lt_days'] = round((datetime.now() - clean_df['dt_customer'].astype('datetime64[ns]'))\/np.timedelta64(1,'D')).astype(int)","f63bf614":"clean_df['lt_category'] = define_percentile_category(clean_df['lt_days'])\n\nclean_df['lt_category'] = clean_df['lt_category'].astype('category')","ab2ae783":"clean_df['children_total'].value_counts()","aec59d0d":"clean_df['children_category']=clean_df['children_total'].map({0:'no_kids',\n                               1:'one_kid',\n                               2:'two_and_more',\n                               3:'two_and_more'})\n\nclean_df['children_category'] = clean_df['children_category'].astype('category')","fd166001":"clean_df.head()","96760b25":"px.scatter_matrix(clean_df[['total_purchases','total_spend']])","c4561bb1":"clean_df[['total_purchases','total_spend']].corr('pearson')","74559e35":"X = np.array(clean_df[['total_purchases','total_spend']])","d7b16f2b":"clean_df['purch_behaviour_claster'] = ((KMeans(n_clusters=4, random_state=0).fit(X)).labels_).astype('str')","5056ae3b":"px.scatter(clean_df[['total_purchases','total_spend','purch_behaviour_claster']], x='total_spend', y='total_purchases',\n          color='purch_behaviour_claster', title='Clients clusters by purchase behaviour')","8ceaa7cb":"clusters_1_2_df = clean_df[clean_df['purch_behaviour_claster'].isin(['1','2'])]","c97d452c":"clusters_1_2_education_pvt = clusters_1_2_df.pivot_table(values=['id'],\n                            index=['purch_behaviour_claster','education'],\n                            aggfunc=pd.Series.nunique).sort_values('id',ascending=False).reset_index()\n","3977ae98":"clusters_1_2_education_pvt['ed_group_%'] = round(clusters_1_2_education_pvt.groupby('purch_behaviour_claster')['id'].apply(lambda x: 100 * x\/float(x.sum())),2)","79837362":"clusters_1_2_education_pvt","3187ad7f":"px.bar(clusters_1_2_education_pvt.sort_values(['education','purch_behaviour_claster']),\n       x='education', y='ed_group_%', color='purch_behaviour_claster',barmode='group', title='education level discrepancy between 1 and 2 clusters')","7d58f68a":"education_observed = np.array([[525,147],[202,71],[180,54],[111,12],[52,0]])","a1f1180d":"chi2, p, df, expected = scipy.stats.chi2_contingency(education_observed)\nprint('x-squared =', chi2)\nprint('p=%.3f'% p)\nprint('df =', df)\nprint('expected distribution if H0 is correct', expected)","186bd785":"clusters_1_2_df.columns","83207ad8":"px.box(clusters_1_2_df, x='purch_behaviour_claster', y='income', points='all', color='purch_behaviour_claster', title = 'Income disspersion between 1 and 2 clusters')","0890c1da":"px.histogram(clusters_1_2_df, x='income', color='purch_behaviour_claster', title = 'Income disspersion between 1 and 2 clusters')","70753293":"clusters_1_2_income = clusters_1_2_df[['purch_behaviour_claster','income']]","bc380aa7":"np.percentile(clusters_1_2_income['income'], 25)","33b609f4":"clusters_1_2_income['income'].dtype","b5492bd1":"def exclude_extreme_values(df, low_fence, upper_fence):\n    \n    result_df=pd.DataFrame(columns=df.columns)\n    \n    for cluster in df['purch_behaviour_claster'].unique():\n        \n        cluster_df=df[df['purch_behaviour_claster']==cluster]\n        \n        cluster_df_clean=cluster_df[(cluster_df['income'] > np.percentile(cluster_df['income'], low_fence)) & (cluster_df['income'] < np.percentile(cluster_df['income'], upper_fence))]\n        \n        result_df=result_df.append(cluster_df_clean)\n        \n    result_df.reset_index(drop=True)\n    \n    return(result_df)","17a8a45f":"clusters_1_2_income_clean = exclude_extreme_values(clusters_1_2_income, 10, 90)","6a55ce95":"px.histogram(clusters_1_2_income_clean, x='income', color='purch_behaviour_claster', nbins=120 ,title = 'Income distribution for 1 and 2 clusters')","9fb0594b":"stat, p = scipy.stats.shapiro(clusters_1_2_income_clean[clusters_1_2_income_clean['purch_behaviour_claster']=='1']['income'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","17893d21":"stat, p = scipy.stats.shapiro(clusters_1_2_income_clean[clusters_1_2_income_clean['purch_behaviour_claster']=='2']['income'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","bc273be2":"stat, p = scipy.stats.mannwhitneyu(clusters_1_2_income_clean[clusters_1_2_income_clean['purch_behaviour_claster']=='1']['income'],\n                       clusters_1_2_income_clean[clusters_1_2_income_clean['purch_behaviour_claster']=='2']['income'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","0a9b2c10":"clusters_1_2_df.head()","690f8529":"clusters_1_2_df.columns","ec341963":"clusters_1_2_df[['id','mnt_wines','mnt_fruits','mnt_meat_prod','mnt_fish_prod','mnt_sweet_prod','mnt_gold_prod','total_spend']]","8ba31bb8":"for column in ['mnt_wines','mnt_fruits','mnt_meat_prod','mnt_fish_prod','mnt_sweet_prod','mnt_gold_prod']:\n    \n    column_name = column.split('_')[1]+'_%'\n    \n    clusters_1_2_df[column_name] =  round(clusters_1_2_df[column]\/clusters_1_2_df['total_spend'],2)\n    \n    ","b5984ae6":"clusters_1_2_df.head()","ad08b3c0":"px.histogram(clusters_1_2_df, x='wines_%', color='purch_behaviour_claster', nbins=120 ,title = 'wines_% distribution for 1 and 2 clusters')","49fcf3d3":"#Visually distribution for wines_% looks quite similar, lets check box-plot \npx.box(clusters_1_2_df, x='wines_%', color='purch_behaviour_claster', points='all' ,title = 'wines_% distribution for 1 and 2 clusters')","3919d341":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['wines_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['wines_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","cfd5e620":"print('Cluster 1 mean % of wine spends:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['wines_%'].mean(),3))\nprint('Cluster 2 mean % of wine spends:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['wines_%'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['wines_%'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['wines_%'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","8cbb5f54":"px.box(clusters_1_2_df, x='fruits_%', color='purch_behaviour_claster', points='all' ,title = 'fruits_% distribution for 1 and 2 clusters')","f38f9a6a":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['fruits_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['fruits_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","f8b9b0f6":"print('Cluster 1 mean % of fruits spends:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['fruits_%'].mean(),3))\nprint('Cluster 2 mean % of fruits spends:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['fruits_%'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['fruits_%'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['fruits_%'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","a503d9e7":"px.box(clusters_1_2_df, x='meat_%', color='purch_behaviour_claster', points='all' ,title = 'meat_% distribution for 1 and 2 clusters')","99f235b9":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['meat_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['meat_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","a0fe2b53":"print('Cluster 1 mean % of meat spends:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['meat_%'].mean(),3))\nprint('Cluster 2 mean % of meat spends:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['meat_%'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['meat_%'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['meat_%'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","5067e371":"px.box(clusters_1_2_df, x='fish_%', color='purch_behaviour_claster', points='all' ,title = 'fish_% distribution for 1 and 2 clusters')","b38550c2":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['fish_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['fish_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","0636d831":"print('Cluster 1 mean % of fish spends:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['fish_%'].mean(),3))\nprint('Cluster 2 mean % of fish spends:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['fish_%'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['fish_%'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['fish_%'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","6ed17268":"px.box(clusters_1_2_df, x='sweet_%', color='purch_behaviour_claster', points='all' ,title = 'sweet_% distribution for 1 and 2 clusters')\n","87ec3496":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['sweet_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['sweet_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","9abafbc9":"print('Cluster 1 mean % of sweet spends:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['sweet_%'].mean(),3))\nprint('Cluster 2 mean % of sweet spends:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['sweet_%'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['sweet_%'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['sweet_%'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","cab81f83":"px.box(clusters_1_2_df, x='gold_%', color='purch_behaviour_claster', points='all' ,title = 'gold_% distribution for 1 and 2 clusters')\n","5dee2cb9":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['gold_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['gold_%'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","b900a746":"print('Cluster 1 mean % of gold spends:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['gold_%'].mean(),3))\nprint('Cluster 2 mean % of gold spends:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['gold_%'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['gold_%'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['gold_%'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","64a412b1":"px.box(clusters_1_2_df, x='age', color='purch_behaviour_claster', points='all' ,title = 'Age distribution for 1 and 2 clusters')\n","414868e1":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['age'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['age'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","2a5ecbd3":"print('Cluster 1 mean of age:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['age'].mean(),3))\nprint('Cluster 2 mean of age:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['age'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['age'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['age'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","14b40e8b":"px.box(clusters_1_2_df, x='children_total', color='purch_behaviour_claster', points='all' ,title = 'Num of kids distribution for 1 and 2 clusters')\n","e2018957":"stat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['children_total'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n\nstat, p = scipy.stats.shapiro(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['children_total'])\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","715681ec":"print('Cluster 1 mean of children:', round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['children_total'].mean(),3))\nprint('Cluster 2 mean of children:',round(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['children_total'].mean(),3))\n\nstat, p = scipy.stats.mannwhitneyu(clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='1']['children_total'],\n                       clusters_1_2_df[clusters_1_2_df['purch_behaviour_claster']=='2']['children_total'],\n                       axis=0,\n                       method='auto')\n\nprint('Statistics=%.3f, p=%.3f' % (stat, p))","44ed5098":"clusters_1_2_marital_status_pvt = clusters_1_2_df.pivot_table(values=['id'],\n                            index=['marital_status','purch_behaviour_claster'],\n                            aggfunc=pd.Series.nunique).sort_values('id',ascending=False).reset_index()\n","1f68d888":"clusters_1_2_marital_status_pvt['marital_group_%'] = round(clusters_1_2_marital_status_pvt.groupby('purch_behaviour_claster')['id'].apply(lambda x: 100 * x\/float(x.sum())),2)","f1bde504":"px.bar(clusters_1_2_marital_status_pvt, x = 'marital_status', y = 'marital_group_%', color='purch_behaviour_claster', barmode='group')","4773d0ca":"clusters_1_2_marital_status_pvt","8ae610e8":"obs = [[415,102],[281,76],[238,67],[109,27],[27,12]]","03e29c96":"chi2, p, df, expected = scipy.stats.chi2_contingency(obs)\nprint('x-squared =', chi2)\nprint('p-value =', p)\nprint('df =', df)\nprint('expected distribution if H0 is correct', expected)","2498fb5f":"We will keep \"Together\" and \"Married\" as different groups couse this actually can be recognized as different life-experience which can influence client habits and other parameters a lot\n\nSame thing with Single\/Divorced\/Widow - we will also keep them as separate groups ","857a0cbd":"Here we see some values with 0 in total purchases, lets check this values","9a5555a3":"# Data cleaning and general data overview","c9ebd14b":"5 education levels. In general everything seems to be ok, lets convert datatype to category","d93d3277":"**Distribution seems to be multimodal, so lets provide normality distribution tests to define which methods we will use - parametric or non-parametric** \n\n**We will handle Shapiro normality test** \n","3c3632f4":"**Lets check if there is a significant difference between groups in terms of % of wine spends across client's total spend** \n\nOnce again we will firstly check distribution for normality and provide parameteric or non-parametric test based on shapiro normality test test results ","5fbad6d9":"**lets also categorise clients by age**","4a3ad42e":"**There is no significant difference in sweet- related spend**\n\nGold products on the way","681e6e6c":"Here we see left-sided alpha dispersion","c74c76b1":"We can see that thouse users have extremely low total spend. As there are only 4 users we can exclude them, but also we can change the number of purchases from 0 to 1","e4afe6dd":"0.19 is actually means that there is no strong correlation between age and income lvl (for strong correlation we shall have pearson coefficient >0.41 in general)\n\nby the way lets take a look at the scatter plot","91a230ad":"**Lets add an additional category based on clients's income**\n\n**I will make a formula which will categories clients by percentile so we can use it for different column's categorisation**","e57e52e9":"**Finally we added an additional column which show in how many campaigns was every user involved**","d527fb6a":"\n**P value for both clusters is close to 0.** \n\nSo here we can see that distribusion is not gausian for both cluster groups. \n\nSo we will use non-parametric Mann Whitneney U test to define difference in income level between clusters ","9c92272c":"Lets check if there is a significant difference between groups in terms of % of ","2e255654":"Lets check income dispersion across all data-set","d885d08e":"**Lets take a look at children total column**","fafb3cc5":"**Lets add an additional category based on clients's total spends**","ef113191":"Lets check kids","edcdd5e4":"# Part 2 conclusion\n\nIn this part of our research we provided k-means claassification of our clients based on client's num of purchases and total spend. \n\nWe found that \n- Cluster 1 client's income is significantly higher then Cluster 2 clients's income \n- We found that there are some differences in education lvl between clusters and Cluster 1 clients a likely to have better education neither Cluster 2 clients \n- We found that there are significant differences in terms of part of total client spend for several goods groups especially for^ \n    - Cluster 1  client's have higher % of meat and wine in the structure of their spends than cluster 2 clients\n    - Cluster 2  client's have higher % of gold-related goods in the structure of their spends. \n    We dond know the exact number of purchases for every goods-group, but I  can hupothesize that with income growing clients are morte likely to purchase more in terms of quantity or better in terms of quality (and expensive) wine\/meat-related products. \n        \n    \nAccording to social data we found that:\n\n- Cluster 1 clients on average have lewss kids than Cluster two. Less than 50% of clients in this clusters have 1 kid\n- There is no significant difference in clients marital status between this two clusters \n- On average Cluster 1 clients have better education than Cluster 2 clients \n\n\n    During this part of research I used such instruments as K-means clustering, Shapiro normality test and Mann-Whitney test, chi2 contingency test. \n    \n    \n  \n\n     ","c8cac357":"Lets take a look at education column","163e6ea3":"Same situation with Z-Revenue column. All values are equal to 11.\nFinally we can drop thouse two columns as they are not seem to be usefull for us","11351a8a":"**Here we will categorise them using 3 groups as 0\/1\/2+** ","48d81c8b":"**We can say that clients from Cluster 2 on average have more kids than Cluster 1**","40800f0b":"Everythin seems to be mostly ok, lets check total purchases","0a254d28":"**P value is less than 0.05 so we reect H0 and can say that mean income across two cllusters statistically different**","8b9058c0":"**Finally lets check accept_cmp columns**","44a1e655":"**Ok, seems that there are significant differences between thouse two clusters in terms of income lvl.**\n\nLets check distribution for normality\n\nFirstly we will take only values from 25-75 percentile from each group\n","4571909f":"We can see here that in general dispersion, median and min and max fences for most of education levels excluding Basic are quite similar. \n\nSo filling missing values in income column relying on education level seems to be a good idea. \n\nTaking median value looks better than taking average in case that 3 of 5 groups have some outliers laying above 140k \n\nBut firstly lets anyway check - maybe client's age describes income better than client's education lvl ?\n\nFirst of all lets find the exact age for every client and check it's correlation with income\n\n","c7c158af":"**We defined 4 clusters of our clients with K-means, lets check the differences between cluster 1 (most valuable clients) and cluster 2 (low spend and low number of purchases)**\n\n\nWhat also I can say, that in general we have really small number of clients, who made 30 and more purchases. \n\nEven in the first cluster we see really small number of users who commited 30 and more purchases. \n\n\n","92ad4440":"\n# As the next step lets take a look at how distribution of spend across items very between clusters","9f4d2291":"We can combine thouse two columns to a new column \"children_total\" which we will use in future exploration","a76399d2":" # Part 2 clusterisation and clusters research \n \n In the next part I am going to devide our clients on several clusters using K-Means clustering \n   \n   Clustering model will be based on users payments behaviuor and include number of purchases and total spends sum\n   \n   After that I will research the differences between clusters based on users's spend structure","c7ba10c7":"Distribution is not normall ,so we will use Mann\u2013Whitney U-Test once again ","d5254be6":"Here we have some garbage data\n\nWe will replace Alone to single and Absurd and YOLO would be replaced with Married as the most common status","f684a125":"There is a significant difference between clusters in terms of gold -products consumption","489e87c0":"So here we see 3 people with yob less or equal to 1900 which means they are really old.\n\n\nThis 3 clients stay away from general popularity for several sigmas. \n\n\nSo I think that we can easily exclude thouse 3 customers from the dataset.","0790cc77":"**Lets count lifetime of every customer based on dt_customer column**","8a5ce65d":"Lets start with correction of column names - lets get back to standard snake-case","d1cd9dbe":"Lets check the distribution in yob. We will see if there are any strange variables.","26be5c26":"**Ok, we found, that there is no significant difference in fruits spends between clusters** \n","ae2b5571":"# Thanks for reading! \n# Looking forward for your comments","fcbe115d":"Also we have some NA values here in this column. 24 values is like 1% of all dataset, so we better fix them instead of just deleting","9caa39a2":" So we will fill missing values using such algorithm:\n- for each client with missed income we will form a group based on his mnt_meat_prod \n- group will include all clients who's mnt_meat_prod is between missing_data_client's mnt_meat_prod+- standard deviation\n- we will fill in na income values with median of a group","10c6e438":"Lets take a look at the marital status","4f7b3076":"**There is no significant diffefence in marital status distribution**","1ea61396":"Ok, this is  constant for every client, so we there is no insights we can get here and nothing to do with this column","464e219a":"Here we can see, that there are no clients with Basic education in the 1st cluster. \n\nAlso number of clients with 2nd Cycle education is higher in the 1st cluster.\n\nOther education lvls are higher in the 1st ","2ac9cce5":"Here we found that income has strong correlation (nearly 0.7 which can be assumed as strong positive correlation) with mnt_meat_prod \n\nLets take a look at general dispersion of mnt_meat_prod value","cd64ca30":"**lets check if there is a significant diffrenece for education lvl distribution**","9077401b":"lets check the general dispersion for total_spend and total_purchases","f281d166":"We shall make a descision what on which client's tdata we will rely on while defing the exact values for NA cells\n\nI assume that first of all we shall check correlation between education level and income and age and income, parameter which have stronger correlation with income will be the main parametert for us during defeing missing values.\n\nOr maybe we will find some other parametr we can rely on","5bacfb66":"Ok, there are like 1% of missing values in Income column.\n\nI think we can substitute missing values with other values based on customers data. We will check it further.\n\nFirst of all lets check other columns to make sure that all other data is clean and ready for analysis**","388a51ce":"Lets add additional columns which will describe part of each product group in total client's spend \n","4cafced9":"So here we see one extremely high value equal to 666666. This value stays away from general group of values for like dozens of sigmas, so we better exclude it\n\nBesides that we can several values exceeding 150k, but this values look logically normal and stay away from median just for several sigmas. So we can keep them","b1ea2923":"**Lets check income dispersion between clusters**\n","bfc475a3":"**We dont see significant diffrence in terms of age between clusters**","0dfa8ff6":"So as we can see the dispersion of values for all ages looks quite similar and age of clients dont describe difference in income lvl at all \n\nBut what if client's spend describes clients income better than other parameters? Lets check correlation between spends and income. ","0aadc77d":"Ok, finally we filled all missing values. It took time, but in this case we had it.\nDuring handling thouse NA values we found strong correlation between income and meat_prod values and also \nresearched how education level interconnected with income level.\nSo we already found some insights which can help us in future research and descision making","308611b8":"**There is no significvant difference between clusters related to fish spends part in their total spend** \n\nLets move to sweet spends","91fa268d":"# Part 1 comclusion.  Here I can say that data-prepartion stage is finished\n\n- **Column names have been changed to snake-case names**\n\n- **Several columns data type was changed to category data type** \n\n- **All NA values in income column were fullfilled based on client's spends data.**\n\n- **Such variables as**\n    * kids_total\n    * total_income\n    * total_purchases\n    * total_spends\n    * total_campaigns\n    * clients lifetime\n    were counted based on information we have\n    \n    \n\n- **Clients were categorised by**\n    * age\n    * total spends\n    * total income\n    * lifetime\n    * total number of children \n    * marriage status\n\n- **Several rows with extreme values werre excluded from the data set (with extreme income and age values)**\n\n## Now we have clean data set which is ready for statistical analysis and  ML instruments usage\n","4f460c42":"lets check z_cost_contact and z_revenue columns","ffef30bc":"**lets count of there is a significant difference between this two clusters in marital_status** ","ad383e4a":"**Ok, we found, that clietns from cluster 1 on average purchase more meat-related goods** \n\nLets move to fish spends","e2302dbd":"**And also categoris them by lifetime group** ","51ad6605":"**There is a significant difference in education lvl** ","fdceb5f0":"Lets check that everything is fine","644da0ed":"Lets also combine all spends and all purchases in total columns\ntotal_purchases and total_spend ","19a8efbb":"**Ok, we found, that clietns from cluster 1 on average purchase more wine-related goods** \n\nLets move to fruits spends","05ddff25":"And also dont forget to convert marital_status column to categorical data type","4e4d125d":"\n\nWe can see that some columns have some number of missing values. Lets check them\n"}}