{"cell_type":{"72833e59":"code","68757651":"code","6bea1ea0":"code","eec123e0":"code","edbbdf4d":"code","8f1b4f70":"code","08167c24":"code","93a5740d":"code","3918defa":"code","6017b139":"code","d0b50be4":"code","ad3c1a2a":"code","d6dc6250":"code","e1bcc5de":"code","1bfe315f":"code","3c13c56d":"code","d899ebb6":"code","104d7d4e":"code","30fd8ce7":"markdown"},"source":{"72833e59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\nwarnings.filterwarnings(\"ignore\")","68757651":"song_data=pd.read_csv(\"..\/input\/19000-spotify-songs\/song_data.csv\")","6bea1ea0":"song_data.head()","eec123e0":"song_data.info()","edbbdf4d":"#drop the features we don't use.\nsong_data.drop([\"song_name\"],axis=1,inplace=True)","8f1b4f70":"song_data.song_duration_ms= song_data.song_duration_ms.astype(float)\nsong_data.time_signature= song_data.time_signature.astype(float)\nsong_data.audio_mode= song_data.audio_mode.astype(float)","08167c24":"song_data[\"popularity\"]= [ 1 if i>=70 else 0 for i in song_data.song_popularity ]\nsong_data[\"popularity\"].value_counts()","93a5740d":"data2=song_data.head(1000)\nplt.scatter(data2[\"danceability\"],data2[\"energy\"],color=\"orange\")\nplt.xlabel(\"danceability\")\nplt.ylabel(\"energy\")\nplt.show()","3918defa":"#Kmeans Clustering\ndata3=data2.loc[:,[\"danceability\",\"energy\"]]\n\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 2)\nkmeans.fit(data3)\nlabels=kmeans.predict(data3) # labels=kmeans.fit_predict(data3)\n\nplt.scatter(data2[\"danceability\"],data2[\"energy\"],c=labels)\nplt.xlabel(\"danceability\")\nplt.ylabel(\"energy\")\nplt.show()\n","6017b139":"# Cross Tabulation Table\ndf = pd.DataFrame({'labels':labels,\"popularity\":data2['popularity']})\nct = pd.crosstab(df['labels'],df['popularity'])\nprint(ct)","d0b50be4":"#Inertia\ninertia_list = np.empty(8)\nfor i in range(1,8):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(data2)\n    inertia_list[i] = kmeans.inertia_\nplt.plot(range(0,8),inertia_list,'-o')\nplt.xlabel('Number of cluster')\nplt.ylabel('Inertia')\nplt.show()","ad3c1a2a":"data4= song_data.drop('popularity',axis = 1)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nscalar = StandardScaler()\nkmeans = KMeans(n_clusters = 2)\npipe = make_pipeline(scalar,kmeans)\npipe.fit(data4)\nlabels = pipe.predict(data4)\ndf = pd.DataFrame({'labels':labels,\"popularity\":song_data['popularity']})\nct = pd.crosstab(df['labels'],df['popularity'])\nprint(ct)","d6dc6250":"from scipy.cluster.hierarchy import linkage,dendrogram\nplt.figure(figsize=[10,10])\n\nmerg = linkage(data2.iloc[200:220,:],method = 'single')\ndendrogram(merg, leaf_rotation = 90, leaf_font_size = 10)\nplt.xlabel(\"Data Points\")\nplt.ylabel(\"Euclidean Distance\")\nplt.show()","e1bcc5de":"from sklearn.cluster import AgglomerativeClustering\ndata_new=data2.iloc[:,[2,3]]\ndata_new[\"label\"]=0\ndata=data_new\n\nhc_cluster=AgglomerativeClustering(n_clusters=3,affinity=\"euclidean\",linkage=\"ward\")\ncluster=hc_cluster.fit_predict(data2)\ndata[\"label\"]=cluster\nplt.scatter(data.acousticness[data.label == 0 ],data.danceability[data.label == 0],color = \"red\")\nplt.scatter(data.acousticness[data.label == 1 ],data.danceability[data.label == 1],color = \"green\")\nplt.scatter(data.acousticness[data.label == 2 ],data.danceability[data.label == 2],color = \"blue\")\nplt.show()\n","1bfe315f":"from sklearn.manifold import TSNE\ncolor_list = ['red' if i==1 else 'purple' for i in data2.loc[:,'popularity']]\n\nmodel = TSNE(learning_rate=100)\ntransformed = model.fit_transform(data3) #danceability and energy\nx = transformed[:,0]\ny = transformed[:,1]\nplt.scatter(x,y,c = color_list )\nplt.xlabel('danceability')\nplt.xlabel('energy')\nplt.show()","3c13c56d":"# PCA\nfrom sklearn.decomposition import PCA\nmodel = PCA()\nmodel.fit(data4) \ntransformed = model.transform(data4)\nprint('Principle components: ',model.components_)","d899ebb6":"# PCA variance\nscaler = StandardScaler() \npca = PCA()\npipeline = make_pipeline(scaler,pca)\npipeline.fit(data4)\n\nplt.bar(range(pca.n_components_), pca.explained_variance_)\nplt.xlabel('PCA feature')\nplt.ylabel('variance')\nplt.show()","104d7d4e":"#popular vs unpopular songs\ncolor_list = ['yellow' if i==1 else 'teal' for i in data2.loc[:,'popularity']]\npca = PCA(n_components = 2)\npca.fit(data2)\ntransformed = pca.transform(data2)\nx = transformed[:,0]\ny = transformed[:,1]\nplt.scatter(x,y,c = color_list)\nplt.show()","30fd8ce7":"If song_popularity is higher than 70 (this is about %25 percent of data )we labeled it \"1\" and if is not we labeled it \"0\". So we have \"1\" for the popular songs and \"0\" for the unpopular ones."}}