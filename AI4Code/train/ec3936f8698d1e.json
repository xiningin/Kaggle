{"cell_type":{"7fc2bdef":"code","d4f6ad92":"code","04ffd55a":"code","39cdaa36":"code","46ce0aa1":"code","23fe6475":"code","d3fbba84":"code","a38ab34f":"code","5d3562af":"code","9af0e612":"code","e079cf77":"code","3d4f4a61":"code","48b56bd1":"code","f734c173":"code","73c1fc80":"code","1629d871":"code","5effab6e":"code","6a3be5d5":"code","015c9346":"code","bf9ff3db":"code","548c445a":"code","0fd1ec89":"code","ec74e203":"code","ec542b4e":"code","9979cc64":"code","d3f38c6d":"code","4fa03ea9":"code","73fda090":"code","b00b873c":"code","ed103273":"code","f33dc0cc":"code","ba9d342b":"code","e1350dae":"code","7b5e0c8d":"code","d76a260a":"code","8d166bbc":"code","deb73eee":"code","b9d634cc":"code","4b97a48a":"code","d7a3a2df":"code","3d56b89f":"code","0f71db66":"code","56c57b5e":"code","90cb4a84":"code","0fc48f50":"code","0310def1":"markdown","a7b4dc49":"markdown","43e52d13":"markdown","5c0c8c47":"markdown","f244df11":"markdown","78a56164":"markdown","373811fe":"markdown","9c5544ad":"markdown","a2ea594c":"markdown","eae710e2":"markdown","823b49b5":"markdown"},"source":{"7fc2bdef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4f6ad92":"import keras \nprint(keras.__version__)","04ffd55a":"#### STEP-1 Loading all necessary libraries \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, cv2, random, time, shutil, csv\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nnp.random.seed(42)\n%matplotlib inline \nimport json\nimport os\nimport cv2\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img","39cdaa36":"#Data Paths\ntrain_dir = '\/kaggle\/input\/dog-breed-identification\/train\/'\ntest_dir = '\/kaggle\/input\/dog-breed-identification\/test\/'\n#Count\/Print train and test samples.","46ce0aa1":"#Read train labels.\nlabels_dataframe = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\n#Read sample_submission file to be modified by pridected labels.\nsample_df = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/sample_submission.csv')\n#Incpect labels_dataframe.\nlabels_dataframe.head(5)\n# here sample df is the format of data to be submitted into kaggle \n","23fe6475":"labels_dataframe.shape","d3fbba84":"# little reminder of working with file and folder with os \nprint(f\"number of pic in test_dir {len(os.listdir(test_dir))}\")\nprint(f\"number of pic in train dir {len(os.listdir(train_dir))}\")","a38ab34f":"# lets crate the  number of unique labels we have available in our dataset \ndog_breeds = sorted(list(set(labels_dataframe.breed)))\nn_classes = len(dog_breeds)\nprint(n_classes)\nprint(dog_breeds[:10])\n\n\n# here we have 120 dog breeeds to classify ","5d3562af":"# so these dog breeds are string so we need to change them into some number for classification\n#Map each label string to an integer label.\nclass_to_num = dict(zip(dog_breeds, range(n_classes)))\nclass_to_num","9af0e612":"(train_dir+labels_dataframe.id+'.jpg')[0]\n# this is how we will access the files from our training data ","e079cf77":"cv2.imread((train_dir+labels_dataframe.id+'.jpg')[0]).shape\n# size of image ","3d4f4a61":"plt.imshow(cv2.imread((train_dir+labels_dataframe.id+'.jpg')[0]))","48b56bd1":"labels_dataframe['file_name'] = labels_dataframe['id'].apply(lambda x:train_dir+f\"{x}.jpg\")","f734c173":"labels_dataframe.head()","73c1fc80":"# now we need to map our breed category according the class_to_num \nlabels_dataframe['breed'] = labels_dataframe.breed.map(class_to_num)\n","1629d871":"labels_dataframe.head()","5effab6e":"y = to_categorical(labels_dataframe.breed)\n# encoded our y variable to pass in our model","6a3be5d5":"from keras.applications.resnet_v2 import ResNet50V2 , preprocess_input as resnet_preprocess\nfrom keras.applications.densenet import DenseNet121, preprocess_input as densenet_preprocess\nfrom keras.layers.merge import concatenate\n\ninput_shape = (331,331,3)\ninput_layer = Input(shape=input_shape)\n\n\n#first extractor inception_resnet\npreprocessor_resnet = Lambda(resnet_preprocess)(input_layer)\ninception_resnet = ResNet50V2(weights = 'imagenet',\n                                     include_top = False,input_shape = input_shape,pooling ='avg')(preprocessor_resnet)\n\npreprocessor_densenet = Lambda(densenet_preprocess)(input_layer)\ndensenet = DenseNet121(weights = 'imagenet',\n                                     include_top = False,input_shape = input_shape,pooling ='avg')(preprocessor_densenet)\n\n\nmerge = concatenate([inception_resnet,densenet])\nmodel = Model(inputs = input_layer, outputs = merge)","015c9346":"model.summary()","bf9ff3db":"model.save('feature_extractor.h5')","548c445a":"loaded_model = keras.models.load_model('.\/feature_extractor.h5')","0fd1ec89":"from keras.utils import plot_model\nplot_model(model, show_shapes = True)","ec74e203":"model.output.shape","ec542b4e":"len(model.trainable_weights)","9979cc64":"# for feature_extraction dataframe must have to contain file_name and  breed columns\ndef feature_extractor(df):\n    img_size = (331,331,3)\n    data_size = len(df)\n    batch_size = 20\n    X = np.zeros([data_size,3072], dtype=np.uint8)\n#     y = np.zeros([data_size,120], dtype=np.uint8)\n    datagen = ImageDataGenerator() # here we dont need to do any image augementaion because we are prediction features \n    generator = datagen.flow_from_dataframe(df,\n    x_col = 'file_name', class_mode = None, \n    batch_size=20, shuffle = False,target_size = (img_size[:2]),color_mode = 'rgb')\n    i = 0\n    \n    for input_batch in tqdm(generator):\n        input_batch = model.predict(input_batch)\n        X[i * batch_size : (i + 1) * batch_size] = input_batch\n        i += 1\n        if i * batch_size >= data_size:\n            break\n    return X\n ","d3f38c6d":"X = feature_extractor(labels_dataframe)\n","4fa03ea9":"X.shape","73fda090":"X\n","b00b873c":"from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n#Prepare call backs\nEarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('\/kaggle\/working\/checkpoint',\n                             monitor = 'val_loss',mode = 'min',save_best_only= True)\nlr = ReduceLROnPlateau(monitor = 'val_loss',factor = 0.5,patience = 3,min_lr = 0.00001)\nmy_callback=[EarlyStop_callback,checkpoint]","ed103273":"dnn = keras.models.Sequential([\n    InputLayer(X.shape[1:]),\n    Dropout(0.7),\n    Dense(n_classes, activation='softmax')\n])\n\ndnn.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Train simple DNN on extracted features.\nh = dnn.fit(X , y,\n            batch_size=128,\n            epochs=60,\n            validation_split=0.1 ,\n           callbacks = my_callback)","f33dc0cc":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\nax1.plot(h.history['loss'],color = 'b',label = 'loss')\nax1.plot(h.history['val_loss'],color = 'r',label = 'val_loss')\nax1.set_xticks(np.arange(1, 60, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\nax1.legend(['loss','val_loss'],shadow = True)\n\n\nax2.plot(h.history['accuracy'],color = 'green',label = 'accuracy')\nax2.plot(h.history['val_accuracy'],color = 'red',label = 'val_accuracy')\nax2.legend(['accuracy','val_accuracy'],shadow = True)\n# ax2.set_xticks(np.arange(1, 60, 1))\n# ax2.set_yticks(np.arange(0, 60, 0.1))\nplt.show()","ba9d342b":"# saving the model\nfrom keras.models import load_model\ndnn.save('\/kaggle\/working\/dogbreed.h5')","e1350dae":"import pickle\nwith open('dog_breeds_category.pickle', 'wb') as handle:\n    pickle.dump(dog_breeds, handle, protocol=pickle.HIGHEST_PROTOCOL)","7b5e0c8d":"test_data = []\nids = []\nfor pic in os.listdir(test_dir):\n    ids.append(pic.split('.')[0])\n    test_data.append(test_dir+pic)","d76a260a":"test_dataframe = pd.DataFrame({'file_name':test_data})\n# we are converting into a dataframe beacause our feature extractor funtion only support dataframe","8d166bbc":"test_features = feature_extractor(test_dataframe)\n","deb73eee":"y_pred = dnn.predict(test_features)","b9d634cc":"def get_key(val): \n    for key, value in class_to_num.items(): \n        if val == value: \n            return key \npred_codes = np.argmax(y_pred, axis = 1)\npredictions = []\nfor i in pred_codes:\n    predictions.append(get_key(i))","4b97a48a":"test_dataframe['breed'] = predictions","d7a3a2df":"np.set_printoptions(suppress=True)","3d56b89f":"pd.set_option('display.float_format', lambda x: '%.10f' % x)","0f71db66":"submission = pd.DataFrame(y_pred, columns = dog_breeds)\nsubmission['id'] = ids\n","56c57b5e":"submission.set_index('id')","90cb4a84":"submission.to_csv('sumbmission.csv', index = False)","0fc48f50":"plt.figure(figsize=(6,6))\n\nfor index , data in test_dataframe[:10].iterrows():\n    img = data['file_name']\n    label = data['breed']\n    img = cv2.imread(img)\n#     plt.subplot(2,5, index+1)\n    plt.imshow(img)\n    plt.xlabel(label,fontsize = (15))\n    plt.tight_layout()\n    plt.show()","0310def1":"#### Uptill now we have created our dataframe with file names and categories ","a7b4dc49":"### its time for prediction \n","43e52d13":"so here the size of labels_dataframe and the size of train directory is the same \nand in train directory every file have unique name and in labels_dataframe we can see the label of that picture and labels_dataframe and train directory both are in ordered manned ","5c0c8c47":"#### Defining some model callbacks for our training","f244df11":"### Lets create a model for training \n","78a56164":"#### Lets Design model architecture for feature extraction\n","373811fe":"#### creating submission  file for the competetion","9c5544ad":"#### Plot the result","a2ea594c":"**Introduction**\n\n* This kernel is a detailed guide for transfer learning on Dog Breeds problem, it's all about learning a new technique, evaluate it using only Kaggle training set without cheating.\n\n* The aim of this kernel is to show you how to use pre-trained CNN models as feature extractors, which one of the most effective transfer learning techniques.\n\n* A reasonable question comes to your mind, 'Wait, why do we have to use this technique, why don't we just use regular transfer learning ?', if you try to do so, you will figure out that the problem is pretty hard for a single model to handle (you would get higher loss and less accuracy).\n\n* It's even hard for humankind to distinguish between 120 dog breeds!, single poor CNN would struggle.\n\n**Explanation**\n\n* Take look at general CNN architecture for image classification in two main parts, \u201cfeature extractor\u201d that based on conv-layers, and \u201cclassifier\u201d which usually based on fully connected layers:\n\n![image.png](attachment:image.png)\n\n* Simply, feature extractor could be created as follow > (Feature Extractor = Pretrained Model - Late Fully Connected Layers)\n\n* For example, InceptionV3 feature extractor (without last FC layer) outputs 2048 vector for each image sample, each value represent a certain feature of dog image (Coded in numerical values of course), like Dog color?, How big is his head?, Shape of the eyes?, length of the tale?, Size? .. etc\n\n* Hence, more \"different\" feature extractors mean more features to be used to determine which breed does this dog belong.\n\n* So our strategy goes as the following,\n  1. Create 4 feature extractor using different pre-trained CNN models\n  2. Extract features from raw data and stacks the features together.\n  3. Use a simple DNN with one dense layer and a heavy dropout layer to figure out patterns in the feature extracted from the data.\n     \n     \n* The code is simple, concise and fully-commented. Feel free to ask for help \/ more info \/ more explanation in the comments.\n\n* Finally if this kernel helps you somehow, kindly don't forget to leave a little upvote.\n\n* ENJOY.\n","eae710e2":"### Plotting some images ","823b49b5":"#### Feature Extraction by usinng pretrained models "}}