{"cell_type":{"96e3bfa4":"code","4d6e31c4":"code","82070740":"code","23debd9f":"code","4e4c0374":"code","74fd6207":"code","0b04731a":"code","f97ba758":"code","bfde0e89":"code","9262c94b":"code","92e7c6ed":"code","7f8e5a08":"code","413ed60a":"code","cc06c0ed":"code","5eb4d047":"code","9e8ae500":"code","3c5863f2":"code","ff4b0282":"code","7c020dc6":"code","a54c4d6e":"code","d545c7e5":"code","3c52b6b9":"code","147167be":"code","992c2a34":"code","74abee03":"code","2cc3aed0":"code","a37c1bb0":"code","84926409":"code","2beac52d":"code","d22877cb":"code","84ac7214":"code","c2fefe1a":"code","854efa22":"code","acd5e30a":"code","4c06c8c8":"code","9f096787":"code","6389401c":"code","3a171747":"code","ffafa0f4":"code","2a32cf05":"code","065e3bf0":"code","2524c8ee":"code","cc780453":"code","f7f41de6":"code","5b6b517e":"code","b5e7f0ae":"code","c5a86193":"code","98deabe2":"code","d523b919":"code","e6ab17a0":"code","87e8394f":"code","10dc9181":"code","dec4986c":"code","beb8750f":"code","01ecd4a8":"code","9a5a0a2e":"code","ae045861":"code","17694ea1":"code","72aea2df":"code","6a8b633b":"code","905f8632":"code","e9c37376":"code","6d5e4a10":"code","0c0b8ebe":"code","f44d11ef":"code","081d0c6d":"code","a2adb604":"code","6ad6b4e0":"code","86e73f85":"markdown","265b702e":"markdown","8046cd50":"markdown","838bec59":"markdown","618ba986":"markdown","3e145712":"markdown","0695c752":"markdown","1880665b":"markdown","63501af7":"markdown","a9653974":"markdown","d15674fa":"markdown","791903de":"markdown","24d24ee0":"markdown","ed39a447":"markdown","9bf671ac":"markdown","ac3d5468":"markdown","3403d7e6":"markdown","738285d3":"markdown","7120aa14":"markdown","64ea6158":"markdown","0e23aa6f":"markdown","0167abe8":"markdown","ed7c8ca0":"markdown","5e3ce545":"markdown","f4887884":"markdown","7a1b9e70":"markdown","80cfbc18":"markdown","a5296cb0":"markdown","0e103fc7":"markdown","bc7df309":"markdown","6fa275ad":"markdown","b5d0089b":"markdown","012786de":"markdown","b30e25c7":"markdown","cf883dc2":"markdown","6b77d3a3":"markdown","cfff70fe":"markdown","e29daecc":"markdown","926ac8d2":"markdown","0aac3abd":"markdown","b3e1d0a9":"markdown","363a36ea":"markdown","8b5a2737":"markdown","7b9380f4":"markdown","e7832047":"markdown","fa324324":"markdown","4570ee03":"markdown","103e5d8c":"markdown","62097cec":"markdown"},"source":{"96e3bfa4":"# Loading packages \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # data visualization\nimport datetime as dt # for date and time manipulation\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot # data visualization\ninit_notebook_mode(connected=True)\n\nimport cufflinks as cf #  to call plots directly off of a pandas dataframe\ncf.go_offline()\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4d6e31c4":"# Loading dataset train, test and store\ntrain=pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/test.csv')\nstore=pd.read_csv('\/kaggle\/input\/rossmann-store-sales\/store.csv')","82070740":"# Looking into each dataset size\nprint('training dataset shape',train.shape)\nprint('testing dataset shape',test.shape)\nprint('store dataset shape',store.shape)","23debd9f":"# train dataset\ntrain.head(3)","4e4c0374":"# test dataset\ntest.head(3)","74fd6207":"# store dataset\nstore.head(3)","0b04731a":"# Samples having 0 sales \nprint('Sample having 0 sales :',train[train['Sales']<=0].shape,'\\n')\nprint('Store Open : 1,','Store Closed : 0')\nprint(train['Open'].value_counts(),'\\n')\nprint('Sample having closed store and sale is 0 :',train[(train['Sales']<=0)&(train['Open']==0)].shape)","f97ba758":"# making new train dataset having sales greater than zero\ntrain=train[train['Sales']>0]\nprint('New training dataset shape',train.shape)","bfde0e89":"# basic information about columns of train dataset\ntrain.info()","9262c94b":"# Converting into datetime format \ntrain['Date']=pd.to_datetime(train['Date'])\ntrain.sort_values(by='Date',ascending=True,inplace=True)\ntrain.reset_index(inplace=True)\ntrain.drop('index',axis=1,inplace=True)\n\n# Start date record in dataset\nstart_date=train['Date'][0]\nprint('Start date :',start_date)\n\n# End date record in dataset\nend_date=train['Date'][844337]\nprint('End date :',end_date)","92e7c6ed":"# unique values of categorical columns \nfor i in ['DayOfWeek','Open','Promo','StateHoliday','SchoolHoliday']:\n    print( i+':',train[i].unique())","7f8e5a08":"# Droping 'Open' column and making correction in 'StateHoliday' column\nindex=train[train['StateHoliday']==0].index\ntrain['StateHoliday'][index]='0'\ntrain['StateHoliday'].value_counts()\ntrain.drop('Open',axis=1,inplace=True)\n\n# Note : I have converted numeric into string format in StateHoliday column because majority of variables are in string format","413ed60a":"# Checking for negative values\npd.options.display.float_format = '{:.0f}'.format # in order to round up the numbers \ntrain.describe()","cc06c0ed":" # Scatter plot \"Sales Vs Customers\"\nplt.figure(figsize=(15,8))\nsns.scatterplot(x='Sales',y='Customers',data=train,hue='DayOfWeek',palette='coolwarm')\nplt.title('Sales vs Customers',fontdict={'fontsize':20})\nplt.show()\n\n# Count of Weekdays \nplt.figure(figsize=(15,4))\nprint(train['DayOfWeek'].value_counts())\nsns.countplot('DayOfWeek',data=train,palette='coolwarm')\nplt.title('Count of weekdays',fontdict={'fontsize':20})\nplt.show()\n\n# Weekdays wise scatter plot between Sales and Customers\ng=sns.FacetGrid(row='DayOfWeek',data=train,height=3,aspect=4)\ng.map(plt.scatter,'Sales','Customers',color='green',alpha=0.4)\nplt.show()\n\n# Boxplot - \"Sales\"\nplt.figure(figsize=(15,8))\nsns.boxplot(y='Sales',x='DayOfWeek',data=train,palette='Set3')\nplt.title('Sales Statistics',fontdict={'fontsize':20})\nplt.show()\n\n\n# Boxplot - \"Customers\"\nplt.figure(figsize=(15,8))\nsns.boxplot(y='Customers',x='DayOfWeek',data=train,palette='Set3')\nplt.title('Customers Statistics',fontdict={'fontsize':20})\nplt.show()","5eb4d047":"# Scatter plot \"Sales Vs Customers\"\nplt.figure(figsize=(15,8))\nsns.scatterplot(x='Sales',y='Customers',data=train,hue='Promo',palette='plasma')\nplt.title('Sales vs Customers',fontdict={'fontsize':20})\nplt.show()\n\n# Promo wise scatter plot between Sales and Customers\ng=sns.FacetGrid(row='Promo',data=train,height=3,aspect=4)\ng.map(plt.scatter,'Sales','Customers',color='blue',alpha=0.4)\nplt.show()\n\n# Boxplot - \"Sales\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Sales',x='Promo',data=train,palette='Set3')\nplt.title('Sales Statistics',fontdict={'fontsize':20})\nplt.show()\n\n# Boxplot - \"Customers\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Customers',x='Promo',data=train,palette='Set3')\nplt.title('Customers Statistics',fontdict={'fontsize':20})\nplt.show()","9e8ae500":"# Scatter plot \"Sales Vs Customers\"\nplt.figure(figsize=(15,8))\nsns.scatterplot(x='Sales',y='Customers',data=train,hue='StateHoliday',palette='autumn',hue_order=['a','b','c','0'])\nplt.title('Sales vs Customers',fontdict={'fontsize':20})\nplt.show()\n\n# State Holiday wise scatter plot between Sales and Customers\ng=sns.FacetGrid(row='StateHoliday',data=train,height=3,aspect=4)\ng.map(plt.scatter,'Sales','Customers',color='purple',alpha=0.4)\nplt.show()\n\n# Boxplot - \"Sales\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Sales',x='StateHoliday',data=train,order=['a','b','c','0'],palette='Set3')\nplt.title('Sales Statistics',fontdict={'fontsize':20})\nplt.show()\n\n# Boxplot - \"Customers\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Customers',x='StateHoliday',data=train,order=['a','b','c','0'],palette='Set3')\nplt.title('Customers Statistics',fontdict={'fontsize':20})\nplt.show()","3c5863f2":"# Scatter plot \"Sales Vs Customers\"\nplt.figure(figsize=(15,8))\nsns.scatterplot(x='Sales',y='Customers',data=train,hue='SchoolHoliday',palette='viridis')\nplt.title('Sales vs Customers',fontdict={'fontsize':20})\nplt.show()\n\n# State Holiday wise scatter plot between Sales and Customers\ng=sns.FacetGrid(row='SchoolHoliday',data=train,height=3,aspect=4)\ng.map(plt.scatter,'Sales','Customers',color='orange',alpha=0.4)\nplt.show()\n\n# Boxplot - \"Sales\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Sales',x='SchoolHoliday',data=train,palette='Set3')\nplt.title('Sales Statistics',fontdict={'fontsize':20})\nplt.show()\n\n# Boxplot - \"Customers\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Customers',x='SchoolHoliday',data=train,palette='Set3')\nplt.title('Customers Statistics',fontdict={'fontsize':20})\nplt.show()","ff4b0282":"# Making new column of sales per customers \ntrain['SalesPerCustomer']=train['Sales']\/train['Customers']\ntrain['SalesPerCustomer']","7c020dc6":"Table_1=pd.pivot_table(data=train,index=['DayOfWeek','Promo'],values=['Sales','Customers','SalesPerCustomer'],aggfunc='mean').round(0)\nTable_1.rename(columns=lambda x : 'Avg_' + x, inplace=True)\n\n# Visualization\nTable_1.iplot(kind='bar',y=['Avg_Sales','Avg_Customers'],title='Average Sales and Average Customers',xTitle='(DayOfWeek,Promo)')\nTable_1.iplot(y='Avg_SalesPerCustomer',title='Average Sales per Customers',xTitle='(DayOfWeek,Promo)')\n\nTable_1","a54c4d6e":"Table_2=pd.pivot_table(data=train,index=['Promo','StateHoliday'],values=['Sales','Customers','SalesPerCustomer'],aggfunc='mean').round(0)\nTable_2.rename(columns=lambda x : 'Avg_' + x, inplace=True)\n\n# Visualization\nTable_2.iplot(kind='bar',y=['Avg_Sales','Avg_Customers'],title='Average Sales and Average Customers',xTitle='(Promo,StateHoliday)')\nTable_2.iplot(y='Avg_SalesPerCustomer',title='Average Sales per Customers',xTitle='(Promo,StateHoliday)')\n\nTable_2","d545c7e5":"# Checking the columns of store dataset\nstore.info()","3c52b6b9":"# Converting Promo2 column data from integer to category type\nstore['Promo2']=store['Promo2'].astype(object)\nstore.dtypes","147167be":"# Checking the unique values of category columns\nfor i in store.columns[store.dtypes=='object']:\n    print(i,':',store[i].unique(),'\\n')","992c2a34":"pd.options.display.float_format='{:.3f}'.format # in order to show number upto 3 decimal place\n\n# avg_store Dataframe containing columns : 'Average Sales','Average Customers','Average Sales Per Customer'\navg_store=train.groupby('Store')[['Sales','Customers','SalesPerCustomer']].mean()\navg_store.rename(columns=lambda x : 'Avg_' + x,inplace=True)\navg_store.reset_index(inplace=True)\n\n# Adding column Max_Customers(containing maximum value of customers) to avg_store Dataframe \nMax_customer=train.groupby('Store')['Customers'].max()\navg_store=pd.merge(avg_store,Max_customer,how='inner',on='Store')\navg_store.rename(columns={'Customers':'Max_Customers'},inplace=True)\n\n# Adding column Min_Customers(containing mimimum value of customers) to avg_store Dataframe \nMin_customer=train.groupby('Store')['Customers'].min()\navg_store=pd.merge(avg_store,Min_customer,how='inner',on='Store')\navg_store.rename(columns={'Customers':'Min_Customers'},inplace=True)\n\n# Adding column Std_Customers(containing Standard Deviation value of customers) to avg_store Dataframe \nStd_customer=train.groupby('Store')['Customers'].std()\navg_store=pd.merge(avg_store,Std_customer,how='inner',on='Store')\navg_store.rename(columns={'Customers':'Std_Customers'},inplace=True)\n\n# Adding column Med_Customers(containing Median value of customers) to avg_store Dataframe \nMed_customer=train.groupby('Store')['Customers'].median()\navg_store=pd.merge(avg_store,Med_customer,how='inner',on='Store')\navg_store.rename(columns={'Customers':'Med_Customers'},inplace=True)\n\navg_store.head()\n\n# In order to capture all the variability of customer columns, these much columns are made ","74abee03":"# Merging avg_store with store\nstore=pd.merge(store,avg_store,how='inner',on='Store')\nstore.head()","2cc3aed0":"# Removing missing values in CompetitionDistance column\nindex=store[store['CompetitionDistance'].isnull()].index\nstore.loc[index,'CompetitionDistance']=0\nstore['CompetitionDistance'].isnull().any() # for checking","a37c1bb0":"# Scatter plot - Average sale against Competition Distance\nplt.figure(figsize=(15,6))\nsns.set_style('darkgrid')\nsns.scatterplot(x='Avg_Sales',y='CompetitionDistance',data=store)\nplt.title('Average sale against Competition Distance',fontdict={'fontsize':20})\nplt.show()\n\n# Visualization of Competition Distance data\nplt.figure(figsize=(15,6))\nsns.distplot(store['CompetitionDistance'])\nplt.title('Competition Distance distribution',fontdict={'fontsize':20})\nplt.xlim(0,80000)\nplt.show()","84926409":"# unique value check \n\nprint('CompetitionOpenSinceMonth :',store['CompetitionOpenSinceMonth'].unique(),'\\n')\n\nprint('CompetitionOpenSinceYear :',store['CompetitionOpenSinceYear'].unique(),'\\n')\n\nprint('Promo2SinceWeek :',store['Promo2SinceWeek'].unique(),'\\n')\n\nprint('Promo2SinceYear :',store['Promo2SinceYear'].unique())","2beac52d":"# Getting free from missing values\n\nindex=store[(store['CompetitionOpenSinceMonth'].isnull())&(store['CompetitionOpenSinceYear'].isnull())].index\nstore.loc[index,['CompetitionOpenSinceMonth','CompetitionOpenSinceYear']]=0\n\nindex=store[(store['Promo2SinceWeek'].isnull())&(store['Promo2SinceYear'].isnull())&(store['Promo2']==0)].index\nstore.loc[index,['Promo2SinceWeek','Promo2SinceYear']]=0\n\nstore[['CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear']].isnull().any() # To check","d22877cb":"# Converting from float into integer type\nstore[['CompetitionOpenSinceMonth',\n       'CompetitionOpenSinceYear',\n       'Promo2SinceWeek',\n       'Promo2SinceYear']]=store[['CompetitionOpenSinceMonth',\n                                  'CompetitionOpenSinceYear',\n                                  'Promo2SinceWeek',\n                                  'Promo2SinceYear']].astype(int)\n\nstore[['CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear']].dtypes # To check","84ac7214":"# Setting Promo Interval equal to zero for those who are not continuing Promo and for missing values\nindex=store[(store['Promo2']==0)&(store['PromoInterval'].isnull().any())].index\nstore.loc[index,'PromoInterval']=0\n\nstore['PromoInterval'].isnull().any() # To check","c2fefe1a":"# Last check in columns of store\nstore.info()","854efa22":"# scatter plot - Average Customers against Average Sales\nplt.figure(figsize=(15,8))\nsns.lmplot(x='Avg_Customers',y='Avg_Sales',hue='StoreType',data=store,hue_order=['a','b','c','d'],height=6,aspect=2.5)\nplt.title('Average Customers Vs Average Sales', fontdict={'fontsize':20})\nplt.show()\n\n# boxplot - Average sale per customers \nplt.figure(figsize=(15,5))\nsns.boxplot(x='StoreType',y='Avg_SalesPerCustomer',data=store,order=['a','b','c','d'],palette='Set3')\nplt.title('Average sale per customers Statistics', fontdict={'fontsize':20})\nplt.show()","acd5e30a":"# scatter plot - Average Customers against Average Sales\nplt.figure(figsize=(15,8))\nsns.lmplot(x='Avg_Customers',y='Avg_Sales',hue='Assortment',data=store,hue_order=['a','b','c'],height=6,aspect=2.5)\nplt.title('Average Customers Vs Average Sales', fontdict={'fontsize':20})\nplt.show()\n\n# boxplot - Average sale per customers\nplt.figure(figsize=(15,5))\nsns.boxplot(x='Assortment',y='Avg_SalesPerCustomer',data=store,order=['a','b','c'],palette='Set3')\nplt.title('Average sale per customers Statistics', fontdict={'fontsize':20})\nplt.show()","4c06c8c8":"# scatter plot - Average Customers against Average Sales\nsns.lmplot(x='Avg_Customers',y='Avg_Sales',hue='Promo2',data=store,height=6,aspect=2.5)\nplt.title('Average Customers Vs Average Sales', fontdict={'fontsize':20})\nplt.show()\n\n# boxplot - Average sale per customers\nplt.figure(figsize=(15,5))\nsns.boxplot(x='Promo2',y='Avg_SalesPerCustomer',data=store,palette='Set3')\nplt.title('Average sale per customers Statistics', fontdict={'fontsize':20})\nplt.show()\n\n# scatter plot - Maximum Average Customers against Minimum Average Customers\nsns.lmplot(x='Max_Customers',y='Min_Customers',hue='Promo2',data=store,height=6,aspect=2.5)\nplt.title('Maximum Average Customers Vs Minimum Average Customers', fontdict={'fontsize':20})\nplt.show()","9f096787":"# scatter plot - Average Customers against Average Sales\nplt.figure(figsize=(15,8))\nsns.lmplot(x='Avg_Customers',y='Avg_Sales',hue='PromoInterval',data=store,height=6,aspect=2.5)\nplt.title('Average Customers Vs Average Sales', fontdict={'fontsize':20})\nplt.show()\n\n# boxplot - Average sale per customers\nplt.figure(figsize=(15,5))\nsns.boxplot(x='PromoInterval',y='Avg_SalesPerCustomer',data=store,palette='Set3')\nplt.title('Average sale per customers Statistics', fontdict={'fontsize':20})\nplt.show()","6389401c":"Table_3=pd.pivot_table(data=store,index=['StoreType','Assortment','PromoInterval'],\n               values=['Avg_Sales','Avg_Customers','Avg_SalesPerCustomer'],aggfunc='mean').round(0)\n\nTable_3.iplot(kind='bar',y=['Avg_Sales','Avg_Customers'],title='Average Sales and Average Customers',\n              xTitle='(StoreType,Assortment,Assortment)')\n\nTable_3.iplot(y='Avg_SalesPerCustomer',title='Average Sales per customers',xTitle='(StoreType,Assortment,Assortment)')\n\nTable_3","3a171747":"# Merging\nnew_train=pd.merge(train,store,how='left',on='Store')\nprint('New training dataset shape :',new_train.shape)\nnew_train.head()","ffafa0f4":"# Making new columns to show Date information separately \nnew_train['Year']=new_train['Date'].dt.year\nnew_train['Month']=new_train['Date'].dt.month\nnew_train['Day']=new_train['Date'].dt.day\nnew_train['Week']=new_train['Date'].dt.week\nnew_train.head()","2a32cf05":"# Making column \"MonthCompetitionOpen\" which contains date information in months since the competition was opened \nnew_train['MonthCompetitionOpen']=12*(new_train['Year']-new_train['CompetitionOpenSinceYear'])+\\\nnew_train['Month']-new_train['CompetitionOpenSinceMonth']\n\nnew_train.loc[(new_train['CompetitionOpenSinceYear']==0),'MonthCompetitionOpen']=0\n# Negative values indcate that the competitor's store was opened after the Rossman's store opening date.","065e3bf0":"# Making column \"WeekPromoOpen\" which contains date information in weeks since the promo is running\nnew_train['WeekPromoOpen']=52.14298*(new_train['Year']-new_train['Promo2SinceYear'])+\\\nnew_train['Week']-new_train['Promo2SinceWeek']\n\nnew_train.loc[(new_train['Promo2SinceYear']==0),'WeekPromoOpen']=0","2524c8ee":"# scatter plot - Sales against Customers\ng=sns.FacetGrid(row='Month',data=new_train,height=3,aspect=4)\ng.map(plt.scatter,'Sales','Customers',color='red',alpha=0.4)\nplt.show()\n\n# Boxplot - \"Sales\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Sales',x='Month',data=new_train,palette='Set3')\nplt.title('Sales Statistics',fontdict={'fontsize':20})\nplt.show()\n\n# Boxplot - \"Customers\"\nplt.figure(figsize=(10,8))\nsns.boxplot(y='Customers',x='Month',data=new_train,palette='Set3')\nplt.title('Customers Statistics',fontdict={'fontsize':20})\nplt.show()","cc780453":"Table_4=pd.pivot_table(data=new_train,index=['Month','Promo'],\n                      values=['Avg_Sales','Avg_Customers','Avg_SalesPerCustomer'],aggfunc='mean').round(0)\n\n# Visualization\nTable_4.iplot(kind='bar',y=['Avg_Sales','Avg_Customers'],title='Average Sale and Average Customers',xTitle='(Months,Promo)')\nTable_4.iplot(y='Avg_SalesPerCustomer',title='Average sales per customer',xTitle='(Months,Promo)')\n\ndel(Table_4)","f7f41de6":"new_train.info()","5b6b517e":"# converting into integer type\nnew_train['Promo2']=new_train['Promo2'].astype(int)","b5e7f0ae":"\"\"\"Droping column customer because we are performing sales prediction and knowing the number of customers on particular store before actual\n   sales happen is not possible\"\"\"\nnew_train.drop('Customers',axis=1,inplace=True)","c5a86193":"# Making a new data set for model building\ntrainS=new_train[['Store', 'DayOfWeek','Sales','Promo',\n       'StateHoliday', 'SchoolHoliday','StoreType',\n       'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n       'Promo2SinceYear', 'PromoInterval','Avg_Customers',\n       'Max_Customers', 'Min_Customers',\n       'Std_Customers', 'Med_Customers', 'Year', 'Month', 'Day', 'Week',\n       'MonthCompetitionOpen', 'WeekPromoOpen']]\ntrainS.shape","98deabe2":"# Visualization to chech whether the data is distributed normally\ntrainS.hist(figsize=(25,25))\nplt.show()","d523b919":"# Taking log transformation \ntrainS['Log_Sales']=np.log(trainS['Sales'])\n\nindex=trainS[trainS['CompetitionDistance']==0].index\ntrainS['CompetitionDistance'][index]=1\ntrainS['Log_CompetitionDistance']=np.log(trainS['CompetitionDistance'])\n\ntrainS[['Log_Sales','Log_CompetitionDistance',]].hist(figsize=(8,5))\nplt.show()\n\ntrainS.drop(['Sales','CompetitionDistance'],axis=1,inplace=True)\n\n# Note : This is not a necessary step but doing this will redistribute the data in normal curve which is better for good prediction ","e6ab17a0":"# Getting dummies columns for categorical columns \nfinal_train=pd.get_dummies(data=trainS,columns=['StoreType','StateHoliday','Assortment','PromoInterval'])\nfinal_train.shape","87e8394f":"# Spliting dataset into X and y \nX=final_train.drop('Log_Sales',axis=1)\ny=final_train['Log_Sales']\n\n# Spliting dataset into test and train\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101) ","10dc9181":"from sklearn.ensemble import RandomForestRegressor\n\nrfr=RandomForestRegressor(n_estimators=200,\n                          criterion='mse',\n                          max_features='sqrt',\n                          oob_score=True,\n                          n_jobs=32,\n                          verbose=1,\n                          random_state=101)\n\nrfr.fit(X_train,y_train)","dec4986c":"# Prediction\npredict=rfr.predict(X_test)\npredict","beb8750f":"# Out of Bag score\nprint('oob score :',rfr.oob_score_)","01ecd4a8":"# Root mean square error\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nmse=mean_squared_error(np.exp(y_test),np.exp(predict))\nprint('Root Mean Square Error {}'.format(sqrt(mse)))","9a5a0a2e":"# Import attributes according to model\npd.options.display.float_format='{:.5f}'.format\nimportant_features=pd.DataFrame(rfr.feature_importances_,index=X_train.columns)\nimportant_features.sort_values(by=0,ascending=False)","ae045861":"# Visualization of important features\nimportant_features.sort_values(by=0,ascending=False).iplot(mode='markers',title='Important Attributes')","17694ea1":"prediction=pd.DataFrame(np.exp(y_test))\nprediction['Sales_prediction']=np.exp(predict).round()\nprediction.rename(columns={'Log_Sales':'Sales'},inplace=True)\n\n# Visualization\nplt.figure(figsize=(8,8))\nsns.scatterplot(x='Sales',y='Sales_prediction',data=prediction)\nplt.title('Actual vs Prediction of Sales',fontdict={'fontsize':20})\nplt.show()\n\nprediction.reset_index(inplace=True)\nprediction.drop('index',axis=1,inplace=True)\nprediction","72aea2df":"# Residual Histogram\nplt.figure(figsize=(15,8))\nsns.distplot((np.exp(y_test)-np.exp(predict)),bins=100)\nplt.title('Residual Histogram',fontdict={'fontsize':15})\nplt.show()","6a8b633b":"test.info()","905f8632":"# Merging the store set\nnew_test=pd.merge(test,store,how='inner',on='Store')\nnew_test.drop(['Avg_Sales','Avg_SalesPerCustomer','Open'],axis=1,inplace=True)\nnew_test.info()","e9c37376":"# Making new columns to show Date information separately \nnew_test['Year']=new_train['Date'].dt.year\nnew_test['Month']=new_train['Date'].dt.month\nnew_test['Day']=new_train['Date'].dt.day\nnew_test['Week']=new_train['Date'].dt.week\nnew_test.drop('Date',axis=1,inplace=True)\nnew_test.info()","6d5e4a10":"# Making column \"MonthCompetitionOpen\" which contains date information in months since the competition was opened \nnew_test['MonthCompetitionOpen']=12*(new_test['Year']-new_test['CompetitionOpenSinceYear'])+\\\nnew_test['Month']-new_test['CompetitionOpenSinceMonth']\n\nnew_test.loc[(new_test['CompetitionOpenSinceYear']==0),'MonthCompetitionOpen']=0\n# Negative values indcate that the competitor's store was opened after the Rossman's store opening date.\n\n# Making column \"WeekPromoOpen\" which contains date information in weeks since the promo is running\nnew_test['WeekPromoOpen']=52.14298*(new_test['Year']-new_test['Promo2SinceYear'])+\\\nnew_test['Week']-new_test['Promo2SinceWeek']\n\nnew_test.loc[(new_test['Promo2SinceYear']==0),'WeekPromoOpen']=0","0c0b8ebe":"# Checking the categorical variable columns unique values\nfor i in new_test.columns[new_test.dtypes=='object']:\n    print(i+':',new_test[i].unique())","f44d11ef":"# Converting into integer format\nnew_test['Promo2']=new_test['Promo2'].astype(int)\n\n# Deleting Id column from new_test dataset\nId=new_test['Id']\nnew_test.drop('Id',axis=1,inplace=True)\n\n# Getting dummy columns\nnew_test=pd.get_dummies(new_test)\nnew_test.info()","081d0c6d":"# Making new columns to match the numbers with the X_train columns\nnew_test['StateHoliday_b']=0\nnew_test['StateHoliday_c']=0\nnew_test=pd.get_dummies(new_test,columns=['StateHoliday_b','StateHoliday_c'])\nnew_test.rename(columns={'StateHoliday_b_0':'StateHoliday_b','StateHoliday_c_0':'StateHoliday_c'},inplace=True)\nnew_test.info()","a2adb604":"# Final prediction for submission\n\nSales=np.exp(rfr.predict(new_test))\n\npd.options.display.float_format='{:.0f}'.format\nFinal_submission=pd.DataFrame(Sales)\nFinal_submission['Id']=test['Id']\nFinal_submission.rename(columns={0:'Sales'},inplace=True)\nFinal_submission=Final_submission[['Id','Sales']]\nFinal_submission","6ad6b4e0":"Final_submission.to_csv('Random_Forest_Regression_submission.csv',index=False)","86e73f85":"### 3.2.4 Predictions from Model","265b702e":"* 4 new columns were added","8046cd50":"## 2.5 Visualization based on Assortment","838bec59":"## 2.1 Table_1 : Average sales, average number of customers and average sales per customers based on weekdays and whether the promo is running on that day. ","618ba986":"* People are more often to buy more on Christmas and Easter festival, therefore sales and count of customers visit are more on this seasons\n* But it is clearly seen the variation in public choice is less in these festival as people tend to buy particular range and type of product,where as the opposite behavior is been observed when there is no holiday","3e145712":"## 2.4 Visualization based on Store type","0695c752":"## 2.10 Visualization based on Months ","1880665b":"* Some of the columns data are positively skewed, therefore have to deal with it.\n* This is not a necessary step but normally distributed data yields better result","63501af7":"* It is quite interesting to observe that the line of assortment type a and c are almost parallel, ie. both are having the same average number of customers but the sales are higher in type c\n* Also the sales rate is highest in type c","a9653974":"* The sales rate are almost same ","d15674fa":"* Almost normally distributed ","791903de":"### 1.2 Visualization based on running Promo","24d24ee0":"* The train dataset have total 172817 samples having 0 sale and the store is closed. Model is building to predict the sale, therefore getting rid of irrelevant samples ","ed39a447":"## 2.2 Table_2 : Average sales, average number of customers and average sales per customer based on State Holidays and whether the promo is running on that day. ","9bf671ac":"* The data is clean and free from missing values","ac3d5468":"* As early said Christman and Easter festival season shows high rate of sales ","3403d7e6":"# 3. Building and Implementing Machine Learning Models","738285d3":"### 1.4 Visualization based on School Holidays ","7120aa14":"### 1.3 Visualization based on State Holidays ","64ea6158":"* Open column having only 1 value so no need of this column\n* StateHoliday column having two identical values but in different format so need to deal with this ","0e23aa6f":"## 2.6 Visualization based on whether the Promo is continuing ","0167abe8":"## 2.11 Table_4 : Average sales, average number of customers and average sales per customer based on Months.","ed7c8ca0":"## 2.9 Merging train and store dataset to form new train dataset containing all the attributes ","5e3ce545":"## 2.7 Visualization based on Promo Interval","f4887884":"## 2.8 Table_3 : Average sales, average number of customers and average sales per customer based on StoreType, Assortment and Promo Interval.","7a1b9e70":"* No promo was runned on weekends.\n* The average sales and average number of customers on weekdays while running promo is high than not running promo.\n* The average sale on sunday is quite high than some of the weekdays and the average number of customers is the highest on sunday.\n* The average sale per customer is also high on days when promo was runned but the weekends is showing low sales rate. This means people are not buying even though they are capable of as it is evident in the weekdays.\n* Should capture the profit potential seen on weekends by running Promos on weekends ","80cfbc18":"## 2.3 Creating Dataframe - \"avg_store\" and merging with store dataset for further analysis","a5296cb0":"* There is much difference in sale before and after running Promo. It indicates that promo have done a great job in increasing the sale\n* Not much noticable difference is seen in number of customers visit to store. Promo idea was not capable to attract new customers but the buying quantity of existing old customers have increased, therefore overall the running of promo worked  ","0e103fc7":"* From the above table as well as figures it is clear that continuing promo is not helping the business, it does not matter on which month the promo was runned .\n* The b type store is most effected as sales rate is lowest","bc7df309":"* Dataset is pretty much clear","6fa275ad":"* Not much difference is observed by the closure of public schools","b5d0089b":"# 2. Feature Engineering","012786de":"### 3.2.1 Spliting the dataset","b30e25c7":"### 1.1 Visualization based on Days of Week","cf883dc2":"### 3.2.3 Model Evaluation ","6b77d3a3":"* The 7th day of week has very less variability as compare to other days of week\n* The count of 7th days is very less as compare to other days but the average sales and average number of customers are pretty much high. One possible reason could be on sunday customers comes for a specific commodity as an essential need for survival","cfff70fe":"* There are lots of column having null values\n* Some columns are not having right format data, so need to take care of it","e29daecc":"# 1. Exploratory Data Analysis and Visualization","926ac8d2":"* We don't have negative values in dataset, therefore dataset is very clean","0aac3abd":"* In the first figure : the line at the begining overlaps each other but as its moves further it diverge from each other with 0 assigned line showing more sales for the same number of customers \n* The box plot shows the sales rate is high for those store who are continuing the promo but the difference is narrow \n* In the last figure : there is still divergence in line and the mimimum number of customers is less for the 1 assigned line as compare to 0 assigned one \n* this indicates the continuing of advertisements and promo is not a good idea as people are getting bored with the same promo.","b3e1d0a9":"* Store type d is having much higher sale but the variability is very less as people are buying one particular set of products \n* Store type a and c are same sales but both are less than d type\n* The least one is b type store and its shows large variability. May be this type of store is located in rural or suburban area \n* As expected the sales rate of d type is higher than a and c type and b type have very less sales rate ","363a36ea":"#### Further model can be enhanced by\n* Droping some of the very low assigned weightage columns \n* Standard normalize scaling the whole dataset\n* Hyper tuning the parameters \n\n#### Some of the code for hyper tuning the parameters using GridSearchCv\n\n      from sklearn.model_selection import GridSearchCV\n      from sklearn.ensemble import RandomForestRegressor\n\n      rfr=RandomForestRegressor(random_state=101)\n\n      param_grid=dict(n_estimators=np.arange(200,500,50),max_depth=np.arange(2,6,1),\n                max_features=['auto','sqrt'],min_samples_leaf=[3,4,5],min_samples_split=[3,4,5])\n\n      gridSearch=GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 4, n_jobs = 32,\n                        verbose=1,scoring='neg_mean_squared_error')\n\n      gridSearch.fit(X_train,y_train)\n      gridSearch.best_param\n\n* Using best parameter obtain by GridSearch to build again random forest model and making the prediction and evaluating the model based on root mean square error.\n\nNote : I have not performed hypertuning because i have used maximum of provided ram by kaggle.","8b5a2737":"# 4. Test dataset prediction for submission","7b9380f4":"* It seens there are less competitor's store near to Rossman's store\n* Even though many competitor's are near to Rossman's store, the sale is far good enough to beat the compoetition. May be this is because good service quality, better behaviour towards customers and last but not least is the quality of product.","e7832047":"## 3.2 Model Building : Random Forest Regressor ","fa324324":"## 3.1 Preparing dataset and Normalizing certain column data","4570ee03":"* Date column having date information but is of object type, so have to convert into datetime format \n* Dataset does not cantain any missing values","103e5d8c":"* Now it is obvious that the month of November and December the sale and number of customers would be high\n* Sales are also high in the summer season","62097cec":"### 3.2.2 Creating and Training the model "}}