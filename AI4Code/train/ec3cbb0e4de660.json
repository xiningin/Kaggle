{"cell_type":{"e39e4088":"code","03e42826":"code","410c9a40":"code","4a721317":"code","2033556c":"code","d8279847":"code","580ca2c5":"code","98973a08":"code","7d445713":"code","ec418447":"code","cee7e5fb":"code","0f282703":"code","ce565590":"code","a9167363":"code","6a2cf5d2":"code","a09eb3d1":"code","af2bc327":"code","d2aa6dd7":"code","5ae43a7c":"code","269f7b35":"code","09e66758":"code","3718a3bb":"code","f708034d":"code","7845676d":"code","b27689a5":"code","31d14d24":"code","36051833":"code","9c92bec9":"code","92b5c023":"code","73df6dc0":"code","f4abaf41":"code","3ec8b0d2":"code","328b7e66":"code","cde1cc3d":"code","dd7aef53":"code","cb810772":"markdown","06ceab01":"markdown","151cfc91":"markdown","f2908126":"markdown","2adc4b06":"markdown","643911c9":"markdown","63febcbf":"markdown","5be1a2be":"markdown","3c80bc68":"markdown","f709f4cf":"markdown","ee258b01":"markdown","4a1aa4a2":"markdown","ee212dad":"markdown","67dd53f1":"markdown","06577992":"markdown","1e7d7d0c":"markdown","0b9abaf3":"markdown","af00cebd":"markdown","3ca5b814":"markdown","c78b072c":"markdown","f1f0aaea":"markdown","61923517":"markdown","454c5b2e":"markdown","8721cf05":"markdown","3d8e8a38":"markdown","5bdda931":"markdown","cfae2e07":"markdown","742954e8":"markdown","ee98edbc":"markdown","ebf0c9bf":"markdown"},"source":{"e39e4088":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport tensorflow as tf\nfrom keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D,BatchNormalization\n\nimport glob, os, random","03e42826":"base_garbage = '..\/input\/garbage-classification\/Garbage classification\/Garbage classification'\n\nimg_list = glob.glob(os.path.join(base_garbage, '*\/*.jpg'))\n\nprint(len(img_list))\n","410c9a40":"train_garbage=ImageDataGenerator(horizontal_flip=True,\n                         vertical_flip=True,\n                         validation_split=0.2,\n                         rescale=1.\/255,\n                         shear_range = 0.1,\n                         zoom_range = 0.1,\n                         width_shift_range = 0.1,\n                         height_shift_range = 0.1,)\n\ntest_garbage=ImageDataGenerator(rescale=1\/255,\n                        validation_split=0.2)\n\ntrain_generator_g=train_garbage.flow_from_directory(base_garbage,\n                                          target_size=(100,100),\n                                          batch_size=32,\n                                          class_mode='categorical',\n                                          subset='training',seed=42)\n\ntest_generator_g=test_garbage.flow_from_directory(base_garbage,\n                                        target_size=(100,100),\n                                        batch_size=32,\n                                        class_mode='categorical',\n                                        subset='validation',seed=42)\n\nlabels = (train_generator_g.class_indices)\nprint(labels)\n\nlabels = dict((v,k) for k,v in labels.items())\nprint(labels)","4a721317":"base_rice = '..\/input\/rice-leaf-diseases\/rice_leaf_diseases'\nimg_list = glob.glob(os.path.join(base_rice, '*\/*.*'))\nprint(len(img_list))\n","2033556c":"train_rice=ImageDataGenerator(horizontal_flip=True,\n                         vertical_flip=True,\n                         validation_split=0.1,\n                         rescale=1.\/255,\n                         shear_range = 0.1,\n                         zoom_range = 0.1,\n                         width_shift_range = 0.1,\n                         height_shift_range = 0.1,)\n\ntest_rice=ImageDataGenerator(rescale=1\/255,\n                        validation_split=0.1) #Mas peque\u00f1o al ser pocos datos\n\ntrain_generator_r=train_rice.flow_from_directory(base_rice,\n                                          target_size=(64,64),\n                                          batch_size=32,\n                                          class_mode='categorical',\n                                          subset='training',seed=42)\n\ntest_generator_r=test_rice.flow_from_directory(base_rice,\n                                        target_size=(64,64),\n                                        batch_size=32,\n                                        class_mode='categorical',\n                                        subset='validation',seed=42)\n\nlabels = (train_generator_r.class_indices)\nprint(labels)\n\nlabels = dict((v,k) for k,v in labels.items())\nprint(labels)\n\n","d8279847":"labels_garbage = os.listdir(base_garbage)\nlabels_rice = os.listdir(base_rice)","580ca2c5":"for i in labels_garbage:\n    directory = os.path.join(base_garbage, i)\n    print(\"Images of label \\\"\" + i + \"\\\":\\t\", len(os.listdir(directory)))","98973a08":"import matplotlib.image as mpimg\n\nplt.figure(figsize=(15,15))\n\nfor i in range(6):\n    directory = os.path.join(base_garbage, labels_garbage[i])\n    for j in range(5):\n        path = os.path.join(directory, os.listdir(directory)[j])\n        img = mpimg.imread(path)\n        \n        plt.subplot(6, 5, i*5 + j + 1)\n        plt.imshow(img)\n        \n        if j == 0:\n            plt.ylabel(labels_garbage[i], fontsize=20)\n        \nplt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\nplt.tight_layout()\nplt.show()","7d445713":"#Se revisa el tama\u00f1o de las imagenes \nfor image_batch, label_batch in train_generator_g:\n  break\nimage_batch.shape, label_batch.shape","ec418447":"# definicion del modelo Perceptron\nmodel = keras.Sequential(\n    [\n        layers.Flatten(input_shape=(100, 100, 3)),\n        layers.Dropout(0.1),\n        layers.Dense(1000, activation=\"relu\"),\n        layers.Dense(750, activation=\"relu\"),# Se prueba con otra funcion de activacion\n        layers.Dense(500, activation=\"relu\"),\n        layers.Dense(250, activation=\"relu\"),\n        layers.Dense(125, activation=\"relu\"),\n        layers.Dense(6, activation=\"softmax\"),\n    ]\n)\n\n# Construir el modelo y ver la arquitectura\nmodel.build((100, 100, 3))\nmodel.summary()","cee7e5fb":"# Definir los parametros de optimizacion y perdida del modelo (con CrossValidation)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['acc'])\n\n# ejecutar training\nhistory = model.fit_generator(train_generator_g,\n                              epochs=50,\n                              steps_per_epoch=32, \n                              validation_data=test_generator_g,\n                              validation_steps=32) ","0f282703":"score1= model.evaluate(test_generator_g, verbose=0)\nprint('Test loss:', score1[0])\nprint('Test accuracy:', score1[1])","ce565590":"history","a9167363":"def line_plot(series, legends, title, ylabel, xlabel):\n    for serie in series:\n        plt.plot(serie)\n    plt.title(title)\n    plt.ylabel(ylabel)\n    plt.xlabel(xlabel)\n    plt.legend(legends, loc='upper left')\n    #plt.ylim([0, 1.1])\n    plt.show()\n\n    \nline_plot(\n    [history.history['acc'], history.history['val_acc']],\n    ['train', 'test'],\n    'model accuracy',\n    'acc',\n    'epoch'\n)\n\nline_plot(\n    [history.history['loss'], history.history['val_loss']],\n    ['train', 'test'],\n    'model loss',\n    'loss',\n    'epoch'\n)","6a2cf5d2":"from keras.callbacks import ModelCheckpoint,EarlyStopping\nmodel2=Sequential()\n\n#Bloques Convulocionales\n\nmodel2.add(Conv2D(32,(3,3), padding='same',input_shape=(100,100,3),activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2,2))) \nmodel2.add(BatchNormalization())\n\nmodel2.add(Conv2D(64,(3,3), padding='same',activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2,2)))\nmodel2.add(BatchNormalization())\n\nmodel2.add(Conv2D(32,(3,3), padding='same',activation='relu'))\nmodel2.add(BatchNormalization())\n\n#Capas\nmodel2.add(Flatten())\nmodel2.add(Dense(100,activation='relu'))\nmodel2.add(Dropout(0.1))\nmodel2.add(Dense(50,activation='relu'))\nmodel2.add(Dropout(0.1))\nmodel2.add(Dense(6,activation='softmax'))\n\n#Se utiliza para guardar el epoch con mejor accuracy acumulado\nfilepath=\"trained_model.h5\"\ncheckpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint1]\n\nmodel2.summary()","a09eb3d1":"model2.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['acc'])","af2bc327":"history2 = model2.fit_generator(train_generator_g,\n                              epochs=100,\n                              steps_per_epoch=2024\/\/32,# imagenes del train\/32\n                              validation_data=test_generator_g,\n                              validation_steps=502\/\/16,# imagenes del test\/32\n                              workers = 4,\n                              callbacks=callbacks_list) ","d2aa6dd7":"score2= model2.evaluate(test_generator_g, verbose=0)\nprint('Test loss:', score2[0])\nprint('Test accuracy:', score2[1])","5ae43a7c":"def line_plot(series, legends, title, ylabel, xlabel):\n    for serie in series:\n        plt.plot(serie)\n    plt.title(title)\n    plt.ylabel(ylabel)\n    plt.xlabel(xlabel)\n    plt.legend(legends, loc='upper left')\n    #plt.ylim([0, 1.1])\n    plt.show()\n\n    \nline_plot(\n    [history2.history['acc'], history2.history['val_acc']],\n    ['train', 'test'],\n    'model accuracy',\n    'acc',\n    'epoch'\n)\n\nline_plot(\n    [history2.history['loss'], history2.history['val_loss']],\n    ['train', 'test'],\n    'model loss',\n    'loss',\n    'epoch'\n)","269f7b35":"test_steps_per_epoch = np.math.ceil(test_generator_g.samples \/ test_generator_g.batch_size)\n\npredictions = model.predict_generator(test_generator_g, steps=test_steps_per_epoch)\n# Get most likely class\npredicted_classes1 = np.argmax(predictions, axis=1)","09e66758":"from sklearn import metrics\ntrue_classes = test_generator_g.classes\nclass_labels = list(test_generator_g.class_indices.keys()) \nreport = metrics.classification_report(true_classes, predicted_classes1, target_names=class_labels)\nprint(report)","3718a3bb":"def plot_cm(cm, title=\"\"):\n    fig = px.imshow(cm,x=class_labels,y=class_labels,title=title)\n    fig.show()","f708034d":"from sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(true_classes, predicted_classes1,normalize='true')\nplot_cm(conf_mat, \"Confusion Matrix (Test)\")","7845676d":"predictions = model2.predict_generator(test_generator_g, steps=test_steps_per_epoch)\n# Get most likely class\npredicted_classes2 = np.argmax(predictions, axis=1)","b27689a5":"report = metrics.classification_report(true_classes, predicted_classes2, target_names=class_labels)\nprint(report)","31d14d24":"conf_mat = confusion_matrix(true_classes, predicted_classes2,normalize='true')\nplot_cm(conf_mat, \"Confusion Matrix (Test) Model 2\")","36051833":"for i in labels_rice:\n    directory = os.path.join(base_rice, i)\n    print(\"Images of label \\\"\" + i + \"\\\":\\t\", len(os.listdir(directory)))","9c92bec9":"plt.figure(figsize=(20,10))\n\nfor i in range(3):\n    directory = os.path.join(base_rice, labels_rice[i])\n    for j in range(5):\n        path = os.path.join(directory, os.listdir(directory)[j])\n        img = mpimg.imread(path)\n        \n        plt.subplot(3, 5, i*5 + j + 1)\n        plt.imshow(img)\n        \n        if j == 0:\n            plt.ylabel(labels_rice[i], fontsize=20)\n        \nplt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\nplt.tight_layout()\nplt.show()","92b5c023":"X_train=np.concatenate([train_generator_r.next()[0] for i in range(train_generator_r.__len__())])\ny_train=np.concatenate([train_generator_r.next()[1] for i in range(train_generator_r.__len__())])\nprint(X_train.shape)\nprint(y_train.shape)","73df6dc0":"X_test=np.concatenate([test_generator_r.next()[0] for i in range(test_generator_r.__len__())])\ny_test=np.concatenate([test_generator_r.next()[1] for i in range(test_generator_r.__len__())])\nprint(X_test.shape)\nprint(y_test.shape)","f4abaf41":"d2_X_train = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\nd2_X_test = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2]*X_test.shape[3])\nprint(d2_X_train.shape)\nprint(d2_X_test.shape)","3ec8b0d2":"import warnings\n\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.neural_network import MLPClassifier\n\n \nmlp = MLPClassifier(\n    hidden_layer_sizes=(64,32,16,3),\n    activation=\"relu\" ,\n    max_iter=1000,\n    alpha=1e-4,\n    solver=\"sgd\",# mejor para datasets pequennos\n    verbose=10,\n    random_state=1,\n    learning_rate_init=0.005,\n)\n\n# this example won't converge because of CI's time constraints, so we catch the\n# warning and are ignore it here\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n    mlp.fit(d2_X_train, y_train)\n\nprint(\"Training set score: %f\" % mlp.score(d2_X_train, y_train))\nprint(\"Test set score: %f\" % mlp.score(d2_X_test, y_test))\n","328b7e66":"predictions = mlp.predict(d2_X_test)\n# Get most likely class\npredicted_classes3 = np.argmax(predictions, axis=1)","cde1cc3d":"from sklearn import metrics\ntrue_classes = test_generator_r.classes\nclass_labels = list(test_generator_r.class_indices.keys()) \nreport = metrics.classification_report(true_classes, predicted_classes3, target_names=class_labels)\nprint(report)","dd7aef53":"from sklearn.metrics import confusion_matrix\nconf_mat = confusion_matrix(true_classes, predicted_classes3,normalize='true')\nplot_cm(conf_mat, \"Confusion Matrix (Test)\")","cb810772":"#### 2.1 Validaciones","06ceab01":"##### Modelo 2","151cfc91":"Se revisaran dos cosas inicialmente, si el dataset se encuentra balanceado en cuanto a imagenes de cada clase y luego se visualizaran unas muestras.","f2908126":"#### 1.2 Red Multicapa","2adc4b06":"1. Implemente y Ajuste un Multi Layers Perceptron con Scikitlearn (3 pts)\n2. Muestre sus resultados con una matriz de confusi\u00f3n o un reporte (4 pts)","643911c9":"#### 2.2 Perceptron Multicapas Scikitlearn","63febcbf":"El dataset se encuentra bastante balanceado, exceptuando por la etiqueta de trash, por lo que se podrian crear muestras para balancear, pero esto se manejara como una alternativa si es necesario mejorar la predicci\u00f3n","5be1a2be":"Las predicciones son mas variadas, pero el True de cada clase no es tan alto como se espera","3c80bc68":"Se utilizara un modelo con 6 capas, 1000, 750, 500, 250,100 y 6 neuronas. Adicionalmente se utilizara la funci\u00f3n de Dropout que sirve para quitar un determinado % de conexiones entre capas de manera aleatoria, lo que permite evitar un overfitting de manera temprana. Se utilizar\u00e1 un dropout de 10%","f709f4cf":"#### 1.3 Matriz de confusi\u00f3n","ee258b01":"Se hicieron varias pruebas cambiando parametros, teniendo el mejor resultado cuando se utiliza el optimizador adam y usando funciones de activacion Relu . Sin embargo el criterio que hace subir el accuracy en mayor medida es la cantidad de epochs, ya que cuando se realiz\u00f3 con 15 el maximo valor que se logr\u00f3 fue de 26%, mientras que con 50 epochs se llego a un valor de accuracy por arriba de 40, el cu\u00e1l a\u00fan es bastante bajo","4a1aa4a2":"#### Accuracy plots","ee212dad":"Se convierte el tensor en un arreglo numpy para poder utilizarlo en Scikitlearn","67dd53f1":"#### Parte 2. Red convulocional (Tarea 3)","06577992":"##### Modelo 1","1e7d7d0c":"1. Implemente la arquitectura de una red neuronal convolucional con Keras (5 pts) para realizar la clasificaci\u00f3n.\n2. Muestre el accuracy y el loss a lo largo del tiempo \/ epochs (2 pts)\n2. Muestre sus resultados con una matriz de confusi\u00f3n o un reporte (3 pts)","0b9abaf3":"#### Parte 1","af00cebd":"### 2. Scikit learn","3ca5b814":"El dataset se encuentra balanceado a nivel de clases","c78b072c":"### 1. Neural Network","f1f0aaea":"Se realiza la misma validaci\u00f3n de antes; si las clases est\u00e1n balanceadas y la visualizaci\u00f3n de muestras de cada clase","61923517":"##### Se realiza el fit del modelo","454c5b2e":"1. Implemente la arquitectura de una red neuronal de multiples capas con Keras (4 pts) para realizar la clasificaci\u00f3n.\n2. Investigue para que funciona la capa DropOut y utilicela en caso de ser necesario (2 pts).\n3. Muestre sus resultados con una matriz de confusi\u00f3n o un reporte (4 pts)","8721cf05":"Se ajusta en dos dimensiones para poder utilizarlo","3d8e8a38":"##### Accuracy plots","5bdda931":"Se obtienen resultados deficientes, por lo que se probara con otro modelo usando una red convulocional 2D","cfae2e07":"Se guardan los nombres de las etiquetas de cada dataset","742954e8":"#### 2.3 Reporte\/ Matriz de confusi\u00f3n","ee98edbc":"Mal resultado, ya que predice en su mayor\u00eda que es papel o vidrio. Son las clase en dominancia, por lo que otro tramiento que se puede hacer es balancear las clases para evitar que solo realice dicha predicci\u00f3n","ebf0c9bf":"### 0. Carga de las im\u00e1genes"}}