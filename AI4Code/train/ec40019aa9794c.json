{"cell_type":{"eaf5ad3f":"code","f3ddec57":"code","444e54d0":"code","c4acbf9c":"code","49f8d205":"code","788fb234":"code","2108dc4d":"code","16037747":"code","3ffd251c":"code","6e4a9d69":"code","2fff82f7":"code","e14610f7":"code","5fc09c2e":"code","23d5df41":"code","7c7274b9":"code","be8767c9":"code","5a0b02bc":"code","088a3dfd":"code","179659eb":"code","b74d6168":"code","def8b536":"code","b39c5617":"code","8b589075":"code","4aae4a82":"code","e86a8760":"code","eab4c4b4":"code","5d888ca2":"code","d3ed9ba5":"code","b4ffd77c":"code","9ce795c8":"code","0dec1ed9":"code","e866969b":"code","121b53ab":"code","b1ccc9a1":"code","f86193b4":"code","9d01eaff":"code","22a586b1":"code","f9376bb4":"code","a5489ebb":"code","d60e3506":"code","f5f7c335":"code","05965170":"code","bab12e15":"code","a9937996":"code","f75a414d":"code","23173ec6":"code","f5a46bbb":"code","b93f46f8":"code","ed57bf82":"code","ab692dbf":"code","4f8febef":"code","9de060ca":"code","0c7be489":"markdown","c4eb9a22":"markdown","61904fb0":"markdown","084ddfff":"markdown","7e644b00":"markdown","63dd270c":"markdown","2d0a9e8f":"markdown","4577b65f":"markdown","c39350f7":"markdown","87c2ba86":"markdown","e1d7343e":"markdown","8d7389c7":"markdown","dc7d7ff1":"markdown","ceaad639":"markdown","7a4abfe2":"markdown","adacedcc":"markdown"},"source":{"eaf5ad3f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f3ddec57":"data = pd.read_csv('\/kaggle\/input\/employee-attrition\/employee_attrition_train.csv')\ndata.head()","444e54d0":"data.info()","c4acbf9c":"# check for imbalanced data\nprint(data['Attrition'].unique())\nplt.pie(data['Attrition'].value_counts(), autopct='%1.1f%%', labels=['No', 'Yes']);","49f8d205":"def plot_category(feature, figsize=None):\n    yes_count = data[data['Attrition']=='Yes'].groupby([feature]).size()\n    no_count = data[data['Attrition']=='No'].groupby([feature]).size()\n    labels = no_count.index\n\n    x = np.arange(len(labels)) # the label locations\n    width = 0.35  # the width of the bars\n\n    if figsize:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig, ax = plt.subplots()\n    rects1 = ax.bar(x-width\/2, round(yes_count*100\/data.groupby([feature]).size(), 2), \n                    width, label='Yes')\n    rects2 = ax.bar(x+width\/2, round(no_count*100\/data.groupby([feature]).size(), 2), \n                    width, label='No')\n\n    ax.set_ylabel('Count')\n    ax.set_title('Based on %s'%feature)\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels, rotation=80)\n    ax.legend();\n\n    ax.bar_label(rects1, padding=1)\n    ax.bar_label(rects2, padding=1)\n\n    fig.tight_layout()\n    plt.show()\n    \ndef plot_numerical(feature, figsize=None):\n    # Attrition vs Age Distribution\n    fig = plt.figure(figsize=(10,6))\n\n    sns.kdeplot(data[data['Attrition']=='No'][feature])\n    sns.kdeplot(data[data['Attrition']=='Yes'][feature])\n\n    fig.legend(labels=['Attrition No', 'Attrition Yes'])\n    plt.title('Based on %s'%feature)\n    plt.show()","788fb234":"for feature in ['Age']:\n    plot_numerical(feature)","2108dc4d":"for feature in ['DailyRate', 'HourlyRate', 'MonthlyRate']:\n    plot_numerical(feature)","16037747":"for feature in ['BusinessTravel']:\n    plot_category(feature)","3ffd251c":"for feature in ['Department', 'JobRole', 'Education', 'EducationField']:\n    plot_category(feature, figsize=(8,5))","6e4a9d69":"for feature in ['DistanceFromHome']:\n    plot_numerical(feature)","2fff82f7":"for feature in ['EnvironmentSatisfaction', 'JobInvolvement', 'JobSatisfaction']:\n    plot_category(feature, figsize=(8,5))","e14610f7":"for feature in ['Gender']:\n    plot_category(feature)","5fc09c2e":"for feature in ['JobLevel']:\n    plot_category(feature)","23d5df41":"for feature in ['MaritalStatus', 'Over18']:\n    plot_category(feature)","7c7274b9":"for feature in ['MonthlyIncome', 'TotalWorkingYears']:\n    plot_numerical(feature)","be8767c9":"for feature in ['NumCompaniesWorked']:\n    plot_numerical(feature, figsize=(8,5))","5a0b02bc":"for feature in ['OverTime', 'StandardHours', 'WorkLifeBalance']:\n    plot_category(feature)","088a3dfd":"for feature in ['PercentSalaryHike']:\n    plot_numerical(feature)","179659eb":"for feature in ['PerformanceRating']:\n    plot_category(feature)","b74d6168":"for feature in ['YearsSinceLastPromotion', 'YearsInCurrentRole', 'YearsAtCompany', \n                'YearsWithCurrManager']:\n    plot_numerical(feature)","def8b536":"for feature in [ 'RelationshipSatisfaction', 'StockOptionLevel', 'TrainingTimesLastYear']:\n    plot_category(feature)","b39c5617":"categorical_features = ['BusinessTravel', 'Department', 'JobRole', 'Education', \n                        'EducationField', 'Gender', 'MaritalStatus', 'OverTime']\nnumerical_features = ['Age', 'DailyRate', 'DistanceFromHome', 'EnvironmentSatisfaction',\n                      'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n                      'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',\n                      'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n                      'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n                      'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n                      'YearsWithCurrManager']\n\nto_drop = ['StandardHours', 'Over18', 'EmployeeCount', 'EmployeeNumber'] # contain only single unique value","8b589075":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport os\nimport joblib","4aae4a82":"df = data.copy()\npath = '\/kaggle\/working'\nfor i, feature in enumerate(categorical_features):\n    le = LabelEncoder()\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    \n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding\/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding\/le_{}_classes.sav\".format(feature)), 'wb'))","e86a8760":"# Bivariate Analysis Correlation plot with the Numeric variables\nplt.figure(figsize=(15, 15))\nsns.heatmap(round(data[numerical_features].corr(), 2), annot=True,\n            mask=None, cmap='GnBu')\ncorr_mat = data[numerical_features].corr()\nplt.show()","eab4c4b4":"# Correlated Features\ns = corr_mat.unstack()\nso = s.sort_values(kind=\"quicksort\").drop_duplicates()\nres1 = so[so>=0.5]\nprint(res1)","5d888ca2":"# Bivariate Analysis Correlation plot with the Categorical variables\nplt.figure(figsize=(20, 20))\nsns.heatmap(round(df[categorical_features+numerical_features].corr(method='spearman'), 2), annot=True,\n            mask=None, cmap='GnBu')\nplt.show()","d3ed9ba5":"from statsmodels.stats.outliers_influence import variance_inflation_factor","b4ffd77c":"# Calculating VIF\nvif = pd.DataFrame()\ntemp = df.dropna()\nvif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['PerformanceRating', 'JobLevel',\n                                                                                                     'Age', 'PercentSalaryHike',\n                                                                                                     'WorkLifeBalance', 'JobInvolvement',\n                                                                                                     'Department', 'YearsAtCompany']]\nvif[\"VIF\"] = [variance_inflation_factor(temp[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\nprint(vif)","9ce795c8":"missingValueFeatures = pd.DataFrame({'missing %': data.isnull().sum()*100\/len(data)})\nmissingValueFeatures[missingValueFeatures['missing %']>0]","0dec1ed9":"# Imputing BusinessTravel with Back fill\nprint('Before Imputation:')\nprint(data[['BusinessTravel']].value_counts())\ndata['BusinessTravel'].fillna(method='bfill', inplace=True)\nprint('\\nAfter Imputation:')\nprint(data[['BusinessTravel']].value_counts())","e866969b":"# Imputing DailyRate and DistanceFromHome with Mean values\nprint('Before Imputation:')\nprint(data[['DailyRate', 'DistanceFromHome']].describe().T)\ndata[['DailyRate', 'DistanceFromHome']] = data[['DailyRate', 'DistanceFromHome']].fillna(data[['DailyRate', 'DistanceFromHome']].mean())\nprint('\\nAfter Imputation:')\nprint(data[['DailyRate', 'DistanceFromHome']].describe().T)","121b53ab":"# Imputing Age as per TotalWorkingYears\n\nprint('Before Imputation:')\nprint(data[['Age']].describe().T)\n\ndata.sort_values(by='TotalWorkingYears', inplace=True)\n\n# now use backfill method to replace Age\ndata['Age'].fillna(method='bfill', inplace=True)\n\nprint('\\nAfter Imputation:')\nprint(data[['Age']].describe().T)","b1ccc9a1":"# Imputing MaritalStatus as per StockOptionLevel\nprint(pd.crosstab(data['MaritalStatus'], data['StockOptionLevel']))\nprint('\\nStockOptionLevel Distribution across missing MaritalStatus values:')\nprint(data[data['MaritalStatus'].isna()]['StockOptionLevel'])","f86193b4":"# For StockOptionLevel 1 & 2 mode of MaritalStatus is Married\nprint('\\nBefore Imputation:')\nprint(data[['MaritalStatus']].value_counts())\ndata['MaritalStatus'].fillna(data['MaritalStatus'].mode()[0], inplace=True)\nprint('\\nAfter Imputation:')\nprint(data[['MaritalStatus']].value_counts())","9d01eaff":"# verifying missing values\ndata.info()","22a586b1":"NumericData = data[[feature for feature in numerical_features if feature not in ['MonthlyIncome', \n                                                                               'MonthlyRate', \n                                                                               'DailyRate',\n                                                                              'HourlyRate']]]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","f9376bb4":"NumericData = data[['DailyRate', 'HourlyRate']]\n# skipping 'MonthlyIncome', 'MonthlyRate', 'DailyRate' \n# due to very different range of values compared to others\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(8,5))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","a5489ebb":"NumericData = data[['MonthlyIncome', 'MonthlyRate']]\n# skipping 'MonthlyIncome', 'MonthlyRate', 'DailyRate' \n# due to very different range of values compared to others\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(8,5))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","d60e3506":"# Percentage of outliers present in each variable\noutlier_percentage = {}\nfor feature in ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n                'YearsWithCurrManager', 'TrainingTimesLastYear', 'NumCompaniesWorked', 'MonthlyIncome']:\n    tempData = data.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)\n    outlier_percentage[feature] = round((((tempData<(Q1 - 1.5 * IQR)) | (tempData>(Q3 + 1.5 * IQR))).sum()\/tempData.shape[0])*100,2)\noutlier_percentage","f5f7c335":"# Outlier treatment with more thatn 4% outlier values\ndf_outlier = data.copy()\nfor feature in ['TotalWorkingYears', 'YearsAtCompany', 'YearsSinceLastPromotion', 'TrainingTimesLastYear', 'MonthlyIncome']:\n    tempData = df_outlier.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)    \n    df_outlier.loc[(df_outlier[feature]<(Q1 - 1.5 * IQR))|(df_outlier[feature]>(Q3 + 1.5 * IQR)), \n                   feature] = Upper_range","05965170":"df = df_outlier.copy()\npath = '\/kaggle\/working'\nfor i, feature in enumerate(categorical_features):\n    \n    le = LabelEncoder()\n    ohe = OneHotEncoder(sparse=False)\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding\/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding\/le_{}_classes.sav\".format(feature)), 'wb'))\n    # load classes\n    columns = joblib.load(\n        open(os.path.join(path, \"TextEncoding\/le_{}_classes.sav\".format(feature)), 'rb'))\n\n    if len(le.classes_)>2:\n        # perform one hot encoding\n        ohe.fit(df[[feature]])\n        # save the encoder\n        joblib.dump(ohe, \n                    open(os.path.join(path, \"TextEncoding\/ohe_{}.sav\".format(feature)), 'wb'))\n\n        # transfrom training data\n        # removing first column of encoded data to elude from dummy variable trap\n        tempData = ohe.transform(df[[feature]])[:, 1:]\n\n        # create Dataframe with columns as classes\n        tempData = pd.DataFrame(tempData, columns=columns)\n    else:\n        tempData = df[feature]\n    \n    # create dataframe with all the label encoded categorical features along with hot encoding\n    if i==0:\n        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n    else:\n        encodedData = pd.concat([encodedData, tempData], axis=1)","bab12e15":"# merge numerical features and categorical encoded features\ndf = df[numerical_features+['Attrition']]\ndf = pd.concat([df, encodedData], axis=1)\ndf.info()","a9937996":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.svm import SVC","f75a414d":"train_data = df.copy()\nfeature_cols = [feature for feature in train_data.columns if feature not in(['Attrition', 'PerformanceRating', 'JobLevel',\n                                                                             'Age', 'PercentSalaryHike',\n                                                                             'WorkLifeBalance', 'JobInvolvement',\n                                                                             'YearsAtCompany', 'Department Research & Development',\n                                                                             'Department Sales'])]\n\n''' Rescaling to [0,1] '''\nscaler = MinMaxScaler()\nscaler.fit(train_data[feature_cols])\ntrain_data[feature_cols] = scaler.transform(train_data[feature_cols])","23173ec6":"X = train_data[feature_cols]\ny = train_data['Attrition']\ny.replace('No', 0, inplace=True)\ny.replace('Yes', 1, inplace=True)\n\nvalidation_size = 0.25\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, \n                                                    random_state=4, stratify=y)","f5a46bbb":"model = LogisticRegression(class_weight={0:1, 1:10})\nmodel.fit(X_train, y_train)","b93f46f8":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","ed57bf82":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Attrition'] * n\n    pred = ['prediction Attrition'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(train_data['Attrition'], y_pred),['No','Yes'])\n\ndisplay(df_matrix)\nprint(classification_report(train_data['Attrition'], y_pred))","ab692dbf":"model = SVC(class_weight={0: 1, 1: 10})\nmodel.fit(X_train, y_train)","4f8febef":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Test metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","9de060ca":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Attrition'] * n\n    pred = ['prediction Attrition'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(train_data['Attrition'], y_pred),['No','Yes'])\n\ndisplay(df_matrix)\nprint(classification_report(train_data['Attrition'], y_pred))","0c7be489":"**Columns that seem to contribute towards Attrition:**<br>\n1. YearsWithCurrManager < 5\n2. YearsAtCompany < 5\n3. YearsInCurrentRole < 4\n4. TotalWorkingHours < 10\n6. DailyRate < 1000\n7. NumCompaniesWorked > 5\n8. MonthlyIncome < 5000\n9. Age < 35\n10. TrainingTimeLastYear - 0\n11. StockOptionLevel - 0 \n12. OverTime - yes \n13. JobRole - Sales Representative\n14. Married - Single\n15. JobLevel - 1\n16. BusinessTravel - travel frequently\n17. EducationField - Technical Field, Human Resources\n18. WorkLifeBalance - 1\n19. EnvironmentSatisfaction - 1\n20. JobInvolvement - 1\n21. JobSatisfaction - 1","c4eb9a22":"# Handling Missing Values","61904fb0":"**Observations:**\n\n1. As age increases the TotalWorkingYears(experience) increases.\n2. Monthly Income is directly proportional to Job level & TotalWorkingYears. Employees at Higher position & more experience gets more income.\n3. Higher performance rating bring higher percent salary hikes\n4. TotalWorkingYears-YearsAtCompany shows that people who have more experience might be liking to continue their association with the company\n5. YearsAtCompany, YearsWithCurrManager, YearsInCurrentRole shows a positive correlation among each other.","084ddfff":"# Label Encoding Categorical Features for Correlation (includes missing values)","7e644b00":"**Observations:**\n\n1. Department - JobRole\n2. MaritalStatus - StockOptionLevel (-)","63dd270c":"So More you travel higher the chances of attrition","2d0a9e8f":"# Model 1: Logistic Regression","4577b65f":"|Column|Correlation|\n|---|---|\n|Age|TotalWorkingYears| \n|BusinessTravel|NA| \n|DailyRate|   NA|\n|DistanceFromHome|NA|\n|MaritalStatus|StockOptionLevel|","c39350f7":"# Training Model","87c2ba86":"# CORRELATION","e1d7343e":"# Looking at Outliers","8d7389c7":"# Handling Categorical Features (Label and One Hot Encoding)","dc7d7ff1":"**Columns with Outlier values:**<br>\n1. TotalWorkingYears\n2. YearsAtCompany\n3. YearsInCurrentRole\n4. YearsSinceLastPromotion\n5. YearsWithCurrManager\n6. TrainingTimesLastYear\n7. NumCompaniesWorked\n8. MonthlyIncome<br>\nOther columns like PerformanceRating are not considered in outliers as they have very few unique values","ceaad639":"# UNDERSTANDING DATA DISTRIBUTION","7a4abfe2":"# Model 2: SVM","adacedcc":"We can impute missing values as per the correlation table above. Columns with NA values can be replaced by mean, mode, median or back fill methods"}}