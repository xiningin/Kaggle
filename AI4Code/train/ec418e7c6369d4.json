{"cell_type":{"caf859a5":"code","08b3b86e":"code","75c2bb6f":"code","33aaf5b2":"code","f3674c4a":"code","e0887592":"code","a1d41d17":"code","a905b476":"code","24697804":"code","ed5aadf4":"code","5ffd9986":"code","f128410b":"code","dcedac84":"markdown"},"source":{"caf859a5":"# Instaling fastai2\n!pip install git+https:\/\/github.com\/fastai\/fastai2 \n!pip install git+https:\/\/github.com\/fastai\/fastcore","08b3b86e":"from fastai2.vision.all import *","75c2bb6f":"!wget {URLs.MNIST}\n!tar -xf mnist_png.tgz","33aaf5b2":"path = Path('mnist_png')\npath.ls()","f3674c4a":"files = [get_image_files(path\/f'training\/{i}')[:100] for i in range(10)]\nfiles = np.concatenate(files)\nsequence_order = [int(f.parent.stem) for f in files]\nsequence_id = [f's{i:02d}' for i in range(100)]*10\n\ndf = pd.DataFrame({'file': files, 'sequence_id': sequence_id, 'sequence_order': sequence_order,\n                   'label': [int(s[1:]) for s in sequence_id]})","e0887592":"df.head()","a1d41d17":"df.loc[df.sequence_id=='s00']","a905b476":"def int2float(o:TensorImage):\n    return o.float().div_(255.)\n\nclass ImageSequence(Tuple):\n    @classmethod\n    def create(cls, fns): return cls(tuple(PILImage.create(f) for f in fns))\n\ndef ImageSequenceBlock(): \n    return TransformBlock(type_tfms=ImageSequence.create, batch_tfms=int2float)\n\nclass SequenceGetItems():\n    def __init__(self, filename_col, sequence_id_col, label_col):\n        self.fn = filename_col\n        self.seq = sequence_id_col\n        self.label = label_col\n        \n    def __call__(self, df):\n        data = []\n        for fn in progress_bar(df[self.seq].unique()):\n            similar = df[self.seq] == fn\n            similar = df.loc[similar]\n            fns = similar[self.fn].tolist()\n            lbl = similar[self.label].values[0]\n            data.append([*fns, lbl])\n        return data\n\ndef create_batch(data):\n    xs, ys = [], []\n    for d in data:\n        xs.append(d[0])\n        ys.append(d[1])\n    xs = torch.cat([TensorImage(torch.cat([im[None] for im in x], dim=0))[None] for x in xs], dim=0)\n    ys = torch.cat([y[None] for y in ys], dim=0)\n    return TensorImage(xs), TensorCategory(ys)\n\ndef show_sequence_batch(max_n=4):\n    xb, yb = dls.one_batch()\n    fig, axes = plt.subplots(ncols=10, nrows=max_n, figsize=(12,6), dpi=120)\n    for i in range(max_n):\n        xs, ys = xb[i], yb[i]\n        for j, x in enumerate(xs):\n            axes[i,j].imshow(x.permute(1,2,0).cpu().numpy())\n            axes[i,j].set_title(ys.item())\n            axes[i,j].axis('off')","24697804":"class SequenceTfms(Transform):\n    def __init__(self, tfms): \n        self.tfms = tfms\n        \n    def encodes(self, x:TensorImage): \n        bs, seq_len, ch, rs, cs = x.shape\n        x = x.view(bs, seq_len*ch, rs, cs)\n        x = compose_tfms(x, self.tfms)\n        x = x.view(bs, seq_len, ch, rs, cs) \n        return x\n    \nclass BatchTfms(Transform):\n    def __init__(self, tfms): \n        self.tfms = tfms\n        \n    def encodes(self, x:TensorImage): \n        bs, seq_len, ch, rs, cs = x.shape\n        x = x.view(bs*seq_len, ch, rs, cs)\n        x = compose_tfms(x, self.tfms)\n        x = x.view(bs, seq_len, ch, rs, cs) \n        return x","ed5aadf4":"dblock = DataBlock(\n    blocks    = (ImageSequenceBlock, CategoryBlock),\n    get_items = SequenceGetItems('file', 'sequence_id', 'label'), \n    get_x     = lambda t : t[:-1],\n    get_y     = lambda t : t[-1],\n    splitter  = RandomSplitter(valid_pct=0.2, seed=2020))\n\ndls = dblock.dataloaders(df, bs=8, create_batch=create_batch)\nshow_sequence_batch()","5ffd9986":"affine_tfms, light_tfms = aug_transforms(flip_vert=True)\nbrightness = lambda x : x.brightness(p=0.75, max_lighting=0.9)\ncontrast   = lambda x : x.contrast(p=0.75, max_lighting=0.9)\n\ndblock = DataBlock(\n    blocks     = (ImageSequenceBlock, CategoryBlock),\n    get_items  = SequenceGetItems('file', 'sequence_id', 'label'), \n    get_x      = lambda t : t[:-1],\n    get_y      = lambda t : t[-1],\n    splitter   = RandomSplitter(valid_pct=0.2, seed=2020),\n    item_tfms  = Resize(128),\n    batch_tfms = [SequenceTfms([affine_tfms]), BatchTfms([brightness, contrast])])\n\ndls = dblock.dataloaders(df, bs=8, create_batch=create_batch)\nshow_sequence_batch()","f128410b":"xb, yb = dls.one_batch()\nxb.shape, yb.shape","dcedac84":"# Working with 3D data - fastai2\nIn this notebook I show an example of how to work with 3D data using fastai2. I use MNIST and create sequences from 0 to 9 in order to make the example more intuitive and easier to debug.\n\nA detailed explanation of the code is available at: https:\/\/towardsdatascience.com\/working-with-3d-data-fastai2-5e2baa09037e\n"}}