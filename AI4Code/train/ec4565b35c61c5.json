{"cell_type":{"5e823bc5":"code","0d961512":"code","fe08f6fb":"code","7615f285":"code","59db9a57":"code","5176f8a6":"code","5ebf6684":"code","3047c7ed":"code","779fc570":"code","5dab8b97":"code","b3c02de7":"code","1b138c30":"code","e064e153":"code","0c23813d":"code","62a18568":"code","f1eec59c":"code","95d9a7e4":"code","adcfb0fe":"code","d08a017f":"code","0cb938ca":"code","283d1965":"code","2e6b32ac":"code","200e4862":"code","72330633":"code","e6636772":"code","91d57186":"code","49085709":"code","f1d9ff89":"code","3574f399":"code","c5eece8a":"code","4a2f2bb6":"code","df6be9ad":"code","2512bca5":"code","dba9781d":"markdown","81f889aa":"markdown","9db43bae":"markdown","1366feaf":"markdown","394075d5":"markdown","35774467":"markdown","e73421e0":"markdown","d0997dc3":"markdown","ccec8d7d":"markdown","a0b5b70c":"markdown","9332ae81":"markdown","64476a56":"markdown","358e54fe":"markdown","c1fcd138":"markdown","32bb1b88":"markdown","89eebbf3":"markdown","8a2065a1":"markdown","14f9d819":"markdown","ad51e6db":"markdown","bae9670b":"markdown","b6324b88":"markdown","5682bcc8":"markdown"},"source":{"5e823bc5":"import numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport os\nimport re\nfrom tensorflow import keras\nimport tensorflow_datasets as tfds\nfrom sklearn.metrics import classification_report, confusion_matrix","0d961512":"tf.compat.v1.disable_eager_execution()","fe08f6fb":"tf.executing_eagerly()","7615f285":"strategy = tf.distribute.get_strategy()\ntf.config.optimizer.set_jit(True)\n    \nprint(strategy)","59db9a57":"CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                             ","5176f8a6":"IMAGE_SIZES = [(192, 192), (224, 224), (331, 331), (512, 512)]","5ebf6684":"IMAGE_SIZE = IMAGE_SIZES[1]","3047c7ed":"stem = \"\/kaggle\/input\/tpu-getting-started\/\"","779fc570":"FOLDER_PATHS = [stem + str(item) for item in os.listdir(\"\/kaggle\/input\/tpu-getting-started\") if \"contains\" not in str(item)]","5dab8b97":"def return_files(f):\n    return [f + \"\/\" + item for item in os.listdir(f)]\n\ntrain_files = []\ntest_files = []\nval_files = []\n\n#if \"sample\" not in str(p):\nfor p in FOLDER_PATHS:\n    if \"sample\" not in str(p):\n        train_folder = p + \"\/train\"\n        test_folder = p + \"\/test\"\n        val_folder = p + \"\/val\"\n\n        print(train_folder)\n        for f in return_files(train_folder):\n            train_files.append(f)\n        for f in return_files(test_folder):\n            test_files.append(f)\n        for f in return_files(val_folder):\n            val_files.append(f)\n","b3c02de7":"train_files","1b138c30":"LABELED_TFREC_FORMAT = {\n    \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n    \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n}\nUNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n}","e064e153":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.image.resize(image,[224,224],method='nearest', preserve_aspect_ratio=True,)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    #image = tf.image.resize(image,[224,224],method='nearest', preserve_aspect_ratio=True,)\n    #image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_record(example_proto):\n    ex = tf.io.parse_single_example(example_proto, LABELED_TFREC_FORMAT)\n    img = decode_image(ex[\"image\"])\n    label = tf.cast(ex[\"class\"], tf.int64)\n    return img, label\n\ndef read_unlabeled_record(example_proto):\n    ex = tf.io.parse_single_example(example_proto, UNLABELED_TFREC_FORMAT)\n    img = decode_image(ex)\n    label = tf.cast(ex[\"class\"], tf.int64)\n    return img, label","0c23813d":"def data_augment(image, label):\n    #image = tf.image.resize(image,(224,224))\n    image = tf.image.random_flip_left_right(image, seed=None)\n    image = tf.image.random_flip_up_down(image, seed=None)\n    image = tf.image.random_saturation(image, lower=0, upper=2, seed=None)\n#     image = tf.image.random_contrast(image, lower=.8, upper=2, seed=seed)\n#     image = tf.image.random_brightness(image, max_delta=.2, seed=seed)\n    image = tf.image.random_crop(image, size=[int(224), int(224), 3], seed=None)\n\n    return image, label","62a18568":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","f1eec59c":"def load_dataset(filenames, augment):\n    ignore_order = tf.data.Options()\n\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_record)\n    #dataset = dataset.map(reshape)\n    if augment:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    \n    return dataset","95d9a7e4":"TRAIN_LEN = count_data_items(train_files)\nVAL_LEN = count_data_items(val_files)\nprint(\"There are \" + str(TRAIN_LEN) + \" training pictures.\")\nprint(\"There are \" + str(VAL_LEN) + \" validation pictures.\")","adcfb0fe":"def BatchGen(files, augment):\n    data = load_dataset(files, augment)\n    iterator = tf.compat.v1.data.make_one_shot_iterator(data)\n    next_element = iterator.get_next()\n    \n    #tf.compat.v1.disable_eager_execution()\n    train_x = []\n    train_y = []\n    \n    with tf.compat.v1.Session() as s:                \n        try:\n            while True:\n                data_record = s.run(next_element)\n                train_x.append(data_record[0])\n                train_y.append(data_record[1])\n        except:\n            pass\n        \n    return train_x, train_y","d08a017f":"#CLASS_WEIGHT = \nEPOCHS=5\nAUTO = tf.data.experimental.AUTOTUNE\nLEARNING_RATE = 0.000051","0cb938ca":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler","283d1965":"from tensorflow.keras import layers","2e6b32ac":"#base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\ndef get_model():\n    with strategy.scope():\n        global model\n        base_model = tf.keras.applications.DenseNet201(\n            include_top=False,\n            weights=\"imagenet\",\n            input_shape=[None, None, 3],\n        )\n\n        base_model.trainable = False\n\n        set_trainable = False\n\n            # Un-freeze the last 256 layers\n        for layer in base_model.layers:\n            if layer == base_model.layers[-2]: \n                set_trainable = True\n            if set_trainable:\n                layer.trainable = True\n            else:\n                layer.trainable = False\n\n        N_CLASSES = len(CLASSES)\n\n        model = tf.keras.Sequential([\n            base_model,\n            layers.GlobalAveragePooling2D(),\n            layers.Dropout(0.075),\n            layers.Dense(N_CLASSES*10, activation='relu'),\n            layers.Dropout(0.075),\n            layers.Dense(N_CLASSES, activation='softmax')\n        ])\n        \n        return model\nmodel = get_model()","200e4862":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE), loss='sparse_categorical_crossentropy', run_eagerly=False, metrics=[\"sparse_categorical_accuracy\"])","72330633":"tensorboard_callback = tf.keras.callbacks.EarlyStopping(\n    monitor=\"sparse_categorical_accuracy\",\n    min_delta=0,\n    patience=2,\n    verbose=1,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=False,\n)","e6636772":"def scheduler(epoch, lr):\n    if epoch < 10:\n        return LEARNING_RATE*1.1\n    elif epoch < 20:\n        return lr * 0.9\n    else:\n        return lr * 0.8\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)","91d57186":"#To run the 64 files multiple times\nfor t in range(10):\n    print(\"Iteration: \", t)\n    for i, file in enumerate(train_files):\n        train_x, train_y = BatchGen(file, augment=True)\n        print(\"File Number: \", i, \"Number of Records: \", len(train_x))\n        train_x, train_y = np.asarray(train_x), np.asarray(train_y)\n                \n        model.fit(train_x, train_y, epochs=25, \n                  batch_size=24, \n                  verbose=1, shuffle=False,\n              callbacks=[tensorboard_callback, lr_scheduler])\n\nprint(\"Model fit completed!!\")","49085709":"pred_arr = []\nlabel_arr = []\nfor file in val_files:\n    val_x, val_y = BatchGen(file, False)\n    val_x = np.asarray(val_x)\n    \n    pred = model.predict(val_x)\n    pred = np.argmax(pred, axis=-1)\n    \n    for p in pred:\n        pred_arr.append(p)\n    for label in val_y:\n        label_arr.append(label)","f1d9ff89":"from sklearn.metrics import confusion_matrix, precision_score","3574f399":"print(len(pred_arr))","c5eece8a":"print(len(label_arr))","4a2f2bb6":"confusion_matrix(label_arr, pred_arr)","df6be9ad":"arr = classification_report(label_arr, pred_arr, target_names=CLASSES)","2512bca5":"print(arr)","dba9781d":"# XLA GPU\nSET STRATEGY FOR TF","81f889aa":"Some more constants","9db43bae":"# DATA PROCESSING","1366feaf":"# PREPROCESSING","394075d5":"## Defining the Model","35774467":"Counts number of data items in files","e73421e0":"# TRAINING","d0997dc3":"for i, p in enumerate(FOLDER_PATHS):\n    if \"224\" in str(p):\n        PATH = FOLDER_PATHS[i]","ccec8d7d":"Image Decoding and Reading Functions","a0b5b70c":"Define Batch Fetching function","9332ae81":"## Accuracy Analysis","64476a56":"## Training Function","358e54fe":"Validation function that predicts data","c1fcd138":"Train the model","32bb1b88":"Data augmentation function","89eebbf3":"# VALIDATION","8a2065a1":"## Compiling the model and initializing callbacks","14f9d819":"Loads dataset with tfds","ad51e6db":"Return all the files so they can be used in the dataset","bae9670b":"**Define Image Reading Dictionaries**","b6324b88":"# SET UP\n**Importing necessary modules**","5682bcc8":"# FOLDERS AND CLASS LABELS"}}