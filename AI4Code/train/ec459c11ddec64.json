{"cell_type":{"8c779d29":"code","e769b51c":"code","534c9ca8":"code","adfb89ba":"code","2e3ecf41":"code","9efd92e5":"code","cba5d9cf":"code","1db65654":"code","fe74cc4f":"code","a23b7475":"code","6f3be1d7":"code","e5abb2e0":"code","76ceb3de":"code","33145efd":"code","323105b5":"code","f2200bdb":"code","58de70a5":"code","31e58c60":"code","cea549e9":"code","bc19af74":"code","3adb84de":"code","64ceabef":"code","7c67eb28":"code","29b796c1":"code","d44570ad":"code","ce1c8c24":"code","5a15e715":"code","708b7d59":"code","3ce3352e":"code","32c43bbb":"code","cc1786b3":"code","a31d704b":"code","16f798fd":"code","4d30b93c":"code","f0afe5cf":"code","44ec347d":"code","6a78cdfa":"code","9d6a21cd":"code","0a48ead9":"code","f0e270d9":"code","7122a999":"code","bb3a6058":"code","5be287e8":"code","26c35797":"code","adef5258":"code","bee84751":"code","7446ab68":"code","2f5ad089":"code","c0d822b2":"code","d390f612":"code","60322d48":"code","a3c65cc8":"code","89e7590f":"code","df64229b":"code","b8529866":"code","7e88d8f1":"code","68008d81":"code","928a6375":"code","bf3ac808":"code","286bd7db":"code","94647dfc":"code","b5ea0205":"code","7c93b309":"code","82941a14":"code","97d33d50":"code","e93fc961":"markdown","5ae270db":"markdown","4c282138":"markdown","9f64a9ea":"markdown","dd406de7":"markdown","49d0b9d7":"markdown","d6112fa8":"markdown","460ba5dd":"markdown","0c708999":"markdown","66204165":"markdown"},"source":{"8c779d29":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\nimport random\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport os\nimport time\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"..\/input\"))\n\nimport gc\n","e769b51c":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all():  # case if row has NA value, then return False, also inverse returns True.\n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props","534c9ca8":"%%time\ndf_train_tr = pd.read_csv('..\/input\/train_transaction.csv')\ndf_train_id = pd.read_csv('..\/input\/train_identity.csv')","adfb89ba":"%%time\ndf_train_tr = reduce_mem_usage(df_train_tr)\ndf_train_id = reduce_mem_usage(df_train_id)","2e3ecf41":"gc.collect()","9efd92e5":"%%time\ndf_test_tr = pd.read_csv('..\/input\/test_transaction.csv')\ndf_test_id = pd.read_csv('..\/input\/test_identity.csv')","cba5d9cf":"%%time\ndf_test_tr = reduce_mem_usage(df_test_tr)\ndf_test_id = reduce_mem_usage(df_test_id)","1db65654":"submission = pd.read_csv('..\/input\/sample_submission.csv')","fe74cc4f":"%%time\ndf_train = pd.merge(df_train_tr, df_train_id, on = 'TransactionID', how = 'left')\ndf_test = pd.merge(df_test_tr, df_test_id, on = 'TransactionID', how = 'left')\ndf = pd.concat([df_train, df_test], axis=0, sort=False)\ndf.reset_index(inplace=True)","a23b7475":"del df_train, df_test, df_train_id, df_train_tr, df_test_id, df_test_tr\ngc.collect()","6f3be1d7":"#pd.options.display.max_columns = 500","e5abb2e0":"def missing_data(df) :\n    count = df.isnull().sum()\n    percent = (df.isnull().sum()) \/ (df.isnull().count()) * 100\n    total = pd.concat([count, percent], axis=1, keys = ['Count', 'Percent'])\n    types = []\n    for col in df.columns :\n        dtypes = str(df[col].dtype)\n        types.append(dtypes)\n    total['dtypes'] = types\n    \n    return np.transpose(total)","76ceb3de":"#missing_df = missing_data(df)\n#missing_df","33145efd":"#df.head()","323105b5":"#df.tail()","f2200bdb":"#num_cols = [col for col in df.columns if df[col].dtype in ['int64']]\n#df[num_cols].describe()","58de70a5":"#cat_cols = [col for col in df.columns if df[col].dtype in ['object']]\n#df[cat_cols].describe()","31e58c60":"#pd.options.display.max_rows = 300\n#for col in cat_cols :\n    \n    #print('-' * 50)\n    #print('# col : ', col)\n    ##print(df[df.index < 590540]['isFraud'].groupby(df[col]).sum(),df[df.index < 590540]['isFraud'].groupby(df[col]).count())\n    #print(100*df[df.index < 590540]['isFraud'].groupby(df[col]).sum()\/\n    #      df[df.index < 590540]['isFraud'].groupby(df[col]).count()) ","cea549e9":"#for col in cat_cols :\n#    uniq = np.unique(df[col].astype(str))\n#    print('-' * 100)\n#    print('# col {}, n_uniq {}, uniq {}'.format(col, len(uniq), uniq))","bc19af74":"#cor = df[num_cols].astype(float).corr()\n#cor = pd.DataFrame(cor)\n#cor = cor['isFraud']\n#cor = pd.DataFrame(cor)\n#cor = cor[cor['isFraud'] > 0.2]\n#cor_columns_over_zero_dot_tree = cor.index.tolist()","3adb84de":"#colormap = plt.cm.RdBu\n#plt.figure(figsize = (23,23))\n#plt.title('Correlation Analysis of Numeric Columns', y = 1.05, size = 15)\n#sns.heatmap(df[cor_columns_over_zero_dot_tree].astype(float).corr(), linewidths = 0.1, vmax = 1.0, sqaure = True,\n#            cmap = colormap, linecolor = 'white', annot = True)","64ceabef":"df['V39_V51_V52_cor'] = df['V39'] + df['V51'] + df['V52']\ndf['V40_V51_V52_cor'] = df['V40'] + df['V51'] + df['V52']\ndf['V44_V86_V87_cor'] = df['V44'] + df['V86'] + df['V87']\ndf['V45_V86_V87_cor'] = df['V45'] + df['V86'] + df['V87']\ndf['V86_V190_V199_V246_V257_cor'] = df['V86'] + df['V190'] + df['V199'] + df['V246'] + df['V257']\ndf['V87_V257_cor'] = df['V87'] + df['V257']\ndf['V148_V149_V154_V155_V156_V157_V158_cor'] = df['V148'] + df['V149'] + df['V154'] + df['V155'] + df['V156']+ df['V157'] + df['V158']\ndf['V170_V171_V188_V200_V201_cor'] = df['V170'] + df['V171'] + df['V188'] + df['V200'] + df['V201']\ndf['V171_V189_V200_V201_cor'] = df['V171'] + df['V189'] + df['V200'] + df['V201']\ndf['V188_V189_V200_V201_V242_V244_cor'] = df['V188'] + df['V189'] + df['V200'] + df['V201'] + df['V242'] + df['V244']\ndf['V189_V200_V201_V242_V233_V244_cor'] = df['V189'] + df['V200'] + df['V201'] + df['V242'] + df['V243'] + df['V244']\ndf['V190_V199_V228_V233_cor'] = df['V190'] + df['V199'] + df['V228'] + df['V233']\ndf['V199_V228_V230_V246_V257_V258_cor'] = df['V199'] + df['V228'] + df['V230'] + df['V246'] + df['V257'] + df['V258']\ndf['V200_V201_V244_cor'] = df['V200'] + df['V201'] + df['V244']\ndf['V201_V242_V244_cor'] = df['V201'] + df['V242'] + df['V244']\ndf['V228_V230_V246_V257_V258_cor'] = df['V228'] + df['V230'] + df['V246'] + df['V257'] + df['V258']\ndf['V230_V246_V257_V258_cor'] = df['V230'] + df['V246'] + df['V257'] + df['V258']\ndf['V242_V243_V244_cor'] = df['V242'] + df['V243'] + df['V244']\ndf['V243_V244_cor'] = df['V243'] + df['V244']\ndf['V246_V257_V258_cor'] = df['V246'] + df['V257'] + df['V258']","7c67eb28":"df.shape","29b796c1":"START_DATE = '2019-01-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\ndf[\"Date\"] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))","d44570ad":"df['TransactionDT_Weekdays'] = df['Date'].dt.dayofweek\ndf['TransactionDT_Days'] = df['Date'].dt.day\ndf['TransactionDT_Hours'] = df['Date'].dt.hour","ce1c8c24":"df.drop(columns='Date', inplace=True)","5a15e715":"def change_value_P_emaildomain(x) :\n    if x in ['gmail.com', 'icloud.com', 'mail.com' , 'outlook.es', 'protonmail.com'] :\n        return x\n    else :\n        return 'etc'\n    \ndf.loc[:,'P_emaildomain'] = df['P_emaildomain'].apply(lambda x : change_value_P_emaildomain(x))","708b7d59":"def change_value_R_emaildomain(x) :\n    if x in ['gmail.com', 'icloud.com', 'mail.com', 'netzero.net', 'outlook.com', 'outlook.es', 'protonmail.com'] :\n        return x\n    else :\n        return 'etc'\n    \ndf.loc[:,'R_emaildomain'] = df['R_emaildomain'].apply(lambda x : change_value_R_emaildomain(x))","3ce3352e":"def change_value_id_30(x) :\n    if x in ['Android 4.4.2', 'Android 5.1.1' 'iOS 11.0.1' 'iOS 11.1.0', 'iOS 11.4.0', 'other'] :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'id_30'] = df['id_30'].apply(lambda x : change_value_id_30(x))","32c43bbb":"def change_value_id_31(x) :\n    if x in ['Lanix\/Ilium', 'Mozilla\/Firefox' 'comodo' 'icedragon', 'opera', 'opera generic'] :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'id_31'] = df['id_31'].apply(lambda x : change_value_id_31(x))","cc1786b3":"def change_value_id_33(x) :\n    if x in ['1024x552', '1364x768' '1440x759' '1916x901', '1920x975', '2076x1080', '640x360'] :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'id_33'] = df['id_33'].apply(lambda x : change_value_id_33(x))","a31d704b":"tmp = 100*df[df.index < 590540]['isFraud'].groupby(df['DeviceInfo']).sum()\/df[df.index < 590540]['isFraud'].groupby(df['DeviceInfo']).count()\ntmp","16f798fd":"Device_Info = []\nfor i in tqdm_notebook(range(len(tmp))) :\n    if tmp[i] == 100.0 :\n        Device_Info.append(tmp.index[i])\nDevice_Info","4d30b93c":"def change_value_DeviceInfo(x) :\n    if x in Device_Info :\n        return x\n    else :\n        return 'etc'\n\ndf.loc[:,'DeviceInfo'] = df['DeviceInfo'].apply(lambda x : change_value_DeviceInfo(x))","f0afe5cf":"#cat_cols_after_FE = [col for col in df.columns if df[col].dtype in ['object']]\n#df[cat_cols_after_FE].describe()","44ec347d":"#for col in cat_cols_after_FE :\n#    uniq = np.unique(df[col].astype(str))\n#    print('-' * 100)\n#    print('# col {}, n_uniq {}, uniq {}'.format(col, len(uniq), uniq))","6a78cdfa":"#skip_column_because_to_many_variables = []\n#for col in cat_cols:\n#    if col in skip_column_because_to_many_variables :\n#        continue\n#    print('-' *100)\n#    print('col :', col)\n#    \n#    f, ax = plt.subplots(figsize=(12,10))\n#    sns.countplot(x=col, data=df, alpha=0.5)\n#   plt.show()","9d6a21cd":"#eli_columns = []\n\n#for col in df.columns :\n#    if col == 'isFraud' :\n#        continue\n#    if (df[col].count()) < df.shape[0] * 0.3:\n#        eli_columns.append(col)\n#    \n#print(eli_columns)","0a48ead9":"df_num = df.select_dtypes(exclude = ['object'])\ndf_cat = df.select_dtypes(include = ['object'])","f0e270d9":"del df\ngc.collect()","7122a999":"df_cat_one_hot = pd.get_dummies(df_cat)\ndf_total = pd.concat([df_num, df_cat_one_hot], axis=1)\ndf_total.shape","bb3a6058":"df_total.drop(columns = ['TransactionID', 'index'], inplace=True)","5be287e8":"del df_num, df_cat\ngc.collect()","26c35797":"#df_total_oversample = df_total[df_total['isFraud'] == 1]\n#df_total_oversample.shape","adef5258":"#df_total_oversample = pd.concat([df_total_oversample] * 1, axis = 0)\n#df_total_oversample.shape","bee84751":"#df_total = pd.concat([df_total_oversample, df_total], axis = 0)\n#df_total.reset_index(inplace=True)","7446ab68":"#gc.collect()","2f5ad089":"# Oversampling\n#df_train = df_total[df_total.index < 590540 + df_total_oversample.shape[0]]\n#df_test = df_total[df_total.index >= 590540 + df_total_oversample.shape[0]]\n","c0d822b2":"df_train = df_total[df_total.index < 590540]\ndf_test = df_total[df_total.index >= 590540]","d390f612":"#del df_total_oversample\n#gc.collect()","60322d48":"y = pd.DataFrame(df_train['isFraud'])\nX = df_train.drop(columns=['isFraud'])\nX_test = df_test.drop(columns=['isFraud'])","a3c65cc8":"X.shape, y.shape, X_test.shape","89e7590f":"del df_train, df_test, df_total\ngc.collect()","df64229b":"X.shape, y.shape, X_test.shape","b8529866":"np.unique(y['isFraud'])","7e88d8f1":"index_array = np.arange(len(X))\nval_index = index_array[random.sample(range(0,X.shape[0]), X.shape[0]\/\/5)]\ntrain_index = np.delete(index_array[:X.shape[0]], val_index, axis=0)","68008d81":"len(train_index), len(val_index)","928a6375":"X_train, X_val = X.iloc[train_index], X.iloc[val_index]\ny_train, y_val = y.iloc[train_index], y.iloc[val_index]","bf3ac808":"%%time\nprediction_test_fold = []\n\nparam = {'booster' : 'gbtree',\n         'max_depth' : 9,\n         'nthread' : -1,\n         'num_class' : 1,\n         'objective' : 'binary:logistic',\n         'silent' : 1,\n         'eval_metric' : 'auc',\n         'eta' : 0.15,\n         'tree_method' : 'gpu_hist',\n         'min_child_weight' : 1,\n         'colsample_bytree' : 0.8,\n         'colsample_bylevel' : 0.8,\n         'seed' : 2019}\n\n\n\n#X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n#y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    \n\nprint(\"Train Shape :\", X_train.shape,\n      \"Validation Shape :\", X_val.shape,\n      \"Test Shape :\", X_test.shape)\n    \ndtrn = xgb.DMatrix(X_train, label=y_train, feature_names = X.columns)\ndval = xgb.DMatrix(X_val, label = y_val, feature_names = X.columns)\ndtst = xgb.DMatrix(X_test, feature_names = X.columns)\n    \nxgb1 = xgb.train(param, dtrn, num_boost_round=10000, evals = [(dtrn, 'train'), (dval, 'eval')],\n                 early_stopping_rounds = 200, verbose_eval=200)\n                 \nprediction_XGB = xgb1.predict(dtst)\n#prediction_test_fold.append(prediction_XGB)","286bd7db":"\n\nparams = {'num_leaves': 500,\n          'min_child_weight': 0.03,\n          'feature_fraction': 0.4,\n          'bagging_fraction': 0.4,\n          'min_data_in_leaf': 100,\n          'objective': 'binary',\n          'max_depth': 9,\n          'learning_rate': 0.15,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 10,\n          \"metric\": 'auc',\n          \"verbosity\": -1,\n          'reg_alpha': 0.4,\n          'reg_lambda': 0.6,\n          'random_state': 50,\n         }","94647dfc":"%%time\n#X_train, X_valid = X.iloc[train_index], X.iloc[val_index]\n#y_train, y_valid = y.iloc[train_index], y.iloc[val_index]\n  \n\ndtrain = lgb.Dataset(X_train, label=y_train)\ndvalid = lgb.Dataset(X_val, label=y_val)\n#dtest = lgb.Dataset(X_test)\nmodel = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)\n    \n\nprediction_LGB = model.predict(X_test)\n\n","b5ea0205":"submission['isFraud'] = np.nan\nsubmission.head()","7c93b309":"submission['isFraud'] = (0.5 * prediction_XGB) + (0.5 * prediction_LGB)\nsubmission.head()","82941a14":"submission.to_csv('sample_submission_after_Feature_Engineering6.csv', index = False)","97d33d50":"submission[submission['isFraud'] > 0.1]","e93fc961":"## 1. Loading Library","5ae270db":"## 5. Modeling","4c282138":"## 0. Context","9f64a9ea":"## 2. Reading Data SET","dd406de7":"### 1) Reduce Memory using down sizing Data SET","49d0b9d7":"## 4. Feature Engineering","d6112fa8":"- In this competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\n- The data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information.\n--------------------------------\n- -Categorical Features - Transaction\n- ProductCD\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9\n- -Categorical Features - Identity\n- DeviceType\n- DeviceInfo\nid_12 - id_38\n\n--------------------------------\n- The TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).","460ba5dd":"1. Loading Library\n2. Read Data SET\n3. EDA\n4. Preprocessing\n5. Feature Engineering\n6. Modeling\n7. Evaluation","0c708999":"- From above on, Usage of RAM is 3.8GB","66204165":"## 3. EDA"}}