{"cell_type":{"4dfec185":"code","52074c6b":"code","66011e05":"code","bb345dcf":"code","bee14762":"code","63d2ef14":"code","a0fe7245":"code","7ec0fc6a":"code","97a96aee":"code","e28546b9":"code","0fc14c9c":"code","a7a1f0db":"code","39a9d7e8":"code","f038d80d":"code","e52be759":"code","491c9174":"code","e74f39ad":"code","9d3d49a3":"code","321ddf99":"code","3b7862a8":"markdown","05c78051":"markdown","875b6a38":"markdown","fc77c138":"markdown","ef0debf7":"markdown","9959d399":"markdown","41aba706":"markdown","94494ab1":"markdown","43c0f491":"markdown","6447274e":"markdown","b6465edb":"markdown","3cd5631a":"markdown","1deb0b06":"markdown"},"source":{"4dfec185":"#First we need import pandas to create dataframes, Matplotlib to visualize our data and numpy to create and reshape arrays.\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\n%matplotlib inline  ","52074c6b":"#A class to analyze punctuations from a text\nclass PunctuationAnalyzer():\n    \n    #function that counts punctuation\n    def count_punctuation(self,text):\n\n        punctuation_list={\"Ellipsis Points\":0,\"Dot\":0,\"Comma\":0,\"Colon\":0,\"Dash\":0,\"Exclamation Mark\":0,\"Question Mark\":0,\"Semi-colon\":0,\"Parantheses\":0,\"Apostrophe\":0,\"Quotation Marks\":0}\n        char=0\n        for i in text:\n            elnot=True\n            if(char+2<len(text)):\n                if((i+text[char+1]+text[char+2])==\"...\" or i==\"\u2026\" or i+text[char+1]==\"..\"):\n                    \n                    punctuation_list[\"Ellipsis Points\"]+=1\n                    elnot=False\n                    \n            if(i==\".\" and elnot):\n                punctuation_list[\"Dot\"]+=1\n            elif(i==\",\"):\n                punctuation_list[\"Comma\"]+=1\n            elif(i==\":\"):\n                punctuation_list[\"Colon\"]+=1\n            elif(i==\"-\"):\n                punctuation_list[\"Dash\"]+=1\n            elif(i==\"!\"):\n                punctuation_list[\"Exclamation Mark\"]+=1\n            elif(i==\"?\"):\n                punctuation_list[\"Question Mark\"]+=1\n            elif(i==\";\"):\n                punctuation_list[\"Semi-colon\"]+=1\n            elif(i==\"(\"):\n                punctuation_list[\"Parantheses\"]+=1\n            elif(i==\"'\"):\n                punctuation_list[\"Apostrophe\"]+=1\n            elif(i=='\"'):\n                 punctuation_list[\"Quotation Marks\"]+=1     \n            char+=1\n        return punctuation_list\n    \n    #function that returns data and labels to create data frames\n    def punct_forFrame(self,punct_dict):\n        data=[]\n        labels=list()\n        for k,v in punct_dict.items():\n            l=[v]\n            data.append(l)\n            labels.append(k)\n        return data,labels\n    \n    def to_Frame(self,i\u015faretler):\n        data,labels=pa.punct_forFrame(i\u015faretler)\n        data=np.array(data)\n        data=data.reshape(1,11)\n        \n        return pd.DataFrame(data,columns=labels)\n","66011e05":"#a function that read a file\ndef read_file(path):\n    with open(path,\"r\") as file:\n\n        return file.read()","bb345dcf":"#Reading the files\ntext1=read_file(\"..\/input\/Montaigne-JoA.txt\")\ntext2=read_file(\"..\/input\/Montaigne-OfIdleness.txt\")\ntext3=read_file(\"..\/input\/Montaigne-OfLiars.txt\")\ntext4=read_file(\"..\/input\/Montaigne-OfSorrow.txt\")\ntext5=read_file(\"..\/input\/Montaigne-PD.txt\")\n","bee14762":"#Creating the PunctuationAnalyzer object\npa=PunctuationAnalyzer()","63d2ef14":"#We analyze the punctuations here\nMontaigne1=pa.count_punctuation(text1)\nMontaigne2=pa.count_punctuation(text2)\nMontaigne3=pa.count_punctuation(text3)\nMontaigne4=pa.count_punctuation(text4)\nMontaigne5=pa.count_punctuation(text5)\n","a0fe7245":"print(Montaigne1)","7ec0fc6a":"#Here we plot our data\n\nfigure,axes=plt.subplots(2,3,figsize=[20,15])\n\naxes[0][0].pie(Montaigne1.values(),labels=Montaigne1.keys())\naxes[0][0].set_title(\"JoA\")\n\naxes[0][1].pie(Montaigne2.values(),labels=Montaigne2.keys())\naxes[0][1].set_title(\"OfIdleness\")\n\naxes[0][2].pie(Montaigne3.values(),labels=Montaigne3.keys())\naxes[0][2].set_title(\"OfLiars\")\n\naxes[1][0].pie(Montaigne4.values(),labels=Montaigne4.keys())\naxes[1][0].set_title(\"OfSorrow\")\n\naxes[1][1].pie(Montaigne5.values(),labels=Montaigne5.keys())\naxes[1][1].set_title(\"PD\")\n\naxes[1][2].remove()\n\n\nfigure.tight_layout(pad=4,w_pad=8,h_pad=2)\n\n","97a96aee":"dan1=pa.count_punctuation(read_file(\"..\/input\/DanBrown-DaA1.txt\"))\ndan2=pa.count_punctuation(read_file(\"..\/input\/DanBrown-DaA2.txt\"))\ndan3=pa.count_punctuation(read_file(\"..\/input\/DanBrown-DaA3-4.txt\"))\ndan4=pa.count_punctuation(read_file(\"..\/input\/DanBrown-Origin1.txt\"))\ndan5=pa.count_punctuation(read_file(\"..\/input\/DanBrown-OriginP.txt\"))\n","e28546b9":"figure,axes=plt.subplots(2,3,figsize=[15,10])\n\naxes[0][0].pie(dan1.values(),labels=dan1.keys())\naxes[0][0].set_title(\"AaD 1\")\n\naxes[0][1].pie(dan2.values(),labels=dan2.keys())\naxes[0][1].set_title(\"AaD 2\")\n\naxes[0][2].pie(dan3.values(),labels=dan3.keys())\naxes[0][2].set_title(\"AaD 2\")\n\naxes[1][0].pie(dan4.values(),labels=dan4.keys())\naxes[1][0].set_title(\"Origin 1\")\n\naxes[1][1].pie(dan5.values(),labels=dan5.keys())\naxes[1][1].set_title(\"Origin Prologue\")\n\naxes[1][2].remove()\n\nfigure.tight_layout(pad=4,w_pad=8,h_pad=2)\n\n","0fc14c9c":"GRRM1=pa.count_punctuation(read_file(\"..\/input\/GRRM-GOTPrologue.txt\"))\nGRRM2=pa.count_punctuation(read_file(\"..\/input\/GRRM-GOTDany.txt\"))\nGRRM3=pa.count_punctuation(read_file(\"..\/input\/GRRM-SOSPrologue.txt\"))\nGRRM4=pa.count_punctuation(read_file(\"..\/input\/GRRM-SOSPrologue 2.txt\"))","a7a1f0db":"figure,axes=plt.subplots(2,2,figsize=[15,10])\n\naxes[0][0].pie(GRRM1.values(),labels=GRRM1.keys())\naxes[0][0].set_title(\"GoT Prologue\")\n\naxes[0][1].pie(GRRM2.values(),labels=GRRM2.keys())\naxes[0][1].set_title(\"GOT Dany\")\n\n\naxes[1][0].pie(GRRM3.values(),labels=GRRM3.keys())\naxes[1][0].set_title(\"SoS Prologue 1\")\n\naxes[1][1].pie(GRRM4.values(),labels=GRRM4.keys())\naxes[1][1].set_title(\"Sos Prologue 2\")\n\n\nfigure.tight_layout(pad=4,w_pad=8,h_pad=2)\n","39a9d7e8":"\nMontaigneDF=pa.to_Frame(Montaigne1)\nMontaigneDF=pd.concat([MontaigneDF,pa.to_Frame(Montaigne2)])\nMontaigneDF=pd.concat([MontaigneDF,pa.to_Frame(Montaigne3)])\nMontaigneDF=pd.concat([MontaigneDF,pa.to_Frame(Montaigne4)])\nMontaigneDF=pd.concat([MontaigneDF,pa.to_Frame(Montaigne5)])\n\nMontaigneDF[\"Name\"]=\"Essays\"\n\n\n\nMontaigneDF\n","f038d80d":"DanDf=pa.to_Frame(dan1)\nDanDf=pd.concat([DanDf,pa.to_Frame(dan2)])\nDanDf=pd.concat([DanDf,pa.to_Frame(dan3)])\nDanDf=pd.concat([DanDf,pa.to_Frame(dan4)])\nDanDf=pd.concat([DanDf,pa.to_Frame(dan5)])\n\nDanDf[\"Name\"]=\"Angels and Demons\"\nDanDf[\"Name\"].iloc[3:]=\"Origin\"\n\nDanDf\n\n","e52be759":"GrrmDf=pa.to_Frame(GRRM1)\nGrrmDf=pd.concat([GrrmDf,pa.to_Frame(GRRM2)])\nGrrmDf=pd.concat([GrrmDf,pa.to_Frame(GRRM3)])\nGrrmDf=pd.concat([GrrmDf,pa.to_Frame(GRRM4)])\n\nGrrmDf[\"Name\"]=\"GoT\"\nGrrmDf[\"Name\"].iloc[2:]=\"SoS\"\n\n\nGrrmDf","491c9174":"TextsDf=pd.concat([MontaigneDF,DanDf,GrrmDf])\nTextsDf\n","e74f39ad":"from sklearn.cross_validation import train_test_split\nX=TextsDf.iloc[:,:-1]\nY=TextsDf.iloc[:,-1:]\n\nOriginX=X\nfrom sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nX=ss.fit_transform(X)\n\nx_train, x_test, y_train, y_test=train_test_split(X,Y,test_size=0.33,random_state=0)\n\n","9d3d49a3":"from sklearn.metrics import confusion_matrix #We will rate algorithms with confusion matrix\n\nfrom sklearn.neighbors import KNeighborsClassifier #KNN algorithm\nknn=KNeighborsClassifier(n_neighbors=2)\nknn.fit(x_train,y_train)\ny_predict=knn.predict(x_test)\n\nprint(\"KNN\")\nprint(confusion_matrix(y_test,y_predict))\nprint(\"4 out of 5\")\nprint(\"-------------------\")\n\nfrom sklearn.svm import SVC #Support Vector Classifier Algorithm\nsvc=SVC(kernel=\"poly\",degree=3)\nsvc.fit(x_train,y_train)\ny_predict=svc.predict(x_test)\n\nprint(\"SVC\")\nprint(confusion_matrix(y_test,y_predict))\nprint(\"2 out of 5\")\n\nprint(\"-------------------\")\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(n_estimators=3)\nrf.fit(x_train,y_train)\ny_predict=rf.predict(x_test)\n\nprint(\"Random Forest\")\nprint(confusion_matrix(y_test,y_predict))\nprint(\"3 out of 5\")\n\nprint(\"-------------------\")\n\nfrom sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\ny_predict=nb.predict(x_test)\n\nprint(\"Naive Bayes\")\nprint(confusion_matrix(y_test,y_predict))\nprint(\"3 out of 5\")\n\nprint(\"-------------------\")\n\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(random_state=0)\nlr.fit(x_train,y_train)\ny_predict=lr.predict(x_test)\n\nprint(\"Logistic Regression\")\nprint(confusion_matrix(y_test,y_predict))\nprint(\"5 out of 5\")\n\nprint(\"-------------------\")","321ddf99":"MontaigneNew=read_file(\"..\/input\/OfDH.txt\")\nMontaigneNew=pa.count_punctuation(MontaigneNew)\nMontaigneNew=pa.to_Frame(MontaigneNew)\n\nss=StandardScaler()\nNewDataset=pd.concat([OriginX,MontaigneNew])\nNewDataset=ss.fit_transform(NewDataset)\nMontaigneNew=NewDataset[-1]\nMontaigneNew=[MontaigneNew]\n\nprint(knn.predict(MontaigneNew))\nprint(lr.predict(MontaigneNew))","3b7862a8":"**HYPOTHESIS**\n\nProve that every author has his\/her  special punctuation pattern that they use in their writings.\n\n","05c78051":"Situation that we have seen in the previous example is visible here to. ","875b6a38":"**RESULT**\n> This research brings some evidence that punctuation marks define a book's idendity and by using this knowledge in machine learning we can find out which book does a text belongs.","fc77c138":"**STEP 1: Data Preprocessing**\n> We simplify the text and count punctuations.","ef0debf7":"**Data Preprocessing**\nIn order to use machine learning algorithms we need to turn our data to pandas dataframes.\n","9959d399":"**Machine Learning**\n> Now we can find the best classification algorithm for our dataset.","41aba706":"**CONCLUSION**\n> As we can see in the examples, every book has it's own punctuation pattern but this \ndoesn't mean that other books of same author will be following the same pattern.\n \n> With this knowledge we can use machine learning algortihms in order to find which book does a text belongs to.","94494ab1":"**STEP 2: Data Visualization**\n> In order to analyze the distibutions of punctuations we visualize them.","43c0f491":"As we can see all of the essays of Montaigne follow the similar distribution in punctuations.\n\nLet's look  at Dan Brown's books.","6447274e":"As you can see from the test results Logistic Regression is the best algorithm for this dataset with 5 out of 5  and KNN comes the second. Now lets test these to algorithms with another text from Montaigne.","b6465edb":"Next we need split our data to test and train sets.  And we need to standardize it in order to avoid outlayer examples.","3cd5631a":"But in this occasion we can't say the same thing. \"Angels and Demons\" follow a pattern but Origin has it's own pattern.\n\nLet's have a look to another example:","1deb0b06":"**USING IT IN MACHINE LEARNING**"}}