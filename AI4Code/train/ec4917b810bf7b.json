{"cell_type":{"1b2f9f4e":"code","1d74f896":"code","459c939b":"code","c5b27b2c":"code","82e3a538":"code","042af600":"code","ae97200e":"code","4ee3a43b":"code","a588e8d6":"code","e79d433c":"code","124358f6":"code","b4ea2f83":"markdown"},"source":{"1b2f9f4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d74f896":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom yellowbrick.classifier import ROCAUC\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","459c939b":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf.head()","c5b27b2c":"df.isna().sum()\/df.shape[0]*100 #Check proprtion of null value for each column","82e3a538":"df = df.dropna()\ndf.columns","042af600":"df = df[['Survived', 'Pclass','Sex', 'Age', 'SibSp',\n       'Parch',  'Fare', 'Embarked']]\ndf['Embarked'] = df['Embarked'].apply(str)\nle = LabelEncoder()\ndf['Sex'] = le.fit_transform(df['Sex'])\ndf['Embarked'] = le.fit_transform(df['Embarked'])\ndf.head()","ae97200e":"X,y = df.loc[:, df.columns != 'Survived'], df.loc[:, df.columns == 'Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","4ee3a43b":"X_train","a588e8d6":"model = RandomForestClassifier()\nvisualizer = ROCAUC(model, classes=[0,1])\n\nvisualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)        # Evaluate the model on the test data\nvisualizer.show() ","e79d433c":"trees=model.estimators_\nfeature_imporance_tree_wise = []\nfor each_tree in trees:\n    feature_imporance_tree_wise.append(each_tree.feature_importances_)\nfeature_imporance_tree_wise = pd.DataFrame(feature_imporance_tree_wise,\n                                         columns = [ 'Pclass','Sex', 'Age', 'SibSp',\n       'Parch',  'Fare', 'Embarked'] )\nfeature_imporance_tree_wise.head()","124358f6":"import seaborn as sns\nsns.set(style=\"whitegrid\")\n\nax = sns.barplot(x=feature_imporance_tree_wise.columns, y=feature_imporance_tree_wise.mean(),\n                yerr = feature_imporance_tree_wise.std()).set_title(\"Feature Importance Plot\")\n                \n","b4ea2f83":"We drop the missing value based rows. "}}