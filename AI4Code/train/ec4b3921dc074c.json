{"cell_type":{"509ba7ff":"code","bdfdb38a":"code","5fed52a5":"code","8a6bc33a":"code","ccb815c1":"code","3dde8382":"code","e418da14":"code","2fdb8ee6":"code","9051add2":"code","12d0f6c4":"code","53c16826":"code","1651a29e":"code","5f9cd59d":"code","ec329ef0":"code","68f33f1b":"code","9997f4dd":"code","277838db":"code","a2752e6a":"code","88a65bdf":"code","97058a6c":"code","b0128955":"code","e100dd54":"code","66ddd547":"code","9ca56078":"code","0f22894c":"code","411185a3":"code","9f3b64d0":"code","61f1ac8a":"code","5b3f2c79":"code","63681245":"code","e056aff4":"code","8e878953":"code","ed704749":"code","62109229":"code","9a972abd":"code","e2ef6a1a":"code","a37a6b7a":"code","2186e0fe":"code","9dec06d0":"code","9ddf6703":"code","07238245":"code","7433ab6e":"code","e9e99542":"code","3e1ee2ec":"code","d216313f":"code","340973d3":"code","b01cc7e9":"code","9c38e03e":"code","0defca4f":"code","ffc90fe6":"code","3c96cb9f":"code","55c891fd":"code","85e04e5c":"code","f4a69aec":"code","8904c841":"code","e9315fce":"code","f1c9d135":"code","e9dc1d8b":"code","c70dbcf2":"code","10124a6f":"code","7d3bb519":"code","99a91560":"code","41c6d01a":"code","b23d6925":"code","40332c84":"code","05e968ad":"code","727e2b64":"code","4db8bbd3":"code","3769e7ba":"code","4ded498d":"code","c45f6df7":"code","f03d480e":"code","6c0206bc":"code","4d05a7b7":"code","33ea32f1":"code","5708ad34":"code","7e7d5029":"code","8a351bb3":"code","fa7dcca9":"code","3e76a417":"code","4923d275":"code","26e0c7b0":"code","498265b3":"code","bb0226ea":"code","9b95e6de":"code","8a49fc22":"code","5d744bb9":"code","4702eef9":"code","59eabf0e":"code","653aa358":"code","1d4043c7":"code","f19a2cab":"code","69a6d0c6":"code","a7ae040f":"code","e9a04f55":"code","2c30376f":"code","c1791063":"code","ae0d99ba":"code","38d6d9a2":"code","3a448d8d":"code","1dfe3284":"code","1ccb8df8":"code","f29842aa":"code","3cec4343":"code","b3fca4c2":"code","c17d3043":"code","c0bc5fff":"code","9847ef14":"code","e22653e2":"code","09aee7b5":"code","36639a79":"code","20b27472":"code","e5b1c01f":"code","6c1ca76a":"code","3e4d14d9":"code","47eb06b2":"code","06046a09":"code","cd67c6dd":"code","c56bc245":"code","96a16827":"code","ebe5ce0d":"code","e8c268ae":"code","a2fa31a1":"code","de3ca229":"code","a483c4d3":"code","b9a0971e":"code","6653a952":"code","bbdf447d":"code","58e692ed":"code","e8ddc58f":"code","7cbd8925":"code","9cc79774":"code","4feef9c5":"code","bbb34946":"code","74c37116":"code","32a52711":"code","a84f8f0f":"code","0ec99c6e":"code","b2aedeef":"code","af1fecfc":"code","2730c52d":"code","f1b4ff68":"code","c25ec6f5":"code","a1fee832":"code","ce9e97dd":"code","1280aedc":"code","3aa4e691":"code","7703774f":"code","c4e163e6":"code","46d6ac70":"code","d5f47a1d":"code","f37d3a2c":"code","adaff1fd":"code","d81822d2":"markdown","d9d74118":"markdown","2d21ca6b":"markdown","655ec112":"markdown","dc6f4b9e":"markdown","b2d93f10":"markdown","2f5c0793":"markdown","a8a17fcd":"markdown","c3d763ec":"markdown","9ccf2673":"markdown","8d111bbd":"markdown","5a4f893f":"markdown","39e69424":"markdown","b76f9e63":"markdown","4af4af32":"markdown","91c6a017":"markdown","6cead877":"markdown","696f97b6":"markdown","dfbffdce":"markdown","dc838f53":"markdown","6eedc3bb":"markdown","3f3d8ddd":"markdown","bc072b5b":"markdown","2fe87619":"markdown","4e1ce6f3":"markdown","105a4217":"markdown","b72f12f6":"markdown","3cb83e6c":"markdown","5ca7eaba":"markdown","0e80d0a2":"markdown","113379fd":"markdown","deeb529a":"markdown","63eaf3ff":"markdown","d7bdf236":"markdown","084a2d89":"markdown","1e7de4d1":"markdown","f93947a4":"markdown","00a83513":"markdown","d4693466":"markdown","5596cb2f":"markdown","10757755":"markdown","f8fd8ccc":"markdown","51d267ec":"markdown","4c93c0c9":"markdown","581ed9b1":"markdown","62881b05":"markdown"},"source":{"509ba7ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option(\"display.max_columns\",None) \npd.set_option(\"display.max_rows\",None)\n# Any results you write to the current directory are saved as output.","bdfdb38a":"data = pd.read_csv(\"..\/input\/2015.csv\")","5fed52a5":"data.info()# Display the content of data","8a6bc33a":"data.rename(columns={\"Economy (GDP per Capita)\":\"economy\",\"Health (Life Expectancy)\":\"health\",\"Trust (Government Corruption)\":\"Trust\"}, inplace=True)","ccb815c1":"# shape gives number of rows and columns in a tuple\ndata.shape","3dde8382":"data.columns","e418da14":"data.columns = [each.replace(\" \",\"_\") if(len(each.split())>1) else each for each in data.columns]\nprint(data.columns)","2fdb8ee6":"data.columns = [each.lower() for each in data.columns]\nprint(data.columns)","9051add2":"data.describe()","12d0f6c4":"data.head()","53c16826":"data.tail()","1651a29e":"data.sample(5)","5f9cd59d":"data.dtypes","ec329ef0":"# Display positive and negative correlation between columns\ndata.corr()","68f33f1b":"#sorts all correlations with ascending sort.\ndata.corr().unstack().sort_values().drop_duplicates()","9997f4dd":"#correlation map\nplt.subplots(figsize=(10,10))\nsns.heatmap(data.corr(), annot=True, linewidth=\".5\", cmap=\"YlGnBu\", fmt=\".2f\")\nplt.show()\n#figsize - image size\n#data.corr() - Display positive and negative correlation between columns\n#annot=True -shows correlation rates\n#linewidths - determines the thickness of the lines in between\n#cmap - determines the color tones we will use\n#fmt - determines precision(Number of digits after 0)\n#if the correlation between the two columns is close to 1 or 1, the correlation between the two columns has a positive ratio.\n#if the correlation between the two columns is close to -1 or -1, the correlation between the two columns has a negative ratio.\n#If it is close to 0 or 0 there is no relationship between them.","277838db":"data.isnull().head(15)","a2752e6a":"data.isnull().sum() #Indicates values not defined in our data","88a65bdf":"data.isnull().sum().sum()  #Indicates sum of values in our data","97058a6c":"data[[\"happiness_score\"]].isnull().head(15)","b0128955":"data.sort_values(\"happiness_score\", ascending=False).head(10)","e100dd54":"data.sort_values(\"happiness_score\", ascending=True).head(10)","66ddd547":"data[[\"happiness_score\",\"economy\",\"family\",\"health\"]].head(10)","9ca56078":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.happiness_score.plot(kind=\"line\", color=\"g\", label=\"happiness_score\", linewidth=1, alpha=0.5, grid=True, figsize=(12,12))\ndata.economy.plot(kind=\"line\", color=\"r\", label=\"economy\", linewidth=1, alpha=0.5, grid=True)\ndata.family.plot(kind=\"line\", color=\"y\", label=\"family\", linewidth=1, alpha=0.5, grid=True)\ndata.health.plot(kind=\"line\", color=\"b\", label=\"health\", linewidth=1, alpha=0.5, grid=True)\nplt.legend(loc=\"upper right\")# legend = puts label into plot\nplt.xlabel(\"x axis\")         # label = name of label\nplt.ylabel(\"y axis\")\nplt.title(\"line Plot\")       # title = title of plot\nplt.show()\n\n#plt.xticks(np.arange(first value,last value,step)) \n#plt.xticks(np.arange(0,800,30)) #Determines the ranges of values in the x-axis\n#plt.yticks(np.arange(0,300,30)) #Determines the ranges of values in the y-axis\n#plt.show()","0f22894c":"# subplots\ndata.plot(subplots = True, figsize=(12,12))\nplt.show()","411185a3":"plt.subplot(4,2,1)\ndata.family.plot(kind=\"line\", color=\"orange\", label=\"family\", linewidth=1, alpha=0.5, grid=True, figsize=(10,10))\ndata.happiness_score.plot(kind=\"line\", color=\"green\", label=\"family\", linewidth=1, alpha=0.5, grid=True, figsize=(10,10))\nplt.ylabel(\"family\")\nplt.subplot(4,2,2)\ndata.generosity.plot(kind=\"line\", color=\"blue\", label=\"generosity\", linewidth=1, alpha=0.5, grid=True, linestyle=\":\")\nplt.ylabel(\"generosity\")\nplt.subplot(4,2,3)\ndata.trust.plot(kind=\"line\", color=\"green\", label=\"trust\", linewidth=1, alpha=0.5, grid=True, linestyle=\"-.\")\nplt.ylabel(\"trust\")\nplt.subplot(4,2,4)\ndata.freedom.plot(kind=\"line\", color=\"red\", label=\"freedom\", linewidth=1, alpha=0.5, grid=True)\nplt.ylabel(\"freedom\")\nplt.show()","9f3b64d0":"# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind=\"scatter\", x=\"happiness_score\", y=\"economy\", alpha=0.5, color=\"green\", figsize=(5,5))\nplt.xlabel(\"happiness_score\")    # label = name of label\nplt.ylabel(\"economy\")\nplt.title(\"Happiness Score Economy Scatter Plot\") # title = title of plot\nplt.show()","61f1ac8a":"data.plot(kind=\"scatter\", x=\"economy\", y=\"health\", alpha=0.5, color=\"blue\", figsize=(5,5))\nplt.xlabel(\"economy\")    # label = name of label\nplt.ylabel(\"health\")\nplt.title(\"Economy Health Scatter Plot\") # title = title of plot\nplt.show()","5b3f2c79":"# Histogram\n# bins = number of bar in figure\ndata.happiness_score.plot(kind=\"hist\",color=\"orange\", bins=160, figsize=(10,10))\nplt.show()","63681245":"data.happiness_score.head(30).plot(kind=\"bar\")\nplt.show()","e056aff4":"data.happiness_score.sample(30).plot(kind=\"bar\")\nplt.show()","8e878953":"data.happiness_score.head(100).plot(kind=\"area\")\nplt.show()","ed704749":"# clf() = cleans it up again you can start a fresh\ndata.happiness_score.plot(kind=\"hist\", bins=50)\nplt.clf() # We can not see plot if we use clf() method\nplt.show()","62109229":"#we dont use.its just example\ndic2 = [{\"id\": 825, \"name\": \"Orhan\"}, {\"id\": 851, \"name\": \"Kadir\"},{\"id\": 856, \"name\": \"Cemal\"}]\ndf2 = pd.DataFrame(dic2)\ndf2","9a972abd":"#create dictionary and look its keys and values\ndictionary = {\"Turkey\":\"Ankara\",\"Germany\":\"Berlin\"}\nprint(dictionary.keys())\nprint(dictionary.values())","e2ef6a1a":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary[\"Turkey\"] = \"Ankara\" # update existing entry\nprint(dictionary)\ndictionary[\"France\"] = \"Paris\"    #Add new entry\nprint(dictionary)\ndel dictionary[\"France\"]           # remove entry with key 'spain'\nprint(dictionary)\nprint(\"France\" in dictionary)     # check include or not\ndictionary.clear()                # remove all entries in dict\nprint(dictionary)","a37a6b7a":"# In order to run all code you need to take comment this line\n#del dictionary         # delete entire dictionary     \nprint(dictionary)       # it gives error because dictionary is deleted","2186e0fe":"print(type(data)) # pandas.core.frame.DataFrame\nprint(type(data[[\"freedom\"]])) #pandas.core.frame.DataFrame\nprint(type(data[\"freedom\"])) #pandas.core.series.Series\nprint(type(data[\"freedom\"].values)) #numpy.ndarray","9dec06d0":"series = data['freedom']        # data['Defense'] = series\ndata_frame = data[['freedom']]  # data[['Defense']] = data frame\n\nprint(type(series))\nprint(type(data_frame))\n\nprint(series.head(10))\ndata_frame.head(10)","9ddf6703":"# Comparison operator\nprint(3 > 2)\nprint(3!=2)\n# Boolean operators\nprint(True and False)\nprint(True or False)","07238245":"# 1 - Filtering Pandas data frame\nx = data[\"happiness_score\"]>5.0\ndata[x]","7433ab6e":"# 2 - Filtering pandas with logical_and\ndata[np.logical_and(data[\"family\"]>1.3,data[\"economy\"]>1.3)]","e9e99542":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data[\"family\"]>1.3) & (data[\"economy\"]>1.3)]","3e1ee2ec":"# Stay in loop if condition( i is not equal 5) is true\ni = 0\nwhile i != 5:\n    print(\"i is: \",i)\n    i+=1\nprint(i,\" is equal to 5\")","d216313f":"# Stay in loop if condition( i is not equal 5) is true\nlis = [1,2,3,4,5]\n\nfor i in lis:\n    print(\"i is: \",i)\nprint(\"\")    \n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index,value in enumerate(lis):\n    print(index,\" : \",value)\nprint(\"\")\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = dictionary = {'Turkey':'Ankara','France':'Paris'}\nfor key in dictionary:\n    print(key)\nprint(\"\")\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint(\"\")\n# For pandas we can achieve index and value\nfor index,value in data[[\"freedom\"]][0:5].iterrows():\n    print(index,\" : \",value)\ndata[[\"freedom\"]][0:5]","340973d3":"# example of what we learn above\ndef tuple_ex():\n    \"\"\" return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuple_ex()\nprint(a,b,c)","b01cc7e9":"# guess print what\nx = 2\ndef f():\n    x=3\n    return x\nprint(x)      # x = 2 global scope\nprint(f())    # x = 3 local scope","9c38e03e":"# What if there is no local scope\nx = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","0defca4f":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","ffc90fe6":"#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())    ","3c96cb9f":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","55c891fd":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1,1,2)\nprint(\"\")\nf(1,2,3,4)\nprint(\"\")\nf(\"orhan\",\"kadir\",\"cemal\",1)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():     # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(country = 'Turkey', capital = 'Ankara', population = 80000000)","85e04e5c":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(4))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))","f4a69aec":"number_list=(1,2,3,4,5,6,7,8,9)\ny = map(lambda x : x**2,number_list)\n#liste_Y = list(y) \n#print(liste_Y) #[1, 4, 9, 16, 25, 36, 49, 64, 81]\n#OR short way\nprint(list(y)) #[1, 4, 9, 16, 25, 36, 49, 64, 81]","8904c841":"# iteration example\nname = \"Orhan\"\nitr = iter(name)\nprint(next(itr))# print next iteration\nprint(next(itr))# print next iteration\nprint(*itr)     # print remaining iteration","e9315fce":"list1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)  #converting zip to list type\nprint(z_list)\nprint(\"\")    \nitr = iter(z_list) \nprint(next(itr))   # print next iteration\nprint(*itr)        # print remaining iteration","f1c9d135":"un_zip = zip(*z_list)\nunlist1,unlist2 = list(un_zip) # unzip returns tuple\nprint(unlist1)\nprint(unlist2)\nprint(type(unlist1))\nprint(type(list(unlist1))) #if we want to change data type tuple to list we need to use list() method.","e9dc1d8b":"num1 = [1,2,3]\nnum2 = [i+1 for i in num1]\nprint(num2)\n#OR\nprint([i+1 for i in num1])","c70dbcf2":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i==10 else i-5 if i<7 else i+5 for i in num1]\nprint(num2)","10124a6f":"# lets return 2015.csv and make one more list comprehension example\n# lets classify happiness_score whether they have high or low. Our threshold is happiness_score.\nthreshold = sum(data.happiness_score)\/len(data.happiness_score)\ndata[\"happiness_score_level\"] = [\"high\" if i>threshold else \"low\" for i in data.happiness_score]\ndata.loc[60:90,[\"happiness_score_level\",\"happiness_score\"]]","7d3bb519":"data = pd.read_csv('..\/input\/2015.csv')\ndata.head()  # head shows first 5 rows","99a91560":"data.rename(columns={\"Economy (GDP per Capita)\":\"economy\",\"Health (Life Expectancy)\":\"health\",\"Trust (Government Corruption)\":\"Trust\"}, inplace=True)\n","41c6d01a":"data.columns = [each.replace(\" \",\"_\") if(len(each.split())>1) else each for each in data.columns]\nprint(data.columns)","b23d6925":"\ndata.columns = [each.lower() for each in data.columns]\nprint(data.columns)","40332c84":"# tail shows last 5 rows\ndata.tail()","05e968ad":"# columns gives column names of features\ndata.columns","727e2b64":"# shape gives number of rows and columns in a tuple\ndata.shape","4db8bbd3":"data.dtypes","3769e7ba":"data[\"region\"].unique() #shows the unique region values","4ded498d":"(data[\"happiness_score\"] > 1).head(20) # We can filter the data if we want ","c45f6df7":"data[\"happiness_score\"] > 1 # We can filter the data if we want \ndata[data[\"happiness_score\"] > 1].head(20)","f03d480e":"# For example lets look frequency of region types\nprint(data[\"region\"].value_counts(dropna=False,sort=True))# if there are nan values that also be counted\n#sort : boolean, default True   =>Sort by values\n#dropna : boolean, default True =>Don\u2019t include counts of NaN.\n# As it can be seen below there are 40 Sub-Saharan Africa region or 29 Central and Eastern Europe region\n# As you can see, there are no NAN values","6c0206bc":"# For example: compare happiness_score of region\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n#Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1).     (Q3-Q1) = IQR\ndata.boxplot(column='happiness_score',by = 'region',fontsize=9,figsize=(20,20))\n\ndata2 = data[data[\"region\"]==\"Western Europe\"]\nprint(data2.happiness_score.max())\nprint(data2.happiness_score.quantile(q=0.75))\nprint(data2.happiness_score.quantile(q=0.5))\nprint(data2.happiness_score.quantile(q=0.25))\nprint(data2.happiness_score.min())\n\ndata3 = data[data[\"region\"]==\"North America\"]\nprint(data3.happiness_score.max())\nprint(data3.happiness_score.quantile(q=0.75))\nprint(data3.happiness_score.quantile(q=0.5))\nprint(data3.happiness_score.quantile(q=0.25))\nprint(data3.happiness_score.min())\n\ndata4 = data[data[\"region\"]==\"Australia and New Zealand\"]\nprint(data4.happiness_score.max())\nprint(data4.happiness_score.quantile(q=0.75))\nprint(data4.happiness_score.quantile(q=0.5))\nprint(data4.happiness_score.quantile(q=0.25))\nprint(data4.happiness_score.min())\n\ndata5 = data[data[\"region\"]==\"Latin America and Caribbean\"]\nprint(data5.happiness_score.max())\nprint(data5.happiness_score.quantile(q=0.75))\nprint(data5.happiness_score.quantile(q=0.5))\nprint(data5.happiness_score.quantile(q=0.25))\nprint(data5.happiness_score.min())\n# FINDING OUTLIERS\n#we should change the formula according to our data\n\n#FOR data2\nprint(\"max outliers=\",[x for x in data2.happiness_score if x>(data2.happiness_score.quantile(0.75)+1.5*(data2.happiness_score.quantile(0.75)-data2.happiness_score.quantile(0.25)))])\nprint(\"min outliers=\",[x for x in data2.happiness_score if x<(data2.happiness_score.quantile(0.25)-1.5*(data2.happiness_score.quantile(0.75)-data2.happiness_score.quantile(0.25)))])\nprint(\"\")\n\n#FOR data3\nprint(\"max outliers=\",[x for x in data3.happiness_score if x>(data3.happiness_score.quantile(0.75)+1.5*(data3.happiness_score.quantile(0.75)-data3.happiness_score.quantile(0.25)))])\nprint(\"min outliers=\",[x for x in data3.happiness_score if x<(data3.happiness_score.quantile(0.25)-1.5*(data3.happiness_score.quantile(0.75)-data3.happiness_score.quantile(0.25)))])\nprint(\"\")\n\n#FOR data4\nprint(\"max outliers=\",[x for x in data4.happiness_score if x>(data4.happiness_score.quantile(0.75)+1.5*(data4.happiness_score.quantile(0.75)-data4.happiness_score.quantile(0.25)))])\nprint(\"min outliers=\",[x for x in data4.happiness_score if x<(data4.happiness_score.quantile(0.25)-1.5*(data4.happiness_score.quantile(0.75)-data4.happiness_score.quantile(0.25)))])\nprint(\"\")\n\n#doing with for loop\n#FOR data5\nfor x in data5.happiness_score:\n    if x>(data5.happiness_score.quantile(0.75)+1.5*(data5.happiness_score.quantile(0.75)-data5.happiness_score.quantile(0.25))):\n       print(\"max outliers=\",x)\n    elif x<(data5.happiness_score.quantile(0.25)-1.5*(data5.happiness_score.quantile(0.75)-data5.happiness_score.quantile(0.25))):\n       print(\"min outliers=\",x)","4d05a7b7":"# Firstly I create new data from 2015 data to explain melt more easily.\ndata_new = data.head(5)    # I only take 5 rows into new data\ndata_new","33ea32f1":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new, id_vars = \"country\",value_vars=[\"economy\",\"health\"])\nmelted","5708ad34":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index=\"country\", columns = \"variable\", values=\"value\")","7e7d5029":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2 = data.tail()\nv_concat = pd.concat([data1,data2],axis=0,ignore_index=True)# axis = 0 : adds dataframe\nv_concat","8a351bb3":"data1 = data.country.head()\ndata2 = data.happiness_score.head()\nh_concat = pd.concat([data1,data2], axis=1)\nh_concat","fa7dcca9":"data.info()","3e76a417":"data1 = data.country.head(10)\ndata2 = data.happiness_score.head(10)\ndata3 = data.trust.head(10)\ndata4 = data.region.head(10)\nh_concat = pd.concat([data4+\" - \"+data1,data2,data3], axis=1)\nh_concat","4923d275":"data.dtypes","26e0c7b0":"#lets convert object(str) to categorical and float to int.\n#DONT forget ,Setting return back default setting to int\n#data[\"region\"] = data[\"region\"].astype(\"category\")\n#data.freedom = data.freedom.astype(\"int\")\n#data.freedom[0:10] #as you see it is converted from int to float","498265b3":"# As you can see region is converted from object to categorical\n# And freedom is converted from float to int\ndata.dtypes","bb0226ea":"data = pd.read_csv(\"..\/input\/2015.csv\")\ndata.rename(columns={\"Economy (GDP per Capita)\":\"economy\",\"Health (Life Expectancy)\":\"health\",\"Trust (Government Corruption)\":\"Trust\"}, inplace=True)\ndata.columns = [each.replace(\" \",\"_\") if(len(each.split())>1) else each for each in data.columns]\ndata.columns = [each.lower() for each in data.columns]\nprint(data.columns)\n\ndata2 = data.copy(deep=True)\ndata2[\"region\"][4:8] = np.nan\ndata2","9b95e6de":"# Lets chech happiness_score\ndata2[\"region\"].value_counts(dropna =False)\n# As you can see, there are 4 NAN value","8a49fc22":"# Lets drop nan values\n# also we will use data to fill missing value\ndata2[\"region\"].dropna(inplace = True)\ndata2","5d744bb9":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","4702eef9":"#In order to run all code, we need to make this line comment\n#assert 1==2 # return error because it is false","59eabf0e":"assert  data2['region'].notnull().all() # returns nothing because we drop nan values","653aa358":"data2[\"region\"].fillna(\"empty\",inplace = True)\ndata2 \n#you can not assign empty values after delete nan values\n#if you want to assign empty values firstly make that! after import csv file","1d4043c7":"# # With assert statement we can check a lot of thing. For example\nassert data2.columns[1] == \"region\"\nassert data2.happiness_score.dtype == \"float\"\n#OR\nassert data2.region.dtype == \"object\"\nassert data2.happiness_score.dtype == \"float64\"\nprint(data2.happiness_score.dtypes)","f19a2cab":"country = [\"Turkey\",\"France\"]\npopulation = [\"1000\",\"2000\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nprint(list_col)\nzipped = list(zip(list_label,list_col))\nprint(zipped)\ndata_dict = dict(zipped)\nprint(data_dict)\ndf = pd.DataFrame(data_dict)\ndf","69a6d0c6":"df[\"capital\"]=[\"madrid\",\"paris\"]\ndf","a7ae040f":"df[\"income\"] = 0\ndf","e9a04f55":"# Plotting all data \ndata1 = data.loc[:,[\"happiness_score\",\"freedom\",\"health\"]]\ndata1.plot()\n# SAME THING\n#data.happiness_score.plot()\n#data.freedom.plot()\n#data.health.plot()","2c30376f":"# subplots\ndata1.plot(subplots = True)\nplt.show()","c1791063":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"freedom\",y = \"health\")\nplt.show()","ae0d99ba":"# hist plot  \ndata1.happiness_score.plot(kind =\"hist\",range= (0,10),bins=50)\nplt.show()","38d6d9a2":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"happiness_score\",color=\"orange\",bins = 50,range= (0,10),ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"happiness_score\",color=\"green\",bins = 50,range= (0,10),ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt.show()","3a448d8d":"# In order to practice lets take head of 2015.csv data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\n#OR\n#data2.set_index(\"date\",inplace=True)\ndata2 ","1dfe3284":"#b\u00fct\u00fcn columnlar\u0131 ve rowlar\u0131 g\u00f6sterir.\npd.set_option(\"display.max_columns\",None) \npd.set_option(\"display.max_rows\",None)\n\n# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"]) #print(data2.loc[\"1993-03-16\",:]) same thing\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","1ccb8df8":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean() #y\u0131ldan y\u0131la featurelar\u0131n kendi i\u00e7inde ortalamas\u0131","f29842aa":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","3cec4343":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","b3fca4c2":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","c17d3043":"data1 = data.head(10)\ndata1","c0bc5fff":"# indexing using square brackets\ndata1[\"happiness_rank\"][1]","9847ef14":"# using column attribute and row label\ndata1.happiness_rank[1]","e22653e2":"# using loc accessor\ndata1.loc[2,[\"happiness_rank\"]]","09aee7b5":"# Selecting only some columns\ndata1[[\"happiness_rank\"]]","36639a79":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"freedom\"]))     # series\nprint(type(data[[\"freedom\"]]))   # data frames","20b27472":"# Slicing and indexing series\ndata.loc[1:10,\"health\":\"generosity\"]   # 10 and \"Defense\" are inclusive","e5b1c01f":"# Reverse slicing \na =data.loc[10:1:-1,\"generosity\":\"health\":-1] \na","6c1ca76a":"# From something to end\ndata.loc[1:10,\"trust\":] ","3e4d14d9":"# Creating boolean series\nboolean = data.health > 0.95\ndata[boolean]","47eb06b2":"# Combining filters\nfirst_filter = data.family > .95\nsecond_filter = data.health > .95\ndata[np.logical_and(first_filter,second_filter)]\n#OR\n#data[np.logical_and(first_filter,second_filter)]","06046a09":"# Filtering column based others\ndata.country[data.happiness_score>7]","cd67c6dd":"# Filtering column based others\ndata[[\"freedom\"]][data.happiness_score>7]","c56bc245":"# Filtering column based others\na = data[data.happiness_score>7]\na[[\"trust\"]]","96a16827":"# Plain python functions\ndef div(n):\n    return n\/2\ndata[\"new_happiness_score\"]=data.happiness_score.apply(div)\ndata","ebe5ce0d":"data[\"new_happiness_score\"] = data.happiness_score.apply(lambda hp : hp\/2)\ndata","e8c268ae":"# Defining column using other columns\ndata[\"new_total_happiness_score\"] = data.trust + data.economy\ndata.head()","a2fa31a1":"# our index name is this:\nprint(data.index.name)\n#lets change it\ndata.index.name = \"index_name\"\ndata.head()","de3ca229":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index\ndata2 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata2.index = range(100,258,1)#100 exclusive->258\ndata2.tail()","a483c4d3":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"happiness_rank\")\n# also you can use \ndata.index = data[\"happiness_rank\"]\ndata.index = data[\"freedom\"]\ndata.index = data[\"happiness_rank\"]\ndata.head()\n#with using set_index means make index happiness_rank and you can not back it as a column\n#but if we using data[\"happiness_rank\"] series we can use that feature as index and feature","b9a0971e":"# Setting index : region is outer country is inner index\ndata1 = data.set_index([\"region\",\"country\"]) \ndata1","6653a952":"data1.loc[[\"Western Europe\"]] # how to use indexes","bbdf447d":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","58e692ed":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","e8ddc58f":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n#OR\n#df1 = df.set_index([\"gender\",\"treatment\"])","7cbd8925":"# lets unstack it\n# level determines indexes\ndf1.unstack(level=0)","9cc79774":"df1.unstack(level=1)","4feef9c5":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","bbb34946":"df","74c37116":"pd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","32a52711":"data = pd.read_csv(\"..\/input\/2015.csv\")\ndata.rename(columns={\"Economy (GDP per Capita)\":\"economy\",\"Health (Life Expectancy)\":\"health\",\"Trust (Government Corruption)\":\"Trust\"}, inplace=True)\ndata.columns = [each.replace(\" \",\"_\") if(len(each.split())>1) else each for each in data.columns]\ndata.columns = [each.lower() for each in data.columns]\ndata.head()","a84f8f0f":"data.groupby(\"region\").count()","0ec99c6e":"data.groupby(\"region\").country.count()","b2aedeef":"data.groupby(\"region\").country.count().sum()","af1fecfc":"data.groupby(\"region\").country.count().sort_values(ascending=False)","2730c52d":"#let find North America counts\ndata[data[\"region\"]==\"North America\"].region.count()","f1b4ff68":"data.groupby(\"region\").country.count().sort_values(ascending=False).plot(kind=\"line\")\nplt.show()","c25ec6f5":"data.groupby(\"region\").country.count().sort_values(ascending=False).plot(kind=\"bar\")\nplt.show()","a1fee832":"data.groupby(\"region\").country.count().sort_values(ascending=False).plot(kind=\"hist\",bins=50)\nplt.show()","ce9e97dd":"data.groupby(\"region\").country.count().sort_values(ascending=False).plot(kind=\"box\")\nplt.show()","1280aedc":"data.groupby(\"region\").country.count().sort_values(ascending=False).plot(kind=\"area\")\nplt.show()","3aa4e691":"data.groupby(\"region\").country.count().sort_values(ascending=False).plot(kind=\"pie\")\nplt.show()","7703774f":"# according to region take means of other features\ndata.groupby(\"region\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","c4e163e6":"# we can only choose one of the feature\ndata.groupby(\"region\").happiness_score.mean() \n#OR\n#df.groupby(\"region\")[[\"happiness_score\"]].mean() ","46d6ac70":"data.groupby(\"region\").mean().sort_values(\"happiness_score\",ascending=False)","d5f47a1d":"# we can only choose one of the feature\ndata.groupby(\"region\").happiness_score.max()","f37d3a2c":"# Or we can choose multiple features\ndata.groupby(\"region\")[[\"happiness_score\",\"economy\"]].mean()","adaff1fd":"data.groupby(\"region\")[[\"happiness_score\"]].mean() ","d81822d2":"**Filtering Data**","d9d74118":"<a id=\"9\"><\/a> <br>\n### SCOPE\nWhat we need to know about scope:\n* global: defined main body in script\n* local: defined in a function\n* built in scope: names in predefined built in scope module such as print, len\n<br><br>Lets make some basic examples","2d21ca6b":"<a id=\"6\"><\/a> <br>\n### WHILE and FOR LOOPS\nWe will learn most basic while and for loops","655ec112":"<a id=\"8\"><\/a> <br>\n### USER DEFINED FUNCTION\nWhat we need to know about functions:\n* docstrings: documentation for functions. Example:\n<br>for f():\n    <br>\"\"\"This is docstring for documentation of function f\"\"\"\n* tuble: sequence of immutable python objects. \n<br>cant modify values\n<br>tuple uses paranthesis like tuple = (1,2,3)\n<br>unpack tuple into several variables like a,b,c = tuble\n    ","dc6f4b9e":"<a id=\"21\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","b2d93f10":"<a id=\"13\"><\/a> <br>\n### ANONYMOUS FUNCT\u0130ON\nLike lambda function but it can take more than one arguments.\n* map(func,seq) : applies a function to all the items in a list\n","2f5c0793":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","a8a17fcd":"<a id=\"7\"><\/a> <br>\n# 2. PYTHON DATA SCIENCE TOOLBOX\n","c3d763ec":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","9ccf2673":"<a id=\"37\"><\/a> <br>\n### INDEX OBJECTS AND LABELED DATA\nindex: sequence of label\n","8d111bbd":"<a id=\"35\"><\/a> <br>\n### FILTERING DATA FRAMES\nCreating boolean series\nCombining filters\nFiltering column based others","5a4f893f":"<a id=\"34\"><\/a> <br>\n### SLICING DATA FRAME\n* Difference between selecting columns\n* Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end","39e69424":"<a id=\"39\"><\/a> <br>\n### PIVOTING DATA FRAMES\n* pivoting: reshape tool","b76f9e63":"<a id=\"1\"><\/a> <br>\n# 1. INTRODUCTION TO PYTHON","4af4af32":"<a id=\"16\"><\/a> <br>\n# 3.CLEANING DATA","91c6a017":"Up to now, you learn \n* User defined function \n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n*  Anonymous function\n*  Iterators\n* List comprehension","6cead877":"**Content:**\n1. [Introduction to Python:](#1)\n    1. [Matplotlib](#2)\n    1. [Dictionaries ](#3)\n    1. [Pandas](#4)\n    1. [Logic, control flow and filtering](#5)\n    1. [Loop data structures](#6)\n1. [Python Data Science Toolbox:](#7)\n    1. [User defined function](#8)\n    1. [Scope](#9)\n    1. [Nested function](#10)\n    1. [Default and flexible arguments](#11)\n    1. [Lambda function](#12)\n    1. [Anonymous function](#13)\n    1. [Iterators](#14)\n    1. [List comprehension](#15)\n1. [Cleaning Data](#16)\n    1. [Diagnose data for cleaning](#17)\n    1. [Exploratory data analysis](#18)\n    1. [Visual exploratory data analysis](#19)\n    1. [Tidy data](#20)\n    1. [Pivoting data](#21)\n    1. [Concatenating data](#22)\n    1. [Data types](#23)\n    1. [Missing data and testing with assert](#24)\n1. [Pandas Foundation](#25)\n    1. [Review of pandas](#26)\n    1. [Building data frames from scratch](#27)\n    1. [Visual exploratory data analysis](#28)\n    1. [Statistical explatory data analysis](#29)\n    1. [Indexing pandas time series](#30)\n    1. [Resampling pandas time series](#31)\n1. [Manipulating Data Frames with Pandas](#32)\n    1. [Indexing data frames](#33)\n    1. [Slicing data frames](#34)\n    1. [Filtering data frames](#35)\n    1. [Transforming data frames](#36)\n    1. [Index objects and labeled data](#37)\n    1. [Hierarchical indexing](#38)\n    1. [Pivoting data frames](#39)\n    1. [Stacking and unstacking data frames](#40)\n    1. [Melting data frames](#41)\n    1. [Categoricals and groupby](#42)","696f97b6":"<a id=\"17\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data\n","dfbffdce":"<a id=\"2\"><\/a> <br>\n### MATPLOTLIB\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle  ","dc838f53":"<a id=\"40\"><\/a> <br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","6eedc3bb":"**zip(): zip lists**","3f3d8ddd":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","bc072b5b":"<a id=\"5\"><\/a> <br>\nBefore continue with pandas,   we need to learn **logic, control flow** and **filtering.**\n<br>Comparison operator:  ==, <, >, <=\n<br>Boolean operators: and, or ,not\n<br> Filtering pandas","2fe87619":"<a id=\"26\"><\/a> <br>\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","4e1ce6f3":"<a id=\"41\"><\/a> <br>\n### MELTING DATA FRAMES\n* Reverse of pivoting","105a4217":"<a id=\"14\"><\/a> <br>\n### ITERATORS\n* iterable is an object that can return an iterator\n* iterable: an object with an associated iter() method\n<br> example: list, strings and dictionaries\n* iterator: produces next value with next() method","b72f12f6":"### PANDAS\nWhat we need to know about pandas?\n* CSV: comma - separated values","3cb83e6c":"<a id=\"10\"><\/a> <br>\n### NESTED FUNCTION\n* function inside function.\n* There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively.","5ca7eaba":"<a id=\"33\"><\/a> <br>\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","0e80d0a2":"Standard Error: The standard error of the happiness score.\n\nEconomy (GDP per Capita): The extent to which GDP contributes to the calculation of the Happiness Score.\n\nFamily: The extent to which Family contributes to the calculation of the Happiness Score\n\nHealth (Life Expectancy): The extent to which Life expectancy contributed to the calculation of the Happiness Score.\n\nFreedom: The extent to which Freedom contributed to the calculation of the Happiness Score.\n\nTrust (Government Corruption): The extent to which Perception of Corruption contributes to Happiness Score.\n\nGenerosity: The extent to which Generosity contributed to the calculation of the Happiness Score.\n\nDystopia Residual: The extent to which Dystopia Residual contributed to the calculation of the Happiness Score.\n","113379fd":"<a id=\"23\"><\/a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)","deeb529a":"<a id=\"11\"><\/a> <br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n* Default argument example:\n<br> def f(a, b=1):\n        \"\"\" b = 1 is default argument\"\"\"\n* Flexible argument example:\n<br> def f(*args):\n       \"\"\" *args can be one or more\"\"\"\n<br>def f(** kwargs)\n       \"\"\" **kwargs is a dictionary\"\"\"\n       \n<br><br> lets write some code to practice  ","63eaf3ff":"<a id=\"22\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe ","d7bdf236":"<a id=\"3\"><\/a> <br>\n### DICTIONARY\nWhy we need dictionary?\n* It has 'key' and 'value'\n* Faster than lists\n<br>\nWhat is key and value. Example:\n* dictionary = {'spain' : 'madrid'}\n* Key is spain.\n* Values is madrid.\n<br>\n<br>**It's that easy.**\n<br>Lets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary.","084a2d89":"[i + 1 for i in num1 ]: list of comprehension\n<br> i +1: list comprehension syntax\n<br> for i in num1: for loop syntax\n<br> i: iterator\n<br> num1: iterable object","1e7de4d1":"<a id=\"15\"><\/a> <br>\n### LIST COMPREHENS\u0130ON\n**One of the most important topic of this kernel**\n<br>We use list comprehension for data analysis often. \n<br> list comprehension: collapse for loops for building lists into a single line\n<br>Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is  unnecessarily long. We can make it one line code that is list comprehension.","f93947a4":"<a id=\"20\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it.\n","00a83513":"<a id=\"28\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","d4693466":"<a id=\"25\"><\/a> <br>\n# 4. PANDAS FOUNDATION ","5596cb2f":"# DATA SCIENTIST\n\n**In this tutorial,I only will show you the first steps to be a data scientist using python.**","10757755":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","f8fd8ccc":"<a id=\"36\"><\/a> <br>\n### TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","51d267ec":"<a id=\"31\"><\/a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html\n","4c93c0c9":"<a id=\"32\"><\/a> <br>\n# MANIPULATING DATA FRAMES WITH PANDAS","581ed9b1":"<a id=\"27\"><\/a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","62881b05":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing"}}