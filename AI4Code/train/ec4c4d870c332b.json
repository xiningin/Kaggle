{"cell_type":{"6a745f63":"code","7064351e":"code","3e427f22":"code","c68b30ac":"code","b801d81c":"code","d82bfa68":"code","01c96202":"code","284f5403":"code","19d9db7b":"code","72d6a1e2":"markdown","45d4b0e0":"markdown","3f4cef24":"markdown","24eb3c8f":"markdown","d405975e":"markdown","0fd0071f":"markdown","10485f32":"markdown","db8190fc":"markdown","5c31a4df":"markdown","e4f0a6c4":"markdown","8238d0a8":"markdown","aaca625d":"markdown","c3862605":"markdown","8fbbd748":"markdown","1f6d3043":"markdown","d21eae1a":"markdown","85e977f9":"markdown","97870534":"markdown","a7b730cc":"markdown","3b13ecf1":"markdown"},"source":{"6a745f63":"#Importing Libraries\nimport numpy as np\nimport pandas as pd\n\n#For visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nfrom matplotlib.cm import rainbow\n\n#Importing sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n\n\n#reading data\ndf=pd.read_csv(\"..\/input\/spam.csv\", encoding='latin-1')","7064351e":"#making ham=0,spam=1 used as target matrix in label_num column\ndf['v1'] = df.v1.map({'ham':0,'spam':1})\nfeatures = df[\"v2\"]\nlabels=df[\"v1\"]\n\n\n#plotting data\nsns.countplot(df[\"v1\"])\nprint(plt.show())","3e427f22":"#spliting training and testing data\nf_train,f_test,l_train,l_test= train_test_split(features,labels,test_size=.1)\nf_train=np.array(f_train)\nf_test=np.array(f_test)\nl_train=np.array(l_train)\nl_test=np.array(l_test)\n\n\n#Inorder to train model we need to convert text to appropriate numerical values using vetorization\nvect = CountVectorizer()\nf_train_count = vect.fit_transform(f_train)\nf_test_count= vect.transform(f_test)\ntrans = TfidfTransformer()","c68b30ac":"#DecisionTree Algorithm\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifier1 = DecisionTreeClassifier(criterion = 'entropy', random_state =0)\nclassifier1.fit(f_train_count,l_train)\nprint(\"\\n\\n\\033[1;32;40m [+]train score: \",classifier1.score(f_train_count,l_train))\nprint(\"\\n\\n[+]test score:  \",classifier1.score(f_test_count,l_test))\ny_pred1 = classifier1.predict(f_train_count)\nscDT = classifier1.score(f_test_count,l_test)\nprint(\"\\n\\n[+]accuracy score of DecisionTree Algorithm= \" ,scDT)","b801d81c":"#KNeighbors Algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclassifier2 = KNeighborsClassifier(n_neighbors =2, metric ='minkowski', p=2)\nclassifier2.fit(f_train_count,l_train)\nprint(\"\\n\\n\\033[1;32;40m [+]train score: \",classifier2.score(f_train_count,l_train))\nprint(\"\\n\\n[+]test score:  \",classifier2.score(f_test_count,l_test))\ny_pred2 = classifier2.predict(f_train_count)\nscKNN = classifier2.score(f_test_count,l_test)\nprint(\"\\n\\n[+]accuracy score of KNeighbors Algorithm = \" ,scKNN)","d82bfa68":"#RandomForest Algorithm\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier3 = RandomForestClassifier(n_estimators = 55,criterion = 'entropy', random_state =0)\nclassifier3.fit(f_train_count,l_train)\nprint(\"\\n\\n\\033[1;32;40m [+]train score: \",classifier3.score(f_train_count,l_train))\nprint(\"\\n\\n[+]test score:  \",classifier3.score(f_test_count,l_test))\ny_pred3 = classifier3.predict(f_train_count)\nscRF = classifier3.score(f_test_count,l_test)\nprint(\"\\n\\n[+]accuracy score of RandomForest Algorithm = \" ,scRF)","01c96202":"#Naive_Bayes Algorithm\nfrom sklearn.naive_bayes import MultinomialNB\n\nclassifier4 = MultinomialNB()\nclassifier4.fit(f_train_count,l_train)\nprint(\"\\n\\n\\033[1;32;40m [+]train score: \",classifier4.score(f_train_count,l_train))\nprint(\"\\n\\n[+]test score:  \",classifier4.score(f_test_count,l_test))\ny_pred4 = classifier4.predict(f_test_count)\nscNB = accuracy_score(l_test,y_pred4)\n#precision_score = precision_score(l_test,y_pred4)\n#recall_score = recall_score(l_test,y_pred4)\n#f1_score = f1_score(l_test,y_pred4)\nprint(\"\\n\\n[+]accuracy score of Naive_Bayes Algorithm = \" ,scNB)\nreport = classification_report(y_pred4,l_test)\nprint(\"\\n\",report)","284f5403":"#Plotting seaborn comapritive Accuracies Graph \nscores = [scDT,scKNN,scRF,scNB]\nalgorithms = [\"Decision Tree\",\"KNeighbors\",\"RandomForest\",\"Naive Bayes\"] \nsns.set(rc={'figure.figsize':(15,8)})\nplt.xlabel(\"Algorithms\")\nplt.ylabel(\"Accuracy Score\")\n\nsns.barplot(algorithms,scores)","19d9db7b":"#Testing HAM and SPAM Predection SMS\nprint(\"\\n\\n[+] lets test whether SMS is HAM or SPAM: \") \nt=['hello']\nt=np.array(t)\nt=vect.transform(t)\nprediction = classifier4.predict(t)\nif prediction == 0:\n    print(\"HAM!\")\nelse:\n    print(\"\\033[1;31;40m [+]SPAM!\")","72d6a1e2":"**The score for Random Forest Classifier is 96.4%**","45d4b0e0":"# Loading & Pre-processing Data\n\nNow by splitting train and test data i.e features and labels are trained and tested.. f_train, f_test and l_train, l_test. Firstly after splitting test test features, convert into array form.\n\nInorder to train model we need to convert text to appropriate numerical values using vetorization. Need to do fit transform features that are trained.","3f4cef24":"Accuracies plotted for all algorithms comparison..","24eb3c8f":"Thus according to SMS what we have typed in user input, it will make prediction and provide a resultant output whether **HAM or SPAM**.\nHere is the [Github](https:\/\/github.com\/EpuriHarika\/NLP-Concepts\/tree\/master\/Spam_Detection_NLP_Text_Classification\/) Repo Link for this article. And also checkout my other repo [NLP-concepts](https:\/\/github.com\/EpuriHarika\/NLP-Concepts\/) on github.","d405975e":"**Data generated** from conversations, declarations or even tweets are examples of unstructured data. **Unstructured data** doesn\u2019t fit neatly into the traditional row and column structure of relational databases, and represent the vast majority of data available in the actual world.\n\n","0fd0071f":"Adding Algorithms to predict the features train, and find the accuracy based of features train to labels tested..","10485f32":"**Predicting SMS:** Predicting Ham Or Spam based on training and test models..","db8190fc":"![whole%20nlp%20pic.jpg](attachment:whole%20nlp%20pic.jpg)","5c31a4df":"# Decision Tree Algorithm","e4f0a6c4":"So, Lets try Spam Detection project using Python,\nImporting Libraries...","8238d0a8":"**The score for Naive-Bayes Classifier is around 98%**","aaca625d":"# Naive Bayes Algorithm ","c3862605":"**The score for Decision Tree Classifier is 96.2%**","8fbbd748":"# KNeighbors Algorithm","1f6d3043":"**The score for K Neighbors Classifier is 91%**","d21eae1a":"# Text Classification\n\nText classification also known as text tagging or text categorization is the process of categorizing text into organized groups. By using Natural Language Processing (NLP), text classifiers can automatically analyze text and then assign a set of pre-defined tags or categories based on its content.\n\n![text%20classification.png](attachment:text%20classification.png)","85e977f9":"Please do connect with me on [Linkedin](https:\/\/www.linkedin.com\/in\/harika-epuri-121b7412b\/), [Facebook](https:\/\/www.facebook.com\/harika.jds), [Instagram ](https:\/\/www.instagram.com\/epuriharika\/)and [Tumblr](https:\/\/www.tumblr.com\/blog\/harikaepuri).\nHope you enjoyed this kernel. I welcome your comments. If you like this kernel please make a upvote. Thankyou.\n**Happy Learning :)**","97870534":"# Natural language Processing \n\nNatural Language Processing or NLP is a field of Artificial Intelligence that gives the machines the ability to read, understand and derive meaning from human languages.\n\n![nltk%20py.jpg](attachment:nltk%20py.jpg)\n\nNLP concepts include like:\n\n* NLTK Tokenizer\n\n* NLTK StopWords\n\n* NLTK Parts Of Speech(POS)\n\n* NLTK Stemming\n\n* NLTK Lemmatization\n\n* NLTK Named Entity Recognition\n\n* NLTK Chunking\n\n* NLTK Wordnet\n\n\nThis project helps you in understanding how to do NLP text classification.","a7b730cc":"# Random Forest Algorithm","3b13ecf1":"Ham and Spam comparison barplot plotting image.."}}