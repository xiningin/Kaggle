{"cell_type":{"94c52036":"code","4f5eefb2":"code","74548989":"code","335b4129":"code","9e44247a":"code","aa45721a":"code","f1d014b9":"code","db409679":"code","8685c224":"code","8b96210c":"code","d88d1943":"code","45015728":"code","01c675e0":"code","04ce5341":"code","8ad82976":"code","572a03fa":"code","9fc117ca":"code","2238fa34":"code","bc114e9e":"code","ed11744b":"code","7c418add":"code","2698d098":"code","b283f367":"code","649f6a4a":"code","32a2108d":"code","a769da03":"code","f2f5985d":"code","ad877a17":"code","e7d43ad3":"code","dda99b37":"code","1fdaee40":"code","85d96beb":"code","7210c472":"code","90de7586":"code","6b3502d4":"code","ace7ce4a":"code","669346f2":"code","9c34faeb":"code","3631ca15":"code","0d6bd772":"code","71715ed3":"code","4489766d":"code","b45d5fec":"code","35a4472a":"code","a0f2f241":"code","4b1a0871":"code","7429a1b5":"code","13a5cdca":"code","2a11eabf":"code","92987d8a":"code","cfde5fcf":"code","8587ce1d":"code","e1387235":"code","5b1e9f6e":"code","fd88b2b1":"code","ddcfcad3":"code","27529f05":"code","a163044f":"code","51a5873a":"code","50861188":"code","c0489002":"code","6dad12cb":"markdown","a823d4a0":"markdown","fd395102":"markdown","8bf14b6c":"markdown","adfef70c":"markdown","9458d250":"markdown","5bbd936e":"markdown","8abd6f07":"markdown","25080b90":"markdown","7b18bc55":"markdown","bd44cf56":"markdown","4b08041b":"markdown","18c327e8":"markdown","1174076a":"markdown","910cbe60":"markdown","029ed9a6":"markdown","566fe651":"markdown","a7a14252":"markdown","eb941da7":"markdown"},"source":{"94c52036":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport pandas.plotting as plt2\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve, auc","4f5eefb2":"data = pd.read_csv('..\/input\/pima-indians-diabetes\/pima-indians-diabetes.csv',names=['Pregnancies','Glucose',\n    'BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome'])\ndata.head()","74548989":"Features = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\nprint('Missing values :')\nfor values in data[Features]:\n    print(values + '=' + str(data[values][data[values]==0].count()))","335b4129":"for values in data.drop('Outcome',axis=1):\n    plt.hist(data[values])\n    plt.title(values)\n    plt.show()","9e44247a":"data.dtypes","aa45721a":"VariableDType = pd.DataFrame(data.dtypes.value_counts(),columns=['Count of Variable'])","f1d014b9":"VariableDType","db409679":"plt.bar(['Integer','Float'],VariableDType['Count of Variable'])\nplt.xlabel('Variable Datatype')\nplt.ylabel('Count of variable')\nplt.title('Frequency plot describing the data types and the count of variables')","8685c224":"def median_target(var):   \n    temp = data[data[var]!=0]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp","8b96210c":"median_target('Glucose')","d88d1943":"data.loc[(data['Outcome'] == 0 ) & (data['Glucose']==0), 'Glucose'] = 107\ndata.loc[(data['Outcome'] == 1 ) & (data['Glucose']==0), 'Glucose'] = 140","45015728":"median_target('BloodPressure')","01c675e0":"data.loc[(data['Outcome'] == 0 ) & (data['BloodPressure']==0), 'BloodPressure'] = 70.0\ndata.loc[(data['Outcome'] == 1 ) & (data['BloodPressure']==0), 'BloodPressure'] = 74.5","04ce5341":"median_target('SkinThickness')","8ad82976":"data.loc[(data['Outcome'] == 0 ) & (data['SkinThickness']==0), 'SkinThickness'] = 27\ndata.loc[(data['Outcome'] == 1 ) & (data['SkinThickness']==0), 'SkinThickness'] = 32","572a03fa":"median_target('Insulin')","9fc117ca":"data.loc[(data['Outcome'] == 0 ) & (data['Insulin']==0), 'Insulin'] = 102.5\ndata.loc[(data['Outcome'] == 1 ) & (data['Insulin']==0), 'Insulin'] = 169.5","2238fa34":"median_target('BMI')","bc114e9e":"data.loc[(data['Outcome'] == 0 ) & (data['BMI']==0), 'BMI'] = 30.1\ndata.loc[(data['Outcome'] == 1 ) & (data['BMI']==0), 'BMI'] = 34.3","ed11744b":"f,ax = plt.subplots(1,2,figsize=(15,5))\ndata['Outcome'].value_counts().plot.pie(ax=ax[0],autopct='%1.1f%%',explode=[0,.1])\nsns.countplot('Outcome',data=data,ax=ax[1])","7c418add":"sns.pairplot(data,hue='Outcome')","2698d098":"plt.figure(figsize=(15,10))\nsns.heatmap(data.corr(),annot=True,cmap='Blues',fmt='.2f',linewidth=2)","b283f367":"X = data.drop('Outcome',axis=1)\nY = data.Outcome","649f6a4a":"# Data standardization\nsc = StandardScaler()\nsc.fit(X)\n\nX_std = pd.DataFrame(sc.transform(X),columns=X.columns)\nX_std","32a2108d":"Xtrain,Xtest,Ytrain,Ytest = train_test_split(X_std,Y,test_size=0.25,random_state=0)\nprint('\\nDimension of Xtrain :',Xtrain.shape)\nprint('\\nDimension of Xtest :',Xtest.shape)\nprint('\\nDimension of Ytrain :',Ytrain.shape)\nprint('\\nDimension of Ytest :',Ytest.shape)","a769da03":"from sklearn.ensemble import RandomForestClassifier\nRFCfr = RandomForestClassifier()","f2f5985d":"RFCfr.fit(Xtrain,Ytrain)","ad877a17":"Ypred = RFCfr.predict(Xtest)","e7d43ad3":"cm1 = confusion_matrix(Ytest,Ypred)","dda99b37":"print(classification_report(Ytest,Ypred))","1fdaee40":"print('Confusion matrix :','\\n',cm1)\n\nprint('\\nAccuracy :',accuracy_score(Ytest,Ypred))\n\nprint('\\nSensitivity : ', cm1[0,0]\/(cm1[0,0]+cm1[0,1]) )\n \nprint('\\nSpecificity : ', cm1[1,1]\/(cm1[1,0]+cm1[1,1]))","85d96beb":"train_rfc_probabilities = RFCfr.predict_proba(Xtrain)[:,1]\ntrain_rfc_fpr, train_rfc_tpr, train_rfc_thershold = roc_curve(Ytrain, train_rfc_probabilities)\n\ntest_rfc_probabilities = RFCfr.predict_proba(Xtest)[:,1]\ntest_rfc_fpr, test_rfc_tpr, test_rfc_thershold = roc_curve(Ytest, test_rfc_probabilities)","7210c472":"plt.plot(train_rfc_fpr, train_rfc_tpr, label='Train')\nplt.plot(test_rfc_fpr, test_rfc_tpr, label='Test')\n\nplt.plot([0,1],[0,1], color='black',linestyle='--')\n\nplt.xlabel('False positive rate - FPR')\nplt.ylabel('True positive rate - TPR')\nplt.legend()\nplt.title('Receiver operating characteristics - ROC Curve')","90de7586":"from sklearn.svm import SVC\nsvc=SVC(random_state=0, kernel='rbf',probability=True)","6b3502d4":"svc.fit(Xtrain,Ytrain)","ace7ce4a":"Ypred2 = svc.predict(Xtest)","669346f2":"cm2 = confusion_matrix(Ytest,Ypred2)","9c34faeb":"print(classification_report(Ytest,Ypred2))","3631ca15":"print('Confusion matrix :','\\n',cm2)\n\nprint('\\nAccuracy :',accuracy_score(Ytest,Ypred2))\n\nprint('\\nSensitivity : ', cm2[0,0]\/(cm2[0,0]+cm2[0,1]) )\n \nprint('\\nSpecificity : ', cm2[1,1]\/(cm2[1,0]+cm2[1,1]))","0d6bd772":"train_svc_probabilities = svc.predict_proba(Xtrain)[:,1]\ntrain_svc_fpr, train_svc_tpr, train_svc_thershold = roc_curve(Ytrain, train_svc_probabilities)\n\ntest_svc_probabilities = svc.predict_proba(Xtest)[:,1]\ntest_svc_fpr, test_svc_tpr, test_svc_thershold = roc_curve(Ytest, test_svc_probabilities)","71715ed3":"plt.plot(train_svc_fpr, train_svc_tpr, label='Train')\nplt.plot(test_svc_fpr, test_svc_tpr, label='Test')\n\nplt.plot([0,1],[0,1], color='black',linestyle='--')\n\nplt.xlabel('False positive rate - FPR')\nplt.ylabel('True positive rate - TPR')\nplt.legend()\nplt.title('Receiver operating characteristics - ROC Curve')","4489766d":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()","b45d5fec":"gnb.fit(Xtrain,Ytrain)","35a4472a":"Ypred3 = gnb.predict(Xtest)","a0f2f241":"cm3 = confusion_matrix(Ytest,Ypred3)","4b1a0871":"print(classification_report(Ytest,Ypred3))","7429a1b5":"print('Confusion matrix :','\\n',cm3)\n\nprint('\\nAccuracy :',accuracy_score(Ytest,Ypred3))\n\nprint('\\nSensitivity : ', cm3[0,0]\/(cm3[0,0]+cm3[0,1]) )\n \nprint('\\nSpecificity : ', cm3[1,1]\/(cm3[1,0]+cm3[1,1]))","13a5cdca":"train_gnb_probabilities = gnb.predict_proba(Xtrain)[:,1]\ntrain_gnb_fpr, train_gnb_tpr, train_gnb_thershold = roc_curve(Ytrain, train_gnb_probabilities)\n\ntest_gnb_probabilities = svc.predict_proba(Xtest)[:,1]\ntest_gnb_fpr, test_gnb_tpr, test_gnb_thershold = roc_curve(Ytest, test_gnb_probabilities)","2a11eabf":"plt.plot(train_gnb_fpr, train_gnb_tpr, label='Train')\nplt.plot(test_gnb_fpr, test_gnb_tpr, label='Test')\n\nplt.plot([0,1],[0,1], color='black',linestyle='--')\n\nplt.xlabel('False positive rate - FPR')\nplt.ylabel('True positive rate - TPR')\nplt.legend()\nplt.title('Receiver operating characteristics - ROC Curve')","92987d8a":"df = {}\nN = []\nac = []\nfor  i in range(1,100):\n    from sklearn.neighbors import KNeighborsClassifier\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(Xtrain,Ytrain)\n    Y_pred = knn.predict(Xtest)\n    \n    N.append(i)\n    ac.append(roc_auc_score(Ytest,Y_pred))\n    df.update({'K':N})\n    df.update({'ROC_ACC':ac})\n    \n    df1 = pd.DataFrame(df)\n    df1.sort_values('ROC_ACC',ascending=False,inplace=True,ignore_index=True)\n    \ndf1.head(10)","cfde5fcf":"## Selecting \u2018K = 11\u2019\nknn = KNeighborsClassifier(n_neighbors=11)","8587ce1d":"knn.fit(Xtrain,Ytrain)","e1387235":"Ypred4 = knn.predict(Xtest)","5b1e9f6e":"cm4 = confusion_matrix(Ytest,Ypred4)","fd88b2b1":"print(classification_report(Ytest,Ypred4))","ddcfcad3":"print('Confusion matrix :','\\n',cm4)\n\nprint('\\nAccuracy :',accuracy_score(Ytest,Ypred4))\n\nprint('\\nSensitivity : ', cm4[0,0]\/(cm4[0,0]+cm4[0,1]) )\n \nprint('\\nSpecificity : ', cm4[1,1]\/(cm4[1,0]+cm4[1,1]))","27529f05":"train_knn_probabilities = knn.predict_proba(Xtrain)[:,1]\ntrain_knn_fpr, train_knn_tpr, train_knn_thershold = roc_curve(Ytrain, train_knn_probabilities)\n\ntest_knn_probabilities = knn.predict_proba(Xtest)[:,1]\ntest_knn_fpr, test_knn_tpr, test_knn_thershold = roc_curve(Ytest, test_knn_probabilities)","a163044f":"plt.plot(train_knn_fpr, train_knn_tpr, label='Train')\nplt.plot(test_knn_fpr, test_knn_tpr, label='Test')\n\nplt.plot([0,1],[0,1], color='black',linestyle='--')\n\nplt.xlabel('False positive rate - FPR')\nplt.ylabel('True positive rate - TPR')\nplt.legend()\nplt.title('Receiver operating characteristics - ROC Curve')","51a5873a":"# ROC Curve of all four models\nplt.plot(test_rfc_fpr, test_rfc_tpr, label='Random forest classifier')\nplt.plot(test_svc_fpr, test_svc_tpr, label='SVM classifier')\nplt.plot(test_gnb_fpr, test_gnb_tpr, label='Naive bayes classifier')\nplt.plot(test_knn_fpr, test_knn_tpr, label='K-nearest neighbour classifier')\n\nplt.plot([0,1],[0,1], color='black',linestyle='--')\n\nplt.xlabel('False positive rate - FPR')\nplt.ylabel('True positive rate - TPR')\nplt.legend()\nplt.title('Receiver operating characteristics - ROC Curve')","50861188":"Comparison_Table = pd.DataFrame({'Random Forest':[accuracy_score(Ytest,Ypred),cm1[0,0]\/(cm1[0,0]+cm1[0,1]),\n                                                             cm1[1,1]\/(cm1[1,0]+cm1[1,1])], 'SVM Classifier':\n                                                             [accuracy_score(Ytest,Ypred2),cm2[0,0]\/(cm2[0,0]+cm2[0,1]),\n                                                              cm2[1,1]\/(cm2[1,0]+cm2[1,1])], 'Naive Bayes':\n                                                             [accuracy_score(Ytest,Ypred3),cm3[0,0]\/(cm3[0,0]+cm3[0,1]),\n                                                              cm3[1,1]\/(cm3[1,0]+cm3[1,1])],'KNN':[accuracy_score(Ytest,\n                                                              Ypred4),cm4[0,0]\/(cm4[0,0]+cm4[0,1]),cm4[1,1]\/(cm4[1,0]+\n                                                              cm4[1,1])]}, index=['Accuracy','Sensitivity','Specificity'])","c0489002":"Comparison_Table","6dad12cb":"So in this case it is very important to correctly predict that the patient is actually suffering from diabetes so that the patient can be treated accordingly and if our model is not able to correctly predict the diabetic patient that means our model fails to do its job. Sensitivity or true positive rate is a measure of the proportion of people suffering from the diabetes who got predicted correctly as the ones suffering from the diabetes.\n\nTherefore to decide which model should be used for prediction we should use sensitivity and out of all the four model KNN has the the highest sensitivity.","a823d4a0":"The above graph shows that the data is a bit biased towards datapoints having outcome value as 0. The ratio of non-diabetics to diabetic patients is 65% to 35% which is sufficient for making the model.","fd395102":"* ## Treating missing values","8bf14b6c":"The above graph shows that there is a huge amount of overlapping in data points and cannot be seperated linearly.","adfef70c":"Accuracy is the ratio of number of correct predictions to the total number of predictions.  \n\nSensitivity is a measure of the proportion of actual positive cases which got predicted as positive (or true               positive). Sensitivity is also termed as Recall.\nSensitivity or true positive rate is a measure of the proportion of people suffering from the diabetes who got              predicted correctly as the ones suffering from the diabetes. In other words, the person who is diabetic                     (positive) actually got predicted as diabetic.\n\nSpecificity is defined as the proportion of actual negatives which got predicted as the negative. Specificity is a measure of the proportion of people not suffering from the diabetes who got predicted correctly as the ones who are not suffering from the diabetes. In other words, the proportion of person who is non-diabetic actually got predicted as non-diabetic is specificity.","9458d250":"* ## Heatmap for correlation analysis","5bbd936e":"# Importing necessary libraries","8abd6f07":"# Descriptive analysis :\n* ## Finding missing values","25080b90":"# Data Modeling :  \nAs we can see in the scatter chart that there is a huge amount of overlapping in the data points and cannot be linearly seperated. So it is better to use non-linear classifiers like Random forest, Support Vector Machine(SVM), Naive Bayes Classifier and K-nearest Neighbors Algorithm.  \n\nNon-linear classifiers are more more accurate than linear classifiers.","7b18bc55":"* Comparison of various models with the results from KNN algorithm :","bd44cf56":"* Naive bayes classifier :","4b08041b":"* ## Scatter charts between the pair of variables","18c327e8":"* ## Count(frequency) plot describing the data types","1174076a":"* K-nearest neighbour classifier :","910cbe60":"* Random forest classifier :","029ed9a6":"# Loading data","566fe651":"# Data Exploration :  \n* ## Count of outcomes by their value","a7a14252":"* SVM(Support vector machine) classifier :","eb941da7":"* ## Visually explore the data using histograms"}}