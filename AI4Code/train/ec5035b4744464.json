{"cell_type":{"7186d82f":"code","1903744d":"code","c1576185":"code","3b41d44c":"code","13b4d665":"code","67677242":"code","26eb728a":"code","8a9b110b":"code","698a0a74":"code","add48a4b":"code","c3f355b2":"code","1ca6732c":"code","ecaefeee":"markdown","1bb85f59":"markdown","abffc0eb":"markdown","0329e159":"markdown","ecdb76e2":"markdown","79427b9d":"markdown","1c8c4fd9":"markdown","76215e44":"markdown","285852b6":"markdown"},"source":{"7186d82f":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom torchvision import models\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport csv\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","1903744d":"train_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('..\/input\/lish-moa\/train_targets_nonscored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nsubmission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')","c1576185":"train_data = train_features.iloc[:,4:].to_numpy()\ntrain_labels = train_targets_scored.iloc[:,1:].to_numpy()\n\ntest_data = test_features.iloc[:,4:].to_numpy()","3b41d44c":"class my_train_dataset():    \n\n    def __init__(self, train_data, train_labels):\n\n        super(my_train_dataset).__init__()\n        \n        \n        self.X = np.pad(train_data,((0,0),(14, 14)), 'constant', constant_values=(0)).reshape(-1,1,30,30)       \n        \n        self.X = torch.from_numpy(self.X).float()\n        self.Y = torch.from_numpy(train_labels).float()\n        \n            \n    def __getitem__(self,index):\n        \n        image = self.X[index]\n        label= self.Y[index]\n\n        return image, label\n        \n    def __len__(self):\n        return len(self.X)\n    \n\n\nclass my_test_dataset():    \n\n    def __init__(self, test_images):\n\n        super(my_test_dataset).__init__()\n        \n        self.X = np.pad(test_data, ((0,0),(14, 14)), 'constant', constant_values=(0)).reshape(-1,1,30,30)       \n        \n        self.X = torch.from_numpy(self.X).float()\n        \n            \n    def __getitem__(self,index):\n        \n        image = self.X[index]\n\n        return image\n        \n    def __len__(self):\n        return len(self.X)\n","13b4d665":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n      \n        self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)\n        self.bn1 = nn.BatchNorm2d(num_features = 32, eps=1e-05, momentum=0.1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n        self.bn2 = nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(64, 256, 5, padding = 2)\n        self.bn3 = nn.BatchNorm2d(num_features=256, eps=1e-05, momentum=0.1)\n        self.conv4 = nn.Conv2d(256, 512, 5, padding = 2)\n        self.bn4 = nn.BatchNorm2d(num_features=512, eps=1e-05, momentum=0.1)\n        self.conv5 = nn.Conv2d(512, 1024, 5, padding = 2)\n        self.bn5 = nn.BatchNorm2d(num_features=1024, eps=1e-05, momentum=0.1)\n\n            \n        self.hidden = nn.Linear(1024,512)\n        self.output = nn.Linear(512, 206)\n        \n        \n        \n    def forward(self, x):\n\n        x = self.bn1(F.relu(self.conv1(x)))\n        x = self.bn2(self.pool(F.relu(self.conv2(x))))       \n        x = self.bn3(F.relu(self.conv3(x)))\n        x = self.bn4(F.relu(self.conv4(x)))\n        x = self.bn5(F.relu(self.conv5(x)))\n\n        x = F.avg_pool2d(x, [x.size(2), x.size(3)], stride=1)\n       \n        x = x.reshape(x.shape[0],x.shape[1])\n       \n        x = F.relu(self.hidden(x))\n        x = self.output(x)\n        \n        return x","67677242":"net = Net()\nnet.to(device)\nnet","26eb728a":"Training_Loss = []\n\ndef train(model, data_loader, epochs):\n    net.train()\n    for epoch in range(epochs):\n        \n        for batch_num, (feats, labels) in enumerate(data_loader):\n            feats, labels = feats.to(device), labels.to(device)\n            \n            outputs = model(feats)\n            loss = criterion(outputs, labels)\n            \n            optimizer.zero_grad()\n            \n            loss.backward()\n            optimizer.step()\n            \n            \n            del feats\n            del labels\n            del loss\n        \n        lr_scheduler.step()            \n            \n        train_loss = test_classify(model, data_loader)\n        print('Epoch:'+str(epoch)+' Train Loss: {:.4f}\\t'.format(train_loss))\n        Training_Loss.append(train_loss)\n        \n        \ndef test_classify(model, test_loader):\n    model.eval()\n    test_loss = []\n\n    for batch_num, (feats, labels) in enumerate(test_loader):\n        feats, labels = feats.to(device), labels.to(device)\n        outputs = model(feats)\n\n        loss = criterion(outputs, labels.float())\n        \n#         pred_labels = (outputs>0.5).long()\n#         accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n        \n        test_loss.extend([loss.item()]*feats.size()[0])\n        del feats\n        del labels\n\n    model.train()\n    return np.mean(test_loss)\n","8a9b110b":"#Training Batch size\nBatch_size = 256\n\n# Loss Function\ncriterion = nn.BCEWithLogitsLoss()\n\n# Optimizer\noptimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n\n# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 90, eta_min=0)  \nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 25, gamma = 0.1)\n\n# Epochs\nnum_Epochs = 90","698a0a74":"#Train Dataloader\ntrain_dataset = my_train_dataset(train_data,train_labels)          \ntrain_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = Batch_size, num_workers=4,pin_memory=True)\n\n\n#Test Dataloader\ntest_dataset = my_test_dataset(test_data)\ntest_dataloader = data.DataLoader(test_dataset, shuffle=False, batch_size=1, num_workers=0, pin_memory=True)","add48a4b":"train(net, train_dataloader, epochs = num_Epochs)","c3f355b2":"def predict(model, test_loader):\n    \n    model.eval()  \n    prediction = []\n    for batch_num, (feats) in enumerate(test_loader):\n        feats = feats.to(device)\n        outputs = model(feats)\n\n        prediction.append(outputs.sigmoid().detach().cpu().numpy())\n    prediction = np.concatenate(prediction)\n\n    return prediction\n\n\n\nprediction = predict(net, test_dataloader)\nsubmission[submission.columns[1:]] = prediction\nsubmission.to_csv(\"submission.csv\", index = False)","1ca6732c":"plt.figure(figsize=(10,10))\nx = np.arange(1,num_Epochs+1)\nplt.plot(x, Training_Loss, label = 'Training Loss')\nplt.xlabel('Epochs', fontsize =16)\nplt.ylabel('Loss', fontsize =16)\nplt.title('Loss v\/s Epochs',fontsize =16)\nplt.legend(fontsize=16)","ecaefeee":"> # Import necessary modules","1bb85f59":"# Hyperparameters","abffc0eb":"# Inference","0329e159":"> # Start Training","ecdb76e2":"> # Loss Plots","79427b9d":"> #  Read Data","1c8c4fd9":"# Writing Custom Dataloader using PyTorch's Dataset class","76215e44":"# Model Architecture","285852b6":"# Training Method"}}