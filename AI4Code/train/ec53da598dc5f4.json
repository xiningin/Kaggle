{"cell_type":{"8fb16012":"code","cf30eed3":"code","44041a01":"code","e24f011d":"code","77625a12":"code","0beecb2b":"code","79044c14":"code","a58f4c01":"code","4580da31":"code","7b020541":"code","5a7c0cf5":"code","1436c7d2":"code","be385862":"code","04133d35":"code","12cf4ce1":"code","8d526fc5":"code","9901dfe8":"code","02254c23":"code","ad6487be":"code","d7099cab":"code","31a2c27c":"code","98d0e8e2":"code","fea974c5":"code","a6eb0ef8":"markdown","f64ed2e6":"markdown"},"source":{"8fb16012":"########## Hyperparameters ##############\nimg_size= (300,300)\nclasses= 19\nseed= 32\nbatch_size= 14\nval_split= 0.12\nlr= 0.001","cf30eed3":"import pandas as pd \nimport numpy as np\nimport os\n\nimport tensorflow as tf","44041a01":"# Reading images\ndef build_decoder(with_labels=True, target_size=img_size, ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n            \n        img = tf.cast(img, tf.float32) \/ 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n\n# Augmenting images\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        #img= tf.image.random_crop(img, size, seed=None, name=None)\n        img= tf.image.random_brightness(img, 0.2)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment","e24f011d":"# TPU or GPU detection\ndef auto_select_accelerator():\n    \"\"\"\n    Reference: \n        * https:\/\/www.kaggle.com\/mgornergoogle\/getting-started-with-100-flowers-on-tpu\n        * https:\/\/www.kaggle.com\/xhlulu\/ranzcr-efficientnet-tpu-training\n    \"\"\"\n    try:  # detect TPUs\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  ## detect TPUs\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n        #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n        #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n        \n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    return strategy\n\n","77625a12":"test_decoder = build_decoder(with_labels=False, target_size= img_size)","0beecb2b":"def Build_dataset(paths, labels= None, batch= batch_size,\n                  decode_fn=test_decoder, augment_fn=None,\n                  augment= False, repeat= True, shuffle= seed):\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(batch).prefetch(AUTO)\n    \n    return dset","79044c14":"Base_dir = \"hpa-single-cell-image-classification\"\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * batch_size","a58f4c01":"tpu_bsize= batch_size * strategy.num_replicas_in_sync\ntpu_bsize","4580da31":"sub_df = pd.read_csv('\/kaggle\/input\/hpa-single-cell-image-classification\/sample_submission.csv')\ntest_paths = '..\/input\/hpaimage512-data\/TarName\/test\/' + sub_df['ID'] + '.jpg'","7b020541":"# Get the multi-labels\nlabel_cols = sub_df.columns[1:]\n\n#dtest = Build_dataset(paths= test_paths, labels= None, augment= False, repeat=False, shuffle=False)\ndtest = Build_dataset(paths= test_paths, labels= None, augment= False, repeat=False, shuffle=False)","5a7c0cf5":"img_size = img_size[0]\nseed= 35\n#from tensorflow.keras import layers","1436c7d2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom keras.models import Sequential\nfrom keras.layers import Input, Dense, Flatten, Activation, Conv2D, Lambda, \\\n                            Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, multiply\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import Model\n# import tensorflow.keras.applications.efficientnet as efn\nfrom tensorflow.keras.applications import Xception\nimport os\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","be385862":"with strategy.scope():\n    model= tf.keras.models.load_model('..\/input\/hpa-cell-classification-efficientnets-tpu-training\/hpa_effb3.h5')","04133d35":"model.summary()","12cf4ce1":"preds = model.predict(dtest, verbose=1)\npreds.shape","8d526fc5":"sub_df['INDEX']= list(range(0, sub_df.shape[0]))\nsub_df.head()","9901dfe8":"encoded_df= pd.read_csv('..\/input\/generated-mask\/encoded_csv.csv')\nencoded_df.drop(['PredictionString'], 1, inplace=True)\nencoded_df.head()","02254c23":"df=pd.merge(sub_df, encoded_df, on='ID', how='left')\ndf.head()","ad6487be":"def thresh(i, thr=0.5):\n    p= preds[i]\n    string=''\n#     for ind, confi in enumerate(p):\n#         if confi >thr:\n#             x= '{} {:.6} '.format(ind, confi) + df.encode[i][2:-1] +' '\n#             string+= x\n    string+= '0 1 ' + df.encode[i][2:-1] +' '\n    return string","d7099cab":"sub_df.PredictionString= sub_df.INDEX.apply(thresh)\nsub_df.drop(['INDEX'], 1, inplace=True)\nsub_df.head(5)","31a2c27c":"sub_df.PredictionString[0].split(' ')","98d0e8e2":"#sub_df = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv')","fea974c5":"sub_df.to_csv('submission.csv', index=False)\nsub_df.head()","a6eb0ef8":"<h1 style=\"font-family:verdana;\"> <center>Human Protein Atlas - Single Cell Classification\ud83c\udf96 <\/center> <\/h1>\n\n<h3><center style=\"color:#159364; font-family:cursive;\">Inference Notebook \ud83e\uddbe<\/center><\/h3>\n\n\n### Do check-out for [Traning NOTEBOOK](https:\/\/www.kaggle.com\/akhileshdkapse\/hpa-cell-classification-efficientnets-tpu-training) :-)","f64ed2e6":"\n\n## \ud83c\udf04 Thanks for Reading\n\n![](https:\/\/i.gifer.com\/7ImI.gif)\n\n\n\n<div class=\"alert alert-block alert-info\" style=\"font-size:20px; font-family:verdana;\">\n <a target=\"_blank\" style=\"color:orange;\">Do UPVOTE for more Motivation\ud83e\udd1e<\/a>\n<\/div>\n\n\n\n<hr><hr><hr>\n\n<hr>"}}