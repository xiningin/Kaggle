{"cell_type":{"59cdd84a":"code","47e70fe9":"code","fca3cfbd":"code","56e2dc67":"code","e654daac":"code","c5509bf2":"code","76639206":"code","c60751cc":"code","0d4f8a5e":"code","1da79cbc":"code","185f9e1e":"code","e03cb3f0":"code","1d16c7ad":"code","ec17ad64":"code","41e07a62":"code","ea17614d":"code","d29c2c4f":"code","f97a9aae":"code","b9f00120":"markdown","67e33fd5":"markdown","5a649b56":"markdown","d3cda722":"markdown","4b3afc33":"markdown","12022a42":"markdown","86d32b1a":"markdown","8ba4638a":"markdown","aa943d33":"markdown","bdd1495a":"markdown"},"source":{"59cdd84a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os, sys, glob\n\nimport json\n\n# Any results you write to the current directory are saved as output.","47e70fe9":"tickdata = dict()\nfor root, dirs, filenames in os.walk('\/kaggle\/input'):\n    for dirname in dirs:\n        if dirname.startswith('histdata-forex-'):\n            files_csv_zg = glob.glob(os.path.join(root, dirname,'*.csv.zg'))\n            info=dict()\n            missing = dict()\n            with open(os.path.join(root, dirname, 'info.json')) as f:\n              info = json.load(f)\n            with open(os.path.join(root, dirname, 'missing.json')) as f:\n              missing = json.load(f)\n            provider, sectype, ticker = dirname.split('-',3)\n            tickdata[str(dirname)] = {'provider':provider, 'ticker':ticker, 'sectype':sectype, 'details':info, 'count_of_missing_days':len(missing['days']), 'missing_days': missing['days'], 'files':files_csv_zg}","fca3cfbd":"import tensorflow as tf","56e2dc67":"datasets = dict()\nfor key, values in tickdata.items():\n    datasets[key]=tf.data.experimental.CsvDataset(values['files'], [tf.string,tf.float32,tf.float32],header=False, compression_type=\"GZIP\",select_cols=[0,1,2])","e654daac":"input_ds = next(iter(datasets.values()))\ninput_ds.element_spec","c5509bf2":"for f in input_ds.take(5):\n    print(f)","76639206":"from datetime import datetime, timedelta","c60751cc":"def conv_func(dt, bid, ask):\n    txt = lambda t : t.numpy().decode('ascii')\n    conv = lambda z : pd.Timestamp(datetime.strptime(z.numpy().decode('ascii'), '%Y%m%d %H%M%S%f')).to_datetime64()\n    return tf.py_function(txt,[dt], tf.string), tf.py_function(conv, [dt], tf.float64), bid, ask,(bid+ask)\/2, ask-bid","0d4f8a5e":"ts_data = dict()\nfor key, ds in datasets.items():\n    ts_data[key] = ds.map(conv_func)\n    ","1da79cbc":"test_ds = next(iter(ts_data.values()))\ntest_ds.element_spec","185f9e1e":"for f in test_ds.take(5):\n    print(f)","e03cb3f0":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nopendrive_usr = user_secrets.get_secret(\"OPENDRIVE_USERNAME\")\nopendrive_passwd = user_secrets.get_secret(\"OPENDRIVE_PASSWORD\")","1d16c7ad":"!pip install webdavclient3","ec17ad64":"import urllib3\nfrom webdav3.client import Client\noptions = {\n 'webdav_hostname': \"https:\/\/webdav.opendrive.com\",\n 'webdav_login':    opendrive_usr,\n 'webdav_password': opendrive_passwd\n}\nclient = Client(options)\nclient.verify = False\nurllib3.disable_warnings()","41e07a62":"client.list()","ea17614d":"if not client.check('ds_cache'):\n    client.mkdir('ds_cache')","d29c2c4f":"os.makedirs('\/kaggle\/working\/cache', exist_ok=True)\nfor key, value in ts_data.items():\n    cachefilepath = os.path.join('cache',\"{}.cache\".format(key))\n    it = value.cache(cachefilepath).prefetch(tf.data.experimental.AUTOTUNE)\n    # it = iter(value)\n    count = 0\n    for i in it:\n        count+=1\n    print(\"{} has {} quotes\".format(key, count))\n","f97a9aae":"# Uncomment following to upload cache to opendrive\n# client.push('ds_cache','\/kaggle\/working\/cache')","b9f00120":"### Conversion function\n\n```(datetime: string, bid: float32, ask: float32) -> (dateime: string, timestamp: float64,  bid: float32, ask: float32, mid: float32, spread: float32)```","67e33fd5":"# Upload dataset cache","5a649b56":"### username and password stored in kaggle secrets","d3cda722":"#  Click link >> [OpenDrive, Cloud storage with Webdav support](https:\/\/www.opendrive.com\/?od=5eecb28b9dda9)","4b3afc33":"# Connect Opendrive","12022a42":"### Load the gzipped csv, extension set to .csv.zg to disable decompression in kaggle\u00b6\n","86d32b1a":"## Access via WebDAV","8ba4638a":"### Listing of tick data files","aa943d33":"## Make a cache directory","bdd1495a":"### Creating tensorflow CsvDataset for time series data"}}