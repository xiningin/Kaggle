{"cell_type":{"d2608b29":"code","c54cf6d6":"code","c788e6b3":"code","ce80166f":"code","2737a37a":"code","9d421db7":"code","8c7bc37d":"code","f7b4e885":"code","7691e95f":"code","16baaaa6":"code","e35145a8":"code","a0072dc3":"code","0b8f1a83":"code","57629030":"code","327cd882":"code","72ba2667":"code","57162205":"code","aba0a610":"code","99d96961":"code","0ce9d386":"code","cf5947d3":"code","2dff4ce5":"code","e0cb029a":"code","ef9eaf08":"code","a3da375f":"code","38ecc90b":"code","ee9d3c96":"code","31eb34d0":"code","9dd9bdb4":"code","e4b68ef1":"code","eb0908c0":"code","4a8c061d":"code","0c007f8d":"code","b5f5938e":"code","8439c371":"code","0489aa1f":"markdown","da9d0feb":"markdown","14ece99d":"markdown","34dc7688":"markdown","7d345c5a":"markdown","7162ea07":"markdown"},"source":{"d2608b29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport cv2\nimport random\nfrom random import randint\nimport time\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c54cf6d6":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","c788e6b3":"from PIL import Image\n\nimage = Image.open(\"..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg\")\nimage","ce80166f":"#flip image up-to-down\nflipUD = np.flipud(image)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped')","2737a37a":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","9d421db7":"loader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","8c7bc37d":"loader_transform = transforms.CenterCrop(140)\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","f7b4e885":"loader_transform = transforms.Grayscale(num_output_channels=1)\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","7691e95f":"loader_transform = transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","16baaaa6":"loader_transform = transforms.Pad(140, fill=0, padding_mode='constant')\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","e35145a8":"# left, top, right, bottom\nloader_transform = transforms.Pad((2, 5, 0, 5))\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","a0072dc3":"loader_transform = transforms.RandomAffine(45, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","0b8f1a83":"loader_transform = transforms.RandomAffine(90, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","57629030":"# random affine transformation of the image keeping center invariant\nloader_transform = transforms.RandomAffine(0, translate=(0.4, 0.5))\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","327cd882":"#With a Little (Big) help from my friend Balraj Ashwath @balraj98\n\nloader_transform = transforms.RandomApply([transforms.Resize((140, 140))], p=0.5)\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","72ba2667":"#With a Little (Big) help from my friend Balraj Ashwath @balraj98\n\nloader_transform = transforms.RandomApply([transforms.Resize((140, 140)),transforms.Pad(140, fill=0), transforms.RandomHorizontalFlip()],p=0.5)\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","57162205":"loader_transform = transforms.RandomCrop(32, padding=4, padding_mode='reflect')\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","aba0a610":"loader_transform = transforms.RandomHorizontalFlip(p=0.5)\n\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","99d96961":"#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","0ce9d386":"# horizontal flip with probability 1 (default is 0.5)\nloader_transform = transforms.RandomHorizontalFlip(p=1)\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","cf5947d3":"loader_transform = transforms.RandomRotation(30)\nimshow('..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg', loader_transform)","2dff4ce5":"#Code by Ryan Holbrook\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='summer')\n\nimage_path = '..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\nplt.figure(figsize=(6, 6))\nplt.imshow(tf.squeeze(image), cmap='summer')\nplt.axis('off')\nplt.show();","e0cb029a":"import learntools.computer_vision.visiontools as visiontools\nfrom learntools.computer_vision.visiontools import edge, bottom_sobel, emboss, sharpen\n\nKaggleNotebooks = [edge, bottom_sobel, emboss, sharpen]\nnames = [\"Edge Detect\", \"Bottom Sobel\", \"Emboss\", \"Sharpen\"]\n\nplt.figure(figsize=(12, 12))\nfor i, (KaggleNotebook, name) in enumerate(zip(KaggleNotebooks, names)):\n    plt.subplot(1, 4, i+1)\n    visiontools.show_kernel(KaggleNotebook)\n    plt.title(name)\nplt.tight_layout()","ef9eaf08":"#Code By Ryan Holbrook\n# Reformat for batch compatibility.\nimage = tf.image.convert_image_dtype(image, dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nKaggleNotebook = tf.reshape(KaggleNotebook, [*KaggleNotebook.shape, 1, 1])\nKaggleNotebook = tf.cast(KaggleNotebook, dtype=tf.float32)","a3da375f":"conv_fn = tf.nn.conv2d","38ecc90b":"image_filter = conv_fn(\n    input=image,\n    filters=KaggleNotebook,\n    strides=1, # or (1, 1)\n    padding='SAME',\n)\n\nplt.imshow(\n    # Reformat for plotting\n    tf.squeeze(image_filter)\n)\nplt.axis('off')\nplt.show();","ee9d3c96":"# Give the TensorFlow ReLU function (without arguments)\nrelu_fn = tf.nn.relu","31eb34d0":"#Code By Ryan Holbrook\nimage_detect = relu_fn(image_filter)\n\nplt.imshow(\n    # Reformat for plotting\n    tf.squeeze(image_detect)\n)\nplt.axis('off')\nplt.show();","9dd9bdb4":"#Code By Ryan Holbrook\n# Sympy is a python library for symbolic mathematics. It has a nice\n# pretty printer for matrices, which is all we'll use it for.\nimport sympy\nsympy.init_printing()\nfrom IPython.display import display\n\nimage = np.array([\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 0, 0, 0],\n    [0, 1, 0, 1, 1, 1],\n    [0, 1, 0, 0, 0, 0],\n])\n\nKaggleNotebook = np.array([\n    [1, -1],\n    [1, -1],\n])\n\ndisplay(sympy.Matrix(image))\ndisplay(sympy.Matrix(KaggleNotebook))\n# Reformat for Tensorflow\nimage = tf.cast(image, dtype=tf.float32)\nimage = tf.reshape(image, [1, *image.shape, 1])\nKaggleNotebook = tf.reshape(KaggleNotebook, [*KaggleNotebook.shape, 1, 1])\nKaggleNotebook = tf.cast(KaggleNotebook, dtype=tf.float32)","e4b68ef1":"# Read image\nimage_path = '..\/input\/cusersmarildownloadstigerjpg\/tiger.jpg'\nimage = tf.io.read_file(image_path)\nimage = tf.io.decode_jpeg(image, channels=1)\nimage = tf.image.resize(image, size=[400, 400])\n\n# Embossing kernel\nkernel = tf.constant([\n    [-2, -1, 0],\n    [-1, 1, 1],\n    [0, 1, 2],\n])\n\n# Reformat for batch compatibility.\nimage = tf.image.convert_image_dtype(image, dtype=tf.float32)\nimage = tf.expand_dims(image, axis=0)\nkernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\nkernel = tf.cast(kernel, dtype=tf.float32)\n\nimage_filter = tf.nn.conv2d(\n    input=image,\n    filters=kernel,\n    strides=1,\n    padding='VALID',\n)\n\nimage_detect = tf.nn.relu(image_filter)\n\n# Show what we have so far\nplt.figure(figsize=(12, 6))\nplt.subplot(131)\nplt.imshow(tf.squeeze(image), cmap='gray')\nplt.axis('off')\nplt.title('Input')\nplt.subplot(132)\nplt.imshow(tf.squeeze(image_filter))\nplt.axis('off')\nplt.title('Filter')\nplt.subplot(133)\nplt.imshow(tf.squeeze(image_detect))\nplt.axis('off')\nplt.title('Detect')\nplt.show();","eb0908c0":"image_condense = image_condense = tf.nn.pool(\n    input=image_detect,\n    window_shape=(2, 2),\n    pooling_type='MAX',\n    strides=(2, 2),\n    padding='SAME',\n)","4a8c061d":"plt.figure(figsize=(8, 6))\nplt.subplot(121)\nplt.imshow(tf.squeeze(image_detect))\nplt.axis('off')\nplt.title(\"Detect (ReLU)\")\nplt.subplot(122)\nplt.imshow(tf.squeeze(image_condense))\nplt.axis('off')\nplt.title(\"Condense (MaxPool)\")\nplt.show();","0c007f8d":"REPEATS = 4\nSIZE = [64, 64]\n\n# Create a randomly shifted circle\nimage = visiontools.circle(SIZE, r_shrink=4, val=1)\nimage = tf.expand_dims(image, axis=-1)\nimage = visiontools.random_transform(image, jitter=3, fill_method='replicate')\nimage = tf.squeeze(image)\n\nplt.figure(figsize=(16, 4))\nplt.subplot(1, REPEATS+1, 1)\nplt.imshow(image, vmin=0, vmax=1)\nplt.title(\"Original\\nShape: {}x{}\".format(image.shape[0], image.shape[1]))\nplt.axis('off')\n\n# Now condense with maximum pooling several times\nfor i in range(REPEATS):\n    ax = plt.subplot(1, REPEATS+1, i+2)\n    image = tf.reshape(image, [1, *image.shape, 1])\n    image = tf.nn.pool(image, window_shape=(2,2), strides=(2, 2), padding='SAME', pooling_type='MAX')\n    image = tf.squeeze(image)\n    plt.imshow(image, vmin=0, vmax=1)\n    plt.title(\"MaxPool {}\\nShape: {}x{}\".format(i+1, image.shape[0], image.shape[1]))\n    plt.axis('off')","b5f5938e":"#Codes by Ryan Holbrook\n\nfrom matplotlib import gridspec\n\nfeature_maps = [visiontools.random_map([5, 5], scale=0.1, decay_power=4) for _ in range(8)]\n\ngs = gridspec.GridSpec(1, 8, wspace=0.01, hspace=0.01)\nplt.figure(figsize=(18, 2))\nfor i, feature_map in enumerate(feature_maps):\n    plt.subplot(gs[i])\n    plt.imshow(feature_map, vmin=0, vmax=1)\n    plt.axis('off')\nplt.suptitle('Feature Maps', size=18, weight='bold', y=1.1)\nplt.show()\n\n# reformat for TensorFlow\nfeature_maps_tf = [tf.reshape(feature_map, [1, *feature_map.shape, 1])\n                   for feature_map in feature_maps]\n\nglobal_avg_pool = tf.keras.layers.GlobalAvgPool2D()\npooled_maps = [global_avg_pool(feature_map) for feature_map in feature_maps_tf]\nimg = np.array(pooled_maps)[:,:,0].T\n\nplt.imshow(img, vmin=0, vmax=1)\nplt.axis('off')\nplt.title('Pooled Feature Maps')\nplt.show();","8439c371":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#32a832','#32a84e','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Mar\u00edlia Prata, @mpwolke is here' )","0489aa1f":"#Apply ReLU","da9d0feb":"#The first step of feature extraction, the filtering step. Do some reformatting for TensorFlow","14ece99d":"#Apply Transformations. Codes by Ryan Holbrook (from now, till the end).","34dc7688":"Define a simple array to act as an image, and another array to act as the Kaggle Notebook. The following cell show these arrays.","7d345c5a":"#The Embrace. (by Sergey Gorshkov) \n\nGrand Title Winner and Animals in their Environment Winner: A tigress hugs an ancient Manchurian fir, rubbing her cheek against the bark to leave secretions from her scent glands. She is an Amur, or Siberian, tiger, in Russia's Land of the Leopard National Park.https:\/\/www.theatlantic.com\/photo\/2020\/10\/winners-wildlife-photographer-year-2020\/616710\/","7162ea07":"#Apply Pooling to Condense"}}