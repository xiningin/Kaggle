{"cell_type":{"d389ae89":"code","acf79dcb":"code","74716ad5":"code","584a18da":"code","78b10e1c":"code","91554865":"code","aed01a95":"code","cd04637a":"code","1e213ef6":"code","6d43fe9b":"code","d525836a":"code","a2193f1a":"code","25ad3865":"code","cc55aa0a":"code","001ad7cd":"code","2315f974":"code","ab2eb5cd":"code","a8cfbd8c":"code","7aa8f97a":"code","be439008":"markdown","b0cf4d16":"markdown","8b91afe3":"markdown","954e5f33":"markdown","b2d2f846":"markdown","f3b1d506":"markdown","0a85ad1d":"markdown","35499f84":"markdown","72c0bec1":"markdown","b9e58f7a":"markdown","bc77d399":"markdown","c916746e":"markdown","1a26bcc7":"markdown","1b0d9ad1":"markdown"},"source":{"d389ae89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport cv2 #opencv-python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.applications.nasnet import preprocess_input\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.applications.resnet50 import decode_predictions, ResNet50\nimport h5py\nimport datetime\nimport os\nimport shutil\nimport pathlib\nimport time\nfrom IPython.display import display, Image, Markdown\nimport pickle\nfrom numba import cuda\n\ninput = '\/kaggle\/input\/dog-breed-identification\/'\noutput = '\/kaggle\/working\/'\n\ndef md(input):\n    display(Markdown(input))\n\ndef step(input):\n    return md(f\"\u2705 *{input}*\")\n\n\ndef save_model(model, model_path):\n  \"\"\"\n  Saves a given model in a models directory and appends a suffix (str)\n  for clarity and reuse.\n  \"\"\"\n  # Create model directory with current time\n#   modeldir = os.path.join(\"models\",\n#                           datetime.datetime.now().strftime(\"%d-%m-%y-%Hh%Mm\"))\n  print(f\"Saving model to: {model_path}...\")\n  model.save(model_path)\n\ndef load_model(model_path):\n  \"\"\"\n  Loads a saved model from a specified path.\n  \"\"\"\n  print(f\"Loading saved model from: {model_path}\")\n  model = tf.keras.models.load_model(model_path)\n  return model\n    \n    \ndef plot_history(history):\n    metrics = (('accuracy', 'val_accuracy'), ('loss', 'val_loss'))\n    for metric in metrics:\n        plt.plot(history[metric[0]])\n        plt.plot(history[metric[1]])\n        plt.title('model {}'.format(metric[0]))\n        plt.ylabel(metric[0])\n        plt.xlabel('epoch')\n        plt.legend(['train', 'test'], loc='upper left')\n        plt.show()\n\nprint(\"GPU\", \"available (YES!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\nprint(\"clear GPU memory...\")\ndevice = cuda.get_current_device()\ndevice.reset() # clear GPU memory\nstep(\"Setup\")\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","acf79dcb":"train_dir = \"{}train\/\".format(input)\ntest_dir = \"{}test\/\".format(input)\nTRAINING_MODE = False # False = load model and history saved in file (much much faster) instead build it from zero\ndf = pd.read_csv(\"{}labels.csv\".format(input))\ndf=df.sample(frac=1).reset_index(drop=True) #shuffle\ndf['path'] = df.id.apply(lambda x: '{}\/{}.jpg'.format(train_dir, x)) # replace id by path to feed generator with flow_from_dataframe\ndf.drop('id', axis=1, inplace=True)\ndisplay(df.head())\nstep(\"Data loading\")","74716ad5":"print(\"Nombre de photos des diff\u00e9rentes races de chiens\")\ndf[\"breed\"].value_counts().plot.bar(figsize=(20, 10));","584a18da":"{'nombre totale de chiens': df.shape[0], 'nombre de chiens de race la plus repr\u00e9sent\u00e9e': df[\"breed\"].value_counts()[0], 'nombre de chiens de race la moins repr\u00e9sent\u00e9e': df[\"breed\"].value_counts()[-1]}","78b10e1c":"max_breed = df[\"breed\"].value_counts().index[0]\nmin_breed = df[\"breed\"].value_counts().index[-1]\nrandom_max_breed = df.query(\"breed == @max_breed\").sample()\nrandom_min_breed = df.query(\"breed == @min_breed\").sample()","91554865":"print(\"La classe la plus repr\u00e9sent\u00e9e : {} ({} images)\".format(max_breed, df[\"breed\"].value_counts()[0]))\nImage(random_max_breed.path.item())","aed01a95":"print(\"La classe la moins repr\u00e9sent\u00e9e : {} ({} images)\".format(min_breed, df[\"breed\"].value_counts()[-1]))\nImage(random_min_breed.path.item())","cd04637a":"pd.DataFrame(df.breed.value_counts())","1e213ef6":"from os import listdir\nfrom os.path import isfile, join\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport matplotlib.pyplot as plt\n\n\nsample_submission = pd.read_csv('{}sample_submission.csv'.format(input))\n\ndef get_all_files_in_dir(dir_path, full_path=True):\n    if full_path:\n        return [dir_path+f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n    else:\n        return [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n    \ntrain_image_paths = get_all_files_in_dir(train_dir)\ntest_image_paths = get_all_files_in_dir(test_dir)\nmd(f'Il y a **{len(train_image_paths):,}** images dans notre dossier train')\nmd(f'Il y a **{len(test_image_paths):,}** images dans notre dossier test')\nif df.shape[0] != len(train_image_paths) or sample_submission.shape[0] != len(test_image_paths):\n    print(\"\/!\\ Il y a une diff\u00e9rence entre le nombre d'image est le nombre de lignes dans notre dataset!\")\nelse:\n    print(\"Il y autant d'images dans nos dossiers que de ligne dans nos dataset de train et de test.\")\n    \n\ndef get_img_infos(img):\n    img_type = type(img)\n    img_format = img.format\n    img_mode = img.mode\n    img_size = img.size\n    return img_type, img_format, img_mode, img_size\n\nsample_image = load_img(train_image_paths[0])\nsample_type, sample_format, sample_mode, sample_size = get_img_infos(sample_image)\n\n\n\nbad_img_count = 0\nfor image_paths in (train_image_paths, test_image_paths):\n    for img_path in image_paths:\n        img = load_img(img_path)\n        img_type, img_format, img_mode, img_size = get_img_infos(img)\n        if img_type != sample_type or img_format != sample_format or img_mode != sample_mode:\n            print(\"L'image n'est pas conforme : {}\".format(img_path))\n            bad_img_count += 1\n        \nif bad_img_count == 0:\n    md(\"**Toutes les images sont conformes**\")\nelse:\n    print(\"{} image(s) doivent \u00eatre ajust\u00e9es\".format(bad_img_count))\n    \n\n\n","6d43fe9b":"print(\"Voici une image pris au hasard:\")\nsample_image_array = img_to_array(sample_image)\nplt.imshow(sample_image_array \/ 255.0);\nprint('Image type: {}'.format(sample_type))\nprint('Image format: {}'.format(sample_format))\nprint('Image mode: {}'.format(sample_mode))\nprint('Image size: {}'.format(sample_size))","d525836a":"print(\"Pour pouvoir travailler avec des images on doit les convertir en chiffre c'est \u00e0 dire en matrice. Chaque pixel devient un vecteur de taille 3 codant les couleurs RGB (red, green, blue)\")\nprint('Transformation en matrice...')\nprint(f'Image type: {type(sample_image_array)}')\nprint(f'Image array shape: {sample_image_array.shape}')\nsample_image_array","a2193f1a":"model_name = 'nasnet'\nimage_width = 331\nimage_size = (image_width, image_width)\n\n\ngenerator = ImageDataGenerator(\n    validation_split=0.02,\n    horizontal_flip = True,\n    preprocessing_function = preprocess_input\n)\n\n# WITH AUGMENTATION\n# generator = ImageDataGenerator(\n#     validation_split=0.02,\n#     horizontal_flip = True,\n#     rotation_range = 20,\n#     width_shift_range = 0.1,\n#     height_shift_range = 0.1,\n#     shear_range = 0.1,\n#     zoom_range=0.1,\n#     fill_mode = 'nearest',\n#     preprocessing_function = preprocess_input\n# )\n        \ntrain_generator = generator.flow_from_dataframe(\n    dataframe=df,\n    x_col=\"path\",\n    y_col=\"breed\",\n    target_size=image_size,\n    batch_size=32,\n    subset=\"training\",\n    shuffle=False,\n)\n\n\n\n\nvalid_generator = generator.flow_from_dataframe(\n    dataframe=df,\n    x_col=\"path\",\n    y_col=\"breed\",\n    target_size=image_size,\n    batch_size=32,\n    subset=\"validation\",\n    shuffle=False,\n)\n\nstep(\"Tensor generator\")","25ad3865":"model_path = output + 'model_'+ model_name + \".h5\"\nhistory_path = output + 'history_'+ model_name + \".h5\"\n\nif not pathlib.Path(model_path).exists() or not pathlib.Path(history_path).exists() or TRAINING_MODE:\n    md(\"**Il n'existe pas de fichiers, on doit entrainer notre mod\u00e8le compl\u00e9tement une premi\u00e8re fois**\")\n    \n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_accuracy\",\n        patience=2, \n        min_delta=0.001, \n        restore_best_weights=True\n    )\n\n    # Setup input shape to the model\n    input_shape = [None, image_width, image_width, 3] # batch, height, width, colour channels\n\n    # Setup output shape of the model\n    output_shape = 120 # number of unique labels\n\n\n    nas_model=NASNetLarge(\n        include_top=False, \n        weights='imagenet', \n        input_shape=(image_width,image_width,3),\n    )\n\n    nas_model.trainable = False\n\n    \n    # Setup the model layers\n    model = tf.keras.Sequential([\n        nas_model,   \n        layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(120, activation='softmax')\n    ])\n\n\n    # Compile the model\n    opt = SGD(lr=1e-3, momentum=0.9)\n    model.compile(\n        optimizer = opt, \n        loss=\"categorical_crossentropy\", \n        metrics=[\"accuracy\"]\n    )\n    model.summary()\n\n    STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\n    STEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\n    history = model.fit(\n        train_generator, \n        steps_per_epoch=STEP_SIZE_TRAIN, \n        validation_data=valid_generator, \n        validation_steps=STEP_SIZE_VALID, \n        epochs=25, \n        batch_size=32, \n        callbacks=[early_stopping], \n    )\n    \n    \n    history = history.history\n    pickle.dump(history, open( history_path, \"wb\" ) )\n    save_model(model, model_path)\n    \nstep(\"Making model\")","cc55aa0a":"model = load_model(model_path)\nhistory = pickle.load(open(history_path, 'rb'))\ndef plot_history(history):\n    metrics = (('accuracy', 'val_accuracy'), ('loss', 'val_loss'))\n    for metric in metrics:\n        plt.plot(history[metric[0]])\n        plt.plot(history[metric[1]])\n        plt.title('model {}'.format(metric[0]))\n        plt.ylabel(metric[0])\n        plt.xlabel('epoch')\n        plt.legend(['train', 'valid'], loc='upper left')\n        plt.show();\n        if metric[0] == 'accuracy':\n            md(\"best validation {} score: **{}**\".format(metric[0], max(history[metric[1]])))\n        else:\n            md(\"best validation {} score: **{}**\".format(metric[0], min(history[metric[1]])))\n        \n        \nplot_history(history)\ny_pred = model.predict(valid_generator, workers=16, verbose=1)\nstep(\"Evaluation\")","001ad7cd":"unique_breeds = list(pd.unique(df.breed))\nunique_breeds.sort()\nbreed_pred = []\ntop10_pred = []\nall_preds = []\n\nfor pred in y_pred:\n    breed_pred.append(unique_breeds[np.argmax(pred)])\n    top10_keys = pred.argsort()[-10:][::-1]\n    top10_values = np.sort(pred)[-10:][::-1] \n    top10_pred.append(dict(zip([unique_breeds[key] for key in top10_keys], top10_values)))\n    \n\ndf_pred = pd.DataFrame({'path':valid_generator.filenames, 'breed':[unique_breeds[label_index] for label_index in valid_generator.labels], 'pred': breed_pred, 'proba': top10_pred })\nclass_to_num = dict(zip(unique_breeds, range(120)))  # affenpinscher : 0\nfor name in unique_breeds:  \n    df_pred[name] = y_pred[:,class_to_num[name]]\n\nmd(\"**Une ligne de notre dataframe de pr\u00e9dictions**\")\ndisplay(df_pred.sample().T)\nstep(\"Predictions on validation data\")","2315f974":"def get_error(row):\n    predictions = row.proba\n    if row.pred != row.breed:\n        best_score = list(predictions.values())[0]\n        return best_score\n    else:\n        return 0\n\nkey_cols = ['path', 'breed', 'pred', 'proba']\n\ndf_pred = df_pred[key_cols].copy()\ndf_pred[\"error\"] = df_pred.apply(get_error, axis=1)\n\nerror_counts = len(df_pred.query(\"pred != breed\"))\nerrors_percent = round(error_counts\/df_pred.shape[0]*100)\nprint(\"Nombre d'erreurs du mod\u00e8le sur les donn\u00e9es de validations : {}\/{} ({}%)\".format(error_counts,df_pred.shape[0], errors_percent))\nprint(\"Nous avons voulu savoir quelle pr\u00e9dictions avaient r\u00e9alis\u00e9 notre mod\u00e8le lorsqu'il c'est tromp\u00e9, pour cela on a filtrer les mauvaises pr\u00e9dictions et on a retenu le score de la plus forte pr\u00e9diction \u00e9ronn\u00e9e pour produire deux classements diff\u00e9rents. Le premier tableau montre les races de chiens les plus difficiles \u00e0 pr\u00e9dire (moyenne de la marge d'\u00e9rreur) tandis que le second montre les races qui d\u00e9t\u00e9riorent le plus notre mod\u00e8le (sommme au lieu de la moyenne)\")\nmd(\"**les races les plus difficiles \u00e0 pr\u00e9dire:**\")\ndisplay(df_pred.groupby(\"breed\").mean(\"error\").sort_values(by=[\"error\"],ascending=False)[0:20])\nmd(\"**les races dont les mauvaises pr\u00e9dictions impactent le plus notre mod\u00e8le:**\")\ndisplay(df_pred.groupby(\"breed\").sum(\"error\").sort_values(by=[\"error\"],ascending=False)[0:20])\n","ab2eb5cd":"md(\"**TRUE**{}**PRED**\".format(\"&nbsp;\"*75))\n\ndef plot_dog(row):\n    breeds = list(row.proba.keys())\n    scores = list(row.proba.values())\n    pred_image_path = df.query(\"breed == @row.pred\").sample().path.item()\n    img = mpimg.imread(row.path)\n    img = cv2.resize(img, (300, 300))\n    pred_img = mpimg.imread(pred_image_path)\n    pred_img = cv2.resize(pred_img, (300, 300))\n    plt.figure(figsize=(20,5))\n    Grid_plot = plt.GridSpec(1, 3, wspace=0.45)\n    plt.subplot(Grid_plot[0, 0])\n    plt.axis('off')\n    imgplot = plt.imshow(img);\n    plt.subplot(Grid_plot[0, 1])\n    plt.axis('off')\n    imgplot = plt.imshow(pred_img);    \n    plt.subplot(Grid_plot[0, 2:])\n    clrs = ['green' if x == row.breed else 'grey' for x in breeds]\n    sns.barplot(y=breeds, x=scores, orient='h', palette=clrs)\n    \n    \ndf_pred.query(\"pred != breed\").sort_values(by=[\"error\"],ascending=False).apply(plot_dog, axis=1);","a8cfbd8c":"step(\"Predictions details on validation data\")","7aa8f97a":"test_df = pd.read_csv('{}sample_submission.csv'.format(input))\n\nnew_id = [el +\".jpg\" for el in test_df[\"id\"]]\ntest_df[\"id\"] = new_id\n\n\n\ntest_datagen=ImageDataGenerator(\n    horizontal_flip = True,\n    preprocessing_function = preprocess_input\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=test_dir,\n    x_col=\"id\",\n    y_col=None,\n    target_size=image_size,\n    batch_size=32,\n    class_mode=None,\n    shuffle=False,\n)\n\n\ny_pred = model.predict(test_generator)\n\n\ndf_sub = pd.read_csv('{}sample_submission.csv'.format(input))\ndisplay(df_sub.head())\n\ndf_sub.iloc[:,1:] = y_pred\ndisplay(df_sub.head())\n\nfinal_df = df_sub.set_index('id')\nfilename = 'my_submission.csv'\nfinal_df.to_csv(filename)\nstep(\"Fichier de soumission cr\u00e9e: {}\".format(filename))","be439008":"## V\u00e9rification des donn\u00e9es","b0cf4d16":"## Cr\u00e9ations des tenseurs","8b91afe3":"Si aucun fichier n'existe on entraine notre mod\u00e8le puis on le sauvegarde ainsi que ses stats (history). Le mod\u00e8le est optimis\u00e9 pour maximiser l'accuracy, pour diminuer le loss on peut supprimmer le monitor=\"val_accuracy\" et mettre patience=3 \u00e0 l'early stopping, ainsi le mod\u00e8le sera plus pertinent mais s'arretera plus tard et perdra un peu en pr\u00e9cision.","954e5f33":"## Mod\u00e8le","b2d2f846":"On m\u00e9lange le dataframe d\u00e8s le d\u00e9but pour \u00e9viter de le faire par la suite ce qui pourrais compliquer notre interpr\u00e9tation des pr\u00e9dictions, notemment savoir quelle image est associ\u00e9e \u00e0 chaque pr\u00e9diction","f3b1d506":"## Exploration","0a85ad1d":"## Analyse des erreurs de pr\u00e9dictions\nA partir de notre dataframe de pr\u00e9dictions on cherche \u00e0 mieux visualiser les diff\u00e9rentes \u00e9rreurs de notre mod\u00e8le\n","35499f84":"On cr\u00e9e nos tenseurs \u00e0 l'aide des g\u00e9n\u00e9rateurs de Tensorflow, comme nous disposons d\u00e9j\u00e0 d'un dataframe avec l'emplacement de nos fichiers et les labels associ\u00e9s on peut utiliser la fonctions **flow_from_dataframe**. On donne un nom \u00e0 notre mod\u00e8le qui servira \u00e0 cr\u00e9er le fichier d'export du mod\u00e8le. Toutes nos images doivent avoir **la m\u00eame taille** pour avoir un traitement uniforme (un pixel = 3 donn\u00e9es RGB). Si on a le choix on choisira 300x300 ou les recommandation du mod\u00e8le pr\u00e9-entrain\u00e9 que l'on utilise. Il faut \u00e9galement **normaliser** les valeurs RGB pour cela on applique un rescale. Le batch size, c'est \u00e0 dire la taille des paquet d'images qui seront soumises \u00e0 chaque it\u00e9ration de notre entrainement est fix\u00e9 \u00e0 **32**, c'est la valeur qui marche la plupart du temps pour limiter le suraprentissage. **20%** de nos donn\u00e9es seront d\u00e9di\u00e9es \u00e0 la validation. On peut ou pas choisir d'augmenter notre dataset \u00e0 travers divers transformations (si vous d\u00e9commentez il faut repasser un entrainement en passant TRAINING_MODE \u00e0 True).","72c0bec1":"## Cr\u00e9ation du fichier de soumission\nOn utilise notre mod\u00e8le pour pr\u00e9dire les races de chiens de notre \u00e9chantillion de test et on enregistre ces pr\u00e9dictions dans un fichier que l'on pourra soumettre \u00e0 Kaggle pour obtenir un score","b9e58f7a":"**Effectif de chaque race de chien**","bc77d399":"### Les images les plus difficiles \u00e0 pr\u00e9dire\nVoici les images o\u00f9 le mod\u00e8le a le moins perform\u00e9. La bonne r\u00e9ponse est en vert. La photo de gauche est l'image erron\u00e9e et celle de droite est la race pr\u00e9dite. On constate que le probl\u00e8me ne vient pas de la qualit\u00e9 des images ou de leur driversit\u00e9 mais plut\u00f4t de la forte ressemblance que peuvent avoir diff\u00e9rentes races de chien.","c916746e":"## Pr\u00e9dictions sur les donn\u00e9es de validation\nA partir des pr\u00e9dictions de notre mod\u00e8le on va construire un dataframe avec pour chaque pr\u00e9diction l'image associ\u00e9e et les probabilit\u00e9es attribu\u00e9es \u00e0 chaque race de chien.","1a26bcc7":"Apr\u00e8s avoir explorer et v\u00e9rifier les donn\u00e9es passons \u00e0 cr\u00e9ation de notre mod\u00e8le de machine learning pour pr\u00e9dire les races de chien.","1b0d9ad1":"## Evaluation"}}