{"cell_type":{"452c02c5":"code","26f47948":"code","57ce3bc1":"code","16ae7f3a":"code","fedba7e1":"code","4db3a259":"code","f43d3d58":"code","bfcd7e3e":"code","7e1c672d":"code","8d279792":"code","e8f3881d":"code","5424c022":"code","a5dc717c":"code","4789f1df":"code","e1e3a97a":"code","f78d39e1":"code","53906c50":"code","9a97c93e":"code","bbd6e17c":"code","230b592c":"code","7488b252":"code","27883ed5":"code","d6c5f676":"code","35993d66":"code","d375e59c":"code","fa12d5f0":"code","344d6239":"code","f22a8270":"code","26d2e3b8":"code","7b6fc28e":"code","38735c80":"code","1b7c548a":"code","b511f865":"code","7301a7c8":"code","63c23cc4":"code","78c678d4":"code","034e70e4":"code","1e33d217":"code","cd488230":"code","df344106":"code","84356a3d":"code","3fadf31e":"code","daa8ec93":"code","e2435545":"code","7f5a6c0f":"code","40770f97":"code","3f1daaab":"code","06e85fb5":"code","156a152d":"code","2c9fbd0e":"markdown","f6b30aef":"markdown","1694d5cd":"markdown","994963f9":"markdown","498284c9":"markdown","4c2017a6":"markdown","0b959db2":"markdown","e3eeba69":"markdown","ea6ac39e":"markdown","d245871d":"markdown","38ec6260":"markdown","377165bb":"markdown","58683464":"markdown","2b9b87a9":"markdown","5ad65703":"markdown","11952407":"markdown","2083ae3d":"markdown","077722a3":"markdown"},"source":{"452c02c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('..\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","26f47948":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\nrsna_df = pd.read_csv(\"..\/input\/rsna-bone-age\/boneage-training-dataset.csv\")\n","57ce3bc1":"base_bone_dir = '..\/input\/rsna-bone-age\/'\nrsna_df['path'] = rsna_df['id'].map(lambda x: os.path.join(base_bone_dir,\n                                                         'boneage-training-dataset', \n                                                         'boneage-training-dataset', \n                                                          '{}.png'))\n#rsna_df['imagepath'] = [f'{pid}.png' for pid in rsna_df.id]\nrsna_df['imagepath'] = rsna_df['id'].map(lambda x: '{}.png'.format(x))\nrsna_df.head()\nbone_age_mean = rsna_df['boneage'].mean()\nbone_age_dev = 2 * rsna_df['boneage'].std()\nbone_age_std = rsna_df['boneage'].std()\nrsna_df['bone_age_zscore'] = rsna_df.boneage.map(lambda x: (x - bone_age_mean)\/bone_age_dev)\n# we take the mean , dev as 0 and 1\n#bone_age_mean = 0\n#bone_age_dev = 1.0\nrsna_df['bone_age_float'] = rsna_df.boneage.map(lambda x: (x - 0.)\/1.)\nrsna_df.dropna(inplace = True)\nrsna_df.head(5)","16ae7f3a":"rsna_df['gender'] = rsna_df['male'].map(lambda x: 'male' if x else 'female')\nrsna_df.head()\nimport seaborn as sns\ngender = sns.countplot(rsna_df['gender'])\nrsna_df['sex'] = rsna_df['gender'].map(lambda x: 1 if x=='male' else 0)\nrsna_df.head()","fedba7e1":"X = pd.DataFrame(rsna_df[['id','bone_age_float','imagepath','bone_age_zscore']])","4db3a259":"Y = pd.DataFrame(X['bone_age_zscore'])","f43d3d58":"from pathlib import Path\ntrain_img_path = Path('..\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset\/')\n#test_img_path = Path('..\/input\/rsna-bone-age\/boneage-test-dataset\/boneage-test-dataset\/')","bfcd7e3e":"from sklearn.model_selection import train_test_split\nx_train,    x_test,  y_train, y_test = train_test_split(X,Y, \n                                   test_size = 0.2, \n                                   random_state = 2020,\n                                   )\nprint(' x train', x_train.shape[0], 'x validation', x_test.shape[0])\nprint('y train', y_train.shape[0], 'y validation', y_test.shape[0])","7e1c672d":"#For training  i have taken only these records\n#x_train = x_train.head(9600)\n#x_test = x_train.tail(3000)\n#y_train = y_train.head(9600)\n#y_test = y_train.tail(3000)","8d279792":"import matplotlib.pyplot as plt\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nimport tensorflow as tf","e8f3881d":"tf.keras.backend.clear_session()","5424c022":"img_rows = 224\nimg_cols = 224\n\ndatagen=ImageDataGenerator(rescale=1.\/255, rotation_range=20, zoom_range=0.15,\n                           width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n                           horizontal_flip=True, vertical_flip = False, fill_mode=\"nearest\"\n                           )\n\ntrain_gen_mnet=datagen.flow_from_dataframe(dataframe=x_train,\n                                            #directory=train_img_path,\n                                            directory=\"..\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset\/\", \n                                            x_col='imagepath', \n                                            y_col= 'bone_age_zscore', \n                                            class_mode = 'raw',\n                                            color_mode = 'rgb',\n                                            target_size = (img_rows, img_cols), \n                                            batch_size=64)\nvalid_gen_mnet=datagen.flow_from_dataframe(dataframe=x_test,\n                                            #directory=train_img_path,\n                                            directory=\"..\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset\/\", \n                                            x_col='imagepath', \n                                            y_col= 'bone_age_zscore', \n                                            class_mode = 'raw',\n                                            color_mode = 'rgb',\n                                            target_size = (img_rows, img_cols), \n                                            batch_size=64)","a5dc717c":"STEP_SIZE_TRAIN=np.ceil(train_gen_mnet.n\/\/train_gen_mnet.batch_size)\nSTEP_SIZE_VALID=np.ceil(valid_gen_mnet.n\/\/valid_gen_mnet.batch_size)","4789f1df":"print (STEP_SIZE_TRAIN, STEP_SIZE_VALID)","e1e3a97a":"train_img_mnet, train_lbl_mnet = next(train_gen_mnet)\nvalid_img_mnet, valid_lbl_mnet = next(valid_gen_mnet)","f78d39e1":"train_img_mnet.shape","53906c50":"train_X, train_Y = next(datagen.flow_from_dataframe(dataframe=x_train, \n                                            directory=\"..\/input\/rsna-bone-age\/boneage-training-dataset\/boneage-training-dataset\/\", \n                                            #directory=train_img_path,\n                                            x_col='imagepath', \n                                            y_col='bone_age_zscore', \n                                            class_mode = 'raw',\n                                            color_mode = 'rgb',\n                                            target_size=(224, 224), \n                                            batch_size=1024))","9a97c93e":"train_X.shape","bbd6e17c":"base_model=MobileNet(input_shape =  train_img_mnet.shape[1:],weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n\nbase_mobilenet_model=base_model.output\nbase_mobilenet_model=GlobalAveragePooling2D()(base_mobilenet_model)\nbase_mobilenet_model=Dense(1024,activation='relu')(base_mobilenet_model) #we add dense layers so that the model can learn more complex functions and classify for better results.\nbase_mobilenet_model=Dense(1024,activation='relu')(base_mobilenet_model) #dense layer 2\nbase_mobilenet_model=Dense(512,activation='relu')(base_mobilenet_model) #dense layer 3\noutput1=Dense(1,activation='linear')(base_mobilenet_model) #final layer with linear activation","230b592c":"rsna_mobilenet=Model(inputs=base_model.input,outputs=output1)\n#specify the inputs\n#specify the outputs\n#now a model has been created based on our architecture\nfor i,layer in enumerate(rsna_mobilenet.layers):\n  print(i,layer.name)\nfor layer in rsna_mobilenet.layers:\n    layer.trainable=False\n# or if we want to set the first 20 layers of the network to be non-trainable\nfor layer in rsna_mobilenet.layers[:20]:\n    layer.trainable=False\nfor layer in rsna_mobilenet.layers[20:]:\n    layer.trainable=True\n","7488b252":"rsna_mobilenet.compile(optimizer = 'adam', loss = 'mse',\n                           metrics = ['mae'])\n\nrsna_mobilenet.summary()","27883ed5":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_mnet_weights.h5\".format('bone_age')\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=3, min_lr=0.01)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3) # probably needs to be more patient\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","d6c5f676":"history_mobilenet = rsna_mobilenet.fit_generator( generator=train_gen_mnet,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_gen_mnet,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10\n                    ,callbacks = callbacks_list)","35993d66":"mae = history_mobilenet.history['mae']\nval_mae = history_mobilenet.history['val_mae']\n\nloss = history_mobilenet.history['loss']\nval_loss = history_mobilenet.history['val_loss']\nepochs = 6\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, mae, label='Training MAE ')\nplt.plot(epochs_range, val_mae, label='Validation MAE ')\nplt.legend(loc='lower right')\nplt.title('Training and Validation MAE')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","d375e59c":"#print ( (rsna_mobilenet.evaluate(valid_gen_mnet, verbose = 0))*100)","fa12d5f0":"from keras.models import Model\nimport keras.backend as K","344d6239":"rsna_mobilenet.load_weights(weight_path)","f22a8270":"val_pred_Y = (bone_age_dev*rsna_mobilenet.predict(train_X, batch_size = 64, verbose = True))+bone_age_mean\nval_Y_months = (bone_age_dev*train_Y)+bone_age_mean","26d2e3b8":"rand_idx = np.random.choice(range(train_X.shape[0]), 80)\nfig, m_axs = plt.subplots(20, 4, figsize = (14, 30))\nfor (idx, c_ax) in zip(rand_idx, m_axs.flatten()):\n    c_ax.imshow(train_X[idx, :,:,0], cmap = 'bone')\n    c_ax.set_title('\\n\\nActual (Prediction) : %2.1f (%2.1f)' % (val_Y_months[idx], val_pred_Y[idx]))\n    c_ax.axis('off')","7b6fc28e":"fig, ax1 = plt.subplots(1,1, figsize = (10,10))\nax1.plot(val_Y_months, val_pred_Y, 'r.', label = 'predictions')\nax1.plot(val_Y_months, val_Y_months, 'b-', label = 'actual')\nax1.legend()\nax1.set_xlabel('Actual Age (Months)')\nax1.set_ylabel('Predicted Age (Months)')","38735c80":"# evaluate the model\n_, train_acc = rsna_mobilenet.evaluate(train_gen_mnet)\n_, valid_acc = rsna_mobilenet.evaluate(valid_gen_mnet)\nprint('Train: %.3f, Validation: %.3f' % (train_acc, valid_acc))","1b7c548a":"test_df = pd.read_csv(\"..\/input\/rsna-bone-age\/boneage-test-dataset.csv\")","b511f865":"test_df.head()","7301a7c8":"test_df.shape","63c23cc4":"test_img_path = ('..\/input\/rsna-bone-age\/boneage-test-dataset\/')","78c678d4":"test_images = os.listdir(test_img_path)\n#print(len(test_images), 'test images found')","034e70e4":"pred_datagen = ImageDataGenerator(rescale=1.\/255)\npred_generator = pred_datagen.flow_from_directory(\n        str(test_img_path),#\"..\/input\/rsna-bone-age\/boneage-test-dataset\/boneage-test-dataset\/\",\n        target_size=(224, 224),\n        batch_size=10,\n        class_mode='sparse',\n        color_mode ='rgb',\n        shuffle=False)","1e33d217":"_, pred_acc = rsna_mobilenet.evaluate(pred_generator)","cd488230":"print('Test: %.3f' % (pred_acc))","df344106":"img_batch = next(pred_generator)","84356a3d":"pred=rsna_mobilenet.predict_generator(pred_generator, steps=len(pred_generator), verbose=1)","3fadf31e":"# Get classes by np.round\ncl = np.round(pred)\n# Get filenames (set shuffle=false in generator is important)\nfilenames=pred_generator.filenames","daa8ec93":"y_months = (pred[:,0]*41.18 + 127.32).astype(int)","e2435545":"y_months","7f5a6c0f":"# Data frame\nresults=pd.DataFrame({\"file\":filenames,\"prediction\":y_months})","40770f97":"results.head(20)","3f1daaab":"results.to_csv(\"boneage_testdata_predict.csv\")","06e85fb5":"test_df.insert(2, \"Boneage\",y_months, True)","156a152d":"test_df.head()","2c9fbd0e":"This is my first ever Public kernal in Kaggle Community and I referred these great kernals. \nhttps:\/\/www.kaggle.com\/kmader\/attention-on-pretrained-vgg16-for-bone-age\n\nhttps:\/\/www.kaggle.com\/jackbyte\/predict-age-from-x-rays-selfmade-cnn","f6b30aef":"### Let's change the batchsize from 256 to 64 , the prediction improves \n\n\n![image.png](attachment:image.png)","1694d5cd":"![image.png](attachment:image.png)","994963f9":"### Detecting the boneage from X-Ray images ","498284c9":"**Mobile net with 5 epochs, BS 64 resulted in val loss of 0.06 and acc of 0.254, 0.256 **","4c2017a6":"***TEST \/ PREDICT the model*","0b959db2":"**BUILD MODEL**","e3eeba69":"****Set Hyperparameter and Start training\n\n#### Adam optimizer\n#### Using mse as loss function****","ea6ac39e":"### Learning \/ Inferences\n1. Try with different test-train split ratio.(90:10, 80:20,70:30 etc)\n2. Image pre-processing plays a vital role, try with different augmentation types like flipping , rotating, reducing the size of the image\n3. Train with different batch sizes\n4. While using transfer learning , always use pre-trained weights\n5. Play with learning rate\n6. Try Changing the output layer activation function from sigmoid to linear for regression problems\n7. Use early stopping to save training time\n8. Use batch normalization, drop-outs during model building to avoid overfitting or underfitting issue\n9. Play with Epochs, train-valid batch sizes for better model learning\n10. Adam is the mostly used optimizer, SGD and AdaGrad, RAdam are other better options.\n11. Relu\/TanH is the activation function used in other layers\n12. mse, mae ,rmse are used for regressive models wheras acc is measured for classification problems\n13. In model compile, other than std metrics, userdefined metrics can be used.\n14. It is always better to mormalize the x values, ((x-mean(x))\/std(x))\n15. Complex problems , ensampling techniques are preferred\n* Split data into Grp A, B\n* Feed data to Models X and Y\n* Take the combined result of X and Y and feed to model Z","d245871d":"The Boneage prediction is a regressive model, I tried with many pre-trained models like VGG, MobileNet, InceptionNet. Batchsize plays a major role and my 8GB RAM is crashing when i use batchsize 512in train test split. ","38ec6260":"![image.png](attachment:image.png)\n\n\nval_loss improved from 0.13853 to 0.06031, saving model to bone_age_mnet_weights.h5","377165bb":"***mobile net V2***","58683464":"### Please upvote if you like the kernal, Thank you.","2b9b87a9":"### Thanks to DanB for his deep learning kaggle tutorials, they helped me a lot.**","5ad65703":"## Since I used bone_age_mean and bone_age_std to find zscore, the following code must be applied to return the bone age in months","11952407":"**val_pred_Y - Prediction by model\n\nval_Y_months - Actual Y from df converted to months since our model takes zscore of Y**","2083ae3d":"### Use the below snippet to preprocess image of test dataset to be predicted","077722a3":"* **Validation loss went down to 0.06031, when lr=0.01 and 'linear' function used at the output layer with batch size of 64 and train data split at 9:1 ratio"}}