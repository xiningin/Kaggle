{"cell_type":{"c2713183":"code","65cd4f7d":"code","026b296b":"code","515e2398":"code","d768c32a":"code","64a3fc0b":"code","111b670b":"code","c38b1410":"code","4803b35c":"code","2b275edb":"code","7f9188d4":"code","077fec72":"code","d81aa1f2":"code","da4046ad":"code","3980eec1":"code","da813d92":"code","c6c5a515":"code","48fc6f74":"markdown","e1978bb1":"markdown","0fad34ff":"markdown","4948150e":"markdown","390fe2d2":"markdown","3a7185cf":"markdown"},"source":{"c2713183":"!pip install efficientnet_pytorch","65cd4f7d":"# lib.optimizer\n\nimport os\nimport math\nimport itertools as it\n\nimport torch\nfrom torch.optim import Adam, AdamW\nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n\nclass CustomOneCycleLR(OneCycleLR):\n    \"\"\"\n    This implements a 2-phase one cycle learning rate policy\n    that fast.ai says improves performance.\n    Phase 1: Increase LR linearly from initial to max\n    Phase 2: Decrease LR using cosine annealing from max to 0\n    \"\"\"\n\n    def get_lr(self):\n\n        lrs = []\n        step_num = self.last_epoch\n\n        if step_num > self.total_steps:\n            raise ValueError(\"Tried to step {} times. The specified number of total steps is {}\"\n                             .format(step_num + 1, self.total_steps))\n\n        for group in self.optimizer.param_groups:\n            if step_num <= self.step_size_up:\n                # Linear on the way up\n                computed_lr = self._annealing_linear(group['initial_lr'], group['max_lr'], step_num \/ self.step_size_up)\n                if self.cycle_momentum:\n                    computed_momentum = self._annealing_linear(group['max_momentum'], group['base_momentum'],\n                                                         step_num \/ self.step_size_up)\n            else:\n                # Cosine on the way down\n                down_step_num = step_num - self.step_size_up\n                computed_lr = self._annealing_cos(group['max_lr'], group['min_lr'], down_step_num \/ self.step_size_down)\n                if self.cycle_momentum:\n                    computed_momentum = self._annealing_cos(group['base_momentum'], group['max_momentum'],\n                                                         down_step_num \/ self.step_size_down)\n\n            lrs.append(computed_lr)\n            if self.cycle_momentum:\n                if self.use_beta1:\n                    _, beta2 = group['betas']\n                    group['betas'] = (computed_momentum, beta2)\n                else:\n                    group['momentum'] = computed_momentum\n\n        return lrs","026b296b":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom efficientnet_pytorch import EfficientNet\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbestModel = EfficientNet.from_name('efficientnet-b5', in_channels=1, num_classes=7)\nbestModel.to(device)\nstate = torch.load(\"..\/input\/bestmodelb5\/models\/005\/44_0.01606_0.09701.pt\", map_location=device)\nbestModel.load_state_dict(state['model'])","515e2398":"import torchvision.transforms as T\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom scipy.stats import iqr\n\nfrom tqdm.notebook import tqdm\n\nviewMap = ['ch2', 'ch3', 'ch4', 'sax', 'aov', 'rv', 'lvot']\n\ndef preprocess(npy_path):\n    img = np.load(npy_path, allow_pickle=True)\n\n    img = img - np.median(img)\n    img = img \/ iqr(img)\n    \n    transform = T.Compose([\n        # T.Resize((256,256)),\n        T.ToTensor(),\n    ])\n    \n    img_t = transform(img)\n\n\n    x = torch.tensor(img_t).unsqueeze(0).float()  \n    return x\n\ndef test(fDir, tLabel):\n    inc_labels = 0\n    for file in os.listdir(fDir):\n        file = fDir + \"\/\" + file\n        tensor = preprocess(file)\n        tensor = tensor.to(device)\n        bestModel.eval()\n        probabilities = bestModel(tensor)\n        predictions = torch.argmax(probabilities,1)\n        predictions_np = predictions.cpu().numpy()\n        label = viewMap[int(predictions_np)]\n        if label != tLabel:\n            inc_labels += 1\n            print(label)\n            print(file)\n    \n    print(f\"Accuracy {tLabel}: {1-(inc_labels\/50)}\")\n    \ndef evalAnswers(fDir):\n    fileMap = {'ch2' : [], 'ch3' : [], 'ch4' : [], 'sax' : [], 'aov' : [], 'rv' : [], 'lvot' : []}\n    for file in tqdm(os.listdir(fDir)):\n        originalFile = file\n        file = fDir + \"\/\" + file\n        tensor = preprocess(file)\n        tensor = tensor.to(device)\n        bestModel.eval()\n        probabilities = bestModel(tensor)\n        predictions = torch.argmax(probabilities,1)\n        predictions_np = predictions.cpu().numpy()\n        label = viewMap[int(predictions_np)]\n        \n        fileMap[label].append(originalFile)\n        \n    return fileMap\n\n\ndef compare2(jSet, nnSet, trueSet):\n\n    james_correct = [True if j_a == t_a else False for (j_a, t_a) in zip(jSet, trueSet)]\n    nn_correct = [True if nn_a == t_a else False for (nn_a, t_a) in zip(nnSet, trueSet)]\n    \n    james_correct_nn_incorrect = [True if j_c == True and nn_c == False else False for (j_c, nn_c) in zip(james_correct, nn_correct)]\n    james_incorrect_nn_correct = [True if j_c == False and nn_c == True else False for (j_c, nn_c) in zip(james_correct, nn_correct)]\n    both_correct = [True if j_c == True and nn_c == True else False for (j_c, nn_c) in zip(james_correct, nn_correct)]\n    both_incorrect = [True if j_c == False and nn_c == False else False for (j_c, nn_c) in zip(james_correct, nn_correct)]\n    \n    return sum(both_correct), sum(both_incorrect), sum(james_correct_nn_incorrect), sum(james_incorrect_nn_correct)\n\ndef assess(jSet, nnSet, trueSet):\n    \n    j_correct = set(jSet) & set(trueSet)\n    nn_correct = set(nnSet) & set(trueSet)\n    \n    j_incorrect = set(jSet) - set(trueSet)\n    nn_incorrect = set(nnSet) - set(trueSet)\n    \n    return list(j_correct), list(j_incorrect), list(nn_correct), list(nn_incorrect)\n\ndef compare(j_correct, j_incorrect, nn_correct, nn_incorrect):\n\n    both_right = len(list(set(j_correct) & set(nn_correct)))\n    both_wrong = len(list(set(j_incorrect) & set(nn_incorrect)))\n    \n    j_right_nn_wrong = len(list( set(j_correct) & set(nn_incorrect) ))\n    nn_right_j_wrong = len(list( set(nn_correct) & set(j_incorrect) ))\n    \n    return both_right, both_wrong, j_right_nn_wrong, nn_right_j_wrong","d768c32a":"nnAnswers = evalAnswers(\"..\/input\/jamesdata\/JamesDataset\/JamesDataset\")","64a3fc0b":"j_correct, j_incorrect, nn_correct, nn_incorrect = [], [], [], []","111b670b":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/aov\")\nnnSet = nnAnswers['aov']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/AOV\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","c38b1410":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/2ch\")\nnnSet = nnAnswers['ch2']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/CH2\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","4803b35c":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/3ch\")\nnnSet = nnAnswers['ch3']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/CH3\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","2b275edb":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/4ch\")\nnnSet = nnAnswers['ch4']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/CH4\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","7f9188d4":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/lvot\")\nnnSet = nnAnswers['lvot']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/LVOT\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","077fec72":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/rv\")\nnnSet = nnAnswers['rv']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/RV\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","d81aa1f2":"jSet = os.listdir(\"..\/input\/jamesdata\/JamesAnswers\/JamesAnswers\/sax\")\nnnSet = nnAnswers['sax']\ntrueSet = os.listdir(\"..\/input\/viewdsvalidation\/TrueAnswers\/SAX\")\n\nj_t, j_f, nn_t, nn_f = assess(jSet, nnSet, trueSet)\n\nj_correct.append(j_t)\nj_incorrect.append(j_f)\nnn_correct.append(nn_t)\nnn_incorrect.append(nn_f)","da4046ad":"j_correct = [val for sublist in j_correct for val in sublist]\nj_incorrect = [val for sublist in j_incorrect for val in sublist]\nnn_correct = [val for sublist in nn_correct for val in sublist]\nnn_incorrect = [val for sublist in nn_incorrect for val in sublist]","3980eec1":"PP, NN, jPnnN, nnPjN = compare(j_correct, j_incorrect, nn_correct, nn_incorrect)","da813d92":"print(\"Positive, Positive: \", PP)\nprint(\"Negative, Positive: \", jPnnN)\nprint(\"Positive, Negative: \", nnPjN)\nprint(\"Negative, Negative: \", NN)\n","c6c5a515":"from statsmodels.stats.contingency_tables import mcnemar\n# define contingency table\ntable = [[PP, jPnnN],\n        [nnPjN, NN]]\n# calculate mcnemar test\nresult = mcnemar(table, exact=False)\n# summarize the finding\nprint('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))","48fc6f74":"# Loading Model","e1978bb1":"McNemer's Comparison done using online calculator available [here](https:\/\/scistatcalc.blogspot.com\/2013\/11\/mcnemars-test-calculator.html_). The p-value is greater than 0.05. This indicates that the human expert is not significantly better than the network. Additionally, this result agrees with the metrics calculcated by the statsmodel function. \n\n**Results:**\n\nMcNemar chi-squared statistic is 0.257143\nCorresponding p-value is 0.612090\n\nMcNemar chi-squared statistic with Yates correction of 0.5 is 0.178571\nCorresponding p-value is 0.672604\n\nMcNemar chi-squared statistic with Yates correction of 1.0 is 0.114286\nCorresponding p-value is 0.735317\n\nResult using binomial exact test is 0.735879\n\nOdds ratio equals 0.842105 with 95% Confidence interval from 0.433051 to 1.637545\n\n","0fad34ff":"# Results for McNemar's Comparison of Single B5 Model and Human Expert","4948150e":"\n# Calculating Values for McNemar's Comparison","390fe2d2":"## Helper Functions","3a7185cf":"\n\n# McNemer Comparison\n\nFormal testing to evaluate model performance against that of an expert cardiologist. Results for the McNemar's comparison against the model ensemble can be found at the end of [this notebook](https:\/\/www.kaggle.com\/samueldsouza\/viewdetector-ensemble-testing)."}}