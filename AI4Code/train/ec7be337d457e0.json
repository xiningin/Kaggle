{"cell_type":{"9a3f4571":"code","e71310ea":"code","d255f95f":"code","2f44d668":"code","ef308cc2":"code","333d3368":"code","052e8340":"code","267d218c":"code","6aa48d20":"code","59ac66e7":"code","52db20ab":"code","71f9b14b":"code","82f0ec31":"code","74bd891d":"code","0e214265":"code","a2e8f3c9":"code","cf8c5746":"code","1c494250":"code","de87c36a":"code","4cd32e06":"markdown","88723900":"markdown","28dbde1c":"markdown","0977a298":"markdown","bc2536a8":"markdown","0320925e":"markdown","51f2c270":"markdown","460c13cd":"markdown","67473066":"markdown","7ab4322d":"markdown","0dc95eb3":"markdown","50570e72":"markdown","afa03d57":"markdown","e12ab481":"markdown","d834101b":"markdown","69d0a77a":"markdown","889f78e4":"markdown"},"source":{"9a3f4571":"import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npath = \"\/kaggle\/input\/competitive-data-science-predict-future-sales\/\"\n\nitems = pd.read_csv(path+'\/items.csv')\nitem_cats = pd.read_csv(path+'\/item_categories.csv')\nshops = pd.read_csv(path+'\/shops.csv')\nsales = pd.read_csv(path+'\/sales_train.csv')\ntest = pd.read_csv(path+'\/test.csv')\nsubmission = pd.read_csv(path+'\/sample_submission.csv')\n\nprint(\"Data set loaded successfully.\")\n","e71310ea":"print(\"Items\")\nprint(items.head(2))\nprint(\"\\nItem Catagerios\")\nprint(item_cats.tail(2))\nprint(\"\\nShops\")\nprint(shops.sample(n=2))\nprint(\"\\nTraining Data Set\")\nprint(sales.sample(n=3,random_state=1))\nprint(\"\\nTest Data Set\")\nprint(test.sample(n=3,random_state=1))","d255f95f":"from datetime import datetime\nsales['year'] = pd.to_datetime(sales['date']).dt.strftime('%Y')\nsales['month'] = sales.date.apply(lambda x: datetime.strptime(x,'%d.%m.%Y').strftime('%m')) #another way for same thing\n\nsales.head(2)","2f44d668":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#will make your plot outputs appear and be stored within the notebook.\n%matplotlib inline \n\ngrouped = pd.DataFrame(sales.groupby(['year','month'])['item_cnt_day'].sum().reset_index())\nsns.pointplot(x='month', y='item_cnt_day', hue='year', data=grouped)\n","ef308cc2":"#Price\ngrouped_price = pd.DataFrame(sales.groupby(['year','month'])['item_price'].mean().reset_index())\nsns.pointplot(x='month', y='item_price', hue='year', data=grouped_price)\n","333d3368":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the whole time period')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","052e8340":"sns.jointplot(x=\"item_cnt_day\", y=\"item_price\", data=sales, height=8)\nplt.show()","267d218c":"sales.item_cnt_day.hist(bins=100)\nsales.item_cnt_day.describe()","6aa48d20":"print('Data set size before remove item price 0 cleaning:', sales.shape)\nsales = sales.query('item_price > 0')\nprint('Data set size after remove item price 0 cleaning:', sales.shape)","59ac66e7":"print('Data set size before filter valid:', sales.shape)\n# Only shops that exist in test set.\nsales = sales[sales['shop_id'].isin(test['shop_id'].unique())]\n# Only items that exist in test set.\nsales = sales[sales['item_id'].isin(test['item_id'].unique())]\nprint('Data set size after filter valid:', sales.shape)","52db20ab":"print('Data set size before remove outliers:', sales.shape)\nsales = sales.query('item_cnt_day >= 0 and item_cnt_day <= 125 and item_price < 75000')\nprint('Data set size after remove outliers:', sales.shape)","71f9b14b":"#After cleaning plot\nsns.jointplot(x=\"item_cnt_day\", y=\"item_price\", data=sales, height=8)\nplt.show()\n\ncleaned = pd.DataFrame(sales.groupby(['year','month'])['item_cnt_day'].sum().reset_index())\nsns.pointplot(x='month', y='item_cnt_day', hue='year', data=cleaned)","82f0ec31":"# Aggregate to monthly level the sales\nmonthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n    \"date_block_num\",\"date\",\"item_price\",\"item_cnt_day\"].agg({\"date_block_num\":'mean',\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\nmonthly_sales.head(5)","74bd891d":"sales_data_flat = monthly_sales.item_cnt_day.apply(list).reset_index()\n#Keep only the test data of valid\nsales_data_flat = pd.merge(test,sales_data_flat,on = ['item_id','shop_id'],how = 'left')\n#fill na with 0\nsales_data_flat.fillna(0,inplace = True)\nsales_data_flat.drop(['shop_id','item_id'],inplace = True, axis = 1)\nsales_data_flat.head(20)","0e214265":"#We will create pivot table.\n# Rows = each shop+item code\n# Columns will be out time sequence\npivoted_sales = sales_data_flat.pivot_table(index='ID', columns='date_block_num',fill_value = 0,aggfunc='sum' )\npivoted_sales.head(20)","a2e8f3c9":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(pivoted_sales.values[:,:-1],axis = 2)\n# the last column is our prediction\ny_train = pivoted_sales.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(pivoted_sales.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)","cf8c5746":"from keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom keras.models import load_model, Model\n\n# our defining sales model \nsales_model = Sequential()\nsales_model.add(LSTM(units = 64,input_shape = (33,1)))\n#sales_model.add(LSTM(units = 64,activation='relu'))\nsales_model.add(Dropout(0.5))\nsales_model.add(Dense(1))\n\nsales_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nsales_model.summary()","1c494250":"sales_model.fit(X_train,y_train,batch_size = 4096,epochs = 10)","de87c36a":"submission_output = sales_model.predict(X_test)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':test['ID'],'item_cnt_month':submission_output.ravel()})\n# creating csv file from dataframe\n#submission.to_csv('submission.csv',index = False)\nsubmission.to_csv('submission_stacked.csv',index = False)\nsubmission.head()","4cd32e06":"**Step 5** : Spilit training,validation and test dataset.","88723900":"Let's try to plot sales for every year, to understand about seosaonal data","28dbde1c":"As we can see, simple way to address this is to use sales data and try to group and summarize those.\nFor the conveniet purpose we will split date column to year and month","0977a298":"### Please help by upvoting this kernel if you feel useful and share your suggestions for any improvement. It will be very motivating for me. \n","bc2536a8":"As we can see, \"item_cnt_day\" > 125 and < 0, \"item_price\" >= 75000  we can treat as outliers,\nIn data cleaing stage we will remove those items.","0320925e":"**Step 1:** Define the problem and expected output. Break down the problem into simple steps.\nEnd Goal ->  Forcast total amount of products sold in every shop for the next month","51f2c270":"\nExpecting your feedback.\n\nThank you.","460c13cd":"By seeing this graph we can see that\n1. last two months of the year having more sales.\n2. 2015, we are expecting more sales.\n\nLet's try to draw Total sales along with the linear month period time.","67473066":"**Step 2:** Load the data. \nHere I'm using library pandas.","7ab4322d":"Check the distribution, for detectiting outliers","0dc95eb3":"**Step 4:**  Data preprocessing. Identify features. This means, selecting only needed features and create the proper dataset for the processing.\nWe need to find out what are the features that will affect the sales\n1. Price\n2. Month\n3. Year\n4. Item catagory\n\nBased on above features, sales can be vary. So, we will keep only the interested columns and drop others.","50570e72":"After seeing this dataset we can catagerioze this data to meta data and effective data.\nSo, shop_names and item names, we don't care much. We can have a shop and item combined id and the\n sales data for the analyze further.\n\nFinal goal to predict sales, so we can ignore names of the products. we are interested in item count in a date time series. And price also can be a factor for the sales.\n\nSo, Try to plot some data which is relavant. \nBefore plotting anything it is better to get an idea about the boundaries of the data set.\n]","afa03d57":"Our 'date_block_num' column will be the sequnce index, sales will be the value. ","e12ab481":"### Train the dataset\n\nWe will use LSTM(Long Short Term Memory) algorithum to model this time series data.\nLSTM model will learn a function that maps a sequence of past observations as input to an output observation.\n\nFor this approach, we need to prapare our data set with input and output sequence.\n\nEg:  Let say we have monthly avarage sales as,  \n\n[10, 20, 30, 40, 50, 60, 70, 80, 90]\n\nWe can divide the sequence into multiple input\/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned.\n\n            X\t\t y\n    10, 20, 30\t\t40\n    20, 30, 40\t\t50\n    30, 40, 50\t\t60","d834101b":"\n**Problem Statement : **\n\nYou are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.","69d0a77a":"**Step 3: Data Cleaning**\n\nFilter incorrect data. Eg:  \n1. Item price is equal to 0\n2. data not in the test set given\n3. Remove outliers","889f78e4":"****Step 2:** Visualize data. First try to visualize some random samples extracted from the data. I'm using different methods which we can use to visualize data in tabular way."}}