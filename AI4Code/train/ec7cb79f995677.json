{"cell_type":{"3a367e7e":"code","69e31499":"code","a92de931":"code","39450ebd":"code","330ddba1":"code","b64ff29a":"code","130a42b2":"code","62f3645f":"code","5bc6ac23":"code","79ad481c":"code","5f110774":"code","fc21789c":"code","c0fdfb4e":"code","e81a722e":"code","169d3403":"code","5756144d":"code","986e61ca":"code","9fe77497":"code","709fa03c":"code","6854dddb":"code","6e5bdf02":"code","17240174":"code","1d9e8a17":"code","293a6c77":"markdown","3830eaf9":"markdown","ae09a885":"markdown","d9122406":"markdown"},"source":{"3a367e7e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","69e31499":"data = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsubm = pd.read_csv('..\/input\/sample_submission.csv')","a92de931":"data.head()","39450ebd":"data['difficulty'].value_counts()","330ddba1":"data['target'].value_counts().to_frame().T","b64ff29a":"pd.crosstab(data['difficulty'], data['target'])","130a42b2":"data['ciphertext'].apply(len).describe()","62f3645f":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import GridSearchCV","5bc6ac23":"vectorizer = CountVectorizer(\n    analyzer = 'char',\n    lowercase = False,\n    ngram_range=(1, 6))\n\nestimator = SGDClassifier(loss='hinge', max_iter=1000, random_state=0,\n                          tol=1e-3, n_jobs=-1)","79ad481c":"model = Pipeline([('selector', \n                   FunctionTransformer(\n                       lambda x: x['ciphertext'], validate=False)),\n                  ('vectorizer', vectorizer), \n                  ('tfidf', TfidfTransformer()),\n                  ('estimator', estimator)])","5f110774":"X = data.drop('target', axis=1)\ny = data['target']","fc21789c":"from sklearn.model_selection import train_test_split","c0fdfb4e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=0)","e81a722e":"model.fit(X_train, y_train)","169d3403":"y_pred = model.predict(X_test)","5756144d":"from sklearn.metrics import f1_score, classification_report, confusion_matrix","986e61ca":"print(classification_report(y_test, y_pred))","9fe77497":"f1_score(y_test, y_pred, average='macro')","709fa03c":"def get_f1_score(difficulty):\n    score = f1_score(y_test[X_test['difficulty'] == difficulty], \n                     y_pred[X_test['difficulty'] == difficulty], average='macro') \n    return score","6854dddb":"print(\"f1_score per difficulty\")\nfor i in range(1, 5):\n    print(\"Difficulty: {} ==> {:5f}\".format(i, get_f1_score(i)))","6e5bdf02":"model.fit(X, y)","17240174":"test_pred = model.predict(test)","1d9e8a17":"subm['Predicted'] = test_pred\nsubm.to_csv('submission.csv', index=False)","293a6c77":"Let's see if the model is more successful with a particular 'difficulty':","3830eaf9":"## Submission\nWe fit the model with all the data and prepare the submission:","ae09a885":"This is a quite fast solution working only on the encrypted text, without the use of brute force. It is possible to get this way **0.48+ LB** \nAs it is shown in this [kernel](https:\/\/www.kaggle.com\/lbronchal\/don-t-waste-your-time-decrypting-the-texts), it would be also possible to identify the delimiters used (at least for difficulty 1 and 2), even without decryting the full text. With that knowledge it would be possible to get even a better result without seeing the plain texts or using brute force.","d9122406":"The more encrypted the text is, the more difficult is to have accurate predictions."}}