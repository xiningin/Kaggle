{"cell_type":{"93e377f8":"code","cf7c221b":"code","aa2b190e":"code","66d69542":"code","d29382ce":"code","3f34c0c6":"code","7be8b394":"code","d2156eab":"code","0dedfc9d":"code","089d8f6a":"code","dabac1f4":"code","5ed3c460":"code","9abfe712":"code","dae0092c":"code","5757ada9":"code","f1ef0545":"code","6202c351":"code","f6859a58":"code","9b10f1b9":"code","61f46174":"code","887b0b70":"code","6e329d40":"code","c1ba667d":"code","d1bf2e53":"code","653ebdf6":"code","d9c6f22f":"code","800349f0":"code","f306163a":"code","1d110231":"code","82e87c5e":"code","976019bf":"code","a204c5ee":"code","2d3ae6d8":"code","6293ecae":"code","81e36b6d":"code","af69de43":"code","df0eb4ea":"code","9039650d":"code","23d11ca2":"code","37afe5fa":"code","2d4d1f23":"code","256b29fd":"code","cf7e1a57":"code","75442520":"code","3dc023ef":"code","f991bf04":"code","35c983ce":"code","7d9cc6d3":"markdown","8f72cf2b":"markdown","9be6780e":"markdown","1905bdd9":"markdown","58902413":"markdown","057aa50f":"markdown","3db768d2":"markdown"},"source":{"93e377f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cf7c221b":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nsns.set()","aa2b190e":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","66d69542":"train.head()","d29382ce":"test.head()","3f34c0c6":"print(f'shape of train dataset : {train.shape}')\nprint(f'shape of test dataset : {test.shape}')","7be8b394":"training_array = np.array(train,dtype = 'float32')\ntesting_array = np.array(test,dtype = 'float32')","d2156eab":"i = random.randint(0,training_array.shape[0])\nplt.figure()\nplt.imshow(training_array[i,1:].reshape(28,28))\nplt.grid(False)\nplt.show()\nprint(f'The image is for : {int(training_array[i,0])}')","0dedfc9d":"w_grid = 15\nl_gird = 15\n\nfig ,axes = plt.subplots(l_gird,w_grid,figsize=(15,15))\naxes = axes.ravel()\n\nn_training = len(training_array)\n\nfor i in np.arange(0,l_gird*w_grid):\n    \n    index = np.random.randint(0,n_training)\n    axes[i].imshow(training_array[index,1:].reshape(28,28))\n    axes[i].set_title(int(training_array[index,0]),fontsize=8)\n    axes[i].axis('off')\n    \nplt.subplots_adjust(hspace=0.4)","089d8f6a":"X_train = training_array[:,1:]\/255\ny_train = training_array[:,0]","dabac1f4":"test = testing_array\/255","5ed3c460":"print(f'The shape of X_train : {X_train.shape}')\nprint(f'The shape of y_train : {y_train.shape}')\nprint(f'The shape of test dataset : {test.shape}')","9abfe712":"X_train = X_train.reshape(X_train.shape[0],28,28,1)\ntest = test.reshape(test.shape[0],28,28,1)","dae0092c":"print(f'The shape of X_train : {X_train.shape}')\nprint(f'The shape of y_train : {y_train.shape}')\nprint(f'The shape of test dataset : {test.shape}')","5757ada9":"from sklearn.model_selection import train_test_split","f1ef0545":"X_train , X_validate ,y_train,y_validate = train_test_split(X_train,y_train,test_size = 0.1,random_state = 2)","6202c351":"print(f'The Shape of X_train : {X_train.shape}')\nprint(f'The Shape of X_validate : {X_validate.shape}')\nprint(f'The Shape of y_train : {y_train.shape}')\nprint(f'The Shape of y_validate : {y_validate.shape}')","f6859a58":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping","9b10f1b9":"print(f'The shape of y_train : {y_train.shape}')\nprint(f'The shape of y_validate : {y_validate.shape}')","61f46174":"y_train = to_categorical(y_train,num_classes=10)\ny_validate = to_categorical(y_validate,num_classes=10)","887b0b70":"print(f'The shape of y_train : {y_train.shape}')\nprint(f'The shape of y_validate : {y_validate.shape}')","6e329d40":"model = Sequential()\n\nmodel.add(Conv2D(filters=32,\n                kernel_size=(3,3),\n                padding='Same',\n                 activation='relu',\n                input_shape=(28,28,1)))\n\nmodel.add(Conv2D(filters=32,\n                kernel_size=(3,3),\n                padding='Same',\n                activation='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256,\n               activation='relu'))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10,\n               activation='softmax'))","c1ba667d":"model.summary()","d1bf2e53":"from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","653ebdf6":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","d9c6f22f":"model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","800349f0":"early_stopping =EarlyStopping(monitor='val_loss',patience=3,verbose=1)","f306163a":"model.fit(X_train,\n         y_train,\n         epochs=50,\n          verbose=1,\n         validation_data=(X_validate,y_validate),\n         callbacks=[early_stopping])","1d110231":"model_history = pd.DataFrame(model.history.history)","82e87c5e":"model_history","976019bf":"model_history[['accuracy','val_accuracy']].plot()","a204c5ee":"model_history[['loss','val_loss']].plot()","2d3ae6d8":"predict_class = model.predict_classes(test)","6293ecae":"predict_class","81e36b6d":"predict_class.shape","af69de43":"plt.imshow(test[0].reshape(28,28))","df0eb4ea":"evaluate = model.evaluate(X_validate,y_validate)\nprint(f'The final Loss is : {evaluate[0]} \\n The final Accuracy is : {evaluate[1]}')","9039650d":"y_hat = model.predict(X_validate)\ny_pred = np.argmax(y_hat, axis=1)\ny_true = np.argmax(y_validate, axis=1)","23d11ca2":"from sklearn.metrics import confusion_matrix","37afe5fa":"cm = confusion_matrix(y_true,y_pred)","2d4d1f23":"plt.figure(figsize=(10,10))\nsns.heatmap(cm,annot=True,fmt='d',cmap='viridis')\nplt.show()","256b29fd":"W_grid = 6\nL_grid = 6\n\nfig,axes = plt.subplots(L_grid,W_grid,figsize=(15,15))\n\naxes = axes.ravel()\n\nfor i in np.arange(0,L_grid*W_grid):\n    axes[i].imshow(X_validate[i].reshape(28,28))\n    axes[i].set_title(f'Predicted Class : {int(y_pred[i])} \\n True Class : {y_true[i]}')\n    axes[i].axis('off')\n    \nplt.subplots_adjust(wspace=0.4)","cf7e1a57":"from sklearn.metrics import classification_report\n\nnum_classes = 10\ntarget_names = ['Class {}'.format(i) for i in range(num_classes)]\n\nprint(classification_report(y_true,y_pred,target_names=target_names))","75442520":"result = model.predict(test)","3dc023ef":"results = np.argmax(result,axis = 1)","f991bf04":"results = pd.Series(results,name=\"Label\")","35c983ce":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","7d9cc6d3":"# **Optimizer**\nOnce our layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm.\n\nWe define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\".\n\nThe most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n\nI choosed RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.","8f72cf2b":"## **Import Keras libraries**","9be6780e":"# **Digit Recognizer**\n\n\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We\u2019ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.","1905bdd9":"## **Split the training Dataset into test and Train**","58902413":"## **Load Dataset**","057aa50f":"# **Build the CNN model**","3db768d2":"# **Early Stopping in Keras**\n\nKeras supports the early stopping of training via a callback called EarlyStopping.\n\nThis callback allows you to specify the performance measure to monitor, the trigger, and once triggered, it will stop the training process.\n\nThe EarlyStopping callback is configured when instantiated via arguments.\n\nThe \u201cmonitor\u201d allows you to specify the performance measure to monitor in order to end training. Recall from the previous section that the calculation of measures on the validation dataset will have the \u2018val_\u2018 prefix, such as \u2018val_loss\u2018 for the loss on the validation dataset."}}