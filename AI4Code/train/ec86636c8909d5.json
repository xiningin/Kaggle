{"cell_type":{"12d69eb5":"code","893c8827":"code","26549ec0":"code","1c1ae7c7":"code","8837f9f2":"code","048962bd":"code","25cd9d82":"code","a92684f5":"code","829f50fe":"code","a60894c9":"code","28be5686":"code","5cc31276":"code","b84df40a":"code","583d5f77":"code","c52de6bb":"code","5243a997":"code","7c3ac684":"code","560f8c2a":"code","b662ba3f":"code","6f9f36f6":"code","bb79610f":"code","53c18deb":"code","d461d142":"code","b442edb1":"code","db6e32a2":"code","ee1403c2":"code","2b69e2fb":"code","c43727e4":"code","67cd69de":"code","6c0a3cc6":"code","7d464a16":"code","d22f54c9":"code","8336be0c":"code","2328badf":"code","d5477da3":"code","6a92eba7":"code","16db4cb8":"code","1021bd22":"code","eecb08a7":"code","c62608db":"code","a93ea700":"code","0921e41f":"code","eb5a3c31":"code","c762ee7f":"code","f357ffa3":"code","7cd7efaf":"code","10471b8f":"markdown","bef5a310":"markdown","dff1d516":"markdown","36b81bbc":"markdown","5d622774":"markdown","d55086c2":"markdown","06152d04":"markdown","46f3c89d":"markdown","c462bd2a":"markdown","98036a06":"markdown","c58ad298":"markdown","abff315b":"markdown","b1e0b9c4":"markdown"},"source":{"12d69eb5":"# Importing dependencies\nimport pandas as pd    # for reading tabular data\nimport numpy as np     # for numerical data and arithmetic operations","893c8827":"# for plotting and visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt","26549ec0":"df = pd.read_csv('..\/input\/ccdata\/CC GENERAL.csv')\ndf","1c1ae7c7":"# checking if the dataset has any missing data\ndf.isnull().mean()*100","8837f9f2":"sns.heatmap(df.isnull())","048962bd":"# let's drop those columns\ndf = df.dropna()","25cd9d82":"# lets check the results again\ndf.isnull().mean()*100","a92684f5":"# Shape of the dataset\ndf.shape","829f50fe":"df.info()","a60894c9":"df.describe()","28be5686":"df.corr()","5cc31276":"sns.heatmap(df.corr())","b84df40a":"# let's check the dataset for outliers\nsns.boxplot(x= 'BALANCE', data=df)","583d5f77":"df.boxplot(column = ['BALANCE', 'PURCHASES'])","c52de6bb":"plt.figure(figsize = (10,10))\nsns.boxplot(data = df, orient = 'h', palette = 'Set2')","5243a997":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","7c3ac684":"df = df.drop('CUST_ID', axis=1)\ndf","560f8c2a":"std_scaler = StandardScaler()\ndf_scaled = std_scaler.fit_transform(df)","b662ba3f":"df_scaled.shape","6f9f36f6":"df_scaled","bb79610f":"# Applying PCA\nfrom sklearn.decomposition import PCA","53c18deb":"pca = PCA()\npca.fit(df_scaled)","d461d142":"# Let's check it's performance\nexp_var = pca.explained_variance_\nexp_var","b442edb1":"# Amount of variance that lies in each principal component's axis.\nvar_ratio = pca.explained_variance_ratio_\nvar_ratio","db6e32a2":"cumsum = np.cumsum(var_ratio)\ncumsum","ee1403c2":"plt.title('Optimal number of Dimensions')\nplt.plot(cumsum)","2b69e2fb":"pca_final = PCA(n_components = 7).fit(df_scaled)\npca_final","c43727e4":"pca_final.explained_variance_","67cd69de":"pca_final.explained_variance_ratio_","6c0a3cc6":"reduced_cr = pca_final.fit_transform(df_scaled)","7d464a16":"dimensions = pd.DataFrame(reduced_cr)\ndimensions.columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']\ndimensions","d22f54c9":"from sklearn.cluster import KMeans\nk_means = KMeans(n_clusters = 3, random_state = 123)\nk_means.fit(dimensions)","8336be0c":"k_means.cluster_centers_","2328badf":"# Lets try with 4,5,6,7,8,9 clusters\nk_means4 = KMeans(n_clusters = 4,random_state = 123).fit(dimensions)\nk_means5 = KMeans(n_clusters = 5,random_state = 123).fit(dimensions)\nk_means6 = KMeans(n_clusters = 6,random_state = 123).fit(dimensions)\nk_means7 = KMeans(n_clusters = 7,random_state = 123).fit(dimensions)\nk_means8 = KMeans(n_clusters = 8,random_state = 123).fit(dimensions)\nk_means9 = KMeans(n_clusters = 9,random_state = 123).fit(dimensions)","d5477da3":"labels = k_means.labels_\ndf['3_clusters'] = k_means.labels_","6a92eba7":"df['4_clusters'] = k_means4.labels_\ndf['5_clusters'] = k_means5.labels_\ndf['6_clusters'] = k_means6.labels_\ndf['7_clusters'] = k_means7.labels_\ndf['8_clusters'] = k_means8.labels_\ndf['9_clusters'] = k_means9.labels_","16db4cb8":"df['3_clusters'].value_counts()","1021bd22":"df.head()","eecb08a7":"sns.scatterplot(x = 'BALANCE', y = 'PURCHASES', data = df, hue = '8_clusters')","c62608db":"sns.scatterplot(y = 'CASH_ADVANCE', x = 'PURCHASES', data = df, hue = '8_clusters')","a93ea700":"print(df['8_clusters'].value_counts()\/ sum(df['8_clusters'].value_counts()))","0921e41f":"from sklearn.metrics import silhouette_score\nscore = silhouette_score(dimensions, labels = k_means.labels_)\nscore","eb5a3c31":"cluster_range = range(2,20)\nvariance = []\n\nfor num_clusters in cluster_range:\n    cluster = KMeans(num_clusters)\n    cluster.fit(dimensions)\n    variance.append(cluster.inertia_)","c762ee7f":"variance","f357ffa3":"cluster_df = pd.DataFrame({'Cluster_no' : range(2,20), 'unexplained_variance': variance})\ncluster_df.head(10)","7cd7efaf":"# Plotting the elbow to find out the optimal number of clusters\n%matplotlib inline\nplt.plot(cluster_df.Cluster_no, cluster_df.unexplained_variance, marker = 'o')\nplt.xlabel('No of clusters')\nplt.ylabel('Unexplained Variance(error)')\nplt.grid('True')","10471b8f":"# DATA PREPARATION","bef5a310":"ELBOW ANALYSIS","dff1d516":"# EXPLORATORY DATA ANLAYSIS","36b81bbc":"As we can see that the explained variance starts to decrease at 7 or 8 number of dimensions. So, the number of dimensions should be 7 or 8.","5d622774":"# DIMENSIONALITY REDUCTION","d55086c2":"# CLUSTERING USING K-MEANS","06152d04":"Nothing extraordinary. Purchases and other types of purchases have a high correlation.","46f3c89d":"Almost all the columns have many outliers. It's obvious that they have because it's financial data and comprises of wealth of individual. Wealth is unequally distributed among the individuals and hence purchase realted data also have so many outliers.","c462bd2a":"As we can see that, the rate of decreasing of inertia values starts to decrease once we reach 8 or 9 clusters. That means 8 is optimum number of clusters.","98036a06":"We have cleared the missing values.","c58ad298":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abff315b":"Lets explore the dataset","b1e0b9c4":"Looks like minimum payments and credit limit columns have some missing data"}}