{"cell_type":{"1b3df1a6":"code","eec53e45":"code","8a51b40e":"code","671bc8c0":"code","2bb9e8a1":"code","3f24bdd9":"code","4fea229d":"code","19ef5864":"code","f41c5fd5":"code","7114980a":"code","6bee5d82":"code","62f260c7":"code","877320ed":"code","6e42dcd5":"code","df85b54f":"code","d8a0f7a1":"code","6ebd6154":"code","d5f6852a":"code","5b9443ac":"code","78970d7c":"code","e2cb4aad":"code","b6804231":"code","c2e22299":"code","ed11a75f":"code","50ddfcd6":"code","12d0859a":"code","3fa0e071":"code","eb9976e1":"code","4f6efd3e":"code","a4fd62b0":"code","3e180df7":"code","b9b2149b":"code","f6dc2e66":"code","761a469b":"code","314758e9":"code","31252572":"code","7e7def61":"code","13bdf399":"code","1eb1b56f":"code","700bb23d":"code","ac4a02a8":"code","33276993":"code","db48e822":"code","198a39ec":"code","bd29898b":"code","ae02d590":"code","4e5b895f":"code","c5b8697e":"code","90424dc0":"code","84e305da":"code","8bd3b1a8":"markdown","c074baea":"markdown","7b1a30f8":"markdown","72ba9502":"markdown","527161fe":"markdown","94e7ca69":"markdown","4efb3fc9":"markdown","3b6c5c3c":"markdown"},"source":{"1b3df1a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eec53e45":"import numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport requests","8a51b40e":"data=requests.get('https:\/\/restcountries.eu\/rest\/v2\/all').json()","671bc8c0":"data","2bb9e8a1":"for i in range(len(data)):\n    print(data[i]['name'])","3f24bdd9":"for i in range(len(data)):\n    print(data[i]['region'])","4fea229d":"for i in range(len(data)):\n    print(data[i]['gini'])","19ef5864":"for i in range(len(data)):\n    print(data[i]['capital'])","f41c5fd5":"name=[]\nregion=[]\nsubregion=[]\npopulation=[]\ndemonym=[]\narea=[]\ngini=[]\npopulation=[]\nnum_code=[]\ncapital=[]\nfor i in range(len(data)):\n    name.append(data[i]['name'])\n    region.append(data[i]['region'])\n    subregion.append(data[i]['subregion'])\n    population.append(data[i]['population'])\n    demonym.append(data[i]['demonym'])\n    area.append(data[i]['area'])\n    try:\n        gini.append(data[i]['gini'])\n    except:\n        gini.append('None')\n    num_code.append(data[i]['numericCode'])\n    capital.append(data[i]['capital'])","7114980a":"df=pd.DataFrame({\n    'name':name,\n    'region':region,\n    'subregion':subregion,\n    'population':population,\n    'demonym':demonym,\n    'area':area,\n    'gini':gini,\n    'num_code':num_code,\n    'capital':capital,\n})","6bee5d82":"df","62f260c7":"df.isnull().sum()","877320ed":"df[df['num_code'].isnull()]","6e42dcd5":"df[df['area'].isnull()]","df85b54f":"df[df['name']=='India']","d8a0f7a1":"df.info()","6ebd6154":"df[df['region']=='']","d5f6852a":"df[df['capital']=='']","5b9443ac":"df[df['subregion']=='']","78970d7c":"df[df['demonym']=='']","e2cb4aad":"webpage=requests.get('https:\/\/www.infoplease.com\/world\/countries\/Afghanistan').text\nsoup=BeautifulSoup(webpage,'lxml')\nsoup.prettify()\nx=soup.find_all('li')[118].find_all('p')[2].find_all('b')[0].next_sibling.strip()\nfor j in range(len(x)):\n    if x[j]==' ':\n                break\nx=x[:j]\nprint(x)","b6804231":"area","c2e22299":"RGR=[]\nfor i in range(len(name)):\n    x=name[i]\n    lst=[]\n    for j in range(len(x)):\n        lst.append(x[j])\n        if x[j]==' ':\n            lst.pop()\n            lst.append('-')\n    x=''.join(lst)\n    k=0\n    c=0\n    webpage=requests.get('https:\/\/www.infoplease.com\/world\/countries\/{}'.format(x)).text\n    soup=BeautifulSoup(webpage,'lxml')\n    soup.prettify()\n    print(name[i])\n    if name[i]=='Gambia' or name[i]=='Palau' or name[i]=='South Africa' or name[i]=='Western Sahara':\n        c=20\n        \n    try:\n        while c!=20:\n            \n            try:\n                if soup.find_all('li')[118].find_all('p')[k].find_all('b')[2].text.strip()=='Real growth rate:':\n                    x=soup.find_all('li')[118].find_all('p')[k].find_all('b')[2].next_sibling.strip()\n                    RGR.append(x)\n                    break\n            except:\n                k=k+1\n                c=c+1\n    except:\n        pass\n    if c==20:\n        RGR.append(np.nan)","ed11a75f":"RGR","50ddfcd6":"len(RGR)","12d0859a":"df['Real Growth Rating(%)']=RGR","3fa0e071":"df.drop(['capital'],axis=1,inplace=True)#","eb9976e1":"df.drop(['demonym'],axis=1,inplace=True)","4f6efd3e":"df.drop(['num_code'],axis=1,inplace=True)","a4fd62b0":"df","3e180df7":"df.isnull().sum()","b9b2149b":"LR=[]\nfor i in range(len(name)):\n    x=name[i]\n    lst=[]\n    for j in range(len(x)):\n        lst.append(x[j])\n        if x[j]==' ':\n            lst.pop()\n            lst.append('-')\n    x=''.join(lst)\n    k=0\n    c=0\n    webpage=requests.get('https:\/\/www.infoplease.com\/world\/countries\/{}'.format(x)).text\n    soup=BeautifulSoup(webpage,'lxml')\n    soup.prettify()\n    print(name[i])\n    if name[i]=='\u00c5land Islands':\n        c=20\n        \n    try:\n        \n        \n        while c!=20:\n            try:\n                if soup.find_all('li')[118].find_all('p')[k].find_all('b')[0].text.strip()=='Literacy rate:':\n                    x=soup.find_all('li')[118].find_all('p')[k].find_all('b')[0].next_sibling.strip()\n                    LR.append(x)\n                    break\n                \n                k=k+1\n                c=c+1\n            except:\n                k=k+1\n                c=c+1\n                \n        \n            \n    except:\n        LR.append(np.nan)\n    if c==20:\n        LR.append(np.nan)","f6dc2e66":"LR","761a469b":"len(LR)\n    ","314758e9":"\ndf['Literacy Rate(%)']=LR","31252572":"df","7e7def61":"df.isnull().sum()","13bdf399":"INF=[]\nfor i in range(len(name)):\n    x=name[i]\n    lst=[]\n    for j in range(len(x)):\n        lst.append(x[j])\n        if x[j]==' ':\n            lst.pop()\n            lst.append('-')\n    x=''.join(lst)\n    k=0\n    c=0\n    temp=['Gambia','Palau','South Africa','Western Sahara','American Samoa','Comoros','Luxembourg']\n    webpage=requests.get('https:\/\/www.infoplease.com\/world\/countries\/{}'.format(x)).text\n    soup=BeautifulSoup(webpage,'lxml')\n    soup.prettify()\n    print(name[i])\n    if name[i] in temp:\n        c=20\n        \n    try:\n        while c!=20:\n\n            \n            try:\n                if soup.find_all('li')[118].find_all('p')[k].find_all('b')[3].text.strip()=='Inflation:':\n                    x=soup.find_all('li')[118].find_all('p')[k].find_all('b')[3].next_sibling.strip()\n                    INF.append(x)\n                    break\n            except:\n                k=k+1\n                c=c+1\n    except:\n        pass\n    if c==20:\n        INF.append(np.nan)","1eb1b56f":"INF","700bb23d":"len(INF)","ac4a02a8":"df['Inflation(%)']=INF","33276993":"df","db48e822":"df.isnull().sum()","198a39ec":"UN=[]\nfor i in range(len(name)):\n    x=name[i]\n    lst=[]\n    for j in range(len(x)):\n        lst.append(x[j])\n        if x[j]==' ':\n            lst.pop()\n            lst.append('-')\n    x=''.join(lst)\n    k=0\n    c=0\n    temp=['Gambia','Palau','South Africa','Western Sahara','American Samoa','Comoros','Luxembourg']\n    webpage=requests.get('https:\/\/www.infoplease.com\/world\/countries\/{}'.format(x)).text\n    soup=BeautifulSoup(webpage,'lxml')\n    soup.prettify()\n    print(name[i])\n    if name[i] in temp:\n        c=20\n        \n    try:\n        while c!=20:\n\n            \n            try:\n                if soup.find_all('li')[118].find_all('p')[k].find_all('b')[4].text.strip()=='Unemployment:':\n                    x=soup.find_all('li')[118].find_all('p')[k].find_all('b')[4].next_sibling.strip()\n                    UN.append(x)\n                    break\n            except:\n                k=k+1\n                c=c+1\n    except:\n        pass\n    if c==20:\n        UN.append(np.nan)","bd29898b":"UN","ae02d590":"len(UN)","4e5b895f":"df['Unemployement(%)']=UN","c5b8697e":"df","90424dc0":"df.isnull().sum()","84e305da":"df.to_csv('250 Country Data')","8bd3b1a8":"# Plannning to make the dataframe with columns:\n\n1.Index   \n2.Name   \n3.Region   \n4.SubRegion    \n5.Population    \n6.Area    \n7.Gini   \n8.RealGrowthRate    \n9.Unemployement    \n10.Inflation   \n11.Literacy Rate      \n\n\nFirst 7 from API and Last 4 from web scraping","c074baea":"#### 1.Have to replace the 'space' values with nan","7b1a30f8":"### 11.Unemployement","72ba9502":"# WebScrape","527161fe":"### 10.Inflation","94e7ca69":"### 8.Real Growth Rating","4efb3fc9":"### 9.Literacy Rate","3b6c5c3c":"# API "}}