{"cell_type":{"fff349e5":"code","0c6c9248":"code","35bd467e":"code","1735793f":"code","a02eb431":"code","4c9c7558":"code","cc19db36":"code","97126471":"code","70da0b41":"code","62115ddb":"code","6f646797":"code","4eb2806a":"code","64628964":"code","634681be":"code","0ef2582a":"code","ba4ef633":"code","ba1f5c6e":"code","27b1f3ab":"code","1220d711":"code","945cd2bc":"code","58440423":"code","91a5aaa0":"code","9f34baa6":"code","5e4112b1":"code","0b29a800":"code","8f59e0a6":"code","c3c4e88c":"code","5ad750e8":"code","61da8624":"markdown","f1855ff3":"markdown","785fb499":"markdown","c6990c8d":"markdown","db024122":"markdown","90e6af93":"markdown","b165a271":"markdown","8d64b832":"markdown"},"source":{"fff349e5":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","0c6c9248":"data = pd.read_csv(\"..\/input\/indian-liver-patient-records\/indian_liver_patient.csv\")\ndf = pd.DataFrame(data)","35bd467e":"df.head()","1735793f":"df.shape","a02eb431":"df.info()","4c9c7558":"# showing column wise %ge of NaN values they contains\nnull_col = []\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n  if df[i].isna().mean()*100 > 0:\n    null_col.append(i)","cc19db36":"for i in null_col:\n  df[i] = df[i].fillna(df[i].mean())\n\n# lets check for null values again\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)","97126471":"# Checking for unbalanced dataset\n\nplt.figure(figsize=(5,5))\nax = sns.countplot(x='Dataset', data=df)\n\nfor p in ax.patches:\n        ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\n","70da0b41":"from imblearn.over_sampling import RandomOverSampler\n\noversample = RandomOverSampler()\nx, y = oversample.fit_resample(df.drop(['Dataset'], axis=1), df['Dataset'])\n\nnew_df = pd.DataFrame(x, columns=df.drop(['Dataset'], axis=1).columns)\nnew_df['Dataset'] = y\n\nnew_df.head()\n\n","62115ddb":"plt.figure(figsize=(5,5))\nax = sns.countplot(x='Dataset', data=new_df)\n\nfor p in ax.patches:\n        ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\n","6f646797":"from sklearn.preprocessing import LabelEncoder\n\nenc = LabelEncoder()\nnew_df['Gender'] = enc.fit_transform(new_df['Gender'].astype('str'))\n","4eb2806a":"new_df.head()","64628964":"new_df.shape","634681be":"new_df.info()","0ef2582a":"for i in new_df.select_dtypes(include=['object']).columns:\n  new_df[i] = new_df[i].astype(str).astype(float)","ba4ef633":"cormap = new_df.corr()\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(cormap, annot = True)","ba1f5c6e":"sns.pairplot(data=new_df, hue='Dataset', corner=True)\n","27b1f3ab":"X = new_df.drop(['Dataset'], axis=1)\ny = new_df['Dataset']","1220d711":"# Scale the data to be between -1 and 1\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\nX.head()","945cd2bc":"#now lets split data in test train pairs\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)","58440423":"# model training \n\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\n\nmodel= KNN()   \nmodel.fit(X_train, y_train)","91a5aaa0":"model.get_params()","9f34baa6":"from sklearn.model_selection import GridSearchCV\nn_neighbors = [x for x in range(5, 86, 2)]\nalgorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\nweights = ['uniform', 'distance']\n\ngrid = {'n_neighbors': n_neighbors,\n        'algorithm': algorithm,\n        'weights': weights}","5e4112b1":"new_model = KNN() \n\nknn_grid = GridSearchCV(estimator = new_model, param_grid = grid, cv = 7, verbose=0)\nknn_grid.fit(X_train, y_train)","0b29a800":"knn_grid.best_params_","8f59e0a6":"y_pred = knn_grid.best_estimator_.predict(X_test)\n\npred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\npred_df.head()","c3c4e88c":"from sklearn.metrics import confusion_matrix\n\nmat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(mat, annot = True)","5ad750e8":"from sklearn import metrics\n\n# Measure the Accuracy Score\nprint(\"Accuracy score of the predictions: {value:.2f} %\".format(value=metrics.accuracy_score(y_pred, y_test)*100))\n","61da8624":"> Since due to over sampling some of columns get converted in *objec* type, lets convert them back in numericals","f1855ff3":"## **KNN**","785fb499":"> Since we got only one column *Gender* with string value, let's encode it in numerical value","c6990c8d":"> Since no column has signficant missing values, there is no need to drop column here . Now fill the num values of column *Albumin_and_Globulin_Ratio* the mean of column (as it is only column with few Nan values)\n","db024122":"> Here this bar graph easily shows how data is imbalanced. Less than 30% data is in class __2__. So, first, we have to balance the data in to get more precise predictions.\n\n\n> For that we are using Over sampling\n","90e6af93":"> Here we can see that all the classes are balanced.","b165a271":"> Hyper parameter tunning\n","8d64b832":">Let's further see how other attributes are related to each other using pairplot"}}