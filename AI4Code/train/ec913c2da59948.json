{"cell_type":{"948db835":"code","81e348d5":"code","0779fc84":"code","17ae747c":"code","ea9e6d3e":"code","3f4484c3":"code","cfa2b868":"code","a0fac932":"code","a3d79742":"code","8b3c746e":"code","060d45fd":"code","6a605e66":"code","ca6a4326":"code","514fe854":"code","9800bfb4":"code","c95cdd56":"code","fc4a0eec":"code","a33518b5":"code","108f2cbe":"markdown","b0af6823":"markdown","17c9e90e":"markdown","b18369fa":"markdown","e5194d93":"markdown","8d1abb08":"markdown","b57bb851":"markdown"},"source":{"948db835":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets","81e348d5":"from keras.datasets import mnist\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils.np_utils import to_categorical","0779fc84":"import cv2\nimport os\nimport glob","17ae747c":"img_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\"\ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\nX=[]\ny=[]\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.resize(img, (100,100))\n    X.append(np.array(img))\n    y.append(0)\nn_normal = len(X)","ea9e6d3e":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(X[i])\n    plt.title('Label: %i' % y[i])","3f4484c3":"img_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\"\ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.resize(img, (100,100))\n    X.append(np.array(img))\n    y.append(1)\nn_pneumonia = len(X)-n_normal","cfa2b868":"plt.figure(figsize=(10,20))\nfor i in range(0,49) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(X[n_pneumonia + i])\n    plt.title('Label: %i' % y[n_pneumonia + i])","a0fac932":"X = np.array(X)\ny = np.array(y)\n\nX = X\/255","a3d79742":"model = Sequential()\nmodel.add(Conv2D(32, (5, 5), input_shape=(100, 100, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(1))\n\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","8b3c746e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","060d45fd":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=1)","6a605e66":"scores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))\n\ndef plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.grid()\n    plt.show()\n    \nplot_scores(train)","ca6a4326":"y_cnn = model.predict_classes(X_test)","514fe854":"cm = confusion_matrix(y_cnn,y_test)\nprint(cm)","9800bfb4":"plt.figure(figsize=(15,25))\nn_test = X_test.shape[0]\ni=1\nfor j in range(len(X_test)) :\n    if (y_cnn[j] != y_test[j]) & (i<50):\n        plt.subplot(10,5,i)\n        plt.axis('off')\n        plt.imshow(X_test[j])\n        pred_classe = y_cnn[j].argmax(axis=-1)\n        plt.title('%d \/ %d' % (y_cnn[j], y_test[j]))\n        i+=1","c95cdd56":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(1))\n\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","fc4a0eec":"train = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200, verbose=1)\n\n# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","a33518b5":"plot_scores(train)","108f2cbe":"#### Entra\u00eenement du mod\u00e8le","b0af6823":"#### R\u00e9seau convolutionel simple","17c9e90e":"#### Normalisation des donn\u00e9es","b18369fa":"#### Scores","e5194d93":"## R\u00e9seau neuronel","8d1abb08":"## Lecture des donn\u00e9es","b57bb851":"#### R\u00e9seau neuronel plus complexe (avec plus de couches)"}}