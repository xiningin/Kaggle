{"cell_type":{"373dc344":"code","f7d8cbe5":"code","691960bd":"code","81cf6720":"code","8658b926":"code","6c71983d":"code","161cca6b":"code","0d557224":"code","6e8a12bc":"code","f3c2e9de":"code","3037e060":"code","3ef77b93":"code","000295bb":"code","bcc4a3be":"code","8a4ff13c":"markdown","42ab99c5":"markdown","1d9a4cb6":"markdown","7b757df6":"markdown","7d3d490e":"markdown","4e3c98f1":"markdown","d8765126":"markdown","df86d65f":"markdown","5bf6438c":"markdown","904d81cf":"markdown","538b1a25":"markdown","e47315ac":"markdown","00324f7b":"markdown","64d5a76f":"markdown","73cc6eb7":"markdown"},"source":{"373dc344":"import os\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms, models\nimport torchvision \nfrom collections import OrderedDict\nfrom torch import nn \nimport matplotlib.pyplot as plt\nimport numpy as np","f7d8cbe5":"datasets_dir = \"..\/input\/malwarerevealer3subsetimages\/malware-revealer-3subset-images\/\"\ndata1 = datasets_dir + \"data1\"\ndata2 = datasets_dir + \"data2\"\ndata3 = datasets_dir + \"data3\"\ndatasets = [\"data1\", \"data2\", \"data3\"]\ndata_path = {\n    'data1': data1,\n    'data2': data2,\n    'data3': data3,\n}","691960bd":"data_transforms = transforms.Compose([\n    transforms.Resize(224),              \n    transforms.ToTensor(),\n])\n\nimage_datasets = {\n    name: torchvision.datasets.ImageFolder(data_path[name], transform=data_transforms) for name in datasets\n}","81cf6720":"from torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.sampler import SubsetRandomSampler\nvalid_size_and_test = 0.3\n\ntargets = {name: image_datasets[name].targets for name in datasets}\n\ndataloaders = {}\nfor name in datasets:\n    train_idx, rest_idx= train_test_split(np.arange(len(targets[name])), test_size=valid_size_and_test, random_state=42, shuffle=True, stratify=targets[name])\n    test_size = int(len(rest_idx) * valid_size_and_test)\n    valid_idx, test_idx = rest_idx[:test_size], rest_idx[test_size:]\n    \n    dataloaders[name] = {\n        'trainLoader' : torch.utils.data.DataLoader(image_datasets[name], batch_size=32,sampler=SubsetRandomSampler(train_idx)),\n        'validLoader' : torch.utils.data.DataLoader(image_datasets[name], batch_size=32,sampler=SubsetRandomSampler(valid_idx)),\n        'testLoader' :  torch.utils.data.DataLoader(image_datasets[name], batch_size=32,sampler=SubsetRandomSampler(test_idx)),\n    }","8658b926":"def new_squeezenet1_1(device):\n    model = models.squeezenet1_1(pretrained=True)\n    # Customizing the squeezenet architecture\n    features = list(model.classifier.children())\n    features[1] = nn.Conv2d(model.classifier[1].in_channels, 2, kernel_size=(1,1))\n    model.classifier = nn.Sequential(*features)\n    model.num_classes = 2\n    # make sure gradient is calcualted\n    for param in model.parameters():\n        param.requires_grad = True\n    model.to(device)\n    \n    return model\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = new_squeezenet1_1(device)\nprint(model.classifier[1].in_channels)\nprint( model.classifier[1].out_channels)","6c71983d":"epochs = 90\nsteps = 0\nrunning_loss = 0\nprint_every = 26","161cca6b":"training_losses = {}\nvalidation_losses = {}\nfor name in dataloaders.keys():\n    dataloader = dataloaders[name]\n    model = new_squeezenet1_1(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adadelta(model.parameters(), lr=0.002)\n    \n    min_val_loss = np.inf\n    training_loss = []\n    validation_loss = []\n    for e in range(epochs):\n        running_loss = 0\n        model.train() \n\n        for ii, (inputs, labels) in enumerate(dataloader['trainLoader']):\n            steps += 1\n            #move the labels and inputs to the device ( GPU or CPU )\n            inputs,labels = inputs.to(device), labels.to(device)\n            # get rid of accumulated gradient \n            optimizer.zero_grad()\n\n            # Forward and backward passes\n            outputs = model.forward(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            # cumulating the loss \n            running_loss += loss.item()\n\n            if steps % print_every == 0:\n                model.eval()\n                vlost = 0\n                accuracy=0\n                # no grad because we are looping in the validation set we don't need to update the weights ( this data is not used for training the model )\n                with torch.no_grad():\n                    for ii, (inputs2,labels2) in enumerate(dataloader['validLoader']):\n\n                        optimizer.zero_grad()\n                        inputs2, labels2 = inputs2.to(device) , labels2.to(device)\n                        model.to(device)\n                        with torch.no_grad():    \n                            outputs = model.forward(inputs2)\n                            vlost = criterion(outputs,labels2)\n                            ps = torch.exp(outputs).data\n                            equality = (labels2.data == ps.max(1)[1])\n                            accuracy += equality.type_as(torch.FloatTensor()).mean()\n\n                    vlost = vlost \/ len(dataloader['validLoader'])\n                    accuracy = accuracy \/len(dataloader['validLoader'])\n                    #print some statistics \n                    training_loss.append(running_loss\/print_every)\n                    validation_loss.append(vlost)\n                    print(\"Epoch: {}\/{}... \".format(e+1, epochs),\n                          \"Training Loss: {:.4f} | \".format(running_loss\/print_every),\n                          \"Validation Lost {:.4f} | \".format(vlost),\n                           \"Accuracy: {:.4f}\".format(accuracy))\n                    # checkpointing the best model\n                    if vlost < min_val_loss:\n                        print(\"New validation loss, checkpointing ...\")\n                        min_val_loss = vlost\n                        torch.save(model.state_dict(), 'squeezenet1_1_%s.pth' % name)\n                        \n            running_loss = 0\n    \n    # saving losses for analyzing training behaviour\n    training_losses[name] = training_loss\n    validation_losses[name] = validation_loss\n\nprint(\"\\nTraining process finished \")\n \n","0d557224":"for name in training_losses.keys():\n    training_loss = training_losses[name]\n    validation_loss = validation_losses[name]\n    x = [i for i in range(len(validation_loss))]\n    plt.plot(x, training_loss)\n    plt.plot(x, validation_loss)\n    plt.legend(['training loss %s' % name, 'validation loss %s' % name], loc='upper left')\n    plt.show()","6e8a12bc":"def load_checkpointed_model(checkpoint_file):\n    if checkpoint_file == None:\n        return new_squeezenet1_1(device)\n    \n    model = new_squeezenet1_1(device)\n    state_dict = torch.load(checkpoint_file, map_location=device)\n    model.load_state_dict(state_dict)\n    model.eval()\n    return model\n\n\ndef get_overall_accuracy(model, testloader):\n    correct = 0\n    total = 0\n    total_per_label = {0: 0, 1: 0}\n    correct_per_label = {0: 0, 1: 0}\n    model.to(device)\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            zero_indices = (labels == 0).cpu()\n            one_indices = (labels == 1).cpu()\n            total_per_label[0] += np.count_nonzero(zero_indices)\n            total_per_label[1] += np.count_nonzero(one_indices)\n            correct_per_label[0] += np.count_nonzero(labels[zero_indices].cpu() == predicted[zero_indices].cpu())\n            correct_per_label[1] += np.count_nonzero(labels[one_indices].cpu() == predicted[one_indices].cpu())\n\n    print('Accuracy of the network on the test images: %d %%' % (100 * correct \/ total))\n    print(\"Benings {correct}\/{total}\".format(correct=correct_per_label[0], total=total_per_label[0]))\n    print(\"Malwares {correct}\/{total}\".format(correct=correct_per_label[1], total=total_per_label[1]))\n    \n    \nfor name in datasets:\n    checkpoint_file = \"squeezenet1_1_%s.pth\" % name\n    model = load_checkpointed_model(checkpoint_file)\n    print(\"Testing model trained on data: %s\" % name)\n    get_overall_accuracy(model, dataloaders[name]['testLoader'])","f3c2e9de":"\nclass MalwareRevealerEnsemble(nn.Module):\n    \n    def __init__(self, model_checkpoints):\n        super(MalwareRevealerEnsemble, self).__init__()\n        self.models = [load_checkpointed_model(model_checkpoint) for model_checkpoint in model_checkpoints]\n        \n        \n    def forward(self, x):\n        preds = [model(x) for model in self.models]\n        votes = preds[0]\n        for pred in preds[1:]:\n            votes += pred\n        votes \/= len(preds)\n        return votes\n        ","3037e060":"# Instanciate an ensemble of 3 models\nensemble = MalwareRevealerEnsemble([\"squeezenet1_1_%s.pth\" % name for name in datasets])","3ef77b93":"valid_dir = \"..\/input\/malware-test\/malware_revealer_test_malwares\/data_test\"\n\nvalid_image_datasets = torchvision.datasets.ImageFolder(valid_dir, transform=data_transforms)\nvalid_image_loader = torch.utils.data.DataLoader(valid_image_datasets, batch_size=32)","000295bb":"print(\"Ensemble accuracy ...\")\nget_overall_accuracy(ensemble, valid_image_loader)","bcc4a3be":"print(\"Individual models accuracy ...\")\nfor name in datasets:\n    checkpoint_file = \"squeezenet1_1_%s.pth\" % name\n    model = load_checkpointed_model(checkpoint_file)\n    print(\"Testing model trained on data: %s\" % name)\n    get_overall_accuracy(model, valid_image_loader)","8a4ff13c":"## Ensemble model","42ab99c5":"## Instanciating a pretrained Squeezenet1_1","1d9a4cb6":"## Plot some statistics about the trainings bahaviour\nThis section will help in tracking the training behaviour because ploting the data makes it so easy to see the trends and get sense about the overall trend to make decision about the next step in order to enhance the performance of the network .","7b757df6":"# Convolutional Neural Network for Malware Revealer + Ensembling","7d3d490e":"We need to adjust the final layer so it just output 2 classes","4e3c98f1":"## Tests the 3 models\nIt's mendatory to test the model on whole unseen sub set of the data to judge its performance .","d8765126":"## Train the 3 models","df86d65f":"## Load the dataset","5bf6438c":"## Load the necessary libraries ","904d81cf":"## Define the hyper parameters","538b1a25":"## Evaluating the ensemble model against individual models","e47315ac":"# Ensembling","00324f7b":"In this section, we are gonna make use of the 3 last trained model to make predictions and aggregate their result","64d5a76f":"## Split the dataset into training, validation and test set\nA good practice is to split the dataset into : \n- Training set : the weights of our neural network will be trained on this set of training examples and it will be the larger portion of the data set 70% .\n- Validation set : to measure the progress of the training and be able to tune the hyper parameters more effectively and watch out the the training progress in order to detect any underfitting or overfitting behaviours , it will be about 20% of our original data set .\n- The test set : this one will remain untouchable and will not be involved in any training ,and it's used to purely test the performance of the trained model , the size will be 10% from our original data set.","73cc6eb7":"In this notebook we trained three convolutonal neural networks based on 'SqueezeNet1_1' to classify our dataset of malwares\/benign files, the training was done on different subset of the data to use ensembling technics later.\n\nThis training part was done after preprocessing the executables, it consisted of transforming the binaries to images. You can find out more about this in our [github project](https:\/\/github.com\/youben11\/malware-revealer)."}}