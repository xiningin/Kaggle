{"cell_type":{"3288d1bf":"code","5920ad0b":"code","b88645b2":"code","a3df4cd5":"code","3a691882":"code","3a2d188a":"code","362190fc":"code","5de24970":"code","d970766f":"code","7957d3ec":"code","dcf7c801":"code","bf012e19":"code","d6806d40":"code","77ab03d0":"code","01232123":"markdown","178467a3":"markdown","fdec453f":"markdown","4f708854":"markdown"},"source":{"3288d1bf":"import os\nimport numpy as np\nimport tensorflow as tf\nimport h5py\nimport math\n\ndef load_dataset():\n    train_dataset = h5py.File('..\/input\/residualnetworks\/train_signs.h5', \"r\")\n    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n\n    test_dataset = h5py.File('..\/input\/residualnetworks\/\/test_signs.h5', \"r\")\n    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n\n    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n    \n    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n    \n    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n\n\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n    mini_batch_size - size of the mini-batches, integer\n    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    m = X.shape[0]                  # number of training examples\n    mini_batches = []\n    np.random.seed(seed)\n    \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[permutation,:,:,:]\n    shuffled_Y = Y[permutation,:]\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m\/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches\n\n\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)].T\n    return Y\n\n\ndef forward_propagation_for_predict(X, parameters):\n    \"\"\"\n    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n    \n    X -- input dataset placeholder, of shape (input size, number of examples)\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n                  the shapes are given in initialize_parameters\n    Returns:\n    Z3 -- the output of the last LINEAR unit\n    \"\"\"\n    \n    # Retrieve the parameters from the dictionary \"parameters\" \n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3'] \n                                                           # Numpy Equivalents:\n    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n    \n    return Z3\n\ndef predict(X, parameters):\n    \n    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n    \n    params = {\"W1\": W1,\n              \"b1\": b1,\n              \"W2\": W2,\n              \"b2\": b2,\n              \"W3\": W3,\n              \"b3\": b3}\n    \n    x = tf.placeholder(\"float\", [12288, 1])\n    \n    z3 = forward_propagation_for_predict(x, params)\n    p = tf.argmax(z3)\n    \n    sess = tf.Session()\n    prediction = sess.run(p, feed_dict = {x: X})\n        \n    return prediction","5920ad0b":"import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","b88645b2":"def identity_block(X, f, filters, stage, block):\n    \"\"\"\n        X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n        f -- integer, specifying the shape of the middle convolutional's window for the main path\n        filters -- python list of integers, defining the number of filters in the convolutional layers of the main path\n        stage -- integer, used to name the layers, depending on their position in the network\n        block -- string\/character, used to name the layers, depending on their position in the network\n        \n        Returns\n        X -- output of identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    F1, F2,F3 = filters\n    \n    X_shortcut = X\n    \n    #First component of main path\n    X = Conv2D(filters = F1, kernel_size= (f,f), strides = (1,1), padding='same', name = conv_name_base + '2a',\n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    \n    #Second componentj of main path\n    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding='same', name = conv_name_base + '2b',\n              kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n    \n    #Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1,1), strides=(1,1), padding='valid', name=conv_name_base+'2c', \n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n    \n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","a3df4cd5":"#convolutional_block\n\ndef convolutional_block(X, f, filters, stage, block, s =2):\n    \"\"\"\n        X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n        f -- integer, specifying the shape of the middle CONV's window for the main path\n        filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n        stage -- integer, used to name the layers, depending on their position in the network\n        block -- string\/character, used to name the layers, depending on their position in the network\n        s -- Integer, specifying the stride to be used\n\n        Returns:\n        X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    F1, F2, F3 = filters\n    \n    X_shortcut = X\n    \n    #first component of main path\n    X = Conv2D(F1, (1,1), strides = (s,s), padding='valid', name = conv_name_base + '2a',\n               kernel_initializer=glorot_uniform(seed=0))(X)\n    \n    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    #second component of main path\n    X = Conv2D(F2, (f,f), strides = (1,1), padding='same', name = conv_name_base + '2b',\n              kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n    \n    #third component of main path\n    X = Conv2D(F3, (1,1), strides=(1,1), padding='valid', name=conv_name_base + '2c',\n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n    \n    #shortcut path\n    X_shortcut = Conv2D(F3, (1,1), strides = (s,s), padding='valid', name=conv_name_base + '1',\n                       kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n    \n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","3a691882":"def ResNet50(input_shape = (64,64,3), classes=6):\n    \"\"\"\n        Implementation of the popular ResNet50 the following architecture:\n        CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n        -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n    \"\"\"\n    X_input = Input(input_shape)\n    X = ZeroPadding2D((3,3))(X_input)\n    \n    #stage 1\n    X = Conv2D(64, (7,7), strides = (2,2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name ='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3,3), strides = (2,2))(X)\n    \n    #stage 2\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage = 2, block='a', s = 1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n    \n     # Stage 3 \n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4 \n    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5 \n    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n    \n    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n    \n    X = Flatten()(X)\n    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n    return model","3a2d188a":"model = ResNet50(input_shape = (64, 64, 3), classes = 6)","362190fc":"\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","5de24970":"X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n\n\n# Normalize image vectors\nX_train = X_train_orig\/255.\nX_test = X_test_orig\/255.\n\n# Convert training and test labels to one hot matrices\nY_train = convert_to_one_hot(Y_train_orig, 6).T\nY_test = convert_to_one_hot(Y_test_orig, 6).T\n\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))","d970766f":"\nmodel.summary()","7957d3ec":"! pip install visualkeras\nimport visualkeras\n\nvisualkeras.layered_view(model)","dcf7c801":"history = model.fit(X_train, Y_train, epochs = 50,validation_split = 0.2, batch_size = 32)","bf012e19":"history.history","d6806d40":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training & validation on accuracy')\nplt.figure()\n\nplt.plot(epochs,loss)\nplt.plot(epochs,val_loss)\nplt.title('Training & validation loss')","77ab03d0":"preds = model.evaluate(X_test, Y_test)\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","01232123":"**First component of main path:**\n\n* The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\" and its name should be conv_name_base + '2a'. Use 0 as the seed for the random initialization.\n* The first BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '2a'.\n* Then apply the ReLU activation function. This has no name and no hyperparameters.\n\n\n**Second component of main path:**\n\n* The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\" and its name should be conv_name_base + '2b'. Use 0 as the seed for the random initialization.\n* The second BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '2b'.\n* Then apply the ReLU activation function. This has no name and no hyperparameters.\n\n\n**Third component of main path:**\n\n* The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\" and its name should be conv_name_base + '2c'. Use 0 as the seed for the random initialization.\n* The third BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '2c'. Note that there is no ReLU activation function in this component.\n\n\n**Final step:**\n\n* The shortcut and the input are added together.\n* Then apply the ReLU activation function. This has no name and no hyperparameters","178467a3":"# ResNet50","fdec453f":"References: \n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https:\/\/arxiv.org\/abs\/1512.03385)\n\nFrancois Chollet's github repository: https:\/\/github.com\/fchollet\/deep-learning-models\/blob\/master\/resnet50.py","4f708854":"The details of the convolutional block are as follows.\n\n*First component of main path:*\n\n* The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\" and its name should be conv_name_base + '2a'.\n* The first BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '2a'.\n* Then apply the ReLU activation function. This has no name and no hyperparameters.\n\n\n*Second component of main path:*\n\n* The second CONV2D has $F_2$ filters of (f,f) and a stride of (1,1). Its padding is \"same\" and it's name should be conv_name_base + '2b'.\n* The second BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '2b'.\n* Then apply the ReLU activation function. This has no name and no hyperparameters.\n\n\n*Third component of main path:*\n\n* The third CONV2D has $F_3$ filters of (1,1) and a stride of (1,1). Its padding is \"valid\" and it's name should be conv_name_base + '2c'.\n* The third BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '2c'. Note that there is no ReLU activation function in this component.\n\n\n*Shortcut path:*\n\n* The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\" and its name should be conv_name_base + '1'.\n* The BatchNorm is normalizing the channels axis. Its name should be bn_name_base + '1'.\n\n\n*Final step:*\n\n* The shortcut and the main path values are added together.\n* Then apply the ReLU activation function. This has no name and no hyperparameters."}}