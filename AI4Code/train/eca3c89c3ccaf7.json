{"cell_type":{"9f5e64c0":"code","ed9a49fd":"code","db4d8ff4":"code","44e1be1d":"code","31c9247a":"code","92974490":"code","49f74434":"code","2c0413e6":"code","69826634":"code","afcbc82e":"code","1549cd88":"code","feb4744f":"code","69ce7e8b":"code","fcbcaddc":"code","ffe42491":"code","f39b3685":"code","3a935c42":"code","a7cfa735":"code","83fbd64c":"code","9b3aece0":"code","afcfc86f":"code","0d9b6a16":"markdown","d809ee00":"markdown","c4287cc5":"markdown","4aba8284":"markdown","61e28b21":"markdown","50910f61":"markdown","e042123c":"markdown","517eac67":"markdown"},"source":{"9f5e64c0":"#Pytorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntorch.set_printoptions(linewidth=120)\n\n#Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cuda\")","ed9a49fd":"#transformacion, normalizacion de las imagenes y definimos los set de prueba y entrenamiento\n\ntrainset = torchvision.datasets.FashionMNIST('data', \n                                              train = True,\n                                              download = True,\n                                              transform = transforms.Compose([\n                                                 transforms.ToTensor(),\n                                                 transforms.Normalize([0.5], [0.5])\n                                             ]))\ntestset = torchvision.datasets.FashionMNIST('data', \n                                              train = False,\n                                              download = True,\n                                              transform = transforms.Compose([\n                                                 transforms.ToTensor(),\n                                                 transforms.Normalize([0.5], [0.5])\n                                              ]))                       \n\n# Definimos el tama\u00f1os de los batch, los Epoch y el rate de aprendizaje\ntrain_batch_size = 128\ntest_batch_size = 128\nlearning_rate = 0.01\ndrop_rate = 0.25\nepochs = 60\n\n# Creamos los dataloaders para el set de entrenamiento y prueba\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size,\n                                           shuffle=True\n#                                           num_workers=10\n                                           )\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n                                          shuffle=False\n#                                         num_workers=5\n                                          )\n","db4d8ff4":"# Creando las clases para los diferentes articulos de ropa para clasificar\nclasses = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n#Funcion que facilita la muestra de la imagen\n\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n      img =img.mean(dim=0) \n    img = img \/ 2 + 0.5  # desnormalizar\n    npimg = img.numpy()\n    if one_channel:\n      plt.imshow(npimg, cmap=\"Greys\")\n    else:\n      plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show\n\n#traemos alguna imegenes para demostracion \n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n#mostramos las imagenes\nmatplotlib_imshow(torchvision.utils.make_grid(images))","44e1be1d":"# Creamos una clase para el primero modelo \n\nclass Classifier(nn.Module): \n  def __init__(self):\n    super().__init__()\n    self.fc1 = nn.Linear(784, 256)\n    self.fc2 = nn.Linear(256, 128)\n    self.fc3 = nn.Linear(128, 64)\n    self.fc4 = nn.Linear(64, 10)\n\n  def forward(self, x):\n\n    x = x.view(x.shape[0],-1)\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = F.relu(self.fc3(x))\n    x = F.log_softmax(self.fc4(x), dim=1)\n\n    return x","31c9247a":"# Creamos una clase para el segundo modelo \n\nclass Classifier(nn.Module): \n  def __init__(self):\n    super(Classifier, self).__init__()\n    self.fc1 = nn.Linear(784, 256)\n    self.relu1 = nn.ReLU()\n    self.fc2 = nn.Linear(256, 128)\n    self.relu2 = nn.ReLU()\n    self.fc3 = nn.Linear(128, 64)\n    self.relu3 = nn.ReLU()\n    self.fc4 = nn.Linear(64, 10)\n    self.relu4 = nn.ReLU()\n\n  def forward(self, x):\n\n    x = x.view(x.shape[0],-1)\n    x = F.relu(self.fc1(x))\n    x = F.relu(self.fc2(x))\n    x = F.relu(self.fc3(x))\n    x = F.log_softmax(self.fc4(x), dim=1)\n\n    return x","92974490":"# Creamos una clase para el tercer modelo \n\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        self.pool = nn.MaxPool2d(2, stride = 2 )\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n\n         x = F.relu(self.conv1(x))\n         x = self.pool(F.relu(self.conv2(x)))\n         x = self.dropout1(x)\n         x = torch.flatten(x, 1)\n         x = F.relu(self.fc1(x))\n         x = self.dropout2(x)\n         x = self.fc2(x)\n         x = F.log_softmax(x, dim=1)\n         return x\n","49f74434":"# Creamos una clase para el cuarto modelo modelo \n\nclass Classifier(nn.Module):\n    def __init__(self, drop_rate = drop_rate):\n        super(Classifier, self).__init__()\n\n        self.conv1 = nn.Conv2d(1,64,3, padding = 1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.conv2 = nn.Conv2d(64,64,3, padding = 1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64,128,3, padding = 1 )\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool = nn.MaxPool2d(2, stride = 2 )\n\n        self.fc1 = nn.Linear(3*3*128, 512)\n        self.bn4 = nn.BatchNorm1d(512)\n\n        self.output = nn.Linear(512, 10)\n        self.dropout = nn.Dropout(p = drop_rate)\n        self.dropout = nn.Dropout2d(p = drop_rate)\n    \n\n    def forward(self, x):\n\n        x = x.view(-1,1,28,28)\n        x = self.pool(self.bn1(F.relu(self.conv1(x)))) \n        x = self.dropout(x)\n        x = self.pool(self.bn2(F.relu(self.conv2(x)))) \n        x = self.dropout(x)\n        x = self.pool(self.bn3(F.relu(self.conv3(x)))) \n        x = self.dropout(x)\n        x = x.view(-1, 3*3*128)\n\n        x = self.bn4(F.relu(self.fc1(x)))\n        x = self.dropout(x)\n        x = F.log_softmax(self.output(x), dim=1)\n\n        return x","2c0413e6":"# Definimos nuestra funcion de perdida y el optimizador\n\nmodel = Classifier()\n\n# Movemos el modelo al gpu si no lo estaba ya \nmodel.cuda()\n\n# Definimos la metrica de la funcion de perdida\n#criterion = nn.CrossEntropyLoss()\ncriterion = nn.NLLLoss()\n\n# Seleccionamos nuestro optimizador, usaremos el Adam optimizar o el SGD\noptimizar = optim.SGD(model.parameters(), lr=learning_rate)\n#optimizer = optim.Adam(model.parameters(), lr=earning_rate, weight_decay=1e-4)","69826634":"#ver el peso en fc1\nmodel.fc1.weight","afcbc82e":"#ver el peso en conv1\nmodel.conv1.weight","1549cd88":"#probamos el gradiante computacional\nimages, labels = iter(train_loader).next()\nlog_ps = model(images.cuda())\n\nloss = criterion(log_ps,labels.cuda())\n\nloss.backward()\n\nprint(model.fc1.weight.grad)","feb4744f":"#cargamos en tensor\nwriter = SummaryWriter('runs\/fashion_mnist')\nwriter.close()\n%load_ext tensorboard","69ce7e8b":"# traer mas imagenes de entramiento \ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# creamos un grid de las imagenes \nimg_grid = torchvision.utils.make_grid(images)\n\n# volvemos a mostrar las imagens\nmatplotlib_imshow(img_grid, one_channel=True)\n\n# Escribimos en el tensorboard\nwriter.add_image('Four_fashion_mnist_images', img_grid)","fcbcaddc":"#cargamos en tensor\nwriter.add_graph(model, images.cuda())\nwriter.close()","ffe42491":"for e in range(epochs):\n  running_loss = 0\n  model.train()\n  for images, labels in train_loader:\n    log_ps = model(images.cuda())\n    loss = criterion(log_ps, labels.cuda())\n\n    optimizar.zero_grad()\n    loss.backward()\n    optimizar.step()\n\n    running_loss += loss.item()\n  else:\n    print(f\"Perdida de entrenamiento: {running_loss\/1000}\", end=\"\")\n    writer.add_scalar('perdida de entrenamiento', running_loss \/ 100)\n\n  model.eval()\n  with torch.no_grad():\n    total = 0\n    correcto = 0\n\n    for images, labels in test_loader:\n      log_ps = model(images.cuda()).cpu()\n      mx_index = torch.argmax(log_ps, dim=1)\n      total += labels.numel()\n      correcto += (mx_index == labels).sum().item()\n\n    print(f\" La precision del test numero {e} es de {correcto \/ total * 100:.2f}%\")\nwriter.close()","f39b3685":"tensorboard --logdir=runs --port 8085","3a935c42":"# Otro metodo para visualizar las imagenes\ndef viewClassifier(img, ps, version=\"Fashion\"):\n\n  ps = ps.data.numpy().squeeze()\n\n  fig, (ax1, ax2) =plt.subplots(figsize=(6,9), ncols=2)\n  ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n  ax1.axis('off')\n  ax2.barh(np.arange(10), ps)\n  ax2.set_aspect(0,1)\n  ax2.set_yticks(np.arange(10))\n  ax2.set_yticklabels(['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'], size = 'small');\n  ax2.set_title('Probabilidad de la clase')\n  ax2.set_xlim(0,1.1)","a7cfa735":"def viewClassifier(img, ps, version=\"Fashion\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.cpu().data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    ax2.set_yticklabels(['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'], size = 'small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n    plt.tight_layout()","83fbd64c":"images, labels = next(iter(test_loader))\ntd = iter(test_loader)\nfor _ in range(15):\n  img = images[_].view(1, 784)\n# apagamos los gradiantes para acelerar el proceso\n  \n  with torch.no_grad():\n     logps = model(img.cuda())\n\n  ps = torch.exp(logps)\n  probab = list(ps.cpu().numpy()[0])\n  print(\"Classe para predecir =\", probab.index(max(probab)))\n  viewClassifier(img.view(1, 28, 28), ps)","9b3aece0":"correctos = 0\ntodos = 0\nfor images,labels in train_loader:\n  for i in range(len(labels)):\n    img = images[i].view(1, 784)\n    # apagamos los gradiantes para acelerar el proceso\n    with torch.no_grad():\n        logps = model(img.cuda())\n\n    # salida del resultado de las redes con sus prob \n    ps = torch.exp(logps)\n    probab = list(ps.cpu().numpy()[0])\n    pred_label = probab.index(max(probab))\n    true_label = labels.numpy()[i]\n    if(true_label == pred_label):\n      correctos += 1\n    todos += 1\n\nprint(\"Numero de imagenes probadas =\", todos)\nprint(\"\\nPrecision del modelo de entrenamiento =\", (correctos\/todos))","afcfc86f":"correctos = 0\ntodos = 0\nfor images,labels in test_loader:\n  for i in range(len(labels)):\n    img = images[i].view(1, 784)\n    # apagamos los gradiantes para acelerar el proceso\n    with torch.no_grad():\n        logps = model(img.cuda())\n\n    # salida del resultado de las redes con sus prob \n    ps = torch.exp(logps)\n    probab = list(ps.cpu().numpy()[0])\n    pred_label = probab.index(max(probab))\n    true_label = labels.numpy()[i]\n    if(true_label == pred_label):\n      correctos += 1\n    todos += 1\n\nprint(\"Numero de imagenes probadas =\", todos)\nprint(\"\\nPrecision del modelo prueba =\", (correctos\/todos))","0d9b6a16":"## **Muestra de ejemplos de entrenamiento** ","d809ee00":"## **Ejecicion del entrenamiento**","c4287cc5":"## **Resultados del modelo**","4aba8284":"## **Definimos la funcion de perida y el optimizador**","61e28b21":"## **Distintos modelos**","50910f61":"## **Cargamos la Data**","e042123c":"## **Establecemos el Tensorboard**","517eac67":"## **Importacion de todos los paquetes**"}}