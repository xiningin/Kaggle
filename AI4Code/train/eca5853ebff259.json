{"cell_type":{"5e9d390d":"code","27827e81":"code","280365d2":"code","5e2279fd":"code","f2f9a38f":"code","ff640365":"code","171c3fc3":"code","08e85130":"code","5e636983":"code","a6b5e87c":"code","f8e39dd8":"code","91a0fbdc":"code","9f94048e":"code","419aab95":"code","e6da88cf":"code","45da2d3a":"code","e675809b":"code","89a6d41e":"code","e3980ee1":"code","448ef76f":"code","a885d38d":"code","ca1688dc":"code","28f6a805":"code","29bc4cc6":"code","417cbd43":"code","a622f015":"code","4ff79af9":"code","eb707a2d":"code","2e08208c":"code","a44b3202":"code","511bb2fd":"code","5b89fc85":"code","2b7c5db1":"code","f8f0385e":"code","87a919cd":"code","44d2c48d":"code","9fe55ace":"code","278e99eb":"markdown","f0c101d1":"markdown","1a3370d6":"markdown","cf719cb8":"markdown","89b7593e":"markdown","99d071c4":"markdown","2c30e7f3":"markdown","488e57bf":"markdown","d1647c75":"markdown","572bf04a":"markdown","e79023fc":"markdown","2a3369ff":"markdown","239b64e7":"markdown","3a1135ef":"markdown","e3ff8634":"markdown","54d10edf":"markdown","f4d478cd":"markdown","cca0408e":"markdown","637aa179":"markdown","a74c34a0":"markdown"},"source":{"5e9d390d":"from pandas.core.computation.expressions import evaluate\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n","27827e81":"\ncredits=pd.read_csv('..\/input\/the-movies-dataset\/credits.csv')\nmovies=pd.read_csv('..\/input\/the-movies-dataset\/movies_metadata.csv')\nkeywords=pd.read_csv('..\/input\/the-movies-dataset\/keywords.csv')\n\n","280365d2":"credits['id']=credits['id'].astype('str')\nkeywords['id']=keywords['id'].astype('str')","5e2279fd":"training_df=(credits.merge(movies,on='id')).merge(keywords,on='id')","f2f9a38f":"training_df=training_df[:10000]","ff640365":"training_df.head(5)","171c3fc3":"training_df['status'].value_counts()","08e85130":"training_df=training_df[training_df['status']=='Released']\ntraining_df.drop('status', axis=1, inplace=True)","5e636983":"training_df=training_df[['title','cast','crew','genres','keywords','original_language',\n                         'popularity','release_date']]\n","a6b5e87c":"training_df.head(3)","f8e39dd8":"import unicodedata\nimport re\ndef clean_data(value):\n    value =  unicodedata.normalize('NFD', value).encode('ascii', 'ignore').decode('ascii')\n    x= str.lower(re.sub(r\"[^a-zA-Z0-9]+\", '_', value.strip().replace(\" \",\"_\")))\n    if(x!='_'):\n        return x \n    else:\n        return \" \" \n    ","91a0fbdc":" training_df.isnull().sum()","9f94048e":"training_df['original_language']=training_df['original_language'].fillna('').astype('str')\n","419aab95":"\ntraining_df['release_date'] = pd.to_datetime(training_df['release_date'], errors='coerce')\n","e6da88cf":"training_df['release_date'].head(3)","45da2d3a":"import math\ntraining_df['release_date']=training_df['release_date'].dt.year.fillna(0).astype('int')\ntraining_df['release_date']=training_df['release_date'].apply(lambda x: str(math.floor((int(x))\/ 10) * 10))\n","e675809b":"\ntraining_df['release_date'].head(3)","89a6d41e":"import ast\ntraining_df['cast']=training_df['cast'].apply(lambda s: list(ast.literal_eval(s)))","e3980ee1":"training_df['cast'] = training_df['cast'].map(lambda x: x[:3] if len(x) >=4 else x)\ntraining_df['cast']=training_df['cast'].apply((lambda cast : [ clean_data(actor['name'])  for actor in cast  if actor != '' and actor != ' ' ]))\ntraining_df.head(3)","448ef76f":"\ntraining_df['clean_title']=training_df['title'].apply((lambda title: clean_data(title)))\n","a885d38d":"def get_director(crew):\n    for man in crew :\n        if(man['job']==\"Director\"):\n            return   clean_data(man['name'])\n    return np.nan \n    \ntraining_df['crew']=training_df['crew'].apply(lambda s: list(literal_eval(s)))\ntraining_df['crew']=training_df['crew'].apply(get_director)\ntraining_df['crew']=training_df['crew'].fillna('')","ca1688dc":"training_df['genres']=training_df['genres'].apply(lambda s: list(ast.literal_eval(s)))\ntraining_df['genres']=training_df['genres'].apply((lambda genres : [ clean_data(genre['name'])  for genre in genres]))\n","28f6a805":"training_df['keywords']=training_df['keywords'].apply(lambda s: list(ast.literal_eval(s)))\ntraining_df['keywords']=training_df['keywords'].apply((lambda keywords : [ keyword['name']  for keyword in keywords]))\n\nkeywords = training_df.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\nkeywords_count = keywords.value_counts()\n\n\n","29bc4cc6":"valid_keywords=keywords_count[(keywords_count > 2) & (keywords_count<30) ]\ntraining_df['keywords'] = training_df['keywords'].apply(\n    lambda row: [clean_data(val)  for val in row if val in valid_keywords]\n)","417cbd43":"training_df.head(5)","a622f015":"training_df['bow']=training_df['cast']+training_df['keywords'] + training_df['genres']\ntraining_df['bow']=training_df['bow'].apply(lambda x: ' '.join(x))+\" \"+training_df['crew']+\" \"+training_df['clean_title']\n\n\n","4ff79af9":"training_df[\"bow\"].head(3)","eb707a2d":"training_df=training_df.reset_index(drop=True)\n","2e08208c":"directors = training_df.apply(lambda x: pd.Series(x['crew']),axis=1).stack().reset_index(level=1, drop=True)\ncast = training_df.apply(lambda x: pd.Series(x['cast']),axis=1).stack().reset_index(level=1, drop=True)\ngenres = training_df.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)\n","a44b3202":"\ndirectors=list(filter(None, directors))\ncast=list(filter(None, cast))\ngenres=list(filter(None, genres))\n\n","511bb2fd":"from scipy.spatial.distance import cosine\nimport numpy as np\n\nvectorizer = CountVectorizer(analyzer='word',min_df=0,strip_accents='ascii')\ntrain_array = vectorizer.fit_transform(training_df['bow'])\nwords_weights =  dict.fromkeys(cast, 5)\nwords_weights.update(dict.fromkeys(directors,3))\nwords_weights.update(dict.fromkeys(genres,4))\n\nfeature_names = vectorizer.get_feature_names()\nweights = np.ones(len(feature_names))\n\n\n","5b89fc85":"for key, value in words_weights.items():\n        x=feature_names.index(str(key))\n        weights[x] = value","2b7c5db1":"train_array=train_array.toarray()\ntrain_array=train_array*weights\n\n","f8f0385e":"cosine_sim = cosine_similarity(train_array, train_array)","87a919cd":"indices = pd.Series(training_df.index, index=training_df['title'])    ","44d2c48d":"def get_recommendations(title):\n    idx = indices[title].iloc[0]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:31]\n    movie_indices = [i[0] for i in sim_scores]\n    return training_df.iloc[movie_indices]['title']","9fe55ace":"get_recommendations('Titanic').head(10)","278e99eb":"I will use only 'title', 'cast', 'crew', 'genres', 'keywords', 'original_language', 'popularity' and 'release_date'. We will not rely on overview or tagline, These feature could confuse the algorithm because it could be written allegory that the computer could not understand.  ","f0c101d1":"#  Content Based Recommender System\n\n![](https:\/\/images.unsplash.com\/photo-1598899134739-24c46f58b8c0?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1476&q=80)\n\nRecommendations are playing a major role in social media, advertisement and many other applications. We will start the series with a simple content-based algorithm. You can use it to create similar movies; which are used for 'more like this' or, 'because you watched' and maybe 'recommended for you'.\n\n### What is Content Based Recomendation ?\nThe content-based Recommender extract movie metadata such as genres, cast, overview, etc. then convert them into features then find similar movies based on these features. \nThe content-Based recommender could generate bad results if you didn't utilize metadata wisely, once I got Ice Age as a recommendation because I watched Titanic!. First, you should determine specific criteria of how the recommender system will recommend. Our criteria will be to recommend movies with same features as directors, cast, genres, keywords, release date, etc. The director, genres and cast. Will have a higher weight than the other features.\n\nWe will start with importing, cleaning and preparing the data.\n","1a3370d6":"We will use the director name only from the crew. ","cf719cb8":"We have a large dataset, so it will take only the first 10000 movies for testing, using the whole dataset will cause slowness in the algorithm. You can change it as you like.  Using a small dataset will make it difficult for the algorithm to work well. So make sure to slice enough data.","89b7593e":"The cast will have (5 * original count). Mostly the actor name will appear one in each bow for a movie so the count will be 1, the reason why the actors will have the most weight is a business decision, you could say the genres should have the highest weight or maybe the director. Try to change these weights and check how the recommendations will change accordingly.","99d071c4":"Now we will contact the features into one column (bow) stands for a bag of words. So we can feed it to the algorithm.","2c30e7f3":"The main idea of this recommendations algorithm to find the most similar movies based on the features we determine earlier (cast, director, genres...etc). Popularity narrows the list to the most popular items and reduces the risk for showing items that are for particular (and maybe unpopular) tastes but remember that if a user likes unusual items more than popular items, the unusual ones would still bubble up in the list.  Our algorithm will not rerank the movies and depends on the similarity score to determine the rank.","488e57bf":"Generate one DataFrame from the three dataframes ","d1647c75":"We will only use the first three leading actors of the movie. Some movies have only one leading actor, Others have many. So we will stick with three. We will extract only the names of the cast as we mention earlier.","572bf04a":" We will only work with released movies. It does not make a scene to recommend rumoured or post-production movies.","e79023fc":"We will use clean_data method to remove any special characters in the words. Then encode them to ASCII after and use underscore between words so the algorithm will count it as one word.","2a3369ff":"Use the day and month of the release date for the movie does not make sense. We will convert the release date to release decade, so the algorithm be able to recommend movies with a similar decade.","239b64e7":"We will not use all the features(columns) from the dataset in the algorithm, for example, revenue, video homepage and many other features are irrelevant data.  Sometimes including this kind of data will decrease the algorithm accuracy. other data as cast, crew, genres need some cleaning to extract names only from them.","3a1135ef":"###Cosine Similarity  \nwe will use cosine similarity to find the similarity between movies based on the words counts in each movie. you could use other algorithms or create you on. \n\n![](https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/1d94e5903f7936d3c131e040ef2c51b473dd071d)\nExample: Let two movies M1 and M2, and cosine_similarity(M1, M2) the similarity between these two movies according to their similarity in the (bow) column:\ncosine_similarity(M1, M2)=1 if the two movies have the same words counts or if M1=M2.\ncosine_similarity(M1, M2)=0 if we do not find any common words between them.\nyou can read more about cosine similarity [here](https:\/\/en.wikipedia.org\/wiki\/Cosine_similarity) and [here](https:\/\/scikit-learn.org\/stable\/modules\/metrics.html#cosine-similaritycosine_similarity). ","e3ff8634":"We will use CountVectorizer to count the number of words in each movie which will be represented by a row and the words of all movies will be the columns, then we will use the cosine similarity function to find similar movies. but before that, we will modify the count of the (genres, cast and directors) to have a higher weight than other words in the similarity function.","54d10edf":"This kind of recommender system called white box recommender because you have the answer to why you getting these recommendations. for example in the Titanic results we got most movies with the same leading actors as Titanic. Recommender system called black box recommender system like for example collaborative filtering if it's hard to explain why we are getting these result. The more your system needs to explain, the simpler the algorithm. The better the quality of the recommendation, the more complex and harder to show explanations. This problem is known as[ model accuracy-model interpretation trade-off](https:\/\/machinelearningmastery.com\/model-prediction-versus-interpretation-in-machine-learning\/). ","f4d478cd":"References:\n1. https:\/\/www.kaggle.com\/rounakbanik\/movie-recommender-systems\n2. https:\/\/www.goodreads.com\/book\/show\/28510003-practical-recommender-systems","cca0408e":"We will only select keywords that appear more than two times and not more than 30 times, other than that it will not be a helpful keyword.","637aa179":"There is always room for improvement. The algorithm we used has many Disadvantages, for example when we use to increase the size of the data a little bit then the size of movies\/words matrix train_array will significantly increase. In the next notebook, we will try to use other recommednation algorithims stay tuned.","a74c34a0":"Some columns have been dropped from the cleaning. So we need to reset the index of the rows."}}