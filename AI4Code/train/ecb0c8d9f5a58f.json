{"cell_type":{"fdb28b50":"code","e09577ea":"code","a821a7e3":"code","9a7d5938":"code","5ddd7514":"code","2f175ce9":"code","b207b7b6":"code","3eabb09b":"code","140f442c":"code","bacc8e02":"code","247c517f":"code","5f3754b4":"code","93f37f0f":"code","0f601239":"code","955ec6e8":"code","47d61b60":"code","2f0784d8":"code","55da8a11":"code","e29f64b3":"code","27705f00":"code","35d7da34":"code","f2636d14":"code","1224d0f6":"code","0729ae60":"code","bcb8e941":"code","12e9338a":"code","0c98a939":"code","6e1ef9db":"code","49db73f1":"code","15a17368":"code","076688bf":"code","e443da82":"code","ae4c89e4":"code","07eaab21":"code","caa236d7":"code","7a808ba6":"code","cb32e259":"code","d886a97a":"code","0cc12c41":"code","ec210d21":"code","8e2ac370":"code","7ed74be8":"code","35c8268f":"code","14aa6634":"code","3cd44490":"code","f951a1bd":"code","a60407cb":"code","acac1c23":"code","047d8ec6":"code","b2808f44":"code","c1b96eb2":"code","46691d9c":"code","60800208":"code","9451a8dc":"code","ab2ce027":"code","062504dc":"code","635332af":"code","73760e85":"code","729df563":"code","e9185be2":"code","1428284a":"code","ff68086a":"code","8e0c3de2":"code","31150a8b":"code","6753f443":"code","29a631fe":"code","480d7f86":"code","068b2dbd":"code","d8d952d4":"code","4e0a81b8":"code","9a49f5ab":"code","c39b503a":"code","b0ade660":"code","a4587cee":"code","906c22af":"code","aa01d45b":"code","2bbd2764":"code","adcb3ffe":"code","526430b7":"code","10af706f":"code","a35bce19":"code","de29fe12":"code","52094501":"code","0c4314a6":"code","27d2b043":"code","f1239169":"code","e465cb17":"code","20a90ee0":"code","9076944c":"markdown","6ca78067":"markdown","d7d7b6f1":"markdown","96076320":"markdown","6278965b":"markdown","9a042243":"markdown","268e143d":"markdown","a3102461":"markdown","1bc72758":"markdown","95e3a097":"markdown","ec8273bd":"markdown","83efa978":"markdown","5543d096":"markdown"},"source":{"fdb28b50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e09577ea":"pd.set_option('display.max_rows', None)","a821a7e3":"from IPython.display import Image\nImage(url= \"https:\/\/impm.org\/wp-content\/uploads\/2020\/04\/titanic-1.jpg\")","9a7d5938":"import pandas as pd\npd.set_option('display.max_rows', 500)\ntrain=pd.read_csv('..\/input\/titanic\/train.csv')\ntest=pd.read_csv('..\/input\/titanic\/test.csv')","5ddd7514":"pd.set_option('display.max_rows', 80)\ntrain.head(80)","2f175ce9":"train.head()","b207b7b6":"train.shape","3eabb09b":"train.columns","140f442c":"test.shape","bacc8e02":"train.info()","247c517f":"test.info()","5f3754b4":"train.isnull().sum()","93f37f0f":"test.isnull().sum()","0f601239":"import matplotlib.pyplot as plt\n%matplotlib inline \nimport seaborn as sns\nsns.set()   ##set sns defaults","955ec6e8":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","47d61b60":"bar_chart('Sex')","2f0784d8":"bar_chart(\"Pclass\")","55da8a11":"bar_chart('SibSp')","e29f64b3":"bar_chart('Embarked')","27705f00":"def facet_grid(div):\n    g=sns.FacetGrid(train,col=div)\n    g.map(plt.hist,'Survived')","35d7da34":"facet_grid('Embarked')","f2636d14":"facet_grid('Sex')","1224d0f6":"facet_grid('Pclass')","0729ae60":"facet_grid('SibSp')","bcb8e941":"train.head()","12e9338a":"Image(url= \"https:\/\/static1.squarespace.com\/static\/5006453fe4b09ef2252ba068\/t\/5090b249e4b047ba54dfd258\/1351660113175\/TItanic-Survival-Infographic.jpg?format=1500w\")","0c98a939":"train.head(10)","6e1ef9db":"train_test_data = [train, test] # combining train and test dataset","49db73f1":"for dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","15a17368":"train['Title'].value_counts()\n","076688bf":"test['Title'].value_counts()","e443da82":"title_mapping= {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title']=dataset['Title'].map(title_mapping)","ae4c89e4":"train.head()","07eaab21":"test.head()","caa236d7":"bar_chart('Title')","7a808ba6":"train.drop('Name',axis=1,inplace=True)\ntest.drop('Name',axis=1,inplace=True)","cb32e259":"train.head()","d886a97a":"test.head()","0cc12c41":"sex_mapping={'male':0,'female':1}\nfor dataset in train_test_data:\n    dataset['Sex']=dataset['Sex'].map(sex_mapping)\n    \n    ","ec210d21":"bar_chart('Sex')","8e2ac370":"train.groupby(\"Title\")[\"Age\"].transform('median')","7ed74be8":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)  #first grouped by then median is done and all the grouped are back into place with the same values (ie replced wth median) and inside fillna is a dataframe and it matches in index inside and out\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","35c8268f":"\ntrain.head(30)\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","14aa6634":"g=sns.FacetGrid(train,hue='Survived',aspect=4)  ##aspect made the graph spread out ##shows the graphs in the same graph rows annd columns separately draw graph where as hue draws in the same graph\ng.map(sns.kdeplot,'Age',shade=True)  ##density plot\ng.set(xlim=(0,train['Age'].max()))\ng.add_legend()\n\nplt.show()","3cd44490":"train.info()","f951a1bd":"test.info()","a60407cb":"##for dataset in train_test_data:\n##    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n##    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1\n##    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2\n##    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3\n##    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","acac1c23":"train.head()","047d8ec6":"bar_chart('Age')","b2808f44":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","c1b96eb2":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","46691d9c":"train.head()","60800208":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","9451a8dc":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(50)","ab2ce027":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","062504dc":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","635332af":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","73760e85":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","729df563":"##for dataset in train_test_data:\n##    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n##    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n##    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n##    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","e9185be2":"train.head()","1428284a":"train.Cabin.value_counts()","ff68086a":"\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","8e0c3de2":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","31150a8b":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","6753f443":"\n# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","29a631fe":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","480d7f86":"\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","068b2dbd":"family_mapping = {1: 0, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","d8d952d4":"train.head()","4e0a81b8":"\nfeatures_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","9a49f5ab":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","c39b503a":"train_data.head(10)","b0ade660":"\n# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","a4587cee":"train.info()","906c22af":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","aa01d45b":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","2bbd2764":"# kNN Score\nround(np.mean(score)*100, 2)","adcb3ffe":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","526430b7":"\n# decision tree Score\nround(np.mean(score)*100, 2)","10af706f":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","a35bce19":"# Random Forest Score\nround(np.mean(score)*100, 2)","de29fe12":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","52094501":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","0c4314a6":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","27d2b043":"round(np.mean(score)*100,2)","f1239169":"clf = RandomForestClassifier(n_estimators=13)\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","e465cb17":"\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","20a90ee0":"submission = pd.read_csv('submission.csv')\nsubmission.head()","9076944c":"# # > > **Collecting the data**","6ca78067":"# ****. Modelling","d7d7b6f1":"#  Feature engineering","96076320":"this chart confirms that 1st class is more likely survived than other classes\n\n 3rd class is more likely dead than others","6278965b":"# pyhton for visualization","9a042243":"this shows that women are more likely to survive than men","268e143d":"# Bar Chart for Categorical Features\n.Pclass\n\n.Sex\n\n.SibSp ( # of siblings and spouse)\n\n.Parch ( # of parents and children)\n\n.Embarked\n\n.Cabin","a3102461":"fillna + groupby + transform + mean\nThis seems intuitive:\n\ndf['value'] = df['value'].fillna(df.groupby('name')['value'].transform('mean'))\nThe groupby + transform syntax maps the groupwise mean to the index of the original dataframe. This is roughly equivalent to @DSM's solution, but avoids the need to define an anonymous lambda function.","1bc72758":"# EXPLORATORY DATA ANALYSIS# # ","95e3a097":"# \n# Data Dictionary\n# Survived: 0 = No, 1 = Yes\n# pclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n# sibsp: # of siblings \/ spouses aboard the Titanic\n# parch: # of parents \/ children aboard the Titanic\n# ticket: Ticket number\n# cabin: Cabin number\n# embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton","ec8273bd":"all of the code below has been followed so i would not recommend watching it right now probably later","83efa978":"1. # Feature engineering is the process of using domain knowledge of the data\n1. # to create features (feature vectors) that make machine learning algorithms work.\n1. # \n1. # feature vector is an n-dimensional vector of numerical features that represent some object.\n1. # Many algorithms in machine learning require a numerical representation of objects,\n1. # since such representations facilitate processing and statistical analysis.","5543d096":"# Filling missing values"}}