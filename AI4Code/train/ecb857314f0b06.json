{"cell_type":{"29598ee7":"code","745b1c8e":"code","279003a4":"code","5f309680":"code","9b2cd0ac":"code","980dcd06":"code","a62c8699":"code","106d2200":"code","031f0a45":"code","10f75aa3":"code","5eeae4d9":"code","30d7a7cf":"code","ff43db12":"code","dc1af15b":"code","46aa03b3":"code","3183b674":"code","45810513":"code","f99df08c":"code","5b65eb66":"code","5bc17dff":"code","ccc0c15b":"code","7855b64a":"code","0736aeda":"code","bdd54414":"code","83038f14":"code","48a1801c":"code","db85e7eb":"code","123b02c1":"code","a6ce1ffc":"code","b8d44432":"code","28a3cea5":"code","1893e221":"code","e0f18160":"code","46978a3b":"code","dda7bd96":"code","19f2ad71":"code","8c8e53fe":"code","bb10b9d6":"code","3e68f933":"code","3dc4ba9e":"code","14217379":"code","f94bcbba":"code","9454cf97":"code","c2d74199":"code","5a615a4e":"code","04fdd40c":"code","6a50ab9a":"code","1f32d6cc":"code","220736dc":"markdown","d4d06840":"markdown","8f59f138":"markdown","2ff31bb7":"markdown","5c2d6052":"markdown","b83f0758":"markdown","58573cef":"markdown"},"source":{"29598ee7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom matplotlib import pyplot as plt\nimport seaborn as sns \n%matplotlib inline \nimport os\nimport matplotlib as mpl\nfrom pandas import Series\nimport re\n#Pas de message d'alertes\nimport warnings\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.","745b1c8e":"df = pd.read_csv(\"..\/input\/train.csv\")  \nxtest=pd.read_csv('..\/input\/xtest.csv')","279003a4":"\ndf.sample(5)","5f309680":"\ndf.dtypes","9b2cd0ac":"\ndf['author']=df['author'].astype('object')","980dcd06":"df.columns","a62c8699":"#Regardons les vleurs manquantes \ndf.isnull().sum()","106d2200":"#Statistiques descriptives des variables quantitatives \ndf_qual=df.select_dtypes(exclude=['object'])\ndf_qual.describe().plot(kind = \"area\",fontsize=22, figsize = (18,8), table = True,colormap=\"rainbow\")\nplt.xlabel('',)\nplt.ylabel('Value')\nplt.title(\"Statistiques g\u00e9n\u00e9rales des variables \")","031f0a45":"df1=df\ndf1['author']=df1['author'].astype('object')\ndf1['author'][df1['author'] == '0' ] = 'Trump'\ndf1['author'][df1['author'] == '1' ] = 'Clinton'\nf,ax=plt.subplots(1,2,figsize=(16,7))\ndf['author'].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('df1 author Count')\nax[0].set_ylabel('Count')\nsns.countplot('author',data=df,ax=ax[1])\nax[1].set_title('df1 author Count')\nplt.show()","10f75aa3":"#Description des variables quantitatives \ndf.select_dtypes(exclude='object').describe()","5eeae4d9":"#description des variables quantitatives \ndf.select_dtypes(include='object').describe()","30d7a7cf":"df2=df[['retweet_count', 'favorite_count', 'author']]\ndf2['author'] = df2['author'].astype('object')\ndf2['author'][df2['author'] == 1 ] = 'Trump'\ndf2['author'][df2['author'] == 0 ] = 'Clinton'\nfig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.stripplot(x='author',\n                  y='favorite_count',data=df2,jitter=True,\n                  edgecolor='gray',size=8,palette='winter',orient='v')","ff43db12":"df2=df[['retweet_count', 'favorite_count', 'author']]\ndf2['author'] = df2['author'].astype('object')\ndf2['author'][df2['author'] == 1 ] = 'Trump'\ndf2['author'][df2['author'] == 0 ] = 'Clinton'\nfig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.stripplot(x='author',\n                  y='retweet_count',data=df2,jitter=True,\n                  edgecolor='gray',size=8,palette='winter',orient='v')","dc1af15b":" data=df[['author', 'text', 'favorite_count']] \ndata['author'][data['author'] == 1 ] = 'Trump'\ndata['author'][data['author'] == 0 ] = 'Clinton'","46aa03b3":"data.sample(5)","3183b674":"\nsns.factorplot('author','favorite_count',data=df)\nplt.ioff()\nplt.show()","45810513":"\nmpl.rcParams['patch.force_edgecolor'] = True\nplt.style.use('seaborn-bright')\ndf.hist(column='favorite_count', by='author', bins=50,figsize=(11,5))","f99df08c":"import nltk\nfrom wordcloud import WordCloud,STOPWORDS\nimport re\nfrom nltk.corpus import stopwords\n#nltk.download('stopwords')","5b65eb66":"def cleanedWords(raw_sentence):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_sentence)\n    words = letters_only.lower().split()                            \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words\n                       if w not in stops]\n    return meaningful_words","5bc17dff":"#sms=tweet\n#cr\u00e9ation de la base tweet\ntweet=data[['text','author']]\n#fonction de code en binaire 0\/1\ndef transformSpamColumn(x):\n    if x=='Clinton':\n        return 0\n    return 1\n#appication de la fonction sur tweet['author']\ntweet['author']=tweet['author'].apply(transformSpamColumn)","ccc0c15b":"def getWordCloud(data, author):\n    data=data[data['author'] == author]\n    words = ' '.join(df['text'])\n    cleaned_word = \" \".join(cleanedWords(words))\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     )\n    wordcloud.generate(cleaned_word)\n    plt.figure(1,figsize=(12, 12))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","7855b64a":"#les mots les plus fr\u00e9quent de Trump\ngetWordCloud(tweet,1)","0736aeda":"#Les mots plus fr\u00e9quents de Clinton\ngetWordCloud(tweet,0)","bdd54414":"from textblob import TextBlob\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import learning_curve, GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split \n#from sklearn.cross_validation import StratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier \n\nimport calendar\nimport datetime\nimport re","83038f14":"messages = df[['author','text']]\ntest = xtest[['text']] \nmessages.columns = ['label', 'message']\ntest.columns = ['message']","48a1801c":"print(messages[:5])","db85e7eb":"def split_into_tokens(message):\n    message = message  # convert bytes into proper unicode\n    return TextBlob(message).words","123b02c1":"messages.message.head()","a6ce1ffc":"messages.message.apply(split_into_tokens).head()","b8d44432":"# nltk.download('wordnet')\ndef split_into_lemmas(message):\n    message = message.lower()\n    words = TextBlob(message).words\n    # for each word, take its \"base form\" = lemma \n    return [word.lemma for word in words]\n\nmessages.message.apply(split_into_lemmas).head()","28a3cea5":"bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(messages['message'])\nprint(len(bow_transformer.vocabulary_))\nprint(bow_transformer.get_feature_names()[:5])","1893e221":"messages_bow = bow_transformer.transform(messages['message'])\nprint('sparse matrix shape:', messages_bow.shape)\nprint('number of non-zeros:', messages_bow.nnz)\nprint('sparsity: %.2f%%' % (100.0 * messages_bow.nnz \/ (messages_bow.shape[0] * messages_bow.shape[1])))","e0f18160":"tfidf_transformer = TfidfTransformer().fit(messages_bow)","46978a3b":"print (tfidf_transformer.idf_[bow_transformer.vocabulary_['the']])\nprint (tfidf_transformer.idf_[bow_transformer.vocabulary_['hannity']])","dda7bd96":"messages_tfidf = tfidf_transformer.transform(messages_bow)\nprint(messages_tfidf.shape)","19f2ad71":" messages['label'] = messages['label']\n messages['label'] =  messages['label'].astype('int64')","8c8e53fe":"spam_detector = SVC(kernel='sigmoid', gamma=1.0).fit(messages_tfidf,  messages['label'])","bb10b9d6":"all_predictions = spam_detector.predict(messages_tfidf)","3e68f933":"tr_acc = accuracy_score(messages['message'], all_predictions)\n#print(\"Accuracy on training set:  %.2f%%\" % (100 * tr_acc))","3dc4ba9e":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=split_into_lemmas)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', SVC(kernel='sigmoid', gamma=1.0)),  # train on TF-IDF vectors w\/ Naive Bayes classifier\n])        ","14217379":"scores = cross_val_score(pipeline,  # steps to convert raw messages into models\n                         messages['message'], # training data\n                         messages['label'],  # training labels\n                         cv=10,  # split data randomly into 10 parts: 9 for training, 1 for scoring\n                         scoring='accuracy',  # which scoring metric?\n                         n_jobs=-1,  # -1 = use all cores = faster\n                         )\nprint(scores)","f94bcbba":"print(classification_report(messages['label'], all_predictions))","9454cf97":"print('Mean score:', scores.mean(), '\\n')\nprint('Stdev:', scores.std())","c2d74199":"skf = StratifiedKFold(n_splits=5)\nparams = {\n    'tfidf__use_idf': (True, False),\n    'bow__analyzer': (split_into_lemmas, split_into_tokens),\n}\n\ngrid = GridSearchCV(\n    pipeline,  # pipeline from above\n    params,  # parameters to tune via cross validation\n    refit=True,  # fit using all available data at the end, on the best found param combination\n    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\"\n    scoring='accuracy',  # what score are we optimizing?\n    cv=StratifiedKFold( n_splits=5),  # what type of cross validation to use\n)\n\n%time nb_detector = grid.fit(messages['message'], messages['label'])\nprint(nb_detector.cv_results_)","5a615a4e":"from sklearn.model_selection import GridSearchCV\nnb_detector.cv_results_","04fdd40c":"predictions = nb_detector.predict(test['message'])","6a50ab9a":"print(predictions.shape[0])","1f32d6cc":"predictions = pd.Series(predictions)\npredictions.index = range(predictions.shape[0])\npredictions.to_csv(\"predictions.csv\", index_label =\"index\", header = [\"prediction\"])","220736dc":" Dans notre base donn\u00e9es df, il n'y a aucune valeurs manquantes ","d4d06840":"En moyenne  Trump \u00e0 plus de favorite_count que Clinton ","8f59f138":"Soumission ","2ff31bb7":"1. D'apr\u00e8s ce graphique les twet de Clinton sont plus longue en moyenne que ceux de Trump ","5c2d6052":"# Textmining Tweets Trump vs Clinton","b83f0758":"Dans la  base de donn\u00e9e, nous avons 50% de tweet fait par Clinton et 50% fait par Trump","58573cef":"# Partie Mod\u00e9lisation "}}