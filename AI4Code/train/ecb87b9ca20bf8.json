{"cell_type":{"b25bde4c":"code","1d30d37c":"code","68bad65e":"code","0d56a329":"code","599ccd91":"code","ef58a916":"code","9e4ef328":"code","232b113d":"code","1d586472":"code","3289a0b7":"code","1ff51d00":"code","392c29a2":"markdown"},"source":{"b25bde4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1d30d37c":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head(10)\ntrain_data.tail(10)\n\ntrain_data.query('Cabin == Cabin').shape\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","68bad65e":"len(train_data.loc[(train_data.Sex == 'female') & (train_data.Survived == 1)][\"Survived\"])\ntrain_data.loc[:,[\"Name\", \"Age\", \"Pclass\"]]\ntrain_data[[\"Name\", \"Age\", \"Pclass\"]]\n\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)\n\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived=\", rate_men)","0d56a329":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\nactual = model.predict(X)\npredictions = model.predict(X_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('my_submission.csv', index=False)\nprint ( \"X data accuracy: \" , round(accuracy_score(y, actual) * 100, 2), \"%\" )\n#print(\"Your submission was successfully saved!\")","599ccd91":"##############################################\n######    \ubcc0\uc218 \ucd94\uac00 Age Fare Cabin     ########\n# X data accuracy:  84.4 %\n#     77.5%\n##############################################\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"] # class \ubcc0\uc218\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nX['Age'] = train_data['Age']\nX['Fare'] = train_data['Fare']\nX['Cabin'] = np.where(train_data['Cabin'].isna()==True,0,1)\n#np.where(\uc870\uac74, \ucc38\uac12, \uac70\uc9d3\uac12)\n\nX.groupby('Cabin').count()\n\nX_test['Age'] = test_data['Age']\nX_test['Fare'] = test_data['Fare']\nX_test['Cabin'] = np.where(test_data['Cabin'].isna()==True,0,1)\n#X.isna().sum()\nX['Age'] = X['Age'].fillna(X['Age'].mean())\n\nX_test['Age'] = X_test['Age'].fillna(X_test['Age'].mean())\nX_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].mean())\n\nmodel = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=1)\nmodel.fit(X, y)\nactual = model.predict(X)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint ( \"X data accuracy: \" , round(accuracy_score(y, actual) * 100, 2), \"%\" )\nprint(\"Your submission was successfully saved!\")","ef58a916":"X","9e4ef328":"#[age if age > 10 else 10 for age in X['Age']]\n\n#new_age = []\n#for age in X['Age']:\n#    if age > 10:\n#        new_age.append(age)\n#    else:\n#        new_age.append(10)\n","232b113d":"    \n# Logistic regression\n# Gradient Boosting\n# SVM\n# Deep learning\n\n############################\n### Logistic regression \n### X data accuracy:  80.36 %\n## test data : 75%\n############################\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n#model = LogisticRegression(C=1000.0, random_state=7)\n#model.fit(X, y)\n\n#actual = model.predict(X)\n#predictions = model.predict(X_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('my_submission.csv', index=False)\n\n#print ( \"X data accuracy: \" , round(accuracy_score(y, actual) * 100, 2), \"%\" )\n#print(\"Your submission was successfully saved!\")","1d586472":"##########################\n### XGBOOST  \n### X data accuracy:  93.71%\n## test data : 73.2%\n##########################\n\nfrom xgboost import plot_importance\nfrom xgboost import XGBClassifier\n\n#model = XGBClassifier(n_estimators=500, learning_rate=0.1, max_depth=5)\n#model.fit(X, y)\n#actual = model.predict(X)\n#predictions = model.predict(X_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('my_submission.csv',index=False)\n\n#print ( \"X data accuracy: \" , round(accuracy_score(y, actual) * 100, 2), \"%\" )\n#print(\"Your submission was successfully saved!\")","3289a0b7":"############################\n###          SVM         \n### X data accuracy:  78.68 %\n## test data : 76.5%\n############################\n\n\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\n\n#model = svm.SVC(kernel = 'linear')\n#model.fit(X, y)\n\n#actual = model.predict(X)\n#predictions = model.predict(X_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('my_submission.csv', index=False)\n\n#print ( \"X data accuracy: \" , round(accuracy_score(y, actual) * 100, 2), \"%\" )\n#print(\"Your submission was successfully saved!\")","1ff51d00":"######################################\n###          Deep Learning \n###      X data accuracy:  78.68 % \n## test data : \n######################################\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nnp.random.seed(7)\n\n#model = Sequential()\n#model.add(Dense(255, input_shape=(8,), activation='relu'))\n#model.add(Dense((1), activation='sigmoid'))\n#model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n#model.summary()\n\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\n#SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n#hist = model.fit(X, y,epochs=100)\n\nimport matplotlib.pyplot as plt\n\n#predictions = model.predict(X_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.ravel()})\n#output.to_csv('my_submission.csv', index=False)\n\n#print ( \"X data accuracy: \" , round(accuracy_score(y, actual) * 100, 2), \"%\" )\n#print(\"Your submission was successfully saved!\")\n","392c29a2":"predictions"}}