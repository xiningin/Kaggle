{"cell_type":{"5b1598f3":"code","670da1b8":"code","81fc0f78":"code","b75d48e4":"code","c793e4dd":"code","7453ad7f":"code","b3192794":"code","73bc9ded":"code","a78faaba":"code","bb9d0137":"code","979c1782":"code","7c86359c":"code","a47a7916":"code","cdd0bc12":"code","17d80ca7":"code","5f222e04":"code","86e2b669":"code","3298dc97":"code","8bf4cb64":"code","b4e20ae0":"code","78d18ce5":"markdown","4460dd8c":"markdown","0a245e72":"markdown","8a02e282":"markdown","78b77c58":"markdown"},"source":{"5b1598f3":"import pandas as pd\nimport numpy as np\nimport math, re, os\nimport random\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nprint(\"Tensorflow version \" + tf.__version__)\nimport tensorflow.keras.backend as K\nimport tensorflow_addons as tfa","670da1b8":"path = '..\/input\/cloud-anomaly-detection-images\/noncloud\/noncloud'\npath2 = '..\/input\/cloud-anomaly-detection-images\/cloud\/cloud'","81fc0f78":"all_images=[]\nimport os\nimg_list = os.listdir(path)\nfor i in tqdm(img_list):\n    img = tf.keras.preprocessing.image.load_img(path+'\/'+str(i), target_size=(384,384,3))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = img\/255.\n    all_images.append(img)\n    \nall_images= np.array(all_images)\nall_images.shape","b75d48e4":"IMAGE_SIZE = [384,384]\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\nn_hidden_1 = 512\nn_hidden_2 = 256\nn_hidden_3 = 64\nn_hidden_4 = 16\nn_hidden_5 = 8\nconvkernel = (3, 3)  # convolution kernel\npoolkernel = (2, 2)  # pooling kernel","c793e4dd":"X_train, X_test = train_test_split(all_images, test_size=0.2, random_state=SEED)\nprint(X_train.shape, X_test.shape)","7453ad7f":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","b3192794":"def get_vgg19():\n    K.clear_session()\n    with strategy.scope():\n        image_input = tf.keras.layers.Input(shape = (*IMAGE_SIZE,3))\n        vg19 = tf.keras.applications.VGG19(input_tensor = image_input, weights = 'imagenet', include_top=False)\n        encoded = vg19.get_layer('block5_pool').output\n        #decode\n        x = tf.keras.layers.Conv2DTranspose(n_hidden_5, convkernel, strides=2, activation='relu', padding='same')(encoded)\n        x = tf.keras.layers.Conv2DTranspose(n_hidden_4, convkernel, strides=2, activation='relu', padding='same')(x)\n        x = tf.keras.layers.Conv2DTranspose(n_hidden_3, convkernel, strides=2, activation='relu', padding='same')(x)\n        x = tf.keras.layers.Conv2DTranspose(n_hidden_2, convkernel, strides=2, activation='relu', padding='same')(x)\n        x = tf.keras.layers.Conv2DTranspose(n_hidden_1, convkernel, strides=2, activation='relu', padding='same')(x)\n        decoded = tf.keras.layers.Conv2DTranspose(3, convkernel, activation=\"sigmoid\", padding='same')(x)\n        model = tf.keras.models.Model(inputs = image_input, outputs = decoded)\n        opt = tfa.optimizers.RectifiedAdam(lr=3e-4)\n        model.compile(\n            optimizer = opt,\n            loss = 'mse',\n            metrics = [tf.keras.metrics.RootMeanSquaredError()]\n        )\n        return model","73bc9ded":"model= get_vgg19()","a78faaba":"model.load_weights('..\/input\/model-encoder\/Enc.h5')","bb9d0137":"model.summary()","979c1782":"cld_images=[]\nimport os\nimg_list = os.listdir(path2)\nfor i in tqdm(img_list):\n    img = tf.keras.preprocessing.image.load_img(path2+'\/'+str(i), target_size=(384,384,3))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = img\/255.\n    cld_images.append(img)\n    \ncld_images= np.array(cld_images)\ncld_images.shape","7c86359c":"n = 5\nplt.figure(figsize= (20,10))\n\nfor i in range(n):\n    ax = plt.subplot(2, n, i+1)\n    plt.imshow(cld_images[i+50])\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    ax = plt.subplot(2, n, i+1+n)\n    plt.imshow(cld_images[i+30])\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()","a47a7916":"test_predictions =  model.predict(np.concatenate((X_test[:100], cld_images), axis=0))","cdd0bc12":"pred = []\nfor i in (tf.keras.losses.mean_squared_error(np.concatenate((X_test[:100], cld_images), axis=0), test_predictions)).numpy():\n    pred.append(tf.math.reduce_mean(i).numpy())","17d80ca7":"y_cap=[]\nthreshold=0.001\nfor i in pred:\n    if i> threshold:\n        y_cap.append(1)\n    else:\n        y_cap.append(0)","5f222e04":"pd.value_counts(y_cap)","86e2b669":"actual = [0 for i in range(0,len(X_test[:100]))]+[1 for i in range(0,len(cld_images))]","3298dc97":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(actual, y_cap)\nimport seaborn as sns\nimport matplotlib.pyplot as plt     \nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); ","8bf4cb64":"score = pd.DataFrame()\nscore['matrix'] = ['F1_score','Recall','Precision']\nscore['Values'] = [(f1_score(actual,y_cap)),(recall_score(actual,y_cap)),(precision_score(actual,y_cap))]","b4e20ae0":"score","78d18ce5":"# Threshold is defined based on training loss. \n![image.png](attachment:image.png)","4460dd8c":"# Reconstruction loss\n\nThe entire network is usually trained as a whole. The loss function is usually either the mean-squared error or cross-entropy between the output and the input, known as the reconstruction loss, which penalizes the network for creating outputs different from the input.\n\n![image.png](attachment:image.png)","0a245e72":"![image.png](attachment:image.png)","8a02e282":"# You can find the training code [here](https:\/\/www.kaggle.com\/kishor1210\/autoencoders-for-anomaly-detection-training)","78b77c58":"![image.png](attachment:image.png)"}}