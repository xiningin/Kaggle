{"cell_type":{"d2da9518":"code","c0139733":"code","53f6e4bd":"code","4780921d":"code","3605d172":"code","cc9001ba":"code","4ddb5842":"code","02f430d4":"code","d6379717":"code","8eba501f":"code","f062cb21":"code","a3a448c9":"code","6cf2bd23":"code","33427e7d":"code","6e954ed5":"code","67bf83da":"code","32fd379d":"code","39d47610":"code","3e031185":"code","bb8fe5dd":"code","4a0d4e0b":"code","98e189de":"code","694cc253":"code","a387c4ee":"code","f69d0d59":"code","bd128157":"code","b5ae1e27":"code","976a7471":"code","9c98cf91":"code","d104531b":"code","17b8cce8":"code","82983596":"code","1be37e59":"code","99ff7683":"code","bdf02186":"code","19ba0e18":"code","45ce4499":"code","6ed37d48":"code","1729fd5b":"code","78c100c6":"markdown","c9caf268":"markdown","17daf80d":"markdown","b09d3a07":"markdown","b5cad0d9":"markdown","33812d25":"markdown","a1162276":"markdown","fd204ed1":"markdown","2ce621f5":"markdown","2b062d30":"markdown","84713657":"markdown","7bfe0ed6":"markdown","051b29f4":"markdown","943610a7":"markdown","a0e274cd":"markdown","767a4308":"markdown","2c125772":"markdown","bcdc65ad":"markdown","862d7bca":"markdown"},"source":{"d2da9518":"import sys\n!{sys.executable} -m pip install ..\/input\/pydicomfastaihelper\/torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl -q\n!{sys.executable} -m pip install ..\/input\/pydicomfastaihelper\/torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl -q\n!{sys.executable} -m pip install ..\/input\/pydicomfastaihelper\/fastcore-1.3.26-py3-none-any.whl -q\n!{sys.executable} -m pip install ..\/input\/pydicomfastaihelper\/fastai-2.5.2-py3-none-any.whl -q","c0139733":"# from Awsaf pydicom_conda_helper\n!conda install '\/kaggle\/input\/pydicomfastaihelper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicomfastaihelper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicomfastaihelper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicomfastaihelper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicomfastaihelper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicomfastaihelper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","53f6e4bd":"import os\nimport PIL\nimport cv2\nimport tarfile\nimport numpy as np\nimport pydicom\nimport pandas as pd\nfrom glob import glob\nimport nibabel as nib\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage as ndi\nfrom tqdm.notebook import tqdm\nimport shutil\n\nimport random\nrandom.seed(42)\n\nfrom pathlib import Path","4780921d":"def normalize_contrast(voxel):\n    if voxel.sum() == 0:\n        return voxel\n    voxel = voxel - np.min(voxel)\n    voxel = voxel \/ np.max(voxel)\n    voxel = (voxel * 255).astype(np.uint8)\n    return voxel\n\ndef load_nii(study_id, scan_type):\n    fn = f'{data_folder}\/BraTS2021_{study_id}\/BraTS2021_{study_id}_{scan_type}.nii.gz'\n    if Path(fn).is_file():\n        nii = nib.load(fn).get_fdata()\n        nii = normalize_contrast(nii)\n        return nii\n    else:\n        print(fn)\n        return None","3605d172":"min_brain = 1000\ndata_folder = '..\/input\/task1-output\/data'\n\nif not os.path.isdir(\"\/kaggle\/working\/slices\"):\n    os.makedirs(\"\/kaggle\/working\/slices\", exist_ok=True)\n    \ncollect = []\ncase_dirs = Path(data_folder).iterdir()\ncase_dirs = [_ for _ in case_dirs]\n\nfor case in tqdm(case_dirs, total =len(case_dirs)):\n    seg_files = [_ for _ in case.glob(\"*_seg.nii.gz\")]\n    \n    if len(seg_files) > 0:\n        seg = nib.load(seg_files[0]).get_fdata()\n        #Labels 1 and 4 are tumor labels\n        labels = [1* (((seg[:,:,o] == 1).sum() + (seg[:,:,o] == 4).sum()) > 0) for o in range(seg.shape[-1])]\n\n        study_id= str(case).split('_')[1]\n        nii = load_nii(study_id, 't1ce')\n\n        for i in range(0,nii.shape[-1],3):\n            if (nii[:,:,i] > 0).sum() > min_brain:\n                save_fn = f'slices\/{study_id}_{i}.jpg'\n                collect.append({'filename':save_fn, 'study_id': study_id, 'slice': i, 'has_tumor': labels[i]})\n                #Rotate\n                rot = np.rot90(nii[:,:,i],3)\n                img = Image.fromarray(rot)\n                img = img.convert(\"L\")\n                img.save(save_fn)\n    \n\ncollect = pd.DataFrame(collect)\ncollect.to_csv('.\/tumor_slices_brats_axial_thirds.csv',index=False)\ncollect.head()","cc9001ba":"collect.has_tumor.value_counts()","4ddb5842":"#!pip install fastai --upgrade -q","02f430d4":"models_data_root = Path('models\/')\nmodels_data_root.mkdir(parents=True, exist_ok=True)\n\ncwd = '\/kaggle\/working\/'","d6379717":"from fastai.vision.all import *\n\nbs = 64\n\ndf = collect[['filename', 'has_tumor']]\n\ndls = ImageDataLoaders.from_df(df, path=cwd, bs=bs, item_tfms=Resize(224), batch_tfms=[ *aug_transforms()])\ndls.vocab","8eba501f":"learn = cnn_learner(dls, resnet50,loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[accuracy])\nlearn.fine_tune(20)","f062cb21":"tumor_slice_model_name = Path.joinpath(models_data_root, 'tumor_slice.pkl')\nlearn.export(tumor_slice_model_name)","a3a448c9":"#remove training folder\nshutil.rmtree('slices') ","6cf2bd23":"# Voxel from dicom from \"Normalized Voxels: Align Planes and Crop\" by yu4u\n    # https:\/\/www.kaggle.com\/ren4yu\/normalized-voxels-align-planes-and-crop\/data\n    # https:\/\/www.kaggle.com\/arnabs007\/part-1-rsna-miccai-btrc-understanding-the-data\n    # https:\/\/www.kaggle.com\/davidbroberts\/determining-mr-image-planes\n    \nclass Voxel:\n    def __init__(self,study_id, dicom_folder, save_data_folder, icon_size):\n\n        self.study_id=study_id\n        self.dicom_folder=dicom_folder\n        self.save_data_folder=save_data_folder\n        self.icon_size=icon_size\n\n    def get_voxel_data_root(self):\n        return Path(self.save_data_folder).joinpath(f'voxels_{self.icon_size}')\n\n    def get_voxel_prepared(self):\n        #\/kaggle\/working\/data\/voxels_128\/{study_id}\/{scan_type}.npy\n        fn = f'{self.get_voxel_data_root()}\/{self.study_id}\/{Path(self.dicom_folder).parts[-1]}.npy'\n        if os.path.isfile(fn) == False:\n            self.create_and_save_voxels()\n        voxel = np.load(fn)\n        return voxel\n\n    def get_image_plane(self, data):\n        x1, y1, _, x2, y2, _ = [round(j) for j in data.ImageOrientationPatient]\n        cords = [x1, y1, x2, y2]\n\n        if cords == [1, 0, 0, 0]:\n            return 'Coronal'\n        elif cords == [1, 0, 0, 1]:\n            return 'Axial'\n        elif cords == [0, 1, 0, 0]:\n            return 'Sagittal'\n        else:\n            return 'Unknown'\n        \n    def get_dicom_paths(self):\n        dicom_paths = sorted(self.dicom_folder.glob(\"*.dcm\"), key=lambda x: int(x.stem.split(\"-\")[-1]))\n        return dicom_paths\n\n    def get_voxel(self):\n        imgs = []\n        positions = []\n        dcm_paths = self.get_dicom_paths()\n        for dcm_path in dcm_paths:\n            img = pydicom.dcmread(str(dcm_path))\n            imgs.append(img.pixel_array)\n            positions.append(img.ImagePositionPatient)\n            \n        plane = self.get_image_plane(img)\n        voxel = np.stack(imgs)\n        \n        # reorder planes if needed and rotate voxel\n        if plane == \"Coronal\":\n            if positions[0][1] < positions[-1][1]:\n                voxel = voxel[::-1]\n                #print(f\"{study_id} {scan_type} {plane} reordered\")\n            voxel = voxel.transpose((1, 0, 2))\n        elif plane == \"Sagittal\":\n            if positions[0][0] < positions[-1][0]:\n                voxel = voxel[::-1]\n                #print(f\"{study_id} {scan_type} {plane} reordered\")\n            voxel = voxel.transpose((1, 2, 0))\n            voxel = np.rot90(voxel, 2, axes=(1, 2))\n        elif plane == \"Axial\":\n            if positions[0][2] > positions[-1][2]:\n                voxel = voxel[::-1]\n                #print(f\"{study_id} {scan_type} {plane} reordered\")\n            voxel = np.rot90(voxel, 2)\n        else:\n            if positions[0][2] > positions[-1][2]:\n                voxel = voxel[::-1]\n                #print(f\"{study_id} {scan_type} {plane} reordered\")\n            voxel = np.rot90(voxel, 2)\n            #raise ValueError(f\"Unknown plane {plane}\")\n        return voxel, plane\n\n    def normalize_contrast(self, voxel):\n        if voxel.sum() == 0:\n            return voxel\n        voxel = voxel - np.min(voxel)\n        voxel = voxel \/ np.max(voxel)\n        voxel = (voxel * 255).astype(np.uint8)\n        return voxel\n\n    def crop_voxel(self, voxel):\n        if voxel.sum() == 0:\n            return voxel\n        keep = (voxel.mean(axis=(0, 1)) > 0)\n        voxel = voxel[:, :, keep]\n        keep = (voxel.mean(axis=(0, 2)) > 0)\n        voxel = voxel[:, keep]\n        keep = (voxel.mean(axis=(1, 2)) > 0)\n        voxel = voxel[keep]\n        return voxel\n\n    def resize_voxel(self, voxel):\n        sz = int(self.icon_size)\n        output = np.zeros((sz, sz, sz), dtype=np.uint8)\n\n        if np.argmax(voxel.shape) == 0:\n            for i, s in enumerate(np.linspace(0, voxel.shape[0] - 1, sz)):\n                output[i] = cv2.resize(voxel[int(s)], (sz, sz))\n        elif np.argmax(voxel.shape) == 1:\n            for i, s in enumerate(np.linspace(0, voxel.shape[1] - 1, sz)):\n                output[:, i] = cv2.resize(voxel[:, int(s)], (sz, sz))\n        elif np.argmax(voxel.shape) == 2:\n            for i, s in enumerate(np.linspace(0, voxel.shape[2] - 1, sz)):\n                output[:, :, i] = cv2.resize(voxel[:, :, int(s)], (sz, sz))\n\n        return output\n\n    def create_voxel(self):\n        voxel, _ = self.get_voxel()\n        voxel = self.normalize_contrast(voxel)\n        voxel = self.crop_voxel(voxel)\n        voxel = self.resize_voxel(voxel)\n        return voxel\n\n    def create_and_save_voxels(self):\n        p = self.get_voxel_data_root().joinpath(self.study_id)\n        p.mkdir(parents=True, exist_ok=True)\n        #create and save voxels\n        fn = f'{self.get_voxel_data_root()}\/{self.study_id}\/{Path(self.dicom_folder).parts[-1]}.npy'\n        \n        if Path(fn).is_file() == False:\n            voxel = self.create_voxel()\n            np.save(fn, voxel)","33427e7d":"# specific function to get ids\ndef get_study_ids(dicom_data_root):\n    study_ids = dicom_data_root.iterdir()\n    return [o.name for o in study_ids]\n","6e954ed5":"scan_types= ['T1w','FLAIR','T1wCE']\n# Size of one image\/tile in tiles\nicon_size=128\n# Tiles is an n x n array but can be made larger\nicons_per_side=5\n\norientation='axial'\n#dataset = 'train'\n\ntrain_dicom_data_root = Path(f\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\")\ntest_dicom_data_root = Path(f\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\")\n\nsave_data_folder=Path('data\/')\nsave_data_folder.mkdir(parents=True, exist_ok=True)\n\nslices_data_root= Path('slices\/')\nslices_data_root.mkdir(parents=True, exist_ok=True)\n\nvoxel_data_root = Path(save_data_folder).joinpath(f'voxels_{icon_size}')\nvoxel_data_root.mkdir(parents=True, exist_ok=True)\n\ntiles_data_root = Path('tiles\/')\ntiles_data_root.mkdir(parents=True, exist_ok=True)","67bf83da":"def create_voxels_for_dataset(dicom_data_root):\n    study_ids = get_study_ids(dicom_data_root)\n    print('Creating voxels - ', scan_types)\n    for study_id in tqdm(study_ids):\n        for scan_type in scan_types:\n            #create voxels\n            dicom_folder = Path(f'{dicom_data_root}\/{study_id}\/{scan_type}')\n            if dicom_folder.is_dir():\n                v = Voxel(study_id, dicom_folder, save_data_folder, icon_size)\n\n                p = v.get_voxel_data_root().joinpath(study_id)\n                p.mkdir(parents=True, exist_ok=True)\n                    #create and save voxels\n                fn = f'{p}\/{scan_type}.npy'\n                #print(fn)\n                if Path(fn).is_file() == False:\n                    voxel = v.create_voxel()\n                    np.save(fn, voxel)","32fd379d":"create_voxels_for_dataset(train_dicom_data_root)","39d47610":"# Create slices\ndef create_slices(dicom_folder):\n    #Load voxel\n    if dicom_folder.is_dir():\n        study_id = dicom_folder.parts[-2]\n        # Load T1wCE voxel\n        v = Voxel(study_id, dicom_folder, save_data_folder, icon_size)\n        voxel = v.get_voxel_prepared()\n        \n        # Create directory for study_id\n        if not os.path.isdir(f\"\/kaggle\/working\/slices\/{study_id}\"):\n            os.makedirs(f\"\/kaggle\/working\/slices\/{study_id}\", exist_ok=True)\n    \n        # Convert to jpg\n        step = 3\n        if voxel.shape[0] < 100:\n            step = 2\n        for i in range(0,voxel.shape[0],step):\n            if (voxel[i] > 0).sum() > min_brain:\n                im = Image.fromarray(np.array(np.flipud(voxel[i])))\n                save_fn = f'\/kaggle\/working\/slices\/{study_id}\/{study_id}_{i}.jpg'\n                im.save(save_fn)\n                \ndef create_slices_for_dataset(dicom_data_root, scan_type = 'T1wCE'):\n    study_ids = get_study_ids(dicom_data_root)\n    for study_id in tqdm(study_ids):\n        dicom_folder = Path(f'{dicom_data_root}\/{study_id}\/{scan_type}')\n        create_slices(dicom_folder)","3e031185":"create_slices_for_dataset(train_dicom_data_root)","bb8fe5dd":"# Predict tumor slices\n#load model\nlearn = load_learner(tumor_slice_model_name)\n\ndef predict(image_paths):\n    dl = learn.dls.test_dl(image_paths)\n    preds, _ = learn.get_preds(dl=dl)\n    class_idxs = preds.argmax(dim=1)\n    predictions =  [learn.dls.vocab[c] for c in class_idxs]\n    confidence = preds.max(dim=1)[0]\n    return predictions, confidence\n\ndef predict_dataset(dicom_data_root, scan_type = 'T1wCE'):\n    collect = []\n    study_ids = get_study_ids(dicom_data_root)\n\n    for idx, study_id in enumerate(study_ids):\n        if idx%250==0 and idx > 0:\n            print(idx)\n            temp = pd.DataFrame(collect)\n            temp.to_csv(f'predict_slices_{dicom_data_root.parts[-1]}_{idx}.csv', index=False)\n\n        #get image_paths\n        study_folder = Path(f\"\/kaggle\/working\/slices\/{study_id}\")\n        if study_folder.is_dir():\n            image_paths = study_folder.glob('*.jpg')\n            image_paths = [_ for _ in image_paths]\n            #predict\n            predictions, confidence = predict(image_paths)\n            tmp = []\n            for i,image_path in enumerate(image_paths):\n                slice_number = image_path.stem.split('_')[-1]\n                tmp.append({'filename':image_path,'scan_type':scan_type, 'study_id': study_id, 'slice': int(slice_number), 'has_tumor': predictions[i], 'confidence':float(confidence[i])})\n\n            collect.extend(tmp)\n    if len(collect) == 0:\n        print(\"No predictions\")\n        return pd.DataFrame(columns=['filename','scan_type', 'study_id', 'slice', 'has_tumor', 'confidence'])\n    else:\n        return pd.DataFrame(collect)","4a0d4e0b":"df = predict_dataset(train_dicom_data_root)\ndf.to_csv(f'predict_slices_train.csv', index=False)","98e189de":"df.head()","694cc253":"def get_tumor_slices(study_id, df):\n    studydf = df[df.study_id == study_id].sort_values('confidence',ascending=False).head(icons_per_side**2)\n    if studydf.shape[0] == 0:\n        #each voxel has 128 slices\n        return list(range(15,icon_size-15))\n    return studydf.slice.unique()\n\ndef get_idxs(study_id, df):\n    slices = get_tumor_slices(study_id, df)\n    if len(slices) >= icons_per_side**2:\n        return random.sample(list(slices), icons_per_side**2)\n    else:\n        #fill in tiles with duplicates\n        return random.choices(slices, k=icons_per_side**2)","a387c4ee":"class Tiles:\n    def __init__(self,study_id, input_array, tiles_data_root, icon_size, icons_per_side):\n   \n        self.study_id=study_id\n        self.input_array=input_array\n        self.tiles_data_root=tiles_data_root\n        self.icon_size=icon_size\n        self.icons_per_side=icons_per_side\n      \n   \n    def create_tile_channel(self, i):\n        inputs = self.input_array[i]\n        tile = Image.new(\"RGB\", (self.icons_per_side * self.icon_size, self.icons_per_side * self.icon_size))\n        for index, im in enumerate(inputs):\n            img = Image.fromarray(im)\n            y = index \/\/ self.icons_per_side * self.icon_size\n            x = index % self.icons_per_side * self.icon_size\n            w, h = self.icon_size, self.icon_size\n            box = (int(x), int(y), int(x + w), int(y + h))\n            tile.paste(img, box)\n        return tile.split()[0]\n\n    def create_tiles(self):\n        channels = []\n        for i in range(len(self.input_array)): \n            if len(self.input_array) == 0:\n                return None\n            channel = self.create_tile_channel(i)\n            channels.append(channel)\n        if len(channels) >=3:\n            return Image.merge('RGB',channels[:3])\n        elif len(channels) == 2:\n            return Image.merge('RGB',(channels[0],channels[1],channels[0]))\n        elif len(channels) ==1 :\n            return Image.merge('RGB',(channels[0],channels[0],channels[0]))\n\n    def get_save_filename(self):\n        save_dir = self.tiles_data_root\n        save_dir.mkdir(parents=True, exist_ok=True)\n        fn = Path(save_dir).joinpath(f'{self.study_id}.jpg')\n        return str(fn)\n\n    def create_and_save_tiles(self):\n        img = self.create_tiles()\n        if img is not None:\n            fn = self.get_save_filename()\n            img.save(fn)","f69d0d59":"def create_tile(df, study_id):\n    input_array = []\n    #use same idxs for all 3 channels, use positive slices\n    idxs = get_idxs(study_id, df[(df.study_id == study_id) & (df.has_tumor == 1)])\n    #create 3 channel input array from each of the 3 scan_types  ['T1w','FLAIR','T1wCE']\n    for scan_type in scan_types:\n        #get voxel\n        fn = f'{voxel_data_root}\/{study_id}\/{scan_type}.npy'\n        if Path(fn).is_file():\n            voxel = np.load(fn)\n            #axial\n            voxel = np.array([np.flipud(voxel[i]) for i in range(voxel.shape[0])])\n            inputs = [voxel[idx] for idx in idxs]\n            input_array.append(inputs)\n        else:\n            print(fn)\n    #create tile\n    tile = Tiles(study_id, input_array, tiles_data_root, icon_size, icons_per_side)\n    tile.create_and_save_tiles()\n    \n","bd128157":"# not using Pool\ndef create_tiles_for_dataset(df, dicom_data_root):\n    study_ids = get_study_ids(dicom_data_root)\n    for study_id in tqdm(study_ids):\n        create_tile(df, study_id)\n\ncreate_tiles_for_dataset(df, train_dicom_data_root)","b5ae1e27":"#Using Pool\n# import multiprocessing as mp\n# pool = mp.Pool(mp.cpu_count())\n\n# study_ids = get_study_ids(train_dicom_data_root)\n\n# # Step 1: Init multiprocessing.Pool()\n# pool = mp.Pool(mp.cpu_count())\n\n# # Step 2: `pool.apply` the `howmany_within_range()`\n# results = pool.map(create_tile, [study_id for study_id in study_ids])\n\n# # Step 3: Don't forget to close\n# pool.close()","976a7471":"# Load Competition Training Dataframe\na = pd.read_csv(\"\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\", dtype={'BraTS21ID': str, 'MGMT_value': int})\na = a.rename({'BraTS21ID':'study_id'}, axis=1)\n\nremove = ['00109', '00123', '00709']\na = a[~a.study_id.isin(remove)]\n\na['filename'] = [f'{tiles_data_root}\/{study_id}.jpg' for _,study_id in a.study_id.iteritems()]\na =  a[['filename', 'MGMT_value']]\na.head()","9c98cf91":"bs = 32\n\ndls = ImageDataLoaders.from_df(a, path=cwd, bs=bs, item_tfms=Resize(224), batch_tfms=[ *aug_transforms(mult=1.0, do_flip=True, flip_vert=False, max_rotate=10.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.05, p_affine=0.1, p_lighting=0.75, xtra_tfms=None, size=None, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0)])\ndls.vocab","d104531b":"dls.show_batch()","17b8cce8":"learn = cnn_learner(dls, resnet50, loss_func=LabelSmoothingCrossEntropy(), metrics=[accuracy, RocAucBinary()])\nlearn.fine_tune(50)","82983596":"mgmt_model_name = Path.joinpath(models_data_root, 'miccai.pkl')\nlearn.export(mgmt_model_name)","1be37e59":"#cleanup voxels, slices, tiles for training data\nfor dir in ['slices','data','tiles']:\n    path = os.path.join(cwd, dir)\n    # removing directory\n    if Path(path).is_dir():\n        shutil.rmtree(path) ","99ff7683":"#reset directories\nsave_data_folder=Path('data\/')\nsave_data_folder.mkdir(parents=True, exist_ok=True)\n\nslices_data_root= Path('slices\/')\nslices_data_root.mkdir(parents=True, exist_ok=True)\n\nvoxel_data_root = Path(save_data_folder).joinpath(f'voxels_{icon_size}')\nvoxel_data_root.mkdir(parents=True, exist_ok=True)\n\ntiles_data_root = Path('tiles\/')\ntiles_data_root.mkdir(parents=True, exist_ok=True)","bdf02186":"#create voxels\nprint('Creating voxels...')\ncreate_voxels_for_dataset(test_dicom_data_root)\n#create slices\nprint('Creating slices...')\ncreate_slices_for_dataset(test_dicom_data_root)\n#predict on slices to get those with tumor\nprint('Evaluating slices...')\nlearn = load_learner(tumor_slice_model_name)\ndf = predict_dataset(test_dicom_data_root)\n#create tiles\nprint('Creating tiles...')\ncreate_tiles_for_dataset(df, test_dicom_data_root)\nprint('Done')","19ba0e18":"learn = load_learner(mgmt_model_name)\n\nimage_paths = tiles_data_root.glob('*.jpg')\nimage_paths = [_ for _ in image_paths]\n\ndl = learn.dls.test_dl(image_paths)\npreds, _ = learn.get_preds(dl=dl)\nclass_idxs = preds.argmax(dim=1)\npredictions =  [learn.dls.vocab[c] for c in class_idxs]\nconfidence = preds.max(dim=1)[0]\n\nfinal = []\nfor i,image_path in enumerate(image_paths):\n    study_id = image_path.stem\n    final.append({'study_id': study_id, 'prediction': predictions[i], 'confidence':confidence[i]})\n\nfinal = pd.DataFrame(final)\nfinal.head()","45ce4499":"final.prediction.value_counts()","6ed37d48":"#cleanup voxels, slices, tiles\ndr = '\/kaggle\/working'\n# path\nfor dir in ['slices','data','tiles']:\n    path = os.path.join(dr, dir)\n    # removing directory\n    if Path(path).is_dir():\n        shutil.rmtree(path) ","1729fd5b":"final = final[['study_id', 'prediction']]\nfinal.columns = ['BraTS21ID','MGMT_value']\nfinal.to_csv('submission.csv', index=False)","78c100c6":"## **Imports**","c9caf268":"## Create voxels for T1w, FLAIR, T1wCE","17daf80d":"# *Multi Step Approach*\n\n- Use the Task 1 labeled data to create a model to predict tumor presence or absence on axial T1wCE images\n- The tumor slice predictor is then used on Task 2 data after converting the data to 128x128x128 volumes to account for orientation differences in the dicom data\n- Positive tumor slices are used to create a tiled image\n- The image is composed of 3 channels in order to use info from three scan types at once\n- Finally, MGMT status is trained with the 3 channel, tumor positive tiles and predicted on the test set\n\n\n## *Building on the prior work from:*\n\n- \"Load Task 1 Dataset & Comparison w\/ Task 2 Dataset\" by Darien Schettler  https:\/\/www.kaggle.com\/dschettler8845\/load-task-1-dataset-comparison-w-task-2-dataset which was used to create the data in '..\/input\/task1-output\/data'\n\n- \"Normalized Voxels: Align Planes and Crop\" by yu4u  https:\/\/www.kaggle.com\/ren4yu\/normalized-voxels-align-planes-and-crop\/data\n\n\nThis approach is new because the tiled approach flattens the 3D volume into a 2D array of images. Only the images with tumor are used and the RGB channels of the jpg images are used to store info from three different scan types.\n\nThis gets about as bad results as everything else :-) but it's a different way to look at the data. \n\n","b09d3a07":"## Dicom -> Voxels -> Slices -> Tiles","b5cad0d9":"## Create Test set Tiles","33812d25":"## Use model to evaluate training slices on Task 2 - T1wCE","a1162276":"## Submission file","fd204ed1":"# Tiles","2ce621f5":"## Train MGMT on Tiles","2b062d30":"### Cleanup","84713657":"# 4x4 \n\n![00022.jpg](attachment:f58436f2-2145-4559-ba3f-7d19339a4543.jpg)\n\n# 5x5\n\n![00011.jpg](attachment:20b715ac-1ed6-4951-bbc7-7ddd1d660dc9.jpg)","7bfe0ed6":"## Predict MGMT_value on Test set Tiles","051b29f4":"## Voxel class","943610a7":"## Identify Slices with Tumor Labels","a0e274cd":"## Use positive predictions to create tiles","767a4308":"## Example of a Tiled image with one scan type in each of 3 channels","2c125772":"- Label 1 shows necrotic and non-enhancing tumor core and label 4 shows contrast enhancing tumor. We'll combine those and call those slices tumor positive. Other slices are negative.\n\n- Only one volume is used for tumor slice prediction - T1wCE. The contrast enhanced study is used to take advantage of label 4.\n\n- The volumes are large, so we will only use every third slice. There are also many slices with minimal or no brain, only slices with more than the minimum number of non-zero pixels will be included.\n\n- Create a csv for training labels identifying slices with and without tumor.\n\n- Save chosen slices to jpg for training.","bcdc65ad":"## Train on Tumor Slices from Part 1","862d7bca":"# Prepare Test set"}}