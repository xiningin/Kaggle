{"cell_type":{"0ddb1290":"code","72da8aba":"code","0412ca4f":"code","de4297bb":"code","4da833c3":"code","f48ae122":"code","a798aa82":"code","251932ab":"code","35a4629e":"markdown","63a2856c":"markdown","75fe86b0":"markdown","ce080ec3":"markdown","08101c07":"markdown","a113e8b5":"markdown","e14157fd":"markdown"},"source":{"0ddb1290":"from PIL import Image,ImageColor,ImageDraw,ImageOps,ImageFont\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\nimport numpy as np","72da8aba":"def download_and_resize_image(url, new_width=369, new_height=215,display=False):\n  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n  response = urlopen(url)\n  image_data = response.read()\n  image_data = BytesIO(image_data)\n  pil_image = Image.open(image_data)\n  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n  pil_image_rgb = pil_image.convert(\"RGB\")\n  pil_image_rgb.save(filename, format=\"JPEG\", quality=100)\n  print(\"Image downloaded to %s.\" % filename)\n  if display:\n    display_image(pil_image)\n  return filename","0412ca4f":"def display_image(image):\n  fig = plt.figure(figsize=(20, 15))\n  plt.grid(False)\n  plt.imshow(image)","de4297bb":"image_url = \"http:\/\/osaka-japan.weebly.com\/uploads\/2\/8\/3\/1\/28315495\/3307892.jpeg\"\ndownloaded_image_path = download_and_resize_image(image_url, 369, 215, True)","4da833c3":"def draw_bounding_box_on_image(image,ymin,xmin,ymax,xmax,color,font,thickness=4,display_str_list=()):\n  draw = ImageDraw.Draw(image)\n  im_width, im_height = image.size\n  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,ymin * im_height, ymax * im_height)\n  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),(left, top)],width=thickness,fill=color)\n\n  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n  if top > total_display_str_height:\n    text_bottom = top\n  else:\n    text_bottom = top + total_display_str_height\n  for display_str in display_str_list[::-1]:\n    text_width, text_height = font.getsize(display_str)\n    margin = np.ceil(0.05 * text_height)\n    draw.rectangle([(left, text_bottom - text_height - 2 * margin),(left + text_width, text_bottom)],fill=color)\n    draw.text((left + margin, text_bottom - text_height - margin),display_str,fill=\"black\",font=font)\n    text_bottom -= text_height - 2 * margin\n\ndef draw_boxes(image, boxes, class_names, max_boxes=10, min_score=0.1):\n  colors = list(ImageColor.colormap.values())\n  font = ImageFont.load_default() \n\n  for i in range(min(boxes.shape[0], max_boxes)):\n      ymin, xmin, ymax, xmax = tuple(boxes[i])\n      display_str = class_names[i].decode(\"ascii\")\n      color = colors[hash(class_names[i]) % len(colors)]\n      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n      draw_bounding_box_on_image(image_pil,ymin,xmin,ymax,xmax,color,font,display_str_list=[display_str])\n      np.copyto(image, np.array(image_pil))\n  return image","f48ae122":"import warnings\nwarnings.simplefilter('ignore')\nmodule_handle = \"https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1\"\ndetector = hub.load(module_handle).signatures['default']\n","a798aa82":"def ssd(detector, path):\n  img = tf.io.read_file(path)\n  img = tf.image.decode_jpeg(img, channels=3)\n  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis,]\n  result = detector(converted_img)\n  result = {key:value.numpy() for key,value in result.items()}\n  result_image = draw_boxes(img.numpy(), result[\"detection_boxes\"],result[\"detection_class_entities\"])\n  display_image(result_image)","251932ab":"ssd(detector, downloaded_image_path)","35a4629e":"1. Import Libraries\n","63a2856c":"2. Make a definition to download images and resize them. ","75fe86b0":"\n<HR>\n(1)<BR>\nI wanted to experience object detection tech with simple ways and instantly.<BR>\nI found 2 ways after searching such ways in books on websites .etc.<BR>\nOne is from Pytorch torchvision which has many examples on websites, <BR>\nthe other is Tensorflow Hub, this one. So programing codes of this notebook is<BR> originally from the following Tensoflow Hub official website.<BR>\nAnd I made the following programing codes easier for newbies like me.<BR><BR>\nhttps:\/\/www.tensorflow.org\/hub\/tutorials\/object_detection\n<HR>\n(2)<BR>\nThe original notebook uses Google's pretrained faster_rcnn, but <BR>\nthis notebook uses Google's pretrained SSD; single shot detection<BR>\nThe accuracy is lower than the original one, but the detection speed is faster.<BR>\n<HR>\n","ce080ec3":"5. Make a definition to drown bounding boxes on example images","08101c07":"4. Show an example image from Japan-Guide.com","a113e8b5":"3. Make a definition to display images","e14157fd":"Thanks for checking this notebook."}}