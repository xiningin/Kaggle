{"cell_type":{"88026d13":"code","7aab3dd0":"code","9d957ea3":"code","a0dd8fe6":"code","6e986a0e":"code","9e78c0a1":"code","07e0fbb0":"code","09d372af":"code","cbd513cf":"code","4e94d3e3":"code","19bc6d09":"markdown","2fd8483e":"markdown","49db1f3d":"markdown","25b26133":"markdown","f0693ce5":"markdown","40c3caff":"markdown","a19cd852":"markdown","74f7414d":"markdown","4b33067a":"markdown","c1b591e0":"markdown","64c511f8":"markdown"},"source":{"88026d13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfiles = []\nlabel_name = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n    for filename in filenames:\n        label_name += [dirname[52:]]\n        files += [str(dirname)+'\/'+str(filename)]\n    \n    \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7aab3dd0":"from skimage import filters, color, morphology, io\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nn1 = 3\nn2 = 5\nfig, axs = plt.subplots(n1, n2, figsize=(32, 16))\nfor i in range(n1):\n    for j in range(n2):\n        z = random.randint(0, len(files)-1)\n        pic = np.array(io.imread(files[z], as_gray=True, plugin='pil'))\n        shape = np.shape(pic)\n        axs[i, j].imshow(pic)\n        axs[i, j].set_title('%s x=%.f, y=%.f' % (label_name[z], shape[0], shape[1]))","9d957ea3":"import numpy as np\n\nN = len(files)\nshape = np.zeros((2, N))\n\n# use only .jpg becuase of an empty .png (bishop_216)\ntmp = []\nfor i in range(N):\n    if files[i][-3:] == 'jpg':\n        tmp = tmp + [files[i]]\n        \n\nfiles = tmp\nN = len(files)\n\nfor i in range(N):    \n    tmp = np.shape(np.array(io.imread(files[i], as_gray=True, plugin='pil')))\n    shape[:, i] = [tmp[0], tmp[1]]\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 5))\naxs[0].scatter(shape[0, :], shape[1, :])\naxs[0].plot(range(0, 2000), range(0, 2000), 'k')\naxs[0].set_ylabel('dim 1')\naxs[0].set_xlabel('dim 0')\naxs[0].grid()\naxs[0].set_title('Scatter of images shapes')\naxs[0].set_xlim([0, 2000])\naxs[0].set_ylim([0, 2000])\n\naxs[1].hist(shape[0, :]\/shape[1, :])\naxs[1].grid()\naxs[1].set_xlabel('Aspect Ratio')\naxs[1].set_ylabel('Frequency')\naxs[1].set_title('Histogram of aspect ration for images')\naxs[1].set_xlim([0, 2])\n\naxs[2].hist(shape[0, :])\naxs[2].grid()\naxs[2].set_xlabel('#pixel of dim 0')\naxs[2].set_ylabel('Frequency')\naxs[2].set_title('Histogram of pixel in dim 0')\naxs[2].set_xlim([0, 2000])\n\naxs[3].hist(shape[1, :])\naxs[3].grid()\naxs[3].set_xlabel('#pixel of dim 1')\naxs[3].set_ylabel('Frequency')\naxs[3].set_title('Histogram of pixel in dim 1')\naxs[3].set_xlim([0, 2000])","a0dd8fe6":"from skimage import io\nimport skimage as si\n\ndef load_and_resize(file, dim0, dim1):\n    img = io.imread(file, as_gray=True, plugin='pil')\n    img = si.transform.resize(img, (dim0, dim1), anti_aliasing=True) #Resizing\n    img = np.reshape(img, (dim0, dim1, 1))\n    return img\n\n","6e986a0e":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers\n\nclass CNN_Model():\n    '''\n    Class to create and train the CNN model\n    '''\n    def __init__(self):\n        '''\n        Constructor\n        '''\n        # empty property for the model\n        self.model = []\n        # defining default parameters\n        # Input Parameter\n        self.xPixel = 250 # Pixel in x\n        self.yPixel = 250 # Pixel in y\n        self.outLayer = 1 # number of classes\n        self.dropout = 0.4\n        self.NEpoch = 200\n        self.KS = 3     # kernel size of cnn kernel\n        self.reg = 0.00 # regularization rate  \n        # Augmentation Parameter\n        self.Rotation = 0.2\n        self.Zoom = 0.2\n        \n    '''\n        Convolutinal neral Network for Image Classification\n    '''\n    def build_CNN(self):\n        data_augmentation = keras.Sequential([\n                layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", input_shape=(self.xPixel, self.yPixel, 1)),\n                layers.experimental.preprocessing.RandomRotation(self.Rotation),\n                layers.experimental.preprocessing.RandomZoom(self.Zoom),\n        ])\n        # Defintion of DNN\n        self.model = keras.Sequential([\n            layers.experimental.preprocessing.Normalization(axis=1, input_shape=(self.xPixel, self.yPixel, 1)),\n            data_augmentation,\n            \n            layers.Conv2D(16, self.KS, padding='same', kernel_regularizer=regularizers.l2(self.reg), activation='relu'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(),\n            \n            layers.Conv2D(32, self.KS, padding='same', kernel_regularizer=regularizers.l2(self.reg), activation='relu'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(),\n            \n            layers.Conv2D(64, self.KS, padding='same', kernel_regularizer=regularizers.l2(self.reg), activation='relu'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(),\n            \n            layers.Conv2D(128, self.KS, padding='same', kernel_regularizer=regularizers.l2(self.reg), activation='relu'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(),\n            \n            layers.Flatten(),\n            layers.Dropout(self.dropout),\n            layers.Dense(128, kernel_regularizer=regularizers.l2(self.reg), activation='relu'),\n            layers.BatchNormalization(),\n            layers.Dense(128, kernel_regularizer=regularizers.l2(self.reg), activation='relu'),\n            layers.BatchNormalization(),\n            layers.Dense(self.outLayer, activation='softmax', name='Output_Layer')\n        ])\n        ","9e78c0a1":"from collections import Counter\nAR = 0.8         # choosen aspect ration from histogram\npixel_dim1 = 500 # choosen number of pixel in dim 1\npixel_dim0 =  int(AR*pixel_dim1)\nclasses = list(Counter(label_name).keys())\nNclasses = len(classes)\n\ndef create_label(label_name, idx, files):\n    classes = list(Counter(label_name).keys())\n    Nclasses = len(classes)\n\n    # generate label using one hot encoding\n    label = np.zeros((len(idx), Nclasses))\n    for i in range(len(idx)):\n        for j in range(Nclasses):\n            if classes[j] in files[idx[i]]:\n                label[i, j] = 1\n    return label\n\ndef create_feature(idx, files,pixel_dim0, pixel_dim1):\n    Data = np.zeros((len(idx), pixel_dim0, pixel_dim1, 1))\n    \n    for i in range(len(idx)):\n        Data[i, :, :, :] = load_and_resize(files[idx[i]], pixel_dim0, pixel_dim1)\n    \n    return Data\n","07e0fbb0":"from sklearn.model_selection import train_test_split, KFold\n\nTrainFiles, ValFiles = train_test_split(files, test_size=0.2, random_state=42)\nkfold = KFold(5, shuffle=True, random_state=42)","09d372af":"Epochs  = 15 # number of epochs to train\nlr = 1e-4    # learning rate\n\nModel = CNN_Model()\nModel.xPixel  = 224 #pixel_dim0\nModel.yPixel = 224 #pixel_dim1\nModel.outLayer = Nclasses\nModel.NEpoch = Epochs\nModel.reg = 0.01\nModel.dropout = 0.3\nModel.Rotation = 0.3\nModel.Zoom = 0.3\nbs = 128\n\nModel.build_CNN()\ntf.keras.optimizers.Adam(learning_rate=lr)\nModel.model.compile(optimizer='Adam', loss='CategoricalCrossentropy', metrics=['acc'])\n\nValData = create_feature(range(0, len(ValFiles)), ValFiles, Model.xPixel, Model.yPixel)\nValLabel = create_label(label_name, range(0, len(ValFiles)), ValFiles)\n\nhist = np.zeros((6, 5*Epochs))\nfor id_epoch, (id_train_files, id_test_files) in enumerate(kfold.split(TrainFiles)):\n    start = id_epoch*Model.NEpoch\n    end = (id_epoch+1)*Model.NEpoch\n    \n    TrainData = create_feature(id_train_files, TrainFiles, Model.xPixel, Model.yPixel)\n    TestData = create_feature(id_test_files, TrainFiles, Model.xPixel, Model.yPixel)\n    \n    TrainLabel = create_label(label_name, id_train_files, TrainFiles)\n    TestLabel = create_label(label_name, id_test_files, TrainFiles)\n    \n    tmp = Model.model.fit(TrainData, TrainLabel, validation_data=(TestData, TestLabel), batch_size=bs, initial_epoch=start ,epochs=end)\n    hist[0, start:end] = tmp.history['loss']\n    hist[1, start:end] = tmp.history['acc']\n    hist[2, start:end] = tmp.history['val_loss']\n    hist[3, start:end] = tmp.history['val_acc']\n    loss, acc = Model.model.evaluate(ValData, ValLabel, batch_size=32)\n    hist[4, start:end] = loss*np.ones(Model.NEpoch)\n    hist[5, start:end] = acc*np.ones(Model.NEpoch)\n    ","cbd513cf":"fig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].plot(hist[0, :], 'r', label='Train')\naxs[0].plot(hist[2, :], 'b', label='Test')\naxs[0].plot(hist[4, :], 'g', label='Validation')\naxs[0].set_ylabel('Loss (CCE)')\naxs[0].set_xlabel('Epoch')\naxs[0].legend()\naxs[0].grid()\n\naxs[1].plot(hist[1, :], 'r', label='Train')\naxs[1].plot(hist[3, :], 'b', label='Test')\naxs[1].plot(hist[5, :], 'g', label='Validation')\naxs[1].plot(range(5*Epochs), 1\/Nclasses*np.ones(5*Epochs), 'k',label='guessing prob.')\naxs[1].set_ylabel('ACC')\naxs[1].set_xlabel('Epoch')\naxs[1].legend(loc='upper left')\naxs[1].grid()","4e94d3e3":"hyper_searching = False\nif hyper_searching == True:\n    NRuns = 20\n    Epochs = 20\n    book = np.zeros((NRuns, 7))\n    for i in range(NRuns):\n        # coose random training parameter\n        lr = float(np.random.uniform(1e-6, 1e-1, size=1))\n        book[i, 0] = lr\n        reg_l2 = float(np.random.uniform(1e-6, 1e-1, size=1))\n        book[i, 1] = reg_l2\n        dropout = float(np.random.uniform(0, 0.9, size=1))\n        book[i, 2] = dropout\n        rotation =float( np.random.uniform(0, 1, size=1))\n        book[i, 3] = rotation\n        zoom = float(np.random.uniform(0, 1, size=1))\n        book[i, 4] = zoom\n        batch_size = int(np.array(random.sample(list([1, 2, 4, 8, 16, 32, 64, 128]), 1)))\n        book[i, 5] = batch_size\n\n        Model = CNN_Model()\n        Model.xPixel  = pixel_dim0\n        Model.yPixel = pixel_dim1\n        Model.outLayer = Nclasses\n        Model.NEpoch = Epochs\n        Model.reg = reg_l2\n        Model.dropout = dropout\n        Model.Rotation = rotation\n        Model.Zoom = zoom\n\n        Model.build_CNN()\n\n        tf.keras.optimizers.Adam(learning_rate=lr)\n        Model.model.compile(optimizer='Adam', loss='CategoricalCrossentropy', metrics=['acc'])\n        hist = Model.model.fit(TrainData, TrainLabel, validation_data=(TestData, TestLabel), batch_size=batch_size, epochs=Model.NEpoch)\n\n        book[i, 6] = np.array(hist.history['val_acc']).max()\n\n        tf.keras.backend.clear_session()\n        del Model\n\n    import pandas as pd\n    SearchFrame = pd.DataFrame(book, columns=['Learing Rate', 'L2 Rate', 'Dropout', 'Rotation', 'Zoom', 'Batch size', 'Val Acc']).sort_values(by=['Val Acc'], ascending=False)\n    SearchFrame.head()\n","19bc6d09":"The images are all different in size. Since we will need a fixed size later, we will first take a closer look at the sizes of the images.","2fd8483e":"The hyperparameters of this model can be estimated more precisely with the following code. Here, different parameter combinations are set randomly. If a good parameter set is found, the value range of the individual parameters can also be examined more closely.","49db1f3d":"Now we create the network based on CNN. We also use a few methods to minimize overfitting. This includes data augumentation methods like pixel flip or zooming. We also use l2 regularization to limit ourselves to the important areas within the images. ","25b26133":"In order not to change the aspect ratio of the images too much, we look for the aspect ratio that occurs most often (left histogram). Since the distribution of pixels in dimension 1 is somewhat narrower, we use this to define the pixel size. For this we take 500 pixels in the following.","f0693ce5":"Now we create a function to read and process the data","40c3caff":"Now we set the size of the images and create the labels using one hot encoding.","a19cd852":"The results don't look good, maybe the resizing step crushes the aspect ratio of the images or we have to clean our dataset for better results.","74f7414d":"Let's start by creating a little overview of the images we want to classify.","4b33067a":"For the later training and evaluation of the DNN we need two data sets. We take 80% of the data for training and the remaining 20% for evaluation.","c1b591e0":"Let's have look on our results.","64c511f8":"Lets train our model"}}