{"cell_type":{"734bd638":"code","d675d8ef":"code","ddfe01de":"code","54d1b408":"code","abb7b2d4":"code","07bd56b2":"code","afba87de":"markdown","0dc3fada":"markdown"},"source":{"734bd638":"import pandas  as pd\nimport numpy   as np","d675d8ef":"train  = pd.read_csv('..\/input\/ingv-lgbm-baseline-the-train-test-csv-files\/volcano_train.csv')\ntest   = pd.read_csv('..\/input\/ingv-lgbm-baseline-the-train-test-csv-files\/volcano_test.csv')\nsample = pd.read_csv('..\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv')","ddfe01de":"X_train       = train.drop([\"segment_id\",\"time_to_eruption\"],axis=1)\ny_train       = train[\"time_to_eruption\"]\nX_test        = test.drop(\"segment_id\",axis=1)","54d1b408":"from rgf.sklearn import RGFRegressor\n\nregressor = RGFRegressor(max_leaf=2000, \n                         algorithm=\"RGF_Sib\", \n                         test_interval=100, \n                         loss=\"LS\",\n                         verbose=False)\n\nregressor.fit(X_train, y_train)\npredictions = regressor.predict(X_test)","abb7b2d4":"sample.iloc[:,1:] = predictions\nsample.to_csv('submission.csv',index=False)","07bd56b2":"train.to_csv('volcano_train.csv')\ntest.to_csv('volcano_test.csv')","afba87de":"#### Appendix\nWrite out a copy of the `train.csv` and `test.csv` files used in this work.","0dc3fada":"# The Volcano and the Regularized Greedy Forest\nThis is a demonstration script using the ***Regularized Greedy Forest*** regressor (RGF)(see my notebook [\"Introduction to the Regularized Greedy Forest\"](https:\/\/www.kaggle.com\/carlmcbrideellis\/introduction-to-the-regularized-greedy-forest)) for the [INGV - Volcanic Eruption Prediction](https:\/\/www.kaggle.com\/c\/predict-volcanic-eruptions-ingv-oe) competition. The RGF performs as well as XGBoost, and is a very useful estimator to include when one is creating a [stacking ensemble](https:\/\/www.kaggle.com\/carlmcbrideellis\/stacking-ensemble-using-the-house-prices-data), which combines multiple estimators to produce one strong result. For the input I use the `train.csv` and `test.csv` produced by the excellent notebook [\"INGV Volcanic Eruption Prediction - LGBM Baseline\"](https:\/\/www.kaggle.com\/ajcostarino\/ingv-volcanic-eruption-prediction-lgbm-baseline) written by [Adam James](https:\/\/www.kaggle.com\/ajcostarino). (For completeness I include these `train.csv` and `test.csv` files in the **Output** section of this notebook, as they take nearly three hours to produce). I have not undertaken any feature selection (for example using the [Boruta-SHAP](https:\/\/www.kaggle.com\/carlmcbrideellis\/feature-selection-using-the-borutashap-package) package), nor have I performed any cross validation, hyperparameter tuning, *etc.* so there is *plenty* of room for improvement.\n\nI hope you find the RGF technique useful, and good luck!"}}