{"cell_type":{"ad44ef37":"code","a4fbebd0":"code","7fad76ef":"code","07660014":"code","6b922cdb":"code","e40666eb":"code","5f98cdc5":"code","018e8c46":"code","6202ffa6":"code","dadf4535":"code","803073d7":"code","41286ad4":"code","575044d8":"code","a31eb518":"code","9548924a":"code","9082d33e":"code","90941ba2":"code","4755a8e1":"code","485076f3":"code","e62421f9":"code","dc1b6d54":"code","654c6d3d":"code","7630178c":"code","b8d55f68":"code","89233077":"code","06fba611":"code","90b27ef2":"code","77ae48bd":"code","7d914e19":"code","c89e96a8":"code","2687ff05":"code","70123f20":"code","da05256e":"code","d2fa32e2":"code","c5680ffd":"code","c613425f":"code","7590586d":"code","da82a792":"code","cdfe153e":"code","4dcb87bb":"code","3fe7c147":"code","1c2d9cda":"code","40b8bfbc":"code","9013ced3":"code","a8a8cb80":"code","ca97b79e":"code","c5d54ffc":"code","68dda425":"code","5a07e48c":"code","7062940a":"code","9bedc8a2":"code","6a5c3311":"code","16dfeaf8":"code","a0eb1402":"markdown","e97af533":"markdown","565e3c45":"markdown","0ebb2c57":"markdown","fd7e0462":"markdown","826f8357":"markdown","3d9565dd":"markdown","55368c20":"markdown","641d4a1a":"markdown","ec5e23f8":"markdown","a2a87883":"markdown","25c8318f":"markdown","f61c84a0":"markdown","a8ff5a9f":"markdown","8c5f75e8":"markdown","7a8bbc85":"markdown","ed77822d":"markdown","9d7cce61":"markdown","45a34b6b":"markdown","62dc048e":"markdown","1d9f132b":"markdown","bebd1bd0":"markdown","b4ac3810":"markdown","b7cf6ab4":"markdown","50fa6055":"markdown","cac94cbe":"markdown","52b26107":"markdown","6019a12c":"markdown","3ae912ed":"markdown","8fadfe5e":"markdown","923f83a9":"markdown","9f3f948d":"markdown","ad0f4d12":"markdown","6e485889":"markdown","85110102":"markdown","1572b8b9":"markdown","d48bcea4":"markdown"},"source":{"ad44ef37":"# Data analysis libraries \nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# ML libraries\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n# from sklearn import metrics\n# from sklearn.cluster import AgglomerativeClustering\n\n# Regex & time\nimport re\nimport time\n\n# Web scraping libraries \nimport requests \nfrom bs4 import BeautifulSoup \n\n# Spotipy library\n!pip install spotipy\nimport spotipy","a4fbebd0":"# Spotify API credentials\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nclient_id = user_secrets.get_secret(\"client_id\")\nclient_secret = user_secrets.get_secret(\"client_secret\")\n\n# Authenticate credentials\nfrom spotipy.oauth2 import SpotifyClientCredentials \nclient_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\nsp = spotipy.Spotify(client_credentials_manager=client_credentials_manager) ","7fad76ef":"# Point Spotipy library at Beatles Spotify page \nartist = sp.artist(\"https:\/\/open.spotify.com\/artist\/3WrFJ7ztbogyGnTHbHJFl2\")\n\n# Store artist's albums in list\nbeatles_albums = []\n\n# Extract artist's uri\nartist_albums = sp.artist_albums(artist['id'], album_type='album')\n\n#Pull all of the artist's albums\nbeatles_albums.extend(artist_albums['items'])\nwhile artist_albums['next']:\n    artist_albums = sp.next(artist_albums)\n    beatles_albums.extend(artist_albums['items'])\n\nfor album in beatles_albums:\n    name = album['name']\n    print((' ' + name))","07660014":"beatles_albums.sort(key=lambda album:album['name'].lower())\nbeatles_album_names = [album['name'] for album in beatles_albums]\nbeatles_album_names","6b922cdb":"beatles_album_uris = [album['uri'] for album in beatles_albums]\nbeatles_album_uris","e40666eb":"def album_songs(uri):\n    album = uri \n    spotify_albums[album] = {}\n    # Create keys-values of empty lists inside nested dictionary for album\n    spotify_albums[album]['album'] = [] \n    spotify_albums[album]['track_number'] = []\n    spotify_albums[album]['id'] = []\n    spotify_albums[album]['name'] = []\n    spotify_albums[album]['uri'] = []\n    # Pull data on album tracks\n    tracks = sp.album_tracks(album) \n    for n in range(len(tracks['items'])): \n        spotify_albums[album]['album'].append(beatles_album_names[album_count]) \n        spotify_albums[album]['track_number'].append(tracks['items'][n]['track_number'])\n        spotify_albums[album]['id'].append(tracks['items'][n]['id'])\n        spotify_albums[album]['name'].append(tracks['items'][n]['name'])\n        spotify_albums[album]['uri'].append(tracks['items'][n]['uri'])","5f98cdc5":"# Store all the albums\nspotify_albums = {}\nalbum_count = 0\nfor i in beatles_album_uris: #each album\n    album_songs(i)\n    print(str(beatles_album_names[album_count]) + \" album songs has been added to spotify_albums dictionary\")\n    album_count+=1 # Updates album count once all tracks have been added","018e8c46":"def audio_features(album):\n    # Add new key-values to store audio features\n    spotify_albums[album]['acousticness'] = []\n    spotify_albums[album]['danceability'] = []\n    spotify_albums[album]['duration_ms'] = []\n    spotify_albums[album]['energy'] = []\n    spotify_albums[album]['instrumentalness'] = []\n    spotify_albums[album]['liveness'] = []\n    spotify_albums[album]['loudness'] = []\n    spotify_albums[album]['speechiness'] = []\n    spotify_albums[album]['tempo'] = []\n    spotify_albums[album]['valence'] = []\n    spotify_albums[album]['popularity'] = []\n    \n    track_count = 0\n    for track in spotify_albums[album]['uri']:\n        # Pull audio features per track\n        features = sp.audio_features(track)\n        \n        # Append to relevant key-value\n        spotify_albums[album]['acousticness'].append(features[0]['acousticness'])\n        spotify_albums[album]['danceability'].append(features[0]['danceability'])\n        spotify_albums[album]['duration_ms'].append(features[0]['duration_ms'])\n        spotify_albums[album]['energy'].append(features[0]['energy'])\n        spotify_albums[album]['instrumentalness'].append(features[0]['instrumentalness'])\n        spotify_albums[album]['liveness'].append(features[0]['liveness'])\n        spotify_albums[album]['loudness'].append(features[0]['loudness'])\n        spotify_albums[album]['speechiness'].append(features[0]['speechiness'])\n        spotify_albums[album]['tempo'].append(features[0]['tempo'])\n        spotify_albums[album]['valence'].append(features[0]['valence'])\n        # Popularity is stored elsewhere:\n        pop = sp.track(track)\n        spotify_albums[album]['popularity'].append(pop['popularity'])\n        track_count+=1","6202ffa6":"sleep_min = 2\nsleep_max = 5\nstart_time = time.time()\nrequest_count = 0\nfor i in spotify_albums:\n    audio_features(i)\n    request_count+=1\n    if request_count % 5 == 0:\n        print(str(request_count) + \" playlists completed\")\n        time.sleep(np.random.uniform(sleep_min, sleep_max))\n        print('Loop #: {}'.format(request_count))\n        print('Elapsed Time: {} seconds'.format(time.time() - start_time))","dadf4535":"dic_df = {}\ndic_df['album'] = []\ndic_df['track_number'] = []\ndic_df['id'] = []\ndic_df['name'] = []\ndic_df['uri'] = []\ndic_df['acousticness'] = []\ndic_df['danceability'] = []\ndic_df['duration_ms'] = []\ndic_df['energy'] = []\ndic_df['instrumentalness'] = []\ndic_df['liveness'] = []\ndic_df['loudness'] = []\ndic_df['speechiness'] = []\ndic_df['tempo'] = []\ndic_df['valence'] = []\ndic_df['popularity'] = []\nfor album in spotify_albums: \n    for feature in spotify_albums[album]:\n        dic_df[feature].extend(spotify_albums[album][feature])\n        \nlen(dic_df['album'])","803073d7":"df = pd.DataFrame.from_dict(dic_df)","41286ad4":"# Remove all the compilation albums and deluxe editions \nnon_core_albums = df[ (df['album'] == 'Live At The Hollywood Bowl') | \n                   (df['album'] == 'Live At The BBC (Remastered)') | \n                   (df['album'] == 'Let It Be... Naked (Remastered)') | \n                    (df['album'] == '1 (Remastered)') |\n                    (df['album'] == 'On Air - Live At The BBC (Vol.2)') |\n                  (df['album'] == 'Let It Be (Super Deluxe)') |\n                  (df['album'] == 'Abbey Road (Super Deluxe Edition)') |\n                   (df['album'] == 'Yellow Submarine Songtrack') |\n                  (df['album'] == 'The Beatles') |\n                   (df['album'] == \"Sgt. Pepper's Lonely Hearts Club Band (Deluxe Edition)\") |\n                   (df['album'] == \"Sgt. Pepper's Lonely Hearts Club Band (Super Deluxe Edition)\")].index\n\ndf.drop(non_core_albums, inplace = True)","575044d8":"df.album.nunique()","a31eb518":"df.album.unique()","9548924a":"df['album'] = df['album'].apply(lambda x: re.sub('\\(Remastered\\)', '', x))\ndf['name'] = df['name'].apply(lambda x: re.sub(' - Remastered 2009', '', x))","9082d33e":"df = df[~((df['album']  == 'Yellow Submarine ') & (df['track_number'] > 6))] ","90941ba2":"album_year = {\n'Please Please Me':'1963',\n'With The Beatles':'1963',\n'A Hard Day\\'s Night' :'1964',\n'Beatles For Sale':'1964',\n'Help!' :'1965',\n'Rubber Soul':'1965',\n'Revolver' :'1966',\n'Sgt. Pepper\\'s Lonely Hearts Club Band' :'1967',\n'Magical Mystery Tour' :'1967',\n'The Beatles':'1968',\n'Yellow Submarine':'1969',\n'Abbey Road':'1969',\n'Let It Be':'1970'}\n\ndf['album'] = df['album'].str.strip()\ndf['year'] = df['album']\ndf['year'].replace(album_year, inplace=True)\ncol = df.pop('year')\ndf.insert(1, 'year', col)\ndf","4755a8e1":"def getdata(url): \n    r = requests.get(url) \n    return r.text \n  \nsonglist = []\n    \nhtmldata = getdata(\"https:\/\/www.beatlesbible.com\/songs\/\") \nsoup = BeautifulSoup(htmldata, 'html.parser') \ndata = '' \nfor data in soup.find_all(\"ul\"): \n    for li in data:\n        songlist.append(li.get_text()) ","485076f3":"# Find indexes of items to delete:\n# for (i, item) in enumerate(songlist, start=1):\n#     print(i, item)\ndel songlist[:38]\ndel songlist[341:]","e62421f9":"# Split each item in list to song name and song composer\nsong_composer_list = [song.rsplit((' ('), 1) for song in songlist]\nsong_composer_list\n\n# Turn list into dataframe\nsong_composer_list = pd.DataFrame.from_records(song_composer_list)\nsong_composer_list.rename({0: 'name', 1: 'composer'}, axis='columns', inplace=True)\nsong_composer_list['composer'] = song_composer_list['composer'].str.rstrip(')')\n\n# Merge list to main dataset\ndf = pd.merge(df, song_composer_list, on=['name'])\ndf","dc1b6d54":"# Put the composer column after the song name\ncol = df.pop('composer')\ndf.insert(5, 'composer', col)\ndf","654c6d3d":"df.shape","7630178c":"df['composer'].value_counts()","b8d55f68":"df['composer'] = df['composer'].apply(lambda x:\n                                            'Other' if x != 'Lennon-McCartney' and 'Lennon' in x else x)\ndf['composer'].value_counts()","89233077":"df.shape","06fba611":"df['composer'] = df['composer'].apply(lambda x:\n                                            'Cover' if x != 'Lennon-McCartney' and x != 'Harrison' and x != 'Other' else x)\ndf['composer'].value_counts()","90b27ef2":"import matplotlib.style as style\nstyle.use('seaborn-poster') #sets the size of the charts\nstyle.use('ggplot')","77ae48bd":"sns.countplot(x=\"composer\", data=df)\nplt.xlabel(\"Songwriter\", size=15)","7d914e19":"plt.figure(figsize=(15,6))\n# make barplot and sort bars in descending order\nsns.barplot(x='popularity', \n            y=\"name\", \n            data=df, \n            hue='composer',\n            order=df.sort_values('popularity',ascending = False).iloc[:10].name)\n# set labels\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\nplt.xlabel(\"Popularity\", size=15)\nplt.ylabel(\"Song name\", size=15)\nplt.tight_layout()","c89e96a8":"plt.figure(figsize=(15,6))\n# make barplot and sort bars in descending order\nsns.barplot(x='energy', \n            y=\"name\", \n            data=df, \n            hue='composer',\n            order=df.sort_values('energy',ascending = False).iloc[:10].name)\n# set labels\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\nplt.xlabel(\"Energy\", size=15)\nplt.ylabel(\"Song name\", size=15)\nplt.tight_layout()","2687ff05":"plt.figure(figsize=(15,6))\n# make barplot and sort bars in descending order\nsns.barplot(x='valence', \n            y=\"name\", \n            data=df, \n            hue = 'composer',\n            order=df.sort_values('valence',ascending = False).iloc[:10].name)\n# set labels\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\nplt.xlabel(\"Valence (Positivity)\", size=15)\nplt.ylabel(\"Song name\", size=15)\nplt.tight_layout()","70123f20":"plt.figure(figsize=(15,6))\n# make barplot and sort bars in descending order\nsns.barplot(x='valence', \n            y=\"name\", \n            data=df,\n            hue='composer',\n            order=df.sort_values('valence',ascending = True).iloc[:10].name)\n# set labels\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\nplt.xlabel(\"Valence (Positivity)\", size=15)\nplt.ylabel(\"Song name\", size=15)\nplt.tight_layout()","da05256e":"plt.figure(figsize=(15,6))\n# make barplot and sort bars in descending order\nsns.barplot(x='danceability', \n            y=\"name\", \n            data=df, \n            hue='composer',\n            order=df.sort_values('danceability',ascending = False).iloc[:10].name, \n#             dodge=False\n           )\n# set labels\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\nplt.xlabel(\"Danceability\", size=15)\nplt.ylabel(\"Song name\", size=15)\nplt.tight_layout()","d2fa32e2":"plt.figure(figsize=(15,6))\n# make barplot and sort bars in descending order\nsns.barplot(x='danceability', \n            y=\"name\", \n            data=df,\n            hue='composer',\n            order=df.sort_values('danceability',ascending = True).iloc[:10].name)\n# set labels\nplt.xlabel(\"danceability\", size=15)\nplt.ylabel(\"name\", size=15)\nplt.tight_layout()","c5680ffd":"grid = sns.FacetGrid(df, col = \"composer\", hue = \"composer\", col_wrap=5)\ngrid.map(sns.scatterplot, \"popularity\", \"danceability\")","c613425f":"grid = sns.FacetGrid(df, col = \"composer\", hue = \"composer\", col_wrap=5)\ngrid.map(sns.scatterplot, \"valence\", \"energy\")","7590586d":"grid = sns.FacetGrid(df, col = \"album\", hue = \"album\", col_wrap=5)\ngrid.map(sns.scatterplot, \"popularity\", \"danceability\")","da82a792":"grid = sns.FacetGrid(df, col = \"album\", hue = \"album\", col_wrap=5)\ngrid.map(sns.scatterplot, \"valence\", \"energy\")","cdfe153e":"grid = sns.FacetGrid(df, col = \"year\", hue = \"year\", col_wrap=5, col_order=['1963','1964','1965','1966','1967','1968','1969','1970'])\ngrid.map(sns.scatterplot, \"popularity\", \"danceability\")","4dcb87bb":"grid = sns.FacetGrid(df, col = \"year\", hue = \"year\", col_wrap=5, col_order=['1963','1964','1965','1966','1967','1968','1969','1970'])\ngrid.map(sns.scatterplot, \"valence\", \"energy\")","3fe7c147":"cols_of_interest = df[['energy', 'valence', 'danceability']]\nprint(cols_of_interest.columns)","1c2d9cda":"X = StandardScaler().fit_transform(cols_of_interest)","40b8bfbc":"#for each value of k, initialise k_means and use inertia to identify the sum of squared distances of samples to the nearest cluster centre\nsum_of_squared_distances = []\nK = range(1,15)\nfor k in K:\n    k_means = KMeans(n_clusters=k)\n    model = k_means.fit(X)\n    sum_of_squared_distances.append(k_means.inertia_)","9013ced3":"plt.plot(K, sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('sum_of_squared_distances')\nplt.title('Optimal no. of clusters')\nplt.show()","a8a8cb80":"k_means_3 = KMeans(n_clusters=3)\nmodel = k_means_3.fit(X)\npredict = k_means_3.predict(X)","ca97b79e":"df['compilation album nr'] = pd.Series(predict, index=df.index)","c5d54ffc":"# Put the compilation album nr column after the song name\ncol = df.pop('compilation album nr')\ndf.insert(5, 'compilation album nr', col)\ndf","68dda425":"label = k_means_3.fit_predict(X)","5a07e48c":"df['compilation album nr'].value_counts()","7062940a":"# Plot each of the cluster points on a scatterplot\nfiltered_label0 = X[label == 0]\nfiltered_label1 = X[label == 1]\nfiltered_label2 = X[label == 2]\n\nplt.scatter(filtered_label0[:,0] , filtered_label0[:,1] , color = 'blue')\nplt.scatter(filtered_label1[:,0] , filtered_label1[:,1] , color = 'black')\nplt.scatter(filtered_label2[:,0] , filtered_label2[:,1] , color = 'red')\nplt.show()","9bedc8a2":"df['name'][df['compilation album nr'] == 0].unique()","6a5c3311":"df['name'][df['compilation album nr'] == 1].unique()","16dfeaf8":"df['name'][df['compilation album nr'] == 2].unique()","a0eb1402":"<a id=\"section-two\"><\/a>\n## Import libraries","e97af533":"### Which are the most positive (highest valence) songs?","565e3c45":"Harrison also appears at rank 3 for the least danceable song with **Only A Northern Song**. Would be very skeptical of the assessment that it or **Helter Skelter** (rank 2) are less danceable than **Revolution 9** (rank 4) though.","0ebb2c57":"<a id=\"section-four\"><\/a>\n## Data cleansing\n\nThe retrieved albums contain compilation albums and deluxe versions that contain alternative takes of songs. Since we're only interested in songs in the [13 studio albums in the Beatles \"core catalogue\"](https:\/\/en.wikipedia.org\/wiki\/The_Beatles_discography#Studio_albums), will remove the rest.\n","fd7e0462":"One potentially useful bit of data that Spotify does not provide is the year each album was initially released. Will add that data (extracted from Wikipedia) below.","826f8357":"The [2nd side of the Yellow Submarine album](https:\/\/en.wikipedia.org\/wiki\/Yellow_Submarine_(album)#Track_listing) is the fully instrumental orchestral film score, which has quite a different vibe from the rest of the catalogue. As I'm primarily interested in analyzing the songs made by the core band members, will remove those tracks.","3d9565dd":"Another bit of data it'd be extremely cool to have is the composer per each song. Luckily, the [Beatles Bible website](https:\/\/www.beatlesbible.com\/) provides that all that info on one page. Will scrape that data and add it to the dataset.","55368c20":"## Table of Contents\n* [Introduction](#section-one)\n* [Import libraries](#section-two)\n* [Retrieve music data via API](#section-three)\n* [Data cleansing](#section-four)\n* [EDA: Visualizations \/ Explorations](#section-five)\n* [Clustering: Build compilation albums](#section-six)\n\n<a id=\"section-one\"><\/a>\n## Introduction\nSpotify is the largest music streaming platform in the world, [owning a third of the whole of the market](https:\/\/www.midiaresearch.com\/blog\/global-music-subscriber-market-shares-q1-2021).\n\nThe platform has an API which gives access their huge database of music to build interesting applications and uncover insights.\n\nIn this notebook, I will use the API and do some web scraping to gather data on the Beatles discography. I will compare different Spotify metrics on each of the songs on the 13 core Beatles albums, published between 1963-1970.","641d4a1a":"### Which are the least danceable Beatles songs?","ec5e23f8":"<a id=\"section-three\"><\/a>\n## Retrieve music data via API\n\nAccess [Spotify for Developers](https:\/\/developer.spotify.com\/dashboard) to create Spotify API credentials (free).","a2a87883":"#### Popularity x Danceability per Composer","25c8318f":"### Which are the most popular Beatles songs?","f61c84a0":"#### Popularity x Danceability per Album","a8ff5a9f":"### Which are the most energetic Beatles songs?","8c5f75e8":"### Which are the most danceable Beatles songs?","7a8bbc85":"### Which are the least positive (lowest valence) songs?","ed77822d":"### Spotify audio features\nA description of the all the retrieved features in the official Spotify API docs: https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/#\/operations\/get-audio-features\n\n* **acousticness**\n>A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n\n* **danceability**\n>Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n\n* **duration_ms**\n>The duration of the track in milliseconds.\n\n* **energy**\n>Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n\n* **instrumentalness**\n>Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n\n* **liveness**\n>Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n\n* **speechiness**\n>Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n\n* **loudness**\n>The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n\n* **tempo**\n>The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n\n* **valence**\n>A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n* **popularity**\n>The popularity of the artist. The value will be between 0 and 100, with 100 being the most popular. The artist's popularity is calculated from the popularity of all the artist's tracks.","9d7cce61":"As indicated in the top 10 rankings, covers are somewhat high in valence.","45a34b6b":"All other songs are composed by non-Beatles, so will rename them to *Cover*.","62dc048e":"Based on the steepness, looks like 3 clusters is the sweet spot","1d9f132b":"Like with energetic songs, in the entire core catalogue, a whole 4 out of the top 10 most positive songs were covers. That's a lot considering just over 10% of the songs are covers. Apparently when choosing songs to cover, the Beatles preferred energetic\/positive ones. ","bebd1bd0":"There is a number of composer combinations that include other combinations of Beatles members, but they're low in volume, so will rename them to *Other*.","b4ac3810":"#### Valence x Energy per Year","b7cf6ab4":"<a id=\"section-six\"><\/a>\n## Clustering: Build compilation albums\n\nWill create compilation Beatles albums based on the combination of energy, danceability and valence per song.","50fa6055":"#### Popularity x Danceability per Year","cac94cbe":"In spite of recording about a sixth of the number of songs the Lennon-McCartney duo did, Harrison is the winner in terms of composing the single most popular song, **Here Comes The Sun**. Rank 9, **Something** is also a Harrison song. \n\nRank 6, **Twist and Shout**, is a cover. The rest of the top 10 are all Lennon-McCartney songs.","52b26107":"In the entire core catalogue, 4 out of the top 10 most energetic songs were covers.","6019a12c":"#### Valence x Energy per Composer","3ae912ed":"In spite of not appearing in the top 10 energetic or positive songs rankings, Harrison appears at the top for having composed the most danceable song in the catalogue, **For You Blue**. And [it is quite danceable indeed](https:\/\/www.youtube.com\/watch?v=TIFHRaZERHg).","8fadfe5e":" Harrison's songs appear to stand out as relatively dispersed in both axes.","923f83a9":"We now have all the albums we need. \n\nAll the retrieved albums and songs are remastered versions of the original recordings and as such have \"*(Remastered)*\" at the end. For brevity's sake, I'll remove that word.","9f3f948d":"73.8% of the songs are composed by **Lennon-McCartney**. Of course, some are more Lennon, others are more McCartney, and I could attempt to attribute them accordingly based on interviews with them and other sources, but for the sake of simplicity, will keep it as it is. Besides Lennon-McCartney, there are 18 instances (12.8%) of songs composed by **George Harrison**. 10.6% of the songs are **covers**.","ad0f4d12":"#### Valence x Energy per Album","6e485889":"The scraped data contains text I don't need. Will keep only the song and song composer names:","85110102":"Harrison takes the 1st place in terms of least positive song with **Blue Jay Way**. Given it was [written out of boredom under jet-lag on a foggy evening while waiting for a friend](https:\/\/en.wikipedia.org\/wiki\/Blue_Jay_Way#Background_and_inspiration) and the main hook is literally \"please don't be (very) long\", its lack of positivity isn't surprising.","1572b8b9":"### Scatterplots: \n\nIn this section, will compare 2 conceptually co-related metrics against each other in scatterplots, per composer and per album: \n\n- **Popularity** (how much the song is listened to on Spotify) x **Danceability** (a proxy for how \"catchy\" a song is). \n\n- **Valence** (how positive the song is) x **Energy** (how loud or intense the song is)","d48bcea4":"<a id=\"section-five\"><\/a>\n## EDA: Visualizations \/ Explorations"}}