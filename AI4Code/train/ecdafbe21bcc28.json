{"cell_type":{"cfd52287":"code","6c580c21":"code","e2af3fc2":"code","f299a076":"code","be3fbf1f":"code","0c68de46":"code","aafd9027":"code","65faa25b":"code","e2d94929":"code","30bb8950":"code","8412c914":"markdown","78449cec":"markdown","621623d3":"markdown"},"source":{"cfd52287":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6c580c21":"df=pd.read_csv('\/kaggle\/input\/telco-paging-a-interface\/Paging_Analysis_A_interface.csv')\ndf.head()","e2af3fc2":"df1=df[['Success_Rate','Response','Failures']]\nimport seaborn as sns\nsns.pairplot(df1)","f299a076":"X=df[['Response','Failures']]\nX.head()","be3fbf1f":"y=df[['Success_Rate']]\ny.head()","0c68de46":"from sklearn.preprocessing import StandardScaler\nscale=StandardScaler()\nX_trans=scale.fit_transform(X)\nprint(X_trans.shape)\nprint(X_trans.mean())\nprint(X_trans.std())","aafd9027":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test= train_test_split(X_trans,y,test_size=0.2, random_state=42)\nprint(X_train.shape)\nprint(y_test.shape)","65faa25b":"from sklearn.linear_model import Ridge\nmodel_r=Ridge().fit(X_train, y_train)\ny_pred=model_r.predict(X_test)\ny_pred","e2d94929":"print('In Sample Score: ', model_r.score(X_train, y_train))\nprint('Out Sample Score: ', model_r.score(X_test, y_test))","30bb8950":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nX_poly_train=PolynomialFeatures(3).fit_transform(X_train)\nX_poly_test=PolynomialFeatures(3).fit_transform(X_test)\nmodel_lr=LinearRegression().fit(X_poly_train, y_train)\nprint('In Sample Score: ', model_lr.score(X_poly_train, y_train))\nprint('Out Sample Score: ', model_lr.score(X_poly_test, y_test))","8412c914":"Now Let's improve our model by including polynomial feature","78449cec":"**Very bad model indeed, but no worry as we can explore always!**","621623d3":"Congratulations! our model improved a lot & having no bias\/variance problem as in sample and out sample r^2 score close to each other."}}