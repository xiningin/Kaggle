{"cell_type":{"0a983908":"code","9b643f76":"code","3962944d":"code","1842f6ca":"code","cb460192":"code","bb01709d":"code","f575f857":"code","053fe6f9":"code","0c236c12":"code","76ddab93":"code","e00afb89":"code","37712186":"code","9eeb77fa":"code","32c53474":"code","612bc0d4":"code","c1c4e846":"code","5a2099fc":"code","ce178774":"code","4aeeac9e":"code","989a193d":"code","4db2e2a4":"code","5dad5548":"code","97d0029d":"code","aaf7b67e":"code","340dd831":"code","c5e725ac":"code","158866bd":"code","322a2d8f":"code","eae7ce23":"code","06771e30":"code","98ab5ae2":"code","e76be327":"markdown","708b912a":"markdown","5ff2a9c4":"markdown","1d228b3a":"markdown","ca65b46b":"markdown","6776d163":"markdown","a74e0a66":"markdown","bcff6b0f":"markdown","66eeecad":"markdown","646db48b":"markdown","95458db7":"markdown","ed995614":"markdown"},"source":{"0a983908":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","9b643f76":"df = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ndf.title = df.excerpt","3962944d":"min(df.target.tolist())\n# df","1842f6ca":"%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig = sns.displot(x=df.excerpt.str.len(), data=df, color='black', kde=False, height=6, aspect=3, kind='hist')\n\nprint(df.excerpt.str.len().min())\nprint(df.excerpt.str.len().max())\nprint(df.excerpt.str.len().mean())","cb460192":"%matplotlib inline\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntemp = df.title.str.split().map(lambda x: len(x))\n\nfig = sns.displot(x=temp, color='blue', kde=False, height=6, aspect=3, kind='hist')\n\nprint(temp.min())\nprint(temp.max())\nprint(temp.mean())","bb01709d":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nstop = set(stopwords.words('english'))\n\ncorpus = []\ntitle = df.title.str.split()\ntitle = title.values.tolist()\ncorpus = [word for i in title for word in i]\n\nfrom collections import defaultdict\n\ndic = defaultdict(int)\n\nfor word in corpus:\n    if word in stop:\n        dic[word] += 1","f575f857":"from collections import Counter\nfrom nltk.stem import PorterStemmer\n\nsns.set(rc={'figure.figsize':(15,15)})\n\nps = PorterStemmer()\ncounter = Counter(corpus)\nmost = counter.most_common()\n\nx, y = [], []\nlookup = []\nfor word,count in most[:120]:\n    if (word.lower() not in stop) and (ps.stem(word.lower()) not in lookup) and word.isalpha():\n        x.append(word)\n        y.append(count)\n        lookup.append(ps.stem(word.lower()))\n        \nsns.barplot(x=y,y=x)","053fe6f9":"from sklearn.feature_extraction.text import CountVectorizer\n\ndef get_top_ngram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    fwords_freq = []\n    for i in words_freq:\n        temp = 0\n        for j in i[0].split():\n            if j in stop:\n                temp += 1\n        if temp != len(i[0].split()):\n            fwords_freq.append(i)\n    words_freq = fwords_freq\n    words_freq =sorted(words_freq, key=lambda x: x[1], reverse=True)\n    return words_freq[:100]","0c236c12":"top_n_bigrams = get_top_ngram(df.title, 2)[:20]\n\nx, y = map(list, zip(*top_n_bigrams)) \n\nsns.barplot(x=y, y=x, palette='hls')","76ddab93":"top_n_trigrams = get_top_ngram(df.title, 3)[:20]\n\nx, y = map(list, zip(*top_n_trigrams)) \n\nsns.barplot(x=y, y=x, palette='coolwarm')","e00afb89":"import nltk\nnltk.download('punkt')\nnltk.download('wordnet')\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import word_tokenize\n\ndef preprocess_news(df):\n    corpus = []\n    stem = PorterStemmer()\n    lem = WordNetLemmatizer()\n    for news in df.title:\n        words = [w for w in word_tokenize(news) if (w.lower() not in stop and w.isalpha())]\n        words = [lem.lemmatize(w) for w in words if len(w) > 2]\n        corpus.append(words)\n    return corpus\n\ncorpus = preprocess_news(df)","37712186":"import gensim\n\ndic = gensim.corpora.Dictionary(corpus)\nbow_corpus = [dic.doc2bow(doc) for doc in corpus]","9eeb77fa":"lda_model = gensim.models.LdaMulticore(bow_corpus, \n                                   num_topics = 5, \n                                   id2word = dic,                                    \n                                   passes = 10,\n                                   workers = 2)\nlda_model.show_topics()","32c53474":"import pyLDAvis\nimport pyLDAvis.gensim_models\n\nLDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dic)\npyLDAvis.display(LDAvis_prepared)","612bc0d4":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data):\n    wordcloud = WordCloud(\n        background_color=None,\n        stopwords=stopwords,\n        max_words=1000,\n        max_font_size=30,\n        scale=4,\n        random_state=42,\n        mode='RGBA',\n        colormap='plasma')\n   \n    wordcloud=wordcloud.generate(str(data))\n\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n\n    plt.imshow(wordcloud)\n    plt.show()\n\nshow_wordcloud(corpus)","c1c4e846":"from textblob import TextBlob\n\nsns.set(rc={'figure.figsize':(6, 6)})\n\ndef polarity(text):\n    return TextBlob(text).sentiment.polarity\n\ndf.polarity_score = df.title.apply(lambda x : polarity(x))\ndf.polarity_score.hist(color='skyblue')","5a2099fc":"def sentiment(x):\n    if x < 0:\n        return 'neg'\n    elif x == 0:\n        return 'neu'\n    else:\n        return 'pos'\n\nsns.set(rc={'figure.figsize':(6, 6)})\ndf.sentiment = df.polarity_score.map(lambda x: sentiment(x))\n\nsns.barplot(x=df.sentiment.value_counts().index, y=df.sentiment.value_counts(), palette='coolwarm')","ce178774":"! python -m spacy download en_core_web_sm","4aeeac9e":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")","989a193d":"def ner(text):\n    doc = nlp(text)\n    return [X.label_ for X in doc.ents]\n\nent = df.title.apply(lambda x : ner(x))\nent = [x for sub in ent for x in sub]\ncounter = Counter(ent)\ncount = counter.most_common()","4db2e2a4":"x, y = map(list, zip(*count))\nsns.set(rc={'figure.figsize':(15, 15)})\nsns.barplot(x=y, y=x, palette='husl')","5dad5548":"! pip install pandarallel","97d0029d":"from pandarallel import pandarallel\n\npandarallel.initialize()","aaf7b67e":"def ner(text, ent=\"PERSON\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\norg = df.title.parallel_apply(lambda x: ner(x))\norg = [i for x in org for i in x]\ncounter = Counter(org)\n\nx, y = map(list,zip(*counter.most_common(20)))\nsns.barplot(y, x, palette='coolwarm')","340dd831":"def ner(text, ent=\"CARDINAL\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\norg = df.title.parallel_apply(lambda x: ner(x))\norg = [i for x in org for i in x]\ncounter = Counter(org)\n\nx, y = map(list,zip(*counter.most_common(20)))\nsns.barplot(y, x, palette='coolwarm')","c5e725ac":"def ner(text, ent=\"DATE\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\norg = df.title.parallel_apply(lambda x: ner(x))\norg = [i for x in org for i in x]\ncounter = Counter(org)\n\nx, y = map(list,zip(*counter.most_common(20)))\nsns.barplot(y, x, palette='coolwarm')","158866bd":"def ner(text, ent=\"GPE\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\norg = df.title.parallel_apply(lambda x: ner(x))\norg = [i for x in org for i in x]\ncounter = Counter(org)\n\nx, y = map(list,zip(*counter.most_common(20)))\nsns.barplot(y, x, palette='coolwarm')","322a2d8f":"def ner(text, ent=\"ORG\"):\n    doc = nlp(text)\n    return [X.text for X in doc.ents if X.label_ == ent]\n\norg = df.title.parallel_apply(lambda x: ner(x))\norg = [i for x in org for i in x]\ncounter = Counter(org)\n\nx, y = map(list,zip(*counter.most_common(20)))\nsns.barplot(y, x, palette='coolwarm')","eae7ce23":"def pos(text):\n    pos = nltk.pos_tag(word_tokenize(text))\n    pos = list(map(list,zip(*pos)))[1]\n    return pos\n\ntags = df.title.parallel_apply(lambda x : pos(x))\ntags = [x for l in tags for x in l]\ncounter = Counter(tags)\n\nx, y = list(map(list,zip(*counter.most_common(6))))\nsns.barplot(x=y, y=x, palette='coolwarm')","06771e30":"def get_nouns(text):\n    noun = []\n    pos = nltk.pos_tag(word_tokenize(text))\n    for word, tag in pos:\n        if tag == 'NN' and word.isalpha():\n            noun.append(word)\n    return noun\n\nwords = df.title.parallel_apply(lambda x : get_nouns(x))\nwords = [x for l in words for x in l]\ncounter = Counter(words)\n\nx, y = list(map(list,zip(*counter.most_common(10))))\nsns.barplot(x=y, y=x, palette='magma')","98ab5ae2":"def get_nouns(text):\n    noun = []\n    pos = nltk.pos_tag(word_tokenize(text))\n    for word, tag in pos:\n        if tag == 'JJ' and word.isalpha():\n            noun.append(word)\n    return noun\n\nwords = df.title.parallel_apply(lambda x : get_nouns(x))\nwords = [x for l in words for x in l]\ncounter = Counter(words)\n\nx, y = list(map(list,zip(*counter.most_common(10))))\nsns.barplot(x=y, y=x, palette='magma')","e76be327":"## Number of words in publication titles","708b912a":"## Most common trigrams","5ff2a9c4":"We see the length of excerpts range from 669 to 1341 characters. On average, the publication title length is 972.","1d228b3a":"We see the number of words in the excerpt range from 135 to 205. On average, we have 172 words in an excerpt.","ca65b46b":"# NER Analysis","6776d163":"# Topic Modelling","a74e0a66":"# Most occuring words","bcff6b0f":"# Preliminary Analysis\n\n## Number of characters present in the publication titles.","66eeecad":"# Sentiment Analysis\n\n## We'll first see the polarity of the publication titles.","646db48b":"# POS Tagging\n## We'll now do Part-of-Speech Tagging.\n\n**Here's the list of tags**:\n\nNoun (NN)- Joseph, London, table, cat, teacher, pen, city\n\nVerb (VB)- read, speak, run, eat, play, live, walk, have, like, are, is\n\nAdjective(JJ)- beautiful, happy, sad, young, fun, three\n\nAdverb(RB)- slowly, quietly, very, always, never, too, well, tomorrow\n\nPreposition (IN)- at, on, in, from, with, near, between, about, under\n\nDeterminer (DT) - one, many\n\nConjunction (CC)- and, or, but, because, so, yet, unless, since, if\n\nPronoun(PRP)- I, you, we, they, he, she, it, me, us, them, him, her, this\n\nInterjection (INT)- Ouch! Wow! Great! Help! Oh! Hey! Hi!","95458db7":"# N-Gram Exploration\n\n## Most common bigrams","ed995614":"# Wordcloud Analysis"}}