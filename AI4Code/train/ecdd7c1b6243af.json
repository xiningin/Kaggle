{"cell_type":{"c34600bf":"code","1c8e687f":"code","83d9c921":"code","65865c93":"code","7293b45c":"code","0c6365b8":"code","1d0ba2b9":"code","6db7c94c":"code","39fc2fc2":"code","24637b67":"code","da9508f9":"code","7212f410":"code","92dab8ec":"code","a3d40abd":"code","f405c575":"code","10559f88":"code","e372be4e":"code","5d5d0312":"code","f2665167":"markdown","f5e2852f":"markdown","42bee0d0":"markdown","e050da0c":"markdown","573aaeea":"markdown","3fd686da":"markdown","063248b6":"markdown","f6bec395":"markdown"},"source":{"c34600bf":"import numpy as np \nimport tensorflow as tf\nimport cv2\nimport os \nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom numpy import save","1c8e687f":"def download(path):\n  '''\n  Input: The path for the dataset\n  \n  Output: y_train ; It is a pandas dataframe consisting of the y labels.\n          x_train ; It is a tensor with image data.\n  '''\n  data = pd.DataFrame({0:['n99999999_001.JPEG'], \n                       1:[5],\n                       2:[0],\n                       3:[0]}) \n  image = None\n  for (root,dirs,files) in os.walk(path): \n    if(root != path):\n      if(dirs == []):\n        for file in files:\n          print(file)\n          if(image != None):\n            a = root+'\/' + file\n            image_raw = tf.io.read_file(a)\n            new = tf.image.decode_image(image_raw)\n            if(tf.shape(new)[2] == 1):\n              new = tf.image.grayscale_to_rgb(new, name=None)\n            new = tf.reshape(new,[1,64,64,3])\n            image = tf.concat([image,new],0)\n    \n          \n          else:\n            a = root+'\/' + file\n            image_raw = tf.io.read_file(a)\n            image = tf.image.decode_image(image_raw)\n            if(tf.shape(image)[2] == 1):\n              image = tf.image.grayscale_to_rgb(image, name=None)\n            image = tf.reshape(image,[1,64,64,3])\n     \n     \n      else:\n        for dir in files:\n          a = root + '\/' + dir \n          data = data.append(pd.read_csv(a,delimiter=\"\\t\",header = None),ignore_index = True)\n          \n  y_train = data \n  x_train = image\n  return y_train,x_train\n     \n         \n\n","83d9c921":"def Y_dataframe(Y_values):\n\n '''\nInput : It is a pandas dataframe that countains the lables and bounding boxes of each image in the file.\n\nOutput: Y and Y_keys \n        Y_ keys is a  dataframe that has all the labels.\n        Y is a  dataframe that holds all the one hot codes and its respective labels. \n '''\n \n Y_values[0] = Y_values[0].str[:9]\n Y_values.drop(Y_values.index[:1], inplace=True)\n\n # Key for the dataset \n image_types = Y_values[0].unique()\n Y_train = pd.DataFrame(image_types, columns=['Image_Types'])\n labelencoder = LabelEncoder()\n Y_train['Image_Types_labels'] = labelencoder.fit_transform(Y_train['Image_Types'])\n Y_keys = Y_train\n \n image_types = np.array(Y_values[0])\n Y = pd.DataFrame(image_types, columns=['Image_Types'])\n labelencoder = LabelEncoder()\n Y['Image_Types_labels'] = labelencoder.fit_transform(Y['Image_Types'])\n \n    \n enc = OneHotEncoder(handle_unknown='ignore')\n enc_df = pd.DataFrame(enc.fit_transform(Y[['Image_Types_labels']]).toarray())\n Y = Y.join(enc_df)\n \n return Y,Y_keys","65865c93":"# Seperate Code for validation y_values \n\ndef dow_val():\n Y_values = pd.read_csv('..\/input\/image-detect\/val\/val_annotations.txt',delimiter=\"\\t\",header = None)\n# Y_values = Y_values.sort_values([0])\n\n # Key for the dataset \n image_types = Y_values[1].unique()\n Y_train = pd.DataFrame(image_types, columns=['Image_Types'])\n labelencoder = LabelEncoder()\n Y_train['Image_Types_labels'] = labelencoder.fit_transform(Y_train['Image_Types'])\n Y_keys = Y_train\n\n image_types = np.array(Y_values[1])\n\n Y = pd.DataFrame(image_types, columns=['Image_Types'])\n labelencoder = LabelEncoder()\n    \n Y['Image_Types_labels'] = labelencoder.fit_transform(Y['Image_Types']) \n enc = OneHotEncoder(handle_unknown='ignore')\n enc_df = pd.DataFrame(enc.fit_transform(Y[['Image_Types_labels']]).toarray())\n Y = Y.join(enc_df)\n \n return Y,Y_keys\n \n","7293b45c":"def hot_encode(X_train):\n arra = X_train[X_train.columns[2:]]\n arra = np.array(arra)\n return arra ","0c6365b8":"# First downloading data from drive \ny_train,X_train = download('..\/input\/image-detect\/train')\ny_val,X_val = download('..\/input\/image-detect\/val')\n\n# Assembling the Y values in the right order\ny_train,y_train_keys = Y_dataframe(y_train)\ny_val,y_val_keys =  dow_val()\n","1d0ba2b9":"y_val,X_val = download('..\/input\/image-detect\/val')","6db7c94c":"for (root,dirs,files) in os.walk('..\/input\/image-detect\/val\/images'):\n    print(files)","39fc2fc2":"import glob\nfor filepath in glob.iglob(r'..\/input\/image-detect\/val\/images\/*.JPEG'):\n    print(filepath)","24637b67":"Y_train = hot_encode(y_train)\nY_val = hot_encode(y_val)\nX_train = X_train\/255\nX_val = X_val\/255\n","da9508f9":"save('X_val_unsortted.npy',X_val)\nsave('Y_val_unsortted',Y_val)\n\n\n","7212f410":"print(X_train.dtype)\n\ntf.dtypes.cast(X_train, tf.float16)\nprint(X_train.dtype)","92dab8ec":"import numpy as np \nimport tensorflow as tf\nfrom numpy import load\nimport pandas as pd\nimport gc","a3d40abd":"#Downloading X_train,X_val,Y_train,Y_val\nX_train = load('..\/input\/pre-trained-data\/X_train.npy')\nX_val = load('..\/input\/last-data\/X_train(3).npy')\/255\nY_train = load('..\/input\/pre-trained-data\/Y_train.npy')\nY_val = load('..\/input\/validation\/Y_val_unsortted.npy')\n\n#Dowloading Key values dataframe \nY_train_keys = pd.read_csv('..\/input\/pre-trained-data\/y_train_keys.txt',delimiter=\"\\t\")\nY_val_keys =pd.read_csv('..\/input\/pre-trained-data\/y_val_keys.txt',delimiter=\"\\t\")","f405c575":"inputs = tf.keras.layers.Input(shape = (64, 64,3))\n\nlayer1 = tf.keras.layers.Conv2D(42,(3,3),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',padding = 'same')(inputs)\nMaxPool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1,1),padding = 'same')(layer1)\n\n\nlayer2 = tf.keras.layers.Conv2D(42,(3,3),activation = 'relu',use_bias = 1,kernel_regularizer= 'l2',padding = 'same')(MaxPool1)\nMaxPool2 = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1,1),padding = 'same')(layer2)\n\n\n#Inception Layer 1\nInception_layer1_con_1 = tf.keras.layers.Conv2D(42,(3,3),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',strides = (1,1),padding ='same')(MaxPool2)\nInception_layer1_con_2 = tf.keras.layers.Conv2D(42,(5,5),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',strides = (1,1),padding ='same')(MaxPool2)\nMaxPool3 = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1,1),padding = 'same')(MaxPool2)\nConcatenate1 = tf.keras.layers.Concatenate(axis=-1)([Inception_layer1_con_1,Inception_layer1_con_2,MaxPool3])\n\n#Inception Layer 2 \nInception_layer2 = tf.keras.layers.Conv2D(64,(1,1),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',strides = (1,1),padding ='same')(Concatenate1)\n\nInception_layer2_con_1 = tf.keras.layers.Conv2D(42,(3,3),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',strides = (1,1),padding ='same')(Inception_layer2)\nInception_layer2_con_2 = tf.keras.layers.Conv2D(42,(5,5),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',strides = (1,1),padding ='same')(Inception_layer2)\nMaxPool4 = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(1,1),padding = 'same')(Inception_layer2)\nConcatenate2 = tf.keras.layers.Concatenate(axis=-1)([Inception_layer2_con_1,Inception_layer2_con_2,MaxPool4])\n\nConcatenate3 =  tf.keras.layers.Concatenate(axis=-1)([Concatenate1, Concatenate2])\nlayer3 = tf.keras.layers.Conv2D(64,(1,1),activation = 'relu',use_bias = 1,kernel_regularizer = 'l2',strides = (1,1),padding ='same')(Concatenate3)\n\n#Fully Connected Layers\nFlatten =  tf.keras.layers.Flatten()(layer3)\nhidden_1 = tf.keras.layers.Dense(20, activation = 'relu')(Flatten)\ndropout = tf.keras.layers.Dropout(rate = 0.1)(hidden_1)\noutputs = tf.keras.layers.Dense(200, activation = tf.keras.activations.softmax)(dropout)\n\n\nmodel = tf.keras.Model(inputs = inputs, outputs = outputs)\nmodel.summary()","10559f88":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    zoom_range=0.0,\n    channel_shift_range=0.0,\n    fill_mode=\"nearest\",\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=1.\/255,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split=0.0,\n    dtype=None,\n)\n","e372be4e":"checkpoint_filepath = '.\/checkpoint.ckpt'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    verbose = 1)\n","5d5d0312":"model.load_weights('.\/checkpoint')\nmodel.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.02), loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\nprint('done')\nhis = model.fit(datagen.flow(X_train, Y_train, batch_size=500),steps_per_epoch=len(X_train) \/500, epochs=800,validation_data=(X_val,Y_val),shuffle = True,callbacks=[model_checkpoint_callback])","f2665167":"# Pre Processing of Y Train","f5e2852f":"# Setting up Data from Functions","42bee0d0":"# Importing Libraries","e050da0c":"## Image Classification \n\n\n> 200 Classes are present in this file. Training data contains 450 images per class. Validation and test set contains 50 images for each class.\n\n> For the training data we are given with labels and boundix boxes in (x1,y1,x2,y2) format representing the diagonal sides of a bounding box.\n\n> The project is categerozied into 3 portions\n\n\n*   Preprocessing The Data\n*   Training The Data\n*   Testing the Data \n\n> We will be using numpy arrays throught the project.","573aaeea":"# Architecture for Convolutional Network\n* 2 Convolutional networks with max pooling.\n* 2 Inception Networks\n* Concatenation of both Inception Networks\n* 1 Fully connected dense layer \n* Output \n","3fd686da":"# Downloading Data","063248b6":"# Downloading Pre- Processed Data  ","f6bec395":"# Seperating Hot- encode from Y_values\n"}}