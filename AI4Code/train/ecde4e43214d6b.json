{"cell_type":{"8a206c38":"code","bbf67aef":"code","3f9d6a05":"code","49764211":"code","ac62e9a3":"code","78566100":"code","6f0cf5bb":"code","f443af75":"code","50b4a402":"code","474d4dfc":"code","58ce4a03":"code","4d907c78":"code","a3bd836c":"code","4792bda9":"code","42f7ea36":"code","0cf6b0b9":"code","5cf10600":"code","6f32b34e":"code","2a2e1cd5":"code","6dd236c3":"code","7c4d5475":"code","da1b62a8":"code","b393d3fd":"code","b8529c4d":"code","b9291093":"code","5b9335e3":"code","fc14f9af":"code","e599dbfb":"code","1ae989e1":"code","b8799060":"code","b98b9337":"code","8ca35d19":"code","8f7cacc7":"code","6c46e3a9":"code","b496be57":"code","5f55df43":"code","f1f2f325":"code","0527e86b":"code","d7c73da0":"code","3db4b73c":"code","b8450a23":"code","866a4913":"code","8a233ed9":"code","c4585502":"code","e9143c6d":"code","b05d2bb5":"code","b1459af6":"code","b8c70d73":"code","80ffe786":"markdown","b9dd363e":"markdown","58bb677d":"markdown","3b490c10":"markdown","a9068047":"markdown","114bc8db":"markdown","da03dfc8":"markdown","4b6716b4":"markdown"},"source":{"8a206c38":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","bbf67aef":"# File Directory for both the train and test\ntrain_path = \"..\/input\/chest-ctscan-images\/Data\/train\"\nval_path = \"..\/input\/chest-ctscan-images\/Data\/valid\"\ntest_path = \"..\/input\/chest-ctscan-images\/Data\/test\"","3f9d6a05":"def GetDatasetSize(path):\n    num_of_image = {}\n    for folder in os.listdir(path):\n        # Counting the Number of Files in the Folder\n        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n    return num_of_image;\n    \ntrain_set = GetDatasetSize(train_path)\nval_set = GetDatasetSize(val_path)\ntest_set = GetDatasetSize(test_path)\nprint(train_set,\"\\n\\n\",val_set,\"\\n\\n\",test_set)","49764211":"labels = ['squamous.cell.carcinoma', 'normal', 'adenocarcinoma', 'large.cell.carcinoma']\ntrain_list = list(train_set.values())\nval_list = list(val_set.values())\ntest_list = list(test_set.values())\n\nx = np.arange(len(labels))  # the label locations\nwidth = 0.25  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(x - width, train_list, width, label='Train')\nrects2 = ax.bar(x, val_list, width, label='Val')\nrects3 = ax.bar(x + width, test_list, width, label='Test')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Images Count')\nax.set_title('Dataset')\nax.set_xticks(x, labels)\nplt.xticks(rotation=15)\nax.legend()\n\nax.bar_label(rects1)\nax.bar_label(rects2)\nax.bar_label(rects3)\n\nfig.tight_layout()\n\nplt.show()","ac62e9a3":"import tensorflow.keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.models import load_model, Model\nfrom tensorflow.keras.layers import Dense,Conv2D, Flatten, MaxPool2D, Dropout","78566100":"train_datagen = ImageDataGenerator(rescale = 1.0\/255.0,\n                                  horizontal_flip = True,\n                                  fill_mode = 'nearest',\n                                  zoom_range=0.2,\n                                  shear_range = 0.2,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  rotation_range=0.4)\n\ntrain_data = train_datagen.flow_from_directory(train_path,\n                                                   batch_size = 5,\n                                                   target_size = (224,224),\n                                                   class_mode = 'categorical')","6f0cf5bb":"train_data.class_indices","f443af75":"val_datagen = ImageDataGenerator(rescale = 1.0\/255.0)\nval_data = val_datagen.flow_from_directory(val_path,\n                                                   batch_size = 5,\n                                                   target_size = (224,224),\n                                                   class_mode = 'categorical')","50b4a402":"val_data.class_indices","474d4dfc":"test_datagen = ImageDataGenerator(rescale = 1.0\/255.0)\ntest_data = test_datagen.flow_from_directory(test_path,\n                                                   batch_size = 5,\n                                                   target_size = (224,224),\n                                                   class_mode = 'categorical')","58ce4a03":"test_data.class_indices","4d907c78":"model = Sequential() \n\n# Convolutional Layer with input shape (224,224,3)\nmodel.add(Conv2D(filters=32, kernel_size= (3,3), activation= 'relu', input_shape=(224,224,3)) )\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=4, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']  )\n \nmodel.summary()","a3bd836c":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/ct_cnn_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [mc];","4792bda9":"# Fitting the Model\ncnn = model.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back\n    )","42f7ea36":"# Loading the Best Fit Model \nmodel = load_model(\".\/ct_cnn_best_model.hdf5\")","0cf6b0b9":"# Checking the Accuracy of the Model \naccuracy_cnn = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_cnn*100} %\")","5cf10600":"cnn.history.keys()","6f32b34e":"# Plot model performance\nacc = cnn.history['accuracy']\nval_acc = cnn.history['val_accuracy']\nloss = cnn.history['loss']\nval_loss = cnn.history['val_loss']\nepochs_range = range(1, len(cnn.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","2a2e1cd5":"base_model = VGG16(\n    weights='imagenet',\n    include_top=False, \n    input_shape=(224,224,3)\n)\n\nfor layer in base_model.layers:\n       layer.trainable = False","6dd236c3":"NUM_CLASSES = 4\n\nvgg_model = Sequential()\nvgg_model.add(base_model)\nvgg_model.add(layers.Flatten())\nvgg_model.add(layers.Dropout(0.25))\nvgg_model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n\nvgg_model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nvgg_model.summary()","7c4d5475":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/ct_vgg_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [ mc];","da1b62a8":"# Fitting the Model\nvgg = vgg_model.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back \n    )","b393d3fd":"# Loading the Best Fit Model \nmodel = load_model(\".\/ct_vgg_best_model.hdf5\")","b8529c4d":"# Checking the Accuracy of the Model \naccuracy_vgg = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_vgg*100} %\")","b9291093":"vgg.history.keys()","5b9335e3":"# Plot model performance\nacc = vgg.history['accuracy']\nval_acc = vgg.history['val_accuracy']\nloss = vgg.history['loss']\nval_loss = vgg.history['val_loss']\nepochs_range = range(1, len(vgg.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","fc14f9af":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nbase_model = InceptionV3(input_shape = (224, 224, 3), \n                         include_top = False, \n                         weights = 'imagenet')","e599dbfb":"for layer in base_model.layers:\n    layer.trainable = False","1ae989e1":"x = layers.Flatten()(base_model.output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)\n\n# Adding a final softmax layer with 4 node for classification output\nx = layers.Dense(4, activation='softmax')(x)\n\nmodel_incep = tf.keras.models.Model(base_model.input, x)\n\nmodel_incep.compile(optimizer = tensorflow.keras.optimizers.RMSprop(learning_rate=0.0001), \n                    loss = 'categorical_crossentropy', \n                    metrics = ['accuracy'])","b8799060":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/ct_incep_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [mc];","b98b9337":"# Fitting the Model\nincep = model_incep.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back \n    )","8ca35d19":"# Loading the Best Fit Model \nmodel = load_model(\".\/ct_incep_best_model.hdf5\")","8f7cacc7":"# Checking the Accuracy of the Model \naccuracy_incep = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_incep*100} %\")","6c46e3a9":"incep.history.keys()","b496be57":"# Plot model performance\nacc = incep.history['accuracy']\nval_acc = incep.history['val_accuracy']\nloss = incep.history['loss']\nval_loss = incep.history['val_loss']\nepochs_range = range(1, len(incep.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","5f55df43":"from tensorflow.keras.applications import ResNet50\n\nbase_model = ResNet50(input_shape=(224, 224,3),\n                      include_top=False, weights=\"imagenet\", \n                      pooling='max')","f1f2f325":"for layer in base_model.layers:\n    layer.trainable = False","0527e86b":"model_resnet = Sequential()\nmodel_resnet.add(base_model)\nmodel_resnet.add(Dense(4, activation='softmax'))","d7c73da0":"model_resnet.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001), \n                     loss = 'categorical_crossentropy', \n                     metrics = ['accuracy'])","3db4b73c":"# Adding Model check point Callback\n\nmc = ModelCheckpoint(\n    filepath=\".\/ct_resnet_best_model.hdf5\",\n    monitor= 'val_accuracy', \n    verbose= 1,\n    save_best_only= True, \n    mode = 'auto'\n    );\n\ncall_back = [mc];","b8450a23":"# Fitting the Model\nresnet = model_incep.fit(\n    train_data, \n    steps_per_epoch = train_data.samples\/\/train_data.batch_size, \n    epochs = 32, \n    validation_data = val_data, \n    validation_steps = val_data.samples\/\/val_data.batch_size,\n    callbacks = call_back \n    )","866a4913":"# Loading the Best Fit Model \nmodel = load_model(\".\/ct_resnet_best_model.hdf5\")","8a233ed9":"# Checking the Accuracy of the Model \naccuracy_resnet = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy_resnet*100} %\")","c4585502":"resnet.history.keys()","e9143c6d":"# Plot model performance\nacc = resnet.history['accuracy']\nval_acc = resnet.history['val_accuracy']\nloss = resnet.history['loss']\nval_loss = resnet.history['val_loss']\nepochs_range = range(1, len(resnet.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","b05d2bb5":"algos = ['CNN', 'VGG16', 'InceptionV3', 'Resnet50']\naccuracy = [accuracy_cnn, accuracy_vgg, accuracy_incep, accuracy_resnet]\naccuracy = np.floor([i * 100 for i in accuracy])\n  \nfig = plt.figure(figsize = (10, 5))\n \n# creating the bar plot\nplt.bar(algos, accuracy, color ='red', width = 0.3)\n \nplt.xlabel(\"Algorithms Applied\")\nplt.ylabel(\"Accuracy\")\nplt.show()","b1459af6":"def chestScanPrediction(path, _model):\n    classes_dir = [\"Adenocarcinoma\",\"Large cell carcinoma\",\"Normal\",\"Squamous cell carcinoma\"]\n    # Loading Image\n    img = image.load_img(path, target_size=(224,224))\n    # Normalizing Image\n    norm_img = image.img_to_array(img)\/255\n    # Converting Image to Numpy Array\n    input_arr_img = np.array([norm_img])\n    # Getting Predictions\n    pred = np.argmax(_model.predict(input_arr_img))\n    # Printing Model Prediction\n    print(classes_dir[pred])","b8c70d73":"path = \"..\/input\/chest-ctscan-images\/Data\/test\/large.cell.carcinoma\/000110.png\"\nchestScanPrediction(path,model_incep)","80ffe786":"## CNN Model","b9dd363e":"## RestNet50 Model","58bb677d":"## Importing Keras for Image Classification","3b490c10":"## Comparison","a9068047":"## Inceptionv3 Model","114bc8db":"## Importing Libraries","da03dfc8":"### Predictions","4b6716b4":"## VGG16 Model"}}