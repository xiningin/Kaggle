{"cell_type":{"1ab43a14":"code","26aedbec":"code","4a4707ac":"code","7ad6e1eb":"code","b6a2dc14":"code","b3df4b3b":"code","634e67ab":"code","2645d464":"code","2ba06c88":"code","08a5dd5a":"code","a07a0162":"code","ecc66030":"code","a444966a":"code","ccd68786":"code","ab3d475c":"code","8121fdc6":"code","002e227d":"code","1edc0ea3":"code","a59fd28e":"markdown","44ea7330":"markdown","553130f8":"markdown","4338a0e8":"markdown","81202333":"markdown","f9f1dfd4":"markdown","ef19ad29":"markdown","30606cd5":"markdown","5117efa4":"markdown","5413095c":"markdown","a96e981c":"markdown","cdda0caa":"markdown","919226d3":"markdown","430aa18a":"markdown","22ec7d2b":"markdown","b41f482a":"markdown","1f0d90ea":"markdown","b3502d7d":"markdown","28bb048f":"markdown","672d0252":"markdown","a8e5dcee":"markdown","be3f088e":"markdown"},"source":{"1ab43a14":"# -*- coding: utf-8 -*-\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib as mpl\nfrom tensorflow import keras\nimport os","26aedbec":"PATH = \"..\/input\/lego-brick-images\/dataset\/\"","4a4707ac":"first = mpl.image.imread(PATH + \"2357 brick corner 1x2x2 000L.png\")\nprint(first.dtype)\nprint(first.shape)\nmpl.pyplot.imshow(first)\nmpl.pyplot.show()","7ad6e1eb":"#This function extracts filenames\ndef load_names(directory):\n    f = []\n    for (filenames) in os.walk(directory):\n        f.extend(filenames)\n        break\n    return f\ndata = pd.DataFrame(load_names(PATH) [2])\n\n#Let's check:\nprint(data.shape)\nprint(data)","b6a2dc14":"#Rename the first column for clarity\ndata.rename(columns = {0:\"file_name\"}, inplace=True)\n#Extract the piece id at the beginning of the filename\ndata[\"piece_id\"] = data[\"file_name\"].str.split(\" \").str[0]\n#Drop the filename before drop duplicates\ndata = data.drop([\"file_name\"], axis=1)\n#Drop duplicates\ndata = data.drop_duplicates()\n#Reset ids\ndata = data.reset_index(drop=True)\n#We convert the string id to numeric id\ndata[\"piece_id\"] = pd.to_numeric(data[\"piece_id\"])\n\n#Let's check the size\nprint(data.shape)\nprint(data)","b3df4b3b":"#Dictionnary of piece_id's with the order id that will be used in the classifier\ndic = data.to_dict(\"dict\")[\"piece_id\"]\n\n#Set two useful id vectors\nconversion_vector = [i for i in range(len(dic))]\nprint(conversion_vector)\nconversion_empty = [0 for i in range(len(dic))]\nprint(conversion_empty)\n\n#General variables\nCLASS_NAMES = data[\"piece_id\"]\nNB_CLASSES = len(CLASS_NAMES)","634e67ab":"np.random.seed(42)\ntf.random.set_seed(42)","2645d464":"#Load file names, all in the dataset directory, we remove auto shuffle\nlist_ds = tf.data.Dataset.list_files(str(PATH + '*'), shuffle=False)\n\n#We shuffle the list, but not at each iteration because as we don't want train, test and validation datasets to overlap on a new run\nlist_ds = list_ds.shuffle(40000, seed=42, reshuffle_each_iteration=False)\n\n#We check 2x list_ds is always shuffled in the same order\nfor i in list_ds.take(5):\n  print(i.numpy())\nfor i in list_ds.take(5):\n  print(i.numpy())","2ba06c88":"#Split\ntrain_size = int(32000)\nval_size = int(3200)\ntest_size = int(4800)\n\ntrain_ds = list_ds.take(train_size)\ntest_ds = list_ds.skip(train_size)\nval_ds = test_ds.skip(test_size)\ntest_ds = test_ds.take(test_size)\n\n#Check dataset size\nprint(tf.data.experimental.cardinality(train_ds))\nprint(tf.data.experimental.cardinality(test_ds))\nprint(tf.data.experimental.cardinality(val_ds))","08a5dd5a":"#Load and resize images to tensor with floats in the [0,1] range, at a specific size for the CNN\ndef decode_img(img):\n  img = tf.image.decode_png(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  return tf.image.resize(img, [224, 224])\n\n#Get the label corresponding to the image returning a number in the [0,50] range , corresponding to the id in the earlier DataFrame\ndef get_label(file_path):\n  parts=tf.strings.split(file_path,\n                 os.path.sep)[-1]\n  parts=tf.strings.split(parts, \" \")[0]\n  parts=tf.strings.to_number(parts, out_type=tf.dtypes.int64) \n  parts=tf.where(parts==CLASS_NAMES, conversion_vector, conversion_empty)\n  return tf.math.reduce_sum(parts)\n\n#Return Images and their corresponding label (id)\ndef process_path(file_path):\n  label = get_label(file_path)\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label","a07a0162":"#Create Loading using parallel calls, hypermeters hasn't been tweaked\ntrain_load = train_ds.map(process_path, num_parallel_calls=50)\ntest_load = test_ds.map(process_path, num_parallel_calls=50)\nval_load = val_ds.map(process_path, num_parallel_calls=50)\n\n#Check 5 images in the train dataset\nfor image, label in train_load.take(5):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","ecc66030":"\"\"\"Re-shuffle and prepare for training\"\"\"\n#Cache parameter was originally set on True\ndef prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n  if cache:\n    if isinstance(cache, str):\n      ds = ds.cache(cache)\n    else:\n      ds = ds.cache()\n\n  ds = ds.shuffle(buffer_size=shuffle_buffer_size, reshuffle_each_iteration=True)\n  # Repeat forever after shuffling at each iteration, as the sets are now clearly distinct to have different batches at each epoch\n  ds = ds.repeat()\n  \n  #Batch by 8, this was the highest value possible with my GPU\/CPU\n  ds = ds.batch(8)\n  \n  # `prefetch` lets the dataset fetch batches in the background while the model\n  # is training. Bufer size is an hyperparameter that hasn't been tweaked, set to 1.\n  ds = ds.prefetch(buffer_size=1)\n  return ds","a444966a":"train_set = prepare_for_training(train_load)\nval_set = prepare_for_training(val_load)\ntest_set = prepare_for_training(test_load)","ccd68786":"#Import a Xception Model\nbase_model = keras.applications.xception.Xception(weights=\"imagenet\",\n                                                  include_top=False)\n#Create a Average Pooling after the CNN layers\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n\n#Create a top Dense Layer\noutput = keras.layers.Dense(NB_CLASSES, activation=\"softmax\")(avg)\nmodel = keras.models.Model(inputs=base_model.input, outputs=output)\n\n#View the CNN layers\nfor index, layer in enumerate(base_model.layers):\n    print(index, layer.name)","ab3d475c":"#Train all layers in the model including pre-trained\nfor layer in base_model.layers:\n    layer.trainable = True\n\n#We set the optimizer to a Nesterov, good convergence quality, I haven't tested Nadam or RMSProp, the training is slow with the input size\noptimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n                                 nesterov=True, decay=0.001)\n\n#We use accuracy and crossentropy to have distinct classes\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n              metrics=[\"accuracy\"])","8121fdc6":"#Steps = number of batches per epoch\nhistory = model.fit(train_set,\n                    steps_per_epoch=int(32000\/8),\n                    validation_data=val_set,\n                    validation_steps=int(3200\/8),\n                    epochs=5)","002e227d":"model.evaluate(test_set,steps=int(4800\/8))","1edc0ea3":"model.save(\"lego_CNN_95.h5\")","a59fd28e":"After training we can see that the model is still converging, very slowly. We might go for 5 more epochs to get a better result, but we could risk overfitting! In fact, the training has already taken some time and 95% is already satisfying!","44ea7330":"Now with this data pipeline we can feed the model. Let's import a pre-trained model. You might wonder why I am using a Xception model.\n\nOriginally, this code was made as an exercise for Chapter 14, Geron, Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow. The book uses this model as an example and it has a reasonable amount of parameters for my bandwidth. I could have used a ResNet or VGG19, but I did not have the time to test \/ download those architectures, and the Xception worked reasonably well at the end.\n\nThe folowing part is directly extracted from this notebook:\nhttps:\/\/github.com\/ageron\/handson-ml2\/blob\/master\/14_deep_computer_vision_with_cnns.ipynb\n","553130f8":"We now set Training, Test and Validation sets:","4338a0e8":"Importation of general purpose modules:","81202333":"We load images and check the first five images of the training dataset:","f9f1dfd4":"Now we measure the accuracy of this model on the test set to evaluate our model on unseen Lego images:","ef19ad29":"That's all! If you have any question or remark, please do not hesitate to leave a comment.","30606cd5":"Here is a list of thinks I haven't done, but could be done to improve this kernel:\n\n-We could analyze images that were misclassified to see if a Human is able to differentiate them. Some 3d views are tricky displaying only parts of the block hidden by perspective and make the classification harder;\n\n-We could run this model for few epochs more;\n\n-The hyperparameters haven't been tweaked enough (to speed up the training for example);\n\n-We could plot the Train\/Val loss after training to enhance the visualization of the model or some TensorBoard visualization.","5117efa4":"95-96% accuracy on the test set is quite nice for a quick-made classifier! We can save this model as it performs well: ","5413095c":"Set seeds to handle randomness:","a96e981c":"Let's now create a function to batch randomly in each dataset. We don't use the cache, because Kaggle disk space is too small (but I originally used it on Spyder):","cdda0caa":"We then create functions to load images:\n(The following part is inspired from https:\/\/www.tensorflow.org\/tutorials\/load_data\/images)","919226d3":"Load and display an image with matplotlib:","430aa18a":"We create the table to find all labels:","22ec7d2b":"We split between training, test and validation datasets, taking the different filepaths:","b41f482a":"Define path to images (taken directly from Kaggle):","1f0d90ea":"Now let's get to Tensorflow, we load filenames as tensor:","b3502d7d":"The objective of this Kernel is to build a classifier of the 40,000 3d Lego images. (ie. I have an image of a Lego piece, what is the name \/ id of this piece ?)\n\nI used Tensorflow 2 with tf.keras and tf.data to handle those images.\nAs the total dataset is around 1Go, I am creating a pipeline to progressively feed in batches the CNN.\nThe code was originally made on Spyder and trained with Tensorflow-gpu on my computer.\nI was able to reach 96% accuracy in the test set, with a quick training on 5 epochs with the Kaggle kernel.\n\nDate: May 2020\n\nArchitecture: CNN, Transfer Learning using an Xception architecture with Tensorflow 2.\n\nAuthor: Guillaume Karklins","28bb048f":"We don't know the name and id of categories. We need to create a table to extract them. We start by recovering filenames:","672d0252":"Let's now set a dictionnary and some general purpose vectors \/ variables:","a8e5dcee":"Let's train for 5 epochs to see how good the Xception performs on the Lego dataset (I used the Kaggle GPU accelerator provided with the Kernel to accelerate the process, but still takes some time):","be3f088e":"Now let's set the optimizer to a Nesterov type, as it was used with the Xception in the book example:"}}