{"cell_type":{"9f9312ce":"code","451ed5e4":"code","003ab12a":"code","d82de5e9":"code","fb7948b9":"code","b9fd1acf":"code","8cc01723":"code","743aa02e":"code","d9324916":"markdown","ddd3b7ca":"markdown","d52f23e7":"markdown","398a2eed":"markdown","a9098345":"markdown","312eddd5":"markdown","e7b70920":"markdown"},"source":{"9f9312ce":"import pandas as pd\n\ndata = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', encoding='latin-1')\ndata = data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)","451ed5e4":"%pip install urlextract\nimport urlextract\nimport re\nimport numpy as np\n\nurl_extractor = urlextract.URLExtract()\n\ndata = data.replace(['ham','spam'],[0, 1])\ndata['Count']=0\nfor i in np.arange(0,len(data.v2)):\n    data.loc[i,'Count'] = len(data.loc[i,'v2'])\ndata['URL'] = 0\nfor i in np.arange(0,len(data.v2)):\n    data.loc[i,'URL'] = 1 if len(url_extractor.find_urls(data.loc[i,'v2'])) > 0 else 0\n\ndata['NUMBER'] = 0\nfor i in np.arange(0,len(data.v2)):\n    data.loc[i,'NUMBER'] = 1 if len(re.findall(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', data.loc[i,'v2'])) > 0 else 0\n\n\n\ndata.head()","003ab12a":"import nltk\nnltk.download('stopwords')\nfrom nltk import stem\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\n\nstemmer = stem.SnowballStemmer('english')\nstopwords = set(stopwords.words('english'))\n\ndef alternative_review_messages(msg):\n    stemmer = SnowballStemmer(\"english\")\n    msg = re.sub(r'\\W+', ' ', msg, flags=re.M)\n    # converting messages to lowercase\n    msg = msg.lower()\n    urls = list(set(url_extractor.find_urls(msg)))\n    urls.sort(key=lambda url: len(url), reverse=True)\n    for url in urls:\n        msg = msg.replace(url, \"URL\")\n    msg = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', msg)\n    # removing stopwords\n    msg = [word for word in msg.split() if word not in stopwords]\n    # using a stemmer\n    msg = \" \".join([stemmer.stem(word) for word in msg])\n    # print(msg)\n    # print(stemmer.stem(\"girls\"))\n    return msg\n\nprint(alternative_review_messages('33Ok lar... Joking wif u oni...'))","d82de5e9":"all_ = []\nfor i in np.arange(0,len(data.v2)):\n  all_.append(alternative_review_messages(data.loc[i,'v2']))\n  \nprint(len(all_))","fb7948b9":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nx = cv.fit_transform(all_).toarray()","b9fd1acf":"y = data['v1']\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x, y,test_size= 0.20, random_state = 0)","8cc01723":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report\n\ndt = MultinomialNB()\ndt.fit(xtrain, ytrain)\n","743aa02e":"y_pred_dt = dt.predict(xtest)\nprint (classification_report(ytest, y_pred_dt))\nprint('score: ', dt.score(xtest, ytest))\nfrom sklearn.metrics import recall_score\nprint('recall: ', recall_score(ytest, y_pred_dt, average='macro'))\nfrom sklearn.metrics import precision_score\nprint('prec: ', precision_score(ytest, y_pred_dt, average='macro'))\nfrom sklearn.metrics import f1_score\nprint('f1_score: ', f1_score(ytest, y_pred_dt, average='macro'))","d9324916":"### Normalize email text for spam detection","ddd3b7ca":"### Select best model","d52f23e7":"### Read data","398a2eed":"### Count words","a9098345":"### feature engineering","312eddd5":"### Split test train data","e7b70920":"### Use metrics for evaluating"}}