{"cell_type":{"1e1bda1a":"code","bc660d05":"code","f0966908":"code","a065e64f":"code","aa30a1e0":"code","9d6b699d":"code","8b127100":"code","0f62723c":"code","327d0345":"code","1f044d6e":"code","79ce6cc6":"code","58ad692a":"code","fa7cae08":"code","bb2aeeb8":"code","d20f1c62":"code","e0a0187e":"code","0cdcf630":"code","600a71ae":"code","6e5f570b":"code","ec866694":"code","28fd95f8":"code","12c139b5":"code","25141743":"code","f253b8f2":"code","f4d1d8cf":"code","483cd59f":"code","11baa089":"code","28e5c239":"code","c8ac0307":"code","6726ccbb":"code","5f2a0608":"code","d56ef0b7":"code","50fca2c9":"code","5b6b8da3":"code","c1fb70f9":"code","6592f543":"code","4b4cd355":"code","7be9f16a":"code","9ecfe189":"code","c141376c":"code","448c6261":"code","1001906c":"code","f5b69511":"code","02b8ef5f":"code","b3fb74b0":"code","89380629":"code","eec2af26":"code","cc14e3b4":"code","7d0f832f":"code","5057ed8c":"code","a4d5f1f5":"code","45f4cf78":"code","98af4727":"code","7da154e5":"code","7a0a9394":"code","5bcef669":"code","d686e40c":"code","066feef7":"code","911d85f5":"markdown","38a2330d":"markdown","81bf9d5c":"markdown","6b7d57c7":"markdown","8cb9b745":"markdown","855bdd38":"markdown","0708b05a":"markdown","94391858":"markdown","6f436990":"markdown","285d140d":"markdown","9ff65275":"markdown","23b750c6":"markdown","b1a15f01":"markdown","2769fc70":"markdown","ed569b73":"markdown","e63c84f6":"markdown","2e4e3071":"markdown","4f03d6ee":"markdown","a00e58dc":"markdown","1bac7be8":"markdown","dc6d5308":"markdown","ef5471cd":"markdown","f7642cdb":"markdown","5d875bfd":"markdown","ebc34d05":"markdown","31795f84":"markdown","35cd3898":"markdown","69381661":"markdown","1a110157":"markdown","37bb16a3":"markdown"},"source":{"1e1bda1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc660d05":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom lightgbm import LGBMClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\npd.set_option('display.max_columns', None)","f0966908":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntrain.head()","a065e64f":"test = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\ntest.head()","aa30a1e0":"sample_submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')\nsample_submission.head()","9d6b699d":"train.isnull().sum()","8b127100":"test.isnull().sum()","0f62723c":"train.info()","327d0345":"train.shape","1f044d6e":"test.shape","79ce6cc6":"train.drop('id', axis=1, inplace = True)","58ad692a":"test.drop('id', axis=1, inplace = True)","fa7cae08":"for i in train.columns:\n    print(train[i].value_counts())","bb2aeeb8":"for i in train.columns:\n    sns.histplot(train[i])\n    plt.show()","d20f1c62":"X = train.iloc[:,0:50]\ny = train.iloc[:,50:]\n\ny = np.ravel(y)","e0a0187e":"np.seterr(divide = 'ignore')\nfor i in X.columns:\n    #X[i] = np.where(X[i]>0, np.log1p(X[i]), 0)\n    X[i] = np.log(X[i]-(min(X[i]-1)))","0cdcf630":"np.seterr(divide = 'ignore')\nfor i in test.columns:\n    #test[i] = np.where(test[i]>0, np.log1p(test[i]), 0)\n    test[i] = np.log(test[i]-(min(test[i]-1)))","600a71ae":"label = LabelEncoder()\ny = label.fit_transform(y)","6e5f570b":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 42)","ec866694":"skfold = StratifiedKFold(n_splits=5)","28fd95f8":"pipe_1 = Pipeline([\n    ('scale',StandardScaler()),\n    ('gnb',GaussianNB())\n])","12c139b5":"cross_score = cross_val_score(pipe_1,X,y,cv=skfold)\nprint(np.mean(cross_score))","25141743":"pipe_2 = Pipeline([\n    ('scale',StandardScaler()),\n    ('bnb',BernoulliNB())\n])","f253b8f2":"cross_score = cross_val_score(pipe_2,X,y,cv=skfold)\nprint(np.mean(cross_score))","f4d1d8cf":"pipe_3 = Pipeline([\n    ('scale',StandardScaler()),\n    ('lr',LogisticRegression(solver = 'sag',multi_class='multinomial'))\n])","483cd59f":"cross_score = cross_val_score(pipe_3,X,y,cv=skfold)\nprint(np.mean(cross_score))","11baa089":"pipe_4 = Pipeline([\n    ('scale',StandardScaler()),\n    ('rf',RandomForestClassifier())\n])","28e5c239":"cross_score = cross_val_score(pipe_4,X,y,cv=skfold)\nprint(np.mean(cross_score))","c8ac0307":"pipe_5 = Pipeline([\n    ('scale',StandardScaler()),\n    ('lgbm',LGBMClassifier())\n])","6726ccbb":"cross_score = cross_val_score(pipe_5,X,y,cv=skfold)\nprint(np.mean(cross_score))","5f2a0608":"pipe_6 = Pipeline([\n    ('scale',StandardScaler()),\n    ('xgb',XGBClassifier())\n])","d56ef0b7":"cross_score = cross_val_score(pipe_6,X,y,cv=skfold)\nprint(np.mean(cross_score))","50fca2c9":"pipe_7 = Pipeline([\n    ('scale',StandardScaler()),\n    ('knn',KNeighborsClassifier())\n])","5b6b8da3":"cross_score = cross_val_score(pipe_7,X,y,cv=skfold)\nprint(np.mean(cross_score))","c1fb70f9":"params = {\n    'lgbm__boosting_type' : ['gbdt'],\n    'lgbm__objective' : ['multiclass'],\n    'lgbm__num_leaves': [30,35,40],\n    'lgbm__learning_rate' : [0.001,0.01,0.1],\n}","6592f543":"lgbm_search = GridSearchCV(pipe_5, params)","4b4cd355":"lgbm_search.fit(X_train,y_train)","7be9f16a":"lgbm_search.best_params_","9ecfe189":"lgbm_search.best_score_ ","c141376c":"params = {\n    'bnb__alpha' : [1.0,2.0,3.0,4.0,5.0]\n}","448c6261":"bnb_search = GridSearchCV(pipe_2, params)","1001906c":"bnb_search.fit(X,y)","f5b69511":"bnb_search.best_params_","02b8ef5f":"bnb_search.best_score_ ","b3fb74b0":"pipe_2 = Pipeline([\n    ('scale',StandardScaler()),\n    ('bnb',BernoulliNB(alpha=4.0))\n])","89380629":"pipe_2.fit(X_train,y_train)","eec2af26":"predictions = pipe_2.predict(X_test)\nprint(predictions)","cc14e3b4":"probability_predictions = pipe_2.predict_proba(X_test)\nprobability_predictions","7d0f832f":"probability_predictions = pipe_2.predict_proba(test)\nprobability_predictions","5057ed8c":"sample_submission.iloc[:,1:5] = probability_predictions\nsample_submission","a4d5f1f5":"sample_submission.to_csv('submission.csv',index=False)","45f4cf78":"pipe_5 = Pipeline([\n    ('scale',StandardScaler()),\n    ('lgbm',LGBMClassifier(boosting_type='gbdt',num_leaves=35, learning_rat=0.1,objective='multiclass'))\n])","98af4727":"pipe_5.fit(X_train,y_train)","7da154e5":"predictions = pipe_5.predict(X_test)\nprint(predictions)","7a0a9394":"probability_predictions = pipe_5.predict_proba(X_test)\nprobability_predictions","5bcef669":"probability_predictions = pipe_5.predict_proba(test)\nprobability_predictions","d686e40c":"sample_submission.iloc[:,1:5] = probability_predictions\nsample_submission","066feef7":"sample_submission.to_csv('submission_lgbm.csv',index=False)","911d85f5":"## \ud83d\udef0\ufe0f Check train data shape","38a2330d":"## \ud83d\udef0\ufe0f Loading sample submission dataset","81bf9d5c":"## \ud83d\udef0\ufe0f Loading test dataset","6b7d57c7":"## \ud83d\udef0\ufe0f Predicting probabilities for all classes for BernoulliNB algorithm","8cb9b745":"## \ud83d\udef0\ufe0f Separating dependent and independent variables","855bdd38":"## \ud83d\udef0\ufe0f Drop 'id' column from train dataset","0708b05a":"## \ud83d\udef0\ufe0f Loading test dataset","94391858":"# \ud83d\ude80 Data Preprocessing","6f436990":"## \ud83d\udef0\ufe0f Tuning hyperparameters for BernoulliNB","285d140d":"## \ud83d\udef0\ufe0f Verify the values under each feature","9ff65275":"## \ud83d\udef0\ufe0f Checking for null values in test dataset","23b750c6":"# \ud83d\ude80 Importing Libraries","b1a15f01":"## \ud83d\udef0\ufe0f Splitting the data into training and validation","2769fc70":"## \ud83d\udef0\ufe0f Check the data distribution","ed569b73":"# \ud83d\ude80 Building Model Pipeline","e63c84f6":"## \ud83d\udef0\ufe0f Checking for null values in train dataset","2e4e3071":"## \ud83d\udef0\ufe0f Log Transform Train data","4f03d6ee":"## \ud83d\udef0\ufe0f Check data information","a00e58dc":"## \ud83d\udef0\ufe0f Tuning hyperparameters for LightGBM","1bac7be8":"## \ud83d\udef0\ufe0f  Label Encoding target variable","dc6d5308":"## \ud83d\udef0\ufe0f Predicting probabilities on test dataset using BernoulliNB algorithm","ef5471cd":"# \ud83d\ude80 Loading Train and Test dataset","f7642cdb":"## \ud83d\udef0\ufe0f Check test data shape","5d875bfd":"## \ud83d\udef0\ufe0f Predicting probabilities on test dataset using LightGBM algorithm","ebc34d05":"# \ud83d\ude80 Exploratory Data Analysis (EDA)","31795f84":"## \ud83d\udef0\ufe0f Drop 'id' column from test dataset","35cd3898":"## \ud83d\udef0\ufe0f Log Transform Test data","69381661":"# \ud83d\ude80 Hyperparamaters Tuning","1a110157":"## \ud83d\udef0\ufe0f Trying different models","37bb16a3":"## \ud83d\udef0\ufe0f Predicting probabilities for all classes for LightGBM algorithm"}}