{"cell_type":{"071a6dcf":"code","29dff18a":"code","b2e132d7":"code","80a4525e":"code","d952f044":"code","8d95e4e9":"code","cd00f17d":"code","504aa3ff":"code","0203efc2":"code","ebc49ca4":"code","746f7e67":"code","3b8465aa":"code","206764a2":"code","5f898af7":"code","7e230d40":"code","21fa07dd":"code","9e0257aa":"code","f821ff31":"code","8e47add5":"code","cfd873e1":"code","69e0ddb5":"code","897d7611":"code","6125a076":"code","17cd7e78":"code","015d885c":"code","3c50903c":"code","b577c400":"code","856404de":"code","b8bbad7a":"code","35f38c36":"code","99c54a83":"code","72c8fa33":"code","860367bd":"code","d880a91d":"code","b199417e":"code","9308eedf":"code","8ef68b44":"code","bbed4d50":"code","4a1fd817":"code","e3edcdde":"code","91b1927c":"code","1a9e97c3":"code","a3541cc9":"code","3a8d5aa8":"code","948739d5":"code","3b03dbdd":"code","01f2204f":"code","933a6976":"code","78c00e81":"code","3e62effb":"code","c59dafb4":"code","1c0e9488":"code","536da02b":"code","616c1983":"code","d02073b0":"code","fc77e428":"code","6755917e":"code","0fabcad0":"code","da5cfec5":"code","b93ebdc9":"code","9586ac89":"markdown","c11f3bc2":"markdown","5d77650f":"markdown","d0ce4b69":"markdown","fc0fdd4f":"markdown","f2dbb217":"markdown","87c2c1ef":"markdown","897c3379":"markdown","19d1ca6a":"markdown"},"source":{"071a6dcf":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","29dff18a":"s_t = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/train.csv\")","b2e132d7":"s_t.head()","80a4525e":"s_t.shape","d952f044":"s_t.isnull().sum()","8d95e4e9":"s_t.nunique()","cd00f17d":"from datetime import date","504aa3ff":"s_t['date'] = pd.to_datetime(s_t.date)","0203efc2":"s_t['day'] = s_t.date.apply(lambda x:x.day)\ns_t['month'] = s_t.date.apply(lambda x: x.month)\ns_t['weekday'] = s_t.date.apply(lambda x:x.dayofweek)","ebc49ca4":"s_t.head()","746f7e67":"s_t.drop(['row_id','date'],axis=1,inplace = True)","3b8465aa":"for i in list(s_t.columns):\n    print(s_t[i].unique())","206764a2":"def product(c):\n    l = c.split(' ')\n    return l[1]","5f898af7":"s_t['product'] = s_t['product'].apply(product)","7e230d40":"s_t.head(2)","21fa07dd":"from sklearn.preprocessing import OneHotEncoder,LabelEncoder,LabelBinarizer","9e0257aa":"ohc = OneHotEncoder()\nle = LabelEncoder()\nlb = LabelBinarizer()\ncol = ['country','store','product']\ns_t[col].head().T\ns_t = pd.get_dummies(s_t, columns=col, drop_first=False)\n# for i in col:\n#     if s_t[i].nunique() == 2:\n#         s_t[i] = lb.fit_transform(s_t[i]).astype(int)\n#     else:\n#         s_t[i] = le.fit_transform(s_t[i]).astype(int)","f821ff31":"s_t.head()","8e47add5":"tst = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\ntstc = tst.copy()\ntst['date'] = pd.to_datetime(tst.date)\ntst['day'] = tst.date.apply(lambda x:x.day)\ntst['month'] = tst.date.apply(lambda x: x.month)\ntst['weekday'] = tst.date.apply(lambda x:x.dayofweek)\ntst.drop(['row_id','date'],axis=1,inplace = True)\ntst['product'] = tst['product'].apply(product)\ncol = ['country','store','product']\ntst = pd.get_dummies(tst, columns=col, drop_first=False)\ntst.head(2)","cfd873e1":"x_d = s_t.drop('num_sold',axis = 1)\ny_d = s_t['num_sold']","69e0ddb5":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nlr = LinearRegression()\nrr = Ridge(max_iter = 10000,alpha = 10,fit_intercept = True,random_state = 34)\nls = Lasso(max_iter = 1000000,alpha = 0.0005,fit_intercept = True,random_state = 34)","897d7611":"from sklearn.model_selection import train_test_split,GridSearchCV,KFold\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\ns = StandardScaler()\nm = MinMaxScaler()\nkf = KFold(n_splits = 8,random_state = 32,shuffle = True)\npf = PolynomialFeatures()\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox","6125a076":"from sklearn.metrics import r2_score,accuracy_score,mean_squared_error","17cd7e78":"x_train,x_test,y_train,y_test = train_test_split(x_d,y_d,test_size = 0.2)","015d885c":"mm = m.fit_transform(x_train)\nmm1 = m.transform(x_test)\ntr = boxcox(y_train)\ny = tr[0]\nlam = tr[1]","3c50903c":"ls.fit(mm,y)","b577c400":"y_pred = ls.predict(mm1)\nf_y_pred = inv_boxcox(y_pred,lam)","856404de":"r2_score(y_test,f_y_pred)","b8bbad7a":"m1 = m.fit_transform(x_train)\nm2 = m.transform(x_test)\nrr.fit(m1,y)\nr_pred = rr.predict(m2)","35f38c36":"new_y = inv_boxcox(r_pred,lam)","99c54a83":"r2_score(y_test,new_y)","72c8fa33":"from sklearn.neighbors import KNeighborsRegressor\nkn= KNeighborsRegressor(n_neighbors = 5)\nkn.fit(m1,y)\nk_pred = kn.predict(m2)","860367bd":"new_k = inv_boxcox(k_pred,lam)\nr2_score(y_test,new_k)","d880a91d":"from sklearn.svm import SVR","b199417e":"sv_l = SVR(kernel = 'rbf',C = 12.0,gamma = 'scale',max_iter = 100000000)","9308eedf":"sv_l.fit(m1,y)\nsv_pred = sv_l.predict(m2)","8ef68b44":"f_sv = inv_boxcox(sv_pred,lam)\nr2_score(y_test,f_sv)","bbed4d50":"# from sklearn.tree import DecisionTreeRegressor","4a1fd817":"# dc = DecisionTreeRegressor(criterion = 'mse',max_depth = 10,max_features = 'auto',random_state = 34)","e3edcdde":"# dc.fit(m1,y)","91b1927c":"# dc_r = dc.predict(m2)\n# f_dc = inv_boxcox(dc_r,lam)\n# r2_score(y_test,f_dc)","1a9e97c3":"# from sklearn.ensemble import BaggingRegressor","a3541cc9":"# bg = BaggingRegressor(n_estimators = 500,max_features = 11)","3a8d5aa8":"# bg.fit(m1,y)","948739d5":"# bg_p = bg.predict(m2)\n# f_bg = inv_boxcox(bg_p,lam)\n# r2_score(y_test,f_bg)","3b03dbdd":"# from sklearn.ensemble import RandomForestRegressor","01f2204f":"# rf = RandomForestRegressor(n_estimators = 500,criterion = 'mse',max_depth = 10,max_features = 'auto',random_state = 34)\n# rf.fit(m1,y)","933a6976":"# rfs = rf.predict(m2)\n# rf_s = inv_boxcox(rfs,lam)\n# r2_score(y_test,rf_s)","78c00e81":"# from sklearn.ensemble import GradientBoostingRegressor","3e62effb":"# gr = GradientBoostingRegressor(learning_rate=0.1,n_estimators = 1000,criterion = 'mse',max_features = 'sqrt',max_depth = 15,random_state = 34,)","c59dafb4":"# gr.fit(m1,y)","1c0e9488":"# y_gr = gr.predict(m2)\n# fgr = inv_boxcox(y_gr,lam)\n# r2_score(y_test,fgr)","536da02b":"# from sklearn.ensemble import AdaBoostRegressor","616c1983":"# abc = AdaBoostRegressor(n_estimators = 900,learning_rate = 0.2,loss = 'linear')","d02073b0":"# abc.fit(m1,y)","fc77e428":"# ab = abc.predict(m2)\n# fab = inv_boxcox(ab,lam)\n# r2_score(y_test,fab)","6755917e":"# m3 = m.fit_transform(x_d)\n# m4 = m.transform(tst)\n\n\n# rf_y = boxcox(y_d)\n# rfy = rf_y[0]\n# lam1 = rf_y[1]\n\n\n# rf.fit(m3,rfy)\n# prf = rf.predict(m4)\n\n\n# rfn = inv_boxcox(prf,lam1)","0fabcad0":"# xgb_params = {\n#         'tree_method': 'hist',\n#         'grow_policy' : 'lossguide',\n#         'learning_rate': 0.03399878704233446,\n#         'max_depth': 5,\n#         'reg_alpha': 0.7814373604498039,\n#         'reg_lambda': 0.00018093104956619317,\n#         'max_delta_step': 2,\n#         'min_child_weight': 14,\n#         'colsample_bytree': 0.6489299778623602,\n#         'subsample': 0.6033298718112065,\n#        lea 'max_ves': 187,  \n#         }","da5cfec5":"from xgboost import XGBRegressor\nxg = XGBRegressor(n_estimators = 10000,grow_policy ='lossguide',learning_rate = 0.06399878704233446, max_depth = 18 ,reg_alpha =  0.2814373604498039,reg_lambda= 0.80018093104956619317,colsample_bytree= 0.9589299778623602,subsample=0.9833298718112065,max_leaves= 187,tree_method= 'hist',max_delta_step= 3,booster = 'gbtree')\nxg.fit(m1,y)\nxgb = xg.predict(m2)\nfx = inv_boxcox(xgb,lam)\nr2_score(y_test,fx)","b93ebdc9":"m5 = m.fit_transform(x_d)\nm6 = m.transform(tst)\n\nxg_y = boxcox(y_d)\nxgy = xg_y[0]\nlam2 = xg_y[1]\n\nxg.fit(m5,xgy)\nprx = xg.predict(m6)\n\nxgt = inv_boxcox(prx,lam2)\n\n\nfinal = pd.DataFrame(xgt,columns = ['num_sold'])\nfinal['row_id'] = tstc.row_id\nfinal.to_csv('submission.csv',index=False)","9586ac89":"**Creating month,day,weekday from the date column**","c11f3bc2":"***XGboost regressor score is  5.85 now and i will try to experiment more to improve it.***","5d77650f":"**imported the necessary encoders but they are not required**","d0ce4b69":"**We see ;the RandomForestRegressor result looks more promising and we will use that to train the whole training dataset and predict over the test dataset**","fc0fdd4f":"***The score is now 6.00 and rank is 327***","f2dbb217":"**lets test with all the regression techniques and i will use m1 which is the scaled version of x_d and y which is transformed using boxcox method. M1 and M2 and Y are defined after two steps**","87c2c1ef":"**Process the test data in same way**","897c3379":"**create the train and target data to train, use train_test_split to test different regression techniques and import necessary libraries. I have scaled the data using minmax scaler mostly**","19d1ca6a":"**lets drop the row_id and date column as they are not usefull**"}}