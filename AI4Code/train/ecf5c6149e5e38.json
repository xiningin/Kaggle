{"cell_type":{"3c0eeba0":"code","c346aff1":"code","a1a69bed":"code","30e3f5af":"code","2ae0f74f":"code","d0c258e6":"code","f52dfc13":"code","5166dfeb":"code","ecf5d22f":"code","6cbaf795":"code","f5c26a0d":"code","bf8d00ec":"code","1454734e":"code","501ca0c9":"code","e084f7ec":"code","73aec3ed":"code","e3a20033":"code","2a9ac580":"code","900d24a9":"code","54d76800":"code","ce7486a9":"code","5e791bbe":"code","472b95f6":"code","61aa2c1d":"code","bf1a7867":"code","6e0f9533":"code","f0c42403":"code","26fca51c":"code","30ac66e6":"code","21ac0e2d":"code","39cf3f95":"code","10d7ec34":"code","24ab9638":"code","b7d0a802":"code","7c508935":"code","936e758a":"code","43586229":"code","4323eccc":"code","aa3fcf90":"code","a33d22d0":"code","d797a87a":"code","06939ac6":"markdown","09d2bfaf":"markdown","cdc24638":"markdown","4d0a25d4":"markdown","ca563b1b":"markdown","b68f83aa":"markdown","d3576cd0":"markdown","2d3f3779":"markdown","af644f91":"markdown","40944d33":"markdown","77a2fb72":"markdown","09dfc5ab":"markdown","f035237e":"markdown","de8da8f3":"markdown","64ae6f79":"markdown","b526538e":"markdown","d0f5ad3b":"markdown","d61fd749":"markdown","e87afa07":"markdown","54ae5331":"markdown","7cf88a3c":"markdown","df6c392d":"markdown","9cec6546":"markdown","967341bd":"markdown","e285389a":"markdown","c601e5cf":"markdown","f6f08602":"markdown","11f43df7":"markdown","2bbdd74c":"markdown"},"source":{"3c0eeba0":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c346aff1":"# Importing the required libraries\nimport numpy as np\nimport pandas as pd","a1a69bed":"# Importing the metadata of movies\ndf1 = pd.read_csv('\/kaggle\/input\/the-movies-dataset\/movies_metadata.csv')","30e3f5af":"df1.head()","2ae0f74f":"df = df1[['title', 'tagline', 'original_title', 'overview', 'genres']]","d0c258e6":"# Setting `title` as the index\ndf.set_index('title',inplace = True)","f52dfc13":"df.isna().sum()","5166dfeb":"df.dropna(subset = ['overview'], inplace = True)","ecf5d22f":"from ast import literal_eval\ndf['genres'] = df['genres'].apply(literal_eval).apply(lambda x: [i['name'] for i in x] \n                                                                   if isinstance(x, list) else [])\n                                                                # List Comprehension","6cbaf795":"# Selecting only those rows which have an actual genre\ngenre_present = df['genres'] != '[]'\n\n# Series of the genres present in the movies_metadata\ngenres = df['genres'][genre_present]","f5c26a0d":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\n\nlabels = mlb.fit_transform(genres)\nlabel_classes = mlb.classes_","bf8d00ec":"label_classes","1454734e":"label_data = pd.DataFrame(labels, columns=label_classes)","501ca0c9":"val = {}\nfor x in label_classes :\n    val.update({x:label_data[x].value_counts()[1]})","e084f7ec":"sorted_val = sorted(val.items(), key=lambda kv: kv[1], reverse=True)","73aec3ed":"val_pd = pd.DataFrame.from_dict(sorted_val, orient='columns')\nval_pd.rename(columns={0: \"Genre\", 1: \"Count\"}, inplace = True) ","e3a20033":"val_pd","2a9ac580":"dummy_counts = sorted(val.items(), key=lambda kv: kv[1], reverse=True)[0:20] # Selecting the first 20 genres.\ndummy_counts","900d24a9":"# List Comprehension\ngenre_counts = [i[0] for i in dummy_counts]","54d76800":"genre_counts","ce7486a9":"final_genres = MultiLabelBinarizer(classes = genre_counts) \n# 'genre_counts' is the final list of genres that will be used for futher training ot model\n\ntop = final_genres.fit(genres)","5e791bbe":"# Dependent Variable\ny = final_genres.transform(genres)","472b95f6":"final_genres.classes_","61aa2c1d":"# Independent Variable\nX = df['overview']","bf1a7867":"# Including only those rows\nno_label_classes = y.sum(axis = 1) == 0","6e0f9533":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X[~no_label_classes], y[~no_label_classes],\n                                                     test_size = 0.3, random_state = 1234)","f0c42403":"X_train.shape, y_train.shape","26fca51c":"X_valid.shape, y_valid.shape","30ac66e6":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(max_features = 1000, stop_words = 'english', lowercase = True)\n\nX_train_vec = vectorizer.fit_transform(X_train)\nX_valid_vec = vectorizer.transform(X_valid)","21ac0e2d":"X_train_vec","39cf3f95":"from sklearn.model_selection import GridSearchCV\n\ndef model_building(model, parameters = None, cv = 10):\n    if parameters == None:\n        model.fit(X_train_vec, y_train)\n        return(model, model.predict(X_train_vec), model.predict(X_valid_vec))\n    else:\n        model_cv = GridSearchCV(estimator = model, param_grid = parameters, cv = cv)\n        model_cv.fit(X_train_vec, y_train)\n        model = model_cv.best_estimator_\n            \n        return(model_cv,model, model.predict(X_train_vec), model.predict(X_valid_vec))","10d7ec34":"### Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\ndtr = DecisionTreeClassifier()\nmodel, train_dtr, valid_dtr = model_building(dtr)","24ab9638":"from sklearn.metrics import classification_report, accuracy_score\nprint(\"Classification Report\")\nprint(\"Training:\\n\",classification_report(y_true = y_train, y_pred = train_dtr, target_names = genre_counts))\nprint(\"Validation:\\n\",classification_report(y_true = y_valid, y_pred = valid_dtr, target_names = genre_counts))\n\nprint(\"Accuracy\")\ntrain_dtr_acc = accuracy_score(y_true = y_train, y_pred = train_dtr)\nvalid_dtr_acc = accuracy_score(y_true = y_valid, y_pred = valid_dtr)\nprint(\"Traning: \", train_dtr_acc)\nprint(\"Validation: \",valid_dtr_acc)","b7d0a802":"### Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\nmodel, train_rfc, valid_rfc = model_building(rfc)","7c508935":"print(\"Classification Report\")\nprint(\"Training:\\n\",classification_report(y_true = y_train, y_pred = train_rfc, target_names = genre_counts))\nprint(\"Validation:\\n\",classification_report(y_true = y_valid, y_pred = valid_rfc, target_names = genre_counts))\n\nprint(\"Accuracy\")\ntrain_rfc_acc = accuracy_score(y_true = y_train, y_pred = train_rfc)\nvalid_rfc_acc = accuracy_score(y_true = y_valid, y_pred = valid_rfc)\nprint(\"Traning: \", train_rfc_acc)\nprint(\"Validation: \",valid_rfc_acc)","936e758a":"### MLP Classifier\nfrom sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(verbose = True, max_iter = 100, hidden_layer_sizes=(100))\n\nmodel, train_mlp, valid_mlp = model_building(mlp, cv = 10)","43586229":"print(\"Classification Report\")\nprint(\"Training:\\n\",classification_report(y_true = y_train, y_pred = train_mlp, target_names = genre_counts))\nprint(\"Validation:\\n\",classification_report(y_true = y_valid, y_pred = valid_mlp, target_names = genre_counts))\n\nprint(\"Accuracy\")\ntrain_mlp_acc = accuracy_score(y_true = y_train, y_pred = train_mlp)\nvalid_mlp_acc = accuracy_score(y_true = y_valid, y_pred = valid_mlp)\nprint(\"Traning: \", train_mlp_acc)\nprint(\"Validation: \",valid_mlp_acc)","4323eccc":"# Evaluation Metrics' Dataframe\ntrain_acc = [train_dtr_acc, train_rfc_acc, train_mlp_acc]\nvalid_acc = [valid_dtr_acc, valid_rfc_acc, valid_mlp_acc]\neval_mat = pd.DataFrame([train_acc, valid_acc],  index = ['Traning','Validation'],\n                        columns = ['Decision Tree Classifier', 'Random Forest Classifier', 'MLP Classifier'])","aa3fcf90":"eval_mat.T","a33d22d0":"test_preds = final_genres.inverse_transform(valid_mlp)","d797a87a":"[list(i) for i in test_preds][0:10]","06939ac6":"The purpose of the following code is to *excluded* any such instances where the genres absent or is '[ ]'.","09d2bfaf":"On filtering the actual list of genres, we can now proceed for further processing.\n___\nBinarizing the selected genres.","cdc24638":"As discussed earlier, the genre(s) of any movie can be identified by its reviews or description. Here, we have a feature `overview` and we  will use this to predict the genre(s) of the movies.","4d0a25d4":"The genre(s) of any movie can be identified by its reviews or description. Here, we have a feature `overview` and we  will use this to predict the genre(s) of the movies.\n\nHence, if for any instance there is *no overview present*, we shall *drop* that partcular instance(s).","ca563b1b":"## Step 1: Extracting the `genres` of each film(row) present in the list of dictionery\/ies under the **key** `name`.","b68f83aa":"Ref: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPClassifier.html","d3576cd0":"## Challenges Faced\n\n1. Extracting genres from the list of dictionaries present in the feature genres.\n2. Selecting the right method to convert multi-class labels\n3. Selecting the right classification algorithm\n4. Evaluation metrics\n5. Combining the validation dataset after predicting the genres\n___","2d3f3779":"## Step 3: Separaring the independent variable","af644f91":"Ref: https:\/\/kite.com\/python\/answers\/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python","40944d33":"## Step 2: Separating and selecting the genres","77a2fb72":"#### Train-Validation Split","09dfc5ab":"Ref: https:\/\/datascience.stackexchange.com\/questions\/11797\/split-a-list-of-values-into-columns-of-a-dataframe","f035237e":"**ATTENSION**\n\nIf we have a review present but there is no genre present, this would mistrain our predictive model. Therefore for training, we would include only those rows which contains actual genres and not '[ ]'\n\nOne of the simplest ways to perform this action is to check the sum of each row in the genres after executing the MultiLabelBinarizer. If the sum equals 0, this proves that the particular movie has no genres mentioned . Hence, we would not include them in the training purpose.","de8da8f3":"Sorting the `genres` according to the number of instances in *ascending* order.","64ae6f79":"Ref: https:\/\/www.kaggle.com\/rounakbanik\/movie-recommender-systems, In [3]","b526538e":"# <center>Predicting the movie genres<\/center>\n___\n\n## Abstract\n> From a long time, movies have been an amazing source of entertainment. It has given a chance for family members to enjoy together, for friends to socialize and for artists to display their talents, be it an actor\/actress, directors, cinematographer, dialogue writers and so on. Movies have been a visual art that focuses on storytelling, communicating ideas, stimulate different experiences(like romance, anger, travel, etc.)\n\n> In the initial years of filming, films were recorded on a celluloid film through a photochemical process. Since movies are nothing but continuous series of pictures, there were no possibility to include sounds with the moving frames. As humans progressed, learned new techniques to record and display movies, we transitioned to large movie projectors. This gave us a chance to include sound to our motion-pictures. And in no time, we transioned to the era of digital cameras which eased the efforts or recording a movie along with the sound. \n\n> I have been a fan of movies, as it gave me an opportunity to look at the world in a broader perspective. I am not a detective, but Sherlock Holmes enlightened me to the world of detectives. I am not a stockbroker, but The Wolf Of Wall Street gave me deep insights to what it takes to be a one. I have never learned or studied mythology, but The Ramayana educated me with it's prolonged history and it's importance.\n___\n\n## Introduction\n#### 1. Problem Statement\n> Movies have a range of genres; from romance to sci-fi to drama to comedy and so on. In this notebook, I will try to **predict the genres** of the movies based on _title, tagline, original_title_ and _overview_. With us, we have a dataset of about 45000 movies with metadata collected from IMDB and complied on Kaggle (https:\/\/www.kaggle.com\/rounakbanik\/the-movies-dataset).\n\n#### 2. Key Documents\n>  Out of the 7 documents, as directed, we would only use **movies_metadata.csv**.\n\n#### 3. Breakdown of this notebook\n  > 1. Importing Libraries\n  2. Loading the dataset\n  3. Remove\/filling the NaN values from the datasets.\n  4. Cleaning the dataset\n  6. Classification Analysis:\n    1. Decision Tree Classifier\n    2. Random Forest Classifier\n    3. Multi-layer Perceptron (MLP) Classifier","d0f5ad3b":"## Model Building\n___\nSince we build a classification model, we would build the following models:\n1. Decision Tree Classifier\n2. Random Forest Classifier\n\nOn researching on multiclass classification, I found out about **MLPClassifer**. \n\nThe advantage of MLP Classifier is this implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values. Being out training credentials are sparse matrix and numpy arrays, this would, intuitively, help build a better classification model. \n","d61fd749":"___","e87afa07":"As mentioned earlier, the genres would be predicted based on the `overview`. \n\nThe steps that we follow are as following:\n  1. Convert the overview rows into TF-IDF features using TfidfVectorizer\n  2. Train and build a multi-class classification model\n  3. Predict the genres of the given overview.","54ae5331":"Ref: https:\/\/stackoverflow.com\/questions\/613183\/how-do-i-sort-a-dictionary-by-value","7cf88a3c":"We have _vectorized_ the `overview` columns and are done with preprocessing steps, we can now build our predictive model.","df6c392d":"<div class=\"alert alert-block alert-info\"><b> \n    \n- According to the problem statement, we need only the following columns:\n    1. title, \n    2. tagline\n    3. original_title\n    4. overview \n    5. genres\n    \n  Hence, we subset these columns into a new dataframe.\n<\/b><\/div>","9cec6546":"When we look at those rows, we notice that the `genres` with value count 1 do not seem to be genres. They seem to be names of production houses or TV channels.\n\nHence we would drop these rows to reduce our search space.\n___\n\nConversely, we can select the top 20 `genres` from the above data frame for prediction which contain the actual genres.","967341bd":"Observations:\n - As we know the characteristic of **Decision trees**, they tend to *overfit* the traning dataset (as it can be seen above too) and perfomance is measured on the validation dataset. We can clearly see that **Decision Tree Classifier** fails to perform well on the validation dataset.\n \n - **Random Forest** is a bagging algorithm and has a better control on over-fitting. Here, we can see that **Random Forest Classifier** has better performance that decision tree.\n \n - **Multi-layer Perceptron (MLP)** is based on neural networks and uses a supervised learning technique called backpropagation for training. In the above dataframe, we can clearly see that **MLP Classifier** performs the best among the 3.\n \n____\n\n","e285389a":"<div class=\"alert alert-block alert-info\"><b> \n    \n- The genres excluded in the genre_counts will be ignored while implementing MultiLabelBinarizer.\n  \n<\/b><\/div>","c601e5cf":"Displaying the predicted genres.","f6f08602":"___","11f43df7":"Here, we select only the first top 20 genres from a list of tuples.","2bbdd74c":"## Future Scope\n\n1. Hyper parameter tuning\n"}}