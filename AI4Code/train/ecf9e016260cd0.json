{"cell_type":{"5cab9c48":"code","7cbae51f":"code","c9cfb7a3":"code","f4d3c6f5":"code","3c4b1ed9":"code","70b94ae6":"code","3ea7b112":"code","24bac4b1":"code","e2bbe9ba":"code","b64f6637":"code","71c48390":"code","5dd8c736":"code","4d62369e":"code","610d9d84":"code","a4aef2fe":"code","b82a277b":"code","d80749d0":"code","98eb676c":"code","7d1d86ae":"code","98f511cf":"code","43736d7f":"code","2a697b9f":"code","b2542197":"code","e674f201":"code","1a4ab790":"markdown","63fa5abe":"markdown","6e20720f":"markdown","74053d63":"markdown","cd83e5c9":"markdown","8b11136d":"markdown","e4fbe175":"markdown","865f0592":"markdown","d6df4a1c":"markdown","f7ff5cf3":"markdown","cb1ffb1e":"markdown","6386a047":"markdown","87785ca0":"markdown"},"source":{"5cab9c48":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler","7cbae51f":"if(torch.cuda.is_available()):\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\nprint(device)","c9cfb7a3":"stats = ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n\ntransform = transforms.Compose([\n    transforms.Resize((120,120)),\n    transforms.ColorJitter(0.05),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize(*stats, inplace=True)\n])","f4d3c6f5":"input_dir = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images'\ntrain_set = ImageFolder(input_dir, transform=transform)","3c4b1ed9":"print(len(train_set))","70b94ae6":"test_size = 0.2\n\nnum_train = len(train_set)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\n\ntest_split = int(np.floor((test_size) * num_train))\ntest_index, train_index = indices[:test_split - 1], indices[test_split - 1:]\n\ntrain_sampler = SubsetRandomSampler(train_index)\ntest_sampler = SubsetRandomSampler(test_index)\n\ntrain_loader = DataLoader(train_set, sampler=train_sampler, batch_size=128)\ntest_loader = DataLoader(train_set, sampler=test_sampler, batch_size=64)\nprint(\"Images in Test set: {}\\nImages in Train set: {}\".format(len(test_index), len(train_index)))","3ea7b112":"classes=['infected','uninfected']","24bac4b1":"def imshow(img):\n    img = img \/ 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    \nimages, labels = next(iter(train_loader))\n\nfig = plt.figure(figsize=(25, 15))\n\nfor i in range(10):\n    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[], title=classes[labels[i]])\n    imshow(images[i])\nplt.show()","e2bbe9ba":"#Defining a helper function which will help us to measure accuracy.\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass MalariaCellDetectBase(nn.Module):\n    def train_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))","b64f6637":"class MalariaNet(MalariaCellDetectBase):\n    \n    def __init__(self):\n        super(MalariaNet, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  \n        )\n        \n        self.flatten = nn.Flatten()\n        \n        self.fc1 = nn.Linear(64*15*15, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 2)\n        self.drop = nn.Dropout2d(0.2)\n            \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        \n        out = self.flatten(out)\n        \n        out = self.fc1(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        \n        out = self.fc2(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        \n        out = self.fc3(out)\n        \n        return out       ","71c48390":"model = MalariaNet()\nmodel","5dd8c736":"for images, labels in train_loader:\n    print(f'shape of images: {images.shape}')\n    out = model(images)\n    print(f'shape of output: {out.shape}')\n    print(f'prediction of first image {out[0]}')\n    break","4d62369e":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","610d9d84":"device = get_default_device()\ndevice","a4aef2fe":"train_loader = DeviceDataLoader(train_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)\nto_device(model, device)","b82a277b":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.train_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","d80749d0":"model = to_device(MalariaNet(), device)","98eb676c":"evaluate(model, test_loader)","7d1d86ae":"learning_rate = 0.0001\noptimizer = torch.optim.Adam\nepochs = 20","98f511cf":"history = fit(epochs, learning_rate, model, train_loader, test_loader, opt_func=optimizer)","43736d7f":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')","2a697b9f":"plot_accuracies(history)","b2542197":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","e674f201":"plot_losses(history)","1a4ab790":"# Transformation.","63fa5abe":"# Creating our model.","6e20720f":"# Helper function to visualize our inputs.","74053d63":"# Evaluating our model.","cd83e5c9":"# Checking out if the input and output dims are as we expected.","8b11136d":"# Checking our accuracy just after creating the model.\n\nWe are doing this step so that we can check how well our model improved in the course of time.","e4fbe175":"# Moving the model and data to cuda.","865f0592":"# Randomly splitting the dataset into train and test.","d6df4a1c":"# Importing necessary libraries.","f7ff5cf3":"Transforming the input images into tensor and using some basic data augmentation techniques.","cb1ffb1e":"# Defining the optimizer and learning rate.","6386a047":"# Checking out if GPU is working fine.","87785ca0":"# Defining the base class for our model.\n\n1. train_step : Takes a batch of input and calculates the loss and returns it.\n2. validation_step : Takes a batch of input, calculates the loss and also the accuracy and stores both of them in a python dictionary.\n3. validation_epoch_end : Takes the output after an epoch, returns the average loss and average accuracy.\n4. epoch_end : Just a basic function. We will use this later to print the losses and accuracy after the end of each epoch."}}