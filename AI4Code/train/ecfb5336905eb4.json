{"cell_type":{"32891dad":"code","fcbbc28b":"code","9c4455d7":"code","751b7ab3":"code","a46d001e":"code","0f241fe8":"code","8193684c":"code","a754fc96":"code","4fc73807":"code","dbc75486":"code","c44944ca":"code","ad248141":"markdown","e76d1c86":"markdown","3ecb4a2f":"markdown","b4e90be8":"markdown","df27ea10":"markdown","52b724a5":"markdown"},"source":{"32891dad":"import os\nimport numpy as np\nimport cv2\nfrom scipy import ndimage as ndi\nimport imageio\nfrom os import walk\nfrom pyefd import elliptic_fourier_descriptors\nfrom skimage import feature\nimport pandas as pd\nfrom sklearn.preprocessing import normalize \nfrom sklearn.decomposition import PCA\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns; sns.set()\nimport collections\nfrom sklearn.externals import joblib\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n","fcbbc28b":"# Pre-processing of the images is done\ndef ImageSegmentation():\n    path_IS = \"C:\\Image-Segmentation\"\n    if not os.path.exists(path_IS):\n        os.makedirs(path_IS)\n    lstFiles = []  # nombre de imagenes\n    path = r\"C:\\Users\\Ever\\Google Drive\\Proyecto de grado\\dataset\"\n\n    for (path, _, archivos) in walk(path):\n        for arch in archivos:\n            (nomArch, ext) = os.path.splitext(arch)\n            if (ext == \".JPG\"):\n                lstFiles.append(nomArch + ext)\n                direc = path + \"\\\\\" + nomArch + ext\n                name = nomArch + ext\n                print(path + \"\\\\\" + nomArch + ext)\n                img_rgb = cv2.imread(direc)\n                # print(path)\n                # print(archivos)\n\n                img_rgb = cv2.resize(img_rgb, (461, 260))\n\n                img_ycrcb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2YCR_CB)  \n                ycrcbmin = np.array((0, 133, 77))\n                ycrcbmax = np.array((255, 173, 127))\n                skin_ycrcb = cv2.inRange(img_ycrcb, ycrcbmin, ycrcbmax)\n                kernel = np.ones((5, 5), np.uint8)\n\n                img_erode = cv2.erode(skin_ycrcb, kernel, iterations=1)  \n\n                holesimg = ndi.binary_fill_holes(img_erode).astype(np.int)  \n                \n                imageio.imwrite(os.path.join(path_IS, name), holesimg)\n","9c4455d7":"# The Fourier elliptical features are extracted from each of the images and we proceed to save them in a. txt file.\ndef EllipticFourier():\n    print(\"EF\\n\")\n    path_EF = \"C:\\Feature-Extraction\"\n    if not os.path.exists(path_EF):\n        os.makedirs(path_EF)\n\n    #file = open(\"C:\\Feature-Extraction\\Elliptic-Fourier.txt\", \"w\")\n    # file = open(r\"C:\\Users\\Ever\\Desktop\\Elliptic-Fourier.txt\", \"w\")\n    lstFiles = []  # nombre de imagenes\n    path = r\"C:\\Image-Segmentation\"\n    for (path, _, archivos) in walk(path):\n        for arch in archivos:\n            (nomArch, ext) = os.path.splitext(arch)\n            if (ext == \".JPG\"):\n                lstFiles.append(nomArch + ext)\n                direc = path + \"\\\\\" + nomArch + ext\n                name = nomArch + ext\n                print(nomArch + ext)\n                img_binary = cv2.imread(direc)\n\n                img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n\n                ret, img_binary = cv2.threshold(img_binary, 127, 255, 0)\n                _, contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n                maxcontour = max(contours, key=cv2.contourArea)\n\n                coeffs = []\n                # Find the coefficients of all contours\n                coeffs.append(elliptic_fourier_descriptors(np.squeeze(maxcontour), order=13))\n                # print(\"coeff\",coeffs)\n                coeffs2 = []\n                for row in coeffs:\n                    for elem in row:\n                        coeffs2.append(elem)\n                coeffs = []\n                for row in coeffs2:\n                    for elem in row:\n                        coeffs.append(elem)\n\n                file.write(name)\n                for item in range(len(coeffs)):\n                    file.write(\",%.4f\" % coeffs[item])\n                file.write(\",\" + name[0] + \"\\n\")\n\n    file.close()","751b7ab3":"# The Histogram of Oriented Gradients features are extracted from each of the images and we proceed to save them in a. txt file\ndef HOG():\n    print(\"HOG\\n\")\n\n    file = open(\"C:\\Feature-Extraction\\Histogram-of-Oriented-Gradients.txt\", \"w\")\n    file2 = open(\"C:\\Feature-Extraction\\Histogram-of-Oriented-Gradients-PCA.txt\", \"w\")\n\n    lstFiles = []  # nombre de imagenes\n    path = r\"C:\\Image-Segmentation\"\n    for (path, _, archivos) in walk(path):\n        for arch in archivos:\n            (nomArch, ext) = os.path.splitext(arch)\n            if (ext == \".JPG\"):\n                lstFiles.append(nomArch + ext)\n                direc = path + \"\\\\\" + nomArch + ext\n                name = nomArch + ext\n                print(nomArch + ext)\n                img_binary = cv2.imread(direc)\n                \n                (H) = feature.hog(img_binary, orientations=9, pixels_per_cell=(16,16),\n                                  cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\")  # ,visualize=True\n                # hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))     ,hogImage\n                # hogImage = hogImage.astype(\"uint8\")\n                \n                # plt.imshow(\"HOG Image\", hogImage)\n                file.write(name)\n                for item in range(len(H)):\n                    file.write(\",%.3f\" % H[item])\n                file.write(\",\" + name[0] + \"\\n\")\n    file.close()\n    \n    data_HOG = pd.read_csv(r'C:\\Feature-Extraction\\Histogram-of-Oriented-Gradients.txt', sep=',', header=None)\n    name_HOG = data_HOG.iloc[:, 0]\n    value_HOG = data_HOG.iloc[:, 1:-1]\n    tag_HOG = data_HOG.iloc[:, -1]\n    \n    pca = PCA(0.95).fit(value_HOG)\n    components = pca.transform(value_HOG)\n    for row in range(len(components)):\n        file2.write(name_HOG[row])\n        for colm in range(len(components[row])):\n            file2.write(\",%.4f\" %components[row][colm])\n        file2.write(\",%s\" %tag_HOG[row] + \"\\n\")\n    file2.close()","a46d001e":"# The Hu Moments features are extracted from each of the images and we proceed to save them in a. txt file\n\ndef HU():\n    print(\"HU\\n\")\n\n    file = open(\"C:\\Feature-Extraction\\Hu-Moments.txt\", \"w\")\n\n    lstFiles = []  # nombre de imagenes\n    path = r\"C:\\Image-Segmentation\"\n    for (path, _, archivos) in walk(path):\n        for arch in archivos:\n            (nomArch, ext) = os.path.splitext(arch)\n            if (ext == \".JPG\"):\n                lstFiles.append(nomArch + ext)\n                direc = path + \"\\\\\" + nomArch + ext\n                name = nomArch + ext\n                print(nomArch + ext)\n                img_binary = cv2.imread(direc)\n                # https:\/\/www.pyimagesearch.com\/2014\/10\/27\/opencv-shape-descriptor-hu-moments-example\/\n                img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n                HU = cv2.HuMoments(cv2.moments(img_binary)).flatten()\n\n                file.write(name)\n                for item in range(len(HU)):\n                    # print(HU[item])\n                    num = str(HU[item])\n                    file.write(\",%s\" % num[0:25])\n                    # print(num[0:22])\n                file.write(\",\" + name[0] + \"\\n\")\n    file.close()\n    \n    file = open(r\"C:\\Feature-Extraction\\Hu-Moments-Nmz.txt\", \"w\")\n\n    data = pd.read_csv(r'C:\\Feature-Extraction\\Hu-Moments.txt', sep=',', header=None)\n\n    name = data.iloc[:, 0]\n    value = data.iloc[:, 1:-1]\n    tag = data.iloc[:, -1]\n\n    # print(value)\n    normalizedata = normalize(value, axis=0, norm='max')\n    # print(normalizedata)\n\n\n    for row in range(len(normalizedata)):\n        file.write(name[row])\n        for colm in range(len(normalizedata[row])):\n            # print(HU[item])\n            num = str(normalizedata[row][colm])\n            file.write(\",%s\" % num[0:25])\n            # print(num[0:22])\n        file.write(\",\" + tag[row] + \"\\n\")\n    file.close()","0f241fe8":"# The Contour Features are extracted from each of the images and we proceed to save them in a. txt file\ndef GM():\n    print(\"GM\\n\")\n\n    file = open(\"C:\\Feature-Extraction\\Geometric.txt\", \"w\")\n\n    lstFiles = []  # nombre de imagenes\n    path = r\"C:\\Image-Segmentation\"\n    for (path, _, archivos) in walk(path):\n        for arch in archivos:\n            (nomArch, ext) = os.path.splitext(arch)\n            if (ext == \".JPG\"):\n                lstFiles.append(nomArch + ext)\n                direc = path + \"\\\\\" + nomArch + ext\n                name = nomArch + ext\n                print(nomArch + ext)\n                img_binary = cv2.imread(direc)\n\n                img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n\n                ret, img_binary = cv2.threshold(img_binary, 127, 255, 0)\n                _, contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n                cnt = max(contours, key=cv2.contourArea)\n                # Area\n                area = cv2.contourArea(cnt)\n                # Perimetro\n                perimeter = cv2.arcLength(cnt, True)\n\n                # Relaci\u00f3n de aspecto\n                x, y, w, h = cv2.boundingRect(cnt)\n                aspect_ratio = float(w) \/ h\n\n                # Grado\n                rect_area = w * h\n                extent = float(area) \/ rect_area\n\n                # ConvexHull\n                hull = cv2.convexHull(cnt)\n                hull_area = cv2.contourArea(hull)\n\n                # Solidez\n                solidity = float(area) \/ hull_area\n\n                # Di\u00e1metro equivalente\n                equi_diameter = np.sqrt(4 * area \/ np.pi)\n\n\n                file.write(name)\n                file.write(\",%.4f\" % area)\n                file.write(\",%.4f\" % perimeter)\n                file.write(\",%.4f\" % aspect_ratio)\n                file.write(\",%.4f\" % extent)\n                file.write(\",%.4f\" % hull_area)\n                file.write(\",%.4f\" % solidity)\n                file.write(\",%.4f\" % equi_diameter)\n                file.write(\",\" + name[0] + \"\\n\")\n    file.close()","8193684c":"# After obtaining the characteristics individually we proceed to make a unification \ndef CoF():\n    print(\"Cof\\n\")\n\n    file = open(\"C:\\Feature-Extraction\\CoF.txt\", \"w\")\n    file2 = open(\"C:\\Feature-Extraction\\HOG_EF.txt\", \"w\")\n\n    data_EF = pd.read_csv(r'C:\\Feature-Extraction\\Elliptic-Fourier.txt', sep=',', header=None)\n    name_EF = data_EF.iloc[:, 0]\n    value_EF = data_EF.iloc[:, 1:-1]\n    tag_EF = data_EF.iloc[:, -1]\n    # -------------------------------- HM---------------------------------#\n    data_HM = pd.read_csv(r'C:\\Feature-Extraction\\Hu-Moments.txt', sep=',', header=None)\n    value_HM = data_HM.iloc[:, 1:-1]\n    normalizedata = normalize(value_HM, axis=0, norm='max')\n    # -------------------------------- GM---------------------------------#\n    data_GM = pd.read_csv(r'C:\\Feature-Extraction\\Geometric.txt', sep=',', header=None)\n    value_GM = data_GM.iloc[:, 1:-1]\n    # -------------------------------- HOG---------------------------------#\n    data_HOG = pd.read_csv(r'C:\\Feature-Extraction\\Histogram-of-Oriented-Gradients-PCA.txt', sep=',', header=None)\n    value_HOG = data_HOG.iloc[:, 1:-1]\n    # -------------------------------- Save Cof ---------------------------------#\n    \n    for row in range(len(value_EF)):\n        file.write(name_EF[row])\n        file2.write(name_EF[row])\n        for colm in range(value_EF.shape[1]):\n            file.write(\",%.4f\" %value_EF.iloc[row,colm])\n            file2.write(\",%.4f\" %value_EF.iloc[row,colm])\n        for colm in range(len(normalizedata[row])):\n            num = str(normalizedata[row][colm])\n            file.write(\",%s\" % num[0:25])\n        for colm in range(value_GM.shape[1]):\n            file.write(\",%.4f\" %value_GM.iloc[row,colm])\n        for colm in range(value_HOG.shape[1]):\n            file.write(\",%.4f\" %value_HOG.iloc[row,colm])\n            file2.write(\",%.4f\" %value_HOG.iloc[row,colm])\n        file.write(\",%s\" %tag_EF[row] + \"\\n\")\n        file2.write(\",%s\" %tag_EF[row] + \"\\n\")\n        \n    file.close()\n    file2.close()","a754fc96":"#As the first method of classification we use Support Vector Machine \ndef SVM(txt,test):\n       \n    pathsvm = \"C:\\Feature-Extraction\\SVM\"\n    if not os.path.exists(pathsvm):\n        os.makedirs(pathsvm)\n        \n    data = pd.read_csv('C:\\Feature-Extraction\\\\'+txt+'.txt',sep=',',header=None)\n    data=shuffle(data, random_state=0)\n    \n    s=data.shape# tama\u00f1o de dataframe\n    col=[]\n    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n     \n    for x in range(0, s[1]):\n        if x==0:\n            col.append(\"NAME\")\n        elif x ==s[1]-1:\n            col.append(\"TAG\")\n        else:\n            col.append(\"VALOR-\"+str(x))\n    \n    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n    data.columns = col\n    \n    ##print(data.groupby(['TAG'])['TAG'].count())\n    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5','a':'6', 'e':'7', 'i':'8', 'o':'9', 'u':'10'}\n    \n    data['TAG'] = data['TAG'].map(vals_to_replace)\n    \n    #print(data.tail())\n    \n    no_col=['NAME','TAG']\n    #obtener todas las columnas\n    Name_value = [x for x in col if x not in no_col]\n    #se obtienen solo los coefficientes\n    value=data[Name_value]\n    \n    tags=data[col[-1]] #columna de tags\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n    C_range=[0.01, 0.1, 1, 10, 100, 1000]\n    gamma_range=[1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5]\n    parameters= [\n        {\n            'kernel': ['rbf'],\n            'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n            'C': [0.01, 0.1, 1, 10, 100, 1000]\n        }#, \n        #{\n        #    'kernel': ['linear'],\n        #    'C': [0.01, 0.1, 1, 10, 100, 1000, 10000]\n        #}, \n        #{\n        #    'kernel': ['sigmoid'],\n        #    'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n        #    'C': [0.01, 0.1, 1, 10, 100, 1000, 10000]\n        #}, \n        #{\n        #    'kernel': ['poly'],\n        #    'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n        #    'C': [0.01, 0.1, 1, 10, 100, 1000, 10000]\n        #}\n        \n    ]\n    \n    clf =GridSearchCV(svm.SVC(decision_function_shape='ovr'), param_grid=parameters, cv=5)\n    clf.fit(X_train,Y_train)\n    \n    scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n    print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n    \n    plt.figure(figsize=(8, 6))\n    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n    plt.xlabel('Gamma')\n    plt.ylabel('C')\n    plt.colorbar()\n    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n    plt.yticks(np.arange(len(C_range)), C_range)\n    fig=plt.title('Heat map '+txt+'-'+str(int(test*100))+'%')\n    fig.get_figure().savefig('C:\\Feature-Extraction\\SVM\\Heatmap-'+txt+'-'+str(int(test*100))+'%.jpg')\n    plt.show()\n    print(clf.best_params_)#mejor parametro\n    \n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    params = clf.cv_results_['params']\n    for m, s, p in zip(means, stds, params):\n        print(\"%0.3f (+\/-%0.3f) para %r\"%(m, 2*s, p))\n    \n    y_pred = clf.predict(X_test)\n    \n    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"a\",\"e\",\"i\",\"o\",\"u\"]\n    \n    table=classification_report(Y_test,y_pred, target_names=target_names)\n    table=str(table)\n    print(table)\n    file = open(\"C:\\Feature-Extraction\\SVM\\Reports.txt\", \"a+\")\n    file.write(txt+'-'+str(int(test*100))+'%\\n\\n')\n    file.write(table+'\\n')\n    mat=confusion_matrix(Y_test, y_pred)\n    \n    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n               xticklabels=target_names, yticklabels= target_names )\n    \n    plt.xlabel('Actual')\n    plt.ylabel('Predicted')\n    mat=plt.title('Confusion map '+txt+'-'+str(int(test*100))+'%')\n    \n    Matrizconf.get_figure().savefig('C:\\Feature-Extraction\\SVM\\Confusionmap-'+txt+'-'+str(int(test*100))+'%.png')\n    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n    \n    joblib.dump(clf,'C:\\Feature-Extraction\\SVM\\modelo_entrenado-'+txt+'-'+str(int(test*100))+'%.pkl')\n    \n    # se llama el modelo\n    #clf=joblib.load('modelo_entrenado.pkl')\n    # se toma todo el dataset\n    print(clf.score(value,tags))\n    file.close()","4fc73807":"#As a second method of classification we use K-Nearest Neighbour Classifier\ndef KNN(txt,test):\n       \n    pathknn = \"C:\\Feature-Extraction\\KNN\"\n    if not os.path.exists(pathknn):\n        os.makedirs(pathknn)\n        \n    data = pd.read_csv('C:\\Feature-Extraction\\\\'+txt+'.txt',sep=',',header=None)\n    data=shuffle(data, random_state=0)\n    \n    s=data.shape# tama\u00f1o de dataframe\n    col=[]\n    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n     \n    for x in range(0, s[1]):\n        if x==0:\n            col.append(\"NAME\")\n        elif x ==s[1]-1:\n            col.append(\"TAG\")\n        else:\n            col.append(\"VALOR-\"+str(x))\n    \n    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n    data.columns = col\n    \n    ##print(data.groupby(['TAG'])['TAG'].count())\n    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5','a':'6', 'e':'7', 'i':'8', 'o':'9', 'u':'10'}\n    \n    data['TAG'] = data['TAG'].map(vals_to_replace)\n    \n    #print(data.tail())\n    \n    no_col=['NAME','TAG']\n    #obtener todas las columnas\n    Name_value = [x for x in col if x not in no_col]\n    #se obtienen solo los coefficientes\n    value=data[Name_value]\n    \n    tags=data[col[-1]] #columna de tags\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n    C_range=[1,2,5,25,50,100]\n    gamma_range=[1,2,5,10]\n    parameters= [\n        {\n            'n_neighbors': [1,2,5,25,50,100],\n            'metric': ['minkowski'],\n            'p': [1,2,5,10]\n        }        \n    ]\n    \n    clf = GridSearchCV(KNeighborsClassifier(), param_grid=parameters, cv=5)\n    clf.fit(X_train,Y_train)\n    \n    scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n    print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n    \n    plt.figure(figsize=(8, 6))\n    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n    plt.xlabel('P')\n    plt.ylabel('N neighbors')\n    plt.colorbar()\n    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n    plt.yticks(np.arange(len(C_range)), C_range)\n    fig=plt.title('Heat map '+txt+'-'+str(int(test*100))+'%')\n    fig.get_figure().savefig('C:\\Feature-Extraction\\KNN\\Heatmap-'+txt+'-'+str(int(test*100))+'%.jpg')\n    plt.show()\n    print(clf.best_params_)#mejor parametro\n    \n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    params = clf.cv_results_['params']\n    for m, s, p in zip(means, stds, params):\n        print(\"%0.3f (+\/-%0.3f) para %r\"%(m, 2*s, p))\n    \n    y_pred = clf.predict(X_test)\n    \n    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"a\",\"e\",\"i\",\"o\",\"u\"]\n    \n    table=classification_report(Y_test,y_pred, target_names=target_names)\n    table=str(table)\n    print(table)\n    file = open(\"C:\\Feature-Extraction\\KNN\\Reports.txt\", \"a+\")\n    file.write(txt+'-'+str(int(test*100))+'%\\n\\n')\n    file.write(table+'\\n')\n    mat=confusion_matrix(Y_test, y_pred)\n    \n    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n               xticklabels=target_names, yticklabels= target_names )\n    \n    plt.xlabel('Actual')\n    plt.ylabel('Predicted')\n    mat=plt.title('Confusion map '+txt+'-'+str(int(test*100))+'%')\n    \n    Matrizconf.get_figure().savefig('C:\\Feature-Extraction\\KNN\\Confusionmap-'+txt+'-'+str(int(test*100))+'%.png')\n    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n    \n    joblib.dump(clf,'C:\\Feature-Extraction\\KNN\\modelo_entrenado-'+txt+'-'+str(int(test*100))+'%.pkl')\n    \n    # se llama el modelo\n    #clf=joblib.load('modelo_entrenado.pkl')\n    # se toma todo el dataset\n    print(clf.score(value,tags))\n    file.close()","dbc75486":"#As Tecer method of classification we use Neural Networks\ndef NN(txt,test):\n    \n    pathnn = r\"C:\\Feature-Extraction\\NN\"\n    if not os.path.exists(pathnn):\n        os.makedirs(pathnn)\n        \n    data = pd.read_csv('C:\\Feature-Extraction\\\\'+txt+'.txt',sep=',',header=None)\n    data=shuffle(data, random_state=0)\n    \n    s=data.shape# tama\u00f1o de dataframe\n    col=[]\n    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n     \n    for x in range(0, s[1]):\n        if x==0:\n            col.append(\"NAME\")\n        elif x ==s[1]-1:\n            col.append(\"TAG\")\n        else:\n            col.append(\"VALOR-\"+str(x))\n    \n    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n    data.columns = col\n    \n    ##print(data.groupby(['TAG'])['TAG'].count())\n    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5','a':'6', 'e':'7', 'i':'8', 'o':'9', 'u':'10'}\n    \n    data['TAG'] = data['TAG'].map(vals_to_replace)\n    \n    #print(data.tail())\n    \n    no_col=['NAME','TAG']\n    #obtener todas las columnas\n    Name_value = [x for x in col if x not in no_col]\n    #se obtienen solo los coefficientes\n    value=data[Name_value]\n    \n    tags=data[col[-1]] #columna de tags\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n    C_range=[1,0.1,0.01,0.001,0.0001,0]\n    gamma_range=[(100,1), (100,2), (100,3)]\n    parameters= [\n        {\n            'solver':['lbfgs'], \n            'alpha':[1,0.1,0.01,0.001,0.0001,0],\n            'hidden_layer_sizes':[(100,1), (100,2), (100,3)]\n        }\n    ]\n        \n    clf =GridSearchCV(MLPClassifier(), param_grid=parameters, cv=5)\n    clf.fit(X_train,Y_train)\n    \n    scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n    print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n    \n    plt.figure(figsize=(8, 6))\n    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n    plt.xlabel('hidden_layer_sizes')\n    plt.ylabel('Alpha')\n    plt.colorbar()\n    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n    plt.yticks(np.arange(len(C_range)), C_range)\n    fig=plt.title('Validation accuracy')\n    fig.get_figure().savefig(r'C:\\Feature-Extraction\\NN\\Heatmap-'+txt+'-'+str(int(test*100))+'%.jpg')\n    plt.show()\n    print(clf.best_params_)#mejor parametro\n    \n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    params = clf.cv_results_['params']\n    for m, s, p in zip(means, stds, params):\n        print(\"%0.3f (+\/-%0.3f) para %r\"%(m, 2*s, p))\n    \n    y_pred = clf.predict(X_test)\n    \n    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"a\",\"e\",\"i\",\"o\",\"u\"]\n    \n    table=classification_report(Y_test,y_pred, target_names=target_names)\n    table=str(table)\n    print(table)\n    file = open(r\"C:\\Feature-Extraction\\NN\\Reports.txt\", \"a+\")\n    file.write(txt+'-'+str(int(test*100))+'%\\n\\n')\n    file.write(table+'\\n')\n    mat=confusion_matrix(Y_test, y_pred)\n    \n    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n               xticklabels=target_names, yticklabels= target_names )\n    \n    plt.xlabel('Actual')\n    plt.ylabel('Predicted')\n    mat=plt.title('Confusion map '+txt+'-'+str(int(test*100))+'%')\n    \n    Matrizconf.get_figure().savefig(r'C:\\Feature-Extraction\\NN\\Confusionmap-'+txt+'-'+str(int(test*100))+'%.png')\n    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n    \n    joblib.dump(clf,r'C:\\Feature-Extraction\\NN\\modelo_entrenado-'+txt+'-'+str(int(test*100))+'%.pkl')\n    \n    # se llama el modelo\n    #clf=joblib.load('modelo_entrenado.pkl')\n    # se toma todo el dataset\n    print(clf.score(value,tags))\n    file.close()\n","c44944ca":"if __name__ == \"__main__\":\n    #Preprocessing\n    ImageSegmentation()\n    #Feature Extraction\n    EllipticFourier()\n    HOG()\n    HU()\n    GM()\n    CoF()\n    porcentaje_test=[0.30,0.25,0.20]\n    #Classification\n    for j in range(len(porcentaje_test)):\n        #Support Vector Machine\n        SVM(\"Elliptic-Fourier\",porcentaje_test[j])\n        SVM(\"Histogram-of-Oriented-Gradients-PCA\",porcentaje_test[j])\n        SVM(\"Hu-Moments-Nmz\",porcentaje_test[j])\n        SVM(\"Geometric\",porcentaje_test[j])\n        SVM(\"CoF\",porcentaje_test[j])\n        SVM(\"HOG_EF\",porcentaje_test[j])\n        #K-Nearest Neighbors\n        KNN(\"Elliptic-Fourier\",porcentaje_test[j])\n        KNN(\"Histogram-of-Oriented-Gradients-PCA\",porcentaje_test[j])\n        KNN(\"Hu-Moments-Nmz\",porcentaje_test[j])\n        KNN(\"Geometric\",porcentaje_test[j])\n        KNN(\"CoF\",porcentaje_test[j])\n        KNN(\"HOG_EF\",porcentaje_test[j])\n        #Neural Network\n        NN(\"Elliptic-Fourier\",porcentaje_test[j])\n        NN(\"Histogram-of-Oriented-Gradients-PCA\",porcentaje_test[j])\n        NN(\"Hu-Moments-Nmz\",porcentaje_test[j])\n        NN(\"Geometric\",porcentaje_test[j])\n        NN(\"CoF\",porcentaje_test[j])\n        NN(\"HOG_EF\",porcentaje_test[j])","ad248141":"## Introduction\nThis experiment developed a system that is designed to facilitate communication between people who have vocal-auditory disability. The experiment has machine learning techniques to perform the due process of recognition of hand gestures of the Colombian sign language, recognizing the numbers from 0 to 5 and the vowels. \n\nThis experiment works through 4 stages: taking photographs, pre-processing the photo, extracting the characteristics of the photo and finally performs the classification process for the identification of the gesture being carried out. \nThe image is captured by any camera that has a good quality shot. Then move on to the next stage of pre-processing, where you want to clean the techniques to remove the shadow, the background and leave the image clean to perform the process of segmentation where the process of eliminating the noises that this pose takes place. \n\nAt the stage of extraction of characteristics, it extracts the characteristics of the image that give us the mathematical methods like: Moments of Hu, ellipticals of Fourier, histograms oriented to gradients (HOG) and geometric characteristics. \nFinally, using the vector support machine classifier (SVM) you get the value of the sign, if it is a number or a vowel.","e76d1c86":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","3ecb4a2f":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions perform pre-processing and extracting features ` Cv2` (OpenCV), ` Sklearn`, `scipy`, `skimage`. \nUse the `pyefd` library to get the Fourier ellipticals.\nFor the classification processes the library of `sklearn` was used.\n","b4e90be8":"We then proceed to create our classification methods","df27ea10":"There is 0 csv file in the current version of the dataset:\n","52b724a5":"## Conclusion\n1. With this method for the recognition of Colombian sign language can be tried with new signs extending the dataset, also is open research because it can be tested with new methods of preprocessing, extraction of characteristics, classification being able to get to raise even more the percentages of prediction.\n\n2. According to the methods used for the extraction of characteristics, based on table 2, the characteristics of the gradient-oriented histograms (HOG) are the ones that obtained the highest percentage.\n\n3. When performing the main component analysis process, it is concluded that this process will reduce the percentage of the model's performance measure slightly.\n\n4. The geometric characteristics did not give a good result because the images contain similar characteristics such as the area or contour, this results in the model being able to predict the signs in a bad way."}}