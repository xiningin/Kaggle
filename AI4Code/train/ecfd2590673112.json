{"cell_type":{"0975a352":"code","9610512c":"code","42a4b2fa":"code","e7d72504":"code","ff21db35":"code","c6ab277f":"code","a505750c":"code","e6b533a7":"code","7c644736":"code","afebc90c":"code","2e72bdc5":"code","c8c9d263":"code","4f7baf36":"code","e2c80ff4":"code","7737f68f":"code","cb64f46f":"code","13f95b7c":"code","904327ac":"code","5aad55ca":"code","1be3dc44":"code","5a05bdf8":"code","21aa8481":"code","5f01ffe3":"code","7ca7a957":"code","9f5b21e6":"code","c70c39c4":"code","14018450":"code","c1941efe":"code","b4ad823b":"code","b70de860":"code","6a977408":"code","57f70042":"code","1e8c135f":"code","fa4905b5":"code","1c3600df":"code","24cc33aa":"code","e9b51b6d":"code","2cf87ab0":"code","fc6ae7c5":"code","4bd0c5a2":"code","58c9ff32":"code","16e83851":"code","85b8e320":"code","9a8da370":"code","e416f9cd":"code","3c566dac":"code","1e98b385":"code","64fb4efe":"code","113472ab":"code","edf26d64":"code","07535e23":"code","e04bc26a":"code","6176640e":"code","1c3817ff":"code","d0aa8ce1":"code","c8a7e21b":"code","78c5600a":"code","dd2596c1":"code","7f68b546":"code","f924c278":"code","2c0482dd":"code","cbf196da":"code","c4cfb659":"code","ca466ff3":"code","02a90d77":"code","f841de7f":"code","681161ac":"code","d7fe1e1f":"code","b7cf661f":"code","0d2df82c":"code","3c8e2c10":"code","ebd7ca8a":"code","132afed7":"code","dc6e6bdb":"code","db2ed3a5":"code","b5a0560e":"markdown","185f30f2":"markdown","99f9ab32":"markdown","e2928fd0":"markdown","86dede37":"markdown","21d175cc":"markdown","7ac842d2":"markdown","dae1db38":"markdown","3fe7d9ee":"markdown","68ef114a":"markdown","79faeaf2":"markdown","205b83d3":"markdown","8788a43c":"markdown","7e693820":"markdown"},"source":{"0975a352":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nnp.random.seed(100)\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9610512c":"import tensorflow as tf\nimport pathlib\nimport PIL\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt","42a4b2fa":"path_utk = '..\/input\/utkface-new'\npath_face_cropped = '..\/input\/utkface-new\/crop_part1'\n\n\npath_face_cropped = pathlib.Path(path_face_cropped)\nprint(path_face_cropped)\nprint(len(str(path_face_cropped)))\n\nimage_count = len(list(path_face_cropped.glob('*.jpg')))\nprint(image_count)","e7d72504":"faces = list(path_face_cropped.glob('*.jpg'))\nprint(faces[1])\nimg1 = PIL.Image.open(str(faces[1]))\nimg1","ff21db35":"batch = 32\nimg_height = 210\nimg_width = 210","c6ab277f":"age_class=['0-20','21-40','41-60','61-80','81-116']","a505750c":"df = pd.DataFrame(columns=['images','age','gender'])\nfor img in faces:\n    new_img = str(img)\n    img = new_img.split(\"\/\")\n    #print(img)\n    img_name = img[4]\n    img = img_name.split(\"_\")\n    #print(img)\n    #Making 0 and 1 into male and female to make it more interpretable\n    if img[1] == '0':\n        img[1] = 'male'\n    else:\n        img[1] = 'female'\n    #Making the age label into age ranges instead\n    img[0] = int(img[0])\n#     if int(img[0]) > 100:\n#         img[0] = '101-116'\n    if img[0] >80:\n        img[0] = '81-116'\n    elif img[0] > 60:\n        img[0] = '61-80'\n    elif img[0] > 40:\n        img[0] = '41-60'\n    elif img[0] > 20:\n        img[0] = '21-40'\n    else:\n        img[0] = '0-20'    \n    df2 = {'images':new_img,'age':img[0],'gender':img[1]}\n    df = df.append(df2,ignore_index=True)\ndf","e6b533a7":"df_data = df.images\ny_data = df.age\ny2_data = df.gender\nX_train, X_test, y_train, y_test = train_test_split(df_data, y_data, test_size=0.2)","7c644736":"type(X_train)","afebc90c":"d = {'images':X_train,'age':y_train}\ndf_train = pd.concat(d,axis=1)\ndf_train.images","2e72bdc5":"df_data = df_train.images\ny_data = df_train.age\ny2_data = df.gender\nX_train, X_val, y_train, y_val = train_test_split(df_data, y_data, test_size=0.2)","c8c9d263":"d = {'images':X_train,'age':y_train}\ntrain = pd.concat(d,axis=1)\ntrain","4f7baf36":"train['age'].value_counts()","e2c80ff4":"d = {'images':X_val,'age':y_val}\nval = pd.concat(d,axis=1)\nval","7737f68f":"d = {'images':X_test,'age':y_test}\ndf_test = pd.concat(d,axis=1)\ndf_test","cb64f46f":"train_gen = ImageDataGenerator(#rotation_range=45,\n                               rescale=1.\/255#,\n                               #horizontal_flip=True\n)\ntest_gen = ImageDataGenerator(rescale = 1.\/255)","13f95b7c":"train_data = train_gen.flow_from_dataframe(dataframe = train, \n                                           #directory = train_folder, \n                                           x_col = 'images',\n                                           y_col = 'age', seed = 42,\n                                           batch_size = batch,\n                                           shuffle = True, \n                                           class_mode=\"sparse\",\n                                           target_size = (img_height,img_width))\n\ntest_data = test_gen.flow_from_dataframe(dataframe = df_test,\n                                         #directory = test_folder,\n                                         x_col = 'images',\n                                         y_col = 'age',\n                                         batch_size = batch,\n                                         shuffle = True,\n                                         class_mode='sparse',\n                                         target_size = (img_height,img_width))\n\nval_data = train_gen.flow_from_dataframe(dataframe = val, \n                                           #directory = train_folder, \n                                           x_col = 'images',\n                                           y_col = 'age', seed = 42,\n                                           batch_size = batch,\n                                           shuffle = True, \n                                           class_mode=\"sparse\",\n                                           target_size = (img_height,img_width))","904327ac":"normalization_layer = layers.experimental.preprocessing.Rescaling(1.\/255)\nconv_layer_32 = layers.Conv2D(32,(3,3),activation='relu')\nconv_layer_64 = layers.Conv2D(64,3,activation='relu')\nconv_layer_16 = layers.Conv2D(16,3,activation='relu')\nmax_pool = layers.MaxPooling2D()\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)","5aad55ca":"for image_batch, labels_batch in train_data:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","1be3dc44":"for image_batch, labels_batch in val_data:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","5a05bdf8":"num_classes = 5\n\nmodel = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  #\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  #  \n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n    \n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  #layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","21aa8481":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","5f01ffe3":"history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs= 10,\n    callbacks = callback,\n    shuffle=False\n)\neff_epochs = len(history.history['loss'])","7ca7a957":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = 10\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(eff_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.show()","9f5b21e6":"model.summary()","c70c39c4":"results_age = model.evaluate(test_data)\nprint(\"test loss, test acc:\", results_age)","14018450":"df_data = df.images\ny2_data = df.gender\nX_train, X_test, y_train, y_test = train_test_split(df_data, y2_data, test_size=0.2)","c1941efe":"d = {'images':X_train,'gender':y_train}\ndf_train2 = pd.concat(d,axis=1)\ndf_train2.images","b4ad823b":"df_data = df_train2.images\ny2_data = df_train2.gender\nX_train, X_val, y_train, y_val = train_test_split(df_data, y2_data, test_size=0.2)","b70de860":"d = {'images':X_train,'gender':y_train}\ntrain = pd.concat(d,axis=1)\ntrain","6a977408":"d = {'images':X_val,'gender':y_val}\nval = pd.concat(d,axis=1)\nval","57f70042":"d = {'images':X_test,'gender':y_test}\ndf_test = pd.concat(d,axis=1)\ndf_test","1e8c135f":"train_data = train_gen.flow_from_dataframe(dataframe = train, \n                                           #directory = train_folder, \n                                           x_col = 'images',\n                                           y_col = 'gender', seed = 42,\n                                           batch_size = batch,\n                                           shuffle = True, \n                                           class_mode=\"categorical\",\n                                           target_size = (img_height,img_width))\n\ntest_data = test_gen.flow_from_dataframe(dataframe = df_test,\n                                         #directory = test_folder,\n                                         x_col = 'images',\n                                         y_col = 'gender',\n                                         batch_size = batch,\n                                         shuffle = True,\n                                         class_mode='categorical',\n                                         target_size = (img_height,img_width))\n\nval_data = train_gen.flow_from_dataframe(dataframe = val, \n                                           #directory = train_folder, \n                                           x_col = 'images',\n                                           y_col = 'gender', seed = 42,\n                                           batch_size = batch,\n                                           shuffle = True, \n                                           class_mode=\"categorical\",\n                                           target_size = (img_height,img_width))","fa4905b5":"num_classes = 2\n\nmodel2 = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_64,\n  max_pool,\n  conv_layer_64,\n  max_pool,\n  conv_layer_64,\n  max_pool,\n  #\n  conv_layer_64,\n  max_pool,\n  conv_layer_64,\n  max_pool,\n  conv_layer_64,\n  max_pool,\n    \n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  #layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","1c3600df":"model2.compile(\n  optimizer='adam',\n  loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","24cc33aa":"history = model2.fit(\n    train_data,\n    validation_data=val_data,\n    epochs= 10,\n    callbacks = callback,\n    shuffle=False\n)\neff_epochs = len(history.history['loss'])","e9b51b6d":"model2.summary()","2cf87ab0":"results_gender = model2.evaluate(test_data)\nprint(\"test loss, test acc:\", results_gender)","fc6ae7c5":"path_ck= '..\/input\/ckplus\/CK+48\/'\n\npath_ck = pathlib.Path(path_ck)\nprint(path_ck)\nprint(len(str(path_ck)))\n\n#Images in this dataset are saved as .png\nimage_count = len(list(path_ck.glob('*\/*.png')))\nprint(image_count)","4bd0c5a2":"emotion_class = os.listdir(path_ck)\nemotion_class","58c9ff32":"surprise = len(list(path_ck.glob('surprise\/*.png')))\nprint(surprise)\nfear = len(list(path_ck.glob('fear\/*.png')))\nprint(fear)\nsadness = len(list(path_ck.glob('sadness\/*.png')))\nprint(sadness)\ndisgust = len(list(path_ck.glob('disgust\/*.png')))\nprint(disgust)\ncontempt = len(list(path_ck.glob('contempt\/*.png')))\nprint(contempt)\nhappy = len(list(path_ck.glob('happy\/*.png')))\nprint(happy)\nanger = len(list(path_ck.glob('anger\/*.png')))\nprint(anger)","16e83851":"emotion_df = pd.DataFrame(columns=['images','emotion'])\nfor label in emotion_class:\n    for image in list(path_ck.glob(label+'\/*.png')):\n        df2 = {'images':str(image),'emotion':label}\n        emotion_df = emotion_df.append(df2,ignore_index=True)\nemotion_df","85b8e320":"emotion_df = emotion_df.sample(frac=1)\nemotion_df","9a8da370":"emotion_data = emotion_df.images\ny_data = emotion_df.emotion\nX_train, X_test, y_train, y_test = train_test_split(emotion_data, y_data, test_size=0.2)","e416f9cd":"d3 = {'images':X_train,'emotion':y_train}\nemotion_train = pd.concat(d3,axis=1)\nemotion_train","3c566dac":"d3 = {'images':X_test,'emotion':y_test}\nemotion_test = pd.concat(d3,axis=1)\nemotion_test","1e98b385":"emotion_test['emotion'].value_counts()","64fb4efe":"occurences_test = list(emotion_test['emotion'].value_counts())\ntot = sum(occurences_test)\noccurences_test = [el\/ tot for el in occurences_test]\noccurences_test","113472ab":"emotion_data = emotion_train.images\ny_data = emotion_train.emotion\nX_train, X_val, y_train, y_val = train_test_split(emotion_data, y_data, test_size=0.2)","edf26d64":"d3 = {'images':X_val,'emotion':y_val}\nemotion_val = pd.concat(d3,axis=1)\nemotion_val","07535e23":"emotion_val['emotion'].value_counts()","e04bc26a":"occurences_val = list(emotion_val['emotion'].value_counts())\ntot = sum(occurences_val)\noccurences_val = [el\/ tot for el in occurences_val]\noccurences_val","6176640e":"d3 = {'images':X_train,'emotion':y_train}\nemotion_train = pd.concat(d3,axis=1)\nemotion_train","1c3817ff":"emotion_train['emotion'].value_counts()","d0aa8ce1":"occurences_train = list(emotion_train['emotion'].value_counts())\ntot = sum(occurences_train)\noccurences_train = [el\/ tot for el in occurences_train]\noccurences_train","c8a7e21b":"train_gen = ImageDataGenerator(rescale=1.\/255)\ntest_gen = ImageDataGenerator(rescale = 1.\/255)","78c5600a":"train = train_gen.flow_from_dataframe(dataframe = emotion_train, \n                                           #directory = train_folder, \n                                           x_col = 'images',\n                                           y_col = 'emotion', seed = 42,\n                                           batch_size = batch,\n                                           shuffle = True, \n                                           class_mode=\"sparse\",\n                                           target_size = (img_height,img_width))\n\ntest = test_gen.flow_from_dataframe(dataframe = emotion_test,\n                                         #directory = test_folder,\n                                         x_col = 'images',\n                                         y_col = 'emotion',\n                                         batch_size = batch,\n                                         shuffle = True,\n                                         class_mode='sparse',\n                                         target_size = (img_height,img_width))\n\nval = train_gen.flow_from_dataframe(dataframe = emotion_val, \n                                           #directory = train_folder, \n                                           x_col = 'images',\n                                           y_col = 'emotion', seed = 42,\n                                           batch_size = batch,\n                                           shuffle = True, \n                                           class_mode=\"sparse\",\n                                           target_size = (img_height,img_width))","dd2596c1":"num_classes = 7\n\nmodel3 = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","7f68b546":"model3.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n","f924c278":"history = model3.fit(\n    train,\n    validation_data=val,\n    epochs= 10,\n    callbacks = callback,\n    shuffle=False\n)\neff_epochs = len(history.history['loss'])","2c0482dd":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = 10\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(eff_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.show()","cbf196da":"model3.summary()","c4cfb659":"results_emotion = model3.evaluate(test)\nprint(\"test loss, test acc:\", results_emotion)","ca466ff3":"picture_url = \"https:\/\/icdn5.digitaltrends.com\/image\/screen-shot-2019-02-15-at-19-16-58-720x720.jpg\"\npic_path = tf.keras.utils.get_file('screen-shot-2019-02-15-at-19-16-58-720x720', origin=picture_url)","02a90d77":"plt.figure(figsize=(5,5))\nimg = PIL.Image.open(pic_path)\nplt.imshow(img)","f841de7f":"img = tf.keras.preprocessing.image.load_img(\n    pic_path, target_size=(img_height, img_width)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)","681161ac":"predictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(age_class[np.argmax(score)], 100 * np.max(score))\n)","d7fe1e1f":"gender_class = ['male','female']\npredictions = model2.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(gender_class[np.argmax(score)], 100 * np.max(score))\n)","b7cf661f":"predictions = model3.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(emotion_class[np.argmax(score)], 100 * np.max(score))\n)","0d2df82c":"picture_url = \"https:\/\/qodebrisbane.com\/wp-content\/uploads\/2019\/07\/This-is-not-a-person-2-1.jpeg\"\npic_path = tf.keras.utils.get_file('This-is-not-a-person-2-1', origin=picture_url)","3c8e2c10":"plt.figure(figsize=(5,5))\nimg = PIL.Image.open(pic_path)\nplt.imshow(img)","ebd7ca8a":"img = tf.keras.preprocessing.image.load_img(\n    pic_path, target_size=(img_height, img_width)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)","132afed7":"predictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(age_class[np.argmax(score)], 100 * np.max(score))\n)","dc6e6bdb":"gender_class = ['male','female']\npredictions = model2.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(gender_class[np.argmax(score)], 100 * np.max(score))\n)","db2ed3a5":"predictions = model3.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(emotion_class[np.argmax(score)], 100 * np.max(score))\n)","b5a0560e":"# Emotion Detection Model","185f30f2":"# Data Preprocessing for gender detection model","99f9ab32":"### Splitting the emotion_train again for validation set","e2928fd0":"# Predicting on new data","86dede37":"### Shuffling the dataframe","21d175cc":"Age ranges:<br>\n1. 0-20\n2. 21-40\n3. 41-60\n4. 61-80\n5. 81-116","7ac842d2":"# Using the UTKFace dataset for age and gender detection","dae1db38":"# Gender Detection Model","3fe7d9ee":"## Checking the count of images in each class","68ef114a":"# Data Preprocessing for age detection model","79faeaf2":"## Creating a csv file for the images and their labels","205b83d3":"# Using the CKPlus dataset for emotion detection","8788a43c":"# Age Detection Model","7e693820":"### Second Example"}}