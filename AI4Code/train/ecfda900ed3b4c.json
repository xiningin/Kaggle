{"cell_type":{"595a9a14":"code","1676b0e5":"code","676e90be":"code","83d082d7":"code","296a789f":"code","b41ca2e7":"code","d2be8a38":"code","a6499a4c":"code","6d979f98":"code","f2e67b6d":"code","1bd62300":"code","4af36986":"markdown","c646c9e0":"markdown","53863788":"markdown","ed4aa3c1":"markdown","c1de6291":"markdown","71ce53cb":"markdown","0e8edb1f":"markdown","c57e4fa3":"markdown","fc5f1698":"markdown","433646c7":"markdown","0695ea36":"markdown","10a51454":"markdown","5a66c670":"markdown","be1b9f2a":"markdown"},"source":{"595a9a14":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt #for plotting the graphs or images\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\nimport matplotlib.image as mpimg\n\n# Set Color Palettes for the notebook (https:\/\/color.adobe.com\/)\ncolors_nude = ['#FFE61A','#B2125F','#FF007B','#14B4CC','#099CB3']\nsns.palplot(sns.color_palette(colors_nude))\n\n# Set Style\nsns.set_style(\"whitegrid\")\nsns.despine(left=True, bottom=True)","1676b0e5":"train_data= pd.read_csv(\"..\/input\/landmark-recognition-2020\/train.csv\")","676e90be":"print(train_data.head(10))\nprint()\nprint(\"Here, id means Image Id and landmark_id points to a specific ID of the landmark \")","83d082d7":"train_data.describe()","296a789f":"print(train_data.isna().sum())\nprint()","b41ca2e7":"!pip install basic_image_eda\nfrom basic_image_eda import BasicImageEDA","d2be8a38":"data_dir = \"..\/input\/landmark-recognition-2020\/train\/0\"\nextensions = ['jpg']\nthreads = 0\ndimension_plot = True\nchannel_hist = True\nnonzero = False\nhw_division_factor = 1.0\n\nBasicImageEDA.explore(data_dir, extensions, threads, dimension_plot, channel_hist, nonzero, hw_division_factor)","a6499a4c":"train_data['landmark_id'].value_counts()\nprint(\"Types of Landmarks: {81313}\")\nprint(\"Landmark ID: 138982 has the highest number of images (6272)\")","6d979f98":"# Occurance of landmark_id in decreasing order(Top categories)\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['Landmark ID','Number of Images']\n\n# Plot the most frequent landmark_ids\nplt.figure(figsize = (9, 10))\nplt.title('Top 10 the mostfrequent landmarks')\nsns.set_color_codes(\"deep\")\nsns.barplot(x=\"Landmark ID\", y=\"Number of Images\", data=temp,\n            label=\"Count\")\nplt.show()\n","f2e67b6d":"temp = pd.DataFrame(train_data.landmark_id.value_counts().tail(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['Landmark ID','Number of Images']\n# Plot the least frequent landmark_ids\nplt.figure(figsize = (9, 10))\nplt.title('Top 10 the least frequent landmarks')\nsns.set_color_codes(\"deep\")\nsns.barplot(x=\"Landmark ID\", y=\"Number of Images\", data=temp,\n            label=\"Count\")\nplt.show()\n","1bd62300":"from random import randrange\nfig= plt.figure(figsize=(20,10))\nindex= '..\/input\/landmark-recognition-2020\/train\/2\/3\/6\/23603d71816b6452.jpg'\na= fig.add_subplot(2,3,1)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/7\/0\/4\/7040a5cfa43e0633.jpg'\na= fig.add_subplot(2,3,2)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/4\/1\/0\/41000aafca574dfe.jpg'\na= fig.add_subplot(2,3,3)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/4\/3\/1\/43101b9ac11ed672.jpg'\na= fig.add_subplot(2,3,4)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/4\/3\/1\/43105797059abd97.jpg'\na= fig.add_subplot(2,3,5)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '..\/input\/landmark-recognition-2020\/train\/4\/1\/0\/41008546ba23b770.jpg'\na= fig.add_subplot(2,3,6)\na.set_title(index.split(\"\/\")[-1])\nplt.imshow(plt.imread(index))\n\nplt.show()\n    ","4af36986":"**There are a total of 1580470 images in the train folder. It will take a huge amout of time to perform EDA over all the images. So, here I am applying this only for one of the subfolders. You can choose any of the subfolder by just changing the path. Like, if you want to use the subfolder \"1\", then the data_dir value will be \"..\/input\/landmark-recognition-2020\/train\/1\" or if you want to perform the operation over whole training images then, cahnge the value to \"..\/input\/landmark-recognition-2020\/train\".**","c646c9e0":"Now, let's analyze the number of landmark types and their distributions.","53863788":"**Take a look at the first 10 entries. (we defined the number inside the parentheses. You can change the value to whatever you want. By default it is 5)**","ed4aa3c1":"**Here I checked for any missing value in the csv file and found that, there is no missing values.**","c1de6291":"# Exploratory Data Analysis","71ce53cb":"**Now let's take a look at the summary of the loaded data**","0e8edb1f":"**If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That will keep me motivated :)**","c57e4fa3":"Now let's plot some random images","fc5f1698":"**To begin with, Let's first import the necessary modules.**","433646c7":"**Now, Let's perform the Exploratory Data Analysis importing the *basic_image_eda* library**","0695ea36":"**Least frequent landmark counts (Top 10)**","10a51454":"# Google Landmark Recognition-2020\n\n**Here, I will try to perform the Exploratory Data Analysis (EDA) on this dataset. I will try to explain each step as clearly as possible. As I'm a beginner myself, if you find any mistakes, please suggest your valuable opinions in the comment section.**\n\nThese notebooks gave me the necessary ideas for this task and I'm really grateful to them:\n1. https:\/\/www.kaggle.com\/chirag9073\/landmark-recognition-exploratory-data-analysis\/notebook\n2. https:\/\/www.kaggle.com\/azaemon\/mura-classification\n3. [https:\/\/www.kaggle.com\/azaemon\/eda-data-augmentation-for-beginners?scriptVersionId=40504799](https:\/\/www.kaggle.com\/azaemon\/eda-data-augmentation-for-beginners?scriptVersionId=40504799)\n\n\n","5a66c670":"**Load the training csv file**","be1b9f2a":"**Most frequent landmark counts (Top 10)**"}}