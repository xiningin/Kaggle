{"cell_type":{"cf719d71":"code","25ba94e7":"code","1c788993":"code","a72bd7bd":"code","8f020cc2":"code","3339fef3":"code","8afd9ab5":"code","4c6e58d9":"code","3c576282":"code","086030a0":"code","a47e3927":"code","78f4c31c":"code","2dfb6390":"code","de0149c3":"code","31a38b07":"code","babfe49b":"code","ae0bcedf":"code","0bd1fb70":"code","4fc2b1e5":"code","947370d6":"code","3bd29afa":"code","5ffdd072":"markdown","bf648739":"markdown","9fa91cc4":"markdown","b57a55e7":"markdown","b04e312d":"markdown","38e9b1d6":"markdown","3a3d41f0":"markdown","348b532b":"markdown","2c237437":"markdown","01952fa9":"markdown","a1f00240":"markdown","cdfee033":"markdown","c46f9305":"markdown"},"source":{"cf719d71":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder","25ba94e7":"yes_data = []\n\nno_data = []\n\npaths = []\n\nlabels = []\n\nimport os\nfor dirname, _, filenames in os.walk(r'..\/input\/brain-mri-images-for-brain-tumor-detection\/yes'):\n    \n    for filename in filenames:\n        \n        if '.jpg' in filename:\n            \n            paths.append(os.path.join(dirname, filename))","1c788993":"encoder = OneHotEncoder()\n\nencoder.fit([[0], [1]])\n\nfor path in paths:\n    \n    image = Image.open(path)\n    \n    image = image.resize((128,128))\n    \n    image= np.array(image)\n    \n    if image.shape == (128,128,3):\n        \n        yes_data.append(np.array(image))\n        \n        labels.append(encoder.transform([[0]]).toarray())\n        \nlabels[0]","a72bd7bd":"more_paths = []\n\nfor dirname, _, filenames in os.walk(r'..\/input\/brain-mri-images-for-brain-tumor-detection\/no'):\n    \n    for filename in filenames:\n        \n        if '.jpg' in filename:\n            \n            more_paths.append(os.path.join(dirname, filename))","8f020cc2":"for path in more_paths:\n    \n    image = Image.open(path)\n    \n    image = image.resize((128,128))\n    \n    image = np.array(image)\n    \n    if image.shape == (128,128,3):\n        \n        yes_data.append(np.array(image))\n        \n        labels.append(encoder.transform([[1]]).toarray())\n        \n","3339fef3":"yes_data = np.array(yes_data)\n\nyes_data.shape","8afd9ab5":"labels = np.array(labels)\n\nlabels = labels.reshape(139,2)\n\nlabels.shape","4c6e58d9":"np.set_printoptions(linewidth = 200)\n\nplt.imshow(yes_data[0])\n\nprint(yes_data[0])\n\nprint(labels[0])","3c576282":"train_data, test_data, train_labels, test_labels = train_test_split(yes_data, labels, random_state = 3, shuffle = True)","086030a0":"train_data.shape, test_data.shape, train_labels.shape, test_labels.shape","a47e3927":"train_data = train_data \/255.0\ntest_data = test_data\/255.0","78f4c31c":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization\n\n\ninput = Input(shape = (128,128,3))\n\nx = Conv2D(16, (3,3), activation = 'relu')(input)\n\nx = BatchNormalization()(x)\n\nx = MaxPooling2D(2,2)(x)\n\nx = Conv2D(32, (3,3), activation = 'relu')(x)\n\nx = MaxPooling2D(2,2)(x)\n\n\n\nx = Flatten()(x)\n\nx = BatchNormalization()(x)\n\nx = Dense(124, activation = 'relu')(x)\n\nx = Dropout(0.27)(x)\n\nx = Dense(124, activation = 'relu')(x)\n\noutput = Dense(2, activation = 'softmax')(x)\n\nmodel = Model(inputs = input, outputs = output)\n\nmodel.summary()","2dfb6390":"from keras.optimizers import RMSprop","de0149c3":"model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.001), metrics = [\"accuracy\"])","31a38b07":"lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8*10**(epoch \/ 20))","babfe49b":"history = model.fit(train_data, train_labels, epochs = 75, callbacks = [lr_schedule],validation_data = (test_data, test_labels))","ae0bcedf":"# accuracy\n\nplt.figure(figsize = (12,7))\n\nplt.plot(history.history['accuracy'], label = 'train accuracy')\nplt.plot(history.history['val_accuracy'], label = 'validation accuracy')\nplt.title(\"train accuracy vs validation accuracy\")\nplt.legend()\nplt.show()","0bd1fb70":"# loss\n\nplt.figure(figsize = (12,7))\n\nplt.plot(history.history['loss'], label = 'train loss')\nplt.plot(history.history['val_loss'], label = 'validation loss')\nplt.legend()\nplt.title(\"train vs validation loss\")\nplt.show()\n","4fc2b1e5":"def tumor(number):\n    \n    if number == 0:\n        \n        return \"Not a tumor\"\n    \n    else:\n        \n        return \"a tumor\"","947370d6":"\n\nimg = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y1.jpg\")\n\nx = np.array(img.resize((128,128)))\n\nx = x.reshape(1, 128, 128, 3)\n\nresult = model.predict([x])\n\nclassification = np.where(result == np.amax(result))[1][0]\n\nprint(str(result[0][classification]*100) + '% Confidence This Is ' + tumor(classification))\n\nplt.imshow(img)\n","3bd29afa":"img2 = Image.open(r\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/18 no.jpg\")\n\ny = np.array(img2.resize((128,128)))\n\ny = y.reshape(1, 128, 128, 3)\n\nresult2 = model.predict([y])\n\nind = 0\nclassification2 = 0\n\nimport numpy as np\n\nfor result in result2:\n    result = result.tolist()\n    print(result)\n    \n    if result[0] > result[1]:\n        classification = 1\n        ind = 0\n    else:\n        classification = 0\n        ind = 1\n\n#classification2 = np.where(result2 == np.amax(result2))[1][0]\n\nprint(str(result2[0][ind]*100) + '% Confidence This Is ' + tumor(classification2))\n\nplt.imshow(img2)\n\n\n\n\n","5ffdd072":"## BRAIN TUMOR PREDICTION","bf648739":"## Getting a glance at the data","9fa91cc4":"## Fitting the Model","b57a55e7":"EXAMPLE IMAGE :","b04e312d":"## Plotting results","38e9b1d6":"### Preprocessing Data ","3a3d41f0":"## Normalizing Data","348b532b":"## Training + Testing data","2c237437":"## Predictions","01952fa9":"## Compile Model","a1f00240":"### Importing Required Libraries","cdfee033":"## Building A Model :","c46f9305":"## Making a Learning Rate Scheduler"}}