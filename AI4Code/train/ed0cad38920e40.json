{"cell_type":{"15905642":"code","b4e76d8e":"code","8904c404":"code","f2e85255":"code","2fefc64c":"code","47587e3e":"code","9dace61a":"code","55f91b97":"code","edca5d18":"code","c2d310f2":"code","fed619a7":"code","e819c1d2":"code","c75ce5d8":"code","093c487f":"code","f226ae6c":"code","d5671aa4":"code","24a4eb4b":"markdown","a6307c01":"markdown","07d79d24":"markdown","4c563031":"markdown","2da5529c":"markdown","87f8999d":"markdown","9d802e53":"markdown","deb8e7dd":"markdown","95117cc1":"markdown","9474f07f":"markdown","75530b21":"markdown","22fabd3e":"markdown","c13267aa":"markdown","a5c02c15":"markdown","0477c11b":"markdown"},"source":{"15905642":"#Import TensorFlow into your program:\nfrom __future__ import absolute_import, division, print_function, unicode_literals\n# Install TensorFlow\nimport tensorflow as tf\nfrom sklearn import preprocessing\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import Callback, EarlyStopping\n\n","b4e76d8e":"# importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# roc curve and auc score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n","8904c404":"# loading dataset \ntraining_v2 = pd.read_csv(\"..\/input\/widsdatathon2020\/training_v2.csv\")\ntest = pd.read_csv(\"..\/input\/widsdatathon2020\/unlabeled.csv\")","f2e85255":"# creating independent features X and dependant feature Y\ny = training_v2['hospital_death']\nX = training_v2\nX = training_v2.drop('hospital_death',axis = 1)\ntest = test.drop('hospital_death',axis = 1)","2fefc64c":"# Remove Features with more than 75 percent missing values\ntrain_missing = (X.isnull().sum() \/ len(X)).sort_values(ascending = False)\ntrain_missing = train_missing.index[train_missing > 0.75]\nX = X.drop(columns = train_missing)\ntest = test.drop(columns = train_missing)","47587e3e":"categoricals_features = ['hospital_id','ethnicity','gender','hospital_admit_source','icu_admit_source','icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem']\nX = X.drop(columns = categoricals_features)\ntest = test.drop(columns = categoricals_features)","9dace61a":"# Imputation transformer for completing missing values.\nmy_imputer = SimpleImputer()\nnew_data = pd.DataFrame(my_imputer.fit_transform(X))\ntest_data = pd.DataFrame(my_imputer.fit_transform(test))\nnew_data.columns = X.columns\ntest_data.columns = test.columns\nX= new_data\ntest = test_data","55f91b97":"# Normalize the data attributes\nnormalized_X = preprocessing.normalize(X)","edca5d18":"x_train, x_test ,y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","c2d310f2":"checkpoint_callback = ModelCheckpoint(\"model.h5\", monitor='accuracy', save_best_only=True, save_freq=2)","fed619a7":"model = Sequential()\nmodel.add(Dense(128, input_shape=(131,), activation='relu', name='fc1'))\nmodel.add(Dense(64, activation='relu', name='fc2'))\nmodel.add(Dense(2, activation='softmax', name='output'))\noptimizer = SGD(lr=0.1)\n","e819c1d2":"model.compile(optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","c75ce5d8":"model.fit(x_train, y_train, verbose=0, batch_size=10, epochs=20, callbacks=[checkpoint_callback])","093c487f":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","f226ae6c":"probs = model.predict_proba(x_test)\nprobs = probs[:, 1]\nauc = roc_auc_score(y_test, probs)\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplot_roc_curve(fpr, tpr)\nprint(\"AUC-ROC :\",auc)\n","d5671aa4":"test1 = test.copy()\nprobstest = model.predict_proba(test)\nprobstest = probstest[:, 1]\ntest1[\"hospital_death\"] = probstest\ntest1[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission5.csv\",index=False)\ntest1[[\"encounter_id\",\"hospital_death\"]].head()","24a4eb4b":"## Import the relevant libraries","a6307c01":"Reference : \n\nLee, M., Raffa, J., Ghassemi, M., Pollard, T., Kalanidhi, S., Badawi, O., Matthys, K., Celi, L. A. (2020). WiDS (Women in Data Science) Datathon 2020: ICU Mortality Prediction. PhysioNet. doi:10.13026\/vc0e-th79\n\nGoldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals (2003). Circulation. 101(23):e215-e220.\n\nOfficial TensorFlow documentation\n","07d79d24":"## Build the model  \n\n\nBuilding the neural network requires configuring the layers of the model, then compiling the model.\n\n## Set up the layers  \n\nThe basic building block of a neural network is the layer. Layers extract representations from the data fed into them. Most of deep learning consists of chaining together simple layers. Most layers, such as tf.keras.layers.Dense, have parameters that are learned during training.\n\nThe network consists of a sequence of three tf.keras.layers.Dense layers. These are densely connected, or fully connected, neural layers. The first Dense layer has 128 nodes (or neurons). The second layer is a 64-nodes with relu activation and the third Dense layer with softmax activation returns an array of 2 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 2 classes","4c563031":"<img src = \"https:\/\/drive.google.com\/uc?id=1QFpY4TjfXYfKrCiRl1BcePuFEXOQ8-pX\">","2da5529c":"\n## Callbacks :\n\nCallback is a python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch\/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to any of tf.keras.Model.fit(), tf.keras.Model.evaluate(), and tf.keras.Model.predict() methods. The methods of the callbacks will then be called at different stages of training\/evaluating\/inference.","87f8999d":"## Compile the model :\n\nBefore the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n\n**Loss function** \u2014This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n\n**Optimizer** \u2014This is how the model is updated based on the data it sees and its loss function.\n\n**Metrics** \u2014Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.","9d802e53":"## TensorFlow 2.0\n\n**TensorFlow is a general-purpose high-performance computing library open-sourced by Google in 2015. Since the beginning, its main focus was to provide high-performance APIs for building Neural Networks (NNs). However, with the advance of time and interest by the Machine Learning (ML) community, the lib has grown to a full ML ecosystem.**\n\n**TensorFlow 2.0 represents a major milestone in the library\u2019s development. Over the past few years, one of TensorFlow\u2019s main weaknesses was its very complicated API.Defining deep neural networks required far more work than was reasonable. This led to the development of several high-level APIs that sat on-top of TensorFlow including TF Slim and Keras.Keras will be the official API of TensorFlow 2.0. Loading data, defining models, training, and evaluating are all now much easier to do, with cleaner Keras style code and faster development time.**","deb8e7dd":"## Train the model :\n\nTraining the neural network model requires the following steps:\n\n**Feed the training data to the model. In this example, the training data is in the x_train and y_train.  \nThe model learns to associate features and labels.  \nYou ask the model to make predictions about a test set\u2014in this example, the x_test   \nVerify that the predictions match the labels from the y_test .**\n\n## Feed the model :  \n\nTo start training, call the model.fit method\u2014so called because it \"fits\" the model to the training data:\n\n","95117cc1":"<img src = \"https:\/\/drive.google.com\/uc?id=1flZ84DlI8gQlkmFvC7Ql3Gkb1ACpEOkY\" >","9474f07f":"## Data Description \n\nMIT's GOSSIS community initiative, with privacy certification from the Harvard Privacy Lab, has provided a dataset of more than 130,000 hospital Intensive Care Unit (ICU) visits from patients, spanning a one-year timeframe. This data is part of a growing global effort and consortium spanning Argentina, Australia, New Zealand, Sri Lanka, Brazil, and more than 200 hospitals in the United States.\n\nThe data includes:\n\n**Training data** for 91,713 encounters.  \n**Unlabeled test data** for 39,308 encounters, which includes all the information in the training data except for the values for hospital_death.  \n**WiDS Datathon 2020 Dictionary** with supplemental information about the data, including the category (e.g., identifier, demographic, vitals), unit of measure, data type (e.g., numeric, binary), description, and examples.  \n**Sample submission files**","75530b21":"## Train\/Test Split :  \n\nThe data is split into training data and test data. The training set contains a known output and the model learns on this data in order to be generalized to other data later on. We have the test dataset (or subset) in order to test our model\u2019s prediction on this subset.The above is achieved in Scikit-Learn library using the train_test_split method.","22fabd3e":"## Read the dataset","c13267aa":"## Submissions :\n\nSubmissions will be evaluated on the Area under the Receiver Operating Characteristic (ROC) curve between the predicted mortality and the observed target (hospital_death)","a5c02c15":"## AUC - ROC Curve :\n\nAUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. Higher the AUC, better the model is at distinguishing between patients with disease and no disease. The ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis","0477c11b":"<img src=\"https:\/\/drive.google.com\/uc?id=1fqvUVxD8GcnwREynD5HQYndqP68SnIBd\">\n\n## Objective\n\n**The challenge is to create a model that uses data from the first 24 hours of intensive care to predict patient survival. MIT's GOSSIS community initiative, with privacy certification from the Harvard Privacy Lab, has provided a dataset of more than 130,000 hospital Intensive Care Unit (ICU) visits from patients, spanning a one-year timeframe. This data is part of a growing global effort and consortium spanning Argentina, Australia, New Zealand, Sri Lanka, Brazil, and more than 200 hospitals in the United States.**"}}