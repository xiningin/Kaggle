{"cell_type":{"2abcb6a6":"code","fb6a49bf":"code","ac28f324":"code","51fa048d":"code","29ab1252":"code","e021cbe0":"code","19aa8677":"code","6f6cb5dd":"code","e36762e3":"code","4eb71550":"code","129cd11a":"code","c669b70a":"code","8d9dd0ad":"code","cc6e6db7":"code","be5b23c1":"code","a5085298":"code","79891f35":"code","f79b925d":"code","b1ae949b":"code","be0f8b5e":"code","fd2b13ff":"code","5535b0fe":"code","9e8b938c":"code","fca853a4":"code","03224868":"code","5cab245b":"code","e9b36332":"code","41fd8944":"code","88005154":"code","8903912b":"code","8bcc13c9":"code","b9eebbf6":"code","59ea28c3":"code","12f26cbe":"code","77db5e19":"code","4eeafd1c":"code","b0630abe":"code","d230acb2":"code","c4f22132":"code","83d405cc":"code","8249ef4b":"code","234a6348":"code","6bc89092":"code","ef57eb4e":"code","0326fe36":"code","543a987c":"code","eee0c663":"code","501893e2":"code","e0668e16":"code","ede2a74a":"code","6fa19d63":"code","6f08e7bd":"code","dbfdecaa":"code","2a6a5ded":"code","ccbd7aa3":"code","3d788b1b":"code","921a75bb":"code","19be2d12":"code","d1567263":"code","8b3b6d9f":"code","61ec4614":"code","48841a65":"code","ec551309":"code","43ce0c93":"code","d3e6a00a":"code","44394dc5":"markdown","b23916b1":"markdown","79022a88":"markdown","63c916d8":"markdown","08751754":"markdown","0a70fbc9":"markdown","0c2d3e14":"markdown"},"source":{"2abcb6a6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('ggplot')\n\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom PIL import Image\n\nimport datetime\nfrom string import punctuation","fb6a49bf":"train = pd.read_csv('..\/input\/quora-insincere-questions-classification\/train.csv')","ac28f324":"train.head()","51fa048d":"sum(train.target)\/len(train)","29ab1252":"train = train.drop('qid',axis=1)","e021cbe0":"# preprocess text for further use\ntrain['question_text'] = train.question_text.apply(lambda x: x.lower())\ntrain['question_text'] = train.question_text.apply(lambda x: ''.join([c for c in x if c not in punctuation]))","19aa8677":"train['question_length'] = train.question_text.apply(lambda x: len(x))","6f6cb5dd":"print('The max length of question is:',train.question_length.max())\nprint('The minimum length of question is:',train.question_length.min())\nprint('The mean length of question is:',train.question_length.mean())\nprint('The max standard deviation of question is:',train.question_length.std())","e36762e3":"train.question_length.hist(bins=50)\nplt.title('The distribution of length of questions')\nplt.axvline(np.mean(train.question_length),color='y')","4eb71550":"train['question_length_scaled'] = train.question_length.apply(lambda x: np.log(x+1))","129cd11a":"train.describe()","c669b70a":"train.question_length_scaled.hist(bins=50)","8d9dd0ad":"sns.boxplot(train.target,train.question_length_scaled)\nplt.title('The distribution of length of target or not')","cc6e6db7":"Q = np.array(Image.open('..\/input\/quora-logo1\/quora-logo-rubber-stamp.png'))","be5b23c1":"np.random.seed(321)\nsns.set(rc={'figure.figsize':(14,8)})\nreviews = ' '.join(train['question_text'].tolist())\n\nwordcloud = WordCloud(mask=Q,background_color=\"white\").generate(reviews)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.title('Questions',size=20)\nplt.show()","a5085298":"train_1 = train[train.target == 1]\ntrain_0 = train[train.target == 0]","79891f35":"reviews = ' '.join(train_1['question_text'].tolist())\n\nwordcloud = WordCloud(mask=Q,background_color=\"white\").generate(reviews)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.title('Target 1',size=20)\nplt.show()","f79b925d":"reviews = ' '.join(train_0['question_text'].tolist())\n\nwordcloud = WordCloud(mask=Q,background_color=\"white\").generate(reviews)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.title('Target 0',size=20)\nplt.show()","b1ae949b":"from collections import Counter\n\ntext = ' '.join(train['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","be0f8b5e":"print('Unique words: ', len((vocab_to_int)))","fd2b13ff":"counts.most_common(20)","5535b0fe":"text = ' '.join(train_0['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","9e8b938c":"counts.most_common(20)","fca853a4":"text = ' '.join(train_1['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","03224868":"counts.most_common(20)","5cab245b":"train.head()","e9b36332":"from nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \n\nstop_words = set(stopwords.words('english')) \n\ntrain['question_text'] = train.question_text.apply(lambda x: word_tokenize(x))\n\ntrain['question_text'] = train.question_text.apply(lambda x: [w for w in x if w not in stop_words])","41fd8944":"train.head()","88005154":"train['question_text'] = train.question_text.apply(lambda x: ' '.join(x))","8903912b":"train.head()","8bcc13c9":"text = ' '.join(train['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","b9eebbf6":"print('Unique words: ', len((vocab_to_int)))","59ea28c3":"counts.most_common(20)","12f26cbe":"train['question_text'] = train['question_text'].apply(lambda x: x.replace('\u2019', \"\"))","77db5e19":"train_1 = train[train.target == 1]\ntrain_0 = train[train.target == 0]","4eeafd1c":"text = ' '.join(train_0['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","b0630abe":"counts.most_common(20)","d230acb2":"text = ' '.join(train_1['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","c4f22132":"counts.most_common(20)","83d405cc":"dup_words = ['people','would','get','like','india','think', 'many']\n\ntrain['question_text'] = train.question_text.apply(lambda x: word_tokenize(x))\n\ntrain['question_text'] = train.question_text.apply(lambda x: [w for w in x if w not in dup_words])\n\ntrain['question_text'] = train.question_text.apply(lambda x: ' '.join(x))\n\ntrain_1 = train[train.target == 1]\ntrain_0 = train[train.target == 0]","8249ef4b":"text = ' '.join(train_0['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","234a6348":"counts.most_common(20)","6bc89092":"text = ' '.join(train_1['question_text'].tolist())\nquestion_word = text.split(' ')\nall_question = ' '.join(question_word)\nwords = all_question.split()\n\n# words wrong datatype\ncounts = Counter(words)\nvocab = sorted(counts, key=counts.get, reverse=True)\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nquestions_ints = []\nfor questions in question_word:\n    questions_ints.append([vocab_to_int[word] for word in questions.split()])","ef57eb4e":"counts.most_common(20)","0326fe36":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nX_train, X_test, y_train, y_test = train_test_split(train[\"question_text\"], train['target'], test_size=0.33\n                                    ,random_state=53)\n\n# Initialize a CountVectorizer object: count_vectorizer\ncount_vectorizer = CountVectorizer(stop_words=\"english\")\n\n# Transform the training data using only the 'text' column values: count_train \ncount_train = count_vectorizer.fit_transform(X_train)\n\ny_train = np.asarray(y_train.values)\n\nch2 = SelectKBest(chi2, k = 300)\n\nX_new = ch2.fit_transform(count_train, y_train)\n\n# Transform the test data using only the 'text' column values: count_test \ncount_test = count_vectorizer.transform(X_test)\n\nX_test_new = ch2.transform(X=count_test)","543a987c":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize a TfidfVectorizer object: tfidf_vectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n\n# Transform the training data: tfidf_train \ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\n\n# Transform the test data: tfidf_test \ntfidf_test = tfidf_vectorizer.transform(X_test)","eee0c663":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n\nclf = RandomForestClassifier()\n# Fit the classifier to the training data\nclf.fit(X_new, y_train)\n\n# Create the predicted tags: pred\npred = clf.predict(X_test_new)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","501893e2":"sns.heatmap(metrics.confusion_matrix(pred,y_test),annot=True,fmt='2.0f')","e0668e16":"clf = RandomForestClassifier()\n# Fit the classifier to the training data\nclf.fit(tfidf_train, y_train)\n\n# Create the predicted tags: pred\npred = clf.predict(tfidf_test)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","ede2a74a":"sns.heatmap(metrics.confusion_matrix(pred,y_test),annot=True,fmt='2.0f')","6fa19d63":"from sklearn.naive_bayes import MultinomialNB\n\n\n# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\nnb_classifier = MultinomialNB()\n\n# Fit the classifier to the training data\nnb_classifier.fit(X_new, y_train)\n\n# Create the predicted tags: pred\npred = nb_classifier.predict(X_test_new)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","6f08e7bd":"sns.heatmap(metrics.confusion_matrix(pred,y_test),annot=True,fmt='2.0f')","dbfdecaa":"from sklearn.naive_bayes import MultinomialNB\n\n\n# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\nnb_classifier = MultinomialNB()\n\n# Fit the classifier to the training data\nnb_classifier.fit(tfidf_train, y_train)\n\n# Create the predicted tags: pred\npred = nb_classifier.predict(tfidf_test)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","2a6a5ded":"sns.heatmap(metrics.confusion_matrix(pred,y_test),annot=True,fmt='2.0f')","ccbd7aa3":"from sklearn import svm\n\nclf = svm.SVC()\n\nclf.fit(X_new, y_train)\n\npred = clf.predict(X_test_new)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","3d788b1b":"clf = svm.SVC()\n\nclf.fit(tfidf_train, y_train)\n\npred = clf.predict(tfidf_test)\n\n# Calculate the accuracy score: score\nscore = metrics.accuracy_score(y_test, pred)\nprint('Accuracy is:',score)\nf1 = metrics.f1_score(y_test, pred)\nprint('F score is:',f1)","921a75bb":"test = pd.read_csv('..\/input\/quora-insincere-questions-classification\/test.csv')","19be2d12":"test = test.drop('qid',axis=1)\n\ntest['question_text'] = test.question_text.apply(lambda x: x.lower())\ntest['question_text'] = test.question_text.apply(lambda x: ''.join([c for c in x if c not in punctuation]))","d1567263":"test['question_text'] = test.question_text.apply(lambda x: word_tokenize(x))\n\ntest['question_text'] = test.question_text.apply(lambda x: [w for w in x if w not in stop_words])\n\ntest['question_text'] = test.question_text.apply(lambda x: [w for w in x if w not in dup_words])","8b3b6d9f":"test['question_text'] = test.question_text.apply(lambda x: ' '.join(x))","61ec4614":"# Transform the training data using only the 'text' column values: count_train \ncount = count_vectorizer.transform(test.question_text)\n\nX = ch2.transform(count)","48841a65":"y_pred = clf.predict(X)","ec551309":"submission = pd.read_csv('..\/input\/quora-insincere-questions-classification\/sample_submission.csv')","43ce0c93":"submission['prediction'] = y_pred","d3e6a00a":"submission.to_csv('submission.csv')","44394dc5":"One thing that catch my eyes is that both of the word clouds have india. But the ratios are different. While in target 1, there are trump, liberal, muslim, and american in there. I'll use counter to find more insights.","b23916b1":"# Intro\n\nThere are so many insincere and inaccurate questions I saw on Quora. Even the questioners themselves not sure about what they are asking. I'm here to explore the questions text and implement text mining to find a way to build NLP Model classify the insincere question from sincere one.","79022a88":"I'll split the data into target 1 and target 0 to see what's different in their word clouds.","63c916d8":"As you see, the most of the words are not really meaningful to us.","08751754":"Well, this is a good result. I can tell the difference of target 1 from target 0.\n\nBut I'll remove the duplicated words in both part","0a70fbc9":"### Only 6.18% of the data are target 1","0c2d3e14":"What I saw is:\n\n* Donal Trump\n* liberal\n* india\n* muslim\n* american\n* christian\n* conservative"}}