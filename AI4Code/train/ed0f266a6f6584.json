{"cell_type":{"69d12f10":"code","dec2a7fe":"code","5c2381eb":"code","8edf7052":"code","0e0a89e2":"code","16317081":"code","1b015123":"code","fa7e0f3f":"code","f6a4b384":"code","ba662bb3":"code","37fcb4d8":"code","78868deb":"code","8254b3de":"code","505d9c97":"code","38256799":"code","cd7c0134":"code","cfdc6077":"code","958e55b8":"code","2c03a1bd":"code","cb95c84e":"code","5ffd529e":"code","8958c3a7":"code","591e151b":"code","a113e525":"code","9b6e7900":"code","0558c555":"code","56b04d2c":"code","d61da316":"code","458e0f78":"code","152c5347":"code","97deb116":"code","2f42fc0e":"code","91255aa9":"code","1198bdd6":"code","ecb42580":"code","a59d3c6f":"code","fbb75547":"code","aa095995":"code","ab1a46f4":"code","524403e5":"code","0006f2fb":"code","9a6b5fa5":"code","ce284c0e":"code","1c1ebd0e":"code","aee9abc9":"code","7dbc24b4":"code","64e38e94":"code","a7f9349a":"markdown","e6b278c5":"markdown","bb2cf2f9":"markdown","27d19cdd":"markdown","75b500b2":"markdown","75057e10":"markdown","a53e2efb":"markdown","86166df5":"markdown","0e4089a1":"markdown","80ac01f0":"markdown","d4bdb640":"markdown","b4d2a84b":"markdown","d1447986":"markdown","1f77c25a":"markdown","634fee73":"markdown"},"source":{"69d12f10":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dec2a7fe":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt","5c2381eb":"import warnings\nwarnings.filterwarnings(\"ignore\")","8edf7052":"df = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf.head()","0e0a89e2":"df.shape","16317081":"df.describe()","1b015123":"plt.figure(figsize=(10,5))\nsns.countplot(x=df.RainTomorrow)","fa7e0f3f":"df['Date'] =  pd.to_datetime(df['Date'])","f6a4b384":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","ba662bb3":"missing_value=pd.DataFrame(df.isna().sum().sort_values(ascending=False),columns=['Column'])\nmissing_value['%']=(df.isna().sum()\/145460)*100","37fcb4d8":"missing_value","78868deb":"d={'Yes':1,'No':0}","8254b3de":"df['RainTomorrow']=df.RainTomorrow.map(d)\ndf['RainToday']=df.RainToday.map(d)","505d9c97":"df=df.drop(['Sunshine','Evaporation','Cloud3pm','Cloud9am'], axis=1)","38256799":"df_numerical=df.select_dtypes(exclude='object')","cd7c0134":"numerical_cols=[]\nfor c in df_numerical:\n    numerical_cols.append(c)","cfdc6077":"numerical_cols.remove(\"RainTomorrow\")\nnumerical_cols.remove(\"RainToday\")","958e55b8":"numerical_cols","2c03a1bd":"for c in numerical_cols:\n    fig=plt.figure(figsize=(10,4))\n    sns.boxplot(x=df[c])\n    plt.show()","cb95c84e":"for col in numerical_cols:\n    plt.figure(figsize=(10,8))\n    sns.distplot(df.loc[df.RainTomorrow==1][col],kde_kws={'label':'Will Rain'},color='green')\n    sns.distplot(df.loc[df.RainTomorrow==0][col],kde_kws={'label':'No Rain'},color='purple')\n    \n    plt.legend(['Rain','No Rain'])\n    plt.title(c)","5ffd529e":"for col in numerical_cols:\n    df[col] = df[col].fillna((df[col].mean()))\n","8958c3a7":"missing_value=pd.DataFrame(df.isna().sum().sort_values(ascending=False),columns=['Column'])\nmissing_value['%']=(df.isna().sum()\/145460)*100","591e151b":"missing_value[:6]","a113e525":"df_cat=df.select_dtypes(include='object')","9b6e7900":"categorical=[]\nfor c in df_cat:\n    categorical.append(c)","0558c555":"for c in categorical:\n    print(c)\n    df[c]=df[c].fillna(df[c].mode()[0])","56b04d2c":"df['RainToday']=df.RainToday.fillna(df['RainToday'].mode()[0])\ndf['RainTomorrow']=df.RainTomorrow.fillna(df['RainTomorrow'].mode()[0])","d61da316":"df.isna().sum()","458e0f78":"categorical","152c5347":"df['WindDir9am']","97deb116":"plt.figure(figsize=(20,20))\n\nplt.subplot(4,1,1)\nsns.countplot(x=df.WindDir9am,hue=df.RainTomorrow)\n\nplt.subplot(4,1,2)\nsns.countplot(x=df.WindGustDir,hue=df.RainTomorrow)\n\nplt.subplot(4,1,3)\nsns.countplot(x=df.WindDir3pm,hue=df.RainTomorrow)\n\nplt.subplot(4,1,4)\nplt.xticks(rotation=90)\nsns.countplot(x=df.Location,hue=df.RainTomorrow)\n\nplt.show()","2f42fc0e":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import preprocessing\n\nfrom sklearn.metrics import plot_roc_curve,roc_auc_score,roc_curve","91255aa9":"df=df.apply(preprocessing.LabelEncoder().fit_transform)","1198bdd6":"X = df.drop(['RainTomorrow'], axis=1)\ny = df['RainTomorrow']","ecb42580":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","a59d3c6f":"X_train","fbb75547":"clf_random_forest=RandomForestClassifier()\nclf_random_forest=clf_random_forest.fit(X_train,y_train)\nrandom_forest_predictions=clf_random_forest.predict(X_test)\n\naccuracy_random_forest=accuracy_score(y_test,random_forest_predictions)*100\nprint(accuracy_random_forest)","aa095995":"r_fpr,r_tpr,_=roc_curve(y_test,random_forest_predictions)\nr_auc=roc_auc_score(y_test,random_forest_predictions)\nplt.plot(r_fpr,r_tpr,label='Random Forest Prediction (area={:.3f})'.format(r_auc))\nplt.title('ROC plot Random Forest Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","ab1a46f4":"KNC=KNeighborsClassifier()\nKNC=KNC.fit(X_train,y_train)\nKNN_predictions=KNC.predict(X_test)\n\nknn_accuracy=accuracy_score(y_test, KNN_predictions)*100\nprint(knn_accuracy)","524403e5":"k_fpr,k_tpr,_=roc_curve(y_test,KNN_predictions)\nknn_score=roc_auc_score(y_test,KNN_predictions)\nplt.plot(k_fpr,k_tpr,label='KNN prediction (area={:.3f})'.format(knn_score))\nplt.title('ROC plot KNN')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","0006f2fb":"d_tree=DecisionTreeClassifier()\nd_tree=d_tree.fit(X_train,y_train)\nd_tree_predictions=d_tree.predict(X_test)\n\nd_tree_accuracy=accuracy_score(y_test,d_tree_predictions)*100\nprint(d_tree_accuracy)","9a6b5fa5":"d_fpr,d_tpr,_=roc_curve(y_test,d_tree_predictions)\nd_tree_score=roc_auc_score(y_test,d_tree_predictions)\nplt.plot(d_fpr,d_tpr,label='Decision Tree prediction (area={:.3f})'.format(d_tree_score))\nplt.title('ROC plot Decision Tree Classifier')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","ce284c0e":"gbc = GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, random_state=0)\ngbc=gbc.fit(X_train,y_train)\ngbc_predictions=gbc.predict(X_test)\n\ngbc_accuracy=accuracy_score(y_test,gbc_predictions)*100\nprint(gbc_accuracy)","1c1ebd0e":"gbc_fpr,gbc_tpr,_=roc_curve(y_test,gbc_predictions)\ngbc_score=roc_auc_score(y_test,gbc_predictions)\nplt.plot(d_fpr,d_tpr,label='Gradient Boosting prediction (area={:.3f})'.format(gbc_score))\nplt.title('ROC plot Gradient Boosting')\nplt.xlabel('False Positive rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.show()","aee9abc9":"models =pd.DataFrame({'Model':['RandomForestClassifier','KNeighborsClassifier','DecisionTreeClassifier',' GradientBoostingClassifier'],\n                      'Score':[accuracy_random_forest,knn_accuracy,d_tree_accuracy,gbc_accuracy]\n                     })","7dbc24b4":"models.head()","64e38e94":"fig=plt.figure(figsize=(15,9))\nplt.plot(models.Model,models.Score,marker='H',mfc='r')\nplt.xticks(rotation=90)\nplt.show()","a7f9349a":"# Heatmap to understand correlation of variables and the degree","e6b278c5":"# Experimenting with different models","bb2cf2f9":"# Splitting the dataset for Train\/Test","27d19cdd":"# Replacing missing categorical features with the mode","75b500b2":"# Missing column values in the dataframe","75057e10":"# Filtering Out Numerical Columns","a53e2efb":"# Random forest seems to be the most accruate model for this dataset. ","86166df5":"# Box Plots for Numerical Features","0e4089a1":"# Replacing discrete variables with the mode ","80ac01f0":"# Density Plots of Numerical Features","d4bdb640":"# Rechecking for empty values","b4d2a84b":"**Replacing missing numerical values with their mean**","d1447986":"# Categorical Features","1f77c25a":"# Count Plot for direction of wind","634fee73":"# Dropping columns with more than 38% Missing values"}}