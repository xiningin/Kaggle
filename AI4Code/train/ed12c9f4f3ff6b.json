{"cell_type":{"6da12881":"code","89f2e150":"code","8e4a030a":"code","6683f76d":"code","fb0ab765":"code","83106fd4":"code","342151de":"code","0320486d":"code","83f441b1":"code","fac6b429":"code","0f9e8c8f":"code","48fc0c53":"code","6b999278":"code","a8197f8b":"code","95edd96e":"code","498e4690":"code","ddb1da99":"markdown","ab74c531":"markdown","ceac6d16":"markdown","442cd4f1":"markdown","da689b5c":"markdown","12287f3a":"markdown","ffdefc94":"markdown","6a8dc796":"markdown"},"source":{"6da12881":"#Importing libraries\nimport pandas as pd\nimport time\nfrom bs4 import BeautifulSoup as BS\nimport requests\nimport re\nimport selenium\nfrom selenium import webdriver\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom itertools import product","89f2e150":"# I kept all the values of the cars details to use them in our scraper later on\nbody_type_values=['Cabriolet','Coupe','Hatchback','SUV','Sedan','Station','Van']\ntransmission_type_values=['CVT','Dual Clutch','Manual','Automatic']\nmotor_capacity_values=['800 cc','900 cc','1000 cc','1100 cc','1200 cc','1300 cc','1400 cc','1500 cc','1600 cc','1700 cc','1800 cc','1900 cc','2000 cc','2200 cc','2400 cc','2500 cc','2700 cc','2800 cc','2900 cc','3000 cc','3200 cc','3400 cc','3500 cc','3600 cc','3700 cc','3800 cc','3900 c','4000 cc','4200 cc','4300 cc','4400 cc','4600 cc','4700 cc','4800 cc','5000 cc','5400 cc','5600 cc','5700 cc','5800 cc','6000 cc','6200 cc','6400 cc']\ncolor_values=['Baby Blue','Beige','Black','Blue','Bronze','Brown','Champagne','Dark Grey','Gold','Gray','Green','Maroon','Navy Blue','Orange','Pink','Purple','Red','Silver','Turquoise','White','Yellow']","8e4a030a":"Cars_links = []\ndef collect_add_links(page_nums):\n    driver=webdriver.Chrome(r\"C:\\Users\\abdal\\Downloads\\Contact cars - WEB SCARAPING\\chromedriver.exe\")\n            \n    # Intialize\n    print('Starting, please wait....')\n    \n    for page_num in list(range(page_nums + 1))[1:]:\n        # Get page link\n        link = f'https:\/\/www.contactcars.com\/en\/cars\/used\/engines?make=120&make=1&make=64&make=33&make=2&make=68&make=63&make=42&make=109&make=61&make=115&make=59&make=122&make=57&make=21&make=22&make=23&make=81&make=101&make=11&make=30&make=36&make=45&make=116&make=6&make=24&make=102&make=58&make=52&make=53&make=123&make=108&make=119&make=25&make=46&make=7&make=43&make=73&make=66&make=124&make=31&make=27&make=117&make=10&make=51&make=26&make=103&make=38&make=37&make=113&make=48&make=56&make=50&make=110&make=62&make=28&make=3&make=47&make=39&make=4&make=29&make=14&make=15&make=34&make=16&make=107&make=40&make=32&make=55&make=17&make=69&make=104&make=118&make=105&make=8&make=65&make=19&make=70&make=60&make=44&make=41&make=35&make=20&make=121&make=5&make=13&make=12&make=114&page={page_num}&sortOrder=false&sortBy=CreatedAt'\n        driver.get(link)\n        \n        # sleep for 2 seconds after loading the page\n        time.sleep(1)\n        \n        # working on page number: \n        print(f'Working in page {page_num}....')\n        \n        # Scrolling fuction\n        scroll_pause_time = 1\n        screen_height = driver.execute_script(\"return window.screen.height;\")\n\n        i = 1 \n        while True:\n            elems=driver.find_elements_by_css_selector('div.full-side')\n            driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n            i += 1\n            time.sleep(scroll_pause_time)\n            # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n            scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n            # Break the loop when the height we need to scroll to is larger than the total scroll height\n            if (screen_height) * i > scroll_height:\n                break\n                \n        # sleep for 2 seconds after scrolling down the page        \n        time.sleep(1)\n        \n        # Get page html content \n        src = driver.page_source\n        soup=BS(src,'html.parser')\n\n        # Get all adds  \n        Cars_link = soup.find_all('div', {'class':['col-xl-4 col-md-6 mt-3 px-2 ng-star-inserted']})\n\n        # Get links from these adds \n        for item in Cars_link: \n            for link in item.find_all('a', href = True):\n                Cars_links.append(link[\"href\"])\n\n        print(f'Page {page_num} completed')\n        \n        if page_num == page_nums:\n            print(f'Job Done: All {len(Cars_links)} Links from your {page_nums} have been collected')","6683f76d":"collect_add_links(1)","fb0ab765":"# A sample of the collected Cars links\nCars_links[:4]","83106fd4":"#These are all the features i am going to scrap from the website\nMobile_number=[]\nModel_name=[]\nSubModel_name=[]\nCar_condition=[]\nKilometers_crossed=[]\nCar_price=[]\nSeller_City=[]\nModel_year=[]\nbody_type=[]\nTransmission_type=[]\nMotor_capacity=[]\nCar_color=[]\nwaranty_condition=[]\nCar_paint=[]\nAd_post_date=[]\nInterior_Features=[]\nExterior_Features=[]\nMultimedia_Features=[]\nSafety_Features=[]","342151de":"ADs_list = []\ndriver = webdriver.Chrome(r\"C:\\Users\\abdal\\Downloads\\Contact cars - WEB SCARAPING\\chromedriver.exe\")\nstarting_part = 'https:\/\/www.contactcars.com'\ncount = 1\n\nfor link in Cars_links[:10]:\n    print(f'AD number {count}: Collecting data....')\n    driver.get(starting_part+link)\n    time.sleep(1)\n    html=driver.page_source #import page source\n    soup=BS(html,'html.parser')\n\n    \n    #-----------------------------------------\n    #section 1: easy straight forward features\n    #----------------------------------------- \n    \n    \n    try:\n          Model_name.append(soup.find_all('a',{'class':'breadcrumb__items__item ng-star-inserted'})[1].text.strip())\n    except AttributeError:\n          Model_name.append('Not available')\n    try:\n          Kilometers_crossed.append(soup.find('div',{'class':'car-details__status ng-star-inserted'}).text.strip())\n    except AttributeError:\n          Kilometers_crossed.append('Not available')\n    try:\n          SubModel_name.append(soup.find('div',{'class':'d-inline-block'}).text.strip())\n    except AttributeError:\n          SubModel_name.append('Not available')\n    try:\n          Car_price.append(soup.find('h3',{'class':'car-details__used-info__car-info__finance__total'}).text.strip())\n    except AttributeError:\n          Car_price.append('Not available')\n    try:\n          Car_condition.append(soup.find('p',{'class':'car-details__used-info__about__details pre-line'}).text.strip())\n    except AttributeError:\n          Car_condition.append('Not available')\n    try:\n          Seller_City.append(soup.find('div',{'class':'car-details__used-info__car-info__locations ng-star-inserted'}).text.strip())\n    except AttributeError:\n          Seller_City.append('Not available')\n    try:\n          Model_year.append(soup.find('div',{'class':'d-inline-block margin-start--sm'}).text.strip())\n    except AttributeError:\n          Model_year.append('Not available')\n            \n        \n    Date_div = soup.find_all(\"span\", class_=\"car-details__sumary__item__details\")\n        \n    try:\n          for i in Date_div[3]:\n            Ad_post_date.append(i.strip()) # we chose Div[2] because it has the UsedCar_post_date in it\n    except IndexError:\n                    Ad_post_date.append('Not available')\n            \n            \n                \n    #-----------------------------------------\n    #section 2: Getting Additional Features from the ads\n    #----------------------------------------- \n    \n\n    try:\n          Interior_Features.append(soup.find_all('div',{'class':'row mx-n5'})[0].text)\n    except IndexError:\n          Interior_Features.append('Not available')\n            \n    try:\n          Exterior_Features.append(soup.find_all('div',{'class':'row mx-n5'})[1].text)\n    except IndexError:\n          Exterior_Features.append('Not available')\n            \n    try:\n          Multimedia_Features.append(soup.find_all('div',{'class':'row mx-n5'})[2].text)\n    except IndexError:\n          Multimedia_Features.append('Not available')\n            \n    try:\n          Safety_Features.append(soup.find_all('div',{'class':'row mx-n5'})[3].text)\n    except IndexError:\n          Safety_Features.append('Not available')\n        \n        \n    #-----------------------------------------\n    #section 3: Getting car details such as (color, bodytype, motor capacity, ...) \n    #----------------------------------------- \n    \n    \n    try:\n        car_details = soup.find_all('span', class_ = 'car-details__car-data__item__desc')\n        car_details_list = []\n        for item in car_details:\n            car_details_list.append(item.text.strip())\n\n    \n        if set(color_values)&set(car_details_list):\n            Car_color.append(','.join(set(color_values)&set(car_details_list)))\n        else:\n            Car_color.append('Not available')\n                \n     \n        if set(body_type_values)&set(car_details_list):\n            body_type.append(','.join(set(body_type_values)&set(car_details_list)))\n        else:\n            body_type.append('Not available')\n            \n            \n        if set(transmission_type_values)&set(car_details_list):\n            Transmission_type.append(','.join(set(transmission_type_values)&set(car_details_list)))\n        else:\n            Transmission_type.append('Not available')\n            \n            \n        if set(motor_capacity_values)&set(car_details_list):\n            Motor_capacity.append(','.join(set(motor_capacity_values)&set(car_details_list)))\n        else:\n            Motor_capacity.append('Not available')\n            \n            \n            \n        if 'In Warranty' in car_details_list:\n            waranty_condition.append('In Warranty')\n        else:\n            waranty_condition.append('Not available')\n\n        if 'Factory Paint' in car_details_list:\n            Car_paint.append('Factory Paint')\n        else:\n            Car_paint.append('Not available')\n        \n        \n    except:\n            car_details.append('Not available')\n            \n        \n    #Getting the phone number before we Move on to another page\n    \n    try:\n        button = driver.find_element_by_xpath('\/html\/body\/app-root\/app-index\/div\/div[2]\/app-index\/div[3]\/div\/div\/div[2]\/div[1]\/div\/div[2]\/div[2]\/div[2]')\n        button.click()\n        #time.sleep(1)\n        Mobile_number.append(soup.find('a',{'class':'text-decoration-none text--brand'}).text.strip())\n    except:\n        Mobile_number.append('Not available')\n        \n        \n    #-----------------------------------------        \n    #Section 4: create the data frame \n    #----------------------------------------- \n    \n    \n    df={'Mobile_number':Mobile_number,\n             'Model_name':Model_name,\n             'SubModel_name':SubModel_name,\n             'Car_condition':Car_condition,\n             'Kilometers_crossed':Kilometers_crossed,\n             'Car_price':Car_price,\n             \"Seller_City\":Seller_City,\n             'Model_year':Model_year,\n             'body_type':body_type,\n             'Transmission_type':Transmission_type,\n             'Motor_capacity':Motor_capacity,\n             'Car_color':Car_color,\n             'waranty_condition':waranty_condition,\n             'Car_paint':Car_paint,\n             'Ad_post_date':Ad_post_date,\n             'Interior_Features':Interior_Features,\n             'Exterior_Features':Exterior_Features,\n             'Multimedia_Features':Multimedia_Features,\n             'Safety_Features':Safety_Features}\n    ADs_list.append(df)\n        \n    print(f'AD number {count}: Done')\n    count += 1","0320486d":"#Converting the Collected data into a dataframe\ndf = pd.DataFrame(df)","83f441b1":"#checking results\ndf","fac6b429":"#collecting all features\nAll_Features=['Keyless Start\/Stop', 'Analoge Air Condition', 'Rear parking sensors', 'Rear View Camera', 'Leather Seats', 'Electronic Window', 'Multi function steering wheel', 'Paddle shifters', 'Front parking sensors', 'Front Camera','Sun Roof','Panorama Roof','Power mirrors','AUX','Bluetooth','USB','Touch screen','Navigation System','Tire Pressure Monitoring (TPMS)','Electronic Stability Program (ESP)','Cruise Control','Anti-Lock Braking System (ABS)','Air Bags For Driver','Air Bags Passenger','Side Airbags','Traction Control']","0f9e8c8f":"#Creating a column for each feature in the All_Features list in the dataframe and giving it a basic value ('Not available')\nfor feature in All_Features:\n    df[feature] = 'Not available'","48fc0c53":"#Checking result\ndf.head(2)","6b999278":"def Capture_features(x,b,c,d):\n    for i in range(len(df[x])):\n        for s in All_Features:\n            if s in df[x][i]:\n                df[s][i]=s\n            if s in df[b][i]:\n                df[s][i]=s\n            if s in df[c][i]:\n                df[s][i]=s\n            if s in df[d][i]:\n                df[s][i]=s","a8197f8b":"#Applying the function on the collected features for each car\nCapture_features('Interior_Features','Exterior_Features','Multimedia_Features','Safety_Features')","95edd96e":"#Checking final result\ndf","498e4690":"#exporting data into an excel file\n#df.to_excel('Contactcars.com.xlsx')","ddb1da99":"Objective of this Notebook:\n\nIn this notebook i will go through the first stage of my project which is scraping data, i am going to scrape around 12000 Ads from www.Contactcars.com website to use them in my project.","ab74c531":"## Used Cars Market: Web Scraping","ceac6d16":"Great! Now I can move on to the final step","442cd4f1":"I will create a function that checks each value in the All_Features List and Return the value of the feature in the feature column if it found it in the car, if it didn't find it it will leave the value as Not available","da689b5c":"Amazing! Our data seems Consistent.\n\nNow i can export it to an excel file and move on through the stages of my project.","12287f3a":"Now Let's Collect all the Additional Features of the cars from the website in a list and and create a column for each feature and mention wether the car has that feature or not ","ffdefc94":"Done !\n\nWe have finished scraping our data completely","6a8dc796":"### Purpose the study\n\nThe Used cars market in the past few years has reached a big improvement in the number of Buyers, Sellers and Investors due to the Economic developments that the country has gone through and the nature of the market it self.\n\nThis has raised alot of questions about the market and the concern to estimate the different types of used cars prices.\n\nFor that purpose i am conducting a Data Science project that would answer these questions and predict the cars prices in the \nEgyptian market.\n\nThis project will go through Five main stages:\n\n1. Getting Used Cars data (Scraping data)\n2. Data Cleaning\n3. Features Engineering\n4. Data Anlaysis\n5. Applying Machine Learning Model"}}