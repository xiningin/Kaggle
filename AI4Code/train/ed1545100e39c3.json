{"cell_type":{"874dd7d2":"code","5ed8881b":"code","2626748c":"code","b5118c2f":"code","2879ae32":"code","7a9c535d":"code","2f85a503":"code","75ce37a0":"code","db2ca648":"code","6b71a608":"code","28d45946":"code","e0fa4ca4":"code","fa06f9a6":"code","8c8d8566":"code","f795cffe":"code","81cfd4ef":"code","a5e7bb6e":"code","f9822546":"code","00b8359b":"code","8b340532":"code","68e91c05":"code","89155597":"code","1f4c4acd":"code","0ac8a22a":"code","7d8bef20":"code","7db16193":"code","a7e9bec4":"code","3a2f96ae":"code","17170f5f":"code","be954767":"code","265e7eb9":"code","7527b8f1":"code","f7536e7d":"code","9bca1900":"code","e29d8ba5":"code","c9c8dd2e":"code","57feae28":"code","d50b7af4":"code","875e4d44":"code","1f046e30":"code","d41edcf6":"code","02585b9c":"markdown","d7f352b1":"markdown","845c6d95":"markdown","3fb396ef":"markdown","50707cb3":"markdown","86094c28":"markdown","003a1919":"markdown"},"source":{"874dd7d2":"dev_TPU=False\nkaggle=True","5ed8881b":"if dev_TPU==True:\n    !curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --version 20200515 --apt-packages libomp5 libopenblas-dev","2626748c":"if dev_TPU==True:\n    !export XLA_USE_BF16=1","b5118c2f":"if dev_TPU==True:\n    !pip install torch_xla","2879ae32":"if dev_TPU==True:\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp","7a9c535d":"! pip install iterative-stratification\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","2f85a503":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, random_split, DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import f1_score\nfrom sklearn import model_selection \nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.utils import multiclass\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom torch.cuda import amp\n\n%matplotlib inline","75ce37a0":"torch.manual_seed(10)","db2ca648":"if kaggle==True:\n    ROOT_DIR = '..\/input\/jovian-pytorch-z2g'\n    DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas'\nelse:\n    ROOT_DIR = '\/content'\n    DATA_DIR = '\/content'\n    \n\nTRAIN_DIR = DATA_DIR + '\/train'                           # Contains training images\nTEST_DIR = DATA_DIR + '\/test'                             # Contains test images\n\nTRAIN_CSV = DATA_DIR + '\/train.csv'                       # Contains real labels for training images\nTEST_CSV = ROOT_DIR+'\/submission.csv'   # Contains dummy labels for test image","6b71a608":"df = pd.read_csv(TRAIN_CSV)\nvals = df.Label.values\ny=[]\nfor x in vals:\n    y.append([int(i) for i in x.split()])\n\ny = MultiLabelBinarizer().fit_transform(y)\nmulticlass.type_of_target(y)\n\n","28d45946":"df = pd.read_csv(TRAIN_CSV)\ndf['kfold'] = -1\ndf = df.sample(frac=1).reset_index(drop=True)\n\"\"\"\nkf = model_selection.KFold(n_splits=5)\nfor f, (t_, v_) in enumerate(kf.split(X=df)):\n    df.loc[v_, 'kfold'] = f\n\"\"\"\nmskf = MultilabelStratifiedKFold(n_splits=5)\nvals = df.Label.values\ny=[]\nfor x in vals:\n    y.append([int(i) for i in x.split()])\ny = MultiLabelBinarizer().fit_transform(y)\n#multiclass.type_of_target(y) - > multilabel-indicator\nfor f, (t_, v_) in enumerate(mskf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n\ndf.to_csv(\"train_folds.csv\", index=False)\n","e0fa4ca4":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","fa06f9a6":"public_threshold = 0.3\nlocal_threshold = 0.5\ndef encode_label(label):\n    #print(label)\n    target = torch.zeros(10)\n    #for l in str(label).split(' '):\n    for l in label:\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target, text_labels=False, threshold=public_threshold):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)\n    ","8c8d8566":"class HumanProteinDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n\n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['Image'], row['Label']\n        #print(img_label)\n        img_fname = self.root_dir + \"\/\" + str(img_id) + \".png\"\n        img = Image.open(img_fname)\n        if self.transform:\n            img = self.transform(img)\n        return img, encode_label(img_label)","f795cffe":"mean = [0.0792, 0.0529, 0.0544]\nstd = [0.1288, 0.0884, 0.1374]\ntrain_transform = transforms.Compose([\n            #transforms.RandomCrop(512, padding=8, padding_mode='reflect'),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomVerticalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=mean,std=std)])\ntest_transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=mean,std=std)])\n","81cfd4ef":"batch_size = 64","a5e7bb6e":"def F_score(output, label, threshold=local_threshold, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    #return F2.mean(0)\n    return F2.mean()\n\ndef F_loss(output, label, threshold=local_threshold, beta=1):\n    #prob = output > threshold\n    prob = output\n    label = label > threshold\n\n    TP = torch.sum(prob * label,axis=0).float()\n    #TN = torch.sum((torch.ones_like(prob)-prob) * (~label),axis=0).float()\n    FP = torch.sum(prob * (~label),axis=0).float()\n    FN = torch.sum((torch.ones_like(prob)-prob) * label,axis=0).float()\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    #return (1-F2.mean(0))\n    return (1-F2.mean())","f9822546":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        \n        return loss.sum(dim=1).mean()","00b8359b":"class MultilabelImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        #loss = F.binary_cross_entropy(out, targets) \n        loss = F_loss(out, targets)     \n        #loss = FocalLoss()(out, targets)\n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        #loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n        loss = F_loss(out, targets)     \n        #loss = FocalLoss()(out, targets)\n        score = F_score(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_score']))","8b340532":"class ProteinCnnModel2(MultilabelImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 10)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n        #return self.network(xb)\n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","68e91c05":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","89155597":"if dev_TPU==True:\n    #TPU\n    device = xm.xla_device()\nelse:\n    #CUDA\n    device = get_default_device()","1f4c4acd":"device, device==torch.device('cpu')","0ac8a22a":"class Oversampling:\n    #def __init__(self,path):\n        #self.train_labels = pd.read_csv(path)\n    def __init__(self,df):\n        self.train_labels = df\n        self.train_labels['Label'] = [[int(i) for i in s.split()] \n                                       for s in self.train_labels['Label']]  \n        #set the minimum number of duplicates for each class\n        self.multi = [2,2,2,2,1,3,1,2,3,2]  #{0: 1.94, 1: 2.12, 2: 1.75, 3: 2.0, 4: 1.0, 5: 2.58, 6: 1.0, 7: 1.71, 8: 2.64, 9: 2.44}\n\n    def get(self,image_id):\n        labels = self.train_labels.loc[image_id,'Label'] if image_id \\\n          in self.train_labels.index else []\n        #print(labels)\n        m = 1\n        for l in labels:\n            if m < self.multi[l]: m = self.multi[l]\n        return m\n","7d8bef20":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    tk1 = tqdm(val_loader, total=len(val_loader), desc=\"Validating\")\n    #outputs = [model.validation_step(batch) for batch in tk1]\n    outputs = []\n    for batch in tk1:\n        vstep = model.validation_step(batch)\n        outputs.append(vstep)\n        if dev_TPU==False:\n            tk1.set_postfix(vloss=vstep['val_loss'].item())\n    return model.validation_epoch_end(outputs)\n\n#def fit(fold, epochs, lr, model, opt_func=torch.optim.SGD):\ndef fit(fold, epochs, lr, model, opt_func, scaler):\n    torch.cuda.empty_cache()\n    history = []\n    best_score = 0\n    df = pd.read_csv(\"train_folds.csv\")\n    train_df = df[df.kfold != fold].reset_index(drop=True)\n    val_df = df[df.kfold == fold].reset_index(drop=True)\n    \n    #Oversampling to increase threshold of rare classes\n    train_df_orig=train_df.copy()\n    s = Oversampling(train_df)\n    tr_n = [idx for idx in train_df['Image'].values for _ in range(s.get(idx))]\n    #print(len(tr_n),flush=True)\n    l = list(set(tr_n))\n    finallist = [i for i in tr_n if not i in l or l.remove(i)]\n    #print(len(finallist))\n    \n    #train_df_orig=train_df.copy()\n    for i in finallist:\n        #indicies = train_df_orig.loc[train_df_orig['Image'] == i].index\n        #print(indicies)\n        #print(train_df_orig.loc[indicies])\n        #train_df = pd.concat([train_df,train_df_orig.loc[indicies]], ignore_index=True)\n        #train_df = train_df_orig.loc[indicies]#, ignore_index=True)\n        dfindex = train_df_orig[train_df_orig['Image'] == i]\n        train_df.append([dfindex],ignore_index=True)\n    val_df['Label'] = [[int(i) for i in s.split()] for s in val_df['Label']]\n    train_ds = HumanProteinDataset(train_df, TRAIN_DIR, transform=train_transform)\n    val_ds = HumanProteinDataset(val_df, TRAIN_DIR, transform=test_transform)\n    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    val_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)\n    train_loader = DeviceDataLoader(train_dl, device)\n    val_loader = DeviceDataLoader(val_dl, device)\n    to_device(model, device);\n    optimizer = opt_func(model.parameters(), lr)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        factor=0.5,\n        patience=3,\n        threshold=0.001,\n        verbose = True,\n        mode=\"max\"\n    )\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        tk0 = tqdm(train_loader, total=len(train_loader), desc=\"Training\")\n        for batch in tk0: #tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            #loss.backward()\n            scaler.scale(loss).backward()\n            if dev_TPU==False:\n                #optimizer.step()\n                scaler.step(optimizer)\n            else:\n                xm.optimizer_step(optimizer, barrier=True)  # Note: Cloud TPU-specific code!\n            scaler.update()\n            optimizer.zero_grad()\n            if dev_TPU==False:\n                tk0.set_postfix(loss=loss.item())\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        if result['val_score'] > best_score:\n            print(\"Saving model for fold {} : Score {} --> {}\".format(fold, best_score, result['val_score']))\n            best_score = result['val_score']\n            if dev_TPU==True:\n                xm.save(model.state_dict(), f\"model_tpufold{fold}.bin\")\n            else:\n                torch.save(model.state_dict(), \"model_mskf{}.bin\".format(fold))\n        model.epoch_end(epoch, result)\n        scheduler.step(result['val_score'])\n        history.append(result)\n    return history","7db16193":"train=True","a7e9bec4":"if kaggle==True:\n    modelpath = '..\/input\/zerotogan-folds\/'\nelse:\n    modelpath = '\/content\/'\nopt_func = torch.optim.Adam\nlr = 0.00025 #1e-4  # pudae 3rd place 0.00025 -> 0.000125 -> 0.0000625\nif train == True:\n    num_epochs_freezed = 2\n    num_epochs_unfreezed = 5\nelse:\n    num_epochs = 2","3a2f96ae":"scaler = amp.GradScaler()\nif train==True:\n  #Train for all the folds\n  for fold in range(0,5):\n    model = ProteinCnnModel2()\n    #model.load_state_dict(torch.load(modelpath+\"model_fold{}.bin\".format(fold)))\n    model.load_state_dict(torch.load(modelpath+\"model_mskf{}.bin\".format(fold)))\n    if fold == 4:\n        model.load_state_dict(torch.load(\"model_mskf{}.bin\".format(fold)))\n    model.freeze()\n    history = fit(fold, num_epochs_freezed, lr, model, opt_func, scaler)\n    model.unfreeze()\n    history = fit(fold, num_epochs_unfreezed, lr, model, opt_func, scaler)\nelse:\n    #For Experimentation\n    model = ProteinCnnModel2()\n    model.freeze()\n    if dev_TPU==False and device!=torch.device('cpu'):\n        model.load_state_dict(torch.load(modelpath+\"model_mskf4.bin\"))#, map_location=torch.device('cpu')))\n    history = fit(4, num_epochs, lr, model, opt_func,scaler)\n    model.unfreeze()\n    history = fit(4, num_epochs, lr, model, opt_func,scaler)\n","17170f5f":"fold=4\nscaler = amp.GradScaler()\nmodel = ProteinCnnModel2()\n#model.load_state_dict(torch.load(modelpath+\"model_fold{}.bin\".format(fold)))\nmodel.load_state_dict(torch.load(modelpath+\"model_mskf{}.bin\".format(fold)))\nmodel.freeze()\nhistory = fit(fold, num_epochs_freezed, lr, model, opt_func, scaler)\nmodel.unfreeze()\nhistory = fit(fold, num_epochs_unfreezed, lr, model, opt_func, scaler)\n","be954767":"df_test = pd.read_csv(TEST_CSV)\ndf_test['Label'] = [[i] for i in df_test['Label']]\ntest_dataset = HumanProteinDataset(df_test, TEST_DIR, transform=test_transform)\ntest_dl = DeviceDataLoader(DataLoader(test_dataset, batch_size, num_workers=2, pin_memory=True), device)","265e7eb9":"df_test.head()","7527b8f1":"@torch.no_grad()\ndef predict_dl(dl, model):\n    if dev_TPU==False:\n        torch.cuda.empty_cache()\n    batch_probs = []\n    model.to(device)\n    for xb, _ in tqdm(dl):\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    return batch_probs","f7536e7d":"if train==True:\n    #Predict with all the fold models\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(modelpath+\"model_fold0.bin\"))\n    test_preds0 = predict_dl(test_dl, model).clone().detach()\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(modelpath+\"model_fold1.bin\"))\n    test_preds1 = predict_dl(test_dl, model).clone().detach()\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(modelpath+\"model_fold2.bin\"))\n    test_preds2 = predict_dl(test_dl, model).clone().detach()\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(modelpath+\"model_fold3.bin\"))\n    test_preds3 = predict_dl(test_dl, model).clone().detach()\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(modelpath+\"model_fold4.bin\"))\n    test_preds4 = predict_dl(test_dl, model).clone().detach()\nelse:\n    #Experimentation\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(\"model_mskf4.bin\"))\n    test_pred = predict_dl(test_dl, model).clone().detach()\n    test_pred.shape\n","9bca1900":"if train==True:\n    test_pred = test_preds0 + test_preds1 + test_preds2 + test_preds3 + test_preds4\n    test_pred \/= 5\n    test_pred.shape","e29d8ba5":"test_predictions = [decode_target(x) for x in test_pred]","c9c8dd2e":"submission_df = pd.read_csv(TEST_CSV)\nsubmission_df.Label = test_predictions\nsubmission_df.head()","57feae28":"sub_fname = 'resnet34_submission.csv'\nsubmission_df.to_csv(sub_fname, index=False)","d50b7af4":"#!pip install jovian --upgrade\n#import jovian\n#jovian.commit(project='zerogans-protein-trainfolds')","875e4d44":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', decode_target(target, text_labels=True))\n\ndef predict_single(image):\n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)\n    model = ProteinCnnModel2()\n    model.load_state_dict(torch.load(\"model_mskf4.bin\"))\n    model.to(device)\n    preds = model(xb)\n    prediction = preds[0]\n    print(\"Prediction: \", prediction)\n    show_sample(image, prediction)","1f046e30":"valdf[340:380], len(traindf)\n","d41edcf6":"#predict_single(valds[376][0]),predict_single(valds[368][0]),predict_single(valds[374][0]),predict_single(valds[375][0]),predict_single(valds[372][0])\n#predict_single(valds[377][0]),predict_single(valds[371][0]),predict_single(valds[373][0]),predict_single(valds[340][0]),predict_single(valds[344][0])\n\ntorch.mean(torch.stack(predict_single(valds[344][0]),predict_single(valds[367][0])))","02585b9c":"traindf_orig=traindf.copy()    \nfor i in finallist:\n    indicies = traindf_orig.loc[traindf_orig['Image'] == i].index\n    traindf = pd.concat([traindf,traindf_orig.loc[indicies]], ignore_index=True)\n","d7f352b1":"len([name for name in os.listdir(TRAIN_DIR)])\nimport fnmatch\nlen(fnmatch.filter(os.listdir(TRAIN_DIR), '*.png'))","845c6d95":"df = pd.read_csv(\"train_folds.csv\")\nvaldf = df[df.kfold == 0].reset_index(drop=True)\ntraindf = df[df.kfold != 0].reset_index(drop=True)\nvaldf['Label'] = [[int(i) for i in s.split()] for s in valdf['Label']]\ntraindf['Label'] = [[int(i) for i in s.split()] for s in traindf['Label']]\n\nvalds = HumanProteinDataset(valdf, TRAIN_DIR, transform=test_transform)\ntrainds = HumanProteinDataset(traindf, TRAIN_DIR, transform=test_transform)\n","3fb396ef":"#mu in \"create_class_weight\" is a dampening parameter that could be tuned\n\nimport numpy as np\nimport math\n\ndef create_class_weight(labels_dict, mu=0.5):\n    total = np.sum([labels_dict[i] for i in labels_dict.keys()])\n    print(total)\n    keys = labels_dict.keys()\n    class_weight = dict()\n    class_weight_log = dict()\n\n    for key in keys:\n        score = total \/ float(labels_dict[key])\n        score_log = math.log(mu * total \/ float(labels_dict[key]))\n        class_weight[key] = round(score, 2) if score > 1.0 else round(1.0, 2)\n        class_weight_log[key] = round(score_log, 2) if score_log > 1.0 else round(1.0, 2)\n\n    return class_weight, class_weight_log\n\n# Class abundance for protein dataset\nlabels_dict = {  #[2088, 1752, 2542, 1977, 9066, 1109, 5711, 2629, 1037, 1278]\n    0: 2088,\n    1: 1752,\n    2: 2542,\n    3: 1977,\n    4: 9066,\n    5: 1109,\n    6: 5711,\n    7: 2629,\n    8: 1037,\n    9: 1278\n}\n\nprint('\\nTrue class weights:')\nprint(create_class_weight(labels_dict)[0])\nprint('\\nLog-dampened class weights:')\nprint(create_class_weight(labels_dict)[1])\n#inferred this [4,4,3,4,1,7,1,3,7,6]","50707cb3":"class Oversampling:\n    def __init__(self,path):\n        self.train_labels = pd.read_csv(path)\n        self.train_labels['Label'] = [[int(i) for i in s.split()] \n                                       for s in self.train_labels['Label']]  \n        #set the minimum number of duplicates for each class\n        self.multi = [2,2,2,2,1,3,1,2,3,2]  #{0: 1.94, 1: 2.12, 2: 1.75, 3: 2.0, 4: 1.0, 5: 2.58, 6: 1.0, 7: 1.71, 8: 2.64, 9: 2.44}\n\n    def get(self,image_id):\n        labels = self.train_labels.loc[image_id,'Label'] if image_id \\\n          in self.train_labels.index else []\n        #print(labels)\n        m = 1\n        for l in labels:\n            if m < self.multi[l]: m = self.multi[l]\n        return m\n    \ns = Oversampling(TRAIN_CSV)\n#print(s.train_labels.index)\n#tr_n = [idx for idx in tr_n for _ in range(s.get(idx))]\ntr_n = [idx for idx in traindf['Image'].values for _ in range(s.get(idx))]\nprint(len(tr_n),flush=True)","86094c28":"s = Oversampling(TRAIN_CSV)\ntr_n = [idx for idx in traindf['Image'].values for _ in range(s.get(idx))]\nprint(len(tr_n),flush=True)\nl = list(set(tr_n))\nfinallist = [i for i in tr_n if not i in l or l.remove(i)]\n\ntraindf_orig=traindf.copy()    \nfor i in finallist:\n    indicies = traindf_orig.loc[traindf_orig['Image'] == i].index\n    traindf = pd.concat([traindf,traindf_orig.loc[indicies]], ignore_index=True)\n","003a1919":"#from collections import Counter\ns = list(set(tr_n))\nfinallist = [i for i in tr_n if not i in s or s.remove(i)]\nprint(len(finallist))\n#counts = Counter(tr_n)\n#dupids = [id for id in tr_n if counts[id] > 1]\n#print(dupids)\n#len(dupids)"}}