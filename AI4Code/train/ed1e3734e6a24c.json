{"cell_type":{"7d9cfdec":"code","f941e6dc":"code","5b7466fc":"code","c0e7e6f4":"code","61e1dead":"code","50ff2846":"code","89dcc11b":"code","68b19008":"code","ec30e999":"code","eb2fea29":"code","ba8d69fc":"code","b8580c86":"code","9db5dc5e":"code","d94e2ea9":"code","bb8c45a0":"code","26d0a97b":"code","8106c28f":"code","2a4ceeb0":"code","ef0f926c":"code","b46f1d1b":"code","30f0b082":"code","13de0170":"code","79d4ca76":"code","df7167ca":"code","1570dcf6":"code","d506b8aa":"code","a99ae12a":"markdown","5a465161":"markdown","ef95e943":"markdown"},"source":{"7d9cfdec":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC \nfrom sklearn.metrics import classification_report, confusion_matrix,accuracy_score,fbeta_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import log_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dropout\nfrom keras.layers import Dense\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f941e6dc":"#Reading dataset \ndf=pd.read_csv('..\/input\/heart.csv')","5b7466fc":"# Checking first few entries of the dataset\ndf.head()","c0e7e6f4":"# looking into the summary of the dataset such as mean, standard deviation minimum and maximum values of the attributes\ndf.describe()","61e1dead":"df.isna().sum()","50ff2846":"# checking the number of observation i.e., number of rows and columns\/features\ndf.shape","89dcc11b":"df.dtypes","68b19008":"# Checking the number of disease and healthy observations \nsns.countplot(df['target'], label = \"Count\") ","ec30e999":"plt.figure(figsize=(20,10)) \nsns.heatmap(df.corr(), annot=True)","eb2fea29":"X=df.drop(['target'],axis=1)\nX.corrwith(df['target']).plot.bar(\n        figsize = (20, 10), title = \"Correlation with Target\", fontsize = 20,\n        rot = 90, grid = True)","ba8d69fc":"y = df['target']","b8580c86":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10,stratify=y, random_state=5)","9db5dc5e":"min_train = X_train.min()\nrange_train = (X_train - min_train).max()\nX_train_scaled = (X_train - min_train)\/range_train","d94e2ea9":"min_test = X_test.min()\nrange_test = (X_test - min_test).max()\nX_test_scaled = (X_test - min_test)\/range_test","bb8c45a0":"svc_model = SVC(gamma='auto')\nsvc_model.fit(X_train_scaled, y_train)","26d0a97b":"y_predict = svc_model.predict(X_test_scaled)\ncm = confusion_matrix(y_test, y_predict)","8106c28f":"sns.heatmap(cm, annot=True)","2a4ceeb0":"print(classification_report(y_test,y_predict))","ef0f926c":"param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear']} \n\ngrid = GridSearchCV(SVC(probability=True),param_grid,refit=True,verbose=4,cv=5,scoring='neg_log_loss')\ngrid.fit(X_train_scaled,y_train)","b46f1d1b":"grid.best_params_","30f0b082":"grid.best_estimator_","13de0170":"grid_predictions = grid.predict(X_test_scaled)","79d4ca76":"cm = confusion_matrix(y_test, grid_predictions)","df7167ca":"sns.heatmap(cm, annot=True)","1570dcf6":"print(classification_report(y_test,grid_predictions))","d506b8aa":"from sklearn import metrics\ny_pred=grid.predict(X_test_scaled) # predict the test data\n# Compute False postive rate, and True positive rate\nfpr, tpr, thresholds = metrics.roc_curve(y_test, grid.predict_proba(X_test_scaled)[:,1])\n# Calculate Area under the curve to display on the plot\nauc = metrics.roc_auc_score(y_test,grid.predict(X_test_scaled))\n# Now, plot the computed values\nplt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (SVC, auc))\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","a99ae12a":"Heart disease is the number one cause of death worldwide, so, in this notebook we will try to use data science for the good reason i.e., predicting heart disease.To learn how to prevent heart disease we must first learn to reliably detect it.\n\nThe dataset is from a study of heart disease that has been open to the public for many years. The study collects various measurements on patient health and cardiovascular statistics, and of course makes patient identities anonymous.\n\nData is provided courtesy of the [Cleveland Heart Disease Database](http:\/\/archive.ics.uci.edu\/ml\/datasets\/statlog+(heart)) via the **UCI Machine Learning repository**.\n\nAha, D., and Dennis Kibler. **\"Instance-based prediction of heart-disease presence with the Cleveland database.\"** University of California 3.1 (1988): 3-2.","5a465161":"# Normalization","ef95e943":"## Model Improvement - Parameter Tuning"}}