{"cell_type":{"0dd1e0eb":"code","678b222e":"code","85c2723d":"code","a691a67e":"code","397ecc53":"code","3cf02b07":"code","f588fd96":"code","e78168d0":"code","de699e76":"code","a9204684":"code","c142ba06":"code","736a0286":"code","9314283b":"code","0fd54962":"code","81257c56":"code","7e8eb663":"code","ef63db56":"markdown"},"source":{"0dd1e0eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport numpy as np\nnp.random.seed(13)\nfrom keras.datasets import mnist\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","678b222e":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n","85c2723d":"x_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nx_test = test.values.astype('float32')","a691a67e":"def draw_digit(data, row, col, n):\n    size = int(np.sqrt(data.shape[0]))\n    plt.subplot(row, col, n)    \n    plt.imshow(data.reshape(size, size))\n    plt.gray()","397ecc53":"input_unit_size = 28*28\nx_train = x_train.reshape(x_train.shape[0], input_unit_size)\nx_train = x_train.astype('float32')\nx_train \/= 255","3cf02b07":"inputs = Input(shape=(input_unit_size,))\nx = Dense(144, activation='relu')(inputs)\noutputs = Dense(input_unit_size)(x)\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss='binary_crossentropy', optimizer='adadelta')","f588fd96":"model.fit(x_train, x_train, epochs=10, batch_size=256)","e78168d0":"# raw image\nshow_size = 10\ntotal = 0\nplt.figure(figsize=(20, 20))\nfor i in range(show_size):\n    for j in range(show_size):    \n        draw_digit(x_train[total], show_size, show_size, total+1)\n        total+=1\nplt.show()","de699e76":"# hidden\nget_layer_output = K.function([model.layers[0].input],\n                              [model.layers[1].output])\n\nhidden_outputs = get_layer_output([x_train[0:show_size**2]])[0]\n\ntotal = 0\nplt.figure(figsize=(20, 20))\nfor i in range(show_size):\n    for j in range(show_size):    \n        draw_digit(hidden_outputs[total], show_size, show_size, total+1)\n        total+=1\nplt.show()","a9204684":"# reconstruct image\nget_layer_output = K.function([model.layers[0].input],\n                              [model.layers[2].output])\n\nlast_outputs = get_layer_output([x_train[0:show_size**2]])[0]\n\ntotal = 0\nplt.figure(figsize=(20, 20))\nfor i in range(show_size):\n    for j in range(show_size):    \n        draw_digit(last_outputs[total], show_size, show_size, total+1)\n        total+=1\nplt.show()","c142ba06":"encoding_dim = 32\n# Model definition\ninput_img = Input(shape=(784,))\nencoded = Dense(128, activation='relu')(input_img)\nencoded = Dense(64, activation='relu')(encoded)\n\nencoded = Dense(encoding_dim, activation='relu')(encoded)\n\ndecoded = Dense(64, activation='relu')(encoded)\ndecoded = Dense(128, activation='relu')(decoded)\ndecoded = Dense(784, activation='sigmoid')(decoded)\n","736a0286":"x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint(x_train.shape)\nprint(x_test.shape)","9314283b":"# Model compilation\nautoencoder = Model(input=input_img, output=decoded)\nautoencoder.summary()\n","0fd54962":"encoder = Model(input=input_img, output=encoded)\n# create a placeholder for an encoded (32-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\n# create the decoder model\n\ndecoder1 = autoencoder.layers[-3]\ndecoder2 = autoencoder.layers[-2]\ndecoder3 = autoencoder.layers[-1]\n\ndecoder = Model(input=encoded_input, output=decoder3(decoder2(decoder1(encoded_input))))\n\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n","81257c56":"# Model training\nautoencoder.fit(x_train, x_train,\n                nb_epoch=20,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))","7e8eb663":"# Testing\n\n# encode and decode some digits\n# note that we take them from the *test* set\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)\n\nn = 10  # how many digits we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","ef63db56":"**Deep autoencoder**\n\nThe code basically looks like this:\n\ndecoder1 = autoencoder.layers[-3] decoder2 = autoencoder.layers[-2] decoder3 = autoencoder.layers[-1]\n\ndecoder = Model(input=encoded_input, output=decoder3(decoder2(decoder1(encoded_input))))"}}