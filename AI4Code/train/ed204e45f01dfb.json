{"cell_type":{"929cdd56":"code","12e9500c":"code","c34f88e3":"code","0bbecd20":"code","9e4fd6e2":"code","4cf59767":"code","68ca7fb0":"code","105d47c2":"code","22ffb3e6":"code","e2fa50a0":"code","2f1f8add":"code","ad82e931":"code","14f07a10":"code","6cc60aa0":"code","030e9856":"code","447b8bd2":"code","f59e55dc":"markdown","e22c948a":"markdown"},"source":{"929cdd56":"# import libraries\nimport tensorflow as tf\nimport numpy as np\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\n# utilities\nfrom datetime import datetime\n# Disable warning output\nimport warnings\nwarnings.filterwarnings('ignore')","12e9500c":"class ReadCsvData(object):\n\n  def __init__(self):\n    # Read data from train dataset\n    df_train = pd.read_csv('..\/input\/train.csv')\n\n    # Read data from test dataset\n    df_test = pd.read_csv('..\/input\/test.csv')\n\n    self._train = df_train.drop(['label'], axis=1).values\n    self._labels = df_train['label'].values\n    self._test = df_test.values\n\n  def get_data(self):\n    # Convert train and test data from [0, 255] -> [0.0, 1.0]\n    self._train = self._train.astype(np.float32)\n    self._train = np.multiply(self._train, 1.0 \/ 255.0)\n    self._test = self._test.astype(np.float32)\n    self._test = np.multiply(self._test, 1.0 \/ 255.0)\n    \n    # Convert label to one-hot presenting\n    self._labels = np.identity(10)[self._labels]\n    # Return data\n    return self._train, self._labels,self._test","c34f88e3":"class DataSet(object):\n\n  def __init__(self,\n               images,\n               labels):\n    assert images.shape[0] == labels.shape[0], ('images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n    self._num_examples = images.shape[0]\n    self._images = images\n    self._labels = labels\n    self._epochs_completed = 0\n    self._index_in_epoch = 0\n\n  def next_batch(self, batch_size):\n    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n    start = self._index_in_epoch\n    self._index_in_epoch += batch_size\n    if self._index_in_epoch > self._num_examples:\n      # Finished epoch\n      self._epochs_completed += 1\n      # Shuffle the data\n      perm = np.arange(self._num_examples)\n      np.random.shuffle(perm)\n      self._images = self._images[perm]\n      self._labels = self._labels[perm]\n      # Start next epoch\n      start = 0\n      self._index_in_epoch = batch_size\n      assert batch_size <= self._num_examples\n    end = self._index_in_epoch\n    return self._images[start:end], self._labels[start:end]","0bbecd20":"# Initiate tensorflow session\nsess = tf.InteractiveSession()\n\n# placeholder\nx = tf.placeholder(tf.float32, shape=[None, 784])\ny_ = tf.placeholder(tf.float32, shape=[None, 10])\n\n# variable\nW = tf.Variable(tf.zeros([784,10]))\nb = tf.Variable(tf.zeros([10]))\n\n# weights and bias variable: 1st layer\nW_conv1 = tf.Variable(tf.truncated_normal([5, 5, 1, 50], stddev=0.1))\nb_conv1 = tf.Variable(tf.constant(0.1, shape=[50]))","9e4fd6e2":"# resharpe train data to 28*28 \n# parameter:\n# -1: number of image 28,28: size of each image 1: No. of channel\nx_image = tf.reshape(x, [-1,28,28,1])\n\n# convolutional and pool: 1st layer\nh_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\nh_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')","4cf59767":"# weights and bias variable: 2nd layer\nW_conv2 = tf.Variable(tf.truncated_normal([5, 5, 50, 100], stddev=0.1))\nb_conv2 = tf.Variable(tf.constant(0.1, shape=[100]))\n\n# convolutional and pool: 2nd layer\nh_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\nh_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')","68ca7fb0":"# FULL connection and relu: 1st layer \nW_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 100, 1024], stddev=0.1))\nb_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]))\nh_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*100])\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)","105d47c2":"# Dropout\nrate = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, 1-rate)","22ffb3e6":"# FULL connection : 2nd layer \nW_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1))\nb_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\ny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)","e2fa50a0":"# cross entropy\ncross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n\n# Train function : AdamOptimizer\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n# accuracy\ncorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n# prediction\npredict = tf.argmax(y_conv,1)","2f1f8add":"# initiate variables of tensorflow\nsess.run(tf.global_variables_initializer())","ad82e931":"# Get input data and initiate DataSet\ninput_data=ReadCsvData()\nx_train, y_label, x_test = input_data.get_data()","14f07a10":"# Start train CNN\nBatch_size=100\n# Train_NUmber:18000 rate:0.5 Kaggle Accuracy:0.99242\n# Train_NUmber:10000 rate:0.5 Kaggle Accuracy:0.99071\nTrain_Number=5300\naccracies = []","6cc60aa0":"print('Start Learning', datetime.now(),)\nfor j in range(3):\n    train_dataset = DataSet(x_train,y_label)\n    for i in range(Train_Number):\n      batch_x, batch_y = train_dataset.next_batch(Batch_size)\n      if i%100 == 0:\n        train_accuracy = accuracy.eval(feed_dict={x:batch_x, y_: batch_y, rate: 0.0})\n        accracies.append(train_accuracy)\n        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n      train_step.run(feed_dict={x: batch_x, y_: batch_y, rate: 0.5})\n\nprint(\"step %d, training accuracy %g\"%(i, train_accuracy))\nprint('Finish Learning', datetime.now(),)","030e9856":"# Show the prediction\nsubmission_file=pd.DataFrame({'ImageId':np.arange(1,(x_test.shape[0] + 1)), 'Label':predict.eval(feed_dict={x: x_test, rate: 0.0})})\nprint(submission_file)\nsubmission_file.to_csv(\"submission_v1.csv\", index=False)\nprint('Save submission', datetime.now(),)","447b8bd2":"saver = tf.train.Saver()\n# saver.save(sess, 'mnist_model')\n# saver.restore(sess, \"mnist_model\")\nsess.close()","f59e55dc":"####################################\n# Learning, Evaluating and Predicting\n####################################","e22c948a":"# Overview\nThis kernel is using CNN(Convolutional Neural Network) based on tensorflow.\nTensorflow provides low-level API and high-level API(keras).\nThe low-level APIs are used in this kernel for practice purpose. \nIt implemented a typical multiple layers CNN as the following from left to right.\nconvolutional - pooling - convolutional - pooling - FULL connection - relu - dropout FULL connection - result"}}