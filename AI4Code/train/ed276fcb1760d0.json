{"cell_type":{"0c8ab4cb":"code","b396f326":"code","df70d732":"code","375d9573":"code","59aaab7d":"code","8dbbc536":"code","b7fcde1c":"code","d4726407":"code","66bb2edc":"code","c0d6a8bb":"code","6ab85222":"code","5bc785e5":"code","c3992e89":"code","b0a5e3e4":"code","f8fc0234":"code","443600b9":"code","9ee516f8":"code","0fdddab6":"code","275dbece":"code","ac894f4c":"code","8ddf775a":"code","d8cff0cb":"code","e183b22d":"code","0b3be442":"code","67b917b1":"code","e08dd28e":"code","031c9ee9":"code","4167cd17":"code","927a6bbd":"code","f59eda31":"code","b99fb324":"code","0c24d010":"code","7a80d59f":"markdown","a7341f90":"markdown"},"source":{"0c8ab4cb":"import numpy as np\nimport pandas as pd\nimport pickle\nimport tensorflow as tf\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nprint(tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(filename)","b396f326":"# Load data\ntrain_df = pd.read_csv('\/kaggle\/input\/hate-speech-detection\/toxic_train.csv')\ntrain_df.head()","df70d732":"train_df.sample(10,random_state=1)","375d9573":"x = train_df['comment_text']\ny = train_df['toxic']","59aaab7d":"# View some toxic comments\ntrain_df[train_df.toxic==1].sample(5)","8dbbc536":"comments = train_df['comment_text'].loc[train_df['toxic']==1].values\nwordcloud = WordCloud(\n    width = 640,\n    height = 640,\n    background_color = 'black',\n    stopwords = STOPWORDS).generate(str(comments))\nfig = plt.figure(\n    figsize = (12, 8),\n    facecolor = 'k',\n    edgecolor = 'k')\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","b7fcde1c":"# Plot frequency of toxic comments\nfig = sns.distplot(train_df['toxic'], kde=False)\nplt.xlabel(\"Toxicity Label\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Toxic Comments\")\nplt.show(fig)","d4726407":"train_df['toxic'].value_counts()","66bb2edc":"\nmax_features = 20000\nmax_text_length = 400","c0d6a8bb":"x_tokenizer = text.Tokenizer(max_features)\nx_tokenizer.fit_on_texts(list(x))","6ab85222":"# Save tokenizer for future use\nwith open('toxic_tokenizer.pkl', 'wb') as f:\n    pickle.dump(x_tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)","5bc785e5":"x_tokenized = x_tokenizer.texts_to_sequences(x)\nx_train_val= sequence.pad_sequences(x_tokenized, maxlen=max_text_length)","c3992e89":"embedding_dim =100\nembeddings_index = dict()\nf = open('\/kaggle\/input\/glove6b100dtxt\/glove.6B.100d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:],dtype='float32')\n    embeddings_index[word]= coefs\nf.close()\nprint(f'Found {len(embeddings_index)} word vectors')","b0a5e3e4":"embedding_matrix= np.zeros((max_features,embedding_dim))\nfor word, index in x_tokenizer.word_index.items():\n    if index>max_features-1:\n        break\n    else:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index]= embedding_vector","f8fc0234":"filters= 250\nkernel_size=3\nhidden_dims= 250","443600b9":"model = Sequential()\nmodel.add(Embedding(max_features,\n                    embedding_dim,\n                    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n                    trainable=False))\nmodel.add(Dropout(0.2))\nmodel.add(Conv1D(filters,\n                 kernel_size,\n                 padding='valid',\n                 activation='relu'))\nmodel.add(MaxPooling1D())\nmodel.add(Conv1D(filters,\n                 5,\n                 padding='valid',\n                 activation='relu'))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(hidden_dims, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","9ee516f8":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","0fdddab6":"x_train,x_val,y_train,y_val = train_test_split(x_train_val,y,test_size=0.3,random_state=1)","275dbece":"batch_size= 32\nepochs = 3\nhist = model.fit(x_train,y_train,\n                    batch_size= batch_size,\n                    epochs=epochs,\n                    validation_data= (x_val,y_val))","ac894f4c":"# Plot loss\nplt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training loss vs. Epochs')\nplt.legend()\nplt.show()","8ddf775a":"# Plot accuracy\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training accuracy vs. Epochs')\nplt.legend()\nplt.show()","d8cff0cb":"test_df = pd.read_csv('\/kaggle\/input\/hate-speech-detection\/toxic_test.csv')","e183b22d":"x_test = test_df['comment_text'].values\ny_test = test_df['toxic'].values","0b3be442":"x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\nx_testing = sequence.pad_sequences(x_test_tokenized,maxlen=max_text_length)","67b917b1":"y_pred = model.predict(x_testing,verbose=1,batch_size=32)","e08dd28e":"y_pred = [0 if y[0] < 0.5 else 1 for y in y_pred]","031c9ee9":"print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))","4167cd17":"print(\"F1 Score: {:.6f}\".format(f1_score(y_test, y_pred, average='macro')))","927a6bbd":"cm = confusion_matrix(y_test, y_pred)\nfig = sns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show(fig)","f59eda31":"test_df['prediction'] = [ 'not toxic' if y == 0 else 'toxic' for y in y_pred]","b99fb324":"test_df.head(20)","0c24d010":"model.save('toxic_cnn.h5')","7a80d59f":"# Building Model","a7341f90":"# Compiling the Model"}}