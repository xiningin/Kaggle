{"cell_type":{"f4d8de55":"code","f9de02ed":"code","583cc962":"code","a64bf6b5":"code","fa4091e9":"code","5f8468ab":"code","34064694":"code","6cf87528":"code","a9efa096":"code","d6576d16":"code","c91542a4":"code","40e64711":"code","4b13504e":"code","a40a7de9":"code","a53cb6ca":"code","7a7e0eed":"code","4b9dff59":"code","d98c37bb":"code","e9a7b3b4":"code","ab1fed70":"code","b06d4b46":"code","7a5474f4":"code","10c7c20b":"code","42de8175":"code","b847ee3c":"code","bdc11eb9":"code","c6eb2b9b":"code","9b848340":"code","19c5bb08":"code","d3d9cb08":"code","0ecc2336":"code","31757b40":"code","5eaf1b89":"code","19e727f9":"code","18777f4a":"code","9db76277":"code","8da3d5d0":"code","75afcef5":"code","360198a2":"code","d51ae58b":"code","9528f296":"code","dedc308f":"code","5515a246":"code","178bde35":"code","2da4f155":"code","b73bce1b":"code","df544e6c":"code","9089d13e":"code","243c769d":"code","590ed6c6":"code","88a3e3a1":"code","3f01be7e":"code","2ef614a1":"code","8055cbfb":"code","4621e3a1":"code","79c216dd":"code","95eb51bb":"code","37d24d92":"code","29b7fc01":"markdown","cf626b4e":"markdown","4e744141":"markdown","d0716541":"markdown","80d8323b":"markdown","80df408d":"markdown","a18a31e3":"markdown","6c229cf5":"markdown","9aaada2d":"markdown"},"source":{"f4d8de55":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f9de02ed":"# Import libraries\nimport pandas as pd\npd.set_option(\"display.max_rows\",200)\npd.set_option(\"display.max_columns\",200)\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nfrom scipy import stats\n","583cc962":"# Import train and test datasets and check lengths\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\nprint(len(df_train),len(df_test))","a64bf6b5":"# Check the 1st 5 rows\ndf_train.head()","fa4091e9":"df_test.head()\n# We have to predict the Survived column (Target)","5f8468ab":"df_train.info()\n# Have to change columns with object values to numerical values\n","34064694":"# Explore the features in the df_train set\n# Should drop Name from train but check to see if\n# names have any significance, perhaps an honorific implies a higher survival chance?\n\nplt.subplot(2,2,1)\ndf_train[df_train['Name'].str.contains('Mr. ')]['Survived'].value_counts().plot(kind='bar',\\\n                                                                               title='Survived by Mr')\n\n\nplt.xticks(rotation=0);\n\nplt.subplot(2,2,2)\ndf_train[df_train['Name'].str.contains('Mrs. ')]['Survived'].value_counts().plot(kind='bar',\\\n                                                                                title=\\\n                                                                        'Survived by Mrs');\n\nplt.xticks(rotation=0);\n\nplt.subplot(2,2,3)\ndf_train[df_train['Name'].str.contains('Miss. ')]['Survived'].value_counts().plot(kind='bar',\\\n                                                                    title='Survived by Miss');\n\nplt.xticks(rotation=0);\n\nplt.subplot(2,2,4)\ndf_train[df_train['Name'].str.contains('Master. ')]['Survived'].value_counts().plot(kind='bar',\\\n                                                            title='Survived by Master');\nplt.tight_layout()\nplt.xticks(rotation=0);","6cf87528":"\nlen(df_train[df_train['Name'].str.contains('Dr. ')])","a9efa096":"len(df_train[df_train['Name'].str.contains('Sir. ')])","d6576d16":"len(df_train[df_train['Cabin'].isnull()])\n# Since most of the values for Cabin are null we can safely drop it","c91542a4":"# Drop columns that we won't use as features from train and test\ndf_train.drop(['Name','PassengerId','Ticket','Cabin'],axis=1,inplace=True)\ndf_train.head()","40e64711":"# Exploring features\n# 1. Embarked\n\n# Any missing values?\ndf_train[df_train['Embarked'].isnull()]","4b13504e":"df_train['Embarked'].unique()","a40a7de9":"\ndf_train['Embarked'].value_counts()","a53cb6ca":"# So the port S is most common, so it would make sense to fill in\n# the missing values with 'S'\ndf_train['Embarked'].fillna('S',inplace=True)\ndf_train[df_train['Embarked'].isnull()]","7a7e0eed":"# Check survival rates by port of embarkation\nsns.factorplot('Embarked','Survived',data=df_train,aspect=3);\n# Port C has highest Survival Rate, so a case could be made for \n# filling in missing Embarked vals with 'C' instead of 'S'","4b9dff59":"# More checks on dependence of survival on embarkation port\nfig,(axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\nsns.countplot(x='Embarked',data=df_train,ax=axis1);\nsns.countplot(x='Survived',hue='Embarked',data=df_train,order=[0,1],ax=axis2);\n# Plot mean survival rate for each port of embarkation\nembark_grp_mean = df_train[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean()\nsns.barplot(x='Embarked',y='Survived',data=embark_grp_mean,order=['S','C','Q'],ax=axis3);","d98c37bb":"# Get unique vals of embarked\nembarked_vals = sorted(df_train['Embarked'].unique())\n# Generate mapping of embarked from strings to numbers\nembarked_map = dict(zip(embarked_vals,range(0,len(embarked_vals)+1)))\nembarked_map","e9a7b3b4":"\n# A numerical ordering for Embarked makes no sense\n# so change this to dummy variables instead\ndf_train = pd.concat([df_train,pd.get_dummies(df_train['Embarked'],prefix='Embarked')],axis=1)\ndf_train.drop('Embarked',axis=1,inplace=True)\ndf_train.head()","ab1fed70":"\n# Check passenger class and sex based on embarkation port\nplt.subplot(2,1,1)\ndf_train[df_train['Embarked_C']==1.0]['Sex'].value_counts().plot(kind='bar',\\\n                                                                title='Cherbourg')\nplt.xticks(rotation=0);\nplt.subplot(2,1,2)\ndf_train[df_train['Embarked_C']==1.0]['Pclass'].value_counts().plot(kind='bar')\n                                                                \nplt.xticks(rotation=0);","b06d4b46":"# Check passenger class and sex based on embarkation port\nplt.subplot(2,1,1)\ndf_train[df_train['Embarked_Q']==1.0]['Sex'].value_counts().plot(kind='bar',\\\n                                                                title='Queenstown')\nplt.xticks(rotation=0);\nplt.subplot(2,1,2)\ndf_train[df_train['Embarked_Q']==1.0]['Pclass'].value_counts().plot(kind='bar')\n                                                                \nplt.xticks(rotation=0);","7a5474f4":"\n# Check passenger class and sex based on embarkation port\nplt.subplot(2,1,1)\ndf_train[df_train['Embarked_S']==1.0]['Sex'].value_counts().plot(kind='bar',\\\n                                                                title='Southampton')\nplt.xticks(rotation=0);\nplt.subplot(2,1,2)\ndf_train[df_train['Embarked_S']==1.0]['Pclass'].value_counts().plot(kind='bar')\n                                                                \nplt.xticks(rotation=0);","10c7c20b":"\n# Exploring features\n# 2. Fare\n\n# Check for null values\ndf_train[df_train['Fare'].isnull()]","42de8175":"# Look at relationship between Fare and survival rate\n\nfare_notsurv = df_train[df_train['Survived']==0]['Fare'] #Fare of passengers who didn't survive\nfare_surv = df_train[df_train['Survived']==1]['Fare'] #Fare of passengers who survived\nmax_fare = df_train['Fare'].max()\nplt.hist([fare_notsurv,fare_surv],stacked=True,bins=int(max_fare\/50),range=(1,max_fare));\nplt.xlabel('Fare');plt.ylabel('Count');\nplt.legend(['Dead','Survived'],loc='best');","b847ee3c":"\navg_fare = pd.DataFrame([fare_notsurv.mean(),fare_surv.mean()])\nstd_fare = pd.DataFrame([fare_notsurv.std(),fare_surv.std()])\nprint(\"Mean fare for not survived is {} and survived is {}\".format(fare_notsurv.mean(),\\\n                                                                   fare_surv.mean()))","bdc11eb9":"avg_fare.plot(yerr=std_fare,kind='bar',legend=None)\nplt.ylabel('Fare')\nplt.xlabel('Survived')\nplt.xticks(rotation=0);","c6eb2b9b":"#Exploring features\n#3. Age\n\nfig,(axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\naxis1.set_title('Original age values')\naxis2.set_title('New age values')\n\ndf_train['Age'].dropna().hist(bins=70,ax=axis1);\n# The age distribution seems skewed, so using median value to fillna\ndf_train['Age'].fillna(df_train['Age'].dropna().median(),inplace=True)\ndf_train['Age'].hist(bins=70,ax=axis2);\n# Basic nature of distribution seems to be unchanged; this statement can be investigated","9b848340":"df_train[df_train['Age'].isnull()]","19c5bb08":"# Look at relationship between Age and survival rate\n\nage_notsurv = df_train[df_train['Survived']==0]['Age'] #Fare of passengers who didn't survive\nage_surv = df_train[df_train['Survived']==1]['Age'] #Age of passengers who survived\nmax_age = df_train['Age'].max()\nplt.hist([age_notsurv,age_surv],stacked=True,bins=int(max_age\/10),range=(1,max_age));\nplt.xlabel('Age');plt.ylabel('Count');\nplt.legend(['Dead','Survived'],loc='best');","d3d9cb08":"\navg_age = pd.DataFrame([age_notsurv.mean(),age_surv.mean()])\nstd_age = pd.DataFrame([age_notsurv.std(),age_surv.std()])\nprint(\"Mean age for not survived is {} and survived is {}\".format(age_notsurv.mean(),\\\n                                                                   age_surv.mean()))","0ecc2336":"\navg_age.plot(yerr=std_age,kind='bar',legend=None)\nplt.ylabel('Age')\nplt.xlabel('Survived')\nplt.xticks(rotation=0);\n# Hard to tell a dependency from this plot","31757b40":"# Check age dependencies and survival of various other features\ndf_train_survived = df_train[df_train['Survived']==1]\n\nplt.subplot(2,2,1)\ndf_train_survived['Age'].hist(bins=int(max_age\/10),range=(1,max_age))\nplt.title('Age of survivors')\n\nplt.subplot(2,2,2)\ndf_train_survived[df_train_survived['Sex']=='female']['Age'].hist(bins=int(max_age\/10),range=(1,max_age))\nplt.title('Age of female survivors')\n\nplt.subplot(2,2,3)\ndf_train_survived[df_train_survived['Pclass']==1]['Age'].hist(bins=int(max_age\/10),range=(1,max_age))\nplt.title('Age of 1st class passengers who survived')\n\nplt.subplot(2,2,4)\ndf_train_survived[df_train_survived['Fare']>50]['Age'].hist(bins=int(max_age\/10),range=(1,max_age))\nplt.title('Age of survivors who paid > 50 fare')\nplt.tight_layout()\n\n# In all cases, most survivors seem to be between 20 and 30 years of age","5eaf1b89":"\npassenger_classes = sorted(df_train['Pclass'].unique())\nfor p in passenger_classes:\n    df_train[df_train['Pclass']==p]['Age'].plot(kind='kde')\nplt.title('Age density by passenger class')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.legend(('1st class','2nd class','3rd class'),loc='best');\n# 1st class passengers tend to be the oldest","19e727f9":"\nfor p in passenger_classes:\n    df_train_survived[df_train_survived['Pclass']==p]['Age'].plot(kind='kde')\nplt.title('Age density by passenger class (survivors)')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.legend(('1st class','2nd class','3rd class'),loc='best');\n# Difference between this and above plot seems most marked for 2nd and 3rd class passengers","18777f4a":"# Exploring features\n# 4. Family\n\n# Create one family column\ndf_train['Family'] = df_train['Parch'] + df_train['SibSp']\ndf_train.drop(['Parch','SibSp'],axis=1,inplace=True)","9db76277":"# Make family a categorical variable, family member present = 1, else = 0\ndf_train['Family'].loc[df_train['Family']>1]=1\ndf_train['Family'].loc[df_train['Family']==0]=0\ndf_train['Family'].value_counts()","8da3d5d0":"family_surv = df_train[['Family','Survived']].groupby(['Family'],as_index=False).mean()\nax=sns.barplot(x='Family',y='Survived',data=family_surv,order=[1,0])\nax.set_xticklabels(['With family','No family'],rotation=0);","75afcef5":"\n# Exploring features\n# 5. Sex\n\n# 'Women' and 'children' first so divide into male, female and child categories (child age is < 12)\n\ndef get_person(passenger):\n    age,sex=passenger\n    return 'child' if age < 12 else sex\n\ndf_train['Person'] = df_train[['Age','Sex']].apply(get_person,axis=1)\ndf_train.drop('Sex',axis=1,inplace=True)","360198a2":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n\nsns.countplot(x='Person',data=df_train,ax=ax1)\n\n# Mean survival rate for male, female, child\nperson_mean = df_train[['Person','Survived']].groupby(['Person'],as_index=False).mean()\nsns.barplot(x='Person',y='Survived',data=person_mean,ax=ax2,order=['male','female','child']);\n# As we would expect, females and children have a high rate of survival","d51ae58b":"# Make 'Person' a categorical variable\ndf_train = pd.concat([df_train,pd.get_dummies(df_train['Person'],prefix='Person')],axis=1)\ndf_train.drop(['Person'],axis=1,inplace=True)","9528f296":"# Exploring features\n# 6. Passenger Class\n\nsns.factorplot(x='Pclass',y='Survived',data=df_train,order=[1,2,3],size=5,aspect=3);\n# Very high survival rate for first class passengers, Pclass is definitely important for survival predictions","dedc308f":"df_train.head()","5515a246":"df_train.info()\n# All columns now have numeric entries","178bde35":"# Go through all the formatting steps for the test data set\n\ndf_test.drop(['Name','Ticket','Cabin'],axis=1,inplace=True) #Can't drop PassengerId here, has to be associated \n#  to binary survival output\n\ndf_test['Embarked'].fillna('S',inplace=True)\ndf_test = pd.concat([df_test,pd.get_dummies(df_test['Embarked'],prefix='Embarked')],axis=1)\ndf_test.drop('Embarked',axis=1,inplace=True)\n\ndf_test['Fare'].fillna(df_test['Fare'].mean(),inplace=True)\n\ndf_test['Age'].fillna(df_test['Age'].dropna().median(),inplace=True)\n\ndf_test['Family'] = df_test['Parch'] + df_test['SibSp']\ndf_test.drop(['Parch','SibSp'],axis=1,inplace=True)\ndf_test['Family'].loc[df_test['Family']>1]=1\ndf_test['Family'].loc[df_test['Family']==0]=0\n\ndef get_person(passenger):\n    age,sex=passenger\n    return 'child' if age < 12 else sex\ndf_test['Person'] = df_test[['Age','Sex']].apply(get_person,axis=1)\ndf_test.drop('Sex',axis=1,inplace=True)\ndf_test = pd.concat([df_test,pd.get_dummies(df_test['Person'],prefix='Person')],axis=1)\ndf_test.drop(['Person'],axis=1,inplace=True)\n\ndf_test.head()","2da4f155":"# Define training and testing sets\n\nfeatures_train = df_train.drop(['Survived'],axis=1) #Train_features\ntarget_train= df_train['Survived'] #Train_target\n\nfeatures_test = df_test.drop(['PassengerId'],axis=1) #Test_feature","b73bce1b":"from sklearn import metrics\nfrom sklearn.model_selection import train_test_split, GridSearchCV\ntrain_x,test_x,train_y,test_y = train_test_split(features_train,target_train,test_size=0.2,random_state=42)\n#train test split for evaluating model accuracy","df544e6c":"# 1. Gaussian NB\nfrom sklearn.naive_bayes import GaussianNB\nclf_nb = GaussianNB()\nclf_nb.fit(features_train,target_train)\ntarget_test_nb = clf_nb.predict(features_test)","9089d13e":"df_test['Survived'] = target_test_nb\ndf_test[['PassengerId','Survived']].to_csv('gaussnb-kaggle.csv',index=False) #Kaggle Submission","243c769d":"# Evaluate model accuracy\nclf_nb.fit(train_x,train_y)\npred_gnb_y = clf_nb.predict(test_x)\nprint('Accuracy score of Gaussian NB is {}'.format(metrics.accuracy_score(pred_gnb_y,test_y)))","590ed6c6":"# 2. SVM\nfrom sklearn.svm import SVC\nsvc = SVC(kernel='rbf',class_weight='balanced')\nparam_grid_svm = {'C': [1, 5, 10, 50,100],\n              'gamma': [0.0001, 0.0005, 0.001, 0.005,0.01]}\ngrid_svm = GridSearchCV(estimator=svc, param_grid=param_grid_svm)\ngrid_svm.fit(train_x,train_y)\ngrid_svm.best_params_","88a3e3a1":"clf_svm = grid_svm.best_estimator_\nclf_svm.fit(features_train,target_train)\ntarget_test_svm = clf_svm.predict(features_test)","3f01be7e":"df_test['Survived'] = target_test_svm\ndf_test[['PassengerId','Survived']].to_csv('svm-kaggle.csv',index=False) #Kaggle Submission","2ef614a1":"#Evaluate model accuracy\nclf_svm.fit(train_x,train_y)\npred_svm_y = clf_svm.predict(test_x)\nprint('Accuracy score of SVM is {}'.format(metrics.accuracy_score(pred_svm_y,test_y)))","8055cbfb":"# 3. RF\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(criterion='entropy')\nparam_grid_rf = {'n_estimators':[10,100,250,500,1000],\n               'max_features':['sqrt','log2'],'min_samples_split':[2,5,10,50,100]}\ngrid_rf = GridSearchCV(estimator=rf,param_grid=param_grid_rf)\ngrid_rf.fit(train_x,train_y)\ngrid_rf.best_params_","4621e3a1":"clf_rf = grid_rf.best_estimator_\nclf_rf.fit(features_train,target_train)\ntarget_test_rf = clf_rf.predict(features_test)","79c216dd":"df_test['Survived'] = target_test_rf\ndf_test[['PassengerId','Survived']].to_csv('rf-kaggle.csv',index=False) #Kaggle Submission","95eb51bb":"#Evaluate model accuracy\nclf_rf.fit(train_x,train_y)\npred_rf_y = clf_rf.predict(test_x)\nprint('Accuracy score of RF is {}'.format(metrics.accuracy_score(pred_rf_y,test_y)))","37d24d92":"### Try out a basic averaging\n\ntarget_avg = 0.2 * target_test_nb + 0.3 * target_test_svm + 0.5 * target_test_rf\ndf_test['Survived'] = target_test_rf\ndf_test[['PassengerId','Survived']].to_csv('avg-kaggle.csv',index=False) #Kaggle Submission","29b7fc01":"So Cherbourg, which has the highest mean survival rate of passengers, has a high percentage of 1st class passengers.","cf626b4e":"\nSo there is a definite correlation between fare and survival rate","4e744141":"\nNow we have the training and testing sets to try out different machine learning classification algorithms for Kagg","d0716541":"## Hope that helps! ","80d8323b":"## I used this competiton as my introduction to Kaggle quite a long time ago. I just found my notes on Github and decided to make this a kernel, which will hopefully help other beginners get started with this competition. \n\n### I've left the comments as they were when I first wrote this notebook, so they can be quite rudimentary sometimes. ","80df408d":"\nThe port of embarkation definitely seems like a factor for survival, though logically why would this be? Perhaps more first class passengers (higher fare) or more women embarked from 'C' (Cherbourg)? Needs investigation.","a18a31e3":"Age definitely affects survival rate. We already know of the women and children first policy. Older people were also more likely to survive since they were more likely to be 1st class passengers.","6c229cf5":"\nSo we see that it doesn't make sense to look for a relationship between honorifics\/titles and survival rate. The distinction between Mr. Miss. Mrs. and Master. will show up in the gender classification, as well as the age. There is not enough data for other titles such as Dr. and Sir. for that to be of significance.","9aaada2d":"\nSo the presence of a family seems to indicate a higher probability of survival. Why? Perhaps because children would be more likely to belong to a family, and children have a higher survival rate"}}