{"cell_type":{"0df8ef91":"code","01207ecf":"code","00173b55":"code","8a371107":"code","c32e8118":"code","fb59bc27":"code","5c180197":"code","21efa39c":"code","fd8510e3":"code","8dce26ff":"code","2d502538":"code","d3c57e87":"code","263cb7ca":"code","800e7bc6":"code","8fc06641":"code","2bfec8fd":"code","76f15bd1":"code","2f5ba768":"code","348ef50b":"code","a1a637b3":"code","64aea14b":"code","be51e6eb":"code","9d0d7059":"code","3fee7b47":"code","e70b4d28":"code","5edf6dbf":"code","ef1764be":"code","01feaa8a":"markdown","caeef283":"markdown","cca9adb4":"markdown","8100140b":"markdown","51a01ab9":"markdown","6c407510":"markdown","123fccdd":"markdown","c4cbcec0":"markdown","a3a159f4":"markdown","be0c48c8":"markdown","156900a7":"markdown","da5b8923":"markdown","57138427":"markdown","4e41a78e":"markdown","0d5ee842":"markdown"},"source":{"0df8ef91":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport glob","01207ecf":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","00173b55":"IMAGE_SIZE = 224","8a371107":"img_dir = \"..\/input\/car-plate-detection\/images\" # Enter Directory of all images \ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\nfiles.sort() #We sort the images in alphabetical order to match them to the xml files containing the annotations of the bounding boxes\nX=[]\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    X.append(np.array(img))\n    ","c32e8118":"from lxml import etree\ndef resizeannotation(f):\n    tree = etree.parse(f)\n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n    for dim in tree.xpath(\"object\/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text)\/(width\/IMAGE_SIZE)\n        ymin = int(dim.xpath(\"ymin\")[0].text)\/(height\/IMAGE_SIZE)\n        xmax = int(dim.xpath(\"xmax\")[0].text)\/(width\/IMAGE_SIZE)\n        ymax = int(dim.xpath(\"ymax\")[0].text)\/(height\/IMAGE_SIZE)\n    return [int(xmax), int(ymax), int(xmin), int(ymin)]\n        ","fb59bc27":"path = '..\/input\/car-plate-detection\/annotations'\ntext_files = ['..\/input\/car-plate-detection\/annotations\/'+f for f in sorted(os.listdir(path))]\ny=[]\nfor i in text_files:\n    y.append(resizeannotation(i))","5c180197":"resizeannotation(\"\/kaggle\/input\/car-plate-detection\/annotations\/Cars147.xml\")","21efa39c":"y[0]","fd8510e3":"np.array(X).shape","8dce26ff":"np.array(y).shape","2d502538":"plt.figure(figsize=(10,20))\nfor i in range(0,17) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(X[i])","d3c57e87":"#Example with the first image of the dataset\nimage = cv2.rectangle(X[0],(y[0][0],y[0][1]),(y[0][2],y[0][3]),(0, 0, 255))\nplt.imshow(image)\nplt.show()\n","263cb7ca":"#Example with the second image of the dataset\nimage = cv2.rectangle(X[1],(y[1][0],y[1][1]),(y[1][2],y[1][3]),(0, 0, 255))\nplt.imshow(image)\nplt.show()\n","800e7bc6":"#Transforming in array\nX=np.array(X)\ny=np.array(y)","8fc06641":"#Renormalisation\nX = X \/ 255\ny = y \/ 255","2bfec8fd":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)","76f15bd1":"from keras.models import Sequential\n\nfrom keras.layers import Dense, Flatten\n\nfrom keras.applications.vgg16 import VGG16","2f5ba768":"# Create the model\nmodel = Sequential()\nmodel.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"sigmoid\"))\n\nmodel.layers[-6].trainable = False\n\nmodel.summary()","348ef50b":"model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","a1a637b3":"train = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=32, verbose=1)","64aea14b":"model.save('my_model.h5', overwrite=True) ","be51e6eb":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","9d0d7059":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","3fee7b47":"plot_scores(train)","e70b4d28":"test_loss, test_accuracy = model.evaluate(X_test, y_test,steps=int(100))\n\nprint(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)\n","5edf6dbf":" y_cnn = model.predict(X_test)","ef1764be":"plt.figure(figsize=(20,40))\nfor i in range(0,43) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    ny = y_cnn[i]*255\n    image = cv2.rectangle(X_test[i],(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    plt.imshow(image)\n\n","01feaa8a":"We prepare the data for the CNN :","caeef283":"![image.png](attachment:image.png)","cca9adb4":"We can draw the rectangle containing the license plate using the OpenCV library","8100140b":"This dataset contains 433 images with bounding box annotations of the car license plates within the image. Our goal here is to train a convolutional neural network capable of locating licenses plate on new images. ","51a01ab9":"And we display the first eighteen image of the dataset : ","6c407510":"We create the variable y containing all the bounding boxe annotations (label). \nBefore that, we will have to resize the annotations so that it fits the new size of the images (200*200). We create a function resizeannotation for that. ","123fccdd":"## Convolutionnal Neural Network","c4cbcec0":"We create the variable X containing all the images of cars by resizing them.\n\n","a3a159f4":"We can see how our model localize license plates on our testing set :","be0c48c8":"Import libraries","156900a7":"We display the files in Kaggle repertoire :","da5b8923":"We split our dataset in two : training set\/testing set","57138427":"## DETECTION ","4e41a78e":"## Preparation of the data","0d5ee842":"We check X et y shape"}}