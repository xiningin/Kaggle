{"cell_type":{"821afcff":"code","920939eb":"code","cc709ab0":"code","b876f8dd":"code","8c373fbc":"code","5a3dc729":"code","da215c7a":"code","f5e5c82c":"code","d4100bda":"code","caf551f7":"code","d5291b35":"code","00d28df4":"code","52daf51c":"code","8c9eff46":"code","3bd3a3e9":"code","77e3ee66":"markdown","b0214b18":"markdown","43f60588":"markdown","342cf878":"markdown","7ccb93a8":"markdown","818e6931":"markdown","72e6b1b0":"markdown","62f18a06":"markdown","965d828d":"markdown","7d6b0981":"markdown","91769d49":"markdown","7050d056":"markdown"},"source":{"821afcff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","920939eb":"!unzip ..\/input\/train.zip","cc709ab0":"from skimage import io \n\nimage = io.imread(\"train\/0011485b40695e9138e92d0b3fb55128.jpg\")\nio.imshow(image)","b876f8dd":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport keras.backend as K\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Dropout, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import layer_utils\nfrom keras.applications import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.callbacks import History, ModelCheckpoint, Callback\nfrom sklearn.metrics import roc_auc_score","8c373fbc":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntrain_df.head()","5a3dc729":"train_df[\"has_cactus\"].value_counts()","da215c7a":"datagen = ImageDataGenerator(rescale=1\/255.0)\ntrain_dir = \"train\/\"\nbatch_size = 64\nimage_size = 32\ntrain_df.has_cactus = train_df.has_cactus.astype(str)\ntrain_generator = datagen.flow_from_dataframe(dataframe=train_df[:14001],directory=train_dir,x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                           target_size=(image_size,image_size))\n\n\nvalidation_generator = datagen.flow_from_dataframe(dataframe=train_df[14001:],directory=train_dir,x_col='id',\n                                                y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                target_size=(image_size,image_size))","f5e5c82c":"num_classes=1\n\ndef get_model():\n    \n    # Get base model: ResNet 50 - don't include the last set of layers dense and FC\n    base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(32, 32, 3))\n    \n    # Freeze the layers in base model\n    for layer in base_model.layers:\n        layer.trainable = True\n        \n    # Get output from base model\n    base_model_output = base_model.output\n    \n    # Add our layers of Dense and FC at the end\n    \n    # FC layer and softmax\n    last_layers = Flatten()(base_model_output)\n    last_layers = Dense(512,activation='relu')(last_layers)\n    last_layers = Dense(num_classes,activation='sigmoid',name='fcnew')(last_layers)\n    \n    model = Model(inputs=base_model.input,outputs=last_layers)\n    return model","d4100bda":"model = get_model()\noptimizer = optimizers.adam(lr=0.0001)\nmodel.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\nmodel.summary()","caf551f7":"class Loss(Callback):    \n    def on_train_begin(self, logs={}):\n        self.losses = []\n        logs['val_auc'] = 0\n            \n    def on_epoch_begin(self, epoch, logs={}):\n        return\n    \n    def on_epoch_end(self, epoch, logs={}):\n        self.losses.append(logs['loss'])\n        \n        y_p = []\n        y_v = []\n        for i in range(len(validation_generator)):\n            x_val, y_val = validation_generator[i]\n            y_pred = self.model.predict(x_val)\n            y_p.append(y_pred)\n            y_v.append(y_val)\n        y_p = np.concatenate(y_p)\n        y_v = np.concatenate(y_v)\n        roc_auc = roc_auc_score(y_v, y_p)\n        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n        logs['val_auc']=roc_auc","d5291b35":"epochs = 10\n\nloss = Loss()\ncheckpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min', period=1)\nhistory = model.fit_generator(train_generator,\n                    steps_per_epoch=train_generator.n\/\/batch_size,\n                   validation_data=validation_generator,\n                   validation_steps=validation_generator.n\/\/batch_size,\n                   epochs=epochs,\n                   callbacks=[loss,checkpoint]\n    )\n","00d28df4":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title(\"Accuracy for every epoch\")\nplt.xlabel('epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train','validation'],loc='lower right')\nplt.show()","52daf51c":"val_model = get_model()\nval_model.load_weights('best_model.hdf5')","8c9eff46":"import os\ntest_dir = \"..\/input\/test\/test\/\"\ntest_df=pd.read_csv(\"..\/input\/sample_submission.csv\")\nfor _ , _, files in os.walk(test_dir):\n    i=0\n    for file in files:\n        image=io.imread(os.path.join(test_dir, file))\n        test_df.iloc[i,0]=file\n        image=image.astype(np.float32)\/255.0\n        test_df.iloc[i,1]=val_model.predict(image.reshape((1, 32, 32, 3)))[0][0]\n        i+=1","3bd3a3e9":"test_df.to_csv(\"sample_submission.csv\",index=False)","77e3ee66":"## Predict on test data and submit predictions","b0214b18":"## Plot accuracy for every epoch","43f60588":"## Import necessary libraries","342cf878":"## Read the data from train.csv","7ccb93a8":"## Unzipping train dataset","818e6931":"## Visualizing an image from train dataset","72e6b1b0":"### Exploratory Data Analysis","62f18a06":"## Fit Generator","965d828d":"## Add callback functions for loss & AUC","7d6b0981":"## Compiling the model","91769d49":"## Model creation using Resnet50 with trainable parameter True","7050d056":"## Create Image Data Generators for train and validation"}}