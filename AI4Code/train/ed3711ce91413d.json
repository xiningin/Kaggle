{"cell_type":{"7a677668":"code","25496d19":"code","c4bdd599":"code","1866a969":"code","ac07b156":"code","c2232531":"code","82686725":"code","653e14cc":"code","e01a12c0":"code","a576aa8e":"code","5c70e3b5":"code","8bc84bfd":"code","debdf7d2":"code","fbf27318":"code","082610f1":"code","0c3b3349":"code","f7b42ba8":"code","0e72178a":"code","3b27aba0":"code","703771b2":"code","bcf2904a":"code","b24dd593":"code","bad188cd":"code","ff483735":"code","b7f6c536":"code","2cc061b4":"code","95e3f6ad":"code","2bece1a9":"code","5a656a93":"code","08a36e39":"code","484b5b4d":"code","b07c15ef":"code","3ad3a0f2":"code","71947f68":"code","d7a95713":"code","ca378883":"code","38e3a9c0":"code","d1c202b5":"code","0282a753":"code","c7eb5cfa":"code","d4dbe315":"code","9e47b1e1":"code","8b754e1e":"code","59a0bd61":"code","aa0d5a50":"code","6eb9236c":"code","d6bdef74":"code","7785602b":"code","7a9fbf7a":"markdown","bd786aae":"markdown","04a15c6d":"markdown","5b959b68":"markdown","40202bc2":"markdown","a5fa4955":"markdown","496405b3":"markdown","199b1c98":"markdown","cade12c5":"markdown","4d7c4904":"markdown","612d4243":"markdown","d13d69da":"markdown","1bfe0aa0":"markdown","b44d5953":"markdown","68812d67":"markdown","77a2a561":"markdown","1bcfe86b":"markdown","6096460c":"markdown","db8ca5f6":"markdown","04a1a391":"markdown","c7f9167c":"markdown","b109fa64":"markdown","8734928f":"markdown","8d84e1d5":"markdown","de0a4dbe":"markdown","c04d04dc":"markdown","3775725e":"markdown","d116ee9f":"markdown","fae86815":"markdown","3bfd9ad1":"markdown","9f664813":"markdown","f36d4629":"markdown","951e933e":"markdown","75b5197b":"markdown","c54051a8":"markdown","bac815a4":"markdown","3b8833d3":"markdown","12b356a0":"markdown","e645a97e":"markdown","56fdcc50":"markdown","b8bce0b0":"markdown","d4571bf0":"markdown","f6fb39b3":"markdown","10ac523f":"markdown"},"source":{"7a677668":"import numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom pylab import rcParams","25496d19":"gps = pd.read_csv(\"..\/input\/googleplaystore.csv\")","c4bdd599":"print(\"Shape of the dataset is:\", gps.shape, \" where no. of rows is \", gps.shape[0] , \"and no. of columns is \", gps.shape[1])","1866a969":"gps.head(5)","ac07b156":"gps['Rating'] = gps['Rating'].astype(str).astype(float)","c2232531":"gps['Reviews'] = gps['Reviews'].apply(lambda x: x.replace('3.0M', '3000000'))\ngps['Reviews'] = gps['Reviews'].apply(lambda x: int(x))\n#gps.head(5)","82686725":"gps = gps[gps['Installs'] != 'Free']\ngps = gps[gps['Installs'] != 'Paid']\ngps['Installs'] = gps['Installs'].apply(lambda x: x.replace('+', '') if '+' in str(x) else x)\ngps['Installs'] = gps['Installs'].apply(lambda x: x.replace(',', '') if ',' in str(x) else x)\ngps['Installs'] = gps['Installs'].apply(lambda x: int(x))","653e14cc":"gps['Price'] = gps['Price'].apply(lambda x: str(x).replace('$', '') if '$' in str(x) else str(x))\ngps['Price'] = gps['Price'].apply(lambda x: float(x))","e01a12c0":"gps['Size'] = gps['Size'].apply(lambda x: str(x).replace('Varies with device', 'NaN') if 'Varies with device' in str(x) else x)\ngps['Size'] = gps['Size'].apply(lambda x: str(x).replace('M', '') if 'M' in str(x) else x)\ngps['Size'] = gps['Size'].apply(lambda x: str(x).replace(',', '') if 'M' in str(x) else x)\ngps['Size'] = gps['Size'].apply(lambda x: float(str(x).replace('k', '')) \/ 1000 if 'k' in str(x) else x)\ngps['Size'] = gps['Size'].apply(lambda x: float(x))","a576aa8e":"avg_rate = gps.groupby('Category', as_index=False)['Rating'].mean()","5c70e3b5":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go","8bc84bfd":"avg_rate_data = [go.Histogram(\n        x = gps.Rating,\n        xbins = {'start': 1, 'size': 0.1, 'end' :5}\n)]\n\nprint('Average app rating:', np.mean(gps['Rating']))\npy.offline.iplot(avg_rate_data, filename='rating_dist')","debdf7d2":"def box_plot(datas):\n    traces = []\n    a = avg_rate['Category'].tolist()\n    for i in range(33):\n        y = np.array(datas[datas['Category'] == a[i]].Rating)\n        trace = go.Box(\n                    y=y,\n                    name = a[i]\n                )\n        traces.append(trace)\n    layout = go.Layout(\n    title='',\n    xaxis=dict(\n        title='',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        \n        )\n    )\n)    \n    data_avg_rating = traces\n    fig = go.Figure(data=data_avg_rating, layout=layout)\n    plot_url = py.iplot(fig, filename='avg_rating-plot')","fbf27318":"box_plot(gps)","082610f1":"rcParams['figure.figsize'] = 11,11\ncat_cnt = sns.countplot(x=\"Category\",data=gps, palette = \"Set3\")\ncat_cnt.set_xticklabels(cat_cnt.get_xticklabels(), rotation=90, ha=\"right\")\ncat_cnt\nplt.title('Number of Apps in each category',size = 15)","0c3b3349":"no_reviews = gps.groupby('Category', as_index=False)['Reviews'].sum()\nmost_space = gps.groupby('Category', as_index=False)['Size'].sum().sort_values(by='Size', ascending=False)\nbest_cat = gps.groupby('Category', as_index=False)['Installs'].sum()","f7b42ba8":"from plotly import tools\nimport plotly.offline as py\nimport plotly.graph_objs as go\n\ndata_pie = [go.Pie(\n        labels = no_reviews['Category'].tolist(),\n        values = no_reviews['Reviews'].tolist(),\n        hoverinfo = 'label+value',\n        name= 'Reviews by Category'\n    \n)]\n\npy.offline.iplot(data_pie, filename='active_category')\n\ndata_size_pie = [go.Pie(\n        labels = most_space['Category'].tolist(),\n        values = most_space['Size'].tolist(),\n        hoverinfo = 'label+value',\n        name = 'x'\n    \n)]\n\npy.offline.iplot(data_size_pie, filename='active_category')\n\ndata_cat_pie = [go.Pie(\n        labels = best_cat['Category'].tolist(),\n        values = best_cat['Installs'].tolist(),\n        hoverinfo = 'label+value',\n        name='y'\n    \n)]\n\npy.offline.iplot(data_cat_pie, filename='active_category')","0e72178a":"relate = gps.corr()","3b27aba0":"import plotly.graph_objs as go\n\ntrace = go.Heatmap(z=[relate.Rating.values.tolist(), relate.Reviews.values.tolist(), relate.Size.values.tolist(), relate.Installs.values.tolist(), relate.Price.values.tolist()],\n                   x=[relate.columns[0], relate.columns[1], relate.columns[2], relate.columns[3], relate.columns[4]],\n                   y=[relate.columns[0], relate.columns[1], relate.columns[2], relate.columns[3], relate.columns[4]])\ndata_cor=[trace]\npy.iplot(data_cor, filename='corr-heatmap')","703771b2":"rcParams['figure.figsize'] = 11,11\nplt.ticklabel_format(style='plain', axis='x',useOffset=False)\nplt.ticklabel_format(style='plain', axis='y',useOffset=False)\n\nax = sns.distplot(gps['Reviews'], kde=True)\nax","bcf2904a":"import plotly.graph_objs as go\n\nx0 = gps[gps['Type'] == 'Free']['Rating']\nx1 = gps[gps['Type'] == 'Paid']['Rating']\n\ntrace0 = go.Box(\n    x=x0,\n    name='Free'\n)\ntrace1 = go.Box(\n    x=x1,\n    name='Paid'\n)\ndata_type_rating = [trace0, trace1]\npy.iplot(data_type_rating)\n\ny0 = gps[gps['Type'] == 'Free']['Size']\ny1 = gps[gps['Type'] == 'Paid']['Size']\n\ntrace0 = go.Box(\n    y=y0,\n    name='Free'\n)\ntrace1 = go.Box(\n    y=y1,\n    name='Paid'\n)\ndata_type_rating = [trace0, trace1]\npy.iplot(data_type_rating)","b24dd593":"trace0 = go.Scatter(\n    x=gps[gps['Type']=='Free']['Rating'],\n    y=gps[gps['Type']=='Free']['Size'],\n   name='Free',\n   mode = 'markers',\n    marker = dict(\n        size = 10,\n        color = 'rgba(152, 0, 0, .8)',\n        line = dict(\n            width = 2,\n            color = 'rgb(0, 0, 0)'\n        )\n   )\n)\ntrace1 = go.Scatter(\n    x = gps[gps['Type']=='Paid']['Rating'],\n    y = gps[gps['Type']=='Paid']['Size'],\n    name='Paid',\n    mode = 'markers',\n    marker = dict(\n        size = 10,\n        color = 'rgba(255, 182, 193, .9)',\n        line = dict(\n            width = 2,\n        )\n   )\n)\nlayout = dict(title = 'Size Vs Rating',\n              yaxis = dict(zeroline = False, title='Size'),\n              xaxis = dict(zeroline = False, title='Rating')\n             )\n\ndata_sc = [trace0, trace1]\n\nfig = dict(data=data_sc, layout=layout)\npy.iplot(fig, filename='size-scatter')","bad188cd":"plt.figure(figsize = (11,11))\nsns.regplot(x=\"Reviews\", y=\"Rating\", color = 'lightgreen',data=gps[gps['Reviews']<100000]);\nplt.title('Reviews Vs Ratings for an App',size = 15)","ff483735":"from plotly import tools\nimport plotly.offline as py\nimport plotly.graph_objs as go\n\n# Data to plot\nlabels = gps['Type'].value_counts(sort = True).index\nvalues = gps['Type'].value_counts(sort = True)\n\ndata_pie1 = [go.Pie(\n        labels = labels.tolist(),\n        values = values.tolist(),\n        hoverinfo = 'label+value',\n        name= ''\n    \n)]\n\npy.offline.iplot(data_pie1, filename='active_category1')","b7f6c536":"avg_size=gps.groupby('Type', as_index=False)['Size'].mean()","2cc061b4":"import plotly.figure_factory as ff\n\ndata_bul = (\n  {\"label\": \"Free\", \"range\": [1, 50, 100], \"performance\": [20,50], \"point\": [21.7]},\n  {\"label\": \"Paid\", \"range\": [1, 50, 100], \"performance\": [20,50],\"point\": [19.3]}\n)\nmeasure_colors=['rgb(63,102,153)', 'rgb(120,194,195)']\nrange_colors=['rgb(245,225,218)', 'rgb(241,241,241)']\n\nfig = ff.create_bullet(\n    data_bul, titles='label', markers='point', measures='performance', title='Average Size in MB of free and paid apps',\n    ranges='range', orientation='v', range_colors=range_colors, width=800,measure_colors=measure_colors\n)\npy.iplot(fig, filename='bulletchart_size')","95e3f6ad":"gps.head(5)","2bece1a9":"gps.Price.max()","5a656a93":"gps.loc[gps['Price'] == 400]","08a36e39":"gps['Price'].describe()","484b5b4d":"import seaborn as sns\nax = sns.lmplot(x=\"Price\", y=\"Rating\", hue = 'Content Rating', data=gps, size = 10)\nax.set(xlim=(-20, 450))\nax.set(ylim=(0, 7))\nplt.show()","b07c15ef":"reviews = pd.read_csv(\"..\/input\/googleplaystore_user_reviews.csv\")","3ad3a0f2":"reviews.head()","71947f68":"from wordcloud import WordCloud\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import sent_tokenize, word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc)\n    plt.axis('off')","d7a95713":"from collections import Counter\nfrom nltk.tokenize import RegexpTokenizer\nfrom stop_words import get_stop_words\nimport re\n\ntop_N = 100\n\npos_review_lower = reviews[reviews['Sentiment']=='Positive']['Translated_Review'].str.lower().str.cat(sep=' ')\nneg_review_lower = reviews[reviews['Sentiment']=='Negative']['Translated_Review'].str.lower().str.cat(sep=' ')\nneu_review_lower = reviews[reviews['Sentiment']=='Neutral']['Translated_Review'].str.lower().str.cat(sep=' ')\n\npos_review_remove_pun = re.sub('[^A-Za-z]+', ' ', pos_review_lower)\nneg_review_remove_pun = re.sub('[^A-Za-z]+', ' ', neg_review_lower)\nneu_review_remove_pun = re.sub('[^A-Za-z]+', ' ', neu_review_lower)\n\n#remove all the stopwords from the text\nstop_words = list(get_stop_words('en'))         \nnltk_words = list(stopwords.words('english'))   \nstop_words.extend(nltk_words)\n\npos_word_tokens_tags = word_tokenize(pos_review_remove_pun)\nneg_word_tokens_tags = word_tokenize(neg_review_remove_pun)\nneu_word_tokens_tags = word_tokenize(neu_review_remove_pun)\npos_filtered_sentence_tags = [w_tags for w_tags in pos_word_tokens_tags if not w_tags in stop_words]\npos_filtered_sentence_tags = []\nfor w_tags in pos_word_tokens_tags:\n    if w_tags not in stop_words:\n        pos_filtered_sentence_tags.append(w_tags)\n\nneg_filtered_sentence_tags = [w_tags for w_tags in neg_word_tokens_tags if not w_tags in stop_words]\nneg_filtered_sentence_tags = []\nfor w_tags in neg_word_tokens_tags:\n    if w_tags not in stop_words:\n        neg_filtered_sentence_tags.append(w_tags)\n        \nneu_filtered_sentence_tags = [w_tags for w_tags in neu_word_tokens_tags if not w_tags in stop_words]\nneu_filtered_sentence_tags = []\nfor w_tags in neu_word_tokens_tags:\n    if w_tags not in stop_words:\n        neu_filtered_sentence_tags.append(w_tags)","ca378883":"# Remove characters which have length less than 2  \n\npos_without_single_chr_rev = [word_tags for word_tags in pos_filtered_sentence_tags if len(word_tags) > 2]\nneg_without_single_chr_rev = [word_tags for word_tags in neg_filtered_sentence_tags if len(word_tags) > 2]\nneu_without_single_chr_rev = [word_tags for word_tags in neu_filtered_sentence_tags if len(word_tags) > 2]\n\n# Remove numbers\npos_cleaned_data_rev = [word_tags for word_tags in pos_without_single_chr_rev if not word_tags.isnumeric()]  \nneg_cleaned_data_rev = [word_tags for word_tags in neg_without_single_chr_rev if not word_tags.isnumeric()]  \nneu_cleaned_data_rev = [word_tags for word_tags in neu_without_single_chr_rev if not word_tags.isnumeric()]  ","38e3a9c0":"\nword_dist_tags = nltk.FreqDist(pos_cleaned_data_rev)\nrslt_rev = pd.DataFrame(word_dist_tags.most_common(top_N),\n                    columns=['Word', 'Frequency'])\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt_rev.head(7))","d1c202b5":"wc(pos_cleaned_data_rev,'black','Common Words' )","0282a753":"wc(neg_cleaned_data_rev,'White','Common Words' )","c7eb5cfa":"from nltk.corpus import wordnet\n\ndef get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n    \nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\n\ndef clean_text(text):\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    # remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    # pos tag text\n    pos_tags = pos_tag(text)\n    # lemmatize text\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)\n\n# clean text data\nreviews[\"review_clean\"] = reviews[\"Translated_Review\"].apply(lambda x: clean_text(str(x)))","d4dbe315":"reviews = reviews.dropna()\n\nreviews['is_good'] = np.where(reviews['Sentiment'] == 'Positive', 1, 0)","9e47b1e1":"# add number of characters column\nreviews[\"nb_chars\"] = reviews[\"review_clean\"].apply(lambda x: len(x))\n\n# add number of words column\nreviews[\"nb_words\"] = reviews[\"review_clean\"].apply(lambda x: len(x.split(\" \")))","8b754e1e":"# create doc2vec vector columns\n\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews[\"review_clean\"].apply(lambda x: x.split(\" \")))]\n\n# train a Doc2Vec model with our text data\n\nmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\n# transform each document into a vector data\n\ndoc2vec_df = reviews[\"review_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\nreviews_df = pd.concat([reviews, doc2vec_df], axis=1)","59a0bd61":"# Add TFIDF columns\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(min_df = 10)\ntfidf_result = tfidf.fit_transform(reviews_df[\"review_clean\"]).toarray()\ntfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\ntfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\ntfidf_df.index = reviews_df.index\nreviews_df = pd.concat([reviews_df, tfidf_df], axis=1)","aa0d5a50":"reviews_df[\"is_good\"].value_counts(normalize = True)","6eb9236c":"# plot sentiment distribution for positive and negative reviews\n\nimport seaborn as sns\n\nfor x in [0, 1]:\n    subset = reviews_df[reviews_df['is_good'] == x]\n    \n    # Draw the density plot\n    if x == 1:\n        label = \"Good reviews\"\n    else:\n        label = \"Bad reviews\"\n    sns.distplot(subset['Sentiment_Subjectivity'], hist = False, label = label)","d6bdef74":"# feature selection\n\nlabel = \"Sentiment\"\nignore_cols = [label, \"is_good\", \"App\",\"Translated_Review\", \"review_clean\"]\nfeatures = [c for c in reviews_df.columns if c not in ignore_cols]\n\n# split the data into train and test\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(reviews_df[features], reviews_df[label], test_size = 0.20, random_state = 42)","7785602b":"# train a random forest classifier\n\nrf = RandomForestClassifier(n_estimators = 100, random_state = 42)\nrf.fit(X_train, y_train)\n\n# show feature importance\n\nfeature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\nfeature_importances_df.head(20)","7a9fbf7a":"### Category with the Most Reviews, Most Space Consumption and Most Installations","bd786aae":"**Free Apps constitute almost 93% of the play store apps.**","04a15c6d":"## **Modeling**","5b959b68":"### Clearly, reviews and no. of installs are correlated to an extent.","40202bc2":"**Wordcloud for Positive Sentiment Reviews**","a5fa4955":"### Inference\n***\n**While Gaming Apps have the Most reviews & Installations, family apps consume more spaces in Google play.**\n***","496405b3":"### Distribution and Average Rating of all the Apps & per category of apps","199b1c98":"### How are rating, size, reviews and installs related? ","cade12c5":"### Function to create wordclouds","4d7c4904":"###  How to predict sentiment of a text?","612d4243":"#### 64-36 ratio seems to be alright and not that imbalanced.","d13d69da":"![](https:\/\/cdn-images-1.medium.com\/max\/900\/1*keqyBCQ5FL6A7DZLrXamvQ.png)","1bfe0aa0":"### Free vs Paid - Average Size","b44d5953":"**Does high Price impact Ratings?**","68812d67":"**Distribution of Reviews**","77a2a561":"Lets add another numerical conversion method similar to doc2vec, which is TFIDF\n\nWord counts are a good starting point, but are very basic.\n\nOne issue with simple counts is that some words like \u201cthe\u201d will appear many times and their large counts will not be very meaningful in the encoded vectors.\n\nAn alternative is to calculate word frequencies, and by far the most popular method is called TF-IDF. This is an acronym than stands for \u201cTerm Frequency \u2013 Inverse Document\u201d Frequency which are the components of the resulting scores assigned to each word.\n\nTerm Frequency: This summarizes how often a given word appears within a document.\nInverse Document Frequency: This downscales words that appear a lot across documents.\nTF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n\nThe TfidfVectorizer will tokenize documents\/sentence, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents","1bcfe86b":"The most important features are indeed the ones that come from the previous sentiment analysis. \n\nThe vector representations of the texts also have a lot of importance in our training. Some words appear to have a fairly good importance as well.","6096460c":"**Of course, lesser the reviews, lesser the ratings as well**","db8ca5f6":"**Percent of Free and Paid Apps in the play store**","04a1a391":"### Free vs Paid Apps  -  Ratings & Size","c7f9167c":"To Follow","b109fa64":"**Wordcloud for Negative Sentiment Reviews**","8734928f":"At first I thought it was a joke, but no its a real app -- https:\/\/play.google.com\/store\/apps\/details?id=com.richstudios.trumpedition&hl=en","8d84e1d5":"**Reviews vs Ratings**","de0a4dbe":"**Inference -- Most high rated apps are free(of course), but for the paid apps, the high rated are mostly < 100 dollars and a few above 200 dollars.**","c04d04dc":"### Function for PoS tags and cleaning the data","3775725e":"**The highest priced app is $400. What app is it?**","d116ee9f":"### What is a doc2vec model and why do you need it?\n\n\nWhen you would like to build models using words, simply labeling\/one-hot encoding them is a one way to go. However, when using such encoding, the words lose their meaning. e.g, if we encode Paris as id_4, France as id_6 and power as id_8, France will have the same relation to power as with Paris. We would prefer a representation in which France and Paris will be closer than France and power. This is where models like word2vec and doc2vec are used, to represent text data numerically.\n\nSuch representations, encapsulate different relations between words, like synonyms, antonyms, or analogies, such as this one:","fae86815":"### Per category","3bfd9ad1":"**This Kernel is an Exploration on the Google Play Store dataset, along with a baseline model**\n\n** Please Upvote if you liked the kernel**","9f664813":"**What's the highest and the lowest paid app?**","f36d4629":"### Baseline Model","951e933e":"Doc2vec is known to perform better than word2vec and we'll implement the same here.\n\nDoc2vec = word2vec + 1 feature vector(which is document-unique.)","75b5197b":"> **Frequency of words in Translated Review column.**","c54051a8":"### How is size impacting the app rating ?","bac815a4":"### The points are more dense at the lower bottom-right, meaning, less sized apps have higher ratings.","3b8833d3":"**Inference -- Clearly, Family category has the most number of apps**","12b356a0":"**The Average Price is around 1$**","e645a97e":"**Count of App in each category***","56fdcc50":"**Looks very skewed on the right.**","b8bce0b0":"#### Distribution of Positive and non-positive reviews from the dataset. ","d4571bf0":"### App Reviews","f6fb39b3":"##### Next, we add some simple metrics for every text\n   ##### - Number of characters in the text\n   ##### - Number of words in the text","10ac523f":"### Frequency distribution of positive words"}}