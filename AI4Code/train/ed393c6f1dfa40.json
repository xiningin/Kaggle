{"cell_type":{"d0d2aad0":"code","a4077002":"code","dbdd8f1d":"code","5d2ecaa5":"code","a877cfd5":"code","2a53172d":"code","9df68765":"code","99bd9648":"code","ac7dae28":"code","d6cc5b3c":"code","f38cbaf9":"markdown","7503aaa2":"markdown","cc9d5687":"markdown","45bf0b3a":"markdown","35491766":"markdown","831e5307":"markdown"},"source":{"d0d2aad0":"# Import Libraries\nimport sys\nimport numpy as np\nimport random\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint","a4077002":"import os\nimport glob\nfilepath = \"\/kaggle\/input\/donald-trumps-rallies\/\"\nfor f in glob.glob(filepath+\"*.txt\"):\n    os.system(\"cat \"+f+\" >> DonaldTrumpRallies.txt\")","dbdd8f1d":"# Load Dataset\nfilename    = 'DonaldTrumpRallies.txt'\ntext        = open(filename, encoding='utf-8').read()\ntext        = text.lower()\nprint('corpus length:', len(text))\n\n# Find all the unique characters\nchars        = sorted(list(set(text)))\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))\nvocab_size   = len(chars)\n\nprint(\"List of unique characters : \\n\", chars)\nprint(\"Number of unique characters : \\n\", vocab_size)\nprint(\"Character to integer mapping : \\n\", char_indices)","5d2ecaa5":"# Preprocessing Dataset\nmax_seq_len = 64 # cut text in semi-redundant sequences of max_seq_len characters\nstep = 3 \nsentences = [] # list_X\nnext_chars= [] # list_Y\n\nfor i in range(0, len(text) - max_seq_len, step):\n    sentences.append(text[i: i + max_seq_len])\n    next_chars.append(text[i + max_seq_len])\nprint('nb sequences:', len(sentences))\n\nnum_sequences  = len(sentences)\nprint(\"Number of sequences: \", num_sequences)\nprint(sentences[0])","a877cfd5":"print('Vectorization...')\ntrain_X = np.zeros((len(sentences), max_seq_len, len(chars)), dtype=np.bool)\ntrain_Y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        train_X[i, t, char_indices[char]] = 1\n    train_Y[i, char_indices[next_chars[i]]] = 1\n\nprint(train_X.shape)\nprint(train_Y.shape)","2a53172d":"input_shape = (max_seq_len, vocab_size)\nprint(input_shape)","9df68765":"# Build Model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))\nmodel.add(Bidirectional(LSTM(64)))\nmodel.add(Dense(len(chars), activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nmodel.summary()","99bd9648":"# Train Model\nnum_epochs = 30\nbatch_size = 128\n#model_path = \"BiLSTM-DonaldTrumpRallies .h5\"\n#checkpoint = ModelCheckpoint(model_path, monitor='loss', save_best_only=True, verbose=1, mode='min')\n#callbacks_list = [checkpoint]\n\nmodel.fit(train_X, train_Y, epochs = num_epochs, batch_size = batch_size, verbose=1) #, callbacks=callbacks_list)","ac7dae28":"model.save('BiLSTM-DonaldTrumpRallies.h5')","d6cc5b3c":"# Generate Text\ndef sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) \/ temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds \/ np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_text():\n    start_index = random.randint(0, len(text) - max_seq_len - 1)\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\n        print('----- diversity:', diversity)\n        generated = ''\n        sentence = text[start_index: start_index + max_seq_len]\n        generated += sentence\n        print('----- Generating with seed: \"' + sentence + '\"')\n        sys.stdout.write(generated)\n\n        for i in range(400):\n            x_pred = np.zeros((1, max_seq_len, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] = 1.\n\n            preds = model.predict(x_pred, verbose=0)[0]\n            next_index = sample(preds, diversity)\n            next_char = indices_char[next_index]\n\n            sentence = sentence[1:] + next_char\n\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()\n\ngenerate_text()","f38cbaf9":"## Preprocess Dataset","7503aaa2":"## Build Model","cc9d5687":"## Load Dataset","45bf0b3a":"## Train Model","35491766":"## Generate Text","831e5307":"# LSTM for Trump's Rallies"}}