{"cell_type":{"3432d87d":"code","59e436f7":"code","67af7e64":"code","8ac755a9":"code","e924583b":"code","ebe1e82b":"code","42f724c5":"code","7b3c6e3e":"code","592a3fd5":"code","0357b6c8":"code","1389f79b":"code","70247739":"code","aee40f3d":"code","eef47830":"code","197f440c":"code","40407b97":"code","30b5aacf":"code","dfd969e1":"code","2cedb480":"code","c0228888":"code","f5bf2a1b":"code","6d238331":"code","97faffdb":"code","72362382":"code","4823f932":"code","1d551b48":"code","d7b60466":"code","142fe279":"code","5cf3eb0b":"code","d5977a53":"code","104877c8":"code","dce2d62c":"code","5f929671":"code","fe6691fe":"markdown","9b9fef9f":"markdown","cbe3d735":"markdown","3162cc5f":"markdown","c46409c5":"markdown","b8d1d145":"markdown","57ffa8b1":"markdown","d9554501":"markdown","6f5822c6":"markdown","218e3ab8":"markdown","06eb5386":"markdown","eb3cc5a4":"markdown","8b538c47":"markdown","523ca365":"markdown","77e7a978":"markdown"},"source":{"3432d87d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","59e436f7":"test=pd.read_csv(r\"\/kaggle\/input\/movie-review-sentiment-analysis-kernels-only\/test.tsv.zip\",sep=\"\\t\")\ntrain=pd.read_csv(r\"\/kaggle\/input\/movie-review-sentiment-analysis-kernels-only\/train.tsv.zip\",sep=\"\\t\")\nsub = pd.read_csv('..\/input\/movie-review-sentiment-analysis-kernels-only\/sampleSubmission.csv', sep=\",\")","67af7e64":"#lets look at the test data\ntest.head()","8ac755a9":"#lets look at the test data\ntrain.head(100)","e924583b":"# lets look at the shape of the train data\ntrain.shape","ebe1e82b":"# lets look at the shape of the test data\ntest.shape","42f724c5":"train.loc[train['SentenceId']==3]","7b3c6e3e":"train.loc[train['SentenceId']==2]","592a3fd5":"# since we have different values in  sentenceId,check the total no of unique sentenceId \nprint(\"For train data \",train['SentenceId'].nunique()) \nprint(\"For test data \",test['SentenceId'].nunique()) ","0357b6c8":"\npd.DataFrame(train.groupby('SentenceId')['Phrase'].count()).head(10)","1389f79b":"## Returning average count of phrases per sentence, per Dataset\nint(train.groupby('SentenceId')['Phrase'].count().mean())","70247739":"int(test.groupby('SentenceId')['Phrase'].count().mean())","aee40f3d":"#Returning average word length of phrases\nprint(\"train \",int(np.mean(train['Phrase'].apply(lambda x: len(x.split())))))\nprint(\"test\",int(np.mean(test['Phrase'].apply(lambda x: len(x.split())))))","eef47830":"train_count=train['Sentiment'].value_counts() ","197f440c":"#gets the unique value count of an object\ntrain_labels=train['Sentiment'].value_counts().index","40407b97":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfig,ax = plt.subplots(1, 1, dpi = 100, figsize = (7, 5))\ng=sns.barplot(train_labels,train_count)\nax.set_xlabel(\"target\")\nax.set_ylabel(\"count\")","30b5aacf":"import nltk","dfd969e1":"tokenizer = nltk.tokenize.TweetTokenizer()","2cedb480":"# import tfidf vectoriser\nfrom sklearn.feature_extraction.text import TfidfVectorizer","c0228888":"vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\nfull_text = list(train['Phrase'].values) + list(test['Phrase'].values)\nvectorizer.fit(full_text)  #learns both train and test data vocabulary\n","f5bf2a1b":"train_vectorized = vectorizer.transform(train['Phrase'])\ntest_vectorized = vectorizer.transform(test['Phrase'])","6d238331":"train_vectorized.shape","97faffdb":"y = train['Sentiment']","72362382":"test_vectorized.shape","4823f932":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression","1d551b48":"logreg = LogisticRegression()\novr = OneVsRestClassifier(logreg)","d7b60466":"ovr.fit(train_vectorized, y)\n","142fe279":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(ovr, train_vectorized, y, scoring='accuracy', n_jobs=-1, cv=10)","5cf3eb0b":"print(\"Mean of 10 cv :\",np.mean(scores) * 100)\nprint( \"standard deviation\",np.std(scores) * 100)","d5977a53":"y_test=ovr.predict(test_vectorized)","104877c8":"sub.Sentiment=y_test","dce2d62c":"sub.head()","5f929671":"sub.to_csv('submission.csv',index=False)","fe6691fe":"### **Output Inspection**\n* 0 - negative   \n* 1 - somewhat negative    \n* 2 - neutral   \n* 3 - somewhat positive   \n* 4 - positive   ","9b9fef9f":"**Point to Note**\n\n*       We can say here that each sentenceId is grouped  based on the similar words in phrase column","cbe3d735":"we can see that the sentenceId with value 3 has mostly same  repeated words in Phrase column ","3162cc5f":"Know about OneVsRestClassifier here https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.multiclass.OneVsRestClassifier.html","c46409c5":"Similarly,we can see that the sentenceId with value 2 has mostly same repeated words in Phrase column","b8d1d145":"**Applying Model**","57ffa8b1":"Importing the train,test,submission datasets","d9554501":"**TF-IDF**","6f5822c6":"So, we have only phrases as data. And a phrase can contain a single word. And one punctuation mark can cause phrase to receive a different sentiment. Also assigned sentiments can be strange. This means several things:\n* using stopwords can be a bad idea, especially when phrases contain one single stopword\n* untuation could be important, so it should be used;\n* ngrams are necessary to get the most info from data (know about ngrams ->https:\/\/www.kaggle.com\/c\/avito-demand-prediction\/discussion\/58819)\n","218e3ab8":"* we can say that almost half of the target values are 2(neutral).\n* we can also say that data is not balanced based on target feature","06eb5386":"# **Feature Engineering** ","eb3cc5a4":"# **Data Analysis**","8b538c47":"# **Exploring Target Value**","523ca365":"**Why have i fitted the vectorizer with both train and test data?**\n> In real world we don't know what will be in new(test) data, so we have to fit only train data. On the other hand, in kaggle we have both train and test, this means we can    take   into account word distribution in both datasets.\nAlso go through this link https:\/\/www.kaggle.com\/questions-and-answers\/58368 to know more","77e7a978":"It is a huge dataset."}}