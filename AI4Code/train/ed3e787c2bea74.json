{"cell_type":{"bab7571f":"code","85527ab8":"code","fe0c4124":"code","13bf37c7":"code","ce0fc16b":"code","070fcd9c":"code","c4826823":"code","438e1a19":"markdown","d4b0faa6":"markdown","8961078a":"markdown","b65537b0":"markdown","99164330":"markdown","29d6ba00":"markdown","107407bb":"markdown","48173982":"markdown","becd8c5a":"markdown","643cb887":"markdown"},"source":{"bab7571f":"import tensorflow as tf \nimport tensorflow.keras # tensorflow and keras are deep learning API's which makes our Deep Learning process Simple\nfrom tensorflow.keras import Sequential  #this package is for stacking the layers of my model\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout #these are the differnet types of layers in the Deep learning model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #this a package used to scale our dataset images\nfrom tensorflow.keras.optimizers import RMSprop #this is an type of optimizer and this is a algorithm to minimize loss\nimport matplotlib.pyplot as plt #this package is used to plot our data or result","85527ab8":"TRAINING_DIR = '..\/input\/cat-and-dog\/training_set\/training_set\/'\ntrain_datagen = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=40,\n                    width_shift_range=0.2,\n                    height_shift_range=0.2,\n                    shear_range=0.2,\n                    zoom_range=0.2,\n                    horizontal_flip=True,\n                    fill_mode='nearest')\ntrain_generator =train_datagen.flow_from_directory(\n                   TRAINING_DIR,\n                   target_size=(224,224),\n                   batch_size=64,\n                   class_mode='binary'\n                     )","fe0c4124":"VALIDATION_DIR = '..\/input\/cat-and-dog\/test_set\/test_set\/'\nvalidation_datagen = ImageDataGenerator(\n                           rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(\n                            VALIDATION_DIR,\n                            target_size=(224,224),\n                            batch_size=32,\n                            class_mode='binary')","13bf37c7":"model = tf.keras.models.Sequential([\n    Conv2D(16,(3,3),activation='relu',input_shape=(224,224,3)),\n    MaxPool2D(2,2),\n    Conv2D(32,(3,3),activation='relu'),\n    Conv2D(32,(3,3),activation='relu'),\n    MaxPool2D(2,2),\n    Conv2D(64,(3,3),activation='relu'),\n    MaxPool2D(2,2),\n    Dropout(0.3),\n    Flatten(),\n    Dense(256,activation='relu'),\n    Dense(128,activation='relu'),\n    Dense(64,activation='relu'),\n    Dropout(0.25),\n    Dense(1,activation='sigmoid')\n])\n\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","ce0fc16b":"model.summary()","070fcd9c":"history = model.fit(train_generator,\n                              epochs=30,\n                              steps_per_epoch=125,\n                              verbose=1,\n                              validation_data=validation_generator)","c4826823":"acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\nepochs=range(len(acc))\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","438e1a19":"# Plotting the Results\nWith the below cell we can plot our results of our training. And clearly both the testing and training accuracy increases and the testing and training loss decreases which means our model is working fine.","d4b0faa6":"# If you like my Notebook please upvote and also comment your opinions.","8961078a":"# **INTRODUCTION:**\n \nIn this dataset i will be using cat-and-dog public dataset.When it comes to Classifying Images CNN plays a vital role in Deep Learning.CNN is a is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects\/objects in the image and be able to differentiate one from the other.I used keras for using CNN. ","b65537b0":"# **Cat or Dog Image Classification with Convolutional Neural Network (ConvNet\/CNN)**\nThis notbook contains \n1.       Introduction\n1.       Importing Libraries\n1.       Data preprocessing(both testing and training data)\n1.       Training the Model \n1.       Plotting the Results\n    \n    \n    ","99164330":"**From the below cell you can visualze the model clearly the shape of inputs and outputs and also please compare the input values and output shapes of CNN layers so you can understand its working clearly**","29d6ba00":"# **Libraries:**\n\nI imported necessary libraries to use in do our classification in the below cell.\n","107407bb":"# **Data Preprocessing**\n\nwe will be using ImageDataGenerator to augment our data. Image augmentation is one useful technique in building convolutional neural networks that can increase the size of the training set without acquiring new images. Also it is a regularization technique to avoid overfitting.","48173982":"**We are training our model with our training and testing data in the below cell. The number of epochs indicates the number of times we loop over our dataset,and steps per epoch indicates the number of batches of random images we will be training our model.**","becd8c5a":"![kaggle2.jpg](attachment:kaggle2.jpg)\n","643cb887":"# **training the model**\n1.  The first layer of our model will be a Convolutional Layer and we need to mention the input shape in the first layer ,we need not mention it in the other layers. The shape is (224,224,3) the first two arguments indicate the width and height of the image and the third argument indicates the number of color channels in our image (i.e) RGB - Red,Blue and Green color format .If our dataset contains black and white images then we must have our third argument as 1 as B\/W image contains only one color channel.\n1.  The Conv2D indicates Convolutions in a 2d image and it requires 3 minimum arguments first will be number of filters and second will be size of the filter and the third will be the activation function,mostly **relu** will be used in image classification as it performs better in images.\n1. The MaxPool2D layers is used to reduce the dimension by considering only the important features in the image usually this is not considered as a separate layer as it is a part of convolution layer but for simpler understanding consider it as a separate layer.\n1. After extracting the important features in the image we can now move towards the Fully Connected layers i.e Dense Layers\n1. Dense layers doesnot accept images it accepts only Flattened datas so we will be flattening the output from the Convolutional layers usinf Flatten layer \n1. Dense layer has two arguments one is number of nodes at that layer and the activation function to be used as i mentioned earlier we use relu for images except the output layer.\n1. After multiple Dense layers we have a Dropout layer,this layer helps in avoiding overfitting and this layer has a argument which requires a value which makes  that percentage of random nodes in the previous layers to non-active so that we can avoid overfitting.\n1. The final layer has the number of nodes which here is 1 rather than 2(cat or dog) because i used sigmoid activation function because sigmoid function gives the probability value with which we can understand that if the probability value is less a  threshold value (commonly 0.5) is the label 0 (here cat) and above the threshold value indicates label 1(here dog). if u want to have number of output nodes as the number of labels then use **sotmax** activation function but in case of binary classification **Sigmoid** works fine than Softmax.\n"}}