{"cell_type":{"67cb284c":"code","0e6dfecb":"code","9bd8ebc7":"code","005fb676":"code","3d4657b4":"code","f72ffdb7":"code","56486102":"code","4d9de1ab":"code","18d55105":"code","9cdb7a5f":"code","9b6ada2b":"code","f3a510a2":"code","f50fb8bb":"code","fdb88f80":"code","6b355785":"code","8f64f55a":"code","65e35b91":"code","ba2632be":"code","bb8317f1":"code","18e406d3":"code","9a4bd6c1":"markdown","030b59e3":"markdown","850d5ba2":"markdown","75acc9fd":"markdown","d4a48515":"markdown","6044d574":"markdown","e64c3283":"markdown","0e769589":"markdown","1aa9c263":"markdown","0504dfab":"markdown","2bf276eb":"markdown","72d7674c":"markdown"},"source":{"67cb284c":"# Libraries\nimport os, shutil\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom keras import layers\nfrom keras import models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers","0e6dfecb":"# path to the folder where the whole dataset is stored\noriginal_dataset_dir = '..\/input\/microsoft-catsvsdogs-dataset\/PetImages'\n\n# create a folder to store our small sample of images\nbase_dir = '..\/cats_and_dogs_small'\nos.mkdir(base_dir)","9bd8ebc7":"# create sub-folders for training, validation and test sets\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\n\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\n\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# create sub-folders Cat and Dog \ntrain_Cat_dir = os.path.join(train_dir, 'Cat')\nos.mkdir(train_Cat_dir)\n\ntrain_Dog_dir = os.path.join(train_dir, 'Dog')\nos.mkdir(train_Dog_dir)\n\nvalidation_Cat_dir = os.path.join(validation_dir, 'Cat')\nos.mkdir(validation_Cat_dir)\n\nvalidation_Dog_dir = os.path.join(validation_dir, 'Dog')\nos.mkdir(validation_Dog_dir)\n\ntest_Cat_dir = os.path.join(test_dir, 'Cat')\nos.mkdir(test_Cat_dir)\n\ntest_Dog_dir = os.path.join(test_dir, 'Dog')\nos.mkdir(test_Dog_dir)","005fb676":"# copy images from the whole dataset to different folders :\n\n# copy the first 1000 cats images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Cat', fname)\n    dst = os.path.join(train_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# copy the following 500 cats images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Cat', fname)\n    dst = os.path.join(validation_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copy the following 500 cats images to the folder test_dir    \nfnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Cat', fname)\n    dst = os.path.join(test_Cat_dir, fname)\n    shutil.copyfile(src, dst)\n\n    \n# copy the first 1000 dogs images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Dog', fname)\n    dst = os.path.join(train_Dog_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# copy the following 500 dogs images to the folder train_dir \nfnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Dog', fname)\n    dst = os.path.join(validation_Dog_dir, fname)\n    shutil.copyfile(src, dst)\n\n# copy the following 500 dogs images to the folder test_dir    \nfnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir + '\/Dog', fname)\n    dst = os.path.join(test_Dog_dir, fname)\n    shutil.copyfile(src, dst)","3d4657b4":"# quick check\nprint(\"total training cat images :\", len(os.listdir(train_Cat_dir)))\nprint(\"total training dog images :\", len(os.listdir(train_Dog_dir)))\nprint(\"total validation cat images :\", len(os.listdir(validation_Cat_dir)))\nprint(\"total validation dog images :\", len(os.listdir(validation_Dog_dir)))\nprint(\"total test cat images :\", len(os.listdir(test_Cat_dir)))\nprint(\"total test dog images :\", len(os.listdir(test_Dog_dir)))","f72ffdb7":"# size of an image\nimg = cv2.imread(train_Cat_dir + '\/' + os.listdir(train_Cat_dir)[0])\nimg.shape","56486102":"# error in data : cf Annexe\n# We just replace 666.jpg by 665.jpg\nshutil.copyfile(train_Cat_dir + '\/665.jpg', train_Cat_dir + '\/666.jpg')","4d9de1ab":"# scale the values with a 1\/255 coefficient\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                        train_dir,\n                        target_size=(150,150),\n                        batch_size=20,\n                        class_mode='binary' \n                        )\n\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation_dir,\n                        target_size=(150,150),\n                        batch_size=20,\n                        class_mode='binary' \n                        )","18d55105":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation='relu',\n                       input_shape=(150,150, 3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',  # optimizers.RMSprop(lr=1e-4) ??\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","9cdb7a5f":"model.summary()","9b6ada2b":"history = model.fit_generator(\n            train_generator,\n            steps_per_epoch=100,\n            epochs=30, \n            validation_data=validation_generator,\n            validation_steps=50\n)","f3a510a2":"# save the trained model\nmodel.save('classifying_cats_dogs_small_1.h5')","f50fb8bb":"# evaluate the model\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='training')\nplt.plot(epochs, val_acc, 'b', label='validation')\nplt.title('Accuracy during Training and Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='training')\nplt.plot(epochs, val_loss, 'b', label='validation')\nplt.title('Loss during Training and Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","fdb88f80":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2, \n                                  horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                        train_dir,\n                        target_size=(150,150),\n                        batch_size=32,\n                        class_mode='binary' \n                        )\n\nvalidation_generator = test_datagen.flow_from_directory(\n                        validation_dir,\n                        target_size=(150,150),\n                        batch_size=32,\n                        class_mode='binary' \n                        )","6b355785":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation='relu',\n                       input_shape=(150,150, 3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=1e-4), \n             loss='binary_crossentropy',\n             metrics=['accuracy'])","8f64f55a":"history = model.fit_generator(\n            train_generator,\n            #steps_per_epoch=100,     \n            epochs=100, \n            validation_data=validation_generator,\n            #validation_steps=50      \n)","65e35b91":"# save the trained model\nmodel.save('classifying_cats_dogs_small_2.h5')","ba2632be":"# evaluate the model\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'bo', label='training')\nplt.plot(epochs, val_acc, 'b', label='validation')\nplt.title('Accuracy during Training and Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='training')\nplt.plot(epochs, val_loss, 'b', label='validation')\nplt.title('Loss during Training and Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","bb8317f1":"from pathlib import Path\nimport PIL\nfrom PIL import UnidentifiedImageError\n\npath = Path(train_Cat_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)\n\npath = Path(train_Dog_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)\n            \npath = Path(validation_Cat_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)\n\npath = Path(validation_Dog_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)\n\npath = Path(test_Cat_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)\n\npath = Path(test_Dog_dir).rglob(\"*.jpg\")\nfor img_p in path:\n    try:\n        img = PIL.Image.open(img_p)\n    except PIL.UnidentifiedImageError:\n            print(img_p)","18e406d3":"# We just replace 666.jpg by 665.jpg\nshutil.copyfile(train_Cat_dir + '\/665.jpg', train_Cat_dir + '\/666.jpg')","9a4bd6c1":"***\n# Reference \n\n* book : Francois Chollet, L'apprentissage profond avec Python ","030b59e3":"***\n# **Improve the model**\n\nSome techniques :\n* dropout\n* data augmentation.\n\n**Data augmentation** creates some 'new' training data with the existing training data, by applying some random transformations (rotation, translation, ...).\n\nWe just use **ImageDataGenerator()** with some additional arguments. \n\nThe augmented data are still pretty correlated, we can add a dropout layer.  ","850d5ba2":"## Prepare the data with Data Augmentation\n\nWe only use Data Augmentation for the training data, not the validation data. ","75acc9fd":"***\n# **Train and Evaluate the model**\n\nWe use **fit_generator()** instead of the classical fit(), with arguments :\n* the generator for the training data\n* steps_per_epoch : number of batches for each epoch\n* epochs\n* validation_data\n* validation_steps.","d4a48515":"***\n\n# **Build the Convolution Neural Network model**","6044d574":"## Train and Evaluate the model\n\nNB : steps_per_epoch and validation_steps removed because the training stops after 1 epoch\n([stackoverflow](https:\/\/stackoverflow.com\/questions\/60579988\/keras-stops-after-1-completed-epoch))","e64c3283":"The model is in overfitting. ","0e769589":"***\n# **Data**\n\n* Whole dataset : around 25 000 images (around 12 500 of each class)\n  \n* We use just a small part of those images. \n\n* Steps \n  * Load the dataset\n  * Create 3 sets :\n    * a training set with 1000 images\n    * a validation set with 500 images\n    * a test set with 500 images.\n\n* Functions we use :\n  * os.mkdir() : create a new folder\n  * os.path.join(path, string) : add the string to the path\n  * shutil.copyfile(source, destination) : copy the file from the source to the destination.\n\n* NB : ignore the potential error messages due to multiple use of mkdir to create the same folder.","1aa9c263":"***\n# Annexe : an error in the data !\n\nThere was an error when I was training the model (...PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7ff1343af3b0>\n...) \n\nActually, there was an error with the cat image 666 (0 octect), detected with the following code ([stackoverflow](https:\/\/stackoverflow.com\/questions\/67505710\/pil-unidentifiedimageerror-cannot-identify-image-file-io-bytesio-object)) :","0504dfab":"## Construct the model with Dropout","2bf276eb":"***\n\n# **Prepare the data**\n\nMain Steps :\n* read the images\n* convert from JPEG to RGB\n* convert from RGB to tensor with floats\n* transform the values between 0 and 255 into values between 0 and 1\n* pack the images into batches.\n\nThose steps are performed by the class **ImageDataGenerator**. \n\nWe then use the function **flow_from_directory()** with arguments :\n* directory : folder where the data are stored\n* target_size : modify the images size into the target_size\n* batch_size\n* class_mode. \n\nHere, the generator creates batches with\n* 20 images, each with the shape (150, 150, 3)\n* 20 labels.","72d7674c":"# **Classifying Dogs and Cats : from scratch**\n\nOriginal dataset : [Cats-vs-Dogs : image dataset for binary classification](https:\/\/www.kaggle.com\/shaunthesheep\/microsoft-catsvsdogs-dataset)\n\n***"}}