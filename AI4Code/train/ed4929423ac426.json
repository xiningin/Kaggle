{"cell_type":{"a1b8f9c8":"code","5404d0be":"code","1beafe47":"code","fb6a8d85":"code","731a1c40":"code","0c42895a":"code","7126fd17":"code","790edaa3":"code","179f690e":"code","98708f2b":"code","1bcf0e3c":"code","94f47ac3":"code","186e6f6e":"code","7adaffbb":"code","6058e951":"code","294f2e5a":"code","46627422":"code","e12f42ed":"code","326300ad":"code","ad13a7d7":"code","720e1ab1":"code","bd1352cb":"code","ffb155f3":"code","10b24911":"code","242dfb26":"code","28b5750f":"code","9c744859":"markdown"},"source":{"a1b8f9c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5404d0be":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","1beafe47":"# First fetch train and test dataset in your notebook\n\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","fb6a8d85":"# Check the data format and first 5 row to better understanding for column and datatypes\ntrain.head()","731a1c40":"test.head()","0c42895a":"# Check the number of records in train and test dataset\ntrain.shape, test.shape","7126fd17":"# To get all columns in dataset\ntrain.columns","790edaa3":"# Basic information of dataset, you can find data type and if any missing data.\n# Here you can Sex, Cabin and Embarked do not have complete 891 data.\ntrain.info()","179f690e":"# To find out number of Null values in train dataset\ntrain.isnull().sum()","98708f2b":"# To find out number of Null values in test dataset\ntest.isnull().sum()","1bcf0e3c":"# Fill all null value with their Mean value for train and test dataset\ntrain.Age = train.Age.fillna(train.Age.median())\ntest.Age = test.Age.fillna(test.Age.median())\ntest.Fare = test.Fare.fillna(test.Fare.median()) # Only one record in Test is NaN","94f47ac3":"# Now check after filling null values\ntrain.isnull().sum()","186e6f6e":"# Remove those column, that have either ID or not have much impact on prediction result\n# Be sure, you have to do same operation in both train and test dataset.\n\ndel_col = [\"PassengerId\",\"Name\",\"Embarked\",\"Cabin\",\"Ticket\"]\ntrain.drop(columns=  del_col ,inplace =True)\ntest.drop(columns=  del_col ,inplace =True)","7adaffbb":"train.columns","6058e951":"train.head()","294f2e5a":"# All column must be numerical value in your dataset to use any ML algorithm.\n# We have to take Sex column here, have to convert into numerical using LabelEncoder\n\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nlabelEncoder  = LabelEncoder()\ntrain['Sex'] = LabelEncoder().fit_transform(train['Sex'])   \ntest['Sex'] = LabelEncoder().fit_transform(test['Sex'])  ","46627422":"train.head()","e12f42ed":"# Partiiton our train data set into X (all column except target column) and y (only target column)\n# 'Servived' is the target column here in our dataset\n\ntrain_X = train.drop('Survived', axis = 1) # train_WithoutLabel\ntrain_y = train['Survived'] # train_onlyLabel\ntrain_X.shape, train_y.shape","326300ad":"# Implementing Logistic Regression Machine Learning Model on train_X , train_y \nfrom  sklearn.linear_model import LogisticRegression\nlg_model = LogisticRegression()\nlg_model.fit(train_X,train_y)","ad13a7d7":"from  sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nlg = LogisticRegression(max_iter = 2000)\nscores = cross_val_score(lg,train_X, train_y,cv=5)\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","720e1ab1":"# Here you can see, we got accuracy 78%, but we have lots of scope to make accuracy more better\n# We will see in next notebook","bd1352cb":"# Get the prediction from test dataset\npreds = lg_model.predict(test)\npreds","ffb155f3":"# Now prepare for final submission \n# Fetch all passendger ID from either Test or submission CSV\npassIDs = pd.read_csv(\"..\/input\/titanic\/test.csv\")[[\"PassengerId\"]].values","10b24911":"# Make one new Pandas DataFrame for our submission\ndf_for_submission = {'PassengerId': passIDs.ravel(), 'Survived': preds}\ndf_submission_predictions = pd.DataFrame(df_for_submission).set_index(['PassengerId'])\ndf_submission_predictions.head(10)","242dfb26":"# Create one final CSV output for your final Kaggle submission\ndf_submission_predictions.to_csv('Binod_submission_predictions_kaggle_1.csv')\n# You can see one new file \"Binod_submission_predictions_kaggle_1.csv\" generated in right top in output folder.","28b5750f":"# Thank you, please visit to other notebook and kindly give your valuable feedback and Vote.","9c744859":"Binod Suman first Kaggle notebook for Titanic"}}