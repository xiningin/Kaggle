{"cell_type":{"ba109d06":"code","116224ae":"code","41de123e":"code","00f05bfb":"code","1ceed6fb":"code","0e2f134d":"code","f82baef6":"code","57a03946":"code","2ad4147c":"code","9de5eab4":"code","680d466c":"code","9617f0b7":"code","c42c1d24":"code","9bd0a6db":"code","a0547c19":"code","31cd8fbf":"markdown","ba50ecca":"markdown","45a2ea2f":"markdown","32f3766e":"markdown","ae729fb9":"markdown","a9527597":"markdown","ff506c48":"markdown","b24cd03a":"markdown","06b2906f":"markdown"},"source":{"ba109d06":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","116224ae":"!nvidia-smi","41de123e":"# Check Python Version\n!python --version","00f05bfb":"# Check CUDA\/cuDNN Version\n!nvcc -V && which nvcc","1ceed6fb":"import sys\n!cp ..\/input\/rapids\/rapids.0.14.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","0e2f134d":"import cudf\nfrom cudf.core import Series\nimport math","f82baef6":"%time a = Series([9, 16, 25, 36, 49], dtype=np.float64)","57a03946":"a","2ad4147c":"%time a.applymap(lambda x : x**2)","9de5eab4":"%time a.applymap(lambda x: 1 if x < 18 else 2)","680d466c":"#defining averaging of sqare roots rolling window function\n\ndef foo(A):\n    sum = 0\n    for a in A:\n        sum = sum + math.sqrt(a)\n    return sum \/ len(A)","9617f0b7":"#defining averaging rolling window function\n\ndef foo2(A):\n    sum = 0\n    for a in A:\n        sum = sum + a\n    return sum \/ len(A)","c42c1d24":"%time a.rolling(3, 1, False).apply(foo)","9bd0a6db":"%time a.rolling(3, 1, False).apply(foo2)","a0547c19":"%time a.rolling(3, 1, True).apply(foo2)","31cd8fbf":"### Python Version","ba50ecca":"## rooling window udf\n----------------------------\n![image.png](attachment:image.png)\n\n(source: http:\/\/developer.download.nvidia.com\/video\/gputechconf\/gtc\/2020\/presentations\/s21393-combined-pythoncuda-jit-for-flexible-acceleration-in-rapids.pdf)","45a2ea2f":"### installing Rapids\n\n#### prerequists\n\nshould the rapids dataset have to be added into input folder before running the installation since\nit contains the libraries that needed to be installed.","32f3766e":"## InliningPython user defined functions (UDFs) into native CUDA kernels:\n* A combination of flexibility and performance\n* A very good example of the power of just-in-time (JIT) compilation\n* Userdoes not need to know CUDA****","ae729fb9":"# CUDF tutorials","a9527597":"### Check CUDA Version","ff506c48":"**cudf.core.Series.rolling(W, m, center).apply(some_custom_udf)**\n    \n    W - window size\n    m - minimum size of included element in the first window. eg: 1 means the first window will start\n        at the first element itself. But if it is two the first window will start with first 2 elements.\n    center - True or Flase. If true the result will be set at the center of the window. Else on edge of the window\n    ","b24cd03a":"# Setup:\n","06b2906f":"# Environment Sanity Check\n\nClick the Runtime dropdown at the top of the page, then Change Runtime Type and confirm the instance type is GPU.\n\nCheck the output of !nvidia-smi to make sure you've been allocated a Tesla T4, P4, or P100"}}