{"cell_type":{"4549290e":"code","0601a09c":"code","37768d4c":"code","d2139dde":"code","49286f18":"code","d3aae92d":"code","7f540e60":"code","33d18309":"code","d98a244c":"code","9ee6f217":"code","07609c81":"code","a836c7cc":"code","2bd26ca3":"code","b9050183":"code","620b6dde":"code","345c5228":"code","1f9dc65e":"code","98a2ac0f":"code","b57c85c8":"code","cd6c7a3d":"code","e1db1ec4":"code","d35a29ca":"code","fe1f5cd3":"code","f93f30cc":"code","2b3984e3":"code","9f9b5f4d":"code","39c85eb4":"code","ef709566":"code","4e379718":"code","65c52ea0":"code","c8e596cf":"code","e95ba068":"code","ec3279c1":"code","b05378ae":"code","38038450":"code","04f911d7":"code","9c09c0fa":"code","a606f376":"code","4d8b5688":"code","67efe45b":"code","568fea99":"code","fb613453":"code","e240343a":"code","7cac478c":"code","52182abf":"code","fc3e8378":"code","41b18b39":"code","cb68be71":"code","993a01ec":"code","da86615d":"code","ff5ed91f":"code","753ad49f":"code","61169bc4":"code","8b639041":"code","19a1d0e8":"code","c6d26870":"code","8025c989":"code","d169f802":"code","63916ba8":"code","943c2eb3":"code","302ec784":"code","3429ad5b":"code","bfe316ff":"code","b65783d1":"code","7e339306":"code","8373565c":"code","7ca3a018":"code","54668573":"code","346c84ee":"code","a0992994":"code","75b4cce0":"code","279edcca":"code","97958263":"code","ecbc4bad":"code","0ee9db69":"markdown","d98de118":"markdown","fdd84bd7":"markdown","bd02cbbd":"markdown","bb995eac":"markdown"},"source":{"4549290e":"import os\nimport shutil\nimport cv2\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.python.ops.numpy_ops import np_config\nfrom tqdm import tqdm","0601a09c":"input_data_path='\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images'\nlabels=os.listdir(input_data_path)\nprint(labels)","37768d4c":"labels.pop()\nprint(labels)","d2139dde":"def get_image_path():\n    image_path_list,name_list=[],[]\n    for label in tqdm(labels):\n        folder_path=os.path.join(input_data_path,label)\n        image_set=random.sample(os.listdir(folder_path),1)\n        for file in image_set:\n            file_path=os.path.join(folder_path,file)\n            image_path_list.append(file_path)\n            name_list.append(label)\n    return image_path_list,name_list\nimage_path_list,name_list=get_image_path()","49286f18":"def plot_images(image_path_list,name_list,row,col):\n    fig=plt.figure(figsize=(16,16))\n    for i in range(len(name_list)):\n        fig.add_subplot(row,col,i+1)\n        plt.title(name_list[i])\n        plt.axis('off')\n        plt.imshow(cv2.imread(image_path_list[i]))\n    plt.tight_layout()\n    plt.show()\nplot_images(\n    image_path_list=image_path_list,\n    name_list=name_list,\n    row=1,col=2\n)","d3aae92d":"data_dir='\/kaggle\/data'\ntrain_path=os.path.join(data_dir,'train')\nvalid_path=os.path.join(data_dir,'valid')\ntest_path=os.path.join(data_dir,'test')","7f540e60":"def create_dir():\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n        os.mkdir(train_path)\n        os.mkdir(valid_path)\n        os.mkdir(test_path)\n        for label in tqdm(labels):\n            os.mkdir(os.path.join(train_path,label))\n            os.mkdir(os.path.join(valid_path,label))\n            os.mkdir(os.path.join(test_path,label))\ncreate_dir()","33d18309":"def check_dir():\n    print(f'{data_dir}: {os.path.isdir(data_dir)}')\n    print(f'{train_path}: {os.path.isdir(train_path)}')\n    print(f'{valid_path}: {os.path.isdir(valid_path)}')\n    print(f'{test_path}: {os.path.isdir(test_path)}')\n    for label in labels:\n        print(f'{os.path.join(train_path,label)}: {os.path.isdir(os.path.join(train_path,label))}')\n        print(f'{os.path.join(valid_path,label)}: {os.path.isdir(os.path.join(valid_path,label))}')\n        print(f'{os.path.join(test_path,label)}: {os.path.isdir(os.path.join(test_path,label))}')\ncheck_dir()","d98a244c":"def load_images(n,mode,src_dir,dest_dir):\n    for label in labels:\n        src_folder=os.path.join(src_dir,label)\n        dest_folder=os.path.join(dest_dir,label)\n        image_set=random.sample(os.listdir(src_folder),n)\n        if mode=='train':\n            print(f'Loading the training images for {label}')\n        elif mode=='valid':\n            print(f'Loading the validation images for {label}')\n        elif mode=='test':\n            print(f'Loading the testing images for {label}')\n        else:\n            print('Invalid mode of operation')\n            return\n        for file in tqdm(image_set):\n            file_path=os.path.join(src_folder,file)\n            shutil.copy(file_path,dest_folder)","9ee6f217":"load_images(\n    n=7000,mode='train',\n    src_dir=input_data_path,\n    dest_dir=train_path\n)","07609c81":"load_images(\n    n=3000,mode='valid',\n    src_dir=input_data_path,\n    dest_dir=valid_path\n)","a836c7cc":"load_images(\n    n=2000,mode='test',\n    src_dir=input_data_path,\n    dest_dir=test_path\n)","2bd26ca3":"target_size=(64,64)\nbatch_size=32\nepochs=40","b9050183":"datagen=ImageDataGenerator(\n    rescale=1.\/255,\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n)\n\ntrain_data=ImageDataGenerator(\n    rescale=1.\/255,\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    horizontal_flip=True,vertical_flip=True\n).flow_from_directory(\n    directory=train_path,target_size=target_size,\n    classes=labels,batch_size=batch_size\n)\n\nvalid_data=datagen.flow_from_directory(\n    directory=valid_path,target_size=target_size,\n    classes=labels,batch_size=batch_size\n)\n\ntest_data=datagen.flow_from_directory(\n    directory=test_path,target_size=target_size,\n    classes=labels,batch_size=batch_size,shuffle=False\n)","620b6dde":"class MCDropout(layers.Dropout):\n    def call(self,inputs):\n        return super().call(inputs,training=True)","345c5228":"lrn_layer=layers.Lambda(\n    lambda x: tf.nn.local_response_normalization(\n        input=x,depth_radius=2,bias=1,\n        alpha=0.00002,beta=0.75\n    )\n)","1f9dc65e":"class ResnetLayer(layers.Layer):\n    def __init__(self,filters,kernel_size=3,strides=1,n_conv=4,**kwargs):\n        super().__init__(**kwargs)\n        self.resnet_layer=[]\n        for _ in range(n_conv):\n            self.resnet_layer.append(\n                layers.Conv2D(\n                    filters=filters,kernel_size=kernel_size,\n                    strides=strides,padding='same',activation='relu'\n                )\n            )\n            self.resnet_layer.append(layers.BatchNormalization())\n    def call(self,inputs):\n        out=inputs\n        for resnet_layer in self.resnet_layer:\n            out=resnet_layer(out)\n        out=layers.Concatenate()([out,inputs])\n        return tf.keras.activations.relu(out)","98a2ac0f":"class InceptionModule(layers.Layer):\n    def __init__(self,filters_list,**kwargs):\n        super().__init__(**kwargs)\n        self.layer_list=[]\n        for i in range(len(filters_list)):\n            if i==0:\n                google_net_layer=tf.keras.models.Sequential([\n                    layers.Conv2D(\n                        filters=filters_list[i],kernel_size=1,\n                        strides=1,padding='same',activation='relu'\n                    ),\n                    layers.BatchNormalization()\n                ])\n            elif i!=len(filters_list)-1:\n                google_net_layer=tf.keras.models.Sequential([\n                    layers.Conv2D(\n                        filters=filters_list[i],kernel_size=1,\n                        strides=1,padding='same',activation='relu'\n                    ),\n                    layers.BatchNormalization(),\n                    layers.Conv2D(\n                        filters=int(filters_list[i])\/2,kernel_size=2*i-1,\n                        strides=1,padding='same',activation='relu'\n                    ),\n                    layers.BatchNormalization()\n                ])\n            else:\n                google_net_layer=tf.keras.models.Sequential([\n                    layers.MaxPool2D(\n                        pool_size=3,strides=1,\n                        padding='same'\n                    ),\n                    layers.Conv2D(\n                        filters=filters_list[i],kernel_size=1,\n                        strides=1,padding='same',activation='relu'\n                    ),\n                    layers.BatchNormalization()\n                ])\n            self.layer_list.append(google_net_layer)\n    def call(self,inputs):\n        output_list=[]\n        for google_net_path in self.layer_list:\n            out=google_net_path(inputs)\n            output_list.append(out)\n        output=layers.Concatenate()(output_list)\n        return tf.keras.activations.relu(output)","b57c85c8":"def build_model_googlenet_resnet(target_size,n_conv=4,rate=0.45):\n    model=[]\n    steps=int(np.log2(target_size[0]))\n    model.append(layers.Input(shape=(*target_size,3)))\n    filters=8\n    cnt=0\n    for _ in range(steps):\n        if cnt==0:\n            model.append(InceptionModule(\n                filters_list=[int(filters\/2),filters,filters*2,int(filters\/2)]\n                )\n            )\n        else:\n            model.append(ResnetLayer(filters=filters,n_conv=n_conv))\n        model.append(lrn_layer)\n        model.append(layers.AvgPool2D(\n            pool_size=2,\n            strides=2\n        ))\n        filters*=2\n        cnt=(cnt+1)%2\n    model+=[\n        layers.Flatten(),\n        MCDropout(rate),\n        layers.Dense(units=4096,activation='relu'),\n        MCDropout(rate),\n        layers.Dense(units=4096,activation='relu'),\n        layers.Dense(units=len(labels),activation='softmax'),\n    ]\n    return tf.keras.models.Sequential(model)","cd6c7a3d":"model=build_model_googlenet_resnet(target_size=target_size)","e1db1ec4":"model.summary()","d35a29ca":"ckpt_path1='\/kaggle\/model_checkpoint1'\nif not os.path.isdir(ckpt_path1):\n    os.mkdir(ckpt_path1)","fe1f5cd3":"model_checkpoint=ModelCheckpoint(\n    filepath=ckpt_path1,monitor='val_accuracy',\n    save_best_only=True,save_weights_only=True,\n    mode='max'\n)","f93f30cc":"model.compile(optimizer=Adam(learning_rate=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])","2b3984e3":"history1=model.fit(\n    x=train_data,batch_size=batch_size,epochs=epochs,\n    callbacks=[model_checkpoint],validation_data=valid_data\n)","9f9b5f4d":"def accuracy(data,steps=20):\n    y_prob_stack=np.stack([np.array(model.predict(data)) for _ in tqdm(range(steps))])\n    y_prob=np.mean(y_prob_stack,axis=0)\n    cm=confusion_matrix(y_true=data.classes,y_pred=np.argmax(y_prob,axis=-1))\n    acc=cm.trace()\/cm.sum()\n    return acc*100","39c85eb4":"print(f'The accuracy of the model on test set is {accuracy(test_data)}')","ef709566":"model.load_weights(ckpt_path1)","4e379718":"print(f'The accuracy of the model with MCDropout on test set is {accuracy(test_data)}')","65c52ea0":"def plot_history(history):\n    val_loss=history.history['val_loss']\n    train_loss=history.history['loss']\n    plt.figure()\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.plot(train_loss,'bo--')\n    plt.plot(val_loss,'ro--')\n    plt.title('Loss vs Epochs')\n    plt.legend(['Train','Valid'])\n    plt.tight_layout()\n    plt.show()","c8e596cf":"plot_history(history1)","e95ba068":"tf.keras.backend.clear_session()","ec3279c1":"class BottleNeckLayer(tf.keras.models.Model):\n    def __init__(self,out_channels,n_conv=3,ratio=2,kernel_size=3,strides=1):\n        super().__init__()\n        self.model=[]\n        intermediate_filters=int(out_channels\/ratio)\n        self.model.append(layers.Conv2D(filters=intermediate_filters,kernel_size=1,strides=1,activation='relu',padding='same'))\n        for i in range(n_conv):\n            self.model.append(layers.Conv2D(filters=intermediate_filters,kernel_size=kernel_size,strides=strides,activation='relu',padding='same'))\n            self.model.append(layers.BatchNormalization())\n        self.model.append(layers.Conv2D(filters=out_channels,kernel_size=1,strides=1,activation='relu',padding='same'))\n        self.model=tf.keras.models.Sequential(self.model)\n    def call(self,inputs):\n        out=self.model(inputs)\n        out=layers.Concatenate()([inputs,out])\n        return tf.keras.activations.relu(out)","b05378ae":"def build_model_bottleneck_resnet(size=target_size[0],n_conv=4,ratio=2):\n    steps=int(np.log2(size))\n    model=[]\n    out_channels=16\n    model.append(layers.Input(shape=(size,size,3)))\n    model.append(layers.Conv2D(filters=out_channels,kernel_size=1,strides=1,activation='relu',padding='same'))\n    for i in range(steps):\n        model.append(BottleNeckLayer(out_channels=out_channels,n_conv=n_conv,ratio=ratio))\n        model.append(lrn_layer)\n        model.append(layers.AvgPool2D(pool_size=2,strides=2))\n        out_channels*=2\n    model+=[\n        layers.Flatten(),\n        layers.Dense(units=4096,activation='relu'),\n        layers.Dense(units=4096,activation='relu'),\n        layers.Dense(units=len(labels),activation='softmax')\n    ]\n    return tf.keras.models.Sequential(model)","38038450":"model=build_model_bottleneck_resnet(size=target_size[0])","04f911d7":"model.summary()","9c09c0fa":"ckpt_path2='\/kaggle\/model_checkpoint2'\nif not os.path.isdir(ckpt_path2):\n    os.mkdir(ckpt_path2)","a606f376":"model_checkpoint=ModelCheckpoint(\n    filepath=ckpt_path2,monitor='val_accuracy',\n    save_best_only=True,save_weights_only=True,\n    mode='max'\n)","4d8b5688":"model.compile(optimizer=Adam(learning_rate=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])","67efe45b":"history2=model.fit(\n    x=train_data,batch_size=batch_size,epochs=epochs,\n    callbacks=[model_checkpoint],validation_data=valid_data\n)","568fea99":"print(f'The accuracy of the model on test set is {accuracy(test_data)}')","fb613453":"model.load_weights(ckpt_path2)","e240343a":"print(f'The accuracy of the model with MCDropout on test set is {accuracy(test_data)}')","7cac478c":"plot_history(history2)","52182abf":"tf.keras.backend.clear_session()","fc3e8378":"def build_model_resnet(target_size,n_conv=4,rate=0.45):\n    model=[]\n    steps=int(np.log2(target_size[0]))\n    model.append(layers.Input(shape=(*target_size,3)))\n    filters=8\n    for _ in range(steps):\n        model.append(ResnetLayer(filters=filters,n_conv=n_conv))\n        model.append(lrn_layer)\n        model.append(layers.AvgPool2D(\n            pool_size=2,\n            strides=2\n        ))\n        filters*=2\n    model+=[\n        layers.Flatten(),\n        MCDropout(rate),\n        layers.Dense(units=4096,activation='relu'),\n        MCDropout(rate),\n        layers.Dense(units=4096,activation='relu'),\n        layers.Dense(units=len(labels),activation='softmax'),\n    ]\n    return tf.keras.models.Sequential(model)","41b18b39":"model=build_model_resnet(target_size=target_size)","cb68be71":"model.summary()","993a01ec":"ckpt_path3='\/kaggle\/model_checkpoint3'\nif not os.path.isdir(ckpt_path3):\n    os.mkdir(ckpt_path3)","da86615d":"model_checkpoint=ModelCheckpoint(\n    filepath=ckpt_path3,monitor='val_accuracy',\n    save_best_only=True,save_weights_only=True,\n    mode='max'\n)","ff5ed91f":"model.compile(optimizer=Adam(learning_rate=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])","753ad49f":"history3=model.fit(\n    x=train_data,batch_size=batch_size,epochs=epochs,\n    callbacks=[model_checkpoint],validation_data=valid_data\n)","61169bc4":"print(f'The accuracy of the model on test set is {accuracy(test_data)}')","8b639041":"model.load_weights(ckpt_path3)","19a1d0e8":"print(f'The accuracy of the model with MCDropout on test set is {accuracy(test_data)}')","c6d26870":"plot_history(history3)","8025c989":"tf.keras.backend.clear_session()","d169f802":"np_config.enable_numpy_behavior()","63916ba8":"class ConvStack(layers.Layer):\n    def __init__(self,filters,n_conv=4,kernel_size=3,strides=1,**kwargs):\n        super().__init__(**kwargs)\n        self.resnet_layers=[]\n        for _ in range(n_conv):\n            self.resnet_layers.append(layers.Conv2D(\n                filters=filters,kernel_size=kernel_size,\n                strides=1,padding='same',activation='relu'\n            ))\n            self.resnet_layers.append(layers.BatchNormalization())\n    def call(self,inputs):\n        output=inputs\n        for resnet_layer in self.resnet_layers:\n            output=resnet_layer(output)\n        return output","943c2eb3":"class SE_block(layers.Layer):\n    def __init__(self,output_channels,**kwargs):\n        super().__init__(**kwargs)\n        self.block=[]\n        self.block.append(layers.GlobalAveragePooling2D())\n        if output_channels<128:\n            self.block.append(layers.Dense(units=int(output_channels)\/2,activation='relu'))\n        else:\n            self.block.append(layers.Dense(units=int(output_channels)\/16,activation='relu'))\n        self.block.append(layers.Dense(units=output_channels,activation='sigmoid'))\n        self.out_channels=output_channels\n    def call(self,inputs):\n        output=inputs\n        for block_layer in self.block:\n            output=block_layer(output)\n        outputs=output.reshape(inputs.shape[0],1,1,self.out_channels)\n        outputs=layers.Multiply()([inputs,outputs])\n        return outputs","302ec784":"class SEResnet(layers.Layer):\n    def __init__(self,filters,kernel_size=3,strides=1,n_conv=4,**kwargs):\n        super().__init__(**kwargs)\n        self.hidden_layers=[]\n        self.hidden_layers.append(ConvStack(\n            filters=filters,n_conv=n_conv,\n            kernel_size=kernel_size,strides=strides\n        ))\n        self.hidden_layers.append(SE_block(output_channels=filters))\n    def call(self,inputs):\n        output=inputs\n        for hidden_layer in self.hidden_layers:\n            output=hidden_layer(output)\n        output=layers.Concatenate()([output,inputs])\n        return tf.keras.activations.relu(output)","3429ad5b":"def build_model_se_net(n_conv=4,rate=0.45,target_size=target_size):\n    steps=int(np.log2(int(target_size[0])))\n    inputs=layers.Input(shape=(*target_size,3),batch_size=batch_size)\n    filters=8\n    model=SEResnet(filters=filters,n_conv=n_conv)(inputs)\n    model=layers.AvgPool2D(pool_size=2,strides=2)(model)\n    model=layers.Lambda(lrn_layer)(model)\n    for _ in tqdm(range(steps-1)):\n        filters*=2\n        model=SEResnet(filters=filters,n_conv=n_conv)(model)\n        model=layers.AvgPool2D(pool_size=2,strides=2)(model)\n        model=layers.Lambda(lrn_layer)(model)\n    model=MCDropout(rate)(model)\n    model=layers.Conv2D(\n        filters=4096,kernel_size=1,\n        padding='valid',strides=1\n    )(model)\n    model=MCDropout(rate)(model)\n    model=layers.Conv2D(\n        filters=4096,kernel_size=1,\n        padding='valid',strides=1\n    )(model)\n    model=layers.Flatten()(model)\n    model=layers.Dense(units=len(labels),activation='softmax')(model)\n    model=tf.keras.models.Model(inputs=inputs,outputs=model)\n    model.compile(optimizer=Adam(learning_rate=0.0003),loss='categorical_crossentropy',metrics=['accuracy'])\n    return model","bfe316ff":"model=build_model_se_net(target_size=target_size)","b65783d1":"model.summary()","7e339306":"ckpt_path4='\/kaggle\/ckpt'\nif not os.path.isdir(ckpt_path4):\n    os.mkdir(ckpt_path4)","8373565c":"model_checkpoint=ModelCheckpoint(\n    filepath=ckpt_path4,monitor='val_accuracy',\n    save_best_only=True,save_weights_only=True,\n    mode='max'\n)","7ca3a018":"tf.config.run_functions_eagerly(True)","54668573":"history4=model.fit(\n    x=train_data,batch_size=batch_size,epochs=epochs,\n    validation_data=valid_data,callbacks=[model_checkpoint]\n)","346c84ee":"print(f'The accuracy of the model on test set is {accuracy(test_data)}')","a0992994":"model.load_weights(ckpt_path4)","75b4cce0":"print(f'The accuracy of the model with MCDropout on test set is {accuracy(test_data)}')","279edcca":"plot_history(history4)","97958263":"tf.keras.backend.clear_session()","ecbc4bad":"googlenet_resnet_val_loss=history1.history['val_loss']\nbottleneck_resnet_val_loss=history2.history['val_loss']\nresnet_val_loss=history3.history['val_loss']\nse_resnet_val_loss=history4.history['val_loss']\nplt.figure()\nplt.plot(googlenet_resnet_val_loss,'bo--')\nplt.plot(bottleneck_resnet_val_loss,'ro--')\nplt.plot(resnet_val_loss,'go--')\nplt.plot(se_resnet_val_loss,'co--')\nplt.title('Model validation loss vs Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Validation Loss')\nplt.legend(['Googlenet Resnet','Bottleneck Resnet','Resnet','SE-resnet'])\nplt.show()","0ee9db69":"## Data loading and preprocessing","d98de118":"## GoogleNet-Resnet","fdd84bd7":"## Resnet","bd02cbbd":"## Bottleneck Resnet","bb995eac":"## SE-Resnet"}}