{"cell_type":{"e7a63eab":"code","67529e14":"code","612afdc9":"code","cd82b11e":"code","ea178c12":"code","4420d8e0":"code","23152d81":"code","d25f7f9b":"code","289668cf":"code","c709fab8":"code","9fd2ad45":"code","3c797fff":"code","087f5db3":"code","c38c1b12":"code","09de5dcf":"code","3b314630":"code","3ebc54d8":"code","a4d0a452":"code","5b163d78":"code","6c8bcba6":"code","c3242f53":"code","26feac65":"code","a69c6b88":"code","c2877219":"code","350bf9f7":"code","5e69874d":"code","5af1e7eb":"code","ff6e7149":"code","8279b516":"code","0cb64910":"code","2f9eae7c":"code","042c30b6":"code","aa2722a9":"code","b674f077":"code","18212e89":"code","baf14d27":"code","c13ca7be":"code","40f77d94":"code","4ef775e1":"code","b42814c6":"code","f476c5d5":"code","d63d5ae0":"code","a995cf14":"code","23391105":"code","fbdb019e":"code","fb256f4b":"code","a21fdbf2":"code","a5b8308d":"markdown"},"source":{"e7a63eab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","67529e14":"from platform import python_version\n\nprint('Python version on this Jupyter Notebook:', python_version())","612afdc9":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","cd82b11e":"sns.set_palette(\"Accent\")\nsns.set(style=\"whitegrid\", color_codes=True, font_scale=1.5)\n\ncolor = sns.color_palette()","ea178c12":"data =pd.read_csv('..\/input\/titanic\/train.csv')\ndata.head()","4420d8e0":"data.tail()","23152d81":"data.shape","d25f7f9b":"data.info()","289668cf":"data.dtypes","c709fab8":"data.var()","9fd2ad45":"data.duplicated()","3c797fff":"print(\"Rows:\", data.shape[0])\nprint(\"Columns:\", data.shape[1])","087f5db3":"print(\"\\nMissing values :  \", data.isnull().sum().values.sum())\nprint(\"\\nUnique values :  \\n\",data.nunique())","c38c1b12":"data.drop([\"Name\", \"Ticket\", \"Cabin\"], axis = 1, inplace = True)\ndata.head()","09de5dcf":"data.Survived.max()","3b314630":"data.Survived.min()","3ebc54d8":"df = data.reset_index().drop(\"index\", axis = 1)\ndf","a4d0a452":"data.describe()","5b163d78":"corr = data.corr()\ncorr","6c8bcba6":"plt.figure(figsize=(18.2, 8))\n\nax = sns.distplot(data['Age']);\nplt.title(\"Distribution\", fontsize=20)\nplt.axvline(data['Age'].mean(), color='k')\nplt.axvline(data['Age'].median(), color='r')\nplt.axvline(data['Age'].mode()[0], color='g');","c3242f53":"plt.figure(figsize=(20,11))\n\ndf_corr = data.corr()\nax = sns.heatmap(df_corr, annot=True, vmin=0, vmax=8000, cmap=\"YlGnBu\", linewidths=.5, annot_kws={'size':14} ,fmt=\".1f\") \nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","26feac65":"plt.figure(figsize=(20,11))\n\nmask = np.triu(np.ones_like(corr, dtype = bool))\nsns.heatmap(corr, mask = mask, annot = True, cmap=\"YlGnBu\", linewidths=.5, annot_kws={'size':15} ,fmt=\".1f\")\nplt.show()","a69c6b88":"plt.figure(figsize=(10, 8))\n\nax = sns.countplot(data[\"Sex\"])","c2877219":"plt.figure(figsize=(10, 8))\n\nax = sns.countplot(data[\"Embarked\"])","350bf9f7":"plt.figure(figsize=(10, 8))\n\nsns.boxplot(x=\"Sex\" , y=\"Age\", data = data)","5e69874d":"plt.figure(figsize=(15, 8))\n\nplt.pie(data.groupby('Sex')['Sex'].count(), labels=['Masculino','Feminino'], autopct='%1.1f%%');","5af1e7eb":"plt.figure(figsize=(20.5, 8))\n\nsns.barplot(x=\"Sex\", y=\"Age\", data = data, hue=\"Embarked\")","ff6e7149":"plt.figure(figsize=(10, 8))\n\nax = sns.scatterplot(data=df, x = \"Fare\", y = \"Age\", hue = \"Embarked\")","8279b516":"plt.figure(figsize=(10, 8))\n\nax = sns.scatterplot(data=df, x = \"Age\", y = \"Fare\", hue = \"Embarked\")","0cb64910":"data.hist(bins = 40, figsize=(20.2, 20))\nplt.show()","2f9eae7c":"fig1 , axes = plt.subplots(nrows=3,ncols=3 , figsize = (20,20))\n\nsns.distplot(data[\"PassengerId\"] , ax=axes[0, 0])\nsns.distplot(data[\"Survived\"] ,  ax=axes[0, 1])\nsns.distplot(data[\"Pclass\"] , ax=axes[0, 2])\nsns.distplot(data[\"Age\"], ax=axes[1, 0] )\nsns.distplot(data[\"SibSp\"] , ax=axes[1, 1] )\nsns.distplot(data[\"Parch\"] , ax=axes[1, 2] )\nsns.distplot(data[\"Fare\"] , ax=axes[2, 0])\nsns.countplot(data[\"Sex\"], ax=axes[2, 1])\nsns.countplot(data[\"Embarked\"], ax=axes[2, 2])\n\nplt.show()","042c30b6":"sns.pairplot(data)","aa2722a9":"data['Embarked'].loc[data['Embarked']=='C']=1\ndata['Embarked'].loc[data['Embarked']=='S']=0\n\ndata","b674f077":"y = data['Survived']\nx = data.drop('Survived', axis=1)","18212e89":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state=42)","baf14d27":"x_train.shape","c13ca7be":"y_train.shape","40f77d94":"x_test.shape","4ef775e1":"y_test.shape","b42814c6":"from category_encoders import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_pipeline = Pipeline(steps = [\n    ('one-hot encoder', OneHotEncoder()),\n    ('imputer', SimpleImputer(strategy = \"mean\")),\n    ('tree', DecisionTreeClassifier(max_depth = 3, random_state = 0))\n])\n\nmodel_pipeline_fit_1 = model_pipeline.fit(x_train, y_train)\nmodel_pipeline_fit_1","f476c5d5":"model_pipeline_pred = model_pipeline.predict(x_test)\nmodel_pipeline_pred","d63d5ae0":"from sklearn.metrics import accuracy_score, confusion_matrix\n\naccuracy = accuracy_score(y_test, model_pipeline_pred)\nmatrix_confusion = confusion_matrix(y_test, model_pipeline_pred)\n\nprint(\"Accuracy - pipeline: %.2f\" % (accuracy * 100))","a995cf14":"matrix = sns.heatmap(matrix_confusion, vmin=0, vmax=400, cmap = \"BuGn_r\", linewidths=.6, annot=True ,annot_kws={'size':14} ,fmt=\".1f\")\nplt.yticks(rotation=0)\nplt.show()","23391105":"from sklearn.metrics import roc_curve, roc_auc_score\n\nroc = model_pipeline.predict_proba(x_test)[:,1]\ntfp, tvp, limite = roc_curve(y_test, roc)\nprint('roc_auc', roc_auc_score(y_test, roc))\n\nplt.subplots(1, figsize=(5,5))\nplt.title('CROC curve')\nplt.plot(tfp,tvp)\nplt.xlabel('Specificity')\nplt.ylabel('Sensitivity')\nplt.plot([0, 1], ls=\"--\", c = 'red')\nplt.plot([0, 0], [1, 0], ls=\"--\", c = 'green'), plt.plot([1, 1], ls=\"--\", c = 'green')\nplt.show()","fbdb019e":"from sklearn.metrics import classification_report\n\nclass_report = classification_report(y_test, model_pipeline_pred)\nprint(\"Pipeline\")\nprint(\"\\n\")\nprint(class_report)","fb256f4b":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\nprecision = precision_score(y_test, model_pipeline_pred)\nRecall = recall_score(y_test, model_pipeline_pred)\nAccuracy = accuracy_score(y_test, model_pipeline_pred)\nF1_Score = f1_score(y_test, model_pipeline_pred)\n\nprecisao = pd.DataFrame({\n    \n    \"Metrics\" : [\"precision\",\n                 \"Recall\", \n                  \"Accuracy\", \n                  \"F1_Score\"],\n    \n    \"Result\": [precision,\n                Recall, \n                Accuracy, \n                F1_Score]})\n\nprecisao.sort_values(by = \"Result\", ascending = False)","a21fdbf2":"import pickle\n    \nwith open('model_pipeline_pred.pkl', 'wb') as file:\n    pickle.dump(model_pipeline_pred, file)","a5b8308d":"# Machine learning - Pipeline"}}