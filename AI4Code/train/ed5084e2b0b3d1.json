{"cell_type":{"cc13372b":"code","cee36e84":"code","3dce2dff":"code","c35ad2e9":"code","a23d7bb9":"code","f69043ad":"code","a418c51a":"code","77c675df":"code","e1b76545":"code","e73dba19":"code","0011ce97":"code","4f240762":"code","cad90f28":"code","2e00375d":"code","ced88ed4":"code","984a05bb":"code","9f023a44":"code","98cbca4b":"markdown","52020db7":"markdown","f688651f":"markdown","bb0c784e":"markdown","75d42126":"markdown","2e79fb5a":"markdown","c8d998e3":"markdown","28186415":"markdown","38528585":"markdown","d300b90d":"markdown","eecd4ee5":"markdown","b444f685":"markdown","e9ba965f":"markdown","be6a6d17":"markdown","f311e49f":"markdown","2d9b2af4":"markdown","1ae38225":"markdown","bfbe8957":"markdown","621ca4ca":"markdown","fa0c300a":"markdown","a9495e8c":"markdown","ec914523":"markdown","50b3af40":"markdown","394893b8":"markdown","15435245":"markdown","9ed7f6c9":"markdown","1b98b3d0":"markdown","cda461fd":"markdown","4f0b9f2c":"markdown","358a3929":"markdown","92ba02fb":"markdown","5aeb6001":"markdown","5fca0c6d":"markdown","1ebf1390":"markdown","985a220f":"markdown","46ac6e8b":"markdown","17bc59fc":"markdown","a85d8713":"markdown","8ea925e1":"markdown","c2a9df45":"markdown","37045d51":"markdown"},"source":{"cc13372b":"import pandas as pd # to store data as dataframe\nimport numpy as np # # for numerical calculations such as histogramming\nimport matplotlib.pyplot as plt # for plotting\nfrom scipy.optimize import curve_fit # for the signal and background fit","cee36e84":"samples_list = ['data_A'] # add 'data_B','data_C','data_D' later if you want\n\nfraction = 0.8 # increase this later if you want\n\nDataFrames = {} # define empty dictionary to hold dataframes\nfor s in samples_list: # loop over samples\n    DataFrames[s] = pd.read_csv('\/kaggle\/input\/gamgam-csv\/'+s+'.csv', index_col='entry') # read .csv file\nall_data = pd.concat(DataFrames) # merge DataFrames into one","3dce2dff":"def calc_myy(photon_pt_1,photon_eta_1,photon_phi_1,photon_E_1,\n             photon_pt_2,photon_eta_2,photon_phi_2,photon_E_2):\n    # 1st photon is _1, 2nd photon is _2 etc\n    \n    # sumE = sum of energy\n    sumE = photon_E_1 + photon_E_2\n    \n    px_1 = photon_pt_1*np.cos(photon_phi_1) # x-momentum of photon_1\n    # px_2 = x-momentum of photon_2\n    px_2 = photon_pt_2*np.cos(photon_phi_2)\n    \n    py_1 = photon_pt_1*np.sin(photon_phi_1) # y-momentum of photon_1\n    # py_2 = y-momentum of photon_2\n    py_2 = photon_pt_2*np.sin(photon_phi_2)\n    \n    pz_1 = photon_pt_1*np.sinh(photon_eta_1) # z-momentum of photon_1\n    # pz_2 = z-momentum of photon_2\n    pz_2 = photon_pt_2*np.sinh(photon_eta_2)\n    \n    # sumpx = sum of x-momenta\n    sumpx = px_1 + px_2\n    \n    # sumpy = sum of y-momenta\n    sumpy = py_1 + py_2\n    \n    # sumpz = sum of z-momenta\n    sumpz = pz_1 + pz_2\n    \n    # sump = magnitude of total momentum\n    sump = np.sqrt(sumpx**2 + sumpy**2 + sumpz**2)\n    \n    # myy = invariant mass from M^2 = E^2 - p^2\n    myy = np.sqrt(sumE**2 - sump**2)\n    \n    return myy","c35ad2e9":"# myy is calculated for each row in the data\nall_data['myy'] = np.vectorize(calc_myy)(all_data['photon_pt_1'],\n                                         all_data['photon_eta_1'],\n                                         all_data['photon_phi_1'],\n                                         all_data['photon_E_1'],\n                                         all_data['photon_pt_2'],\n                                         all_data['photon_eta_2'],\n                                         all_data['photon_phi_2'],\n                                         all_data['photon_E_2'])","a23d7bb9":"# xmin = x-axis minimum in GeV from the Higgs discovery diphoton graph \nxmin = 100\n# xmax = x-axis minimum in GeV from the Higgs discovery diphoton graph \nxmax = 160\n# step_size = x-axis separation between data points in GeV from the Higgs discovery diphoton graph\nstep_size = 2\n\nbin_edges = np.arange(start=xmin, # The interval includes this value\n                 stop=xmax+step_size, # The interval doesn't include this value\n                 step=step_size ) # Spacing between values\n\nbin_centres = np.arange(start=xmin+step_size\/2, # The interval includes this value\n                        stop=xmax+step_size\/2, # The interval doesn't include this value\n                        step=step_size ) # Spacing between values","f69043ad":"print(all_data['myy'])","a418c51a":"print(type(bin_edges))\nprint(bin_edges)","77c675df":"print(type(bin_centres))\nprint(bin_centres)","e1b76545":"def plot_data():\n    \n    #####################\n    # Filling a histogram\n    # For you to complete\n    # Complete the lines below\n    histogrammed_data,_ = np.histogram( all_data['myy'],\n                                       bins=bin_edges )\n    # For you to complete\n    #####################\n\n    histogrammed_data_errors = np.sqrt( histogrammed_data ) # statistical error on the data\n\n    #####################\n    # Plot the data points\n    # For you to complete\n    # Complete the lines below then uncomment them\n    plt.errorbar(x=bin_centres, \n                 y=histogrammed_data, \n                 yerr=histogrammed_data_errors,\n                 label='Data',\n                 fmt='ko' ) # 'k' means black and 'o' means circles\n    # For you to complete\n    #####################\n    \n    return histogrammed_data","e73dba19":"plot_data()","0011ce97":"# Select eta outside the barrel\/end-cap transition region\n# you can think of eta as the photon's position in the detector\n# paper: \"excluding the calorimeter barrel\/end-cap transition region 1.37 < |\u03b7| < 1.52\"\ndef select_eta(photon_eta_1,photon_eta_2):\n# want to keep events where absolute value of photon_eta is outside the range 1.37 to 1.52\n    # if absolute value of either photon_eta between 1.37 and 1.52: return False\n    if abs(photon_eta_1)>1.37 and abs(photon_eta_1)<1.52: return False\n    if abs(photon_eta_2)>1.37 and abs(photon_eta_2)<1.52: return False\n    else: return True\n    \nall_data = all_data[ np.vectorize(select_eta)(all_data.photon_eta_1,all_data.photon_eta_2) ]\n\n\n# Select photons with high pt\n# pt is related to the photon's momentum\n# paper: \"The leading (sub-leading) photon candidate is required to have ET > 40 GeV (30 GeV)\"\ndef select_pt(photon_pt_1,photon_pt_2):\n# want to keep events where photon_pt_1>40 GeV and photon_pt_2>30 GeV\n    # if photon_pt_1 greater than 40 GeV and photon_pt_2 greater than 30 GeV: return True\n    #if photon_pt_1>40 and photon_pt_2>30: return True\n    #if photon_pt...\n    if True: return True\n    else: return False\n    \nall_data = all_data[ np.vectorize(select_pt)(all_data.photon_pt_1,all_data.photon_pt_2) ]\n\n\n# Select photons with low noise around them\n# you can think of etcone20 as how much noise is going on around the photon\n# paper: \"Photon candidates are required to have an isolation transverse energy of less than 4 GeV\"\ndef select_etcone20(photon_etcone20_1,photon_etcone20_2):\n# want to keep events where isolation eT<4 GeV\n    # if both photon_etcone20 less than 4 GeV: return True\n    #if photon_etcone20_1<4 and photon_etcone20_2<4: return True\n    #if photon_etcone20_1...\n    if True: return True\n    else: return False\n    \nall_data = all_data[ np.vectorize(select_etcone20)(all_data.photon_etcone20_1,all_data.photon_etcone20_2) ]\n\n\n# Select tightly identified photons\n# isTightID==True means a photon more likely to be a real photon, and not some error in the detector\n# paper: \"Photon candidates are required to pass identification criteria\"\ndef select_isTightID(photon_isTightID_1,photon_isTightID_2):\n# isTightID==True means a photon identified as being well reconstructed\n# want to keep events where True for both photons\n    # if both photon_isTightID are True: return True\n    #if photon_isTightID_1==True and photon_isTightID_2==True: return True\n    #if photon_isTightID_1...\n    if True: return True\n    else: return False\n\nall_data = all_data[ np.vectorize(select_isTightID)(all_data.photon_isTightID_1,all_data.photon_isTightID_2) ]","4f240762":"plot_data()","cad90f28":"def func(x, c0, c1, c2, c3, c4, A, mu, sigma): # define function for polynomial + Gaussian\n    return c0 + c1*x + c2*x**2+ c3*x**3 + c4*x**4 + A*np.exp(-0.5*((x-mu)\/sigma)**2)\n\ndata = plot_data() # draw a plot\nerrors = np.sqrt(data) # get the errors on the y values\n\n# data fit\npopt,_ = curve_fit(func, # function to fit\n                   bin_centres, # x\n                   data, # y\n                   p0=[data.max(),0,0,0,0,91.7,125,2.4], # initial guesses for the fit parameters\n                   sigma=errors) # errors on y\n\n# background part of fit\nc0 = popt[0] # c0 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\nc1 = popt[1] # c1 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\nc2 = popt[2] # c2 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\nc3 = popt[3] # c3 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\nc4 = popt[4] # c4 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n# get the background only part of the fit to data\nbackground_fit = c0 + c1*bin_centres + c2*bin_centres**2 + c3*bin_centres**3 + c4*bin_centres**4\n\nA = popt[5] # amplitude of Gaussian\nmu = popt[6] # centre of Gaussian\nsigma = popt[7] # width of Gaussian\nfit = func(bin_centres,c0,c1,c2,c3,c4,A,mu,sigma) # call func with fitted parameters\n\n# plot the signal + background fit\nplt.plot(bin_centres, # x\n         fit, # y\n         '-r', # single red line\n         label='Sig+Bkg Fit ($m_H=125$ GeV)' )\n# plot the background only fit\nplt.plot(bin_centres, # x\n         background_fit, # y\n         '--r', # dashed red line\n         label='Bkg (4th order polynomial)' )\n\nplt.ylabel( 'Events' ) # write y-axis label for main axes\nplt.ylim( bottom=0 ) # set the y axis limit for the main axes\nplt.xlabel(r'di-photon invariant mass $\\mathrm{m_{\\gamma\\gamma}}$ [GeV]') # x-axis label\n\n# draw the legend\nplt.legend()\n\nprint('gaussian centre = '+str(mu))\nprint('gaussian sigma = '+str(sigma))","2e00375d":"print(fit)","ced88ed4":"print(data)","984a05bb":"print(errors)","9f023a44":"# calculate chi squared\nfit_minus_data = fit - data\nfit_minus_data_over_errors = fit_minus_data\/errors\nfit_minus_data_over_errors_squared = fit_minus_data_over_errors**2\nchisq = sum(fit_minus_data_over_errors_squared)\n\nprint('chi^2 = '+str(chisq))","98cbca4b":"<a id='applying_cuts'><\/a>","52020db7":"## Chi squared - Week 10\n\nRecall that the function for $\\chi^2$ is \n$$\\Sigma{(\\frac{fit-data}{errors})^2}$$ \nwhere the sum is over each data point\n\n1. Fill in the variable `fit_minus_data`\n2. Use the variable `fit_minus_data` to fill the variable `fit_minus_data_over_errors`\n3. Use the variable `fit_minus_data_over_errors` to fill the variable `fit_minus_data_over_errors_squared`\n4. Use the variable `fit_minus_data_over_errors_squared` to fill the variable `chisq`\n5. In the top menu, click 'Run' -> 'Run all'","f688651f":"and now the array of data values","bb0c784e":"<a id='invariant_mass'><\/a>","75d42126":"Now that we've applied selections to separate signal from background, let's make a fit.","2e79fb5a":"and lastly the array of data errors","c8d998e3":"## Running a Jupyter notebook\n\nTo run the whole Jupyter notebook, in the top menu click Run -> Run all.\n\nTo propagate a change you've made to a piece of code, click Run -> Run after.\n\nYou can also run a single code cell, by using the keyboard shortcut Shift+Enter.","28186415":"<a id='view_plot'><\/a>","38528585":"<a id='chi'><\/a>","d300b90d":"## Instructions\n\n1. Fill in the missing pieces in the ['Invariant mass calculation' code cell](#invariant_mass)\n2. Fill in the missing pieces in the ['Plotting definitions' code cell](#plotting)\n3. Fill in the missing pieces in the ['Data histogramming and plotting' code cell](#histogramming)\n4. In the top menu, click 'Run' -> 'Run all'\n5. [Check out the plot you've made](#view_plot)\n\nLet's try separate the signal from the background to see a more significant bump around the Higgs mass.\n6. Fill in the missing pieces in the ['Applying selections' code cell](#applying_cut)\n7. In the top menu, click 'Run' -> 'Run all'\n8. [Check out the new plot you've made](#plot_data_after_cut)\n\nNow that we've applied selections to separate signal from background, let's make a fit.\n9. [Check out the fitted plot you've made](#view_fit)\n10. Fill in the missing pieces in the ['Chi squared' code cell](#chi)\n11. Follow the instructions underneath the ['Chi squared' code cell](#chi) to interpret your result.\n","eecd4ee5":"and the array of bin centres","b444f685":"1. Write your value for $M_H$, the mass of the Higgs boson, and the uncertainty there-on, from the width of the fitted peak.\n\nNow let's move onto whether this is a good fit.\n\nThe formula for the 4th order polynomial fit is given by\n$$y=c0+c1x+c2x^2+c3x^3+c4x^4,$$\nwhere $c0$, $c1$, $c2$, $c3$, $c4$ are variables in the fit. The formula for the Gaussian fit is given by\n$$y=Aexp[-0.5((x-\\mu)\/\\sigma )^2],$$\nwhere $A$ is the amplitude, $\\mu$ is the centre, $\\sigma$ is the sigma.\n2. Explain whether this is a good fit, and try give some reasoning as to why this is\/isn\u2019t a good fit. Reminder: $\\chi^2$ is printed out just above.\n3. Compare your result with the accepted value for $M_H$: do they agree? If they differ, by how much do they differ (in terms of the measured uncertainty on your result)?\n4. At the end of your analysis, discuss whether your result is compatible with the accepted value for the Higgs mass.\n\nAnd that's it! You can finish there or you can explore this analysis further using the suggestions below.","e9ba965f":"Making a histogram of the number of times a particular $\\sqrt{E^2-p^2}$ occurs is a way to search for heavy particles that decay so quickly that they can\u2019t be measured by the ATLAS detector directly. In this analysis, we\u2019re searching for the Higgs boson decaying to two photons.","be6a6d17":"<a id='histogramming'><\/a>","f311e49f":"## Input data\n\nSamples to process, fraction of data used","2d9b2af4":"2. Fill in `?diphoton invariant mass values?` using the information at [the start of the 'Data histogramming and plotting' section](#histogramming)\n3. Fill in `?array of bin edges?` using the information at [the start of the 'Data histogramming and plotting' section](#histogramming)\n4. Fill in `?array of bin_centres?` using the information at [the start of the 'Data histogramming and plotting' section](#histogramming)\n5. Fill in `?the histogrammed data you defined in the earlier step?`\n6. Fill in `?the errors on the histogrammed data defined for you in the line above?`\n7. Fill in `?what label should this have in the legend?`\n8. In the top menu, click 'Run' -> 'Run all'","1ae38225":"## Fitting - Week 10\n\nDefine function to fit to data\n\n","bfbe8957":"<a id='going_further'><\/a>","621ca4ca":"<a id='running'><\/a>","fa0c300a":"<a id='instructions'><\/a>","a9495e8c":"Let's take a look at the array of bin edges","ec914523":"## Invariant mass calculation - Week 6\n\n1. If the energy of the 2 photons are *photon_E_1* and *photon_E_2*, write the sum of energy, *sumE*\n2. Write the x-momentum of photon_2, *px_2*, using the definition of x-momentum of photon_1 momentum, *px_1*, written for you. All you need to do is replace 1 with 2\n3. Do the same for y and z momenta of photon_2 (*py_2* and *pz_2*)\n4. Write the sum of x-momentum, *sumpx*\n5. Do the same for y and z momenta (*sumpy* and *sumpz*)\n6. Write the magnitude of total momentum, *sump*\n\nThe invariant mass *M* of a parent particle decaying to two daughter particles is related to properties of the daughter particles by the formula:\n\n$$M^2=E^2-p^2,$$\n\nwhere *E* is the total energy of the daughter particles, and *p* is the magnitude of the vector sum of the momenta of the daughter particles.\n\n7. Write *myy* using this formula for invariant mass","50b3af40":"<a id='setup_everytime'><\/a>","394893b8":"## Plotting definitions - Week 7\n\n1. Take a look at the [ATLAS Higgs discovery diphoton graph](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S037026931200857X-gr004_lrg.jpg)\n2. Write the x-axis minimum, *xmin*, from the [ATLAS Higgs discovery diphoton graph](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S037026931200857X-gr004_lrg.jpg)\n3. Write the x-axis maximum, *xmax*, from the [ATLAS Higgs discovery diphoton graph](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S037026931200857X-gr004_lrg.jpg)\n4. Write the x-axis separation between data points, *step_size*, from the [ATLAS Higgs discovery diphoton graph](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S037026931200857X-gr004_lrg.jpg)","15435245":"<a id='plotting'><\/a>","9ed7f6c9":"Let's try separate the signal from the background to see a more significant bump around the Higgs mass.\n\n## Applying selections - Week 9\n\nThe select_eta function is provided as an example to help you fill in the rest.\n\n1. In the `select_pt` function, modify the if statement to write code for `if photon_pt_1 greater than 40 and photon_pt_2 greater than 30: return True`\n2. In the `select_etcone20` function, modify the if statement to write code for `if both photon_etcone20 less than 4: return True`\n3. In the `select_isTightID` function, modify the if statement to write code for `if both photon_isTightID are True: return True`\n4. In the top menu, click 'Run' -> 'Run all'","1b98b3d0":"## To setup everytime\n\nto be done every time you re-open this notebook\n\nWe're going to be using a number of tools to help us:\n* pandas: lets us store data as dataframes, a format widely used in python\n* numpy: provides numerical calculations such as histogramming\n* matplotlib: common tool for making plots, figures, images, visualisations\n* scipy: tool for statistical fitting","cda461fd":"# How to rediscover the Higgs boson yourself!\nThis notebook uses ATLAS Open Data http:\/\/opendata.atlas.cern to show you the steps to rediscover the Higgs boson yourself!\n\nATLAS Open Data provides open access to proton-proton collision data at the LHC for educational purposes. ATLAS Open Data resources are ideal for high-school, undergraduate and postgraduate students.\n\nNotebooks are web applications that allow you to create and share documents that can contain for example:\n1. live code\n2. visualisations\n3. narrative text\n\nThis analysis loosely follows the [paper for the discovery of the Higgs boson by ATLAS](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S037026931200857X#fg0040) (mostly Section 5 and 5.1)\n\nAt the sort of level of understanding to follow this notebook, you can read this [article on the Higgs boson](http:\/\/hyperphysics.phy-astr.gsu.edu\/hbase\/Forces\/higgs.html?fbclid=IwAR1ocxfiTOUW2dsdn1AMUL8IBnyBARS8mKKpWIlosTor66yRBdyyHH12naA#c1)\n\nBy the end of this notebook you will be able to:\n1. rediscover the Higgs boson yourself!\n2. know some general principles of a particle physics analysis\n\nThe datasets used in this notebook have already been filtered to include at least 2 photons per event, so that processing is quicker.\n\nFeynman diagram pictures are borrowed from our friends at [Particle Zoo](https:\/\/www.particlezoo.net)","4f0b9f2c":"Call the function to plot the data","358a3929":"## Data histogramming and plotting - Week 8\n\n1. Read this section to be able to fill in the next missing pieces\n\nLet's take a look at the data before plotting\n\nThe diphoton invariant mass can be accessed like:","92ba02fb":"<a id='fraction'><\/a>","5aeb6001":"Contents: \n\n[Instructions](#instructions) <br \/>\n[Running a Jupyter notebook](#running) <br \/>\n[To setup everytime](#setup_everytime) <br \/>\n[Input data](#fraction) <br \/>\n[Invariant mass calculation](#invariant_mass) <br \/>\n[Plotting definitions](#plotting) <br \/>\n[Data histogramming and plotting](#histogramming) <br \/>\n[Applying selections](#applying_cut) <br \/>\n[Fitting](#fitting) <br \/>\n[Chi squared](#chi) <br \/>\n[What can you do to explore this analysis?](#going_further) <br \/>","5fca0c6d":"Then myy is calculated for each row in the data","1ebf1390":"<a id='fitting'><\/a>","985a220f":"## What can you do to explore this analysis?\n\n* Increase the fraction of data used in '[Input data](#fraction)'\n* Use data_B, data_C and data_D in '[Input data](#fraction)'\n* Try different initial guesses for the parameters of the fit in '[Fitting](#fitting)'\n* Try different functions for the fit in '[Fitting](#fitting)'\n* Check how many events are being thrown away by each selection in '[Applying selections](#applying_cuts)'\n* Define more selections from the [Higgs discovery paper](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S037026931200857X#se0090) and then apply them in '[Applying selections](#applying_cuts)'\n* Add some extra commands in '[Fitting](#fitting)' to make it look more similar to the [Higgs discovery paper](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S037026931200857X#fg0040)\n* Your idea!\n\n[Back to instructions](#instructions)\n\n[Back to plot before selections](#view_plot)\n\n[Back to plot after selections](#plot_data_after_cuts)","46ac6e8b":"<a id='view_fit'><\/a>","17bc59fc":"<a id='plot_data_after_cut'><\/a>","a85d8713":"<img src=\"attachment:ATLASOD.gif\">","8ea925e1":"This is a histogram of $M$ vs. the number of events. The error bars on the number of events are given by statistical uncertainty, i.e. the square root of the number of events, e.g. 10000 $\\pm$ 100. The errors bars on $M$ are given by the width of the histogram bin. A 4th order polynomial + Gaussian fit is used around the peak in $M$. To find the centre of the Gaussian, we need to subtract the polynomial background. This has been done for you in the code above.\n\n\n\nLet's print the array of fitted values to give you an idea of how it looks.","c2a9df45":"<img src=\"attachment:Hyy_feynman.png\" width=40%>","37045d51":"After making the selections, check out how the plot has changed."}}