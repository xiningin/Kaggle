{"cell_type":{"53708374":"code","7c55f3ab":"code","3aa165a5":"code","0b032fea":"code","6e0ecf2a":"code","083282cf":"code","9af06302":"code","d6ffd245":"code","82efc804":"code","0a9ac4e5":"code","bc1121c0":"code","e38be1b3":"code","dda76170":"code","93084ba1":"code","d553c7a7":"code","8e6a5cfd":"code","7217291d":"code","3b3af3af":"code","ba1a8763":"code","0375f671":"code","bb6a4dde":"code","116ece4f":"code","a71ec732":"code","d14e8329":"code","9d39b62e":"code","f61e41a0":"code","c8861aec":"code","7e572c08":"code","933afc07":"code","4d322586":"code","7db48769":"code","68d83a15":"code","4e2eab58":"code","023c8614":"code","fce13e04":"code","12ae1e65":"code","f9c9388b":"code","26ad473f":"code","9c1a5887":"code","ea5d5a27":"code","8e92b2dc":"code","3b7c0389":"code","dcb42163":"code","2ce0630f":"code","2f641051":"code","4f7bfeff":"code","e72c5444":"code","809eb331":"code","4a3139d8":"code","88e66f1b":"code","10f595bd":"code","73f814f1":"code","cc953d82":"code","cdb1ba15":"code","218b2b80":"code","edcba727":"code","453928d8":"code","82e60490":"code","25d5ae1f":"code","c688b5d5":"markdown","67872070":"markdown","a92efde2":"markdown","aefaf3f2":"markdown","2819d1cc":"markdown","e9b5645f":"markdown","46b972df":"markdown","94e01445":"markdown","13607890":"markdown","7d68393b":"markdown","53eb8ce7":"markdown","99927213":"markdown","7f71c95f":"markdown","04dc8261":"markdown","aaad4153":"markdown","1a8839c3":"markdown","963696e0":"markdown","fe5afc92":"markdown","1af3aebc":"markdown","cca605e5":"markdown","feeb255b":"markdown","26374642":"markdown","a79b3de5":"markdown","4b233b23":"markdown","0905376a":"markdown","2ecc8607":"markdown","c4b35907":"markdown","aa3e7913":"markdown","b75ca911":"markdown","74f7ace7":"markdown","39c779d4":"markdown","7d157a4f":"markdown","2af9ee8d":"markdown","afc05363":"markdown","bb6b8953":"markdown","67ae6ed4":"markdown","5cf48ba2":"markdown","c4c69538":"markdown","65e169ba":"markdown","b9e5dbe4":"markdown","d869ec64":"markdown","b10359eb":"markdown","0f6776e0":"markdown","72236985":"markdown","3fcecb50":"markdown","a38c430f":"markdown","9751ba0c":"markdown","db4ec71a":"markdown","f85a79ee":"markdown","f557f859":"markdown","64016e5d":"markdown","ee531753":"markdown","9e27b5c4":"markdown","c454aafe":"markdown","feadb64f":"markdown","3f4f8802":"markdown","9ddc7e09":"markdown","7ea2f188":"markdown","7db01b01":"markdown","772d71f5":"markdown"},"source":{"53708374":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport os\n\n# for train-test split of dataset\nfrom sklearn.model_selection import train_test_split\n\n# for scaling of dataset\nfrom sklearn.preprocessing import MinMaxScaler\n\n# RFE\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\n\n# to create linear model\nimport statsmodels.api as sm\n\n# to check VIFs\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# R-squared\nfrom sklearn.metrics import r2_score\n\n# MSE\nfrom sklearn.metrics import mean_squared_error\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","7c55f3ab":"print(os.listdir('..\/input\/geely-auto'))","3aa165a5":"# importing csv file\ncar_df = pd.read_csv(\"..\/input\/geely-auto\/CarPriceAssignment.csv\")\ncar_df.head()","0b032fea":"print(car_df.shape)\ncar_df.info()","6e0ecf2a":"# Describing the numerical vars\ncar_df.describe()","083282cf":"sns.pairplot(car_df)\nplt.show()","9af06302":"# searching for outliers in compressionratio\n\n# Box-plot\nplt.figure(figsize=(15,6))\nplt.subplot(121)\nsns.boxplot(data=car_df.compressionratio, width=0.5, palette=\"colorblind\")\nplt.title('Box-Plot Compression Ratio')\n\n# Scatter plot\nplt.subplot(122)\nsns.scatterplot(data=car_df.compressionratio, palette=\"colorblind\")\nplt.title('Scatter Plot Compression Ratio')\nplt.show()","d6ffd245":"# percentage of outliers\ncomp_ratio = car_df[['compressionratio']].copy().sort_values(by='compressionratio',ascending=False)\ncomp_ratio_outlier = car_df[car_df['compressionratio']>12]\nprint(len(comp_ratio))\nprint(len(comp_ratio_outlier))\n\ncomp_ratio_outlier_perc = round(100*(len(comp_ratio_outlier) \/ len(comp_ratio)),2)\nprint('Outlier percentage of compressionratio: ' + str(comp_ratio_outlier_perc))","82efc804":"# heatmap\nplt.figure(figsize = (20,10))  \nsns.heatmap(car_df.corr(), cmap= 'YlGnBu',annot = True)","0a9ac4e5":"# Keeping 'citympg' and 'carlength' from above\ncar_df = car_df.drop(['carwidth','curbweight','wheelbase','highwaympg'], axis=1)\ncar_df.head()","bc1121c0":"# dropping car_ID\ncar_df = car_df.drop('car_ID', 1)\ncar_df.head()","e38be1b3":"# Categorical columns\ncar_df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","dda76170":"plt.figure(figsize=(20, 20))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'fueltype', y = 'price', data = car_df)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'aspiration', y = 'price', data = car_df)\nplt.subplot(3,3,3)\nsns.boxplot(x = 'doornumber', y = 'price', data = car_df)\nplt.subplot(3,3,4)\nsns.boxplot(x = 'carbody', y = 'price', data = car_df)\nplt.subplot(3,3,5)\nsns.boxplot(x = 'drivewheel', y = 'price', data = car_df)\nplt.subplot(3,3,6)\nsns.boxplot(x = 'enginelocation', y = 'price', data = car_df)\nplt.subplot(3,3,7)\nsns.boxplot(x = 'enginetype', y = 'price', data = car_df)\nplt.subplot(3,3,8)\nsns.boxplot(x = 'cylindernumber', y = 'price', data = car_df)\nplt.subplot(3,3,9)\nsns.boxplot(x = 'fuelsystem', y = 'price', data = car_df)\nplt.show()","93084ba1":"car_df.CarName.head(20)","d553c7a7":"# split and taking the Company name\ncar_df['CarName'] = car_df['CarName'].apply(lambda x:re.split('-| ',x)[0])\ncar_df['CarName'].head(10)","8e6a5cfd":"# Names and count of Cars according to Companies\ncar_df['CarName'].value_counts()","7217291d":"# mapping similar companies into one\ncar_df['CarName'] = car_df.CarName.str.replace('vw','volkswagen')\ncar_df['CarName'] = car_df.CarName.str.replace('vokswagen','volkswagen')\ncar_df['CarName'] = car_df.CarName.str.replace('toyouta','toyota')\ncar_df['CarName'] = car_df.CarName.str.replace('porcshce','porsche')\ncar_df['CarName'] = car_df.CarName.str.replace('maxda','mazda')\ncar_df['CarName'] = car_df.CarName.str.replace('Nissan','nissan')\ncar_df['CarName'].value_counts()","3b3af3af":"print(car_df['fueltype'].value_counts())\nprint(car_df['aspiration'].value_counts())\nprint(car_df['doornumber'].value_counts())\nprint(car_df['enginelocation'].value_counts())","ba1a8763":"# quantifying into 1 and 0\ncar_df['fueltype'] = car_df['fueltype'].map({'gas': 1, 'diesel':0})\ncar_df['aspiration'] = car_df['aspiration'].map({'std': 1, 'turbo':0})\ncar_df['doornumber'] = car_df['doornumber'].map({'four': 1, 'two':0})\ncar_df['enginelocation'] = car_df['enginelocation'].map({'front': 1, 'rear':0})\n\ncar_df.head()","0375f671":"# creating dummy variables for categorical columns\ndummy_car_df = pd.get_dummies(car_df, drop_first=True)\ndummy_car_df.head()","bb6a4dde":"dummy_car_df.info()","116ece4f":"# train-test split\nnp.random.seed(0)\ndf_train, df_test = train_test_split(dummy_car_df, train_size = 0.7, random_state=100)\nprint(df_train.shape)\ndf_train.head()","a71ec732":"# Apply scalar to all columns except 'quantified' and 'dummy' variables\nvars_list = ['price','carlength','enginesize','boreratio','stroke','compressionratio','horsepower','peakrpm','citympg']\n\nscalar = MinMaxScaler()\ndf_train[vars_list] = scalar.fit_transform(df_train[vars_list])\ndf_train.head()","d14e8329":"df_train.describe()","9d39b62e":"y_train = df_train.pop('price')\nX_train = df_train\nprint(y_train.head())\nX_train.head()","f61e41a0":"# RFE\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm,12)      # choosing top 12 features\nrfe = rfe.fit(X_train,y_train)\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))","c8861aec":"# selecting the top 12 features\ncol = X_train.columns[rfe.support_]\ncol","7e572c08":"# variables which are redundant\nX_train.columns[~rfe.support_]","933afc07":"# eatures selected for model building\nX_train_rfe = X_train[col]\nX_train_rfe.head()","4d322586":"# add constant variable\nX_train_rfe_1 = sm.add_constant(X_train_rfe)\n\n# 1st linear model\nlr_model_1 = sm.OLS(y_train,X_train_rfe_1).fit()\n\n# summary\nlr_model_1.summary()","7db48769":"# VIF of model_1\nvif = pd.DataFrame()\nX = X_train_rfe_1.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","68d83a15":"# heatmap\nplt.figure(figsize=(15,8))\nsns.heatmap(X.corr(), cmap='YlGnBu', annot=True)","4e2eab58":"# dropping 'enginetype_rotor' \nX_train_rfe_2 = X_train_rfe_1.drop('enginetype_rotor', axis=1)","023c8614":"# add constant variable\nX_train_rfe_2 = sm.add_constant(X_train_rfe_2)\n\n# 2nd linear model\nlr_model_2 = sm.OLS(y_train,X_train_rfe_2).fit()\n\n# summary\nlr_model_2.summary()","fce13e04":"# VIF of model_2\nvif = pd.DataFrame()\nX = X_train_rfe_2.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","12ae1e65":"# dropping 'cylindernumber_four'\nX_train_rfe_3 = X_train_rfe_2.drop('cylindernumber_four',1)\n\n# add constant variable\nX_train_rfe_3 = sm.add_constant(X_train_rfe_3)\n\n# 3rd linear model\nlr_model_3 = sm.OLS(y_train,X_train_rfe_3).fit()\n\n# summary\nlr_model_3.summary()","f9c9388b":"# VIF of model_3\nvif = pd.DataFrame()\nX = X_train_rfe_3.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","26ad473f":"# dropping 'boreratio'\nX_train_rfe_4 = X_train_rfe_3.drop('boreratio',1)\n\n# add constant variable\nX_train_rfe_4 = sm.add_constant(X_train_rfe_4)\n\n# 4th linear model\nlr_model_4 = sm.OLS(y_train,X_train_rfe_4).fit()\n\n# summary\nlr_model_4.summary()","9c1a5887":"# VIF of model_4\nvif = pd.DataFrame()\nX = X_train_rfe_4.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","ea5d5a27":"# heatmap\nplt.figure(figsize=(12,5))\nsns.heatmap(X.corr(), cmap='YlGnBu', annot=True)","8e92b2dc":"# dropping 'carlength'\nX_train_rfe_5 = X_train_rfe_4.drop('carlength',1)\n\n# add constant variable\nX_train_rfe_5 = sm.add_constant(X_train_rfe_5)\n\n# 5th linear model\nlr_model_5 = sm.OLS(y_train,X_train_rfe_5).fit()\n\n# summary\nlr_model_5.summary()","3b7c0389":"# VIF of model_5\nvif = pd.DataFrame()\nX = X_train_rfe_5.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","dcb42163":"# dropping 'stroke'\nX_train_rfe_6 = X_train_rfe_5.drop('stroke',1)\n\n# add constant variable\nX_train_rfe_6 = sm.add_constant(X_train_rfe_6)\n\n# 6th linear model\nlr_model_6 = sm.OLS(y_train,X_train_rfe_6).fit()\n\n# summary\nlr_model_6.summary()","2ce0630f":"# VIF of model_6\nvif = pd.DataFrame()\nX = X_train_rfe_6.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","2f641051":"# dropping 'cylindernumber_three'\nX_train_rfe_7 = X_train_rfe_6.drop('cylindernumber_three',1)\n\n# add constant variable\nX_train_rfe_7 = sm.add_constant(X_train_rfe_7)\n\n# 7th linear model\nlr_model_7 = sm.OLS(y_train,X_train_rfe_7).fit()\n\n# summary\nlr_model_7.summary()","4f7bfeff":"# VIF of model_7\nvif = pd.DataFrame()\nX = X_train_rfe_7.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","e72c5444":"# heatmap\nplt.figure(figsize=(8,5))\nsns.heatmap(X.corr(), cmap='YlGnBu', annot=True)","809eb331":"# dropping 'cylindernumber_twelve'\nX_train_rfe_8 = X_train_rfe_7.drop('cylindernumber_twelve',1)\n\n# add constant variable\nX_train_rfe_8 = sm.add_constant(X_train_rfe_8)\n\n# 8th linear model\nlr_model_8 = sm.OLS(y_train,X_train_rfe_8).fit()\n\n# summary\nlr_model_8.summary()","4a3139d8":"# VIF of model_8\nvif = pd.DataFrame()\nX = X_train_rfe_8.drop('const',1)  # no need of 'const' in finding VIF\nvif['features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = 'VIF', ascending=False)\nvif","88e66f1b":"# heatmap\nplt.figure(figsize=(8,5))\nsns.heatmap(X.corr(), cmap='YlGnBu', annot=True)","10f595bd":"y_train_pred = lr_model_8.predict(X_train_rfe_8)\nresidual = y_train - y_train_pred\n\nplt.figure()\nsns.distplot(residual, bins = 20)\nplt.title('Error Terms', fontsize = 18)     \nplt.xlabel('Errors')   ","73f814f1":"fig = plt.figure(figsize=(18,5))\nx_axis_range = [i for i in range(1,144,1)]\nfig.suptitle('Error Terms', fontsize=20)\n\nplt.subplot(1,2,1)\nplt.scatter(x_axis_range, residual)\nplt.ylabel('Residuals')\n\nplt.subplot(1,2,2)\nplt.plot(x_axis_range,residual, color=\"green\", linewidth=2.5, linestyle=\"-\")\n","cc953d82":"vars_list = ['price','carlength','enginesize','boreratio','stroke','compressionratio','horsepower','peakrpm','citympg']\n\ndf_test[vars_list] = scalar.transform(df_test[vars_list])\ndf_test.head()","cdb1ba15":"y_test = df_test.pop('price')\nX_test = df_test\nprint(y_test.head())\nX_test.head()","218b2b80":"# creating X_test_new dataframe by selected columns from final model\nX = X_train_rfe_8.drop('const',1)\nX_test_new = X_test[X.columns]\n\n# adding contant\nX_test_new = sm.add_constant(X_test_new)\nX_test_new.head()","edcba727":"# making prediction using final model\ny_pred = lr_model_8.predict(X_test_new)\ny_pred.head()","453928d8":"# R-squared value of test set\nr2_score(y_test, y_pred)","82e60490":"np.sqrt(mean_squared_error(y_test, y_pred))","25d5ae1f":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure(figsize=(20,5))\nfig.suptitle('y_test vs y_pred', fontsize=20)              \n\nplt.subplot(1,2,1)\nplt.scatter(y_test,y_pred)\nplt.xlabel('y_test', fontsize=18)                          \nplt.ylabel('y_pred', fontsize=16)                          \n\nplt.subplot(1,2,2)\nsns.regplot(y_test,y_pred)\nplt.xlabel('y_test', fontsize=18)                          \n","c688b5d5":"-  VIFs are normal, let's see the correlation..","67872070":"#### # RMSE:","a92efde2":"We should not rescale the `symboling` column as it defines `insurance risk rating` in range of `-3 to +3`.","aefaf3f2":"#### # Dividing tset set into X_test and y_test:","2819d1cc":"-  So R-squared of Test set is `0.866` which nearly same for Train data `0.861`, telling that none of the independent features in this model are redundant.","e9b5645f":"## Step 5: Building Linear Regression Model","46b972df":"- Now, `VIF`s of all of the features are in considerable range, as well as `p-value`s are also 0 for all of them. So, we can consider it as our final model, having `Adj. R-squared: 0.861` and `F-statistic: 177.6` telling us that overall model fit is good, all of the final independent variables are able to define `86%` variance of our dependent variable `price`, claiming it is a pretty significant model. We can confirm it by feeding the Test data into the model.\n","94e01445":"-  `Adj. R-squared` dropped to 0.885, and some of the p-values arises.","13607890":"-  So, the Error terms are normally distributed, which validates our one of the assumptions on residuals.","7d68393b":"Let's see the VIFs of the features for `multicollinearity`..","53eb8ce7":"#### # Visualising the Numerical Variables:","99927213":"### Conclusion:\n-  So, we got our best fitted line, and it is clearly showing the Linear Relationship between Train and Test data.\n-  The final equation of of Best-fitted line:\n\n$ price = -0.0816 + 1.1205 \\times enginesize + 0.2233 \\times CarNamebmw + 0.2311 \\times CarNameporsche + 0.1474 \\times cylindernumberfive + 0.2513 \\times cylindernumbertwo $\n\n- The variables which are significant in predicting the Price of a car:\n    -  enginesize\n    -  CarName_bmw\n    -  cylindernumber_five\n    -  CarName_porsche\t\n    -  cylindernumber_two","7f71c95f":"#### # Scaling the Features:","04dc8261":"#### # Recursive Feature Elimination:","aaad4153":"#### # Building model using Statsmodel:","1a8839c3":"-  So, we should drop one of the `inf` feature..","963696e0":"#### # Finding patterns in the residuals:","fe5afc92":"> #### # Distribution of error terms:\nwhich should be normally distributed by validating our assumptions.","1af3aebc":"-  More or less every Numerical variables are Normally distributed, whereas `Price` is highly Right-skewed which is our `Dependent Variable`,`horsepower` also right-skewed.\n-  `compressionratio` is the only variable having different spikes, one at left another at right, we should inspect it more...","cca605e5":"-  `boreratio` having VIF `13.35` with p-value `0.013`, we'll drop it now...","feeb255b":"-  Let's see the heatmap of the final independent features once for satisfaction..","26374642":"-  Whichever is higher between two values of each category that will be denoted by 1, another will be 0, and column name will be changed according to it.","a79b3de5":"## Step 7: Prediction on Test Set","4b233b23":"-  VIFs of all of them is in significant range (<2)\n-  So, `cylindernumber_three` should be dropped based on its p-value.","0905376a":"- **CarName** comprised of `car comapny` and `car model`, as per direction of this assignment we have to consider only `Company name`.","2ecc8607":"There are **`205`** `rows` and **`26`** `columns` without any missing values...its a good thing, we need not to perform any missing value treatments.","c4b35907":"#### # VIF:","aa3e7913":"-  p-value of `cylindernumber_three` is 0.218, which is not considerable.","b75ca911":"Summary:\n-  `Adj. R-squared` is reduced `0.881`.\n-  `p-value` increased of some of them:\n    -  stroke 0.071\n    -  cylindernumber_three 0.069\n    -  cylindernumber_twelve 0.029","74f7ace7":"-  As we can see, there is high correlation(0.97) between `citympg` and `highwaympg`, so we can get rid one of them, as they will have same impact on dataset.\n-  High collinearity also exist among `carlength`, `curbweight`, `wheelbase` and `carwidth` around 0.84 to 0.88, so we can keep only one of them and drop others","39c779d4":"From summary what we get:\n1.  None of the co-efficients are 0, they are having some values (positive as well as negative), so all of them are adding some efforts into the model. \n2.  `F-statistics` is 120.2, resulting in the Probablity 7.94e-63, so the overall model fit is significant.\n3.  `Adjusted R-squraed` value is 0.902, that means 90% variance in `price` is described by the selected features.\n4.  `p-values` for all of the features are 0 telling that they all are significant.","7d157a4f":"-  RMSE is lesser the better, for our case it is `0.085` telling our Prediction is very good.","2af9ee8d":"-  So, there is no such patterns in the Error terms, which validates our one of the major assumptions of residuals.","afc05363":"## Step 1: Reading and Understanding the data","bb6b8953":"## Step 8: Model Evaluation","67ae6ed4":"#### # Visualising the Categorical Variables:","5cf48ba2":"#### # R-squared of Test set:","c4c69538":"So, we've to pick the company name from CarName by using delimitters `-` and `space`","65e169ba":"## Step 2: Visualising the Data","b9e5dbe4":"So, majority of the values lies between `0-12`, whereas few others lying arround `22`, those seems to be outliers, lets check their percentage...","d869ec64":"#### # Scaling the test data:","b10359eb":"## Step 6: Residual Analysis on Train Data","0f6776e0":"-  Let's see the heatmap also, to get some insight...","72236985":"We may drop the `car_ID` column as it just a serial no. which is not putting any significance.","3fcecb50":"\nSo, there are so many different comapnies, some of them belongs to only one company having different names, like:\n-  `toyota` = `toyouta`\n-  `vw`=`volkswagen`\n-  `vokswagen`=`volkswagen`\n-  `toyouta`=`toyota`\n-  `porcshce`=`porsche`\n-  `maxda`=`mazda`\n-  `Nissan`=`nissan`","a38c430f":"- `stroke` is having p-value `0.023` as well as VIF `4.96`","9751ba0c":"-  `carlength` is correlated (0.7) with `enginesize` and also having VIF `13.52`.","db4ec71a":"-  We can see that 4 categorical columns `fueltype`,`aspiration`,`doornumber`,`enginelocation` having only two types of data in them, so in order to build a regression model we need to quantify them into Numerical values like 1 and 0.","f85a79ee":"So, the outlier percentage is around `10%`, removing 20 rows out of 205 seems to be expensive, lets keep them for now, in future we may handle them.","f557f859":"#### # Visualising the fit on Test set:","64016e5d":"#### # Dividing the Dataset into X_train and y_train for model building:","ee531753":"Looks pretty decent....","9e27b5c4":"## Step 4: Splitting the Data into Train and Test sets","c454aafe":"-  So, `cylindernumber_twelve` is positively correlated (0.41) with `enginesize`, and also having negative co-efficient (-0.2382), which we get from summary stats. There is a pssibility of `Multicollinearity`.","feadb64f":"## Step 3: Data Preparation","3f4f8802":"-  `cylindernumber_two` and `enginetype_rotor` are showing VIF as `inf`, because they are highly correlated with each other having `Pearson Correlation factor(R)` nearly equal to 1. we can see it by the heatmap also...","9ddc7e09":"####  # Inspecting the Car Dataset","7ea2f188":"-  No significant change in `Adj. R-squared` (0.867), let's see the VIF also..","7db01b01":"#### # Dummy Variables for categorical columns:","772d71f5":"-  Now from heatmap we can see, `cylindernumber_four` is highly negatively correlated(-0.61) with `enginesize`, also having VIF = 22.95. Let's drop it."}}