{"cell_type":{"c310d769":"code","2c450561":"code","ed2ff885":"code","f629450b":"code","4b5c85ea":"code","6361b2c1":"code","34481bc3":"code","9cae093d":"code","726e9cde":"code","e1175f18":"code","8025f716":"code","2bfebd63":"code","bbc37cba":"code","ff6d1912":"code","3907f743":"code","c8122785":"code","bd5c0899":"code","3419a306":"code","8fbc46d1":"code","4242160e":"code","1b09c275":"code","03312e38":"code","f89929e9":"code","21589887":"code","505d0ff7":"code","196dc3f0":"code","71862f5d":"code","c8851f7b":"code","7985ff8c":"code","ddf08157":"code","9d1d82d5":"code","44286443":"code","ba526de0":"code","49dc076c":"code","35b56942":"code","e8e04686":"code","8092ac07":"code","b9fc7c85":"code","460da759":"code","e6a0d90d":"code","f1170ef3":"code","d28e9ee1":"code","961c764c":"code","0a9c1534":"markdown","b77168e8":"markdown","4e5ae53d":"markdown","3c845c92":"markdown","328c48b3":"markdown","2e623a2c":"markdown","81bfc0b5":"markdown","6333042f":"markdown","68cee518":"markdown","2d199722":"markdown","c1bdd764":"markdown","4af039c2":"markdown","4cdda3b4":"markdown","97ee350c":"markdown"},"source":{"c310d769":"# Disabling warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")","2c450561":"# Import Main libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Import Visualization lib.\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","ed2ff885":"import os\nprint(os.listdir('..\/input'))","f629450b":"# set our Dataframe\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/gender_submission.csv')","4b5c85ea":"# Show first 5 rows of train data\ntrain_df.head()","6361b2c1":"# data size\nprint(\"Train Data Size: \", train_df.shape)\nprint(\"Test Data Size:  \", test_df.shape)","34481bc3":"# Show if any NAN data\ntrain_df.isnull().sum()","9cae093d":"test_df.isnull().sum()","726e9cde":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(np.nan, \"mean\")\n\ntrain_df['Age'] = imputer.fit_transform(np.array(train_df['Age']).reshape(891, 1)) # 1st\ntrain_df.Embarked.fillna(method='ffill', inplace=True) # 2nd\ntrain_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True) # 3rd\n\ntest_df['Age'] = imputer.fit_transform(np.array(test_df['Age']).reshape(418, 1))\ntest_df.Embarked.fillna(method='ffill', inplace=True)\ntest_df.Fare.fillna(method='ffill', inplace=True)\ntest_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)","e1175f18":"trn_mid = train_df.Age.median() # set median value\n\n# fill NAN data\ntrain_df.Age.fillna(trn_mid, inplace=True)\ntrain_df.Embarked.fillna(method='ffill', inplace=True)\ntrain_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)\n\ntst_mid = test_df.Age.median() # set median value\n\n# fill NAN data\ntest_df.Age.fillna(tst_mid, inplace=True)\ntest_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)","8025f716":"sns.countplot(x='Survived', hue='Sex', data=train_df)","2bfebd63":"sns.countplot(x='Embarked', hue='Survived', data=train_df)","bbc37cba":"sns.countplot(x='SibSp', hue='Survived', data=train_df)","ff6d1912":"sns.countplot(x='Pclass', hue='Survived', data=train_df)","3907f743":"plt.figure(figsize=(10,5))\nsns.distplot(train_df['Age'], bins=24, color='b')","c8122785":"train_df.info()","bd5c0899":"objects_cols = train_df.select_dtypes(\"object\").columns\nobjects_cols","3419a306":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain_df[objects_cols] = train_df[objects_cols].apply(le.fit_transform)\ntest_df[objects_cols] = test_df[objects_cols].apply(le.fit_transform)\ntrain_df[objects_cols].head()","8fbc46d1":"train_df.head()","4242160e":"plt.figure(figsize=(12, 8))\nplt.title('Titanic Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_df.corr(), linewidths=0.1, vmax=1.0, \n            square=True, linecolor='white', annot=True)","1b09c275":"from sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import accuracy_score","03312e38":"# Machine Learning \nX = train_df.drop(['Survived'], 1).values\ny = train_df['Survived'].values","f89929e9":"scale = StandardScaler()\nscale.fit(X)\n\nX = scale.transform(X)","21589887":"# Split data to 80% training data and 20% of test to check the accuracy of our model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1\/3, random_state=0)","505d0ff7":"class Model:\n    def __init__(self, model):\n        self.model = model\n        self.X, self.y = X, y\n        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n        \n        self.train()\n    \n    def model_name(self):\n        model_name = type(self.model).__name__\n        return model_name\n        \n    def cross_validation(self, cv=5):\n        print(f\"Evaluate {self.model_name()} score by cross-validation...\")\n        CVS = cross_val_score(self.model, self.X, self.y, scoring='accuracy', cv=cv)\n        print(CVS)\n        print(\"=\"*60, \"\\nMean accuracy of cross-validation: \", CVS.mean())\n    \n    def train(self):\n        print(f\"Training {self.model_name()} Model...\")\n        self.model.fit(X_train, y_train)\n        print(\"Model Trained.\")\n        \n    def prediction(self, test_x=None, test=False):\n        if test == False:\n            y_pred = self.model.predict(self.X_test)\n        else:\n            y_pred = self.model.predict(test_x)\n            \n        return y_pred\n    \n    def accuracy(self):\n        y_pred = self.prediction()\n        y_test = self.y_test\n        \n        acc = accuracy_score(y_pred, y_test)\n        print(f\"{self.model_name()} Model Accuracy: \", acc)","196dc3f0":"xgb = XGBClassifier()\nxgb = Model(xgb)","71862f5d":"xgb.cross_validation()","c8851f7b":"xgb.accuracy()","7985ff8c":"gnb = GaussianNB()\ngnb = Model(gnb)","ddf08157":"gnb.cross_validation()","9d1d82d5":"gnb.accuracy()","44286443":"svc = SVC()\nsvc = Model(svc)","ba526de0":"svc.cross_validation()","49dc076c":"svc.accuracy()","35b56942":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc = Model(rfc)\nrfc.cross_validation()\nrfc.accuracy()","e8e04686":"test_df.head()","8092ac07":"# Predict our file test\ntest_X = test_df.values\ntest_X = scale.transform(test_X)","b9fc7c85":"xgb_pred = xgb.prediction(test_x=test_X, test=True)\ngnb_pred = gnb.prediction(test_x=test_X, test=True)\nsvc_pred = svc.prediction(test_x=test_X, test=True)\nrfc_pred = rfc.prediction(test_x=test_X, test=True)","460da759":"sub.head()\nsub.to_csv('submission.csv', index=False)\nsub.head()","e6a0d90d":"sub['Survived'] = xgb_pred # Best Submission (Top 5% LB)\nsub.to_csv('xgb_submission.csv', index=False)\nsub.head(10)","f1170ef3":"sub['Survived'] = gnb_pred\nsub.to_csv('gnb_submission.csv', index=False)\nsub.head(10)","d28e9ee1":"sub['Survived'] = svc_pred\nsub.to_csv('svc_submission.csv', index=False)\nsub.head(10)","961c764c":"sub['Survived'] = rfc_pred\nsub.to_csv('rfc_submission.csv', index=False)\nsub.head(10)","0a9c1534":"Fix Data using 3 various methods. ","b77168e8":"Encode target labels with value between 0 and (n_classes - 1).","4e5ae53d":"**<h2 style='color:red'>Titanic: Simple Models For Beginners With EDA<\/h2>**\n* ** 1- Introduction **\n* ** 2- Data Preparation **\n* ** 3- Data Visualization **\n* ** 4- Preprocessing data for machine learning **\n* ** 5- Machine Learning **\n* ** 6- Submitting **\n<hr>","3c845c92":"# Machine Learing","328c48b3":"# Data Visualization","2e623a2c":"**Introduction**<br>\nThis is the legendary Titanic ML competition \u2013 the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.<br>\n**Goal**\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","81bfc0b5":"1- Thier is more NAN value in \"Cabin\", \"Age\" columns.\n2- we did not need \"PassengerId\" columns.\n\nSo we need to fix that","6333042f":"# Preprocessing data for machine learning","68cee518":"Start modeling.\n\nClass Model Idea from \"Heart Disease - Classifications\" kernel here:\nhttps:\/\/www.kaggle.com\/elcaiseri\/heart-disease-classifications","2d199722":"<h3>Thanks For Being Here.  <span style='color:red'>UPVOTE<\/span>  If Interested .. Feel Free In Comments<\/h3>","c1bdd764":"# Data Preparation","4af039c2":"As you see 3 columns have \"object\" data type. So we must convert it to numbers.","4cdda3b4":"SimpleImputer is sklearn library for Imputation of missing values\nYou Can find all of them here:\nhttps:\/\/scikit-learn.org\/stable\/modules\/impute.html#univariate-feature-imputation","97ee350c":"# Submitting"}}