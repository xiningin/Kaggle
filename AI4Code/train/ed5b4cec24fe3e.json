{"cell_type":{"20d5671c":"code","c07cf3a1":"code","03bedd87":"code","f21f2f63":"code","fb1cf07d":"code","d36dfbe9":"code","663682c4":"code","741ac6b2":"code","c2734491":"code","7b9722b5":"code","e181e3e9":"code","8bd5a04b":"code","8b112f2f":"code","880545c9":"code","e3723e66":"code","fbd2421f":"code","845aa309":"code","32b9627c":"code","1c9de63c":"code","7d0b880d":"code","8c6574db":"code","53406e9f":"code","512c6a05":"code","0bb1413d":"code","02066595":"markdown","ac99fe08":"markdown","1f8ff40b":"markdown","e781a400":"markdown","9f1af4e8":"markdown","2903d51f":"markdown","fa8af32e":"markdown","0967a68e":"markdown","9c2c2427":"markdown"},"source":{"20d5671c":"import os\nfrom tqdm.notebook import tqdm_notebook as tqdm\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras.utils import np_utils\nimport tensorflow as tf\nimport keras\nfrom keras.applications.mobilenet import MobileNet, preprocess_input\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\n\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau","c07cf3a1":"CLASS = {\n    'Black-grass': 0,\n    'Charlock': 1,\n    'Cleavers': 2,\n    'Common Chickweed': 3,\n    'Common wheat': 4,\n    'Fat Hen': 5,\n    'Loose Silky-bent': 6,\n    'Maize': 7,\n    'Scentless Mayweed': 8,\n    'Shepherds Purse': 9,\n    'Small-flowered Cranesbill': 10,\n    'Sugar beet': 11\n}\n\nINV_CLASS = {CLASS[j]:j for j in CLASS}","03bedd87":"def preprop_img(image_path, verbose=0):\n    if verbose:\n        print(image_path)\n    img=cv2.imread(image_path)\n    img=cv2.resize(img, (128,128))\n    return img","f21f2f63":"#Reading the image file and converting them to array\ntrain_image=[]\ntrain_label=[]\nBASE='..\/input\/plant-seedlings-classification\/train'\nfor i in tqdm(os.listdir(BASE), total=len(CLASS)):\n    for j in os.listdir(os.path.join(BASE,i)):\n        train_image.append(preprop_img(os.path.join(BASE,i,j)))\n        train_label.append(CLASS[i])\ntrain_image=np.array(train_image)\ntrain_label=np.array(train_label)\n\nprint(\"Shape of train_image:\",train_image.shape,\"Shape of train_label:\",train_label.shape)","fb1cf07d":"train_label_cat = keras.utils.to_categorical(train_label,len(CLASS))\nprint(train_label_cat.shape)","d36dfbe9":"plt.figure(figsize=(12,12))\n\nfor i in range(12):  \n    \n    plt.subplot(3,4,i+1)\n    \n    index = np.where(train_label==i)[0][1]\n    plt.imshow(train_image[index])\n    plt.title(INV_CLASS[np.argmax(train_label_cat[index])])\n    plt.xticks([]), plt.yticks([])\n\nplt.suptitle(\"Visualization of Plant Seedlings\", fontsize=20)    \nplt.tight_layout()\nplt.show()","663682c4":"clearTrainImg = []\nexamples = []; getEx = True\nplt.figure(figsize=(10,9))\n\nfor img in train_image:\n    \n    # Use gaussian blur\n    blurImg = cv2.GaussianBlur(img, (5, 5), 0)   \n    \n    # Convert to HSV image\n    hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  \n    \n    # Create mask (parameters - green color range)\n    lower_green = (25, 40, 50)\n    upper_green = (75, 255, 255)\n    mask = cv2.inRange(hsvImg, lower_green, upper_green)  \n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    # Create bool mask\n    bMask = mask > 0  \n    \n    # Apply the mask\n    clear = np.zeros_like(img, np.uint8)  # Create empty image\n    clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n    \n    clearTrainImg.append(clear)  # Append image without backgroung\n    \n    # Show examples\n    if getEx:\n        plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n        plt.xticks([]), plt.yticks([]), plt.title(\"Original Image\")\n        plt.subplot(2, 3, 2); plt.imshow(blurImg)  # Blur image\n        plt.xticks([]), plt.yticks([]), plt.title(\"Blur Image\")\n        plt.subplot(2, 3, 3); plt.imshow(hsvImg)  # HSV image\n        plt.xticks([]), plt.yticks([]), plt.title(\"HSV Image\")\n        plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n        plt.xticks([]), plt.yticks([]), plt.title(\"Mask\")\n        plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask\n        plt.xticks([]), plt.yticks([]), plt.title(\"Boolean mask Image\")\n        plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background\n        plt.xticks([]), plt.yticks([]), plt.title(\"Image without background\")\n        getEx = False\n\nplt.suptitle(\"Masking the Plant\", fontsize=20)\nplt.tight_layout()","741ac6b2":"# Visulaising the sample result\nclearTrainImg = np.asarray(clearTrainImg)\nplt.figure(figsize=(12,8))\n\nfor i in range(8):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(clearTrainImg[i])\n    plt.xticks([]), plt.yticks([])\n    \nplt.suptitle(\"Sample result\", fontsize=20)  \nplt.tight_layout()\nplt.show()","c2734491":"# Plot of label types numbers\nclasses = list(INV_CLASS.values())\n\nsns.set_style('darkgrid')  \nax = sns.countplot(x=0, data=pd.DataFrame(train_label))\nax.set_xticklabels(classes)\n\nplt.xticks(rotation=90)\nplt.show()","7b9722b5":"clearTrainImg = clearTrainImg \/ 255","e181e3e9":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(clearTrainImg,train_label_cat, shuffle=True, test_size=0.2)\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","8bd5a04b":"X_train=X_train.astype('float32') \nX_test=X_test.astype('float32')","8b112f2f":"datagen = ImageDataGenerator(\n        rotation_range=180,  # randomly rotate images in the range\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically \n        horizontal_flip=True,  # randomly flip images horizontally\n        vertical_flip=True  # randomly flip images vertically\n    )  \ndatagen.fit(X_train)","880545c9":"#Got 90 % test accuracy on model built from scratch\n\ntf.keras.backend.clear_session() #clear the weights\n\nnp.random.seed(2)  # Fix seed\n\nmodel = Sequential([Conv2D(filters=64, kernel_size=(5, 5), input_shape=(128, 128, 3), activation='relu'),\n                    BatchNormalization(axis=3),\n                    Conv2D(filters=64, kernel_size=(5, 5), activation='relu'),\n                    MaxPooling2D((2, 2)),\n                    BatchNormalization(axis=3),\n                    Dropout(0.1),\n                    \n                    Conv2D(filters=128, kernel_size=(5, 5), activation='relu'),\n                    BatchNormalization(axis=3),\n                    Conv2D(filters=128, kernel_size=(5, 5), activation='relu'),\n                    MaxPooling2D((2, 2)),\n                    BatchNormalization(axis=3),\n                    Dropout(0.1),\n                   \n                    Conv2D(filters=256, kernel_size=(5, 5), activation='relu'),\n                    BatchNormalization(axis=3),\n                    Conv2D(filters=128, kernel_size=(5, 5), activation='relu'),\n                    MaxPooling2D((2, 2)),\n                    BatchNormalization(axis=3),\n                    Dropout(0.1),\n                   \n                    Flatten(),\n                    \n                    Dense(256, activation='relu'),\n                    BatchNormalization(),\n                    Dropout(0.5),\n                   \n                    Dense(256, activation='relu'),\n                    BatchNormalization(),\n                    Dropout(0.5),\n                   \n                    Dense(12, activation='softmax')])\n\n\n\nmodel.summary()\n\n# compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","e3723e66":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.4, \n                                            min_lr=0.00001)","fbd2421f":"history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),epochs=5,\n                    validation_data=(X_test, Y_test),\n                    steps_per_epoch=(X_train.shape[0]),\n                    verbose=1,\n                    callbacks=[learning_rate_reduction])","845aa309":"plt.figure(figsize=(20,10))\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","32b9627c":"path = '..\/input\/samplele-data\/Sample images\/*.png'\nfiles = glob(path)\n\ntestImg = []\n\nfor img in files:\n    testImg.append(cv2.resize(cv2.imread(img), (128, 128)))\n\ntestImg = np.asarray(testImg)  # Train images set\n\nplt.figure(figsize=(10,6))\nfor i in range(5):\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(testImg[i])\n    \nplt.suptitle(\"Visualising the test dataset\", fontsize=20)    \nplt.tight_layout()\nplt.show()","1c9de63c":"clearTestImg = []\nexamples = []; getEx = True\nplt.figure(figsize=(10,9))\n\nfor img in testImg:\n    # Use gaussian blur\n    blurImg = cv2.GaussianBlur(img, (5, 5), 0)   \n    \n    # Convert to HSV image\n    hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  \n    \n    # Create mask (parameters - green color range)\n    lower_green = (25, 40, 50)\n    upper_green = (75, 255, 255)\n    mask = cv2.inRange(hsvImg, lower_green, upper_green)  \n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    # Create bool mask\n    bMask = mask > 0  \n    \n    # Apply the mask\n    clear = np.zeros_like(img, np.uint8)  # Create empty image\n    clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n    \n    clearTestImg.append(clear)  # Append image without backgroung\n    \n    # Show examples\n    if getEx:\n        plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n        plt.xticks([]), plt.yticks([]), plt.title(\"Original Image\")\n        plt.subplot(2, 3, 2); plt.imshow(blurImg)  # Blur image\n        plt.xticks([]), plt.yticks([]), plt.title(\"Blur Image\")\n        plt.subplot(2, 3, 3); plt.imshow(hsvImg)  # HSV image\n        plt.xticks([]), plt.yticks([]), plt.title(\"HSV Image\")\n        plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n        plt.xticks([]), plt.yticks([]), plt.title(\"Mask\")\n        plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask\n        plt.xticks([]), plt.yticks([]), plt.title(\"Boolean mask Image\")\n        plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background\n        plt.xticks([]), plt.yticks([]), plt.title(\"Image without background\")\n        getEx = False\n\nplt.suptitle(\"Masked Test Image\", fontsize=20)\nplt.tight_layout()\nclearTestImg = np.asarray(clearTestImg)","7d0b880d":"#Normalizing the test data\nclearTestImg = clearTestImg \/ 255","8c6574db":"pred = model.predict(clearTestImg)\npredNum = np.argmax(pred, axis=1)","53406e9f":"testId = []\nfor i in files:\n    testId.append(i.split('\/')[-1]) ","512c6a05":"predStr=[]\nfor i in predNum:\n    predStr.append(INV_CLASS[i])","0bb1413d":"plt.figure(figsize=(12,12))\n\nfor i,j in enumerate(files[:5]):  \n    \n    plt.subplot(3,4,i+1)\n    \n    img = np.array(cv2.imread(j))\n    plt.imshow(img)\n    plt.title(predStr[i])\n    plt.xticks([]), plt.yticks([])\n\nplt.suptitle(\"Visualization of Predicted Plant Seedlings\", fontsize=20)    \nplt.tight_layout()\nplt.show()","02066595":"## EDA, Visualization and Data preparation","ac99fe08":"## Splitting the data\n* Splitting the image data into train and test class","1f8ff40b":"## Visualizing the training","e781a400":"## Visualising Prediction","9f1af4e8":"## Predictions","2903d51f":"## Importing Library","fa8af32e":"## Preparing Test Data","0967a68e":"## Defining Class","9c2c2427":"## Callback"}}