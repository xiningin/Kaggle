{"cell_type":{"e645e680":"code","6d1dc3dc":"code","5c417f2a":"code","b45cbdde":"code","483cbac1":"code","aedc458d":"code","df83bced":"code","a0a75402":"code","1b3be05e":"code","56b44540":"code","372b1e21":"code","7ff58f37":"code","0309de94":"code","524afa1e":"code","d7895972":"code","6358c3a3":"code","e4c56a95":"code","1b2ec831":"code","25c91f1c":"code","4b2a8c34":"code","a1f935cd":"code","151a85fe":"code","465c98ef":"code","b427e053":"code","a232dc2f":"code","83357ee4":"markdown","2d546775":"markdown","9ce9ddaa":"markdown","50c2fcb2":"markdown","2aa480cd":"markdown","20348dc1":"markdown","139e56e5":"markdown","54d38836":"markdown","8c8c986f":"markdown","a745fb57":"markdown","fc237d28":"markdown","2877fcfb":"markdown","14517264":"markdown","5f67d8fc":"markdown","2ac3236b":"markdown"},"source":{"e645e680":"import os\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn.metrics as metrics\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom keras.utils import np_utils\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, ResNet101, Xception\nfrom tensorflow.keras.layers import Input, Dense, Flatten, MaxPooling2D, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, InputLayer","6d1dc3dc":"LR = 0.0001\nEPOCHS = 7\nBATCH_SIZE = 32\nIMG_SIZE = 224","5c417f2a":"imagePaths = []\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'):\n    for filename in filenames:\n        if (filename[-3:] == 'png'):\n            imagePaths.append(os.path.join(dirname, filename))\n\n#Should return true for our dataset.\nlen(imagePaths) == 219+1341+1345","b45cbdde":"print(imagePaths[66])\n\nimage = cv2.imread(imagePaths[0])\nprint(image.shape)\n\nplt.imshow(image)\nplt.show()","483cbac1":"X = []\ny = []\n\nfor img_path in imagePaths:\n    label = img_path.split(os.path.sep)[-2]\n    \n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\/255.0\n    \n    X.append(img)\n    y.append(label)\n\nX = np.array(X)\ny = np.array(y)\n\nprint(type(X), type(y), '\\n')\nprint(X.shape, y.shape)","aedc458d":"#View counts of different labels\ny_df = pd.DataFrame(y, columns=['Labels'])\nprint(y_df.head(), \"\\n\")\nprint(y_df['Labels'].value_counts())\n\nsns.countplot(y_df['Labels'])\nplt.show()","df83bced":"#Encode labels as integers\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n#Convert list of labels to one-hot format\ny_encoded = np_utils.to_categorical(y_encoded)","a0a75402":"#Check properties of label array\nprint(y_encoded, '\\n')\nprint(y_encoded[0], '\\n')\nprint(type(y_encoded), '\\n')\nprint(le.classes_, '\\n')","1b3be05e":"#Generate training and testing subsets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.25, stratify=y_encoded, random_state=3)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\ntrain_aug = ImageDataGenerator(rotation_range=15)","56b44540":"#Code to create custom model is provided for convenience\n\ndef my_model():\n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n    model.add(MaxPooling2D((2, 2), padding='same'))\n    model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add(MaxPooling2D((2, 2), padding='same'))\n    model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add(MaxPooling2D((2, 2), padding='same'))\n    model.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add(MaxPooling2D((2, 2), padding='same'))\n    model.add(Conv2D(512, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add(MaxPooling2D((2, 2), padding='same'))\n    model.add(Flatten())\n    model.add(Dropout(0.25))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(3, activation='sigmoid'))\n\n    return model","372b1e21":"#Transfer learning with VGG16\n\ndef VGG16_model():\n    base_model = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    output = base_model.layers[-1].output\n    output = Flatten()(output)\n    \n    model = Model(base_model.input, outputs=output)\n    \n    for layer in model.layers:\n        layer.trainable = False\n    \n    return model","7ff58f37":"#Transfer learning with ResNet101\n\ndef ResNet101_model():\n    base_model = ResNet101(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    output = base_model.layers[-1].output\n    output = Flatten()(output)\n    \n    model = Model(base_model.input, outputs=output)\n    \n    for layer in model.layers:\n        layer.trainable = False\n    \n    return model","0309de94":"#Transfer learning with Xception\n\ndef Xception_model():\n    base_model = Xception(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    output = base_model.layers[-1].output\n    output = Flatten()(output)\n    \n    model = Model(base_model.input, outputs=output)\n    \n    for layer in model.layers:\n        layer.trainable = False\n    \n    return model","524afa1e":"covid_model = Sequential()\ncovid_model.add(VGG16_model()) #Change to ResNet or Xception as preferred\ncovid_model.add(Dropout(0.25))\ncovid_model.add(Dense(512, activation='relu'))\ncovid_model.add(Dropout(0.25))\ncovid_model.add(Dense(64, activation='relu'))\ncovid_model.add(Dense(3, activation='sigmoid'))\n\ncovid_model.summary()","d7895972":"optim = Adam(lr = LR, decay = LR\/EPOCHS)\n\ncovid_model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\nhistory = covid_model.fit_generator(train_aug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                                    steps_per_epoch=len(X_train)\/\/BATCH_SIZE,\n                                    validation_data=(X_test, y_test),\n                                    validation_steps=len(X_test)\/\/BATCH_SIZE,\n                                    epochs=EPOCHS,\n                                    verbose=1)","6358c3a3":"print(history.history.keys())","e4c56a95":"#Accuracy plot\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1b2ec831":"#Loss plot\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","25c91f1c":"score = covid_model.evaluate(X_test, y_test)\nprint(\"Model accuracy on validation dataset: %f.\" %(score[1]*100))","4b2a8c34":"y_pred = np.argmax(covid_model.predict(X_test), axis=1)\nprint(y_pred)\nprint(len(y_pred))\nprint(le.classes_)","a1f935cd":"y_test_labels = np.argmax(y_test, axis=1)\nprint(y_test_labels)\nprint(len(y_test_labels))","151a85fe":"#Confusion matrix\ncm = confusion_matrix(y_test_labels, y_pred)\nprint(cm)\ncm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\ncm_df.head()","465c98ef":"sns.set(font_scale=1.5, color_codes=True, palette='deep')\nsns.heatmap(cm_df, annot=True, annot_kws={'size':16}, fmt='d', cmap='YlGnBu')\nplt.ylabel(\"True Label\")\nplt.xlabel(\"Predicted Label\")\nplt.title('Confusion Matrix of Validation Data')\nplt.show()","b427e053":"covid_model.save('covid_model_v1')","a232dc2f":"A few summary and learning points.\n\n* This model appears to have high specificity for COVID-19. That is, if the model predicts COVID-19, there is actually a very good chance that it is COVID-19. Another way to phrase this is that if the image is not COVID-19, there is a good chance that the model will predict it is not COVID-19.\n* Theoretically speaking, if such a model were to be implemented in a clinical setting, it may be helpful in that if it gives a prediction of COVID-19 to a chest X-ray, special attention should be paid to the image as there is a good chance it may represent an actual case of COVID-19.\n* The prevalence of COVID-19 in a particular patient population is important for designing a good training set, but it is very difficult to determine. \n* COVID-19 images may be misinterpreted as viral pneumonia, which makes sense. However, few viral pneumonia images are mislabeled as COVID-19.","83357ee4":"Please feel free to share this notebook as you like, and give me credit if you do so. If you like what you see here, you can check out my Kaggle profile. You can also follow me on Twitter [@leoyuguanall38](https:\/\/twitter.com\/leoyuguanall38). Please also check out my [GitHub profile](https:\/\/github.com\/leoyuguanall38).","2d546775":"Analyzing the training and validation statistics for our model.","9ce9ddaa":"We will use a confusion matrix to better visualize our predicted vs true values for the validation data.","50c2fcb2":"We did not set aside a separate testing dataset, so we will use the validation dataset for illustration purposes. Keep in mind that the validation dataset in this case is not a good evaluation of the accuracy of the model because it is data that the model has already seen.","2aa480cd":"Save model weights for future use.","20348dc1":"This notebook is intended to serve as an introduction to transfer learning as a method of classifying chest x-rays into 3 categories (COVID-19, viral pneumonia, normal). The goal here is to introduce the concept of deep learning as a way to classify chest x-rays and in particular for patients with COVID-19. The models produced here are not intended to substitute for an impression given by an expert radiologist. Rather it may serve as a foundation for those who are interested in applications of deep learning in medicine for triaging, diagnosis, prognosis, and treatment.\n\nIt should be noted that there are many limitations associated with such a model, including using only 3 classes of CXRs. It is also impossible to accurately predict the distribution of CXRs that you will obtain in a real clinical setting. \n\nThe dataset we are using is the Covid-19 Radiography Database which is publically available on Kaggle at this url, https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database. Please refer to this url for details regarding the dataset. The following reference is provided to give credit to the team responsible for organizing the dataset.\n\nM.E.H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M.A. Kadir, Z.B. Mahbub, K.R. Islam, M.S. Khan, A. Iqbal, N. Al-Emadi, M.B.I. Reaz, \u201cCan AI help in screening Viral and COVID-19 pneumonia?\u201d arXiv preprint, 29 March 2020, https:\/\/arxiv.org\/abs\/2003.13145. https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database\n\nIt should be noted that some of the normal and viral pneumonia chest x-ray images are obtained from existing datasets on Kaggle.","139e56e5":"Let's convert the label list to a one hot format.","54d38836":"Set constants and hyperparameter values:","8c8c986f":"Obtain list of image paths. Last line is to verify number of image paths obtained matches number of expected images for our dataset.","a745fb57":"Use the following code to view sample images from the dataset.","fc237d28":"Let's start with imports:","2877fcfb":"Thank you for checking out this notebook. Check out my [Twitter](https:\/\/twitter.com\/leoyuguanall38) and [GitHub profile](https:\/\/github.com\/leoyuguanall38) if you like what you see here.","14517264":"Use the following code to convert list of image paths to ndarrays containing image data and labels.","5f67d8fc":"Use the following code to design your model. In this tutorial we will focus primarily on transfer learning, although code is also provided to create your own model.","2ac3236b":"Code for transfer learning model. Each pre-trained model is loaded by a separate function and then added to sequential model with FC layers to produce final classification."}}