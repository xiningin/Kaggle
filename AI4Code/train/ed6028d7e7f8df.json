{"cell_type":{"8ad470ed":"code","8daca879":"code","e5f28d09":"code","730962a5":"code","18079579":"code","1f9a27dd":"code","15bb4484":"code","42a6b7e5":"code","500bfe7a":"code","e0dc5325":"code","2eb0a4dc":"code","948cea4d":"code","60af5fb4":"code","68810a63":"code","7deeb520":"code","f14a0e53":"code","781973d5":"code","029cef98":"code","6d19ed25":"markdown","45b1fd99":"markdown","08a85332":"markdown","fc9ab9fd":"markdown","e7cfaa73":"markdown","fa31bce9":"markdown","de135265":"markdown","1bffa07c":"markdown","7fe505b9":"markdown","af60f77d":"markdown","c97844b2":"markdown"},"source":{"8ad470ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8daca879":"import glob\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport zipfile","e5f28d09":"def split(data_path,train,validation,split_size=0.1):\n    folders = os.listdir(data_path)\n    for f in folders:\n        fullpath = os.path.join(data_path,f)\n        image = glob.glob(os.path.join(fullpath,'*.png'))\n       \n        x_train,x_val = train_test_split(image,test_size = split_size)\n        #print(\"folder name\",f,len(x_train))\n       \n        for x in x_train:\n         #   print(x)\n            path_to_folder = os.path.join(train,f)\n           \n            if not os.path.isdir(path_to_folder):\n                os.makedirs(path_to_folder)\n            shutil.copy(x,path_to_folder)\n       \n        for y in x_val:\n            path_to_folder = os.path.join(validation,f)\n            if not os.path.isdir(path_to_folder):\n                os.makedirs(path_to_folder)\n            shutil.copy(y,path_to_folder)","730962a5":"data_path = '..\/input\/gtsrb-german-traffic-sign\/Train'\nif not os.path.isdir('\/kaggle\/working\/Training'):\n    os.mkdir('\/kaggle\/working\/Training')\nif not os.path.isdir('\/kaggle\/working\/Validation'):\n    os.mkdir('\/kaggle\/working\/Validation')\n\ntrain = '\/kaggle\/working\/Training'\nvalidation = '\/kaggle\/working\/Validation'\nsplit(data_path,train=train,validation=validation,split_size = 0.1)","18079579":"df =pd.read_csv(\"..\/input\/gtsrb-german-traffic-sign\/Test.csv\")\ndf['Path'] = df['Path'].str.replace('Test\/','')\ndf.to_csv('\/kaggle\/working\/Test1.csv')\nos.mkdir(\"\/kaggle\/working\/Test\")","1f9a27dd":"def prepare_test(path_to_image,path_file):\n\n    with open(path_file,\"r\") as csvfile:\n        r= csv.reader(csvfile,delimiter =',')\n  \n        for i,row in enumerate(r):\n            if i == 0: \n                continue\n            label = row[-2]\n            img_name = row[-1]\n            \n            dest = os.path.join('\/kaggle\/working\/Test\/',label)\n            if not os.path.isdir(dest):\n                os.makedirs(dest)\n            \n            to_move = os.path.join(path_to_image,img_name)\n            shutil.copy(to_move,dest)","15bb4484":"import csv\npath_to_image = \"..\/input\/gtsrb-german-traffic-sign\/Test\"\npath_file ='\/kaggle\/working\/Test1.csv'\nprepare_test(path_to_image,path_file)","42a6b7e5":"import tensorflow\nfrom tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, Flatten, BatchNormalization, GlobalAvgPool2D,Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom tensorflow.keras import Model\nimport PIL","500bfe7a":"def run_cnn(number_classes):\n    \n    i_shape = Input(shape=(60,60,3)) #Check the picture sizes randomly and decided. Can also done systematically by checking for all files and using median value\n    x = Conv2D(32, (3,3), activation='relu', padding=\"same\") (i_shape)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x)\n    \n    x = Conv2D(64, (3,3),  activation='relu', padding=\"same\") (x)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x)\n    \n    x = Conv2D(128, (3,3),  activation='relu', padding=\"same\") (x)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x)  \n    \n    x = Conv2D(128, (3,3),  activation='relu') (x)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x) \n    \n      \n   # x = Flatten()(x)\n    x = GlobalAvgPool2D()(x)\n    x = Dense(1024,  activation='relu') (x)\n    x = Dense(number_classes,activation=\"softmax\")(x)\n    \n\n    return Model(inputs=i_shape,outputs=x)","e0dc5325":"def run_cnn_elu(number_classes):\n    \n    i_shape = Input(shape=(60,60,3)) #Check the picture sizes randomly and decided. Can also done systematically by checking for all files and using median value\n    x = Conv2D(32, (3,3), activation='elu', padding=\"same\") (i_shape)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x)\n    \n    x = Conv2D(64, (3,3),  activation='elu', padding=\"same\") (x)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x)\n    \n    x = Conv2D(128, (3,3),  activation='elu', padding=\"same\") (x)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x)  \n    \n    x = Conv2D(128, (3,3),  activation='elu') (x)\n    x = MaxPool2D()(x)\n    x = BatchNormalization()(x) \n    \n      \n   # x = Flatten()(x)\n    x = GlobalAvgPool2D()(x)\n    x = Dense(1024,  activation='elu') (x)\n    x = Dense(number_classes,activation=\"softmax\")(x)\n    \n\n    return Model(inputs=i_shape,outputs=x)","2eb0a4dc":"def create_generators(train_dir,batch_size,validation_dir,test_dir):\n  #  train_datagen1 = ImageDataGenerator(\n   #   rescale=1.\/255,\n    #  rotation_range=40,\n     # width_shift_range=0.2,\n      #height_shift_range=0.2,\n      #shear_range=0.2,\n      #zoom_range=0.2,\n      #horizontal_flip=True,\n      #fill_mode='nearest')\n     \n    train_datagen = ImageDataGenerator(\n      rescale=1.\/255)\n    \n    validation_datagen = ImageDataGenerator(rescale=1.\/255)\n    test_datagen = ImageDataGenerator(rescale=1.\/255)\n     \n    train_generator=train_datagen.flow_from_directory(\n         train_dir,target_size=(60,60),batch_size = batch_size,\n         color_mode = 'rgb',class_mode =\"categorical\",\n         shuffle=True)\n     \n    validation_generator=validation_datagen.flow_from_directory(\n         validation_dir,target_size=(60,60),batch_size = batch_size,\n         color_mode = 'rgb',class_mode =\"categorical\",\n         shuffle=True)\n     \n    test_generator=test_datagen.flow_from_directory(\n         test_dir,target_size=(60,60),batch_size = batch_size,\n         color_mode = 'rgb',class_mode =\"categorical\",\n         shuffle=True) \n     \n    return(train_generator,validation_generator,test_generator)","948cea4d":"train_dir = train\nvalidation_dir = validation\ntest_dir = '\/kaggle\/working\/Test'\nbatch_size = 60\nnumber_classes = 43 \n\nos.mkdir('\/kaggle\/working\/model1')\npath_to_save_model = '\/kaggle\/working\/model1'\nchkpt_saver = ModelCheckpoint(\n    path_to_save_model, monitor='val_accuracy',\n    mode ='max',save_best_only= True,\n    save_freq='epoch',verbose = 1\n    )\n\n\n \ntrain_generator,validation_generator,test_generator = create_generators(train_dir,batch_size,validation_dir,test_dir)  \nmodel =   run_cnn(number_classes)\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(train_generator, # 2000 images = batch_size * steps\n      epochs=15,batch_size = batch_size,\n      validation_data=validation_generator, callbacks=[chkpt_saver]\n    ) \n  \n     \nmodel = tensorflow.keras.models.load_model(path_to_save_model)  \n","60af5fb4":"train_dir = train\nvalidation_dir = validation\ntest_dir = '\/kaggle\/working\/Test'\nbatch_size = 60\nnumber_classes = 43 \n\nos.mkdir('\/kaggle\/working\/model_n')\npath_to_save_model = '\/kaggle\/working\/model_n'\nchkpt_saver = ModelCheckpoint(\n    path_to_save_model, monitor='val_accuracy',\n    mode ='max',save_best_only= True,\n    save_freq='epoch',verbose = 1\n    )\n\n\n \ntrain_generator,validation_generator,test_generator = create_generators(train_dir,batch_size,validation_dir,test_dir)  \nmodel_n =   run_cnn_elu(number_classes)\nmodel_n.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model_n.fit(train_generator, # 2000 images = batch_size * steps\n      epochs=15,batch_size = batch_size,\n      validation_data=validation_generator, callbacks=[chkpt_saver]\n    ) \n  \n     \nmodel_n = tensorflow.keras.models.load_model(path_to_save_model)  ","68810a63":"\nprint(\"validation set\")\nmodel.evaluate(validation_generator)\nprint(\"test set\")\nmodel.evaluate(test_generator)\n\n \n    ","7deeb520":"\nprint(\"validation set\")\nmodel_n.evaluate(validation_generator)\nprint(\"test set\")\nmodel_n.evaluate(test_generator)","f14a0e53":"\ntrain_1_fnames = os.listdir( '\/kaggle\/working\/Training\/1' )\ntrain_2_fnames = os.listdir( '\/kaggle\/working\/Training\/2' )\n\nprint(train_1_fnames[:10])\nprint(train_2_fnames[:10])\n","781973d5":"import numpy as np\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n\nvisualization_model = tensorflow.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n\nsign1_files = [os.path.join('\/kaggle\/working\/Training\/1', f) for f in train_1_fnames]\nsign2_files = [os.path.join('\/kaggle\/working\/Training\/2', f) for f in train_2_fnames]\n\nimg_path = random.choice(sign1_files + sign2_files)\nimg = load_img(img_path, target_size=(60, 60))  # this is a PIL image\n\nx   = img_to_array(img)                          \nx   = x.reshape((1,) + x.shape)                  \n\n# Rescale by 1\/255\nx \/= 255.0\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n\n# Now let's display our representations\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x \/= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. \/ n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' )\n","029cef98":"\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","6d19ed25":"# Create a functional CNN\n\nI have created 3 Convolutional layers with Maxpool layers in between. For all layers I have maintained same padding to ensure the layer's outputs to have same spatial dimensions as its inputs. This will ensure we dont miss out the info in the edges. These are all small images and we cant afford to miss out the edges\n\nI also tried other activation functions like Selu. But only relu provides the highest accuracy\n","45b1fd99":"# Generators - Train, Validation & Test\n\nData augmentation was not that helpful for this case study. So commented out that part. Usually, data augmentation helps well. For Eg. Check out my other notebook on cats vs dogs classification ","08a85332":"# Split the folders\n**> *Write a function to split the existing train folder to training and validation folders. ***","fc9ab9fd":"With Elu activation function","e7cfaa73":"Model fitting for ELu","fa31bce9":"# Plot the training\/validation accuracy ","de135265":"# Visualizing Intermediate Representations\nTo get a feel for what kind of features our convnet has learned, one fun thing to do is to visualize how an input gets transformed as it goes through the convnet.","1bffa07c":"# Prepare Test Data","7fe505b9":"# Fit the model\nUse callbacks to save the best model based on validation accuracy","af60f77d":"# Start Modelling","c97844b2":"**Import necessary libraries**"}}