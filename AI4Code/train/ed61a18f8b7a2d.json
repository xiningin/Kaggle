{"cell_type":{"adc946c3":"code","1cfefa43":"code","8bcc176e":"code","9aff7a92":"code","dc12b39d":"code","80d0e08d":"code","f7986048":"code","0ba1b2b2":"code","ba342296":"code","051efc99":"code","aa773ff5":"code","88b5de8e":"code","6d10bdaa":"code","087fd976":"code","69ada8ae":"code","7be97dee":"code","8ed41e22":"code","92ac42e8":"code","fdc87351":"code","f101aca8":"code","bd448175":"markdown","defaefdd":"markdown","94796954":"markdown","2bf043f2":"markdown","476a1856":"markdown","5546b7a8":"markdown","88551d0f":"markdown"},"source":{"adc946c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1cfefa43":"building_metadata=pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/building_metadata.csv')\nweather_train=pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/weather_train.csv')\ntrain=pd.read_csv('\/kaggle\/input\/ashrae-energy-prediction\/train.csv')","8bcc176e":"#view some records of building_metadata\n\nbuilding_metadata.head()","9aff7a92":"building_metadata.describe()","dc12b39d":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props, NAlist","80d0e08d":"reduce_mem_usage(train)\n","f7986048":"reduce_mem_usage(weather_train)","0ba1b2b2":"building_metadata.loc[: ,['building_id', 'primary_use']].groupby('primary_use').count().plot(kind='bar')","ba342296":"#display some rows of train data\ntrain.head()","051efc99":"#display information about train data. After a first attempt, added a column meter_reading_int to make it more readble\ntrain['meter_reading_int']=train['meter_reading'].apply(lambda x: int(x))\nprint(train['meter_reading_int'].mean())","aa773ff5":"train.describe()","88b5de8e":"def ecdf(data):\n    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n    # Number of data points: n\n    n = len(data)\n\n    # x-data for the ECDF: x\n    x = np.sort(data)\n\n    # y-data for the ECDF: y\n    y = np.arange(1, n+1) \/ n\n\n    return x, y\n","6d10bdaa":"import matplotlib.pyplot as plt\nx, y = ecdf(train[\"meter_reading\"])","087fd976":"_ = plt.hist(x, y, bin=50)\nplt.show()","69ada8ae":"weather_train.describe()","7be97dee":"#take a look on how surface, number of floors and building age are correlated\nimport matplotlib.pyplot as plt \nmetadata_pivot = building_metadata.groupby(building_metadata[\"primary_use\"]).count()\n\nplt.xticks(rotation=90)\n_ = plt.bar(metadata_pivot.index, metadata_pivot.site_id)\n","8ed41e22":"#merge the data \ntrain_details = building_metadata.merge(train, on=\"building_id\")","92ac42e8":"train_details.describe()","fdc87351":"train_details.head()","f101aca8":"train_details['timestamp']=pd.to_datetime(['timestamp'])\n","bd448175":"**Load the data files into Panda dataframes**","defaefdd":"**Define memory optimization function**","94796954":"**Explore Train data**","2bf043f2":"Define ECDF function, can be usefull for data representation","476a1856":"**![](http:\/\/)![](http:\/\/)Explore Building Meta Data content**","5546b7a8":"Notice here above the statistics are not relevant for site_id and building_id but you can check out the average square feet, year of build and number of floors. You can also check the min and max of these to say a few. Also seems that we have 1449 buildings. There are no statistics available for categorical data.\n\nLet's see then how the buildings are distributed by primary_use","88551d0f":"**Not clear to me why soo big proportion of Education buildings**"}}