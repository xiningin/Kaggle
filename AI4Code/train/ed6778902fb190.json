{"cell_type":{"2b97d558":"code","dd4948a0":"code","ab71c462":"code","d42cc6a2":"code","ba5820ba":"code","b15e72c6":"code","05c34923":"code","ed14f430":"code","64e31631":"code","a9013b35":"code","9d42f9e5":"code","38323aaa":"code","90d6855c":"code","b10d8534":"code","58f55884":"code","03c48ebd":"code","10ce1a2a":"code","8399ee30":"code","6ee60484":"code","5629e8e5":"code","6b7b69f6":"code","ab6452bc":"code","310adb72":"code","90389be8":"code","d08905cf":"code","fe3e3919":"code","1567711c":"code","510e122c":"code","6d0f4e78":"code","ebc0b5ec":"code","65c83757":"code","979b585a":"code","c487aa3e":"code","d9118a66":"markdown","1e3d5e4e":"markdown","599d939c":"markdown","d582568d":"markdown","cdd05cfe":"markdown","a3b9944f":"markdown","c0861afa":"markdown","b1506a47":"markdown","faa0c32b":"markdown"},"source":{"2b97d558":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd4948a0":"import numpy as np\nimport pandas as pd\nimport datetime as dt\n\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\nimport matplotlib.pyplot as plt\nimport squarify\nimport seaborn as sns\n\n\nimport os\nprint(os.listdir('..\/input\/'))\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)","ab71c462":"df = pd.read_csv('..\/input\/onlineretail\/OnlineRetail.csv', encoding = 'unicode_escape')\nprint(df.shape)\ndf.head()","d42cc6a2":"df.info()","ba5820ba":"df.dropna(inplace=True)\n# there are negative values on Quantity variable, this is caused by the refund invoices (Invoices containing the letter \"C\"), reassign df without refund invoices\ndf = df[~df[\"InvoiceNo\"].str.contains(\"C\", na=False)]","b15e72c6":"df.describe([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).T","05c34923":"df[[\"Quantity\", \"UnitPrice\"]].boxplot();","ed14f430":"# checking the different values for country in the dataset\n\nplt.rcParams['figure.figsize'] = (12, 10)\na = df['Country'].value_counts().head(21)[1:]\nsns.barplot(x = a.values, y = a.index, palette = 'PuBuGn_d')\nplt.title('Top 20 Countries having Online Retail Market except UK', fontsize = 20)\nplt.xlabel('Names of Countries')\nplt.ylabel('Count')\nplt.show()","64e31631":"# looking at each country's sales\ncolor = plt.cm.viridis(np.linspace(0, 1, 20))\ndf['Sales'] = df['UnitPrice'] * df['Quantity']\ndf['Sales'].groupby(df['Country']).agg('sum').sort_values(ascending = False).head(21)[1:].plot.bar(figsize = (15, 7),color = color)\n#sns.barplot(x = b.values, y = b.index, palette = 'magma')\nplt.title('Top 20 Sales of all the Countries Except UK', fontsize = 20)\nplt.xlabel('Names of the Countries')\nplt.ylabel('Number of sales')\nplt.show()","a9013b35":"from wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'white', width = 900, height = 900).generate(str(df['Description']))\n\nprint(wordcloud)\nplt.rcParams['figure.figsize'] = (12, 12)\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.title('Most Occuring word in the Description list', fontsize = 20)\nplt.show()","9d42f9e5":"# checking how many unique customer IDs and different number of unique countriesare there\n\nx = df['CustomerID'].nunique()\ny = df['Country'].nunique()\n\n# printing the value\nprint(\"There are {} number of different customers\".format(x))\nprint(\"There are {} number of different countries who do online retailing from UK\".format(y))\n","38323aaa":"# time-series plot for Australia\n\ndataset = df[df['Country'] == 'Australia']\ndataset.plot(x = 'InvoiceDate', y = 'Sales')\nplt.title('Time-Series for Australia', fontsize = 20)\nplt.xlabel('Date of Purchase')\nplt.ylabel('Sales Amount')\nplt.show()","90d6855c":"df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\ndf.head(2)","b10d8534":"#creating invoice month column to see first month when customer purchased \ndf['InvoiceMonth'] = df['InvoiceDate'].apply(lambda x: dt.datetime(x.year, x.month, 1))\n\n#assign smallest invoice value to each customer\ndf['CohortMonth'] = df.groupby('CustomerID')['InvoiceMonth'].transform('min')\ndf.head()","58f55884":"#function to extract year, month, day as integers\ndef get_date_int(df, column):\n    year = df[column].dt.year\n    month = df[column].dt.month\n    day = df[column].dt.day\n    return year, month, day","03c48ebd":"#extract month\ninvoice_year, invoice_month, _ = get_date_int(df, 'InvoiceMonth')\ncohort_year, cohort_month, _ = get_date_int(df, 'CohortMonth')","10ce1a2a":"years_diff = invoice_year - cohort_year\nmonths_diff = invoice_month - cohort_month","8399ee30":"# Extract the difference in days from all previous values\ndf['CohortIndex'] = years_diff * 12 + months_diff + 1\ndf.head(2)","6ee60484":"#count monthly active customers from each cohort\ncohort_data = df.groupby(['CohortMonth', 'CohortIndex'])['CustomerID'].apply(pd.Series.nunique).reset_index()\ncohort_counts = cohort_data.pivot(index='CohortMonth', columns = 'CohortIndex', values='CustomerID')","5629e8e5":"#Customer retention\ncohort_sizes = cohort_counts.iloc[:,0]\nretention = cohort_counts.divide(cohort_sizes, axis=0)\nretention = retention.round(3) * 100\nretention.head(20)","6b7b69f6":"month_list = [\"Dec '10\", \"Jan '11\", \"Feb '11\", \"Mar '11\", \"Apr '11\",\\\n              \"May '11\", \"Jun '11\", \"Jul '11\", \"Aug '11\", \"Sep '11\", \\\n              \"Oct '11\", \"Nov '11\", \"Dec '11\"]\n\nplt.figure(figsize=(15,8))\nplt.title('Retention by Monthly Cohorts')\nsns.heatmap(data=retention,\n            annot = True,\n            cmap = \"Greens\",\n            vmin = 0.0,\n            vmax = list(retention.max().sort_values(ascending = False))[1]+3,\n            fmt = '.1f',\n            linewidth = 0.3,\n            yticklabels=month_list)\n\nplt.show()","ab6452bc":"last_date = df['InvoiceDate'].max() #+ dt.timedelta(days=1)\nlast_date","310adb72":"rfm = df.groupby('CustomerID').agg({'InvoiceDate': lambda date: (last_date - date.max()).days,\n                                    'InvoiceNo': lambda inv: inv.nunique(),\n                                    'Sales': lambda price: price.sum()})\nrfm.columns = ['Recency', 'Frequency', 'Monetary']\nrfm.head()","90389be8":"#check if there are any zeros in rfm:\nrfm.describe([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]).T","d08905cf":"rfm[\"RecencyScore\"] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])\n\nrfm[\"FrequencyScore\"] = pd.qcut(rfm['Frequency'].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n\nrfm[\"MonetaryScore\"] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])","fe3e3919":"rfm[\"RFM_SCORE\"] = (rfm['RecencyScore'].astype(str) +\n                    rfm['FrequencyScore'].astype(str) +\n                    rfm['MonetaryScore'].astype(str))\n\nrfm.head()","1567711c":"# display some of the customers with the highest scores:\nrfm[rfm['RFM_SCORE'] == \"555\"].head()","510e122c":"# the following dict has been made according to the famous RFM graphic\nseg_map = {\n    r'[1-2][1-2]': 'Hibernating',      # Customer's shopped long ago but with less frequency and monetary value\n    r'[1-2][3-4]': 'At_Risk',          # Customer's shopping less often now who used to shop a lot\n    r'[1-2]5': 'Cant_Lose',            # Customer's shopped long ago who used to shop a lot.\n    r'3[1-2]': 'About_to_Sleep',\n    r'33': 'Need_Attention',           # High monetary value but good recency and frequency values\n    r'[3-4][4-5]': 'Loyal_Customers',  # High frequency as well as monetary value with good recency\n    r'41': 'Promising',\n    r'51': 'New_Customers',            # Customer's who recently started shopping a lot but with less monetary value\n    r'[4-5][2-3]': 'Potential_Loyalists', # High recency and monetary value, average frequency\n    r'5[4-5]': 'Best Customers'        # Highest frequency as well as monetary value with least recenc\n}","6d0f4e78":"#we will be using Recency and Frequency scores for customer segmentation. \n#We are assuming that a customer who has recently purchased and who is often purchasing should have high RFM scores.\nrfm['Segment'] = rfm['RecencyScore'].astype(str) + rfm['FrequencyScore'].astype(str)\nrfm['Segment'] = rfm['Segment'].replace(seg_map, regex=True)\nrfm=rfm.reset_index()\nrfm.head(2)","ebc0b5ec":"rfm[[\"Segment\", \"Recency\", \"Frequency\", \"Monetary\"]].groupby(\"Segment\").agg([\"mean\", \"count\"])","65c83757":"rfm.head()","979b585a":"retail_rfm_segments = rfm.groupby('Segment')['CustomerID'].count().reset_index(name='counts')\nretail_rfm_segments.head(15)","c487aa3e":"#let's exclude others segment for visualization\nsegment = list(retail_rfm_segments.Segment)\nscore = list(retail_rfm_segments.counts)\ncolor_list = [\"#248af1\", \"#eb5d50\", \"#8bc4f6\", \"#8c5c94\", \"#a170e8\", \"#fba521\", \"#75bc3f\",'#50ebde','#808080']\nplt.figure(figsize=(12,8))\nplt.title('Customer Segments distribution')\nsquarify.plot(sizes=score, label=segment,color=color_list, alpha=0.7)\n\nplt.show()","d9118a66":"# Cohort Analysis","1e3d5e4e":"#### negative values are excluded. We are not removing outliers (such as the max value on Quantity and Price variables)","599d939c":"# data visualization","d582568d":"# Naming the RFM Scores","cdd05cfe":"# read data","a3b9944f":"# Data Preperation","c0861afa":"# RFM analysis","b1506a47":"### create a new df called rfm in order to calculate Recency, Frequency and Monetary values.\n\n* the number of days between the last purchase date of this customer is Recency\n* the number of unique invoices of this customer is Frequency\n* the sum of sales is this customer's Monetary","faa0c32b":"# RFM Scores\n* the min number of Recency metric means that this customer has just purchased, so the highest score (5) should be given to the lower number of Recency.\n* the max number of Frequency and Monetary metrics mean that the customer is purchasing frequently and spending more money, so the highest score (5) should be given to the highest Frequency and Monetary values."}}