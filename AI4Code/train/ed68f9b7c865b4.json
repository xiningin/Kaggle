{"cell_type":{"19a2f4f0":"code","a9679816":"code","dcd40600":"code","0eb1bc08":"code","ce9c252c":"code","cfe0c84e":"code","77810b8d":"code","083b6aae":"code","ecdcd516":"code","c4b0f490":"code","381d5135":"code","aff8b8ee":"code","b8cf172f":"code","d5b7985b":"code","33367ce8":"code","aed8a0aa":"code","8e9620ca":"code","fc7dd586":"code","4a4636fe":"code","37280c7a":"code","9a3e37e9":"code","4a373efc":"code","41f660f4":"code","54873aed":"code","6002ec59":"code","c95ac191":"code","4bc4d6cb":"code","a7e33845":"code","ac085cbf":"code","8e37406b":"code","a7890c35":"markdown","5642e784":"markdown","b3f4b31e":"markdown","461333f2":"markdown","62e86e73":"markdown","14104867":"markdown","b35a1a67":"markdown","515988a3":"markdown","a033f580":"markdown"},"source":{"19a2f4f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9679816":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, Conv1D, MaxPool1D, Dropout, SimpleRNN, LSTM, Input\nfrom tensorflow.keras.layers import Flatten\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import sequence\nimport tensorflow\nimport string\nimport re","dcd40600":"from tensorflow.keras.datasets import fashion_mnist\nimport numpy as np\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()","0eb1bc08":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nplt.imshow(X_test[0])\nplt.gray()\nplt.show()","ce9c252c":"X_train = X_train.astype('float32') \/ 255.\nX_test = X_test.astype('float32') \/ 255.","cfe0c84e":"X_train.shape","77810b8d":"y_train = np.array(y_train)\ny_test = np.array(y_test)","083b6aae":"from tensorflow.keras.utils import to_categorical\ny_test = to_categorical(y_test)\ny_train = to_categorical(y_train)","ecdcd516":"model = Sequential()\nmodel.add(Input(shape=(28,28)))\nmodel.add(Conv1D(16,3, padding='same', activation=\"relu\" ))\nmodel.add(MaxPool1D(pool_size=2))\nmodel.add(Conv1D(8,3, padding='same', activation=\"relu\" ))\nmodel.add(MaxPool1D(pool_size=2))\nmodel.add(Conv1D(4, 3, padding='same', activation=\"relu\" ))\nmodel.add(MaxPool1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","c4b0f490":"model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=50, batch_size=128, verbose=2)","381d5135":"model = Sequential()\nmodel.add(Input(shape=(28,28)))\nmodel.add(LSTM(32,return_sequences=True))\nmodel.add(LSTM(16,return_sequences=True))\nmodel.add(LSTM(8))\nmodel.add(Flatten())\nmodel.add(Dense(250, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","aff8b8ee":"model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=50, batch_size=128, verbose=2)","b8cf172f":"(X_train, _), (X_test, _) = fashion_mnist.load_data()","d5b7985b":"X_train = X_train.astype('float32') \/ 255.\nX_test = X_test.astype('float32') \/ 255.","33367ce8":"X_train = X_train.reshape(X_train.shape[0], -1)\nX_test = X_test.reshape(X_test.shape[0], -1)","aed8a0aa":"from tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\n\n\ninput_img = Input(shape=(784,))\nencoded = Dense(128, name='e1', activation='relu')(input_img)\nencoded = Dense(64, name='e2', activation='relu')(encoded)\nencoded = Dense(32, name='e3', activation='relu')(encoded)\n\ndecoded = Dense(64, name='d1', activation='relu')(encoded)\ndecoded = Dense(128, name='d2', activation='relu')(decoded)\ndecoded = Dense(784, name='d3', activation='sigmoid')(decoded)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.summary()","8e9620ca":"encoder = Model(input_img, encoded)\nencoder.summary()","fc7dd586":"autoencoder.compile(optimizer='adam', loss='binary_crossentropy')","4a4636fe":"autoencoder.fit(X_train, X_train,\n                epochs=10,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(X_test, X_test))\nencoded_imgs = encoder.predict(X_test)","37280c7a":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nplt.imshow(X_test[10].reshape(28,28))\nplt.gray()\nplt.show()","9a3e37e9":"img_to_find = encoded_imgs[10]","4a373efc":"def custom_cosine_sim(a,b):\n    return np.dot(a, b) \/ ( np.linalg.norm(a) * np.linalg.norm(b))","41f660f4":"from scipy import spatial\ncosine_list = []\nfor index_image,xt in enumerate(encoded_imgs):\n    #print (spatial.distance.cosine(img_to_find, xt))\n    #print (1 - spatial.distance.cosine(img_to_find, xt))\n    #print (custom_cosine_sim(img_to_find, xt))\n    #print()\n    result = 1 - spatial.distance.cosine(img_to_find, xt)\n    cosine_list.append(dict({'res':result, 'i':index_image}))","54873aed":"from operator import itemgetter\ncosine_list.sort(key=itemgetter('res'), reverse=True)","6002ec59":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=1, ncols=10,figsize=(20, 4))\nplt.gray()\nfor indice, row in enumerate(ax):\n    print (cosine_list[indice]['i'])\n    row.imshow(X_test[cosine_list[indice]['i']].reshape(28,28))\n\nplt.show()","c95ac191":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nplt.imshow(X_test[0].reshape(28,28))\nplt.gray()\nplt.show()","4bc4d6cb":"img_to_find = encoded_imgs[0]","a7e33845":"cosine_list = []\nfor index_image,xt in enumerate(encoded_imgs):\n    #print (spatial.distance.cosine(img_to_find, xt))\n    #print (1 - spatial.distance.cosine(img_to_find, xt))\n    #print (custom_cosine_sim(img_to_find, xt))\n    #print()\n    result = 1 - spatial.distance.cosine(img_to_find, xt)\n    cosine_list.append(dict({'res':result, 'i':index_image}))","ac085cbf":"cosine_list.sort(key=itemgetter('res'), reverse=True)","8e37406b":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=1, ncols=10,figsize=(20, 4))\nplt.gray()\nfor indice, row in enumerate(ax):\n    print (cosine_list[indice]['i'])\n    row.imshow(X_test[cosine_list[indice]['i']].reshape(28,28))\n\nplt.show()","a7890c35":"On obtient une meilleur pr\u00e9cision de 88,5%","5642e784":"# Reconnaissance LSTM","b3f4b31e":"On trouve bien des chaussures","461333f2":"On cherche des chaussures","62e86e73":"On obtient une pr\u00e9cision de 87%","14104867":"Nous allons tenter de trouver des v\u00eatements similaires","b35a1a67":"On trouve des v\u00eatements similaires ainsi que le mod\u00e8le","515988a3":"# Similarit\u00e9","a033f580":"# Reconaissance Conv1D"}}