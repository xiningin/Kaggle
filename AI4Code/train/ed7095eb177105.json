{"cell_type":{"733a64e6":"code","59e6e591":"code","b6e59cda":"code","80b6fa9c":"code","14fe4c5a":"code","d0911ff4":"code","168b8228":"code","1c1904ed":"code","cd3510c7":"code","e028d8b8":"code","8aa0ab73":"code","d6e2678b":"code","bdd7f439":"code","08bc743b":"code","ff88e85b":"code","c931ba1c":"code","57d01748":"code","55d9fa20":"code","965551b1":"code","c4b10f76":"code","0b4a4ab6":"code","f4922edc":"code","ea06c04f":"code","2466d3f2":"code","680b4649":"code","4e4c6a84":"code","e65874b5":"code","a8cacd76":"code","142d52c6":"code","f0818d6f":"code","2b13a03f":"code","92b05290":"code","22b2002f":"code","79237445":"code","bffe3361":"code","424a00c2":"code","016fe20d":"code","dbaf9885":"code","b17336ef":"code","545fa29b":"code","3488b154":"code","bfbb6d1e":"code","ecbdadd9":"code","843e73e5":"code","1b36a5d4":"code","924b3d4d":"code","88f48207":"code","291d59b3":"code","e3b006b5":"code","cc05b442":"code","2a672b9c":"code","f862e64b":"code","dfd58cba":"code","bb414038":"code","f9a8d55b":"code","61ac2089":"code","9f5cb871":"code","8be63e60":"code","a551cb0b":"code","56621ad1":"code","3e955148":"code","ef0795ad":"code","d16fb540":"code","e5c1f07e":"code","e94e7501":"code","0fdeeb1a":"code","c88f2a2a":"code","50273e26":"code","910ba8a1":"code","53baf209":"code","0026e1b0":"code","cd38bc4e":"code","ec4acfcf":"code","d35378e2":"code","166e1e5c":"code","7dc7aaee":"code","0a552fc0":"code","8586b02c":"code","14143b2e":"code","de1ca7ba":"code","9e655dee":"code","8893aaec":"code","621a602f":"code","dcb40045":"code","e1af9eae":"code","22c6691e":"code","5410b72e":"code","2112f767":"code","587b9693":"code","1eeb2d33":"code","f3d5b907":"code","d0d5916e":"code","dc0a252f":"code","4a485b23":"code","b072af93":"code","3e9c3151":"code","de285f44":"code","b36efe8e":"code","70fd3035":"code","89b48987":"code","d238ee32":"code","d2c5b247":"code","f90bbc81":"code","70e76bb1":"code","988c3a77":"code","ef179d61":"code","991a40dd":"code","96b49ec7":"code","656eaf8f":"code","0305e610":"code","47321b45":"code","8770c279":"code","f5c20aa8":"code","b6518bdb":"code","363baee7":"code","86ef0d34":"markdown","76438814":"markdown","89ed9526":"markdown","1b457101":"markdown","2bd81fbf":"markdown","1ed0fcd4":"markdown","a44d6120":"markdown","c354531a":"markdown","2c1f52d6":"markdown","8f43359a":"markdown","00dc07e6":"markdown","87702307":"markdown","4351405e":"markdown"},"source":{"733a64e6":"import torch as th\nimport syft as sy","59e6e591":"x = th.tensor([1,2,3,4,5])\nx","b6e59cda":"y = x + x","80b6fa9c":"print(y)","14fe4c5a":"hook = sy.TorchHook(th)","d0911ff4":"th.tensor([1,2,3,4,5])","168b8228":"bob = sy.VirtualWorker(hook, id=\"bob\")","1c1904ed":"bob._objects","cd3510c7":"x = th.tensor([1,2,3,4,5])","e028d8b8":"x = x.send(bob)","8aa0ab73":"bob._objects","d6e2678b":"x.location","bdd7f439":"x.id_at_location","08bc743b":"x.id","ff88e85b":"x.owner","c931ba1c":"hook.local_worker","57d01748":"x","55d9fa20":"x = x.get()\nx","965551b1":"bob._objects\n\n","c4b10f76":"# try this project here!\nbob = sy.VirtualWorker(hook, 'bob')\nada = sy.VirtualWorker(hook, 'ada')\n\nmytensor = th.Tensor([2,3,5,7])","0b4a4ab6":"tensor_pointer = mytensor.send(bob, ada)","f4922edc":"print(bob._objects)\nprint(ada._objects)\n","ea06c04f":"tensor_pointer","2466d3f2":"mytensor = tensor_pointer.get()\nmytensor","680b4649":"x = th.tensor([1,2,3,4,5]).send(bob)\ny = th.tensor([1,1,1,1,1]).send(bob)","4e4c6a84":"x","e65874b5":"y","a8cacd76":"z = x + y","142d52c6":"z","f0818d6f":"z = z.get()\nz","2b13a03f":"z = th.add(x,y)\nz","92b05290":"z = z.get()\nz","22b2002f":"x = th.tensor([1.,2,3,4,5], requires_grad=True).send(bob)\ny = th.tensor([1.,1,1,1,1], requires_grad=True).send(bob)","79237445":"z = (x + y).sum()","bffe3361":"z.backward()","424a00c2":"x = x.get()","016fe20d":"x","dbaf9885":"x.grad","b17336ef":"# try this project here!\nmyinput = th.tensor([[0.,0], [1,0], [0,1], [1,1]], requires_grad=True)\ninput_ptr = myinput.send(ada)\ntarget = th.tensor([[0.], [1], [0], [1]], requires_grad=True).send(ada)\nweights = th.tensor([[0.], [0.]], requires_grad=True).send(ada)","545fa29b":"for i in range(10):\n    prediction = input_ptr.mm(weights)\n    loss = ((prediction - target)**2).sum()\n    loss.backward()\n    weights.data.sub_(weights.grad * 0.15)\n    weights.grad *= 0\n\n    print(loss.get().data)","3488b154":"ada._objects","bfbb6d1e":"\ndel input_ptr\nada.clear_objects()\nada._objects","ecbdadd9":"bob = bob.clear_objects()","843e73e5":"bob._objects","1b36a5d4":"x = th.tensor([1,2,3,4,5]).send(bob)","924b3d4d":"bob._objects","88f48207":"del x","291d59b3":"bob._objects","e3b006b5":"x = th.tensor([1,2,3,4,5]).send(bob)","cc05b442":"bob._objects","2a672b9c":"x = \"asdf\"","f862e64b":"bob._objects","dfd58cba":"x = th.tensor([1,2,3,4,5]).send(bob)","bb414038":"x","f9a8d55b":"bob._objects","61ac2089":"x = \"asdf\"","9f5cb871":"bob._objects","8be63e60":"del x","a551cb0b":"bob._objects","56621ad1":"bob = bob.clear_objects()\nbob._objects","3e955148":"for i in range(1000):\n    x = th.tensor([1,2,3,4,5]).send(bob)","ef0795ad":"bob._objects","d16fb540":"x = th.tensor([1,2,3,4,5]).send(bob)\ny = th.tensor([1,1,1,1,1]).send(bob)","e5c1f07e":"z = x + y\nz","e94e7501":"from torch import nn, optim","0fdeeb1a":"# A Toy Dataset\ndata = th.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\ntarget = th.tensor([[1.],[1], [0], [0]], requires_grad=True)\n\nbob = sy.VirtualWorker(hook, 'bob')\nada = sy.VirtualWorker(hook, 'ada')","c88f2a2a":"# A Toy Model\nmodel = nn.Linear(2,1)","50273e26":"opt = optim.SGD(params=model.parameters(), lr=0.1)","910ba8a1":"def train(iterations=20):\n    for iter in range(iterations):\n        opt.zero_grad()\n\n        pred = model(data)\n\n        loss = ((pred - target)**2).sum()\n\n        loss.backward()\n\n        opt.step()\n\n        print(loss.data)\n        \ntrain()","53baf209":"data_bob = data[0:2].send(bob)\ntarget_bob = target[0:2].send(bob)","0026e1b0":"data_ada = data[2:4].send(ada)\ntarget_ada = target[2:4].send(ada)","cd38bc4e":"datasets = [(data_bob, target_bob), (data_ada, target_ada)]","ec4acfcf":"def train(iterations=20):\n\n    model = nn.Linear(2,1)\n    opt = optim.SGD(params=model.parameters(), lr=0.1)\n    \n    for iter in range(iterations):\n\n        for _data, _target in datasets:\n\n            # send model to the data\n            model = model.send(_data.location)\n\n            # do normal training\n            opt.zero_grad()\n            pred = model(_data)\n            loss = ((pred - _target)**2).sum()\n            loss.backward()\n            opt.step()\n\n            # get smarter model back\n            model = model.get()\n\n            print(loss.get())","d35378e2":"train()","166e1e5c":"bob.clear_objects()\nada.clear_objects()","7dc7aaee":"x = th.tensor([1,2,3,4,5]).send(bob)","0a552fc0":"x = x.send(ada)","8586b02c":"bob._objects","14143b2e":"ada._objects","de1ca7ba":"y = x + x","9e655dee":"y","8893aaec":"bob._objects","621a602f":"ada._objects","dcb40045":"jon = sy.VirtualWorker(hook, id=\"jon\")","e1af9eae":"bob.clear_objects()\nada.clear_objects()\n\nx = th.tensor([1,2,3,4,5]).send(bob).send(ada)","22c6691e":"bob._objects","5410b72e":"ada._objects","2112f767":"x = x.get()\nx","587b9693":"bob._objects","1eeb2d33":"ada._objects","f3d5b907":"x = x.get()\nx","d0d5916e":"bob._objects","dc0a252f":"bob.clear_objects()\nada.clear_objects()\n\nx = th.tensor([1,2,3,4,5]).send(bob).send(ada)","4a485b23":"bob._objects","b072af93":"ada._objects","3e9c3151":"del x","de285f44":"bob._objects","b36efe8e":"ada._objects","70fd3035":"bob.clear_objects()\nada.clear_objects()","89b48987":"x = th.tensor([1,2,3,4,5]).send(bob)","d238ee32":"bob._objects","d2c5b247":"ada._objects","f90bbc81":"x.move(ada)","70e76bb1":"bob._objects","988c3a77":"ada._objects","ef179d61":"x = th.tensor([1,2,3,4,5]).send(bob).send(ada)","991a40dd":"bob._objects","96b49ec7":"ada._objects","656eaf8f":"x.remote_get()","0305e610":"bob._objects","47321b45":"ada._objects","8770c279":"x.move(bob)","f5c20aa8":"x","b6518bdb":"bob._objects","363baee7":"ada._objects","86ef0d34":"# Lesson: Introducing Remote Arithmetic","76438814":"# Project: Playing with Remote Tensors\n\nIn this project, I want you to .send() and .get() a tensor to TWO workers by calling .send(bob,alice). This will first require the creation of another VirtualWorker called alice.","89ed9526":"# Section 2: Federated Learning\nfrom Kaggle\n\nA notebook from the Udacity course about Secure and Private AI\nhttps:\/\/eu.udacity.com\/course\/secure-and-private-ai--ud185","1b457101":"# Lesson: Toy Federated Learning\n\nLet's start by training a toy model the centralized way. This is about a simple as models get. We first need:\n\n- a toy dataset\n- a model\n- some basic training logic for training a model to fit the data.","2bd81fbf":"# Lesson: Advanced Remote Execution Tools\n\nIn the last section we trained a toy model using Federated Learning. We did this by calling .send() and .get() on our model, sending it to the location of training data, updating it, and then bringing it back. However, at the end of the example we realized that we needed to go a bit further to protect people privacy. Namely, we want to average the gradients BEFORE calling .get(). That way, we won't ever see anyone's exact gradient (thus better protecting their privacy!!!)\n\nBut, in order to do this, we need a few more pieces:\n\n- use a pointer to send a Tensor directly to another worker\n\nAnd in addition, while we're here, we're going to learn about a few more advanced tensor operations as well which will help us both with this example and a few in the future!","1ed0fcd4":"# Lesson: Pointer Chain Operations","a44d6120":"# Lesson: Introducing \/ Installing PySyft\n\nIn order to perform Federated Learning, we need to be able to use Deep Learning techniques on remote machines. This will require a new set of tools. Specifically, we will use an extensin of PyTorch called PySyft.\n\n### Install PySyft\n\nThe easiest way to install the required libraries is with [Conda](https:\/\/docs.conda.io\/projects\/conda\/en\/latest\/user-guide\/overview.html). Create a new environment, then install the dependencies in that environment. In your terminal:\n\n```bash\nconda create -n pysyft python=3\nconda activate pysyft # some older version of conda require \"source activate pysyft\" instead.\nconda install jupyter notebook\npip install syft\npip install numpy\n```\n\nIf you have any errors relating to zstd - run the following (if everything above installed fine then skip this step):\n\n```\npip install --upgrade --force-reinstall zstd\n```\n\nand then retry installing syft (pip install syft).\n\nIf you are using Windows, I suggest installing [Anaconda and using the Anaconda Prompt](https:\/\/docs.anaconda.com\/anaconda\/user-guide\/getting-started\/) to work from the command line. \n\nWith this environment activated and in the repo directory, launch Jupyter Notebook:\n\n```bash\njupyter notebook\n```\n\nand re-open this notebook on the new Jupyter server.\n\nIf any part of this doesn't work for you (or any of the tests fail) - first check the [README](https:\/\/github.com\/OpenMined\/PySyft.git) for installation help and then open a Github Issue or ping the #beginner channel in our slack! [slack.openmined.org](http:\/\/slack.openmined.org\/)","c354531a":"''' performing on x: \nit is going to send a message to self.location, \nthe worker finds the tensor with the ID x.id_at_location\nexecute the command'''","2c1f52d6":"## PySyft => Remote PyTorch\n\nThe essence of Federated Learning is the ability to train models in parallel on a wide number of machines. Thus, we need the ability to tell remote machines to execute the operations required for Deep Learning.\n\nThus, instead of using Torch tensors - we're now going to work with **pointers** to tensors. Let me show you what I mean. First, let's create a \"pretend\" machine owned by a \"pretend\" person - we'll call him Bob.","8f43359a":"# Project: Learn a Simple Linear Model\n\nIn this project, I'd like for you to create a simple linear model which will solve for the following dataset below. You should use only Variables and .backward() to do so (no optimizers or nn.Modules). Furthermore, you must do so with both the data and the model being located on Bob's machine.","00dc07e6":"# Lesson: Introducing Federated Learning\n\nFederated Learning is a technique for training Deep Learning models on data to which you do not have access. Basically:\n\nFederated Learning: Instead of bringing all the data to one machine and training a model, we bring the model to the data, train it locally, and merely upload \"model updates\" to a central server.\n\nUse Cases:\n\n    - app company (Texting prediction app)\n    - predictive maintenance (automobiles \/ industrial engines)\n    - wearable medical devices\n    - ad blockers \/ autotomplete in browsers (Firefox\/Brave)\n    \nChallenge Description: data is distributed amongst sources but we cannot aggregated it because of:\n\n    - privacy concerns: legal, user discomfort, competitive dynamics\n    - engineering: the bandwidth\/storage requirements of aggregating the larger dataset","87702307":"# Lesson: Garbage Collection and Common Errors\n","4351405e":"# Lesson: Basic Remote Execution in PySyft"}}