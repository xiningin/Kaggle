{"cell_type":{"6baa0f63":"code","1fa420b1":"code","c65739a0":"code","c147b058":"code","d713288a":"code","6c66c487":"code","2191f72b":"code","2204d5af":"code","5c53ad28":"code","58680389":"code","a6e16322":"code","b2e6d646":"code","19aec8ad":"markdown","a55453e6":"markdown","5d9ba9be":"markdown","ee04de20":"markdown","bb09d61c":"markdown","6f16c470":"markdown","a95260e7":"markdown"},"source":{"6baa0f63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nprint(f\"Torch Version {torch.__version__}\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1fa420b1":"# To Check if we are Cuda (Switch on your GPU option and try again, \n# be sure to make judicial use of your GPU Time)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","c65739a0":"import torch.nn as nn \n# HAS TORCH NEURAL NET MODULES (LINEAR,CONV LAYERS,LOSS FUNCTIONS)\n# Base class for all neural network modules.\n# Your models should also subclass this class.","c147b058":"import torch.optim as optim # HAS TORCH OPTIMISER FUNCTIONS LIKE ADAM, SGD,ETC;\n# torch.optim.Optimizer(params, defaults) => Base class for all optimizers.\n\nimport torch.nn.functional as F # HAS NON-PARAMETER FUNCTIONS (RELU, SOFTMAX ETC;)\nfrom torch.utils.data import Dataset, DataLoader # Helps us load data\nimport torchvision.datasets as datasets # Standard Datasets\nimport torchvision.transforms as transforms","d713288a":"class Neural(nn.Module):\n    def __init__(self,input_size,num_classes):\n        # Define the model's architecture in the  __init__ function.\n        super(Neural,self).__init__()\n        self.fc1 = nn.Linear(input_size,50) # Fully Connected Layer 1\n        self.fc2 = nn.Linear(50,num_classes) # Fully Connected Layer 2\n    \n    def forward(self,x):\n        # Defines the computation performed at every call.\n        # Should be overridden by all subclasses.\n        # This is the heart of the model, it runs once for every input\n        \n        x = F.relu(self.fc1(x)) # Passing the output of fc1 through the relu function \n        x = self.fc2(x) # Passing the relu's output through fc2\n        return x # Output is achived as a tensor of shape [10].\n\nsamp_mod = Neural(784,10) # Model Input Size = 784, Number of Classes = 10\nx = torch.randn(4,784) # Passing into the model 4 value of input size [784]\nprint(samp_mod(x)) # The model returns the output of fc2 for the 4 values in arrays of 10","6c66c487":"# Set Hyper Parameters\ninput_size = 784\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epochs = 10","2191f72b":"# Prepare the Dataset using the Pytorch Dataset Class\ntrain_csv = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest_csv = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\n\nclass Fashion(Dataset):\n    # Define this class by inheriting the Dataset Class\n    \n    def __init__(self,data,transform = None):\n        # To initialise the Variables\n        self.fashion = list(data.values)\n        self.transform = transform\n        \n        label = []\n        image = []\n        \n        for i in self.fashion: # takes one item per loop\n            # First Column is the label\n            label.append(i[0])\n            image.append(i[1:])\n        self.labels = np.asarray(label)\n        # Dimension of images is 28x28x1 => h = 28; w = 28; color = 1\n        self.images = np.asarray(image).reshape(-1,28,28,1).astype('float32')\n        \n    # Every time this function is called,\n    # we recieve an index and that data,target pair is returned.\n    \n    def __getitem__(self,index):\n        label = self.labels[index]\n        image = self.images[index]\n        \n        # If transform was applied, we apply the transform\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image,label\n    \n    # Returns length of images\n    def __len__(self):\n        return len(self.images)","2204d5af":"# Get & Load the Train Dataset\ntrain_data = Fashion(train_csv,transform=transforms.ToTensor())\ntrain_loader = DataLoader(dataset=train_data,batch_size=64)\n# Get & Load the Test Dataset\ntest_data = Fashion(test_csv,transform=transforms.ToTensor())\ntest_loader = DataLoader(dataset=test_data,batch_size=64)","5c53ad28":"# Create & Set the Device to the model\nmodel = Neural(input_size=input_size,num_classes=num_classes).to(device)\n# Set Loss Function and Optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),lr=learning_rate)","58680389":"# Training the Model\nfor epoch in range(num_epochs):\n    for batch_idx,(data,targets) in enumerate(train_loader):\n        # Get Data to CUDA if possible\n        data = data.to(device=device)\n        target = targets.to(device=device)\n        \n        # Get to correct shape\n        data = data.reshape(data.shape[0],-1)\n        \n        # Forward\n        score = model(data)\n        loss = loss_fn(score,targets)\n        \n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # Gradient Descent or Adam Step\n        optimizer.step()","a6e16322":"# Check Accuracy\ndef check_accuracy(loader,model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n    \n    with torch.no_grad():\n        for x,y in loader:\n            x = x.to(device = device)\n            y = y.to(device = device)\n            \n            x = x.reshape(x.shape[0],-1)\n\n            scores = model(x)\n            _,predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n        print(f\"Got {num_correct} \/ {num_samples} with accuracy {float(num_correct)\/float(num_samples)*100:.2f}\")\n    model.train()","b2e6d646":"check_accuracy(train_loader,model)\ncheck_accuracy(test_loader,model)","19aec8ad":"[nn.Module Docs](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.Module.html)","a55453e6":"## Importing Required Modules","5d9ba9be":"# Making a SIMPLE NEURAL NET","ee04de20":"[Click Here for more datasets from PyTorch](https:\/\/pytorch.org\/vision\/stable\/datasets.html#mnist)","bb09d61c":"[What's Inside the nn.Module](https:\/\/pytorch.org\/docs\/stable\/nn.html)","6f16c470":"## Create a Fully Connected NN","a95260e7":"## Training on MNIST Dataset"}}