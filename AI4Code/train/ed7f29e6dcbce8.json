{"cell_type":{"b48f4f37":"code","9b682fdd":"code","b3f5cb3b":"code","dcfa083f":"code","fbfce958":"code","cf89102c":"code","3eeb6ac3":"code","7948d190":"code","5575c5b7":"code","f0bc9269":"code","e113e4a7":"code","ceb03926":"code","d8609764":"code","ee93282e":"code","d4510a5e":"code","dcd08b68":"code","ef35ad1a":"code","2f2b6ed3":"code","1353a8be":"code","a0a10cdb":"code","a7f7a57b":"code","0081751e":"code","b0d7f45d":"code","43679850":"code","a0b7cc2a":"code","bbd44384":"code","dc05c2b6":"code","0c6160cc":"code","bc4c0f5f":"code","38c6cc6a":"code","9e698111":"code","848ca181":"code","eaa5b806":"code","4fe53582":"code","8ac20e0e":"code","11c524d7":"code","adcd1e39":"code","4eabb9e1":"code","b4399ebd":"code","c71ae635":"code","759fc442":"code","667428bb":"code","26df1310":"code","0ef59cc5":"code","1ce001cf":"code","319ccb9d":"code","65abfdf2":"code","4740d9a3":"code","603e7df1":"code","256ffd57":"code","9913d1a6":"code","0634fd87":"code","9b8451cf":"code","94b2ce94":"code","8d906907":"code","2a93a88f":"code","ba28a33a":"code","0327dc55":"code","242a995a":"code","8dee834e":"code","f6e2ff9d":"code","8297b90b":"code","6b917d58":"code","addb9e8e":"code","7d9d63f8":"code","cb3ac55e":"code","75528c53":"code","c9712675":"code","e62e6e25":"code","5ba48ddd":"code","6a75f325":"code","6fb11935":"code","f2ad494a":"code","f4f758d8":"code","4e7a0181":"code","b0249740":"code","a4032b65":"code","4d57c5bd":"code","64bb8422":"code","a180a69a":"code","c44a809a":"code","4ffaf709":"code","4dd8edc6":"code","df03bb9a":"code","911bd12e":"code","80d86e12":"markdown"},"source":{"b48f4f37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9b682fdd":"df = pd.read_csv('..\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')","b3f5cb3b":"df.head()","dcfa083f":"df.shape","fbfce958":"df.info()","cf89102c":"df.describe()","3eeb6ac3":"for col in df.columns:\n    if 'Satisfaction' in col:\n        print(col)","7948d190":"for col in df.columns:\n    if 'Satisfaction' in col:\n        print(df[col].describe())","5575c5b7":"import seaborn as sns\nimport matplotlib.pyplot as plt","f0bc9269":"df['OverallSatisfaction'] = (df['EnvironmentSatisfaction']+df['JobSatisfaction']+df['RelationshipSatisfaction'])\/3","e113e4a7":"df.head()","ceb03926":"df.drop(['EnvironmentSatisfaction','JobSatisfaction','RelationshipSatisfaction'], axis=1, inplace=True)","d8609764":"df.head()","ee93282e":"### Dropping Employee count column as it has only value 1 throughout\n### Also, dropping employee number column as it is of no use as well (same as Emp Id)","d4510a5e":"df.drop(['EmployeeCount','EmployeeNumber'], axis=1, inplace=True)","dcd08b68":"df.describe()","ef35ad1a":"df['AgeGroup'] = 'Old'\ndf.loc[df['Age']<=30, 'AgeGroup'] = 'Young'\ndf.loc[(df['Age']>30) & (df['Age']<=50), 'AgeGroup'] = 'MidAge'","2f2b6ed3":"df.head()","1353a8be":"df.drop('Age', axis=1, inplace=True)","a0a10cdb":"df.head()","a7f7a57b":"df.describe()","0081751e":"df.corr()","b0d7f45d":"### We see that there is almost no multicollinearity between numerical columns\n### Also, column StandardHours have 8 throughout. So, dropping this column as well","43679850":"df.drop('StandardHours', axis=1, inplace=True)","a0b7cc2a":"sns.distplot(df.MonthlyRate)","bbd44384":"sns.distplot(df.HourlyRate)","dc05c2b6":"df[['MonthlyRate','HourlyRate','MonthlyIncome']]","0c6160cc":"plt.figure(figsize=(20,20))\nplt.scatter(x='MonthlyRate', y='HourlyRate', data=df)","bc4c0f5f":"### From above, we see that either MonthlyRate or HourlyRate column is required\n### As we have MonthlyIncome column as well, we don't need MonthlyRate anymore","38c6cc6a":"df.drop('MonthlyRate', axis=1, inplace=True)","9e698111":"df.head()","848ca181":"df.Attrition.value_counts()","eaa5b806":"df.Attrition = np.where(df.Attrition=='Yes',1,0)\ndf.Attrition = pd.to_numeric(df.Attrition, errors='coerce')","4fe53582":"df.info()","8ac20e0e":"df_num = df.select_dtypes('number')\ndf_num.head()","11c524d7":"from sklearn.feature_selection import SelectKBest, chi2","adcd1e39":"selector = SelectKBest(score_func=chi2, k=10).fit(df_num.iloc[:,1:], df_num.Attrition)\nkbest = selector.transform(df_num.iloc[:,1:])","4eabb9e1":"print(kbest.shape)\ndf_num.iloc[:,1:].columns[selector.get_support(indices=True)]","b4399ebd":"df_num_kbest = df_num[['DailyRate', 'DistanceFromHome', 'JobLevel', 'MonthlyIncome',\n       'StockOptionLevel', 'TotalWorkingYears', 'YearsAtCompany',\n       'YearsInCurrentRole', 'YearsSinceLastPromotion',\n       'YearsWithCurrManager','Attrition']]","c71ae635":"df_num_kbest.head()","759fc442":"df_char = df.select_dtypes('object')\ndf_all = pd.concat([df_char, df_num_kbest], axis=1)","667428bb":"df_all.head()","26df1310":"df_all.shape","0ef59cc5":"df_all.Over18.value_counts()","1ce001cf":"### There is only 1 value 'Y' in this columns. So, dropping this\ndf_all.drop('Over18', axis=1, inplace=True)","319ccb9d":"df_all.head()","65abfdf2":"df_final = pd.get_dummies(data=df_all, drop_first=True)","4740d9a3":"df_final.shape","603e7df1":"df_final.head()","256ffd57":"X = df_final.drop('Attrition', axis=1)\ny = df_final.Attrition","9913d1a6":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn import metrics","0634fd87":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, stratify=y)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","9b8451cf":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\ny_train_scaled = scaler.transform(X_test)","94b2ce94":"X_train_scaled1 = pd.DataFrame(X_train_scaled, columns=X_train.columns.values)","8d906907":"X_test_scaled1 = pd.DataFrame(y_train_scaled, columns=X_test.columns.values)","2a93a88f":"et_clf = ExtraTreeClassifier(random_state=2)\net_clf.fit(X_train_scaled1, y_train)","ba28a33a":"y_pred = et_clf.predict(X_test_scaled1)","0327dc55":"acc = metrics.accuracy_score(y_test, y_pred)\nacc","242a995a":"cf_mat = metrics.confusion_matrix(y_test, y_pred)\nprint(cf_mat)","8dee834e":"et_clf.feature_importances_","f6e2ff9d":"features = pd.DataFrame(et_clf.feature_importances_, index=X_train_scaled1.columns, columns=['Score'])","8297b90b":"features.nlargest(12, columns=['Score']).index","6b917d58":"X_train_imp = X_train_scaled1[['DailyRate', 'DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany',\n       'OverTime_Yes', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n       'StockOptionLevel', 'MonthlyIncome', 'AgeGroup_Young',\n       'YearsInCurrentRole', 'JobLevel']]","addb9e8e":"X_test_imp = X_test_scaled1[['DailyRate', 'DistanceFromHome', 'TotalWorkingYears', 'YearsAtCompany',\n       'OverTime_Yes', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n       'StockOptionLevel', 'MonthlyIncome', 'AgeGroup_Young',\n       'YearsInCurrentRole', 'JobLevel']]","7d9d63f8":"Name = \"ExtraTreesClf\"\nprint(Name)\nprint('Accuracy: ',metrics.accuracy_score(y_pred, y_test))\nprint('ROC_AUC_Score: ',metrics.roc_auc_score(y_pred, y_test))","cb3ac55e":"svc = SVC(random_state=2, C=10)\nsvc.fit(X_train_imp, y_train)","75528c53":"y_pred_svc = svc.predict(X_test_imp)","c9712675":"Name = \"SVC\"\nprint(Name)\nprint('Accuracy: ',metrics.accuracy_score(y_pred_svc, y_test))\nprint('ROC_AUC_Score: ',metrics.roc_auc_score(y_pred_svc, y_test))","e62e6e25":"Log_reg = LogisticRegression(penalty='none')","5ba48ddd":"Log_reg.fit(X_train_imp, y_train)","6a75f325":"y_log_pred = Log_reg.predict(X_test_imp)","6fb11935":"Name = \"Log Reg\"\nprint(Name)\nprint('Accuracy: ',metrics.accuracy_score(y_log_pred, y_test))\nprint('ROC_AUC_Score: ',metrics.roc_auc_score(y_log_pred, y_test))","f2ad494a":"xgb_clf = XGBClassifier()","f4f758d8":"xgb_clf.fit(X_train_imp, y_train)\ny_xgb_pred = xgb_clf.predict(X_test_imp)","4e7a0181":"Name = \"XGBoost\"\nprint(Name)\nprint('Accuracy: ',metrics.accuracy_score(y_xgb_pred, y_test))\nprint('ROC_AUC_Score: ',metrics.roc_auc_score(y_xgb_pred, y_test))","b0249740":"rf_clf = RandomForestClassifier(random_state=2, max_features=5, max_depth=5)\nrf_clf.fit(X_train_imp, y_train)\ny_rf_pred = rf_clf.predict(X_test_imp)","a4032b65":"Name = \"Random Forest\"\nprint(Name)\nprint('Accuracy: ',metrics.accuracy_score(y_test, y_rf_pred))\nprint('ROC_AUC_Score: ',metrics.roc_auc_score(y_test, y_rf_pred))","4d57c5bd":"rf_clf.get_params","64bb8422":"params = {'n_estimators' : [100, 300, 500, 700, 1000],\n         'max_depth' : [3,4,5,6,7,9,10],\n         'min_samples_split' : [10,15,20,25,30],\n         'min_samples_leaf' : [10,15,20,25,30],\n         'max_leaf_nodes' : [10,15,20,25,30]}","a180a69a":"rf_clf = RandomForestClassifier(random_state=2)\ncv_clf = RandomizedSearchCV(rf_clf, param_distributions=params, cv=5, scoring='accuracy', verbose=1)\ncv_clf.fit(X_train_imp, y_train)","c44a809a":"cv_clf.best_estimator_","4ffaf709":"rf_clf = RandomForestClassifier(max_depth=9, max_leaf_nodes=25, min_samples_leaf=10,\n                       min_samples_split=25, n_estimators=700, random_state=2)","4dd8edc6":"rf_clf.fit(X_train_imp, y_train)\ny_rf_pred = rf_clf.predict(X_test_imp)","df03bb9a":"Name = \"Random Forest\"\nprint(Name)\nprint('Accuracy: ',metrics.accuracy_score(y_test, y_rf_pred))\nprint('ROC_AUC_Score: ',metrics.roc_auc_score(y_test, y_rf_pred))","911bd12e":"### If we check Accuracy and ROC_AUC both, ExtraTreeClassifier and Log Regression has performed better\n### Log Reg\n### Accuracy:  0.832579185520362\n### ROC_AUC_Score:  0.6534632034632034\n\n### ExtraTreesClf\n### Accuracy:  0.8190045248868778\n### ROC_AUC_Score:  0.6521095484826055","80d86e12":"#### Glad that there are no null values. \n#### Let's now proceed with EDA and feature engineering"}}