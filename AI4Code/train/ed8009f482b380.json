{"cell_type":{"56808a4f":"code","78e0cc29":"code","e31cac2e":"code","c01618a2":"code","96378733":"code","b318cf56":"code","1d167c74":"code","797430d9":"code","07038f49":"code","add97b51":"code","8b37df44":"code","e1f1a65a":"code","bc6174e7":"code","9b6f0ab8":"code","3c323da1":"code","b954ce4a":"code","46c0c3fc":"code","f3f4d791":"code","0bfafa09":"code","5fd952d4":"code","f24ee90b":"code","5ca5c0df":"code","97f03c68":"code","f7a65bb1":"code","3b79984c":"code","db4716be":"code","b2d66733":"code","3b6e2ede":"code","9dfaceb7":"code","c5b570b9":"code","98a91795":"code","f6354e64":"code","020d85b0":"code","704bb770":"code","92653212":"code","5f330616":"code","c80752ce":"code","952f6bb7":"markdown","40e97aa8":"markdown","42a61634":"markdown","846ebc76":"markdown","98e47392":"markdown","8234bde6":"markdown","92b81bf0":"markdown","603ed63d":"markdown","b5d0b6b7":"markdown","e274efbe":"markdown","5b367ab9":"markdown","e4a1d1b7":"markdown","369798e0":"markdown","8a1915dd":"markdown","6641d903":"markdown","52ddac2c":"markdown","e7df68ce":"markdown","4330096e":"markdown","806044bf":"markdown","ee4a37d7":"markdown","a51248a4":"markdown","ef79b72a":"markdown"},"source":{"56808a4f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","78e0cc29":"df=pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","e31cac2e":"df.head()","c01618a2":"df.info()","96378733":"sns.heatmap(df.isna(), cmap='magma')","b318cf56":"df2=df.dropna()","1d167c74":"df2.info()","797430d9":"df2.head()","07038f49":"sns.countplot(x='gender', data=df2)\nprint(df['gender'].value_counts())","add97b51":"sns.countplot(x='stroke', data=df2, palette='rocket', hue='gender')\nplt.xlabel('Stroke')\nplt.ylabel('Count')\nprint(df['stroke'].value_counts())","8b37df44":"sns.countplot(x='Residence_type', data=df2, palette='magma', hue='gender')\nplt.xlabel('Residence Type')\nplt.ylabel('Count')\nplt.title('Classification Based on Residence Type', fontsize=14)\nprint(df['Residence_type'].value_counts())","e1f1a65a":"sns.countplot(x='smoking_status', data=df2, palette='viridis', hue='gender')\nplt.xlabel('Smoking Status')\nplt.ylabel('Count')\nplt.title('Classification Based on Smoking Status', fontsize=14)\nprint(df['smoking_status'].value_counts())","bc6174e7":"sns.countplot(x='ever_married', data=df2, palette='mako', hue='gender')\nplt.xlabel('Ever Married')\nplt.ylabel('Count')\nplt.title('Classification Based on Marriage', fontsize=14)\nprint(df['ever_married'].value_counts())","9b6f0ab8":"sns.countplot(x='work_type', data=df2, palette='viridis', hue='gender')\nplt.xlabel('Work Type')\nplt.ylabel('Count')\nplt.title('Classification Based on Work', fontsize=14)\nprint(df['work_type'].value_counts())\nplt.legend(loc='upper right')","3c323da1":"gender=pd.get_dummies(df2['gender'], drop_first=True)\nmarried=pd.get_dummies(df2['ever_married'], drop_first=True)\nwork=pd.get_dummies(df2['work_type'], drop_first=True)\nreside=pd.get_dummies(df2['Residence_type'], drop_first=True)\nsmoke=pd.get_dummies(df2['smoking_status'], drop_first=True)","b954ce4a":"ndf=pd.concat([df2,gender,married,work,reside,smoke], axis=1)","46c0c3fc":"ndf.head()","f3f4d791":"ndf.drop(['id','gender','ever_married','work_type','Residence_type','smoking_status'], axis=1, inplace=True)","0bfafa09":"ndf.head()","5fd952d4":"from sklearn.model_selection import train_test_split","f24ee90b":"X=ndf.drop('stroke', axis=1)","5ca5c0df":"y=ndf['stroke']","97f03c68":"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline","f7a65bb1":"oversample = SMOTE()\nundersample = RandomUnderSampler()\nsteps = [(\"o\", oversample), (\"u\", undersample)]\npipeline = Pipeline(steps=steps)\n# transform the dataset\nX, y = pipeline.fit_resample(X, y)","3b79984c":"y.value_counts()","db4716be":"X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3)","b2d66733":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","3b6e2ede":"err_rate=[]\n\nfor i in range (1,50):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    err_rate.append(np.mean(pred_i != y_test))","9dfaceb7":"plt.figure(figsize=(12,5))\nsns.set_style('whitegrid')\nplt.plot(range(1,50),err_rate, color='green', marker='d', ls='--')\nplt.xticks(np.arange(1,50,1))","c5b570b9":"lm=LogisticRegression()\nrfc=RandomForestClassifier()\ngnb=GaussianNB()\nknn=KNeighborsClassifier(n_neighbors=2)","98a91795":"lm.fit(X_train,y_train)\nrfc.fit(X_train,y_train)\ngnb.fit(X_train,y_train)\nknn.fit(X_train,y_train)","f6354e64":"lmpredict=lm.predict(X_test)\nrfcpredict=rfc.predict(X_test)\ngnbpredict=gnb.predict(X_test)\nknnpredict=knn.predict(X_test)","020d85b0":"from sklearn.metrics import classification_report","704bb770":"print('Classification report for Logistic Regression')\nprint(classification_report(lmpredict,y_test))","92653212":"print('Classification report for Random Forest Classifier')\nprint(classification_report(rfcpredict,y_test))","5f330616":"print('Classification report for KNN')\nprint(classification_report(knnpredict,y_test))","c80752ce":"print('Classification report for GNB')\nprint(classification_report(gnbpredict,y_test))","952f6bb7":"## Thank You","40e97aa8":"We can see that the y dataframe is now evenly distributed. Now we build the model.","42a61634":"So the optimal number of n_neighbors is 2","846ebc76":"Import SMOTE and RandomUnderSampler","98e47392":"## Stroke Prediction","8234bde6":"Elbow method for optimal number of n_neighbors in KNN","92b81bf0":"## Comparison","603ed63d":"Now we do train test split with test size = 30%","b5d0b6b7":"Predicting whether or not a person would have a stroke. The dataset is acquired from kaggle (https:\/\/www.kaggle.com\/fedesoriano\/stroke-prediction-dataset)","e274efbe":"## Turn Categorical Columns into Numerical Values","5b367ab9":"Drop 'id' column and also the original categorical columns","e4a1d1b7":"For this project we're gonna use Logistic Regression, Random Forest, KNN, and Gaussian Naive Bayes and then we're gonna compare the scores of each model.","369798e0":"As we can see, the data is heavily imbalanced. We're going to have to deal with this later on.","8a1915dd":"## Deal with the imbalanced data","6641d903":"What we're gonna do is that we're gonna oversample the minority data (stroke=1) and undersample the majority data (stroke=0). <br>\n<br>\nWe are going to use SMOTE for the oversampling process and RandomUnderSampler for the undersampling process","52ddac2c":"## Building model","e7df68ce":"Concat to the dataframe (df2) and make it into a new dataframe","4330096e":"Use classification report to determine which model fits this project best.","806044bf":"First we separate the target and the features","ee4a37d7":"## Some EDA","a51248a4":"As we can see from the .info() command, the bmi columns are missing about 100 data. But in the heatmap we see that the missing values are actually not too significant, so we're just gonna drop the entire missing values.","ef79b72a":"Using One Hot encoding, we should transform categorical columns such as gender, ever_married, work_type, Residence_type and smoking_status into numerical columns"}}