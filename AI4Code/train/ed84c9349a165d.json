{"cell_type":{"e691a34f":"code","135c85ec":"code","7928687c":"code","d6cf2fda":"code","ecba2082":"code","ae419aca":"code","7b57038b":"code","96a5b693":"code","0cce11bb":"code","4e052610":"code","2a4b687d":"code","f68a0467":"code","63ac85a2":"code","e9d967c0":"code","eb1a7cc1":"code","ac45ee96":"code","a53bbaeb":"code","e47ff96f":"code","f477db0e":"code","864b55e7":"code","bf12aee8":"code","1672f90f":"code","8c5ae35d":"code","a54764a7":"code","c832b05b":"code","5a8912c0":"code","390b5e5c":"code","539b3075":"code","be215e68":"code","3726905d":"code","e1f0b958":"code","63f5702a":"code","c38174af":"code","9616ec3a":"code","57503347":"code","ef8b884d":"code","1c821966":"code","68615002":"code","eb5de7c6":"code","e5f17f50":"code","7bf360f2":"code","430fdbd8":"code","a605615f":"code","47519b98":"code","8501a5f3":"code","99d157ce":"markdown","7508b84e":"markdown","3c3f21f0":"markdown","87b34390":"markdown","b2c0c71f":"markdown","8fb72e31":"markdown","1dc5488f":"markdown","6858fd4c":"markdown","88725fc7":"markdown","fa435cd8":"markdown","07b5e9c3":"markdown","040509f9":"markdown","8611dfb6":"markdown","884224c2":"markdown","bc27902e":"markdown","508f9327":"markdown","27bcba58":"markdown","d6cecb34":"markdown","87271334":"markdown","b3d8e815":"markdown","13f1d549":"markdown","463eefc8":"markdown","fe3c8a7b":"markdown","bee91daf":"markdown","3941f6f8":"markdown"},"source":{"e691a34f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","135c85ec":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","7928687c":"train = pd.read_csv('\/kaggle\/input\/airbnb-recruiting-new-user-bookings\/train_users_2.csv.zip')\ntest = pd.read_csv('\/kaggle\/input\/airbnb-recruiting-new-user-bookings\/test_users.csv.zip')\nage_gender = pd.read_csv('\/kaggle\/input\/airbnb-recruiting-new-user-bookings\/age_gender_bkts.csv.zip')\nsessions = pd.read_csv('\/kaggle\/input\/airbnb-recruiting-new-user-bookings\/sessions.csv.zip')","d6cf2fda":"train.info()","ecba2082":"train.head()","ae419aca":"X_train = train.drop(['date_first_booking', 'country_destination'], axis=1)\nX_test = test.drop(['date_first_booking'], axis=1)","7b57038b":"y_des = train['country_destination'].values\nX=pd.concat((X_train, X_test), axis=0, ignore_index=True)\nX.shape","96a5b693":"X.fillna(method='pad').head()","0cce11bb":"X.loc[X.age > 90, 'age'] = -1\nX.loc[X.age < 13, 'age'] = -1\nX['age'].describe()","4e052610":"X.loc[X.age.isnull(), 'age']=X.age.mean()","2a4b687d":"dac = np.vstack(\n    X.date_account_created.astype(str).apply(\n        lambda x: list(map(int, x.split('-')))\n    ).values\n)\nX['dac_year'] = dac[:, 0]\nX['dac_month'] = dac[:, 1]\nX['dac_day'] = dac[:, 2]\nX = X.drop(['date_account_created'], axis=1)\nX.head()","f68a0467":"df = sessions.user_id.value_counts()\nprint(df.shape)\nprint(df.head())","63ac85a2":"df = df.to_frame()\ndf = df.rename(columns = {'user_id' : 'session_count'})\ndf['id'] = df.index\ndf.head()","e9d967c0":"X = pd.merge(X, df, how = 'left', on = ['id'])\nX.session_count.fillna(-1, inplace = True)\nX.session_count = X.session_count.astype(int)","eb1a7cc1":"tfa = np.vstack(\n    X.timestamp_first_active.astype(str).apply(\n        lambda x: list(map(int, [x[:4], x[4:6], x[6:8],\n                                 x[8:10], x[10:12],\n                                 x[12:14]]))\n    ).values\n)\nX['tfa_year'] = tfa[:, 0]\nX['tfa_month'] = tfa[:, 1]\nX['tfa_day'] = tfa[:, 2]\nX = X.drop(['timestamp_first_active'], axis=1)","ac45ee96":"# age distributions\ntrain['corrected_age']=train['age'].apply(lambda x : 36 if x>90 or x<10 else x)\nsns.distplot(train.corrected_age.dropna())","a53bbaeb":"# percentage of users using different signup_method\nsignup_method = X.signup_method.value_counts(dropna = False) \/ len(X) * 100\nsignup_method.plot('bar', rot = 0)\nplt.xlabel('Sign up method')\nplt.ylabel('Percentage of signup_method')","e47ff96f":"# percentage of gender\ngender = X.gender.value_counts(dropna = False) \/ len(X) * 100\ngender.plot('bar', rot = 0)\nplt.xlabel('gender')\nplt.ylabel('Percentage of gender')","f477db0e":"# percentage of people going to different countries\ndes_countries = train.country_destination.value_counts(dropna = False) \/ len(train) * 100\ndes_countries.plot('bar', rot = 0)\nplt.xlabel('Destination country')\nplt.ylabel('Percentage of booking')","864b55e7":"# Relavance between Age and destination\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 7)\nsns.boxplot(y='age' , x='country_destination',data=train)\nplt.xlabel('Destination Country box plot',size=15)\nplt.ylabel('Age of Users', size=15)\nplt.tick_params(labelsize=12)","bf12aee8":"# relevance between age and signup method\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(6, 4)\nsns.boxplot(y='age' , x='signup_method',data=train)\nplt.xlabel('Signup method', size=15)\nplt.ylabel('age', size=15)\nplt.tick_params(labelsize=12)\n#sns.despine()","1672f90f":"# relevence between age and signup app\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(6, 4)\nsns.boxplot(y='age' , x='signup_app',data=train)\nplt.xlabel('Signup app',size=15)\nplt.ylabel('Age of Users', size=15)\nplt.tick_params(labelsize=12)\n#sns.despine()","8c5ae35d":"#relevence between age and language\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(8, 5)\nsns.boxplot(y='age' , x='language',data=train)\nplt.xlabel('Language', size=15)\nplt.ylabel('Age of Users', size=15)\nplt.tick_params(labelsize=12)\n#sns.despine()","a54764a7":"# relevance between age and gender\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(6, 4)\nsns.boxplot(y='age' , x='gender',data=train)\nplt.xlabel('Gender', size=15)\nplt.ylabel('Age of Users', size=15)\nplt.tick_params(labelsize=10)\n#sns.despine()","c832b05b":"# chart for number of account created\ntrain['date_account_created_new'] = pd.to_datetime(train['date_account_created'])\nsns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 8)\ntrain.date_account_created_new.value_counts().plot(kind='line', linewidth=1, color='#1F618D')\nplt.xlabel('Date ', size=20)\nplt.ylabel('Number of account created ', size=15)\nplt.tick_params(labelsize=12)\n#sns.despine()","5a8912c0":"oh_features = ['gender', 'signup_method', 'signup_flow', 'language',\n                'affiliate_channel', 'affiliate_provider',\n                'first_affiliate_tracked', 'signup_app',\n                'first_device_type', 'first_browser']","390b5e5c":"for feature in oh_features:\n    X_dummy = pd.get_dummies(X[feature], prefix=feature)\n    X = X.drop([feature], axis=1)\n    X = pd.concat((X, X_dummy), axis=1)\nX.head()","539b3075":"#split the well processed dataset into X_train and X_test\nX_train = X.iloc[:len(train), :]\nX_test = X.iloc[len(train):, :]\nX_train = X_train.drop(['id'], axis=1)\nX_train.shape\nX_test = X_test.drop(['id'], axis=1)","be215e68":"le = LabelEncoder()\ny_trans = le.fit_transform(y_des)\ny_trans.shape","3726905d":"dtrain, dtest, train_label, test_label = train_test_split(X_train, y_trans, test_size = 0.3, random_state = 817)","e1f0b958":"#logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(dtrain, train_label)\npred_log=logreg.predict(dtest)\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(test_label, pred_log))","63f5702a":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(max_depth=20, n_estimators=100)\nrfc.fit(dtrain , train_label)\npred = rfc.predict(dtest)\nprint(accuracy_score(test_label, pred))","c38174af":"fi=pd.Series(rfc.feature_importances_, index=dtrain.columns)\nfn=fi.sort_values(ascending=True)\nfn[-20:].plot(kind='barh', color='r', figsize=(25, 12))\nplt.xlabel('importance', size=15)\nplt.title('Random Forest Importance', size=20)\nplt.tick_params(labelsize=15)","9616ec3a":"from sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(max_depth=10)\ndtc.fit(dtrain , train_label)\npred = dtc.predict(dtest)\nprint(accuracy_score(test_label, pred))","57503347":"from xgboost.sklearn import XGBClassifier\nxgb = XGBClassifier(max_depth=4, learning_rate=0.03, n_estimators=100,\n                    objective='multi:softprob', subsample=0.6, colsample_bytree=0.6, seed=40)\nxgb.fit(dtrain , train_label)\npred = xgb.predict(dtest) \nprint(accuracy_score(test_label, pred))","ef8b884d":"# only XGBoost\nxgb = XGBClassifier(max_depth=4, learning_rate=0.03, n_estimators=100,\n                    objective='multi:softprob', subsample=0.6, colsample_bytree=0.6, seed=40)\nxgb.fit(X_train, y_trans)\nXGBC_pred_test = xgb.predict(X_test)\nXGBC_pred_test_prob=xgb.predict_proba(X_test)","1c821966":"ids_test = test['id']\n\nids = []\ncountries = []\n\nfor i in range(len(X_test)):\n    idx = ids_test[i]\n    ids += [idx] * 5\n    countries += le.inverse_transform(np.argsort(XGBC_pred_test_prob[i])[::-1][:5]).tolist()","68615002":"submission = pd.DataFrame({\n    \"id\" : ids,\n    \"country\" : countries\n})\nsubmission.to_csv('submission_XGBC.csv', index = False)","eb5de7c6":"n_labels=len(set(y_des))\nn_labels","e5f17f50":"params = {\n    'objective': 'multi:softprob',\n    'eval_metric': 'merror',\n    'num_class': n_labels,\n    'eta': 0.5,\n    'max_depth': 6,\n    'subsample': 0.5,\n    'colsample_bytree': 0.3,\n    'silent': 1,\n    'seed': 123\n}","7bf360f2":"import xgboost as xgb\nnum_boost_round = 50\n\nDtrain = xgb.DMatrix(X_train, y_trans)\nres = xgb.cv(params, Dtrain, num_boost_round=num_boost_round, nfold=5,\n             callbacks=[xgb.callback.print_evaluation(show_stdv=True),\n                        xgb.callback.early_stop(50)])","430fdbd8":"num_boost_round = res['test-merror-mean'].idxmin()\nprint(format(num_boost_round))\nclf = xgb.train(params, Dtrain, num_boost_round=num_boost_round)\nclf","a605615f":"import operator\nimportance = clf.get_fscore()\nimportance_df = pd.DataFrame(\n    sorted(importance.items(), key=operator.itemgetter(1)),\n    columns=['feature', 'fscore']\n)","47519b98":"importance_df = importance_df.iloc[-20:, :]","8501a5f3":"plt.figure()\nimportance_df.plot(kind='barh', x='feature', y='fscore',\n                   legend=False, figsize=(20, 10))\nplt.title('XGBoost Feature Importance', size=25)\nplt.xlabel('Relative importance', size=20)\nplt.ylabel('Features', size=20)\nplt.tick_params(labelsize=15)\n#plt.gcf().savefig('feature_importance.png')","99d157ce":"Split 'date_account_created' as dac_year, dac_month, dac_day","7508b84e":" train test split","3c3f21f0":"Add feature \"session_count\" to dataset.","87b34390":"Decision Tree","b2c0c71f":"Percentage of Sign up methods used. This is the approach that users using to sign up for their new accounts, including basic, facebook, google and weibo. ","8fb72e31":"Findings:\nI tried different classification algorithms. Similar performance among those different algorithms after adjusting their parameters to be the optimal. I finally choose to use XGBoosting to predict for the test dataset. It has 63% accuracy and a 86.5% score on kaggle. Developing high resolution cross validation did not help with better feature selection and model ensembling. I think this is because there is no overfitting by using simply XGBoost classifier. And cross validation is mainly help with avoiding overfittings so that it doesn\u2019t help in this condition. Age is the most important feature given by XGBoost and Random Forest algorithm, which means that it is a strong predictor for the outcome. This is meaningful because other than age, there are no many other information provided when users creating their accounts. Meanwhile, from my relevance analysis, I saw that people who are within different age intervals are prone to going to different countries. Session count is another good predictor, which is the total number of actions when new users browse on the app. Date of account creating and timestamp of first active day are also important predictors that affect the outcome greatly. The weight of gender to be a predictor is less significant, which means that there are no difference for males and females in choosing their destinations. ","1dc5488f":"* Except for the destination column, there are 16 features including user id, date account created, timestamp first active, date first booking, gender, age, signup method, signup flow, language, affiliate channel, affiliate provider, first affiliate tracked, signup app, first device type, first browser. \n* Among those, date first booking is useless information because we want to predict before their first booking. Thus, for the first step, I drop \u2018date_first_booking\u201d and \u2018country_destination\u2019 column, and contatenate train and test dataset.\n* Second, fill the missing data with its last value in the dataset. ","6858fd4c":"Predict using XGBClassifier","88725fc7":"The relationship between age and destination countries. Users booking for countries Spain, Portugal and Netherlands tend to be younger whereas Users booking for Great Britain tend to be older. ","fa435cd8":"logistic regression","07b5e9c3":"Label Encode target y colunm","040509f9":" One hot coding--by get.dummies","8611dfb6":"XGBClassifier","884224c2":"Data:\n1.\tTrain\/Test_users.cvs: there are 16 features, include User_ID, gender, age, signup_method, language, affiliate_channel, etc.\n2.\tAge_gender_bkts.cvs: summary statistics of users' age group, gender, country of destination\n3.\tCountries.csv: summary statistics of destination countries and their locations\n4.\tSessions.csv: web sessions log for users, includes user\u2019s actions, device type, etc.","bc27902e":"People who using web to sign up for the account is older than those using other methods.","508f9327":"Random Forest","27bcba58":"Fill missing data with its last value","d6cecb34":"Predict by using XGBoost with cross Validate, score 0.86491 evaluated by kaggle","87271334":"There is no a significant difference of the age among the different genders. But the average of female is slightly less than other genders. ","b3d8e815":"Percentage of booking countries. NDF represents that people did not book for a trip or went to a country. Less than 30% went to US. Other countries all show small percentage of booking.","13f1d549":"Split 'timestamp_first_active' as tfa_year, tfa_month, tfa_day","463eefc8":"In the age column, there are some unmeaningful values such as 1, 2014. We don\u2019t want those unmeaningful data exist in our analysis. Therefore, I set those value beyond 13 to 90 as -1. ","fe3c8a7b":"Airbnb is an online marketplace for arranging or offering lodging, primarily homestays, or tourism experiences. New users on Airbnb can book a place to stay in 34000+ cities and across 190+ countries. Through analyzing past data provided by Airbnb, accurately predicting where a new user will book their first travel. As a result, Airbnb can share more personalized content with their community, decrease the average time to first booking, and better forecast demand. In this case, we need to predict the first travel destination of a new user based on his\/her registration information. ","bee91daf":"Gender Counts. The classes of genders are unknown, female, male, and others. Unknowns are those that users didn\u2019t provide their gender when they sign up. Count number of females is slightly greater than male. Few people are other. ","3941f6f8":"some visualizations"}}