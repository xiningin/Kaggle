{"cell_type":{"db4c12b2":"code","caac6d2a":"code","43d5f876":"code","e40710ff":"code","e23330c8":"code","ec8a0376":"code","d3c29670":"code","4b97bfa7":"code","faadec0d":"code","73a9fce8":"code","758f511a":"code","444d22b1":"code","d602e3d9":"markdown","e07c6fcf":"markdown","992a5061":"markdown","8adeeab7":"markdown"},"source":{"db4c12b2":"# Import necessary libraries\nfrom copy import deepcopy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom collections import Counter","caac6d2a":"# Set three centers, the model should predict similar results\ncenter_1 = np.array([1,1])\ncenter_2 = np.array([5,5])\ncenter_3 = np.array([8,1])\n\n# Generate random data and center it to the three centers\ndata_1 = np.random.randn(200, 2) + center_1\ndata_2 = np.random.randn(200,2) + center_2\ndata_3 = np.random.randn(200,2) + center_3\n\ndata = np.concatenate((data_1, data_2, data_3), axis = 0)\n\nplt.scatter(data[:,0], data[:,1], s=7)","43d5f876":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","e40710ff":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\ncenters_new    ","e23330c8":"# Plot the data and the centers generated as random\nplt.scatter(data[:,0], data[:,1], s=7)\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","ec8a0376":"df = pd.read_csv(\"..\/input\/Iris.csv\") #load the dataset\ndf.drop('Id',axis=1,inplace=True) # Se elimina la columna no requerida","d3c29670":"df.head()","4b97bfa7":"# Change categorical data to number 0-2\ndf[\"Species\"] = pd.Categorical(df[\"Species\"])\ndf[\"Species\"] = df[\"Species\"].cat.codes\n# Change dataframe to numpy matrix\ndata = df.values[:, 0:4]\ncategory = df.values[:, 4]","faadec0d":"# Number of clusters\nk = 3\n# Number of training data\nn = data.shape[0]\n# Number of features in the data\nc = data.shape[1]\n\n# Generate random centers, here we use sigma and mean to ensure it represent the whole data\nmean = np.mean(data, axis = 0)\nstd = np.std(data, axis = 0)\ncenters = np.random.randn(k,c)*std + mean\n\n# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)","73a9fce8":"centers_old = np.zeros(centers.shape) # to store old centers\ncenters_new = deepcopy(centers) # Store new centers\n\ndata.shape\nclusters = np.zeros(n)\ndistances = np.zeros((n,k))\n\nerror = np.linalg.norm(centers_new - centers_old)\n\n# When, after an update, the estimate of that center stays the same, exit loop\nwhile error != 0:\n    # Measure the distance to every center\n    for i in range(k):\n        distances[:,i] = np.linalg.norm(data - centers[i], axis=1)\n    # Assign all training data to closest center\n    clusters = np.argmin(distances, axis = 1)\n    \n    centers_old = deepcopy(centers_new)\n    # Calculate mean for every cluster and update the center\n    for i in range(k):\n        centers_new[i] = np.mean(data[clusters == i], axis=0)\n    error = np.linalg.norm(centers_new - centers_old)\ncenters_new    ","758f511a":"# Plot the data and the centers generated as random\ncolors=['orange', 'blue', 'green']\nfor i in range(n):\n    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\nplt.scatter(centers_new[:,0], centers_new[:,1], marker='*', c='g', s=150)","444d22b1":"# Predict clusters using existing data\ndf_for_clustering = df.drop(\"Species\", axis=1)\ncluster_arr = []\nfor i in range(n):\n    a = {}\n    for j in range(k):\n        a[j] = np.linalg.norm(df_for_clustering.values[i,:] - centers_new[j])\n    #print(\"{}. Line's predicted cluster is {}\".format(i, min(a, key = lambda x: a.get(x) )))#if wanna see cluster of each row\n    cluster_arr.append(min(a, key = lambda x: a.get(x)))\n\ncounter=Counter(cluster_arr)\nfor i in range(len(counter)):\n    print(\"cluster {}: {} samples\".format(i, counter[i]))","d602e3d9":"# Generate Random Data\nGenerate random data normally distributed around 3 centers, with a noise.","e07c6fcf":"# K-Means Clustering\nThis work is based on Mubaris' great work (\nhttps:\/\/mubaris.com\/2017\/10\/01\/kmeans-clustering-in-python\/).\n\nA description of the algorithm can be found:\nhttps:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/cs229-notes7a%202.pdf\n\n![](https:\/\/github.com\/andrewxiechina\/DataScience\/blob\/master\/K-Means\/k4XcapI.gif?raw=true)","992a5061":"# Test on Iris Dataset","8adeeab7":"# Create K-Means Algorithm\nGenerate random data normally distributed around 3 centers, with a noise."}}