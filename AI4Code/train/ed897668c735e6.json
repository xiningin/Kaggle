{"cell_type":{"d9121bdf":"code","4f939576":"code","9fe62e82":"code","5aa809ca":"code","c81218e7":"code","6e3c6300":"code","87f7c1c1":"code","c51d514b":"code","6049936c":"code","c0562a3d":"code","7e963480":"code","ec812e5a":"code","5e5ace33":"code","25a4c60f":"code","88d48356":"code","b672e230":"code","4afcf6a0":"code","bbf75503":"code","f54aaa33":"code","6d1983b6":"markdown","88b47e51":"markdown","351367df":"markdown","85850e8e":"markdown","61c96ba8":"markdown","1587df66":"markdown","87589641":"markdown","966583d3":"markdown"},"source":{"d9121bdf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4f939576":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nplt.style.use('ggplot')","9fe62e82":"train_dirty = pd.read_csv('\/kaggle\/input\/train.csv')\ntest_dirty = pd.read_csv('\/kaggle\/input\/test.csv')","5aa809ca":"train_dirty.head()","c81218e7":"test_dirty.head()","6e3c6300":"# identify any missing values in train_dirty and test_dirty\nprint(train_dirty.isnull().sum())\nprint(test_dirty.isnull().sum())","87f7c1c1":"# calculate mean of y in train_dirty data frame and fill NaN value\navg_y = train_dirty['y'].mean()\ntrain_dirty['y'].replace(np.nan, avg_y, inplace = True)\ntrain_dirty.isnull().sum()","c51d514b":"# shape of data\ntrain_dirty.shape, test_dirty.shape","6049936c":"# use seaborn residplot to see if a linear relationship exists\nsns.scatterplot(train_dirty['x'], train_dirty['y'])\nplt.show()","c0562a3d":"# remove outlier (max value of x or y)\nmax_x = train_dirty['x'].idxmax()\ntrain_dirty.drop(max_x, inplace = True)","7e963480":"sns.scatterplot(train_dirty['x'], train_dirty['y'])\nplt.show()","ec812e5a":"df_train = pd.DataFrame(data=train_dirty)\nx_train = np.array(train_dirty['x']).reshape(-1,1) # reshape data \ny_train = train_dirty['y']\nx_test = np.array(test_dirty['x']).reshape(-1,1) # reshape data\ny_test = test_dirty['y']\n\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","5e5ace33":"# residual plot \nsns.residplot(x_train, y_train)\nplt.show()","25a4c60f":"# scatter plot\nsns.scatterplot(df_train['x'], df_train['y'])\nplt.show()","88d48356":"df_train.corr()","b672e230":"# create a linear model and fit to training data\nlm = LinearRegression().fit(x_train, y_train)","4afcf6a0":"# estimate value of y uisng x_test\nyhat = lm.predict(x_test)","bbf75503":"plt.scatter(x_test, y_test, color='r', marker='.')\nplt.plot(x_test, yhat, color ='b', lw=2)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()","f54aaa33":"# rsquared using LinearRegression.score()\nr2 = lm.score(x_test,y_test)\n\n# rsquared using r2_score from sklearn.metrics library\n#r2_skl = r2_score(y_test, yhat)\n\n# mean squared error\nmse = mean_squared_error(y_test, yhat)\nmse\n\n# root mean squared error\nrmse = np.sqrt(mse)\nrmse\n\nprint('R2: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","6d1983b6":"# Conclusion  \n\n**From the above model and statistics:  \n\n1. A total of 98.88% of the varaince in 'y' is explained by the linear model \n2. The MSE and RMSE are incredibly low indicated that our model has performed well","88b47e51":"## Import necessary libraries","351367df":"### Idenitfy relationship between x and y variables","85850e8e":"## By the above analysis:\n\n1. Residual plot show that data points are randomly spread around the x_axis, indicating a linear relationship exists  \n2. Scatterplot indicates a linear model will fit the data, also shows data is strongly correlated  \n3. The correlation of 0.995 indicates that a strong linear relationship exists","61c96ba8":"### Before more analyis is done, lets rename the data sets","1587df66":"**read in csv data as x_dirty and y_dirty, using pandas**","87589641":"### From the scatterplot above, an outlier makes it difficult to determine if a linear relationship exists.","966583d3":"## Explore dataset"}}