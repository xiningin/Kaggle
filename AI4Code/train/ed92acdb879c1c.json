{"cell_type":{"945b88b6":"code","a4dc9ebc":"code","f521e998":"code","5c01eb48":"code","bda5f8af":"code","2a6d2c66":"code","c8aa15c7":"code","112f95ae":"code","fcd4426d":"code","e96a1eb7":"code","fdeda7e6":"code","74c5974a":"code","3c7f6ef0":"markdown","d62f198b":"markdown","727c6461":"markdown","a02c26e1":"markdown","292bf536":"markdown","bfd4634c":"markdown","ddbd64e0":"markdown","b286bcf6":"markdown","9e3f6003":"markdown","9dc44bdb":"markdown"},"source":{"945b88b6":"import gc\nimport os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport PIL\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageEnhance, ImageOps\n\nfrom tqdm import tqdm, tqdm_notebook\n\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader","a4dc9ebc":"'''\nAutoAugment: Learning Augmentation Policies from Data\nhttps:\/\/arxiv.org\/abs\/1905.\n'''\n\nclass ImageNetPolicy(object):\n    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment ImageNet Policy\"\n\nclass SVHNPolicy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on SVHN.\n        Example:\n        >>> policy = SVHNPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     SVHNPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.9, \"shearX\", 4, 0.2, \"invert\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.7, \"invert\", 5, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.6, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 3, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"equalize\", 1, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.8, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"shearY\", 8, 0.4, \"invert\", 5, fillcolor),\n            SubPolicy(0.9, \"shearY\", 5, 0.2, \"solarize\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 6, 0.8, \"autocontrast\", 1, fillcolor),\n            SubPolicy(0.6, \"equalize\", 3, 0.9, \"rotate\", 3, fillcolor),\n\n            SubPolicy(0.9, \"shearX\", 4, 0.3, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 8, 0.7, \"invert\", 4, fillcolor),\n            SubPolicy(0.9, \"equalize\", 5, 0.6, \"translateY\", 6, fillcolor),\n            SubPolicy(0.9, \"invert\", 4, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.3, \"contrast\", 3, 0.8, \"rotate\", 4, fillcolor),\n\n            SubPolicy(0.8, \"invert\", 5, 0.0, \"translateY\", 2, fillcolor),\n            SubPolicy(0.7, \"shearY\", 6, 0.4, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 0.8, \"rotate\", 4, fillcolor),\n            SubPolicy(0.3, \"shearY\", 7, 0.9, \"translateX\", 3, fillcolor),\n            SubPolicy(0.1, \"shearX\", 6, 0.6, \"invert\", 5, fillcolor),\n\n            SubPolicy(0.7, \"solarize\", 2, 0.6, \"translateY\", 7, fillcolor),\n            SubPolicy(0.8, \"shearY\", 4, 0.8, \"invert\", 8, fillcolor),\n            SubPolicy(0.7, \"shearX\", 9, 0.8, \"translateY\", 3, fillcolor),\n            SubPolicy(0.8, \"shearY\", 5, 0.7, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.7, \"shearX\", 2, 0.1, \"invert\", 5, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment SVHN Policy\"\n\n\nclass CIFAR10Policy(object):\n    \"\"\" Randomly choose one of the best 25 Sub-policies on CIFAR10.\n        Example:\n        >>> policy = CIFAR10Policy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     CIFAR10Policy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.1, \"invert\", 7, 0.2, \"contrast\", 6, fillcolor),\n            SubPolicy(0.7, \"rotate\", 2, 0.3, \"translateX\", 9, fillcolor),\n            SubPolicy(0.8, \"sharpness\", 1, 0.9, \"sharpness\", 3, fillcolor),\n            SubPolicy(0.5, \"shearY\", 8, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.5, \"autocontrast\", 8, 0.9, \"equalize\", 2, fillcolor),\n\n            SubPolicy(0.2, \"shearY\", 7, 0.3, \"posterize\", 7, fillcolor),\n            SubPolicy(0.4, \"color\", 3, 0.6, \"brightness\", 7, fillcolor),\n            SubPolicy(0.3, \"sharpness\", 9, 0.7, \"brightness\", 9, fillcolor),\n            SubPolicy(0.6, \"equalize\", 5, 0.5, \"equalize\", 1, fillcolor),\n            SubPolicy(0.6, \"contrast\", 7, 0.6, \"sharpness\", 5, fillcolor),\n\n            SubPolicy(0.7, \"color\", 7, 0.5, \"translateX\", 8, fillcolor),\n            SubPolicy(0.3, \"equalize\", 7, 0.4, \"autocontrast\", 8, fillcolor),\n            SubPolicy(0.4, \"translateY\", 3, 0.2, \"sharpness\", 6, fillcolor),\n            SubPolicy(0.9, \"brightness\", 6, 0.2, \"color\", 8, fillcolor),\n            SubPolicy(0.5, \"solarize\", 2, 0.0, \"invert\", 3, fillcolor),\n\n            SubPolicy(0.2, \"equalize\", 0, 0.6, \"autocontrast\", 0, fillcolor),\n            SubPolicy(0.2, \"equalize\", 8, 0.8, \"equalize\", 4, fillcolor),\n            SubPolicy(0.9, \"color\", 9, 0.6, \"equalize\", 6, fillcolor),\n            SubPolicy(0.8, \"autocontrast\", 4, 0.2, \"solarize\", 8, fillcolor),\n            SubPolicy(0.1, \"brightness\", 3, 0.7, \"color\", 0, fillcolor),\n\n            SubPolicy(0.4, \"solarize\", 5, 0.9, \"autocontrast\", 3, fillcolor),\n            SubPolicy(0.9, \"translateY\", 9, 0.7, \"translateY\", 9, fillcolor),\n            SubPolicy(0.9, \"autocontrast\", 2, 0.8, \"solarize\", 3, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.1, \"invert\", 3, fillcolor),\n            SubPolicy(0.7, \"translateY\", 9, 0.9, \"autocontrast\", 1, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment CIFAR10 Policy\"\n\n    \nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            \"shearX\": np.linspace(0, 0.3, 10),\n            \"shearY\": np.linspace(0, 0.3, 10),\n            \"translateX\": np.linspace(0, 150 \/ 331, 10),\n            \"translateY\": np.linspace(0, 150 \/ 331, 10),\n            \"rotate\": np.linspace(0, 30, 10),\n            \"color\": np.linspace(0.0, 0.9, 10),\n            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n            \"solarize\": np.linspace(256, 0, 10),\n            \"contrast\": np.linspace(0.0, 0.9, 10),\n            \"sharpness\": np.linspace(0.0, 0.9, 10),\n            \"brightness\": np.linspace(0.0, 0.9, 10),\n            \"autocontrast\": [0] * 10,\n            \"equalize\": [0] * 10,\n            \"invert\": [0] * 10\n        }\n\n        # from https:\/\/stackoverflow.com\/questions\/5252170\/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n        def rotate_with_fill(img, magnitude):\n            rot = img.convert(\"RGBA\").rotate(magnitude)\n            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n\n        func = {\n            \"shearX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"shearY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"translateX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n                fillcolor=fillcolor),\n            \"translateY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n                fillcolor=fillcolor),\n            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n        }\n\n        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n        #     operation1, ranges[operation1][magnitude_idx1],\n        #     operation2, ranges[operation2][magnitude_idx2])\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n\n    def __call__(self, img):\n        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n        return img","f521e998":"'''\n\ud5c8\ud0dc\uba85\ub2d8 kernel\nhttps:\/\/www.kaggle.com\/tmheo74\/3rd-ml-month-car-image-cropping\n'''\ndef crop_boxing_img(img_name, margin=16) :\n    if img_name.split('_')[0] == \"train\" :\n        PATH = TRAIN_IMAGE_PATH\n        data = train_df\n    elif img_name.split('_')[0] == \"test\" :\n        PATH = TEST_IMAGE_PATH\n        data = test_df\n        \n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, \\\n                   ['bbox_x1','bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n\n    return img.crop((x1,y1,x2,y2))\n\n\n\ndef imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated","5c01eb48":"class TestDataset(Dataset):\n    def __init__(self, df, mode='original', transforms=None, crop=False):\n        self.df = df\n        self.mode = mode\n        self.transforms = transforms[self.mode]\n        self.crop = crop\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        if self.crop:\n            image = crop_boxing_img(self.df['img_file'][idx]).convert('RGB')\n        else:\n            image = Image.open(os.path.join(TEST_IMAGE_PATH, self.df['img_file'][idx])).convert(\"RGB\")\n            \n        if self.transforms:\n            image = self.transforms(image)\n            \n        return image        \n\n    \ntarget_size = (224, 224)\n\n\ndata_transforms = {\n    'original': transforms.Compose([\n        transforms.Resize(target_size),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n    'augment': transforms.Compose([\n        transforms.Resize(target_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(20),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n    'cifar10_autoaug': transforms.Compose([\n        transforms.Resize(target_size),\n        CIFAR10Policy(),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n    'SVHN_autoaug': transforms.Compose([\n        transforms.Resize(target_size),\n        SVHNPolicy(),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n    'ImageNet_autoaug': transforms.Compose([\n        transforms.Resize(target_size),\n        ImageNetPolicy(),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n    'resized_crop': transforms.Compose([\n        transforms.RandomResizedCrop(target_size),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ])\n}\n","bda5f8af":"DATA_PATH = '..\/input\/'\nTEST_IMAGE_PATH = os.path.join(DATA_PATH, 'test')\ntest_df = pd.read_csv('..\/input\/test.csv')","2a6d2c66":"batch_size = 4\ntest_dataset = TestDataset(test_df, mode='original', transforms=data_transforms, crop=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","c8aa15c7":"test_dataset = TestDataset(test_df, mode='original', transforms=data_transforms, crop=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","112f95ae":"test_dataset = TestDataset(test_df, mode='augment', transforms=data_transforms, crop=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","fcd4426d":"test_dataset = TestDataset(test_df, mode='cifar10_autoaug', transforms=data_transforms, crop=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","e96a1eb7":"test_dataset = TestDataset(test_df, mode='SVHN_autoaug', transforms=data_transforms, crop=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","fdeda7e6":"test_dataset = TestDataset(test_df, mode='ImageNet_autoaug', transforms=data_transforms, crop=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","74c5974a":"test_dataset = TestDataset(test_df, mode='resized_crop', transforms=data_transforms, crop=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\ninputs = next(iter(test_loader))\nout = torchvision.utils.make_grid(inputs)\nplt.figure(figsize=(30, 30))\nimshow(out)","3c7f6ef0":"+ **\ub525\ub7ec\ub2dd\uc5d0\uc11c augmentation\uc740 \uc6ec\ub9cc\ud574\uc11c \ub2e4 \ub4e4\uc5b4\uac00\ub294 \ud3b8\uc774\uae30 \ub54c\ubb38\uc5d0 \uc774\ub97c \uc9c1\uc811 \ub208\uc73c\ub85c \ud655\uc778\ud558\ub294 \uc791\uc5c5\uc774 \ud544\uc218\uc801\uc785\ub2c8\ub2e4.**\n+ **autoaugment\ub97c \uc0ac\uc6a9\ud558\uba74 \uc9c1\uc811 augmentation\uc744 \uace8\ub77c\uc900\ub2e4\uace0\ub294 \ud558\uc9c0\ub9cc autoaug\ub3c4 policy\uac00 \uc5ec\ub7ec\uac00\uc9c0\ub85c \ub098\ub269\ub2c8\ub2e4.**\n+ **\uc800\ub3c4 \uc774 \ucf54\ub4dc\ub97c \uae30\ubc18\uc73c\ub85c \uc55e\uc73c\ub85c \uc788\uc744 \ub300\ud68c\uc5d0 \uc801\uc6a9\ud574\ubcfc \uc0dd\uac01\uc785\ub2c8\ub2e4.**","d62f198b":"#### \uc5b4\ub5a4 augmentation\uc774 \uc131\ub2a5\uc5d0 \ub3c4\uc6c0\ub420\uc9c0\ub294 \uc9c1\uc811 \ub208\uc73c\ub85c \ud655\uc778\ud574\ubcf4\uc138\uc694!\n#### \ub3c4\uc6c0\ub418\uc168\ub2e4\uba74 \uc6b0\uce21 \uc0c1\ub2e8\uc5d0 **Upvote** \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4!","727c6461":"## 7. wrong example (RandomResizecrop)","a02c26e1":"## 4. crop + autoaugment(cifar10)","292bf536":"## 6. crop + autoaugment(ImageNet)","bfd4634c":"## 1. Original Image\n","ddbd64e0":"## 3. crop + augmentation(horizontal flip, rotation) \uc801\uc6a9\ud588\uc744 \uacbd\uc6b0","b286bcf6":"#### randomresized crop\uc5d0\uc11c scale argument\uc758 default \uac12\uc740 0.08~1.0 \uc785\ub2c8\ub2e4. \ub530\ub77c\uc11c **RandomResizedCrop(target_size, scale=(0.8, 1.0))**\uacfc \uac19\uc774 \uc8fc\uc9c0 \uc54a\uc744 \uacbd\uc6b0\uc5d0\ub294 \uc624\ud788\ub824 \ud559\uc2b5\uc5d0 \ubc29\ud574\uac00 \ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","9e3f6003":"## 5. crop + autoaugment(SVHN)","9dc44bdb":"## 2. Original + crop (no augmentation)"}}