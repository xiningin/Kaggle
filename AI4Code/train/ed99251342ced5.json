{"cell_type":{"2aea689d":"code","97569b61":"code","5f1b6773":"code","b2ecc837":"code","355b4230":"code","28fe22b1":"code","7d5438f2":"code","fe60c1b1":"code","67ab629a":"code","36847746":"code","d9b85139":"code","0bba03cd":"code","fe87ca16":"markdown","a7d3e3fe":"markdown","f7e39e5f":"markdown","00f6aa6b":"markdown","f3392c52":"markdown"},"source":{"2aea689d":"%%capture\n!pip install pytorch-lightning","97569b61":"from typing import Callable, Tuple\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport pandas as pd\nimport pytorch_lightning as pl\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm\n\n%matplotlib inline","5f1b6773":"BATCH_SIZE = 128\nEPOCHS = 2\nLR = 1e-3","b2ecc837":"df = pd.read_csv(\"\/kaggle\/input\/100-bird-species\/birds.csv\")\ndf[\"filepaths\"] = df[\"filepaths\"].str.replace(\"\\\\\", \"\/\", regex=False)\nprefix = \"\/kaggle\/input\/100-bird-species\/\"\ndf[\"filepaths\"] = prefix + df[\"filepaths\"]\nle = LabelEncoder()\ndf[\"y\"] = le.fit_transform(df[\"labels\"])\ndf.head()","355b4230":"df[\"data set\"].value_counts(), df[\"labels\"].value_counts()","28fe22b1":"subset = df.sample(6).reset_index()\nplt.figure(figsize=(12, 12))\nfor i in range(len(subset)):\n    img = mpimg.imread(subset.loc[i, \"filepaths\"])\n    label = subset.loc[i, \"labels\"]\n    plt.subplot(3,2, i+1)\n    plt.imshow(img)\n    plt.title(label)\nplt.show()","7d5438f2":"class Data(Dataset):\n    def __init__(self, df: pd.DataFrame) -> None:\n        self.files = df[\"filepaths\"].values\n        self.y = df[\"y\"].values\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, i):\n        return torchvision.io.read_image(self.files[i]) \/ 255.0, self.y[i]\n    \ntrain_ds = Data(df[df[\"data set\"]==\"train\"])\nvalid_ds = Data(df[df[\"data set\"]==\"valid\"])\ntest_ds = Data(df[df[\"data set\"]==\"test\"])\n\ntrain_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=4, pin_memory=True)\ntest_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=4, pin_memory=True)","fe60c1b1":"# base_model = torchvision.models.resnet34(pretrained=True)\n# base_model","67ab629a":"class Model(nn.Module):\n    def __init__(self, num_classes, freeze=True):\n        super().__init__()\n        self.base = torchvision.models.resnet34(pretrained=False)\n        self.base.fc = nn.Identity()\n        self.bn = nn.BatchNorm1d(512)\n        self.linear = nn.Linear(512, num_classes)\n        \n        if freeze:\n            self.base = self.base.eval()\n            for p in self.base.parameters():\n                p.requires_grad = False\n        \n    def forward(self, x):\n        return self.linear(self.bn(self.base(x)))\n\nclass LightningModel(pl.LightningModule):\n    def __init__(self, model: nn.Module, lr: float, loss_fn: Callable) -> None:\n        super().__init__()\n        self.model = model\n        self.lr = lr\n        self.loss_fn = loss_fn\n        self.accuracy = lambda x, y: (x.argmax(-1) == y).float().mean()\n        \n    def common_step(\n        self, \n        batch: Tuple[torch.FloatTensor, torch.LongTensor],\n    ) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n        x, y = batch\n        logits = self.model(x)\n        loss = self.loss_fn(logits, y)\n        acc = self.accuracy(logits, y)\n        return loss, acc\n    \n    def training_step(self, batch: Tuple[torch.FloatTensor, torch.LongTensor], *args) -> torch.FloatTensor:\n        loss, acc = self.common_step(batch)\n        self.log(\"training_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log(\"training_accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True)\n        return loss\n    \n    def validation_step(self, batch: Tuple[torch.FloatTensor, torch.LongTensor], *args) -> None:\n        loss, acc = self.common_step(batch)\n        self.log(\"validation_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log(\"validation_accuracy\", acc, on_step=True, on_epoch=True, prog_bar=True)\n                        \n    def configure_optimizers(self) -> torch.optim.Optimizer:\n        return torch.optim.Adam(self.model.parameters(), self.lr)","36847746":"model = Model(len(le.classes_))\nlightning_model = LightningModel(model, lr=LR, loss_fn=nn.CrossEntropyLoss())","d9b85139":"trainer = pl.Trainer(\n    max_epochs=EPOCHS,\n    gpus=torch.cuda.device_count(),\n)\n\ntrainer.fit(lightning_model, train_dl, valid_dl)","0bba03cd":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = model.eval().to(device)\n\ny_preds = []\nys = []\nfor x, y in tqdm(test_dl):\n    y_preds.append(model(x.to(device)).argmax(dim=-1))\n    ys.append(y.to(device))\n    \n(torch.cat(y_preds) == torch.cat(ys)).float().mean()","fe87ca16":"## Training","a7d3e3fe":"## Model","f7e39e5f":"## Data","00f6aa6b":"## Shameless Self Promotion\nIf you wish to see more of content like this explained buy my [DL course](https:\/\/www.udemy.com\/course\/machine-learning-and-data-science-2021\/?referralCode=E79228C7436D74315787) (usually $15).","f3392c52":"Accuracy is printed below."}}