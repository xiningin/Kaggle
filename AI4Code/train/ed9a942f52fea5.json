{"cell_type":{"72a9ca21":"code","e7733f73":"code","a6737b8e":"code","75a6ca01":"code","cacf12fc":"code","6c654595":"code","15f28ef0":"code","601db8b5":"code","06b46ccc":"code","015ab98d":"code","39b649bc":"code","a14b862f":"code","7c421578":"code","c6b60d1a":"code","c6aabb78":"code","86f9ada4":"code","e0f2506c":"code","7ede1a72":"code","e6418b8d":"markdown","2ca7449c":"markdown","f49aa729":"markdown","e8fbffeb":"markdown","e39797df":"markdown","933bd49c":"markdown"},"source":{"72a9ca21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7733f73":"!pip install git+git:\/\/github.com\/AndLen\/simpletransformers.git --quiet","a6737b8e":"import csv\nimport os\nimport torch\nfrom transformers import pipeline\nimport gc\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy.special import softmax\nfrom simpletransformers.classification import (ClassificationModel, ClassificationArgs)\nimport sklearn\nfrom sklearn.model_selection import train_test_split","75a6ca01":"test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\ntraining = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")","cacf12fc":"training[\"text\"].isna().sum()","6c654595":"training_df = training[[\"text\", \"target\"]]\ntraining_df.columns = [\"text\", \"labels\"]","15f28ef0":"training_df.shape","601db8b5":"shuffled_training = training_df.sample(frac=1).reset_index(drop=True)","06b46ccc":"#train_df, test_df = train_test_split(training_df, test_size=0.15, random_state=42, stratify=training_df[\"labels\"])\n#eval_df, test_df = train_test_split(test_df, test_size=0.50, random_state=42, stratify=test_df[\"labels\"])","015ab98d":"#train_df.shape ,test_df.shape, eval_df.shape","39b649bc":"# This cleans ram and vram during re-runs\ngc.collect()\ntorch.cuda.empty_cache()","a14b862f":"# Create a ClassificationModel\nmodel_args = ClassificationArgs(num_train_epochs=2, \n                                overwrite_output_dir=True)\nmodel_args.manual_seed = 42\nmodel_args.best_model_dir = \"\/kaggle\/working\/best_model\"\nmodel_args.output_dir = \"\/kaggle\/temp\/output\"\nmodel_args.normalization = True #this enables the built-in Bertweet custom tokenizer\n\nmodel_args.reprocess_input_data = True\n#odel_args.evaluate_during_training = True\n#model_args.evaluate_during_training_verbose = True\nmodel_args.train_batch_size = 80\nmodel_args.eval_batch_size = 80\n\nmodel_args.early_stopping_metric = \"mcc\"\nmodel_args.early_stopping_metric_minimize = False\nmodel_args.use_early_stopping = True\nmodel_args.early_stopping_consider_epochs = True\nmodel_args.early_stopping_patience = 1\n\nmodel = ClassificationModel(model_type='bertweet', \n                            model_name='vinai\/bertweet-base', \n                            args = model_args, \n                            num_labels = 2)","7c421578":"model.train_model(shuffled_training,\n                  acc=sklearn.metrics.accuracy_score, \n                  f1=sklearn.metrics.f1_score)","c6b60d1a":"result, model_outputs, wrong_predictions = model.eval_model(shuffled_training, \n                                                            acc=sklearn.metrics.accuracy_score,\n                                                            f1=sklearn.metrics.f1_score)","c6aabb78":"#0.85 accuracy on test set\nresult","86f9ada4":"predictions, raw_outputs = model.predict(test[\"text\"].to_list())","e0f2506c":"mypreds = pd.DataFrame(test[[\"id\"]])\nmypreds[\"target\"] = predictions","7ede1a72":"mypreds.to_csv(\"submission.csv\", index=False)","e6418b8d":"## Predictions on new data","2ca7449c":"## Loading Bertweet from Huggingface","f49aa729":"Used for model selection, finally I train the classifier on the whole training set","e8fbffeb":"## Train, test, eval splitting with 70:15:15 proportions","e39797df":"## Installing SimpleTransformers","933bd49c":"## Loading Data"}}