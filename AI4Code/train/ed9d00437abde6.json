{"cell_type":{"26c66848":"code","f07eafd2":"code","0951e92c":"code","82610724":"code","3661392d":"code","c94e4565":"code","9c02ce3f":"code","a80fbf07":"code","5e548bdb":"code","353d9245":"code","c2d1c654":"code","0b07d2b5":"code","4399ff23":"markdown","096cf4bf":"markdown","5fe02f1a":"markdown","e985259d":"markdown","1397905d":"markdown","272b3f51":"markdown","8eef437b":"markdown","6e04fd4e":"markdown","a742c2ea":"markdown","c0edcb1f":"markdown"},"source":{"26c66848":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","f07eafd2":"df = pd.read_csv('..\/input\/severstal-steel-defect-detection\/train.csv')\ndf","0951e92c":"def load(image_id):\n    \"\"\"\n    Steel Defect Detection \uc218\ud589\uc744 \uc704\ud574\uc11c \uc6d0\ubcf8 \uc774\ubbf8\uc9c0(\ucca0\ud310)\uc640 \uacb0\ud568 \uc774\ubbf8\uc9c0\ub97c \ubd88\ub7ec\uc635\ub2c8\ub2e4.\n    \"\"\"\n    \n    # \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uac00 \uc800\uc7a5\ub41c \ud3f4\ub354\uc758 \uc704\uce58\ub97c \uc815\uc758\ud55c\ub2e4.\n    path = '..\/input\/severstal-steel-defect-detection\/train_images\/'\n    \n    # \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\ub97c \ubd88\ub7ec\uc628\ub2e4.\n    image = plt.imread(path + image_id)\n    \n    # \uacb0\ud568 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\ud55c\ub2e4.\n    label = np.zeros(256 * 1600)\n    \n    where = df['ImageId'] == image_id\n\n    # DataFrame\uc758 \uac01 \ud589\ubcc4\ub85c \ubc18\ubcf5 \uc2e4\ud589\ud55c\ub2e4.\n    for idx, (image_id, class_id, pixels) in df[where].iterrows():\n\n        pixels = pixels.split()               # \uacf5\ubc31\ub2e8\uc704\ub85c \ubd84\ub9ac\n        pixels = np.array(pixels, dtype=int)  # \ub118\ud30c\uc774 \uc5b4\ub808\uc774\ub85c \ubcc0\ud658\n        pixels = pixels.reshape(-1, 2)        # n X 2 \uc758 \ud589\ub82c\ub85c \ubcc0\ud658\n\n        # \uacb0\ud568 \uc815\ubcf4(\uc2dc\uc791\uc810 \ubc0f \uae38\uc774)\uc5d0 \ub530\ub77c\uc11c \uacb0\ud568 \ubd80\ubd84\uc5d0 \uacb0\ud568 \uc885\ub958\ub97c \uae30\uc785\ud569\ub2c8\ub2e4.\n        for start, length in pixels:\n            label[start:start + length] = class_id\n\n    # \uacb0\ud568 \uc815\ubcf4\ub97c \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\uc640 \uac19\uc740 Shape\ub85c \uce58\ud658 \ud569\ub2c8\ub2e4.\n    label = label.reshape(256, 1600, order='F')\n    \n    return image, label","82610724":"image_id = df.sample()['ImageId'].values[0]\nimage, label = load(image_id)\nplt.imshow(image)\nplt.show()\nplt.imshow(label)\nplt.show()","3661392d":"def f1_score(y_true, y_pred, c):\n    \n    y_pred = tf.argmax(y_pred, axis=-1)\n\n    pred = tf.cast(y_pred == c, dtype=tf.float32)\n    true = tf.cast(y_true == c, dtype=tf.float32)\n\n    tp = tf.reduce_sum(pred * true)\n    fp = tf.reduce_sum(pred * (1 - true))\n    fn = tf.reduce_sum((1 - pred) * true)\n\n    return tp \/ (tp + 0.5 * (fp + fn))\n\n\ndef f1_0(y_true, y_pred):\n    return f1_score(y_true, y_pred, 0)\n\ndef f1_1(y_true, y_pred):\n    return f1_score(y_true, y_pred, 1)\n\ndef f1_2(y_true, y_pred):\n    return f1_score(y_true, y_pred, 2)\n\ndef f1_3(y_true, y_pred):\n    return f1_score(y_true, y_pred, 3)\n\ndef f1_4(y_true, y_pred):\n    return f1_score(y_true, y_pred, 4)","c94e4565":"tf.keras.backend.clear_session()\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input((256, 1600, 3)),\n    tf.keras.layers.Conv2D(16, (5, 5), strides=2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32, (5, 5), strides=2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (5, 5), strides=2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.UpSampling2D(8),\n    tf.keras.layers.Conv2D(5, (5, 5), padding='same', activation='softmax'),\n])\nmetrics = [f1_0, f1_1, f1_2, f1_3, f1_4]\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=metrics, loss_weights=[0.001, 1, 1, 1, 1])\nmodel.summary()","9c02ce3f":"class UNet(tf.keras.Model):\n    \n    def __init__(self):\n        super(UNet, self).__init__()\n        \n        # Pooling Layers.\n        self.maxpool = tf.keras.layers.MaxPool2D()\n        \n        # Convolution Layers.\n        self.conv1 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n        self.conv2 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n        self.conv3 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n        self.conv4 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n        self.conv5 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        self.conv6 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        self.conv7 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv8 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv9 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n        self.conv10 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n        self.conv11 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv12 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n        self.conv13 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        self.conv14 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n        self.conv15 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n        self.conv16 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n        self.conv17 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n        self.conv18 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n\n        # Transposed Convolution Layers.\n        self.upconv1 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=2, padding='same', activation='relu')\n        self.upconv2 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=2, padding='same', activation='relu')\n        self.upconv3 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=2, padding='same', activation='relu')\n        self.upconv4 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=2, padding='same', activation='relu')\n        self.upconv5 = tf.keras.layers.Conv2DTranspose(5, (2, 2), strides=2, padding='same', activation='softmax')\n        \n        # Batch Normalization Layers.\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.bn3 = tf.keras.layers.BatchNormalization()\n        self.bn4 = tf.keras.layers.BatchNormalization()\n        self.bn5 = tf.keras.layers.BatchNormalization()\n        self.bn6 = tf.keras.layers.BatchNormalization()\n        self.bn7 = tf.keras.layers.BatchNormalization()\n        self.bn8 = tf.keras.layers.BatchNormalization()\n        self.bn9 = tf.keras.layers.BatchNormalization()\n        self.bn10 = tf.keras.layers.BatchNormalization()\n        self.bn11 = tf.keras.layers.BatchNormalization()\n        self.bn12 = tf.keras.layers.BatchNormalization()\n        self.bn13 = tf.keras.layers.BatchNormalization()\n        self.bn14 = tf.keras.layers.BatchNormalization()\n        self.bn15 = tf.keras.layers.BatchNormalization()\n        self.bn16 = tf.keras.layers.BatchNormalization()\n        self.bn17 = tf.keras.layers.BatchNormalization()\n        self.bn18 = tf.keras.layers.BatchNormalization()\n        \n    def call(self, x, training=False):\n        \n        x = x \/ 255\n        \n        x = self.bn1(self.conv1(x), training)\n        x = self.bn2(self.conv2(x), training)\n        x_2 = x\n        \n        x = self.maxpool(x)\n        x = self.bn3(self.conv3(x), training)\n        x = self.bn4(self.conv4(x), training)\n        x_4 = x\n        \n        x = self.maxpool(x)\n        x = self.bn5(self.conv5(x), training)\n        x = self.bn6(self.conv6(x), training)\n        x_6 = x\n        \n        x = self.maxpool(x)\n        x = self.bn7(self.conv7(x), training)\n        x = self.bn8(self.conv8(x), training)\n        x_8 = x\n        \n        x = self.maxpool(x)\n        x = self.bn9(self.conv9(x), training)\n        x = self.bn10(self.conv10(x), training)\n        \n        x = self.upconv1(x)\n        x = tf.concat([x, x_8], axis=-1)\n\n        x = self.bn11(self.conv11(x), training)\n        x = self.bn12(self.conv12(x), training)\n        \n        x = self.upconv2(x)\n        x = tf.concat([x, x_6], axis=-1)\n        \n        x = self.bn13(self.conv13(x), training)\n        x = self.bn14(self.conv14(x), training)\n        \n        x = self.upconv3(x)\n        x = tf.concat([x, x_4], axis=-1)\n        \n        x = self.bn15(self.conv15(x), training)\n        x = self.bn16(self.conv16(x), training)\n        \n        x = self.upconv4(x)\n        x = tf.concat([x, x_2], axis=-1)\n        \n        x = self.bn17(self.conv17(x), training)\n        x = self.bn18(self.conv18(x), training)\n        \n        x = self.upconv5(x)\n        \n        return x\n\n\ntf.keras.backend.clear_session()\nmodel = UNet()\nmetrics = [f1_0, f1_1, f1_2, f1_3, f1_4]\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=metrics, loss_weights=[0.0001, 1, 1, 1, 1])\nmodel.build(input_shape=(None, 128, 800, 3))\nmodel.summary()\nmodel(np.random.randn(10, 128, 800, 3)).shape","a80fbf07":"# Train\/Valid split\n\nids = df['ImageId']          # \uc778\ub371\uc2a4\ub9cc \uac00\uc838\uc624\uae30\nids = ids.drop_duplicates()  # \uc911\ubcf5 \uc81c\uac70\n\nids_train = ids.sample(frac=0.8)\nids_valid = ids.drop(index=ids_train.index)","5e548bdb":"def gen(ids, batch_size):\n\n    ids = ids.values             # Pandas\uc5d0\uc11c Numpy\ub85c \ubcc0\uacbd\n    \n    while True:\n\n        # \uc774\ubbf8\uc9c0 \uc544\uc774\ub514\ub97c \uc154\ud50c \ud569\ub2c8\ub2e4.\n        np.random.shuffle(ids)\n\n        for i in range(0, ids.shape[0], batch_size):\n\n            images = []  # \uc6d0\ubcf8 \uc774\ubbf8\uc9c0 \ub2f4\uc744 \ubc84\ud37c\n            labels = []  # \uacb0\ud568 \uc774\ubbf8\uc9c0 \ub2f4\uc744 \ubc84\ud37c\n\n            for image_id in ids[i:i + batch_size]:     # \ud604\uc7ac \ubbf8\ub2c8 \ubc30\uce58\uc758 \uccab\ubc88\uc9f8 \ubd80\ud130 \ub05d\uae4c\uc9c0 \ubc18\ubcf5\n                image, label = load(image_id)          # image.shape == (256, 1600, 3) \/ label.shape == (256, 1600)\n                image = cv2.resize(image, (800, 128))  # image.shape == (128, 800) => GPU Memory \uc544\ub07c\uae30 \uc704\ud574\uc11c \uc808\ubc18\uc73c\ub85c \ucd95\uc18c\n                images.append(image)\n                labels.append(label)\n\n            images = np.array(images, copy=False)    # shape == (batch_size, 128, 800)\n            labels = np.array(labels, copy=False)    # shape == (batch_size, 256, 1600)\n\n            yield images, labels","353d9245":"hist = model.fit(\n    # train dataset generator.\n    gen(ids_train, 64),\n    # valid dataset generator.\n    validation_data = gen(ids_valid, 128),\n    # number of steps for train set.\n    steps_per_epoch = np.ceil(ids_train.shape[0] \/ 64).astype('int'),\n    # number of steps for valid set.\n    validation_steps = np.ceil(ids_valid.shape[0] \/ 128).astype('int'),\n    # number of epochs.\n    epochs = 10\n)","c2d1c654":"plt.title('F1 Score for each classes in validation set')\nplt.plot(hist.history['val_f1_0'], label='val_f1_0')\nplt.plot(hist.history['val_f1_1'], label='val_f1_1')\nplt.plot(hist.history['val_f1_2'], label='val_f1_2')\nplt.plot(hist.history['val_f1_3'], label='val_f1_3')\nplt.plot(hist.history['val_f1_4'], label='val_f1_4')\nplt.legend()\nplt.show()","0b07d2b5":"for _ in range(5):\n    \n    image_id = ids_valid.sample().values[0]\n\n    image, label = load(image_id)\n    image = cv2.resize(image, (800, 128))\n\n    pred = model(image[np.newaxis, ...])\n\n    pred = np.argmax(pred, axis=-1)\n    \n    fig, axs = plt.subplots(3, 1, figsize=[20, 10])\n    axs[0].imshow(image)\n    axs[1].imshow(label)\n    axs[2].imshow(pred[0])\n    fig.show()","4399ff23":"### Plot the result","096cf4bf":"### \uc6d0\ubcf8 \uc774\ubbf8\uc9c0 \ubc0f \uacb0\ud568 \uc774\ubbf8\uc9c0\ub97c \ubd88\ub7ec\uc624\ub294 \ud568\uc218\ub97c \uc815\uc758\ud569\ub2c8\ub2e4.","5fe02f1a":"### Load modules","e985259d":"![image.png](attachment:image.png)","1397905d":"### U-Net","272b3f51":"### FCN","8eef437b":"$$\n{\\displaystyle F_{1}={\\frac {2}{\\mathrm {recall} ^{-1}+\\mathrm {precision} ^{-1}}}=2\\cdot {\\frac {\\mathrm {precision} \\cdot \\mathrm {recall} }{\\mathrm {precision} +\\mathrm {recall} }}={\\frac {\\mathrm {t} p}{\\mathrm {tp} +{\\frac {1}{2}}(\\mathrm {fp} +\\mathrm {fn} )}}}.\n$$","6e04fd4e":"### Training","a742c2ea":"### Custom Metric","c0edcb1f":"### Load dataset"}}