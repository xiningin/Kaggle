{"cell_type":{"fa592507":"code","0c3cebc6":"code","6ccc6e27":"code","fa00044a":"code","cb0b3aa1":"code","c4c96939":"code","583173ea":"code","3e5cc87a":"code","2f1134b5":"code","9f4bb9df":"code","f57539c5":"code","ade69088":"code","63b12d34":"code","c926ea57":"code","1fe32e64":"code","b1eeaa66":"code","797c2eb1":"code","e113ab05":"code","f2b90f7e":"code","a6c44750":"code","647d30d2":"code","ef06533e":"code","9f090447":"code","c8c23f9e":"code","47b5068e":"code","ed54cc37":"code","cdaebe88":"code","e33d853f":"code","ba0a7782":"code","7a90f68a":"code","5066608a":"code","0d218ecf":"code","c0d61b36":"code","0fbee5e0":"code","d1edb01e":"code","b7494069":"code","38883942":"code","5d2f0379":"markdown","7e6bccb6":"markdown"},"source":{"fa592507":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport glob\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nimport os\nfrom tensorflow.keras.utils import to_categorical\nfrom tqdm import tqdm\nfrom PIL import Image\nimport cv2","0c3cebc6":"#used label encoder\ncode = {'Benign':0 ,'Malware':1}\n\ndef getcode(n) : \n    for x , y in code.items() : \n        if n == y : \n            return x","6ccc6e27":"s=224#size\ntrain=80\ntest=20","fa00044a":"X_train = []\ny_train = []\ntraining_data = []","cb0b3aa1":"# Dir = '..\/input\/iot-malware-removed-dublicated\/IOT_Malware_dataset'\nDir_1 = '..\/input\/androiddb-gray\/Android_DB_Gray'","c4c96939":"files = glob.glob(pathname= str( Dir_1+'\/Benign'+'\/*.*'))\na=len(files)\nn_train1=int((train \/100)*a)\nn_test1=a-n_train1\nfor file in tqdm(files[0:n_train1]): \n    image = cv2.imread(file)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_array = cv2.resize(image , (s,s), interpolation = cv2.INTER_AREA)\n    X_train.append(list(image_array))\n    y_train.append(code['Benign'])\n    training_data.append([image_array, code['Benign']])","583173ea":"\nfiles = glob.glob(pathname= str( Dir_1+'\/Malware'+'\/*.*'))\na=len(files)\nn_train2=int((train \/100)*a)\nn_test2=a-n_train2\nfor file in tqdm(files[0:n_train2]): \n    image = cv2.imread(file)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_array = cv2.resize(image , (s,s), interpolation = cv2.INTER_AREA)\n    X_train.append(list(image_array))\n    y_train.append(code['Malware'])\n    training_data.append([image_array, code['Malware']])","3e5cc87a":"print(f'we have {len(X_train)} items in X_train')","2f1134b5":"# test for randomness\nprint(len(training_data))\nprint('y_train',y_train[70:80])\n\n#using Random library\nimport random\nrandom.shuffle(training_data)\n#for sample in training_data[:10]:# just test for Shuffle\n  #  print(sample[1])\n    \n#then return data to X_train and y_train\nX_train = []\ny_train = []\n\nfor features,label in training_data:\n    X_train.append(features)\n    y_train.append(label)\nprint('y_train after shuffle',y_train[70:80]) # so data it's random\n# free some space in Ram\ndel training_data # means var train ,we did not needed any more so deleted for free space from ram ","9f4bb9df":"plt.figure(figsize=(20,20))\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    plt.imshow(X_train[i]) \n    plt.axis('off')\n    plt.title(getcode(y_train[i]), fontsize=15)","f57539c5":"X_test = []\ny_test = []\ntraining_data = []","ade69088":"files = glob.glob(pathname= str( Dir_1+'\/Benign'+'\/*.*'))\nfor file in tqdm(files[n_train1:n_train1+n_test1]): \n    image = cv2.imread(file)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_array = cv2.resize(image , (s,s), interpolation = cv2.INTER_AREA)\n    X_test.append(list(image_array))\n    y_test.append(code['Benign'])\n    training_data.append([image_array, code['Benign']])","63b12d34":"files = glob.glob(pathname= str( Dir_1+'\/Malware'+'\/*.*'))\nfor file in tqdm(files[n_train2:n_train2+n_test2]): \n    image = cv2.imread(file)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_array = cv2.resize(image , (s,s), interpolation = cv2.INTER_AREA)\n    X_test.append(list(image_array))\n    y_test.append(code['Malware'])\n    training_data.append([image_array, code['Malware']])","c926ea57":"print(f'we have {len(X_test)} items in X_train')","1fe32e64":"# test for randomness\nprint(len(training_data))\nprint('y_train',y_test[70:80])\n\n#using Random library\nimport random\nrandom.shuffle(training_data)\n#for sample in training_data[:10]:# just test for Shuffle\n    #print(sample[1])\n    \n#then return data to X_train and y_train\nX_test = []\ny_test = []\n\nfor features,label in training_data:\n    X_test.append(features)\n    y_test.append(label)\n\nprint('y_train after shuffle',y_test[70:80]) # so data it's random\n# free some space in Ram\ndel training_data # means var train ,we did not needed any more so deleted for free space from ram ","b1eeaa66":"plt.figure(figsize=(18,18))\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    plt.imshow(X_test[i]) \n    plt.axis('off')\n    plt.title(getcode(y_test[i]), fontsize=15)","797c2eb1":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nprint(f'X_train shape  is {X_train.shape}')\nprint(f'X_test shape  is {X_test.shape}')\nprint(f'y_train shape  is {y_train.shape}')\nprint(f'y_test shape  is {y_test.shape}')","e113ab05":"#from keras.utils import to_categorical\n#y_train1 = to_categorical(y_train)\n#print(y_train1.shape)\n#Keras need data in 4 dimention\n# Reshape image in 3 dimensions (height = 28px, width = 28px , channels = 1)\nX_train = X_train.reshape(-1,s,s,3)\nX_test = X_test.reshape(-1,s,s,3)\n\nprint(X_train.shape)\nprint(X_test.shape)\n","f2b90f7e":"#Convert y_train to categorical\ny_train=to_categorical(y_train)\nprint(\"y_train \",y_train.shape)\n#Convert y_train to categorical\ny_test=to_categorical(y_test)\nprint(\"y_test \",y_test.shape)","a6c44750":"from tensorflow.keras.applications import ResNet50, VGG16, VGG19, DenseNet121\nfrom tensorflow.keras.utils import plot_model\n# pre_trained_model = DenseNet121(input_shape = (s, s, 3), \n#                                 include_top = False, \n#                                 weights = 'imagenet')#imagenet\n# for layer in pre_trained_model.layers:\n#     layer.trainable = False  #to make the layers to Freeze Weights\n# # pre_trained_model.summary()\n# # plot_model(pre_trained_model, show_shapes=True, to_file='ResNetwork.png')","647d30d2":"\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPool2D,BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import SGD,Adam,RMSprop,Adagrad\nfrom tensorflow.keras.regularizers import l1,l2\nimport numpy as np\nnp.random.seed(1000)#512\n\nconv_args = {\n        \"activation\": \"relu\",\n        \"kernel_initializer\": \"Orthogonal\",#Orthogonal RandomNormal\n        \"padding\": \"same\",\n        \"strides\":1,\n        #\"activity_regularizer\":\"l2\",\n}\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(s,s,3)))\n#, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001)\nmodel.add(Conv2D(8, kernel_size=(3,3), **conv_args))#input_shape=(s,s,3),\nmodel.add(Conv2D(16, kernel_size=(3,3), **conv_args))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#,activity_regularizer=l1(0.000001)\n\nmodel.add(Conv2D(32, kernel_size=(3,3), **conv_args))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(64, kernel_size=(3,3), **conv_args))#\nmodel.add(Conv2D(64, kernel_size=(3,3), **conv_args))#, kernel_regularizer=l2(0.001), activity_regularizer=l2(0.001)\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(256, kernel_size=(3,3), **conv_args))#64,101\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.08))#0.08 0.18\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))#1024#,kernel_initializer='random_uniform')\nmodel.add(Dropout(0.40))\n# model.add(Dense(1024, activation='relu'))#1024\n# model.add(Dropout(0.33))\n#model.add(Dense(1024, activation='relu'))#1024\n#model.add(Dropout(0.33))\n#model.add(Dense(1024, activation='relu'))#1024\n#model.add(Dropout(0.33))\nmodel.add(Dense(2, activation='softmax'))\nmodel.summary()\nopt = Adam(learning_rate=0.0001)#, momentum=0.9\n# Compile the model\n\nMETRICS = ['categorical_accuracy']#, tensorflow.keras.metrics.Precision(name='categorical_precision'),\n           #tensorflow.keras.metrics.Recall(name='categorical_recall')]\nmodel.compile(loss=tensorflow.keras.losses.CategoricalCrossentropy(),#label_smoothing = 0.1\n              optimizer=opt, metrics=METRICS) #[\"categorical_accuracy\"]\n#categorical_crossentropy\n#lr=0.00001\n#plot_model(model, show_shapes=True, to_file='ResNetwork.png')","ef06533e":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n#ModelCheckpoint means save best weights\nmodel_chkpt = ModelCheckpoint('best_mod.h5', save_best_only=True, monitor='accuracy')\nlearning_rate_reduction1 = ReduceLROnPlateau(monitor='loss', \n                                             patience=2, verbose=1, factor=0.5,mode=\"min\", min_lr=0.00001)\nlearning_rate_reduction2 = ReduceLROnPlateau(monitor='val_loss', \n                                             patience=2, verbose=1, factor=0.5,mode=\"min\", min_lr=0.00001)\n\nearly_stopping = EarlyStopping(monitor='val_categorical_accuracy', restore_best_weights=True, patience=20)#False\ncallbacks1=[early_stopping]#,learning_rate_reduction2,learning_rate_reduction1]","9f090447":"# FAST_RUN=True\n#if FAST_RUN else 6\nepochs=128 #64\nhistory = model.fit(X_train, y_train, \n          validation_data=(X_test, y_test),\n          epochs=epochs, batch_size=32, shuffle=True, #True  16\n          callbacks=callbacks1\n         )\n#validation_data=(X_test, y_test)  validation_split=0.20,","c8c23f9e":"fig, ax = plt.subplots(1,2, figsize=(12, 3))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","47b5068e":"import plotly.express as px\npx.line(history.history, y=['categorical_accuracy', 'val_categorical_accuracy'],title=\"Training accuracy\")","ed54cc37":"import plotly.express as px\npx.line(history.history, y=['loss', 'val_loss'], title=\"Training loss\")","cdaebe88":"ModelLoss, ModelAccuracy = model.evaluate(X_test,y_test,batch_size=32)#,precision, recall\nprint('Test Loss is {}'.format(ModelLoss))\nprint('Test Accuracy is {}'.format(ModelAccuracy ))","e33d853f":"import sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_val_score\nimport tensorflow as tf\nplt.figure()\nax = plt.subplot()\nax.set_title('Confusion Matrix')\n#pred = model.predict_classes(X_test) #we can't using this function because not founding in Function Model\npred = model.predict(X_test)\npred = np.argmax(pred, axis=1)\nY_TEST = np.argmax(y_test, axis =1)\n# cm = metrics.confusion_matrix(Y_TEST,pred)\n# print(cm)\ncm = tf.math.confusion_matrix(\n    Y_TEST, pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n    name=None\n)\nprint(cm)\n\nclasses=['Benign', 'Ransomware']\nsns.heatmap(cm, annot=True,xticklabels=classes, yticklabels=classes,cmap='Blues')#YlGnBu_r or Blues or twilight_shifted_r\nprint('Number of images:',Y_TEST.shape)\nprint('Actual image ',Y_TEST[0:21])\nprint('Predic image ',pred[0:21])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show","ba0a7782":"from sklearn.metrics import classification_report\nprint(classification_report(Y_TEST, pred))\n\n#support : means number each classifier","7a90f68a":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import precision_recall_curve\n# precision recall curve\nprecision = dict()\nrecall = dict()\nPRED = to_categorical(pred)\ny = y_test\n#Df['label'].values\n# Binarize the output\ny = label_binarize(y, classes=[0,1])\nn_classes = y.shape[1]\n\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n                                                        PRED[:, i])\n    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n\nplt.xlabel(\"recall\")\nplt.ylabel(\"precision\")\nplt.legend(loc=\"best\")\nplt.title(\"precision vs. recall curve\")\nplt.show()","5066608a":"from sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\n\nPRED = to_categorical(pred)\ny = y_test\n#Df['label'].values\n# Binarize the output\ny = label_binarize(y, classes=[0,1])\nn_classes = y.shape[1]\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n       fpr[i], tpr[i], _ = roc_curve(y_test[:,i], PRED[:,i])\n       roc_auc[i] = auc(fpr[i], tpr[i])\ncolors = ['blue', 'red', 'green']\n#cls = {1:'normal', 2:'other pneumonia', 0:'covid'}\ncls = {0:'covid', 1:'normal', 2:'other pneumonia'}\nfor i, color ,c in zip(range(n_classes), colors, cls.values()):\n    plt.plot(fpr[i], tpr[i], color=color, lw=1.5,\n             label='ROC curve of '+c+ '(AUC = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n    \nplt.plot([0, 1], [0, 1], 'k--',linestyle='--')\nplt.xlim([-0.05, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC for multi-class data')\nplt.legend(loc=\"lower right\")\nplt.show()","0d218ecf":"import matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n#precision, recall, _ = precision_recall_curve(Y_test, PRED)\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n                                                        PRED[:, i])\n   # plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n    #fig, ax = plt.subplots(1, figsize=(6,3))\n    plt.step(recall[i], precision[i],where='post', lw=2 ,label='class {}'.format(i))\n    #plt.fill_between(recall[i], precision[i], step='post', color='lightgray')\n    \nplt.suptitle('Precision-Recall Tradeoff')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend(loc=\"best\")\nplt.show()\n","c0d61b36":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test, PRED)","0fbee5e0":"from sklearn.metrics import log_loss\nlog_loss(y_test, PRED)","d1edb01e":"from sklearn.metrics import accuracy_score\n\nprint('accuracy_score     :',accuracy_score(Y_TEST,pred,normalize=True)) # fraction of all Trues over everything normalize by default is true\n#print('number of all Trues:',accuracy_score(Y_TEST,pred, normalize=False)) #number of all Trues\nprint('Number of images   :',Y_TEST.shape)","b7494069":"\nfrom sklearn.metrics import recall_score\n# recall_score(y_true, y_pred, labels=None, pos_label=1, average=\u2019binary\u2019, sample_weight=None)\n\nRecallScore = recall_score(Y_TEST, pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('Recall Score(Sensitivity) is : ', RecallScore)","38883942":"from sklearn.metrics import precision_score\n\n# precision_score(y_true, y_pred, labels=None, pos_label=1, average=\u2019binary\u2019,sample_weight=None)\nPrecisionScore = precision_score(Y_TEST, pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('Precision Score is : ', PrecisionScore)","5d2f0379":"## ====================================================================================","7e6bccb6":"![alt text](https:\/\/miro.medium.com\/max\/712\/1*Z54JgbS4DUwWSknhDCvNTQ.png)"}}