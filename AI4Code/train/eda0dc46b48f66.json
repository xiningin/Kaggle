{"cell_type":{"49fbfb97":"code","b6bfa392":"code","f9d8744b":"code","0df5a69f":"code","87307534":"code","916d51df":"code","72d5466d":"code","f22e7d57":"code","37e35afe":"code","6ac7e3db":"code","e823b5ee":"code","6d63a2d4":"code","330e67b2":"code","42e0445a":"code","794b5046":"code","c5a2924a":"code","aa1d5a89":"code","bb576579":"code","09fb026f":"markdown","bd481c22":"markdown","48403c59":"markdown","f6366e9b":"markdown","222e06a4":"markdown","048939e5":"markdown","4dd2a2c3":"markdown","75a14067":"markdown","131accb8":"markdown","c227a913":"markdown","7ab09bb0":"markdown","8fdc7b0e":"markdown","8104d651":"markdown","f97cb3e5":"markdown","b9c0d97a":"markdown","ba027e39":"markdown","5ab48266":"markdown","e30a6b8c":"markdown"},"source":{"49fbfb97":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#flag missing data\nna_sentinels = {'SALEDATE':['1900-01-01T00:00:00.000Z'],'PRICE':[0,''],'AYB':[0],'EYB':[0]}\n\n#three data sources\nresidential = pd.read_csv(\"..\/input\/raw_residential_data.csv\", index_col='SSL', na_values=na_sentinels).drop(columns=[\"OBJECTID\"])\ncondo = pd.read_csv(\"..\/input\/raw_condominium_data.csv\", index_col='SSL', na_values=na_sentinels).drop(columns=[\"OBJECTID\"])\naddress = pd.read_csv(\"..\/input\/raw_address_points.csv\")\n","b6bfa392":"residential[\"SOURCE\"] = \"Residential\"\ncondo[\"SOURCE\"] = \"Condominium\"\n\ndf = pd.concat([residential,condo], sort=False)\ndf.info()","f9d8744b":"#Identify all categorical variables\ncategories = [['CNDTN_D','CNDTN'],['HEAT_D','HEAT'],['STYLE_D','STYLE'],['STRUCT_D','STRUCT'],['GRADE_D','GRADE'],['ROOF_D','ROOF'],['EXTWALL_D','EXTWALL'],['INTWALL_D','INTWALL']]\ncat_drop = []\nfor c in categories:\n    df[c[1]] = df[c[0]].astype('category')\n    cat_drop.append(c[0])\n\ndf['SOURCE'] = df['SOURCE'].astype('category')    \n#eliminate redundant dummy variables\ndf.drop(cat_drop, inplace=True, axis=1)","0df5a69f":"print(df.isnull().sum())","87307534":"df.dropna(subset=['ROOMS','BEDRM','BATHRM','HF_BATHRM','FIREPLACES','EYB','QUALIFIED'], inplace=True)\n\nprint(df.isnull().sum())","916d51df":"int_col = ['BATHRM','HF_BATHRM','ROOMS','BEDRM','EYB','SALE_NUM','BLDG_NUM','FIREPLACES','LANDAREA']\n#con_col = ['BATHRM','HF_BATHRM','NUM_UNITS','ROOMS','BEDRM','EYB','STORIES','SALE_NUM','KITCHENS','FIREPLACES','LANDAREA']\n\nfor i in int_col:\n    df[i] = df[i].astype('int64')","72d5466d":"print(df[\"SALEDATE\"].sort_values(ascending=True).head(5))\nprint(df[\"SALEDATE\"].sort_values(ascending=False).head(5))","f22e7d57":"import re\n\ndef valid_datestring(x):\n    if re.match(r'(19|20)\\d{2}\\-',str(x)):\n        return x\n    else:\n        return None\n\ndf[\"SALEDATE\"] = df['SALEDATE'].map(valid_datestring)\ndf['GIS_LAST_MOD_DTTM'] =  df['GIS_LAST_MOD_DTTM'].map(valid_datestring)","37e35afe":"df['SALEDATE'] = pd.to_datetime(df['SALEDATE'], dayfirst=False)\ndf['GIS_LAST_MOD_DTTM'] = pd.to_datetime(df['GIS_LAST_MOD_DTTM'], dayfirst=False)","6ac7e3db":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-colorblind')\n# Basic correlogram\nsns.pairplot(df[['ROOMS','BATHRM','HF_BATHRM','BEDRM']], kind=\"scatter\", diag_kind = 'kde', plot_kws = {'alpha': 0.33, 's': 80, 'edgecolor': 'k'}, size = 4)\nplt.show()","e823b5ee":"df = df[( (df[\"ROOMS\"]<100) & (df[\"ROOMS\"]>=df[\"BEDRM\"]) & (df[\"BATHRM\"]<24) )]","6d63a2d4":"#df.head()\naddress.head(5)","330e67b2":"address_subset = address.drop_duplicates(['SSL'], keep='last').set_index(\"SSL\")[[\"FULLADDRESS\",\"CITY\",\"STATE\",\"ZIPCODE\",\"NATIONALGRID\",\"LATITUDE\",\"LONGITUDE\",\"ASSESSMENT_NBHD\",\"ASSESSMENT_SUBNBHD\",\"CENSUS_TRACT\",\"CENSUS_BLOCK\",\"WARD\"]]","42e0445a":"premaster = pd.merge(df,address_subset,how=\"left\",on=\"SSL\")","794b5046":"address[\"SQUARE\"] = address[\"SQUARE\"].apply(lambda x: str(x)[0:4])\n\naddress_impute = address[((address[\"SQUARE\"]!=\"0000\") & (address[\"SQUARE\"].str.match(r'\\d+')) )] \\\n    .groupby(\"SQUARE\") \\\n    .agg({'X':'median','Y':'median','QUADRANT':'first','ASSESSMENT_NBHD':'first','ASSESSMENT_SUBNBHD':'first','CENSUS_TRACT': 'median','WARD':'first','ZIPCODE':'median','LATITUDE':'median','LONGITUDE':'median'})  \n\nprint(address_impute.head())","c5a2924a":"#create a SQUARE key on premaster\npremaster[\"SQUARE\"] = df.apply(axis=1, func=lambda x: str(x.name)[0:4]) \nmaster = pd.merge(premaster,address_impute,how=\"left\",on=\"SQUARE\", suffixes=('', '_impute')) \\\n\ncols_to_impute = [\"CENSUS_TRACT\",\"LATITUDE\",\"LONGITUDE\",\"ZIPCODE\",\"WARD\",\"ASSESSMENT_NBHD\",\"ASSESSMENT_SUBNBHD\"]\nfor c in cols_to_impute:\n    master[c] = master[c].fillna(master[(c + \"_impute\")])\n\nmaster.drop([\"CENSUS_TRACT_impute\",\"LATITUDE_impute\",\"LONGITUDE_impute\",\"ZIPCODE_impute\",\"WARD_impute\",\"ASSESSMENT_NBHD_impute\",\"ASSESSMENT_SUBNBHD_impute\"],axis=1,inplace=True)","aa1d5a89":"master.describe()","bb576579":"master.to_csv(\"DC_Properties.csv\", header=True)","09fb026f":"...and change data type to *datetime* where appropriate:","bd481c22":"Many entries, including most condiminiums, do not have a specific SSL match in the address points database. In these cases, we will impute with data from nearnby properties (in the same by *square*).\n\nFirst, we will build a lookup DataFrame that includes summarized data for properties in each square:","48403c59":"A correlogram o\n","f6366e9b":"It seems like there a few dozen entries that are missing key descriptors. Let's remove these rows.","222e06a4":"...and change data types to integer where appropriate.","048939e5":"Next, eliminate redundant dummy codes for categorical values.","4dd2a2c3":"Inspect the new master dataset","75a14067":"### Wrangling the D.C. Real Property Dataset\nThis notebook describes the steps required to inspect, clean, and merge several sources of information on residential properties in Washington, D.C.","131accb8":"Merge the Address Points columns with the combined property database, using the SSL index:","c227a913":"Now let's see if there are any missing values in our dataset.","7ab09bb0":"Finally, save the master dataframe to *DC_Properties.csv*","8fdc7b0e":"There are two timestamp fields. Any suspicious outlier values?","8104d651":"A number of columns reflect the jurisdictions of municipal agencies. For the main dataset, we will only include a subset of rows of interest.\n\nAlso note we will drop rows duplicate SSL rows. More than one address\/row may be associated with a single  SSL (square,suffix,lot), such as a corner address with separate addresses facing each adjacent street ([source](http:\/\/https:\/\/octo.dc.gov\/sites\/default\/files\/dc\/sites\/octo\/publication\/attachments\/DCGIS-MarFAQ_0.pdf)). The descriptive information we are interested in - other than mailing address - will typically be identical for both rows, so we only need to keep one.","f97cb3e5":"First, we will merge the [residential ](http:\/\/http:\/\/opendata.dc.gov\/datasets\/computer-assisted-mass-appraisal-condominium?page=2)and [condominium ](http:\/\/http:\/\/opendata.dc.gov\/datasets\/computer-assisted-mass-appraisal-condominium) datasets provided by the [DC Geographic Informtion Service](http:\/\/https:\/\/octo.dc.gov\/service\/dc-gis-services).\n\nThe **SSL** - the square, suffix, and lot - will serve as an index for the properties:","b9c0d97a":"Do not allow sale dates outside the 20th or 21st century:","ba027e39":"This reveals several impossible properties:\n* The ROOMS X BTHRM plot includes at least one place with 101 rooms and only 3 bathrooms. \n* The BEDRM X ROOMS plot includes properties with more bedrooms than rooms.\n* The BEDRM X BATHRM plot includes one point representing 24 bedrooms and 24 bathrooms. As it turns out, this represents a[ pile of shipping containers](http:\/\/https:\/\/dc.curbed.com\/2014\/9\/30\/10041494\/dc-gets-first-apartments-made-of-shipping-containers) that would be more accureately described as four separate 6 Bed\/6 Bath units.\n\nWe will eliminate all these suspicious rows:","5ab48266":"Next, we will explore the [Address Points database](http:\/\/http:\/\/opendata.dc.gov\/datasets\/address-residential-units ). This source will complement the property information with spatial information and links to census data.\n","e30a6b8c":"Next, we will impute the fields from the address dataset for any properties lacking this information"}}