{"cell_type":{"a95d73d4":"code","036ee7ea":"code","9de72abe":"code","c4456471":"code","3af7c9c6":"code","b99f6657":"code","6f8c7fe6":"code","14ddd55b":"code","4a4c19e8":"markdown","48b41af1":"markdown","9cd8fdc1":"markdown","da8b66a3":"markdown","ccd7d356":"markdown","8027c6eb":"markdown","ac793211":"markdown","58e6869b":"markdown","b6bcb5d9":"markdown","eb50e456":"markdown","8c5c9400":"markdown","1aab985c":"markdown","fa4d5fce":"markdown","198bd873":"markdown","7cfba8cf":"markdown"},"source":{"a95d73d4":"import numpy as np\n\nimport tensorflow as tf\n\n!pip install -q tensorflow-hub\n!pip install -q tfds-nightly\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\n\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"Hub version: \", hub.__version__)\n","036ee7ea":"# Split do dataset de treino em  60% and 40%: haver\u00e1  15,000 examplos\n# para treino, 10,000 para valida\u00e7\u00e3o e 25,000 examplos para teste.\ntrain_data, validation_data, test_data = tfds.load(\n    name=\"imdb_reviews\", \n    split=('train[:60%]', 'train[60%:]', 'test'),\n    as_supervised=True)","9de72abe":"train_examples_batch, train_labels_batch = next(iter(train_data.batch(20)))\ntrain_examples_batch","c4456471":"#modelo de embedding pr\u00e9-treinado do TF Hub: google\/tf2-preview\/gnews-swivel-20dim\/1.\n#cria\u00e7\u00e3o de biblioteca no Keras\n#formato de outputs dos embedding: (num_eamples, embedding_dimension)\n\nembedding = \"https:\/\/tfhub.dev\/google\/tf2-preview\/gnews-swivel-20dim\/1\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[], \n                           dtype=tf.string, trainable=True)\nhub_layer(train_examples_batch[:3])","3af7c9c6":"model = tf.keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.summary()","b99f6657":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","6f8c7fe6":"history = model.fit(train_data.shuffle(10000).batch(512),\n                    epochs=20,\n                    validation_data=validation_data.batch(512),\n                    verbose=1)","14ddd55b":"results = model.evaluate(test_data.batch(512), verbose=2)\n\nfor name, value in zip(model.metrics_names, results):\n  print(\"%s: %.3f\" % (name, value))","4a4c19e8":"**Perda e acur\u00e1cia**","48b41af1":"**Download do dataset e split**","9cd8fdc1":"Abaixo, s\u00e3o impressos 20 reviews e seus labels, 0 ou 1, sendo 0 para review negativo e 1 pare review positivo:","da8b66a3":"**Treino do modelo** ","ccd7d356":"**Constru\u00e7\u00e3o do modelo:**","8027c6eb":"Treino do modelo com 20 epochs, em batches de 512 samples. While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set: ","ac793211":"**Classifica\u00e7\u00e3o de reviews de filmes: TF Hub**","58e6869b":"O objetivo dessa an\u00e1lise \u00e9 classificar reviews de filmes em negativos ou positivos, com base em 500.000 reviews do IMDB. O dataset \u00e9 dividido em 25.000 para treino e 25.000 para teste. ","b6bcb5d9":"**Constru\u00e7\u00e3o do modelo**","eb50e456":"**Overview dos dados**","8c5c9400":"**Loss function e otimizador**","1aab985c":"Para criar o classificador, as camadas s\u00e3o empilhadas sequencialmente:\n\nA. A primeira camada \u00e9 do TensorFlow Hub e usa um modelo pr\u00e9-treinado para mapear uma frase em seu vetor de incorpora\u00e7\u00e3o. O modelo utilizado est\u00e1 dispon\u00edvel em  google \/ tf2-preview \/ gnews-swivel-20dim \/ 1 e divide a frase em tokens, incorpora cada token e combina a incorpora\u00e7\u00e3o. As dimens\u00f5es resultantes s\u00e3o: (num_examples, embedding_dimension).\nB. Vetor de sa\u00edda de comprimento fixo,  sendo uma camada totalmente conectada, com 16 unidades ocultas.\nC. A \u00faltima camada est\u00e1 conectada a um \u00fanico n\u00f3 de sa\u00edda.\n","fa4d5fce":"O modelo necessita de uma fun\u00e7\u00e3o de perda e de um otimizador para treino. A fun\u00e7\u00e3o escolhida foi binary_crossentropy, por tratar-se de classifica\u00e7\u00e3o bin\u00e1ria com model outputs logits (a single-unit layer with a linear activation).","198bd873":"Um dos modos de representa\u00e7\u00e3o do texto \u00e9 convert\u00ea-los em modelos de embedding vectors, que s\u00e3o utilizados para convers\u00e3o do texto em vetores. Utilizamos um modelo pr\u00e9-treinado do TensorFLow Hub, o que traz vantagens como diminui\u00e7\u00e3o do tempo de preprocessamento e o processo \u00e9 mais simples pelo fato de os embeddings terem tamanho fixo.","7cfba8cf":"Pensando na arquitetura de cria\u00e7\u00e3o das redes neurais e suas camadas, algumas decis\u00f5es s\u00e3o relevantes: como representar o texto, quantas camadas utilizar e quantas hidden units utilizar por camada.\n"}}