{"cell_type":{"ce132483":"code","e8f2541e":"code","db7e2c8b":"code","9441dedf":"code","51e7a345":"code","1b61c101":"code","5059a614":"code","f3a5808e":"code","a6ccd004":"code","05f3f623":"code","5073c9c1":"code","0f36e62e":"code","e0da655d":"code","af566db6":"code","a6e7a2fe":"code","bdd2bbaa":"code","cbb9b0cc":"code","98fc2c53":"code","ed6d562f":"code","23b21b30":"code","4b0a6698":"code","55a184f5":"code","f40cf3fc":"code","fad9901d":"code","05c85805":"code","5ae2ddee":"code","71eaf1dd":"code","ec2cdf91":"code","98fbab77":"code","fcbc7522":"code","420b8ef4":"code","c67d2da5":"code","65036415":"code","81bd295e":"code","08d309fc":"code","e99411d9":"code","f5186e7f":"code","77848afd":"code","6c2c826f":"code","a26a02ec":"code","00cfb268":"code","a5c22566":"code","6eae162c":"code","d7adf1d3":"markdown","f1010895":"markdown","1c579b3b":"markdown","867df80d":"markdown","27d33013":"markdown"},"source":{"ce132483":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8f2541e":"pd.pandas.set_option('display.max_columns',None)","db7e2c8b":"dataset=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\n\n## print shape of dataset with rows and columns\nprint(dataset.shape)","9441dedf":"## print the top5 records\ndataset.head()","51e7a345":"## Here we will check the percentage of nan values present in each feature\n## 1 -step make the list of features which has missing values\nfeatures_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n## 2- step print the feature name and the percentage of missing values\n\nfor feature in features_with_na:\n    print(feature, np.round(dataset[feature].isnull().mean(), 4),  ' % missing values')","1b61c101":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfor feature in features_with_na:\n    data = dataset.copy()\n    \n    # let's make a variable that indicates 1 if the observation was missing or zero otherwise\n    data[feature] = np.where(data[feature].isnull(), 1, 0)\n    \n    # let's calculate the mean SalePrice where the information is missing or present\n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['red','green','orange','cyan'])\n    plt.title(feature)\n    plt.show()","5059a614":"print(\"Id of Houses {}\".format(len(dataset.Id)))","f3a5808e":"numerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\n\nprint('Number of numerical variables: ', len(numerical_features))\n\n# visualise the numerical variables\ndataset[numerical_features].head()","a6ccd004":"# list of variables that contain year information\nyear_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","05f3f623":"# let's explore the content of these year variables\nfor feature in year_feature:\n    print(feature, dataset[feature].unique())","5073c9c1":"## Lets analyze the Temporal Datetime Variables\n## We will check whether there is a relation between year the house is sold and the sales price\n\ndataset.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","0f36e62e":"year_feature","e0da655d":"## Here we will compare the difference between All years feature with SalePrice\n\nfor feature in year_feature:\n    if feature!='YrSold':\n        data=dataset.copy()\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()\n","af566db6":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature=[feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))\n","a6e7a2fe":"discrete_feature","bdd2bbaa":"\ndataset[discrete_feature].head()","cbb9b0cc":"\n## Lets Find the realtionship between them and Sale PRice\n\nfor feature in discrete_feature:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['red','green','pink','blue','orange','brown','cyan','violet'])\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","98fc2c53":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","ed6d562f":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","23b21b30":"## We will be using logarithmic transformation\n\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data['SalePrice']=np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalesPrice')\n        plt.title(feature)\n        plt.show()","4b0a6698":"for feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","55a184f5":"categorical_features=[feature for feature in dataset.columns if data[feature].dtypes=='O']\ncategorical_features","f40cf3fc":"dataset[categorical_features].head()","fad9901d":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(dataset[feature].unique())))","05c85805":"## Find out the relationship between categorical variable and dependent feature SalesPrice\nfor feature in categorical_features:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['red','green','pink','blue','orange','brown','cyan','violet'])\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","5ae2ddee":"## Always remember there way always be a chance of data leakage so we need to split the data first and then apply feature\n## Engineering\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(dataset,dataset['SalePrice'],test_size=0.1,random_state=0)\n","71eaf1dd":"X_train.shape, X_test.shape","ec2cdf91":"## Let us capture all the nan values\n## First lets handle Categorical features which are missing\nfeatures_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\n\nfor feature in features_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","98fbab77":"## Replace missing value with a new label\ndef replace_cat_feature(dataset,features_nan):\n    data=dataset.copy()\n    data[features_nan]=data[features_nan].fillna('Missing')\n    return data\n\ndataset=replace_cat_feature(dataset,features_nan)\n\ndataset[features_nan].isnull().sum()","fcbc7522":"dataset[features_nan].head()","420b8ef4":"numerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n\n## We will print the numerical nan variables and percentage of missing values\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))","c67d2da5":"for feature in numerical_with_nan:\n    median=dataset[feature].median()\n    dataset[feature+'_nan']=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median,inplace=True)\n\ndataset[numerical_with_nan].isnull().sum()","65036415":"dataset.head(20)","81bd295e":"year_feature","08d309fc":"\nfor feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    dataset[feature]=dataset['YrSold']-dataset[feature]","e99411d9":"dataset.head()","f5186e7f":"\ndataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","77848afd":"dataset.head()","6c2c826f":"skewed=['LotFrontage','LotArea','1stFlrSF','GrLivArea','SalePrice']\ndataset[skewed].head()","a26a02ec":"for feature in skewed:\n    dataset[feature]=np.log(dataset[feature])\n\ndataset[skewed].head()","00cfb268":"cat_fea=[feature for feature in dataset.columns if dataset[feature].dtypes=='O']\ncat_fea","a5c22566":"for feature in cat_fea:\n    temp=dataset.groupby(feature)['SalePrice'].count()\/len(dataset)\n    temp_df=temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')","6eae162c":"dataset[cat_fea].head(50)","d7adf1d3":"**Numerical Variables**","f1010895":"**Handle rare catagarical feature**","1c579b3b":"**Check how many numericals features have NAN values**","867df80d":"**Access % of every catagrical feature**\n# It is little bit of tricky","27d33013":"**Replace numerical feature's NAN values**"}}