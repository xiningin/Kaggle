{"cell_type":{"73d244ab":"code","2211fc42":"code","2b3d0b1b":"code","ba9cfe79":"code","4368dd51":"code","27222f4f":"code","9629cd2b":"code","358a11b5":"code","8abbf995":"code","71ade78f":"code","038c7311":"code","e6b660c5":"code","8384da75":"code","f5f7733e":"code","2e2a55ac":"code","3910dcb7":"code","2607f23f":"code","402a9aa3":"code","a50dd69c":"code","eefe1f3f":"code","c0e0bd91":"code","8cb8faca":"code","c96cace2":"code","07e4993b":"code","744a343e":"code","4f3cadd1":"code","26766fe1":"code","79041013":"code","ccbd5a0b":"code","82dd4751":"code","ec55e895":"code","d081b0bc":"code","06285653":"code","bc141187":"code","84b5fff2":"code","235b9ea2":"code","c093198c":"code","0c92b093":"code","06325f97":"code","b55fb4b2":"code","fd75c820":"code","77753c20":"code","06b39eae":"code","e93fc8a6":"code","2855eed6":"code","2a104fce":"code","6521d996":"code","d0aca092":"code","64f4e02f":"code","f864aff0":"code","581ff277":"code","fbc61c8b":"code","07a875bf":"code","21a79f31":"code","1dfe1c50":"code","7885bee9":"code","fc493d4d":"code","c6de5eb0":"code","af9e144e":"code","afcd3f5e":"code","e395d828":"code","ec0e79c6":"code","267ad57d":"code","94c655bf":"code","ee30eb00":"code","c19d605b":"code","45b93ac9":"code","26dd43be":"code","8d38b211":"markdown","3198cbe9":"markdown","a55c435a":"markdown","e58888e8":"markdown","c5f91ce2":"markdown","13840cb9":"markdown","ade351f6":"markdown","59e3c638":"markdown","3d8d8f71":"markdown"},"source":{"73d244ab":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('whitegrid')\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import accuracy_score","2211fc42":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","2b3d0b1b":"df_train.head()","ba9cfe79":"df_test.head()","4368dd51":"# Count the number of rows and columns in the dataset\nprint(\"Train Data Shape : \", df_train.shape)\nprint(\"Train Data Shape : \", df_test.shape)","27222f4f":"# Get statistics\ndf_train.describe()","9629cd2b":"df_test.describe()","358a11b5":"# Get a count of the number of survivors\ndf_train['Survived'].value_counts()","8abbf995":"# Count of Survivors\nsns.countplot(df_train['Survived'],  palette=['#fc0303',\"#030efc\"])\nplt.show()","71ade78f":"sns.countplot(df_train['Sex'], hue=df_train['Survived'], palette=['#fc0303',\"#030efc\"])\nplt.show()","038c7311":"sns.countplot(df_train['Pclass'], hue=df_train['Survived'], palette=['#fc0303',\"#030efc\"])\nplt.show()","e6b660c5":"sns.countplot(df_train['SibSp'], hue=df_train['Survived'], palette=['#fc0303',\"#030efc\"])\nplt.show()","8384da75":"sns.countplot(df_train['Parch'], hue=df_train['Survived'], palette=['#fc0303',\"#030efc\"])\nplt.show()","f5f7733e":"sns.countplot(df_train['Embarked'], hue=df_train['Survived'], palette=['#fc0303',\"#030efc\"])\nplt.show()","2e2a55ac":"# Survival rate by sex\ndf_train.groupby('Sex')[['Survived']].mean()","3910dcb7":"# Survival rate by sex and class\ndf_train.pivot_table('Survived', index='Sex', columns='Pclass')","2607f23f":"# Plot survival rate of each class\nsns.barplot(x=df_train['Pclass'], y=df_train['Survived'])\nplt.show()","402a9aa3":"# Survival rate by sex, age and class\nage = pd.cut(df_train['Age'], [0,18,80])\ndf_train.pivot_table('Survived', ['Sex', age], 'Pclass')","a50dd69c":"# Plot the prices paid of each class \nplt.scatter(df_train['Fare'], df_train['Pclass'], color='blue', label='Passenger Paid')\nplt.ylabel('Class')\nplt.xlabel('Price \/ Fare')\nplt.yticks(np.arange(min(df_train['Pclass']), max(df_train['Pclass'])+1, 1))\nplt.title('Price of each class')\nplt.legend()\nplt.show()","eefe1f3f":"# Count the null vlaues in each column\nfig = plt.figure(figsize=(12,6))\nplt.title('Training Datset')\nsns.heatmap(df_train.isnull(),yticklabels=False,cmap='summer')\nprint(\"Count of Null Values : \\n\\n\" ,df_train.isna().sum(), \"\\n\")","c0e0bd91":"# Check the values in each column and get a count\nfor val in df_train:\n    print(df_train[val].value_counts())\n    print()","8cb8faca":"titles=set()\nfor name in df_train['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","c96cace2":"titles_dict={'Mrs':'Mrs','Major':'Other','Master':'Master','Lady':'Other','Mlle':'Miss','Dr':'Other','Col':'Other','Capt':'Other','Don':'Other','the Countess':'Other','Mme':'Mrs','Miss':'Miss','Jonkheer':'Other','Rev':'Other','Sir':'Other','Ms':'Miss','Mr':'Mr'}","07e4993b":"df_train['Title'] = df_train['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\ndf_train['Title'] = df_train.Title.map(titles_dict)\ndf_train.head()","744a343e":"df1=df_train.drop(['Name','Ticket','Cabin','PassengerId'], axis=1)\ndf1.head()","4f3cadd1":"# Encording categorical features\ndf1.Sex=df1.Sex.map({'female':0, 'male':1})\ndf1.Title=df1.Title.map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5})\ndf1.Embarked=df1.Embarked.map({'S':0, 'C':1, 'Q':2,'nan':'NaN'})","26766fe1":"df1.head()","79041013":"df_train.Title.value_counts()","ccbd5a0b":"# Handling NaN values\nmean_men=df1[df1['Sex']==0]['Age'].mean()\nmean_female=df1[df1['Sex']==1]['Age'].mean()","82dd4751":"df1.loc[(df1.Age.isnull())&(df1['Sex']==1),'Age']=mean_female\ndf1.loc[(df1.Age.isnull())&(df1['Sex']==0),'Age']=mean_men","ec55e895":"df1.dropna(inplace=True)","d081b0bc":"df1.isnull().sum()","06285653":"df1.Age=(df1.Age-min(df1.Age))\/(max(df1.Age)-min(df1.Age))\ndf1.Fare=(df1.Fare-min(df1.Fare))\/(max(df1.Fare)-min(df1.Fare))","bc141187":"df1.head()","84b5fff2":"# Split the data into independent 'X' and dependent 'Y' variables\nX = df1.drop(['Survived'],axis=1)\ny = df1.Survived","235b9ea2":"# Split dataset into 80% training and 20% testing\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=0, stratify=df1.Survived)","c093198c":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlog = LogisticRegression(random_state=0)\nlog.fit(x_train, y_train)\ny_pred1 = log.predict(x_test)\n\n#KNeighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\nknn.fit(x_train, y_train)\ny_pred2 = knn.predict(x_test)\n    \n#SVC (Linear Kernel)\nfrom sklearn.svm import SVC\nsvc_lin = SVC(kernel='linear', random_state=0, probability=True)\nsvc_lin.fit(x_train, y_train)\ny_pred3 = svc_lin.predict(x_test)\n    \n#SVC (RBF Kernel)\nfrom sklearn.svm import SVC\nsvc_rbf = SVC(kernel='rbf', random_state=0, probability=True)\nsvc_rbf.fit(x_train, y_train)\ny_pred4 = svc_rbf.predict(x_test)\n    \n#GaussianNB\nfrom sklearn.naive_bayes import GaussianNB\ngauss = GaussianNB()\ngauss.fit(x_train, y_train)\ny_pred5 = gauss.predict(x_test)\n    \n#Desicion Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier(criterion='entropy', random_state=0)\ndtc.fit(x_train, y_train)\ny_pred6 = dtc.predict(x_test)\n\n#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=30, criterion='entropy', random_state=0)\nrfc.fit(x_train, y_train)\ny_pred7 = rfc.predict(x_test)\n \n#Multi-Layer Perceptron \nfrom sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(random_state=1, max_iter=500)\nmlp.fit(x_train, y_train)\ny_pred8 = mlp.predict(x_test)\n    \n#Print training accuracy for each model\nprint('[1] Logistic Regression Training Accuracy : ', log.score(x_train, y_train))\nprint('[2] KNN Training Accuracy : ', knn.score(x_train, y_train))\nprint('[3] SVC Linear Training Accuracy : ', svc_lin.score(x_train, y_train))\nprint('[4] SVC RBF Training Accuracy : ', svc_rbf.score(x_train, y_train))\nprint('[5] Gaussian NB Regression Training Accuracy : ', gauss.score(x_train, y_train))\nprint('[6] Desicion Tree Training Accuracy : ', dtc.score(x_train, y_train))\nprint('[7] Random Forest Training Accuracy : ', rfc.score(x_train, y_train))\nprint('[8] Multi-Layer Perceptron Training Accuracy : ', mlp.score(x_train, y_train))","0c92b093":"print(\"Logistic Regression : \\n \\n\", classification_report(y_test, y_pred1),\"\\n\")\nprint(\"KNeighbors Classifier : \\n \\n\", classification_report(y_test, y_pred2),\"\\n\")\nprint(\"SVC (Linear) : \\n \\n\", classification_report(y_test, y_pred3),\"\\n\")\nprint(\"SVC (RBF) : \\n \\n\", classification_report(y_test, y_pred4),\"\\n\")\nprint(\"Gaussian NB : \\n \\n\", classification_report(y_test, y_pred5),\"\\n\")\nprint(\"Desicion Tree : \\n \\n\", classification_report(y_test, y_pred6),\"\\n\")\nprint(\"Random Forest : \\n \\n\", classification_report(y_test, y_pred7),\"\\n\")\nprint(\"Multi-Layer Perceptron Classifier : \\n \\n\", classification_report(y_test, y_pred8),\"\\n\")","06325f97":"logreg_cm = confusion_matrix(y_test, y_pred1)  # Logistic Regression\nknncla_cm = confusion_matrix(y_test, y_pred2)  # KNN\nsvclin_cm = confusion_matrix(y_test, y_pred3)  # SVC (linear)\nsvcrbf_cm = confusion_matrix(y_test, y_pred4)   # SVC (RBF)\ngauss_cm = confusion_matrix(y_test, y_pred5)   # GaussianNB\ndtc_cm = confusion_matrix(y_test, y_pred6)   # Desicion Tree\nrfc_cm = confusion_matrix(y_test, y_pred7)   # Random Forest\nxgb_cm = confusion_matrix(y_test, y_pred8)   # MLP\n\n\nfig = plt.figure(figsize=(19,14))\nax1 = fig.add_subplot(3, 4, 1) \nax1.set_title('Logistic Regression Classifier')\nax2 = fig.add_subplot(3, 4, 2) \nax2.set_title('KNN Classifier')\nax3 = fig.add_subplot(3, 4, 3)\nax3.set_title('SVC (Linear) Classifier')\nax4 = fig.add_subplot(3, 4, 4)\nax4.set_title('SVC (RBF) Classifier')\nax5 = fig.add_subplot(3, 4, 5)\nax5.set_title('Gaussian NB Classifier')\nax6 = fig.add_subplot(3, 4, 6)\nax6.set_title('Decision Tree Classifier')\nax7 = fig.add_subplot(3, 4, 7)\nax7.set_title('Random Forest Classifier')\nax8 = fig.add_subplot(3, 4, 8)\nax8.set_title('MLP Classifier')\n\n\nsns.heatmap(data=logreg_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False, ax=ax1)\nsns.heatmap(data=knncla_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False, ax=ax2)  \nsns.heatmap(data=svclin_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False,ax=ax3)\nsns.heatmap(data=svcrbf_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False,ax=ax4)\nsns.heatmap(data=gauss_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False,ax=ax5)\nsns.heatmap(data=dtc_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False,ax=ax6)\nsns.heatmap(data=rfc_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False,ax=ax7)\nsns.heatmap(data=xgb_cm, annot=True, linewidth=0.7, linecolor='black',cmap=\"YlGnBu\" ,fmt='g', cbar=False,ax=ax8)\n\nax1.set_xlabel('Predicted Labels')\nax1.set_ylabel('True Labels')\nax1.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax1.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nax2.set_xlabel('Predicted Labels')\nax2.set_ylabel('True Labels')\nax2.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax2.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nax3.set_xlabel('Predicted Labels')\nax3.set_ylabel('True Labels')\nax3.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax3.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nax4.set_xlabel('Predicted Labels')\nax4.set_ylabel('True Labels')\nax4.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax4.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nax5.set_xlabel('Predicted Labels')\nax5.set_ylabel('True Labels')\nax5.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax5.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\n\nax6.set_xlabel('Predicted Labels')\nax6.set_ylabel('True Labels')\nax6.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax6.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nax7.set_xlabel('Predicted Labels')\nax7.set_ylabel('True Labels')\nax7.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax7.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nax8.set_xlabel('Predicted Labels')\nax8.set_ylabel('True Labels')\nax8.xaxis.set_ticklabels(['Not Survived', 'Survived'])\nax8.yaxis.set_ticklabels(['Not Survived', 'Survived'])\n\nplt.show()","b55fb4b2":"fig = plt.figure(figsize=(12,6))\n\n# Logistic Regression \nY_predict1_proba = log.predict_proba(x_test)\nY_predict1_proba = Y_predict1_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict1_proba)\nplt.subplot(341)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve Logistic Regression')\n\n# KNN \nY_predict2_proba = knn.predict_proba(x_test)\nY_predict2_proba = Y_predict2_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict2_proba)\nplt.subplot(342)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve KNN')\n\n# SVC (linear)\nY_predict3_proba = svc_lin.predict_proba(x_test)\nY_predict3_proba = Y_predict3_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict3_proba)\nplt.subplot(343)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve SVC (linear)')\n\n# SVC (RBF)\nY_predict4_proba = svc_rbf.predict_proba(x_test)\nY_predict4_proba = Y_predict4_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict4_proba)\nplt.subplot(344)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve SVC (RBF)')\n\n# Gaussian NB\nY_predict5_proba = gauss.predict_proba(x_test)\nY_predict5_proba = Y_predict5_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict5_proba)\nplt.subplot(345)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve Gassian NB')\n\n# Desicion Tree \nY_predict6_proba = dtc.predict_proba(x_test)\nY_predict6_proba = Y_predict6_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict6_proba)\nplt.subplot(346)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve Desicion Tree')\nplt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45)\n\n# Random Forest\nY_predict7_proba = rfc.predict_proba(x_test)\nY_predict7_proba = Y_predict7_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict7_proba)\nplt.subplot(347)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve Random Forest')\nplt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45)\n\n# MLP\nY_predict8_proba = mlp.predict_proba(x_test)\nY_predict8_proba = Y_predict8_proba[:, 1]\nfpr, tpr, thresholds = roc_curve(y_test, Y_predict8_proba)\nplt.subplot(348)\nplt.plot([0,1],[0,1],'k--', color='gray')\nplt.plot(fpr,tpr, label='ANN', color='r')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.title('ROC Curve MLP')\nplt.subplots_adjust(top=2, bottom=0.08, left=0.10, right=1.4, hspace=0.45, wspace=0.45)\n\nplt.show()","fd75c820":"MyList = []\n\nscore_1 = accuracy_score(y_test, y_pred1) # Logistic Regression\nMyList.append(score_1)\nscore_2 = accuracy_score(y_test, y_pred2) # KNN\nMyList.append(score_2)\nscore_3 = accuracy_score(y_test, y_pred3) # SVC (linear)\nMyList.append(score_3)\nscore_4 = accuracy_score(y_test, y_pred4) # SVC (RBF)\nMyList.append(score_4)\nscore_5 = accuracy_score(y_test, y_pred5) # Gaussian NB\nMyList.append(score_5)\nscore_6 = accuracy_score(y_test, y_pred6) # Decision Tree\nMyList.append(score_6)\nscore_7 = accuracy_score(y_test, y_pred7) # Random Forest\nMyList.append(score_7)\nscore_8 = accuracy_score(y_test, y_pred8) # MLP\nMyList.append(score_8)\n\nModels_Names =[\"Logistic Regression\", \"KNN\", \"SVC_Linear\", \"SVC_RBF\", \"Gaussian NB\", \"Decision Tree\", \"Random Forest\", \"MLP\"]\n\nplt.rcParams['figure.figsize']=20,8 \n\nax = sns.barplot(x=Models_Names, y=MyList, palette = \"cubehelix\", saturation =1.5)\n\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"Accuracy (%)\", fontsize = 20)\nplt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","77753c20":"df_test.info()","06b39eae":"df_test.isnull().sum()","e93fc8a6":"df_test.head()","2855eed6":"titles= set()\nfor name in df_test['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","2a104fce":"titles_dict","6521d996":"df_test['Title'] = df_test['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\ndf_test['Title'] = df_test.Title.map(titles_dict)\ndf_test.head()","d0aca092":"df2 = df_test.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)","64f4e02f":"df2.Sex=df2.Sex.map({'female':0, 'male':1})\ndf2.Embarked=df2.Embarked.map({'S':0, 'C':1, 'Q':2,'nan':'Nan'})\ndf2.Title=df2.Title.map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5})","f864aff0":"df2.head()","581ff277":"df2.isnull().sum()","fbc61c8b":"mean_female=df2[df2['Sex']==1]['Age'].mean()\nmean_men=df2[df2['Sex']==0]['Age'].mean()","07a875bf":"df2.loc[(df2.Age.isnull())&(df2['Sex']==1),'Age']=mean_female\ndf2.loc[(df2.Age.isnull())&(df2['Sex']==0),'Age']=mean_men","21a79f31":"df2.isnull().sum()","1dfe1c50":"df2['Fare']=df2['Fare'].fillna(df2['Fare'].mean())","7885bee9":"df2.isnull().sum()","fc493d4d":"df2[df2.Title.isnull()]","c6de5eb0":"df2['Title']=df2.Title.fillna(3)","af9e144e":"df2.isnull().sum()","afcd3f5e":"df2.head()","e395d828":"df2['Age']=(df2.Age-min(df2.Age))\/(max(df2.Age)-min(df2.Age))","ec0e79c6":"df2['Fare']=(df2.Fare-min(df2.Fare))\/(max(df2.Fare)-min(df2.Fare))","267ad57d":"df2.head()","94c655bf":"prediction = mlp.predict(df2)","ee30eb00":"prediction","c19d605b":"submit=pd.DataFrame({'PassengerId':df_test['PassengerId'],'Survived':prediction})\nsubmit.to_csv('.\/submission.csv',index=False)","45b93ac9":"pred_df = pd.read_csv('.\/submission.csv')\npred_df.head()","26dd43be":"sns.countplot(x='Survived', data=pred_df ,palette=['#fc0303',\"#030efc\"])\nplt.show()","8d38b211":"### Load Dependencies","3198cbe9":"**So we see that MLP achieve better results among all of the models**","a55c435a":"If we look at Age, the first thing that we'll notice is the count on age is 714, and so that's not 891 like we would expect which is telling us that the age column is missing a few values.","e58888e8":"### Data preparation & Model building","c5f91ce2":"### Data Preprocessing & Visualization","13840cb9":"### Submission","ade351f6":"# Titanic Survival Prediction Using ML","59e3c638":"### Load Dataset","3d8d8f71":"### Model Evaluation"}}