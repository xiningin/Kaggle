{"cell_type":{"ead2d2f1":"code","6325414e":"code","8cd20d59":"code","e99f69f7":"code","1eed7589":"code","9f673c5a":"code","c8fde6b6":"code","1fdad192":"code","bc8fccd0":"code","6d83bf46":"code","0e93813a":"code","df32f7eb":"code","98609b5e":"code","8e9d31d3":"code","27103f92":"code","2c3c0451":"code","999c658e":"code","b7a70549":"code","28b90c97":"code","a0748e4c":"code","4841189c":"code","a917bff4":"markdown","e72e9679":"markdown","c1c8dc01":"markdown","84642ce5":"markdown","392ffb03":"markdown","a7cf8db9":"markdown","aef1483f":"markdown","fd142484":"markdown","9ba8b361":"markdown","9e956399":"markdown","956cbcda":"markdown","6471112a":"markdown","3f23618a":"markdown","4f6850fa":"markdown","520fd1a5":"markdown"},"source":{"ead2d2f1":"# Base directory\n#base_dir = r'insert the folder directory where you unzipped the files'\n\n# Directory to import cleaned and transformed dataframes for modelling\nimport_dir = r'..\/input\/shortterm-electricity-load-forecasting-panama\/'\n\n# Directory to save models and optimization studies\nmodels_dir = r'\/kaggle\/working\/'","6325414e":"pip install xlrd==1.2.0","8cd20d59":"pip install scikit-plot","e99f69f7":"pip install optuna==2.3.0","1eed7589":"pip install plotly==4.14.1","9f673c5a":"import os\nimport glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom IPython import display\nimport plotly as plotly\n%matplotlib inline\n\nimport calendar\nimport datetime as dt\nfrom datetime import timedelta, date\nfrom pprint import pprint\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\nimport joblib\nimport optuna\nfrom optuna import Trial, visualization\nfrom optuna.samplers import TPESampler\n\nfrom scipy.stats import randint as sp_randint\nfrom time import time\nimport pickle\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# set random_state\nrandom_state = 123","c8fde6b6":"# set the working directory\nos.chdir(import_dir)\n\n# Add legend\nlegend_elements = [Patch(facecolor='#5D666D', label='Training weeks'),\n                   Patch(facecolor='#BFD630', label='Testing weeks')]\nfig, ax = plt.subplots(figsize=(20,1))\nax.legend(handles=legend_elements, loc='center')\nplt.axis('off')\nplt.show()\n# Display gif\ndisplay.Image(r'Animated_3D_plot.gif')","1fdad192":"# set the working directory\n# os.chdir(import_dir)\n\n# csv file with load forecast to improve (weekly pre-dispatch)\nfilename = 'weekly pre-dispatch forecast.csv'\n\n# Read the file and convert into \"pre_disp_df\" \npre_disp_df = pd.read_csv(filename)\n\n# set datetime as index\npre_disp_df.set_index('datetime', inplace=True)\n\n# converting the index as date\npre_disp_df.index = pd.to_datetime(pre_disp_df.index)\n\n# plot weekly pre-dispatch forecast (forecast to improve)\npre_disp_df.plot(figsize=(20,5), color='grey')\nplt.title('Pre-dispatch load forecast (forecast to improve)', fontsize=16)\nplt.ylabel('Load (MWh)', fontsize=16);","bc8fccd0":"# set the working directory\n# os.chdir(import_dir)\n\n# Import a dictionary with all the training dataframes\n# Use parameter sheet_name=None, from pd.read_excel\n# to return a dictionary of Dataframes, with the sheet_names as dictionary keys.\ntrain_dict = pd.read_excel(open('train_dataframes.xlsx', 'rb'), sheet_name = None, index_col=0)\n\n# Import a dictionary with all the testing dataframes\ntest_dict = pd.read_excel(open('test_dataframes.xlsx', 'rb'), sheet_name = None, index_col=0)","6d83bf46":"# Get the keys from 'test_dict' dictionary\n# keys are the same for both 'test_dict' and 'train_dict'\nkeys = list(test_dict.keys())\n\n# Show keys\nkeys","0e93813a":"# Plot the electricity load, just for the first training\/testing pair \n# notice the small gap between the two series, it's the 72 hours gap\ntrain_dict[keys[0]]['DEMAND'].plot(figsize=(20,5), label='training dataset')\ntest_dict[keys[0]]['DEMAND'].plot(figsize=(20,5), label='testing dataset')\nplt.ylabel('Load (MWh)', fontsize=16)\nplt.title('Load series for testing ' + keys[0],fontsize=16)\nplt.legend();","df32f7eb":"################################################################################\n# ------------------------- MAPE evaluation functions --------------------------\n################################################################################\n\n# Define a function to calculate WEEKLY Mean Absolute Percentage Error (MAPE)\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return round(np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100, 2)\n\n# Define a function to calculate HOURLY Mean Absolute Percentage Error (MAPE)\ndef H_mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    H_MAPE = (np.abs((y_true - y_pred) \/ y_true) * 100)\n    rounded_H_MAPE = [round(num, 1) for num in H_MAPE]\n    return rounded_H_MAPE","98609b5e":"################################################################################\n# ------------------ Time-based train and test splitting -----------------------\n################################################################################\n# Reference:\n# https:\/\/towardsdatascience.com\/time-based-cross-validation-d259b13d42b8\nimport pandas as pd\nimport datetime\nfrom datetime import datetime as dt\nfrom dateutil.relativedelta import *\n\nclass TimeBasedCV(object):\n    '''\n    Parameters \n    ----------\n    train_period: int\n        number of time units to include in each train set\n        default is 30\n    test_period: int\n        number of time units to include in each test set\n        default is 7\n    freq: string\n        frequency of input parameters. possible values are: days, months, years, weeks, hours, minutes, seconds\n        possible values designed to be used by dateutil.relativedelta class\n        deafault is days\n    '''\n    \n    \n    def __init__(self, train_period=30, test_period=7, freq='days'):\n        self.train_period = train_period\n        self.test_period = test_period\n        self.freq = freq\n\n        \n        \n    def split(self, data, validation_split_date=None, date_column='record_date', gap=0):\n        '''\n        Generate indices to split data into training and test set\n        \n        Parameters \n        ----------\n        data: pandas DataFrame\n            your data, contain one column for the record date \n        validation_split_date: datetime.date()\n            first date to perform the splitting on.\n            if not provided will set to be the minimum date in the data after the first training set\n        date_column: string, deafult='record_date'\n            date of each record\n        gap: int, default=0\n            for cases the test set does not come right after the train set,\n            *gap* days are left between train and test sets\n        \n        Returns \n        -------\n        train_index ,test_index: \n            list of tuples (train index, test index) similar to sklearn model selection\n        '''\n        \n        # check that date_column exist in the data:\n        try:\n            data[date_column]\n        except:\n            raise KeyError(date_column)\n                    \n        train_indices_list = []\n        test_indices_list = []\n\n        if validation_split_date==None:\n            validation_split_date = data[date_column].min().date() + eval('relativedelta('+self.freq+'=self.train_period)')\n        \n        start_train = validation_split_date - eval('relativedelta('+self.freq+'=self.train_period)')\n        end_train = start_train + eval('relativedelta('+self.freq+'=self.train_period'+'-gap)')\n        start_test = end_train + eval('relativedelta('+self.freq+'=gap)')\n        end_test = start_test + eval('relativedelta('+self.freq+'=self.test_period)')\n\n        while end_test < data[date_column].max().date():\n            # train indices:\n            cur_train_indices = list(data[(data[date_column].dt.date>=start_train) & \n                                     (data[date_column].dt.date<end_train)].index)\n\n            # test indices:\n            cur_test_indices = list(data[(data[date_column].dt.date>=start_test) &\n                                    (data[date_column].dt.date<end_test)].index)\n            \n            print(\"Train period:\",start_train,\"-\" , end_train, \", Test period\", start_test, \"-\", end_test,\n                  \"# train records\", len(cur_train_indices), \", # test records\", len(cur_test_indices))\n\n            train_indices_list.append(cur_train_indices)\n            test_indices_list.append(cur_test_indices)\n\n            # update dates:\n            start_train = start_train + eval('relativedelta('+self.freq+'=self.test_period)')\n            end_train = start_train + eval('relativedelta('+self.freq+'=self.train_period'+'-gap)')\n            start_test = end_train + eval('relativedelta('+self.freq+'=gap)')\n            end_test = start_test + eval('relativedelta('+self.freq+'=self.test_period)')\n\n        # mimic sklearn output  \n        index_output = [(train,test) for train,test in zip(train_indices_list,test_indices_list)]\n\n        self.n_splits = len(index_output)\n        \n        return index_output\n    \n    \n    def get_n_splits(self):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\n        Returns\n        -------\n        n_splits : int\n            Returns the number of splitting iterations in the cross-validator.\n        \"\"\"\n        return self.n_splits ","8e9d31d3":"################################################################################\n# ------------------- Plotting test and demand forecast  -----------------------\n################################################################################\n\ndef plot_test_forecast(y_test, y_pred_test, y_pre_disp):\n  # Calculate values to plot\n  delta_demand = y_test - y_pred_test\n  H_MAPE = H_mean_absolute_percentage_error(y_test, y_pred_test)\n\n  import matplotlib.pyplot\n  from matplotlib.ticker import MaxNLocator\n  import matplotlib.ticker\n  fig, (ax, bx) = plt.subplots(1,2, figsize=(20, 5))\n  matplotlib.rc('xtick', labelsize=12) \n  matplotlib.rc('ytick', labelsize=12) \n\n  # First plot\n  ax.plot(np.arange(1, 169, 1), y_test, c= 'green', label = 'Real Demand')\n  ax.plot(np.arange(1, 169, 1), y_pred_test, c= 'red', label = 'Demand Forecast')\n  ax.plot(np.arange(1, 169, 1), y_pre_disp, c= 'gray', linestyle='--', label = 'Pre-dispatch Forecast')\n  ax.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n  ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n  ax.set_xlabel('Hours of the week', fontsize = 12)\n  ax.set_ylabel('MWh', rotation=0, fontsize = 12, labelpad=20)\n  ax.set_title('Real demand vs Forecasts')\n    \n  # Second plot\n  bx.bar(np.arange(1, 169, 1), delta_demand, width=1.0, color = 'grey', label = 'Error')\n  bx.xaxis.set_major_locator(MaxNLocator(integer=True))\n  bx.set_xlabel('Hours of the week', fontsize = 12)\n  bx.set_ylabel('MWh', rotation=0, fontsize = 12, labelpad=5)\n  bx.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n  bx2 = bx.twinx()  # instantiate a second axes that shares the same x-axis\n  legend = ax.legend(loc='lower left', fontsize = 12)\n  bx.set_title('Forecast errors and MAPE')\n\n  # Calculate weekly MAPE to improve\n  MAPE2improve = mean_absolute_percentage_error(y_test, y_pre_disp)\n\n  color = 'tab:blue'\n  bx2.set_ylabel('MAPE', color=color, labelpad=20, rotation=0, fontsize = 12)\n  bx2.plot(np.arange(1, 169, 1), H_MAPE, color=color, label = 'Absolute Error (%)')\n  bx2.yaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(decimals=0))\n  bx2.tick_params(axis='y', labelcolor=color)\n  bx2.set_ylim(bottom=0)\n  plt.axhline(y=MAPE2improve, color='k', linestyle='--', label = str('Error cap (' + str(MAPE2improve)+'%)'))\n  legend = bx.legend(loc='upper left', fontsize = 12)\n  legend = bx2.legend(loc='upper right', fontsize = 12)\n\n  fig.tight_layout()\n  plt.show()","27103f92":"################################################################################\n# ------------------ Define a model inside a function --------------------------\n################################################################################\n# This function define the objective to optimize\n# This function uses: X (regressors), y (target), \n#   and time-series cross-validation index\n# This fuction returns the RMSE score for a trial\n# The estimator or pipeline is fixed and defined inside\ndef model_hyperparameter_search(trial):\n\n    # Define hyperparameter space\n    space = {\n            'n_neighbors'     : trial.suggest_int('n_neighbors', 3, 50, 2),\n            'n_jobs'          : -1\n            }\n    \n    # Define default regressor pipeline\n    reg = Pipeline([('scaler', MinMaxScaler()), \n                    ('estimator', KNeighborsRegressor(**space)\n                  )])\n    \n    # Define cross validation setting and evaluation metric\n    rmse_cv_score = round(cross_val_score(reg, X, y, \n                           scoring = 'neg_root_mean_squared_error',\n                           n_jobs = -1,\n                           cv = index_output).mean(), 3)\n    \n    return rmse_cv_score","2c3c0451":"################################################################################\n# ---------------------- Function to train a model --------------------------\n################################################################################\n# This function train a model\n# This function uses: X_Train, y_train\n# This fuction returns a trained and fitted model and the optimization study\n# The estimator or pipeline is fixed and defined inside\n\ndef train_model(data_for_modeling):\n    # -------------- Train the model using only the holidays data ---------------\n    # Create a study object setting the sampling and direction \n    # of the optimization process (maximize -RMSE with Bayesian GMM)\n    study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=random_state))\n    # Define the function to optimize, number of trials, execution time and processors to use\n    study.optimize(model_hyperparameter_search, n_trials=10, timeout=None, n_jobs=-1)\n    # Fit the estimator using the best hyperparameters\n    reg = Pipeline([('scaler', MinMaxScaler()), \n                    ('estimator', KNeighborsRegressor(**study.best_trial.params))])\n    \n    # ------------- Return trained model using only the holidays data -------------\n    X_train = data_for_modeling.set_index(['record_date']).drop(columns=['DEMAND'])\n    y_train = data_for_modeling['DEMAND']\n    return reg.fit(X_train, y_train), study","999c658e":"%%time\n################################################################################\n# -------------- Loop to optimize models for each testing week -----------------\n################################################################################\n\nfor key in keys[:1]: \n    # 1. -------------------- Define weekly data to use ---------------------\n    # Rename the training dataframe\n    train_df = train_dict[key]\n\n    # Select a single training and testing example, with the key name\n    # and separate the target variable 'DEMAND'\n    X_train = train_dict[key].drop(columns=['DEMAND'])\n    X_test = test_dict[key].drop(columns=['DEMAND'])\n    y_train = train_dict[key]['DEMAND']\n    y_test  = test_dict[key]['DEMAND']\n    \n    # Reconstruct the pandas objects rounding hourly the datetime index\n    # This cell is needed for some platforms\n    train_df = pd.DataFrame(data=train_df.values, index=pd.Series(train_df.index).dt.round(\"H\"), columns=train_df.columns)\n    X_train = pd.DataFrame(data=X_train.values, index=pd.Series(X_train.index).dt.round(\"H\"), columns=X_train.columns)\n    X_test = pd.DataFrame(data=X_test.values, index=pd.Series(X_test.index).dt.round(\"H\"), columns=X_test.columns)\n    y_train = pd.Series(data=y_train.values, index=pd.Series(y_train.index).dt.round(\"H\"), name=y_train.name)\n    y_test = pd.Series(data=y_test.values, index=pd.Series(y_test.index).dt.round(\"H\"), name=y_test.name)\n\n    # Filter the pre-dispatch forecast only for the testing week\n    y_pre_disp = pd.merge(y_test, pre_disp_df['load_forecast'], how='inner', left_index=True, right_index=True)['load_forecast']\n    \n    # 2. ----------------- Apply Time Based Cross Validation ----------------\n    # 2.1. --------------- Time Based Cross Validation \n    # validation starts 64 weeks (1.23 years) before the last training record\n    weeks_to_val = 64\n    hours_to_val = (weeks_to_val*168 + 168)\n    train_val_split  = train_df.index[(-hours_to_val)].strftime('%Y-%m-%d %H:%M:%S')\n    \n    # Create a Time Split Cross Validation object specifying \n    # 168 hours to test, this is a week for each CV fold\n    tscv = TimeBasedCV(train_period = 25032,  # hours \/ 149 weeks \/ 2.8 years\n                       test_period = 168,     # hours \/ 1 week\n                       freq = 'hours')\n\n    # Prepare dataframe before using TimeBasedCV\n    data_for_modeling = train_df.reset_index(level=0)\n    data_for_modeling.rename(columns={'datetime' : 'record_date'}, inplace=True)\n    data_for_modeling['record_date'] =  pd.to_datetime(data_for_modeling['record_date'], format='%Y\/%m\/%d %H:%M:%S')  \n    \n    # 2.2 --------------- Prepare data for modelling and Cross Validation indexes\n    # Set regressors dataframe 'X' and target 'y'\n    X = data_for_modeling.drop(columns=['DEMAND', 'record_date'], axis=1)\n    y = data_for_modeling['DEMAND']\n\n    # Define each Cross Validation Fold using TimeBased splitter\n    index_output = tscv.split(data_for_modeling, \n                          validation_split_date=dt.strptime(train_val_split, '%Y-%m-%d %H:%M:%S').date(),\n                          gap = 72) # this is a 3 days gap needed for planning the next week dispatch \n    \n    # 3. --------------- Modelling and optimizing hyperparameters ---------------\n    # Train model, and return the fitted model and its optimization study\n    generic_model, generic_model_study = train_model(data_for_modeling)\n  \n    # 4. --------------- Save the optimized and trained model in the selected folder -------\n    # set the working directory\n    os.chdir(models_dir)\n\n    # save the Optuna study\n    filename = 'KNN_study_'+ str(key) + '.pkl'\n    joblib.dump(generic_model_study, filename)\n    del filename\n    \n    # save the model\n    filename = 'KNN_'+ str(key) + '.sav'\n    pickle.dump(generic_model, open(filename, 'wb'))\n    del filename","b7a70549":"# Select a testing week, by it's key\nweek_to_forecast = keys[0]\n\n# Import saved model\nwith open('KNN_'+ week_to_forecast + '.sav', 'rb') as file:\n    generic_model = pickle.load(file)\n    \n# Import saved Optuna study\ngeneric_model_study = joblib.load('KNN_study_'+ week_to_forecast + '.pkl')","28b90c97":"%%time\n# ------- Forecast with generic model ---------\ny_pred_train = generic_model.predict(X_train)\ny_pred_test = generic_model.predict(X_test)\n\n# Calculate weekly MAPE and RMSE to improve\nMAPE2improve = mean_absolute_percentage_error(y_test, y_pre_disp)\nRMSE2improve = round(np.sqrt(mean_squared_error(y_test, y_pre_disp)),2)\n\n# Compare average training score with average test score\nRMSE_train_score = round(np.sqrt(mean_squared_error(y_train, y_pred_train)),2)\nRMSE_test_score  = round(np.sqrt(mean_squared_error(y_test, y_pred_test)),2)\nMAPE_train_score = round(mean_absolute_percentage_error(y_train, y_pred_train),2)\nMAPE_test_score  = round(mean_absolute_percentage_error(y_test, y_pred_test),2)\n\nprint('Train RMSE:', RMSE_train_score, 'MWh')\nprint('Test  RMSE:', RMSE_test_score, 'MWh')\nprint('Train MAPE:', MAPE_train_score, '%')\nprint('Test  MAPE:', MAPE_test_score, '%')\nprint('')\nprint('RMSE to improve:', RMSE2improve, 'MWh')\nprint('MAPE to improve:', MAPE2improve, '%')\n\n# Show hourly forecast and errors\nplot_test_forecast(y_test, y_pred_test, y_pre_disp)","a0748e4c":"# Visualize the optimization progress along the trials\noptuna.visualization.plot_optimization_history(generic_model_study)","4841189c":"# Visualize the optimization progress by parameter\noptuna.visualization.plot_slice(generic_model_study)","a917bff4":"# 4.0 Import the model and test it","e72e9679":"## User Input: Introduce your directories","c1c8dc01":"The continious dataset was split into train and test datasets, keeping the cronological order of the records, this is, keeping records sorted by 'datetime', leaving always the **last week for testing the model and the rest, older data for training it.** <br>\n\nBased on this logic, there will be 14 pairs of train\/test datasets. 12 pairs with the testing week on each month of the last year of records, before the quarentine started, and 2 more testing weeks after the quarentine started. As a fact, the lockdown in Panama started on Wednesday March 25th of 2020 (week 12 - 2020). <br>\n\nThe following table shows more information about the train\/test splits: <br>\n\n| Testing week number| Testing week name | Datetime split |\n| -: | -: | -: |\n|                   1 | Week 15, Apr 2019 | 2019-04-13 01:00:00 |\n|                   2 | Week 21, May 2019 | 2019-05-25 01:00:00 |\n|                   3 | Week 24, Jun 2019 | 2019-06-15 01:00:00 |\n|                   4 | Week 29, Jul 2019 | 2019-07-20 01:00:00 |\n|                   5 | Week 33, Aug 2019 | 2019-08-17 01:00:00 |\n|                   6 | Week 37, Sep 2019 | 2019-09-14 01:00:00 |\n|                   7 | Week 41, Oct 2019 | 2019-10-12 01:00:00 |\n|                   8 | Week 44, Nov 2019 | 2019-11-02 01:00:00 |\n|                   9 | Week 51, Dec 2019 | 2019-12-21 01:00:00 |\n|                  10 | Week 01, Jan 2020 | 2020-01-04 01:00:00 |\n|                  11 | Week 06, Feb 2020 | 2020-02-08 01:00:00 |\n|                  12 | Week 10, Mar 2020 | 2020-03-07 01:00:00 |\n|                  13 | Week 20, May 2020 | 2020-05-16 01:00:00 |\n|                  14 | Week 24, Jun 2020 | 2020-06-13 01:00:00 |","84642ce5":"# 2.0 Define functions","392ffb03":"# Short-term electricity load forecasting \n### (Panama case study)","a7cf8db9":"#### Context\nThese case study are framed on predicting the short-term electricity, this forecasting problem is known in the research field as short-term load forecasting (STLF). These datasets address the STLF problem for the Panama power system, in which the forecasting horizon is one week, with hourly steps, which is a total of 168 hours. These datasets are useful to train and test forecasting models and compare their results with the grid operator official forecast ([take a look at real-time electricity load](https:\/\/sitr.cnd.com.pa\/m\/pub\/sin.html)). The datasets include historical load, a vast set of weather variables, holidays, and historical load weekly forecast features.\n\n#### Objectives\nThe main objectives around these datasets are:\n1. Evaluate the grid operator official forecasts (weekly pre-dispatch forecast) against the real load, on weekly basis.\n2. Develop, train and test forecasting models to improve the operator official weekly forecasts (168 hours), in different scenarios.\n\n#### Considerations to compare results\nThe following considerations should be kept to compare forecasting results with the weekly pre-dispatch forecast:\n\n1. Saturday is the first day of each weekly forecast; for instance, Friday is the last day.\n2. The first full-week starting on Saturday should be considered as the first week of the year, to number the weeks.\n3. A 72 hours gap of unseen records should be considered before the first day to forecast. In other words, next week forecast should be done with records until each Tuesday last hour.\n4. Make sure to train and test keeping the chronological order of records.","aef1483f":"The first training\/testing week pair is selected, with its corresponding trained and fitted model.","fd142484":"Notice keys list is contrained to its first element **keys[:1]** to run a fast demo <br>\nselect the whole list 'keys' to train 14 models","9ba8b361":"# 3.0 Optimize models for each testing week","9e956399":"## Install packages","956cbcda":"## Import packages","6471112a":"Lastly, take a look at the imported Optuna study to see the optimization progress and the hyperparameters impact. <br>\nNotice that the objective value is **-RMSE**, and the optimization is trying to maximize this value, as defined in *model_hyperparameter_search* function.","3f23618a":"# 1.0 Import datasets","4f6850fa":"Now, let's forecast using the trained model, evaluate the results and compare with the pre-dispatch forecast for this testing week.","520fd1a5":"## Animation of the 14 suggested training-testing pairs along the horizon "}}