{"cell_type":{"8e8fa5e2":"code","830fe1a8":"code","6e5c0f32":"code","08214d79":"code","6329c44a":"code","26a85b9e":"code","56ec729a":"code","b507e09c":"code","f4d06b93":"code","1c7ede46":"code","523d73a5":"code","9fe54736":"code","cfdcdf92":"code","98843755":"code","b452a4e8":"code","32ea6331":"code","3c956d8c":"code","4e5838d9":"code","869c85be":"code","07adc063":"code","99aa9a40":"code","38cb0c41":"markdown","d54af524":"markdown","0dedf38a":"markdown","2e15e8cc":"markdown","d02fcc9e":"markdown"},"source":{"8e8fa5e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.feature_selection import RFE\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","830fe1a8":"dataset = pd.read_csv(\"..\/input\/train.csv\", names=['Store','Dept','Date','weeklySales','isHoliday'],sep=',', header=0)\nfeatures = pd.read_csv(\"..\/input\/features.csv\",sep=',', header=0,\n                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\nstores = pd.read_csv(\"..\/input\/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\ndataset = dataset.merge(stores, how='left').merge(features, how='left')\n\n# dataset[\"nextWeekHoliday\"] = dataset[\"isHoliday\"].shift(-1).fillna(False)\n# dataset[\"next2WeekHoliday\"] = dataset[\"isHoliday\"].shift(-2).fillna(False)\ndataset","6e5c0f32":"def scatter(dataset, column):\n    plt.figure()\n    plt.scatter(dataset[column] , dataset['weeklySales'])\n    plt.ylabel('weeklySales')\n    plt.xlabel(column)","08214d79":"scatter(dataset, 'Fuel_Price')\nscatter(dataset, 'Size')\nscatter(dataset, 'CPI')\nscatter(dataset, 'Type')\nscatter(dataset, 'isHoliday')\nscatter(dataset, 'Unemployment')\nscatter(dataset, 'Temperature')\nscatter(dataset, 'Store')\nscatter(dataset, 'Dept')","6329c44a":"fig = plt.figure(figsize=(18, 14))\ncorr = dataset.corr()\nc = plt.pcolor(corr)\nplt.yticks(np.arange(0.5, len(corr.index), 1), corr.index)\nplt.xticks(np.arange(0.5, len(corr.columns), 1), corr.columns)\nfig.colorbar(c)","26a85b9e":"sns.pairplot(dataset, vars=['weeklySales', 'Fuel_Price', 'Size', 'CPI', 'Dept', 'Temperature', 'Unemployment'])","56ec729a":"sns.pairplot(dataset.fillna(0), vars=['weeklySales', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'])","b507e09c":"for name, group in dataset.groupby([\"Store\", \"Dept\"]):\n    plt.title(name)\n    plt.scatter(range(len(group)), group[\"weeklySales\"])\n    plt.show()\n    break","f4d06b93":"dataset = pd.get_dummies(dataset, columns=[\"Type\"])\ndataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\ndataset['Month'] = pd.to_datetime(dataset['Date']).dt.month\ndataset = dataset.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\ndataset","1c7ede46":"def knn():\n    knn = KNeighborsRegressor(n_neighbors=10)\n    return knn\n\ndef extraTreesRegressor():\n    clf = ExtraTreesRegressor(n_estimators=100,max_features='auto', verbose=1, n_jobs=1)\n    return clf\n\ndef randomForestRegressor():\n    clf = RandomForestRegressor(n_estimators=100,max_features='log2', verbose=1)\n    return clf\n\ndef svm():\n    clf = SVR(kernel='rbf', gamma='auto')\n    return clf\n\ndef nn():\n    clf = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', verbose=3)\n    return clf\n\ndef predict_(m, test_x):\n    return pd.Series(m.predict(test_x))\n\ndef model_():\n#     return knn()\n    return extraTreesRegressor()\n#     return svm()\n#     return nn()\n#     return randomForestRegressor()    \n\ndef train_(train_x, train_y):\n    m = model_()\n    m.fit(train_x, train_y)\n    return m\n\ndef train_and_predict(train_x, train_y, test_x):\n    m = train_(train_x, train_y)\n    return predict_(m, test_x), m\n#","523d73a5":"def calculate_error(test_y, predicted, weights):\n    return mean_absolute_error(test_y, predicted, sample_weight=weights)","9fe54736":"kf = KFold(n_splits=5)\nsplited = []\n# dataset2 = dataset.copy()\nfor name, group in dataset.groupby([\"Store\", \"Dept\"]):\n    group = group.reset_index(drop=True)\n    trains_x = []\n    trains_y = []\n    tests_x = []\n    tests_y = []\n    if group.shape[0] <= 5:\n        f = np.array(range(5))\n        np.random.shuffle(f)\n        group['fold'] = f[:group.shape[0]]\n        continue\n    fold = 0\n    for train_index, test_index in kf.split(group):\n        group.loc[test_index, 'fold'] = fold\n        fold += 1\n    splited.append(group)\n\nsplited = pd.concat(splited).reset_index(drop=True)","cfdcdf92":"splited","98843755":"best_model = None\nerror_cv = 0\nbest_error = np.iinfo(np.int32).max\nfor fold in range(5):\n    dataset_train = splited.loc[splited['fold'] != fold]\n    dataset_test = splited.loc[splited['fold'] == fold]\n    train_y = dataset_train['weeklySales']\n    train_x = dataset_train.drop(columns=['weeklySales', 'fold'])\n    test_y = dataset_test['weeklySales']\n    test_x = dataset_test.drop(columns=['weeklySales', 'fold'])\n    print(dataset_train.shape, dataset_test.shape)\n    predicted, model = train_and_predict(train_x, train_y, test_x)\n    weights = test_x['isHoliday'].replace(True, 5).replace(False, 1)\n    error = calculate_error(test_y, predicted, weights)\n    error_cv += error\n    print(fold, error)\n    if error < best_error:\n        print('Find best model')\n        best_error = error\n        best_model = model\nerror_cv \/= 5","b452a4e8":"error_cv","32ea6331":"best_error","3c956d8c":"dataset_test = pd.read_csv(\"..\/input\/test.csv\", names=['Store','Dept','Date','isHoliday'],sep=',', header=0)\nfeatures = pd.read_csv(\"..\/input\/features.csv\",sep=',', header=0,\n                       names=['Store','Date','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4',\n                              'MarkDown5','CPI','Unemployment','IsHoliday']).drop(columns=['IsHoliday'])\nstores = pd.read_csv(\"..\/input\/stores.csv\", names=['Store','Type','Size'],sep=',', header=0)\ndataset_test = dataset_test.merge(stores, how='left').merge(features, how='left')","4e5838d9":"dataset_test = pd.get_dummies(dataset_test, columns=[\"Type\"])\ndataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4', 'MarkDown5']] = dataset_test[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].fillna(0)\ndataset_test = dataset_test.fillna(0)\ncolumn_date = dataset_test['Date']\ndataset_test['Month'] = pd.to_datetime(dataset_test['Date']).dt.month\ndataset_test = dataset_test.drop(columns=[\"Date\", \"CPI\", \"Fuel_Price\", 'Unemployment', 'MarkDown3'])\ndataset_test","869c85be":"predicted_test = best_model.predict(dataset_test)","07adc063":"dataset_test['weeklySales'] = predicted_test\ndataset_test['Date'] = column_date\ndataset_test['id'] = dataset_test['Store'].astype(str) + '_' +  dataset_test['Dept'].astype(str) + '_' +  dataset_test['Date'].astype(str)\ndataset_test = dataset_test[['id', 'weeklySales']]\ndataset_test = dataset_test.rename(columns={'id': 'Id', 'weeklySales': 'Weekly_Sales'})","99aa9a40":"dataset_test.to_csv('output.csv', index=False)","38cb0c41":"# K-Fold Cross Validation","d54af524":"# Data manipulation","0dedf38a":"# Data exploration","2e15e8cc":"# Test part","d02fcc9e":"# Algorithms"}}