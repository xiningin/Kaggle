{"cell_type":{"5d4c74a4":"code","56c4be17":"code","6e9d3376":"code","87c2b78b":"code","5aeb4214":"code","170c4787":"code","b88f7f2a":"code","5ae710c5":"code","84138279":"code","dd0659e8":"code","fa26a519":"code","25d60a98":"code","2fad1785":"code","aaf4e66b":"code","b29dc0bf":"code","a092132a":"code","a715bdd7":"code","b2c68953":"code","36a8d3a4":"code","e81801b4":"code","4d469430":"code","772565d7":"code","e6df239f":"code","70f3a146":"code","f08e03fa":"code","3a9dacee":"code","573fa115":"code","46e1902b":"code","e971d0af":"code","f914959c":"code","7726b740":"code","06076e37":"code","d38cda7c":"code","0b1e2aec":"code","6a2369ad":"code","378bafd9":"code","90f32520":"code","079b46b4":"code","82ab553f":"code","1d151133":"code","053f3407":"code","864ecf0c":"code","eee19df7":"code","b425b245":"code","2a730feb":"code","4fdf6aa3":"code","4fe7be44":"code","56d15a7f":"code","5594df11":"code","60150b0c":"code","c43e116e":"code","8fdf1c7c":"code","6f02c342":"code","9b1e8e12":"code","3f9c3e1e":"code","af271738":"code","5f6ffb35":"code","cf43ffae":"code","d710ce23":"code","0255bdee":"code","aac0b4c2":"code","1fa78e37":"code","f27e5b6e":"code","4ab49ef4":"code","d87d3d96":"code","226eee3c":"code","e4e96f21":"code","f7ec3d1e":"code","fa6299f3":"code","80063d5b":"code","4d949d82":"code","c4989fb7":"code","71b60304":"code","f0d7ccb5":"code","01ff6172":"code","66fbdaa8":"code","81d28d00":"code","f9294ae3":"code","d8ba55d2":"code","f0dbbe17":"code","8265dc3e":"code","f73bf40c":"code","87e53f40":"code","e30b0cd3":"code","5ceb1192":"code","2e91b750":"code","6551b76c":"code","dcf8555a":"code","572e1adb":"code","a247435b":"code","2058b78d":"code","0fc6c6aa":"code","9f9e1f2e":"code","2d83e0de":"code","b47d3329":"code","721cc122":"code","45191e6d":"code","2c196ad4":"code","11f24712":"markdown","4b70fe96":"markdown","be88e320":"markdown","1c12f9f1":"markdown","9658ca95":"markdown","490ac720":"markdown","97829ed5":"markdown","ff8d510b":"markdown","fa2789ff":"markdown","49bc7a19":"markdown","e626f055":"markdown","ebd09022":"markdown","edc87859":"markdown","d2609f50":"markdown","30b91f2d":"markdown","d38494c8":"markdown","aafdf259":"markdown","c5f450d6":"markdown","b53fbf38":"markdown","487650dd":"markdown","1ebddbe2":"markdown","fa8902ff":"markdown","7c292003":"markdown","53e715f8":"markdown","f35c6de1":"markdown","5200b2a8":"markdown","08cc46c7":"markdown","1d3952d4":"markdown","ba8dd127":"markdown","3de71fa5":"markdown","8224100b":"markdown","10242e83":"markdown","2404d4cc":"markdown","e52e7134":"markdown","201b20e8":"markdown","0448eea9":"markdown","24a9d6c4":"markdown","ac433352":"markdown","55dd30ef":"markdown","ad762fbf":"markdown","0876cf40":"markdown","63010182":"markdown","c560add8":"markdown","8e6fa625":"markdown","392726ac":"markdown","9ef5e85f":"markdown","a5f1430e":"markdown","d6c65a71":"markdown","f4bceb01":"markdown","314f24eb":"markdown","236e5f62":"markdown","28059b98":"markdown","81979136":"markdown","32e0761e":"markdown","a5635e44":"markdown","c0399842":"markdown","a37f6d91":"markdown","f8daf10e":"markdown","2411149f":"markdown","c83fcc69":"markdown","ecd2f3b4":"markdown","08939748":"markdown","2bae0ac9":"markdown","9626798c":"markdown","b0f0954c":"markdown","9c1afada":"markdown","97cbaff5":"markdown","bb173315":"markdown","c0ab545f":"markdown","9c29795f":"markdown","dcb72c30":"markdown","68a66fc8":"markdown","900dfda9":"markdown","1046a836":"markdown","30d10419":"markdown","c1781ba1":"markdown","97af5b4e":"markdown","1af4a1e1":"markdown","5b4cf9b3":"markdown","ae269e24":"markdown","af566839":"markdown","4bb43af3":"markdown","05c71e17":"markdown","a441f481":"markdown","8940e1b9":"markdown","480e579d":"markdown","b3aace1a":"markdown","60aa1973":"markdown","cc5db9cd":"markdown","29ffb3fd":"markdown","5f7c02f2":"markdown","5f3a0ee8":"markdown","0f070b50":"markdown","5ed47661":"markdown","9a8b3bf3":"markdown"},"source":{"5d4c74a4":"# Yedaya Schwalm 302320056\n# Nikita Kogan 320767643","56c4be17":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n#data visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nhotel_data = pd.read_csv(\"\/kaggle\/input\/hotel-booking-demand\/hotel_bookings.csv\")","6e9d3376":"#data processing\nimport pandas as pd\nimport numpy as np\n\n\n#data visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set_style(\"whitegrid\")\n\n","87c2b78b":"SMALL_SIZE = 12\nMEDIUM_SIZE = 14\nBIGGER_SIZE = 16\n\n\nplt.rc('font', size=SMALL_SIZE)          # controls default text sizes\nplt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\nplt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\nplt.rc('figure', titlesize=BIGGER_SIZE)","5aeb4214":"hotel_data.shape","170c4787":"hotel_data.head(4)","b88f7f2a":"hotel_data.info()","5ae710c5":"hotel_data.describe()","84138279":"eda_data = hotel_data.copy()\neda_data['is_canceled'] = eda_data.is_canceled.replace([1,0],[\"Cancelled\",\"Not Cancelled\"])\neda_data['is_repeated_guest'] = hotel_data.is_repeated_guest.replace([1,0],[\"Repeated\",\"Not Repeated\"])\n\n\nsns.countplot(x='is_canceled', data=eda_data)\nplt.title('Canceled Distributions', fontsize=14)","dd0659e8":"hotel_data['is_canceled'].value_counts()\/hotel_data.shape[0]*100","fa26a519":"\n\nnumeric_variables_normal = ['lead_time','arrival_date_week_number','total_of_special_requests']\n\nnumeric_variables_normal2 = ['arrival_date_day_of_month', 'arrival_date_year','stays_in_weekend_nights',\n                             'stays_in_week_nights','babies', 'booking_changes', 'company', 'adr']\n\n\nnumeric_variables_log1 = ['adults','children','previous_cancellations']\nnumeric_variables_log2 = ['previous_bookings_not_canceled','days_in_waiting_list','required_car_parking_spaces']","25d60a98":"\n#      reservation_status_date\n#  30  reservation_status              \n","2fad1785":"categorical_variables = ['country', 'market_segment', 'agent','arrival_date_month', 'meal', 'reserved_room_type', 'assigned_room_type' ]\nfor i in categorical_variables:\n    print((\"{} : {} \\n\").format(i,hotel_data[i].nunique()))","aaf4e66b":"plt.figure(figsize=(18,6))\ncountry_booking = hotel_data['country'].value_counts(normalize=True).rename_axis('country').reset_index(name='Percentage')\nsns.barplot(x='country', y='Percentage', data=country_booking.head(10))\nplt.title('Country of Customers')\nplt.show()","b29dc0bf":"#generate a figures grid:\nfig, axes = plt.subplots(2,3,figsize=(22,12))\nfig.subplots_adjust(hspace=0.5)\n\n#we will create a histogram for each categorical attribute\nn=len(categorical_variables[1:])\nnum_rows = 3\nmax_bars = 8\n\nfor i,variable in enumerate(categorical_variables[1:]):\n    #calculate the current place on the grid\n    r=int(i\/num_rows)\n    c=i%num_rows\n    \n    #create the \"value counts\" for the first <max_bars> categories:\n    u=min(hotel_data[variable].nunique(),max_bars)\n    vc = hotel_data[variable].value_counts()[:u]\n    \n    # plot a bar chart using Pandas\n    vc.plot(kind='bar',ax=axes[r,c],title=variable , color=\"rbgkm\"[i%5])","a092132a":"binary_variables = ['hotel', 'is_repeated_guest','is_canceled', 'distribution_channel', 'deposit_type', 'customer_type']","a715bdd7":"plt.rcParams.update({'font.size': 10})\n#initialize a Matplotlib figures grid\nfig, axes = plt.subplots(2,3,figsize=(18,8))\n                         \nfig.subplots_adjust(hspace=0.5)\n\n#we will create a histogram for each categorical attribute\nn=len(binary_variables)\nnum_rows = 3\n                    \n#generate a histogram using Pandas, for each numeric variable\nfor i, var in enumerate(binary_variables):\n    r=int(i\/num_rows)\n    c=i%num_rows         \n    eda_data[var].value_counts().plot.pie(ax=axes[r,c] ,autopct=\"%.2f%%\")\n    \n\n","b2c68953":"numeric_variables_normal = ['lead_time','arrival_date_week_number','total_of_special_requests']\n\nnumeric_variables_normal2 = ['arrival_date_day_of_month', 'arrival_date_year','stays_in_weekend_nights',\n                             'stays_in_week_nights','babies', 'booking_changes', 'company', 'adr']","36a8d3a4":"# Show numeric_variables\n#initialize a Matplotlib figures grid\nfig, axes = plt.subplots(1, len(numeric_variables_normal),figsize=(18,3))\n\n#generate a histogram using Pandas, for each numeric variable\nfor ind,var in enumerate(numeric_variables_normal):\n    hotel_data[var].hist(ax=axes[ind],edgecolor='black' ,color=\"rbgkm\"[ind%5])\n    axes[ind].set_title(var)\n","e81801b4":"sns.kdeplot(hotel_data[\"lead_time\"], kernel='epa')","4d469430":"fig, axes = plt.subplots(2,4,figsize=(18,8))\nfig.subplots_adjust(hspace=0.5)\n\n#we will create a histogram for each categorical attribute\nn=len(numeric_variables_normal2)\nnum_rows = 4\n\nfor i,var in enumerate(numeric_variables_normal2):\n    #calculate the current place on the grid\n    r=int(i\/num_rows)\n    c= i%num_rows\n    \n    \n    hotel_data[var].hist(ax=axes[r,c] ,edgecolor='black' ,color=\"rbgkm\"[i%5]).set_title(var)\n\n    ","772565d7":"fig, axs = plt.subplots(1,3, figsize=(22,3))\n\nsns.boxplot(hotel_data.stays_in_weekend_nights, ax=axs[0])\naxs[0].set_title(\"Stays in weekend - box plot\")\n\nsns.boxplot(hotel_data.stays_in_week_nights, ax=axs[1])\naxs[1].set_title(\"stays in week nights - box plot\")\n\n\ncountry_booking = hotel_data['stays_in_week_nights'].value_counts(normalize=True).rename_axis('stays_in_week_nights').reset_index(name='Percentage')\nsns.barplot(ax=axs[2], x='stays_in_week_nights', y='Percentage', data=country_booking.head(10))\nplt.title('stays_in_week_nights')\n","e6df239f":"fig, axs = plt.subplots(1,3, figsize=(22,3))\n\n\ncountry_booking = hotel_data['babies'].value_counts(normalize=True).rename_axis('babies').reset_index(name='Percentage')\nsns.barplot(ax=axs[0], x='babies', y='Percentage', data=country_booking.head(5))\naxs[0].set_title('babies (top 5)')\n\ncg = hotel_data[hotel_data[\"babies\"] > 0]\ncountry_booking = cg['babies'].value_counts(normalize=True).rename_axis('babies').reset_index(name='Percentage')\nsns.barplot(ax=axs[1], x='babies', y='Percentage', data=country_booking.head(5))\naxs[1].set_title('babies more than 1 (top 5)')\n\n\ncountry_booking = hotel_data['booking_changes'].value_counts(normalize=True).rename_axis('booking_changes').reset_index(name='Percentage')\nsns.barplot(ax=axs[2], x='booking_changes', y='Percentage', data=country_booking.head(5))\nplt.title('booking_changes')","70f3a146":"fig, axs = plt.subplots(1,2, figsize=(12,3))\n\nsns.kdeplot(hotel_data[\"adr\"], kernel='epa', ax=axs[0])\naxs[0].set_title(\"Adr - kdeplot\")\n\n# days in waiting list not 0.. (boxplot)\n\ncg = hotel_data[hotel_data[\"adr\"] < 1000]\nsns.boxplot(cg[\"adr\"], ax=axs[1])\naxs[1].set_title(\"Adr - box plot\")","f08e03fa":"numeric_variables_log1 = ['adults','children','previous_cancellations']\nnumeric_variables_log2 = ['previous_bookings_not_canceled','days_in_waiting_list','required_car_parking_spaces']\n# Const\nbins = []\nfor x in range(-1,5400,1):\n    bins.append(x+0.5)","3a9dacee":"# Show numeric_variables: \n#initialize a Matplotlib figures grid\nfig, axes = plt.subplots(1, len(numeric_variables_log1),figsize=(24,3))\n\n\n#generate a histogram using Pandas, for each numeric variable\nfor ind,var in enumerate(numeric_variables_log1):\n    max_value = int(hotel_data[var].max())\n    slice_object = slice(max_value)\n    hotel_data[var].hist(ax=axes[ind],bins=bins[slice_object], edgecolor='black', log=True)\n    axes[ind].set_title(var)","573fa115":"# Show numeric_variables:\n#initialize a Matplotlib figures grid\nfig, axes = plt.subplots(1, len(numeric_variables_log2),figsize=(24,3))\n\n#generate a histogram using Pandas, for each numeric variable\nfor ind,var in enumerate(numeric_variables_log2):\n    max_value = int(hotel_data[var].max())\n    slice_object = slice(max_value)\n    hotel_data[var].hist(ax=axes[ind],bins=bins[slice_object], edgecolor='black', log=True)\n    axes[ind].set_title(var)","46e1902b":"# days in waiting list not 0.. (boxplot)\nfig, axs = plt.subplots(1,1, figsize=(6,4))\n\ncg = hotel_data[hotel_data[\"days_in_waiting_list\"] > 0]\nsns.boxplot(cg[\"days_in_waiting_list\"])","e971d0af":"_, ax = plt.subplots( nrows = 2, ncols = 1, figsize = (12,8))\nsns.countplot(x = 'market_segment', data = hotel_data, ax = ax[0])\nsns.countplot(x = 'market_segment', data = hotel_data, hue = 'is_canceled', ax = ax[1])\nplt.show()","f914959c":"# Number of Canceled Each Month\n\n# We can simply use a countplot as we sre visualising categorical data\nplt.figure(figsize=(20,5))\n\n# data we will use in a list\nl1 = ['is_canceled','arrival_date_month']\n\n# plotting\nsns.countplot(data = hotel_data[l1],x= \"arrival_date_month\",hue=\"is_canceled\",order=[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\n                                                                              \"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]).set_title(\n'Illustration of Number of Canceled Each Month')\nplt.xlabel('Month')\nplt.ylabel('Count')","7726b740":"hotel_data.groupby(['arrival_date_year'])['is_canceled'].mean()","06076e37":"fig, axs = plt.subplots(2,1, figsize=(16,12))\n\n\n# We can simply use a countplot as we sre visualising categorical data\n# plt.figure(figsize=(20,5))\n\n# data we will use in a list\nl1 = ['is_canceled','arrival_date_week_number']\n\n# plotting\nsns.countplot(ax = axs[0], data = hotel_data[l1],x= \"arrival_date_week_number\").set_title(\n'Illustration of Canceled Each week')\n\n# plotting\nsns.countplot(ax = axs[1], data = hotel_data[l1],x= \"arrival_date_week_number\",hue=\"is_canceled\").set_title(\n'Illustration of Canceled Each week')\n","d38cda7c":"_, ax = plt.subplots( nrows = 1, ncols = 2, figsize = (18,4))\nsns.countplot(x = 'deposit_type', data = hotel_data, hue = 'hotel', ax = ax[0])\nsns.countplot(x = 'deposit_type', data = hotel_data, hue = 'is_canceled', ax = ax[1])\nplt.show()","0b1e2aec":"# Let's look into how much of bookings were cancelled in each type of hotel\nfig, axs = plt.subplots(1,2, figsize=(16,3))\n\nsns.countplot(x = 'hotel', data = hotel_data, ax = axs[0], order = hotel_data['hotel'].value_counts().index).set_title('city and resort hotel')\n\nlst1 = ['is_canceled', 'hotel']\ntype_of_hotel_canceled = eda_data[lst1]\ncanceled_hotel = type_of_hotel_canceled[type_of_hotel_canceled['is_canceled'] == 'Cancelled'].groupby(['hotel']).size().reset_index(name = 'count')\ncanceled_hotel\nsns.barplot(data = canceled_hotel, x = 'hotel', y = 'count', ax=axs[1]).set_title('Graph showing cancellation rates in city and resort hotel')","6a2369ad":"hotel_data.groupby(['hotel'])['is_canceled'].mean()","378bafd9":"fig, axs = plt.subplots(1,3, figsize=(22,3))\n\n\n# We will just look at number of children that canceled booking.\nsns.countplot(ax=axs[0], data=hotel_data,x='children',hue='is_canceled').set_title(\"Illustration of number of children canceling booking\")\n\n# We will just look at number of babies that canceled booking.\nsns.countplot(ax=axs[1],data=hotel_data,x='babies',hue='is_canceled').set_title(\"Illustration of number of babies canceling booking\")\n\n\nsns.countplot(ax=axs[2],data=hotel_data,x='adults',hue='is_canceled').set_title(\"Illustration of number of babies canceling booking\")\n","90f32520":"_, ax = plt.subplots( nrows = 1, ncols = 2, figsize = (18,5))\nsns.countplot(x = 'customer_type', data = hotel_data, ax = ax[0])\nsns.countplot(x = 'customer_type', data = hotel_data, hue = 'is_canceled', ax = ax[1])\nplt.show()","079b46b4":"_, ax = plt.subplots( nrows = 1, ncols = 2, figsize = (18,5))\nsns.countplot(x = 'reservation_status', data = hotel_data, ax = ax[0])\nsns.countplot(x = 'reservation_status', data = hotel_data, hue = 'is_canceled', ax = ax[1])\nplt.show()","82ab553f":"clean_data = hotel_data.copy()\n\nclean_data.fillna({\"children\": 0}, inplace=True)\n\n# missing countries can be labeled unknown\nclean_data.fillna({\"country\": \"Unknown\"}, inplace=True)\n\n# missing agent ID can be zero, presuming the booking was made privately\nclean_data.fillna({\"agent\": 0}, inplace=True)\n\n# missing company ID can be zero (for the same reason as agent ID)\nclean_data.fillna({\"company\": 0}, inplace=True)","1d151133":"clean_data.isnull().sum()\/clean_data.shape[0]*100","053f3407":"corr_matrix = clean_data.corr(method='spearman')\nfig, ax = plt.subplots(figsize=(25,25))\nsns.heatmap(clean_data.corr(method='spearman'),annot=True,linewidths=.5)\n","864ecf0c":"corr_matrix = clean_data.corr()\ncorr_matrix[\"is_canceled\"].sort_values(ascending=False)","eee19df7":"# hist plot of lead time\n# kde = kernel density estimation (displays distribution function, density curve)\n# shows the distribution and highest concentration points\nplt.figure(figsize=(10,5))\nlead_time = clean_data['lead_time']\nlead_time = pd.DataFrame(sorted(lead_time, reverse = True), columns = ['Lead'])\nsns.histplot(lead_time, kde=True)\nplt.title(\"Lead Time\", size=20)\nplt.xlabel(\"lead time days\", size=15)\nplt.tight_layout()\nplt.show()","b425b245":"lead_time_1 = clean_data[clean_data[\"lead_time\"] < 50]\nlead_time_2 = clean_data[clean_data[\"lead_time\"] < 100]\nlead_time_3 = clean_data[clean_data[\"lead_time\"] < 150]\nlead_time_4 = clean_data[clean_data[\"lead_time\"] < 200]\nlead_time_5 = clean_data[(clean_data[\"lead_time\"] >= 200) & (clean_data[\"lead_time\"] < 365)]\nlead_time_6 = clean_data[clean_data[\"lead_time\"] >= 365]\n# calculates cancellations according to lead time groups\nlead_cancel_1 = lead_time_1[\"is_canceled\"].value_counts()\nlead_cancel_2 = lead_time_2[\"is_canceled\"].value_counts()\nlead_cancel_3 = lead_time_3[\"is_canceled\"].value_counts()\nlead_cancel_4 = lead_time_4[\"is_canceled\"].value_counts()\nlead_cancel_5 = lead_time_5[\"is_canceled\"].value_counts()\nlead_cancel_6 = lead_time_6[\"is_canceled\"].value_counts()","2a730feb":"# total count of lead time according to cancellation\ntotal_lead_days_cancel = pd.DataFrame(data=[lead_cancel_1,lead_cancel_2,lead_cancel_3,lead_cancel_4,lead_cancel_5,lead_cancel_6],\n                                      index=[\"[0,50) days\",\"[50,100) days\",\"[100,150) days\",\"[150,200) days\",\"200,365) days\",\"[365,max) days\"])\n\n# pie plot for each lead time group\nfig, ax = plt.subplots(2,3, figsize=(15,6))\nax[0,0].pie(np.array([total_lead_days_cancel[0][0], total_lead_days_cancel[1][0]]),\n          labels=[\"not_canceled\", \"canceled\"], autopct='%1.1f%%', startangle=90,\n          colors=['forestgreen', 'firebrick'])\nax[0,0].set_title(\"lead_time [0,50) days\", size=15)\nax[0,1].pie(np.array([total_lead_days_cancel[0][1], total_lead_days_cancel[1][1]]),\n          labels=[\"not_canceled\", \"canceled\"], autopct='%1.1f%%', startangle=90,\n          colors=['forestgreen', 'firebrick'])\nax[0,1].set_title(\"lead_time [50,100) days\", size=15)\nax[0,2].pie(np.array([total_lead_days_cancel[0][2], total_lead_days_cancel[1][2]]),\n          labels=[\"not_canceled\", \"canceled\"], autopct='%1.1f%%', startangle=90,\n          colors=['forestgreen', 'firebrick'])\nax[0,2].set_title(\"lead_time [100,150) days\", size=15)\n\n\nax[1,0].pie(np.array([total_lead_days_cancel[0][3], total_lead_days_cancel[1][3]]),\n          labels=[\"not_canceled\", \"canceled\"], autopct='%1.1f%%', startangle=90,\n          colors=['forestgreen', 'firebrick'])\nax[1,0].set_title(\"lead_time [150,200) days\", size=15)\n\nax[1,1].pie(np.array([total_lead_days_cancel[0][4], total_lead_days_cancel[1][4]]),\n          labels=[\"not_canceled\", \"canceled\"], autopct='%1.1f%%', startangle=90,\n          colors=['forestgreen', 'firebrick'])\nax[1,1].set_title(\"lead_time [200,356) days\", size=15)\n\nax[1,2].pie(np.array([total_lead_days_cancel[0][5], total_lead_days_cancel[1][5]]),\n          labels=[\"not_canceled\", \"canceled\"], autopct='%1.1f%%', startangle=90,\n          colors=['forestgreen', 'firebrick'])\nax[1,2].set_title(\"lead_time [356,max) days\", size=15)\n\nplt.tight_layout()\nplt.show()","4fdf6aa3":"# plot special requests according to cancellations\nplt.figure(figsize=(10,5))\nsns.countplot(x=clean_data[\"total_of_special_requests\"], hue=clean_data[\"is_canceled\"])\nplt.title(\"Special Requests\", size=20)\nplt.xlabel(\"Number of Special Requests\", size=15)\nplt.legend([\"not canceled\", \"canceled\"])\nplt.tight_layout()\nplt.show()\n\n# Nearly half of the bookings without special requests are canceled.","4fe7be44":"var_a = 'lead_time'\nvar_b = 'total_of_special_requests'\n\ncanceled = clean_data[clean_data['is_canceled'] == 1]\nnot_canceled = clean_data[clean_data['is_canceled'] == 0]","56d15a7f":"sns.set(color_codes=True)\nfig,ax=plt.subplots(figsize=(16,8))\n\nsns.regplot(var_a, var_b, canceled,ax=ax, \n            scatter_kws={\"marker\": \".\", \"color\": \"blue\"},\n            line_kws = {\"linewidth\": \"1\", \"color\": \"blue\"},\n            order = 3,\n            label = 'canceled')\nsns.regplot(var_a, var_b, not_canceled,ax=ax, \n            scatter_kws={\"marker\": \".\", \"color\": \"orange\"},\n            line_kws = {\"linewidth\": \"1\", \"color\": \"orange\"},\n            order = 3,\n            label = 'not canceled')\n\nfig.legend(loc=\"lower right\")\nfig.suptitle(f\"Scatter plot of {var_a} and {var_b}\")","5594df11":"hot_data = clean_data.copy()","60150b0c":"def setDictionary(dictionary,unique_data_arr): \n    for i in range (len(unique_data_arr)):\n        dictionary[unique_data_arr[i]] = i\n    return dictionary","c43e116e":"num_data = clean_data.copy()\n\n# hotel to bool\nnum_data['hotel']= num_data['hotel'].replace([\"Resort Hotel\",\"City Hotel\"],[1,0])\n\n# arrival_date_month to int \nmonth_dict = {'January': 0, 'February': 1, 'March': 2, 'April': 3, 'May': 4, 'June': 5, 'July': 6, 'August': 7, 'September': 8, 'October': 9, 'November': 10, 'December': 11} \nnum_data['arrival_date_month']= num_data['arrival_date_month'].map(month_dict)\n\n# meal to int \nmeal_dict = {'BB':1, 'FB':2 ,'HB':3, 'SC':4 ,'Undefined':0}\nnum_data['meal'] = num_data['meal'].map(meal_dict)\n\n\n# countery to int \ncountry_dict ={}\ncountry_arr = num_data['country'].unique()\ncountry_dict = setDictionary(country_dict, num_data['country'].unique())\nnum_data['country'] = num_data['country'].map(country_dict)\n\n# market_segment to int \nmarket_segment_dict ={}\nmarket_segment_dict = setDictionary(market_segment_dict,num_data['market_segment'].unique())\nnum_data['market_segment'] = num_data['market_segment'].map(market_segment_dict) \n\n# distribution_channel to int\ndistribution_channel_dict = {}\ndistribution_channel_dict = setDictionary(distribution_channel_dict,num_data['distribution_channel'].unique())\nnum_data['distribution_channel'] = num_data['distribution_channel'].map(distribution_channel_dict) \n\n# reserved_room_type to int\nreserved_room_type_dict = {}\nreserved_room_type_dict = setDictionary(reserved_room_type_dict,num_data['reserved_room_type'].unique())\nnum_data['reserved_room_type'] = num_data['reserved_room_type'].map(reserved_room_type_dict)\n\n# assigned_room_type_dict TO INT \nassigned_room_type_dict = {}\nassigned_room_type_dict = setDictionary(assigned_room_type_dict, num_data['assigned_room_type'].unique())\nnum_data['assigned_room_type'] = num_data['assigned_room_type'].map(assigned_room_type_dict)\n\n# deposit_typ TO INT \ndeposit_type_dict = {}\ndeposit_type_dict = setDictionary(deposit_type_dict,num_data['deposit_type'].unique())\nnum_data['deposit_type'] = num_data['deposit_type'].map(deposit_type_dict)\n\n# customer_type TO INT \ncustomer_type_dict = {}\ncustomer_type_dict = setDictionary(customer_type_dict, num_data['customer_type'].unique())\nnum_data['customer_type'] = num_data['customer_type'].map(customer_type_dict)\n\n# reservation_status TO INT \nreservation_status_dict = {}\nreservation_status_dict = setDictionary(reservation_status_dict,num_data['reservation_status'].unique())\nnum_data['reservation_status'] = num_data['reservation_status'].map(reservation_status_dict)\n\n# reservation_status_date TO INT \nreservation_status_date_dict ={}\nreservation_status_date_dict =setDictionary(reservation_status_date_dict, num_data['reservation_status_date'].unique())\nnum_data['reservation_status_date'] = num_data['reservation_status_date'].map(reservation_status_date_dict)\n\nnum_data.shape","8fdf1c7c":"corr_matrix = num_data.corr()\ncorr_matrix[\"is_canceled\"].sort_values(ascending=False)","6f02c342":"num_data = num_data.drop('reservation_status_date', axis = 1)\nnum_data = num_data.drop('reservation_status', axis = 1)\n\nclean_data = clean_data.drop('reservation_status_date', axis = 1)\nclean_data = clean_data.drop('reservation_status', axis = 1)","9b1e8e12":"hot_data = hot_data.drop('reservation_status_date', axis = 1)\nhot_data = hot_data.drop('reservation_status', axis = 1)","3f9c3e1e":"from sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n\nhot_data = pd.get_dummies(hot_data, prefix='Category_', columns=['hotel','arrival_date_month','meal','country','market_segment',\n                                                                'distribution_channel','reserved_room_type','assigned_room_type',\n                                                                'deposit_type','customer_type'])","af271738":"hot_data.shape\n","5f6ffb35":"clean_data['arrival_date_month'] = num_data['arrival_date_month']\nclean_data['hotel'] = num_data['hotel']\nremove_country_data = clean_data.copy()","cf43ffae":"clean_data = pd.get_dummies(clean_data, prefix='Category_', columns=['meal','country','market_segment', 'distribution_channel',\n                                                                     'reserved_room_type','assigned_room_type',\n                                                                    'deposit_type','customer_type'])","d710ce23":"remove_country_data = remove_country_data.drop('country', axis=1)\nremove_country_data = pd.get_dummies(remove_country_data, prefix='Category_', columns=['meal','market_segment', 'distribution_channel',\n                                                                     'reserved_room_type','assigned_room_type',\n                                                                    'deposit_type','customer_type'])","0255bdee":"print(f'clean data (A combination of hot and number) shape {clean_data.shape}')\nprint(f'hot vector (hot only) data shape {hot_data.shape}')\nprint(f'num data (number only) shape {num_data.shape}')\nprint(f'remove_country_data (like the first affter remove country) shape {remove_country_data.shape}')","aac0b4c2":"data = {\"clean_data\": clean_data, \"hot_data\": hot_data, \"num_data\": num_data, \"remove_country_data\": remove_country_data}","1fa78e37":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix, roc_curve, roc_auc_score,auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris","f27e5b6e":"def train(clean_data, class_w):\n    y = clean_data['is_canceled']\n    X = clean_data.drop('is_canceled',axis = 1)\n    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n    \n    \n    clf = LogisticRegression(random_state=0, class_weight=class_w).fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    \n    predicted_probs = clf.predict_proba(X_test)\n    \n    return({\"clf\": clf, \"y_t\": y_test, \"y_p\": y_pred, \"p_p\": predicted_probs, \"x_train\": X_train, \"y_train\":y_train, 'x_test': X_test})\n\n    ","4ab49ef4":"class_w = ['weights', 'balanced']","d87d3d96":"ans = {}\nfor key in data:\n    for c_w in class_w:\n        ans[key+'_'+ c_w] = train(data[key], c_w)\n\nfor key, value in ans.items():\n    print(f'{key} accuracy -> {accuracy_score(value[\"y_t\"],value[\"y_p\"])}')","226eee3c":"#TODO delte warninng","e4e96f21":"for key, value in ans.items():\n    print(f' \\n  {key} :')\n\n    values = value[\"y_t\"].value_counts(dropna=False).keys().tolist()\n    counts = value[\"y_t\"].value_counts(dropna=False).tolist()\n    print(f'y_test: {dict(zip(values, counts))}')\n    \n    unique, counts = np.unique(value[\"y_p\"], return_counts=True)\n    print(f'y_prid: {dict(zip(unique, counts))}')\n    ","f7ec3d1e":"#todo show in plot comper (only clean_data_weights & clean_data_balanced  )","fa6299f3":"### 'weights' VS 'balanced'\n# todo add note\n","80063d5b":"clf, y_test, y_pred , predicted_probs, x_train , y_train, x_test = ans['clean_data_weights'].values()\ny_score = predicted_probs[:,1]","4d949d82":"#TODO add croosvalidtion on  clean data weights' and 'balanced'","c4989fb7":"from sklearn import metrics\nimport plotly.figure_factory as ff","71b60304":"from sklearn.metrics import confusion_matrix\nmat = confusion_matrix(y_test, y_pred)","f0d7ccb5":"import plotly.offline as pyo\nimport plotly.graph_objs as go\n\npyo.init_notebook_mode()\n\n\nfig = ff.create_annotated_heatmap(z=mat,\n                                  x=[\"False\", \"True\"], y=[\"False\", \"True\"], \n                                  showscale=True)\nfig.update_layout(font=dict(size=12))\n# Add Labels\nfig.add_annotation(x=0,y=0, text=\"True Negative\", \n                   yshift=40, showarrow=False, font=dict(color=\"black\",size=24))\nfig.add_annotation(x=1,y=0, text=\"False Positive\", \n                   yshift=40, showarrow=False, font=dict(color=\"white\",size=24))\nfig.add_annotation(x=0,y=1, text=\"False Negative\", \n                   yshift=40, showarrow=False, font=dict(color=\"white\",size=24))\nfig.add_annotation(x=1,y=1, text=\"True Positive\", \n                   yshift=40, showarrow=False, font=dict(color=\"white\",size=24))\n\nfig.update_xaxes(title=\"Predicted\")\nfig.update_yaxes(title=\"Actual\", autorange=\"reversed\")\n","01ff6172":"# for key, value in ans.items():\n#     unique, counts = np.unique(value[\"y_p\"], return_counts=True)\n#     print(f' \\n  {key} :')\n    \n#     print(metrics.classification_report(value[\"y_t\"], value[\"y_p\"]))","66fbdaa8":"from sklearn.metrics import precision_recall_fscore_support as score\nbalanced = ans['clean_data_weights']\nw = score(balanced[\"y_t\"], balanced[\"y_p\"])","81d28d00":"balanced = ans['clean_data_balanced']\nb = score(balanced[\"y_t\"], balanced[\"y_p\"])","f9294ae3":"weights_not_canceled = [w[0][0],w[1][0],w[2][0]]\nbalanced_not_canceled = [b[0][0],b[1][0],b[2][0]]\n\nweights_is_canceled = [w[0][1],w[1][1],w[2][1]]\nbalanced_is_canceled = [b[0][1],b[1][1],b[2][1]]\nindex = ['Precision ', 'Recall', 'F-score']\n\n\npd1 = pd.DataFrame({'weights': weights_not_canceled,\n                   'balanced': balanced_not_canceled}, index=index)\n\npd2 = pd.DataFrame({'weights': weights_is_canceled,\n                   'balanced': balanced_is_canceled}, index=index)\n\nfig, axes = plt.subplots(ncols=2,figsize=(18,5))\npd1.plot.bar(ax = axes[0])\naxes[0].set_title(\"Not Canceled Performence\")\naxes[0].set_xlabel(\"Evaluation\")\naxes[0].set_ylabel(\"Score\")\npd2.plot.bar(ax = axes[1])\naxes[1].set_title(\"Is Canceled Performence\")\naxes[1].set_xlabel(\"Evaluation\")\naxes[1].set_ylabel(\"Score\")\n","d8ba55d2":"def plotPR(precision, recall):\n    plt.figure()\n    plt.plot(recall, precision, label='PR curve')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall curve')\n    plt.legend(loc='lower left')\n    plt.show()","f0dbbe17":"import sklearn\nprecision, recall, thresholds = sklearn.metrics.precision_recall_curve(y_test, y_score, pos_label=1)\nplotPR(precision, recall)","8265dc3e":"def plotRoc(fpr, tpr, auc):\n    plt.figure()\n    plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characterist')\n    plt.legend(loc=\"lower right\")\n    plt.show()","f73bf40c":"auc = sklearn.metrics.roc_auc_score(y_test, y_score)\nfpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_score)\nplotRoc(fpr, tpr, auc)","87e53f40":"import shap\nshap.initjs()","e30b0cd3":"clf, y_test, y_pred , predicted_probs, x_train , y_train, x_test = ans['ans'].values()","5ceb1192":"def predict_fcn(x):\n    return clf.predict_proba(x)[:,1]","2e91b750":"background_data = shap.maskers.Independent(x_train,  max_samples=100)\nexplainer = shap.Explainer(predict_fcn, background_data)","6551b76c":"shap_values_100 = explainer(x_test[:100])","dcf8555a":"shap.plots.waterfall(shap_values_100[5], max_display=14)","572e1adb":"shap.plots.beeswarm(shap_values_100, max_display=8)","a247435b":"def perf_measure(y_actual, y_hat, x_t):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    \n\n    for i in range(len(y_hat)): \n#         if y_actual[i]==y_hat[i]==1:\n#            TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n            FP += 1\n            if FP>100:\n                break\n#         if y_actual[i]==y_hat[i]==0:\n#            TN += 1\n#         if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n#             FN += 1\n#             if FN>100:\n#                 break\n        else :\n            x_t.drop(x_t.iloc[i].name, inplace=True)\n        \n\n    return(FP, x_t)","2058b78d":"x_copy = x_test.copy()\nFP, x_t = perf_measure(y_test.values, y_pred, x_copy )","0fc6c6aa":"background_data = shap.maskers.Independent(x_train,  max_samples=100)\nexplainer = shap.Explainer(predict_fcn, background_data)\nshap_values = explainer(x_t[:100])","9f9e1f2e":"shap.plots.beeswarm(shap_values, max_display=8)","2d83e0de":"from sklearn.model_selection import train_test_split\ny = clean_data['is_canceled']\nX = clean_data.drop('is_canceled',axis = 1)\nx_train,x_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)","b47d3329":"#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\n\ny_pred_knn = knn.predict(x_test)\n\nacc_knn = accuracy_score(y_test, y_pred_knn)\nconf = confusion_matrix(y_test, y_pred_knn)\nclf_report = classification_report(y_test, y_pred_knn)\n\nprint(f\"Confusion Matrix : \\n{conf}\")\nprint(f\"Classification Report : \\n{clf_report}\")\nprint(f\"Accuracy Score of KNN is : {acc_knn}\")\n","721cc122":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(max_depth=6, random_state=123,criterion='entropy')\n\ndtree.fit(x_train,y_train)\n# DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=123)\ny_pred=dtree.predict(x_test)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nprint(\"Decision Tree score: \",score)","45191e6d":"#Random Forest \n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nrfc=RandomForestClassifier()\nrfc.fit(x_train,y_train)\nRandomForestClassifier()\ny_pred=rfc.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nconf =print(confusion_matrix(y_test, y_pred))\nclf =print(classification_report(y_test, y_pred))\nscore=accuracy_score(y_test,y_pred)\nprint(\"Random Forest score: \",score)","2c196ad4":"import plotly.offline as pyo\nimport plotly.graph_objs as go\n\npyo.init_notebook_mode()\n\n\nfig = ff.create_annotated_heatmap(z=cm,\n                                  x=[\"False\", \"True\"], y=[\"False\", \"True\"], \n                                  showscale=True)\nfig.update_layout(font=dict(size=12))\n# Add Labels\nfig.add_annotation(x=0,y=0, text=\"True Negative\", \n                   yshift=40, showarrow=False, font=dict(color=\"black\",size=24))\nfig.add_annotation(x=1,y=0, text=\"False Positive\", \n                   yshift=40, showarrow=False, font=dict(color=\"white\",size=24))\nfig.add_annotation(x=0,y=1, text=\"False Negative\", \n                   yshift=40, showarrow=False, font=dict(color=\"white\",size=24))\nfig.add_annotation(x=1,y=1, text=\"True Positive\", \n                   yshift=40, showarrow=False, font=dict(color=\"white\",size=24))\n\nfig.update_xaxes(title=\"Predicted\")\nfig.update_yaxes(title=\"Actual\", autorange=\"reversed\")","11f24712":"#  2.  Naive Model :","4b70fe96":"### Naive approach to converting categories to numbers","be88e320":"#### Arrival date month","1c12f9f1":"* Same order for customer of bookings and cancellation rate","9658ca95":"* The average time to be on the waiting list is 0.5\n* The vast majority of straight orderers are happy and not waiting on the waiting list\n  <br>But those who waited usually waited about 50 days\n* Most of the waiters are in the range of 40 to 90\n* There are extreme values that have waited over 170 days (half a year or more)","490ac720":"* Delete reservation_status & reservation_status_date","97829ed5":"* Can see similarities between the graphs\n*There are weeks when the cancellation ratio changes slightly but not something extreme","ff8d510b":"### Date vs Cancellations","fa2789ff":"### Categories to Numbers :","49bc7a19":"### Delete features :\n* We will check if there are strong ties with the features we created","e626f055":"### Market segment vs Cancellations","ebd09022":"# 1. Exploration (EDA) & Visualization\n","edc87859":"### Deposit  type vs Cancellations","d2609f50":"### Create numerical data:\n* From 32 colume to 32 \n* The features are now dependent of the order\n\n### Preparation of this model is for comparison only<br> (class presentation)","30b91f2d":"### Model results :\n* Clean_Data has the best performance (78.4%)\n* Class_weight 'balanced' decreases accuracy Raises the recall\n* Conversion to numbers led to a decrease in performance (confused the model)","d38494c8":"## Understanding the results of the naive model\n","aafdf259":"### Deatils\n* Logistic Regression model\n* Division 20% to test and 80% train\n* Class_weight : 'weights' Or 'balanced'","c5f450d6":"* Most bookings are for 1 adult or more (2 is must commen)\n* Most customers do not have children (or at least did not include them in the order)\n* Most people have not previously canceled an order before the current orde\n\n#### Can see that there are slight noises in the data : \n* There are data showing over 20 guests and even 50\n* Or order with 10 babies (unlikely)","b53fbf38":"### Comparison precision, recall,  f1-score","487650dd":"#### Summary  date vs cancellations:\n* The cancellation rate is quite consistently high during april to october having its peak at august.\n* There is no direct effect between the month and the amount of cancellations\n* This year does not affect the cancellation at all around 36%\n*There are weeks when the cancellation ratio changes slightly but not something extreme\n\n","1ebddbe2":"### Categories to One Hot :","fa8902ff":"### Hotel type vs Cancellations","7c292003":"# Hotel Data Analysis - Prediction of Cancellation\n## Goal Of Project: Analyse relation between human and machine decesion making. In this project, we will try to predict hotel reservation cancellations based on various feaures. We will emphisize the human-based decision factor in the prediction. ","53e715f8":"#### It can be clearly seen, as the lead time increases the chance of cancellation increases :\n* And that does make sense, since there is more time to cancel, and the chances of change are greater","f35c6de1":"#### Comparison True positive, false positive and so on:\nAdvance data 62 percent without cancellation.\n* So it makes sense- The majority is true negative","5200b2a8":"### Created Small Combination data:\n* Arrival date month - to number (save the order)\n* Delete country feature - 177 unique\n* All ohter is hot vector","08cc46c7":"### Lead time","1d3952d4":"## Correlation Heat Map of features","ba8dd127":"#### Canceled Distribution :\n* Not Canceled: 62.96%\n* Canceled: 37.04%\n### Interesting conclusion - widely speaking, in average, every 3rd room reservation is eventually cancelled! \n","3de71fa5":"delet  Reservation status...","8224100b":"* Note that the number of columns depends on the change in the data\n* Hot vector increases the number of columns","10242e83":"##  Distribution :","2404d4cc":"* It can be seen that according to previous orders most customers do not cancel orders\n* Most people do not require parking, and those who do, ask for one","e52e7134":"#### Arrival year","201b20e8":"### Similar behavior can be seen both in false negative and in general and therefore, we did not find it appropriate to work on a particular feature","0448eea9":"* Most of the columns are full - according to the count line\n* Avg. lead time is 104 days, around 3.5 months.\n* Each booking has on an average 1.8 adults and 0.1 children.\n* Only 3% of the guests are repeated.\n* Median lead time is 69 days.","24a9d6c4":"* Avg. lead time is 104 days, around 3.5 months.\n* Median lead time is 69 days.\n* The decrease in lead time can be seen as time increases\n","ac433352":"## Comparative Visualizations To Cancellation :","55dd30ef":"* City hotel has high Cancellation rate than Resort Hotel.\n* Around 27% for resort hotel and greater than 40 % for city hotel.\n\n","ad762fbf":"### Categorical Variables :","0876cf40":"# 3. Evaluate results (Naiv)\n","63010182":"* Deposit type has 3 categories - No Deposit, refundable, Non Refund\n* Either customers have opted for no deposit or non refundable deposits.\n* Maybe refundable deposit type is not offered by the hotels.\n* All of the non refund bookings have been cancelled in our dataset. That might prove important feature based on how many such   bookings are part of cancelled bookings.\n* No hotel has refundable deposit type\n\n* In city hotel is more common Non Refund deposit policy ","c560add8":"### Special Requests","8e6fa625":"## Shapes of the various data :","392726ac":"### 0.3 Reading the Datase","9ef5e85f":"* Delete reservation_status & reservation_status_date","a5f1430e":"# Conclusions:\n### We've tried to predict hotel reservation cancellations, and achieved a nice score of 90% (using the best module - Random Forest). We've shown interesting human-decision making facts which impact the cacellation rate, such as:\n1. Lead time (the delta time from reservation to expected arrvial date) - key features. People don't have control of time and can't assure their status. Today, we see many advertisment with a cancellation option till a few days before the arrival date. This allows people to order with no guarantee. \n2. Special requests - people with special requests may be less stable and more pedant to find their exact requirements.\n3. City hotel vs Resort hotel - it's easier to cancel a business trip than a family trip. People use the hotel as a base to the entire trip. \n","d6c65a71":"* The vast majority of orders are with zero babys\n* Those who did book with a baby usually booked for a single baby\n* Most people do not change their order","f4bceb01":"* Week 30 is the most popular week for August bookings (holiday)\n* Earlier lead time is more common\n* Most visitors do not make special requests","314f24eb":"###  Class distribution","236e5f62":"* It can be seen that the order of the amount of orders in market segment does change in cancellations filter:\n<br> **from -** \n<br> &emsp; Online TA -> Offline TA -> Groups -> Direct -> Corporate\n<br> **To -**\n<br> &emsp; Online TA -> **Groups** -> **Offline TA** -> Direct -> Corporate\n\n#### It is possible that order in a group increased the chances of cancellations\n","28059b98":"### Reservation status vs Cancellations","81979136":"#### There is a strong connection between the number of requests and the cancellations\n* The more requests there are the chance of cancellation decreases significantly\n* One request is enough to greatly reduce the chance of cancellation","32e0761e":"### Replace missing value","a5635e44":"### Comparison True positive, false positive..","c0399842":"### Hot_data :\n* From 20 colume to 259 \n* Delete reservation_status\n* The features are now independent of the order","a37f6d91":"### Customer profile vs Cancellations","f8daf10e":"* A strong connection can be seen between the two features\n* **Because this is the feature we predict we will delete it at the cleaning stage**","2411149f":"## A combination of the two features","c83fcc69":"## Data Info :","ecd2f3b4":"### Create Combination Data (clean data) :\n* Arrival date month - to number (save the order)\n* All ohter is hot vector","08939748":"### Numeric Variables :","2bae0ac9":"#### At this stage, we will examine only the numerical features (later we will convert additional features)\n\n#### The must strong connections are between cancelesion and this features:\n* lead_time \n* total_of_special_requests\n* required_car_parking_spaces\n* previous_cancellations","9626798c":"* can assume that null is represents no children\n* missing countries can be labeled unknown\n* missing agent ID can be zero, presuming the booking was made privately\n* missing company ID can be zero (for the same reason as agent ID)\n","b0f0954c":"## Imports","9c1afada":"### Columns & Data types","97cbaff5":"### Interestng: Resort hotels have a lower canceellation rate. This makes sense, since a Resort hotel is usually for beneficial purposes, while a City hotel is a business-type or practcial place to nest. It can be assumed that a resort hotel is part of a larger trip plan, and therefore more stable. ","bb173315":"### 0.2 Import Python Libraries","c0ab545f":"#### Binary Variables :","9c29795f":"* There does not appear to be a direct link between the customer profile and the cancellations.\n* We will later choose to try and convert these features to a single feature (After cleaning and arranging)","dcb72c30":"## Introducing the various features :\n","68a66fc8":"### The following plot shows the two points presented earlier\n* Relationship between the number of requests and cancellations\n* Relationship between order time and cancellations\n\n### In the plot it can be seen that looking at the two features together allows for understanding (partial prediction) at a higher probability.\n* The sheer majority of the blue dots in the lower right quarter of the graph","900dfda9":"* reserved_room_type and assigned_room_type similar, We will examine later the option to unify or download one of them\n* Agent 9 is the most popular\n* We will present the orders by months in a more orderly manner below\n* The most common meal is BB (Bed & Breakfast)","1046a836":"#### Distribution of lead time:","30d10419":"### Size of the Dataset","c1781ba1":"## Activating the simple model\n","97af5b4e":"* Arrival time is kind of uniform distributed, the most popular is arrival at the end of the month\n* At 2016 was most of the arrival\n* There are 236 different companies (id) where some of the data in them is null\n\n#### Some of the plots are not informative so we will show them more plots:","1af4a1e1":"### Create combination data of hot vector and numbers","5b4cf9b3":"## Depth analysis of the strong bond (nunrical feature) :","ae269e24":"#### There are 32 columns.\n* 12 Categorical\n* 20 Numerical\n\n#### There are 4 columns with the missing values-\n* country\n* agent\n* company\n* children","af566839":"TODO Comparative Visualizations To Cancellation : (The categorical features)","4bb43af3":"#### ADR - Average Daily Rate\n    Calculated by dividing the sum of all lodging transactions by the total number of staying nights\n* Can see an average in the 95 range and most of the data is between 90 and 115\n* There is a some data that is considered extreme (over 210)","05c71e17":"* There are extreme values - people who have booked for more than 5 weeks (over a month)\n* The avarge pf stay in weekend is 1.19 day and weekday is 3.13\n* More than 25 percent order 2 days a week","a441f481":"### Customer type vs Cancellations","8940e1b9":"* Most hotels are City hotel: 66% \n* The vast majority of customers are not repeat visitors\n* In the most of the hotel no policy of diposit\n* Most of thr custumer are transient (when the booking is not part of a group or contract)\n* The most poplar Distribution Channel is \u201cTA\u201d means \u201cTravel Agents\u201d and \u201cTO\u201d means \u201cTour Operators\u201d","480e579d":"## Feature Engineering & Clean The Data ( part 2 ) :","b3aace1a":"recall ->As expected no higher recall was canceled\nbalanced -> make priecision to be higher \n","60aa1973":"* PRT or Portugal has the most booking demand based on the data (more than 60%). It is pretty obvious because if we trace to the publication page, the description tells us that the data source locations are from hotels located in Portugal.","cc5db9cd":"* It seems there's no differences in cancellations between the years. This data set doesn't include Covid-19 which probablly had large impact on these results.","29ffb3fd":"#### High dependence between reservation_status and is_canceled  (0.980601)","5f7c02f2":"# 4. The improved model \n","5f3a0ee8":"### Data Statistics","0f070b50":"### 0.1 install libraries","5ed47661":"#### Arrival week number","9a8b3bf3":"## Clean The Data ( part 1 ) :"}}