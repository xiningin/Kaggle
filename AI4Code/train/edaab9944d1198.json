{"cell_type":{"6923e627":"code","ad4c680a":"code","d802dfed":"code","2c9cbc32":"code","ed0111c4":"code","9978a896":"code","179a84db":"code","4afbd452":"markdown"},"source":{"6923e627":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ad4c680a":"pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')","d802dfed":"from mlxtend.data import iris_data\nfrom mlxtend.preprocessing import standardize\nfrom mlxtend.feature_extraction import LinearDiscriminantAnalysis\n\nX, y = iris_data()\nX = standardize(X)\n\nlda = LinearDiscriminantAnalysis(n_discriminants=2)\nlda.fit(X, y)\nX_lda = lda.transform(X)","2c9cbc32":"import matplotlib.pyplot as plt\n\nwith plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(6, 4))\n    for lab, col in zip((0, 1, 2),\n                        ('blue', 'red', 'green')):\n        plt.scatter(X_lda[y == lab, 0],\n                    X_lda[y == lab, 1],\n                    label=lab,\n                    c=col)\n    plt.xlabel('Linear Discriminant 1')\n    plt.ylabel('Linear Discriminant 2')\n    plt.legend(loc='lower right')\n    plt.tight_layout()\n    plt.show()","ed0111c4":"from mlxtend.data import iris_data\nfrom mlxtend.preprocessing import standardize\nfrom mlxtend.feature_extraction import LinearDiscriminantAnalysis\n\nX, y = iris_data()\nX = standardize(X)\n\nlda = LinearDiscriminantAnalysis(n_discriminants=None)\nlda.fit(X, y)\nX_lda = lda.transform(X)","9978a896":"import numpy as np\n\ntot = sum(lda.e_vals_)\nvar_exp = [(i \/ tot)*100 for i in sorted(lda.e_vals_, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)","179a84db":"with plt.style.context('seaborn-whitegrid'):\n    fig, ax = plt.subplots(figsize=(6, 4))\n    plt.bar(range(4), var_exp, alpha=0.5, align='center',\n            label='individual explained variance')\n    plt.step(range(4), cum_var_exp, where='mid',\n             label='cumulative explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.xticks(range(4))\n    ax.set_xticklabels(np.arange(1, X.shape[1] + 1))\n    plt.legend(loc='best')\n    plt.tight_layout()","4afbd452":"http:\/\/rasbt.github.io\/mlxtend\/user_guide\/feature_extraction\/LinearDiscriminantAnalysis\/"}}