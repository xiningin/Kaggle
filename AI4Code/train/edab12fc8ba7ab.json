{"cell_type":{"aaf47477":"code","4575a09a":"code","88f8c7c4":"code","0be6630b":"code","04de3f37":"code","23d52ebf":"code","e89b23dd":"code","b2f6004f":"code","ca659aa4":"code","ab3e0129":"code","f2bd87a8":"code","e7c63e85":"markdown","6980eba6":"markdown","26564e32":"markdown","4da9ea5d":"markdown","f9066863":"markdown","62c5a757":"markdown","96181452":"markdown","7669c196":"markdown","56bcb2b0":"markdown","a377cc54":"markdown","869c5a84":"markdown","e4621b72":"markdown","383b4856":"markdown","44489390":"markdown","371ee182":"markdown","fa8bdc7a":"markdown","d9791697":"markdown","35ce348c":"markdown","aff59452":"markdown","d58ba488":"markdown","f24c31fa":"markdown","0e6290e2":"markdown"},"source":{"aaf47477":"!pip install git+git:\/\/github.com\/neurostuff\/NiMARE.git@608516ec3034e356326dfe70df5e9ed77efd2be8\nimport os\nimport json\nimport numpy as np\nimport nibabel as nb\nimport tempfile\nfrom glob import glob\nfrom os.path import basename, join, dirname, isfile\n\nimport pandas as pd\nimport nibabel as nib\nimport pylab as plt\nfrom scipy.stats import t\nfrom nilearn.masking import apply_mask\nfrom nilearn.plotting import plot_stat_map\n\nimport nimare\nfrom nimare.meta.ibma import (stouffers, fishers, weighted_stouffers,\n                              rfx_glm, ffx_glm)\nfrom nimare.utils import t_to_z","4575a09a":"pd.read_csv('..\/input\/coordinates.csv').head()","88f8c7c4":"pd.read_csv('..\/input\/studies.csv').head()","0be6630b":"dset_dict = {}\ncoords_df = pd.read_csv('..\/input\/coordinates.csv')\nfor i, row in pd.read_csv('..\/input\/studies.csv').iterrows():\n    this_study_coords = coords_df[coords_df['study_id'] == row[0]]\n    contrast = {\"sample_sizes\": [row[1]],\n                \"coords\": { \"space\": this_study_coords['space'].unique()[0],\n                            \"x\": list(this_study_coords['x']),\n                            \"y\": list(this_study_coords['y']),\n                            \"z\": list(this_study_coords['z'])}}\n    dset_dict[row[0]] = {\"contrasts\": {\"1\": contrast }}\nwith tempfile.NamedTemporaryFile(mode='w', suffix=\".json\") as fp:\n    json.dump(dset_dict, fp)\n    fp.flush()\n    db = nimare.dataset.Database(fp.name)\n    dset = db.get_dataset()\nmask_img = dset.mask","04de3f37":"dset.data['pain_01']","23d52ebf":"ale = nimare.meta.cbma.ALE(dset, ids=dset.ids)\nale.fit(n_iters=10)\nplot_stat_map(ale.results.images['ale'], cut_coords=[0, 0, -8],\n              draw_cross=False, cmap='RdBu_r', figure=plt.figure(figsize=(18,4)))\nplot_stat_map(ale.results.images['z_vfwe'], cut_coords=[0, 0, -8],\n              draw_cross=False, cmap='RdBu_r', figure=plt.figure(figsize=(18,4)))","e89b23dd":"mkda = nimare.meta.cbma.MKDADensity(dset, ids=dset.ids, kernel__r=10)\nmkda.fit(n_iters=10)\nplot_stat_map(mkda.results.images['vfwe'], cut_coords=[0, 0, -8],\n              draw_cross=False, cmap='RdBu_r', figure=plt.figure(figsize=(18,4)))","b2f6004f":"z_imgs = []\nsample_sizes = []\nfor study in dset_dict.keys():\n    z_map_path = \"..\/input\/stat_maps\/%s.nidm\/ZStatistic_T001.nii.gz\"%study\n    t_map_path = \"..\/input\/stat_maps\/%s.nidm\/TStatistic.nii.gz\"%study\n    sample_size = dset_dict[study][\"contrasts\"][\"1\"][\"sample_sizes\"][0]\n    if os.path.exists(z_map_path):\n        z_imgs.append(nb.load(z_map_path))\n        sample_sizes.append(sample_size)\n    elif os.path.exists(t_map_path):\n        t_map_nii = nb.load(t_map_path)\n        # assuming one sided test\n        z_map_nii = nb.Nifti1Image(t_to_z(t_map_nii.get_fdata(), sample_size-1), t_map_nii.affine)\n        z_imgs.append(z_map_nii)\n        sample_sizes.append(sample_size)\n        \nz_data = apply_mask(z_imgs, mask_img)\nsample_sizes = np.array(sample_sizes)","ca659aa4":"for z_img in z_imgs[:5]:\n    plot_stat_map(z_img, threshold=0, cut_coords=[0, 0, -8], \n                  draw_cross=False, figure=plt.figure(figsize=(18,4)))","ab3e0129":"result = fishers(z_data, mask_img)\nplot_stat_map(result.images['ffx_stat'], threshold=0,\n              cut_coords=[0, 0, -8], draw_cross=False,\n              figure=plt.figure(figsize=(18,4)))\nplot_stat_map(result.images['log_p'], threshold=-np.log(.05),\n              cut_coords=[0, 0, -8], draw_cross=False,\n              cmap='RdBu_r', figure=plt.figure(figsize=(18,4)))","f2bd87a8":"result = weighted_stouffers(z_data, sample_sizes, mask_img)\nplot_stat_map(result.images['log_p'], threshold=-np.log(.05),\n              cut_coords=[0, 0, -8], draw_cross=False,\n              cmap='RdBu_r', figure=plt.figure(figsize=(18,4)))","e7c63e85":"# Exploring the data\nThis tutorial assumes that you did literature review and extracted coordinates of peaks of activation from relevant papers. Those could be saved in spreadsheeta (or CSV files). In our case we have to CSV files. One with all of the coordinates:","6980eba6":"## Weighted Stouffer's\nWe can use sample_sizes to perform a weighted version of the above analysis.","26564e32":"Before using NiMARE we need to prepare the data in a format the library expects","4da9ea5d":"## Get z-maps\nHere'we are going to prepare the maps for analysis. All maps will be masked and converted to numpy arrays. T maps will be converted to Z maps.","f9066863":"Note that we are only using 10 interations in permutation testing to speed things up. Normally you would use ~10,000 permutations to accuratelly establish the null distribution.","62c5a757":"**Excercise: how many coordinates are there per study?**","96181452":"Lets have a look at some of the  individual maps.","7669c196":"# Image based meta-analysis","56bcb2b0":"Want to explore more coordinate based data? Check out https:\/\/www.kaggle.com\/chrisfilo\/neurosynth","a377cc54":"So far we used only coordinates of peaks. This is a massive data reduction if you take into account the amount of data acquired by the scanner. How would the results of the analysis look if we had access to the underlying statistical maps?","869c5a84":"An alternative to ALE is convolving with solid spheres and accounting for overlaps. This is known as the MKDA method","e4621b72":"**Excercise: adjust the sample sizes to influence the weighted analysis.**","383b4856":"We will start with using coordinates of peaks and convolving them with gaussians. This is also known as the ALE method. First image is before statistical inference and the second is showing only statistically significant regions.","44489390":"Tutorial adapted from [NiMARE examples](https:\/\/github.com\/neurostuff\/NiMARE\/blob\/98dd69b7b637ab61c90a8de0f45b36cdadc8154a\/examples\/nidm_pain_meta-analyses.ipynb)  prepared by Taylor Salo. ","371ee182":"The results in this particular example are vey similar.","fa8bdc7a":"**Before you begin please make sure your kernel is [Internet connected](https:\/\/www.kaggle.com\/product-feedback\/63544)**","d9791697":"## Fisher's","35ce348c":"**Excercise: does this method distinguish positive and negative activation? Could you plot such map?**","aff59452":"## MKDA","d58ba488":"## ALE","f24c31fa":"...and one with information about the studies:","0e6290e2":"# Coordinate based meta-analysis"}}