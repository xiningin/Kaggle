{"cell_type":{"d5d9e386":"code","7faa414a":"code","5bd6546b":"code","ad686310":"code","ab480f6a":"code","1697906b":"code","280d3e4d":"code","1a18923c":"code","bc9b2345":"code","4c043f32":"code","f53e5965":"code","e836f7ad":"code","af371cd7":"code","24197f5d":"code","a2949cee":"code","9d61423f":"code","aa5eb2ff":"code","1835138c":"code","cb7b52ac":"code","5e8006ea":"code","bcfd2e99":"code","b922a148":"code","302f0904":"code","65b87e2b":"code","882d34c2":"code","dc409abc":"markdown","090600c2":"markdown"},"source":{"d5d9e386":"!pip install git+https:\/\/github.com\/keras-team\/keras-applications.git -q","7faa414a":"import keras_applications as ka\ndef set_to_tf(ka):\n    from tensorflow.keras import backend, layers, models, utils\n    ka._KERAS_BACKEND = backend\n    ka._KERAS_LAYERS = layers\n    ka._KERAS_MODELS = models\n    ka._KERAS_UTILS = utils\n    \n    \nset_to_tf(ka)","5bd6546b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import Model\n# import tensorflow.keras.applications.efficientnet as efn\nfrom tensorflow.keras.applications import Xception, ResNet50V2\nimport os, cv2\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","ad686310":"df = pd.read_csv('..\/input\/hpa-csv-file\/hpa_csv.csv')\ndisplay(df.head(5))\nprint(df.shape)","ab480f6a":"def load(file):\n    img= cv2.imread(file)\n    img= cv2.resize(img, (600, 600))\n    return img\n\ndef show(df, sub_dir= 'train\/'):\n    df= df.iloc[0:12, :]\n    f, ax= plt.subplots(2, 6, figsize=(18, 4))\n    for i, row in df.iterrows():\n        file= '..\/input\/hpaimage512-data\/TarName\/' + sub_dir + row['ID'] + '.jpg'\n        img= load(file)\n        ax[i\/\/6][i%6].imshow(img, aspect='auto')\n        try:\n            ax[i\/\/6][i%6].set_title(row['Label'])\n        except:\n            pass\n        ax[i\/\/6][i%6].set_xticks([]); ax[i\/\/6][i%6].set_yticks([])\n    plt.suptitle(sub_dir[:-1].capitalize(), size= 20)\n    plt.show()\n        ","1697906b":"show(df)","280d3e4d":"show(pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv'), sub_dir='test\/')","1a18923c":"target_cols = df.drop(['ID','Label'], axis=1).columns.to_list()","bc9b2345":"############# CONFIG ##############\n\nn_classes = len(target_cols)\nimg_size = 300\nn_epochs = 30\nlr= 0.001\nseed= 35\nbatch_size=14","4c043f32":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy","f53e5965":"'''\nReference\nhttps:\/\/www.kaggle.com\/xhlulu\/ranzcr-efficientnet-tpu-training\n\n'''\n\ndef build_decoder(with_labels=True, target_size=(img_size, img_size), ext='jpg'):\n    def decode(path):\n        #print(path)\n        file_bytes = tf.io.read_file(path) # Reads and outputs the entire contents of the input filename.\n\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3) # Decode a PNG-encoded image to a uint8 or uint16 tensor\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3) # Decode a JPEG-encoded image to a uint8 tensor\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) \/ 255.0 # Casts a tensor to the type float32 and divides by 255.\n        img = tf.image.resize(img, target_size) # Resizing to target size\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_contrast(img, 0.9, 1.2)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO) # overlaps data preprocessing and model execution while training\n    return dset\n","e836f7ad":"COMPETITION_NAME = \"hpaimage512-data\"\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)\nGCS_DS_PATH","af371cd7":"strategy = auto_select_accelerator()\nbatch_size = strategy.num_replicas_in_sync * batch_size\nprint('batch size', batch_size)","24197f5d":"paths = GCS_DS_PATH + \"\/TarName\/train\/\" + df['ID'] + '.jpg'\n\n# Get the multi-labels\nlabels = df.iloc[:, 2:].values\nlabels.shape","a2949cee":"# Train test split\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(paths, labels, test_size=0.12, random_state=seed)\nprint(train_paths.shape, valid_paths.shape)\ntrain_labels.sum(axis=0), valid_labels.sum(axis=0)","9d61423f":"# Build the tensorflow datasets\n\ndecoder = build_decoder(with_labels=True, target_size=(img_size, img_size))\n\n# Build the tensorflow datasets\ndtrain = build_dataset(\n    train_paths, train_labels, bsize=batch_size, decode_fn=decoder\n)\n\ndvalid = build_dataset(\n    valid_paths, valid_labels, bsize=batch_size, \n    repeat=False, shuffle=False, augment=False, decode_fn=decoder\n)","aa5eb2ff":"def build_model():\n    inp = layers.Input(shape = (img_size, img_size, 3))\n    base = ka.efficientnet.EfficientNetB3(input_shape=(img_size, img_size, 3),weights='imagenet',\n                                                include_top=False)\n    \n    x= base(inp)\n    x= layers.GlobalAveragePooling2D()(layers.Dropout(0.1)(x))\n    x= layers.Dropout(0.3)(x)\n    x= layers.Dense(n_classes, 'sigmoid')(x)\n    \n    return Model(inp, x)\n    ","1835138c":"with strategy.scope():\n    model= build_model()\n    loss= tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0)\n    model.compile(optimizers.Adam(lr=lr),loss=loss,metrics=[tf.keras.metrics.AUC(multi_label=True)])","cb7b52ac":"model.summary()","5e8006ea":"tf.keras.utils.plot_model(model, show_shapes=True)","bcfd2e99":"rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n                                min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n        \nckp = ModelCheckpoint('hpa_effb3.h5',monitor = 'val_loss',\n                      verbose = 1, save_best_only = True, mode = 'min')\n        \nes = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                    restore_best_weights = True, verbose = 1)","b922a148":"steps_per_epoch = train_paths.shape[0] \/\/ batch_size\nsteps_per_epoch","302f0904":"history = model.fit(dtrain,                      \n                    validation_data=dvalid,                                       \n                    epochs=n_epochs,\n                    callbacks=[rlr,es,ckp],\n                    steps_per_epoch=steps_per_epoch,\n                    verbose=1)","65b87e2b":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.plot( history.history[\"loss\"], label = \"Training Loss\", marker='o')\nplt.plot( history.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","882d34c2":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"AUC\")\nplt.plot( history.history[\"auc\"], label = \"Training AUC\" , marker='o')\nplt.plot( history.history[\"val_auc\"], label = \"Validation AUC\", marker='+')\nplt.grid(True)\nplt.legend()\nplt.show()","dc409abc":"<h1 style=\"font-family:verdana;\"> <center>Human Protein Atlas - Single Cell Classification\ud83c\udf96 <\/center> <\/h1>\n\n<h3><center style=\"color:#159364; font-family:cursive;\">Training Notebook \ud83e\uddbe<\/center><\/h3>\n\n\n","090600c2":"\n\n## \ud83c\udf04 Thanks for Reading\n\n![](https:\/\/i.gifer.com\/7ImI.gif)\n\n\n\n<div class=\"alert alert-block alert-info\" style=\"font-size:20px; font-family:verdana;\">\n <a target=\"_blank\" style=\"color:orange;\">Do UPVOTE for more Motivation\ud83e\udd1e<\/a>\n<\/div>\n\n\n\n<hr><hr><hr>\n\n<hr>"}}