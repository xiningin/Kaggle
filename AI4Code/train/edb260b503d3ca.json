{"cell_type":{"6ed4b960":"code","63cb3ce9":"code","e1ca682a":"code","c950bda8":"code","015e4a6b":"code","7c11a743":"code","7a6cf365":"code","527e0d22":"code","126a0897":"code","ded50621":"code","ea50b641":"code","f99348c4":"markdown","05ae6dc9":"markdown","bd5d5cb4":"markdown","c38d4482":"markdown","c4d5ee0b":"markdown","1450d265":"markdown","37b6840e":"markdown","b01a47c1":"markdown","cd28ca75":"markdown","e78a39e9":"markdown","342a8d87":"markdown"},"source":{"6ed4b960":"import glob\n\n# \u4e86\u89e3\u6570\u636e\u96c6\u7684\u7ec4\u6210\n\ntrain_files = glob.glob('\/kaggle\/input\/dogs-vs-cats\/train\/train\/*')\ntest_files = glob.glob('\/kaggle\/input\/dogs-vs-cats\/test1\/test1\/*')\n\ntrain_cat_files = [file_name for file_name in train_files if 'cat' in file_name]\ntrain_dog_files = [file_name for file_name in train_files if 'dog' in file_name]\n\nprint('train samples of cat:', len(train_cat_files))\nprint('train samples of dog:', len(train_dog_files))\nprint( train_dog_files[0])\n","63cb3ce9":"import numpy as np\nfrom random import shuffle\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.preprocessing import LabelEncoder\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d61500\u5f20\u8bad\u7ec3\u6837\u672c\ncat_train = list(np.random.choice(train_cat_files, size=1500, replace=False))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d61500\u5f20\u8bad\u7ec3\u6837\u672c\ndog_train = list(np.random.choice(train_dog_files, size=1500, replace=False))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u8bad\u7ec3\u6837\u672c\ntrain_cat_files = list(set(train_cat_files) - set(cat_train))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u8bad\u7ec3\u6837\u672c\ntrain_dog_files = list(set(train_dog_files) - set(dog_train))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6821\u9a8c\u6837\u672c\ncat_val = list(np.random.choice(train_cat_files, size=500, replace=False))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6821\u9a8c\u6837\u672c\ndog_val = list(np.random.choice(train_dog_files, size=500, replace=False))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u6821\u9a8c\u6837\u672c\ntrain_cat_files = list(set(train_cat_files) - set(cat_val))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u5254\u9664\u5df2\u7ecf\u62bd\u53d6\u7684\u6821\u9a8c\u6837\u672c\ntrain_dog_files = list(set(train_dog_files) - set(dog_val))\n\n# \u4ece\u732b\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6d4b\u8bd5\u6837\u672c\ncat_test = list(np.random.choice(train_cat_files, size=500, replace=False))\n\n# \u4ece\u72d7\u8bad\u7ec3\u6570\u636e\u4e2d\u968f\u673a\u62bd\u53d6500\u5f20\u6d4b\u8bd5\u6837\u672c\ndog_test = list(np.random.choice(train_dog_files, size=500, replace=False))\n\n# \u5408\u5e76\u732b\u72d7\u8bad\u7ec3\u96c6\ntrain_files = cat_train + dog_train\n# \u5408\u5e76\u732b\u72d7\u6821\u9a8c\u96c6\nval_files = cat_val + dog_val\n# \u5408\u5e76\u732b\u72d7\u6d4b\u8bd5\u96c6\ntest_files = cat_test + dog_test\n\n# \u968f\u673a\u5316\u732b\u72d7\u8bad\u7ec3\u96c6\nshuffle(train_files)\n\n# \u6837\u672c\u5c3a\u5bf8\nIMG_DIM = (150, 150)\n# \u4ece\u78c1\u76d8\u52a0\u8f7d\u8bad\u7ec3\u96c6\nx_train = np.array([img_to_array(load_img(image_file, target_size=IMG_DIM)) for image_file in train_files])\n# \u4ece\u78c1\u76d8\u52a0\u8f7d\u6821\u9a8c\u96c6\nx_val = np.array([img_to_array(load_img(image_file, target_size=IMG_DIM)) for image_file in val_files])\n# \u4ece\u78c1\u76d8\u52a0\u8f7d\u6d4b\u8bd5\u96c6\nx_test = np.array([img_to_array(load_img(image_file, target_size=IMG_DIM)) for image_file in test_files])\n\n# \u5c06\u8bad\u7ec3\u96c6\u5217\u8868\u8f6c\u6362\u4e3anumpy\u77e9\u9635\nx_train = np.array(x_train)\n# \u5c06\u6821\u9a8c\u96c6\u5217\u8868\u8f6c\u6362\u4e3anumpy\u77e9\u9635\nx_val = np.array(x_val)\n# \u5c06\u6d4b\u8bd5\u96c6\u5217\u8868\u8f6c\u6362\u4e3anumpy\u77e9\u9635\nx_test = np.array(x_test)\n\n# \u6807\u7b7e\u7f16\u7801\ntrain_labels = [fn.split('\/')[-1].split('.')[0].strip() for fn in train_files]\nval_labels = [fn.split('\/')[-1].split('.')[0].strip() for fn in val_files]\ntest_labels = [fn.split('\/')[-1].split('.')[0].strip() for fn in test_files]\nle = LabelEncoder()\nle.fit(train_labels)\ny_train = le.transform(train_labels)\ny_val = le.transform(val_labels)\ny_test = le.transform(test_labels)\n\n\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint('x_validate shape:', x_val.shape)\nprint('y_validate shape:', y_val.shape)\nprint('x_test shape:', x_test.shape)\nprint('y_test shape:', y_test.shape)","e1ca682a":"import matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')\n\nval_datagen = ImageDataGenerator(rescale=1.\/255)\n\nimg_id = 3\ncat_generator = train_datagen.flow(x_train[img_id:img_id+1], train_labels[img_id:img_id+1],\n                                   batch_size=1)\ncat = [next(cat_generator) for i in range(0,5)]\nfig, ax = plt.subplots(1,5, figsize=(16, 6))\nprint('Labels:', [item[1][0] for item in cat])\nl = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]","c950bda8":"img_id = 5\ncat_generator = train_datagen.flow(x_train[img_id:img_id+1], train_labels[img_id:img_id+1],\n                                   batch_size=1)\ncat = [next(cat_generator) for i in range(0,5)]\nfig, ax = plt.subplots(1,5, figsize=(16, 6))\nprint('Labels:', [item[1][0] for item in cat])\nl = [ax[i].imshow(cat[i][0][0]) for i in range(0,5)]","015e4a6b":"from keras.applications import vgg16\nfrom keras.models import Model\nimport keras\ninput_shape = (150, 150, 3)\nvgg = vgg16.VGG16(include_top=False, weights='imagenet', \n                                     input_shape=input_shape)\n\noutput = vgg.layers[-1].output\noutput = keras.layers.Flatten()(output)\nvgg_model = Model(vgg.input, output)\n\nvgg_model.trainable = False\nfor layer in vgg_model.layers:\n    layer.trainable = False\n    \nimport pandas as pd\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) \n\n","7c11a743":"train_imgs_scaled = x_train.astype('float32')\ntrain_imgs_scaled \/= 255.0\nbottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1])\nprint(bottleneck_feature_example.shape)\nplt.imshow(bottleneck_feature_example[0][:,:,0])","7a6cf365":"def get_bottleneck_features(model, input_imgs):\n    features = model.predict(input_imgs, verbose=0)\n    return features\n\ntrain_imgs_scaled = x_train.astype('float32')\ntrain_imgs_scaled \/= 255.0\nvalidation_imgs_scaled = x_val.astype('float32')\nvalidation_imgs_scaled \/= 255.0\n\ntrain_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)\nvalidation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)\n\nprint('Train Bottleneck Features:', train_features_vgg.shape, \n      '\\tValidation Bottleneck Features:', validation_features_vgg.shape)\n\n","527e0d22":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\nfrom keras.models import Sequential\nfrom keras import optimizers\n\ninput_shape = vgg_model.output_shape[1]\n\nmodel = Sequential()\nmodel.add(InputLayer(input_shape=(input_shape,)))\nmodel.add(Dense(512, activation='relu', input_dim=input_shape))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['accuracy'])\n\nmodel.summary()","126a0897":"batch_size = 30\nepochs = 30\nhistory = model.fit(x=train_features_vgg, y=y_train,\n                    validation_data=(validation_features_vgg, y_val),\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1)","ded50621":"import matplotlib.pyplot as plt\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Pre-trained CNN Transfer Learn Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,31))\nax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\nax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, 31, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch #')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, history.history['loss'], label='Train Loss')\nax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, 31, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch #')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","ea50b641":"model.save('cats_dogs_basic_cnn_re_tl.h5')","f99348c4":"### \u4e94\u3001\u8f93\u51favgg16\u7f51\u7edc\u6241\u5e73\u5c42\u4fe1\u606f\n\n\u3000\u3000\u7528vgg16\u7f51\u7edc\u6241\u5e73\u5c42\u8f93\u51fa\u4f5c\u4e3a\u6211\u4eec\u81ea\u5df1\u7f51\u7edc\u7684\u8f93\u5165\u3002","05ae6dc9":"## \u3000\u4f60\u53ef\u4ee5\u6e05\u695a\u5730\u89c2\u5bdf\u52302\u20133\u8d9f\u8bad\u7ec3\u540e\u6a21\u578b\u5f00\u59cb\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\u51fa\u73b0\u62df\u5408\u3002\u8be5\u6a21\u578b\u5728\u6821\u9a8c\u96c6\u7684\u5206\u7c7b\u51c6\u786e\u7387\u5927\u7ea6\u4e3a90%\uff0c\u867d\u7136\u4e0d\u5b8c\u7f8e\uff0c\u4f46\u6709\u6240\u8fdb\u6b65\uff01\u6211\u4eec\u8fd8\u80fd\u591f\u6539\u8fdb\u8be5\u6a21\u578b\u5417\uff1f","bd5d5cb4":"### \u56db\u3001\u4f7f\u7528vgg16\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\n\n\u3000\u3000vgg16\u7f51\u7edc\u5404\u5c42\u53c2\u6570\u56fa\u5b9a\u3002","c38d4482":"### \u4e03\u3001\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\u3000\u3000\u6307\u5b9a\u8bad\u7ec3\u6570\u636e\u3001\u6821\u9a8c\u6570\u636e\uff0c\u6bcf\u6279\u6837\u672c\u6570\u91cf\u3001\u8bad\u7ec3\u8d9f\u6570\u3001\u56de\u663e\u7ea7\u522b\u3002 ","c4d5ee0b":"### \u4e00\u3001\u4e86\u89e3\u6570\u636e\u96c6\n\n\u3000\u3000\u8be5\u6570\u636e\u96c6\u4e3a\u732b\u72d7\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u96c6\u753150000\u5f20\u7167\u7247\uff08\u5176\u4e2d\u732b25000\u5f20\uff0c\u72d725000\u5f20\uff09\uff0c\u6d4b\u8bd5\u96c625000\u5f20\u7167\u7247\uff08\u5176\u4e2d\u5176\u4e2d\u732b12500\u5f20\uff0c\u72d712500\u5f20\uff09\u3002","1450d265":"### \u4e5d\u3001\u4fdd\u5b58\u6a21\u578b\n\u3000\u3000\u4fdd\u5b58\u6a21\u578b\u4ee5\u4fbf\u540e\u9762\u6211\u4eec\u7528\u6d4b\u8bd5\u96c6\u5bf9\u8be5\u6a21\u578b\u7684\u6027\u80fd\u8fdb\u884c\u8bc4\u4f30\u3002","37b6840e":"# \u8fc1\u79fb\u5b66\u4e60\u6848\u4f8b\u7814\u7a76\n# \u56db\u3001\u6570\u636e\u589e\u5f3a\uff1a\u8fc1\u79fb\u5b66\u4e60\uff0c\u4f7f\u7528vgg16\u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u5668\n## \u6570\u636e\u96c6\u6837\u672c\u6570\u91cf\u53d7\u9650\u7684\u8fc1\u79fb\u5b66\u4e60\uff08\u4f7f\u7528kaggle Dogs vs. Cats\u6570\u636e\u96c6\uff09\n","b01a47c1":"### \u4e8c\u3001\u6784\u5efa\u5c0f\u6570\u636e\u96c6\n\n\u3000\u3000\u73b0\u5728\u6211\u4eec\u6784\u9020\u4e00\u4e2a\u5c0f\u578b\u6570\u636e\u96c6\uff0c\u5373\u8bad\u7ec3\u56fe\u50cf\u5305\u542b3000\u5f20\u56fe\u7247\uff0c\u6821\u9a8c\u56fe\u50cf\u5305\u542b1000\u5f20\u56fe\u7247\uff0c\u6d4b\u8bd5\u56fe\u50cf\u5305\u542b1000\u5f20\u56fe\u7247\uff08\u6bcf\u7c7b\u4e2d\u732b\u72d7\u56fe\u7247\u6570\u91cf\u76f8\u540c\uff09\u3002","cd28ca75":"### \u4e09\u3001\u6570\u636e\u589e\u5f3a\n\n\u3000\u3000\u5b9a\u4e49\u6570\u636e\u589e\u5f3a\u5668\uff0c\u76f4\u89c2\u6d4b\u8bd5\u589e\u5f3a\u7684\u6837\u672c\u6548\u679c\u3002","e78a39e9":"### \u516d\u3001\u5b9a\u4e49\u8fc1\u79fb\u5b66\u4e60\u7f51\u7edc\u6a21\u578b","342a8d87":"### \u516b\u3001\u7ed8\u5236\u6a21\u578b\u8bad\u7ec3\u7684\u51c6\u786e\u5ea6\u548c\u635f\u5931\u56fe\n\u3000\u3000\u901a\u8fc7\u89c2\u5bdf\u8bad\u7ec3\u548c\u6821\u9a8c\u7684\u51c6\u786e\u5ea6\uff0c\u7f51\u7edc\u6027\u80fd\u6709\u6240\u63d0\u5347\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed8\u5236\u6a21\u578b\u8bad\u7ec3\u7684\u51c6\u786e\u5ea6\u548c\u635f\u5931\u56fe\u6765\u76f4\u89c2\u53d1\u73b0\u62df\u5408\u95ee\u9898\u3002"}}