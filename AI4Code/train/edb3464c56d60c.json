{"cell_type":{"4badc3a6":"code","7b1a7fb4":"code","a0369211":"code","4b7375c5":"code","e3d09e44":"code","2183ae42":"code","0d423d57":"code","8bcbf371":"code","7505f286":"code","96a43e9c":"code","2f6b401f":"code","ff3a6d38":"code","06c7d9b7":"code","2d1c3160":"code","219f5e44":"code","296d8c06":"code","57b0ce73":"code","2680cf74":"code","53843dac":"code","57fd81ff":"code","0fb05457":"code","53ff24d0":"code","581e94da":"code","50b41e45":"code","d234ed22":"code","30a49249":"code","db95bbc7":"code","6bd20e19":"code","344fb875":"code","73bdf363":"code","bbde450b":"code","a1f5a5b2":"code","62bbb8ed":"code","22b58d98":"code","c5221384":"code","de9ae73c":"code","108f41ab":"code","9ba68ae5":"code","09f5f547":"code","e821d0f3":"code","79c7deb4":"code","7d8ece2a":"code","4c5f7d1e":"code","fd322893":"code","2cf27486":"code","4951ef04":"code","a866a23a":"code","5c5df1bc":"code","f474f16f":"code","25e4d72f":"code","ab85b6c9":"code","19cce0df":"code","a559bc75":"code","4f9a62b2":"code","aa1a8f6f":"code","27ea264b":"code","5f5e82fd":"code","5a7736d8":"markdown"},"source":{"4badc3a6":"# \u0426\u0435\u043b\u044c \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u0443\u0435\u043c\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438: \u043f\u043e \u0434\u0430\u043d\u043d\u044b\u043c \u0438\u0437 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0441\u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u043e\u0441\u0442\u044c \u043f\u0443\u0431\u043b\u0438\u043a\u0430\u0446\u0438\u0438. \n# \u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f: shares - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430, \u043e\u0442\u0440\u0430\u0436\u0430\u044e\u0449\u0430\u044f, \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0440\u0430\u0437 \u043f\u043e\u0434\u0435\u043b\u0438\u043b\u0438\u0441\u044c \u043f\u043e\u043b\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0438 \u043f\u0443\u0431\u043b\u0438\u043a\u0430\u0446\u0438\u0435\u0439.\n# \u0414\u0430\u0442\u0430\u0441\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u043f\u0443\u0431\u043b\u0438\u043a\u0430\u0446\u0438\u044f\u0445 \u043d\u0430 \u0441\u0430\u0439\u0442\u0430\u0445 (\u043d\u043e\u0432\u043e\u0441\u0442\u0438).\n# \u0414\u0430\u043d\u043d\u0430\u044f \u0437\u0430\u0434\u0430\u0447\u0430 - \u044d\u0442\u043e \u0437\u0430\u0434\u0430\u0447\u0430 \u0440\u0435\u0433\u0440\u0435\u0441\u0438\u0438. \u041f\u0440\u043e\u0433\u043d\u043e\u0437 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0441 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u043c\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\u043c\u0438. \u041d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435 \u0434\u043e\u043b\u0436\u043d\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c\u0441\u044f \u0432\u0435\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e.\n\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","7b1a7fb4":"df = pd.read_csv('..\/input\/online-news-popularity-dataset\/OnlineNewsPopularityReduced.csv', sep=',')\ndf.head()","a0369211":"df.head().T","4b7375c5":"df.info()","e3d09e44":"# drop'\u0430\u0435\u043c (\u0443\u0434\u0430\u043b\u044f\u0435\u043c) \u043d\u0435\u043d\u0443\u0436\u043d\u0443\u044e \u043a\u043e\u043b\u043e\u043d\u043a\u0443 \"url\". \ndf1 = df.drop(['url'], axis=1)\ndf1.head()","2183ae42":"df.describe().T","0d423d57":"#\u0418\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u043c\u0435\u043d\u043d\u0443\u044e. \u0420\u0430\u043d\u0435\u0435 \u043c\u044b \u0432\u044b\u044f\u0441\u043d\u0438\u0438\u043b\u0438, \u0447\u0442\u043e \u043f\u0435\u0440\u0435\u0434 \u043d\u0430\u043c\u0438 \u0437\u0430\u0434\u0430\u0447\u0430 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438.\ntarget = df1['shares']\ntarget","8bcbf371":"# \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u0443\u0435\u043c \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u043c\u0435\u043d\u043d\u0443\u044e.\nimport seaborn as sns\nsnsplot = sns.kdeplot(df['shares'], shade=True)\nfigure = snsplot.get_figure()","7505f286":"# \u041c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445.\nfrom sklearn.preprocessing import StandardScaler \nscaler = StandardScaler()\nStandardScaler(df1)","96a43e9c":"# \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e (\u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e).\nfrom sklearn.model_selection import train_test_split\nX = df1.drop(['min_negative_polarity', 'shares', 'max_negative_polarity'], axis=1)\ny = df1['shares']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size=0.3, random_state=42) \n\n","2f6b401f":"X_train.head()","ff3a6d38":"X_valid.head()","06c7d9b7":"y_train.head()","2d1c3160":"y_valid.head()","219f5e44":"train_test_split(y, shuffle=False)","296d8c06":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 KNeighborsRegressor.\n# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0433\u043e \u043c\u043d\u043e\u0436\u0435\u0441\u0442\u0432\u0430.\nfrom sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors = 10)\nneigh.fit(X_train, y_train)\ny_pred = neigh.predict(X_valid)\ny_pred\n","57b0ce73":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438.\nfrom sklearn.tree import DecisionTreeRegressor\ntree = DecisionTreeRegressor(random_state=42, max_depth = 5)\ntree.fit(X_train, y_train)","2680cf74":"# \u0421\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0435 \u0434\u0435\u0440\u0435\u0432\u043e.\nfrom sklearn.tree import export_graphviz\nexport_graphviz(tree, out_file='tree.dot', feature_names=X.columns)\nprint(open('tree.dot').read()) \n","53843dac":"#  \u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0441 \u043f\u043e\u043c\u043e\u0448\u044c\u044e mean_squared_error.\nfrom sklearn.metrics import mean_squared_error\nprint(\"\u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \",mean_squared_error(y_valid, y_pred))","57fd81ff":"tree.score(X_valid, y_valid)","0fb05457":"# \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u0438 \u043f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nKFold = KFold(n_splits=5, shuffle=True, random_state=42) \n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0438\u0432\u0430\u0435\u0442 \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043f\u0435\u0440\u0435\u0434 \u0441\u043e\u0437\u0434\u0430\u043d\u0438-\n#\u0435\u043c \u0431\u043b\u043e\u043a\u043e\u0432 ( shuffle=True ). \u0427\u0438\u0441\u043b\u043e \u0431\u043b\u043e\u043a\u043e\u0432 n_splits \u0440\u0430\u0432\u043d\u043e 5. \u0417\u0430\u0434\u0430\u0435\u043c \u0442\u0430\u043a\u0436\u0435\n#\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 random_state \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432. \u0412 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435 = 12.\n\n# \u0423\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u043b\u044f \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438.\nhyper_params = [{'n_features_to_select': list(range(1, 14))}]\n\n# \u0412\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043f\u043e\u0438\u0441\u043a \u043f\u043e \u0441\u0435\u0442\u043a\u0435.\n# \u0423\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c.\nlm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm)             \n\n# \u0412\u044b\u0437\u043e\u0432 GridSearchCV\nmodel_cv = GridSearchCV(estimator = rfe, \n                        param_grid = hyper_params, \n                        scoring= 'r2', \n                        cv = KFold, \n                        verbose = 1,\n                        return_train_score=True)      \n\n# \u0421\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0432\u0443\u044e\u0449\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u0438\nmodel_cv.fit(X_train, y_train)\n\n","53ff24d0":"# cv results\ncv_results = pd.DataFrame(model_cv.cv_results_).T\ncv_results","581e94da":"# \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u0438 \u043f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440a\nfrom sklearn.model_selection import GridSearchCV\ntree_params = {'min_samples_split': np.arange(2, 11)}\ntree_grid = GridSearchCV(tree, tree_params, cv=5, scoring='max_error') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043f\u043e 5 \u0431\u043b\u043e\u043a\u0430\u043c\ntree_grid.fit(X_train, y_train)","50b41e45":"# \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u0438 \u043f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 max_depth - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430,\n#mian_samples_leaf - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435, max_features - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0440\u0430\u0441\u0441\u0442\u043c\u0430\u0440\u0438\u0432\u0430\u0435\u043c\u044b\u0445 \u043f\u0440\u0438 \u043f\u043e\u0438\u0441\u043a\u0435 \u043b\u0443\u0447\u0448\u0435\u0433\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438\u044f. \nfrom sklearn.model_selection import GridSearchCV\ntree_params1 = {'max_depth': np.arange(3, 31)}\ntree_grid1 = GridSearchCV(tree, tree_params1, cv=5, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043f\u043e 5 \u0431\u043b\u043e\u043a\u0430\u043c\ntree_grid1.fit(X_train, y_train)\n\n","d234ed22":"tree_grid1.best_estimator_","30a49249":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0447\u0438\u0441\u043b\u043e, \u043e\u0442\u0440\u0430\u0436\u0430\u044e\u0449\u0435\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0443\u044e \u0433\u043b\u0443\u0431\u0438\u043d\u0443.\nmax_depth = list(tree_grid1.best_params_.values())[0]\nprint(\"\u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430: \", max_depth)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_grid1.best_score_)","db95bbc7":"tree_params2 = {'min_samples_split': np.arange(3, 31)}\ntree_grid2 = GridSearchCV(tree, tree_params2, cv=KFold, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \ntree_grid2.fit(X_train, y_train)","6bd20e19":"tree_grid2.best_estimator_","344fb875":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 min_samples_split - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435.\nmin_samples_split = list(tree_grid2.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435: \", min_samples_split)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_grid2.best_score_)","73bdf363":"tree_params3 = {'min_samples_leaf': np.arange(3, 31)}\ntree_grid3 = GridSearchCV(tree, tree_params3, cv=KFold, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \ntree_grid3.fit(X_train, y_train)","bbde450b":"tree_grid3.best_estimator_","a1f5a5b2":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 min_samples_split - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435.\nmin_samples_leaf = list(tree_grid3.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435: \", min_samples_leaf)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_grid3.best_score_)","62bbb8ed":"tree_params4 = {'max_features': np.arange(3, 31)}\ntree_grid4 = GridSearchCV(tree, tree_params4, cv=KFold, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \ntree_grid4.fit(X_train, y_train)","22b58d98":"tree_grid4.best_estimator_","c5221384":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 ma_features - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c\u044b\u0445 \u043f\u0440\u0438 \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0435\u043c \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438.\nmax_features = list(tree_grid4.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435: \", max_features)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_grid4.best_score_)","de9ae73c":"# \u0420\u0438\u0441\u0443\u0435\u043c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0443\u044e \u043a\u0440\u0438\u0432\u0443\u044e\n# \u041f\u043e \u043e\u0441\u0438 \u0445 --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 (param_n_features_to_select)\n# \u041f\u043e \u043e\u0441\u0438 y --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0438 (mean_test_score)\nimport matplotlib.pyplot as plt\nresults_df = pd.DataFrame(model_cv.cv_results_)\nplt.plot(results_df['param_n_features_to_select'], results_df['mean_test_score'])\n# \u041f\u043e\u0434\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u043e\u0441\u0438 \u0438 \u0433\u0440\u0430\u0444\u0438\u043a\nplt.xlabel('param_n_features_to_select')\nplt.ylabel('Test accuracy')\nplt.title('Validation curve')\nplt.show()","108f41ab":"# \u041e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0430 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\n# \u0418\u0437 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043c\u043e\u0436\u0435\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0442\u0435\u0440\u043e\u0432 \u0431\u0443\u0434\u0435\u0442:\n#max_depth = 5, max_features = 4, min_samples_leaf = 30,min_samples_split = 18.\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=2, ncols=2, sharey=False, figsize = (20,10))\n\nax[0, 0].plot(tree_params1['max_depth'], tree_grid1.cv_results_['mean_test_score']) \nax[0, 0].set_xlabel('max_depth')\nax[0, 0].set_ylabel('Mean accuracy on test set')\n\nax[0, 1].plot(tree_params2['min_samples_split'], tree_grid2.cv_results_['mean_test_score']) \nax[0, 1].set_xlabel('min_samples_split')\nax[0, 1].set_ylabel('Mean accuracy on test set')\n\nax[1, 0].plot(tree_params3['min_samples_leaf'], tree_grid3.cv_results_['mean_test_score']) \nax[1, 0].set_xlabel('min_samples_leaf')\nax[1, 0].set_ylabel('Mean accuracy on test set')\n\nax[1, 1].plot(tree_params4['max_features'],tree_grid4.cv_results_['mean_test_score']) \nax[1, 1].set_xlabel('max_features')\nax[1, 1].set_ylabel('Mean accuracy on test set')\n","9ba68ae5":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430 \u0441 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432 = 100, \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0439 \u0433\u043b\u0443\u0431\u0442\u043d\u043e\u0439 =3.\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nrf = RandomForestRegressor(n_estimators=100, max_depth = 3,random_state=42)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_valid)\nmean_squared_error(y_valid, y_pred)\n","09f5f547":"\nfeatures = {'f' + str(i + 1):name for (i, name) in zip(range(len(df1.columns)), df1.columns)}\nimportances = tree.feature_importances_\nindices = np.argsort(importances)[:: -1]\nnum_to_plot = 10\nfeature_indices = [ind + 1 for ind in indices[:num_to_plot]]\nprint(\"Feature ranking:\")\nfor f in range(num_to_plot):\n    print(f + 1, features[\"f\" + str(feature_indices[f])], importances[indices[f]])\n    plt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i\/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[\"f\"+str(i)]) for i in feature_indices]);\n# \u041f\u043e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u043c \u0434\u0430\u043d\u043d\u044b\u043c \u043c\u043e\u0436\u0435\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u043c\u043e\u0434\u0435\u043b\u044c, \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u043d\u0430\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432, \u043b\u0443\u0447\u0448\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 knn.\n# \u0421\u0430\u043c\u044b\u043c \u0432\u043b\u0438\u044f\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u044f\u043b\u0432\u044f\u043b\u0435\u0442\u0441\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a - avg_negative_polarity, \u0435\u043c\u0443 \u0430\u043d\u0442\u0430\u0433\u043e\u043d\u0438\u0441\u0442\u043e\u043c \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f -  LDA_01, kv_avg_min","e821d0f3":"from sklearn.model_selection import GridSearchCV\ntree_paramss = {'n_estimators': [100]}\ntree_gridss = GridSearchCV(rf, tree_paramss, cv=KFold, scoring='explained_variance')\ntree_gridss.fit(X_train, y_train)","79c7deb4":"tree_gridss.best_estimator_","7d8ece2a":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 n_estimators - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432.\nn_estimatorstr = list(tree_gridss.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435: \", n_estimatorstr)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_gridss.best_score_)","4c5f7d1e":"# \u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u0438 \u043f\u043e\u0434\u0431\u043e\u0440 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 max_depth - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430,\n#mian_samples_leaf - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u043b\u0438\u0441\u0442\u0435, max_features - \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0440\u0430\u0441\u0441\u0442\u043c\u0430\u0440\u0438\u0432\u0430\u0435\u043c\u044b\u0445 \u043f\u0440\u0438 \u043f\u043e\u0438\u0441\u043a\u0435 \u043b\u0443\u0447\u0448\u0435\u0433\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0438\u044f, n_estimators - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0434\u0435\u0440\u0435\u0432\u044c\u0435\u0432. \nfrom sklearn.model_selection import GridSearchCV\n\ntree_paramss1 = {'max_depth': np.arange(3, 31)}           \ntree_gridss1 = GridSearchCV(tree, tree_params1, cv=5, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \u043f\u043e 5 \u0431\u043b\u043e\u043a\u0430\u043c\ntree_gridss1.fit(X_train, y_train)\n","fd322893":"tree_gridss1.best_estimator_","2cf27486":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0447\u0438\u0441\u043b\u043e, \u043e\u0442\u0440\u0430\u0436\u0430\u044e\u0449\u0435\u0435 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0443\u044e \u0433\u043b\u0443\u0431\u0438\u043d\u0443.\nmax_depthtr = list(tree_gridss1.best_params_.values())[0]\nprint(\"\u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u043b\u0443\u0431\u0438\u043d\u0430: \", max_depthtr)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_gridss1.best_score_)","4951ef04":"tree_paramss2 = {'min_samples_split': np.arange(3, 31)}\ntree_gridss2 = GridSearchCV(tree, tree_paramss2, cv=KFold, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \ntree_gridss2.fit(X_train, y_train)","a866a23a":"tree_gridss2.best_estimator_","5c5df1bc":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 min_samples_split - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435.\nmin_samples_splittr = list(tree_gridss2.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435: \", min_samples_splittr)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_gridss2.best_score_)","f474f16f":"tree_paramss3 = {'min_samples_leaf': np.arange(3, 31)}\ntree_gridss3 = GridSearchCV(tree, tree_paramss3, cv=KFold, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \ntree_gridss3.fit(X_train, y_train)","25e4d72f":"tree_gridss3.best_estimator_","ab85b6c9":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 min_samples_split - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435.\nmin_samples_leaftr = list(tree_gridss3.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435: \", min_samples_leaftr)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_gridss3.best_score_)","19cce0df":"tree_paramss4 = {'max_features': np.arange(3, 31)}\ntree_gridss4 = GridSearchCV(tree, tree_paramss4, cv=KFold, scoring='explained_variance') # \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f \ntree_gridss4.fit(X_train, y_train)","a559bc75":"tree_gridss4.best_estimator_","4f9a62b2":"# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043e\u0446\u0435\u043d\u043a\u0443 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 min_samples_split - \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435.\nmax_featurestr = list(tree_gridss4.best_params_.values())[0]\nprint(\"\u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u0447\u0438\u0441\u043b\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0432\u043e \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u0435: \", max_featurestr)\nprint(\"\u041d\u0430\u0438\u043b\u0443\u0447\u0448\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043c\u043e\u0434\u0435\u043b\u0438: \", tree_gridss4.best_score_)","aa1a8f6f":"# \u041e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0430 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\n# \u0418\u0437 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043c\u043e\u0436\u0435\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0442\u0435\u0440\u043e\u0432 \u0431\u0443\u0434\u0435\u0442:\n#max_depth = 5, max_features = 4, min_samples_leaf = 30,min_samples_split = 18, n_estimators = \nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=3, ncols=2, sharey=False, figsize = (40,40))\nax[0, 0].plot(tree_paramss['n_estimators'], tree_gridss.cv_results_['mean_test_score']) \nax[0, 0].set_xlabel('max_depth')\nax[0, 0].set_ylabel('Mean accuracy on test set')\n\nax[0, 1].plot(tree_paramss1['max_depth'], tree_gridss1.cv_results_['mean_test_score']) \nax[0, 1].set_xlabel('max_depth')\nax[0, 1].set_ylabel('Mean accuracy on test set')\n\nax[1, 0].plot(tree_paramss2['min_samples_split'], tree_gridss2.cv_results_['mean_test_score']) \nax[1, 0].set_xlabel('min_samples_split')\nax[1, 0].set_ylabel('Mean accuracy on test set')\n\nax[1, 1].plot(tree_paramss3['min_samples_leaf'], tree_gridss3.cv_results_['mean_test_score']) \nax[1, 1].set_xlabel('min_samples_leaf')\nax[1, 1].set_ylabel('Mean accuracy on test set')\n\nax[2, 0].plot(tree_paramss4['max_features'],tree_gridss4.cv_results_['mean_test_score']) \nax[2, 0].set_xlabel('max_features')\nax[2, 0].set_ylabel('Mean accuracy on test set')\n","27ea264b":"# \u041e\u0446\u0435\u043d\u0438\u0432\u0430\u0435\u043c \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0432 \u0434\u0430\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438. \n#\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0442\u043e\u043f-10 \u0441\u0430\u043c\u044b\u0445 \u043f\u043e\u043b\u0435\u0437\u043d\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0442\u043e\u043b\u0431\u0447\u0430\u0442\u043e\u0439 \u0434\u0438\u0430\u0433\u0440\u0430\u043c\u043c\u044b.\n# \u041f\u043e \u0434\u0430\u043d\u043d\u044b\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430\u043c \u0434\u0435\u043b\u0430\u0435\u043c \u0432\u044b\u0432\u043e\u0434, \u0447\u0442\u043e \u0431\u043e\u043b\u0435\u0435 \u0432\u043b\u0438\u044f\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a global_sentiment_polarity, \u0430 \u043c\u0435\u043d\u0435\u0435 - kw_avg_avg.\nimport matplotlib.pyplot as plt\nfeatures = {'f'+str(i+1):name for (i, name) in zip(range(len(df1.columns)), df1.columns)}\n# \u0412\u0430\u0436\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\nforest.fit(X_train, y_train)\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1]\n# \u0421\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a \u0432\u0430\u0436\u043d\u043e\u0441\u0442\u0438 \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0435\u0439 \u043b\u0435\u0441\u0430\nnum_to_plot = 10\nfeature_indices = [ind+1 for ind in indices[:num_to_plot]]\n# \u0420\u0430\u0441\u043f\u0435\u0447\u0430\u0442\u0430\u0442\u044c \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0444\u0443\u043d\u043a\u0446\u0438\u0439\nprint(\"Feature ranking:\")\nfor f in range(num_to_plot):\n    print(f+1, features[\"f\"+str(feature_indices[f])], importances[indices[f]])\n    plt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i\/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[\"f\"+str(i)]) for i in feature_indices]);","5f5e82fd":"#\u041f\u043e \u0434\u0430\u043d\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u0435 \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0432\u044b\u0432\u043e\u0434\u044b:\n#1. Decision Tree \u0438\u043c\u0435\u0435\u0442 \u043e\u0441\u043e\u0431\u0443\u044e \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 - \u043c\u043e\u043b\u043d\u0438\u0435\u043d\u043e\u0441\u043d\u0430\u044f \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0430\u0435\u043c\u043e\u0441\u0442\u044c.\n#2. Random Forest \u043f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0440\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u0442 \u0441\u043e\u043b\u0438\u0434\u043d\u0443\u044e \u0447\u0430\u0441\u0442\u044c \u043c\u043e\u0435\u0439 \u0436\u0438\u0437\u043d\u0438:) \n#3. \u041d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435 kNN - \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0435 \u0441\u0430\u043c\u043e\u0433\u043e \u043b\u0443\u0447\u0448\u0435\u0433\u043e \u043a\u0430\u0447\u0435\u0442\u0441\u0432\u0430.","5a7736d8":"![](https:\/\/dreampuf.github.io\/GraphvizOnline\/#digraph%20Tree%20%7B%0D%0Anode%20%5Bshape%3Dbox%5D%20%3B%0D%0A0%20%5Blabel%3D\"kw_avg_avg%20<%3D%204303.344%5Cnmse%20%3D%2062184747.661%5Cnsamples%20%3D%203467%5Cnvalue%20%3D%203298.271\"%5D%20%3B%0D%0A1%20%5Blabel%3D\"timedelta%20<%3D%2089.5%5Cnmse%20%3D%2029397830.79%5Cnsamples%20%3D%202857%5Cnvalue%20%3D%202613.645\"%5D%20%3B%0D%0A0%20->%201%20%5Blabeldistance%3D2.5%2C%20labelangle%3D45%2C%20headlabel%3D\"True\"%5D%20%3B%0D%0A2%20%5Blabel%3D\"LDA_01%20<%3D%200.916%5Cnmse%20%3D%2023333842.941%5Cnsamples%20%3D%202794%5Cnvalue%20%3D%202418.355\"%5D%20%3B%0D%0A1%20->%202%20%3B%0D%0A3%20%5Blabel%3D\"global_sentiment_polarity%20<%3D%20-0.32%5Cnmse%20%3D%2020756224.228%5Cnsamples%20%3D%202791%5Cnvalue%20%3D%202389.049\"%5D%20%3B%0D%0A2%20->%203%20%3B%0D%0A4%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2048500.0\"%5D%20%3B%0D%0A3%20->%204%20%3B%0D%0A5%20%5Blabel%3D\"kw_max_avg%20<%3D%205114.61%5Cnmse%20%3D%2020001304.627%5Cnsamples%20%3D%202790%5Cnvalue%20%3D%202372.522\"%5D%20%3B%0D%0A3%20->%205%20%3B%0D%0A6%20%5Blabel%3D\"mse%20%3D%2011472350.383%5Cnsamples%20%3D%202034%5Cnvalue%20%3D%201992.103\"%5D%20%3B%0D%0A5%20->%206%20%3B%0D%0A7%20%5Blabel%3D\"mse%20%3D%2041511327.384%5Cnsamples%20%3D%20756%5Cnvalue%20%3D%203396.028\"%5D%20%3B%0D%0A5%20->%207%20%3B%0D%0A8%20%5Blabel%3D\"kw_avg_min%20<%3D%20207.786%5Cnmse%20%3D%201677200384.889%5Cnsamples%20%3D%203%5Cnvalue%20%3D%2029683.333\"%5D%20%3B%0D%0A2%20->%208%20%3B%0D%0A9%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2087600.0\"%5D%20%3B%0D%0A8%20->%209%20%3B%0D%0A10%20%5Blabel%3D\"self_reference_min_shares%20<%3D%201443.5%5Cnmse%20%3D%2045369.0%5Cnsamples%20%3D%202%5Cnvalue%20%3D%20725.0\"%5D%20%3B%0D%0A8%20->%2010%20%3B%0D%0A11%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%20512.0\"%5D%20%3B%0D%0A10%20->%2011%20%3B%0D%0A12%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%20938.0\"%5D%20%3B%0D%0A10%20->%2012%20%3B%0D%0A13%20%5Blabel%3D\"kw_avg_min%20<%3D%20360.5%5Cnmse%20%3D%20221627291.509%5Cnsamples%20%3D%2063%5Cnvalue%20%3D%2011274.603\"%5D%20%3B%0D%0A1%20->%2013%20%3B%0D%0A14%20%5Blabel%3D\"avg_negative_polarity%20<%3D%20-0.435%5Cnmse%20%3D%2057167880.992%5Cnsamples%20%3D%2055%5Cnvalue%20%3D%208189.091\"%5D%20%3B%0D%0A13%20->%2014%20%3B%0D%0A15%20%5Blabel%3D\"n_unique_tokens%20<%3D%200.552%5Cnmse%20%3D%20188674400.0%5Cnsamples%20%3D%205%5Cnvalue%20%3D%2021340.0\"%5D%20%3B%0D%0A14%20->%2015%20%3B%0D%0A16%20%5Blabel%3D\"mse%20%3D%2080686666.667%5Cnsamples%20%3D%203%5Cnvalue%20%3D%2031000.0\"%5D%20%3B%0D%0A15%20->%2016%20%3B%0D%0A17%20%5Blabel%3D\"mse%20%3D%20722500.0%5Cnsamples%20%3D%202%5Cnvalue%20%3D%206850.0\"%5D%20%3B%0D%0A15%20->%2017%20%3B%0D%0A18%20%5Blabel%3D\"global_sentiment_polarity%20<%3D%20-0.048%5Cnmse%20%3D%2024993124.0%5Cnsamples%20%3D%2050%5Cnvalue%20%3D%206874.0\"%5D%20%3B%0D%0A14%20->%2018%20%3B%0D%0A19%20%5Blabel%3D\"mse%20%3D%2049702500.0%5Cnsamples%20%3D%202%5Cnvalue%20%3D%2024550.0\"%5D%20%3B%0D%0A18%20->%2019%20%3B%0D%0A20%20%5Blabel%3D\"mse%20%3D%2010402760.417%5Cnsamples%20%3D%2048%5Cnvalue%20%3D%206137.5\"%5D%20%3B%0D%0A18%20->%2020%20%3B%0D%0A21%20%5Blabel%3D\"kw_avg_max%20<%3D%20214143.609%5Cnmse%20%3D%20836846093.75%5Cnsamples%20%3D%208%5Cnvalue%20%3D%2032487.5\"%5D%20%3B%0D%0A13%20->%2021%20%3B%0D%0A22%20%5Blabel%3D\"num_videos%20<%3D%200.5%5Cnmse%20%3D%20194602500.0%5Cnsamples%20%3D%202%5Cnvalue%20%3D%2070850.0\"%5D%20%3B%0D%0A21%20->%2022%20%3B%0D%0A23%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2084800.0\"%5D%20%3B%0D%0A22%20->%2023%20%3B%0D%0A24%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2056900.0\"%5D%20%3B%0D%0A22%20->%2024%20%3B%0D%0A25%20%5Blabel%3D\"global_rate_positive_words%20<%3D%200.037%5Cnmse%20%3D%20396846666.667%5Cnsamples%20%3D%206%5Cnvalue%20%3D%2019700.0\"%5D%20%3B%0D%0A21%20->%2025%20%3B%0D%0A26%20%5Blabel%3D\"mse%20%3D%2026522500.0%5Cnsamples%20%3D%202%5Cnvalue%20%3D%2047450.0\"%5D%20%3B%0D%0A25%20->%2026%20%3B%0D%0A27%20%5Blabel%3D\"mse%20%3D%204461875.0%5Cnsamples%20%3D%204%5Cnvalue%20%3D%205825.0\"%5D%20%3B%0D%0A25%20->%2027%20%3B%0D%0A28%20%5Blabel%3D\"global_sentiment_polarity%20<%3D%200.326%5Cnmse%20%3D%20203268769.519%5Cnsamples%20%3D%20610%5Cnvalue%20%3D%206504.785\"%5D%20%3B%0D%0A0%20->%2028%20%5Blabeldistance%3D2.5%2C%20labelangle%3D-45%2C%20headlabel%3D\"False\"%5D%20%3B%0D%0A29%20%5Blabel%3D\"n_tokens_title%20<%3D%2017.5%5Cnmse%20%3D%20177126862.926%5Cnsamples%20%3D%20592%5Cnvalue%20%3D%206148.346\"%5D%20%3B%0D%0A28%20->%2029%20%3B%0D%0A30%20%5Blabel%3D\"kw_avg_max%20<%3D%20435434.719%5Cnmse%20%3D%20175272270.353%5Cnsamples%20%3D%20591%5Cnvalue%20%3D%206088.022\"%5D%20%3B%0D%0A29%20->%2030%20%3B%0D%0A31%20%5Blabel%3D\"timedelta%20<%3D%2072.5%5Cnmse%20%3D%2040004147.82%5Cnsamples%20%3D%20309%5Cnvalue%20%3D%204783.806\"%5D%20%3B%0D%0A30%20->%2031%20%3B%0D%0A32%20%5Blabel%3D\"mse%20%3D%2030704316.924%5Cnsamples%20%3D%20232%5Cnvalue%20%3D%204017.142\"%5D%20%3B%0D%0A31%20->%2032%20%3B%0D%0A33%20%5Blabel%3D\"mse%20%3D%2060917607.874%5Cnsamples%20%3D%2077%5Cnvalue%20%3D%207093.753\"%5D%20%3B%0D%0A31%20->%2033%20%3B%0D%0A34%20%5Blabel%3D\"kw_avg_min%20<%3D%20459.449%5Cnmse%20%3D%20319585464.197%5Cnsamples%20%3D%20282%5Cnvalue%20%3D%207517.11\"%5D%20%3B%0D%0A30%20->%2034%20%3B%0D%0A35%20%5Blabel%3D\"mse%20%3D%20193483042.084%5Cnsamples%20%3D%20268%5Cnvalue%20%3D%206681.679\"%5D%20%3B%0D%0A34%20->%2035%20%3B%0D%0A36%20%5Blabel%3D\"mse%20%3D%202464424351.658%5Cnsamples%20%3D%2014%5Cnvalue%20%3D%2023509.643\"%5D%20%3B%0D%0A34%20->%2036%20%3B%0D%0A37%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2041800.0\"%5D%20%3B%0D%0A29%20->%2037%20%3B%0D%0A38%20%5Blabel%3D\"LDA_01%20<%3D%200.572%5Cnmse%20%3D%20921442590.333%5Cnsamples%20%3D%2018%5Cnvalue%20%3D%2018227.667\"%5D%20%3B%0D%0A28%20->%2038%20%3B%0D%0A39%20%5Blabel%3D\"global_rate_positive_words%20<%3D%200.072%5Cnmse%20%3D%20456781777.384%5Cnsamples%20%3D%2017%5Cnvalue%20%3D%2012858.706\"%5D%20%3B%0D%0A38%20->%2039%20%3B%0D%0A40%20%5Blabel%3D\"avg_positive_polarity%20<%3D%200.69%5Cnmse%20%3D%2066419872.249%5Cnsamples%20%3D%2015%5Cnvalue%20%3D%205786.533\"%5D%20%3B%0D%0A39%20->%2040%20%3B%0D%0A41%20%5Blabel%3D\"mse%20%3D%2016959306.388%5Cnsamples%20%3D%2014%5Cnvalue%20%3D%203885.571\"%5D%20%3B%0D%0A40%20->%2041%20%3B%0D%0A42%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2032400.0\"%5D%20%3B%0D%0A40%20->%2042%20%3B%0D%0A43%20%5Blabel%3D\"abs_title_sentiment_polarity%20<%3D%200.8%5Cnmse%20%3D%20196000000.0%5Cnsamples%20%3D%202%5Cnvalue%20%3D%2065900.0\"%5D%20%3B%0D%0A39%20->%2043%20%3B%0D%0A44%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2079900.0\"%5D%20%3B%0D%0A43%20->%2044%20%3B%0D%0A45%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%2051900.0\"%5D%20%3B%0D%0A43%20->%2045%20%3B%0D%0A46%20%5Blabel%3D\"mse%20%3D%200.0%5Cnsamples%20%3D%201%5Cnvalue%20%3D%20109500.0\"%5D%20%3B%0D%0A38%20->%2046%20%3B%0D%0A%7D)"}}