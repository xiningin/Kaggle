{"cell_type":{"c0bd9ca4":"code","86d32963":"code","3615ab2d":"code","aff3c34e":"code","3aeaaf3b":"code","e97f4bcb":"code","d61089e9":"code","4765c87e":"code","d67961dd":"code","8d52a00d":"code","3de87035":"code","677e801a":"code","99fbd79c":"code","77eef2a1":"code","15f1b7fa":"code","800e69db":"code","68a27e2a":"code","cfcb7073":"code","ca021138":"code","743c24ca":"code","82648a40":"code","81ea4abb":"code","8c8a6b7a":"code","dbacd594":"code","4077db53":"code","c6851973":"code","fb72843e":"code","49c3d04b":"code","93007515":"code","86e1ef06":"code","0c92cf62":"code","6597d858":"code","e2e620e0":"code","1e6170dc":"code","cba735af":"code","e254f215":"code","32b2cc54":"code","c7f09a08":"code","63aea087":"code","a6153453":"code","1a09a672":"code","8b3a5d37":"code","34179cd5":"code","727b2c76":"code","ce71a69b":"code","4043bc59":"code","cf501c88":"code","dbf80932":"code","9e76757b":"code","de9979b9":"code","d2e00208":"code","8a2b1e21":"code","50f48ae5":"markdown","9d5e82b9":"markdown","7cb7023b":"markdown","650f0277":"markdown","71322806":"markdown","d52df92b":"markdown","d6c992fd":"markdown","701b1d46":"markdown","fb81d8d4":"markdown","7940811d":"markdown","e5e47964":"markdown","96283516":"markdown"},"source":{"c0bd9ca4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86d32963":"import pandas as pd\nimport numpy as np\nfrom numpy import percentile\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib\nimport re # for regular expressions\nimport pandas as pd \npd.set_option(\"display.max_colwidth\", 200) \nimport string\nfrom sklearn import metrics \nfrom sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve\nfrom sklearn.model_selection import train_test_split,cross_val_score,KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nimport nltk # for text manipulation\nfrom nltk.stem.porter import *\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom tqdm import tqdm\nimport gensim\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy import stats \nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords \nfrom wordcloud import WordCloud, STOPWORDS","3615ab2d":"train = pd.read_csv('\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv')","aff3c34e":"train.head()","3aeaaf3b":"test.head()","e97f4bcb":"train.shape","d61089e9":"test.shape","4765c87e":"train.info()","d67961dd":"test.info()","8d52a00d":"train.columns","3de87035":"test.columns","677e801a":"test.value_counts()","99fbd79c":"train.value_counts()","77eef2a1":"train.isnull().sum()","15f1b7fa":"test.isnull().sum()","800e69db":"test.nunique()","68a27e2a":"train.nunique()","cfcb7073":"train['text'] = train.OriginalTweet\n\ntest['text'] = test.OriginalTweet","ca021138":"train.head()","743c24ca":"test.head()","82648a40":"def change_def(x):\n    if x ==  \"Extremely Positive\":\n        return \"1\"\n    elif x == \"Extremely Negative\":\n        return \"-1\"\n    elif x == \"Negative\":\n        return \"-1\"\n    elif x ==  \"Positive\":\n        return \"1\"\n    else:\n        return \"0\"\n\ntrain['label'] = train['Sentiment'].apply(lambda x:change_def(x))\ntest ['label'] = test ['Sentiment'].apply(lambda x:change_def(x))\n\n\ntrain.label.value_counts()","81ea4abb":"train.head()","8c8a6b7a":"test.head()","dbacd594":"def wordCloud(sentiment):\n    text = \",\".join(\n               review for review in train[train['Sentiment'] == sentiment].OriginalTweet \n        if 'COVID' not in review and 'https' not in review and 'Covid' not in review)\n\n    wordcloud = WordCloud(max_words=200, colormap='Set2', background_color=\"magenta\").generate(text)\n    plt.figure(figsize=(15,10))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.figure(1,figsize=(12, 12))\n    plt.title('Prevalent words in ' + sentiment + ' tweets', fontsize=19)\n    plt.show()","4077db53":"wordCloud(\"Extremely Negative\")","c6851973":"wordCloud(\"Negative\")","fb72843e":"wordCloud(\"Positive\")","49c3d04b":"wordCloud(\"Extremely Positive\")","93007515":"wordCloud(\"Neutral\")","86e1ef06":"plot = sns.countplot(x='Sentiment', data=train).set_xticklabels(labels=['Neutral', 'Positive', 'Extremely Negative', 'Negative','Extremely Positive'],rotation=20)","0c92cf62":"polt1=sns.catplot(\"TweetAt\", data=train, kind=\"count\", height=8)","6597d858":"# remove special characters, numbers, punctuations\ntrain['TweetAt'] = train['TweetAt'].str.replace('[^a-zA-Z#]+',' ')\ntest['TweetAt'] = test['TweetAt'].str.replace('[^a-zA-Z#]+',' ')","e2e620e0":"train.head()","1e6170dc":"test.head()","cba735af":"\ndef remove_pattern(input_txt, pattern):    # write function for removing @user\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i,'',input_txt)\n    return input_txt","e254f215":"train['TweetAt'] = np.vectorize(remove_pattern)(train['OriginalTweet'], '@[\\w]*')  # create new column with removed @user\ntest['TweetAt'] = np.vectorize(remove_pattern)(test['OriginalTweet'], '@[\\w]*') ","32b2cc54":"train.head()","c7f09a08":"test.head()","63aea087":"import re\ntrain['OriginalTweet'] = train['OriginalTweet'].apply(lambda x: re.split('https:\\\/\\\/.*', str(x))[0])\ntest['OriginalTweet'] = test['OriginalTweet'].apply(lambda x: re.split('https:\\\/\\\/.*', str(x))[0])","a6153453":"train.head()","1a09a672":"test.head()","8b3a5d37":"train['TweetAt'] = train['TweetAt'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\ntest['TweetAt'] = test['TweetAt'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))","34179cd5":"train.head()","727b2c76":"test.head()","ce71a69b":"def lower(text):\n    low_text= text.lower()\n    return low_text\ntrain['text'] = train['text'].apply(lambda x:lower(x))\ntest ['text'] = test ['text'].apply(lambda x:lower(x))","4043bc59":"train.head()","cf501c88":"test.head()","dbf80932":"new_data = train[['TweetAt','Sentiment']]\nnew_data.head()","9e76757b":"train,test = train_test_split(new_data,test_size = 0.2,random_state=0,stratify = new_data.Sentiment.values)\nprint(\"train shape : \", train.shape)\nprint(\"test shape : \", test.shape)","de9979b9":"stop = list(stopwords.words('english'))\nvectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n\nX_train = vectorizer.fit_transform(train.TweetAt.values)\nX_test = vectorizer.transform(test.TweetAt.values)\n\ny_train = train.Sentiment.values\ny_test = test.Sentiment.values\n\nprint(\"X_train.shape : \", X_train.shape)\nprint(\"X_test.shape : \", X_test.shape)\nprint(\"y_train.shape : \", y_train.shape)\nprint(\"y_test.shape : \", y_test.shape)","d2e00208":"rf_clf = RandomForestClassifier()\n\nrf_clf.fit(X_train,y_train)\n\nrf_prediction = rf_clf.predict(X_test)\nrf_accuracy = accuracy_score(y_test,rf_prediction)\nprint(\"Training accuracy Score    : \",rf_clf.score(X_train,y_train))\nprint(\"Testing accuracy Score : \",rf_accuracy )\nprint(classification_report(rf_prediction,y_test))","8a2b1e21":"logisticreg = LogisticRegression()\n\nlogisticreg.fit(X_train, y_train)\n\nlogisticreg_prediction = logisticreg.predict(X_test)\nlogisticreg_accuracy = accuracy_score(y_test,logisticreg_prediction)\nprint(\"Training accuracy Score    : \",logisticreg.score(X_train,y_train))\nprint(\"Testing accuracy Score : \",logisticreg_accuracy )\nprint(classification_report(logisticreg_prediction,y_test))","50f48ae5":"## Text Cleaning","9d5e82b9":"## Converting a Selected Column Categorical To Numerical data ","7cb7023b":"### 5) Lower Casing","650f0277":"### 4) Removing Short Words","71322806":"## Use Of Counter Vectorizer For Multi Class Classification","d52df92b":"### 1) Removing Punctuations, Numbers, and Special Characters","d6c992fd":"## Visualize the text data using wordcloud","701b1d46":"## Spitting Our Dataset into Training And Testing Dataset","fb81d8d4":"### 3) Removed HTTP And URLS From OriginalTweet","7940811d":"### 2) Removing @user","e5e47964":"## Random Forest Classifier","96283516":"## Logistic Regression(lr)"}}