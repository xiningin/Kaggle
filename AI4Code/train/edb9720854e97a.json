{"cell_type":{"ed2ba26a":"code","3be31d85":"code","418dab2d":"code","4fb3f639":"code","8815ef80":"code","434a37d2":"code","67c15e2a":"code","9cb3db29":"code","46e661a5":"code","87e94a17":"code","4048b40e":"code","3e67a5bf":"code","4f70dc97":"code","75ce2615":"code","b71d06f0":"code","f3db82d0":"code","88784c53":"code","a65356b5":"code","60465da3":"code","10ebfc21":"code","c420b21f":"code","8b5f5659":"code","199911dd":"code","6664f896":"code","f84d0c8c":"code","3f0f8820":"code","93e5d2eb":"code","5dca2ebc":"code","0819d257":"code","4dc02ece":"code","b2156518":"code","c87692bf":"code","4645a269":"code","6a0cf1db":"code","d40eea60":"markdown","dbeb9daf":"markdown","7e6ff497":"markdown","fdc8abd2":"markdown","2219a964":"markdown","19839e2b":"markdown","dca3b977":"markdown","efa906c0":"markdown","fb5aa67b":"markdown","50b8d3f0":"markdown","a0afa014":"markdown","a6695253":"markdown","f10c55cf":"markdown","a6693e72":"markdown","c70e5484":"markdown","b3b7e152":"markdown","0867bafd":"markdown","28f5f4d7":"markdown","ea00b0d0":"markdown","dde0a75e":"markdown","2b67e3df":"markdown","7177c736":"markdown","f6fccfce":"markdown","0776a637":"markdown"},"source":{"ed2ba26a":"import numpy as np\nimport pandas as pd\nimport os, sys, math\nimport tensorflow as tf\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# AUTO will be used in tf.data.Dataset API\nAUTO = tf.data.experimental.AUTOTUNE \n\nprint(\"Tensorflow version \" + tf.__version__)","3be31d85":"show_files=0\n\n# if you want to see the full content of the\n# 'kaggle\/input'directory set show_files=1\n\nif show_files:\n    for dirname, _, filenames in os.walk('\/kaggle\/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))","418dab2d":"NFOLDS=5 # this must be consistent with PATH_FOLDS below\nSHARDS = 4 # the number of .tfrec files in each fold\nTARGET_SIZE = [512, 512] # the desired size of the output images\nCLASSES = [b'benign', b'malignant']\n\nPATH_DATA=Path('\/kaggle\/input\/siim-isic-melanoma-classification\/')\nPATH_FOLDS=Path('\/kaggle\/input\/siim-stratified-groupkfold-5-folds\/')","4fb3f639":"train=pd.read_csv(PATH_DATA\/'train.csv')\nprint(f\"The shape of the `train` is {train.shape}.\\n\")\nprint(f\"The columns present in `train` are {train.columns.values}.\")","8815ef80":"test=pd.read_csv(PATH_DATA\/'test.csv')\nprint(f\"The shape of the `test` is {test.shape}.\\n\")\nprint(f\"The columns present in `test` are {test.columns.values}.\")","434a37d2":"train.isna().sum()","67c15e2a":"test.isna().sum()","9cb3db29":"median_age=train['age_approx'].median()\nprint(f\"The median age of the patients in the training set is {median_age} years.\")","46e661a5":"train['age_approx'].fillna(median_age, inplace=True)\ntrain.fillna('unknown', inplace=True)\ntest.fillna('unknown', inplace=True)","87e94a17":"print(f\"The total number of NA's after imputation in `train` is {train.isna().sum().sum()}.\")\nprint(f\"The total number of NA's after imputation in `test` is {test.isna().sum().sum()}.\")","4048b40e":"print(\"The unique values of 'age_approx':\")\nprint(np.unique(train['age_approx'].values))\nprint(\"\\nThe unique values of 'sex':\")\nprint(np.unique(train['sex'].values))\nprint(\"\\nThe unique values of 'anatom_site_general_challenge':\")\nprint(np.unique(train['anatom_site_general_challenge'].values))\nprint(\"\\nThe unique values of 'diagnosis':\")\nprint(np.unique(train['diagnosis'].values))","3e67a5bf":"print(\"The unique values of 'age_approx':\")\nprint(np.unique(test['age_approx'].values))\nprint(\"\\nThe unique values of 'sex':\")\nprint(np.unique(test['sex'].values))\nprint(\"\\nThe unique values of 'anatom_site_general_challenge':\")\nprint(np.unique(test['anatom_site_general_challenge'].values))","4f70dc97":"train['age_approx']=train['age_approx'].astype(np.uint8)\ntest['age_approx']=test['age_approx'].astype(np.uint8)","75ce2615":"np.equal(np.unique(test['anatom_site_general_challenge'].values),\n         np.unique(train['anatom_site_general_challenge'].values)\n        ).all()","b71d06f0":"train = pd.concat([train, pd.get_dummies(train['sex'], prefix='sex')], axis=1)\ntrain = pd.concat([train, pd.get_dummies(train['anatom_site_general_challenge'], \n                                         prefix='site')], axis=1)\n# train = pd.concat([train, pd.get_dummies(train['diagnosis'], prefix='diagn')], axis=1)\n\ntrain.shape","f3db82d0":"test = pd.concat([test, pd.get_dummies(test['sex'], prefix='sex')], axis=1)\ntest = pd.concat([test, pd.get_dummies(test['anatom_site_general_challenge'],\n                                       prefix='site')], axis=1)\n\ntest.shape","88784c53":"%%time\n\nscaler=StandardScaler()\n\ntrain['age_scaled']=scaler.fit_transform(train['age_approx'].values.reshape(-1, 1))\ntest['age_scaled']=scaler.transform(test['age_approx'].values.reshape(-1, 1))","a65356b5":"train_idx={fn: np.load(PATH_FOLDS\/f\"train_idx_fold_{fn}.npy\") for fn in range(1, NFOLDS+1)}\nval_idx={fn: np.load(PATH_FOLDS\/f\"val_idx_fold_{fn}.npy\") for fn in range(1, NFOLDS+1)}\n\nfor fn in range(1, NFOLDS+1):\n    print(\"=\"*50)\n    print(f\"Fold {fn}:\")\n    print(f\"The training set consists of {len(train_idx[fn])} elements.\")\n    print(f\"The validation set consists of {len(val_idx[fn])} elements.\")\n\n    assert len(train)==(len(train_idx[fn])+len(val_idx[fn])), \"Wrong total number of elements\"","60465da3":"excluded_cols=['sex', 'anatom_site_general_challenge', 'diagnosis', ]\n\ncols=[c for c in train.columns if c not in excluded_cols]\n\nprint(cols)\nprint(f\"\\nThe total number of features is {len(cols)}.\")","10ebfc21":"train_fold={fn: train.loc[val_idx[fn], cols] for fn in range(1, NFOLDS+1)}","c420b21f":"labels={fn: train_fold[fn].pop('target') for fn in range(1, NFOLDS+1)}\ndataset0 = {fn: tf.data.Dataset.from_tensor_slices((dict(train_fold[fn]), labels[fn])) \n            for fn in range(1, NFOLDS+1)\n           }","8b5f5659":"def decode_jpeg(data_dict, label): \n    fname=\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/\" \\\n          +data_dict['image_name']+\".jpg\"\n    bits = tf.io.read_file(fname)\n    data_dict['image'] = tf.image.decode_jpeg(bits)  \n    return data_dict, label","199911dd":"dataset1 = {fn: dataset0[fn].map(decode_jpeg, num_parallel_calls=AUTO) for fn in range(1, NFOLDS+1)}","6664f896":"def resize_and_crop_image(data, label):\n    # Resize and crop using \"fill\" algorithm:\n    # always make sure the resulting image\n    # is cut out from the source image so that\n    # it fills the TARGET_SIZE entirely with no\n    # black bars and a preserved aspect ratio.\n    w = tf.shape(data['image'])[0] \n    h = tf.shape(data['image'])[1]\n    tw = TARGET_SIZE[1]\n    th = TARGET_SIZE[0]\n    resize_crit = (w * th) \/ (h * tw)\n    data['image'] = tf.cond(resize_crit < 1,\n                            # if true\n                            lambda: tf.image.resize(data['image'], [w*tw\/w, h*tw\/w],\n                                                    method='lanczos3',\n                                                    antialias=True\n                                                   ),\n                            # if false\n                            lambda: tf.image.resize(data['image'], [w*th\/h, h*th\/h],\n                                                    method='lanczos3',\n                                                    antialias=True\n                                                   )\n                           )\n    nw = tf.shape(data['image'])[0]\n    nh = tf.shape(data['image'])[1]\n    data['image'] = tf.image.crop_to_bounding_box(data['image'], \n                                                  (nw - tw) \/\/ 2, \n                                                  (nh - th) \/\/ 2, \n                                                  tw, th\n                                                 )\n    return data, label, h, w","f84d0c8c":"dataset2 = {fn: dataset1[fn].map(resize_and_crop_image, num_parallel_calls=AUTO) \n            for fn in range(1, NFOLDS+1)}","3f0f8820":"def recompress_image(data, label, h, w):\n    data['image'] = tf.cast(data['image'], tf.uint8)\n    data['image'] = tf.image.encode_jpeg(data['image'], \n                                         #quality=100, # the default is 95% (the original images \n                                         # are already compressed, so no need to increase this \n                                         # value -- we can't create new information.)\n                                         optimize_size=True, \n                                         chroma_downsampling=False)\n    return data, label, h, w","93e5d2eb":"dataset3 = {fn: dataset2[fn].map(recompress_image, num_parallel_calls=AUTO) for fn in range(1, NFOLDS+1)}","5dca2ebc":"nb_images = {fn: len(train_fold[fn]) for fn in range(1, NFOLDS+1)}\nshard_size = {fn: math.ceil(1.0 * nb_images[fn] \/ SHARDS) for fn in range(1, NFOLDS+1)}\n\nfor fn in range(1, NFOLDS+1):\n    print(\"=\"*50)\n    print(f\"Fold {fn}:\")\n    print(f\"The total number of images = {nb_images[fn]}\")\n    print(f\"The number of  .tfrecord files = {SHARDS}\")\n    print(f\"The number of images in each .tfrecord file = {shard_size[fn]}\")","0819d257":"dataset4 = {fn: dataset3[fn].batch(shard_size[fn]) for fn in range(1, NFOLDS+1)}","4dc02ece":"def _bytestring_feature(list_of_bytestrings):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))","b2156518":"def _int_feature(list_of_ints): # int64\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))","c87692bf":"def _float_feature(list_of_floats): # float32\n    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))","4645a269":"def to_tfrecord(tfrec_filewriter, image, image_name, patient_id, \n                benign_malignant, age, age_scaled, sex_female, sex_male, sex_unknown, \n                site_head_neck, site_lower_extremity, site_oral_genital, \n                site_palms_soles, site_torso, site_unknown, site_upper_extremity, \n                label, height, width):\n\n    feature = {\n        # bytestring features\n        \"image\": _bytestring_feature([image]), \n        \"image_name\": _bytestring_feature([image_name]),\n        \"patient_id\": _bytestring_feature([patient_id]), \n        \"benign_malignant\": _bytestring_feature([benign_malignant]),\n        # integer features\n        \"age\": _int_feature([age]),\n        \"sex_female\": _int_feature([sex_female]),        \n        \"sex_male\": _int_feature([sex_male]),\n        \"sex_unknown\": _int_feature([sex_unknown]),\n        \"site_head\/neck\": _int_feature([site_head_neck]),\n        \"site_lower extremity\": _int_feature([site_lower_extremity]),\n        \"site_oral\/genital\": _int_feature([site_oral_genital]),\n        \"site_palms\/soles\": _int_feature([site_palms_soles]), \n        \"site_torso\": _int_feature([site_torso]), \n        \"site_unknown\": _int_feature([site_unknown]), \n        \"site_upper extremity\": _int_feature([site_upper_extremity]),\n        \"height\": _int_feature([height]),\n        \"width\": _int_feature([width]),\n        \"target\": _int_feature([label]),\n        # float features\n        \"age_scaled\": _float_feature([age_scaled]),\n    }\n    \n    return tf.train.Example(features=tf.train.Features(feature=feature))","6a0cf1db":"print(\"Writing TFRecords\")\n\nfor fn in range(1, NFOLDS+1):\n    \n    print(\"=\"*50)\n    print(f\"Fold {fn} out of {NFOLDS}:\")\n    \n    for shard, (data, label, height, width) in enumerate(dataset4[fn]):\n        # batch size used as shard size here\n        shard_size = data['image'].numpy().shape[0]\n        # good practice to have the number of records in the filename\n        filename = \"fold_{}_{:02d}-{}.tfrec\".format(fn, shard, shard_size)\n\n        with tf.io.TFRecordWriter(filename) as out_file:\n            for i in range(shard_size):\n                example = to_tfrecord(out_file,\n                                      # re-compressed image: already a byte string\n                                      data['image'].numpy()[i],\n                                      data['image_name'].numpy()[i],\n                                      data['patient_id'].numpy()[i],\n                                      data['benign_malignant'].numpy()[i],\n                                      data['age_approx'].numpy()[i],\n                                      data['age_scaled'].numpy()[i],\n                                      data['sex_female'].numpy()[i],\n                                      data['sex_male'].numpy()[i],\n                                      data['sex_unknown'].numpy()[i],\n                                      data['site_head\/neck'].numpy()[i],\n                                      data['site_lower extremity'].numpy()[i],\n                                      data['site_oral\/genital'].numpy()[i],\n                                      data['site_palms\/soles'].numpy()[i],\n                                      data['site_torso'].numpy()[i],\n                                      data['site_unknown'].numpy()[i],\n                                      data['site_upper extremity'].numpy()[i],\n                                      label.numpy()[i],\n                                      height.numpy()[i],\n                                      width.numpy()[i]\n                                     )\n\n                out_file.write(example.SerializeToString())\n\n            print(\"Wrote file {} containing {} records\".format(filename, shard_size))","d40eea60":"Sharding: there will be one \"batch\" of images per file","dbeb9daf":"### Loading libraries","7e6ff497":"The `anatom_site_general_challenge` column of the test set contains missing values as well","fdc8abd2":"We will replace the missing values for `age_approx` with the median age of the patients present in the dataset. As for the other two columns, we will mark the missing values with the word \"unknown\". ","2219a964":"Observe that the age values are all integer in both `train` and `test`. Let's cast `age_approx` into `np.uint8` format.","19839e2b":"### Recompress the images\n\nGoogle Cloud Storage is capable of great throughput but has a per-file access penalty. Training on thousands of individual files will be too slow. We have to use the TFRecord format to group files together. To do that, we first need to recompress our images. The bandwidth savings outweight the decoding CPU cost.","dca3b977":"### Setting up basic parameters","efa906c0":"### Acknowledgement\n\nIn this notebook, we follow the approach outlined by Martin G\u00f6rner in [Part 1 of his Keras on TPU series](https:\/\/codelabs.developers.google.com\/codelabs\/keras-flowers-data\/#0).","fb5aa67b":"### Turning the fold data into a TF dataset\n\nOur next step is to make a set of Tensor Flow datasets, one for each fold. Each dataset will include the input data and the labels. The input data will placed in a dictionary. We can access different features by calling the dictionary with the corresponding key.","50b8d3f0":"Note that there is no `diagnosis` column in the test set. ","a0afa014":"Three types of data can be stored in TFRecords: bytestrings, integers and floats. They are always stored as lists, a single data element will be a list of size 1.","a6695253":"### Resizing and cropping\n\nThe function below does resizing and cropping of the original images. We also add the original height and width to the list of features.","f10c55cf":"Yes, it does. Now we will apply one-hot encoding to `sex` and `anatom_site_general_challenge`. We will not be one-hot encoding `diagnosis` since it is present only in the training set. ","a6693e72":"The unique values in `train`:","c70e5484":"The unique values in `test`:","b3b7e152":"### One-hot encoding for categorical variables","0867bafd":"### Loading the fold indicies\n\nWe will use the validation and training fold indicies generated in [this kernel](https:\/\/www.kaggle.com\/graf10a\/siim-stratified-groupkfold-5-folds).","28f5f4d7":"Checking if `anatom_site_general_challenge` has the same set of values in `train` and `test`:","ea00b0d0":"The function below reads each J PEG image file from the disk using the filename provided in the `image_name` column of `train` or `test`. Then it turns the JPEG-encoded image into a uint8 tensor using `tf.image.decode_jpeg`.","dde0a75e":"### Write dataset to TFRecord files ","2b67e3df":"Applying this function to each of the datasets using `map`:","7177c736":"### Imputing missing values\n\nThe `sex`, `age_approx`, and `anatom_site_general_challenge` columns of the training set contain missing values:","f6fccfce":"### Loading training data","0776a637":"### Scaling the age feature"}}