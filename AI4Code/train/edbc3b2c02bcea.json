{"cell_type":{"c959dea0":"code","cb59be1c":"code","e34b2cd8":"code","96e99b19":"code","214280e3":"code","943e9607":"code","66827267":"code","fef6443b":"code","cd3e2138":"code","043bfbe2":"code","2e6ddbfd":"code","3087c572":"code","55a21000":"code","89957b55":"code","f9ffc998":"code","fdca378b":"code","79cdb146":"code","82cf3352":"code","b50ecac5":"code","89fb1485":"code","2b7226a6":"code","842c4c8c":"code","5d742464":"code","f7ccfb0c":"code","bcb569ff":"code","48bc8362":"code","2454d23a":"code","8c7a4655":"code","48b16f39":"code","d75ca27c":"code","1781b6d0":"code","00d2482d":"code","e1e5bf99":"code","b4f57c95":"code","26922b93":"code","75def234":"code","d38f1189":"code","b1f0508a":"code","e53c9315":"code","386183b5":"markdown","fa5bfa00":"markdown","8bf90069":"markdown","dafd5e9c":"markdown","191ab9ff":"markdown","c3607db4":"markdown","07ed56c2":"markdown","25f0c41a":"markdown","93bf192b":"markdown","329f2a62":"markdown","b0778824":"markdown","fa32d5cb":"markdown","5b1f0ca5":"markdown","0f0cef7b":"markdown","582c93d0":"markdown","d504fee0":"markdown","56c17ba8":"markdown","c3079f34":"markdown","cdac77d6":"markdown","1368a1f0":"markdown"},"source":{"c959dea0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","cb59be1c":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()","e34b2cd8":"(market_train_df, news_train_df) = env.get_training_data()","96e99b19":"# inspired by\n# https:\/\/www.kaggle.com\/artgor\/eda-feature-engineering-and-everything\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler","214280e3":"print(f'{market_train_df.shape[0]} samples and {market_train_df.shape[1]} features in the training market dataset.')","943e9607":"market_train_df.isna().sum()","66827267":"# Chrono sort data\nmarket_train_df = market_train_df.sort_values('time')\nmarket_train_df['date'] = market_train_df['time'].dt.date\n\n# Fill nan\nmarket_train_fill = market_train_df\ncolumn_market = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolumn_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\nfor i in range(len(column_raw)):\n    market_train_fill[column_market[i]] = market_train_fill[column_market[i]].fillna(market_train_fill[column_raw[i]])","fef6443b":"data = []\nfor asset in np.random.choice(market_train_df['assetName'].unique(), 10):\n    asset_df = market_train_df[(market_train_df['assetName'] == asset)]\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"v\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","cd3e2138":"market_train_df['close'].head() ","043bfbe2":"# ako na quint reg - chcel som vidie\u0165 ako reaguju lacn\u00e9 a drah\u0161ie, teda men\u0161ie spolo\u010dnosti a top.\n\ndata = []\n\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['close'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['close'].values,\n        name = f'{i} quantile'))\n    \nlayout = go.Layout(dict(title = \"Trends of closing prices by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'USD'),\n                  ),legend=dict(\n                orientation=\"v\"))\n\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","2e6ddbfd":"price_df.head()","3087c572":"outliers = market_train_df[(market_train_df['returnsOpenNextMktres10'] > 1) |  (market_train_df['returnsOpenNextMktres10'] < -1)]\noutliers['returnsOpenNextMktres10'].describe()","55a21000":"# returnsOpenNextMktres10 data without outliers\nwoOutliers = market_train_df[(market_train_df['returnsOpenNextMktres10'] < 1) &  (market_train_df['returnsOpenNextMktres10'] > -1)]\nwoOutliers['returnsOpenNextMktres10'].describe()","89957b55":"# Create a trace\ntrace1 = go.Histogram(\n    x = woOutliers.sample(n=10000)['returnsOpenNextMktres10'].values\n)\n\nlayout = dict(title = \"returnsOpenNextMktres10 (random 10.000 sample; without outliers)\")\ndata = [trace1]\n\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","f9ffc998":"# zavies\u0165 ist\u00fa metriku, pre detekovanie\nmarket_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\n\ngrouped = market_train_df.groupby('time').agg({'price_diff': ['std', 'min']}).reset_index()\n\nprint(f\"Average standard deviation of price change within a day in {grouped['price_diff']['std'].mean():.4f}.\")","fdca378b":"# Vizualiz\u00e1cia n\u00e1\u0161ho probl\u00e9mu\n\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * g['price_diff']['min']).astype(str)\n\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","79cdb146":"market_train_df.sort_values('price_diff')[:10]","82cf3352":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] \/ market_train_df['open'])","b50ecac5":"print(f\"In {(market_train_df['close_to_open'] >= 1.2).sum()} lines price increased by 20% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.8).sum()} lines price decreased by 20% or more.\")","89fb1485":"print(f\"In {(market_train_df['close_to_open'] >= 2).sum()} lines price increased by 100% or more.\")\nprint(f\"In {(market_train_df['close_to_open'] <= 0.5).sum()} lines price decreased by 100% or more.\")","2b7226a6":"market_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']","842c4c8c":"market_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\ngrouped = market_train_df.groupby(['time']).agg({'price_diff': ['std', 'min']}).reset_index()\ng = grouped.sort_values(('price_diff', 'std'), ascending=False)[:10]\ng['min_text'] = 'Maximum price drop: ' + (-1 * np.round(g['price_diff']['min'], 2)).astype(str)\n\ntrace = go.Scatter(\n    x = g['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = g['price_diff']['std'].values,\n    mode='markers',\n    marker=dict(\n        size = g['price_diff']['std'].values * 5,\n        color = g['price_diff']['std'].values,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = g['min_text'].values\n    #text = f\"Maximum price drop: {g['price_diff']['min'].values}\"\n    #g['time'].dt.strftime(date_format='%Y-%m-%d').values\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Top 10 months by standard deviation of price change within a day',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'price_diff',\n        ticklen= 5,\n        gridwidth= 2,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","5d742464":"data = []\n\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['returnsOpenNextMktres10'].values,\n        name = f'{i} quantile'\n    ))\n    \nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"v\"),\n                  )\n\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","f7ccfb0c":"data = []\n\nmarket_train_df = market_train_df.loc[market_train_df['time'] >= '2010-01-01 22:00:00+0000']\n\nprice_df = market_train_df.groupby('time')['returnsOpenNextMktres10'].mean().reset_index()\n\ndata.append(go.Scatter(\n    x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n    y = price_df['returnsOpenNextMktres10'].values,\n    name = f'{i} quantile'))\n\nlayout = go.Layout(dict(title = \"Treand of returnsOpenNextMktres10 mean\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","bcb569ff":"data = []\nfor col in ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n       'returnsOpenNextMktres10']:\n    df = market_train_df.groupby('time')[col].mean().reset_index()\n    data.append(go.Scatter(\n        x = df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = df[col].values,\n        name = col\n    ))\n    \nlayout = go.Layout(dict(title = \"Treand of mean values\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","48bc8362":"print(f'{news_train_df.shape[0]} samples and {news_train_df.shape[1]} features in the training news dataset.')","2454d23a":"text = ' '.join(news_train_df['headline'].str.lower().values[-1000000:])\nwordcloud = WordCloud(max_font_size=None, stopwords=stop, background_color='white',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in headline')\nplt.axis(\"off\")\nplt.show()","8c7a4655":"news_train_df['sentence_word_count'] =  news_train_df['wordCount'] \/ news_train_df['sentenceCount']\nplt.boxplot(news_train_df['sentence_word_count'][news_train_df['sentence_word_count'] < 40]);","48b16f39":"provider_count = news_train_df.groupby('provider')['sourceId'].count()","d75ca27c":"provider_sort = provider_count.sort_values(ascending= False)\nprovider_sort[:10].plot.barh()\nplt.xlabel('Count')\nplt.ylabel('Provider')\nplt.title('Top 10 news provider')\nplt.gca().invert_yaxis()\ndel provider_count","1781b6d0":"asset_name = news_train_df.groupby('assetName')['sourceId'].count()\nprint('Total number of assets: ',news_train_df['assetName'].nunique())","00d2482d":"asset_name = asset_name.sort_values(ascending=False)\nasset_name[:10].plot.barh()\nplt.gca().invert_yaxis()\nplt.xlabel('Count')\nplt.title('Top 10 assets news')","e1e5bf99":"# top mentioned by sentiment\nfor i, j in zip([-1, 0, 1], ['negative', 'neutral', 'positive']):\n    df_sentiment = news_train_df.loc[news_train_df['sentimentClass'] == i, 'assetName']\n    print(f'Top mentioned companies for {j} sentiment are:')\n    print(df_sentiment.value_counts().head(5))\n    print('')","b4f57c95":"# Function to remove outliers\ndef remove_outliers(data_frame, column_list, low=0.02, high=0.98):\n    temp_frame = data_frame\n    for column in column_list:\n        this_column = data_frame[column]\n        quant_df = this_column.quantile([low,high])\n        low_limit = quant_df[low]\n        high_limit = quant_df[high]\n        temp_frame[column] = data_frame[column].clip(lower=low_limit, upper=high_limit)\n    return temp_frame","26922b93":"# Remove outlier\ncolumns_outlier = ['takeSequence', 'bodySize', 'sentenceCount', 'wordCount', 'sentimentWordCount', 'firstMentionSentence','noveltyCount12H',\\\n                  'noveltyCount24H', 'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H', 'volumeCounts24H',\\\n                  'volumeCounts3D','volumeCounts5D','volumeCounts7D']\nnews_rmv_outlier = remove_outliers(news_train_df, columns_outlier)","75def234":"# Plot correlation\ncolumns_corr = ['urgency', 'takeSequence', 'companyCount','marketCommentary','sentenceCount',\\\n           'firstMentionSentence','relevance','sentimentClass','sentimentWordCount','noveltyCount24H',\\\n           'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D','volumeCounts24H','volumeCounts3D','volumeCounts5D','volumeCounts7D']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(18,15))\nsns.heatmap(news_rmv_outlier[columns_corr].astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\nplt.title('Pair-wise correlation')","d38f1189":"market_train_df.head()","b1f0508a":"class LinearRegressionGD(object):\n    def __innit__(self, eta=0.01, n_iter=20):\n        self.eta = eta\n        self.n_iter = n.iter\n    \n    def fit(self, X, y):\n        self.w_ = np.zeros(1 + X.shape[1])\n        self.cost_ = []\n        \n        for i in range(self.n_iter):\n            output = self.net_input(X)\n            errors = (y - output)\n            self.w_[1:] += self.eta * X.T.dot(errors)\n            self.w_[0] += self.eta * errors.sum()\n            cost = (errors**2).sum() \/ 2.0\n            self.cost_.append(cost)\n        return self\n    \n    def net_input(self, X):\n        return np.dot(X, self.w_[1:]) + self.w_[0]\n    \n    def predict(self, X):\n        return self.net_input(X)","e53c9315":"X = market_train_df[]","386183b5":"## Auto Features Engineering   \/\/ WIP","fa5bfa00":"TO DO: Elab. more, DOW and Dataset logic behind the fall","8bf90069":"### WIP MESS \/\/ working in KernelBC","dafd5e9c":"Asset Name","191ab9ff":"### Add TA Features\n\nTypes of Returns\n\nReturns calculated close-to-close (from the closing time of one trading day to the closing time of anotherc & not adjusted) for 1 day. returnsClosePrevRaw1\n\nReturns calculated open-to-open (from the opening time of one trading day to the opening time of another & not adjusted) for 1 day. returnsOpenPrevRaw1\n\nReturns calculated close-to-close (from the closing time of one trading day to the closing time of anotherc & market adjusted) for 1 day. returnsClosePrevMktres1\n\nReturns calculated open-to-open (from the opening time of one trading day to the opening time of another & market adjusted) for 1 day. returnsOpenPrevMktres1\n\nReturns calculated close-to-close (from the closing time of one trading day to the closing time of anotherc & not adjusted) for 10 days. returnsClosePrevRaw10\n\nReturns calculated open-to-open (from the opening time of one trading day to the opening time of another & not adjusted) for 10 days. returnsOpenPrevRaw10\n\nReturns calculated close-to-close (from the closing time of one trading day to the closing time of anotherc & market adjusted) for 10 days. returnsClosePrevMktres10\n\nReturns calculated open-to-open (from the opening time of one trading day to the opening time of another & market adjusted) for 10 days. returnsOpenPrevMktres10\n\nReturns calculated open-to-open (from the closing time of one trading day to the closing time of another & market adjusted) for 10 days. **returnsCloseNextMktres10 Prediction of returns in next 10 days, then hist how off model is**.","c3607db4":"# Modelling; sep","07ed56c2":"slov na vetu","25f0c41a":"We can see that quantiles have a high deviation, but mean value doesn't change much.","93bf192b":"Fix = spravi\u0165 mean open | close pre t\u00fa spolo\u010dnos\u0165 \u010di vyhodi\u0165","329f2a62":"H\u013ead\u00e1me \u010dud\u00e1cke miesta","b0778824":"Providers of news","fa32d5cb":"Aha, nie\u010do tu nesed\u00ed.\nDrop v cene o skoro 10 000 v Jan 2010? O tom nevieme. Pozrime sa hlb\u0161ie","5b1f0ca5":"![Picture 1](https:\/\/www.tradingview.com\/x\/1KyPFYtW\/)","0f0cef7b":"# News","582c93d0":"# EDA Asset prices","d504fee0":"#### \u010ealej sa pozrieme na tie outlier-ish situ\u00e1cie","56c17ba8":"Vidie\u0165, ako reaguj\u00fa ak\u00e9 spolo\u010dnosti na v\u00fdvoj trhu od 2007 do 2017.","c3079f34":"Tak\u00e9to ploty m\u00fdlia \u013eud\u00ed, \u017ee v\u00fdnosy na akciov\u00fdch trhoch poch\u00e1dzaj\u00fa z norm.dist??","cdac77d6":"V d\u00e1tach \u010dasov\u00fdch radov je auto-korel\u00e1cia?\nWhen regression is performed on time series data, the errors may not be independent. Often errors are autocorrelated; that is, each error is correlated with the error immediately before it. Autocorrelation is also a symptom of systematic lack of fit. Recall test DW_MAR1","1368a1f0":"Disappearence could be due to bankruptcy, acquisition or other reasons."}}