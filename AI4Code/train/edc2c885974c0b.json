{"cell_type":{"7c3d4893":"code","2ca80ad9":"code","181dd9ec":"code","419d8786":"code","44456f2e":"code","74996fd2":"code","956a5a8d":"code","b6070334":"code","acbf9ae0":"code","c8c72b8f":"code","8b135dd1":"code","2d4203ac":"code","ecdd1acf":"code","7a28c6f3":"code","2afefb74":"code","caaae7e9":"code","f3630dd8":"code","17b01c1a":"code","7e8a0fad":"code","7b02ce5c":"code","d40ae5c1":"code","09122243":"code","108e1ed1":"code","60879c1c":"code","eb946b43":"code","29127f6f":"code","9ca5c87e":"code","3a14de17":"code","59abdc99":"code","8caf9c9d":"code","173738b6":"code","5990fa6e":"code","68003c28":"code","f7ee60de":"code","3f9b8bda":"code","de20d427":"code","5eea0fcc":"code","b33278a3":"code","6e2923b1":"code","76611524":"code","6e853b6e":"code","08b92af2":"code","bc35ad25":"code","33b9294f":"markdown","5d1a0840":"markdown"},"source":{"7c3d4893":"#Import libraries\n#install specific version of libraries used in lab\n#! mamba install pandas==1.3.3-y\n#! mamba install numpy=1.21.2-y\n#! mamba install sklearn=0.20.1-y","2ca80ad9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","181dd9ec":"# path of data \npath = 'https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork\/labs\/Data%20files\/automobileEDA.csv'\ndf = pd.read_csv(path)\ndf.head()","419d8786":"#Linear Regression and Multiple Linear Regression\n#loading\nfrom sklearn.linear_model import LinearRegression\n#Create the linear regression object\nlm = LinearRegression()\nlm","44456f2e":"# how highway-mpg can help us predict car price. Using simple linear regression, we will create a linear function with \"highway-mpg\" as the predictor variable and the \"price\" as the response variable\nX = df[['highway-mpg']]\nY = df['price']","74996fd2":"#Fit the linear model using highway-mpg:\nlm.fit(X,Y)","956a5a8d":"#prediction\nYhat=lm.predict(X)\nYhat[0:5]   ","b6070334":"#value of the intercept(a)and value of the slope (b)\nlm.intercept_\nlm.coef_","acbf9ae0":"#Creating a linear regression object called \"lm1\".\nlm1 = LinearRegression()\nlm1","c8c72b8f":"#Training the model using \"engine-size\" as the independent variable and \"price\" as the dependent variable\nlm1.fit(df[['engine-size']], df[['price']])\nlm1","8b135dd1":"# Slope \nlm1.coef_\n\n# Intercept\nlm1.intercept_","2d4203ac":"#equation of the predicted line using x and yhat or \"engine-size\" or \"price\"\n# using X and Y  \nYhat=-7963.34 + 166.86*X\nPrice=-7963.34 + 166.86*X","ecdd1acf":"#Multiple Linear Regression\n#good predictors of price could be:Horsepower,Curb-weight,Engine-size,Highway-mpg\n#develop a model using these variables as the predictor variables\nZ = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\nlm.fit(Z, df['price'])\nlm.intercept_\nlm.coef_\n\n","7a28c6f3":"#Create and train a Multiple Linear Regression model \"lm2\" where the response variable is \"price\", and the predictor variable is \"normalized-losses\" and \"highway-mpg\".\nlm2 = LinearRegression()\nlm2.fit(df[['normalized-losses' , 'highway-mpg']],df['price'])","2afefb74":"lm2.coef_","caaae7e9":"#Model Evaluation Using Visualization\n#Importing the visualization package, seaborn\nimport seaborn as sns\n%matplotlib inline ","f3630dd8":"#Regression Plot\n#visualize highway-mpg as potential predictor variable of price\nwidth = 12\nheight = 10\nplt.figure(figsize=(width, height))\nsns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\nplt.ylim(0,)","17b01c1a":"#We can see from this plot that price is negatively correlated to highway-mpg since the regression slope is negative.\n#One thing to keep in mind when looking at a regression plot is to pay attention to how scattered the data points are around the regression line. This will give you a good indication of the variance of the data and whether a linear model would be the best fit or not. If the data is too far off from the line, this linear model might not be the best model for this data.","7e8a0fad":"# compare this plot to the regression plot of \"peak-rpm\".\nplt.figure(figsize=(width, height))\nsns.regplot(x=\"peak-rpm\", y=\"price\", data=df)\nplt.ylim(0,)","7b02ce5c":"#Comparing the regression plot of \"peak-rpm\" and \"highway-mpg\", we see that the points for \"highway-mpg\" are much closer to the generated line and, on average, decrease. The points for \"peak-rpm\" have more spread around the predicted line and it is much harder to determine if the points are decreasing or increasing as the \"peak-rpm\" increases.","d40ae5c1":"## The variable \"highway-mpg\" has a stronger correlation with \"price\", it is approximate -0.704692  compared to \"peak-rpm\" which is approximate -0.101616. You can verify it using the following command:\ndf[[\"peak-rpm\",\"highway-mpg\",\"price\"]].corr()","09122243":"#Multiple Linear Regression, distribution plot\nY_hat = lm.predict(Z)\nplt.figure(figsize=(width, height))\n\n\nax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")\nsns.distplot(Y_hat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n\n\nplt.title('Actual vs Fitted Values for Price')\nplt.xlabel('Price (in dollars)')\nplt.ylabel('Proportion of Cars')\n\nplt.show()\nplt.close()\n","108e1ed1":"#We can see that the fitted values are reasonably close to the actual values since the two distributions overlap a bit. However, there is definitely some room for improvement.","60879c1c":"#Polynomial Regression and Pipelines\n#We saw earlier that a linear model did not provide the best fit while using \"highway-mpg\" as the predictor variable. Let's see if we can try fitting a polynomial model to the data instead.\ndef PlotPolly(model, independent_variable, dependent_variabble, Name):\n    x_new = np.linspace(15, 55, 100)\n    y_new = model(x_new)\n\n    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n    ax = plt.gca()\n    ax.set_facecolor((0.898, 0.898, 0.898))\n    fig = plt.gcf()\n    plt.xlabel(Name)\n    plt.ylabel('Price of Cars')\n\n    plt.show()\n    plt.close()","eb946b43":"#variables:\n\nx = df['highway-mpg']\ny = df['price']","29127f6f":"#fit the polynomial using the function polyfit, then use the function poly1d to display the polynomial function.\n# Here we use a polynomial of the 3rd order (cubic) \nf = np.polyfit(x, y, 3)\np = np.poly1d(f)\nprint(p)\n\n#plot the function\nPlotPolly(p, x, y, 'highway-mpg')\nnp.polyfit(x, y, 3)","9ca5c87e":"#We can already see from plotting that this polynomial model performs better than the linear model. This is because the generated polynomial function \"hits\" more of the data points","3a14de17":"#Create 11 order polynomial model with the variables x and y from above\n# Here we use a polynomial of the 11rd order (cubic) \nf1 = np.polyfit(x, y, 11)\np1 = np.poly1d(f1)\nprint(p1)\nPlotPolly(p1,x,y, 'Highway MPG')","59abdc99":"#polynomial transform on multiple features. First, we import the module\nfrom sklearn.preprocessing import PolynomialFeatures\n#create a PolynomialFeatures object of degree 2:\npr=PolynomialFeatures(degree=2)\npr\nZ_pr=pr.fit_transform(Z)\n#In the original data, there are 201 samples and 4 features.\nZ.shape\nZ_pr.shape#After the transformation, there are 201 samples and 15 features.","8caf9c9d":"#Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n","173738b6":"#Create the pipeline by creating a list of tuples including the name of the model or estimator and its corresponding constructor.\nInput=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]","5990fa6e":"pipe=Pipeline(Input)\npipe","68003c28":"#convert the data type Z to type float to avoid conversion warnings that may appear as a result of StandardScaler taking float inputs.\n#normalizing\nZ = Z.astype(float)\npipe.fit(Z,y)","f7ee60de":"#normalize the data, perform a transform and produce a prediction\nypipe=pipe.predict(Z)\nypipe[0:4]","3f9b8bda":"#Creating a pipeline that standardizes the data, then produce a prediction using a linear regression model using the features Z and target y.\nInput=[('scale',StandardScaler()),('model',LinearRegression())]\n\npipe=Pipeline(Input)\n\npipe.fit(Z,y)\n\nypipe=pipe.predict(Z)\nypipe[0:10]","de20d427":"#Measures for In-Sample Evaluation\n#Simple Linear Regression\n#highway_mpg_fit\nlm.fit(X, Y)\n# Find the R^2\nprint('The R-square is: ', lm.score(X, Y))\n","5eea0fcc":"#MSC\n#We can predict the output i.e., \"yhat\" using the predict method, where X is the input variable\nYhat=lm.predict(X)\nprint('The output of the first four predicted value is: ', Yhat[0:4])","b33278a3":"#importing function MSC\nfrom sklearn.metrics import mean_squared_error\n#compare the predicted results with the actual results\nmse = mean_squared_error(df['price'], Yhat)\nprint('The mean square error of price and predicted value is: ', mse)","6e2923b1":"#Multiple Linear Regression\n#calculation of R^2\n# fit the model \nlm.fit(Z, df['price'])\n# Find the R^2\nprint('The R-square is: ', lm.score(Z, df['price']))","76611524":"#We can say that ~80.896 % of the variation of price is explained by this multiple linear regression \"multi_fit\".\n#calculate MSE.\n#prediction:\nY_predict_multifit = lm.predict(Z)\nprint('The mean square error of price and predicted value using multifit is: ', \\\n      mean_squared_error(df['price'], Y_predict_multifit))","6e853b6e":"# Polynomial Fit\nfrom sklearn.metrics import r2_score\n#We apply the function to get the value of R^2\nr_squared = r2_score(y, p(x))\nprint('The R-square value is: ', r_squared)\n#We can say that ~67.419 % of the variation of price is explained by this polynomial fit.","08b92af2":"#MSE\nmean_squared_error(df['price'], p(x))","bc35ad25":"#Prediction and Decision Making\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline \n\n#Create a new input:\n\nnew_input=np.arange(1, 100, 1).reshape(-1, 1)\n#Fit the model:\n\nlm.fit(X, Y)\nlm\n#Produce a prediction:\n\nyhat=lm.predict(new_input)\nyhat[0:5]\n#We can plot the data:\n\nplt.plot(new_input, yhat)\nplt.show()","33b9294f":"Questions\n 1.Do I know if the dealer is offering fair value for my trade-in?\n 2.Do I know if I put a fair value on my car?","5d1a0840":"Conclusion:\nComparing these three models, we conclude that the MLR model is the best model to be able to predict price from our dataset. This result makes sense since we have 27 variables in total and we know that more than one of those variables are potential predictors of the final car price."}}