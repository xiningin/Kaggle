{"cell_type":{"ea2e87b1":"code","57bdcbd5":"code","81272372":"code","6aa13be4":"code","6ffed8a7":"code","0aae8b3b":"code","91b7a515":"code","6cf8bd8d":"code","46141bc4":"code","151e4ad9":"code","a718a8ea":"code","6de4443b":"code","6223cddb":"code","2d8ca707":"code","eb0160b7":"code","6a2b6d97":"code","cde77757":"code","2417f44a":"code","a4865534":"code","83f65f01":"code","6fda25f8":"code","6da9910e":"code","4c9f7215":"code","05b6bc85":"code","a59a2cf9":"code","8b62e41a":"code","d0cde033":"code","f9d419a1":"code","369237c8":"code","c9664b20":"code","fe5da25e":"code","676f0a11":"code","993d0957":"code","10e9be25":"code","0c79d52b":"markdown","7a6f8180":"markdown","b23d8241":"markdown","3ca41a05":"markdown","0114dbd4":"markdown","14f0b432":"markdown","35ca11d1":"markdown","8eaa41cd":"markdown","f47d5c61":"markdown","02c3fed9":"markdown","b76c1de4":"markdown","d6b85506":"markdown","950032bc":"markdown","e769d241":"markdown","cc6f81bb":"markdown","da8c3e6b":"markdown"},"source":{"ea2e87b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport os\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","57bdcbd5":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","81272372":"train.shape, test.shape, gender.shape","6aa13be4":"train.head()","6ffed8a7":"test.head()","0aae8b3b":"gender.head()","91b7a515":"train.columns","6cf8bd8d":"train.dtypes","46141bc4":"train.isna().sum()","151e4ad9":"train.drop('Name', axis = 1, inplace = True)\ntest.drop('Name', axis = 1, inplace = True)\ntrain.describe()","a718a8ea":"train['Sex'].replace({'male' : 1, 'female' : 0}, inplace=True)\ntest['Sex'].replace({'male' : 1, 'female' : 0}, inplace=True)","6de4443b":"train['Ticket'].unique().shape","6223cddb":"train['Ticket'].value_counts(sort = True, ascending=False)[:20]","2d8ca707":"ticket_to_keep = train['Ticket'].value_counts(sort = True, ascending=False)[:6].index","eb0160b7":"l = []\nfor i, j in enumerate(train['Ticket']):\n    if j in ticket_to_keep[:5]:\n        l.append(j)\n    else:\n        l.append('other')\nTicket_dummy = pd.get_dummies(ticket).drop(['0_other', '0_347082'], axis = 1)\nTicket_dummy.head()","6a2b6d97":"l_test = []\nfor i, j in enumerate(test['Ticket']):\n    if j in ticket_to_keep:\n        l_test.append(j)\n    else:\n        l_test.append('other')\nticket_test = pd.DataFrame(l_test)\nTicket_dummy_test = pd.get_dummies(ticket_test).drop('0_other', axis = 1)\nTicket_dummy_test.head()","cde77757":"Ticket_dummy.shape, Ticket_dummy_test.shape","2417f44a":"train['Cabin'].unique()","a4865534":"train['Embarked'].unique()","83f65f01":"Embarked_dummies = pd.get_dummies(train['Embarked'], drop_first=True)\nEmbarked_dummies_test = pd.get_dummies(test['Embarked'], drop_first=True)\nEmbarked_dummies.shape, Embarked_dummies_test.shape","6fda25f8":"train1 = train.drop(['PassengerId', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\ntest1 = test.drop(['PassengerId', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\ntrain1.head(3)","6da9910e":"columns = train1.columns[1:]\nfig, axe = plt.subplots(2,3, figsize = (14,7))\nfor i in range(2):\n    for j in range(3):\n        s = 3*i + j\n        axe[i,j].plot(train[columns[s]])\n        axe[i,j].set_title(columns[s])","4c9f7215":"x_train = pd.concat([train1.drop('Survived', axis = 1), Ticket_dummy, Embarked_dummies], axis = 1)\nx_test = pd.concat([test1, Ticket_dummy_test, Embarked_dummies_test], axis = 1)\ny_train = train1['Survived']\ny_test = gender['Survived']\nx_train.head(4)","05b6bc85":"train1.groupby('Survived').mean()","a59a2cf9":"print(pd.crosstab(train1.Pclass, train1.Survived))\npd.crosstab(train1.Pclass, train1.Survived).plot(kind = 'bar', figsize = (10,7))\nplt.ylabel('no. of people')\nplt.show()","8b62e41a":"print(pd.crosstab(train1.Age, train1.Survived))\ntrain2 = train1.copy()\ntrain2 = train2.sort_values(by = 'Age', ascending=True)\npd.crosstab(train2.Age, train2.Survived).plot(kind = 'bar', figsize = (25,7))\nplt.ylabel('no. of people')\nplt.show()","d0cde033":"train3 = train1.copy()\ntrain3 = train2.sort_values(by = 'Fare', ascending=True)\npd.crosstab(train3.Fare, train3.Survived).plot(kind = 'bar', figsize = (25,7))\nplt.ylabel('no. of people')\nplt.show()","f9d419a1":"x_train.Age = x_train.Age.fillna(x_train.Age.mean())\nx_test.Age = x_test.Age.fillna(x_train.Age.mean())\nx_train.isna().sum()","369237c8":"x_test.isna().sum()","c9664b20":"x_test.Fare = x_test.Fare.fillna(x_test.Fare.mean())\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","fe5da25e":"def find_best_model(x, y):\n    algorithums = {\n        'RandomForestClassifier' : {\n            'model' : RandomForestClassifier(),\n            'parameters' : {\n                'n_estimators' : [100],\n                'random_state' : [0]\n            } \n        },\n        'AdaBoostClassifier' : {\n            'model' : AdaBoostClassifier(),\n            'parameters' : {\n                'learning_rate' : [0.1],\n                'random_state' : [0]\n            }\n        },\n        'DecisionTreeClassifier' : {\n            'model' : DecisionTreeClassifier(),\n            'parameters' : {\n                'random_state' : [0]\n            }\n        },\n        'LogisticRegression' : {\n            'model' : LogisticRegression(),\n            'parameters' : {\n                'C' : [0.5],\n                'random_state' : [0]\n            }\n        },\n        'LogisticRegressionCV' : {\n            'model' : LogisticRegressionCV(),\n            'parameters' : {\n                'Cs' : [10]\n            }\n        },\n        'SVC' : {\n            'model' : SVC(),\n            'parameters' : {\n                'C' : [5]\n            }\n        },\n        'KNeighborsClassifier' :  {\n            'model' : KNeighborsClassifier(),\n            'parameters' : {\n                'n_neighbors' : [10]\n            }\n        }\n    }\n    score = []\n    cv = StratifiedShuffleSplit(n_splits=5, test_size = 0.2, random_state=0)\n    for algo_name, algo in algorithums.items():\n        fitter = GridSearchCV(algo['model'], algo['parameters'], cv = cv, return_train_score=False)\n        fitter.fit(x, y)\n        score.append({\n            'model' : algo_name,\n            'best_score' : fitter.best_score_,\n            'best_parameter' : fitter.best_params_\n        })\n    return score","676f0a11":"model_score_dict = find_best_model(x_train, y_train)","993d0957":"pd.DataFrame(model_score_dict)","10e9be25":"model = RandomForestClassifier(n_estimators=60, random_state=0)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\nprint('accuracy is : ', accuracy_score(y_test, y_pred))","0c79d52b":"Label encoding can be performed easily ","7a6f8180":"Lets now explore the data by ploting various plots","b23d8241":"#pessangers who have paid more fare have more no. of survival\n\n#Age is also a major factor which shows that young people have more chances of survival","3ca41a05":"Age is also a major factor which shows that young people have more chances of being survived","0114dbd4":"for our shake lets check ticket data and take 5 best occuring types of ticket and perform label encoding","14f0b432":"lets check which kind of data we have","35ca11d1":"Lets now drop all columns which are of no use while training our model","8eaa41cd":"Lets define a function to select the best model","f47d5c61":"Fare have direct impact on chances of surviving. Those people who had paid more, are survived in large amount than others","02c3fed9":"the graph shows that people who are in 3rd class have very little chances of survival whereas people in 1st class have highest chances","b76c1de4":"Cabin contains a lot of NaN values and remaining are categorical. So, insted of performing label encoding, i am going to drop it in further steps","d6b85506":"Drop Name as it is not providing any information","950032bc":"del train2, train3","e769d241":"by clearly inspecting, found that '0_347082' ticket is not occuring in same sequence as in train data","cc6f81bb":"RandomForestClassifier is performing better than other models","da8c3e6b":"Lets handle categorical variables"}}