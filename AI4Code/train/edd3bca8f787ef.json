{"cell_type":{"1d96143b":"code","ee6587fc":"code","361f1fe0":"code","75d9a426":"code","9941609a":"code","2080bdbd":"code","5a487eac":"code","dbd3c35c":"code","34a23c10":"code","f5fdda89":"code","240bfc17":"code","d7fbfaac":"code","65b180a9":"code","b6d43e7f":"code","2daf2dc5":"code","ccd64f86":"code","e1aba23e":"code","65f02699":"code","2eb63459":"markdown","db1fa097":"markdown","2e83bd91":"markdown","8c6cdc6f":"markdown","b9e33cf8":"markdown","58932ac3":"markdown","da961699":"markdown","3b0040b5":"markdown","1c25b82d":"markdown","338bcfbb":"markdown","d7bd06ef":"markdown","a6c571f6":"markdown","927c1c90":"markdown","2ac76f37":"markdown","883e9cc5":"markdown","14787c26":"markdown","0373301c":"markdown"},"source":{"1d96143b":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport copy\nimport time\nimport torch.optim as optim","ee6587fc":"from torchvision import transforms\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","361f1fe0":"trainset = torchvision.datasets.ImageFolder(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\", transform = transform)\nvalset = torchvision.datasets.ImageFolder(\"..\/input\/chest-xray-pneumonia\/chest_xray\/val\", transform = transform)\ntestset = torchvision.datasets.ImageFolder(\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\", transform = transform)","75d9a426":"batch_size = 128\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\nevalloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)","9941609a":"dataiter = iter(trainloader)\nimages, labels = dataiter.next()\nprint(images.shape)\nprint(labels.shape)","2080bdbd":"classes = ['Normal', 'Pneumonia']","5a487eac":"model = torchvision.models.resnet50(pretrained=True, progress=True)","dbd3c35c":"print(model)","34a23c10":"for p in model.parameters():\n    p.requires_grad = False\n","f5fdda89":"model.fc = nn.Sequential(\n    nn.Linear(2048, 1024),\n    nn.ReLU(),\n    nn.Linear(1024, 512),\n    nn.ReLU(),\n    nn.Linear(512, 256),\n    nn.ReLU(),\n    nn.Linear(256,2)\n    \n)","240bfc17":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","d7fbfaac":"model = model.to(device)","65b180a9":"loss_fn = nn.CrossEntropyLoss()\nopt = optim.Adam(model.parameters(), lr = 0.001)","b6d43e7f":"def evaluation(dataloader):\n    total, correct = 0,0\n    model.eval()\n    for data in dataloader:\n        images, labels = data\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, pred = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (pred == labels).sum().item()\n    return 100*correct\/total","2daf2dc5":"%%time\nloss_train_arr = []\nloss_val_arr = []\n\nmax_epochs = 10\nmin_val_loss = 1000\nfor epoch in range(max_epochs):\n    for i, data in enumerate(trainloader, 0):\n        inputs,labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        opt.zero_grad()\n        model.train()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        opt.step()\n        model.eval()\n        for j in evalloader:\n            images_val, labels_val = j\n            images_val, labels_val = images_val.to(device), labels_val.to(device)\n            output_val = model(images_val)\n            val_loss = loss_fn(output_val, labels_val)\n            if min_val_loss > val_loss.item():\n                min_val_loss = val_loss.item()\n                best_model = copy.deepcopy(model.state_dict())\n                print('Train loss %0.2f' % loss.item(), end = \" \")\n                print('Min val loss %0.2f' % min_val_loss)  \n                del inputs, labels, outputs, images_val, labels_val, output_val\n                torch.cuda.empty_cache()\n    loss_val_arr.append(val_loss.item())\n    loss_train_arr.append(loss.item())\n    model.eval()\n        \n    print('Epoch: %d\/%d, Train acc: %0.2f, eval acc: %0.2f' % (\n        epoch+1, max_epochs, \n        evaluation(trainloader), evaluation(evalloader)))\n    \n","ccd64f86":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nplt.plot(loss_train_arr, label='Training Loss')\nplt.plot(loss_val_arr, label='Validation Loss')\nplt.legend(frameon=False)","e1aba23e":"model.load_state_dict(best_model)\nprint(evaluation(testloader))","65f02699":"classes = ['Normal', 'Pneumonia']\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n    plt.show()\nimshow(torchvision.utils.make_grid(images[:1]))\nprint(\"Ground_Truth-\")\nprint(classes[labels[0]])\nimages = images.to(device)\noutput = model(images)\nmax_values, pred_class = torch.max(output.data, 1)\nprint(\"Predicted class-\")\nprint(classes[pred_class[0]])","2eb63459":"Here we will use Transfer Learning..i.e..using predefined RESNET model with a small variation in output layer. For Resnet we need the \nsize of input image to be 224 X 224 and also necessary transformations.","db1fa097":"Here we are dealing with 2 classes...but in resnet model there are 1000 classes in output layer. So we will redefine model.fc layer(last layer) by adding several layers and 2 classes at the end...","2e83bd91":"Model transeferred to device","8c6cdc6f":"Loaded RESNET model","b9e33cf8":"Just visuslised the shapes of images and labels","58932ac3":"We fixed the batch_size to be 128. Larger batch size gives us more accurate results but they are a bit slower...Smaller batch size performance is faster. This means that training will be faster.","da961699":"We are using CrossEntropyloss function here.. We use this loss function for classification problem. This loss function is a combination of Softmax and Negative logloss likelihood(nn.NLLLoss) loss function.","3b0040b5":"Loaded the best model and found accuracy of test dataset..","1c25b82d":"Visualised train and val losses...","338bcfbb":"The dataset is already divided into train, val and test folders. Also two subfolders of 'NORMAL' and 'Pneumonia' in each folder. We just need to open the Imagefolder to define dataset.","d7bd06ef":"Trained the model and saved the best model ..","a6c571f6":"IMPORTED LIBRARIES","927c1c90":"As we have loaded pretrained model the weights need not to be trained again...So we set it to False","2ac76f37":"Defined evaluation function for calculating accuracy.","883e9cc5":"Defined the two classes.","14787c26":"Model is completely ready...","0373301c":"Checked for GPU"}}