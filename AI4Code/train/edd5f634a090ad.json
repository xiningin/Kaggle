{"cell_type":{"f3f58d1f":"code","25b4d4f1":"code","383de215":"code","16d6089d":"code","439dd42c":"code","86470f2c":"code","77280179":"code","6c2b3dec":"code","95277e32":"code","8e9598fd":"code","52932b87":"code","97b196ba":"code","f7855f90":"code","ec135c01":"code","26079b74":"code","a628620f":"code","b501d19a":"code","c022820b":"code","fb8a9c8a":"code","0aa812dd":"code","8dac506d":"code","fb867c6a":"code","87154918":"code","130d726f":"code","a11f662c":"code","d1a454ed":"code","9d886c3c":"code","0bb5dacb":"code","56163967":"code","fb8f3860":"code","888474a3":"code","688b061d":"code","b1b035c7":"code","5023ecaf":"code","1fad624f":"code","ae0c5daf":"code","3938627a":"code","450a4f56":"code","23cdbd59":"code","861080f8":"code","4fc2ce8a":"code","013b5a76":"code","4cb229d3":"code","5ab6ce43":"code","136aa962":"code","be9ad9c8":"code","3cb061b7":"code","3c17e23a":"code","26c46904":"code","3463f7dd":"code","c4fa2228":"code","28ce14b4":"code","af4cb7ad":"code","be4ce4a5":"code","360172a7":"code","cdb46162":"code","f4cbf19e":"code","97d171bf":"code","c61afdf3":"markdown","55c2332c":"markdown","5ecc4e76":"markdown","642ea1f6":"markdown","c391855a":"markdown","58f5fd68":"markdown","ab04ddd8":"markdown","d981ba71":"markdown","459e667e":"markdown","ee1d4200":"markdown","ce5d7ded":"markdown","2e76acba":"markdown","6828604c":"markdown","3fbe601c":"markdown","4b986395":"markdown","b17d3af4":"markdown","78710247":"markdown","bfa11d5d":"markdown","4f638216":"markdown","d780503b":"markdown","88cb02ee":"markdown","6c2c8b59":"markdown","51c12ab2":"markdown","f8c43ea7":"markdown","740c5fa6":"markdown","aee02cf9":"markdown","69fa5a73":"markdown","b818b50e":"markdown","a100084f":"markdown","52de5598":"markdown","bc70c8c3":"markdown","e7f24908":"markdown","92025d09":"markdown","483b21a8":"markdown","d9635cb9":"markdown","c2771365":"markdown","c9783b66":"markdown","ac37b03c":"markdown","d6c1dbbf":"markdown","542b4602":"markdown","62491908":"markdown","4fd3a471":"markdown","d48c9ea4":"markdown","a24c841b":"markdown","16dfeca4":"markdown","7fb92121":"markdown","a8ab78fc":"markdown","40f6171a":"markdown","02fd7f21":"markdown","3a3dfd18":"markdown","ab4dd138":"markdown","81a25fa1":"markdown","c8fc1ae0":"markdown","24379d66":"markdown","8d3af5bb":"markdown"},"source":{"f3f58d1f":"!pip install sidetable","25b4d4f1":"##Standard Libraries for data handling\nimport numpy as np\nimport pandas as pd\n\n##Standard Visualisation Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mlxtend.plotting import plot_confusion_matrix as pcm\nimport plotly.graph_objects as go\n\n## Finding the area under the curve\nfrom scipy import integrate\n\n##For data summarize\nimport sidetable\n\n##Libraries for Preprocesing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n##Libraries for Model building\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n##Library for Model performance\nfrom sklearn.metrics import confusion_matrix, accuracy_score,plot_confusion_matrix,plot_precision_recall_curve,plot_roc_curve\nfrom sklearn.metrics import average_precision_score,recall_score\n\n## Libraries for Deep Models\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n##Setting up environment\nimport os\nimport pylab","383de215":"pylab.rc('figure', figsize=(10,7))\n\nSMALL_SIZE = 8\nMEDIUM_SIZE = 10\nBIGGER_SIZE = 12\n\nplt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\nplt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\nplt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\nplt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\nplt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","16d6089d":"dataset = pd.read_csv('\/kaggle\/input\/Telco_Churn.csv')","439dd42c":"dataset.head()","86470f2c":"sns.heatmap(dataset.isna(),cbar=False,yticklabels=False);","77280179":"dataset.info()","6c2b3dec":"dataset[\"TotalCharges\"]=[i.strip() for i in dataset[\"TotalCharges\"]]\ndataset[\"TotalCharges\"]=pd.to_numeric(dataset[\"TotalCharges\"], downcast=\"float\")","95277e32":"dataset.isna().sum()","8e9598fd":"Null_values=dataset[\"TotalCharges\"].isna()\ndataset[Null_values]","52932b87":"dataset=dataset.fillna(0)","97b196ba":"dataset['Churn'].value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True,figsize=(10,8));\nplt.title(\"% of Attrition\")","f7855f90":"fig, ax =plt.subplots(nrows=2,ncols=2,figsize=(14,10))\nsns.countplot('MultipleLines',hue='Churn',data=dataset,color='darkblue',ax=ax[0,0])\nsns.countplot('PhoneService',hue='Churn',data=dataset,color='firebrick',ax=ax[0,1])\nsns.countplot('InternetService',hue='Churn',data=dataset,color='goldenrod',ax=ax[1,0])\nsns.countplot('OnlineSecurity',hue='Churn',data=dataset,color='darkslategray',ax=ax[1,1])\nplt.show()","ec135c01":"fig, ax =plt.subplots(nrows=2,ncols=2,figsize=(14,10))\nsns.countplot('OnlineBackup',hue='Churn',data=dataset,color='aqua',ax=ax[0,0],)\nsns.countplot('DeviceProtection',hue='Churn',data=dataset,color='crimson',ax=ax[0,1])\nsns.countplot('TechSupport',hue='Churn',data=dataset,color='indigo',ax=ax[1,0])\nsns.countplot('StreamingTV',hue='Churn',data=dataset,color='saddlebrown',ax=ax[1,1])\nplt.show()","26079b74":"fig, ax =plt.subplots(nrows=2,ncols=2,figsize=(14,10))\nsns.countplot('StreamingMovies',hue='Churn',data=dataset,color='salmon',ax=ax[0,0])\nsns.countplot('PaperlessBilling',hue='Churn',data=dataset,color='forestgreen',ax=ax[0,1])\nsns.countplot('Contract',hue='Churn',data=dataset,color='forestgreen',ax=ax[1,0])\nsns.countplot('PaymentMethod',hue='Churn',data=dataset,color='forestgreen',ax=ax[1,1])\nplt.xticks(rotation=15)\nplt.show()","a628620f":"dataset.stb.freq(['TechSupport','Churn'],style=\"{:.2%}\")","b501d19a":"dataset.stb.freq(['InternetService','Churn'],style=\"{:.2%}\")","c022820b":"fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(16,7))\ndataset[dataset['Churn']=='Yes']['TechSupport'].value_counts().plot.pie(explode=[0.05,0.0,0.0],autopct='%1.1f%%',shadow=True,ax=ax[0])\ndataset[dataset['Churn']=='Yes']['InternetService'].value_counts().plot.pie(explode=[0.05,0.0,0.0],autopct='%1.1f%%',shadow=True,ax=ax[1]);","fb8a9c8a":"def col_trans(col):\n    X=[1 if i=='Yes' else 0 for i in col]\n    return X\n\nmake_dollar = lambda x: \"${:,.2f}\".format(x)\n","0aa812dd":"def highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: orangered' if v else '' for v in is_max]\n\n\n\ndef highlight_min(s):\n    is_min = s == s.min()\n    return ['background-color: palegreen' if v else '' for v in is_min]\n","8dac506d":"dataset['Churn']=col_trans(dataset['Churn'])\n\ndemographics=dataset.groupby(['gender', 'SeniorCitizen']).agg({'customerID': ['count'],\n                                                     'Churn':['sum'],\n                                                       'MonthlyCharges': ['mean']}).reset_index()","fb867c6a":"demographics['Index']=(demographics['Churn']['sum']\/demographics['customerID']['count'])\ndemographics['% Mix']=(demographics['customerID']['count']\/np.sum(demographics['customerID']['count']))\ndemographics[\"MonthlyCharges\"]=demographics[\"MonthlyCharges\"][\"mean\"].apply(make_dollar)","87154918":"demographics.columns=[\"Gender\",\"SeniorCitizen\",\"CustomerCount[A]\",\"ChurnCount[B]\",\"Avg. Monthly Rev\",\"% Churn([A]\/[B])\",\"% Mix([A]\/Sum[A])\"]\ndemographics[\"% Mix([A]\/Sum[A])\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in demographics[\"% Mix([A]\/Sum[A])\"]], index = demographics.index)\ndemographics['% Churn([A]\/[B])'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in demographics['% Churn([A]\/[B])']], index = demographics.index)\ndemographics.style.apply(highlight_max,subset=[\"Avg. Monthly Rev\",'% Churn([A]\/[B])'])","130d726f":"dataset['tenure_bins'] = pd.cut(x=dataset['tenure'], bins=[0,12, 24, 36,48,60,72])\nplt.figure(figsize=(12,9))\nsns.barplot(dataset['tenure_bins'],dataset['MonthlyCharges'],hue=dataset['Churn'],palette='Wistia')\nplt.title('Avg. Monthly charge by Tenure (in months)',fontsize=14)\nplt.xlabel('Tenure (in months)',fontsize=14)\nplt.ylabel('Monthly Charges',fontsize=14)\nplt.show()","a11f662c":"plt.figure(figsize=(12,9))\nsns.barplot(dataset['tenure_bins'],dataset['TotalCharges'],hue=dataset['Churn'],palette='Wistia')\nplt.title('Avg. Monthly charge by Tenure (in months)',fontsize=14)\nplt.xlabel('Tenure (in months)',fontsize=14)\nplt.ylabel('Total Charges',fontsize=14)\nplt.show()","d1a454ed":"churn_by_tenure=dataset.groupby(['tenure_bins']).agg({'customerID': ['count'],\n                                                     'Churn':['sum'],\n                                                       }).reset_index()\nchurn_by_tenure.columns=['Tenure (in months)','# Customers','# Churns']\nchurn_by_tenure['Index']=churn_by_tenure['# Churns']\/churn_by_tenure['# Customers']\nchurn_by_tenure['Index']=pd.Series([\"{0:.2f}%\".format(val * 100) for val in churn_by_tenure[\"Index\"]], index = churn_by_tenure.index)\nchurn_by_tenure","9d886c3c":"sns.scatterplot(x=\"MonthlyCharges\",y=\"TotalCharges\",hue=\"tenure_bins\",data=dataset,palette='tab20')\nplt.title('Distribution of Total Charges with Monthly Charges by Tenure')\nplt.show()","0bb5dacb":"#dataset.drop('tenure_bins',axis=1,inplace=True)\ncol_count=pd.DataFrame({\"col_name\":dataset.nunique().index,\n              \"Unique_Val\":dataset.nunique()}).reset_index(drop=True)\ndef col_cat(col):  ##To differentiate the column types\n    x=[]\n    for i in col:\n        if i ==2:\n            x.append('Binary')\n        elif (i>2) & (i<7):\n            x.append('Categorical')\n        else:\n            x.append('Continuous')\n    return x\n        \n\ncol_count['Type']=col_cat(col_count[\"Unique_Val\"])\n\ncol_count","56163967":"continuous=list(col_count[col_count[\"Type\"]=='Continuous']['col_name'])\nbinary=list(col_count[col_count[\"Type\"]=='Binary']['col_name'])\ncategorical=list(col_count[col_count[\"Type\"]=='Categorical']['col_name'])\nbinary.pop(binary.index('Churn'))\ncontinuous.pop(continuous.index('customerID'))","fb8f3860":"le=LabelEncoder()\nfor i in binary:\n    dataset[i]=le.fit_transform(dataset[i])","888474a3":"sns.heatmap(dataset.corr(),annot=True,cmap='viridis');","688b061d":"X=dataset.drop('tenure_bins',axis=1)\ny=X.iloc[:,-1]\nX=X.iloc[:,1:-1]","b1b035c7":"categorical_ind=[i for i,j in enumerate(X.columns) if j in categorical]\n\nX=X.values\ny=y.values","5023ecaf":"# Let's check shape of X and y\n\nprint(\"Dimension of X vector:\",X.shape)\nprint(\"Dimension of y labels:\",y.shape)","1fad624f":"ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),list(categorical_ind))],remainder='passthrough')\nX=np.array(ct.fit_transform(X))  ##Moves the dummy columns to the begining","ae0c5daf":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","3938627a":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","450a4f56":"def capcurve(y_values, y_preds_proba): ##Cap Curve for model performance\n    num_pos_obs = np.sum(y_values)\n    num_count = len(y_values)\n    rate_pos_obs = float(num_pos_obs) \/ float(num_count)\n    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n    xx = np.arange(num_count) \/ float(num_count - 1)\n    \n\n    y_cap = np.c_[y_values,y_preds_proba]\n    y_cap_df_s = pd.DataFrame(data=y_cap)\n    y_cap_df_s = y_cap_df_s.sort_values([1], ascending=False).reset_index( drop=True)\n\n    #print(y_cap_df_s.head(20))\n\n    yy = np.cumsum(y_cap_df_s[0]) \/ float(num_pos_obs)\n    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n\n    percent = 0.5\n    row_index = int(np.trunc(num_count * percent))\n\n    val_y1 = yy[row_index]\n    val_y2 = yy[row_index+1]\n    if val_y1 == val_y2:\n        val = val_y1*1.0\n    else:\n        val_x1 = xx[row_index]\n        val_x2 = xx[row_index+1]\n        val = val_y1 + ((val_x2 - percent)\/(val_x2 - val_x1))*(val_y2 - val_y1)\n\n    sigma_ideal = 1 * xx[num_pos_obs - 1 ] \/ 2 + (xx[num_count - 1] - xx[num_pos_obs]) * 1\n    sigma_model = integrate.simps(yy,xx)\n    sigma_random = integrate.simps(xx,xx)\n\n    ar_value = (sigma_model - sigma_random) \/ (sigma_ideal - sigma_random)\n    #ar_label = 'ar value = %s' % ar_value\n    val=np.round(val,2)\n\n    fig, ax = plt.subplots(nrows = 1, ncols = 1,figsize=(10,7))\n    ax.plot(ideal['x'],ideal['y'], color='C0', label='Perfect Model',lw=2,marker='o')\n    ax.plot(xx,yy, color='red', label='Our Model')\n    #ax.scatter(xx,yy, color='red')\n    ax.plot(xx,xx, color='blue', label='Random Model',lw=2)\n    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=2)\n    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=2, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n\n    plt.xlim(0, 1.02)\n    plt.ylim(0, 1.25)\n    plt.title(f\"CAP Curve - a_r value ={ar_value:.2f}\")\n    plt.xlabel('% of the data')\n    plt.ylabel('% of Positive obs (Churn=1)')\n    plt.legend()\n    plt.show()\n    return val","23cdbd59":"def classifier_Logistic(X_train,y_train,X_test,y_test):  \n    classifier = LogisticRegression(random_state = 0)\n    classifier.fit(X_train, y_train)\n    y_pred_prob=classifier.predict_proba(X_test)\n    y_pred = classifier.predict(X_test)\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    plt.style.use('seaborn')\n    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    ax[0].set_title(\"ROC Curve\")\n    ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob[:,1])\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n    print(f\"Validation Accuracy of the Logistic Regression model is {val_accuracy:.2f}%\")\n    return score","861080f8":"def classifier_SVC(X_train,y_train,X_test,y_test,kernel='linear'):  \n    classifier = SVC(kernel=kernel,random_state = 0,probability=True)\n    classifier.fit(X_train, y_train)\n    y_pred_prob=classifier.predict_proba(X_test)\n    y_pred = classifier.predict(X_test)\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    plt.style.use('seaborn')\n    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    ax[0].set_title(\"ROC Curve\")\n    ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob[:,1])\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n\n    print(f\"Validation Accuracy of the Support Vector model is {val_accuracy:.2f}%\")\n    return score","4fc2ce8a":"def classifier_KNN(X_train,y_train,X_test,y_test,n_neighbors=5):  \n    classifier = KNeighborsClassifier(n_neighbors=n_neighbors,p=2,metric='minkowski')\n    classifier.fit(X_train, y_train)\n    y_pred_prob=classifier.predict_proba(X_test)\n    y_pred = classifier.predict(X_test)\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    plt.style.use('seaborn')\n    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    ax[0].set_title(\"ROC Curve\")\n    ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob[:,1])\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n    \n    print(f\"Validation Accuracy of the KNN model is {val_accuracy:.2f}%\")\n    return score","013b5a76":"def classifier_Tree(X_train,y_train,X_test,y_test,criterion='entropy'):  \n    classifier = DecisionTreeClassifier(criterion=criterion)\n    classifier.fit(X_train, y_train)\n    y_pred_prob=classifier.predict_proba(X_test)\n    y_pred = classifier.predict(X_test)\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    plt.style.use('seaborn')\n    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    ax[0].set_title(\"ROC Curve\")\n    ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob[:,1])\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n\n    print(f\"Validation Accuracy of Decision Tree the model is {val_accuracy:.2f}%\")\n    return score","4cb229d3":"def classifier_RF(X_train,y_train,X_test,y_test,n_estimators=10,criterion='entropy'):  \n    classifier = RandomForestClassifier(n_estimators=n_estimators,criterion=criterion)\n    classifier.fit(X_train, y_train)\n    y_pred_prob=classifier.predict_proba(X_test)\n    y_pred = classifier.predict(X_test)\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    plt.style.use('seaborn')\n    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    ax[0].set_title(\"ROC Curve\")\n    ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob[:,1])\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n    \n\n    print(f\"Validation Accuracy of the Random Forest model is {val_accuracy:.2f}%\")\n    return score","5ab6ce43":"def classifier_NaiveB(X_train,y_train,X_test,y_test):  \n    classifier = GaussianNB()\n    classifier.fit(X_train, y_train)\n    y_pred_prob=classifier.predict_proba(X_test)\n    y_pred = classifier.predict(X_test)\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    plt.style.use('seaborn')\n    fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    ax[0].set_title(\"ROC Curve\")\n    ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob[:,1])\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n\n    print(f\"Validation Accuracy of the Naive Bayers model is {val_accuracy:.2f}%\")\n    return score","136aa962":"def classifier_ANN(X_train,y_train,X_test,y_test,epochs=100,batch_size=32,optimizer='adam',loss='binary_crossentropy'): \n    classifier=Sequential()\n\n    #Creating the input layer and first hidden layer\n    classifier.add(Dense(units=6,activation='relu',kernel_initializer='uniform',input_dim=40))  ## Check all the other params\n\n    #adding 2nd hidden Layer\n    classifier.add(Dense(units=6,activation='relu',kernel_initializer='uniform'))\n\n\n    #adding 3rd hidden Layer\n    #classifier.add(Dense(units=6,activation='relu',kernel_initializer='uniform'))\n\n    #Adding the output layer\n    classifier.add(Dense(units=1,activation='sigmoid',kernel_initializer='uniform'))\n\n    #Compiling the ANN\n    classifier.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])\n\n    #Fitting ANN to training set\n    classifier.fit(X_train,y_train,batch_size=batch_size,epochs=epochs)\n    y_pred_prob=classifier.predict(X_test)\n    y_pred=(y_pred_prob>0.5).astype('int')\n    val_accuracy=accuracy_score(y_test,y_pred)\n    cm=confusion_matrix(y_test,y_pred)\n    \n    \n    \n    plt.style.use('seaborn')\n    #fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(10,5))\n    \n    #plot_roc_curve(classifier,X_test,y_test,ax=ax[0])\n    #plot_precision_recall_curve(classifier,X_test,y_test,ax=ax[1])\n    #ax[0].set_title(\"ROC Curve\")\n    #ax[1].set_title(\"Precision vs Recall Curve\")\n    val=capcurve(y_test,y_pred_prob)\n    precision=average_precision_score(y_test,y_pred)\n    recall=recall_score(y_test,y_pred)\n    #plt.style.use('default')\n    #plot_confusion_matrix(classifier,X_test,y_test,cmap=plt.cm.Blues,normalize='true')\n    pcm(cm,colorbar=True,show_normed=True)\n    plt.title('Confusion Matrix')\n    plt.show()\n    score={\"accuracy\":val_accuracy,\n           \"con_mat\":cm,\n           \"y_pred\":y_pred,\n           \"y_pred_prob\":y_pred_prob,\n           \"classifier\":classifier,\n           \"CAC\":val,\n          \"precision\":precision,\n          \"recall\":recall}\n\n    \n    \n    #score=(val_accuracy,cm,y_pred,y_pred_prob)\n    print(f\"Validation Accuracy of the ANN model is {val_accuracy:.2f}%\")\n    \n    return score","be9ad9c8":"Score_Log=classifier_Logistic(X_train,y_train,X_test,y_test)","3cb061b7":"Score_SVCL=classifier_SVC(X_train,y_train,X_test,y_test)","3c17e23a":"Score_SVCR=classifier_SVC(X_train,y_train,X_test,y_test,kernel='rbf')","26c46904":"Score_KNN=classifier_KNN(X_train,y_train,X_test,y_test)","3463f7dd":"Score_Tree=classifier_Tree(X_train,y_train,X_test,y_test)","c4fa2228":"Score_RF=classifier_RF(X_train,y_train,X_test,y_test)","28ce14b4":"Score_NaiveB=classifier_NaiveB(X_train,y_train,X_test,y_test)","af4cb7ad":"Score_ANN=classifier_ANN(X_train,y_train,X_test,y_test,epochs=10)","be4ce4a5":"metrics={}\nfor metric in Score_Log.keys():\n    metrics[metric]=[Score_Log[metric],Score_NaiveB[metric],Score_KNN[metric],Score_SVCL[metric],Score_SVCR[metric],Score_Tree[metric],Score_RF[metric],Score_KNN[metric]]","360172a7":"modelnames=['Log Reg',\n            'Naive Bayes',\n            'KNN','SVM','Kernel','Tree','Random Forest','Artificial NN']\n\nmetrics['ModelNames']=modelnames\nmodel_summary=pd.DataFrame(metrics)","cdb46162":"model_summary=model_summary[['ModelNames','accuracy','precision','recall','CAC','con_mat']]\nmodel_summary.columns=['Model Names','Accuracy','Precision','Recall','CAC Score','Confusion Mat']\nmodel_summary=model_summary.round(3)","f4cbf19e":"fig,ax=plt.subplots(nrows=2,ncols=2,figsize=(14,10))\n\nsns.barplot(model_summary['Model Names'],model_summary['Accuracy'],ax=ax[0,0])\n\nsns.barplot(model_summary['Model Names'],model_summary['Precision'],ax=ax[0,1])\n\nsns.barplot(model_summary['Model Names'],model_summary['Recall'],ax=ax[1,0])\n\nsns.barplot(model_summary['Model Names'],model_summary['CAC Score'],ax=ax[1,1])\n\nplt.tight_layout()","97d171bf":"fig = go.Figure(data=[go.Table(\n    header=dict(values=list(model_summary.columns),\n                fill_color='paleturquoise',\n                align='center'),\n    cells=dict(values=[model_summary['Model Names'], model_summary['Accuracy'], model_summary['Precision'], model_summary['Recall'],model_summary['CAC Score'],model_summary['Confusion Mat']],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()","c61afdf3":"# <a id='5.6'>5.6 Rando Forest Classification<\/a>","55c2332c":"- Ensure proper tech support to elevate customer satisfaction and mitigate churn.\n- People without any online backup service are more likely to leave the carrier.\n- Device protection plan can be leveraged as a strong metric for customer loyalty.","5ecc4e76":"# <a id='5.3'>5.3 Kernel Classifier<\/a>","642ea1f6":"# <a id='2.5'>2.5 Analysing Continuous Variables<\/a>","c391855a":"# <a id='1.2'>1.2 Data Wrangling<\/a>","58f5fd68":"# <a id='4.1'>4.1 Logistic Regression<\/a>","ab04ddd8":"# Table of Content\n- <a href='#0'>0. Importing Libraries<\/a>\n    - <a href='#0.1'>0.1 Setting up Environment<\/a>\n    \n    \n- <a href='#1'>1. Data Overview<\/a>\n    - <a href='#1.1'>1.1. Missing Data<\/a>\n    - <a href='#1.2'>1.1. Data wrangling<\/a>\n    \n    \n- <a href='#2'>2. Exploratory Data Analysis<\/a>\n    - <a href='#2.1'>2.1. Customer attrition in data<\/a>\n    - <a href='#2.2'>2.2. Analysing Categorical Variables<\/a>\n    - <a href='#2.3'>2.3. Summary Tables<\/a>\n    - <a href='#2.4'>2.4. Demographics<\/a>\n    - <a href='#2.5'>2.5. Analysing Continous Variables<\/a>\n    \n    \n- <a href='#3'>3. Data preprocessing<\/a>\n    - <a href='#3.1'>3.1. Identifying Columns<\/a>\n    - <a href='#3.2'>3.2. Label Encoding<\/a>\n    - <a href='#3.3'>3.3. Corelation Matix<\/a>\n    - <a href='#3.4'>3.4. One-Hot Encoding<\/a>\n    - <a href='#3.5'>3.5. Train-test split<\/a>\n    - <a href='#3.6'>3.6. Feature Scaling<\/a>\n    \n    \n- <a href='#4'>4. Model Building<\/a>\n    - <a href='#4.1'>4.1. Logistic Regression<\/a>\n    - <a href='#4.2'>4.2. Support Vector Classifier<\/a>\n    - <a href='#4.3'>4.3. K-Nearest Neighbors<\/a>\n    - <a href='#4.4'>4.4. Decision Tree<\/a>\n    - <a href='#4.5'>4.5. Random Forest<\/a>\n    - <a href='#4.6'>4.6. Naive Bayes<\/a>\n    - <a href='#4.7'>4.7. Artificial Neural Network<\/a>    \n    \n    \n- <a href='#5'>5. Prediction and Model Performance<\/a>\n    - <a href='#5.1'>5.1. Logistic Regression<\/a>\n    - <a href='#5.2'>5.2. Support Vector Classifier<\/a>\n    - <a href='#5.3'>5.3. Kernel Classifier<\/a>\n    - <a href='#5.4'>5.4. K-Nearest Neighbors<\/a>\n    - <a href='#5.5'>5.5. Decision Tree <\/a>\n    - <a href='#5.6'>5.6. Random Forest Classifier<\/a>\n    - <a href='#5.7'>5.7. Naive Bayes Classifier<\/a>\n    - <a href='#5.8'>5.8. Artificial Neural Network<\/a>\n\n\n- <a href='#6'>6. Model Comparision<\/a>\n    - <a href='#6.1'>6.1. Summary Table<\/a>\n","d981ba71":"- The distribution is highly skewed towards the higher tenure groups which is natural.","459e667e":"# <a id='2.1'>2.1 Customer Attrition in Data<\/a>\n\nMakes even more sense now. Since the tenure is 0 for each of the records, there is no `TotalCharges` on these accounts. However, let's stick to our argument and fill these rows instead of dropping them.","ee1d4200":"# <a id='6'>6 Model Comparision<\/a>","ce5d7ded":"# <a id='4.6'>4.6 Naive Bayes Classifier<\/a>","2e76acba":"# <a id='3.4'>3.4 One Hot Encoding<\/a>","6828604c":"- Of all the customer who left `1446` customers didn't have `TechSupport` and `1297` had fibre optic Internet Service\n\n- That accounts for `77.4%` and `69.4%` of all the churns respectively\n\nLooks like these two attributes can be strongly related with the `Churns` ","3fbe601c":"Let's check for missing data again.","4b986395":"Also, majority of churn comes from people who joined the carrier less than a year ago. There are two possibilities that are on top of mind:\n\n- They didn't get service as expected. \n- A segment of these people are actually switchers who always are on a lookout for good offers and don't really mind switching carriers often.","b17d3af4":"# <a id='1'>1. Data overview<\/a>","78710247":"Here is a summary of our findings:\n- Customers with fiber optic service as home Internet, are more likely to churn.\n- Absence of Tech Support is leading to more churns than overall as of all the churns 77.4% didn\u2019t have tech support.\n- People with Device protection plan can be considered as low risk.\n- Demographically, Senior female citizens are at a higher risk.\n- Customers who have been with the company longer are on average paying more every month and are less likely to churn.\n- However, within each tenure group, high valued customers are more likely to churn compared to the ones paying less.\n- People who joined less than 1 year ago are at highest risk customers as 47% of them have left within first year of joining.\n- Na\u00efve Bayes gives least false negatives but overall has less accuracy.\n- Linear SVM outperforms all the other models in terms of accuracy, but recall could be increased.\n- Complex ensemble method, like Random forest and deep methods don\u2019t look promising at all. \n","bfa11d5d":"We have a few NaN values for `TotalCharges`. Considering it's too small compared to the sample size we can drop these values.\nHowever, 1 thing to notice is `TotalCharges` roughly amounts to the product of `tenure` and `MonthlyCharges`. We can replace the values for the missing rows as per this observation\/assumption. So let's look at the rows with missing values.","4f638216":"# <a id='3.6'>3.6 Feature Scaling<\/a>","d780503b":"# <a id='6.1'>6.1 Summary Table<\/a>","88cb02ee":"# <a id='5.1'>5.1 Logistic Regression<\/a>","6c2c8b59":"\n\n# Overview:\n\n\n![customer-churn-edit.jpeg](attachment:customer-churn-edit.jpeg)\n\n\nCustomer churn is one of the biggest challenges that companies face today. Be it be in banking, retail, telecommunication, hospitality or any engineering or e-commerce industry.\n\nOur goal is to analyse on such set of data identify the point at issue and explore oppurtunities to mitigate it. We will come up with a few models that can predict the possible high risk customers help the company to take preventive measures.","51c12ab2":"- Like we expected tenure has comparatively stronger negative relation with Churn.\n- 1 new observation is the correlation between having a `Partner` and `Tenure`","f8c43ea7":"# <a id='3.1'>3.1 Identifying Columns<\/a>","740c5fa6":"# <a id='4.5'>4.5 Random Forest Classifier<\/a>","aee02cf9":"### Thank you for your time. Feel free to drop any feedback.","69fa5a73":"First thing first, lets inspect if we have any missing data. Not even 1, so we're golden here. Let's move ahead and visualise some of the metrics, their distribution and dependencies on others.","b818b50e":"# <a id='5.4'>5.4 K Nearest Neighbors<\/a>","a100084f":"# <a id='3.2'>3.2 Label encoding<\/a>","52de5598":"Sorry to disappoint you if you were looking for some nice chart, being an SQL guy I always feel that a nice and simple summary table is always richer in information than a complex chart.\n\n- Looks like Churn Index is pretty high for the senior female citizens, they happen to be the most valued customers as well.\n- However they only attribute 8% of our population, so we might want to reconsider before making any action plan or strategic investment.","bc70c8c3":"# <a id='2'>2. Exploratory Data Analysis<\/a>","e7f24908":"# <a id='4.3'>4.3 K Nearest Neighbors Classifier<\/a>","92025d09":"# <a id='1.1'>1.1 Missing Values<\/a>","483b21a8":"# <a id='5.8'>5.8 Artificial Neural Network<\/a>","d9635cb9":"Out of curiosity let's create a simple ANN and see how it performs with respect to all the other models.\n\n# <a id='4.7'>4.7 Artificial Neural Network<\/a>","c2771365":"# <a id='5.5'>5.5 Decision Tree Classification<\/a>","c9783b66":"# <a id='2.3'>2.3 Summary Tables<\/a>","ac37b03c":"Total Charges should have been float, but for some reason is in text format. Let's fix that before proceeding.","d6c1dbbf":"# <a id='2.4'>2.4 Demographics<\/a>\n\nWe don't have many demographics variables to analyse here, but can see how `gender` and `SeniorCitizen` play in.","542b4602":"- We see a general trend here. People who have been with the carrier for long time tend to be spending more on average each month.\n- Looks like we are losing more high valued customers throughout all tenure groups. This is in fact a great finding. Clearly, people with higher ARPU do not feel the services they are getting is worth the spending\u2019s.","62491908":"# <a id='2.2'>2.2 Analysing Categorical Attributes<\/a>","4fd3a471":"- People with fibre optic Internet Service are more likely to move out than people with DSL\n- The data corresponds to not just cellular service but also people who are just home internet customers. From TR chart it appears customers with only internet and no cellular connection are satisfied with the service and are our area of concern. \n- Looks like people having multiple lines are not very satisfied with the service. But one thing to ponder is why would the go with multiple lines if they weren't happy in the first place?\n- Possible argument: Usually Telcom companies offer some promos\/discounts when adding another line and now they might have ceased to offer the promo. This would have resulted in people's dismay and high churn.","d48c9ea4":"# <a id='4.2'>4.2 Support Vector Classifier<\/a>","a24c841b":"# <a id='4.4'>4.4 Decision Tree Classifier<\/a>","16dfeca4":"# <a id='5.7'>5.7 Naive Bayes Classification<\/a>","7fb92121":"# <a id='0.1'>0.1 Setting up environtment<\/a>","a8ab78fc":"# <a id='0'>0.Importing Libraries<\/a>","40f6171a":"# <a id='5.2'>5.2 Support Vector Classifier<\/a>","02fd7f21":"Okay this might be a redundant plot, but just wanted to be sure. Everything make sense as people with higher ARPU tend to pay more in total over time.","3a3dfd18":"# <a id='3.5'>3.5 Splitting training and Test Data<\/a>","ab4dd138":"Makes even more sense now. Since the tenure is 0 for each of the records, there is no `TotalCharges` on these accounts. However, let's stick to our argument and fill these rows instead of dropping them.","81a25fa1":"# <a id='5'>5 Prediction and Model Performance<\/a>\n\nNow all of our models are defined. Let predict our results, compare them and choose the best one.\n\nFor understanding our model performance, we are going to analyse the following things:\n- Accuracy: This is simple the ratio of correct prediction and total number of observations.\n- Receiver Operating Characteristics: It is a plot between `False Positive Rate` and `True Positive Rate`. ROC curve tells us how capable our model is to distinguish between right classes by observing the area under the curve. The goal should be to maximize the area.\n        Further Readings: https:\/\/towardsdatascience.com\/understanding-auc-roc-curve-68b2303cc9c5\n        \n- Recall vs Precision: In our current problem we are more focused on identifying the users who may walk out of the subscription. For us a False Negative is more dangerous than a `False Positive` and hence in case of tough competition in terms of other metrics we may choose a model with higher `recall` at the cost of `precision`. \n\n    $$Recall = \\frac{True Positives}{True Positives + False Negatives} $$\n    \n    $$Precision = \\frac{True Positives}{True Positives + False Positives}$$\n    \n        Further Readings: https:\/\/towardsdatascience.com\/beyond-accuracy-precision-and-recall-3da06bea9f6c\n        \n- Cumulative Accuracy Profile: Although it may look similar to the `ROC` curve, `CAP` curve plots the % of Positives correctly classified with % of data analysed. Say out of `1000` people who came for a test `50` are positive (5%). Hence the ideal model would reach `100%` of `True Positive` results just after going through `5%` of the data. By calculating the area under CAP curve, we can have a better understanding of the performance of our model. Generally, a model performance is analysed based % of True positives the model can detect by going over 50% of the data. We will call that `CAP score`.\n\n\n\n- Confusion Metrix: Well, this is the go-to metric to analyse how well our model is performing. Best thing is, contradictory to its name, it is one of the simplest metrics to analyse.","c8fc1ae0":"# <a id='3.3'>3.3 Co-relation Matrix<\/a>","24379d66":"# <a id='4'>4 Model Building<\/a>","8d3af5bb":"# <a id='3'>3 Data Preprocessing<\/a>\n\n\nWe would also like to see how there features relate to each other and how strong is the correlation between them. But since our data has string values for most of the columns, we'd have to pre-process them before we can analyse them together.\n\n- Columns with only two possible distinct values, are need to be Label Encoded.\n- Categorical columns with more than two possible distinct values, are need to be One hot Encoded.\n\nLet's identify those columns."}}