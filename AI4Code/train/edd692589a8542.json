{"cell_type":{"be05521f":"code","c6968c10":"code","3a88dbbb":"code","dd7416fa":"code","6ba78db4":"code","b4388179":"code","260fe1c4":"code","15f504e6":"code","70e5f888":"code","de87e229":"code","ef89abc3":"code","89cfc697":"code","bf0c6388":"code","fccf709b":"code","4dc9110f":"code","cd0e0b34":"code","8afc7765":"code","8e1df52c":"code","031c2982":"code","2c8e7d82":"code","cea4b943":"code","48c10a9f":"code","86ca92ad":"code","92bf42d9":"code","fbb5d4f4":"code","0666a337":"code","e4de7c9e":"code","194b9388":"code","95eda265":"code","6244ec03":"code","61699d58":"code","55bcac33":"code","1b76d2ea":"code","4f4b8368":"code","a5561b82":"code","8628653c":"code","308ff9e9":"code","7542f9ef":"code","1905d5cd":"code","4376a5ac":"code","fa1fc78f":"code","4ad4ca6f":"code","bffad233":"code","03ce06bd":"code","65d51614":"code","f84d9034":"code","e2c989de":"code","03587e09":"code","eeb722cf":"code","b89e3bec":"code","47abb9af":"code","3b86620c":"code","e9f8f7de":"code","c1ff86d6":"code","26aaf74e":"code","4c45919a":"code","ac560f68":"code","8298e4c9":"code","952a76d4":"code","97a3b3c6":"code","6198ed38":"code","7529b27c":"code","24e2799d":"code","092563b0":"code","994cebd5":"code","33e57441":"code","96c469af":"code","4e92ab98":"code","bc4326e5":"code","7bd3b56d":"code","535e8452":"code","6dd34542":"code","f6d9b71a":"code","02b22427":"code","414c4c61":"code","bfc35601":"code","3dd147c4":"code","d49b89e5":"code","79c7063c":"code","f464f12f":"code","5a820046":"code","5eb5c759":"code","ce82e6c4":"code","61461239":"code","d47315c6":"code","24362a32":"code","f4cfc302":"code","753be96d":"code","d0d5af9a":"code","1a82efd7":"code","baa076b1":"code","0f2c8ad0":"code","af828732":"code","be6a4db2":"code","cdcea78b":"code","7e576ebe":"code","8b34b95e":"code","e0cd5367":"code","5a626189":"code","ec4362f6":"code","1d8d68f9":"code","55dd86e1":"code","38208323":"code","8bedca28":"code","f3424267":"code","ced643cd":"code","410ae6aa":"code","531ce7ae":"code","a4de32fa":"code","9fc95a8c":"code","7439dcdf":"code","fcb9e119":"code","17313d3f":"code","63f6f5e8":"code","4ab3058b":"code","520df9a2":"code","2ceafeed":"code","1e01d9ff":"code","14c15086":"code","5367c544":"code","ccda30e6":"code","2c095d0f":"markdown","17f0f827":"markdown","cefd19ae":"markdown","a71a6399":"markdown","87174816":"markdown","20fa6487":"markdown","5c3e1956":"markdown","49c60277":"markdown","10f20e45":"markdown","17b79af0":"markdown","ab133268":"markdown","f1bf786f":"markdown","6148bdc4":"markdown","d4b6671a":"markdown","786e0f07":"markdown","74771dd0":"markdown","4acfeec7":"markdown","e79e2576":"markdown","45d8e3c1":"markdown","ef88d48e":"markdown","c43c5f20":"markdown","187a0bfc":"markdown","de56cc0c":"markdown","452e2574":"markdown","b617a6ba":"markdown","3d4b8fec":"markdown","0e82b84f":"markdown","685d399e":"markdown","352a13cb":"markdown","3e81f93a":"markdown","16550649":"markdown","0953fda8":"markdown","0559dfc8":"markdown","733e8b5d":"markdown","ad183657":"markdown","450cbf8c":"markdown"},"source":{"be05521f":"# Data Analysis Libraries;\nimport numpy as np\nimport pandas as pd\n\n# Data Visualization Libraries;\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# To Ignore Warnings;\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# To Display All Columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","c6968c10":"# Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\n\n# Model Selection\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler,minmax_scale\n","3a88dbbb":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","dd7416fa":"# Copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","6ba78db4":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","b4388179":"import missingno as msno","260fe1c4":"msno.bar(train);","15f504e6":"train.head()","70e5f888":"train.tail()","de87e229":"train.info()","ef89abc3":"test.head()","89cfc697":"test.tail()","bf0c6388":"test.info()","fccf709b":"train.describe().T","4dc9110f":"test.describe().T","cd0e0b34":"train['Pclass'].value_counts()","8afc7765":"train['Sex'].value_counts()","8e1df52c":"train['SibSp'].value_counts()","031c2982":"train['Parch'].value_counts()","2c8e7d82":"train['Ticket'].value_counts()","cea4b943":"train['Cabin'].value_counts()","48c10a9f":"train['Embarked'].value_counts()","86ca92ad":"sns.barplot(x='Pclass', y ='Survived',data = train);","92bf42d9":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","fbb5d4f4":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","0666a337":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","e4de7c9e":"train.head()","194b9388":"test.head()","95eda265":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","6244ec03":"train.describe([0.10,0.25,0.50,0.75,0.90,0.99]).T","61699d58":"# It looks like there is a problem in Fare max data.Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","55bcac33":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1-1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","1b76d2ea":"# Observations with Fare data higher than the upper limit.\n\ntrain['Fare'] > (upper_limit)","4f4b8368":"train.sort_values(\"Fare\",ascending = False).head()","a5561b82":"train.sort_values(\"Fare\",ascending = False).tail()","8628653c":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512-\ntrain['Fare'] = train['Fare'].replace(512.3292, 312)","308ff9e9":"train.sort_values(\"Fare\", ascending = False).head()","7542f9ef":"train.sort_values(\"Fare\", ascending = False).tail()","1905d5cd":"test.sort_values(\"Fare\", ascending = False)","4376a5ac":"test['Fare'] = test['Fare'].replace(512.3292, 312)","fa1fc78f":"test.sort_values(\"Fare\", ascending = False)","4ad4ca6f":"train.isnull().values.any()","bffad233":"train.isnull().sum()","03ce06bd":"train[\"Age\"].fillna(0, inplace = True)","65d51614":"train.isnull().sum()","f84d9034":"train[\"Cabin\"].fillna(0, inplace = True)","e2c989de":"train.isnull().sum()","03587e09":"100 * train.isnull().sum() \/ len(train)","eeb722cf":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","b89e3bec":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","47abb9af":"train.isnull().values.any()","3b86620c":"test.isnull().values.any()","e9f8f7de":"train.isnull().sum()","c1ff86d6":"test.isnull().sum()","26aaf74e":"train.isnull().sum()","4c45919a":"test.isnull().sum()","ac560f68":"train[\"Embarked\"].value_counts()","8298e4c9":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","952a76d4":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","97a3b3c6":"train.isnull().sum()","6198ed38":"test.isnull().sum()","7529b27c":"test[test[\"Fare\"].isnull()]","24e2799d":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","092563b0":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","994cebd5":"test[\"Fare\"].isnull().sum()","33e57441":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = train[\"Cabin\"].isnull().astype('int')\ntest[\"CabinBool\"] = test[\"Cabin\"].isnull().astype('int')\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","96c469af":"train.isnull().sum()","4e92ab98":"test.isnull().sum()","bc4326e5":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\":2, \"Q\":3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","7bd3b56d":"train.head()","535e8452":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\n\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","6dd34542":"train.head()","f6d9b71a":"train[\"Title\"] = train[\"Name\"].str.extract('([A-Za-z]+)\\.', expand = False)\n\ntest[\"Title\"] = test[\"Name\"].str.extract('([A-Za-z]+)\\.', expand = False)","02b22427":"train.head()","414c4c61":"train['Title'].value_counts()","bfc35601":"train['Title'] = train['Title'].replace(['Lady','Capt','Col','Don','Dr','Major','Rev','Jonkheer','Dona'], 'Rare')\n\ntrain['Title'] = train['Title'].replace(['Countess','Lady','Sir'], 'Royal')\n\ntrain['Title'] = train['Title'].replace('Mlle','Miss')\n\ntrain['Title'] = train['Title'].replace('Ms','Miss')\n\ntrain['Title'] = train['Title'].replace('Mme','Mrs')","3dd147c4":"test['Title'] = test['Title'].replace(['Lady','Capt','Col','Don','Dr','Major','Rev','Jonkheer','Dona'], 'Rare')\n\ntest['Title'] = test['Title'].replace(['Countess','Lady','Sir'], 'Royal')\n\ntest['Title'] = test['Title'].replace('Mlle','Miss')\n\ntest['Title'] = test['Title'].replace('Ms','Miss')\n\ntest['Title'] = test['Title'].replace('Mme','Mrs')","d49b89e5":"train.head()","79c7063c":"test.head()","f464f12f":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","5a820046":"train[['Title','Survived']].groupby(['Title'], as_index = False).agg({\"count\",\"mean\"})","5eb5c759":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\":1, \"Miss\":2, \"Mrs\":3, \"Master\":4, \"Royal\":5, \"Rare\":5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","ce82e6c4":"train.isnull().sum()","61461239":"test['Title'] = test['Title'].map(title_mapping)","d47315c6":"test.head()","24362a32":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","f4cfc302":"train.head()","753be96d":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins,labels = mylabels)","d0d5af9a":"# Map each Age value to a numerical value:\nage_mapping = {'Baby':1, 'Child':2, 'Teenager':3, 'Student':4, 'Young Adult':5, 'Adult':6, 'Senior':7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest ['AgeGroup'] = test['AgeGroup'].map(age_mapping)","1a82efd7":"train.head()","baa076b1":"# Dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","0f2c8ad0":"train.head()","af828732":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1,2,3,4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1,2,3,4])","be6a4db2":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","cdcea78b":"train.head()","7e576ebe":"train.head()","8b34b95e":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","e0cd5367":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","5a626189":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s:1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s:1 if s == 2 else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s:1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s:1 if s>=5 else 0)","ec4362f6":"train.head()","1d8d68f9":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s:1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s:1 if s == 2 else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s:1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s:1 if s >= 5 else 0)","55dd86e1":"test.head()","38208323":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix = \"Em\")","8bedca28":"train.head()","f3424267":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix = \"Em\")","ced643cd":"test.head()","410ae6aa":"train.groupby(\"Pclass\")[\"Survived\"].mean()","531ce7ae":"# Creat categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"], prefix = \"Pc\")","a4de32fa":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"], prefix = \"Pc\")","9fc95a8c":"train.head()","7439dcdf":"test.head()","fcb9e119":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX = train.drop(['Survived', 'PassengerId'], axis = 1)\nY = train[\"Survived\"]\n","17313d3f":"x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.20, random_state = 17)","63f6f5e8":"x_train.shape","4ab3058b":"x_train.head()","520df9a2":"x_val.shape","2ceafeed":"x_val.head()","1e01d9ff":"y_train.shape","14c15086":"y_train.head()","5367c544":"y_val.shape","ccda30e6":"y_val.head()","2c095d0f":"# Embarked","17f0f827":"# Exploratory Data Analysis","cefd19ae":"## Sex vs survived:","a71a6399":"## Fare","87174816":"## Deleting Unnecessary Variables:","20fa6487":"**Survival: Survival**      0 = No, \n                            1 = Yes\n\n**Pclass:** Ticket class    1 = 1st, \n                            2 = 2nd, \n                            3 = 3rd\n\n**Sex:** Sex\n\n**Age:** Age in years\n\n**SibSp:** # of siblings \/ spouses aboard the Titanic\n\n**Parch:** # of parents \/ children aboard the Titanic\n\n**Ticket:** Ticket number\n\n**Fare:** Passenger fare\n\n**Cabin:** Cabin number\n\n**Embarked:** Port of Embarkation -> C = Cherbourg, \n                                    Q = Queenstown,\n                                    S = Southampton","5c3e1956":"## Embarked","49c60277":"## Embarked & Title","10f20e45":"## Cabin","17b79af0":"# Data Preparation","ab133268":"## Pclass","f1bf786f":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","6148bdc4":"# Veriable Transformation","d4b6671a":"## Parch vs survived:","786e0f07":"## Visualization","74771dd0":"## Spliting the train data","4acfeec7":"# Modeling, Evaluation and Model Tuning","e79e2576":"## Sex","45d8e3c1":"## Classification of categorical variables;","ef88d48e":"## Loading Data","c43c5f20":"# Fare","187a0bfc":"## Age Group","de56cc0c":"When the data in the graph is observed, the total number of passengers in the train data is 891. Age and cabin values are missing. Age (714) is an important factor for survival. The low number of the cabin (204) was low in relation to the number of people staying in the cabin. We can leave these two variables in the dataset.","452e2574":"## Variables Types:","b617a6ba":"## Analysis and Visualization of Numeric and Categorical Variables","3d4b8fec":"## Missing Value Treatment","0e82b84f":"## Age","685d399e":"## Family Size","352a13cb":"## Notes:\n\n**Pclass:** A proxy for socio-economic status (SES)\n\n    1st = Upper\n    2nd = Middle\n    3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n\n    Sibling = brother, sister, stepbrother, stepsister\n    Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n\n    Parent = mother, father\n    Child = daughter, son, stepdaughter, stepson Some children travelled only with a nanny, therefore parch=0 for them.\n\n","3e81f93a":"# Titanic Survival Estimation Project","16550649":"# Feature Engineering","0953fda8":"## Outlier Treatment","0559dfc8":"# Name - Title","733e8b5d":"## Ticket:","ad183657":"## Pclass vs survived:","450cbf8c":"## SibSp vs survived:"}}