{"cell_type":{"64a9a4aa":"code","08c1810c":"code","87b76362":"code","2fba2d6e":"code","79afd7f6":"code","ab03511b":"code","f75c00fb":"code","894edd32":"code","cb2729fc":"code","976f1a83":"code","6f13a461":"code","1c89053f":"code","c1c58430":"code","be1d609f":"code","747bc648":"code","00c1f610":"code","688d72e8":"code","fff93680":"code","92b36bdf":"code","c4d9b1f3":"code","8fbdcf5c":"code","5860bb08":"code","76ea46d1":"code","0ea95302":"code","a9f06674":"code","6f2b5e40":"markdown","40857350":"markdown","9b8e2321":"markdown","79da8eda":"markdown","98464da7":"markdown","142a3866":"markdown","1b89ba7f":"markdown","dd9b23a8":"markdown","a0dee51f":"markdown","ef4c6b60":"markdown","4757b992":"markdown","c617b817":"markdown","5a01bc11":"markdown","4f0c018a":"markdown","62e8d55b":"markdown","a347cfa5":"markdown","003c8347":"markdown","87413993":"markdown","81922a52":"markdown","697f8721":"markdown","8e0be71f":"markdown","6769f978":"markdown","9b469b20":"markdown","39d2fcd1":"markdown"},"source":{"64a9a4aa":"# importing libraries\nimport numpy as np # For numerical computation\nimport pandas as pd # Data manipulation\nimport seaborn as sns # plotting\nimport scipy.io # reading matlab files in python\nfrom scipy import signal #signal processing\nfrom scipy.fftpack import fft, dct #signal processing\n\nfrom sklearn.linear_model import LinearRegression #linear regression model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold, train_test_split # cross validation split\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom matplotlib import pyplot as plt # For plotting graphs(Visualization)\n\nimport os # system-wide functions\nos.listdir('\/kaggle\/input\/BloodPressureDataset')","08c1810c":"sample_file = scipy.io.loadmat(f'..\/input\/BloodPressureDataset\/part_{1}.mat')\nprint(f'sample_file Data type: {type(sample_file)}')\nprint(f'sample_file keys:\\n{sample_file.keys()}')\n","87b76362":"# Loading a sample .mat file to understand the data dimensions\ntest_sample = scipy.io.loadmat(f'..\/input\/BloodPressureDataset\/part_{1}.mat')['p']\nprint(f'test_sample Data type: {type(test_sample)}')\nprint(f'test_sample shape\/dimensions: {test_sample.shape}')","2fba2d6e":"## Try printing out the entire array to see its data.\n","79afd7f6":"print(f\"Total Samples: {len(test_sample[0])}\")\nprint(f\"Number of readings in each sample(column): {len(test_sample[0][0])}\")\nprint(f\"Number of samples in each reading(ECG): {len(test_sample[0][0][2])}\")\n\ntemp_mat = test_sample[0, 999]\ntemp_length = temp_mat.shape[1]\nsample_size = 125\n\n\nprint(temp_length)\nprint((int)(temp_length\/sample_size))","ab03511b":"sample_size = 125\nppg = []\nfor i in range(1000):\n    temp_mat = test_sample[0, i]\n    temp_length = temp_mat.shape[1]\n    for j in range((int)(temp_length\/sample_size)):\n        temp_ppg = temp_mat[0, j*sample_size:(j+1)*sample_size]\n        ppg.append(temp_ppg)","f75c00fb":"ecg = []\nbp = []\nsbp = [] #Systolic Blood Pressure\ndbp = [] #Diastolic Blood Pressue\nsize = 125 #sample size\n\nfor i in range(1000):\n    temp_mat = test_sample[0, i]\n    temp_length = temp_mat.shape[1]\n    for j in range((int)(temp_length\/sample_size)):\n        temp_ecg = temp_mat[2, j*size:(j+1)*size]\n        temp_bp = temp_mat[1, j*size:(j+1)*size]\n        \n        max_value = max(temp_bp)\n        min_value = min(temp_bp)\n        \n        sbp.append(max_value)\n        dbp.append(min_value)\n        ecg.append(temp_ecg)\n        bp.append(temp_bp)","894edd32":"# Reshaping the ecg, ppg and bp signal data into column vectors\n# This makes it easy to load the data into the prediction models \n# we are going to build in the sections to come\n\nppg, ecg, bp = np.array(ppg).reshape(-1,1), np.array(ecg).reshape(-1,1), np.array(bp).reshape(-1,1)\nsbp, dbp = np.array(sbp).reshape(-1,1), np.array(dbp).reshape(-1,1)\nprint(f'PPG_shape: {ppg.shape}\\n ECG_shape: {ecg.shape}\\n BP_shape: {bp.shape}')\nprint(f'Systolic-BP_shape: {sbp.shape},\\n Diastolic-BP_shape: {dbp.shape}')","cb2729fc":"##plotting sample ppg, ecg and bp signals\n##using a sample size of 125 for speed up since the dataset is huge\n##and loading all data will be very very slow\nfig, ax = plt.subplots(3,1, figsize=(9,12), sharex=True)\n\nax[0].set_title('PPG graph', fontsize=16)\nax[0].set_ylabel('Signal Value')\nax[0].plot(ppg[:125])\n\nax[1].set_title('ECG graph', fontsize=16)\nax[1].set_ylabel('Signal Value')\nax[1].plot(ecg[:125])\n\nax[2].set_title('Blood Pressure (BP) graph', fontsize=16)\nax[2].set_ylabel('Signal Value')\nax[2].set_xlabel('Sample size')\nax[2].plot(bp[:125])","976f1a83":"## Visualizing SBP and DBP\n#fig, ax = plt.subplots(1,1, figsize=(9,12))\n\nplt.title('SBP vs DBP graph', fontsize=16)\nplt.ylabel('Signal Value')\nplt.plot(sbp[:125])\nplt.plot(dbp[:125])\nplt.legend(['SBP', 'DBP'])","6f13a461":"# Computing the cross correlation of ppg and bp signals\ncross_corr = np.convolve(ppg[:125].squeeze(), bp[:125].squeeze(), mode='full')\n\nfig, ax = plt.subplots(3,1, figsize=(9,12), sharex=True)\n\nax[0].set_title('PPG graph', fontsize=16)\nax[0].set_ylabel('Signal Value')\nax[0].plot(ppg[:125])\n\nax[1].set_title('BP graph', fontsize=16)\nax[1].set_ylabel('Signal Value')\nax[1].plot(bp[:125])\n\nax[2].set_title('Cross-correlated resultant graph', fontsize=16)\nax[2].set_ylabel('Signal Value')\nax[2].set_xlabel('Sample size')\nax[2].plot(cross_corr[:125])","1c89053f":"# defining our evaluation error function\n# the lower the root_mean_squared_error, the better.\n\ndef root_mean_squared_error(y_true, y_pred):\n    \"\"\"Computes the Root Mean Squared Error (RMSE).\"\"\"\n    return np.sqrt(mean_squared_error(y_true, y_pred))","c1c58430":"#Computing the discrete cosine transform (DCT)\ndppg_dbp = np.diff(ppg[:100000])\/np.diff(bp[:100000]) #derivative of ppg with respect to bp\nprint(dppg_dbp.squeeze())\n#error = root_mean_squared_error(bp.squeeze(), cosine_transformed_array.squeeze())\n#print(f'Root_mean_squared_error: {error}')","be1d609f":"# creating train and test sets\nX_train, X_test, y_train, y_test = train_test_split(ppg, bp, test_size=0.30)","747bc648":"#Kfold cross-validation\nfolds = KFold(n_splits=5, shuffle=False)\nscores = []\nfor i, (train_index, val_index) in enumerate(folds.split(X_train, y_train)):\n    train_data, target = X_train[train_index], y_train[train_index]\n    validation_data, val_target = X_train[val_index], y_train[val_index]\n    \n    model = LinearRegression()\n    model.fit(train_data, target)\n    #model = RandomForestRegressor(n_estimators=50,max_depth=5, n_jobs=-1, random_state=42)\n    #model.fit(train_data[:100000], target[:100000].squeeze())  # training on few samples to save time.\n    val_predictions = model.predict(validation_data)\n    error = root_mean_squared_error(val_target, val_predictions)\n    scores.append(error)\n    print(f'Fold {i} Root_mean_squared_error: {error}')\nprint(f'Average Root_mean_squared_error over 5 folds: {np.mean(scores)}')","00c1f610":"# Visualizing train error.\nfig, ax = plt.subplots(1,2, figsize=(16,6))\nax[0].set_title(\"=======Training error=======\")\nax[0].set_xlabel('Number of folds')\nax[0].set_ylabel('Error values')\nax[0].plot(scores)\n\n# Visualize predicted BP and the True BP\nax[1].set_title(\"===True BP values Vs Predicted BP values===\")\nax[1].set_xlabel('Number of samples taken')\nax[1].set_ylabel('BP values')\nax[1].plot(val_target[:100]) #only plotting 100 samples so as not to clog the graph\nax[1].plot(val_predictions[:100])\nax[1].legend(['True_BP', 'Predicted_BP'])","688d72e8":"# Predicting on the test set\ntest_predictions = model.predict(X_test[:1000000]) #predicting on the first 1million rows for speed.\ntest_error = root_mean_squared_error(y_test[:1000000], test_predictions)\nprint(f'Error on test set predictions: {test_error}')","fff93680":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import optimizers","92b36bdf":"def Model(input_dim, activation, num_class):\n    model = Sequential()\n\n    model.add(Dense(1024, input_dim = input_dim))\n    model.add(Activation(activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(512)) \n    model.add(Activation(activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(64))    \n    model.add(Activation(activation))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(num_class))    \n    model.add(Activation('linear'))\n    \n    model.compile(loss='Huber',\n                  optimizer=optimizers.Adam(lr = 0.001),\n                  metrics=['MeanAbsoluteError']\n                 )\n    return model","c4d9b1f3":"input_dim = X_train.shape[1]\nactivation = 'relu'\nclasses = 1\nmodel = Model(input_dim=input_dim, activation=activation, num_class=classes)\nmodel.summary()","8fbdcf5c":"# Visualizing the layers in our neural network model\ntf.keras.utils.plot_model(model)","5860bb08":"# Training the model\nhistory = model.fit(X_train[:1000000], # using the first 1million rows for speed.\n                    y_train[:1000000].squeeze(),\n                    epochs=5,\n                    batch_size=128,\n                    verbose = 1\n                   )","76ea46d1":"#Predicting on the test set using the nn(neural network) model\nnn_predictions = model.predict(X_test[:1000000])\nerror = root_mean_squared_error(y_test[:1000000], nn_predictions)\nprint(f'Neural Net root_mean_squared_error: {error}')","0ea95302":"plt.title('Train loss against mean_absolute_error')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.plot(history.history['loss'])\nplt.plot(history.history['mean_absolute_error'])\nplt.legend(['Loss', 'Mean_absolute_error'])","a9f06674":"# Visualize predicted BP and the True BP\nplt.title(\"===True BP values Vs Predicted BP values===\")\nplt.xlabel('Number of samples taken')\nplt.ylabel('BP values')\nplt.plot(y_test[:100]) #only plotting 100 samples\nplt.plot(nn_predictions[:100])\nplt.legend(['True_BP', 'Predicted_BP'])","6f2b5e40":"From  what we've seen above, we only need the values contained in the key `p` (photoplethysmograph or (PPG)). The other keys contain meta data that we won't need.\nTherefore in all other cells I'll apply `['p']` at the end of the `.loadmat() method` to only read the values contained in the key `['p']`i.e `scipy.io.loadmat(f'..\/input\/BloodPressureDataset\/part_{1}.mat')['p']`","40857350":"<a id='analysis'><\/a>\nWhat's happening in the cell above?\n\n* We use the `scipy.io.loadmat()` method to read our sample matlab(.mat) file and store it in the variable `sample_file`\n    * The `scipy.io.loadmat()` method reads the matlab file and returns a `dict`\/(dictionary) which is then stored back in the `sample_file` variable. To prove this, we print the data type of sample_file `type(sample_file)` as seen in line-2 and bingo it tells us its a `dict`\n    \n* A [dictionary](https:\/\/realpython.com\/python-dicts\/) is a [data structure](https:\/\/en.wikipedia.org\/wiki\/Data_structure#:~:text=In%20computer%20science%2C%20a%20data,be%20applied%20to%20the%20data.) that stores data in key, value pairs. For instance; {key1: value1, key2: value2}. What line-3 in the cell above does is to get and return the keys of the `sample_file` dictionary.\n\n### Things to try out:\n   * try displaying all contents of the `sample file` dictionary to see all its data (hint: just type sample file below the last print statement)\n   * display only the values of the `sample file` dictionary (hint: replace `.keys() with .values()`)\n   * load any other matlab file by substituting the value 1 with any other in the range (1-12) as there are only 12 files provided.","9b8e2321":"#### So here's what's happening in the cell above:\n\n* We use the `scipy.io.loadmat()` method to read our sample matlab(.mat) file and store it in the variable `test_sample`\n    * The `scipy.io.loadmat()` method reads the matlab file and this time around returns a [numpy ndarray](https:\/\/numpy.org\/doc\/stable\/reference\/arrays.ndarray.html#:~:text=Quick%20search-,The%20N%2Ddimensional%20array%20(%20ndarray%20),the%20sizes%20of%20each%20dimension.) (because of the `['p']`)  which is then stored in the `test_sample` variable. To prove this, we print the data type of test_sample `type(test_sample)` as seen in line-2 and bingo it tells us its `numpy.ndarray` (nd means n-dimensional)\n* Additionally, we check and print the size\/dimensions of `test_sample` by running `test_sample.shape` and it prints out `(1,1000)`; <strong> this means the array contains 1 row and 1000 columns.<\/strong>\n\n### Things to try out:\n\n* Load any other matlab file by substituting the value 1 with any other in the range (1-12) and re-run the cell (there are only 12 files provided.). You should get the same shape `(1,1000)`\n\n* Print out the entire `test_sample` array and see what it contains. (Hint: use print(test_sample) or just type test_sample and run the cell). You should see an outer array and multiple inner arrays.i.e all files contain one row and 1000 columns where each column is itself an array.\n\n* Try finding out the contents of each column and the size of each column (hint: accessing nested arrays)","79da8eda":"### Things to try:\n\n* <em style=color:red>Can you get a lower error than the current one with deep learning??<\/em>  Experiment with different techniques such as using different `hyperparameters` like:\n\n    * Increasing or decreasing the learning rate at `optimizer=optimizers.Adam(lr = 0.001)`: Learning rate is an adjustable parameter in a neural network that controls the step size at each iteration\/epoch while moving toward a minimum of a loss function. <em style=color:red> Does it improve or worsen the final result? <\/em>\n    \n    * Increasing or decreasing the number of epochs at (`model.fit(X_train[:1000000], y_train[:1000000].squeeze(), epochs=5, batch_size=128,verbose = 1)`):  Epochs are the number of cycles\/iterations through the training dataset.<em style=color:red> Does it improve or worsen the final result? <\/em>\n    \n    * Different Neural Network architecture: Architecture here refers to the number and organisation of layers in a neural network. So try increasing or reducing the number of layers in `def Model()` to see how it impacts the final results. <em style=color:red> Does it improve or worsen the final result? <\/em>\n\n**Food for Thought:**\nCan you find a similarity between learning rate and number of epochs\/iterations and the iterative methods in statistics","98464da7":"# 8. Further reading:\n\nWhat you've seen so far in [approach 2](#ml) and [approach 3](#dl) is just a tip of what Machine Learning and Deep Learning can be used for; Predicting Blood Pressure.\n\n<em style=color:red>What other tasks can Deep learning and Machine Learning solve??<\/em>\n\nIn the links below, you'll see how you can build models to solve tasks such as `training a Machine Learning model to classify clothes`, `predict fuel prices` and many others.\n\n1. [Intro to Machine Learning with tensorflow](https:\/\/www.youtube.com\/watch?v=KNAWp2S3w94&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=13&t=48s)\n\n2. [Solving a regression task with tensorflow](https:\/\/www.youtube.com\/watch?v=-vHQub0NXI4&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=20)\n\n3. [Time series analysis](https:\/\/www.tensorflow.org\/tutorials\/structured_data\/time_series)\n\n4. [Intro to Computer Vision](https:\/\/www.youtube.com\/watch?v=bemDFpNooA8&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=13)\n\n5. [Intro to Convolutional Neural Networks (CNNs)](https:\/\/www.youtube.com\/watch?v=x_VrgWTKkiM&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=14)\n\n6. [Image Classification](https:\/\/www.youtube.com\/watch?v=u2TjZzNuly8&list=PLQY2H8rRoyvwLbzbnKJ59NkZvQAW9wLbx&index=15)\n","142a3866":"**ElectroCardiogram (ECG)**\n\nECG or EKG check for signs of heart disease. It's a test that records the electrical activity of your ticker through small electrode patches that a technician attaches to the skin of your chest, arms, and legs.\n\nAn abnormal ECG can tell your doctor if you have any of these issues:\n\n\n1.   irregular heartbeat (an arrhythmia)\n2.   problems with the spread of electrical activity within the heart\n3.   an enlarged heart\n4.   areas of the heart with reduced blood supply\n5.   a \u2018silent\u2019 heart attack (an interruption to blood flow in the     coronary arteries without usual heart attack symptoms).\n\n\n<div><img src=\"https:\/\/ecglibrary.com\/ecgs\/norm_2x.png\", height=\"100\", width=\"500\"\/><\/div>","1b89ba7f":"# 3. Computing and Visualizing the Cross correlation of PPG and BP signals to assess their similarity\n\n[Cross correlation](https:\/\/en.wikipedia.org\/wiki\/Cross-correlation#:~:text=In%20signal%20processing%2C%20cross%2Dcorrelation,for%20a%20shorter%2C%20known%20feature.) is where two signals are compared inorder to produce a third signal that shows the similarity between the two signals compared. It can be used to create plots that may reveal hidden sequences.","dd9b23a8":"**The dataset:**\n\nThe blood pressure dataset provides clean and valid signals for designing cuff-less blood pressure estimation algorithms. \nThe matlab files (.mat) contain raw electrocardiogram (ECG), photoplethysmograph (PPG), and arterial blood pressure (ABP) signals stored as [cell arrays](https:\/\/www.mathworks.com\/help\/matlab\/ref\/cell.html#:~:text=A%20cell%20array%20is%20a,indices%20in%20smooth%20parentheses%2C%20()%20.) of matrices where each cell is one record part. \nIn each matrix, each row corresponds to one signal channel: \n\n1: PPG signal, FS=125Hz; photoplethysmograph from fingertip \n\n2: ABP signal, FS=125Hz; invasive arterial blood pressure (mmHg) \n\n3: ECG signal, FS=125Hz; electrocardiogram from channel II \n\nNote: Each cell is a record. There might be more than one record per patient (which is not possible to distinguish). However, records of the same patient appear next to each other. \nn-fold cross test and train is suggested to reduce the chance of train set being contaminated by test patients","a0dee51f":"# 2. Analyzing the Blood Pressure Dataset\nAnalysing and visualizing the structure and content of the Blood Pressure dataset to get a deeper understanding of how we'll manipulate the data and thereafter feed it into any of our models for training.","ef4c6b60":"# 5. Predicting Blood Pressure using Machine Learning:\n### Approach 2:\n\n* [Intro to Machine Learning video](https:\/\/www.youtube.com\/watch?v=KNAWp2S3w94&t=31s)\n<a id='ml'><\/a>\n\nI'll train a simple [linear regression model](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LinearRegression.html) model on `ppg signals` with `bp` as my target variable (you may add `ecg` too but I'll only focus on `bp`.\nI'll split the data into train and test sets and further split the train set using KFold splits into train and validation sets.","4757b992":"The error margin seem too big so let's try other methods and see what error we'll get. If we get lower values, then our assumption won't be true as `dct` will then become a bad prediction method.","c617b817":"<a id='sbp_cell'><\/a>\nIn the cell below, I extract BP and ECG signals from the mat file and store them in an array\/list.\n* I additionally extract Systolic blood pressure(SBP) and Diastolic Blood pressure(DBP) from the BP signal.\n\n* `systole` and `diastole` are two phases of a heart beat. `BP` <strong>increases<\/strong> as the heart muscle contracts during `systole`, where blood is pushed towards the periphery of the body and it <strong>decreases<\/strong> when the heart relaxes to fill with blood during the `diastole`. Hence we take `max(BP)` to derive `SBP` and `min(BP)` to get `DBP`. refer to [this paper](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6696196\/) for more insight.","5a01bc11":"From the graph above it can be seen that the training loss and mean_absolute_error stabilize at around epoch number 4 meaning that our model is starting to converge to a stable loss value.","4f0c018a":"The challenge here is <em style='color: red'>can you predict Blood Pressure(BP) and (ECG) given PPG signals?<\/em> We'll evaluate our predictions using the `Root Mean Squared Error` where a lower value means our predictions are closer to the true values of `BP`.\n\nWe explore some estimation methods in this notebook.\n\nContent:\n1. [Analysis](#analysis)\n2. [Differentiation](#dct)\n3. [Predicting BP from PPG using Machine Learning](#ml)\n4. [Deep Learning approach to predicting BP](#dl)","62e8d55b":"We'll build a 3-layer neural network with the `relu` activation function and a `dropout layer` at the end of every `dense layer` to predict Blood pressure given PPG signals. The final `dense layer` with the `linear activation function` will output the `final predictions`. We train our neural network with the `Adam Optimizer` and the huber `loss function`.\n\nFor more details about all these terminology, refer the [videos here](https:\/\/www.youtube.com\/channel\/UC0rqucBdTuFTjJiefW5t-IQ)","a347cfa5":"Our test and validation errors are within the same range. However from the second graph above (True BP vs Predicted BP) we see that our model doesn't predict the peaks correctly.\n\n### Things to try out:\n\n* Predict ecg from ppg instead of bp. (Hint: replace bp with ecg in the cell that has `train_test_split(...)`)\n* Experiment with other machine learning models to reduce the error to below `27` for example comment out the `model = LinearRegression()` and the next `model.fit` line and uncomment the commented code to see the improvement","003c8347":"It can be seen from above that `SBP` is higher than `DBP` as was explained [earlier](#sbp_cell)","87413993":"# 6. Predicting Blood Pressure using Deep Learning\n### Approach 3:\n\n<a id='dl'><\/a>\nFor more resource about deep learning,[VISIT this site](https:\/\/www.tensorflow.org\/tutorials\/keras\/regression)\n\nOther links to useful videos:\n* [blood pressure estimation with CNNs](https:\/\/www.youtube.com\/watch?v=tZLotOFiyZ4)","81922a52":"# 7. Conclusion\nOur model seems to predict peaks in signal very well compared to our machine learning model in approach 2 which didn't predict the peaks very well. It also gives a smaller `root_mean_squared_error` compared to [approach 2](#ml) and [approach 1](#dct)\n\nThis means that our Neural network model performs better than the machine learning model in approach 2.\n\n**Note:**\n\nYou notice that I have used [TensorFlow](https:\/\/www.tensorflow.org\/tutorials\/) to build the Neural network for approach 3; However there is another popular [deep learning framework](https:\/\/www.analyticsvidhya.com\/blog\/2019\/03\/deep-learning-frameworks-comparison\/) called [PyTorch](https:\/\/pytorch.org\/) that you can read more about and perhaps use in your other deep learning tasks.","697f8721":"As can be seen from above, the layers follow each other in a sequential manner implying that the output of one layer is the input of the next layer.\n\nFor more details about Neural network layers and how they work, refer the [tensorflow playground](https:\/\/playground.tensorflow.org\/) and TRY different parameter configurations to see how they affect the final outcome\/prediction","8e0be71f":"# Cuff_Less Blood Pressure Estimation:\n\n# 1. Overview:\n\n<em style='color: red'>Blood pressure (BP)<\/em>, also referred to as <em style='color: red'>Arterial blood pressure (ABP)<\/em>, is the pressure exerted by circulating blood upon the walls of blood vessels.\n\n\nThe most common approach to measure Blood Pressure (BP) without clinical supervision is the automated BP cuff employing oscillometry. A cuff is wrapped around the upper arm and inflated above systolic pressure, then deflated to a pressure below diastolic BP. A pressure sensor inserted in the cuff records the arterial pulsations during the cuff deflation, and the amplitudes of these pulsations are used to calculate systolic and diastolic BP. \n\n<div><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/c\/c6\/Blood_pressure_monitoring.jpg\/1920px-Blood_pressure_monitoring.jpg\", height=\"100\", width=\"500\"\/><\/div>\n\n\nThis approach has many limitations, the primary one being that it relies on a set of empirical coefficients to map the pulse amplitudes to systolic and diastolic BP. Most of these coefficients are specific to the device and can vary across devices. \n\nFurther, since it relies solely on pulse amplitudes, <strong> it fails to provide accurate readings in patients with atherosclerosis or obese patients whose pulse amplitudes can be weak<\/strong>.","6769f978":"# 4. Are BP signals a derivative of PPG\n### Approach 1: Representing BP as a derivative of PPG\n\n<a id='dct'><\/a>\nLets assume that `BP` is `derivative(PPG)` or that `BP` is a derivative of PPG and try to prove this hypothesis using the root mean squared error as our evaluation function.","9b469b20":"**PhotoPlethysmoGraph (PPG)**\n\nA photoplethysmogram (PPG) is an optically obtained plethysmogram that can be used to detect blood volume changes in the microvascular bed of tissue. A PPG is often obtained by using a pulse oximeter which illuminates the skin and measures changes in light absorption.A conventional pulse oximeter monitors the perfusion of blood to the dermis and subcutaneous tissue of the skin.\n\nA plethysmograph is an instrument for measuring changes in volume within an organ or whole body (usually resulting from fluctuations in the amount of blood or air it contains). \n\n<div><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/d\/dc\/Pulse_oximiter%2C_Photoplethysmograph.jpg\/675px-Pulse_oximiter%2C_Photoplethysmograph.jpg\", height=\"50\", width=\"300\"\/><\/div>","39d2fcd1":"### Use this kernel as inspiration to dive deeper into some topics you find interesting\n"}}