{"cell_type":{"ada406e7":"code","7b9a9977":"code","f414057b":"code","91d0a154":"code","91d9b497":"code","b6822cde":"code","4b861ab1":"code","b46f5700":"code","96657fa1":"code","44ad2441":"code","ed5eb8e8":"code","9392bf75":"code","a3813101":"code","8cc5e365":"code","f80aeb9d":"code","a05d6c91":"code","9637f0e9":"code","7417dc58":"code","534f9a8c":"code","3c01f875":"markdown","40ce836d":"markdown","d2e0f03f":"markdown","a860536f":"markdown","a49bc195":"markdown","a6fd8b0a":"markdown"},"source":{"ada406e7":"import torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\n\ntorch.manual_seed(1)","7b9a9977":"V = [1., 2. , 3.]\nV_ten = torch.tensor(V)\nV_ten","f414057b":"M = [ [1., 2., 3.], [4., 5., 6.]]\nM_ten = torch.tensor(M)\nM_ten","91d0a154":"T = [ [[1., 2., 3.], [4., 5., 6.]], [ [7., 8., 9.], [10., 11., 12.]] ]\nT_ten = torch.tensor(T)\nT_ten","91d9b497":"print(V_ten[0])\nprint(V_ten[0].item())\n","b6822cde":"print(M_ten[0])","4b861ab1":"print(T_ten[0])","b46f5700":"x = torch.tensor([1., 2., 3.])\ny = torch.tensor([4., 5., 6.])","96657fa1":"x+y","44ad2441":"x1 = torch.randn(2, 5)\ny1 = torch.randn(3, 5)\nz1 = torch.cat([x1, y1]) #by default concatenates along the first axis (row \/ one under another)\nprint(z1)","ed5eb8e8":"x2 = torch.randn(2, 3)\ny2 = torch.randn(2, 5)\nz2 = torch.cat( [x2, y2], 1) #concatenation along 2nd axis - column\nprint(z2)","9392bf75":"x = torch.randn(2, 3, 4)\nprint(x)\n\nprint(x.view(2, 12))\n#OR\nprint(x.view(2, -1))","a3813101":"x = torch.tensor([1., 2., 3.], requires_grad= True)\ny = torch.tensor([4., 5., 6.], requires_grad= True)\nz = x+y\nprint(z.grad_fn)","8cc5e365":"s = z.sum()\nprint(s)\nprint(s.grad_fn)","f80aeb9d":"s.backward()\nprint( x.grad )","a05d6c91":"x = torch.randn(2, 2)\ny = torch.randn(2, 2)\nprint(x.requires_grad, y.requires_grad)\nprint(z.grad_fn)\nprint('\\n')\nx = x.requires_grad_() #change in place the value of x.requires_grad\ny = y.requires_grad_()\nz = x+y\nprint(x.requires_grad, y.requires_grad)\nprint(z.grad_fn)\nprint(z.requires_grad)","9637f0e9":"new_z = z.detach()\nprint(new_z.grad_fn)","7417dc58":"print( x.requires_grad)\nprint((x**2).requires_grad)\n\nwith torch.no_grad():\n    print(x.requires_grad)\n    print((x**2).requires_grad)","534f9a8c":"#This is the code for tutorial from the website https:\/\/pytorch.org\/tutorials\/beginner\/nlp\/pytorch_tutorial.html#sphx-glr-beginner-nlp-pytorch-tutorial-py","3c01f875":"**COMPUTATION GRAPH AND AUTOMATIC DIFFERENTATION**","40ce836d":"**CRUCIAL PART**","d2e0f03f":"**TENSOR CONCATANATION**","a860536f":"**TORCH.NO_GRAD()**","a49bc195":"**TENSORS**","a6fd8b0a":"**RESHAPING TENSORS**"}}