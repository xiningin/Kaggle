{"cell_type":{"71e89444":"code","0b1580a4":"code","404512eb":"code","8f6e71c6":"code","fc1ae872":"code","add3534a":"code","920d5619":"code","9467bb91":"code","9a7ca6a6":"code","8795729b":"code","c3276678":"code","96059a55":"code","75361fe1":"code","165e011d":"code","7c908fc5":"code","05855b5a":"code","5ba375c9":"code","7d71a6b7":"code","4903c604":"code","7572766d":"code","2dcf866c":"code","7e9677f4":"code","d91812e3":"code","80277c33":"code","d1df9421":"code","f1e7e53b":"code","f588d811":"code","640d0c78":"code","71446c89":"code","32c729e6":"code","90207b0f":"code","63f7776a":"code","22b77293":"code","89b53f26":"code","34e217e6":"code","f0c95b65":"code","ae4fb756":"markdown","67e94c95":"markdown"},"source":{"71e89444":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b1580a4":"import tensorflow as tf\n#import tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom shutil import copyfile","404512eb":"import os\nimport numpy as np \nimport pandas as pd ","8f6e71c6":"tf.__version__","fc1ae872":"# CONFIGURE GPUs\n#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\ngpus = tf.config.list_physical_devices('GPU'); print(gpus)\nif len(gpus)==1: strategy = tf.distribute.OneDeviceStrategy(device=\"\/gpu:0\")\nelse: strategy = tf.distribute.MirroredStrategy()","add3534a":"import IPython.display as display\nfrom PIL import Image","920d5619":"import pathlib\ndata_dir = pathlib.Path('\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/')\nimage_count = len(list(data_dir.glob('*.jpg')))\nimage_count","9467bb91":"df = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv')\ndf.head(3)","9a7ca6a6":"df_sorted = df.sort_values(by='target', ascending=False)\ndf_sorted.head()","8795729b":"import shutil\nex = list(data_dir.glob('*.jpg'))\n\n#for image_path in ex[:3]:\n    #display.display(Image.open(str(image_path)))","c3276678":"str(ex[1])","96059a55":"# create a list of labels (0 - benign, 1 - cancer)\nlabels = []\nfilenames = []\ncounter = 0\nfor item in ex:\n    tmp = df.loc[df['image_name'] == item.stem,'target'].iloc[0]\n    labels.append(tmp)\n    filenames.append(str(item))\n    if tmp == 1:\n        counter+=1\ncounter        ","75361fe1":"AUTOTUNE = tf.data.experimental.AUTOTUNE","165e011d":"train_data = tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))","7c908fc5":"next(iter(train_data))","05855b5a":"# Function to load and preprocess each image\ndef _parse_fn(filename, label):\n    img = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img)\n    img = (tf.cast(img, tf.float32)\/127.5) - 1\n    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n    return img, label","5ba375c9":"IMAGE_SIZE = 224 # Minimum image size for use with MobileNetV2\nBATCH_SIZE = 32\ntrain_data = train_data.map(_parse_fn)","7d71a6b7":"for image, label in train_data.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","4903c604":"def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    #ds = ds.repeat()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","7572766d":"train_ds_batched = prepare_for_training(train_data)","2dcf866c":"for image, label in train_data.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","7e9677f4":"#next(iter(train_ds_batched))","d91812e3":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam","80277c33":"METRICS = [\n      #tf.keras.metrics.TruePositives(name='tp'),\n      #tf.keras.metrics.FalsePositives(name='fp'),\n      #tf.keras.metrics.TrueNegatives(name='tn'),\n      #tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      #tf.keras.metrics.Precision(name='precision'),\n      #tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n]","d1df9421":"model = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', input_shape=(224, 224 ,3)),\n    MaxPooling2D(),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])\n\nmodel.summary()","f1e7e53b":"class_weight = {0: 1.,\n                1: 1.}","f588d811":"# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss='binary_crossentropy',\n              metrics=[tf.keras.metrics.Accuracy()])","640d0c78":"model.fit(train_ds_batched,\n          epochs=20,\n          class_weight=class_weight,\n          steps_per_epoch = 100)","71446c89":"alt_model = Sequential()\nalt_model.add(Conv2D(32,3, activation='relu', input_shape=(224, 224 ,3)))\nalt_model.add(Dropout(0.5))\nalt_model.add(MaxPooling2D())\nalt_model.add(BatchNormalization())\nalt_model.add(Conv2D(64,3, activation='relu'))\nalt_model.add(Dropout(0.5))\nalt_model.add(MaxPooling2D())\nalt_model.add(BatchNormalization())\nalt_model.add(Conv2D(128,3,activation='relu'))\nalt_model.add(MaxPooling2D())\nalt_model.add(Flatten())\nalt_model.add(Dropout(0.5))\nalt_model.add(BatchNormalization())\nalt_model.add(Dense(512, activation='relu'))\nalt_model.add(Dense(1,activation='softmax'))\n\nalt_model.summary()","32c729e6":"# Compile the model\nalt_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss='binary_crossentropy',\n              metrics=['accuracy'])","90207b0f":"alt_model.fit(train_ds_batched,\n          epochs=10,\n          class_weight=class_weight,\n          steps_per_epoch = 20)","63f7776a":"#Using pretrained ImageNet\nIMAGE_SIZE = 224\nIMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n# Pre-trained model with MobileNetV2\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=IMG_SHAPE,\n    include_top=False,\n    weights='imagenet'\n)\n# Freeze the pre-trained model weights\nbase_model.trainable = True\n# Trainable classification head\nmaxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\nprediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n# Layer classification head with feature detector\nmodel_mobileNet = tf.keras.Sequential([\n    base_model,\n    maxpool_layer,\n    prediction_layer\n])\n\n\nmodel_mobileNet.summary()","22b77293":"learning_rate = 0.0005\nmodel_mobileNet.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), \n              loss='binary_crossentropy',\n              metrics=METRICS\n)","89b53f26":"model_mobileNet.fit(train_ds_batched,\n          epochs=5,\n          steps_per_epoch = 50)","34e217e6":"with strategy.scope():\n    #Using pretrained ImageNet\n    IMAGE_SIZE = 224\n    IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n    # Pre-trained model with MobileNetV2\n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=IMG_SHAPE,\n        include_top=False,\n        weights='imagenet'\n    )\n    # Freeze the pre-trained model weights\n    base_model.trainable = True\n    # Trainable classification head\n    maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n    prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n    # Layer classification head with feature detector\n    model_mobileNet = tf.keras.Sequential([\n        base_model,\n        maxpool_layer,\n        prediction_layer\n    ])\n    \n    # Compile the model\n    model_mobileNet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel_mobileNet.summary()","f0c95b65":"model_mobileNet.fit(train_ds_batched,\n          epochs=5,\n          steps_per_epoch = 50)","ae4fb756":"# Model","67e94c95":"Models while using GPU"}}