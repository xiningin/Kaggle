{"cell_type":{"7eee99c0":"code","5a02e2f6":"code","8c41cd23":"code","72e68411":"code","508f5e7d":"code","fa0f5656":"code","34f83f5c":"code","9224a846":"code","15af6382":"code","9fd97ab3":"code","545abc5a":"code","a9550ec4":"code","7481f0a2":"code","e844cae7":"code","e1677031":"code","e480c187":"code","44930773":"code","c374c720":"code","8917c588":"code","d1a96584":"markdown"},"source":{"7eee99c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5a02e2f6":"!ls","8c41cd23":"import sklearn.datasets\nimport sklearn.model_selection\nimport keras.preprocessing.image\nimport keras.utils\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom skimage import color\nfrom sklearn.metrics import accuracy_score\nimport sklearn.neighbors\n\nimport os\nimport numpy as np\nimport cv2\n\n#def load_data(infDir):\n#    infData=sklearn.datasets.load_files(infDir,load_content=False)\n#    y_inf = np.array(infData['target'])\n#    y_inf_names = np.array(infData['target_names'])\n#    nclasses = len(np.unique(y_inf))\n#    target_size=50\n#    x_inf=[]\n#    for filename in infData['filenames']:\n#        x_inf.append(\n#                keras.preprocessing.image.img_to_array(\n#                        keras.preprocessing.image.load_img(filename,target_size=(target_size, target_size))\n#                )\n#        )\n#    return([x_inf,y_inf])\n    \n    \n\ntrain_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Training'\ntrainData=sklearn.datasets.load_files(train_dir,load_content=False)\n\ntest_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Test'\ntestData=sklearn.datasets.load_files(test_dir,load_content=False)\n\n\ny_train = np.array(trainData['target'])\ny_train_names = np.array(trainData['target_names'])\n\ny_test = np.array(testData['target'])\ny_test_names = np.array(testData['target_names'])\n\nnclasses = len(np.unique(y_train))\ntarget_size=50\n\nx_train=[]\nfor filename in trainData['filenames']:\n    x_train.append(\n            keras.preprocessing.image.img_to_array(\n                    keras.preprocessing.image.load_img(filename,target_size=(target_size, target_size))\n                    )\n            )\n    \n    \nx_test=[]\nfor filename in testData['filenames']:\n    x_test.append(\n            keras.preprocessing.image.img_to_array(\n                    keras.preprocessing.image.load_img(filename,target_size=(target_size, target_size))\n                    )\n            )","72e68411":"x_train=np.array(x_train)\nx_train=x_train\/255\ny_train=keras.utils.np_utils.to_categorical(y_train,nclasses)\n\n\nx_test=np.array(x_test)\nx_test=x_test\/255\ny_test=keras.utils.np_utils.to_categorical(y_test,nclasses)","508f5e7d":"x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(\n        x_train, y_train, test_size=0.2\n)\nprint(y_train.shape)\nprint(y_val.shape)","fa0f5656":"model = keras.models.Sequential()\n\n \n#1st convolution layer\nmodel.add(keras.layers.Conv2D(32, (3, 3) #16 is number of filters and (3, 3) is the size of the filter.\n, padding='same', input_shape=x_train.shape[1:], activation='relu'))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'))\n#model.add(keras.layers.BatchNormalization())\n \n#2nd convolution layer\nmodel.add(keras.layers.Conv2D(16,(3, 3), padding='same', activation='relu')) # apply 2 filters sized of (3x3)\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'))\n#model.add(keras.layers.BatchNormalization())\n\n#3nd convolution layer\nmodel.add(keras.layers.Conv2D(8,(3, 3), padding='same', activation='relu')) # apply 2 filters sized of (3x3)\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2), padding='same',name='encoder'))\n#model.add(keras.layers.BatchNormalization())\n\n#here compressed version\n \n#4rd convolution layer\nmodel.add(keras.layers.Conv2D(8,(3, 3), padding='same', activation='relu')) # apply 2 filters sized of (3x3)\nmodel.add(keras.layers.UpSampling2D((2, 2)))    \n#model.add(keras.layers.BatchNormalization())\n\n#5rd convolution layer\nmodel.add(keras.layers.Conv2D(16,(3, 3), padding='same', activation='relu')) # apply 2 filters sized of (3x3)\nmodel.add(keras.layers.UpSampling2D((2, 2)))\n#model.add(keras.layers.BatchNormalization()) \n    \n#6rd convolution layer\nmodel.add(keras.layers.Conv2D(32,(3, 3), padding='same', activation='relu'))\nmodel.add(keras.layers.UpSampling2D((2, 2)))\n#model.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(3,(7, 7)))\nmodel.add(keras.layers.Activation('sigmoid'))\n\nmodel.summary()","34f83f5c":"from IPython.display import SVG\nimport IPython\nfrom keras.utils import model_to_dot\n\nprint(model.summary())\n\nkeras.utils.plot_model(model, to_file='test_keras_plot_model.png', show_shapes=True)\nIPython.display.Image('test_keras_plot_model.png')","9224a846":"model.compile(optimizer='adadelta', loss='binary_crossentropy')\ncheckpointer = keras.callbacks.ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = True)\nearlystopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto', baseline=None, restore_best_weights=False)","15af6382":"history=model.fit(x_train,\n          x_train,\n          batch_size=256,\n          epochs=50,\n          validation_data=(\n               x_val,\n               x_val), callbacks = [checkpointer], shuffle=True)","9fd97ab3":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","545abc5a":"encoder = keras.models.Model(inputs=model.input, outputs=model.get_layer('encoder').output)\nencoder.summary()","a9550ec4":"num_images = 10\nrandom_test_images = np.random.randint(x_val.shape[0], size=num_images)\n\nencoded_imgs = encoder.predict(x_val)\ndecoded_imgs = model.predict(x_val)\n\nplt.figure(figsize=(18, 4))\n\nfor i, image_idx in enumerate(random_test_images):\n    # plot original image\n    ax = plt.subplot(3, num_images, i + 1)\n    plt.imshow(x_val[image_idx].reshape(50,50,3))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    ## plot encoded image\n    #ax = plt.subplot(3, num_images, num_images + i + 1)\n    #plt.imshow(encoded_imgs[image_idx].reshape(28, 28))\n    #plt.gray()\n    #ax.get_xaxis().set_visible(False)\n    #ax.get_yaxis().set_visible(False)\n\n    # plot reconstructed image\n    ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n    plt.imshow(decoded_imgs[image_idx].reshape(50,50,3))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","7481f0a2":"x_encoded_train=encoder.predict(x_train)\nx_encoded_val=encoder.predict(x_val)\nprint(x_encoded_val.shape)","e844cae7":"x_train_flatted=x_encoded_train.reshape(x_encoded_train.shape[0],np.prod(x_encoded_train.shape[1:]))\nx_val_flatted=x_encoded_val.reshape(x_encoded_val.shape[0],np.prod(x_encoded_val.shape[1:]))","e1677031":"import sklearn.neighbors\nknn_model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\nknn_model.fit(x_train_flatted, y_train)","e480c187":"x_encoded_test=encoder.predict(x_test)\nx_test_flatted=x_encoded_test.reshape(x_encoded_test.shape[0],np.prod(x_encoded_test.shape[1:]))","44930773":"y_test_pred = knn_model.predict(x_test_flatted)\nprint(accuracy_score(y_test_pred, y_test))","c374c720":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, verbose=1, n_iter=500)\ntsne_results = tsne.fit_transform(x_val_flatted)","8917c588":"plt.figure(figsize=(30, 30))\nplt.scatter(x=tsne_results[:,0],y=tsne_results[:,1],c=np.argmax(y_val, axis=1),cmap='rainbow')\n#plt.colorbar()\nplt.show()","d1a96584":"**Visualization** T-SNE\n"}}