{"cell_type":{"7bc74aeb":"code","da11d135":"code","dda34059":"code","32d9b48b":"code","2c6d3546":"code","ae277d84":"code","2bafda2d":"code","f091b799":"code","6af68064":"code","e0b5e616":"code","391c2d64":"code","90aa85d0":"code","a2cdbd7e":"code","0a6f8491":"code","71cce688":"markdown","c1683410":"markdown","e6d86b13":"markdown","35f4b316":"markdown","feaf73d1":"markdown","2ad6d7da":"markdown","6d67ca43":"markdown","96baf556":"markdown","8daf5694":"markdown","a2044794":"markdown","e6e7adc7":"markdown","2335fe1d":"markdown","5936186c":"markdown","4e248835":"markdown","5f0c2318":"markdown","8c362ca6":"markdown","add2af66":"markdown","ee6b9a62":"markdown","5da1d74b":"markdown"},"source":{"7bc74aeb":"# Copy-pasted map between questions and columns\n\nq7_list_of_columns = ['Q7_Part_1',\n                      'Q7_Part_2',\n                      'Q7_Part_3',\n                      'Q7_Part_4',\n                      'Q7_Part_5',\n                      'Q7_Part_6',\n                      'Q7_Part_7',\n                      'Q7_Part_8',\n                      'Q7_Part_9',\n                      'Q7_Part_10',\n                      'Q7_Part_11',\n                      'Q7_Part_12',\n                      'Q7_OTHER']\n\nq9_list_of_columns = ['Q9_Part_1',\n                      'Q9_Part_2',\n                      'Q9_Part_3',\n                      'Q9_Part_4',\n                      'Q9_Part_5',\n                      'Q9_Part_6',\n                      'Q9_Part_7',\n                      'Q9_Part_8',\n                      'Q9_Part_9',\n                      'Q9_Part_10',\n                      'Q9_Part_11',\n                      'Q9_OTHER']\n\nq10_list_of_columns = ['Q10_Part_1',\n                       'Q10_Part_2',\n                       'Q10_Part_3',\n                       'Q10_Part_4',\n                       'Q10_Part_5',\n                       'Q10_Part_6',\n                       'Q10_Part_7',\n                       'Q10_Part_8',\n                       'Q10_Part_9',\n                       'Q10_Part_10',\n                       'Q10_Part_11',\n                       'Q10_Part_12',\n                       'Q10_Part_13',\n                       'Q10_OTHER']\n\nq12_list_of_columns = ['Q12_Part_1',\n                            'Q12_Part_2',\n                            'Q12_Part_3',\n                            'Q12_OTHER']\n\nq14_list_of_columns = ['Q14_Part_1',\n                            'Q14_Part_2',\n                            'Q14_Part_3',\n                            'Q14_Part_4',\n                            'Q14_Part_5',\n                            'Q14_Part_6',\n                            'Q14_Part_7',\n                            'Q14_Part_8',\n                            'Q14_Part_9',\n                            'Q14_Part_10',\n                            'Q14_Part_11',\n                            'Q14_OTHER']\n\nq16_list_of_columns = ['Q16_Part_1',\n                       'Q16_Part_2',\n                       'Q16_Part_3',\n                       'Q16_Part_4',\n                       'Q16_Part_5',\n                       'Q16_Part_6',\n                       'Q16_Part_7',\n                       'Q16_Part_8',\n                       'Q16_Part_9',\n                       'Q16_Part_10',\n                       'Q16_Part_11',\n                       'Q16_Part_12',\n                       'Q16_Part_13',\n                       'Q16_Part_14',\n                       'Q16_Part_15',\n                       'Q16_OTHER']\n\nq17_list_of_columns = ['Q17_Part_1',\n                       'Q17_Part_2',\n                       'Q17_Part_3',\n                       'Q17_Part_4',\n                       'Q17_Part_5',\n                       'Q17_Part_6',\n                       'Q17_Part_7',\n                       'Q17_Part_8',\n                       'Q17_Part_9',\n                       'Q17_Part_10',\n                       'Q17_Part_11',\n                       'Q17_OTHER']\n\nq18_list_of_columns = ['Q18_Part_1',\n                       'Q18_Part_2',\n                       'Q18_Part_3',\n                       'Q18_Part_4',\n                       'Q18_Part_5',\n                       'Q18_Part_6',\n                       'Q18_OTHER']\n\nq19_list_of_columns = ['Q19_Part_1',\n                       'Q19_Part_2',\n                       'Q19_Part_3',\n                       'Q19_Part_4',\n                       'Q19_Part_5',\n                       'Q19_OTHER']\n\nq23_list_of_columns = ['Q23_Part_1',\n                       'Q23_Part_2',\n                       'Q23_Part_3',\n                       'Q23_Part_4',\n                       'Q23_Part_5',\n                       'Q23_Part_6',\n                       'Q23_Part_7',\n                       'Q23_OTHER']\n\nq26a_list_of_columns = ['Q26_A_Part_1',\n                        'Q26_A_Part_2',\n                        'Q26_A_Part_3',\n                        'Q26_A_Part_4',\n                        'Q26_A_Part_5',\n                        'Q26_A_Part_6',\n                        'Q26_A_Part_7',\n                        'Q26_A_Part_8',\n                        'Q26_A_Part_9',\n                        'Q26_A_Part_10',\n                        'Q26_A_Part_11',\n                        'Q26_A_OTHER']\n\nq26b_list_of_columns = ['Q26_B_Part_1',\n                        'Q26_B_Part_2',\n                        'Q26_B_Part_3',\n                        'Q26_B_Part_4',\n                        'Q26_B_Part_5',\n                        'Q26_B_Part_6',\n                        'Q26_B_Part_7',\n                        'Q26_B_Part_8',\n                        'Q26_B_Part_9',\n                        'Q26_B_Part_10',\n                        'Q26_B_Part_11',\n                        'Q26_B_OTHER']\n\nq27a_list_of_columns = ['Q27_A_Part_1',\n                        'Q27_A_Part_2',\n                        'Q27_A_Part_3',\n                        'Q27_A_Part_4',\n                        'Q27_A_Part_5',\n                        'Q27_A_Part_6',\n                        'Q27_A_Part_7',\n                        'Q27_A_Part_8',\n                        'Q27_A_Part_9',\n                        'Q27_A_Part_10',\n                        'Q27_A_Part_11',\n                        'Q27_A_OTHER']\n\nq27b_dictionary_of_counts = ['Q27_B_Part_1',\n                             'Q27_B_Part_2',\n                             'Q27_B_Part_3',\n                             'Q27_B_Part_4',\n                             'Q27_B_Part_5',\n                             'Q27_B_Part_6',\n                             'Q27_B_Part_7',\n                             'Q27_B_Part_8',\n                             'Q27_B_Part_9',\n                             'Q27_B_Part_10',\n                             'Q27_B_Part_11',\n                             'Q27_B_OTHER']\n\nq28a_list_of_columns = ['Q28_A_Part_1',\n                        'Q28_A_Part_2',\n                        'Q28_A_Part_3',\n                        'Q28_A_Part_4',\n                        'Q28_A_Part_5',\n                        'Q28_A_Part_6',\n                        'Q28_A_Part_7',\n                        'Q28_A_Part_8',\n                        'Q28_A_Part_9',\n                        'Q28_A_Part_10',\n                        'Q28_A_OTHER']\n\nq28b_list_of_columns = ['Q28_B_Part_1',\n                        'Q28_B_Part_2',\n                        'Q28_B_Part_3',\n                        'Q28_B_Part_4',\n                        'Q28_B_Part_5',\n                        'Q28_B_Part_6',\n                        'Q28_B_Part_7',\n                        'Q28_B_Part_8',\n                        'Q28_B_Part_9',\n                        'Q28_B_Part_10',\n                        'Q28_B_OTHER']\n\nq29a_list_of_columns = ['Q29_A_Part_1',\n                        'Q29_A_Part_2',\n                        'Q29_A_Part_3',\n                        'Q29_A_Part_4',\n                        'Q29_A_Part_5',\n                        'Q29_A_Part_6',\n                        'Q29_A_Part_7',\n                        'Q29_A_Part_8',\n                        'Q29_A_Part_9',\n                        'Q29_A_Part_10',\n                        'Q29_A_Part_11',\n                        'Q29_A_Part_12',\n                        'Q29_A_Part_13',\n                        'Q29_A_Part_14',\n                        'Q29_A_Part_15',\n                        'Q29_A_Part_16',\n                        'Q29_A_Part_17',\n                        'Q29_A_OTHER']\n\nq29b_list_of_columns = ['Q29_B_Part_1',\n                        'Q29_B_Part_2',\n                        'Q29_B_Part_3',\n                        'Q29_B_Part_4',\n                        'Q29_B_Part_5',\n                        'Q29_B_Part_6',\n                        'Q29_B_Part_7',\n                        'Q29_B_Part_8',\n                        'Q29_B_Part_9',\n                        'Q29_B_Part_10',\n                        'Q29_B_Part_11',\n                        'Q29_B_Part_12',\n                        'Q29_B_Part_13',\n                        'Q29_B_Part_14',\n                        'Q29_B_Part_15',\n                        'Q29_B_Part_16',\n                        'Q29_B_Part_17',\n                        'Q29_B_OTHER']\n\nq31a_list_of_columns = ['Q31_A_Part_1',\n                        'Q31_A_Part_2',\n                        'Q31_A_Part_3',\n                        'Q31_A_Part_4',\n                        'Q31_A_Part_5',\n                        'Q31_A_Part_6',\n                        'Q31_A_Part_7',\n                        'Q31_A_Part_8',\n                        'Q31_A_Part_9',\n                        'Q31_A_Part_10',\n                        'Q31_A_Part_11',\n                        'Q31_A_Part_12',\n                        'Q31_A_Part_13',\n                        'Q31_A_Part_14',\n                        'Q31_A_OTHER']\n\nq31b_list_of_columns = ['Q31_B_Part_1',\n                        'Q31_B_Part_2',\n                        'Q31_B_Part_3',\n                        'Q31_B_Part_4',\n                        'Q31_B_Part_5',\n                        'Q31_B_Part_6',\n                        'Q31_B_Part_7',\n                        'Q31_B_Part_8',\n                        'Q31_B_Part_9',\n                        'Q31_B_Part_10',\n                        'Q31_B_Part_11',\n                        'Q31_B_Part_12',\n                        'Q31_B_Part_13',\n                        'Q31_B_Part_14',\n                        'Q31_B_OTHER']\n\nq33a_list_of_columns = ['Q33_A_Part_1',\n                        'Q33_A_Part_2',\n                        'Q33_A_Part_3',\n                        'Q33_A_Part_4',\n                        'Q33_A_Part_5',\n                        'Q33_A_Part_6',\n                        'Q33_A_Part_7',\n                        'Q33_A_OTHER']\n\nq33b_list_of_columns = ['Q33_B_Part_1',\n                        'Q33_B_Part_2',\n                        'Q33_B_Part_3',\n                        'Q33_B_Part_4',\n                        'Q33_B_Part_5',\n                        'Q33_B_Part_6',\n                        'Q33_B_Part_7',\n                        'Q33_B_OTHER']\n\nq34a_list_of_columns = ['Q34_A_Part_1',\n                        'Q34_A_Part_2',\n                        'Q34_A_Part_3',\n                        'Q34_A_Part_4',\n                        'Q34_A_Part_5',\n                        'Q34_A_Part_6',\n                        'Q34_A_Part_7',\n                        'Q34_A_Part_8',\n                        'Q34_A_Part_9',\n                        'Q34_A_Part_10',\n                        'Q34_A_Part_11',\n                        'Q34_A_OTHER']\n\nq34b_list_of_columns = ['Q34_B_Part_1',\n                        'Q34_B_Part_2',\n                        'Q34_B_Part_3',\n                        'Q34_B_Part_4',\n                        'Q34_B_Part_5',\n                        'Q34_B_Part_6',\n                        'Q34_B_Part_7',\n                        'Q34_B_Part_8',\n                        'Q34_B_Part_9',\n                        'Q34_B_Part_10',\n                        'Q34_B_Part_11',\n                        'Q34_B_OTHER']\n\n\nq35a_list_of_columns = ['Q35_A_Part_1',\n                        'Q35_A_Part_2',\n                        'Q35_A_Part_3',\n                        'Q35_A_Part_4',\n                        'Q35_A_Part_5',\n                        'Q35_A_Part_6',\n                        'Q35_A_Part_7',\n                        'Q35_A_Part_8',\n                        'Q35_A_Part_9',\n                        'Q35_A_Part_10',\n                        'Q35_A_OTHER']\n\nq35b_list_of_columns = ['Q35_B_Part_1',\n                        'Q35_B_Part_2',\n                        'Q35_B_Part_3',\n                        'Q35_B_Part_4',\n                        'Q35_B_Part_5',\n                        'Q35_B_Part_6',\n                        'Q35_B_Part_7',\n                        'Q35_B_Part_8',\n                        'Q35_B_Part_9',\n                        'Q35_B_Part_10',\n                        'Q35_B_OTHER']\n\nq36_list_of_columns = ['Q36_Part_1',\n                       'Q36_Part_2',\n                       'Q36_Part_3',\n                       'Q36_Part_4',\n                       'Q36_Part_5',\n                       'Q36_Part_6',\n                       'Q36_Part_7',\n                       'Q36_Part_8',\n                       'Q36_Part_9',\n                       'Q36_OTHER']\n\nq37_list_of_columns = ['Q37_Part_1',\n                       'Q37_Part_2',\n                       'Q37_Part_3',\n                       'Q37_Part_4',\n                       'Q37_Part_5',\n                       'Q37_Part_6',\n                       'Q37_Part_7',\n                       'Q37_Part_8',\n                       'Q37_Part_9',\n                       'Q37_Part_10',\n                       'Q37_Part_11',\n                       'Q37_OTHER']\n\nq39_list_of_columns = ['Q39_Part_1',\n                       'Q39_Part_2',\n                       'Q39_Part_3',\n                       'Q39_Part_4',\n                       'Q39_Part_5',\n                       'Q39_Part_6',\n                       'Q39_Part_7',\n                       'Q39_Part_8',\n                       'Q39_Part_9',\n                       'Q39_Part_10',\n                       'Q39_Part_11',\n                       'Q39_OTHER']","da11d135":"answer_order = {\n    'Q25': [ \n            '$100,000 or more ($USD)', \n            '$10,000-$99,999',\n            '$1000-$9,999', \n            '$100-$999',\n            '$1-$99', \n            '$0 ($USD)', \n           ],\n    'Q21': [\n            '20+', \n            '15-19',\n            '10-14', \n            '5-9', \n            '3-4', \n            '1-2', \n            '0',         \n           ],\n    'Q6': [\n            '20+ years', \n            '10-20 years', \n            '5-10 years', \n            '3-5 years', \n            '1-2 years',\n            '< 1 years', \n            'I have never written code',\n          ]\n}","dda34059":"\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nsurvey_df = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv',low_memory=False)\nsurvey_df['num_algs']=survey_df[q17_list_of_columns].count(axis=1)\nresponses_df = survey_df[1:]","32d9b48b":"# helper functions\n\ndef get_counts_for_multicol_q(cols, df=responses_df):\n    return {df[df[col].notnull()][col].unique()[0]:\\\n            df[df[col].notnull()].shape[0] for col in cols}\n\ndef get_counts_for_singlecol_q(col, df=responses_df):\n    return df.groupby(col)[col].count().to_dict()\n\ndef bar_chart(ans_dict, ax=plt, comparison=None, labels=None, ans_order = None):\n    answers = ans_dict.keys()\n    if ans_order:\n        answers = [a for a in ans_order if a in ans_dict]\n    x_pos = np.arange(len(answers))\n    ax.yticks(x_pos, answers)\n\n    y = [ans_dict[a] for a in answers]  # list(ans_dict.values())\n    \n    width = 0.8\n\n    if comparison:\n        ax.xlabel('Fraction of respondents')\n        y = [y_i\/sum(y) for y_i in y]\n        comparison_y = [(comparison[k] if k in comparison else 0) for k in answers]\n        comparison_y = [y_i\/sum(comparison_y) for y_i in comparison_y]\n        width=0.4\n        b2 = ax.barh(x_pos-width, comparison_y, height=width)\n    \n    b1 = ax.barh(x_pos, y, height=width)\n    if labels:\n        ax.legend((b1,  b2), labels)\n    # return ax","2c6d3546":"all_applicable = responses_df[\n    (~responses_df['Q5'].isin({'Student', 'Currently not employed'}))  # Not Students or Unemployed\n    & (responses_df['Q25'] != '$0 ($USD)')\n]\nprint(f'limited responses to {len(all_applicable)} applicable respondents out of {len(responses_df)} total')","ae277d84":"automl_users = all_applicable[all_applicable['Q33_A_Part_6'].notnull()]\nprint(f'{len(automl_users)}\\\n applicable respondents ({len(automl_users)\/len(all_applicable)*100:.1f}%) said they have used full-pipeline AutoML tools.')","2bafda2d":"def compare_multicol(col_list, ax=plt):\n    bar_chart(\n        get_counts_for_multicol_q(col_list, all_applicable), \n        comparison = get_counts_for_multicol_q(col_list, automl_users),\n        labels = ('All', 'AutoML users')\n    )\n\ndef compare_singlecol(col, ax=plt):\n    bar_chart(\n        get_counts_for_singlecol_q(col, all_applicable),\n        comparison = get_counts_for_singlecol_q(col, automl_users),\n        labels = ('All', 'AutoML users'),\n        ans_order = answer_order[col] if col in answer_order else None\n    )","f091b799":"plt.title('Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services ... in the past 5 years?')\ncompare_singlecol('Q25')","6af68064":"plt.title('Does your current employer incorporate machine learning methods into their business?')\ncompare_singlecol('Q22')","e0b5e616":"plt.title('Approximately how many individuals are responsible for data science workloads at your place of business?')\ncompare_singlecol('Q21')","391c2d64":"\nplt.title('Select the title most similar to your current role (or most recent title if retired)')\ncompare_singlecol('Q5')\n","90aa85d0":"fig, ax = plt.subplots(2,1)\nax[0].hist(all_applicable['num_algs'], bins=12)\nax[0].set_title('All applicable respondents')\nax[1].hist(automl_users['num_algs'], bins=12)\nax[1].set_title('AutoML users')\nplt.suptitle('Total number of algorithms selected as being \"used on a regular basis\" (Q17)')\nplt.tight_layout()\nfig.subplots_adjust(top=0.8)\nplt.show()","a2cdbd7e":"plt.title('For how many years have you been writing code and\/or programming?')\ncompare_singlecol('Q6')\n\n","0a6f8491":"plt.title('Select any activities that make up an important part of your role at work: (Select all that apply)')\ncompare_multicol(q23_list_of_columns)\n","71cce688":"H2O.ai's [Driverless AI](https:\/\/docs.h2o.ai\/driverless-ai\/latest-stable\/docs\/userguide\/index.html) is currently one of the more popular AutoML solutions. The name \"Driverless\" certainly does seem to suggest a \"no need to worry about what is happening and how\" philosophy, which does not bode well in this context.\n\n[This blog post](https:\/\/www.h2o.ai\/blog\/kaggle-grand-masters-recipes-production-ready-clicks\/) describes the parts of ML that Driverless AI seeks to automate. In particular, it says:\n\n> we are trying to mimic what top data science teams would do when they need to develop a new machine learning pipeline\n\n---\n\n> We call this part of Driverless AI \u201cKaggle Grand Masters in a Box\u201d. It is essentially the best data science practices, tricks and **creative feature engineering** of our Kaggle Grand Masters translated into an artificial intelligence (AI) platform.\n\n(again, emphasis mine)\n\nThe idea of automating the **creative** process of \"top data science teams\" - of putting Grand Masters \"in a box\" - necessarily implies that the main contibutions of these data scientists are automatable. That replicating the \"recipes\" that top-level Kaggle competitors tend to use, and then seeing which ones stick, is sufficient for capturing their expertise in an automated system. \n\nThis, again, does not bode well for the idea of putting more rather than less emphasis on the importance of human aspects of ML. Although the documentation and marketing of Driverless AI do not claim to automate aspects like data collection or selecting a metric for optimization, they do tend to avoid placing any emphasis on these aspects altogether. The documentation *does* come dangerously close to making the seductive claim that users can leave creative and subjective parts of feature engineering to an automated system. A system that, no matter how clever it is, cannot have any domain knowledge when it makes these decisions.   \n\n\nA non-expert drawn in by the promise of democratized ML may well have some trouble noticing the distinction between what Driverless AI does or does not claim to do. So it is perhaps good that, at least in [its current documentation](http:\/\/docs.h2o.ai\/driverless-ai\/latest-stable\/docs\/userguide\/why_dai.html), Driverless AI doesn't actually try to sell itself as a \"democratization\" product - in fact, it seems directly geared toward empowering existing experts and making their job easier:\n\n> With not enough data scientists to fill the increasing demand for data-driven business processes, H2O.ai offers Driverless AI, which automates several time consuming aspects of a typical data science workflow, including data visualization, feature engineering, predictive modeling, and model explanation.\n\n---\n\n> Driverless AI empowers data scientists or data analysts to work on projects faster and more efficiently by using automation and state-of-the-art computing power to accomplish tasks in just minutes or hours instead of the weeks or months that it can take humans.\n","c1683410":"First, let's try to validate the idea that AutoML might be prohibitively expensive for personal use (or even smaller-scale business use):","e6d86b13":"AutoML users are much more likely to be Data Scientists or ML Engineers (and slightly more likely to be Research Scientists) - professionals who specialize in DS and ML, rather than generalist engineers trying to apply ML to their problems.\n\nWe can also verify the hypothesis that AutoML users are more likely to be ML specialists by analyzing how many different ML algorithms people in either group use on a regular basis:","35f4b316":"AutoML users also tend to skew toward being more experienced programmers - even though one of the major selling points of AutoML tools is the ability to \"do Machine Learning\" without writing any code.","feaf73d1":"# Data","2ad6d7da":"Perhaps most notably, AutoML users are less likely to be responsible for \"influenc[ing] product or business decisions\". Rather than focusing on **the application of ML** to business needs, they tend to have roles which focus on **ML directly** (advancing the state of the art of ML, improving exsting ML models, building and running ML services).  \n\nI find this notable because, again, it seems to go against AutoML's goal of enabling many different types of people to apply ML to their business needs. Rather, at least for now, it seems the primary users of AutoML are ML experts trying to enhance or build on their already existing expertise.","6d67ca43":"So, companies which employ people with AutoML experience tend to have **bigger, better-funded, more mature ML and Data Science teams**. \n\nBut what about the AutoML users themselves? Who are they, and how do they differ from the average population of Kagglers?","96baf556":"<p style=\"\n    text-align: center;\n\"><img src=\"https:\/\/imgs.xkcd.com\/comics\/machine_learning.png\" alt=\"xkcd: Machine Learning\">\n<a href=\"https:\/\/xkcd.com\/1838\/\">xkcd: Machine Learning<\/a><\/p>\n\nThe evidence suggests that so far, AutoML is being used more by experts to help make their job easier and faster than by non-experts hoping to democratize ML. There could be several reasons for this apparent disconnect with the motivation behind AutoML. Part of this may be because AutoML is still in the \"early adopter\" phase, and early adopters tend to be experts. Another (related) reason may be that using these systems still requires expertise: even in systems which require no programming, the user is expected to make decisions like which columns to drop and how to balance performance vs. speed before they can even get started on the ML part. \n\nWhether this apparent disconnect is bad or good - whether it's a good idea to enable \"hundreds of thousands of developers\" to use ML at this stage in the evolution of ML as a field - is a separate question. And I think the answer depends on how ML is used now, and how that will change with the advent of AutoML.","8daf5694":"Certain aspects of Machine Learning will be impossible to automate until we invent Skynet. These are human, creative aspects which require the developer to understand the context of the problem being solved, such as:\n\n- Collecting the right data that will enable you to solve your problem; ensuring your input data contains the information you want the system to learn\n- Choosing a target metric which actually represents the problem you're trying to solve, and does not fall prey to the [steetlight effect](https:\/\/en.wikipedia.org\/wiki\/Streetlight_effect) or [Goodhart's law](https:\/\/en.wikipedia.org\/wiki\/Goodhart%27s_law)\n- Incorporating domain knowledge into feature engineering and model selection","a2044794":"# Is that good?","e6e7adc7":"# Analysis","2335fe1d":"Due to the nature of the survey, I limited the set of respondents using two conditions:\n\n- Only consider those respondents who spent more than $0 on cloud services\n- Only consider those respondents who are not students or unemployed\n\nI needed to do this because the questions I'm interested in - whether you use AutoML, and how you use ML at work - were only asked of people who have spent money on cloud services and who did not say they were a student or unemployed, respectively.\n\nOther respondents may also have been able to provide relevant data. for example, it's entirely possible that a PhD student with industry experience has never spent a dollar on cloud services, but has nevertheless explored the possibility of auto-sklearn or even played around with the free trial version of Cloud AutoML. But we simply don't have that data.","5936186c":"Automatic ML systems seek to \"democratize\" Machine Learning by making it more accessible to non-experts. For example, [Google Cloud AutoML](https:\/\/cloud.google.com\/automl\/)'s main selling point is that:\n\n> Cloud AutoML enables developers with limited machine learning expertise to train high-quality models specific to their business needs. \n\nI would like to explore whether Automatic ML services - in particular, services that automate the entire ML pipeline - seem to be achieving this goal. To do this, I want to compare the subset of the Kaggle community who uses AutoML to the general population. \nHow do AutoML users differ from Kaggle users at large in terms of:\n\n- The amount of experience they tend to have?\n- The ways they use ML in the workplace?\n\n\n\nI'm limiting the use of ML to the workplace, rather than personal and hobby use, for two simple reasons:\n\n1. That is the only data available in the Kaggle Survey dataset.\n2. AutoML products are currently prohibitively expensive for personal use, and they tend to be explicitly targeted at businesses seeking to use ML for making business decisions.","4e248835":"It's interesting that only a very small percentage of Kaggle users who *could* use AutoML are actually using it. This could indicate that AutoML is still in its nascency, or it could mean that the intesection of people who are interested in AutoML and those who use Kaggle is small.\n\nIn May 2018, the CEO of Google stated in his [announcement of Cloud AutoML](https:\/\/blog.google\/technology\/ai\/making-ai-work-for-everyone\/):\n\n> We hope AutoML will take an ability that a few PhDs have today and will make it possible **in three to five years** for hundreds of thousands of developers to design new neural nets for their particular needs. \n\n(emphasis mine)\n\nConsidering that this was about 2.5 years ago, it appears some part of that hope is not quite on track. AutoML in general, and Cloud AutoML in particular, is **not yet** being adopted widely by large numbers of developers who were previously unable to break into ML.\n\nNevertheless, it's interesting to see who **is** currently adopting full-pipeline AutoML.","5f0c2318":"\nSo, for at least one AutoML system, the trends we see in the current AutoML userbase are evidence of the product working as intended. This driverless system should be operated by an experienced driver who is paying attention. [This is probably fine.](https:\/\/cal.streetsblog.org\/2020\/06\/03\/surprise-even-partial-automation-is-encouraging-drivers-not-to-pay-attention\/)\n\n\nThen again, perhaps none of it matters. After all, humans are very adept at making these same mistakes in optimization problems that *don't* involve ML. From startups focusing on \"day-one retention\" instead of whether their app is actually serving the intended purpose, to individuals becoming obsessed with climbing leaderboards or corporate ladders - to err in the human aspects of decision-making is human.","8c362ca6":"Indeed, AutoML users tend to skew toward spending more money on ML than the general population. This demonstrates that companies who tend to be able to afford AutoML are those that already have a well-funded ML department or program. \n\nMoreover, as we can see from the next two graphs, people who use AutoML are more likely to belong to organizations with mature, well-established ML methods, with larger dedicated data science teams:","add2af66":"We can expect people with more ML expertise to be able to use many different algorithms, and choose algorithms that are most suitable for a given application. Non-experts, on the other hand, may learn one or two algorithms and apply them to everything (the [Maslow's Hammer](https:\/\/en.wikipedia.org\/wiki\/Law_of_the_instrument) phenomenon).\n\nIndeed, AutoML users do tend to skew toward using more algorithms than the general population. In fact, the distribution for AutoML users is slightly bimodal, with a second spike at regularly using 10 algorithms (a.k.a. \"all of the above\"). Meanwhile, the distribution for the general population has a huge spike at 0 algorithms. In other words, a lot of Kagglers who have spent at least some money on ML-related cloud services nevertheless report not using any of the common ML algorithms.","ee6b9a62":"# Who is using Automatic Machine Learning pipelines?","5da1d74b":"But these human aspects of ML can easily be neglected, even by experts. In the wild, it is easy to find examples of:\n\n- Optimizing for something that's easy to quantify instead of the thing you're actually trying to improve\n- Making initial assumptions (e.g. of linearity) which cripple your advanced algorithm and make it entirely unnecessary\n- Conversely, accepting hyperparameters suggested by a grid search even though they invalidate your initial assumptions \n- Focusing on specific successs metrics (e.g. AUC\/ROC) because they are familiar to you, regardless of how applicable they are to the problem at hand.\n- Trying to extract information that's simply not present in the underlying data (and almost inevitably falling into the overfitting\/p-hacking trap as you try to get at least *some* result)\n- Trying to naively apply ML to extrapolation problems, where the patterns that were common in the past are not likely to be applicable to the future\n\nWould \"democratizing\" ML make these kinds of mistakes more or less likely to occur? \n\nWould AutoML open doors for people who may have great ideas about how to address these human aspects, but haven't had a chance to try until now? Or would it encourage many more people to take a \"black box\" approach to ML, by making it easy to do well on the standard metrics without having to reason about whether a solution makes sense from the \"human aspects\" perspective? "}}