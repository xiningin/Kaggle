{"cell_type":{"c10442eb":"code","2fdb906f":"code","31b8cecc":"code","cb79fa5c":"code","a81e028c":"code","98933e22":"code","21938430":"code","6b8bad03":"code","99566685":"code","c0ac535a":"code","2776cdfa":"code","98461181":"code","f7237eb6":"code","b3588cb6":"code","b7e8b0e0":"code","7f676b93":"code","66736bd5":"code","ea1bb1ac":"code","7987db26":"code","242e3cd5":"code","f768262d":"code","2ec9b88b":"code","8874e10c":"code","a3757bd1":"markdown","5407a9b4":"markdown","06b8672a":"markdown","bb61e861":"markdown","66389356":"markdown","61a0bc98":"markdown","db57ec37":"markdown"},"source":{"c10442eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2fdb906f":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\ntf.random.set_seed(0)\ntf.keras.backend.clear_session","31b8cecc":"path = '\/kaggle\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\/'\ntdat = pd.read_csv(path+'icml_face_data.csv')\ntdat.sample(5)","cb79fa5c":"emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}","a81e028c":"tdat.info()","98933e22":"dat = tdat.copy()\ndat.drop_duplicates(inplace=True)\ndat.info()","21938430":"dat[' Usage'].unique()","6b8bad03":"fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20,5))\nsns.countplot(data = dat[dat[' Usage']=='Training'], x='emotion', ax=ax1).set_title('Training')\nax1.set_xticklabels(emotions.values())\nsns.countplot(data = dat[dat[' Usage']=='PublicTest'], x='emotion', ax=ax2).set_title('Testing')\nax2.set_xticklabels(emotions.values())\nsns.countplot(data = dat[dat[' Usage']=='PrivateTest'], x='emotion', ax=ax3).set_title('Validation')\nax3.set_xticklabels(emotions.values())","99566685":"def prepare_data(data):\n    \"\"\" Prepare data for modeling \n        input: data frame with labels und pixel data\n        output: image and label array \"\"\"\n    \n    image_array = np.zeros(shape=(len(data), 48, 48))\n    image_label = np.array(list(map(int, data['emotion'])))\n    \n    for i, row in enumerate(data.index):\n        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n        image = np.reshape(image, (48, 48))\n        image_array[i] = image\n        \n    return image_array, image_label\n\n  \ndef sample_plot(x,y=None):\n    #x, y are numpy arrays\n    n = 20\n    samples = random.sample(range(x.shape[0]),n)\n    \n    fig, axs = plt.subplots(2,10, figsize=(25,5), sharex=True, sharey=True)\n    ax = axs.ravel()\n    for i in range(n):\n        ax[i].imshow(x[samples[i],:,:], cmap=plt.get_cmap('gray'))\n        ax[i].set_xticks([])\n        ax[i].set_yticks([])\n        if y is not None:\n            ax[i].set_title(emotions[y[samples[i]]])\n              ","c0ac535a":"from imblearn.under_sampling import RandomUnderSampler, TomekLinks\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.pipeline import Pipeline\n\nfrom collections import Counter","2776cdfa":"train_image_array1, train_image_label1 = prepare_data(dat[dat[' Usage']=='Training'])\nval_image_array, val_image_label = prepare_data(dat[dat[' Usage']=='PrivateTest'])\ntest_image_array, test_image_label = prepare_data(dat[dat[' Usage']=='PublicTest'])","98461181":"# pp = Pipeline([('rus',RandomUnderSampler(random_state=0, replacement=False))])\npp = Pipeline([('tk',TomekLinks()),('ros',RandomOverSampler(random_state=0))])\ntrain_image_array, train_image_label = pp.fit_resample(train_image_array1.reshape(train_image_array1.shape[0],48*48), train_image_label1)\nprint(Counter(train_image_label))\ntrain_image_array = train_image_array.reshape(train_image_array.shape[0], 48, 48)","f7237eb6":"train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\ntrain_images = train_images.astype('float32')\nval_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\nval_images = val_images.astype('float32')\ntest_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\ntest_images = test_images.astype('float32')\n\ntrain_labels = tf.keras.utils.to_categorical(train_image_label)\nval_labels = tf.keras.utils.to_categorical(val_image_label)\ntest_labels = tf.keras.utils.to_categorical(test_image_label)","b3588cb6":"sample_plot(train_image_array, train_image_label)","b7e8b0e0":"sample_plot(val_image_array, val_image_label)","7f676b93":"sample_plot(test_image_array, test_image_label)","66736bd5":"wt = dat[dat[' Usage']==\"Training\"].groupby('emotion').agg('count')\n# class_weights = \nwt['fraction'] = wt[' pixels']\/np.sum(wt[' pixels'])\nclass_weights = dict(zip(range(7), wt.fraction))","ea1bb1ac":"model = tf.keras.models.Sequential([\n    tf.keras.layers.experimental.preprocessing.Rescaling(scale=1.\/255, input_shape=(48,48,1)),\n    tf.keras.layers.experimental.preprocessing.RandomContrast(factor = 0.2),\n    tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n    \n    tf.keras.layers.Conv2D(16,3,activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(16,5,activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(16,3,activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.MaxPooling2D(2),\n    \n    tf.keras.layers.Conv2D(16,3,activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(16,3,activation='relu',padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.4),\n    \n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(len(emotions), activation='softmax'),    \n])","7987db26":"from sklearn.metrics import f1_score\n\ndef eager_f1score(y_true, y_pred):\n    return f1_score(y_true=np.argmax(np.array(y_true), axis=1), y_pred=np.argmax(np.array(y_pred),axis=1), average='macro')\n\n\n# eager_f1score(test_image_label, test_pred)","242e3cd5":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', \n              metrics=['accuracy',eager_f1score], run_eagerly=True)\n\nearlystop = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=1e-4, restore_best_weights=True)\nlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=1e-7)","f768262d":"hist = model.fit(train_images, train_labels,\n                    validation_data=(val_images, val_labels),\n                    epochs=50,\n#                     class_weight=class_weights,\n                    batch_size=128,\n                    callbacks=[earlystop, lr])","2ec9b88b":"for key in hist.history.keys():\n    plt.plot(hist.history[key], label=key)\nplt.legend()","8874e10c":"model.evaluate(test_images, test_labels)\ntest_pred = model.predict(test_images)\nconfusion_matrix(y_true=test_image_label, y_pred=np.argmax(test_pred,axis=1))","a3757bd1":"# Helper functions","5407a9b4":"# Load data","06b8672a":"# Prepare data for CNN, accounting for class imbalance","bb61e861":"# CNN","66389356":"# Sample and visualize images from train\/valid\/test data sets","61a0bc98":"# Load libraries","db57ec37":"# Preprocess data"}}