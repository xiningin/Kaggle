{"cell_type":{"acf58102":"code","9b30b9f5":"code","66448b2f":"code","5c8d670c":"code","8b0b782b":"code","b7d38997":"code","f64a2194":"code","b1c73373":"code","e0f8e6ab":"code","c5769856":"code","f73d1bee":"code","7032cf98":"code","fc1286fe":"code","12eb27a7":"code","263736b8":"code","8791db2e":"code","4a91d406":"code","c36229b8":"code","9425dc7b":"code","d0e73db9":"code","e281457e":"code","8b399604":"code","6a0bf35a":"code","a3785891":"code","3c3b0185":"code","9841c5a3":"code","56ae6a27":"code","9f2b8887":"code","30f9e011":"code","74bf023d":"code","e50b01fd":"markdown","f0fe5030":"markdown","3fa2addb":"markdown","abea4605":"markdown","192f971c":"markdown","bf4a1fa9":"markdown","6666a55e":"markdown","3d070593":"markdown"},"source":{"acf58102":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9b30b9f5":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission_df = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","66448b2f":"train.head()","5c8d670c":"test.head()","8b0b782b":"# first check how many null values we are dealing with\nprint('train:\\n', train.isnull().sum())\nprint()\nprint('test:\\n', test.isnull().sum())","b7d38997":"# Embarked\n# Only 2 null values in train data so we can replace  the null with most common value\n\ntrain['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode())","f64a2194":"# Lets combine train and test data before applying the transformations\n\ndata = pd.concat([train.assign(ind='train'), test.assign(ind='test')], ignore_index=True)","b1c73373":"print(train.Cabin.unique())","e0f8e6ab":"def extract_cabin(cabin):\n    cabin = str(cabin)\n    if cabin=='nan':\n        return 'M'\n    else:\n        return cabin[0]\n\ndata['Deck'] = data['Cabin'].apply(extract_cabin)","c5769856":"sns.barplot(x=data['Deck'],y=data['Survived'])","f73d1bee":"def group_deck(deck):\n    if deck in ['A','B','C','T']:\n        return 'ABC'\n    elif deck in ['D','E']:\n        return 'DE'\n    elif deck in ['F','G']:\n        return 'FG'\n    else:\n        return 'M'\n\ndata['Deck'] = data['Deck'].apply(group_deck)","7032cf98":"sns.barplot(x=data['Deck'],y=data['Survived'])","fc1286fe":"data['Age'] = data.groupby(['Sex','Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n\ndata['Age'] = data['Age'].astype(int)\ndata.loc[ data['Age'] <= 15, 'Age'] = 0\ndata.loc[(data['Age'] > 15) & (data['Age'] <= 30), 'Age'] = 1\ndata.loc[(data['Age'] > 30) & (data['Age'] <= 45), 'Age'] = 2\ndata.loc[(data['Age'] > 45) & (data['Age'] <= 60), 'Age'] = 3\ndata.loc[ data['Age'] > 60, 'Age'] = 4","12eb27a7":"data.describe(include='all')","263736b8":"# Making bins according to distribution\ndata['Fare_bins'] = pd.cut(data['Fare'], bins=[0.0, 7.895, 14.45, 31.275, 512.329], labels=[0,1,2,3])\ndata['Fare_bins'] = data['Fare_bins'].fillna(0)\ndata['Fare_bins'] = data['Fare_bins'].astype(int)","8791db2e":"data['Family_size'] = data['SibSp']+data['Parch']","4a91d406":"data.head()","c36229b8":"final_data = data.drop(['PassengerId','Fare','Ticket','Cabin','Name','SibSp', 'Parch'], axis=1)","9425dc7b":"test_data, train_data= final_data[final_data[\"ind\"].eq(\"test\")], final_data[final_data[\"ind\"].eq(\"train\")]","d0e73db9":"test_data = test_data.drop(['ind'], axis=1)\ntrain_data = train_data.drop(['ind'], axis=1)","e281457e":"train_data.head()","8b399604":"# split train data into dependent and independent data\nX = train_data.drop(['Survived'], axis=1)\ny = train_data['Survived']","6a0bf35a":"# Convert Categorical data into numerical data\ntraindf_X = pd.get_dummies(X, columns=['Sex','Embarked','Fare_bins','Deck'],\n                          prefix=['Sex','Embarked','Fare_type','Deck'])\n\ntestdf = pd.get_dummies(test_data, columns=['Sex','Embarked','Fare_bins','Deck'],\n                          prefix=['Sex','Embarked','Fare_type','Deck']).drop(['Survived'], axis=1)","a3785891":"from sklearn import metrics\n\n# lets first define a function that'll help us know how good\/bad our model is doing\ndef get_scores(y_preds,y):\n    return {\n        'Accuracy':metrics.accuracy_score(y_preds,y),\n        'Precision':metrics.precision_score(y_preds,y),\n        'Recall':metrics.recall_score(y_preds,y),\n        'F1':metrics.f1_score(y_preds,y),\n        'ROC_AUC': metrics.roc_auc_score(y_preds,y)\n    }","3c3b0185":"# split data into train and val\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(traindf_X, y, test_size=0.3, random_state=42)","9841c5a3":"from sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier","56ae6a27":"def train_model(model):\n    model_ = model\n    model_.fit(X_train, y_train)\n    y_pred = model_.predict(X_val)\n    return get_scores(y_pred, y_val)","9f2b8887":"model_list = [\n             DecisionTreeClassifier(random_state=42), \n            RandomForestClassifier(random_state=42),\n            XGBClassifier(random_state=42), \n            LGBMClassifier(random_state=42, is_unbalance=True), \n            LogisticRegression(random_state=42),\n            svm.SVC(random_state=42),\n            AdaBoostClassifier(random_state=42),\n            KNeighborsClassifier(),\n            GaussianNB()\n]\nmodel_names = ['Decision Tree', 'Random Forest', 'XGB Classifier','LGBM Classifier','Logistic Regression','SVC','AdaBoost ', 'KNN','GaussianNB']","30f9e011":"scores = pd.DataFrame(columns=['Name','Accuracy','Precision','Recall','F1','ROC_AUC'])\n\nfor i in range(len(model_list)):\n    score = train_model(model_list[i])\n    scores.loc[i] = [model_names[i]]+list(score.values())","74bf023d":"figure, axis = plt.subplots(2, 3)\nfigure.set_figheight(15)\nfigure.set_figwidth(30)\n\nfor i in range(2):\n    for j in range(3):\n        axis[i,j].set_xlim([.5,.9])\n\naxis[0, 0].barh(scores['Name'],scores['Accuracy'],height=.5)\naxis[0, 0].set_title(\"Accuracy Score\")\n  \naxis[0, 1].barh(scores['Name'],scores['Precision'],height=.5)\naxis[0, 1].set_title(\"Precision\")\n\naxis[1, 0].barh(scores['Name'],scores['Recall'],height=.5)\naxis[1, 0].set_title(\"Recall\")\n\naxis[1, 2].barh(scores['Name'],scores['F1'],height=.5)\naxis[1, 2].set_title(\"F1\")\n\naxis[0, 2].barh(scores['Name'],scores['ROC_AUC'],height=.5)\naxis[0, 2].set_title('ROC_AUC')\n\naxis[1, 1].set_visible(False)\n\nplt.show()","e50b01fd":"# Model Selection","f0fe5030":"* Age","3fa2addb":"* Cabin","abea4605":"# Feature Engineering","192f971c":"* SibSp and Parch","bf4a1fa9":"# Data Analysis","6666a55e":"* Fare","3d070593":"* Embarked"}}