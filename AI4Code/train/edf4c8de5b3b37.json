{"cell_type":{"9db30945":"code","9ac29a33":"code","228a2c5b":"code","3d23af10":"code","2ede4032":"code","ed083ad9":"code","804bf620":"code","09a0e5d1":"code","482b58f2":"code","c536e93a":"code","deeb7341":"code","2295a5cc":"code","d5549228":"code","17ea464c":"code","7037cb3e":"code","3b0507a3":"code","0f77c421":"code","b51b7a63":"code","34d11962":"code","0da5538f":"code","10760991":"code","e94f1a59":"code","dd40cee5":"code","f92c5898":"code","c63a1a61":"code","31a3544e":"code","67df0de1":"code","c8db1766":"code","a2cb4fcf":"code","13192579":"code","6f022c7d":"code","111ca149":"code","a6fce346":"code","8d2fb98f":"code","40df0bba":"code","48fd4951":"code","2d11438a":"code","35c60aa4":"code","ffdfdc8e":"code","39284e15":"code","0283861b":"code","52657cdb":"code","ea578528":"code","d25a7049":"code","ba7f1c3e":"code","5eeb1420":"code","1a2b9cc1":"code","5a64125b":"code","c564edb5":"code","91da2c65":"code","7194f5a8":"code","fbef7d6d":"code","55bea00a":"code","e76149a8":"code","79c4f187":"code","2b5ea621":"code","b767abe0":"code","9b64868c":"code","6847584f":"code","dbd3da13":"code","e9c3e598":"code","6f5b9e86":"code","908210b5":"code","7e337c21":"markdown","43355304":"markdown","1ddf5d82":"markdown","b4eacb24":"markdown","d126b6b4":"markdown","ff6495af":"markdown","1b58ec15":"markdown","1ff9fd6d":"markdown","31e57f99":"markdown","cc37ee83":"markdown","0aa76ec8":"markdown","27d96a93":"markdown","a88854dd":"markdown","eb86222a":"markdown","8fb28b12":"markdown","f980e33a":"markdown","0bebfa6d":"markdown","28ff484e":"markdown","d31cbb61":"markdown","9ef88098":"markdown","2ebf72ce":"markdown","2b6e6990":"markdown","fc88291b":"markdown","9c742f8b":"markdown","f369c461":"markdown","24c79bd0":"markdown","0fcf4840":"markdown","406124d3":"markdown","b8ec3e51":"markdown","8a2756f7":"markdown","7e1b9216":"markdown","3ecfe5de":"markdown"},"source":{"9db30945":"# Preparing essentials environment\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn import preprocessing\nfrom itertools import cycle\npd.options.mode.chained_assignment = None","9ac29a33":"# Reading CSV data\ndf = pd.read_csv('..\/input\/give-me-some-credit-dataset\/cs-training.csv')","228a2c5b":"# Checking the data types and column names\ndf.dtypes","3d23af10":"# Checking the data top 15 rows \ndf.head(15)","2ede4032":"# Checking basic stats\nrs = round(df.describe(), 2)\nrs","ed083ad9":"# Renaming the first column to \"id\"\ndf.rename(\n    columns = {'Unnamed: 0':'id'},\n    inplace = True\n)","804bf620":"# Counting empty cells in each column\ndf.isnull().sum()","09a0e5d1":"# Checking the issues with RevolvingUtilizationOfUnsecuredLines\ndf[df[\"RevolvingUtilizationOfUnsecuredLines\"] > 2].sample(n = 30)","482b58f2":"# There seems to be no clear source of the issue (i.e. no connection with other columns) for the wrong values\n# Checking how many RevolvingUtilizationOfUnsecuredLines values are over 2\ndf[\"id\"][df[\"RevolvingUtilizationOfUnsecuredLines\"] >= 2].count()","c536e93a":"# Checking RevolvingUtilizationOfUnsecuredLines for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\na = sns.boxplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\", \n    x = \"SeriousDlqin2yrs\",\n    data = df\n)\na.set(\n    ylim = (0, 2)\n);","deeb7341":"df.sort_values(by = [\"age\"]).head(5)","2295a5cc":"df.sort_values(by = [\"age\"], ascending = False).head(5)","d5549228":"df['NumberOfTime30-59DaysPastDueNotWorse'].value_counts().sort_index()","17ea464c":"df['NumberOfTime60-89DaysPastDueNotWorse'].value_counts().sort_index()","7037cb3e":"df['NumberOfTimes90DaysLate'].value_counts().sort_index()","3b0507a3":"# Checking the data when MonthlyIncome is null \nrs = round(df[df[\"MonthlyIncome\"].isnull()].describe(), 2)\nrs","0f77c421":"# Seems like when MonthlyIncome is null, DebtRatio is 100% wrong (i.e. way over 1, which should be it's max value by definition)...\nplt.figure(figsize = (16,5))\n\na = sns.boxplot(\n    y = \"DebtRatio\",\n    x = pd.qcut((df[df[\"MonthlyIncome\"].isnull()][\"age\"]), 15),\n    data = df[df[\"MonthlyIncome\"].isnull()]\n)\n\na.set(\n    ylim = (0, 9000)\n)\n\nplt.setp(\n    a.get_xticklabels(), \n    rotation = 55\n);","b51b7a63":"# ... and when MonthlyIncome is not null, DebtRatio is behaving as expected and could be considered as \"correct\"\nplt.figure(figsize = (16,10))\n\na = sns.boxplot(\n    y = \"DebtRatio\",\n    x = pd.qcut((df[df[\"MonthlyIncome\"] > 0][\"age\"]), 15),\n    data = df[df[\"MonthlyIncome\"] > 0]\n)\n\na.set(\n    ylim = (0, 10)\n)\n\nplt.setp(\n    a.get_xticklabels(), \n    rotation = 55\n);","34d11962":"df[df[\"MonthlyIncome\"] > 0]['DebtRatio'].value_counts().sort_index()","0da5538f":"df[df[\"MonthlyIncome\"] > 0]['DebtRatio'].describe()","10760991":"df[df[\"MonthlyIncome\"] > 0]['MonthlyIncome'].quantile(.02)","e94f1a59":"df[df[\"MonthlyIncome\"] > 0]['MonthlyIncome'].quantile(.98)","dd40cee5":"# Checking NumberOfOpenCreditLinesAndLoans for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\n\na = sns.boxplot(\n    y = \"NumberOfOpenCreditLinesAndLoans\",\n    x =\"SeriousDlqin2yrs\",  \n    data = df\n);","f92c5898":"# Checking NumberRealEstateLoansOrLines for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\n\na = sns.boxplot(\n    y = \"NumberRealEstateLoansOrLines\",\n    x =\"SeriousDlqin2yrs\",  \n    data = df\n);","c63a1a61":"# Checking NumberOfDependents for outliers (Q1 - 1.5*IQR, Q3 + 1.5*IQR)\nplt.figure(figsize = (4,8))\n\na = sns.boxplot(\n    y = \"NumberOfDependents\",\n    x =\"SeriousDlqin2yrs\",  \n    data = df\n);","31a3544e":"# Creating a clean dataset for EDA according to the Actions memo\ndf_clean = df[\n    df['RevolvingUtilizationOfUnsecuredLines'].notnull() & \n    (df['RevolvingUtilizationOfUnsecuredLines'] <= 1.9) &\n    (df['age'] > 0) &\n    (df['DebtRatio'] < 50) &\n    (df['MonthlyIncome'] > 0) &\n    (df['MonthlyIncome'].notnull())\n]\n\ndf_clean[\"RevolvingUtilizationOfUnsecuredLines\"] = df_clean[\"RevolvingUtilizationOfUnsecuredLines\"].clip(upper = 1.2)\ndf_clean[\"age\"] = df_clean[\"age\"].clip(upper = 95)\ndf_clean[\"NumberOfTime30-59DaysPastDueNotWorse\"] = df_clean[\"NumberOfTime30-59DaysPastDueNotWorse\"].clip(upper = 5)\ndf_clean[\"NumberOfTime60-89DaysPastDueNotWorse\"] = df_clean[\"NumberOfTime60-89DaysPastDueNotWorse\"].clip(upper = 5)\ndf_clean[\"NumberOfTimes90DaysLate\"] = df_clean[\"NumberOfTimes90DaysLate\"].clip(upper = 6)\ndf_clean[\"MonthlyIncome\"] = df_clean[\"MonthlyIncome\"].clip(upper = 20000, lower = 800)\ndf_clean[\"DebtRatio\"] = df_clean[\"DebtRatio\"].clip(upper = 1.2)\ndf_clean[\"NumberOfOpenCreditLinesAndLoans\"] = df_clean[\"NumberOfOpenCreditLinesAndLoans\"].clip(upper = 20)\ndf_clean[\"NumberRealEstateLoansOrLines\"] = df_clean[\"NumberRealEstateLoansOrLines\"].clip(upper = 5)\ndf_clean[\"NumberOfDependents\"] = df_clean[\"NumberOfDependents\"].clip(upper = 5)\ndf_clean[\"NumberOfDependents\"].fillna(0, inplace = True)","67df0de1":"# Adding a custom predictor\ndf_clean[\"Custom1\"] = df_clean[\"NumberOfTime30-59DaysPastDueNotWorse\"] + df_clean[\"NumberOfTime60-89DaysPastDueNotWorse\"] * 1.6 + df_clean[\"NumberOfTimes90DaysLate\"] * 2","c8db1766":"# Checking the clean dataset \nrs = round(df_clean.describe(), 2)\nrs","a2cb4fcf":"# Checking the distribution of the target variable SeriousDlqin2yrs\nsns.countplot(\n    x = \"SeriousDlqin2yrs\",\n    data = df_clean\n);\n# Seems like Accuracy is not a good metric for ML models","13192579":"# Plotting the pair grid to better understand connections between columns \ngrid = sns.pairplot(\n    df_clean[[\"SeriousDlqin2yrs\",\n              \"RevolvingUtilizationOfUnsecuredLines\",\n              \"age\",\n              \"DebtRatio\",\n              \"MonthlyIncome\",\n              \"NumberOfOpenCreditLinesAndLoans\",\n              \"NumberRealEstateLoansOrLines\",\n              \"NumberOfDependents\"\n             ]].sample(n = 3000),\n    hue = \"SeriousDlqin2yrs\",\n    height = 3,\n    kind = \"reg\",\n    plot_kws = {'scatter_kws': {'alpha': 0}}\n)\ngrid = grid.map_upper(plt.scatter)\ngrid = grid.map_lower(\n    sns.kdeplot, \n    shade = True,\n    shade_lowest = False,\n    alpha = 0.6,\n    n_levels = 5\n);","6f022c7d":"# Checking most highly correlated variables\ndef highestcorrelatedpairs (df, top_num):\n    correl_matrix = df.corr()\n    correl_matrix *=np.tri(*correl_matrix.values.shape, k = -1).T\n    correl_matrix = correl_matrix.stack()\n    correl_matrix = correl_matrix.reindex(correl_matrix.abs().sort_values(ascending = False).index).reset_index()\n    correl_matrix.columns = [\n        \"Variable 1\",\n        \"Variable 2\",\n        \"Correlation\"\n    ]\n    return correl_matrix.head(top_num)\n\nhighestcorrelatedpairs(df_clean, 16)","111ca149":"# Preparations for ECDF plot \ndef ecdf_plot(df, col, split):\n    x0 = np.sort(df[(df[split] == 0) | (df[split] == -1)][col])\n    x1 = np.sort(df[df[split] == 1][col])\n    y0 = np.arange(1, len(x0)+1) \/ len(x0)\n    y1 = np.arange(1, len(x1)+1) \/ len(x1)\n    _ = plt.plot(x0, y0, marker = '.', linestyle = 'none')\n    _ = plt.plot(x1, y1, marker = '.', linestyle = 'none')\n    plt.margins(0.04) \n    plt.legend([split + \": 0\", split + \": 1\"])\n    plt.xlabel(col, fontsize = 12)\n    plt.grid()\n    plt.show()","a6fce346":"# 1st variable for ECDF: Age\nplt.figure(figsize = (8.5,6))\necdf_plot(df_clean, \"age\", \"SeriousDlqin2yrs\")","8d2fb98f":"# 2nd pair for ECDF: RevolvingUtilizationOfUnsecuredLines\nplt.figure(figsize = (8.5,6))\necdf_plot(df_clean, \"RevolvingUtilizationOfUnsecuredLines\", \"SeriousDlqin2yrs\")","40df0bba":"# Defining ageRange for easier visualization\nageRange = pd.interval_range(\n    start = 20, \n    freq = 10, \n    end = 90\n)\ndf_clean['ageRange'] = pd.cut(df_clean['age'], bins = ageRange)","48fd4951":"# Exploring the connections between RevolvingUtilizationOfUnsecuredLines and age\nplt.figure(figsize = (16,8))\nsns.violinplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"ageRange\",\n    data = df_clean\n);","2d11438a":"# Explorning the RevolvingUtilizationOfUnsecuredLines by age groups for both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.boxplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"ageRange\",\n    hue =\"SeriousDlqin2yrs\",  \n    data = df_clean\n);","35c60aa4":"# Explorning the DebtRatio by age groups for both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.boxplot(\n    y = \"DebtRatio\",\n    x = \"ageRange\",\n    hue =\"SeriousDlqin2yrs\",  \n    data = df_clean\n);","ffdfdc8e":"# Checking the RevolvingUtilizationOfUnsecuredLines distribution differences by age group and both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.violinplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"ageRange\",\n    hue = \"SeriousDlqin2yrs\",  \n    data = df_clean,\n    split = True,\n    inner = \"quart\"\n);","39284e15":"# Checking the RevolvingUtilizationOfUnsecuredLines distribution differences by NumberOfTime30-59DaysPastDueNotWorse and both categories of the target variable\nplt.figure(figsize = (16,8))\nsns.violinplot(\n    y = \"RevolvingUtilizationOfUnsecuredLines\",\n    x = \"NumberOfTime30-59DaysPastDueNotWorse\",\n    hue = \"SeriousDlqin2yrs\",  \n    data = df_clean,\n    split = True,\n    inner = \"quart\"\n);","0283861b":"g = sns.FacetGrid(\n    df_clean,\n    col = \"SeriousDlqin2yrs\", \n    row = \"ageRange\", \n    height = 2.5,\n    aspect = 1.6\n)\ng.map(sns.kdeplot, \"RevolvingUtilizationOfUnsecuredLines\", \"DebtRatio\");\nplt.ylim(-0.5, 1.5);","52657cdb":"# Defining MonthlyIncomeRanges for easier visualization\nincomeRange = pd.interval_range(\n    start = 0, \n    freq = 2500, \n    end = 25000\n)\ndf_clean['MonthlyIncomeRanges'] = pd.cut(df_clean['MonthlyIncome'], bins = incomeRange)","ea578528":"# Explorning the NumberOfOpenCreditLinesAndLoans by income groups for both categories of the target variable\nplt.figure(figsize = (16,8))\na = sns.boxplot(\n    y = \"DebtRatio\",\n    x = \"MonthlyIncomeRanges\",\n    hue =\"SeriousDlqin2yrs\",  \n    data = df_clean\n)\nplt.setp(\n    a.get_xticklabels(), \n    rotation = 55\n);","d25a7049":"sns.jointplot(\n    \"MonthlyIncome\",\n    \"NumberRealEstateLoansOrLines\",\n    data = df_clean.sample(n = 3000),\n    kind = 'kde'\n);","ba7f1c3e":"# Checking medium and strong correlations in preparation for ML \ncorr = df_clean.corr()\nplt.subplots(figsize = (11, 9))\nsns.heatmap(\n    corr[(corr >= 0.25) | (corr <= -0.25)], \n    cmap = 'viridis', \n    vmax = 1.0, \n    vmin = -1.0, \n    linewidths = 0.1,\n    annot = True, \n    annot_kws = {\"size\": 10}, \n    square = True\n);","5eeb1420":"# ML environment for Random Forest with Random Search optimization \n\nfrom numpy import arange\nfrom numpy import argmax\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, classification_report, confusion_matrix, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nimport itertools\n\n# Set a random seed\nseed = 87\n\n# Define evaluation function (source: https:\/\/github.com\/WillKoehrsen\/Machine-Learning-Projects\/blob\/master\/Random%20Forest%20Tutorial.ipynb)\ndef evaluate_model(predictions, probs, train_predictions, train_probs):\n    \n    baseline = {}\n    \n    baseline['recall'] = recall_score(test_labels, [1 for _ in range(len(test_labels))])\n    baseline['precision'] = precision_score(test_labels, [1 for _ in range(len(test_labels))])\n    baseline['roc'] = 0.5\n    \n    results = {}\n    \n    results['recall'] = recall_score(test_labels, predictions)\n    results['precision'] = precision_score(test_labels, predictions)\n    results['roc'] = roc_auc_score(test_labels, probs)\n    \n    train_results = {}\n    train_results['recall'] = recall_score(train_labels, train_predictions)\n    train_results['precision'] = precision_score(train_labels, train_predictions)\n    train_results['roc'] = roc_auc_score(train_labels, train_probs)\n    \n    for metric in ['recall', 'precision', 'roc']:\n        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n    \n    # Calculate false positive rates and true positive rates\n    base_fpr, base_tpr, _ = roc_curve(test_labels, [1 for _ in range(len(test_labels))])\n    model_fpr, model_tpr, _ = roc_curve(test_labels, probs)\n\n    plt.figure(figsize = (8, 6))\n    plt.rcParams['font.size'] = 12\n    \n    # Plot both curves\n    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n    plt.legend();\n    plt.xlabel('False Positive Rt'); plt.ylabel('True Positive Rt'); plt.title('ROC Curves');\n    \n# Define confusion matrix function (source: http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html)\ndef plot_confusion_matrix(cm,\n                          classes,\n                          normalize = False,\n                          title = 'Confusion matrix',\n                          cmap = plt.cm.Oranges):\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis = 1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.figure(figsize = (4, 4))\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title, size = 10)\n    plt.colorbar(aspect = 3)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45, size = 10)\n    plt.yticks(tick_marks, classes, size = 10)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    \n    # Labeling the plot\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), fontsize = 12,\n                 horizontalalignment = \"center\",\n                 color = \"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.grid(None)\n    plt.tight_layout()\n    plt.ylabel('True label', size = 10)\n    plt.xlabel('Predicted label', size = 10)","1a2b9cc1":"# Test data preparations\n# a) Dropping MonthlyIncome and id\ndf_ml = df_clean.drop(\n    columns = [\n        \"MonthlyIncome\",\n        \"id\",\n        \"MonthlyIncomeRanges\",\n        \"ageRange\",\n        \"NumberOfTime60-89DaysPastDueNotWorse\",\n        \"NumberOfTime30-59DaysPastDueNotWorse\",\n        \"NumberOfTimes90DaysLate\",\n        \"NumberRealEstateLoansOrLines\",\n        \"NumberOfDependents\"\n    ]\n);\n# b) Splitting the dataset (30%)\nlabels = np.array(df_ml.pop('SeriousDlqin2yrs'))\ntrain, test, train_labels, test_labels = train_test_split(\n    df_ml, \n    labels, \n    stratify = labels,\n    test_size = 0.3, \n    random_state = seed\n);\n# c) Saving features\nfeatures = list(train.columns);","5a64125b":"train.shape","c564edb5":"test.shape","91da2c65":"model = RandomForestClassifier(\n    n_estimators = 230, \n    random_state = seed, \n    max_features = 'sqrt',\n    n_jobs = -1,\n    verbose = 1\n)\n\n# Fitting on the Train dataset, predicting\nmodel.fit(train, train_labels)\n\ntrain_rf_pred = model.predict(train)\ntrain_rf_probs = model.predict_proba(train)[:, 1]\n\nrf_pred = model.predict(test)\nrf_probs = model.predict_proba(test)[:, 1]","7194f5a8":"# Evaluating\nevaluate_model(rf_pred, rf_probs, train_rf_pred, train_rf_probs)","fbef7d6d":"roc_auc_score(test_labels, rf_probs)","55bea00a":"cm = confusion_matrix(test_labels, rf_pred)\nplot_confusion_matrix(\n    cm, \n    classes = ['0', '1'],\n    normalize = True,\n    title = 'Confusion Matrix'\n);\nplt.grid(None);","e76149a8":"print(classification_report(test_labels, rf_pred))","79c4f187":"# Checking variables importance\nrf_model = pd.DataFrame({'feature': features,\n                   'importance': model.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\nrf_model.head(10)","2b5ea621":"# Hyperparameters\nparams = {\n    'n_estimators': np.linspace(100, 210).astype(int),\n    'max_depth': [None] + list(np.linspace(4, 24).astype(int)),\n    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.2, 0.4)),\n    'max_leaf_nodes': [None] + list(np.linspace(16, 48, 80).astype(int)),\n    'min_samples_split': [1, 2, 3],\n    'bootstrap': [True, False]\n}\n\n# Estimator\nestimator = RandomForestClassifier(random_state = seed)\n\n# Random search model\nrs = RandomizedSearchCV(\n    estimator,\n    params,\n    n_jobs = -1, \n    scoring = 'recall',\n    cv = 3, \n    n_iter = 10, \n    verbose = 1,\n    random_state = seed\n)\n\n# Fitting\nrs.fit(train, train_labels)","b767abe0":"# Predicting\ntrain_rs_pred = rs.predict(train)\ntrain_rs_probs = rs.predict_proba(train)[:, 1]\n\nrs_pred = rs.predict(test)\nrs_probs = rs.predict_proba(test)[:, 1]","9b64868c":"# Evaluating\nevaluate_model(rs_pred, rs_probs, train_rs_pred, train_rs_probs)","6847584f":"roc_auc_score(test_labels, rs_probs)","dbd3da13":"rs.best_params_","e9c3e598":"cm = confusion_matrix(test_labels, rs_pred)\nplot_confusion_matrix(\n    cm, \n    classes = ['0', '1'],\n    normalize = True,\n    title = 'Confusion Matrix'\n);\nplt.grid(None);","6f5b9e86":"print(classification_report(test_labels, rs_pred))","908210b5":"# Checking variables importance\nrs_model = pd.DataFrame({'feature': features,\n                   'importance': rs.best_estimator_.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\nrs_model.head(10)","7e337c21":"### Take 2 - RandomForest with Random Search optimization","43355304":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code> limit at 1.9","1ddf5d82":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code> limit at 1.9\n* <code>age<\/code> remove one row with 0\n* <code>NumberOfTime30-59DaysPastDueNotWorse<\/code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTime60-89DaysPastDueNotWorse<\/code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTimes90DaysLate<\/code>: clip at 6 to exclude values \"96\" and \"98\"","b4eacb24":"### 6) NumberRealEstateLoansOrLines","d126b6b4":"### 3) NumberOfTime30-59DaysPastDueNotWorse, NumberOfTime60-89DaysPastDueNotWorse, NumberOfTimes90DaysLate","ff6495af":"### 5) NumberOfOpenCreditLinesAndLoans","1b58ec15":"#### Quick notes about the data quality:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code>: contains wrong data (max = 50708.00), needs cleaning\n* <code>age<\/code>: contains wrong data (min = 0.00), needs cleaning\n* <code>NumberOfTime30-59DaysPastDueNotWorse<\/code>: seems fine\n* <code>DebtRatio<\/code>: seems off when MonthlyIncome is \"NaN\", contains wrong data (max = 329664.00), needs cleaning\n* <code>MonthlyIncome<\/code>: 19.8% are \"NaN\" values, some outliers (min = 0, max = 3,008,750) >> needs cleaning, possibly splitting the dataset in 2 to build the model if this is a good predictor\n* <code>NumberOfOpenCreditLinesAndLoans<\/code>: seems fine\n* <code>NumberOfTimes90DaysLate<\/code>: seems fine \n* <code>NumberRealEstateLoansOrLines<\/code>: seems fine \n* <code>NumberOfTime60-89DaysPastDueNotWorse<\/code>: seems fine\n* <code>NumberOfDependents<\/code>: 2.6% are \"NaN\" values, needs cleaning","1ff9fd6d":"# Step 2: Making a clean dataset, EDA","31e57f99":"For all age groups, <code>RevolvingUtilizationOfUnsecuredLines<\/code> is noticably different between defaulted and non-defaulted users","cc37ee83":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code> limit at 1.9\n* <code>age<\/code> remove one row with 0\n* <code>NumberOfTime30-59DaysPastDueNotWorse<\/code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTime60-89DaysPastDueNotWorse<\/code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTimes90DaysLate<\/code>: clip at 6 to exclude values \"96\" and \"98\"\n* <code>MonthlyIncome<\/code>: remove nulls for analysis, clip between 800 and 20,000\n* <code>DebtRatio<\/code>: after removing MonthlyIncome null data the distribuion should be back to as expected, limit at 50 and clip at 1.2\n","0aa76ec8":"**Observations from the sample:**\n* <code>Unnamed: 0<\/code> is most likely the \"id\" column\n* <code>DebtRatio<\/code> has unexpected (> 1) values\n* <code>MonthlyIncome<\/code> has unexpected (NaN, 0) values\n* <code>NumberOfDependants<\/code> has unexpected (NaN) values","27d96a93":"#### ML-relevant observations summary:\n* <code>MonthlyIncome<\/code> has >20% of missing values AND is not a strong predictor (correlation is less than 0.2), so consider removing it from the model","a88854dd":"For all income groups, average <code>DebtRatio<\/code> of defaulted users is higher than non-defaulted users, with the difference becoming bigger as the income increases","eb86222a":"Out of all age groups, users between 20 and 30 have the highest ratio of very high (close to 1) <code>RevolvingUtilizationOfUnsecuredLines<\/code>","8fb28b12":"# Step 0: Environment preparation, data load, brief quality check","f980e33a":"# Step 1: Data cleaning: wrong values, nulls, outliers, etc.","0bebfa6d":"### 1) RevolvingUtilizationOfUnsecuredLines","28ff484e":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code> limit at 1.9\n* <code>age<\/code> remove one row with 0\n* <code>NumberOfTime30-59DaysPastDueNotWorse<\/code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTime60-89DaysPastDueNotWorse<\/code>: clip at 5 to exclude values \"96\" and \"98\"\n* <code>NumberOfTimes90DaysLate<\/code>: clip at 6 to exclude values \"96\" and \"98\"\n* <code>MonthlyIncome<\/code>: remove nulls for analysis, clip between 800 and 20,000\n* <code>DebtRatio<\/code>: after removing MonthlyIncome null data the distribuion should be back to as expected, limit at 50 and clip at 1.2\n* <code>NumberOfOpenCreditLinesAndLoans<\/code>: clip at 20\n* <code>NumberRealEstateLoansOrLines<\/code>: clip at 5\n* <code>NumberOfDependents<\/code>: clip at 5","d31cbb61":"### 2) age","9ef88098":"More than half of defaulted users have the <code>RevolvingUtilizationOfUnsecuredLines<\/code> above **0.8**<br>\nOnly 18% of non-defaulted users have such high <code>RevolvingUtilizationOfUnsecuredLines<\/code>","2ebf72ce":"### 4) MonthlyIncome and DebtRatio","2b6e6990":"When the <code>NumberOfTime30-59DaysPastDueNotWorse<\/code> is **4 or higher**, it becomes less effective to use <code>RevolvingUtilizationOfUnsecuredLines<\/code> as a predictor of default.","fc88291b":"#### Data prep actions memo:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code> limit at 1.4\n* <code>age<\/code> remove one row with 0","9c742f8b":"#### Explore further memo - part 2:\n* <code>MonthlyIncome<\/code> has an unexpected medium positive correlation with <code>NumberRealEstateLoansOrLines<\/code>","f369c461":"#### Explore further memo:\n* Defaulted (<code>SeriousDlqin2yrs<\/code> = 1) users are generally younger than non-defaulted users \n* Defaulted users have <code>RevolvingUtilizationOfUnsecuredLines<\/code> much closer to maximum (1), which is opposite for the non-defaulted users\n* Defaulted users' <code>DebpRatio<\/code> tend to be increasing with <code>age<\/code>, and for non-defaulted users the trend is the opposite ","24c79bd0":"### 7) NumberOfDependents","0fcf4840":"While the average <code>DebtRatio<\/code> is decreasing with age for the groups from 40 to 80 for non-defaulted users, it almost doesn't change for defaulted users","406124d3":"# Step 3: ML","b8ec3e51":"For higher age groups, it's easier to tell if the user would default if the <code>RevolvingUtilizationOfUnsecuredLines<\/code> is high (around \"1\")","8a2756f7":"### Take 1 - RandomForest","7e1b9216":"![](http:\/\/)Average age of the defaulted user is around **45**, and non-default user is around **52**","3ecfe5de":"# Key insights summary\n\n### (1) For predicting the 2-years default (<code>SeriousDlqin2yrs<\/code>), the following 7 columns are useful:\n* <code>RevolvingUtilizationOfUnsecuredLines<\/code> correlation with the target 0.28\n* <code>DebtRatio<\/code>\n* <code>NumberOfOpenCreditLinesAndLoans<\/code>\n* <code>age<\/code>\n* <code>NumberOfTime30-59DaysPastDueNotWorse<\/code> correlation with the target 0.28\n* <code>NumberOfTime60-89DaysPastDueNotWorse<\/code> correlation with the target 0.27\n* <code>NumberOfTimes90DaysLate<\/code>: correlation with the target 0.32\n    \nIn other words, there is no need to use extra resources to obtain and\/or increase the quality of the <code>MonthlyIncome<\/code> and <code>NumberOfDependents<\/code> data.\n\n### (2) RevolvingUtilizationOfUnsecuredLines is a great predictor for the 2-year default, effective for all age groups\nMore than half of all defaulted users have the <code>RevolvingUtilizationOfUnsecuredLines<\/code> above 0.8,<br>but only 18% of non-defaulted users are above that value.\n\n\n### (3) More users default at younger age\nHalf of all defaults are happening before 45, while the average are of the non-default user is around 52.<br>\nNoticeably, younger age groups (20 ~ 40) have the highest concentration of users with high <code>RevolvingUtilizationOfUnsecuredLines<\/code>.\n\n### (4) Average DebtRatio of the default users is above 0.4 for over 40 age group\nFor the non-default users, the average <code>DebtRatio<\/code> is at 0.33 for the 40~50 age group, and from there decreases<br>\nto below 0.2 for users over 80. "}}