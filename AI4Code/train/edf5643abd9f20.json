{"cell_type":{"8b440a81":"code","8da5cd0e":"code","b1238d50":"code","0c4ba61b":"code","9c0f87cf":"code","8b9f55b8":"code","f44053ec":"code","c0426dc0":"code","da849fa0":"code","d464c47c":"code","944c763a":"code","5ba15f06":"code","a5f67918":"code","0ce127ec":"code","63ef8b12":"code","ec46eab6":"code","e27cca94":"code","47d0942b":"code","790ef121":"code","83205533":"code","59c7e949":"code","f94f2803":"code","05e71201":"code","a1fb2fad":"code","fe566a25":"code","703049bc":"code","bf7fdb89":"code","da0e720b":"code","6029f5d2":"code","fc02d773":"code","c4f47422":"code","8cfa7dd9":"code","f8a88e52":"code","08a8c0fb":"code","53653a69":"code","8c1847e2":"code","902d23e1":"code","4195fe2b":"code","5664a537":"code","1a39268b":"code","1e4bc0b1":"code","b19a0024":"code","3bd2b1c7":"code","7c8ba145":"code","20cf31e3":"code","157c2b6a":"code","1645cc30":"code","25586a13":"code","83356362":"code","53201538":"code","14f4585a":"code","696951bd":"code","02dc3651":"code","1acac9cb":"code","37d1e2c2":"code","c6947df2":"markdown","e1a51f7d":"markdown","af3d5717":"markdown","55c7eccb":"markdown","2625e759":"markdown"},"source":{"8b440a81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8da5cd0e":"dirname = '\/kaggle\/input'\ntrain_path = os.path.join(dirname, 'kermany2018\/OCT2017 \/train')\ntrain_normal_pth = os.path.join(train_path, 'NORMAL')\ntrain_dme_pth = os.path.join(train_path, 'DME')\ntrain_drusen_pth = os.path.join(train_path, 'DRUSEN')\ntrain_cnv_pth = os.path.join(train_path, 'CNV')\n    \ntest_path = os.path.join(dirname, 'kermany2018\/OCT2017 \/test')\ntest_normal_pth = os.path.join(test_path, 'NORMAL')\ntest_dme_pth = os.path.join(test_path, 'DME')\ntest_drusen_pth = os.path.join(test_path, 'DRUSEN')\ntest_cnv_pth = os.path.join(test_path, 'CNV')\n    \nval_path = os.path.join(dirname, 'kermany2018\/OCT2017 \/val')\nval_normal_pth = os.path.join(val_path, 'NORMAL')\nval_dme_pth = os.path.join(val_path, 'DME')\nval_drusen_pth = os.path.join(val_path, 'DRUSEN')\nval_cnv_pth = os.path.join(val_path, 'CNV')","b1238d50":"print(test_normal_pth)\nprint(train_drusen_pth)","0c4ba61b":"import matplotlib.pyplot as plt","9c0f87cf":"def plot_imgs(item_dir, num_imgs=4):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_imgs]\n\n    plt.figure(figsize=(16, 16))\n    for idx, img_path in enumerate(item_files):\n        plt.subplot(1, 4, idx+1)\n\n        img = plt.imread(img_path)\n        plt.imshow(img, cmap='bone')\n\n    plt.tight_layout()\n","8b9f55b8":"plot_imgs(train_normal_pth)","f44053ec":"plot_imgs(train_dme_pth)","c0426dc0":"plot_imgs(train_drusen_pth)","da849fa0":"plot_imgs(train_cnv_pth)","d464c47c":"input_path = \"\/kaggle\/input\/kermany2018\/OCT2017 \/\"\n\nfor _set in ['train', 'test', 'val']:\n    normal = len(os.listdir(input_path + _set + '\/NORMAL'))\n    dme = len(os.listdir(input_path + _set + '\/DME'))\n    drusen = len(os.listdir(input_path + _set + '\/DRUSEN'))\n    cnv = len(os.listdir(input_path + _set + '\/CNV'))\n    print('{}, Normal images: {}, DME images: {}, DRUSEN images: {}, CNV images: {}'.format(_set, normal, dme, drusen, cnv))","944c763a":"datadir = '..\/input\/kermany2018\/OCT2017 \/'\ntraindir = datadir + 'train\/'\nvaliddir = datadir + 'val\/'\ntestdir = datadir + 'test\/'","5ba15f06":"import glob\nfrom PIL import Image","a5f67918":"# Empty lists\ncategories = []\nimg_categories = []\nn_train = []\nn_valid = []\nn_test = []\nhs = []\nws = []\n\n# Iterate through each category\nfor d in os.listdir(traindir):\n    categories.append(d)\n\n    # Number of each image\n    train_imgs = os.listdir(traindir + d)\n    valid_imgs = os.listdir(validdir + d)\n    test_imgs = os.listdir(testdir + d)\n    n_train.append(len(train_imgs))\n    n_valid.append(len(valid_imgs))\n    n_test.append(len(test_imgs))\n\n    # Find stats for train images\n    for i in train_imgs:\n        img_categories.append(d)\n        img = Image.open(traindir + d + '\/' + i)\n        img_array = np.array(img)\n        # Shape\n        hs.append(img_array.shape[0])\n        ws.append(img_array.shape[1])\n\n# Dataframe of categories\ncat_df = pd.DataFrame({'category': categories,\n                       'n_train': n_train,\n                       'n_valid': n_valid, 'n_test': n_test}).\\\n    sort_values('category')\n\n# Dataframe of training images\nimage_df = pd.DataFrame({\n    'category': img_categories,\n    'height': hs,\n    'width': ws\n})\n\ncat_df.sort_values('n_train', ascending=False, inplace=True)\ncat_df.head()","0ce127ec":"cat_df.set_index('category')['n_train'].plot.bar(figsize=(15, 6))\nplt.xticks(rotation=80)\nplt.ylabel('Count')\nplt.title('Training Images by Category')\nplt.show()","63ef8b12":"img_dsc = image_df.groupby('category').describe()\nimg_dsc.head()","ec46eab6":"import seaborn as sns","e27cca94":"plt.figure(figsize=(10, 6))\nsns.kdeplot(\n    img_dsc['height']['mean'], label='Average Height')\nsns.kdeplot(\n    img_dsc['width']['mean'], label='Average Width')\nplt.xlabel('Pixels')\nplt.ylabel('Density')\nplt.title('Average Size Distribution')","47d0942b":"import os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, classification_report\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers import MaxPooling2D,AveragePooling2D, GlobalAveragePooling2D,BatchNormalization\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.inception_v3 import InceptionV3\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\n%matplotlib inline","790ef121":"# Model parameters\nimage_size = 256\nbatch_size = 16\nnum_classes = 4\nepochs = 10","83205533":"# Baseline Model.\nmodel = Sequential()\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=(image_size, image_size,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2)))\n# model.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n# model.add(Dropout(0.4))\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n# model.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\nprint(model.summary())\n\nmodel.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])","59c7e949":"train_datagen = ImageDataGenerator(validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(traindir,target_size=(image_size, image_size),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(traindir,target_size=(image_size,image_size),\n                                                         batch_size=batch_size,\n                                                         class_mode='categorical',\n                                                         subset='validation') # set as validation data\n\n\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow_from_directory(testdir,target_size=(image_size, image_size),\n                                                  batch_size=batch_size,\n                                                  class_mode='categorical')","f94f2803":"class_weights = class_weight.compute_class_weight('balanced',\n                                                  np.unique(train_generator.classes),\n                                                  train_generator.classes)","05e71201":"from keras.callbacks import ModelCheckpoint, EarlyStopping\nfilepath=\"\/kaggle\/output\/5layered_best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n# earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3,verbose = 1,restore_best_weights = True)\ncallbacks_list = [checkpoint]","a1fb2fad":"history = model.fit_generator(train_generator,\n                              steps_per_epoch = train_generator.samples \/\/ batch_size,\n                              validation_data = validation_generator,\n                              validation_steps = validation_generator.samples \/\/ batch_size,\n                              epochs = epochs, \n                              callbacks=callbacks_list,\n                              class_weight=class_weights)","fe566a25":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model_balanced_cnn5layered.json\", \"w\") as json_file:\n    json_file.write(model_json)","703049bc":"score = model.evaluate_generator(test_generator,steps = test_generator.samples \/\/ batch_size) \nprint(\"\\n\\n\")\nprint('Testing Loss:', score[0])\nprint('Testing accuracy:', score[1])\n\n","bf7fdb89":"def load_test_data(folder):\n    \"\"\"\n    Function to load the images and labels.\n    \"\"\"\n    Image = []\n    Label = []\n    \n    for folder_name in os.listdir(folder):\n        # Reading the labels.\n        if not folder_name.startswith('.'):\n            if folder_name in ['CNV']:\n                label = 0\n            elif folder_name in ['DME']:\n                label = 1\n            elif folder_name in ['DRUSEN']:\n                label = 2\n            elif folder_name in ['NORMAL']:\n                label = 3\n            else:\n                label = 4\n            for image_file_name in tqdm(os.listdir(folder + folder_name)):\n                # Reading the images.\n                image_file = cv2.imread(folder + folder_name + '\/' + image_file_name)\n                if image_file is not None:\n                    # Converting images into array.\n                    image_file = skimage.transform.resize(image_file, (image_size, image_size, 3))\n                    image_array = np.asarray(image_file)\n                    Image.append(image_array)\n                    Label.append(label)\n    Image = np.asarray(Image)\n    Label = np.asarray(Label)\n    return Image,Label","da0e720b":"X_test,Y_test= load_test_data(testdir)","6029f5d2":"pred_datagen = ImageDataGenerator()\n\npred_generator = pred_datagen.flow_from_directory(testdir,target_size=(image_size, image_size),\n                                                  batch_size=1,\n                                                  class_mode='categorical',\n                                                  shuffle = False)","fc02d773":"\npred_generator.reset()\ny_pred = model.predict_generator(pred_generator,steps = 968)\nY_test = pred_generator.classes[pred_generator.index_array]\nY_pred = np.argmax(y_pred, axis=-1)","c4f47422":"Y_pred = np.argmax(y_pred,axis = 1)","8cfa7dd9":"import pickle\nwith open('y_pred_baseline_model.pkl','wb') as f:\n    pickle.dump(y_pred, f)","f8a88e52":"print ('Train Accuracy', np.mean(history.history['accuracy']))\nprint ('Train Loss', np.mean(history.history['loss']))\nprint ('Validation Accuracy', np.mean(history.history['val_accuracy']))\nprint ('Validation Loss', np.mean(history.history['val_loss']))","08a8c0fb":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","53653a69":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","8c1847e2":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","902d23e1":"cm = confusion_matrix(Y_test, Y_pred)\n \nprint('--------------------')\nprint('| Confusion Matrix |')\nprint('--------------------')\nprint('\\n {}'.format(cm))\n        \n# plot confusin matrix\nplt.figure(figsize=(8,8))\nplt.grid(b=False)\nplot_confusion_matrix(cm, classes=['CNV','DME','DRUSEN','NORMAL'], normalize=False, \n                      title='Confusion matrix', cmap = plt.cm.Blues)","4195fe2b":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test,Y_pred,target_names=['CNV','DME','DRUSEN','Normal']))","5664a537":"FP = cm.sum(axis=0) - np.diag(cm)  \nFN = cm.sum(axis=1) - np.diag(cm)\nTP = np.diag(cm)\nTN = cm.sum() - (FP + FN + TP)\n\nFP = FP.astype(float)\nFN = FN.astype(float)\nTP = TP.astype(float)\nTN = TN.astype(float)\n\n# Sensitivity, hit rate, recall, or true positive rate\nTPR = TP\/(TP+FN)\nprint(\"Recall\/TPR = {}\".format(TPR))\n\n# Specificity or true negative rate\nTNR = TN\/(TN+FP) \nprint(\"Specificity\/TNR = {}\".format(TNR))\n\n# Precision or positive predictive value\nPPV = TP\/(TP+FP)\nprint(\"Precision\/PPV = {}\".format(PPV))\n\n# Negative predictive value\nNPV = TN\/(TN+FN)\nprint(\"Negative Predict Value = {}\".format(NPV))\n\n# Fall out or false positive rate\nFPR = FP\/(FP+TN)\nprint(\"False Positive Rate = {}\".format(FPR))\n\n# False negative rate\nFNR = FN\/(TP+FN)\nprint(\"False Negative Rate = {}\".format(FNR))\n\n# False discovery rate\nFDR = FP\/(TP+FP)\nprint(\"False discovery rate = {}\".format(FDR))\n\n# Overall accuracy\nACC = (TP+TN)\/(TP+FP+FN+TN)\nprint(\"Overall Accuracy = {}\".format(ACC))","1a39268b":"import numpy as np   \nfrom keras.preprocessing import image    \nim1_path=\"..\/input\/kermany2018\/OCT2017 \/test\/DME\/DME-15208-2.jpeg\"\ntest_image=image.load_img(im1_path,target_size=(256,256))","1e4bc0b1":"import matplotlib.pyplot as plt\nplt.imshow(test_image)\n# now to convert to 3 dimensional from 2d\ntest_image=image.img_to_array(test_image)\nprint(test_image.size)","b19a0024":"def get_name_layer_filters(model):\n    filter_whole=[]\n    layer_whole=[]\n    for layer in model.layers:\n        if 'conv' not in layer.name:\n            continue\n        filters,biases=layer.get_weights()\n        filter_whole.append(filters)\n        layer_whole.append(biases)\n        print(layer.name,filters.shape)\n    return filter_whole,layer_whole    \n        ","3bd2b1c7":"filter_whole,layer_whole=get_name_layer_filters(model)","7c8ba145":"filters,biases=model.layers[0].get_weights()","20cf31e3":"f_min,f_max=filters.min(),filters.max()\nfilters=(filters-f_min)\/(f_max-f_min)","157c2b6a":"from matplotlib import pyplot\nn_filters,ix=6,1\nfor i in range(n_filters):\n    f=filters[:,:,:,i]\n    #Plot each channel\n    for j in range(3):\n        ax=pyplot.subplot(n_filters,3,ix)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        #Plot filter channel\n        pyplot.imshow(f[:,:,j])\n        ix+=1\n        \npyplot.show() ","1645cc30":"from keras.models import Model\nmodel_feature=Model(inputs=model.inputs,outputs=model.layers[4].output)","25586a13":"test_image = np.expand_dims(test_image, axis=0)\nfeature_map=model_feature.predict(test_image)","83356362":"feature_map.shape","53201538":"pyplot.figure(figsize=(10,10))        \n        \nsquare=8\nix=1\nfor _ in range(4):\n    for _ in range(8):\n        ax=pyplot.subplot(square,square,ix)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        pyplot.imshow(feature_map[0,:,:,ix-1])\n        ix+=1\n        \npyplot.show()","14f4585a":"def get_convolutional_layers(model):\n    convolutions_models=[]\n    for layer in model.layers:\n        if 'conv2d' not in layer.name:\n            continue\n        model_temp=Model(inputs=model.inputs,outputs=layer.output)\n        convolutions_models.append(model_temp)\n    return convolutions_models    \n        ","696951bd":"def generate_feature_maps(model,test_image):\n    models=get_convolutional_layers(model)#Fetching convolution layers models\n    feature_maps=[]\n    \n    for model_temp in models:\n        feature_map=model_feature.predict(test_image)\n        feature_maps.append(feature_map)\n    return feature_maps,models   ","02dc3651":"def plot_graph(feature_map):\n    \n    #plot all 32 maps in an 8*4 squares\n    pyplot.figure(figsize=(10,10))        \n        \n    square=8\n    ix=1\n    for _ in range(4):\n        for _ in range(8):\n            ax=pyplot.subplot(square,square,ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            pyplot.imshow(feature_map[0,:,:,ix-1])\n            ix+=1\n        \n    pyplot.show()","1acac9cb":"def plots_generator(model):\n    print(\"IMAGE UNDER CONSIDERATION\")\n    test_image=image.load_img(im1_path,target_size=(256,256))\n    plt.imshow(test_image)\n    test_image=image.img_to_array(test_image)\n\n    test_image= np.expand_dims(test_image,axis=0)\n    print()\n    feature_maps,models=generate_feature_maps(model,test_image)\n    #ax=pyplot.subplot(square,square,ix)# only 32 filters will be shown of each layer\n    counter=1\n    for each_map in feature_maps:\n        print(\"Convolutional Layer Number {} \".format(counter))\n        counter+=1\n        #ax=pyplot.subplot(square,square,ix)\n        plot_graph(each_map)","37d1e2c2":"plots_generator(model)","c6947df2":"This function returns feature maps and models list","e1a51f7d":"32 feature maps will be plotted. We will try to analyze these maps and interpret them in a useful way after plotting them.","af3d5717":"Starting with the plotting\n\nMaking a model from feature map.We will start with making a model with outputs from 1st convolution layer of model and input from model.","55c7eccb":"**Layer Visualization**","2625e759":"Now implementing above feature map plotting for all convolution layer."}}