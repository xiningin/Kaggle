{"cell_type":{"97cea19b":"code","15fc6ca4":"code","8d4c518c":"code","d564af68":"code","07180d67":"code","211fb876":"code","658b9551":"code","1c1d69e3":"code","dede2413":"code","9cb6def8":"code","a7c3bec1":"code","e962c07d":"code","46a55cd1":"code","e50bd3d1":"code","5c6214af":"code","49d62117":"code","94bd6086":"code","2b8c5471":"code","a3adeb53":"code","8989a2ee":"code","1005d149":"markdown","a36a2f8e":"markdown","77855f69":"markdown","9f4306a7":"markdown"},"source":{"97cea19b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","15fc6ca4":"import numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale \nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n","8d4c518c":"train_identity=pd.read_csv('..\/input\/train_identity.csv', index_col='TransactionID')","d564af68":"train_identity.shape","07180d67":"train_transaction=pd.read_csv('..\/input\/train_transaction.csv', index_col='TransactionID')","211fb876":"train_transaction.shape","658b9551":"test_transaction = pd.read_csv('..\/input\/test_transaction.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='TransactionID')","1c1d69e3":"train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n","dede2413":"test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)","9cb6def8":"y_train_full = train['isFraud'].copy()\nX_train_full = train.drop('isFraud', axis=1)\nX_test = test.copy()","a7c3bec1":"del train_transaction, train_identity, test, test_transaction, test_identity","e962c07d":"X_train_full = X_train_full.fillna(-999)\nX_test = X_test.fillna(-999)","46a55cd1":"from sklearn import preprocessing\n\nfor f in X_train_full.columns:\n    if X_train_full[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train_full[f].values) + list(X_test[f].values))\n        X_train_full[f] = lbl.transform(list(X_train_full[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values)) ","e50bd3d1":"X_train, X_val, Y_train, Y_val = train_test_split(X_train_full, y_train_full, \n                                                    test_size=0.15, \n                                                    random_state=42)","5c6214af":"del X_train_full, y_train_full","49d62117":"from sklearn.ensemble import RandomForestRegressor\nrf_tuned = RandomForestRegressor(max_depth  = 45,max_features = 30, n_estimators =500, n_jobs=-1, min_samples_leaf=200)","94bd6086":"%time rf_tuned.fit(X_train, Y_train)","2b8c5471":"print(\"Square root of error squares\",np.sqrt(mean_squared_error(Y_val,rf_tuned.predict(X_val))))\nprint(\"Roc Auc Score:\",roc_auc_score(Y_val,rf_tuned.predict(X_val)))","a3adeb53":"sample_submission['isFraud'] = rf_tuned.predict(X_test)\nsample_submission.to_csv('fraud-detection-submission.csv')","8989a2ee":"import matplotlib.pyplot as plt\n\nImportance = pd.DataFrame(index=X_train.columns)\nImportance['Importance'] = rf_tuned.feature_importances_*100\nImportance.loc[Importance['Importance'] > 1.5].sort_values('Importance').head(40).plot(kind='barh', figsize=(14, 28),color=\"r\", title='Feature Importance')\nplt.xlabel(\"Variable Severity Levels\")\nplt.show()","1005d149":"# FEATURE IMPORTANCES","a36a2f8e":"# Librairies and data","77855f69":"Label Encoding","9f4306a7":"# MODEL"}}