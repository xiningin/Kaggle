{"cell_type":{"50b836f9":"code","1d488387":"code","c62fdf43":"code","741ebcfd":"code","9a50e8b7":"code","6f66ea81":"code","03b437dc":"code","da885e12":"code","ee48774d":"code","8e38dbf3":"code","7c2dfd7e":"code","381524c4":"code","3cff184c":"code","dfc5165b":"code","410b98e0":"code","45081f48":"code","63d28c33":"code","78e6f068":"markdown","680af37b":"markdown","6a143e5f":"markdown","6572214b":"markdown","31ba1223":"markdown","0d482f7d":"markdown","810e65a3":"markdown","89d443b5":"markdown","a693c1cd":"markdown","e8a5f336":"markdown","52fe61fa":"markdown","661a7975":"markdown","bbf1ec83":"markdown","25e0f3cc":"markdown","39867860":"markdown","888adc7f":"markdown"},"source":{"50b836f9":"import numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')","1d488387":"train_data = pd.read_csv(\"..\/input\/tabular-playground-series-jan-2022\/train.csv\")\ntrain_data = train_data.sort_values(by=['date'])\ntrain_data.head() ","c62fdf43":"train_data.info()","741ebcfd":"train_data.describe()","9a50e8b7":"numerical_columns = [var for var in train_data.columns if train_data[var].dtype!='O']\nprint(\" Numerical columns : \", len(numerical_columns),\"\\n Columns: \",numerical_columns)","6f66ea81":"categorical_columns = [var for var in train_data.columns if train_data[var].dtype=='O']\nprint(\" Categorical columns : \", len(categorical_columns),\"\\n Columns: \",categorical_columns)","03b437dc":"train_data['year'] = \"\"\ntrain_data['month'] = \"\"\ntrain_data['day'] = \"\"\n\nfor i in range(len(train_data)):\n    train_data['year'].iloc[i] = train_data['date'].iloc[i].split(\"-\")[0]\n    train_data['month'].iloc[i] = train_data['date'].iloc[i].split(\"-\")[1]\n    train_data['day'].iloc[i] = train_data['date'].iloc[i].split(\"-\")[2]","da885e12":"train_data.head()","ee48774d":"train_data.isna().sum()","8e38dbf3":"train_data[train_data.duplicated()]","7c2dfd7e":"train_data_2015 = train_data[train_data['year']=='2015']\n\nfig1 = px.line(train_data_2015, x='date', y=\"num_sold\",title=\"Daily Sales for 2015\")\nfig1.show()","381524c4":"train_data_2015_max = pd.DataFrame(train_data_2015.groupby(['date','year'], sort=False)['num_sold'].max()).reset_index()\n\nfig2= px.line(train_data_2015_max, x='date', y=\"num_sold\", title=\"Maximum Daily Sales for 2015\")\nfig2.show()","3cff184c":"train_data_max = pd.DataFrame(train_data.groupby(['date','year','month','day'], sort=False)['num_sold'].max()).reset_index()\n\nfig3 = px.line(train_data_max, x='date', y=\"num_sold\", title=\"Maximum Daily Sales 2015-18\")\nfig3.update_xaxes(rangeslider_visible=True)\nfig3.show()","dfc5165b":"train_data_max_monthly = train_data_max.groupby(['year','month'], sort=False)['num_sold'].max().reset_index()\n\nfig4 = px.area(train_data_max_monthly, x='month', y='num_sold', facet_col=\"year\", color ='year',facet_col_wrap=2)\nfig4.show()","410b98e0":"year_sold = train_data.groupby(['year','store'], sort=False)['num_sold'].max().reset_index()\nfig5 = px.bar(year_sold, x='year',y='num_sold',barmode='group',color='store',title=\"Sales vs Years for Type of Stores\")\nfig5.show()","45081f48":"product_year_sold = train_data.groupby(['year','product'], sort=False)['num_sold'].max().reset_index()\nfigure = px.bar(product_year_sold, x='year',y='num_sold',color='product',title=\"Sales vs Years for Type of Product\")\nfigure.show()","63d28c33":"country_year_sold = train_data.groupby(['year','country'], sort=False)['num_sold'].max().reset_index()\nfigure_country = px.bar(country_year_sold, x='year',y='num_sold',color='country',\n                        barmode='group',title=\"Sales vs Years w.r.t Countries\")\nfigure_country.show()","78e6f068":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <h2>(2) Importing Data<\/h2>\n<\/div>\n<hr>","680af37b":"# Please do upvote ! \ud83d\ude03\n\n<hr>\n\n### References and Resources : \n \n 1. [Plotly](https:\/\/plotly.com\/) \n 2. [Pandas](https:\/\/pandas.pydata.org\/)\n\n\n<div class=\"alert alert-block alert-warning\" align=\"center\" style=\"margin-top: 20px\">\n    <h2><i>Thank you and wish you a Happy New year !<\/i> \ud83c\udf89<\/h2>\n<\/div>","6a143e5f":"### Year-Year Maximum Sales","6572214b":"### Sales per Country","31ba1223":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <h2>(1) Importing Libraries<\/h2>\n<\/div>\n<hr>\n","0d482f7d":"### Month-Month Maximum Sales","810e65a3":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <h2>(3) Exploring Data<\/h2>\n<\/div>\n<hr>\n","89d443b5":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <h2>(5) Visualizing Data<\/h2>\n<\/div>\n<hr>\n\nVisualizing entire dataset in a graph could be overwhelming and might not give much value out. Hence we will break this into smaller sets by considering year and then maximum values of \"num_sold\" values in a day. \n\nIn the following cells, we will be looking at training dataset for 2015 year only.\n\n\n### Sales for a Year ","a693c1cd":"### Product Sales","e8a5f336":"Creating new columns from \"date\" feature.","52fe61fa":"<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <h2>(4) Cleaning Data<\/h2>\n<\/div>\n<hr>\n","661a7975":"### Store vs Years","bbf1ec83":"Also, there are **no** duplicated rows.","25e0f3cc":"### Maximum sales for a Year ","39867860":"# TPS Jan 2022 \n\n---\n\nThis notebook is basic EDA on the training and test datasets for the TPS January 2022. I have used Pandas, NumPy and Plotly Libraries for this. The next steps after this notebook will be developing machine learning models using ML and DL libraries and practices.\n","888adc7f":"There are **no** missing values or Null Values to clean."}}