{"cell_type":{"71b255f2":"code","13012e5e":"code","9d34fd00":"code","f74f20d3":"code","b623d7db":"code","94f4b8b8":"code","7d67484e":"code","4be5d389":"code","17aabcb8":"code","76518028":"code","58ef2bb4":"code","97e396a6":"code","3e18b1f1":"markdown","7f850db6":"markdown","4ca0d392":"markdown","0c873955":"markdown","fe9fa2bb":"markdown","3d0f3d9c":"markdown","19bd572b":"markdown"},"source":{"71b255f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13012e5e":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport matplotlib.pyplot as plt #for plotting things\n\nfrom PIL import Image\nimport cv2\nimport tensorflow as tf","9d34fd00":"train_folder='\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/',\ntrain_horse_dir=os.path.join('\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/horses\/')\ntrain_human_dir=os.path.join('\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/humans\/')\nvalidation_horse_dir=os.path.join('\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/horses\/')\nvalidation_human_dir=os.path.join('\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/humans\/')","f74f20d3":"print('total training horse images:', len(os.listdir(train_horse_dir)))\nprint('total training human images:', len(os.listdir(train_human_dir)))\nprint('total validation horse images:', len(os.listdir(validation_horse_dir)))\nprint('total validation human images:', len(os.listdir(validation_human_dir)))","b623d7db":"#horses pic\nrand_horse=np.random.randint(0,len(os.listdir(train_horse_dir)))\nhorse_pic=os.listdir(train_horse_dir)[rand_horse]\nprint('Horse picture title:',horse_pic)\n\nhorses_pic_address='\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/horses\/'+horse_pic\n\n#human pic\nrand_human=np.random.randint(0,len(os.listdir(train_human_dir)))\nhuman_pic=os.listdir(train_human_dir)[rand_human]\nprint('Human picture title:',human_pic)\n\nhumans_pic_address='\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/humans\/'+human_pic\n\n#Load the images\nhorse_load = Image.open(horses_pic_address)\nhuman_load = Image.open(humans_pic_address)\n\n#Lets plot the images\nf=plt.figure(figsize=(10,10))\n\na1=f.add_subplot(1,2,1)\nimg_plot=plt.imshow(horse_load)\na1.set_title('Horse')\n\na2=f.add_subplot(1,2,2)\nimg_plot=plt.imshow(human_load)\na2.set_title('Human')","94f4b8b8":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300,300,3)),#the input shape is the desired size of the image 300x300 with 3 bytes color\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),# Flatten the results to feed into a DNN\n    tf.keras.layers.Dense(512,activation='relu'),# 512 neuron hidden layer\n    tf.keras.layers.Dense(1,activation='sigmoid')# Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n])","7d67484e":"model.summary()","4be5d389":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=RMSprop(lr=0.001),\n             metrics=['accuracy'])","17aabcb8":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#augmentation on training, validation data\n\n# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_batch = train_datagen.flow_from_directory(\n                '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/train\/',# This is the source directory for training images\n                target_size=(300,300),# All images will be resized to 300x300\n                batch_size=128,\n    # Since we use binary_crossentropy loss, we need binary labels\n                class_mode='binary')\n\n# Flow training images in batches of 32 using validation_datagen generator\nvalidation_batch=validation_datagen.flow_from_directory(\n                '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/horse-or-human\/validation\/',# This is the source directory for validation images\n                target_size=(300,300),# All images will be resized to 300x300\n                batch_size=32,\n    # Since we use binary_crossentropy loss, we need binary labels\n                class_mode='binary')\n","76518028":"hist=model.fit(\n            train_batch,\n            steps_per_epoch=8,\n            epochs=15,\n            verbose=1,\n            validation_data=validation_batch,\n            validation_steps=8)","58ef2bb4":"#prediction=model.predict(validation_batch)\n#print(prediction)","97e396a6":"test_acc=model.evaluate_generator(validation_batch,steps=5)\nprint('the testing accuracy is:',test_acc[1]*100,'%')","3e18b1f1":"Let's find out the total number of horse and human images in the directories:","7f850db6":"Now let's take a look at a few pictures to get a better sense of what they look like","4ca0d392":"**Lets build the model**","0c873955":"**Data Preprocessing**\n\n\nLet's set up data generators that will read pictures in our source folders, convert them to float32 tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of images of size 300x300 and their labels (binary).\n\nData that goes into neural networks should usually be normalized in some way to make it more amenable to processing by the network. (It is uncommon to feed raw pixels into a convnet.) we will preprocess our images by normalizing the pixel values to be in the [0, 1] range (originally all values are in the [0, 255] range).\n\nIn Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class using the rescale parameter. This ImageDataGenerator class allows us to instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs: fit, evaluate_generator, and predict_generator.","fe9fa2bb":"**Training**\n\nThe Loss and Accuracy are a great indication of progress of training. It's making a guess as to the classification of the training data, and then measuring it against the known label, calculating the result. Accuracy is the portion of correct guesses. ","3d0f3d9c":"Let's define the directories","19bd572b":"We add convolutional layers and flatten the final result to feed into the densely connected layers, we add the densely connected layers.\n\nNote that because we are facing a two-class classification problem, i.e. a binary classification problem, we will end our network with a sigmoid activation, so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0).\n"}}