{"cell_type":{"0029b4f5":"code","42f292fc":"code","a8cb9894":"code","71737c90":"code","23f16dba":"code","4b2c1fd9":"code","8ecbb6f2":"code","eb211da8":"code","f2b1c961":"code","d979954e":"code","83d4bef6":"code","9eecdf60":"code","9256ce37":"code","0aa0670a":"code","24689820":"code","b93b1f3f":"code","9c461408":"code","104cca25":"code","0451ab64":"code","37b18a86":"code","9929c24a":"code","17412c97":"code","2311d32d":"code","da95ea34":"markdown","415951d7":"markdown","5ad563c3":"markdown","f96a6d7a":"markdown","aedd69ef":"markdown","a67c09d5":"markdown","946253ef":"markdown","ae5bc39f":"markdown","34edde2a":"markdown","47f80d12":"markdown","a07bad7c":"markdown"},"source":{"0029b4f5":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport os\nimport zipfile\nimport random\nimport shutil\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nfrom os import getcwd\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","42f292fc":"\nprint(os.listdir(\"..\/input\"))\n\npath_cats_and_dogs = \"..\/input\/dogs-vs-cats\/train.zip\"\n#shutil.rmtree('\/tmp')\n\nlocal_zip = path_cats_and_dogs\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('.')\nzip_ref.close()\n","a8cb9894":"path_cats_and_dogs = \"..\/input\/dogs-vs-cats\/test1.zip\"\n#shutil.rmtree('\/tmp')\n\nlocal_zip = path_cats_and_dogs\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('.')\nzip_ref.close()","71737c90":"try:\n    main_dir = \"\/kaggle\/working\/\"\n    train_dir = \"train\"\n    val_dir = \"val\"\n\n    train_dir = os.path.join(main_dir,train_dir)\n    # Directory with our training cat\/dog pictures\n    train_cats_dir = os.path.join(train_dir, 'cats')\n    train_dogs_dir = os.path.join(train_dir, 'dogs')\n    os.mkdir(train_cats_dir)\n    os.mkdir(train_dogs_dir)\n    # Directory with our validation cat\/dog pictures\n    val_dir = os.path.join(main_dir,\"val\")\n    os.mkdir(val_dir)\n    val_cats_dir = os.path.join(val_dir, 'cats')\n    val_dogs_dir = os.path.join(val_dir, 'dogs')\n    os.mkdir(val_cats_dir)\n    os.mkdir(val_dogs_dir)\n\nexcept OSError:\n    pass","23f16dba":"##let's put the cats images in the cats directory and the dogs in the dogs directory\n# for the train directory we parse the jpg name if the name start with cat we put it in the cats dir\nmain_dir = \"\/kaggle\/working\/\"\ntrain_dir = \"train\"\ntrain_path = os.path.join(main_dir,train_dir)\n\nprefixed_dogs = [filename for filename in os.listdir(train_path) if filename.startswith(\"dog.\")]\nprint(len(prefixed_dogs))\nprefixed_cats = [filename for filename in os.listdir(train_path) if filename.startswith(\"cat.\")]\nprint(len(prefixed_cats))\n\ndef move_files(src_file):\n    \n    for filename in prefixed_dogs:\n        shutil.move(src_file+filename, src_file+'dogs\/'+filename)\n        \n    for filename in prefixed_cats:\n        shutil.move(src_file+filename, src_file+'cats\/'+filename)\n    \n\nmove_files(\"\/kaggle\/working\/train\/\")\n\n\n\n","4b2c1fd9":"print(len(os.listdir('\/kaggle\/working\/train\/dogs')))\nprint(len(os.listdir('\/kaggle\/working\/train\/cats')))\nprint(len(os.listdir('\/kaggle\/working\/train')))\n","8ecbb6f2":"def split_data(SOURCE, VALID, SPLIT_SIZE):\n# This funtion takes as argument:\n###SOURCE : the directory's path of images that will be splitted\n###VALID : the directory's path of the validation receiving the dogs or the cats images\n###SPLIT_SIZE: the size of the split. 0.9 means 90% of cats images will remain in train\/cats and 10% will be moved to the validation directory's cats \n###and the same will be done to the dogs images\n    SRC_files = [f for f in os.listdir(SOURCE) if os.path.isfile(os.path.join(SOURCE, f))]\n    SRC_Size = len(SRC_files)\n    #print(SRC_Size)\n    if SRC_Size != 0:\n        # we shuffle the images before the split\n        shuffled_files = random.sample(SRC_files, len(SRC_files))\n        #print(\"shuffled\")\n        TRN_size = int(SRC_Size * SPLIT_SIZE)\n        VAL_SIZE = int(SRC_Size - TRN_size)\n        print(TRN_size)\n        train_set = shuffled_files[0:TRN_size]\n        val_set = shuffled_files[-VAL_SIZE:SRC_Size]\n        for filename in val_set:\n            if os.path.getsize(SOURCE+filename)!=0:\n                shutil.move(SOURCE+filename, VALID+filename)\n            else:\n                print(filename + ' is zero length. So ignoring!')\n                pass\n\n\n                    \nCAT_SOURCE_DIR = \"\/kaggle\/working\/train\/cats\/\"\nTESTING_CATS_DIR = \"\/kaggle\/working\/val\/cats\/\"\n\nDOG_SOURCE_DIR = \"\/kaggle\/working\/train\/dogs\/\"\nTESTING_DOGS_DIR = \"\/kaggle\/working\/val\/dogs\/\"\n\nsplit_size = .9\nsplit_data(CAT_SOURCE_DIR, TESTING_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TESTING_DOGS_DIR, split_size)","eb211da8":"print(len(os.listdir('\/kaggle\/working\/train\/dogs')))\nprint(len(os.listdir('\/kaggle\/working\/train\/cats')))\nprint(len(os.listdir('\/kaggle\/working\/train')))\nprint(len(os.listdir('\/kaggle\/working\/val\/dogs')))\nprint(len(os.listdir('\/kaggle\/working\/val\/cats')))","f2b1c961":"# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n# USE AT LEAST 3 CONVOLUTION LAYERS\nIMAGE_WIDTH=150\nIMAGE_HEIGHT=150\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n\nmodel = tf.keras.models.Sequential([\n# YOUR CODE HERE\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'), \n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])\n\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])","d979954e":"TRAINING_DIR = '\/kaggle\/working\/train'\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\n#       rotation_range=40,\n#       width_shift_range=0.2,\n#       height_shift_range=0.2,\n#       shear_range=0.2,\n#       zoom_range=0.2,\n#       horizontal_flip=True,\n#       fill_mode='nearest')#YOUR CODE HERE\n\n# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n# TRAIN GENERATOR.\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=10,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))\n\nVALIDATION_DIR = '\/kaggle\/working\/val'#YOUR CODE HERE\nvalidation_datagen = ImageDataGenerator( rescale = 1.0\/255. )#YOUR CODE HERE\n\n# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n# VALIDATION GENERATOR.\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                         batch_size=10,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))\n\n\n\n","83d4bef6":"history = model.fit_generator(train_generator,\n                              epochs=2,\n                              verbose=1,\n                              validation_data=validation_generator)","9eecdf60":"model.save_weights(\"model.h5\")","9256ce37":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')","0aa0670a":"test = os.listdir('\/kaggle\/working\/test1')\nprint(type(test))\n\n# preprocessing test\nTEST_DIR  = '\/kaggle\/working\/test1'\ntest_df = pd.DataFrame({'filename': test})\n\nnb_samples = test_df.shape[0]\n\ntest_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    TEST_DIR, \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=(150,150),\n    batch_size = 10\n)\n\n\n\n","24689820":"test_df","b93b1f3f":"predict = model.predict_generator(test_generator)","9c461408":"predict[2]","104cca25":"test_df['prediction'] = predict","0451ab64":"\ntest_df","37b18a86":"from keras.preprocessing.image import ImageDataGenerator, load_img\nimport matplotlib.pyplot as plt\nimg = load_img('\/kaggle\/working\/test1\/10392.jpg', target_size=(150,150))\nplt.imshow(img)","9929c24a":"submission_df = test_df.copy()","17412c97":"submission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df[\"label\"] =  np.where(submission_df['prediction'] >0.7, 1, 0)\nsubmission_df.drop(['filename','prediction'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df\n","2311d32d":"submission_df.to_csv('submission.csv', index=False)","da95ea34":"you can change the test image path to check if the prediction is correct","415951d7":"We'll next create a cats and dogs directories for the train data and the validation data. Here down I created this:\ntrain->dogs - cats\nval -> dogs - cats\n","5ad563c3":"We will use the ImageDataGenerator to handle the images but without any augmentation","f96a6d7a":"So now let's build our model. It will be a simple one with three layers of conv2d and Maxpooling. We will finish by a Dense layer with sigmoid activation to have the probabilities.","aedd69ef":"Let's see what our predictions look like","a67c09d5":"So now we've got a directory train with two subdirectory cats and dogs and a validation directory that is, at this point, empty. Let's split our training data.\nTo do that I created the split function. \n","946253ef":"Now let's put the test images into the datagenertor so we could predict.","ae5bc39f":"The training images has the classification in their name. Dogs images names is built like this: dog.number.jpg and cat's : cat.number.jpg \nSo to classify the files we will create two lists one for dogs files and another for cats files. thanks to the shutil library we will move the files to the according directories in train.","34edde2a":" We extract the test images","47f80d12":" We extract the train images","a07bad7c":"This notebook is a simple walkthrough a binary classification.  I'll try to make the model better in a next notebook."}}