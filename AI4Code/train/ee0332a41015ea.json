{"cell_type":{"cd4dbb25":"code","d668cde0":"code","d77615f6":"code","19fec535":"code","fcc26df3":"code","5ee54cf7":"code","628a5203":"code","67a98517":"code","2ad2c447":"code","986b3a10":"code","b2e53223":"code","f88c23eb":"code","07dc09f0":"code","05839338":"code","9be1a214":"code","341a0b62":"code","d90faab3":"code","b2244e6e":"code","dd77a9cb":"code","c1207315":"code","3c1a93b8":"code","b8a84b64":"code","5cf4b738":"code","e420041c":"markdown","ad9a0188":"markdown","438702ed":"markdown","03cfb094":"markdown","c5bd4057":"markdown","ed0e7ac0":"markdown","1706cd2c":"markdown","fd9002b6":"markdown"},"source":{"cd4dbb25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d668cde0":"# Load the dataset\ndf_2009_2010 = pd.read_excel(\"..\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\", sheet_name = \"Year 2009-2010\")\ndf_2010_2011 = pd.read_excel(\"..\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\", sheet_name = \"Year 2010-2011\")","d77615f6":"# Concatenate the data frames of two years\ndf_concat = pd.concat([df_2009_2010,df_2010_2011],axis=0,ignore_index=True)\n# Copy the dataset for pre-precessing\/analytics\ndf=df_concat.copy()","19fec535":"# 1.Eyeball the data\ndf.head()","fcc26df3":"df.info()","5ee54cf7":"# 2. Check if there is records with Null values\nprint(f\"Fields with null values:\\n{df.isnull().any()}\")\n# Null values in CustomerID: some orders may purchased by non-member-> no Customer No.?","628a5203":"# 3. For the purpose of RFM analysis, drop the order without customer ID (this customers are not trackable)\ndf.drop(index = df[df['Customer ID'].isnull()].index, inplace = True)\nprint(f\"Fields with null values:\\n{df.isnull().any()}\")","67a98517":"# 4. Detact the abnormal records (Invoice start with 'C', but not a cancellation invocie, and vice verer)\nprint(\"Any invoice starts with 'C' but is not a cancelation order ?\",((df[df['Invoice'].str.startswith(\"C\",na=False)]['Quantity']) > 0).any())\nprint(\"Any invoice not starts with 'C' but is a cancelation order ?\", ((df[df['Invoice'].str.startswith(\"C\",na=False) == False]['Quantity']) < 0).any())","2ad2c447":"# 5. Calculate the sales amount of each order \/ Indicated whether the order is cancelled (chargeback) \/ turn Customer ID into INT\ndf['Sales'] = df['Quantity']*df['Price']\ndf['Chargeback'] = df['Invoice'].str.startswith(\"C\",na=False) # show False (na=False) if element tested is not start with C (not a string).\ndf['Customer ID'] = df['Customer ID'].astype(int)","986b3a10":"# 6. Present the cleaned table\nprint(\"Show cleaned data set\")\ndf.head()\n# df.info()","b2e53223":"import matplotlib.pyplot as plt\nimport datetime\nimport calendar\n%matplotlib inline","f88c23eb":"# Navigate the sales trend over months\ndf['Month']=df['InvoiceDate'].dt.month\ndf_plot=df.loc[:,['Sales','Month','Chargeback']].sort_values(by=['Month'])\n# Prepare the data: Calculate the sales and chargeback amount\nx=df_plot.Month.unique()\ny1=df.groupby('Month')['Sales'].sum().values\/1e6\ny2=df[df.Chargeback==True].groupby('Month').Sales.sum().values\/-1e6","07dc09f0":"# Sales trend Figure:\n#1 Figure name and size\nf1=plt.figure(figsize=(16,8))\nplt.gcf()\n#2 Grid\nplt.grid(alpha=0.4)\nplt.axis=([0,10,0,10])\n# plt.xlim(0.5,12.5)\nplt.ylim(-.2,3)\n# 3 coordinate,tick scale\/tick label\/label rotation\/font size\nplt.xticks(x,rotation = 0.1,fontsize=16)\nplt.xlabel('Months',fontsize=16)\nplt.yticks(fontsize=16)\nplt.ylabel(u'Total Sales (Minion \\u00a3)',fontsize=16)\n#4 plot y axis(#0022FF rgb(0,255))\nplt.plot(x,y1,label='Sales Amount',color=\"blue\",marker='o',markersize=10)\nplt.plot(x,y2,label='Chargeback',color=\"red\",marker = 'x',markersize=10)\n#5 Legend#\nplt.legend(loc='upper left',fontsize=20)\n#6 Corrdinate showpoints\nfor a,b in zip(x,y1):\n    plt.annotate('%.2f'%(b),xy=(a,b),xytext=(-15,15),textcoords='offset points',fontsize=12)\nfor a,b in zip(x,y2):\n    plt.annotate('(%.2f)'%(b),xy=(a,b),xytext=(-15,15),textcoords='offset points',fontsize=12)    \nplt.show()\nplt.clf()","05839338":"# 1.Only consider the non-chargeback orders when establishing the RFM models\ndf_C=df[df['Chargeback']==False]","9be1a214":"# 2. An invoice is ordered at certain time, which can include several products -> Group the invoice and create a pivot table\ntable=df_C.pivot_table(index=['Invoice'],values=['InvoiceDate','Customer ID','Sales'],aggfunc={'InvoiceDate':'first','Customer ID':'first','Sales':'sum'})\ntable.head()","341a0b62":"# 3. Group the customer ID to form a RFM table\ntable.rename(columns={'InvoiceDate':'R','Sales':'M'},inplace=True)\ntable['F'] = 1\ntable_RMF=table.pivot_table(index=['Customer ID'],values=['R','M','F'],aggfunc={'R':'max','M':'sum','F':'count'})\n# 4. Normalised the recency, using the most recent day in the data set as the reference day\ntable_RMF['R']=(table_RMF['R'].max()-table_RMF['R']).dt.days\ntable_RMF.head()\n# 5. Ignore the one off customers\ntable_RMF.drop(index=table_RMF[table_RMF['F']==1].index, inplace = True)","d90faab3":"# 5. Simple Statistic analysis on the RFM table\ntable_RMF.describe()\n# 4314 customers: F: Frequency (no. of orders), M: Monetary (UK Pound), Recency (days)","b2244e6e":"# End. Write the table into excel files for further analytics in Tableau\n# df.to_csv('customer_segmentation.csv', index = True)\ntable_RMF.to_csv('RMF_table.csv',index = True)","dd77a9cb":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans","c1207315":"#1 Standardise the data in RFM table\nnp.random.seed(42)\ndf_std=StandardScaler()\ndf_std=df_std.fit_transform(table_RMF)\nx=df_std[:,0]\ny=df_std[:,1]\nz=df_std[:,2]","3c1a93b8":"#2 K-means clustering\nkm=KMeans(n_clusters=6)\nres=km.fit(df_std)\nclusterNo=res.predict(df_std)","b8a84b64":"#3 Show the number of customers in each segment\n# table_RMF['clusterNo']=clusterNo\nseg,segNo=np.unique(clusterNo,return_counts=True)\nprint(seg,'\\t',segNo) ","5cf4b738":"# Plot the 3D clustering results\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nf1=plt.figure(figsize=(16,8))\nax1 = f1.add_subplot(111, projection='3d')\nax1.set_xlabel('Recency',size=16)\nax1.set_ylabel('Frequency',size=16)\nax1.set_zlabel('Monetary',size=16)\nax1.scatter(x,y,z,c=clusterNo,cmap='plasma')","e420041c":"## 3a. Data Analytics","ad9a0188":"## 1. System setup\/Loading dataset","438702ed":"# Business Analytics: Customer Segmentation on Online Retail Transaction Data\n**Data Source: https:\/\/www.kaggle.com\/mathchi\/online-retail-ii-data-set-from-ml-repository**\n\n**Data Analytics Created by Tableau can be viewed at:**\n\nhttps:\/\/public.tableau.com\/profile\/minli.yu4995#!\/vizhome\/UK_MY\/SalesAnalysisrofaUKOn-lineStore\n\n**Note:** \n\nAn Online Retail data set contains all the transactions occurring for a UK-based and registered, non-store online sales between 01\/12\/2009 and 09\/12\/2011. The company mainly sells unique all-occasion gift-ware. Many customers of the company are wholesalers.**\n\n**Attribute Information provided by the dataset:** \n\n* InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation.\n* StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product.\n* Description: Product (item) name. Nominal.\n* Quantity: The quantities of each product (item) per transaction. Numeric.\n* InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated.\n* UnitPrice: Unit price. Numeric. Product price per unit in sterling (\u00c2\u00a3).\n* CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer.\n* Country: Country name. Nominal. The name of the country where a customer resides.","03cfb094":"# Summary of Customer Segmentation\n\n* Seg 1 : Navy: Low Recency, Low ~ Medium Frequency, High Monetary ->  Best Customers (Monetatry is the dominant factor)\n* Seg 2 : Orange: Low Recency, Low Frequency, Medimum Monetary -> High-spending Active Loyal Customers \n* Seg 3 : Purple: Low to Medium Recency, Low Frequency, Low Monetary -> Low-Spending Active Loyal Customers\n* Seg 4 : Red: Medium, Low ~ Medium Frequency, Low to Medium Monetary -> Churning Customers\n* Seg 5 : Yellow: High recency, Medium Frequency, low Monetary ->retail customers\n* Seg 6 : Pink: High recency,High Frequency, Low Monetary  ->retail customers\n* Note: Segments 1 to 4 are wholesaler while 5 to 6 are very likey retail customers (they ordered frequently with small amount)  \n","c5bd4057":"* It showed that the sales amount started to increase from Auguest. \n* It reached a maximum at November and dropped down a little bit at November. \n* This make sense since all customers tended to order their stocks for Christmas sale proactively.\n* It is not suprised that the sales amount dramatically declined in January.","ed0e7ac0":"## 4. Established a k-means clustering model\n\nclass sklearn.cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=None, algorithm='auto')","1706cd2c":"## 3b. Data analytics: RFM Model","fd9002b6":"## 2. Pre-process the dataset"}}