{"cell_type":{"5260a7d4":"code","ccb7cfb5":"code","f5f04b0d":"code","906e33c8":"code","7bfe395b":"code","58bebff5":"code","d6bd877b":"code","c6046a5d":"code","7ee5864a":"code","e91c2eaa":"code","382edb52":"code","133dcf95":"code","4181e0dc":"code","11c77f9d":"code","e4a53c80":"code","b67fbd05":"code","0aac9906":"code","04da2558":"code","0dd9c53e":"code","3b6543b2":"code","b21c4843":"code","501edb06":"code","626b7bb9":"code","99531a72":"code","c7bd9147":"code","205ba7c9":"code","cacb0e7c":"code","53289787":"code","4065aeb0":"code","0c002b68":"code","66059d85":"code","22e6d7ad":"code","6444e13d":"code","3047376b":"code","14fe5e0d":"code","594f592b":"code","87270469":"code","164eed1f":"code","f377fb53":"code","6c954c27":"markdown","3572d7af":"markdown","d885fc95":"markdown","4cea89b7":"markdown","8a19cea3":"markdown","b83f668b":"markdown","9568d0a4":"markdown","71ed8582":"markdown","0b906782":"markdown","6fd205ea":"markdown","33f3fed4":"markdown","5b2ee02c":"markdown","a35c5e21":"markdown","709f3d04":"markdown","cd89d109":"markdown","83d84792":"markdown","44c1e22e":"markdown","e808850b":"markdown","160317e3":"markdown","2be9f798":"markdown","24b63fee":"markdown","ef2755ec":"markdown","918df027":"markdown","e221eed8":"markdown","2bc8721b":"markdown","0324dbdd":"markdown"},"source":{"5260a7d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ccb7cfb5":"# importing libraries for visualization\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use(\"ggplot\")","f5f04b0d":"df = pd.read_csv('\/kaggle\/input\/social-network-ads\/Social_Network_Ads.csv')","906e33c8":"# Shape of Data\n\ndf.shape","7bfe395b":"# datatype of df\ndf.info()","58bebff5":"# contents of Df\ndf.head()","d6bd877b":"# lets remove the columns User ID from our dataset\ndf.drop(\"User ID\", axis = 1, inplace = True)","c6046a5d":"# Statistical Summary\n\ndf.describe()","7ee5864a":"# Lets check the skewness of our features\n\ndf['Age'].skew()","e91c2eaa":"df['EstimatedSalary'].skew()","382edb52":"sns.histplot(df['Age'],kde=True,color='brown',bins=20)\nplt.show()","133dcf95":"sns.histplot(df['EstimatedSalary'],kde=True,color='violet',bins=20)\nplt.show()","4181e0dc":"# Lets check the Target Variable\n\nsns.countplot(x='Purchased', data = df)\nplt.show()","11c77f9d":"df['Purchased'].value_counts()","e4a53c80":"ratio_of_purchaser = 143\/400\nratio_of_purchaser","b67fbd05":"# Lets check the gender ratio in our dataset\nsns.countplot(x='Gender', data= df)\nplt.show()","0aac9906":"plt.figure(figsize=(10, 3))\nsns.catplot(x='Purchased', col='Gender', kind='count', data=df,palette=\"husl\");\nplt.show()","04da2558":"sns.pairplot(df , hue = 'Purchased',palette='CMRmap_r',corner=True )","0dd9c53e":"df.corr()","3b6543b2":"sns.heatmap(df.corr(), annot = True, cmap = 'CMRmap' )\nplt.show()","b21c4843":"df = pd.get_dummies(df, columns = ['Gender'], drop_first=True)","501edb06":"df.head()","626b7bb9":"X = df.drop(\"Purchased\", axis = 1)\ny = df['Purchased']","99531a72":"# importing library for further spliting of dataset into train and test for Algorithm\n\nfrom sklearn.model_selection import train_test_split","c7bd9147":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.25, random_state = 100)","205ba7c9":"# importing library for feature scaling\nfrom sklearn.preprocessing import StandardScaler","cacb0e7c":"# saving the columns name in one variable for further use\n\ncol = X.columns","53289787":"# initializing the StandardScaler\nsc = StandardScaler()\n\n# fit & transform of train and test data\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# converting X_train and X_test into dataframe\n\nX_train = pd.DataFrame(X_train, columns = col)\nX_test = pd.DataFrame(X_test, columns = col)","4065aeb0":"# importing KNN\nfrom sklearn.neighbors import KNeighborsClassifier","0c002b68":"# initializing of KNN\n\nknn_classifier = KNeighborsClassifier(n_neighbors=5,metric = 'minkowski', p=2)\n\n# model fitting & training\nknn_classifier.fit(X_train, y_train)\n\n","66059d85":"# Prediction\n\ny_pred = knn_classifier.predict(X_test)","22e6d7ad":"# Comparing true and predicted value using plot\nc = [i for i in range(1,len(y_test)+1,1)]\nfig = plt.figure()\n#Plotting Actual\nplt.plot(c,y_test, color = 'blue', linewidth = 1.5, linestyle = \"-\")\n#Plotting predicted\nplt.plot(c, y_pred, color = 'red', linewidth = 1.5, linestyle = \"-\")\n# Plot heading \nfig.suptitle('Actual and Predicted', fontsize = 20)\n# X-label\nplt.xlabel('No. of samples ', fontsize = 18)\n# Y-label\nplt.ylabel('Values', fontsize = 16)\n#showing the plot\nplt.show()","6444e13d":"# importing of Evaluation metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report,recall_score,precision_score","3047376b":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)","14fe5e0d":"ac = accuracy_score(y_pred,y_test)\nprint(ac)","594f592b":"print(classification_report(y_test,y_pred))","87270469":"# try K=1 through K=25 and record testing accuracy\nk_range = np.arange(1,26)\n\n# empty list to append scores\nscores = []\n\n# loop through k_range\nfor k in k_range:\n    \n    #Initiate KNN with n_neighbors as k\n    knn = KNeighborsClassifier(n_neighbors = k, p=2)\n    \n    #Fitting model on training data\n    knn.fit(X_train,y_train)\n    \n    #Predict on X_test\n    y_pred1 = knn.predict(X_test)\n    \n    # We append the scores in the dictionary in list\n    scores.append(\"{:.2f}\".format(accuracy_score(y_pred1,y_test)))\n\n    \n#print scores\nprint(scores)","164eed1f":"# plot the relationship between K and testing accuracy\nfig = plt.figure()\n\nplt.plot(k_range, scores, color = 'green', linewidth = 1.5, linestyle = \"-\")\n# X-label\nplt.xlabel('Value of k for KNN', fontsize = 18)\n# Y-label\nplt.ylabel('Testing Accuracy', fontsize = 16)\n#showing the plot\nplt.show()","f377fb53":"print(classification_report(y_test,y_pred1))","6c954c27":"# Statistical Analysis","3572d7af":"### Feature Scaling","d885fc95":"From above graph, we can conclude that **Age** is dense around 38 to 40\nand\n**EstimatedSalary** is between 70-90 K","4cea89b7":"We have total 400 rows and 5 columns, Out of 5 columns UserId is not of any use, so we can drop that.\nGender columns has two attribute Male & Female. Our Target Column is Purchased with values of 0 and 1.\nThere is no missing value in our dataset.\n\nLets dive deep to find more about the statistical part of data","8a19cea3":"Before feeding features to algorithm, it is a best practice to bring all the values of features in one scale, in order to decrease the chances of bisness.\nWe will use Standard Scaler method to perform feature scaling","b83f668b":"Approx 35% of the vistors purchesed after clicking the advertisment","9568d0a4":"### Encoding Categorical Data","71ed8582":"### Analysis of Target Variable with Gender","0b906782":"### KNN - K Nearest Neighbour\nfor our model we will use KNN","6fd205ea":"### Pair Plot","33f3fed4":"So, Age is correlated with Purchased as per above analysis.","5b2ee02c":"#### Lets find out the Correlation and also visualize the correlation matrix for better understanding","a35c5e21":"# General Investigation of Data","709f3d04":"# Importing Libraries and Reading Data","cd89d109":"Well though our model seems performing pretty good with 92% accuracy\n\nCan we locate an even better value for K?","83d84792":"From above output, We can say that **Age** is spread between 18 to 60, with an average of 37.65 and Std Dev of 10.48\n&\n**Estimated Salary** between 15000 to 150,000, with an average of 69,742.50 and Std Dev of 34,096.96.","44c1e22e":"Training accuracy rises as model complexity increases\nTesting accuracy penalizes models that are too complex or not complex enough\nFor KNN models, complexity is determined by the value of K (lower value = more complex)","e808850b":"In our dataset, Gender column is only categorical value,and we need to conver it to numerical value, before feeding it to Algorithm.\nWe will use Pandas dummy variable method of encoding","160317e3":"### Spliting of Dataset ","2be9f798":"### Accuracy","24b63fee":"# Univariate Analysis","ef2755ec":"### Evaluation of Model","918df027":"# Bivariate Analysis","e221eed8":"### Confusion Metrics","2bc8721b":"It Looks Like Female customer make purchase more than Male customer.\nIsn't it normal. Jokes apart.","0324dbdd":"Any K value between 5 to 13 is good for the Model."}}