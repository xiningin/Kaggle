{"cell_type":{"379081a2":"code","bb5cb37a":"code","26ee259c":"code","7fbd7172":"code","18b861ca":"code","b5b64a17":"code","f238d3f7":"code","9469b85d":"code","e447a144":"code","bd91e49e":"code","6d2e90ce":"code","214654bb":"code","2136170c":"code","58889f4e":"code","6d226030":"code","93231a63":"code","53226b4a":"code","445d73d6":"code","cb573855":"code","52db1e68":"code","b82ced96":"code","743cc731":"markdown","43f8b6e1":"markdown","3770b59e":"markdown","56c1c317":"markdown","e8f4d9fe":"markdown"},"source":{"379081a2":"!pip install fastai==2.5.1","bb5cb37a":"from fastai.vision.all import *\nimport fastai\nimport random\nimport PIL","26ee259c":"## For experimenting purpose, only type 'T1W' is chosen and sequence with more than 16 images\nmri_type = 'T1w'\nmin_subset = 16\npatients_seq_folder = [patient\/mri_type for patient in Path('..\/input\/rsna-miccai-png\/train').ls() if (patient\/mri_type).exists() and len((patient\/mri_type).ls()) > min_subset]","7fbd7172":"patients_seq_folder[:5]","18b861ca":"labels = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')\nlabels.head()","b5b64a17":"def open_image(fname, size=224):\n    img = PIL.Image.open(fname)\n    img = img.resize((size, size))\n    t = torch.Tensor(np.array(img))\n    return t.float()\/255.0","f238d3f7":"class SeqImage(fastuple):\n    def show(self, ctx=None, **kwargs):\n        *imgs, label = self\n        if not isinstance(imgs[0], Tensor):\n            imgs = [tensor(img).permute(2,0,1) for img in imgs]\n        img_cat = torch.cat(imgs, dim=2)\n        return show_image(img_cat, figsize=(20,20), title=label, ctx=ctx, **kwargs)","9469b85d":"# splits the data to training set and validation set\nsplits = RandomSplitter()(patients_seq_folder)","e447a144":"train_folders, valid_folders = L(patients_seq_folder)[splits[0]], L(patients_seq_folder)[splits[1]]","bd91e49e":"files_test = train_folders[0].ls()[:16]","6d2e90ce":"imgs_label = [PILImage.create(file) for file in files_test]\nimgs_label.append(0)","214654bb":"s = SeqImage(imgs_label)","2136170c":"tst = Resize(224)(s)\ntst = ToTensor()(tst)\ntst.show();","58889f4e":"class SeqTransform(Transform):\n    def encodes(self, folder):\n        files = folder.ls()\n        files = sorted(random.sample(files, min_subset), key=lambda path: int(path.stem.split('-')[1]))\n        imgs = [PILImage.create(file) for file in files]\n        label = labels[labels['BraTS21ID']==int((folder).parent.name)]['MGMT_value'].values[0]\n        return SeqImage(*imgs, label)","6d226030":"tfm = SeqTransform()","93231a63":"tls = TfmdLists(patients_seq_folder, tfm, splits=splits)\n","53226b4a":"show_at(tls.valid, 3);","445d73d6":"dls = tls.dataloaders(after_item=[Resize(224), ToTensor], \n                      after_batch=[IntToFloatTensor])","cb573855":"@typedispatch\ndef show_batch(x:SeqImage, y, samples, ctxs=None, max_n=6, nrows=None, ncols=1, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*6, max_n\/\/ncols * 3)\n    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)\n    for index,ctx in enumerate(ctxs): \n        imgs_ls = [x[i][index] for i in range(min_subset)]\n        label = int(x[-1][index])\n        SeqImage(*imgs_ls, label).show(ctx=ctx)","52db1e68":"b = dls.one_batch()","b82ced96":"dls.show_batch(figsize=(20,20))","743cc731":"Define a show_batch function as below to make show_batch works. x is a batch of SeqImage item","43f8b6e1":"To help fastai know how to show your batch, each item (including x and y) need to be an instance of a class which has a *show* function. And by subclassing fastuple, fastai will know how to apply the transformation for each element based on their type (For example applying Resize on to PILImage and not the string)","3770b59e":"We will try to show an SeqImage as below","56c1c317":"### Introduction\nThis notebook is to introduce how to build a customize fastai's DataLoader for a task with item is sequence of images (MRI Images, Video, ...) \n\nWith fastai's DataLoader, you can leverage many of the neat fastai functionalities like *item transformation* or *batch transformation* or my favorite part: *show batch*. This great feature help you to visualize how your raw data is tranformed to the input of your model, and it is especially helpful to debug or present to others. \n\nYou can checkout the official tutorial for *Using fastai on a custom new task* here: https:\/\/docs.fast.ai\/tutorial.siamese.html","e8f4d9fe":"Then encodes function in Transform class used to apply the transformation to each item (similar to *forward* in Pytorch modules) "}}