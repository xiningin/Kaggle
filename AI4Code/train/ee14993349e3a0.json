{"cell_type":{"86264e17":"code","d030b2ca":"code","c4c97d12":"code","d98a6f13":"code","990fc018":"code","d2ee5245":"code","6a675fa5":"markdown","8c822a47":"markdown","6d323641":"markdown","4dc3b3f7":"markdown","b3c48d91":"markdown"},"source":{"86264e17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D\nfrom tensorflow.keras.optimizers import Adadelta\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nimport pandas as pd\nimport numpy as np\nimport os\n","d030b2ca":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","c4c97d12":"train.head()","d98a6f13":"mnist_train_data = train.loc[:, \"pixel0\":]\nmnist_train_label = train.loc[:, \"label\"]\n\nmnist_train_data = mnist_train_data\/255.0\nmnist_test = test\/255.0\n\nmnist_train_data = np.array(mnist_train_data)\nmnist_train_label = np.array(mnist_train_label)\n\nmnist_train_data = mnist_train_data.reshape(mnist_train_data.shape[0], 28, 28, 1)\n\nnclasses = mnist_train_label.max() - mnist_train_label.min() + 1\nmnist_train_label = to_categorical(mnist_train_label, num_classes = nclasses)","990fc018":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size = 4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel_history = model.fit(mnist_train_data, mnist_train_label, shuffle=True, batch_size=200, epochs=100, validation_split=0.2)\nmodel.save(\"digit.model\")","d2ee5245":"model = tf.keras.models.load_model(\"digit.model\")\n\nmnist_test_arr = np.array(mnist_test)\nmnist_test_arr = mnist_test_arr.reshape(mnist_test_arr.shape[0], 28, 28, 1)\npredictions = model.predict(mnist_test_arr)\npredictions_test = []\n\nfor i in predictions:\n    predictions_test.append(np.argmax(i))\nsubmission =  pd.DataFrame({\n        \"ImageId\": mnist_test.index+1,\n        \"Label\": predictions_test\n    })\n\nsubmission.to_csv('final_submission.csv', index=False)\n","6a675fa5":"Let's see how the data looks like using pandas.","8c822a47":"First of all we make all the necessary imports and then lets load the files\n","6d323641":"Now prepare the data to be given to the model","4dc3b3f7":"Let's make the model now","b3c48d91":"The above model gets saved in the output directory of kaggle.\nTo make predictions let's load the model and predict and save the predictions in a csv file."}}