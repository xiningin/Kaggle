{"cell_type":{"cebbb2fa":"code","ecbf5edc":"code","2fea4a06":"code","40b80845":"code","68cf484f":"code","504b645d":"code","cc9ce63c":"code","a2ba63a8":"code","05e92b7f":"code","90dc6bc4":"code","d77d7ea6":"code","0b094654":"code","8d1c0160":"code","13a96e54":"code","d8a0569e":"code","be0c10e1":"code","7f8828a5":"code","259ac376":"code","78caf1a6":"code","4795944a":"code","59eddb69":"code","2a6ed6a7":"code","8dca741e":"code","852e2320":"code","73b715fc":"code","133f8687":"code","59dc0e4a":"code","4fb9b38e":"code","32b6f0ec":"code","430a768a":"code","3144296b":"code","9ec70985":"code","3e909093":"code","1fdf0755":"code","c5e4816b":"code","0f3f777d":"code","3796945c":"code","bce686dd":"code","3ac6e105":"code","51d0bf2d":"code","b3426b7e":"code","62b02e29":"code","6ff79b63":"code","b91ca7d6":"code","7229fa55":"code","b9672761":"code","70cabe87":"code","ae5f509a":"code","695904eb":"code","607e13b9":"code","de4dc0cd":"code","e0c6b479":"code","c6ac4353":"code","6b47fc7d":"code","fdc960f2":"markdown","82aee91c":"markdown","8aca01ad":"markdown","7740b260":"markdown","3b9c736e":"markdown","eeb12886":"markdown","9b4edc2c":"markdown","d9363181":"markdown","96fdf715":"markdown","3456b6ab":"markdown","9ce2270b":"markdown","16c00c4b":"markdown","5743795d":"markdown","f6c5be70":"markdown","1787ea5b":"markdown"},"source":{"cebbb2fa":"!nvidia-smi","ecbf5edc":"# \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435 tensorflow\n!pip install tensorflow --upgrade\n# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 efficientnet\n!pip install -q efficientnet\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043e\u0431\u0432\u044f\u0437\u043a\u0443 \u043f\u043e\u0434 keras \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, albuminations\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor","2fea4a06":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau,\\\n                                       Callback, ModelCheckpoint, EarlyStopping\n\nfrom tensorflow.keras import optimizers\n\nimport tensorflow.keras.models as Model\nfrom tensorflow.keras.models import Sequential\n\nimport tensorflow.keras.layers as Layer\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\\\n                                    BatchNormalization\n\nfrom tensorflow.keras.regularizers import l2\n\n#from keras.utils import np_utils\n#from keras.applications.xception import Xception\n\n#import tensorflow.keras.backend as K\n#import tensorflow.keras.callbacks as C\n\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","40b80845":"# \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u0432\u0435\u0440\u0441\u0438\u0438 \u043f\u0430\u043a\u0435\u0442\u043e\u0432\n!pip freeze > requirements.txt","68cf484f":"# \u0412 \u0441\u0435\u0442\u0430\u043f \u0432\u044b\u043d\u043e\u0448\u0443 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438, \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0439 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c\n\nRANDOM_SEED          = 50\n\nEPOCHS               = 7 \nBATCH_SIZE           = 8    # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-3\nVAL_SPLIT            = 0.2   # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 20%\n\nCLASS_NUM            = 10    # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435 (10)\nIMG_SIZE             = 224   # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3     # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/sf-dl-car-classification\/'\nPATH ='..\/output\/kaggle\/working\/'  \n\nos.makedirs(PATH,exist_ok=True)\nnp.random.seed(RANDOM_SEED)","504b645d":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","cc9ce63c":"train_df.info()","a2ba63a8":"train_df.Category.value_counts()","05e92b7f":"sns.countplot(x='Category', data=train_df)# \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432","90dc6bc4":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"..\/input\/sf-dl-car-classification\/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","d77d7ea6":"image = PIL.Image.open(PATH+'\/train\/5\/283709.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","0b094654":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0447\u0435\u043d\u044c \u0432\u0430\u0436\u043d\u0430 \u043a\u043e\u0433\u0434\u0430 \u0443 \u043d\u0430\u0441 \u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u043a\u0430\u043a \u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435)\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations as A","8d1c0160":"AUGMENTATIONS = A.Compose([\n    A.RandomBrightness(limit=0.2, p=0.5),\n    A.HueSaturationValue(p=0.5),\n    A.GaussianBlur(p=0.05),\n    A.RGBShift(p=0.5),\n    A.Rotate(limit=30,\n             interpolation=1,\n             border_mode=4,\n             value=None,\n             mask_value=None,\n             always_apply=False,\n             p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.0625,\n                       scale_limit=0.01,\n                       interpolation=1,\n                       border_mode=4,\n                       rotate_limit=20,\n                       p=.75),\n    A.OneOf([\n        A.CenterCrop(height=224, width=200),\n        A.CenterCrop(height=200, width=224)],\n        p=0.5),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)],\n        p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    A.Resize(IMG_SIZE, IMG_SIZE)\n])","13a96e54":"train_gen = ImageDataAugmentor(rescale=1.\/255,\n                               augment=AUGMENTATIONS,\n                               seed=RANDOM_SEED,\n                               validation_split=VAL_SPLIT)","d8a0569e":"train_datagen = train_gen.flow_from_directory(PATH+'train\/',\n                                              class_mode='categorical',\n                                              batch_size=BATCH_SIZE,\n                                              target_size=(IMG_SIZE, IMG_SIZE),\n                                              shuffle=True,\n                                              subset='training') # set as training data\n\ntest_datagen = train_gen.flow_from_directory(PATH+'train\/',\n                                             class_mode='categorical',\n                                             batch_size=BATCH_SIZE,\n                                             target_size=(IMG_SIZE, IMG_SIZE),\n                                             shuffle=True,\n                                             subset='validation') # set as test data","be0c10e1":"train_datagen.show_data(rows=3, cols=5)","7f8828a5":"base_model = efn.EfficientNetB6(weights='imagenet', #\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b B6 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f \u0440\u0430\u0431\u043e\u0442\u044b\n                                include_top=False, \n                                input_shape=input_shape)","259ac376":"#base_model.summary()","78caf1a6":"# \u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0432\u0435\u0441\u0430 EfficientNetB7 \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e top-\u0441\u043b\u043e\u0438. \n# \u0414\u0435\u043b\u0430\u0435\u043c \u044d\u0442\u043e \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0445\u043e\u0440\u043e\u0448\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 Imagenet \u043d\u0435 \u0437\u0430\u0442\u0438\u0440\u0430\u043b\u0438\u0441\u044c \u0432 \u0441\u0430\u043c\u043e\u043c \u043d\u0430\u0447\u0430\u043b\u0435 \u043d\u0430\u0448\u0435\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nbase_model.trainable = False","4795944a":"# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u0443\u044e \"\u0433\u043e\u043b\u043e\u0432\u0443\"\nmodel=Model.Sequential()\nmodel.add(base_model)\nmodel.add(Layer.GlobalAveragePooling2D()) # \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0432\u0441\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u0435\u0434\u0438\u043d\u044b\u0439 \u0432\u0435\u043a\u0442\u043e\u0440 \n\n# \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c \u0441 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043e\u0439\n# \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0435\u0449\u0451 \u043e\u0434\u0438\u043d \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439, dropout \u0438 Batch Normalization\nmodel.add(Layer.Dense(256, \n                      activation='relu', \n                      bias_regularizer=l2(1e-4),\n                      activity_regularizer=l2(1e-5)))\nmodel.add(Layer.BatchNormalization())\nmodel.add(Layer.Dropout(0.25))\nmodel.add(Layer.Dense(CLASS_NUM, activation='softmax'))","59eddb69":"model.summary()","2a6ed6a7":"# \u0414\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0441\u043b\u043e\u044f - \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u0441\u0442\u0430\u0442\u0443\u0441\u0430 trainable\nfor layer in model.layers:\n    print(layer, layer.trainable)","8dca741e":"model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(learning_rate=LR),\n              metrics=['accuracy'])","852e2320":"# \u0414\u043e\u0431\u0430\u0432\u0438\u043c ModelCheckpoint. \n# \u042d\u0442\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438, \n# \u0447\u0442\u043e\u0431\u044b \u0432 \u043d\u0443\u0436\u043d\u044b\u0439 \u043c\u043e\u043c\u0435\u043d\u0442 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u0435\u0433\u043e \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c.\ncheckpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor = ['val_accuracy'], \n                             verbose = 1,\n                             mode = 'max')\nearlystop = EarlyStopping(monitor = 'accuracy',\n                          patience = 5,\n                          restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.25,\n                              patience=2,\n                              min_lr=0.0000001,\n                              verbose=1,\n                              mode='auto')\ncallbacks_list = [checkpoint, earlystop]","73b715fc":"tf.test.is_gpu_available()       ","133f8687":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = train_datagen.samples\/\/train_datagen.batch_size,\n        validation_data = test_datagen, \n        validation_steps = test_datagen.samples\/\/test_datagen.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list)","59dc0e4a":"scores = model.evaluate(test_datagen, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","4fb9b38e":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u0441\u0435\u0442\u044c \u0438 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044e \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (best_model)\nmodel.load_weights('best_model.hdf5')\nmodel.save('..output\/kaggle\/working\/model_last.hdf5')\nplot_history(history)","32b6f0ec":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)\/\/2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","430a768a":"LR=0.0001\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(learning_rate=LR), \n              metrics=[\"accuracy\"])","3144296b":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = train_datagen.samples\/\/train_datagen.batch_size,\n        validation_data = test_datagen, \n        validation_steps = test_datagen.samples\/\/test_datagen.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list)","9ec70985":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel.save('..output\/kaggle\/working\/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","3e909093":"scores = model.evaluate(test_datagen, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","1fdf0755":"plot_history(history)","c5e4816b":"base_model.trainable = True\nLR = 1e-5\n\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(learning_rate=LR), \n              metrics=[\"accuracy\"])","0f3f777d":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = train_datagen.samples\/\/train_datagen.batch_size,\n        validation_data = test_datagen, \n        validation_steps = test_datagen.samples\/\/test_datagen.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list)","3796945c":"# \u0421\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel.save('..output\/kaggle\/working\/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')\n\nscores = model.evaluate(test_datagen, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","bce686dd":"plot_history(history)","3ac6e105":"IMG_SIZE             = 512\nBATCH_SIZE           = 2\nEPOCHS               = 5\nLR                   = 1e-5\nIMG_CHANNELS         = 3    # \u0443 RGB \u0442\u0440\u0438 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","51d0bf2d":"AUGMENTATIONS = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.0625, \n                       scale_limit=0.01, \n                       interpolation=1, \n                       border_mode=4, \n                       rotate_limit=20, \n                       p=.75)])","b3426b7e":"train_gen = ImageDataAugmentor(rescale=1.\/255,\n                        augment=AUGMENTATIONS, \n                        seed=RANDOM_SEED,\n                        validation_split=VAL_SPLIT)","62b02e29":"train_datagen = train_gen.flow_from_directory(PATH+'train\/',\n                                              class_mode='categorical',\n                                              batch_size=BATCH_SIZE,\n                                              target_size=(IMG_SIZE, IMG_SIZE),\n                                              shuffle=True,\n                                              subset='training') # set as training data\n\ntest_datagen = train_gen.flow_from_directory(PATH+'train\/',\n                                             class_mode='categorical',\n                                             batch_size=BATCH_SIZE,\n                                             target_size=(IMG_SIZE, IMG_SIZE),\n                                             shuffle=True,\n                                             subset='validation') # set as test data","6ff79b63":"base_model = efn.EfficientNetB6(weights='imagenet', \n                                include_top=False, \n                                input_shape=input_shape)","b91ca7d6":"base_model.trainable = True","7229fa55":"model.compile(loss='categorical_crossentropy', \n              optimizer=optimizers.Adam(learning_rate=LR), \n              metrics=['accuracy'])\nmodel.load_weights('best_model.hdf5') # \u041f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0440\u0430\u043d\u0435\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0432\u0435\u0441\u0430","b9672761":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit(\n        train_datagen,\n        steps_per_epoch = train_datagen.samples\/\/train_datagen.batch_size,\n        validation_data = test_datagen, \n        validation_steps = test_datagen.samples\/\/test_datagen.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","70cabe87":"model.save('..output\/kaggle\/working\/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","ae5f509a":"scores = model.evaluate(test_datagen, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","695904eb":"plot_history(history)","607e13b9":"test_gen = ImageDataAugmentor(rescale=1.\/255)\ntest_sub_generator = test_gen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=PATH+'test_upload\/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","de4dc0cd":"test_sub_generator.samples","e0c6b479":"test_sub_generator.reset()\npredictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","c6ac4353":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_IMG_SIZE.csv', index=False)\nprint('Submission is saved')","6b47fc7d":"submission.head()","fdc960f2":"# Submission","82aee91c":"# \u0420\u0435\u0437\u044e\u043c\u0435","8aca01ad":"# \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438","7740b260":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","3b9c736e":"# \u0420\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0443 \u0432\u0435\u0441\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438","eeb12886":"**\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445**","9b4edc2c":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","d9363181":"**\u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c FixEfficientNet-B7:**","96fdf715":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438","3456b6ab":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","9ce2270b":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","16c00c4b":"# \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u043f\u043e\u043d\u0438\u0437\u0438\u043c \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438","5743795d":"# \u0420\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0432\u0435\u0441\u0430 \u043c\u043e\u0434\u0435\u043b\u0438","f6c5be70":"# EDA","1787ea5b":"**\u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f**"}}