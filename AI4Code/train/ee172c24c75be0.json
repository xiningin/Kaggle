{"cell_type":{"233d67e9":"code","ad822caa":"code","887d8ef3":"code","c9aca080":"code","cffa671d":"code","e511bbd0":"code","e978f6ab":"code","11c6236d":"code","cad1a6ba":"code","064d4c85":"code","456c3391":"markdown","d6f0421b":"markdown","5363f561":"markdown"},"source":{"233d67e9":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom xgboost import XGBClassifier","ad822caa":"df = pd.read_csv(\"..\/input\/d\/pasadenian\/titanic\/train_5folds.csv\") # use your own splitted data (5 folds)\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","887d8ef3":"# check data type of each column\ndf.dtypes","c9aca080":"# fraction of null data in each column of the training data\ndf.isnull().sum()\/len(df)","cffa671d":"# fraction of null data in each column of the test data\ndf_test.isnull().sum()\/len(df_test)","e511bbd0":"useful_features = [c for c in df.columns if c not in ('PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'kfold')]\nobject_cols = ['Pclass', 'Sex', 'Embarked']\nobject_cols_to_impute = ['Embarked']\nnumerical_cols_to_impute = ['Age', 'Fare']\ndf_test = df_test[useful_features]","e978f6ab":"final_predictions = []; scores=[]; acc_scores=[]\nfor fold in range(5):\n    \n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    imputer1 = SimpleImputer(strategy='median')\n    xtrain[numerical_cols_to_impute] = imputer1.fit_transform(xtrain[numerical_cols_to_impute])\n    xvalid[numerical_cols_to_impute] = imputer1.transform(xvalid[numerical_cols_to_impute])\n    xtest[numerical_cols_to_impute] = imputer1.transform(xtest[numerical_cols_to_impute])\n    \n    imputer2 = SimpleImputer(strategy='most_frequent')\n    xtrain[object_cols_to_impute] = imputer2.fit_transform(xtrain[object_cols_to_impute])\n    xvalid[object_cols_to_impute] = imputer2.transform(xvalid[object_cols_to_impute])\n    xtest[object_cols_to_impute] = imputer2.transform(xtest[object_cols_to_impute])\n\n    ytrain = xtrain.Survived\n    yvalid = xvalid.Survived\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBClassifier(random_state=fold, objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    loss = log_loss(yvalid, preds_valid)\n    accuracy = accuracy_score(yvalid, preds_valid)\n    print(fold, loss)\n    scores.append(loss)\n    acc_scores.append(accuracy)\n    \nprint(np.mean(scores), np.std(scores))\nprint(f\"CV score (accuracy): {np.mean(acc_scores):.3f}\")","11c6236d":"preds = np.column_stack(final_predictions)\npreds = [*map(lambda x:np.argmax(np.bincount(x)), preds)]","cad1a6ba":"sample_submission.Survived = preds\nsample_submission.to_csv(\"submission.csv\", index=False)","064d4c85":"sample_submission","456c3391":"### XGBoost","d6f0421b":"We consider simple imputation methods as follows: \n- drop 'Cabin' due to a large number of missing values (maybe try imputation later)\n- Since 'Embarked' is categorical, we impute with most frequent value\n- Since 'Age' is numerical, we'll impute with median","5363f561":"Inherited from https:\/\/www.kaggle.com\/abhishek\/competition-part-1-baseline?scriptVersionId=72291885\n\nThe difference is it was about Regression in the above notebook but it is about Classification in the Titanic survival prediction problem. \n\n- Pclass: Ticket class; 1 = 1st, 2 = 2nd, 3 = 3rd,\n- SibSp: # of siblings \/ spouses aboard the Titanic,\n- Parch: # of parents \/ children aboard the Titanic,\n- Ticket: Ticket number,\n- Cabin: Cabin number,\n- Embarked: Port of Embarkation; C = Cherbourg, Q = Queenstown, S = Southampton"}}