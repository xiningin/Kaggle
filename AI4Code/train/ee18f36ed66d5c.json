{"cell_type":{"b16775d0":"code","e0744322":"code","0c98f3b8":"code","5cc2bef1":"code","6e814189":"code","2a46323a":"code","abfa32e2":"code","47110876":"code","8865d2e5":"code","e9400f0b":"code","a943a56e":"code","6cad039c":"code","978b34e6":"code","66fc515e":"code","6801fe6a":"code","b290a6c2":"code","d412c860":"code","cb40f20d":"code","688d44bc":"code","6b37ca75":"code","bed6750a":"code","7caba85e":"code","3dddb917":"markdown","e00af465":"markdown"},"source":{"b16775d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0744322":"train = pd.read_csv(\"..\/input\/ds2-ds5-competition-2\/train.csv\")\ntest_input = pd.read_csv(\"..\/input\/ds2-ds5-competition-2\/test_input.csv\")\ntest = pd.read_csv(\"..\/input\/ds2-ds5-competition-2\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/ds2-ds5-competition-2\/sample_submission.csv\")","0c98f3b8":"train.head()","5cc2bef1":"train['month'] = train['timestamp'].str[5:7]\ntrain['time'] = train['timestamp'].str[11:13]\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])","6e814189":"mean_usage_by_id = train[['device_id', 'value']].groupby(\"device_id\", as_index=False).mean()\nmean_usage_by_id.describe()","2a46323a":"ax = sns.lineplot(x=\"month\", y=\"value\", data=train)","abfa32e2":"sns.set()\nplt.figure(figsize=(10, 7))\nax = sns.lineplot(x=\"time\", y=\"value\", hue=\"month\", data=train, palette = sns.color_palette(\"hls\", 12))","47110876":"p_start = '2013-09-01 00:00:00'\np_end = '2013-10-01 00:00:00'\nnew_train = train.set_index('timestamp')[p_start:p_end]\nplt.figure(figsize=(10, 7))\nax = sns.lineplot(x=\"time\", y=\"value\", data=new_train)","8865d2e5":"set(test_input['timestamp'])","e9400f0b":"def window_stack(a, stepsize=24, width=144):\n    n = a.shape[0]\n    nd = np.empty((0, width))\n    for i in range(0,(int(n\/stepsize) - int(width\/stepsize - 1))):\n        nd = np.vstack([nd, a[(i*stepsize):(i*stepsize + width)]])\n    return nd","a943a56e":"train = train.sort_values(by=['device_id', 'timestamp'], axis=0).reset_index(drop=True)\n\ntrain_usage = np.empty((0, 144))\nid_set = list(set(train['device_id']))\nfor id_ in id_set:\n    one_id_usage = train.loc[train['device_id'] == id_]['value'].reset_index(drop=True)\n    train_usage = np.concatenate((train_usage, window_stack(one_id_usage)), axis=0)","6cad039c":"test_input_usage = np.empty((0, 120))\nid_set = list(set(test_input['device_id']))\nfor id_ in id_set:\n    one_id_usage = test_input.loc[test_input['device_id'] == id_]['value'].reset_index(drop=True)\n    test_input_usage = np.concatenate((test_input_usage, window_stack(one_id_usage, stepsize=120, width=120)), axis=0)","978b34e6":"id_order = np.concatenate([[i]*96 for i in id_set])","66fc515e":"train_usage.shape","6801fe6a":"test_input_usage.shape","b290a6c2":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.multioutput import MultiOutputRegressor\n\nX_train, y_train = np.split(train_usage, (120, ), axis=1)\nX_test = test_input_usage\n\nmultioutputregressor_trvalte = MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10))\nmultioutputregressor_trvalte.fit(X_train, y_train)\npredictions = multioutputregressor_trvalte.predict(X_test)\n\ny_pred = np.concatenate(predictions)","d412c860":"pred_df = pd.DataFrame({'device_id' : id_order,\n                        'timestamp' : test['timestamp'],\n                       'value' : y_pred})\npred_df = pd.merge(test, pred_df, on=['device_id', 'timestamp'])","cb40f20d":"submission['value'] = pred_df['value'].values\nsubmission.to_csv('submission_xgb.csv', index=False)","688d44bc":"avg_usage = np.mean(X_train, axis=1)\n\nX_train = np.divide(X_train, avg_usage[:,None])\ny_train = np.divide(y_train, avg_usage[:,None])\n\navg_usage_test = np.mean(X_test, axis=1)\nX_test = np.divide(X_test, avg_usage_test[:,None])","6b37ca75":"multioutputregressor_trvalte = MultiOutputRegressor(xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 10))\nmultioutputregressor_trvalte.fit(X_train, y_train)\nnor_predictions = multioutputregressor_trvalte.predict(X_test)\n\npredictions = np.multiply(nor_predictions, avg_usage_test[:,None])\ny_pred = np.concatenate(predictions)","bed6750a":"pred_df = pd.DataFrame({'device_id' : id_order,\n                        'timestamp' : test['timestamp'],\n                       'value' : y_pred})\npred_df = pd.merge(test, pred_df, on=['device_id', 'timestamp'])","7caba85e":"submission['value'] = pred_df['value'].values\nsubmission.to_csv('submission_xgb_nor.csv', index=False)","3dddb917":"Unnormalized version","e00af465":"Normalized version"}}