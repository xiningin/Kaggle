{"cell_type":{"25c77902":"code","c6d32114":"code","54659bc2":"code","59f02799":"code","4430e12e":"code","631f06e2":"code","9a6da1c5":"code","c490fb40":"code","818385a4":"code","395fd09f":"code","ab964da5":"code","8cb878c1":"code","7fd2f455":"code","d07fbc5c":"code","084be63b":"code","d09a3516":"code","2058a214":"code","35c1ca33":"code","99f81539":"code","b4817405":"code","61506507":"code","0b4f1660":"code","dc17bf79":"code","7b415cf5":"code","95a15b27":"code","c62eeaf7":"code","6657fb6c":"code","dc7277ca":"code","39baf91f":"code","382ac4cd":"code","aea03bb4":"code","3f7183ea":"code","640c9665":"code","1293ee4c":"code","8ce06af8":"code","c70aa104":"code","450ca154":"code","6e47b946":"code","b04f87e1":"code","3b3c923c":"code","f7d66318":"code","5ceceaf3":"code","23c15944":"markdown","1e352a78":"markdown","637128a6":"markdown","141ba941":"markdown","075ba00c":"markdown","8b33eb4e":"markdown","f8a43635":"markdown","612fde1d":"markdown","accbb4cf":"markdown","29fcda0e":"markdown","526f6cd6":"markdown","12e52476":"markdown","a89f980b":"markdown","7805544f":"markdown","ee4ef74b":"markdown","4a54f7b9":"markdown","03a65fe3":"markdown","7cd97eaf":"markdown","ba671065":"markdown","8eb471aa":"markdown","12c118f2":"markdown","d90410f0":"markdown"},"source":{"25c77902":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c6d32114":"test = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\nitem_categories = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nsales = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv',  parse_dates=['date'], infer_datetime_format=True, dayfirst=True)","54659bc2":"print(sales.head())\nprint('____________________________')\nprint(sales.info())\nprint('____________________________')\nprint(sales.describe())","59f02799":"print(test.head())\nprint('____________________________')\nprint(test.info())\nprint('____________________________')\nprint(test.describe())","4430e12e":"print(items.head())\nprint('____________________________')\nprint(items.info())\nprint('____________________________')\nprint(items.describe())","631f06e2":"print(shops.head())\nprint('____________________________')\nprint(shops.info())\nprint('____________________________')\nprint(shops.describe())","9a6da1c5":"print(item_categories.head())\nprint('____________________________')\nprint(item_categories.info())\nprint('____________________________')\nprint(item_categories.describe())","c490fb40":"print(shops.head())\nprint('____________________________')\nprint(shops.info())\nprint('____________________________')\nprint(shops.describe())","818385a4":"df_item=pd.merge(items,item_categories,on='item_category_id',how='inner')\nsales_train=pd.merge(sales,shops,on='shop_id',how='inner')\nsales=pd.merge(sales_train,df_item,on='item_id',how='inner')","395fd09f":"sales = sales[sales['shop_id'].isin(test['shop_id'].unique())]\nsales = sales[sales['item_id'].isin(test['item_id'].unique())]","ab964da5":"sales","8cb878c1":"import seaborn as sns\nsns.boxplot(x=sales.item_cnt_day)","7fd2f455":"import seaborn as sns\nsns.boxplot(x=sales.item_price)","d07fbc5c":"sales = sales[(sales.item_price < 300000 )& (sales.item_cnt_day < 1000)]\n# remove negative item price\nsales = sales[sales.item_price > 0].reset_index(drop = True)","084be63b":"sales = sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[['date_block_num','date', 'shop_id', 'item_id', 'item_price', 'item_cnt_day']].agg({\"date_block_num\":'mean',\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n","d09a3516":"sales","2058a214":"sales = sales.item_cnt_day.apply(list).reset_index()","35c1ca33":"sales","99f81539":"sales_data = pd.merge(test,sales,on = ['item_id','shop_id'],how = 'left')","b4817405":"sales_data.fillna(0,inplace = True)\nsales_data.drop(['shop_id','item_id'],inplace = True, axis = 1)","61506507":"sales_data","0b4f1660":"sales_data = sales_data.pivot_table(index = 'ID', columns='date_block_num', values = 'sum', aggfunc='sum')","dc17bf79":"sales_data","7b415cf5":"sales_data = sales_data.fillna(0)","95a15b27":"sales_data.head(20)","c62eeaf7":"X=sales_data[sales_data.columns[:-1]]","6657fb6c":"y=sales_data[sales_data.columns[-1]]","dc7277ca":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split( X, y, test_size=0.20, random_state=1)","39baf91f":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\n#fitting data\nregressor.fit(X_train, Y_train)","382ac4cd":"from sklearn.metrics import mean_squared_error\nprint('Train set mse:', mean_squared_error(Y_train, regressor.predict(X_train)))\nprint('Test set mse:', mean_squared_error(Y_test, regressor.predict(X_test)))\nprint('Test set score:', regressor.score(X_train,Y_train))","aea03bb4":"#cross validation score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import TimeSeriesSplit\nts_cross_val = TimeSeriesSplit(n_splits=5)\nprint('cross_val_score',cross_val_score(regressor, X, y, cv = ts_cross_val, scoring= \"neg_mean_squared_error\"))","3f7183ea":"submission = pd.DataFrame({'ID':X_test.index,'item_cnt_month':regressor.predict(X_test)})","640c9665":"submission.to_csv('submission.csv',index = False)","1293ee4c":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout\nfrom keras.models import load_model, Model\n\n# defining model \nmodel = Sequential()\nmodel.add(LSTM(units = 128,return_sequences=True,input_shape = (33,1)))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(units = 64,return_sequences=False,activation='relu'))\n# model.add(Dropout(0.5))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(16))\nmodel.add(Dense(1))\n\n# opt = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(loss = 'mse',optimizer = 'Nadam', metrics = ['mean_squared_error'])\nmodel.summary()","8ce06af8":"#Splitting data for LSTM's\nfrom sklearn.model_selection import train_test_split\nX_train = np.expand_dims(sales_data.values[:,:-1],axis = 2)\ny_train = sales_data.values[:,-1:]\nmodel.fit(X_train,y_train, batch_size = 1024,epochs = 10, validation_split=0.1)","c70aa104":"# performance \nimport matplotlib.pyplot as plt\nplt.plot(model.history.history['loss'], label='Train loss')\nplt.plot(model.history.history['val_loss'], label='Validation loss')\nplt.legend(loc='best')\n# plt.title\nplt.title('Regular LSTM')\nplt.xlabel('Epochs')\nplt.ylabel('MSE')","450ca154":"train_pred = model.predict(X_train)","6e47b946":"print('Train rmse:', np.sqrt(mean_squared_error(y_train, train_pred)))","b04f87e1":"X_test = sales_data.loc[:,sales_data.columns!=sales_data.columns[0]]\ny_test = sales_data[sales_data.columns[0]]","3b3c923c":"icm = model.predict(np.expand_dims(X_test,axis = 2))","f7d66318":"print('test rmse:', np.sqrt(mean_squared_error(y_test, icm)))","5ceceaf3":"submission = pd.DataFrame({'ID':X_test.index, 'item_cnt_month':icm.reshape(214200,)})\nsubmission.to_csv('submission.csv',index = False)","23c15944":"performance on test data","1e352a78":"## LSTM\nLong short term memory cells for time series","637128a6":"**Fill NaN values with zero**","141ba941":"## Analyze data","075ba00c":"**fill Nan values with 0 and drop shop_id and item_id**","8b33eb4e":"## Load Data","f8a43635":"## Performance","612fde1d":"**preparing for time series data format**","accbb4cf":"**Linear Regression**","29fcda0e":"### Remove outliers","526f6cd6":" [amitnikhade.com](http:\/\/amitnikhade.com)","12e52476":"# Future sales Prediction using:\n* LSTM\n* Linear regression","a89f980b":"### Aggregation on monthly basis\n","7805544f":"**dividing data to features and label like a supervised problem**","ee4ef74b":"### keeping only the data in train dataset, present in the test dataset.","4a54f7b9":"### Outliers","03a65fe3":"Performance on train data","7cd97eaf":"# amitnikhade.com[](http:\/\/amitnikhade.com)","ba671065":"# Pipeline\n1. Problem Definition\n2. Analyzing data\n3. Preparing train and test purpose data\n4. creating model\n5. Evaluate model\n6. Improve performance\n7. Present performances\n8. Save results","8eb471aa":"**splitting to training and testing**","12c118f2":"###  Dataset merging operation","d90410f0":"**merging test with sales data on item_id and shop_id**"}}