{"cell_type":{"2f16d165":"code","70cdaa74":"code","46e94962":"code","eb1fd246":"code","ea6ff5d0":"code","be56e4af":"code","bcdaa8dc":"code","0cd0ed23":"code","a88fff4a":"markdown","951e4ef1":"markdown","6f7bb39a":"markdown"},"source":{"2f16d165":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport os\nprint(os.listdir(\"..\/input\"))\npd.set_option('max_columns', 1000)\npd.set_option('max_rows', 10)\nx= pd.read_csv('..\/input\/clustering_x.csv',encoding='latin1')","70cdaa74":"from sklearn.cluster import KMeans\nSum_of_squared_distances = []\nK = range(1,15)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(x)\n    Sum_of_squared_distances.append(km.inertia_)\nimport matplotlib.pyplot as plt\nplt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","46e94962":"iteration = 500 \nmodel = KMeans(n_clusters =5, n_jobs = 4, max_iter = iteration)\nmodel.fit(x) \n\nprint(pd.Series(model.labels_).value_counts())\n\npd.DataFrame(model.cluster_centers_) \n\nnew_data=pd.concat([x, pd.Series(model.labels_, index = x.index)], axis = 1) \nnew_data.rename(columns={0:'clusters'},inplace=True) ","eb1fd246":"new_data2=new_data.loc[:5000,]\nfrom sklearn.manifold import TSNE\ntsne = TSNE()\ntsne.fit_transform(new_data2) \ntsne = pd.DataFrame(tsne.embedding_, index = new_data2.index) \nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei'] \nplt.rcParams['axes.unicode_minus'] = False \n#\u4e0d\u540c\u7c7b\u522b\u7528\u4e0d\u540c\u989c\u8272\u548c\u6837\u5f0f\u7ed8\u56fe\nd = tsne[new_data2['clusters'] == 0]\nplt.plot(d[0], d[1], 'r.')\nd = tsne[new_data2['clusters'] == 1]\nplt.plot(d[0], d[1], 'go')\nd = tsne[new_data2['clusters'] == 2]\nplt.plot(d[0], d[1], 'b*')\nd = tsne[new_data2['clusters'] == 3]\nplt.plot(d[0], d[1], 'k*')\nd = tsne[new_data2['clusters'] == 4]\nplt.plot(d[0], d[1], 'y.')\nplt.show()","ea6ff5d0":"from sklearn.cluster import DBSCAN\nmodel = DBSCAN(eps=1000,min_samples=1500)\nmodel.fit(x) \n\npd.Series(model.labels_).value_counts()\n\nnew_data=pd.concat([x, pd.Series(model.labels_, index = x.index)], axis = 1) \nnew_data.rename(columns={0:'clusters'},inplace=True) ","be56e4af":"new_data2=new_data.loc[:5000,]\nfrom sklearn.manifold import TSNE\ntsne = TSNE()\ntsne.fit_transform(new_data2) \ntsne = pd.DataFrame(tsne.embedding_, index = new_data2.index) \nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei'] \nplt.rcParams['axes.unicode_minus'] = False \n#\u4e0d\u540c\u7c7b\u522b\u7528\u4e0d\u540c\u989c\u8272\u548c\u6837\u5f0f\u7ed8\u56fe\nd = tsne[new_data2['clusters'] == 0]\nplt.plot(d[0], d[1], 'r.')\nd = tsne[new_data2['clusters'] == 1]\nplt.plot(d[0], d[1], 'go')\nd = tsne[new_data2['clusters'] == -1]\nplt.plot(d[0], d[1], 'b*')\nd = tsne[new_data2['clusters'] == 2]\nplt.plot(d[0], d[1], 'k*')\nplt.show()\n","bcdaa8dc":"from sklearn.cluster import AgglomerativeClustering\nmodel = AgglomerativeClustering(n_clusters=7)\n\nx=x[:20000]\nmodel.fit(x)\n\nprint(pd.Series(model.labels_).value_counts())\n\nnew_data=pd.concat([x, pd.Series(model.labels_, index = x.index)], axis = 1) \nnew_data.rename(columns={0:'clusters'},inplace=True) ","0cd0ed23":"new_data2=new_data.loc[:5000,]\nfrom sklearn.manifold import TSNE\ntsne = TSNE()\ntsne.fit_transform(new_data2) \ntsne = pd.DataFrame(tsne.embedding_, index = new_data2.index) \nimport matplotlib.pyplot as plt\nplt.rcParams['font.sans-serif'] = ['SimHei'] \nplt.rcParams['axes.unicode_minus'] = False \n#\u4e0d\u540c\u7c7b\u522b\u7528\u4e0d\u540c\u989c\u8272\u548c\u6837\u5f0f\u7ed8\u56fe\nd = tsne[new_data2['clusters'] == 3]\nplt.plot(d[0], d[1], 'r.')\nd = tsne[new_data2['clusters'] == 2]\nplt.plot(d[0], d[1], 'go')\nd = tsne[new_data2['clusters'] == 4]\nplt.plot(d[0], d[1], 'b*')\nd = tsne[new_data2['clusters'] == 6]\nplt.plot(d[0], d[1], 'k*')\nd = tsne[new_data2['clusters'] == 0]\nplt.plot(d[0], d[1], 'y.')\nplt.show()\n","a88fff4a":"**Machine Learning-Hierarchical clustering**","951e4ef1":"**Machine Learning-K-Means clustering**","6f7bb39a":"**Machine Learning-DBSCAN clustering**"}}