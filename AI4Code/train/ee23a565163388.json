{"cell_type":{"61d30326":"code","a500ae0b":"code","a44052d8":"code","7f525643":"code","af5c97d1":"code","38023b12":"code","5133098e":"code","e1c0b101":"code","f335aa90":"code","50603d90":"code","0a11ab37":"code","ab309061":"code","71acb0f7":"code","e624abb8":"code","8a6ddc52":"code","6fcdc345":"code","c0a90930":"code","0de63529":"code","62a3fd28":"code","faaec970":"code","625c3c17":"code","2dc1f08c":"code","b85adee9":"code","cab9dfd8":"code","c0d7328b":"code","a7bc6024":"code","5de622be":"code","d567fb9d":"code","f549c8f2":"code","5a2167f8":"code","aaa51bc3":"code","6c24643e":"code","ab07eb4f":"code","fa1c062e":"code","7c3ac46a":"code","67786b10":"code","37fffef5":"code","7764098c":"code","49d0121a":"code","cb541618":"code","45b7f9cd":"code","bc8007f8":"code","e1e5f98b":"code","a4b78c36":"code","da900fa0":"code","4792d67f":"code","5881c251":"code","525c8c40":"code","8edc986e":"code","1236a351":"code","58078ff5":"code","c22d549d":"code","16e4e233":"code","c80e7855":"code","669f691c":"code","0ba68f00":"code","c390ccb6":"code","ff528891":"code","607e0a2c":"code","177fe7e7":"markdown","39ab4bd0":"markdown","19c10f4c":"markdown","77f407b3":"markdown","b684d353":"markdown","43d89fad":"markdown","030285d0":"markdown","ed0c1be7":"markdown","4dbed80f":"markdown","96b9338c":"markdown","0d1ba1a7":"markdown","d4687f18":"markdown","8e81f24d":"markdown","045c5607":"markdown","52824d9c":"markdown","e62da3d9":"markdown","b62104c7":"markdown","faad0bb4":"markdown","16793743":"markdown","117d107d":"markdown","f0604bb1":"markdown","cf5bc321":"markdown","ca5f43f9":"markdown","e47eafb8":"markdown","6e2f3ab2":"markdown","602ae5fb":"markdown","7041d8d9":"markdown","37db045e":"markdown","7f8f0eaf":"markdown","bda8168e":"markdown","d37d8ffa":"markdown","3b5d0d92":"markdown","dc5ba7e1":"markdown","b78a9521":"markdown","080a0dd2":"markdown","3dd25231":"markdown","f6f17ef8":"markdown","5aa8f545":"markdown","112acb99":"markdown","e701f8df":"markdown","16f3022c":"markdown","cf64c32c":"markdown","b9364868":"markdown","1f271537":"markdown","0c14a82a":"markdown","e3b04896":"markdown","f4ed6df1":"markdown","55379fd5":"markdown","a96955a7":"markdown","f7ad1805":"markdown","9aaaa35d":"markdown","543ff0eb":"markdown","9bb099d6":"markdown","4c39a1fc":"markdown","cb96a23f":"markdown","b2957af6":"markdown","4b40896e":"markdown","ef36e34c":"markdown","a393ed7a":"markdown","fc7566f0":"markdown","1cd22e20":"markdown","bfc3c070":"markdown","ebef6aa6":"markdown","1135445a":"markdown","43cd8113":"markdown","ff2f3ad9":"markdown","c37fef10":"markdown","1cb5a107":"markdown","9a0e4006":"markdown","e39fff70":"markdown","1e86a127":"markdown","80857615":"markdown"},"source":{"61d30326":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a500ae0b":"# Reading the dataset into a dataframe and storing the original copy for later reference\n\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\noriginal = df.copy()","a44052d8":"# Printing the shape of the dataset\n\nprint('Dataset has', df.shape[0], 'rows and', df.shape[1], 'columns')","7f525643":"# Printing the info of the dataset\n\ndf.info()","af5c97d1":"# Printing the head of the dataset\n\ndf.head()","38023b12":"# Printing the descriptive stats of the dataset\n\ndf.describe()","5133098e":"init_notebook_mode()","e1c0b101":"#Splitting up the dataset based on the death event feature\n\nfailed = df.loc[df['DEATH_EVENT'] == 1, :]\nnot_failed = df.loc[df['DEATH_EVENT'] == 0, :]","f335aa90":"print(failed.shape)\nprint(not_failed.shape)","50603d90":"# Create two traces each with the target class label and plot boxplots by considering age\n\ntrace1 = go.Box(y = failed['age'], \n             name = 'Failed',\n             marker = dict(color = 'black'))\n\ntrace2 = go.Box(y = not_failed['age'], \n             name = 'Not Failed',\n             marker = dict(color = '#eb2862'))\n\n\nlayout = go.Layout(title = 'Failure Rate by Age Group',\n                  xaxis = dict(title = 'Heart Failure'),\n                  yaxis = dict(title = 'Age'))\n\nfig = go.Figure(data = [trace1, trace2], layout = layout)\niplot(fig)","0a11ab37":"#Splitting up the dataset based on the 'anaemia' feature\n\nanaemic = df.loc[df['anaemia'] == 1, :]\nnot_anaemic = df.loc[df['anaemia'] == 0, :]","ab309061":"# Calculate the percentage of patients in each of the class (Anaemic or Not)\n\nfailed_anaemia = anaemic['DEATH_EVENT'].value_counts(normalize = True).reset_index()\nfailed_not_anaemia = not_anaemic['DEATH_EVENT'].value_counts(normalize = True).reset_index()","71acb0f7":"# Create two traces of bar plots\n\ntrace1 = go.Bar(x = failed_anaemia.index,\n                y = failed_anaemia.DEATH_EVENT,\n                name = \"Anaemic\",\n                marker = dict(color = '#eb2862',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))\n\n\ntrace2 = go.Bar(x = failed_not_anaemia.index,\n                y = failed_not_anaemia.DEATH_EVENT,\n                name = \"Not Anaemic\",\n                marker = dict(color = '#615a5c',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))","e624abb8":"# Add appropriate titles and labels\n\ndata = [trace1, trace2]\nlayout = go.Layout(title = 'Failure Rate by Anaemia',\n                   xaxis = dict(title = 'Heart Failed'),\n                   yaxis = dict(title = '% Patients'),\n                   barmode = \"group\")\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","8a6ddc52":"# Create two traces each with the target class label and plot boxplots by considering creatinine phosphokinase\n\ntrace1 = go.Box(y = failed['creatinine_phosphokinase'], \n             name = 'Failed',\n             marker = dict(color = 'black'))\n\ntrace2 = go.Box(y = not_failed['creatinine_phosphokinase'], \n             name = 'Not Failed',\n             marker = dict(color = '#eb2862'))\n\n\nlayout = go.Layout(title = 'Failure Rate by CPK Level',\n                  xaxis = dict(title = 'Heart Failure'),\n                  yaxis = dict(title = 'CPK'))\n\nfig = go.Figure(data = [trace1, trace2], layout = layout)\niplot(fig)","6fcdc345":"#Splitting up the dataset based on the diabetes feature\n\ndiabetic = df.loc[df['diabetes'] == 1, :]\nnot_diabetic = df.loc[df['diabetes'] == 0, :]","c0a90930":"# Calculate the percentage of patients in each of the class (Diabetic or Not)\n\nfailed_diabetic = diabetic['DEATH_EVENT'].value_counts(normalize = True).reset_index()\nfailed_not_diabetic = not_diabetic['DEATH_EVENT'].value_counts(normalize = True).reset_index()","0de63529":"# Create two traces of bar plots\n\ntrace1 = go.Bar(x = failed_diabetic.index,\n                y = failed_diabetic.DEATH_EVENT,\n                name = \"Diabetic\",\n                marker = dict(color = '#eb2862',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))\n\n\ntrace2 = go.Bar(x = failed_not_diabetic.index,\n                y = failed_not_diabetic.DEATH_EVENT,\n                name = \"Not Diabetic\",\n                marker = dict(color = '#615a5c',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))","62a3fd28":"# Add appropriate titles and labels\n\ndata = [trace1, trace2]\nlayout = go.Layout(title = 'Failure Rate by Diabetes',\n                   xaxis = dict(title = 'Heart Failed'),\n                   yaxis = dict(title = '% Patients'),\n                   barmode = \"group\")\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","faaec970":"# Create two traces each with the target class label and plot boxplots by considering ejection fraction\n\ntrace1 = go.Box(y = failed['ejection_fraction'], \n             name = 'Failed',\n             marker = dict(color = 'black'))\n\ntrace2 = go.Box(y = not_failed['ejection_fraction'], \n             name = 'Not Failed',\n             marker = dict(color = '#eb2862'))\n\n\nlayout = go.Layout(title = 'Failure Rate by Ejection Fraction',\n                  xaxis = dict(title = 'Heart Failure'),\n                  yaxis = dict(title = 'Ejection Fraction'))\n\nfig = go.Figure(data = [trace1, trace2], layout = layout)\niplot(fig)","625c3c17":"#Splitting up the dataset based on the 'high_blood_pressure' feature\n\nbp = df.loc[df['high_blood_pressure'] == 1, :]\nnormal = df.loc[df['high_blood_pressure'] == 0, :]","2dc1f08c":"# Calculate the percentage of patients in each of the class (BP or Normal)\n\nfailed_bp = bp['DEATH_EVENT'].value_counts(normalize = True).reset_index()\nfailed_normal = normal['DEATH_EVENT'].value_counts(normalize = True).reset_index()","b85adee9":"# Create two traces of bar plots\n\ntrace1 = go.Bar(x = failed_bp.index,\n                y = failed_bp.DEATH_EVENT,\n                name = \"High Blood Pressure\",\n                marker = dict(color = '#eb2862',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))\n\n\ntrace2 = go.Bar(x = failed_normal.index,\n                y = failed_normal.DEATH_EVENT,\n                name = \"Normal\",\n                marker = dict(color = '#615a5c',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))","cab9dfd8":"# Add appropriate titles and labels\n\ndata = [trace1, trace2]\nlayout = go.Layout(title = 'Failure Rate by High BP',\n                   xaxis = dict(title = 'Heart Failed'),\n                   yaxis = dict(title = '% Patients'),\n                   barmode = \"group\")\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","c0d7328b":"# Create two traces each with the target class label and plot boxplots by considering platelets\n\ntrace1 = go.Box(y = failed['platelets'], \n             name = 'Failed',\n             marker = dict(color = 'black'))\n\ntrace2 = go.Box(y = not_failed['platelets'], \n             name = 'Not Failed',\n             marker = dict(color = '#eb2862'))\n\n\nlayout = go.Layout(title = 'Failure Rate by Platelets Count',\n                  xaxis = dict(title = 'Heart Failure'),\n                  yaxis = dict(title = 'Platelets'))\n\nfig = go.Figure(data = [trace1, trace2], layout = layout)\niplot(fig)","a7bc6024":"# Create two traces each with the target class label and plot boxplots by considering creatinine\n\ntrace1 = go.Box(y = failed['serum_creatinine'], \n             name = 'Failed',\n             marker = dict(color = 'black'))\n\ntrace2 = go.Box(y = not_failed['serum_creatinine'], \n             name = 'Not Failed',\n             marker = dict(color = '#eb2862'))\n\n\nlayout = go.Layout(title = 'Failure Rate by Serum Creatinine Level',\n                  xaxis = dict(title = 'Heart Failure'),\n                  yaxis = dict(title = 'Serum Creatinine'))\n\nfig = go.Figure(data = [trace1, trace2], layout = layout)\niplot(fig)","5de622be":"# Create two traces each with the target class label and plot boxplots by considering sodium\n\ntrace1 = go.Box(y = failed['serum_sodium'], \n             name = 'Failed',\n             marker = dict(color = 'black'))\n\ntrace2 = go.Box(y = not_failed['serum_sodium'], \n             name = 'Not Failed',\n             marker = dict(color = '#eb2862'))\n\n\nlayout = go.Layout(title = 'Failure Rate by Serum sodium Level',\n                  xaxis = dict(title = 'Heart Failure'),\n                  yaxis = dict(title = 'Serum Sodium'))\n\nfig = go.Figure(data = [trace1, trace2], layout = layout)\niplot(fig)","d567fb9d":"#Splitting up the dataset based on the 'sex' feature\n\nmen = df.loc[df['sex'] == 1, :]\nwomen = df.loc[df['sex'] == 0, :]","f549c8f2":"# Calculate the percentage of patients in each of the gender\n\nfailed_men = men['DEATH_EVENT'].value_counts(normalize = True).reset_index()\nfailed_women = women['DEATH_EVENT'].value_counts(normalize = True).reset_index()","5a2167f8":"# Create two traces of bar plots\n\ntrace1 = go.Bar(x = failed_men.index,\n                y = failed_men.DEATH_EVENT,\n                name = \"Men\",\n                marker = dict(color = '#eb2862',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))\n\n\ntrace2 = go.Bar(x = failed_women.index,\n                y = failed_women.DEATH_EVENT,\n                name = \"Women\",\n                marker = dict(color = '#615a5c',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))","aaa51bc3":"# Add appropriate titles and labels\n\ndata = [trace1, trace2]\nlayout = go.Layout(title = 'Failure Rate by Gender',\n                   xaxis = dict(title = 'Heart Failed'),\n                   yaxis = dict(title = '% Patients'),\n                   barmode = \"group\")\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","6c24643e":"#Splitting up the dataset based on the 'smoking' feature\n\nsmoking = df.loc[df['smoking'] == 1, :]\nnot_smoking = df.loc[df['smoking'] == 0, :]","ab07eb4f":"# Calculate the percentage of patients in each of the class\n\nfailed_smoking = smoking['DEATH_EVENT'].value_counts(normalize = True).reset_index()\nfailed_no_smoking = not_smoking['DEATH_EVENT'].value_counts(normalize = True).reset_index()","fa1c062e":"# Create two traces of bar plots\n\ntrace1 = go.Bar(x = failed_smoking.index,\n                y = failed_smoking.DEATH_EVENT,\n                name = \"Smoker\",\n                marker = dict(color = '#eb2862',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))\n\n\ntrace2 = go.Bar(x = failed_no_smoking.index,\n                y = failed_no_smoking.DEATH_EVENT,\n                name = \"Non Smoker\",\n                marker = dict(color = '#615a5c',\n                             line=dict(color='rgb(0,0,0)',width=1.5)))","7c3ac46a":"# Add appropriate titles and labels\n\ndata = [trace1, trace2]\nlayout = go.Layout(title = 'Failure Rate by Smoking',\n                   xaxis = dict(title = 'Heart Failed'),\n                   yaxis = dict(title = '% Patients'),\n                   barmode = \"group\")\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","67786b10":"fig, ax = plt.subplots(figsize = (14, 10))\n\nsns.heatmap(df.corr(), annot = True, cmap = 'summer')\nplt.show()","37fffef5":"df.head()","7764098c":"scale = df.drop(columns = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT'])\nno_scale = df[['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']]","49d0121a":"# Import StandardScaler for standardizing the features\n\nfrom sklearn.preprocessing import StandardScaler","cb541618":"# Fitting the scaler on the training data and transform both the sets\n\nsc = StandardScaler()\n\nsc.fit(scale)\n\nscaled = pd.DataFrame(sc.transform(scale), columns = scale.columns)","45b7f9cd":"scaled.head(2)","bc8007f8":"no_scale.head(2)","e1e5f98b":"scaled_df = pd.concat([scaled, no_scale], axis = 1)\n\nscaled_df.head(3)","a4b78c36":"# Importing required libraries\n\nfrom sklearn.model_selection import train_test_split","da900fa0":"X = scaled_df.drop(columns = ['DEATH_EVENT'])\ny = scaled_df['DEATH_EVENT']","4792d67f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = 36)","5881c251":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB","525c8c40":"lr = LogisticRegression(solver = 'liblinear', random_state = 42)\n\nlr_model = lr.fit(X_train, y_train)\nprint('Training Score:', lr_model.score(X_train, y_train))\nprint('Testing Score:', lr_model.score(X_test, y_test))","8edc986e":"dt = DecisionTreeClassifier(random_state = 42)\n\ndt_model = dt.fit(X_train, y_train)\nprint('Training Score:', dt_model.score(X_train, y_train))\nprint('Testing Score:', dt_model.score(X_test, y_test))","1236a351":"rf = RandomForestClassifier(random_state = 42)\n\nrf_model = rf.fit(X_train, y_train)\nprint('Training Score:', rf_model.score(X_train, y_train))\nprint('Testing Score:', rf_model.score(X_test, y_test))","58078ff5":"knn = KNeighborsClassifier()\n\nknn_model = knn.fit(X_train, y_train)\nprint('Training Score:', knn_model.score(X_train, y_train))\nprint('Testing Score:', knn_model.score(X_test, y_test))","c22d549d":"svm = SVC(kernel = 'linear')\n\nsvm_model = svm.fit(X_train, y_train)\nprint('Training Score:', svm_model.score(X_train, y_train))\nprint('Testing Score:', svm_model.score(X_test, y_test))","16e4e233":"nb = GaussianNB()\n\nnb_model = nb.fit(X_train, y_train)\nprint('Training Score:', nb_model.score(X_train, y_train))\nprint('Testing Score:', nb_model.score(X_test, y_test))","c80e7855":"# Check the weights given to features in the LR model\n\nimp = lr_model.coef_","669f691c":"imp","0ba68f00":"data = [0.86033582,  0.07359915, -0.88052799, -0.29623866,  0.35454231,\n        -0.26178752, -1.57917285, -0.10954753,  0.16821838, -0.60792902,\n        -0.69118234,  0.13141275]\ncols = X_train.columns","c390ccb6":"# Plotting the coefficients of LR Model to observe visually\n\nfig, ax = plt.subplots(figsize = (14, 7))\n\nsns.barplot(x = cols, y = data, palette = 'winter')\nplt.title('Coefficients of LR Model')\nplt.xlabel('Feature')\nplt.ylabel('Coefficient')\nplt.xticks(rotation = 90)\nplt.show()","ff528891":"features = ['age', 'ejection_fraction', 'time', 'serum_creatinine', 'serum_sodium']","607e0a2c":"lr = LogisticRegression(solver = 'liblinear', random_state = 42, C = 0.05, max_iter = 300)\n\nlr_model = lr.fit(X_train[features], y_train)\nprint('Training Score:', lr_model.score(X_train[features], y_train))\nprint('Testing Score:', lr_model.score(X_test[features], y_test))","177fe7e7":"**Standardization** is a technique which is aimed at scaling the values in such a way that the standard deviation is around 1. When this is performed over a dataframe, all the features would be rescaled with an unit standard deviation.","39ab4bd0":"## **Logistic Regression**","19c10f4c":"**Inference**\n- Even though the difference in platelet counts is subtle between two groups, the affected patients have comparatively less platelets.","77f407b3":"## **Diabetes and Heart Failure**","b684d353":"**Inference**\n- 38% of the patients who have high BP also suffered heart failure.","43d89fad":"# **Prerequisites**","030285d0":"**Inference**\n- This graph suggests that the failure rate is equal among both the genders.","ed0c1be7":"In this section, we'll try to understand the factors which cause the heart failure by plotting various graphs. The inferences drawn out of this graphs would highly help us in building the predictive model. We'll try to answer different questions about the causal factors which pop in our mind.","4dbed80f":"# **Dataset**","96b9338c":"The SVM classifier forms a hyperplane to differentiate between different target labels and predict the outcomes.","0d1ba1a7":"The Naive Bayes Classifier predicts the outcomes by calculating the conditional probabilities for each of the target label.","d4687f18":"The heart is the muscular organ made of cardiac muscles and other tissues. The primary function of the heart is to pump the blood through the vessels of circulatory system. There are many ailments which a human can suffer because of disfunctioning of this vital organ. One of such ailments is the **heart failure**. Heart failure happens when the heart fails to do its function of pumping blood.\n\nThere could be multiple reasons which can leave heart in such a condition like narrowing of the arteries or high blood pressure. Certain treatments and change in lifestyle can help cure this disease.\n","8e81f24d":"As the Logistic Regression model has the decent training and testing score, let's check how it could be further improved. We'll also try to reduce the number of features to reduce the model complexity.","045c5607":"**Inference**\n- 31% of the smokers have faced heart failure.","52824d9c":"# **Importing Libraries and Dataset**","e62da3d9":"I'll update this notebook in regular intervals with more interesting insights and sophisticated models. The points mentioned in the further steps can be carried out by yourself, which can help you gain more knowledge in predictive modelling.\n\nHope you enjoyed reading this notebook. Please upvote and leave your comments if you like my work. Thanks!","b62104c7":"## **K-Neighbors Classifier**","faad0bb4":"# **Model Building**","16793743":"Logistic Regression calculates the probabilities of an observation falling under a particular class by using a sigmoid curve.","117d107d":"# **Feature Engineering**","f0604bb1":"# **Quick Inspection of Dataset**","cf5bc321":"The dataset we have consist of different attributes of the heart patients as follows.\n- Age (Age of the patient)\n- Creatinine (Level of the CPK enzyme in the blood (mcg\/L))\n- Aneamia (Decrease of red blood cells or hemoglobin)\n- Diabetes (If the patient has diabetes)\n- Ejection Fraction (Percentage of blood leaving the heart at each contraction (percentage))\n- Hypertension (If the patient has hypertension)\n- Platelets (Platelets in the blood (kiloplatelets\/mL))\n- Serum Creatinine (Level of serum creatinine in the blood (mg\/dL))\n- Serum Sodium (Level of serum sodium in the blood (mEq\/L))\n- Sex (Gender of the patient)\n- Smoking (If the patient smokes or not (boolean))\n- Time (Follow-up period (days))\n- Death Event (If the patient deceased during the follow-up period)","ca5f43f9":"## **Are elder patients more prone to heart failure**","e47eafb8":"We've split in such a way that the testing set has 30% of the data. The parameter 'stratify' ensures that the equal distribution of the dependant feature is split across different sets.","6e2f3ab2":"**Inference**\n- The CPK enzyme level in the blood of affected patients is more than the others.\n- Eventhough the difference in enzyme level between both the groups tend to be less, this may also be one of the factors.","602ae5fb":"Decision Tree algorithm creates a model that can use to predict the class or value of the target variable by learning simple decision rules inferred from training dataset.","7041d8d9":"The K-Neighbors Classifier predicts the target label by considering the k-neighbors.","37db045e":"# **Objective**","7f8f0eaf":"The training and testing score are low.","bda8168e":"Let's build a baseline model with all the features in the dataset. The dataset has 12 independant features. We'll then reduce the model complexity by reducing the number of independant features.","d37d8ffa":"# **Further Steps**","3b5d0d92":"The training and test scores both look to be decent. Let's try other models as well to conclude on the best approach.","dc5ba7e1":"The primary objective of this notebook is to visualize the trends in the dataset and to predict the heart failure of different patients. There could be many reasons behind the heart failure. We'll use Python's visualization libraries to understand the trends lying in the patient dataset and then build a model to predict the heart failure.","b78a9521":"This gives out the array of weights given by the logistic regression to each of the features.","080a0dd2":"**Inference**\n- 35% of the diabetic patients faced heart failure.\n- Only 29% of the non-diabetic patients suffered heart failure.","3dd25231":"**Inference**\n- 35% of the anaemic patients have faced heart failure while the other 65% did not.","f6f17ef8":"To get the most out of this notebook, make sure that you know the basics of Pandas, Plotly and machine learning algorithms. This notebook is aimed to help the beginners understand the machine learning flow, hence it is prepared simple. No advanced knowledge is required.","5aa8f545":"**Inference**\n- There is no significant difference observed in the two groups.","112acb99":"# **Symptoms**","e701f8df":"- Importing Libraries and Dataset\n- Quick Inspection of Dataset\n- Exploratory Data Analysis\n- Feature Engineering\n- Building Predictive Model","16f3022c":"# **Introduction**","cf64c32c":"## **Decision Tree Classifier**","b9364868":"## **Random Forest Classifier**","1f271537":"## **Naive Bayes Classifier**","0c14a82a":"# **Table of Contents**","e3b04896":"The training score is 1.0 whereas the testing score is 0.77.","f4ed6df1":"## **Impact of Sodium level in Heart Failure**","55379fd5":"Let's try with reduced number of features to avoid the model getting more complex. We'll try different combinations and conclude the best one.","a96955a7":"## **Does platelets count really matter**","f7ad1805":"## **Influence of CPK Enzyme in Heart Failure**","9aaaa35d":"The SVM model gives pretty decent training and testing score.","543ff0eb":"## **Are BP patients more prone to heart failure**","9bb099d6":"# **Exploratory Data Analysis**","4c39a1fc":"Random Forest is an ensemble method which is collection of multiple decision trees. The predictions from different decision trees are aggregated to obtain the final prediction.","cb96a23f":"## **Is a particular gender more prone to heart failure**","b2957af6":"- This dataset is fairly clean and does not require any imputation as it does not have any missing values. \n- The datatypes of the features are also meaningful and does not require any type conversion.","4b40896e":"## **Does the fluctuation in percentage of blood leaving the heart makes it to fail**","ef36e34c":"**Inference**\n- The ejection percentage of blood in patients who suffered heart failure is more than others.","a393ed7a":"The baseline model was first built and then it was fine tuned. The more complex model may lead to overfitting whereas the least complex model may lead to underfitting. Hence it is very important to make sure that the model learnt the underlying patterns in the data. The model can be further improved by,\n\n- Hyperparamater tuning \n    - By performing GridSearchCV or RandomStratifiedCV\n- Averaging techniques\n    - By using either hard or soft Voting Classifier\n- Bagging techniques\n    - Bagging Classifier\n- Boosting techniques\n    - AdaBoost Classifier\n    - Gradient Boosting Classifier\n    - Extreme Gradient Boosting","fc7566f0":"## **Support Vector Classifier**","1cd22e20":"The independant and dependant features need to be split into two different dataframes.","bfc3c070":"## **What difference does serum creatinine make**","ebef6aa6":"## **Is a decrease in heamoglobin cause heart failure**","1135445a":"The model performs decently in both training and testing datasets with an accuracy of ~84%. This tells us that the model is neither underfitted nor overfitted.","43cd8113":"Training score is 1.0, which is ideal. But the testing score is 0.7 which clearly says that the model is overfitting on the training dataset.","ff2f3ad9":"## **Impact of smoking on the functioning of heart**","c37fef10":"The symptoms of heart failure are including but not limited to,\n- Chest Pain\n- Fatigue\n- Swelling in body parts\n- Fainting\n- Shortness in breath","1cb5a107":"**Inference:**\n- The median age of patients whose heart failed is higher than others.\n- This makes sense as the elder patients tend to suffer from heart failure.","9a0e4006":"**Inference**\n- The serum creatinine level in the patients who suffered heart failure is more than the others.","e39fff70":"# **Conclusion**","1e86a127":"The accuracy on the training set is high and testing dataset is pretty low.","80857615":"Let's split up the features and then scale them since the features are of different scales."}}