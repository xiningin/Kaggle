{"cell_type":{"cc8a9ef7":"code","8b6a26e1":"code","f63b8ece":"code","1725531f":"code","12e748b2":"code","5b980203":"code","2b898825":"code","a772bb13":"code","6e80a72a":"code","fd0c0dac":"code","da470104":"code","64348cee":"code","903c875b":"code","bdc0a29a":"markdown","00cf9f72":"markdown"},"source":{"cc8a9ef7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b6a26e1":"from keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\n\nimport tensorflow as tf\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","f63b8ece":"DATASET_DIR = \"\/kaggle\/input\/covid19-patient-xray-image-dataset\/COVID-19 patient X-ray image dataset\/corona\/train\"","1725531f":"os.listdir(DATASET_DIR)","12e748b2":"import glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nprint(\"-----------------------\")\nnormal_images = []\nfor img_path in glob.glob(DATASET_DIR + '\/normal\/*'):\n    normal_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('normal')\nplt.imshow(normal_images[0], cmap='gray') \n\n\ncovid_images = []\nfor img_path in glob.glob(DATASET_DIR + '\/corona\/*'):\n    covid_images.append(mpimg.imread(img_path))\n\nfig = plt.figure()\nfig.suptitle('covid')\nplt.imshow(covid_images[0], cmap='gray')","5b980203":"print(len(normal_images))\nprint(len(covid_images))","2b898825":"IMG_W = 150\nIMG_H = 150\nCHANNELS = 3\n\nINPUT_SHAPE = (IMG_W, IMG_H, CHANNELS)\nNB_CLASSES = 2\nEPOCHS = 40\nBATCH_SIZE = 20","a772bb13":"model=tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(INPUT_SHAPE)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    \n    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(32,activation='relu'),\n    #tf.keras.layers.Dropout(0.25)\n    tf.keras.layers.Dense(1,activation='sigmoid')\n    \n    \n])","6e80a72a":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',\n                  optimizer=RMSprop(lr=0.001),\n                  metrics=['accuracy'])","fd0c0dac":"print(model.summary())","da470104":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.3)\n\ntrain_generator = train_datagen.flow_from_directory(\n    DATASET_DIR,\n    target_size=(IMG_H, IMG_W),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    DATASET_DIR, \n    target_size=(IMG_H, IMG_W),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle= False,\n    subset='validation')\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ BATCH_SIZE,\n    epochs = EPOCHS)","64348cee":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","903c875b":"label = validation_generator.classes\npred= model.predict(validation_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","bdc0a29a":"Prediction","00cf9f72":"Graphical Visulization"}}