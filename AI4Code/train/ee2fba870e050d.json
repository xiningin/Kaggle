{"cell_type":{"3e85eec7":"code","5ca6b3dc":"code","1c675d99":"code","9f062b14":"code","5208d148":"code","d520c981":"code","a3a2419c":"code","c8c62601":"code","239cce34":"code","3d2e541c":"code","24afdfb9":"code","6a64ee3b":"code","09eef1de":"code","a41efe97":"code","bfc2a6fa":"code","7b0cd881":"code","e068466a":"code","ea93497d":"code","3b8def20":"code","c6651871":"code","50a6d002":"code","3c7c22a2":"code","bd18354f":"code","932875b9":"code","686e3d36":"code","cf568d3f":"code","3f9d43fe":"code","e520fec9":"markdown","a5c951c1":"markdown","99735751":"markdown","cda06b50":"markdown"},"source":{"3e85eec7":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom IPython.display import display\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nimport gc\nimport lightgbm as lgb\n\n\nimport re","5ca6b3dc":"pd.options.display.max_columns = None\nInteractiveShell.ast_node_interactivity = \"all\"","1c675d99":"traindf = pd.read_csv('..\/input\/titanic\/train.csv')\ntestdf = pd.read_csv('..\/input\/titanic\/test.csv')","9f062b14":"print('check missing value on training dataset')\nprint('-'*120)\nmissing_value_1 = traindf.isnull().sum()\nmissing_value_1\n\nprint('check missing value on test dataset')\nprint('-'*120)\nmissing_value_2 = testdf.isnull().sum()\nmissing_value_2","5208d148":"traindf['Survived'].value_counts().plot(kind='bar',title='Unbalance target variable')","d520c981":"ax = testdf[\"Age\"].hist(bins=15, color='blue', alpha=0.9)\nax.set(xlabel='Age', ylabel='Count')\nplt.show()","a3a2419c":"ax = testdf[\"Fare\"].hist(bins=15, color='blue', alpha=0.9)\nax.set(xlabel='Fare', ylabel='Count')\nplt.show()","c8c62601":"print('Fill missing value on train dataset')\nprint('-'*120)\ntraindf.loc[traindf.Cabin.isnull(), 'Cabin'] = 'Unknown'\ntraindf['Age'].fillna(28, inplace=True)\ntraindf['Embarked'].fillna('S', inplace=True)\n\nprint('Fill missing value on test dataset')\nprint('-'*120)\ntestdf['Age'].fillna(27, inplace=True)\ntestdf['Fare'].fillna(14, inplace=True)\ntestdf.loc[testdf.Cabin.isnull(), 'Cabin'] = 'Unknown'","239cce34":"print('Feature engineering: create new feature and change cabin value')\nprint('-'*120)\ntraindf['FamilySize'] = traindf['SibSp'] + traindf['Parch'] + 1\ntraindf['Cabin'] = traindf['Cabin'].map(lambda x:re.compile(\"([a-zA-Z])\").search(x).group())\ntestdf['FamilySize'] = testdf['SibSp'] + testdf['Parch'] + 1\ntestdf['Cabin'] = testdf['Cabin'].map(lambda x:re.compile(\"([a-zA-Z])\").search(x).group())","3d2e541c":"print('Check missing value on train dataset')\nprint('-'*120)\ntraindf.isnull().sum()\n\nprint('Check missing value on test dataset')\nprint('-'*120)\ntestdf.isnull().sum()","24afdfb9":"print('Check order of Cabin based on number of survived and unsurvived')\nprint('-'*120)\na = traindf[['PassengerId','Cabin','Survived']].groupby('Cabin', as_index=False).agg({\n    'PassengerId': 'count',\n    'Survived': 'sum'\n})\n\na['CabinGroup'] = a.Cabin.str[0]\na = a[['PassengerId','Survived','CabinGroup']].groupby('CabinGroup').agg({\n    'PassengerId' : 'sum',\n    'Survived': 'sum'\n})\n\na['Unsurvived'] = a['PassengerId'] - a['Survived']\na['Survived_perc'] = (a['Survived']\/a['PassengerId'])*100\na['Unsurvived_perc'] = (a['Unsurvived']\/a['PassengerId'])*100\n\na.head(10)","6a64ee3b":"print('Check order of Title based on number of survived and unsurvived')\nprint('-'*120)\n\ncopy_df = traindf.copy()\ncopy_df['Title'] = copy_df['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n\nb = copy_df[['PassengerId','Title','Survived']].groupby('Title', as_index=False).agg({\n    'PassengerId': 'count',\n    'Survived': 'sum'\n})\n\n\nb['Unsurvived'] = b['PassengerId'] - b['Survived']\nb['Survived_perc'] = (b['Survived']\/b['PassengerId'])*100\nb['Unsurvived_perc'] = (b['Unsurvived']\/b['PassengerId'])*100\n\nb.head(17)","09eef1de":"print('Change Title value based on number of percentage survived and unsurvived')\nprint('-'*120)\n\nunsurvived_title_order = {'Capt':8, 'Col':5, 'Don':8, 'Dr':6, 'Jonkheer':8, 'Lady':1, 'Major':5, 'Master':4,\n       'Miss':3, 'Mlle':1, 'Mme':1, 'Mr':7, 'Mrs':2, 'Ms':1, 'Rev':8, 'Sir':1,\n       'the Countess':1}\nsurvived_title_order = {'Capt':1, 'Col':4, 'Don':1, 'Dr':3, 'Jonkheer':1, 'Lady':8, 'Major':4, 'Master':5,\n       'Miss':6, 'Mlle':8, 'Mme':8, 'Mr':2, 'Mrs':7, 'Ms':8, 'Rev':1, 'Sir':8,\n       'the Countess':8}\ntraindf['Title'] = traindf['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\ntestdf['Title'] = testdf['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\ntraindf['TitleSurvivedOrder'] = traindf['Title'].map(survived_title_order)\ntraindf['TitleUnsurvivedOrder'] = traindf['Title'].map(unsurvived_title_order)\ntestdf['TitleSurvivedOrder'] = testdf['Title'].map(survived_title_order)\ntestdf['TitleUnsurvivedOrder'] = testdf['Title'].map(unsurvived_title_order)","a41efe97":"testdf['TitleSurvivedOrder'].fillna(0, inplace=True)\ntestdf['TitleUnsurvivedOrder'].fillna(0, inplace=True)","bfc2a6fa":"print('Change cabin value based on number of percentage survived and unsurvived')\nprint('-'*120)\n\n#Survived : DEBFCGAUT\n#Unsurvived: TUAGCFBED\nunsurvived_cabin_order = {'A':7,'B':3,'C':5,'D':1,'E':2,'F':4,'G':6,'T':9,'U':8}\nsurvived_cabin_order = {'A':3,'B':7,'C':5,'D':9,'E':8,'F':6,'G':4,'T':1,'U':2}\n\ntraindf['CabinSurvivedOrder'] = traindf['Cabin'].map(survived_cabin_order)\ntraindf['CabinUnsurvivedOrder'] = traindf['Cabin'].map(unsurvived_cabin_order)\ntestdf['CabinSurvivedOrder'] = testdf['Cabin'].map(survived_cabin_order)\ntestdf['CabinUnsurvivedOrder'] = testdf['Cabin'].map(unsurvived_cabin_order)","7b0cd881":"print('Transform and map sex feature on train dataset & test dataset')\nprint('-'*120)\nsex_le = LabelEncoder()\nsex_le_2 = LabelEncoder()\nsex_labels = sex_le.fit_transform(traindf['Sex'])\nsex_labels_2 = sex_le_2.fit_transform(testdf['Sex'])\ntraindf['Sex_Label'] = sex_labels\ntestdf['Sex_Label'] = sex_labels_2\n\nprint('Transform and map embarked feature on train dataset & test dataset')\nprint('-'*120)\nembk_le = LabelEncoder()\nembk_le_2 = LabelEncoder()\nembk_labels = embk_le.fit_transform(traindf['Embarked'])\nembk_labels_2 = embk_le_2.fit_transform(testdf['Embarked'])\ntraindf['Embk_Label'] = embk_labels\ntestdf['Embk_Label'] = embk_labels_2","e068466a":"# encode sex labels using one-hot encoding scheme\nprint('Encode sex labels using one-hot encoding scheme for train & test dataset')\nprint('-'*120)\nsex_ohe = OneHotEncoder()\nsex_ohe_2 = OneHotEncoder()\nsex_feature_arr = sex_ohe.fit_transform(\n                              traindf[['Sex_Label']]).toarray()\nsex_feature_arr_2 = sex_ohe_2.fit_transform(\n                              testdf[['Sex_Label']]).toarray()\n\nsex_feature_labels = list(sex_le.classes_)\nsex_features = pd.DataFrame(sex_feature_arr, \n                            columns=sex_feature_labels)\nsex_features_2 = pd.DataFrame(sex_feature_arr_2, \n                            columns=sex_feature_labels)\n\nprint('Encode embarked labels using one-hot encoding scheme for train & test dataset')\nprint('-'*120)\nembk_ohe = OneHotEncoder()\nembk_ohe_2 = OneHotEncoder()\nembk_feature_arr = embk_ohe.fit_transform(\n                                traindf[['Embk_Label']]).toarray()\nembk_feature_arr_2 = embk_ohe_2.fit_transform(\n                                testdf[['Embk_Label']]).toarray()\n\nembk_feature_labels = list(embk_le.classes_)\nembk_feature_labels_2 = list(embk_le_2.classes_)\n\nembk_features = pd.DataFrame(embk_feature_arr, \n                            columns=embk_feature_labels)\nembk_features_2 = pd.DataFrame(embk_feature_arr_2, \n                            columns=embk_feature_labels_2)\nprint('Encode pclass labels using one-hot encoding scheme for train & test dataset')\nprint('-'*120)\nstatus_ohe = OneHotEncoder()\nstatus_ohe_2 = OneHotEncoder()\nstatus_feature_arr = status_ohe.fit_transform(\n                                traindf[['Pclass']]).toarray()\nstatus_feature_arr_2 = status_ohe_2.fit_transform(\n                                testdf[['Pclass']]).toarray()\nstatus_feature_labels = ['Upper', 'Middle', 'Lower']\nstatus_features = pd.DataFrame(status_feature_arr, \n                            columns=status_feature_labels)\nstatus_features_2 = pd.DataFrame(status_feature_arr_2, \n                            columns=status_feature_labels)\n\ntraindf = pd.concat([traindf, sex_features, status_features, embk_features], axis=1)\n\ntestdf = pd.concat([testdf, sex_features_2, status_features_2, embk_features_2], axis=1)","ea93497d":"print('Remove Unneccessary on train dataset')\nprint('-'*120)\ntraindf.drop(['Name','Ticket','PassengerId','Sex','SibSp','Parch','Embarked',\n             'Sex_Label','Embk_Label','Cabin','Title'],axis=1,inplace=True)\n\nprint('Remove Unneccessary on test dataset')\nprint('-'*120)\ntestdf.drop(['Name','Ticket','Sex','SibSp','Parch','Embarked',\n             'Sex_Label','Embk_Label','Cabin','Title'],axis=1,inplace=True)","3b8def20":"traindf.corr()","c6651871":"cols=[c for c in traindf.columns if c not in ['Survived', 'PassengerId']]\ny = traindf[\"Survived\"]\nx = traindf[cols]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","50a6d002":"rb = RobustScaler(with_centering=True,copy=False)\nx_train = rb.fit_transform(x_train)\nx_test = rb.fit_transform(x_test)\ntransform_2 = rb.fit_transform(testdf[cols])\ntestdf[cols] = transform_2","3c7c22a2":"params = {\n    'num_iterations': 1000000,\n    'learning_rate': 0.01,\n    'early_stopping_rounds':2500,\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'boosting' : 'gbdt',\n    'is_unbalance': True,\n    'max_depth': 10\n}","bd18354f":"train_data = lgb.Dataset(x_train, label=y_train)\nvalid_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n\nlgbmodel = lgb.train(params, train_data,                     \n                 valid_sets=[valid_data],\n                 valid_names=['valid'],\n                 verbose_eval=1000)\ny_pred = lgbmodel.predict(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test, y_pred.round(0).astype(int))*100)\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred.round(0).astype(int))*100))","932875b9":"regr = RandomForestClassifier(max_depth=5, random_state=42)\n\nscores = cross_val_score(regr, x_train, y_train, cv=5)\nprint(\"Accuracy on train data: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\nregr.fit(x_train, y_train.ravel())\n#Predict the response for test dataset\ny_pred = regr.predict(x_test)\n\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test.ravel(), y_pred)*100)\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)*100))","686e3d36":"dtclf = DecisionTreeClassifier(max_depth = None, criterion='gini')\n\nscores = cross_val_score(dtclf, x_train, y_train, cv=5)\nprint(\"Accuracy on train data: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\ndtclf.fit(x_train, y_train.ravel())\n\n#Predict the response for test dataset\ny_pred = dtclf.predict(x_test)\n\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test.ravel(), y_pred)*100)\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)*100))","cf568d3f":"logreg = LogisticRegression(max_iter=10000, C=5)\n\nscores = cross_val_score(logreg, x_train, y_train, cv=10)\nprint(\"Accuracy on train data: %0.2f (+\/- %0.2f)\" % (scores.mean(), scores.std() * 2))\nlogreg.fit(x_train, y_train.ravel())\n\ny_pred = logreg.predict(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test.ravel(), y_pred)*100)\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)*100))","3f9d43fe":"y_pred_1 = logreg.predict(testdf[cols].to_numpy())\ny_pred_2 = dtclf.predict(testdf[cols].to_numpy())\ny_pred_3 = regr.predict(testdf[cols].to_numpy())\ny_pred_4 = lgbmodel.predict(testdf[cols].to_numpy()).round(0).astype(int)\n\ntestdf['Survived'] = y_pred_1\ntestdf[['PassengerId','Survived']].to_csv('TitanicSubmission1.csv', index=False)\n\ntestdf['Survived'] = y_pred_2\ntestdf[['PassengerId','Survived']].to_csv('TitanicSubmission2.csv', index=False)\n\ntestdf['Survived'] = y_pred_3\ntestdf[['PassengerId','Survived']].to_csv('TitanicSubmission3.csv', index=False)\n\ntestdf['Survived'] = y_pred_4\ntestdf[['PassengerId','Survived']].to_csv('TitanicSubmission4.csv', index=False)","e520fec9":"# Logistic Regression","a5c951c1":"# Decision Tree","99735751":"# Random Forest","cda06b50":"## Light Boost Method Decision Tree"}}