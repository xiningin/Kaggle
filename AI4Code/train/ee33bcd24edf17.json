{"cell_type":{"713610d9":"code","d3db47c9":"code","d1427948":"code","2a327e3c":"code","4cc1a6c9":"code","529f5b2b":"code","bd04374e":"code","ea5b1052":"code","cf568fbd":"code","5612662b":"code","bce6d175":"code","c8f446fe":"code","72fb6ece":"code","1a510691":"code","47f8880c":"code","983128a4":"code","b07cf54a":"code","0cb7f6eb":"code","d39da5b5":"code","126e6a4a":"code","5dcb6577":"code","e8fe7278":"code","155b7615":"code","d04afeb6":"code","8ef56d0a":"code","093180ac":"code","3ac9fcdc":"code","c145e3d9":"code","562d91e0":"code","558ac85a":"markdown","24f7c806":"markdown","ee4a9bf2":"markdown","38dd92f5":"markdown","fb4b1da8":"markdown","43d34d62":"markdown","c80288d9":"markdown","6ecbc388":"markdown","9149825c":"markdown","f54be8c1":"markdown","dd445b83":"markdown","23739c64":"markdown","019242d8":"markdown","8b130ca2":"markdown","903e6ff9":"markdown","825b4e15":"markdown","c011de8f":"markdown","60d343d1":"markdown","bf21d803":"markdown","799e33e6":"markdown","c5a1eb8f":"markdown","dd06fc02":"markdown","94c81685":"markdown","959f5f66":"markdown","c783fc19":"markdown"},"source":{"713610d9":"# Basics:\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Geospatial analysis:\nimport geopandas as gpd \nfrom geopandas.tools import geocode\nimport folium # interactive maps\nfrom folium import Circle, Marker,GeoJson,Icon\nfrom folium.plugins import HeatMap, MarkerCluster\nimport math\nfrom geopy.geocoders import Nominatim\nfrom geopy import distance\n\n# Linear regression:\nimport statsmodels.api as sm\n#\u00a0Predictions:\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n","d3db47c9":"# Defining colors for the visualizations that match Airbnb's design\ncolor1=\"#FF5A60\"\ncolor2=\"#565a5d\"\ncolor3=\"#cfd1cc\"\ncolor4=\"#007a87\"\n\n# Setting style for visualizations\",\nsns.set_style(\"darkgrid\")","d1427948":"# Loading data\nnyc_data = pd.read_csv(\"..\/input\/AB_NYC_2019.csv\")\nnyc_data.head()","2a327e3c":"print(nyc_data.isnull().sum(axis=0))","4cc1a6c9":"cols_without_nans=list(nyc_data.columns[~nyc_data.isna().any()])\n# Only keeping columns with no NaNs and reviews_per_month:\nnyc_data=nyc_data[cols_without_nans+[\"reviews_per_month\"]]\n\n# Impute the mean for the reviews_per_month column:\nnyc_data=nyc_data.fillna(nyc_data.mean())\n\nprint(\"\\n\")\nprint(\"Any NaNs after cleaning?:\",nyc_data.isnull().any().any())\n","529f5b2b":"nyc_data.describe()","bd04374e":"f, axes = plt.subplots(1, 2,figsize=(12,5))\nsns.distplot(nyc_data[\"price\"],color=color2,ax=axes[0]).set(title=\"Price distribution\")\nsns.distplot(nyc_data[nyc_data[\"price\"]<2000][\"price\"],color=color1,ax=axes[1]).set(\n    title=\"Price distribution of Airbnb listings below 2000 $ per night\")","ea5b1052":"f, axes = plt.subplots(1, 2,figsize=(12,5))\nsns.distplot(nyc_data[\"number_of_reviews\"],color=color1,ax=axes[0]).set(\n    title=\"Distribution of the number of reviews per listing\",xlabel=\"\")\nsns.distplot(nyc_data.dropna()[\"reviews_per_month\"],color=color2,ax=axes[1]).set(\n    title=\"Distribution of the number of reviews per listing per month\",xlabel=\"\")","cf568fbd":"f, axes = plt.subplots(1, 2,figsize=(12,5))\nsns.countplot(y=\"room_type\",data=nyc_data,orient=\"h\",\n                color=color1,ax=axes[0]).set(title='Number of listing per room type', ylabel='')\n\nsns.barplot(y=list(nyc_data.groupby(\"room_type\").mean()[\"price\"].index),\n            x=list(nyc_data.groupby(\"room_type\").mean()[\"price\"].values),\n            ax=axes[1],color=color2,orient=\"h\").set(title='Price per room type')\n\nplt.tight_layout()","5612662b":"f, axes = plt.subplots(1, 2,figsize=(12,5))\nsns.countplot(y=\"neighbourhood_group\",data=nyc_data,orient=\"h\",\n                color=color1,ax=axes[0]).set(title='Boroughs', ylabel='')\n\nmost_frequent_neighborhoods=nyc_data[\"neighbourhood\"].value_counts()[0:10].index.tolist()\nprint(\"The most neighborhoods with the most Airbnb listings are:  \\n\")\nfor neighborhood in most_frequent_neighborhoods:\n    print(neighborhood)\n\nsns.countplot(y=\"neighbourhood\",data=nyc_data[nyc_data[\"neighbourhood\"].isin(most_frequent_neighborhoods)]\n            ,orient=\"h\",color=color1,ax=axes[1]).set(title='Neighbourhoods', ylabel='')\nplt.tight_layout()","bce6d175":"# Defining a color palette\npalette ={\"Private room\": color2, \"Entire home\/apt\": color1, \"Shared room\": color3}\nsns.barplot(x='neighbourhood_group', y='price', hue='room_type',data=nyc_data,palette=palette).set(\n    ylabel=\"Price\",xlabel=\"Borough\",title=\"Average price in the five boroughs according to room type\")","c8f446fe":"TimesSquare=[40.758896,-73.985130] #Latitude and longitude of Times Square\n\n# Creating a map with Time Square as its starting location:\nm_1 = folium.Map(location=TimesSquare, tiles='cartodbpositron', zoom_start=12)\n\n# Add markers for Airbnb listings:\nmc = MarkerCluster()\nfor idx, row in nyc_data.iterrows():\n    if not math.isnan(row['longitude']) and not math.isnan(row['latitude']):\n        mc.add_child(Marker([row['latitude'], row['longitude']]))\nm_1.add_child(mc)\n\n# Display the map\nm_1","72fb6ece":"m_2 = folium.Map(location=TimesSquare, tiles='cartodbpositron', zoom_start=11)\n\n# Add a heatmap to the base map\nHeatMap(data=nyc_data[['latitude', 'longitude']], radius=10).add_to(m_2)\n\n# Display the map\nm_2","1a510691":"# Get the names of top tourist attractions (according to Google)\ntop_sights=[\"Empire State Building\",\"Central Park\",\"Times Square\",\"Brooklyn Bridge\",\n            \"The Metropolitan Museum of Art\",\"Museum of Modern Art\",\"Rockefeller Center\",\n            \"The High Line\",\"Grand Central Terminal\",\"One World Trade Center\"]\n\n# This object can be used to return latitude and longitude values for a named location\nlocator = Nominatim(user_agent=\"myGeocoder\")\n\n#\u00a0We will store the location data for top sights in the top_sights list\ntop_sight_locations=[]\nfor sight in top_sights:\n    location=locator.geocode(sight)\n    top_sight_locations.append((location.latitude,location.longitude))\n    \n# Let's check if we all locations are correct (i.e. are in New York City) by displaying them on a map\nm_3 = folium.Map(location=TimesSquare, tiles='cartodbpositron', zoom_start=12)\n\nfor i in range(len(top_sight_locations)):\n    loc=top_sight_locations[i]\n    Marker([loc[0], loc[1]],popup=top_sights[i],icon=Icon(color=\"gray\")).add_to(m_3)\n\n# Display the map\nm_3","47f8880c":"def get_distance(loc_from,loc_to):\n    \"\"\"\n    Returns the distance between two locations\n    Input: \n        loc_from: tuple or list of latitude and longitude coordinates\n        loc_to:   tuple or list of latitude and longitude coordinates\n        \n    Output: \n        dis:      distance (in kilometers)\n    \"\"\"\n    dis=distance.distance(loc_from,loc_to).km   \n    return dis","983128a4":"# Example - the second row entry of the database is a \"Skylit Midtown Castle\":\nSkylitMidtownCastle=nyc_data.iloc[1]\nSkylitMidtownCastle_distances = [get_distance(\n                        (SkylitMidtownCastle.latitude,SkylitMidtownCastle.longitude),\n                        (sight[0],sight[1])) \n                        for sight in top_sight_locations]\nprint(\"Distance from: \\n\")\nfor i in range(len(top_sights)):\n    print(top_sights[i],\": \",round(SkylitMidtownCastle_distances[i],2),\"kilometers\")","b07cf54a":"# Create the map\nm_4 = folium.Map(location=TimesSquare, tiles='cartodbpositron', zoom_start=12)\n\n# Add the Airbnb listing\nMarker([SkylitMidtownCastle.latitude, SkylitMidtownCastle.longitude],\n       popup=\"Skylit Midtown Castle\",icon=Icon(color=color1)).add_to(m_4)\n\n# Add top sights and lines between them and the Skylit Midtown Castle\nfor i in range(len(top_sight_locations)):\n    loc=top_sight_locations[i]\n    Marker([loc[0], loc[1]],popup=top_sights[i],icon=Icon(color=\"gray\")).add_to(m_4)\n    line_from_SkylitMidtownCastle=folium.PolyLine(locations=[\n        [SkylitMidtownCastle.latitude, SkylitMidtownCastle.longitude],[loc[0], loc[1]]],\n                                                  weight=2,color=color1,\n                                                  tooltip=((str(round(SkylitMidtownCastle_distances[i],2)))+\" km\"))\n    m_4.add_children(line_from_SkylitMidtownCastle)\n    \n# Display map\nm_4","0cb7f6eb":"for i in range(len(top_sights)): # Loop through all the top sights\n    column_name=\"dist_from_\"+top_sights[i].replace(\" \",\"_\").lower()\n    # Calculate the distances from each Airbnb listing\n    distances=nyc_data.apply(lambda x: get_distance((x[\"latitude\"],x[\"longitude\"]),(top_sight_locations[i])),axis=1)\n    #\u00a0Add distances to our dataframe\n    nyc_data[column_name]=distances\n\nprint(len(top_sights),\" new columns added to the dataset.\")","d39da5b5":"# calculate distance to closest_sight\nnyc_data[\"dist_to_nearest_sight\"]=nyc_data[[colname for colname in nyc_data.columns \n                                            if colname.startswith(\"dist_from\")]].apply(min,axis=1)","126e6a4a":"y=np.log(nyc_data.price+0.0001)\n# (The + 0.0001 smoothing is needed because some Airbnbs have a price of 0, which we cannot take the logarithm of)","5dcb6577":"#\u00a0Creating a dataframe of the predictors with selected variables\nX_1=pd.concat([pd.Series([1]*len(nyc_data),name=\"(cons)\"), # for constant term\n    nyc_data[[\"minimum_nights\",\"reviews_per_month\",\"number_of_reviews\",\"availability_365\"]],\n# Creating dummies from room_type, shared room is the reference\npd.get_dummies(nyc_data['room_type'])[[\"Entire home\/apt\",\"Private room\"]]], \naxis=1)\n\nX_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y, test_size=0.3, random_state=24)","e8fe7278":"lm_1 = sm.OLS(y_train_1,X_train_1).fit()\nlm_1.summary()","155b7615":"#\u00a0Creating a dataframe of the predictors with selected variables\nX_2=pd.concat([pd.Series([1]*len(nyc_data),name=\"(cons)\"), # for constant term\n    nyc_data[[\"minimum_nights\",\"reviews_per_month\",\"number_of_reviews\",\"availability_365\"]],\n# Creating dummies from neighborhood, bronx is the reference\npd.get_dummies(nyc_data['neighbourhood_group'],drop_first=True), \n# Creating dummies from room_type, shared room is the reference\npd.get_dummies(nyc_data['room_type'])[[\"Entire home\/apt\",\"Private room\"]]], \naxis=1)\n\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y, test_size=0.3, random_state=24)","d04afeb6":"lm_2 = sm.OLS(y_train_2,X_train_2).fit()\nlm_2.summary()","8ef56d0a":"base_vars=[\"minimum_nights\",\"reviews_per_month\",\"number_of_reviews\",\"availability_365\"]\ndistance_vars=[colname for colname in nyc_data.columns if colname.startswith(\"dist\")]\n\n#\u00a0Creating a dataframe of the predictors with selected variables\nX_3=pd.concat([pd.Series([1]*len(nyc_data),name=\"(cons)\"), # for constant term\n    nyc_data[base_vars+distance_vars], \n# Creating dummies from room_type, shared room is the reference\npd.get_dummies(nyc_data['room_type'])[[\"Entire home\/apt\",\"Private room\"]]], \naxis=1)\n\nX_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, test_size=0.3, random_state=24)","093180ac":"lm_3 = sm.OLS(y_train_3,X_train_3).fit()\nlm_3.summary()","3ac9fcdc":"base_vars=[\"minimum_nights\",\"reviews_per_month\",\"number_of_reviews\",\"availability_365\"]\ndistance_vars=[colname for colname in nyc_data.columns if colname.startswith(\"dist\")]\n\n#\u00a0Creating a dataframe of the predictors with selected variables\nX_4=pd.concat([nyc_data[base_vars+distance_vars], \n# Creating dummies from neighborhood, bronx is the reference\npd.get_dummies(nyc_data['neighbourhood_group'],drop_first=True), \n# Creating dummies from room_type, shared room is the reference\npd.get_dummies(nyc_data['room_type'])[[\"Entire home\/apt\",\"Private room\"]]], \naxis=1)\n\nX_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4, y, test_size=0.3, random_state=24)","c145e3d9":"lm = LinearRegression()\nrf = RandomForestRegressor(random_state=24)\ngb = GradientBoostingRegressor(max_depth=10)\n\n# Train the models\nlm.fit(X_train_4, y_train_4)\nrf.fit(X_train_4, y_train_4)\ngb.fit(X_train_4, y_train_4)\n\n# Make predictions using the testing set\ny_hat_lm = lm.predict(X_test_4)\ny_hat_rf = rf.predict(X_test_4)\ny_hat_gb = gb.predict(X_test_4)\n\n\nMSE_lm=mean_squared_error(y_hat_lm,y_test_4)\nMSE_rf=mean_squared_error(y_hat_rf,y_test_4)\nMSE_gb=mean_squared_error(y_hat_gb,y_test_4)\n\nprint(\"Linear Regression Mean Squared Error:\",MSE_lm)\nprint(\"Random Forest Regression Mean Squared Error:\",MSE_rf)\nprint(\"Gradient Boosting Regression Mean Squared Error:\",MSE_gb)","562d91e0":"# Train the models on the dataset without geospatial variables \n#\u00a0Creating a dataframe of the predictors with selected variables\nX_5=pd.concat([nyc_data[base_vars], \n# Creating dummies from neighborhood, bronx is the reference\npd.get_dummies(nyc_data['neighbourhood_group'],drop_first=True), \n# Creating dummies from room_type, shared room is the reference\npd.get_dummies(nyc_data['room_type'])[[\"Entire home\/apt\",\"Private room\"]]], \naxis=1)\n\nX_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X_5, y, test_size=0.3, random_state=24)\n\nlm.fit(X_train_5, y_train_5)\nrf.fit(X_train_5, y_train_5)\ngb.fit(X_train_5, y_train_5)\n\nprint(\"Improvement for Linear Regression:\",\n      round((1-MSE_lm\/mean_squared_error(lm.predict(X_test_5),y_test_5))*100,2),\"%\")\nprint(\"Improvement for Random Forest Regression:\",\n      round((1-MSE_lm\/mean_squared_error(rf.predict(X_test_5),y_test_5))*100,2),\"%\")\nprint(\"Improvement for Gradient Boosting Regression:\",\n      round((1-MSE_lm\/mean_squared_error(gb.predict(X_test_5),y_test_5))*100,2),\"%\")","558ac85a":"We only want to use `reviews_per_month` from the columns that have NaNs. The rest of the columns with missing values can simply be deleted. For reviews_per_month, simple mean imputation will suffice.","24f7c806":"##\u00a02. Exploratory Data Analysis <a class=\"anchor\" id=\"EDA\"><\/a>\n### 2.1 Basic visualizations <a class=\"anchor\" id=\"dataviz\"><\/a>","ee4a9bf2":"Entire homes and private rooms are more common. As to be expected, entire homes are much more expensive than rooms.\n\n#### Boroughs and neighbourhoods","38dd92f5":"Random forest regression performs best. As a final step, I am curious to see how much we gained in prediction performance as a result of using the custom-made \"distance-from-sight\" variables. We can answer this by comparing the MSEs we just calculated with the MSEs resulting from running the same models on the explanatory variables of Model 2 of the previous section. ","fb4b1da8":"In all of the models, the dependent variable will be the log of price. Again, log transformation is performed because the distribution of prices is skewed.","43d34d62":"Maybe for some guests it's not the proximity to a certain tourist attraction is what matters, but that is near to at least one important tourist attraction. To capture this behavior, we can calculate the distance to the closest top attraction:\n","c80288d9":"Linear Regression and Random Forest improved substantially and Gradient Boosting Regression improved a little bit.\n\n## 4. Summary <a class=\"anchor\" id=\"summary\"><\/a>\n\nI have shown that creating and using geospatial variables can improve models, both in terms of explanatory and predictive power. However, we have to note that the inclusion of several distance variables at the same time introduces multicollinearity to a model. This might cause problems, if the locations from which we calculate distances are not selected carefully, or too many new variables are created in this fashion.","6ecbc388":"#### Data cleaning\n\nThe data is well structured for the analysis we intend to perform, but we have to look at missing values.\n\nLet's have a look at which columns have missing values:","9149825c":"Seems correct! Now let's define a function to compute the distance between two points. I use geopy to do this","f54be8c1":"The third model results in an even larger than improvement compared to Model 1, than Model 2. Some of the newly added are significant. This suggests that the distance-from-sight variables are useful in explaining price. The fact that they are not all significant could be due to some multicollinearity. For example, the MoMA and Rockefeller Center are quite close to each other, therefore the corresponding distance variables will have a high correlation. Interestingly, there is a relatively strong positive relationship between distance from Times Square and (the log of) price. Having visited New York as a tourist, I can confirm that many of the cheap, run-down, tourist-trap hotels and hostels are close to Times Square. \n\n## 3.3 Models for predicting price  <a class=\"anchor\" id=\"pred\"><\/a>\n\nWhen we want to accurately predict price, we use all the variables that we have. Furthermore, apart from linear regression, now we can try some more complex models that can introduce some non-linearities to the price model. I use random forest regression and gradient boosting regression.","dd445b83":"The number of reviews (aka the number of guests, or the place's popularity) is also skewed to the right. \n\n#### Room type","23739c64":"## 3. \u00a0Models for price <a class=\"anchor\" id=\"methods\"><\/a>\n\nNow I will create models to explain and predict the price of Airbnb listings. \n\nLatitude and longitude variables are hardly of any use in themselves in a regression, but they can be very informative when used right. For example, a tourist may look at the location of an Airbnb and place it in the city relative to the tourist attractions they want to see. Therefore, I calculate the distances of the Airbnb apartments and rooms of the dataset from the most popular sights of New York city. Hopefully these variables will be informative in the models for price.\n\n### 3.1 Feature Engineering <a class=\"anchor\" id=\"features\"><\/a>","019242d8":"Brooklyn and Manhattan have the most Airbnbs. Regarding neighbourhoods, Williamsburg, Bedford-Stuyvesant and Harlem are the ones where we would find the most options to choose from. \n\nLet's look the average prices for the five boroughs:","8b130ca2":"As expected, the price distribution is very skewed to the right: there are a few incredibly pricey listings, but the majority of them are around 100-250 USD per night. Due to this skewness, I will use the natural logarithm of price for linear regressions.\n\n#### Number of reviews  \/ Number of reviews per month","903e6ff9":"## 3.2 Models for explaining price <a class=\"anchor\" id=\"models\"><\/a>","825b4e15":"Let's look at an example.","c011de8f":"Manhattan is the most expensive, followed by Brooklyn.\n\n### 2.2 Geospatial analysis <a class=\"anchor\" id=\"geo\"><\/a>\n\nI use folium to create an interactive map with all the Airbnb listings of the dataset. The map has Times Square as its center point. The bubbles show many listings there are in that area. Clicking on the bubbles zoomes on the map.  ","60d343d1":"### 3.2.1 Model I - No location variables <a class=\"anchor\" id=\"model1\"><\/a>\nFirst let's look at the case where we don't include variables that have anything to do with location - not even information on the borough.","bf21d803":"All variables except `reviews_per_month` are significant at 5% significance level. Surprisingly, there is negative relationship between the number of reviews and price.\n\n### 3.2.2 Model II - Borough dummies <a class=\"anchor\" id=\"model2\"><\/a>\n\nIn our second setup, we include borough dummies.","799e33e6":"There are 48,895 Airbnb listings in the dataset. Each have location data, which we'll use. Price is given per night, in USD. Surprisingly, there are free Airbnbs in New York City. How nice! The median is 106 USD, which is quite expensive. The number of reviews and the number of reviews per month can be a proxy for how many guests have been at the place. \n\nStrangely, there is no data on how many guests these places can welcome, although this piece of information could be quite useful. We don't have any data on number stars given in the reviews either. \n\nLet's zoom in on some of these features.\n\n#### Price","c5a1eb8f":"This second model seems to be better based on the Adj. R-squared value. In this model, `reviews_per_month` becomes significant. All four boroughs are associated with a higher price (although Staten Island is not significant), which suggests that they are all more expensive than the Bronx.\n\n### 3.2.3 Model III - Geospatial distance variables <a class=\"anchor\" id=\"model3\"><\/a>\n\nFinally, we include the newly created distance variables in our third and final explanatory model.","dd06fc02":"Let us also visualize these distances:","94c81685":"# Geospatial analysis of New York City Airbnb data & modeling price\n\nIn this project I am looking the the [New York City Airbnb dataset](https:\/\/www.kaggle.com\/dgomonov\/new-york-city-airbnb-open-data\/notebooks) and I apply what I learned in the Kaggle Learn course on [Geospatial Analysis](https:\/\/www.kaggle.com\/learn\/geospatial-analysis).\n\nFirst, I explore the data through basic data visualizations and some interactive maps using Folium. In Section 3.1 I define some additional variables, such as the distance between Airbnb listings and top NYC sights like the Empire State Building and the Brooklyn Bridge. I investigate what effect these variables have on price in Section 3.2. This is done via linear models using different sets of variables. In Section 3.3, along with Linear Regression, I use Random Forest and Gradient Boosting regressions for price prediction and compare the models performance.\n\n### Table of Contents\n\n* [1 Preparations](#prep)\n* [2 Exploratory Data Analysis](#EDA)\n    * [2.1 Basic visualizations](#dataviz)\n    * [2.2 Geospatial Analysis](#geo)\n* [3 Modeling price](#methods)\n    * [3.1 Feature engineering](#pred)\n    * [3.2 Models for explaining price](#models)\n        * [3.2.1 Model 1 - No location variables](#model1)\n        * [3.2.2 Model 2 - Borough dummies](#model2)\n        * [3.2.3 Model 3 - Distance from sights](#model3)\n    * [3.3 Models for predicting price](#pred)\n* [4 Summary](#summary)\n\n\n## 1. Preparations <a class=\"anchor\" id=\"prep\"><\/a>","959f5f66":"Another way to visualize where most of the Airbnb's are is via a heatmap. Let's see:","c783fc19":"Now that we are confident that our calculations are right, we can compute the distances for all entries in our dataset"}}