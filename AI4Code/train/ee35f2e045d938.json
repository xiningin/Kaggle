{"cell_type":{"056c8e72":"code","37b9d0fc":"code","26597682":"code","9fb7d844":"code","5d86ce4a":"code","d3cfd46e":"code","92d99c14":"code","123064c2":"code","7c64188d":"code","73e94339":"code","cd2c64ff":"code","eea3ce27":"code","517d81a2":"code","708c6e0c":"markdown","9b3d475a":"markdown","89ec136d":"markdown","d37998e1":"markdown","2a8525c0":"markdown","38d60f61":"markdown","0c121388":"markdown","a9381768":"markdown","36ff72ad":"markdown","621af95f":"markdown","953a6ca0":"markdown","5298377f":"markdown","766d415f":"markdown","25402f19":"markdown","01845e77":"markdown"},"source":{"056c8e72":"import pandas as pd\nimport numpy as np\nimport keras as ks\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","37b9d0fc":"# Check for null values\ntrain.isna().sum().sum()\ntest.isna().sum().sum()","26597682":"train['label'].value_counts()","9fb7d844":"#%% Preprocess\ny_train =  train['label'].copy()\nX_train =  train.drop(['label'], axis = 1)\n\n# Normalize pixel values which helps during model fitting\nX_train = (X_train \/ 255)\ntest = (test \/ 255)\n\n# Convert to numpy arrays which play well with keras\nX_train = X_train.to_numpy()\ny_train = y_train.to_numpy()\ntest = test.to_numpy()\n\n# one-hot encode the response variable, the required imput for this NN in keras\ny_train = to_categorical(y_train)\n\n\n# Pixel values for the 28 * 28 image were flattened into a single row in the \n# provided data files. Reconstruct the 3D structure, which is needed for \n# keras's Conv2D(): 28 (rows) * 28 (columns) * 1 (channel i.e. grayscale)\n\nX_train = X_train.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)","5d86ce4a":"random_int = np.random.randint(0, len(X_train))\nplt.imshow(X_train[random_int][:,:,0])\nplt.title(\"Character is labelled as: \" + str(y_train[random_int]))","d3cfd46e":"X_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size = 0.2, random_state=100\n    )","92d99c14":"datagen = ks.preprocessing.image.ImageDataGenerator(\n    rotation_range=0.1, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.1, zoom_range=0.1\n    )\ndatagen.fit(X_train) # I'm not sure if 'fitting' is necessary for these datagen parameters, but it shouldn't hurt","123064c2":"iterator = datagen.flow(X_train, y_train, batch_size = 1)\nsample = iterator.next()\nplt.imshow((sample[0][0]*255).astype('uint8'))\nplt.title(\"Character is labelled as: \" + str(sample[1]))","7c64188d":"model = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size=(3,3), activation = 'relu', \n                      padding = 'Same',input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 64, kernel_size=(3,3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 64, kernel_size=(3,3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 64, kernel_size=(3,3), activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10,activation='softmax'))","73e94339":"model.compile(\n    optimizer = 'adam', loss = 'categorical_crossentropy', metrics=(['accuracy'])\n)\n\nearly_stopping = EarlyStopping(\n    monitor = 'val_loss', patience = 10, restore_best_weights = True\n)\n\n# Saving checkpoints of the model after each epoch during training can \n# also be helpful (e.g. if training is interrupted)\nmodel_checkpoint = ModelCheckpoint(\n    'Digit_CNN_best.hdf5', monitor = 'val_loss', save_best_only=True\n)","cd2c64ff":"#%% Fit the model\n\nhist = model.fit(datagen.flow(X_train, y_train, batch_size = 32),\n                                     epochs = 100, \n                                     validation_data = (X_val, y_val),\n                 callbacks = [early_stopping, model_checkpoint])\n\n#best_model = ks.models.load_model('Digit_CNN_best.hdf5') # re-load the best model from disk if desired\n","eea3ce27":"# Model diagnostics\nplt.figure()\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.legend(['Val', 'Train'])","517d81a2":"preds = model.predict(test)\n\n# Convert from one-hot encoding back to a single variable\npreds_transform = preds.argmax(axis=1)\n\n# Create a dataframe in the format requried by kaggle, and export to a csv\nindexes = np.arange(1,len(preds_transform)+1)\nresults = pd.DataFrame({\"ImageId\": indexes, \"Label\": preds_transform})\nresults.to_csv(\"CNN predictions.csv\", index = False)\n\n","708c6e0c":"## Generate predictions and export results\n","9b3d475a":"## Preprocess data\nNormalize values so that they range between 0-1, which can help the model fit more quickly, and possibly achieve a better fit.\n\nData also need to be reshaped: In the provided dataset, each image is represented as a single row from a matrix, but Conv2D expects images to be presented with a 3-D input shape","89ec136d":"\n## Possible ways to try and improve the model further.\n* Try different architectures (number of layers, number of filters per layer)\n* Try using batch normalization \n* Try different optimisers, and tuning optimizer parameters (e.g. learning rate)","d37998e1":"Check how many training examples are available for each digit. If any digit has too few training examples, then it may need to be addressed. Here, a large number of training examples were available for all digits, so there is no issue.","2a8525c0":"#### Check that reshaping worked\nAfter reshaping, plot some random images from the dataset to check that it worked as expected, and to get a feel for what the images look like. We will also see the one-hot encoded labels. The cell below can be re-run to get different examples","38d60f61":"## Fit the model\nI'll use an unreasonably high number of epochs, given that I have an early stopping rule in place. My best model, according to validation loss, was found after ~30 epochs.\n","0c121388":"## Summarise data\n\nCheck for null values in the dataset (corrupted images): none were found\n\n","a9381768":"To get an example of an image with random distortions, run the below block of code","36ff72ad":"## Model diagnotics\nWe will plot the change in training loss and the validation loss during training, which can help detect overfitting.","621af95f":"## Specify the structure of the CNN\nWe will build the neural network using keras's high-level API. \nWe will use 4 pairs of Conv2D and pooling layers. \nWe'll also randomly drop 25-50% of weights in each layer to reduce overfitting.\nWe flatten the results and pass through a final Dense layer before the output layer. The output layer should be specified as 'softmax', which means that output node values can be interpreted as probabilities, and will sum to 1 across all classes.\n","953a6ca0":"## Data Augmentation\nWe will use data augmentation to add distortions to the original training images in order to increase the effective sample size. We can do with with keras's ImageDataGenerator. It takes out original images and adds random distortions according to the parameters that we specify. A different distortion is applied to each image in the training set after each epoch.\n\nWhen we fit the model, instead of providing our raw dataset, we provide the generated images.\n\nWe will add rotations, position shifts, zoom, and shear.\n","5298377f":"### Split into training and validation sets\nWe will not create our own test set, because we can evaluate our final \nmodel on Kaggle's test set when we submit results\n","766d415f":"## My first CNN: Digit recognition with Keras \n\nI build a model to classify digits 0 through 9, using convolutional neural networks in python with keras.\n\nThe model achieved 99.36% accuracy, and trains in ~30 minutes on my CPU","25402f19":"## Load packages and data","01845e77":"## Specify the optimizer & early stopping rule\nI'll use the adam optimizer, which is meant to work well for many applications. categorical_crossentropy is the loss function required for multi-class classification.\n\nWe will set up an early stopping instance which will be used by the model during training. If there are signs of overfitting, it will terminate training and revert to the model with the lowest validation loss. If processing power is limited, patience could be reduced (e.g. to ~2-5) to terminate training earlier.\n\n\n\n\n"}}