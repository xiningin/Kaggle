{"cell_type":{"5faed235":"code","d329b12c":"code","107406a7":"code","769368ba":"code","8881d6fe":"code","54051c85":"code","26959cb8":"code","4fc8ae1f":"code","72c33ba2":"code","c4055b1f":"code","b5fdc7f7":"code","085d012b":"code","63eba5b1":"code","933bde0e":"code","e846a7e7":"code","a9a81278":"code","ebbebf98":"code","0c52f681":"code","3731ef72":"code","8eaa74c3":"code","993fe5c7":"code","06cee829":"code","b4220259":"code","77c8ba7f":"code","50c278f1":"code","35795778":"code","af2bbcb2":"code","576417d0":"code","dee8cbb0":"code","11d256db":"code","ed90f2c0":"code","64c1a8bf":"code","be118e0f":"code","535a46ee":"code","1fd73576":"code","9e9938b7":"code","96e03cd8":"code","063b47e1":"code","30847ad4":"code","7714a15e":"code","19eee1a8":"code","37407d59":"code","bf4e18c8":"code","e1a3826f":"code","37643364":"code","c3512552":"code","4aa4d644":"code","d01d6b2f":"code","06ed5b48":"markdown","9e420e04":"markdown","7fc89129":"markdown","3639f3c7":"markdown","d1f06649":"markdown","c98bd862":"markdown","f0aa7032":"markdown","a781b815":"markdown","9235a961":"markdown","ec8eae82":"markdown","6f02a3b4":"markdown","55aa9177":"markdown","a99372d7":"markdown","fcd73fb8":"markdown","4dc478ea":"markdown","5add6e68":"markdown","5f27f03d":"markdown","b001810d":"markdown","7c8615e7":"markdown","c821318e":"markdown","ca207add":"markdown","16e9245c":"markdown","facb1a86":"markdown","f6c3a7a7":"markdown","98de5dd6":"markdown","caaada63":"markdown","64a46965":"markdown","1c1473e2":"markdown","f95d353d":"markdown","59cd6554":"markdown","9752f250":"markdown"},"source":{"5faed235":"#begin by importing programs \nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image \nimport glob\nfrom pathlib import Path\nimport seaborn as sns\nimport tensorflow as tf\n\ntf.random.set_seed(16)\nnp.random.seed(11)","d329b12c":"print(os.listdir(\"..\/input\"))","107406a7":"#explore main directory\nmainDIR = os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray')\nprint(mainDIR)","769368ba":"#create paths to each individual folder \ntrain_folder = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\nval_folder = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')\ntest_folder = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')","8881d6fe":"#train data pathways\nnormal_cases_dir = train_folder \/ 'NORMAL'\npneu_cases_dir = train_folder \/ 'PNEUMONIA'\n\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneu_cases_dir.glob('*.jpeg')\n\ntrain_data = []\n\n#append data to list\nfor img in normal_cases:\n    train_data.append((img,0))\n    \nfor img in pneumonia_cases:\n    train_data.append((img, 1))\n\n#convert to pandas dataframe\ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n\n#shuffle\ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)","54051c85":"\nprint(train_data.shape)\ntrain_data.head()","26959cb8":"#validation data pathways\nnormal_cases_dir = val_folder \/ 'NORMAL'\npneu_cases_dir = val_folder \/ 'PNEUMONIA'\n\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneu_cases_dir.glob('*.jpeg')\n\nval_data = []\n\n#append data to list\nfor img in normal_cases:\n    val_data.append((img,0))\n    \nfor img in pneumonia_cases:\n    val_data.append((img, 1))\n\n#convert to pandas dataframe\nval_data = pd.DataFrame(val_data, columns=['image', 'label'], index=None)\n\n#shuffle\nval_data = val_data.sample(frac=1.).reset_index(drop=True)","4fc8ae1f":"print(val_data.shape)\nval_data.head()","72c33ba2":"#test data pathways\nnormal_cases_tdir = test_folder \/ 'NORMAL'\npneu_cases_tdir = test_folder \/ 'PNEUMONIA'\n\nnormal_tcases = normal_cases_tdir.glob('*.jpeg')\npneumonia_tcases = pneu_cases_tdir.glob('*.jpeg')\n\ntest_data = []\n\n#append data to list\nfor img in normal_tcases:\n    test_data.append((img,0))\n    \nfor img in pneumonia_tcases:\n    test_data.append((img, 1))\n\n#convert to pandas dataframe\ntest_data = pd.DataFrame(test_data, columns=['image', 'label'], index=None)\n\n#shuffle\ntest_data = test_data.sample(frac=1.).reset_index(drop=True)","c4055b1f":"print(test_data.shape)\ntest_data.head()","b5fdc7f7":"#how many cases each? \n\nf = plt.figure(figsize=(10,6))\n\na1 = f.add_subplot(1,2,1)\nsns.countplot(train_data.label, ax = a1)\na1.set_title('Train Data')\na1.set_xticklabels(['Normal', 'Pneumonia'])\n\na2 = f.add_subplot(1,2,2)\nsns.countplot(test_data.label, ax=a2)\na2.set_title('Test Data')\na2.set_xticklabels(['Normal', 'Pneumonia'])","085d012b":"f = plt.figure(figsize=(12,8))\n\na1 = f.add_subplot(1,2,1)\nimg_plot = plt.imshow(Image.open(train_data.image[0]))\na1.set_title('Pneumonia')\n\na2 = f.add_subplot(1,2,2)\nimg_plot = plt.imshow(Image.open(train_data.image[2]))\na2.set_title('Normal')","63eba5b1":"#make a list with each image size \nshapes = []\n\nfor x in range(0,5215):\n    shapes.append(plt.imread(train_data.image[x]).shape)","933bde0e":"#find the smallest one\nmin(shapes)","e846a7e7":"#importing necessary programs \nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom PIL import Image \nfrom scipy import ndimage ","a9a81278":"#scale images\ntrain_dir = ImageDataGenerator(rescale=1.\/255)\nval_dir = ImageDataGenerator(rescale=1.\/255)\ntest_dir = ImageDataGenerator(rescale=1.\/255)","ebbebf98":"#Make Directories \ntrain_gen = train_dir.flow_from_directory(train_folder, target_size=(127,384), batch_size = 20, class_mode='binary')\nval_gen = val_dir.flow_from_directory(val_folder, target_size=(127,384), batch_size=10, class_mode='binary')\ntest_gen = test_dir.flow_from_directory(test_folder, target_size=(127,384), batch_size=20, class_mode='binary')","0c52f681":"from keras import layers \nfrom keras import models \nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom keras.models import Sequential \n\n# CNN model \n\nmodel_1 = Sequential()\n\n#Convolution\nmodel_1.add(Conv2D(32, (3,3), activation ='relu', input_shape=(127, 384, 3)))\n\n#Pooling\nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\n#Convolution 2 \nmodel_1.add(Conv2D(64, (3,3), activation='relu'))\n\n#Pooling Layer 2 \nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\n#Convolution 3\nmodel_1.add(Conv2D(128, (3,3), activation='relu'))\n\n#Pooling again\nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\n#Convolution 4\nmodel_1.add(Conv2D(128, (3,3), activation='relu'))\n\n#Flattening\nmodel_1.add(Flatten())\n\n#Add Dense Layers \nmodel_1.add(Dense(512, activation='relu'))\nmodel_1.add(Dense(1, activation='sigmoid'))","3731ef72":"#Compile\n\nfrom keras import optimizers \n\nmodel_1.compile(loss='binary_crossentropy',\n           optimizer=optimizers.RMSprop(lr=1e-4),\n           metrics=['acc'])","8eaa74c3":"history = model_1.fit_generator(train_gen,\n                           steps_per_epoch=100,\n                           epochs=20,\n                           validation_data=val_gen,\n                           validation_steps=50)","993fe5c7":"test_1_acc = model_1.evaluate_generator(test_gen, steps=50)\nprint('The accuracy of this test is:', test_1_acc[1]*100,'%')","06cee829":"from keras.layers import Dropout\n\nmodel_2 = Sequential()\n\n#Convolution\nmodel_2.add(Conv2D(32, (3,3), activation ='relu', input_shape=(127, 384, 3)))\n\n#Pooling\nmodel_2.add(MaxPooling2D(pool_size=(2,2)))\n\n#Convolution 2 \nmodel_2.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n\n#Dropout 1\nmodel_2.add(Dropout(0.35))\n\n#Pooling Layer 2 \nmodel_2.add(MaxPooling2D(pool_size=(2,2)))\n\n#Convolution 3\nmodel_2.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n\n#Dropout 2\nmodel_2.add(Dropout(0.35))\n\n#Pooling again\nmodel_2.add(MaxPooling2D(pool_size=(2,2)))\n\n#Convolution 4\nmodel_2.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n\n#Dropout 3\nmodel_2.add(Dropout(0.35))\n\n#Flattening\nmodel_2.add(Flatten())\n\n#Add Dense Layers \nmodel_2.add(Dense(512, activation='relu'))\nmodel_2.add(Dense(128, activation='relu'))\nmodel_2.add(Dense(1, activation='sigmoid'))","b4220259":"model_2.compile(loss='binary_crossentropy',\n           optimizer=optimizers.RMSprop(lr=1e-4),\n           metrics=['acc'])","77c8ba7f":"history_2 = model_2.fit_generator(train_gen,\n                           steps_per_epoch=100,\n                           epochs=30,\n                           validation_data=val_gen,\n                           validation_steps=50)","50c278f1":"test_4_acc = model_2.evaluate_generator(test_gen, steps=50)\nprint('The accuracy of this test is:', test_4_acc[1]*100,'%')","35795778":"train_data.label.value_counts()","af2bbcb2":"pneu_count = train_data.label.value_counts(1)[1]\nnorm_count = train_data.label.value_counts(1)[0]\nweight_for_0 = (1\/norm_count)\nweight_for_1 = (1\/pneu_count)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}","576417d0":"history = model_2.fit_generator(train_gen,\n                                steps_per_epoch=100,\n                                epochs=30,\n                                validation_data=val_gen,\n                                validation_steps=50,\n                               class_weight = class_weight)","dee8cbb0":"test_4_acc = model_2.evaluate_generator(test_gen, steps=50)\nprint('The accuracy of this test is:', test_4_acc[1]*100,'%')","11d256db":"#import network and create CNN base\nfrom keras.applications import VGG19\ncnn_base = VGG19(weights='imagenet',\n                include_top = False,\n                input_shape=(127,384,3))","ed90f2c0":"#build the dense layer of the model w\/ cnn_base as convolutional model \nmodel_pt = models.Sequential()\nmodel_pt.add(cnn_base)\nmodel_pt.add(layers.Flatten())\nmodel_pt.add(layers.Dense(132, activation='relu'))\nmodel_pt.add(layers.Dense(1, activation='sigmoid'))","64c1a8bf":"#checking trainable layers and trainable weights \nfor layer in model_pt.layers:\n    print(layer.name, layer.trainable)\n    \nprint(len(model_pt.trainable_weights))","be118e0f":"#we will now \"freeze\" the layer by setting the trainable attribute to false\n\ncnn_base.trainable = False ","535a46ee":"#repeat this for a sanity check \nfor layer in model_pt.layers:\n    print(layer.name, layer.trainable)\n    \nprint(len(model_pt.trainable_weights))","1fd73576":"#compile model \nMETRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\nmodel_pt.compile(loss='binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=2e-5),\n             metrics= METRICS)","9e9938b7":"#fit\n\nhistory = model_pt.fit_generator(train_gen,\n                               steps_per_epoch=27,\n                               epochs=7,\n                               validation_data=val_gen,\n                               validation_steps=10,\n                             class_weight=class_weight)","96e03cd8":"#visualizing training accruacy and loss \nfig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","063b47e1":"loss, acc, prec, rec =model_pt.evaluate(test_gen)","30847ad4":"#first, unfreeze the base.\n\ncnn_base.trainable = True","7714a15e":"#iterate thru the layers \nset_trainable = False\nfor layer in cnn_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False ","19eee1a8":"#remodel \nmodel_ft = models.Sequential()\nmodel_ft.add(cnn_base)\nmodel_ft.add(layers.Flatten())\nmodel_ft.add(layers.Dense(132, activation='relu'))\nmodel_ft.add(layers.Dense(1, activation='sigmoid'))","37407d59":"model_ft.compile(loss='binary_crossentropy',\n             optimizer = optimizers.RMSprop(lr=1e-4),\n             metrics=METRICS)","bf4e18c8":"batch_size = 50\n\nhistory = model_ft.fit_generator(train_gen,\n                               steps_per_epoch=27,\n                               epochs=7,\n                               validation_data=val_gen,\n                               validation_steps=10,\n                             class_weight=class_weight)","e1a3826f":"loss, acc, prec, rec =model_ft.evaluate(test_gen)","37643364":"#visualizing training accruacy and loss \nfig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","c3512552":"from sklearn.metrics import accuracy_score, confusion_matrix\nloss, acc, prec, rec =model_ft.evaluate(test_gen)","4aa4d644":"import sklearn.metrics as metrics\n\ntest_gen_final = test_dir.flow_from_directory(test_folder, target_size=(127,384),batch_size=624, class_mode='binary')\ntest_data, test_labels = next(test_gen_final)\npreds = model_ft.predict(test_data)\n\nfpr, tpr, threshold = metrics.roc_curve(test_labels, np.round(preds))\nroc_auc = metrics.auc(fpr, tpr)\n\nimport matplotlib.pyplot as plt\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","d01d6b2f":"acc = accuracy_score(test_labels, np.round(preds))*100\ncm = confusion_matrix(test_labels, np.round(preds))\ntn, fp, fn, tp = cm.ravel()\n\n#confusion matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nfig, ax = plot_confusion_matrix(conf_mat=cm ,  figsize=(5, 5))\nplt.show()\n\nprint('\\nTEST METRICS ----------------------')\nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\nsensitivity = recall\nspecificity = tn\/(tn+fp)*100\nprint('Accuracy: {}%'.format(acc))\nprint('Precision: {}%'.format(precision))\nprint('Recall: {}%'.format(recall))\nprint('F1-score: {}'.format(2*precision*recall\/(precision+recall)))\nprint('Specificity: {}%'.format(specificity))\nprint('Sensitivity: {}%'.format(recall))","06ed5b48":"## Further Recommendations\n\n1. Train a similar model on adult images \n\n2. Continue to search for diagnosis processes worthy of streamlining through machine learning to improve efficiency and accuracy in healthcare.","9e420e04":"## Pathway Manipulation and Data Organization\n\n\nFirst up, make the data reachable. ","7fc89129":"### Confusion Matrix","3639f3c7":"The intention of this project is to create an algorith which will accurately identify a pneumonia diagnosis from a chest x-ray. Never more than now have medical practitioners been bogged down by a never ending list of tasks which keep them from doing the important work of interacting with patients and thinking critically about intervetions. Any measure which would decrease time spent waiting around for results prior to intervetion is precious time for the patient, and an accurate measure has the potential to mitigate false diagnosis. \n\nAdditionally, one study found that patients were a false negative rate (patient's whose pneumonia diagnosis is missed) at 11.4%, this is an alarming statistic especially in the times of COVID-19. Pneumonia is one of the most serious side effects of COVID-19 and if missed, could lead to poor outcomes in patients. \n\nThis project seeks to improve efficiency and accuracy of diagnosis of pneumonia.","d1f06649":"As we can observe above the information is quite unbalanced (other than the valdiation data, which is a small sample). This is not uncommon in medical data and we can adjust this later depending on how our model plays out. ","c98bd862":"## Performance Breakdown","f0aa7032":"### Accuracy, precision & recall","a781b815":"The next step is normalizing the data and making the images smaller to perform the neural network analysis. In order to decide what size our images should be, I'll find the smallest image in the dataset and change the sizes all to that size. ","9235a961":"## Normalization and Image Processing","ec8eae82":"91 % !!!!!!!!! \n\n<img src=\"https:\/\/media.giphy.com\/media\/TlK63Eu7Dwok2j8TgfS\/giphy.gif\">\n\nI'll keep this as the final model. ","6f02a3b4":"# Pulmonary Predictions with CNN","55aa9177":"## Modeling","a99372d7":"## Fine Tuning","fcd73fb8":"The smallest image in the training data is 127x384, so we'll use that size for the rest of the images. ","4dc478ea":"Hmm, it doesn't seem like balancing the classes made much of a difference either. \n\nNext, let's try using a well known, pre-trained convulusion in our neural network.","5add6e68":"## Visualization & Class Balance\n\nI'd like to explore a little more about the data now and make sure our images are processed appropriately (size and colorscale). ","5f27f03d":"83%! This is much more in the range I'm looking for. Next, I'll do a little fine tuning of the model to try and increase the accuracy even further. ","b001810d":"Overall, this model gives us safe, reliable readings of patient chest xray screens. This leaves the practitioners with quicker results for quicker action as well as more time to spend with their patients.","7c8615e7":"Let's visualize some images!","c821318e":"Ok, 77% isn't too bad. However if we examine the training data we were getting 98% accuracy in some cases so it seems we've got some overtraining going on. Let's add a few dropout layers and see how it looks. ","ca207add":"### ROC curve & AUC","16e9245c":"#### **1. Accuracy (91%)**\nThis is the one most people are intuitively familiar with. Accuracy represents the ratio of correctly predicted obersations to the total observations. This is the same measure all our test were graded on in school, etc. \n\n\n#### **2. Precision or Positive Predictive Value (90%):** \nPrecision is the ratio of correctly predicted positive observations to all observations to total predicted positive observations (re: true positives \/ true positives + false positives ). It answers the question \"Of all the positive identifications, what proportion were actuall correct?\". In our case, 90% of the time we told someone they had pneumonia, they actually did. \n\n\n#### **3. Recall or Sensitivity (96%):** \nRecall is the ratio of correct predictions and the total number of correct items in the set (re: true positives\/ true positives + false negatives). Sensitivity is a good measure of how many false negatives you had, or in our case, a measure of how many people will be told they don't have pneumonia when they actually do. For us, we will detect 96% of pneumonia cases.\n\n\n#### **4. F1 Score (93):** \nThe F1 score is a combination of the precision and recall scores as follows: 2 * (precision * recall)\/(precision + recall). It gives equal wait to both measures. This model's F1 score is 93 which is excellent. It demonstrates good and balanced precision and recall.\n\n#### **5. ROC curves and AUC score (.90):**\nA Reciever Operator Characterstic (ROC) curve illustrates the true positive rate against the false positive rate. This graph gives us a tradeoff between these two and the Area Under the Curve (AUC) gives us a single metric to evaluate this. An AUC of 1 is a perfect classifier and an AUC of 0.5 is considered \"Worthless\" because there is a 50\/50 chance of getting a true\/flase positive. This model scored an .87, which is considered quite good. \n\n#### 6. Specificity (83%):\n\nSpecificity refers the proportion of negatives which are truly negative (re: the number of patients without the diagnosis who test negative). It's a good measure of false positives and is calculated as follows: True Negatives \/ True Negatives + False Positives. This model's specificity is 83% which is considered excellent. With this specific model I wuld prefer to have a higher sensitivity and am not as worried about specificity, which I will explain below. \n\n#### 7. Confusion Matrix:\n\nThis confusion matrix is especially important for our data. In the top left and bottom right corners you'll see the true negative and true positive representation (respectively). The other two corners represent the false positive (top right) and false negative (bottom left). Depending on the situation you may prefer for your model to lean towards one of these categories. In most medical testing you would prefer that your incorrectly identified labels to have more false positives than false negatives as the implications of an incorrect prelimary diagnosis are much less malignant than a missed diagnosis. \n\nOur model produced 54 incorrect predictions, only 15 (27% of the incorrect predictions and 2.4% of whole) of which were false negatives. This means that our model arguably gives us a favorable outcome 97.6% of the time. ","facb1a86":"### Introduction","f6c3a7a7":"As seen above these images are not easily distinguishable with the naked eye - that's what we're trying to create the algorithm for!","98de5dd6":"Somehow adding the dropout layers made out accuracy go down. \n\n<img src=\"https:\/\/media.giphy.com\/media\/y1YqNut2cuOGY\/giphy.gif\">\n\nI'll try balancing the data now.","caaada63":"After doing this it looks like we have the following:\n\n* 5,216 training datapoints\n* 16 validation datapoints\n* 624 test datapoints \n\nWhich is:\n\n*  89% Train\n*  .2% Validation\n*  10% Test ","64a46965":"## Conclusion","1c1473e2":"## Pretrained CNN Base","f95d353d":"## Performance Measures Explanation","59cd6554":"The following is called the VGG-19 network, which was trained on 1.2 million images. ","9752f250":"## Balancing the training data"}}