{"cell_type":{"2b692abf":"code","48f3be05":"code","e235942a":"code","be2cc9ea":"code","7bf321c4":"code","80746ba7":"code","c4319ec2":"code","dadfa103":"code","1c65c85b":"code","6accfd81":"code","a47bbc89":"code","027c4e77":"code","af16f0a7":"code","4f8d5197":"code","ab7687a7":"code","555c2aad":"markdown","13b3cdab":"markdown","4374bc4a":"markdown","65459012":"markdown","35b1f366":"markdown","20b14b5b":"markdown","3a34766b":"markdown","4e78dfb2":"markdown","aa504212":"markdown","a8c3be44":"markdown","589ba1d3":"markdown","530afc31":"markdown","7961a406":"markdown","4bc7b156":"markdown","4f293d49":"markdown","783d84b3":"markdown","6714b0db":"markdown","1d931730":"markdown"},"source":{"2b692abf":"import numpy as np\nnp.random.seed(1000)\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split","48f3be05":"import keras\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\nfrom keras.models import Sequential","e235942a":"import os\nimport cv2\nfrom PIL import Image","be2cc9ea":"DATA_DIR = '..\/input\/cell_images\/cell_images\/'\nSIZE = 64\ndataset = []\nlabel = []","7bf321c4":"parasitized_images = os.listdir(DATA_DIR + 'Parasitized\/')\nfor i, image_name in enumerate(parasitized_images):\n    try:\n        if (image_name.split('.')[1] == 'png'):\n            image = cv2.imread(DATA_DIR + 'Parasitized\/' + image_name)\n            image = Image.fromarray(image, 'RGB')\n            image = image.resize((SIZE, SIZE))\n            dataset.append(np.array(image))\n            label.append(0)\n    except Exception:\n        print(\"Could not read image {} with name {}\".format(i, image_name))","80746ba7":"uninfected_images = os.listdir(DATA_DIR + 'Uninfected\/')\nfor i, image_name in enumerate(uninfected_images):\n    try:\n        if (image_name.split('.')[1] == 'png'):\n            image = cv2.imread(DATA_DIR + 'Uninfected\/' + image_name)\n            image = Image.fromarray(image, 'RGB')\n            image = image.resize((SIZE, SIZE))\n            dataset.append(np.array(image))\n            label.append(1)\n    except Exception:\n        print(\"Could not read image {} with name {}\".format(i, image_name))","c4319ec2":"plt.figure(figsize = (20, 12))\nfor index, image_index in enumerate(np.random.randint(len(parasitized_images), size = 5)):\n    plt.subplot(1, 5, index+1)\n    \n    plt.imshow(dataset[image_index])","dadfa103":"plt.figure(figsize = (20, 12))\nfor index, image_index in enumerate(np.random.randint(len(uninfected_images), size = 5)):\n    plt.subplot(1, 5, index+1)\n    plt.imshow(datasetlen(parasitized_images))","1c65c85b":"classifier = None\nclassifier = Sequential()\nclassifier.add(Convolution2D(32, (3, 3), input_shape = (SIZE, SIZE, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Flatten())\nclassifier.add(Dense(activation = 'relu', units=512))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Dense(activation = 'relu', units=256))\nclassifier.add(BatchNormalization(axis = -1))\nclassifier.add(Dropout(0.2))\nclassifier.add(Dense(activation = 'sigmoid', units=2))\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nprint(classifier.summary())","6accfd81":"from keras.utils import to_categorical\n\nX_train, X_test, y_train, y_test = train_test_split(dataset, to_categorical(np.array(label)), test_size = 0.20, random_state = 0)","a47bbc89":"history = classifier.fit(np.array(X_train), \n                         y_train, \n                         batch_size = 64, \n                         verbose = 2, \n                         epochs = 50, \n                         validation_split = 0.1,\n                         shuffle = False)","027c4e77":"print(\"Test_Accuracy: {:.2f}%\".format(classifier.evaluate(np.array(X_test), np.array(y_test))[1]*100))","af16f0a7":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_generator = ImageDataGenerator(rescale = 1\/255,\n                                     zoom_range = 0.3,\n                                     horizontal_flip = True,\n                                     rotation_range = 30)\n\ntest_generator = ImageDataGenerator(rescale = 1\/255)\n\ntrain_generator = train_generator.flow(np.array(X_train),\n                                       y_train,\n                                       batch_size = 64,\n                                       shuffle = False)\n\ntest_generator = test_generator.flow(np.array(X_test),\n                                     y_test,\n                                     batch_size = 64,\n                                     shuffle = False)","4f8d5197":"history = classifier.fit_generator(train_generator,\n                                   steps_per_epoch = len(X_train)\/64,\n                                   epochs = 50,\n                                   shuffle = False)","ab7687a7":"print(\"Test_Accuracy(after augmentation): {:.2f}%\".format(classifier.evaluate_generator(test_generator, steps = len(X_test), verbose = 1)[1]*100))","555c2aad":"## Import libraries\n\nThe first step is to import all the necessary packages including `sklearn`, `pandas`, `numpy`, `matplotlib` and `keras`. I'll work with **Tensorflow** as the backend. I'll also import `Image`, `cv2` and `os` to work with images.","13b3cdab":"### Exploring new accuracy\n\nFinally, after training on augmented data, I'll check the accuracy on the testing data.","4374bc4a":"### Parasitized cell images\n\nI iterate through all images in the **Parasitized** folder. I check if the file extension of the file being read is *png*.\nI then resize the image to 64x64 and then save it to the `dataset` variable as numpy array. The label for this is set as `0`.","65459012":"### Uninfected images\n\nI randomly select 5 values from the number of uninfected images and then display them in a row. I add the count of images of parasitized images to these index such that I am now showing images with label 1.","35b1f366":"## Conclusion\n\nIn this notebook, I worked with the Malaria Cell Images dataset and applied **Convolutional Neural Networks** using Keras.\nI observed high accuracy which further increased with data augmentation.","20b14b5b":"# Classification using Keras\n\nIn this notebook, I'll work with the Malaria Cell Images dataset to classify cells as either **Parasitized** or **Uninfected**. I'll use **Convolutional Neural Networks** to make the classification.","3a34766b":"## Accuracy calculation\n\nI'll now calculate the accuracy on the test data.","4e78dfb2":"### Parasitized images\n\nI randomly select 5 values from the number of parasitized images and then display them in a row.","aa504212":"### Training the model\n\nAs the training data is now ready, I will use it to train the classifier.","a8c3be44":"As we can see, with **Data Augmentation** I was able to improve the accuracy further. Such a technique can be highly useful whenever we have limited dataset. This can ensure proper training of the model.","589ba1d3":"## Applying CNN\n\nI'll apply Convolutional Neural Networks with 2 Convolutional Layers followed by 2 Dense layers.","530afc31":"## Visualize data\n\nNow, I'll take a look at 5 random images from both **Parasitized** and **Uninfected** pools.","7961a406":"### Uninfected cell images\n\nI iterate through all images in the **Uninfected** folder. I check if the file extension of the file being read is *png*.\nI then resize the image to 64x64 and then save it to the `dataset` variable as numpy array. The label for this is set as `0`.","4bc7b156":"## Import dataset\n\nI'll now import the dataset and take a look at the two types of image data available. I'll use the image size to be 64x64.","4f293d49":"### Split the dataset\n\nI split the dataset into training and testing dataset.\n1. Training data: 80%\n2. Testing data: 20%","783d84b3":"### Build the classifier\n\nI create a Sequential model with all the layers. I used the metric as `accuracy`.","6714b0db":"Now I will use `fit_generator` methods to train the model and test on the validation data.","1d931730":"## Improving the accuracy with Augmentation\n\nI will use **ImageDataGenerator** to generate more image data and then train the model on the same."}}