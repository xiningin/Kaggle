{"cell_type":{"f1a6def4":"code","44b11485":"code","8a9c5b0d":"code","81f093ec":"code","a7a7799d":"code","a0c8e193":"code","f8129310":"code","98d3f436":"code","0fbe34b7":"code","1ed61421":"code","cc9c9cf6":"code","7674a234":"markdown","bb62ac12":"markdown","694d8852":"markdown"},"source":{"f1a6def4":"import numpy as np\nimport pandas as pd\nimport optuna\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","44b11485":"train_set = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntest_set = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\n\ntrain = train_set.copy()\ntest = test_set.copy()\n\ntrain.drop(\"id\",axis=1,inplace=True)\ntest.drop(\"id\",axis=1,inplace=True)\n\ntrain[\"sum\"] = train.sum(axis=1)\ntest[\"sum\"] = test.sum(axis=1)\n\nX = np.array(train.drop(\"target\",axis=1))\ny = np.array(train[\"target\"])\nle = LabelEncoder()\ny = le.fit_transform(np.ravel(y))","8a9c5b0d":"def objective(trial,X,y):\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,random_state=17)\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1 , 100),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 500 , 1000),\n        'num_leaves' : trial.suggest_int('num_leaves' , 90 , 150), \n        'learning_rate' : trial.suggest_float('learning_rate' , 0.01 , 0.5),\n        'max_depth' : trial.suggest_int('max_depth' , 2 , 5),               \n        'n_estimators' : trial.suggest_int('n_estimators' , 1 ,50000),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 10),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-3 , 2),\n        'subsample' : trial.suggest_float('subsample' , 0.008 , 1.0),\n        'colsample_bytree' : trial.suggest_float('colsample_bytree' , 0.01 , 0.3)\n    }\n    lgb = LGBMClassifier(**params)  \n    lgb.fit(X_train,y_train,eval_set=[(X_val,y_val)],eval_metric='multi_logloss',early_stopping_rounds=50, verbose=False)\n        \n    y_pred = lgb.predict_proba(X_val)\n \n    log_loss_ = log_loss(y_val, y_pred)\n    \n    return log_loss_","81f093ec":"study = optuna.create_study(direction='minimize')\nstudy.optimize(lambda trial: objective(trial,X,y), n_trials=30)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","a7a7799d":"best_params = study.best_trial.params\nbest_params","a0c8e193":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,random_state=17)","f8129310":"lgb = LGBMClassifier(**best_params)\nlgb.fit(X_train, y_train)","98d3f436":"y_pred = lgb.predict_proba(X_val)\nloss = log_loss(y_val, y_pred)\nloss","0fbe34b7":"y_test = lgb.predict_proba(test)\ny_test","1ed61421":"result = pd.DataFrame(index=test_set[\"id\"], data={\"Class_1\": y_test[:,0],\"Class_2\": y_test[:,1],\"Class_3\": y_test[:,2],\"Class_4\": y_test[:,3],\"Class_5\": y_test[:,4],\n                                                 \"Class_6\": y_test[:,5],\"Class_7\": y_test[:,6],\"Class_8\": y_test[:,7],\"Class_9\": y_test[:,8]})\nresult.head()","cc9c9cf6":"sub = result.to_csv(\"sub.csv\")","7674a234":"# Defining Model","bb62ac12":"# Optuna","694d8852":"# Libraries"}}