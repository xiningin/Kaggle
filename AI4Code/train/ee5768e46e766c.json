{"cell_type":{"071e4486":"code","6fc20410":"code","dd90c669":"code","c709d0f6":"code","d8ac50e3":"code","f49bd2dc":"code","aceb4c0d":"code","0e0457d8":"code","d6865107":"code","0e2b21bb":"code","9201674c":"code","1c18d45c":"code","487cae86":"code","91210a96":"code","716e554e":"code","d38f33fb":"code","64e6a02e":"code","1d05d8f6":"code","5b1307c3":"code","1c8743c0":"code","569832ad":"code","a494d451":"code","6bf58638":"code","612e5da1":"code","50a784c5":"markdown","4147677a":"markdown","5c3f3d82":"markdown","8ca78a67":"markdown","32bb58fb":"markdown","5191d103":"markdown","ff175247":"markdown","e682d3c8":"markdown","0e1f8354":"markdown","7eb43a23":"markdown","6b047559":"markdown","b1c67733":"markdown","8a78e52d":"markdown","14835b4a":"markdown","e53c09ed":"markdown","0e52cc67":"markdown"},"source":{"071e4486":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\nfrom gensim import corpora, models\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.naive_bayes import MultinomialNB\nimport spacy\nfrom spacy import displacy\nfrom spacy.matcher import Matcher\nfrom spacy.tokens import Span\nimport en_core_web_lg\nfrom wordcloud import WordCloud\n\n# Input data files are available in the \"..\/input\/\" directory.\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6fc20410":"data = pd.read_csv(\"..\/input\/train.csv\", usecols=[0,1,2])\ndata.sample(5)","dd90c669":"data.target.describe()","c709d0f6":"sns.distplot(data.target)","d8ac50e3":"data.loc[:,\"target_binary\"] = np.where(data.target < 0.5, 0, 1)","f49bd2dc":"data.target_binary.value_counts()","aceb4c0d":"# divide data into two dataframes: positive and negative\npositive = data[data.target_binary == 0]\npositive = positive.sample(100000)\n\nnegative = data[data.target_binary == 1]\nnegative = negative.sample(100000)","0e0457d8":"# convert content of positive comment_text column to one single string\npositive_string = \" \".join([word for word in positive.comment_text])\nprint(len(positive_string))\nprint(positive_string[:100])","d6865107":"wordcloud = WordCloud(max_font_size=50, background_color=\"white\").generate(positive_string)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","0e2b21bb":"# convert content of negative comment_text column to one single string\nnegative_string = \" \".join([word for word in negative.comment_text])\nprint(len(negative_string))\nprint(negative_string[:100])","9201674c":"wordcloud = WordCloud(max_font_size=50, background_color=\"white\").generate(negative_string)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","1c18d45c":"sample = data.sample(1000)","487cae86":"# load spaCy's english large language model\nnlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\"])","91210a96":"nlp.pipeline","716e554e":"# instantiate Matcher\nmatcher = Matcher(nlp.vocab)\n\n# define pattern\npattern = [{\"IS_ALPHA\": True,\n            \"IS_STOP\": False,\n            \"LENGTH\": {\">\": 1},\n            \"LENGTH\": {\"<=\": 20}\n           }]\n\n# add pattern to matcher\nmatcher.add(\"Cleaning\", None, pattern)","d38f33fb":"# initialize empty list for proccessed texts\ntexts = []\n\nfor idx, row in sample.iterrows():\n    # get nlp doc of comment text\n    doc = nlp(row.comment_text)\n    \n    # apply matcher on doc\n    matches = matcher(doc)\n    \n    # initialize empty list for matched tokens\n    token_matches = []\n    \n    for match_id, start, end in matches:\n        # add custom entitiy \"MATCH\" to doc.ents\n        doc.ents = list(doc.ents) + [Span(doc, start, end, label=\"MATCH\")]  \n    \n        # get lemma for matched tokens and write to data frame\n        token_matches.append(doc[start:end].lemma_.lower())\n        sample.loc[idx, \"comment_preprocessed\"] = \" \".join(token_matches)\n    \n    # append processed comment to list of texts\n    texts.append(token_matches)","64e6a02e":"displacy.render(doc, style=\"ent\", options={\"ents\": [\"MATCH\"]})","1d05d8f6":"sample[[\"comment_text\", \"comment_preprocessed\"]].sample(10)","5b1307c3":"dictionary = corpora.Dictionary(texts)","1c8743c0":"print(\"The dictionary consists of {} different tokens. In total, {} documents were processed.\".format(dictionary.num_pos, dictionary.num_docs))","569832ad":"# get bow representation for each text\ncorpus_bow = [dictionary.doc2bow(text) for text in texts]\n\n# serialize corpus\ncorpora.MmCorpus.serialize(\"corpus.mm\", corpus_bow)\n\n# get tfidf representation for each text\ncorpus_tfidf = models.TfidfModel(corpus_bow)","a494d451":"#for document in corpus_tfidf[corpus_bow]:\n#    for token in document:\n#        print(token)","6bf58638":"for token, id in dictionary.token2id.items():   \n    if id == 6007:\n        print(token)","612e5da1":"# instantiate NB model\nclf = MultinomialNB()\n\n# fit classifier on data\nclf.fit(corpus_tfidf[corpus_bow], list(sample.target_binary.values))","50a784c5":"## Target","4147677a":"Inspect resulting tfidf corpus: list of tuples constisting of token id and tfidf weight.","5c3f3d82":"## Features","8ca78a67":"Convert continuous target variable to binary variable","32bb58fb":"Convert dictionary to tfidf-weighted corpus and serialize corpus","5191d103":"### Use spaCy functionalities to preprocess the comments","ff175247":"Set up Matcher class","e682d3c8":"Use displaCy to inspect matched tokens","0e1f8354":"## Machine Learning\nUse simple NaivesBayes to challenge different preprocessing techniques.","7eb43a23":"Convert list of comments to gensim dictionary ","6b047559":"## Preprocessing","b1c67733":"Apply matcher on comments","8a78e52d":"I am disabling the pipeline step \"NER\" in order to be able to set my own NER tags later. These are remaining steps names and classes, which the en_core_web_lg pipeline executes after configuration:","14835b4a":"Inspect distribution of target variable","e53c09ed":"### Use gensim functionalities to vectorize the preprocessed comment text","0e52cc67":"spaCy's Matcher class offers the opportunity to search for words, defined by attributes and rules:\n* Official docs: https:\/\/spacy.io\/usage\/rule-based-matching#matcher\n* Rule Explorer: https:\/\/explosion.ai\/demos\/matcher"}}