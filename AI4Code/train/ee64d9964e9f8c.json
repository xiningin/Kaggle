{"cell_type":{"15f12725":"code","827b64cd":"code","4508bac0":"code","8862e7f7":"code","8cdef2eb":"code","f52e3a39":"code","ba7f3162":"code","e9dd2655":"code","0280b86d":"code","e4e38216":"code","88ed31c5":"code","7d1bc7c9":"code","2c7e14e8":"code","ffe3f8e3":"code","966a2eb5":"code","fd5742a7":"code","2fc292aa":"code","7c2d3dad":"code","392b8c66":"code","b2ee997d":"code","cc68ce25":"code","4d91f08d":"code","758f8d3e":"code","7155b3c2":"code","72c0c41a":"markdown","80953001":"markdown","ef2bf11d":"markdown","24104feb":"markdown","2e57b9f0":"markdown"},"source":{"15f12725":"import os\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom os import getcwd\nimport zipfile\nimport shutil\nimport numpy as np\nimport glob\nimport random\nimport pandas as pd\n\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split","827b64cd":"fire_dir = glob.glob('..\/input\/fire-dataset\/fire_dataset\/fire_images\/*.png')\nnon_fire_dir = glob.glob('..\/input\/fire-dataset\/fire_dataset\/non_fire_images\/*.png')","4508bac0":"fire_df = []\nnon_fire_df = []\nfor i in fire_dir:\n    fire_df.append([i,'fire'])\nfor j in non_fire_dir:\n    non_fire_df.append([j,'non-fire'])\ndf = fire_df + non_fire_df\nrandom.shuffle(df)","8862e7f7":"data_df = pd.DataFrame(df, columns = ['path','label'])","8cdef2eb":"datagen = ImageDataGenerator(rescale=1.\/255,\n                             height_shift_range=0.2,\n                             width_shift_range=0.2,\n                             horizontal_flip=True,\n                             validation_split=0.2)","f52e3a39":"train_generator = datagen.flow_from_dataframe(data_df,\n                                              x_col='path',\n                                              y_col='label',\n                                              images_size=(256,256),\n                                              class_mode='binary',\n                                              subset='training')\n\nvalidation_generator = datagen.flow_from_dataframe(data_df,\n                                                   x_col='path',\n                                                   y_col='label',\n                                                   images_size=(256,256),\n                                                   class_mode='binary',\n                                                   subset='validation')","ba7f3162":"inception_v3 = InceptionV3(input_shape=(256,256,3),\n                           weights='imagenet',\n                           include_top=False)\ninception_v3.trainable = False","e9dd2655":"x = layers.Flatten()(inception_v3.output)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(1024,activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(1,activation='sigmoid')(x)           \n\nmodel1 = Model(inception_v3.input, x) \n\nmodel1.compile(optimizer = Adam(lr=0.0001), \n               loss = 'binary_crossentropy', \n               metrics =['acc'])","0280b86d":"history = model1.fit_generator(train_generator,\n                               epochs=50,\n                               verbose=0,\n                               validation_data=validation_generator)","e4e38216":"%matplotlib inline\nimport matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","88ed31c5":"val_acc1 = model1.evaluate(validation_generator)[1]\nprint(\"validation_accuracy: \" + str(val_acc1))","7d1bc7c9":"from tensorflow.keras.applications import EfficientNetB0","2c7e14e8":"efficientnet_b0 = EfficientNetB0(include_top=False,\n                             weights=\"imagenet\",\n                             input_shape=(256,256,3))\nefficientnet_b0.trainable = False","ffe3f8e3":"x = layers.Flatten()(efficientnet_b0.output)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(1024,activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(1,activation='sigmoid')(x)           \n\nmodel2 = Model(efficientnet_b0.input, x) \n\nmodel2.compile(optimizer = Adam(lr=0.0001), \n               loss = 'binary_crossentropy', \n               metrics =['acc'])","966a2eb5":"history = model2.fit_generator(train_generator,\n                               epochs=50,\n                               verbose=0,\n                               validation_data=validation_generator)","fd5742a7":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","2fc292aa":"val_acc2 = model2.evaluate(validation_generator)[1]\nprint(\"validation_accuracy: \" + str(val_acc2))","7c2d3dad":"from tensorflow.keras.applications import EfficientNetB7","392b8c66":"efficientnet_b7 = EfficientNetB7(include_top=False,\n                                 weights=\"imagenet\",\n                                 input_shape=(256,256,3))\nefficientnet_b7.trainable = False","b2ee997d":"x = layers.Flatten()(efficientnet_b7.output)\nx = layers.BatchNormalization()(x)\nx = layers.Dense(1024,activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(1,activation='sigmoid')(x)           \n\nmodel3 = Model(efficientnet_b7.input, x) \n\nmodel3.compile(optimizer = Adam(lr=0.0001), \n               loss = 'binary_crossentropy', \n               metrics =['acc'])","cc68ce25":"history = model3.fit_generator(train_generator,epochs=50,\n                               verbose=0,\n                               validation_data=validation_generator)","4d91f08d":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","758f8d3e":"val_acc3 = model3.evaluate(validation_generator)[1]\nprint(\"validation_accuracy: \" + str(val_acc3))","7155b3c2":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nacc = [val_acc1,val_acc2,val_acc3]\nmodel = ['InceptionV3','EfficientNetB0','EfficientNetB7']\nax.bar(model,acc)\nplt.show()","72c0c41a":"### EfficientNet B0","80953001":"### InceptionV3","ef2bf11d":"### EfficientNet B7","24104feb":"### Data Preprocessing","2e57b9f0":"### Model Comparison"}}