{"cell_type":{"b151a0e2":"code","c5f18b4f":"code","b4760664":"code","ac204afa":"code","944b3d0b":"code","796118d7":"code","aefabc78":"code","3afdc3f1":"code","2663cbc0":"code","53a61d15":"code","c2403357":"code","50d6c2ee":"code","930ec9b2":"code","463825aa":"code","115c9b6f":"code","239f1872":"code","c5ceb806":"code","def93498":"code","cc7cd02a":"code","0280de7c":"code","e9b53f82":"code","0c3a7ee6":"code","38f0443d":"code","d3fcb8e9":"code","7f34a1cb":"code","27b4227c":"code","f7985f80":"code","ddba4e1f":"code","94bbe407":"code","5541e030":"code","376e8505":"code","41311003":"code","5dffdaf8":"code","b790c189":"code","60121cca":"code","8c87203a":"code","1c10c503":"code","adf8c361":"code","587cb526":"code","3858099b":"code","5e89f90f":"code","ea663e66":"code","8aa6db08":"code","0aab3c97":"markdown","a613de41":"markdown","fcf08a79":"markdown","22213811":"markdown","fb04ec73":"markdown","6dc036c4":"markdown","3e88c5e2":"markdown","b7a87ec5":"markdown","72874036":"markdown"},"source":{"b151a0e2":"# https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud","c5f18b4f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,precision_score, recall_score, f1_score, roc_auc_score, roc_curve\nimport warnings\nwarnings.filterwarnings(action='ignore')","b4760664":"def mysplit(df, test_size=0.3) :\n    df_X = df.iloc[:, :-1]\n    df_y = df.iloc[:, -1]\n    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=test_size, random_state=0, stratify=df_y)   #------Stratified \uae30\ubc18 \ubd84\ud560\n    return  X_train, X_test, y_train, y_test","ac204afa":"def myscore(y_test,pred,proba, pr_curve=0, auc_curve=0):\n    accuracy = accuracy_score(y_test,pred)\n    precision = precision_score(y_test,pred)\n    recall = recall_score(y_test,pred)\n    f1 = f1_score(y_test,pred)\n    auc = roc_auc_score(y_test, proba[:,-1])\n    print(\"Accuracy:{:.6f}  precision:{:.6f}, recall:{:.6f}, f1:{:.6f}, auc:{:.6f}\".format(accuracy, precision, recall, f1, auc))\n\n    mtx = confusion_matrix(y_test, pred)\n    print(mtx)\n    \n    if pr_curve==1:\n        mycurve(y_test, proba)\n    if auc_curve==1:\n        mycurve_auc(y_test, proba)\n        ","944b3d0b":"from sklearn.metrics import precision_recall_curve\ndef mycurve(y_test, proba):  \n    precision, recall, thresholds = precision_recall_curve(y_test, proba[ : , -1])\n    print(len(precision), len(recall), len(thresholds))  #66 66 65\n    plt.plot(thresholds, precision[:len(thresholds)], label=\"precision\")\n    plt.plot(thresholds, recall[:len(thresholds)], label=\"recall\")\n    plt.xlabel(\"thresholds\")\n    plt.ylabel(\"score\")\n    plt.grid()\n    plt.legend()\n    plt.show()\n    ","796118d7":"def mycurve_auc(y_test, proba):  \n    fpr, tpr, thresholds = roc_curve(y_test, proba[:,-1])\n    print(len(fpr), len(tpr), len(thresholds))  #66 66 65\n    plt.plot(fpr, tpr, label=\"roc\")\n    plt.plot([0,1], [0,1], label=\"th:0.5\")\n    plt.xlabel(\"FPR (1-TNR(specificity)\")      #FP\n    plt.ylabel(\"TPR (recall,sensitivity)\") #TP\n    plt.title(f\"auc : {roc_auc_score(y_test, proba[:,-1]):.4f}\")\n    plt.grid()\n    plt.legend()\n    plt.show()","aefabc78":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","3afdc3f1":"df.info()","2663cbc0":"df.head()","53a61d15":"df[\"Class\"].value_counts()","c2403357":"sacler_val = np.log1p(df[\"Amount\"])  #Amount\ndf.insert(0, 'T_Amount', sacler_val)\ndf[[\"Amount\", \"T_Amount\"]]","50d6c2ee":"# Time : \uc77c\ubc18\/\uc815\uc0c1 \uac70\ub798...\ndf.drop([\"Amount\"], inplace=True, axis=1)\ndf","930ec9b2":"# MinMax StandardScaler ---?","463825aa":"# Time : \uc77c\ubc18\/\uc815\uc0c1 \uac70\ub798...\ndf.drop([\"Time\"], inplace=True, axis=1)","115c9b6f":"nan_dict = {\"CNT\": df.isin([0]).sum(),\n           \"RATE\": df.isin([0]).sum()\/df.shape[0]*100}\nnan_df = pd.DataFrame(nan_dict)\nprint(nan_df[nan_df[\"RATE\"]>0].sort_values(\"CNT\", ascending=False))","239f1872":"df.corrwith(df[\"Class\"]).sort_values(ascending=False)","c5ceb806":"df_y = df.iloc[:, -1]  #df[\"traget\"]  \ndf_X = df.iloc[:, :-1]\nprint(len(df_y), df_X.shape)\nX_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=36,  shuffle=True)\nprint(X_train.shape, X_test.shape, len(y_train), len(y_test))","def93498":"dt = DecisionTreeClassifier(random_state=36)","cc7cd02a":"from sklearn.model_selection import GridSearchCV\n#cross_val_score +  param_grid(\ud29c\ub2dd) \/ refit=True(best\ubaa8\ub378\ubc18\uc601)\n# depth\uac00 \uae4a\uc5b4\uc9c8\uc218\ub85d \uacb0\uc815\ud2b8\ub9ac\ub294 \uacfc\uc801\ud569\ub418\uae30 \uc26c\uc6cc \uc608\uce21 \uc131\ub2a5\uc774 \uc800\ud558\ub420 \uc218 \uc788\ub2e4\n# min_samples_split \uc791\uac8c \uc124\uc815\ud560 \uc218\ub85d \ubd84\ud560 \ub178\ub4dc\uac00 \ub9ce\uc544\uc838 \uacfc\uc801\ud569 \uac00\ub2a5\uc131 \uc99d\uac00\nmyparam = {'max_depth':[1,3,5], 'min_samples_split':[1,2,3]}\nGCV_model = GridSearchCV(dt, param_grid=myparam, refit=True, cv=10, scoring='f1_macro',verbose=0)\nGCV_model.fit(X_train, y_train)\n\n#max_depth 4\ubc88 * min_samples_split 3\ubc88 * cv=10  = \ucd1d 120\ubc88 \ud559\uc2b5\nprint(GCV_model.best_score_)\nprint(GCV_model.best_estimator_)\nprint(GCV_model.best_params_)\n\npred = GCV_model.predict(X_test)  \ndf_score = f1_score(y_test, pred, average='macro')\nprint(\"F1 : {:.6f}\".format(df_score))\n\n\nproba = GCV_model.predict_proba(X_test)\nmyscore(y_test, pred, proba, pr_curve=1, auc_curve=1)\n\n# 0.9083462500525215, {'max_depth': 5, 'min_samples_split': 2}, F1 : 0.947778 executed in 2m 36s","0280de7c":"lr = LogisticRegression(random_state = 36)","e9b53f82":"from sklearn.model_selection import GridSearchCV\n#cross_val_score +  param_grid(\ud29c\ub2dd) \/ refit=True(best\ubaa8\ub378\ubc18\uc601)\n# depth\uac00 \uae4a\uc5b4\uc9c8\uc218\ub85d \uacb0\uc815\ud2b8\ub9ac\ub294 \uacfc\uc801\ud569\ub418\uae30 \uc26c\uc6cc \uc608\uce21 \uc131\ub2a5\uc774 \uc800\ud558\ub420 \uc218 \uc788\ub2e4\n# min_samples_split \uc791\uac8c \uc124\uc815\ud560 \uc218\ub85d \ubd84\ud560 \ub178\ub4dc\uac00 \ub9ce\uc544\uc838 \uacfc\uc801\ud569 \uac00\ub2a5\uc131 \uc99d\uac00\nmyparam = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n              'penalty': ['l1', 'l2']}\nGCV_model = GridSearchCV(lr, param_grid=myparam, refit=True, cv=10, scoring='f1_macro',verbose=0)\nGCV_model.fit(X_train, y_train)\n\nprint(GCV_model.best_score_)\nprint(GCV_model.best_estimator_)\nprint(GCV_model.best_params_)\n\npred = GCV_model.predict(X_test)  \ndf_score = f1_score(y_test, pred, average='macro') \nprint(\"F1 : {:.6f}\".format(df_score))\n\n\nproba = GCV_model.predict_proba(X_test)\nmyscore(y_test, pred, proba, pr_curve=1, auc_curve=1)\n# Accuracy:0.999298  precision:0.868852, recall:0.623529, f1:0.726027, auc:0.985200, executed in 1m 19.1s","0c3a7ee6":"lr = LogisticRegression(random_state = 36)\nlr.fit(X_train,y_train)\npred_lr = lr.predict(X_test)\nproba_lr = lr.predict_proba(X_test)\nmyscore(y_test, pred_lr, proba_lr, pr_curve=1, auc_curve=1)","38f0443d":"dt = DecisionTreeClassifier(random_state = 36)\ndt.fit(X_train, y_train)\npred_dt = dt.predict(X_test)\nproba_dt = dt.predict_proba(X_test)\nmyscore(y_test, pred_dt, proba_dt, pr_curve=1, auc_curve=1)","d3fcb8e9":"lgbm = LGBMClassifier(boost_from_average=False)\nlgbm.fit(X_train, y_train)\npred_dt = lgbm.predict(X_test)\nproba_dt = lgbm.predict_proba(X_test)\nmyscore(y_test, pred_dt, proba_dt, pr_curve=1, auc_curve=1)","7f34a1cb":"plt.figure(figsize=(9, 5))\nsns.heatmap(df.corr(), cmap='RdBu')  #under_df.corr()\n\ndf.corrwith(df[\"Class\"]).sort_values(ascending=False)","27b4227c":"from imblearn.over_sampling  import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics  import classification_report_imbalanced\nfrom sklearn.metrics   import classification_report\nfrom sklearn.pipeline  import make_pipeline\nfrom imblearn.pipeline import make_pipeline as make_pipeline_imb\nfrom sklearn.utils     import shuffle","f7985f80":"from collections import Counter","ddba4e1f":"print('Distribution of Target Variable in Original Data: {}\\n'.format(Counter(df_y)))\nprint('Distribution of Target Variable in Training Set of Original Data: {}\\n'.format(Counter(y_train)))\nprint('Distribution of Target Variable in Test Set of Original Data: {}\\n'.format(Counter(y_test)))","94bbe407":"X_train_NearMiss, y_train_NearMiss = NearMiss().fit_resample(X_train.values, y_train.values)\nX_test_NearMiss, y_test_NearMiss   = NearMiss().fit_resample(X_test.values, y_test.values)\nprint('after NearMiss(train): {}\\n'.format(Counter(y_train_NearMiss)))\nprint('after NearMiss(test): {}\\n'.format(Counter(y_test_NearMiss)))\n","5541e030":"# NearMiss\uc640 \ub3d9\uc77c \ucf54\ub4dc \n# Shuffle \uc5b8\ub354\ud504\ub808\uc784\ndf = df.sample(frac=1)   #shuffle\ndf1 = df.loc[df['Class'] == 1]\ndf0 = df.loc[df['Class'] == 0][:len(df1)]\nunder_df_f1f0 = pd.concat([df1, df0])\nunder_df = under_df_f1f0.sample(frac=1, random_state=42)","376e8505":"lr_clf = LogisticRegression(random_state = 36)\nlr_clf.fit(X_train_NearMiss,y_train_NearMiss)\npred_lr = lr.predict(X_test_NearMiss)\nproba_lr = lr.predict_proba(X_test_NearMiss)\nmyscore(y_test_NearMiss, pred_lr, proba_lr, pr_curve=1, auc_curve=1)","41311003":"from imblearn.over_sampling import SMOTE","5dffdaf8":"smote = SMOTE(random_state=0)\nprint('SMOTE \uc0ac\uc6a9 \uc804 train ', X_train.shape, y_train.shape)\nX_train_over, y_train_over = smote.fit_resample(X_train, y_train)\nprint('SMOTE \uc0ac\uc6a9 \ud6c4 train_over ', X_train_over.shape, y_train_over.shape)\nprint('SMOTE \uc0ac\uc6a9 \ud6c4 y_train_over ', pd.Series(y_train_over).value_counts())","b790c189":"lr_clf = LogisticRegression(random_state = 36)\nlr_clf.fit(X_train_over,y_train_over)\npred_lr = lr.predict(X_test)\nproba_lr = lr.predict_proba(X_test)\nmyscore(y_test, pred_lr, proba_lr, pr_curve=1, auc_curve=1)","60121cca":"lgbm = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\nlgbm.fit(X_train_over, y_train_over)\npred_dt = lgbm.predict(X_test)\nproba_dt = lgbm.predict_proba(X_test)\nmyscore(y_test, pred_dt, proba_dt, pr_curve=1, auc_curve=1)","8c87203a":"def get_outlier(df=None, column=None, weight=1.5):\n    fraud = df[df['Class']==0][column]\n    quantile_25 = np.percentile(fraud.values, 25)\n    quantile_75 = np.percentile(fraud.values, 75)\n    \n    iqr = quantile_75 - quantile_25\n    iqr_weight = iqr * weight\n    lowest_val = quantile_25 - iqr_weight\n    highest_val = quantile_75 + iqr_weight\n    \n    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n    return outlier_index","1c10c503":"outlier_index = get_outlier(df=df, column='V14', weight=1.5)\nprint('\uc774\uc0c1\uce58 \uc778\ub371\uc2a4', outlier_index)","adf8c361":"df_copy = df.copy()","587cb526":"df_copy.drop(outlier_index, axis=0, inplace=True)","3858099b":"lgbm = LGBMClassifier(boost_from_average=False)\nlgbm.fit(X_train, y_train)\npred_dt = lgbm.predict(X_test)\nproba_dt = lgbm.predict_proba(X_test)\nmyscore(y_test, pred_dt, proba_dt, pr_curve=1, auc_curve=1)","5e89f90f":"df_y = df_copy.iloc[:, -1]  #df[\"traget\"]  \ndf_X = df_copy.iloc[:, :-1]\nprint(len(df_y), df_X.shape)\nX_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=36,  shuffle=True)\nprint(X_train.shape, X_test.shape, len(y_train), len(y_test))","ea663e66":"smote = SMOTE(random_state=0)\nprint('SMOTE \uc0ac\uc6a9 \uc804 train ', X_train.shape, y_train.shape)\nX_train_over, y_train_over = smote.fit_resample(X_train, y_train)\nprint('SMOTE \uc0ac\uc6a9 \ud6c4 train_over ', X_train_over.shape, y_train_over.shape)\nprint('SMOTE \uc0ac\uc6a9 \ud6c4 y_train_over ', pd.Series(y_train_over).value_counts())","8aa6db08":"lgbm = LGBMClassifier(boost_from_average=False)\nlgbm.fit(X_train_over, y_train_over)\npred_dt = lgbm.predict(X_test)\nproba_dt = lgbm.predict_proba(X_test)\nmyscore(y_test, pred_dt, proba_dt, pr_curve=1, auc_curve=1)","0aab3c97":"### \uc774\uc0c1\uce58 \uc81c\uac70 \ud6c4, \uc624\ubc84\uc0d8\ud50c\ub9c1","a613de41":"## \uc774\uc0c1\uce58 \uc81c\uac70","fcf08a79":"### 0 \ub370\uc774\ud130 \ud655\uc778","22213811":"##  \uac80\uc99d\n * GridSearchCV cv=10\ud68c\n * \uad50\ucc28\uac80\uc99d","fb04ec73":"## \uc624\ubc84\uc0d8\ud50c\ub9c1","6dc036c4":"### \uc5b8\ub354\uc0d8\ud50c\ub9c1 - shuffle","3e88c5e2":"## \uc5b8\ub354\uc0d8\ud50c\ub9c1 \n- \uacfc\uc801\ud569 \ub9ce\uc774 \ub098\uc634\n- \ud604\uc5c5\uc5d0\uc11c \uac70\uc758 \uc548\uc4f0\uc784\n- \uacf5\ubaa8\uc804\uc5d0\uc11c\ub294 \uc810\uc218 \uc62c\ub9ac\ub824\uace0 \uc4f0\uae34 \ud568 ","b7a87ec5":"  ## EDA","72874036":"### \uc5b8\ub354\uc0d8\ud50c\ub9c1 - NearMiss build model"}}