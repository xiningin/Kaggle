{"cell_type":{"f3795da2":"code","90849d0c":"code","557c8eac":"code","59ba2c30":"markdown","036c43c9":"markdown","c928fe99":"markdown"},"source":{"f3795da2":"from pyspark.ml.classification import RandomForestClassifier\nimport sklearn.metrics as metrics\nimport pandas as pd\nfrom plotnine import *\nfrom plotnine.data import meat\nfrom mizani.breaks import date_breaks\nfrom mizani.formatters import date_format\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StandardScaler, StringIndexer, OneHotEncoder, Imputer, VectorAssembler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nimport mlflow\nimport mlflow.spark\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\nfrom pyspark.ml.linalg import Vectors\n\n\n# setting the parameters\nmaxIter = 10    #max itteration is the number of trees\n  \n \n # we start with mlflow.start_run() which essentially start tracking what we are doing in this notebook in databricks\nwith mlflow.start_run():\n    indexers = list(map(lambda c: StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid = \"keep\"), categoricals))\n    ohes = list(map(lambda c: OneHotEncoder(inputCol=c + \"_idx\", outputCol=c+\"_class\"), categoricals))\n    imputers = Imputer(inputCols = numerics, outputCols = numerics)\n    featureCols = list(map(lambda c: c+\"_class\", categoricals)) + numerics\n    \n    # Define vector assemblers\n    labelCol = \"default_loan\"\n    model_matrix_stages = indexers + ohes + \\\n                          [imputers] + \\\n                          [VectorAssembler(inputCols=featureCols, outputCol=\"features\"), \\\n                           StringIndexer(inputCol= labelCol, outputCol=\"label\")]\n    \n       \n    # here, we define a RF model.\n    rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n    \n    \n    params = ParamGridBuilder() \\\n             .addGrid(rf.numTrees, [3, 5, 10]) \\\n             .build()\n\n    \n    # Chain indexer and RF in a Pipeline\n    #now, we define a pipline which includes everything from standardazing the data, imputing missing values and encoding for categorical columns\n    pipeline_rf = Pipeline(stages=model_matrix_stages+[rf])\n    \n    # Train model. This also runs the indexer. \n    cv = CrossValidator(estimator=pipeline_rf, estimatorParamMaps=params, evaluator=BinaryClassificationEvaluator(), numFolds=5)\n    rf_model = cv.fit(train)\n    \n     \n         ## Evaluate and Log Metrics  (here we score the customers)\n    def extract(row):\n      return (row.remain,) + tuple(row.probability.toArray().tolist()) + (row.label,) + (row.prediction,)\n\n    def score(model,data):\n      pred = model.transform(data).select(\"remain\", \"probability\", \"label\", \"prediction\")\n      pred = pred.rdd.map(extract).toDF([\"remain\", \"p0\", \"p1\", \"label\", \"prediction\"])\n      return pred\n\n    def auc(pred):\n      metric = BinaryClassificationMetrics(pred.select(\"p1\", \"label\").rdd)\n      return metric.areaUnderROC\n    \n    \n    ## Evaluate and Log Metrics  (here we score the customers)\n    rfm_train = score(rf_model, train)\n    rfm_valid = score(rf_model, valid)\n    \n    rfm_train.registerTempTable(\"rfm_train\")\n    rfm_valid.registerTempTable(\"rfm_valid\")\n    \n    print( \"RFM Training AUC :\" + str( auc(rfm_train)))\n    print( \"RFM Validation AUC :\" + str(auc(rfm_valid)))\n  \n    ## here we log the auc values and the area under the curve for the models metrics as we defined before for training as well as validation dataset\n    mlflow.log_metric(\"train_auc\", auc(rfm_train))\n    mlflow.log_metric(\"valid_auc\", auc(rfm_valid))","90849d0c":"pandas_df = glm_valid.toPandas()\ntxt = 'This table represents the \"CONFUSION MATRIX\" from Random Forest'\nprint(txt.title())\npd.crosstab(pandas_df.label, pandas_df.prediction, values=pandas_df.remain, aggfunc=\"count\").round(2)\n","557c8eac":"pandas_df_sum_net = glm_valid.groupBy(\"label\", \"prediction\").agg((sum(col(\"remain\"))).alias(\"sum_net\")).toPandas()\r\ntxt = 'This table represents the \"SUM NET\" from Random Forest'\r\nprint(txt.title())\r\npd.crosstab(pandas_df_sum_net.label, pandas_df_sum_net.prediction, values=pandas_df_sum_net.sum_net , aggfunc=\"sum\").round(2)","59ba2c30":"Links: \n*[ResearchGate](https:\/\/www.researchgate.net\/profile\/Afshin-Ashofteh-2)\n*[Kaggle](https:\/\/www.kaggle.com\/aashofteh)\n*[Google Scholar](https:\/\/scholar.google.com\/citations?user=oIa1W0gAAAAJ&hl=en)\n*[Data Science Discussion Group](https:\/\/www.linkedin.com\/groups\/12420006)\n*[email](aashofteh@novaims.unl.pt)","036c43c9":"# Machine Learning Codes for Credit Scoring - Random Forests\n\nFor citation: https:\/\/doi.org\/10.1016\/j.eswa.2021.114835 (Journal - Expert Systems with Applications.)\n\nAsk for full-text in [ResearchGate](https:\/\/www.researchgate.net\/profile\/Afshin-Ashofteh-2)\n\nAfshin Ashofteh [email](aashofteh@novaims.unl.pt)\n\nSubject: Credit Risk and Credit Scoring.\n\nDatasource: loan.csv - Each loan includes applicant information provided by the applicant as well as current loan status (Current, Late, Fully Paid, etc.) and latest payment information.\n\n","c928fe99":"# Random Forests"}}