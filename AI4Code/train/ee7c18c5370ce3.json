{"cell_type":{"0f6fbc5d":"code","b314a501":"code","a07750ad":"code","21dc5479":"code","84a5c57e":"code","065a81be":"code","6a3d1058":"code","796296fa":"code","0f7d8075":"code","af44a601":"code","480de9a8":"code","83c48962":"code","287fff05":"code","c74bfd89":"markdown","6b8b76ab":"markdown","076d7adc":"markdown","a14f3ed9":"markdown","be6a108f":"markdown"},"source":{"0f6fbc5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b314a501":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Importing data\ndata = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndel data['Unnamed: 32']","a07750ad":"X = data.iloc[:, 2:].values\ny = data.iloc[:, 1].values\n\n# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X_1 = LabelEncoder()\ny = labelencoder_X_1.fit_transform(y)\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n\n#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","21dc5479":"import keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout","84a5c57e":"Classifier = tf.keras.models.Sequential()","065a81be":"# Add the input Layer and first hidden layer\n\n#How to check the number of nodes in hidden layer = [(Number of nodes in input)+(Number of nodes in Output layer)]\/2\n# (30+1)\/2 = 15.5 ~16\n\n\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim=16, init='uniform', activation='relu', input_dim=30))\n# Adding dropout to prevent overfitting\nclassifier.add(Dropout(p=0.1))\n\n# Adding the 2nd Hidden Layer\nclassifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\nclassifier.add(Dropout(p=0.1))\n\n#Adding the Output Layer\nclassifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))","6a3d1058":"classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","796296fa":"classifier.fit(X_train, y_train, batch_size=100, nb_epoch=250)","0f7d8075":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","af44a601":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","480de9a8":"cm","83c48962":"print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])\/57)*100))","287fff05":"sns.heatmap(cm,annot=True)\nplt.savefig('h.png')","c74bfd89":"# Initialise ANN","6b8b76ab":"# Compile the ANN","076d7adc":"# Training the ANN on the training Set","a14f3ed9":"# Data Preprocessing","be6a108f":"# Building an Artificial Neural Network"}}