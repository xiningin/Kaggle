{"cell_type":{"417920fe":"code","3553f35b":"code","07d9fae8":"code","4ef7147c":"code","779ae461":"code","e4d69714":"code","297782aa":"code","37293a29":"code","62857434":"code","fcb4d4c3":"code","0f602431":"code","61796c55":"code","df48d017":"code","ef6f4c46":"code","41193950":"code","0bd5540c":"code","fd59987a":"code","00b695f0":"code","a73e0937":"code","e4b2c601":"code","80157614":"code","934dfdda":"code","4ab3c5cb":"code","6c183e24":"code","5affc87f":"code","239356bd":"code","2d1497ce":"code","a4feef6c":"code","fd16d9b1":"code","80c085bc":"code","34545d1f":"markdown","f18b7e75":"markdown","8841e0d3":"markdown","b38c790c":"markdown","1190b3ce":"markdown","b8a1c229":"markdown","6875834d":"markdown","b9f282fe":"markdown","fffce023":"markdown","a87450d0":"markdown","a760d177":"markdown","29763913":"markdown","89d0fd5e":"markdown","35918578":"markdown","da25d2d3":"markdown","3b66e79d":"markdown","bf9d88eb":"markdown","69fa220b":"markdown","316b7b5a":"markdown","1bef89d2":"markdown","5db89535":"markdown","982d3d28":"markdown","81358414":"markdown","df35a2eb":"markdown"},"source":{"417920fe":"import pandas as pd\nimport numpy as np\n\n# What do we say to python warnings? NOT TODAY\nimport warnings\nwarnings.filterwarnings('ignore')","3553f35b":"def select_features(df, target, th):\n    \"\"\"\n    Select features.\n    \"\"\"\n    # Select rows with our target value\n    proc_df = df[df[target].isna() == False]\n    \n    # Remove useless columns\n    to_drop = [col for col in proc_df.columns if ((\"(F)\" in col) or (\"(fpm)\" in col) or (\"Thermal\" in col) or (\"Air movement\" in col)) and (col != target)] + [\"Database\", \"Publication (Citation)\", \"Data contributor\"]\n    proc_df = proc_df.drop(to_drop, axis=1)\n    \n    # Remove columns with a lot of missing values\n    # Get columns with less than 30% of data missing\n    s = (proc_df.isna().sum() \/ len(proc_df) * 100 < th)\n    to_keep = list(s[s].index)\n    proc_df = proc_df[to_keep]\n    \n    return proc_df","07d9fae8":"def group_koppen_categories(category):\n    if \"A\" in category:\n        return \"A\"\n    elif \"B\" in category:\n        return \"B\"\n    elif \"C\" in category:\n        return \"C\"\n    elif \"D\" in category:\n        return \"D\"\n    elif \"E\" in category:\n        return \"E\"\n    else:\n        return None\n    \ndef handle_categorical_features(df):\n\n    from sklearn.impute import SimpleImputer\n    from sklearn.preprocessing import OneHotEncoder\n    \n    # Drop climate\n    df.drop(\"Climate\", axis=1, inplace=True)\n    # Group koppen climate\n    df[\"Koppen climate classification\"] = [group_koppen_categories(category) for category in df[\"Koppen climate classification\"]]\n    # Fill missing cooling strategy in city Harbin\n    df.loc[df.City == \"Harbin\", \"Cooling startegy_building level\"] = \"Naturally Ventilated\"\n    # Fill missing city in Malaysia\n    df.loc[df.Country == \"Malaysia\", \"City\"] = \"Kota Kinabalu\"\n    \n    # Input mode by city in Season and Cooling strategy\n    # Get list of categorical variables with missing values\n    cols = [\"Season\", \"Cooling startegy_building level\"]\n    # Input mode for each city\n    for city in df.City.unique():\n        # Filter data of selected city\n        temp = df.loc[df.City == city, cols]\n        # Create imputer\n        imputer = SimpleImputer(strategy='most_frequent')\n        # Input missing values with mode\n        imputed = pd.DataFrame(imputer.fit_transform(temp))\n        # Rename columns and index\n        imputed.columns = temp.columns\n        imputed.index = temp.index\n        # Replace in dataframe\n        df.loc[df.City == city, cols] = imputed\n        \n    # Encode\n    # Get list of categorical variables\n    s = (df.dtypes == 'object')\n    cols = list(s[s].index)\n    # One Hot Encoder\n    for col in cols:\n        # Create encoder\n        OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        # Transform\n        OH_cols = pd.DataFrame(OH_encoder.fit_transform(df[[col]]))\n        # Get categories names and rename\n        names = OH_encoder.categories_\n        OH_cols.columns = names\n        OH_cols.index = df.index\n        # Add encoded columns\n        df[list(names[0])] = OH_cols\n\n    # Drop un-encoded column\n    df.drop(cols, axis=1, inplace=True)\n    \n    return df\n\n    \n    \ndef get_balance_dataset_index(df, target):\n    \"\"\"\n    df: the dataset to balance\n    target: the name of the target column\n    \"\"\"\n    \n    # Get count for each category\n    value_counts = df.value_counts(target).to_dict()\n    \n    # List comprehension to find the key with the minimum value (count)\n    min_category = [k for k,v in value_counts.items() if v == min(value_counts.values())][0]\n    min_count = [v for k,v in value_counts.items() if v == min(value_counts.values())][0]\n    \n    # For each category in your target\n    dfs = []\n    for key in value_counts:\n        if key == min_category:\n            df1 = df[df[target] == min_category]\n        else:\n            df1 = df[df[target] == key].sample(min_count, random_state=55)\n        dfs.append(df1)\n    \n    dfb = pd.concat(dfs)\n    print(f\"Your balance dataset: {dfb.value_counts(target).to_dict()}\")\n    \n    return dfb.index","4ef7147c":"def handle_numerical_features(df, df_raw):\n    \"\"\"\n    Input mean by city.\n    \"\"\"\n    \n    cols = ['Clo',\n             'Met',\n             'Air temperature (C)',\n             'Relative humidity (%)',\n             'Air velocity (m\/s)',\n             'Outdoor monthly air temperature (C)',\n             'City',\n             'Country']\n\n    df1 = df_raw[cols]\n\n    # Input mode in missing Malaysia city\n    df1.loc[df1.Country == \"Malaysia\", \"City\"] = \"Kota Kinabalu\"\n\n    cols = ['Clo',\n             'Met',\n             'Air temperature (C)',\n             'Relative humidity (%)',\n             'Air velocity (m\/s)',\n             'Outdoor monthly air temperature (C)']\n\n    # Input mean by city in numerical features\n    # Input mode for each city\n    for city in df1.City.unique():\n        # Filter data of selected city\n        temp = df1.loc[df1.City == city, cols]\n        # Serie with the mean per column\n        means = temp.mean()\n        # Fill the missing values with the mean\n        temp = temp.fillna(means)\n        # Replace in dataframe\n        df1.loc[df1.City == city, cols] = temp\n\n    # there are cities with all null\n    df1 = df1.fillna(df1.mean())\n\n    # Add to dataset\n    df = df.drop(cols, axis=1)\n    df[cols] = df1.drop([\"City\",\"Country\"], axis=1) # we don't need the column City anymore, we have it encoded\n    \n    return df","779ae461":"target = \"Thermal sensation acceptability\"\n\n# Load original data\ndf_raw = pd.read_csv(\"\/kaggle\/input\/ashrae-global-thermal-comfort-database-ii\/ashrae_db2.01.csv\", low_memory=False)\n# Select features\ndf = select_features(df_raw, target, 25)\n# Handle categorical features\ndf = handle_categorical_features(df)\n#get indexes from balanced dataset, this is to use always the same rows to predict\nidx = get_balance_dataset_index(df, target)\n# Handle numerical features\ndf = handle_numerical_features(df, df_raw)","e4d69714":"df.head()","297782aa":"df.info()","37293a29":"# Load data\ncountries = pd.read_csv(\"..\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv\",\n                       usecols=[\"country\",\"latitude\"])\n# Rename column\ncountries = countries.rename(columns={\"country\":\"Country\"})","62857434":"df_country = pd.merge(df_raw[[\"Country\"]], countries, how=\"left\", on=\"Country\")\ndf_country.head()","fcb4d4c3":"df_country[\"is_northern\"] = [1 if lat > 0 else 0 for lat in df_country.latitude]","0f602431":"df_country[df_country.latitude.isna()].Country.unique()","61796c55":"df_country.loc[df_country[\"Country\"].isin([\"USA\", \"UKA\"]), [\"latitude\"]] = 1","df48d017":"df = df.join(df_country[[\"is_northern\"]])","ef6f4c46":"df[\"clo_met_ratio\"] = df.Clo \/ df.Met","41193950":"df.info()","0bd5540c":"mean_air_temp = pd.DataFrame(df_raw.groupby([\"City\",\"Season\"])[\"Air temperature (C)\"].mean()).reset_index().rename(columns={\"Air temperature (C)\":\"mean_air_temp\"})\nmean_rel_humidity = pd.DataFrame(df_raw.groupby([\"City\",\"Season\"])[\"Relative humidity (%)\"].mean()).reset_index().rename(columns={\"Relative humidity (%)\":\"mean_rel_humidity\"})","fd59987a":"means_df = pd.merge(df_raw, mean_air_temp, how=\"left\", on=[\"City\",\"Season\"]).merge(mean_rel_humidity, how=\"left\", on=[\"City\",\"Season\"])[[\"mean_air_temp\", \"mean_rel_humidity\"]]\nmeans_df","00b695f0":"means_df.fillna(means_df.mean(), inplace=True)","a73e0937":"df = df.join(means_df)","e4b2c601":"df.info()","80157614":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import roc_auc_score, classification_report","934dfdda":"dfb = df.loc[idx]","4ab3c5cb":"dfb.head()","6c183e24":"X = dfb.drop(\"Thermal sensation acceptability\", axis=1)\ny = dfb[\"Thermal sensation acceptability\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)","5affc87f":"# Define the model\nmy_model = XGBClassifier(n_estimators=50, learning_rate=0.1, n_jobs=4, random_state=55, \n                         objective=\"binary:logistic\", eval_metric=\"auc\", use_label_encoder=False)\n\n# Perform cross validation with 5 folds\nprint(\"Training...\")\nscores = cross_val_score(my_model, \n                          X_train, y_train,\n                          cv=5,\n                          scoring='roc_auc')\nprint(\"...done.\")","239356bd":"print(f\"Scores: {scores}\")\nprint(f\"Mean scores: {np.mean(scores)}\")","2d1497ce":"# This is the model we are going to train (a simple one)\nmy_model = XGBClassifier(n_estimators=50, learning_rate=0.1, n_jobs=4, random_state=55, objective=\"binary:logistic\")\n\n# Train\nprint(\"Training...\")\nmy_model.fit(X_train, y_train, verbose=False)\nprint(\"...done\")","a4feef6c":"# And we predict\nprediction = pd.DataFrame({\"y_pred\": my_model.predict(X_test), \"y_real\": y_test})\nroc_auc_score(prediction.y_real, prediction.y_pred)","fd16d9b1":"print(classification_report(prediction.y_real, prediction.y_pred))","80c085bc":"def simple_fe(df, df_raw):\n    \"\"\"\n    Add simple features to data frame.\n    \"\"\"\n    # New categorical features\n    # Load countries data\n    countries = pd.read_csv(\"..\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv\",\n                           usecols=[\"country\",\"latitude\"])\n    # Rename column\n    countries = countries.rename(columns={\"country\":\"Country\"})\n    # Merge\n    df_country = pd.merge(df_raw[[\"Country\"]], countries, how=\"left\", on=\"Country\")\n    # Add feature\n    df_country[\"is_northern\"] = [1 if lat > 0 else 0 for lat in df_country.latitude]\n    # Fill missings\n    df_country.loc[df_country[\"Country\"].isin([\"USA\", \"UKA\"]), [\"latitude\"]] = 1\n    # Join\n    df = df.join(df_country[[\"is_northern\"]])\n    \n    # New numerical feature\n    df[\"clo_met_ratio\"] = df.Clo \/ df.Met\n    \n    # Group features\n    mean_air_temp = pd.DataFrame(df_raw.groupby([\"City\",\"Season\"])[\"Air temperature (C)\"].mean()).reset_index().rename(columns={\"Air temperature (C)\":\"mean_air_temp\"})\n    mean_rel_humidity = pd.DataFrame(df_raw.groupby([\"City\",\"Season\"])[\"Relative humidity (%)\"].mean()).reset_index().rename(columns={\"Relative humidity (%)\":\"mean_rel_humidity\"})\n    means_df = pd.merge(df_raw, mean_air_temp, how=\"left\", on=[\"City\",\"Season\"]).merge(mean_rel_humidity, how=\"left\", on=[\"City\",\"Season\"])[[\"mean_air_temp\", \"mean_rel_humidity\"]]\n    means_df.fillna(means_df.mean(), inplace=True)\n    df = df.join(means_df)\n    \n    return df","34545d1f":"## Balance dataset\nWe are going to use the function we defined before! it's at the beginning of this notebook.","f18b7e75":"And we cross-validate with our training data:","8841e0d3":"# Model\nNow is time to train the model We are going the follow the same process as before:\n1. Balance data set\n2. Split in train and test\n3. 5-folds cross validation training\n4. Training with whole training data set\n5. Prediction of test data set","b38c790c":"And finally, we join with our data set.","1190b3ce":"This kind of features that are simple for us sometimes are useful because they \"help\" the model: instead of training a long time to find out those values we are feeding them to it.\n\nLet's create a dataframe with these features:","b8a1c229":"## New categorical feature\nOne way to create new features is to extract data, related to our problem, from external data sets. For example, our data is focused on thermal comfort, which is highly related to season; we have geographical data like city, what about adding a feature that indicates if the person asked about thermal comfort is in the northern or southern hemisphere? Season depends on that and it's much simpler than a 4 categories feature (sometimes less is more).\n\nLet's try out that! Remember how northern and southern hemispheres are set: latitudes greater than zero are in the north and negative latitudes are in the south ([photo source](https:\/\/www.geographyrealm.com\/latitude-longitude\/)).\n![hemishperes](https:\/\/cdn.shortpixel.ai\/spai\/w_546+q_lossless+ret_img+to_webp\/https:\/\/www.geographyrealm.com\/wp-content\/uploads\/2014\/08\/latitude.png)\n\nWe already have the country in our data, now we need the latitude. We can use [this Kaggle dataset](https:\/\/www.kaggle.com\/paultimothymooney\/latitude-and-longitude-for-every-country-and-state). Let's load it and select the features we want, country and latitude:","6875834d":"## Train and predict\nLet's see what happens when we train with the whole training data set.","b9f282fe":"And we add it to our data set! we are going to use the method join because we are joining by index.","fffce023":"Now is time to merge! Let's hope the countries are written exactly in the same way. When you work with data from different sources is common to have to deal with the data first, cleaning and making it consistent among all the data sets.","a87450d0":"# Group features\nAnother quite simple way of adding features is summarizing any of the existent numerical features in your data. We can play around with some of the weather features, for example air temperature or relative humidity; let's calculate the **mean by City and Season**.","a760d177":"# Simple features","29763913":"We are still getting similar values, not a great improvement.","89d0fd5e":"# Load data\nThe functions used here were defined in previous notebooks, they replicate the process followed there to use always the same dataset, you can ignore them.","35918578":"We have some missings, this is because of a problem we have already encountered: it may not be data for all city-season combination. Let's fill them with the column mean.","da25d2d3":"## New numerical feature\nLet's try our a numerical feature. We have these two:\n\n- `Clo`: intrinsic ensemble insulation of the subject\n- `Met`: average metabolic rate if the subject\n\nMaybe getting the ratio of these two features could work? It's really easy to add it.","3b66e79d":"# Notebook goal\nThe goal of this notebook is to create some simple new features:\n\n- Categorical feature created from external data\n- Numerical feature created by simple mathematical operations\n- Group features\n\nAt the end, we will train a predictive model. Here will be shown only one of the many possibilities in machine learning, feel free to experiment and play around with the data on your own. We will be focusing on the techniques and not on the model performance.","bf9d88eb":"# Introduction\n\nThis is a serie of notebooks thar should be visited in order, they are all linked in the table of content. In this notebook we are going to create some simple features and run a classification model.\n\n### Content table\n- [Preprocessing pt. 1: data transformation & EDA](https:\/\/www.kaggle.com\/ponybiam\/classification-preprocessing-pt-1\/)\n- [Preprocessing pt. 2: encoding categorical variables](https:\/\/www.kaggle.com\/ponybiam\/classification-preprocessing-pt-2)\n- [Preprocessing pt. 3: handling missing values](https:\/\/www.kaggle.com\/ponybiam\/classification-preprocessing-pt-3) \n- **Feature engineering pt. 1: simple features** (you are here)\n    - [Load data](#Load-data)\n    - [Simple features](#Simple-features)\n        - [New categorical feature](#New-categorical-feature)\n        - [New numerical feature](#New-categorical-feature)\n    - [Model](#Model)\n        - [Balance dataset](#Balance-dataset)\n        - [Split and cross validation](#Split-and-cross-validation)\n        - [Train and predict](#Train-and-predict)\n- [Feature engineering pt. 2: clustering & PCA](https:\/\/www.kaggle.com\/ponybiam\/classification-feature-engineering-pt-2)\n- [Feature engineering pt. 3: target encoding](https:\/\/www.kaggle.com\/ponybiam\/classification-feature-engineering-pt-3)","69fa220b":"## Split and cross validation\nLet's split our data. Don't forget to set a `random_state` if you want to replicate the process and obtain the same results.","316b7b5a":"# (Optional) One function to do it all\nThis part is optional. We are going to write functions that follows all the steps we performed here. These functions will be used in the following notebooks.","1bef89d2":"Ok we missed two. We could rename the countries in our external data set or create the value `is_northern` manually. We are going to do it manually because they are only two and both are northern countries.","5db89535":"I can't beleive we are still getting a lower score than our first attemp. But we still have some stronger feature engineering to apply!","982d3d28":"Now, let's check out the missing values, maybe any of the countries wasn't on the table and we didn't notice:","81358414":"| Notebook           | Categorical features | Missing values in categorical | Missing values in numerical | Feature engineering | ROC-AUC score |\n|--------------------|----------------------|-------------------------------|-----------------------------|---------------------|---------------|\n| Preprocessing pt.2 | One Hot Encoding     | Mode input                    | 0 input                     | -                   |0.6591         |\n| Preprocessing pt.3 | One Hot Encoding     | Mode Input                    | Mean input                  | -                   |0.6466         |\n| FE pt.1            | One Hot Encoding     | Mode Input                    | Mean input                  | Simple              |0.6507         |","df35a2eb":"Seems like it's working! Now we are going to create a boolean feature named `is_northern`: we will use 1 when True and 0 when False. This way it's already encoded ;)"}}