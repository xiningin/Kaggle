{"cell_type":{"fcb95771":"code","2545d591":"code","366241d8":"code","2d5d691b":"code","211f09e5":"code","9b71b376":"code","21a5b701":"code","f44934ac":"code","9762b595":"code","5847b553":"code","7f14d2c7":"code","0868fc0e":"code","bd1b4c2a":"code","be70bc74":"code","20e1bc0a":"code","49ff899f":"code","ef7fe714":"code","1f91c2da":"code","437bb30b":"code","bd6100d7":"code","063ceda0":"code","df9b874a":"code","5bd6a20f":"code","8bf4d8f4":"code","195e6f1c":"code","9f91fc2f":"code","b22497f5":"code","f6550752":"code","22db85eb":"code","2e4d9b6b":"code","71a5280d":"code","0dfbe62a":"code","c0e85a01":"code","9f48e257":"code","06f88751":"code","9596f05f":"code","8866218b":"code","f4cf9cdd":"code","89702aa0":"code","62694e99":"code","ba39a53d":"code","b468ea50":"code","fbfbb24a":"code","ae367058":"code","5982d433":"code","c868c341":"code","a6b48c02":"code","5a5b3275":"code","b941ea57":"code","4620f654":"code","1b1e16ce":"code","956e8bc1":"code","f5cc36e6":"code","32928136":"code","5edf973f":"code","2757440c":"code","3492b155":"code","0f270ee8":"code","f2fc3285":"code","6ce96a6b":"code","3d792e68":"code","f4f8a0d3":"code","783076c7":"code","a817764a":"markdown","3721735f":"markdown","c2d2adde":"markdown","bc139d97":"markdown"},"source":{"fcb95771":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nfrom sklearn.metrics import roc_auc_score, roc_curve\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2545d591":"import datetime","366241d8":"%%time\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")","2d5d691b":"print('Train data Rows {} and Clomuns {}'.format(train_df.shape[0], train_df.shape[1]))\n\nprint('Test data Rows {} and Clomuns {}'.format(test_df.shape[0], test_df.shape[1]))","211f09e5":"# load the random train data\ntrain_df.sample(5)","9b71b376":"#load the random test data\ntest_df.sample(5)","21a5b701":"#Check the train data type\ntrain_df.info()","f44934ac":"#ID_code are object type \n#Traget values are in int64\n#Variable data are in float","9762b595":"#Check the test data type\ntest_df.info()","5847b553":"#Now check for missing values\ntotal = train_df.isnull().sum().sort_values(ascending = False)\npercent = (train_df.isnull().sum()\/train_df.isnull().count()*100).sort_values(ascending = False)\nmissing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","7f14d2c7":"# As we can see there is No mising values in data set\nmissing_df.head()","0868fc0e":"#Now check for missing values\ntotal = test_df.isnull().sum().sort_values(ascending = False)\npercent = (test_df.isnull().sum()\/test_df.isnull().count()*100).sort_values(ascending = False)\nmissing_df_test = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df_test.head()","bd1b4c2a":"train_df.describe()","be70bc74":"test_df.describe()","20e1bc0a":"#Lets check for target data distribution\nsns.set(style=\"darkgrid\")\nsns.countplot(train_df['target'],palette=\"Set3\")\nplt.show()","49ff899f":"%%time\nprint('% values of Target 0 is {}'.format(100*train_df['target'].value_counts()[0]\/train_df.shape[0]))\nprint('% values of Target 1 is {}'.format(100*train_df['target'].value_counts()[1]\/train_df.shape[0]))","ef7fe714":"#90% of data contain 0 values & 10% is 1 ----> (Imbalance data)","1f91c2da":"from scipy.stats import norm\nfrom scipy import stats\n#histogram and normal probability plot\nsns.distplot(train_df['target'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_df['target'], plot=plt)","437bb30b":"#train_df.drop(axis=1, columns=['ID_code'], inplace=True)","bd6100d7":"#X = train_df.drop(['target'], axis=1)\n#y = train_df['target']","063ceda0":"#from sklearn.feature_selection import RFE\n#from sklearn.ensemble import RandomForestClassifier","df9b874a":"#rfe_selector = RFE(estimator=RandomForestClassifier(), n_features_to_select=1, step=1, verbose=0)\n#rfe_selector.fit(X, y)","5bd6a20f":"#rfe_support = rfe_selector.get_support()\n#rfe_feature = X.loc[:,rfe_support].columns.tolist()\n#print(str(len(rfe_feature)), 'Selected Features')","8bf4d8f4":"#Rank=rfe_selector.ranking_\n#Columns = X.columns","195e6f1c":"#REF_Fea = pd.DataFrame([Columns,Rank], index=['Name','Rank'])\n#REF_Fea.transpose().sort_values('Rank',ascending=True)\n#REF_Fea.transpose().sort_values('Rank',ascending=True).Name.tolist()","9f91fc2f":"#pd.Series(Rank.Rank).plot.barh(color='red', figsize=(10, 8))","b22497f5":"#EDA for selected Features\ntrain_df1=train_df[['var_139', 'var_146', 'var_81', 'var_12', 'var_80', 'var_174', 'var_6', 'var_13', 'var_18', 'var_110', 'var_26',\n 'var_166', 'var_133', 'var_198', 'var_21', 'var_127', 'var_22', 'var_86', 'var_190', 'var_40', 'var_99', 'var_75',\n 'var_109', 'var_170', 'target']]","f6550752":"#taking Mean, Max, Std and Min values for checking distribtion\ndf=pd.DataFrame(train_df1.mean(axis=0),columns=[\"Mean\"])\ndf['Min']=train_df1.min(axis=0)\ndf['Max']=train_df1.max(axis=0)\ndf['Std']=train_df1.std(axis=0)\ndf['Var_name']=df.index\ndf = df.reset_index(drop=True)\ndf","22db85eb":"plt.subplots(figsize=(10,5))\ndf.boxplot(rot=90);","2e4d9b6b":"train_df1.head(2)","71a5280d":"#Box flot of Selected variable for checking the distriution\nplt.subplots(figsize=(18,8))\ntrain_df1.boxplot(rot=90);","0dfbe62a":"#Histogram for Selected Variables\ntrain_df1.hist(figsize=(20,20));","c0e85a01":"Yes = train_df1[train_df1['target']==1]\nNo = train_df1[train_df1['target']==0]","9f48e257":"z1=len(train_df1.columns)\nz1","06f88751":"var=train_df1.columns\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(5,5,figsize=(15,15))\nj=0\nfor i in var:\n    j+=1\n    plt.subplot(5,5,j)\n    sns.kdeplot(Yes[i], label='1', color='r',alpha=0.75)\n    sns.kdeplot(No[i], label='0', color='b',alpha=0.75)\n    plt.title(i)","9596f05f":"#for traget value=1\ndf_Yes=pd.DataFrame(Yes.mean(axis=0),columns=[\"Mean\"])\ndf_Yes['Min']=Yes.min(axis=0)\ndf_Yes['Max']=Yes.max(axis=0)\ndf_Yes['Std']=Yes.std(axis=0)\ndf_Yes['Sum']=Yes.sum(axis=0)\ndf_Yes['Skew']=Yes.skew(axis=0)\ndf_Yes['Kurt']=Yes.kurt(axis=0)\ndf_Yes['Var_name']=df_Yes.index\ndf_Yes = df_Yes.reset_index(drop=True)","8866218b":"#for target value 0\ndf_No=pd.DataFrame(No.mean(axis=0),columns=[\"Mean\"])\ndf_No['Min']=No.min(axis=0)\ndf_No['Max']=No.max(axis=0)\ndf_No['Std']=No.std(axis=0)\ndf_No['Sum']=No.sum(axis=0)\ndf_No['Skew']=No.skew(axis=0)\ndf_No['Kurt']=No.kurt(axis=0)\ndf_No['Var_name']=df_Yes.index\ndf_No = df_No.reset_index(drop=True)","f4cf9cdd":"var1=df_Yes.columns[:-1]\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(4,2,figsize=(10,10))\nj=0\nfor i in var1:\n    j+=1\n    plt.subplot(4,2,j)\n    sns.kdeplot(df_Yes[i], label='1', color='r',alpha=0.75)\n    sns.kdeplot(df_No[i], label='0', color='b',alpha=0.75)\n    plt.title(i)","89702aa0":"#Distribution for Target 1 along axis 1\ndf_Y=pd.DataFrame(Yes.mean(axis=1),columns=[\"Mean\"])\ndf_Y['Min']=Yes.min(axis=1)\ndf_Y['Max']=Yes.max(axis=1)\ndf_Y['Std']=Yes.std(axis=1)\ndf_Y['Sum']=Yes.sum(axis=1)\ndf_Y['Skew']=Yes.skew(axis=1)\ndf_Y['Kurt']=Yes.kurt(axis=1)\ndf_Y['Var_name']=df_Y.index\ndf_Y = df_Y.reset_index(drop=True)\n\n#Distribution for Target 0 along axis 1\ndf_N=pd.DataFrame(No.mean(axis=1),columns=[\"Mean\"])\ndf_N['Min']=No.min(axis=1)\ndf_N['Max']=No.max(axis=1)\ndf_N['Std']=No.std(axis=1)\ndf_N['Sum']=No.sum(axis=1)\ndf_N['Skew']=No.skew(axis=1)\ndf_N['Kurt']=No.kurt(axis=1)\ndf_N['Var_name']=df_N.index\ndf_N = df_N.reset_index(drop=True)","62694e99":"var2=df_N.columns[:-1]\nsns.set_style('whitegrid')\nplt.figure()\nfig, ax = plt.subplots(4,2,figsize=(10,10))\nj=0\nfor i in var2:\n    j+=1\n    plt.subplot(4,2,j)\n    sns.kdeplot(df_Y[i], label='1', color='r',alpha=0.75)\n    sns.kdeplot(df_N[i], label='0', color='b',alpha=0.75)\n    plt.title(i)","ba39a53d":"plt.subplots(4,2,figsize=(20,15))\nplt.subplot(4,2,1)\ntrain_df1.std(axis=0).plot('hist')\nplt.title('Std')\nplt.subplot(4,2,2)\ntrain_df1.std(axis=1).plot('hist')\nplt.title('std')\n\nplt.subplot(4,2,3)\ntrain_df1.mean(axis=0).plot('hist')\nplt.title('Mean')\nplt.subplot(4,2,4)\ntrain_df1.mean(axis=1).plot('hist')\nplt.title('Mean')\n\nplt.subplot(4,2,5)\ntrain_df1.max(axis=0).plot('hist')\nplt.title('Max')\nplt.subplot(4,2,6)\ntrain_df1.max(axis=1).plot('hist')\nplt.title('Max')\n\nplt.subplot(4,2,7)\ntrain_df1.min(axis=0).plot('hist')\nplt.title('Min')\nplt.subplot(4,2,8)\ntrain_df1.min(axis=1).plot('hist')\nplt.title('Min')","b468ea50":"from xgboost import XGBClassifier\nxgb = XGBClassifier(learning_rate=0.02, n_estimators=10, objective='binary:logistic',silent=True)","fbfbb24a":"#XGBOOST Parameters\nparams = {\n        'min_child_weight': [12, 15, 20, 30, 40],\n        'gamma': [0.1, 0.2, 0.3],\n        'subsample': [0.5, 0.55, 0.6, 0.7],\n        'colsample_bytree': [0.5, 0.6, 0.7],\n        'max_depth': [4, 5, 7, 8],\n        'learning_rate': [0.01,0.02],\n        'n_estimators':[10,15],\n        'reg_alpha': [0,1],\n        'reg_lambda': [1,2]\n        }","ae367058":"from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, RepeatedStratifiedKFold","5982d433":"X = train_df.drop(['target'], axis=1)\ny = train_df['target']","c868c341":"X_fit, X_val, y_fit, y_val = train_test_split(X, y, test_size=0.2, stratify=y)","a6b48c02":"X_test=test_df.drop(\"ID_code\",axis=1)","5a5b3275":"X = train_df.drop(['ID_code','target'],axis=1)\ny = train_df['target']","b941ea57":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)","4620f654":"clf = XGBClassifier(objective = \"binary:logistic\",\n                    subsample= 0.5, \n                    reg_lambda= 1, \n                    reg_alpha= 0, \n                    n_estimators= 2500, \n                    min_child_weight=12, \n                    max_depth= 20, \n                    learning_rate= 0.02, \n                    gamma= 0.3,\n                    colsample_bytree= 0.5,\n                    eval_metric =\"auc\").fit(train_X, train_y)","1b1e16ce":"y_pred_xgb = clf.predict(X_test)","956e8bc1":"clf.get_booster().get_score(importance_type='gain')","f5cc36e6":"#DataFrame.from_dict(data, orient='columns', dtype=None)\nfeature_importance=pd.DataFrame.from_dict(clf.get_booster().get_score(importance_type='gain'), orient='index')\nfeature_importance['Var_name']=feature_importance.index\nfeature_importance = feature_importance.reset_index(drop=True)\nplt.figure(figsize=(20,30))\nsns.barplot(x=0, y=\"Var_name\", data=feature_importance.sort_values(by=0,ascending=False));","32928136":"submission_rfc = pd.DataFrame({\n        \"ID_code\": test_df[\"ID_code\"],\n        \"target\": y_pred_xgb\n    })\nsubmission_rfc.to_csv('submission_gxb1.csv', index=False)","5edf973f":"#Top 46 Feature selected on the basis of Gain\ntrain_df3=train_df[['ID_code','target','var_81', 'var_12', 'var_53', 'var_174','var_139', 'var_22', 'var_80', 'var_166', 'var_26', 'var_177', 'var_146', 'var_78', 'var_198', 'var_6', 'var_110', 'var_133', 'var_164', 'var_109', 'var_99', 'var_190', 'var_13', 'var_94', 'var_165','var_7', 'var_0', 'var_76', 'var_2', 'var_178', 'var_108', 'var_44', 'var_179', 'var_5', 'var_145', 'var_194', 'var_33', 'var_137','var_154','var_40', 'var_18', 'var_1', 'var_121', 'var_92', 'var_75', 'var_14', 'var_173', 'var_34', 'var_50', 'var_127']]","2757440c":"#Top 46 Feature selected on the basis of Gain\ntest_df3=test_df[['ID_code','var_81', 'var_12', 'var_53', 'var_174','var_139', 'var_22', 'var_80', 'var_166', 'var_26', 'var_177', 'var_146', 'var_78', 'var_198', 'var_6', 'var_110', 'var_133', 'var_164', 'var_109', 'var_99', 'var_190', 'var_13', 'var_94', 'var_165','var_7', 'var_0', 'var_76', 'var_2', 'var_178', 'var_108', 'var_44', 'var_179', 'var_5', 'var_145', 'var_194', 'var_33', 'var_137','var_154','var_40', 'var_18', 'var_1', 'var_121', 'var_92', 'var_75', 'var_14', 'var_173', 'var_34', 'var_50', 'var_127']]","3492b155":"X = train_df3.drop(['ID_code','target'],axis=1)\ny = train_df3['target']","0f270ee8":"#train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=42)\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)","f2fc3285":"clf = XGBClassifier(objective = \"binary:logistic\",\n                    subsample= 0.5, \n                    reg_lambda= 1, \n                    reg_alpha= 0, \n                    n_estimators= 2500, \n                    min_child_weight=12, \n                    max_depth= 10, \n                    learning_rate= 0.02, \n                    gamma= 0.3,\n                    colsample_bytree= 0.5,\n                    eval_metric =\"auc\").fit(train_X, train_y)","6ce96a6b":"predictions_train = clf.predict_proba(train_X)\npredictions_test = clf.predict_proba(val_X)\n\nprint('train',roc_auc_score(train_y, predictions_train[:,1]))\nprint('test',roc_auc_score(val_y, predictions_test[:,1]))","3d792e68":"X_test=test_df3.drop(\"ID_code\",axis=1)","f4f8a0d3":"Test_Prediction = clf.predict_proba(X_test)[:,1]","783076c7":"sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsub_df[\"target\"] = Test_Prediction\nsub_df.to_csv(\"submission_final1.csv\", index=False)","a817764a":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.5, gamma=0.3, learning_rate=0.02,\n       max_delta_step=0, max_depth=8, min_child_weight=12, missing=None,\n       n_estimators=15, n_jobs=1, nthread=None,\n       objective='binary:logistic', random_state=0, reg_alpha=0,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=0.55)","3721735f":"**In this challenge, Santander wants to identify which customers will makea specific transaction in the future, irrespective of the amount of money transacted.\n**\n\nProblem Statement\nSantander Customer Transaction Prediction\n\nCan you identify who will make a transaction?","c2d2adde":"**#Best Parameter**\n\n{'subsample': 0.55,\n 'reg_lambda': 1,\n 'reg_alpha': 0,\n 'n_estimators': 15,\n 'min_child_weight': 12,\n 'max_depth': 8,\n 'learning_rate': 0.02,\n 'gamma': 0.3,\n 'colsample_bytree': 0.5}","bc139d97":"#References & credits\nThanks to following kernels:-\n\n1)https:\/\/www.kaggle.com\/mjbahmani\/santander-ml-explainability\n\n2)https:\/\/www.kaggle.com\/gpreda\/santander-eda-and-prediction\n\n3)...."}}