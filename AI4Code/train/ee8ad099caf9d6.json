{"cell_type":{"e168c67f":"code","92b6fa36":"code","415bf996":"code","92125b67":"code","cd91283c":"code","0a807462":"code","27b75365":"code","71f39f0d":"code","53faa61f":"code","1ee12453":"code","f74d56b7":"code","a5b8c669":"code","25f24533":"code","1123b86d":"code","6a43aadd":"code","56b449de":"code","a6cf9c89":"code","cbaf05fa":"code","37ea1bcf":"code","b144de06":"code","bb6cb449":"code","4358e00e":"markdown","adfde4cf":"markdown","69e4be2e":"markdown","e957d403":"markdown","fc074230":"markdown"},"source":{"e168c67f":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.optimizers import RMSprop,SGD\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \ntf.logging.set_verbosity(tf.logging.ERROR)\n\n\n\n\n","92b6fa36":"dataset = pd.read_csv(\"..\/input\/A_Z Handwritten Data\/A_Z Handwritten Data.csv\").astype('float32')\ndataset.head() ","415bf996":"dataset.rename(columns={'0':'label'}, inplace=True)\n\n# Splite data the X - Our data , and y - the prdict label\n\nX = dataset.drop('label',axis = 1)\ny = dataset['label']","92125b67":"print(X.shape)\n\nprint(y.shape)","cd91283c":"from sklearn.utils import shuffle\n\nX_shuffle = shuffle(X)\n\nplt.figure(figsize = (10,10))\nrow, colums = 4, 4\nfor i in range(16):  \n    plt.subplot(colums, row, i+1)\n    plt.imshow(X_shuffle.iloc[i].values.reshape(28,28),interpolation='nearest', cmap='Blues')\nplt.show()","0a807462":"\n\n# Change label to alphabets\nalphabets_mapper = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'} \ndataset_alphabets = dataset.copy()\ndataset['label'] = dataset['label'].map(alphabets_mapper)\n\n\n\n\n","27b75365":"label_size = dataset.groupby('label').size()\nlabel_size.plot.barh(figsize=(12,10))\nplt.show()","71f39f0d":"# splite the data\nX_train, X_test, y_train, y_test = train_test_split(X,y)\n\n\n\n\n","53faa61f":"X_train.shape","1ee12453":"# scale data\nstandard_scaler = MinMaxScaler()\nX_train = standard_scaler.fit_transform(X_train)\nX_test = standard_scaler.transform(X_test)","f74d56b7":"print(\"Data after scaler\")\nX_shuffle = shuffle(X_train)\n\nplt.figure(figsize = (12,10))\nrow, colums = 4, 4\nfor i in range(16):  \n    plt.subplot(colums, row, i+1)\n    plt.imshow(X_shuffle[i].reshape(28,28),interpolation='nearest', cmap='Blues')\nplt.show()","a5b8c669":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n\n","25f24533":"X_train.shape","1123b86d":"y_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)","6a43aadd":"y_train.shape","56b449de":" model = Sequential()\n model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n model.add(MaxPooling2D((2, 2)))\n model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n model.add(MaxPooling2D((2, 2)))\n model.add(Flatten())\n model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n model.add(Dense(26, activation='softmax'))\n","a6cf9c89":"opt = SGD(lr=0.01, momentum=0.9)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","cbaf05fa":"history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)\n","37ea1bcf":"scores = model.evaluate(X_test,y_test, verbose=0)\nprint(\"CNN Score:\",scores[1])","b144de06":"fig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\n","bb6cb449":"cm=confusion_matrix(y_test.argmax(axis=1),model.predict(X_test).argmax(axis=1))\ndf_cm = pd.DataFrame(cm, range(26),\n                  range(26))\nplt.figure(figsize = (20,15))\nsns.heatmap(df_cm,annot=True)","4358e00e":"# Data preparation","adfde4cf":"# Build the model\n","69e4be2e":"look at the data images","e957d403":"# Explore","fc074230":"# Import librarys and data\n"}}