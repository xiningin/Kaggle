{"cell_type":{"fd5fbb68":"code","d4dc9a1d":"code","c34146fd":"code","f4ca8995":"code","bebfcb59":"code","4753bfe8":"code","7fec141d":"code","d9d52c7f":"code","9de70bd2":"code","92ef1f2c":"code","5a4b691a":"code","3100a865":"code","91b801aa":"code","afa54adc":"code","848fa1d2":"code","a97c8a53":"code","f36bd948":"code","3f1771d4":"code","46986fcc":"code","7adade5e":"code","156b8388":"code","f5e04b42":"code","0440266f":"code","76748990":"code","6862d9b0":"code","5dff58bf":"code","b49cd9ee":"code","295cd97d":"code","37fa9855":"code","6e05a76a":"code","48c9923a":"code","262b13f5":"code","9f6ae559":"code","27272796":"code","98d69bbb":"code","326bcb0c":"code","6a641556":"code","99876303":"code","64dc00da":"code","29d7d1bb":"code","89758c55":"markdown","fd36c9cc":"markdown","b856501a":"markdown","a4d5199f":"markdown","c01f8484":"markdown","c7c3e259":"markdown","6d04a991":"markdown","d67348a1":"markdown","d83dc3ed":"markdown","35b7f623":"markdown","70a8f87f":"markdown","40e79ffd":"markdown","42f64b00":"markdown"},"source":{"fd5fbb68":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4dc9a1d":"train= pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntrain.head()","c34146fd":"train.info()","f4ca8995":"train.isna().sum()","bebfcb59":"train.describe()","4753bfe8":"sns.countplot(train['Survived'])","7fec141d":"train['Age'].hist(width=5)","d9d52c7f":"col=[\"red\",\"yellow\",\"aqua\"]\nlbl = \"Cherbourg\",\"Queenstown\",\"South Hampton\"\nsizes = [sum(train['Embarked']=='C'),sum(train['Embarked']=='Q'),sum(train['Embarked']=='S')]\nplt.pie(sizes,labels=lbl,colors=col)","9de70bd2":"sns.countplot(train['Survived'],hue=train['Pclass'])\ntrain[['Pclass','Survived']].groupby('Pclass').mean()\n\n#Seeing the relation of Passenger Class on Survival\n#People who bought First Class Ticket are more likely to survive","92ef1f2c":"sns.countplot(train['Survived'],hue=train['Sex'])\ntrain[['Sex','Survived']].groupby('Sex').mean()\n\n#Females were more likeley to survive","5a4b691a":"g = sns.FacetGrid(train,col='Survived')\ng.map(plt.hist,'Age')","3100a865":"g=sns.FacetGrid(train,col='Pclass')\ng.map(plt.hist,\"Age\")","91b801aa":"sns.heatmap(train.corr(),annot=True)","afa54adc":"train.isna().sum()","848fa1d2":"train['Embarked'].value_counts()","a97c8a53":"#Since Embarked has only Two Missing Values. I will fill it by S ie Majority\ntrain[\"Embarked\"]=train[\"Embarked\"].fillna(\"S\")\ntest[\"Embarked\"]=test[\"Embarked\"].fillna(\"S\")","f36bd948":"train[\"Cabin\"]=train[\"Cabin\"].fillna(\"U\")\ntest[\"Cabin\"]=test[\"Cabin\"].fillna(\"U\")\ntrain[\"Cabin\"]=train[\"Cabin\"].map(lambda x: x[0])\ntest[\"Cabin\"]=test[\"Cabin\"].map(lambda x: x[0])","3f1771d4":"cab = pd.get_dummies(train[\"Cabin\"],drop_first = True)\ntrain = pd.concat([train,cab],axis=1)","46986fcc":"cab = pd.get_dummies(test[\"Cabin\"],drop_first = True)\ntest = pd.concat([test,cab],axis=1)","7adade5e":"final_emb = pd.get_dummies(test[\"Embarked\"],drop_first = True)\ntest = pd.concat([test,final_emb],axis=1)\nfinal_emb = pd.get_dummies(train[\"Embarked\"],drop_first = True)\ntrain = pd.concat([train,final_emb],axis=1)","156b8388":"test[\"Fare\"] = test[\"Fare\"].fillna(np.mean(test[\"Fare\"]))","f5e04b42":"#Dividing each Pclass category based no. of SibSp and their respective Age Median\n#So as to fill missing age values as it has max correlation with Pclass and SibSp\ntrain_set_1_median = train[['Pclass','SibSp','Age']].groupby(['Pclass','SibSp']).median()\ntest_set_1_median = train[['Pclass','SibSp','Age']].groupby(['Pclass','SibSp']).median()","0440266f":"test_set_1_median","76748990":"def fillage(dataset,dataset_median):\n    for x in range (len(dataset)):\n        if dataset[\"Pclass\"][x]==1:\n            if dataset[\"SibSp\"][x]==0:\n                return dataset_median.iloc[0,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==1:\n                return dataset_median.iloc[1,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==2:\n                  return dataset.set_median.iloc[2,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==3:\n                return dataset_median.iloc[3,:][\"Age\"]\n        if dataset[\"Pclass\"][x]==2:\n            if dataset[\"SibSp\"][x]==0:\n                return dataset_median.iloc[4,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==1:\n                return dataset_median.iloc[5,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==2:\n                return dataset_median.iloc[6,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==3:\n                return dataset_median.iloc[7,:][\"Age\"]    \n        if dataset[\"Pclass\"][x]==3:\n            if dataset[\"SibSp\"][x]==0:\n                return dataset_median.iloc[8,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==1:\n                return dataset_median.iloc[9,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==2:\n                return dataset_median.iloc[10,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==3:\n                return dataset_median.iloc[11,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==4:\n                return dataset_median.iloc[12,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==5:\n                return dataset_median.iloc[13,:][\"Age\"]\n            elif dataset[\"SibSp\"][x]==8:\n                return dataset_median.iloc[8:13,:].median()\n                    \n                ","6862d9b0":"train['Age']=train['Age'].fillna(fillage(train,train_set_1_median))\ntest['Age']=test['Age'].fillna(fillage(test,test_set_1_median))","5dff58bf":"train.isna().sum()","b49cd9ee":"\ntrain['Title'] = train['Name'].map(lambda x:x.split(\".\")[0].split(\",\")[1].strip())\ntest['Title'] = test['Name'].map(lambda x:x.split(\".\")[0].split(\",\")[1].strip())","295cd97d":"train['Title'].unique()","37fa9855":"tits_map = {\"Mr\":1,\"Mrs\":2,\"Miss\":3,\"Master\":4,\"Don\":5,\"Rev\":5,\"Dr\":6,\"Mme\":2,\"Ms\":3,\"Major\":6,\"Lady\":2,\"Sir\":1,\"Mlle\":3,\"Col\":6,\"Capt\":6,\"the Countess\":5,\"Jonkheer\":5,\"Dona\":5 }","6e05a76a":"train['Title']=train['Title'].map(tits_map)\ntest['Title']=test['Title'].map(tits_map)","48c9923a":"sex_map={\"male\":0,\"female\":1}","262b13f5":"train['Sex']=train['Sex'].map(sex_map)\ntest['Sex']=test['Sex'].map(sex_map)","9f6ae559":"train['Family_Size']=train['SibSp']+train['Parch']+1\ntest['Family_Size']=test['SibSp']+test['Parch']+1","27272796":"train = train.drop(['Name','Ticket','Cabin','T','Embarked'],axis=1)","98d69bbb":"test = test.drop(['Name','Ticket','Cabin','Embarked'],axis=1)","326bcb0c":"test.shape","6a641556":"X_train = train.iloc[:,2:]\nX_test = test.iloc[:,1:]\ny_train = train.iloc[:,1]","99876303":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.linear_model import LogisticRegression\n","64dc00da":"lr = LogisticRegression()\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)","29d7d1bb":"my_submission = pd.DataFrame({'PassngerId': test.PassengerId, 'Survived': y_pred})\nmy_submission.to_csv('submission.csv', index=False)","89758c55":"**Correlation of all the Features with each other**","fd36c9cc":"**Cabins location can be an important factor when it comes to Rescuing those onboard. Therefore Missing Values are being assigned Unknown 'U' becuase we cannot assign it randomly **","b856501a":"**Dividing into Training and Test DataSet**","a4d5199f":"**All the Missing Values have been Adequately Filled**","c01f8484":"**Dropping out the Old Categorical Features**","c7c3e259":"**FEATURE ENGINEERING (Dropping the Missing Values and derriving important features from the existing one's**","6d04a991":"**Reading the DataSet**","d67348a1":".\/submission.csv is the final submission","d83dc3ed":"**EXPLORATORY DATA ANALYSIS**","35b7f623":"sns.countplot(train['Pclass'])","70a8f87f":"**Encoding the Title and Sex Feature. So that we can convert them from Categorical to Numeric**","40e79ffd":"**Extracting the title out of the Name. So that it can be included in our DataSet for an in - deapth Analysis**","42f64b00":"* **Making the Model based on Logistic Regression and KNearestNeighbors.**\n* **Evaluating the Model using Confusion Matrix and Accuracy Score**\n    "}}