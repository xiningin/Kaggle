{"cell_type":{"cba2a296":"code","0c7fc24c":"code","81b3cb71":"code","e7fc8318":"code","20e2f3d5":"code","3567ffb3":"code","6e4aecb9":"code","64545e43":"code","c80db0e1":"code","1476b379":"code","53f0b268":"code","48ef9ca2":"code","4d15ccc7":"code","cbef9ab5":"code","a202cbd8":"code","0c16f3cd":"code","9ff562cc":"code","c61cbd1a":"code","e06d2a65":"code","8083a1e4":"code","b80759fb":"code","70e36431":"markdown","f9ba5c0f":"markdown","af04cdb1":"markdown","dd40f8f0":"markdown","0be1175f":"markdown","5315b88c":"markdown"},"source":{"cba2a296":"import datetime\nimport random \nimport time \nimport pandas as pd \nimport numpy as np\nfrom scipy import signal\nfrom scipy.signal import find_peaks, resample\nimport matplotlib.pyplot as plt \nimport os \nimport sys\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\nprint('Packages Loaded')","0c7fc24c":"data_dir = '..\/input\/ai-medical-contest-2021'\ntrain_path = f'{data_dir}\/train.csv'\ntest_path = f'{data_dir}\/test.csv'\n\ncol_target = 'target'\ncol_index = 'Id' \ncol_features = ['age', 'sex', 'label_type']\n\nSEED = 42\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","81b3cb71":"df_train = pd.read_csv(train_path)\nprint(\"df_train.shape\", df_train.shape) \ndf_train.head() ","e7fc8318":"df_test = pd.read_csv(test_path)\nprint(\"df_test.shape\", df_test.shape) \ndf_test.head() ","20e2f3d5":"df_traintest = pd.concat([df_train, df_test]).reset_index(drop=True)\ndf_traintest['path'] = df_traintest['Id'].apply(lambda x: f\"{data_dir}\/ecg\/{x}.npy\")\nprint(df_traintest['path'][0]) \ndf_traintest.head()","3567ffb3":"df_traintest['sex'] = df_traintest['sex'].replace('female', 0) \ndf_traintest['sex'] = df_traintest['sex'].replace('male', 1) \ndf_traintest['sex'] = df_traintest['sex'].astype(int) \n\ndf_traintest['label_type'] = df_traintest['label_type'].replace('human', 0) \ndf_traintest['label_type'] = df_traintest['label_type'].replace('auto', 1) \ndf_traintest['label_type'] = df_traintest['label_type'].astype(int) \ndf_traintest.head()\ndf_traintest['sex'] = df_traintest['sex'].replace('female', 0)\ndf_traintest['sex'] = df_traintest['sex'].replace('male', 1) \ndf_traintest['sex'] = df_traintest['sex'].astype(int) \n\ndf_traintest['label_type'] = df_traintest['label_type'].replace('human', 0) \ndf_traintest['label_type'] = df_traintest['label_type'].replace('auto', 1) \ndf_traintest['label_type'] = df_traintest['label_type'].astype(int) \n\ndf_traintest['age'] = (df_traintest['age'] - df_traintest['age'].min()) \/ (df_traintest['age'].max() - df_traintest['age'].min())\ndf_traintest.head()","6e4aecb9":"df_train = df_traintest.iloc[:len(df_train)]\ndf_test = df_traintest.iloc[len(df_train):].reset_index(drop=True)\nprint(df_train.shape, df_test.shape)","64545e43":"ecg_train = np.zeros([len(df_train), 800, 12], np.float32) \nfor i in range(len(df_train)): \n    path_tmp = df_train['path'][i] \n    ecg_tmp = np.load(path_tmp) \n    ecg_train[i] = ecg_tmp \n\necg_test = np.zeros([len(df_test), 800, 12], np.float32) \nfor i in range(len(df_test)): \n    path_tmp = df_test['path'][i] \n    ecg_tmp = np.load(path_tmp) \n    ecg_test[i] = ecg_tmp \n\necg_train = ecg_train.transpose(0, 2, 1)\necg_test = ecg_test.transpose(0, 2, 1)\nprint(\"ecg_train.shape: {}\".format(ecg_train.shape))\nprint(\"ecg_test.shape: {}\".format(ecg_test.shape))","c80db0e1":"target_train = df_train[col_target].values.astype(np.float32)\nprint(\"target_train.shape: {}\".format(target_train.shape))","1476b379":"def stretch(x, l):\n    y = resample(x, l)\n    if l < 800:\n        y_ = np.zeros(shape=(800, ))\n        y_[:l] = y\n    else:\n        y_ = y[:800]\n    return y_\n\ndef amplify(x, alpha):\n    factor = -alpha*x + (1+alpha)\n    return x*factor\n\ndef stretch_twelve(ecg):\n    l = int(800 * (1 + (random.random()-0.5)\/3))\n    *y_, = map(stretch, ecg, [l] * 12)\n    return np.array(y_, dtype=np.float32)\n\ndef amplify_twelve(ecg):\n    alpha = (random.random()-0.5)\n    *y_, = map(amplify, ecg, [alpha] * 12)\n    return np.array(y_, dtype=np.float32)","53f0b268":"def get_train_transforms():\n    return transforms.Compose([\n        transforms.Lambda(amplify_twelve),\n        transforms.Lambda(stretch_twelve),\n        transforms.ToTensor(),\n    ])\ndef get_valid_transforms():\n    return transforms.Compose([\n        transforms.ToTensor(),\n    ])","48ef9ca2":"class ECGDataset(Dataset):\n    def __init__(self, X, X_add=None, y=None, train=True, transforms=None):\n        super().__init__()\n        self.X = X\n        self.X_add = X_add\n        self.y = y\n        self.train = train\n        self.transforms = transforms\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, index):\n        X_trans = self.transforms(self.X[index])[0]\n        if self.X_add is not None:\n            X_add = torch.tensor(self.X_add[index], dtype=torch.float)\n        else:\n            X_add = None\n        if self.train == True:\n            return X_trans, X_add, torch.tensor(self.y[index], dtype=torch.float)\n        else:\n            return X_trans, X_add","4d15ccc7":"class Anomaly_Classifier(nn.Module):\n    def __init__(self, input_size,num_classes):\n        super(Anomaly_Classifier, self).__init__()\n    \n        self.conv= nn.Conv1d(in_channels=input_size, out_channels=32, kernel_size=5,stride=1)\n        \n        self.conv_pad = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5,stride=1,padding=2)\n        self.drop_50 = nn.Dropout(p=0.5)\n\n        self.maxpool = nn.MaxPool1d(kernel_size=5,stride=2) \n\n        self.dense1 = nn.Linear(32 * 46, 32) \n        self.dense1_add = nn.Linear(32 * 46 + len(col_features), 32) \n        self.dense2 = nn.Linear(32, 32) \n        \n        self.dense_final = nn.Linear(32, num_classes)\n\n    def forward(self, x, x_add=None):\n        residual= self.conv(x)\n      \n        #block1 \n        x = F.relu(self.conv_pad(residual))\n        x = self.conv_pad(x)\n        x+= residual \n        x = F.relu(x)\n        residual = self.maxpool(x) \n       \n        #block2\n        x=F.relu(self.conv_pad(residual))\n        x=self.conv_pad(x)\n        x+=residual\n        x= F.relu(x)\n        residual = self.maxpool(x) \n        \n        #block3\n        x=F.relu(self.conv_pad(residual))\n        x=self.conv_pad(x)\n        x+=residual\n        x= F.relu(x)\n        residual = self.maxpool(x) \n        \n        \n        #block4\n        x=F.relu(self.conv_pad(residual))\n        x=self.conv_pad(x)\n        x+=residual\n        x= F.relu(x)\n        x= self.maxpool(x) \n        \n        #MLP\n        x = x.view(-1, 32 * 46) \n        if x_add is not None:\n            x = torch.cat([x, x_add], axis=1)\n            x = F.relu(self.dense1_add(x))\n        else:\n            x = F.relu(self.dense1(x))\n        x= self.dense2(x)\n        x = self.dense_final(x)\n        return x","cbef9ab5":"def run_one_fold(train_X, train_y, valid_X, valid_y, num_fold, train_X_add=None, valid_X_add = None):\n    train_dataset = ECGDataset(train_X, train_X_add, train_y, transforms=get_train_transforms())\n    valid_dataset = ECGDataset(valid_X, valid_X_add, valid_y, transforms=get_valid_transforms())\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=DataLoaderConfig.batch_size,\n        shuffle=True,\n        num_workers=DataLoaderConfig.num_workers,\n    )\n    valid_loader = DataLoader(\n        valid_dataset, \n        batch_size=DataLoaderConfig.batch_size,\n        shuffle=False,\n        num_workers=DataLoaderConfig.num_workers,\n    )\n\n    fitter = Fitter(\n        model=net, \n        device=DEVICE, \n        criterion=TrainConfig.criterion, \n        n_epochs=TrainConfig.n_epochs, \n        lr=TrainConfig.lr, \n        sheduler=TrainConfig.scheduler, \n        scheduler_params=TrainConfig.scheduler_params\n    )\n    fitter.fit(train_loader, valid_loader, num_fold=num_fold)","a202cbd8":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n        \nclass AccMeter:\n    def __init__(self):\n        self.y_preds = []\n        self.y_trues = []\n        \n    def update(self, y_true, y_pred):\n        self.y_preds += list(y_pred.sigmoid().cpu().numpy().ravel())\n        self.y_trues += list(y_true.cpu().numpy().ravel())\n    \n    def auc(self):\n        if len(self.y_preds) == 0 or len(self.y_trues) == 0:\n            return 0\n        else:\n            return roc_auc_score(self.y_trues, self.y_preds)","0c16f3cd":"class Fitter:\n    def __init__(\n        self, model, device, criterion, n_epochs, \n        lr, sheduler=None, scheduler_params=None\n    ):\n        self.epoch = 0\n        self.n_epochs = n_epochs\n        self.base_dir = '.\/'\n        self.log_path = f'{self.base_dir}\/log.txt'\n        self.best_summary_loss = np.inf\n\n        self.model = model\n        self.device = device\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-5)\n        \n        if sheduler:\n            self.scheduler = sheduler(self.optimizer, **scheduler_params)\n            \n        self.criterion = criterion().to(self.device)\n        \n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, valid_loader, num_fold=0):\n        for e in range(self.n_epochs):\n            current_lr = self.optimizer.param_groups[0]['lr']\n            self.log(f'\\n{datetime.datetime.utcnow().isoformat()}\\nLR: {current_lr}')\n\n            t = int(time.time())\n            summary_loss, final_scores = self.train_one_epoch(train_loader)\n            self.log(\n                f'[RESULT]: Train. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.auc():.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n\n            t = int(time.time())\n            summary_loss, final_scores = self.validation(valid_loader)\n            self.log(\n                f'[RESULT]: Valid. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.auc():.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n            \n            f_best = 0\n            if summary_loss.avg < self.best_summary_loss:\n                self.best_summary_loss = summary_loss.avg\n                f_best = 1\n\n            \n            self.scheduler.step(metrics=summary_loss.avg)\n                \n            self.save(f'{self.base_dir}\/last-checkpoint-{num_fold}.bin')\n            \n            if f_best:\n                self.save(f'{self.base_dir}\/best-checkpoint-{num_fold}.bin')\n                print('New best checkpoint')\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n\n        t = int(time.time())\n        for step, (images, add_feat, labels) in enumerate(val_loader):\n            with torch.no_grad():\n                labels = labels.unsqueeze(1).to(self.device)\n                images = images.to(self.device)\n                if add_feat is not None:\n                    add_feat = add_feat.to(self.device)\n                batch_size = images.shape[0]\n                \n                outputs = self.model(images, add_feat)\n                loss = self.criterion(outputs, labels)\n                \n                final_scores.update(labels, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n        return summary_loss, final_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, add_feat, labels) in enumerate(train_loader):\n            labels = labels.unsqueeze(1).to(self.device)\n            images = images.to(self.device)\n            if add_feat is not None:\n                add_feat = add_feat.to(self.device)\n            batch_size = images.shape[0]\n\n            self.optimizer.zero_grad()\n            outputs = self.model(images, add_feat)\n\n            loss = self.criterion(outputs, labels)\n            loss.backward()\n\n            final_scores.update(labels.detach(), outputs.detach())\n            summary_loss.update(loss.detach().item(), batch_size)\n            \n            self.optimizer.step()\n\n        return summary_loss, final_scores\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_summary_loss': self.best_summary_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_summary_loss = checkpoint['best_summary_loss']\n        self.epoch = checkpoint['epoch'] + 1\n        \n    def log(self, message):\n        print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')\n\ndef run_inference(test_X, num_fold, test_X_add=None):\n\n    test_dataset = ECGDataset(\n        X = test_X,\n        X_add = test_X_add,\n        transforms=get_valid_transforms(),\n        train=False\n    )\n\n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=DataLoaderConfig.batch_size,\n        shuffle=False,\n        num_workers=DataLoaderConfig.num_workers\n    )\n\n    checkpoint = torch.load(f'.\/best-checkpoint-{num_fold}.bin')\n    net.load_state_dict(checkpoint['model_state_dict'])\n    net.eval()\n    print(\"model loaded\")\n\n    result = []\n    for step, (images, add_feat) in enumerate(test_loader):\n        print(step, end='\\r')\n        if add_feat is not None:\n            add_feat = add_feat.to(DEVICE)\n        y_pred = net(images.to(DEVICE), add_feat).detach().sigmoid().cpu().numpy().ravel()\n        result.extend(y_pred)\n    return np.array(result)","9ff562cc":"class DataLoaderConfig:\n    batch_size = 32\n    num_workers = 8\n\nclass TrainConfig:\n    criterion = nn.BCEWithLogitsLoss\n    n_epochs = 15\n    n_splits = 10\n    lr = 0.001\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n    # scheduler = torch.optim.lr_scheduler.StepLR\n    scheduler_params = dict(\n        mode='min',\n        factor=0.5,\n        patience=2,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","c61cbd1a":"seed_everything(SEED)\n\nskf = StratifiedKFold(n_splits=TrainConfig.n_splits)\ny_preds = np.zeros(len(df_train), np.float32)\ny_trues = np.zeros(len(df_train), np.float32)\nfor fold, (train_index, valid_index) in enumerate(skf.split(np.arange(len(df_train)), y=df_train[col_target])):\n    train_X, train_X_add, train_y, valid_X, valid_X_add, valid_y = ecg_train[train_index], df_train.iloc[train_index][col_features].values, target_train[train_index], ecg_train[valid_index], df_train.iloc[valid_index][col_features].values, target_train[valid_index]\n    print('-'*30)\n    print(f'fold: {fold}')\n    net = Anomaly_Classifier(input_size=12, num_classes=1).to(DEVICE)\n    run_one_fold(train_X, train_y, valid_X, valid_y, fold, train_X_add=train_X_add, valid_X_add=valid_X_add)\n\n    y_pred = run_inference(valid_X, fold, test_X_add=valid_X_add)\n    y_preds[valid_index] = y_pred\n    y_trues[valid_index] = valid_y\n\ncv = roc_auc_score(y_trues, y_preds)\nprint(f'AUC CV: {cv}')","e06d2a65":"y_preds_test = []\nfor fold in range(TrainConfig.n_splits):\n    y_pred = run_inference(ecg_test, fold, test_X_add=df_test[col_features].values)\n    y_preds_test += [y_pred]\ny_preds_test_mean = np.array(y_preds_test).mean(axis=0)","8083a1e4":"df_sub = pd.read_csv(f'{data_dir}\/sample_submission.csv')\ndf_sub['target'] = y_preds_test_mean\ndf_sub.to_csv(\"submission.csv\", index=None) \ndf_sub.head()","b80759fb":"# !kaggle competitions submit -c ai-medical-contest-2021 -f submission.csv -m \"basline+DA+feature\"","70e36431":"# train","f9ba5c0f":"# Dataset","af04cdb1":"# DA","dd40f8f0":"# model","0be1175f":"# submit","5315b88c":"# \u524d\u51e6\u7406"}}