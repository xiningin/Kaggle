{"cell_type":{"5859b7c0":"code","0336b162":"code","45f9a5e0":"code","05e5ed75":"code","da581a9d":"code","0344cca9":"code","e196b3c3":"code","415e6496":"code","82c0a3c9":"code","b1e44a35":"code","b7aabac9":"code","5addf92d":"code","82465e92":"code","ddc836d8":"code","68245407":"code","0aa77307":"code","fce05fbc":"code","98cee969":"code","415e7efb":"code","d0aa0a36":"code","c7082959":"code","b923b3e0":"code","fc37a779":"code","e366c037":"code","d246667d":"code","b34fe921":"code","2f2f19ab":"code","12947ae5":"code","b3c6d8a1":"code","2d250f35":"code","bfc37f0f":"code","d9b1f701":"code","0b0c27d1":"code","4c026c9f":"code","ef6e3fb2":"markdown","5e926169":"markdown","e4b44871":"markdown","cdb85ec8":"markdown","405ca86e":"markdown","0ae86aaa":"markdown","38840e8d":"markdown","733b6bf8":"markdown","cc5f04a2":"markdown","5b9e7a6e":"markdown","805b01ab":"markdown","39b4b27f":"markdown","af41fef1":"markdown","5c133852":"markdown","a75d7b25":"markdown","8e4337b8":"markdown","8dcfefac":"markdown","a74751f7":"markdown"},"source":{"5859b7c0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0336b162":"train_df = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-1\/test.csv')","45f9a5e0":"print('Missing Data in training dataset:', end = '\\n')\nprint(train_df.isnull().sum(), '\\n')\nprint(\"*\" * 40)\nprint('Missing Data in testing dataset:', end = '\\n' )\nprint(test_df.isnull().sum())","05e5ed75":"train_df.info()","da581a9d":"test_df.info()","0344cca9":"test_df.head(9)","e196b3c3":"train_df = train_df.loc[train_df['HHS Region']=='United States']\ntrain_df = train_df.loc[train_df['Group'] == 'By Week']\ntest_df = test_df.loc[test_df['HHS Region']=='United States']\ntest_df = test_df.loc[test_df['Group'] == 'By Week']","415e6496":"ax = sns.catplot(y='Race and Hispanic Origin Group', x='COVID-19 Deaths', data=train_df, height=5,aspect=2)\n#plt.xticks(rotation=90, horizontalalignment='right', fontweight='light', fontsize='small')\nplt.show()","82c0a3c9":"ax = sns.catplot(y='Age Group', x='COVID-19 Deaths', data=train_df, height=5,aspect=2)\n#plt.xticks(rotation=90, horizontalalignment='right', fontweight='light', fontsize='small')\nplt.show()","b1e44a35":"def data_prep(df):\n    # Convert to datetime datatype\n    pd.to_datetime(df['Start Date'])\n    \n    # filling missing values month\n    df['Month'] =  pd.DatetimeIndex(df['Start Date']).month\n   \n    # Dropping unneeded columns!\n    df = df.drop(columns = ['Data As Of','End Date', 'Group','Year','Week-Ending Date', 'HHS Region','Year','Total Deaths'])\n    \n    # mapping for One-Hot Encoding\n    age_mapping = {'0-4 years':'0-4','5-17 years':'5-17','18-29 years':'18-29','30-39 years':'30-39','40-49 years':'40-49','50-64 years':'50-64','65-74 years':'65-74','75-84 years':'75-84', '85 years or older':'85+'}\n    age = pd.get_dummies(df['Age Group'].map(age_mapping))\n    race = pd.get_dummies(df['Race and Hispanic Origin Group'])\n    df = df.join(race)\n    df = df.join(age)\n    \n    # Assigning indices for each week.\n    #df['Start Date'] = df.groupby('Start Date').ngroup()\n    df['Start Date'] = (df['id']\/72).astype(int)\n    #df = df.drop(columns = ['Start Date'])\n    df = df.drop(columns = ['Age Group','Race and Hispanic Origin Group'])\n    return df\n\n# prepping the data\ntrain_df = data_prep(train_df)\ntest_df = data_prep(test_df)\n\n# Add column to test_df for COVID-19 Deaths\ntest_df['COVID-19 Deaths'] = ''\n\ntrain_df = train_df.drop(columns=['Footnote'])\n","b7aabac9":"plt.figure(figsize=(8,5))\nplt.plot(train_df['COVID-19 Deaths'])\nplt.xlabel('id')\nplt.ylabel('Deaths')\nplt.show()","5addf92d":"train_df['COVID-19 Deaths'].describe()","82465e92":"#train_df = train_df.loc[train_df[\"Start Date\"]]","ddc836d8":"train_df","68245407":"# setting a ceiling for outlier values.\ntrain_df[\"COVID-19 Deaths\"] = train_df[\"COVID-19 Deaths\"].clip(upper = 950)","0aa77307":"beg_of_may = 18\ntrain_df = train_df.loc[train_df[\"Start Date\"] >= beg_of_may]","fce05fbc":"plt.figure(figsize=(8,5))\nplt.plot(train_df['Start Date'],train_df['COVID-19 Deaths'])\nplt.xlabel('Week')\nplt.ylabel('Deaths')\nplt.show()","98cee969":"pd.options.display.max_columns = None\ntest_df","415e7efb":"from sklearn.model_selection import TimeSeriesSplit\nX = train_df.drop(columns=['id','COVID-19 Deaths','Start Date','MMWR Week'],axis=1)\nX_test_df = test_df.drop(columns=['id','COVID-19 Deaths','Start Date','MMWR Week'],axis=1)\ny = train_df['COVID-19 Deaths']\ntscv = TimeSeriesSplit(n_splits=100,max_train_size=None)","d0aa0a36":"X","c7082959":"X_test_df","b923b3e0":"y","fc37a779":"from sklearn.metrics import mean_squared_error\ndef train_model(model):\n    rmse = []\n    scores_list = []\n    for train_index, test_index in tscv.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        model = model.fit(X_train,y_train)\n        model_pred = model.predict(X_test)\n        rmse.append(mean_squared_error(y_test,model_pred) ** (1\/2))\n        scores_list.append(model.score(X_train,y_train))\n    return rmse,scores_list","e366c037":"from sklearn.linear_model import LinearRegression\n\nols = LinearRegression()\nols_rmse_scores,ols_scores_list = train_model(ols)\nprint('RMSE:', np.mean(ols_rmse_scores))\nprint(pd.Series(ols_rmse_scores).describe())\nprint(pd.Series(ols_scores_list).describe())","d246667d":"sns.displot(ols_rmse_scores)","b34fe921":"from sklearn.linear_model import Ridge\n\nridge = Ridge(alpha=.01)\nridge_rmse_scores, ridge_scores_list = train_model(ridge)\nprint('RMSE:', np.mean(ridge_rmse_scores))\nprint(pd.Series(ridge_rmse_scores).describe())\nprint(pd.Series(ridge_scores_list).describe())","2f2f19ab":"sns.displot(ridge_rmse_scores)","12947ae5":"from sklearn.linear_model import Lasso\n\nlasso = Lasso()\nlasso_rmse_scores, lasso_scores_list = train_model(lasso)\nprint('RMSE:', np.mean(lasso_rmse_scores))\nprint(pd.Series(lasso_rmse_scores).describe())\nprint(pd.Series(lasso_scores_list).describe())","b3c6d8a1":"sns.displot(lasso_rmse_scores)","2d250f35":"from sklearn.linear_model import ElasticNet\n\nelastic = ElasticNet()\nelastic_rmse_scores, elastic_scores_list = train_model(elastic)\nprint('RMSE:', np.mean(elastic_rmse_scores))\nprint(pd.Series(elastic_rmse_scores).describe())\nprint(pd.Series(elastic_scores_list).describe())","bfc37f0f":"sns.displot(elastic_rmse_scores)","d9b1f701":"predict = ridge.predict(X_test_df)\npredict[predict < 0] = 0\npredict[predict < 10] = 10\noutput = pd.DataFrame({'id': test_df['id'], 'COVID-19 Deaths': predict})\nprint(output.to_string())\noutput.to_csv('submission.csv',index=False)\nprint(\"Your submission was successfully saved!\")","0b0c27d1":"test_df['COVID-19 Deaths'] = output['COVID-19 Deaths']\n\nplt.figure(figsize=(8,5))\nplt.plot(test_df['COVID-19 Deaths'] )\nplt.xlabel('id')\nplt.ylabel('Deaths')\nplt.show()\ntest_df","4c026c9f":"plt.figure(figsize=(8,5))\nplt.plot(train_df['id'],train_df['COVID-19 Deaths'])\nplt.plot(test_df['id'],test_df['COVID-19 Deaths'])\nplt.xlabel('id')\nplt.ylabel('Deaths')\nplt.show()","ef6e3fb2":"### Ridge Regression\n","5e926169":"#### Building the submission file!","e4b44871":"##### start data in may","cdb85ec8":"#### More Data Visualization\n##### Here we plot the COVID-19 Deaths over the given weeks in the dataset.","405ca86e":"#### Data Clean-Up: data_prep()\n##### We see from above that there are alot of missing values. We also see the nature of the dataset. We can drop actually drop many of them. \n##### Important to note: There are 9 unique Age Groups, and 8 unique Race and Ethnic group categories. \n1. Dropping unneeded columns: 'Data As Of','End Date', 'Group','Year','Week-Ending Date', 'HHS Region','Year','Total Deaths'\n2. Mapping the age categories and race\/ethnicities categories for One Hot Encoding, giving us machine readable data.\n3. Setting a weekly index value to group weekly data together. \n4. Filling missing values!\n","0ae86aaa":"### Lasso Regression","38840e8d":"# CAP 4611 2021 Fall - Assignment 1\n##### The following data represents weekly COVID-19 death statistics from the CDC. These values are segmented up by HHS Region, age, and race.\n\n##### Our goal is to build a linear model that will predict the **weekly COVID 19 deaths** in the United States given a date, age bracket, and race.","733b6bf8":"#### Data Visualization: Race\/Ethnicities and Age Groups","cc5f04a2":"#### Outliers & Feature Enginneering\n##### The graph above shows the distributions of deaths per week. We see that for approximately the first 10 weeks(January-March), there were no COVID-19 Deaths in the United States. This holds true, knowing that COVID started impacting the US in early march. To refine our dataset we can drop outliers. \n1. We have early data (2019-early 2020) that will reads 0 COVID deaths.. this might affect the forecasting for the following winter - early spring season. It is not accurate since we know this wasn't the case for (2020- early 2021) ... testing out dropping data so we have a valid full year for our training set. MAY -> MAY\n2. We also have the fact that they're are weeks where the death counts are very high. In forecasting, these values could be outliers.","5b9e7a6e":"### Exponential Smoothing! [optional]","805b01ab":"### Elastic Net","39b4b27f":"### Starting the Data Clean up. \n1. Need to sort out the 'HHS Region' of the data. We only need the 'United States' data. We can drop the other HHS Regions,\n2. Need to sort out the 'Group' column. We really only need 'By Week' data. This gives us predictions for COVID19 Deaths for weekly increments. ","af41fef1":"## Loading the data from the testing and training files.\n\n##### Here we are accessing and loading the data from the 'CAP 4611 - 2021 Fall - Assignment1'","5c133852":"## Building and Training Models\n1. Ordinary Least Squares Model [required]\n2. Ridge Regression [required]\n3. Lasso Regression [required]\n4. Elastic Net Regression [required]\n5. Any traditional time series model (Exponential Smoothing, ARIMA, etc). [optional]\n\n#### We must select the best model that you've generated and use that model to predict the target vector for the test data. Output this target vector to the notebook as well as save it to your 'submission.csv' file.\n","a75d7b25":"#### hmmm","8e4337b8":"### Ordinary Least Squares Model","8dcfefac":"#### train_model(model) takes in a model and splits your data into training and testing sets, builds the model and returns the model scores.","a74751f7":"## Exploratory Data Analysis:\n##### In this section we will be doing data analysis to check for missing values, outliers, and neccesary feature transformations. \n\n##### **Columns:**\n1. COVID-19 Deaths: Total number of covid-19 related deaths.\n2. Total Deaths: Total number of deaths including deaths from COVID, pneumonia, and the flu.\n\n##### Data is ordered by Race\/Origin, age group, and then per week. "}}