{"cell_type":{"9d5a1f43":"code","732e6d8e":"code","5d1af6bd":"code","68417a9b":"code","3518fdc5":"code","a65d0904":"code","4e6ed5fa":"code","7eea3c36":"code","48259e4d":"code","4543e819":"code","c2c0f26b":"markdown","e907d991":"markdown","7d6e106a":"markdown"},"source":{"9d5a1f43":"import pandas as pd\nimport numpy as np\nimport glob, os\n","732e6d8e":"PATH = \"..\/input\/rsna-str-pulmonary-embolism-detection\/\"\n\ntrain_df = pd.read_csv(PATH + \"train.csv\")\ntest_df = pd.read_csv(PATH + \"test.csv\")\n\nTRAIN_PATH = PATH + \"train\/\"\nTEST_PATH = PATH + \"test\/\"\nsub = pd.read_csv(PATH + \"sample_submission.csv\")\ntrain_image_file_paths = glob.glob(TRAIN_PATH + '\/*\/*\/*.dcm')\ntest_image_file_paths = glob.glob(TEST_PATH + '\/*\/*\/*.dcm')\n\nprint(f'Train dataframe shape  :{train_df.shape}')\nprint(f'Test dataframe shape   :{test_df.shape}')\n\nprint(f'Number of train images : {len(train_image_file_paths)}')\nprint(f'Number of test images  : {len(test_image_file_paths)}')","5d1af6bd":"exam_level_features = ['negative_exam_for_pe', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1',\n                       'leftsided_pe',         'chronic_pe',        'rightsided_pe', \n                       'acute_and_chronic_pe', 'central_pe',        'indeterminate']","68417a9b":"sub.info()","3518fdc5":"from tqdm.notebook import tqdm\nprediction_counts = {}\nfor idx in tqdm(range(sub.shape[0])):\n    if len(sub['id'][idx][13:]) > 1:\n        key = sub['id'][idx][13:]\n    else:\n        key = 'pe_present_on_image'\n    prediction_counts[key] = prediction_counts.get(key, 0) + 1\nprint(f'Total row count in submission: {sub.shape[0]}')\nprediction_counts","a65d0904":"N_img = len(test_image_file_paths)\nN_exams = len(os.listdir(TEST_PATH))\nN_exam_level_features = len(exam_level_features)\n\ntotal_rows_submission = N_img + (N_exams * N_exam_level_features)\nprint(f'Total row count in submission: {total_rows_submission}')","4e6ed5fa":"StudyInstanceUIDs = os.listdir(TEST_PATH)\nSOPInstanceUIDs = [filename[-16:-4] for filename in test_image_file_paths]\n\nsubmission_rows = []\n\nfor exam_level_feature in exam_level_features:\n    for StudyInstanceUID in StudyInstanceUIDs:\n        submission_rows.append(StudyInstanceUID+'_'+exam_level_feature)\n\nsubmission_rows = submission_rows + SOPInstanceUIDs \nprint(f'Total row count in submission: {len(submission_rows)}')","7eea3c36":"len(submission_rows)","48259e4d":"submission_file = pd.DataFrame({'id': submission_rows, 'label': (np.zeros(len(submission_rows))+0.35)})","4543e819":"submission_file.head()\nsubmission_file.to_csv('submission.csv', index = False)","c2c0f26b":"This is just a demo submission to understand the format of the submission. This has nothing to do with the actual submission. If you think that this clarifies your doubt regarding sample submission, have a look at this notebook,I hope you will understand this. ","e907d991":"## Submission size calculation for correctness: \n\nHere among the labels given in the training data, `pe_present_on_image` is the image level feature that needs to be predicted for all the images. \n\nAnd the rest of the features will be predicted for only the exam (the observation). In that case each exam will have multiple images. But for that whole group we will submit only one set of prediction for those following labels:\n \n * negative_exam_for_pe\n * rv_lv_ratio_gte_1\n * rv_lv_ratio_lt_1\n * leftsided_pe\n * chronic_pe\n * rightsided_pe\n * acute_and_chronic_pe\n * central_pe\n * indeterminate\n \nTherefore our prediction file should have a number of rows equal to: $$(N_{img}) + (N_{exams} * N_{examlevelfeature}).$$\n\nFor example, In the above calculation we have 650 examination and 146853 images in total. So the total number of rows in the submission file will ","7d6e106a":"Now let us have a look at the sample submission file so that we can understand what to predict from all the images. **"}}