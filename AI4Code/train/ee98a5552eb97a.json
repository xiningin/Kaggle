{"cell_type":{"d96bb090":"code","5f265d74":"code","3b929486":"code","9801e53d":"code","981b55f7":"code","0bfe8977":"code","b41d27af":"code","8644d5a7":"code","3b63aaad":"code","f8378ab5":"code","8ff3a6e2":"code","bf7cbafd":"code","72d8a2de":"code","3e2c9768":"code","4f1496e6":"code","df4778c2":"code","6bca0a8d":"code","6effd4f6":"markdown","78ccda81":"markdown","8f05a2d2":"markdown"},"source":{"d96bb090":"# Install fastai2 (note that soon fastai2 will be officially released as fastai)\n!pip install fastai2","5f265d74":"import numpy as np\nimport scipy.stats\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_pacf\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom IPython.core.debugger import set_trace\nfrom fastai2.vision.all import *","3b929486":"N  = 20000\n\nb   = 0.1\nc   = 0.2\ntau = 17\n\ny = [0.9697, 0.9699, 0.9794, 1.0003, 1.0319, 1.0703, 1.1076, 1.1352, 1.1485,\n     1.1482, 1.1383, 1.1234, 1.1072, 1.0928, 1.0820, 1.0756, 1.0739, 1.0759]\n\nfor n in range(17,N+99):\n    y.append(y[n] - b*y[n] + c*y[n-tau]\/(1+y[n-tau]**10))\ny = y[100:]","9801e53d":"plt.figure(figsize=(5,4), dpi=150)\nplt.plot(y[:500])","981b55f7":"sl = int(N\/\/1.3333333333)\ny_train, y_valid = np.array(y[:sl]), np.array(y[sl:])\ny_train.shape, y_valid.shape","0bfe8977":"trn_len, pred_len = 100, 400","b41d27af":"def create_sequences(yin, input_seq_size, output_seq_size):\n    xout = []\n    yout = []\n    for ii in tqdm(range(yin.shape[0]-input_seq_size-output_seq_size)):\n        xout.append(yin[ii:ii+input_seq_size, ...].view(1, 1, -1))\n        yout.append(yin[ii+input_seq_size:ii+input_seq_size+output_seq_size, ...].view(1, 1, -1))\n    xout = torch.cat(xout, dim=0)\n    yout = torch.cat(yout, dim=0)\n    return xout, yout.squeeze()","8644d5a7":"x_train, y_train = create_sequences(torch.from_numpy(y_train).float(), trn_len, pred_len)\nx_valid, y_valid = create_sequences(torch.from_numpy(y_valid).float(), trn_len, pred_len)\nx_train.size(), y_train.size(), x_valid.size(), y_valid.size()","3b63aaad":"train_ind = list(range(len(x_train)))\nvalid_ind = list(range(len(x_train), len(x_train)+len(x_valid)))\nx = torch.cat([x_train, x_valid], dim=0)\ny = torch.cat([y_train, y_valid], dim=0)\nx.size(), y.size()","f8378ab5":"data = Datasets(list(range(len(x))), [lambda i : x[i], lambda i : y[i]], splits=[train_ind, valid_ind])\ndls = data.dataloaders(bs=64)","8ff3a6e2":"class TimeSeriesModel(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(TimeSeriesModel, self).__init__()\n        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=7, stride=2)\n        self.conv1_bn = nn.BatchNorm1d(64)\n        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=2)\n        self.conv2_bn = nn.BatchNorm1d(128)\n        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, stride=2)\n        self.conv3_bn = nn.BatchNorm1d(256)\n        self.drop = nn.Dropout(0.5)\n        self.pool = nn.AdaptiveAvgPool1d(10)\n        self.linear = nn.Linear(10*256, output_size)\n        self.linear_bn = nn.BatchNorm1d(output_size)\n        self.out = nn.Linear(output_size, output_size)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.conv1_bn(x)\n        x = F.relu(self.conv2(x))\n        x = self.conv2_bn(x)\n        x = F.relu(self.conv3(x))\n        x = self.conv3_bn(x)\n        x = self.pool(x)\n        x = x.view(-1, 10*256)\n        x = F.relu(self.linear(x))\n        x = self.drop(self.linear_bn(x))\n        return self.out(x)","bf7cbafd":"model = TimeSeriesModel(1, pred_len)\nlearn = Learner(dls, model, loss_func=nn.MSELoss())","72d8a2de":"learn.lr_find()","3e2c9768":"learn.fit_one_cycle(20, max_lr=3e-2)","4f1496e6":"ye_valid, y_valid = learn.get_preds()\nye_valid.shape, y.shape","df4778c2":"fig, axes = plt.subplots(ncols=4, nrows=3, figsize=(12,6), dpi=150)\nfor i, ax in enumerate(axes.flat):\n    plot_idx = np.random.choice(np.arange(0, len(ye_valid)))\n    true = np.concatenate([x_valid.numpy()[plot_idx,-1,:].reshape(-1), y_valid.numpy()[plot_idx,:].reshape(-1)])\n    pred = np.concatenate([x_valid.numpy()[plot_idx,-1,:].reshape(-1), ye_valid[plot_idx,:].reshape(-1)])\n    ax.plot(pred, color='red', label='preds')\n    ax.plot(true, color='green', label='true')\n    ax.vlines(trn_len-1, np.min(true), np.max(true), color='black')\n    if i == 0: ax.legend()\nfig.tight_layout();","6bca0a8d":"plt.figure(figsize=(5,4), dpi=150)\nplt.plot(((ye_valid-y_valid)**2).mean(0))\nplt.ylabel('MSE')","6effd4f6":"# Learn AI Today: 04 - Time-series forecasting with Convolutional Neural Networks\n\n**What you will learn in this story:**\n* Create a chaotic time series\n* Split the series in sequences to feed to a model\n* Define and train a 1d convolutional neural network for time series forecast\n* Using fastai2 Dataset and Learner\n\n\n**If you want to receive updates consider joining my mailing list at [learn-ai-today.com](http:\/\/learn-ai-today.com)**\n\n## Note: The full description of the code and steps is available on Medium at https:\/\/towardsdatascience.com\/learn-ai-today-04-time-series-multi-step-forecasting-6eb48bbcc724.","78ccda81":"* # Generate Chaotic Time Series","8f05a2d2":"To generate a chaotic time series I will use the [Mackey-Glass equation](http:\/\/www.scholarpedia.org\/article\/Mackey-Glass_equation), with the parameters described [here](http:\/\/lab.fs.uni-lj.si\/lasin\/wp\/IMIT_files\/neural\/nn05_narnet\/).\n"}}