{"cell_type":{"f8b151e0":"code","b3629954":"code","8cd501f1":"code","40d133b1":"code","ba21d74e":"code","c2196254":"code","b3e9a266":"code","b67af619":"code","4def13f5":"code","fc6c2588":"code","349ac4e8":"code","84dc63c9":"code","1f96e122":"code","ef1727e6":"code","1fb94fa0":"code","2c418403":"code","0c2f2565":"code","174af8ac":"code","d32bea7b":"code","ab5f6f9a":"code","747c2d1c":"code","76611eeb":"code","3ffb0b43":"code","2c647cf6":"code","2a90ad7d":"code","c0baaaac":"code","087fe1c3":"code","a8f76ba3":"code","8c756e15":"code","afcf6436":"code","27a2b836":"code","8cf09897":"code","cd19ae56":"code","6bb2f56b":"code","19500a73":"code","7c0c340f":"code","c44ec7e4":"code","1c7d874e":"markdown","26efddba":"markdown","c44f5870":"markdown","3600a8f7":"markdown","68935d37":"markdown","bde54bac":"markdown","499155b3":"markdown","217e4413":"markdown","a03aadfc":"markdown","aa38989e":"markdown","49eb865f":"markdown","7efd09f0":"markdown","d2445acc":"markdown","3fed6da3":"markdown","b8f73c2e":"markdown"},"source":{"f8b151e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3629954":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder","8cd501f1":"train = pd.read_csv('\/kaggle\/input\/customer-segmentation\/Train.csv')\ntrain.head()","40d133b1":"train.info()","ba21d74e":"train.describe(include='all').T","c2196254":"print(train.columns.to_list())","b3e9a266":"# check for segmentation columns\ntrain.groupby('Segmentation')[[ 'Age','Work_Experience','Family_Size', 'Var_1']].agg('mean')","b67af619":"#plot\nplt.style.use('seaborn-dark-palette')\ntrain.groupby('Segmentation')[[ 'Age','Work_Experience','Family_Size', 'Var_1']].agg('mean').plot(kind = 'bar')","4def13f5":"# by Gender\ntrain.groupby('Gender')[['Age','Work_Experience','Family_Size']].agg('mean')","fc6c2588":"plt.style.use('fivethirtyeight')\ntrain.groupby('Gender')[['Age','Work_Experience','Family_Size']].agg('mean').plot(kind = 'barh')","349ac4e8":"# we will check for profession by gender\ntrain.groupby(['Profession','Gender'])[['Gender']].count()","84dc63c9":"# check the spending score by Gender\ntrain.groupby(['Gender','Spending_Score'])[['Spending_Score']].count()","1f96e122":"train.groupby(['Gender','Spending_Score'])[['Spending_Score']].count().plot(kind = 'barh')","ef1727e6":"train.isnull().sum()","1fb94fa0":"# there are missing values in some of the columns so we can drop them \ntrain.dropna(axis=0,inplace=True)\ntrain.isnull().sum()","2c418403":"plt.style.use('ggplot')\nsns.pairplot(train)","0c2f2565":"sns.heatmap(train.corr(),annot = True)","174af8ac":"cat = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\ndf_dummies = pd.get_dummies(train,columns=cat)\nprint(df_dummies.columns.tolist())","d32bea7b":"le = LabelEncoder()\ndf_dummies['Segmentation'] = le.fit_transform(df_dummies['Segmentation'])\n","ab5f6f9a":"plt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\ntrain['Segmentation'].value_counts().plot(kind = 'bar')\nplt.subplot(1,2,2)\ndf_dummies['Segmentation'].value_counts().plot(kind = 'bar')\nplt.show()","747c2d1c":"X = df_dummies.drop(['Segmentation','ID'],axis = 1)\ny = df_dummies['Segmentation']\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.20)","76611eeb":"dct = DecisionTreeClassifier()\ndct.fit(X_train,y_train)\ny_pred_dct = dct.predict(X_test)\nprint(f\"The accuracy score for Decision Tree is {(accuracy_score(y_test,y_pred_dct)*100).round(2)} %\")","3ffb0b43":"rf = RandomForestClassifier(n_estimators=1000)\nrf.fit(X_train,y_train)\ny_pred_rf = rf.predict(X_test)\nprint(f\"The accuracy score for Random Forest is {(accuracy_score(y_test,y_pred_rf)*100).round(2)}\")","2c647cf6":"# For decision tree\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(dct, X, y, cv=10)\nprint(f\"10-fold cross validation average accuracy: {(scores.mean()*100).round(3)} %\")","2a90ad7d":"# for Random forest\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(rf, X, y, cv=10)\nprint(f\"10-fold cross validation average accuracy: {scores.mean().round(3)}\")","c0baaaac":"# max score\nprint(f\"10-fold cross validation max accuracy: {(scores.max() *100).round(2)} %\")","087fe1c3":"test = pd.read_csv(\"\/kaggle\/input\/customer-segmentation\/Test.csv\")\ntest.head()","a8f76ba3":"# shape\nprint(train.shape)\nprint(test.shape)","8c756e15":"test.isnull().sum()","afcf6436":"# drop missing values\ntest.dropna(inplace = True)\ntest.isnull().sum()","27a2b836":"cat = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\ndf_dummies_test = pd.get_dummies(test,columns=cat)\nprint(df_dummies_test.columns.tolist())","8cf09897":"le = LabelEncoder()\ndf_dummies_test['Segmentation_label'] = le.fit_transform(df_dummies_test['Segmentation'])","cd19ae56":"df_dummies_test['Segmentation_label']","6bb2f56b":"X_test_new = df_dummies_test.drop(['Segmentation','ID','Segmentation_label'],axis = 1)\ny_test_new = df_dummies_test['Segmentation_label']\ny_pred_new = rf.predict(X_test_new)\ny_new = pd.DataFrame({'Actual':y_test_new,'Predicted': y_pred_new })\ny_new","19500a73":"y_new['outcome'] = np.where( y_new['Actual'] == y_new['Predicted'] , 'Correct', 'Incorrect')","7c0c340f":"y_new","c44ec7e4":"# Random forest is the best performing model which gives an accuracy of 52.47% using cross validation.","1c7d874e":"**Fitting the model on test data**","26efddba":"__Random Forest__","c44f5870":"**Exploratory Data Analysis**","3600a8f7":"__Checking for Datatypes__","68935d37":"**Checking for Descriptive statistics using the Describe method**","bde54bac":"**Using Cross Validation**","499155b3":"__Checking for correlation__","217e4413":"**Checking for column names**","a03aadfc":"**Check for missing values in test data**","aa38989e":"**Decision Tree**","49eb865f":"__Divide the data into train and test set__","7efd09f0":"**Using Label encoder to encode Segmentation column**","d2445acc":"__Checking for missing values__","3fed6da3":"__Import the libraries__","b8f73c2e":"__Creating Dummy Variables__"}}