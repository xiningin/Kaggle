{"cell_type":{"0b96b58b":"code","8a78adc8":"code","f2c99c37":"code","7c97ac40":"code","547ea35f":"code","b3c5075c":"code","094d5f92":"code","78a24bbf":"code","d0dd1002":"code","7e2fecfc":"code","23381660":"code","dca4c32b":"code","8ce55d23":"code","18f8ad6f":"code","b695a7c4":"code","3c18d84d":"code","14dbec91":"code","2e75be1c":"code","19765633":"code","ab45140e":"code","e8696840":"code","a24a77ae":"code","4fb67663":"code","9c5aab79":"code","fb37ba42":"code","f9c46951":"code","4a581769":"code","07818d5b":"code","1d102c7b":"code","d63f5441":"code","719b5a75":"code","d53ebbb6":"code","dd3eb666":"code","d29c80af":"code","41367807":"code","ceec01cf":"code","8405e7f0":"code","ddd9e989":"code","06095b43":"code","56dc1785":"code","b75ae4c5":"code","64a1e468":"code","e8c09899":"code","9e23fbc9":"code","39c49a75":"code","95aec8d4":"code","0427fb96":"code","e6fc39b2":"code","6307aba2":"code","5346740d":"code","f2382d60":"code","151d12fd":"code","7694a2c7":"code","bbce1c91":"code","4ae2ddf5":"code","23b6e389":"code","586e090d":"code","7154bfc3":"code","2bd5a90f":"code","9e1e04dd":"code","00e160c4":"code","64843b33":"code","57530518":"code","c7cb7c56":"code","6d6566d7":"code","7ddf817c":"markdown","3af63bb9":"markdown","7fafa48f":"markdown","68c080f7":"markdown","6dd97e92":"markdown","4dc14e9a":"markdown","5a528931":"markdown","9c129271":"markdown","ac7ce45e":"markdown","534bf762":"markdown","f2438bdd":"markdown","33f416f0":"markdown","9d63b17e":"markdown","6935b302":"markdown","5b7d73e7":"markdown","1f59dc82":"markdown","63850f42":"markdown","0bdc4684":"markdown","c4577732":"markdown","0f73d4b6":"markdown","183b253e":"markdown","9c6ccf30":"markdown"},"source":{"0b96b58b":"#importo le librerie necessarie\nimport os\nimport sys\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport keras\nimport numpy as np\nimport requests\nimport random \nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n%matplotlib inline\nimport cv2\nsys.path.append('..')","8a78adc8":"!pip install imutils\nimport imutils","f2c99c37":"#installo e importo efficientnetB5\n!pip install keras_efficientnets\n!pip install efficientnet\n!pip install git+https:\/\/github.com\/qubvel\/efficientnet\n!git clone https:\/\/github.com\/qubvel\/efficientnet.git\n    \nfrom keras_efficientnets import EfficientNetB5\nfrom keras.applications.imagenet_utils import decode_predictions","7c97ac40":"model = EfficientNetB5(weights='imagenet')","547ea35f":"model.summary()","b3c5075c":"layer_name = 'global_average_pooling2d'          \nintermediate_layer_model = keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n\nimage_size = model.input_shape[1]","094d5f92":"#leggo i dati in due formati utili per i due modelli di features extraction\nyes=[]\nyes2=[]\nfor i in range(300):\n    try:\n        yes.append(plt.imread('..\/input\/brain-tumor-detection\/yes\/yes%s.jpg' %i))  \n        yes2.append(cv2.imread('..\/input\/brain-tumor-detection\/yes\/yes%s.jpg' %i, cv2.IMREAD_GRAYSCALE))  \n    except:\n        pass \nlen(yes)","78a24bbf":"#disegno un campione di cervelli che presentano tumore\n#come si pu\u00f2 vedere le immagini sono molto varie\n#di dimensioni diverse,\n#alcune in bianco e nero (1 canale) altre a colori (3 canali, RGB)\n\nfig, axs = plt.subplots(nrows=1, ncols=5, figsize=(30, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nG=[yes[0], yes[1], yes[2], yes[3], yes[4]]\n\nfor ax, g in zip(axs.flat, G):\n    ax.imshow(g)\n    ax.set_title('brain with tumor')\n\nplt.tight_layout()\nplt.show()","d0dd1002":"no=[]\nno2=[]\nfor i in range(300):\n    try:\n        no.append(plt.imread('..\/input\/brain-tumor-detection\/no\/no%s.jpg' %i)) \n        no2.append(cv2.imread('..\/input\/brain-tumor-detection\/no\/no%s.jpg' %i, cv2.IMREAD_GRAYSCALE)) \n    except:\n        pass  \n\nlen(no)","7e2fecfc":"#disegno un campione di cervelli sani\nfig, axs = plt.subplots(nrows=1, ncols=5, figsize=(30, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nG=[no[0], no[1], no[2], no[3], no[4]]\n\nfor ax, g in zip(axs.flat, G):\n    ax.imshow(g)\n    ax.set_title('health brain')\n\nplt.tight_layout()\nplt.show()","23381660":"print('initial dataset dimension:', len(yes+no))\nprint('the dataset is balanced:', 'positive:', len(yes), 'negative:', len(no))","dca4c32b":"#test set creation: creo un test set bilanciato\n#prendo il 10% del dataset, essendo esso di piccole dimensioni \n#25 positive and 25 negative\n\ntest_yes=yes[:25]\ntest_no=no[:25]\ntest_yes2=yes2[:25]\ntest_no2=no2[:25]","8ce55d23":"#remove test set from the dataset\nyes=yes[25:]\nno=no[25:]\nyes2=yes2[25:]\nno2=no2[25:]","18f8ad6f":"print('training set dimension:', len(yes+no))\nprint('the dataset is still bilanced:', 'positive:', len(yes), 'negative:', len(no))","b695a7c4":"#funzione che pulisce l'immagine, per il primo modello di features extraction\n#tale funzione identifica il contorno della figura, nel nostro caso del cervello, e una volta identificati i 4 punti estremi del bordo\n#ritaglia un rettangolo attorno all'immagine (tolgo le parti laterali delle immagini che sono senza significato perch\u00e8 composte da pixel neri)\n#ho richiesto le dimensioni dell'immagine finale uguali alle dimensioni dell'input che deve avere un'immagine per essere passata come\n#input in efficientnetB5\n\ndef crop_image(img):   \n\n                                       \n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)      #Read the image in gray format (1 channel instead of 3)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)          #Image blurring for removing noise\n    \n    # threshold the image and then perform a series of erosions + dilations to remove any small regions of noise\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]  \n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n         \n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  #find the contours of the brain\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)     \n\n    # find the extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    \n    \n    #pudding\n    ADD_PIXELS = 0\n    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    new_img = cv2.resize(new_img, dsize=(image_size,image_size))\n        \n    return new_img","3c18d84d":"#funzione che pulisce l'immagine, per il secondo modello di features extraction\n#stessa funzione, ma \u00e8 gi\u00e0 \"letta\" in bianco e nero\n\ndef crop_image2(img):  \n\n    thresh = cv2.threshold(img, 45, 255, cv2.THRESH_BINARY)[1]  \n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n  \n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n    ADD_PIXELS = 0\n    new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    new_img = cv2.resize(new_img, dsize=(image_size,image_size))\n        \n    return new_img","14dbec91":"#applico la funzione a tutte le immagini per fare preprocessing e lavorare con immagini della stessa dimensione e ben pulite\n\nyes_pre=[]\nyes_pre2=[]\nno_pre=[]\nno_pre2=[]\n\nfor i in range(len(yes)):\n    try:\n        yes_pre.append(crop_image(yes[i]))\n        yes_pre2.append(crop_image2(yes2[i]))\n    except:\n        pass\n    \n    \nfor i in range(len(no)):\n    try:\n        no_pre.append(crop_image(no[i]))\n        no_pre2.append(crop_image2(no2[i]))\n    except:\n        pass","2e75be1c":"#guardo i risultati su un campione\n\nfig, axs = plt.subplots(nrows=1, ncols=4, figsize=(30, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nG=[yes_pre[0], yes_pre[1], no_pre[0], no_pre[1]]\n\nfor ax, g in zip(axs.flat, G):\n    ax.imshow(g)\n    ax.set_title('preprocessed image')\n\nplt.tight_layout()\nplt.show()","19765633":"#per il test set\ntest_yes_pre=[]\ntest_yes_pre2=[]\ntest_no_pre=[]\ntest_no_pre2=[]\n\nfor i in range(len(test_yes)):\n    try:\n        test_yes_pre.append(crop_image(test_yes[i]))\n        test_yes_pre2.append(crop_image2(test_yes2[i]))\n    except:\n        pass\n    \n    \nfor i in range(len(test_no)):\n    try:\n        test_no_pre.append(crop_image(test_no[i]))\n        test_no_pre2.append(crop_image2(test_no2[i]))\n    except:\n        pass","ab45140e":"#pass the images in efficientnet and prepare the features vectors\nFvector_yes=[]\nfor i in range(len(yes_pre)):\n    try:\n        x = np.expand_dims(yes_pre[i], 0)   #sistemo le dimensioni\n        intermediate_output = intermediate_layer_model.predict(x)   #predizione che esce dal layer di interesse\n        f_vector=np.reshape(intermediate_output, (np.size(intermediate_output), 1))   #sistemo le dimensioni\n        Fvector_yes.append(f_vector)  #creo una lista che contiene i features vectors\n    except:\n        print(i)","e8696840":"Fvector_no=[]\nrem=[]\nfor i in range(len(no_pre)):\n    try:\n        x = np.expand_dims(no_pre[i], 0)\n        intermediate_output = intermediate_layer_model.predict(x)\n        f_vector=np.reshape(intermediate_output, (np.size(intermediate_output), 1))\n        Fvector_no.append(f_vector)  \n    except:\n        print(i)\n        rem.append(i)      #la funzione non lavora su 5 immagini che sono dimensionalmente complesse, \n                           #vado a toglierle anche nel secondo metodo per avere stesso training set\n        ","a24a77ae":"#per la fase di test\nFvector_yes_test=[]\nfor i in range(len(test_yes_pre)):\n    try:\n        x = np.expand_dims(test_yes_pre[i], 0)\n        intermediate_output = intermediate_layer_model.predict(x)\n        f_vector=np.reshape(intermediate_output, (np.size(intermediate_output), 1))\n        Fvector_yes_test.append(f_vector)  \n    except:\n        print(i)","4fb67663":"Fvector_no_test=[]\nfor i in range(len(test_no_pre)):\n    try:\n        x = np.expand_dims(test_no_pre[i], 0)\n        intermediate_output = intermediate_layer_model.predict(x)\n        f_vector=np.reshape(intermediate_output, (np.size(intermediate_output), 1))\n        Fvector_no_test.append(f_vector)  \n    except:\n        print(i)","9c5aab79":"#train label creation\nyes_target=[]\nno_target=[]\n\nfor i in range(len(Fvector_yes)):\n    yes_target.append(1)\nfor i in range(len(Fvector_no)):\n    no_target.append(0) ","fb37ba42":"#test label creation \nyes_target_test=[]\nno_target_test=[]\n\nfor i in range(len(Fvector_yes_test)):\n    yes_target_test.append(1)\nfor i in range(len(Fvector_no_test)):\n    no_target_test.append(0) ","f9c46951":"from sklearn.preprocessing import normalize\nfrom sklearn.decomposition import NMF","4a581769":"#normalize the train\nfor i in range(len(yes_pre2)):\n    yes_pre2[i]=normalize(yes_pre2[i])\nfor i in range(len(no_pre2)):\n    no_pre2[i]=normalize(no_pre2[i]) \n    \n#normalize the test\nfor i in range(len(test_yes_pre2)):\n    test_yes_pre2[i]=normalize(test_yes_pre2[i])\nfor i in range(len(test_no_pre2)):\n    test_no_pre2[i]=normalize(test_no_pre2[i]) ","07818d5b":"#applico nmf sulle immagini preprocessate\n\nnmf_yes=[]\nnmf_no=[]\n\nnmf = NMF(n_components=1, random_state=0)  #nmf rango 1, per ottenere vettori\n\nfor i in range(len(yes_pre2)):\n    nmf_yes.append(nmf.fit_transform(yes_pre2[i]))\nfor i in range(len(no_pre2)):\n    if i!=111 and i!=113 and i!=120 and i!=121 and i!=122:   #da no_pre2 rimuovo rem, le immagini che mi hanno dato problemi nel metodo 1\n        nmf_no.append(nmf.fit_transform(no_pre2[i]))","1d102c7b":"#nmf sul test set\nnmf_yes_test=[]\nnmf_no_test=[]\n\nnmf = NMF(n_components=1, random_state=0)\nfor i in range(len(test_yes_pre2)):\n    nmf_yes_test.append(nmf.fit_transform(test_yes_pre2[i]))\nfor i in range(len(test_no_pre2)):\n    nmf_no_test.append(nmf.fit_transform(test_no_pre2[i]))","d63f5441":"#creo il target per il train \ntarget_no_2=[]\nfor i in range(len(nmf_no)):\n    target_no_2.append(0)\n    \ntarget_yes_2=[]\nfor i in range(len(nmf_yes)):\n    target_yes_2.append(1) \n    \n#per il test\ntarget_no_2T=[]\nfor i in range(len(nmf_no_test)):\n    target_no_2T.append(0)\n    \ntarget_yes_2T=[]\nfor i in range(len(nmf_yes_test)):\n    target_yes_2T.append(1) ","719b5a75":"#metto insieme i risultati e li mescolo\nFvector=Fvector_yes+Fvector_no   #features metodo 1\ntarget=yes_target+no_target   \n\nnmf=nmf_yes+nmf_no            #features metodo 2\ntarget2=target_yes_2+target_no_2\n\ntarget==target2  #True, posso usare solo uno dei due come target, che chiamo unicamente target","d53ebbb6":"#shuffle train data\nc = list(zip(Fvector, nmf, target))\n\nrandom.shuffle(c)\n\nFvector, nmf, target = zip(*c) ","dd3eb666":"#faccio lo stesso per il test\n\ntest_Fvector=Fvector_yes_test+Fvector_no_test  #modello 1\ntest_target=yes_target_test+no_target_test\n\nnmf_test=nmf_yes_test+nmf_no_test   #modello 2\ntarget2_test=target_yes_2T+target_no_2T\n\ntest_target==target2_test  #True ","d29c80af":"#shuffle test data\nc = list(zip(test_Fvector,nmf_test, test_target))\n\nrandom.shuffle(c)\n\ntest_Fvector, nmf_test, test_target = zip(*c) ","41367807":"#definisco una funzione che calcoli true positive, false positive, true negative, false negative\n\ndef TF(y,pred):    #y=ground truth, pred=prediction del modello\n    TN=0\n    TP=0\n    FN=0\n    FP=0\n\n    for i in range(len(pred)):\n        if y[i]==0:\n            if pred[i]==0:\n                TN=TN+1\n            else:\n                FP=FP+1\n        elif y[i]==1:\n            if pred[i]==1:\n                TP=TP+1\n            else:\n                FN=FN+1\n                \n    return(TP, TN, FP, FN)","ceec01cf":"#definisco una funzione che calcoli la metrica 'sensitivity'\n#essa si serve dei valori di true positive, false positive, true negative, false negative\n\ndef sensitivity(y,pred):\n    \n    TP, TN, FP, FN = TF(y,pred)\n    \n    sens=(TP)\/(TP+FN)    #def\n    \n    return(sens)","8405e7f0":"from sklearn import model_selection\nfrom sklearn import preprocessing, linear_model, naive_bayes, metrics, svm\nfrom sklearn import decomposition, ensemble\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression","ddd9e989":"#sistemo le dimensioni del training set\na=np.shape(Fvector)[0]\nb=np.shape(Fvector)[1]\n\nFvector=np.array(Fvector)\nFvector=Fvector.reshape(a,b)","06095b43":"#sistemo le dimensioni del test set\n#per la successiva fase di test\na=np.shape(test_Fvector)[0]\nb=np.shape(test_Fvector)[1]\n\ntest_Fvector=np.array(test_Fvector)\ntest_Fvector=test_Fvector.reshape(a,b)","56dc1785":"print('vectors length:',np.shape(Fvector)[1],'... it is necessary dimensionality reduction in order to work with easiest objects')","b75ae4c5":"#dim reduction: PCA (principal component analysis)\n#questa tecnica di riduzione di dimensionalit\u00e0, basata sulla fattorizzazione SVD, riduce dataset complessi a dimensioni minori\n#in modo da preservarne le informazioni principali\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.decomposition import PCA, KernelPCA\n\nnp.random.seed(0)\n\nX = np.concatenate((Fvector,test_Fvector))        #train + test per avere stessa dimensione finale \nkpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10)     #Non-linear dimensionality reduction (make use of a kernel rbf)\nX_kpca = kpca.fit_transform(X)   \nX_back = kpca.inverse_transform(X_kpca)\npca = PCA()\nX = pca.fit_transform(X)\n\nnp.shape(X)","64a1e468":"#resplit in the original sets\nXtrain=X[:len(Fvector),:]\nXtest=X[len(Fvector):,:]","e8c09899":"#matrix normalization\nXtrain=normalize(Xtrain)\nXtest=normalize(Xtest)","9e23fbc9":"#cross validation\n#support vector machine con kernel polinomiale\n\nkf = KFold(n_splits=20, random_state=None, shuffle=False)\nkf.get_n_splits(Xtrain)\ntargetcv=np.array(target)\nav=0\nfor train_index, test_index in kf.split(Xtrain):\n    X_train, X_test = Xtrain[train_index], Xtrain[test_index]\n    y_train, y_test = targetcv[train_index], targetcv[test_index]\n    SVMcv=svm.SVC(C=15, kernel='poly', probability=True).fit(X_train, y_train)   #c=1, rbf\n    av=av+sensitivity(SVMcv.predict(X_test), y_test)\n    print(sensitivity(SVMcv.predict(X_test), y_test))\nprint('average sensitivity with cross validation:',av\/20)     #0.74","39c49a75":"#divido il training set in validation set e training set, per la fase di model evaluation ma soprattutto per la regressione finale\n#stesso random seed per i due modelli\ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(Xtrain,target,random_state = 50, test_size=0.20)  ","95aec8d4":"#support vector machine con kernel polinomiale\nSVM=svm.SVC(C=15, kernel='poly', probability=True).fit(train_x, train_y) ","0427fb96":"p=SVM.predict_proba(valid_x)[:,1]   #preparo le prediction per la regressione logistica finale (per unire i risultati dei due modelli)\n                                    #lista che esprime per ogni paziente, la probabilit\u00e0 che esso sia malato (P di ottenere 1)","e6fc39b2":"#sistemo le dimesnioni del training e del test set\nM=np.transpose((np.transpose(nmf)[0])) \nN=np.transpose((np.transpose(nmf_test)[0]))","6307aba2":"#cross validation\n#support vector machine con kernel rbf\n\nkf = KFold(n_splits=20, random_state=None, shuffle=False)\nkf.get_n_splits(M)\ntargetcv=np.array(target)\nav=0\nfor train_index, test_index in kf.split(M):\n    X_train, X_test = M[train_index], M[test_index]\n    y_train, y_test = targetcv[train_index], targetcv[test_index]\n    SVMcv=svm.SVC(C=2, kernel='rbf', probability=True).fit(X_train, y_train)  \n    av=av+sensitivity(SVMcv.predict(X_test), y_test)\n    print(sensitivity(SVMcv.predict(X_test), y_test))\nprint('average sensitivity with cross validation:',av\/20)   #0.71","5346740d":"#divido il training set in validation set e training set, per la fase di model evaluation ma soprattutto per la regressione finale\n#stesso random seed per i due modelli\ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(M, target, random_state = 50, test_size=0.20)","f2382d60":"#support vector machine con kernel rbf\nSVM2 = svm.SVC(C=2, kernel='rbf', probability=True).fit(train_x, train_y)  ","151d12fd":"q=SVM2.predict_proba(valid_x)[:,1] #preparo le pred per la regressione logistica finale (per unire i risultati dei due modelli)","7694a2c7":"#organizzo i dati in una tabella\npred_valid = pd.DataFrame({\"target\": valid_y,\"pred1\": p, \"pred2\": q}) \npred_valid","bbce1c91":"#feature matrix and target\nXf = pred_valid.iloc[:, 1:3]\nyf = pred_valid.target","4ae2ddf5":"#train-valid split\nSEED = 30\nx_trainLR , x_validationLR, y_trainLR , y_validationLR = model_selection.train_test_split(Xf, yf, test_size = 0.1,random_state = SEED)","23b6e389":"#uso gridsearch per avere un'idea dei parametri ottimali (ma per l'accuracy...)\n#poi provo a modificare i parametri che ottengo\n\nGSL=GridSearchCV(estimator=linear_model.LogisticRegression(),\n             param_grid={'multi_class':('auto', 'ovr', 'multinomial'), 'C': (0.001,0.1,0.01,0.8,0.9,1,1.1,1.2,2,10), 'max_iter': (100,200,300,400), 'solver': ('newton-cg', 'lbfgs', 'sag', 'saga')})","586e090d":"GSL=GSL.fit(Xf, yf)","7154bfc3":"print (\"best parameter choice:\", GSL.best_params_)  ","2bd5a90f":"#cross validation\n#logistic reegression\n\nkf = KFold(n_splits=10, random_state=None, shuffle=False)\nkf.get_n_splits(Xf)\ntargetcv=np.array(yf)\nXfcv=np.array(Xf)\nav=0\nfor train_index, test_index in kf.split(Xfcv):\n    X_train, X_test = Xfcv[train_index], Xfcv[test_index]\n    y_train, y_test = targetcv[train_index], targetcv[test_index]\n    lrClfcv = LogisticRegression(C = 1, max_iter= 100, multi_class= 'multinomial', solver= 'newton-cg').fit(X_train, y_train) \n    av=av+sensitivity(lrClfcv.predict(X_test), y_test)\n    print(sensitivity(lrClfcv.predict(X_test), y_test))\nprint('average sensitivity with cross validation:',av\/10)  #0.74","9e1e04dd":"#rialleno e prendo le prediction (ovviamente con gli iperparametri prima trovati)\n\nSVM_=svm.SVC(C=15, kernel='poly', probability=True).fit(Xtrain,target)\np2=SVM_.predict_proba(Xtest)[:,1] \n\nSVM2_ = svm.SVC(C=2, kernel='rbf', probability=True).fit(M, target)\nq2=SVM2_.predict_proba(N)[:,1]","00e160c4":"#organizzo i dati in una tabella\npred_test= pd.DataFrame({\"target\": test_target,\"pred1\": p2, \"pred2\": q2}) \npred_test","64843b33":"#test feature matrix and test target\nXf2 = pred_test.iloc[:, 1:3]\nyf2 = pred_test.target","57530518":"#rialleno e prendo le prediction \nlrClf = LogisticRegression(C= 1, max_iter= 100, multi_class= 'multinomial', solver= 'newton-cg').fit(Xf, yf)  #c=0.1\n\nfinal_pre=lrClf.predict(Xf2)         #final prediction\nPfinal_pre=lrClf.predict_proba(Xf2)  #final prob prediction ","c7cb7c56":"sensitivity(list(yf2), final_pre)  #risultato finale: sensitivity 0.9","6d6566d7":"# per una visione d'insieme:\n# Roc Curve (Receiver operating characteristic Curve) and AUC (area under the curve)\n# auc = 0.86, risultati buoni ma non ottimi (auc circa 1 per un modello ottimo, che classifica perfettamente)\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(test_target,Pfinal_pre[:,1])\nroc_auc = auc(fpr, tpr) \n\nplt.figure()\nlw = 2\nplt.plot(fpr, tpr, color='darkorange',\n         lw=lw, label='ROC curve (area = %0.4f)'% roc_auc )\n\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","7ddf817c":"# Features extraction","3af63bb9":"# Soluzione finale sul test set\n\n### rialleno i modelli sull'intero training set e calcolo le prediction sul test set","7fafa48f":"## Modello 2: uso le features che ho creato con nmf e uso svm","68c080f7":"#### Problemi riscontrati nel lavoro:\n\nIl dataset che ho trovato \u00e8 molto rumoroso, ho fatto fatica ad analizzare i dati nella loro totalit\u00e0.\n\nHo dovuto calcolare i features vectors tenendo separate le classi, per non perdere informazioni sull'ordine, importante perch\u00e8 utilizzo due modelli diversi e devo metterne insieme i risultati.\n\nInoltre, come per la maggior parte dei dataset medici, il numero di immagini \u00e8 molto limitato. Lavorare su un dataset piccolo non permette di ottenere risultati molto accurati. Una soluzione \u00e8 data-augmentation: tuttavia, \u00e8 un lavoro che va fatto con cura e con qualche competenza medica (fare il flip delle immagini, ad esempio, non \u00e8 possibile, in quanto il cervello \u00e8 per sua natura asimmetrico; anche altri tipi di deformazioni delle immagini vanno valutate e analizzate con attenzione, per evitare di creare immagini non reali sulle quali fare training, il che porterebbe a un peggioramento del risultato finale).","6dd97e92":"## train - test split","4dc14e9a":"### Metriche\n\nHo esplorato alcune metriche utili in diagnostica, basandomi su un lavoro precedente fatto con alcuni miei colleghi: https:\/\/medium.com\/mljcunito\/daignosis-exploring-the-space-of-metrics-c6bca5d53acb\n\nOttimizzando la metrica sensitivity sono riuscita ad ottenere buoni (ma non ottimi) risultati.\n\n\"*Sensitivity is the probability that the model predicts positive if the patient have the disease: it is the proportion of examples classified as positive in a total of positive examples.*\"\n\n*Sensitivity = True positive \/ (True positive + False negative)*\n\nDunque il seguente lavoro \u00e8 buono nel riconoscere un paziente malato, che presenta tumore.\n","5a528931":"### Features extraction\n\n**1. Primo metodo: efficientnetB5**\n\nReferences: \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\" Mingxing Tan 1 Quoc V. Le 1\n\n\nEfficientnet \u00e8 una recente classe di modelli di reti convoluzionali; al momento ne esistono 8 tipi (dalla B0 alla B7), e presentano via via maggiore efficienza e accuratezza. \n\nUna possibile applicazione di queste reti convoluzionali \u00e8 in diagnostica medica.\n\nHo utilizzato efficientnetB5 (in model.summary() \u00e8 possibile vedere nel dettaglio le componenti di questa rete convoluzionale), inzializzata con i pesi di imagenet. Dunque ho utilizzato la rete \"pretrained\" per estrarre i features vectors dalle immagini, che ho poi utilizzato nella vera e propria parte di training.\n\nPer estrarre i feature vectors ho \"tagliato\" la rete al layer 'global_average_pooling2d', uno dei layer finali, dove le informazioni piu dettagliate vengono elaborate (dunque la presenza di un oggetto estraneo nel cervello potrebbe essere messa in evidenza negli ultimi layer; avessi preso un layer iniziale la distinzione tra cervello sano e malato sarebbe stata meno evidente).\n\n**2. Secondo metodo: non negative matrix factorization**\n\nHo implementato NMF di rango 1 sulle immagini per estrarre un altro tipo di features vectors.\n\nUn'immagine pu\u00f2 essere vista come una matrice, quindi \u00e8 possibile implementare matrix factorization (con opportuna normalizzazione).\n\nNMF \u00e8 un metodo di apprendimento non supervisionato che mette in evidenza le parti delle immagini e il loro peso; questo algoritmo permette di fare 'image encoding' catturando le informazioni fondamentali dall'immagine.\n","9c129271":"### Metodo 2: implemento non-negative matrix factorization","ac7ce45e":"## Modello 1: uso le features che ho creato con efficientnet e uso svm","534bf762":"# Brain tumor detection in mri brain images\n\n## Machine Learning 2019\/2020 ","f2438bdd":"# Load Data and EDA","33f416f0":"# Preprocessing","9d63b17e":"> I vettori features che utilizza la regressione logistica sono vettori a due componenti: ad ogni paziente (rappresentato dall'immagine della sua risonanza magnetica) corrisponde un vettore di due predizioni (la probabilit\u00e0 di avere il tumore per i due modelli)","6935b302":"### Metodo 1: passo le immagini in efficientnet ed estraggo i features vectors","5b7d73e7":"Ho trovato due set di features con due metodi, ora provo due modelli di ML, ma per vedere se ottengo informazioni rilevanti nella classificazione, mischio il dataset (mescolo nello stesso modo i due dataset e il target)","1f59dc82":"> Per la parte di model selection ho fatto alcuni tentativi, servendomi di gridsearch, il quale metodo per\u00f2 riporta risultati ottimali per la metrica accuracy, dunque li ho poi modificati\n\n> Ho regolarizzato meno nei due modelli e di piu nel modello finale di logistic regression","63850f42":"Ho studiato e modificato la funzione di preprocessing da questo lavoro, poich\u00e8 si adattava bene al mio progetto https:\/\/www.kaggle.com\/ruslankl\/brain-tumor-detection-v1-0-cnn-vgg-16","0bdc4684":"# Definzione della metrica da utilizzare","c4577732":"**Breve descrizione del progetto:**\n\nNel seguente lavoro ho cercato di costruire un classificatore che fosse in grado di distinguere un paziente sano da uno malato in base alla sua risonanza magnetica cerebrale (--> classificazione binaria)\n\nLe immagini mediche che ho analizzato rappresentano delle slice del cervello dal punto vi vista assiale, alcune sono immagini di cervelli sani, altre immagini di cervelli con tumore cerebrale.\n\n\nHo utilizzato due metodi per estrarre le features su cui lavorare, e successivamente le ho utilizzate per allenare due modelli support vector machines, dei quali ho unito i risultati mediante regressione logistica.\n\nLa metrica che ho utilizzato \u00e8 **sensitivity** (in base ad alcuni tentativi posso dire che basando il mio lavoro sull'ottimizzazione di tale metrica ho raggiunto risultati migliori).","0f73d4b6":"Data comes from kaggle: https:\/\/www.kaggle.com\/ahmedhamada0\/brain-tumor-detection ","183b253e":"### Regressione logistica per mettere insieme nel migliore dei modi i due risultati","9c6ccf30":"# Training e model evaluation"}}