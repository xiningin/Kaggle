{"cell_type":{"d6f034eb":"code","927b8922":"code","f2dbec2f":"code","4021e7d6":"code","29894f1e":"code","22af3487":"code","34d4b1aa":"code","78541c91":"code","709c9380":"code","bdd1897c":"code","2ad05ccc":"code","1f6268f8":"code","967460d5":"code","eeb66c43":"code","92c2ca59":"code","519192d2":"code","3a492b77":"code","694aeb42":"code","51cca7e8":"code","149f0ae8":"code","e8cbcbe4":"code","d70c9137":"code","13e2e43e":"code","82b86b51":"code","1382cc3c":"code","69f814f5":"code","7073cb4a":"code","49fffb36":"code","4c84ded3":"code","353871f8":"code","484355cf":"code","a0454b5a":"code","61521b48":"code","2dd54900":"code","2293adca":"code","375b4250":"code","d104ef0f":"code","5b70e57f":"code","b2415797":"code","7f76dc5c":"code","bc491064":"code","cadd91da":"markdown","c156ac3e":"markdown","90d34e32":"markdown","33ed6695":"markdown","7387eff3":"markdown","6829ceee":"markdown","bc16ddf9":"markdown","2e3cff2e":"markdown","ff41a6c5":"markdown","5949e452":"markdown","c19eb1eb":"markdown","a55108f2":"markdown","ae8b9b73":"markdown","de1afb40":"markdown","59613442":"markdown","d26a4ba1":"markdown","3ca612dc":"markdown","84c6e3a4":"markdown"},"source":{"d6f034eb":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport glob #for searching files in directory\nimport warnings \nwarnings.filterwarnings('ignore')","927b8922":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f2dbec2f":"base_dataset=glob.glob(\"..\/input\/ieee-fraud-detection\/*.csv\")","4021e7d6":"base_dataset[1].split(\"\\\\\")[-1].split(\".\")[0]=10","29894f1e":"for i in base_dataset:\n    print(i)","22af3487":"\"\"\" iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.        \n\"\"\"\n\nfor i in base_dataset:\n    df=pd.read_csv(i)\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\ni.split(\"\\\\\")[-1].split(\".\")[0]=df\nend_mem = df.memory_usage().sum() \/ 1024**2\nprint('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\nprint('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\nprint(\"*******************************************************************************************\")","34d4b1aa":"train=pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_transaction.csv\")","78541c91":"train.head()","709c9380":"train.shape","bdd1897c":"null_value_table=(train.isna().sum()\/train.shape[0])*100\n\nretained_columns=null_value_table[null_value_table<30].index\ndrop_columns=null_value_table[null_value_table>30].index\n\ntrain.drop(drop_columns,axis=1,inplace=True)\n\nlen(train.isna().sum().index)\n\ncont=train.describe().columns\n\ncat=[i for i in train.columns if i not in train.describe().columns]\n\nfor i in cat:\n    train[i].fillna(train[i].value_counts().index[0],inplace=True)\n\nfor i in cont:\n    train[i].fillna(train[i].median(),inplace=True)","2ad05ccc":"from sklearn.preprocessing import LabelEncoder\nfor i in cat:\n    le=LabelEncoder()\n    le.fit( train[i])\n    x=le.transform( train[i])\n    train[i]=x","1f6268f8":"train=train.sample(200000)","967460d5":"for i in train.var().sort_values(ascending=False).index[1:10]:\n    x=np.array(train[i])\n    qr1=np.quantile(x,0.25)\n    qr3=np.quantile(x,0.75)\n    iqr=qr3-qr1\n    utv=qr3+(1.5*(iqr))\n    ltv=qr1-(1.5*(iqr))\n    y=[]\n    for p in x:\n        if p <ltv or p>utv:\n            y.append(np.median(x))\n        else:\n            y.append(p)\n    train[i]=y","eeb66c43":"train[\"isFraud\"].value_counts()","92c2ca59":"X = np.array(train.iloc[:, train.columns != 'isFraud'])\ny = np.array(train.iloc[:, train.columns == 'isFraud'])\nprint('Shape of X: {}'.format(X.shape))\nprint('Shape of y: {}'.format(y.shape))\n","519192d2":"from imblearn.over_sampling import SMOTE\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","3a492b77":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n","694aeb42":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfor i in  train.var().sort_values(ascending=False).index[1:10]:\n    sns.boxplot( train[i])\n    plt.show()","51cca7e8":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfor i in  train.var().sort_values(ascending=False).index[1:10]:\n    for j in  train.var().sort_values(ascending=False).index[1:10]:\n        plt.scatter( train[i], train[j])  \n        plt.show()","149f0ae8":" train.corr()","e8cbcbe4":"sns.heatmap(train.corr())","d70c9137":"y=train['isFraud']\nx=train.drop(['isFraud','M6'],axis=1)","13e2e43e":"x.shape","82b86b51":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=121)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","1382cc3c":"from sklearn.tree import DecisionTreeClassifier\nln=DecisionTreeClassifier()\nln.fit(X_train,y_train)\nln.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\nprint(\"\\n\",confusion_matrix(y_test,ln.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint(\"\\n\\naccuracy_score using DT : \",accuracy_score(y_test,ln.predict(X_test)))","69f814f5":"ln.predict(X_test)[1:20]","7073cb4a":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(random_state=121)\nrf.fit(X_train,y_train)\nrf.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\nprint(\"\\n\",confusion_matrix(y_test,rf.predict(X_test)))\n\nfrom sklearn.metrics import accuracy_score\nprint(\"\\n\\naccuracy_score using RF : \",accuracy_score(y_test,rf.predict(X_test)))","49fffb36":"rf.predict(X_test)[1:20] ","4c84ded3":"test=pd.read_csv(\"..\/input\/ieee-fraud-detection\/test_transaction.csv\")\n","353871f8":"test.shape","484355cf":"null_value_table=(test.isna().sum()\/test.shape[0])*100\n\nretained_columns=null_value_table[null_value_table<30].index\ndrop_columns=null_value_table[null_value_table>30].index\n\ntest.drop(drop_columns,axis=1,inplace=True)\n\nlen(test.isna().sum().index)\n\ncont=test.describe().columns\n\ncat=[i for i in test.columns if i not in test.describe().columns]\n\nfor i in cat:\n    test[i].fillna(test[i].value_counts().index[0],inplace=True)\n\nfor i in cont:\n    test[i].fillna(test[i].median(),inplace=True)","a0454b5a":"from sklearn.preprocessing import LabelEncoder\nfor i in cat:\n    le=LabelEncoder()\n    le.fit(test[i])\n    z=le.transform(test[i])\n    test[i]=z","61521b48":"pred=rf.predict(test)\npred=pred.astype(float)","2dd54900":"final_res=pd.DataFrame([test['TransactionID']]).T\nfinal_res['isFraud']=pred","2293adca":"final_res.head()","375b4250":"final_res.to_csv('test_res.csv', index=False)","d104ef0f":"sample=pd.read_csv(\"..\/input\/ieee-fraud-detection\/sample_submission.csv\")\nsample.head()","5b70e57f":"sample=sample.drop('isFraud',axis=1)\nsample = pd.merge(sample,final_res , on='TransactionID', how='inner')","b2415797":"sample.head()","7f76dc5c":"from IPython.display import HTML\n\nsample.to_csv('submission.csv', index=False)\n\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}<\/a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='submission.csv')\n","bc491064":"create_download_link(filename='test_res.csv')","cadd91da":"label encoding\n","c156ac3e":"#### Correlation","90d34e32":"#### Lable_Encoding","33ed6695":"### Heatmap","7387eff3":"#### Bivariate","6829ceee":"#### Base Models","bc16ddf9":"outlier treatment","2e3cff2e":"#### Univariate","ff41a6c5":"sampling","5949e452":"### merging dataset","c19eb1eb":"# Import packages","a55108f2":"## Memory optimization","ae8b9b73":"# Confusion matrix & Accuracy","de1afb40":"null value treatment","59613442":"## Test dataset prediction","d26a4ba1":"# Final Prediction","3ca612dc":"#### Null_Value_Treatment","84c6e3a4":"## load dataset"}}