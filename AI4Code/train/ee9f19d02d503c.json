{"cell_type":{"9428da52":"code","b3a9eab7":"code","253d8077":"code","50ee593f":"code","ba64612b":"code","ef0ea3f5":"code","6fa26db0":"code","995e2416":"code","96e6d305":"code","f8ee42ac":"code","9ecef648":"code","6cf1fcc0":"code","78408192":"code","2dc35347":"code","0f8ca089":"code","bf22b003":"code","cc2d79f5":"code","aa92e2c7":"code","0cb22ae9":"code","128b5a7b":"code","1b6fec9a":"code","538c7027":"code","1b84138b":"code","a2662cc8":"code","40d07a65":"code","9a2c4188":"code","be0683fb":"code","c78397c5":"code","88a0f744":"code","7661a90c":"code","55d775ad":"code","63920e17":"code","5cee2071":"code","5004f51c":"code","a1afe6cb":"code","01e54484":"code","8390857a":"code","80f20352":"code","04c7c757":"code","5d8acad0":"code","affaf7cd":"code","89c5c8b6":"code","8cb564cf":"code","d0c08384":"code","9730fd75":"code","6e264e10":"code","f0a42698":"code","e0459601":"code","a61b478f":"code","2c6b4437":"code","7bcc4dbe":"code","28d62d58":"code","fc6f7c4b":"code","7b45eaf8":"code","9af87b5f":"code","c771edc0":"code","884de2cb":"code","c6bab1a6":"code","b58bf188":"code","cedd13d9":"code","5b3e5cbc":"code","614885d2":"code","b6de140b":"code","82b0a699":"code","1eab0eca":"code","69b4a405":"code","2157c786":"code","c7d9466e":"code","38dd309c":"code","4f8422ec":"code","07b550d8":"markdown","529a6f78":"markdown","ce446a6c":"markdown","992470e2":"markdown","bf43ae12":"markdown","38389e71":"markdown","6ecabfa4":"markdown","38f53001":"markdown","c579c50a":"markdown","d6fe6add":"markdown","74f8eaee":"markdown","37a49ecd":"markdown","0accf996":"markdown","3159fde6":"markdown","1fd9b29f":"markdown","a4debc71":"markdown","831ebf88":"markdown"},"source":{"9428da52":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n# plt.rcParams.update({'figure.figsize':(15,7)})","b3a9eab7":"train = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/train.csv')\ntrain.head()","253d8077":"test = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/test.csv')\ntest.head()","50ee593f":"train.info()","ba64612b":"train.describe()","ef0ea3f5":"train['Response'].nunique()","6fa26db0":"train.describe(include='O')","995e2416":"for i in train.describe(include='O'):\n    print(i,' is =\\n',train[i].value_counts(),'\\n')","96e6d305":"import seaborn as sns\nsns.catplot(x=\"Vehicle_Age\", y=\"Response\", hue=\"Gender\", kind=\"bar\", data=train)","f8ee42ac":"sns.catplot(x=\"Vehicle_Age\", y=\"Response\", hue=\"Previously_Insured\", kind=\"bar\", data=train)","9ecef648":"sns.catplot(x=\"Previously_Insured\", y=\"Response\", hue=\"Gender\", kind=\"bar\", data=train)","6cf1fcc0":"sns.catplot(x=\"Gender\", y=\"Response\", hue=\"Previously_Insured\", kind=\"bar\", data=train.query(\"Vehicle_Age == '> 2 Years'\"))","78408192":"sns.catplot(x=\"Gender\", y=\"Response\", hue=\"Previously_Insured\", kind=\"bar\", data=train.query(\"Vehicle_Age == '1-2 Year'\"))","2dc35347":"sns.catplot(x=\"Gender\", y=\"Response\", hue=\"Previously_Insured\", kind=\"bar\", data=train.query(\"Vehicle_Age == '< 1 Year'\"))","0f8ca089":"sns.lineplot(x=\"Policy_Sales_Channel\", y=\"Vintage\",\n             hue=\"Gender\",\n             data=train)","bf22b003":"sns.distplot(train.Age)","cc2d79f5":"train.iloc[:200].query('Response == 1')['Annual_Premium'].plot(color='cyan')\ntrain.iloc[:200].query('Response == 0')['Annual_Premium'].plot(color='red')\n","aa92e2c7":"data = train.groupby(['Gender'])['Driving_License'].count().to_frame().reset_index()\nsns.catplot(x='Gender', y ='Driving_License', data=data, kind = 'bar')","0cb22ae9":"sns.countplot(train.Vehicle_Age)","128b5a7b":"plt.figure(figsize=(5,5))\nsns.countplot(train['Response'])","1b6fec9a":"train","538c7027":"train['Vintage'].nunique()","1b84138b":"corr = train.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(corr,annot=True)","a2662cc8":"data = pd.concat([train,test], axis=0)\ndata","40d07a65":"data.isnull().sum()","9a2c4188":"from sklearn.preprocessing import   KBinsDiscretizer\n\nest = KBinsDiscretizer(n_bins=30, encode='ordinal', strategy='kmeans')\ndata[\"Age_Bin\"] = est.fit_transform(np.reshape(data[\"Age\"].values, (-1,1)))","be0683fb":"a = data.groupby(['Region_Code'])['Annual_Premium'].mean()\na\ndata = pd.merge(data, a , on='Region_Code') \ndata = data.sort_values(['id']).reset_index(drop=True)\ndata","c78397c5":"a = data.groupby(['Age_Bin'])['Annual_Premium_x'].std().to_frame().reset_index()\na = a.rename(columns={'Annual_Premium_x':\"age_premium_average\"})\na\ndata = pd.merge(data, a , on='Age_Bin') \ndata = data.sort_values(['id']).reset_index(drop=True)\ndata","88a0f744":"a = data.groupby(['Policy_Sales_Channel'])['Annual_Premium_x'].std().to_frame().reset_index()\na = a.rename(columns={'Annual_Premium_x':\"policy_premium_average\"})\na\ndata = pd.merge(data, a , on='Policy_Sales_Channel') \ndata = data.sort_values(['id']).reset_index(drop=True)\ndata","7661a90c":"a = data.groupby(['Vintage'])['Annual_Premium_x'].std().to_frame().reset_index()\na = a.rename(columns={'Annual_Premium_x':\"Vintage_premium_average\"})\na\ndata = pd.merge(data, a , on='Vintage')\ndata = data.sort_values(['id']).reset_index(drop=True)\ndata","55d775ad":"gender = {'Male':0,\n         \"Female\":1}\ndata['Gender'] = data['Gender'].map(gender)","63920e17":"# vehicle_age = {'> 2 Years':2,\n#               '1-2 Year':1,\n#               '< 1 Year':0}\n# train['Vehicle_Age'] = train['Vehicle_Age'].map(vehicle_age)\n\ndummy = pd.get_dummies(data['Vehicle_Age'])\ndummy = dummy.rename(columns= {'1-2 Year':'two',\n                    '< 1 Year':'first',\n                    '> 2 Years':'third'})\ndata = pd.concat([data,dummy], axis=1)","5cee2071":"data.drop(columns='Vehicle_Age', inplace=True)","5004f51c":"damage = {'Yes':1,\n         'No':0}\n\ndata['Vehicle_Damage'] = data['Vehicle_Damage'].map(damage)","a1afe6cb":"corr = data.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(corr<-0.8,annot=True)","01e54484":"l = len(train) \ntrain = data.iloc[:l]\ntrain.tail()","8390857a":"test = data.iloc[l:]\ntest.head()","80f20352":"print(train.isnull().sum())\ntrain.dropna(axis=0,inplace=True)\nprint(train.isnull().sum())","04c7c757":"X = train.drop(columns=['id','Response'])\nY = train['Response']","5d8acad0":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X ,Y, test_size=0.3, random_state=7)","affaf7cd":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nraw_model = RandomForestClassifier()\nraw_model.fit(x_train,y_train)\nraw_pred = raw_model.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(raw_pred, y_test))\n\n \n#             precision    recall  f1-score   support\n\n#            0       0.98      0.89      0.93    110439\n#            1       0.11      0.38      0.17      3892\n","89c5c8b6":"a = raw_model.feature_importances_ #feature_importances\ntotal = sum(a)\nnew = [value * 100 \/ total for value in a]\nnew = np.round(new,2)\n\nreport = pd.DataFrame()\nreport['name'] = x_train.columns\nreport['feature_imp'] = new\n\nreport.sort_values(['feature_imp'],ascending = False).reset_index(drop=True)","8cb564cf":"\nfrom imblearn.over_sampling import RandomOverSampler\n\nsm = RandomOverSampler(random_state=42)\nx_train_o, y_train_o = sm.fit_resample(x_train, y_train)","d0c08384":"print(x_train_o.shape, y_train_o.shape)","9730fd75":"from sklearn.ensemble import RandomForestClassifier\nover_model = RandomForestClassifier( criterion = 'gini', max_depth=10, min_samples_leaf=6, min_samples_split=10, n_estimators=500 )\nover_model.fit(x_train_o,y_train_o)\npred = over_model.predict(x_test)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(pred, y_test))\n\n#               precision    recall  f1-score   support\n\n#            0       0.67      0.99      0.80     67961\n#            1       0.93      0.28      0.43     46370\n\n","6e264e10":"from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nimport matplotlib.pyplot as plt\n\ny_score = over_model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\nplt.title('Random Forest ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","f0a42698":"from imblearn.under_sampling import RandomUnderSampler\ncc = RandomUnderSampler(random_state=42)\nX_resampled, y_resampled = cc.fit_resample(x_train, y_train)\n","e0459601":"print(X_resampled.shape, y_resampled.shape)","a61b478f":"under_model = RandomForestClassifier( criterion = 'gini', max_depth=10, min_samples_leaf=6, min_samples_split=10, n_estimators=500 )\nunder_model.fit(X_resampled,y_resampled)\npred = under_model.predict(x_test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(pred, y_test))\n\n#               precision    recall  f1-score   support\n\n#            0       0.66      0.99      0.79     67096\n#            1       0.94      0.27      0.42     47235\n\n","2c6b4437":"y_score = under_model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","7bcc4dbe":"from sklearn.model_selection import RandomizedSearchCV\nparameter = {'criterion': ['entropy', 'gini'],\n               'max_depth': [2,3,4,5,6,7,10],\n               'min_samples_leaf': [4, 6, 8],\n               'min_samples_split': [5, 7,10],\n               'n_estimators': [300]}\n\nclf = RandomForestClassifier()\nmodel = RandomizedSearchCV(estimator = clf, param_distributions = parameter, n_iter = 10, \n                               cv = 3, verbose= 1, random_state= 101, n_jobs = -1)\nmodel.fit(X_resampled,y_resampled)","28d62d58":"parameter = model.best_params_","fc6f7c4b":"model = RandomForestClassifier( **parameter )\nmodel.fit(X_resampled,y_resampled)\npred = model.predict(x_test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(pred, y_test))\n\n#               precision    recall  f1-score   support\n\n#            0       0.66      0.99      0.79     67096\n#            1       0.94      0.27      0.42     47235","7b45eaf8":"from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nimport matplotlib.pyplot as plt\n\ny_score = model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\nplt.title('Random Forest ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","9af87b5f":"from sklearn.model_selection import RandomizedSearchCV\nfrom lightgbm import LGBMClassifier\nparameter = {'boosting_type': ['gbdt', 'dart'],\n               'learning_rate': [0.001,0.003,0.01,0.03,0.1],\n              \n               \n               }\n\nclf = LGBMClassifier()\nmodel = RandomizedSearchCV(estimator = clf, param_distributions = parameter, n_iter = 10, \n                               cv = 3, verbose= 1, random_state= 101, n_jobs = -1)\nmodel.fit(X_resampled,y_resampled)","c771edc0":" model.best_params_","884de2cb":"from lightgbm import LGBMClassifier\nmodel_1 = LGBMClassifier(\n    boosting_type='gbdt',\n    objective='binary',\n learning_rate =0.01,\n n_estimators=5000,\n colsample_bytree=0.3,\n class_weight='balanced')\n#model.fit(X_train, y_train)\nmodel_1.fit(X_resampled, y_resampled, eval_metric='auc', \n          eval_set=[(x_test, y_test)], early_stopping_rounds=500, verbose=100)\n","c6bab1a6":"lgbm_model = LGBMClassifier(class_weight='balanced', colsample_bytree=0.3,\n               learning_rate=0.01, n_estimators=1057, objective='binary')\n\nlgbm_model.fit(X_resampled, y_resampled)\npred = lgbm_model.predict(x_test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(pred, y_test))\n\n\n\n#               precision    recall  f1-score   support\n\n#            0       0.66      0.99      0.79     67096\n#            1       0.94      0.27      0.42     47235","b58bf188":"\ny_score = lgbm_model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\nplt.title('lgbm Model ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","cedd13d9":"import catboost as cat\ncat_model = cat.CatBoostClassifier()\n\ncat_model.fit(X_resampled, y_resampled)\npred = cat_model.predict(x_test)\nfrom sklearn.metrics import classification_report\nprint(classification_report(pred, y_test))\n","5b3e5cbc":"y_score = cat_model.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, y_score)\n\nplt.title('lgbm Model ROC curve: CC Fraud')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr)\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()\nprint ('Area under curve (AUC): ', auc(fpr,tpr))","614885d2":"test.isnull().sum()","b6de140b":"test.drop(columns=['Response','id'],inplace=True)","82b0a699":"test.fillna(method='ffill', inplace=True)","1eab0eca":"sub = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/sample_submission.csv')\nsub.head()","69b4a405":"Final_pred =  cat_model.predict(test)","2157c786":"sub['Response'] = Final_pred","c7d9466e":"from sklearn.model_selection import KFold \nscore = []\nfinal = []\nkfold = KFold(n_splits=5, random_state=24, shuffle=True)\n\nfor train, tests in kfold.split(X):\n    X_train, X_test = X.iloc[train], X.iloc[tests]\n    Y_train, Y_test = Y.iloc[train], Y.iloc[tests]\n    \n    test_model =LGBMClassifier(\n                        boosting_type='gbdt',\n                        objective='binary',\n                        learning_rate =0.01,\n                        n_estimators=5000,\n                        colsample_bytree=0.3,\n                        class_weight='balanced')\n    \n    #model.fit(X_train, y_train)\n    test_model.fit(X_train, Y_train, eval_metric='auc', \n          eval_set=[(X_test, Y_test)], early_stopping_rounds=500, verbose=100)\n    a = test_model.best_iteration_\n    \n    lin_model = LGBMClassifier(\n                        boosting_type='gbdt',\n                        objective='binary',\n                        learning_rate =0.01,\n                        n_estimators=a,\n                        colsample_bytree=0.3,\n                        class_weight='balanced')\n    lin_model.fit(X_train, Y_train)\n    y_test_predict = lin_model.predict(X_test)\n    \n    \n    final_pred = lin_model.predict_proba(test)\n    final.append(final_pred)\n    \n    y_score = lin_model.predict_proba(x_test)[:,1]\n    fpr, tpr, _ = roc_curve(y_test, y_score)\n    print ('Area under curve (AUC): ', auc(fpr,tpr))\n    \n    score.append(auc(fpr,tpr))\n        \n        \naverage_score = np.mean(score)\nprint('The average RMSE is ', average_score)\n","38dd309c":"np.round(final)","4f8422ec":"sub.to_csv('submission_final_cp.csv')","07b550d8":"## Vehicle_Age == '> 2 Years'","529a6f78":"# We are done with Data Visualization Lets move to Feature Engineering","ce446a6c":"## Lets Take Light LGBM model","992470e2":"## Age distribution","bf43ae12":"## driving_license count per gender","38389e71":"## Vehicle_Age == '1-2 Year","6ecabfa4":"# our target variable is Response\n# Lets take some analytics out","38f53001":"## vehicle age count","c579c50a":"## Over Sampling","d6fe6add":"# A Higly Imbalanced Dataset","74f8eaee":"## Vehicle_Age == '< 1 Year","37a49ecd":"# lets tune our random forest model","0accf996":"## Data Featuring","3159fde6":"# People who have vehicle more than 2 years old tends to buy insurance more compared than others.","1fd9b29f":"# we can see who are previously Insured, are very less likely to take insure again.","a4debc71":"#### as we see under sampling proved better lets go with it","831ebf88":"## Under sampling"}}