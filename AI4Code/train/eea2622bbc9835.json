{"cell_type":{"9ce30983":"code","ea23c659":"code","7244d0cc":"code","7fef777e":"code","fe658eb4":"code","3254a4a5":"code","a77fa30d":"code","8a691cf3":"code","6e3494b7":"code","4f41dab0":"code","b6b95994":"code","a6f00cf2":"code","9e481b26":"code","6762ff26":"code","dd13d44d":"code","3532125e":"code","9091c7e2":"code","f1967b0f":"code","253a7953":"code","493b2341":"markdown","e7a1e2a0":"markdown"},"source":{"9ce30983":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea23c659":"# Importando as bibliotecas\nimport os\nimport time\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import random_split, DataLoader\nfrom torch import nn, optim","7244d0cc":"# Verificando o diret\u00f3rio com as imagens\nimg_dir = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\"\nprint(os.listdir(img_dir))","7fef777e":"# Temos GPU?\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","fe658eb4":"train_transform = transforms.Compose([transforms.Resize((224, 224)),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(35),\n                                      transforms.RandomGrayscale(p=0.02),                                      \n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], \n                                                           [0.229, 0.224, 0.225])])","3254a4a5":"# Criando nossos conjuntos de dados com base nas imagens\ntrain = datasets.ImageFolder(img_dir, transform=train_transform)","a77fa30d":"len(train)","8a691cf3":"# Dividindo os dados em treino e teste\ntrain_data, test_data = random_split(train, (4200, 1016))","6e3494b7":"# Definindo os loaders\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=True)","4f41dab0":"# Usando uma Resnet18 por meio de Transfer Learning\nmodel = models.resnet18(pretrained=True)\n\nmodel","b6b95994":"# Vamos configurar a rede e redefinir a camada fully connected\n\n# Congelando os par\u00e2metros originais\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Definindo o novo classificador\nnew_fc = nn.Linear(512, 2)\n\n# Substituindo o classificador original\nmodel.fc = new_fc\n\nmodel","a6f00cf2":"# Enviando o modelo para GPU\nmodel.to(device)","9e481b26":"# Temos que definir a fun\u00e7\u00e3o de erro e o otimizador (que vai alterar os pesos dos perceptrons)\nerror_function = nn.CrossEntropyLoss() # criterion\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nerror_function.to(device)","6762ff26":"# Treinamento do modelo\n\n# Definindo o n\u00famero de \u00e9pocas\nepochs = 10\n\n# Colocando o modelo em modo de treinamento\nmodel.train()\n\n\n# For para rodar o n\u00famero de \u00e9pocas\nfor i in range(epochs):\n    # Treinamento\n    \n    # Monitorando o training loss\n    train_loss = 0.0\n    \n    # Obtendo dados e respostas\n    for data, target in train_loader:\n        \n        # Enviando os dados para GPU, se existir\n        data, target = data.to(device), target.to(device)\n    \n        # Foward Propagation (passando os dados de treino pela rede)\n        outputs = model(data)\n        # Calculando o erro\n        loss = error_function(outputs, target)\n       \n        # Back Propagation\n        # Limpar os parametros do otimizador (zerar o Gradiente Descendent)\n        optimizer.zero_grad()\n        # Calcular os novos pesos\n        loss.backward()\n        # Executar o optimizador (efetivamente fazer o back propagation mudando os pesos)\n        optimizer.step()\n        \n        # Atualizando o training loss\n        train_loss += loss.item() * data.size(0)\n        \n    # Calculando a m\u00e9dia de erro por epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(i+1, train_loss))","dd13d44d":"# Variaveis para controlar os acertos das previs\u00f5es da rede\n# e  calcular a acur\u00e1cia\ncorrect = 0\ntotal = 0\n\n# Vamos colocar o modelo em modo de avalia\u00e7\u00e3o\/teste\nmodel.eval()\n\n# Obtendo dados e respostas\nfor data, target in test_loader:\n    \n    # Enviando os dados para GPU, se existir\n    data, target = data.to(device), target.to(device)    \n    \n    output = model(data)\n    \n    for index, i in enumerate(output):\n        if torch.argmax(i) == target[index]:\n            correct += 1\n        total += 1","3532125e":"print('Accuracy: ', round(correct\/total, 3))","9091c7e2":"# As tranforma\u00e7\u00f5es que ser\u00e3o aplicadas a cada imagem\n# No caso elas ser\u00e3o convertidas em tensores e nornalizadas\nimage_transform = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Normalize((0.5,), (0.5,))])","f1967b0f":"# Define path to the data directory\ndata_dir = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray')\n\n# Path to train directory (Fancy pathlib...no more os.path!!)\ntrain_dir = data_dir \/ 'train'\n\n# Path to validation directory\nval_dir = data_dir \/ 'val'\n\n# Path to test directory\ntest_dir = data_dir \/ 'test'","253a7953":"# Get the path to the normal and pneumonia sub-directories\nnormal_cases_dir = train_dir \/ 'NORMAL'\npneumonia_cases_dir = train_dir \/ 'PNEUMONIA'\n\n# Get the list of all the images\nnormal_cases = normal_cases_dir.glob('*.jpeg')\npneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n\n# An empty list. We will insert the data into this list in (img_path, label) format\ntrain_data = []\n\n# Go through all the normal cases. The label for these cases will be 0\nfor img in normal_cases:\n    train_data.append((img,0))\n    \n# Go through all the pneumonia cases. The label for these cases will be 1\nfor img in pneumonia_cases:\n    train_data.append((img, 1))\n\n# Get a pandas dataframe from the data we have in our list \ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n\n# Shuffle the data \ntrain_data = train_data.sample(frac=1.).reset_index(drop=True)\n\n# How the dataframe looks like?\ntrain_data.head()","493b2341":"Data Augumentation","e7a1e2a0":"rascunho"}}