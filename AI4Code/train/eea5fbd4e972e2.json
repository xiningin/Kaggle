{"cell_type":{"9da96a65":"code","d3ac476d":"code","0df71f51":"code","899140ac":"code","9b0d1ca8":"code","3ec512e6":"code","48f7c6a5":"code","df21ba74":"code","e159d7a6":"code","39f635a2":"code","36f8317b":"code","6b69c3ce":"code","b423afe4":"code","dcf010e3":"code","d7275973":"code","609a6997":"code","7b9c5e60":"code","1abde07e":"code","e3737a87":"code","25d92eeb":"code","b186bdbe":"code","e6355fc9":"markdown","3a3944f0":"markdown","3f9c3a25":"markdown","20612686":"markdown","c060ac52":"markdown","5f2caeb6":"markdown"},"source":{"9da96a65":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom PIL import Image\nfrom tensorflow.keras.applications import vgg19","d3ac476d":"IMAGE_SIZE = 512\nCHANNELS = 3","0df71f51":"def load_image(path):\n    image = Image.open(path)\n    image = image.resize([IMAGE_SIZE, IMAGE_SIZE])\n    image = np.array(image)\n    return image","899140ac":"path = '...\\\\Style Transfer Images'\n\ncontent_image = load_image(path + '\\\\GoldenGate.jpg')\nstyle_image = load_image(path + '\\\\abstract.jpg')","9b0d1ca8":"plt.figure(figsize = (10, 10))\n\nplt.subplot(121)\nplt.imshow(content_image)\nplt.title('Content Image')\nplt.axis('off')\n\nplt.subplot(122)\nplt.imshow(style_image)\nplt.title('Style Image')\nplt.axis('off')\n\nplt.show()","3ec512e6":"CONTENT_LAYERS = ['block5_conv2']\nSTYLE_LAYERS = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']","48f7c6a5":"def build_model():\n    model = vgg19.VGG19(include_top = False, weights = 'imagenet')\n    model.trainable = True\n    \n    output_layers = [model.get_layer(layer).output for layer in (CONTENT_LAYERS + STYLE_LAYERS)]\n    return tf.keras.Model(model.input, output_layers)","df21ba74":"base_model = build_model()","e159d7a6":"def preprocess_image(image):\n    return vgg19.preprocess_input(np.expand_dims(image, axis=0))","39f635a2":"VGG_BIAS = vgg19.preprocess_input((np.zeros(3)).astype('float32'))\ndef deprocess_image(image):\n    image = image - VGG_BIAS\n\n    \n    image = np.concatenate([np.array(image)[:,:,:,2].reshape(IMAGE_SIZE, IMAGE_SIZE, 1), \n                            np.array(image)[:,:,:,1].reshape(IMAGE_SIZE, IMAGE_SIZE, 1), \n                            np.array(image)[:,:,:,0].reshape(IMAGE_SIZE, IMAGE_SIZE, 1)], axis=2)\n    return image","36f8317b":"def get_content_loss(gen_img, base_content_image):\n    return tf.reduce_mean(tf.square(base_content_image - gen_img))","6b69c3ce":"def get_gram_matrix(layer):\n    layer = tf.reshape(layer, (-1, layer.shape[-1]))\n    gram_matrix = tf.matmul(layer, layer, transpose_a=True)\n    n = gram_matrix.shape[0]\n    return gram_matrix\/tf.cast(n, tf.float32), n\n\ndef get_style_loss(gen_img, base_style_img):\n    gram_gen_img, n1 = get_gram_matrix(gen_img)\n    gram_base_style_img, n2 = get_gram_matrix(base_style_img)\n    \n    assert n1 == n2\n    \n    loss = tf.reduce_mean(tf.square(gram_gen_img - gram_base_style_img))\/(4*(n1**2)*(n2**2))\n    return loss\n    ","b423afe4":"def get_total_loss(gen_img, base_content_image, base_style_img, alpha = 0.5):\n    \n    # content loss\n    new_gen_img_cont = gen_img[:len(CONTENT_LAYERS)]\n    new_base_content_image = base_content_image[:len(CONTENT_LAYERS)]\n    content_loss = 0\n    N1 = len(new_gen_img_cont)\n    \n    for i in range(N1):\n        content_loss += get_content_loss(new_gen_img_cont[i], new_base_content_image[i])\/N1\n        \n    # style loss\n    new_gen_img_sty = gen_img[len(CONTENT_LAYERS):]\n    new_base_style_img = base_style_img[len(CONTENT_LAYERS):]\n    style_loss = 0\n    N2 = len(new_gen_img_sty)\n    \n    for i in range(N2):\n        style_loss += get_style_loss(new_gen_img_sty[i], new_base_style_img[i])\n        \n    total_loss = ((1 - alpha) * style_loss) + (alpha * content_loss)\n    return total_loss","dcf010e3":"processed_content_image = preprocess_image(content_image)\nprocessed_style_image = preprocess_image(style_image)\n\nprocessed_input_image = processed_content_image + tf.random.normal(processed_content_image.shape)","d7275973":"plt.figure(figsize = (10, 10))\n\nplt.subplot(121)\nplt.imshow(np.clip(processed_content_image[0], 0, 1))\nplt.title('Processed Content Image')\nplt.axis('off')\n\nplt.subplot(122)\nplt.imshow(np.clip(processed_style_image[0], 0, 1))\nplt.title('Processed Style Image')\nplt.axis('off')\n\nplt.show()","609a6997":"deprocessed_content_image = deprocess_image(processed_content_image)\ndeprocessed_style_image = deprocess_image(processed_style_image)","7b9c5e60":"plt.figure(figsize = (10, 10))\n\nplt.subplot(121)\nplt.imshow(deprocessed_content_image.astype('uint8'))\nplt.title('Deprocessed Content Image')\nplt.axis('off')\n\nplt.subplot(122)\nplt.imshow(deprocessed_style_image.astype('uint8'))\nplt.title('Deprocessed Style Image')\nplt.axis('off')\n\nplt.show()","1abde07e":"opt = tf.keras.optimizers.Adam(learning_rate=5, beta_1 = 0.99, epsilon=1e-3)","e3737a87":"def edit_image(epochs = 10):\n    \n    min_val = VGG_BIAS\n    max_val = 255 + VGG_BIAS\n    \n    base_model = build_model()\n    \n    processed_content_image = preprocess_image(content_image)\n    processed_style_image = preprocess_image(style_image)\n    processed_input_image = tf.Variable(processed_content_image + tf.random.normal(processed_content_image.shape))\n    \n    base_content_image = base_model(processed_content_image)\n    base_style_image = base_model(processed_style_image)\n\n    for e in range(epochs):\n        with tf.GradientTape() as tape:\n            base_processed_content_input = base_model(processed_input_image)\n            loss = get_total_loss(base_processed_content_input, base_content_image, base_style_image)\n\n        grad = tape.gradient(loss, processed_input_image)\n        opt.apply_gradients([(grad, processed_input_image)])\n\n        clipped = tf.clip_by_value(processed_input_image, min_val, max_val)\n        processed_input_image.assign(clipped)\n\n\n        if e%100 == 0:\n            print(f'Epoch: {e} \\t Loss: {loss}')\n            \n    return processed_input_image","25d92eeb":"EPOCHS = 501\nprocessed_input_image = edit_image(EPOCHS)","b186bdbe":"plt.figure(figsize = (10 ,10))\nplt.imshow(deprocess_image(processed_input_image).astype('uint8'))\nplt.axis('off');","e6355fc9":"### Loading and Plotting Images ","3a3944f0":"### Importing libraries","3f9c3a25":"### Putting it all together","20612686":"### Pre-Processing and De-processing image","c060ac52":"### Building Model from Selected Layers of Vgg19","5f2caeb6":"### Defining Losses"}}