{"cell_type":{"e99834e1":"code","4f708fab":"code","b373ecaa":"code","caab9651":"code","652416be":"code","71d042d1":"code","a01f057a":"code","74c56b88":"code","2291783d":"code","fd6e5663":"code","805c2a8b":"code","950a9d19":"code","d56ca7f0":"code","a29a119d":"code","680c6b34":"code","97add3b3":"code","74f6d476":"code","f96c497c":"code","956fdb54":"code","73d3ca30":"code","edecbf04":"code","9b2ac509":"code","d270c894":"code","1d3f5dc9":"code","c5cf1a2f":"code","c912936f":"code","ea6cc930":"code","cd90a3ac":"code","19d6465a":"code","671eadcb":"code","7ad08792":"code","cbad917e":"code","95e17ead":"code","e585b883":"code","49cebb1d":"markdown","3a42e36d":"markdown","dfe013d6":"markdown","8de2ae57":"markdown","8ace15fb":"markdown","5fabfce6":"markdown","5612a916":"markdown","45936c91":"markdown","744fc027":"markdown","d7172f63":"markdown","0abcc0bd":"markdown","1d327ec7":"markdown","630df820":"markdown","f99f4e32":"markdown","95825f65":"markdown","7c505334":"markdown","c4fc5254":"markdown","6f6254a5":"markdown"},"source":{"e99834e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f708fab":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b373ecaa":"df = pd.read_csv('\/kaggle\/input\/employee-future-prediction\/Employee.csv')","caab9651":"df.head()","652416be":"df['Education'].value_counts()","71d042d1":"df['City'].value_counts()","a01f057a":"out_df=pd.DataFrame(df.groupby('Education')['Education'].count())\n\nout_df\n","74c56b88":"plt.pie(out_df['Education'],labels=['Bachelors','Masters','PHD'],autopct='%.0f%%',radius=2,explode = (0.02,0.1, 0.1),shadow=True)\nplt.legend( \n          title =\"Education\",\n         \n          bbox_to_anchor =(1, 0.5,0.5, 1))","2291783d":"sns.countplot(df['Education'], hue = df['LeaveOrNot'])\nplt.tight_layout()\nplt.grid(True)\nplt.show()","fd6e5663":"new_df = pd.DataFrame(df.groupby(['JoiningYear' , 'LeaveOrNot', ])['JoiningYear'].count())\nnew_df","805c2a8b":"sns.countplot(df['JoiningYear'],hue=df['LeaveOrNot'])\nplt.tight_layout()\nplt.grid(True)\nplt.show()","950a9d19":"out_df=pd.DataFrame(df.groupby('City')['City'].count())\n\nout_df","d56ca7f0":"plt.pie(out_df['City'],labels=['Banglore','New Delhi','Pune'],autopct='%.0f%%',radius=2,explode = (0.02,0.1, 0.1),shadow=True)\nplt.legend( \n          title =\"City\",\n         \n          bbox_to_anchor =(1, 0.5,0.5, 1))","a29a119d":"plt.figure(figsize=(10,8))\nsns.displot(df['Age'] , color='green', bins=15)\nplt.tight_layout()\nplt.grid(True)\nplt.show()","680c6b34":"out_df=pd.DataFrame(df.groupby('Gender')['Gender'].count())\ncolors = ['#61ad66','#3b528b']\nplt.pie(out_df['Gender'] , labels = ['Female', 'Male'],colors = colors , radius = 2 ,explode = (0, 0.1), shadow = True)\nplt.show()","97add3b3":"df.head()","74f6d476":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","f96c497c":"feature = ['Education', 'JoiningYear', 'City', 'PaymentTier','Gender', 'EverBenched', 'ExperienceInCurrentDomain']","956fdb54":"for col in feature:\n    df[col] = le.fit_transform(df[col])","73d3ca30":"df.head()","edecbf04":"from sklearn.model_selection import train_test_split","9b2ac509":"x = df.drop(['LeaveOrNot' , 'ExperienceInCurrentDomain'] , axis = 1)\ny = df.LeaveOrNot","d270c894":"x_train, x_test, y_train, y_test = train_test_split(x, y ,test_size = 0.2 , random_state = 12)","1d3f5dc9":"scores = []\nfrom sklearn.metrics import f1_score","c5cf1a2f":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbors = 7 )\nmodel.fit(x_train, y_train)","c912936f":"pred = model.predict(x_test)\nscores.append({\n    'model' : 'KNeighborsClassifier',\n    'score' :  model.score(x_test,y_test),\n'f1_score'  :  f1_score(y_test , pred)\n})\n\nmodel.score(x_test,y_test)","ea6cc930":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=35, random_state=42, criterion='entropy')\nmodel.fit(x_train, y_train)","cd90a3ac":"y_predict = model.predict(x_test)\n\nscores.append({\n    'model' : 'RandomForestClassifier',\n    'score' :  model.score(x_test,y_test),\n'f1_score'  :  f1_score(y_test , pred)\n})\n\nmodel.score(x_test,y_test)","19d6465a":"from sklearn.tree import DecisionTreeClassifier\n \nmodel = DecisionTreeClassifier( random_state=42, criterion='entropy', splitter='random')\nmodel.fit(x_train, y_train)","671eadcb":"y_predict = model.predict(x_test)\n\nscores.append({\n    'model' : 'DecisionTreeClassifier',\n    'score' :  model.score(x_test,y_test),\n'f1_score'  :  f1_score(y_test , pred)\n})\n\nmodel.score(x_test,y_test)","7ad08792":"from xgboost import XGBRFClassifier\n\nmodel = XGBRFClassifier(eval_metric='mlogloss',\n                        random_state=42,\n                       learning_rate=0.01,\n                       max_depth=10, \n                       scale_pos_weight=1.5)\nmodel.fit(x_train, y_train)","cbad917e":"pred=model.predict(x_test)\n\nscores.append({\n        'model': 'XGBRFClassifier',\n        'score': model.score(x_test,y_test),\n    'f1_score' : f1_score(y_test,pred)\n    })\n\n\nmodel.score(x_test, y_test)","95e17ead":"Score = pd.DataFrame(scores,columns=['model','score','f1_score'])\nScore.sort_values('score',ascending=False,inplace=True)\nScore","e585b883":"plt.figure(figsize=(10,5))\nsns.barplot(y=Score['model'],x=Score['score'])\nplt.tight_layout()\n\nplt.show()","49cebb1d":"XGBRFClassifier model gives the best accuracy of 0.879% to predict whether the employee will leave the company or not.","3a42e36d":"**KNeighbours Classifier**","dfe013d6":"# Age","8de2ae57":"# Model Fitting","8ace15fb":"# Joining Year","5fabfce6":"# RandomForest Classifier","5612a916":"# XGBRFClassifier","45936c91":"# Thank you !!\n\nPlease upvote if you liked my work :):)","744fc027":"**Best Model**","d7172f63":"# Data Preprocessing","0abcc0bd":"# Gender","1d327ec7":"# Complete Analysis","630df820":"# Importing Dependencies ","f99f4e32":"**Employee who leave company in next 2 years**","95825f65":"# Education","7c505334":"# City","c4fc5254":"**Employee who leave company in next 2 years**","6f6254a5":"# DecisionTree Classifier"}}