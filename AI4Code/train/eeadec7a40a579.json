{"cell_type":{"f05f41b4":"code","12d04926":"code","aec031f2":"code","eb841fb0":"code","e7b01f00":"code","9641536d":"code","8119e185":"code","65e6c79a":"code","2592ae69":"code","1d52bb17":"markdown","e0da5b5e":"markdown"},"source":{"f05f41b4":"import os\nimport numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","12d04926":"# Read the data\nX_full = pd.read_csv('..\/input\/learn-together\/train.csv', index_col='Id')\nX_test = pd.read_csv('..\/input\/learn-together\/test.csv', index_col='Id')\n\n#Drop a couple of useless columns\nX_full.drop('Soil_Type7', axis=1, inplace=True)\nX_test.drop('Soil_Type7',axis=1, inplace=True)\nX_full.drop('Soil_Type15', axis=1, inplace=True)\nX_test.drop('Soil_Type15',axis=1, inplace=True)\n\n# Separate target from predictors \ny_full = X_full.Cover_Type\nX_full.drop(['Cover_Type'], axis=1, inplace=True)","aec031f2":"weights = [\n3.3860658430898054,\n0.4163438499758126,\n7.35783588470092,\n1.4635508470705287,\n2.512455585483701,\n0.7879386244955993,\n2.3361452772106412,\n4.509437549105931,\n1.2565844481748276,\n0.8105744594321818,\n357.62840785739945,\n195.87206818235353]","eb841fb0":"# Apply weights to copies of data\nX_full_copy = X_full.copy()\nX_test_copy = X_test.copy()\n\nfor i in range(10):\n    c = X_full.columns[i]\n    X_full_copy[c] = weights[i]*X_full_copy[c]\n    X_test_copy[c] = weights[i]*X_test_copy[c]\nfor i in range(10,14):\n    c = X_full.columns[i]\n    X_full_copy[c] = weights[10]*X_full_copy[c]\n    X_test_copy[c] = weights[10]*X_test_copy[c]\nfor i in range(14,len(X_full.columns)):\n    c = X_full.columns[i]\n    X_full_copy[c] = weights[11]*X_full_copy[c]\n    X_test_copy[c] = weights[11]*X_test_copy[c]","e7b01f00":"# Use first KNN model with n_neighbors=1\nmodel = KNeighborsClassifier(n_neighbors=1, p=1)\nmodel.fit(X_full_copy, y_full)\npreds_full = model.predict(X_full_copy)\ny_test = model.predict(X_test_copy)","9641536d":"# Put (X_full, y_full) and (X_test,y_test) together into big list (X_all, y_all)\nX_all = X_full_copy.append(X_test_copy)\ny_test = pd.Series(y_test)\ny_all = y_full.append(y_test)","8119e185":"# Use a second KNN model with lots of neighbors on big set\nmodel2 = KNeighborsClassifier(n_neighbors=101, p=1)\nmodel2.fit(X_all, y_all)\npreds_all = model2.predict(X_all)","65e6c79a":"# Recover just the test portion\nn_full = len(y_full)\npreds_test = preds_all[n_full:]","2592ae69":"# Make the submission file\noutput = pd.DataFrame({'Id': X_test_copy.index,'Cover_type': preds_test})\noutput.to_csv('submission.csv', index=False)","1d52bb17":"Here is the list of weights from [Nearest Neighbor kicks ass](https:\/\/www.kaggle.com\/chrisfreiling\/nearest-neighbor-kicks-ass).   The first ten are for the first ten features. The eleventh one is for the four \"Wilderness_Area\" features, and the last one is for all of the \"Soil_Type\" features.  If you are interested, see [Nearest Neighbor kicks ass](https:\/\/www.kaggle.com\/chrisfreiling\/nearest-neighbor-kicks-ass) for the code used to get this list. These weights need to be optimized better!  I believe a lot of improvement can be made here. ","e0da5b5e":"I think this is so cool, though probably well-known.  So I just had to share it.  The idea is to use KNN to correct some of its own errors.  First we copy the KNN model from [Nearest Neighbor kicks ass](https:\/\/www.kaggle.com\/chrisfreiling\/nearest-neighbor-kicks-ass).  This first model uses just one neighbor.  Then we see if it can self-improve by applying a second KNN on the train and test set together.  In training this second model, the labels on the test set are taken from the first model.  This second model uses lots of neighbors (because it is trained on lots more data).  The purpose of the second model is to smooth out the decision boundary from the first model.  It seems to work!  The accuracy went from .79817 to .80611.  Okay, not a huge improvement, but I still think it's pretty cool!  There is lots more to explore.  For example, what happens if we do it again?  Can we applly this to correct other models? etc."}}