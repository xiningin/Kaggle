{"cell_type":{"ff4cd536":"code","e4e45f99":"code","98d0af28":"code","faa5bb18":"code","53ca4fdd":"code","ffcdc15d":"code","f212b1c3":"code","70362021":"code","e2d480b5":"code","d2e9a679":"code","ed97dd7d":"code","f834f9d0":"code","ee8bb1af":"code","e9649c25":"code","fd16f709":"code","662afbf0":"markdown","65f5ffc2":"markdown","47fb283f":"markdown","b1f26ea3":"markdown","fad36ca1":"markdown","962abd97":"markdown","b7488680":"markdown"},"source":{"ff4cd536":"import gc\nimport os\nimport pandas as pd\nimport numpy as np\n\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\n\nfrom tqdm.autonotebook import tqdm\nimport pickle\n\nfrom transformers import *\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score\n\ndevice = torch.device('cuda')","e4e45f99":"class config:\n    TOKEN_ID_DIR = \"\/kaggle\/input\/aio-make-token-ids\"\n    SEED = 416\n    TRAIN_BATCH_SIZE = 2\n    VALID_BATCH_SIZE = 2\n    OPTIONS = 4\n    EPOCHS = 1\n    LEARNING_RATE = 1e-6\n    MODEL_TYPE = \"cl-tohoku\/bert-base-japanese\"","98d0af28":"with open(f\"{config.TOKEN_ID_DIR}\/train.pkl\", \"rb\") as f:\n    train = pickle.load(f)\nwith open(f\"{config.TOKEN_ID_DIR}\/dev1.pkl\", \"rb\") as f:\n    dev1 = pickle.load(f)\nwith open(f\"{config.TOKEN_ID_DIR}\/dev2.pkl\", \"rb\") as f:\n    dev2 = pickle.load(f)","faa5bb18":"class JaSQuADBert(nn.Module):\n    def __init__(self):\n        super(JaSQuADBert, self).__init__()\n\n        self.bert = BertModel.from_pretrained(config.MODEL_TYPE)\n        self.qa_outputs = nn.Linear(768, 2)\n\n    \n    def forward(self, ids, mask, token_type_ids):\n        out, _ = self.bert(\n            ids,\n            attention_mask=mask,\n            token_type_ids=token_type_ids\n        )\n        logits = self.qa_outputs(out)\n        \n        start_logits, end_logits = logits.split(1, dim=-1)\n\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits\n    \njasquad_model = JaSQuADBert()\njasquad_model.load_state_dict(torch.load(\"\/kaggle\/input\/jasquad-train-bert\/model_2.bin\", map_location=torch.device('cpu')))\ntorch.save(jasquad_model.bert.state_dict(), \"squad_weight.bin\")\ndel jasquad_model\n!ls","53ca4fdd":"class BertForAIO(nn.Module):\n    def __init__(self):\n        super(BertForAIO, self).__init__()\n\n        self.bert = AutoModel.from_pretrained(config.MODEL_TYPE)\n        self.bert.load_state_dict(torch.load(\"squad_weight.bin\", map_location=torch.device('cpu')))\n        \n        self.fc = nn.Linear(768, 1)\n\n        \n    def forward(self, ids, mask, token_type_ids):\n        n_choice = ids.shape[1]\n        \n        ids = ids.view(-1, ids.size(-1))\n        mask = mask.view(-1, mask.size(-1))\n        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n\n        _, h = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n        logits = self.fc(h)\n        logits = logits.view(-1, n_choice)\n\n        return logits","ffcdc15d":"class JaqketDataset:\n    def __init__(self, data, train=True):\n        self.data = data\n        self.train = train\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, item):\n        d = self.data[item]\n        if self.train:\n            return {'ids': torch.tensor(d[\"input_ids\"][:config.OPTIONS], dtype=torch.long),\n                    'mask': torch.tensor(d[\"attention_mask\"][:config.OPTIONS], dtype=torch.long),\n                    'token_type_ids': torch.tensor(d[\"token_type_ids\"][:config.OPTIONS], dtype=torch.long),\n                    'targets': torch.tensor(d[\"label\"], dtype=torch.long)}\n        else:\n            return {'ids': torch.tensor(d[\"input_ids\"], dtype=torch.long),\n                    'mask': torch.tensor(d[\"attention_mask\"], dtype=torch.long),\n                    'token_type_ids': torch.tensor(d[\"token_type_ids\"], dtype=torch.long),\n                    'targets': torch.tensor(d[\"label\"], dtype=torch.long)}","f212b1c3":"train_dataset = JaqketDataset(train, train=True)\ntrain_data_loader = DataLoader(train_dataset,\n                               batch_size=config.TRAIN_BATCH_SIZE,\n                               shuffle=True,\n                               drop_last=True,\n                               num_workers=2)\n\ndev1_dataset = JaqketDataset(dev1, train=False)\ndev1_data_loader = DataLoader(dev1_dataset,\n                              batch_size=config.TRAIN_BATCH_SIZE,\n                              shuffle=False,\n                              drop_last=False,\n                              num_workers=2)\n\ndev2_dataset = JaqketDataset(dev2, train=False)\ndev2_data_loader = DataLoader(dev2_dataset,\n                              batch_size=config.TRAIN_BATCH_SIZE,\n                              shuffle=False,\n                              drop_last=False,\n                              num_workers=2)","70362021":"model = BertForAIO()\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr=config.LEARNING_RATE)","e2d480b5":"trn_losses = []\nfor epoch in range(config.EPOCHS):\n    # \u5b66\u7fd2\n    model.train()\n    for d in tqdm(train_data_loader):\n        ids = d[\"ids\"].to(device, dtype=torch.long)\n        mask = d[\"mask\"].to(device, dtype=torch.long)\n        token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n        targets = d[\"targets\"].to(device, dtype=torch.long)\n        \n        model.zero_grad()\n        y_pred = model(ids, mask, token_type_ids)\n        loss = nn.CrossEntropyLoss()(y_pred, targets)\n        loss.backward()\n        optimizer.step()\n        trn_losses.append(loss.item())\n        \n    # \u8a55\u4fa1\n    model.eval()\n    dev1_scores, dev2_scores = [], []\n    with torch.no_grad(): \n        for d in tqdm(dev1_data_loader):\n            ids = d[\"ids\"].to(device, dtype=torch.long)\n            mask = d[\"mask\"].to(device, dtype=torch.long)\n            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n            targets = d[\"targets\"].to(device, dtype=torch.long).cpu().numpy()\n\n            y_pred = model(ids, mask, token_type_ids)\n            y_pred = y_pred.cpu().detach().numpy().argmax(1)\n            acc = accuracy_score(targets, y_pred)\n            dev1_scores.append(acc)\n        dev1_acc = sum(dev1_scores)\/len(dev1_scores)\n        \n        for d in tqdm(dev2_data_loader):\n            ids = d[\"ids\"].to(device, dtype=torch.long)\n            mask = d[\"mask\"].to(device, dtype=torch.long)\n            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n            targets = d[\"targets\"].to(device, dtype=torch.long).cpu().numpy()\n\n            y_pred = model(ids, mask, token_type_ids)\n            y_pred = y_pred.cpu().detach().numpy().argmax(1)\n            acc = accuracy_score(targets, y_pred)\n            dev2_scores.append(acc)\n        dev2_acc = sum(dev2_scores)\/len(dev2_scores)\n\n    print(f\"{epoch} epoch: dev1={dev1_acc} \/ dev2={dev2_acc}\")\n    torch.save(model.state_dict(), f\"aio_bert_epoch_{epoch}.bin\")","d2e9a679":"print(f\"{epoch} epoch: dev1={dev1_acc} \/ dev2={dev2_acc}\")","ed97dd7d":"plt.plot(trn_losses)","f834f9d0":"del train, train_dataset, train_data_loader\ndel dev1, dev1_dataset, dev1_data_loader\ndel dev2, dev2_dataset, dev2_data_loader\ngc.collect()","ee8bb1af":"df_aio_leaderboard = pd.read_json(f\"{config.TOKEN_ID_DIR}\/aio_leaderboard.json\", orient='records', lines=True)       \n\nwith open(f\"{config.TOKEN_ID_DIR}\/test.pkl\", \"rb\") as f:\n    test = pickle.load(f)\n    \ntest_dataset = JaqketDataset(test, train=False)","e9649c25":"predicts = []\nmodel.eval()\nwith torch.no_grad():\n    for idx, d in enumerate(test_dataset):\n        ids = d[\"ids\"].to(device, dtype=torch.long).unsqueeze(0)\n        mask = d[\"mask\"].to(device, dtype=torch.long).unsqueeze(0)\n        token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long).unsqueeze(0)\n        \n        y_pred = model(ids, mask, token_type_ids)\n        y_pred = y_pred.cpu().detach().numpy().argmax(1)\n\n        p = {\"qid\": df_aio_leaderboard.loc[idx, \"qid\"],\n             \"answer_entity\": df_aio_leaderboard.loc[idx, \"answer_candidates\"][y_pred[0]]}\n        predicts.append(p)\n\npd.DataFrame(predicts).to_json(f'lb_predict.jsonl', orient='records', force_ascii=False, lines=True)","fd16f709":"!head \"lb_predict.jsonl\"","662afbf0":"DataLoader\u306e\u5b9a\u7fa9","65f5ffc2":"# \u30af\u30a4\u30baAI\u738b BERT\u5b66\u7fd2notebook\n\u65e5\u672c\u8a9eSQuAD\u3092\u5b66\u7fd2\u3055\u305b\u305f\u91cd\u307f\u3092\u4f7f\u3046","47fb283f":"\u30ea\u30fc\u30c0\u30fc\u30dc\u30fc\u30c9\u30c7\u30fc\u30bf\u306e\u4e88\u6e2c","b1f26ea3":"\u65e5\u672c\u8a9eSQuAD\u3092\u5b66\u7fd2\u3055\u305b\u305f\u91cd\u307f\u3092\u8aad\u307f\u8fbc\u3080","fad36ca1":"\u5b66\u7fd2loss\u306e\u78ba\u8a8d","962abd97":"\u30e2\u30c7\u30eb\u3068Optimizer\u306e\u5b9a\u7fa9","b7488680":"\u5b66\u7fd2"}}