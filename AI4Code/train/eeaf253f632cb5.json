{"cell_type":{"0898ffb9":"code","75d039ae":"code","0cc365e3":"code","98dd0554":"code","f98d6e6d":"code","49cc2c51":"code","9311b075":"code","c98bacc1":"code","b45458a6":"code","7b7a382a":"code","b02bff5f":"code","73a88648":"code","3b6a3b85":"code","35ff326f":"code","af8f5d02":"code","7659c584":"code","9715cc6b":"code","239f1d16":"code","080c2717":"code","5c642041":"code","14806f06":"code","ba7ecd06":"code","c4cb6163":"code","da60eaf3":"code","27c1fcc9":"code","84dd0566":"code","3d510756":"code","445cbbdc":"code","b5fef384":"code","8f91f4ac":"code","2de75f8f":"code","6667acb6":"code","a5d07abe":"code","d33772b1":"code","78137792":"code","1ca161c5":"code","055ae592":"code","adc62b67":"code","6964834a":"code","ef3c4037":"code","3c9f272f":"code","d28940c2":"code","a63c1845":"code","b1d98b38":"code","a673804f":"code","6398aec8":"code","45d9f5e3":"code","603ee80b":"code","e3efab15":"code","554939ab":"code","ffd0dd05":"code","f9578c4a":"code","83bca201":"code","9cedf069":"markdown","4a1d805e":"markdown","4b398603":"markdown","7156a770":"markdown","e34264fb":"markdown","da9a8a1e":"markdown","e8d2af78":"markdown","a42488a5":"markdown","5c3cb68f":"markdown"},"source":{"0898ffb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75d039ae":"bank = pd.read_csv(r'\/kaggle\/input\/banksim1\/bs140513_032310.csv')","0cc365e3":"bank.head() # to get first five columns ","98dd0554":"bank.shape # shape (no.of rows,no.of columns)","f98d6e6d":"bank.info()  # information of a dataset","49cc2c51":"bank.describe()  # to count statistical value of numerical columns ","9311b075":"bank.isnull().sum() # gives information about null value in data set","c98bacc1":"bank.corr()  # to find correlation betweeen two numerical values ","b45458a6":"import seaborn as sns\nimport matplotlib.pyplot as plt  # import visualization module ","7b7a382a":"%matplotlib inline","b02bff5f":"print(bank['fraud'].value_counts())\nsns.countplot(x='fraud',data=bank)  # visualization of fraud transactions ","73a88648":"# groupby the categories and their respective transactions and fraud\nbank.groupby('category')[['amount','fraud']].sum() ","3b6a3b85":"# groupby the categories and their respective amount and fraud mean\nbank.groupby('category')[['amount','fraud']].mean()","35ff326f":"(bank.groupby('age')['fraud'].mean()*100).reset_index().sort_values(by='age' , ascending = False).rename(columns={'fraud':'fraud_percent'})","af8f5d02":"bank.head()","7659c584":"bank['zipcodeOri'].nunique() # no of unique values ","9715cc6b":"bank['zipMerchant'].nunique()","239f1d16":"# drop the column 'zipcodeOri',zipMerchant from the table \nbank.drop(['zipcodeOri','zipMerchant'],axis=1,inplace=True)","080c2717":"bank.shape","5c642041":"bank.head(3)","14806f06":"# to transform all the column which contains the object or string \ncol_categorical = bank.select_dtypes(include= ['object']).columns\nfor col in col_categorical:\n    bank[col] = bank[col].astype('category')\nbank[col_categorical] = bank[col_categorical].apply(lambda x: x.cat.codes)\nbank.head(5)","ba7ecd06":"# to divide the columns in x and y .iloc[row,column]\nX = bank.iloc[:,0:7]\ny = bank.iloc[:,-1]","c4cb6163":"# solving oversampling problem\nfrom imblearn.over_sampling import SMOTE","da60eaf3":"sm = SMOTE()\nX_res, y_res = sm.fit_resample(X, y)\ny_res = pd.DataFrame(y_res)","27c1fcc9":"#before oversampling\ny.value_counts()","84dd0566":"# after oversampling \ny_res.value_counts()","3d510756":"# train_test split\nfrom sklearn.model_selection import train_test_split","445cbbdc":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)","b5fef384":"X_train","8f91f4ac":"y_train","2de75f8f":"#scaling the value \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","6667acb6":"scaler.fit(X_train)","a5d07abe":"X_train_scaled = scaler.transform(X_train)","d33772b1":"X_test_scaled = scaler.transform(X_test)","78137792":"X_train_scaled = pd.DataFrame(X_train_scaled,columns=X_train.columns)","1ca161c5":"X_train_scaled","055ae592":"X_test_scaled = pd.DataFrame(X_test_scaled , columns=X_test.columns)","adc62b67":"X_test_scaled","6964834a":"y_train","ef3c4037":"y_test","3c9f272f":"# applying logistic model \nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()","d28940c2":"lr.fit(X_train_scaled,y_train)","a63c1845":"y_predict = lr.predict(X_test_scaled)","b1d98b38":"y_predict","a673804f":"print(X_test.shape)\nprint(y_predict.shape)","6398aec8":"# Evaluation metrics \nfrom sklearn.metrics import confusion_matrix,classification_report","45d9f5e3":"print(\"Classification Report for logistic regresssion : \\n\", classification_report(y_test, y_predict))","603ee80b":"print(confusion_matrix(y_test,y_predict))","e3efab15":"# kneigborsclassifier\nfrom sklearn.neighbors import KNeighborsClassifier","554939ab":"knn = KNeighborsClassifier(n_neighbors=5,p=1)","ffd0dd05":"knn.fit(X_train_scaled,y_train)","f9578c4a":"y_predict = knn.predict(X_test_scaled)","83bca201":"print(\"Classification Report for K-Nearest Neighbours: \\n\", classification_report(y_test, y_predict))\nprint(\"Confusion Matrix of K-Nearest Neigbours: \\n\", confusion_matrix(y_test,y_predict)) ","9cedf069":"**Import the Data**","4a1d805e":"**Train Test split**","4b398603":"**Transformation**","7156a770":"**Standardization**","e34264fb":"**Oversampling**","da9a8a1e":"**Visualization of fraud transaction**","e8d2af78":"**Classification report for logistic Regression**","a42488a5":"**Logistic Regression**","5c3cb68f":"**KNeighborsClassifier**"}}