{"cell_type":{"7f2bce87":"code","a92c0b2b":"code","f287a419":"code","24797740":"code","e5878699":"code","8ae01681":"code","6f6539a5":"code","23683db3":"code","bc043884":"code","5ee58124":"code","95159f33":"code","5cabb823":"code","cf141da4":"code","f171b075":"code","137bc76b":"code","2d6f8459":"code","4cfb7f6a":"code","3664f8bc":"code","dc673652":"code","bf102ce3":"code","d1bfa831":"code","2d49d0b0":"code","e91c5dde":"code","86c1420a":"code","346291b3":"code","2cc9ab40":"code","3653c00b":"code","33bbb2d9":"code","590d7d23":"code","031858d8":"code","db2be2ab":"code","71e403f3":"code","07faf955":"code","3f3eb329":"code","f6f6feb8":"code","0a64abe4":"code","4de044d2":"code","02015575":"code","c1d8c85b":"code","03da55ce":"code","1de8185c":"code","3e55f503":"code","05d1f490":"code","7628c303":"code","67714f08":"code","31cd1c29":"code","aaab7900":"code","1eb6ddc8":"code","f745e5e6":"code","5a9a96be":"markdown","9126345f":"markdown","f5990c81":"markdown","408056dc":"markdown","7d954c1a":"markdown","a4dc3b21":"markdown","0f56a3b6":"markdown","dc84bc18":"markdown","991e60a0":"markdown","62ac39d2":"markdown","87127910":"markdown","8e7e721d":"markdown","269af128":"markdown","8ef39b7a":"markdown","4b9f55e5":"markdown","093d4b7d":"markdown","640f3f16":"markdown","acab2b45":"markdown","a6646687":"markdown","2eb6e0b9":"markdown"},"source":{"7f2bce87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a92c0b2b":"import numpy as np \nimport pandas as pd\ntrain= pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ntrain.head()","f287a419":"test = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv')\ntest.head()","24797740":"train.shape","e5878699":"test.shape","8ae01681":"train.info()","6f6539a5":"test.info()","23683db3":"train.columns","bc043884":"train.describe(include='all')","5ee58124":"train.isnull().sum()","95159f33":"def fill_with_mode(dataframe, colname):\n    mode = dataframe[colname].mode()[0]\n    dataframe[colname].fillna(mode, inplace=True)\nfor i in train.select_dtypes(include='object').columns:\n    fill_with_mode(train,i)\nfor j in test.select_dtypes(include='object').columns:\n    fill_with_mode(test,j)","5cabb823":"def fill_with_median(dataframe, colname):\n    mode = dataframe[colname].mode()[0]\n    dataframe[colname].fillna(mode, inplace=True)\nfor i in train.select_dtypes(include=['float64', 'int64']).columns:\n    fill_with_median(train,i)\nfor j in test.select_dtypes(include=['float64', 'int64']).columns:\n    fill_with_median(test,j)","cf141da4":"train.isnull().sum()","f171b075":"test.isnull().sum()","137bc76b":"import matplotlib.pyplot as plt\nimport seaborn as sns","2d6f8459":"plt.figure(figsize=[18,20])\nvariables= ['gender',\n       'relevent_experience', 'enrolled_university', 'education_level',\n       'major_discipline', 'experience', 'company_size', 'company_type',\n       'last_new_job']\ntotal = float(len(train))\nn=1\nfor v in variables:\n    plt.subplot(3,3,n)\n    ax=sns.countplot(x = v, data = train,hue='target', alpha=0.7, edgecolor='black', palette='pastel')\n    sns.set(style=\"whitegrid\")\n    plt.subplots_adjust(hspace=0.3)\n    plt.title('distribution of unique values of {} with target'.format(v))\n    plt.xticks(fontsize=8)\n    plt.subplots_adjust(wspace=0.3)\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()\/total)\n        x = p.get_x() + p.get_width()\n        y = p.get_height()\n        ax.annotate(percentage, (x, y),ha='center')\n    n=n+1\n    plt.tight_layout()\n    sns.despine()\n\nplt.show()\n","4cfb7f6a":"\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.figure(figsize=[12,4])\nsns.distplot(train['city_development_index'], color='red')\nplt.title('Distribution of City Development Index')\nplt.show()","3664f8bc":"plt.figure(figsize=[30,10])\nsns.countplot(x='city', data=train)\nplt.title('Countplot of unique values of city')\nplt.xticks(rotation=90)\nplt.show()","dc673652":"plt.figure(figsize=[30,10])\nsns.barplot(data=train, x='city', y='city_development_index')\nplt.xticks(rotation=90)\nplt.show()","bf102ce3":"plt.figure(figsize=[30,10])\nsns.distplot(train['training_hours'])\nplt.title('Countplot of unique values of training hours', fontsize='30')\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nplt.show()","d1bfa831":"plt.figure(figsize=(20,1))\nsns.heatmap(train.corr().sort_values(by = ['target'], ascending = False).head(1), cmap='coolwarm', annot=True, annot_kws={'size': 8}, fmt = '.2f')\n\nplt.title('Correlation of Numerical Features with the Target', weight = 'bold', fontsize = 18)\nplt.xticks(weight='bold')\nplt.yticks(weight='bold', color='dodgerblue', rotation=0)\n\nplt.show()","2d49d0b0":"sns.boxplot(x='target', y='city_development_index', data=train)\nplt.show()","e91c5dde":"sns.boxplot(x='target', y='training_hours', data=train)\nplt.show()","86c1420a":"# Making Dictionaries of ordinal features\n\ngender_map = {\n        'Female': 2,\n        'Male': 1,\n        'Other': 0\n         }\n\nrelevent_experience_map = {\n    'Has relevent experience':  1,\n    'No relevent experience':    0\n}\n\nenrolled_university_map = {\n    'no_enrollment'   :  0,\n    'Full time course':    1, \n    'Part time course':    2 \n}\n    \neducation_level_map = {\n    'Primary School' :    0,\n    'Graduate'       :    2,\n    'Masters'        :    3, \n    'High School'    :    1, \n    'Phd'            :    4\n    } \n    \nmajor_map ={ \n    'STEM'                   :    0,\n    'Business Degree'        :    1, \n    'Arts'                   :    2, \n    'Humanities'             :    3, \n    'No Major'               :    4, \n    'Other'                  :    5 \n}\n    \nexperience_map = {\n    '<1'      :    0,\n    '1'       :    1, \n    '2'       :    2, \n    '3'       :    3, \n    '4'       :    4, \n    '5'       :    5,\n    '6'       :    6,\n    '7'       :    7,\n    '8'       :    8, \n    '9'       :    9, \n    '10'      :    10, \n    '11'      :    11,\n    '12'      :    12,\n    '13'      :    13, \n    '14'      :    14, \n    '15'      :    15, \n    '16'      :    16,\n    '17'      :    17,\n    '18'      :    18,\n    '19'      :    19, \n    '20'      :    20, \n    '>20'     :    21\n} \n    \ncompany_type_map = {\n    'Pvt Ltd'               :    0,\n    'Funded Startup'        :    1, \n    'Early Stage Startup'   :    2, \n    'Other'                 :    3, \n    'Public Sector'         :    4, \n    'NGO'                   :    5\n}\n\ncompany_size_map = {\n    '<10'          :    0,\n    '10\/49'        :    1, \n    '100-500'      :    2, \n    '1000-4999'    :    3, \n    '10000+'       :    4, \n    '50-99'        :    5, \n    '500-999'      :    6, \n    '5000-9999'    :    7\n}\n    \nlast_new_job_map = {\n    'never'        :    0,\n    '1'            :    1, \n    '2'            :    2, \n    '3'            :    3, \n    '4'            :    4, \n    '>4'           :    5\n}","346291b3":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder","2cc9ab40":"# Transforming Categorical features into numerical features\n\ntrain.loc[:,'education_level'] = train['education_level'].map(education_level_map)\ntrain.loc[:,'company_size'] = train['company_size'].map(company_size_map)\ntrain.loc[:,'company_type'] = train['company_type'].map(company_type_map)\ntrain.loc[:,'last_new_job'] = train['last_new_job'].map(last_new_job_map)\ntrain.loc[:,'major_discipline'] = train['major_discipline'].map(major_map)\ntrain.loc[:,'enrolled_university'] = train['enrolled_university'].map(enrolled_university_map)\ntrain.loc[:,'relevent_experience'] = train['relevent_experience'].map(relevent_experience_map)\ntrain.loc[:,'gender'] = train['gender'].map(gender_map)\ntrain.loc[:,'experience'] = train['experience'].map(experience_map)\n\n#encoding city feature using label encoder\nlb_en = LabelEncoder()\n\ntrain.loc[:,'city'] = lb_en.fit_transform(train.loc[:,'city']) \ntrain.drop(['enrollee_id'], axis=1, inplace=True)","3653c00b":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.barplot(data=train, x='gender', y='relevent_experience')\nplt.title('Barplots of gender vs relevent experience')\nplt.subplot(1,2,2)\nsns.barplot(data=train, x='gender', y='relevent_experience', hue='target')\nplt.title('Distribution on the basis of target')\n\nplt.show()","33bbb2d9":"total = float(len(train))\nplt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.barplot(data=train, x='gender', y='enrolled_university')\nplt.title('Barplot of gender vs enrolled in university')\nplt.subplot(1,2,2)\nsns.barplot(data=train, x='gender', y='enrolled_university', hue='target')\nplt.title('distribution on the basis of target')\n\nplt.show()","590d7d23":"total = float(len(train))\nplt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.barplot(data=train, x='education_level', y='relevent_experience')\nplt.title('barplot of education level vs relevent experience')\nplt.subplot(1,2,2)\nsns.barplot(data=train, x='education_level', y='relevent_experience', hue='target')\nplt.title('distribution on the basis of target')\n\nplt.show()","031858d8":"total = float(len(train))\nplt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.barplot(data=train, y='training_hours', x='gender')\nplt.subplot(1,2,2)\nsns.barplot(data=train, y='training_hours', x='gender', hue='target')\n\nplt.show()","db2be2ab":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","71e403f3":"sns.countplot(x='target', data=train)\nplt.show()","07faf955":"from imblearn.over_sampling import SMOTE","3f3eb329":"X = train.drop(\"target\", axis=1)\ny = train[\"target\"]","f6f6feb8":"oversample = SMOTE()\nsmote = SMOTE(random_state = 0)\nX_smote, y_smote = smote.fit_resample(X,y)","0a64abe4":"plt.figure(figsize=(6, 4))\nsns.barplot(y_smote.value_counts().index.astype(int),\n            y_smote.value_counts().values, palette='bwr')\nplt.ylabel('Number of rows', fontsize=12)\nplt.xlabel('Target', fontsize=12)\nplt.title('After sampling')\nplt.show()","4de044d2":"X_train, X_test, y_train, y_test = train_test_split(X_smote,\n                                                    y_smote,\n                                                    test_size=0.2,\n                                                    random_state=42)","02015575":"gb = GaussianNB()\ngb.fit(X_smote,y_smote)\nprint(classification_report(y_smote, gb.predict(X_smote)))","c1d8c85b":"print(gb.score(X_smote, y_smote))","03da55ce":"lr = LogisticRegression()\nlr.fit(X_smote,y_smote)\nprint(classification_report(y_smote, lr.predict(X_smote)))","1de8185c":"print(lr.score(X_smote, y_smote))","3e55f503":"rfc = RandomForestClassifier()\nrfc.fit(X_smote,y_smote)\nprint(classification_report(y_smote, rfc.predict(X_smote)))","05d1f490":"print(rfc.score(X_smote, y_smote))","7628c303":"# Transforming Categorical features into numerical features\n\ntest.loc[:,'education_level'] = test['education_level'].map(education_level_map)\ntest.loc[:,'company_size'] = test['company_size'].map(company_size_map)\ntest.loc[:,'company_type'] = test['company_type'].map(company_type_map)\ntest.loc[:,'last_new_job'] = test['last_new_job'].map(last_new_job_map)\ntest.loc[:,'major_discipline'] = test['major_discipline'].map(major_map)\ntest.loc[:,'enrolled_university'] = test['enrolled_university'].map(enrolled_university_map)\ntest.loc[:,'relevent_experience'] = test['relevent_experience'].map(relevent_experience_map)\ntest.loc[:,'gender'] = test['gender'].map(gender_map)\ntest.loc[:,'experience'] = test['experience'].map(experience_map)\n\n#encoding city feature using label encoder\nlb_en = LabelEncoder()\n\ntest.loc[:,'city'] = lb_en.fit_transform(test.loc[:,'city']) ","67714f08":"test.head()","31cd1c29":"df_test=test.drop([\"enrollee_id\"], axis=1)","aaab7900":"predictions=rfc.predict(df_test.values)","1eb6ddc8":"#Create a  DataFrame\nsubmission = pd.DataFrame({'enrollee_id':test['enrollee_id'],'target':predictions})\n                        \n\n#Visualize the first 10 rows\nsubmission.head(10)","f745e5e6":"filename = 'submission.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","5a9a96be":"## 3. Do some EDA now","9126345f":"#### So Data Scientists living in the cities with higher CDI are less likely to change their jobs.","f5990c81":"#### here 0:primary school, 1: high school, 2: graduate, 3: masters, 4: phd","408056dc":"### Now the data is balanced. ","7d954c1a":"### Distribution of unique values of all the features on the basis of target --->","a4dc3b21":"## Since the data is imbalanced, we are going to use SMOTE--->","0f56a3b6":"### Heatmap of numerical features with target --->","dc84bc18":"## 5. Modelling","991e60a0":"### Features\nenrollee_id : Unique ID for enrollee\n\ncity: City code\n\ncitydevelopmentindex: Developement index of the city (scaled)\n\ngender: Gender of enrolee\n\nrelevent_experience: Relevent experience of enrolee\n\nenrolled_university: Type of University course enrolled if any\n\neducation_level: Education level of enrolee\n\nmajor_discipline :Education major discipline of enrolee\n\nexperience: Enrolee total experience in years\n\ncompany_size: No of employees in current employer's company\n\ncompany_type : Type of current employer\n\nlastnewjob: Difference in years between previous job and current job\n\ntraining_hours: training hours completed\n\ntarget: 0 \u2013 Not looking for job change, 1 \u2013 Looking for a job change","62ac39d2":"## 2. Checking for missing values","87127910":" ## 1. Let's read the data first ","8e7e721d":"## 4. Let's encode our categorical features using Label Encoder","269af128":"## Now we are good to go with no more missing values :)","8ef39b7a":"#### Training hours does not effect the probability of changing the job","4b9f55e5":"## Let's gather some more knowledge about our dataset","093d4b7d":"#### Here 0: others, 1: males, 2: females.","640f3f16":"# Let's predict which Data Scientist is going to change his job in future???","acab2b45":"## Let's fill the categorical values with mode and numerical values with median","a6646687":"## So these are the features--->","2eb6e0b9":"### Some more EDA --->"}}