{"cell_type":{"61ffb911":"code","e5d21dfd":"code","e2d69c9b":"code","8b756d3c":"code","a6725ff8":"code","0c0c9f6f":"code","3ed8cb24":"code","54c4301c":"code","54255c75":"code","421f981c":"code","d813180e":"code","db1ecccc":"code","0e490def":"code","1d0347d7":"code","387857b1":"code","57cd01d4":"code","a63f71de":"code","7ba6b3cb":"code","fd3780a2":"code","b01d667c":"code","93b4af5d":"code","f0849a47":"code","216aeaee":"code","10fae2a8":"code","a44f4e04":"code","b5c5367f":"code","665d073c":"code","184a29e1":"code","51cc71ad":"code","18b9be51":"code","908c0b63":"code","ad071425":"code","3ceb86ec":"code","1b4885f5":"code","a879d978":"markdown","ac23f366":"markdown","6a967723":"markdown","a4a3db4f":"markdown","61d2f480":"markdown","e84b49be":"markdown","c08d519c":"markdown","31d659cc":"markdown","0b37c263":"markdown","be78b1a3":"markdown","dd6f2dc0":"markdown","4b390148":"markdown","de9995ad":"markdown","2d28296b":"markdown","49a0558e":"markdown","b5b24724":"markdown","d6f046cf":"markdown"},"source":{"61ffb911":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plot\nimport seaborn as sos\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import normalize\nfrom scipy.stats import boxcox, probplot, norm, shapiro\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom time import time","e5d21dfd":"#ANN Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout","e2d69c9b":"import seaborn as sns\nimport matplotlib.pyplot as plt","8b756d3c":"df = pd.read_csv('..\/input\/bankadditionalfullcsv\/bank-additional-full.csv', sep=';')\ndf.columns = ['age', 'job', 'marital', 'education', 'credit', 'housing', 'loan','contact', 'month', 'day_of_week',\n              'duration', 'campaign', 'pdays','previous', 'poutcome', 'emp.var.rate', 'cons.price.idx','cons.conf.idx',\n              'euribor3m', 'nr.employed', 'subscribed']\ndf.head()","a6725ff8":"df.isnull().sum()","0c0c9f6f":"#The number of Subscribes users - Binary Yes\/No, Checking balanced Dataset\nplt.rcParams['figure.figsize']=15,5\nplt.subplot(121)\nplt.title('Checking balance of Dataset', fontsize=10)\ns = sns.countplot(x=\"subscribed\", data=df, alpha=0.7)\nfor p in s.patches:\n    s.annotate(format(p.get_height(), '.1f'), \n               (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                ha = 'center', va = 'center', \n                xytext = (0, 4), \n                textcoords = 'offset points')\n\n\nax = plt.subplot(122)\nmush_classpie = df['subscribed'].value_counts()\nmush_size = mush_classpie.values.tolist()\nmush_types = mush_classpie.axes[0].tolist()\nmush_labels = 'No', 'Yes'\ncolors = ['#BCC6CC', '#00FFFF']\nplt.title('Subscribed Status In Percentange', fontsize=10)\npatches, texts, autotexts = plt.pie(mush_size, labels=mush_labels, colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=150)\nfor text,autotext in zip(texts,autotexts):\n    text.set_fontsize(14)\n    autotext.set_fontsize(14)\n\nplt.axis('equal')  \nplt.show()","3ed8cb24":"#barplot of job with bars split by education\n#pivot table to get jobs as index and education as column. count of 'age' are the values\ndf_pivot = pd.pivot_table(df,columns='education', index='job', aggfunc='count',values='age')\ndf_pivot.plot(kind='bar',stacked=True, figsize=(15,8), alpha=0.75)\nplt.title('Jobwise count of people\/ Bar split Education level')\nplt.ylabel('---Count---')\nplt.xlabel('---Job---')","54c4301c":"\nf, axes = plt.subplots(4,1, figsize=(17,10), sharey = True) \nnum_col = ['contact', 'loan', 'credit', 'housing']\n\nfor j,col in enumerate(num_col):\n    cols = df[col].value_counts()\n    pop_size = cols.values.tolist()\n    pop_types = cols.axes[0].tolist()\n    poisonous_pop = [] \n    edible_pop = []   \n    for pop in pop_types: \n        size = len(df[df[col] == pop].index)\n        edibles = len(df[(df[col] == pop) & (df['subscribed'] == 'yes')].index)\n        edible_pop.append(edibles)\n        poisonous_pop.append(size-edibles)\n    combine_ed_poi = []\n    for i in range(0,len(edible_pop)):\n        combine_ed_poi.append(edible_pop[i])\n        combine_ed_poi.append(poisonous_pop[i])\n\n    #Double pie chart.\n    plt.subplot(2,2,j+1)\n    plt.title(col)\n    #Outer Pie Chart\n    patches1, texts1 = plt.pie(combine_ed_poi,radius = 4.5,labels= combine_ed_poi,\n                                    colors=['#C4F6F5','#F6EEC4'], shadow=True, labeldistance= 1.1)\n    for i in range(0,len(texts1)):\n        if(i%2==0):\n            texts1[i].set_color('blue')\n        else:\n            texts1[i].set_color('red')\n    for aut in texts1:\n        aut.set_fontsize(9)\n    #Inner Pie Chart\n    patches2, texts2, autotexts2 = plt.pie(pop_size, radius = 3.5,\n            autopct='%1.2f%%', shadow=True, labeldistance= 4.2)\n    for aut in autotexts2:\n        aut.set_fontsize(10)\n        aut.set_horizontalalignment('center')\n    #Set 2 Legends to the plot.\n    first_legend   = plt.legend(patches1, ['Yes','No'], loc=\"upper left\", fontsize=10)\n    second_ledgend = plt.legend(patches2, pop_types, loc=\"best\",fontsize=8)\n    plt.gca().add_artist(first_legend)\n    plt.axis('equal')\nplt.show()","54255c75":"def absolute_value(val,month):\n    a = round(val*sum(df[df['month']==month].subscribed.value_counts())\/100,0)\n    return a","421f981c":"fig, axs = plt.subplots(2,5,figsize=(20,8))\nplot_dict=dict(zip(range(0,10),[axs[0,0],axs[0,1],axs[0,2],axs[0,3],axs[0,4],\n                     axs[1,0],axs[1,1], axs[1,2], axs[1,3], axs[1,4]]))\n\n#enumerate returns tuple of month and a number(idx)\nfor idx, month in enumerate(['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']):\n    #gets axes from dict and plots on it\n    plot_dict.get(idx).pie(df[df['month']==month].subscribed.value_counts(),\n             labels=df[df['month']==month].subscribed.value_counts().index, autopct=lambda val: absolute_value(val,month))\n    plot_dict.get(idx).set_title(month)","d813180e":"df.select_dtypes('object').info()","db1ecccc":"dict_job = {\n    \"job\":{\n        \"housemaid\":1,\n        \"unemployed\":0,\n        \"entrepreneur\":4,\n        \"blue-collar\":1,\n        \"services\":3,\n        \"admin.\":2,\n        \"technician\":2,\n        \"retired\":1,\n        \"management\":4,\n        \"self-employed\":3,\n        \"unknown\":1,\n        \"student\":0.5\n    }}\ndict_education = {\n    \"education\":{\n        \"basic.4y\":1,\n        \"basic.6y\":1,\n        \"basic.9y\":1,\n        \"high.school\":1,\n        \"professional.course\":2,\n        \"university.degree\":2,\n        \"illiterate\":0.9,\n        \"unknown\":0.9\n    }}\n\ndict_poutcome = {\n    \"poutcome\":{\n        \"nonexistent\":0,\n        \"failure\":0,\n        \"success\":1\n    }}\ndict_y = {\n    \"subscribed\":{\n        \"no\":0,\n        \"yes\":1\n    }}","0e490def":"for i in [dict_poutcome,dict_y, dict_education, dict_job]:\n    df.replace(i,inplace=True)","1d0347d7":"df.head()","387857b1":"#Encoding rest of the un ordinal categorical variable \nlc_X1 = LabelEncoder()\nlst = ['marital','credit','housing','loan']\n\nfor i in lst:\n    df[i] = lc_X1.fit_transform(df[i])","57cd01d4":"df_1 = pd.get_dummies(df,\n                      columns=['marital','credit','housing','loan'],\n                      drop_first=True)\ndf.head()","a63f71de":"corr = df_1.corr()\nprint(corr['subscribed'].sort_values(axis=0, ascending=True))","7ba6b3cb":"# Let's Remove features that has less correlation\ndf_1.drop(columns=[\n    'nr.employed','pdays','euribor3m','emp.var.rate',\n    'cons.price.idx','contact','month','campaign', 'day_of_week'\n    ], axis=0, inplace=True)","fd3780a2":"mask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(15,12))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n#Drawing heatmap\nsns.heatmap(corr, \n            mask=mask,\n            cmap=cmap, \n            vmax=1, \n            center=0.5, \n            square=True, \n            linewidths=.5, \n            cbar_kws={\"shrink\": .6},\n            annot=True\n           )\nplt.title(\"Correlation\", fontsize =10)","b01d667c":"X = df_1.drop(columns = 'subscribed',axis=1).values\ny = df_1['subscribed'].values ","93b4af5d":"#split training - test set\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)","f0849a47":"df_1['subscribed'].value_counts()","216aeaee":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","10fae2a8":"# We are using this function to calculate the accuracy, precision, recall, f1_score etc.\n# Hyperparams: model = string, labels = y, pred = model.pred(y)\ndef print_scores(model, labels, pred):\n    # Confusion matrix\n    accuracy = round(accuracy_score(labels, pred), 3)\n    precision = round(precision_score(labels, pred), 3)    \n    recall = round(recall_score(labels, pred), 3)\n    f1 = round(f1_score(labels, pred), 3)\n    \n    cm = confusion_matrix(labels, pred)\n    df = pd.DataFrame(cm)\n    \n    labels = [f\"TP: {df[0][0]} \",f\"TN: {df[1][1]} \",f\"FP: {df[1][0]} \",f\"FN: {df[0][1]} \"]\n    labels = np.asarray(labels).reshape(2,2)\n    \n    f, ax = plt.subplots(figsize=(6,5))\n    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', ax=ax)    \n    print(f\"{model}:: Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, f1_score: {f1}\")","a44f4e04":"# print the cross-validation results\ndef print_cv_result(results):\n    print(f\"Best Params : {results.best_params_}\\n\")\n    \n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    \n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print(f'{round(mean, 3)} (+\/-{round(std * 2, 3)}) for {params}')","b5c5367f":"start = time()\nsvc = SVC(kernel = \"rbf\", C=10)\nsvc.fit(X_train,y_train)\ny_pred_svm = svc.predict(X_test)\nend = time()\nprint(f\"SVM Time:{round((end - start), 5) * 1000}\")\nprint_scores(\"SVM\", y_test, y_pred_svm)","665d073c":"lgr = LogisticRegression()\nlgr.fit(X_train, y_train)\ny_pred_lgr = lgr.predict(X_test)\nprint_scores(\"LGR\", y_test, y_pred_lgr)","184a29e1":"classifier = Sequential()\nprint(df_1.shape)","51cc71ad":"classifier.add(Dense(units=13,\n                     activation='relu',\n                     kernel_initializer='uniform',\n                     input_dim=16))\nclassifier.add(Dropout(rate=0.1))","18b9be51":"classifier.add(Dense(units=13,\n                     activation='relu',\n                     kernel_initializer='uniform'))\nclassifier.add(Dropout(rate=0.1))","908c0b63":"classifier.add(Dense(units=1,\n                     activation='sigmoid',\n                     kernel_initializer='uniform'))","ad071425":"#compile ANN\nclassifier.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy'])","3ceb86ec":"#fitting ANN\nstart = time()\nclassifier.fit(x=X_train, y=y_train, batch_size=10,epochs=100)","1b4885f5":"y_pred_ann = classifier.predict(X_test)\nend = time()\nprint(f\"ANN Time:{round((end - start), 5) * 1000}\")\n\"\"\"\ny_pred array contains boolean value of whether dependent variable has more than 50% chance of being \u2018yes\u2019 or not.\n\nIf \u2018yes\u2019 it will be True, if \u2018no\u2019 it will be \u2018False\u2019.\n\"\"\"\ny_pred_ann_bool = y_pred_ann > 0.5\n\nprint_scores(\"ANN\", y_test, y_pred_ann_bool)","a879d978":"### Problem\n\n**Our goal is to predict , when customer service representative call the customer, will they subscribe for a bank term deposit or not?**\n\n**Dataset : https:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing**\n\n### Team\n\n* [Ankur Rokad](https:\/\/github.com\/ankurrokad)\n* [Sahista Patel](https:\/\/github.com\/Sahista-Patel)\n* [Murali Krishna](https:\/\/github.com\/muralikrishnarar)\n* [Gursanjam Kaur](https:\/\/github.com\/sv2021)\n\n\n","ac23f366":"# Printing Results","6a967723":"## Splitting the data and Scaling","a4a3db4f":"## Checking the correlation ","61d2f480":"##### Configuring the layers\n* units \u2014 number of nodes for the layer\n* activation \u2014 activation function we use hidden layers\n* kernel_initializer \u2014 initiating weight as close as 0\n* input_dim \u2014 number of independent variable in our dataset\n\n<!-- ![img](https:\/\/miro.medium.com\/max\/4200\/1*GTLzJ0sUmwDPb9uVffnZ6g.png) -->","e84b49be":"# Logistic Regression","c08d519c":"## EDA","31d659cc":"*We dont have any null values, so no need to do any imputation or anything*","0b37c263":"# Pre processing","be78b1a3":"## Assign Variable","dd6f2dc0":"# ANN","4b390148":"# References","de9995ad":"# Dataset Discription\n\n### User Details:\n\n1 - age (numeric)\n\n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n\n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n\n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n\n5 - default: has credit in default? (categorical: 'no','yes','unknown')\n\n6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n\n7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n\n### Related with the last contact of the current campaign:\n8 - contact: contact communication type (categorical: 'cellular','telephone')\n\n9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n\n10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n\n11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n\n### Other attributes:\n12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n\n13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n\n14 - previous: number of contacts performed before this campaign and for this client (numeric)\n\n15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n\n### Social and economic context attributes\n16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n\n17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n\n18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n\n19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n\n20 - nr.employed: number of employees - quarterly indicator (numeric)\n\n### Output variable (desired target):\n21 - y - has the client subscribed a term deposit? (binary: 'yes','no')","2d28296b":"# SVM","49a0558e":"* Activation Function : https:\/\/www.analyticsvidhya.com\/blog\/2020\/01\/fundamentals-deep-learning-activation-functions-when-to-use-them\/\n* Keras : https:\/\/medium.com\/datadriveninvestor\/building-neural-network-using-keras-for-classification-3a3656c726c1\n* Confusion Matrix : https:\/\/towardsdatascience.com\/accuracy-precision-recall-or-f1-331fb37c5cb9","b5b24724":"#####  Training and testing\n\n* batch_size \u2014 number of sample it takes for each iteration\n* epochs \u2014 number of iteration to optimise the model","d6f046cf":"## Label Encoding"}}