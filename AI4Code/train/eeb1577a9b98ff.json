{"cell_type":{"56d3f4a4":"code","f210a820":"code","832ee0a6":"code","5c0b48a5":"code","11587647":"code","69ca3a61":"code","44099126":"code","1b5e449e":"code","851e8325":"code","dda7213b":"code","f45b2874":"code","7ba44219":"code","dc936d4b":"code","f39a74aa":"code","42c559fa":"markdown","7a73b0c1":"markdown"},"source":{"56d3f4a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f210a820":"X_train_full = pd.read_csv(\"..\/input\/home-data-for-ml-course\/train.csv\", index_col='Id')\nX_test_full = pd.read_csv(\"..\/input\/home-data-for-ml-course\/test.csv\", index_col='Id')\nprint(X_train_full.shape, X_test_full.shape)\nprint(X_train_full.columns)\nprint(X_test_full.columns)","832ee0a6":"# drop rows with missing targets, extract target to y, drop target from predictors\nX_full = X_train_full.copy(deep=True)\n\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\nyhat = X_full.SalePrice.mean()\nysig = X_full.SalePrice.std()\nboolcond = (X_full.SalePrice > yhat + 6*ysig) \nprint('Dropping the following rows\\n',X_full.loc[X_full[boolcond].index,'SalePrice'])\n\nX_full.drop(X_full[X_full.SalePrice > yhat + 6*ysig].index,inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\nprint(X_train_full.shape)\nprint(X_full.shape)","5c0b48a5":"ylog = np.log(y)\nplt.hist(ylog,bins=10)","11587647":"# print(X_full.loc[list(np.where(y_pred>6e5)[0]),:])\n# print(X_full_preproc[list(np.where(y_pred>6e5)[0]),:])\ncoldrop = []\nnr = X_full.shape[0]\nfor col in  X_full.columns:\n    if X_full[col].isnull().sum()>0:\n        print(col,'\\t',X_full[col].isnull().sum(),'\\t',np.round(X_full[col].isnull().sum()\/nr,3),'\\t',X_full[col].nunique(),'\\t',X_full[col].dtype)\n    if X_full[col].isnull().sum()\/nr > 0.7:\n        coldrop.append(col)\n\nprint(coldrop)\ncolkeep = list(set(X_full.columns)-set(coldrop))\nprint(colkeep, len(colkeep))","69ca3a61":"# extract out categorical and numerical columns\ncat_col = [col for col in colkeep if X_full[col].dtype == 'object' and X_full[col].nunique() < 30 and 'Qu' not in col]\nprint(len(cat_col),cat_col)\nnumcolpop=['MSSubClass','YrSold','MoSold','MiscVal','3SsnPorch','ScreenPorch','PoolArea','LowQualFinSF','BsmtHalfBath','BsmtFinSF2','EnclosedPorch']\nnum_col = [col for col in colkeep if X_full[col].dtype in [\"int64\", \"float64\"] and col not in numcolpop]\nprint(len(num_col), num_col)","44099126":"with pd.option_context('display.max_columns', 40):\n    print(X_full[cat_col].describe(include=['object']))","1b5e449e":"# for col in cat_col:\n#     if 'Qu' in col:\n#         print(col,X_full[col].unique())","851e8325":"import seaborn as sns\n\nfig = plt.figure(figsize=(30,30))\nax = fig.gca()\nX_full.hist(ax=ax, bins=40)","dda7213b":"fig = plt.figure(figsize=(30,30))\nfeattar = ['SalePrice']\nfeat= []\nfor col in cat_col:\n    feat.append(col)\n    feattar.append(col)\nfor col in num_col:\n    feat.append(col)\n    feattar.append(col)\nprint(feat)\nsns.heatmap(X_train_full[feattar].corr(),annot=True,cmap='coolwarm')","f45b2874":"# imput and encode\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nnum_trans = Pipeline(steps=[\n    (\"imputer\",SimpleImputer(strategy=\"mean\")),\n    (\"normalize\", StandardScaler())\n    ])\ncat_trans = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encoder\",OneHotEncoder(handle_unknown=\"ignore\", sparse=False))])\npreproc = ColumnTransformer(transformers=[(\"num\", num_trans, num_col),(\"cat\",cat_trans, cat_col)]) \n\nX_full_preproc = preproc.fit_transform(X_full[feat])\nX_test_full_preproc = preproc.transform(X_test_full[feat])\n\nprint(X_full_preproc.shape, X_test_full_preproc.shape)","7ba44219":"import tensorflow as tf\ntf.random.set_seed(0)\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(units=500, activation=\"selu\", input_shape=X_full_preproc.shape),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(units=500, activation=\"selu\"),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(units=500, activation=\"selu\"),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(units=1, activation='relu'),\n    ])\n\nmodel.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=\"mean_absolute_error\", metrics=[\"mae\"])\n\nearlystop = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=0.001, restore_best_weights=True)\ncallog = model.fit(X_full_preproc, y, validation_split=0.2,\n          epochs=200, batch_size=256, steps_per_epoch=5, shuffle=True,callbacks=[earlystop],verbose=False)\n\nopttrace = pd.DataFrame(callog.history)\n# print(opttrace.columns)\nopttrace.loc[15:,['loss','val_loss']].plot()\n# opttrace.loc[15:,['mse','val_mse']].plot()\n\n","dc936d4b":"from sklearn.metrics import r2_score\ny_pred = model.predict(X_full_preproc)\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y,y_pred,'bo')\n# plt.axis('scaled')\n# plt.xlim([0,1e6])\n# plt.ylim([0,1e6])\nplt.plot([10,14],[10,14],'k')\nplt.title(np.round(r2_score(y,y_pred),3))\nplt.show()","f39a74aa":"pred_test = model.predict(X_test_full_preproc)\nprint(pred_test[:,0].shape)\noutput = pd.DataFrame({'Id': X_test_full.index,\n                       'SalePrice': pred_test[:,0]})\noutput.to_csv('submission.csv', index=False)","42c559fa":"1. Read in the data for training and testing datasets","7a73b0c1":"2. Clean up the data - Preprocessing"}}