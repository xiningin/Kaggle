{"cell_type":{"1b7facd7":"code","d472447e":"code","4899334e":"code","f9680a15":"code","a7844cd3":"code","e7d086d6":"code","35a641b0":"code","123b13e4":"code","3245021d":"code","99d4ea12":"code","e2fdd53f":"code","2b2e9cb9":"code","3645f4f8":"code","4e22df1a":"code","e9dd3285":"code","834fbeb2":"code","980261ba":"markdown","e2eeadec":"markdown"},"source":{"1b7facd7":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","d472447e":"import os\nimport sys\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Dense, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Add, UpSampling2D, Reshape, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Set some parameters\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nIMG_CHANNELS = 3\nTRAIN_PATH = '..\/input\/mydata-ns2\/stage1_train\/'\nTEST_PATH = '..\/input\/mydata-ns2\/stage1_test\/'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\nrandom.seed = seed\nnp.random.seed = seed","4899334e":"tf.__version__","f9680a15":"# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]","a7844cd3":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    for mask_file in next(os.walk(path + '\/masks\/'))[2]:\n        mask_ = imread(path + '\/masks\/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                      preserve_range=True), axis=-1)\n        mask = np.maximum(mask, mask_)\n    Y_train[n] = mask\n\n# Get and resize test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '\/images\/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[n] = img\n\nprint('Done!')","e7d086d6":"# X_train = X_train \/ 255\nY_train = np.array(Y_train, dtype='float32')","35a641b0":"# Check if training data looks all right\nix = random.randint(0, len(train_ids))\nimshow(X_train[ix])\nplt.show()\nimshow(np.squeeze(Y_train[ix]))\nplt.show()\n","123b13e4":"# From: https:\/\/github.com\/jocicmarko\/ultrasound-nerve-segmentation\/blob\/master\/train.py\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred, smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred))\n    sum_ = K.sum(K.square(y_true)) + K.sum(K.square(y_pred))\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac","3245021d":"from tensorflow.keras.applications.vgg16 import VGG16\n\ndef segnet(input_size=(512, 512, 1)):\n    \n    encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_size)\n    \n    # Encoding layer\n    inp = Input(input_size)\n    x = encoder.get_layer(name='block1_conv1')(inp)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block1_conv2')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D()(x)\n    \n    x = encoder.get_layer(name='block2_conv1')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block2_conv2')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D()(x)\n\n    x = encoder.get_layer(name='block3_conv1')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block3_conv2')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block3_conv3')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D()(x)\n\n    x = encoder.get_layer(name='block4_conv1')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block4_conv2')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block4_conv3')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D()(x)\n    \n    x = encoder.get_layer(name='block5_conv1')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block5_conv2')(x)\n    x = BatchNormalization()(x)\n    x = encoder.get_layer(name='block5_conv3')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D()(x)\n    \n    # Decoding Layer \n    x = UpSampling2D()(x)\n    x = Conv2D(1024, (3, 3), padding='same', name='deconv1')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(1024, (3, 3), padding='same', name='deconv2')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(1024, (3, 3), padding='same', name='deconv3')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2D(512, (3, 3), padding='same', name='deconv4')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(512, (3, 3), padding='same', name='deconv5')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(512, (3, 3), padding='same', name='deconv6')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2D(256, (3, 3), padding='same', name='deconv7')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), padding='same', name='deconv8')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), padding='same', name='deconv9')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2D(128, (3, 3), padding='same', name='deconv10')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), padding='same', name='deconv11')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2D(64, (3, 3), padding='same', name='deconv12')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, (3, 3), padding='same', name='deconv13')(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n\n    x = Conv2D(1, (3, 3), padding='same', name='deconv14')(x)\n    x = Activation('sigmoid')(x)\n    pred = Reshape((IMG_HEIGHT,IMG_WIDTH))(x)\n    \n    return Model(inputs=inp, outputs=pred)","99d4ea12":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle=False)\n\nBATCH_SIZE = 16\nEPOCHS = 100","e2fdd53f":"from tensorflow.keras.applications.vgg16 import preprocess_input\nX_train_process = preprocess_input(X_train)","2b2e9cb9":"histories = []\nlosses = []\naccuracies = []\ndicecoefs = []\nious = []\n\nfor k, (train_index, test_index) in enumerate(kf.split(X_train, Y_train)):\n    print('\\nFold : ', k+1)\n    x_train = X_train_process[train_index]\n    y_train = Y_train[train_index]\n    x_test = X_train_process[test_index]\n    y_test = Y_train[test_index]\n\n    model = segnet(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    \n    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[iou, dice_coef, 'binary_accuracy'])\n    model.summary()\n    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_nuclei_seg.hdf5', \n                                       verbose=1, \n                                       save_best_only=True)\n\n    history = model.fit(x_train, y_train,\n                        epochs=EPOCHS, \n                        callbacks=[model_checkpoint],\n                        validation_data = (x_test, y_test),\n                        batch_size=BATCH_SIZE)\n    \n    model = load_model(str(k+1) + '_unet_nuclei_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\n    \n    results = model.evaluate(x_test, y_test)\n    results = dict(zip(model.metrics_names,results))\n    \n    histories.append(history)\n    accuracies.append(results['binary_accuracy'])\n    losses.append(results['loss'])\n    dicecoefs.append(results['dice_coef'])\n    ious.append(results['iou'])","3645f4f8":"print('accuracies : ', accuracies)\nprint('losses : ', losses)\nprint('dicecoefs : ', dicecoefs)\nprint('ious : ', ious)\n\nprint('-----------------------------------------------------------------------------')\nprint('-----------------------------------------------------------------------------')\n\nprint('average accuracy : ', np.mean(np.array(accuracies)))\nprint('average loss : ', np.mean(np.array(losses)))\nprint('average dicecoefs : ', np.mean(np.array(dicecoefs)))\nprint('average ious : ', np.mean(np.array(ious)))\nprint()\n\nprint('standard deviation of accuracy : ', np.std(np.array(accuracies)))\nprint('standard deviation of loss : ', np.std(np.array(losses)))\nprint('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\nprint('standard deviation of ious : ', np.std(np.array(ious)))","4e22df1a":"import pickle\n\nfor h, history in enumerate(histories):\n\n    keys = history.history.keys()\n    fig, axs = plt.subplots(1, len(keys)\/\/2, figsize = (25, 5))\n    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n\n    for k, key in enumerate(list(keys)[:len(keys)\/\/2]):\n        training = history.history[key]\n        validation = history.history['val_' + key]\n\n        epoch_count = range(1, len(training) + 1)\n\n        axs[k].plot(epoch_count, training, 'r--')\n        axs[k].plot(epoch_count, validation, 'b-')\n        axs[k].legend(['Training ' + key, 'Validation ' + key])\n        \n    with open(str(h+1) + '_mri_trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","e9dd3285":"selector = np.argmin(abs(np.array(ious) - np.mean(ious)))\nmodel = load_model(str(selector+1) +'_unet_nuclei_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","834fbeb2":"for i in range(20):\n    index=np.random.randint(1,len(X_train))\n    pred=model.predict(X_train_process[index][np.newaxis, :, :, :])\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(X_train[index])\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(Y_train[index]))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Predicted mask')\n    plt.show()","980261ba":"# Get the data\nLet's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!","e2eeadec":"Let's see if things look all right by drawing some random images and their associated masks."}}