{"cell_type":{"45820749":"code","41db9a4a":"code","13813cf8":"code","883efc2b":"code","e59d69c9":"code","59f6b2ac":"code","bcffd0d8":"code","024600d7":"code","0f4c3160":"code","6b85ee68":"code","dd9f89c8":"code","3ac4b3d0":"code","7d66f425":"code","6f6fa3cf":"code","3e8030ec":"code","6f844c9e":"code","45610e88":"code","840fdd81":"code","fbbd905a":"code","899ea7e7":"code","9bf96b5f":"code","4fd100d1":"code","ae4fdd3a":"code","cc7860e3":"code","241f3180":"code","fe749c3d":"code","deaa2bed":"code","386dc01d":"code","e949b442":"code","d08092bc":"code","5736ad1c":"code","ecebd1e3":"code","8cc011a3":"code","2d265c38":"code","140e91e2":"code","ac3a4464":"code","7ea89d3e":"code","1b461e70":"code","4a3642cc":"code","656a9ecd":"code","8b845dab":"code","825de38f":"code","df3edee6":"code","9675a946":"code","bb284af4":"code","ea0135ac":"code","8a0d6022":"code","50fe70ad":"code","d0ccd7b7":"code","88b6e9b7":"code","fae5ef63":"code","a226b965":"code","5965d8f4":"code","ac635cdd":"code","7c34d34d":"code","b3a320e1":"markdown","41e0610e":"markdown","6b7c84ac":"markdown","6a7a7d98":"markdown","479ef14f":"markdown","2033fc9f":"markdown","9fc990b9":"markdown","2192c648":"markdown","aa4d6b84":"markdown","1bbaf3da":"markdown","f2a5a89a":"markdown","c1489d0b":"markdown","ce698c0a":"markdown","2fa41e6e":"markdown","d31da157":"markdown","016cb54f":"markdown","804b4233":"markdown","50749b69":"markdown","d0400473":"markdown","65ad47db":"markdown","756f76ce":"markdown","53d69c52":"markdown","2e07188c":"markdown","05483a6b":"markdown","4599ab9d":"markdown","41ba95e3":"markdown","c9ad2c94":"markdown","ce39a12c":"markdown","e71c8cc2":"markdown","fc337582":"markdown","e816d996":"markdown","e62deb8c":"markdown","cca2d59a":"markdown"},"source":{"45820749":"%%capture\n!pip install seaborn --upgrade","41db9a4a":"import pandas as pd\nfrom hyperopt import fmin, tpe, hp, STATUS_OK\nfrom functools import partial","13813cf8":"gender_sub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain","883efc2b":"test","e59d69c9":"gender_sub","59f6b2ac":"train.info()","bcffd0d8":"train.isnull().sum()","024600d7":"test.isnull().sum()","0f4c3160":"train.describe()","6b85ee68":"train.info()","dd9f89c8":"pd.concat([train[\"Age\"], test[\"Age\"]], axis=0).mean()","3ac4b3d0":"fill_age_with_minus = False\nif fill_age_with_minus:\n    train[\"Age\"].fillna(-1, inplace=True)\n    test[\"Age\"].fillna(-1, inplace=True)\nelse:\n    train[\"Age\"].fillna(pd.concat([train[\"Age\"], test[\"Age\"]], axis=0).median(), inplace=True)\n    test[\"Age\"].fillna(pd.concat([train[\"Age\"], test[\"Age\"]], axis=0).median(), inplace=True)","7d66f425":"train","6f6fa3cf":"survived = dict(train[\"Survived\"].value_counts()\/len(train))\nsurvived","3e8030ec":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig, axis = plt.subplots(1, 2, figsize=(20, 10))\nsns.countplot(x=\"Survived\", data=train, ax = axis[0])\naxis[1].pie(survived.values(), labels=survived.keys(), autopct='%1.1f%%')\nfig.show()","6f844c9e":"sns.set_style(\"darkgrid\")\nplt.figure(figsize=(7, 7))\nsns.countplot(x=\"Embarked\", data=pd.concat([train, test], axis=0))","45610e88":"train[\"Embarked\"].fillna(\"S\", inplace=True)\ntest[\"Embarked\"].fillna(\"S\", inplace=True)","840fdd81":"fare_by_embarkation = pd.concat([train, test], axis=0).groupby(\"Embarked\")[\"Fare\"].mean().reset_index()\nfare_by_embarkation","fbbd905a":"test[test.isnull().any(axis=1)]","899ea7e7":"fare_by_embarkation[fare_by_embarkation[\"Embarked\"] == 0][\"Fare\"].values","9bf96b5f":"test[\"Fare\"].fillna(fare_by_embarkation[fare_by_embarkation[\"Embarked\"] == \"C\"][\"Fare\"].values[0],\n                                               inplace=True)\ntest.isnull().sum()","4fd100d1":"cols_to_drop = [\"Name\", \"Cabin\", \"PassengerId\", \"Ticket\"]\ntrain = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop, axis=1)\ntrain","ae4fdd3a":"from sklearn.preprocessing import LabelEncoder\n\nenc = LabelEncoder()\ncategorical_cols = [\"Embarked\", \"Sex\"]\n\nfor df in [train, test]:\n    df[\"Embarked\"] = df[\"Embarked\"].map({\"S\": 0, \"C\": 1, \"Q\" : 2})\n    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\" : 1})\ntrain","cc7860e3":"test","241f3180":"plt.figure(figsize=(10, 10))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm')","fe749c3d":"# sns.pairplot(train, hue=\"Survived\", diag_kind=\"hist\")","deaa2bed":"fig, axis = plt.subplots(1, 3, figsize=(25, 12))\nsns.histplot(x=\"Fare\", data=train[train[\"Pclass\"] == 1], ax = axis[0], kde=True).set_title(\"Pclass: 1st\")\nsns.histplot(x=\"Fare\", data=train[train[\"Pclass\"] == 2], ax = axis[1], kde=True).set_title(\"Pclass: 2nd\")\nsns.histplot(x=\"Fare\", data=train[train[\"Pclass\"] == 3], ax = axis[2], kde=True).set_title(\"Pclass: 3rd\")\nfig.show()","386dc01d":"fig, axis = plt.subplots(1, 3, figsize=(25, 12))\nsns.histplot(x=\"Fare\", data=test[test[\"Pclass\"] == 1], ax = axis[0], kde=True).set_title(\"Pclass: 1st\")\nsns.histplot(x=\"Fare\", data=test[test[\"Pclass\"] == 2], ax = axis[1], kde=True).set_title(\"Pclass: 2nd\")\nsns.histplot(x=\"Fare\", data=test[test[\"Pclass\"] == 3], ax = axis[2], kde=True).set_title(\"Pclass: 3rd\")\nfig.show()","e949b442":"plt.figure(figsize=(7, 7))\nsns.countplot(x=\"Sex\", data=train)","d08092bc":"plt.figure(figsize=(7, 7))\nsns.countplot(x=\"Sex\", data=test)","5736ad1c":"plt.figure(figsize=(7, 7))\nsns.countplot(x=\"Sex\", hue=\"Survived\", data=train)","ecebd1e3":"plt.figure(figsize=(7, 7))\nsns.countplot(x=\"Pclass\", data=train)","8cc011a3":"plt.figure(figsize=(7, 7))\nsns.countplot(x=\"Pclass\", data=test)","2d265c38":"plt.figure(figsize=(10, 10))\nsns.countplot(x=\"Pclass\",hue=\"Survived\", data=train)","140e91e2":"fig, axis = plt.subplots(1, 2, figsize=(20, 12))\nsns.histplot(x=\"Fare\", data=train[train[\"Survived\"] == 0], ax = axis[0]).set_title(\"Survived: 0\")\nsns.histplot(x=\"Fare\", data=train[train[\"Survived\"] == 1], ax = axis[1]).set_title(\"Survived: 1\")\nfig.show()","ac3a4464":"train.groupby(\"Survived\")[\"Fare\"].sum().reset_index()","7ea89d3e":"sns.catplot(x='Pclass', y='Survived',hue='Sex',data=train, kind=\"point\")","1b461e70":"plt.figure(figsize=(10, 10))\nsns.countplot(x=\"Embarked\",hue=\"Survived\", data=train)","4a3642cc":"plt.figure(figsize=(10, 10))\nsns.countplot(x=\"Embarked\", data=test)","656a9ecd":"plt.figure(figsize=(10, 10))\nsns.countplot(x=\"Embarked\", hue=\"Pclass\", data=train)","8b845dab":"train.groupby(\"Embarked\")[\"Fare\"].mean().reset_index()","825de38f":"fig, axis = plt.subplots(1, 2, figsize=(20, 12))\nsns.histplot(x=\"Age\", data=train[train[\"Survived\"] == 0], ax = axis[0], kde=True).set_title(\"Survived: 0\")\nsns.histplot(x=\"Age\", data=train[train[\"Survived\"] == 1], ax = axis[1], kde=True).set_title(\"Survived: 1\")\nfig.show()","df3edee6":"fig, axis = plt.subplots(1, 2, figsize=(20, 10))\nsns.countplot(x=\"SibSp\", hue=\"Survived\", data=train, ax = axis[0])\nsns.countplot(x=\"Parch\", hue=\"Survived\", data=train, ax = axis[1])\nfig.show()","9675a946":"train","bb284af4":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\ndummy_label = train.drop(\"Survived\", axis=1)\nrf.fit(train.loc[:, train.columns != \"Survived\"], train[\"Survived\"])\nrf.feature_importances_","ea0135ac":"train[\"Relative\"] = train[\"SibSp\"] + train[\"Parch\"]\ntrain= train.drop([\"SibSp\", \"Parch\"], axis=1)\n\ntest[\"Relative\"] = test[\"SibSp\"] + test[\"Parch\"]\ntest = test.drop([\"SibSp\", \"Parch\"], axis=1)\ntrain","8a0d6022":"test","50fe70ad":"labels = train[\"Survived\"]\ntrain = train.drop(\"Survived\", axis=1)\ntrain","d0ccd7b7":"test","88b6e9b7":"import catboost as cb\nfrom sklearn.model_selection import train_test_split\n\n\nsplit = True\ncategorical_cols = [\"Pclass\", \"Sex\", \"Embarked\"]\nif split:\n    X_train, X_val, Y_train, Y_val = train_test_split(train, labels, test_size=0.2, random_state=999)\n    train_pool = cb.Pool(data=X_train, label=Y_train, cat_features = categorical_cols)\n    val_pool = cb.Pool(data=X_val, label=Y_val, cat_features = categorical_cols)\nelse:\n    cb_train = cb.Pool(data=train, label=labels, cat_features = categorical_cols)","fae5ef63":"import numpy as np\nfrom catboost import Pool, CatBoostClassifier","a226b965":"ITERATIONS = 3000\nMAX_EVALS = 50\nEARLY_STOP = 500\n\n\ninteger_params = ['depth','min_data_in_leaf','max_bin']\ndef objective_func(params, train_pool, val_pool):\n    for param in integer_params:\n        params[param] = int(params[param])\n#     if params['bootstrap_type']['bootstrap_type'] == 'Bayesian':\n#         bagging_temp = params['bootstrap_type'].get('bagging_temperature')\n#         params['bagging_temperature'] = bagging_temp\n    if params['grow_policy']['grow_policy'] == 'LossGuide':\n        max_leaves = params['grow_policy'].get('max_leaves')\n        params['max_leaves'] = int(max_leaves)\n#     params['bootstrap_type'] = params['bootstrap_type']['bootstrap_type']\n    params['grow_policy'] = params['grow_policy']['grow_policy']\n\n    params['fold_len_multiplier'] = max(params['fold_len_multiplier'], 1)\n\n    print(params)\n    model = CatBoostClassifier(iterations = ITERATIONS, custom_metric = \"Accuracy\", task_type=\"GPU\", devices='0:1',\n                              eval_metric = \"Accuracy\", verbose=False, **params)\n    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds = EARLY_STOP)\n    loss = model.get_best_score()[\"validation\"][\"Accuracy\"]\n    return {\"loss\": -loss, \"status\": STATUS_OK}\n\n\nCB_MAX_DEPTH = 10\n# bootstrap_type = [{'bootstrap_type':'Poisson'}, \n#                   {'bootstrap_type':'MVS'},\n#                    {'bootstrap_type':'Bayesian',\n#                     'bagging_temperature' : hp.loguniform('bagging_temperature', np.log(1), np.log(50))},\n#                   {'bootstrap_type':'Bernoulli'}] \nLEB = ['No', 'AnyImprovement',\n       'Armijo'\n      ]\ngrow_policy = [{'grow_policy':'SymmetricTree'},\n               {'grow_policy':'Depthwise'},\n               {'grow_policy':'Lossguide',\n                'max_leaves': hp.quniform('max_leaves', 2, 32, 1)}]\nspace ={\n        'depth': hp.quniform('depth', 5, CB_MAX_DEPTH, 1),\n        'max_bin' : hp.quniform('max_bin', 1, 32, 1), \n        'l2_leaf_reg' : hp.uniform('l2_leaf_reg', 0, 5),\n        'min_data_in_leaf' : hp.quniform('min_data_in_leaf', 1, 25, 1),\n#         'bootstrap_type' : hp.choice('bootstrap_type', bootstrap_type),\n        'learning_rate' : hp.uniform('learning_rate', 0.01, 0.2),\n        'leaf_estimation_backtracking' : hp.choice('leaf_estimation_backtracking', LEB),\n        'grow_policy': hp.choice('grow_policy', grow_policy),\n        'fold_len_multiplier' : hp.loguniform('fold_len_multiplier', np.log(1.01), np.log(2.5)),\n       }\nfn = partial(objective_func, train_pool=train_pool, val_pool=val_pool)\nprint(\"Tuning hyperparams...\")\n\nbest_params = fmin(fn = fn, space=space, algo=tpe.suggest, max_evals = MAX_EVALS)\n\n# best_params['bootstrap_type'] = bootstrap_type[best_params['bootstrap_type']]['bootstrap_type']\nbest_params['grow_policy'] = grow_policy[best_params['grow_policy']]['grow_policy']\nbest_params['leaf_estimation_backtracking'] = LEB[best_params['leaf_estimation_backtracking']]   \n\nfor param in integer_params:\n    best_params[param] = int(best_params[param])\nif 'max_leaves' in best_params:\n    best_params['max_leaves'] = int(best_params['max_leaves'])\n    \nmodel = CatBoostClassifier(iterations = ITERATIONS, custom_metric = \"Accuracy\",task_type=\"GPU\",devices='0:1'\n                                  , verbose=1000, **best_params)\nmodel.fit(train_pool, eval_set = val_pool, early_stopping_rounds = EARLY_STOP, plot=True)","5965d8f4":"model.plot_tree(\n    tree_idx=0,\n    pool=train_pool\n)","ac635cdd":"gender_sub[\"Survived\"] = model.predict(test)\ngender_sub","7c34d34d":"gender_sub.to_csv(\"submission.csv\", index=False)","b3a320e1":"We confirm that: Rich people had a higher chance to survive","41e0610e":"## Fill NaNs in Age and Fare (in test only)\nBut what is the age mean?","6b7c84ac":"## Pclass count ","6a7a7d98":"## How many people survived? What was the ratio?","479ef14f":"## Drop irrelevant columns","2033fc9f":"## Fill NaNs Embarked with the most frequent port (S)","9fc990b9":"We find that:\n- The correlation matrix shows negative linear correlation between variables, which is true: `Fare` should have negative linear correlation with `Pclass`\n- It also shows negative linear correlation between `Pclass` and `Survived`\n- There were more male than female\n- Female had higher survivability than Male. Lady first guys\n- Most people were 3rd class passengers\n- Most people in 1st class survived, and 3rd class died\n- Both the survived and dead had approximately the same age distribution\n- Most people were in age 20-40, but possibly because of NaNs\n- Age 20-30 died the most, but possibly because of NaNs\n- Most people brought 0-2 sibling\/spouse, with 0 and 1 dominated\n- Most poeple brought no parent\/children\n- People embarked in S and Q port had about 50\/50 chance to survive, but the C port had a surprisingly high chance to die\n- Fare was mostly under 150\n- People age 20-60 could afford higher fare, but possibly because of NaNs","2192c648":"We see that:\n- Negative linear correlation between `Pclass` and `Survived`\n- 1st class female had a very high chance to survive","aa4d6b84":"We see that:\n- 1st class had a higher chance to survive\n- 3rd class people died the most\n- 2nd class had almost equal chance to die\/survive\n\nHypothesis: Did people with higher fare (higher Pclass) have higher chance to survive?","1bbaf3da":"## How many NaNs values are there in each columns?","f2a5a89a":"We only have to create a new column `Relative = SibSp + Parch`, because it is reasonable to count the number of relatives. We can safely drop the rest.","c1489d0b":"We can confirm that there was a (negative?) linear correlation between `Fare` and `Pclass`.","ce698c0a":"## Pearson Correlation Heatmap","2fa41e6e":"## Embarkation and Survivability","d31da157":"We find that:\n- People embarked in S had a higher chance to die\n- People embarked in C had a higher chance to survive\n- People embarked in Q has a higher chance to die\n\nHypothesis: Was C the city of the rich?","016cb54f":"Get name initials using Regular expression","804b4233":"## Fare and Pclass","50749b69":"We see that:\n- Kids (< 20) had higher chance to survive\n- Most people died around age 20-40, peak at ~30, but possibly because of NaNs.","d0400473":"Data definition:\n- Survived: 0 if passenger dies, 1 if passenger survives\n- Pclass: ticket class, 1st = First class, 2nd = Second class and 3rd = Third class. The smaller the more family income\/fares.\n- Sex: sex\n- Age: age in years\n- SibSp: number of siblings and spouses aboard\n- Parch: number of parents and children aboard\n- Ticket: ticket number\n- Fare: passenger fare\n- Cabin: cabin number\n- Embarked: Port of Embarkation, C = Cherbourg, Q = Queenstown, S = Southampton","65ad47db":"## Fill NaN of Fare in test set using fare mean of embark","756f76ce":"## Pclass and Survivability","53d69c52":"# EDA\n","2e07188c":"## DataFrame describe","05483a6b":"## SibSp, Parch and Survivability","4599ab9d":"## Gender distribution and Survivability","41ba95e3":"## Pairplot","c9ad2c94":"## Encode categorical features","ce39a12c":"I am not sure how to evaluate this. During emergency, we cannot sure we can bring our siblings\/parents\/spouses\/children with.","e71c8cc2":"## Count embarkation port","fc337582":"## Age and Survivability\nNote: mean of age is 29, which could affect our assumption","e816d996":"We conclude that: yes, C was the city of the rich. Unlike S and Q, C had the highest 1st class ratio","e62deb8c":"We see that: Female had higher chance to survive. This is a good sign.","cca2d59a":"# Feature Engineering & Predictions\nLook at the `train` again:"}}