{"cell_type":{"48231fc7":"code","7847268c":"code","13e7f043":"code","d8f7f743":"code","5cce27da":"code","cd51abdd":"code","ba3b543c":"code","7b1a942c":"code","57d2a0a1":"code","7caa2b10":"code","47ff0e34":"markdown","8d4a7306":"markdown"},"source":{"48231fc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7847268c":"#Other necessary imports\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nimport keras\nfrom keras import models\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')","13e7f043":"# Defining a results visualization function\ndef visualize_results(history):\n    '''\n    From https:\/\/machinelearningmastery.com\/display-deep-learning-model-training-history-in-keras\/\n    \n    Input: keras history object (output from trained model)\n    '''\n    #Instantiate values\n    train_loss = history.history['loss']\n    train_acc = history.history['accuracy']\n    train_recall = history.history['recall']\n    train_aucroc = history.history['auc']\n    val_loss = history.history['val_loss']\n    val_acc = history.history['val_accuracy']\n    val_recall = history.history['val_recall']\n    val_aucroc = history.history['val_auc']\n    \n    #Create figure for plotting\n    fig, [(ax1, ax2), (ax3, ax4)] = plt.subplots(2, 2, figsize=(10, 5))\n    fig.suptitle('Model Results')\n    #plt.xlabel('Epoch')\n    \n    #Plot Loss\n    ax1.plot(train_loss)\n    ax1.plot(val_loss)\n    ax1.set_ylabel('Loss')\n    ax1.set_xlabel('Epochs')\n    ax1.legend(['train', 'val'])\n    \n    #Plot Accuracy\n    ax2.plot(train_acc)\n    ax2.plot(val_acc)\n    ax2.set_ylabel('Accuracy')\n    ax2.set_xlabel('Epochs')\n    ax2.legend(['train', 'val'])\n    \n    #Plot Recall\n    ax3.plot(train_recall)\n    ax3.plot(val_recall)\n    ax3.set_ylabel('Recall')\n    ax3.set_xlabel('Epochs')\n    ax3.legend(['train', 'val'])\n    \n    #Plot AUC-ROC\n    ax4.plot(train_aucroc)\n    ax4.plot(val_aucroc)\n    ax4.set_ylabel('AUC-ROC')\n    ax4.set_xlabel('Epochs')\n    ax4.legend(['train', 'val'])\n    \n    plt.show();","d8f7f743":"#Load data\ntrain_images = np.load('..\/input\/eda-and-data-preprocessing\/train_images.npy')\ntrain_labels = np.load('..\/input\/eda-and-data-preprocessing\/train_labels.npy')\n\ntrain_images_third = np.load('..\/input\/eda-and-data-preprocessing\/train_images_third.npy')\ntrain_labels_third = np.load('..\/input\/eda-and-data-preprocessing\/train_labels_third.npy')\n\nval_images = np.load('..\/input\/eda-and-data-preprocessing\/val_images.npy')\nval_labels = np.load('..\/input\/eda-and-data-preprocessing\/val_labels.npy')\n\ntest_images = np.load('..\/input\/eda-and-data-preprocessing\/test_images.npy')\ntest_labels = np.load('..\/input\/eda-and-data-preprocessing\/test_labels.npy')","5cce27da":"#Explore the dataset again\nprint (\"Number of training samples: \" + str(train_images.shape[0]))\nprint (\"A third of training samples: \" + str(train_images_third.shape[0]))\nprint (\"Number of validation samples: \" + str(val_images.shape[0]))\nprint (\"Number of testing samples: \" + str(test_images.shape[0]))\nprint (\"===\")\nprint (\"train_images shape: \" + str(train_images.shape))\nprint (\"train_labels shape: \" + str(train_labels.shape))\nprint (\"A third of train_images shape: \" + str(train_images_third.shape))\nprint (\"A third of train_labels shape: \" + str(train_labels_third.shape))\nprint (\"val_images shape: \" + str(val_images.shape))\nprint (\"val_labels shape: \" + str(val_labels.shape))\nprint (\"test_images shape: \" + str(test_images.shape))\nprint (\"test_labels shape: \" + str(test_labels.shape))","cd51abdd":"#Build a baseline fully connected model\nnp.random.seed(42)\nbaseline_model = models.Sequential()\nbaseline_model.add(layers.Dense(12, activation='relu', input_shape=(128,128,3))) # 2 hidden layers\nbaseline_model.add(layers.Flatten())\nbaseline_model.add(layers.Dense(7, activation='relu'))\nbaseline_model.add(layers.Dense(5, activation='relu'))\nbaseline_model.add(layers.Dense(1, activation='sigmoid'))","ba3b543c":"#View summary of model\nbaseline_model.summary()","7b1a942c":"#Compile baseline model\nbaseline_model.compile(optimizer='sgd',\n                       loss='binary_crossentropy',\n                       metrics=['accuracy', 'Recall', 'AUC'])\n\n#Instantiate an EarlyStopping Object\nes = EarlyStopping(monitor='val_loss', mode='min', patience=5)\nmc = ModelCheckpoint('best_baseline_model.h5', monitor='val_recall', mode='max', verbose=1, save_best_only=True)\n\n#And fit the baseline model to the training images, validating on the val images\nresults = baseline_model.fit(train_images_third,\n                            train_labels_third,\n                            epochs=50,\n                            batch_size=32,\n                            callbacks = [es,mc],\n                            validation_data=(val_images, val_labels))","57d2a0a1":"#Visualize model results\nvisualize_results(results)","7caa2b10":"#Save Weights\nbaseline_model.save_weights('baseline_model_weights.h5')","47ff0e34":"# Load Processed Data","8d4a7306":"# Modeling"}}