{"cell_type":{"92ae940d":"code","9a660b68":"code","d5ee43aa":"code","27e5feb3":"code","952e6374":"code","3dabf9aa":"code","ea73175a":"code","4bf30c5b":"code","d76a9f10":"code","ae3ae3ee":"code","57fd31a6":"code","a15c258f":"code","6be7bbe9":"code","2ccea67a":"code","ef5295c3":"code","83c2fcc5":"code","c34441a3":"code","ac70e12a":"code","315e177a":"code","0687ca3b":"code","407bffb3":"code","8a21c1ec":"code","4ee1449b":"code","7155d7c5":"code","341bd94f":"code","93ac1cc3":"code","22a5f188":"code","44c074c7":"code","0831b6c5":"code","73dccbe2":"code","2f9f1824":"code","7b464a92":"code","86d80a83":"code","c53a3d7b":"code","5d81d96d":"code","2c34225c":"code","ec27dd16":"code","e1cd10b7":"code","71c4bfd6":"code","255bd4a7":"code","f9b197a7":"code","f3b281b9":"code","e5a128d1":"code","f263b6e0":"code","5fe675d2":"code","1113dbd2":"code","5425ce40":"code","496d332e":"code","d5e2ff6c":"code","db5fda31":"code","94b490fe":"code","8bd6a554":"code","80fe04a3":"code","c1bcf829":"code","f0890930":"code","c359d336":"code","404c221d":"code","834a4436":"code","cde11a48":"code","a125d91e":"code","a8a873d1":"code","6702d904":"code","f973af2d":"code","396e3bd8":"code","c461e107":"code","a0a76f7c":"markdown"},"source":{"92ae940d":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport sys # to get error message when exception occurs.\nimport re\nimport datetime as dt\n\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\nfrom spacy.util import decaying\nfrom spacy import displacy\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9a660b68":"#activated = spacy.require_gpu()#prefer_gpu()\n#print(f'is GPU activited for spacy: {activated}')","d5ee43aa":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","27e5feb3":"#Load train and test data\ntrain_data = pd.read_csv('..\/input\/tweet-sentiment-extraction\/train.csv')\ntest_data = pd.read_csv('..\/input\/tweet-sentiment-extraction\/test.csv')\n\nprint(f'train_data.shape: {train_data.shape}')\nprint(f'test_data.shape: {test_data.shape}')\ntrain_data.head(10)","952e6374":"test_data.head()","3dabf9aa":"#Train data: Check for null entries\ntrain_data.isnull().mean()","ea73175a":"#Test data: Check for null entries\ntest_data.isnull().mean()","4bf30c5b":"#train_data contains 1 null entry thefore it's safe to drop it.\ntrain_data[train_data.text.isnull() == True]","d76a9f10":"train_data.dropna(inplace=True)\ntrain_data.reset_index(inplace=True) #reset index post dropping NA\nlen(train_data)","ae3ae3ee":"train_data.sentiment.value_counts()","57fd31a6":"print(f'train_data sentiment unique entries: {train_data.sentiment.unique()}')\nprint(f'test_data sentiment unique entries: {test_data.sentiment.unique()}')","a15c258f":"#Validate selected_text match with text in train_data\n\nvalidIdx=[]\ninvalidIdx=[]\nfor row in train_data.index.tolist():\n    try:\n        if train_data.iloc[row].selected_text in train_data.iloc[row].text:\n            validIdx.append(row)\n        else:\n            invalidIdx.append(row)\n        #break\n    except:\n        e = sys.exc_inf()[0]\n        print(e)\n        print(train_data.iloc[row].text)\n\nlen(validIdx), len(invalidIdx)","6be7bbe9":"#train_data['neutral_sel_tx_diff'] = train_data.loc[lambda d: d.sentiment == 'neutral'][['text', 'selected_text']].apply(lambda d: len(d.text) - len(d.selected_text))\n\nf1 = lambda d: d.sentiment == 'neutral'\n#f2 = lambda d: (len(d.text) - len(d.selected_text)) > 0\n#train_data.loc[lambda d: d.neutral_sel_tx_diff > 0][['text', 'selected_text']]\ntrain_data.loc[f1]\n\ntrain_data['txt_and_sel_txt_diff'] = [(len(d.text) - len(d.selected_text)) for d in train_data.itertuples()]\ntrain_data['txt_and_sel_txt_diff_strip'] = [(len(d.text.strip()) - len(d.selected_text.strip())) for d in train_data.itertuples()]\n","2ccea67a":"lst = train_data.loc[lambda d: d.sentiment == 'neutral'].loc[lambda d: d.txt_and_sel_txt_diff > 0].txt_and_sel_txt_diff.value_counts()\nlst_strip = train_data.loc[lambda d: d.sentiment == 'neutral'].loc[lambda d: d.txt_and_sel_txt_diff_strip > 0].txt_and_sel_txt_diff_strip.value_counts()","ef5295c3":"lst[lst > 10]","83c2fcc5":"lst_strip[lst_strip > 3]","c34441a3":"train_data.loc[lambda d: d.sentiment == 'neutral'].loc[lambda d: d.txt_and_sel_txt_diff > 10]","ac70e12a":"train_data.loc[f1].loc[lambda d: d.txt_and_sel_txt_diff_strip > 10]","315e177a":"train_data.loc[f1].loc[lambda d: d.txt_and_sel_txt_diff_strip > 1].loc[lambda d: d.text.str.find('http') > -1]","0687ca3b":"def find_url(string): \n  \n    # findall() has been used  \n    # with valid conditions for urls in string \n    regex = r\"(?i)\\b((?:https?:\/\/|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}\/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))\"\n    url = re.findall(regex,string)       \n    return [x[0] for x in url] \n\ndef replace_url(txt):\n    dat = txt\n    for s in find_url(txt):\n        dat = dat.replace(s,\"\")\n    return dat\n\nprint(replace_url('Hello this www.google.com is google website!!!'))\n\ndef cust_strip(df, lst):\n    for col in lst:\n        df[col] = df[col].str.strip()\n\n#Remove space at the begining of text and selected_text.\ncust_strip(train_data, ['text', 'selected_text'])\n\n#Remove url as they are not part of selected text as per train data\n#train_data.text = train_data.text.apply(replace_url)\n\ntrain_data.head()","407bffb3":"#Remove space at the begining of text and selected_text.\ncust_strip(test_data, ['text'])\n\n#Remove url as they are not part of selected text as per train data\n#test_data.text = test_data.text.apply(replace_url)\ntest_data.head()","8a21c1ec":"#Max len of negative and positive sentiment\nprint(train_data['text'].str.len().max(), \n    train_data.loc[lambda d: d.sentiment == 'neutral']['selected_text'].str.len().max(),\n    train_data.loc[lambda d: d.sentiment == 'positive']['selected_text'].str.len().max(),\n    train_data.loc[lambda d: d.sentiment == 'negative']['selected_text'].str.len().max())\n\n#Max len of negative and positive sentiment\nprint(train_data['text'].str.len().min(), \n    train_data.loc[lambda d: d.sentiment == 'neutral']['selected_text'].str.len().min(),\n    train_data.loc[lambda d: d.sentiment == 'positive']['selected_text'].str.len().min(),\n    train_data.loc[lambda d: d.sentiment == 'negative']['selected_text'].str.len().min())","4ee1449b":"train_data.loc[lambda d: d.selected_text.str.len() <3]","7155d7c5":"#Function prepares data for given row for Spacy model.\n\ndef parse_data(df, idx,lFlag=False):\n    txt = df.iloc[idx].text.lower()\n    sel_txt = df.iloc[idx].selected_text.lower()\n    senti = df.iloc[idx].sentiment.lower()\n    parsedTxt = ''\n    \n    if lFlag == True: # Logging\n        print(f'row: {idx}')\n        print(f'text:{txt}')\n        print(f'sel_txt:{sel_txt}')\n    \n    if sel_txt in txt:\n        start = txt.index(sel_txt)\n        end = start+len(sel_txt)\n        entityTuple = (start, end, senti)\n        parsedTxt = (txt, {'entities': [entityTuple]})\n    \n    if lFlag == True : #Logging\n        s = parsedTxt[1][\"entities\"][0][0]\n        e = parsedTxt[1][\"entities\"][0][1]\n        print(f'sel_txt and parsedTxt matched => {txt[s:e] == sel_txt}')\n    \n    return parsedTxt \n\n#Validate function parse_train_data \nfor row in range(5):\n    print(parse_data(train_data, row))\n    print()\n\n\n#Function to create spacy blank model and add custom labels to ner.\ndef create_blank_nlp(parsed_data):\n    nlp = spacy.blank('en')\n    ner = nlp.create_pipe('ner')\n    nlp.add_pipe(ner, last=True)\n    ner = nlp.get_pipe('ner')\n    for _, annotations in parsed_data:\n        if len(annotations.get(\"entities\")[0]) == 3:\n            #print(annotations.get(\"entities\"))\n            ner.add_label(annotations.get(\"entities\")[0][2])\n    print(f'These labels added to ner: {ner.labels}')\n    return nlp\n\n \ndef train_model(df, model, epoch=20, minBatch=4.0, maxBatch=16.0, lr=1.01, drop=0.5, \n                enableBatchScheme=False, batchScheme=[100,200,300,400,500]):\n    #print(f'nlp pipeline: {nlp.pipeline}')\n    #dropout=decaying(0.6,0.1,1e-4)\n    nextBatchIdx = 0\n    losses_output = []\n    optimizer = model.begin_training()\n    for i in range(epoch):\n        start_dt = dt.datetime.now()\n        random.shuffle(df)\n        losses = {}\n        if enableBatchScheme and epoch >= len(batchScheme):\n            cnt = i%(epoch\/len(batchScheme))\n            if cnt == 0:\n                minBatch = batchScheme[nextBatchIdx]\n                maxBatch = batchScheme[nextBatchIdx]\n                nextBatchIdx += 1\n                #print(f'mini and max batch is: {minBatch}')\n        batches = minibatch(df, size=compounding(minBatch, maxBatch, lr))\n        for batch in batches:\n            txt, annotations = zip(*batch)\n            model.update(txt, annotations, sgd=optimizer, \n                         #drop=next(dropout), \n                         drop=drop,\n                         losses=losses)\n            end_dt = dt.datetime.now()\n            diff = end_dt - start_dt\n        losses_output.append(losses['ner'].max())\n        #print(f'{i}: Losses - {losses} - epoch took {diff}')\n    #print(f'losses_output: {losses_output}')\n    fig = plt.figure(figsize=[20,5])\n    ax = plt.axes()\n    x = [x_i for x_i in range(len(losses_output))]\n    z = np.polyfit(x,losses_output,3)\n    p = np.poly1d(z)\n    ax.plot(x,p(x), 'r--')\n    ax.plot(x, losses_output)\n    print(f'final losses: {x[len(x)-1]}')\n        \n\ndef create_model(df):\n    df.reset_index(drop=True, inplace=True)\n    parse_dt = [parse_data(df,row) for row in df.index.tolist()] \n    return create_blank_nlp(parse_dt), parse_dt\n\nmodels = {}\ndef collect_model(key, model):\n    models[key] = model\n    print(f'Model added for {key} sentiment.')\n    \ndef get_doc(txt, sentiment, is_lower=True):\n    model = models[sentiment]\n    if is_lower:\n        return model(txt.lower())\n    else:\n        return model(txt) \n    \n\n#Method to evaluate for submission\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","341bd94f":"#redudent\n#parsed_train_data = [parse_data(train_data,row) for row in train_data.index.tolist()] \n#nlp = create_blank_nlp(parsed_train_data)\n\n#Visual inpection of parsed_train_data for word 'happy'. it returns ('text', 'annotation', 'selected_text')\n#parsed_train_data[0:5]\nsearch_word='happy'\n#g = ((dt, anno, dt[anno['entities'][0][0]:anno['entities'][0][1]]) for dt, anno in parsed_train_data if search_word in dt.lower())\n\n#for i in range(5):\n#    print(next(g))\n\n#train_model(parsed_train_data,nlp,70)\n\n#nlp.to_disk('\/kaggle\/working\/my_model')\n#nlp = nlp.from_disk('\/kaggle\/working\/my_model')","93ac1cc3":"%%time\n#Create Seaparate Models each for one sentiment\n#nlp_neg, parse_dt_neg = create_model(train_data.loc[lambda d: d.sentiment == 'negative'])\n#nlp_pos, parse_dt_pos = create_model(train_data.loc[lambda d: d.sentiment == 'positive'])\n#nlp_nu, parse_dt_nu = create_model(train_data.loc[lambda d: d.sentiment == 'neutral'])\n#collect_model('negative', nlp_neg)\n#collect_model('positive', nlp_pos)\n#collect_model('neutral', nlp_nu)\n\n#Create single model for all sentiment\nnlp_all , parse_dt_all = create_model(train_data)\ncollect_model('all', nlp_all)","22a5f188":"#Visual inpection of train_data for search_word\ntrain_data.loc[lambda d: d['text'].str.lower().str.contains(search_word)].head(10)","44c074c7":"custBatchScheme = [(cnt+1)*100 for cnt in range(10)]\n#custBatchScheme","0831b6c5":"#%%time\n#train_model(parse_dt_neg,nlp_neg, 50, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","73dccbe2":"#%%time\n#train_model(parse_dt_pos,nlp_pos, 50, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","2f9f1824":"#%%time\n#train_model(parse_dt_nu,nlp_nu, 50, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","7b464a92":"%%time\ntrain_model(parse_dt_all,nlp_all, 300, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","86d80a83":"#Validate to see if NER is working as expected\n\n#doc = nlp_neg('Sooo SAD I will miss you here in San Diego!!!'.lower())\ndoc = nlp_all('Sooo SAD I will miss you here in San Diego!!!'.lower())\ndisplacy.render(doc, style='ent')","c53a3d7b":"#Validate randon 25 records to see if NER is working as expected \nfor i in range(25):\n    idx = i#random.choices(train_data.index)[0]\n    doc = nlp_all(train_data.iloc[idx].text.lower())\n    #doc = get_doc(train_data.iloc[idx].text, train_data.iloc[idx].sentiment)\n    displacy.render(doc, style='ent')\n    print(f'row index: {idx}')\n    print(f'predicted selected_text: {doc.ents}')\n    print(f'   actual selected_text: {train_data.iloc[idx].selected_text}')\n    senti = ()\n    if len(doc.ents) > 0:\n        senti = doc.ents[0].label_\n    print(f'predicted sentiment: {senti}')\n    print(f'   actual sentiment: {train_data.iloc[idx].sentiment}')\n","5d81d96d":"#Prediction with nlp model with all entities i.e. neutral AND positive AND negative\ntest_data.head()\ntest_data[\"predict\"] = ''\ntest_data['txt_predict']=''\ntest_data['is_predicted'] = 0\nfor row in test_data.index.tolist():\n    doc = nlp_all(test_data.iloc[row].text.lower())\n    identified_senti = ''\n    senti = ''\n    txt_predict = ''\n    is_predi = 0\n    if len(doc.ents) > 0:\n        all_senti = {}\n        #print(f' doc.ents: {doc.ents}')\n        len_doc_ent = len(doc.ents)\n        all_senti = {doc.ents[idx].label_: idx for idx in range(len(doc.ents))}\n        if 'negative' in all_senti:\n            senti = 'negative'\n        elif 'positive' in all_senti:\n            senti = 'positive'\n        else:\n            senti = 'neutral'\n        is_predi = 1\n        txt_predict = doc.ents[all_senti[senti]].text\n    test_data[\"predict\"].iloc[row] = senti\n    test_data[\"txt_predict\"].iloc[row] = txt_predict\n    test_data[\"is_predicted\"].iloc[row] = is_predi\n    ","2c34225c":"doc = get_doc('I know him. he is good guy!', 'positive')\ndisplacy.render(doc, style='ent')\nlen(doc.ents)\ndoc.ents[0].label_\ndoc.ents[0].text","ec27dd16":"#Prediction with individual nlp model with entity neutral OR positive OR negative\n# test_data.head()\n# test_data[\"predict\"] = ''\n# test_data['txt_predict']=''\n# test_data['is_predicted'] = 0\n# for row in test_data.index.tolist():\n#     doc = get_doc(test_data.iloc[row].text, test_data.iloc[row].sentiment)\n#     test_data[\"is_predicted\"].iloc[row] = 0\n#     test_data[\"predict\"].iloc[row] = 'cannot_predict'\n#     if len(doc.ents) > 0:\n#         test_data[\"predict\"].iloc[row] = doc.ents[0].label_\n#         test_data[\"txt_predict\"].iloc[row] = doc.ents[0].text\n#         test_data[\"is_predicted\"].iloc[row] = 1","e1cd10b7":"d = test_data[test_data[\"is_predicted\"] == 1]\nd.head()","71c4bfd6":"print(f'            sentiment: {test_data.sentiment.unique()}')\nprint(f'              predict: {test_data.predict.unique()}')\ntotal_rec = len(test_data)\ncnt = len(test_data[test_data.is_predicted == 0])\nprint(f'   count of test_data: {total_rec}')\nprint(f'couldnt predict count: {cnt}')\ncnt_percent = cnt\/total_rec\nprint(f'couldnt predict count: {cnt_percent}')","255bd4a7":"confusion_matrix(test_data.sentiment, test_data.predict)","f9b197a7":"print(classification_report(test_data.sentiment, test_data.predict))","f3b281b9":"pip install vaderSentiment","e5a128d1":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer","f263b6e0":"analyzer = SentimentIntensityAnalyzer()","5fe675d2":"def v_sentiment(x):\n    return analyzer.polarity_scores(x)\n\ndef v_sentiment_class(x):\n    if x['compound'] <= -0.05:\n        return 'negative'\n    elif x['compound'] <= 0.05:\n        return 'neutral'\n    else:\n        return 'positive'\n\nnlp1 = spacy.load('en_core_web_sm')\ndef rem_stop_word(txt):\n    return ' '.join([word.text for word in nlp1(txt) if nlp1.vocab[word.text].is_stop == False])\n    ","1113dbd2":"#Prediction - with stop words\n\ntest_data['v_senti_sw'] = test_data['text'].apply(v_sentiment)\ntest_data['v_senti_sw_class'] = test_data['v_senti_sw'].apply(v_sentiment_class)\ntest_data['v_senti_sw_c_score'] = [txt['compound'] for txt in test_data['text'].apply(v_sentiment)]\ntest_data.head()\n","5425ce40":"test_data.sentiment.unique()","496d332e":"test_data.v_senti_sw_class.unique()","d5e2ff6c":"confusion_matrix(test_data.sentiment, test_data.v_senti_sw_class)","db5fda31":"#Prediction - including stop words\nprint(classification_report(test_data.sentiment, test_data.v_senti_sw_class))","94b490fe":"# find out data for which sentiment and vader prediction doesn't match\ndf = test_data.loc[lambda d: d['sentiment'] != d['v_senti_sw_class']]\ndf.head()","8bd6a554":"#1230 records sentiment doesn't match with vader prediction\ndf.sentiment.value_counts()","80fe04a3":"#Neutral sentiment (given data) was predicted incorrect by vader \ndf.loc[lambda d: d.sentiment == 'neutral'].v_senti_sw_class.value_counts()","c1bcf829":"#Positive sentiment (given data) was predicted incorrect by vader \ndf.loc[lambda d: d.sentiment == 'positive'].v_senti_sw_class.value_counts()","f0890930":"#Negative sentiment (given data) was predicted incorrect by vader \ndf.loc[lambda d: d.sentiment == 'negative'].v_senti_sw_class.value_counts()","c359d336":"#Sample of data in which given sentiment wasn't predicted by vader correctly\ntest_data[test_data.textID == '00d5195223']","404c221d":"#Prediction - without stop words\n\ntest_data['v_senti_nsw'] = test_data['text'].apply(rem_stop_word).apply(v_sentiment)\ntest_data['v_senti_nsw_class'] = test_data['v_senti_nsw'].apply(v_sentiment_class)\ntest_data['v_senti_nsw_c_score'] = [txt['compound'] for txt in test_data['text'].apply(rem_stop_word).apply(v_sentiment)]\ntest_data.head()","834a4436":"#Matrix between vader prediction \"with\" and vader prediction \"without\" stop word.\nconfusion_matrix(test_data.v_senti_sw_class, test_data.v_senti_nsw_class)","cde11a48":"#Classification report between vader prediction \"with\" and vader prediction \"without\" stop word.\nprint(classification_report(test_data.v_senti_sw_class, test_data.v_senti_nsw_class))","a125d91e":"#Classification report between given sentiment and vader prediction \"with\" stop word.\nprint(classification_report(test_data.sentiment, test_data.v_senti_sw_class))","a8a873d1":"#Classification report between given sentiment and vader prediction \"without\" stop word.\nprint(classification_report(test_data.sentiment, test_data.v_senti_nsw_class))","6702d904":"#Classification report between given sentiment and spacy ner prediction \"with\" stop word.\n\nprint(classification_report(test_data.sentiment, test_data.predict))","f973af2d":"sub_df = test_data[['textID','txt_predict']]\nsub_df.columns = [['textID', 'selected_text']]\nsub_df.to_csv('\/kaggle\/working\/submission.csv', index=False, header=True)\nprint(\"done\")","396e3bd8":"test_data.loc[test_data.textID =='1fa8e6ad66']","c461e107":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a0a76f7c":"# Sentiment Analysis using VADER (Valance Aware Dictionary for Sentiment Reasoning)"}}