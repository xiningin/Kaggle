{"cell_type":{"ed8c7c05":"code","e28cf44d":"code","56d4c41a":"code","35885c17":"code","e33061f7":"code","0efd0147":"code","bcf5b2c0":"code","ed69db75":"code","d1a06641":"code","81fb1cb8":"markdown","34ae082e":"markdown","d2184028":"markdown","dc871223":"markdown","0ab5f231":"markdown","b31176fa":"markdown","77d52593":"markdown","3e411ab3":"markdown","512b06d1":"markdown","fdc0b054":"markdown"},"source":{"ed8c7c05":"import pandas as pd\nimport numpy as np","e28cf44d":"filepath = '..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv'\ndata_full = pd.read_csv(filepath, index_col='id')\n\ndata_full.head()","56d4c41a":"from sklearn.model_selection import train_test_split\n\nfeatures = ['gender', 'age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'smoking_status']\n\nX = data_full[features]\n\nX['smoking_status'].replace('Unknown', np.nan, inplace=True)\n\ny = data_full.stroke\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2)","35885c17":"numerical_cols = [col for col in X_train if X_train[col].dtype in ('int64', 'float64')]\ncategorical_cols = [col for col in X_train if X_train[col]. dtype == 'object']\n\nfor col in X_train:\n    print(f\"Number of missing values in {col.title()} = {X_train[col].isnull().sum()}\")","e33061f7":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\n\nnumerical_preprocessor = SimpleImputer(strategy='constant')\n\ncategorical_preprocessor = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('one-hot-encoder', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('numerical', numerical_preprocessor, numerical_cols),\n    ('categorical', categorical_preprocessor, categorical_cols),\n])","0efd0147":"from sklearn.metrics import mean_absolute_error\n\ndef get_m_a_e(model_used, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n    \"Function that gets the mean absolute error after fitting and predicting a model\"\n    model_used.fit(X_t, y_t)\n    predictions = model_used.predict(X_v)\n    mae = mean_absolute_error(predictions, y_v)\n    return mae","bcf5b2c0":"from xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel_1 = XGBRegressor(n_estimators=50, learning_rate=0.1)\nmodel_2 = XGBRegressor(n_estimators=75, learning_rate=0.1)\nmodel_3 = XGBRegressor(n_estimators=100, learning_rate=0.1)\nmodel_4 = XGBRegressor(n_estimators=500, learning_rate=0.1)\n\nmodel_5 = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel_6 = RandomForestClassifier(n_estimators=200, random_state=0)\nmodel_7 = RandomForestClassifier(n_estimators=300, random_state=0)\nmodel_8 = RandomForestClassifier(n_estimators=400, random_state=0)\n\nmodels = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8]","ed69db75":"i = 1\n\nfor model in models:\n    my_pipeline = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])\n    result = get_m_a_e(my_pipeline)\n    print(f\"Mean absolute error for model {i} = {result}\")\n    i += 1","d1a06641":"from sklearn.metrics import classification_report\n\nmodel = RandomForestClassifier(n_estimators=300, random_state=0)\n\nmy_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\nmy_pipeline.fit(X_train, y_train)\npreds = my_pipeline.predict(X_valid)\n\nprint(classification_report(y_valid, preds))\n\noutput = pd.DataFrame({'Stroke_data': y_valid.iloc[:], 'Stroke_preds': preds})\noutput.to_csv('output.csv', index=False)","81fb1cb8":"**MAE function**","34ae082e":"# Creating models","d2184028":"**Testing models**","dc871223":"# Selecting important data","0ab5f231":"# Importing the data","b31176fa":"I am not taking the \"ever_married\", \"work_type\" and \"Residence_type\" since the have nothing to do with suffering from a stroke.","77d52593":"**Models**","3e411ab3":"First I divide the columns in numerical and categorical. After that I create a Pipeline for both of them, containing the SimpleImputer and OneHotEncoder.","512b06d1":"# Preprocessing","fdc0b054":"# Output"}}