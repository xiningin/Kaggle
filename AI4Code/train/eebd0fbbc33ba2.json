{"cell_type":{"9e2aaee1":"code","e785fe4c":"code","6c4f6aa7":"code","8c8ef51e":"code","7d62caa1":"code","84f7fdc3":"code","41e209cc":"code","233ee603":"code","b6bb46b2":"code","5abec6c9":"code","33820147":"code","4a3f2a76":"code","8e066b3f":"code","c7e2248c":"code","f73dc74d":"code","9ff2be17":"code","1852a51e":"code","2efd30b0":"code","17a0f8ca":"code","797539eb":"code","1bc1b91c":"code","8b6d52c3":"code","f68ce50d":"code","3fa68bff":"code","46439861":"code","3550610e":"code","2e2756e9":"code","ed48348f":"code","aeb2e00e":"code","03393086":"code","40493e7a":"code","7ed36930":"code","af0e5639":"code","39e5b1d3":"code","098d8ae9":"code","d92b5e5e":"code","477b721c":"code","55751396":"markdown"},"source":{"9e2aaee1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e785fe4c":"from datetime import datetime\nfrom datetime import date\nfrom datetime import time","6c4f6aa7":"df = pd.read_csv('..\/input\/ecommerce-data\/data.csv',encoding= 'cp874')\ndf","8c8ef51e":"df_time = df.dropna()\ndf_time = df_time[df_time['Quantity']>0]\ndf_time = df_time[df_time['UnitPrice']>0]\ndf_1 = df_time[~df_time['StockCode'].str.contains('POST')]\ndf_1","7d62caa1":"df_t = df_1.loc[:,['CustomerID','InvoiceNo','InvoiceDate']]\ndf_t['InvoiceDate'] = pd.to_datetime(df_t.InvoiceDate)\ndf_t.info()","84f7fdc3":"df_t = df_t.drop_duplicates()","41e209cc":"wd = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\nt = []\ns = []\nfor i in df_t.InvoiceDate :\n    w = i.weekday()\n    s.append(wd[w])\n    if w in [0,1,2,3,4] :\n        t.append('Weekday')\n    else :\n        t.append('Weekend')\n","233ee603":"df_t['DoW'] = s\ndf_t['NofWeek'] = t\ndf_t","b6bb46b2":"df_t = df_t.reset_index()\ndf_t","5abec6c9":"df_t = df_t.drop(['index'],axis=1)\ndf_t","33820147":"from sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_col = pd.DataFrame(OH_encoder.fit_transform(df_t[['NofWeek']]),columns=['Per_weekday','Per_weekend'])\nOH_col","4a3f2a76":"df_t1 = pd.concat([df_t,OH_col],axis=1)\ndf_t1","8e066b3f":"g = df_t1.groupby('CustomerID').sum()\ng","c7e2248c":"g['Count'] = g.sum(axis=1)\ng['Percent_Weekday'] = ((g.Per_weekday \/ g.Count)*100).round(2)\ng['Percent_Weekend'] = ((g.Per_weekend \/ g.Count)*100).round(2)\ng","f73dc74d":"g = g.reset_index()\ng = g.loc[:,['CustomerID','Percent_Weekday','Percent_Weekend']]\ng","9ff2be17":"df_timing = df_t.loc[:,['CustomerID','InvoiceNo','InvoiceDate']]\ntime = []\nfor i in df_timing.InvoiceDate :\n    time.append(i.hour)\ndf_timing['Time'] = time\ndf_timing","1852a51e":"t = []\nfor i in df_timing.Time :\n    if i < 11 :\n        t.append('Morning')\n    elif i < 14 :\n        t.append('Noon')\n    elif i <17 :\n        t.append('Afternoon')\n    else:\n        t.append('Evening')\ndf_timing['Timing'] = t\ndf_timing","2efd30b0":"OH_timing = pd.DataFrame(OH_encoder.fit_transform(df_timing[['Timing']]),columns=['per_morning','per_noon','per_afternoon','per_evening'])\nOH_timing","17a0f8ca":"OH_timing = OH_timing.rename(columns = {'per_morning':'Afternoon','per_noon':'Evening','per_afternoon':'Morning','per_evening':'Noon'})\nOH_timing","797539eb":"class_names = list(OH_encoder.categories_)","1bc1b91c":"class_names","8b6d52c3":"df_timing['Time'] = df_timing['Time'].astype('category')\ndf_timing.info()","f68ce50d":"df_t2 = pd.concat([df_timing,OH_timing],axis=1)\ndf_t2","3fa68bff":"c = df_t2.groupby('CustomerID').sum()\nc","46439861":"c['Count'] = c.sum(axis=1)\nc['%_morning'] = ((c['Morning'] \/ c['Count'])*100).round(2)\nc['%_noon'] = ((c['Noon'] \/ c['Count'])*100).round(2)\nc['%_afternoon'] = ((c['Afternoon'] \/ c['Count'])*100).round(2)\nc['%_evening'] = ((c['Evening'] \/ c['Count'])*100).round(2)\nc","3550610e":"c = c.reset_index()\nc = c.loc[:,['CustomerID','%_morning','%_noon','%_afternoon','%_evening']]\nc","2e2756e9":"df_finish = g.merge(c)\ndf_finish","ed48348f":"df_finish['CustomerID'] = df_finish['CustomerID'].astype('category')\ndf_finish.describe()","aeb2e00e":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score,silhouette_samples","03393086":"X = ['Percent_Weekday', 'Percent_Weekend', '%_morning','%_noon', '%_afternoon', '%_evening']","40493e7a":"df_input = df_finish[X]\ndf_input","7ed36930":"model = KMeans(n_clusters = 5)\ny_kmeans = model.fit_predict(df_input)","af0e5639":"df_finish['Cluster'] = y_kmeans\ndf_finish","39e5b1d3":"df_finish.Cluster.value_counts()","098d8ae9":"T = df_finish.groupby('Cluster').mean()\nT['Count'] = df_finish.Cluster.value_counts()\nT","d92b5e5e":"T['Group Name'] = ['Weekday, Morning','Weekday, Morning-Noon-Afternoon','Weekday, Noon','Weekend, Noon-Afternoon','Weekday,Afternoon']\nT","477b721c":"df_finish[df_finish['Cluster'] == 0 ]","55751396":"Look at the customer cluster 0 . They usually buy the product on Weekday and in the morning."}}