{"cell_type":{"809947be":"code","47756fd6":"code","3fa3d6d9":"code","27135b2a":"code","ad41fefa":"code","31975f0c":"code","67061f61":"code","9103435a":"code","3bddb805":"code","de5b4711":"code","e033db0a":"code","385aaf4c":"code","a98083ea":"markdown","2c5ede4e":"markdown","95070127":"markdown","8b2e3fb6":"markdown","95acb43c":"markdown"},"source":{"809947be":"import numpy as np\nimport pandas as pd \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential,load_model\nfrom tqdm import tqdm\nimport cv2 as cv\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport gc\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats","47756fd6":"main_folder = '..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/'\ndf = pd.read_csv('..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/labels.csv')\ndf = df[df.photo_quality==1]\ndf.head()","3fa3d6d9":"'''\nFrom https:\/\/www.kaggle.com\/koshirosato\/bee-or-wasp-base-line-using-resnet50\n'''\nfor idx in tqdm(df.index):    \n    df.loc[idx,'path']=df.loc[idx,'path'].replace('\\\\', '\/') \n    \ndf.head()","27135b2a":"df_test = df[df.is_final_validation==1].reset_index()\ndf_train = df[df.is_final_validation!=1].reset_index()\ndf_train.shape,df_test.shape","ad41fefa":"df.label.value_counts().plot.pie(autopct='%1.1f%%')","31975f0c":"'''\nFrom https:\/\/www.kaggle.com\/koshirosato\/bee-or-wasp-base-line-using-resnet50\n'''\nimg_size = 225\ndef create_datasets(df, img_size):\n    imgs = []\n    for path in tqdm(df['path']):\n        img = cv.imread(main_folder + path)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = cv.resize(img, (img_size,img_size))\n        imgs.append(img)\n        \n    imgs = np.array(imgs, dtype='float32')\n    imgs = imgs \/ 255.0\n    df = pd.get_dummies(df['label'])\n    return imgs, df\n\n\ntrain, df_train = create_datasets(df_train, img_size)\ntest, df_test = create_datasets(df_test, img_size)","67061f61":"print(train.shape)\nsub=[]\nfor i in range(5):\n    sub.append(np.random.choice(train.shape[0], 3000, replace=False))\nsub = np.array(sub).T\nsub.shape","9103435a":"def mobilenet():\n    model = Sequential()\n    model.add(layers.Input(shape=(img_size,img_size,3)))\n    model.add(tf.keras.applications.MobileNetV2(include_top=False,weights=\"imagenet\"))\n    #model.add(layers. GlobalAveragePooling2D())#BatchNormalization()\n    model.add(layers.Flatten())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(128,activation='relu'))\n    #model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(3,activation='softmax'))\n    for layer in model.layers[:1]:\n        layer.trainable = False\n    #mobilenet.summary()\n    return model\n\ndef xception():\n    model = Sequential()\n    model.add(layers.Input(shape=(img_size,img_size,3)))\n    model.add(tf.keras.applications.Xception(weights='imagenet',include_top=False))\n    model.add(layers. GlobalAveragePooling2D())#BatchNormalization()\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(3,activation='softmax'))\n    for layer in model.layers[:1]:\n        layer.trainable = False\n    #resnet50.summary()\n    return model\n\ndef inception():\n    model = Sequential()\n    model.add(layers.Input(shape=(img_size,img_size,3)))\n    model.add(tf.keras.applications.InceptionV3(include_top=False,weights=\"imagenet\"))\n    model.add(layers. GlobalAveragePooling2D())#BatchNormalization()\n    model.add(layers.Flatten())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(3,activation='softmax'))\n    for layer in model.layers[:1]:\n        layer.trainable = False\n    #inception.summary()\n    return model\n\ndef densenet():\n    model = Sequential()\n    model.add(layers.Input(shape=(img_size,img_size,3)))\n    model.add(tf.keras.applications.DenseNet121(include_top=False,weights=\"imagenet\"))\n    model.add(layers.Flatten())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dense(256,activation='relu'))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Dense(3,activation='softmax'))\n    for layer in model.layers[:1]:\n        layer.trainable = False\n    #inception.summary()\n    return model\n\ndef vgg():\n    model = Sequential()\n    model.add(layers.Input(shape=(img_size,img_size,3)))\n    model.add(tf.keras.applications.VGG16(include_top=False,weights=\"imagenet\"))\n    model.add(layers.Flatten())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(3,activation='softmax'))\n    for layer in model.layers[:1]:\n        layer.trainable = False\n    #inception.summary()\n    return model\n","3bddb805":"models={'mobilenet':mobilenet,'xception':xception,'inception':inception,'densenet':densenet,'vgg':vgg}\npaths=['mobilenet.h5','xception.h5','inception.h5','densenet.h5','vgg16.h5']","de5b4711":"def history_plot(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n\n    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n\n    axes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\n    axes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\n    axes[0].set_title('Training and Validation Accuracy')\n    axes[0].legend(loc='best')\n\n    axes[1].plot(epochs, loss, 'r-', label='Training Loss')\n    axes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\n    axes[1].set_title('Training and Validation Loss')\n    axes[1].legend(loc='best')\n\n    plt.show()","e033db0a":"%%time\n#hist=[]\nprint('Training: ')\nfor m,model_path,tr in zip(models,paths,sub.T):\n    model=models[m]()\n    train_sub=train[tr]\n    #print(train_sub.shape)\n    df_train_sub=df_train.values[tr]\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n    history = model.fit(train_sub,df_train_sub,batch_size=128,epochs=25,validation_split=0.1,callbacks=[checkpoint_cb],verbose=0)\n    print('Model: ',m)\n    #hist.append(history)\n    history_plot(history)\n    del model, history\n    gc.collect()\n    print('')\n# del models","385aaf4c":"labels=[]\nfor m,model_path in zip(models,paths):\n    model = load_model(model_path)\n    print('Model: ',m,' Acc: ',model.evaluate(test,df_test,verbose=0)[1])\n    y_pred=model.predict(test,verbose=0)\n    y_pred=np.argmax(y_pred,axis=1)\n    labels.append(y_pred)\n    print('')\n    del model\n    gc.collect()\nlabels = np.array(labels)\nlabels=labels.T\ny=stats.mode(labels,axis=1)[0]\nprint('Ensemble: ',accuracy_score(y,np.argmax(df_test.values,axis=1)))","a98083ea":"Voting: ","2c5ede4e":"It's my first ensemble learning","95070127":"Each classifier train on a subset of the train set","8b2e3fb6":"Replace `\\`to `\/`","95acb43c":"Use mobilenetV2, xceptionV3, inception, densenet121, VGG16 as base classifier"}}