{"cell_type":{"ec1f9f58":"code","33e318ae":"code","299061e9":"code","2d745bee":"code","3f7b11ee":"code","6e995e70":"code","a2dbddfe":"code","e63107e7":"code","04dc6ae0":"code","916ae183":"code","f7c43e04":"code","ac4de7f9":"code","a5af7d47":"code","a55a8f56":"code","5cbd2bdd":"code","6e2da7ed":"code","8ce140bd":"code","afa0b52d":"code","432e4069":"code","396d608e":"code","1a9e311d":"code","3c26c2a7":"code","362247ea":"code","204e291b":"code","12b48b46":"code","47c5688e":"code","0b9033a9":"code","debbd6bf":"code","25fb7319":"code","cf58accc":"code","c7180f53":"code","4b5e54ae":"code","df118271":"code","abfbf2cf":"code","e46af778":"code","c6e603ba":"code","55cabba4":"code","e8574154":"code","bd52bf24":"code","22d6d2c4":"code","b37cbe54":"code","b1980555":"code","899d4fee":"code","c85f83b3":"code","6f9bac2a":"code","333fab12":"code","dd704b09":"code","1314621e":"code","fc5bfda8":"code","4efe1c5e":"code","7c35c3b9":"code","f816d3a3":"code","86c7f3e7":"code","451c406f":"code","ffa4cf39":"code","ef543133":"code","4db12784":"code","505c6255":"code","eebdc3cc":"code","4fda5796":"code","0141ec9d":"code","532be474":"code","1f39b622":"code","4ee54839":"code","d72a4d1b":"code","c4a1bdb7":"code","0df8c48d":"code","fe0e5349":"code","b5167466":"code","f9e534e6":"code","ef40abd3":"code","3dbe55a6":"code","ab127a54":"code","6bd735f7":"code","b648f120":"code","bb9d776c":"code","ba2dc428":"code","3e92a988":"code","29d22c62":"code","090783ec":"code","eac50da6":"code","14401dcf":"code","02bd3513":"code","91967fb2":"code","f0894cff":"code","0fe53239":"code","08da8faa":"code","5722f089":"code","94535b94":"code","c9bc5c70":"code","f3d7ee3c":"code","10f817f3":"code","5427d437":"code","e1c77d9d":"code","cd34929b":"code","373bf5d3":"code","c445c6a8":"code","ec784aab":"code","d3669d50":"code","80e0645a":"code","40c844f4":"code","cfa11feb":"code","19e5ac77":"code","0da22dfe":"code","5bc5a62c":"code","caf29e1b":"code","d15a3f1e":"code","fb2b762a":"code","894bbe7f":"code","9144c7e4":"code","6834642b":"code","b8cadae4":"code","67721bae":"code","e2c28186":"code","5bc8049f":"code","01871396":"code","a9b51f73":"code","097b321f":"code","9731065a":"code","7a45b1fc":"code","40288065":"code","5e7b0f66":"code","5202267b":"code","b083924d":"code","5464a805":"code","526be251":"markdown","fd2205c9":"markdown","a18707d9":"markdown","df16fd03":"markdown","51a00930":"markdown","d16680bb":"markdown","b0d90821":"markdown","5f84ebe4":"markdown","48ff23d7":"markdown","6a15aace":"markdown","d95564c7":"markdown","e9c9379f":"markdown","d0bebfb6":"markdown","5c7bbdc3":"markdown","a48fe522":"markdown","ce7e3c45":"markdown","583d67c9":"markdown","e55a3186":"markdown","09048063":"markdown","27bee21e":"markdown","d6a20f43":"markdown","e02d17c8":"markdown","8d9be0c1":"markdown","90974d2f":"markdown","8ed8b01d":"markdown","2f4b03bc":"markdown","1b58e7b7":"markdown","7094cc50":"markdown","53230723":"markdown","87b5e089":"markdown","e595f967":"markdown","b9e83522":"markdown","ce84d415":"markdown","c3ae26d3":"markdown","d2bfc63f":"markdown","8a03dc28":"markdown","2e585c81":"markdown","95609627":"markdown","6f33160f":"markdown","32e7c35b":"markdown","e93247ac":"markdown","0e5337fe":"markdown","ca938567":"markdown","9d700730":"markdown","78d5a7bd":"markdown","8c2b6b68":"markdown","f3cb5f24":"markdown","647e5be6":"markdown","6b2eb117":"markdown","f49dbaba":"markdown","081dbb1a":"markdown","a2c9454f":"markdown","637f0f04":"markdown","0b8be47a":"markdown","66145a03":"markdown","d78898ca":"markdown","c64bf5f5":"markdown","ace8ca3a":"markdown","7c21afcc":"markdown","9f0433de":"markdown"},"source":{"ec1f9f58":"import numpy as np\nimport pandas as pd\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\n!pip install xgboost\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score","33e318ae":"path = \"..\/input\/atpdata\/\"\ndata = pd.read_csv(path + \"ATP.csv\")","299061e9":"data.head()","2d745bee":"data.shape","3f7b11ee":"data.info()","6e995e70":"#The score column is the most important in this data set.\ndata[\"score\"].isna().sum()","a2dbddfe":"#We can delete the row with NaN score (0.1% of data)\n#we will drop the rows with \"W\/O\" score (0.43 % of data)\ndata_drop_nanScore = data.dropna(axis=0, subset=[\"score\"])\ndata_drop_nanScore = data_drop_nanScore[data_drop_nanScore[\"score\"] != 'W\/O']\ndata_drop_nanScore = data_drop_nanScore[data_drop_nanScore[\"score\"] != ' W\/O']\ndata_drop_nanScore = data_drop_nanScore[data_drop_nanScore[\"score\"] != 'DEF']\ndata_drop_nanScore = data_drop_nanScore[data_drop_nanScore[\"score\"] != 'In Progress']\ndata_drop_nanScore = data_drop_nanScore[data_drop_nanScore[\"score\"] != 'Walkover']\n# we observed some scores having weird format (example 6-Feb)\n#This line below is to drop them\nexpression = re.compile(\"\\d+-[a-zA-Z]+\")\nweird_score = [x for x in data_drop_nanScore.score.values.tolist() if re.search(expression, x)]\nfor s in weird_score:\n    data_drop_nanScore = data_drop_nanScore[data_drop_nanScore[\"score\"] != s]  \n\n# We kept ~99% of the initial data\ndisplay(data_drop_nanScore.shape)","e63107e7":"#Using score column, let's compute the set won foreach player. the new columns will be: \n# l_setW and w_setW\ndef score_to_sets(score):\n    \n    \"\"\"\n    this function will compute l_setW, w_setW\n    score: the game score\n    return\n    l_setW: set won by the loser\n    w_setW: set won by the winner\n    \"\"\"\n         \n    #Correct some particular cases\n    #score end with 'RET' or 'ABN' or 'ABD' ....\n    if score[-3:] == 'RET' or score[-3:] == 'ABN' \\\n       or score[-3:] == 'DEF' or score[-3:] == 'ABD':\n        score = score[:-4]\n    if score[-21:] == \"Played and unfinished\": \n        score = score[:-22]\n    if score[-20:] == \"Played and abandoned\": \n        score = score[:-21]    \n    if score[-7:] == \"Default\":\n        score = score[:-8]\n    if score[-10:] == \"Unfinished\":\n        score = score[:-11]\n    \n    l_setW, w_setW = 0, 0\n    sets = score.split()\n    for set_i in sets:\n        #Deal with particular score (tie break)\n        #exp: 3-6 7-6(5)\n        if set_i[-1] == \")\":\n            # the 2 lines of code below ensure this cases:\n            #    3-6 7-6(5)\n            #    6-7(10) 7-5\n            #    6-12(10) 7-5  12-6\n            tie_break = set_i.split(\"(\")\n            tie_break = int(tie_break[1][:-1])\n            #Theorically, it is possible to get tie_break > 100 but practically no\n            if tie_break < 10:\n                set_i = set_i[:-3]\n            else:\n                set_i = set_i[:-4]\n        \n        #Deal with particular score (example 7-6 1-6 [10-6])        \n        if set_i[0] == \"[\":\n            set_i = set_i[1:-1]\n        set_i = set_i.split(\"-\")\n        if int(set_i[0]) > int(set_i[1]):\n            w_setW += 1\n        elif int(set_i[0]) < int(set_i[1]):\n            l_setW += 1\n        \n\n    return l_setW, w_setW\n\nsets_won = data_drop_nanScore[\"score\"].apply(lambda x : score_to_sets(x) )","04dc6ae0":"data_drop_nanScore[\"l_setW\"] = sets_won.apply(lambda x: x[0])\ndata_drop_nanScore[\"w_setW\"] = sets_won.apply(lambda x: x[1])\ndata_drop_nanScore.reset_index()","916ae183":"data_drop_nanScore.info()","f7c43e04":"subset = [\n    \"l_1stIn\", \"l_1stWon\", \"l_2ndWon\", \"l_SvGms\", \"l_ace\",\n    \"l_bpFaced\", \"l_bpSaved\", \"l_df\", \"l_svpt\",\n    \"w_1stIn\", \"w_1stWon\", \"w_2ndWon\", \"w_SvGms\", \"w_ace\",\n    \"w_bpFaced\", \"w_bpSaved\", \"w_df\", \"w_svpt\"\n    ]\ndata_drop_nanScore_cleaned = data_drop_nanScore.dropna(axis=0, subset=subset)","ac4de7f9":"data_drop_nanScore_cleaned.info()","a5af7d47":"# We drop draw_size column. It is an empty column\ndata_drop_nanScore_cleaned = data_drop_nanScore_cleaned.drop(labels=[\"draw_size\"], axis=1)","a55a8f56":"#loser_age: The best solutipon is to fill NaN values with the median.\n# The column distribution agree with our choice\n# loser_age before modification\nn_Nan_l_age = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"loser_age\"])[\"loser_age\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_l_age)\n\n# Fill Nan with the median\nmedian_loser_age = n_Nan_l_age.median()\ndata_drop_nanScore_cleaned[\"loser_age\"] = data_drop_nanScore_cleaned[\"loser_age\"]\\\n                                          .fillna(median_loser_age)\n\n# loser_age after modification (fillna)\n\nsns.distplot(data_drop_nanScore_cleaned[\"loser_age\"])\nplt.legend(labels=['Before fillna','after fillna'])\nplt.title(\"loser_age distribution\")","5cbd2bdd":"# We choose to drop loser_entry column (no clear method to fill nan values)\ndata_drop_nanScore_cleaned = data_drop_nanScore_cleaned.drop(labels=[\"loser_entry\"], axis=1)","6e2da7ed":"data_drop_nanScore_cleaned[\"loser_hand\"].value_counts()","8ce140bd":"# Get the loser with nan loser_hand\nnan_hand_names = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_hand\"]\\\n                                           .isnull()][\"loser_name\"].unique()\nprint(nan_hand_names)\n\n# See if the loser_hand is defined for another game\n# when the player is a loser\nfor name in nan_hand_names:\n    hands = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_name\"] == name][\"loser_hand\"]\n    if hands.isnull().all() == False:\n        print(\"loser_hand founded for loser_name\" + name)\n# when the player is a winner\nfor name in nan_hand_names:\n    hands = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_name\"] == name][\"winner_hand\"]\n    if hands.isnull().all() == False:\n        print(\"loser_hand founded for winner_name\" + name)","afa0b52d":"max_loser_hand = data_drop_nanScore_cleaned[\"loser_hand\"].value_counts().idxmax()\ndata_drop_nanScore_cleaned[\"loser_hand\"] = data_drop_nanScore_cleaned[\"loser_hand\"]\\\n                                          .fillna(max_loser_hand)","432e4069":"data_drop_nanScore_cleaned[\"loser_hand\"].value_counts()","396d608e":"n_Nan_l_ht = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"loser_ht\"])[\"loser_ht\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_l_ht)","1a9e311d":"data_drop_nanScore_cleaned.describe()[\"loser_ht\"]","3c26c2a7":"# Get the loser with nan loser_ht\nnan_ht_names = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_ht\"]\\\n                                           .isnull()][\"loser_name\"].unique()\nprint(nan_ht_names)\n\n# See if the loser_ht is defined for another game\n# when the player is a loser\nfor name in nan_ht_names:\n    ht = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_name\"] == name][\"loser_ht\"]\n    if ht.isnull().all() == False:\n        print(\"loser_ht founded for loser_name\" + name)\n# when the player is a winner\nfor name in nan_hand_names:\n    ht = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_name\"] == name][\"winner_ht\"]\n    if ht.isnull().all() == False:\n        print(\"loser_ht founded for loser_name\" + name)","362247ea":"data_drop_nanScore_cleaned[\"loser_ht\"].mean()","204e291b":"mean_loser_ht = data_drop_nanScore_cleaned[\"loser_ht\"].mean()\ndata_drop_nanScore_cleaned[\"loser_ht\"] = data_drop_nanScore_cleaned[\"loser_ht\"]\\\n                                          .fillna(mean_loser_ht)","12b48b46":"# Get the loser with nan loser_ht\nnan_rank_id = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank\"]\\\n                                           .isnull()][\"loser_id\"]\nnan_rank_dates = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank\"]\\\n                                           .isnull()][\"tourney_date\"]\n\n# print(nan_rank_id)\n# print(nan_rank_dates)\n\n\nranks = []\nsuffix = \"atp_rankings_\"\n\nindex = 0\nfor date in nan_rank_dates:\n    id_player = nan_rank_id.to_list()[index]\n    index = index + 1\n    if int(str(date)[:4][-2:]) == 19:\n        file_rank = path + suffix + \"current.csv\"\n        df_rank = pd.read_csv(file_rank)\n        df_rank = df_rank[df_rank[\"ranking_date\"] == date]\n        lst3 = [value for value in df_rank.player.to_list()]\n        if (id_player in lst3):\n            print(\"ok\")\n\n        \n#     elif (year >= 10 \n#         and year <=18):\n#         file_rank = path + suffix + \"10s.csv\"\n        \n#     elif (year >= 0\n#         and year <= 9):   \n#         file_rank = path + suffix + \"00s.csv\"\n\n#     elif (year >= 90\n#         and year <= 99):\n#         file_rank = path + suffix + \"90s.csv\"\n\n#     elif (year >= 80\n#           and year <= 89):\n#         file_rank = path + suffix + \"80s.csv\"\n\n#     elif (year >= 70\n#         and year <= 79):\n#         file_rank = path + suffix + \"70s.csv\"","47c5688e":"n_Nan_l_rank = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"loser_rank\"])[\"loser_rank\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_l_rank)","0b9033a9":"n_Nan_l_rank.describe()","debbd6bf":"add = 0\nfor index in nan_rank_id.index:\n    data_drop_nanScore_cleaned.at[index, \"loser_rank\"] = n_Nan_l_rank.max() + add\n    add = add + 1 ","25fb7319":"plt.figure(figsize=(10,10))\nsns.distplot(data_drop_nanScore_cleaned[\"loser_rank\"])","cf58accc":"n_Nan_l_rank_points = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"loser_rank_points\"])[\"loser_rank_points\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_l_rank_points)","c7180f53":"n_Nan_l_rank_points.describe()","4b5e54ae":"nan_rank_points_id = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"loser_id\"]","df118271":"len(nan_rank_points_id)","abfbf2cf":"len(nan_rank_id)","e46af778":"# let's see if the player is unranked, he have a nan rank points\ninter = nan_rank_id[nan_rank_id.isin(nan_rank_points_id)]\nprint((inter == nan_rank_id).sum())","c6e603ba":"nan_rank_points_id.shape","55cabba4":"print(nan_rank_points_id.shape)\nfor index in nan_rank_id.index:\n    data_drop_nanScore_cleaned.at[index, \"loser_rank_points\"] = 0\nprint(data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"loser_id\"].shape)","e8574154":"new_nan_rank_points_id = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"loser_id\"]\nnew_nan_rank_points_rank = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"loser_rank\"]\nnan_rank_points_dates = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"tourney_date\"]\nnan_rank_points_seeds = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"loser_seed\"]","bd52bf24":"index = 0\npoints = []\nfor date in nan_rank_points_dates:\n#     date = 19910204\n    print(date)\n    id_player = new_nan_rank_points_id.to_list()[index]\n#     id_player = 101723\n    print(id_player)\n    # games and dates when the player lose and win\n    df_player = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_id\"] == id_player]\n    df_player_winner = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_id\"] == id_player]\n    print(df_player.shape)\n    df_dates = df_player[\"tourney_date\"].to_list()\n    df_dates_winner = df_player_winner[\"tourney_date\"].to_list()\n    # seperate the date in loser\/winner and last\/future\n    df_dates_last = [d for d in df_dates if d < date]\n    df_dates_last_winner = [d for d in df_dates_winner if d < date]\n    df_dates_future = [d for d in df_dates if d > date]\n    df_dates_future_winner = [d for d in df_dates_winner if d > date]\n    print(\"****dates*******\")\n#     print(df_dates)\n#     print(df_dates_last)\n#     print(df_dates_last_winner)\n#     print(df_dates_future)\n#     print(df_dates_future_winner)\n    \n    \n    loser_points_last = 0\n    winner_points_last = 0\n    loser_points_future = 0\n    winner_points_future = 0\n    # get the nearest points from the actual date \n    for d in df_dates_last[::-1]:\n        if len(df_dates_last) > 0:\n            loser_points_last = df_player[df_player[\"tourney_date\"]\\\n                                               == d][\"loser_rank_points\"]\n            if (loser_points_last.last_valid_index()):\n                break\n        \n    for d in df_dates_last_winner[::-1]:\n        if len(df_dates_last_winner) > 0:\n            winner_points_last = df_player_winner[df_player_winner[\"tourney_date\"]\\\n                                               == d][\"winner_rank_points\"]         \n            if  (winner_points_last.last_valid_index()):\n                break\n                \n    for d in df_dates_future:\n        if len(df_dates_future) > 0:\n            loser_points_future = df_player[df_player[\"tourney_date\"]\\\n                                               == d][\"loser_rank_points\"]\n            if (loser_points_future.first_valid_index()):\n                break\n            \n    for d in df_dates_future_winner:\n        if len(df_dates_future_winner) > 0:\n            winner_points_future = df_player_winner[df_player_winner[\"tourney_date\"]\\\n                                               == d][\"winner_rank_points\"]\n            if (winner_points_future.first_valid_index()):\n                break\n    \n    print(\"******** points * *******\")      \n    print(loser_points_last)\n    print(winner_points_last)\n    print(loser_points_future)\n    print(winner_points_future)\n    \n    # handle the situation when the dataFrame is all NaN values          \n    if (type(loser_points_last) != int) \\\n        and not(loser_points_last.last_valid_index()):\n        loser_points_last = 0\n    if (type(winner_points_last) != int) \\\n        and not(winner_points_last.last_valid_index()):\n        winner_points_last = 0\n    if (type(loser_points_future) != int) \\\n        and not(loser_points_future.first_valid_index()):\n        loser_points_future = 0\n    if (type(winner_points_future) != int) \\\n        and not(winner_points_future.first_valid_index()):\n        winner_points_future = 0\n    \n    \n    # get the ids of the points\n    id_loser_last = 0\n    if type(loser_points_last) != int: \n        id_loser_last = loser_points_last.last_valid_index()\n    id_winner_last = 0\n    if type(winner_points_last) != int: \n        id_winner_last = winner_points_last.last_valid_index()\n    id_loser_future = 0\n    if type(loser_points_future) != int: \n        id_loser_future = loser_points_future.first_valid_index()\n    id_winner_future = 0\n    if type(winner_points_future) != int: \n        id_winner_future = winner_points_future.first_valid_index()\n    \n    print(\"******ids****\")\n    print(id_loser_last)\n    print(id_winner_last)\n    print(id_loser_future)\n    print(id_winner_future)\n    \n    # chose last\/future , loser\/winner points based on the id (undirectly to the date)\n    point_last = 0\n    if id_loser_last > 0 and id_winner_last > 0:\n        if id_loser_last < id_winner_last:\n            point_last = winner_points_last[id_winner_last]\n        else:\n            point_last = loser_points_last[id_loser_last]\n    elif id_loser_last == 0 and id_winner_last != 0:\n        point_last = winner_points_last[id_winner_last]\n    elif id_loser_last != 0 and id_winner_last == 0:\n            point_last = loser_points_last[id_loser_last]\n            \n    point_future = 0\n    if id_loser_future > 0 and id_winner_future > 0:\n        if id_loser_future < id_winner_future:\n            point_future = loser_points_future[id_loser_future]\n        else:\n            point_future = winner_points_future[id_winner_future]\n    elif id_loser_future == 0 and id_winner_future != 0:\n        point_future = winner_points_future[id_winner_future]\n    elif id_loser_future != 0 and id_winner_future == 0:\n            point_future = loser_points_future[id_loser_future]\n        \n    print(\"******point result*******\")\n    print(point_last)\n    print(point_future)\n    # if we have two values, we return the average, else we return the non zero value \n    # else return zero\n    if(point_last == 0):\n        points.append(point_future)\n    elif(point_future == 0):\n        points.append(point_last)\n    else:\n        points.append((point_last + point_future) \/ 2.0)\n    \n    index += 1\n#     break","22d6d2c4":"p = 0\nfor index in new_nan_rank_points_id.index:\n#     print(index)\n    data_drop_nanScore_cleaned.at[index, \"loser_rank_points\"] = points[p]\n    p += 1\nprint(data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_rank_points\"]\\\n                                           .isnull()][\"loser_id\"].shape)","b37cbe54":"plt.figure(figsize=(10,10))\nsns.distplot(data_drop_nanScore_cleaned[\"loser_rank_points\"])","b1980555":"print(data_drop_nanScore_cleaned[\"loser_seed\"].isnull().sum())\ndata_drop_nanScore_cleaned = data_drop_nanScore_cleaned.drop(labels=[\"loser_seed\"], axis=1)","899d4fee":"plt.figure(figsize=(10,10))\nsns.distplot(data_drop_nanScore_cleaned[\"match_num\"])","c85f83b3":"data_drop_nanScore_cleaned = data_drop_nanScore_cleaned.drop(labels=[\"match_num\"], axis=1)","6f9bac2a":"n_Nan_minutes = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"minutes\"])[\"minutes\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_minutes)\n\n# Fill Nan with the median\nmean_minutes = n_Nan_minutes.mean()\ndata_drop_nanScore_cleaned[\"minutes\"] = data_drop_nanScore_cleaned[\"minutes\"]\\\n                                          .fillna(mean_minutes)\n","333fab12":"data_drop_nanScore_cleaned.info()","dd704b09":"#winner_age: The best solutipon is to fill NaN values with the median.\n\nn_Nan_w_age = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"winner_age\"])[\"winner_age\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_w_age)\n\n# Fill Nan with the median\nmedian_winner_age = n_Nan_w_age.median()\ndata_drop_nanScore_cleaned[\"winner_age\"] = data_drop_nanScore_cleaned[\"winner_age\"]\\\n                                          .fillna(median_winner_age)\n\n# loser_age after modification (fillna)\n\nsns.distplot(data_drop_nanScore_cleaned[\"winner_age\"])\nplt.legend(labels=['Before fillna','after fillna'])\nplt.title(\"winner_age distribution\")","1314621e":"# We choose to drop loser_entry column (no clear method to fill nan values)\ndata_drop_nanScore_cleaned = data_drop_nanScore_cleaned.drop(labels=[\"winner_entry\"], axis=1)","fc5bfda8":"data_drop_nanScore_cleaned[\"winner_hand\"].value_counts()","4efe1c5e":"# Get the loser with nan loser_hand\nnan_hand_names = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_hand\"]\\\n                                           .isnull()][\"winner_name\"].unique()\nprint(nan_hand_names)\n\n# See if the winner_hand is defined for another game\n# when the player is a loser\nverify_name = []\nfor name in nan_hand_names:\n    hands = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_name\"] == name][\"loser_hand\"]\n    if hands.isnull().all() == False:\n        verify_name.append(name)\n        print(\"loser_hand founded for winner_name\" + name)\n# when the player is a winner\nfor name in nan_hand_names:\n    hands = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_name\"] == name][\"winner_hand\"]\n    if hands.isnull().all() == False:\n        verify_name.append(name)\n        print(\"loser_hand founded for winner_name\" + name)","7c35c3b9":"# affect to players in verify_name the mean_loser_ht\nfor name in verify_name:\n    for row_index in data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_name\"] == name].index:\n        data_drop_nanScore_cleaned.loc[row_index,'winner_hand'] = \"R\"","f816d3a3":"max_winner_hand = data_drop_nanScore_cleaned[\"winner_hand\"].value_counts().idxmax()\ndata_drop_nanScore_cleaned[\"winner_hand\"] = data_drop_nanScore_cleaned[\"winner_hand\"]\\\n                                          .fillna(max_winner_hand)","86c7f3e7":"data_drop_nanScore_cleaned[\"winner_hand\"].value_counts()","451c406f":"n_Nan_w_ht = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"winner_ht\"])[\"winner_ht\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_w_ht)","ffa4cf39":"data_drop_nanScore_cleaned.describe()[\"winner_ht\"]","ef543133":"# Get the loser with nan loser_ht\nnan_ht_names = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_ht\"]\\\n                                           .isnull()][\"winner_name\"].unique()\nprint(nan_ht_names)\n\n# See if the loser_ht is defined for another game\n# when the player is a loser\n# save in verify_name, the players that already have a ht\nverify_name = []\nfor name in nan_ht_names:\n    ht = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_name\"] == name][\"loser_ht\"]\n    if ht.isnull().all() == False:\n#         print(ht)\n        verify_name.append(name)\n        print(\"loser_ht founded for winner_name \" + name)\n# when the player is a winner\nfor name in nan_hand_names:\n    ht = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_name\"] == name][\"winner_ht\"]\n    if ht.isnull().all() == False:\n        verify_name.append(name)\n        print(\"winner_ht founded for winner_name \" + name)","4db12784":"# affect to players in verify_name the mean_loser_ht\nfor name in verify_name:\n    for row_index in data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_name\"] == name].index:\n        data_drop_nanScore_cleaned.loc[row_index,'winner_ht'] = mean_loser_ht","505c6255":"mean_winner_ht = data_drop_nanScore_cleaned[\"winner_ht\"].mean()\ndata_drop_nanScore_cleaned[\"winner_ht\"] = data_drop_nanScore_cleaned[\"winner_ht\"]\\\n                                          .fillna(mean_winner_ht)","eebdc3cc":"# Get the loser with nan loser_ht\nnan_rank_id = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank\"]\\\n                                           .isnull()][\"winner_id\"]\nnan_rank_dates = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank\"]\\\n                                           .isnull()][\"tourney_date\"]\n\n# print(nan_rank_id)\n# print(nan_rank_dates)\n\n\nranks = []\nsuffix = \"atp_rankings_\"\n\nindex = 0\nfor date in nan_rank_dates:\n    id_player = nan_rank_id.to_list()[index]\n    index = index + 1\n    if int(str(date)[:4][-2:]) == 19:\n        file_rank = path + suffix + \"current.csv\"\n        df_rank = pd.read_csv(file_rank)\n        df_rank = df_rank[df_rank[\"ranking_date\"] == date]\n        lst3 = [value for value in df_rank.player.to_list()]\n        if (id_player in lst3):\n            print(\"ok\")\n\n        \n#     elif (year >= 10 \n#         and year <=18):\n#         file_rank = path + suffix + \"10s.csv\"\n        \n#     elif (year >= 0\n#         and year <= 9):   \n#         file_rank = path + suffix + \"00s.csv\"\n\n#     elif (year >= 90\n#         and year <= 99):\n#         file_rank = path + suffix + \"90s.csv\"\n\n#     elif (year >= 80\n#           and year <= 89):\n#         file_rank = path + suffix + \"80s.csv\"\n\n#     elif (year >= 70\n#         and year <= 79):\n#         file_rank = path + suffix + \"70s.csv\"","4fda5796":"n_Nan_w_rank = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"winner_rank\"])[\"winner_rank\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_w_rank)","0141ec9d":"n_Nan_w_rank.describe()","532be474":"add = 0\nfor index in nan_rank_id.index:\n    data_drop_nanScore_cleaned.at[index, \"winner_rank\"] = n_Nan_w_rank.max() + add\n    add = add + 1 ","1f39b622":"plt.figure(figsize=(10,10))\nsns.distplot(data_drop_nanScore_cleaned[\"winner_rank\"])","4ee54839":"n_Nan_w_rank_points = data_drop_nanScore_cleaned.dropna(axis=0, subset=[\"winner_rank_points\"])[\"winner_rank_points\"]\nplt.figure(figsize=(10,10))\nsns.distplot(n_Nan_w_rank_points)","d72a4d1b":"n_Nan_w_rank_points.describe()","c4a1bdb7":"nan_rank_points_id = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"winner_id\"]","0df8c48d":"len(nan_rank_points_id)","fe0e5349":"len(nan_rank_id)","b5167466":"# let's see if the player is unranked, he have a nan rank points\ninter = nan_rank_id[nan_rank_id.isin(nan_rank_points_id)]\nprint((inter == nan_rank_id).sum())","f9e534e6":"nan_rank_points_id.shape","ef40abd3":"print(nan_rank_points_id.shape)\nfor index in nan_rank_id.index:\n    data_drop_nanScore_cleaned.at[index, \"winner_rank_points\"] = 0\nprint(data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"winner_id\"].shape)","3dbe55a6":"new_nan_rank_points_id = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"winner_id\"]\nnew_nan_rank_points_rank = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"winner_rank\"]\nnan_rank_points_dates = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"tourney_date\"]\nnan_rank_points_seeds = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"winner_seed\"]","ab127a54":"index = 0\npoints = []\nfor date in nan_rank_points_dates:\n#     date = 19910204\n    print(date)\n    id_player = new_nan_rank_points_id.to_list()[index]\n#     id_player = 101723\n    print(id_player)\n    # games and dates when the player lose and win\n    df_player = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"loser_id\"] == id_player]\n    df_player_winner = data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_id\"] == id_player]\n    print(df_player.shape)\n    df_dates = df_player[\"tourney_date\"].to_list()\n    df_dates_winner = df_player_winner[\"tourney_date\"].to_list()\n    # seperate the date in loser\/winner and last\/future\n    df_dates_last = [d for d in df_dates if d < date]\n    df_dates_last_winner = [d for d in df_dates_winner if d < date]\n    df_dates_future = [d for d in df_dates if d > date]\n    df_dates_future_winner = [d for d in df_dates_winner if d > date]\n    print(\"****dates*******\")\n#     print(df_dates)\n#     print(df_dates_last)\n#     print(df_dates_last_winner)\n#     print(df_dates_future)\n#     print(df_dates_future_winner)\n    \n    \n    loser_points_last = 0\n    winner_points_last = 0\n    loser_points_future = 0\n    winner_points_future = 0\n    # get the nearest points from the actual date \n    for d in df_dates_last[::-1]:\n        if len(df_dates_last) > 0:\n            loser_points_last = df_player[df_player[\"tourney_date\"]\\\n                                               == d][\"loser_rank_points\"]\n            if (loser_points_last.last_valid_index()):\n                break\n        \n    for d in df_dates_last_winner[::-1]:\n        if len(df_dates_last_winner) > 0:\n            winner_points_last = df_player_winner[df_player_winner[\"tourney_date\"]\\\n                                               == d][\"winner_rank_points\"]         \n            if  (winner_points_last.last_valid_index()):\n                break\n                \n    for d in df_dates_future:\n        if len(df_dates_future) > 0:\n            loser_points_future = df_player[df_player[\"tourney_date\"]\\\n                                               == d][\"loser_rank_points\"]\n            if (loser_points_future.first_valid_index()):\n                break\n            \n    for d in df_dates_future_winner:\n        if len(df_dates_future_winner) > 0:\n            winner_points_future = df_player_winner[df_player_winner[\"tourney_date\"]\\\n                                               == d][\"winner_rank_points\"]\n            if (winner_points_future.first_valid_index()):\n                break\n    \n    print(\"******** points * *******\")      \n    print(loser_points_last)\n    print(winner_points_last)\n    print(loser_points_future)\n    print(winner_points_future)\n    \n    # handle the situation when the dataFrame is all NaN values          \n    if (type(loser_points_last) != int) \\\n        and not(loser_points_last.last_valid_index()):\n        loser_points_last = 0\n    if (type(winner_points_last) != int) \\\n        and not(winner_points_last.last_valid_index()):\n        winner_points_last = 0\n    if (type(loser_points_future) != int) \\\n        and not(loser_points_future.first_valid_index()):\n        loser_points_future = 0\n    if (type(winner_points_future) != int) \\\n        and not(winner_points_future.first_valid_index()):\n        winner_points_future = 0\n    \n    \n    # get the ids of the points\n    id_loser_last = 0\n    if type(loser_points_last) != int: \n        id_loser_last = loser_points_last.last_valid_index()\n    id_winner_last = 0\n    if type(winner_points_last) != int: \n        id_winner_last = winner_points_last.last_valid_index()\n    id_loser_future = 0\n    if type(loser_points_future) != int: \n        id_loser_future = loser_points_future.first_valid_index()\n    id_winner_future = 0\n    if type(winner_points_future) != int: \n        id_winner_future = winner_points_future.first_valid_index()\n    \n    print(\"******ids****\")\n    print(id_loser_last)\n    print(id_winner_last)\n    print(id_loser_future)\n    print(id_winner_future)\n    \n    # chose last\/future , loser\/winner points based on the id (undirectly to the date)\n    point_last = 0\n    if id_loser_last > 0 and id_winner_last > 0:\n        if id_loser_last < id_winner_last:\n            point_last = winner_points_last[id_winner_last]\n        else:\n            point_last = loser_points_last[id_loser_last]\n    elif id_loser_last == 0 and id_winner_last != 0:\n        point_last = winner_points_last[id_winner_last]\n    elif id_loser_last != 0 and id_winner_last == 0:\n            point_last = loser_points_last[id_loser_last]\n            \n    point_future = 0\n    if id_loser_future > 0 and id_winner_future > 0:\n        if id_loser_future < id_winner_future:\n            point_future = loser_points_future[id_loser_future]\n        else:\n            point_future = winner_points_future[id_winner_future]\n    elif id_loser_future == 0 and id_winner_future != 0:\n        point_future = winner_points_future[id_winner_future]\n    elif id_loser_future != 0 and id_winner_future == 0:\n            point_future = loser_points_future[id_loser_future]\n        \n    print(\"******point result*******\")\n    print(point_last)\n    print(point_future)\n    # if we have two values, we return the average, else we return the non zero value \n    # else return zero\n    if(point_last == 0):\n        points.append(point_future)\n    elif(point_future == 0):\n        points.append(point_last)\n    else:\n        points.append((point_last + point_future) \/ 2.0)\n    \n    index += 1\n#     break","6bd735f7":"p = 0\nfor index in new_nan_rank_points_id.index:\n#     print(index)\n    data_drop_nanScore_cleaned.at[index, \"winner_rank_points\"] = points[p]\n    p += 1\nprint(data_drop_nanScore_cleaned[data_drop_nanScore_cleaned[\"winner_rank_points\"]\\\n                                           .isnull()][\"winner_id\"].shape)","b648f120":"print(data_drop_nanScore_cleaned[\"winner_seed\"].isnull().sum())\ndata_drop_nanScore_cleaned = data_drop_nanScore_cleaned.drop(labels=[\"winner_seed\"], axis=1)","bb9d776c":"data_drop_nanScore_cleaned.tail()","ba2dc428":"#dataframe winner\ncolumns_w = [\n    \"best_of\", \"w_1stIn\", \"w_1stWon\", \"w_2ndWon\", \"w_SvGms\", \"w_ace\", \"w_bpFaced\", \"w_bpSaved\",\n    \"w_df\", \"w_svpt\", \"winner_age\", \"winner_hand\", \"winner_ht\", \"winner_id\", \"winner_ioc\",\n    \"winner_name\", \"winner_rank\", \"winner_rank_points\", \"minutes\", \"round\", \"score\",\n    \"surface\", \"tourney_date\", \"tourney_id\", \"tourney_level\", \"tourney_name\", \"w_setW\"\n    ]\ndf_w = data_drop_nanScore_cleaned[columns_w]\ndf_w[\"label\"] = 1","3e92a988":"# dataframe loser\ndf_l = data_drop_nanScore_cleaned.copy()\ndf_l = df_l.iloc[:,:26]\ndf_l[\"w_setW\"] = data_drop_nanScore_cleaned[\"l_setW\"]\ndf_l.columns = columns_w\ndf_l[\"label\"] = 0","29d22c62":"# players datafame\nplayer_df = pd.concat([df_w, df_l], ignore_index=True)\nplayer_df.head()","090783ec":"player_df.dtypes","eac50da6":"player_df[\"round\"].value_counts()","14401dcf":"player_df = player_df[player_df[\"round\"] != 'RR']\nplayer_df = player_df[player_df[\"round\"] != 'BR']","02bd3513":"player_df[\"round\"].value_counts()","91967fb2":"round_num = {\n    'round': {\n        'R128': 0, 'R64': 1, 'R32': 2, 'R16': 3,\n        'QF': 4, 'SF': 5, 'F': 6\n        }\n    }","f0894cff":"player_df.replace(round_num, inplace=True)","0fe53239":"player_df[\"round\"].value_counts()","08da8faa":"player_df.drop([\"score\"], axis=1, inplace=True)","5722f089":"player_df[\"surface\"].value_counts()","94535b94":"from sklearn.preprocessing import LabelEncoder\nlb = LabelEncoder()\nplayer_df['surface'] = lb.fit_transform(player_df['surface'].astype(str))","c9bc5c70":"player_df[\"surface\"].value_counts()","f3d7ee3c":"player_df.drop([\"tourney_date\"], axis=1, inplace=True)\nplayer_df.drop([\"tourney_id\"], axis=1, inplace=True)\nplayer_df.drop([\"tourney_name\"], axis=1, inplace=True)","10f817f3":"player_df[\"tourney_level\"].value_counts()","5427d437":"level_num = {\n    'tourney_level': {\n        'A': 0, 'F': 1, 'M': 2, 'G': 3\n        }\n    }","e1c77d9d":"player_df.replace(level_num, inplace=True)","cd34929b":"player_df[\"tourney_level\"].value_counts()","373bf5d3":"player_df[\"winner_hand\"].value_counts()","c445c6a8":"lb_encoder = LabelEncoder()\nplayer_df['winner_hand'] = lb_encoder.fit_transform(player_df['winner_hand'].astype(str))","ec784aab":"player_df[\"winner_hand\"].value_counts()","d3669d50":"player_df.drop([\"winner_id\"], axis=1, inplace=True)\nplayer_df.drop([\"winner_name\"], axis=1, inplace=True)","80e0645a":"player_df[\"winner_ioc\"].value_counts()","40c844f4":"lb_encoder = LabelEncoder()\nplayer_df['winner_ioc'] = lb_encoder.fit_transform(player_df['winner_ioc'].astype(str))","cfa11feb":"player_df[\"winner_ioc\"].value_counts()","19e5ac77":"player_df.drop([\"w_setW\"], axis=1, inplace=True)","0da22dfe":"player_df.dtypes","5bc5a62c":"corr = player_df.corr()\nfig, ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(corr, annot= True, fmt='.2f', linewidths=0.5, ax=ax)","caf29e1b":"df = player_df[[\"winner_age\", \"tourney_level\", \"winner_rank\", \"label\"]]\ndf.columns = [\"age\", \"tourney_level\", \"rank\", \"label\"]\nsns.pairplot(df, hue = \"label\", size=3 )","d15a3f1e":"player_df.head()","fb2b762a":"X = player_df.drop(['label'],axis=1)\ny = player_df[\"label\"]\ndisplay(X.shape)\ndisplay(y.shape)","894bbe7f":"#Split train\/test 90%-10%\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, stratify = y) #10%\n#split raw data \ndisplay(X_train.shape)\ndisplay(y_train.shape)","9144c7e4":"pipeline = Pipeline([\n    ('scaler',MinMaxScaler()),\n    ('svm', svm.SVC())\n])\n\n\nparam_grid = {\n    'svm__kernel': ['linear','rbf'],\n    'svm__C':[1],\n    'svm__gamma':[0.001]\n}\n\ncv = 2\n\nsvm_grid = GridSearchCV(pipeline, param_grid = param_grid, cv = cv, verbose=1, n_jobs = -1,scoring='f1')\n\nsvm_grid.fit(X_train, y_train)","6834642b":"svm_grid.best_score_","b8cadae4":"y_pred = svm_grid.predict(X_test)","67721bae":"f1_score(y_test, y_pred)","e2c28186":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = [\"0\", \"1\"]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","5bc8049f":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(y_test, y_pred, classes=[\"class_names\"],\n                      title='Confusion matrix SVM')","01871396":"pipeline = Pipeline([\n    ('scaler',MinMaxScaler()),\n    ('xgb', XGBClassifier())\n])\n\n\nparam_grid = {\n    'xgb__max_depth': [4],\n    'xgb__min_child_weight':[0.01],\n    'xgb__colsample_bytree':[0.7],\n    'xgb__subsample':[0.6],\n    'xgb__learning_rate':[0.1]\n}\n\ncv = 2\n\nxgb_grid = GridSearchCV(pipeline, param_grid = param_grid, cv = cv, verbose=1, n_jobs = -1,scoring='f1')\n\nxgb_grid.fit(X_train, y_train)\n\n","a9b51f73":"xgb_grid.best_score_","097b321f":"y_pred = xgb_grid.predict(X_test)","9731065a":"f1_score(y_test, y_pred)","7a45b1fc":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(y_test, y_pred, classes=[\"class_names\"],\n                      title='Confusion matrix XGBoost')","40288065":"pipeline = Pipeline([\n    ('scaler',MinMaxScaler()),\n    ('lr', LogisticRegression())\n])\n\n\nparam_grid = {\n    'lr__penalty' : ['l1', 'l2'],\n    'lr__C' : [0.1]# np.logspace(-4, 4, 20)\n}\n\ncv = 2\n\nlr_grid = GridSearchCV(pipeline, param_grid = param_grid, cv = cv, verbose=1, n_jobs = -1,scoring='f1')\n\nlr_grid.fit(X_train, y_train)","5e7b0f66":"lr_grid.best_score_","5202267b":"y_pred = lr_grid.predict(X_test)","b083924d":"f1_score(y_test, y_pred)","5464a805":"# Plot non-normalized confusion matrix\nplot_confusion_matrix(y_test, y_pred, classes=[\"class_names\"],\n                      title='Confusion matrix Logistic Regression')","526be251":"### Winner player columns","fd2205c9":"We see clearly that all the unraked players haven't rank points. We propose to fill this nan points with zero.","a18707d9":"For loser_ht, we will proceed the same as loser_hand (try to find ht in another game)","df16fd03":"#### loser_hand","51a00930":"#### winner_ht","d16680bb":"To handle the missing values for the winner_player, we will exactly the same. It is better to have a clean code. In this work, we will do just a copy of the code above and do the modifications (loser -> winner)","b0d90821":"### V- Prediction Models","5f84ebe4":"#### Import data","48ff23d7":"#### w_setW","6a15aace":"### Loser player columns","d95564c7":"#### winner_rank_points","e9c9379f":"### II. Organize the data","d0bebfb6":"We will drop \"RR\" and \"BR\". We will get ordinal attributes","5c7bbdc3":"Now, we will reorganize our data in order to adapt to the problem. Our idea is to split the data in two loser_player and winner_player. We will give to the losers the target 0 and to the winners the taget 1. We will concatenate the two dataframes. It is about a classification problem in order to know on which player bet.","a48fe522":"### III. Handle with categorical features","ce7e3c45":"We have now 2 possibilities: \\\n1- Take all the rows and drop columns 1stIn, 1stWon, 2ndWon, SvGms, ace, bpFaced, bpSaved, df, svpt. \\\n2- Take ~50% of data rows (starting from ~1990) and keep all the columns. \\\n\nIn this work, we will follow the second possibility for two reasons. The first is to have more features on each player. The second, even with 50% of the data, we still have 80000 rows. It is largely enough to do ML. (We can also test the first possibility in future work).","583d67c9":"In the Loser part, we already affected height to some player. We have to ensure that they will have the height as a loser or a winner.","e55a3186":"#### loser_entry","09048063":"For the \"minutes\" column, we will fill it with the mean(). We can enhance the approximation by do a splitting based on number of set played. ","27bee21e":"#### loser_rank_points","d6a20f43":"### IV. Vizualisation","e02d17c8":"The correlation matrix shows some high correlated features especially for \"w_svpt\". It is correlated to \"w_1stIn\", \"w_1stWon\", \"w_2ndWon\" and \"w_SvGms\". In this work, we will not drop the correlated features but we think that it can be tested in further work","8d9be0c1":"We hope that our approach was clear. In this section, we will present other ideas that can be more adapted to bettings. \\\n1. Clean the code.\n2. Use sklearn imputers to handle the new (unseen) data.\n3. Analyse features correlation and features selection.\n4. Tune the models (modify the range of the parameters).\n5. Combine the models.\n6. Test a second approach based on Time Series Forecasting:\n    1. Build multiv-variate time series for each player.\n    2. Assign to each time-serie probability of winning a game or a set. We started this work by creating the feature \"w_SetW\".\n    3. For a new game, forecast\/predict the probabilities for both players.\n    4. Bet on the player with higher probability.","90974d2f":"If a player have a Nan ht in a game, he will have Nan ht in all the games.\\\nWe will fill the  Nan ht with the mean.","8ed8b01d":"We will drop this columns.","2f4b03bc":"#### b- Age, ioc plot","1b58e7b7":"#### winner_age","7094cc50":"#### winner_rank","53230723":"We will delete also our created feature \"w_setW\". We will explain this in the Further work section.","87b5e089":"#### d- Model3: Logistic Regression","e595f967":"The code below is to see if we can get the ranking from the given files. \\\nWe commented all the code except for one condition.\\\nAter running the code, we confirme that we can not fill the nan ranking using this method.","b9e83522":"### a- Split Data ","ce84d415":"#### minutes","c3ae26d3":"#### b- Model1 : SVM","d2bfc63f":"#### loser_ht","8a03dc28":"#### Winner_hand, winner_id, winner_name and winner_ioc","2e585c81":"We didn't succed to fill the NaN ranks using the methd above.\\\nAs the Nan ranks are for unranked players, We propose to affect  \"max(l_rank) + 1\" to the first nan rank, \"max(l_rank) + 2\" to the second nan rank , and so on.","95609627":"#### winner_seed","6f33160f":"#### winner_entry","32e7c35b":"### Clean \"Score\" column","e93247ac":"We move now to the column \"loser_seed\". Despite her big imporatnce for betting, we fill ourself forced to drop this column.","0e5337fe":"#### loser_age","ca938567":"The code above show 0 result. We propose to fill the NaN with R (Right handed is most frequent).\nThis link as reference https:\/\/summerofjeff.wordpress.com\/2011\/02\/12\/the-prevalence-of-lefties-in-mens-tennis\/ .\nWe choose also to keep U value. We estimate that a player with U (N\/A hand) is \"unknown\". The probability that he lose, is higher. This can help the predictive model to decide the winning player.","9d700730":"In this part, we will work in the categorical features in order to transform them to numerical. We will do the necessary encodings. We will also drop some columns (unrelevant from our point of view).","78d5a7bd":"#### match_num","8c2b6b68":"For the rest of nan rank points, we propose to fill them with the average of \"last_rank_points\" and \"future_rank_points\" for a given player (the date is t). \\\n> last_rank_points : the first valid rank points on t-i (i > 0).\\\n> future_rank_points : the first valid rank points on t+i (i > 0","f3cb5f24":"#### tourney_level","647e5be6":"#### surface","6b2eb117":"#### a- Correlation heatMap","f49dbaba":"#### winner_hand","081dbb1a":"### I- Handling with missing Data","a2c9454f":"The match_num column showed some biased values. It is due to the approch taken to identify a match in a tourney. It is possible to unbias this column. Due to lack of time, we will simply drop this column. ","637f0f04":"#### loser_seed","0b8be47a":"We will drop column score (we undirectly have it in the label).","66145a03":"#### loser_rank","d78898ca":"To fill loser_hand, we propose to see if we can find the hand, for the given player, in another game.","c64bf5f5":"#### tourney_date, tourney_id and tounrney_name","ace8ca3a":"### VI- Further Work","7c21afcc":"#### c- Model2: XGBoost","9f0433de":"<bold><u>__tourney_level x winner_age__<\/u><\/bold>: For level G (grand Shlam), the max is 40 but for level A it is 48. This can be explained by the facct that the oldest player join A level competition in the end of their professional career. \\\n<bold><u>__tourney_level x winner_rank__<\/u><\/bold>: The first ranked players win the hardest tourney (G and M).\\\n<bold><u>__winner_rank x winner_age__<\/u><\/bold>: We can seperate the plot in two parts, from  rank 0 to 1500 and from 1500 to 2500.\nFor the first part, we have the shape of triangle => by the time (the age), the player win points and go higher in the rank. The second part can be explained by the entrance of new player in the ranking or by the end_career players."}}