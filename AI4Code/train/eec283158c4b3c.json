{"cell_type":{"20753c5e":"code","e880f094":"code","d1c57015":"code","434b616c":"code","db793f26":"code","08ffa015":"code","0d9baf82":"code","0c2671d1":"code","25ecc758":"code","83b984b7":"code","f2373317":"code","07c960fb":"code","9e5ee6a1":"code","894d049a":"code","ac5f40dd":"code","2ec796f2":"code","86face19":"code","7b83d3c1":"code","74f9a0dd":"code","342d6eaf":"code","3f434489":"code","6c561933":"code","10be86e2":"code","bbba6b7a":"code","0d701a1c":"code","474a6d85":"code","6987baf4":"code","a1f6c7e5":"code","0df7e68c":"code","dcfe3b77":"code","dfff7a3f":"code","c225d568":"code","141916ea":"code","fab4e6c5":"code","f4fb8403":"code","9e4470a1":"code","51a0afa4":"code","0a307ae1":"code","8fef8b8a":"code","8804b55d":"code","bd18726f":"code","483d5d0e":"markdown","908e15a3":"markdown","aa699f4b":"markdown","0b1c5974":"markdown","4312e271":"markdown","0449389d":"markdown","c7e1b7a7":"markdown","679d0dc9":"markdown"},"source":{"20753c5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e880f094":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder","d1c57015":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv') \ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv') ","434b616c":"train_data.head() \n","db793f26":"test_data.head() \n","08ffa015":"Id = test_data.PassengerId\n\nId","0d9baf82":"test_data.shape\n","0c2671d1":"u_columns = ['PassengerId', 'Name', 'Ticket','Cabin']\n\n#for train data\ntrain_data = train_data.drop(u_columns,axis=1)\n\n","25ecc758":"#for test data\ntest_data = test_data.drop(u_columns, axis=1) ","83b984b7":"train_data.head() ","f2373317":"test_data.head()","07c960fb":"print('For test data', test_data.isnull().sum()) \nprint('\\n')\nprint('for train data', train_data.isnull().sum())","9e5ee6a1":"train_data1 = train_data.fillna(method='ffill')\n","894d049a":"train_data1.head()","ac5f40dd":"train_data1.isnull().sum()\n","2ec796f2":"test_data1 = test_data.fillna(method='ffill') \n","86face19":"print(train_data1.isnull().sum())\nprint('\\n')\nprint(test_data1.isnull().sum()) \n\n","7b83d3c1":"train_data1.Embarked.value_counts() \n","74f9a0dd":"Sex = pd.get_dummies(train_data1.Sex)\n\n#for Embarked,we will use Label Encoder\nle = LabelEncoder() \n\ntrain_data1[\"Embarked\"] = le.fit_transform(train_data1[\"Embarked\"]) \n\ntest_data1[\"Embarked\"] = le.fit_transform(test_data1[\"Embarked\"]) \n\n\n\n","342d6eaf":"test_data1.head()","3f434489":"train_data_1 = pd.concat([train_data1, Sex], axis=1) ","6c561933":"train_data_1.drop('male', axis=1, inplace=True) ","10be86e2":"train_data_1.drop('Sex', axis=1,inplace=True) ","bbba6b7a":"train_data_1.head()","0d701a1c":"Sex1 = pd.get_dummies(test_data1['Sex']) \ntest_data_1 = pd.concat([test_data1, Sex1], axis=1) \ntest_data_1.head() \n","474a6d85":"test_data_1.drop(['Sex', 'male'],axis=1,inplace=True) \n","6987baf4":"test_data_1.head()","a1f6c7e5":"plt.scatter(train_data_1.Fare, train_data_1.Survived) \n","0df7e68c":"train_data_1.drop('Fare', axis=1,inplace=True) ","dcfe3b77":"test_data_1.drop('Fare', axis=1,inplace=True) \n","dfff7a3f":"X = train_data_1.drop('Survived', axis=1) \ny = train_data_1.Survived","c225d568":"#Importing required library for machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nlg = LogisticRegression()\n","141916ea":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1) ","fab4e6c5":"print(X_train.shape) \nprint(X_test.shape) \nprint(y_train.shape)\nprint(y_test.shape)\n","f4fb8403":"lg.fit(X_train, y_train) \n","9e4470a1":"lg.score(X_test, y_test) ","51a0afa4":"prediction = lg.predict(test_data_1) ","0a307ae1":"df = {\n    \n    \"PassengerId\" : Id, \n    \"Survived\" : prediction\n}\n","8fef8b8a":" df1 = pd.DataFrame(df) ","8804b55d":"df1.head() ","bd18726f":"df1.to_csv(\"My_submission \",index=False) ","483d5d0e":"## Now, we can prepare our final model for prdiction","908e15a3":"## Now, we can build a model to predict the data. ","aa699f4b":"## Data after removing unnecessary columns for analysis","0b1c5974":"***Now finally, we can create CSV file to submit predicted data***","4312e271":"**Since, the the feature fare is already covered Pclass(Passenger class),and also it doesn't help us to predict survival rate. we can drop this column.**","0449389d":"****In this dataset, there are two categorical data are available. So before preparing model we need to transform them into numerical form ****","c7e1b7a7":"## Let's remove unnecessary columns for data analysis","679d0dc9":"### let's Handle missing values"}}