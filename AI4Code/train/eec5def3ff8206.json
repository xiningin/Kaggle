{"cell_type":{"78c9d2a6":"code","b1cb0f37":"code","6f996ef0":"code","1aca1933":"code","1a9ebbd4":"code","3dcf2892":"code","766fd2ec":"code","2fddb6e7":"code","5c7e187f":"code","5698a03b":"code","f4e51ce9":"code","274e2c3c":"code","b968ef48":"code","dcf74f32":"code","0e54453e":"code","7f453da3":"code","42d0ecf0":"code","61e69ef4":"code","a3277765":"code","ddb8a75c":"code","f049c6d3":"markdown","981ba35a":"markdown","35fddb12":"markdown","61857552":"markdown","e0552cee":"markdown"},"source":{"78c9d2a6":"import numpy as np\nimport os\nfrom PIL import Image\n\n#Visualization and evaluation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.math import confusion_matrix\n\n# Net libraries\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img ,img_to_array\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import  Flatten, Dense, Dropout\nfrom tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n","b1cb0f37":"path = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/'\nexample_with_mask = path + '\/Train\/WithMask\/1035.png'\nexample_without_mask = path + '\/Train\/WithoutMask\/10.png'\n\n# Global Variables\nBATCH_SIZE = 64\nEPOCHS = 8\nTARGET_SIZE = (128,128)\nCLASSES = ['Without Mask ','With Mask']","6f996ef0":"plt.imshow(load_img(example_with_mask))\n","1aca1933":"plt.imshow(load_img(example_without_mask))\n","1a9ebbd4":"fig, axes = plt.subplots(1, 3, figsize=(20, 12))\n\nfor set_ in os.listdir(path):\n    total = []\n    ax = axes[os.listdir(path).index(set_)]\n    for class_ in os.listdir(path+'\/'+set_):\n        count=len(os.listdir(path+'\/'+set_+'\/'+class_))\n        total.append(count)\n    ax.bar(CLASSES, total, color=['#a8e37e','#fa8072'])\n    ax.set_title(set_)\nplt.suptitle('Image distribution', size=33)\nplt.show()","3dcf2892":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=10,\n                                   width_shift_range=0.2, \n                                   height_shift_range=0.2,\n                                   zoom_range=0.25, \n                                   horizontal_flip=True, \n                                   samplewise_center=True, \n                                   samplewise_std_normalization=True,\n                                   fill_mode='nearest')\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\nimg = load_img(example_with_mask)\nexample_aug = img_to_array(img)\/255.\n#input have 4 axis - need to add extra empty axis for batch\nexample_aug = example_aug[np.newaxis]\nplt.figure(figsize=(20,10))\n\nfor i,img in enumerate(train_datagen.flow(example_aug, batch_size=1)):\n    plt.subplot(4, 6, i+1)\n    #remove empty axis \n    plt.imshow(np.squeeze(img))\n    \n    if i == 23:\n        break\n    \nplt.show()","766fd2ec":"train_set = train_datagen.flow_from_directory(directory= path+'Train', batch_size=BATCH_SIZE, class_mode='categorical', target_size=TARGET_SIZE)\nvalidation_set = test_datagen.flow_from_directory(path + 'Validation',target_size=TARGET_SIZE)\n","2fddb6e7":"def craete_model():\n    \n    denseNet_model = DenseNet201(input_shape=TARGET_SIZE + (3,), weights='imagenet', include_top=False)\n    denseNet_model.trainable = False\n    \n    flatten = Flatten()(denseNet_model.layers[-1].output)\n    fc = Dense(units=512, activation='relu')(flatten)\n    dropout = Dropout(0.35)(fc)\n    output = Dense(2, activation='softmax')(dropout)\n   \n    model = Model(inputs=denseNet_model.input, outputs=output)\n    \n    model.summary()\n    \n    return model\n\n\nmodel = craete_model()","5c7e187f":"starter_learning_rate = 1e-2\nend_learning_rate = 1e-6\ndecay_steps = 10000\nlearning_rate = optimizers.schedules.PolynomialDecay(starter_learning_rate,decay_steps,end_learning_rate,power=0.4)","5698a03b":"# Define Optimizer, Loss & Metrics\n\n\nopt = optimizers.Adam(learning_rate=learning_rate)\nloss = CategoricalCrossentropy()\nmet = 'accuracy'\n\n# Compile the Model\nmodel.compile(optimizer=opt, loss=loss, metrics=[met])","f4e51ce9":"\nmy_callbacks = [\n                EarlyStopping(monitor='val_accuracy', min_delta=1e-5, patience=5, mode='auto',restore_best_weights=False, verbose=1),\n                ModelCheckpoint(filepath='my_model.h5', monitor='accuracy', save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch', verbose=1)\n]\n","274e2c3c":"history = model.fit(train_set,\n                    epochs=EPOCHS, steps_per_epoch=len(train_set), # How many mini_batchs we have inside each epoch.\n                    validation_data=validation_set,\n                    callbacks=[my_callbacks],\n                    verbose=1)\n\nprint('\\n*** Fit is over ***')\nmodel.save('my_model.h5')\n#model.save_weights(\"my_model.h5\")","b968ef48":"train_loss = np.array(history.history['loss'])\nval_loss = np.array(history.history['val_loss'])\nplt.semilogy(train_loss, label='Train Loss')\nplt.semilogy(val_loss, label='Validation Loss')\n\n\nplt.legend(loc='upper right')\nplt.xlabel('Epoch')\nplt.ylabel('Loss - Cross Entropy')\nplt.title('Train and Validation Loss')\n\n\nplt.show()\n    \n\n","dcf74f32":"    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.xlabel('Epoch'),\n    plt.ylabel('Accuracy')\n    plt.title('Train and Validation Accuracy')\n    plt.show()\n","0e54453e":"test_set = test_datagen.flow_from_directory(path + 'Test',target_size=TARGET_SIZE,shuffle=False)","7f453da3":"# Model Evaluate \nloss, accuracy = model.evaluate(test_set)\nprint('Test Accuracy: ', '\\033[1m',round(accuracy*100, 2),'%\\033[0m')","42d0ecf0":"# True Label & Predict of a particular Batch\nimage, label = test_set.next()\nnum_imgs = 20\nlab_names = ['With Mask','Without Mask ']\nimages = image[0:num_imgs,:,:,:]\nlabels = label[0:num_imgs,:]\npredict = np.round(model.predict(images))\n\nimage_rows = 4\nimage_col = int(num_imgs\/image_rows)\n\n_, axs = plt.subplots(image_rows, image_col, figsize=(32,8))\naxs = axs.flatten()\n\nfor i in range(num_imgs):\n    img = images[i,:,:,:]\n    lab = labels[i,:]\n    axs[i].imshow(img)\n    pred = predict[i]\n    axs[i].axis('off')\n    lab, pred = np.argmax(lab), np.argmax(pred)\n    axs[i].set_title(label = f'y: {lab_names[lab]}  |  y_pred: {lab_names[pred]}', fontsize=14)\n\nplt.show()","61e69ef4":"y_pred = model.predict(test_set).argmax(axis=-1)\ny_test = test_set.classes\n\nConfusion_Matrix = confusion_matrix(y_test,y_pred)\n","a3277765":"fig, ax = plt.subplots(figsize=(25,10))\nsns.heatmap(Confusion_Matrix,xticklabels=CLASSES,yticklabels=CLASSES, ax=ax, annot=True,fmt=\"1.0f\",cbar=False,annot_kws={\"size\": 40})\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nplt.title(\"Confusion matrix\",fontsize=30)","ddb8a75c":"model.save('my_model.h5')\n","f049c6d3":"#  Get started\nOur data is divided into 2 categories:  people who wear a mask and people who do not wear a mask.\nFirst lets see an example for each of the categories , then we will define our global variables","981ba35a":"# Finish","35fddb12":"# Learning rate\nDefining a learning rate that decay with the help of a polynomial function of a root (power of 0.4) The learning rate range will be between 0.01 and 0.00001)","61857552":"We want to ensure that our data is balanced so we will count the amount of images belonging to each label","e0552cee":"# Data Augmentation\nwe want to do some data augmentation to get better result , some of the parameters were chosen as a result of an existing standard and some were chosen with the help of trial and error and an effect on the percentage of accuracy."}}