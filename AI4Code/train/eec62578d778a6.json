{"cell_type":{"1615f42b":"code","73923d30":"code","840ce5f6":"code","b766c20f":"code","504fb9c4":"code","76548da8":"code","27d5acb5":"code","2029a6fe":"code","8fee71a6":"code","7b66cab4":"code","dc0b9690":"code","635e1509":"code","1af64832":"code","3ea901ed":"code","b6ea5ece":"code","d8e2c33f":"code","07e2d8a6":"code","369e39bc":"code","c4b73b7f":"code","bcd8348f":"code","e7a68846":"code","b1ae377a":"code","231e60e3":"code","94deb237":"code","8121e502":"code","6e037093":"code","a22d0c9f":"code","1372aa00":"code","a3853afd":"code","33d460c9":"code","3928cbea":"code","04473394":"code","ce92b099":"code","8cb009c3":"code","3ba21e49":"code","962ed12e":"code","14597c4b":"code","b46eed61":"code","12483f24":"code","0d34c823":"code","0e33a3db":"code","e6be9975":"code","38f888f8":"code","90243734":"code","3b85c027":"code","ae5d9d85":"code","cbce42f3":"code","457421dd":"code","9c62fc87":"code","c74f38c5":"code","7c1b3d00":"code","7043c60e":"code","46f659da":"code","70241425":"code","a49735d7":"code","3b4109f8":"code","50077791":"code","001db745":"code","4e9226e5":"code","d6135ee3":"code","0d8b4a4a":"code","0edaffa7":"code","d47258ca":"code","af7facfc":"markdown","dabe9b2f":"markdown","2631ef00":"markdown","17b3f9c9":"markdown","ae2af381":"markdown","aee10292":"markdown","63c31c50":"markdown","1e643f47":"markdown","0f1ec01d":"markdown","dea6b4e8":"markdown","8172e3a1":"markdown","b80dcdb4":"markdown","af872905":"markdown","4a912456":"markdown","9dde78dc":"markdown","9aa10e4a":"markdown","cd00f0d8":"markdown","ccebf17f":"markdown","7974d76e":"markdown","9f7131d9":"markdown","a03a5010":"markdown","7f453e5a":"markdown","b438edc1":"markdown","de8b3d79":"markdown","d8dece0c":"markdown","05f0cb1e":"markdown","19354f53":"markdown","9f922c46":"markdown","8f1fe041":"markdown"},"source":{"1615f42b":"print(\"hello wooorldddddd\")","73923d30":"from numpy.random import rand # function straight from submodule\nrand(5) # five random numbers between 0 and 1","840ce5f6":"import numpy.random as npr # load submodule\nnpr.rand(5)","b766c20f":"import numpy as np # load main NumPy module\nnp.random.rand(5)","504fb9c4":"session = 2\ntype(session)","76548da8":"session += 1\nprint(session)","27d5acb5":"list_of_strategies = [\"up-sell\", \"cross-sell\", \"down-sell\"]","2029a6fe":"len(list_of_strategies)","8fee71a6":"list_of_strategies[0] # access through indexing (first element is at index 0)","7b66cab4":"list_of_strategies.append(\"stay put\")","dc0b9690":"list_of_strategies","635e1509":"dict_of_participants = { # collection of key-value pairs\n    \"Jan\": (\"XYZ\", 42),\n    \"Sam\": (\"ABC\", 28),\n    \"Daphne\": (\"MNO\", 35)\n}","1af64832":"dict_of_participants[\"Sam\"] # you can only access the data via a key","3ea901ed":"for strategy in list_of_strategies:\n    print(\"Possible strategy:\", strategy)","b6ea5ece":"for participant in dict_of_participants:\n    print(\"name:\", participant)\n    if participant == \"Daphne\":\n        value = dict_of_participants[participant]\n        age = value[1]\n        print(\"   Age:\", age)\n    elif participant == \"Jan\":\n        value = dict_of_participants[participant]\n        company = value[0]\n        print(\"   Company:\", company)\n    else:\n        print(\"   We do not want to know your info.\")","d8e2c33f":"def get_age(participants, who):\n    \"\"\"\n    Parameters\n    ------------\n    - participants : dict\n        Dictionary of participants\n        \n    - who : str\n        Name of participant to get age from, as a string\n        Must be a valid key of 'participants' argument\n    \n    Returns\n    ------------\n    Age of selected participant\n    \"\"\"\n    value = participants[who]\n    age = value[1]\n    \n    if age < 20:\n        print(\"you are young\")\n    else:\n        print(\"you are old\")\n    \n    return age","07e2d8a6":"get_age(dict_of_participants, \"Sam\")","369e39bc":"import pandas as pd","c4b73b7f":"data = {\n    \"Artist\": [\"Billy Holiday\", \"Jimi Hendrix\", \"Miles Davis\", \"SIA\"],\n    \"Genre\": [\"Jazz\", \"Rock\", \"Jazz\", \"Pop\"],\n    \"Listeners\": [1300000, 2700000, 1500000, 2000000],\n    \"Plays\": [27000000, 70000000, 48000000, 74000000]\n}\n\ndf = pd.DataFrame(data)\n\ndf","bcd8348f":"df.mean() # other available functions: https:\/\/pandas.pydata.org\/docs\/reference\/frame.html","e7a68846":"df.max()","b1ae377a":"df[\"avg_plays\"] = df.Plays\/df.Listeners","231e60e3":"df","94deb237":"df[\"avg_plays\"].plot()","8121e502":"df.set_index(\"Artist\")[\"Plays\"].plot(ylabel=\"Total plays\")","6e037093":"# alternative way to create your df\ndata2 = [[\"Billy Holiday\", \"Jazz\", 1300000, 27000000],\n         [\"Jimi Hendrix\", \"Rock\", 2700000, 70000000],\n         [\"Miles Davis\", \"Jazz\", 1500000, 48000000],\n         [\"SIA\", \"Pop\", 2000000, 74000000]]\n\ndf2 = pd.DataFrame(data2, columns = [\"Artist\", \"Genre\", \"Listeners\", \"Plays\"])\n\ndf2","a22d0c9f":"df_jazz = df[df[\"Genre\"] == \"Jazz\"]\n\ndf_jazz","1372aa00":"df_popular = df[df[\"Listeners\"] >= 2000000]\n\ndf_popular","a3853afd":"class Rectangle:\n    def __init__(self, length, breadth, unit_cost=0):\n        self.length = length\n        self.breadth = breadth\n        self.unit_cost = unit_cost\n    def get_perimeter(self):\n        return 2 * (self.length + self.breadth)\n    def get_area(self):\n        return self.length * self.breadth\n    def calculate_cost(self):\n        area = self.get_area()\n        return area * self.unit_cost","33d460c9":"r = Rectangle(160, 120, unit_cost=2000)\n\nprint(\"Area of rectangle: %s cm^2\" % (r.get_area()))\nprint(\"Cost of rectangular field: EUR%s \" %(r.calculate_cost()))","3928cbea":"# settings --> switch internet option on (requires SMS verification)\n!pip install -U pythonpredictions-cobra","04473394":"import pandas as pd\nimport json\nimport warnings\nfrom pathlib import Path\n\n# preprocessing\nfrom cobra.preprocessing import PreProcessor\n\n# feature preselection\nfrom cobra.model_building import univariate_selection\nfrom cobra.evaluation import plot_univariate_predictor_quality\nfrom cobra.evaluation import plot_correlation_matrix\n\n# modelling\nfrom cobra.model_building import ForwardFeatureSelection\nfrom cobra.evaluation import plot_performance_curves\nfrom cobra.evaluation import plot_variable_importance\n\n# evaluation & PIGs\nfrom cobra.evaluation import Evaluator\nfrom cobra.evaluation import generate_pig_tables\nfrom cobra.evaluation import plot_incidence\n\n# Pandas settings\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n# suppress warnings\nwarnings.filterwarnings('ignore')","ce92b099":"ROOT = Path.cwd()\nROOT","8cb009c3":"pth_to_data = '..\/input\/earnings-dataset\/earnings_dataset.csv'\ndf = pd.read_csv(pth_to_data, sep=';')\n\ndf.head(n=5)","3ba21e49":"len(df) # number of rows (= observations)","962ed12e":"# create instance of PreProcessor object from parameters\npreprocessor = PreProcessor.from_params(\n        n_bins=10,\n        strategy='quantile',\n        serialization_path=ROOT\/'pipeline.json')","14597c4b":"# split data into train-selection-validation sets\nbasetable = preprocessor.train_selection_validation_split(\n                data=df,\n                target_column_name='TARGET',\n                train_prop=0.8,\n                selection_prop=0.1,\n                validation_prop=0.1)\n\nbasetable.head(n=5)","b46eed61":"# we need to create a list of variables by their datatype\ncontinuous_vars = ['age', 'education-num', 'capital-gain',\n                   'capital-loss', 'hours-per-week']\n\ndiscrete_vars = ['workclass', 'fnlwgt', 'education',\n                 'marital-status', 'occupation',\n                 'relationship', 'race', 'sex',\n                 'native-country']\n\ntarget_column_name = 'TARGET'","12483f24":"# fit the pipeline\npreprocessor.fit(basetable[basetable['split']=='train'],\n                 continuous_vars=continuous_vars,\n                 discrete_vars=discrete_vars,\n                 target_column_name=target_column_name)\n\n# transform the data (e.g. perform discretisation, incidence replacement, ...)\nbasetable = preprocessor.transform(basetable,\n                                   continuous_vars=continuous_vars,\n                                   discrete_vars=discrete_vars)                        ","0d34c823":"basetable.head(n=5)","0e33a3db":"preprocessed_predictors = [col for col in basetable.columns.tolist() if '_enc' in col]\n\ndf_auc = univariate_selection.compute_univariate_preselection(\n    target_enc_train_data=basetable[basetable['split']=='train'],\n    target_enc_selection_data=basetable[basetable['split']=='selection'],\n    predictors=preprocessed_predictors,\n    target_column=target_column_name,\n    preselect_auc_threshold=0.55,     \n    preselect_overtrain_threshold=0.05)\n\n# get a list of predictors selected by the univariate selection\npreselected_predictors = univariate_selection.get_preselected_predictors(df_auc)   ","e6be9975":"# univariate feature importance\nplot_univariate_predictor_quality(df_auc)","38f888f8":"# compute correlations between preprocessed predictors\ndf_corr = (univariate_selection\n           .compute_correlations(basetable[basetable['split']=='train'],\n                                 preprocessed_predictors))\n\nplot_correlation_matrix(df_corr)","90243734":"forward_selection = ForwardFeatureSelection(max_predictors=30, pos_only=True)\n\nforward_selection.fit(basetable[basetable['split']=='train'],\n                      target_column_name,\n                      preselected_predictors)\n\nperformances = forward_selection.compute_model_performances(basetable, target_column_name)","3b85c027":"# plot performance curves\nplot_performance_curves(performances)","ae5d9d85":"# after plotting the performances we select our model of choice (watch out: 0-based indexing)\nmodel = forward_selection.get_model_from_step(4)\n\n# we have chosen model with 5 variables, which we extract as follows\nfinal_predictors = model.predictors","cbce42f3":"# we can also compute and plot the importance of each predictor in the model\nvariable_importance = model.compute_variable_importance(basetable[basetable['split']=='selection'])\n\n# this is the correlation of the model score and each predictor    \nplot_variable_importance(variable_importance)","457421dd":"# get numpy array of True target labels and predicted scores\ny_true = basetable[basetable['split']=='validation'][target_column_name].values\ny_pred = model.score_model(basetable[basetable['split']=='validation'])\n\nevaluator = Evaluator()\n\n# automatically find the best cut-off probability\nevaluator.fit(y_true, y_pred)","9c62fc87":"# get various scalar metrics such as accuracy, AUC, precision, recall, ...\nevaluator.scalar_metrics","c74f38c5":"evaluator.plot_confusion_matrix()","7c1b3d00":"evaluator.plot_roc_curve()","7043c60e":"evaluator.plot_cumulative_gains()","46f659da":"evaluator.plot_lift_curve()","70241425":"# evaluator.plot_cumulative_response_curve()","a49735d7":"predictor_list = [col for col in basetable.columns if col.endswith('_bin') or col.endswith('_processed')]\n\npig_tables = generate_pig_tables(\n    basetable[basetable['split']=='selection'],\n    id_column_name='ID',\n    target_column_name=target_column_name,\n    preprocessed_predictors=predictor_list)","3b4109f8":"column_age_order = ['17.0 - 22.0', '22.0 - 26.0', '26.0 - 30.0', '30.0 - 33.0',\n                    '33.0 - 37.0', '37.0 - 41.0', '41.0 - 45.0', '45.0 - 50.0',\n                    '50.0 - 58.0', '58.0 - 90.0']              \n\nplot_incidence(pig_tables, 'age', column_age_order)","50077791":"pig_tables[\"variable\"].unique()","001db745":"column_hpw_order = ['1.0 - 24.0', '24.0 - 35.0', '35.0 - 40.0', \n                    '40.0 - 49.0', '49.0 - 55.0', '55.0 - 99.0']  \n\nplot_incidence(pig_tables, 'hours-per-week', column_hpw_order)","4e9226e5":"plot_incidence(pig_tables, 'education')","d6135ee3":"plot_incidence(pig_tables, 'relationship')","0d8b4a4a":"pig_tables.head(n=10)","0edaffa7":"with open(ROOT\/'pipeline.json', \"r\") as read_file:\n    pipeline = json.load(read_file)\n\nprint(pipeline.keys())","d47258ca":"pipeline['target_encoder']['_mapping']['age_bin']","af7facfc":"# MODEL VALIDATION","dabe9b2f":"## Feature preselection\nOnce we have the data prepared, we need to select the right variables. Thus, we perform a univariate preselection to rule out any predictor with little to no predictive power.\n\nThis preselection is based on an AUC threshold of a univariate model on the train and selection datasets.\n\nWe select all variables with `preselect_auc_threshold` > 0.55 and to avoid overfitting, we drop all variables where _(auc_train - auc_selection) >= 0.05_.\n\n","2631ef00":"### General structure\n  \n##### Run univariate preselection procedure and plot output\n`df_auc = univariate_selection.compute_univariate_preselection(basetable, thresholds)`\n\n`plot_univariate_predictor_quality(df_auc)`\n\n##### Get a list of predictors selected by the univariate selection\n`preselected_predictors = univariate_selection.get_preselected_predictors(df_auc)`   \n\n##### Compute and plot correlations between preprocessed predictors\n`df_corr = univariate_selection.compute_correlations(basetable)`\n\n`plot_correlation_matrix(df_corr)`","17b3f9c9":"## Object-oriented programming (OOP)","ae2af381":"# MODEL USAGE","aee10292":"## Evaluation\n\nThe next step after modelling is evaluating how well our model is performing.","63c31c50":"## For loops & conditional statements","1e643f47":"# A. Programming with Python\nSome examples to get you started with programming concepts and Python in particular.","0f1ec01d":"## Industrialization\nOnce we are happy with our model, we can industrialize it. All the preprocessing is in the output pipeline in a JSON format. The model comes from scikit-learn, which can be easily serialized (= saved) and exported.","dea6b4e8":"# DATA PREPARATION","8172e3a1":"### General structure\n  \n##### Initialize forward feature selection procedure\n`forward_selection = ForwardFeatureSelection(parameters)`\n\n`forward_selection.fit(basetable)`\n\n##### Run forward feature selection and plot performance curves\n`performances = forward_selection.compute_model_performances(basetable, target_column_name)`\n\n`plot_performance_curves(performances)`\n\n##### Select and extract model of choice\n`model = forward_selection.get_model_from_step()`\n\n`final_predictors = model.predictors`\n\n##### Compute and plot the importance of each predictor in the model\n`variable_importance = model.compute_variable_importance(basetable)`\n  \n`plot_variable_importance(variable_importance)`","b80dcdb4":"## Functions & parameters","af872905":"### Dictionaries","4a912456":"## PIG tables\nPredictor Insight Graphs, or PIGs, are plots which help us profile how each variable behaves in the model.","9dde78dc":"## Libraries","9aa10e4a":"## Variables & data structures","cd00f0d8":"## Load data","ccebf17f":"### General structure\n\n##### Create instance of PreProcessor object\n`preprocessor = PreProcessor.from_params(parameters)`\n        \n##### Split data into train-selection-validation sets\n`basetable = preprocessor.train_selection_validation_split(data)`\n                \n##### Fit the pipeline\n`basetable = preprocessor.fit(basetable)`\n\n##### Transform the data\n`basetable = preprocessor.transform(basetable)`                  ","7974d76e":"# MODEL BUILDING","9f7131d9":"# PROJECT DEFINITION","a03a5010":"### General structure\n\n##### Generate PIG tables\n`pig_tables = generate_pig_tables(basetable)`\n\n##### Plot PIG tables\n`plot_incidence(pig_tables)`","7f453e5a":"## Rectangular data & filtering","b438edc1":"### Lists","de8b3d79":"## Preprocessing\n\nThe first part focuses on preparing the predictors into an **analytical basetable (ABT)** for modelling by:\n\n  * Splitting the dataset into training, selection and validation datasets.\n  * Binning continuous variables into discrete intervals.\n  * Replacing missing values of both categorical and continuous variables (which are now binned) with an additional \"Missing\" bin\/category.\n  * Regrouping categories in new category \"other\".\n  * Replacing bins\/categories with their corresponding incidence rate per category\/bin.\n","d8dece0c":"## Forward feature selection\nAfter having preselected the features, we can start modelling using forward feature selection.\n\nSince we use target encoding on all our predictors, we will only consider models with positive coefficients (no sign flip should occur) as this makes the model more interpretable.\n","05f0cb1e":"### General structure\n  \n##### Instantiate Evaluator object\n`evaluator = Evaluator()`\n\n##### Automatically find the best cut-off probability\n`evaluator.fit()`\n\n##### Get and plot various scalar metrics\n`evaluator.scalar_metrics`\n\n`evaluator.plot_confusion_matrix()`\n\n`evaluator.plot_roc_curve()`\n\n`...`","19354f53":"## A few exercises you can have a go at if you feel confident...\n\n1. Write a function that takes two lists and outputs them as two named columns of a DataFrame\n2. Compute at least two other summary statistics from the df variable (Google is your friend)\n3. Make a class Customer and add some init variables and functions (no need to fill in the functions, just write keyword 'pass' under the function name)","9f922c46":"Predict whether income exceeds $50k\/year based on U.S. census data.\n\nDataset which will be used:\n\n  * Survey of adults and their earnings\n  * Target variable: \n    * 1 = income > 50k USD\n    * 0 = income <= 50k USD\n  * Source: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Adult","8f1fe041":"# B. Predictive modelling with Cobra\n\nCobra is a Python package for rapid development of predictive models. Cobra focuses on interpretability and its methodology is based on Python Predictions' long experience with statistical modelling.\n\nHow to install Cobra?\n\n  * install the package `pip install -U pythonpredictions-cobra` and you are good to go!"}}