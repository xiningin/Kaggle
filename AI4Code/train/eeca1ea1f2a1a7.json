{"cell_type":{"c23f5dc4":"code","d981827b":"code","35ce0796":"code","056f81c7":"code","dd4bbd72":"code","a3e6a518":"code","bdaeb194":"code","24b16684":"code","43aba4c7":"code","49daaa0c":"code","18593ced":"code","8e9911e6":"code","163723b7":"markdown","dc309b1f":"markdown","c92128db":"markdown","efbbd27a":"markdown","7841c681":"markdown"},"source":{"c23f5dc4":"def jaccard(a, b): \n    intersection = a.intersection(b)\n    union = a.union(b)\n    jaccard = len(intersection) \/ len(union)\n    return float(jaccard)","d981827b":"jaccard({1, 2}, {2})","35ce0796":"jaccard({1, 2, 3}, {2})","056f81c7":"jaccard({1, 2, 3}, {3, 4})","dd4bbd72":"# No overlap\njaccard({1, 2, 3}, {4, 5, 6})","a3e6a518":"# Full overlap\njaccard({1, 2, 3}, {1, 2, 3})","bdaeb194":"# Order doesn't matter\njaccard({1, 2, 3}, {3, 2, 1})","24b16684":"# The function we were using, redefined to jaccard_set\ndef jaccard_set(a, b): \n    intersection = a.intersection(b)\n    union = a.union(b)\n    jaccard = len(intersection) \/ len(union)\n    return float(jaccard)\n\n# The metric used in the competition\n# I edited it to make it more readable\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    intersection = a.intersection(b)\n    union = a.union(b)\n    jaccard = len(intersection) \/ len(union)\n    return float(jaccard)\n    ","43aba4c7":"# 1\/2 overlap\njaccard(\"brown dog\", \"brown\")","49daaa0c":"# 1\/3 overlap\njaccard(\"the brown dog\", \"dog\")","18593ced":"# Full overlap, order doesn't matter\njaccard(\"the brown dog\", \"brown dog the\")","8e9911e6":"# No overlap\njaccard(\"the brown dog\", \"a white cat jumps\")","163723b7":"# Jaccard for texts\n\nNow that we understood Jaccard applied to bare sets, we can extrapolate its behaviour to texts. See the two functions below:","dc309b1f":"The only difference is that we take as input strings and turn them into sets, splitting them by whitespaces:\n\n## Examples:","c92128db":"<img src=\"https:\/\/i.imgur.com\/RFR6UZX.jpg\" width=\"100%\"\/>\n\n# 3. The metric (`Jaccard`)\n### [chaii - Hindi and Tamil Question Answering](https:\/\/www.kaggle.com\/c\/chaii-hindi-and-tamil-question-answering) - A quick overview for QA noobs\n\nHi and welcome! This is the third kernel of the series `chaii - Hindi and Tamil Question Answering - A quick overview for QA noobs`.\n\n**In this short kernel we will go over the metric Jaccard**.\n\n\n---\n\nThe full series consists of the following notebooks:\n1. [The competition](https:\/\/www.kaggle.com\/julian3833\/1-the-competition-qa-for-qa-noobs)\n2. [The dataset](https:\/\/www.kaggle.com\/julian3833\/2-the-dataset-qa-for-qa-noobs)\n3. _[The metric (Jaccard)](https:\/\/www.kaggle.com\/julian3833\/3-the-metric-jaccard-qa-for-qa-noobs) (This notebook)_\n4. [Exploring Public Models](https:\/\/www.kaggle.com\/julian3833\/4-exploring-public-models-qa-for-qa-noobs\/)\n5. [\ud83e\udd47 XLM-Roberta + Torch's extra data [LB: 0.749]](https:\/\/www.kaggle.com\/julian3833\/5-xlm-roberta-torch-s-extra-data-lb-0-749)\n6. [\ud83e\udd17 Pre & post processing](https:\/\/www.kaggle.com\/julian3833\/6-pre-post-processing-qa-for-qa-noobs\/)\n\nThis is an ongoing project, so expect more notebooks to be added to the series soon. Actually, we are currently working on the following ones:\n* Exploring Public Models Revisited\n* Reviewing `squad2`, `mlqa` and others\n* About `xlm-roberta-large-squad2`\n* Own improvements\n\n\n\n---\n\n\n# Evaluation\n\nThis is copied literally from the [evaluation](https:\/\/www.kaggle.com\/c\/chaii-hindi-and-tamil-question-answering\/overview\/evaluation) tab of the competition:\n\n>The metric in this competition is the [word-level Jaccard score](https:\/\/en.wikipedia.org\/wiki\/Jaccard_index). A good description of Jaccard similarity for strings is [here](https:\/\/towardsdatascience.com\/overview-of-text-similarity-metrics-3397c4601f50). \n\n> A Python implementation based on the links above, and matched with the output of the C# implementation on the back end, is provided below.\n\n```python\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n```\n\n\n# Jaccard for sets\n\n\nBefore applying the measure to texts, let's use it for sets of elements.\n\nThe jaccard coefficient measures **the intersection over the union** of two sets:\n\n$$\nJ(A,B) = {{|A \\cap B|}\\over{|A \\cup B|}}\n$$\n \nSo, for example, consider the sets `a={1, 2}` and `b={2}` it's jaccard coefficient is `0.5`, because the intersection of both is `{2}` and has lenght `1` while the union is `{1, 2}` and has lenght `2`, leading to the division `1\/2` (intersection length \/ union length).\n","efbbd27a":"Jaccard is a measure of similarity considering the overlap of elements. It goes from `0` (no overlap of elements) to `1` (all elements overlap).\n\nNote that the order doesn't matter, since it works with sets.","7841c681":"The metric used for this competition is:\n* Calculate jaccard coefficient between the real answer and your prediction for each test sample\n* Average all those coefficients\n\nTherefore, it's still a value between 0 and 1.\n\nThe current leaderboard of ~`0.75` means that the predictions are, in average, reaching a 75% overlap wit the actual responses.\n\n\n\n## What's next?\n\nWe have already understood the problem, took a look at the dataset, and analyzed the metric.\n\nLet's go on to [4. Exploring Public Models](https:\/\/www.kaggle.com\/julian3833\/4-exploring-public-models-qa-for-qa-noobs\/)!\n\n\nIf you want to dig deeper into Jaccard metric, I recommend the notebook [Jaccard Similarity Tamil & Hindi](https:\/\/www.kaggle.com\/mpwolke\/jaccard-similarity-tamil-hindi) by [mpwolke](https:\/\/www.kaggle.com\/mpwolke\/).\n\n\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n&nbsp;\n\n## Remember to upvote the notebook if you found it useful! \ud83e\udd17"}}