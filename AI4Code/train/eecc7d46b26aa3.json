{"cell_type":{"ff4376d6":"code","a26831f7":"code","79ac0f8f":"code","0a016dd6":"code","27621e6f":"code","fbb9bbd5":"code","4545d84d":"code","4c3d01ba":"code","9fe4fd1e":"code","cd37abbb":"code","96dd39c8":"code","e2c03189":"code","d49b25e9":"code","d77fdd9d":"code","a1fe0bee":"code","68dbb51f":"code","276f39ed":"code","399c15a4":"code","1481587d":"code","57d21073":"markdown","546c5cc3":"markdown","4df3d0b1":"markdown","0608ce8e":"markdown","84f8ba41":"markdown","098a16e0":"markdown","6d77cf7b":"markdown","5ec6d6b9":"markdown","21ff9578":"markdown","4fd21ae8":"markdown","9b51777d":"markdown","7f8b6a20":"markdown","19d1735c":"markdown","7366779f":"markdown"},"source":{"ff4376d6":"import os, sys, time\nfrom datetime import datetime\nsys.path.insert(0, '\/kaggle\/input\/siim-acr-pneumothorax-segmentation')\nsys.path.insert(0, '\/kaggle\/input\/pneum-scripts')\n\nimport pneum_aux\nfrom pathlib import Path\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nimport glob\nimport pdb\nfrom IPython.display import FileLink, FileLinks\nfrom scipy import ndimage\n\nimport fastai\nfrom fastai.vision import *\nfrom mask_functions import *\nimport torchvision.transforms as transforms\nimport pydicom\nfastai.__version__\n","a26831f7":"class ParamsManager(object):\n    def __init__(self):    self.config = {}\n    def __call__(self, key, value, method='override'):\n#         assert key not in self.config.keys(), f\"a value has already been set for {key}.\"\n        if method == 'override':\n            self.config[key] = value\n        return value\n    def __getitem__(self, key):    return self.config[key]\n    def name(self):    return '_'.join([k + '-' + str(self.config[k]) for k in self.config])\n\n    \ndef save_weight_n_ipynb(learn, work_path, prms):\n    modelname = prms.name()\n    learn.model_dir = work_path + '\/'\n    model_path = learn.model_dir + modelname\n    ipynb_out_path = model_path + '.ipynb'\n    if not os.path.isdir(learn.model_dir): os.mkdir(learn.model_dir)\n    %notebook $ipynb_out_path\n    learn.save(model_path)\n    FileLinks('.')","79ac0f8f":"pred_sig_id = 0\nvalid_fraction = 0.2\n\nprms = ParamsManager()\nprms.config = {'date': datetime.today().strftime('%m%d'), \n                'SEED': 42, \n                'SZ': 512,\n                'BS': 4 \n               }\n   \n    \nif prms['SEED'] >= 0:\n    pneum_aux.seed_everything(prms['SEED'])\n\n#### Paths\n# copy pretrained weights for resnet34 to the folder fastai will search by default\nPath('\/tmp\/.cache\/torch\/checkpoints\/').mkdir(exist_ok=True, parents=True)\n!cp '\/kaggle\/input\/resnet34\/resnet34.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet34-333f7ec4.pth'\nwork_path = '\/kaggle\/working'\ncsv_path = '\/kaggle\/input\/siim-train-test\/siim\/train-rle.csv'\nsaved_dfs_folder = '\/kaggle\/input\/saved-dfs\/'\n\n\n# IMAGE SIZE\nif prms['SZ'] <= 256:\n    path = Path(f'\/kaggle\/input\/pneumotorax{prms[\"SZ\"]}\/data{prms[\"SZ\"]}\/data{prms[\"SZ\"]}')\n    prms('data','nohisteq')\nelif prms['SZ'] == 512:\n    path = Path(f'\/kaggle\/input\/pneumothorax_{prms[\"SZ\"]}x{prms[\"SZ\"]}_png\/data{prms[\"SZ\"]}')\n    prms('data','nohisteq')\n#     path = Path(f'\/kaggle\/input\/siimacr-pneumothorax-segmentation-data-512')\n#     prms('data','histeq')\nelif prms['SZ'] == 1024:\n#     path = Path(f'\/kaggle\/input\/pneumothorax_{model_params[\"SZ\"]}x{model_params[\"SZ\"]}_png\/data{model_params[\"SZ\"]}')\n    path = Path(f'\/kaggle\/input\/siimacr-pneumothorax-segmentation-data-1024')\n    prms('data','histeq')\n# print(learn.model_dir)\n\n#### define labels df\ndf, df_bal = pneum_aux.make_dfs(csv_path, saved_dfs_folder)\n# prms('data',prms['data'] + '-blncd')  # somehow document that the data is balanced\n# model_params['data'] = model_params['data'] + '-blncd'\n\n# check split\npneum_frac_train = sum(df.loc[df['is_valid']==False, 'EncodedPixels'] !='-1')\/sum(df['is_valid']==False)\npneum_frac_valid = sum(df.loc[df['is_valid']==True, 'EncodedPixels'] !='-1')\/sum(df['is_valid']==True)\nvalid_frac = df.is_valid.mean()\nprint(f'pneum examples \/ tot examples [train] = {pneum_frac_train:.2f}')\nprint(f'pneum examples \/ tot examples [test] = {pneum_frac_valid:.2f}')\nprint(f'validation examples \/ tot examples = {valid_frac:.2f}')\n","0a016dd6":"class BCE_Custom_Loss_MultiTask(nn.Module):\n\n    def __init__(self, num_classes=1, dice_rebal_fact=9, pix_imbal_fact=0):\n        super().__init__()\n        self.num_classes = num_classes\n        self.dice_rebal_fact = dice_rebal_fact\n        self.pix_imbal_fact = pix_imbal_fact\n        self.__name__ = 'BCE_Custom_Loss'\n        self.activefun = 'sigmoid'\n\n    def forward(self, pred, targ_img, targ_meta):\n        t_mask = targ_img[:, 0, :, :].type(torch.FloatTensor).contiguous().cpu()  # note that in addition to the channel-index, squeeze() would omit batch-index when bs=1\n        p_mask = pred[0][:, 0, :, :].cpu()\n        t_gender = targ_meta[:, 0].cpu()\n        p_gender = pred[1][:,0].cpu()\n        t_pneum = targ_meta[:, 1].cpu()\n        p_pneum = pred[1][:,1].cpu()\n        \n        w_pneum = (1 + self.pix_imbal_fact)\n        w_nonpneun = (1 + self.dice_rebal_fact * (1- t_pneum))\n        w = w_pneum * t_mask + w_nonpneun[:,None,None] * (1 - t_mask)\n\n        loss_mask = F.binary_cross_entropy_with_logits(p_mask, t_mask, w, reduction='mean')\n        loss_gender = F.binary_cross_entropy_with_logits(p_gender, t_gender, reduction='mean')\n        loss_pneum = F.binary_cross_entropy_with_logits(p_pneum, t_pneum, reduction='mean')\n        return loss_mask + loss_gender + loss_pneum  # TODO: add relative weights to the loss terms\n\n\nclass MultitaskDataset(Dataset):\n    '''`Dataset` for joint single and multi-label image classification.'''\n    def __init__(self, fns, meta_dict={}):  #labels_gender, labels_pneum, ages, classes_pneum, classes_gender):\n        self.x = np.array(fns)\n        self.meta_dict = meta_dict\n        if len(self.meta_dict) > 0:\n            self.classes_gender = meta_dict['classes_gender']\n            self.classes_pneum = meta_dict['classes_pneum']\n\n            self.class2idx_gender = {v:k for k,v in enumerate(self.classes_gender)}\n            self.y_gender = np.array([self.class2idx_gender[o] for o in meta_dict['labels_gender']], dtype=np.int64)\n\n            self.class2idx_pneum = {v:k for k,v in enumerate(self.classes_pneum)}\n            self.y_pneum = np.array([self.class2idx_pneum[o] for o in meta_dict['labels_pneum']], dtype=np.int64)\n\n            self.y_age = meta_dict['ages'][:, None].astype('float32')\n\n            self.c = 1  #self.c_gender + self.c_pneum + self.c_age\n    \n    def __len__(self): return len(self.x)\n    \n    def __getitem__(self,i:int): \n        if len(self.meta_dict) > 0:\n            img = open_image(self.x[i])\n            return img, [open_mask(self.x[i].replace('train', 'masks'), div=True), torch.tensor([self.y_gender[i], self.y_pneum[i], self.y_age[i]]).float()]\n        else:\n#             oi = open_image(self.x[i]), \n            return [open_image(self.x[i]), torch.tensor([0]).float()]\n        \n    def __repr__(self): return f'{type(self).__name__} of len {len(self)}'\n    \n     \ndef get_dataset(df):\n    return MultitaskDataset(str(path\/'train') + '\/' + df.ImageId + '.png',\n                            meta_dict={'labels_gender': df.Sex, \n                            'labels_pneum': df.is_pneum,\n                            'ages': df.Age,\n                            'classes_pneum': sorted(set(df.is_pneum)),\n                            'classes_gender': sorted(set(df.Sex))\n                            }\n                           )\n\n# The way I constructed MultitaskDataset is not consistent enough with fastai's design, which raises difficulties in applying augmentations to the samples\n# Augs are therefore skipped till this will be solved.\n\n# # Setting transformations on masks to False on test set\n# def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n#     if not tfms: tfms=(None,None)\n#     assert is_listy(tfms) and len(tfms) == 2\n#     self.train.transform(tfms[0], **kwargs)\n#     self.valid.transform(tfms[1], **kwargs)\n#     kwargs['tfm_y'] = False # Test data has no labels\n#     if self.test: self.test.transform(tfms[1], **kwargs)\n#     return self\n# fastai.data_block.ItemLists.transform = transform\n\n# tfms = ([rotate(degrees=90)],[])\n\n\n# train_df = df_bal[df_bal.is_valid==False].sample(prms['BS']*30)\n# valid_df = train_df.copy()\ntrain_df = df[df.is_valid==False]  #.sample(prms['BS']*30)\nvalid_df = df[df.is_valid==True]  #.sample(prms['BS']*30)\ntrain_df = pd.concat([train_df, train_df.iloc[:prms['BS'] - (len(train_df) % prms['BS'])]])\nvalid_df = pd.concat([valid_df, valid_df.iloc[:prms['BS'] - (len(valid_df) % prms['BS'])]])\ntrain_ds = get_dataset(train_df)\nvalid_ds = get_dataset(valid_df)\ntest_ds = MultitaskDataset((path\/'test').ls(), meta_dict={})\ndata2 = ImageDataBunch.create(train_ds=train_ds, valid_ds=valid_ds,test_ds=test_ds, path=str(path\/'train'), bs=prms['BS']).normalize(imagenet_stats)\n#   dl_tfms=get_transforms(flip_vert=True), \n# data2.test_ds = test_ds\n# data2.test_dl = DataLoader(test_ds, batch_size=prms['BS'], shuffle=False)\n# data2_test = ImageDataBunch.create(test_ds, test_ds, path=str(path\/'train'), bs=prms['BS']).normalize(imagenet_stats)\n# data2.add_test(test_ds)\n#  .add_test((path\/'test').ls(), label=None))\nprint('train n = ',len(data2.train_ds), '. valid n = ', len(data2.valid_ds))\nprint('train n % bs = ', len(train_df) % prms['BS'], '. valid n % bs = ', len(valid_df) % prms['BS'])\n# debug\n# for i in range(10):\n#     fig, ax = plt.subplots(1,2)\n#     ax[0].imshow(data2.train_ds[i][0].data[0,:,:]*0.9 + data2.train_ds[i][1][0].data[0,:,:].float())\n# learn.data = data2\n# preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n","27621e6f":"def MT_metrics(metric_func, *args, **kwargs):\n    @functools.wraps(metric_func)\n    def wrapper(inputs, targs_seg, targs_clf, **kwargs):\n        n = targs_seg.shape[0]\n        input_seg, input_clf = inputs\n        input_seg = inputs[0].sigmoid().view(n,-1)  #torch.softmax(input_seg, dim=1)[:,1,...].view(n,-1)\n        input_clf = inputs[1].sigmoid().view(n,3,-1)\n        targs_seg = targs_seg.view(n,-1)\n        targs_clf = targs_clf.view(n,3,-1)\n        return metric_func(input_seg, input_clf, targs_seg, targs_clf, **kwargs)\n    return wrapper\n\n@MT_metrics\ndef mydice(input_seg:Tensor, input_clf:Tensor, targs_seg:Tensor, targs_clf:Tensor, thrs=0.9, eps:float=1e-8):\n    input_seg = (input_seg > thrs).long()\n    input_seg[input_seg.sum(-1) < 0,...] = 0.0 \n    intersect = (input_seg * targs_seg).sum(-1).float()\n    union = (input_seg + targs_seg).sum(-1).float()\n#     return ((2.0*intersect + eps) \/ (union+eps)).mean()\n    u0 = union==0\n    intersect[u0], union[u0] = 1, 2\n#     pdb.set_trace()\n    return (2. * intersect \/ union)\n    \n@MT_metrics\ndef mygender(input_seg:Tensor, input_clf:Tensor, targs_seg:Tensor, targs_clf:Tensor, iou:bool=False, eps:float=1e-8):\n    input_gender = (input_clf[:,0] > 0.5).long()\n    targs_gender = targs_clf[:,0].long()\n    return (input_gender == targs_gender).float().mean()\n    \n@MT_metrics\ndef mypneum(input_seg:Tensor, input_clf:Tensor, targs_seg:Tensor, targs_clf:Tensor, iou:bool=False, eps:float=1e-8):\n    input_gender = (input_clf[:,1] > 0.5).long()\n    targs_gender = targs_clf[:,1].long()\n    return (input_gender == targs_gender).float().mean()\n\n# debug metrics\n# print(mydice(torch.Tensor([[0,1,2],[3,4,5]]), torch.Tensor([[1,1,1]]).long(), torch.Tensor([[1,1,1]]).long()))\n# print(mygender(torch.Tensor([[0,1,2],[3,4,5]]), torch.Tensor([[1,1,1]]).long(), torch.Tensor([[1,1,1]]).long()))","fbb9bbd5":"class AccumulateOptimWrapper(OptimWrapper):\n    def step(self):           pass\n    def zero_grad(self):      pass\n    def real_step(self):      super().step()\n    def real_zero_grad(self): super().zero_grad()\n        \n        \ndef acc_create_opt(self, lr:Floats, wd:Floats=0.):\n        \"Create optimizer with `lr` learning rate and `wd` weight decay.\"\n        self.opt = AccumulateOptimWrapper.create(self.opt_func, lr, self.layer_groups,\n                                         wd=wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\nLearner.create_opt = acc_create_opt\n\n\ndef set_BN_momentum(model,momentum=0.1*prms['BS']\/64):\n    for i, (name, layer) in enumerate(model.named_modules()):\n        if isinstance(layer, nn.BatchNorm2d) or isinstance(layer, nn.BatchNorm1d):\n            layer.momentum = momentum\n        \n@dataclass\nclass AccumulateStep(LearnerCallback):\n    \"\"\"\n    Does accumlated step every nth step by accumulating gradients\n    \"\"\"\n    def __init__(self, learn:Learner, n_step:int = 1):\n        super().__init__(learn)\n        self.n_step = n_step\n        set_BN_momentum(learn.model)\n        \n        \n    def on_epoch_begin(self, **kwargs):\n        \"init samples and batches, change optimizer\"\n        self.acc_batches = 0\n        \n    def on_batch_begin(self, last_input, last_target, **kwargs):\n        \"accumulate samples and batches\"\n        self.acc_batches += 1\n        \n    def on_backward_end(self, **kwargs):\n        \"step if number of desired batches accumulated, reset samples\"\n        if (self.acc_batches % self.n_step) == self.n_step - 1:\n            for p in (self.learn.model.parameters()):\n                 if p.requires_grad: p.grad.div_(self.acc_batches)\n    \n            self.learn.opt.real_step()\n            self.learn.opt.real_zero_grad()\n            self.acc_batches = 0\n    \n    def on_epoch_end(self, **kwargs):\n        \"step the rest of the accumulated grads\"\n        if self.acc_batches > 0:\n            for p in (self.learn.model.parameters()):\n                if p.requires_grad: p.grad.div_(self.acc_batches)\n            self.learn.opt.real_step()\n            self.learn.opt.real_zero_grad()\n            self.acc_batches = 0\n           \n        \n@dataclass\nclass KeepKernelAlive(LearnerCallback):\n    def __init__(self,time_interval):\n        self.time_interval = time_interval\n    def reset_time(self): self.time0 = time.time()\n    def on_epoch_begin(self, **kwargs): self.reset_time()\n    def on_batch_begin(self, **kwargs):\n        if time.time() - self.time0 > self.time_interval:\n            self.reset_time()\n            print('Kernel pulse...')          \n# @dataclass\n# class GetGradNorm(LearnerCallback):\n#     \"\"\"\n#     stores & plots grad norm\n#     \"\"\"\n#     def __init__(self, learn:Learner, n_step:int = 1):\n#         super().__init__(learn)\n#         self.gnorms, self.gnorms_tot = [], []\n#         self.fig, self.ax = plt.subplots(ncols=2,nrows=1, figsize=(4,4))\n\n#     def on_backward_end(self, **kwargs):\n#         \"calc total grads norm\"\n#         parameters = list(filter(lambda p: p.grad is not None, learn.model.parameters()))\n#         total_norm = 0\n#         for p in parameters:\n#             param_norm = p.grad.data.norm(2)\n#             total_norm += param_norm.item() ** 2\n#         total_norm = total_norm ** (1. \/ 2)\n#         self.gnorms.append(total_norm)\n    \n#     def on_epoch_begin(self, **kwargs):\n#         self.gnorms_tot.append(self.gnorms)\n#         self.gnorms = []\n        \n#     def on_epoch_end(self, **kwargs):\n#         \"plot the total grads norms\"\n#         self.ax[0].plot(self.gnorms)\n#         plt.show()\n    \n#     def on_training_end(self, **kwargs):\n#         self.ax[1].plot(np.hstack(get_grad_norm.gnorms_tot[2:]));\n#         plt.show()\n        \n\n# class RunningBatchNorm(nn.Module):\n#     def __init__(self, nf, mom=0.1, eps=1e-5):\n#         super().__init__()\n#         self.mom,self.eps = mom,eps\n#         self.mults = nn.Parameter(torch.ones (nf,1,1))\n#         self.adds = nn.Parameter(torch.zeros(nf,1,1))\n#         self.register_buffer('sums', torch.zeros(1,nf,1,1))\n#         self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n#         self.register_buffer('batch', tensor(0.))\n#         self.register_buffer('count', tensor(0.))\n#         self.register_buffer('step', tensor(0.))\n#         self.register_buffer('dbias', tensor(0.))\n\n#     def update_stats(self, x):\n#         bs,nc,*_ = x.shape\n#         self.sums.detach_()\n#         self.sqrs.detach_()\n#         dims = (0,2,3)\n#         s = x.sum(dims, keepdim=True)\n#         ss = (x*x).sum(dims, keepdim=True)\n#         c = self.count.new_tensor(x.numel()\/nc)\n#         mom1 = 1 - (1-self.mom)\/math.sqrt(bs-1)\n#         self.mom1 = self.dbias.new_tensor(mom1)\n#         self.sums.lerp_(s, self.mom1)\n#         self.sqrs.lerp_(ss, self.mom1)\n#         self.count.lerp_(c, self.mom1)\n#         self.dbias = self.dbias*(1-self.mom1) + self.mom1\n#         self.batch += bs\n#         self.step += 1\n\n#     def forward(self, x):\n#         if self.training: self.update_stats(x)\n#         sums = self.sums\n#         sqrs = self.sqrs\n#         c = self.count\n#         if self.step<100:\n#             sums = sums \/ self.dbias\n#             sqrs = sqrs \/ self.dbias\n#             c    = c    \/ self.dbias\n#         means = sums\/c\n#         vars = (sqrs\/c).sub_(means*means)\n#         if bool(self.batch < 20): vars.clamp_min_(0.01)\n#         x = (x-means).div_((vars.add_(self.eps)).sqrt())\n#         return x.mul_(self.mults).add_(self.adds)\n    \n\n#### Test loss function\n# from torch.autograd import Variable as V\n# x,y = next(iter(data.valid_dl))\n# # x,y = V(x).cpu(),V(y)\n# x,y = V(x),V(y)\n\n# for i,o in enumerate(y): y[i] = o.cuda()\n# learn.model.cuda()\n\n# batch = learn.model(x)\n# learn.loss_func(batch, y)\n","4545d84d":"# Extend the unet model to preform classification at the encoder end\nclass MultiTaskUnetResnet(nn.Module):\n    def __init__(self,pretrained_unet_resnet34):\n        super(MultiTaskUnetResnet, self).__init__()\n        self.unet_resnet34=pretrained_unet_resnet34\n        self.clf_layer = AdaptiveConcatPool2d((1,2))\n        self.fc = nn.Linear(2*1024, 3)\n\n\n    def forward(self, x):\n        res = x\n    \n        res.orig = x\n        nres = self.unet_resnet34[0](res)\n        res.orig = None\n        res = nres\n        \n        res_clf = res.clone()\n        res_clf = self.clf_layer(res_clf)\n        res_clf = self.fc(res_clf.view(res_clf.shape[0],-1))\n        \n        for l in (self.unet_resnet34[1:]):\n            res.orig = x\n            nres = l(res)\n            res.orig = None\n            res = nres\n            \n        return res,  res_clf \n# learn.model, _ = convert_layers(learn.model, 41, nn.BatchNorm2d, RunningBatchNorm, convert_weights=False)\n\n# Function to replace layer of a certain type with an alternative\n# https:\/\/discuss.pytorch.org\/t\/how-can-i-replace-an-intermediate-layer-in-a-pre-trained-network\/3586\/7\ndef convert_layers(model, num_to_convert, layer_type_old, layer_type_new, convert_weights=False):\n    conversion_count = 0\n    for name, module in reversed(model._modules.items()):\n        if len(list(module.children())) > 0:\n            # recurse\n            model._modules[name], num_converted = convert_layers(module, num_to_convert-conversion_count, layer_type_old, layer_type_new, convert_weights)\n            conversion_count += num_converted\n\n        if type(module) == layer_type_old and conversion_count < num_to_convert:\n            layer_old = module\n            layer_new = layer_type_new(module.num_features, mom=0.1, eps=1e-5).cuda()\n\n            if convert_weights == True:\n                layer_new.weight = layer_old.weight\n                layer_new.bias = layer_old.bias\n\n            model._modules[name] = layer_new\n            conversion_count += 1\n\n    return model, conversion_count","4c3d01ba":"arch = models.resnet34\n# Create U-Net with a pretrained resnet34 as encoder\nlearn = unet_learner(data2, arch, metrics=[mydice, mygender, mypneum])  # , opt_func=optim.SGD\nprms('arch', 'unet:' + arch.__name__)\nlearn.loss_func = BCE_Custom_Loss_MultiTask(num_classes=1, dice_rebal_fact=prms('dice_rebal_fact', 0), pix_imbal_fact=prms('pix_imbal_fact',0))\nprms('loss', 'BCECostum_dicefact')\n\nlearn.model = MultiTaskUnetResnet(learn.model).cuda()","9fe4fd1e":"# Find LR\nlearn.model_dir= '\/kaggle\/working\/'\nlearn.lr_find(start_lr=1e-09, end_lr=1e-1, stop_div=True, num_it=100)\nlearn.recorder.plot()","cd37abbb":"# Fit\n# learn.load('\/kaggle\/input\/date0805-seed42-sz512\/date-0805_SEED-42_SZ-512_crop_fact-2_BS-8_data-histeq--blncd_arch-unet_resnet34_loss-BCECostum_dicefact9_lr0-0.0001_cycles0-6')\nn_acc = 64\/\/prms['BS']\nlearn.fit_one_cycle(prms('cycles0',1), max_lr=prms('lr0',1e-5), callbacks=[AccumulateStep(learn, n_acc), KeepKernelAlive(time_interval=60*30)])\nsave_weight_n_ipynb(learn, work_path, prms)\nFileLinks('.')\n    \nprint(torch.cuda.get_device_properties(0).total_memory\/1024\/1024)\nprint(torch.cuda.memory_allocated()\/1024\/1024)","96dd39c8":"# Unfreeze the encoder\n# learn.load('\/kaggle\/input\/date0811-seed42-sz512\/date-0811_SEED-42_SZ-512_crop_fact-2_BS-8_data-nohisteq_arch-unet_resnet34_dice_rebal_fact-10_pix_imbal_fact-10_loss-BCECostum_dicefact_cycles1-4_lr1-0.0001')\nlearn.model_dir= '\/kaggle\/working\/'\n\nlearn.unfreeze()\nlearn.lr_find(start_lr=1e-11, end_lr=1e-1, stop_div=True)  # stop_div=False)\nlearn.recorder.plot()","e2c03189":"# Fit unfreezed\n\n# learn.load('\/kaggle\/input\/date0805-seed42-sz512\/date-0805_SEED-42_SZ-512_crop_fact-2_BS-8_data-histeq--blncd_arch-unet_resnet34_loss-BCECostum_dicefact9_lr0-0.0001_cycles0-6')\nn_acc = 64\/\/prms['BS']\n# get_grad_norm = GetGradNorm(learn)\nlearn.fit_one_cycle(prms('cycles1',1), slice(prms('lr1',1e-8)\/30, prms('lr1',1e-8)), callbacks=[AccumulateStep(learn, n_acc), KeepKernelAlive(time_interval=60*40)])\nsave_weight_n_ipynb(learn, work_path, prms)\nFileLinks('.')\n    \nprint(torch.cuda.get_device_properties(0).total_memory\/1024\/1024)\nprint(torch.cuda.memory_allocated()\/1024\/1024)","d49b25e9":"# get predictions on data withou exhausting RAM\n\n# learn.load('\/kaggle\/input\/1707-blncd-nohisteq-512\/modelsdate-0717_SEED-42_SZ-512_BS-8_augs-rotate_data-nohisteq_balanced_arch-unet_resnet34_lr0-0.0001_cycles0-10')\n# learn.data.batch_size = 8\nif 'preds' in globals():    del preds\nif 'ys' in globals():    del ys\n    \nfrac = 1\nthrs = np.arange(0.5, 1, 0.01)\n\ndef mypreds(prms,dl=data2.valid_dl,frac=frac, thrs=[0.5], batch_size=None):\n    if batch_size is not None:\n        bs = batch_size\n    else:\n        bs = prms['BS']\n    orig_bs = dl.batch_size\n    dl.batch_size = bs\n    \n    dices = []\n    all_preds = []\n    example_cases = []\n    batch_iter = iter(dl)\n    dummy4dice = torch.tensor(np.ones((bs,3,3))*1.)\n\n    for n in tqdm(range(int(len(dl) * frac \/ bs))):\n        batch = next(batch_iter)\n        preds_tup = learn.pred_batch(batch=batch)\n        preds_batch, ys_batch = preds_tup[0][:,0,:,:].sigmoid().data.clone().detach().cpu(), batch[1][0].long().clone().detach().cpu()\n        # store info\n        if n % 10 == 0 : example_cases.append((preds_batch, ys_batch, batch))\n        all_preds.append(preds_batch)\n        for i in thrs:\n            preds_i = (preds_batch>i).float()\n            dices.append(mydice([preds_i, dummy4dice], ys_batch, dummy4dice.long()))\n            \n    try:\n        print(\"explaining 'batch' structure:\")\n        print(\"'batch' elemnts =\",len(batch), ': \\n\\t1st->', batch[0].shape, '. \\n\\t2nd->', len(batch[1]), 'elemnts: \\n\\t\\t1ts->', batch[1][0].shape, '. \\n\\t\\t2nd->', batch[1][1].shape)\n    except:\n        pass\n    dl.batch_size = orig_bs\n    return dices, np.stack(example_cases,1), all_preds\n \ndices, example_cases, _ = mypreds(prms, dl=data2.valid_dl, frac=frac, thrs=thrs)\ndices_reshaped=np.stack(dices).T.reshape((-1, len(thrs)))\ndices_mean = dices_reshaped.mean(0)\n    \n\n## debug\n# for i in range(8):  #[1,2,3,5]:\n#     fig, axs = plt.subplots(1,3)\n#     axs[0].imshow(batch[0][i,0,:,:])\n#     axs[1].imshow(preds_batch[i,:,:].sigmoid())\n#     axs[2].imshow(ys_batch[i,0,:,:])\n# dices = np.array(dices)  # .reshape((-1, len(thrs)))\n# dices_reshaped = dices.reshape((-1, len(thrs)))\n","d77fdd9d":"best_dice = dices_mean.max()\nbest_thr = thrs[dices_mean.argmax()]\n\nplt.figure(figsize=(8,4))\nplt.plot(thrs, dices_mean)\nplt.vlines(x=best_thr, ymin=dices_mean.min(), ymax=dices_mean.max())\nplt.text(best_thr+0.03, best_dice-0.01, f'DICE = {best_dice:.3f} \\n THR = {best_thr: .3f}', fontsize=14);\nplt.show()","a1fe0bee":"# Plot some samples\n\nchk_thr = 0.1 if 'best_thr' not in globals() else best_thr\nbatch_id = 5\nex_preds, ex_ys, ex_imgs = example_cases[0][batch_id].squeeze(), example_cases[1][batch_id], example_cases[2][batch_id][0]\nplot_idx = np.argsort(ex_preds[:,:,:].sum((1,2)))  #ex_preds.squeeze().sum((1,2)).sort(descending=True).indices[:]\ndummy4dice = torch.tensor(np.ones((1,3,3))*1.)\nfor idx in plot_idx:\n    fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n    img = ex_imgs[idx,0,:,:].cpu()\n\n    ax0.imshow(img)\n    ax1.imshow(ex_preds[idx], vmin=0, vmax=1)\n    ex_ys_img = ex_ys.squeeze()[idx].numpy().copy()\n    ax1.imshow(ex_ys_img - ndimage.binary_erosion(ex_ys_img, structure=np.ones((8,8))) , alpha=0.5)\n    ax2.imshow(ex_preds[idx]>chk_thr, vmin=0, vmax=1)\n\n    img_dice= mydice([ex_preds[idx][None,None,:,:].type(torch.FloatTensor), dummy4dice.float()], ex_ys[idx][None,:,:,:], dummy4dice.float(), thrs=best_thr).numpy()[0]\n    ax1.set_title('targs + preds, dice={0:.2f}'.format(img_dice))\n    ax2.set_title('preds threshed')","68dbb51f":"# learn.load('\/kaggle\/input\/1407-unfrz-blncd-model\/modelsdate_0713_SEED_42_SZ_512_crop_fact_2_BS_8_cycles0_5_lr0_1e-05_cycles1_5_lr1_1e-05_augs_rotate_arch_unet_resnet34')\n# best_thr = 0.75\nif 'preds' in globals():    del preds\nif 'ys' in globals():    del ys\n# Predictions for test set\ngc.collect()\n_,_, preds = mypreds(prms,dl=data2.test_dl, frac=1, thrs=[best_thr], batch_size=1)\npreds = [(item.sigmoid()>best_thr).long().numpy() for sublist in preds for item in sublist]\nassert len(preds) == len(learn.data.test_ds), \"haven't ran prediction on all test images\"\n# preds = preds[:,pred_sig_id,:,:].sigmoid()  # .sigmoid()\n# preds = (preds>best_thr).long().numpy()\n# print(preds.sum())\n\n# Generate rle encodings (images are first converted to the original size)\nrles = []\nfor p in progress_bar(preds):\n    im = PIL.Image.fromarray((p.T*255).astype(np.uint8)).resize((1024,1024))\n    im = np.asarray(im)\n    rles.append(mask2rle(im, 1024, 1024))","276f39ed":"prms('finalthr', best_thr)\nmodelname = prms.name()\n\nif not os.path.isdir(modelname):\n    os.mkdir(modelname)\n\n\nids = [o.stem for o in (path\/'test').ls()]  # TODO: replace with the more correct: ids = [o.stem for o in data.test_ds.items]\nsub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\nsub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\nsub_df.to_csv('submission_' + modelname + '.csv', index=False)\nsub_df.head()\n\nsave_weight_n_ipynb(learn, work_path, prms)\nFileLinks('.')","399c15a4":"@dataclass\nclass get_grad_norm(LearnerCallback):\n    \"\"\"\n    stores & plots grad norm\n    \"\"\"\n    def __init__(self, learn:Learner, n_step:int = 1):\n        super().__init__(learn)\n        self.gnorms = []\n        self.fig, self.ax = plt.subplots(ncols=2,nrows=1, figsize=(4,4))\n\n    def on_backward_end(self, **kwargs):\n        \"calc total grads norm\"\n        parameters = list(filter(lambda p: p.grad is not None, learn.model.parameters()))\n        total_norm = 0\n        for p in parameters:\n            param_norm = p.grad.data.norm(2)\n            total_norm += param_norm.item() ** 2\n        total_norm = total_norm ** (1. \/ 2)\n        self.gnorms.append(total_norm)\n    \n    def on_epoch_begin(self, **kwargs):\n        self.gnorms = []\n        \n    def on_epoch_end(self, **kwargs):\n        \"plot the total grads norms\"\n        self.ax.plot(self.gnorms)\n        plt.show()\n","1481587d":"# # Find optimal threshold\n# dices = []\n# thrs = np.arange(0, 1.01, 0.01)\n# for i in progress_bar(thrs):\n#     preds_m = (torch.tensor(preds)>i).long()\n#     dices.append(dice_overall(preds_m, ys).mean())\n# dices = np.array(dices)","57d21073":"## Analyze predictions","546c5cc3":"## test RLEs for submission","4df3d0b1":"TODO:\n* 1024 + running batch norm + accumulate gradients: understand and debug\n* automatically save & download models to not lose them.\n* should I work with a \"balanced\" dataset, or a one that reflects better the acutal test set?\n* from torchviz import make_dot\n","0608ce8e":"## Functions to save models","84f8ba41":"# TODOs","098a16e0":"## Setup loss & data","6d77cf7b":"## Functions for training","5ec6d6b9":"### Train ","21ff9578":"## Paths","4fd21ae8":"### unused drafts","9b51777d":"## Network setup","7f8b6a20":"## Imports","19d1735c":"## Set Learner","7366779f":"## Metrics"}}