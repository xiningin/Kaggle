{"cell_type":{"f0ca009a":"code","dd0ea5a3":"code","7686cb16":"code","bdd494fb":"code","a8ea054a":"code","f19ddc42":"code","b7c90d22":"code","c70a1b94":"code","d06286e2":"code","c56017c5":"code","545944f0":"code","76a8a20d":"code","744a12dd":"code","ee1f9b49":"code","b193f936":"code","b304d2f9":"code","2145e719":"code","086bc801":"code","003cc011":"markdown","85ec9fad":"markdown","c1cddfde":"markdown","98e99c0e":"markdown","a7b7c6c8":"markdown","d1c0a3f7":"markdown","aa5e9eea":"markdown","15091141":"markdown","e3bb6d2e":"markdown","4563f28b":"markdown","a2888f00":"markdown","ac96b00b":"markdown"},"source":{"f0ca009a":"import numpy as np\nimport pandas as pd\n\nimport os\nprint(os.listdir(\"..\/input\"))","dd0ea5a3":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","7686cb16":"train_data.head()","bdd494fb":"train_data.info()","a8ea054a":"train_data.describe()","f19ddc42":"train_data['Survived'].value_counts()","b7c90d22":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass AttributeSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attributes_names):\n        self.attributes_names = attributes_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attributes_names]","c70a1b94":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nnumerical_pipeline = Pipeline([\n    ('select_numeric', AttributeSelector(['Age', 'SibSp', 'Parch'])),\n    ('imputer', SimpleImputer(strategy='median')) # Replacing with median values\n])","d06286e2":"# Using the `numerical_pipeline`\nnumerical_pipeline.fit_transform(train_data)","c56017c5":"class CategoricalImputer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[att].value_counts().index[0] for att in X],\n                                       index=X.columns)\n        return self\n    \n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)","545944f0":"from sklearn.preprocessing import OneHotEncoder","76a8a20d":"categorical_pipeline = Pipeline([\n    ('select_cat', AttributeSelector(['Pclass', 'Sex', 'Embarked'])),\n    ('imputer', CategoricalImputer()),\n    ('cat_encoder', OneHotEncoder(sparse=False)),\n])","744a12dd":"categorical_pipeline.fit_transform(train_data)","ee1f9b49":"from sklearn.pipeline import FeatureUnion\n\npreprocess_pipeline = FeatureUnion(transformer_list=[\n    ('numerical_pipeline', numerical_pipeline),\n    ('categorical_pipeline', categorical_pipeline),\n])","b193f936":"X_train = preprocess_pipeline.fit_transform(train_data)\ny_train = train_data['Survived']","b304d2f9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\nrnd_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\nrnd_forest_clf.fit(X_train, y_train)\nrnd_forest_scores = cross_val_score(rnd_forest_clf, X_train, y_train, cv=10)\nrnd_forest_scores.mean()","2145e719":"X_test = preprocess_pipeline.transform(test_data)\ny_pred = rnd_forest_clf.predict(X_test)\ny_pred","086bc801":"submission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","003cc011":"Let us build a preprocess pipeline to use categorical and numerical attributes effectively.","85ec9fad":"What about the missing values in the string categorical attributes? We will need a different approach for that.","c1cddfde":"Let us see the survived and not-survived numbers.","98e99c0e":"**Pclass** can be an interesting attribute. Another categorical attribute is the **Embarked** attribute. We should not be ignoring the categorical attributes. Also, we would be using `OneHotEncoder` to creat dummy variables.","a7b7c6c8":"* Some of the `Age` values are missing.\n* Most of the `Cabin` values are missing.\n* Only 2 of the `Embarked` values are missing.","d1c0a3f7":"The `Pclass` attribute can be interesting. Can it be that most of the elite class peopel survived? We may dive into that later.","aa5e9eea":"Getting a bit of more info.","15091141":"Taking a look at the numerical attributes.","e3bb6d2e":"We should build a pipeline for the numerical attributes. We do not want to miss out on important features due to missing values and NaNs.","4563f28b":"Looks like more than half the people did not survive.","a2888f00":"Building the categorical attributes' pipeline.","ac96b00b":"**Trying `RandomForestClassifier`**:"}}