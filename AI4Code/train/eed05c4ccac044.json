{"cell_type":{"ed4fdcda":"code","78ccaf7b":"code","9a613608":"code","d17d219f":"code","babdebd1":"code","717e766b":"code","4a58dd5a":"code","519345f5":"code","e66ae381":"code","0b8c910a":"code","e9984724":"code","d78cd88c":"code","7a5cfdfd":"code","d241ad69":"code","dd228300":"code","37209c7e":"code","0c3a6a12":"code","eee94d21":"code","af97ee62":"code","0b7089b1":"code","e9ca8ad4":"markdown","103d614e":"markdown","dac5a4d5":"markdown","a69c8c25":"markdown","bc39dbbe":"markdown","b5ae9f0f":"markdown","95379b09":"markdown","7d35ccb8":"markdown","87687f48":"markdown","f7283546":"markdown","74dfb3d6":"markdown","be39bc49":"markdown","ed34fc88":"markdown","5a141371":"markdown","eef52ead":"markdown","9d9a147c":"markdown","d73f0b49":"markdown","365759d2":"markdown","d07b56c3":"markdown","c3b5001f":"markdown","254094e8":"markdown","e514c5c5":"markdown","dcc2d00e":"markdown","4e3d5232":"markdown","d9e1c508":"markdown","070bc5fa":"markdown","59bdb2f1":"markdown","14324f14":"markdown","850266ee":"markdown"},"source":{"ed4fdcda":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78ccaf7b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nfrom sklearn.cluster import KMeans\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9a613608":"dataset = pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndataset","d17d219f":"#Display the First Five Rows \ndataset.head()","babdebd1":"#Display the last Five Rows \ndataset.tail()","717e766b":"#Check the Shape(Rows,Columns)\ndataset.shape","4a58dd5a":"#Check any null Value in Dataset\ndataset.isnull().sum()","519345f5":"#Display the Statistical Information\ndataset.describe()","e66ae381":"#Plot for Age\nplt.figure(figsize=(15,15))\nsns.countplot(data=dataset, x='Age',palette='gist_rainbow_r') ","0b8c910a":"#Plot for Gender\nplt.figure(figsize=(8,8))\ndataset.Gender.value_counts().plot(kind='pie', autopct='%.2f%%', shadow=True,\n                              explode=(0,0.04))\nplt.legend()","e9984724":"#Plot for Income\nplt.figure(figsize=(20,7))\nsns.countplot(dataset['Annual Income (k$)'], data=dataset,palette='gist_stern')\nplt.title('Distribution of Anuual Income')","d78cd88c":"_,(ax0, ax1) = plt.subplots(1, 2, figsize=(25, 10))\n#plot for Age distribution\nsns.histplot(data=dataset, x='Age', hue='Gender', binwidth=9, multiple='stack', ax=ax0,palette='Pastel1').set_title('Age ditribution')\n#plot for Income distribution\nsns.histplot(data=dataset, x='Annual Income (k$)', hue='Gender', binwidth=11, multiple='stack', ax=ax1,palette='Dark2').set_title('Income distribution') \nplt.show()","7a5cfdfd":"#Implot\nsns.lmplot(data=dataset,x='Spending Score (1-100)', y='Age', hue='Gender')","d241ad69":"#Volin Plot\nplt.figure(figsize=(25,8))\nax = sns.violinplot(x=\"Age\", y=\"Annual Income (k$)\", hue=\"Gender\",data=dataset, palette=\"afmhot\", split=True,scale=\"count\", inner=\"quartile\")","dd228300":"X = dataset.iloc[:, [3, 4]].values\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++',max_iter = 500, n_init = 15)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss, marker = 'o')\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.grid()\nplt.show()","37209c7e":"kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)","0c3a6a12":"plt.figure(figsize=(8,8))\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.grid()\nplt.show()","eee94d21":"import scipy.cluster.hierarchy as sch\nplt.figure(figsize=(8,8))\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()","af97ee62":"from sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","0b7089b1":"plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","e9ca8ad4":"> Avg. age of Customer is 38.\n\n> Customer that visits the mall is having the age b\/w 18 to 70.\n\n> Having the Avg. annual income as $60k.","103d614e":"# Visualising the clusters","dac5a4d5":"# Visualising the clusters","a69c8c25":"**Let's look at the spending scores according to ages**","bc39dbbe":"**Let us look Income Distribution...**","b5ae9f0f":"# K Means Clustering","95379b09":"# Import Dataset","7d35ccb8":"# Heirarical Clustering","87687f48":"# Training the Hierarchical Clustering model on the dataset","f7283546":"> From above we can see the elbow point is at k=5 ,after which the curve almost become linear. This shows that we can define customer in 5 different categories.","74dfb3d6":"> Most of the customer were have age between 28-30, we can also look at the histogram for a better conclusion over the group of ages.\n\n","be39bc49":"# Using the dendrogram to find the optimal number of clusters","ed34fc88":"> At the teenage , the mens were having more annual income but as the age increases the annual income of women increases , and again at the later ages above 55 the annual income of mens are more.","5a141371":"> There is a linear relation between Spending Score and Age.\n\n> Young customers tend to have more spending score and spending score decreases when age goes up. ","eef52ead":"> No. of females > No. of males.\n\n> Females are 12% more than Male.\n\n> Female visits the mall most of the time.","9d9a147c":"# Elbow method\n> We find the inertia for different values of clusters. Inertia is the sum of squared distances of samples to their closest cluster center and we plot a curve for inertia vs number of cluster, and we chose k at the \u201celbow\u201d point from the curve i.e. the point after which the inertia start decreasing in a linear fashion.","d73f0b49":"> 20-30 & 30-40 are the most common age group customers.\n\n> The biggest cusomer age group is 30 year-old customers and those are mostly women.\n\n> Most of customers earn between \\$50k - \\$80k.\n\n> Very few people earns more than $120k.","365759d2":"# Import Libraries","d07b56c3":"**Drawback of K-means:**\n\n> Difficult to predict K-Value.\n\n> With global cluster, it didn't work well.\n\n> Different initial partitions can result in different final clusters.\n\n> To address these problem we use Heirarical clustering.","c3b5001f":"**We can compare their income ranges using histgrams.**","254094e8":"**the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible.The \u2018means\u2019 in the K-means refers to averaging of the data,that is finding the centroid.**\n![](https:\/\/i.ibb.co\/xhJXtBD\/Kmeans-animation.gif)","e514c5c5":"# EDA - Exploratory Data Analysis","dcc2d00e":"**Let's compare their annual income according to gender for different ages.**","4e3d5232":"# Training the K-Means model on the dataset","d9e1c508":"**In this type of clustering we do not define initial random clusters,instead we find the pair of cluster according to the points distances and group them, we this till all the points are grouped, thus its an bottom up approach.It\u2019s also known as AGNES (Agglomerative Nesting).**\n![](https:\/\/i.ibb.co\/hMdwwvW\/hc.gif)","070bc5fa":"> The customers that are having the salary of  54(k)and 78(K), visits the mall most of time","59bdb2f1":"# Conclusion\n> Avg of the customer where from age group of 38 and all kind of cutomers where their having income range from 15-137($k). \n\n> Most of the customer were women , so we need to look after the products that womens mostly focuses on.\n\n> Most of the cutomer where having average income between \\$50k - \\$80k , these are some of the special customers for marketer because they might give more profit.\n\n> People with annual less than 25k and greater the 70k $ shows more spending scores , marketers need to make another strategies for them as they most regular persons.\n\n> People having age lesser than 30 have the avg spending score higher than income score while it got decrease the age increases ,this shows that they are saving or not spending much as compared to their income.","14324f14":"                       \ud83d\ude42THANK YOU FOR SEEING THIS NOTEBOOK\ud83d\ude42","850266ee":"**Let's look how many of them are male and female...**"}}