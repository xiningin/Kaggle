{"cell_type":{"3b9706b1":"code","fc4f234a":"code","c7f6e22a":"code","3c883962":"code","f08ebbbd":"code","8d90add5":"code","e6b9f57d":"code","1026a2d2":"code","ea5603e4":"code","c2b939c1":"code","3122acf6":"code","b86d057f":"code","9ccbaa1b":"code","0a12fdc2":"code","8f259d24":"code","db11a9d7":"markdown","7b44fdc6":"markdown","72fc1482":"markdown","681a87b5":"markdown","3130057e":"markdown","ca419886":"markdown"},"source":{"3b9706b1":"!pip install ipython-autotime\n%load_ext autotime","fc4f234a":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input,Dense,Conv2D,MaxPooling2D,UpSampling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop","c7f6e22a":"def load_data(no_of_images):\n    \n    img_size = (128,128)\n    imgs_source = []\n    imgs_target = []\n    \n    dir_source = \"..\/input\/xray-bone-shadow-supression\/augmented\/augmented\/source\"\n    dir_target = \"..\/input\/xray-bone-shadow-supression\/augmented\/augmented\/target\"\n    \n    i = 0\n    for _, _, filenames in os.walk('\/kaggle\/input\/xray-bone-shadow-supression\/augmented\/augmented\/source\/'):\n        for filename in filenames:\n            i = i+1\n            if(i > no_of_images):\n                break\n            img_source = cv2.imread(os.path.join(dir_source,filename),cv2.IMREAD_GRAYSCALE)\n            img_target = cv2.imread(os.path.join(dir_target, filename),cv2.IMREAD_GRAYSCALE)\n            # resizing images\n            img_source = cv2.resize(img_source,img_size)\n            img_target = cv2.resize(img_target,img_size)\n            # normalizing images\n            img_source = np.array(img_source)\/255\n            img_target = np.array(img_target)\/255\n            \n            imgs_source.append(img_source)\n            imgs_target.append(img_target)\n    return imgs_source, imgs_target","3c883962":"source, target = load_data(1000)","f08ebbbd":"plt.figure(figsize=(15,10))\n\nfor i in range(3):\n    ax = plt.subplot(2, 3, i+1)\n    plt.imshow(source[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.title('Source')\n\n    ax = plt.subplot(2, 3, i+4)\n    plt.imshow(target[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.title('Target')\nplt.show()","8d90add5":"img_rows = 128\nimg_cols = 128\nimg_channels = 1\nimg_shape = (img_rows, img_cols, img_channels)\n\nsource = np.array(source).reshape(-1, img_rows, img_cols, img_channels)\ntarget = np.array(target).reshape(-1, img_rows, img_cols, img_channels)\n\nsource_train, source_test, target_train, target_test = train_test_split(source, target,\n                                                                        test_size=0.20,\n                                                                        random_state=1)","e6b9f57d":"print(source_train.shape, source_test.shape, target_train.shape, target_test.shape)","1026a2d2":"def autoencoder(input_img):\n    #encoder\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) \n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) \n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) \n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) \n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) \n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n\n\n    #decoder\n    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) \n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    up1 = UpSampling2D((2,2))(conv4) \n    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) \n    conv5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    up2 = UpSampling2D((2,2))(conv5) \n    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) \n    return decoded","ea5603e4":"input_img = Input(shape = img_shape)\nautoencoder = Model(input_img, autoencoder(input_img))\nautoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())","c2b939c1":"autoencoder.summary()","3122acf6":"n_epoch = 200\nn_batch = 128\nautoencoder_train = autoencoder.fit(source_train, target_train,\n                                    epochs = n_epoch,\n                                    batch_size = n_batch,\n                                    verbose = 0,\n                                    validation_data = (source_test, target_test))","b86d057f":"interval_epochs = [0, 49,99,149,199]\nfor e in interval_epochs:\n    print(\"epoch = {}\\tLoss = {:.5f}\\tValidation_Loss = {:.5f}\".format(e+1,autoencoder_train.history['loss'][e],autoencoder_train.history['val_loss'][e]))","9ccbaa1b":"n = np.arange(0, n_epoch)\nplt.figure()\nplt.plot(n, autoencoder_train.history['loss'], label = 'Training Loss')\nplt.plot(n, autoencoder_train.history['val_loss'], label = 'Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()","0a12fdc2":"pred = autoencoder.predict(source_test)","8f259d24":"plt.figure(figsize=(15,10))\n\nfor i in range(5):\n    ax = plt.subplot(3, 5, i+1)\n    plt.imshow(source_test[i].reshape(128,128))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.title('Source_Test')\n\n    ax = plt.subplot(3, 5, i+6)\n    plt.imshow(pred[i].reshape(128,128))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.title('Predicted')\n    \n    ax = plt.subplot(3, 5, i+11)\n    plt.imshow(target_test[i].reshape(128,128))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.title('Target')\nplt.show()","db11a9d7":"Now, let's plot the train and validation losses to visualise the model performance.","7b44fdc6":"# Defining the Autoencoder Model","72fc1482":"Reshaping and Spliting the Data ","681a87b5":"Let's see some of the source images and their corresponding targets.","3130057e":"# Loading data","ca419886":"# Predicting on Validation data"}}