{"cell_type":{"63ef078e":"code","6c32bdc2":"code","0a8b9e68":"code","801eb646":"code","4d70c475":"code","e676f212":"code","e507a139":"code","ed583185":"code","14dc1196":"code","3e948bfe":"code","987e0643":"code","1ad69b07":"code","b4178e17":"code","c7df4212":"code","71a47e75":"code","9fd82710":"code","fdb0809d":"code","83896042":"code","27e74ace":"code","16409b98":"code","9d05a437":"code","1b3abbef":"markdown","59ca8a70":"markdown","d2172d36":"markdown","7eccc6da":"markdown","110c4df3":"markdown","57296f40":"markdown","b6a0fb91":"markdown","56451abe":"markdown","33b1ec4d":"markdown","88e151c4":"markdown","d96a7b57":"markdown","a562e0ec":"markdown","6faf4040":"markdown","26c1a931":"markdown","2cf60e86":"markdown","68ff095a":"markdown","fd1cb06f":"markdown","6f82c6c6":"markdown","c2b3b48b":"markdown","743d0469":"markdown"},"source":{"63ef078e":"!pip install face_recognition","6c32bdc2":"# importing all the important libraries\nimport numpy as np \nimport pandas as pd\nimport PIL.Image\nimport PIL.ImageDraw\nimport face_recognition\nimport matplotlib.pyplot as plt","0a8b9e68":"# adding the image\nmanyPeople_img = face_recognition.load_image_file(\"..\/input\/facerecognition\/people.jpg\")\n\nplt.imshow(manyPeople_img)\nplt.axis('off')\nplt.show()\n","801eb646":"# the image is loaded as an array representing the pixels value in numpy array, printing the shape of array \nmanyPeople_img.shape","4d70c475":"# finding location of each face from the array, by default hog is used. We can choose cnn to\nfaceLocMany = face_recognition.face_locations(manyPeople_img, model=\"hog\")\nprint(\"Number of faces: \",len(faceLocMany))\nprint(\"\\nPosition of each face (top, right, bottom, left) : \\n\", faceLocMany)","e676f212":"# creates an image memory from numpy array\nmanyPeople_pil = PIL.Image.fromarray(manyPeople_img)","e507a139":"# drawing a ellipse around the faces in the image \nfor faceLoc in faceLocMany:\n\n    top, right, bottom, left = faceLoc   \n    \n    # creating an instance of Draw, to draw on the image\n    draw = PIL.ImageDraw.Draw(manyPeople_pil)\n    draw.ellipse([(left, top), (right, bottom)], outline=\"red\", width=3)\n\nplt.imshow(manyPeople_pil)\nplt.axis('off')\nplt.show()","ed583185":"# single person image\npersonImage = face_recognition.load_image_file(\"..\/input\/facerecognition\/person.jpg\")\n\npersonFaceLoc = face_recognition.face_locations(personImage)\n\nprint(\"Face location:\", personFaceLoc)\n\nperson_pil = PIL.Image.fromarray(personImage)\n\ntop, right, bottom, left = list(personFaceLoc[0])\n\n# croping the face area\nhead = person_pil.crop((left, top, right, bottom))\n\nplt.imshow(head)\nplt.axis('off')\nplt.show()","14dc1196":"# finally pasting it on top of group image\nmanyPeopleCopy_pil = manyPeople_pil.copy()\nfor faceLoc in faceLocMany:\n\n    top, right, bottom, left = faceLoc   \n    \n    head = head.resize((abs(right-left),abs(top-bottom)), PIL.Image.ANTIALIAS)\n    manyPeopleCopy_pil.paste(head, [left, top])\n\nplt.imshow(manyPeopleCopy_pil)\nplt.axis('off')\nplt.show()","3e948bfe":"# finding the landmarks for single person\nfaceLandmark_list = face_recognition.face_landmarks(personImage)\nfaceLandmark_list[0].keys()","987e0643":"# testing it for multiple people\ntest_faceLandmark_list = face_recognition.face_landmarks(manyPeople_img)\nprint(\"Number of faces\" , len(test_faceLandmark_list))\nprint(\"Landmarks for each face\", test_faceLandmark_list[0].keys())\n","1ad69b07":"# creating a copy first so that we can use the original again\npersonCopy_pil = person_pil.copy()\n\nfor faceLandmark in faceLandmark_list:\n\n    # looping over each facial feature\n    for name, list_of_points in faceLandmark.items():\n\n        # printing the location of each facial feature\n        print(\"The {} in this face has the following points: {}\".format(name, list_of_points))\n\n        # drawing a line on each facial feature\n        draw = PIL.ImageDraw.Draw(personCopy_pil)\n        draw.line(list_of_points, fill=\"red\", width=2)\n\nplt.imshow(personCopy_pil)\nplt.axis('off')\nplt.show()\n","b4178e17":"# eyebrow co-ordinates\nleft_eyebrow =  faceLandmark_list[0].get('left_eyebrow')\nright_eyebrow = faceLandmark_list[0].get('right_eyebrow')\nprint(\"Left eyebrow: \", left_eyebrow)\nprint(\"\\nRight eyebrow: \", right_eyebrow)","c7df4212":"# finding the extreme points\nleftmost_point = left_eyebrow[0]\nrightmost_point = right_eyebrow[len(right_eyebrow)-1]\n\nprint(\"Leftmost point: \", leftmost_point , \" and Righmost point: \", rightmost_point)","71a47e75":"# loading the person image and goggles image\n# ( we have first load the person's image as an array, thus we need to load it again)\ngoggleImage = PIL.Image.open(\"..\/input\/facerecognition\/transparent_goggles.png\")\nimage_person = PIL.Image.open(\"..\/input\/facerecognition\/person.jpg\")\n\n# resize the goggle's image in accordance with the eyebrows extreme point\ngoggleImage = goggleImage.resize((abs(rightmost_point[0]-leftmost_point[0]),int(0.5*abs(rightmost_point[0]-leftmost_point[0]))), PIL.Image.ANTIALIAS)\nfinal1 = PIL.Image.new(\"RGBA\", image_person.size)\n\n# finally pasting the goggles on top of the face\nfinal1.paste(image_person, (0,0))\nfinal1.paste(goggleImage, (leftmost_point[0],leftmost_point[1]), goggleImage)\n\nplt.imshow(final1)\nplt.axis('off')\nplt.show()","9fd82710":"# we can see that image_person is an image not a numpy array like before\nimage_person","fdb0809d":"# finding face encodings\npersonEncoding = face_recognition.face_encodings(personImage)[0]\nprint(personEncoding)","83896042":"unknownPerson1 = face_recognition.load_image_file(\"..\/input\/facerecognition\/unknown_1.jpg\")\nunknownPerson2 = face_recognition.load_image_file(\"..\/input\/facerecognition\/unknown_8.jpg\")\nunknownPerson3 = face_recognition.load_image_file(\"..\/input\/facerecognition\/unknown_6.jpg\")\nunknownPerson4 = face_recognition.load_image_file(\"..\/input\/facerecognition\/person_1.jpg\")\n\nfig,axs = plt.subplots(2,2, figsize = [10,10])\n\naxs[0][0].imshow(unknownPerson1)\naxs[0][0].set_title('Unknown Person 1')\n\naxs[0][1].imshow(unknownPerson2)\naxs[0][1].set_title('Unknown Person 2')\n\naxs[1][0].imshow(unknownPerson3)\naxs[1][0].set_title('Unknown Person 3')\n\naxs[1][1].imshow(unknownPerson4)\naxs[1][1].set_title('Unknown Person 4')\n\nplt.suptitle(\"Unknown Persons\")\nplt.show()\n","27e74ace":"# creating a list of unknown face encodings\nunknownPersonList = [\n    \n    face_recognition.face_encodings(unknownPerson1)[0],\n    face_recognition.face_encodings(unknownPerson2)[0],\n    face_recognition.face_encodings(unknownPerson3)[0],\n    face_recognition.face_encodings(unknownPerson4)[0]        \n]\n\ndistance=[]\nmatch=[]\n# for each unknown face encoding, comapre it with the single person encoding\nfor (i,unknownPerson) in enumerate(unknownPersonList):\n\n    result = face_recognition.compare_faces( [personEncoding], unknownPerson, tolerance=0.6)[0]\n    print(\"Person\", i, \" is a match? \", result)\n\n    face_distance = face_recognition.face_distance([personEncoding], unknownPerson)[0]\n    print(\"Euclidian distance between faces for person\", int(i)+1 ,\" :\", face_distance)\n    \n    distance.append(face_distance)\n    match.append(result)\n\n    print()\n\nfig,axs = plt.subplots(3,2, figsize = [10,10])\n\nfig.tight_layout(pad = 5.0)\n\nplt.suptitle(\"Comparision of faces\", fontsize = 20)\n\n\naxs[0][0].imshow(personImage)\naxs[0][0].set_title(\"Known person\")\naxs[0][0].axis('off')\n\nfig.delaxes(axs[0][1])\n\naxs[1][0].imshow(unknownPerson1)\naxs[1][0].set_title('1. Is a match: ' + str(match[0]) + '\\n Face euclidean distance: ' + str(\"{:.2f}\".format(distance[0])))\naxs[1][0].axis('off')\n\naxs[1][1].imshow(unknownPerson2)\naxs[1][1].set_title('2. Is a match: ' + str(match[1]) + '\\n Face euclidean distance: ' + str(\"{:.2f}\".format(distance[1])))\naxs[1][1].axis('off')\n\naxs[2][0].imshow(unknownPerson3)\naxs[2][0].set_title('3. Is a match: ' + str(match[2]) + '\\n Face euclidean distance: ' + str(\"{:.2f}\".format(distance[2])))\naxs[2][0].axis('off')\n\naxs[2][1].imshow(unknownPerson4)\naxs[2][1].set_title('4. Is a match: ' + str(match[3]) + '\\n Face euclidean distance: ' + str(\"{:.2f}\".format(distance[3])))\naxs[2][1].axis('off')\n\n\nplt.show()\n","16409b98":"# image containing more than one clear face\ngroupOfUnknown = face_recognition.load_image_file('..\/input\/facerecognition\/unknown_2.jpg')\n\ngroupEncoding = face_recognition.face_encodings(groupOfUnknown)\n\nprint(\"Number of persons: \", len(groupEncoding))\n\nfor (i,encoding) in enumerate(groupEncoding):\n\n    result = face_recognition.compare_faces( [personEncoding], encoding, tolerance=0.6)[0]\n    \n    if(result == True):\n        print(\"Match found\")\n        break\n    \n    \nplt.imshow(groupOfUnknown)\nplt.show()","9d05a437":"low_resolution = face_recognition.load_image_file('..\/input\/facerecognition\/unknown_7.jpg')\n\nencoding = face_recognition.face_encodings(low_resolution)\n\nprint(\"Before : Number of persons: \", len(encoding) , \" due to low resolution\")\n\nfaceLoc = face_recognition.face_locations( low_resolution, number_of_times_to_upsample = 2 )\nencoding = face_recognition.face_encodings(low_resolution, known_face_locations = faceLoc)\n\nprint(\"After : Number of persons: \", len(encoding))\n\nresult = face_recognition.compare_faces( personEncoding, encoding, tolerance=0.6)[0]\nprint(\"Match found ?\", result)\n\nface_distance = face_recognition.face_distance(personEncoding, encoding)[0]\nprint(\"Euclidian distance between faces: \", face_distance)\n    \n    \nplt.imshow(low_resolution)\nplt.show()","1b3abbef":"# Face recognition and comparision \n\nFirst let's install the face_recognition library to find face features","59ca8a70":"## Thank you ##","d2172d36":"So it a match. The single person from the image is same as the person in the middle from the above image.\n\nNext, due to less resolution , the encoding method may not be able to find the face. Thus, we will use the face_location method to find the faces. Higher values of number_of_times_to_upsample finds the smaller faces . In the end, pass the results to encoding method.","7eccc6da":"So the results are accurate.\n\nFor more than 1 person in the image, we have to use a loop.","110c4df3":"## Recognizing faces\n\nLoad the first image. It contains multiple faces for us to recognize","57296f40":"We will use single person image for drawing the landmarks","b6a0fb91":"Finding location of each face from the array, by default hog is used. We can choose cnn too by changing the model parameter\n\n[Source code for face_recognition.api](https:\/\/face-recognition.readthedocs.io\/en\/latest\/_modules\/face_recognition\/api.html)","56451abe":"## Facial features ##\n\nWe have found the face, now let's find the parts of faces like nose, eyebrows , eyes , chin and mouth. Face_landmarks returns a list for each face, and for each face we have a dictionary of landmarks","33b1ec4d":"## References:##\n\nDocumentation:\n\n1. [PIL Image Module](https:\/\/pillow.readthedocs.io\/en\/stable\/reference\/Image.html)\n2. [Source code for face_recognition.api](https:\/\/face-recognition.readthedocs.io\/en\/latest\/_modules\/face_recognition\/api.html)\n\nAll the images are taken from:\n\n1. LinkedIn learning course: [Deep Learning: Face Recognition](https:\/\/www.linkedin.com\/feed\/update\/urn:li:lyndaCourse:628706\/)\n","88e151c4":"Might not be the perfect face swap but good work \ud83d\ude05\ud83d\ude09","d96a7b57":"Our source face is the single person image. We will compare it with 4 unknown faces.","a562e0ec":"Let's put goggles on the person's face, for this we will use the eyebrow coordinates instead of eyes as eyes should come inside the goggles. \n\n*Note*:\nWe have used a google with transparent background for this","6faf4040":"We can compare faces based on 128 face encoding values obtained from the image. These encoding are unique for every face. Calculating the Euclidean distance between these endoings can give us the idea about how similar the faces are. If the result is less than 0.6 then its a match, otherwise not.","26c1a931":"To edit the images or draw on them , we need to convert them to array first.","2cf60e86":"## Making our own swag filter \ud83d\ude0e##","68ff095a":"## Let's create out first very awesome face swap ##\n\nWe will use a single person image, cut out the face from it and paste it on top of the above group image. \n\n*Note: We have to resize the source image face to match the target image face size*","fd1cb06f":"## Face comparision ##","6f82c6c6":"We can test it for group image. The group image contains six people","c2b3b48b":"Finally, drawing an ellipse around the faces, increase the width to clearly see it","743d0469":"So, we can see that the unknown person 2 and 3 are a match. Let's try to get the same results."}}