{"cell_type":{"3fefc936":"code","5128c42a":"code","f978c1e6":"code","4fca6e37":"code","580122ab":"code","ef053276":"code","0cedf885":"code","7296c17c":"code","f7e53f9a":"code","283b26bb":"code","cb421eeb":"code","06e58005":"code","2e7f461b":"code","390a966e":"markdown","7febc021":"markdown"},"source":{"3fefc936":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport datetime\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","5128c42a":"# time_load_data = datetime.datetime.now()\ndigits = pd.read_csv('..\/input\/train.csv')\nx_sub = pd.read_csv('..\/input\/test.csv').values.reshape(-1,28,28,1)\/255.\nx = digits.iloc[:,1:].values.reshape(-1,28,28,1)\/255.\ny = digits.iloc[:,0].values\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,shuffle=True)","f978c1e6":"# def leaky_relu(z,alpha=0.001):\n#     \"\"\"\n#     relu sometimes will return zero gradient and make certain neruon \"dead\". Therefore I make some adjustment at the zero size.\n#     Bing Xu, Naiyan Wang, Tianqi Chen, Mu Li(2015), Empirical Evaluation of Rectified Activations in Convolutional Network, https:\/\/arxiv.org\/pdf\/1505.00853.pdf\n#     \"\"\"\n#     return tf.maximum(z,z*alpha,name='leaky_relu')","4fca6e37":"# Feel free to tune this argument\nLEARNING_RATE = 0.0001\nN_KERNEL = [32,16]\nN_EPOCHS = 1000\nBATCH_SIZE = 1000\nEARLY_STOPING = True","580122ab":"# time_start_building_graph = datetime.datetime.now()\ntf.reset_default_graph()\nwith tf.device('\/device:GPU:0'):\n    x = tf.placeholder(tf.float32,[None,28,28,1],name='x')\n    y = tf.placeholder(tf.int64,[None],name='y')\n\n    bn = tf.layers.batch_normalization(x)\n    c1 = tf.layers.conv2d(bn,N_KERNEL[0],kernel_size=5,strides=1,padding='SAME',name='1_convolution_layer')\n    p2 = tf.layers.max_pooling2d(c1,pool_size=2,strides=2,padding='SAME',name='2_max_pooling')\n    \n    c3 = tf.layers.conv2d(p2,N_KERNEL[1],10,1,padding='SAME',name='3_convolution_layer')\n    p4 = tf.layers.max_pooling2d(c3,pool_size=3,strides=2,padding='SAME',name='4_max_pooling')\n    \n    p4_shape = p4.get_shape().as_list()\n    n_nodes_fc = p4_shape[1]*p4_shape[2]*p4_shape[3]#7*7*16\n    flatten = tf.reshape(p4,[-1,n_nodes_fc])\n    \n    f5 = tf.layers.dense(flatten,84,kernel_initializer=tf.keras.initializers.he_normal(),activation=tf.nn.leaky_relu,name='5_fully_connected')\n    dropout1 = tf.layers.dropout(f5,name='drop_out_1')\n    \n    f6 = tf.layers.dense(dropout1,84,kernel_initializer=tf.keras.initializers.he_normal(),activation=tf.nn.leaky_relu,name='6_fully_connected')\n    dropout2 = tf.layers.dropout(f6,name='drop_out_2')\n    \n    logits = tf.layers.dense(dropout2,10,name='logits')\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits),name='Entropy')\n    training_op = tf.train.AdamOptimizer(LEARNING_RATE,name='AdamOptimizer').minimize(loss)\n\n    y_pred = tf.argmax(logits,1,name='Prediction')\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(y,y_pred),tf.float32),name='accuracy')","ef053276":"from IPython.display import clear_output, Image, display, HTML\n\ndef strip_consts(graph_def, max_const_size=32):\n    \"\"\"Strip large constant values from graph_def.\"\"\"\n    strip_def = tf.GraphDef()\n    for n0 in graph_def.node:\n        n = strip_def.node.add() \n        n.MergeFrom(n0)\n        if n.op == 'Const':\n            tensor = n.attr['value'].tensor\n            size = len(tensor.tensor_content)\n            if size > max_const_size:\n                tensor.tensor_content = bytes(b\"<stripped %d bytes>\" % size)\n    return strip_def\n\ndef show_graph(graph_def, max_const_size=32):\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    if hasattr(graph_def, 'as_graph_def'):\n        graph_def = graph_def.as_graph_def()\n    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n    code = \"\"\"\n        <script>\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        <\/script>\n        <link rel=\"import\" href=\"https:\/\/tensorboard.appspot.com\/tf-graph-basic.build.html\" onload=load()>\n        <div style=\"height:600px\">\n          <tf-graph-basic id=\"{id}\"><\/tf-graph-basic>\n        <\/div>\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n\n    iframe = \"\"\"\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"><\/iframe>\n    \"\"\".format(code.replace('\"', '&quot;'))\n    display(HTML(iframe))\nshow_graph(tf.get_default_graph())","0cedf885":"# time_start_training = datetime.datetime.now()\n\nwith tf.name_scope('batch_iterator'):\n    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(buffer_size=1000).repeat(N_EPOCHS).batch(BATCH_SIZE)\n    batch_iterator = dataset.make_one_shot_iterator()\n    next_batch = batch_iterator.get_next()\n    \ntrain_loss = []\ntrain_accuracy = []\ntest_accuracy = []\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nwith tf.Session(config=config) as sess:\n    tf.global_variables_initializer().run()\n    for iteration in range(N_EPOCHS*len(x_train)\/\/BATCH_SIZE):\n        try:\n            x_batch,y_batch = sess.run(next_batch)\n            sess.run(training_op,feed_dict={x: x_batch, y: y_batch})\n            train_loss.append(loss.eval(feed_dict={x: x_batch, y: y_batch}))\n            # each epoch will take about (len(x_train)\/BATCH_SIZE) to complete\n            if iteration % ((len(x_train)\/\/BATCH_SIZE)*10) == 0:\n                __train_accuracy =accuracy.eval(feed_dict={x: x_train, y: y_train})\n                __test_accuracy = accuracy.eval(feed_dict={x:x_test,y:y_test})\n                train_accuracy.append(__train_accuracy)\n                test_accuracy.append(__test_accuracy)\n                print(f'In epoch {iteration\/\/((len(x_train)\/\/BATCH_SIZE))} Train accuracy: {__train_accuracy},     Test accuracy: {__test_accuracy}')\n                if EARLY_STOPING:\n                    if __train_accuracy > 0.999995:\n                        print('Accuracy on training set {} has greater than 99.9995%. Early stopping to avoid overfitting.'.format(__train_accuracy))\n                        break\n        except tf.errors.OutOfRangeError:\n            pass\n#     time_start_predicting = datetime.datetime.now()\n    y_test_pred=y_pred.eval(feed_dict={x:x_test})\n#     time_finish_predicting = datetime.datetime.now()\n    y_sub=y_pred.eval(feed_dict={x:x_sub})","7296c17c":"# time_of_steps = [time_load_data,time_start_building_graph,time_start_training,time_start_predicting,time_finish_predicting]\n# time_consume_of_steps = []\n# for i in range(len(time_of_steps)):\n#     if i == 0:\n#         time_consume_of_steps.append(0)\n#     else:\n#         time_consume_of_steps.append(time_of_steps[i]-time_of_steps[i-1])\n# pd.DataFrame([time_of_steps,time_consume_of_steps])","f7e53f9a":"print('Accuracy on testing set:',accuracy_score(y_test,y_test_pred))","283b26bb":"plt.figure(figsize=(20,5))\n\nplt.subplot(1,2,1)\nplt.title('Training loss:Cross Entropy')\nplt.plot(train_loss)\nplt.xlabel('Iterations')\nplt.ylabel('Cross Entropy')\nplt.xlim(0,)\nplt.ylim(0,1.5)\n\nplt.subplot(1,2,2)\nplt.title('Training accuracy')\nplt.plot([i*10 for i in range(len(train_accuracy))],train_accuracy,label= 'Training set')\nplt.plot([i*10 for i in range(len(train_accuracy))],test_accuracy,label= 'Testing set')\nplt.legend(loc='upper left')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.xlim(0,)\n_=plt.ylim(0.1,)\n","cb421eeb":"random_idx = np.random.choice([i for i in range(len(y_sub))],9)\nprint([y_sub[i] for i in random_idx])\nplt.figure(figsize=(10,10))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(x_sub.reshape(-1,28,28)[random_idx[i]],cmap='gray')","06e58005":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission['Label'] = y_sub\nsubmission.to_csv(f'..\/working\/submission{datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")}.csv',index=False)","2e7f461b":"# To be continued: comparing to SVM\n# from sklearn.svm import SVC\n# svm = SVC()\n# svm.fit(x_train.reshape(-1,784),y_train.reshape(-1))\n","390a966e":"The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) evaluates algorithms for object detection and image classification at large scale. One high level motivation is to allow researchers to compare progress in detection across a wider variety of objects -- taking advantage of the quite expensive labeling effort. The winner of each year is shown below.\n\n| Year | Model     | Top 5 Error Rate(%) |\n|------|-----------|---------------------|\n| [2011](http:\/\/image-net.org\/challenges\/LSVRC\/2011\/results) |  XRCE(SVM based)| 25.8(Classification)   |\n| [2012](http:\/\/image-net.org\/challenges\/LSVRC\/2012\/results.html) | [AlexNet(SuperVision)](https:\/\/papers.nips.cc\/paper\/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)   | 15.3(\tError (5 guesses))                |\n| [2013](http:\/\/www.image-net.org\/challenges\/LSVRC\/2013\/results.php) | [ZF Net](https:\/\/cs.nyu.edu\/~fergus\/papers\/zeilerECCV2014.pdf)    | 14.8                |\n| [2014](http:\/\/image-net.org\/challenges\/LSVRC\/2014\/results) | GoogLeNet |  6.67               |\n| [2015](http:\/\/image-net.org\/challenges\/LSVRC\/2015\/results) | [ResNet(MSRA)](https:\/\/arxiv.org\/abs\/1512.03385)    |  3.57               |\n| [2016](http:\/\/image-net.org\/challenges\/LSVRC\/2016\/results) | [Ensemble 5(Trimps-Soushen)](https:\/\/arxiv.org\/abs\/1602.07261)    | \t2.99               |\n| [2017](http:\/\/image-net.org\/challenges\/LSVRC\/2017\/) | [NUS-Qihoo_DPNs (CLS-LOC](https:\/\/arxiv.org\/abs\/1611.05431))    |  2.71               |\n\n\n\n\nExcept 2011 XRCE is SVM based model, CNN-based architecture became dominant from 2012 AlexNet.  We will implement [LeNet](http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-01a.pdf) which is earliest CNN architecture proposed by Yann Lecun in 1998.  We will use MNIST for demonstrate digit recognition, and I will make some adjustment to enhance performance.\n\nBy the way,[VGG](https:\/\/arxiv.org\/abs\/1409.1556) scored 7.3% in 2014. VGG-16, VGG-19 are also famous CNN architecture. \n\nAnother concept \"Inception\" is a variation of CNN for better way to stacking layers.\n\n[GoogLeNet Inception v1: Going Deeper with Convolutions\n](https:\/\/arxiv.org\/abs\/1409.4842)\n\n[GoogLeNet Inception v2: Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https:\/\/arxiv.org\/abs\/1502.03167)\n\n[GoogLeNet Inception v3:Rethinking the Inception Architecture for Computer Vision\n](https:\/\/arxiv.org\/abs\/1512.00567)\n\n[GoogLeNet Inception v4:Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\n](https:\/\/arxiv.org\/abs\/1602.07261)\n\n\n","7febc021":"ReLU sometimes will return zero gradient and make certain neruon \"dead\".  Therefore I make some adjustment at the zero side. This is also known as leaky-ReLU\n\n[Bing Xu, Naiyan Wang, Tianqi Chen, Mu Li(2015), Empirical Evaluation of Rectified Activations in Convolutional Network](https:\/\/arxiv.org\/pdf\/1505.00853.pdf), \n\nInitialization matters, it helps model learn faster and decrease the chance of gradient explosion,different activation function have different initialization suited for training. Some common initializations are He initialization for ReLU, Xavier(Glorot) initialization for tanh. I use He initialization.\n\n[Xavier Glorot, Yoshua Bengio(2010), Understanding the difficulty of training deep feedforward neural networks](http:\/\/proceedings.mlr.press\/v9\/glorot10a\/glorot10a.pdf), \n\n[ Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun(2015) ,Delving Deep into Rectifiers:Surpassing Human-Level Performance on ImageNet Classification](https:\/\/arxiv.org\/pdf\/1502.01852.pdf)\n\nReLU(Left) vs leaky-ReLU(Right)\n![leaky-relu](https:\/\/imgur.com\/u2c177w.jpg)"}}