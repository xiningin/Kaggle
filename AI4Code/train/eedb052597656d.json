{"cell_type":{"ea2e18e0":"code","36210d22":"code","890cefd2":"code","8e9e275e":"code","eab3ab99":"code","0df84d74":"code","5e56d8a0":"code","f5b46f6f":"code","71720cbe":"code","1d0fb8ac":"code","27d7741e":"code","32c9712d":"code","46abcd8c":"code","770314d6":"code","1f4ac049":"code","3a4b71e3":"code","b53deed9":"code","3359e2c8":"code","060b9850":"code","69649734":"code","4e1b2e14":"code","1702465e":"code","40031b37":"code","c6322088":"code","445c45e9":"code","83537c92":"code","0d872cca":"code","925e7d2e":"code","caee9489":"code","e720eb98":"code","aa5eb161":"code","c1bb9e3c":"code","9454a013":"code","3ff4767a":"code","c2104075":"code","8fd3e17e":"code","979abc35":"code","40b66057":"code","480850fe":"code","b0d373b6":"markdown","3ccddcc9":"markdown","7c395590":"markdown"},"source":{"ea2e18e0":"# IMPORT MODULES\n# TURN ON the GPU !\n\nimport os\nfrom operator import itemgetter    \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nget_ipython().magic(u'matplotlib inline')\nplt.style.use('ggplot')\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Imputer\nfrom pandas.tools.plotting import scatter_matrix\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\nfrom sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n#from sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\nfrom sklearn.utils.fixes import signature\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom mlxtend.plotting import plot_learning_curves\nfrom mlxtend.preprocessing import shuffle_arrays_unison\n\nimport tensorflow as tf\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras.utils import to_categorical\n\nprint(os.getcwd())\nprint(\"Modules imported \\n\")\nimport os\nprint(os.listdir(\"..\/input\/\"))","36210d22":"print(os.listdir(\"..\/input\/\"))","890cefd2":"# Load MIMIC2 data \n\ndata = pd.read_csv('..\/input\/mimic01\/LOS.csv')\nprint(\"With id\", data.shape)\ndata_full = data.drop('hadm_id', 1)\nprint(\"No id\",data_full.shape)","8e9e275e":"print(data_full.shape)\ndata_full.info()\ndata_full.describe()","eab3ab99":"data_full.head(10)","0df84d74":"# Label = LOS\n\ny = data_full['LOSgroupNum']\nX = data_full.drop('LOSgroupNum', 1)\nX = X.drop('LOSdays', 1)\nX = X.drop('ExpiredHospital', 1)\n##X = X.drop('AdmitDiagnosis', 1)\nX = X.drop('AdmitProcedure', 1)\nX = X.drop('marital_status', 1)\n##X = X.drop('ethnicity', 1)\nX = X.drop('religion', 1)\nX = X.drop('insurance', 1)\n\nprint(\"y - Labels\", y.shape)\nprint(\"X - No Label No id \", X.shape)\nprint(X.columns)","5e56d8a0":"data_full.groupby('LOSgroupNum').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_type').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_location').size().plot.bar()\nplt.show()\ndata_full.groupby('AdmitDiagnosis').size().plot.bar()\nplt.show()","f5b46f6f":"# Check that all X columns have no missing values\nX.info()\nX.describe()","71720cbe":"# MAP Text to Numerical Data\n# Use one-hot-encoding to convert categorical features to numerical\n\nprint(X.shape)\ncategorical_columns = [\n                    'gender',                     \n                    'admit_type',\n                    'admit_location',\n                    'AdmitDiagnosis'\n                      ]\n\nfor col in categorical_columns:\n    #if the original column is present replace it with a one-hot\n    if col in X.columns:\n        one_hot_encoded = pd.get_dummies(X[col])\n        X = X.drop(col, axis=1)\n        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n        \nprint(X.shape)","1d0fb8ac":"\nprint(data_full.shape)\nprint(X.shape)\n#XnotNorm = np.array(X.copy())\nXnotNorm = X.copy()\nprint('XnotNorm ', XnotNorm.shape)\n\nynotNorm = y.copy()\nprint('ynotNorm ', ynotNorm.shape)","27d7741e":"# Normalize X\n\nx = XnotNorm.values #returns a numpy array\nscaler = preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(x)\nXNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\n#print(XNorm)\n#print(y)\nprint('X normalized')","32c9712d":"# SPLIT into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=7)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","46abcd8c":"# Test Models and evaluation metric\nseed = 42\nscoring = 'accuracy' \n\n# Spot Check Algorithms\nMymodels = []\n#Mymodels.append(('LogReg', LogisticRegression()))\nMymodels.append(('RandomForestClassifier', RandomForestClassifier()))\nMymodels.append(('SGDclassifier', SGDClassifier()))\n#Mymodels.append(('KNearestNeighbors', KNeighborsClassifier()))\nMymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n#Mymodels.append(('GaussianNB', GaussianNB()))\n#Mymodels.append(('SVM', SVC()))\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in Mymodels:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg) ","770314d6":"# Optimize hyper params for one model\n\nmodel = RandomForestClassifier()\n\nparam_grid = [{},]\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring)\ngrid_search.fit(XNorm, y)\n\nprint(grid_search.best_estimator_)","1f4ac049":"model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","3a4b71e3":"# FEATURE IMPORTANCE - NORMALIZED - last model\n\ntrainFinalFI = XNorm\nyFinalFI = y\n\nmodel.fit(trainFinalFI,yFinalFI)\n\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model[FI_model[\"Feature Importance\"] > 0.005].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\nplt.xticks(rotation=90)\nplt.xticks(rotation=90)\nplt.show()","b53deed9":"# List of important features for model\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model=FI_model.sort_values('Feature Importance', ascending = False)\nprint(FI_model[FI_model[\"Feature Importance\"] > 0.001])","3359e2c8":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Error\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = 1-np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = 1-np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","060b9850":"# LEARNING CURVES Train \/ Validation\n\ntitle = \"Learning Curves \"\ncv = ShuffleSplit(n_splits=7, test_size=0.2)\nplot_learning_curve(model, title, X_train, y_train, cv=cv, n_jobs=4)\n#plot_learning_curve(model, title, XNorm, y, ylim=(0.01, 0.99), cv=cv, n_jobs=4)","69649734":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","4e1b2e14":"# Model FINAL fit and evaluation on test\n\nmodel.fit(X_train, y_train)\nfinal_predictions = model.predict(X_test)\n\n#final_acc = accuracy(y_test, final_predictions)\n# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, final_predictions)\nprint('conf_mx ready')","1702465e":"def plot_confusion_matrix(cm,target_names,title='Confusion Matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n","40031b37":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","c6322088":"# Confusion matrix and all metrics - for EACH class separately\n\nNumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(conf_mx)\n    TPz = conf_mx[z,z]\n    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    #FPz = np.sum(conf_mx[z], axis=-1) \n    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)\/(TPz+TNz+FPz+FNz)\n    recall = TPz\/(TPz+FNz)\n    precision = TPz\/(TPz+FPz)\n    f1score = 2*recall*precision\/(recall+precision)\n    #roc_auc = auc(FPz, TPz)\n    \n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\n    print ('TN: ', TN)\n    print ('FP: ', FP)\n    print ('FN: ', FN)\n    print ('TP: ', TP)\n    print('_'*40) \n","445c45e9":"# Confusion Matrix for the WHOLE MODEL - ALL Classes\n\nprint('Confusion Matix for ALL Classes')\n\nTP = TP \/ NumClasses\nTN = TN \/ NumClasses\nFP = FP \/ NumClasses\nFN = FN \/ NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","83537c92":"def multiclass_roc_auc_score(y_test, final_predictions, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(final_predictions)\n\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('AUC ROC ',multiclass_roc_auc_score(y_test, final_predictions))","0d872cca":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)\n\nprint(y_train)\nprint(y_test)\n","925e7d2e":"# Transfer data to NN format\n\nx_val = X_test\npartial_x_train = X_train\ny_val = y_test\npartial_y_train = y_train\n\nprint(\"partial_x_train \", partial_x_train.shape)\nprint(\"partial_y_train \", partial_y_train.shape)\n\nprint(\"x_val \", x_val.shape)\nprint(\"y_val \", y_val.shape)","caee9489":"yTrain = to_categorical(partial_y_train)\nyVal = to_categorical(y_val)\nprint(yTrain.shape)\nprint(yVal.shape)","e720eb98":"# NN MODEL\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(331,)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(4, activation='softmax'))\nprint(model.summary())\n\n# FIT \/ TRAIN model\n\nNumEpochs = 100\nBatchSize = 16\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nhistory = model.fit(partial_x_train, yTrain, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, yVal))\n\nresults = model.evaluate(x_val, yVal)\nprint(\"_\"*100)\nprint(\"Test Loss and Accuracy\")\nprint(\"results \", results)\nhistory_dict = history.history\nhistory_dict.keys()","aa5eb161":"# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['categorical_accuracy']\nval_acc_values = history_dict['val_categorical_accuracy']\nepochs = range(1, (len(history_dict['categorical_accuracy']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","c1bb9e3c":"# Final Fit \/ Predict\n\nfinal_predictions = model.predict(x_val)\nprint(final_predictions)","9454a013":"# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n\nprint(final_predictions)\npred = []\nnumTest = final_predictions.shape[0]\nfor i in range(numTest):\n    pred.append(np.argmax(final_predictions[i])) \npredictions = np.array(pred)  \nprint(predictions)","3ff4767a":"# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n\nprint(yVal)\npred = []\nnumTest = yVal.shape[0]\nfor i in range(numTest):\n    pred.append(np.argmax(yVal[i])) \nyValNum = np.array(pred)  \nprint(yValNum)","c2104075":"conf_mx = confusion_matrix(yValNum, predictions)\nprint('conf_mx ready')","8fd3e17e":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","979abc35":"# Confusion matrix and all metrics - for EACH class separately\n\nNumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(conf_mx)\n    TPz = conf_mx[z,z]\n    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    #FPz = np.sum(conf_mx[z], axis=-1) \n    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)\/(TPz+TNz+FPz+FNz)\n    recall = TPz\/(TPz+FNz)\n    precision = TPz\/(TPz+FPz)\n    f1score = 2*recall*precision\/(recall+precision)\n    #roc_auc = auc(FPz, TPz)\n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\n    ","40b66057":"# Confusion Matrix for the WHOLE MODEL - ALL Classes\n\nprint('Confusion Matix for ALL Classes')\n\nTP = TP \/ NumClasses\nTN = TN \/ NumClasses\nFP = FP \/ NumClasses\nFN = FN \/ NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","480850fe":"print('AUC ROC ',multiclass_roc_auc_score(yValNum, predictions))","b0d373b6":"**NN model**  ","3ccddcc9":"# IMPUTE missing values\n\nX.fillna(value='unknown', axis=1, inplace=True)","7c395590":"* The original data is from MIMIC2 - Multiparameter Intelligent Monitoring in Intensive Care (deidentified DB) available freely from \nhttps:\/\/mimic.physionet.org\/\n* Each instance in the mldata.csv attached is one admission\n* Testing a theory I have, that one can predict LOS just by the number of interactions betweeen patient and hospital per day, \nLOS days was grouped 0-4, 4-8, etc.\n\nLet me know *your* results on this  dataset"}}