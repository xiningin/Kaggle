{"cell_type":{"123aa60d":"code","17b1e2ca":"code","4a4f265a":"code","040ea273":"code","8adbc742":"code","83ef8e36":"code","96b82fae":"code","fe46cef8":"code","a4b8c5cf":"code","2a167108":"code","1ff5705c":"code","7987c98a":"code","377e4323":"markdown"},"source":{"123aa60d":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch import nn\nfrom tqdm import tqdm\nfrom sklearn.model_selection import KFold\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","17b1e2ca":"# use GPU!\nif torch.cuda.is_available():\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\nprint(device)","4a4f265a":"# read data\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nX, y = torch.FloatTensor(train.drop(['label'],axis=1).values), torch.tensor(train['label'].values)\n\ntraining_size = 40000\nX_train, y_train = X[:training_size], y[:training_size]\nX_val, y_val = X[training_size:], y[training_size:]\nX_test = torch.FloatTensor(test.values)\n\nX_train, y_train, X_val, y_val, X_test = X_train.to(device), y_train.to(device), X_val.to(device), y_val.to(device), X_test.to(device).float()\nprint(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","040ea273":"# visualize one sample\nplt.imshow(X_train[8].reshape(28,28).cpu())\nplt.title(y_train[8].item())\nplt.show()","8adbc742":"# make dataset and dataloader\ndataset_train = TensorDataset(X_train, y_train)\ndataset_val = TensorDataset(X_val, y_val)\n\nbatch_size = 50\ndataloader_train = DataLoader(dataset_train, batch_size=batch_size,  shuffle=True)\ndataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)","83ef8e36":"# build a CNN!\nclass mnist_CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 6, 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        self.fc1 = nn.Linear(400, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, xb):\n        xb = xb.view(-1, 1, 28, 28)\n        xb = self.pool(F.relu(self.conv1(xb)))\n        xb = self.pool(F.relu(self.conv2(xb)))\n        xb = torch.flatten(xb, 1) \n        xb = F.relu(self.fc1(xb))\n        xb = F.relu(self.fc2(xb))\n        xb = self.fc3(xb)\n        return xb","96b82fae":"# loss function \nloss_function = F.cross_entropy\n\n# instantiate model\nmodel = mnist_CNN().to(device)\n\n# optimizer for updating weights\n# optimizer = optim.SGD(model.parameters(), lr=0.5, momentum=0.9)\noptimizer = optim.Adam(model.parameters())","fe46cef8":"# let's train\ndef training(model):\n    n_epochs = 18\n    train_loss = []\n    val_loss = []\n    iteration = []\n    for epoch in tqdm(range(n_epochs)):\n        iteration.append(epoch)\n\n        model.train()\n        for xb, yb in dataloader_train:\n            xb = xb.to(device)\n            yb = yb.to(device)\n\n            pred = model(xb)\n            loss = loss_function(pred, yb)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        with torch.no_grad():\n            train_loss.append(loss_function(model(X_train.to(device)), y_train.to(device)))\n            val_loss.append(loss_function(model(X_val.to(device)), y_val.to(device)))\n        \n    return model, train_loss, val_loss, iteration","a4b8c5cf":"trained_model_cnn, lt, lv, it = training(model)","2a167108":"plt.plot(it, lt, 'o-', label='training loss')\nplt.plot(it, lv, 'o-', label='validation loss')\nplt.legend()\nplt.title('losses for CNN')\nplt.xlabel('epoch')\nplt.show()","1ff5705c":"# output accuracy\ny_train_pred = trained_model_cnn(X_train)\ny_val_pred = trained_model_cnn(X_val)\ny_test_pred = trained_model_cnn(X_test)\n\nprint('train accuracy (CNN): ' + str((y_train_pred.argmax(dim=1) == y_train).float().mean().item()))\nprint('val accuracy (CNN): ' + str((y_val_pred.argmax(dim=1) == y_val).float().mean().item()))","7987c98a":"# save prediction\nprediction = y_test_pred.argmax(dim=1)\n\n# output to csv\nt_np = prediction.cpu().detach().numpy()\ndf = pd.DataFrame(t_np, columns=['Label'])\n\ndf.reset_index(inplace=True)\ndf.rename(columns = {'index':'ImageId'}, inplace=True)\ndf['ImageId'] += 1\ndf.to_csv(\"\/kaggle\/working\/submission.csv\",index=False)\n\n# reload\ndf = pd.read_csv(\"\/kaggle\/working\/submission.csv\")\ndf","377e4323":"### This notebook trains a simple CNN to classify MNIST digits with a reasonable (>98%) accuracy. "}}