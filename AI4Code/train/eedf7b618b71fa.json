{"cell_type":{"055719c1":"code","77e0f87b":"code","ca4701df":"code","b338f228":"code","1bb217e8":"code","b1d868a4":"code","993b60b7":"code","137227d5":"code","d204f3fa":"code","c72fa0a8":"code","f8b32bff":"code","9b5c53e0":"code","b0958c99":"code","6ca7d5b3":"code","71f68dde":"code","e89c513a":"code","48d4a255":"code","5f8e9f3b":"code","6ba077ad":"code","6bb47ca8":"code","6a55029b":"code","c95b0863":"markdown","b5d5590a":"markdown","63d26b1f":"markdown","be2d424c":"markdown","e0f23a8e":"markdown","107b7b73":"markdown","0ddba2a6":"markdown","4b8b8d0b":"markdown","1dfb9465":"markdown","83d32c93":"markdown","f7f23d45":"markdown","429eff81":"markdown","be4861f2":"markdown","91964e20":"markdown","6772cb5b":"markdown","29a20cac":"markdown","8ef5a241":"markdown","d0ff6cfd":"markdown","9625348e":"markdown","b907aa64":"markdown","2cb3e99b":"markdown","26bd47ad":"markdown","eabb5752":"markdown","c6af6e22":"markdown","058e9d23":"markdown","63d2492a":"markdown","f865f788":"markdown","6e619db0":"markdown","1dd498df":"markdown","865c6647":"markdown","cee07b18":"markdown","01d62fbc":"markdown","1e56306c":"markdown"},"source":{"055719c1":"import random\nimport os\n\nimport sklearn.utils\nfrom tqdm import tqdm, tqdm_notebook\nimport pandas as pd\nimport cv2 as cv\n\nfrom tqdm import tqdm\n\nimport tensorflow as tf\n#tf.enable_eager_execution()\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, DepthwiseConv2D, Flatten\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n\nimport json\nimport logging\n\nimport numpy as np\nimport matplotlib.pyplot as plt ","77e0f87b":"data_dir = r'..\/input'\ndataset_dir = os.path.join(data_dir, r'train\/train')\ncsv_dir = os.path.join(data_dir , 'train.csv')\nprint(os.getcwd())\nprint(dataset_dir)","ca4701df":"# I set all seed as 1372\n\nfrom numpy.random import seed\nseed(1372)\nfrom tensorflow import set_random_seed\nset_random_seed(1372)\n\n#df = sklearn.utils.shuffle(df,random_state=1372)","b338f228":"def resize_and_save(filename, input_dir, output_dir, size=32):\n    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n    image = Image.open(os.path.join(input_dir, filename))\n    # No resize Need for this dataset\n    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n    # image = image.resize((size, size), Image.BILINEAR)\n    image.save(os.path.join(output_dir, filename)) # linux => \/ windows => \\\\","1bb217e8":"class Params():\n    \"\"\"Class that loads hyperparameters from a json file.\n\n    Example:\n    ```\n    params = Params(json_path)\n    print(params.learning_rate)\n    params.learning_rate = 0.5  # change the value of learning_rate in params\n    ```\n    \"\"\"\n\n    def __init__(self, json_path):\n        self.update(json_path)\n\n    def save(self, json_path):\n        \"\"\"Saves parameters to json file\"\"\"\n        with open(json_path, 'w') as f:\n            json.dump(self.__dict__, f, indent=4)\n\n    def update(self, json_path):\n        \"\"\"Loads parameters from json file\"\"\"\n        with open(json_path) as f:\n            params = json.load(f)\n            self.__dict__.update(params)\n\n    @property\n    def dict(self):\n        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']`\"\"\"\n        return self.__dict__\n\n\ndef set_logger(log_path):\n    \"\"\"Sets the logger to log info in terminal and file `log_path`.\n\n    In general, it is useful to have a logger so that every output to the terminal is saved\n    in a permanent file. Here we save it to `model_dir\/train.log`.\n\n    Example:\n    ```\n    logging.info(\"Starting training...\")\n    ```\n\n    Args:\n        log_path: (string) where to log\n    \"\"\"\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n\n    if not logger.handlers:\n        # Logging to a file\n        file_handler = logging.FileHandler(log_path)\n        file_handler.setFormatter(logging.Formatter('%(asctime)s:%(levelname)s: %(message)s'))\n        logger.addHandler(file_handler)\n\n        # Logging to console\n        stream_handler = logging.StreamHandler()\n        stream_handler.setFormatter(logging.Formatter('%(message)s'))\n        logger.addHandler(stream_handler)\n\n\ndef save_dict_to_json(d, json_path):\n    \"\"\"Saves dict of floats in json file\n\n    Args:\n        d: (dict) of float-castable values (np.float, int, float, etc.)\n        json_path: (string) path to json file\n    \"\"\"\n    with open(json_path, 'w') as f:\n        # We need to convert the values to float for json (it doesn't accept np.array, np.float, )\n        d = {k: float(v) for k, v in d.items()}\n        json.dump(d, f, indent=4)\n","b1d868a4":"# Get the filenames in each directory (train and test)\ndf = pd.read_csv(csv_dir)\ndf['id'] = dataset_dir + '\/' + df['id'].astype(str)\nfilenames = df['id']\nlabels = df['has_cactus'].astype(np.float32)\n\n\n# Make sure to always shuffle with a fixed seed so that the split is reproducible\ndf = sklearn.utils.shuffle(df,random_state=1372)\ndf = df.reset_index(drop=True)","993b60b7":"print('sample filename ',filenames[0])\nprint('sample label (1 = exsit) , (0 = dosent exist any cactus) ',labels[0],type(labels[0]))","137227d5":"def _parse_function(filename, label, size):\n    \"\"\"Obtain the image from the filename (for both training and validation).\n\n    The following operations are applied:\n        - Decode the image from jpeg format\n        - Convert to float and to range [0, 1]\n    \"\"\"\n    image_string = tf.read_file(filename)\n\n    # Don't use tf.image.decode_image, or the output shape will be undefined\n    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n\n    # This will convert to float values in [0, 1]\n    image = tf.image.convert_image_dtype(image_decoded, tf.float32)\n\n    resized_image = tf.image.resize_images(image, [size, size])\n\n    return resized_image, label","d204f3fa":"def train_preprocess(image, label, use_random_flip):\n    \"\"\"Image preprocessing for training.\n\n    Apply the following operations:\n        - Horizontally flip the image with probability 1\/2\n        - Apply random brightness and saturation\n    \"\"\"\n    if use_random_flip:\n        image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, max_delta=25.0 \/ 255.0)\n    image = tf.image.random_saturation(image, lower=0.6, upper=1.4)\n\n    # Make sure the image is still in [0, 1]\n    image = tf.clip_by_value(image, 0.0, 1.0)\n\n    return image, label","c72fa0a8":"def input_fn(is_training, filenames, labels, params):\n    \"\"\"Input function for the dataset.\n\n        Args:\n        is_training: (bool) whether to use the train or test pipeline.\n                     At training, we shuffle the data and have multiple epochs\n        filenames: (list) filenames of the images, as [\"data_dir\/{label}_IMG_{id}.jpg\"...]\n        labels: (list) corresponding list of labels\n        params: (Params) contains hyperparameters of the model (ex: `params.num_epochs`)\n    \"\"\"\n    num_samples = len(filenames)\n    assert len(filenames) == len(labels), \"Filenames and labels should have same length\"\n\n    # Create a Dataset serving batches of images and labels\n    # We don't repeat for multiple epochs because we always train and evaluate for one epoch\n    parse_fn = lambda f, l: _parse_function(f, l, params.image_size)\n    train_fn = lambda f, l: train_preprocess(f, l, params.use_random_flip)\n\n    if is_training:\n        dataset = (tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))\n            .shuffle(num_samples)  # whole dataset into the buffer ensures good shuffling\n            .map(parse_fn, num_parallel_calls=params.num_parallel_calls)\n            .map(train_fn, num_parallel_calls=params.num_parallel_calls)\n            .batch(params.batch_size)\n            .repeat()\n            .prefetch(32)  # make sure you always have one batch ready to serve\n        )\n    else:\n        dataset = (tf.data.Dataset.from_tensor_slices((tf.constant(filenames), tf.constant(labels)))\n            .map(parse_fn)\n            .batch(params.batch_size)\n            .repeat()\n            .prefetch(32)  # make sure you always have one batch ready to serve\n        )\n        \n    return dataset","f8b32bff":"with open(\"params.json\", \"w\") as text_file:\n    text_file.write(\"{\\n\"+\n    \"\\\"learning_rate\\\": 1.5e-3,\"+\n    \"\\\"batch_size\\\": 64,\"+\n    \"\\\"num_epochs\\\": 50,\"+\n    \"\\\"image_size\\\": 32,\"+\n    \"\\\"use_random_flip\\\": false,\"+\n    \"\\\"num_labels\\\": 2,\"+\n    \"\\\"num_parallel_calls\\\": 8,\"+\n    \"\\\"save_summary_steps\\\": 1\"+\n    \"\\n}\")\n    \nparamPath = r'.\/'\njson_path = os.path.join(paramPath , 'params.json')\nassert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)","9b5c53e0":"params = Params(json_path)\nsplit = int(len(filenames)*0.15)\ntrain_dataset = input_fn(True, filenames[:split], labels[:split], params)\nvalid_dataset = input_fn(False , filenames[split:], labels[split:], params)","b0958c99":"iterator = train_dataset.make_one_shot_iterator()\nnext_element = iterator.get_next()\nwith tf.Session() as sess:\n    one_batch = sess.run(next_element)\n    print(one_batch[0].shape,' = 64 batch-size & 32x32x3 image')\n    for i in range(3):\n        plt.figure()\n        sample = one_batch[0]\n        label = one_batch[1]\n        print(label[i])\n        plt.imshow(sample[i])\n        plt.grid(False)       ","6ca7d5b3":"model = Sequential()\n        \nmodel.add(Conv2D(3, kernel_size = 3, activation = 'relu', input_shape = (32, 32, 3)))\n\nmodel.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 32, kernel_size = 1, activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 128, kernel_size = 1, activation = 'relu'))\nmodel.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\nmodel.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n#model.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(128, activation = 'elu'))\n\nmodel.add(Dense(1, activation = 'sigmoid'))","71f68dde":"Adam = tf.keras.optimizers.Adam(lr=params.learning_rate , amsgrad=True)\nmodel.compile(optimizer = Adam, loss = tf.losses.log_loss, metrics = ['accuracy'])\nmodel.summary()","e89c513a":"file_path = 'weights-aerial-cactus.h5'\n\ncallbacks = [\n        ModelCheckpoint(file_path, monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max'),\n        ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, mode = 'min', min_lr = 0.00001),\n        EarlyStopping(monitor = 'val_loss', min_delta = 1e-10, patience = 15, verbose = 1, restore_best_weights = True)\n        ]","48d4a255":"history = model.fit(train_dataset, validation_data=valid_dataset,\n          epochs=50,verbose=True,\n          steps_per_epoch=int((len(filenames) - split)\/params.batch_size),\n          validation_steps=int(split\/params.batch_size),\n           callbacks = callbacks)","5f8e9f3b":"model.load_weights(file_path)","6ba077ad":"def plot_training_curves(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Losses')\n    plt.legend()\n    plt.figure()\n    \n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Accuracies')\n    plt.legend()\n    plt.figure()\n    \n    plt.show()","6bb47ca8":"plot_training_curves(history)","6a55029b":"test_df = pd.read_csv('..\/input\/sample_submission.csv')\nX_test = []\nimages_test = test_df['id'].values\n\nfor img_id in tqdm_notebook(images_test):\n    X_test.append(cv.imread('..\/input\/test\/test\/' + img_id))\n    \nX_test = np.asarray(X_test)\nX_test = X_test.astype('float32')\nX_test \/= 255\n\ny_test_pred = model.predict_proba(X_test)\n\ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('aerial-cactus-submission_1.csv', index = False)\n\nfor i in range(len(y_test_pred)):\n    if y_test_pred[i][0] >= 0.5:\n        y_test_pred[i][0] = 1.0\n    else:\n        y_test_pred[i][0] = 0.0\n        \ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('aerial-cactus-submission_2.csv', index = False)","c95b0863":"as rule of thumb if you go deeper in ConvNet layer, filters number increase (better to be a power of 2)","b5d5590a":"**see [this](http:\/\/cs230.stanford.edu\/blog\/datapipeline\/#building-an-image-data-pipeline) for more info**","63d26b1f":"if you pass dataset to model.fit() function, you must define **steps_per_epoch** and **validation_steps**","be2d424c":"# All Path","e0f23a8e":"## Create tf.data.dataset","107b7b73":"# Define Model","0ddba2a6":"we can map function on all image of dataset by one line\nSO this can help us a lot like in agumentaion or preprocessing","4b8b8d0b":"**for more info see [This](https:\/\/cs230.stanford.edu\/blog\/datapipeline\/)**","1dfb9465":"**you must put your probability of cactus existence into csv file\nso if you replace prob. with  0 and 1 (I mean P less than 0.5 set to zero and upper that set to 1) then ...?\nare you get higher score?**","83d32c93":"**The END**","f7f23d45":"# Define functions","429eff81":"parameter can be saved or read as **param.json** file","be4861f2":"read ,resize and save image (due to dataset image cut to 32x32 pixel no need to that )","91964e20":"**This notebook write with [tf.data.datset](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/data\/Dataset) pipeline and [tf.keras](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras) high-level API\nand base on [CS230 Stanford Tensorflow Tutorial](https:\/\/cs230.stanford.edu\/blog\/tensorflow\/)**\n\n*codes will be completed by the time*\n\n**some parts of code inspired from [This](https:\/\/www.kaggle.com\/gabrielmv\/aerial-cactus-identification-keras) notebook**\n\nI hope to be useful","6772cb5b":"plot loss and acc","29a20cac":"The most important things for compare hypreParameter is reproductibility in code\nso fixed all seed at first","8ef5a241":"Most popular optimizer ADAM <3","d0ff6cfd":"**base on my [search](https:\/\/stats.stackexchange.com\/questions\/186091\/what-loss-function-should-i-use-for-binary-detection-in-face-non-face-detection) and experience log_loss work better than other loss function**","9625348e":"read parameter and split data into train and validation(%15)","b907aa64":"# Plot some sample to ensure we create  correct dataset","2cb3e99b":"show a sample of label and filename array\noperation like shuffel on filename array is faster than image array","26bd47ad":"load best weight","eabb5752":"# use for reproductibility","c6af6e22":"define path to dataset and csv file","058e9d23":"read image from test file and predict result.\nat the end save as csv file to submit","63d2492a":"The one_shot_iterator method creates an iterator that will be able to iterate once over the dataset. In other words, once we reach the end of the dataset, it will stop yielding elements and raise an Exception.\n\nNow, next_element is a graph\u2019s node that will contain the next element of iterator over the Dataset at each execution (adopted from CS230)","f865f788":"# Defin callbacks","6e619db0":"# Import Necessary library","1dd498df":"Base on CS230 course,It's better to save all hyperParameter to one file\nafter each change can compare between result and select best of them\n","865c6647":"# Dataset Pipeline","cee07b18":"The Dataset API allows you to build an asynchronous, highly optimized data pipeline to prevent your GPU from data starvation. It loads data from the disk (images or text), applies optimized transformations, creates batches and sends it to the GPU. Former data pipelines made the GPU wait for the CPU to load the data, leading to performance issues.","01d62fbc":"create params.json\nNotice:i can't upload it, so i write it as a text file.\nbut in practice you should put it in another folder","1e56306c":"Use tf.keras (I think its faster & better than Kera library)"}}