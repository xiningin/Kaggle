{"cell_type":{"3c8426e7":"code","4902ce56":"code","824286c0":"code","b786fb46":"code","4151334d":"code","95a3e4e1":"code","93caa628":"code","1e9e1c34":"code","1e98ff1a":"code","c79f4e37":"code","cd518bca":"code","b6a115a8":"code","d4918409":"code","943db4f4":"code","a4d59d94":"code","4373d4b0":"code","5104d704":"code","62857537":"code","1642f5f2":"code","323b4e2c":"code","500a3504":"code","db05ee1b":"code","63628b6b":"code","9f3c60cb":"code","bab76182":"code","d54900bf":"code","befa03b5":"code","58686bca":"code","a68ee118":"code","a6bc9877":"code","a5491e1d":"code","48f9b5cc":"code","5e8d10ce":"code","947333b8":"code","dc11bf9f":"code","c364494d":"code","6dec817d":"code","b8ebbeed":"code","051fc8ef":"code","b37d31ac":"code","5aa670dd":"code","72b7fa6c":"code","8094e748":"code","149cc644":"code","c3b21aec":"code","bfd45d1a":"code","8ddbc133":"markdown","6a74c0d3":"markdown","d8e789c3":"markdown"},"source":{"3c8426e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4902ce56":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings","824286c0":"warnings.filterwarnings(\"ignore\")","b786fb46":"raw_trainset = pd.read_csv('..\/input\/titanic\/train.csv')\nraw_testset = pd.read_csv('..\/input\/titanic\/test.csv')","4151334d":"raw_trainset.head()","95a3e4e1":"trainset = raw_trainset.drop(['PassengerId', 'Ticket', 'Fare', 'Cabin'], axis=1)","93caa628":"testset = raw_testset.drop(['PassengerId', 'Ticket', 'Fare', 'Cabin'], axis=1)","1e9e1c34":"# Create a Title feature\n\nfull_name_list=[name.split(\",\") for name in trainset[\"Name\"]]\n\nname_list = [name[1] for name in full_name_list]\n\ntitle = [word.split(\".\")[0] for word in name_list]\n\ntrainset['Title'] = title\ntrainset.drop('Name', axis=1, inplace=True)\ntrainset.head()","1e98ff1a":"full_name_list=[name.split(\",\") for name in testset[\"Name\"]]\n\nname_list = [name[1] for name in full_name_list]\n\ntitle = [word.split(\".\")[0] for word in name_list]\n\ntestset['Title'] = title\ntestset.drop('Name', axis=1, inplace=True)\ntestset.head()","c79f4e37":"# Create a Family Feature wich is the sum of SibSp and Parch\n\ntrainset['Family'] = trainset['SibSp'] + trainset['Parch']\ntrainset.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ntrainset.head()","cd518bca":"testset['Family'] = testset['SibSp'] + testset['Parch']\ntestset.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ntestset.head()","b6a115a8":"trainset.shape","d4918409":"testset.shape","943db4f4":"trainset.isna().sum()","a4d59d94":"trainset['Age'].fillna(trainset['Age'].mean(), inplace=True)\ntestset['Age'].fillna(testset['Age'].mean(), inplace=True)","4373d4b0":"trainset.isna().sum()","5104d704":"trainset['Age'].plot.hist()","62857537":"trainset.dtypes.value_counts()","1642f5f2":"for col in trainset.select_dtypes('int'):\n    plt.figure()\n    trainset[col].value_counts().plot.pie()\nfor col in trainset.select_dtypes('object'):\n    plt.figure()\n    trainset[col].value_counts().plot.pie()\n","323b4e2c":"X = trainset.drop('Survived', axis=1)\ny = trainset['Survived']","500a3504":"y.value_counts(normalize=True)","db05ee1b":"survived_df = trainset[trainset['Survived']==1]","63628b6b":"no_survived_df = trainset[trainset['Survived']==0]","9f3c60cb":"from sklearn.preprocessing import LabelEncoder","bab76182":"encoder = LabelEncoder()\nX['Sex'] = encoder.fit_transform(X['Sex'])\nX['Embarked'] = encoder.fit_transform(X['Embarked'])\nX['Title'] = encoder.fit_transform(X['Title'])\n","d54900bf":"X.head()","befa03b5":"testset['Sex'] = encoder.fit_transform(testset['Sex'])\ntestset['Embarked'] = encoder.fit_transform(testset['Embarked'])\ntestset['Title'] = encoder.fit_transform(testset['Title'])","58686bca":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split","a68ee118":"X.shape","a6bc9877":"from sklearn.metrics import f1_score, recall_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve","a5491e1d":"from sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline","48f9b5cc":"def evaluation(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    print(confusion_matrix(y_test, y_pred))\n    print(classification_report(y_test, y_pred))\n    \"\"\"\n    N, train_score, val_score = learning_curve(model, X_train, y_train, cv=5, scoring='f1', train_sizes=np.linspace(0.1,1,10))\n    \n    plt.figure(figsize=(12,8))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, val_score.mean(axis=1), label='validation score')\"\"\"","5e8d10ce":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n\nmodels = {'RandomForest':RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n          'KNN':make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3, metric='manhattan')),\n           'AdaBoost':AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n                                         n_estimators=50,\n                                         learning_rate=0.41,\n                                         random_state=29)\n         }\n","947333b8":"for name, model in models.items():\n    print(name)\n    evaluation(model)","dc11bf9f":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","c364494d":"models['AdaBoost'].get_params()","6dec817d":"param_grid = {\n    'n_estimators':range(50,74),\n    'learning_rate': np.linspace(0.41,0.5,10)\n}\ngrid = RandomizedSearchCV(AdaBoostClassifier(random_state=29),param_grid, cv=10)\ngrid.fit(X_train, y_train)","b8ebbeed":"grid.best_params_","051fc8ef":"grid.best_score_","b37d31ac":"final_model =  models['AdaBoost'] \nfinal_model.fit(X_train, y_train)\nprint(final_model.score(X_test, y_test))","5aa670dd":"model = grid.best_estimator_\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))","72b7fa6c":"y_pred = final_model.predict(X_test)\nconfusion_matrix(y_test, y_pred)","8094e748":"print(\"recall :\",recall_score(y_test, y_pred))\nprint(\"f1 :\",f1_score(y_test, y_pred))","149cc644":"y_final = final_model.predict(testset)","c3b21aec":"subs = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubs['Survived'] = pd.DataFrame(y_final)","bfd45d1a":"subs.to_csv('.\/TitanicSubmissionV6.csv', index = False)","8ddbc133":"### Feature engineering","6a74c0d3":"Homme : 1\nFemme : 0","d8e789c3":"## Target"}}