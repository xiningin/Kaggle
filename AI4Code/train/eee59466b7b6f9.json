{"cell_type":{"33a4a599":"code","ee80ce77":"code","df11d5a4":"code","5b3fc156":"code","5d74c81d":"code","2837e4e0":"code","72e16c5d":"code","84a58d88":"code","f069ee2c":"code","92866e94":"code","261c4bb4":"code","fad73ba9":"markdown","2c68fc15":"markdown","9b8f2ad4":"markdown","ce486045":"markdown","f8125483":"markdown","9f125896":"markdown","29af8064":"markdown","d7d027e2":"markdown","3fd035b3":"markdown"},"source":{"33a4a599":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee80ce77":"train = pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\n\ntest = pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv')\n\nprint(f'The shape of the training set is: {train.shape}')\nprint(f'The shape of the testing set is: {test.shape}')","df11d5a4":"train.isnull().sum()\ntest.isnull().sum()","5b3fc156":"train = train.drop('id', 1)\ntest = test.drop('id', 1)","5d74c81d":"import matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\n\nplt.figure(figsize=(25,30))\nplt.subplot(331)\nsns.countplot(x='Response', data=train, hue='Vehicle_Age')\n\n\nplt.subplot(332)\nsns.countplot(x='Response', data=train, hue='Vehicle_Damage')\n\nplt.subplot(333)\nsns.countplot(x='Response', data=train, hue='Previously_Insured')","2837e4e0":"from sklearn.utils import resample\n\nminority = train[train.Response==1]\nmajority = train[train.Response==0]\n\ndownsample = resample(majority, replace=False, n_samples=46710)\n\ndata = pd.concat([downsample, minority])\ndata.head()","72e16c5d":"plt.figure(figsize=(25,30))\nplt.subplot(331)\nsns.countplot(train.Response).set_title('Before Downsampling')\n\nplt.subplot(333)\nsns.countplot(data.Response).set_title('After Downsampling')","84a58d88":"x = data.drop('Response', 1)\ny = data.Response","f069ee2c":"from sklearn.preprocessing import LabelEncoder\n\nx.Gender = pd.get_dummies(x.Gender)\nx.Vehicle_Damage = pd.get_dummies(x.Vehicle_Damage)\n\nencoder = LabelEncoder()\nx.Vehicle_Age = encoder.fit_transform(x.Vehicle_Age) ","92866e94":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nx = scaler.fit_transform(x)","261c4bb4":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\nrandom_forest = RandomForestClassifier()\nknn = KNeighborsClassifier()\nxgb = XGBClassifier()\n\nestimators = [random_forest, knn, xgb]\n\nfor i in estimators:\n    score = cross_val_score(i, x, y, cv=3, n_jobs=5)\n    mean = score.mean()\n    print(f'{i} score: {mean}')\n    ","fad73ba9":"> **Splitting data to X and Y**","2c68fc15":"**Encoding categorical columns**","9b8f2ad4":"**Training**","ce486045":"**Dropping 'id' column**","f8125483":"**Before and after applying downsampling**","9f125896":"**Standardizing the features**","29af8064":"**Exploratory Data Analysis**","d7d027e2":"**Checking for missing values** ","3fd035b3":"**Downsampling the Response column**"}}