{"cell_type":{"e2d52677":"code","ebf0ece6":"code","be5ad756":"code","a3a38c5d":"markdown","8f9a5896":"markdown","f88e7655":"markdown"},"source":{"e2d52677":"import numpy as np\nimport matplotlib.pyplot as plt\n\nlines = np.loadtxt('..\/input\/data.csv', delimiter=',', dtype='str')\nx_total = lines[:, 1:3].astype('float')\ny_total = lines[:, 3].astype('float')\n\npos_index = np.where(y_total == 1)\nneg_index = np.where(y_total == 0)\nplt.scatter(x_total[pos_index, 0], x_total[pos_index, 1], marker='o', c='r')\nplt.scatter(x_total[neg_index, 0], x_total[neg_index, 1], marker='x', c='b')\nplt.show()\nprint('\u6570\u636e\u96c6\u5927\u5c0f:', x_total.shape[0])","ebf0ece6":"from sklearn import linear_model\n\nlr_clf = linear_model.LogisticRegression()\nlr_clf.fit(x_total, y_total)\nprint(lr_clf.coef_[0])\nprint(lr_clf.intercept_)\n\ny_pred = lr_clf.predict(x_total)\nprint('accuracy:',(y_pred == y_total).mean())","be5ad756":"def sigmoid(z):\n    result = 1 \/ (1 + np.exp(-z))\n    return result\n\nn_iterations = 1500\nlearning_rate = 0.1\n\nweight = np.zeros(3)\nx_total_concat = np.hstack([x_total, np.ones([x_total.shape[0], 1])])\n\nloss_list = []\nfor i in range(n_iterations):\n    prob_predict = sigmoid(np.dot(x_total_concat, weight))\n    loss = (- y_total * np.log(prob_predict) - (1 - y_total) * (np.log(1 - prob_predict))).mean()\n    loss_list.append(loss)\n    \n    w_gradient = (x_total_concat * np.tile((prob_predict - y_total).reshape([-1, 1]), 3)).mean(axis=0)\n    weight = weight - learning_rate * w_gradient \n    \ny_pred = np.where(np.dot(x_total_concat, weight)>0, 1, 0)\nprint('accuracy:',(y_pred == y_total).mean())\n\nplt.figure(figsize=(13, 4))\nplt.subplot(121)\nplt.plot(np.arange(n_iterations), loss_list)\nplt.subplot(122)\nplot_x = np.linspace(-1.0, 1.0, 100)\nplot_y = - (weight[0] * plot_x + weight[2]) \/ weight[1]\nplt.scatter(x_total[pos_index, 0], x_total[pos_index, 1], marker='o', c='r')\nplt.scatter(x_total[neg_index, 0], x_total[neg_index, 1], marker='x', c='b')\nplt.plot(plot_x, plot_y, c='g')\nplt.show()\n","a3a38c5d":"### 2. Sklearn","8f9a5896":"### 3. \u68af\u5ea6\u4e0b\u964d\n$\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_1} L(w,b) = \\frac{1}{N}\\sum_{i=1}^N (f(x^{(i)}) - y^{(i)}) x^{(i)}_1\n\\end{aligned}\n$\n\n$\n\\begin{aligned}\n\\frac{\\partial}{\\partial b} L(w,b)= \\frac{1}{N}\\sum_{i=1}^N f(x^{(i)}) - y^{(i)}\n\\end{aligned}\n$","f88e7655":"# \u903b\u8f91\u56de\u5f52\n\n* \u4efb\u52a1\uff1a\u4e8c\u5206\u7c7b\n* \u8f93\u5165\uff1a\u4e8c\u7ef4\u7279\u5f81\n* \u6807\u7b7e\uff1a\u6b63\u7c7b\u6216\u8005\u8d1f\u7c7b\n\n\n### 1. \u6570\u636e\u51c6\u5907"}}