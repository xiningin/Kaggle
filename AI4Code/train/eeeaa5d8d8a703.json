{"cell_type":{"c5b326ab":"code","955b844d":"code","a5972b9b":"code","1ce9e10d":"code","c60d3c7f":"code","0d5e3681":"code","9fc49fe6":"code","6c507955":"code","54d47322":"code","00a0f3a1":"code","6710456f":"code","feafbac0":"code","a879624e":"code","e7cfb59c":"code","f42b10a9":"code","457d67c0":"code","ec96bc48":"code","ad865d6a":"code","2d7a918c":"code","6d4c9de8":"code","553a6c00":"code","7ccb931a":"code","df3d3b5c":"code","e65b4486":"code","d121c5c4":"code","751cf91e":"code","4bf3f95d":"code","8899a3d9":"code","a7bbe7fb":"code","8c2fcdab":"code","e827dc64":"code","abda35cf":"code","dd9ab756":"code","eeebcf71":"code","8de4247a":"code","6ab4cd21":"code","9dbc0cf7":"code","fa2db79c":"code","01031daa":"code","1eed6751":"code","83082aed":"code","a2d6dae1":"code","9268ed59":"code","0bf2c68c":"code","09502ab6":"code","0700011d":"code","0d83ce9d":"code","ab54cd86":"code","36243e6f":"code","faea393a":"code","1587d639":"code","0abeb50c":"code","2c5589c7":"code","d56f38ad":"code","97f2c67b":"code","a55fecba":"code","cf7bc6e1":"code","5073bfdd":"code","677de7e4":"code","e7456ae1":"code","939220c6":"code","50f75a27":"code","e4933291":"code","90fb8a6c":"code","6d68871f":"code","11cef5a9":"code","cfa8dad7":"code","15925f2e":"code","c32cbcc4":"code","e3bca8c3":"code","15d9c95d":"code","0e1763f8":"code","5bc9d96f":"code","985dca6a":"code","b149a877":"code","7eee74e8":"code","2bbbf803":"code","492ff931":"code","333bb6f0":"code","ff797be5":"code","10aef95c":"code","c7ebd19b":"code","aec6e765":"code","b84bc768":"code","38ad3804":"code","53ece1b2":"markdown","914e57ab":"markdown","22d3792d":"markdown","6d69c872":"markdown","5336db67":"markdown","58980c3c":"markdown","5cdf3357":"markdown","6b904ca2":"markdown","4f58063b":"markdown","7cdee00f":"markdown","42c76f8e":"markdown","2915e936":"markdown","85a6c87a":"markdown"},"source":{"c5b326ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","955b844d":"import pandas as pd\nimport numpy as np\ndf= pd.read_csv('..\/input\/szeged-weather\/weatherHistory.csv')\ndf.head(4)","a5972b9b":"df.isnull().sum(axis=0)","1ce9e10d":"df.describe()","c60d3c7f":"df = df.dropna(how='any',axis=0) ","0d5e3681":"df.isnull().sum(axis=0)","9fc49fe6":"df.iloc[:,1].value_counts()","6c507955":"#replacing the column values to fit into majority of the values.\ndf['Summary']=df['Summary'].replace(['Breezy and Overcast','Breezy and Mostly Cloudy','Breezy and Partly Cloudy','Breezy and Foggy'],'Breezy')\ndf['Summary']=df['Summary'].replace(['Dry and Partly Cloudy','Dry and Mostly Cloudy','Windy and Dry','Breezy and Dry'],'Dry')\ndf['Summary']=df['Summary'].replace(['Windy and Partly Cloudy','Windy and Overcast','Windy and Mostly Cloudy','Windy and Foggy','Dangerously Windy and Partly Cloudy'],'Windy')\ndf['Summary']=df['Summary'].replace(['Light Rain','Drizzle'],'Rain')\ndf['Summary']=df['Summary'].replace(['Humid and Mostly Cloudy','Humid and Partly Cloudy','Humid and Overcast'],'Humid')","54d47322":"df.iloc[:,1].value_counts()","00a0f3a1":"#We can categorize the column and create dummy variables. But I am tranferring the column values into a numeric values inorder to avoid more number of columns.\n#There is a risk involved in this method. If we get more data, we have to make sure Summary column is mapped to the repective numeric calues. If new value occurs we have to create a new numeric value and re fit the data into the model.\n\nsummary_dict={'Partly Cloudy':0,\n'Mostly Cloudy':1,\n'Overcast':2,\n'Clear':3,\n'Foggy':4,\n'Breezy':5,\n'Windy':6,\n'Dry':7,\n'Rain':8,\n'Humid':9}\n\n","6710456f":"df.shape[0]","feafbac0":"df=df.replace({\"Summary\": summary_dict})\ndf.head(5)","a879624e":"#Handling Categorical variable\n#drop_first=True will avoid dummy variable trap\ncols_to_transform = [ 'Precip Type']\ndf_with_dummies = pd.get_dummies(df,columns = cols_to_transform,drop_first=True)\ndf=df_with_dummies\n\n","e7cfb59c":"df.head(3)","f42b10a9":"df[['Date','Hour','Dummy']]=df['Formatted Date'].str.split(\" \",expand=True) \n#2006-04-01 00:","457d67c0":"df.drop('Dummy',axis=1,inplace=True)\n","ec96bc48":"df['Hour']=df['Hour'].str.split(':').str[0]","ad865d6a":"import datetime as dt\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['Date']=df['Date'].map(dt.datetime.toordinal)","2d7a918c":"#df.drop('Date_1',axis=1,inplace=True)\ndf.head(2)","6d4c9de8":"df.drop('Formatted Date',axis=1,inplace=True)\ndf.head(2)","553a6c00":"df.iloc[:,9].value_counts()","7ccb931a":"df.iloc[:,9].nunique()","df3d3b5c":"def change_category_to_number(DailySummaryCat):\n    if DailySummaryCat=='Partly cloudy throughout the day.':\n        return 1\n    elif DailySummaryCat=='Mostly cloudy throughout the day.':\n        return 2\n    elif DailySummaryCat=='Foggy in the evening.':\n        return 3\n    elif DailySummaryCat=='Foggy overnight and breezy in the morning.':\n        return 4\n    elif DailySummaryCat=='Overcast throughout the day.':\n        return 5\n    elif DailySummaryCat=='Partly cloudy until night.':\n        return 6\n    elif DailySummaryCat=='Motly cloudy until night.':\n        return 7\n    elif DailySummaryCat=='Foggy starting overnight continuing until morning.':\n        return 8\n    elif DailySummaryCat=='Foggy in the morning.':\n        return 9\n    elif DailySummaryCat=='Partly cloudy until evening.':\n        return 10\n    elif DailySummaryCat=='Partly cloudy starting in the morning.':\n        return 11\n    elif DailySummaryCat=='Mostly cloudy starting overnight continuing until night.':\n        return 12\n    elif DailySummaryCat=='Partly cloudy starting in the afternoon.':\n        return 13\n    elif DailySummaryCat=='Partly cloudy starting overnight.':\n        return 14\n    elif DailySummaryCat=='Mostly cloudy starting overnight.':\n        return 15\n    elif DailySummaryCat=='Mostly cloudy until night and breezy in the afternoon.':\n        return 16\n    elif DailySummaryCat=='Mostly cloudy until evening.':\n        return 17\n    elif DailySummaryCat=='Foggy throughout the day.':\n        return 18\n    elif DailySummaryCat=='Partly cloudy starting in the morning.':\n        return 19\n    elif DailySummaryCat=='Partly cloudy starting in the morning continuing until evening.':\n        return 20\n    elif DailySummaryCat=='Foggy until morning.':\n        return 21\n    elif DailySummaryCat=='Partly cloudy starting in the morning continuing until night.':\n        return 22\n    elif DailySummaryCat=='Mostly cloudy starting in the morning.':\n        return 23\n    elif DailySummaryCat=='Foggy starting in the evening.':\n        return 24\n    elif DailySummaryCat=='Partly cloudy starting in the afternoon continuing until evening.':\n        return 25\n    elif DailySummaryCat=='Foggy overnight.':\n        return 26\n    elif DailySummaryCat=='Clear throughout the day.':\n        return 27\n    elif DailySummaryCat=='Partly cloudy starting overnight continuing until night.':\n        return 28\n    elif DailySummaryCat=='Partly cloudy overnight.':\n        return 29\n    elif DailySummaryCat=='Partly cloudy starting overnight continuing until evening.':\n        return 30\n    elif DailySummaryCat=='Foggy until night.':\n        return 31\n    elif DailySummaryCat=='Partly cloudy in the morning.':\n        return 32\n    elif DailySummaryCat=='Foggy starting overnight continuing until afternoon.':\n        return 33\n    elif DailySummaryCat=='Foggy until afternoon.':\n        return 34\n    elif DailySummaryCat=='Breezy and mostly cloudy overnight.':\n        return 35\n    elif DailySummaryCat=='Partly cloudy overnight and breezy starting in the morning continuing until afternoon.':\n        return 36\n    elif DailySummaryCat=='Breezy in the morning and foggy in the evening.':\n        return 37\n    elif DailySummaryCat=='Mostly cloudy until evening and breezy in the evening.':\n        return 38\n    elif DailySummaryCat=='Mostly cloudy starting in the evening.':\n        return 39\n    elif DailySummaryCat=='Mostly cloudy throughout the day and breezy starting overnight continuing until afternoon.':\n        return 40\n    elif DailySummaryCat=='Breezy starting in the morning continuing until night.':\n        return 41\n    elif DailySummaryCat=='Overcast throughout the day and breezy starting overnight continuing until morning.':\n        return 42\n    elif DailySummaryCat=='Breezy starting overnight continuing until morning and foggy in the evening.':\n        return 43\n    elif DailySummaryCat=='Light rain until morning.':\n        return 44\n    elif DailySummaryCat=='Mostly cloudy until night and breezy starting in the afternoon continuing until night.':\n        return 45\n    elif DailySummaryCat=='Mostly cloudy starting in the morning continuing until afternoon.':\n        return 46\n    elif DailySummaryCat=='Breezy until afternoon and overcast throughout the day.':\n        return 47\n    elif DailySummaryCat=='Partly cloudy until evening and breezy in the afternoon.':\n        return 48\n    elif DailySummaryCat=='Breezy starting overnight continuing until morning and partly cloudy starting overnight continuing until evening.':\n        return 49\n    elif DailySummaryCat=='Light rain starting overnight.':\n        return 50\n    elif DailySummaryCat=='Partly cloudy starting overnight continuing until evening and breezy starting in the morning continuing until evening.':\n        return 51\n    elif DailySummaryCat=='Foggy starting in the morning continuing until evening and breezy in the evening.':\n        return 52\n    elif DailySummaryCat=='Partly cloudy throughout the day and breezy in the afternoon.':\n        return 53\n    elif DailySummaryCat=='Mostly cloudy starting overnight continuing until evening and breezy starting overnight continuing until morning.':\n        return 54\n    elif DailySummaryCat=='Partly cloudy starting overnight continuing until evening and breezy in the morning.':\n        return 55\n    elif DailySummaryCat=='Overcast throughout the day and breezy overnight.':\n        return 56\n    elif DailySummaryCat=='Light rain in the morning.':\n        return 57\n    elif DailySummaryCat=='Rain until morning.':\n        return 58\n    elif DailySummaryCat=='Breezy in the morning and mostly cloudy starting in the evening.':\n        return 59\n    elif DailySummaryCat=='Mostly cloudy starting in the morning and breezy overnight.':\n        return 60\n    elif DailySummaryCat=='Partly cloudy starting overnight and breezy starting in the morning continuing until afternoon.':\n        return 61\n    elif DailySummaryCat=='Partly cloudy starting in the morning and breezy starting in the afternoon continuing until evening.':\n        return 62\n    elif DailySummaryCat=='Partly cloudy starting in the morning continuing until evening and breezy in the afternoon.':\n        return 63\n    elif DailySummaryCat=='Foggy starting overnight continuing until morning and breezy in the afternoon.':\n        return 64\n","e65b4486":"# assign a numerical value to the categorical field of class, by using the above function\ndf['DailySummaryCat'] = df['Daily Summary'].apply(change_category_to_number)\n","d121c5c4":"df.isnull().sum(axis=0)","751cf91e":"# Let us remove the null values to ignore less contributing data.\ndf = df.dropna(how='any',axis=0) \ndf.isnull().sum(axis=0)","4bf3f95d":"df.drop('Daily Summary',axis=1,inplace=True)\ndf.head(2)","8899a3d9":"df.shape","a7bbe7fb":"df = df.apply(pd.to_numeric)\ndf.head(2)","8c2fcdab":"df.rename(columns={'Temperature (C)': 'Temparature','Apparent Temperature (C)':'ApparentTemperature','Wind Speed (km\/h)':'WindSpeed','Wind Bearing (degrees)':'WindBearing','Visibility (km)':'Visibility','Pressure (millibars)':'Pressure','Precip Type_snow':'PrecipTypeSnow'}, inplace=True)\ndf.head(2)","e827dc64":"df.rename(columns={'Loud Cover': 'LoudCover'}, inplace=True)\ndf.head(2)","abda35cf":"from sklearn.model_selection import train_test_split\n\nX = df[df.loc[:, df.columns != 'DailySummaryCat'].columns]\ny = df['DailySummaryCat']","dd9ab756":"X.head(3)","eeebcf71":"y.shape","8de4247a":"import matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n%matplotlib inline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n\n#Using Pearson correlation method\n\n#The correlation coefficient has values between -1 to 1\n#\u2014 A value closer to 0 implies weaker correlation (exact 0 implying no correlation)\n#\u2014 A value closer to 1 implies stronger positive correlation\n#\u2014 A value closer to -1 implies stronger negative correlation\n\n#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","6ab4cd21":"#Since LoudCover is 0 across all rows we will drop that column and re run heat map.\n\ndf.drop('LoudCover',axis=1,inplace=True)\ndf.head(2)","9dbc0cf7":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","fa2db79c":"cor[\"DailySummaryCat\"]","01031daa":"#Correlation with output variable\n#Usually we should take 0.05 as the benchmark. But to increase more number of features in input set, we added the bencmark to 0.1\ncor_target = abs(cor[\"DailySummaryCat\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.1]\nrelevant_features","1eed6751":"#print(df[[\"Summary\",\"Visibility\"]].corr())\n","83082aed":"#print(df[[\"PrecipTypeSnow\",\"Summary\"]].corr())","a2d6dae1":"df.head(2)","9268ed59":"from sklearn.model_selection import train_test_split\nX_pearson=df.iloc[:,[0,6,8]] #'Summary','Visibility','PrecipTypeSnow']\n#X = df[df.loc[:, df.columns != ['DailySummaryCat','Temparature','ApparentTemperature','Humidity','WindSpeed','WindBearing','Pressure','Date','Hour']].columns]\ny_pearson = df['DailySummaryCat']","0bf2c68c":"X_pearson.head(3)","09502ab6":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_pearson, y_pearson, test_size=0.25, random_state=128)","0700011d":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\n\nX_train_scaled = sc_X.fit_transform(X_train.values)\nX_test_scaled = sc_X.fit_transform(X_test.values)\n","0d83ce9d":"X_train_scaled.shape","ab54cd86":"y_train.shape","36243e6f":"\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n","faea393a":"Classifer = DecisionTreeClassifier(max_leaf_nodes=15,random_state=0)","1587d639":"Classifer.fit(X_train_scaled, y_train)","0abeb50c":"prediction = Classifer.predict(X_test_scaled)","2c5589c7":"accuracy_score(y_true=y_test, y_pred=prediction)","d56f38ad":"lrClassifier = LogisticRegression()\nlrClassifier.fit(X_train_scaled,y_train)\nprediction = lrClassifier.predict(X_test_scaled)\naccuracy_score(y_true=y_test, y_pred=prediction)","97f2c67b":"X = df[df.loc[:, df.columns != 'DailySummaryCat'].columns]\ny = df['DailySummaryCat']","a55fecba":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=128)","cf7bc6e1":"X_train_scaled = sc_X.fit_transform(X_train.values)\nX_test_scaled = sc_X.fit_transform(X_test.values)","5073bfdd":"model = LogisticRegression()\n#Initializing RFE model\nrfe = RFE(model, 7)   # 7 is chosen at random. But practically we should iterate across all the columns to get best fit features. (Refer - https:\/\/towardsdatascience.com\/feature-selection-with-pandas-e3690ad8504b)\n#Transforming data using RFE\nX_rfe = rfe.fit_transform(X_train_scaled,y_train)  \n#Fitting the data to model\nmodel.fit(X_rfe,y_train)\n","677de7e4":"print(rfe.support_)\n","e7456ae1":"print(rfe.ranking_)","939220c6":"cols = list(X_train.columns)\ntemp = pd.Series(rfe.support_,index = cols)\nselected_features_rfe = temp[temp==True].index\nprint(selected_features_rfe)","50f75a27":"X_test","e4933291":"X_test=X_test.iloc[:,[1,2,3,4,5,6,9]]\nX_test.head(2)","90fb8a6c":"X_test_scaled = sc_X.fit_transform(X_test.values)","6d68871f":"prediction = model.predict(X_test_scaled)\naccuracy_score(y_true=y_test, y_pred=prediction)","11cef5a9":"X = df[df.loc[:, df.columns != 'DailySummaryCat'].columns]\ny = df['DailySummaryCat']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=128)\nX_train_scaled = sc_X.fit_transform(X_train.values)\nX_test_scaled = sc_X.fit_transform(X_test.values)","cfa8dad7":"#If the feature is irrelevant, lasso penalizes it\u2019s coefficient and make it 0. Hence the features with coefficient = 0 are removed and the rest are taken.\nreg = LassoCV()\nreg.fit(X_train_scaled, y_train)\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(X_train_scaled, y_train))\n","15925f2e":"coef = pd.Series(reg.coef_, index = X.columns)\nprint(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","c32cbcc4":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","e3bca8c3":"df.head(3)","15d9c95d":"# we will predict orecip type snow column to keep our model simple.\ndf['PrecipTypeSnow'].unique()","0e1763f8":"#Let us find the important features requied using pearson correlation coefficient method\ncor[\"PrecipTypeSnow\"]","5bc9d96f":"cor_target = abs(cor[\"PrecipTypeSnow\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.2]\nrelevant_features","985dca6a":"df.head(3)","b149a877":"X=df.iloc[:,[0,1,2,3,6]]\ny=df['PrecipTypeSnow']\nX.head(2)","7eee74e8":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=128)\nX_train_scaled = sc_X.fit_transform(X_train.values)\nX_test_scaled = sc_X.fit_transform(X_test.values)","2bbbf803":"#Dependencies\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# Neural network\nmodel = Sequential()\nmodel.add(Dense(5, input_dim=5, activation=\u2019relu\u2019))  # 5 input variables and 4 hidden layers\nmodel.add(Dense(2, activation=\u2019relu\u2019)) # 2 second hidden layer\nmodel.add(Dense(1, activation=\u2019sigmoid\u2019)) # 1 output layer since output node has one classifying variable","492ff931":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","333bb6f0":"history = model.fit(X_train, y_train, epochs=100, batch_size=64)","ff797be5":"y_pred = model.predict(X_test)\n#Converting predictions to label\npred = list()\nfor i in range(len(y_pred)):\n    pred.append(np.argmax(y_pred[i]))\n#Converting one hot encoded test label to label\ntest = list()\nfor i in range(len(y_test)):\n    test.append(np.argmax(y_test[i]))","10aef95c":"from sklearn.metrics import accuracy_score\na = accuracy_score(pred,test)\nprint('Accuracy is:', a*100)","c7ebd19b":"from sklearn.metrics import accuracy_score\na = accuracy_score(pred,test)\nprint('Accuracy is:', a*100)","aec6e765":"history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=100, batch_size=64)","b84bc768":"import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","38ad3804":"plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()","53ece1b2":"**Still the same score compared to using all the fields. But the run time and efficiency in completing the model was quicker. we were able to minimize the usage of resources**","914e57ab":"**Getting train test data**","22d3792d":"**Applying normalization**","6d69c872":"**Finally we will aslo try Lasso regularization to choose the ebst features**","5336db67":"*Lasso picked all the variables. Here it is inefficient*","58980c3c":"**Feature Selection - Finding important features using different methods**","5cdf3357":"**Implementing Artificial Neural Network for the calssification prediction**","6b904ca2":"**Applying logistic regression**","4f58063b":"**Removing Null records**\n> we do not want to impute values to precip type column. I thas only 500+null records and its very low compared to the data records count.","7cdee00f":"*Accuracy was increased a little using RFE method compared to pearson method.*","42c76f8e":"**Training with Decision Tree Classifier**","2915e936":"Finding the best features using recursive feature elimination","85a6c87a":"**Building ANN model**"}}