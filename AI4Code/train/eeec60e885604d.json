{"cell_type":{"b1c9419d":"code","7dd08064":"markdown"},"source":{"b1c9419d":"import networkx as nx\nimport pydot\nfrom hmmlearn import hmm\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\n%matplotlib inline\n\ndef markov_p(data):\n  # from https:\/\/www.kaggle.com\/friedchips\/on-markov-chains-and-the-competition-data\n  channel_range = np.unique(data)\n  channel_bins = np.append(channel_range, 11)\n  data_next = np.roll(data, 1)\n  matrix = []\n  for i in channel_range:\n    current_row = np.histogram(data_next[data == i], bins=channel_bins)[0]\n    current_row = current_row \/ np.sum(current_row)\n    matrix.append(current_row)\n  return np.array(matrix)\n\ntrain_clean = pd.read_csv(\"..\/input\/data-without-drift\/train_clean.csv\")\nX, y = train_clean[\"signal\"].values, train_clean[\"open_channels\"].values\n\nsequences = np.zeros((X.shape[0], 1), dtype=np.float32)\n# max. 1 open channel, low probability\nsequences[0 * 500000:1 * 500000] = 0\nsequences[1 * 500000:2 * 500000] = 0\n# max. 1 open channel, high probability\nsequences[2 * 500000:3 * 500000] = 1\nsequences[6 * 500000:7 * 500000] = 1\n# max. 3 open channels\nsequences[3 * 500000:4 * 500000] = 2\nsequences[7 * 500000:8 * 500000] = 2\n# max. 5 open channels\nsequences[5 * 500000:6 * 500000] = 3\nsequences[8 * 500000:9 * 500000] = 3\n# max. 10 open channels\nsequences[4 * 500000:5 * 500000] = 4\nsequences[9 * 500000:10 * 500000] = 4\n\nfor sequence, components in [(0, 2), (1, 2), (2, 4), (3, 6), (4, 11)]:\n  print(f\"Sequence {sequence} with {components-1} open channel(s)\")\n\n  X_part = X[np.flatnonzero(sequences == sequence)]\n  y_part = y[np.flatnonzero(sequences == sequence)]\n\n  h = hmm.GaussianHMM(n_components=components, covariance_type=\"tied\", verbose=False, n_iter=200, random_state=3)\n  h.fit(X_part.reshape((-1, 1)))\n\n  with open(f\"{sequence}.pkl\", \"wb\") as f:\n    pickle.dump(h, f)\n\n  diff = 0\n  for a, b in zip(sorted(markov_p(y_part).flatten()), sorted(h.transmat_.flatten())):\n        diff += np.abs(a - b)\n\n  print(f\"MAE between histogram and viterbi transition matrix: {diff}\")\n  print(f\"Score: {h.score(X_part.reshape(-1, 1))}\")\n  print(f\"Acc: {np.sum((h.predict(X_part.reshape((-1, 1))) == y_part))\/X_part.shape[0]}\")\n\n  fig, axes = plt.subplots(1, 1)\n  fig.set_size_inches(10, 5)\n  fig.subplots_adjust(wspace=0.05, hspace=0.05)\n    \n  sns.heatmap(h.transmat_, annot=True, fmt='.3f', cmap='Blues', cbar=False, ax=axes, vmin=0, vmax=0.5, linewidths=2)\n  plt.show()\n\n  G = nx.MultiDiGraph()\n  for i, j in itertools.permutations(range(components), 2):\n    percentage = h.transmat_[i][j]\n    if percentage == 0:\n        continue\n\n    G.add_edge(i, j, weight=percentage, label=\"{:.03f}\".format(percentage))\n\n  nx.drawing.nx_pydot.write_dot(G, f\"{sequence}.dot\")\n  (graph,) = pydot.graph_from_dot_file(f\"{sequence}.dot\")\n  graph.write_png(f\"{sequence}.png\")\n\n  plt.figure()\n  img = plt.imread(f\"{sequence}.png\")\n  plt.imshow(img)\n  plt.show()","7dd08064":"This kernel shows the Markov chain and transition table of each sequence. Since the data is a Markov process, HMMs could also be used to predict the open channels. Instead of splitting the data according to batches, it makes more sense to look at each synthetic model (as was done here https:\/\/www.kaggle.com\/cdeotte\/one-feature-model-0-930).\n\nFor sequence 1 and 2: HMMs find the same transition matrix as a histogram computed on open channels. But as the number of channels increases, the performance drops."}}