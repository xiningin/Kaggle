{"cell_type":{"9df33356":"code","f8d80af8":"code","f9624e5d":"code","00fc7da0":"code","a03e9e4a":"code","12d5889b":"code","7d247e80":"code","d50d8962":"code","aec6770c":"code","9403078a":"code","6edb49f8":"code","45b247cc":"code","311022a5":"code","28e164c5":"code","0988e77b":"code","f7a13cec":"code","fd94c690":"code","63da7403":"code","19198e8d":"code","4cf7ca51":"code","073756d3":"code","f9e315ac":"code","24d12517":"code","0faf8d1a":"markdown"},"source":{"9df33356":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cross_validation import train_test_split\nprint(os.listdir(\"..\/input\"))","f8d80af8":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer","f9624e5d":"from sklearn.preprocessing import Imputer","00fc7da0":"data=pd.read_csv('..\/input\/census.csv')","a03e9e4a":"data.head(5)","12d5889b":"y=data['income']","7d247e80":"features=data.drop(columns=['income']) ","d50d8962":"income=y.map({'<=50K': 0, '>50K':1})","aec6770c":"#checking class imbalance \nprint(sum(income==0)\/len(income))","9403078a":"features[['capital-gain','capital-loss']].hist()\n","6edb49f8":"#applying log transformations to capital-gain and capital-loss\nfeatures_log = pd.DataFrame(data = features)\nfeatures_log[['capital-gain','capital-loss']] = features[['capital-gain','capital-loss']].apply(lambda x: np.log(x + 1))","45b247cc":"features_log[['capital-gain','capital-loss']].hist()","311022a5":"#normalizing numerical features \nscaler = MinMaxScaler()\nnumerical_features=['age','education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\nfeatures_log_scaled=pd.DataFrame(data=features_log)\nfeatures_log_scaled[numerical_features]=scaler.fit_transform(features_log[numerical_features])\nfeatures_log_scaled.head(100)","28e164c5":"#one hot encoding all the categorical variables\nfeatures_final = pd.get_dummies(features_log_scaled)\n#printing the number of features after encoding\nencoded = list(features_final.columns)\nprint(\"{} total features after encoding.\".format(len(encoded)))","0988e77b":"features_final.head(5)","f7a13cec":"X_train, X_test, y_train, y_test= train_test_split(features_final, income, test_size=0.2, random_state=21)\n\nprint(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(X_test.shape[0]))","fd94c690":"model=GradientBoostingClassifier()\nparameters = {'n_estimators':[300,400,500],'min_samples_split':[4],'max_depth':[3]}\nscorer = make_scorer(roc_auc_score)\ngridcv_object = GridSearchCV(model, parameters, scoring=scorer)\ngridcv_fit = gridcv_object.fit(X_train, y_train)\nbest_model = gridcv_fit.best_estimator_\npredictions = (model.fit(X_train, y_train)).predict(X_test)\nbest_predictions=best_model.predict(X_test)\n\n\nprint(\"Unoptimized model\\n\")\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"Area under curve on testing data: {:.4f}\".format(roc_auc_score(y_test, predictions)))\nprint(\"\\nOptimized Model\\n\")\nprint(\"Accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"Area under curve on the testing data: {:.4f}\".format(roc_auc_score(y_test, best_predictions)))","63da7403":"probs_train = best_model.predict_proba(X_train)[:, 1]\nprobs_test = best_model.predict_proba(X_test)[:, 1]\nprint(\"score train: {}\".format(roc_auc_score(y_train, probs_train)))\nprint(\"score test: {}\".format(roc_auc_score(y_test, probs_test)))","19198e8d":"test = pd.read_csv(\"..\/input\/test_census.csv\")\nfor cat in test:\n    first=test[cat][0]\n    test[cat].fillna(first, inplace=True)","4cf7ca51":"features_log_test = pd.DataFrame(data = test)\nfeatures_log_test[['capital-gain','capital-loss']] = features_log_test[['capital-gain','capital-loss']].apply(lambda x: np.log(x + 1))\nscaler_test = MinMaxScaler()\nfeatures_log_scaled_test=pd.DataFrame(data=features_log_test)\nfeatures_log_scaled_test[numerical_features]=scaler.fit_transform(features_log_test[numerical_features])\nfeatures_final_test = pd.get_dummies(features_log_scaled_test)","073756d3":"features_final_test_1=features_final_test.drop('Unnamed: 0',1)","f9e315ac":"test['id'] = test.iloc[:,0] \ntest['income'] = best_model.predict_proba(features_final_test_1)[:, 1]","24d12517":"test[['id', 'income']].to_csv(\"submission.csv\", index=False)","0faf8d1a":"I will be using Gradient Boosting classifier for this dataset. "}}