{"cell_type":{"3db0fd34":"code","5c35b1a7":"code","dfb9e676":"code","4db82d37":"code","d62d2093":"code","d97732ce":"code","ea25e2b9":"code","f5878bc4":"code","94df4746":"markdown","45931d7a":"markdown"},"source":{"3db0fd34":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport lightgbm as lgb\nfrom pathlib import Path\nimport seaborn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom warnings import simplefilter\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport datatable as dt","5c35b1a7":"!pip install kaggler","dfb9e676":"import kaggler\nfrom kaggler.model import AutoLGB\nprint(kaggler.__version__)\nplt.style.use('fivethirtyeight')\npd.set_option('max_columns', 100)\nsimplefilter('ignore')","4db82d37":"data_dir = Path('..\/input\/tabular-playground-series-sep-2021')\ntrain_file = data_dir \/ 'train.csv'\ntest_file = data_dir \/ 'test.csv'\nsample_file = data_dir \/ 'sample_solution.csv'\nid_col = 'id'\ntarget_col = ['claim']\n\nn_fold = 5\nseed = 42","d62d2093":"trn = (dt.fread(train_file).to_pandas()).set_index('id')\ntst = pd.read_csv(test_file, index_col=id_col)\nsub = pd.read_csv(sample_file, index_col=id_col)\nprint(trn.shape, tst.shape, sub.shape)","d97732ce":"n_trn = trn.shape[0]\ndf = pd.concat([trn.drop(target_col, axis=1), tst], axis=0)\nprint(df.shape)","ea25e2b9":"cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\nX = df\ny = pd.Series(np.concatenate([np.zeros(n_trn,), np.ones(df.shape[0] - n_trn,)]))\np = np.zeros_like(y, dtype=float)\nfor i, (i_trn, i_val) in enumerate(cv.split(X, y)):\n    if i == 0:\n        clf = AutoLGB(objective='binary', metric='auc', random_state=seed)\n        clf.tune(X.iloc[i_trn], y[i_trn])\n        features = clf.features\n        params = clf.params\n        n_best = clf.n_best\n        print(f'{n_best}')\n        print(f'{params}')\n        print(f'{features}')\n    \n    trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn])\n    val_data = lgb.Dataset(X.iloc[i_val], y[i_val])\n    clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100)\n    p[i_val] = clf.predict(X.iloc[i_val])\n    print(f'CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}')","f5878bc4":"print(f'CV AUC: {roc_auc_score(y, p):.6f}')","94df4746":"# Reference: https:\/\/www.kaggle.com\/jeongyoonlee\/adversarial-validation-with-lightgbm by Jeong-Yoon Lee","45931d7a":"# \"Adversarial validation AUC score is close to 50%. Therefore, we can say that the training and test data sets are similar in terms of feature distributions. In other words, no big shake-up expected at the end of the competition. :)\""}}