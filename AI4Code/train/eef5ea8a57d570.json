{"cell_type":{"ee3d7ab8":"code","04be1a4a":"code","8aab06a6":"code","9985c155":"code","7966c3db":"code","34eb01b1":"code","9138545a":"code","1014dda2":"code","f31948dc":"code","b154db06":"code","9383d1ad":"code","aa6ff032":"code","99eeb9e7":"code","b6e81559":"code","4c5f6e7f":"code","c58de0c1":"code","7ff3a071":"code","f97b49bd":"code","1e5eca0d":"code","ec95a9f1":"code","76dc25b2":"markdown","3bc294c2":"markdown","dc45ec6c":"markdown","b57d6b99":"markdown","90d3d286":"markdown","3e2ddfc2":"markdown","0cc68706":"markdown","2d582d16":"markdown","390b8cc2":"markdown","362cca3a":"markdown"},"source":{"ee3d7ab8":"import pandas as pd\nimport numpy as np","04be1a4a":"# file path\npath_train = '\/kaggle\/input\/titanic\/train.csv'\npath_test = '\/kaggle\/input\/titanic\/test.csv'\n\n# loading CSV\ndata = pd.read_csv(path_train)\ndata_test = pd.read_csv(path_test)","8aab06a6":"# checking index and columns\n\ndata.head()","9985c155":"# checking number of records, data types and number of non null elements\n\ndata.info()\nprint('*****')\ndata_test.info()","7966c3db":"# checking number of null elements\n\nprint(data.isnull().sum())\nprint('*****')\nprint(data_test.isnull().sum())","34eb01b1":"#statistical report of numerical columns\n\ndata.describe()\n# data.describe(include='object')","9138545a":"#removing uninformative columns\ndata = data.drop(['Ticket', 'Name', 'PassengerId', 'Cabin'], axis=1)\n\n# adding new column\ndata['Alone'] = (data.Parch + data.SibSp).map(lambda x : x == 0).astype('float64') # checking if passenger was alone or not\n\ndata.head()","1014dda2":"# survival rate for single people vs. people with family\nax = pd.crosstab(data.Alone, data.Survived).plot.bar(stacked=True)","f31948dc":"# survival rate in different classes\nax = pd.crosstab(data.Pclass, data.Survived).plot.bar(stacked=True)\n\n# class rate in survival groups\nax = pd.crosstab(data.Survived, data.Pclass).plot.bar(stacked=True)","b154db06":"# gender rate in survival groups\nax = pd.crosstab(data.Survived, data.Sex).plot.bar(stacked=True)\n\n# survival rate in gender groups\nax = pd.crosstab(data.Sex, data.Survived).plot.bar(stacked=True)","9383d1ad":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline","aa6ff032":"# loading CSV\ndata_train = pd.read_csv(path_train)\ndata_test = pd.read_csv(path_test)\n\n# keeping index of test dataset\nsubmission_index = data_test.PassengerId","99eeb9e7":"#removing uninformative columns\ndata_train = data_train.drop(['Ticket', 'Name', 'PassengerId', 'Cabin'], axis=1)\ndata_test = data_test.drop(['Ticket', 'Name', 'PassengerId', 'Cabin'], axis=1)\n\n\n\ndata_train.groupby(\"Embarked\").Embarked.count()\n#Most of the Embarked values are from Southampton(S).\ndata_train['Embarked']=data_train['Embarked'].fillna('S')\ndisplay(data_train.isnull().sum())\n\n\n","b6e81559":"#As we can see Age and Pclass have a high corelation.\n#Using median age of the Pclass to missing age will be benefitial rather using median of whole data set. \n\ndata_train.groupby(['Sex', 'Pclass'])['Age'].median()\n\n\ndata_train['Age'] = data_train.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n\ndisplay(data_train.isnull().sum())\n\n# editing column types\ndata_train['Sex'] = data_train.Sex.map({'male': 1, 'female': 0}).astype('float64') # binary gender representation\ndata_test['Sex'] = data_test.Sex.map({'male': 1, 'female': 0}).astype('float64')\ndata_train['Parch'] = (data_train.Parch >= 1).astype('float64') # binary parch representation\ndata_test['Parch'] = (data_test.Parch >= 1).astype('float64')\ndata_train['SibSp'] = (data_train.SibSp >= 1).astype('float64') # binary sibsp representation\ndata_test['SibSp'] = (data_test.SibSp >= 1).astype('float64')\n\ndata_train.head()","4c5f6e7f":"\n# transformation for categorical column\ntransformer_cat = Pipeline(steps =[('imputer', SimpleImputer(strategy= 'most_frequent')),\n                                   ('onehot', OneHotEncoder(handle_unknown= 'ignore'))\n                                  ])\n# transformation for numerical column\ntransformer_num = Pipeline(steps= [('imputer', SimpleImputer(strategy= 'mean')),\n                                   ('standard', StandardScaler())\n                                  ])\n\n# transformation for age column\ntransformer_age = Pipeline(steps= [('imputer', SimpleImputer(strategy= 'constant', fill_value= -10)),\n                                   ('biner', KBinsDiscretizer(n_bins= 9, encode= 'onehot-dense', strategy= 'uniform'))\n                                  ])\n# transformation package\npreprocessor = ColumnTransformer(transformers= [('categorical', transformer_cat, ['Pclass', 'Embarked']),\n                                                ('numerical', transformer_num, ['Fare']),\n                                                ('age', transformer_age, ['Age']) ], remainder= 'passthrough')","c58de0c1":"# backup to keep data files unchanged\nX = data_train.copy() # creating a copy\nX_test = data_test.copy()\n\n\n# splitting to dependent and independent features\ny = X.Survived.values # target vector \/ dependent feature\nX = X.drop('Survived', axis=1) # independent features","7ff3a071":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import confusion_matrix, accuracy_score","f97b49bd":"# model definition\nmodels = {'Logistic Regression': LogisticRegression(),\n          'Random Forest': RandomForestClassifier(n_estimators= 50, max_leaf_nodes= 25)}\n\nmodel_pipeline = Pipeline(steps= [('preprocessor', preprocessor),\n                                  ('model', models['Logistic Regression'])])\n\n# cross validation\nscores = cross_validate(model_pipeline, X, y, cv= 5,\n                        scoring= 'accuracy', return_train_score= True)\nprint('Train Accuracy', round(scores['train_score'].mean() * 100, 2), '%')\nprint('Validation Accuracy', round(scores['test_score'].mean() * 100, 2), '%')","1e5eca0d":"#fitting on full data\nmodel_pipeline.fit(X, y)\n\n# predicting the full data to check its result\npred = model_pipeline.predict(X)\nprint(round(accuracy_score(y, pred) * 100, 2), '%')\n\n# confusion matrix \ncm = pd.DataFrame(confusion_matrix(y, pred), index = ['Really Died', 'Really Survived'], columns = ['Died', 'Survived'])\nprint(cm)\n","ec95a9f1":"# predicting the test data for submission\nsubmission_prediction = model_pipeline.predict(X_test)\n\n# creating output dataframe in a format of competition\noutput = pd.DataFrame({'PassengerId': submission_index, 'Survived': submission_prediction})\noutput.to_csv('submission.csv', index=False) # exporting CSV file","76dc25b2":"## Model Selection & Validation","3bc294c2":"## Loading Data","dc45ec6c":"## Dataset Modifying","b57d6b99":"## Predicting Test Data","90d3d286":"**factors which have the most effect on survival :**\n1. age people between 20-30 has the most survivng \n2.p-class also has an effect since class 3 has small amount of survivals \n3. gender**","3e2ddfc2":"## Full Training","0cc68706":"## Data Preproccessing","2d582d16":"## EDA","390b8cc2":"## Checking Data","362cca3a":"## Filling missing values"}}