{"cell_type":{"aebb1aab":"code","240e6d92":"code","c7905e31":"code","40b69e61":"code","3a7f8e83":"code","3a14b48b":"code","42d2b1b3":"code","302b6d60":"code","9836ade6":"code","fd357ef5":"code","42f6dc81":"code","3fabd70f":"code","65338776":"code","c0af1edf":"code","fbd71a97":"code","94b0b487":"code","66877507":"code","135c998d":"code","9cd3870b":"code","96fbc65d":"code","bd2d78c7":"code","55be0b34":"code","a3adc009":"code","cceca477":"code","154f0ee3":"code","8d407ab3":"code","88584c79":"code","329c6045":"code","33313a12":"code","be8756c8":"code","1c79e1ab":"code","39a03afd":"code","555bcb9f":"code","3fab86ce":"code","9c4c6301":"code","a7653317":"code","a569e96a":"code","8880bcba":"code","fd739992":"code","316de23b":"code","79ef59dd":"code","82f0375b":"code","a5dece25":"code","ed7215a2":"code","25261f8e":"code","3f3f483e":"code","4596e796":"code","3dbc292e":"code","2a828651":"code","638183e6":"code","1735c3bc":"code","9cab23d4":"code","336f45ce":"code","54fb398c":"code","8d047201":"code","20aba8b9":"code","267ed48a":"code","ed9a1346":"code","d5fd0fa3":"code","d6e23c27":"code","6eacd26c":"code","975b0780":"code","dac5ca5d":"code","ac355ec3":"code","2d0fdec3":"code","880c5238":"code","9170d2c0":"code","daa52697":"code","b332e2de":"code","72555fce":"code","7b001a86":"code","c4756122":"code","1efc3643":"code","12b938ae":"code","03cbcafd":"code","e5ae630e":"code","bcf66d07":"code","52cbfb4c":"code","72eb3712":"code","0e72e801":"code","774ad852":"code","4f2fde59":"code","ad533153":"code","8df5fc50":"code","1ea28282":"code","918d9791":"code","ff736235":"code","d8bc4fca":"code","1914d3c9":"code","8951ca06":"code","f4631d1f":"code","766db1b2":"code","5bf45d4b":"code","b8c75ad9":"code","071a3ac3":"code","fb68a6ae":"code","98053263":"code","cac13d06":"code","2b7df704":"code","2caa035b":"code","11baab65":"code","61a83cbf":"code","274fabbb":"code","399dd440":"code","e8ce1bb0":"code","2673eae5":"code","0c025e99":"code","b01582a7":"code","4fc3cbfc":"code","6fff77aa":"code","c7df25d9":"code","40799839":"code","44011711":"code","02f5dbb3":"code","43275f4f":"code","14e0688b":"code","6bab5036":"markdown","02c204a2":"markdown","6a30ae87":"markdown","53f5fb65":"markdown","348ef6d8":"markdown","e9569ef3":"markdown","2a9faee3":"markdown","742f4857":"markdown","206a165e":"markdown","94ac943a":"markdown","cf760558":"markdown","f866826d":"markdown","f5b5ae88":"markdown"},"source":{"aebb1aab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","240e6d92":"import matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nimport optuna","c7905e31":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntrain_data.shape","40b69e61":"train_data.head()","3a7f8e83":"X = train_data.drop('label',axis=1)\ny = train_data[['label']]","3a14b48b":"X.head()","42d2b1b3":"y.head()","302b6d60":"y.shape","9836ade6":"y = to_categorical(y)","fd357ef5":"y.shape","42f6dc81":"y[0]","3fabd70f":"y[3]","65338776":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=100)","c0af1edf":"X_train","fbd71a97":"X_test","94b0b487":"y_train","66877507":"y_test","135c998d":"X.max().unique()","9cd3870b":"X.min().unique()","96fbc65d":"X_train=X_train\/255\nX_test=X_test\/255","bd2d78c7":"X_train","55be0b34":"X_test","a3adc009":"\nX_train = X_train.values.reshape( -1 , 28 , 28 , 1)\nX_test = X_test.values.reshape( -1 , 28 , 28 , 1)","cceca477":"X_train.shape","154f0ee3":"X_test.shape","8d407ab3":"plt.imshow(X_train[10],cmap='gray')","88584c79":"plt.imshow(X_train[100],cmap='gray')","329c6045":"#Sequential API\nmodel = Sequential()\n#Convolutional layer\nmodel.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())    \nmodel.add(Dense(128,activation='relu'))\n#output layer multiclass hence softmax layer\nmodel.add(Dense(10,activation='softmax'))","33313a12":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","be8756c8":"early_stop = EarlyStopping(monitor='value_loss',patience=1)","1c79e1ab":"model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),callbacks=[early_stop])","39a03afd":"metrics = pd.DataFrame(model.history.history)","555bcb9f":"metrics[[\"loss\",\"val_loss\"]].plot()","3fab86ce":"metrics[[\"accuracy\",\"val_accuracy\"]].plot()","9c4c6301":"model.metrics_names","a7653317":"model.evaluate(X_test,y_test,verbose=0)","a569e96a":"preds = model.predict(X_test)","8880bcba":"preds","fd739992":"preds = preds.astype('int32')","316de23b":"preds","79ef59dd":"y_test","82f0375b":"print(classification_report(y_test, preds))","a5dece25":"model_score = model.evaluate(X_test, y_test, verbose=0)\nprint('validation loss:', model_score[0])\nprint('validation accuracy:', model_score[1])","ed7215a2":"test_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\ntest_data.shape","25261f8e":"test_data = test_data \/ 255","3f3f483e":"test_data = test_data.values.reshape( -1 , 28 , 28 , 1)","4596e796":"test_data.shape","3dbc292e":"plt.imshow(test_data[0],cmap='gray')","2a828651":"plt.imshow(test_data[10],cmap='gray')","638183e6":"test_preds = model.predict(test_data)","1735c3bc":"test_preds","9cab23d4":"test_preds.shape","336f45ce":"preds = np.argmax(test_preds , axis = 1)\ntest_image_id = range( 1 , len(preds)+1 )","54fb398c":"preds","8d047201":"len(test_image_id)\n","20aba8b9":"submit_df = {\"Id\" : test_image_id , \"Label\" : preds }\nsubmit_df = pd.DataFrame(submit_df)","267ed48a":"submit_df.head()","ed9a1346":"submit_df.to_csv('submission.csv',index=False) ","d5fd0fa3":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),activation = 'relu',input_shape=(28,28,1),)) # 32 filters and each filter is 3 by 3\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","d6e23c27":"model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])","6eacd26c":"model.summary()","975b0780":"model.fit(X_train,y_train,epochs=10,batch_size=128,validation_data=(X_test,y_test))","dac5ca5d":"metrics = pd.DataFrame(model.history.history)","ac355ec3":"metrics[[\"loss\",\"val_loss\"]].plot()","2d0fdec3":"metrics[[\"accuracy\",\"val_accuracy\"]].plot()","880c5238":"preds = model.predict(X_test)\npreds=preds.astype('int32')","9170d2c0":"print(classification_report(y_test, preds))","daa52697":"test_preds = model.predict(test_data)","b332e2de":"test_preds","72555fce":"test_preds.shape","7b001a86":"preds = np.argmax(test_preds , axis = 1)\ntest_image_id = range( 1 , len(preds)+1 )\npreds","c4756122":"len(test_image_id)","1efc3643":"submission = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission.head()","12b938ae":"submit_df = {\"ImageId\" : test_image_id , \"Label\" : preds }\nsubmit_df = pd.DataFrame(submit_df)","03cbcafd":"submit_df","e5ae630e":"submit_df.to_csv('submission.csv',index=False) # 0.98375","bcf66d07":"model = Sequential()\nmodel.add(Conv2D(32,(3,3), activation='relu',input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(64,(3,3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(10,activation='softmax'))","52cbfb4c":"model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])","72eb3712":"model.summary()","0e72e801":"model.fit(X_train,y_train,epochs=10,batch_size=128,validation_data=(X_test,y_test))","774ad852":"metrics = pd.DataFrame(model.history.history)","4f2fde59":"metrics[[\"loss\",\"val_loss\"]].plot() # by second epoch validation loss came down then going up and down and up which is sign of overfitting","ad533153":"metrics[[\"accuracy\",\"val_accuracy\"]].plot() # similarly accuracy increased then by 5th epoch the accuracy increased then going down and up","8df5fc50":"preds = model.predict(X_test)\npreds=preds.astype('int32')","1ea28282":"print(classification_report(y_test, preds))","918d9791":"test_preds = model.predict(test_data)\ntest_preds","ff736235":"test_preds.shape","d8bc4fca":"preds = np.argmax(test_preds , axis = 1)\ntest_image_id = range( 1 , len(preds)+1 )\npreds","1914d3c9":"len(test_image_id)","8951ca06":"submit_df = {\"ImageId\" : test_image_id , \"Label\" : preds }\nsubmit_df = pd.DataFrame(submit_df)","f4631d1f":"submit_df","766db1b2":"submit_df.to_csv('submission.csv',index=False) # 0.98642 stacking multiple convolutional layers didnot increase the accuracy tremendously.","5bf45d4b":"# objective function\n\ndef objective(trial):\n\n    # Keras Sequential model.\n    model = Sequential()\n\n    # Convolutional layers.\n\n    # the number of convolution layers\n    n_conv_layers = trial.suggest_int('n_conv_layers', 1, 3)\n\n    for i in range(n_conv_layers):\n        \n        # sample different filters, kernels, stride for each convolutional layer\n\n        model.add(Conv2D(\n            filters=trial.suggest_categorical('filters_{}'.format(i), [16, 32, 64]),\n            kernel_size=trial.suggest_categorical('kernel_size{}'.format(i), [3, 5]),\n            strides=trial.suggest_categorical('strides{}'.format(i), [1, 2]),\n            activation='relu',\n            padding='same',\n        ))\n\n    # Max Pooling\n    model.add(MaxPool2D(pool_size=2, strides=2))\n\n    # Flattening for the dense layer\n    model.add(Flatten())\n\n    # fully-connected Dense layers.\n    # The number of layers is a hyper-parameter we want to optimize.\n\n    n_dense_layers = trial.suggest_int('n_dense_layers', 1, 3)\n\n    for i in range(n_dense_layers):\n\n        # we want to optimize the number of nodes (neurons) and the activation function.\n        model.add(Dense(\n            units=trial.suggest_int('units{}'.format(i), 5, 512),\n            activation=trial.suggest_categorical(\n                'activation{}'.format(i), ['relu', 'tanh']),\n        ))\n\n    # the softmax layer for classification\n    model.add(Dense(10, activation='softmax'))\n\n    # the optimizer \n    optimizer_name = trial.suggest_categorical(\n        'optimizer_name', ['Adam', 'RMSprop'])\n\n    if optimizer_name == 'Adam':\n        optimizer = Adam(learning_rate=trial.suggest_float('learning_rate',  1e-6, 1e-2))\n    else:\n        optimizer = RMSprop(\n            learning_rate=trial.suggest_float('learning_rate',  1e-6, 1e-2),\n            momentum=trial.suggest_float('momentum',  0.1, 0.9),\n        )\n\n    # In Keras we need to compile the model so it can be trained.\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    # model training\n    history = model.fit(\n        x=X_train,\n        y=y_train,\n        epochs=5,\n        batch_size=128,\n        validation_split=0.1,\n    )\n\n    # Get the classification accuracy on the validation-set\n    # after the last training-epoch.\n    accuracy = history.history['val_accuracy'][-1]\n\n    return accuracy","b8c75ad9":"study = optuna.create_study(\n    direction='maximize'\n)\n\nstudy.optimize(objective, n_trials=10)","071a3ac3":"study.best_params","fb68a6ae":"study.best_value","98053263":"#Sequential API\nmodel = Sequential()\n#Convolutional layer\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),input_shape=(28,28,1),activation='relu'))\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#Convolutional layer\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),activation='relu'))\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())    \nmodel.add(Dense(242,activation='relu'))\nmodel.add(Dense(27,activation='tanh'))\n#output layer multiclass hence softmax layer\nmodel.add(Dense(10,activation='softmax'))","cac13d06":"opt = Adam(learning_rate=0.004618995519239905)\nmodel.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])","2b7df704":"model.summary()","2caa035b":"model.fit(X_train,y_train,epochs=10,batch_size=128,validation_data=(X_test,y_test))","11baab65":"metrics = pd.DataFrame(model.history.history)","61a83cbf":"metrics[[\"loss\",\"val_loss\"]].plot() # by second epoch validation loss came down then going up and down and up which is sign of overfitting","274fabbb":"metrics[[\"accuracy\",\"val_accuracy\"]].plot() # similarly accuracy increased then by 5th epoch the accuracy increased then going down and up","399dd440":"preds = model.predict(X_test)\npreds","e8ce1bb0":"preds.shape","2673eae5":"preds = np.argmax(preds , axis = 1)\npreds","0c025e99":"preds.shape","b01582a7":"y_test = np.argmax(y_test , axis = 1)\ny_test","4fc3cbfc":"print(classification_report(y_test, preds))","6fff77aa":"test_preds = model.predict(test_data)\ntest_preds","c7df25d9":"test_preds.shape","40799839":"preds = np.argmax(test_preds , axis = 1)\ntest_image_id = range( 1 , len(preds)+1 )\npreds","44011711":"len(test_image_id)","02f5dbb3":"submit_df = {\"ImageId\" : test_image_id , \"Label\" : preds }\nsubmit_df = pd.DataFrame(submit_df)","43275f4f":"submit_df","14e0688b":"submit_df.to_csv('submission.csv',index=False) # 0.98607","6bab5036":"# Model","02c204a2":"# Hyperparameter tuning with Optuna","6a30ae87":"# Test data","53f5fb65":"#### Reading link\n#### https:\/\/github.com\/deadskull7\/MNIST-digit-recognition-and-classification-using-CNN-with-Keras-99.70\/blob\/master\/MNIST%20digit%20recognition%20%5B0.9932%5D.ipynb","348ef6d8":"# CNN Model3 ","e9569ef3":"# Training data","2a9faee3":"# CNN Model2","742f4857":"# Reshaping","206a165e":"# Scaling","94ac943a":"#### preds contains the predicted labels of the digits .\u00b6\n#### argmax(axis = 1) is converting the one hot encoder back to the labels along the row axis","cf760558":"# Libraries","f866826d":"# Evaluation","f5b5ae88":"#### Reading refrence .... Hyperoptimization Udemy"}}