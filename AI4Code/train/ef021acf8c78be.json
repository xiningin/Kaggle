{"cell_type":{"5323d947":"code","a17ce8ea":"code","95b02ca6":"code","53121dcf":"code","720fa6bd":"code","fe3ec066":"code","ac4f17b6":"code","e0e83013":"code","5dc811f6":"code","eb741dff":"code","98d1e572":"code","5dee3003":"code","539c1b3a":"code","16cf3843":"markdown","66729725":"markdown","45be2b08":"markdown"},"source":{"5323d947":"import os\nos.mkdir('\/kaggle\/working\/image_data')\nos.mkdir('\/kaggle\/working\/image_data\/abnormal')\nos.mkdir('\/kaggle\/working\/image_data\/normal')","a17ce8ea":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport wave\nimport pylab\nfrom pathlib import Path\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n#plt.style.use('dark_background')\n\ninput_directory = '..\/input\/heartbeat\/data'                              #Input directory where the wav files are stored\n","95b02ca6":"parent_list_temp = os.listdir(input_directory)\nparent_list = []\n\nfor i in range(len(parent_list_temp)) :\n    if(parent_list_temp[i].endswith(\".wav\")):\n        parent_list.append(parent_list_temp[i])\n    \nfor i in range(10):\n    \n    if(parent_list[i].endswith(\".wav\")):\n        file_name = parent_list[i][0:5]\n        \n        if(file_name[0] == 'e'):\n              file_name = parent_list[i][0:6]\n        \n        with open(input_directory+'\/'+file_name+'.hea') as f:\n            lines = f.read().splitlines()\n            last_line = lines[-1].split()[1]\n            print(file_name + \" \" + last_line)","53121dcf":"def get_wav_info(wav_file):\n    wav = wave.open(wav_file, 'r')\n    frames = wav.readframes(-1)\n    sound_info = pylab.frombuffer(frames, 'int16')\n    frame_rate = wav.getframerate()\n    wav.close()\n    return sound_info, frame_rate\ndef Limit(S,Fs,T):\n    if(len(S)\/Fs>=T):\n        S=S[:T*Fs]\n    else:\n        for i in range(len(S),T*Fs):\n            S=np.append(S,0)\n    return S        \n\n# Plot first 5 WAV files as a waveform and a frequency spectrum\nfor i in range(5): \n    \n    signal_wave,fs = get_wav_info(os.path.join(input_directory, parent_list[i]))\n    signal_wave=Limit(signal_wave,fs,10)\n    max_data = np.max(signal_wave)\n    min_data = np.min(signal_wave)\n    signal_wave = (signal_wave - min_data)\/(max_data - min_data + 0.0001)\n                    \n                    \n    plt.figure(figsize=(12,12))\n    plot_a = plt.subplot(211)\n    plot_a.set_title(parent_list[i])\n    plot_a.plot(signal_wave)\n    plot_a.set_xlabel('sample rate * time')\n    plot_a.set_ylabel('energy')\n\n    plot_b = plt.subplot(212)\n    plot_b.specgram(signal_wave, NFFT=1024, Fs=fs, noverlap=900)\n    plot_b.set_xlabel('Time')\n    plot_b.set_ylabel('Frequency')\n\nplt.show()","720fa6bd":"# Utility function to get sound and frame rate info\ndef get_wav_info(wav_file):\n    wav = wave.open(wav_file, 'r')\n    frames = wav.readframes(-1)\n    sound_info = pylab.frombuffer(frames, 'int16')\n    frame_rate = wav.getframerate()\n    wav.close()\n    return sound_info, frame_rate\n\ndef get_class(hea_file):\n    #Reading the corresponding header file\n    with open(input_directory+'\/'+hea_file+'.hea') as f:\n            lines = f.read().splitlines()\n            last_line = lines[-1].split()[1]\n            \n    return last_line\n\n#To limit the signal to T seconds\ndef Limit(S,Fs,T):\n    if(len(S)\/Fs>=T):\n        S=S[:T*Fs]\n    else:\n        for i in range(len(S),T*Fs):\n            S=np.append(S,0)\n    return S        \n   \n\noutput_directory = '.\/image_data\/'                                     #Output directory where the images of spectogram are stored\nfor filename in parent_list:\n    if \"wav\" in filename:                                              #Making sure only wav files are read\n        file_path = os.path.join(input_directory, filename)\n        file_stem = Path(file_path).stem\n\n        target_dir = f'{get_class(file_stem)}'                         #Getting the target directory\n        \n        dist_dir = output_directory+target_dir.lower()\n        \n        file_dist_path = os.path.join(dist_dir, file_stem)\n        \n        if not os.path.exists(file_dist_path + '.png'):\n            file_stem = Path(file_path).stem\n            sound_info, frame_rate = get_wav_info(file_path)\n            sound_info=Limit(sound_info,frame_rate,10)\n            max_data = np.max(sound_info)\n            min_data = np.min(sound_info)\n            norm_signal = (sound_info - min_data)\/(max_data - min_data + 0.0001)\n            norm_signal = norm_signal - 0.5\n            pylab.specgram(norm_signal, Fs=frame_rate)                #Converting signal to spectogram and saving as png\n            pylab.savefig(f'{file_dist_path}.png')\n            pylab.close()","fe3ec066":"#To read the images into an array\nfrom tqdm import tqdm\nimport cv2\n\n#Properties of image\nIMAGE_HEIGHT = 128\nIMAGE_WIDTH = 128\nBATCH_SIZE = 32\nN_CHANNELS = 3\n\n\n#Number of classes\nN_CLASSES = 2\n\nfrom sklearn.model_selection import train_test_split\nfrom skimage import transform\n\n\ndef load_data(data):\n    X = []\n    y = []\n    X1=[]\n    y1=[]\n    nct=0\n    \n    #To traverse every spectogram image in data \n    for file_type in os.listdir(data):\n        if not file_type.startswith('.'):\n        #It is binary classification so we have two classlabels 0 and 1 \n        #If ABNORMAL the label will be 1\n        #If NORMAL the label will be 0\n            if file_type in ['abnormal']:\n                label = 1\n            elif file_type in ['normal']:\n                label = 0\n            \n            #This loop is to traverse to every condition in train data\n            for filename in tqdm(os.listdir(data + '\/' + file_type)):\n                #To read every sound file in every folder\n                image = cv2.imread(data +'\/'+ file_type + '\/' + filename)\n                \n                #If the image is found\n                if image is not None :\n                    #To resize the random sized images into a fixed size of 128x128x3\n                    image = transform.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS))\n                    #Changing the datatype into array to process through the cnn algorithm\n                    image_data_as_arr = np.asarray(image)\n                    max_data = np.max(image_data_as_arr)\n                    min_data = np.min(image_data_as_arr)\n                    norm_signal = (image_data_as_arr - min_data)\/(max_data - min_data + 0.0001)\n                    norm_signal = norm_signal - 0.5\n                    #Appending the data in the empty lists of X and y\n                    X.append(norm_signal)\n                    y.append(label)\n#                     if(label==0):\n#                         if(nct<=680):\n#                             X1.append(norm_signal)\n#                             y1.append(label)\n#                         nct+=1\n#                     else:\n#                         X1.append(norm_signal)\n#                         y1.append(label)\n    X = np.asarray(X)\n    y = np.asarray(y)\n    return X,y\n\n\n#Loading the train and test data\nX_train, y_train = load_data(r'.\/image_data\/')","ac4f17b6":"#Plotting all the spectogram images\nplt.figure(figsize=(12, 12))\n\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(X_train[i])\n    plt.title(int(y_train[i]))\n    plt.axis(\"off\")\nplt.show()","e0e83013":"#Splitting the train and test data\nxTrain, xTest, yTrain, yTest = train_test_split(X_train, y_train, random_state=42, test_size=0.2)\nfrom keras.utils.np_utils import to_categorical\n\n#One hot encoding the labels\ny_trainHot = np.uint8(to_categorical(yTrain, num_classes = 2))\ny_testHot = np.uint8(to_categorical(yTest, num_classes = 2))\n\nX_train1=[]\ny_train1=[]\nF=np.argwhere(y_train==0)                 #Taking Indexes where condition is normal\nG=np.argwhere(y_train==1)\nimport random\nX=random.sample(list(F),len(G))          #Sampling from those indexes such that size is same as abnormal\nfor i in X:\n    X_train1.append(X_train[i[0]])\n    y_train1.append(1)\nfor j in G:\n    X_train1.append(X_train[j[0]])\n    y_train1.append(0)\nX_train1=np.array(X_train1)\ny_train1=np.array(y_train1)\n\n\n#Splitting the train and test data\nxTrain1, xTest1, yTrain1, yTest1 = train_test_split(X_train1, y_train1, random_state=42, test_size=0.2)\n\n#One hot encoding the labels\ny_trainHot1 = np.uint8(to_categorical(yTrain1, num_classes = 2))\ny_testHot1 = np.uint8(to_categorical(yTest1, num_classes = 2))\n\n\n","5dc811f6":"#The main CNN architecture\nimport keras\nfrom keras import models\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, MaxPool2D\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n#The binary labels for our CNN model in the form of a dictionary\nbin_labels = {0:'Normal',1:'Abnormal'}\n\ndef CNN(imgs,img_labels,test_imgs,test_labels,stride):\n    \n    #Number of classes (2)\n    num_classes = len(img_labels[0])\n    \n    epochs = 20\n    \n    #Size of image\n    img_rows,img_cols=imgs.shape[1],imgs.shape[2]\n    input_shape = (img_rows, img_cols, 3)\n    \n    #Creating the model\n    model = Sequential()\n    \n    #First convolution layer\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation='relu',\n                     input_shape=input_shape,\n                     strides=stride))\n    \n    #First maxpooling layer\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Dropout(0.2))\n    \n    #Second convolution layer\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    \n    #Second maxpooling layer\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    #Third convolution layer\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    \n    #Third maxpooling layer\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Dropout(0.2))\n    \n    #Convert the matrix to a fully connected layer\n    model.add(Flatten())\n    \n    #Dense function to convert FCL to 128 values\n    model.add(Dense(128, activation='relu'))\n    \n    model.add(Dropout(0.2))\n    \n    #Dense function to convert FCL to 128 values\n    model.add(Dense(128, activation='relu'))\n    \n    #Dense function to convert FCL to 128 values\n    model.add(Dense(128, activation='relu'))\n    \n    #Final dense layer on which softmax function is performed\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    #Model parameters\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adamax',\n                  metrics=['accuracy'])\n    \n    #Evaluate the model on the test data before training your model\n    score = model.evaluate(test_imgs,test_labels, verbose=1)\n    \n    print('\\nKeras CNN binary accuracy:', score[1],'\\n')\n    \n    #The model details\n    history = model.fit(imgs,img_labels,\n                        shuffle = True, \n                        epochs=epochs, \n                        validation_data = (test_imgs, test_labels))\n    \n    #Evaluate the model on the test data after training your model\n    score = model.evaluate(test_imgs,test_labels, verbose=1)\n    print('\\nKeras CNN binary accuracy:', score[1],'\\n')\n    \n    #Predict the labels from test data\n    y_pred = model.predict(test_imgs)\n    Y_pred_classes = np.argmax(y_pred,axis=1) \n    Y_true = np.argmax(test_labels,axis=1)\n    \n    #Correct labels\n    for i in range(len(Y_true)):\n        if(Y_pred_classes[i] == Y_true[i]):\n            print(\"The predicted class is : \" , Y_pred_classes[i])\n            print(\"The real class is : \" , Y_true[i])\n            break\n            \n    #The confusion matrix made from the real Y values and the predicted Y values\n    confusion_mtx = [Y_true, Y_pred_classes]\n    \n    #Summary of the model\n    model.summary()\n    \n    return model,confusion_mtx","eb741dff":"model,conf_mat = CNN(xTrain,y_trainHot,xTest,y_testHot,1)","98d1e572":"model1,conf_mat1 = CNN(xTrain1,y_trainHot1,xTest1,y_testHot1,1)","5dee3003":"#Predict the labels from test data\ny_pred = model.predict(xTest)\nY_pred_classes = np.argmax(y_pred,axis=1) \nY_true = np.argmax(y_testHot,axis=1)\n\nfrom sklearn.metrics import precision_recall_fscore_support\nprec,recall,f1,_ = precision_recall_fscore_support(Y_true,Y_pred_classes,average='binary')\n\nprint(\"Precision : \", prec)\nprint(\"Recall : \", recall)\nprint(\"F1 score : \", f1)","539c1b3a":"#Predict the labels from test data\ny_pred1 = model1.predict(xTest1)\nY_pred_classes1 = np.argmax(y_pred1,axis=1) \nY_true1 = np.argmax(y_testHot1,axis=1)\n\nfrom sklearn.metrics import precision_recall_fscore_support\nprec,recall,f1,_ = precision_recall_fscore_support(Y_true1,Y_pred_classes1,average='binary')\n\nprint(\"Precision : \", prec)\nprint(\"Recall : \", recall)\nprint(\"F1 score : \", f1)","16cf3843":"## Step 1 : Read all the .wav files and convert to spectogram and save as png in respective class folders","66729725":"# Performance Improvement in Deep Learning Architecture for Phonocardiogram Signal Classification using Spectrogram\n## Group 14\n\nDone by :\n* >CB.EN.U4AIE19016 \u2013 ASSWIN C R\n* >CB.EN.U4AIE19028 \u2013 AVINASH DORA\n* >CB.EN.U4AIE19044 \u2013 P S SAI GANESH\n* >CB.EN.U4AIE19060 \u2013 SIVA PRAKASH R\n\n\n","45be2b08":"## Step 2 : Read all images and convert them to numpy arrays and also the class labels\n\n#### 1. Read the image\n#### 2. Resize image to 128 x 128 x 3 \n#### 3. Normalize image by taking max and min values for each image\n#### 4. Oversample the respective class if needed (If no augmentation, 3rd input must be greater than number of classes)"}}