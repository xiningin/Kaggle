{"cell_type":{"160a0a7e":"code","14e660f8":"code","9325bb3d":"code","1386779b":"code","ed609c74":"code","7c2f6e7f":"code","a3e1f776":"code","cc232ea5":"code","3f92dea0":"code","58b0ee00":"code","a471372a":"code","52bd9b42":"code","85180354":"code","a66b7c4a":"code","db2b905f":"code","7e1f3e01":"code","9cdedfa6":"code","077e34ec":"code","0803ddbd":"code","5625ef5b":"code","714f9256":"code","5ccb9887":"code","507466bb":"code","287eed4e":"code","d022036f":"code","51789898":"code","7ff02dcf":"code","153ddeb2":"code","1650733d":"code","28acd174":"code","7829cdc6":"code","3884ed3c":"code","ff937ec9":"code","3b55da43":"code","6da7d598":"code","73e6c014":"code","7793a41b":"code","a9d822e1":"code","22d130c7":"code","85f9ba40":"code","afd82739":"code","878c73c4":"code","afedcdf4":"code","5c17e8f5":"code","cf58527f":"code","f0ebf601":"code","82bde2b2":"code","5b82804c":"code","edae19a8":"code","82aaea12":"code","4359f7dc":"code","0d1454df":"code","10ea0244":"code","6d2509b8":"code","297c0cae":"code","b01aaa3c":"code","d98e002f":"code","17fa0930":"code","c8c81650":"code","e3da8f04":"code","8895c379":"code","99c114a3":"code","6373c523":"code","d7b5b416":"code","069ea701":"code","1594eb72":"code","6831b897":"code","05fdbc2e":"code","b535a88a":"code","a79d3b96":"code","d645e48a":"code","cc8a8774":"code","e1094d49":"code","aca3b47f":"code","9246505a":"code","73213049":"code","ea8a9e6a":"markdown","7ba24cd8":"markdown","d139cc1a":"markdown","f18232f2":"markdown","2cc87a4e":"markdown","561f3fbb":"markdown","98ad9b5e":"markdown","0665cdb5":"markdown","1e19572a":"markdown","7e01e5a7":"markdown","ae165900":"markdown","b3077cab":"markdown","eb860556":"markdown","d7ddc3c7":"markdown","4d709d73":"markdown","75d4187d":"markdown","e5758d3d":"markdown","f070a6c1":"markdown","af1395da":"markdown","75949103":"markdown","86b81c8e":"markdown","477a002e":"markdown","be369a48":"markdown","dcc82e09":"markdown"},"source":{"160a0a7e":"# necessary imports \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\n%matplotlib inline\npd.set_option('display.max_columns', 26)","14e660f8":"# loading data\n\ndf= pd.read_csv('..\/input\/ckdisease\/kidney_disease.csv')\ndf.head()","9325bb3d":"df.shape","1386779b":"# dropping id column\ndf.drop('id', axis = 1, inplace = True)","ed609c74":"# rename column names to make it more user-friendly\n\ndf.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n              'aanemia', 'class']","7c2f6e7f":"df.head()","a3e1f776":"df.describe()","cc232ea5":"df.info()","3f92dea0":"# converting necessary columns to numerical type\n\ndf['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')\ndf['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')\ndf['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')","58b0ee00":"df.info()","a471372a":"# Extracting categorical and numerical columns\n\ncat_cols = [col for col in df.columns if df[col].dtype == 'object']\nnum_cols = [col for col in df.columns if df[col].dtype != 'object']","52bd9b42":"# looking at unique values in categorical columns\n\nfor col in cat_cols:\n    print(f\"{col} has {df[col].unique()} values\\n\")","85180354":"# replace incorrect values\n\ndf['diabetes_mellitus'].replace(to_replace = {'\\tno':'no','\\tyes':'yes',' yes':'yes'},inplace=True)\n\ndf['coronary_artery_disease'] = df['coronary_artery_disease'].replace(to_replace = '\\tno', value='no')\n\ndf['class'] = df['class'].replace(to_replace = {'ckd\\t': 'ckd', 'notckd': 'not ckd'})","a66b7c4a":"df['class'] = df['class'].map({'ckd': 0, 'not ckd': 1})\ndf['class'] = pd.to_numeric(df['class'], errors='coerce')","db2b905f":"cols = ['diabetes_mellitus', 'coronary_artery_disease', 'class']\n\nfor col in cols:\n    print(f\"{col} has {df[col].unique()} values\\n\")","7e1f3e01":"# checking numerical features distribution\n\nplt.figure(figsize = (20, 15))\nplotnumber = 1\n\nfor column in num_cols:\n    if plotnumber <= 14:\n        ax = plt.subplot(3, 5, plotnumber)\n        sns.distplot(df[column])\n        plt.xlabel(column)\n        \n    plotnumber += 1\n\nplt.tight_layout()\nplt.show()","9cdedfa6":"# looking at categorical columns\n\nplt.figure(figsize = (20, 15))\nplotnumber = 1\n\nfor column in cat_cols:\n    if plotnumber <= 11:\n        ax = plt.subplot(3, 4, plotnumber)\n        sns.countplot(df[column], palette = 'rocket')\n        plt.xlabel(column)\n        \n    plotnumber += 1\n\nplt.tight_layout()\nplt.show()","077e34ec":"# heatmap of data\n\nplt.figure(figsize = (15, 8))\n\nsns.heatmap(df.corr(), annot = True, linewidths = 2, linecolor = 'lightgrey')\nplt.show()","0803ddbd":"df.columns","5625ef5b":"# defining functions to create plot\n\ndef violin(col):\n    fig = px.violin(df, y=col, x=\"class\", color=\"class\", box=True, template = 'plotly_dark')\n    return fig.show()\n\ndef kde(col):\n    grid = sns.FacetGrid(df, hue=\"class\", height = 6, aspect=2)\n    grid.map(sns.kdeplot, col)\n    grid.add_legend()\n    \ndef scatter(col1, col2):\n    fig = px.scatter(df, x=col1, y=col2, color=\"class\", template = 'plotly_dark')\n    return fig.show()","714f9256":"violin('red_blood_cell_count')","5ccb9887":"kde('red_blood_cell_count')","507466bb":"violin('white_blood_cell_count')","287eed4e":"kde('white_blood_cell_count')","d022036f":"violin('packed_cell_volume')","51789898":"kde('packed_cell_volume')","7ff02dcf":"violin('haemoglobin')","153ddeb2":"kde('haemoglobin')","1650733d":"violin('albumin')","28acd174":"kde('albumin')","7829cdc6":"violin('blood_glucose_random')","3884ed3c":"kde('blood_glucose_random')","ff937ec9":"violin('sodium')","3b55da43":"kde('sodium')","6da7d598":"violin('blood_urea')","73e6c014":"kde('blood_urea')","7793a41b":"violin('specific_gravity')","a9d822e1":"kde('specific_gravity')","22d130c7":"scatter('haemoglobin', 'packed_cell_volume')","85f9ba40":"scatter('red_blood_cell_count', 'packed_cell_volume')","afd82739":"scatter('red_blood_cell_count', 'albumin')","878c73c4":"scatter('sugar', 'blood_glucose_random')","afedcdf4":"scatter('packed_cell_volume','blood_urea')","5c17e8f5":"px.bar(df, x=\"specific_gravity\", y=\"packed_cell_volume\", color='class', barmode='group', template = 'plotly_dark', height = 400)","cf58527f":"px.bar(df, x=\"specific_gravity\", y=\"albumin\", color='class', barmode='group', template = 'plotly_dark', height = 400)","f0ebf601":"px.bar(df, x=\"blood_pressure\", y=\"packed_cell_volume\", color='class', barmode='group', template = 'plotly_dark', height = 400)","82bde2b2":"px.bar(df, x=\"blood_pressure\", y=\"haemoglobin\", color='class', barmode='group', template = 'plotly_dark', height = 400)","5b82804c":"# checking for null values\n\ndf.isna().sum().sort_values(ascending = False)","edae19a8":"df[num_cols].isnull().sum()","82aaea12":"df[cat_cols].isnull().sum()","4359f7dc":"# filling null values, we will use two methods, random sampling for higher null values and \n# mean\/mode sampling for lower null values\n\ndef random_value_imputation(feature):\n    random_sample = df[feature].dropna().sample(df[feature].isna().sum())\n    random_sample.index = df[df[feature].isnull()].index\n    df.loc[df[feature].isnull(), feature] = random_sample\n    \ndef impute_mode(feature):\n    mode = df[feature].mode()[0]\n    df[feature] = df[feature].fillna(mode)","0d1454df":"# filling num_cols null values using random sampling method\n\nfor col in num_cols:\n    random_value_imputation(col)","10ea0244":"df[num_cols].isnull().sum()","6d2509b8":"# filling \"red_blood_cells\" and \"pus_cell\" using random sampling method and rest of cat_cols using mode imputation\n\nrandom_value_imputation('red_blood_cells')\nrandom_value_imputation('pus_cell')\n\nfor col in cat_cols:\n    impute_mode(col)","297c0cae":"df[cat_cols].isnull().sum()","b01aaa3c":"for col in cat_cols:\n    print(f\"{col} has {df[col].nunique()} categories\\n\")","d98e002f":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nfor col in cat_cols:\n    df[col] = le.fit_transform(df[col])","17fa0930":"df.head()","c8c81650":"ind_col = [col for col in df.columns if col != 'class']\ndep_col = 'class'\n\nX = df[ind_col]\ny = df[dep_col]","e3da8f04":"# splitting data intp training and test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)","8895c379":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of knn\n\nknn_acc = accuracy_score(y_test, knn.predict(X_test))\n\nprint(f\"Training Accuracy of KNN is {accuracy_score(y_train, knn.predict(X_train))}\")\nprint(f\"Test Accuracy of KNN is {knn_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, knn.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, knn.predict(X_test))}\")","99c114a3":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")","6373c523":"# hyper parameter tuning of decision tree \n\nfrom sklearn.model_selection import GridSearchCV\ngrid_param = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : [3, 5, 7, 10],\n    'splitter' : ['best', 'random'],\n    'min_samples_leaf' : [1, 2, 3, 5, 7],\n    'min_samples_split' : [1, 2, 3, 5, 7],\n    'max_features' : ['auto', 'sqrt', 'log2']\n}\n\ngrid_search_dtc = GridSearchCV(dtc, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_dtc.fit(X_train, y_train)","d7b5b416":"# best parameters and best score\n\nprint(grid_search_dtc.best_params_)\nprint(grid_search_dtc.best_score_)","069ea701":"# best estimator\n\ndtc = grid_search_dtc.best_estimator_\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")","1594eb72":"from sklearn.ensemble import RandomForestClassifier\n\nrd_clf = RandomForestClassifier(criterion = 'entropy', max_depth = 11, max_features = 'auto', min_samples_leaf = 2, min_samples_split = 3, n_estimators = 130)\nrd_clf.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of random forest\n\nrd_clf_acc = accuracy_score(y_test, rd_clf.predict(X_test))\n\nprint(f\"Training Accuracy of Random Forest Classifier is {accuracy_score(y_train, rd_clf.predict(X_train))}\")\nprint(f\"Test Accuracy of Random Forest Classifier is {rd_clf_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, rd_clf.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, rd_clf.predict(X_test))}\")","6831b897":"from sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(base_estimator = dtc)\nada.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of ada boost\n\nada_acc = accuracy_score(y_test, ada.predict(X_test))\n\nprint(f\"Training Accuracy of Ada Boost Classifier is {accuracy_score(y_train, ada.predict(X_train))}\")\nprint(f\"Test Accuracy of Ada Boost Classifier is {ada_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, ada.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(X_test))}\")","05fdbc2e":"from sklearn.ensemble import GradientBoostingClassifier\n\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of gradient boosting classifier\n\ngb_acc = accuracy_score(y_test, gb.predict(X_test))\n\nprint(f\"Training Accuracy of Gradient Boosting Classifier is {accuracy_score(y_train, gb.predict(X_train))}\")\nprint(f\"Test Accuracy of Gradient Boosting Classifier is {gb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, gb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, gb.predict(X_test))}\")","b535a88a":"sgb = GradientBoostingClassifier(max_depth = 4, subsample = 0.90, max_features = 0.75, n_estimators = 200)\nsgb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of stochastic gradient boosting classifier\n\nsgb_acc = accuracy_score(y_test, sgb.predict(X_test))\n\nprint(f\"Training Accuracy of Stochastic Gradient Boosting is {accuracy_score(y_train, sgb.predict(X_train))}\")\nprint(f\"Test Accuracy of Stochastic Gradient Boosting is {sgb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, sgb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, sgb.predict(X_test))}\")","a79d3b96":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(objective = 'binary:logistic', learning_rate = 0.5, max_depth = 5, n_estimators = 150)\nxgb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of xgboost\n\nxgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n\nprint(f\"Training Accuracy of XgBoost is {accuracy_score(y_train, xgb.predict(X_train))}\")\nprint(f\"Test Accuracy of XgBoost is {xgb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, xgb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, xgb.predict(X_test))}\")","d645e48a":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(iterations=10)\ncat.fit(X_train, y_train)","cc8a8774":"# accuracy score, confusion matrix and classification report of cat boost\n\ncat_acc = accuracy_score(y_test, cat.predict(X_test))\n\nprint(f\"Training Accuracy of Cat Boost Classifier is {accuracy_score(y_train, cat.predict(X_train))}\")\nprint(f\"Test Accuracy of Cat Boost Classifier is {cat_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, cat.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, cat.predict(X_test))}\")","e1094d49":"from sklearn.ensemble import ExtraTreesClassifier\n\netc = ExtraTreesClassifier()\netc.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of extra trees classifier\n\netc_acc = accuracy_score(y_test, etc.predict(X_test))\n\nprint(f\"Training Accuracy of Extra Trees Classifier is {accuracy_score(y_train, etc.predict(X_train))}\")\nprint(f\"Test Accuracy of Extra Trees Classifier is {etc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, etc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, etc.predict(X_test))}\")","aca3b47f":"from lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(learning_rate = 1)\nlgbm.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of lgbm classifier\n\nlgbm_acc = accuracy_score(y_test, lgbm.predict(X_test))\n\nprint(f\"Training Accuracy of LGBM Classifier is {accuracy_score(y_train, lgbm.predict(X_train))}\")\nprint(f\"Test Accuracy of LGBM Classifier is {lgbm_acc} \\n\")\n\nprint(f\"{confusion_matrix(y_test, lgbm.predict(X_test))}\\n\")\nprint(classification_report(y_test, lgbm.predict(X_test)))","9246505a":"models = pd.DataFrame({\n    'Model' : [ 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier','Ada Boost Classifier',\n             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting', 'XgBoost', 'Cat Boost', 'Extra Trees Classifier'],\n    'Score' : [knn_acc, dtc_acc, rd_clf_acc, ada_acc, gb_acc, sgb_acc, xgb_acc, cat_acc, etc_acc]\n})\n\n\nmodels.sort_values(by = 'Score', ascending = False)","73213049":"px.bar(data_frame = models, x = 'Score', y = 'Model', color = 'Score', template = 'plotly_dark', \n       title = 'Models Comparison')","ea8a9e6a":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>Skewness is present in some of the columns.<\/strong><\/p> ","7ba24cd8":"<a id = '5.4'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Ada Boost Classifier<\/strong><\/p>","d139cc1a":"<a id = '0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Table of Contents<\/strong><\/p> \n\n* [EDA](#2.0)\n* [Data Pre Processing](#3.0)\n* [Feature Encoding](#4.0)\n* [Model Building](#5.0)\n    * [Knn](#5.1)\n    * [Decision Tree Classifier](#5.2)\n    * [Random Forest Classifier](#5.3)\n    * [Ada Boost Classifier](#5.4)\n    * [Gradient Boosting Classifier](#5.5)\n    * [Stochastic Gradient Boosting (SGB)](#5.6)\n    * [XgBoost](#5.7)\n    * [Cat Boost Classifier](#5.8)\n    * [Extra Trees Classifier](#5.9)\n    * [LGBM Classifier](#5.10)\n\n* [Models Comparison](#6.0)","f18232f2":"<img style=\"margin-left: 10%; float: center;  border:5px solid #ffb037; width:80%; height : 80%;\" src = https:\/\/medicaldialogues.in\/h-upload\/2020\/12\/30\/145030-chronic-kidney-disease.jpg> ","2cc87a4e":"<a id = '6.0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Models Comparison<\/strong><\/p> ","561f3fbb":"<a id = '5.0'><\/a>\n<p style = \"font-size : 45px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Model Building<\/strong><\/p> ","98ad9b5e":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>There is some ambugity present in the columns we have to remove that.<\/strong><\/p> ","0665cdb5":"<p style = \"font-size : 25px; color : #f55c47 ; font-family : 'Comic Sans MS'; \"><strong>If you like my work, don't forget to leave an upvote!!<\/strong><\/p> ","1e19572a":"<a id = '5.10'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>LGBM Classifier<\/strong><\/p>","7e01e5a7":"<a id = '4.0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Feature Encoding<\/strong><\/p> ","ae165900":"<a id = '5.3'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Random Forest Classifier<\/strong><\/p>","b3077cab":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>As all of the categorical columns have 2 categories we can use label encoder<\/strong><\/p> ","eb860556":"<a id = '5.9'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Extra Trees Classifier<\/strong><\/p>","d7ddc3c7":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>All the missing values are handeled now, lets do ctaegorical features encding now<\/strong><\/p> ","4d709d73":"<a id = '5.8'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Cat Boost Classifier<\/strong><\/p>","75d4187d":"<a id = '2.0'><\/a>\n<p style = \"font-size : 40px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Exploratory Data Analysis (EDA)<\/strong><\/p> ","e5758d3d":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>As we can see that 'packed_cell_volume', 'white_blood_cell_count' and 'red_blood_cell_count'  are object type. We need to change them to numerical dtype.<\/strong><\/p> ","f070a6c1":"<a id = '5.7'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>XgBoost<\/strong><\/p>","af1395da":"<a id = '5.2'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Decision Tree Classifier<\/strong><\/p> ","75949103":"<a id = '5.1'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>KNN<\/strong><\/p> ","86b81c8e":"<a id = '3.0'><\/a>\n<p style = \"font-size : 40px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Data Pre Processing<\/strong><\/p> ","477a002e":"<a id = '5.5'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Gradient Boosting Classifier<\/strong><\/p>","be369a48":"<a id = '5.6'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Stochastic Gradient Boosting (SGB)<\/strong><\/p>","dcc82e09":"<p style = \"font-size : 50px; color : #532e1c ; font-family : 'Comic Sans MS'; text-align : center; background-color : #bedcfa; border-radius: 5px 5px;\"><strong>Chronic Kidney Disease Prediction<\/strong><\/p>"}}