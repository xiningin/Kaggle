{"cell_type":{"12af9df6":"code","36921f89":"code","02cc640c":"code","09a6db18":"code","a202928c":"code","5d625697":"code","2edf5c8e":"code","e56325e3":"code","77a4bff3":"code","849aa2d5":"code","36619fd9":"code","320401af":"code","1c62f052":"code","1fc62037":"code","d18ef9aa":"markdown","7f804269":"markdown"},"source":{"12af9df6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","36921f89":"import pandas as pd\nimport keras\nimport sklearn\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom dateutil.parser import parse\n\ndata = pd.read_csv('\/kaggle\/input\/population-time-series-data\/POP.csv', parse_dates=['date'], index_col='date')\ndata.reset_index(inplace=True)\n\ndata.head(3)","02cc640c":"data.index = pd.date_range(freq='D',start=data['date'][0], periods=len(data['date']))\nfrom matplotlib.pyplot import plot\n\ndata['value'].plot(color='k', title='Original Series')","09a6db18":"result_mul = seasonal_decompose(data['value'], model='multiplicative', extrapolate_trend='freq')\nresult_mul.plot()","a202928c":"result_add = seasonal_decompose(data['value'], model='additive', extrapolate_trend='freq')\nresult_add.plot()","5d625697":"from statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nplot_acf(data['value'].tolist(), lags=50)\n#plot_pacf(data['value'].tolist(), lags=50)","2edf5c8e":"from statsmodels.nonparametric.smoothers_lowess import lowess\n\n# 1. Moving Average\ndf_ma = data['value'].rolling(1000, center=True, closed='both').mean()\ndf_ma.plot(title='Moving Average')\ndf_std = data['value'].rolling(12, center=True, closed='both').std()\ndf_std.plot(title='Moving Average')\ndata['value'].plot(title='Moving Average')","e56325e3":"# 2. Loess Smoothing (5% and 15%)\ndf_loess_5 = pd.DataFrame(lowess(data['value'], np.arange(len(data['value'])), frac=0.05)[:, 1], index=data['date'], columns=['value'])\ndf_loess_15 = pd.DataFrame(lowess(data['value'], np.arange(len(data['value'])), frac=0.85)[:, 1], index=data['date'], columns=['value'])\n\n# Plot\ndf_loess_5['value'].plot(title='Loess Smoothed 5%')\ndf_loess_15['value'].plot(title='Loess Smoothed 85%')\n","77a4bff3":"#Stationarity test\nfrom statsmodels.tsa.stattools import adfuller\n\nprint('Results of Dickey-Fuller Test:')\ndftest = adfuller(data['value'], autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint(dfoutput)","849aa2d5":"diff = data['value'] - data['value'].shift()\ndf_ma = diff.rolling(40, center=True, closed='both').mean()\ndf_ma.plot(title='Moving Average')\ndf_std = diff.rolling(12, center=True, closed='both').std()\ndf_std.plot(title='Moving Average')\ndiff.plot(title='Moving Average')","36619fd9":"#seasonality\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.pylab as plt\n\ndiff.dropna(inplace=True)\ndecomposition = seasonal_decompose(diff)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.plot(diff,label='Original')\nplt.legend(loc='best')\nplt.plot(trend,label='Trend')\nplt.legend(loc='best')\nplt.plot(seasonal,label='Seasonal')\nplt.legend(loc='best')\nplt.plot(residual,label='Residual')\nplt.legend(loc='best')","320401af":"#let's try to predict now\nfrom statsmodels.tsa.arima_model import ARIMA\n\ndiff_trend = diff-trend\ndiff_trend.dropna(inplace=True)\n\nmodel = ARIMA(diff_trend,order=(1,1,0))\nresults_AR = model.fit(disp=-1)\n\nplt.plot(diff_trend,label='Original')\nplt.legend(loc='best')\nplt.plot(results_AR.fittedvalues,label='fit')\nplt.legend(loc='best')\nplt.title('RSS: %.4f'% sum((results_AR.fittedvalues-diff_trend)**2))","1c62f052":"model = ARIMA(diff_trend,order=(0,1,2))\nresults_MA = model.fit(disp=0)\n\nplt.plot(diff_trend,label='Original')\nplt.legend(loc='best')\nplt.plot(results_MA.fittedvalues,label='fit')\nplt.legend(loc='best')\nplt.title('RSS: %.4f'% sum((results_MA.fittedvalues-diff_trend)))","1fc62037":"#we can plot the predictions and extrapolate to the future\npredictions_ARIMA_diff = pd.Series(results_MA.fittedvalues,copy=True)\nplt.plot(predictions_ARIMA_diff,label='Fit')\n\n#how to extrapolate to the future?\ndate_rng = pd.date_range(start='1952-01-01', end='1958-01-01', freq='D')\n\noutput = results_MA.forecast()\nprint(output)\n\n\n#create a time series from a random generation\n#df = pd.DataFrame(date_rng, columns=['date'])\n#df['data'] = np.random.randint(0,100,size=(len(date_rng)))","d18ef9aa":"This is not stationary because :\n\n\u2022 mean is increasing even though the std is small.\n\n\u2022 Test stat is > critical value.","7f804269":"Dickey-fuller Test :This is one of the statistical tests for checking stationarity. First we consider the null hypothesis: the time series is non- stationary. The result from the rest will contain the test statistic and critical value for different confidence levels. The idea is to have Test statistics less than critical value, in this case we can reject the null hypothesis and say that this Time series is indeed stationary (the force is strong with this one !!)"}}