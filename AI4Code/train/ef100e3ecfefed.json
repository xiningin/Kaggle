{"cell_type":{"5a9823d4":"code","50f08566":"code","8a7896de":"code","5195fa0f":"code","b6063462":"code","0b4b6b76":"code","faf171f9":"code","ccce4a92":"code","2c3f9a05":"code","305c526d":"code","87c83808":"code","53a51e3f":"code","923be2cc":"code","b26d4d16":"markdown","8ec97605":"markdown","0ef1a8fc":"markdown","7ab4f6e9":"markdown"},"source":{"5a9823d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport spacy\nimport matplotlib.pyplot as plt\nimport re\nimport random\nfrom spacy.util import minibatch, compounding\n\n# Any results you write to the current directory are saved as output.","50f08566":"df_train = pd.read_csv('..\/input\/drugsComTrain_raw.csv')\ndf_train.head()","8a7896de":"comment_words = ' '\nstopwords = set(STOPWORDS) \nfor review in df_train['review']: \n    # typecaste each val to string \n    review = str(review).lower() \n    \n    # split the value \n    tokens = review.split()\n    comment_words = comment_words + ' '.join(tokens)","5195fa0f":"wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10).generate(comment_words) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show() ","b6063462":"df_train.shape","0b4b6b76":"drug_list = df_train['drugName'].value_counts().index.tolist()\ndrug_list = [x.lower() for x in drug_list]","faf171f9":"#First let's check some NERs in first 10 reviews and remove date, time, ordinal and cardinal.\nnlp = spacy.load('en_core_web_sm')\ncount = 0\nfor review in df_train['review']:\n    if count < 11:\n        doc = nlp(review)\n        ents = [(e.text, e.label_) for e in doc.ents if e.label_ not in ('DATE', 'TIME', 'ORDINAL', 'CARDINAL')]\n        print(ents)\n    count += 1","ccce4a92":"def process_review(review):\n    processed_token = []\n    for token in review.split():\n        token = ''.join(e.lower() for e in token if e.isalnum())\n        processed_token.append(token)\n    return ' '.join(processed_token)","2c3f9a05":"#Step 1: Let's create the training data\ncount = 0\nTRAIN_DATA = []\nfor _, item in df_train.iterrows():\n    ent_dict = {}\n    if count < 1000:\n        review = process_review(item['review'])\n        #We will find a drug and its positions once and add to the visited items.\n        visited_items = []\n        entities = []\n        for token in review.split():\n            if token in drug_list:\n                for i in re.finditer(token, review):\n                    if token not in visited_items:\n                        entity = (i.span()[0], i.span()[1], 'DRUG')\n                        visited_items.append(token)\n                        entities.append(entity)\n        if len(entities) > 0:\n            ent_dict['entities'] = entities\n            train_item = (review, ent_dict)\n            TRAIN_DATA.append(train_item)\n            count+=1","305c526d":"n_iter = 10\ndef train():\n    nlp = spacy.blank(\"en\")  # create blank Language class\n    print(\"Created blank 'en' model\")\n    \n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n        \n    # add labels\n    for _, annotations in TRAIN_DATA:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n            \n    nlp.begin_training()\n    for itn in range(n_iter):\n        random.shuffle(TRAIN_DATA)\n        losses = {}\n        # batch up the examples using spaCy's minibatch\n        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            nlp.update(\n                texts,  # batch of texts\n                annotations,  # batch of annotations\n                drop=0.5,  # dropout - make it harder to memorise data\n                losses=losses,\n            )\n        print(\"Losses\", losses)\n    return nlp","87c83808":"#Step 2: Let's train custom model with the training data\nnlp2 = train()","53a51e3f":"#Test the model\nfor text, _ in TRAIN_DATA[:10]:\n    doc = nlp2(text)\n    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])","923be2cc":"test_reviews = df_train.iloc[-10:, :]['review']\nfor review in test_reviews:\n    review = process_review(review)\n    print(review)\n    doc = nlp2(review)\n    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n    print('________________________')","b26d4d16":"# Let's see some of the important words in this corpus","8ec97605":"If we see the above entity extraction by built-in entities, we do not get proper extraction. So let's train the NER with custom data for DRUG.\n\n## Training SpaCy NER for DRUG","0ef1a8fc":"## In this kernel I am going to extract entities for a custom entity by training a model in SpaCy","7ab4f6e9":"## SpaCy recognizes the following built-in entity types:\n**PERSON** - People, including fictional.\n\n**NORP** - Nationalities or religious or political groups.\n\n**FAC** - Buildings, airports, highways, bridges, etc.\n\n**ORG** - Companies, agencies, institutions, etc.\n\n**GPE** - Countries, cities, states.\n\n**LOC** - Non-GPE locations, mountain ranges, bodies of water.\n\n**PRODUCT** - Objects, vehicles, foods, etc. (Not services.)\n\n**EVENT** - Named hurricanes, battles, wars, sports events, etc.\n\n**WORK_OF_ART** - Titles of books, songs, etc.\n\n**LAW** - Named documents made into laws.\n\n**LANGUAGE** - Any named language.\n\n**DATE** - Absolute or relative dates or periods.\n\n**TIME** - Times smaller than a day.\n\n**PERCENT** - Percentage, including \"%\".\n\n**MONEY** - Monetary values, including unit.\n\n**QUANTITY** - Measurements, as of weight or distance.\n\n**ORDINAL** - \"first\", \"second\", etc.\n\n**CARDINAL** - Numerals that do not fall under another type.\n\n## Along with these, we will train SpaCy NER to recognize drug names as new entity. We will train 10000 reviews with drug names as DRUG entity."}}