{"cell_type":{"75cf7822":"code","7cbf6ad4":"code","289386da":"code","c52b2854":"code","07eda49f":"code","c2f6e8b7":"code","c868156e":"code","5354c6ce":"code","ed7d6bc6":"code","b77025cf":"code","c5609539":"code","8cdafad0":"code","6ebfc663":"code","99aae2e6":"code","70d404fe":"code","0573bd2f":"code","984cbf5a":"markdown","1764699d":"markdown","06cdedfc":"markdown","bfb6397c":"markdown","59badce9":"markdown","d8c346eb":"markdown","865a27ac":"markdown","d6b439cd":"markdown","6e3a521a":"markdown","094e926e":"markdown","082d22e2":"markdown","7f2ce499":"markdown","06c97caf":"markdown","7566c13e":"markdown"},"source":{"75cf7822":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","7cbf6ad4":"rating_data = pd.read_csv(\"..\/input\/anime-recommendation-database-2020\/animelist.csv\",nrows=50000000)\nanima_data = pd.read_csv(\"..\/input\/anime-recommendation-database-2020\/anime.csv\")\n\n# To save my Pc time I made a new data where i just fetch anime_id(MAL_ID) and Name so that i can use merge() function on it.\nanima_data = anima_data.rename(columns={\"MAL_ID\": \"anime_id\"})\nanima_contact_data = anima_data[[\"anime_id\", \"Name\"]]","289386da":"rating_data = rating_data.merge(anima_contact_data, left_on = 'anime_id', right_on = 'anime_id', how = 'left')\nrating_data = rating_data[[\"user_id\", \"Name\", \"anime_id\",\"rating\", \"watching_status\", \"watched_episodes\"]]\nrating_data.head()","c52b2854":"rating_data.shape","07eda49f":"count = rating_data['user_id'].value_counts()\ncount1 = rating_data['anime_id'].value_counts()\nrating_data = rating_data[rating_data['user_id'].isin(count[count >= 500].index)].copy()\nrating_data = rating_data[rating_data['anime_id'].isin(count1[count1 >= 200].index)].copy()","c2f6e8b7":"rating_data.shape","c868156e":"combine_movie_rating = rating_data.dropna(axis = 0, subset = ['Name'])\nmovie_ratingCount = (combine_movie_rating.\n     groupby(by = ['Name'])['rating'].\n     count().\n     reset_index()\n     [['Name', 'rating']]\n    )\nmovie_ratingCount.head()","5354c6ce":"rating_data = combine_movie_rating.merge(movie_ratingCount, left_on = 'Name', right_on = 'Name', how = 'left')\nrating_data = rating_data.drop(columns = \"rating_x\")\nrating_data = rating_data.rename(columns={\"rating_y\": \"rating\"})\nrating_data","ed7d6bc6":"# Encoding categorical data\nuser_ids = rating_data[\"user_id\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuser_encoded2user = {i: x for i, x in enumerate(user_ids)}\nrating_data[\"user\"] = rating_data[\"user_id\"].map(user2user_encoded)\nn_users = len(user2user_encoded)\n\nanime_ids = rating_data[\"anime_id\"].unique().tolist()\nanime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}\nanime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}\nrating_data[\"anime\"] = rating_data[\"anime_id\"].map(anime2anime_encoded)\nn_animes = len(anime2anime_encoded)\n\nprint(\"Num of users: {}, Num of animes: {}\".format(n_users, n_animes))\nprint(\"Min total rating: {}, Max total rating: {}\".format(min(rating_data['rating']), max(rating_data['rating'])))","b77025cf":"g = rating_data.groupby('user_id')['rating'].count()\ntop_users = g.dropna().sort_values(ascending=False)[:20]\ntop_r = rating_data.join(top_users, rsuffix='_r', how='inner', on='user_id')\n\ng = rating_data.groupby('anime_id')['rating'].count()\ntop_animes = g.dropna().sort_values(ascending=False)[:20]\ntop_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='anime_id')\n\npivot = pd.crosstab(top_r.user_id, top_r.anime_id, top_r.rating, aggfunc=np.sum)","c5609539":"pivot.fillna(0, inplace=True)\npivot","8cdafad0":"piviot_table = rating_data.pivot_table(index=\"Name\",columns=\"user_id\", values=\"rating\").fillna(0)\npiviot_table","6ebfc663":"from scipy.sparse import csr_matrix\npiviot_table_matrix = csr_matrix(piviot_table.values)","99aae2e6":"from sklearn.neighbors import NearestNeighbors\nmodel = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\nmodel.fit(piviot_table_matrix)","70d404fe":"def predict():\n    random_anime = np.random.choice(piviot_table.shape[0]) # This will choose a random anime name and our model will predict on it.\n\n    query = piviot_table.iloc[random_anime, :].values.reshape(1, -1)\n    distance, suggestions = model.kneighbors(query, n_neighbors=6)\n    \n    for i in range(0, len(distance.flatten())):\n        if i == 0:\n            print('Recommendations for {0}:\\n'.format(piviot_table.index[random_anime]))\n        else:\n            print('{0}: {1}, with distance of {2}:'.format(i, piviot_table.index[suggestions.flatten()[i]], distance.flatten()[i]))","0573bd2f":"predict()","984cbf5a":"### We are now grouping rating_data by Name and rating into a new column movie_ratingCount.head()","1764699d":"## Screenshots of some more results\n1) ![](https:\/\/raw.githubusercontent.com\/everydaycodings\/files-for-multiplethings\/master\/recommandation_results\/Screenshot%202021-12-05%2013%3A18%3A39.png)<br>\n2) ![](https:\/\/raw.githubusercontent.com\/everydaycodings\/files-for-multiplethings\/master\/recommandation_results\/Screenshot%202021-12-05%2013%3A19%3A14.png)<br>\n3) ![](https:\/\/raw.githubusercontent.com\/everydaycodings\/files-for-multiplethings\/master\/recommandation_results\/Screenshot%202021-12-05%2013%3A19%3A44.png)<br>","06cdedfc":"#### Due to the limitation of The Pc Power I only took first 50million records. If you have access to a good workstation you can use all 109million records","bfb6397c":"### I will create a Predict() function so that every time I call this function it will recommend me the 5 most closest recommendations","59badce9":"# Introduction\n![](https:\/\/miro.medium.com\/max\/1000\/1*WxcROmxvYow2TJrJGXpwWQ.png)<br>\nsource:[medium.com](https:\/\/medium.com\/)\n\n## What is Recommendation Systems\nRecommender systems are the systems that are designed to recommend things to the user based on many different factors. These systems predict the most likely product that the users are most likely to purchase and are of interest to. Companies like Netflix, Amazon, etc. use recommender systems to help their users to identify the correct product or movies for them. \n\n \n\nThe recommender system deals with a large volume of information present by filtering the most important information based on the data provided by a user and other factors that take care of the user\u2019s preference and interest. It finds out the match between user and item and imputes the similarities between users and items for recommendation.\n\n\n**Collaborative filtering systems** use the actions of users to recommend other movies. In general, they can either be user-based or item-based. Item based approach is usually preferred over **user-based approach.** User-based approach is often harder to scale because of the dynamic nature of users, whereas items usually don\u2019t change much, and item based approach often can be computed offline and served without constantly re-training.","d8c346eb":"# Model Creation","865a27ac":"### We will now create a pivot table based on Name and User_id column and save it into a variable name piviot_table","d6b439cd":"# Preprocessing and applying all the methods for Recommendation System","6e3a521a":"# Result","094e926e":"### We will combine movie_ratingCount and combine_movie_rating this will give us the most Known Anime name and filter out the lesser one.","082d22e2":"### Getting some details of the data","7f2ce499":"#### I will now merge the rating data and anima_cantct_data(data extracted from anima_data) in terms of anima_id","06c97caf":"### Now I will take only that data in which a particular anime has more than 200Votes and if a user has gave in total more than 500Votes to the anime.  ","7566c13e":"![](https:\/\/miro.medium.com\/max\/650\/1*OyYyr9qY-w8RkaRh2TKo0w.png)<\/br>\nSource:[towardsdatascience](https:\/\/towardsdatascience.com)\n\n### Implementing kNN\nWe convert our table to a 2D matrix, and fill the missing values with zeros (since we will calculate distances between rating vectors). We then transform the values(ratings) of the matrix dataframe into a scipy sparse matrix for more efficient calculations.\n\n### Finding the Nearest Neighbors\nWe use unsupervised algorithms with sklearn.neighbors. The algorithm we use to compute the nearest neighbors is \u201cbrute\u201d, and we specify \u201cmetric=cosine\u201d so that the algorithm will calculate the cosine similarity between rating vectors. Finally, we fit the model.\n\n# Test our model and make some recommendations:\nThe kNN algorithm measures distance to determine the \u201ccloseness\u201d of instances. It then classifies an instance by finding its nearest neighbors, and picks the most popular class among the neighbors."}}