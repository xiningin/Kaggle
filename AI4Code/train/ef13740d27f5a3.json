{"cell_type":{"6dbda674":"code","13e9b575":"code","cc835552":"code","85e0eb59":"code","c776f0b9":"code","ae94d93a":"code","5c6e1f81":"code","8195b7a5":"code","57b957b9":"code","a7d34d50":"code","5dcca98c":"code","ff89d25a":"code","80b094b2":"code","72a7be72":"code","dff8c981":"code","ebb7e329":"code","a06bef82":"code","3adf454c":"code","1cfbff4a":"code","a32392ad":"code","b7461f36":"code","b687221d":"code","7471e8f2":"code","9781116a":"code","31d126c7":"code","87329abe":"code","0b39c6f1":"markdown","755a9d6f":"markdown","54944029":"markdown","f1a14885":"markdown","febd6480":"markdown","ce76cd1d":"markdown","7cb4ee08":"markdown","a08c4795":"markdown","37286f35":"markdown","ffc3ba4f":"markdown","aa8f7da5":"markdown","a7658d26":"markdown","8c8f40bf":"markdown"},"source":{"6dbda674":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.vision.gan import *\nfrom fastai.callbacks.hooks import *\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nprint(os.listdir(\"..\/input\/cell_images\/cell_images\"))\n\n# Any results you write to the current directory are saved as output.","13e9b575":"img_dir='..\/input\/cell_images\/cell_images\/'\npath = Path(img_dir)","cc835552":"data = ImageDataBunch.from_folder(path, \n                                  train=\".\",\n                                  valid_pct=0.2, \n                                  ds_tfms=get_transforms(flip_vert=True, max_warp=0),\n                                  size=224,bs=64, \n                                  num_workers=0).normalize(imagenet_stats)","85e0eb59":"data.show_batch(rows=5)","c776f0b9":"print(f'Classes: \\n {data.classes}')","ae94d93a":"learn = cnn_learner(data, models.resnet50, metrics=[accuracy, error_rate], model_dir=\"\/temp\/model\/\")","5c6e1f81":"learn.lr_find()\nlearn.recorder.plot()","8195b7a5":"learn_rate = 1e-01","57b957b9":"learn.fit_one_cycle(5, slice(learn_rate))","a7d34d50":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(9, figsize=(15,11))","5dcca98c":"interp.plot_confusion_matrix(figsize=(8,8), dpi=60)","ff89d25a":"learn.save('stage-1-rn50')","80b094b2":"learn.unfreeze()","72a7be72":"learn.lr_find()\nlearn.recorder.plot()","dff8c981":"learn.fit_one_cycle(5, slice(1e-5, learn_rate\/5))","ebb7e329":"learn.save('stage-2-rn50')","a06bef82":"learn.unfreeze()\nlearn.recorder.plot_losses()","3adf454c":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(9, figsize=(15,11))","1cfbff4a":"interp.plot_confusion_matrix(figsize=(8,8), dpi=60)","a32392ad":"from fastai.callbacks.hooks import *\n\nidx=0\nx,y = data.valid_ds[idx]\neval_model = learn.model.eval();\nxb,_ = data.one_item(x)\nxb_im = Image(data.denorm(xb)[0])\nxb = xb.cuda()","b7461f36":"def hooked_backward(cat=y):\n    with hook_output(eval_model[0]) as hook_a: \n        with hook_output(eval_model[0], grad=True) as hook_g:\n            preds = eval_model(xb)\n            preds[0,int(cat)].backward()\n    return hook_a, hook_g","b687221d":"def show_heatmap(hm):\n    _,ax = plt.subplots()\n    xb_im.show(ax)\n    ax.imshow(hm, alpha=0.6, extent=(0,352,352,0),\n              interpolation='bilinear', cmap='magma');","7471e8f2":"hook_a, hook_g = hooked_backward()","9781116a":"acts  = hook_a.stored[0].cpu()\nacts.shape","31d126c7":"grad = hook_g.stored[0][0].cpu()\ngrad_chan = grad.mean(1).mean(1)\ngrad.shape,grad_chan.shape","87329abe":"mult = (acts*grad_chan[...,None,None]).mean(0)\nshow_heatmap(mult)","0b39c6f1":"Before we start trying to optimise the model further, we need to unfreeze it to continue work. Thankfully, FastAI allows you to do that with a simple function call, unfreeze()","755a9d6f":"With the path defined to the dataset, we can start comprising the [ImageDataBunch](http:\/\/https:\/\/docs.fast.ai\/vision.data.html#ImageDataBunch) which will form the data we will propagate over throughout the course of this notebook.","54944029":"## Review Model\n\nWe can utilise a heatmap, provided by [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](http:\/\/https:\/\/arxiv.org\/abs\/1610.02391) to see exactly where the model is looking when it is attempting to differentiate between the classes. \n","f1a14885":"Overall, a well performing image classifier has been devised for this particular task. However, it is prudent to see exactly where the image classifier is looking when it is attempting to differentiate between the classes.","febd6480":"With the model good to go, we can attempt to find a better learning rate now the model has a better representation of the data.","ce76cd1d":"## Model Development\n\nFor image classification, we shall utilise a commonly used model for image classification, Resnet50 to provide us with a ready made means to start work.\nTo compare epochs, we will utilise two metrics to determine validity: \n\n    * Accuracy\n    * Error rate\n    \nFinally, the model will save its progress in '\/temp\/model'. This is due to a limitation where the folder directory used for the project is set to read only.","7cb4ee08":"Superb performance thus far, but there are a few pesky outliers that we could look to recapture. The model is at least failing at points which make sense at this stage, so we can continue.\nWe can save the model for future work.","a08c4795":"## Comprising the Dataset\n\nFor this project, the dataset has been split into two separate folders within cell_images:\n\n    * Parasitized\n    * Uninfected\n\nwhere parasitized is those cell images to which have been infected with malaria.","37286f35":"Let's look at some of the images to check that the data has loaded correctly.","ffc3ba4f":"Got to admit, it's quite cool to see where it's seeing!","aa8f7da5":"Looks like a learning rate of 1e-01 is a good starting point for the model. We can now start learning!\nWe will utilise the above learning rate through 5 epochs, or cycles, and compare the results.","a7658d26":"With the model defined, it serves us to learn the most effective hyperparameters we shall utilise for the model. For this, we shall use [lr_find](http:\/\/https:\/\/docs.fast.ai\/basic_train.html#lr_find) to find a good learning rate for the model.","8c8f40bf":"Looks like a learning rate of 1e-05 is a better learning rate for the model.\nWe will utilise the above learning rate through 5 epochs, or cycles, and compare the results."}}