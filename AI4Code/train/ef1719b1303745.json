{"cell_type":{"3b882738":"code","0bde07e4":"code","7af3ba58":"code","5b597d6e":"code","06e9b913":"code","6ef092cf":"code","b8901f8c":"code","967d07aa":"code","c60bb60a":"code","2cbc6bbc":"code","5bf0c56e":"code","ce1bd56d":"code","0fba0b5e":"code","fa43b4b5":"code","984b005e":"code","2e530472":"code","8af1f6a6":"code","aae193bb":"code","63e0d8b8":"code","427504f6":"code","e9a08b42":"code","98377561":"markdown","f704a8c7":"markdown","5d8a923a":"markdown","d7739dea":"markdown","1d79df08":"markdown"},"source":{"3b882738":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image, ImageStat\nimport cv2\n\nimport numpy             as np\nimport pandas            as pd\nimport matplotlib.pyplot as plt\nimport seaborn           as sns\nfrom sklearn.metrics         import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom keras.models            import Sequential\nfrom keras.layers            import Conv2D\nfrom keras.layers            import MaxPooling2D\nfrom keras.layers            import Dense\nfrom keras.layers            import Flatten\nfrom keras.callbacks import Callback\nfrom tensorflow.keras import callbacks\nfrom functools import reduce\nimport os\nfrom mlxtend.plotting import plot_confusion_matrix","0bde07e4":"files = 0\nimages = 0\n\nfor num, (dirname, _, filenames,) in enumerate(os.walk('\/kaggle\/input')):\n    for file, filename in enumerate(filenames):\n        if file < 4:\n            print(os.path.join(dirname, filename))\n        elif file==4:\n            print(\"... more on this folder\")\n        if filename.endswith((\"xlsx\", \"txt\",)):\n            files+=1\n        elif filename.endswith((\"png\", \"jpeg\", \"jpg\",)):\n            images+=1\nprint(\"...\\n\")\nprint(\"*\"*10, \"          files: {} images: {}\".format(files, images))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7af3ba58":"\nbase_dir= \"\/kaggle\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\"\n\ndef detect_color_image_v1(file, thumb_size=40, MSE_cutoff=22, adjust_color_bias=True):\n    pil_img = Image.open(file)\n    bands = pil_img.getbands()\n    if bands == ('R','G','B') or bands== ('R','G','B','A'):\n        thumb = pil_img.resize((thumb_size,thumb_size))\n        SSE, bias = 0, [0,0,0]\n        if adjust_color_bias:\n            bias = ImageStat.Stat(thumb).mean[:3]\n            bias = [b - sum(bias)\/3 for b in bias ]\n        for pixel in thumb.getdata():\n            mu = sum(pixel)\/3\n            SSE += sum((pixel[i] - mu - bias[i])*(pixel[i] - mu - bias[i]) for i in [0,1,2])\n        MSE = float(SSE)\/(thumb_size*thumb_size)\n        if MSE <= MSE_cutoff:\n            return(\"grayscale\")\n        else:\n            return(\"Color\")\n    elif len(bands)==1:\n        return(\"Black and white\")\n    else:\n        return(\"Don't know...\")\n\nMONOCHROMATIC_MAX_VARIANCE = 0.005\nCOLOR = 1000\nMAYBE_COLOR = 100\n\ndef detect_color_image(file):\n    v = ImageStat.Stat(Image.open(file)).var\n    is_monochromatic = reduce(lambda x, y: x and y < MONOCHROMATIC_MAX_VARIANCE, v, True)\n    if is_monochromatic:\n        return(\"Monochromatic image\")\n    else:\n        if len(v)==3:\n            maxmin = abs(max(v) - min(v))\n            if maxmin > COLOR:\n                return(\"Color\")\n            elif maxmin > MAYBE_COLOR:\n                print(\"Maybe color\")\n                return(\"Color\")\n            else:\n                return(\"grayscale\")\n        elif len(v)==1:\n            return(\"Black and white\")\n        else:\n            return(\"Don't know...\")\n        \ncolor=0\nb_and_w=0\nfor im in os.listdir(base_dir + \"\/Tuberculosis\"):\n    path = base_dir + \"\/Tuberculosis\/\" + im\n    #print(detect_color_image(path)==detect_color_image_v1(path), path, detect_color_image(path), detect_color_image_v1(path),)\n    if detect_color_image_v1(path)==\"Color\":\n        color+=1\n    else:\n        b_and_w+=1\nprint(\"tuberculosis (total img {}) -> color pictures: {} b&w pictures: {}\".format(color + b_and_w, color, b_and_w))\n\ncolor=0\nb_and_w=0\nfor im in os.listdir(base_dir + \"\/Normal\"):\n    path = base_dir + \"\/Normal\/\" + im\n    #print(detect_color_image(path)==detect_color_image_v1(path), path, detect_color_image(path), detect_color_image_v1(path),)\n    if detect_color_image_v1(path)==\"Color\":\n        color+=1\n    else:\n        b_and_w+=1\nprint(\"\\nnormal (total img {}) -----> color pictures: {}  b&w pictures: {}\".format(color + b_and_w, color, b_and_w))","5b597d6e":"# manual cleaning\ndef Targetization(folder,target_tag):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder,filename),0)\n        if img is not None:\n            images.append([img,target_tag])\n    return images\n\nnormal = Targetization(\"..\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\/Normal\/\", 0)\ntuberculosis = Targetization(\"..\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\/Tuberculosis\/\", 1)\nnormal.extend(tuberculosis)\nTOTAL_DATA = normal\n\nFEATURE_MATRIX = []\nTARGET=[]\nfor x,y in TOTAL_DATA:\n    FEATURE_MATRIX.append(x)\n    TARGET.append(y)\n\nX=[]\nIMG_SIZE= 250\nfor x in FEATURE_MATRIX:\n    new_array = cv2.resize(x,(IMG_SIZE,IMG_SIZE)) # b&w\n    X.append(new_array)\nNORMALIZED_X = []\nfor x in X:\n    tmp = x\/255\n    NORMALIZED_X.append(tmp)\n    \n# training\nx_train,x_test,y_train,y_test = train_test_split(NORMALIZED_X,TARGET)\n\nprint(np.array(x_train).shape)\nprint(np.array(x_test).shape)\nprint(np.array(y_train).shape)\nprint(np.array(y_test).shape)\n\nimg_rows=x_train[0].shape[0]\nimg_cols=x_train[0].shape[1]\nprint(img_rows)\nprint(img_cols)\n\nx_train = np.array(x_train)\nx_test = np.array(x_test)\n\n##in crease 1 dimension\nX_train=x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\nX_test=x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n\nprint(np.array(X_train).shape)\nprint(np.array(X_test).shape)\nprint(np.array(y_train).shape)\nprint(np.array(y_test).shape)","06e9b913":"plt.figure();  # weird color plot of the images, but is not real. need to insert the grey command\nf, axarr = plt.subplots(1,5, figsize=(19,19));\n\naxarr[0].imshow(normal[0][0]);\naxarr[1].imshow(tuberculosis[0][0]);\naxarr[2].imshow(TOTAL_DATA[0][0]);\naxarr[3].imshow(FEATURE_MATRIX[0])\naxarr[4].imshow(X_train[0])\nplt.show()\n\nprint(TARGET[0])","6ef092cf":"# generating training data with libraries\nfrom keras.preprocessing.image import ImageDataGenerator\nprint(\"training data :\")\nIMG_SIZE= 250\ntrain_datagen= ImageDataGenerator(rescale=1\/255, zoom_range=0.2,  width_shift_range= 0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True,  validation_split = 0.25)\n\ntrain_datagen= ImageDataGenerator(rescale=1\/255,  validation_split = 0.25)\n\ntrain_data = train_datagen.flow_from_directory(base_dir, \n                                              target_size= (IMG_SIZE,IMG_SIZE),\n                                              class_mode= \"binary\",\n                                              batch_size=32,\n                                              subset= \"training\",\n                                              color_mode =\"grayscale\" # change to dimension 1\n                                              )\n\n# genarating validation data\nprint(\"\\nvalidation data :\")\nval_datagen= ImageDataGenerator(rescale= 1\/255, validation_split= 0.2)\n\nval_data= train_datagen.flow_from_directory(base_dir, \n                                              target_size= (IMG_SIZE,IMG_SIZE),\n                                              class_mode= \"binary\",\n                                              batch_size=32,\n                                              shuffle= False,\n                                              subset= \"validation\",\n                                              color_mode =\"grayscale\"\n                                              )","b8901f8c":"batch=next(train_data)  # returns the next batch of images and labels \nprint(batch[0].shape) # batch[0] is the images, batch[1] are the labels\nimg=batch[0][0]   # this is the first image  batch[0][1] would be the next image\nprint (img.shape)\n#plt.imshow(img, cmap=\"gray\"); # for greyscale\nplt.imshow(img);","967d07aa":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(250, 250,1)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n#model.add(Dense(2, activation='softmax'))\nmodel.add(Dense(1, activation='sigmoid'))","c60bb60a":"# compile model\n#from keras.optimizers import adam_v2\n#opt = adam_v2(lr=0.001)\n\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001,  # minimium amount of change to count as an improvement\n    patience=1,  # how many epochs to wait before stopping\n)\n#model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'], )\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'], )","2cbc6bbc":"# automatic data\nhistory = model.fit(train_data, validation_data=val_data, epochs=3,  callbacks=[early_stopping])\nprediction= model.predict(val_data, steps=np.ceil(val_data.samples\/val_data.batch_size), verbose=2)\nprediction= (prediction > 0.5)\nval_labels=val_data.classes","5bf0c56e":"cm= confusion_matrix(val_data.classes, prediction)\nplot_confusion_matrix(cm, figsize=(5,5))\nprint(accuracy_score(val_data.classes, prediction))\nprint(classification_report(val_data.classes, prediction))","ce1bd56d":"#automatic\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","0fba0b5e":"# manual\nhistory = model.fit(np.array(X_train),np.array(y_train), epochs=3,validation_data=(X_test, np.array(y_test)), callbacks=[early_stopping])","fa43b4b5":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","984b005e":"predicted = model.predict(np.array(X_test))","2e530472":"model.evaluate(X_test,np.array(y_test))","8af1f6a6":"prediction2= (predicted > 0.5)\ncm= confusion_matrix(y_test, prediction2)\nplot_confusion_matrix(cm, figsize=(5,5))\nprint(accuracy_score(y_test, prediction2))\nprint(classification_report(y_test, prediction2))","aae193bb":"print(\"training data :\")\nIMG_SIZE= 250\n\ntrain_datagen= ImageDataGenerator(rescale=1\/255,\n                                  width_shift_range= 0.15, height_shift_range=0.15, shear_range=0.15, \n                                  validation_split = 0.25)\n\ntrain_data = train_datagen.flow_from_directory(base_dir, \n                                              target_size= (IMG_SIZE,IMG_SIZE),\n                                              class_mode= \"binary\",\n                                              batch_size=32,\n                                              subset= \"training\",\n                                              color_mode =\"grayscale\" # change to dimension 1\n                                              )\n\n# genarating validation data\nprint(\"\\nvalidation data :\")\nval_datagen= ImageDataGenerator(rescale= 1\/255, validation_split= 0.2)\n\nval_data= train_datagen.flow_from_directory(base_dir, \n                                              target_size= (IMG_SIZE,IMG_SIZE),\n                                              class_mode= \"binary\",\n                                              batch_size=32,\n                                              shuffle= False,\n                                              subset= \"validation\",\n                                              color_mode =\"grayscale\"\n                                              )","63e0d8b8":"# compile model\nearly_stopping = callbacks.EarlyStopping(\n    min_delta=0.001,  # minimium amount of change to count as an improvement\n    patience=1,  # how many epochs to wait before stopping\n)\n#model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'], )\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'], )","427504f6":"# automatic data\nhistory = model.fit(train_data, validation_data=val_data, epochs=3,  callbacks=[early_stopping])\nprediction= model.predict(val_data, steps=np.ceil(val_data.samples\/val_data.batch_size), verbose=2)\nprediction= (prediction > 0.5)\nval_labels=val_data.classes","e9a08b42":"cm= confusion_matrix(val_data.classes, prediction)\nplot_confusion_matrix(cm, figsize=(5,5))\nprint(accuracy_score(val_data.classes, prediction))\nprint(classification_report(val_data.classes, prediction))","98377561":"# Pilepines parts","f704a8c7":"# And with data augmentation?","5d8a923a":"# modeling","d7739dea":"We have data imbalance and since x rays are not in color, it does not make any sense to include the color. The color is given on the edges, due to the photos of the x-rays.","1d79df08":"# **<br>*Things about the images*<\/br>**"}}