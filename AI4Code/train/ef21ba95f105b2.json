{"cell_type":{"5b82127e":"code","5ff34d93":"code","1ce23afc":"code","287e6a77":"code","0c24e8c4":"code","4fb3889b":"code","b2030fa9":"code","a1ec5dd6":"code","a700f110":"code","008f7cb6":"code","333d4a67":"code","b74dfd58":"code","521eeece":"markdown","bf48685d":"markdown","814d6bed":"markdown","bdbabe87":"markdown","6be88b6c":"markdown"},"source":{"5b82127e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.image as mpimg\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ff34d93":"base_dir = '\/kaggle\/input\/messy-vs-clean-room\/images'\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')","1ce23afc":"os.listdir(train_dir)\nos.listdir(validation_dir)","287e6a77":"train_clean = \"\/kaggle\/input\/messy-vs-clean-room\/images\/train\/clean\"\ntrain_messy = \"\/kaggle\/input\/messy-vs-clean-room\/images\/train\/messy\"\ntest_messy = \"\/kaggle\/input\/messy-vs-clean-room\/images\/val\/messy\"\ntest_clean = \"\/kaggle\/input\/messy-vs-clean-room\/images\/val\/clean\"","0c24e8c4":"print(\"Number of training images: {}\".format(len(os.listdir(train_clean))+len(os.listdir(train_messy))))\nprint(\"Number of test images: {}\".format(len(os.listdir(test_clean))+len(os.listdir(test_messy))))","4fb3889b":"train_datagen = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=20,\n                    horizontal_flip=True,\n                    shear_range = 0.2,\n                    fill_mode = 'nearest')\n\ntest_datagen = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=20,\n                    horizontal_flip=True,\n                    shear_range = 0.2,\n                    fill_mode = 'nearest')","b2030fa9":"train_generator = train_datagen.flow_from_directory(\n        train_dir,  \n        target_size=(150, 150), \n        batch_size=4,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir, \n        target_size=(150, 150), \n        batch_size=4,\n        class_mode='binary')","a1ec5dd6":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","a700f110":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","008f7cb6":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.2,\n    patience=5, \n    min_lr=1.5e-5\n)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=12,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True\n)","333d4a67":"history = model.fit(\n      train_generator,\n      steps_per_epoch=25, \n      epochs=50,\n      validation_data=validation_generator,\n      validation_steps=5, \n#       callbacks=[reduce_lr, early_stopping]\n)","b74dfd58":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(12,4)\n\n# Define accuracy\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Define loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\n# Plotting accuracy\nax[0].plot(epochs, acc, 'r', label='Training Accuracy')\nax[0].plot(epochs, val_acc, 'b', label='Validation Accuracy')\nax[0].set_title('Training and Validation Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\nax[0].legend(loc='upper left')\n\n# Plotting loss \nax[1].plot(epochs, loss, 'r', label='Training Loss')\nax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\nax[1].set_title('Training and Validation Loss')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nax[1].legend(loc='upper left')\n\nplt.show()","521eeece":"## Number of train dan validation set","bf48685d":"## Create Callbacks","814d6bed":"## Build CNN Model","bdbabe87":"## Plotting Accuracy and Loss","6be88b6c":"## Image Augmentation"}}