{"cell_type":{"5967c8f3":"code","b0a4f356":"code","704003d2":"code","238a3c29":"code","d8275338":"code","6cd61ae5":"code","7b751a2b":"code","2d62d66d":"code","f7b7c8ab":"code","f6573ec0":"code","2387c5d9":"code","c97f79c0":"code","9a1fa87b":"code","7d47ad8c":"code","40ba96d1":"code","a022f40b":"code","18e36473":"code","74743408":"code","2e6c86e1":"code","ab067e28":"code","67c4a8d2":"markdown","53fd2ded":"markdown","bed45076":"markdown","a73de1e3":"markdown","d0880bdc":"markdown","988832a8":"markdown"},"source":{"5967c8f3":"!pip install --verbose --no-cache-dir torch-scatter\n!pip install --verbose --no-cache-dir torch-sparse\n!pip install --verbose --no-cache-dir torch-cluster\n!pip install --verbose --no-cache-dir torch-spline-conv (optional)\n!pip install torch-geometric\n!pip install eeg-positions","b0a4f356":"from scipy.io import loadmat\nimport numpy as np\nimport pickle\nimport os\nimport torch\nfrom torch import optim, linalg\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Function\nfrom torch_geometric.nn import SGConv, global_add_pool\nfrom torch_scatter import scatter_add\n#from torch.utils.data import Dataset,DataLoader\nfrom torch_geometric.data import Data, DataLoader\nfrom tqdm import tqdm\nfrom pprint import pprint\nfrom eeg_positions import (\n    get_alias_mapping,\n    get_available_elec_names,\n    get_elec_coords,\n    plot_coords,\n)\nimport time\nimport copy\nfrom sklearn.model_selection import train_test_split","704003d2":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","238a3c29":"fs = 128 \nn_subjects = 5\nmkpt1 = int(fs*10*60)\nmkpt2 = int(fs*20*60)","d8275338":"subject_map = {}\nfor s in range(1, n_subjects+1):\n    a =  int(7*(s-1)) + 3\n    if s!=5:\n        b = a + 5\n    else:\n        b = a + 4\n    subject_map[s] = [i for i in range(a, b)]\nprint(subject_map)","6cd61ae5":"channels = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\nuseful_channels = ['F7','F3','P7','O1','O2','P8','AF4']\nuse_channel_inds = []\nfor c in useful_channels:\n    if c in channels:\n        use_channel_inds.append(channels.index(c))","7b751a2b":"inp_dir = '..\/input\/eeg-data-for-mental-attention-state-detection\/EEG Data\/' ","2d62d66d":"print(mkpt1)\nprint(mkpt2)\nmkpt3 = 214540\ninterval = mkpt3 - mkpt2\nfor s in range(1, n_subjects+1):\n    data = {}\n    data['channels'] = useful_channels\n    data['fs'] = fs\n    for i, t in enumerate(subject_map[s]):\n        trial = {}\n        trial_data = loadmat(inp_dir + f'eeg_record{t}.mat')\n        eeg = trial_data['o']['data'][0][0][:, 3:17]\n        eeg = eeg[:, use_channel_inds]\n        \n        trial['focussed'] = eeg[:interval]\n        trial['unfocussed'] = eeg[mkpt1:mkpt1+interval]\n        trial['drowsed'] = eeg[mkpt2:mkpt2+interval]\n        data[f'trial_{i+1}'] = trial\n    with open(f'subject_{s}.pkl', 'wb') as f: \n        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n        ","f7b7c8ab":"with open('subject_1.pkl', 'rb') as f: \n    data = pickle.load(f)","f6573ec0":"data","2387c5d9":"with open('subject_1.pkl', 'rb') as f: \n    data1 = pickle.load(f)\nwith open('subject_2.pkl', 'rb') as f: \n    data2 = pickle.load(f)\nwith open('subject_3.pkl', 'rb') as f: \n    data3 = pickle.load(f)\nwith open('subject_4.pkl', 'rb') as f: \n    data4 = pickle.load(f)\nwith open('subject_5.pkl', 'rb') as f: \n    data5 = pickle.load(f)","c97f79c0":"state_num = {'focussed': 0, 'unfocussed': 1,'drowsed': 2}","9a1fa87b":"def maybe_num_nodes(index, num_nodes=None):\n    return index.max().item() + 1 if num_nodes is None else num_nodes\n\n\ndef add_remaining_self_loops(edge_index,\n                             edge_weight=None,\n                             fill_value=1,\n                             num_nodes=None):\n    #A' = A + I\n    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n    row, col = edge_index\n    mask = row != col\n    #mask\u306f0\u304b1\n    inv_mask = ~mask\n    #[1,1,1,1,...] shape(62,)\n    loop_weight = torch.full(\n        (num_nodes, ),\n        fill_value,\n        dtype=None if edge_weight is None else edge_weight.dtype,\n        device=edge_index.device)\n\n    if edge_weight is not None:\n        #62x62x8 = edge_index.size(1)?\n        assert edge_weight.numel() == edge_index.size(1)\n        #inv_mask = 0 or 1\n        remaining_edge_weight = edge_weight[inv_mask]\n        if remaining_edge_weight.numel() > 0:\n            loop_weight[row[inv_mask]] = remaining_edge_weight\n        edge_weight = torch.cat([edge_weight[mask], loop_weight], dim=0)\n\n    loop_index = torch.arange(0, num_nodes, dtype=row.dtype, device=row.device)\n    loop_index = loop_index.unsqueeze(0).repeat(2, 1)\n    #loop index\u3092\u4e8c\u6bb5\u968e\u3067\u5f62\u6210[0,1,2,...,61] shape : (2,62)\n    edge_index = torch.cat([edge_index[:, mask], loop_index], dim=1)\n    #loop index\u3092torch.cat()\n\n    return edge_index, edge_weight\n\n\nclass NewSGConv(SGConv):\n    def __init__(self, num_features, num_classes, K=1, cached=False,\n                 bias=True):\n        super(NewSGConv, self).__init__(num_features, num_classes, K=K, cached=cached, bias=bias)\n\n    # allow negative edge weights\n    @staticmethod\n    def norm(edge_index, num_nodes, edge_weight, improved=False, dtype=None):\n        if edge_weight is None:\n            #edge_weight.shape(62x62x8,)\n            #edge_index.shape(2,62x62x8)\n            edge_weight = torch.ones((edge_index.size(1), ),\n                                     dtype=dtype,\n                                     device=edge_index.device)\n\n        fill_value = 1 if not improved else 2\n        edge_index, edge_weight = add_remaining_self_loops(\n            edge_index, edge_weight, fill_value, num_nodes)\n        row, col = edge_index\n        #\u6b21\u6570\u884c\u5217D\u3092\u4f5c\u6210 \u30b5\u30a4\u30ba 62 x 62\n        #\u7e26\u306b62 edge_weight.shape:[62,62] row.shape:[1,62]\n        #edge_weight:62x62x8, row:62x62x8\n        deg = scatter_add(torch.abs(edge_weight), row, dim=0, dim_size=num_nodes)\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n\n        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n\n    def forward(self, x, edge_index, edge_weight=None):\n        if not self.cached or self.cached_result is None:\n            edge_index, norm = NewSGConv.norm(\n                edge_index, x.size(0), edge_weight, dtype=x.dtype)\n\n            #W\u306f\u81ea\u52d5\u3067\u8a08\u7b97\uff1f Z=SXW\n            for k in range(self.K):\n                #print(f'x.shape : {x.size()}')\n                #print(f'edge_index.shape : {edge_index.size()}')\n                #print(f'norm.shape : {norm.size()}')\n                #print(f'norm.max : {norm.max()}')\n                #print(f'norm.min : {norm.min()}')\n                x = self.propagate(edge_index, x=x, norm=norm)\n            self.cached_result = x\n\n        return self.lin(self.cached_result)\n\n    def message(self, x_j, norm):\n        # x_j: (batch_size*num_nodes*num_nodes, num_features)\n        # norm: (batch_size*num_nodes*num_nodes, )\n        return norm.view(-1, 1) * x_j\n\nclass ReverseLayerF(Function):\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n        return output, None\n\n\nclass SymSimGCNNet(torch.nn.Module):\n    def __init__(self, num_nodes, learn_edge_weight, edge_weight, num_features, num_hiddens, num_classes, K, dropout=0.7, domain_adaptation=\"\"):\n        \"\"\"\n            num_nodes: number of nodes in the graph\n            learn_edge_weight: if True, the edge_weight is learnable\n            edge_weight: initial edge matrix\n            num_features: feature dim for each node\/channel\n            num_hiddens: a tuple of hidden dimensions\n            num_classes: number of emotion classes\n            K: number of layers\n            dropout: dropout rate in final linear layer\n            domain_adaptation: RevGrad\n        \"\"\"\n        super(SymSimGCNNet, self).__init__()\n        self.domain_adaptation = domain_adaptation\n        self.num_nodes = num_nodes\n        #\u4e0b\u306e\u4e09\u89d2\u5f62\u306e\u5ea7\u6a19\u53d6\u5f97\n        self.xs, self.ys = torch.tril_indices(self.num_nodes, self.num_nodes, offset=0)\n        edge_weight = edge_weight.reshape(self.num_nodes, self.num_nodes)[self.xs, self.ys] # strict lower triangular values\n        self.edge_weight = nn.Parameter(edge_weight, requires_grad=learn_edge_weight)\n        self.dropout = dropout\n        self.conv1 = NewSGConv(num_features=num_features, num_classes=num_hiddens[0], K=K)\n        self.fc = nn.Linear(num_hiddens[0], num_classes)\n        if self.domain_adaptation in [\"RevGrad\"]:\n            self.domain_classifier = nn.Linear(num_hiddens[0], 2)\n\n    def forward(self, data, alpha=0):\n        batch_size = len(data.y)\n        #edge_index\u306f1batch\u306e\u4f55\u304b 8x?\n        x, edge_index = data.x, data.edge_index\n        #print(f'edge_index shape: {edge_index.size()}')\n        edge_weight = torch.zeros((self.num_nodes, self.num_nodes), device=edge_index.device)\n        #\u4e0b\u306e\u4e09\u89d2\u5f62\u306e\u5024\u3060\u3051\u5165\u308c\u3066\u308b\u3001\u4e0a\u306e\u4e09\u89d2\u5f62\u306f0\n        edge_weight[self.xs.to(edge_weight.device), self.ys.to(edge_weight.device)] = self.edge_weight\n        edge_weight = edge_weight + edge_weight.transpose(1,0) - torch.diag(edge_weight.diagonal()) # copy values from lower tri to upper tri\n        #\u4e0b\u534a\u5206\u306e\u8a08\u7b97\u3067\u4e0a\u306e\u8a08\u7b97\u3082\u3057\u305f\u3053\u3068\u306b\u306a\u308b\n        #1batch\u306e1\u76f4\u7dda\u306e\u30c6\u30f3\u30bd\u30eb\n        edge_weight = edge_weight.reshape(-1).repeat(batch_size)\n        #print(f\"\u9577\u3055:{edge_weight.shape}\")\n        #print(f'edge_weight max : {edge_weight.max()}, edge_weight min : {edge_weight.min()}')\n        x = F.relu(self.conv1(x, edge_index, edge_weight))\n        \n        # domain classification\n        domain_output = None\n        if self.domain_adaptation in [\"RevGrad\"]:\n            reverse_x = ReverseLayerF.apply(x, alpha)\n            domain_output = self.domain_classifier(reverse_x)\n        x = global_add_pool(x, data.batch, size=batch_size)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.fc(x)\n        return x, domain_output","7d47ad8c":"#(62,62)\u306e\u884c\u5217\u3092\u521d\u671f\u5316\u3059\u308b\nedge_weight = torch.zeros(7,7)\n\ncoords = get_elec_coords(\n    elec_names = useful_channels,\n    drop_landmarks = False,\n    dim = \"3d\",\n)\n\nelectrodes_data = {}\nfor ind, row in coords.iterrows():\n    electrodes_data[str(row.label)] = (row.x,row.y,row.z)\n\nfor i in range(7):\n    for j in range(i+1,7):\n        elec_from = useful_channels[i]\n        elec_to = useful_channels[j]\n\n        from_data = electrodes_data[elec_from]\n        to_data = electrodes_data[elec_to]\n        vec_from = np.array(from_data)\n        vec_to = np.array(to_data)\n        dist = np.linalg.norm(vec_from - vec_to)\n        edge_weight[i, j] = dist\n        edge_weight[j, i] = dist\n\nedge_weight = np.where(edge_weight > 0, 0.065 \/ edge_weight, edge_weight)\n\nedge_weight = torch.tensor(edge_weight).float()\nprint(type(edge_weight))","40ba96d1":"def get_dataloader():\n    #\u307e\u305a\u306fdata\u3092\u4f5c\u6210\n    dataset = []    \n    data_list = [data1, data2, data3, data4, data5]\n    for i in range(5):\n        now_data = data_list[i]\n        for j in range(4):\n            now_ind = j + 1\n            trial_name = 'trial_' + str(now_ind)\n            now_trial = now_data[trial_name]\n            for state, val in now_trial.items():\n                y = torch.tensor([state_num[state]]).long()\n                x = torch.tensor(val).float()\n                x = x.permute(1,0)\n                #print(x.size())\n                data = Data(x=x, edge_index=edge_index, y=y)\n                dataset.append(data)\n    \n    #print(len(dataset))\n    #dataset\u4f5c\u6210\u5b8c\u4e86\u3001\u6b21\u306ftrain\u3068val\u3067split\u3057\u3066dataloader\u3092\u4f5c\u6210\u3059\u308b\n    train, val = train_test_split(dataset, train_size=0.6)\n    train_iterator = DataLoader(train, shuffle=True, batch_size=4, num_workers=2)\n    val_iterator = DataLoader(val, shuffle=False, batch_size=4, num_workers=2)    \n    \n    data = next(iter(train_iterator))\n    \n    return train_iterator, val_iterator","a022f40b":"row = []\ncol = []\nfor i in range(7):\n    for j in range(7):\n        row.append(i)\n        col.append(j)\n\nrow = np.array(row)\ncol = np.array(col)\n\nrow = torch.tensor(row).unsqueeze(0)\ncol = torch.tensor(col).unsqueeze(0)\n\nedge_index = torch.cat([row, col], dim = 0)\n\nprint(edge_index.size())","18e36473":"def labelize(label):\n    label = label.float()\n    #print(f'label : {label}')\n    label.requires_grad = True\n    tensor = None\n    for i in range(4):\n        if i == 0:\n            pos = label[i].detach().long()\n            _tensor = torch.zeros(1,3)\n            _tensor[0, pos] = 1\n            tensor = _tensor\n        else:\n            pos = label[i].detach().long()\n            _tensor = torch.zeros(1,3)\n            _tensor[0, pos] = 1\n            tensor = torch.cat([tensor,_tensor], dim=0)\n\n    tensor.requires_grad = True\n    return tensor","74743408":"models = []\n\ndef fit_model(edge_weight, edge_index):\n        train_iterator, valid_iterator = get_dataloader()\n\n        len_dataloader = min(len(train_iterator), len(valid_iterator))\n\n        #print(\"dataloader \u307e\u3067\u4f5c\u3063\u305f\u304a\")\n        #\u3053\u3063\u304b\u3089\u30e2\u30c7\u30eb\u5b9a\u7fa9\n        \"\"\"\n          num_nodes: number of nodes in the graph\n          learn_edge_weight: if True, the edge_weight is learnable\n          edge_weight: initial edge matrix\n          num_features: feature dim for each node\/channel \n          num_hiddens: a tuple of hidden dimensions \n          num_classes: number of emotion classes\n          K: number of layers\n          dropout: dropout rate in final linear layer\n          domain_adaptation: RevGrad\n        \"\"\"\n        \"\"\"\n          train_iterator : batch_size-> 4  \n        \"\"\"\n\n        model = SymSimGCNNet(num_nodes=7, learn_edge_weight=True, edge_weight=edge_weight, num_features=60940, num_hiddens=(10,20), num_classes=3, K=2, dropout=0.7, domain_adaptation=\"RevGrad\")\n        #print(f'model : {model}')\n        #print(f'domain_classifier weight : {model.domain_classifier.weight}')\n\n        for p in model.parameters():\n            p.requires_grad = True\n\n        loss_criterion1 = nn.KLDivLoss(reduction=\"sum\")\n        loss_criterion2 = nn.BCELoss()\n        opt = optim.Adam(model.parameters(), lr=0.001)\n        scheduler = optim.lr_scheduler.StepLR(opt, step_size=2, gamma=0.1)\n        softmax = nn.Softmax(dim=1)\n\n        targets = iter(valid_iterator)\n\n        #print(\"targets!!!!\")\n        all_loss = 0\n\n        for j, data in enumerate(train_iterator):\n\n            if j == len_dataloader:\n                break\n\n            #to device\n            data = data.to(device)\n\n\n            opt.zero_grad()\n            y_pred, domain_output_tr = model(data)\n            y_pred = y_pred \/ linalg.norm(y_pred)\n          \n            y_pred = softmax(y_pred)\n\n            #data.y\u3092(8,4)\u306b\u5909\u3048\u308b\n            y = labelize(data.y)\n            \n            print(y_pred.log().size())\n            print(y.size())\n            loss_tr = F.kl_div(y_pred.log(), y, None, None, 'sum')\n        \n            def calc_domain_loss(domain_output, mode):\n                #domain_output\u3092sigmoid\u306b\u901a\u3059\n                nlf = nn.Sigmoid()\n                domain_output = nlf(domain_output)\n\n                weight = model.domain_classifier.weight\n                weight = weight.to(device)\n\n                #domain_classifier\u306eparameter\u3068\u639b\u3051\u5408\u308f\u305b\u308b\n                p = softmax(torch.mm(domain_output, weight))\n\n\n                res = None\n\n                #bce\u3092\u8a08\u7b97\n                if mode == 'zero': \n                    t = torch.zeros(p.size(0), p.size(1))\n                    t = t.to(device)\n                    res = loss_criterion2(p, t).float()\n                if mode == 'one':\n                    t = torch.ones(p.size(0), p.size(1))\n                    t = t.to(device)\n                    res = loss_criterion2(p, t).float()\n\n                return res\n\n            loss_tr_domain = calc_domain_loss(domain_output_tr, 'zero')\n\n            data_eval = next(targets)\n\n            #to device\n            data_eval = data_eval.to(device)\n\n            _, domain_output_te = model(data_eval)\n\n            loss_te_domain = calc_domain_loss(domain_output_te, 'one')\n\n            #domain classifier\u304b\u3089\u306eloss\u3092\u8a08\u7b97\u3057\u3066\u6700\u9069\u5316\n            total_loss = loss_tr + loss_tr_domain + loss_te_domain\n            all_loss += total_loss\n            total_loss.backward()\n            opt.step()\n\n            #opt.step()\n            print(f'Epoch: {j+1} \/ Lr: {scheduler.get_lr()[0]} \/ Loss: {total_loss}')\n            #print(opt.param_groups[0])\n            scheduler.step()\n\n        end_time = time.time()\n        models.append(model)\n        #epoch_mins, epoch_secs = (end_time - start_time)\/\/60, round((end_time - start_time)%60)","2e6c86e1":"get_dataloader()","ab067e28":"fit_model(edge_weight, edge_index)","67c4a8d2":"Below cell is not really important. I didn't want to manually write the relevant file names for each subject. So, I did the following. It based on what the data contributor has mentioned in an comment. There are 5 subjects, and they have recorded data on 7 separate days (except for subject-5 who has only done that for 6 days). I have segregated each day's data as a trial. Out of these 7, first 2 were used for getting the subject to familiarise with the process. That is why I have only considered the last 5 trials of each subject as training data.","53fd2ded":"### For working with any Machine learning models in python, it will be easier to work with numpy arrays. We can save each subject's numpy arrays inside a structured pickle object.","bed45076":"Suppose I just want the data related to 'focussed' state from trial_1 of subject_1","a73de1e3":"### Loading the pickle objects","d0880bdc":"The sampling frequency is 128 Hz. So, suppose on a particular day, if say the subject has recorded EEG data for 40 minutes. Then total number of rows in the array will 128x60x40. As mentioned by @inancigdem, for each subject, and during every day, first 10 minutes of data corresponds to 'focussed', next 10 minutes to 'unfocussed', and the remaining to 'drowsed' state. So, I have sliced each individual array going by that information (i.e. slicing till row number 128x10x60 for 'focussed', from 128x10x60 to 128x20x60 for 'unfocussed', and from 128x20x60 till last row for 'drowsed).","988832a8":"### Saving the pickle object for each subject"}}