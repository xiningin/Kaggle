{"cell_type":{"4c344e06":"code","1acf849a":"code","3032d0ba":"code","cd649baa":"code","17618747":"code","ca826c46":"code","c293e794":"code","0b8bdab5":"code","0f90a855":"code","3b708df4":"code","db24ebcb":"code","7ad0bfbf":"code","63006f3e":"code","2bcc0f02":"code","9191d866":"code","6e7044e6":"code","fc5687ce":"markdown","5114d30f":"markdown","98fcd706":"markdown","2bce0ff6":"markdown","5ee20c30":"markdown","011552a4":"markdown"},"source":{"4c344e06":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1acf849a":"import warnings\nwarnings.filterwarnings('ignore')","3032d0ba":"train_data = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')","cd649baa":"train_data.shape","17618747":"train_data.head()","ca826c46":"# Missing Values\n\ndef missing_values(data):\n    missing_values =  pd.DataFrame(\n    {\n       'missing_values':data.isnull().sum(),\n       'percentage':data.isnull().sum()*100\/data.shape[0]\n    })\n    missing_values.sort_values(by='missing_values', ascending=False)\n    return missing_values.T","c293e794":"missing_values(train_data)","0b8bdab5":"train_data[train_data.duplicated()]","0f90a855":"sample_data = train_data.iloc[:,1:21]","3b708df4":"fig,ax= plt.subplots(nrows=10,ncols=2,figsize=(20, 35)) \nfor variable, subplot in zip(sample_data.columns,ax.flatten()):\n    z = sns.boxplot(x = sample_data[variable], orient = \"h\",whis=1.5 , ax=subplot) \n    z.set_xlabel(variable, fontsize = 10)\n    \n# fig.delaxes(ax[2][1])\n# fig.delaxes(ax[2][2])\nplt.show()","db24ebcb":"fig,ax= plt.subplots(nrows=10,ncols=2,figsize=(20, 35)) \nfor variable, subplot in zip(sample_data.columns,ax.flatten()):\n    z = sns.distplot(x = sample_data[variable] , ax=subplot) \n    z.set_xlabel(variable, fontsize = 10)\n\n\nplt.show()","7ad0bfbf":"sns.countplot(x='target', data=train_data)\nprint(f\"{train_data.target.value_counts()}\")","63006f3e":"train_data['kfold'] = -1\n\nkf = KFold(n_splits=5, shuffle=True, random_state=43)\nfor fold, (train_indicies, validation_indicies) in enumerate(kf.split(X=train_data)):\n    train_data.loc[validation_indicies, 'kfold'] = fold","2bcc0f02":"train_data.head()","9191d866":"train_data.kfold.value_counts()","6e7044e6":"train_data.to_csv('train_fold.csv', index=False)","fc5687ce":"\ud83d\udcd3 I'll be updating this notebook(EDA part). As we go along in this competition \ud83c\udfc6","5114d30f":"\ud83d\udccc We'are saving data with **5 folds** and will be using same for training the model, rather than using train_test_split. In the next kernal we'll see model training and evaluation. ","98fcd706":"\ud83d\udccc Creating **folds** and saving data back to csv file. ","2bce0ff6":"\ud83d\udccc We selected first 20 feature to check the data distribution, and using same approach we can check other features too.","5ee20c30":"\ud83d\udccc There are no duplicated data trainset","011552a4":"\ud83d\udccc There are no missing data in trainset"}}