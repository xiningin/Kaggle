{"cell_type":{"34f95663":"code","f6a32b6f":"code","4ae86884":"code","62f7e4a7":"code","209f9f69":"code","8c373de0":"code","850748ac":"code","596d6e9e":"code","9a005d8a":"code","6bfbcc0d":"code","34206f2d":"code","5151dcda":"code","886edf60":"code","726412d1":"code","557a4b0a":"code","9be79b80":"code","259c1da1":"code","cb9b4542":"code","48045c20":"code","8f434f98":"markdown","11b03757":"markdown","18e11b90":"markdown","78da5bba":"markdown","a2eef768":"markdown","0c6f3894":"markdown","a5698e2a":"markdown","7b3a1280":"markdown","89d1268e":"markdown","546b5ba3":"markdown","b2a8edf0":"markdown","e850f1f1":"markdown","ba0335db":"markdown","08eca7ed":"markdown","f371a36a":"markdown"},"source":{"34f95663":"import torch\nimport torchvision\nfrom torch.utils import data\nimport torchvision.models as models\n\n\nimport numpy as np\nimport random\nimport glob\nfrom pathlib import Path\nimport os\nimport PIL\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset,DataLoader","f6a32b6f":"main_path = '..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'","4ae86884":"path = Path(main_path)\nimg_dir_path = list(path.glob('**\/*.png'))# images are in png file format\n\nimages_paths = [img_path for img_path in img_dir_path if 'GT' not in str(img_path)]\nprint(f'Number of training images :{len(images_paths)}')\n\nlabels = [os.path.split(os.path.split(name)[0])[1] for name in images_paths]\nprint(f'Number of labels :{len(labels)}')\n\nclasses = list(set(labels))\nlabel_encoder = {label : i for i,label in enumerate(classes)}\nprint('-'*404)\nprint(f'Label Encoder :{label_encoder}')\nlabels_encoded = [label_encoder[label] for label in labels]# Convert string labels to int format","62f7e4a7":"sns.countplot(labels_encoded)","209f9f69":"# Creating a dataset for visualization\nrand_img_paths = []\nfor i in classes:\n    path =  os.path.join(os.path.join(main_path,i),i)\n    rand_path = list(glob.glob(path+'\/*')[:5])\n    rand_img_paths.append(rand_path)","8c373de0":"import cv2\nfig=plt.figure(figsize=(50, 90))\ncolumns = 5; rows = 9\nnum=1\nfor i in range(len(classes)):\n    for j in range(len(rand_img_paths[i])):\n        img = cv2.imread(rand_img_paths[i][j])\n        img = cv2.resize(img, (128, 128))\n        fig.add_subplot(rows, columns, num)\n        num+=1\n        plt.title(classes[i],fontsize=50)\n        plt.imshow(img)\n        plt.axis(False)\n","850748ac":"class fishDataset(Dataset):\n    def __init__(self,images,labels,transform):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self,idx):\n        input_image = self.images[idx]\n        label = self.labels[idx]\n        image = PIL.Image.open(input_image)\n        image = self.transform(image)\n        return image,label","596d6e9e":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","9a005d8a":"#Split data for train and for test\ndata , test_data, labels, test_labels = train_test_split(images_paths, labels_encoded, test_size=0.1, shuffle=True)\n#Split train data for train and validation\ntrain_data , val_data, train_labels, val_labels = train_test_split(data, labels, test_size=0.1, shuffle=True)","6bfbcc0d":"batch_size = 64\n\ntrain_ds = fishDataset(\n        images=train_data,\n        labels=train_labels,\n        transform=data_transforms['train'])\n\ntrain_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True)\n\n\nval_ds = fishDataset(\n        images=val_data,\n        labels=val_labels,\n        transform=data_transforms['val']\n)\n\nval_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False\n)\n\ntest_ds = fishDataset(\n        images=test_data,\n        labels=test_labels,\n        transform=data_transforms['val']\n)\n\ntest_loader = DataLoader(\n        test_ds,\n        batch_size=batch_size,\n        shuffle=False\n)","34206f2d":"labels_dic = {i : label for i,label in enumerate(classes)}\ndef show_batch(loader, batch_size, labels_dic):\n    rows_number = 1\n    cols_number = 2\n    if batch_size > 2:\n        cols_number = 8\n        rows_number = batch_size\/\/cols_number\n        \n    fig = plt.figure(figsize=(48, 30))\n    images,labels = next(iter(loader))\n    for i,data in enumerate(images,1):\n        ax = fig.add_subplot(rows_number, cols_number, i)\n        plt.imshow(data.permute(1,2,0).numpy())\n        ax.set_title(labels_dic[labels[i-1].item()],fontsize = 20)\n        plt.axis(False)\n    plt.show()","5151dcda":"show_batch(train_loader, 64, labels_dic)# We want to look at the data","886edf60":"model = models.resnet18(pretrained=True)\nnum_features = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_features,9)\nfor param in model.fc.parameters():\n    param.requires_grad = True","726412d1":"device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","557a4b0a":"optimizer = torch.optim.Adam(model.fc.parameters(),lr= 0.001)\ncriterion = torch.nn.CrossEntropyLoss()","9be79b80":"model = model.to(device)","259c1da1":"from tqdm import tqdm\nn_epochs = 20\nvalid_loss_min = np.Inf\nfor epoch in tqdm(range(1,n_epochs+1)):\n    train_loss = 0.0\n    valid_loss = 0.0\n    train_running_correct= 0.0\n    val_running_correct = 0.0\n    \n    model.train()\n    \n    for data,target in train_loader:\n        data,target = data.to(device),target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output,target)\n        loss.backward()\n        optimizer.step()\n        train_loss+=loss.item()*data.size(0)\n        _,preds = torch.max(output.data,1)\n        train_running_correct += (preds==target).sum().item()\n    \n    model.eval()\n    for data,target in val_loader:\n        data,target = data.to(device),target.to(device)\n        output = model(data)\n        loss = criterion(output,target)\n        valid_loss+=loss.item()*data.size(0)\n        _,preds =torch.max(output.data,1)\n        val_running_correct += (preds==target).sum().item()\n        \n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(val_loader.sampler)\n    train_accuracy = 100. * train_running_correct\/len(train_loader.sampler)\n    valid_accuracy = 100. * val_running_correct\/len(val_loader.sampler)\n    print('Epoch: {} , Training Loss: {:.6f},Training Accuracy: {:.3f} ,Validation Loss: {:.6f}, Validation Accuracy: {:.3f}'.format(epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n    \n    if valid_loss<=valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_fish.pt')\n        valid_loss_min = valid_loss\n\n  ","cb9b4542":"def eval_accuracy(loader):  \n    model.eval()\n    corrects = 0\n    total = 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        predictions = model(images)\n        predict = torch.max(predictions.data, 1)[1].to(device)\n        total += len(labels)\n        corrects += (predict == labels).sum()\n    accuracy = 100 * corrects \/ float(total)\n    return accuracy","48045c20":"print(f' Accuracy on validation images: {eval_accuracy(val_loader)}')\nprint(f' Accuracy on train images: {eval_accuracy(train_loader)}')\nprint(f' Accuracy on test images: {eval_accuracy(test_loader)}')","8f434f98":"# Importing Libraries","11b03757":"<p style=\"color: red\"><span style=\"font-size:200%\">\nWhat did the shark say after eating a clownfish?<span>\n<\/p> \n<p style=\"color: #0096FF\"><span style=\"font-size:200%\">That tasted a little bit funny!<\/span><\/p>\n\n\n![](https:\/\/media1.tenor.com\/images\/512e464f3e5ef8f40582e4e1b855950a\/tenor.gif?itemid=4921222)\n<br>\n<br>\n\n**Seafood is any form of sea life regarded as food by humans, prominently including fish and shellfish. Shellfish include various species of molluscs (e.g. bivalve molluscs such as clams, oysters, and mussels and cephalopods such as octopus and squid), crustaceans (e.g. shrimp, crabs, and lobster), and echinoderms (e.g. sea cucumbers and sea urchins).** \n    \n**Historically, marine mammals such as cetaceans (whales and dolphins) as well as seals have been eaten as food, though that happens to a lesser extent in modern times. Edible sea plants such as some seaweeds and microalgae are widely eaten as sea vegetables around the world, especially in Asia. In the United States, although not generally in the United Kingdom, the term \"seafood\" is extended to fresh water organisms eaten by humans, so all edible aquatic life may be referred to as \"seafood\".**\n","18e11b90":"# 5. Training","78da5bba":"# 1. Dataset","a2eef768":"# 4. Modelling","0c6f3894":"## Response Variable Distribution\nLet's take a look, how the data is distributed","a5698e2a":"# \ud83d\udc31\u200d\ud83d\udcbb 99% accuracy","7b3a1280":"# 6. Testing","89d1268e":"<strong><span style=\"color:blue\"><span style=\"font-size:150%\">If you like my work, please don't forget to upvote this notebook!<\/span><\/span><\/strong>\n\n<strong><span style=\"color: seagreen\"><span style=\"font-size:150%\"> If you don't, atleast leave a comment on what should I do to improve it!<\/span><\/span><\/strong>","546b5ba3":"# 3. Visualizing Images after DataAugmentation","b2a8edf0":"As we can see the data is quite balanced.","e850f1f1":"# \ud83e\uddb9\u200d\u2642\ufe0fModelling\n1. Dataset\n2. DataGenerator and Loader\n3. Visualizing Images after DataAugmentation\n4. Model\n5. Training\n6. Testing\n","ba0335db":"# Visualizing our Dataset\n\nSimple images from the dataset nothing fancy.","08eca7ed":"I'm new to pytorch, I did not had a good idea to start.\n\nSo this notebook was inspired from [Konstanter](https:\/\/www.kaggle.com\/konstanter) & [Tanay](https:\/\/www.kaggle.com\/heyytanay).","f371a36a":"# 2. DataGenerator and loader"}}