{"cell_type":{"acf4e9cb":"code","5e5d0b72":"code","a7b84a24":"code","bfed7282":"code","f31492a2":"code","b894c843":"code","f33fc935":"code","19ebc796":"code","0e404991":"code","264bafe1":"code","9d104628":"code","3bef0a17":"code","dd1a061c":"code","fad169a7":"code","b502609f":"code","4e695805":"code","2b72d138":"code","8a42d252":"code","7592baea":"code","25f901b7":"code","d0ee5e96":"code","e38f9220":"code","d8fa1972":"code","ba227a06":"code","43cfc74e":"code","02989b91":"code","d60ae88f":"code","c2e0f90f":"code","e5b77c4f":"code","8b730f74":"code","bb981b7d":"code","502d2fb5":"code","a1fe5386":"markdown","38fabc70":"markdown","5255c6fc":"markdown","3644f91c":"markdown","4773b332":"markdown","8fe2f24e":"markdown","9858cc6e":"markdown","ec3f70c6":"markdown","e2a34b56":"markdown","6d82e26c":"markdown","abca3e50":"markdown","c85974aa":"markdown","0324ddf0":"markdown","b4d94f2e":"markdown","18d2971f":"markdown","94d73b34":"markdown","94392d94":"markdown","b91cc00c":"markdown","1c550836":"markdown","fdeaad70":"markdown","7907c8c0":"markdown","d7b9b22a":"markdown","b8d9989a":"markdown","637b593c":"markdown","52c990d1":"markdown","63d8ba6c":"markdown","70dd1878":"markdown"},"source":{"acf4e9cb":"import pandas as pd\nimport numpy as np\nfrom keras.datasets import fashion_mnist as FM\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","5e5d0b72":"df_train=pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntrain_label=df_train['label']\ntrain_data=np.array(df_train[df_train.columns[1:]])","a7b84a24":"df_test=pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\ntest_label=df_test['label']\ntest_data=np.array(df_test[df_test.columns[1:]])","bfed7282":"train_data.shape","f31492a2":"train_data=train_data.reshape(train_data.shape[0],28,28)\ntest_data=test_data.reshape(test_data.shape[0],28,28)","b894c843":"import matplotlib.pyplot as plt","f33fc935":"row,col=10,10\nfig=plt.figure(figsize=(20,20))\nfor i in range(row*col):\n    fig.add_subplot(row,col,i+1)\n    plt.imshow(train_data[i],cmap='Greys_r')\n    plt.axis('off')\n    plt.title(train_label[i])","19ebc796":"import seaborn as sn\nsn.countplot(train_label)\nplt.show()","0e404991":"len(pd.Series(train_label).unique())","264bafe1":"train_data.shape","9d104628":"train_data.max()","3bef0a17":"train_data=train_data\/train_data.max()","dd1a061c":"test_data=test_data\/test_data.max()","fad169a7":"from keras.models import *\nfrom keras.layers import *","b502609f":"from keras.utils import to_categorical\ntrain_label,test_label=to_categorical(train_label),to_categorical(test_label)","4e695805":"model=Sequential()\nmodel.add(InputLayer(input_shape=(28,28)))\nmodel.add(Flatten())\nmodel.add(Dense(units=10,activation='softmax'))","2b72d138":"model.summary()","8a42d252":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(train_data,train_label,epochs=10,batch_size=64,validation_data=(test_data,test_label))","7592baea":"x=train_data\nx_test=test_data\nx_test=x_test.reshape(x_test.shape[0],28*28)\nx=x.reshape(x.shape[0],28*28)","25f901b7":"model=Sequential()\nmodel.add(InputLayer(input_shape=(28*28)))\nmodel.add(Dense(units=1000,activation='relu'))\nmodel.add(Dense(units=100,activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(units=50,activation='relu'))\nmodel.add(Dense(units=10,activation='softmax'))\nmodel.summary()","d0ee5e96":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhist=model.fit(x,train_label,epochs=10,batch_size=64,validation_data=(x_test,test_label))","e38f9220":"train_acc=hist.history.get('accuracy')\nval_acc=hist.history.get('val_accuracy')\ntrain_loss=hist.history.get('loss')\nval_loss=hist.history.get('val_loss')","d8fa1972":"plt.plot(np.arange(1,len(train_acc)+1),train_acc,label='Train Accuracy')\nplt.plot(np.arange(1,len(val_acc)+1),val_acc,label='val accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()\n\nplt.plot(np.arange(1,len(train_loss)+1),train_loss,label='Train loss')\nplt.plot(np.arange(1,len(val_loss)+1),val_loss,label='val loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","ba227a06":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhist=model.fit(x,train_label,epochs=20,batch_size=64,validation_data=(x_test,test_label))","43cfc74e":"cov_model=Sequential()\ncov_model.add(InputLayer(input_shape=(28,28,1)))\ncov_model.add(Conv2D(32,(3,3),activation='relu'))\ncov_model.add(MaxPool2D(2,2))\n\ncov_model.add(Conv2D(128,(3,3),activation='relu'))\ncov_model.add(MaxPool2D(2,2))\ncov_model.add(Dropout(0.5))\n\ncov_model.add(Flatten())\n\ncov_model.add(Dense(units=3200,activation='relu'))\ncov_model.add(Dense(units=100,activation='relu'))\ncov_model.add(Dense(units=10,activation='softmax'))\ncov_model.summary()","02989b91":"test_data.shape","d60ae88f":"train_data,test_data=train_data.reshape(train_data.shape[0],28,28,1),test_data.reshape(test_data.shape[0],28,28,1)","c2e0f90f":"cov_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\ncov_model.fit(train_data,train_label,epochs=15,batch_size=64,validation_data=(test_data,test_label))","e5b77c4f":"cov_model=Sequential()\ncov_model.add(InputLayer(input_shape=(28,28,1)))\ncov_model.add(Conv2D(32,(5,5),activation='relu',padding='same'))\ncov_model.add(MaxPool2D(2,2))\n\ncov_model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\ncov_model.add(MaxPool2D(2,2))\n\ncov_model.add(Conv2D(256,(3,3),activation='relu'))\ncov_model.add(MaxPool2D(4,4))\ncov_model.add(Dropout(0.5))\n#Dropout for regularization\n\n\ncov_model.add(Flatten())\n\ncov_model.add(Dense(units=256,activation='relu'))\ncov_model.add(Dropout(0.5))\n\ncov_model.add(Dense(units=64,activation='relu'))\ncov_model.add(Dense(units=10,activation='softmax'))\ncov_model.summary()","8b730f74":"cov_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhist=cov_model.fit(train_data,train_label,epochs=20,batch_size=64,validation_data=(test_data,test_label))","bb981b7d":"train_acc=hist.history.get('accuracy')\nval_acc=hist.history.get('val_accuracy')\ntrain_loss=hist.history.get('loss')\nval_loss=hist.history.get('val_loss')","502d2fb5":"plt.plot(np.arange(1,len(train_acc)+1),train_acc,label='Train Accuracy')\nplt.plot(np.arange(1,len(val_acc)+1),val_acc,label='val accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()\n\nplt.plot(np.arange(1,len(train_loss)+1),train_loss,label='Train loss')\nplt.plot(np.arange(1,len(val_loss)+1),val_loss,label='val loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","a1fe5386":"# Importing training data and splitting it into train_data and train_label","38fabc70":"# Using covnets:","5255c6fc":"**The validation accuracy was still increasing which means we can either go for a more comlex model or increase the number of epochs**","3644f91c":"**We'll normalize the data that'd be fed to a neural network:**\nie, dividing by the highest value in the array","4773b332":"**Number of classes:**","8fe2f24e":"# Increasing number of epochs:","9858cc6e":"# Fitting the data","ec3f70c6":"# Let's start with a single layer perceptron and we'll go all the up to covnets ;)","e2a34b56":"**Flattening\/vectorizing training data\/images as well as the test images:**","6d82e26c":"# Further suggestions and comments are most welcome! Thank you for your time!","abca3e50":"**Reshaping the image data:**","c85974aa":"# Single layer perceptron","0324ddf0":"# ....And the test data as well","b4d94f2e":"Not bad for a single perceptron tbh!","18d2971f":"**Let's have a look at some training examples with labels:**","94d73b34":"# Plotting (train and test) (accuracies and losses) over the epochs","94392d94":"# Obtaining performance history of the model ie, metrics obtained per epoch:","b91cc00c":"**A very simple covnet:**","1c550836":"# Multilayer perceptron","fdeaad70":"**Defining the model:**","7907c8c0":"Just checking the shape again...","d7b9b22a":"**Flattening\/ vectorizing the test data\/images**","b8d9989a":"# Let's try adding some more convolutional layers so as to reduce the number of parameters in the Dense(MLP,hidden) layers","637b593c":"**Checking for balance among all the classes**","52c990d1":"**Checking the shape again LOL:**","63d8ba6c":"**Converting labels into sparse arrays as they'll represent the output of the neural network which'll have 10 neurons**","70dd1878":"# Reshaping the images so that we have one channel as well (gray channel) so that filters in the convolutional layers can create an instance for that channel. If the images were colored ie, if we had 3 channels, each filter in a convolutional layer would have 3 instances, one for each channel."}}