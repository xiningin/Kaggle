{"cell_type":{"00a1684a":"code","72e76de5":"code","fabfa063":"code","2576caae":"code","445584ea":"code","e37479cf":"code","2ec4bb60":"code","0989cda7":"code","bc8d6df6":"code","b665e252":"code","27946245":"code","4662dcd3":"code","4ac32046":"code","84229987":"code","89b3f8cc":"code","4b732b55":"code","38c3acb9":"code","3eaa83f1":"code","77f01ad3":"code","f19f5136":"code","17ef133e":"code","7ff86a37":"code","75114132":"code","a4f9a1da":"code","eaedcdd3":"code","16bde458":"code","0ebfbc80":"code","e5f4e8bb":"code","8721f553":"code","39acfc1a":"code","7b980faa":"code","0f5bc6e3":"code","683c4a09":"code","108fc330":"code","1d8edc44":"code","2e8f03cf":"code","ce27f12d":"code","86155795":"code","648490e8":"code","1d88287c":"code","a1a601e1":"code","f2be7a59":"code","8fa67cb8":"code","2bb79f19":"code","46e204c8":"code","eeacf67c":"code","73de1d6e":"code","9a5ba8bd":"code","30b38778":"code","48a04ef5":"code","f26d89bf":"code","fd066861":"markdown","85d4f08a":"markdown","f1ae478b":"markdown","8f8b751c":"markdown","9e1a28b9":"markdown","cd84f15a":"markdown"},"source":{"00a1684a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nimport mlb\nimport gc\npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72e76de5":"main_path = r\"..\/input\/mlb-player-digital-engagement-forecasting\"\npreload_path = r\"..\/input\/k\/ssmohanty\/mlb-master-ads-creation-v1-basic-eda\"\n\n#---------------------------------------------------------------------------\nmaster_ads = pd.read_csv(os.path.join(preload_path, \"master_ads_4_left_join.csv\"))\nmaster_ads.drop(columns=['Unnamed: 0','numberOfFollowers_x','numberOfFollowers_y'],inplace=True)\nprint(master_ads.shape)\nprint(master_ads.info())\nmaster_ads.head(3)","fabfa063":"# master_ads['trace_back_flag'] = np.where(master_ads.notna().all(axis=1), 1, 0)\nmaster_ads = master_ads.fillna(0)\nmaster_ads.info()","2576caae":"master_ads.isnull().sum()","445584ea":"# master_ads[master_ads['trace_back_flag']==1].head()","e37479cf":"dateCols = [col for col in master_ads.columns if ('date' in col) | ('Date' in col)]\ndateCols","2ec4bb60":"master_ads[['playerId','eng_date_pre','eng_date']].tail()","0989cda7":"master_ads[['target1','target2','target3','target4']].describe()","bc8d6df6":"target_1_med = master_ads['target1'].mean()\ntarget_2_med = master_ads['target2'].mean()\ntarget_3_med = master_ads['target3'].mean()\ntarget_4_med = master_ads['target4'].mean()","b665e252":"from sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport xgboost as xgb","27946245":"target_cols = ['target1','target2','target3','target4']\ntotal_cols = list(master_ads.columns)\nX_cols = [col for col in total_cols if col not in target_cols]\n\nprint('Total Cols :',len(total_cols))\nprint('X Cols :',len(X_cols))\n#--------------------------------------------------------------------------------------------\n\nX = master_ads.loc[:, X_cols]\ny = master_ads.loc[:, target_cols]\n\n#------------------------------------------------------------------------------------------\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.03,test_size=0.15, random_state=100)\n\nprint('Train X shape :',X_train.shape)\nprint('Test X shape :',X_test.shape)","4662dcd3":"catCols = [col for col in X_train.columns if X_train[col].dtype==\"O\"]\nlen(catCols)\ncatCols\n\ndateCols = [col for col in X_train.columns if ('date' in col) | ('Date' in col)]\nlen(dateCols)\n\nIdCols = [col for col in X_train.columns if ('Id' in col) | ('id' in col)]\nlen(IdCols)\nIdCols\n\nprint(dateCols)\nprint(IdCols)\nprint(catCols)","4ac32046":"level_cols = ['eng_date','eng_date_pre','playerId']\n\nX_train_1 = X_train.drop(columns=level_cols)\nX_test_1 = X_test.drop(columns=level_cols)\n\n#--------------------------------------------\nprint('Train X reduced shape :',X_train_1.shape)\nprint('Test X reduced shape :',X_test_1.shape)","84229987":"#X_train_1 = X_train_1.sample(100000,random_state=100)\n\n\n#print('Train shrinked shape :',X_train_1.shape)","89b3f8cc":"X_train_1.info()\nX_test_1.info()","4b732b55":"del X_train\ndel X_test\n#del master_ads\n\ngc.collect()","38c3acb9":"# ['awardPlayerTeamId', 'awardSeason', 'fromTeamId', 'toTeamId']\nX_train_1.drop(columns=['awardPlayerTeamId', 'awardSeason', 'fromTeamId', 'toTeamId'],inplace=True)\nX_test_1.drop(columns=['awardPlayerTeamId', 'awardSeason', 'fromTeamId', 'toTeamId'],inplace=True)","3eaa83f1":"X_train_1.isnull().sum()","77f01ad3":"xgb.XGBRegressor(random_state=100).get_params()","f19f5136":"#from xgboost import xgb\n\n#--------------------------------------------------\nestimator = xgb.XGBRegressor(reg_alpha = 50, reg_almbda = 60,random_state=100,n_jobs=-1)\nmodel = MultiOutputRegressor(estimator, n_jobs=-1)\n\n#--------------------------------------------------\nmodel.fit(X_train_1, y_train)\n\n#--------------------------------------------------\npred_xgb_multi = model.predict(X_test_1)\n               \n\n#--------------------------------------------------\npred_xgb_multi.shape ","17ef133e":"def scoring(truth_array,pred_array):\n    \n    diff = abs(truth_array - pred_array)\n    \n    print(diff[0:3])\n    \n    mean_col_wise = np.mean(diff,axis=0)\n    print(mean_col_wise)\n    \n    mean_MAE = np.mean(mean_col_wise)\n    \n    return mean_MAE","7ff86a37":"np.array(y_test)[0:3]","75114132":"pred_xgb_multi[0:3]","a4f9a1da":"xgb_score = scoring(np.array(y_test),pred_xgb_multi)\nxgb_score","eaedcdd3":"example_test = pd.read_csv(os.path.join(main_path, \"example_test.csv\"))\nexample_test.head(3)","16bde458":"def unpack_json(json_str):\n    return np.nan if pd.isna(json_str) else pd.read_json(json_str)\n\ndef data_extractor(df_,col_):\n    \n    print('------- Data Extraction for :',col_,'-------')\n    \n    final_df = pd.DataFrame()\n    \n    tmp = df_[col_]\n    tmp = tmp.dropna()\n    \n    #-------------------------------------------------------\n    for i in range(len(tmp)):\n        tmpdf = unpack_json(tmp.iloc[i])\n        final_df = final_df.append(tmpdf)\n    \n    #-------------------------------------------------------\n    print('Shape of final df BEFORE:',final_df.shape)\n    final_df = final_df.drop_duplicates()\n    print('Shape of final df AFTER:',final_df.shape)\n    print(final_df.columns)\n    #-------------------------------------------------------\n    \n    return final_df\n\n\ndef label_encoding_test(unique,col,df):\n    \n    print('-----',col,'-----')\n    \n    print('Before :',len(unique))\n    encodes_pre = unique\n    \n    encodes = np.arange(len(encodes_pre))\n    encodes = list(encodes+1)\n\n    mapping = dict(zip(encodes_pre,encodes))\n    df = df.replace({col:mapping})\n    print('After :',df[col].nunique())\n    \n    return df\n\ndef date_type_converter(df):\n    \n    date_cols = [col for col in list(df.columns) if (('date' in col) | ('Date' in col))]\n    \n    for col in date_cols:\n        df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n        \n    return df","0ebfbc80":"example_test.columns","e5f4e8bb":"example_test.isnull().sum()","8721f553":"test_df = data_extractor(example_test,'teamTwitterFollowers')\ntest_df.head()","39acfc1a":"# transactions_features_ = ['playerId', 'date', 'fromTeamId', 'toTeamId','typeCode','typeDesc']\n# team_twitter_features = ['date', 'teamId','twitterHandle',\n#        'numberOfFollowers']#twitterHandle_x will be of team\n\n#['awardPlayerTeamId', 'awardSeason', 'fromTeamId', 'toTeamId']\n\nstandings_features = ['season', 'gameDate', 'divisionId', 'teamId', 'streakCode',\n       'divisionRank', 'leagueRank', 'wildCardRank', 'leagueGamesBack',\n       'sportGamesBack', 'divisionGamesBack', 'wins', 'losses', 'pct',\n       'runsAllowed', 'divisionChamp', 'divisionLeader',\n       'wildCardLeader', 'eliminationNumber', 'wildCardEliminationNumber',\n       'homeWins', 'homeLosses', 'awayWins', 'awayLosses', 'lastTenWins',\n       'lastTenLosses', 'extraInningWins', 'extraInningLosses', 'oneRunWins',\n       'oneRunLosses', 'dayWins', 'dayLosses', 'nightWins', 'nightLosses',\n       'grassWins', 'grassLosses', 'turfWins', 'turfLosses', 'divWins',\n       'divLosses', 'alWins', 'alLosses', 'nlWins', 'nlLosses', 'xWinLossPct']\n# player_twitter_features = ['date', 'playerId', 'twitterHandle',\n#        'numberOfFollowers'] #twitterHandle_y will be of player\nplayer_scores_features = ['home', 'gamePk', 'gameDate', 'teamId',\n       'playerId', 'jerseyNum', 'positionCode',\n       'positionType', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances']\n# awards_df_features = ['awardId', 'awardDate', 'awardSeason', 'playerId', 'awardPlayerTeamId']","7b980faa":"\nfinal_features = list(X_train_1.columns)\n\n#--------------------------------------------------------------------------------------------------------------------\ndef ads_generator(df,final_features_generic):\n    \n    to_extract = ['standings','playerBoxScores']\n    \n    start = time.time()\n    \n    df_final = data_extractor(df,'playerBoxScores')\n    df_final = df_final[player_scores_features]\n    df_final = date_type_converter(df_final)\n    \n    to_extract.remove('playerBoxScores')\n    \n    for col in to_extract:\n        \n        df_temp = data_extractor(df,col)\n        \n#         if col == 'transactions':\n#             qc_df = df_temp.copy()\n        \n        df_temp = date_type_converter(df_temp)\n        \n        if 'date' in list(df_temp.columns):\n            print('1')\n        \n        \n        if col == 'transactions':\n            print('---------------------- Merging Operation for :',col,'------------------------')\n            df_final = pd.merge(df_final,df_temp[transactions_features_],\n                                left_on=['playerId','gameDate'],\n                                right_on=['playerId','date'],how='left')\n        \n        elif col == 'teamTwitterFollowers':\n            print('---------------------- Merging Operation for :',col,'------------------------')\n            df_final = pd.merge(df_final,df_temp[team_twitter_features],\n                                    left_on=['teamId','gameDate'],\n                                    right_on=['teamId','date'],how='left')\n        elif col == 'standings':\n            print('---------------------- Merging Operation for :',col,'------------------------')\n            df_final = pd.merge(df_final,df_temp[standings_features],\n                                    left_on=['teamId','gameDate'],\n                                    right_on=['teamId','gameDate'],how='left')\n            \n        elif col == 'playerTwitterFollowers':\n            print('---------------------- Merging Operation for :',col,'------------------------')\n            df_final = pd.merge(df_final,df_temp[player_twitter_features],left_on=['playerId','gameDate'],\n                                right_on=['playerId','date'],how='left')\n        \n        elif col == 'awards_df':\n            print('---------------------- Merging Operation for :',col,'------------------------')\n            df_final = pd.merge(df_final,df_temp[awards_df_features],left_on=['playerId','gameDate'],\n                                right_on=['playerId','awardDate'],how='left')\n            \n    df_final = df_final.fillna(0)\n    \n    #----------------------------------------------------------------------------------------------------\n#     df_final = label_encoding_test(twitterHandle_x_unique,'twitterHandle_x',df_final)\n#     df_final = label_encoding_test(awards_df_unique,'awards_df',df_final)\n#     df_final = label_encoding_test(twitterHandle_y_unique,'twitterHandle_y',df_final)\n    \n    #----------------------------------------------------------------------------------------------------\n    level_cols_test = ['gameDate']\n    df_final_1 = df_final.drop(columns=level_cols_test)\n    \n    df_final_1 = df_final_1[final_features_generic]\n    \n    end = time.time()\n    print('Time to Run:',end-start)\n    \n    return df_final\n","0f5bc6e3":"pd.DataFrame(example_test.iloc[0]).T","683c4a09":"pd.DataFrame(example_test.iloc[0]).T['date']","108fc330":"#example_test\ntest_ads_gen_df = ads_generator(pd.DataFrame(example_test.iloc[0]).T,final_features)","1d8edc44":"test_ads_gen_df = test_ads_gen_df[list(X_train_1.columns)]\ntype(test_ads_gen_df)","2e8f03cf":"test_ads_gen_df.head()","ce27f12d":"X_test_1.head(2)","86155795":"test_preds = model.predict(test_ads_gen_df)\ntest_preds","648490e8":"test_preds[:,0].shape","1d88287c":"example_submission = pd.read_csv(os.path.join(main_path, \"example_sample_submission.csv\"))\nexample_submission.head(3)","a1a601e1":"print(example_submission[0:2])","f2be7a59":"players = pd.read_csv(os.path.join(main_path, \"players.csv\"))\nplayers.head(3)","8fa67cb8":"# type(players[players['playerId']>50000000000])","2bb79f19":"# x\/hsybdksh","46e204c8":"# try:\n#     x\/hsybdksh\n# except:\n#     ax = 897\n    \n# print(ax)","eeacf67c":"env = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set","73de1d6e":"# Until the end\n\ncounter = 1\n\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    sample_prediction_df_copy = sample_prediction_df.copy()\n    \n    print('------------------------------------ Starting Date No:',counter,' -----------------------------------------')\n    \n    print(sample_prediction_df_copy[0:2])\n    print('-------------------------')\n        \n    sample_prediction_df_copy = sample_prediction_df_copy.reset_index(drop=True)\n    \n    print(sample_prediction_df_copy[0:2])\n    \n    # creat dataset\n    sample_prediction_df_copy['playerId'] = sample_prediction_df_copy['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[1]))\n    \n    print('Sample Pred Shape :',sample_prediction_df_copy.shape)\n    \n    try:\n        # Example: unpack a dataframe from a json column\n        test_ads_ext = ads_generator(test_df,final_features)\n        test_ads_ext = test_ads_ext.drop_duplicates(subset=['playerId'])\n        print('Pre-Merging of extracted ADS Shape :',test_ads_ext.shape)\n        \n    except:\n        print('Running Alternative Route 1')\n        test_ads_ext = 0\n        \n    \n    players_curr_day = sample_prediction_df_copy[['playerId']].drop_duplicates()\n    print('Pre-Merging of players Shape :',players_curr_day.shape)\n\n    #------------------------------------------------------------------------------------------------\n    if type(test_ads_ext)!=int:\n        \n        try:\n\n            test_ads_ext_final = pd.merge(players_curr_day,test_ads_ext,on=['playerId'],how='left')\n            print('Post Merging final ADS Shape :',test_ads_ext_final.shape)\n\n            test_ads_ext_final = test_ads_ext_final.fillna(0)\n            print('Post Null Treatment ADS Shape :',test_ads_ext_final.shape)\n\n            test_ads_ext_final = test_ads_ext_final[final_features]\n            print('Shape of prediction X :',test_ads_ext_final.shape)\n\n            pred = model.predict(test_ads_ext_final)\n\n            sample_prediction_df['target1'] = np.clip(pred[:,0], 0, 100)\n            sample_prediction_df['target2'] = np.clip(pred[:,1], 0, 100)\n            sample_prediction_df['target3'] = np.clip(pred[:,2], 0, 100)\n            sample_prediction_df['target4'] = np.clip(pred[:,3], 0, 100)\n\n            sample_prediction_df = sample_prediction_df.fillna(0.)\n        \n        except:\n            print('Running Alternative Route 2')\n            # Make your predictions for the next day's engagement\n            sample_prediction_df[\"target1\"] = target_1_med\n            sample_prediction_df[\"target2\"] = target_2_med\n            sample_prediction_df[\"target3\"] = target_3_med\n            sample_prediction_df[\"target4\"] = target_4_med\n            \n        \n    elif test_ads_ext == 0:\n        print('Running Alternative Route 3')\n        # Make your predictions for the next day's engagement\n        sample_prediction_df[\"target1\"] = target_1_med\n        sample_prediction_df[\"target2\"] = target_2_med\n        sample_prediction_df[\"target3\"] = target_3_med\n        sample_prediction_df[\"target4\"] = target_4_med\n          \n    #test_ads_ext_final = test_ads_ext_final.drop_duplicates() #Comment out - suspected\n    \n    #print('Post Merging & dupl drop final ADS Shape :',test_ads_ext_final.shape)\n    \n    \n    # Submit your predictions \n    env.predict(sample_prediction_df)","9a5ba8bd":"# # Until the end\n\n# for (test_df, sample_prediction_df) in iter_test:\n    \n#         # Example: unpack a dataframe from a json column\n#         #today_games = unpack_json(test_df['games'].iloc[0])\n    \n#         # Make your predictions for the next day's engagement\n#         sample_prediction_df[\"target1\"] = 0.26764763\n#         sample_prediction_df[\"target2\"] = 0.4\n#         sample_prediction_df[\"target3\"] = 0.5\n#         sample_prediction_df[\"target4\"] = 0.9\n        \n#         sample_prediction_df[\"target1\"] = sample_prediction_df[\"target1\"].astype('float32')\n#         sample_prediction_df[\"target2\"] = sample_prediction_df[\"target2\"].astype('float32')\n#         sample_prediction_df[\"target3\"] = sample_prediction_df[\"target3\"].astype('float32')\n#         sample_prediction_df[\"target4\"] = sample_prediction_df[\"target4\"].astype('float32')\n        \n    \n#         # Submit your predictions \n#         env.predict(sample_prediction_df)","30b38778":"# print(sample_prediction_df.dtypes)\n# sample_prediction_df.head()\n","48a04ef5":"\n# counter = 1\n\n# #------------------------------------------------------------------------------------------------------------------------\n# for (test_df, sample_prediction_df) in iter_test: # make predictions here\n    \n#     sample_prediction_df_copy = sample_prediction_df.copy()\n    \n#     print('------------------------------------ Starting Date No:',counter,' -----------------------------------------')\n    \n#     print(sample_prediction_df[0:2])\n#     print('-------------------------')\n    \n#     sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n    \n#     print(sample_prediction_df[0:2])\n    \n#     # creat dataset\n#     sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n#                                         .map(lambda x: int(x.split('_')[1]))\n    \n#     print('Sample Pred Shape :',sample_prediction_df.shape)\n    \n#     test_ads_ext = ads_generator(test_df,final_features)\n#     test_ads_ext = test_ads_ext.drop_duplicates(subset=['playerId'])\n    \n#     players_curr_day = sample_prediction_df[['playerId']].drop_duplicates()\n    \n#     print('Pre-Merging of players Shape :',players_curr_day.shape)\n#     print('Pre-Merging of extracted ADS Shape :',test_ads_ext.shape)\n    \n#     test_ads_ext_final = pd.merge(players_curr_day,test_ads_ext,on=['playerId'],how='left')\n          \n#     print('Post Merging final ADS Shape :',test_ads_ext_final.shape)\n          \n#     test_ads_ext_final = test_ads_ext_final.drop_duplicates()\n    \n#     print('Post Merging & dupl drop final ADS Shape :',test_ads_ext_final.shape)\n    \n#     test_ads_ext_final = test_ads_ext_final.fillna(0)\n          \n#     print('Post Null Treatment ADS Shape :',test_ads_ext_final.shape)\n    \n#     test_ads_ext_final = test_ads_ext_final[final_features]\n#     print('Shape of prediction X :',test_ads_ext_final.shape)\n    \n#     pred = model.predict(test_ads_ext_final)\n    \n#     sample_prediction_df['target1'] = np.clip(pred[:,0], 0, 100)\n#     sample_prediction_df['target2'] = np.clip(pred[:,1], 0, 100)\n#     sample_prediction_df['target3'] = np.clip(pred[:,2], 0, 100)\n#     sample_prediction_df['target4'] = np.clip(pred[:,3], 0, 100)\n    \n#     sample_prediction_df = sample_prediction_df.fillna(0.)\n    \n#     submission = (\n#         sample_prediction_df_copy\n#         [['date_playerId']]\n#         .reset_index()  #  preserve index 'date'\n#         .merge(sample_prediction_df[['date_playerId','target1','target2','target3','target4']],\n#                how='left', on='date_playerId')\n#         .set_index('date')  #  restore index 'date'\n#     )\n    \n#     del test_df\n#     del players_curr_day\n#     del test_ads_ext_final\n#     #sample_prediction_df.drop(columns=['playerId'],inplace=True)\n#     del sample_prediction_df\n#     del sample_prediction_df_copy\n    \n#     print('--------------------------------- Submitting for counter :',counter,'------------------------------------')\n#     counter = counter + 1\n    \n#     #print(sample_prediction_df[0:2])\n    \n#     env.predict(submission)\n    \n    \n    ","f26d89bf":"# print(submission.dtypes)\n# submission.head()\n","fd066861":"## Submitting Predictions","85d4f08a":"## Necessary libraries for ML pred","f1ae478b":"## Train-Test Split","8f8b751c":"## XGB Regressor w\/ multiple o\/p's (sklearn wrapper)","9e1a28b9":"## Further data processing (Removing Level Columns from train and test X)","cd84f15a":"## Check for un-encoded categorical cols, date columns, Id columns"}}