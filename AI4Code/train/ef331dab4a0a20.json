{"cell_type":{"091d672b":"code","6a62348d":"code","2318cac7":"code","1bb1df13":"code","9c33a00f":"code","c7fc88fb":"code","8724fc4e":"code","295977d1":"code","fa0f6789":"code","9e3b85d2":"code","95597d60":"code","50dc421d":"code","9221d069":"code","066aca66":"code","3d364eea":"code","d67b7e70":"code","98f8429e":"code","d4598d72":"code","c6cd2944":"code","c99f374f":"code","ec48dd05":"code","636a67c6":"code","0af5d0b6":"code","0290eba0":"code","aa111087":"code","26b1ea60":"code","86b7eb8a":"code","b441e296":"code","11076683":"code","ab2c0399":"code","a848b7c5":"code","9c27b1b5":"code","3eaf498b":"code","8dee6c77":"code","1df5baaf":"markdown","33353f04":"markdown","53c02998":"markdown","a8518e75":"markdown","f48b8619":"markdown","d52499e3":"markdown","cbd20e8d":"markdown","75c9bd91":"markdown","5dd50e3d":"markdown","59696466":"markdown","bccae378":"markdown","7d4aa4b2":"markdown","1809df17":"markdown","30ac5afb":"markdown","c917a395":"markdown","ff1e4ab4":"markdown","6336b99b":"markdown","c0690b9c":"markdown"},"source":{"091d672b":"!pip install -Uqqq scikit-learn","6a62348d":"import sklearn\nsklearn.__version__","2318cac7":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import accuracy_score as acc","1bb1df13":"from sklearn.tree import export_graphviz\nimport graphviz\nimport re\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0, **kwargs):\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n                      special_characters=True, rotate=False, precision=precision, **kwargs)\n    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))","9c33a00f":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_df.tail(2)","c7fc88fb":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.tail(2)","8724fc4e":"X = train_df.copy()\ny = X.pop('Survived')\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)","295977d1":"dummy_most_freq = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\ny_pred = dummy_most_freq.predict(X_valid)\nacc(y_pred, y_valid)","fa0f6789":"pd.concat([X_train, y_train], axis = 1).groupby('Sex')['Survived'].mean()","9e3b85d2":"(X_train['Sex'] == 'female').mean()","95597d60":"def dummy_female(X): return (X['Sex'] == 'female').astype(int)\ny_pred = dummy_female(X_valid)\nacc(y_pred, y_valid)","50dc421d":"X.head(1)","9221d069":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.model_selection import KFold, cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np","066aca66":"kf = KFold(n_splits=10, random_state=42, shuffle=True)","3d364eea":"score = []\nfor train_id, valid_id in kf.split(X, y):\n    X_train = X.loc[train_id]\n    X_valid = X.loc[valid_id]\n    y_train = y.loc[train_id]\n    y_valid = y.loc[valid_id]\n    \n    y_pred = dummy_female(X_valid)\n    score.append(acc(y_pred, y_valid))\nscore = np.array(score)\nscore, score.mean(), score.std()","d67b7e70":"cat_feat = ['Sex', 'Ticket', 'Cabin', 'Embarked']\nnum_feat = ['Pclass', 'Age', 'SibSp', 'Parch']","98f8429e":"num_transform = SimpleImputer(strategy = 'constant', fill_value = -1)\n\ncat_transform = Pipeline(\n    steps = [\n        ('inputer', SimpleImputer(strategy = 'constant', fill_value = '#NA#')),\n        ('encoder', OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1))\n    ]\n)\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num', num_transform, num_feat),\n        ('cat', cat_transform, cat_feat)\n    ]\n)","d4598d72":"pipeline = Pipeline(\n    steps = [\n        ('pre', preprocessor),\n        ('model', DecisionTreeClassifier(max_depth = 1, random_state=42))\n    ]\n)\nscore = cross_val_score(pipeline, X, y, cv = kf)\nscore, score.mean(), score.std()","c6cd2944":"pipeline.fit(X, y);\ndraw_tree(pipeline['model'], X[num_feat+cat_feat], size = 7)","c99f374f":"for md in [1, 2, 3, 5, 10, 20]:\n    pipeline = Pipeline(\n        steps = [\n            ('pre', preprocessor),\n            ('model', DecisionTreeClassifier(max_depth = md, random_state=42))\n        ]\n    )\n    score = cross_val_score(pipeline, X, y, cv = kf)\n    print(f'max_depth: {md:>2} | {score.mean():.3f}+-{score.std():.3f}')","ec48dd05":"for md in [1, 2, 3, 4, 5, 6, 7, 8]:\n    pipeline = Pipeline(\n        steps = [\n            ('pre', preprocessor),\n            ('model', RandomForestClassifier(max_depth = md, random_state=42))\n        ]\n    )\n    score = cross_val_score(pipeline, X, y, cv = kf)\n    print(f'max_depth: {md:>2} | {score.mean():.3f}+-{score.std():.3f}')","636a67c6":"for a in [0.01, 0.1, 1, 10, 100, 1000]:\n    pipeline = Pipeline(\n        steps = [\n            ('pre', preprocessor),\n            ('model', RidgeClassifier(alpha = a, random_state=42))\n        ]\n    )\n    score = cross_val_score(pipeline, X, y, cv = kf)\n    print(f'max_depth: {md:>2} | {score.mean():.3f}+-{score.std():.3f}')","0af5d0b6":"for md in [1, 2, 3, 4, 5, 6, 7, 8]:\n    pipeline = Pipeline(\n        steps = [\n            ('pre', preprocessor),\n            ('model', ExtraTreesClassifier(max_depth = md, random_state=42))\n        ]\n    )\n    score = cross_val_score(pipeline, X, y, cv = kf)\n    print(f'max_depth: {md:>2} | {score.mean():.3f}+-{score.std():.3f}')","0290eba0":"pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', VotingClassifier(estimators=[\n        ('rf', RandomForestClassifier(max_depth = 6, n_estimators=200, random_state=42)),\n        ('ridge', RidgeClassifier(alpha = 100, random_state = 42)),\n        ('et', ExtraTreesClassifier(max_depth = 4, n_estimators=200, random_state=42)), \n    ]))\n])\n\nscore = cross_val_score(pipeline, X, y, cv = kf)\nscore, score.mean(), score.std()","aa111087":"best_single_model = RandomForestClassifier(max_depth = 6, random_state=42)\nbest_single_pipeline = Pipeline(\n    steps = [\n        ('pre', preprocessor),\n        ('model', best_single_model)\n    ]\n).fit(X, y)","26b1ea60":"preds = best_single_pipeline.predict(X)\n(preds == y).mean()","86b7eb8a":"ensemble_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', VotingClassifier(estimators=[\n        ('rf', RandomForestClassifier(max_depth = 6, n_estimators=200, random_state=42)),\n        ('ridge', RidgeClassifier(alpha = 100, random_state = 42)),\n        ('et', ExtraTreesClassifier(max_depth = 4, n_estimators=200, random_state=42)), \n    ]))\n]).fit(X, y);","b441e296":"preds = ensemble_pipeline.predict(X)\n(preds == y).mean()","11076683":"from joblib import dump, load\n\ndump(best_single_pipeline, 'best_single.pipe')\ndump(ensemble_pipeline, 'ensemble.pipe')","ab2c0399":"pipe = load('best_single.pipe')\npreds_loaded = pipe.predict(X)\n(preds_loaded == y).mean()","a848b7c5":"pipe = load('ensemble.pipe')\npreds_loaded = pipe.predict(X)\n(preds_loaded == y).mean()","9c27b1b5":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.tail(2)","3eaf498b":"pipeline = load('ensemble.pipe')\npredictions = test_df.copy()\npredictions['Survived'] = pipeline.predict(predictions)","8dee6c77":"submission = predictions[['PassengerId', 'Survived']]\nsubmission.to_csv('submission.csv', index = False)\nsubmission","1df5baaf":"# Evaluating using CV","33353f04":"## Predicting always 0 (dead, the most common class)","53c02998":"# Saving","a8518e75":"# Baseline","f48b8619":"## Best single model","d52499e3":"# Train\/valid Split","cbd20e8d":"# ET","75c9bd91":"# Baselines","5dd50e3d":"# ML models","59696466":"# Ensembling","bccae378":"## Ensemble","7d4aa4b2":"# RF","1809df17":"# Ridge","30ac5afb":"# Final model","c917a395":"# DT (all male dies)","ff1e4ab4":"## Predicting all females survived","6336b99b":"# Sanity","c0690b9c":"# Inference"}}