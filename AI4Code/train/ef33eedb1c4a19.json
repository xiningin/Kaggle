{"cell_type":{"a314319d":"code","97a4b626":"code","bbca98b2":"code","538021c1":"code","cfece9cb":"code","85b78778":"code","2cad1eca":"code","d648e311":"code","9460db23":"code","30101a7e":"code","a442344a":"code","36992d8a":"code","d1956406":"code","a44a89fe":"code","5535bc41":"code","a4508c91":"code","f27c1e94":"code","7f51a1a0":"code","6b829407":"code","ea7f760a":"code","1c746c2a":"code","78e1b7f6":"code","89c54352":"code","ea658679":"code","1bed4bb8":"code","490c9522":"code","c7e229ae":"code","86c72d49":"code","e3f2426e":"code","afa1cbbd":"code","b159e736":"code","f4b0c45a":"code","518dcc1b":"code","e109d745":"code","b6fb947f":"markdown","c1b90578":"markdown","70f1b898":"markdown","f2e22f5d":"markdown","adb271f1":"markdown","8eb18b36":"markdown"},"source":{"a314319d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97a4b626":"train_path = '..\/input\/cat-in-the-dat\/train.csv'\ntest_path = '..\/input\/cat-in-the-dat\/test.csv'","bbca98b2":"train = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\ntrain","538021c1":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(16,5))\nsns.countplot(x = train['target'], data=train)\n# \uc560\ucd08\uc5d0 '0'\ubcf4\ub2e4 '1'\uc774 \ud6e8\uc52c \uc801\uc74c(\uc808\ubc18\ub3c4 \uc548\ub428)","cfece9cb":"sns.countplot(x=train['bin_3'],)","85b78778":"def find_missing_cols(dataframe, list):\n    list = []\n    columns = dataframe.columns\n    for col in columns:\n        missing_judgement = dataframe[col].isnull().any()\n        if missing_judgement == True:\n            list.append(col)\n        else:\n            pass\n    return list\n\nmissing_col=[]\nmissing_col = find_missing_cols(train, missing_col)\nmissing_col","2cad1eca":"def find_category_col(dataframe):\n    s = (dataframe.dtypes == 'object')\n    object_cols = list(s[s].index)\n    return object_cols\n\ncat_cols = find_category_col(train)\ncat_cols","d648e311":"value_counting = []\nfor cols in cat_cols:\n    a = len(train[cols].unique())\n    value_counting.append(a)    \nvalue_counting\n\nvalues = pd.DataFrame({'columns' : cat_cols, 'values count': value_counting})\nvalues","9460db23":"drop_nom_data = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\ndrop_ord_data = ['ord_5']\n#train['ord_4'].value_counts()","30101a7e":"## train set \uc815\ub9ac\ndr_train = train.drop(drop_nom_data, axis=1)\nnew_train = dr_train.drop(drop_ord_data, axis=1)\n## test set \uc815\ub9ac\ndr_test = test.drop(drop_nom_data, axis=1)\nnew_test = dr_test.drop(drop_ord_data, axis=1)\n\nnew_train","a442344a":"## train, test set categorical column \ucd94\ucd9c\nnew_cat_col = find_category_col(new_train)\nnew_cat_col","36992d8a":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\n\nlabel_train = new_train.copy()\nlabel_test = new_test.copy()\n\nencoder = LabelEncoder()\n\nfor cols in new_cat_col:\n    label_train[cols] = encoder.fit_transform(new_train[cols])\n    label_test[cols] = encoder.transform(new_test[cols])\n","d1956406":"label_test['ord_4']","a44a89fe":"x = label_train.drop('target', axis=1)\ny = label_train['target']\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=7)","5535bc41":"random_regressor = RandomForestRegressor(n_estimators=100, max_leaf_nodes=8)\nrandom_regressor.fit(x_train, y_train)\n\ny_check = random_regressor.predict(x_val)\n\n#tree_regressor = DecisionTreeRegressor(n_estimators=100, max_leaf_nodes=16)","a4508c91":"xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.01, n_jobs=4)\nxgb_model.fit(x_train, y_train, \n             early_stopping_rounds=10, \n             eval_set=[(x_val, y_val)], \n             verbose=False)\nxgb_pred = xgb_model.predict(x_val)\nprint(roc_auc_score(y_val, xgb_pred))\n","f27c1e94":"mean_absolute_error(y_val, xgb_pred)","7f51a1a0":"xgb_test_pred = xgb_model.predict(label_test)","6b829407":"from sklearn.datasets import load_iris\nfrom sklearn.linear_model import Perceptron\n\niris = load_iris()\n\nper_clf = Perceptron()\nper_clf.fit(x_train, y_train)\n\npcp_pred = per_clf.predict(x_val)\nroc_auc_score(y_val, pcp_pred)","ea7f760a":"pcp_test_pred = per_clf.predict(label_test)","1c746c2a":"id = label_test['id']","78e1b7f6":"submission = pd.DataFrame({'id': id, 'target': xgb_test_pred})\n#submission['target'].value_counts()","89c54352":"submission","ea658679":"submission.to_csv('submission3.csv', index=False)","1bed4bb8":"train","490c9522":"## bin_0 : \uac70\uc758 \ube44\uc2b7\ud558\ub2e4\ntrain['bin_0'].value_counts()\nplt.figure(figsize=(10,10))\nsns.barplot(x=train.bin_0, y=train.target)","c7e229ae":"## bin_1\ntrain['bin_1'].value_counts() # '0' >> '1'\n#plt.figure(figsize=(20,10))\nsns.barplot(x=train.bin_1, y=train.target) # '0'\uac12\uc744 \uac00\uc9c4 \ud56d\ubaa9\uc774 '1'\uc758 \ube44\uc728\uc744 \ub354 \ub9ce\uc774 \uac00\uc9d0","86c72d49":"##bin_2\ntrain['bin_2'].value_counts() #'0':185000, '1':115000\nsns.barplot(x=train['bin_2'], y=train['target']) #'0'\uacfc '1'\uc774 target\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc740 \uac70\uc758 \ube44\uc2b7(1\uc774 \ub354 \uc6b0\uc138\ud558\ub2e4)","e3f2426e":"##bin_3\ntrain['bin_3'].value_counts() # 'T':153535  'F':146465\nsns.catplot(data=train, x='bin_3', y='target', hue='bin_0', kind='bar', palette='dark', alpha=.5, height=7)\n## bin_3('T'): bin_0('0') >> bin_0('1')  \n## bin_3('F'): bin_0('0') >> bin_0('1')\n##  ===> bin_3\uc774 T\uc77c \ub54c\ub294 bin_0\uac00 0,  bin_3\uc774 F\uc77c \ub54c\ub294 bin_0\uac00 1\uc77c \ub54c target\uc774 1\uc774 \ub420 \ud655\ub960 up\nsns.catplot(data=train, x='bin_3', y='target', hue='bin_1', kind='bar', palette='dark', alpha=.7, height=7)\n## bin_3('T'): bin_1('0') >> bin_1('1')  \n## bin_3('F'): bin_1('0') >> bin_1('1')\n##  ===> bin_3\uc774 T, F\uc77c \ub54c\ub294 bin_1\uc774 0\uc774\uba74 target\uc774 1\uc774 \ub420 \ud655\ub960 up\nsns.catplot(data=train, x='bin_3', y='target', hue='bin_2', kind='bar', ci='sd', palette='dark', alpha=.7, height=7)\n## bin_3('T'): bin_2('1') >> bin_2('0')  \n## bin_3('F'): bin_2('1') >> bin_2('0')\n##  ===> bin_3\uc774 T, F\uc77c \ub54c\ub294 bin_2\uc774 1\uc774\uba74 target\uc774 1\uc774 \ub420 \ud655\ub960 up\nplt.show()","afa1cbbd":"##bin_4\ntrain['bin_4'].value_counts() #'Y':191633, 'N':108367\nsns.barplot(x=train.bin_4, y=train.target) #N\uc774 Y\ubcf4\ub2e4 target\uc5d0\uc11c 1\uc758 \ube44\uc728\uc774 \uc870\uae08 \ub354 \ub9ce\uc74c\nsns.catplot(data=train, x='bin_4', y='target', hue='bin_3', kind='bar')\n## bin_4('Y'): bin_3('F') >> bin_3('T')  \n## bin_4('N'): bin_3('F') >> bin_3('T')\n##  ===> bin_4\uc774 Y, N\uc77c \ub54c\ub294 bin_3\uc774 F\uc774\uba74 target\uc774 1\uc774 \ub420 \ud655\ub960 up","b159e736":"values","f4b0c45a":"values.iloc[11,1]\nvalues.loc[11,'values count']","518dcc1b":"#train.nom_9.value_counts() <==\ubc84\ub824","e109d745":"train.target.value_counts()","b6fb947f":"## Submission","c1b90578":"## RandomForestRegressor","70f1b898":"## XGBRegressor","f2e22f5d":"### ==> missing value\uac00 \uc5c6\uc74c****","adb271f1":"## Perceptron","8eb18b36":"## Feature Scaling"}}