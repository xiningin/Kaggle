{"cell_type":{"4552cde3":"code","33b4614e":"code","ee1331e6":"code","c61e08ae":"code","3a8d6c3e":"code","52ba9687":"code","d63b6e09":"code","72ad00d3":"code","0dd1020f":"code","d30c8ec3":"code","61e04976":"code","7fe719cb":"code","ecea3a0c":"code","890a0606":"code","f3ab2809":"code","94169b77":"markdown","9e8a42f2":"markdown","6cbc1c01":"markdown","15280731":"markdown","a25935bd":"markdown","8e9e93c8":"markdown","2407039d":"markdown","bb5d3dd3":"markdown","c3a515be":"markdown"},"source":{"4552cde3":"%%writefile SimulationExplorer.py\n\nimport matplotlib.pyplot as plt\n\nclass SimViz:\n    '''\n    '''\n    \n    def __init__(self, sims=None):\n        \n        # Copy simulations to object\n        if sims:\n            self.sims = {name:env for name,env in sims.items()}\n            # Get simulation environments (JSON)\n            self.envs = {k:self.get_env_json(env) for k,env in self.sims.items()}\n        else:\n            self.sims = {}\n            self.envs = {}\n            \n    def get_env_json(self, env):\n        '''\n        '''\n        try:\n            env_json = env.toJSON()\n            return env_json\n        except:\n            print('ERROR: Invalid environment')\n            \n    def add_env(self, env, name=None):\n        '''\n        '''\n        # TODO: Make sure it is a unique name\n        if name is None:\n            name =  f'{len(self.envs) + 1}'\n            name += f'_{\"\".join(k[-1] for k in self.envs.keys())}'\n        # Add to both sims and envs\n        self.sims[name] = env\n        self.envs[name] = self.get_env_json(env)\n        \n    def add_sim(self, env, name=None):\n        '''\n        '''\n        # TODO: Make sure it is a unique name\n        if name is None:\n            name =  f'{len(self.sims) + 1}'\n            name += f'_{\"\".join(k[-1] for k in self.sims.keys())}'\n        # Add to both sim and env\n        self.sims[name] = env\n        self.add_env(env, name)\n            \n\n    def get_rewards(self, name):\n        '''\n        '''\n        # TODO:  Check for error\n        agent_steps = self.envs.get(name).get('steps')\n        n_steps = len(agent_steps)\n        rewards = [agent_steps[s][0].get('reward') for s in range(n_steps)]\n        return rewards\n    \n    def plot_total_reward(self, names=None, *args, **kwargs):\n        '''\n        '''\n        fig,ax = plt.subplots(figsize=(12,8))\n        ax.set_title('Total Rewards Over Steps')\n        ax.set_xlabel('Steps')\n        ax.set_ylabel('Rewards (cummulative)')\n        if names is None:\n            names = list(self.envs.keys())\n        elif not isinstance(names, list):\n            names = [names]\n        \n        # Plot all the simulations given\n        for name in names:\n            rewards = self.get_rewards(name)\n            ax.plot(rewards, label=name, *args, **kwargs)\n        \n        ax.legend(loc='upper left', ncol=2)\n#         ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n#            ncol=2)\n\n        return fig,ax\n   \n        \n            ","33b4614e":"%%writefile always0_agent.py\n\n# Randomly pick different bandits\/machines\ndef always0_agent(observation, configuration):\n    '''Always select machine #0\n    '''\n    choice = 0\n    return choice\n","ee1331e6":"%%writefile random_agent.py\n\nimport numpy as np\nnp.random.seed(27)\n\n# Randomly pick different bandits\/machines\ndef random_agent(observation, configuration):\n    '''Randomly select machine\n    '''\n    # Cast from NumPy integer type\n    choice = int(np.random.choice(np.arange(configuration.banditCount)))\n    return choice\n","c61e08ae":"!pip install kaggle-environments --upgrade","3a8d6c3e":"from kaggle_environments import make","52ba9687":"always0_v_always0 = make(\"mab\", debug=True)\n\nalways0_v_always0.run([\"always0_agent.py\", \"always0_agent.py\"])\nalways0_v_always0.render(mode=\"ipython\", width=800, height=300)","d63b6e09":"random_v_random_env = make(\"mab\", debug=True)\n\nrandom_v_random_env.run([\"random_agent.py\", \"random_agent.py\"])\nrandom_v_random_env.render(mode=\"ipython\", width=800, height=300)","72ad00d3":"random_v_always0 = make(\"mab\", debug=True)\n\nrandom_v_always0.run([\"random_agent.py\", \"always0_agent.py\"])\nrandom_v_always0.render(mode=\"ipython\", width=800, height=300)","0dd1020f":"always0_v_random = make(\"mab\", debug=True)\n\nalways0_v_random.run([\"always0_agent.py\", \"random_agent.py\"])\nalways0_v_random.render(mode=\"ipython\", width=800, height=300)","d30c8ec3":"import SimulationExplorer as Explorer","61e04976":"sims = {\n    'always_0-v-always_0': always0_v_always0,\n    'random-v-always_0': random_v_always0,\n    'random-v-random': random_v_random_env,\n    'always_0-v-random': always0_v_random,\n}","7fe719cb":"test = Explorer.SimViz(sims)","ecea3a0c":"f ,ax = test.plot_total_reward(linestyle='dashed')","890a0606":"f_rand, ax_rand = test.plot_total_reward(['always_0-v-always_0','always_0-v-random'])","f3ab2809":"for n,env in sims.items():\n    print(n,env.toJSON().get('rewards'))","94169b77":"## Motivation\n\nI've been playing around with relatively simple strategies like the $\\epsilon$-greedy algorithm just to see how the agent does in general. I wanted a way to compare the different models other than looking at the final score.","9e8a42f2":"## Visualize Agents","6cbc1c01":"# Example Usage","15280731":"### Run simulation","a25935bd":"### Example agent","8e9e93c8":"# Class Definition\n\nHere we define our class to make life easy to plot multiple simulations to compare","2407039d":"# Visualizing Rewards","bb5d3dd3":"### Check that simulation total results match with plots","c3a515be":"## Simulate Agents"}}